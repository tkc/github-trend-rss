<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Mon, 16 Feb 2026 00:08:23 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[steipete/gogcli]]></title>
            <link>https://github.com/steipete/gogcli</link>
            <guid>https://github.com/steipete/gogcli</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:23 GMT</pubDate>
            <description><![CDATA[Google Suite CLI: Gmail, GCal, GDrive, GContacts.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/steipete/gogcli">steipete/gogcli</a></h1>
            <p>Google Suite CLI: Gmail, GCal, GDrive, GContacts.</p>
            <p>Language: Go</p>
            <p>Stars: 2,957</p>
            <p>Forks: 257</p>
            <p>Stars today: 630 stars today</p>
            <h2>README</h2><pre># üß≠ gogcli ‚Äî Google in your terminal.

![GitHub Repo Banner](https://ghrb.waren.build/banner?header=gogcli%F0%9F%A7%AD&amp;subheader=Google+in+your+terminal&amp;bg=f3f4f6&amp;color=1f2937&amp;support=true)
&lt;!-- Created with GitHub Repo Banner by Waren Gonzaga: https://ghrb.waren.build --&gt;

Fast, script-friendly CLI for Gmail, Calendar, Chat, Classroom, Drive, Docs, Slides, Sheets, Forms, Apps Script, Contacts, Tasks, People, Groups (Workspace), and Keep (Workspace-only). JSON-first output, multiple accounts, and least-privilege auth built in.

## Features

- **Gmail** - search threads and messages, send emails, view attachments, manage labels/drafts/filters/delegation/vacation settings, history, and watch (Pub/Sub push)
- **Email tracking** - track opens for `gog gmail send --track` with a small Cloudflare Worker backend
- **Calendar** - list/create/update events, detect conflicts, manage invitations, check free/busy status, team calendars, propose new times, focus/OOO/working-location events, recurrence + reminders
- **Classroom** - manage courses, roster, coursework/materials, submissions, announcements, topics, invitations, guardians, profiles
- **Chat** - list/find/create spaces, list messages/threads (filter by thread/unread), send messages and DMs (Workspace-only)
- **Drive** - list/search/upload/download files, manage permissions/comments, organize folders, list shared drives
- **Contacts** - search/create/update contacts, access Workspace directory/other contacts
- **Tasks** - manage tasklists and tasks: get/create/add/update/done/undo/delete/clear, repeat schedules
- **Sheets** - read/write/update spreadsheets, format cells, create new sheets (and export via Drive)
- **Forms** - create/get forms and inspect responses
- **Apps Script** - create/get projects, inspect content, and run functions
- **Docs/Slides** - export to PDF/DOCX/PPTX via Drive (plus create/copy, docs-to-text)
- **People** - access profile information
- **Keep (Workspace only)** - list/get/search notes and download attachments (service account + domain-wide delegation)
- **Groups** - list groups you belong to, view group members (Google Workspace)
- **Local time** - quick local/UTC time display for scripts and agents
- **Multiple accounts** - manage multiple Google accounts simultaneously (with aliases)
- **Command allowlist** - restrict top-level commands for sandboxed/agent runs
- **Secure credential storage** using OS keyring or encrypted on-disk keyring (configurable)
- **Auto-refreshing tokens** - authenticate once, use indefinitely
- **Least-privilege auth** - `--readonly` and `--drive-scope` to request fewer scopes
- **Workspace service accounts** - domain-wide delegation auth (preferred when configured)
- **Parseable output** - JSON mode for scripting and automation (Calendar adds day-of-week fields)

## Installation

### Homebrew

```bash
brew install steipete/tap/gogcli
```
### Arch User Repository

```bash
yay -S gogcli
```

### Build from Source

```bash
git clone https://github.com/steipete/gogcli.git
cd gogcli
make
```

Run:

```bash
./bin/gog --help
```

Help:

- `gog --help` shows top-level command groups.
- Drill down with `gog &lt;group&gt; --help` (and deeper subcommands).
- For the full expanded command list: `GOG_HELP=full gog --help`.
- Make shortcut: `make gog -- --help` (or `make gog -- gmail --help`).
- `make gog-help` shows CLI help (note: `make gog --help` is Make‚Äôs own help; use `--`).
- Version: `gog --version` or `gog version`.

## Quick Start

### 1. Get OAuth2 Credentials

Before adding an account, create OAuth2 credentials from Google Cloud Console:

1. Open the Google Cloud Console credentials page: https://console.cloud.google.com/apis/credentials
1. Create a project: https://console.cloud.google.com/projectcreate
2. Enable the APIs you need:
   - Gmail API: https://console.cloud.google.com/apis/api/gmail.googleapis.com
   - Google Calendar API: https://console.cloud.google.com/apis/api/calendar-json.googleapis.com
   - Google Chat API: https://console.cloud.google.com/apis/api/chat.googleapis.com
   - Google Drive API: https://console.cloud.google.com/apis/api/drive.googleapis.com
   - Google Classroom API: https://console.cloud.google.com/apis/api/classroom.googleapis.com
   - People API (Contacts): https://console.cloud.google.com/apis/api/people.googleapis.com
   - Google Tasks API: https://console.cloud.google.com/apis/api/tasks.googleapis.com
   - Google Sheets API: https://console.cloud.google.com/apis/api/sheets.googleapis.com
   - Google Forms API: https://console.cloud.google.com/apis/api/forms.googleapis.com
   - Apps Script API: https://console.cloud.google.com/apis/api/script.googleapis.com
   - Cloud Identity API (Groups): https://console.cloud.google.com/apis/api/cloudidentity.googleapis.com
3. Configure OAuth consent screen: https://console.cloud.google.com/auth/branding
4. If your app is in &quot;Testing&quot;, add test users: https://console.cloud.google.com/auth/audience
5. Create OAuth client:
   - Go to https://console.cloud.google.com/auth/clients
   - Click &quot;Create Client&quot;
   - Application type: &quot;Desktop app&quot;
   - Download the JSON file (usually named `client_secret_....apps.googleusercontent.com.json`)

### 2. Store Credentials

```bash
gog auth credentials ~/Downloads/client_secret_....json
```

For multiple OAuth clients/projects:

```bash
gog --client work auth credentials ~/Downloads/work-client.json
gog auth credentials list
```

### 3. Authorize Your Account

```bash
gog auth add you@gmail.com
```

This will open a browser window for OAuth authorization. The refresh token is stored securely in your system keychain.

Headless / remote server flows (no browser on the server):

Manual interactive flow (recommended):

```bash
gog auth add you@gmail.com --services user --manual
```

- The CLI prints an auth URL. Open it in a local browser.
- After approval, copy the full loopback redirect URL from the browser address bar.
- Paste that URL back into the terminal when prompted.

Split remote flow (`--remote`, useful for two-step/scripted handoff):

```bash
# Step 1: print auth URL (open it locally in a browser)
gog auth add you@gmail.com --services user --remote --step 1

# Step 2: paste the full redirect URL from your browser address bar
gog auth add you@gmail.com --services user --remote --step 2 --auth-url &#039;http://127.0.0.1:&lt;port&gt;/oauth2/callback?code=...&amp;state=...&#039;
```

- The `state` is cached on disk for a short time (about 10 minutes). If it expires, rerun step 1.
- Remote step 2 requires a redirect URL that includes `state` (state check mandatory).

### 4. Test Authentication

```bash
export GOG_ACCOUNT=you@gmail.com
gog gmail labels list
```

## Authentication &amp; Secrets

### Accounts and tokens

`gog` stores your OAuth refresh tokens in a ‚Äúkeyring‚Äù backend. Default is `auto` (best available backend for your OS/environment).

Before you can run `gog auth add`, you must store OAuth client credentials once via `gog auth credentials &lt;credentials.json&gt;` (download a Desktop app OAuth client JSON from the Cloud Console). For multiple clients, use `gog --client &lt;name&gt; auth credentials ...`; tokens are isolated per client.

List accounts:

```bash
gog auth list
```

Verify tokens are usable (helps spot revoked/expired tokens):

```bash
gog auth list --check
```

Accounts can be authorized either via OAuth refresh tokens or Workspace service accounts (domain-wide delegation). If a service account key is configured for an account, it takes precedence over OAuth refresh tokens (see `gog auth list`).

Show current auth state/services for the active account:

```bash
gog auth status
```

### Multiple OAuth clients

Use `--client` (or `GOG_CLIENT`) to select a named OAuth client:

```bash
gog --client work auth credentials ~/Downloads/work.json
gog --client work auth add you@company.com
```

Optional domain mapping for auto-selection:

```bash
gog --client work auth credentials ~/Downloads/work.json --domain example.com
```

How it works:

- Default client is `default` (stored in `credentials.json`).
- Named clients are stored as `credentials-&lt;client&gt;.json`.
- Tokens are isolated per client (`token:&lt;client&gt;:&lt;email&gt;`); defaults are per client too.

Client selection order (when `--client` is not set):

1) `--client` / `GOG_CLIENT`
2) `account_clients` config (email -&gt; client)
3) `client_domains` config (domain -&gt; client)
4) Credentials file named after the email domain (`credentials-example.com.json`)
5) `default`

Config example (JSON5):

```json5
{
  account_clients: { &quot;you@company.com&quot;: &quot;work&quot; },
  client_domains: { &quot;example.com&quot;: &quot;work&quot; },
}
```

List stored credentials:

```bash
gog auth credentials list
```

See `docs/auth-clients.md` for the full client selection and mapping rules.

### Keyring backend: Keychain vs encrypted file

Backends:

- `auto` (default): picks the best backend for the platform.
- `keychain`: macOS Keychain (recommended on macOS; avoids password management).
- `file`: encrypted on-disk keyring (requires a password).

Set backend via command (writes `keyring_backend` into `config.json`):

```bash
gog auth keyring file
gog auth keyring keychain
gog auth keyring auto
```

Show current backend + source (env/config/default) and config path:

```bash
gog auth keyring
```

Non-interactive runs (CI/ssh): file backend requires `GOG_KEYRING_PASSWORD`.

```bash
export GOG_KEYRING_PASSWORD=&#039;...&#039;
gog --no-input auth status
```

Force backend via env (overrides config):

```bash
export GOG_KEYRING_BACKEND=file
```

Precedence: `GOG_KEYRING_BACKEND` env var overrides `config.json`.

## Configuration

### Account Selection

Specify the account using either a flag or environment variable:

```bash
# Via flag
gog gmail search &#039;newer_than:7d&#039; --account you@gmail.com

# Via alias
gog auth alias set work work@company.com
gog gmail search &#039;newer_than:7d&#039; --account work

# Via environment
export GOG_ACCOUNT=you@gmail.com
gog gmail search &#039;newer_than:7d&#039;

# Auto-select (default account or the single stored token)
gog gmail labels list --account auto
```

List configured accounts:

```bash
gog auth list
```

### Output

- Default: human-friendly tables on stdout.
- `--plain`: stable TSV on stdout (tabs preserved; best for piping to tools that expect `\t`).
- `--json`: JSON on stdout (best for scripting).
- Human-facing hints/progress go to stderr.
- Colors are enabled only in rich TTY output and are disabled automatically for `--json` and `--plain`.

### Service Scopes

By default, `gog auth add` requests access to the **user** services (see `gog auth services` for the current list and scopes).

To request fewer scopes:

```bash
gog auth add you@gmail.com --services drive,calendar
```

To request read-only scopes (write operations will fail with 403 insufficient scopes):

```bash
gog auth add you@gmail.com --services drive,calendar --readonly
```

To control Drive‚Äôs scope (default: `full`):

```bash
gog auth add you@gmail.com --services drive --drive-scope full
gog auth add you@gmail.com --services drive --drive-scope readonly
gog auth add you@gmail.com --services drive --drive-scope file
```

Notes:

- `--drive-scope readonly` is enough for listing/downloading/exporting via Drive (write operations will 403).
- `--drive-scope file` is write-capable (limited to files created/opened by this app) and can‚Äôt be combined with `--readonly`.

If you need to add services later and Google doesn&#039;t return a refresh token, re-run with `--force-consent`:

```bash
gog auth add you@gmail.com --services user --force-consent
# Or add just Sheets
gog auth add you@gmail.com --services sheets --force-consent
```

`--services all` is accepted as an alias for `user` for backwards compatibility.

Docs commands are implemented via the Drive API, and `docs` requests both Drive and Docs API scopes.

Service scope matrix (auto-generated; run `go run scripts/gen-auth-services-md.go`):

&lt;!-- auth-services:start --&gt;
| Service | User | APIs | Scopes | Notes |
| --- | --- | --- | --- | --- |
| gmail | yes | Gmail API | `https://www.googleapis.com/auth/gmail.modify`&lt;br&gt;`https://www.googleapis.com/auth/gmail.settings.basic`&lt;br&gt;`https://www.googleapis.com/auth/gmail.settings.sharing` |  |
| calendar | yes | Calendar API | `https://www.googleapis.com/auth/calendar` |  |
| chat | yes | Chat API | `https://www.googleapis.com/auth/chat.spaces`&lt;br&gt;`https://www.googleapis.com/auth/chat.messages`&lt;br&gt;`https://www.googleapis.com/auth/chat.memberships`&lt;br&gt;`https://www.googleapis.com/auth/chat.users.readstate.readonly` |  |
| classroom | yes | Classroom API | `https://www.googleapis.com/auth/classroom.courses`&lt;br&gt;`https://www.googleapis.com/auth/classroom.rosters`&lt;br&gt;`https://www.googleapis.com/auth/classroom.coursework.students`&lt;br&gt;`https://www.googleapis.com/auth/classroom.coursework.me`&lt;br&gt;`https://www.googleapis.com/auth/classroom.courseworkmaterials`&lt;br&gt;`https://www.googleapis.com/auth/classroom.announcements`&lt;br&gt;`https://www.googleapis.com/auth/classroom.topics`&lt;br&gt;`https://www.googleapis.com/auth/classroom.guardianlinks.students`&lt;br&gt;`https://www.googleapis.com/auth/classroom.profile.emails`&lt;br&gt;`https://www.googleapis.com/auth/classroom.profile.photos` |  |
| drive | yes | Drive API | `https://www.googleapis.com/auth/drive` |  |
| docs | yes | Docs API, Drive API | `https://www.googleapis.com/auth/drive`&lt;br&gt;`https://www.googleapis.com/auth/documents` | Export/copy/create via Drive |
| slides | yes | Slides API, Drive API | `https://www.googleapis.com/auth/drive`&lt;br&gt;`https://www.googleapis.com/auth/presentations` | Create/edit presentations |
| contacts | yes | People API | `https://www.googleapis.com/auth/contacts`&lt;br&gt;`https://www.googleapis.com/auth/contacts.other.readonly`&lt;br&gt;`https://www.googleapis.com/auth/directory.readonly` | Contacts + other contacts + directory |
| tasks | yes | Tasks API | `https://www.googleapis.com/auth/tasks` |  |
| sheets | yes | Sheets API, Drive API | `https://www.googleapis.com/auth/drive`&lt;br&gt;`https://www.googleapis.com/auth/spreadsheets` | Export via Drive |
| people | yes | People API | `profile` | OIDC profile scope |
| forms | yes | Forms API | `https://www.googleapis.com/auth/forms.body`&lt;br&gt;`https://www.googleapis.com/auth/forms.responses.readonly` |  |
| appscript | yes | Apps Script API | `https://www.googleapis.com/auth/script.projects`&lt;br&gt;`https://www.googleapis.com/auth/script.deployments`&lt;br&gt;`https://www.googleapis.com/auth/script.processes` |  |
| groups | no | Cloud Identity API | `https://www.googleapis.com/auth/cloud-identity.groups.readonly` | Workspace only |
| keep | no | Keep API | `https://www.googleapis.com/auth/keep.readonly` | Workspace only; service account (domain-wide delegation) |
&lt;!-- auth-services:end --&gt;

### Service Accounts (Workspace only)

A service account is a non-human Google identity that belongs to a Google Cloud project. In Google Workspace, a service account can impersonate a user via **domain-wide delegation** (admin-controlled) and access APIs like Gmail/Calendar/Drive as that user.

In `gog`, service accounts are an **optional auth method** that can be configured per account email. If a service account key is configured for an account, it takes precedence over OAuth refresh tokens (see `gog auth list`).

#### 1) Create a Service Account (Google Cloud)

1. Create (or pick) a Google Cloud project.
2. Enable the APIs you‚Äôll use (e.g. Gmail, Calendar, Drive, Sheets, Docs, People, Tasks, Cloud Identity).
3. Go to **IAM &amp; Admin ‚Üí Service Accounts** and create a service account.
4. In the service account details, enable **Domain-wide delegation**.
5. Create a key (**Keys ‚Üí Add key ‚Üí Create new key ‚Üí JSON**) and download the JSON key file.

#### 2) Allowlist scopes (Google Workspace Admin Console)

Domain-wide delegation is enforced by Workspace admin settings.

1. Open **Admin console ‚Üí Security ‚Üí API controls ‚Üí Domain-wide delegation**.
2. Add a new API client:
   - Client ID: use the service account‚Äôs ‚ÄúClient ID‚Äù from Google Cloud.
   - OAuth scopes: comma-separated list of scopes you want to allow (copy from `gog auth services` and/or your `gog auth add --services ...` usage).

If a scope is missing from the allowlist, service-account token minting can fail (or API calls will 403 with insufficient permissions).

#### 3) Configure `gog` to use the service account

Store the key for the user you want to impersonate:

```bash
gog auth service-account set you@yourdomain.com --key ~/Downloads/service-account.json
```

Verify `gog` is preferring the service account for that account:

```bash
gog --account you@yourdomain.com auth status
gog auth list
```

### Google Keep (Workspace only)

Keep requires Workspace + domain-wide delegation. You can configure it via the generic service-account command above (recommended), or the legacy Keep helper:

```bash
gog auth service-account set you@yourdomain.com --key ~/Downloads/service-account.json
gog keep list --account you@yourdomain.com
gog keep get &lt;noteId&gt; --account you@yourdomain.com
```

### Environment Variables

- `GOG_ACCOUNT` - Default account email or alias to use (avoids repeating `--account`; otherwise uses keyring default or a single stored token)
- `GOG_CLIENT` - OAuth client name (selects stored credentials + token bucket)
- `GOG_JSON` - Default JSON output
- `GOG_PLAIN` - Default plain output
- `GOG_COLOR` - Color mode: `auto` (default), `always`, or `never`
- `GOG_TIMEZONE` - Default output timezone for Calendar/Gmail (IANA name, `UTC`, or `local`)
- `GOG_ENABLE_COMMANDS` - Comma-separated allowlist of top-level commands (e.g., `calendar,tasks`)

### Config File (JSON5)

Find the actual config path in `gog --help` or `gog auth keyring`.

Typical paths:

- macOS: `~/Library/Application Support/gogcli/config.json`
- Linux: `~/.config/gogcli/config.json` (or `$XDG_CONFIG_HOME/gogcli/config.json`)
- Windows: `%AppData%\\gogcli\\config.json`

Example (JSON5 supports comments and trailing commas):

```json5
{
  // Avoid macOS Keychain prompts
  keyring_backend: &quot;file&quot;,
  // Default output timezone for Calendar/Gmail (IANA, UTC, or local)
  default_timezone: &quot;UTC&quot;,
  // Optional account aliases
  account_aliases: {
    work: &quot;work@company.com&quot;,
    personal: &quot;me@gmail.com&quot;,
  },
  // Optional per-account OAuth client selection
  account_clients: {
    &quot;work@company.com&quot;: &quot;work&quot;,
  },
  // Optional domain -&gt; client mapping
  client_domains: {
    &quot;example.com&quot;: &quot;work&quot;,
  },
}
```

### Config Commands

```bash
gog config path
gog config list
gog config keys
gog config get default_timezone
gog config set default_timezone UTC
gog config unset default_timezone
```

### Account Aliases

```bash
gog auth alias set work work@company.com
gog auth alias list
gog auth alias unset work
```

Aliases work anywhere you pass `--account` or `GOG_ACCOUNT` (reserved: `auto`, `default`).

### Command Allowlist (Sandboxing)

```bash
# Only allow calendar + tasks commands for an agent
gog --enable-commands calendar,tasks calendar events --today

# Same via env
export GOG_ENABLE_COMMANDS=calendar,tasks
gog tasks list &lt;tasklistId&gt;
```
 
## Security

### Credential Storage

OAuth credentials are stored securely in your system&#039;s keychain:
- **macOS**: Keychain Access
- **Linux**: Secret Service (GNOME Keyring, KWallet)
- **Windows**: Credential Manager

The CLI uses [github.com/99designs/keyring](https://github.com/99designs/keyring) for secure storage.

If no OS keychain backend is available (e.g., Linux/WSL/container), keyring can fall back to an encrypted on-disk store and may prompt for a password; for non-interactive runs set `GOG_KEYRING_PASSWORD`.

### Keychain Prompts (macOS)

macOS Keychain may prompt more than you‚Äôd expect when the ‚Äúapp identity‚Äù keeps changing (different binary path, `go run` temp builds, rebuilding to new `./bin/gog`, multiple copies). Keychain treats those as different apps, so it asks again.

Options:

- **Default (recommended):** keep using Keychain (secure) and run a stable `gog` binary path to reduce repeat prompts.
- **Force Key

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[github/gh-aw]]></title>
            <link>https://github.com/github/gh-aw</link>
            <guid>https://github.com/github/gh-aw</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:22 GMT</pubDate>
            <description><![CDATA[GitHub Agentic Workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/gh-aw">github/gh-aw</a></h1>
            <p>GitHub Agentic Workflows</p>
            <p>Language: Go</p>
            <p>Stars: 2,695</p>
            <p>Forks: 199</p>
            <p>Stars today: 213 stars today</p>
            <h2>README</h2><pre>&lt;!--

Hello fellow agent! Welcome to GitHub Agentic Workflows = Actions + Agent + Safety. 
Here are some pointers to get you started in using this tool.

- Create a new workflow: https://raw.githubusercontent.com/github/gh-aw/main/create.md
- Install: https://raw.githubusercontent.com/github/gh-aw/main/install.md
- Reference: https://raw.githubusercontent.com/github/gh-aw/main/.github/aw/github-agentic-workflows.md

--&gt;

# GitHub Agentic Workflows

Write agentic workflows in natural language markdown, and run them in GitHub Actions.

## Contents

- [Quick Start](#quick-start)
- [Overview](#overview)
- [Guardrails](#guardrails)
- [Documentation](#documentation)
- [Contributing](#contributing)
- [Share Feedback](#share-feedback)
- [Peli&#039;s Agent Factory](#pelis-agent-factory)
- [Related Projects](#related-projects)

## Quick Start

Ready to get your first agentic workflow running? Follow our step-by-step [Quick Start Guide](https://github.github.com/gh-aw/setup/quick-start/) to install the extension, add a sample workflow, and see it in action.

## Overview

Learn about the concepts behind agentic workflows, explore available workflow types, and understand how AI can automate your repository tasks. See [How It Works](https://github.github.com/gh-aw/introduction/how-they-work/).

## Guardrails

Guardrails, safety and security are foundational to GitHub Agentic Workflows. Workflows run with read-only permissions by default, with write operations only allowed through sanitized `safe-outputs`. The system implements multiple layers of protection including sandboxed execution, input sanitization, network isolation, supply chain security (SHA-pinned dependencies), tool allow-listing, and compile-time validation. Access can be gated to team members only, with human approval gates for critical operations, ensuring AI agents operate safely within controlled boundaries. See the [Security Architecture](https://github.github.com/gh-aw/introduction/architecture/) for comprehensive details on threat modeling, implementation guidelines, and best practices.

Using agentic workflows in your repository requires careful attention to security considerations and careful human supervision, and even then things can still go wrong. Use it with caution, and at your own risk.

## Documentation

For complete documentation, examples, and guides, see the [Documentation](https://github.github.com/gh-aw/).

## Contributing

For development setup and contribution guidelines, see [CONTRIBUTING.md](CONTRIBUTING.md).

## Share Feedback

We welcome your feedback on GitHub Agentic Workflows! 

- [Community Feedback Discussions](https://github.com/orgs/community/discussions/186451)
- [GitHub Next Discord](https://gh.io/next-discord)

## Peli&#039;s Agent Factory

See the [Peli&#039;s Agent Factory](https://github.github.com/gh-aw/blog/2026-01-12-welcome-to-pelis-agent-factory/) for a guided tour through many uses of agentic workflows.

## Related Projects

GitHub Agentic Workflows is supported by companion projects that provide additional security and integration capabilities:

- **[Agent Workflow Firewall (AWF)](https://github.com/github/gh-aw-firewall)** - Network egress control for AI agents, providing domain-based access controls and activity logging for secure workflow execution
- **[MCP Gateway](https://github.com/github/gh-aw-mcpg)** - Routes Model Context Protocol (MCP) server calls through a unified HTTP gateway for centralized access management
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[AdguardTeam/AdGuardHome]]></title>
            <link>https://github.com/AdguardTeam/AdGuardHome</link>
            <guid>https://github.com/AdguardTeam/AdGuardHome</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:21 GMT</pubDate>
            <description><![CDATA[Network-wide ads & trackers blocking DNS server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AdguardTeam/AdGuardHome">AdguardTeam/AdGuardHome</a></h1>
            <p>Network-wide ads & trackers blocking DNS server</p>
            <p>Language: Go</p>
            <p>Stars: 32,585</p>
            <p>Forks: 2,245</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>&amp;nbsp;
&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;doc/adguard_home_darkmode.svg&quot;&gt;
    &lt;img alt=&quot;AdGuard Home&quot; src=&quot;doc/adguard_home_lightmode.svg&quot; width=&quot;300px&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;
&lt;h3 align=&quot;center&quot;&gt;Privacy protection center for you and your devices&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
  Free and open source, powerful network-wide ads &amp; trackers blocking DNS server.
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://adguard.com/&quot;&gt;AdGuard.com&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/AdguardTeam/AdGuardHome/wiki&quot;&gt;Wiki&lt;/a&gt; |
  &lt;a href=&quot;https://reddit.com/r/Adguard&quot;&gt;Reddit&lt;/a&gt; |
  &lt;a href=&quot;https://twitter.com/AdGuard&quot;&gt;Twitter&lt;/a&gt; |
  &lt;a href=&quot;https://t.me/adguard_en&quot;&gt;Telegram&lt;/a&gt;
  &lt;br/&gt;&lt;br/&gt;
  &lt;a href=&quot;https://codecov.io/github/AdguardTeam/AdGuardHome?branch=master&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/codecov/c/github/AdguardTeam/AdGuardHome/master.svg&quot; alt=&quot;Code Coverage&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/AdguardTeam/AdGuardHome&quot;&gt;
    &lt;img src=&quot;https://goreportcard.com/badge/github.com/AdguardTeam/AdGuardHome&quot; alt=&quot;Go Report Card&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/r/adguard/adguardhome&quot;&gt;
    &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/adguard/adguardhome.svg?maxAge=604800&quot;/&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;a href=&quot;https://github.com/AdguardTeam/AdGuardHome/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/release/AdguardTeam/AdGuardHome/all.svg&quot; alt=&quot;Latest release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://snapcraft.io/adguard-home&quot;&gt;
    &lt;img alt=&quot;adguard-home&quot; src=&quot;https://snapcraft.io/adguard-home/badge.svg&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://cdn.adtidy.org/public/Adguard/Common/adguard_home.gif&quot; width=&quot;800&quot;/&gt;
&lt;/p&gt;
&lt;hr/&gt;

AdGuard Home is a network-wide software for blocking ads and tracking. After you set it up, it&#039;ll cover ALL your home devices, and you don&#039;t need any client-side software for that.

It operates as a DNS server that re-routes tracking domains to a ‚Äúblack hole‚Äù, thus preventing your devices from connecting to those servers. It&#039;s based on software we use for our public [AdGuard DNS] servers, and both share a lot of code.

[AdGuard DNS]: https://adguard-dns.io/

- [Getting Started](#getting-started)
    - [Automated install (Linux/Unix/MacOS/FreeBSD/OpenBSD)](#automated-install-linux-and-mac)
    - [Alternative methods](#alternative-methods)
    - [Guides](#guides)
    - [API](#api)
- [Comparing AdGuard Home to other solutions](#comparison)
    - [How is this different from public AdGuard DNS servers?](#comparison-adguard-dns)
    - [How does AdGuard Home compare to Pi-Hole](#comparison-pi-hole)
    - [How does AdGuard Home compare to traditional ad blockers](#comparison-adblock)
    - [Known limitations](#comparison-limitations)
- [How to build from source](#how-to-build)
    - [Prerequisites](#prerequisites)
    - [Building](#building)
- [Contributing](#contributing)
    - [Test unstable versions](#test-unstable-versions)
    - [Reporting issues](#reporting-issues)
    - [Help with translations](#translate)
    - [Other](#help-other)
- [Projects that use AdGuard Home](#uses)
- [Acknowledgments](#acknowledgments)
- [Privacy](#privacy)

## &lt;a href=&quot;#getting-started&quot; id=&quot;getting-started&quot; name=&quot;getting-started&quot;&gt;Getting Started&lt;/a&gt;

### &lt;a href=&quot;#automated-install-linux-and-mac&quot; id=&quot;automated-install-linux-and-mac&quot; name=&quot;automated-install-linux-and-mac&quot;&gt;Automated install (Linux/Unix/MacOS/FreeBSD/OpenBSD)&lt;/a&gt;

To install with `curl` run the following command:

```sh
curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v
```

To install with `wget` run the following command:

```sh
wget --no-verbose -O - https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v
```

To install with `fetch` run the following command:

```sh
fetch -o - https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v
```

The script also accepts some options:

- `-c &lt;channel&gt;` to use specified channel;
- `-r` to reinstall AdGuard Home;
- `-u` to uninstall AdGuard Home;
- `-v` for verbose output.

Note that options `-r` and `-u` are mutually exclusive.

### &lt;a href=&quot;#alternative-methods&quot; id=&quot;alternative-methods&quot; name=&quot;alternative-methods&quot;&gt;Alternative methods&lt;/a&gt;

#### &lt;a href=&quot;#manual-installation&quot; id=&quot;manual-installation&quot; name=&quot;manual-installation&quot;&gt;Manual installation&lt;/a&gt;

Please read the **[Getting Started][wiki-start]** article on our Wiki to learn how to install AdGuard Home manually, and how to configure your devices to use it.

#### &lt;a href=&quot;#docker&quot; id=&quot;docker&quot; name=&quot;docker&quot;&gt;Docker&lt;/a&gt;

You can use our official Docker image on [Docker Hub].

#### &lt;a href=&quot;#snap-store&quot; id=&quot;snap-store&quot; name=&quot;snap-store&quot;&gt;Snap Store&lt;/a&gt;

If you&#039;re running **Linux,** there&#039;s a secure and easy way to install AdGuard Home: get it from the [Snap Store].

[Docker Hub]: https://hub.docker.com/r/adguard/adguardhome
[Snap Store]: https://snapcraft.io/adguard-home
[wiki-start]: https://adguard-dns.io/kb/adguard-home/getting-started/

### &lt;a href=&quot;#guides&quot; id=&quot;guides&quot; name=&quot;guides&quot;&gt;Guides&lt;/a&gt;

See our [Wiki][wiki].

[wiki]: https://github.com/AdguardTeam/AdGuardHome/wiki

### &lt;a href=&quot;#api&quot; id=&quot;api&quot; name=&quot;api&quot;&gt;API&lt;/a&gt;

If you want to integrate with AdGuard Home, you can use our [REST API][openapi]. Alternatively, you can use this [python client][pyclient], which is used to build the [AdGuard Home Hass.io Add-on][hassio].

[hassio]:   https://www.home-assistant.io/integrations/adguard/
[openapi]:  https://github.com/AdguardTeam/AdGuardHome/tree/master/openapi
[pyclient]: https://pypi.org/project/adguardhome/

## &lt;a href=&quot;#comparison&quot; id=&quot;comparison&quot; name=&quot;comparison&quot;&gt;Comparing AdGuard Home to other solutions&lt;/a&gt;

### &lt;a href=&quot;#comparison-adguard-dns&quot; id=&quot;comparison-adguard-dns&quot; name=&quot;comparison-adguard-dns&quot;&gt;How is this different from public AdGuard DNS servers?&lt;/a&gt;

Running your own AdGuard Home server allows you to do much more than using a public DNS server. It&#039;s a completely different level. See for yourself:

- Choose what exactly the server blocks and permits.

- Monitor your network activity.

- Add your own custom filtering rules.

- **Most importantly, it&#039;s your own server, and you are the only one who&#039;s in control.**

### &lt;a href=&quot;#comparison-pi-hole&quot; id=&quot;comparison-pi-hole&quot; name=&quot;comparison-pi-hole&quot;&gt;How does AdGuard Home compare to Pi-Hole&lt;/a&gt;

At this point, AdGuard Home has a lot in common with Pi-Hole. Both block ads and trackers using the so-called ‚ÄúDNS sinkholing‚Äù method and both allow customizing what&#039;s blocked.

&gt; [!NOTE]
&gt; We&#039;re not going to stop here. DNS sinkholing is not a bad starting point, but this is just the beginning.

AdGuard Home provides a lot of features out-of-the-box with no need to install and configure additional software. We want it to be simple to the point when even casual users can set it up with minimal effort.

&gt; [!NOTE]
&gt; Some of the listed features can be added to Pi-Hole by installing additional software or by manually using SSH terminal and reconfiguring one of the utilities Pi-Hole consists of. However, in our opinion, this cannot be legitimately counted as a Pi-Hole&#039;s feature.

| Feature                                                                 | AdGuard&amp;nbsp;Home | Pi-Hole                                                   |
|-------------------------------------------------------------------------|-------------------|-----------------------------------------------------------|
| Blocking ads and trackers                                               | ‚úÖ                | ‚úÖ                                                        |
| Customizing blocklists                                                  | ‚úÖ                | ‚úÖ                                                        |
| Built-in DHCP server                                                    | ‚úÖ                | ‚úÖ                                                        |
| HTTPS for the Admin interface                                           | ‚úÖ                | Kind of, but you&#039;ll need to manually configure lighttpd   |
| Encrypted DNS upstream servers (DNS-over-HTTPS, DNS-over-TLS, DNSCrypt) | ‚úÖ                | ‚ùå (requires additional software)                         |
| Cross-platform                                                          | ‚úÖ                | ‚ùå (not natively, only via Docker)                        |
| Running as a DNS-over-HTTPS or DNS-over-TLS server                      | ‚úÖ                | ‚ùå (requires additional software)                         |
| Blocking phishing and malware domains                                   | ‚úÖ                | ‚ùå (requires non-default blocklists)                      |
| Parental control (blocking adult domains)                               | ‚úÖ                | ‚ùå (requires non-default blocklists)                      |
| Force Safe search on search engines                                     | ‚úÖ                | ‚ùå                                                        |
| Per-client (device) configuration                                       | ‚úÖ                | ‚úÖ                                                        |
| Access settings (choose who can use AGH DNS)                            | ‚úÖ                | ‚ùå                                                        |
| Running [without root privileges][wiki-noroot]                          | ‚úÖ                | ‚ùå                                                        |

[wiki-noroot]: https://adguard-dns.io/kb/adguard-home/getting-started/#running-without-superuser

### &lt;a href=&quot;#comparison-adblock&quot; id=&quot;comparison-adblock&quot; name=&quot;comparison-adblock&quot;&gt;How does AdGuard Home compare to traditional ad blockers&lt;/a&gt;

It depends.

DNS sinkholing is capable of blocking a big percentage of ads, but it lacks the flexibility and the power of traditional ad blockers. You can get a good impression about the difference between these methods by reading [this article][blog-adaway], which compares AdGuard for Android (a traditional ad blocker) to hosts-level ad blockers (which are almost identical to DNS-based blockers in their capabilities). This level of protection is enough for some users.

Additionally, using a DNS-based blocker can help to block ads, tracking and analytics requests on other types of devices, such as SmartTVs, smart speakers or other kinds of IoT devices (on which you can&#039;t install traditional ad blockers).

### &lt;a href=&quot;#comparison-limitations&quot; id=&quot;comparison-limitations&quot; name=&quot;comparison-limitations&quot;&gt;Known limitations&lt;/a&gt;

Here are some examples of what cannot be blocked by a DNS-level blocker:

- YouTube, Twitch ads;

- Facebook, Twitter, Instagram sponsored posts.

Essentially, any advertising that shares a domain with content cannot be blocked by a DNS-level blocker.

Is there a chance to handle this in the future?  DNS will never be enough to do this. Our only option is to use a content blocking proxy like what we do in the standalone AdGuard applications. We&#039;re [going to bring][issue-1228] this feature support to AdGuard Home in the future. Unfortunately, even in this case, there still will be cases when this won&#039;t be enough or would require quite a complicated configuration.

[blog-adaway]: https://adguard.com/blog/adguard-vs-adaway-dns66.html
[issue-1228]:  https://github.com/AdguardTeam/AdGuardHome/issues/1228

## &lt;a href=&quot;#how-to-build&quot; id=&quot;how-to-build&quot; name=&quot;how-to-build&quot;&gt;How to build from source&lt;/a&gt;

### &lt;a href=&quot;#prerequisites&quot; id=&quot;prerequisites&quot; name=&quot;prerequisites&quot;&gt;Prerequisites&lt;/a&gt;

Run `make init` to prepare the development environment.

You will need this to build AdGuard Home:

- [Go](https://golang.org/dl/) v1.25 or later;
- [Node.js](https://nodejs.org/en/download/) v24.10.0 or later;
- [npm](https://www.npmjs.com/) v10.8 or later;

### &lt;a href=&quot;#building&quot; id=&quot;building&quot; name=&quot;building&quot;&gt;Building&lt;/a&gt;

Open your terminal and execute these commands:

```sh
git clone https://github.com/AdguardTeam/AdGuardHome
cd AdGuardHome
make
```

&gt; [!WARNING]
&gt; The non-standard `-j` flag is currently not supported, so building with `make -j 4` or setting your `MAKEFLAGS` to include, for example, `-j 4` is likely to break the build. If you do have your `MAKEFLAGS` set to that, and you don&#039;t want to change it, you can override it by running `make -j 1`.

Check the [`Makefile`][src-makefile] to learn about other commands.

#### &lt;a href=&quot;#building-cross&quot; id=&quot;building-cross&quot; name=&quot;building-cross&quot;&gt;Building for a different platform&lt;/a&gt;

You can build AdGuard Home for any OS/ARCH that Go supports. In order to do this, specify `GOOS` and `GOARCH` environment variables as macros when running `make`.

For example:

```sh
env GOOS=&#039;linux&#039; GOARCH=&#039;arm64&#039; make
```

or:

```sh
make GOOS=&#039;linux&#039; GOARCH=&#039;arm64&#039;
```

#### &lt;a href=&quot;#preparing-releases&quot; id=&quot;preparing-releases&quot; name=&quot;preparing-releases&quot;&gt;Preparing releases&lt;/a&gt;

You&#039;ll need [`snapcraft`] to prepare a release build. Once installed, run the following command:

```sh
make build-release CHANNEL=&#039;...&#039; VERSION=&#039;...&#039;
```

See the [`build-release` target documentation][targ-release].

#### &lt;a href=&quot;#docker-image&quot; id=&quot;docker-image&quot; name=&quot;docker-image&quot;&gt;Docker image&lt;/a&gt;

Run `make build-docker` to build the Docker image locally (the one that we publish to DockerHub). Please note, that we&#039;re using [Docker Buildx][buildx] to build our official image.

You may need to prepare before using these builds:

- (Linux-only) Install Qemu:

  ```sh
  docker run --rm --privileged multiarch/qemu-user-static --reset -p yes --credential yes
  ```

- Prepare the builder:

  ```sh
  docker buildx create --name buildx-builder --driver docker-container --use
  ```

See the [`build-docker` target documentation][targ-docker].

#### &lt;a href=&quot;#debugging-the-frontend&quot; id=&quot;debugging-the-frontend&quot; name=&quot;debugging-the-frontend&quot;&gt;Debugging the frontend&lt;/a&gt;

When you need to debug the frontend without recompiling the production version every time, for example to check how your labels would look on a form, you can run the frontend build a development environment.

1. In a separate terminal, run:

   ```sh
   ( cd ./client/ &amp;&amp; env NODE_ENV=&#039;development&#039; npm run watch )
   ```

2. Run your `AdGuardHome` binary with the `--local-frontend` flag, which instructs AdGuard Home to ignore the built-in frontend files and use those from the `./build/` directory.

3. Now any changes you make in the `./client/` directory should be recompiled and become available on the web UI. Make sure that you disable the browser cache to make sure that you actually get the recompiled version.

[`snapcraft`]:  https://snapcraft.io/
[buildx]:       https://docs.docker.com/buildx/working-with-buildx/
[src-makefile]: https://github.com/AdguardTeam/AdGuardHome/blob/master/Makefile
[targ-docker]:  https://github.com/AdguardTeam/AdGuardHome/tree/master/scripts#build-dockersh-build-a-multi-architecture-docker-image
[targ-release]: https://github.com/AdguardTeam/AdGuardHome/tree/master/scripts#build-releasesh-build-a-release-for-all-platforms

#### &lt;a href=&quot;#e2e-frontend-tests&quot; id=&quot;e2e-frontend-tests&quot; name=&quot;e2e-frontend-tests&quot;&gt;End-to-End (E2E) Frontend Tests&lt;/a&gt;

AdGuard Home uses [Playwright](https://playwright.dev) for E2E testing. Tests are located in `tests/e2e`.

**Running Tests:**
- `npm run test:e2e` ‚Äì run all tests (headless).
- `npm run test:e2e:interactive` ‚Äì run tests interactively.
- `npm run test:e2e:debug` ‚Äì run tests in debug mode.
- `npm run test:e2e:codegen` ‚Äì generate new test code.

**Setup:**
1. Run `npm install` to install dependencies.
2. Run `npx playwright install` to set up required browsers.

&gt; **Warning:** Playwright will download and install its own browser binaries for testing, which may differ from the browsers installed on your system.

## &lt;a href=&quot;#contributing&quot; id=&quot;contributing&quot; name=&quot;contributing&quot;&gt;Contributing&lt;/a&gt;

You are welcome to fork this repository, make your changes and [submit a pull request][pr]. Please make sure you follow our [code guidelines][guide] though.

Please note that we don&#039;t expect people to contribute to both UI and backend parts of the program simultaneously. Ideally, the backend part is implemented first, i.e. configuration, API, and the functionality itself. The UI part can be implemented later in a different pull request by a different person.

[guide]: https://github.com/AdguardTeam/CodeGuidelines/
[pr]:    https://github.com/AdguardTeam/AdGuardHome/pulls

### &lt;a href=&quot;#test-unstable-versions&quot; id=&quot;test-unstable-versions&quot; name=&quot;test-unstable-versions&quot;&gt;Test unstable versions&lt;/a&gt;

There are two update channels that you can use:

- `beta`: beta versions of AdGuard Home. More or less stable versions, usually released every two weeks or more often.

- `edge`: the newest version of AdGuard Home from the development branch. New updates are pushed to this channel daily.

There are three options how you can install an unstable version:

1. [Snap Store]: look for the `beta` and `edge` channels.

2. [Docker Hub]: look for the `beta` and `edge` tags.

3. Standalone builds. Use the automated installation script or look for the available builds [on the Wiki][wiki-platf].

   Script to install a beta version:

   ```sh
   curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -c beta
   ```

   Script to install an edge version:

   ```sh
   curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -c edge
   ```

[wiki-platf]: https://github.com/AdguardTeam/AdGuardHome/wiki/Platforms

### &lt;a href=&quot;#reporting-issues&quot; id=&quot;reporting-issues&quot; name=&quot;reporting-issues&quot;&gt;Report issues&lt;/a&gt;

If you run into any problem or have a suggestion, head to [this page][iss] and click on the ‚ÄúNew issue‚Äù button. Please follow the instructions in the issue form carefully and don&#039;t forget to start by searching for duplicates.

[iss]: https://github.com/AdguardTeam/AdGuardHome/issues

### &lt;a href=&quot;#translate&quot; id=&quot;translate&quot; name=&quot;translate&quot;&gt;Help with translations&lt;/a&gt;

If you want to help with AdGuard Home translations, please learn more about translating AdGuard products [in our Knowledge Base][kb-trans]. You can contribute to the [AdGuardHome project on CrowdIn][crowdin].

[crowdin]:  https://crowdin.com/project/adguard-applications/en#/adguard-home
[kb-trans]: https://kb.adguard.com/en/general/adguard-translations

### &lt;a href=&quot;#help-other&quot; id=&quot;help-other&quot; name=&quot;help-other&quot;&gt;Other&lt;/a&gt;

Another way you can contribute is by [looking for issues][iss-help] marked as `help wanted`, asking if the issue is up for grabs, and sending a PR fixing the bug or implementing the feature.

[iss-help]: https://github.com/AdguardTeam/AdGuardHome/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22

## &lt;a href=&quot;#uses&quot; id=&quot;uses&quot; name=&quot;uses&quot;&gt;Projects that use AdGuard Home&lt;/a&gt;

Please note that these projects are not affiliated with AdGuard, but are made by third-party developers and fans.

- [AdGuard Home Remote](https://apps.apple.com/app/apple-store/id1543143740): iOS app by [Joost](https://rocketscience-it.nl/).

- [Python library](https://github.com/frenck/python-adguardhome) by [@frenck](https://github.com/frenck).

- [Home Assistant add-on](https://github.com/hassio-addons/addon-adguard-home) by [@frenck](https://github.com/frenck).

- [OpenWrt LUCI app](https://github.com/kongfl888/luci-app-adguardhome) by [@kongfl888](https://github.com/kongfl888) (originally by [@rufengsuixing](https://github.com/rufengsuixing)).

- [AdGuardHome sync](https://github.com/bakito/adguardhome-sync) by [@bakito](https://github.com/bakito).

- [Terminal-based, real-time traffic monitoring and statistics for your AdGuard Home instance](https://github.com/Lissy93/AdGuardian-Term) by [@Lissy93](https://github.com/Lissy93)

- [AdGuard Home on GLInet routers](https://forum.gl-inet.com/t/adguardhome-on-gl-routers/10664) by [Gl-Inet](https://gl-inet.com/).

- [Cloudr

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[charmbracelet/crush]]></title>
            <link>https://github.com/charmbracelet/crush</link>
            <guid>https://github.com/charmbracelet/crush</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:20 GMT</pubDate>
            <description><![CDATA[Glamourous agentic coding for all üíò]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/charmbracelet/crush">charmbracelet/crush</a></h1>
            <p>Glamourous agentic coding for all üíò</p>
            <p>Language: Go</p>
            <p>Stars: 20,006</p>
            <p>Forks: 1,232</p>
            <p>Stars today: 62 stars today</p>
            <h2>README</h2><pre># Crush

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://stuff.charm.sh/crush/charm-crush.png&quot;&gt;&lt;img width=&quot;450&quot; alt=&quot;Charm Crush Logo&quot; src=&quot;https://github.com/user-attachments/assets/cf8ca3ce-8b02-43f0-9d0f-5a331488da4b&quot; /&gt;&lt;/a&gt;&lt;br /&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/crush/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/charmbracelet/crush&quot; alt=&quot;Latest Release&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/crush/actions&quot;&gt;&lt;img src=&quot;https://github.com/charmbracelet/crush/actions/workflows/build.yml/badge.svg&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Your new coding bestie, now available in your favourite terminal.&lt;br /&gt;Your tools, your code, and your workflows, wired into your LLM of choice.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;ÁªàÁ´ØÈáåÁöÑÁºñÁ®ãÊñ∞Êê≠Ê°£Ôºå&lt;br /&gt;Êó†ÁºùÊé•ÂÖ•‰Ω†ÁöÑÂ∑•ÂÖ∑„ÄÅ‰ª£Á†Å‰∏éÂ∑•‰ΩúÊµÅÔºåÂÖ®Èù¢ÂÖºÂÆπ‰∏ªÊµÅ LLM Ê®°Âûã„ÄÇ&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;800&quot; alt=&quot;Crush Demo&quot; src=&quot;https://github.com/user-attachments/assets/58280caf-851b-470a-b6f7-d5c4ea8a1968&quot; /&gt;&lt;/p&gt;

## Features

- **Multi-Model:** choose from a wide range of LLMs or add your own via OpenAI- or Anthropic-compatible APIs
- **Flexible:** switch LLMs mid-session while preserving context
- **Session-Based:** maintain multiple work sessions and contexts per project
- **LSP-Enhanced:** Crush uses LSPs for additional context, just like you do
- **Extensible:** add capabilities via MCPs (`http`, `stdio`, and `sse`)
- **Works Everywhere:** first-class support in every terminal on macOS, Linux, Windows (PowerShell and WSL), Android, FreeBSD, OpenBSD, and NetBSD
- **Industrial Grade:** built on the Charm ecosystem, powering 25k+ applications, from leading open source projects to business-critical infrastructure

## Installation

Use a package manager:

```bash
# Homebrew
brew install charmbracelet/tap/crush

# NPM
npm install -g @charmland/crush

# Arch Linux (btw)
yay -S crush-bin

# Nix
nix run github:numtide/nix-ai-tools#crush

# FreeBSD
pkg install crush
```

Windows users:

```bash
# Winget
winget install charmbracelet.crush

# Scoop
scoop bucket add charm https://github.com/charmbracelet/scoop-bucket.git
scoop install crush
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Nix (NUR)&lt;/strong&gt;&lt;/summary&gt;

Crush is available via the official Charm [NUR](https://github.com/nix-community/NUR) in `nur.repos.charmbracelet.crush`, which is the most up-to-date way to get Crush in Nix.

You can also try out Crush via the NUR with `nix-shell`:

```bash
# Add the NUR channel.
nix-channel --add https://github.com/nix-community/NUR/archive/main.tar.gz nur
nix-channel --update

# Get Crush in a Nix shell.
nix-shell -p &#039;(import &lt;nur&gt; { pkgs = import &lt;nixpkgs&gt; {}; }).repos.charmbracelet.crush&#039;
```

### NixOS &amp; Home Manager Module Usage via NUR

Crush provides NixOS and Home Manager modules via NUR.
You can use these modules directly in your flake by importing them from NUR. Since it auto detects whether its a home manager or nixos context you can use the import the exact same way :)

```nix
{
  inputs = {
    nixpkgs.url = &quot;github:NixOS/nixpkgs/nixos-unstable&quot;;
    nur.url = &quot;github:nix-community/NUR&quot;;
  };

  outputs = { self, nixpkgs, nur, ... }: {
    nixosConfigurations.your-hostname = nixpkgs.lib.nixosSystem {
      system = &quot;x86_64-linux&quot;;
      modules = [
        nur.modules.nixos.default
        nur.repos.charmbracelet.modules.crush
        {
          programs.crush = {
            enable = true;
            settings = {
              providers = {
                openai = {
                  id = &quot;openai&quot;;
                  name = &quot;OpenAI&quot;;
                  base_url = &quot;https://api.openai.com/v1&quot;;
                  type = &quot;openai&quot;;
                  api_key = &quot;sk-fake123456789abcdef...&quot;;
                  models = [
                    {
                      id = &quot;gpt-4&quot;;
                      name = &quot;GPT-4&quot;;
                    }
                  ];
                };
              };
              lsp = {
                go = { command = &quot;gopls&quot;; enabled = true; };
                nix = { command = &quot;nil&quot;; enabled = true; };
              };
              options = {
                context_paths = [ &quot;/etc/nixos/configuration.nix&quot; ];
                tui = { compact_mode = true; };
                debug = false;
              };
            };
          };
        }
      ];
    };
  };
}
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Debian/Ubuntu&lt;/strong&gt;&lt;/summary&gt;

```bash
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo &quot;deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *&quot; | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;&amp; sudo apt install crush
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Fedora/RHEL&lt;/strong&gt;&lt;/summary&gt;

```bash
echo &#039;[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key&#039; | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install crush
```

&lt;/details&gt;

Or, download it:

- [Packages][releases] are available in Debian and RPM formats
- [Binaries][releases] are available for Linux, macOS, Windows, FreeBSD, OpenBSD, and NetBSD

[releases]: https://github.com/charmbracelet/crush/releases

Or just install it with Go:

```
go install github.com/charmbracelet/crush@latest
```

&gt; [!WARNING]
&gt; Productivity may increase when using Crush and you may find yourself nerd
&gt; sniped when first using the application. If the symptoms persist, join the
&gt; [Discord][discord] and nerd snipe the rest of us.

## Getting Started

The quickest way to get started is to grab an API key for your preferred
provider such as Anthropic, OpenAI, Groq, OpenRouter, or Vercel AI Gateway and just start
Crush. You&#039;ll be prompted to enter your API key.

That said, you can also set environment variables for preferred providers.

| Environment Variable        | Provider                                           |
| --------------------------- | -------------------------------------------------- |
| `ANTHROPIC_API_KEY`         | Anthropic                                          |
| `OPENAI_API_KEY`            | OpenAI                                             |
| `VERCEL_API_KEY`            | Vercel AI Gateway                                  |
| `GEMINI_API_KEY`            | Google Gemini                                      |
| `SYNTHETIC_API_KEY`         | Synthetic                                          |
| `ZAI_API_KEY`               | Z.ai                                               |
| `MINIMAX_API_KEY`           | MiniMax                                            |
| `HF_TOKEN`                  | Hugging Face Inference                             |
| `CEREBRAS_API_KEY`          | Cerebras                                           |
| `OPENROUTER_API_KEY`        | OpenRouter                                         |
| `IONET_API_KEY`             | io.net                                             |
| `GROQ_API_KEY`              | Groq                                               |
| `VERTEXAI_PROJECT`          | Google Cloud VertexAI (Gemini)                     |
| `VERTEXAI_LOCATION`         | Google Cloud VertexAI (Gemini)                     |
| `AWS_ACCESS_KEY_ID`         | Amazon Bedrock (Claude)                            |
| `AWS_SECRET_ACCESS_KEY`     | Amazon Bedrock (Claude)                            |
| `AWS_REGION`                | Amazon Bedrock (Claude)                            |
| `AWS_PROFILE`               | Amazon Bedrock (Custom Profile)                    |
| `AWS_BEARER_TOKEN_BEDROCK`  | Amazon Bedrock                                     |
| `AZURE_OPENAI_API_ENDPOINT` | Azure OpenAI models                                |
| `AZURE_OPENAI_API_KEY`      | Azure OpenAI models (optional when using Entra ID) |
| `AZURE_OPENAI_API_VERSION`  | Azure OpenAI models                                |

### Subscriptions

If you prefer subscription-based usage, here are some plans that work well in
Crush:

- [Synthetic](https://synthetic.new/pricing)
- [GLM Coding Plan](https://z.ai/subscribe)
- [Kimi Code](https://www.kimi.com/membership/pricing)
- [MiniMax Coding Plan](https://platform.minimax.io/subscribe/coding-plan)

### By the Way

Is there a provider you‚Äôd like to see in Crush? Is there an existing model that needs an update?

Crush‚Äôs default model listing is managed in [Catwalk](https://github.com/charmbracelet/catwalk), a community-supported, open source repository of Crush-compatible models, and you‚Äôre welcome to contribute.

&lt;a href=&quot;https://github.com/charmbracelet/catwalk&quot;&gt;&lt;img width=&quot;174&quot; height=&quot;174&quot; alt=&quot;Catwalk Badge&quot; src=&quot;https://github.com/user-attachments/assets/95b49515-fe82-4409-b10d-5beb0873787d&quot; /&gt;&lt;/a&gt;

## Configuration

Crush runs great with no configuration. That said, if you do need or want to
customize Crush, configuration can be added either local to the project itself,
or globally, with the following priority:

1. `.crush.json`
2. `crush.json`
3. `$HOME/.config/crush/crush.json`

Configuration itself is stored as a JSON object:

```json
{
  &quot;this-setting&quot;: { &quot;this&quot;: &quot;that&quot; },
  &quot;that-setting&quot;: [&quot;ceci&quot;, &quot;cela&quot;]
}
```

As an additional note, Crush also stores ephemeral data, such as application state, in one additional location:

```bash
# Unix
$HOME/.local/share/crush/crush.json

# Windows
%LOCALAPPDATA%\crush\crush.json
```

&gt; [!TIP]
&gt; You can override the user and data config locations by setting:
&gt; * `CRUSH_GLOBAL_CONFIG`
&gt; * `CRUSH_GLOBAL_DATA`

### LSPs

Crush can use LSPs for additional context to help inform its decisions, just
like you would. LSPs can be added manually like so:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;lsp&quot;: {
    &quot;go&quot;: {
      &quot;command&quot;: &quot;gopls&quot;,
      &quot;env&quot;: {
        &quot;GOTOOLCHAIN&quot;: &quot;go1.24.5&quot;
      }
    },
    &quot;typescript&quot;: {
      &quot;command&quot;: &quot;typescript-language-server&quot;,
      &quot;args&quot;: [&quot;--stdio&quot;]
    },
    &quot;nix&quot;: {
      &quot;command&quot;: &quot;nil&quot;
    }
  }
}
```

### MCPs

Crush also supports Model Context Protocol (MCP) servers through three
transport types: `stdio` for command-line servers, `http` for HTTP endpoints,
and `sse` for Server-Sent Events. Environment variable expansion is supported
using `$(echo $VAR)` syntax.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;mcp&quot;: {
    &quot;filesystem&quot;: {
      &quot;type&quot;: &quot;stdio&quot;,
      &quot;command&quot;: &quot;node&quot;,
      &quot;args&quot;: [&quot;/path/to/mcp-server.js&quot;],
      &quot;timeout&quot;: 120,
      &quot;disabled&quot;: false,
      &quot;disabled_tools&quot;: [&quot;some-tool-name&quot;],
      &quot;env&quot;: {
        &quot;NODE_ENV&quot;: &quot;production&quot;
      }
    },
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;,
      &quot;timeout&quot;: 120,
      &quot;disabled&quot;: false,
      &quot;disabled_tools&quot;: [&quot;create_issue&quot;, &quot;create_pull_request&quot;],
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer $GH_PAT&quot;
      }
    },
    &quot;streaming-service&quot;: {
      &quot;type&quot;: &quot;sse&quot;,
      &quot;url&quot;: &quot;https://example.com/mcp/sse&quot;,
      &quot;timeout&quot;: 120,
      &quot;disabled&quot;: false,
      &quot;headers&quot;: {
        &quot;API-Key&quot;: &quot;$(echo $API_KEY)&quot;
      }
    }
  }
}
```

### Ignoring Files

Crush respects `.gitignore` files by default, but you can also create a
`.crushignore` file to specify additional files and directories that Crush
should ignore. This is useful for excluding files that you want in version
control but don&#039;t want Crush to consider when providing context.

The `.crushignore` file uses the same syntax as `.gitignore` and can be placed
in the root of your project or in subdirectories.

### Allowing Tools

By default, Crush will ask you for permission before running tool calls. If
you&#039;d like, you can allow tools to be executed without prompting you for
permissions. Use this with care.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;permissions&quot;: {
    &quot;allowed_tools&quot;: [
      &quot;view&quot;,
      &quot;ls&quot;,
      &quot;grep&quot;,
      &quot;edit&quot;,
      &quot;mcp_context7_get-library-doc&quot;
    ]
  }
}
```

You can also skip all permission prompts entirely by running Crush with the
`--yolo` flag. Be very, very careful with this feature.

### Disabling Built-In Tools

If you&#039;d like to prevent Crush from using certain built-in tools entirely, you
can disable them via the `options.disabled_tools` list. Disabled tools are
completely hidden from the agent.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;disabled_tools&quot;: [
      &quot;bash&quot;,
      &quot;sourcegraph&quot;
    ]
  }
}
```

To disable tools from MCP servers, see the [MCP config section](#mcps).

### Agent Skills

Crush supports the [Agent Skills](https://agentskills.io) open standard for
extending agent capabilities with reusable skill packages. Skills are folders
containing a `SKILL.md` file with instructions that Crush can discover and
activate on demand.

Skills are discovered from:

- `~/.config/crush/skills/` on Unix (default, can be overridden with `CRUSH_SKILLS_DIR`)
- `%LOCALAPPDATA%\crush\skills\` on Windows (default, can be overridden with `CRUSH_SKILLS_DIR`)
- Additional paths configured via `options.skills_paths`

```jsonc
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;skills_paths&quot;: [
      &quot;~/.config/crush/skills&quot;, // Windows: &quot;%LOCALAPPDATA%\\crush\\skills&quot;,
      &quot;./project-skills&quot;
    ]
  }
}
```

You can get started with example skills from [anthropics/skills](https://github.com/anthropics/skills):

```bash
# Unix
mkdir -p ~/.config/crush/skills
cd ~/.config/crush/skills
git clone https://github.com/anthropics/skills.git _temp
mv _temp/skills/* . &amp;&amp; rm -rf _temp
```

```powershell
# Windows (PowerShell)
mkdir -Force &quot;$env:LOCALAPPDATA\crush\skills&quot;
cd &quot;$env:LOCALAPPDATA\crush\skills&quot;
git clone https://github.com/anthropics/skills.git _temp
mv _temp/skills/* . ; rm -r -force _temp
```

### Initialization

When you initialize a project, Crush analyzes your codebase and creates
a context file that helps it work more effectively in future sessions.
By default, this file is named `AGENTS.md`, but you can customize the
name and location with the `initialize_as` option:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;initialize_as&quot;: &quot;AGENTS.md&quot;
  }
}
```

This is useful if you prefer a different naming convention or want to
place the file in a specific directory (e.g., `CRUSH.md` or
`docs/LLMs.md`). Crush will fill the file with project-specific context
like build commands, code patterns, and conventions it discovered during
initialization.

### Attribution Settings

By default, Crush adds attribution information to Git commits and pull requests
it creates. You can customize this behavior with the `attribution` option:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;attribution&quot;: {
      &quot;trailer_style&quot;: &quot;co-authored-by&quot;,
      &quot;generated_with&quot;: true
    }
  }
}
```

- `trailer_style`: Controls the attribution trailer added to commit messages
  (default: `assisted-by`)
	- `assisted-by`: Adds `Assisted-by: [Model Name] via Crush &lt;crush@charm.land&gt;`
	  (includes the model name)
	- `co-authored-by`: Adds `Co-Authored-By: Crush &lt;crush@charm.land&gt;`
	- `none`: No attribution trailer
- `generated_with`: When true (default), adds `üíò Generated with Crush` line to
  commit messages and PR descriptions

### Custom Providers

Crush supports custom provider configurations for both OpenAI-compatible and
Anthropic-compatible APIs.

&gt; [!NOTE]
&gt; Note that we support two &quot;types&quot; for OpenAI. Make sure to choose the right one
&gt; to ensure the best experience!
&gt; * `openai` should be used when proxying or routing requests through OpenAI.
&gt; * `openai-compat` should be used when using non-OpenAI providers that have OpenAI-compatible APIs.

#### OpenAI-Compatible APIs

Here‚Äôs an example configuration for Deepseek, which uses an OpenAI-compatible
API. Don&#039;t forget to set `DEEPSEEK_API_KEY` in your environment.

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;providers&quot;: {
    &quot;deepseek&quot;: {
      &quot;type&quot;: &quot;openai-compat&quot;,
      &quot;base_url&quot;: &quot;https://api.deepseek.com/v1&quot;,
      &quot;api_key&quot;: &quot;$DEEPSEEK_API_KEY&quot;,
      &quot;models&quot;: [
        {
          &quot;id&quot;: &quot;deepseek-chat&quot;,
          &quot;name&quot;: &quot;Deepseek V3&quot;,
          &quot;cost_per_1m_in&quot;: 0.27,
          &quot;cost_per_1m_out&quot;: 1.1,
          &quot;cost_per_1m_in_cached&quot;: 0.07,
          &quot;cost_per_1m_out_cached&quot;: 1.1,
          &quot;context_window&quot;: 64000,
          &quot;default_max_tokens&quot;: 5000
        }
      ]
    }
  }
}
```

#### Anthropic-Compatible APIs

Custom Anthropic-compatible providers follow this format:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;providers&quot;: {
    &quot;custom-anthropic&quot;: {
      &quot;type&quot;: &quot;anthropic&quot;,
      &quot;base_url&quot;: &quot;https://api.anthropic.com/v1&quot;,
      &quot;api_key&quot;: &quot;$ANTHROPIC_API_KEY&quot;,
      &quot;extra_headers&quot;: {
        &quot;anthropic-version&quot;: &quot;2023-06-01&quot;
      },
      &quot;models&quot;: [
        {
          &quot;id&quot;: &quot;claude-sonnet-4-20250514&quot;,
          &quot;name&quot;: &quot;Claude Sonnet 4&quot;,
          &quot;cost_per_1m_in&quot;: 3,
          &quot;cost_per_1m_out&quot;: 15,
          &quot;cost_per_1m_in_cached&quot;: 3.75,
          &quot;cost_per_1m_out_cached&quot;: 0.3,
          &quot;context_window&quot;: 200000,
          &quot;default_max_tokens&quot;: 50000,
          &quot;can_reason&quot;: true,
          &quot;supports_attachments&quot;: true
        }
      ]
    }
  }
}
```

### Amazon Bedrock

Crush currently supports running Anthropic models through Bedrock, with caching disabled.

- A Bedrock provider will appear once you have AWS configured, i.e. `aws configure`
- Crush also expects the `AWS_REGION` or `AWS_DEFAULT_REGION` to be set
- To use a specific AWS profile set `AWS_PROFILE` in your environment, i.e. `AWS_PROFILE=myprofile crush`
- Alternatively to `aws configure`, you can also just set `AWS_BEARER_TOKEN_BEDROCK`

### Vertex AI Platform

Vertex AI will appear in the list of available providers when `VERTEXAI_PROJECT` and `VERTEXAI_LOCATION` are set. You will also need to be authenticated:

```bash
gcloud auth application-default login
```

To add specific models to the configuration, configure as such:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;providers&quot;: {
    &quot;vertexai&quot;: {
      &quot;models&quot;: [
        {
          &quot;id&quot;: &quot;claude-sonnet-4@20250514&quot;,
          &quot;name&quot;: &quot;VertexAI Sonnet 4&quot;,
          &quot;cost_per_1m_in&quot;: 3,
          &quot;cost_per_1m_out&quot;: 15,
          &quot;cost_per_1m_in_cached&quot;: 3.75,
          &quot;cost_per_1m_out_cached&quot;: 0.3,
          &quot;context_window&quot;: 200000,
          &quot;default_max_tokens&quot;: 50000,
          &quot;can_reason&quot;: true,
          &quot;supports_attachments&quot;: true
        }
      ]
    }
  }
}
```

### Local Models

Local models can also be configured via OpenAI-compatible API. Here are two common examples:

#### Ollama

```json
{
  &quot;providers&quot;: {
    &quot;ollama&quot;: {
      &quot;name&quot;: &quot;Ollama&quot;,
      &quot;base_url&quot;: &quot;http://localhost:11434/v1/&quot;,
      &quot;type&quot;: &quot;openai-compat&quot;,
      &quot;models&quot;: [
        {
          &quot;name&quot;: &quot;Qwen 3 30B&quot;,
          &quot;id&quot;: &quot;qwen3:30b&quot;,
          &quot;context_window&quot;: 256000,
          &quot;default_max_tokens&quot;: 20000
        }
      ]
    }
  }
}
```

#### LM Studio

```json
{
  &quot;providers&quot;: {
    &quot;lmstudio&quot;: {
      &quot;name&quot;: &quot;LM Studio&quot;,
      &quot;base_url&quot;: &quot;http://localhost:1234/v1/&quot;,
      &quot;type&quot;: &quot;openai-compat&quot;,
      &quot;models&quot;: [
        {
          &quot;name&quot;: &quot;Qwen 3 30B&quot;,
          &quot;id&quot;: &quot;qwen/qwen3-30b-a3b-2507&quot;,
          &quot;context_window&quot;: 256000,
          &quot;default_max_tokens&quot;: 20000
        }
      ]
    }
  }
}
```

## Logging

Sometimes you need to look at logs. Luckily, Crush logs all sorts of
stuff. Logs are stored in `./.crush/logs/crush.log` relative to the project.

The CLI also contains some helper commands to make perusing recent logs easier:

```bash
# Print the last 1000 lines
crush logs

# Print the last 500 lines
crush logs --tail 500

# Follow logs in real time
crush logs --follow
```

Want more logging? Run `crush` with the `--debug` flag, or enable it in the
config:

```json
{
  &quot;$schema&quot;: &quot;https://charm.land/crush.json&quot;,
  &quot;options&quot;: {
    &quot;debug&quot;: true,
    &quot;debug_lsp&quot;: true
  }
}
```

## Provider Auto-Updates

By default, Crush automatically checks for the latest and greatest list of
providers and models from [Catwalk](h

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[v2fly/domain-list-community]]></title>
            <link>https://github.com/v2fly/domain-list-community</link>
            <guid>https://github.com/v2fly/domain-list-community</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:19 GMT</pubDate>
            <description><![CDATA[Community managed domain list. Generate geosite.dat for V2Ray.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/v2fly/domain-list-community">v2fly/domain-list-community</a></h1>
            <p>Community managed domain list. Generate geosite.dat for V2Ray.</p>
            <p>Language: Go</p>
            <p>Stars: 7,569</p>
            <p>Forks: 1,210</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># Domain list community

This project manages a list of domains, to be used as geosites for routing purpose in Project V.

## Purpose of this project

This project is not opinionated. In other words, it does NOT endorse, claim or imply that a domain should be blocked or proxied. It can be used to generate routing rules on demand.

## Download links

- **dlc.dat**Ôºö[https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat](https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat)
- **dlc.dat.sha256sum**Ôºö[https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum](https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum)
- **dlc.dat_plain.yml**Ôºö[https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat_plain.yml](https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat_plain.yml)
- **dlc.dat_plain.yml.sha256sum**Ôºö[https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat_plain.yml.sha256sum](https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat_plain.yml.sha256sum)

## Notice

- Rules with `@!cn` attribute has been cast out from cn lists. `geosite:geolocation-cn@!cn` is no longer available. Check [#390](https://github.com/v2fly/domain-list-community/issues/390), [#3119](https://github.com/v2fly/domain-list-community/pull/3119) and [#3198](https://github.com/v2fly/domain-list-community/pull/3198) for more information.
- Dedicated non-category ad lists like `geosite:xxx-ads` has been removed. Use `geosite:xxx@ads` instead. `geosite:category-ads[-xx]` is not affected.

Please report if you have any problems or questions.

## Usage example

Each file in the `data` directory can be used as a rule in this format: `geosite:filename`.

```json
&quot;routing&quot;: {
  &quot;domainStrategy&quot;: &quot;IPIfNonMatch&quot;,
  &quot;rules&quot;: [
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Reject&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-ads-all&quot;,
        &quot;geosite:category-porn&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Direct&quot;,
      &quot;domain&quot;: [
        &quot;domain:icloud.com&quot;,
        &quot;domain:icloud-content.com&quot;,
        &quot;domain:cdn-apple.com&quot;,
        &quot;geosite:cn&quot;,
        &quot;geosite:private&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-1&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-anticensorship&quot;,
        &quot;geosite:category-media&quot;,
        &quot;geosite:category-vpnservices&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-2&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-dev&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-3&quot;,
      &quot;domain&quot;: [
        &quot;geosite:geolocation-!cn&quot;
      ]
    }
  ]
}
```

## Generate `dlc.dat` manually

- Install `golang` and `git`
- Clone project code: `git clone https://github.com/v2fly/domain-list-community.git`
- Navigate to project root directory: `cd domain-list-community`
- Install project dependencies: `go mod download`
- Generate `dlc.dat` (without `datapath` option means to use domain lists in `data` directory of current working directory):
  - `go run ./`
  - `go run ./ --datapath=/path/to/your/custom/data/directory`

Run `go run ./ --help` for more usage information.

## Structure of data

All data are under `data` directory. Each file in the directory represents a sub-list of domains, named by the file name. File content is in the following format.

```
# comments
include:another-file
domain:google.com @attr1 @attr2
full:analytics.google.com @ads
keyword:google
regexp:^odd[1-7]\.example\.org(\.[a-z]{2})?$
```

**Syntax:**

&gt; [!NOTE]
&gt; Adding new `regexp` and `keyword` rules is discouraged because it is easy to use them incorrectly, and proxy software cannot efficiently match these types of rules.

&gt; [!NOTE]
&gt; The following types of rules are **NOT** fully compatible with the ones that defined by user in V2Ray config file. Do **Not** copy and paste directly.

- Comment begins with `#`. It may begin anywhere in the file. The content in the line after `#` is treated as comment and ignored in production.
- Subdomain begins with `domain:`, followed by a valid domain name. The prefix `domain:` may be omitted.
- Full domain begins with `full:`, followed by a complete and valid domain name.
- Keyword begins with `keyword:`, followed by a substring of a valid domain name.
- Regular expression begins with `regexp:`, followed by a valid regular expression (per Golang&#039;s standard).
- Domain rules (including `domain`, `full`, `keyword`, and `regexp`) may have none, one or more attributes. Each attribute begins with `@` and followed by the name of the attribute. Attributes will remain available in final lists and `dlc.dat`.
- Domain rules may have none, one or more affiliations, which additionally adds the domain rule into the affiliated target list. Each affiliation begins with `&amp;` and followed by the name of the target list (nomatter whether the target has a dedicated file in data path). This is a method for data management, and will not remain in the final lists or `dlc.dat`.
- Inclusion begins with `include:`, followed by the name of another valid domain list. A simple `include:listb` in file `lista` means adding all domain rules of `listb` into `lista`. Inclusions with attributes stands for selective inclusion. `include:listb @attr1 @-attr2` means only adding those domain rules *with* `@attr1` **and** *without* `@attr2`. This is a special type for data management, and will not remain in the final lists or `dlc.dat`.

## How it works

The entire `data` directory will be built into an external `geosite` file for Project V. Each file in the directory represents a section in the generated file.

**General steps:**

1. Read files in the data path (ignore all comments and empty lines).
2. Parse and resolve source data, turn affiliations and inclusions into actual domain rules in proper lists.
3. Deduplicate and sort rules in every list.
4. Export desired plain text lists.
5. Generate `dlc.dat`:
   - turn each `domain:` line into a [sub-domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L21).
   - turn each `full:` line into a [full domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L23).
   - turn each `keyword:` line into a [plain domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L17).
   - turn each `regexp:` line into a [regex domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/routercommon/common.proto#L19).

Read [main.go](./main.go) for details.

## How to organize domains

### File name

Theoretically any string can be used as the name, as long as it is a valid file name. In practice, we prefer names for determinic group of domains, such as the owner (usually a company name) of the domains, e.g., &quot;google&quot;, &quot;netflix&quot;. Names with unclear scope are generally unrecommended, such as &quot;evil&quot;, or &quot;local&quot;.

### Attributes

Attribute is useful for sub-group of domains, especially for filtering purpose. For example, the list of `google` may contains its main domains, as well as domains that serve ads. The ads domains may be marked by attribute `@ads`, and can be used as `geosite:google@ads` in V2Ray routing. Domains and services that originate from outside China mainland but have access point in China mainland, may be marked by attribute `@cn`.

## Contribution guideline

- Fork this repo, make modifications to your own repo, file a PR.
- Please begin with small size PRs, say modification in a single file.
- A PR must be reviewed and approved by another member.
- A script will verify your pull request to test whether your PR is correct or not every time you update the PR. Only the PR which passes the test will be merged. Please go to the Action label to get detailed information if you didn&#039;t pass it. We also provide the file which has been generated to make you test.
- After a few successful PRs, you may apply for manager access to this repository.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gosom/google-maps-scraper]]></title>
            <link>https://github.com/gosom/google-maps-scraper</link>
            <guid>https://github.com/gosom/google-maps-scraper</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:18 GMT</pubDate>
            <description><![CDATA[scrape data data from Google Maps. Extracts data such as the name, address, phone number, website URL, rating, reviews number, latitude and longitude, reviews,email and more for each place]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gosom/google-maps-scraper">gosom/google-maps-scraper</a></h1>
            <p>scrape data data from Google Maps. Extracts data such as the name, address, phone number, website URL, rating, reviews number, latitude and longitude, reviews,email and more for each place</p>
            <p>Language: Go</p>
            <p>Stars: 3,096</p>
            <p>Forks: 427</p>
            <p>Stars today: 135 stars today</p>
            <h2>README</h2><pre># Google Maps Scraper

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/gosom/google-maps-scraper/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/gosom/google-maps-scraper?style=social&quot; alt=&quot;GitHub Stars&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/gosom/google-maps-scraper/network/members&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/gosom/google-maps-scraper?style=social&quot; alt=&quot;GitHub Forks&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/intent/tweet?text=Powerful%20open-source%20Google%20Maps%20scraper%20-%20extract%20business%20data%20at%20scale%20with%20CLI%2C%20Web%20UI%2C%20or%20REST%20API&amp;url=https%3A%2F%2Fgithub.com%2Fgosom%2Fgoogle-maps-scraper&amp;hashtags=golang,webscraping,googlemaps,opensource&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/url/http/shields.io.svg?style=social&quot; alt=&quot;Tweet&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

[![Build Status](https://github.com/gosom/google-maps-scraper/actions/workflows/build.yml/badge.svg)](https://github.com/gosom/google-maps-scraper/actions/workflows/build.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/gosom/google-maps-scraper)](https://goreportcard.com/report/github.com/gosom/google-maps-scraper)
[![GoDoc](https://godoc.org/github.com/gosom/google-maps-scraper?status.svg)](https://godoc.org/github.com/gosom/google-maps-scraper)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Discord](https://img.shields.io/badge/Discord-Join%20Chat-7289DA?logo=discord&amp;logoColor=white)](https://discord.gg/fpaAVhNCCu)

**A powerful, free, and open-source Google Maps scraper** for extracting business data at scale. Available as CLI, Web UI, REST API, or deployable to Kubernetes/AWS Lambda.

![Example GIF](img/example.gif)

&gt; üí° **New:** Export leads directly to [LeadsDB](https://getleadsdb.com/) - manage via API, AI/MCP integration, or UI with custom filtering and exports.

&gt; **Love this project?** A star helps others discover it and motivates continued development. [Become a sponsor](https://github.com/sponsors/gosom) to directly support new features and maintenance.

---

## Sponsored By

&lt;p align=&quot;center&quot;&gt;&lt;i&gt;This project is made possible by our amazing sponsors&lt;/i&gt;&lt;/p&gt;

### [Scrap.io](https://scrap.io?utm_medium=ads&amp;utm_source=github_gosom_gmap_scraper) - Extract ALL Google Maps listings at country-scale

[![Scrap.io - Extract ALL Google Maps Listings](./img/premium_scrap_io.png)](https://scrap.io?utm_medium=ads&amp;utm_source=github_gosom_gmap_scraper)

No keywords needed. No limits. Export millions of businesses in 2 clicks. [**Try it free ‚Üí**](https://scrap.io?utm_medium=ads&amp;utm_source=github_gosom_gmap_scraper)

---

### [G Maps Extractor](https://gmapsextractor.com?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=gosom) - No-code Google Maps scraper

[![G Maps Extractor](./img/gmaps-extractor-banner.png)](https://gmapsextractor.com?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=gosom)

Chrome extension that extracts emails, social profiles, phone numbers, reviews &amp; more. [**Get 1,000 free leads ‚Üí**](https://gmapsextractor.com?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=gosom)

---

### [SerpApi](https://serpapi.com/?utm_source=google-maps-scraper) - Google Maps API and 30+ search engine APIs

[![SerpApi](./img/SerpApi-banner.png)](https://serpapi.com/?utm_source=google-maps-scraper)

Fast, reliable, and scalable. Used by Fortune 500 companies. [**View all APIs ‚Üí**](https://serpapi.com/search-api)

---

### [HasData](https://hasdata.com/scrapers/google-maps?utm_source=github&amp;utm_medium=sponsorship&amp;utm_campaign=gosom) - No-code Google Maps Scraper &amp; Email Extraction

[![HasData Google Maps Scraper](./img/hd-gm-banner.png)](https://hasdata.com/scrapers/google-maps?utm_source=github&amp;utm_medium=sponsorship&amp;utm_campaign=gosom)

Extract business leads, emails, addresses, phones, reviews and more. [**Get 1,000 free credits ‚Üí**](https://hasdata.com/scrapers/google-maps?utm_source=github&amp;utm_medium=sponsorship&amp;utm_campaign=gosom)

---

### [LeadsDB](https://getleadsdb.com/) - Your Central Database for Business Leads

[![LeadsDB](./img/leadsdb-banner.png)](https://getleadsdb.com/)

Push leads via API or AI agent, remove duplicates automatically, and export when ready. [**Start free ‚Üí**](https://getleadsdb.com/)

---

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#sponsors&quot;&gt;View all sponsors&lt;/a&gt; | &lt;a href=&quot;https://github.com/sponsors/gosom&quot;&gt;Become a sponsor&lt;/a&gt;
&lt;/p&gt;

---

## Why Use This Scraper?

| | |
|---|---|
| **Completely Free &amp; Open Source** | MIT licensed, no hidden costs or usage limits |
| **Multiple Interfaces** | CLI, Web UI, REST API - use what fits your workflow |
| **High Performance** | ~120 places/minute with optimized concurrency |
| **33+ Data Points** | Business details, reviews, emails, coordinates, and more |
| **Production Ready** | Scale from a single machine to Kubernetes clusters |
| **Flexible Output** | CSV, JSON, PostgreSQL, S3, LeadsDB, or custom plugins |
| **Proxy Support** | Built-in SOCKS5/HTTP/HTTPS proxy rotation |

---

## What&#039;s Next After Scraping?

Once you&#039;ve collected your data, you&#039;ll need to manage, deduplicate, and work with your leads. **[LeadsDB](https://getleadsdb.com/)** is a companion tool designed exactly for this:

- **Automatic Deduplication** - Import from multiple scrapes without worrying about duplicates
- **AI Agent Ready** - Query and manage leads with natural language via MCP
- **Advanced Filtering** - Combine filters with AND/OR logic on any field
- **Export Anywhere** - CSV, JSON, or use the REST API

The scraper has [built-in LeadsDB integration](#export-to-leadsdb) - just add your API key and leads flow directly into your database.

**[Start free with 500 leads](https://getleadsdb.com/)**

---

## Table of Contents

- [Quick Start](#quick-start)
  - [Web UI](#web-ui)
  - [Command Line](#command-line)
  - [REST API](#rest-api)
- [Installation](#installation)
- [Features](#features)
- [Extracted Data Points](#extracted-data-points)
- [Configuration](#configuration)
  - [Command Line Options](#command-line-options)
  - [Using Proxies](#using-proxies)
  - [Email Extraction](#email-extraction)
  - [Fast Mode](#fast-mode)
- [Export to LeadsDB](#export-to-leadsdb)
- [Advanced Usage](#advanced-usage)
  - [PostgreSQL Database Provider](#postgresql-database-provider)
  - [Kubernetes Deployment](#kubernetes-deployment)
  - [Custom Writer Plugins](#custom-writer-plugins)
- [Performance](#performance)
- [Support the Project](#support-the-project)
- [Sponsors](#sponsors)
- [Community](#community)
- [Contributing](#contributing)
- [License](#license)

---

## Quick Start

### Web UI

Start the web interface with a single command:

```bash
mkdir -p gmapsdata &amp;&amp; docker run -v $PWD/gmapsdata:/gmapsdata -p 8080:8080 gosom/google-maps-scraper -data-folder /gmapsdata
```

Then open http://localhost:8080 in your browser.

Or download the [binary release](https://github.com/gosom/google-maps-scraper/releases) for your platform.

&gt; **Note:** Results take at least 3 minutes to appear (minimum configured runtime).
&gt; 
&gt; **macOS Users:** Docker command may not work. See [MacOS Instructions](MacOS%20instructions.md).

### Command Line

```bash
touch results.csv &amp;&amp; docker run \
  -v $PWD/example-queries.txt:/example-queries \
  -v $PWD/results.csv:/results.csv \
  gosom/google-maps-scraper \
  -depth 1 \
  -input /example-queries \
  -results /results.csv \
  -exit-on-inactivity 3m
```

&gt; **Tip:** Use `gosom/google-maps-scraper:latest-rod` for the Rod version with faster container startup.

**Want emails?** Add the `-email` flag.

**Want all reviews (up to ~300)?** Add `--extra-reviews` and use `-json` output.

**Want to skip CSV files?** Send leads directly to [LeadsDB](https://getleadsdb.com/):

```bash
docker run \
  -v $PWD/example-queries.txt:/example-queries \
  gosom/google-maps-scraper \
  -depth 1 \
  -input /example-queries \
  -leadsdb-api-key &quot;your-api-key&quot; \
  -exit-on-inactivity 3m
```

### REST API

When running the web server, a full REST API is available:

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/v1/jobs` | POST | Create a new scraping job |
| `/api/v1/jobs` | GET | List all jobs |
| `/api/v1/jobs/{id}` | GET | Get job details |
| `/api/v1/jobs/{id}` | DELETE | Delete a job |
| `/api/v1/jobs/{id}/download` | GET | Download results as CSV |

Full OpenAPI 3.0.3 documentation available at http://localhost:8080/api/docs

---

## Installation

### Using Docker (Recommended)

Two Docker image variants are available:

| Image | Tag | Browser Engine | Best For |
|-------|-----|----------------|----------|
| Playwright (default) | `latest`, `vX.X.X` | Playwright | Most users, better stability |
| Rod | `latest-rod`, `vX.X.X-rod` | Rod/Chromium | Lightweight, faster startup |

```bash
# Playwright version (default)
docker pull gosom/google-maps-scraper

# Rod version (alternative)
docker pull gosom/google-maps-scraper:latest-rod
```

### Build from Source

Requirements: Go 1.25.6+

```bash
git clone https://github.com/gosom/google-maps-scraper.git
cd google-maps-scraper
go mod download

# Playwright version (default)
go build
./google-maps-scraper -input example-queries.txt -results results.csv -exit-on-inactivity 3m

# Rod version (alternative)
go build -tags rod
./google-maps-scraper -input example-queries.txt -results results.csv -exit-on-inactivity 3m
```

&gt; First run downloads required browser libraries (Playwright or Chromium depending on version).

---

## Features

| Feature | Description |
|---------|-------------|
| **33+ Data Points** | Business name, address, phone, website, reviews, coordinates, and more |
| **Email Extraction** | Optional crawling of business websites for email addresses |
| **Multiple Output Formats** | CSV, JSON, PostgreSQL, S3, LeadsDB, or custom plugins |
| **Proxy Support** | SOCKS5, HTTP, HTTPS with authentication |
| **Scalable Architecture** | Single machine to Kubernetes cluster |
| **REST API** | Programmatic control for automation |
| **Web UI** | User-friendly browser interface |
| **Fast Mode (Beta)** | Quick extraction of up to 21 results per query |
| **AWS Lambda** | Serverless execution support (experimental) |

---

## Extracted Data Points

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Click to expand all 33 data points&lt;/strong&gt;&lt;/summary&gt;

| # | Field | Description |
|---|-------|-------------|
| 1 | `input_id` | Internal identifier for the input query |
| 2 | `link` | Direct URL to the Google Maps listing |
| 3 | `title` | Business name |
| 4 | `category` | Business type (e.g., Restaurant, Hotel) |
| 5 | `address` | Street address |
| 6 | `open_hours` | Operating hours |
| 7 | `popular_times` | Visitor traffic patterns |
| 8 | `website` | Official business website |
| 9 | `phone` | Contact phone number |
| 10 | `plus_code` | Location shortcode |
| 11 | `review_count` | Total number of reviews |
| 12 | `review_rating` | Average star rating |
| 13 | `reviews_per_rating` | Breakdown by star rating |
| 14 | `latitude` | GPS latitude |
| 15 | `longitude` | GPS longitude |
| 16 | `cid` | Google&#039;s unique Customer ID |
| 17 | `status` | Business status (open/closed/temporary) |
| 18 | `descriptions` | Business description |
| 19 | `reviews_link` | Direct link to reviews |
| 20 | `thumbnail` | Thumbnail image URL |
| 21 | `timezone` | Business timezone |
| 22 | `price_range` | Price level ($, $$, $$$) |
| 23 | `data_id` | Internal Google Maps identifier |
| 24 | `images` | Associated image URLs |
| 25 | `reservations` | Reservation booking link |
| 26 | `order_online` | Online ordering link |
| 27 | `menu` | Menu link |
| 28 | `owner` | Owner-claimed status |
| 29 | `complete_address` | Full formatted address |
| 30 | `about` | Additional business info |
| 31 | `user_reviews` | Customer reviews (text, rating, timestamp) |
| 32 | `emails` | Extracted email addresses (requires `-email` flag) |
| 33 | `user_reviews_extended` | Extended reviews up to ~300 (requires `-extra-reviews`) |
| 34 | `place_id` | Google&#039;s unique place id |

&lt;/details&gt;

**Custom Input IDs:** Define your own IDs in the input file:
```
Matsuhisa Athens #!#MyCustomID
```

---

## Configuration

### Command Line Options

```
Usage: google-maps-scraper [options]

Core Options:
  -input string       Path to input file with queries (one per line)
  -results string     Output file path (default: stdout)
  -json              Output JSON instead of CSV
  -depth int         Max scroll depth in results (default: 10)
  -c int             Concurrency level (default: half of CPU cores)

Email &amp; Reviews:
  -email             Extract emails from business websites
  -extra-reviews     Collect extended reviews (up to ~300)

Location Settings:
  -lang string       Language code, e.g., &#039;de&#039; for German (default: &quot;en&quot;)
  -geo string        Coordinates for search, e.g., &#039;37.7749,-122.4194&#039;
  -zoom int          Zoom level 0-21 (default: 15)
  -radius float      Search radius in meters (default: 10000)

Web Server:
  -web               Run web server mode
  -addr string       Server address (default: &quot;:8080&quot;)
  -data-folder       Data folder for web runner (default: &quot;webdata&quot;)

Database:
  -dsn string        PostgreSQL connection string
  -produce           Produce seed jobs only (requires -dsn)

Proxy:
  -proxies string    Comma-separated proxy list
                     Format: protocol://user:pass@host:port

Export:
  -leadsdb-api-key   Export directly to LeadsDB (get key at getleadsdb.com)

Advanced:
  -exit-on-inactivity duration    Exit after inactivity (e.g., &#039;5m&#039;)
  -fast-mode                      Quick mode with reduced data
  -debug                          Show browser window
  -writer string                  Custom writer plugin (format: &#039;dir:pluginName&#039;)
```

Run `./google-maps-scraper -h` for the complete list.

### Using Proxies

For larger scraping jobs, proxies help avoid rate limiting. Here&#039;s how to configure them:

```bash
./google-maps-scraper \
  -input queries.txt \
  -results results.csv \
  -proxies &#039;socks5://user:pass@host:port,http://host2:port2&#039; \
  -depth 1 -c 2
```

**Supported protocols:** `socks5`, `socks5h`, `http`, `https`

#### Proxy Providers

If you need reliable proxies, these providers support this project as sponsors:

| Provider | Highlight | Offer |
|----------|-----------|-------|
| [Decodo](https://visit.decodo.com/APVbbx) | #1 response time, 125M+ IPs | [3-day free trial](https://visit.decodo.com/APVbbx) |
| [Evomi](https://evomi.com?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=gosom-maps) | Swiss quality, 150+ countries | From $0.49/GB |

Using their services helps fund continued development of this scraper.

### Email Extraction

Email extraction is **disabled by default**. When enabled, the scraper visits each business website to find email addresses.

```bash
./google-maps-scraper -input queries.txt -results results.csv -email
```

&gt; **Note:** Email extraction increases processing time significantly.

### Fast Mode

Fast mode returns up to 21 results per query, ordered by distance. Useful for quick data collection with basic fields.

```bash
./google-maps-scraper \
  -input queries.txt \
  -results results.csv \
  -fast-mode \
  -zoom 15 \
  -radius 5000 \
  -geo &#039;37.7749,-122.4194&#039;
```

&gt; **Warning:** Fast mode is in Beta. You may experience blocking.

---

## Export to LeadsDB

Skip the CSV files and send leads directly to a managed database. [LeadsDB](https://getleadsdb.com/) handles deduplication, filtering, and provides an API for your applications.

**Using Docker:**
```bash
docker run \
  -v $PWD/example-queries.txt:/example-queries \
  gosom/google-maps-scraper \
  -depth 1 \
  -input /example-queries \
  -leadsdb-api-key &quot;your-api-key&quot; \
  -exit-on-inactivity 3m
```

**Using binary:**
```bash
./google-maps-scraper \
  -input queries.txt \
  -leadsdb-api-key &quot;your-api-key&quot; \
  -exit-on-inactivity 3m
```

Or via environment variable:
```bash
export LEADSDB_API_KEY=&quot;your-api-key&quot;
./google-maps-scraper -input queries.txt -exit-on-inactivity 3m
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Field Mapping&lt;/strong&gt;&lt;/summary&gt;

| Google Maps | LeadsDB |
|-------------|---------|
| Title | Name |
| Category | Category |
| Categories | Tags |
| Phone | Phone |
| Website | Website |
| Address | Address, City, State, Country, PostalCode |
| Latitude/Longitude | Coordinates |
| Review Rating | Rating |
| Review Count | ReviewCount |
| Emails | Email |
| Thumbnail | LogoURL |
| CID | SourceID |

Additional fields (Google Maps link, plus code, price range, etc.) are stored as custom attributes.

&lt;/details&gt;

Get your API key at [getleadsdb.com/settings](https://getleadsdb.com/settings) after signing up.

---

## Advanced Usage

### PostgreSQL Database Provider

For distributed scraping across multiple machines:

**1. Start PostgreSQL:**
```bash
docker-compose -f docker-compose.dev.yaml up -d
```

**2. Seed the jobs:**
```bash
./google-maps-scraper \
  -dsn &quot;postgres://postgres:postgres@localhost:5432/postgres&quot; \
  -produce \
  -input example-queries.txt \
  -lang en
```

**3. Run scrapers (on multiple machines):**
```bash
./google-maps-scraper \
  -c 2 \
  -depth 1 \
  -dsn &quot;postgres://postgres:postgres@localhost:5432/postgres&quot;
```

### Kubernetes Deployment

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: google-maps-scraper
spec:
  replicas: 3  # Adjust based on needs
  selector:
    matchLabels:
      app: google-maps-scraper
  template:
    metadata:
      labels:
        app: google-maps-scraper
    spec:
      containers:
      - name: google-maps-scraper
        image: gosom/google-maps-scraper:latest
        args: [&quot;-c&quot;, &quot;1&quot;, &quot;-depth&quot;, &quot;10&quot;, &quot;-dsn&quot;, &quot;postgres://user:pass@host:5432/db&quot;]
        resources:
          requests:
            memory: &quot;512Mi&quot;
            cpu: &quot;500m&quot;
```

&gt; **Note:** The headless browser requires significant CPU/memory resources.

### Custom Writer Plugins

Create custom output handlers using Go plugins:

**1. Write the plugin** (see `examples/plugins/example_writer.go`)

**2. Build:**
```bash
go build -buildmode=plugin -tags=plugin -o myplugin.so myplugin.go
```

**3. Run:**
```bash
./google-maps-scraper -writer ~/plugins:MyWriter -input queries.txt
```

---

## Performance

**Expected throughput:** ~120 places/minute (with `-c 8 -depth 1`)

| Keywords | Results/Keyword | Total Jobs | Estimated Time |
|----------|-----------------|------------|----------------|
| 100 | 16 | 1,600 | ~13 minutes |
| 1,000 | 16 | 16,000 | ~2.5 hours |
| 10,000 | 16 | 160,000 | ~22 hours |

For large-scale scraping, use the PostgreSQL provider with Kubernetes.

### Telemetry

Anonymous usage statistics are collected for improvement purposes. Opt out:
```bash
export DISABLE_TELEMETRY=1
```

---

## Support the Project

This project is **free and open source**, maintained in my spare time. If it&#039;s useful to you, here&#039;s how you can help it grow:

### Quick Ways to Help

| Action | Impact |
|--------|--------|
| **[Star this repo](https://github.com/gosom/google-maps-scraper)** | Helps others discover the project |
| **[Sponsor on GitHub](https://github.com/sponsors/gosom)** | Directly funds development time |
| **Share your success** | Tweet or blog about how you use it |
| **Report bugs &amp; contribute** | Help improve the codebase |

### Use Sponsor Services

When you need proxies, APIs, or cloud services, consider using our sponsors. You get quality tools, and the referral helps fund this project:

- **Need proxies?** [Decodo](https://visit.decodo.com/APVbbx) or [Evomi](https://evomi.com?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=gosom-maps)
- **Prefer an API?** [SerpApi](https://serpapi.com/?utm_source=google-maps-scraper) or [SearchAPI](https://www.searchapi.io/google-maps?via=gosom)
- **No-code solution?** [Scrap.io](https://scrap.io?utm_medium=ads&amp;utm_source=github_gosom_gmap_scraper) or [G Maps Extractor](https://gmapsextractor.com?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=gosom)
- **Manage your leads?** [LeadsDB](https://getleadsdb.com/) - dedupl

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[steipete/wacli]]></title>
            <link>https://github.com/steipete/wacli</link>
            <guid>https://github.com/steipete/wacli</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:17 GMT</pubDate>
            <description><![CDATA[WhatsApp CLI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/steipete/wacli">steipete/wacli</a></h1>
            <p>WhatsApp CLI</p>
            <p>Language: Go</p>
            <p>Stars: 399</p>
            <p>Forks: 64</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># üóÉÔ∏è wacli ‚Äî WhatsApp CLI: sync, search, send.

WhatsApp CLI built on top of `whatsmeow`, focused on:

- Best-effort local sync of message history + continuous capture
- Fast offline search
- Sending messages
- Contact + group management

This is a third-party tool that uses the WhatsApp Web protocol via `whatsmeow` and is not affiliated with WhatsApp.

## Status

Core implementation is in place. See `docs/spec.md` for the full design notes.

## Recent updates (0.2.0)

- Messages: search/list includes display text for reactions, replies, and media types.
- Send: `wacli send file --filename` to override the display name.
- Auth: optional `WACLI_DEVICE_LABEL` / `WACLI_DEVICE_PLATFORM` env overrides.

## Install / Build

Choose **one** of the following options.  
If you install via Homebrew, you can skip the local build step.

### Option A: Install via Homebrew (tap)

- `brew install steipete/tap/wacli`

### Option B: Build locally

- `go build -tags sqlite_fts5 -o ./dist/wacli ./cmd/wacli`

Run (local build only):

- `./dist/wacli --help`

## Quick start

Default store directory is `~/.wacli` (override with `--store DIR`).

```bash
# 1) Authenticate (shows QR), then bootstrap sync
pnpm wacli auth
# or: ./dist/wacli auth (after pnpm build)

# 2) Keep syncing (never shows QR; requires prior auth)
pnpm wacli sync --follow

# Diagnostics
pnpm wacli doctor

# Search messages
pnpm wacli messages search &quot;meeting&quot;

# Backfill older messages for a chat (best-effort; requires your primary device online)
pnpm wacli history backfill --chat 1234567890@s.whatsapp.net --requests 10 --count 50

# Download media for a message (after syncing)
./wacli media download --chat 1234567890@s.whatsapp.net --id &lt;message-id&gt;

# Send a message
pnpm wacli send text --to 1234567890 --message &quot;hello&quot;

# Send a file
./wacli send file --to 1234567890 --file ./pic.jpg --caption &quot;hi&quot;
# Or override display name
./wacli send file --to 1234567890 --file /tmp/abc123 --filename report.pdf

# List groups and manage participants
pnpm wacli groups list
pnpm wacli groups rename --jid 123456789@g.us --name &quot;New name&quot;
```

## Prior Art / Credit

This project is heavily inspired by (and learns from) the excellent `whatsapp-cli` by Vicente Reig:

- [`whatsapp-cli`](https://github.com/vicentereig/whatsapp-cli)

## High-level UX

- `wacli auth`: interactive login (shows QR code), then immediately performs initial data sync.
- `wacli sync`: non-interactive sync loop (never shows QR; errors if not authenticated).
- Output is human-readable by default; pass `--json` for machine-readable output.

## Storage

Defaults to `~/.wacli` (override with `--store DIR`).

## Environment overrides

- `WACLI_DEVICE_LABEL`: set the linked device label (shown in WhatsApp).
- `WACLI_DEVICE_PLATFORM`: override the linked device platform (defaults to `CHROME` if unset or invalid).

## Backfilling older history

`wacli sync` stores whatever WhatsApp Web sends opportunistically. To try to fetch *older* messages, use on-demand history sync requests to your **primary device** (your phone).

Important notes:

- This is **best-effort**: WhatsApp may not return full history.
- Your **primary device must be online**.
- Requests are **per chat** (DM or group). `wacli` uses the *oldest locally stored message* in that chat as the anchor.
- Recommended `--count` is `50` per request.

### Backfill one chat

```bash
pnpm wacli history backfill --chat 1234567890@s.whatsapp.net --requests 10 --count 50
```

### Backfill all chats (script)

This loops through chats already known in your local DB:

```bash
pnpm -s wacli -- --json chats list --limit 100000 \
  | jq -r &#039;.[].JID&#039; \
  | while read -r jid; do
      pnpm -s wacli -- history backfill --chat &quot;$jid&quot; --requests 3 --count 50
    done
```

## License

See `LICENSE`.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[charmbracelet/glow]]></title>
            <link>https://github.com/charmbracelet/glow</link>
            <guid>https://github.com/charmbracelet/glow</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:16 GMT</pubDate>
            <description><![CDATA[Render markdown on the CLI, with pizzazz! üíÖüèª]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/charmbracelet/glow">charmbracelet/glow</a></h1>
            <p>Render markdown on the CLI, with pizzazz! üíÖüèª</p>
            <p>Language: Go</p>
            <p>Stars: 22,798</p>
            <p>Forks: 574</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># Glow

Render markdown on the CLI, with _pizzazz_!

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://stuff.charm.sh/glow/glow-banner-github.gif&quot; alt=&quot;Glow Logo&quot;&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/glow/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/charmbracelet/glow.svg&quot; alt=&quot;Latest Release&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://pkg.go.dev/github.com/charmbracelet/glow?tab=doc&quot;&gt;&lt;img src=&quot;https://godoc.org/github.com/golang/gddo?status.svg&quot; alt=&quot;GoDoc&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/glow/actions&quot;&gt;&lt;img src=&quot;https://github.com/charmbracelet/glow/workflows/build/badge.svg&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://goreportcard.com/report/github.com/charmbracelet/glow&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/charmbracelet/glow&quot; alt=&quot;Go ReportCard&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/c2246366-f84b-4847-b431-32a61ca07b74&quot; width=&quot;800&quot; alt=&quot;Glow UI Demo&quot;&gt;
&lt;/p&gt;

## What is it?

Glow is a terminal based markdown reader designed from the ground up to bring
out the beauty‚Äîand power‚Äîof the CLI.

Use it to discover markdown files, read documentation directly on the command
line. Glow will find local markdown files in subdirectories or a local
Git repository.

## Installation

### Package Manager

```bash
# macOS or Linux
brew install glow
```

```bash
# macOS (with MacPorts)
sudo port install glow
```

```bash
# Arch Linux (btw)
pacman -S glow
```

```bash
# Void Linux
xbps-install -S glow
```

```bash
# Nix shell
nix-shell -p glow --command glow
```

```bash
# FreeBSD
pkg install glow
```

```bash
# Solus
eopkg install glow
```

```bash
# Windows (with Chocolatey, Scoop, or Winget)
choco install glow
scoop install glow
winget install charmbracelet.glow
```

```bash
# Android (with termux)
pkg install glow
```

```bash
# Ubuntu (Snapcraft)
sudo snap install glow
```

```bash
# Debian/Ubuntu
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo &quot;deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *&quot; | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;&amp; sudo apt install glow
```

```bash
# Fedora/RHEL
echo &#039;[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key&#039; | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install glow
```

Or download a binary from the [releases][releases] page. MacOS, Linux, Windows,
FreeBSD and OpenBSD binaries are available, as well as Debian, RPM, and Alpine
packages. ARM builds are also available for macOS, Linux, FreeBSD and OpenBSD.

### Go

Or just install it with `go`:

```bash
go install github.com/charmbracelet/glow/v2@latest
```

### Build (requires Go 1.21+)

```bash
git clone https://github.com/charmbracelet/glow.git
cd glow
go build
```

[releases]: https://github.com/charmbracelet/glow/releases

## The TUI

Simply run `glow` without arguments to start the textual user interface and
browse local. Glow will find local markdown files in the
current directory and below or, if you‚Äôre in a Git repository, Glow will search
the repo.

Markdown files can be read with Glow&#039;s high-performance pager. Most of the
keystrokes you know from `less` are the same, but you can press `?` to list
the hotkeys.

## The CLI

In addition to a TUI, Glow has a CLI for working with Markdown. To format a
document use a markdown source as the primary argument:

```bash
# Read from file
glow README.md

# Read from stdin
echo &quot;[Glow](https://github.com/charmbracelet/glow)&quot; | glow -

# Fetch README from GitHub / GitLab
glow github.com/charmbracelet/glow

# Fetch markdown from HTTP
glow https://host.tld/file.md
```

### Word Wrapping

The `-w` flag lets you set a maximum width at which the output will be wrapped:

```bash
glow -w 60
```

### Paging

CLI output can be displayed in your preferred pager with the `-p` flag. This defaults
to the ANSI-aware `less -r` if `$PAGER` is not explicitly set.

### Styles

You can choose a style with the `-s` flag. When no flag is provided `glow` tries
to detect your terminal&#039;s current background color and automatically picks
either the `dark` or the `light` style for you.

```bash
glow -s [dark|light]
```

Alternatively you can also supply a custom JSON stylesheet:

```bash
glow -s mystyle.json
```

For additional usage details see:

```bash
glow --help
```

Check out the [Glamour Style Section](https://github.com/charmbracelet/glamour/blob/master/styles/gallery/README.md)
to find more styles. Or [make your own](https://github.com/charmbracelet/glamour/tree/master/styles)!

## The Config File

If you find yourself supplying the same flags to `glow` all the time, it&#039;s
probably a good idea to create a config file. Run `glow config`, which will open
it in your favorite $EDITOR. Alternatively you can manually put a file named
`glow.yml` in the default config path of you platform. If you&#039;re not sure where
that is, please refer to `glow --help`.

Here&#039;s an example config:

```yaml
# style name or JSON path (default &quot;auto&quot;)
style: &quot;light&quot;
# mouse wheel support (TUI-mode only)
mouse: true
# use pager to display markdown
pager: true
# at which column should we word wrap?
width: 80
# show all files, including hidden and ignored.
all: false
# show line numbers (TUI-mode only)
showLineNumbers: false
# preserve newlines in the output
preserveNewLines: false
```

## Contributing

See [contributing][contribute].

[contribute]: https://github.com/charmbracelet/glow/contribute

## Feedback

We‚Äôd love to hear your thoughts on this project. Feel free to drop us a note!

- [Twitter](https://twitter.com/charmcli)
- [The Fediverse](https://mastodon.social/@charmcli)
- [Discord](https://charm.sh/chat)

## License

[MIT](https://github.com/charmbracelet/glow/raw/master/LICENSE)

---

Part of [Charm](https://charm.sh).

&lt;a href=&quot;https://charm.sh/&quot;&gt;&lt;img alt=&quot;The Charm logo&quot; src=&quot;https://stuff.charm.sh/charm-badge.jpg&quot; width=&quot;400&quot;&gt;&lt;/a&gt;

CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[minio/minio]]></title>
            <link>https://github.com/minio/minio</link>
            <guid>https://github.com/minio/minio</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:15 GMT</pubDate>
            <description><![CDATA[MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/minio/minio">minio/minio</a></h1>
            <p>MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license.</p>
            <p>Language: Go</p>
            <p>Stars: 60,310</p>
            <p>Forks: 7,031</p>
            <p>Stars today: 89 stars today</p>
            <h2>README</h2><pre>&gt; [!NOTE]
&gt; **THIS REPOSITORY IS NO LONGER MAINTAINED.**
&gt;
&gt; **Alternatives:**
&gt; - **[AIStor Free](https://min.io/download)** ‚Äî Full-featured, standalone edition for community use (free license)
&gt; - **[AIStor Enterprise](https://min.io/pricing)** ‚Äî Distributed edition with commercial support

---

# MinIO Quickstart Guide

[![Slack](https://slack.min.io/slack?type=svg)](https://slack.min.io) [![Docker Pulls](https://img.shields.io/docker/pulls/minio/minio.svg?maxAge=604800)](https://hub.docker.com/r/minio/minio/) [![license](https://img.shields.io/badge/license-AGPL%20V3-blue)](https://github.com/minio/minio/blob/master/LICENSE)

[![MinIO](https://raw.githubusercontent.com/minio/minio/master/.github/logo.svg?sanitize=true)](https://min.io)

MinIO is a high-performance, S3-compatible object storage solution released under the GNU AGPL v3.0 license.
Designed for speed and scalability, it powers AI/ML, analytics, and data-intensive workloads with industry-leading performance.

- S3 API Compatible ‚Äì Seamless integration with existing S3 tools
- Built for AI &amp; Analytics ‚Äì Optimized for large-scale data pipelines
- High Performance ‚Äì Ideal for demanding storage workloads.

This README provides instructions for building MinIO from source and deploying onto baremetal hardware.
Use the [MinIO Documentation](https://github.com/minio/docs) project to build and host a local copy of the documentation.

## MinIO is Open Source Software

We designed MinIO as Open Source software for the Open Source software community. We encourage the community to remix, redesign, and reshare MinIO under the terms of the AGPLv3 license.

All usage of MinIO in your application stack requires validation against AGPLv3 obligations, which include but are not limited to the release of modified code to the community from which you have benefited. Any commercial/proprietary usage of the AGPLv3 software, including repackaging or reselling services/features, is done at your own risk.

The AGPLv3 provides no obligation by any party to support, maintain, or warranty the original or any modified work.
All support is provided on a best-effort basis through Github and our [Slack](https://slack.min.io) channel, and any member of the community is welcome to contribute and assist others in their usage of the software.

MinIO [AIStor](https://www.min.io/product/aistor) includes enterprise-grade support and licensing for workloads which require commercial or proprietary usage and production-level SLA/SLO-backed support. For more information, [reach out for a quote](https://min.io/pricing).

## Source-Only Distribution

**Important:** The MinIO community edition is now distributed as source code only. We will no longer provide pre-compiled binary releases for the community version.

### Installing Latest MinIO Community Edition

To use MinIO community edition, you have two options:

1. **Install from source** using `go install github.com/minio/minio@latest` (recommended)
2. **Build a Docker image** from the provided Dockerfile

See the sections below for detailed instructions on each method.

### Legacy Binary Releases

Historical pre-compiled binary releases remain available for reference but are no longer maintained:

- GitHub Releases: https://github.com/minio/minio/releases
- Direct downloads: https://dl.min.io/server/minio/release/

**These legacy binaries will not receive updates.** We strongly recommend using source builds for access to the latest features, bug fixes, and security updates.

## Install from Source

Use the following commands to compile and run a standalone MinIO server from source.
If you do not have a working Golang environment, please follow [How to install Golang](https://golang.org/doc/install). Minimum version required is [go1.24](https://golang.org/dl/#stable)

```sh
go install github.com/minio/minio@latest
```

You can alternatively run `go build` and use the `GOOS` and `GOARCH` environment variables to control the OS and architecture target.
For example:

```
env GOOS=linux GOARCH=arm64 go build
```

Start MinIO by running `minio server PATH` where `PATH` is any empty folder on your local filesystem.

The MinIO deployment starts using default root credentials `minioadmin:minioadmin`.
You can test the deployment using the MinIO Console, an embedded web-based object browser built into MinIO Server.
Point a web browser running on the host machine to &lt;http://127.0.0.1:9000&gt; and log in with the root credentials.
You can use the Browser to create buckets, upload objects, and browse the contents of the MinIO server.

You can also connect using any S3-compatible tool, such as the MinIO Client `mc` commandline tool:

```sh
mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info local
```

See [Test using MinIO Client `mc`](#test-using-minio-client-mc) for more information on using the `mc` commandline tool.
For application developers, see &lt;https://docs.min.io/enterprise/aistor-object-store/developers/sdk/&gt; to view MinIO SDKs for supported languages.

&gt; [!NOTE]
&gt; Production environments using compiled-from-source MinIO binaries do so at their own risk.
&gt; The AGPLv3 license provides no warranties nor liabilities for any such usage.

## Build Docker Image

You can use the `docker build .` command to build a Docker image on your local host machine.
You must first [build MinIO](#install-from-source) and ensure the `minio` binary exists in the project root.

The following command builds the Docker image using the default `Dockerfile` in the root project directory with the repository and image tag `myminio:minio`

```sh
docker build -t myminio:minio .
```

Use `docker image ls` to confirm the image exists in your local repository.
You can run the server using standard Docker invocation:

```sh
docker run -p 9000:9000 -p 9001:9001 myminio:minio server /tmp/minio --console-address :9001
```

Complete documentation for building Docker containers, managing custom images, or loading images into orchestration platforms is out of scope for this documentation.
You can modify the `Dockerfile` and `dockerscripts/docker-entrypoint.sh` as-needed to reflect your specific image requirements.

See the [MinIO Container](https://docs.min.io/community/minio-object-store/operations/deployments/baremetal-deploy-minio-as-a-container.html#deploy-minio-container) documentation for more guidance on running MinIO within a Container image.

## Install using Helm Charts

There are two paths for installing MinIO onto Kubernetes infrastructure:

- Use the [MinIO Operator](https://github.com/minio/operator)
- Use the community-maintained [Helm charts](https://github.com/minio/minio/tree/master/helm/minio)

See the [MinIO Documentation](https://docs.min.io/community/minio-object-store/operations/deployments/kubernetes.html) for guidance on deploying using the Operator.
The Community Helm chart has instructions in the folder-level README.

## Test MinIO Connectivity

### Test using MinIO Console

MinIO Server comes with an embedded web based object browser.
Point your web browser to &lt;http://127.0.0.1:9000&gt; to ensure your server has started successfully.

&gt; [!NOTE]
&gt; MinIO runs console on random port by default, if you wish to choose a specific port use `--console-address` to pick a specific interface and port.

### Test using MinIO Client `mc`

`mc` provides a modern alternative to UNIX commands like ls, cat, cp, mirror, diff etc. It supports filesystems and Amazon S3 compatible cloud storage services.

The following commands set a local alias, validate the server information, create a bucket, copy data to that bucket, and list the contents of the bucket.

```sh
mc alias set local http://localhost:9000 minioadmin minioadmin
mc admin info
mc mb data
mc cp ~/Downloads/mydata data/
mc ls data/
```

Follow the MinIO Client [Quickstart Guide](https://docs.min.io/community/minio-object-store/reference/minio-mc.html#quickstart) for further instructions.

## Explore Further

- [The MinIO documentation website](https://docs.min.io/community/minio-object-store/index.html)
- [MinIO Erasure Code Overview](https://docs.min.io/community/minio-object-store/operations/concepts/erasure-coding.html)
- [Use `mc` with MinIO Server](https://docs.min.io/community/minio-object-store/reference/minio-mc.html)
- [Use `minio-go` SDK with MinIO Server](https://docs.min.io/enterprise/aistor-object-store/developers/sdk/go/)

## Contribute to MinIO Project

Please follow MinIO [Contributor&#039;s Guide](https://github.com/minio/minio/blob/master/CONTRIBUTING.md) for guidance on making new contributions to the repository.

## License

- MinIO source is licensed under the [GNU AGPLv3](https://github.com/minio/minio/blob/master/LICENSE).
- MinIO [documentation](https://github.com/minio/minio/tree/master/docs) is licensed under [CC BY 4.0](https://creativecommons.org/licenses/by/4.0/).
- [License Compliance](https://github.com/minio/minio/blob/master/COMPLIANCE.md)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[seaweedfs/seaweedfs]]></title>
            <link>https://github.com/seaweedfs/seaweedfs</link>
            <guid>https://github.com/seaweedfs/seaweedfs</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:14 GMT</pubDate>
            <description><![CDATA[SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/seaweedfs/seaweedfs">seaweedfs/seaweedfs</a></h1>
            <p>SeaweedFS is a fast distributed storage system for blobs, objects, files, and data lake, for billions of files! Blob store has O(1) disk seek, cloud tiering. Filer supports Cloud Drive, xDC replication, Kubernetes, POSIX FUSE mount, S3 API, S3 Gateway, Hadoop, WebDAV, encryption, Erasure Coding. Enterprise version is at seaweedfs.com.</p>
            <p>Language: Go</p>
            <p>Stars: 30,274</p>
            <p>Forks: 2,703</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre># SeaweedFS


[![Slack](https://img.shields.io/badge/slack-purple)](https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY)
[![Twitter](https://img.shields.io/twitter/follow/seaweedfs.svg?style=social&amp;label=Follow)](https://twitter.com/intent/follow?screen_name=seaweedfs)
[![Build Status](https://img.shields.io/github/actions/workflow/status/seaweedfs/seaweedfs/go.yml)](https://github.com/seaweedfs/seaweedfs/actions/workflows/go.yml)
[![GoDoc](https://godoc.org/github.com/seaweedfs/seaweedfs/weed?status.svg)](https://godoc.org/github.com/seaweedfs/seaweedfs/weed)
[![Wiki](https://img.shields.io/badge/docs-wiki-blue.svg)](https://github.com/seaweedfs/seaweedfs/wiki)
[![Docker Pulls](https://img.shields.io/docker/pulls/chrislusf/seaweedfs?maxAge=4800)](https://hub.docker.com/r/chrislusf/seaweedfs/)
[![SeaweedFS on Maven Central](https://img.shields.io/maven-central/v/com.github.chrislusf/seaweedfs-client)](https://search.maven.org/search?q=g:com.github.chrislusf)
[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/seaweedfs)](https://artifacthub.io/packages/search?repo=seaweedfs)

![SeaweedFS Logo](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/seaweedfs.png)

&lt;h2 align=&quot;center&quot;&gt;&lt;a href=&quot;https://www.patreon.com/seaweedfs&quot;&gt;Sponsor SeaweedFS via Patreon&lt;/a&gt;&lt;/h2&gt;

SeaweedFS is an independent Apache-licensed open source project with its ongoing development made
possible entirely thanks to the support of these awesome [backers](https://github.com/seaweedfs/seaweedfs/blob/master/backers.md).
If you&#039;d like to grow SeaweedFS even stronger, please consider joining our
&lt;a href=&quot;https://www.patreon.com/seaweedfs&quot;&gt;sponsors on Patreon&lt;/a&gt;.

Your support will be really appreciated by me and other supporters!

&lt;!--
&lt;h4 align=&quot;center&quot;&gt;Platinum&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;&quot; target=&quot;_blank&quot;&gt;
    Add your name or icon here
  &lt;/a&gt;
&lt;/p&gt;
--&gt;

### Gold Sponsors
[![nodion](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/sponsor_nodion.png)](https://www.nodion.com)
[![piknik](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/piknik.png)](https://www.piknik.com)
[![keepsec](https://raw.githubusercontent.com/seaweedfs/seaweedfs/master/note/keepsec.png)](https://www.keepsec.ca)

---

- [Download Binaries for different platforms](https://github.com/seaweedfs/seaweedfs/releases/latest)
- [SeaweedFS on Slack](https://join.slack.com/t/seaweedfs/shared_invite/enQtMzI4MTMwMjU2MzA3LTEyYzZmZWYzOGQ3MDJlZWMzYmI0OTE4OTJiZjJjODBmMzUxNmYwODg0YjY3MTNlMjBmZDQ1NzQ5NDJhZWI2ZmY)
- [SeaweedFS on Twitter](https://twitter.com/SeaweedFS)
- [SeaweedFS on Telegram](https://t.me/Seaweedfs) 
- [SeaweedFS on Reddit](https://www.reddit.com/r/SeaweedFS/)
- [SeaweedFS Mailing List](https://groups.google.com/d/forum/seaweedfs)
- [Wiki Documentation](https://github.com/seaweedfs/seaweedfs/wiki)
- [SeaweedFS White Paper](https://github.com/seaweedfs/seaweedfs/wiki/SeaweedFS_Architecture.pdf)
- [SeaweedFS Introduction Slides 2025.5](https://docs.google.com/presentation/d/1tdkp45J01oRV68dIm4yoTXKJDof-EhainlA0LMXexQE/edit?usp=sharing)
- [SeaweedFS Introduction Slides 2021.5](https://docs.google.com/presentation/d/1DcxKWlINc-HNCjhYeERkpGXXm6nTCES8mi2W5G0Z4Ts/edit?usp=sharing)
- [SeaweedFS Introduction Slides 2019.3](https://www.slideshare.net/chrislusf/seaweedfs-introduction)

Table of Contents
=================

* [Quick Start](#quick-start)
    * [Quick Start with weed mini](#quick-start-with-weed-mini)
    * [Quick Start for S3 API on Docker](#quick-start-for-s3-api-on-docker)
    * [Quick Start with Single Binary](#quick-start-with-single-binary)
* [Introduction](#introduction)
* [Features](#features)
    * [Additional Features](#additional-features)
    * [Filer Features](#filer-features)
* [Example: Using Seaweed Object Store](#example-using-seaweed-object-store)
* [Architecture](#object-store-architecture)
* [Compared to Other File Systems](#compared-to-other-file-systems)
    * [Compared to HDFS](#compared-to-hdfs)
    * [Compared to GlusterFS, Ceph](#compared-to-glusterfs-ceph)
    * [Compared to GlusterFS](#compared-to-glusterfs)
    * [Compared to Ceph](#compared-to-ceph)
    * [Compared to Minio](#compared-to-minio)
* [Dev Plan](#dev-plan)
* [Installation Guide](#installation-guide)
* [Disk Related Topics](#disk-related-topics)
* [Benchmark](#benchmark)
* [Enterprise](#enterprise)
* [License](#license)

# Quick Start #


## Quick Start with weed mini ##
The easiest way to get started with SeaweedFS for development and testing:

* Download the latest binary from https://github.com/seaweedfs/seaweedfs/releases and unzip a single binary file `weed` or `weed.exe`.

Example:

```bash
# remove quarantine on macOS
# xattr -d com.apple.quarantine  ./weed

./weed mini -dir=/data
```

This single command starts a complete SeaweedFS setup with:
- **Master UI**: http://localhost:9333
- **Volume Server**: http://localhost:9340
- **Filer UI**: http://localhost:8888
- **S3 Endpoint**: http://localhost:8333
- **WebDAV**: http://localhost:7333
- **Admin UI**: http://localhost:23646

Perfect for development, testing, learning SeaweedFS, and single node deployments!

## Quick Start for S3 API on Docker ##

`docker run -p 8333:8333 chrislusf/seaweedfs server -s3`

## Quick Start with Single Binary ##
* Download the latest binary from https://github.com/seaweedfs/seaweedfs/releases and unzip a single binary file `weed` or `weed.exe`. Or run `go install github.com/seaweedfs/seaweedfs/weed@latest`.
* `export AWS_ACCESS_KEY_ID=admin ; export AWS_SECRET_ACCESS_KEY=key` as the admin credentials to access the object store.
* Run `weed server -dir=/some/data/dir -s3` to start one master, one volume server, one filer, and one S3 gateway. The difference with `weed mini` is that `weed mini` can auto configure based on the single host environment, while `weed server` requires manual configuration and are designed for production use.

Also, to increase capacity, just add more volume servers by running `weed volume -dir=&quot;/some/data/dir2&quot; -master=&quot;&lt;master_host&gt;:9333&quot; -port=8081` locally, or on a different machine, or on thousands of machines. That is it!

# Introduction #

SeaweedFS is a simple and highly scalable distributed file system. There are two objectives:

1. to store billions of files!
2. to serve the files fast!

SeaweedFS started as a blob store to handle small files efficiently. 
Instead of managing all file metadata in a central master, 
the central master only manages volumes on volume servers, 
and these volume servers manage files and their metadata. 
This relieves concurrency pressure from the central master and spreads file metadata into volume servers, 
allowing faster file access (O(1), usually just one disk read operation).

There is only 40 bytes of disk storage overhead for each file&#039;s metadata. 
It is so simple with O(1) disk reads that you are welcome to challenge the performance with your actual use cases.

SeaweedFS started by implementing [Facebook&#039;s Haystack design paper](http://www.usenix.org/event/osdi10/tech/full_papers/Beaver.pdf). 
Also, SeaweedFS implements erasure coding with ideas from 
[f4: Facebook‚Äôs Warm BLOB Storage System](https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-muralidhar.pdf), and has a lot of similarities with [Facebook‚Äôs Tectonic Filesystem](https://www.usenix.org/system/files/fast21-pan.pdf) and [Google&#039;s Colossus File System](https://cloud.google.com/blog/products/storage-data-transfer/a-peek-behind-colossus-googles-file-system)

On top of the blob store, optional [Filer] can support directories and POSIX attributes. 
Filer is a separate linearly-scalable stateless server with customizable metadata stores, 
e.g., MySql, Postgres, Redis, Cassandra, HBase, Mongodb, Elastic Search, LevelDB, RocksDB, Sqlite, MemSql, TiDB, Etcd, CockroachDB, YDB, etc.

SeaweedFS can transparently integrate with the cloud. 
With hot data on local cluster, and warm data on the cloud with O(1) access time, 
SeaweedFS can achieve both fast local access time and elastic cloud storage capacity.
What&#039;s more, the cloud storage access API cost is minimized. 
Faster and cheaper than direct cloud storage!

[Back to TOC](#table-of-contents)

# Features #
## Additional Blob Store Features ##
* Support different replication levels, with rack and data center aware.
* Automatic master servers failover - no single point of failure (SPOF).
* Automatic compression depending on file MIME type.
* Automatic compaction to reclaim disk space after deletion or update.
* [Automatic entry TTL expiration][VolumeServerTTL].
* Flexible Capacity Expansion: Any server with some disk space can add to the total storage space.
* Adding/Removing servers does **not** cause any data re-balancing unless triggered by admin commands.
* Optional picture resizing.
* Support ETag, Accept-Range, Last-Modified, etc.
* Support in-memory/leveldb/readonly mode tuning for memory/performance balance.
* Support rebalancing the writable and readonly volumes.
* [Customizable Multiple Storage Tiers][TieredStorage]: Customizable storage disk types to balance performance and cost.
* [Transparent cloud integration][CloudTier]: unlimited capacity via tiered cloud storage for warm data.
* [Erasure Coding for warm storage][ErasureCoding]  Rack-Aware 10.4 erasure coding reduces storage cost and increases availability. Enterprise version can customize EC ratio.

[Back to TOC](#table-of-contents)

## Filer Features ##
* [Filer server][Filer] provides &quot;normal&quot; directories and files via HTTP.
* [File TTL][FilerTTL] automatically expires file metadata and actual file data.
* [Mount filer][Mount] reads and writes files directly as a local directory via FUSE.
* [Filer Store Replication][FilerStoreReplication] enables HA for filer meta data stores.
* [Active-Active Replication][ActiveActiveAsyncReplication] enables asynchronous one-way or two-way cross cluster continuous replication.
* [Amazon S3 compatible API][AmazonS3API] accesses files with S3 tooling.
* [Hadoop Compatible File System][Hadoop] accesses files from Hadoop/Spark/Flink/etc or even runs HBase.
* [Async Replication To Cloud][BackupToCloud] has extremely fast local access and backups to Amazon S3, Google Cloud Storage, Azure, BackBlaze.
* [WebDAV] accesses as a mapped drive on Mac and Windows, or from mobile devices.
* [AES256-GCM Encrypted Storage][FilerDataEncryption] safely stores the encrypted data.
* [Super Large Files][SuperLargeFiles] stores large or super large files in tens of TB.
* [Cloud Drive][CloudDrive] mounts cloud storage to local cluster, cached for fast read and write with asynchronous write back.
* [Gateway to Remote Object Store][GatewayToRemoteObjectStore] mirrors bucket operations to remote object storage, in addition to [Cloud Drive][CloudDrive]

## Kubernetes ##
* [Kubernetes CSI Driver][SeaweedFsCsiDriver] A Container Storage Interface (CSI) Driver. [![Docker Pulls](https://img.shields.io/docker/pulls/chrislusf/seaweedfs-csi-driver.svg?maxAge=4800)](https://hub.docker.com/r/chrislusf/seaweedfs-csi-driver/)
* [SeaweedFS Operator](https://github.com/seaweedfs/seaweedfs-operator)

[Filer]: https://github.com/seaweedfs/seaweedfs/wiki/Directories-and-Files
[SuperLargeFiles]: https://github.com/seaweedfs/seaweedfs/wiki/Data-Structure-for-Large-Files
[Mount]: https://github.com/seaweedfs/seaweedfs/wiki/FUSE-Mount
[AmazonS3API]: https://github.com/seaweedfs/seaweedfs/wiki/Amazon-S3-API
[BackupToCloud]: https://github.com/seaweedfs/seaweedfs/wiki/Async-Replication-to-Cloud
[Hadoop]: https://github.com/seaweedfs/seaweedfs/wiki/Hadoop-Compatible-File-System
[WebDAV]: https://github.com/seaweedfs/seaweedfs/wiki/WebDAV
[ErasureCoding]: https://github.com/seaweedfs/seaweedfs/wiki/Erasure-coding-for-warm-storage
[TieredStorage]: https://github.com/seaweedfs/seaweedfs/wiki/Tiered-Storage
[CloudTier]: https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Tier
[FilerDataEncryption]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Data-Encryption
[FilerTTL]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Stores
[VolumeServerTTL]: https://github.com/seaweedfs/seaweedfs/wiki/Store-file-with-a-Time-To-Live
[SeaweedFsCsiDriver]: https://github.com/seaweedfs/seaweedfs-csi-driver
[ActiveActiveAsyncReplication]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Active-Active-cross-cluster-continuous-synchronization
[FilerStoreReplication]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-Store-Replication
[KeyLargeValueStore]: https://github.com/seaweedfs/seaweedfs/wiki/Filer-as-a-Key-Large-Value-Store
[CloudDrive]: https://github.com/seaweedfs/seaweedfs/wiki/Cloud-Drive-Architecture
[GatewayToRemoteObjectStore]: https://github.com/seaweedfs/seaweedfs/wiki/Gateway-to-Remote-Object-Storage


[Back to TOC](#table-of-contents)

## Example: Using Seaweed Blob Store ##

By default, the master node runs on port 9333, and the volume nodes run on port 8080.
Let&#039;s start one master node, and two volume nodes on port 8080 and 8081. Ideally, they should be started from different machines. We&#039;ll use localhost as an example.

SeaweedFS uses HTTP REST operations to read, write, and delete. The responses are in JSON or JSONP format.

### Start Master Server ###

```
&gt; ./weed master
```

### Start Volume Servers ###

```
&gt; weed volume -dir=&quot;/tmp/data1&quot; -max=5  -master=&quot;localhost:9333&quot; -port=8080 &amp;
&gt; weed volume -dir=&quot;/tmp/data2&quot; -max=10 -master=&quot;localhost:9333&quot; -port=8081 &amp;
```

### Write A Blob ###

A blob, also referred as a needle, a chunk, or mistakenly as a file, is just a byte array. It can have attributes, such as name, mime type, create or update time, etc. But basically it is just a byte array of a relatively small size, such as 2 MB ~ 64 MB. The size is not fixed.

To upload a blob: first, send a HTTP POST, PUT, or GET request to `/dir/assign` to get an `fid` and a volume server URL:

```
&gt; curl http://localhost:9333/dir/assign
{&quot;count&quot;:1,&quot;fid&quot;:&quot;3,01637037d6&quot;,&quot;url&quot;:&quot;127.0.0.1:8080&quot;,&quot;publicUrl&quot;:&quot;localhost:8080&quot;}
```

Second, to store the blob content, send a HTTP multi-part POST request to `url + &#039;/&#039; + fid` from the response:

```
&gt; curl -F file=@/home/chris/myphoto.jpg http://127.0.0.1:8080/3,01637037d6
{&quot;name&quot;:&quot;myphoto.jpg&quot;,&quot;size&quot;:43234,&quot;eTag&quot;:&quot;1cc0118e&quot;}
```

To update, send another POST request with updated blob content.

For deletion, send an HTTP DELETE request to the same `url + &#039;/&#039; + fid` URL:

```
&gt; curl -X DELETE http://127.0.0.1:8080/3,01637037d6
```

### Save Blob Id ###

Now, you can save the `fid`, 3,01637037d6 in this case, to a database field.

The number 3 at the start represents a volume id. After the comma, it&#039;s one file key, 01, and a file cookie, 637037d6.

The volume id is an unsigned 32-bit integer. The file key is an unsigned 64-bit integer. The file cookie is an unsigned 32-bit integer, used to prevent URL guessing.

The file key and file cookie are both coded in hex. You can store the &lt;volume id, file key, file cookie&gt; tuple in your own format, or simply store the `fid` as a string.

If stored as a string, in theory, you would need 8+1+16+8=33 bytes. A char(33) would be enough, if not more than enough, since most uses will not need 2^32 volumes.

If space is really a concern, you can store the file id in the binary format. You would need one 4-byte integer for volume id, 8-byte long number for file key, and a 4-byte integer for the file cookie. So 16 bytes are more than enough.

### Read a Blob ###

Here is an example of how to render the URL.

First look up the volume server&#039;s URLs by the file&#039;s volumeId:

```
&gt; curl http://localhost:9333/dir/lookup?volumeId=3
{&quot;volumeId&quot;:&quot;3&quot;,&quot;locations&quot;:[{&quot;publicUrl&quot;:&quot;localhost:8080&quot;,&quot;url&quot;:&quot;localhost:8080&quot;}]}
```

Since (usually) there are not too many volume servers, and volumes don&#039;t move often, you can cache the results most of the time. Depending on the replication type, one volume can have multiple replica locations. Just randomly pick one location to read.

Now you can take the public URL, render the URL or directly read from the volume server via URL:

```
 http://localhost:8080/3,01637037d6.jpg
```

Notice we add a file extension &quot;.jpg&quot; here. It&#039;s optional and just one way for the client to specify the file content type.

If you want a nicer URL, you can use one of these alternative URL formats:

```
 http://localhost:8080/3/01637037d6/my_preferred_name.jpg
 http://localhost:8080/3/01637037d6.jpg
 http://localhost:8080/3,01637037d6.jpg
 http://localhost:8080/3/01637037d6
 http://localhost:8080/3,01637037d6
```

If you want to get a scaled version of an image, you can add some params:

```
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200&amp;mode=fit
http://localhost:8080/3/01637037d6.jpg?height=200&amp;width=200&amp;mode=fill
```

### Rack-Aware and Data Center-Aware Replication ###

SeaweedFS applies the replication strategy at a volume level. So, when you are getting a blob id, you can specify the replication strategy. For example:

```
curl http://localhost:9333/dir/assign?replication=001
```

The replication parameter options are:

```
000: no replication
001: replicate once on the same rack
010: replicate once on a different rack, but same data center
100: replicate once on a different data center
200: replicate twice on two different data center
110: replicate once on a different rack, and once on a different data center
```

More details about replication can be found [on the wiki][Replication].

[Replication]: https://github.com/seaweedfs/seaweedfs/wiki/Replication

You can also set the default replication strategy when starting the master server.

### Allocate Blob Key on Specific Data Center ###

Volume servers can be started with a specific data center name:

```
 weed volume -dir=/tmp/1 -port=8080 -dataCenter=dc1
 weed volume -dir=/tmp/2 -port=8081 -dataCenter=dc2
```

When requesting a blob key, an optional &quot;dataCenter&quot; parameter can limit the assigned volume to the specific data center. For example, this specifies that the assigned volume should be limited to &#039;dc1&#039;:

```
 http://localhost:9333/dir/assign?dataCenter=dc1
```

### Other Features ###
  * [No Single Point of Failure][feat-1]
  * [Insert with your own keys][feat-2]
  * [Chunking large files][feat-3]
  * [Collection as a Simple Name Space][feat-4]

[feat-1]: https://github.com/seaweedfs/seaweedfs/wiki/Failover-Master-Server
[feat-2]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#insert-with-your-own-keys
[feat-3]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#upload-large-files
[feat-4]: https://github.com/seaweedfs/seaweedfs/wiki/Optimization#collection-as-a-simple-name-space

[Back to TOC](#table-of-contents)

## Blob Store Architecture ##

Usually distributed file systems split each file into chunks. A central server keeps a mapping of filenames to chunks, and also which chunks each chunk server has.

The main drawback is that the central server can&#039;t handle many small files efficiently, and since all read requests need to go through the central master, so it might not scale well for many concurrent users.

Instead of managing chunks, SeaweedFS manages data volumes in the master server. Each data volume is 32GB in size, and can hold a lot of blobs. And each storage node can have many data volumes. So the master node only needs to store the metadata about the volumes, which is a fairly small amount of data and is generally stable.

The actual blob metadata, which are the blob volume, offset, and size, is stored in each volume on volume servers. Since each volume server only manages metadata of blobs on its own disk, with only 16 bytes for each blob, all access can read the metadata just from memory and only needs one disk operation to actually read file data.

For comparison, consider that an xfs inode structure in Linux is 536 bytes.



... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hatchet-dev/hatchet]]></title>
            <link>https://github.com/hatchet-dev/hatchet</link>
            <guid>https://github.com/hatchet-dev/hatchet</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:13 GMT</pubDate>
            <description><![CDATA[ü™ì Run Background Tasks at Scale]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hatchet-dev/hatchet">hatchet-dev/hatchet</a></h1>
            <p>ü™ì Run Background Tasks at Scale</p>
            <p>Language: Go</p>
            <p>Stars: 6,584</p>
            <p>Forks: 304</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href =&quot;https://hatchet.run?utm_source=github&amp;utm_campaign=readme&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/hatchet_logo_dark.svg&quot;&gt;
  &lt;img width=&quot;200&quot; alt=&quot;Hatchet Logo&quot; src=&quot;./assets/hatchet_logo_light.svg&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;

### Run Background Tasks at Scale

[![Docs](https://img.shields.io/badge/docs-docs.hatchet.run-3F16E4)](https://docs.hatchet.run) [![License: MIT](https://img.shields.io/badge/License-MIT-purple.svg)](https://opensource.org/licenses/MIT) [![Go Reference](https://pkg.go.dev/badge/github.com/hatchet-dev/hatchet.svg)](https://pkg.go.dev/github.com/hatchet-dev/hatchet) [![NPM Downloads](https://img.shields.io/npm/dm/%40hatchet-dev%2Ftypescript-sdk)](https://www.npmjs.com/package/@hatchet-dev/typescript-sdk)

[![Discord](https://img.shields.io/discord/1088927970518909068?style=social&amp;logo=discord)](https://hatchet.run/discord)
[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/hatchet-dev.svg?style=social&amp;label=Follow%20%40hatchet-dev)](https://twitter.com/hatchet_dev)
[![GitHub Repo stars](https://img.shields.io/github/stars/hatchet-dev/hatchet?style=social)](https://github.com/hatchet-dev/hatchet)

  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://cloud.onhatchet.run&quot;&gt;Hatchet Cloud&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://docs.hatchet.run&quot;&gt;Documentation&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://hatchet.run&quot;&gt;Website&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/hatchet-dev/hatchet/issues&quot;&gt;Issues&lt;/a&gt;
  &lt;/p&gt;

&lt;/div&gt;

### What is Hatchet?

Hatchet is a platform for running background tasks and durable workflows, built on top of Postgres. It bundles a durable task queue, observability, alerting, a dashboard, and a CLI into a single platform.

### Get started quickly

The fastest way to get started with a running Hatchet instance is to install the Hatchet CLI (on MacOS, Linux or WSL) - note that this requires [Docker](https://www.docker.com/get-started) installed locally to work:

```sh
curl -fsSL https://install.hatchet.run/install.sh | bash
hatchet --version
hatchet server start
```

You can also sign up on [Hatchet Cloud](https://cloud.onhatchet.run) to try it out! We recommend this even if you plan on self-hosting, so you can have a look at what a fully-deployed Hatchet platform looks like.

To view full documentation for self-hosting and using cloud, have a look at the [docs](https://docs.hatchet.run).

### When should I use Hatchet?

Background tasks are critical for offloading work from your main web application. Usually background tasks are sent through a FIFO (first-in-first-out) queue, which helps guard against traffic spikes (queues can absorb a lot of load) and ensures that tasks are retried when your task handlers error out. Most stacks begin with a library-based queue backed by Redis or RabbitMQ (like Celery or BullMQ). But as your tasks become more complex, these queues become difficult to debug, monitor and start to fail in unexpected ways.

This is where Hatchet comes in. Hatchet is a full-featured background task management platform, with built-in support for chaining complex tasks together into workflows, alerting on failures, making tasks more durable, and viewing tasks in a real-time web dashboard.

### Features

&lt;details open&gt;&lt;summary&gt;&lt;strong&gt;üì• Queues&lt;/strong&gt;&lt;/summary&gt;

####

Hatchet is built on a durable task queue that enqueues your tasks and sends them to your workers at a rate that your workers can handle. Hatchet will track the progress of your task and ensure that the work gets completed (or you get alerted), even if your application crashes.

**This is particularly useful for:**

- Ensuring that you never drop a user request
- Flattening large spikes in your application
- Breaking large, complex logic into smaller, reusable tasks

[Read more ‚û∂](https://docs.hatchet.run/home/your-first-task)

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Python&lt;/code&gt;&lt;/summary&gt;

  ```python
  # 1. Define your task input
  class SimpleInput(BaseModel):
      message: str

  # 2. Define your task using hatchet.task
  @hatchet.task(name=&quot;SimpleWorkflow&quot;, input_validator=SimpleInput)
  def simple(input: SimpleInput, ctx: Context) -&gt; dict[str, str]:
      return {
        &quot;transformed_message&quot;: input.message.lower(),
      }

  # 3. Register your task on your worker
  worker = hatchet.worker(&quot;test-worker&quot;, workflows=[simple])
  worker.start()

  # 4. Invoke tasks from your application
  simple.run(SimpleInput(message=&quot;Hello World!&quot;))
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Typescript&lt;/code&gt;&lt;/summary&gt;

  ```ts
  // 1. Define your task input
  export type SimpleInput = {
    Message: string;
  };

  // 2. Define your task using hatchet.task
  export const simple = hatchet.task({
    name: &quot;simple&quot;,
    fn: (input: SimpleInput) =&gt; {
      return {
        TransformedMessage: input.Message.toLowerCase(),
      };
    },
  });

  // 3. Register your task on your worker
  const worker = await hatchet.worker(&quot;simple-worker&quot;, {
    workflows: [simple],
  });

  await worker.start();

  // 4. Invoke tasks from your application
  await simple.run({
    Message: &quot;Hello World!&quot;,
  });
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Go&lt;/code&gt;&lt;/summary&gt;

  ```go
  // 1. Define your task input
  type SimpleInput struct {
    Message string `json:&quot;message&quot;`
  }

  // 2. Define your task using factory.NewTask
  simple := factory.NewTask(
    create.StandaloneTask{
      Name: &quot;simple-task&quot;,
    }, func(ctx worker.HatchetContext, input SimpleInput) (*SimpleResult, error) {
      return &amp;SimpleResult{
        TransformedMessage: strings.ToLower(input.Message),
      }, nil
    },
    hatchet,
  )

  // 3. Register your task on your worker
  worker, err := hatchet.Worker(v1worker.WorkerOpts{
    Name: &quot;simple-worker&quot;,
    Workflows: []workflow.WorkflowBase{
      simple,
    },
  })

  worker.StartBlocking()

  // 4. Invoke tasks from your application
  simple.Run(context.Background(), SimpleInput{Message: &quot;Hello, World!&quot;})
  ```

  &lt;/details&gt;

&lt;/details&gt;
&lt;details&gt;&lt;summary&gt;&lt;strong&gt;üéª Task Orchestration&lt;/strong&gt;&lt;/summary&gt;

####

Hatchet allows you to build complex workflows that can be composed of multiple tasks. For example, if you&#039;d like to break a workload into smaller tasks, you can use Hatchet to create a fanout workflow that spawns multiple tasks in parallel.

Hatchet supports the following mechanisms for task orchestration:

- **DAGs (directed acyclic graphs)** ‚Äî pre-define the shape of your work, automatically routing the outputs of a parent task to the input of a child task. [Read more ‚û∂](https://docs.hatchet.run/home/dags)

- **Durable tasks** ‚Äî these tasks are responsible for orchestrating other tasks. They store a full history of all spawned tasks, allowing you to cache intermediate results. [Read more ‚û∂](https://docs.hatchet.run/home/durable-execution)

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Python&lt;/code&gt;&lt;/summary&gt;

  ```python
  # 1. Define a workflow (a workflow is a collection of tasks)
  simple = hatchet.workflow(name=&quot;SimpleWorkflow&quot;)

  # 2. Attach the first task to the workflow
  @simple.task()
  def task_1(input: EmptyModel, ctx: Context) -&gt; dict[str, str]:
      print(&quot;executed task_1&quot;)
      return {&quot;result&quot;: &quot;task_1&quot;}

  # 3. Attach the second task to the workflow, which executes after task_1
  @simple.task(parents=[task_1])
  def task_2(input: EmptyModel, ctx: Context) -&gt; None:
      first_result = ctx.task_output(task_1)
      print(first_result)

  # 4. Invoke workflows from your application
  result = simple.run(input_data)
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Typescript&lt;/code&gt;&lt;/summary&gt;

  ```ts
  // 1. Define a workflow (a workflow is a collection of tasks)
  const simple = hatchet.workflow&lt;DagInput, DagOutput&gt;({
    name: &quot;simple&quot;,
  });

  // 2. Attach the first task to the workflow
  const task1 = simple.task({
    name: &quot;task-1&quot;,
    fn: (input) =&gt; {
      return {
        result: &quot;task-1&quot;,
      };
    },
  });

  // 3. Attach the second task to the workflow, which executes after task-1
  const task2 = simple.task({
    name: &quot;task-2&quot;,
    parents: [task1],
    fn: (input, ctx) =&gt; {
      const firstResult = ctx.getParentOutput(task1);
      console.log(firstResult);
    },
  });

  // 4. Invoke workflows from your application
  await simple.run({ Message: &quot;Hello World&quot; });
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Go&lt;/code&gt;&lt;/summary&gt;

  ```go
  // 1. Define a workflow (a workflow is a collection of tasks)
  simple := v1.WorkflowFactory[DagInput, DagOutput](
      workflow.CreateOpts[DagInput]{
          Name: &quot;simple-workflow&quot;,
      },
      hatchet,
  )

  // 2. Attach the first task to the workflow
  const task1 = simple.Task(
      task.CreateOpts[DagInput]{
          Name: &quot;task-1&quot;,
          Fn: func(ctx worker.HatchetContext, _ DagInput) (*SimpleOutput, error) {
              return &amp;SimpleOutput{
                  Result: &quot;task-1&quot;,
              }, nil
          },
      },
  );

  // 3. Attach the second task to the workflow, which executes after task-1
  const task2 = simple.Task(
      task.CreateOpts[DagInput]{
          Name: &quot;task-2&quot;,
          Parents: []task.NamedTask{
              step1,
          },
          Fn: func(ctx worker.HatchetContext, _ DagInput) (*SimpleOutput, error) {
              return &amp;SimpleOutput{
                  Result: &quot;task-2&quot;,
              }, nil
          },
      },
  );

  // 4. Invoke workflows from your application
  simple.Run(ctx, DagInput{})
  ```

  &lt;/details&gt;

&lt;/details&gt;
&lt;details&gt;&lt;summary&gt;&lt;strong&gt;üö¶ Flow Control&lt;/strong&gt;&lt;/summary&gt;

####

Don&#039;t let busy users crash your application. With Hatchet, you can throttle execution on a per-user, per-tenant and per-queue basis, increasing system stability and limiting the impact of busy users on the rest of your system.

Hatchet supports the following flow control primitives:

- **Concurrency** ‚Äî set a concurrency limit based on a dynamic concurrency key (e.g., each user can only run 10 batch jobs at a given time). [Read more ‚û∂](https://docs.hatchet.run/home/concurrency)

- **Rate limiting** ‚Äî create both global and dynamic rate limits. [Read more ‚û∂](https://docs.hatchet.run/home/rate-limits)

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Python&lt;/code&gt;&lt;/summary&gt;

  ```python
  # limit concurrency on a per-user basis
  flow_control_workflow = hatchet.workflow(
    name=&quot;FlowControlWorkflow&quot;,
    concurrency=ConcurrencyExpression(
      expression=&quot;input.user_id&quot;,
      max_runs=5,
      limit_strategy=ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,
    ),
    input_validator=FlowControlInput,
  )

  # rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit
  @flow_control_workflow.task(
      rate_limits=[
          RateLimit(
              dynamic_key=&quot;input.user_id&quot;,
              units=1,
              limit=10,
              duration=RateLimitDuration.MINUTE,
          )
      ]
  )
  def rate_limit_task(input: FlowControlInput, ctx: Context) -&gt; None:
      print(&quot;executed rate_limit_task&quot;)
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Typescript&lt;/code&gt;&lt;/summary&gt;

  ```ts
  // limit concurrency on a per-user basis
  flowControlWorkflow = hatchet.workflow&lt;SimpleInput, SimpleOutput&gt;({
    name: &quot;ConcurrencyLimitWorkflow&quot;,
    concurrency: {
      expression: &quot;input.userId&quot;,
      maxRuns: 5,
      limitStrategy: ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,
    },
  });

  // rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit
  flowControlWorkflow.task({
    name: &quot;rate-limit-task&quot;,
    rateLimits: [
      {
        dynamicKey: &quot;input.userId&quot;,
        units: 1,
        limit: 10,
        duration: RateLimitDuration.MINUTE,
      },
    ],
    fn: async (input) =&gt; {
      return {
        Completed: true,
      };
    },
  });
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Go&lt;/code&gt;&lt;/summary&gt;

  ```go
  // limit concurrency on a per-user basis
  flowControlWorkflow := factory.NewWorkflow[DagInput, DagResult](
    create.WorkflowCreateOpts[DagInput]{
      Name: &quot;simple-dag&quot;,
      Concurrency: []*types.Concurrency{
        {
          Expression:    &quot;input.userId&quot;,
          MaxRuns:       1,
          LimitStrategy: types.GroupRoundRobin,
        },
      },
    },
    hatchet,
  )

  // rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit
  flowControlWorkflow.Task(
    create.WorkflowTask[FlowControlInput, FlowControlOutput]{
      Name: &quot;rate-limit-task&quot;,
      RateLimits: []*types.RateLimit{
        {
          Key:            &quot;user-rate-limit&quot;,
          KeyExpr:        &quot;input.userId&quot;,
          Units:          1,
          LimitValueExpr: 10,
          Duration:       types.Minute,
        },
      },
    }, func(ctx worker.HatchetContext, input FlowControlInput) (interface{}, error) {
      return &amp;SimpleOutput{
        Step: 1,
      }, nil
    },
  )
  ```

  &lt;/details&gt;

&lt;/details&gt;
&lt;details&gt;&lt;summary&gt;&lt;strong&gt;üìÖ Scheduling&lt;/strong&gt;&lt;/summary&gt;

####

Hatchet has full support for scheduling features, including cron, one-time scheduling, and pausing execution for a time duration. This is particularly useful for:

- **Cron schedules** ‚Äì run data pipelines, batch processes, or notification systems on a cron schedule [Read more ‚û∂](https://docs.hatchet.run/home/cron-runs)
- **One-time tasks** ‚Äì schedule a workflow for a specific time in the future [Read more ‚û∂](https://docs.hatchet.run/home/scheduled-runs)
- **Durable sleep** ‚Äì pause execution of a task for a specific duration [Read more ‚û∂](https://docs.hatchet.run/home/durable-execution)

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Python&lt;/code&gt;&lt;/summary&gt;

  ```python
  tomorrow = datetime.today() + timedelta(days=1)

  # schedule a task to run tomorrow
  scheduled = simple.schedule(
    tomorrow,
    SimpleInput(message=&quot;Hello, World!&quot;)
  )

  # schedule a task to run every day at midnight
  cron = simple.cron(
    &quot;every-day&quot;,
    &quot;0 0 * * *&quot;,
    SimpleInput(message=&quot;Hello, World!&quot;)
  )
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Typescript&lt;/code&gt;&lt;/summary&gt;

  ```ts
  const tomorrow = new Date(Date.now() + 1000 * 60 * 60 * 24);
  // schedule a task to run tomorrow
  const scheduled = simple.schedule(tomorrow, {
    Message: &quot;Hello, World!&quot;,
  });

  // schedule a task to run every day at midnight
  const cron = simple.cron(&quot;every-day&quot;, &quot;0 0 * * *&quot;, {
    Message: &quot;Hello, World!&quot;,
  });
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Go&lt;/code&gt;&lt;/summary&gt;

  ```go
  const tomorrow = time.Now().Add(24 * time.Hour);

  // schedule a task to run tomorrow
  simple.Schedule(ctx, tomorrow, ScheduleInput{
    Message: &quot;Hello, World!&quot;,
  })

  // schedule a task to run every day at midnight
  simple.Cron(ctx, &quot;every-day&quot;, &quot;0 0 * * *&quot;, CronInput{
    Message: &quot;Hello, World!&quot;,
  })
  ```

  &lt;/details&gt;

&lt;/details&gt;
&lt;details&gt;&lt;summary&gt;&lt;strong&gt;üöè Task routing&lt;/strong&gt;&lt;/summary&gt;

####

While the default Hatchet behavior is to implement a FIFO queue, it also supports additional scheduling mechanisms to route your tasks to the ideal worker.

- **Sticky assignment** ‚Äî allows spawned tasks to prefer or require execution on the same worker. [Read more ‚û∂](https://docs.hatchet.run/home/sticky-assignment)

- **Worker affinity** ‚Äî ranks workers to discover which is best suited to handle a given task. [Read more ‚û∂](https://docs.hatchet.run/home/worker-affinity)

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Python&lt;/code&gt;&lt;/summary&gt;

  ```python
  # create a workflow which prefers to run on the same worker, but can be
  # scheduled on any worker if the original worker is busy
  hatchet.workflow(
    name=&quot;StickyWorkflow&quot;,
    sticky=StickyStrategy.SOFT,
  )

  # create a workflow which must run on the same worker
  hatchet.workflow(
    name=&quot;StickyWorkflow&quot;,
    sticky=StickyStrategy.HARD,
  )
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Typescript&lt;/code&gt;&lt;/summary&gt;

  ```ts
  // create a workflow which prefers to run on the same worker, but can be
  // scheduled on any worker if the original worker is busy
  hatchet.workflow({
    name: &quot;StickyWorkflow&quot;,
    sticky: StickyStrategy.SOFT,
  });

  // create a workflow which must run on the same worker
  hatchet.workflow({
    name: &quot;StickyWorkflow&quot;,
    sticky: StickyStrategy.HARD,
  });
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Go&lt;/code&gt;&lt;/summary&gt;

  ```go
  // create a workflow which prefers to run on the same worker, but can be
  // scheduled on any worker if the original worker is busy
  factory.NewWorkflow[StickyInput, StickyOutput](
    create.WorkflowCreateOpts[StickyInput]{
      Name: &quot;sticky-dag&quot;,
      StickyStrategy: types.StickyStrategy_SOFT,
    },
    hatchet,
  );

  // create a workflow which must run on the same worker
  factory.NewWorkflow[StickyInput, StickyOutput](
    create.WorkflowCreateOpts[StickyInput]{
      Name: &quot;sticky-dag&quot;,
      StickyStrategy: types.StickyStrategy_HARD,
    },
    hatchet,
  );
  ```

  &lt;/details&gt;

&lt;/details&gt;
&lt;details&gt;&lt;summary&gt;&lt;strong&gt;‚ö°Ô∏è Event triggers and listeners&lt;/strong&gt;&lt;/summary&gt;

####

Hatchet supports event-based architectures where tasks and workflows can pause execution while waiting for a specific external event. It supports the following features:

- **Event listening** ‚Äî tasks can be paused until a specific event is triggered. [Read more ‚û∂](https://docs.hatchet.run/home/durable-execution)
- **Event triggering** ‚Äî events can trigger new workflows or steps in a workflow. [Read more ‚û∂](https://docs.hatchet.run/home/run-on-event)

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Python&lt;/code&gt;&lt;/summary&gt;

  ```python
  # Create a task which waits for an external user event or sleeps for 10 seconds
  @dag_with_conditions.task(
    parents=[first_task],
    wait_for=[
      or_(
        SleepCondition(timedelta(seconds=10)),
        UserEventCondition(event_key=&quot;user:event&quot;),
      )
    ]
  )
  def second_task(input: EmptyModel, ctx: Context) -&gt; dict[str, str]:
      return {&quot;completed&quot;: &quot;true&quot;}
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Typescript&lt;/code&gt;&lt;/summary&gt;

  ```ts
  // Create a task which waits for an external user event or sleeps for 10 seconds
  dagWithConditions.task({
    name: &quot;secondTask&quot;,
    parents: [firstTask],
    waitFor: Or({ eventKey: &quot;user:event&quot; }, { sleepFor: &quot;10s&quot; }),
    fn: async (_, ctx) =&gt; {
      return {
        Completed: true,
      };
    },
  });
  ```

  &lt;/details&gt;

- &lt;details&gt;

    &lt;summary&gt;&lt;code&gt;Go&lt;/code&gt;&lt;/summary&gt;

  ```go
  // Create a task which waits for an external user event or sleeps for 10 seconds
  simple.Task(
    conditionOpts{
      Name: &quot;Step2&quot;,
      Parents: []create.NamedTask{
        step1,
      },
      WaitFor: condition.Conditions(
        condition.UserEventCondition(&quot;user:event&quot;, &quot;&#039;true&#039;&quot;),
        condition.SleepCondition(10 * time.Second),
      ),
    }, func(ctx worker.HatchetContext, input DagWithConditionsInput) (interface{}, error) {
      // ...
    },
  );
  ```

  &lt;/details&gt;

&lt;/details&gt;
&lt;details&gt;&lt;summary&gt;&lt;strong&gt;üñ•Ô∏è Real-time Web UI&lt;/strong&gt;&lt;/summary&gt;

####

Hatchet comes bundled with a number of features to help you monitor your tasks, workflows, and queues.

**Real-time dashboards and metrics**

Monitor your tasks, workflows, and queues with live updates to quickly detect issues. Alerting is built in so you can respond to problems as soon as they occur.

https://github.com/user-attachments/assets/b1797540-c9da-4057-b50f-4780f52a2cb9

**Logging**

Hatchet supports logging from your tasks, allowing you to easily correlate task failures with logs in your system. No more digging through your logging service to figure out why your tasks failed.

https://github.com/user-attachments/assets/427c15cd-8842-4b54-ab2e-3b1cabc01c7b

**Alerting**

Hatchet supports Slack and email-based alerting for when your tasks fail. Alerts are real-time with adjustable alerting windows.

&lt;/details&gt;

### Documentation

The most up-to-date documentation can be found at https://docs.hatchet.run.

### Community &amp; Support

- [Discord](https://discord.gg/ZMeUafwH89) - best

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[fleetdm/fleet]]></title>
            <link>https://github.com/fleetdm/fleet</link>
            <guid>https://github.com/fleetdm/fleet</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:12 GMT</pubDate>
            <description><![CDATA[Open device management]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fleetdm/fleet">fleetdm/fleet</a></h1>
            <p>Open device management</p>
            <p>Language: Go</p>
            <p>Stars: 6,041</p>
            <p>Forks: 781</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;&lt;a href=&quot;https://fleetdm.com&quot;&gt;&lt;img width=&quot;200&quot; alt=&quot;Fleet logo, landscape, dark text, transparent background&quot; src=&quot;https://github.com/user-attachments/assets/5b52c536-f33e-4159-b2a3-d48f31868cd2&quot;&gt;&lt;/a&gt;&lt;/h1&gt;


#### [News](https://fleetdm.com/announcements) &amp;nbsp; ¬∑ &amp;nbsp; [Report a bug](https://github.com/fleetdm/fleet/issues/new) &amp;nbsp; ¬∑ &amp;nbsp; [Handbook](https://fleetdm.com/handbook/company) &amp;nbsp; ¬∑ &amp;nbsp; [Why open source?](https://fleetdm.com/handbook/company/why-this-way#why-open-source) &amp;nbsp; ¬∑ &amp;nbsp; [Art](https://fleetdm.com/logos)


Open-source platform for IT and security teams with thousands of computers.  Designed for APIs, GitOps, webhooks, YAML, and humans.

&lt;a href=&quot;https://fleetdm.com/logos&quot;&gt;&lt;img src=&quot;https://github.com/fleetdm/fleet/assets/618009/f835ec29-1cb9-49ba-a0f3-395ffd9d5c9f&quot; alt=&quot;A glass city in the clouds&quot;/&gt;&lt;/a&gt;


## What&#039;s it for?
Organizations like Fastly and Gusto use Fleet for vulnerability reporting, detection engineering, device management (MDM), device health monitoring, posture-based access control, managing unused software licenses, and more.

#### Explore data
To see what kind of data you can use Fleet to gather, check out the [table reference documentation](https://fleetdm.com/tables).

#### Out-of-the-box policies
Fleet includes out-of-the box support for all [CIS benchmarks for macOS and Windows](https://fleetdm.com/docs/using-fleet/cis-benchmarks), as well as many [simpler queries](https://fleetdm.com/queries).

Take as much or as little as you need for your organization.

#### Supported platforms
Here are the platforms Fleet currently supports:

- Linux (all distros)
- macOS
- Windows
- Chromebooks
- Amazon Web Services (AWS)
- Google Cloud (GCP)
- Azure (Microsoft cloud)
- Data centers
- Containers (kube, etc)
- Linux-based IoT devices

## Lighter than air
Fleet is lightweight and modular.  You can use it for security without using it for MDM, and vice versa.  You can turn off features you are not using.

#### Openness
Fleet is dedicated to flexibility, accessibility, and clarity.  We think [everyone can contribute](https://fleetdm.com/handbook/company#openness) and that tools should be as easy as possible for everyone to understand.

#### Good neighbors
Fleet has no ambition to replace all of your other tools.  (Though it might replace some, if you want it to.)  Ready-to-use, enterprise-friendly integrations exist for Snowflake, Splunk, GitHub Actions, Vanta, Elastic Jira, Zendesk, and more.

Fleet plays well with Munki, Chef, Puppet, and Ansible, as well as with security tools like Crowdstrike and SentinelOne.  For example, you can use the free version of Fleet to quickly report on what hosts are _actually_ running your EDR agent.

#### Free as in free
The free version of Fleet will [always be free](https://fleetdm.com/pricing).  Fleet is [independently backed](https://linkedin.com/company/fleetdm) and actively maintained with the help of many amazing [contributors](https://github.com/fleetdm/fleet/graphs/contributors).

#### Longevity
The [company behind Fleet](https://fleetdm.com/handbook/company) is founded (and majority-owned) by [true believers in open source](https://fleetdm.com/handbook/company/why-this-way#why-open-source).  The company&#039;s business model is influenced by GitLab (NYSE: GTLB), with great investors, happy customers, and the capacity to become profitable at any time.

In keeping with Fleet&#039;s value of openness, [Fleet Device Management&#039;s company handbook](https://fleetdm.com/handbook/company) is public and open source.  You can read about the [history of Fleet and osquery](https://fleetdm.com/handbook/company#history) and our commitment to improving the product.

&lt;!-- &gt; To upgrade from Fleet ‚â§3.2.0, just follow the upgrading steps for the earliest subsequent major release from this repository (it&#039;ll work out of the box until the release of Fleet 5.0). --&gt;


## Is it any good?
Fleet is used in production by IT and security teams with thousands of laptops and servers.  Many deployments support tens of thousands of hosts, and a few large organizations manage deployments as large as 400,000+ hosts.



## Chat
Please join us in [MacAdmins Slack](https://www.macadmins.org/) or in [osquery Slack](https://fleetdm.com/slack).

The Fleet community is full of [kind and helpful people](https://fleetdm.com/handbook/company#empathy).  Whether or not you are a paying customer, if you need help, just ask.


## Contributing &amp;nbsp; [![Go Report Card](https://goreportcard.com/badge/github.com/fleetdm/fleet)](https://goreportcard.com/report/github.com/fleetdm/fleet) &amp;nbsp; [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5537/badge)](https://bestpractices.coreinfrastructure.org/projects/5537) &amp;nbsp; [![Twitter Follow](https://img.shields.io/twitter/follow/fleetctl.svg?style=social&amp;maxAge=3600)](https://twitter.com/fleetctl) &amp;nbsp; 

The landscape of cybersecurity and IT is too complex.  Let&#039;s open it up.

Contributions are welcome, whether you answer questions on [Slack](https://fleetdm.com/slack) / [GitHub](https://github.com/fleetdm/fleet/issues) / [StackOverflow](https://stackoverflow.com/search?q=osquery) / [LinkedIn](https://linkedin.com/company/fleetdm) / [Twitter](https://twitter.com/fleetctl), improve the documentation or [website](./website), write a tutorial, give a talk at a conference or local meetup, give an [interview on a podcast](https://fleetdm.com/podcasts), troubleshoot reported issues, or [submit a patch](https://fleetdm.com/docs/contributing/contributing).  The Fleet code of conduct is [on GitHub](https://github.com/fleetdm/fleet/blob/main/CODE_OF_CONDUCT.md).

&lt;!-- - Great contributions are motivated by real-world use cases or learning.
- Some of the most valuable contributions might not touch any code at all.
- Small, iterative, simple (boring) changes are the easiest to merge. --&gt;

## What&#039;s next?
To see what Fleet can do, head over to [fleetdm.com](https://fleetdm.com) and try it out for yourself, grab time with one of the maintainers to discuss, or visit the docs and roll it out to your organization.

#### Production deployment
Fleet is simple enough to [spin up for yourself](https://fleetdm.com/docs/get-started/tutorials-and-guides).  Or you can have us [host it for you](https://fleetdm.com/pricing).  Premium features are [available](https://fleetdm.com/pricing) either way.

#### Documentation
Complete documentation for Fleet can be found at [https://fleetdm.com/docs](https://fleetdm.com/docs).


## License
The free version of Fleet is available under the MIT license.  The commercial license is also designed to allow contributions to paid features for users whose employment agreements allow them to contribute to open source projects.  (See LICENSE.md for details.)

&gt; Fleet is built on [osquery](https://github.com/osquery/osquery), [nanoMDM](https://github.com/micromdm/nanomdm), [Nudge](https://github.com/macadmins/nudge), and [swiftDialog](https://github.com/swiftDialog/swiftDialog).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[netbirdio/netbird]]></title>
            <link>https://github.com/netbirdio/netbird</link>
            <guid>https://github.com/netbirdio/netbird</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:11 GMT</pubDate>
            <description><![CDATA[Connect your devices into a secure WireGuard¬Æ-based overlay network with SSO, MFA and granular access controls.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/netbirdio/netbird">netbirdio/netbird</a></h1>
            <p>Connect your devices into a secure WireGuard¬Æ-based overlay network with SSO, MFA and granular access controls.</p>
            <p>Language: Go</p>
            <p>Stars: 22,501</p>
            <p>Forks: 1,101</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre>
&lt;div align=&quot;center&quot;&gt;
&lt;br/&gt;
  &lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;234&quot; src=&quot;docs/media/logo-full.png&quot;/&gt;
&lt;/p&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://img.shields.io/badge/license-BSD--3-blue)&quot;&gt;
       &lt;img src=&quot;https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;metric=alert_status&quot; /&gt;
     &lt;/a&gt; 
     &lt;a href=&quot;https://github.com/netbirdio/netbird/blob/main/LICENSE&quot;&gt;
       &lt;img src=&quot;https://img.shields.io/badge/license-BSD--3-blue&quot; /&gt;
     &lt;/a&gt; 
    &lt;br&gt;
    &lt;a href=&quot;https://docs.netbird.io/slack-url&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack&quot;/&gt;
     &lt;/a&gt;
    &lt;a href=&quot;https://forum.netbird.io&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/community forum-@netbird-red.svg?logo=discourse&quot;/&gt;
     &lt;/a&gt;  
     &lt;br&gt;
    &lt;a href=&quot;https://gurubase.io/g/netbird&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF&quot;/&gt;
     &lt;/a&gt;    
  &lt;/p&gt;
&lt;/div&gt;


&lt;p align=&quot;center&quot;&gt;
&lt;strong&gt;
  Start using NetBird at &lt;a href=&quot;https://netbird.io/pricing&quot;&gt;netbird.io&lt;/a&gt;
  &lt;br/&gt;
  See &lt;a href=&quot;https://netbird.io/docs/&quot;&gt;Documentation&lt;/a&gt;
  &lt;br/&gt;
   Join our &lt;a href=&quot;https://docs.netbird.io/slack-url&quot;&gt;Slack channel&lt;/a&gt; or our &lt;a href=&quot;https://forum.netbird.io&quot;&gt;Community forum&lt;/a&gt;
  &lt;br/&gt;
 
&lt;/strong&gt;
&lt;br&gt;
&lt;strong&gt;
  üöÄ &lt;a href=&quot;https://careers.netbird.io&quot;&gt;We are hiring! Join us at careers.netbird.io&lt;/a&gt;
&lt;/strong&gt;
&lt;br&gt;
&lt;br&gt;
&lt;a href=&quot;https://registry.terraform.io/providers/netbirdio/netbird/latest&quot;&gt;
    New: NetBird terraform provider
  &lt;/a&gt; 
&lt;/p&gt;

&lt;br&gt;

**NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.**

**Connect.** NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.

**Secure.** NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.

### Open Source Network Security in a Single Platform

https://github.com/user-attachments/assets/10cec749-bb56-4ab3-97af-4e38850108d2

### Self-Host NetBird (Video)
[![Watch the video](https://img.youtube.com/vi/bZAgpT6nzaQ/0.jpg)](https://youtu.be/bZAgpT6nzaQ)

### Key features

| Connectivity | Management | Security | Automation| Platforms |
|----|----|----|----|----|
| &lt;ul&gt;&lt;li&gt;- \[x] Kernel WireGuard&lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Admin Web UI](https://github.com/netbirdio/dashboard)&lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [SSO &amp; MFA support](https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login)&lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Public API](https://docs.netbird.io/api)&lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Linux&lt;/ul&gt;&lt;/li&gt; |
| &lt;ul&gt;&lt;li&gt;- \[x] Peer-to-peer connections&lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Auto peer discovery and configuration&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Access control - groups &amp; rules](https://docs.netbird.io/how-to/manage-network-access)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Setup keys for bulk network provisioning](https://docs.netbird.io/how-to/register-machines-using-setup-keys)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Mac&lt;/ui&gt;&lt;/li&gt; |
| &lt;ul&gt;&lt;li&gt;- \[x] Connection relay fallback&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [IdP integrations](https://docs.netbird.io/selfhosted/identity-providers)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Activity logging](https://docs.netbird.io/how-to/audit-events-logging)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Self-hosting quickstart script](https://docs.netbird.io/selfhosted/selfhosted-quickstart)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Windows&lt;/ui&gt;&lt;/li&gt; |
| &lt;ul&gt;&lt;li&gt;- \[x] [Routes to external networks](https://docs.netbird.io/how-to/routing-traffic-to-private-networks)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Private DNS](https://docs.netbird.io/how-to/manage-dns-in-your-network)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Device posture checks](https://docs.netbird.io/how-to/manage-posture-checks)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] IdP groups sync with JWT&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Android&lt;/ui&gt;&lt;/li&gt; |
| &lt;ul&gt;&lt;li&gt;- \[x] NAT traversal with BPF&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] [Multiuser support](https://docs.netbird.io/how-to/add-users-to-your-network)&lt;/ui&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt;- \[x] Peer-to-peer encryption&lt;/ui&gt;&lt;/li&gt; || &lt;ul&gt;&lt;li&gt;- \[x] iOS&lt;/ui&gt;&lt;/li&gt; |
||| &lt;ul&gt;&lt;li&gt;- \[x] [Quantum-resistance with Rosenpass](https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn)&lt;/ui&gt;&lt;/li&gt; || &lt;ul&gt;&lt;li&gt;- \[x] OpenWRT&lt;/ui&gt;&lt;/li&gt; |
||| &lt;ul&gt;&lt;li&gt;- \[x] [Periodic re-authentication](https://docs.netbird.io/how-to/enforce-periodic-user-authentication)&lt;/ui&gt;&lt;/li&gt; || &lt;ul&gt;&lt;li&gt;- \[x] [Serverless](https://docs.netbird.io/how-to/netbird-on-faas)&lt;/ui&gt;&lt;/li&gt; |
||||| &lt;ul&gt;&lt;li&gt;- \[x] Docker&lt;/ui&gt;&lt;/li&gt; |

### Quickstart with NetBird Cloud

- Download and install NetBird at [https://app.netbird.io/install](https://app.netbird.io/install)
- Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.
- Check NetBird [admin UI](https://app.netbird.io/).
- Add more machines.

### Quickstart with self-hosted NetBird

&gt; This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM.
Follow the [Advanced guide with a custom identity provider](https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider) for installations with different IDPs.

**Infrastructure requirements:**
- A Linux VM with at least **1CPU** and **2GB** of memory.
- The VM should be publicly accessible on TCP ports **80** and **443** and UDP port: **3478**.
- **Public domain** name pointing to the VM.

**Software requirements:**
- Docker installed on the VM with the docker-compose plugin ([Docker installation guide](https://docs.docker.com/engine/install/)) or docker with docker-compose in version 2 or higher.
- [jq](https://jqlang.github.io/jq/) installed. In most distributions
  Usually available in the official repositories and can be installed with `sudo apt install jq` or `sudo yum install jq`
- [curl](https://curl.se/) installed.
  Usually available in the official repositories and can be installed with `sudo apt install curl` or `sudo yum install curl`

**Steps**
- Download and run the installation script:
```bash
export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started.sh | bash
```
- Once finished, you can manage the resources via `docker-compose`

### A bit on NetBird internals
-  Every machine in the network runs [NetBird Agent (or Client)](client/) that manages WireGuard.
-  Every agent connects to [Management Service](management/) that holds network state, manages peer IPs, and distributes network updates to agents (peers).
-  NetBird agent uses WebRTC ICE implemented in [pion/ice library](https://github.com/pion/ice) to discover connection candidates when establishing a peer-to-peer connection between machines.
-  Connection candidates are discovered with the help of [STUN](https://en.wikipedia.org/wiki/STUN) servers.
-  Agents negotiate a connection through [Signal Service](signal/) passing p2p encrypted messages with candidates.
-  Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn&#039;t possible. When this occurs the system falls back to a relay server called [TURN](https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT), and a secure WireGuard tunnel is established via the TURN server. 
 
[Coturn](https://github.com/coturn/coturn) is the one that has been successfully used for STUN and TURN in NetBird setups.

&lt;p float=&quot;left&quot; align=&quot;middle&quot;&gt;
  &lt;img src=&quot;https://docs.netbird.io/docs-static/img/about-netbird/high-level-dia.png&quot; width=&quot;700&quot;/&gt;
&lt;/p&gt;

See a complete [architecture overview](https://docs.netbird.io/about-netbird/how-netbird-works#architecture) for details.

### Community projects
-  [NetBird installer script](https://github.com/physk/netbird-installer)
-  [NetBird ansible collection by Dominion Solutions](https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/)

**Note**: The `main` branch may be in an *unstable or even broken state* during development.
For stable versions, see [releases](https://github.com/netbirdio/netbird/releases).

### Support acknowledgement

In November 2022, NetBird joined the [StartUpSecure program](https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure) sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with [CISPA Helmholtz Center for Information Security](https://cispa.de/en) NetBird brings the security best practices and simplicity to private networking.

![CISPA_Logo_BLACK_EN_RZ_RGB (1)](https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png)

### Testimonials
We use open-source technologies like [WireGuard¬Æ](https://www.wireguard.com/), [Pion ICE (WebRTC)](https://github.com/pion/ice), [Coturn](https://github.com/coturn/coturn), and [Rosenpass](https://rosenpass.eu). We very much appreciate the work these guys are doing and we&#039;d greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).

### Legal
This repository is licensed under BSD-3-Clause license that applies to all parts of the repository except for the directories management/, signal/ and relay/.
Those directories are licensed under the GNU Affero General Public License version 3.0 (AGPLv3). See the respective LICENSE files inside each directory.

_WireGuard_ and the _WireGuard_ logo are [registered trademarks](https://www.wireguard.com/trademark-policy/) of Jason A. Donenfeld.
 

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[AlexanderGrooff/mermaid-ascii]]></title>
            <link>https://github.com/AlexanderGrooff/mermaid-ascii</link>
            <guid>https://github.com/AlexanderGrooff/mermaid-ascii</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:10 GMT</pubDate>
            <description><![CDATA[Render Mermaid graphs inside your terminal]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AlexanderGrooff/mermaid-ascii">AlexanderGrooff/mermaid-ascii</a></h1>
            <p>Render Mermaid graphs inside your terminal</p>
            <p>Language: Go</p>
            <p>Stars: 1,176</p>
            <p>Forks: 49</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># Mermaid ASCII

Render mermaid diagrams in your terminal:

## Installation

You can download the binary from Github releases:

```bash
# Get the latest release
$ curl -s https://api.github.com/repos/AlexanderGrooff/mermaid-ascii/releases/latest | grep &quot;browser_download_url.*mermaid-ascii&quot; | grep &quot;$(uname)_$(uname -m)&quot; | cut -d: -f2,3 | tr -d \&quot; | wget -qi -
# Unzip it
$ tar xvzf mermaid-ascii_*.tar.gz
$ ./mermaid-ascii --help
```

You can also build it yourself:

```bash
$ git clone
$ cd mermaid-ascii
$ go build
$ mermaid-ascii --help
```

Or using Nix:
```bash
$ git clone
$ cd mermaid-ascii
$ nix build
$ ./result/bin/mermaid-ascii --help
```

## Usage

You can render graphs directly from the command line or start a web interface to render them interactively.

```bash
$ cat test.mermaid
graph LR
A --&gt; B &amp; C
B --&gt; C &amp; D
D --&gt; C
$ mermaid-ascii --file test.mermaid
‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ
‚îÇ A ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ B ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ D ‚îÇ
‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ
‚îî‚îÄ‚î¨‚îÄ‚îò     ‚îî‚îÄ‚î¨‚îÄ‚îò     ‚îî‚îÄ‚î¨‚îÄ‚îò
  ‚îÇ         ‚îÇ         ‚îÇ  
  ‚îÇ         ‚îÇ         ‚îÇ  
  ‚îÇ         ‚îÇ         ‚îÇ  
  ‚îÇ         ‚îÇ         ‚îÇ  
  ‚îÇ         ‚ñº         ‚îÇ  
  ‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ  
  ‚îÇ       ‚îÇ   ‚îÇ       ‚îÇ  
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ C ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  
          ‚îÇ   ‚îÇ          
          ‚îî‚îÄ‚îÄ‚îÄ‚îò          

# Increase horizontal spacing
$ mermaid-ascii --file test.mermaid -x 8
‚îå‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ‚îÇ        ‚îÇ   ‚îÇ        ‚îÇ   ‚îÇ
‚îÇ A ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ B ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ D ‚îÇ
‚îÇ   ‚îÇ        ‚îÇ   ‚îÇ        ‚îÇ   ‚îÇ
‚îî‚îÄ‚î¨‚îÄ‚îò        ‚îî‚îÄ‚î¨‚îÄ‚îò        ‚îî‚îÄ‚î¨‚îÄ‚îò
  ‚îÇ            ‚îÇ            ‚îÇ  
  ‚îÇ            ‚îÇ            ‚îÇ  
  ‚îÇ            ‚îÇ            ‚îÇ  
  ‚îÇ            ‚îÇ            ‚îÇ  
  ‚îÇ            ‚ñº            ‚îÇ  
  ‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ  
  ‚îÇ          ‚îÇ   ‚îÇ          ‚îÇ  
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ C ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  
             ‚îÇ   ‚îÇ             
             ‚îî‚îÄ‚îÄ‚îÄ‚îò             

# Increase box padding
$ mermaid-ascii -f ./test.mermaid -p 3
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ
‚îÇ   A   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   B   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   D   ‚îÇ
‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ
‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ     ‚îÇ       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ             ‚îÇ             ‚îÇ
    ‚îÇ             ‚îÇ             ‚îÇ
    ‚îÇ             ‚îÇ             ‚îÇ
    ‚îÇ             ‚îÇ             ‚îÇ
    ‚îÇ             ‚ñº             ‚îÇ
    ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
    ‚îÇ         ‚îÇ       ‚îÇ         ‚îÇ
    ‚îÇ         ‚îÇ       ‚îÇ         ‚îÇ
    ‚îÇ         ‚îÇ       ‚îÇ         ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   C   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              ‚îÇ       ‚îÇ
              ‚îÇ       ‚îÇ
              ‚îÇ       ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

# Labeled edges
$ cat test.mermaid
graph LR
A --&gt; B
A --&gt; C
B --&gt; C
B --&gt;|example| D
D --&gt; C
$ mermaid-ascii -f ./test.mermaid
‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ         ‚îÇ   ‚îÇ
‚îÇ A ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ B ‚îú‚îÄexample‚ñ∫‚îÇ D ‚îÇ
‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ         ‚îÇ   ‚îÇ
‚îî‚îÄ‚î¨‚îÄ‚îò     ‚îî‚îÄ‚î¨‚îÄ‚îò         ‚îî‚îÄ‚î¨‚îÄ‚îò
  ‚îÇ         ‚îÇ             ‚îÇ  
  ‚îÇ         ‚îÇ             ‚îÇ  
  ‚îÇ         ‚îÇ             ‚îÇ  
  ‚îÇ         ‚îÇ             ‚îÇ  
  ‚îÇ         ‚ñº             ‚îÇ  
  ‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ  
  ‚îÇ       ‚îÇ   ‚îÇ           ‚îÇ  
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ C ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  
          ‚îÇ   ‚îÇ              
          ‚îî‚îÄ‚îÄ‚îÄ‚îò              

# Top-down layout
$ cat test.mermaid
graph TD
A --&gt; B
A --&gt; C
B --&gt; C
B --&gt;|example| D
D --&gt; C
$ mermaid-ascii -f ./test.mermaid
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          
‚îÇ         ‚îÇ          
‚îÇ    A    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  
‚îÇ         ‚îÇ       ‚îÇ  
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ  
     ‚îÇ            ‚îÇ  
     ‚îÇ            ‚îÇ  
     ‚îÇ            ‚îÇ  
     ‚îÇ            ‚îÇ  
     ‚ñº            ‚ñº  
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ‚îÇ     ‚îÇ   ‚îÇ
‚îÇ    B    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ C ‚îÇ
‚îÇ         ‚îÇ     ‚îÇ   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ            ‚ñ≤  
     ‚îÇ            ‚îÇ  
  example         ‚îÇ  
     ‚îÇ            ‚îÇ  
     ‚ñº            ‚îÇ  
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ  
‚îÇ         ‚îÇ       ‚îÇ  
‚îÇ    D    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  
‚îÇ         ‚îÇ          
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          

# Read from stdin
$ cat test.mermaid | mermaid-ascii
‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ
‚îÇ A ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ B ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ D ‚îÇ
‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ
‚îî‚îÄ‚î¨‚îÄ‚îò     ‚îî‚îÄ‚î¨‚îÄ‚îò     ‚îî‚îÄ‚î¨‚îÄ‚îò
  ‚îÇ         ‚îÇ         ‚îÇ  
  ‚îÇ         ‚îÇ         ‚îÇ  
  ‚îÇ         ‚îÇ         ‚îÇ  
  ‚îÇ         ‚îÇ         ‚îÇ  
  ‚îÇ         ‚ñº         ‚îÇ  
  ‚îÇ       ‚îå‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ  
  ‚îÇ       ‚îÇ   ‚îÇ       ‚îÇ  
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ C ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  
          ‚îÇ   ‚îÇ          
          ‚îî‚îÄ‚îÄ‚îÄ‚îò          

# Only ASCII
$ cat test.mermaid | mermaid-ascii --ascii
+---+     +---+     +---+
|   |     |   |     |   |
| A |----&gt;| B |----&gt;| D |
|   |     |   |     |   |
+---+     +---+     +---+
  |         |         |
  |         |         |
  |         |         |
  |         |         |
  |         v         |
  |       +---+       |
  |       |   |       |
  -------&gt;| C |&lt;-------
          |   |
          +---+

# Using Docker
$ docker build -t mermaid-ascii .
$ echo &#039;sequenceDiagram
Alice-&gt;&gt;Bob: Hello
Bob--&gt;&gt;Alice: Hi&#039; | docker run -i mermaid-ascii -f -
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Alice ‚îÇ     ‚îÇ Bob ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
    ‚îÇ            ‚îÇ
    ‚îÇ Hello      ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
    ‚îÇ            ‚îÇ
    ‚îÇ Hi         ‚îÇ
    ‚îÇ‚óÑ‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚î§
    ‚îÇ            ‚îÇ

# Graph diagrams work too
$ echo &#039;graph LR
A--&gt;B--&gt;C&#039; | docker run -i mermaid-ascii -f -
‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ
‚îÇ A ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ B ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ C ‚îÇ
‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îò

# Run web interface
$ docker run -p 3001:3001 mermaid-ascii web --port 3001
# Then visit http://localhost:3001
```

### Sequence Diagrams

Sequence diagrams are also fully supported! They visualize message flows between participants over time.

```bash
# Simple sequence diagram
$ cat sequence.mermaid
sequenceDiagram
Alice-&gt;&gt;Bob: Hello Bob!
Bob--&gt;&gt;Alice: Hi Alice!
$ mermaid-ascii -f sequence.mermaid
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Alice ‚îÇ     ‚îÇ Bob ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
    ‚îÇ            ‚îÇ
    ‚îÇ Hello Bob! ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
    ‚îÇ            ‚îÇ
    ‚îÇ Hi Alice!  ‚îÇ
    ‚îÇ‚óÑ‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚î§
    ‚îÇ            ‚îÇ

# Solid arrows (-&gt;&gt;) and dotted arrows (--&gt;&gt;)
$ cat sequence.mermaid
sequenceDiagram
Client-&gt;&gt;Server: Request
Server--&gt;&gt;Client: Response
$ mermaid-ascii -f sequence.mermaid
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Client ‚îÇ     ‚îÇ Server ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ              ‚îÇ
    ‚îÇ   Request    ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
    ‚îÇ              ‚îÇ
    ‚îÇ   Response   ‚îÇ
    ‚îÇ‚óÑ‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚î§
    ‚îÇ              ‚îÇ

# Multiple participants
$ cat sequence.mermaid
sequenceDiagram
Alice-&gt;&gt;Bob: Hello!
Bob-&gt;&gt;Charlie: Forward message
Charlie--&gt;&gt;Alice: Got it!
$ mermaid-ascii -f sequence.mermaid
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Alice ‚îÇ     ‚îÇ Bob ‚îÇ     ‚îÇ Charlie ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ            ‚îÇ              ‚îÇ
    ‚îÇ   Hello!   ‚îÇ              ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ              ‚îÇ
    ‚îÇ            ‚îÇ              ‚îÇ
    ‚îÇ            ‚îÇ Forward message
    ‚îÇ            ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
    ‚îÇ            ‚îÇ              ‚îÇ
    ‚îÇ         Got it!           ‚îÇ
    ‚îÇ‚óÑ‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚î§
    ‚îÇ            ‚îÇ              ‚îÇ

# Self-messages
$ cat sequence.mermaid
sequenceDiagram
Alice-&gt;&gt;Alice: Think
Alice-&gt;&gt;Bob: Hello
$ mermaid-ascii -f sequence.mermaid
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Alice ‚îÇ     ‚îÇ Bob ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
    ‚îÇ            ‚îÇ
    ‚îÇ Think      ‚îÇ
    ‚îú‚îÄ‚îÄ‚îê         ‚îÇ
    ‚îÇ  ‚îÇ         ‚îÇ
    ‚îÇ‚óÑ‚îÄ‚îò         ‚îÇ
    ‚îÇ            ‚îÇ
    ‚îÇ Hello      ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
    ‚îÇ            ‚îÇ

# Explicit participant declarations with aliases
$ cat sequence.mermaid
sequenceDiagram
participant A as Alice
participant B as Bob
A-&gt;&gt;B: Message from Alice
B--&gt;&gt;A: Reply to Alice
$ mermaid-ascii -f sequence.mermaid
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Alice ‚îÇ     ‚îÇ Bob ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
    ‚îÇ            ‚îÇ
    ‚îÇ Message from Alice
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
    ‚îÇ            ‚îÇ
    ‚îÇ Reply to Alice
    ‚îÇ‚óÑ‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚îà‚î§
    ‚îÇ            ‚îÇ

# ASCII mode for sequence diagrams
$ cat sequence.mermaid | mermaid-ascii --ascii
+-------+     +-----+
| Alice |     | Bob |
+---+---+     +--+--+
    |            |
    | Hello Bob! |
    +-----------&gt;|
    |            |
    | Hi Alice!  |
    |&lt;...........+
    |            |

```

```bash
$ mermaid-ascii --help
Generate ASCII diagrams from mermaid code.

Usage:
  mermaid-ascii [flags]
  mermaid-ascii [command]

Available Commands:
  completion  Generate the autocompletion script for the specified shell
  help        Help about any command
  web         HTTP server for rendering mermaid diagrams.

Flags:
  -p, --borderPadding int   Padding between text and border (default 1)
  -c, --coords              Show coordinates
  -f, --file string         Mermaid file to parse
  -h, --help                help for mermaid-ascii
  -x, --paddingX int        Horizontal space between nodes (default 5)
  -y, --paddingY int        Vertical space between nodes (default 5)
  -v, --verbose             Verbose output

Use &quot;mermaid-ascii [command] --help&quot; for more information about a command.

# And some ridiculous example
$ mermaid-ascii -f complex.mermaid
‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ
‚îÇ A ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ B ‚îú‚îÄ‚îÄ‚î¨‚îÄ‚ñ∫‚îÇ E ‚îú‚îÄ‚îÄ‚î¨‚îÄ‚ñ∫‚îÇ M ‚îú‚îÄ‚îÄ‚î¨‚îÄ‚ñ∫‚îÇ U ‚îú‚îÄ‚îÄ‚î¨‚îÄ‚ñ∫‚îÇ W ‚îÇ
‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ
‚îî‚îÄ‚î¨‚îÄ‚îò     ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò
  ‚îÇ         ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚ñ≤    ‚îÇ    ‚îÇ  
  ‚îÇ         ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ  
  ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îò  
  ‚îÇ    ‚îÇ         ‚îÇ         ‚îÇ    ‚îÇ         ‚îÇ    ‚îÇ       
  ‚îÇ    ‚îÇ         ‚îÇ         ‚îÇ    ‚ñº         ‚ñº    ‚îÇ       
  ‚îÇ    ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚î¥‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îê
  ‚îÇ    ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ
  ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚ñ∫‚îÇ C ‚îú‚îÄ‚îÄ‚îº‚îÄ‚ñ∫‚îÇ F ‚îÇ  ‚îú‚îÄ‚ñ∫‚îÇ Q ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Y ‚îÇ‚óÑ‚îÄ‚îº‚îÄ‚ñ∫‚îÇ V ‚îÇ
  ‚îÇ    ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ
  ‚îÇ    ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò
  ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ                   ‚îÇ    ‚ñ≤  
  ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ                   ‚îÇ    ‚îÇ  
  ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î§                   ‚îÇ    ‚îÇ  
  ‚îÇ         ‚îÇ    ‚îÇ         ‚îÇ                   ‚îÇ    ‚îÇ  
  ‚îÇ         ‚ñº    ‚îÇ         ‚îÇ                   ‚îÇ    ‚îÇ  
  ‚îÇ       ‚îå‚îÄ‚î¥‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ  
  ‚îÇ       ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ  ‚îÇ    ‚îÇ  
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ D ‚îÇ  ‚îú‚îÄ‚ñ∫‚îÇ G ‚îÇ  ‚îú‚îÄ‚ñ∫‚îÇ L ‚îú‚îÄ‚îÄ‚î¨‚îÄ‚ñ∫‚îÇ T ‚îú‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§  
          ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ    ‚îÇ  
          ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚ñ≤    ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îÇ  
            ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ         ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îÇ    ‚ñº    ‚îÇ         ‚îÇ    ‚ñº    ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îÇ  ‚îå‚îÄ‚î¥‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îú‚îÄ‚ñ∫‚îÇ H ‚îÇ  ‚îú‚îÄ‚ñ∫‚îÇ J ‚îÇ  ‚îú‚îÄ‚ñ∫‚îÇ X ‚îÇ‚óÑ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§  
            ‚îÇ    ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ         ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ         ‚îÇ    ‚îÇ  
            ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îÇ  
            ‚îÇ         ‚îÇ    ‚îÇ         ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ  
            ‚îÇ         ‚ñº    ‚îÇ         ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ  
            ‚îÇ       ‚îå‚îÄ‚î¥‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚î¥‚îÄ‚îê  ‚îÇ    ‚îÇ  
            ‚îÇ       ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ    ‚îÇ  
            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ I ‚îÇ  ‚îú‚îÄ‚ñ∫‚îÇ K ‚îÇ  ‚îú‚îÄ‚ñ∫‚îÇ R ‚îú‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îò  
                    ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ       
                    ‚îî‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ       
                           ‚îÇ    ‚îÇ    ‚îÇ         ‚îÇ       
                           ‚îÇ    ‚îÇ    ‚îÇ         ‚îÇ       
                           ‚îÇ    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î§       
                           ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ       
                           ‚îÇ    ‚ñº    ‚îÇ    ‚îÇ    ‚îÇ       
                           ‚îÇ  ‚îå‚îÄ‚î¥‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚î¥‚îÄ‚îê  ‚îÇ       
                           ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ       
                           ‚îú‚îÄ‚ñ∫‚îÇ N ‚îÇ  ‚îú‚îÄ‚ñ∫‚îÇ O ‚îÇ  ‚îÇ       
                           ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ       
                           ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îî‚îÄ‚î¨‚îÄ‚îò  ‚îÇ       
                           ‚îÇ         ‚îÇ    ‚îÇ    ‚îÇ       
                           ‚îÇ         ‚îÇ    ‚îÇ    ‚îÇ       
                           ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚î§    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îò       
                           ‚îÇ    ‚îÇ    ‚îÇ    ‚îÇ            
                           ‚îÇ    ‚ñº    ‚îÇ    ‚ñº            
                           ‚îÇ  ‚îå‚îÄ‚î¥‚îÄ‚îê  ‚îÇ  ‚îå‚îÄ‚î¥‚îÄ‚îê          
                           ‚îÇ  ‚îÇ   ‚îÇ  ‚îÇ  ‚îÇ   ‚îÇ          
                           ‚îî‚îÄ‚ñ∫‚îÇ P ‚îÇ  ‚îî‚îÄ‚ñ∫‚îÇ S ‚îÇ          
                              ‚îÇ   ‚îÇ     ‚îÇ   ‚îÇ          
                              ‚îî‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îò          

```

Colored output is also supported (given that your terminal supports it) using the `classDef` syntax:

```bash
graph LR
classDef example1 color:#ff0000
classDef example2 color:#00ff00
classDef example3 color:#0000ff
test1:::example1 --&gt; test2
test2:::example2 --&gt; test3:::example3
```

This results in the following graph:

![](docs/colored_graph.png)

## How it works

We parse a mermaid file into basic components in order to render a grid. The grid is used for mapping purposes, which is eventually converted to a drawing.
The grid looks a bit like this:

```
There are three grid-points per node, and one in-between nodes.
These coords don&#039;t have to be the same size, as long as they
can be used for pathing purposes where we convert them to drawing
coordinates.
This allows us to navigate edges between nodes, like the arrow in this
drawing taking the path [(2,1), (3,1), (3,5), (4,5)].
    0      1      2  3  4      5      6
    |      |      |  |  |      |      |
    v      v      v  v  v      v      v
                                       
0-&gt; +-------------+     +-------------+
    |             |     |             |
1-&gt; |  Some text  |---  |  Some text  |
    |             |  |  |             |
2-&gt; +-------------+  |  +-------------+
                     |                 
3-&gt;                  |                 
                     |                 
4-&gt; +-------------+  |  +-------------+
    |             |  |  |             |
5-&gt; |  Some text  |  --&gt;|  Some text  |
    |             |     |             |
6-&gt; +-------------+     +-------------+
```

You can show these coords in your graph by enabling the `--coords` flag:

```bash
$ mermaid-ascii -f ./test.mermaid --coords
   01  23    45  67  89       0
   0123456789012345678901234567
0 0+---+     +---+   +--------+
  1|   |     |   |   |        |
1 2| A |-123&gt;| B |--&gt;|   D    |
  3|   |     |   |   |        |
2 4+---+     +---+   +--------+
  5  |         |          |
3 6  |         2          |
  7  |         v       123456
4 8  |       +---+        |
  9  |       |   |        |
510  -------&gt;| C |&lt;--------
 11          |   |
612          +---+
```

Note that with `--coords` enabled, the grid-coords shown show the starting location of the coord, not the center of the coord. This is why `(1,0)` is next to `(0,0)` instead of in the center of the `A` node.

## Supported Diagram Types

### Graphs / Flowcharts ‚úÖ
- [x] Graph directions (`graph LR` and `graph TD`)
- [x] Labelled edges (like `A --&gt;|label| B`)
- [x] Multiple arrows on one line (like `A --&gt; B --&gt; C`)
- [x] `A &amp; B` syntax
- [x] `classDef` and `class` for colored output
- [x] Prevent arrows overlapping nodes
- [ ] `subgraph` support
- [ ] Shapes other than rectangles
- [ ] Diagonal arrows

### Sequence Diagrams ‚úÖ
- [x] Basic message syntax (`A-&gt;&gt;B: message`)
- [x] Solid arrows (`-&gt;&gt;`) and dotted arrows (`--&gt;&gt;`)
- [x] Self-messages (`A-&gt;&gt;A: think`)
- [x] Participant declarations (`participant Alice`)
- [x] Participant aliases (`participant A as Alice`)
- [x] Unicode support (emojis, CJK characters, etc.)
- [x] Both ASCII and Unicode rendering modes
- [ ] Activation boxes
- [ ] Notes (`Note left of Alice: text`)
- [ ] Loops, alt, opt blocks

## TODOs

The baseline components for Mermaid work, but there are a lot of things that are not supported yet. Here&#039;s a list of things that are not yet supported:

### Syntax support

- [x] Labelled edges (like `A --&gt;|label| B`)
- [x] Graph directions like `graph LR` and `graph TD`
- [x] `classDef` and `class`
- [x] `A &amp; B`
- [x] Multiple arrows on one line (like `A --&gt; B --&gt; C`)
- [ ] `subgraph`
- [ ] Shapes other than rectangles
- [ ] Whitespacing and comments

### Rendering

- [x] Prevent arrows overlapping nodes
- [ ] Diagonal arrows
- [ ] Place nodes in a more compact way
- [ ] Prevent rendering more than X characters wide (like default 80 for terminal width)

### Sequence Diagram Improvements

- [ ] Activation boxes (activate/deactivate)
- [ ] Notes (`Note left of Alice: text`)
- [ ] Loops, alt, opt, and par blocks

### General

- [ ] Support for more diagram types (class diagrams, state diagrams, etc.)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[googleapis/genai-toolbox]]></title>
            <link>https://github.com/googleapis/genai-toolbox</link>
            <guid>https://github.com/googleapis/genai-toolbox</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:09 GMT</pubDate>
            <description><![CDATA[MCP Toolbox for Databases is an open source MCP server for databases.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/googleapis/genai-toolbox">googleapis/genai-toolbox</a></h1>
            <p>MCP Toolbox for Databases is an open source MCP server for databases.</p>
            <p>Language: Go</p>
            <p>Stars: 12,993</p>
            <p>Forks: 1,196</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>![logo](./logo.png)

# MCP Toolbox for Databases

&lt;a href=&quot;https://trendshift.io/repositories/13019&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13019&quot; alt=&quot;googleapis%2Fgenai-toolbox | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

[![Docs](https://img.shields.io/badge/docs-MCP_Toolbox-blue)](https://googleapis.github.io/genai-toolbox/)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=flat&amp;logo=discord&amp;logoColor=white)](https://discord.gg/Dmm69peqjh)
[![Medium](https://img.shields.io/badge/Medium-12100E?style=flat&amp;logo=medium&amp;logoColor=white)](https://medium.com/@mcp_toolbox)
[![Go Report Card](https://goreportcard.com/badge/github.com/googleapis/genai-toolbox)](https://goreportcard.com/report/github.com/googleapis/genai-toolbox)

&gt; [!NOTE]
&gt; MCP Toolbox for Databases is currently in beta, and may see breaking
&gt; changes until the first stable release (v1.0).

MCP Toolbox for Databases is an open source MCP server for databases. It enables
you to develop tools easier, faster, and more securely by handling the complexities
such as connection pooling, authentication, and more.

This README provides a brief overview. For comprehensive details, see the [full
documentation](https://googleapis.github.io/genai-toolbox/).

&gt; [!NOTE]
&gt; This solution was originally named ‚ÄúGen AI Toolbox for Databases‚Äù as
&gt; its initial development predated MCP, but was renamed to align with recently
&gt; added MCP compatibility.

&lt;!-- TOC ignore:true --&gt;
## Table of Contents

&lt;!-- TOC --&gt;

- [Why Toolbox?](#why-toolbox)
- [General Architecture](#general-architecture)
- [Getting Started](#getting-started)
  - [Installing the server](#installing-the-server)
  - [Running the server](#running-the-server)
  - [Integrating your application](#integrating-your-application)
  - [Using Toolbox with Gemini CLI Extensions](#using-toolbox-with-gemini-cli-extensions)
- [Configuration](#configuration)
  - [Sources](#sources)
  - [Tools](#tools)
  - [Toolsets](#toolsets)
  - [Prompts](#prompts)
- [Versioning](#versioning)
  - [Pre-1.0.0 Versioning](#pre-100-versioning)
  - [Post-1.0.0 Versioning](#post-100-versioning)
- [Contributing](#contributing)
- [Community](#community)

&lt;!-- /TOC --&gt;

## Why Toolbox?

Toolbox helps you build Gen AI tools that let your agents access data in your
database. Toolbox provides:

- **Simplified development**: Integrate tools to your agent in less than 10
  lines of code, reuse tools between multiple agents or frameworks, and deploy
  new versions of tools more easily.
- **Better performance**: Best practices such as connection pooling,
  authentication, and more.
- **Enhanced security**: Integrated auth for more secure access to your data
- **End-to-end observability**: Out of the box metrics and tracing with built-in
  support for OpenTelemetry.

**‚ö° Supercharge Your Workflow with an AI Database Assistant ‚ö°**

Stop context-switching and let your AI assistant become a true co-developer. By
[connecting your IDE to your databases with MCP Toolbox][connect-ide], you can
delegate complex and time-consuming database tasks, allowing you to build faster
and focus on what matters. This isn&#039;t just about code completion; it&#039;s about
giving your AI the context it needs to handle the entire development lifecycle.

Here‚Äôs how it will save you time:

- **Query in Plain English**: Interact with your data using natural language
  right from your IDE. Ask complex questions like, *&quot;How many orders were
  delivered in 2024, and what items were in them?&quot;* without writing any SQL.
- **Automate Database Management**: Simply describe your data needs, and let the
  AI assistant manage your database for you. It can handle generating queries,
  creating tables, adding indexes, and more.
- **Generate Context-Aware Code**: Empower your AI assistant to generate
  application code and tests with a deep understanding of your real-time
  database schema.  This accelerates the development cycle by ensuring the
  generated code is directly usable.
- **Slash Development Overhead**: Radically reduce the time spent on manual
  setup and boilerplate. MCP Toolbox helps streamline lengthy database
  configurations, repetitive code, and error-prone schema migrations.

Learn [how to connect your AI tools (IDEs) to Toolbox using MCP][connect-ide].

[connect-ide]: https://googleapis.github.io/genai-toolbox/how-to/connect-ide/

## General Architecture

Toolbox sits between your application&#039;s orchestration framework and your
database, providing a control plane that is used to modify, distribute, or
invoke tools. It simplifies the management of your tools by providing you with a
centralized location to store and update tools, allowing you to share tools
between agents and applications and update those tools without necessarily
redeploying your application.

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;./docs/en/getting-started/introduction/architecture.png&quot; alt=&quot;architecture&quot; width=&quot;50%&quot;/&gt;
&lt;/p&gt;

## Getting Started

### Quickstart: Running Toolbox using NPX

You can run Toolbox directly with a [configuration file](#configuration):

```sh
npx @toolbox-sdk/server --tools-file tools.yaml
```

This runs the latest version of the toolbox server with your configuration file.

&gt; [!NOTE]
&gt; This method should only be used for non-production use cases such as
&gt; experimentation. For any production use-cases, please consider [Installing the
&gt; server](#installing-the-server) and then [running it](#running-the-server).

### Installing the server

For the latest version, check the [releases page][releases] and use the
following instructions for your OS and CPU architecture.

[releases]: https://github.com/googleapis/genai-toolbox/releases

&lt;details open&gt;
&lt;summary&gt;Binary&lt;/summary&gt;

To install Toolbox as a binary:

&lt;!-- {x-release-please-start-version} --&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;Linux (AMD64)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on Linux (AMD64):
&gt;
&gt; ```sh
&gt; # see releases page for other versions
&gt; export VERSION=0.27.0
&gt; curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/linux/amd64/toolbox
&gt; chmod +x toolbox
&gt; ```
&gt;
&gt; &lt;/details&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;macOS (Apple Silicon)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on macOS (Apple Silicon):
&gt;
&gt; ```sh
&gt; # see releases page for other versions
&gt; export VERSION=0.27.0
&gt; curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/arm64/toolbox
&gt; chmod +x toolbox
&gt; ```
&gt;
&gt; &lt;/details&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;macOS (Intel)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on macOS (Intel):
&gt;
&gt; ```sh
&gt; # see releases page for other versions
&gt; export VERSION=0.27.0
&gt; curl -L -o toolbox https://storage.googleapis.com/genai-toolbox/v$VERSION/darwin/amd64/toolbox
&gt; chmod +x toolbox
&gt; ```
&gt;
&gt; &lt;/details&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;Windows (Command Prompt)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on Windows (Command Prompt):
&gt;
&gt; ```cmd
&gt; :: see releases page for other versions
&gt; set VERSION=0.27.0
&gt; curl -o toolbox.exe &quot;https://storage.googleapis.com/genai-toolbox/v%VERSION%/windows/amd64/toolbox.exe&quot;
&gt; ```
&gt;
&gt; &lt;/details&gt;
&gt; &lt;details&gt;
&gt; &lt;summary&gt;Windows (PowerShell)&lt;/summary&gt;
&gt;
&gt; To install Toolbox as a binary on Windows (PowerShell):
&gt;
&gt; ```powershell
&gt; # see releases page for other versions
&gt; $VERSION = &quot;0.27.0&quot;
&gt; curl.exe -o toolbox.exe &quot;https://storage.googleapis.com/genai-toolbox/v$VERSION/windows/amd64/toolbox.exe&quot;
&gt; ```
&gt;
&gt; &lt;/details&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Container image&lt;/summary&gt;
You can also install Toolbox as a container:

```sh
# see releases page for other versions
export VERSION=0.27.0
docker pull us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Homebrew&lt;/summary&gt;

To install Toolbox using Homebrew on macOS or Linux:

```sh
brew install mcp-toolbox
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Compile from source&lt;/summary&gt;

To install from source, ensure you have the latest version of
[Go installed](https://go.dev/doc/install), and then run the following command:

```sh
go install github.com/googleapis/genai-toolbox@v0.27.0
```
&lt;!-- {x-release-please-end} --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Gemini CLI Extensions&lt;/summary&gt;

To install Gemini CLI Extensions for MCP Toolbox, run the following command:

```sh
gemini extensions install https://github.com/gemini-cli-extensions/mcp-toolbox
```

&lt;/details&gt;

### Running the server

[Configure](#configuration) a `tools.yaml` to define your tools, and then
execute `toolbox` to start the server:

&lt;details open&gt;
&lt;summary&gt;Binary&lt;/summary&gt;

To run Toolbox from binary:

```sh
./toolbox --tools-file &quot;tools.yaml&quot;
```

&gt; ‚ìò Note  
&gt; Toolbox enables dynamic reloading by default. To disable, use the
&gt; `--disable-reload` flag.

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Container image&lt;/summary&gt;

To run the server after pulling the [container image](#installing-the-server):

```sh
export VERSION=0.24.0 # Use the version you pulled
docker run -p 5000:5000 \
-v $(pwd)/tools.yaml:/app/tools.yaml \
us-central1-docker.pkg.dev/database-toolbox/toolbox/toolbox:$VERSION \
--tools-file &quot;/app/tools.yaml&quot;
```

&gt; ‚ìò Note  
&gt; The `-v` flag mounts your local `tools.yaml` into the container, and `-p` maps
&gt; the container&#039;s port `5000` to your host&#039;s port `5000`.

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Source&lt;/summary&gt;

To run the server directly from source, navigate to the project root directory
and run:

```sh
go run .
```

&gt; ‚ìò Note  
&gt; This command runs the project from source, and is more suitable for development
&gt; and testing. It does **not** compile a binary into your `$GOPATH`. If you want
&gt; to compile a binary instead, refer the [Developer
&gt; Documentation](./DEVELOPER.md#building-the-binary).

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Homebrew&lt;/summary&gt;

If you installed Toolbox using [Homebrew](https://brew.sh/), the `toolbox`
binary is available in your system path. You can start the server with the same
command:

```sh
toolbox --tools-file &quot;tools.yaml&quot;
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;NPM&lt;/summary&gt;

To run Toolbox directly without manually downloading the binary (requires Node.js):
```sh
npx @toolbox-sdk/server --tools-file tools.yaml
```

&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;Gemini CLI&lt;/summary&gt;

Interact with your custom tools using natural language. Check
[gemini-cli-extensions/mcp-toolbox](https://github.com/gemini-cli-extensions/mcp-toolbox)
for more information.

&lt;/details&gt;

You can use `toolbox help` for a full list of flags! To stop the server, send a
terminate signal (`ctrl+c` on most platforms).

For more detailed documentation on deploying to different environments, check
out the resources in the [How-to
section](https://googleapis.github.io/genai-toolbox/how-to/)

### Integrating your application

Once your server is up and running, you can load the tools into your
application. See below the list of Client SDKs for using various frameworks:

&lt;details open&gt;
  &lt;summary&gt;Python (&lt;a href=&quot;https://github.com/googleapis/mcp-toolbox-sdk-python&quot;&gt;Github&lt;/a&gt;)&lt;/summary&gt;
  &lt;br&gt;
  &lt;blockquote&gt;

  &lt;details open&gt;
    &lt;summary&gt;Core&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core]:

    ```bash
    pip install toolbox-core
    ```

1. Load tools:

    ```python
    from toolbox_core import ToolboxClient

    # update the url to point to your server
    async with ToolboxClient(&quot;http://127.0.0.1:5000&quot;) as client:

        # these tools can be passed to your application!
        tools = await client.load_toolset(&quot;toolset_name&quot;)
    ```

For more detailed instructions on using the Toolbox Core SDK, see the
[project&#039;s README][toolbox-core-readme].

[toolbox-core]: https://pypi.org/project/toolbox-core/
[toolbox-core-readme]: https://github.com/googleapis/mcp-toolbox-sdk-python/tree/main/packages/toolbox-core/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt;

1. Install [Toolbox LangChain SDK][toolbox-langchain]:

    ```bash
    pip install toolbox-langchain
    ```

1. Load tools:

    ```python
    from toolbox_langchain import ToolboxClient

    # update the url to point to your server
    async with ToolboxClient(&quot;http://127.0.0.1:5000&quot;) as client:

        # these tools can be passed to your application!
        tools = client.load_toolset()
    ```

    For more detailed instructions on using the Toolbox LangChain SDK, see the
    [project&#039;s README][toolbox-langchain-readme].

    [toolbox-langchain]: https://pypi.org/project/toolbox-langchain/
    [toolbox-langchain-readme]: https://github.com/googleapis/mcp-toolbox-sdk-python/blob/main/packages/toolbox-langchain/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LlamaIndex&lt;/summary&gt;

1. Install [Toolbox Llamaindex SDK][toolbox-llamaindex]:

    ```bash
    pip install toolbox-llamaindex
    ```

1. Load tools:

    ```python
    from toolbox_llamaindex import ToolboxClient

    # update the url to point to your server
    async with ToolboxClient(&quot;http://127.0.0.1:5000&quot;) as client:

        # these tools can be passed to your application!
        tools = client.load_toolset()
    ```

    For more detailed instructions on using the Toolbox Llamaindex SDK, see the
    [project&#039;s README][toolbox-llamaindex-readme].

    [toolbox-llamaindex]: https://pypi.org/project/toolbox-llamaindex/
    [toolbox-llamaindex-readme]: https://github.com/googleapis/genai-toolbox-llamaindex-python/blob/main/README.md

  &lt;/details&gt;
&lt;/details&gt;
&lt;/blockquote&gt;
&lt;details&gt;
  &lt;summary&gt;Javascript/Typescript (&lt;a href=&quot;https://github.com/googleapis/mcp-toolbox-sdk-js&quot;&gt;Github&lt;/a&gt;)&lt;/summary&gt;
  &lt;br&gt;
  &lt;blockquote&gt;

  &lt;details open&gt;
    &lt;summary&gt;Core&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core-js]:

    ```bash
    npm install @toolbox-sdk/core
    ```

1. Load tools:

    ```javascript
    import { ToolboxClient } from &#039;@toolbox-sdk/core&#039;;

    // update the url to point to your server
    const URL = &#039;http://127.0.0.1:5000&#039;;
    let client = new ToolboxClient(URL);

    // these tools can be passed to your application!
    const tools = await client.loadToolset(&#039;toolsetName&#039;);
    ```

    For more detailed instructions on using the Toolbox Core SDK, see the
    [project&#039;s README][toolbox-core-js-readme].

    [toolbox-core-js]: https://www.npmjs.com/package/@toolbox-sdk/core
    [toolbox-core-js-readme]: https://github.com/googleapis/mcp-toolbox-sdk-js/blob/main/packages/toolbox-core/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LangChain / LangGraph&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core-js]:

    ```bash
    npm install @toolbox-sdk/core
    ```

2. Load tools:

    ```javascript
    import { ToolboxClient } from &#039;@toolbox-sdk/core&#039;;

    // update the url to point to your server
    const URL = &#039;http://127.0.0.1:5000&#039;;
    let client = new ToolboxClient(URL);

    // these tools can be passed to your application!
    const toolboxTools = await client.loadToolset(&#039;toolsetName&#039;);

    // Define the basics of the tool: name, description, schema and core logic
    const getTool = (toolboxTool) =&gt; tool(currTool, {
        name: toolboxTool.getName(),
        description: toolboxTool.getDescription(),
        schema: toolboxTool.getParamSchema()
    });

    // Use these tools in your Langchain/Langraph applications
    const tools = toolboxTools.map(getTool);
    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;Genkit&lt;/summary&gt;

1. Install [Toolbox Core SDK][toolbox-core-js]:

    ```bash
    npm install @toolbox-sdk/core
    ```

2. Load tools:

    ```javascript
    import { ToolboxClient } from &#039;@toolbox-sdk/core&#039;;
    import { genkit } from &#039;genkit&#039;;

    // Initialise genkit
    const ai = genkit({
        plugins: [
            googleAI({
                apiKey: process.env.GEMINI_API_KEY || process.env.GOOGLE_API_KEY
            })
        ],
        model: googleAI.model(&#039;gemini-2.0-flash&#039;),
    });

    // update the url to point to your server
    const URL = &#039;http://127.0.0.1:5000&#039;;
    let client = new ToolboxClient(URL);

    // these tools can be passed to your application!
    const toolboxTools = await client.loadToolset(&#039;toolsetName&#039;);

    // Define the basics of the tool: name, description, schema and core logic
    const getTool = (toolboxTool) =&gt; ai.defineTool({
        name: toolboxTool.getName(),
        description: toolboxTool.getDescription(),
        schema: toolboxTool.getParamSchema()
    }, toolboxTool)

    // Use these tools in your Genkit applications
    const tools = toolboxTools.map(getTool);
    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;ADK&lt;/summary&gt;

1. Install [Toolbox ADK SDK][toolbox-adk-js]:

    ```bash
    npm install @toolbox-sdk/adk
    ```

2. Load tools:

    ```javascript
    import { ToolboxClient } from &#039;@toolbox-sdk/adk&#039;;

    // update the url to point to your server
    const URL = &#039;http://127.0.0.1:5000&#039;;
    let client = new ToolboxClient(URL);

    // these tools can be passed to your application!
    const tools = await client.loadToolset(&#039;toolsetName&#039;);
    ```

    For more detailed instructions on using the Toolbox ADK SDK, see the
    [project&#039;s README][toolbox-adk-js-readme].

    [toolbox-adk-js]: https://www.npmjs.com/package/@toolbox-sdk/adk
    [toolbox-adk-js-readme]:
       https://github.com/googleapis/mcp-toolbox-sdk-js/blob/main/packages/toolbox-adk/README.md

  &lt;/details&gt;
&lt;/details&gt;
&lt;/blockquote&gt;
&lt;details&gt;
  &lt;summary&gt;Go (&lt;a href=&quot;https://github.com/googleapis/mcp-toolbox-sdk-go&quot;&gt;Github&lt;/a&gt;)&lt;/summary&gt;
  &lt;br&gt;
  &lt;blockquote&gt;

  &lt;details&gt;
    &lt;summary&gt;Core&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main

    import (
      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;context&quot;
    )

    func main() {
      // Make sure to add the error checks
      // update the url to point to your server
      URL := &quot;http://127.0.0.1:5000&quot;;
      ctx := context.Background()

      client, err := core.NewToolboxClient(URL)

      // Framework agnostic tools
      tools, err := client.LoadToolset(&quot;toolsetName&quot;, ctx)
    }
    ```

    For more detailed instructions on using the Toolbox Go SDK, see the
    [project&#039;s README][toolbox-core-go-readme].

    [toolbox-go]: https://pkg.go.dev/github.com/googleapis/mcp-toolbox-sdk-go/core
    [toolbox-core-go-readme]: https://github.com/googleapis/mcp-toolbox-sdk-go/blob/main/core/README.md

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;LangChain Go&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main

    import (
      &quot;context&quot;
      &quot;encoding/json&quot;

      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;github.com/tmc/langchaingo/llms&quot;
    )

    func main() {
      // Make sure to add the error checks
      // update the url to point to your server
      URL := &quot;http://127.0.0.1:5000&quot;
      ctx := context.Background()

      client, err := core.NewToolboxClient(URL)

      // Framework agnostic tool
      tool, err := client.LoadTool(&quot;toolName&quot;, ctx)

      // Fetch the tool&#039;s input schema
      inputschema, err := tool.InputSchema()

      var paramsSchema map[string]any
      _ = json.Unmarshal(inputschema, &amp;paramsSchema)

      // Use this tool with LangChainGo
      langChainTool := llms.Tool{
        Type: &quot;function&quot;,
        Function: &amp;llms.FunctionDefinition{
          Name:        tool.Name(),
          Description: tool.Description(),
          Parameters:  paramsSchema,
        },
      }
    }

    ```

  &lt;/details&gt;
  &lt;details&gt;
    &lt;summary&gt;Genkit&lt;/summary&gt;

1. Install [Toolbox Go SDK][toolbox-go]:

    ```bash
    go get github.com/googleapis/mcp-toolbox-sdk-go
    ```

2. Load tools:

    ```go
    package main
    import (
      &quot;context&quot;
      &quot;log&quot;

      &quot;github.com/firebase/genkit/go/genkit&quot;
      &quot;github.com/googleapis/mcp-toolbox-sdk-go/core&quot;
      &quot;github.com/googleapis/mcp-toolbox-sdk-go/tbgenkit&quot;
    )

    func main() {
      // Make sure to add the erro

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[VictoriaMetrics/VictoriaMetrics]]></title>
            <link>https://github.com/VictoriaMetrics/VictoriaMetrics</link>
            <guid>https://github.com/VictoriaMetrics/VictoriaMetrics</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:08 GMT</pubDate>
            <description><![CDATA[VictoriaMetrics: fast, cost-effective monitoring solution and time series database]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/VictoriaMetrics/VictoriaMetrics">VictoriaMetrics/VictoriaMetrics</a></h1>
            <p>VictoriaMetrics: fast, cost-effective monitoring solution and time series database</p>
            <p>Language: Go</p>
            <p>Stars: 16,323</p>
            <p>Forks: 1,570</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># VictoriaMetrics

[![Latest Release](https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaMetrics?sort=semver&amp;label=&amp;filter=!*-victorialogs&amp;logo=github&amp;labelColor=gray&amp;color=gray&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Freleases%2Flatest)](https://github.com/VictoriaMetrics/VictoriaMetrics/releases)
![Docker Pulls](https://img.shields.io/docker/pulls/victoriametrics/victoria-metrics?label=&amp;logo=docker&amp;logoColor=white&amp;labelColor=2496ED&amp;color=2496ED&amp;link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-metrics)
[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaMetrics?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics)](https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaMetrics)
[![Build Status](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml/badge.svg?branch=master&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Factions)](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml)
[![codecov](https://codecov.io/gh/VictoriaMetrics/VictoriaMetrics/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaMetrics)](https://app.codecov.io/gh/VictoriaMetrics/VictoriaMetrics)
[![License](https://img.shields.io/github/license/VictoriaMetrics/VictoriaMetrics?labelColor=green&amp;label=&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Fblob%2Fmaster%2FLICENSE)](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/LICENSE)
![Slack](https://img.shields.io/badge/Join-4A154B?logo=slack&amp;link=https%3A%2F%2Fslack.victoriametrics.com)
[![X](https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&amp;label=Follow&amp;color=black&amp;logo=x&amp;labelColor=black&amp;link=https%3A%2F%2Fx.com%2FVictoriaMetrics)](https://x.com/VictoriaMetrics/)
[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&amp;label=Join&amp;labelColor=red&amp;logoColor=white&amp;logo=reddit&amp;link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics)](https://www.reddit.com/r/VictoriaMetrics/)

&lt;picture&gt;
  &lt;source srcset=&quot;docs/victoriametrics/logo_white.webp&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
  &lt;source srcset=&quot;docs/victoriametrics/logo.webp&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
  &lt;img src=&quot;docs/victoriametrics/logo.webp&quot; width=&quot;300&quot; alt=&quot;VictoriaMetrics logo&quot;&gt;
&lt;/picture&gt;

VictoriaMetrics is a fast, cost-effective, and scalable solution for monitoring and managing time series data. It delivers high performance and reliability, making it an ideal choice for businesses of all sizes.

Here are some resources and information about VictoriaMetrics:

- **Case studies**: [Grammarly, Roblox, Wix, Spotify,...](https://docs.victoriametrics.com/victoriametrics/casestudies/).
- **Available**: [Binary releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest), Docker images on [Docker Hub](https://hub.docker.com/r/victoriametrics/victoria-metrics/) and [Quay](https://quay.io/repository/victoriametrics/victoria-metrics), [Source code](https://github.com/VictoriaMetrics/VictoriaMetrics).
- **Deployment types**: [Single-node version](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/) and [Cluster version](https://docs.victoriametrics.com/victoriametrics/cluster-victoriametrics/) under [Apache License 2.0](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/LICENSE).
- **Getting started:** Read [key concepts](https://docs.victoriametrics.com/victoriametrics/keyconcepts/) and follow the
  [quick start guide](https://docs.victoriametrics.com/victoriametrics/quick-start/).
- **Community**: [Slack](https://slack.victoriametrics.com/) (join via [Slack Inviter](https://slack.victoriametrics.com/)), [X (Twitter)](https://x.com/VictoriaMetrics), [YouTube](https://www.youtube.com/@VictoriaMetrics). See full list [here](https://docs.victoriametrics.com/victoriametrics/#community-and-contributions).
- **Changelog**: Project evolves fast - check the [CHANGELOG](https://docs.victoriametrics.com/victoriametrics/changelog/), and [How to upgrade](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-upgrade-victoriametrics).
- **Enterprise support:** [Contact us](mailto:info@victoriametrics.com) for commercial support with additional [enterprise features](https://docs.victoriametrics.com/victoriametrics/enterprise/).
- **Enterprise releases:** Enterprise and [long-term support releases (LTS)](https://docs.victoriametrics.com/victoriametrics/lts-releases/) are publicly available and can be evaluated for free
  using a [free trial license](https://victoriametrics.com/products/enterprise/trial/).
- **Security:** we achieved [security certifications](https://victoriametrics.com/security/) for Database Software Development and Software-Based Monitoring Services.

Yes, we open-source both the single-node VictoriaMetrics and the cluster version.

## Prominent features

VictoriaMetrics is optimized for timeseries data, even when old time series are constantly replaced by new ones at a high rate, it offers a lot of features:

* **Long-term storage for Prometheus** or as a drop-in replacement for Prometheus and Graphite in Grafana.
* **Powerful stream aggregation**: Can be used as a StatsD alternative.
* **Ideal for big data**: Works well with large amounts of time series data from APM, Kubernetes, IoT sensors, connected cars, industrial telemetry, financial data and various [Enterprise workloads](https://docs.victoriametrics.com/victoriametrics/enterprise/).
* **Query language**: Supports both PromQL and the more performant MetricsQL.
* **Easy to setup**: No dependencies, single [small binary](https://medium.com/@valyala/stripping-dependency-bloat-in-victoriametrics-docker-image-983fb5912b0d), configuration through command-line flags, but the default is also fine-tuned; backup and restore with [instant snapshots](https://medium.com/@valyala/how-victoriametrics-makes-instant-snapshots-for-multi-terabyte-time-series-data-e1f3fb0e0282).
* **Global query view**: Multiple Prometheus instances or any other data sources may ingest data into VictoriaMetrics and queried via a single query.
* **Various Protocols**: Support metric scraping, ingestion and backfilling in various protocol.
    * [Prometheus exporters](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-scrape-prometheus-exporters-such-as-node-exporter), [Prometheus remote write API](https://docs.victoriametrics.com/victoriametrics/integrations/prometheus/), [Prometheus exposition format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-prometheus-exposition-format).
    * [InfluxDB line protocol](https://docs.victoriametrics.com/victoriametrics/integrations/influxdb/) over HTTP, TCP and UDP.
    * [Graphite plaintext protocol](https://docs.victoriametrics.com/victoriametrics/integrations/graphite/#ingesting) with [tags](https://graphite.readthedocs.io/en/latest/tags.html#carbon).
    * [OpenTSDB put message](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-telnet).
    * [HTTP OpenTSDB /api/put requests](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-http).
    * [JSON line format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-json-line-format).
    * [Arbitrary CSV data](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-csv-data).
    * [Native binary format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-native-format).
    * [DataDog agent or DogStatsD](https://docs.victoriametrics.com/victoriametrics/integrations/datadog/).
    * [NewRelic infrastructure agent](https://docs.victoriametrics.com/victoriametrics/integrations/newrelic/#sending-data-from-agent).
    * [OpenTelemetry metrics format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#sending-data-via-opentelemetry).
* **NFS-based storages**: Supports storing data on NFS-based storages such as Amazon EFS, Google Filestore.
* And many other features such as metrics relabeling, cardinality limiter, etc.

## Enterprise version

In addition, the Enterprise version includes extra features:

- **Anomaly detection**: Automation and simplification of your alerting rules, covering complex anomalies found in metrics data.
- **Backup automation**: Automates regular backup procedures.
- **Multiple retentions**: Reducing storage costs by specifying different retentions for different datasets.
- **Downsampling**: Reducing storage costs and increasing performance for queries over historical data.
- **Stable releases** with long-term support lines ([LTS](https://docs.victoriametrics.com/victoriametrics/lts-releases/)).
- **Comprehensive support**: First-class consulting, feature requests and technical support provided by the core VictoriaMetrics dev team.
- Many other features, which you can read about on [the Enterprise page](https://docs.victoriametrics.com/victoriametrics/enterprise/).

[Contact us](mailto:info@victoriametrics.com) if you need enterprise support for VictoriaMetrics. Or you can request a free trial license [here](https://victoriametrics.com/products/enterprise/trial/), downloaded Enterprise binaries are available at [Github Releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest).

We strictly apply security measures in everything we do. VictoriaMetrics has achieved security certifications for Database Software Development and Software-Based Monitoring Services. See [Security page](https://victoriametrics.com/security/) for more details.

## Benchmarks 

Some good benchmarks VictoriaMetrics achieved:

* **Minimal memory footprint**: handling millions of unique timeseries with [10x less RAM](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) than InfluxDB, up to [7x less RAM](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) than Prometheus, Thanos or Cortex.
* **Highly scalable and performance** for [data ingestion](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and [querying](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4), [20x outperforms](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) InfluxDB and TimescaleDB.
* **High data compression**: [70x more data points](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4) may be stored into limited storage than TimescaleDB, [7x less storage](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) space is required than Prometheus, Thanos or Cortex.
* **Reducing storage costs**: [10x more effective](https://docs.victoriametrics.com/victoriametrics/casestudies/#grammarly) than Graphite according to the Grammarly case study.
* **A single-node VictoriaMetrics** can replace medium-sized clusters built with competing solutions such as Thanos, M3DB, Cortex, InfluxDB or TimescaleDB. See [VictoriaMetrics vs Thanos](https://medium.com/@valyala/comparing-thanos-to-victoriametrics-cluster-b193bea1683), [Measuring vertical scalability](https://medium.com/@valyala/measuring-vertical-scalability-for-time-series-databases-in-google-cloud-92550d78d8ae), [Remote write storage wars - PromCon 2019](https://promcon.io/2019-munich/talks/remote-write-storage-wars/).
* **Optimized for storage**: [Works well with high-latency IO](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and low IOPS (HDD and network storage in AWS, Google Cloud, Microsoft Azure, etc.).

## Community and contributions

Feel free asking any questions regarding VictoriaMetrics:

* [Slack Inviter](https://slack.victoriametrics.com/) and [Slack channel](https://victoriametrics.slack.com/)
* [X (Twitter)](https://x.com/VictoriaMetrics/)
* [Linkedin](https://www.linkedin.com/company/victoriametrics/)
* [Reddit](https://www.reddit.com/r/VictoriaMetrics/)
* [Telegram-en](https://t.me/VictoriaMetrics_en)
* [Telegram-ru](https://t.me/VictoriaMetrics_ru1)
* [Mastodon](https://mastodon.social/@victoriametrics/)

If you like VictoriaMetrics and want to contribute, then please [read these docs](https://docs.victoriametrics.com/victoriametrics/contributing/).

## VictoriaMetrics Logo

The provided [ZIP file](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/VM_logo.zip) contains three folders with different logo orientations. Each folder includes the following file types:

* JPEG: Preview files
* PNG: Preview files with transparent background
* AI: Adobe Illustrator files

### VictoriaMetrics Logo Usage Guidelines

#### Font

* Font Used: Lato Black
* Download here: [Lato Font](https://fonts.google.com/specimen/Lato)

#### Color Palette

* Black [#000000](https://www.color-hex.com/color/000000)
* Purple [#4d0e82](https://www.color-hex.com/color/4d0e82)
* Orange [#ff2e00](https://www.color-hex.com/color/ff2e00)
* White [#ffffff](https://www.color-hex.com/color/ffffff)

### Logo Usage Rules

* Only use the Lato Black font as specified.
* Maintain sufficient clear space around the logo for visibility.
* Do not modify the spacing, alignment, or positioning of design elements.
* You may resize the logo as needed, but ensure all proportions remain intact.

Thank you for your cooperation!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[charmbracelet/lipgloss]]></title>
            <link>https://github.com/charmbracelet/lipgloss</link>
            <guid>https://github.com/charmbracelet/lipgloss</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:07 GMT</pubDate>
            <description><![CDATA[Style definitions for nice terminal layouts üëÑ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/charmbracelet/lipgloss">charmbracelet/lipgloss</a></h1>
            <p>Style definitions for nice terminal layouts üëÑ</p>
            <p>Language: Go</p>
            <p>Stars: 10,549</p>
            <p>Forks: 310</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># Lip Gloss

&lt;p&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://stuff.charm.sh/lipgloss/lip-gloss-light-2025-06.png&quot; width=&quot;340&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://stuff.charm.sh/lipgloss/lip-gloss-dark-2025-06.png&quot; width=&quot;340&quot;&gt;
      &lt;img src=&quot;https://stuff.charm.sh/lipgloss/lip-gloss-light-2025-06.png&quot; width=&quot;340&quot; /&gt;
    &lt;/picture&gt;
    &lt;br&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/lipgloss/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/charmbracelet/lipgloss.svg&quot; alt=&quot;Latest Release&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://pkg.go.dev/github.com/charmbracelet/lipgloss?tab=doc&quot;&gt;&lt;img src=&quot;https://godoc.org/github.com/golang/gddo?status.svg&quot; alt=&quot;GoDoc&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/lipgloss/actions&quot;&gt;&lt;img src=&quot;https://github.com/charmbracelet/lipgloss/workflows/build/badge.svg&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Style definitions for nice terminal layouts. Built with TUIs in mind.

![Lip Gloss example](https://github.com/user-attachments/assets/92560e60-d70e-4ce0-b39e-a60bb933356b)

Lip Gloss takes an expressive, declarative approach to terminal rendering.
Users familiar with CSS will feel at home with Lip Gloss.

```go

import &quot;github.com/charmbracelet/lipgloss&quot;

var style = lipgloss.NewStyle().
    Bold(true).
    Foreground(lipgloss.Color(&quot;#FAFAFA&quot;)).
    Background(lipgloss.Color(&quot;#7D56F4&quot;)).
    PaddingTop(2).
    PaddingLeft(4).
    Width(22)

fmt.Println(style.Render(&quot;Hello, kitty&quot;))
```

## Colors

Lip Gloss supports the following color profiles:

### ANSI 16 colors (4-bit)

```go
lipgloss.Color(&quot;5&quot;)  // magenta
lipgloss.Color(&quot;9&quot;)  // red
lipgloss.Color(&quot;12&quot;) // light blue
```

### ANSI 256 Colors (8-bit)

```go
lipgloss.Color(&quot;86&quot;)  // aqua
lipgloss.Color(&quot;201&quot;) // hot pink
lipgloss.Color(&quot;202&quot;) // orange
```

### True Color (16,777,216 colors; 24-bit)

```go
lipgloss.Color(&quot;#0000FF&quot;) // good ol&#039; 100% blue
lipgloss.Color(&quot;#04B575&quot;) // a green
lipgloss.Color(&quot;#3C3C3C&quot;) // a dark gray
```

...as well as a 1-bit ASCII profile, which is black and white only.

The terminal&#039;s color profile will be automatically detected, and colors outside
the gamut of the current palette will be automatically coerced to their closest
available value.

### Adaptive Colors

You can also specify color options for light and dark backgrounds:

```go
lipgloss.AdaptiveColor{Light: &quot;236&quot;, Dark: &quot;248&quot;}
```

The terminal&#039;s background color will automatically be detected and the
appropriate color will be chosen at runtime.

### Complete Colors

CompleteColor specifies exact values for True Color, ANSI256, and ANSI color
profiles.

```go
lipgloss.CompleteColor{TrueColor: &quot;#0000FF&quot;, ANSI256: &quot;86&quot;, ANSI: &quot;5&quot;}
```

Automatic color degradation will not be performed in this case and it will be
based on the color specified.

### Complete Adaptive Colors

You can use `CompleteColor` with `AdaptiveColor` to specify the exact values for
light and dark backgrounds without automatic color degradation.

```go
lipgloss.CompleteAdaptiveColor{
    Light: CompleteColor{TrueColor: &quot;#d7ffae&quot;, ANSI256: &quot;193&quot;, ANSI: &quot;11&quot;},
    Dark:  CompleteColor{TrueColor: &quot;#d75fee&quot;, ANSI256: &quot;163&quot;, ANSI: &quot;5&quot;},
}
```

## Inline Formatting

Lip Gloss supports the usual ANSI text formatting options:

```go
var style = lipgloss.NewStyle().
    Bold(true).
    Italic(true).
    Faint(true).
    Blink(true).
    Strikethrough(true).
    Underline(true).
    Reverse(true)
```

## Block-Level Formatting

Lip Gloss also supports rules for block-level formatting:

```go
// Padding
var style = lipgloss.NewStyle().
    PaddingTop(2).
    PaddingRight(4).
    PaddingBottom(2).
    PaddingLeft(4)

// Margins
var style = lipgloss.NewStyle().
    MarginTop(2).
    MarginRight(4).
    MarginBottom(2).
    MarginLeft(4)
```

There is also shorthand syntax for margins and padding, which follows the same
format as CSS:

```go
// 2 cells on all sides
lipgloss.NewStyle().Padding(2)

// 2 cells on the top and bottom, 4 cells on the left and right
lipgloss.NewStyle().Margin(2, 4)

// 1 cell on the top, 4 cells on the sides, 2 cells on the bottom
lipgloss.NewStyle().Padding(1, 4, 2)

// Clockwise, starting from the top: 2 cells on the top, 4 on the right, 3 on
// the bottom, and 1 on the left
lipgloss.NewStyle().Margin(2, 4, 3, 1)
```

## Aligning Text

You can align paragraphs of text to the left, right, or center.

```go
var style = lipgloss.NewStyle().
    Width(24).
    Align(lipgloss.Left).  // align it left
    Align(lipgloss.Right). // no wait, align it right
    Align(lipgloss.Center) // just kidding, align it in the center
```

## Width and Height

Setting a minimum width and height is simple and straightforward.

```go
var style = lipgloss.NewStyle().
    SetString(&quot;What‚Äôs for lunch?&quot;).
    Width(24).
    Height(32).
    Foreground(lipgloss.Color(&quot;63&quot;))
```

## Borders

Adding borders is easy:

```go
// Add a purple, rectangular border
var style = lipgloss.NewStyle().
    BorderStyle(lipgloss.NormalBorder()).
    BorderForeground(lipgloss.Color(&quot;63&quot;))

// Set a rounded, yellow-on-purple border to the top and left
var anotherStyle = lipgloss.NewStyle().
    BorderStyle(lipgloss.RoundedBorder()).
    BorderForeground(lipgloss.Color(&quot;228&quot;)).
    BorderBackground(lipgloss.Color(&quot;63&quot;)).
    BorderTop(true).
    BorderLeft(true)

// Make your own border
var myCuteBorder = lipgloss.Border{
    Top:         &quot;._.:*:&quot;,
    Bottom:      &quot;._.:*:&quot;,
    Left:        &quot;|*&quot;,
    Right:       &quot;|*&quot;,
    TopLeft:     &quot;*&quot;,
    TopRight:    &quot;*&quot;,
    BottomLeft:  &quot;*&quot;,
    BottomRight: &quot;*&quot;,
}
```

There are also shorthand functions for defining borders, which follow a similar
pattern to the margin and padding shorthand functions.

```go
// Add a thick border to the top and bottom
lipgloss.NewStyle().
    Border(lipgloss.ThickBorder(), true, false)

// Add a double border to the top and left sides. Rules are set clockwise
// from top.
lipgloss.NewStyle().
    Border(lipgloss.DoubleBorder(), true, false, false, true)
```

For more on borders see [the docs][docs].

## Copying Styles

Just use assignment:

```go
style := lipgloss.NewStyle().Foreground(lipgloss.Color(&quot;219&quot;))

copiedStyle := style // this is a true copy

wildStyle := style.Blink(true) // this is also true copy, with blink added

```

Since `Style` data structures contains only primitive types, assigning a style
to another effectively creates a new copy of the style without mutating the
original.

## Inheritance

Styles can inherit rules from other styles. When inheriting, only unset rules
on the receiver are inherited.

```go
var styleA = lipgloss.NewStyle().
    Foreground(lipgloss.Color(&quot;229&quot;)).
    Background(lipgloss.Color(&quot;63&quot;))

// Only the background color will be inherited here, because the foreground
// color will have been already set:
var styleB = lipgloss.NewStyle().
    Foreground(lipgloss.Color(&quot;201&quot;)).
    Inherit(styleA)
```

## Unsetting Rules

All rules can be unset:

```go
var style = lipgloss.NewStyle().
    Bold(true).                        // make it bold
    UnsetBold().                       // jk don&#039;t make it bold
    Background(lipgloss.Color(&quot;227&quot;)). // yellow background
    UnsetBackground()                  // never mind
```

When a rule is unset, it won&#039;t be inherited or copied.

## Enforcing Rules

Sometimes, such as when developing a component, you want to make sure style
definitions respect their intended purpose in the UI. This is where `Inline`
and `MaxWidth`, and `MaxHeight` come in:

```go
// Force rendering onto a single line, ignoring margins, padding, and borders.
someStyle.Inline(true).Render(&quot;yadda yadda&quot;)

// Also limit rendering to five cells
someStyle.Inline(true).MaxWidth(5).Render(&quot;yadda yadda&quot;)

// Limit rendering to a 5x5 cell block
someStyle.MaxWidth(5).MaxHeight(5).Render(&quot;yadda yadda&quot;)
```

## Tabs

The tab character (`\t`) is rendered differently in different terminals (often
as 8 spaces, sometimes 4). Because of this inconsistency, Lip Gloss converts
tabs to 4 spaces at render time. This behavior can be changed on a per-style
basis, however:

```go
style := lipgloss.NewStyle() // tabs will render as 4 spaces, the default
style = style.TabWidth(2)    // render tabs as 2 spaces
style = style.TabWidth(0)    // remove tabs entirely
style = style.TabWidth(lipgloss.NoTabConversion) // leave tabs intact
```

## Rendering

Generally, you just call the `Render(string...)` method on a `lipgloss.Style`:

```go
style := lipgloss.NewStyle().Bold(true).SetString(&quot;Hello,&quot;)
fmt.Println(style.Render(&quot;kitty.&quot;)) // Hello, kitty.
fmt.Println(style.Render(&quot;puppy.&quot;)) // Hello, puppy.
```

But you could also use the Stringer interface:

```go
var style = lipgloss.NewStyle().SetString(&quot;‰Ω†Â•ΩÔºåÁå´Âí™„ÄÇ&quot;).Bold(true)
fmt.Println(style) // ‰Ω†Â•ΩÔºåÁå´Âí™„ÄÇ
```

### Custom Renderers

Custom renderers allow you to render to a specific outputs. This is
particularly important when you want to render to different outputs and
correctly detect the color profile and dark background status for each, such as
in a server-client situation.

```go
func myLittleHandler(sess ssh.Session) {
    // Create a renderer for the client.
    renderer := lipgloss.NewRenderer(sess)

    // Create a new style on the renderer.
    style := renderer.NewStyle().Background(lipgloss.AdaptiveColor{Light: &quot;63&quot;, Dark: &quot;228&quot;})

    // Render. The color profile and dark background state will be correctly detected.
    io.WriteString(sess, style.Render(&quot;Heyyyyyyy&quot;))
}
```

For an example on using a custom renderer over SSH with [Wish][wish] see the
[SSH example][ssh-example].

## Utilities

In addition to pure styling, Lip Gloss also ships with some utilities to help
assemble your layouts.

### Joining Paragraphs

Horizontally and vertically joining paragraphs is a cinch.

```go
// Horizontally join three paragraphs along their bottom edges
lipgloss.JoinHorizontal(lipgloss.Bottom, paragraphA, paragraphB, paragraphC)

// Vertically join two paragraphs along their center axes
lipgloss.JoinVertical(lipgloss.Center, paragraphA, paragraphB)

// Horizontally join three paragraphs, with the shorter ones aligning 20%
// from the top of the tallest
lipgloss.JoinHorizontal(0.2, paragraphA, paragraphB, paragraphC)
```

### Measuring Width and Height

Sometimes you‚Äôll want to know the width and height of text blocks when building
your layouts.

```go
// Render a block of text.
var style = lipgloss.NewStyle().
    Width(40).
    Padding(2)
var block string = style.Render(someLongString)

// Get the actual, physical dimensions of the text block.
width := lipgloss.Width(block)
height := lipgloss.Height(block)

// Here&#039;s a shorthand function.
w, h := lipgloss.Size(block)
```

### Placing Text in Whitespace

Sometimes you‚Äôll simply want to place a block of text in whitespace.

```go
// Center a paragraph horizontally in a space 80 cells wide. The height of
// the block returned will be as tall as the input paragraph.
block := lipgloss.PlaceHorizontal(80, lipgloss.Center, fancyStyledParagraph)

// Place a paragraph at the bottom of a space 30 cells tall. The width of
// the text block returned will be as wide as the input paragraph.
block := lipgloss.PlaceVertical(30, lipgloss.Bottom, fancyStyledParagraph)

// Place a paragraph in the bottom right corner of a 30x80 cell space.
block := lipgloss.Place(30, 80, lipgloss.Right, lipgloss.Bottom, fancyStyledParagraph)
```

You can also style the whitespace. For details, see [the docs][docs].

## Rendering Tables

Lip Gloss ships with a table rendering sub-package.

```go
import &quot;github.com/charmbracelet/lipgloss/table&quot;
```

Define some rows of data.

```go
rows := [][]string{
    {&quot;Chinese&quot;, &quot;ÊÇ®Â•Ω&quot;, &quot;‰Ω†Â•Ω&quot;},
    {&quot;Japanese&quot;, &quot;„Åì„Çì„Å´„Å°„ÅØ&quot;, &quot;„ÇÑ„ÅÇ&quot;},
    {&quot;Arabic&quot;, &quot;ÿ£ŸáŸÑŸäŸÜ&quot;, &quot;ÿ£ŸáŸÑÿß&quot;},
    {&quot;Russian&quot;, &quot;–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ&quot;, &quot;–ü—Ä–∏–≤–µ—Ç&quot;},
    {&quot;Spanish&quot;, &quot;Hola&quot;, &quot;¬øQu√© tal?&quot;},
}
```

Use the table package to style and render the table.

```go
var (
    purple    = lipgloss.Color(&quot;99&quot;)
    gray      = lipgloss.Color(&quot;245&quot;)
    lightGray = lipgloss.Color(&quot;241&quot;)

    headerStyle  = lipgloss.NewStyle().Foreground(purple).Bold(true).Align(lipgloss.Center)
    cellStyle    = lipgloss.NewStyle().Padding(0, 1).Width(14)
    oddRowStyle  = cellStyle.Foreground(gray)
    evenRowStyle = cellStyle.Foreground(lightGray)
)

t := table.New().
    Border(lipgloss.NormalBorder()).
    BorderStyle(lipgloss.NewStyle().Foreground(purple)).
    StyleFunc(func(row, col int) lipgloss.Style {
        switch {
        case row == table.HeaderRow:
            return headerStyle
        case row%2 == 0:
            return evenRowStyle
        default:
            return oddRowStyle
        }
    }).
    Headers(&quot;LANGUAGE&quot;, &quot;FORMAL&quot;, &quot;INFORMAL&quot;).
    Rows(rows...)

// You can also add tables row-by-row
t.Row(&quot;English&quot;, &quot;You look absolutely fabulous.&quot;, &quot;How&#039;s it going?&quot;)
```

Print the table.

```go
fmt.Println(t)
```

![Table Example](https://github.com/charmbracelet/lipgloss/assets/42545625/6e4b70c4-f494-45da-a467-bdd27df30d5d)

&gt; [!WARNING]
&gt; Table `Rows` need to be declared before `Offset` otherwise it does nothing.

### Table Borders

There are helpers to generate tables in markdown or ASCII style:

#### Markdown Table

```go
table.New().Border(lipgloss.MarkdownBorder()).BorderTop(false).BorderBottom(false)
```

```
| LANGUAGE |    FORMAL    | INFORMAL  |
|----------|--------------|-----------|
| Chinese  | N«ên h«éo      | N«ê h«éo    |
| French   | Bonjour      | Salut     |
| Russian  | Zdravstvuyte | Privet    |
| Spanish  | Hola         | ¬øQu√© tal? |
```

#### ASCII Table

```go
table.New().Border(lipgloss.ASCIIBorder())
```

```
+----------+--------------+-----------+
| LANGUAGE |    FORMAL    | INFORMAL  |
+----------+--------------+-----------+
| Chinese  | N«ên h«éo      | N«ê h«éo    |
| French   | Bonjour      | Salut     |
| Russian  | Zdravstvuyte | Privet    |
| Spanish  | Hola         | ¬øQu√© tal? |
+----------+--------------+-----------+
```

For more on tables see [the docs](https://pkg.go.dev/github.com/charmbracelet/lipgloss?tab=doc) and [examples](https://github.com/charmbracelet/lipgloss/tree/master/examples/table).

## Rendering Lists

Lip Gloss ships with a list rendering sub-package.

```go
import &quot;github.com/charmbracelet/lipgloss/list&quot;
```

Define a new list.

```go
l := list.New(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)
```

Print the list.

```go
fmt.Println(l)

// ‚Ä¢ A
// ‚Ä¢ B
// ‚Ä¢ C
```

Lists have the ability to nest.

```go
l := list.New(
    &quot;A&quot;, list.New(&quot;Artichoke&quot;),
    &quot;B&quot;, list.New(&quot;Baking Flour&quot;, &quot;Bananas&quot;, &quot;Barley&quot;, &quot;Bean Sprouts&quot;),
    &quot;C&quot;, list.New(&quot;Cashew Apple&quot;, &quot;Cashews&quot;, &quot;Coconut Milk&quot;, &quot;Curry Paste&quot;, &quot;Currywurst&quot;),
    &quot;D&quot;, list.New(&quot;Dill&quot;, &quot;Dragonfruit&quot;, &quot;Dried Shrimp&quot;),
    &quot;E&quot;, list.New(&quot;Eggs&quot;),
    &quot;F&quot;, list.New(&quot;Fish Cake&quot;, &quot;Furikake&quot;),
    &quot;J&quot;, list.New(&quot;Jicama&quot;),
    &quot;K&quot;, list.New(&quot;Kohlrabi&quot;),
    &quot;L&quot;, list.New(&quot;Leeks&quot;, &quot;Lentils&quot;, &quot;Licorice Root&quot;),
)
```

Print the list.

```go
fmt.Println(l)
```

&lt;p align=&quot;center&quot;&gt;
&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;https://github.com/charmbracelet/lipgloss/assets/42545625/0dc9f440-0748-4151-a3b0-7dcf29dfcdb0&quot;&gt;
&lt;/p&gt;

Lists can be customized via their enumeration function as well as using
`lipgloss.Style`s.

```go
enumeratorStyle := lipgloss.NewStyle().Foreground(lipgloss.Color(&quot;99&quot;)).MarginRight(1)
itemStyle := lipgloss.NewStyle().Foreground(lipgloss.Color(&quot;212&quot;)).MarginRight(1)

l := list.New(
    &quot;Glossier&quot;,
    &quot;Claire‚Äôs Boutique&quot;,
    &quot;Nyx&quot;,
    &quot;Mac&quot;,
    &quot;Milk&quot;,
    ).
    Enumerator(list.Roman).
    EnumeratorStyle(enumeratorStyle).
    ItemStyle(itemStyle)
```

Print the list.

&lt;p align=&quot;center&quot;&gt;
&lt;img width=&quot;600&quot; alt=&quot;List example&quot; src=&quot;https://github.com/charmbracelet/lipgloss/assets/42545625/360494f1-57fb-4e13-bc19-0006efe01561&quot;&gt;
&lt;/p&gt;

In addition to the predefined enumerators (`Arabic`, `Alphabet`, `Roman`, `Bullet`, `Tree`),
you may also define your own custom enumerator:

```go
l := list.New(&quot;Duck&quot;, &quot;Duck&quot;, &quot;Duck&quot;, &quot;Duck&quot;, &quot;Goose&quot;, &quot;Duck&quot;, &quot;Duck&quot;)

func DuckDuckGooseEnumerator(l list.Items, i int) string {
    if l.At(i).Value() == &quot;Goose&quot; {
        return &quot;Honk ‚Üí&quot;
    }
    return &quot;&quot;
}

l = l.Enumerator(DuckDuckGooseEnumerator)
```

Print the list:

&lt;p align=&quot;center&quot;&gt;
&lt;img width=&quot;600&quot; alt=&quot;image&quot; src=&quot;https://github.com/charmbracelet/lipgloss/assets/42545625/157aaf30-140d-4948-9bb4-dfba46e5b87e&quot;&gt;
&lt;/p&gt;

If you need, you can also build lists incrementally:

```go
l := list.New()

for i := 0; i &lt; repeat; i++ {
    l.Item(&quot;Lip Gloss&quot;)
}
```

## Rendering Trees

Lip Gloss ships with a tree rendering sub-package.

```go
import &quot;github.com/charmbracelet/lipgloss/tree&quot;
```

Define a new tree.

```go
t := tree.Root(&quot;.&quot;).
    Child(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;)
```

Print the tree.

```go
fmt.Println(t)

// .
// ‚îú‚îÄ‚îÄ A
// ‚îú‚îÄ‚îÄ B
// ‚îî‚îÄ‚îÄ C
```

Trees have the ability to nest.

```go
t := tree.Root(&quot;.&quot;).
    Child(&quot;macOS&quot;).
    Child(
        tree.New().
            Root(&quot;Linux&quot;).
            Child(&quot;NixOS&quot;).
            Child(&quot;Arch Linux (btw)&quot;).
            Child(&quot;Void Linux&quot;),
        ).
    Child(
        tree.New().
            Root(&quot;BSD&quot;).
            Child(&quot;FreeBSD&quot;).
            Child(&quot;OpenBSD&quot;),
    )
```

Print the tree.

```go
fmt.Println(t)
```

&lt;p align=&quot;center&quot;&gt;
&lt;img width=&quot;663&quot; alt=&quot;Tree Example (simple)&quot; src=&quot;https://github.com/user-attachments/assets/5ef14eb8-a5d4-4f94-8834-e15d1e714f89&quot;&gt;
&lt;/p&gt;

Trees can be customized via their enumeration function as well as using
`lipgloss.Style`s.

```go
enumeratorStyle := lipgloss.NewStyle().Foreground(lipgloss.Color(&quot;63&quot;)).MarginRight(1)
rootStyle := lipgloss.NewStyle().Foreground(lipgloss.Color(&quot;35&quot;))
itemStyle := lipgloss.NewStyle().Foreground(lipgloss.Color(&quot;212&quot;))

t := tree.
    Root(&quot;‚Åú Makeup&quot;).
    Child(
        &quot;Glossier&quot;,
        &quot;Fenty Beauty&quot;,
        tree.New().Child(
            &quot;Gloss Bomb Universal Lip Luminizer&quot;,
            &quot;Hot Cheeks Velour Blushlighter&quot;,
        ),
        &quot;Nyx&quot;,
        &quot;Mac&quot;,
        &quot;Milk&quot;,
    ).
    Enumerator(tree.RoundedEnumerator).
    EnumeratorStyle(enumeratorStyle).
    RootStyle(rootStyle).
    ItemStyle(itemStyle)
```

Print the tree.

&lt;p align=&quot;center&quot;&gt;
&lt;img width=&quot;663&quot; alt=&quot;Tree Example (makeup)&quot; src=&quot;https://github.com/user-attachments/assets/06d12d87-744a-4c89-bd98-45de9094a97e&quot;&gt;
&lt;/p&gt;

The predefined enumerators for trees are `DefaultEnumerator` and `RoundedEnumerator`.

If you need, you can also build trees incrementally:

```go
t := tree.New()

for i := 0; i &lt; repeat; i++ {
    t.Child(&quot;Lip Gloss&quot;)
}
```

---

## FAQ

&lt;details&gt;
&lt;summary&gt;
Why are things misaligning? Why are borders at the wrong widths?
&lt;/summary&gt;
&lt;p&gt;This is most likely due to your locale and encoding, particularly with
regard to Chinese, Japanese, and Korean (for example, &lt;code&gt;zh_CN.UTF-8&lt;/code&gt;
or &lt;code&gt;ja_JP.UTF-8&lt;/code&gt;). The most direct way to fix this is to set
&lt;code&gt;RUNEWIDTH_EASTASIAN=0&lt;/code&gt; in your environment.&lt;/p&gt;

&lt;p&gt;For details see &lt;a href=&quot;https://github.com/charmbracelet/lipgloss/issues/40&quot;&gt;https://github.com/charmbracelet/lipgloss/issues/40.&lt;/a&gt;&lt;/p&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Why isn&#039;t Lip Gloss displaying colors?
&lt;/summary&gt;
&lt;p&gt;Lip Gloss automatically degrades colors to the best available option in the
given terminal, and if output&#039;s not a TTY it will remove color output entirely.
This is common when running tests, CI, or when piping output elsewhere.&lt;/p&gt;

&lt;p&gt;If necessary, you can force a color profile in your tests with
&lt;a href=&quot;https://pkg.go.dev/github.com/charmbracelet/lipgloss#SetColorProfile&quot;&gt;&lt;code&gt;SetColorProfile&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

```go
import (
    &quot;github.com/charmbracelet/lipgloss&quot;
    &quot;github.com/muesli/termenv&quot;
)

lipgloss.SetColorProfile(termenv.TrueColor)
```

_Note:_ this option limits the flexibility of your application and can cause
ANSI escape codes to be output in cases where that might not be desired. Take
careful note of your use case and environment before choosing to force a color
profile.

&lt;/details&gt;

## What about [Bubble Tea][tea]?

Lip Gloss doesn‚Äôt replace Bubble Tea. Rather, it is an excellent Bubble Tea
companion. It was designed to make assembling terminal u

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[evcc-io/evcc]]></title>
            <link>https://github.com/evcc-io/evcc</link>
            <guid>https://github.com/evcc-io/evcc</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:06 GMT</pubDate>
            <description><![CDATA[solar charging ‚òÄÔ∏èüöò]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/evcc-io/evcc">evcc-io/evcc</a></h1>
            <p>solar charging ‚òÄÔ∏èüöò</p>
            <p>Language: Go</p>
            <p>Stars: 6,151</p>
            <p>Forks: 1,189</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># evcc üöò‚òÄÔ∏è

[![Build](https://github.com/evcc-io/evcc/actions/workflows/nightly.yml/badge.svg)](https://github.com/evcc-io/evcc/actions/workflows/nightly.yml)
[![Translation](https://hosted.weblate.org/widgets/evcc/-/evcc/svg-badge.svg)](https://hosted.weblate.org/engage/evcc/)
![Docker Pulls](https://img.shields.io/docker/pulls/evcc/evcc)
[![OSS hosting by cloudsmith](https://img.shields.io/badge/OSS%20hosting%20by-cloudsmith-blue?logo=cloudsmith)](https://cloudsmith.io/~evcc/packages/)
[![Latest Version](https://img.shields.io/github/release/evcc-io/evcc.svg)](https://github.com/evcc-io/evcc/releases)&lt;br/&gt;
[![Built with Depot](https://depot.dev/badges/built-with-depot.svg)](https://depot.dev/?utm_source=evcc)

evcc is an extensible EV Charge Controller and home energy management system.

![Screenshot](assets/github/screenshot.webp)

Our goal is to provide local energy management, without relying on cloud services.
Featured in [PV Magazine](https://www.pv-magazine.de/2022/01/14/mit-open-source-lademanager-schnittstellen-zu-wallbox-und-photovoltaik-anlage-meistern/) and [c‚Äôt Magazin](https://www.youtube.com/watch?v=MoBpEXHMNjI).

## Features

- simple and clean user interface
- support for many [EV chargers](https://docs.evcc.io/en/docs/devices/chargers):
  - ABB, ABL, Alfen, Alphatec, Amperfied, Ampure, Audi, AUTEL, Autoaid, Bender, BMW, cFos, Charge Amps, Compleo, CUBOS, Cupra, Dadapower, DaheimLaden, Delta, E.ON Drive, E3/DC, Easee, Ebee, echarge, EcoHarmony, Edgetech, Elecq, eledio, Elli, EM2GO, EN+, enercab, Ensto, EntraTek, ESL, eSystems, Etrel, EVBox, Free2Move, Free2move eSolutions, Fronius, Garo, go-e, Hardy Barth, Heidelberg, Hesotec, Homecharge, Huawei, Innogy, INRO, Juice, Kathrein, KEBA, Kontron Solar, Kostal, KSE, LadeFoxx, LRT, Mennekes, NRGkick, OBO Bettermann, OpenEVSE, openWB, Optec, Orbis, PC Electric, Peblar, Phoenix Contact, Plugchoice, Porsche, Pracht, Pulsares, Pulsatrix, Qcells, Schneider, Schrack, SENEC, Siemens, Skoda, SMA, Smartfox, SolarEdge, Solax, Sonnen, Spelsberg, Stark in Strom, Sungrow, TechniSat, Tesla, Tigo, TinkerForge, Ubitricity, V2C Trydan, Vestel, Victron, Viridian EV, Volkswagen, Volt Time, Wallbe, wallbox, Walther Werke, Webasto, Weidm√ºller, Zaptec, ZJ Beny. [Read more.](https://docs.evcc.io/en/docs/devices/chargers)
  - **EEBus** support (Elli, PMCC)
  - **OCPP** support
  - **build-your-own:** Phoenix Contact (includes ESL Walli), EVSE DIN
  - **smart switches:** AVM, FRITZ!, Home Assistant, Homematic IP, HomeWizard, myStrom, Shelly, Tasmota, TP-Link. [Read more.](https://docs.evcc.io/en/docs/devices/smartswitches)
  - **heat pumps and electric heaters:** alpha innotec, Bosch, Buderus, B√∂sch, CTA All-In-One, Daikin, Elco, IDM, Junkers, Kermi, Lambda, my-PV, Nibe, Novelan, Roth, Stiebel Eltron, Tecalor, Vaillant, Viessmann, Wolf, Zewotherm. [Read more.](https://docs.evcc.io/en/docs/devices/heating)
- support for many [energy meters](https://docs.evcc.io/en/docs/devices/meters):
  - **solar inverters and battery systems:** A-Tronix, Acrel, Ads-tec, Alpha ESS, Ampere, Anker, APsystems, AVM, Axitec, BGEtech, Bosch, Bosswerk, Carlo Gavazzi, Deye, E3/DC, Eastron, Enphase, FENECON, FRITZ!, FoxESS, Fronius, Ginlong, go-e, GoodWe, Growatt, Homematic IP, HomeWizard, Hoymiles, Huawei, IAMMETER, IGEN Tech, Kostal, LG, Loxone, M-TEC, Marstek, myStrom, OpenEMS, Powerfox, Qcells, RCT, SAJ, SAX, SENEC, Senergy, Shelly, Siemens, Sigenergy, SMA, Smartfox, SofarSolar, Solaranzeige, SolarEdge, SolarMax, Solarwatt, Solax, Solinteng, Sonnen, St-ems, Steca, Sungrow, Sunsynk, Sunway, Tasmota, Tesla, TP-Link, VARTA, Victron, Wattsonic, Youless, ZCS Azzurro, Zendure. [Read more.](https://docs.evcc.io/en/docs/devices/meters)
  - **general energy meters:** A-Tronix, ABB, Acrel, Alpha ESS, Ampere, AVM, Axitec, Bernecker Engineering, BGEtech, Bosch, Carlo Gavazzi, cFos, Deye, DSMR, DZG, E3/DC, Eastron, Enphase, ESPHome, FENECON, FoxESS, FRITZ!, Fronius, Ginlong, go-e, GoodWe, Growatt, Homematic IP, HomeWizard, Huawei, IAMMETER, inepro, IOmeter, Janitza, KEBA, Kostal, LG, Loxone, M-TEC, mhendriks, my-PV, myStrom, OpenEMS, ORNO, P1Monitor, Powerfox, Qcells, RCT, Saia-Burgess Controls (SBC), SAJ, SAX, Schneider Electric, SENEC, Shelly, Siemens, Sigenergy, SMA, Smartfox, SofarSolar, Solaranzeige, SolarEdge, SolarMax, Solarwatt, Solax, Solinteng, Sonnen, St-ems, Sungrow, Sunsynk, Sunway, Tasmota, Tesla, Tibber, TQ, VARTA, Victron, Volksz√§hler, Wago, Wattsonic, Weidm√ºller, Youless, ZCS Azzurro, Zuidwijk. [Read more.](https://docs.evcc.io/en/docs/devices/meters)
  - **integrated systems**: SMA Sunny Home Manager and Energy Meter, KOSTAL Smart Energy Meter (KSEM, EMxx)
  - **sunspec**-compatible inverter or home battery devices
  - **mbmd**-compatible devices, see [volkszaehler/mbmd](https://github.com/volkszaehler/mbmd#supported-devices) for a complete list
- [vehicle](https://docs.evcc.io/en/docs/devices/vehicles) integrations (state of charge, remote charge, battery and preconditioning status):
  - Aiways, Audi, BMW, Citro√´n, Dacia, DS, Fiat, Ford, Hyundai, Jeep, Kia, Mercedes-Benz, MG, Mini, Nissan, NIU, Opel, Peugeot, Polestar, Renault, Seat, Skoda, Smart, Subaru, Tesla, Toyota, Volkswagen, Volvo, Zero Motorcycles. [Read more.](https://docs.evcc.io/en/docs/devices/vehicles)
  - **services:** OVMS, Tronity, evNotify, ioBroker.bmw, mg2mqtt, mz2mqtt, TeslaLogger, TeslaMate, Tessi, volvo2mqtt
- [plugins](https://docs.evcc.io/en/docs/devices/plugins) for integrating with any charger, smartswitch, heatpump, electric heater, meter, solar- / battery-inverter or vehicle:
  - Modbus, HTTP, MQTT, JavaScript, WebSocket, Go and shell scripts
- status [notifications](https://docs.evcc.io/en/docs/reference/configuration/messaging) using [Telegram](https://telegram.org), [PushOver](https://pushover.net) and [many more](https://containrrr.dev/shoutrrr/)
- logging using [InfluxDB](https://www.influxdata.com) and [Grafana](https://grafana.com/grafana/)
- [REST](https://docs.evcc.io/en/docs/integrations/rest-api) and [MQTT](https://docs.evcc.io/en/docs/integrations/mqtt-api) APIs for integration with home automation systems
- Add-ons for [Home Assistant](https://docs.evcc.io/en/docs/integrations/home-assistant) and [openHAB](https://www.openhab.org/addons/bindings/evcc) (not maintained by the evcc core team)

## Getting Started

You&#039;ll find everything you need in our [documentation](https://docs.evcc.io/en/).

## Contributing

Technical details on how to contribute, how to add translations and how to build evcc from source can be found [here](CONTRIBUTING.md).

[![Weblate Hosted](https://hosted.weblate.org/widgets/evcc/-/evcc/287x66-grey.png)](https://hosted.weblate.org/engage/evcc/)

## Sponsorship

&lt;img src=&quot;assets/github/evcc-gopher.png&quot; align=&quot;right&quot; width=&quot;150&quot; /&gt;

evcc believes in open source software. We&#039;re committed to provide best in class EV charging experience.
Maintaining evcc consumes time and effort. With the vast amount of different devices to support, we depend on community and vendor support to keep evcc alive.

While evcc is open source, we would also like to encourage vendors to provide open source hardware devices, public documentation and support open source projects like ours that provide additional value to otherwise closed hardware. Where this is not the case, evcc requires &quot;sponsor token&quot; to finance ongoing development and support of evcc.

Learn more about our [sponsorship model](https://docs.evcc.io/en/docs/sponsorship).

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

For additional license information regarding fonts, icons, and other assets, please see the [LICENSES](LICENSES/) folder.

**Note:** All sponsor-required components are excluded from the MIT License.
See file license header for details.
If you want to use them in your own project, one evcc sponsorship token is required per evcc instance.
Custom licensing agreements are available - please [contact us](mailto:info@evcc.io) to discuss your specific requirements.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mikefarah/yq]]></title>
            <link>https://github.com/mikefarah/yq</link>
            <guid>https://github.com/mikefarah/yq</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:05 GMT</pubDate>
            <description><![CDATA[yq is a portable command-line YAML, JSON, XML, CSV, TOML, HCL and properties processor]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mikefarah/yq">mikefarah/yq</a></h1>
            <p>yq is a portable command-line YAML, JSON, XML, CSV, TOML, HCL and properties processor</p>
            <p>Language: Go</p>
            <p>Stars: 14,893</p>
            <p>Forks: 743</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># yq

![Build](https://github.com/mikefarah/yq/workflows/Build/badge.svg)  ![Docker Pulls](https://img.shields.io/docker/pulls/mikefarah/yq.svg) ![Github Releases (by Release)](https://img.shields.io/github/downloads/mikefarah/yq/total.svg) ![Go Report](https://goreportcard.com/badge/github.com/mikefarah/yq) ![CodeQL](https://github.com/mikefarah/yq/workflows/CodeQL/badge.svg)


A lightweight and portable command-line YAML, JSON, INI and XML processor. `yq` uses [jq](https://github.com/stedolan/jq) (a popular JSON processor) like syntax but works with yaml files as well as json, kyaml, xml, ini, properties, csv and tsv. It doesn&#039;t yet support everything `jq` does - but it does support the most common operations and functions, and more is being added continuously.

yq is written in Go - so you can download a dependency free binary for your platform and you are good to go! If you prefer there are a variety of package managers that can be used as well as Docker and Podman, all listed below.

## Quick Usage Guide

### Basic Operations

**Read a value:**
```bash
yq &#039;.a.b[0].c&#039; file.yaml
```

**Pipe from STDIN:**
```bash
yq &#039;.a.b[0].c&#039; &lt; file.yaml
```

**Update a yaml file in place:**
```bash
yq -i &#039;.a.b[0].c = &quot;cool&quot;&#039; file.yaml
```

**Update using environment variables:**
```bash
NAME=mike yq -i &#039;.a.b[0].c = strenv(NAME)&#039; file.yaml
```

### Advanced Operations

**Merge multiple files:**
```bash
# merge two files
yq -n &#039;load(&quot;file1.yaml&quot;) * load(&quot;file2.yaml&quot;)&#039;

# merge using globs (note: `ea` evaluates all files at once instead of in sequence)
yq ea &#039;. as $item ireduce ({}; . * $item )&#039; path/to/*.yml
```

**Multiple updates to a yaml file:**
```bash
yq -i &#039;
  .a.b[0].c = &quot;cool&quot; |
  .x.y.z = &quot;foobar&quot; |
  .person.name = strenv(NAME)
&#039; file.yaml
```

**Find and update an item in an array:**
```bash
# Note: requires input file - add your file at the end
yq -i &#039;(.[] | select(.name == &quot;foo&quot;) | .address) = &quot;12 cat st&quot;&#039; data.yaml
```

**Convert between formats:**
```bash
# Convert JSON to YAML (pretty print)
yq -Poy sample.json

# Convert YAML to JSON
yq -o json file.yaml

# Convert XML to YAML
yq -o yaml file.xml
```

See [recipes](https://mikefarah.gitbook.io/yq/recipes) for more examples and the [documentation](https://mikefarah.gitbook.io/yq/) for more information.

Take a look at the discussions for [common questions](https://github.com/mikefarah/yq/discussions/categories/q-a), and [cool ideas](https://github.com/mikefarah/yq/discussions/categories/show-and-tell)

## Install

### [Download the latest binary](https://github.com/mikefarah/yq/releases/latest)

### wget
Use wget to download pre-compiled binaries. Choose your platform and architecture:

**For Linux (example):**
```bash
# Set your platform variables (adjust as needed)
VERSION=v4.2.0
PLATFORM=linux_amd64

# Download compressed binary
wget https://github.com/mikefarah/yq/releases/download/${VERSION}/yq_${PLATFORM}.tar.gz -O - |\
  tar xz &amp;&amp; sudo mv yq_${PLATFORM} /usr/local/bin/yq

# Or download plain binary
wget https://github.com/mikefarah/yq/releases/download/${VERSION}/yq_${PLATFORM} -O /usr/local/bin/yq &amp;&amp;\
    chmod +x /usr/local/bin/yq
```

**Latest version (Linux AMD64):**
```bash
wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/local/bin/yq &amp;&amp;\
    chmod +x /usr/local/bin/yq
```

**Available platforms:** `linux_amd64`, `linux_arm64`, `linux_arm`, `linux_386`, `darwin_amd64`, `darwin_arm64`, `windows_amd64`, `windows_386`, etc.

### MacOS / Linux via Homebrew:
Using [Homebrew](https://brew.sh/)
```
brew install yq
```

### Linux via snap:
```
snap install yq
```

#### Snap notes
`yq` installs with [_strict confinement_](https://docs.snapcraft.io/snap-confinement/6233) in snap, this means it doesn&#039;t have direct access to root files. To read root files you can:

```
sudo cat /etc/myfile | yq &#039;.a.path&#039;
```

And to write to a root file you can either use [sponge](https://linux.die.net/man/1/sponge):
```
sudo cat /etc/myfile | yq &#039;.a.path = &quot;value&quot;&#039; | sudo sponge /etc/myfile
```
or write to a temporary file:
```
sudo cat /etc/myfile | yq &#039;.a.path = &quot;value&quot;&#039; | sudo tee /etc/myfile.tmp
sudo mv /etc/myfile.tmp /etc/myfile
rm /etc/myfile.tmp
```

### Run with Docker or Podman

#### One-time use:
```bash
# Docker - process files in current directory
docker run --rm -v &quot;${PWD}&quot;:/workdir mikefarah/yq &#039;.a.b[0].c&#039; file.yaml

# Podman - same usage as Docker
podman run --rm -v &quot;${PWD}&quot;:/workdir mikefarah/yq &#039;.a.b[0].c&#039; file.yaml
```

**Security note:** You can run `yq` in Docker with restricted privileges:
```bash
docker run --rm --security-opt=no-new-privileges --cap-drop all --network none \
  -v &quot;${PWD}&quot;:/workdir mikefarah/yq &#039;.a.b[0].c&#039; file.yaml
```

#### Pipe data via STDIN:

You&#039;ll need to pass the `-i --interactive` flag to Docker/Podman:

```bash
# Process piped data
docker run -i --rm mikefarah/yq &#039;.this.thing&#039; &lt; myfile.yml

# Same with Podman
podman run -i --rm mikefarah/yq &#039;.this.thing&#039; &lt; myfile.yml
```

#### Run commands interactively:

```bash
docker run --rm -it -v &quot;${PWD}&quot;:/workdir --entrypoint sh mikefarah/yq
```

```bash
podman run --rm -it -v &quot;${PWD}&quot;:/workdir --entrypoint sh mikefarah/yq
```

It can be useful to have a bash function to avoid typing the whole docker command:

```bash
yq() {
  docker run --rm -i -v &quot;${PWD}&quot;:/workdir mikefarah/yq &quot;$@&quot;
}
```

```bash
yq() {
  podman run --rm -i -v &quot;${PWD}&quot;:/workdir mikefarah/yq &quot;$@&quot;
}
```
#### Running as root:

`yq`&#039;s container image no longer runs under root (https://github.com/mikefarah/yq/pull/860). If you&#039;d like to install more things in the container image, or you&#039;re having permissions issues when attempting to read/write files you&#039;ll need to either:


```
docker run --user=&quot;root&quot; -it --entrypoint sh mikefarah/yq
```

```
podman run --user=&quot;root&quot; -it --entrypoint sh mikefarah/yq
```

Or, in your Dockerfile:

```
FROM mikefarah/yq

USER root
RUN apk add --no-cache bash
USER yq
```

#### Missing timezone data
By default, the alpine image yq uses does not include timezone data. If you&#039;d like to use the `tz` operator, you&#039;ll need to include this data:

```
FROM mikefarah/yq

USER root
RUN apk add --no-cache tzdata
USER yq
```

#### Podman with SELinux

If you are using podman with SELinux, you will need to set the shared volume flag `:z` on the volume mount:

```
-v &quot;${PWD}&quot;:/workdir:z
```

### GitHub Action
```
  - name: Set foobar to cool
    uses: mikefarah/yq@master
    with:
      cmd: yq -i &#039;.foo.bar = &quot;cool&quot;&#039; &#039;config.yml&#039;
  - name: Get an entry with a variable that might contain dots or spaces
    id: get_username
    uses: mikefarah/yq@master
    with:
      cmd: yq &#039;.all.children.[&quot;${{ matrix.ip_address }}&quot;].username&#039; ops/inventories/production.yml
  - name: Reuse a variable obtained in another step
    run: echo ${{ steps.get_username.outputs.result }}
```

See https://mikefarah.gitbook.io/yq/usage/github-action for more.

### Go Install:
```
go install github.com/mikefarah/yq/v4@latest
```

## Community Supported Installation methods
As these are supported by the community :heart: - however, they may be out of date with the officially supported releases.

_Please note that the Debian package (previously supported by @rmescandon) is no longer maintained. Please use an alternative installation method._


### X-CMD
Checkout `yq` on x-cmd: https://x-cmd.com/mod/yq

- Instant Results: See the output of your yq filter in real-time.
- Error Handling: Encounter a syntax error? It will display the error message and the results of the closest valid filter

Thanks @edwinjhlee!

### Nix

```
nix profile install nixpkgs#yq-go
```

See [here](https://search.nixos.org/packages?channel=unstable&amp;show=yq-go&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=yq-go)


### Webi

```
webi yq
```

See [webi](https://webinstall.dev/)
Supported by @adithyasunil26 (https://github.com/webinstall/webi-installers/tree/master/yq)

### Arch Linux

```
pacman -S go-yq
```

### Windows:

Using [Chocolatey](https://chocolatey.org)

[![Chocolatey](https://img.shields.io/chocolatey/v/yq.svg)](https://chocolatey.org/packages/yq)
[![Chocolatey](https://img.shields.io/chocolatey/dt/yq.svg)](https://chocolatey.org/packages/yq)
```
choco install yq
```
Supported by @chillum (https://chocolatey.org/packages/yq)

Using [scoop](https://scoop.sh/)
```
scoop install main/yq
```

Using [winget](https://learn.microsoft.com/en-us/windows/package-manager/)
```
winget install --id MikeFarah.yq
```

### MacPorts:
Using [MacPorts](https://www.macports.org/)
```
sudo port selfupdate
sudo port install yq
```
Supported by @herbygillot (https://ports.macports.org/maintainer/github/herbygillot)

### Alpine Linux

Alpine Linux v3.20+ (and Edge):
```
apk add yq-go
```

Alpine Linux up to v3.19:
```
apk add yq
```

Supported by Tuan Hoang (https://pkgs.alpinelinux.org/packages?name=yq-go)

### Flox:

Flox can be used to install yq on Linux, MacOS, and Windows through WSL.

```
flox install yq
```


### MacOS / Linux via gah:
Using [gah](https://github.com/marverix/gah)

```
gah install yq
```

## Features
- [Detailed documentation with many examples](https://mikefarah.gitbook.io/yq/)
- Written in portable go, so you can download a lovely dependency free binary
- Uses similar syntax as `jq` but works with YAML, INI, [JSON](https://mikefarah.gitbook.io/yq/usage/convert) and [XML](https://mikefarah.gitbook.io/yq/usage/xml) files
- Fully supports multi document yaml files
- Supports yaml [front matter](https://mikefarah.gitbook.io/yq/usage/front-matter) blocks (e.g. jekyll/assemble)
- Colorized yaml output
- [Date/Time manipulation and formatting with TZ](https://mikefarah.gitbook.io/yq/operators/datetime)
- [Deep data structures](https://mikefarah.gitbook.io/yq/operators/traverse-read)
- [Sort keys](https://mikefarah.gitbook.io/yq/operators/sort-keys)
- Manipulate yaml [comments](https://mikefarah.gitbook.io/yq/operators/comment-operators), [styling](https://mikefarah.gitbook.io/yq/operators/style), [tags](https://mikefarah.gitbook.io/yq/operators/tag) and [anchors and aliases](https://mikefarah.gitbook.io/yq/operators/anchor-and-alias-operators).
- [Update in place](https://mikefarah.gitbook.io/yq/v/v4.x/commands/evaluate#flags)
- [Complex expressions to select and update](https://mikefarah.gitbook.io/yq/operators/select#select-and-update-matching-values-in-map)
- Keeps yaml formatting and comments when updating (though there are issues with whitespace)
- [Decode/Encode base64 data](https://mikefarah.gitbook.io/yq/operators/encode-decode)
- [Load content from other files](https://mikefarah.gitbook.io/yq/operators/load)
- [Convert to/from json/ndjson](https://mikefarah.gitbook.io/yq/v/v4.x/usage/convert)
- [Convert to/from xml](https://mikefarah.gitbook.io/yq/v/v4.x/usage/xml)
- [Convert to/from hcl (terraform)](https://mikefarah.gitbook.io/yq/v/v4.x/usage/hcl)
- [Convert to/from toml](https://mikefarah.gitbook.io/yq/v/v4.x/usage/toml)
- [Convert to/from properties](https://mikefarah.gitbook.io/yq/v/v4.x/usage/properties)
- [Convert to/from csv/tsv](https://mikefarah.gitbook.io/yq/usage/csv-tsv)
- [General shell completion scripts (bash/zsh/fish/powershell)](https://mikefarah.gitbook.io/yq/v/v4.x/commands/shell-completion)
- [Reduce](https://mikefarah.gitbook.io/yq/operators/reduce) to merge multiple files or sum an array or other fancy things.
- [Github Action](https://mikefarah.gitbook.io/yq/usage/github-action) to use in your automated pipeline (thanks @devorbitus)

## [Usage](https://mikefarah.gitbook.io/yq/)

Check out the [documentation](https://mikefarah.gitbook.io/yq/) for more detailed and advanced usage.

```
Usage:
  yq [flags]
  yq [command]

Examples:

# yq tries to auto-detect the file format based off the extension, and defaults to YAML if it&#039;s unknown (or piping through STDIN)
# Use the &#039;-p/--input-format&#039; flag to specify a format type.
cat file.xml | yq -p xml

# read the &quot;stuff&quot; node from &quot;myfile.yml&quot;
yq &#039;.stuff&#039; &lt; myfile.yml

# update myfile.yml in place
yq -i &#039;.stuff = &quot;foo&quot;&#039; myfile.yml

# print contents of sample.json as idiomatic YAML
yq -P -oy sample.json


Available Commands:
  completion  Generate the autocompletion script for the specified shell
  eval        (default) Apply the expression to each document in each yaml file in sequence
  eval-all    Loads _all_ yaml documents of _all_ yaml files and runs expression once
  help        Help about any command

Flags:
  -C, --colors                          force print with colors
      --csv-auto-parse                  parse CSV YAML/JSON values (default true)
      --csv-separator char              CSV Separator character (default ,)
      --debug-node-info                 debug node info
  -e, --exit-status                     set exit status if there are no matches or null or false is returned
      --expression string               forcibly set the expression argument. Useful when yq argument detection thinks your expression is a file.
      --from-file string                Load expression from specified file.
  -f, --front-matter string             (extract|process) first input as yaml front-matter. Extract will pull out the yaml content, process will run the expression against the yaml content, leaving the remaining data intact
      --header-preprocess               Slurp any header comments and separators before processing expression. (default true)
  -h, --help                            help for yq
  -I, --indent int                      sets indent level for output (default 2)
  -i, --inplace                         update the file in place of first file given.
  -p, --input-format string             [auto|a|yaml|y|json|j|kyaml|ky|props|p|csv|c|tsv|t|xml|x|base64|uri|toml|hcl|h|lua|l|ini|i] parse format for input. (default &quot;auto&quot;)
      --lua-globals                     output keys as top-level global variables
      --lua-prefix string               prefix (default &quot;return &quot;)
      --lua-suffix string               suffix (default &quot;;\n&quot;)
      --lua-unquoted                    output unquoted string keys (e.g. {foo=&quot;bar&quot;})
  -M, --no-colors                       force print with no colors
  -N, --no-doc                          Don&#039;t print document separators (---)
  -0, --nul-output                      Use NUL char to separate values. If unwrap scalar is also set, fail if unwrapped scalar contains NUL char.
  -n, --null-input                      Don&#039;t read input, simply evaluate the expression given. Useful for creating docs from scratch.
  -o, --output-format string            [auto|a|yaml|y|json|j|kyaml|ky|props|p|csv|c|tsv|t|xml|x|base64|uri|toml|hcl|h|shell|s|lua|l|ini|i] output format type. (default &quot;auto&quot;)
  -P, --prettyPrint                     pretty print, shorthand for &#039;... style = &quot;&quot;&#039;
      --properties-array-brackets       use [x] in array paths (e.g. for SpringBoot)
      --properties-separator string     separator to use between keys and values (default &quot; = &quot;)
      --security-disable-env-ops        Disable env related operations.
      --security-disable-file-ops       Disable file related operations (e.g. load)
      --shell-key-separator string      separator for shell variable key paths (default &quot;_&quot;)
  -s, --split-exp string                print each result (or doc) into a file named (exp). [exp] argument must return a string. You can use $index in the expression as the result counter. The necessary directories will be created.
      --split-exp-file string           Use a file to specify the split-exp expression.
      --string-interpolation            Toggles strings interpolation of \(exp) (default true)
      --tsv-auto-parse                  parse TSV YAML/JSON values (default true)
  -r, --unwrapScalar                    unwrap scalar, print the value with no quotes, colors or comments. Defaults to true for yaml (default true)
  -v, --verbose                         verbose mode
  -V, --version                         Print version information and quit
      --xml-attribute-prefix string     prefix for xml attributes (default &quot;+@&quot;)
      --xml-content-name string         name for xml content (if no attribute name is present). (default &quot;+content&quot;)
      --xml-directive-name string       name for xml directives (e.g. &lt;!DOCTYPE thing cat&gt;) (default &quot;+directive&quot;)
      --xml-keep-namespace              enables keeping namespace after parsing attributes (default true)
      --xml-proc-inst-prefix string     prefix for xml processing instructions (e.g. &lt;?xml version=&quot;1&quot;?&gt;) (default &quot;+p_&quot;)
      --xml-raw-token                   enables using RawToken method instead Token. Commonly disables namespace translations. See https://pkg.go.dev/encoding/xml#Decoder.RawToken for details. (default true)
      --xml-skip-directives             skip over directives (e.g. &lt;!DOCTYPE thing cat&gt;)
      --xml-skip-proc-inst              skip over process instructions (e.g. &lt;?xml version=&quot;1&quot;?&gt;)
      --xml-strict-mode                 enables strict parsing of XML. See https://pkg.go.dev/encoding/xml for more details.
      --yaml-fix-merge-anchor-to-spec   Fix merge anchor to match YAML spec. Will default to true in late 2025

Use &quot;yq [command] --help&quot; for more information about a command.
```

## Troubleshooting

### Common Issues

**PowerShell quoting issues:**
```powershell
# Use single quotes for expressions
yq &#039;.a.b[0].c&#039; file.yaml

# Or escape double quotes
yq &quot;.a.b[0].c = \&quot;value\&quot;&quot; file.yaml
```

### Getting Help

- **Check existing issues**: [GitHub Issues](https://github.com/mikefarah/yq/issues)
- **Ask questions**: [GitHub Discussions](https://github.com/mikefarah/yq/discussions)
- **Documentation**: [Complete documentation](https://mikefarah.gitbook.io/yq/)
- **Examples**: [Recipes and examples](https://mikefarah.gitbook.io/yq/recipes)

## Known Issues / Missing Features
- `yq` attempts to preserve comment positions and whitespace as much as possible, but it does not handle all scenarios (see https://github.com/go-yaml/yaml/tree/v3 for details)
- Powershell has its own...[opinions on quoting yq](https://mikefarah.gitbook.io/yq/usage/tips-and-tricks#quotes-in-windows-powershell)
- &quot;yes&quot;, &quot;no&quot; were dropped as boolean values in the yaml 1.2 standard - which is the standard yq assumes.

See [tips and tricks](https://mikefarah.gitbook.io/yq/usage/tips-and-tricks) for more common problems and solutions.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[knadh/listmonk]]></title>
            <link>https://github.com/knadh/listmonk</link>
            <guid>https://github.com/knadh/listmonk</guid>
            <pubDate>Mon, 16 Feb 2026 00:08:04 GMT</pubDate>
            <description><![CDATA[High performance, self-hosted, newsletter and mailing list manager with a modern dashboard. Single binary app.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/knadh/listmonk">knadh/listmonk</a></h1>
            <p>High performance, self-hosted, newsletter and mailing list manager with a modern dashboard. Single binary app.</p>
            <p>Language: Go</p>
            <p>Stars: 19,059</p>
            <p>Forks: 1,923</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://zerodha.tech&quot;&gt;&lt;img src=&quot;https://zerodha.tech/static/images/github-badge.svg&quot; align=&quot;right&quot; /&gt;&lt;/a&gt;

[![listmonk-logo](https://user-images.githubusercontent.com/547147/231084896-835dba66-2dfe-497c-ba0f-787564c0819e.png)](https://listmonk.app)

listmonk is a standalone, self-hosted, newsletter and mailing list manager. It is fast, feature-rich, and packed into a single binary. It uses a PostgreSQL database as its data store.

[![listmonk-dashboard](https://github.com/user-attachments/assets/689b5fbb-dd25-4956-a36f-e3226a65f9c4)](https://listmonk.app)

Visit [listmonk.app](https://listmonk.app) for more info. Check out the [**live demo**](https://demo.listmonk.app).

## Installation

### Docker

The latest image is available on DockerHub at [`listmonk/listmonk:latest`](https://hub.docker.com/r/listmonk/listmonk/tags?page=1&amp;ordering=last_updated&amp;name=latest).
Download and use the sample [docker-compose.yml](https://github.com/knadh/listmonk/blob/master/docker-compose.yml).


```shell
# Download the compose file to the current directory.
curl -LO https://github.com/knadh/listmonk/raw/master/docker-compose.yml

# Run the services in the background.
docker compose up -d
```
Visit `http://localhost:9000`

See [installation docs](https://listmonk.app/docs/installation)

__________________

### Binary
- Download the [latest release](https://github.com/knadh/listmonk/releases) and extract the listmonk binary.
- `./listmonk --new-config` to generate config.toml. Edit it.
- `./listmonk --install` to setup the Postgres DB (or `--upgrade` to upgrade an existing DB. Upgrades are idempotent and running them multiple times have no side effects).
- Run `./listmonk` and visit `http://localhost:9000`

See [installation docs](https://listmonk.app/docs/installation)
__________________


## Developers
listmonk is free and open source software licensed under AGPLv3. If you are interested in contributing, refer to the [developer setup](https://listmonk.app/docs/developer-setup). The backend is written in Go and the frontend is Vue with Buefy for UI. 


## License
listmonk is licensed under the AGPL v3 license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>