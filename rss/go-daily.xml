<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Thu, 04 Sep 2025 00:04:42 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[aquasecurity/trivy]]></title>
            <link>https://github.com/aquasecurity/trivy</link>
            <guid>https://github.com/aquasecurity/trivy</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aquasecurity/trivy">aquasecurity/trivy</a></h1>
            <p>Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more</p>
            <p>Language: Go</p>
            <p>Stars: 28,198</p>
            <p>Forks: 2,701</p>
            <p>Stars today: 42 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/imgs/logo.png&quot; width=&quot;200&quot;&gt;

[![GitHub Release][release-img]][release]
[![Test][test-img]][test]
[![Go Report Card][go-report-img]][go-report]
[![License: Apache-2.0][license-img]][license]
[![GitHub Downloads][github-downloads-img]][release]
![Docker Pulls][docker-pulls]

[üìñ Documentation][docs]
&lt;/div&gt;

Trivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.
Trivy has *scanners* that look for security issues, and *targets* where it can find those issues.

Targets (what Trivy can scan):

- Container Image
- Filesystem
- Git Repository (remote)
- Virtual Machine Image
- Kubernetes

Scanners (what Trivy can find there):

- OS packages and software dependencies in use (SBOM)
- Known vulnerabilities (CVEs)
- IaC issues and misconfigurations
- Sensitive information and secrets
- Software licenses

Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.

To learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.

## Quick Start

### Get Trivy

Trivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:

- `brew install trivy`
- `docker run aquasec/trivy`
- Download binary from &lt;https://github.com/aquasecurity/trivy/releases/latest/&gt;
- See [Installation] for more

Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:

- [GitHub Actions](https://github.com/aquasecurity/trivy-action)
- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)
- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)
- See [Ecosystem] for more

### Canary builds
There are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) as generated every push to main branch.

Please be aware: canary builds might have critical bugs, it&#039;s not recommended for use in production.

### General usage

```bash
trivy &lt;target&gt; [--scanners &lt;scanner1,scanner2&gt;] &lt;subject&gt;
```

Examples:

```bash
trivy image python:3.4-alpine
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov

&lt;/details&gt;

```bash
trivy fs --scanners vuln,secret,misconfig myproject/
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov

&lt;/details&gt;

```bash
trivy k8s --report summary cluster
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

![k8s summary](docs/imgs/trivy-k8s.png)

&lt;/details&gt;

## FAQ

### How to pronounce the name &quot;Trivy&quot;?

`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.

## Want more? Check out Aqua

If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  
You can find a high level comparison table specific to Trivy users [here](https://trivy.dev/latest/commercial/compare/).
In addition check out the &lt;https://aquasec.com&gt; website for more information about our products and services.
If you&#039;d like to contact Aqua or request a demo, please use this form: &lt;https://www.aquasec.com/demo&gt;

## Community

Trivy is an [Aqua Security][aquasec] open source project.  
Learn about our open source work and portfolio [here][oss].  
Contact us about any matter by opening a GitHub Discussion [here][discussions]

Please ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.

[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml
[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg
[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy
[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy
[release]: https://github.com/aquasecurity/trivy/releases
[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github
[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github
[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;label=docker%20pulls%20%2F%20trivy
[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE
[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[homepage]: https://trivy.dev
[docs]: https://trivy.dev/latest/docs/
[pronunciation]: #how-to-pronounce-the-name-trivy
[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md

[Installation]:https://trivy.dev/latest/getting-started/installation/
[Ecosystem]: https://trivy.dev/latest/ecosystem/
[Scanning Coverage]: https://trivy.dev/latest/docs/coverage/

[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/
[rego]: https://www.openpolicyagent.org/docs/latest/#rego
[sigstore]: https://www.sigstore.dev/

[aquasec]: https://aquasec.com
[oss]: https://www.aquasec.com/products/open-source-projects/
[discussions]: https://github.com/aquasecurity/trivy/discussions
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[google/mangle]]></title>
            <link>https://github.com/google/mangle</link>
            <guid>https://github.com/google/mangle</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:41 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google/mangle">google/mangle</a></h1>
            <p></p>
            <p>Language: Go</p>
            <p>Stars: 2,155</p>
            <p>Forks: 103</p>
            <p>Stars today: 177 stars today</p>
            <h2>README</h2><pre># Mangle

Mangle is a programming language for deductive database programming. It
is an extension of Datalog, with various extensions like aggregation, function
calls and optional type-checking.

Deductive database programming is useful for bringing data from multiple
data sources together since it enables us to represent and query that data in
a uniform way. It can also be used to model domain knowledge, similar
to machine-readable ontology but without being restricted to binary
predicates.

Datalog is an expressive declarative language similar to relational calculus
(think SQL and relational views). Unlike relational calculus, it also supports
recursive rules and program structuring in a straightforward way.

Mangle contains Datalog as a fragment and adds extensions that make its use
more practical. Some of the good properties like guaranteed termination are
lost when such extensions are used.

The goal of Mangle as an open source project is to convey the concepts in
a way that is accessible to developers and lends itself to easy experimentation.
This repository contains an implementation of Mangle as a go library that can be
easily embedded into applications.

Check out the [docs](docs/README.md) and the
[GitHub discussions](https://github.com/google/mangle/discussions) for more
information. There is also a Q&amp;A section.

For an example how to use Mangle library in a database-like grpc service,
see the separate [Mangle demo service repo](https://github.com/burakemir/mangle-service).

This is not an officially supported Google product. 

## Table of Contents
- [Examples](#examples)
- [Building](#building)

## Examples

### Simple Queries

Imagine you were asked to spot software affected by the
[log4j vulnerability discovered in late 2021](https://www.cisa.gov/uscert/apache-log4j-vulnerability-guidance).
We want to look for projects that contain a Java archive (jar file) of
log4j that is not updated to the patched version.

```prolog
projects_with_vulnerable_log4j(P) :-
  projects(P),
  contains_jar(P, &quot;log4j&quot;, Version),
  Version != &quot;2.17.1&quot;,
  Version != &quot;2.12.4&quot;,
  Version != &quot;2.3.2&quot;.
```

This is a Mangle *rule*: conceptually, the implementation retrieve all
possible values for variables `P` and `Version` that make all the subgoals true.

Simple Mangle rules like this correspond to select-project-join relational
queries. The same query in SQL would look like this:

```sql
SELECT projects.id as P
FROM projects JOIN contains_jar ON projects.id = contains_jar.project_id
WHERE contains_jar.version NOT IN (&quot;2.17.1&quot;, &quot;2.12.4&quot;, &quot;2.3.2&quot;)
```

Unlike SQL, our Mangle rule `projects_with_vulnerable_log4j` has a name
and can be referenced in other queries.

(If translating non-recursive Datalog into SQL queries sounds interesting, you
should check out the [Logica](https://logica.dev/) open source project.)

### Aggregation

In practice, querying is rarely enough and we also need grouping and
aggregation.

```
count_projects_with_vulnerable_log4j(Num) :-
  projects_with_vulnerable_log4j(P) |&gt; do fn:group_by(), let Num = fn:Count().
```

### Recursive Queries

The example does not specify what `contains_jar` does. Here is a possible
implementation for `contains_jar` that walks a dependency graph.
This shows that Mangle rules can be recursive. 

```
contains_jar(P, Name, Version) :-
  contains_jar_directly(P, Name, Version).

contains_jar(P, Name, Version) :-
  project_depends(P, Q),
  contains_jar(Q, Name, Version).
```

The two rules correspond to two cases in which a project may &quot;contain&quot; a jar:
either directly, or through some dependency.

### Knowledge Graphs, Property Graphs

In requirements engineering, one needs to captures real world concepts in a
domain model and controlled vocabulary. Description logics use
roles to describe how concepts interact, but these relationships are always
binary. Mangle can represent binary predicates, but also arbitrary n-ary
relations. Moreover it also has support for structured data.

```
one_or_two_leg_trip(Codes, Start, Destination, Price) :-
  direct_conn(Code, Start, Destination, Price)
  |&gt; let Codes = [Code].

one_or_two_leg_trip(Codes, Start, Destination, Price) :-
  direct_conn(FirstCode, Start, Connecting, FirstLegPrice).
  direct_conn(SecondCode, Connecting, Destination, SecondLegPrice)
  |&gt; let Code = [FirstCode, SecondCode],
     let Price = fn:plus(FirstLegPrice, SecondLegPrice).

```

```mermaid
graph LR
    /zurich --&gt;|/code/ZL &lt;br /&gt; 60 CHF| /lausanne
    /zurich --&gt;|/code/ZB &lt;br /&gt; 30 CHF| /bern
    /bern --&gt;|/code/BL &lt;br /&gt; 30 CHF| /lausanne
```

## Building &amp; Testing

Get the dependencies (see [go.mod](go.mod)), build the library, run tests:

```
go get -t ./...
go build ./...
go test ./...
```

### Regenerating the parser sources

If you want to regenerate the parser sources, you need to set up ANTLR first.
This requires a Java runtime environment.

```
wget http://www.antlr.org/download/antlr-4.13.2-complete.jar
alias antlr=&#039;java -jar $PWD/antlr-4.13.2-complete.jar&#039;
antlr -Dlanguage=Go -package gen -o ./ parse/gen/Mangle.g4 -visitor
```

## Contributing

The Mangle maintainers welcome external contributions to spec, documentation
and this implementation (see [CONTRIBUTING.md](CONTRIBUTING.md)) and also other
implementations. Pull requests will be handled
[like for tensorflow](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md),
to ensure our internal usage and tests will pass. 
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mayswind/ezbookkeeping]]></title>
            <link>https://github.com/mayswind/ezbookkeeping</link>
            <guid>https://github.com/mayswind/ezbookkeeping</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:40 GMT</pubDate>
            <description><![CDATA[A lightweight, self-hosted personal finance app with a user-friendly interface and powerful bookkeeping features.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mayswind/ezbookkeeping">mayswind/ezbookkeeping</a></h1>
            <p>A lightweight, self-hosted personal finance app with a user-friendly interface and powerful bookkeeping features.</p>
            <p>Language: Go</p>
            <p>Stars: 1,538</p>
            <p>Forks: 159</p>
            <p>Stars today: 59 stars today</p>
            <h2>README</h2><pre># ezBookkeeping
[![License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/mayswind/ezbookkeeping/blob/master/LICENSE)
[![Latest Build](https://img.shields.io/github/actions/workflow/status/mayswind/ezbookkeeping/docker-snapshot.yml?branch=main)](https://github.com/mayswind/ezbookkeeping/actions)
[![Go Report](https://goreportcard.com/badge/github.com/mayswind/ezbookkeeping)](https://goreportcard.com/report/github.com/mayswind/ezbookkeeping)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/mayswind/ezbookkeeping)
[![Latest Docker Image Size](https://img.shields.io/docker/image-size/mayswind/ezbookkeeping.svg?style=flat)](https://hub.docker.com/r/mayswind/ezbookkeeping)
[![Latest Release](https://img.shields.io/github/release/mayswind/ezbookkeeping.svg?style=flat)](https://github.com/mayswind/ezbookkeeping/releases)

[![Recommend By HelloGitHub](https://api.hellogithub.com/v1/widgets/recommend.svg?rid=ded5af09da574ec1811ddb154f1b2093&amp;claim_uid=LT7EZxeBukCnh0K)](https://hellogithub.com/en/repository/mayswind/ezbookkeeping)

## Introduction
ezBookkeeping is a lightweight, self-hosted personal finance app with a user-friendly interface and powerful bookkeeping features. It&#039;s easy to deploy, and you can start it with just one single Docker command. Designed to be resource-efficient and highly scalable, it can run smoothly on devices as small as a Raspberry Pi, or scale up to NAS, MicroServers, and even large cluster environments.

ezBookkeeping offers tailored interfaces for both mobile and desktop devices. With support for PWA (Progressive Web Apps), you can even [add it to your mobile home screen](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/mobile/add_to_home_screen.gif) and use it like a native app.

Live Demo: [https://ezbookkeeping-demo.mayswind.net](https://ezbookkeeping-demo.mayswind.net)

## Features
- **Open Source &amp; Self-Hosted**
    - Built for privacy and control
- **Lightweight &amp; Fast**
    - Optimized for performance, runs smoothly even on low-resource environments
- **Easy Installation**
    - Docker-ready
    - Supports SQLite, MySQL, PostgreSQL
    - Cross-platform (Windows, macOS, Linux)
    - Works on x86, amd64, ARM architectures
- **User-Friendly Interface**
    - UI optimized for both mobile and desktop
    - PWA support for native-like mobile experience
    - Dark mode
- **AI-Powered Features**
    - Supports MCP (Model Context Protocol) for AI integration
- **Powerful Bookkeeping**
    - Two-level accounts and categories
    - Attach images to transactions
    - Location tracking with maps
    - Recurring transactions
    - Advanced filtering, search, visualization, and analysis
- **Localization &amp; Globalization**
    - Multi-language and multi-currency support
    - Automatic exchange rates
    - Multi-timezone awareness
    - Custom formats for dates, numbers, and currencies
- **Security**
    - Two-factor authentication (2FA)
    - Login rate limiting
    - Application lock (PIN code / WebAuthn)
- **Data Import/Export**
    - Supports CSV, OFX, QFX, QIF, IIF, Camt.053, MT940, GnuCash, Firefly III, Beancount, and more

## Screenshots
### Desktop Version
[![ezBookkeeping](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/desktop/en.png)](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/desktop/en.png)

### Mobile Version
[![ezBookkeeping](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/mobile/en.png)](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/mobile/en.png)

## Installation
### Run with Docker
Visit [Docker Hub](https://hub.docker.com/r/mayswind/ezbookkeeping) to see all images and tags.

**Latest Release:**

    $ docker run -p8080:8080 mayswind/ezbookkeeping

**Latest Daily Build:**

    $ docker run -p8080:8080 mayswind/ezbookkeeping:latest-snapshot

### Install from Binary
Download the latest release: [https://github.com/mayswind/ezbookkeeping/releases](https://github.com/mayswind/ezbookkeeping/releases)

**Linux / macOS**

    $ ./ezbookkeeping server run

**Windows**

    &gt; .\ezbookkeeping.exe server run

By default, ezBookkeeping listens on port 8080. You can then visit `http://{YOUR_HOST_ADDRESS}:8080/` .

### Build from Source
Make sure you have [Golang](https://golang.org/), [GCC](http://gcc.gnu.org/), [Node.js](https://nodejs.org/) and [NPM](https://www.npmjs.com/) installed. Then download the source code, and follow these steps:

**Linux / macOS**

    $ ./build.sh package -o ezbookkeeping.tar.gz

All the files will be packaged in `ezbookkeeping.tar.gz`.

**Windows**

    &gt; .\build.bat package -o ezbookkeeping.zip

All the files will be packaged in `ezbookkeeping.zip`.

You can also build a Docker image. Make sure you have [Docker](https://www.docker.com/) installed, then follow these steps:

**Linux**

    $ ./build.sh docker

## Contributing
We welcome contributions of all kinds.

Found a bug? [Submit an issue](https://github.com/mayswind/ezbookkeeping/issues)

Want to contribute code? Feel free to fork and send a pull request.

Contributions of all kinds ‚Äî bug reports, feature suggestions, documentation improvements, or code ‚Äî are highly appreciated.

Check out our [Contributor Graph](https://github.com/mayswind/ezbookkeeping/graphs/contributors) to see the amazing people who‚Äôve already helped.

## Translating
Help make ezBookkeeping accessible to users around the world. If you want to contribute a translation, please refer to our [translation guide](https://ezbookkeeping.mayswind.net/translating).

Currently available translations:

| Tag | Language | Contributors |
| --- | --- | --- |
| de | Deutsch | [@chrgm](https://github.com/chrgm) |
| en | English | / |
| es | Espa√±ol | [@Miguelonlonlon](https://github.com/Miguelonlonlon) |
| it | Italiano | [@waron97](https://github.com/waron97) |
| ja | Êó•Êú¨Ë™û | [@tkymmm](https://github.com/tkymmm) |
| nl | Nederlands | [@automagic](https://github.com/automagics) |
| pt-BR | Portugu√™s (Brasil) | [@thecodergus](https://github.com/thecodergus) |
| ru | –†—É—Å—Å–∫–∏–π | [@artegoser](https://github.com/artegoser) |
| uk | –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ | [@nktlitvinenko](https://github.com/nktlitvinenko) |
| vi | Ti·∫øng Vi·ªát | [@f97](https://github.com/f97) |
| zh-Hans | ‰∏≠Êñá (ÁÆÄ‰Ωì) | / |
| zh-Hant | ‰∏≠Êñá (ÁπÅÈ´î) | / |

Don&#039;t see your language? Help us add it.

## Documentation
1. [English](http://ezbookkeeping.mayswind.net)
1. [‰∏≠Êñá (ÁÆÄ‰Ωì)](http://ezbookkeeping.mayswind.net/zh_Hans)

## License
[MIT](https://github.com/mayswind/ezbookkeeping/blob/master/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[wailsapp/wails]]></title>
            <link>https://github.com/wailsapp/wails</link>
            <guid>https://github.com/wailsapp/wails</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:39 GMT</pubDate>
            <description><![CDATA[Create beautiful applications using Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wailsapp/wails">wailsapp/wails</a></h1>
            <p>Create beautiful applications using Go</p>
            <p>Language: Go</p>
            <p>Stars: 29,910</p>
            <p>Forks: 1,462</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot; style=&quot;text-align: center&quot;&gt;
  &lt;img src=&quot;./assets/images/logo-universal.png&quot; width=&quot;55%&quot;&gt;&lt;br/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  Build desktop applications using Go &amp; Web Technologies.
  &lt;br/&gt;
  &lt;br/&gt;
  &lt;a href=&quot;https://github.com/wailsapp/wails/blob/master/LICENSE&quot;&gt;
    &lt;img alt=&quot;GitHub&quot; src=&quot;https://img.shields.io/github/license/wailsapp/wails&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/wailsapp/wails&quot;&gt;
    &lt;img src=&quot;https://goreportcard.com/badge/github.com/wailsapp/wails&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pkg.go.dev/github.com/wailsapp/wails&quot;&gt;
    &lt;img src=&quot;https://pkg.go.dev/badge/github.com/wailsapp/wails.svg&quot; alt=&quot;Go Reference&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/wailsapp/wails/issues&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat&quot; alt=&quot;CodeFactor&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://app.fossa.com/projects/git%2Bgithub.com%2Fwailsapp%2Fwails?ref=badge_shield&quot; alt=&quot;FOSSA Status&quot;&gt;
    &lt;img src=&quot;https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwailsapp%2Fwails.svg?type=shield&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/avelino/awesome-go&quot; rel=&quot;nofollow&quot;&gt;
    &lt;img src=&quot;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg&quot; alt=&quot;Awesome&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/BrRSWTaxVK&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://dcbadge.vercel.app/api/server/BrRSWTaxVK?style=flat&quot;/&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;a href=&quot;https://github.com/wailsapp/wails/actions/workflows/build-and-test.yml&quot; rel=&quot;nofollow&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/wailsapp/wails/build-and-test.yml?branch=master&amp;logo=Github&quot; alt=&quot;Build&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/wailsapp/wails/tags&quot; rel=&quot;nofollow&quot;&gt;
    &lt;img alt=&quot;GitHub tag (latest SemVer pre-release)&quot; src=&quot;https://img.shields.io/github/v/tag/wailsapp/wails?include_prereleases&amp;label=version&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;strong&gt;
&lt;samp&gt;

[English](README.md) ¬∑ [ÁÆÄ‰Ωì‰∏≠Êñá](README.zh-Hans.md) ¬∑ [Êó•Êú¨Ë™û](README.ja.md) ¬∑
[ÌïúÍµ≠Ïñ¥](README.ko.md) ¬∑ [Espa√±ol](README.es.md) ¬∑ [Portugu√™s](README.pt-br.md) ¬∑
[–†—É—Å—Å–∫–∏–π](README.ru.md) ¬∑ [Francais](README.fr.md) ¬∑ [Uzbek](README.uz.md) ¬∑ [Deutsch](README.de.md) ¬∑
[T√ºrk√ße](README.tr.md)

&lt;/samp&gt;
&lt;/strong&gt;
&lt;/div&gt;

## Table of Contents

- [Table of Contents](#table-of-contents)
- [Introduction](#introduction)
- [Features](#features)
  - [Roadmap](#roadmap)
- [Getting Started](#getting-started)
- [Sponsors](#sponsors)
- [FAQ](#faq)
- [Stargazers over time](#stargazers-over-time)
- [Contributors](#contributors)
- [License](#license)
- [Inspiration](#inspiration)

## Introduction

The traditional method of providing web interfaces to Go programs is via a built-in web server. Wails offers a different
approach: it provides the ability to wrap both Go code and a web frontend into a single binary. Tools are provided to
make this easy for you by handling project creation, compilation and bundling. All you have to do is get creative!

## Features

- Use standard Go for the backend
- Use any frontend technology you are already familiar with to build your UI
- Quickly create rich frontends for your Go programs using pre-built templates
- Easily call Go methods from Javascript
- Auto-generated Typescript definitions for your Go structs and methods
- Native Dialogs &amp; Menus
- Native Dark / Light mode support
- Supports modern translucency and &quot;frosted window&quot; effects
- Unified eventing system between Go and Javascript
- Powerful cli tool to quickly generate and build your projects
- Multiplatform
- Uses native rendering engines - _no embedded browser_!

### Roadmap

The project roadmap may be found [here](https://github.com/wailsapp/wails/discussions/1484). Please consult
it before creating an enhancement request.

## Getting Started

The installation instructions are on the [official website](https://wails.io/docs/gettingstarted/installation).

## Sponsors

This project is supported by these kind people / companies:
&lt;img src=&quot;website/static/img/sponsors.svg&quot; style=&quot;width:100%;max-width:800px;&quot;/&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://wails.io/img/sponsor/jetbrains-grayscale.webp&quot; style=&quot;width: 100px&quot;/&gt;
&lt;/p&gt;

## FAQ

- Is this an alternative to Electron?

  Depends on your requirements. It&#039;s designed to make it easy for Go programmers to make lightweight desktop
  applications or add a frontend to their existing applications. Wails does offer native elements such as menus
  and dialogs, so it could be considered a lightweight electron alternative.

- Who is this project aimed at?

  Go programmers who want to bundle an HTML/JS/CSS frontend with their applications, without resorting to creating a
  server and opening a browser to view it.

- What&#039;s with the name?

  When I saw WebView, I thought &quot;What I really want is tooling around building a WebView app, a bit like Rails is to
  Ruby&quot;. So initially it was a play on words (Webview on Rails). It just so happened to also be a homophone of the
  English name for the [Country](https://en.wikipedia.org/wiki/Wales) I am from. So it stuck.

## Stargazers over time

&lt;a href=&quot;https://star-history.com/#wailsapp/wails&amp;Date&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=wailsapp/wails&amp;type=Date&amp;theme=dark&quot; /&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=wailsapp/wails&amp;type=Date&quot; /&gt;
    &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=wailsapp/wails&amp;type=Date&quot; /&gt;
  &lt;/picture&gt;
&lt;/a&gt;

## Contributors

The contributors list is getting too big for the readme! All the amazing people who have contributed to this
project have their own page [here](https://wails.io/credits#contributors).

## License

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwailsapp%2Fwails.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Fwailsapp%2Fwails?ref=badge_large)

## Inspiration

This project was mainly coded to the following albums:

- [Manic Street Preachers - Resistance Is Futile](https://open.spotify.com/album/1R2rsEUqXjIvAbzM0yHrxA)
- [Manic Street Preachers - This Is My Truth, Tell Me Yours](https://open.spotify.com/album/4VzCL9kjhgGQeKCiojK1YN)
- [The Midnight - Endless Summer](https://open.spotify.com/album/4Krg8zvprquh7TVn9OxZn8)
- [Gary Newman - Savage (Songs from a Broken World)](https://open.spotify.com/album/3kMfsD07Q32HRWKRrpcexr)
- [Steve Vai - Passion &amp; Warfare](https://open.spotify.com/album/0oL0OhrE2rYVns4IGj8h2m)
- [Ben Howard - Every Kingdom](https://open.spotify.com/album/1nJsbWm3Yy2DW1KIc1OKle)
- [Ben Howard - Noonday Dream](https://open.spotify.com/album/6astw05cTiXEc2OvyByaPs)
- [Adwaith - Melyn](https://open.spotify.com/album/2vBE40Rp60tl7rNqIZjaXM)
- [Gwidaith Hen Fran - Cedors Hen Wrach](https://open.spotify.com/album/3v2hrfNGINPLuDP0YDTOjm)
- [Metallica - Metallica](https://open.spotify.com/album/2Kh43m04B1UkVcpcRa1Zug)
- [Bloc Party - Silent Alarm](https://open.spotify.com/album/6SsIdN05HQg2GwYLfXuzLB)
- [Maxthor - Another World](https://open.spotify.com/album/3tklE2Fgw1hCIUstIwPBJF)
- [Alun Tan Lan - Y Distawrwydd](https://open.spotify.com/album/0c32OywcLpdJCWWMC6vB8v)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[VictoriaMetrics/VictoriaMetrics]]></title>
            <link>https://github.com/VictoriaMetrics/VictoriaMetrics</link>
            <guid>https://github.com/VictoriaMetrics/VictoriaMetrics</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:38 GMT</pubDate>
            <description><![CDATA[VictoriaMetrics: fast, cost-effective monitoring solution and time series database]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/VictoriaMetrics/VictoriaMetrics">VictoriaMetrics/VictoriaMetrics</a></h1>
            <p>VictoriaMetrics: fast, cost-effective monitoring solution and time series database</p>
            <p>Language: Go</p>
            <p>Stars: 14,907</p>
            <p>Forks: 1,451</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># VictoriaMetrics

[![Latest Release](https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaMetrics?sort=semver&amp;label=&amp;filter=!*-victorialogs&amp;logo=github&amp;labelColor=gray&amp;color=gray&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Freleases%2Flatest)](https://github.com/VictoriaMetrics/VictoriaMetrics/releases)
![Docker Pulls](https://img.shields.io/docker/pulls/victoriametrics/victoria-metrics?label=&amp;logo=docker&amp;logoColor=white&amp;labelColor=2496ED&amp;color=2496ED&amp;link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-metrics)
[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaMetrics?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics)](https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaMetrics)
[![Build Status](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/main.yml/badge.svg?branch=master&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Factions)](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/main.yml)
[![codecov](https://codecov.io/gh/VictoriaMetrics/VictoriaMetrics/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaMetrics)](https://app.codecov.io/gh/VictoriaMetrics/VictoriaMetrics)
[![License](https://img.shields.io/github/license/VictoriaMetrics/VictoriaMetrics?labelColor=green&amp;label=&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Fblob%2Fmaster%2FLICENSE)](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/LICENSE)
![Slack](https://img.shields.io/badge/Join-4A154B?logo=slack&amp;link=https%3A%2F%2Fslack.victoriametrics.com)
[![X](https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&amp;label=Follow&amp;color=black&amp;logo=x&amp;labelColor=black&amp;link=https%3A%2F%2Fx.com%2FVictoriaMetrics)](https://x.com/VictoriaMetrics/)
[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&amp;label=Join&amp;labelColor=red&amp;logoColor=white&amp;logo=reddit&amp;link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics)](https://www.reddit.com/r/VictoriaMetrics/)

&lt;picture&gt;
  &lt;source srcset=&quot;docs/victoriametrics/logo_white.webp&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
  &lt;source srcset=&quot;docs/victoriametrics/logo.webp&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
  &lt;img src=&quot;docs/victoriametrics/logo.webp&quot; width=&quot;300&quot; alt=&quot;VictoriaMetrics logo&quot;&gt;
&lt;/picture&gt;

VictoriaMetrics is a fast, cost-saving, and scalable solution for monitoring and managing time series data. It delivers high performance and reliability, making it an ideal choice for businesses of all sizes.

Here are some resources and information about VictoriaMetrics:

- Documentation: [docs.victoriametrics.com](https://docs.victoriametrics.com)
- Case studies: [Grammarly, Roblox, Wix,...](https://docs.victoriametrics.com/victoriametrics/casestudies/).
- Available: [Binary releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest), docker images [Docker Hub](https://hub.docker.com/r/victoriametrics/victoria-metrics/) and [Quay](https://quay.io/repository/victoriametrics/victoria-metrics), [Source code](https://github.com/VictoriaMetrics/VictoriaMetrics)
- Deployment types: [Single-node version](https://docs.victoriametrics.com/), [Cluster version](https://docs.victoriametrics.com/victoriametrics/cluster-victoriametrics/), and [Enterprise version](https://docs.victoriametrics.com/victoriametrics/enterprise/)
- Changelog: [CHANGELOG](https://docs.victoriametrics.com/victoriametrics/changelog/), and [How to upgrade](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-upgrade-victoriametrics)
- Community: [Slack](https://slack.victoriametrics.com/), [X (Twitter)](https://x.com/VictoriaMetrics), [LinkedIn](https://www.linkedin.com/company/victoriametrics/), [YouTube](https://www.youtube.com/@VictoriaMetrics)

Yes, we open-source both the single-node VictoriaMetrics and the cluster version.

## Prominent features

VictoriaMetrics is optimized for timeseries data, even when old time series are constantly replaced by new ones at a high rate, it offers a lot of features:

* **Long-term storage for Prometheus** or as a drop-in replacement for Prometheus and Graphite in Grafana.
* **Powerful stream aggregation**: Can be used as a StatsD alternative.
* **Ideal for big data**: Works well with large amounts of time series data from APM, Kubernetes, IoT sensors, connected cars, industrial telemetry, financial data and various [Enterprise workloads](https://docs.victoriametrics.com/victoriametrics/enterprise/).
* **Query language**: Supports both PromQL and the more performant MetricsQL.
* **Easy to setup**: No dependencies, single [small binary](https://medium.com/@valyala/stripping-dependency-bloat-in-victoriametrics-docker-image-983fb5912b0d), configuration through command-line flags, but the default is also fine-tuned; backup and restore with [instant snapshots](https://medium.com/@valyala/how-victoriametrics-makes-instant-snapshots-for-multi-terabyte-time-series-data-e1f3fb0e0282).
* **Global query view**: Multiple Prometheus instances or any other data sources may ingest data into VictoriaMetrics and queried via a single query.
* **Various Protocols**: Support metric scraping, ingestion and backfilling in various protocol.
    * [Prometheus exporters](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-scrape-prometheus-exporters-such-as-node-exporter), [Prometheus remote write API](https://docs.victoriametrics.com/victoriametrics/integrations/prometheus/), [Prometheus exposition format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-prometheus-exposition-format).
    * [InfluxDB line protocol](https://docs.victoriametrics.com/victoriametrics/integrations/influxdb/) over HTTP, TCP and UDP.
    * [Graphite plaintext protocol](https://docs.victoriametrics.com/victoriametrics/integrations/graphite/#ingesting) with [tags](https://graphite.readthedocs.io/en/latest/tags.html#carbon).
    * [OpenTSDB put message](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-telnet).
    * [HTTP OpenTSDB /api/put requests](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-http).
    * [JSON line format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-json-line-format).
    * [Arbitrary CSV data](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-csv-data).
    * [Native binary format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-native-format).
    * [DataDog agent or DogStatsD](https://docs.victoriametrics.com/victoriametrics/integrations/datadog/).
    * [NewRelic infrastructure agent](https://docs.victoriametrics.com/victoriametrics/integrations/newrelic/#sending-data-from-agent).
    * [OpenTelemetry metrics format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#sending-data-via-opentelemetry).
* **NFS-based storages**: Supports storing data on NFS-based storages such as Amazon EFS, Google Filestore.
* And many other features such as metrics relabeling, cardinality limiter, etc.

## Enterprise version

In addition, the Enterprise version includes extra features:

- **Anomaly detection**: Automation and simplification of your alerting rules, covering complex anomalies found in metrics data.
- **Backup automation**: Automates regular backup procedures.
- **Multiple retentions**: Reducing storage costs by specifying different retentions for different datasets.
- **Downsampling**: Reducing storage costs and increasing performance for queries over historical data.
- **Stable releases** with long-term support lines ([LTS](https://docs.victoriametrics.com/victoriametrics/lts-releases/)).
- **Comprehensive support**: First-class consulting, feature requests and technical support provided by the core VictoriaMetrics dev team.
- Many other features, which you can read about on [the Enterprise page](https://docs.victoriametrics.com/victoriametrics/enterprise/).

[Contact us](mailto:info@victoriametrics.com) if you need enterprise support for VictoriaMetrics. Or you can request a free trial license [here](https://victoriametrics.com/products/enterprise/trial/), downloaded Enterprise binaries are available at [Github Releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest).

We strictly apply security measures in everything we do. VictoriaMetrics has achieved security certifications for Database Software Development and Software-Based Monitoring Services. See [Security page](https://victoriametrics.com/security/) for more details.

## Benchmarks 

Some good benchmarks VictoriaMetrics achieved:

* **Minimal memory footprint**: handling millions of unique timeseries with [10x less RAM](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) than InfluxDB, up to [7x less RAM](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) than Prometheus, Thanos or Cortex.
* **Highly scalable and performance** for [data ingestion](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and [querying](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4), [20x outperforms](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) InfluxDB and TimescaleDB.
* **High data compression**: [70x more data points](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4) may be stored into limited storage than TimescaleDB, [7x less storage](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) space is required than Prometheus, Thanos or Cortex.
* **Reducing storage costs**: [10x more effective](https://docs.victoriametrics.com/victoriametrics/casestudies/#grammarly) than Graphite according to the Grammarly case study.
* **A single-node VictoriaMetrics** can replace medium-sized clusters built with competing solutions such as Thanos, M3DB, Cortex, InfluxDB or TimescaleDB. See [VictoriaMetrics vs Thanos](https://medium.com/@valyala/comparing-thanos-to-victoriametrics-cluster-b193bea1683), [Measuring vertical scalability](https://medium.com/@valyala/measuring-vertical-scalability-for-time-series-databases-in-google-cloud-92550d78d8ae), [Remote write storage wars - PromCon 2019](https://promcon.io/2019-munich/talks/remote-write-storage-wars/).
* **Optimized for storage**: [Works well with high-latency IO](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and low IOPS (HDD and network storage in AWS, Google Cloud, Microsoft Azure, etc.).

## Community and contributions

Feel free asking any questions regarding VictoriaMetrics:

* [Slack Inviter](https://slack.victoriametrics.com/) and [Slack channel](https://victoriametrics.slack.com/)
* [X (Twitter)](https://x.com/VictoriaMetrics/)
* [Linkedin](https://www.linkedin.com/company/victoriametrics/)
* [Reddit](https://www.reddit.com/r/VictoriaMetrics/)
* [Telegram-en](https://t.me/VictoriaMetrics_en)
* [Telegram-ru](https://t.me/VictoriaMetrics_ru1)
* [Mastodon](https://mastodon.social/@victoriametrics/)

If you like VictoriaMetrics and want to contribute, then please [read these docs](https://docs.victoriametrics.com/victoriametrics/contributing/).

## VictoriaMetrics Logo

The provided [ZIP file](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/VM_logo.zip) contains three folders with different logo orientations. Each folder includes the following file types:

* JPEG: Preview files
* PNG: Preview files with transparent background
* AI: Adobe Illustrator files

### VictoriaMetrics Logo Usage Guidelines

#### Font

* Font Used: Lato Black
* Download here: [Lato Font](https://fonts.google.com/specimen/Lato)

#### Color Palette

* Black [#000000](https://www.color-hex.com/color/000000)
* Purple [#4d0e82](https://www.color-hex.com/color/4d0e82)
* Orange [#ff2e00](https://www.color-hex.com/color/ff2e00)
* White [#ffffff](https://www.color-hex.com/color/ffffff)

### Logo Usage Rules

* Only use the Lato Black font as specified.
* Maintain sufficient clear space around the logo for visibility.
* Do not modify the spacing, alignment, or positioning of design elements.
* You may resize the logo as needed, but ensure all proportions remain intact.

Thank you for your cooperation!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[projectdiscovery/nuclei]]></title>
            <link>https://github.com/projectdiscovery/nuclei</link>
            <guid>https://github.com/projectdiscovery/nuclei</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[Nuclei is a fast, customizable vulnerability scanner powered by the global security community and built on a simple YAML-based DSL, enabling collaboration to tackle trending vulnerabilities on the internet. It helps you find vulnerabilities in your applications, APIs, networks, DNS, and cloud configurations.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/projectdiscovery/nuclei">projectdiscovery/nuclei</a></h1>
            <p>Nuclei is a fast, customizable vulnerability scanner powered by the global security community and built on a simple YAML-based DSL, enabling collaboration to tackle trending vulnerabilities on the internet. It helps you find vulnerabilities in your applications, APIs, networks, DNS, and cloud configurations.</p>
            <p>Language: Go</p>
            <p>Stars: 24,630</p>
            <p>Forks: 2,873</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>![nuclei](/static/nuclei-cover-image.png)

&lt;div align=&quot;center&quot;&gt;
  
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README.md&quot;&gt;`English`&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_CN.md&quot;&gt;`‰∏≠Êñá`&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_KR.md&quot;&gt;`Korean`&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_ID.md&quot;&gt;`Indonesia`&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_ES.md&quot;&gt;`Spanish`&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_JP.md&quot;&gt;`Êó•Êú¨Ë™û`&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://github.com/projectdiscovery/nuclei/blob/main/README_PT-BR.md&quot;&gt;`Portuguese`&lt;/a&gt;
  
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;

&lt;img src=&quot;https://img.shields.io/badge/go-1.22-%2300ADD8.svg?style=for-the-badge&amp;logo=go&amp;logoColor=white&quot;&gt;
&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://docs.projectdiscovery.io/tools/nuclei/overview?utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Documentation-%23000000.svg?style=for-the-badge&amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9IiNmZmZmZmYiIHN0cm9rZS13aWR0aD0iMiIgc3Ryb2tlLWxpbmVjYXA9InJvdW5kIiBzdHJva2UtbGluZWpvaW49InJvdW5kIiBjbGFzcz0ibHVjaWRlIGx1Y2lkZS1ib29rLW9wZW4iPjxwYXRoIGQ9Ik0xMiA3djE0Ii8+PHBhdGggZD0iTTMgMThhMSAxIDAgMCAxLTEtMVY0YTEgMSAwIDAgMSAxLTFoNWE0IDQgMCAwIDEgNCA0IDQgNCAwIDAgMSA0LTRoNWExIDEgMCAwIDEgMSAxdjEzYTEgMSAwIDAgMS0xIDFoLTZhMyAzIDAgMCAwLTMgMyAzIDMgMCAwIDAtMy0zeiIvPjwvc3ZnPg==&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/projectdiscovery/nuclei-templates&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Templates Library-%23000000.svg?style=for-the-badge&amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNiIgaGVpZ2h0PSIxNiIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9IiNmZmZmZmYiIHN0cm9rZS13aWR0aD0iMS41IiBzdHJva2UtbGluZWNhcD0icm91bmQiIHN0cm9rZS1saW5lam9pbj0icm91bmQiIGNsYXNzPSJsdWNpZGUgbHVjaWRlLXNoaWVsZCI+PHBhdGggZD0iTTIwIDEzYzAgNS0zLjUgNy41LTcuNjYgOC45NWExIDEgMCAwIDEtLjY3LS4wMUM3LjUgMjAuNSA0IDE4IDQgMTNWNmExIDEgMCAwIDEgMS0xYzIgMCA0LjUtMS4yIDYuMjQtMi43MmExLjE3IDEuMTcgMCAwIDEgMS41MiAwQzE0LjUxIDMuODEgMTcgNSAxOSA1YTEgMSAwIDAgMSAxIDF6Ii8+PC9zdmc+&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://discord.gg/projectdiscovery?utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot;&gt;&lt;/a&gt;

&lt;hr&gt;

&lt;/p&gt;

&lt;br&gt;

**Nuclei is a modern, high-performance vulnerability scanner that leverages simple YAML-based templates. It empowers you to design custom vulnerability detection scenarios that mimic real-world conditions, leading to zero false positives.**

- Simple YAML format for creating and customizing vulnerability templates.
- Contributed by thousands of security professionals to tackle trending vulnerabilities.
- Reduce false positives by simulating real-world steps to verify a vulnerability.
- Ultra-fast parallel scan processing and request clustering.
- Integrate into CI/CD pipelines for vulnerability detection and regression testing.
- Supports multiple protocols like TCP, DNS, HTTP, SSL, WHOIS JavaScript, Code and more.
- Integrate with Jira, Splunk, GitHub, Elastic, GitLab.

&lt;br&gt;
&lt;br&gt;

## Table of Contents

- [**`Get Started`**](#get-started)
  - [_`1. Nuclei CLI`_](#1-nuclei-cli)
  - [_`2. Pro and Enterprise Editions`_](#2-pro-and-enterprise-editions)
- [**`Documentation`**](#documentation)
  - [_`Command Line Flags`_](#command-line-flags)
  - [_`Single target scan`_](#single-target-scan)
  - [_`Scanning multiple targets`_](#scanning-multiple-targets)
  - [_`Network scan`_](#network-scan)
  - [_`Scanning with your custom template`_](#scanning-with-your-custom-template)
  - [_`Connect Nuclei to ProjectDiscovery_`_](#connect-nuclei-to-projectdiscovery)
- [**`Nuclei Templates, Community and Rewards`**](#nuclei-templates-community-and-rewards-) üíé
- [**`Our Mission`**](#our-mission)
- [**`Contributors`**](#contributors-heart) ‚ù§
- [**`License`**](#license)

&lt;br&gt;
&lt;br&gt;

## Get Started

### **1. Nuclei CLI**

_Install Nuclei on your machine. Get started by following the installation guide [**`here`**](https://docs.projectdiscovery.io/tools/nuclei/install?utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme). Additionally, We provide [**`a free cloud tier`**](https://cloud.projectdiscovery.io/sign-up) and comes with a generous monthly free limits:_

- Store and visualize your vulnerability findings
- Write and manage your nuclei templates
- Access latest nuclei templates
- Discover and store your targets

&gt; [!Important]
&gt; |**This project is in active development**. Expect breaking changes with releases. Review the release changelog before updating.|
&gt; |:--------------------------------|
&gt; | This project is primarily built to be used as a standalone CLI tool. **Running nuclei as a service may pose security risks.** It&#039;s recommended to use with caution and additional security measures. |

&lt;br&gt;

### **2. Pro and Enterprise Editions**

_For security teams and enterprises, we provide a cloud-hosted service built on top of Nuclei OSS, fine-tuned to help you continuously run vulnerability scans at scale with your team and existing workflows:_

- 50x faster scans
- Large scale scanning with high accuracy
- Integrations with cloud services (AWS, GCP, Azure, CloudFlare, Fastly, Terraform, Kubernetes)
- Jira, Slack, Linear, APIs and Webhooks
- Executive and compliance reporting
- Plus: Real-time scanning, SAML SSO, SOC 2 compliant platform (with EU and US hosting options), shared team workspaces, and more
- We&#039;re constantly [**`adding new features`**](https://feedback.projectdiscovery.io/changelog)!
- **Ideal for:** Pentesters, security teams, and enterprises

[**`Sign up to Pro`**](https://projectdiscovery.io/pricing?utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme) or [**`Talk to our team`**](https://projectdiscovery.io/request-demo?utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme) if you have large organization and complex requirements.

&lt;br&gt;
&lt;br&gt;

## Documentation

Browse the full Nuclei [**`documentation here`**](https://docs.projectdiscovery.io/tools/nuclei/running). If you‚Äôre new to Nuclei, check out our [**`foundational Youtube series`**](https://www.youtube.com/playlist?list=PLZRbR9aMzTTpItEdeNSulo8bYsvil80Rl).

&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://www.youtube.com/watch?v=b5qMyQvL1ZA&amp;list=PLZRbR9aMzTTpItEdeNSulo8bYsvil80Rl&amp;utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/static/nuclei-getting-started.png&quot; width=&quot;350px&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://www.youtube.com/watch?v=nFXygQdtjyw&amp;utm_source=github&amp;utm_medium=web&amp;utm_campaign=nuclei_readme&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;/static/nuclei-write-your-first-template.png&quot; width=&quot;350px&quot;&gt;&lt;/a&gt;

&lt;/div&gt;

&lt;br&gt;

### Installation

`nuclei` requires **go1.23** to install successfully. Run the following command to get the repo:

```sh
go install -v github.com/projectdiscovery/nuclei/v3/cmd/nuclei@latest
```

To learn more about installing nuclei, see `https://docs.projectdiscovery.io/tools/nuclei/install`.

### Command Line Flags

To display all the flags for the tool:

```sh
nuclei -h
```

&lt;details&gt;
  &lt;summary&gt;Expand full help flags&lt;/summary&gt;

```yaml
Nuclei is a fast, template based vulnerability scanner focusing
on extensive configurability, massive extensibility and ease of use.

Usage:
  ./nuclei [flags]

Flags:
TARGET:
   -u, -target string[]          target URLs/hosts to scan
   -l, -list string              path to file containing a list of target URLs/hosts to scan (one per line)
   -eh, -exclude-hosts string[]  hosts to exclude to scan from the input list (ip, cidr, hostname)
   -resume string                resume scan using resume.cfg (clustering will be disabled)
   -sa, -scan-all-ips            scan all the IP&#039;s associated with dns record
   -iv, -ip-version string[]     IP version to scan of hostname (4,6) - (default 4)

TARGET-FORMAT:
   -im, -input-mode string        mode of input file (list, burp, jsonl, yaml, openapi, swagger) (default &quot;list&quot;)
   -ro, -required-only            use only required fields in input format when generating requests
   -sfv, -skip-format-validation  skip format validation (like missing vars) when parsing input file

TEMPLATES:
   -nt, -new-templates                    run only new templates added in latest nuclei-templates release
   -ntv, -new-templates-version string[]  run new templates added in specific version
   -as, -automatic-scan                   automatic web scan using wappalyzer technology detection to tags mapping
   -t, -templates string[]                list of template or template directory to run (comma-separated, file)
   -turl, -template-url string[]          template url or list containing template urls to run (comma-separated, file)
   -ai, -prompt string                    generate and run template using ai prompt
   -w, -workflows string[]                list of workflow or workflow directory to run (comma-separated, file)
   -wurl, -workflow-url string[]          workflow url or list containing workflow urls to run (comma-separated, file)
   -validate                              validate the passed templates to nuclei
   -nss, -no-strict-syntax                disable strict syntax check on templates
   -td, -template-display                 displays the templates content
   -tl                                    list all available templates
   -tgl                                   list all available tags
   -sign                                  signs the templates with the private key defined in NUCLEI_SIGNATURE_PRIVATE_KEY env variable
   -code                                  enable loading code protocol-based templates
   -dut, -disable-unsigned-templates      disable running unsigned templates or templates with mismatched signature
   -esc, -enable-self-contained           enable loading self-contained templates
   -egm, -enable-global-matchers          enable loading global matchers templates
   -file                                  enable loading file templates

FILTERING:
   -a, -author string[]               templates to run based on authors (comma-separated, file)
   -tags string[]                     templates to run based on tags (comma-separated, file)
   -etags, -exclude-tags string[]     templates to exclude based on tags (comma-separated, file)
   -itags, -include-tags string[]     tags to be executed even if they are excluded either by default or configuration
   -id, -template-id string[]         templates to run based on template ids (comma-separated, file, allow-wildcard)
   -eid, -exclude-id string[]         templates to exclude based on template ids (comma-separated, file)
   -it, -include-templates string[]   path to template file or directory to be executed even if they are excluded either by default or configuration
   -et, -exclude-templates string[]   path to template file or directory to exclude (comma-separated, file)
   -em, -exclude-matchers string[]    template matchers to exclude in result
   -s, -severity value[]              templates to run based on severity. Possible values: info, low, medium, high, critical, unknown
   -es, -exclude-severity value[]     templates to exclude based on severity. Possible values: info, low, medium, high, critical, unknown
   -pt, -type value[]                 templates to run based on protocol type. Possible values: dns, file, http, headless, tcp, workflow, ssl, websocket, whois, code, javascript
   -ept, -exclude-type value[]        templates to exclude based on protocol type. Possible values: dns, file, http, headless, tcp, workflow, ssl, websocket, whois, code, javascript
   -tc, -template-condition string[]  templates to run based on expression condition

OUTPUT:
   -o, -output string            output file to write found issues/vulnerabilities
   -sresp, -store-resp           store all request/response passed through nuclei to output directory
   -srd, -store-resp-dir string  store all request/response passed through nuclei to custom directory (default &quot;output&quot;)
   -silent                       display findings only
   -nc, -no-color                disable output content coloring (ANSI escape codes)
   -j, -jsonl                    write output in JSONL(ines) format
   -irr, -include-rr -omit-raw   include request/response pairs in the JSON, JSONL, and Markdown outputs (for findings only) [DEPRECATED use -omit-raw] (default true)
   -or, -omit-raw                omit request/response pairs in the JSON, JSONL, and Markdown outputs (for findings only)
   -ot, -omit-template           omit encoded template in the JSON, JSONL output
   -nm, -no-meta                 disable printing result metadata in cli output
   -ts, -timestamp               enables printing timestamp in cli output
   -rdb, -report-db string       nuclei reporting database (always use this to persist report data)
   -ms, -matcher-status          display match failure status
   -me, -markdown-export string  directory to export results in markdown format
   -se, -sarif-export string     file to export results in SARIF format
   -je, -json-export string      file to export results in JSON format
   -jle, -jsonl-export string    file to export results in JSONL(ine) format
   -rd, -redact string[]         redact given list of keys from query parameter, request header and body

CONFIGURATIONS:
   -config string                        path to the nuclei configuration file
   -tp, -profile string                  template profile config file to run
   -tpl, -profile-list                   list community template profiles
   -fr, -follow-redirects                enable following redirects for http templates
   -fhr, -follow-host-redirects          follow redirects on the same host
   -mr, -max-redirects int               max number of redirects to follow for http templates (default 10)
   -dr, -disable-redirects               disable redirects for http templates
   -rc, -report-config string            nuclei reporting module configuration file
   -H, -header string[]                  custom header/cookie to include in all http request in header:value format (cli, file)
   -V, -var value                        custom vars in key=value format
   -r, -resolvers string                 file containing resolver list for nuclei
   -sr, -system-resolvers                use system DNS resolving as error fallback
   -dc, -disable-clustering              disable clustering of requests
   -passive                              enable passive HTTP response processing mode
   -fh2, -force-http2                    force http2 connection on requests
   -ev, -env-vars                        enable environment variables to be used in template
   -cc, -client-cert string              client certificate file (PEM-encoded) used for authenticating against scanned hosts
   -ck, -client-key string               client key file (PEM-encoded) used for authenticating against scanned hosts
   -ca, -client-ca string                client certificate authority file (PEM-encoded) used for authenticating against scanned hosts
   -sml, -show-match-line                show match lines for file templates, works with extractors only
   -ztls                                 use ztls library with autofallback to standard one for tls13 [Deprecated] autofallback to ztls is enabled by default
   -sni string                           tls sni hostname to use (default: input domain name)
   -dka, -dialer-keep-alive value        keep-alive duration for network requests.
   -lfa, -allow-local-file-access        allows file (payload) access anywhere on the system
   -lna, -restrict-local-network-access  blocks connections to the local / private network
   -i, -interface string                 network interface to use for network scan
   -at, -attack-type string              type of payload combinations to perform (batteringram,pitchfork,clusterbomb)
   -sip, -source-ip string               source ip address to use for network scan
   -rsr, -response-size-read int         max response size to read in bytes
   -rss, -response-size-save int         max response size to read in bytes (default 1048576)
   -reset                                reset removes all nuclei configuration and data files (including nuclei-templates)
   -tlsi, -tls-impersonate               enable experimental client hello (ja3) tls randomization
   -hae, -http-api-endpoint string       experimental http api endpoint

INTERACTSH:
   -iserver, -interactsh-server string  interactsh server url for self-hosted instance (default: oast.pro,oast.live,oast.site,oast.online,oast.fun,oast.me)
   -itoken, -interactsh-token string    authentication token for self-hosted interactsh server
   -interactions-cache-size int         number of requests to keep in the interactions cache (default 5000)
   -interactions-eviction int           number of seconds to wait before evicting requests from cache (default 60)
   -interactions-poll-duration int      number of seconds to wait before each interaction poll request (default 5)
   -interactions-cooldown-period int    extra time for interaction polling before exiting (default 5)
   -ni, -no-interactsh                  disable interactsh server for OAST testing, exclude OAST based templates

FUZZING:
   -ft, -fuzzing-type string           overrides fuzzing type set in template (replace, prefix, postfix, infix)
   -fm, -fuzzing-mode string           overrides fuzzing mode set in template (multiple, single)
   -fuzz                               enable loading fuzzing templates (Deprecated: use -dast instead)
   -dast                               enable / run dast (fuzz) nuclei templates
   -dts, -dast-server                  enable dast server mode (live fuzzing)
   -dtr, -dast-report                  write dast scan report to file
   -dtst, -dast-server-token string    dast server token (optional)
   -dtsa, -dast-server-address string  dast server address (default &quot;localhost:9055&quot;)
   -dfp, -display-fuzz-points          display fuzz points in the output for debugging
   -fuzz-param-frequency int           frequency of uninteresting parameters for fuzzing before skipping (default 10)
   -fa, -fuzz-aggression string        fuzzing aggression level controls payload count for fuzz (low, medium, high) (default &quot;low&quot;)
   -cs, -fuzz-scope string[]           in scope url regex to be followed by fuzzer
   -cos, -fuzz-out-scope string[]      out of scope url regex to be excluded by fuzzer

UNCOVER:
   -uc, -uncover                  enable uncover engine
   -uq, -uncover-query string[]   uncover search query
   -ue, -uncover-engine string[]  uncover search engine (shodan,censys,fofa,shodan-idb,quake,hunter,zoomeye,netlas,criminalip,publicwww,hunterhow,google) (default shodan)
   -uf, -uncover-field string     uncover fields to return (ip,port,host) (default &quot;ip:port&quot;)
   -ul, -uncover-limit int        uncover results to return (default 100)
   -ur, -uncover-ratelimit int    override ratelimit of engines with unknown ratelimit (default 60 req/min) (default 60)

RATE-LIMIT:
   -rl, -rate-limit int               maximum number of requests to send per second (default 150)
   -rld, -rate-limit-duration value   maximum number of requests to send per second (default 1s)
   -rlm, -rate-limit-minute int       maximum number of requests to send per minute (DEPRECATED)
   -bs, -bulk-size int                maximum number of hosts to be analyzed in parallel per template (default 25)
   -c, -concurrency int               maximum number of templates to be executed in parallel (default 25)
   -hbs, -headless-bulk-size int      maximum number of headless hosts to be analyzed in parallel per template (default 10)
   -headc, -headles

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vllm-project/aibrix]]></title>
            <link>https://github.com/vllm-project/aibrix</link>
            <guid>https://github.com/vllm-project/aibrix</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[Cost-efficient and pluggable Infrastructure components for GenAI inference]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vllm-project/aibrix">vllm-project/aibrix</a></h1>
            <p>Cost-efficient and pluggable Infrastructure components for GenAI inference</p>
            <p>Language: Go</p>
            <p>Stars: 4,180</p>
            <p>Forks: 449</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre># AIBrix

Welcome to AIBrix, an open-source initiative designed to provide essential building blocks to construct scalable GenAI inference infrastructure. AIBrix delivers a cloud-native solution optimized for deploying, managing, and scaling large language model (LLM) inference, tailored specifically to enterprise needs.


&lt;p align=&quot;center&quot;&gt;
| &lt;a href=&quot;https://aibrix.readthedocs.io/latest/&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://aibrix.github.io/&quot;&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://arxiv.org/abs/2504.03648&quot;&gt;&lt;b&gt;White Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://x.com/vllm_project&quot;&gt;&lt;b&gt;Twitter/X&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://vllm-dev.slack.com/archives/C08EQ883CSV&quot;&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

## Latest News

- **[2025-08-05]** AIBrix v0.4.0 is released. Check out the [release notes](https://github.com/vllm-project/aibrix/releases/tag/v0.4.0) and [Blog Post](https://aibrix.github.io/posts/2025-08-04-v0.4.0-release/) for more details
- **[2025-06-10]** The AIBrix team delivered a talk at KubeCon China 2025 titled [AIBrix: Cost-Effective and Scalable Kubernetes Control Plane for vLLM](https://kccncchn2025.sched.com/event/1x5im/introducing-aibrix-cost-effective-and-scalable-kubernetes-control-plane-for-vllm-jiaxin-shan-liguang-xie-bytedance), discussing how the framework optimizes vLLM deployment via Kubernetes for cost efficiency and scalability.
- **[2025-05-21]** AIBrix v0.3.0 is released. Check out the [release notes](https://github.com/vllm-project/aibrix/releases/tag/v0.3.0) and [Blog Post](https://aibrix.github.io/posts/2025-05-21-v0.3.0-release/) for more details
- **[2025-04-04]** AIBrix co-delivered a KubeCon EU 2025 keynote with Google on [LLM-Aware Load Balancing in Kubernetes: A New Era of Efficiency](https://kccnceu2025.sched.com/event/1txC7/keynote-llm-aware-load-balancing-in-kubernetes-a-new-era-of-efficiency-clayton-coleman-distinguished-engineer-google-jiaxin-shan-software-engineer-bytedance), focusing on LLM specific routing solutions.
- **[2025-03-30]** AIBrix was featured at the [ASPLOS&#039;25](http://asplos-conference.org/asplos2025/) workshop with the presentation [AIBrix: An Open-Source, Large-Scale LLM Inference Infrastructure for System Research](https://docs.google.com/presentation/d/1YDVsPFTIgGXnROGaJ1VKuDDAB4T5fzpE/edit), showcasing its architecture for efficient LLM inference in system research scenarios.
- **[2025-03-09]** AIBrix v0.2.1 is released. DeepSeek-R1 full weights deployment is supported and gateway stability has been improved! Check [Blog Post](https://aibrix.github.io/posts/2025-03-10-deepseek-r1/) for more details.
- **[2025-02-19]** AIBrix v0.2.0 is released. Check out the [release notes](https://github.com/vllm-project/aibrix/releases/tag/v0.2.0) and [Blog Post](https://aibrix.github.io/posts/2025-02-05-v0.2.0-release/) for more details.
- **[2024-11-13]** AIBrix v0.1.0 is released. Check out the [release notes](https://github.com/vllm-project/aibrix/releases/tag/v0.1.0) and [Blog Post](https://aibrix.github.io/posts/2024-11-12-v0.1.0-release/) for more details.

## Key Features

The initial release includes the following key features:

- **High-Density LoRA Management**: Streamlined support for lightweight, low-rank adaptations of models.
- **LLM Gateway and Routing**: Efficiently manage and direct traffic across multiple models and replicas.
- **LLM App-Tailored Autoscaler**: Dynamically scale inference resources based on real-time demand.
- **Unified AI Runtime**: A versatile sidecar enabling metric standardization, model downloading, and management.
- **Distributed Inference**: Scalable architecture to handle large workloads across multiple nodes.
- **Distributed KV Cache**: Enables high-capacity, cross-engine KV reuse.
- **Cost-efficient Heterogeneous Serving**: Enables mixed GPU inference to reduce costs with SLO guarantees.
- **GPU Hardware Failure Detection**: Proactive detection of GPU hardware issues.

## Architecture

![aibrix-architecture-v1](docs/source/assets/images/aibrix-architecture-v1.jpeg)


## Quick Start

To get started with AIBrix, clone this repository and follow the setup instructions in the documentation. Our comprehensive guide will help you configure and deploy your first LLM infrastructure seamlessly.

```shell
# Local Testing
git clone https://github.com/vllm-project/aibrix.git
cd aibrix

# Install nightly aibrix dependencies
kubectl apply -k config/dependency --server-side

# Install nightly aibrix components
kubectl apply -k config/default
```

Install stable distribution
```shell
# Install component dependencies
kubectl apply -f &quot;https://github.com/vllm-project/aibrix/releases/download/v0.4.0/aibrix-dependency-v0.4.0.yaml&quot; --server-side

# Install aibrix components
kubectl apply -f &quot;https://github.com/vllm-project/aibrix/releases/download/v0.4.0/aibrix-core-v0.4.0.yaml&quot;
```

## Documentation

For detailed documentation on installation, configuration, and usage, please visit our [documentation page](https://aibrix.readthedocs.io/latest/).

## Contributing

We welcome contributions from the community! Check out our [contributing guidelines](./CONTRIBUTING.md) to see how you can make a difference.

Slack Channel: [#aibrix](https://vllm-dev.slack.com/archives/C08EQ883CSV)

## License

AIBrix is licensed under the [Apache 2.0 License](LICENSE).

## Support

If you have any questions or encounter any issues, please submit an issue on our [GitHub issues page](https://github.com/vllm-project/aibrix/issues).

Thank you for choosing AIBrix for your GenAI infrastructure needs!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[syncthing/syncthing]]></title>
            <link>https://github.com/syncthing/syncthing</link>
            <guid>https://github.com/syncthing/syncthing</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[Open Source Continuous File Synchronization]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/syncthing/syncthing">syncthing/syncthing</a></h1>
            <p>Open Source Continuous File Synchronization</p>
            <p>Language: Go</p>
            <p>Stars: 75,855</p>
            <p>Forks: 4,748</p>
            <p>Stars today: 48 stars today</p>
            <h2>README</h2><pre>[![Syncthing][14]][15]

---

[![MPLv2 License](https://img.shields.io/badge/license-MPLv2-blue.svg?style=flat-square)](https://www.mozilla.org/MPL/2.0/)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/88/badge)](https://bestpractices.coreinfrastructure.org/projects/88)
[![Go Report Card](https://goreportcard.com/badge/github.com/syncthing/syncthing)](https://goreportcard.com/report/github.com/syncthing/syncthing)

## Goals

Syncthing is a **continuous file synchronization program**. It synchronizes
files between two or more computers. We strive to fulfill the goals below.
The goals are listed in order of importance, the most important ones first.
This is the summary version of the goal list - for more
commentary, see the full [Goals document][13].

Syncthing should be:

1. **Safe From Data Loss**

   Protecting the user&#039;s data is paramount. We take every reasonable
   precaution to avoid corrupting the user&#039;s files.

2. **Secure Against Attackers**

   Again, protecting the user&#039;s data is paramount. Regardless of our other
   goals, we must never allow the user&#039;s data to be susceptible to
   eavesdropping or modification by unauthorized parties.

3. **Easy to Use**

   Syncthing should be approachable, understandable, and inclusive.

4. **Automatic**

   User interaction should be required only when absolutely necessary.

5. **Universally Available**

   Syncthing should run on every common computer. We are mindful that the
   latest technology is not always available to every individual.

6. **For Individuals**

   Syncthing is primarily about empowering the individual user with safe,
   secure, and easy to use file synchronization.

7. **Everything Else**

   There are many things we care about that don&#039;t make it on to the list. It
   is fine to optimize for these values, as long as they are not in conflict
   with the stated goals above.

## Getting Started

Take a look at the [getting started guide][2].

There are a few examples for keeping Syncthing running in the background
on your system in [the etc directory][3]. There are also several [GUI
implementations][11] for Windows, Mac, and Linux.

## Docker

To run Syncthing in Docker, see [the Docker README][16].

## Getting in Touch

The first and best point of contact is the [Forum][8].
If you&#039;ve found something that is clearly a
bug, feel free to report it in the [GitHub issue tracker][10].

If you believe that you‚Äôve found a Syncthing-related security vulnerability,
please report it by emailing security@syncthing.net. Do not report it in the
Forum or issue tracker.

## Building

Building Syncthing from source is easy. After extracting the source bundle from
a release or checking out git, you just need to run `go run build.go` and the
binaries are created in `./bin`. There&#039;s [a guide][5] with more details on the
build process.

## Signed Releases

Release binaries are GPG signed with the key available from
https://syncthing.net/security/. There is also a built-in automatic
upgrade mechanism (disabled in some distribution channels) which uses a
compiled in ECDSA signature. macOS and Windows binaries are also
code-signed.

## Documentation

Please see the Syncthing [documentation site][6] [[source]][17].

All code is licensed under the [MPLv2 License][7].

[1]: https://docs.syncthing.net/specs/bep-v1.html
[2]: https://docs.syncthing.net/intro/getting-started.html
[3]: https://github.com/syncthing/syncthing/blob/main/etc
[5]: https://docs.syncthing.net/dev/building.html
[6]: https://docs.syncthing.net/
[7]: https://github.com/syncthing/syncthing/blob/main/LICENSE
[8]: https://forum.syncthing.net/
[10]: https://github.com/syncthing/syncthing/issues
[11]: https://docs.syncthing.net/users/contrib.html#gui-wrappers
[13]: https://github.com/syncthing/syncthing/blob/main/GOALS.md
[14]: assets/logo-text-128.png
[15]: https://syncthing.net/
[16]: https://github.com/syncthing/syncthing/blob/main/README-Docker.md
[17]: https://github.com/syncthing/docs
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[amitshekhariitbhu/go-backend-clean-architecture]]></title>
            <link>https://github.com/amitshekhariitbhu/go-backend-clean-architecture</link>
            <guid>https://github.com/amitshekhariitbhu/go-backend-clean-architecture</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[A Go (Golang) Backend Clean Architecture project with Gin, MongoDB, JWT Authentication Middleware, Test, and Docker.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/amitshekhariitbhu/go-backend-clean-architecture">amitshekhariitbhu/go-backend-clean-architecture</a></h1>
            <p>A Go (Golang) Backend Clean Architecture project with Gin, MongoDB, JWT Authentication Middleware, Test, and Docker.</p>
            <p>Language: Go</p>
            <p>Stars: 5,504</p>
            <p>Forks: 585</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre># Go Backend Clean Architecture

A Go (Golang) Backend Clean Architecture project with Gin, MongoDB, JWT Authentication Middleware, Test, and Docker.

![Go Backend Clean Architecture](https://github.com/amitshekhariitbhu/go-backend-clean-architecture/blob/main/assets/go-backend-clean-architecture.png?raw=true)

**You can use this project as a template to build your Backend project in the Go language on top of this project.**

Before creating this project, I have gone through more than 20 projects related to the Go(Golang) Clean Architecture on GitHub.

Thanks to all those projects, I learned a lot from all of those. As I keep saying:

&gt; The best way to learn to code is to code. But, to write good code, you will also have to read good code. Make a habit of reading good code. You can find many open-source projects on GitHub and start reading.

Then for the implementation part, I combined all of my ideas, experiences, and learnings from those projects to create this project.

And as always I would love to get feedback on my project. This helps everyone and most importantly me.

Learn about this project architecture in detail from the blogs mentioned below:

- [Go Backend Clean Architecture](https://outcomeschool.com/blog/go-backend-clean-architecture)
- [Go JWT Authentication Middleware](https://outcomeschool.com/blog/go-jwt-authentication-middleware)
- [Configuration with Viper in Go](https://outcomeschool.com/blog/configuration-with-viper-in-go)
- [Test with Testify and Mockery in Go](https://outcomeschool.com/blog/test-with-testify-and-mockery-in-go)
- [Database Normalization vs Denormalization](https://outcomeschool.com/blog/database-normalization-vs-denormalization)

## Architecture Layers of the project

- Router
- Controller
- Usecase
- Repository
- Domain

![Go Backend Clean Architecture Diagram](https://github.com/amitshekhariitbhu/go-backend-clean-architecture/blob/main/assets/go-backend-arch-diagram.png?raw=true)

## About me

Hi, I am Amit Shekhar, Co-Founder @ [Outcome School](https://outcomeschool.com) ‚Ä¢ IIT 2010-14 ‚Ä¢ I have taught and mentored many developers, and their efforts landed them high-paying tech jobs, helped many tech companies in solving their unique problems, and created many open-source libraries being used by top companies. I am passionate about sharing knowledge through open-source, blogs, and videos.

You can connect with me on:

- [Twitter](https://twitter.com/amitiitbhu)
- [YouTube](https://www.youtube.com/@amitshekhar)
- [LinkedIn](https://www.linkedin.com/in/amit-shekhar-iitbhu)
- [GitHub](https://github.com/amitshekhariitbhu)

## System Design Playlist on YouTube

We have launched our YouTube channel. Subscribe to the [Outcome School YouTube Channel](https://www.youtube.com/@OutcomeSchool)

- [What is System Design?](https://www.youtube.com/watch?v=i4YWRY3hsdA)
- [Twitter Timeline Design with Fanout Approach - System Design](https://www.youtube.com/watch?v=_7qHGfwgPz0)
- [HTTP Request vs HTTP Long-Polling vs WebSocket vs Server-Sent Events](https://www.youtube.com/watch?v=8ksWRX4xV-s)
- [YouTube Video Upload Service - System Design](https://www.youtube.com/watch?v=N0vvJTkokZc)
- [What is Consistent Hashing?](https://www.youtube.com/watch?v=dV5cIm9T3ss)
- [Capacity Estimation: Back-of-the-envelope calculation - Twitter](https://www.youtube.com/watch?v=yrbKxzXm6_Q)

Prepare for Machine Learning Interview: [Machine Learning Interview Questions](https://github.com/amitshekhariitbhu/machine-learning-interview-questions)

## Major Packages used in this project

- **gin**: Gin is an HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance -- up to 40 times faster. If you need a smashing performance, get yourself some Gin.
- **mongo go driver**: The Official Golang driver for MongoDB.
- **jwt**: JSON Web Tokens are an open, industry-standard RFC 7519 method for representing claims securely between two parties. Used for Access Token and Refresh Token.
- **viper**: For loading configuration from the `.env` file. Go configuration with fangs. Find, load, and unmarshal a configuration file in JSON, TOML, YAML, HCL, INI, envfile, or Java properties formats.
- **bcrypt**: Package bcrypt implements Provos and Mazi√®res&#039;s bcrypt adaptive hashing algorithm.
- **testify**: A toolkit with common assertions and mocks that plays nicely with the standard library.
- **mockery**: A mock code autogenerator for Golang used in testing.
- Check more packages in `go.mod`.

### Public API Request Flow without JWT Authentication Middleware

![Public API Request Flow](https://github.com/amitshekhariitbhu/go-backend-clean-architecture/blob/main/assets/go-arch-public-api-request-flow.png?raw=true)

### Private API Request Flow with JWT Authentication Middleware

&gt; JWT Authentication Middleware for Access Token Validation.

![Private API Request Flow](https://github.com/amitshekhariitbhu/go-backend-clean-architecture/blob/main/assets/go-arch-private-api-request-flow.png?raw=true)

### How to run this project?

We can run this Go Backend Clean Architecture project with or without Docker. Here, I am providing both ways to run this project.

- Clone this project

```bash
# Move to your workspace
cd your-workspace

# Clone this project into your workspace
git clone https://github.com/amitshekhariitbhu/go-backend-clean-architecture.git

# Move to the project root directory
cd go-backend-clean-architecture
```

#### Run without Docker

- Create a file `.env` similar to `.env.example` at the root directory with your configuration.
- Install `go` if not installed on your machine.
- Install `MongoDB` if not installed on your machine.
- Important: Change the `DB_HOST` to `localhost` (`DB_HOST=localhost`) in `.env` configuration file. `DB_HOST=mongodb` is needed only when you run with Docker.
- Run `go run cmd/main.go`.
- Access API using `http://localhost:8080`

#### Run with Docker

- Create a file `.env` similar to `.env.example` at the root directory with your configuration.
- Install Docker and Docker Compose.
- Run `docker-compose up -d`.
- Access API using `http://localhost:8080`

### How to run the test?

```bash
# Run all tests
go test ./...
```

### How to generate the mock code?

In this project, to test, we need to generate mock code for the use-case, repository, and database.

```bash
# Generate mock code for the usecase and repository
mockery --dir=domain --output=domain/mocks --outpkg=mocks --all

# Generate mock code for the database
mockery --dir=mongo --output=mongo/mocks --outpkg=mocks --all
```

Whenever you make changes in the interfaces of these use-cases, repositories, or databases, you need to run the corresponding command to regenerate the mock code for testing.

### The Complete Project Folder Structure

```
.
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ api
‚îÇ   ‚îú‚îÄ‚îÄ controller
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ login_controller.go
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ profile_controller.go
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ profile_controller_test.go
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ refresh_token_controller.go
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ signup_controller.go
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ task_controller.go
‚îÇ   ‚îú‚îÄ‚îÄ middleware
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ jwt_auth_middleware.go
‚îÇ   ‚îî‚îÄ‚îÄ route
‚îÇ       ‚îú‚îÄ‚îÄ login_route.go
‚îÇ       ‚îú‚îÄ‚îÄ profile_route.go
‚îÇ       ‚îú‚îÄ‚îÄ refresh_token_route.go
‚îÇ       ‚îú‚îÄ‚îÄ route.go
‚îÇ       ‚îú‚îÄ‚îÄ signup_route.go
‚îÇ       ‚îî‚îÄ‚îÄ task_route.go
‚îú‚îÄ‚îÄ bootstrap
‚îÇ   ‚îú‚îÄ‚îÄ app.go
‚îÇ   ‚îú‚îÄ‚îÄ database.go
‚îÇ   ‚îî‚îÄ‚îÄ env.go
‚îú‚îÄ‚îÄ cmd
‚îÇ   ‚îî‚îÄ‚îÄ main.go
‚îú‚îÄ‚îÄ docker-compose.yaml
‚îú‚îÄ‚îÄ domain
‚îÇ   ‚îú‚îÄ‚îÄ error_response.go
‚îÇ   ‚îú‚îÄ‚îÄ jwt_custom.go
‚îÇ   ‚îú‚îÄ‚îÄ login.go
‚îÇ   ‚îú‚îÄ‚îÄ profile.go
‚îÇ   ‚îú‚îÄ‚îÄ refresh_token.go
‚îÇ   ‚îú‚îÄ‚îÄ signup.go
‚îÇ   ‚îú‚îÄ‚îÄ success_response.go
‚îÇ   ‚îú‚îÄ‚îÄ task.go
‚îÇ   ‚îî‚îÄ‚îÄ user.go
‚îú‚îÄ‚îÄ go.mod
‚îú‚îÄ‚îÄ go.sum
‚îú‚îÄ‚îÄ internal
‚îÇ   ‚îî‚îÄ‚îÄ tokenutil
‚îÇ       ‚îî‚îÄ‚îÄ tokenutil.go
‚îú‚îÄ‚îÄ mongo
‚îÇ   ‚îî‚îÄ‚îÄ mongo.go
‚îú‚îÄ‚îÄ repository
‚îÇ   ‚îú‚îÄ‚îÄ task_repository.go
‚îÇ   ‚îú‚îÄ‚îÄ user_repository.go
‚îÇ   ‚îî‚îÄ‚îÄ user_repository_test.go
‚îî‚îÄ‚îÄ usecase
    ‚îú‚îÄ‚îÄ login_usecase.go
    ‚îú‚îÄ‚îÄ profile_usecase.go
    ‚îú‚îÄ‚îÄ refresh_token_usecase.go
    ‚îú‚îÄ‚îÄ signup_usecase.go
    ‚îú‚îÄ‚îÄ task_usecase.go
    ‚îî‚îÄ‚îÄ task_usecase_test.go
```

### API documentation of Go Backend Clean Architecture

&lt;a href=&quot;https://documenter.getpostman.com/view/391588/2s8Z75S9xy&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;View API Doc Button&quot; src=&quot;https://github.com/amitshekhariitbhu/go-backend-clean-architecture/blob/main/assets/button-view-api-docs.png?raw=true&quot; width=&quot;200&quot; height=&quot;60&quot;/&gt;
&lt;/a&gt;

### Example API Request and Response

- signup

  - Request

  ```
  curl --location --request POST &#039;http://localhost:8080/signup&#039; \
  --data-urlencode &#039;email=test@gmail.com&#039; \
  --data-urlencode &#039;password=test&#039; \
  --data-urlencode &#039;name=Test Name&#039;
  ```

  - Response

  ```json
  {
    &quot;accessToken&quot;: &quot;access_token&quot;,
    &quot;refreshToken&quot;: &quot;refresh_token&quot;
  }
  ```

- login

  - Request

  ```
  curl --location --request POST &#039;http://localhost:8080/login&#039; \
  --data-urlencode &#039;email=test@gmail.com&#039; \
  --data-urlencode &#039;password=test&#039;
  ```

  - Response

  ```json
  {
    &quot;accessToken&quot;: &quot;access_token&quot;,
    &quot;refreshToken&quot;: &quot;refresh_token&quot;
  }
  ```

- profile

  - Request

  ```
  curl --location --request GET &#039;http://localhost:8080/profile&#039; \
  --header &#039;Authorization: Bearer access_token&#039;
  ```

  - Response

  ```json
  {
    &quot;name&quot;: &quot;Test Name&quot;,
    &quot;email&quot;: &quot;test@gmail.com&quot;
  }
  ```

- task create

  - Request

  ```
  curl --location --request POST &#039;http://localhost:8080/task&#039; \
  --header &#039;Authorization: Bearer access_token&#039; \
  --header &#039;Content-Type: application/x-www-form-urlencoded&#039; \
  --data-urlencode &#039;title=Test Task&#039;
  ```

  - Response

  ```json
  {
    &quot;message&quot;: &quot;Task created successfully&quot;
  }
  ```

- task fetch

  - Request

  ```
  curl --location --request GET &#039;http://localhost:8080/task&#039; \
  --header &#039;Authorization: Bearer access_token&#039;
  ```

  - Response

  ```json
  [
    {
      &quot;title&quot;: &quot;Test Task&quot;
    },
    {
      &quot;title&quot;: &quot;Test Another Task&quot;
    }
  ]
  ```

- refresh token

  - Request

  ```
  curl --location --request POST &#039;http://localhost:8080/refresh&#039; \
  --header &#039;Content-Type: application/x-www-form-urlencoded&#039; \
  --data-urlencode &#039;refreshToken=refresh_token&#039;
  ```

  - Response

  ```json
  {
    &quot;accessToken&quot;: &quot;access_token&quot;,
    &quot;refreshToken&quot;: &quot;refresh_token&quot;
  }
  ```

### TODO

- Improvement based on feedback.
- Add more test cases.
- Always try to update with the latest version of the packages used.

## If this project helps you in anyway, show your love ‚ù§Ô∏è by putting a ‚≠ê on this project ‚úåÔ∏è

### License

```
   Copyright (C) 2025 Amit Shekhar

   Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
```

### Contributing to Go Backend Clean Architecture

All pull requests are welcome.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[tmc/langchaingo]]></title>
            <link>https://github.com/tmc/langchaingo</link>
            <guid>https://github.com/tmc/langchaingo</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[LangChain for Go, the easiest way to write LLM-based programs in Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tmc/langchaingo">tmc/langchaingo</a></h1>
            <p>LangChain for Go, the easiest way to write LLM-based programs in Go</p>
            <p>Language: Go</p>
            <p>Stars: 7,538</p>
            <p>Forks: 936</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&gt; üéâ **Join our new official Discord community!** Connect with other LangChain Go developers, get help and contribute: [Join Discord](https://discord.gg/t9UbBQs2rG)

# ü¶úÔ∏èüîó LangChain Go

[![go.dev reference](https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;logoColor=white&amp;style=flat-square)](https://pkg.go.dev/github.com/tmc/langchaingo)
[![scorecard](https://goreportcard.com/badge/github.com/tmc/langchaingo)](https://goreportcard.com/report/github.com/tmc/langchaingo)
[![](https://dcbadge.vercel.app/api/server/t9UbBQs2rG?compact=true&amp;style=flat)](https://discord.gg/t9UbBQs2rG)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/tmc/langchaingo)
[&lt;img src=&quot;https://github.com/codespaces/badge.svg&quot; title=&quot;Open in Github Codespace&quot; width=&quot;150&quot; height=&quot;20&quot;&gt;](https://codespaces.new/tmc/langchaingo)

‚ö° Building applications with LLMs through composability, with Go! ‚ö°

## ü§î What is this?

This is the Go language implementation of [LangChain](https://github.com/langchain-ai/langchain).

## üìñ Documentation

- [Documentation Site](https://tmc.github.io/langchaingo/docs/)
- [API Reference](https://pkg.go.dev/github.com/tmc/langchaingo)


## üéâ Examples

See [./examples](./examples) for example usage.

```go
package main

import (
  &quot;context&quot;
  &quot;fmt&quot;
  &quot;log&quot;

  &quot;github.com/tmc/langchaingo/llms&quot;
  &quot;github.com/tmc/langchaingo/llms/openai&quot;
)

func main() {
  ctx := context.Background()
  llm, err := openai.New()
  if err != nil {
    log.Fatal(err)
  }
  prompt := &quot;What would be a good company name for a company that makes colorful socks?&quot;
  completion, err := llms.GenerateFromSinglePrompt(ctx, llm, prompt)
  if err != nil {
    log.Fatal(err)
  }
  fmt.Println(completion)
}
```

```shell
$ go run .
Socktastic
```

# Resources

Join the Discord server for support and discussions: [Join Discord](https://discord.gg/8bHGKzHBkM)

Here are some links to blog posts and articles on using Langchain Go:

- [Using Gemini models in Go with LangChainGo](https://eli.thegreenplace.net/2024/using-gemini-models-in-go-with-langchaingo/) - Jan 2024
- [Using Ollama with LangChainGo](https://eli.thegreenplace.net/2023/using-ollama-with-langchaingo/) - Nov 2023
- [Creating a simple ChatGPT clone with Go](https://sausheong.com/creating-a-simple-chatgpt-clone-with-go-c40b4bec9267?sk=53a2bcf4ce3b0cfae1a4c26897c0deb0) - Aug 2023
- [Creating a ChatGPT Clone that Runs on Your Laptop with Go](https://sausheong.com/creating-a-chatgpt-clone-that-runs-on-your-laptop-with-go-bf9d41f1cf88?sk=05dc67b60fdac6effb1aca84dd2d654e) - Aug 2023


# Contributors

There is a momentum for moving the development of langchaingo to a more community effort, if you are interested in being a maintainer or you are a contributor please join our [Discord](https://discord.gg/8bHGKzHBkM) and let us know.

&lt;a href=&quot;https://github.com/tmc/langchaingo/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=tmc/langchaingo&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[yorukot/superfile]]></title>
            <link>https://github.com/yorukot/superfile</link>
            <guid>https://github.com/yorukot/superfile</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[Pretty fancy and modern terminal file manager]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yorukot/superfile">yorukot/superfile</a></h1>
            <p>Pretty fancy and modern terminal file manager</p>
            <p>Language: Go</p>
            <p>Stars: 14,916</p>
            <p>Forks: 376</p>
            <p>Stars today: 52 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;p&gt;
  &lt;h4&gt;
    &lt;a href=&quot;https://ko-fi.com/yorukot&quot;&gt;superfile is supported by the community.&lt;/a&gt;
  &lt;/h4&gt;
&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;
   &lt;sup&gt;Special thanks to:&lt;/sup&gt;
   &lt;br&gt;
   &lt;br&gt;
   &lt;a href=&quot;https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=superfile&quot;&gt;
      &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;300&quot; src=&quot;/asset/warp.png&quot;&gt;
   &lt;/a&gt;

### [Warp, the AI terminal for developers](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=superfile)
[Available for MacOS, Linux, &amp; Windows](https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=superfile)&lt;br&gt;

&lt;/div&gt;
&lt;hr&gt;

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;/asset/superfilelogowhite.png&quot; /&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;/asset/superfilelogoblack.png&quot; /&gt;
  &lt;img alt=&quot;superfile LOGO&quot; src=&quot;/asset/superfilelogowhite.png&quot; /&gt;
&lt;/picture&gt;

[![Go Report Card](https://goreportcard.com/badge/github.com/yorukot/superfile)](https://goreportcard.com/report/github.com/yorukot/superfile)
[![License MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://raw.githubusercontent.com/yorukot/superfile/refs/heads/main/LICENSE)
[![Discord Link](https://img.shields.io/discord/1338415256875307110?label=discord&amp;logo=discord&amp;logoColor=white)](https://discord.gg/YYtJ23Du7B)
[![Release](https://img.shields.io/github/v/release/yorukot/superfile.svg?style=flat-square)](https://github.com/yorukot/superfile/releases/latest)
[![CodeRabbit Pull Request Reviews](https://img.shields.io/coderabbit/prs/github/yorukot/superfile?utm_source=oss&amp;utm_medium=github&amp;utm_campaign=yorukot%2Fsuperfile&amp;labelColor=171717&amp;color=FF570A&amp;&amp;label=CodeRabbit+Reviews)](https://www.coderabbit.ai/)

![](/asset/demo.png)

&lt;/div&gt;

## Demo

| Perform common operations |
| ------------------------- |
| ![](/asset/demo.gif)      |

## Content

- [Installation](#installation)
- [Build](#build)
- [Supported Systems](#supported-systems)
- [Tutorial](#tutorial)
- [Plugins](#plugins)
- [Themes](#themes)
- [Hotkeys](#hotkeys)
- [Notes](#notes)
- [Contributing](#contributing)
- [Troubleshooting](#troubleshooting)
- [Thanks](#thanks)
  - [Support](#Support)
  - [Contributors](#contributors)
  - [Star History](#star-history)

## Installation

### MacOS and Linux

```bash
bash -c &quot;$(curl -sLo- https://superfile.netlify.app/install.sh)&quot;
```
If you want to inspect the script, see : [install.sh](./website/public/install.sh)

### Windows

#### Powershell
```powershell
powershell -ExecutionPolicy Bypass -Command &quot;Invoke-Expression ((New-Object System.Net.WebClient).DownloadString(&#039;https://superfile.netlify.app/install.ps1&#039;))&quot;
```
If you want to inspect the script, see : [install.ps1](./website/public/install.ps1)

#### [Winget](https://winget.run/)
```powershell
winget install --id yorukot.superfile
```

#### [Scoop](https://scoop.sh/)
```
scoop install superfile
```

### More installation methods
[Click me to check on how to install](https://superfile.netlify.app/getting-started/installation/)

## Build

You can build the source code yourself by using these steps:

**Requirements**

- [golang](https://go.dev/doc/install)

**Build Steps**

Clone this repository using the following command:

```
git clone https://github.com/yorukot/superfile.git --depth=1
```

Enter the downloaded directory:

```bash
cd superfile
```

### For MacOS/Linux
Run the `build.sh` file:

```bash
./build.sh
```

Add the binary file to your $PATH, e.g., in `/usr/local/bin`:

```bash
sudo mv ./bin/spf /usr/local/bin
```

### For Windows

```bash
go build -o bin/spf.exe
```

Edit System Environment Variables and add superfile repo&#039;s `bin` directory to your PATH  

## Start superfile

```bash
spf
```

## Supported Systems

- \[x\] Linux
- \[x\] MacOS
- \[x\] Windows (Not fully supported yet)

## Tutorial

After you install superfile, you can go [here](https://superfile.netlify.app/getting-started/tutorial/) to briefly understand how to use superfile!

## Plugins

[Click me to the plugins wiki](https://superfile.netlify.app/list/plugin-list/)

## Themes

[Click me to the theme wiki](https://superfile.netlify.app/configure/custom-theme/)

## Hotkeys

&gt; [!WARNING]
&gt; If you are vim/nvim user please change your default hotkeys config to vim version!

[**Click me to see the hotkey wiki**](https://superfile.netlify.app/configure/custom-hotkeys/)

## Notes

We have an auto update functionality, that fetches superfile&#039;s latest released version from github (if last timestamp of last version check was less than 24 hours) and prints a prompt to user, if there is a newer version available.

You can turn this off, by setting `auto_check_update` to false in superfile config. [**Click me to see the config wiki**](https://superfile.netlify.app/configure/superfile-config/) 

## Troubleshooting

[**Click me to see common problem fix**](https://superfile.netlify.app/troubleshooting/)

## Uninstalling

### MacOS and Linux

On MacOS and Linux, you can uninstall superfile by simply removing the binary. If you installed superfile with sudo, runw

```bash
sudo rm /usr/local/bin/spf
```

If you installed superfile without sudo, run

```bash
rm ~/.local/bin/spf
```

If you don&#039;t rember, just try removing both.


### Window

To uninstall superfile on Windows, use this powershell script.

```powershell
powershell -ExecutionPolicy Bypass -Command &quot;Invoke-Expression ((New-Object System.Net.WebClient).DownloadString(&#039;https://superfile.netlify.app/uninstall.ps1&#039;))&quot;
```

## Contributing

If you want to contribute please follow the [contribution guide](./CONTRIBUTING.md)

[**Click me to see changelog**](https://superfile.netlify.app/changelog)

## Thanks

### Support

- a Star on my GitHub repository would be nice üåü
- You can buy a coffee for me üíñ

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/G2G1JEGGC)

### Contributors

**Thanks to all the contributors for making this project even greater!**

&lt;a href=&quot;https://github.com/yorukot/superfile/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=yorukot/superfile&quot; /&gt;
&lt;/a&gt;

### Star History

**THANKS FOR All OF YOUR STARS!**
Your stars are my motivation to keep updating!

&lt;a href=&quot;https://star-history.com/#yorukot/superfile&amp;Timeline&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=yorukot/superfile&amp;type=Timeline&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=yorukot/superfile&amp;type=Timeline&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=yorukot/superfile&amp;type=Timeline&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;


&lt;div align=&quot;center&quot;&gt;

## ‡ºº „Å§ ‚óï_‚óï ‡ºΩ„Å§  Please share.

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[drakkan/sftpgo]]></title>
            <link>https://github.com/drakkan/sftpgo</link>
            <guid>https://github.com/drakkan/sftpgo</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Full-featured and highly configurable SFTP, HTTP/S, FTP/S and WebDAV server - S3, Google Cloud Storage, Azure Blob]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/drakkan/sftpgo">drakkan/sftpgo</a></h1>
            <p>Full-featured and highly configurable SFTP, HTTP/S, FTP/S and WebDAV server - S3, Google Cloud Storage, Azure Blob</p>
            <p>Language: Go</p>
            <p>Stars: 10,964</p>
            <p>Forks: 853</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># SFTPGo

[![CI Status](https://github.com/drakkan/sftpgo/workflows/CI/badge.svg)](https://github.com/drakkan/sftpgo/workflows/CI/badge.svg)
[![License: AGPL-3.0-only](https://img.shields.io/badge/License-AGPLv3-blue.svg)](https://www.gnu.org/licenses/agpl-3.0)
[![Mentioned in Awesome Go](https://awesome.re/mentioned-badge.svg)](https://github.com/avelino/awesome-go)

Full-featured and highly configurable event-driven file transfer solution.
Server protocols: SFTP, HTTP/S, FTP/S, WebDAV.
Storage backends: local filesystem, encrypted local filesystem, S3 (compatible) Object Storage, Google Cloud Storage, Azure Blob Storage, other SFTP servers.

With SFTPGo you can leverage local and cloud storage backends for exchanging and storing files internally or with business partners using the same tools and processes you are already familiar with.

The WebAdmin UI allows to easily create and manage your users, folders, groups and other resources.

The WebClient UI allows end users to change their credentials, browse and manage their files in the browser and setup two-factor authentication which works with Microsoft Authenticator, Google Authenticator, Authy and other compatible apps.

## Sponsors

We strongly believe in Open Source software model, so we decided to make SFTPGo available to everyone, but maintaining and evolving SFTPGo takes a lot of time and work. To make development and maintenance sustainable you should consider to support the project with a [sponsorship](https://github.com/sponsors/drakkan).

We love doing the work and we&#039;d like to keep doing it - your support helps make SFTPGo possible.

It is important to understand that you should support SFTPGo and any other Open Source project you rely on for ongoing maintenance, even if you don&#039;t have any questions or need new features, to mitigate the business risk of a project you depend on going unmaintained, with its security and development velocity implications.

### Thank you to our sponsors

#### Platinum sponsors

[&lt;img src=&quot;./img/Aledade_logo.png&quot; alt=&quot;Aledade logo&quot; width=&quot;202&quot; height=&quot;70&quot;&gt;](https://www.aledade.com/)
&lt;/br&gt;&lt;/br&gt;
[&lt;img src=&quot;./img/jumptrading.png&quot; alt=&quot;Jump Trading logo&quot; width=&quot;362&quot; height=&quot;63&quot;&gt;](https://www.jumptrading.com/)
&lt;/br&gt;&lt;/br&gt;
[&lt;img src=&quot;./img/wpengine.png&quot; alt=&quot;WP Engine logo&quot; width=&quot;331&quot; height=&quot;63&quot;&gt;](https://wpengine.com/)

#### Silver sponsors

[&lt;img src=&quot;./img/IDCS.png&quot; alt=&quot;IDCS logo&quot; width=&quot;212&quot; height=&quot;51&quot;&gt;](https://idcs.ip-paris.fr/)

#### Bronze sponsors

[&lt;img src=&quot;./img/7digital.png&quot; alt=&quot;7digital logo&quot; width=&quot;178&quot; height=&quot;56&quot;&gt;](https://www.7digital.com/)
&lt;/br&gt;&lt;/br&gt;
[&lt;img src=&quot;./img/servinga.png&quot; alt=&quot;servinga logo&quot; width=&quot;258&quot; height=&quot;56&quot;&gt;](https://servinga.com/)
&lt;/br&gt;&lt;/br&gt;
[&lt;img src=&quot;./img/reui.png&quot; alt=&quot;ReUI logo&quot; width=&quot;151&quot; height=&quot;56&quot;&gt;](https://www.reui.io/)

## Support

You can use SFTPGo for free, respecting the obligations of the Open Source [license](#license), but please do not ask or expect free support as well.

Use [discussions](https://github.com/drakkan/sftpgo/discussions) to ask questions and get support from the community.

We offer commercial support, guarantees, and advice for SFTPGo:

- With our [plans](https://sftpgo.com/plans) you can safely install and use SFTPGo on-premise in professional environments.
- With our [SaaS offerings](https://sftpgo.com/saas) you can use SFTPGo hosted in the cloud, fully managed and supported.

## Documentation

You can read more about supported features and documentation at [docs.sftpgo.com](https://docs.sftpgo.com/).

## Internationalization

The translations are available via [Crowdin](https://crowdin.com/project/sftpgo), who have granted us an open source license.

Before start translating please take a look at our contribution [guidelines](https://sftpgo.github.io/latest/web-interfaces/#internationalization).

## Release Cadence

SFTPGo releases are feature-driven, we don&#039;t have a fixed time based schedule. As a rough estimate, you can expect 1 or 2 new major releases per year and several bug fix releases.

## Acknowledgements

SFTPGo makes use of the third party libraries listed inside [go.mod](./go.mod).

We are very grateful to all the people who contributed with ideas and/or pull requests.

Thank you to [ysura](https://www.ysura.com/) for granting us stable access to a test AWS S3 account.

Thank you to [KeenThemes](https://keenthemes.com/) for granting us a custom license to use their amazing [themes](https://keenthemes.com/bootstrap-templates) for the SFTPGo WebAdmin and WebClient user interfaces, across both the Open Source and Open Core versions.

Thank you to [Crowdin](https://crowdin.com/) for granting us an Open Source License.

Thank you to [Incode](https://www.incode.it/) for helping us to improve the UI/UX.

## License

SFTPGo source code is licensed under the GNU AGPL-3.0-only with [additional terms](./NOTICE).

The [theme](https://keenthemes.com/bootstrap-templates) used in WebAdmin and WebClient user interfaces is proprietary, this means:

- KeenThemes HTML/CSS/JS components are allowed for use only within the SFTPGo product and restricted to be used in a resealable HTML template that can compete with KeenThemes products anyhow.
- The SFTPGo WebAdmin and WebClient user interfaces (HTML, CSS and JS components) based on this theme are allowed for use only within the SFTPGo product and therefore cannot be used in derivative works/products without an explicit grant from the [SFTPGo Team](mailto:support@sftpgo.com).

More information about [compliance](https://sftpgo.com/compliance.html).

## Copyright

Copyright (C) 2019 - 2025 Nicola Murino
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[coredns/coredns]]></title>
            <link>https://github.com/coredns/coredns</link>
            <guid>https://github.com/coredns/coredns</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[CoreDNS is a DNS server that chains plugins]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coredns/coredns">coredns/coredns</a></h1>
            <p>CoreDNS is a DNS server that chains plugins</p>
            <p>Language: Go</p>
            <p>Stars: 13,319</p>
            <p>Forks: 2,298</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>[![CoreDNS](https://coredns.io/images/CoreDNS_Colour_Horizontal.png)](https://coredns.io)

[![Documentation](https://img.shields.io/badge/godoc-reference-blue.svg)](https://godoc.org/github.com/coredns/coredns)
![CodeQL](https://github.com/coredns/coredns/actions/workflows/codeql-analysis.yml/badge.svg)
![Go Tests](https://github.com/coredns/coredns/actions/workflows/go.test.yml/badge.svg)
[![CircleCI](https://circleci.com/gh/coredns/coredns.svg?style=shield)](https://circleci.com/gh/coredns/coredns)
[![Code Coverage](https://img.shields.io/codecov/c/github/coredns/coredns/master.svg)](https://codecov.io/github/coredns/coredns?branch=master)
[![Docker Pulls](https://img.shields.io/docker/pulls/coredns/coredns.svg)](https://hub.docker.com/r/coredns/coredns)
[![Go Report Card](https://goreportcard.com/badge/github.com/coredns/coredns)](https://goreportcard.com/report/coredns/coredns)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/1250/badge)](https://bestpractices.coreinfrastructure.org/projects/1250)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/coredns/coredns/badge)](https://scorecard.dev/viewer/?uri=github.com/coredns/coredns)

CoreDNS is a DNS server/forwarder, written in Go, that chains [plugins](https://coredns.io/plugins).
Each plugin performs a (DNS) function.

CoreDNS is a [Cloud Native Computing Foundation](https://cncf.io) graduated project.

CoreDNS is a fast and flexible DNS server. The key word here is *flexible*: with CoreDNS you
are able to do what you want with your DNS data by utilizing plugins. If some functionality is not
provided out of the box you can add it by [writing a plugin](https://coredns.io/explugins).

CoreDNS can listen for DNS requests coming in over:
* UDP/TCP (go&#039;old DNS).
* TLS - DoT ([RFC 7858](https://tools.ietf.org/html/rfc7858)).
* DNS over HTTP/2 - DoH ([RFC 8484](https://tools.ietf.org/html/rfc8484)).
* DNS over QUIC - DoQ ([RFC 9250](https://tools.ietf.org/html/rfc9250)). 
* [gRPC](https://grpc.io) (not a standard).

Currently CoreDNS is able to:

* Serve zone data from a file; both DNSSEC (NSEC only) and DNS are supported (*file* and *auto*).
* Retrieve zone data from primaries, i.e., act as a secondary server (AXFR only) (*secondary*).
* Sign zone data on-the-fly (*dnssec*).
* Load balancing of responses (*loadbalance*).
* Allow for zone transfers, i.e., act as a primary server (*file* + *transfer*).
* Automatically load zone files from disk (*auto*).
* Caching of DNS responses (*cache*).
* Use etcd as a backend (replacing [SkyDNS](https://github.com/skynetservices/skydns)) (*etcd*).
* Use k8s (kubernetes) as a backend (*kubernetes*).
* Serve as a proxy to forward queries to some other (recursive) nameserver (*forward*).
* Provide metrics (by using Prometheus) (*prometheus*).
* Provide query (*log*) and error (*errors*) logging.
* Integrate with cloud providers (*route53*).
* Support the CH class: `version.bind` and friends (*chaos*).
* Support the RFC 5001 DNS name server identifier (NSID) option (*nsid*).
* Profiling support (*pprof*).
* Rewrite queries (qtype, qclass and qname) (*rewrite* and *template*).
* Block ANY queries (*any*).
* Provide DNS64 IPv6 Translation (*dns64*).

And more. Each of the plugins is documented. See [coredns.io/plugins](https://coredns.io/plugins)
for all in-tree plugins, and [coredns.io/explugins](https://coredns.io/explugins) for all
out-of-tree plugins.

## Compilation from Source

To compile CoreDNS, we assume you have a working Go setup. See various tutorials if you don‚Äôt have
that already configured.

First, make sure your golang version is 1.24.0 or higher as `go mod` support and other api is needed.
See [here](https://github.com/golang/go/wiki/Modules) for `go mod` details.
Then, check out the project and run `make` to compile the binary:

~~~
$ git clone https://github.com/coredns/coredns
$ cd coredns
$ make
~~~

&gt; **_NOTE:_**  extra plugins may be enabled when building by setting the `COREDNS_PLUGINS` environment variable with comma separate list of plugins in the same format as plugin.cfg

This should yield a `coredns` binary.

## Compilation with Docker

CoreDNS requires Go to compile. However, if you already have docker installed and prefer not to
setup a Go environment, you could build CoreDNS easily:

```
docker run --rm -i -t \
    -v $PWD:/go/src/github.com/coredns/coredns -w /go/src/github.com/coredns/coredns \
        golang:1.24 sh -c &#039;GOFLAGS=&quot;-buildvcs=false&quot; make gen &amp;&amp; GOFLAGS=&quot;-buildvcs=false&quot; make&#039;
```

The above command alone will have `coredns` binary generated.

## Examples

When starting CoreDNS without any configuration, it loads the
[*whoami*](https://coredns.io/plugins/whoami) and [*log*](https://coredns.io/plugins/log) plugins
and starts listening on port 53 (override with `-dns.port`), it should show the following:

~~~ txt
.:53
CoreDNS-1.6.6
linux/amd64, go1.16.10, aa8c32
~~~

The following could be used to query the CoreDNS server that is running now:

~~~ txt
dig @127.0.0.1 -p 53 www.example.com
~~~

Any query sent to port 53 should return some information; your sending address, port and protocol
used. The query should also be logged to standard output.

The configuration of CoreDNS is done through a file named `Corefile`. When CoreDNS starts, it will
look for the `Corefile` from the current working directory. A `Corefile` for CoreDNS server that listens
on port `53` and enables `whoami` plugin is:

~~~ corefile
.:53 {
    whoami
}
~~~

Sometimes port number 53 is occupied by system processes. In that case you can start the CoreDNS server
while modifying the `Corefile` as given below so that the CoreDNS server starts on port 1053.

~~~ corefile
.:1053 {
    whoami
}
~~~

If you have a `Corefile` without a port number specified it will, by default, use port 53, but you can
override the port with the `-dns.port` flag: `coredns -dns.port 1053`, runs the server on port 1053.

You may import other text files into the `Corefile` using the _import_ directive.  You can use globs to match multiple
files with a single _import_ directive.

~~~ txt
.:53 {
    import example1.txt
}
import example2.txt
~~~

You can use environment variables in the `Corefile` with `{$VARIABLE}`.  Note that each environment variable is inserted
into the `Corefile` as a single token. For example, an environment variable with a space in it will be treated as a single
token, not as two separate tokens.

~~~ txt
.:53 {
    {$ENV_VAR}
}
~~~

A Corefile for a CoreDNS server that forward any queries to an upstream DNS (e.g., `8.8.8.8`) is as follows:

~~~ corefile
.:53 {
    forward . 8.8.8.8:53
    log
}
~~~

Start CoreDNS and then query on that port (53). The query should be forwarded to 8.8.8.8 and the
response will be returned. Each query should also show up in the log which is printed on standard
output.

To serve the (NSEC) DNSSEC-signed `example.org` on port 1053, with errors and logging sent to standard
output. Allow zone transfers to everybody, but specifically mention 1 IP address so that CoreDNS can
send notifies to it.

~~~ txt
example.org:1053 {
    file /var/lib/coredns/example.org.signed
    transfer {
        to * 2001:500:8f::53
    }
    errors
    log
}
~~~

Serve `example.org` on port 1053, but forward everything that does *not* match `example.org` to a
recursive nameserver *and* rewrite ANY queries to HINFO.

~~~ txt
example.org:1053 {
    file /var/lib/coredns/example.org.signed
    transfer {
        to * 2001:500:8f::53
    }
    errors
    log
}

. {
    any
    forward . 8.8.8.8:53
    errors
    log
}
~~~

IP addresses are also allowed. They are automatically converted to reverse zones:

~~~ corefile
10.0.0.0/24 {
    whoami
}
~~~
Means you are authoritative for `0.0.10.in-addr.arpa.`.

This also works for IPv6 addresses. If for some reason you want to serve a zone named `10.0.0.0/24`
add the closing dot: `10.0.0.0/24.` as this also stops the conversion.

This even works for CIDR (See RFC 1518 and 1519) addressing, i.e. `10.0.0.0/25`, CoreDNS will then
check if the `in-addr` request falls in the correct range.

Listening on TLS (DoT) and for gRPC? Use:

~~~ corefile
tls://example.org grpc://example.org {
    whoami
}
~~~

Similarly, for QUIC (DoQ):

~~~ corefile
quic://example.org {
    whoami
    tls mycert mykey
}
~~~

And for DNS over HTTP/2 (DoH) use:

~~~ corefile
https://example.org {
    whoami
    tls mycert mykey
}
~~~
in this setup, the CoreDNS will be responsible for TLS termination

you can also start DNS server serving DoH without TLS termination (plain HTTP), but beware that in such scenario there has to be some kind
of TLS termination proxy before CoreDNS instance, which forwards DNS requests otherwise clients will not be able to communicate via DoH with the server
~~~ corefile
https://example.org {
    whoami
}
~~~

Specifying ports works in the same way:

~~~ txt
grpc://example.org:1443 https://example.org:1444 {
    # ...
}
~~~

When no transport protocol is specified the default `dns://` is assumed.

## Community

We&#039;re most active on GitHub (and Slack):

- GitHub: &lt;https://github.com/coredns/coredns&gt;
- Slack: #coredns on &lt;https://slack.cncf.io&gt;

More resources can be found:

- Website: &lt;https://coredns.io&gt;
- Blog: &lt;https://coredns.io/blog/&gt;
- Twitter: [@corednsio](https://twitter.com/corednsio)
- Mailing list/group: &lt;coredns-discuss@googlegroups.com&gt; (not very active)

## Contribution guidelines

If you want to contribute to CoreDNS, be sure to review the [contribution
guidelines](./.github/CONTRIBUTING.md).

## Deployment

Examples for deployment via systemd and other use cases can be found in the [deployment
repository](https://github.com/coredns/deployment).

## Deprecation Policy

When there is a backwards incompatible change in CoreDNS the following process is followed:

*  Release x.y.z: Announce that in the next release we will make backward incompatible changes.
*  Release x.y+1.0: Increase the minor version and set the patch version to 0. Make the changes,
   but allow the old configuration to be parsed. I.e. CoreDNS will start from an unchanged
   Corefile.
*  Release x.y+1.1: Increase the patch version to 1. Remove the lenient parsing, so CoreDNS will
   not start if those features are still used.

E.g. 1.3.1 announce a change. 1.4.0 a new release with the change but backward compatible config.
And finally 1.4.1 that removes the config workarounds.

## Security

### Security Audits

Third party security audits have been performed by:
* [Cure53](https://cure53.de) in March 2018. [Full Report](https://coredns.io/assets/DNS-01-report.pdf)
* [Trail of Bits](https://www.trailofbits.com) in March 2022. [Full Report](https://github.com/trailofbits/publications/blob/master/reviews/CoreDNS.pdf)

### Reporting security vulnerabilities

If you find a security vulnerability or any security related issues, please DO NOT file a public
issue, instead send your report privately to `security@coredns.io`. Security reports are greatly
appreciated and we will publicly thank you for it.

Please consult [security vulnerability disclosures and security fix and release process
document](https://github.com/coredns/coredns/blob/master/.github/SECURITY.md)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[google/pprof]]></title>
            <link>https://github.com/google/pprof</link>
            <guid>https://github.com/google/pprof</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[pprof is a tool for visualization and analysis of profiling data]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google/pprof">google/pprof</a></h1>
            <p>pprof is a tool for visualization and analysis of profiling data</p>
            <p>Language: Go</p>
            <p>Stars: 8,720</p>
            <p>Forks: 635</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![Github Action CI](https://github.com/google/pprof/workflows/ci/badge.svg)](https://github.com/google/pprof/actions)
[![Codecov](https://codecov.io/gh/google/pprof/graph/badge.svg)](https://codecov.io/gh/google/pprof)
[![Go Reference](https://pkg.go.dev/badge/github.com/google/pprof/profile.svg)](https://pkg.go.dev/github.com/google/pprof/profile)

# Introduction

pprof is a tool for visualization and analysis of profiling data.

pprof reads a collection of profiling samples in profile.proto format and
generates reports to visualize and help analyze the data. It can generate both
text and graphical reports (through the use of the dot visualization package).

profile.proto is a protocol buffer that describes a set of callstacks
and symbolization information. A common usage is to represent a set of
sampled callstacks from statistical profiling. The format is
described on the [proto/profile.proto](./proto/profile.proto) file. For details on protocol
buffers, see https://developers.google.com/protocol-buffers

Profiles can be read from a local file, or over http. Multiple
profiles of the same type can be aggregated or compared.

If the profile samples contain machine addresses, pprof can symbolize
them through the use of the native binutils tools (addr2line and nm).

**This is not an official Google product.**

# Building pprof

Prerequisites:

- Go development kit of a [supported version](https://golang.org/doc/devel/release.html#policy).
  Follow [these instructions](http://golang.org/doc/code.html) to prepare
  the environment.

- Graphviz: http://www.graphviz.org/
  Optional, used to generate graphic visualizations of profiles

To build and install it:

    go install github.com/google/pprof@latest

The binary will be installed `$GOPATH/bin` (`$HOME/go/bin` by default).

# Basic usage

pprof can read a profile from a file or directly from a server via http.
Specify the profile input(s) in the command line, and use options to
indicate how to format the report.

## Generate a text report of the profile, sorted by hotness:

```
% pprof -top [main_binary] profile.pb.gz
Where
    main_binary:  Local path to the main program binary, to enable symbolization
    profile.pb.gz: Local path to the profile in a compressed protobuf, or
                   URL to the http service that serves a profile.
```

## Generate a graph in an SVG file, and open it with a web browser:

```
pprof -web [main_binary] profile.pb.gz
```

## Run pprof on interactive mode:

If no output formatting option is specified, pprof runs on interactive mode,
where reads the profile and accepts interactive commands for visualization and
refinement of the profile.

```
pprof [main_binary] profile.pb.gz

This will open a simple shell that takes pprof commands to generate reports.
Type &#039;help&#039; for available commands/options.
```

## Run pprof via a web interface

If the `-http` flag is specified, pprof starts a web server at
the specified host:port that provides an interactive web-based interface to pprof.
Host is optional, and is &quot;localhost&quot; by default. Port is optional, and is a
random available port by default. `-http=&quot;:&quot;` starts a server locally at
a random port.

```
pprof -http=[host]:[port] [main_binary] profile.pb.gz
```

The preceding command should automatically open your web browser at
the right page; if not, you can manually visit the specified port in
your web browser.

## Using pprof with Linux Perf

pprof can read `perf.data` files generated by the
[Linux perf](https://perf.wiki.kernel.org/index.php/Main_Page) tool by using the
`perf_to_profile` program from the
[perf_data_converter](https://github.com/google/perf_data_converter) package.

## Viewing disassembly on Windows

To view disassembly of profiles collected from Go programs compiled as Windows executables,
the executable must be built with `go build -buildmode=exe`. LLVM or GCC must be installed,
so required tools like `addr2line` and `nm` are available to `pprof`.

## Further documentation

See [doc/README.md](doc/README.md) for more detailed end-user documentation.

See [CONTRIBUTING.md](CONTRIBUTING.md) for contribution documentation.

See [proto/README.md](proto/README.md) for a description of the profile.proto format.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[quii/learn-go-with-tests]]></title>
            <link>https://github.com/quii/learn-go-with-tests</link>
            <guid>https://github.com/quii/learn-go-with-tests</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[Learn Go with test-driven development]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/quii/learn-go-with-tests">quii/learn-go-with-tests</a></h1>
            <p>Learn Go with test-driven development</p>
            <p>Language: Go</p>
            <p>Stars: 23,127</p>
            <p>Forks: 2,902</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># Learn Go with Tests

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;red-green-blue-gophers-smaller.png&quot; /&gt;
&lt;/p&gt;

[Art by Denise](https://twitter.com/deniseyu21)

[![Go Report Card](https://goreportcard.com/badge/github.com/quii/learn-go-with-tests)](https://goreportcard.com/report/github.com/quii/learn-go-with-tests)

## Formats

- [Gitbook](https://quii.gitbook.io/learn-go-with-tests)
- [EPUB or PDF](https://github.com/quii/learn-go-with-tests/releases)

## Translations

- [‰∏≠Êñá](https://studygolang.gitbook.io/learn-go-with-tests)
- [Portugu√™s](https://larien.gitbook.io/aprenda-go-com-testes/)
- [Êó•Êú¨Ë™û](https://andmorefine.gitbook.io/learn-go-with-tests/)
- [Fran√ßais](https://goosegeesejeez.gitbook.io/apprendre-go-par-les-tests)
- [ÌïúÍµ≠Ïñ¥](https://miryang.gitbook.io/learn-go-with-tests/)
- [T√ºrk√ße](https://halilkocaoz.gitbook.io/go-programlama-dilini-ogren/)
- [ŸÅÿßÿ±ÿ≥€å](https://go-yaad-begir.gitbook.io/go-ba-test/)
- [Nederlands](https://bobkosse.gitbook.io/leer-go-met-tests/)

## Support me

I am proud to offer this resource for free, but if you wish to give some appreciation:

- [Tweet me @quii](https://twitter.com/quii)
- &lt;a rel=&quot;me&quot; href=&quot;https://mastodon.cloud/@quii&quot;&gt;Mastodon&lt;/a&gt;
- [Buy me a coffee :coffee:](https://www.buymeacoffee.com/quii)
- [Sponsor me on GitHub](https://github.com/sponsors/quii)

## Why

* Explore the Go language by writing tests
* **Get a grounding with TDD**. Go is a good language for learning TDD because it is a simple language to learn and testing is built-in
* Be confident that you&#039;ll be able to start writing robust, well-tested systems in Go
* [Watch a video, or read about why unit testing and TDD is important](why.md)

## Table of contents

### Go fundamentals

1. [Install Go](install-go.md) - Set up environment for productivity.
2. [Hello, world](hello-world.md) - Declaring variables, constants, if/else statements, switch, write your first go program and write your first test. Sub-test syntax and closures.
3. [Integers](integers.md) - Further Explore function declaration syntax and learn new ways to improve the documentation of your code.
4. [Iteration](iteration.md) - Learn about `for` and benchmarking.
5. [Arrays and slices](arrays-and-slices.md) - Learn about arrays, slices, `len`, varargs, `range` and test coverage.
6. [Structs, methods &amp; interfaces](structs-methods-and-interfaces.md) - Learn about `struct`, methods, `interface` and table driven tests.
7. [Pointers &amp; errors](pointers-and-errors.md) - Learn about pointers and errors.
8. [Maps](maps.md) - Learn about storing values in the map data structure.
9. [Dependency Injection](dependency-injection.md) - Learn about dependency injection, how it relates to using interfaces and a primer on io.
10. [Mocking](mocking.md) - Take some existing untested code and use DI with mocking to test it.
11. [Concurrency](concurrency.md) - Learn how to write concurrent code to make your software faster.
12. [Select](select.md) - Learn how to synchronise asynchronous processes elegantly.
13. [Reflection](reflection.md) - Learn about reflection
14. [Sync](sync.md) - Learn some functionality from the sync package including `WaitGroup` and `Mutex`
15. [Context](context.md) - Use the context package to manage and cancel long-running processes
16. [Intro to property based tests](roman-numerals.md) - Practice some TDD with the Roman Numerals kata and get a brief intro to property based tests
17. [Maths](math.md) - Use the `math` package to draw an SVG clock
18. [Reading files](reading-files.md) - Read files and process them
19. [Templating](html-templates.md) - Use Go&#039;s html/template package to render html from data, and also learn about approval testing
20. [Generics](generics.md) - Learn how to write functions that take generic arguments and make your own generic data-structure
21. [Revisiting arrays and slices with generics](revisiting-arrays-and-slices-with-generics.md) - Generics are very useful when working with collections. Learn how to write your own `Reduce` function and tidy up some common patterns.

### Build an application

Now that you have hopefully digested the _Go Fundamentals_ section you have a solid grounding of a majority of Go&#039;s language features and how to do TDD.

This next section will involve building an application.

Each chapter will iterate on the previous one, expanding the application&#039;s functionality as our product owner dictates.

New concepts will be introduced to help facilitate writing great code but most of the new material will be learning what can be accomplished from Go&#039;s standard library.

By the end of this, you should have a strong grasp as to how to iteratively write an application in Go, backed by tests.

* [HTTP server](http-server.md) - We will create an application which listens to HTTP requests and responds to them.
* [JSON, routing and embedding](json.md) - We will make our endpoints return JSON and explore how to do routing.
* [IO and sorting](io.md) - We will persist and read our data from disk and we&#039;ll cover sorting data.
* [Command line &amp; project structure](command-line.md) - Support multiple applications from one code base and read input from command line.
* [Time](time.md) - using the `time` package to schedule activities.
* [WebSockets](websockets.md) - learn how to write and test a server that uses WebSockets.

### Testing fundamentals

Covering other subjects around testing.

* [Introduction to acceptance tests](intro-to-acceptance-tests.md) - Learn how to write acceptance tests for your code, with a real-world example for gracefully shutting down a HTTP server
* [Scaling acceptance tests](scaling-acceptance-tests.md) - Learn techniques to manage the complexity of writing acceptance tests for non-trivial systems.
* [Working without mocks, stubs and spies](working-without-mocks.md) - Learn about how to use fakes and contracts to create more realistic and maintainable tests.
* [Refactoring Checklist](refactoring-checklist.md) - Some discussion on what refactoring is, and some basic tips on how to do it.

### Questions and answers

I often run in to questions on the internets like

&gt; How do I test my amazing function that does x, y and z

If you have such a question raise it as an issue on github and I&#039;ll try and find time to write a short chapter to tackle the issue. I feel like content like this is valuable as it is tackling people&#039;s _real_ questions around testing.

* [OS exec](os-exec.md) - An example of how we can reach out to the OS to execute commands to fetch data and keep our business logic testable/
* [Error types](error-types.md) - Example of creating your own error types to improve your tests and make your code easier to work with.
* [Context-aware Reader](context-aware-reader.md) - Learn how to TDD augmenting `io.Reader` with cancellation. Based on [Context-aware io.Reader for Go](https://pace.dev/blog/2020/02/03/context-aware-ioreader-for-golang-by-mat-ryer)
* [Revisiting HTTP Handlers](http-handlers-revisited.md) - Testing HTTP handlers seems to be the bane of many a developer&#039;s existence. This chapter explores the issues around designing handlers correctly.

### Meta / Discussion

* [Why unit tests and how to make them work for you](why.md) - Watch a video, or read about why unit testing and TDD is important
* [Anti-patterns](anti-patterns.md) - A short chapter on TDD and unit testing anti-patterns

## Contributing

* _This project is work in progress_ If you would like to contribute, please do get in touch.
* Read [contributing.md](https://github.com/quii/learn-go-with-tests/tree/842f4f24d1f1c20ba3bb23cbc376c7ca6f7ca79a/contributing.md) for guidelines
* Any ideas? Create an issue

## Background

I have some experience introducing Go to development teams and have tried different approaches as to how to grow a team from some people curious about Go into highly effective writers of Go systems.

### What didn&#039;t work

#### Read _the_ book

An approach we tried was to take [the blue book](https://www.amazon.co.uk/Programming-Language-Addison-Wesley-Professional-Computing/dp/0134190440) and every week discuss the next chapter along with the exercises.

I love this book but it requires a high level of commitment. The book is very detailed in explaining concepts, which is obviously great but it means that the progress is slow and steady - this is not for everyone.

I found that whilst a small number of people would read chapter X and do the exercises, many people didn&#039;t.

#### Solve some problems

Katas are fun but they are usually limited in their scope for learning a language; you&#039;re unlikely to use goroutines to solve a kata.

Another problem is when you have varying levels of enthusiasm. Some people just learn way more of the language than others and when demonstrating what they have done end up confusing people with features the others are not familiar with.

This ends up making the learning feel quite _unstructured_ and _ad hoc_.

### What did work

By far the most effective way was by slowly introducing the fundamentals of the language by reading through [go by example](https://gobyexample.com/), exploring them with examples and discussing them as a group. This was a more interactive approach than &quot;read chapter x for homework&quot;.

Over time the team gained a solid foundation of the _grammar_ of the language so we could then start to build systems.

This to me seems analogous to practicing scales when trying to learn guitar.

It doesn&#039;t matter how artistic you think you are, you are unlikely to write good music without understanding the fundamentals and practicing the mechanics.

### What works for me

When _I_ learn a new programming language I usually start by messing around in a REPL but eventually, I need more structure.

What I like to do is explore concepts and then solidify the ideas with tests. Tests verify the code I write is correct and documents the feature I have learned.

Taking my experience of learning with a group and my own personal way I am going to try and create something that hopefully proves useful to other teams. Learning the fundamentals by writing small tests so that you can then take your existing software design skills and ship some great systems.

## Who this is for

* People who are interested in picking up Go.
* People who already know some Go, but want to explore testing with TDD.

## What you&#039;ll need

* A computer!
* [Installed Go](https://golang.org/)
* A text editor
* Some experience with programming. Understanding of concepts like `if`, variables, functions etc.
* Comfortable using the terminal

## Feedback

* Add issues/submit PRs [here](https://github.com/quii/learn-go-with-tests) or [tweet me @quii](https://twitter.com/quii)

[MIT license](LICENSE.md)

[Logo is by egonelbre](https://github.com/egonelbre) What a star!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gravitational/teleport]]></title>
            <link>https://github.com/gravitational/teleport</link>
            <guid>https://github.com/gravitational/teleport</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[The easiest, and most secure way to access and protect all of your infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gravitational/teleport">gravitational/teleport</a></h1>
            <p>The easiest, and most secure way to access and protect all of your infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 19,096</p>
            <p>Forks: 1,915</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>Teleport provides connectivity, authentication, access controls and audit for infrastructure.

Here is why you might use Teleport:

* Set up SSO for all of your cloud infrastructure [1].
* Protect access to cloud and on-prem services using mTLS endpoints and short-lived certificates.
* Establish tunnels to access services behind NATs and firewalls.
* Provide an audit log with session recording and replay for various protocols.
* Unify Role-Based Access Control (RBAC) and enforce the principle of least privilege with  [access requests](https://goteleport.com/features/access-requests/).

[1] The open source version supports only GitHub SSO.

Teleport works with SSH, Kubernetes, databases, RDP, and web services.

* Architecture: https://goteleport.com/docs/reference/architecture/
* Getting Started: https://goteleport.com/docs/get-started/

&lt;div align=&quot;center&quot;&gt;
   &lt;a href=&quot;https://goteleport.com/download&quot;&gt;
   &lt;img src=&quot;./assets/img/hero-teleport-platform.png&quot; width=750/&gt;
   &lt;/a&gt;
   &lt;div align=&quot;center&quot; style=&quot;padding: 25px&quot;&gt;
      &lt;a href=&quot;https://goteleport.com/download&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/github/v/release/gravitational/teleport?sort=semver&amp;label=Release&amp;color=651FFF&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://golang.org/&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/github/go-mod/go-version/gravitational/teleport?color=7fd5ea&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://github.com/gravitational/teleport/blob/master/CODE_OF_CONDUCT.md&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Contribute-üôå-green.svg&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://www.gnu.org/licenses/agpl-3.0.en.html&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/AGPL-3.0-red.svg&quot; /&gt;
      &lt;/a&gt;
   &lt;/div&gt;
&lt;/div&gt;
&lt;/br&gt;

## Table of Contents

1. [Introduction](#introduction)
1. [Installing and Running](#installing-and-running)
1. [Docker](#docker)
1. [Building Teleport](#building-teleport)
1. [Why Did We Build Teleport?](#why-did-we-build-teleport)
1. [More Information](#more-information)
1. [Support and Contributing](#support-and-contributing)
1. [Is Teleport Secure and Production Ready?](#is-teleport-secure-and-production-ready)
1. [Who Built Teleport?](#who-built-teleport)
1. [License](#license)

## Introduction

Teleport includes an identity-aware access proxy, a CA that issues short-lived certificates, a unified access control system and a tunneling system to access resources behind the firewall.

We have implemented Teleport as a single Go binary that integrates with multiple protocols and cloud services:

* [SSH nodes](https://goteleport.com/docs/enroll-resources/server-access/introduction/).
* [Kubernetes clusters](https://goteleport.com/docs/enroll-resources/kubernetes-access/introduction/)
* [PostgreSQL, MongoDB, CockroachDB and MySQL databases](https://goteleport.com/docs/enroll-resources/database-access/).
* [Internal Web apps](https://goteleport.com/docs/enroll-resources/application-access/introduction/).
* [Windows Hosts](https://goteleport.com/docs/enroll-resources/desktop-access/introduction/).
* [Networked servers](https://goteleport.com/docs/enroll-resources/server-access/introduction/).

You can set up Teleport as a [Linux daemon](https://goteleport.com/docs/admin-guides/deploy-a-cluster/linux-demo) or a [Kubernetes deployment](https://goteleport.com/docs/admin-guides/deploy-a-cluster/helm-deployments/).

Teleport focuses on best practices for infrastructure security:

- No need to manage shared secrets such as SSH keys or Kubernetes tokens: it uses certificate-based auth with certificate expiration for all protocols.
- Two-factor authentication (2FA) for everything.
- Collaboratively troubleshoot issues through session sharing.
- Single sign-on (SSO) for everything via GitHub Auth, OpenID Connect, or SAML with endpoints like Okta or Microsoft Entra ID.
- Infrastructure introspection: Use Teleport via the CLI or Web UI to view the status of every SSH node, database instance, Kubernetes cluster, or internal web app.

Teleport uses [Go crypto](https://godoc.org/golang.org/x/crypto). It is _fully compatible with OpenSSH_, `sshd` servers, and `ssh` clients, Kubernetes clusters and more.

|Project Links| Description
|---|----
| [Teleport Website](https://goteleport.com/) | The official website of the project. |
| [Documentation](https://goteleport.com/docs/) | Admin guide, user manual and more. |
| [Blog](https://goteleport.com/blog/) | Our blog where we publish Teleport news. |
| [Forum](https://github.com/gravitational/teleport/discussions) | Ask us a setup question, post your tutorial, feedback, or idea on our forum. |
| [Slack](https://goteleport.com/slack) | Need help with your setup? Ping us in our Slack channel. |
| [Cloud-hosted](https://goteleport.com/pricing) | We offer Enterprise with a Cloud-hosted option. For teams that require easy and secure access to their computing environments. |


## Installing and Running

To set up a single-instance Teleport cluster, follow our [getting started
guide](https://goteleport.com/docs/admin-guides/deploy-a-cluster/linux-demo/). You can then register your
servers, Kubernetes clusters, and other infrastructure with your Teleport
cluster.

You can also get started with Teleport Enterprise Cloud, a managed Teleport
deployment that makes it easier to enable secure access to your infrastructure.

[Sign up for a free trial](https://goteleport.com/signup) of Teleport Enterprise
Cloud.

Follow our guide to [registering your first
server](https://goteleport.com/docs/get-started/)
with Teleport Enterprise Cloud.

## Docker

### Deploy Teleport

If you wish to deploy Teleport inside a Docker container see the
[installation guide](https://goteleport.com/docs/installation/#running-teleport-on-docker).

### For Local Testing and Development

To run a full test suite locally, see [the test dependencies list](BUILD_macos.md#local-tests-dependencies)

## Building Teleport

The `teleport` repository contains the Teleport daemon binary (written in Go)
and a web UI written in TypeScript.

If your intention is to build and deploy for use in a production infrastructure
a released tag should be used.  The default branch, `master`, is the current
development branch for an upcoming major version.  Get the latest release tags
listed at https://goteleport.com/download/ and then use that tag in the `git clone`.
For example `git clone https://github.com/gravitational/teleport.git -b v16.0.0` gets release v16.0.0.

### Dockerized Build

It is often easiest to build with Docker, which ensures that all required
tooling is available for the build. To execute a dockerized build, ensure
that docker is installed and running, and execute:

```
make -C build.assets build-binaries
```

### Local Build

#### Dependencies

The following dependencies are required to build Teleport from source. For
maximum compatibility, install the versions of these dependencies using the
versions listed in [`build.assets/versions.mk`](/build.assets/versions.mk):

1. [`Go`](https://golang.org/dl/)
1. [`Rust`](https://www.rust-lang.org/tools/install)
1. [`Node.js`](https://nodejs.org/en/download/)
1. [`wasm-pack`](https://github.com/rustwasm/wasm-pack)
1. [`libfido2`](https://github.com/Yubico/libfido2)
1. [`pkg-config`](https://www.freedesktop.org/wiki/Software/pkg-config/)

For an example of Dev Environment setup on a Mac, see [these
instructions](/BUILD_macos.md).

##### Linux 64-bit ARM Dependencies

1. On Linux aarch64 (64-bit ARM), you may need to manually install
   [`binaryen`](https://github.com/WebAssembly/binaryen). Check with `which
   wasm-opt`. If not found, install with `apt-get install binaryen`
   (Debian-based systems). On other platforms, `wasm-pack` installs it
   automatically.

#### Perform a build

&gt;**Important**
&gt;
&gt;* The Go compiler is somewhat sensitive to the amount of memory: you will need
   **at least** 1GB of virtual memory to compile Teleport. A 512MB instance
   without swap will **not** work.
&gt;* This will build the latest version of Teleport, **regardless** of whether it
   is stable. If you want to build the latest stable release, run `git checkout`
   and `git submodule update --recursive` to the corresponding tag (for example,
&gt;* run `git checkout v8.0.0`) **before** performing a build.

Get the source

```shell
git clone https://github.com/gravitational/teleport.git
cd teleport
```

To perform a build

```shell
make full
```

`tsh` dynamically links against libfido2 by default, to support development
environments, as long as the library itself can be found:

```shell
$ brew install libfido2 pkg-config  # Replace with your package manager of choice

$ make build/tsh
&gt; libfido2 found, setting FIDO2=dynamic
&gt; (...)
```

Release binaries are linked statically against libfido2. You may switch the
linking mode using the FIDO2 variable:

```shell
make build/tsh FIDO2=dynamic # dynamic linking
make build/tsh FIDO2=static  # static linking, for an easy setup use `make enter`
                             # or `build.assets/macos/build-fido2-macos.sh`.
make build/tsh FIDO2=off     # doesn&#039;t link libfido2 in any way
```

`tsh` builds with Touch ID support require access to an Apple Developer account.
If you are a Teleport maintainer, ask the team for access.

#### Build output and run locally

If the build succeeds, the installer will place the binaries in the `build` directory.

Before starting, create default data directories:

```shell
sudo mkdir -p -m0700 /var/lib/teleport
sudo chown $USER /var/lib/teleport
```

#### Running Teleport in a hot reload mode

To speed up your development process, you can run Teleport using
[`CompileDaemon`](https://github.com/githubnemo/CompileDaemon). This will build
and run the Teleport binary, and then rebuild and restart it whenever any Go
source files change.

1. Install CompileDaemon:

    ```shell
    go install github.com/githubnemo/CompileDaemon@latest
    ```

    Note that we use `go install` instead of the suggested `go get`, because we
    don&#039;t want CompileDaemon to become a dependency of the project.

1. Build and run the Teleport binary:

    ```shell
    make teleport-hot-reload
    ```

    By default, this runs a `teleport start` command. If you want to customize
    the command, for example by providing a custom config file location, you can
    use the `TELEPORT_ARGS` parameter:

    ```shell
    make teleport-hot-reload TELEPORT_ARGS=&#039;start --config=/path/to/config.yaml&#039;
    ```

Note that you still need to run [`make grpc`](api/proto/README.md) if you modify
any Protocol Buffers files to regenerate the generated Go sources; regenerating
these sources should in turn cause the CompileDaemon to rebuild and restart
Teleport.

### Web UI

The Teleport Web UI resides in the [web](web) directory.

#### Rebuilding Web UI for development

To rebuild the Teleport UI package, run the following command:

```bash
make docker-ui
```

Then you can replace Teleport Web UI files with the files from the newly-generated `/dist` folder.

To enable speedy iterations on the Web UI, you can run a [local web-dev server](web#web-ui).

You can also tell Teleport to load the Web UI assets from the source directory.
To enable this behavior, set the environment variable `DEBUG=1` and rebuild with the default target:

```bash
# Run Teleport as a single-node cluster in development mode:
DEBUG=1 ./build/teleport start -d
```

Keep the server running in this mode, and make your UI changes in `/dist` directory.
For instructions about how to update the Web UI, read [the `web` README](web#readme).

### Managing dependencies

All dependencies are managed using [Go modules](https://blog.golang.org/using-go-modules). Here are the instructions for some common tasks:

#### Add a new dependency

Latest version:

```bash
go get github.com/new/dependency
```

and update the source to use this dependency.


To get a specific version, use `go get github.com/new/dependency@version` instead.

#### Set dependency to a specific version

```bash
go get github.com/new/dependency@version
```

#### Update dependency to the latest version

```bash
go get -u github.com/new/dependency
```

#### Update all dependencies

```bash
go get -u all
```

#### Debugging dependencies

Why is a specific package imported?

`go mod why $pkgname`

Why is a specific module imported?

`go mod why -m $modname`

Why is a specific version of a module imported?

`go mod graph | grep $modname`

### Devbox Build (experimental)

**Note**: Devbox support is still experimental. It&#039;s very possible things may not work as intended.

Teleport can be built using [devbox](https://www.jetpack.io/devbox). To use devbox, follow
the instructions to install devbox [here](https://www.jetpack.io/devbox/docs/quickstart/) and
then run:

`devbox shell`

This will install Teleport&#039;s various build dependencies and drop you into a shell with these
dependencies. From here, you can build Teleport normally.

#### flake.nix

A nix flake is located in `build.assets/flake` that allows for installation of Teleport&#039;s less
common build tooling. If this flake is updated, run:

`devbox install`

in order to make sure the changes in the flake are reflected in the local devbox shell.

## Why did We Build Teleport?

The Teleport creators used to work together at Rackspace. We noticed that most cloud computing users struggle with setting up and configuring infrastructure security because popular tools, while flexible, are complex to understand and expensive to maintain. Additionally, most organizations use multiple infrastructure form factors such as several cloud providers, multiple cloud accounts, servers in colocation, and even smart devices. Some of those devices run on untrusted networks, behind third-party firewalls. This only magnifies complexity and increases operational overhead.

We had a choice, either start a security consulting business or build a solution that&#039;s dead-easy to use and understand. A real-time representation of all of your servers in the same room as you, as if they were magically _teleported_. Thus, Teleport was born!

## More Information

* [Teleport Getting Started](https://goteleport.com/docs/get-started/)
* [Teleport
  Architecture](https://goteleport.com/docs/reference/architecture/)
* [Reference](https://goteleport.com/docs/reference/)
* [FAQ](https://goteleport.com/docs/faq)

## Support and Contributing

We offer a few different options for support. First of all, we try to provide clear and comprehensive documentation. The docs are also in GitHub, so feel free to create a PR or file an issue if you have ideas for improvements. If you still have questions after reviewing our docs, you can also:

* Join [Teleport Discussions](https://github.com/gravitational/teleport/discussions) to ask questions. Our engineers are available there to help you.
* If you want to contribute to Teleport or file a bug report/issue, you can create an issue here in GitHub.
* If you are interested in Teleport Enterprise or more responsive support during a POC, we can also create a dedicated Slack channel for you during your POC. You can [reach out to us through our website](https://goteleport.com/pricing/) to arrange for a POC.

## Is Teleport Secure and Production-Ready?

Yes -- Teleport is production-ready and designed to protect and facilitate
access to the most precious and mission-critical applications.

Teleport has completed several security audits from nationally and
internationally recognized technology security companies.

We publicize some of our audit results, security philosophy and related
information on our [trust page](https://trust.goteleport.com/).

You can see the list of companies that use Teleport in production on the Teleport
[product page](https://goteleport.com/case-study/).

## Who Built Teleport?

Teleport was created by [Gravitational, Inc.](https://goteleport.com). We have
built Teleport by borrowing from our previous experiences at Rackspace. [Learn more
about Teleport and our history](https://goteleport.com/about/).

## License

Teleport is distributed in multiple forms with different licensing implications.

The Teleport API module (all code in this repository under `/api`) is available
under the [Apache 2.0 license](./api/LICENSE).

The remainder of the source code in this repository is available under the
[GNU Affero General Public License](./LICENSE). Users compiling Teleport
from source must comply with the terms of this license.

Teleport Community Edition builds distributed on http://goteleport.com/download
are available under a [modified Apache 2.0 license](./build.assets/LICENSE-community).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[oauth2-proxy/oauth2-proxy]]></title>
            <link>https://github.com/oauth2-proxy/oauth2-proxy</link>
            <guid>https://github.com/oauth2-proxy/oauth2-proxy</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oauth2-proxy/oauth2-proxy">oauth2-proxy/oauth2-proxy</a></h1>
            <p>A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.</p>
            <p>Language: Go</p>
            <p>Stars: 11,933</p>
            <p>Forks: 1,783</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>[![Continuous Integration](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml/badge.svg)](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/oauth2-proxy/oauth2-proxy)](https://goreportcard.com/report/github.com/oauth2-proxy/oauth2-proxy)
[![GoDoc](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy?status.svg)](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy)
[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)
[![Maintainability](https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/maintainability)](https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/maintainability)
[![Test Coverage](https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/test_coverage)](https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/test_coverage)

![OAuth2 Proxy](docs/static/img/logos/OAuth2_Proxy_horizontal.svg)

OAuth2-Proxy is a flexible, open-source tool that can act as either a standalone reverse proxy or a middleware component integrated into existing reverse proxy or load balancer setups. It provides a simple and secure way to protect your web applications with OAuth2 / OIDC authentication. As a reverse proxy, it intercepts requests to your application and redirects users to an OAuth2 provider for authentication. As a middleware, it can be seamlessly integrated into your existing infrastructure to handle authentication for multiple applications.

OAuth2-Proxy supports a lot of OAuth2 as well as OIDC providers. Either through a generic OIDC client or a specific implementation for Google, Microsoft Entra ID, GitHub, login.gov and others. Through specialised provider implementations oauth2-proxy can extract more details about the user like preferred usernames and groups. Those details can then be forwarded as HTTP headers to your upstream applications.

![Simplified Architecture](docs/static/img/simplified-architecture.svg)

## Get Started

OAuth2-Proxy&#039;s [Installation Docs](https://oauth2-proxy.github.io/oauth2-proxy/installation) cover how to install and configure your setup. Additionally you can take a further look at the [example setup files](https://github.com/oauth2-proxy/oauth2-proxy/tree/master/contrib/local-environment).

## Releases

### Binaries
We publish oauth2-proxy as compiled binaries on GitHub for all major architectures as well as more exotic ones like `ppc64le` as well as `s390x`.

Check out the [latest release](https://github.com/oauth2-proxy/oauth2-proxy/releases/latest).

### Images

From `v7.6.0` and up the base image has been changed from Alpine to [GoogleContainerTools/distroless](https://github.com/GoogleContainerTools/distroless).
This image comes with even fewer installed dependencies and thus should improve security. The image therefore is also slightly smaller than Alpine.
For debugging purposes (and those who really need it. e.g. `armv6`) we still provide images based on Alpine. The tags of these images are suffixed with `-alpine`.

Since 2023-11-18 we build nightly images directly from the `master` branch and provide them at `quay.io/oauth2-proxy/oauth2-proxy-nightly`.
These images are considered unstable and therefore should **NOT** be used for production purposes unless you know what you&#039;re doing.

## Sponsors

![Microsoft](https://upload.wikimedia.org/wikipedia/commons/9/96/Microsoft_logo_%282012%29.svg)
Microsoft Azure credits for open source projects

Would you like to sponsor the project then please contact us at [sponsors@oauth2-proxy.dev](mailto:sponsors@oauth2-proxy.dev)

## Getting Involved
[![Slack](https://img.shields.io/badge/slack-Gopher_%23oauth2--proxy-red?logo=slack)](https://gophers.slack.com/archives/CM2RSS25N)

Join the #oauth2-proxy [Slack channel](https://gophers.slack.com/archives/CM2RSS25N) to chat with other users of oauth2-proxy or reach out to the maintainers directly. Use the [public invite link](https://invite.slack.golangbridge.org/) to get an invite for the Gopher Slack space.

OAuth2-Proxy is a community-driven project. We rely on the contributÔ∏èions of our users to continually improve it. While review times can vary, we appreciate your patience and understanding. As a volunteer-driven project, we strive to keep this project stable and might take longer to merge changes.

If you want to contribute to the project. Please see our [Contributing](https://oauth2-proxy.github.io/oauth2-proxy/community/contribution) guide.

Who uses OAuth2-Proxy? Have a look at our new [ADOPTERS](ADOPTERS.md) file and
feel free to open a PR to add your organisation.

Thanks to all the people who already contributed ‚ù§

&lt;a href=&quot;https://github.com/oauth2-proxy/oauth2-proxy/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=oauth2-proxy/oauth2-proxy&amp;columns=15&amp;max=75&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/github/contributors/oauth2-proxy/oauth2-proxy&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks).

## Security

If you believe you have found a vulnerability within OAuth2 Proxy or any of its dependencies, please do **NOT** open an issue or PR on GitHub, please do **NOT** post any details publicly.

Security disclosures **MUST** be done in private. If you have found an issue that you would like to bring to the attention of the maintainers, please compose an email and send it to the list of people listed in our [MAINTAINERS](MAINTAINERS) file.

For more details read our full [Security Docs](https://oauth2-proxy.github.io/oauth2-proxy/community/security#security-disclosures)

### Security Notice for v6.0.0 and older

If you are running a version older than v6.0.0 we **strongly recommend** to the current version.

See [open redirect vulnerability](https://github.com/oauth2-proxy/oauth2-proxy/security/advisories/GHSA-5m6c-jp6f-2vcv) for details.

## Repository History

**2018-11-27:** This repository was forked from [bitly/OAuth2_Proxy](https://github.com/bitly/oauth2_proxy). Versions v3.0.0 and up are from this fork and will have diverged from any changes in the original fork. A list of changes can be seen in the [CHANGELOG](CHANGELOG.md).

**2020-03-29:** This project was formerly hosted as `pusher/oauth2_proxy` but has been renamed to `oauth2-proxy/oauth2-proxy`. Going forward, all images shall be available at `quay.io/oauth2-proxy/oauth2-proxy` and binaries will be named `oauth2-proxy`.

## License

OAuth2-Proxy is distributed under [The MIT License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[moby/moby]]></title>
            <link>https://github.com/moby/moby</link>
            <guid>https://github.com/moby/moby</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/moby/moby">moby/moby</a></h1>
            <p>The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems</p>
            <p>Language: Go</p>
            <p>Stars: 70,600</p>
            <p>Forks: 18,800</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>The Moby Project
================

[![PkgGoDev](https://pkg.go.dev/badge/github.com/moby/moby/v2)](https://pkg.go.dev/github.com/moby/moby/v2)
![GitHub License](https://img.shields.io/github/license/moby/moby)
[![Go Report Card](https://goreportcard.com/badge/github.com/moby/moby/v2)](https://goreportcard.com/report/github.com/moby/moby/v2)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/moby/moby/badge)](https://scorecard.dev/viewer/?uri=github.com/moby/moby)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10989/badge)](https://www.bestpractices.dev/projects/10989)


![Moby Project logo](docs/static_files/moby-project-logo.png &quot;The Moby Project&quot;)

Moby is an open-source project created by Docker to enable and accelerate software containerization.

It provides a &quot;Lego set&quot; of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas.
Components include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.

## Principles

Moby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience.
It is open to the community to help set its direction.

- Modular: the project includes lots of components that have well-defined functions and APIs that work together.
- Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.
- Usable security: Moby provides secure defaults without compromising usability.
- Developer focused: The APIs are intended to be functional and useful to build powerful tools.
They are not necessarily intended as end user tools but as components aimed at developers.
Documentation and UX is aimed at developers not end users.

## Audience

The Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers.
It is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.

## Relationship with Docker

The components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project.
New projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product.
However, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.

The Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful.
The releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, [Docker Desktop](https://www.docker.com/products/docker-desktop/) and [Mirantis Container Runtime](https://www.mirantis.com/software/mirantis-container-runtime/) are the appropriate products for these use cases.

-----

Legal
=====

*Brought to you courtesy of our legal counsel. For more context,
please see the [NOTICE](https://github.com/moby/moby/blob/master/NOTICE) document in this repo.*

Use and transfer of Moby may be subject to certain restrictions by the
United States and other governments.

It is your responsibility to ensure that your use and/or transfer does not
violate applicable laws.

For more information, please see https://www.bis.doc.gov

Licensing
=========
Moby is licensed under the Apache License, Version 2.0. See
[LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full
license text.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[bluenviron/mediamtx]]></title>
            <link>https://github.com/bluenviron/mediamtx</link>
            <guid>https://github.com/bluenviron/mediamtx</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[Ready-to-use SRT / WebRTC / RTSP / RTMP / LL-HLS / MPEG-TS / RTP media server and media proxy that allows to read, publish, proxy, record and playback video and audio streams.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bluenviron/mediamtx">bluenviron/mediamtx</a></h1>
            <p>Ready-to-use SRT / WebRTC / RTSP / RTMP / LL-HLS / MPEG-TS / RTP media server and media proxy that allows to read, publish, proxy, record and playback video and audio streams.</p>
            <p>Language: Go</p>
            <p>Stars: 16,250</p>
            <p>Forks: 1,938</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mediamtx.org&quot;&gt;
    &lt;img src=&quot;logo.png&quot; alt=&quot;MediaMTX&quot;&gt;
  &lt;/a&gt;

  &lt;br&gt;
  &lt;br&gt;

  [![Website](https://img.shields.io/badge/website-mediamtx.org-1c94b5)](https://mediamtx.org)
  [![Test](https://github.com/bluenviron/mediamtx/actions/workflows/code_test.yml/badge.svg)](https://github.com/bluenviron/mediamtx/actions/workflows/code_test.yml)
  [![Lint](https://github.com/bluenviron/mediamtx/actions/workflows/code_lint.yml/badge.svg)](https://github.com/bluenviron/mediamtx/actions/workflows/code_lint.yml)
  [![CodeCov](https://codecov.io/gh/bluenviron/mediamtx/branch/main/graph/badge.svg)](https://app.codecov.io/gh/bluenviron/mediamtx/tree/main)
  [![Release](https://img.shields.io/github/v/release/bluenviron/mediamtx)](https://github.com/bluenviron/mediamtx/releases)
  [![Docker Hub](https://img.shields.io/badge/docker-bluenviron/mediamtx-blue)](https://hub.docker.com/r/bluenviron/mediamtx)
&lt;/h1&gt;

&lt;br&gt;

_MediaMTX_ is a ready-to-use and zero-dependency real-time media server and media proxy that allows to publish, read, proxy, record and playback video and audio streams. It has been conceived as a &quot;media router&quot; that routes media streams from one end to the other.

&lt;div align=&quot;center&quot;&gt;

  |[Installation](https://mediamtx.org/docs/kickoff/installation)|[Documentation](https://mediamtx.org/docs/kickoff/introduction)|
  |-|-|

&lt;/div&gt;

&lt;h3&gt;Features&lt;/h3&gt;

* [Publish](https://mediamtx.org/docs/usage/publish) live streams to the server with SRT, WebRTC, RTSP, RTMP, HLS, MPEG-TS, RTP
* [Read](https://mediamtx.org/docs/usage/read) live streams from the server with SRT, WebRTC, RTSP, RTMP, HLS
* Streams are automatically converted from a protocol to another
* Serve several streams at once in separate paths
* [Record](https://mediamtx.org/docs/usage/record) streams to disk in fMP4 or MPEG-TS format
* [Playback](https://mediamtx.org/docs/usage/playback) recorded streams
* [Authenticate](https://mediamtx.org/docs/usage/authentication) users with internal, HTTP or JWT authentication
* [Forward](https://mediamtx.org/docs/usage/forward) streams to other servers
* [Proxy](https://mediamtx.org/docs/usage/proxy) requests to other servers
* [Control](https://mediamtx.org/docs/usage/control-api) the server through the Control API
* Reload the configuration without disconnecting existing clients (hot reloading)
* [Monitor](https://mediamtx.org/docs/usage/metrics) the server through Prometheus-compatible metrics
* [Run hooks](https://mediamtx.org/docs/usage/hooks) (external commands) when clients connect, disconnect, read or publish streams
* Compatible with Linux, Windows and macOS, does not require any dependency or interpreter, it&#039;s a single executable
* ...and many [others](https://mediamtx.org/docs/kickoff/introduction).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ccfos/nightingale]]></title>
            <link>https://github.com/ccfos/nightingale</link>
            <guid>https://github.com/ccfos/nightingale</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[Nightingale for monitoring and alerting, just as Grafana for visualization.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ccfos/nightingale">ccfos/nightingale</a></h1>
            <p>Nightingale for monitoring and alerting, just as Grafana for visualization.</p>
            <p>Language: Go</p>
            <p>Stars: 11,367</p>
            <p>Forks: 1,568</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/ccfos/nightingale&quot;&gt;
    &lt;img src=&quot;doc/img/Nightingale_L_V.png&quot; alt=&quot;nightingale - cloud native monitoring&quot; width=&quot;100&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Open-Source Alerting Expert&lt;/b&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://flashcat.cloud/docs/&quot;&gt;
  &lt;img alt=&quot;Docs&quot; src=&quot;https://img.shields.io/badge/docs-get%20started-brightgreen&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://hub.docker.com/u/flashcatcloud&quot;&gt;
  &lt;img alt=&quot;Docker pulls&quot; src=&quot;https://img.shields.io/docker/pulls/flashcatcloud/nightingale&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ccfos/nightingale/graphs/contributors&quot;&gt;
  &lt;img alt=&quot;GitHub contributors&quot; src=&quot;https://img.shields.io/github/contributors-anon/ccfos/nightingale&quot;/&gt;&lt;/a&gt;
&lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/ccfos/nightingale&quot;&gt;
&lt;img alt=&quot;GitHub forks&quot; src=&quot;https://img.shields.io/github/forks/ccfos/nightingale&quot;&gt;
&lt;br/&gt;&lt;img alt=&quot;GitHub Repo issues&quot; src=&quot;https://img.shields.io/github/issues/ccfos/nightingale&quot;&gt;
&lt;img alt=&quot;GitHub Repo issues closed&quot; src=&quot;https://img.shields.io/github/issues-closed/ccfos/nightingale&quot;&gt;
&lt;img alt=&quot;GitHub latest release&quot; src=&quot;https://img.shields.io/github/v/release/ccfos/nightingale&quot;/&gt;
&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/license-Apache--2.0-blue&quot;/&gt;
&lt;a href=&quot;https://n9e-talk.slack.com/&quot;&gt;
  &lt;img alt=&quot;GitHub contributors&quot; src=&quot;https://img.shields.io/badge/join%20slack-%23n9e-brightgreen.svg&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;



[English](./README.md) | [‰∏≠Êñá](./README_zh.md)

## üéØ What is Nightingale

Nightingale is an open-source monitoring project that focuses on alerting. Similar to Grafana, Nightingale also connects with various existing data sources. However, while Grafana emphasizes visualization, Nightingale places greater emphasis on the alerting engine, as well as the processing and distribution of alarms.

&gt; The Nightingale project was initially developed and open-sourced by DiDi.inc. On May 11, 2022, it was donated to the Open Source Development Committee of the China Computer Federation (CCF ODC).

![](https://n9e.github.io/img/global/arch-bg.png)

## üí° How Nightingale Works

Many users have already collected metrics and log data. In this case, you can connect your storage repositories (such as VictoriaMetrics, ElasticSearch, etc.) as data sources in Nightingale. This allows you to configure alerting rules and notification rules within Nightingale, enabling the generation and distribution of alarms.

![Nightingale Product Architecture](doc/img/readme/20240221152601.png)

Nightingale itself does not provide monitoring data collection capabilities. We recommend using [Categraf](https://github.com/flashcatcloud/categraf) as the collector, which integrates seamlessly with Nightingale.

[Categraf](https://github.com/flashcatcloud/categraf) can collect monitoring data from operating systems, network devices, various middleware, and databases. It pushes this data to Nightingale via the `Prometheus Remote Write` protocol. Nightingale then stores the monitoring data in a time-series database (such as Prometheus, VictoriaMetrics, etc.) and provides alerting and visualization capabilities.

For certain edge data centers with poor network connectivity to the central Nightingale server, we offer a distributed deployment mode for the alerting engine. In this mode, even if the network is disconnected, the alerting functionality remains unaffected.

![Edge Deployment Mode](doc/img/readme/20240222102119.png)

&gt; In the above diagram, Data Center A has a good network with the central data center, so it uses the Nightingale process in the central data center as the alerting engine. Data Center B has a poor network with the central data center, so it deploys `n9e-edge` as the alerting engine to handle alerting for its own data sources.

## üîï Alert Noise Reduction, Escalation, and Collaboration

Nightingale focuses on being an alerting engine, responsible for generating alarms and flexibly distributing them based on rules. It supports 20 built-in notification medias (such as phone calls, SMS, email, DingTalk, Slack, etc.).

If you have more advanced requirements, such as:
- Want to consolidate events from multiple monitoring systems into one platform for unified noise reduction, response handling, and data analysis.
- Want to support personnel scheduling, practice on-call culture, and support alert escalation (to avoid missing alerts) and collaborative handling.

Then Nightingale is not suitable. It is recommended that you choose on-call products such as PagerDuty and FlashDuty. These products are simple and easy to use.

## üó®Ô∏è Communication Channels

- **Report Bugs:** It is highly recommended to submit issues via the [Nightingale GitHub Issue tracker](https://github.com/ccfos/nightingale/issues/new?assignees=&amp;labels=kind%2Fbug&amp;projects=&amp;template=bug_report.yml).
- **Documentation:** For more information, we recommend thoroughly browsing the [Nightingale Documentation Site](https://n9e.github.io/).

## üîë Key Features

![Nightingale Alerting rules](doc/img/readme/2025-05-23_18-43-37.png)

- Nightingale supports alerting rules, mute rules, subscription rules, and notification rules. It natively supports 20 types of notification media and allows customization of message templates.  
- It supports event pipelines for Pipeline processing of alarms, facilitating automated integration with in-house systems. For example, it can append metadata to alarms or perform relabeling on events. 
- It introduces the concept of business groups and a permission system to manage various rules in a categorized manner.  
- Many databases and middleware come with built-in alert rules that can be directly imported and used. It also supports direct import of Prometheus alerting rules.  
- It supports alerting self-healing, which automatically triggers a script to execute predefined logic after an alarm is generated‚Äîsuch as cleaning up disk space or capturing the current system state.

![Nightingale Alarm Dashboard](doc/img/readme/2025-05-30_08-49-28.png)

- Nightingale archives historical alarms and supports multi-dimensional query and statistics.  
- It supports flexible aggregation grouping, allowing a clear view of the distribution of alarms across the company.

![Nightingale Integration Center](doc/img/readme/2025-05-23_18-46-06.png)

- Nightingale has built-in metric descriptions, dashboards, and alerting rules for common operating systems, middleware, and databases, which are contributed by the community with varying quality.  
- It directly receives data via multiple protocols such as Remote Write, OpenTSDB, Datadog, and Falcon, integrates with various Agents.  
- It supports data sources like Prometheus, ElasticSearch, Loki, ClickHouse, MySQL, Postgres, allowing alerting based on data from these sources.  
- Nightingale can be easily embedded into internal enterprise systems (e.g. Grafana, CMDB), and even supports configuring menu visibility for these embedded systems.

![Nightingale dashboards](doc/img/readme/2025-05-23_18-49-02.png)

- Nightingale supports dashboard functionality, including common chart types, and comes with pre-built dashboards. The image above is a screenshot of one of these dashboards.  
- If you are already accustomed to Grafana, it is recommended to continue using Grafana for visualization, as Grafana has deeper expertise in this area.  
- For machine-related monitoring data collected by Categraf, it is advisable to use Nightingale&#039;s built-in dashboards for viewing. This is because Categraf&#039;s metric naming follows Telegraf&#039;s convention, which differs from that of Node Exporter.  
- Due to Nightingale&#039;s concept of business groups (where machines can belong to different groups), there may be scenarios where you only want to view machines within the current business group on the dashboard. Thus, Nightingale&#039;s dashboards can be linked with business groups for interactive filtering.

## üåü Stargazers over time

[![Stargazers over time](https://api.star-history.com/svg?repos=ccfos/nightingale&amp;type=Date)](https://star-history.com/#ccfos/nightingale&amp;Date)

## üî• Users

![User Logos](doc/img/readme/logos.png)

## ü§ù Community Co-Building

- ‚ùáÔ∏è Please read the [Nightingale Open Source Project and Community Governance Draft](./doc/community-governance.md). We sincerely welcome every user, developer, company, and organization to use Nightingale, actively report bugs, submit feature requests, share best practices, and help build a professional and active open-source community.
- ‚ù§Ô∏è Nightingale Contributors
&lt;a href=&quot;https://github.com/ccfos/nightingale/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=ccfos/nightingale&quot; /&gt;
&lt;/a&gt;

## üìú License
- [Apache License V2.0](https://github.com/didi/nightingale/blob/main/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[anchore/grype]]></title>
            <link>https://github.com/anchore/grype</link>
            <guid>https://github.com/anchore/grype</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[A vulnerability scanner for container images and filesystems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anchore/grype">anchore/grype</a></h1>
            <p>A vulnerability scanner for container images and filesystems</p>
            <p>Language: Go</p>
            <p>Stars: 10,563</p>
            <p>Forks: 682</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img alt=&quot;Grype logo&quot; src=&quot;https://user-images.githubusercontent.com/5199289/136855393-d0a9eef9-ccf1-4e2b-9d7c-7aad16a567e5.png&quot; width=&quot;234&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/actions?query=workflow%3A%22Static+Analysis+%2B+Unit+%2B+Integration%22&quot;&gt;&lt;img src=&quot;https://github.com/anchore/grype/workflows/Static%20Analysis%20+%20Unit%20+%20Integration/badge.svg&quot; alt=&quot;Static Analysis + Unit + Integration&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/actions/workflows/validations.yaml&quot;&gt;&lt;img src=&quot;https://github.com/anchore/grype/workflows/Validations/badge.svg&quot; alt=&quot;Validations&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://goreportcard.com/report/github.com/anchore/grype&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/anchore/grype&quot; alt=&quot;Go Report Card&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/releases/latest&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/anchore/grype.svg&quot; alt=&quot;GitHub release&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/go-mod/go-version/anchore/grype.svg&quot; alt=&quot;GitHub go.mod Go version&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &lt;br&gt;
    &amp;nbsp;&lt;a href=&quot;https://github.com/anchore/grype/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-blue.svg&quot; alt=&quot;License: Apache-2.0&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://anchore.com/discourse&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discourse-Join-blue?logo=discourse&quot; alt=&quot;Join our Discourse&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a rel=&quot;me&quot; href=&quot;https://fosstodon.org/@grype&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Mastodon-Follow-blue?logoColor=white&amp;amp;logo=mastodon&quot; alt=&quot;Follow on Mastodon&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://scorecard.dev/viewer/?uri=github.com/anchore/grype&quot;&gt;&lt;img src=&quot;https://api.securityscorecards.dev/projects/github.com/anchore/grype/badge&quot; alt=&quot;OpenSSF Scorecard&quot;&gt;&lt;/a&gt;&amp;nbsp;
    &amp;nbsp;&lt;a href=&quot;https://www.bestpractices.dev/projects/6708&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/6708/badge&quot; alt=&quot;OpenSSF Best Practices&quot;&gt;&lt;/a&gt;&amp;nbsp;
&lt;p&gt;

A vulnerability scanner for container images and filesystems. Easily [install the binary](#installation) to try it out. Works with [Syft](https://github.com/anchore/syft), the powerful SBOM (software bill of materials) tool for container images and filesystems.

### Join our community meetings!

- Calendar: https://calendar.google.com/calendar/u/0/r?cid=Y182OTM4dGt0MjRtajI0NnNzOThiaGtnM29qNEBncm91cC5jYWxlbmRhci5nb29nbGUuY29t
- Agenda: https://docs.google.com/document/d/1ZtSAa6fj2a6KRWviTn3WoJm09edvrNUp4Iz_dOjjyY8/edit?usp=sharing (join [this group](https://groups.google.com/g/anchore-oss-community) for write access)
- All are welcome!

For commercial support options with Syft or Grype, please [contact Anchore](https://get.anchore.com/contact/).

![grype-demo](https://user-images.githubusercontent.com/590471/90276236-9868f300-de31-11ea-8068-4268b6b68529.gif)

## Features

- Scan the contents of a container image or filesystem to find known vulnerabilities.
- Find vulnerabilities for major operating system packages:
  - Alpine
  - Amazon Linux
  - Azure Linux (previously CBL-Mariner)
  - BusyBox
  - CentOS
  - Debian
  - Echo
  - Distroless
  - MinimOS
  - Oracle Linux
  - Red Hat (RHEL)
  - Ubuntu
  - Wolfi
- Find vulnerabilities for language-specific packages:
  - Ruby (Gems)
  - Java (JAR, WAR, EAR, JPI, HPI)
  - JavaScript (NPM, Yarn)
  - Python (Egg, Wheel, Poetry, requirements.txt/setup.py files)
  - Dotnet (deps.json)
  - Golang (go.mod)
  - PHP (Composer)
  - Rust (Cargo)
- Supports Docker, OCI and [Singularity](https://github.com/sylabs/singularity) image formats.
- [OpenVEX](https://github.com/openvex) support for filtering and augmenting scanning results.

If you encounter an issue, please [let us know using the issue tracker](https://github.com/anchore/grype/issues).

## Installation

### Recommended

```bash
curl -sSfL https://get.anchore.io/grype | sudo sh -s -- -b /usr/local/bin
```
Install script options:
-	`-b`: Specify a custom installation directory (defaults to `./bin`)
-	`-d`: More verbose logging levels (`-d` for debug, `-dd` for trace)
-	`-v`: Verify the signature of the downloaded artifact before installation (requires [`cosign`](https://github.com/sigstore/cosign) to be installed)

### Chocolatey

The chocolatey distribution of grype is community-maintained and not distributed by the anchore team.

```bash
choco install grype -y
```

### Homebrew

```bash
brew tap anchore/grype
brew install grype
```

### MacPorts

On macOS, Grype can additionally be installed from the [community-maintained port](https://ports.macports.org/port/grype/) via MacPorts:

```bash
sudo port install grype
```

**Note**: Currently, Grype is built only for macOS and Linux.

### From source

See [DEVELOPING.md](DEVELOPING.md#native-development) for instructions to build and run from source.

### GitHub Actions

If you&#039;re using GitHub Actions, you can use our [Grype-based action](https://github.com/marketplace/actions/anchore-container-scan) to run vulnerability scans on your code or container images during your CI workflows.

## Verifying the artifacts

Checksums are applied to all artifacts, and the resulting checksum file is signed using cosign.

You need the following tool to verify signature:

- [Cosign](https://docs.sigstore.dev/cosign/system_config/installation/)

Verification steps are as follow:

1. Download the files you want, and the checksums.txt, checksums.txt.pem and checksums.txt.sig files from the [releases](https://github.com/anchore/grype/releases) page:

2. Verify the signature:

```shell
cosign verify-blob &lt;path to checksum.txt&gt; \
--certificate &lt;path to checksums.txt.pem&gt; \
--signature &lt;path to checksums.txt.sig&gt; \
--certificate-identity-regexp &#039;https://github\.com/anchore/grype/\.github/workflows/.+&#039; \
--certificate-oidc-issuer &quot;https://token.actions.githubusercontent.com&quot;
```

3. Once the signature is confirmed as valid, you can proceed to validate that the SHA256 sums align with the downloaded artifact:

```shell
sha256sum --ignore-missing -c checksums.txt
```

## Getting started

[Install the binary](#installation), and make sure that `grype` is available in your path. To scan for vulnerabilities in an image:

```
grype &lt;image&gt;
```

The above command scans for vulnerabilities visible in the container (i.e., the squashed representation of the image). To include software from all image layers in the vulnerability scan, regardless of its presence in the final image, provide `--scope all-layers`:

```
grype &lt;image&gt; --scope all-layers
```

To run grype from a Docker container so it can scan a running container, use the following command:

```yml
docker run --rm \
--volume /var/run/docker.sock:/var/run/docker.sock \
--name Grype anchore/grype:latest \
$(ImageName):$(ImageTag)
```

## Supported sources

Grype can scan a variety of sources beyond those found in Docker.

```
# scan a container image archive (from the result of `docker image save ...`, `podman save ...`, or `skopeo copy` commands)
grype path/to/image.tar

# scan a Singularity Image Format (SIF) container
grype path/to/image.sif

# scan a directory
grype dir:path/to/dir
```

Sources can be explicitly provided with a scheme:

```
podman:yourrepo/yourimage:tag          use images from the Podman daemon
docker:yourrepo/yourimage:tag          use images from the Docker daemon
docker-archive:path/to/yourimage.tar   use a tarball from disk for archives created from &quot;docker save&quot;
oci-archive:path/to/yourimage.tar      use a tarball from disk for OCI archives (from Skopeo or otherwise)
oci-dir:path/to/yourimage              read directly from a path on disk for OCI layout directories (from Skopeo or otherwise)
singularity:path/to/yourimage.sif      read directly from a Singularity Image Format (SIF) container on disk
dir:path/to/yourproject                read directly from a path on disk (any directory)
file:path/to/yourfile                  read directly from a file on disk
sbom:path/to/syft.json                 read Syft JSON from path on disk
registry:yourrepo/yourimage:tag        pull image directly from a registry (no container runtime required)
```

If an image source is not provided and cannot be detected from the given reference it is assumed the image should be pulled from the Docker daemon.
If docker is not present, then the Podman daemon is attempted next, followed by reaching out directly to the image registry last.


This default behavior can be overridden with the `default-image-pull-source` configuration option (See [Configuration](https://github.com/anchore/grype#configuration) for more details).

Use SBOMs for even faster vulnerability scanning in Grype:

```
# Then scan for new vulnerabilities as frequently as needed
grype sbom:./sbom.json

# (You can also pipe the SBOM into Grype)
cat ./sbom.json | grype
```

Grype supports input of [Syft](https://github.com/anchore/syft), [SPDX](https://spdx.dev/), and [CycloneDX](https://cyclonedx.org/)
SBOM formats. If Syft has generated any of these file types, they should have the appropriate information to work properly with Grype.
It is also possible to use SBOMs generated by other tools with varying degrees of success. Two things that make Grype matching
more successful are the inclusion of CPE and Linux distribution information. If an SBOM does not include any CPE information, it
is possible to generate these based on package information using the `--add-cpes-if-none` flag. To specify a distribution,
use the `--distro &lt;distro&gt;:&lt;version&gt;` flag. A full example is:

```
grype --add-cpes-if-none --distro alpine:3.10 sbom:some-alpine-3.10.spdx.json
```

## Threat &amp; Risk Prioritization

This section explains the columns and UI cues that help prioritize remediation efforts:

- **Severity**: String severity based on CVSS scores and indicate the significance of a vulnerability in levels.
  This balances concerns such as ease of exploitability, and the potential to affect 
  confidentiality, integrity, and availability of software and services.

- **EPSS**:
  [Exploit Prediction Scoring System](https://www.first.org/epss/model) is a metric expressing the likelihood
  that a vulnerability will be 
  exploited in the wild over the next 30 days (on a 0‚Äì1 scale); higher values signal a greater likelihood of 
  exploitation.
  The table output shows the EPSS percentile, a one-way transform of the EPSS score showing the 
  proportion of all scored vulnerabilities with an equal or lower probability.
  Percentiles linearize a heavily skewed distribution, making threshold choice (e.g. ‚Äúonly CVEs above the 
  90th percentile‚Äù) straightforward.

- **KEV Indicator**: Flags entries from CISA‚Äôs [Known Exploited Vulnerabilities Catalog](https://www.cisa.gov/known-exploited-vulnerabilities-catalog)
  --an authoritative list of flaws observed being exploited in the wild.

- **Risk Score**: A composite 0‚Äì100 metric calculated as:
  ```markdown
  risk = min(1, threat * average(severity)) * 100
  ```
  Where: 
  - `severity` is the average of all CVSS scores and string severity for a vulnerability (scaled between 0‚Äì1).
  - `threat` is the EPSS score (between 0‚Äì1). If the vulnerability is on the KEV list then `threat` is 
    `1.05`, or `1.1` if the vulnerability is associated with a ransomware campaign.
  This metric is one way to combine EPSS and CVSS suggested in the [EPSS user guide](https://www.first.org/epss/user-guide).

- **Suggested Fixes**: All possible fixes for a package are listed, however, when multiple fixes are available, we de-emphasize all 
  upgrade paths except for the minimal upgrade path (which highlights the smallest, safest version bump).

Results default to sorting by Risk Score and can be overridden with `--sort-by &lt;value&gt;`:

- `severity`: sort by severity
- `epss`: sort by EPSS percentile (aka, &quot;threat&quot;)
- `risk`: sort by risk score
- `kev`: just like risk, except that KEV entries are always above non-KEV entries
- `package`: sort by package name, version, type
- `vulnerability`: sort by vulnerability ID

### Supported versions

Software updates are always applied to the latest version of Grype; fixes are not backported to any previous versions of Grype.

In terms of database updates, any version of Grype before v0.51.0 (Oct 2022, before schema v5) will not receive
vulnerability database updates. You can still build vulnerability databases for unsupported Grype releases by using previous
releases of [vunnel](https://github.com/anchore/vunnel) to gather the upstream data and [grype-db](https://github.com/anchore/grype-db)
to build databases for unsupported schemas.

Only the latest database schema is considered to be supported. When a new database schema is introduced then the one it replaces is
marked as deprecated. Deprecated schemas will continue to receive updates for at least one year after they are marked
as deprecated at which point they will no longer be supported.

### Working with attestations
Grype supports scanning SBOMs as input via stdin. Users can use [cosign](https://github.com/sigstore/cosign) to verify attestations
with an SBOM as its content to scan an image for vulnerabilities:
```
COSIGN_EXPERIMENTAL=1 cosign verify-attestation caphill4/java-spdx-tools:latest \
| jq -r .payload \
| base64 --decode \
| jq -r .predicate.Data \
| grype
```

### Vulnerability Summary

#### Basic Grype Vulnerability Data Shape

```json
 {
  &quot;vulnerability&quot;: {
    ...
  },
  &quot;relatedVulnerabilities&quot;: [
    ...
  ],
  &quot;matchDetails&quot;: [
    ...
  ],
  &quot;artifact&quot;: {
    ...
  }
}
```

- **Vulnerability**: All information on the specific vulnerability that was directly matched on (e.g. ID, severity, CVSS score, fix information, links for more information)
- **RelatedVulnerabilities**: Information pertaining to vulnerabilities found to be related to the main reported vulnerability. Maybe the vulnerability we matched on was a GitHub Security Advisory, which has an upstream CVE (in the authoritative national vulnerability database). In these cases we list the upstream vulnerabilities here.
- **MatchDetails**: This section tries to explain what we searched for while looking for a match and exactly what details on the package and vulnerability that lead to a match.
- **Artifact**: This is a subset of the information that we know about the package (when compared to the [Syft](https://github.com/anchore/syft) json output, we summarize the metadata section).
  This has information about where within the container image or directory we found the package, what kind of package it is, licensing info, pURLs, CPEs, etc.

### Excluding file paths

Grype can exclude files and paths from being scanned within a source by using glob expressions
with one or more `--exclude` parameters:

```
grype &lt;source&gt; --exclude &#039;./out/**/*.json&#039; --exclude /etc
```

**Note:** in the case of _image scanning_, since the entire filesystem is scanned it is
possible to use absolute paths like `/etc` or `/usr/**/*.txt` whereas _directory scans_
exclude files _relative to the specified directory_. For example: scanning `/usr/foo` with
`--exclude ./package.json` would exclude `/usr/foo/package.json` and `--exclude &#039;**/package.json&#039;`
would exclude all `package.json` files under `/usr/foo`. For _directory scans_,
it is required to begin path expressions with `./`, `*/`, or `**/`, all of which
will be resolved _relative to the specified scan directory_. Keep in mind, your shell
may attempt to expand wildcards, so put those parameters in single quotes, like:
`&#039;**/*.json&#039;`.

### External Sources

Grype can be configured to incorporate external data sources for added fidelity in vulnerability matching. This
feature is currently disabled by default. To enable this feature add the following to the grype config:

```yaml
external-sources:
  enable: true
  maven:
    search-upstream-by-sha1: true
    base-url: https://search.maven.org/solrsearch/select
    rate-limit: 300ms # Time between Maven API requests
```

You can also configure the base-url if you&#039;re using another registry as your maven endpoint.

The rate at which Maven API requests are made can be configured to match your environment&#039;s requirements. The default is 300ms between requests.

### Output formats

The output format for Grype is configurable as well:

```
grype &lt;image&gt; -o &lt;format&gt;
```

Where the formats available are:

- `table`: A columnar summary (default).
- `cyclonedx`: An XML report conforming to the [CycloneDX 1.6 specification](https://cyclonedx.org/specification/overview/).
- `cyclonedx-json`: A JSON report conforming to the [CycloneDX 1.6 specification](https://cyclonedx.org/specification/overview/).
- `json`: Use this to get as much information out of Grype as possible!
- `sarif`: Use this option to get a [SARIF](https://docs.oasis-open.org/sarif/sarif/v2.1.0/sarif-v2.1.0.html) report (Static Analysis Results Interchange Format)
- `template`: Lets the user specify the output format. See [&quot;Using templates&quot;](#using-templates) below.

### Using templates

Grype lets you define custom output formats, using [Go templates](https://golang.org/pkg/text/template/). Here&#039;s how it works:

- Define your format as a Go template, and save this template as a file.

- Set the output format to &quot;template&quot; (`-o template`).

- Specify the path to the template file (`-t ./path/to/custom.template`).

- Grype&#039;s template processing uses the same data models as the `json` output format ‚Äî so if you&#039;re wondering what data is available as you author a template, you can use the output from `grype &lt;image&gt; -o json` as a reference.

**Please note:** Templates can access information about the system they are running on, such as environment variables. You should never run untrusted templates.

There are several example templates in the [templates](https://github.com/anchore/grype/tree/main/templates) directory in the Grype source which can serve as a starting point for a custom output format. For example, [csv.tmpl](https://github.com/anchore/grype/blob/main/templates/csv.tmpl) produces a vulnerability report in CSV (comma separated value) format:

```text
&quot;Package&quot;,&quot;Version Installed&quot;,&quot;Vulnerability ID&quot;,&quot;Severity&quot;
&quot;coreutils&quot;,&quot;8.30-3ubuntu2&quot;,&quot;CVE-2016-2781&quot;,&quot;Low&quot;
&quot;libc-bin&quot;,&quot;2.31-0ubuntu9&quot;,&quot;CVE-2016-10228&quot;,&quot;Negligible&quot;
&quot;libc-bin&quot;,&quot;2.31-0ubuntu9&quot;,&quot;CVE-2020-6096&quot;,&quot;Low&quot;
...
```

You can also find the template for the default &quot;table&quot; output format in the same place.

Grype also includes a vast array of utility templating functions from [sprig](http://masterminds.github.io/sprig/) apart from the default golang [text/template](https://pkg.go.dev/text/template#hdr-Functions) to allow users to customize the output from Grype.

### Gating on severity of vulnerabilities

You can have Grype exit with an error if any vulnerabilities are reported at or above the specified severity level. This comes in handy when using Grype within a script or CI pipeline. To do this, use the `--fail-on &lt;severity&gt;` CLI flag.

For example, here&#039;s how you could trigger a CI pipeline failure if any vulnerabilities are found in the `ubuntu:latest` image with a severity of &quot;medium&quot; or higher:

```
grype ubuntu:latest --fail-on medium
```

**Note:** Grype returns exit code `2` on vulnerability errors.

### Specifying matches to ignore

If you&#039;re seeing Grype report **false positives** or any other vulnerability matches that you just don&#039;t want to see, you can tell Grype to **ignore** matches by specifying one or more _&quot;ignore rules&quot;_ in your Grype configuration file (e.g. `~/.grype.yaml`). This causes Grype not to report any vulnerability matches that meet the criteria specified by any of your ignore rules.

Each rule can specify any combination of the following criteria:

- vulnerability ID (e.g. `&quot;CVE-2008-4318&quot;`)
- namespace (e.g. `&quot;nvd&quot;`)
- fix state (allowed values: `&quot;fixed&quot;`, `&quot;not-fixed&quot;`, `&quot;wont-fix&quot;`, or `&quot;unknown&quot;`)
- package name (e.g. `&quot;libcurl&quot;`)
- package version (e.g

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-collector-contrib]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-collector-contrib</link>
            <guid>https://github.com/open-telemetry/opentelemetry-collector-contrib</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[Contrib repository for the OpenTelemetry Collector]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-collector-contrib">open-telemetry/opentelemetry-collector-contrib</a></h1>
            <p>Contrib repository for the OpenTelemetry Collector</p>
            <p>Language: Go</p>
            <p>Stars: 3,889</p>
            <p>Forks: 2,985</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>---

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt;
    &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector-contrib/build-and-test.yml?branch=main&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector-contrib&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/branch/main/&quot;&gt;
    &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector-contrib?include_prereleases&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;img alt=&quot;Beta&quot; src=&quot;https://img.shields.io/badge/status-beta-informational?style=for-the-badge&amp;logo=data:image/png;base64,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&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/vision.md&quot;&gt;Vision&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/observability.md&quot;&gt;Observability&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
  &lt;/strong&gt;
&lt;/p&gt;

---

# OpenTelemetry Collector Contrib

This is a repository for OpenTelemetry Collector components that are not suitable for the  [core repository](https://github.com/open-telemetry/opentelemetry-collector) of the collector. 

The official distributions, core and contrib, are available as part of the [opentelemetry-collector-releases](https://github.com/open-telemetry/opentelemetry-collector-releases) repository. Some of the components in this repository are part of the &quot;core&quot; distribution, such as the Jaeger and Prometheus components, but most of the components here are only available as part of the &quot;contrib&quot; distribution. Users of the OpenTelemetry Collector are also encouraged to build their own custom distributions with the [OpenTelemetry Collector Builder](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder), using the components they need from the core repository, the contrib repository, and possibly third-party or internal repositories.

Each component has its own support levels, as defined in the following sections. For each signal that a component supports, there&#039;s a stability level, setting the right expectations. It is possible then that a component will be **Stable** for traces but **Alpha** for metrics and **Development** for logs.

## Stability levels

Stability level for components in this repository follow the [definitions](https://github.com/open-telemetry/opentelemetry-collector#stability-levels) from the OpenTelemetry Collector repository.

## Gated features

Some features are hidden behind feature gates before they are part of the main code path for the component. Note that the feature gates themselves might be at different [lifecycle stages](https://github.com/open-telemetry/opentelemetry-collector/tree/main/featuregate#feature-lifecycle).

## Support

Each component is supported either by the community of OpenTelemetry Collector Contrib maintainers, as defined by the GitHub group [@open-telemetry/collector-contrib-maintainer](https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer), or by specific vendors. See the individual README files for information about the specific components.

The OpenTelemetry Collector Contrib maintainers may at any time downgrade specific components if they are deemed unmaintained or if they pose a risk to the repository and/or binary distribution.

Even though the OpenTelemetry Collector Contrib maintainers are ultimately responsible for the components hosted here, actual support will likely be provided by individual contributors, typically a code owner for the specific component.

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md).

### Maintainers

- [Alex Boten](https://github.com/codeboten), Honeycomb
- [Andrzej Stencel](https://github.com/andrzej-stencel), Elastic
- [Antoine Toulme](https://github.com/atoulme), Splunk
- [Bogdan Drutu](https://github.com/bogdandrutu), Snowflake
- [Dmitrii Anoshin](https://github.com/dmitryax), Splunk
- [Edmo Vamerlatti Costa](https://github.com/edmocosta), Elastic
- [Evan Bradley](https://github.com/evan-bradley), Dynatrace
- [Pablo Baeyens](https://github.com/mx-psi), DataDog
- [Sean Marciniak](https://github.com/MovieStoreGuy), Splunk
- [Tyler Helmuth](https://github.com/TylerHelmuth), Honeycomb
- [Yang Song](https://github.com/songy23), DataDog

For more information about the maintainer role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#maintainer).

### Approvers

- [Andrew Wilkins](https://github.com/axw), Elastic
- [Arthur Silva Sens](https://github.com/ArthurSens), Grafana Labs
- [Braydon Kains](https://github.com/braydonk), Google
- [Christos Markou](https://github.com/ChrsMark), Elastic
- [Curtis Robert](https://github.com/crobert-1), Splunk
- [David Ashpole](https://github.com/dashpole), Google
- [Matt Wear](https://github.com/mwear), Lightstep
- [Paulo Janotti](https://github.com/pjanotti), Splunk
- [Sam DeHaan](https://github.com/dehaansa), Grafana Labs
- [Ziqi Zhao](https://github.com/fatsheep9146), Alibaba

For more information about the approver role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#approver).

### Triagers

- [Benedikt Bongartz](https://github.com/frzifus), Red Hat
- [Douglas Camata](https://github.com/douglascamata), Coralogix
- [Florian Bacher](https://github.com/bacherfl), Dynatrace
- [Israel Blancas](https://github.com/iblancasa), Coralogix
- [James Moessis](https://github.com/jamesmoessis), Atlassian
- [Jared Tan](https://github.com/JaredTan95), DaoCloud
- [Murphy Chen](https://github.com/Frapschen), DaoCloud
- [Ondrej Dubaj](https://github.com/odubajDT), Dynatrace
- [Roger Coll](https://github.com/rogercoll), Elastic
- [Vihas Makwana](https://github.com/VihasMakwana), Elastic
- Actively seeking contributors to triage issues

For more information about the triager role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#triager).

### Emeritus Maintainers

- [Daniel Jaglowski](https://github.com/djaglowski)
- [Juraci Paix√£o Kr√∂hling](https://github.com/jpkrohling)
- [Tigran Najaryan](https://github.com/tigrannajaryan)

For more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).

### Emeritus Approvers

- [Anthony Mirabella](https://github.com/Aneurysm9)
- [Bryan Aguilar](https://github.com/bryan-aguilar)
- [Przemek Maciolek](https://github.com/pmm-sumo)
- [Ruslan Kovalov](https://github.com/kovrus)

For more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).

### Emeritus Triagers

- [Alolita Sharma](https://github.com/alolita)
- [Gabriel Aszalos](https://github.com/gbbr)
- [Goutham Veeramachaneni](https://github.com/gouthamve)
- [Punya Biswal](https://github.com/punya)
- [Steve Flanders](https://github.com/flands)

For more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).

### No Over-Representation

A community member cannot be promoted to be a Collector contrib maintainer if, after their promotion, the resulting maintainers group has more than one-fourth (25%) of the members affiliated with the same employer. Job changes and similar events might result in over-representation, and no new maintainers from the same company can be promoted until representation is balanced again. In the event of confusion or concern, the OpenTelemetry Collector SIG will defer to the CNCF definition of &quot;same employer&quot;.

## PRs and Reviews

When creating a PR please follow the process [described
here](https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md#how-to-structure-prs-to-get-expedient-reviews).

New PRs will be automatically associated with the reviewers based on
[CODEOWNERS](.github/CODEOWNERS). PRs will be also automatically assigned to one of the
maintainers or approvers for facilitation.

The facilitator is responsible for helping the PR author and reviewers to make progress
or if progress cannot be made for closing the PR.

If the reviewers do not have approval rights the facilitator is also responsible
for the official approval that is required for the PR to be merged and if the facilitator
is a maintainer they are responsible for merging the PR as well.

The facilitator is not required to perform a thorough review, but they are encouraged to
enforce Collector best practices and consistency across the codebase and component
behavior. The facilitators will typically rely on codeowner&#039;s detailed review of the code
when making the final approval decision. 
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[oapi-codegen/oapi-codegen]]></title>
            <link>https://github.com/oapi-codegen/oapi-codegen</link>
            <guid>https://github.com/oapi-codegen/oapi-codegen</guid>
            <pubDate>Thu, 04 Sep 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[Generate Go client and server boilerplate from OpenAPI 3 specifications]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oapi-codegen/oapi-codegen">oapi-codegen/oapi-codegen</a></h1>
            <p>Generate Go client and server boilerplate from OpenAPI 3 specifications</p>
            <p>Language: Go</p>
            <p>Stars: 7,552</p>
            <p>Forks: 970</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># `oapi-codegen`

[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9450/badge)](https://www.bestpractices.dev/projects/9450)

`oapi-codegen` is a command-line tool and library to convert OpenAPI specifications to Go code, be it [server-side implementations](#generating-server-side-boilerplate), [API clients](#generating-api-clients), or simply [HTTP models](#generating-api-models).

Using `oapi-codegen` allows you to reduce the boilerplate required to create or integrate with services based on [OpenAPI 3.0](https://github.com/OAI/OpenAPI-Specification/blob/main/versions/3.0.0.md), and instead focus on writing your business logic, and working on the real value-add for your organisation.

With `oapi-codegen`, there are a few [Key Design Decisions](#key-design-decisions) we&#039;ve made, including:

- idiomatic Go, where possible
- fairly simple generated code, erring on the side of duplicate code over nicely refactored code
- supporting as much of OpenAPI 3.x as is possible, alongside Go&#039;s type system

`oapi-codegen` is one part of a wider ecosystem, which can be found described in further detail in the [oapi-codegen organisation on GitHub](https://github.com/oapi-codegen).

‚ö†Ô∏è This README may be for the latest development version, which may contain unreleased changes. Please ensure you&#039;re looking at the README for the latest release version.

## Action Required: The repository for this project has changed

As announced in [May 2024](https://github.com/oapi-codegen/oapi-codegen/discussions/1605),
we have moved the project from the deepmap organization to our own organization, and you will need to update your
import paths to pull updates past this point. You need to do a recursive search/replace from
`github.com/deepmap/oapi-codegen/v2` to `github.com/oapi-codegen/oapi-codegen/v2`.

&gt; [!IMPORTANT]
&gt; `oapi-codegen` moved to its new home with the version tag `v2.3.0`.

If you are using `v2.2.0` or below, please install like so:

```sh
# for the binary install
go install github.com/deepmap/oapi-codegen/v2/cmd/oapi-codegen@v2.2.0
```

If you are using `v2.3.0` or above, please install like so, using the new module import path:

```sh
# for the binary install
go install github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen@latest
```

## Install

## For Go 1.24+

It is recommended to follow [the `go tool` support available from Go 1.24+](https://www.jvt.me/posts/2025/01/27/go-tools-124/) for managing the dependency of `oapi-codegen` alongside your core application.

To do this, you run `go get -tool`:

```sh
$ go get -tool github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen@latest
# this will then modify your `go.mod`
```

From there, each invocation of `oapi-codegen` would be used like so:

```go
//go:generate go tool oapi-codegen -config cfg.yaml ../../api.yaml
```

## Prior to Go 1.24

It is recommended to follow [the `tools.go` pattern](https://www.jvt.me/posts/2022/06/15/go-tools-dependency-management/) for managing the dependency of `oapi-codegen` alongside your core application.

This would give you a `tools/tools.go`:

```go
//go:build tools
// +build tools

package main

import (
	_ &quot;github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen&quot;
)
```

Then, each invocation of `oapi-codegen` would be used like so:

```go
//go:generate go run github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen --config=config.yaml ../../api.yaml
```

Alternatively, you can install it as a binary with:

```sh
$ go install github.com/oapi-codegen/oapi-codegen/v2/cmd/oapi-codegen@latest
$ oapi-codegen -version
```

Which then means you can invoke it like so:

```go
//go:generate oapi-codegen --config=config.yaml ../../api.yaml
```

Note that you can also [move your `tools.go` into its own sub-module](https://www.jvt.me/posts/2024/09/30/go-tools-module/) to reduce the impact on your top-level `go.mod`.

### Pinning to commits

While the project does not ([yet](https://github.com/oapi-codegen/oapi-codegen/issues/1519)) have a defined release cadence, there may be cases where you want to pull in yet-unreleased changes to your codebase.

Therefore, you may want to pin your dependency on `oapi-codegen` to a given commit hash, rather than a tag.

This is **officially recommended** for consumers of `oapi-codegen`, who want features/bug fixes that haven&#039;t yet been released.

We aim to keep the default branch ready-to-release so you should be able to safely pin.

To do so, you can run:

```sh
# pin to the latest version on the default branch
$ go get github.com/oapi-codegen/oapi-codegen/v2@main
# alternatively, to a commit hash i.e. https://github.com/oapi-codegen/oapi-codegen/commit/71e916c59688a6379b5774dfe5904ec222b9a537
$ go get github.com/oapi-codegen/oapi-codegen/v2@71e916c59688a6379b5774dfe5904ec222b9a537
```

This will then make a change such as:

```diff
diff --git go.mod go.mod
index 44f29a4..436a780 100644
--- go.mod
+++ go.mod
@@ -2,21 +2,20 @@
-require github.com/oapi-codegen/oapi-codegen/v2 v2.1.0
+require github.com/oapi-codegen/oapi-codegen/v2 v2.1.1-0.20240331212514-80f0b978ef16
```

## Usage

`oapi-codegen` is largely configured using a YAML configuration file, to simplify the number of flags that users need to remember, and to make reading the `go:generate` command less daunting.

For full details of what is supported, it&#039;s worth checking out [the GoDoc for `codegen.Configuration`](https://pkg.go.dev/github.com/oapi-codegen/oapi-codegen/v2/pkg/codegen#Configuration).

We also have [a JSON Schema](configuration-schema.json) that can be used by IDEs/editors with the Language Server Protocol (LSP) to perform intelligent suggestions, i.e.:

```yaml
# yaml-language-server: $schema=https://raw.githubusercontent.com/oapi-codegen/oapi-codegen/HEAD/configuration-schema.json
package: api
# ...
```

### Backwards compatibility

Although we strive to retain backwards compatibility - as a project that&#039;s using a stable API per SemVer - there are sometimes opportunities we must take to fix a bug that could cause a breaking change for [people relying upon the behaviour](https://xkcd.com/1172/).

In this case, we will expose a [compatibility option](https://pkg.go.dev/github.com/oapi-codegen/oapi-codegen/v2/pkg/codegen#CompatibilityOptions) to restore old behaviour.

## Features

At a high level, `oapi-codegen` supports:

- Generating server-side boilerplate for [a number of servers](#supported-servers) ([docs](#generating-server-side-boilerplate))
- Generating client API boilerplate ([docs](#generating-api-clients))
- Generating the types ([docs](#generating-api-models))
- Splitting large OpenAPI specs across multiple packages([docs](#import-mapping))
  - This is also known as &quot;Import Mapping&quot; or &quot;external references&quot; across our documentation / discussion in GitHub issues

## What does it look like?

Below we can see a trimmed down example taken from the OpenAPI Petstore [example](examples/petstore-expanded/stdhttp/api/petstore.gen.go):

```go
// generated code

type ServerInterface interface {
	// ...
	// Returns all pets
	// (GET /pets)
	FindPets(w http.ResponseWriter, r *http.Request, params FindPetsParams)
	// ...
}

// FindPets operation middleware
func (siw *ServerInterfaceWrapper) FindPets(w http.ResponseWriter, r *http.Request) {

	var err error

	// Parameter object where we will unmarshal all parameters from the context
	var params FindPetsParams

	// ------------- Optional query parameter &quot;tags&quot; -------------

	err = runtime.BindQueryParameter(&quot;form&quot;, true, false, &quot;tags&quot;, r.URL.Query(), &amp;params.Tags)
	if err != nil {
		siw.ErrorHandlerFunc(w, r, &amp;InvalidParamFormatError{ParamName: &quot;tags&quot;, Err: err})
		return
	}

	// ------------- Optional query parameter &quot;limit&quot; -------------

	err = runtime.BindQueryParameter(&quot;form&quot;, true, false, &quot;limit&quot;, r.URL.Query(), &amp;params.Limit)
	if err != nil {
		siw.ErrorHandlerFunc(w, r, &amp;InvalidParamFormatError{ParamName: &quot;limit&quot;, Err: err})
		return
	}

	handler := http.Handler(http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
		siw.Handler.FindPets(w, r, params)
	}))

	for _, middleware := range siw.HandlerMiddlewares {
		handler = middleware(handler)
	}

	handler.ServeHTTP(w, r)
}

// HandlerWithOptions creates http.Handler with additional options
func HandlerWithOptions(si ServerInterface, options StdHTTPServerOptions) http.Handler {
	m := options.BaseRouter

	if m == nil {
		m = http.NewServeMux()
	}
	if options.ErrorHandlerFunc == nil {
		options.ErrorHandlerFunc = func(w http.ResponseWriter, r *http.Request, err error) {
			http.Error(w, err.Error(), http.StatusBadRequest)
		}
	}

	wrapper := ServerInterfaceWrapper{
		Handler:            si,
		HandlerMiddlewares: options.Middlewares,
		ErrorHandlerFunc:   options.ErrorHandlerFunc,
	}

	m.HandleFunc(&quot;GET &quot;+options.BaseURL+&quot;/pets&quot;, wrapper.FindPets)

	return m
}
```

Then, in your own code, you implement the underlying logic for the `FindPets` implementation:

```go
type PetStore struct {
	Pets   map[int64]Pet
	NextId int64
	Lock   sync.Mutex
}

// Make sure we conform to ServerInterface

var _ ServerInterface = (*PetStore)(nil)

func NewPetStore() *PetStore {
	return &amp;PetStore{
		Pets:   make(map[int64]Pet),
		NextId: 1000,
	}
}

// FindPets implements all the handlers in the ServerInterface
func (p *PetStore) FindPets(w http.ResponseWriter, r *http.Request, params FindPetsParams) {
	p.Lock.Lock()
	defer p.Lock.Unlock()

	var result []Pet

	for _, pet := range p.Pets {
		if params.Tags != nil {
			// If we have tags,  filter pets by tag
			for _, t := range *params.Tags {
				if pet.Tag != nil &amp;&amp; (*pet.Tag == t) {
					result = append(result, pet)
				}
			}
		} else {
			// Add all pets if we&#039;re not filtering
			result = append(result, pet)
		}

		if params.Limit != nil {
			l := int(*params.Limit)
			if len(result) &gt;= l {
				// We&#039;re at the limit
				break
			}
		}
	}

	w.WriteHeader(http.StatusOK)
	_ = json.NewEncoder(w).Encode(result)
}
```

As we can see, `oapi-codegen` simplifies some of the boilerplate by taking parameters out of the request and instead allows us to focus on the implementation.

You&#039;ll note that there&#039;s still a bit more marshaling of request/response data, which is further reduced by using the [Strict server](#strict-server) functionality.

&lt;a name=&quot;what-does-it-look-like-strict&quot;&gt;&lt;/a&gt;
When using the strict server, you&#039;ll have the following generated code:

```go
// StrictServerInterface represents all server handlers.
type StrictServerInterface interface {
	// ...
	// Returns all pets
	// (GET /pets)
	FindPets(ctx context.Context, request FindPetsRequestObject) (FindPetsResponseObject, error)
	// ...
}

func NewStrictHandlerWithOptions(ssi StrictServerInterface, middlewares []StrictMiddlewareFunc, options StrictHTTPServerOptions) ServerInterface {
	return &amp;strictHandler{ssi: ssi, middlewares: middlewares, options: options}
}

// FindPets operation middleware
func (sh *strictHandler) FindPets(w http.ResponseWriter, r *http.Request, params FindPetsParams) {
	var request FindPetsRequestObject

	request.Params = params

	handler := func(ctx context.Context, w http.ResponseWriter, r *http.Request, request interface{}) (interface{}, error) {
		return sh.ssi.FindPets(ctx, request.(FindPetsRequestObject))
	}
	for _, middleware := range sh.middlewares {
		handler = middleware(handler, &quot;FindPets&quot;)
	}

	response, err := handler(r.Context(), w, r, request)

	if err != nil {
		sh.options.ResponseErrorHandlerFunc(w, r, err)
	} else if validResponse, ok := response.(FindPetsResponseObject); ok {
		if err := validResponse.VisitFindPetsResponse(w); err != nil {
			sh.options.ResponseErrorHandlerFunc(w, r, err)
		}
	} else if response != nil {
		sh.options.ResponseErrorHandlerFunc(w, r, fmt.Errorf(&quot;unexpected response type: %T&quot;, response))
	}
}
```

Then, in your own code, you implement the underlying logic for the `FindPets` implementation:

```go
// Make sure we conform to StrictServerInterface

var _ StrictServerInterface = (*PetStore)(nil)

func NewPetStore() *PetStore {
	return &amp;PetStore{
		Pets:   make(map[int64]Pet),
		NextId: 1000,
	}
}

// FindPets implements all the handlers in the ServerInterface
func (p *PetStore) FindPets(ctx context.Context, request FindPetsRequestObject) (FindPetsResponseObject, error) {
	p.Lock.Lock()
	defer p.Lock.Unlock()

	var result []Pet

	for _, pet := range p.Pets {
		if request.Params.Tags != nil {
			// If we have tags,  filter pets by tag
			for _, t := range *request.Params.Tags {
				if pet.Tag != nil &amp;&amp; (*pet.Tag == t) {
					result = append(result, pet)
				}
			}
		} else {
			// Add all pets if we&#039;re not filtering
			result = append(result, pet)
		}

		if request.Params.Limit != nil {
			l := int(*request.Params.Limit)
			if len(result) &gt;= l {
				// We&#039;re at the limit
				break
			}
		}
	}

	return FindPets200JSONResponse(result), nil
}
```

We can see that this provides the best means to focus on the implementation of the business logic within the endpoint, rather than (un)marshalling types to and from JSON, or wrangling cookies or headers.

## Key design decisions

- Produce an interface that can be satisfied by your implementation, with reduced boilerplate
- Bulk processing and parsing of OpenAPI document in Go
- Resulting output is using Go&#039;s `text/template`s, which are user-overridable
- Attempts to produce Idiomatic Go
- Single-file output
- Support multiple OpenAPI files by having a package-per-OpenAPI file
- Support of OpenAPI 3.0
  - OpenAPI 3.1 support is [awaiting upstream support](https://github.com/oapi-codegen/oapi-codegen/issues/373)
  - Note that this does not include OpenAPI 2.0 (aka Swagger)
- Extract parameters from requests, to reduce work required by your implementation
- Implicit `additionalProperties` are ignored by default ([more details](#additional-properties-additionalproperties))
- Prune unused types by default

## Generating server-side boilerplate

`oapi-codegen` shines by making it fairly straightforward (note that this is a purposeful choice of wording here - we want to avoid words like &quot;easy&quot;) to generate the server-side boilerplate for a backend API.

Below you can find the supported servers, and more information about how to implement a server using them.

To provide you a fully Test Driven Development style test harness to confirm you are following the specification, you could use a tool such as [openapi.tanna.dev/go/validator](https://openapi.tanna.dev/go/validator/), or craft your own.

### Supported Servers

Right now, we support the following servers, and are supportive of adding new servers, too!

&lt;table&gt;

&lt;tr&gt;
&lt;th&gt;
Server
&lt;/th&gt;
&lt;th&gt;
&lt;code&gt;generate&lt;/code&gt; flag to enable code generation
&lt;/th&gt;
&lt;th&gt;
Example usage
&lt;/th&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[Chi](https://github.com/go-chi/chi)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;chi-server&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;


For a Chi server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  chi-server: true
  models: true
output: gen.go
```

To implement this, check out [the Chi docs](#impl-chi).

&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[Echo](https://github.com/labstack/echo)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;echo-server&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;

For an Echo server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  echo-server: true
  models: true
output: gen.go
```

To implement this, check out [the Echo docs](#impl-echo).

&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[Fiber](https://github.com/gofiber/fiber)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;fiber-server&lt;/code&gt;
&lt;/td&gt;

&lt;td&gt;

For a Fiber server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  fiber-server: true
  models: true
output: gen.go
```

To implement this, check out [the Fiber docs](#impl-fiber).

&lt;/td&gt;
&lt;/tr&gt;


&lt;tr&gt;
&lt;td&gt;

[Gin](https://github.com/gin-gonic/gin)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;gin-server&lt;/code&gt;
&lt;/td&gt;
&lt;td&gt;

For a Gin server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  gin-server: true
  models: true
output: gen.go
```

To implement this, check out [the Gin docs](#impl-gin).

&lt;/td&gt;

&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[gorilla/mux](https://github.com/gorilla/mux)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;gorilla-server&lt;/code&gt;
&lt;/td&gt;

&lt;td&gt;

For a gorilla/mux server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  gorilla-server: true
  models: true
output: gen.go
```

To implement this, check out [the gorilla/mux docs](#impl-gorillamux).

&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[Iris](https://github.com/kataras/iris)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;iris-server&lt;/code&gt;
&lt;/td&gt;

&lt;td&gt;

For a Iris server, you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  iris-server: true
  models: true
output: gen.go
```

To implement this, check out [the Iris docs](#impl-iris).

&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;

[1.22+ `net/http`](https://pkg.go.dev/net/http)

&lt;/td&gt;
&lt;td&gt;
&lt;code&gt;std-http-server&lt;/code&gt;
&lt;/td&gt;

&lt;td&gt;

To use purely `net/http` (for Go 1.22+), you will want a configuration file such as:

```yaml
# yaml-language-server: ...
package: api
generate:
  std-http-server: true
  models: true
output: gen.go
```

To implement this, check out [the Go 1.22+ `net/http` docs](#impl-stdhttp).

&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

### Go 1.22+ `net/http`
&lt;a name=&quot;impl-stdhttp&quot;&gt;&lt;/a&gt;

As of Go 1.22, enhancements have been made to the routing of the `net/http` package in the standard library, which makes it a great starting point for implementing a server with, before needing to reach for another router or a full framework.

For instance, let&#039;s take this straightforward specification:

```yaml
openapi: &quot;3.0.0&quot;
info:
  version: 1.0.0
  title: Minimal ping API server
paths:
  /ping:
    get:
      responses:
        &#039;200&#039;:
          description: pet response
          content:
            application/json:
              schema:
                $ref: &#039;#/components/schemas/Pong&#039;
components:
  schemas:
    # base types
    Pong:
      type: object
      required:
        - ping
      properties:
        ping:
          type: string
          example: pong
```

This then generates code such as:

```go
// Pong defines model for Pong.
type Pong struct {
	Ping string `json:&quot;ping&quot;`
}

// ServerInterface represents all server handlers.
type ServerInterface interface {

	// (GET /ping)
	GetPing(w http.ResponseWriter, r *http.Request)
}

func HandlerFromMux(si ServerInterface, m ServeMux) http.Handler {
	return HandlerWithOptions(si, StdHTTPServerOptions{
		BaseRouter: m,
	})
}

// HandlerWithOptions creates http.Handler with additional options
func HandlerWithOptions(si ServerInterface, options StdHTTPServerOptions) http.Handler {
	m := options.BaseRouter

	// ... omitted for brevity

	m.HandleFunc(&quot;GET &quot;+options.BaseURL+&quot;/ping&quot;, wrapper.GetPing)

	return m
}
```

To implement this HTTP server, we need to write the following code in our [`api/impl.go`](examples/minimal-server/stdhttp/api/impl.go):

```go
import (
	&quot;encoding/json&quot;
	&quot;net/http&quot;
)

// optional code omitted

type Server struct{}

func NewServer() Server {
	return Server{}
}

// (GET /ping)
func (Server) GetPing(w http.ResponseWriter, r *http.Request) {
	resp := Pong{
		Ping: &quot;pong&quot;,
	}

	w.WriteHeader(http.StatusOK)
	_ = json.NewEncoder(w).Encode(resp)
}
```

Now we&#039;ve got our implementation, we can then write the following code to wire it up and get a running server:

```go
import (
	&quot;log&quot;
	&quot;net/http&quot;

	&quot;github.com/oapi-codegen/oapi-codegen/v2/examples/minimal-server/stdhttp/api&quot;
)

func main() {
	// create a type that satisfies the `api.ServerInterface`, which contains an implementation of every operation from the generated code
	server := api.NewServer()

	r := http.NewServeMux()

	// get an `http.Handler` that we can use
	h := api.HandlerFromMux(server, r)

	s := &amp;http.Server{
		Handler: h,
		Addr:    &quot;0.0.0.0:8080&quot;,
	}

	// And we serve HTTP until the world ends.
	log.Fatal(s.ListenAndServe())
}
```

&gt; [!NOTE]
&gt; This doesn&#039;t include [validation of incoming requests](#re

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>