<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Thu, 06 Nov 2025 00:05:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[mudler/LocalAI]]></title>
            <link>https://github.com/mudler/LocalAI</link>
            <guid>https://github.com/mudler/LocalAI</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mudler/LocalAI">mudler/LocalAI</a></h1>
            <p>ü§ñ The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI, running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference</p>
            <p>Language: Go</p>
            <p>Stars: 37,245</p>
            <p>Forks: 2,939</p>
            <p>Stars today: 335 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;img width=&quot;300&quot; src=&quot;./core/http/static/logo.png&quot;&gt; &lt;br&gt;
&lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/fork&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/forks/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI forks&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/stargazers&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/stars/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI stars&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/go-skynet/LocalAI/pulls&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/issues-pr/go-skynet/LocalAI?style=for-the-badge&quot; alt=&quot;LocalAI pull-requests&quot;/&gt;
&lt;/a&gt;
&lt;a href=&#039;https://github.com/go-skynet/LocalAI/releases&#039;&gt;
&lt;img src=&#039;https://img.shields.io/github/release/go-skynet/LocalAI?&amp;label=Latest&amp;style=for-the-badge&#039;&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://hub.docker.com/r/localai/localai&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/dockerhub-images-important.svg?logo=Docker&quot; alt=&quot;LocalAI Docker hub&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://quay.io/repository/go-skynet/local-ai?tab=tags&amp;tag=latest&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/quay.io-images-important.svg?&quot; alt=&quot;LocalAI Quay.io&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://twitter.com/LocalAI_API&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/X-%23000000.svg?style=for-the-badge&amp;logo=X&amp;logoColor=white&amp;label=LocalAI_API&quot; alt=&quot;Follow LocalAI_API&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://discord.gg/uJAeKSAGDy&quot; target=&quot;blank&quot;&gt;
&lt;img src=&quot;https://dcbadge.vercel.app/api/server/uJAeKSAGDy?style=flat-square&amp;theme=default-inverted&quot; alt=&quot;Join LocalAI Discord Community&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/5539&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/5539&quot; alt=&quot;mudler%2FLocalAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

&gt; :bulb: Get help - [‚ùìFAQ](https://localai.io/faq/) [üí≠Discussions](https://github.com/go-skynet/LocalAI/discussions) [:speech_balloon: Discord](https://discord.gg/uJAeKSAGDy) [:book: Documentation website](https://localai.io/)
&gt;
&gt; [üíª Quickstart](https://localai.io/basics/getting_started/) [üñºÔ∏è Models](https://models.localai.io/) [üöÄ Roadmap](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap) [üåç Explorer](https://explorer.localai.io) [üõ´ Examples](https://github.com/mudler/LocalAI-examples) Try on 
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/localaiofficial_bot)

[![tests](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/test.yml)[![Build and Release](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/release.yaml)[![build container images](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/image.yml)[![Bump dependencies](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml/badge.svg)](https://github.com/go-skynet/LocalAI/actions/workflows/bump_deps.yaml)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/localai)](https://artifacthub.io/packages/search?repo=localai)

**LocalAI** is the free, Open Source OpenAI alternative. LocalAI act as a drop-in replacement REST API that&#039;s compatible with OpenAI (Elevenlabs, Anthropic... ) API specifications for local AI inferencing. It allows you to run LLMs, generate images, audio (and not only) locally or on-prem with consumer grade hardware, supporting multiple model families. Does not require GPU. It is created and maintained by [Ettore Di Giacinto](https://github.com/mudler).


## üìöüÜï Local Stack Family

üÜï LocalAI is now part of a comprehensive suite of AI tools designed to work together:

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalAGI/refs/heads/main/webui/react-ui/public/logo_2.png&quot; width=&quot;300&quot; alt=&quot;LocalAGI Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalAGI&quot;&gt;LocalAGI&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A powerful Local AI agent management platform that serves as a drop-in replacement for OpenAI&#039;s Responses API, enhanced with advanced agentic capabilities.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;
        &lt;img src=&quot;https://raw.githubusercontent.com/mudler/LocalRecall/refs/heads/main/static/localrecall_horizontal.png&quot; width=&quot;300&quot; alt=&quot;LocalRecall Logo&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; valign=&quot;top&quot;&gt;
      &lt;h3&gt;&lt;a href=&quot;https://github.com/mudler/LocalRecall&quot;&gt;LocalRecall&lt;/a&gt;&lt;/h3&gt;
      &lt;p&gt;A REST-ful API and knowledge base management system that provides persistent memory and storage capabilities for AI agents.&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Screenshots


| Talk Interface | Generate Audio |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-36 LocalAI - Talk](./docs/assets/images/screenshots/screenshot_tts.png) | ![Screenshot 2025-03-31 at 12-01-29 LocalAI - Generate audio with voice-en-us-ryan-low](./docs/assets/images/screenshots/screenshot_tts.png) |

| Models Overview | Generate Images |
| --- | --- |
| ![Screenshot 2025-03-31 at 12-01-20 LocalAI - Models](./docs/assets/images/screenshots/screenshot_gallery.png) | ![Screenshot 2025-03-31 at 12-31-41 LocalAI - Generate images with flux 1-dev](./docs/assets/images/screenshots/screenshot_image.png) |

| Chat Interface | Home |
| --- | --- |
| ![Screenshot 2025-03-31 at 11-57-44 LocalAI - Chat with localai-functioncall-qwen2 5-7b-v0 5](./docs/assets/images/screenshots/screenshot_chat.png) | ![Screenshot 2025-03-31 at 11-57-23 LocalAI API - c2a39e3 (c2a39e3639227cfd94ffffe9f5691239acc275a8)](./docs/assets/images/screenshots/screenshot_home.png) |

| Login | Swarm |
| --- | --- |
|![Screenshot 2025-03-31 at 12-09-59 ](./docs/assets/images/screenshots/screenshot_login.png) | ![Screenshot 2025-03-31 at 12-10-39 LocalAI - P2P dashboard](./docs/assets/images/screenshots/screenshot_p2p.png) |

## üíª Quickstart

Run the installer script:

```bash
# Basic installation
curl https://localai.io/install.sh | sh
```

For more installation options, see [Installer Options](https://localai.io/docs/advanced/installer/).

### macOS Download:

&lt;a href=&quot;https://github.com/mudler/LocalAI/releases/latest/download/LocalAI.dmg&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Download-macOS-blue?style=for-the-badge&amp;logo=apple&amp;logoColor=white&quot; alt=&quot;Download LocalAI for macOS&quot;/&gt;
&lt;/a&gt;

&gt; Note: the DMGs are not signed by Apple as quarantined. See https://github.com/mudler/LocalAI/issues/6268 for a workaround, fix is tracked here: https://github.com/mudler/LocalAI/issues/6244

Or run with docker:

&gt; **üí° Docker Run vs Docker Start**
&gt; 
&gt; - `docker run` creates and starts a new container. If a container with the same name already exists, this command will fail.
&gt; - `docker start` starts an existing container that was previously created with `docker run`.
&gt; 
&gt; If you&#039;ve already run LocalAI before and want to start it again, use: `docker start -i local-ai`

### CPU only image:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest
```

### NVIDIA GPU Images:

```bash
# CUDA 12.0
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-12

# CUDA 11.7
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-gpu-nvidia-cuda-11

# NVIDIA Jetson (L4T) ARM64
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-nvidia-l4t-arm64
```

### AMD GPU Images (ROCm):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-gpu-hipblas
```

### Intel GPU Images (oneAPI):

```bash
docker run -ti --name local-ai -p 8080:8080 --device=/dev/dri/card1 --device=/dev/dri/renderD128 localai/localai:latest-gpu-intel
```

### Vulkan GPU Images:

```bash
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-gpu-vulkan
```

### AIO Images (pre-downloaded models):

```bash
# CPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-cpu

# NVIDIA CUDA 12 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-12

# NVIDIA CUDA 11 version
docker run -ti --name local-ai -p 8080:8080 --gpus all localai/localai:latest-aio-gpu-nvidia-cuda-11

# Intel GPU version
docker run -ti --name local-ai -p 8080:8080 localai/localai:latest-aio-gpu-intel

# AMD GPU version
docker run -ti --name local-ai -p 8080:8080 --device=/dev/kfd --device=/dev/dri --group-add=video localai/localai:latest-aio-gpu-hipblas
```

For more information about the AIO images and pre-downloaded models, see [Container Documentation](https://localai.io/basics/container/).

To load models:

```bash
# From the model gallery (see available models with `local-ai models list`, in the WebUI from the model tab, or visiting https://models.localai.io)
local-ai run llama-3.2-1b-instruct:q4_k_m
# Start LocalAI with the phi-2 model directly from huggingface
local-ai run huggingface://TheBloke/phi-2-GGUF/phi-2.Q8_0.gguf
# Install and run a model from the Ollama OCI registry
local-ai run ollama://gemma:2b
# Run a model from a configuration file
local-ai run https://gist.githubusercontent.com/.../phi-2.yaml
# Install and run a model from a standard OCI registry (e.g., Docker Hub)
local-ai run oci://localai/phi-2:latest
```

&gt; ‚ö° **Automatic Backend Detection**: When you install models from the gallery or YAML files, LocalAI automatically detects your system&#039;s GPU capabilities (NVIDIA, AMD, Intel) and downloads the appropriate backend. For advanced configuration options, see [GPU Acceleration](https://localai.io/features/gpu-acceleration/#automatic-backend-detection).

For more information, see [üíª Getting started](https://localai.io/basics/getting_started/index.html)

## üì∞ Latest project news

- October 2025: üîå [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) support added for agentic capabilities with external tools
- September 2025: New Launcher application for MacOS and Linux, extended support to many backends for Mac and Nvidia L4T devices. Models: Added MLX-Audio, WAN 2.2. WebUI improvements and Python-based backends now ships portable python environments.
- August 2025: MLX, MLX-VLM, Diffusers and llama.cpp are now supported on Mac M1/M2/M3+ chips ( with `development` suffix in the gallery ): https://github.com/mudler/LocalAI/pull/6049 https://github.com/mudler/LocalAI/pull/6119 https://github.com/mudler/LocalAI/pull/6121 https://github.com/mudler/LocalAI/pull/6060
- July/August 2025: üîç [Object Detection](https://localai.io/features/object-detection/) added to the API featuring [rf-detr](https://github.com/roboflow/rf-detr)
- July 2025: All backends migrated outside of the main binary. LocalAI is now more lightweight, small, and automatically downloads the required backend to run the model. [Read the release notes](https://github.com/mudler/LocalAI/releases/tag/v3.2.0)
- June 2025: [Backend management](https://github.com/mudler/LocalAI/pull/5607) has been added. Attention: extras images are going to be deprecated from the next release! Read [the backend management PR](https://github.com/mudler/LocalAI/pull/5607).
- May 2025: [Audio input](https://github.com/mudler/LocalAI/pull/5466) and [Reranking](https://github.com/mudler/LocalAI/pull/5396) in llama.cpp backend, [Realtime API](https://github.com/mudler/LocalAI/pull/5392),  Support to Gemma, SmollVLM, and more multimodal models (available in the gallery).
- May 2025: Important: image name changes [See release](https://github.com/mudler/LocalAI/releases/tag/v2.29.0)
- Apr 2025: Rebrand, WebUI enhancements
- Apr 2025: [LocalAGI](https://github.com/mudler/LocalAGI) and [LocalRecall](https://github.com/mudler/LocalRecall) join the LocalAI family stack.
- Apr 2025: WebUI overhaul, AIO images updates
- Feb 2025: Backend cleanup, Breaking changes, new backends (kokoro, OutelTTS, faster-whisper), Nvidia L4T images
- Jan 2025: LocalAI model release: https://huggingface.co/mudler/LocalAI-functioncall-phi-4-v0.3, SANA support in diffusers: https://github.com/mudler/LocalAI/pull/4603
- Dec 2024: stablediffusion.cpp backend (ggml) added ( https://github.com/mudler/LocalAI/pull/4289 )
- Nov 2024: Bark.cpp backend added ( https://github.com/mudler/LocalAI/pull/4287 )
- Nov 2024: Voice activity detection models (**VAD**) added to the API: https://github.com/mudler/LocalAI/pull/4204
- Oct 2024: examples moved to [LocalAI-examples](https://github.com/mudler/LocalAI-examples)
- Aug 2024:  üÜï FLUX-1, [P2P Explorer](https://explorer.localai.io)
- July 2024: üî•üî• üÜï P2P Dashboard, LocalAI Federated mode and AI Swarms: https://github.com/mudler/LocalAI/pull/2723. P2P Global community pools: https://github.com/mudler/LocalAI/issues/3113
- May 2024: üî•üî• Decentralized P2P llama.cpp:  https://github.com/mudler/LocalAI/pull/2343 (peer2peer llama.cpp!) üëâ Docs  https://localai.io/features/distribute/
- May 2024: üî•üî• Distributed inferencing: https://github.com/mudler/LocalAI/pull/2324
- April 2024: Reranker API: https://github.com/mudler/LocalAI/pull/2121

Roadmap items: [List of issues](https://github.com/mudler/LocalAI/issues?q=is%3Aissue+is%3Aopen+label%3Aroadmap)

## üöÄ [Features](https://localai.io/features/)

- üß© [Backend Gallery](https://localai.io/backends/): Install/remove backends on the fly, powered by OCI images ‚Äî fully customizable and API-driven.
- üìñ [Text generation with GPTs](https://localai.io/features/text-generation/) (`llama.cpp`, `transformers`, `vllm` ... [:book: and more](https://localai.io/model-compatibility/index.html#model-compatibility-table))
- üó£ [Text to Audio](https://localai.io/features/text-to-audio/)
- üîà [Audio to Text](https://localai.io/features/audio-to-text/) (Audio transcription with `whisper.cpp`)
- üé® [Image generation](https://localai.io/features/image-generation)
- üî• [OpenAI-alike tools API](https://localai.io/features/openai-functions/) 
- üß† [Embeddings generation for vector databases](https://localai.io/features/embeddings/)
- ‚úçÔ∏è [Constrained grammars](https://localai.io/features/constrained_grammars/)
- üñºÔ∏è [Download Models directly from Huggingface ](https://localai.io/models/)
- ü•Ω [Vision API](https://localai.io/features/gpt-vision/)
- üîç [Object Detection](https://localai.io/features/object-detection/)
- üìà [Reranker API](https://localai.io/features/reranker/)
- üÜïüñß [P2P Inferencing](https://localai.io/features/distribute/)
- üÜïüîå [Model Context Protocol (MCP)](https://localai.io/docs/features/mcp/) - Agentic capabilities with external tools and [LocalAGI&#039;s Agentic capabilities](https://github.com/mudler/LocalAGI)
- üîä Voice activity detection (Silero-VAD support)
- üåç Integrated WebUI!

## üß© Supported Backends &amp; Acceleration

LocalAI supports a comprehensive range of AI backends with multiple acceleration options:

### Text Generation &amp; Language Models
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **llama.cpp** | LLM inference in C/C++ | CUDA 11/12, ROCm, Intel SYCL, Vulkan, Metal, CPU |
| **vLLM** | Fast LLM inference with PagedAttention | CUDA 12, ROCm, Intel |
| **transformers** | HuggingFace transformers framework | CUDA 11/12, ROCm, Intel, CPU |
| **exllama2** | GPTQ inference library | CUDA 12 |
| **MLX** | Apple Silicon LLM inference | Metal (M1/M2/M3+) |
| **MLX-VLM** | Apple Silicon Vision-Language Models | Metal (M1/M2/M3+) |

### Audio &amp; Speech Processing
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **whisper.cpp** | OpenAI Whisper in C/C++ | CUDA 12, ROCm, Intel SYCL, Vulkan, CPU |
| **faster-whisper** | Fast Whisper with CTranslate2 | CUDA 12, ROCm, Intel, CPU |
| **bark** | Text-to-audio generation | CUDA 12, ROCm, Intel |
| **bark-cpp** | C++ implementation of Bark | CUDA, Metal, CPU |
| **coqui** | Advanced TTS with 1100+ languages | CUDA 12, ROCm, Intel, CPU |
| **kokoro** | Lightweight TTS model | CUDA 12, ROCm, Intel, CPU |
| **chatterbox** | Production-grade TTS | CUDA 11/12, CPU |
| **piper** | Fast neural TTS system | CPU |
| **kitten-tts** | Kitten TTS models | CPU |
| **silero-vad** | Voice Activity Detection | CPU |
| **neutts** | Text-to-speech with voice cloning | CUDA 12, ROCm, CPU |

### Image &amp; Video Generation
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **stablediffusion.cpp** | Stable Diffusion in C/C++ | CUDA 12, Intel SYCL, Vulkan, CPU |
| **diffusers** | HuggingFace diffusion models | CUDA 11/12, ROCm, Intel, Metal, CPU |

### Specialized AI Tasks
| Backend | Description | Acceleration Support |
|---------|-------------|---------------------|
| **rfdetr** | Real-time object detection | CUDA 12, Intel, CPU |
| **rerankers** | Document reranking API | CUDA 11/12, ROCm, Intel, CPU |
| **local-store** | Vector database | CPU |
| **huggingface** | HuggingFace API integration | API-based |

### Hardware Acceleration Matrix

| Acceleration Type | Supported Backends | Hardware Support |
|-------------------|-------------------|------------------|
| **NVIDIA CUDA 11** | llama.cpp, whisper, stablediffusion, diffusers, rerankers, bark, chatterbox | Nvidia hardware |
| **NVIDIA CUDA 12** | All CUDA-compatible backends | Nvidia hardware |
| **AMD ROCm** | llama.cpp, whisper, vllm, transformers, diffusers, rerankers, coqui, kokoro, bark, neutts | AMD Graphics |
| **Intel oneAPI** | llama.cpp, whisper, stablediffusion, vllm, transformers, diffusers, rfdetr, rerankers, exllama2, coqui, kokoro, bark | Intel Arc, Intel iGPUs |
| **Apple Metal** | llama.cpp, whisper, diffusers, MLX, MLX-VLM, bark-cpp | Apple M1/M2/M3+ |
| **Vulkan** | llama.cpp, whisper, stablediffusion | Cross-platform GPUs |
| **NVIDIA Jetson** | llama.cpp, whisper, stablediffusion, diffusers, rfdetr | ARM64 embedded AI |
| **CPU Optimized** | All backends | AVX/AVX2/AVX512, quantization support |

### üîó Community and integrations

Build and deploy custom containers:
- https://github.com/sozercan/aikit

WebUIs:
- https://github.com/Jirubizu/localai-admin
- https://github.com/go-skynet/LocalAI-frontend
- QA-Pilot(An interactive chat project that leverages LocalAI LLMs for rapid understanding and navigation of GitHub code repository) https://github.com/reid41/QA-Pilot

Agentic Libraries:
- https://github.com/mudler/cogito

MCPs:
- https://github.com/mudler/MCPs

Model galleries
- https://github.com/go-skynet/model-gallery

Voice:
- https://github.com/richiejp/VoxInput

Other:
- Helm chart https://github.com/go-skynet/helm-charts
- VSCode extension https://github.com/badgooooor/localai-vscode-plugin
- Langchain: https://python.langchain.com/docs/integrations/providers/localai/
- Terminal utility https://github.com/djcopley/ShellOracle
- Local Smart assistant https://github.com/mudler/LocalAGI
- Home Assistant https://github.com/sammcj/homeassistant-localai / https://github.com/drndos/hass-openai-custom-conversation / https://github.com/valentinfrlch/ha-gpt4vision
- Discord bot https://github.com/mudler/LocalAGI/tree/main/examples/discord
- Slack bot https://github.com/mudler/LocalAGI/tree/main/examples/slack
- Shell-Pilot(Interact with LLM using LocalAI models via pure shell scripts on your Linux or MacOS system) https://github.com/reid41/shell-pilot
- Telegram bot https://github.com/mudler/LocalAI/tree/master/examples/telegram-bot
- Another Telegram Bot https://github.com/JackBekket/Hellper
- Auto-documentation https://github.com/JackBekket/Reflexia
- Github bot which answer on issue

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[prometheus/alertmanager]]></title>
            <link>https://github.com/prometheus/alertmanager</link>
            <guid>https://github.com/prometheus/alertmanager</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[Prometheus Alertmanager]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prometheus/alertmanager">prometheus/alertmanager</a></h1>
            <p>Prometheus Alertmanager</p>
            <p>Language: Go</p>
            <p>Stars: 7,347</p>
            <p>Forks: 2,286</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># Alertmanager [![CircleCI](https://circleci.com/gh/prometheus/alertmanager/tree/main.svg?style=shield)][circleci]

[![Docker Repository on Quay](https://quay.io/repository/prometheus/alertmanager/status &quot;Docker Repository on Quay&quot;)][quay]
[![Docker Pulls](https://img.shields.io/docker/pulls/prom/alertmanager.svg?maxAge=604800)][hub]

The Alertmanager handles alerts sent by client applications such as the Prometheus server. It takes care of deduplicating, grouping, and routing them to the correct [receiver integrations](https://prometheus.io/docs/alerting/latest/configuration/#receiver) such as email, PagerDuty, OpsGenie, or many other [mechanisms](https://prometheus.io/docs/operating/integrations/#alertmanager-webhook-receiver) thanks to the webhook receiver. It also takes care of silencing and inhibition of alerts.

* [Documentation](http://prometheus.io/docs/alerting/alertmanager/)

## Install

There are various ways of installing Alertmanager.

### Precompiled binaries

Precompiled binaries for released versions are available in the
[*download* section](https://prometheus.io/download/)
on [prometheus.io](https://prometheus.io). Using the latest production release binary
is the recommended way of installing Alertmanager.

### Docker images

Docker images are available on [Quay.io](https://quay.io/repository/prometheus/alertmanager) or [Docker Hub](https://hub.docker.com/r/prom/alertmanager/).

You can launch an Alertmanager container for trying it out with

    $ docker run --name alertmanager -d -p 127.0.0.1:9093:9093 quay.io/prometheus/alertmanager

Alertmanager will now be reachable at http://localhost:9093/.

### Compiling the binary

You can either `go install` it:

```
$ go install github.com/prometheus/alertmanager/cmd/...@latest
# cd $GOPATH/src/github.com/prometheus/alertmanager
$ alertmanager --config.file=&lt;your_file&gt;
```

Or clone the repository and build manually:

```
$ mkdir -p $GOPATH/src/github.com/prometheus
$ cd $GOPATH/src/github.com/prometheus
$ git clone https://github.com/prometheus/alertmanager.git
$ cd alertmanager
$ make build
$ ./alertmanager --config.file=&lt;your_file&gt;
```

You can also build just one of the binaries in this repo by passing a name to the build function:
```
$ make build BINARIES=amtool
```

## Example

This is an example configuration that should cover most relevant aspects of the new YAML configuration format. The full documentation of the configuration can be found [here](https://prometheus.io/docs/alerting/configuration/).

```yaml
global:
  # The smarthost and SMTP sender used for mail notifications.
  smtp_smarthost: &#039;localhost:25&#039;
  smtp_from: &#039;alertmanager@example.org&#039;

# The root route on which each incoming alert enters.
route:
  # The root route must not have any matchers as it is the entry point for
  # all alerts. It needs to have a receiver configured so alerts that do not
  # match any of the sub-routes are sent to someone.
  receiver: &#039;team-X-mails&#039;

  # The labels by which incoming alerts are grouped together. For example,
  # multiple alerts coming in for cluster=A and alertname=LatencyHigh would
  # be batched into a single group.
  #
  # To aggregate by all possible labels use &#039;...&#039; as the sole label name.
  # This effectively disables aggregation entirely, passing through all
  # alerts as-is. This is unlikely to be what you want, unless you have
  # a very low alert volume or your upstream notification system performs
  # its own grouping. Example: group_by: [...]
  group_by: [&#039;alertname&#039;, &#039;cluster&#039;]

  # When a new group of alerts is created by an incoming alert, wait at
  # least &#039;group_wait&#039; to send the initial notification.
  # This way ensures that you get multiple alerts for the same group that start
  # firing shortly after another are batched together on the first
  # notification.
  group_wait: 30s

  # When the first notification was sent, wait &#039;group_interval&#039; to send a batch
  # of new alerts that started firing for that group.
  group_interval: 5m

  # If an alert has successfully been sent, wait &#039;repeat_interval&#039; to
  # resend them.
  repeat_interval: 3h

  # All the above attributes are inherited by all child routes and can
  # overwritten on each.

  # The child route trees.
  routes:
  # This route performs a regular expression match on alert labels to
  # catch alerts that are related to a list of services.
  - matchers:
    - service=~&quot;^(foo1|foo2|baz)$&quot;
    receiver: team-X-mails

    # The service has a sub-route for critical alerts, any alerts
    # that do not match, i.e. severity != critical, fall-back to the
    # parent node and are sent to &#039;team-X-mails&#039;
    routes:
    - matchers:
      - severity=&quot;critical&quot;
      receiver: team-X-pager

  - matchers:
    - service=&quot;files&quot;
    receiver: team-Y-mails

    routes:
    - matchers:
      - severity=&quot;critical&quot;
      receiver: team-Y-pager

  # This route handles all alerts coming from a database service. If there&#039;s
  # no team to handle it, it defaults to the DB team.
  - matchers:
    - service=&quot;database&quot;

    receiver: team-DB-pager
    # Also group alerts by affected database.
    group_by: [alertname, cluster, database]

    routes:
    - matchers:
      - owner=&quot;team-X&quot;
      receiver: team-X-pager

    - matchers:
      - owner=&quot;team-Y&quot;
      receiver: team-Y-pager


# Inhibition rules allow to mute a set of alerts given that another alert is
# firing.
# We use this to mute any warning-level notifications if the same alert is
# already critical.
inhibit_rules:
- source_matchers:
    - severity=&quot;critical&quot;
  target_matchers:
    - severity=&quot;warning&quot;
  # Apply inhibition if the alertname is the same.
  # CAUTION: 
  #   If all label names listed in `equal` are missing 
  #   from both the source and target alerts,
  #   the inhibition rule will apply!
  equal: [&#039;alertname&#039;]


receivers:
- name: &#039;team-X-mails&#039;
  email_configs:
  - to: &#039;team-X+alerts@example.org, team-Y+alerts@example.org&#039;

- name: &#039;team-X-pager&#039;
  email_configs:
  - to: &#039;team-X+alerts-critical@example.org&#039;
  pagerduty_configs:
  - routing_key: &lt;team-X-key&gt;

- name: &#039;team-Y-mails&#039;
  email_configs:
  - to: &#039;team-Y+alerts@example.org&#039;

- name: &#039;team-Y-pager&#039;
  pagerduty_configs:
  - routing_key: &lt;team-Y-key&gt;

- name: &#039;team-DB-pager&#039;
  pagerduty_configs:
  - routing_key: &lt;team-DB-key&gt;
```

## API

The current Alertmanager API is version 2. This API is fully generated via the
[OpenAPI project](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/2.0.md)
and [Go Swagger](https://github.com/go-swagger/go-swagger/) with the exception
of the HTTP handlers themselves. The API specification can be found in
[api/v2/openapi.yaml](api/v2/openapi.yaml). A HTML rendered version can be
accessed [here](http://petstore.swagger.io/?url=https://raw.githubusercontent.com/prometheus/alertmanager/main/api/v2/openapi.yaml).
Clients can be easily generated via any OpenAPI generator for all major languages.

APIv2 is accessed via the `/api/v2` prefix. APIv1 was deprecated in `0.16.0` and is removed as of version `0.27.0`.
The v2 `/status` endpoint would be `/api/v2/status`. If `--web.route-prefix` is set then API routes are
prefixed with that as well, so `--web.route-prefix=/alertmanager/` would
relate to `/alertmanager/api/v2/status`.

## amtool

`amtool` is a cli tool for interacting with the Alertmanager API. It is bundled with all releases of Alertmanager.

### Install

Alternatively you can install with:
```
$ go install github.com/prometheus/alertmanager/cmd/amtool@latest
```

### Examples

View all currently firing alerts:
```
$ amtool alert
Alertname        Starts At                Summary
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Test_Alert       2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
Check_Foo_Fails  2017-08-02 18:30:18 UTC  This is a testing alert!
```

View all currently firing alerts with extended output:
```
$ amtool -o extended alert
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname=&quot;Test_Alert&quot; instance=&quot;node0&quot;       link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname=&quot;Test_Alert&quot; instance=&quot;node1&quot;       link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname=&quot;Check_Foo_Fails&quot; instance=&quot;node0&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname=&quot;Check_Foo_Fails&quot; instance=&quot;node1&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
```

In addition to viewing alerts, you can use the rich query syntax provided by Alertmanager:
```
$ amtool -o extended alert query alertname=&quot;Test_Alert&quot;
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname=&quot;Test_Alert&quot; instance=&quot;node0&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname=&quot;Test_Alert&quot; instance=&quot;node1&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query instance=~&quot;.+1&quot;
Labels                                        Annotations                                                    Starts At                Ends At                  Generator URL
alertname=&quot;Test_Alert&quot; instance=&quot;node1&quot;       link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
alertname=&quot;Check_Foo_Fails&quot; instance=&quot;node1&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local

$ amtool -o extended alert query alertname=~&quot;Test.*&quot; instance=~&quot;.+1&quot;
Labels                                   Annotations                                                    Starts At                Ends At                  Generator URL
alertname=&quot;Test_Alert&quot; instance=&quot;node1&quot;  link=&quot;https://example.com&quot; summary=&quot;This is a testing alert!&quot;  2017-08-02 18:31:24 UTC  0001-01-01 00:00:00 UTC  http://my.testing.script.local
```

Silence an alert:
```
$ amtool silence add alertname=Test_Alert
b3ede22e-ca14-4aa0-932c-ca2f3445f926

$ amtool silence add alertname=&quot;Test_Alert&quot; instance=~&quot;.+0&quot;
e48cb58a-0b17-49ba-b734-3585139b1d25
```

View silences:
```
$ amtool silence query
ID                                    Matchers              Ends At                  Created By  Comment
b3ede22e-ca14-4aa0-932c-ca2f3445f926  alertname=Test_Alert  2017-08-02 19:54:50 UTC  kellel

$ amtool silence query instance=~&quot;.+0&quot;
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel
```

Expire a silence:
```
$ amtool silence expire b3ede22e-ca14-4aa0-932c-ca2f3445f926
```

Expire all silences matching a query:
```
$ amtool silence query instance=~&quot;.+0&quot;
ID                                    Matchers                            Ends At                  Created By  Comment
e48cb58a-0b17-49ba-b734-3585139b1d25  alertname=Test_Alert instance=~.+0  2017-08-02 22:41:39 UTC  kellel

$ amtool silence expire $(amtool silence query -q instance=~&quot;.+0&quot;)

$ amtool silence query instance=~&quot;.+0&quot;

```

Expire all silences:
```
$ amtool silence expire $(amtool silence query -q)
```

Try out how a template works. Let&#039;s say you have this in your configuration file:
```
templates:
  - &#039;/foo/bar/*.tmpl&#039;
```

Then you can test out how a template would look like with example by using this command:
```
amtool template render --template.glob=&#039;/foo/bar/*.tmpl&#039; --template.text=&#039;{{ template &quot;slack.default.markdown.v1&quot; . }}&#039;
```

### Configuration

`amtool` allows a configuration file to specify some options for convenience. The default configuration file paths are `$HOME/.config/amtool/config.yml` or `/etc/amtool/config.yml`

An example configuration file might look like the following:

```
# Define the path that `amtool` can find your `alertmanager` instance
alertmanager.url: &quot;http://localhost:9093&quot;

# Override the default author. (unset defaults to your username)
author: me@example.com

# Force amtool to give you an error if you don&#039;t include a comment on a silence
comment_required: true

# Set a default output format. (unset defaults to simple)
output: extended

# Set a default receiver
receiver: team-X-pager
```

### Routes

`amtool` allows you to visualize the routes of your configuration in form of text tree view.
Also you can use it to test the routing by passing it label set of an alert
and it prints out all receivers the alert would match ordered and separated by `,`.
(If you use `--verify.receivers` amtool returns error code 1 on mismatch)

Example of usage:
```
# View routing tree of remote Alertmanager
$ amtool config routes --alertmanager.url=http://localhost:9090

# Test if alert matches expected receiver
$ amtool config routes test --config.file=doc/examples/simple.yml --tree --verify.receivers=team-X-pager service=database owner=team-X
```

## High Availability

Alertmanager&#039;s high availability is in production use at many companies and is enabled by default.

&gt; Important: Both UDP and TCP are needed in alertmanager 0.15 and higher for the cluster to work.
&gt;  - If you are using a firewall, make sure to whitelist the clustering port for both protocols.
&gt;  - If you are running in a container, make sure to expose the clustering port for both protocols.

To create a highly available cluster of the Alertmanager the instances need to
be configured to communicate with each other. This is configured using the
`--cluster.*` flags.

- `--cluster.listen-address` string: cluster listen address (default &quot;0.0.0.0:9094&quot;; empty string disables HA mode)
- `--cluster.advertise-address` string: cluster advertise address
- `--cluster.peer` value: initial peers (repeat flag for each additional peer)
- `--cluster.peer-timeout` value: peer timeout period (default &quot;15s&quot;)
- `--cluster.gossip-interval` value: cluster message propagation speed
  (default &quot;200ms&quot;)
- `--cluster.pushpull-interval` value: lower values will increase
  convergence speeds at expense of bandwidth (default &quot;1m0s&quot;)
- `--cluster.settle-timeout` value: maximum time to wait for cluster
  connections to settle before evaluating notifications.
- `--cluster.tcp-timeout` value: timeout value for tcp connections, reads and writes (default &quot;10s&quot;)
- `--cluster.probe-timeout` value: time to wait for ack before marking node unhealthy
  (default &quot;500ms&quot;)
- `--cluster.probe-interval` value: interval between random node probes (default &quot;1s&quot;)
- `--cluster.reconnect-interval` value: interval between attempting to reconnect to lost peers (default &quot;10s&quot;)
- `--cluster.reconnect-timeout` value: length of time to attempt to reconnect to a lost peer (default: &quot;6h0m0s&quot;)
- `--cluster.label` value: the label is an optional string to include on each packet and stream. It uniquely identifies the cluster and prevents cross-communication issues when sending gossip messages (default:&quot;&quot;)

The chosen port in the `cluster.listen-address` flag is the port that needs to be
specified in the `cluster.peer` flag of the other peers.

The `cluster.advertise-address` flag is required if the instance doesn&#039;t have
an IP address that is part of [RFC 6890](https://tools.ietf.org/html/rfc6890)
with a default route.

To start a cluster of three peers on your local machine use [`goreman`](https://github.com/mattn/goreman) and the
Procfile within this repository.

	goreman start

To point your Prometheus 1.4, or later, instance to multiple Alertmanagers, configure them
in your `prometheus.yml` configuration file, for example:

```yaml
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager1:9093
      - alertmanager2:9093
      - alertmanager3:9093
```

&gt; Important: Do not load balance traffic between Prometheus and its Alertmanagers, but instead point Prometheus to a list of all Alertmanagers. The Alertmanager implementation expects all alerts to be sent to all Alertmanagers to ensure high availability.

### Turn off high availability

If running Alertmanager in high availability mode is not desired, setting `--cluster.listen-address=` prevents Alertmanager from listening to incoming peer requests.

## Contributing

Check the [Prometheus contributing page](https://github.com/prometheus/prometheus/blob/main/CONTRIBUTING.md).

To contribute to the user interface, refer to [ui/app/CONTRIBUTING.md](ui/app/CONTRIBUTING.md).

## Architecture

![](doc/arch.svg)

## License

Apache License 2.0, see [LICENSE](https://github.com/prometheus/alertmanager/blob/main/LICENSE).

[hub]: https://hub.docker.com/r/prom/alertmanager/
[circleci]: https://circleci.com/gh/prometheus/alertmanager
[quay]: https://quay.io/repository/prometheus/alertmanager
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[charmbracelet/glow]]></title>
            <link>https://github.com/charmbracelet/glow</link>
            <guid>https://github.com/charmbracelet/glow</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[Render markdown on the CLI, with pizzazz! üíÖüèª]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/charmbracelet/glow">charmbracelet/glow</a></h1>
            <p>Render markdown on the CLI, with pizzazz! üíÖüèª</p>
            <p>Language: Go</p>
            <p>Stars: 20,848</p>
            <p>Forks: 500</p>
            <p>Stars today: 186 stars today</p>
            <h2>README</h2><pre># Glow

Render markdown on the CLI, with _pizzazz_!

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://stuff.charm.sh/glow/glow-banner-github.gif&quot; alt=&quot;Glow Logo&quot;&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/glow/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/charmbracelet/glow.svg&quot; alt=&quot;Latest Release&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://pkg.go.dev/github.com/charmbracelet/glow?tab=doc&quot;&gt;&lt;img src=&quot;https://godoc.org/github.com/golang/gddo?status.svg&quot; alt=&quot;GoDoc&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/charmbracelet/glow/actions&quot;&gt;&lt;img src=&quot;https://github.com/charmbracelet/glow/workflows/build/badge.svg&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://goreportcard.com/report/github.com/charmbracelet/glow&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/charmbracelet/glow&quot; alt=&quot;Go ReportCard&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/c2246366-f84b-4847-b431-32a61ca07b74&quot; width=&quot;800&quot; alt=&quot;Glow UI Demo&quot;&gt;
&lt;/p&gt;

## What is it?

Glow is a terminal based markdown reader designed from the ground up to bring
out the beauty‚Äîand power‚Äîof the CLI.

Use it to discover markdown files, read documentation directly on the command
line. Glow will find local markdown files in subdirectories or a local
Git repository.

## Installation

### Package Manager

```bash
# macOS or Linux
brew install glow
```

```bash
# macOS (with MacPorts)
sudo port install glow
```

```bash
# Arch Linux (btw)
pacman -S glow
```

```bash
# Void Linux
xbps-install -S glow
```

```bash
# Nix shell
nix-shell -p glow --command glow
```

```bash
# FreeBSD
pkg install glow
```

```bash
# Solus
eopkg install glow
```

```bash
# Windows (with Chocolatey, Scoop, or Winget)
choco install glow
scoop install glow
winget install charmbracelet.glow
```

```bash
# Android (with termux)
pkg install glow
```

```bash
# Ubuntu (Snapcraft)
sudo snap install glow
```

```bash
# Debian/Ubuntu
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://repo.charm.sh/apt/gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/charm.gpg
echo &quot;deb [signed-by=/etc/apt/keyrings/charm.gpg] https://repo.charm.sh/apt/ * *&quot; | sudo tee /etc/apt/sources.list.d/charm.list
sudo apt update &amp;&amp; sudo apt install glow
```

```bash
# Fedora/RHEL
echo &#039;[charm]
name=Charm
baseurl=https://repo.charm.sh/yum/
enabled=1
gpgcheck=1
gpgkey=https://repo.charm.sh/yum/gpg.key&#039; | sudo tee /etc/yum.repos.d/charm.repo
sudo yum install glow
```

Or download a binary from the [releases][releases] page. MacOS, Linux, Windows,
FreeBSD and OpenBSD binaries are available, as well as Debian, RPM, and Alpine
packages. ARM builds are also available for macOS, Linux, FreeBSD and OpenBSD.

### Go

Or just install it with `go`:

```bash
go install github.com/charmbracelet/glow/v2@latest
```

### Build (requires Go 1.21+)

```bash
git clone https://github.com/charmbracelet/glow.git
cd glow
go build
```

[releases]: https://github.com/charmbracelet/glow/releases

## The TUI

Simply run `glow` without arguments to start the textual user interface and
browse local. Glow will find local markdown files in the
current directory and below or, if you‚Äôre in a Git repository, Glow will search
the repo.

Markdown files can be read with Glow&#039;s high-performance pager. Most of the
keystrokes you know from `less` are the same, but you can press `?` to list
the hotkeys.

## The CLI

In addition to a TUI, Glow has a CLI for working with Markdown. To format a
document use a markdown source as the primary argument:

```bash
# Read from file
glow README.md

# Read from stdin
echo &quot;[Glow](https://github.com/charmbracelet/glow)&quot; | glow -

# Fetch README from GitHub / GitLab
glow github.com/charmbracelet/glow

# Fetch markdown from HTTP
glow https://host.tld/file.md
```

### Word Wrapping

The `-w` flag lets you set a maximum width at which the output will be wrapped:

```bash
glow -w 60
```

### Paging

CLI output can be displayed in your preferred pager with the `-p` flag. This defaults
to the ANSI-aware `less -r` if `$PAGER` is not explicitly set.

### Styles

You can choose a style with the `-s` flag. When no flag is provided `glow` tries
to detect your terminal&#039;s current background color and automatically picks
either the `dark` or the `light` style for you.

```bash
glow -s [dark|light]
```

Alternatively you can also supply a custom JSON stylesheet:

```bash
glow -s mystyle.json
```

For additional usage details see:

```bash
glow --help
```

Check out the [Glamour Style Section](https://github.com/charmbracelet/glamour/blob/master/styles/gallery/README.md)
to find more styles. Or [make your own](https://github.com/charmbracelet/glamour/tree/master/styles)!

## The Config File

If you find yourself supplying the same flags to `glow` all the time, it&#039;s
probably a good idea to create a config file. Run `glow config`, which will open
it in your favorite $EDITOR. Alternatively you can manually put a file named
`glow.yml` in the default config path of you platform. If you&#039;re not sure where
that is, please refer to `glow --help`.

Here&#039;s an example config:

```yaml
# style name or JSON path (default &quot;auto&quot;)
style: &quot;light&quot;
# mouse wheel support (TUI-mode only)
mouse: true
# use pager to display markdown
pager: true
# at which column should we word wrap?
width: 80
# show all files, including hidden and ignored.
all: false
# show line numbers (TUI-mode only)
showLineNumbers: false
# preserve newlines in the output
preserveNewLines: false
```

## Contributing

See [contributing][contribute].

[contribute]: https://github.com/charmbracelet/glow/contribute

## Feedback

We‚Äôd love to hear your thoughts on this project. Feel free to drop us a note!

- [Twitter](https://twitter.com/charmcli)
- [The Fediverse](https://mastodon.social/@charmcli)
- [Discord](https://charm.sh/chat)

## License

[MIT](https://github.com/charmbracelet/glow/raw/master/LICENSE)

---

Part of [Charm](https://charm.sh).

&lt;a href=&quot;https://charm.sh/&quot;&gt;&lt;img alt=&quot;The Charm logo&quot; src=&quot;https://stuff.charm.sh/charm-badge.jpg&quot; width=&quot;400&quot;&gt;&lt;/a&gt;

CharmÁÉ≠Áà±ÂºÄÊ∫ê ‚Ä¢ Charm loves open source
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes-sigs/gateway-api]]></title>
            <link>https://github.com/kubernetes-sigs/gateway-api</link>
            <guid>https://github.com/kubernetes-sigs/gateway-api</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[Repository for the next iteration of composite service (e.g. Ingress) and load balancing APIs.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes-sigs/gateway-api">kubernetes-sigs/gateway-api</a></h1>
            <p>Repository for the next iteration of composite service (e.g. Ingress) and load balancing APIs.</p>
            <p>Language: Go</p>
            <p>Stars: 2,333</p>
            <p>Forks: 611</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># Kubernetes Gateway API

The Gateway API is a part of [SIG Network][sn], and this repository contains
the specification and Custom Resource Definitions (CRDs).

## Status

The latest supported version is `v1` as released by
the [v1.4.0 release][gh_release] of this project.

This version of the API is has GA level support for the following resources:

- `v1.GatewayClass`
- `v1.Gateway`
- `v1.HTTPRoute`
- `v1.GRPCRoute`
- `v1.BackendTLSPolicy`

For all the other APIs and their support levels please consult [the spec][spec].

## Documentation

### Website

The API specification and detailed documentation is available on the project
website: [https://gateway-api.sigs.k8s.io][ghp].

### Concepts

To get started, please read through [API concepts][concepts] and
[Security model][security-model]. These documents give the necessary background
to understand the API and the use-cases it targets.

### Getting started

Once you have a good understanding of the API at a higher-level, check out
[getting started][getting-started] to install your first Gateway controller and try out
one of the guides.

### References

For a complete API reference, please refer to:

- [API reference][spec]
- [Go docs for the package][godoc]

## Gateway API conformance

If you are developing a Gateway API implementation and want to run conformance tests
against your project and eventually submit the proof of conformance, visit the [conformance
documentation][conformance-docs] for the test suite documentation, and the conformance
reports [readme][reports-readme] to see the reports submission rules. If you
are a user who wants to explore the features supported by the various implementations,
navigate the [conformance reports][conformance-reports]

## Contributing

Community meeting schedule, notes and developer guide can be found on the
[community page][cm].
Our Kubernetes Slack channel is [#sig-network-gateway-api][slack].

### Code of conduct

Participation in the Kubernetes community is governed by the
[Kubernetes Code of Conduct](code-of-conduct.md).

[ghp]: https://gateway-api.sigs.k8s.io/
[sn]: https://github.com/kubernetes/community/tree/master/sig-network
[cm]: https://gateway-api.sigs.k8s.io/contributing/community
[slack]: https://kubernetes.slack.com/messages/sig-network-gateway-api
[getting-started]: https://gateway-api.sigs.k8s.io/guides/
[spec]: https://gateway-api.sigs.k8s.io/reference/spec/
[concepts]: https://gateway-api.sigs.k8s.io/concepts/api-overview
[security-model]: https://gateway-api.sigs.k8s.io/concepts/security-model
[gh_release]: https://github.com/kubernetes-sigs/gateway-api/releases/tag/v1.4.0
[godoc]: https://pkg.go.dev/sigs.k8s.io/gateway-api
[conformance-docs]: https://gateway-api.sigs.k8s.io/concepts/conformance/
[reports-readme]: ./conformance/reports/README.md
[conformance-reports]: ./conformance/reports/
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[DataDog/datadog-agent]]></title>
            <link>https://github.com/DataDog/datadog-agent</link>
            <guid>https://github.com/DataDog/datadog-agent</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[Main repository for Datadog Agent]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DataDog/datadog-agent">DataDog/datadog-agent</a></h1>
            <p>Main repository for Datadog Agent</p>
            <p>Language: Go</p>
            <p>Stars: 3,386</p>
            <p>Forks: 1,351</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># Datadog Agent

![GitHub Release](https://img.shields.io/github/v/release/DataDog/datadog-agent?style=flat&amp;logo=datadog&amp;logoColor=%23632CA6&amp;labelColor=%23FFF&amp;color=%23632CA6)
[![Coverage status](https://codecov.io/github/DataDog/datadog-agent/coverage.svg?branch=main)](https://codecov.io/github/DataDog/datadog-agent?branch=main)
[![GoDoc](https://godoc.org/github.com/DataDog/datadog-agent?status.svg)](https://godoc.org/github.com/DataDog/datadog-agent)

This repository contains the source code of the Datadog Agent version 7 and version 6. Please refer to the [Agent user documentation](https://docs.datadoghq.com/agent/) for information about differences between Agent v5, Agent v6 and Agent v7. Additionally, we provide a list of prepackaged binaries for an easy install process [here](https://app.datadoghq.com/fleet/install-agent/latest?platform=overview).

## Documentation

The [developer docs site](https://datadoghq.dev/datadog-agent/setup/) contains information about how to develop the Datadog Agent itself.

The source of the content is located under [the docs directory](docs) and may contain pages that are not yet published.

## Contributing code

You&#039;ll find information and help on how to contribute code to this project under
[the `docs/dev` directory](docs/dev) of the present repo.

## License

The Datadog Agent user space components are licensed under the
[Apache License, Version 2.0](LICENSE). The BPF code is licensed
under the [General Public License, Version 2.0](pkg/ebpf/c/COPYING).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[jesseduffield/lazygit]]></title>
            <link>https://github.com/jesseduffield/lazygit</link>
            <guid>https://github.com/jesseduffield/lazygit</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[simple terminal UI for git commands]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jesseduffield/lazygit">jesseduffield/lazygit</a></h1>
            <p>simple terminal UI for git commands</p>
            <p>Language: Go</p>
            <p>Stars: 67,333</p>
            <p>Forks: 2,315</p>
            <p>Stars today: 140 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;sup&gt;Special thanks to:&lt;/sup&gt;
&lt;br&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=lazygit_20231023&quot;&gt;
  &lt;div&gt;
    &lt;img src=&quot;https://github.com/warpdotdev/brand-assets/blob/main/Github/Sponsor/Warp-Github-LG-02.png?raw=true&quot; width=&quot;400&quot; alt=&quot;Warp&quot;&gt;
  &lt;/div&gt;
  &lt;b&gt;Warp, the intelligent terminal&lt;/b&gt;
  &lt;br&gt;
  &lt;b&gt;Available for MacOS and Linux&lt;/b&gt;
  &lt;br&gt;
  &lt;div&gt;
    &lt;sup&gt;Visit¬†warp.dev¬†to learn more.&lt;/sup&gt;
  &lt;/div&gt;
&lt;/a&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;a href=&quot;https://tuple.app/lazygit&quot;&gt;
  &lt;div&gt;
    &lt;img src=&quot;../assets/tuple.png&quot; width=&quot;400&quot; alt=&quot;Tuple&quot;&gt;
  &lt;/div&gt;
  &lt;b&gt;Tuple, the premier screen sharing app for developers on macOS and Windows.&lt;/b&gt;
&lt;/a&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.subble.com&quot;&gt;
  &lt;div&gt;
    &lt;img src=&quot;../assets/subble.webp&quot; width=&quot;400&quot; alt=&quot;Subble&quot;&gt;
  &lt;/div&gt;
  &lt;b&gt;I (Jesse) co-founded Subble to save your company time and money by finding unused and over-provisioned SaaS licences. Check it out!&lt;/b&gt;
&lt;/a&gt;
&lt;br&gt;

&lt;hr&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;536&quot; src=&quot;https://user-images.githubusercontent.com/8456633/174470852-339b5011-5800-4bb9-a628-ff230aa8cd4e.png&quot;&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

A simple terminal UI for git commands
&lt;br/&gt;

[![GitHub Releases](https://img.shields.io/github/downloads/jesseduffield/lazygit/total)](https://github.com/jesseduffield/lazygit/releases) [![Go Report Card](https://goreportcard.com/badge/github.com/jesseduffield/lazygit)](https://goreportcard.com/report/github.com/jesseduffield/lazygit) [![Codacy Badge](https://app.codacy.com/project/badge/Grade/f46416b715d74622895657935fcada21)](https://app.codacy.com/gh/jesseduffield/lazygit/dashboard?utm_source=gh&amp;utm_medium=referral&amp;utm_content=&amp;utm_campaign=Badge_grade) [![Codacy Badge](https://app.codacy.com/project/badge/Coverage/f46416b715d74622895657935fcada21)](https://app.codacy.com/gh/jesseduffield/lazygit/dashboard?utm_source=gh&amp;utm_medium=referral&amp;utm_content=&amp;utm_campaign=Badge_coverage) [![golangci-lint](https://img.shields.io/badge/linted%20by-golangci--lint-brightgreen)](https://golangci-lint.run/) [![GitHub tag](https://img.shields.io/github/v/tag/jesseduffield/lazygit?color=blue)](https://github.com/jesseduffield/lazygit/releases/latest) [![homebrew](https://img.shields.io/homebrew/v/lazygit?color=blue)](https://formulae.brew.sh/formula/lazygit)

![commit_and_push](../assets/demo/commit_and_push-compressed.gif)

&lt;/div&gt;

## Sponsors

&lt;p align=&quot;center&quot;&gt;
 Maintenance of this project is made possible by all the &lt;a href=&quot;https://github.com/jesseduffield/lazygit/graphs/contributors&quot;&gt;contributors&lt;/a&gt; and &lt;a href=&quot;https://github.com/sponsors/jesseduffield&quot;&gt;sponsors&lt;/a&gt;. If you&#039;d like to sponsor this project and have your avatar or company logo appear below &lt;a href=&quot;https://github.com/sponsors/jesseduffield&quot;&gt;click here&lt;/a&gt;. üíô
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;!-- sponsors --&gt;&lt;a href=&quot;https://github.com/intabulas&quot;&gt;&lt;img src=&quot;https://github.com/intabulas.png&quot; width=&quot;60px&quot; alt=&quot;Mark Lussier&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/peppy&quot;&gt;&lt;img src=&quot;https://github.com/peppy.png&quot; width=&quot;60px&quot; alt=&quot;Dean Herbert&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/piot&quot;&gt;&lt;img src=&quot;https://github.com/piot.png&quot; width=&quot;60px&quot; alt=&quot;Peter Bjorklund&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/rgwood&quot;&gt;&lt;img src=&quot;https://github.com/rgwood.png&quot; width=&quot;60px&quot; alt=&quot;Reilly Wood&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/oliverguenther&quot;&gt;&lt;img src=&quot;https://github.com/oliverguenther.png&quot; width=&quot;60px&quot; alt=&quot;Oliver G√ºnther&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/pawanjay176&quot;&gt;&lt;img src=&quot;https://github.com/pawanjay176.png&quot; width=&quot;60px&quot; alt=&quot;Pawan Dhananjay&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/bdach&quot;&gt;&lt;img src=&quot;https://github.com/bdach.png&quot; width=&quot;60px&quot; alt=&quot;Bart≈Çomiej Dach&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/naoey&quot;&gt;&lt;img src=&quot;https://github.com/naoey.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/carstengehling&quot;&gt;&lt;img src=&quot;https://github.com/carstengehling.png&quot; width=&quot;60px&quot; alt=&quot;Carsten Gehling&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Xetera&quot;&gt;&lt;img src=&quot;https://github.com/Xetera.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/HoldenLucas&quot;&gt;&lt;img src=&quot;https://github.com/HoldenLucas.png&quot; width=&quot;60px&quot; alt=&quot;Holden Lucas&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/nartc&quot;&gt;&lt;img src=&quot;https://github.com/nartc.png&quot; width=&quot;60px&quot; alt=&quot;Chau Tran&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/matejcik&quot;&gt;&lt;img src=&quot;https://github.com/matejcik.png&quot; width=&quot;60px&quot; alt=&quot;matejcik&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/lucatume&quot;&gt;&lt;img src=&quot;https://github.com/lucatume.png&quot; width=&quot;60px&quot; alt=&quot;theAverageDev (Luca Tumedei)&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/IvanZuy&quot;&gt;&lt;img src=&quot;https://github.com/IvanZuy.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/nicholascloud&quot;&gt;&lt;img src=&quot;https://github.com/nicholascloud.png&quot; width=&quot;60px&quot; alt=&quot;Nicholas Cloud&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ava1ar&quot;&gt;&lt;img src=&quot;https://github.com/ava1ar.png&quot; width=&quot;60px&quot; alt=&quot;Aliaksandr Stelmachonak&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/minidfx&quot;&gt;&lt;img src=&quot;https://github.com/minidfx.png&quot; width=&quot;60px&quot; alt=&quot;Burgy Benjamin&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/JoeKlemmer&quot;&gt;&lt;img src=&quot;https://github.com/JoeKlemmer.png&quot; width=&quot;60px&quot; alt=&quot;Joe Klemmer&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/tobi&quot;&gt;&lt;img src=&quot;https://github.com/tobi.png&quot; width=&quot;60px&quot; alt=&quot;Tobias L√ºtke&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/benbfortis&quot;&gt;&lt;img src=&quot;https://github.com/benbfortis.png&quot; width=&quot;60px&quot; alt=&quot;Ben Beaumont&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jakewarren&quot;&gt;&lt;img src=&quot;https://github.com/jakewarren.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/tgpholly&quot;&gt;&lt;img src=&quot;https://github.com/tgpholly.png&quot; width=&quot;60px&quot; alt=&quot;Holly&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/socketbox&quot;&gt;&lt;img src=&quot;https://github.com/socketbox.png&quot; width=&quot;60px&quot; alt=&quot;Casey Boettcher&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/bitprophet&quot;&gt;&lt;img src=&quot;https://github.com/bitprophet.png&quot; width=&quot;60px&quot; alt=&quot;Jeff Forcier&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/tayleighr&quot;&gt;&lt;img src=&quot;https://github.com/tayleighr.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Novakov&quot;&gt;&lt;img src=&quot;https://github.com/Novakov.png&quot; width=&quot;60px&quot; alt=&quot;Maciej T. Nowak&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/nekhaevskiy&quot;&gt;&lt;img src=&quot;https://github.com/nekhaevskiy.png&quot; width=&quot;60px&quot; alt=&quot;Yury&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/reivilibre&quot;&gt;&lt;img src=&quot;https://github.com/reivilibre.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/andreaskurth&quot;&gt;&lt;img src=&quot;https://github.com/andreaskurth.png&quot; width=&quot;60px&quot; alt=&quot;Andreas Kurth&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/BSteffaniak&quot;&gt;&lt;img src=&quot;https://github.com/BSteffaniak.png&quot; width=&quot;60px&quot; alt=&quot;Braden Steffaniak&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jordan-gillard&quot;&gt;&lt;img src=&quot;https://github.com/jordan-gillard.png&quot; width=&quot;60px&quot; alt=&quot;Jordan Gillard&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/smangels&quot;&gt;&lt;img src=&quot;https://github.com/smangels.png&quot; width=&quot;60px&quot; alt=&quot;Sebastian&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/amslezak&quot;&gt;&lt;img src=&quot;https://github.com/amslezak.png&quot; width=&quot;60px&quot; alt=&quot;Andy Slezak&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/cfurrow&quot;&gt;&lt;img src=&quot;https://github.com/cfurrow.png&quot; width=&quot;60px&quot; alt=&quot;Carl Furrow&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mkock&quot;&gt;&lt;img src=&quot;https://github.com/mkock.png&quot; width=&quot;60px&quot; alt=&quot;Martin Kock&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jessealama&quot;&gt;&lt;img src=&quot;https://github.com/jessealama.png&quot; width=&quot;60px&quot; alt=&quot;Jesse Alama&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/danielkokott&quot;&gt;&lt;img src=&quot;https://github.com/danielkokott.png&quot; width=&quot;60px&quot; alt=&quot;Daniel Kokott&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/heijmans&quot;&gt;&lt;img src=&quot;https://github.com/heijmans.png&quot; width=&quot;60px&quot; alt=&quot;Jan Heijmans&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/knowald&quot;&gt;&lt;img src=&quot;https://github.com/knowald.png&quot; width=&quot;60px&quot; alt=&quot;Kevin Nowald&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/omarluq&quot;&gt;&lt;img src=&quot;https://github.com/omarluq.png&quot; width=&quot;60px&quot; alt=&quot;Omar Alani&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ethanjli&quot;&gt;&lt;img src=&quot;https://github.com/ethanjli.png&quot; width=&quot;60px&quot; alt=&quot;Ethan Li&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/phubaba&quot;&gt;&lt;img src=&quot;https://github.com/phubaba.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/logichaos&quot;&gt;&lt;img src=&quot;https://github.com/logichaos.png&quot; width=&quot;60px&quot; alt=&quot;Maxi&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/neunkasulle&quot;&gt;&lt;img src=&quot;https://github.com/neunkasulle.png&quot; width=&quot;60px&quot; alt=&quot;Jan Zenkner&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/RVxLab&quot;&gt;&lt;img src=&quot;https://github.com/RVxLab.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/FrederickGeek8&quot;&gt;&lt;img src=&quot;https://github.com/FrederickGeek8.png&quot; width=&quot;60px&quot; alt=&quot;Frederick Morlock&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ezdac&quot;&gt;&lt;img src=&quot;https://github.com/ezdac.png&quot; width=&quot;60px&quot; alt=&quot;Maximilian Langenfeld&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/lppassos&quot;&gt;&lt;img src=&quot;https://github.com/lppassos.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/neilcode&quot;&gt;&lt;img src=&quot;https://github.com/neilcode.png&quot; width=&quot;60px&quot; alt=&quot;Neil Lambert&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dhh&quot;&gt;&lt;img src=&quot;https://github.com/dhh.png&quot; width=&quot;60px&quot; alt=&quot;David Heinemeier Hansson&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ethanfischer&quot;&gt;&lt;img src=&quot;https://github.com/ethanfischer.png&quot; width=&quot;60px&quot; alt=&quot;Ethan Fischer&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/poshboytl&quot;&gt;&lt;img src=&quot;https://github.com/poshboytl.png&quot; width=&quot;60px&quot; alt=&quot;Terry Tai&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/roesnera&quot;&gt;&lt;img src=&quot;https://github.com/roesnera.png&quot; width=&quot;60px&quot; alt=&quot;Adam Roesner&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/seven1m&quot;&gt;&lt;img src=&quot;https://github.com/seven1m.png&quot; width=&quot;60px&quot; alt=&quot;Tim Morgan&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/sgoridotla1&quot;&gt;&lt;img src=&quot;https://github.com/sgoridotla1.png&quot; width=&quot;60px&quot; alt=&quot;Max Shypulniak&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ADIX7&quot;&gt;&lt;img src=&quot;https://github.com/ADIX7.png&quot; width=&quot;60px&quot; alt=&quot;Kov√°cs √Åd√°m&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/slowdub&quot;&gt;&lt;img src=&quot;https://github.com/slowdub.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/serranomorante&quot;&gt;&lt;img src=&quot;https://github.com/serranomorante.png&quot; width=&quot;60px&quot; alt=&quot;Patricio Serrano&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/kiriDevs&quot;&gt;&lt;img src=&quot;https://github.com/kiriDevs.png&quot; width=&quot;60px&quot; alt=&quot;Kiri&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/bjornevik&quot;&gt;&lt;img src=&quot;https://github.com/bjornevik.png&quot; width=&quot;60px&quot; alt=&quot;John Even Bj√∏rnevik&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/moberst&quot;&gt;&lt;img src=&quot;https://github.com/moberst.png&quot; width=&quot;60px&quot; alt=&quot;Michael Oberst&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/adam-e-trepanier&quot;&gt;&lt;img src=&quot;https://github.com/adam-e-trepanier.png&quot; width=&quot;60px&quot; alt=&quot;Adam Trepanier&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/arkalon76&quot;&gt;&lt;img src=&quot;https://github.com/arkalon76.png&quot; width=&quot;60px&quot; alt=&quot;Kenth Fagerlund&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Djuuu&quot;&gt;&lt;img src=&quot;https://github.com/Djuuu.png&quot; width=&quot;60px&quot; alt=&quot;Julien Tardot&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/antikytheraton&quot;&gt;&lt;img src=&quot;https://github.com/antikytheraton.png&quot; width=&quot;60px&quot; alt=&quot;Aaron Arredondo&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ellord&quot;&gt;&lt;img src=&quot;https://github.com/ellord.png&quot; width=&quot;60px&quot; alt=&quot;Ellord Tayag&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/EdgarPost&quot;&gt;&lt;img src=&quot;https://github.com/EdgarPost.png&quot; width=&quot;60px&quot; alt=&quot;Edgar Post-Buijs&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/caillou&quot;&gt;&lt;img src=&quot;https://github.com/caillou.png&quot; width=&quot;60px&quot; alt=&quot;Pierre Spring&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mebezac&quot;&gt;&lt;img src=&quot;https://github.com/mebezac.png&quot; width=&quot;60px&quot; alt=&quot;Zac Clay&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Tom94&quot;&gt;&lt;img src=&quot;https://github.com/Tom94.png&quot; width=&quot;60px&quot; alt=&quot;Thomas M√ºller&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ccssmnn&quot;&gt;&lt;img src=&quot;https://github.com/ccssmnn.png&quot; width=&quot;60px&quot; alt=&quot;Carl Assmann&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ognevsd&quot;&gt;&lt;img src=&quot;https://github.com/ognevsd.png&quot; width=&quot;60px&quot; alt=&quot;Sergey Ognev&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/moodyhunter&quot;&gt;&lt;img src=&quot;https://github.com/moodyhunter.png&quot; width=&quot;60px&quot; alt=&quot;Moody Liu&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/code-hunger&quot;&gt;&lt;img src=&quot;https://github.com/code-hunger.png&quot; width=&quot;60px&quot; alt=&quot;Alex G&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/elithper&quot;&gt;&lt;img src=&quot;https://github.com/elithper.png&quot; width=&quot;60px&quot; alt=&quot;Michael Howard&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/LasseBloch&quot;&gt;&lt;img src=&quot;https://github.com/LasseBloch.png&quot; width=&quot;60px&quot; alt=&quot;Lasse Bloch Lauritsen&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/lmarburger&quot;&gt;&lt;img src=&quot;https://github.com/lmarburger.png&quot; width=&quot;60px&quot; alt=&quot;Larry Marburger&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dbrockman&quot;&gt;&lt;img src=&quot;https://github.com/dbrockman.png&quot; width=&quot;60px&quot; alt=&quot;David Brockman&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/slavshik&quot;&gt;&lt;img src=&quot;https://github.com/slavshik.png&quot; width=&quot;60px&quot; alt=&quot;Alexander Slavschik&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/aidalgol&quot;&gt;&lt;img src=&quot;https://github.com/aidalgol.png&quot; width=&quot;60px&quot; alt=&quot;Aidan Gauland&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mbienkowsk&quot;&gt;&lt;img src=&quot;https://github.com/mbienkowsk.png&quot; width=&quot;60px&quot; alt=&quot;Maksym Bie≈Ñkowski&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/joshuawootonn&quot;&gt;&lt;img src=&quot;https://github.com/joshuawootonn.png&quot; width=&quot;60px&quot; alt=&quot;Joshua Wootonn&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/I4nJ&quot;&gt;&lt;img src=&quot;https://github.com/I4nJ.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/gurbindersingh&quot;&gt;&lt;img src=&quot;https://github.com/gurbindersingh.png&quot; width=&quot;60px&quot; alt=&quot;Gurbinder Singh&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/sandviklee&quot;&gt;&lt;img src=&quot;https://github.com/sandviklee.png&quot; width=&quot;60px&quot; alt=&quot;Simon Sandvik Lee&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/glagnar&quot;&gt;&lt;img src=&quot;https://github.com/glagnar.png&quot; width=&quot;60px&quot; alt=&quot;Thomas Gilbert&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/skrzepto&quot;&gt;&lt;img src=&quot;https://github.com/skrzepto.png&quot; width=&quot;60px&quot; alt=&quot;Szymon Mucha&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/TimShilov&quot;&gt;&lt;img src=&quot;https://github.com/TimShilov.png&quot; width=&quot;60px&quot; alt=&quot;Tim Shilov&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/unnawut&quot;&gt;&lt;img src=&quot;https://github.com/unnawut.png&quot; width=&quot;60px&quot; alt=&quot;Unnawut Leepaisalsuwanna&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/wortmanb&quot;&gt;&lt;img src=&quot;https://github.com/wortmanb.png&quot; width=&quot;60px&quot; alt=&quot;Bret Wortman&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/DanielYang59&quot;&gt;&lt;img src=&quot;https://github.com/DanielYang59.png&quot; width=&quot;60px&quot; alt=&quot;Haoyu (Daniel) YANG Êù®Êµ©ÂÆá&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/andre-lameirinhas&quot;&gt;&lt;img src=&quot;https://github.com/andre-lameirinhas.png&quot; width=&quot;60px&quot; alt=&quot;Andr√© Lameirinhas&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/SVappsLAB&quot;&gt;&lt;img src=&quot;https://github.com/SVappsLAB.png&quot; width=&quot;60px&quot; alt=&quot;Scott Velez&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ooojustin&quot;&gt;&lt;img src=&quot;https://github.com/ooojustin.png&quot; width=&quot;60px&quot; alt=&quot;justin&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mayfieldiv&quot;&gt;&lt;img src=&quot;https://github.com/mayfieldiv.png&quot; width=&quot;60px&quot; alt=&quot;Mayfield&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/somaholiday&quot;&gt;&lt;img src=&quot;https://github.com/somaholiday.png&quot; width=&quot;60px&quot; alt=&quot;Soma Holiday&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/bizmythy&quot;&gt;&lt;img src=&quot;https://github.com/bizmythy.png&quot; width=&quot;60px&quot; alt=&quot;bizmyth&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dessalines&quot;&gt;&lt;img src=&quot;https://github.com/dessalines.png&quot; width=&quot;60px&quot; alt=&quot;Dessalines&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/KKodiac&quot;&gt;&lt;img src=&quot;https://github.com/KKodiac.png&quot; width=&quot;60px&quot; alt=&quot;Sean Hong(ÌôçÏÑ±ÎØº)&quot; /&gt;&lt;/a&gt;&lt;!-- sponsors --&gt;
&lt;/p&gt;

## Elevator Pitch

Rant time: You&#039;ve heard it before, git is _powerful_, but what good is that power when everything is so damn hard to do? Interactive rebasing requires you to edit a goddamn TODO file in your editor? _Are you kidding me?_ To stage part of a file you need to use a command line program to step through each hunk and if a hunk can&#039;t be split down any further but contains code you don&#039;t want to stage, you have to edit an arcane patch file _by hand_? _Are you KIDDING me?!_ Sometimes you get asked to stash your changes when switching branches only to realise that after you switch and unstash that there weren&#039;t even any conflicts and it would have been fine to just checkout the branch directly? _YOU HAVE GOT TO BE KIDDING ME!_

If you&#039;re a mere mortal like me and you&#039;re tired of hearing how powerful git is when in your daily life it&#039;s a powerful pain in your ass, lazygit might be for you.

## Table of contents

- [Sponsors](#sponsors)
- [Elevator Pitch](#elevator-pitch)
- [Table of contents](#table-of-contents)
- [Features](#features)
  - [Stage individual lines](#stage-individual-lines)
  - [Interactive Rebase](#interactive-rebase)
  - [Cherry-pick](#cherry-pick)
  - [Bisect](#bisect)
  - [Nuke the working tree](#nuke-the-working-tree)
  - [Amend an old commit](#amend-an-old-commit)
  - [Filter](#filter)
  - [Invoke a custom command](#invoke-a-custom-command)
  - [Worktrees](#worktrees)
  - [Rebase magic (custom patches)](#rebase-magic-custom-patches)
  - [Rebase from marked base commit](#rebase-from-marked-base-commit)
  - [Undo](#undo)
  - [Commit graph](#commit-graph)
  - [Compare two commits](#compare-two-commits)
- [Tutorials](#tutorials)
- [Installation](#installation)
  - [Binary Releases](#binary-releases)
  - [Dev container](#dev-container-feature)
  - [Homebrew](#homebrew)
  - [MacPorts](#macports)
  - [Void Linux](#void-linux)
  - [Scoop (Windows)](#scoop-windows)
  - [Arch Linux](#arch-linux)
  - [Fedora and RHEL](#fedora-and-rhel)
  - [Solus Linux](#solus-linux)
  - [Debian and Ubuntu](#debian-and-ubuntu)
  - [Funtoo Linux](#funtoo-linux)
  - [Gentoo Linux](#gentoo-linux)
  - [FreeBSD](#freebsd)
  - [Termux](#termux)
  - [Conda](#conda)
  - [Go](#go)
  - [Chocolatey (Windows)](#chocolatey-windows)
  - [Winget (Windows 10 1709 or later)](#winget-windows-10-1709-or-later)
  - [Manual](#manual)
- [Usage](#usage)
  - [Keybindings](#keybindings)
  - [Changing Directory On Exit](#changing-directory-on-exit)
  - [Undo/Redo](#undoredo)
- [Configuration](#configuration)
  - [Custom Pagers](#custom-pagers)
  - [Custom Commands](#custom-commands)
  - [Git flow support](#git-flow-support)
- [Contributing](#contributing)
  - [Debugging Locally](#debugging-locally)
- [Donate](#donate)
- [FAQ](#faq)
  - [What do the commit colors represent?](#what-do-the-commit-colors-represent)
- [Shameless Plug](#shameless-plug)
- [Alternatives](#alternatives)

Lazygit is not my fulltime job but it is a hefty part time job so if you want to support the project please consider [sponsoring me](https://github.com/sponsors/jesseduffield)

## Features

### Stage individual lines

Press space on the selected line to stage it, or press `v` to start selecting a range of lines. You can also press `a` to select the entirety of the current hunk.

![stage_lines](../assets/demo/stage_lines-compressed.gif)

### Interactive Rebase

Press `i` to start an interactive rebase. Then squash (`s`), fixup (`f`), drop (`d`), edit (`e`), move up (`ctrl+k`) or move down (`ctrl+j`) any of TODO commits, before continuing the rebase by bringing up the rebase options menu with `m` and then selecting `continue`.

You can also perform any these actions as a once-off (e.g. pressing `s` on a commit to squash it) without explicitly starting a rebase.

This demo also uses shift+down to select a range of commits to move and fixup.

![interactive_rebase](../assets/demo/interactive_rebase-compressed.gif)

### Cherry-pick

Press `shift+c` on a commit to copy it and press `shift+v` to paste (cherry-pick) it.

![cherry_pick](../assets/demo/cherry_pick-compressed.gif)

### Bisect

Press `b` in the commits view to mark a commit as good/bad in order to begin a git bisect.

![bisect](../assets/demo/bisect-compressed.gif)

### Nuke the working tree

For when you really want to just get rid of anything that shows up when you run `git status` (and yes that includes dirty submodules) [kidpix style](https://www.youtube.com/watch?v=N4E2B_k2Bss), press `shift+d` to bring up the reset options menu and then select the &#039;nuke&#039; option.

![Nuke working tree](../assets/demo/nuke_working_tree-compressed.gif)

### Amend an old commit

Pressing `shift+a` on any commit will amend that commit with the currently staged changes (running an interactive rebase in the background).

![amend_old_commit](../assets/demo/amend_old_commit-compressed.gif)

### Filter

You can filter a view with `/`. Here we filter down our branches view and then hit `enter` to view its commits.

![filter](../assets/demo/filter-compressed.gif)

### Invoke a custom command

Lazygit has a very flexible [custom command

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[OpenCSGs/csghub-server]]></title>
            <link>https://github.com/OpenCSGs/csghub-server</link>
            <guid>https://github.com/OpenCSGs/csghub-server</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[csghub-server is the backend server for CSGHub which helps user to manage datasets, modes, and also run Model Inference, Finetune and Application Spaces.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenCSGs/csghub-server">OpenCSGs/csghub-server</a></h1>
            <p>csghub-server is the backend server for CSGHub which helps user to manage datasets, modes, and also run Model Inference, Finetune and Application Spaces.</p>
            <p>Language: Go</p>
            <p>Stars: 1,199</p>
            <p>Forks: 259</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>*[English](README_en.md) ‚àô [ÁÆÄ‰Ωì‰∏≠Êñá](README_cn.md) ‚àô [Êó•Êú¨Ë™û](README_ja.md)*

`CSGHub Server` is a part of the open source and reliable large model assets management platform - [CSGHub](https://github.com/OpenCSGs/CSGHub/). It focuses on management of models„ÄÅdatasets and other LLM assets through REST API„ÄÇ

## Key FeaturesÔºö
- Creation and Management of users and orgnizations
- Auto-tagging of model and dataset labels
- Search for users, organizations, models, and data
- Online preview of dataset files, like `.parquet` file
- Content moderation for both text and image 
- Download of individual files, including LFS files
- Tracking of model and dataset activity data, such as downloads and likes volume

## Demo
In order to help users to quickly understand the features and usage of CSGHub, we have recorded a demo video. You can watch this video to get a quick understanding of the main features and operation procedures of this program.
- CSGHub Demo video is as blewÔºåyou can also check it at [YouTube](https://www.youtube.com/watch?v=SFDISpqowXs) or [Bilibili](https://www.bilibili.com/video/BV12T4y187bv/)
&lt;video width=&quot;658&quot; height=&quot;432&quot; src=&quot;https://github-production-user-asset-6210df.s3.amazonaws.com/3232817/296556812-205d07f2-de9d-4a7f-b3f5-83514a71453e.mp4&quot;&gt;&lt;/video&gt;

Please visit the [OpenCSG website](https://portal.opencsg.com/models) to experience the powerful management features. 

## Quick Start
&gt; System resource requirements: 4c CPU/8GB memory

Please install Docker yourself. This project has been tested in Ubuntu22 environment.

You can quickly deploy the localized `CSGHub Server` service through docker-compose:
```shell
# The API token should be at least 128 characters long, and HTTP requests to csghub-server require the API token to be sent as a Bearer token for authentication.
export STARHUB_SERVER_API_TOKEN=&lt;API token&gt;
mkdir -m 777 gitea minio_data
curl -L https://raw.githubusercontent.com/OpenCSGs/csghub-server/main/docker-compose.yml -o docker-compose.yml
docker-compose -f docker-compose.yml up -d
```

## Start CSGHub Server Services Locally

CSGHub supports TOML format for config files. When starting any service from the command line, you can specify the config file with the `--config` option:

```
go run cmd/csghub-server/main.go start server --config local.toml
go run cmd/csghub-server/main.go deploy runner --config local.toml
...
```

We provide an [example config file](common/config/config.toml.example), you can rename it, modify as needed and use. All available configurations are defined in [this Go file](common/config/config.go). The TOML configuration uses snake_case naming convention, and names automatically map to corresponding struct field names.

## Technical Architecture
&lt;div align=center&gt;
  &lt;img src=&quot;docs/csghub_server-arch.png&quot; alt=&quot;csghub-server architecture&quot; width=&quot;800px&quot;&gt;
&lt;/div&gt;

### Extensible and customizable

- Supports different git servers, such as Gitea, GitLab, etc.
- Supports flexible configuration of the LFS storage system, and you can choose to use local or any third-party cloud storage service that is compatible with the S3 protocol.
- Enable content moderation on demand, and choose any third-party content moderation service.

## Roadmap
- [x] Support more Git Servers: Currently supports Gitea, and plans to support mainstream Git repositories in the future.
- [x] Git LFS: Git LFS supports large files, and supports Git command operations and online download through the Web UI. 
- [x] DataSet online viewer: Data set preview, supports the Top20/TopN loading preview of LFS format data sets. 
- [x] Model/Dataset AutoTag: Supports custom metadata and automatic extraction of model/dataset tags. 
- [x] S3 Protocol Support: Supports S3 (MinIO) storage protocol, providing higher reliability and storage cost-effectiveness.
- [ ] Model format convert: Conversion of mainstream model formats.
- [x] Model oneclick deploy: Supports integration with OpenCSG llm-inference, one-click to start model inference.

## License
We use the Apache 2.0 license, the content of which is detailed in the `LICENSE` file.

## Contributing
If you wish to contribute, please follow the [Contribution Guidelines](docs/en/contributing.md). We are very excited about your contributions!

Before you begin development, we highly recommend checking out our [Backend Developer Guides](contribute/), which provide helpful information to ensure a smooth development process.

## Acknowledgments
This project is based on open source projects such as Gin, DuckDB, minio, and Gitea. We would like to express our sincere gratitude to them for their open source contributions!

### CONTACT WITH US
If you meet any problem during usage, you can contact with us by any following way:
1. initiate an issue in github
2. join our WeChat group by scaning wechat helper qrcode
3. join our offical discord channel: [OpenCSG Discord Channel](https://discord.gg/bXnu4C9BkR)
4. join our slack workspace:[OpenCSG Slack Channel](https://join.slack.com/t/opencsghq/shared_invite/zt-2fmtem7hs-s_RmMeoOIoF1qzslql2q~A)
&lt;div style=&quot;display:inline-block&quot;&gt;
&lt;img src=&quot;https://github.com/OpenCSGs/csghub/blob/main/docs/images/wechat-assistant-new.png&quot; width=&#039;200&#039;&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;img src=&quot;https://github.com/OpenCSGs/csghub/blob/main/docs/images/discord-qrcode.png&quot; width=&#039;200&#039;&gt;
  &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;img src=&quot;https://github.com/OpenCSGs/csghub/blob/main/docs/images/slack-qrcode.png&quot; width=&#039;200&#039;&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[actions/actions-runner-controller]]></title>
            <link>https://github.com/actions/actions-runner-controller</link>
            <guid>https://github.com/actions/actions-runner-controller</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[Kubernetes controller for GitHub Actions self-hosted runners]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/actions/actions-runner-controller">actions/actions-runner-controller</a></h1>
            <p>Kubernetes controller for GitHub Actions self-hosted runners</p>
            <p>Language: Go</p>
            <p>Stars: 5,796</p>
            <p>Forks: 1,335</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># Actions Runner Controller (ARC)

[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/6061/badge)](https://bestpractices.coreinfrastructure.org/projects/6061)
[![awesome-runners](https://img.shields.io/badge/listed%20on-awesome--runners-blue.svg)](https://github.com/jonico/awesome-runners)
[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/actions-runner-controller)](https://artifacthub.io/packages/search?repo=actions-runner-controller)

## About

Actions Runner Controller (ARC) is a Kubernetes operator that orchestrates and scales self-hosted runners for GitHub Actions.

With ARC, you can create runner scale sets that automatically scale based on the number of workflows running in your repository, organization, or enterprise. Because controlled runners can be ephemeral and based on containers, new runner instances can scale up or down rapidly and cleanly. For more information about autoscaling, see [&quot;Autoscaling with self-hosted runners.&quot;](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners/autoscaling-with-self-hosted-runners)

You can set up ARC on Kubernetes using Helm, then create and run a workflow that uses runner scale sets. For more information about runner scale sets, see [&quot;Deploying runner scale sets with Actions Runner Controller.&quot;](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/deploying-runner-scale-sets-with-actions-runner-controller#runner-scale-set)

## People

Actions Runner Controller (ARC) is an open-source project currently developed and maintained in collaboration with the GitHub Actions team, external maintainers @mumoshu and @toast-gear, various [contributors](https://github.com/actions/actions-runner-controller/graphs/contributors), and the [awesome community](https://github.com/actions/actions-runner-controller/discussions).

If you think the project is awesome and is adding value to your business, please consider directly sponsoring [community maintainers](https://github.com/sponsors/actions-runner-controller) and individual contributors via GitHub Sponsors.

If you are already the employer of one of the contributors, sponsoring via GitHub Sponsors might not be an option. Just support them by other means!

See [the sponsorship dashboard](https://github.com/sponsors/actions-runner-controller) for the former and the current sponsors.

## Getting Started

To give ARC a try with just a handful of commands, please refer to the [Quickstart guide](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller).

For an overview of ARC, please refer to [About ARC](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/about-actions-runner-controller).

With the introduction of [autoscaling runner scale sets](https://github.com/actions/actions-runner-controller/discussions/2775), the existing [autoscaling modes](./docs/automatically-scaling-runners.md) are now legacy. The legacy modes have certain use cases and will continue to be maintained by the community only.

For further information on what is supported by GitHub and what&#039;s managed by the community, please refer to [this announcement discussion.](https://github.com/actions/actions-runner-controller/discussions/2775)

### Documentation

ARC documentation is available on [docs.github.com](https://docs.github.com/en/actions/hosting-your-own-runners/managing-self-hosted-runners-with-actions-runner-controller/quickstart-for-actions-runner-controller).

### Legacy documentation

The following documentation is for the legacy autoscaling modes that continue to be maintained by the community:

- [Quickstart guide](/docs/quickstart.md)
- [About ARC](/docs/about-arc.md)
- [Installing ARC](/docs/installing-arc.md)
- [Authenticating to the GitHub API](/docs/authenticating-to-the-github-api.md)
- [Deploying ARC runners](/docs/deploying-arc-runners.md)
- [Adding ARC runners to a repository, organization, or enterprise](/docs/choosing-runner-destination.md)
- [Automatically scaling runners](/docs/automatically-scaling-runners.md)
- [Using custom volumes](/docs/using-custom-volumes.md)
- [Using ARC runners in a workflow](/docs/using-arc-runners-in-a-workflow.md)
- [Managing access with runner groups](/docs/managing-access-with-runner-groups.md)
- [Configuring Windows runners](/docs/configuring-windows-runners.md)
- [Using ARC across organizations](/docs/using-arc-across-organizations.md)
- [Using entrypoint features](/docs/using-entrypoint-features.md)
- [Deploying alternative runners](/docs/deploying-alternative-runners.md)
- [Monitoring and troubleshooting](/docs/monitoring-and-troubleshooting.md)

## Contributing

We welcome contributions from the community. For more details on contributing to the project (including requirements), please refer to &quot;[Getting Started with Contributing](https://github.com/actions/actions-runner-controller/blob/master/CONTRIBUTING.md).&quot;

## Troubleshooting

We are very happy to help you with any issues you have. Please refer to the &quot;[Troubleshooting](https://github.com/actions/actions-runner-controller/blob/master/TROUBLESHOOTING.md)&quot; section for common issues.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mayswind/ezbookkeeping]]></title>
            <link>https://github.com/mayswind/ezbookkeeping</link>
            <guid>https://github.com/mayswind/ezbookkeeping</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[A lightweight, self-hosted personal finance app with a user-friendly interface and powerful bookkeeping features.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mayswind/ezbookkeeping">mayswind/ezbookkeeping</a></h1>
            <p>A lightweight, self-hosted personal finance app with a user-friendly interface and powerful bookkeeping features.</p>
            <p>Language: Go</p>
            <p>Stars: 2,810</p>
            <p>Forks: 284</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre># ezBookkeeping
[![License](https://img.shields.io/badge/license-MIT-green.svg)](https://github.com/mayswind/ezbookkeeping/blob/master/LICENSE)
[![Go Report](https://goreportcard.com/badge/github.com/mayswind/ezbookkeeping)](https://goreportcard.com/report/github.com/mayswind/ezbookkeeping)
[![Latest Release](https://img.shields.io/github/release/mayswind/ezbookkeeping.svg?style=flat)](https://github.com/mayswind/ezbookkeeping/releases)
[![Latest Build](https://img.shields.io/github/actions/workflow/status/mayswind/ezbookkeeping/build-snapshot.yml?branch=main)](https://github.com/mayswind/ezbookkeeping/actions)
[![Latest Docker Image Size](https://img.shields.io/docker/image-size/mayswind/ezbookkeeping.svg?style=flat)](https://hub.docker.com/r/mayswind/ezbookkeeping)
[![Docker Pulls](https://img.shields.io/docker/pulls/mayswind/ezbookkeeping)](https://hub.docker.com/r/mayswind/ezbookkeeping)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/mayswind/ezbookkeeping)

[![Recommend By HelloGitHub](https://api.hellogithub.com/v1/widgets/recommend.svg?rid=ded5af09da574ec1811ddb154f1b2093&amp;claim_uid=LT7EZxeBukCnh0K)](https://hellogithub.com/en/repository/mayswind/ezbookkeeping)
[![Trending](https://trendshift.io/api/badge/repositories/12917)](https://trendshift.io/repositories/12917)

## Introduction
ezBookkeeping is a lightweight, self-hosted personal finance app with a user-friendly interface and powerful bookkeeping features. It&#039;s easy to deploy, and you can start it with just one single Docker command. Designed to be resource-efficient and highly scalable, it can run smoothly on devices as small as a Raspberry Pi, or scale up to NAS, MicroServers, and even large cluster environments.

ezBookkeeping offers tailored interfaces for both mobile and desktop devices. With support for PWA (Progressive Web Apps), you can even [add it to your mobile home screen](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/mobile/add_to_home_screen.gif) and use it like a native app.

Live Demo: [https://ezbookkeeping-demo.mayswind.net](https://ezbookkeeping-demo.mayswind.net)

## Features
- **Open Source &amp; Self-Hosted**
    - Built for privacy and control
- **Lightweight &amp; Fast**
    - Optimized for performance, runs smoothly even on low-resource environments
- **Easy Installation**
    - Docker-ready
    - Supports SQLite, MySQL, PostgreSQL
    - Cross-platform (Windows, macOS, Linux)
    - Works on x86, amd64, ARM architectures
- **User-Friendly Interface**
    - UI optimized for both mobile and desktop
    - PWA support for native-like mobile experience
    - Dark mode
- **AI-Powered Features**
    - Receipt image recognition
    - Supports MCP (Model Context Protocol) for AI integration
- **Powerful Bookkeeping**
    - Two-level accounts and categories
    - Attach images to transactions
    - Location tracking with maps
    - Recurring transactions
    - Advanced filtering, search, visualization, and analysis
- **Localization &amp; Globalization**
    - Multi-language and multi-currency support
    - Automatic exchange rates
    - Multi-timezone awareness
    - Custom formats for dates, numbers, and currencies
- **Security**
    - Two-factor authentication (2FA)
    - Login rate limiting
    - Application lock (PIN code / WebAuthn)
- **Data Import/Export**
    - Supports CSV, OFX, QFX, QIF, IIF, Camt.053, MT940, GnuCash, Firefly III, Beancount, and more

## Screenshots
### Desktop Version
[![ezBookkeeping](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/desktop/en.png)](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/desktop/en.png)

### Mobile Version
[![ezBookkeeping](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/mobile/en.png)](https://raw.githubusercontent.com/wiki/mayswind/ezbookkeeping/img/mobile/en.png)

## Installation
### Run with Docker
Visit [Docker Hub](https://hub.docker.com/r/mayswind/ezbookkeeping) to see all images and tags.

**Latest Release:**

    $ docker run -p8080:8080 mayswind/ezbookkeeping

**Latest Daily Build:**

    $ docker run -p8080:8080 mayswind/ezbookkeeping:latest-snapshot

### Install from Binary
Download the latest release: [https://github.com/mayswind/ezbookkeeping/releases](https://github.com/mayswind/ezbookkeeping/releases)

**Linux / macOS**

    $ ./ezbookkeeping server run

**Windows**

    &gt; .\ezbookkeeping.exe server run

By default, ezBookkeeping listens on port 8080. You can then visit `http://{YOUR_HOST_ADDRESS}:8080/` .

### Build from Source
Make sure you have [Golang](https://golang.org/), [GCC](https://gcc.gnu.org/), [Node.js](https://nodejs.org/) and [NPM](https://www.npmjs.com/) installed. Then download the source code, and follow these steps:

**Linux / macOS**

    $ ./build.sh package -o ezbookkeeping.tar.gz

All the files will be packaged in `ezbookkeeping.tar.gz`.

**Windows**

    &gt; .\build.bat package -o ezbookkeeping.zip

or

    PS &gt; .\build.ps1 package -Output ezbookkeeping.zip

All the files will be packaged in `ezbookkeeping.zip`.

You can also build a Docker image. Make sure you have [Docker](https://www.docker.com/) installed, then follow these steps:

**Linux**

    $ ./build.sh docker

## Contributing
We welcome contributions of all kinds.

Found a bug? [Submit an issue](https://github.com/mayswind/ezbookkeeping/issues)

Want to contribute code? Feel free to fork and send a pull request.

Contributions of all kinds ‚Äî bug reports, feature suggestions, documentation improvements, or code ‚Äî are highly appreciated.

Check out our [Contributor Graph](https://github.com/mayswind/ezbookkeeping/graphs/contributors) to see the amazing people who&#039;ve already helped.

## Translating
Help make ezBookkeeping accessible to users around the world. If you want to contribute a translation, please refer to our [translation guide](https://ezbookkeeping.mayswind.net/translating).

Currently available translations:

| Tag | Language | Contributors |
| --- | --- | --- |
| de | Deutsch | [@chrgm](https://github.com/chrgm) |
| en | English | / |
| es | Espa√±ol | [@Miguelonlonlon](https://github.com/Miguelonlonlon) |
| fr | Fran√ßais | [@brieucdlf](https://github.com/brieucdlf) |
| it | Italiano | [@waron97](https://github.com/waron97) |
| ja | Êó•Êú¨Ë™û | [@tkymmm](https://github.com/tkymmm) |
| ko | ÌïúÍµ≠Ïñ¥ | [@overworks](https://github.com/overworks) |
| nl | Nederlands | [@automagic](https://github.com/automagics) |
| pt-BR | Portugu√™s (Brasil) | [@thecodergus](https://github.com/thecodergus) |
| ru | –†—É—Å—Å–∫–∏–π | [@artegoser](https://github.com/artegoser) |
| th | ‡πÑ‡∏ó‡∏¢ | [@natthavat28](https://github.com/natthavat28) |
| uk | –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ | [@nktlitvinenko](https://github.com/nktlitvinenko) |
| vi | Ti·∫øng Vi·ªát | [@f97](https://github.com/f97) |
| zh-Hans | ‰∏≠Êñá (ÁÆÄ‰Ωì) | / |
| zh-Hant | ‰∏≠Êñá (ÁπÅÈ´î) | / |

Don&#039;t see your language? Help us add it.

## Documentation
1. [English](https://ezbookkeeping.mayswind.net)
1. [‰∏≠Êñá (ÁÆÄ‰Ωì)](https://ezbookkeeping.mayswind.net/zh_Hans)

## License
[MIT](https://github.com/mayswind/ezbookkeeping/blob/master/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[github/github-mcp-server]]></title>
            <link>https://github.com/github/github-mcp-server</link>
            <guid>https://github.com/github/github-mcp-server</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[GitHub's official MCP Server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/github-mcp-server">github/github-mcp-server</a></h1>
            <p>GitHub's official MCP Server</p>
            <p>Language: Go</p>
            <p>Stars: 24,248</p>
            <p>Forks: 2,955</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre># GitHub MCP Server

The GitHub MCP Server connects AI tools directly to GitHub&#039;s platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code files, manage issues and PRs, analyze code, and automate workflows. All through natural language interactions.

### Use Cases

- Repository Management: Browse and query code, search files, analyze commits, and understand project structure across any repository you have access to.
- Issue &amp; PR Automation: Create, update, and manage issues and pull requests. Let AI help triage bugs, review code changes, and maintain project boards.
- CI/CD &amp; Workflow Intelligence: Monitor GitHub Actions workflow runs, analyze build failures, manage releases, and get insights into your development pipeline.
- Code Analysis: Examine security findings, review Dependabot alerts, understand code patterns, and get comprehensive insights into your codebase.
- Team Collaboration: Access discussions, manage notifications, analyze team activity, and streamline processes for your team.

Built for developers who want to connect their AI tools to GitHub context and capabilities, from simple natural language queries to complex multi-step agent workflows.

---

## Remote GitHub MCP Server

[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D&amp;quality=insiders)

The remote GitHub MCP Server is hosted by GitHub and provides the easiest method for getting up and running. If your MCP host does not support remote MCP servers, don&#039;t worry! You can use the [local version of the GitHub MCP Server](https://github.com/github/github-mcp-server?tab=readme-ov-file#local-github-mcp-server) instead.

### Prerequisites

1. A compatible MCP host with remote server support (VS Code 1.101+, Claude Desktop, Cursor, Windsurf, etc.)
2. Any applicable [policies enabled](https://github.com/github/github-mcp-server/blob/main/docs/policies-and-governance.md)

### Install in VS Code

For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start. Make sure you&#039;re using [VS Code 1.101](https://code.visualstudio.com/updates/v1_101) or [later](https://code.visualstudio.com/updates) for remote MCP and OAuth support.

Alternatively, to manually configure VS Code, choose the appropriate JSON block from the examples below and add it to your host configuration:

&lt;table&gt;
&lt;tr&gt;&lt;th&gt;Using OAuth&lt;/th&gt;&lt;th&gt;Using a GitHub PAT&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th align=left colspan=2&gt;VS Code (version 1.101 or greater)&lt;/th&gt;&lt;/tr&gt;
&lt;tr valign=top&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;
    }
  }
}
```

&lt;/td&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer ${input:github_mcp_pat}&quot;
      }
    }
  },
  &quot;inputs&quot;: [
    {
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;id&quot;: &quot;github_mcp_pat&quot;,
      &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
      &quot;password&quot;: true
    }
  ]
}
```

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

### Install in other MCP hosts
- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot
- **[Claude Applications](/docs/installation-guides/install-claude.md)** - Installation guide for Claude Web, Claude Desktop and Claude Code CLI
- **[Cursor](/docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE
- **[Windsurf](/docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE

&gt; **Note:** Each MCP host application needs to configure a GitHub App or OAuth App to support remote access via OAuth. Any host application that supports remote MCP servers should support the remote GitHub server with PAT authentication. Configuration details and support levels vary by host. Make sure to refer to the host application&#039;s documentation for more info.

### Configuration

#### Toolset configuration

See [Remote Server Documentation](docs/remote-server.md) for full details on remote server configuration, toolsets, headers, and advanced usage. This file provides comprehensive instructions and examples for connecting, customizing, and installing the remote GitHub MCP Server in VS Code and other MCP hosts.

When no toolsets are specified, [default toolsets](#default-toolset) are used.

#### Enterprise Cloud with data residency (ghe.com)

GitHub Enterprise Cloud can also make use of the remote server.

Example for `https://octocorp.ghe.com`:
```
{
    ...
    &quot;proxima-github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://copilot-api.octocorp.ghe.com/mcp&quot;,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer ${input:github_mcp_pat}&quot;
      }
    },
    ...
}
```

GitHub Enterprise Server does not support remote server hosting. Please refer to [GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)](#github-enterprise-server-and-enterprise-cloud-with-data-residency-ghecom) from the local server configuration.

---

## Local GitHub MCP Server

[![Install with Docker in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D) [![Install with Docker in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D&amp;quality=insiders)

### Prerequisites

1. To run the server in a container, you will need to have [Docker](https://www.docker.com/) installed.
2. Once Docker is installed, you will also need to ensure Docker is running. The image is public; if you get errors on pull, you may have an expired token and need to `docker logout ghcr.io`.
3. Lastly you will need to [Create a GitHub Personal Access Token](https://github.com/settings/personal-access-tokens/new).
The MCP server can use many of the GitHub APIs, so enable the permissions that you feel comfortable granting your AI tools (to learn more about access tokens, please check out the [documentation](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)).

&lt;details&gt;&lt;summary&gt;&lt;b&gt;Handling PATs Securely&lt;/b&gt;&lt;/summary&gt;

### Environment Variables (Recommended)
To keep your GitHub PAT secure and reusable across different MCP hosts:

1. **Store your PAT in environment variables**
   ```bash
   export GITHUB_PAT=your_token_here
   ```
   Or create a `.env` file:
   ```env
   GITHUB_PAT=your_token_here
   ```

2. **Protect your `.env` file**
   ```bash
   # Add to .gitignore to prevent accidental commits
   echo &quot;.env&quot; &gt;&gt; .gitignore
   ```

3. **Reference the token in configurations**
   ```bash
   # CLI usage
   claude mcp update github -e GITHUB_PERSONAL_ACCESS_TOKEN=$GITHUB_PAT

   # In config files (where supported)
   &quot;env&quot;: {
     &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;$GITHUB_PAT&quot;
   }
   ```

&gt; **Note**: Environment variable support varies by host app and IDE. Some applications (like Windsurf) require hardcoded tokens in config files.

### Token Security Best Practices

- **Minimum scopes**: Only grant necessary permissions
  - `repo` - Repository operations
  - `read:packages` - Docker image access
  - `read:org` - Organization team access
- **Separate tokens**: Use different PATs for different projects/environments
- **Regular rotation**: Update tokens periodically
- **Never commit**: Keep tokens out of version control
- **File permissions**: Restrict access to config files containing tokens
  ```bash
  chmod 600 ~/.your-app/config.json
  ```

&lt;/details&gt;

### GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)

The flag `--gh-host` and the environment variable `GITHUB_HOST` can be used to set
the hostname for GitHub Enterprise Server or GitHub Enterprise Cloud with data residency.

- For GitHub Enterprise Server, prefix the hostname with the `https://` URI scheme, as it otherwise defaults to `http://`, which GitHub Enterprise Server does not support.
- For GitHub Enterprise Cloud with data residency, use `https://YOURSUBDOMAIN.ghe.com` as the hostname.
``` json
&quot;github&quot;: {
    &quot;command&quot;: &quot;docker&quot;,
    &quot;args&quot;: [
    &quot;run&quot;,
    &quot;-i&quot;,
    &quot;--rm&quot;,
    &quot;-e&quot;,
    &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
    &quot;-e&quot;,
    &quot;GITHUB_HOST&quot;,
    &quot;ghcr.io/github/github-mcp-server&quot;
    ],
    &quot;env&quot;: {
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;,
        &quot;GITHUB_HOST&quot;: &quot;https://&lt;your GHES or ghe.com domain name&gt;&quot;
    }
}
```

## Installation

### Install in GitHub Copilot on VS Code

For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start.

More about using MCP server tools in VS Code&#039;s [agent mode documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers).

Install in GitHub Copilot on other IDEs (JetBrains, Visual Studio, Eclipse, etc.)

Add the following JSON block to your IDE&#039;s MCP settings.

```json
{
  &quot;mcp&quot;: {
    &quot;inputs&quot;: [
      {
        &quot;type&quot;: &quot;promptString&quot;,
        &quot;id&quot;: &quot;github_token&quot;,
        &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
        &quot;password&quot;: true
      }
    ],
    &quot;servers&quot;: {
      &quot;github&quot;: {
        &quot;command&quot;: &quot;docker&quot;,
        &quot;args&quot;: [
          &quot;run&quot;,
          &quot;-i&quot;,
          &quot;--rm&quot;,
          &quot;-e&quot;,
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
          &quot;ghcr.io/github/github-mcp-server&quot;
        ],
        &quot;env&quot;: {
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;
        }
      }
    }
  }
}
```

Optionally, you can add a similar example (i.e. without the mcp key) to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with other host applications that accept the same format.

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Example JSON block without the MCP key included&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;

```json
{
  &quot;inputs&quot;: [
    {
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;id&quot;: &quot;github_token&quot;,
      &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
      &quot;password&quot;: true
    }
  ],
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;-e&quot;,
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
        &quot;ghcr.io/github/github-mcp-server&quot;
      ],
      &quot;env&quot;: {
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;
      }
    }
  }
}
```

&lt;/details&gt;

### Install in Other MCP Hosts

For other MCP host applications, please refer to our installation guides:

- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot
- **[Claude Code &amp; Claude Desktop](docs/installation-guides/install-claude.md)** - Installation guide for Claude Code and Claude Desktop
- **[Cursor](docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE
- **[Google Gemini CLI](docs/installation-guides/install-gemini-cli.md)** - Installation guide for Google Gemini CLI
- **[Windsurf](docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE

For a complete overview of all installation options, see our **[Installation Guides Index](docs/installation-guides)**.

&gt; **Note:** Any host application that supports local MCP servers should be able to access the local GitHub MCP server. However, the specific configuration process, syntax and stability of the integration will vary by host application. While many may follow a similar format to the examples above, this is not guaranteed. Please refer to your host application&#039;s documentation for the correct MCP configuration syntax and setup process.

### Build from source

If you don&#039;t have Docker, you can use `go build` to build the binary in the
`cmd/github-mcp-server` directory, and use the `github-mcp-server stdio` command with the `GITHUB_PERSONAL_ACCESS_TOKEN` environment variable set to your token. To specify the output location of the build, use the `-o` flag. You should configure your server to use the built executable as its `command`. For example:

```JSON
{
  &quot;mcp&quot;: {
    &quot;servers&quot;: {
      &quot;github&quot;: {
        &quot;command&quot;: &quot;/path/to/github-mcp-server&quot;,
        &quot;args&quot;: [&quot;stdio&quot;],
        &quot;env&quot;: {
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;&lt;YOUR_TOKEN&gt;&quot;
        }
      }
    }
  }
}
```

## Tool Configuration

The GitHub MCP Server supports enabling or disabling specific groups of functionalities via the `--toolsets` flag. This allows you to control which GitHub API capabilities are available to your AI tools. Enabling only the toolsets that you need can help the LLM with tool choice and reduce the context size.

_Toolsets are not limited to Tools. Relevant MCP Resources and Prompts are also included where applicable._

When no toolsets are specified, [default toolsets](#default-toolset) are used.

#### Specifying Toolsets

To specify toolsets you want available to the LLM, you can pass an allow-list in two ways:

1. **Using Command Line Argument**:

   ```bash
   github-mcp-server --toolsets repos,issues,pull_requests,actions,code_security
   ```

2. **Using Environment Variable**:
   ```bash
   GITHUB_TOOLSETS=&quot;repos,issues,pull_requests,actions,code_security&quot; ./github-mcp-server
   ```

The environment variable `GITHUB_TOOLSETS` takes precedence over the command line argument if both are provided.

### Using Toolsets With Docker

When using Docker, you can pass the toolsets as environment variables:

```bash
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&lt;your-token&gt; \
  -e GITHUB_TOOLSETS=&quot;repos,issues,pull_requests,actions,code_security,experiments&quot; \
  ghcr.io/github/github-mcp-server
```

### Special toolsets

#### &quot;all&quot; toolset

The special toolset `all` can be provided to enable all available toolsets regardless of any other configuration:

```bash
./github-mcp-server --toolsets all
```

Or using the environment variable:

```bash
GITHUB_TOOLSETS=&quot;all&quot; ./github-mcp-server
```

#### &quot;default&quot; toolset
The default toolset `default` is the configuration that gets passed to the server if no toolsets are specified.

The default configuration is:
- context
- repos
- issues
- pull_requests
- users

To keep the default configuration and add additional toolsets:

```bash
GITHUB_TOOLSETS=&quot;default,stargazers&quot; ./github-mcp-server
```

### Available Toolsets

The following sets of tools are available:

&lt;!-- START AUTOMATED TOOLSETS --&gt;
| Toolset                 | Description                                                   |
| ----------------------- | ------------------------------------------------------------- |
| `context`               | **Strongly recommended**: Tools that provide context about the current user and GitHub context you are operating in |
| `actions` | GitHub Actions workflows and CI/CD operations |
| `code_security` | Code security related tools, such as GitHub Code Scanning |
| `dependabot` | Dependabot tools |
| `discussions` | GitHub Discussions related tools |
| `experiments` | Experimental features that are not considered stable yet |
| `gists` | GitHub Gist related tools |
| `issues` | GitHub Issues related tools |
| `labels` | GitHub Labels related tools |
| `notifications` | GitHub Notifications related tools |
| `orgs` | GitHub Organization related tools |
| `projects` | GitHub Projects related tools |
| `pull_requests` | GitHub Pull Request related tools |
| `repos` | GitHub Repository related tools |
| `secret_protection` | Secret protection related tools, such as GitHub Secret Scanning |
| `security_advisories` | Security advisories related tools |
| `stargazers` | GitHub Stargazers related tools |
| `users` | GitHub User related tools |
&lt;!-- END AUTOMATED TOOLSETS --&gt;

### Additional Toolsets in Remote Github MCP Server

| Toolset                 | Description                                                   |
| ----------------------- | ------------------------------------------------------------- |
| `copilot` | Copilot related tools (e.g. Copilot Coding Agent) |
| `copilot_spaces` | Copilot Spaces related tools |
| `github_support_docs_search` | Search docs to answer GitHub product and support questions |

## Tools

&lt;!-- START AUTOMATED TOOLS --&gt;
&lt;details&gt;

&lt;summary&gt;Actions&lt;/summary&gt;

- **cancel_workflow_run** - Cancel workflow run
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **delete_workflow_run_logs** - Delete workflow logs
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **download_workflow_run_artifact** - Download workflow artifact
  - `artifact_id`: The unique identifier of the artifact (number, required)
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)

- **get_job_logs** - Get job logs
  - `failed_only`: When true, gets logs for all failed jobs in run_id (boolean, optional)
  - `job_id`: The unique identifier of the workflow job (required for single job logs) (number, optional)
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `return_content`: Returns actual log content instead of URLs (boolean, optional)
  - `run_id`: Workflow run ID (required when using failed_only) (number, optional)
  - `tail_lines`: Number of lines to return from the end of the log (number, optional)

- **get_workflow_run** - Get workflow run
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **get_workflow_run_logs** - Get workflow run logs
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **get_workflow_run_usage** - Get workflow usage
  - `owner`: Repository owner (string, required)
  - `repo`: Repository name (string, required)
  - `run_id`: The unique identifier of the workflow run (number, required)

- **list_workflow_jobs** - List workflow jobs
  - `filter`

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[argoproj/argo-cd]]></title>
            <link>https://github.com/argoproj/argo-cd</link>
            <guid>https://github.com/argoproj/argo-cd</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[Declarative Continuous Deployment for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/argoproj/argo-cd">argoproj/argo-cd</a></h1>
            <p>Declarative Continuous Deployment for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 21,133</p>
            <p>Forks: 6,517</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>**Releases:**
[![Release Version](https://img.shields.io/github/v/release/argoproj/argo-cd?label=argo-cd)](https://github.com/argoproj/argo-cd/releases/latest)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-cd)](https://artifacthub.io/packages/helm/argo/argo-cd)
[![SLSA 3](https://slsa.dev/images/gh-badge-level3.svg)](https://slsa.dev)

**Code:** 
[![Integration tests](https://github.com/argoproj/argo-cd/workflows/Integration%20tests/badge.svg?branch=master)](https://github.com/argoproj/argo-cd/actions?query=workflow%3A%22Integration+tests%22)
[![codecov](https://codecov.io/gh/argoproj/argo-cd/branch/master/graph/badge.svg)](https://codecov.io/gh/argoproj/argo-cd)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4486/badge)](https://bestpractices.coreinfrastructure.org/projects/4486)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-cd/badge)](https://scorecard.dev/viewer/?uri=github.com/argoproj/argo-cd)

**Social:**
[![Twitter Follow](https://img.shields.io/twitter/follow/argoproj?style=social)](https://twitter.com/argoproj)
[![Slack](https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack)](https://argoproj.github.io/community/join-slack)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin)](https://www.linkedin.com/company/argoproj/)

# Argo CD - Declarative Continuous Delivery for Kubernetes

## What is Argo CD?

Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.

![Argo CD UI](docs/assets/argocd-ui.gif)

[![Argo CD Demo](https://img.youtube.com/vi/0WAm0y2vLIo/0.jpg)](https://youtu.be/0WAm0y2vLIo)

## Why Argo CD?

1. Application definitions, configurations, and environments should be declarative and version controlled.
1. Application deployment and lifecycle management should be automated, auditable, and easy to understand.

## Who uses Argo CD?

[Official Argo CD user list](USERS.md)

## Documentation

To learn more about Argo CD [go to the complete documentation](https://argo-cd.readthedocs.io/).
Check live demo at https://cd.apps.argoproj.io/.

## Community

### Contribution, Discussion and Support

 You can reach the Argo CD community and developers via the following channels:

* Q &amp; A : [Github Discussions](https://github.com/argoproj/argo-cd/discussions)
* Chat : [The #argo-cd Slack channel](https://argoproj.github.io/community/join-slack)
* Contributors Office Hours: [Every Thursday](https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com) | [Agenda](https://docs.google.com/document/d/1xkoFkVviB70YBzSEa4bDnu-rUZ1sIFtwKKG1Uw8XsY8)
* User Community meeting: [First Wednesday of the month](https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com) | [Agenda](https://docs.google.com/document/d/1ttgw98MO45Dq7ZUHpIiOIEfbyeitKHNfMjbY5dLLMKQ)


Participation in the Argo CD project is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md)


### Blogs and Presentations

1. [Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo](https://github.com/terrytangyuan/awesome-argo)
1. [Unveil the Secret Ingredients of Continuous Delivery at Enterprise Scale with Argo CD](https://akuity.io/blog/secret-ingredients-of-continuous-delivery-at-enterprise-scale-with-argocd/)
1. [GitOps Without Pipelines With ArgoCD Image Updater](https://youtu.be/avPUQin9kzU)
1. [Combining Argo CD (GitOps), Crossplane (Control Plane), And KubeVela (OAM)](https://youtu.be/eEcgn_gU3SM)
1. [How to Apply GitOps to Everything - Combining Argo CD and Crossplane](https://youtu.be/yrj4lmScKHQ)
1. [Couchbase - How To Run a Database Cluster in Kubernetes Using Argo CD](https://youtu.be/nkPoPaVzExY)
1. [Automation of Everything - How To Combine Argo Events, Workflows &amp; Pipelines, CD, and Rollouts](https://youtu.be/XNXJtxkUKeY)
1. [Environments Based On Pull Requests (PRs): Using Argo CD To Apply GitOps Principles On Previews](https://youtu.be/cpAaI8p4R60)
1. [Argo CD: Applying GitOps Principles To Manage Production Environment In Kubernetes](https://youtu.be/vpWQeoaiRM4)
1. [Creating Temporary Preview Environments Based On Pull Requests With Argo CD And Codefresh](https://codefresh.io/continuous-deployment/creating-temporary-preview-environments-based-pull-requests-argo-cd-codefresh/)
1. [Tutorial: Everything You Need To Become A GitOps Ninja](https://www.youtube.com/watch?v=r50tRQjisxw) 90m tutorial on GitOps and Argo CD.
1. [Comparison of Argo CD, Spinnaker, Jenkins X, and Tekton](https://www.inovex.de/blog/spinnaker-vs-argo-cd-vs-tekton-vs-jenkins-x/)
1. [Simplify and Automate Deployments Using GitOps with IBM Multicloud Manager 3.1.2](https://www.ibm.com/cloud/blog/simplify-and-automate-deployments-using-gitops-with-ibm-multicloud-manager-3-1-2)
1. [GitOps for Kubeflow using Argo CD](https://v0-6.kubeflow.org/docs/use-cases/gitops-for-kubeflow/)
1. [GitOps Toolsets on Kubernetes with CircleCI and Argo CD](https://www.digitalocean.com/community/tutorials/webinar-series-gitops-tool-sets-on-kubernetes-with-circleci-and-argo-cd)
1. [CI/CD in Light Speed with K8s and Argo CD](https://www.youtube.com/watch?v=OdzH82VpMwI&amp;feature=youtu.be)
1. [Machine Learning as Code](https://www.youtube.com/watch?v=VXrGp5er1ZE&amp;t=0s&amp;index=135&amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU). Among other things, describes how Kubeflow uses Argo CD to implement GitOPs for ML
1. [Argo CD - GitOps Continuous Delivery for Kubernetes](https://www.youtube.com/watch?v=aWDIQMbp1cc&amp;feature=youtu.be&amp;t=1m4s)
1. [Introduction to Argo CD : Kubernetes DevOps CI/CD](https://www.youtube.com/watch?v=2WSJF7d8dUg&amp;feature=youtu.be)
1. [GitOps Deployment and Kubernetes - using Argo CD](https://medium.com/riskified-technology/gitops-deployment-and-kubernetes-f1ab289efa4b)
1. [Deploy Argo CD with Ingress and TLS in Three Steps: No YAML Yak Shaving Required](https://itnext.io/deploy-argo-cd-with-ingress-and-tls-in-three-steps-no-yaml-yak-shaving-required-bc536d401491)
1. [GitOps Continuous Delivery with Argo and Codefresh](https://codefresh.io/events/cncf-member-webinar-gitops-continuous-delivery-argo-codefresh/)
1. [Stay up to date with Argo CD and Renovate](https://mjpitz.com/blog/2020/12/03/renovate-your-gitops/)
1. [Setting up Argo CD with Helm](https://www.arthurkoziel.com/setting-up-argocd-with-helm/)
1. [Applied GitOps with Argo CD](https://thenewstack.io/applied-gitops-with-argocd/)
1. [Solving configuration drift using GitOps with Argo CD](https://www.cncf.io/blog/2020/12/17/solving-configuration-drift-using-gitops-with-argo-cd/)
1. [Decentralized GitOps over environments](https://blogs.sap.com/2021/05/06/decentralized-gitops-over-environments/)
1. [Getting Started with ArgoCD for GitOps Deployments](https://youtu.be/AvLuplh1skA)
1. [Using Argo CD &amp; Datree for Stable Kubernetes CI/CD Deployments](https://youtu.be/17894DTru2Y)
1. [How to create Argo CD Applications Automatically using ApplicationSet? &quot;Automation of GitOps&quot;](https://amralaayassen.medium.com/how-to-create-argocd-applications-automatically-using-applicationset-automation-of-the-gitops-59455eaf4f72)
1. [Progressive Delivery with Service Mesh ‚Äì Argo Rollouts with Istio](https://www.cncf.io/blog/2022/12/16/progressive-delivery-with-service-mesh-argo-rollouts-with-istio/)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vmware-tanzu/velero]]></title>
            <link>https://github.com/vmware-tanzu/velero</link>
            <guid>https://github.com/vmware-tanzu/velero</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[Backup and migrate Kubernetes applications and their persistent volumes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vmware-tanzu/velero">vmware-tanzu/velero</a></h1>
            <p>Backup and migrate Kubernetes applications and their persistent volumes</p>
            <p>Language: Go</p>
            <p>Stars: 9,567</p>
            <p>Forks: 1,486</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>![100]

[![Build Status][1]][2] [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3811/badge)](https://bestpractices.coreinfrastructure.org/projects/3811)
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/vmware-tanzu/velero)

## Overview

Velero (formerly Heptio Ark) gives you tools to back up and restore your Kubernetes cluster resources and persistent volumes. You can run Velero with a public cloud platform or on-premises. 

Velero lets you:

* Take backups of your cluster and restore in case of loss.
* Migrate cluster resources to other clusters.
* Replicate your production cluster to development and testing clusters.

Velero consists of:

* A server that runs on your cluster
* A command-line client that runs locally

## Documentation

[The documentation][29] provides a getting started guide and information about building from source, architecture, extending Velero and more.

Please use the version selector at the top of the site to ensure you are using the appropriate documentation for your version of Velero.

## Troubleshooting

If you encounter issues, review the [troubleshooting docs][30], [file an issue][4], or talk to us on the [#velero channel][25] on the Kubernetes Slack server.

## Contributing

If you are ready to jump in and test, add code, or help with documentation, follow the instructions on our [Start contributing][31] documentation for guidance on how to setup Velero for development.

## Changelog

See [the list of releases][6] to find out about feature changes.

### Velero compatibility matrix

The following is a list of the supported Kubernetes versions for each Velero version.

| Velero version | Expected Kubernetes version compatibility | Tested on Kubernetes version        |
|----------------|-------------------------------------------|-------------------------------------|
| 1.17           | 1.18-latest                               | 1.31.7, 1.32.3, 1.33.1, and 1.34.0          |
| 1.16           | 1.18-latest                               | 1.31.4, 1.32.3, and 1.33.0          |
| 1.15           | 1.18-latest                               | 1.28.8, 1.29.8, 1.30.4 and 1.31.1   |
| 1.14           | 1.18-latest                               | 1.27.9, 1.28.9, and 1.29.4          |
| 1.13           | 1.18-latest                               | 1.26.5, 1.27.3, 1.27.8, and 1.28.3  |
| 1.12           | 1.18-latest                               | 1.25.7, 1.26.5, 1.26.7, and 1.27.3  |
| 1.11           | 1.18-latest                               | 1.23.10, 1.24.9, 1.25.5, and 1.26.1 |

Velero supports IPv4, IPv6, and dual stack environments. Support for this was tested against Velero v1.8.

The Velero maintainers are continuously working to expand testing coverage, but are not able to test every combination of Velero and supported Kubernetes versions for each Velero release. The table above is meant to track the current testing coverage and the expected supported Kubernetes versions for each Velero version.

If you are interested in using a different version of Kubernetes with a given Velero version, we&#039;d recommend that you perform testing before installing or upgrading your environment. For full information around capabilities within a release, also see the Velero [release notes](https://github.com/vmware-tanzu/velero/releases) or Kubernetes [release notes](https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG). See the Velero [support page](https://velero.io/docs/latest/support-process/) for information about supported versions of Velero.

For each release, Velero maintainers run the test to ensure the upgrade path from n-2 minor release.  For example, before the release of v1.10.x, the test will verify that the backup created by v1.9.x and v1.8.x can be restored using the build to be tagged as v1.10.x.

[1]: https://github.com/vmware-tanzu/velero/workflows/Main%20CI/badge.svg
[2]: https://github.com/vmware-tanzu/velero/actions?query=workflow%3A&quot;Main+CI&quot;
[4]: https://github.com/vmware-tanzu/velero/issues
[6]: https://github.com/vmware-tanzu/velero/releases
[9]: https://kubernetes.io/docs/setup/
[10]: https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-with-homebrew-on-macos
[11]: https://kubernetes.io/docs/tasks/tools/install-kubectl/#tabset-1
[12]: https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/dns/README.md
[14]: https://github.com/kubernetes/kubernetes
[24]: https://groups.google.com/forum/#!forum/projectvelero
[25]: https://kubernetes.slack.com/messages/velero
[29]: https://velero.io/docs/
[30]: https://velero.io/docs/troubleshooting
[31]: https://velero.io/docs/start-contributing
[100]: https://velero.io/docs/main/img/velero.png
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[stretchr/testify]]></title>
            <link>https://github.com/stretchr/testify</link>
            <guid>https://github.com/stretchr/testify</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[A toolkit with common assertions and mocks that plays nicely with the standard library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stretchr/testify">stretchr/testify</a></h1>
            <p>A toolkit with common assertions and mocks that plays nicely with the standard library</p>
            <p>Language: Go</p>
            <p>Stars: 25,374</p>
            <p>Forks: 1,680</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>Testify - Thou Shalt Write Tests
================================

&gt; [!NOTE]
&gt; Testify is being maintained at v1, no breaking changes will be accepted in this repo.  
&gt; [See discussion about v2](https://github.com/stretchr/testify/discussions/1560).

[![Build Status](https://github.com/stretchr/testify/actions/workflows/main.yml/badge.svg?branch=master)](https://github.com/stretchr/testify/actions/workflows/main.yml) [![Go Report Card](https://goreportcard.com/badge/github.com/stretchr/testify)](https://goreportcard.com/report/github.com/stretchr/testify) [![PkgGoDev](https://pkg.go.dev/badge/github.com/stretchr/testify)](https://pkg.go.dev/github.com/stretchr/testify)

Go code (golang) set of packages that provide many tools for testifying that your code will behave as you intend.

Features include:

  * [Easy assertions](#assert-package)
  * [Mocking](#mock-package)
  * [Testing suite interfaces and functions](#suite-package)

Get started:

  * Install testify with [one line of code](#installation), or [update it with another](#staying-up-to-date)
  * For an introduction to writing test code in Go, see https://go.dev/doc/code#Testing
  * Check out the API Documentation https://pkg.go.dev/github.com/stretchr/testify
  * Use [testifylint](https://github.com/Antonboom/testifylint) (via [golangci-lint](https://golangci-lint.run/)) to avoid common mistakes
  * A little about [Test-Driven Development (TDD)](https://en.wikipedia.org/wiki/Test-driven_development)

[`assert`](https://pkg.go.dev/github.com/stretchr/testify/assert &quot;API documentation&quot;) package
-------------------------------------------------------------------------------------------

The `assert` package provides some helpful methods that allow you to write better test code in Go.

  * Prints friendly, easy to read failure descriptions
  * Allows for very readable code
  * Optionally annotate each assertion with a message

See it in action:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	// assert equality
	assert.Equal(t, 123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(t, 123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(t, object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(t, object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(t, &quot;Something&quot;, object.Value)
	}
}
```

  * Every assert func takes the `testing.T` object as the first argument.  This is how it writes the errors out through the normal `go test` capabilities.
  * Every assert func returns a bool indicating whether the assertion was successful or not, this is useful for if you want to go on making further assertions under certain conditions.

if you assert many times, use the below:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert := assert.New(t)

	// assert equality
	assert.Equal(123, 123, &quot;they should be equal&quot;)

	// assert inequality
	assert.NotEqual(123, 456, &quot;they should not be equal&quot;)

	// assert for nil (good for errors)
	assert.Nil(object)

	// assert for not nil (good when you expect something)
	if assert.NotNil(object) {
		// now we know that object isn&#039;t nil, we are safe to make
		// further assertions without causing any errors
		assert.Equal(&quot;Something&quot;, object.Value)
	}
}
```

[`require`](https://pkg.go.dev/github.com/stretchr/testify/require &quot;API documentation&quot;) package
---------------------------------------------------------------------------------------------

The `require` package provides same global functions as the `assert` package, but instead of returning a boolean result they terminate current test.
These functions must be called from the goroutine running the test or benchmark function, not from other goroutines created during the test.
Otherwise race conditions may occur.

See [t.FailNow](https://pkg.go.dev/testing#T.FailNow) for details.

[`mock`](https://pkg.go.dev/github.com/stretchr/testify/mock &quot;API documentation&quot;) package
----------------------------------------------------------------------------------------

The `mock` package provides a mechanism for easily writing mock objects that can be used in place of real objects when writing test code.

An example test function that tests a piece of code that relies on an external object `testObj`, can set up expectations (testify) and assert that they indeed happened:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/mock&quot;
)

/*
  Test objects
*/

// MyMockedObject is a mocked object that implements an interface
// that describes an object that the code I am testing relies on.
type MyMockedObject struct {
	mock.Mock
}

// DoSomething is a method on MyMockedObject that implements some interface
// and just records the activity, and returns what the Mock object tells it to.
//
// In the real object, this method would do something useful, but since this
// is a mocked object - we&#039;re just going to stub it out.
//
// NOTE: This method is not being tested here, code that uses this object is.
func (m *MyMockedObject) DoSomething(number int) (bool, error) {
	args := m.Called(number)
	return args.Bool(0), args.Error(1)
}

/*
  Actual test functions
*/

// TestSomething is an example of how to use our test object to
// make assertions about some target code we are testing.
func TestSomething(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations
	testObj.On(&quot;DoSomething&quot;, 123).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)
}

// TestSomethingWithPlaceholder is a second example of how to use our test object to
// make assertions about some target code we are testing.
// This time using a placeholder. Placeholders might be used when the
// data being passed in is normally dynamically generated and cannot be
// predicted beforehand (eg. containing hashes that are time sensitive)
func TestSomethingWithPlaceholder(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

}

// TestSomethingElse2 is a third example that shows how you can use
// the Unset method to cleanup handlers and then add new ones.
func TestSomethingElse2(t *testing.T) {
	// create an instance of our test object
	testObj := new(MyMockedObject)

	// set up expectations with a placeholder in the argument list
	mockCall := testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(true, nil)

	// call the code we are testing
	targetFuncThatDoesSomethingWithObj(testObj)

	// assert that the expectations were met
	testObj.AssertExpectations(t)

	// remove the handler now so we can add another one that takes precedence
	mockCall.Unset()

	// return false now instead of true
	testObj.On(&quot;DoSomething&quot;, mock.Anything).Return(false, nil)

	testObj.AssertExpectations(t)
}
```

For more information on how to write mock code, check out the [API documentation for the `mock` package](https://pkg.go.dev/github.com/stretchr/testify/mock).

You can use the [mockery tool](https://vektra.github.io/mockery/latest/) to autogenerate the mock code against an interface as well, making using mocks much quicker.

[`suite`](https://pkg.go.dev/github.com/stretchr/testify/suite &quot;API documentation&quot;) package
-----------------------------------------------------------------------------------------
&gt; [!WARNING]
&gt; The suite package does not support parallel tests. See [#934](https://github.com/stretchr/testify/issues/934).

The `suite` package provides functionality that you might be used to from more common object-oriented languages.  With it, you can build a testing suite as a struct, build setup/teardown methods and testing methods on your struct, and run them with &#039;go test&#039; as per normal.

An example suite is shown below:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including a T() method which
// returns the current testing context
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	assert.Equal(suite.T(), 5, suite.VariableThatShouldStartAtFive)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

For a more complete example, using all of the functionality provided by the suite package, look at our [example testing suite](https://github.com/stretchr/testify/blob/master/suite/suite_test.go)

For more information on writing suites, check out the [API documentation for the `suite` package](https://pkg.go.dev/github.com/stretchr/testify/suite).

`Suite` object has assertion methods:

```go
// Basic imports
import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/suite&quot;
)

// Define the suite, and absorb the built-in basic suite
// functionality from testify - including assertion methods.
type ExampleTestSuite struct {
	suite.Suite
	VariableThatShouldStartAtFive int
}

// Make sure that VariableThatShouldStartAtFive is set to five
// before each test
func (suite *ExampleTestSuite) SetupTest() {
	suite.VariableThatShouldStartAtFive = 5
}

// All methods that begin with &quot;Test&quot; are run as tests within a
// suite.
func (suite *ExampleTestSuite) TestExample() {
	suite.Equal(suite.VariableThatShouldStartAtFive, 5)
}

// In order for &#039;go test&#039; to run this suite, we need to create
// a normal test function and pass our suite to suite.Run
func TestExampleTestSuite(t *testing.T) {
	suite.Run(t, new(ExampleTestSuite))
}
```

------

Installation
============

To install Testify, use `go get`:

    go get github.com/stretchr/testify

This will then make the following packages available to you:

    github.com/stretchr/testify/assert
    github.com/stretchr/testify/require
    github.com/stretchr/testify/mock
    github.com/stretchr/testify/suite
    github.com/stretchr/testify/http (deprecated)

Import the `testify/assert` package into your code using this template:

```go
package yours

import (
	&quot;testing&quot;

	&quot;github.com/stretchr/testify/assert&quot;
)

func TestSomething(t *testing.T) {
	assert.True(t, true, &quot;True is true!&quot;)
}
```

------

Staying up to date
==================

To update Testify to the latest version, use `go get -u github.com/stretchr/testify`.

------

Supported go versions
==================

We currently support the most recent major Go versions from 1.19 onward.

------

Contributing
============

Please feel free to submit issues, fork the repository and send pull requests!

When submitting an issue, we ask that you please include a complete test function that demonstrates the issue. Extra credit for those using Testify to write the test code that demonstrates it.

Code generation is used. [Look for `Code generated with`](https://github.com/search?q=repo%3Astretchr%2Ftestify%20%22Code%20generated%20with%22&amp;type=code) at the top of some files. Run `go generate ./...` to update generated files.

We also chat on the [Gophers Slack](https://gophers.slack.com) group in the `#testify` and `#testify-dev` channels.

------

License
=======

This project is licensed under the terms of the MIT license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[VictoriaMetrics/VictoriaMetrics]]></title>
            <link>https://github.com/VictoriaMetrics/VictoriaMetrics</link>
            <guid>https://github.com/VictoriaMetrics/VictoriaMetrics</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[VictoriaMetrics: fast, cost-effective monitoring solution and time series database]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/VictoriaMetrics/VictoriaMetrics">VictoriaMetrics/VictoriaMetrics</a></h1>
            <p>VictoriaMetrics: fast, cost-effective monitoring solution and time series database</p>
            <p>Language: Go</p>
            <p>Stars: 15,307</p>
            <p>Forks: 1,489</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># VictoriaMetrics

[![Latest Release](https://img.shields.io/github/v/release/VictoriaMetrics/VictoriaMetrics?sort=semver&amp;label=&amp;filter=!*-victorialogs&amp;logo=github&amp;labelColor=gray&amp;color=gray&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Freleases%2Flatest)](https://github.com/VictoriaMetrics/VictoriaMetrics/releases)
![Docker Pulls](https://img.shields.io/docker/pulls/victoriametrics/victoria-metrics?label=&amp;logo=docker&amp;logoColor=white&amp;labelColor=2496ED&amp;color=2496ED&amp;link=https%3A%2F%2Fhub.docker.com%2Fr%2Fvictoriametrics%2Fvictoria-metrics)
[![Go Report](https://goreportcard.com/badge/github.com/VictoriaMetrics/VictoriaMetrics?link=https%3A%2F%2Fgoreportcard.com%2Freport%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics)](https://goreportcard.com/report/github.com/VictoriaMetrics/VictoriaMetrics)
[![Build Status](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml/badge.svg?branch=master&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Factions)](https://github.com/VictoriaMetrics/VictoriaMetrics/actions/workflows/build.yml)
[![codecov](https://codecov.io/gh/VictoriaMetrics/VictoriaMetrics/branch/master/graph/badge.svg?link=https%3A%2F%2Fcodecov.io%2Fgh%2FVictoriaMetrics%2FVictoriaMetrics)](https://app.codecov.io/gh/VictoriaMetrics/VictoriaMetrics)
[![License](https://img.shields.io/github/license/VictoriaMetrics/VictoriaMetrics?labelColor=green&amp;label=&amp;link=https%3A%2F%2Fgithub.com%2FVictoriaMetrics%2FVictoriaMetrics%2Fblob%2Fmaster%2FLICENSE)](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/LICENSE)
![Slack](https://img.shields.io/badge/Join-4A154B?logo=slack&amp;link=https%3A%2F%2Fslack.victoriametrics.com)
[![X](https://img.shields.io/twitter/follow/VictoriaMetrics?style=flat&amp;label=Follow&amp;color=black&amp;logo=x&amp;labelColor=black&amp;link=https%3A%2F%2Fx.com%2FVictoriaMetrics)](https://x.com/VictoriaMetrics/)
[![Reddit](https://img.shields.io/reddit/subreddit-subscribers/VictoriaMetrics?style=flat&amp;label=Join&amp;labelColor=red&amp;logoColor=white&amp;logo=reddit&amp;link=https%3A%2F%2Fwww.reddit.com%2Fr%2FVictoriaMetrics)](https://www.reddit.com/r/VictoriaMetrics/)

&lt;picture&gt;
  &lt;source srcset=&quot;docs/victoriametrics/logo_white.webp&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
  &lt;source srcset=&quot;docs/victoriametrics/logo.webp&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
  &lt;img src=&quot;docs/victoriametrics/logo.webp&quot; width=&quot;300&quot; alt=&quot;VictoriaMetrics logo&quot;&gt;
&lt;/picture&gt;

VictoriaMetrics is a fast, cost-saving, and scalable solution for monitoring and managing time series data. It delivers high performance and reliability, making it an ideal choice for businesses of all sizes.

Here are some resources and information about VictoriaMetrics:

- Documentation: [docs.victoriametrics.com](https://docs.victoriametrics.com)
- Case studies: [Grammarly, Roblox, Wix,...](https://docs.victoriametrics.com/victoriametrics/casestudies/).
- Available: [Binary releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest), docker images [Docker Hub](https://hub.docker.com/r/victoriametrics/victoria-metrics/) and [Quay](https://quay.io/repository/victoriametrics/victoria-metrics), [Source code](https://github.com/VictoriaMetrics/VictoriaMetrics)
- Deployment types: [Single-node version](https://docs.victoriametrics.com/), [Cluster version](https://docs.victoriametrics.com/victoriametrics/cluster-victoriametrics/), and [Enterprise version](https://docs.victoriametrics.com/victoriametrics/enterprise/)
- Changelog: [CHANGELOG](https://docs.victoriametrics.com/victoriametrics/changelog/), and [How to upgrade](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-upgrade-victoriametrics)
- Community: [Slack](https://slack.victoriametrics.com/), [X (Twitter)](https://x.com/VictoriaMetrics), [LinkedIn](https://www.linkedin.com/company/victoriametrics/), [YouTube](https://www.youtube.com/@VictoriaMetrics)

Yes, we open-source both the single-node VictoriaMetrics and the cluster version.

## Prominent features

VictoriaMetrics is optimized for timeseries data, even when old time series are constantly replaced by new ones at a high rate, it offers a lot of features:

* **Long-term storage for Prometheus** or as a drop-in replacement for Prometheus and Graphite in Grafana.
* **Powerful stream aggregation**: Can be used as a StatsD alternative.
* **Ideal for big data**: Works well with large amounts of time series data from APM, Kubernetes, IoT sensors, connected cars, industrial telemetry, financial data and various [Enterprise workloads](https://docs.victoriametrics.com/victoriametrics/enterprise/).
* **Query language**: Supports both PromQL and the more performant MetricsQL.
* **Easy to setup**: No dependencies, single [small binary](https://medium.com/@valyala/stripping-dependency-bloat-in-victoriametrics-docker-image-983fb5912b0d), configuration through command-line flags, but the default is also fine-tuned; backup and restore with [instant snapshots](https://medium.com/@valyala/how-victoriametrics-makes-instant-snapshots-for-multi-terabyte-time-series-data-e1f3fb0e0282).
* **Global query view**: Multiple Prometheus instances or any other data sources may ingest data into VictoriaMetrics and queried via a single query.
* **Various Protocols**: Support metric scraping, ingestion and backfilling in various protocol.
    * [Prometheus exporters](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-scrape-prometheus-exporters-such-as-node-exporter), [Prometheus remote write API](https://docs.victoriametrics.com/victoriametrics/integrations/prometheus/), [Prometheus exposition format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-prometheus-exposition-format).
    * [InfluxDB line protocol](https://docs.victoriametrics.com/victoriametrics/integrations/influxdb/) over HTTP, TCP and UDP.
    * [Graphite plaintext protocol](https://docs.victoriametrics.com/victoriametrics/integrations/graphite/#ingesting) with [tags](https://graphite.readthedocs.io/en/latest/tags.html#carbon).
    * [OpenTSDB put message](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-telnet).
    * [HTTP OpenTSDB /api/put requests](https://docs.victoriametrics.com/victoriametrics/integrations/opentsdb/#sending-data-via-http).
    * [JSON line format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-json-line-format).
    * [Arbitrary CSV data](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-csv-data).
    * [Native binary format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#how-to-import-data-in-native-format).
    * [DataDog agent or DogStatsD](https://docs.victoriametrics.com/victoriametrics/integrations/datadog/).
    * [NewRelic infrastructure agent](https://docs.victoriametrics.com/victoriametrics/integrations/newrelic/#sending-data-from-agent).
    * [OpenTelemetry metrics format](https://docs.victoriametrics.com/victoriametrics/single-server-victoriametrics/#sending-data-via-opentelemetry).
* **NFS-based storages**: Supports storing data on NFS-based storages such as Amazon EFS, Google Filestore.
* And many other features such as metrics relabeling, cardinality limiter, etc.

## Enterprise version

In addition, the Enterprise version includes extra features:

- **Anomaly detection**: Automation and simplification of your alerting rules, covering complex anomalies found in metrics data.
- **Backup automation**: Automates regular backup procedures.
- **Multiple retentions**: Reducing storage costs by specifying different retentions for different datasets.
- **Downsampling**: Reducing storage costs and increasing performance for queries over historical data.
- **Stable releases** with long-term support lines ([LTS](https://docs.victoriametrics.com/victoriametrics/lts-releases/)).
- **Comprehensive support**: First-class consulting, feature requests and technical support provided by the core VictoriaMetrics dev team.
- Many other features, which you can read about on [the Enterprise page](https://docs.victoriametrics.com/victoriametrics/enterprise/).

[Contact us](mailto:info@victoriametrics.com) if you need enterprise support for VictoriaMetrics. Or you can request a free trial license [here](https://victoriametrics.com/products/enterprise/trial/), downloaded Enterprise binaries are available at [Github Releases](https://github.com/VictoriaMetrics/VictoriaMetrics/releases/latest).

We strictly apply security measures in everything we do. VictoriaMetrics has achieved security certifications for Database Software Development and Software-Based Monitoring Services. See [Security page](https://victoriametrics.com/security/) for more details.

## Benchmarks 

Some good benchmarks VictoriaMetrics achieved:

* **Minimal memory footprint**: handling millions of unique timeseries with [10x less RAM](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) than InfluxDB, up to [7x less RAM](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) than Prometheus, Thanos or Cortex.
* **Highly scalable and performance** for [data ingestion](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and [querying](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4), [20x outperforms](https://medium.com/@valyala/insert-benchmarks-with-inch-influxdb-vs-victoriametrics-e31a41ae2893) InfluxDB and TimescaleDB.
* **High data compression**: [70x more data points](https://medium.com/@valyala/when-size-matters-benchmarking-victoriametrics-vs-timescale-and-influxdb-6035811952d4) may be stored into limited storage than TimescaleDB, [7x less storage](https://valyala.medium.com/prometheus-vs-victoriametrics-benchmark-on-node-exporter-metrics-4ca29c75590f) space is required than Prometheus, Thanos or Cortex.
* **Reducing storage costs**: [10x more effective](https://docs.victoriametrics.com/victoriametrics/casestudies/#grammarly) than Graphite according to the Grammarly case study.
* **A single-node VictoriaMetrics** can replace medium-sized clusters built with competing solutions such as Thanos, M3DB, Cortex, InfluxDB or TimescaleDB. See [VictoriaMetrics vs Thanos](https://medium.com/@valyala/comparing-thanos-to-victoriametrics-cluster-b193bea1683), [Measuring vertical scalability](https://medium.com/@valyala/measuring-vertical-scalability-for-time-series-databases-in-google-cloud-92550d78d8ae), [Remote write storage wars - PromCon 2019](https://promcon.io/2019-munich/talks/remote-write-storage-wars/).
* **Optimized for storage**: [Works well with high-latency IO](https://medium.com/@valyala/high-cardinality-tsdb-benchmarks-victoriametrics-vs-timescaledb-vs-influxdb-13e6ee64dd6b) and low IOPS (HDD and network storage in AWS, Google Cloud, Microsoft Azure, etc.).

## Community and contributions

Feel free asking any questions regarding VictoriaMetrics:

* [Slack Inviter](https://slack.victoriametrics.com/) and [Slack channel](https://victoriametrics.slack.com/)
* [X (Twitter)](https://x.com/VictoriaMetrics/)
* [Linkedin](https://www.linkedin.com/company/victoriametrics/)
* [Reddit](https://www.reddit.com/r/VictoriaMetrics/)
* [Telegram-en](https://t.me/VictoriaMetrics_en)
* [Telegram-ru](https://t.me/VictoriaMetrics_ru1)
* [Mastodon](https://mastodon.social/@victoriametrics/)

If you like VictoriaMetrics and want to contribute, then please [read these docs](https://docs.victoriametrics.com/victoriametrics/contributing/).

## VictoriaMetrics Logo

The provided [ZIP file](https://github.com/VictoriaMetrics/VictoriaMetrics/blob/master/VM_logo.zip) contains three folders with different logo orientations. Each folder includes the following file types:

* JPEG: Preview files
* PNG: Preview files with transparent background
* AI: Adobe Illustrator files

### VictoriaMetrics Logo Usage Guidelines

#### Font

* Font Used: Lato Black
* Download here: [Lato Font](https://fonts.google.com/specimen/Lato)

#### Color Palette

* Black [#000000](https://www.color-hex.com/color/000000)
* Purple [#4d0e82](https://www.color-hex.com/color/4d0e82)
* Orange [#ff2e00](https://www.color-hex.com/color/ff2e00)
* White [#ffffff](https://www.color-hex.com/color/ffffff)

### Logo Usage Rules

* Only use the Lato Black font as specified.
* Maintain sufficient clear space around the logo for visibility.
* Do not modify the spacing, alignment, or positioning of design elements.
* You may resize the logo as needed, but ensure all proportions remain intact.

Thank you for your cooperation!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[TykTechnologies/tyk]]></title>
            <link>https://github.com/TykTechnologies/tyk</link>
            <guid>https://github.com/TykTechnologies/tyk</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[Tyk Open Source API Gateway written in Go, supporting REST, GraphQL, TCP and gRPC protocols]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/TykTechnologies/tyk">TykTechnologies/tyk</a></h1>
            <p>Tyk Open Source API Gateway written in Go, supporting REST, GraphQL, TCP and gRPC protocols</p>
            <p>Language: Go</p>
            <p>Stars: 10,463</p>
            <p>Forks: 1,141</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>![tyk-github-header](https://github.com/TykTechnologies/tyk/assets/8012032/02b3fbae-80ed-4d1f-be87-016326f82ece)
![License: MPL 2.0](https://img.shields.io/badge/License-MPL%202.0-brightgreen.svg?style=flat_card&amp;color=8836FB)
[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2FTykTechnologies%2Ftyk.svg?type=shield)](https://app.fossa.io/projects/git%2Bgithub.com%2FTykTechnologies%2Ftyk?ref=badge_shield)

[![GitHub Latest Release](https://img.shields.io/github/v/release/TykTechnologies/tyk?color=8836FB)](https://github.com/TykTechnologies/tyk/releases)
[![GitHub Release Date](https://img.shields.io/github/release-date/TykTechnologies/tyk?color=8836FB)](https://github.com/TykTechnologies/tyk/releases)
[![Docker Pulls](https://img.shields.io/docker/pulls/tykio/tyk-gateway?color=8836FB)](https://hub.docker.com/r/tykio/tyk-gateway/)
[![GitHub Workflow Status (with event)](https://img.shields.io/github/actions/workflow/status/TykTechnologies/tyk/ci-tests.yml?label=Build%20%26%20Tests&amp;color=8438FA)](https://github.com/TykTechnologies/tyk/actions/workflows/ci-tests.yml)
[![Go Report Card](https://img.shields.io/badge/go%20report-A+-brightgreen.svg?color=8836FB)](https://goreportcard.com/report/github.com/TykTechnologies/tyk)

![GitHub commit activity](https://img.shields.io/github/commit-activity/m/TykTechnologies/tyk?color=8836FB)
[![GitHub Repo Stars](https://img.shields.io/github/stars/TykTechnologies/tyk?logoColor=8836FB)](https://github.com/TykTechnologies/tyk/stargazers)
[![GitHub Repo Forks](https://img.shields.io/github/forks/TykTechnologies/tyk.svg?logoColor=8836FB)](https://github.com/TykTechnologies/tyk/fork)
![X twitter Follow](https://img.shields.io/twitter/follow/tyk_io?logoColor=8836FB&amp;cacheSeconds=120)

---
[Documentation](https://tyk.io/docs/) | [Forum](https://community.tyk.io) | [Blog](https://tyk.io/blog/) | [About](https://tyk.io)


# Tyk API Gateway
**Tyk Gateway** is the cloud-native, open source, enterprise-ready API Gateway supporting REST, GraphQL, TCP and gRPC protocols.

Built from the ground up, as the [fastest API Gateway](https://tyk.io/performance-benchmarks/) on the planet since 2014.

_Tyk Gateway_ is provided ‚ÄòBatteries-included‚Äô, with no feature lockout. Enabling your organization to rate limit, auth, gather analytics, apply microservice patterns [and more](#open-source-api-gateway-features) with ease.

Tyk runs natively on _Kubernetes_, if you prefer, thanks to the _[Tyk Kubernetes Operator](https://github.com/TykTechnologies/tyk-operator)_

&lt;table&gt;
  &lt;tr&gt;
   &lt;td&gt;
     &lt;center&gt;
        &lt;a href=&quot;https://tyk.io/docs/deployment-and-operations/tyk-open-source-api-gateway/quick-start&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/TykTechnologies/tyk-docs/master/tyk-docs/assets/img/logos/tyk-logo-opensource.svg&quot; width=&quot;30%&quot;&gt;&lt;/a&gt;
     &lt;/center&gt;
     &lt;/br&gt;Everything you need to manage APIs. Follow the simple Get Started guide below üëá
   &lt;/td&gt;
   &lt;td&gt;
     &lt;center&gt;
       &lt;a href=&quot;https://tyk.io/docs/tyk-self-managed/install&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/TykTechnologies/tyk-docs/master/tyk-docs/assets/img/logos/tyk-logo-selfmanaged.png&quot; width=&quot;25%&quot;&gt;&lt;/a&gt;
     &lt;/center&gt;
     &lt;/br&gt;The Enterprise API Management platform: Management Control Plane, Dashboard GUI &amp; Developer Portal.
     &lt;/br&gt;&lt;a href=&quot;https://tyk.io/api-lifecycle-management/&quot;&gt;Install Tyk Self Managed&lt;/a&gt;
   &lt;/td&gt;
   &lt;td&gt;
     &lt;center&gt;
       &lt;a href=&quot;https://tyk.io/docs/tyk-cloud&quot;&gt; &lt;img src=&quot;https://raw.githubusercontent.com/TykTechnologies/tyk-docs/master/tyk-docs/assets/img/logos/tyk-logo-cloud.png&quot; width=&quot;20%&quot;&gt;&lt;/a&gt;
     &lt;/center&gt;
     &lt;/br&gt;The Enterprise API Management platform SaaS: Management Control Plane, Dashboard GUI &amp; Developer Portal.
     &lt;/br&gt;&lt;a href=&quot;https://tyk.io/docs/deployment-and-operations/tyk-cloud-platform/quick-start&quot;&gt;Deploy Tyk Cloud &lt;/a&gt;
   &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

---

## Get Started

We‚Äôll install Tyk, add auth, analytics, quotas and rate limiting to your API in under 5 minutes.

We recommend [Tyk Gateway Docker](https://github.com/TykTechnologies/tyk-gateway-docker#start-up-the-deployment) as the quickest way to get started now. Later, you can move to one of our other [supported distributions](https://tyk.io/docs/apim/open-source/installation/) if you prefer.

#### Step 1 - Clone the docker-compose repository
```console
git clone https://github.com/TykTechnologies/tyk-gateway-docker
```

#### Step 2 - Change to the new directory
```console
cd tyk-gateway-docker
```

#### Step 3 - Deploy Tyk Gateway and Redis
```console
docker-compose up
```

You can run this in detach mode using the `-d` flag: `docker-compose up -d`

**Congratulations, you‚Äôre done!**

Your Tyk Gateway is now configured and ready to use. Confirm this by checking against the ‚Äòhello‚Äô endpoint:
```console
curl localhost:8080/hello
```
Output:
```json
{&quot;status&quot;: &quot;pass&quot;, &quot;version&quot;: &quot;v3.2.1&quot;, &quot;description&quot;: &quot;Tyk GW&quot;}
```

Next, visit [adding your first API](https://tyk.io/docs/getting-started/create-api/) to Tyk and follow the Open Source instructions.

---

Other Installations are available:

1. [Docker](https://tyk.io/docs/tyk-oss/ce-docker/)
2. [Kubernetes-Native ](https://github.com/TykTechnologies/tyk-oss-k8s-deployment)
3. [Kubernetes-Helm](https://github.com/TykTechnologies/tyk-helm-chart#install-tyk-community-edition)
4. [Ansible](https://tyk.io/docs/tyk-oss/ce-ansible/)
5. [Red Hat](https://tyk.io/docs/tyk-oss/ce-redhat/)
6. [Ubuntu](https://tyk.io/docs/tyk-oss/ce-ubuntu/)
7. [CentOS](https://tyk.io/docs/tyk-oss/ce-centos/)
8. [Compile Tyk from Source](#compiling-tyk-gateway)


## Open Source API Gateway Features
Use any protocol: REST, SOAP, [GraphQL](https://tyk.io/docs/tyk-apis/tyk-gateway-api/api-definition-objects/graphql/), [gRPC](https://tyk.io/docs/key-concepts/grpc-proxy/), and [TCP](https://tyk.io/docs/key-concepts/tcp-proxy/).

Industry Standard Authentication: [OIDC](https://tyk.io/docs/advanced-configuration/integrate/api-auth-mode/open-id-connect/#setting-up-oidc), [JWT,](https://tyk.io/docs/tyk-apis/tyk-gateway-api/api-definition-objects/jwt/) [bearer Tokens](https://tyk.io/docs/basic-config-and-security/security/authentication-authorization/bearer-tokens/), [Basic Auth](https://tyk.io/docs/tyk-apis/tyk-dashboard-api/basic-authentication/), Client Certificates and more.

[Open API Standards:](https://tyk.io/docs/getting-started/using-oas-definitions/import-an-oas-api/) Import your Swagger and OpenAPI Documents (OAS 2.X and OAS 3.0.1) to scaffold APIs in Tyk.

[Ultra performant](https://tyk.io/performance-tuning-your-tyk-api-gateway/): Low latency, and thousands of rps with just a single CPU, horizontally and vertically scalable.

[Content mediation](https://tyk.io/docs/advanced-configuration/transform-traffic/): Transform all the things, from request or response headers to converting between SOAP and GraphQL.

[Extensible Plugin Architecture](https://tyk.io/docs/plugins/): Customize Tyk‚Äôs middleware chain by writing plugins in your language of choice - from Python to Javascript to Go, or any language which supports gRPC.

[Rate Limiting](https://tyk.io/docs/basic-config-and-security/control-limit-traffic/rate-limiting/#setting-rate-limits-in-the-tyk-community-edition-gateway-ce) &amp; Quotas: Protect your upstreams from becoming overloaded and/or apply limits for each consumer.

[API Versioning](https://tyk.io/docs/tyk-apis/tyk-gateway-api/api-definition-objects/versioning-endpoint/) - API Versions can be easily set and sunset (deprecated) at a specific time and date.

[Granular Access Control](https://tyk.io/docs/security/security-policies/secure-apis-method-path/) - Grant access to one or more APIs on a per version and operation basis.

[Blocklist](https://tyk.io/docs/advanced-configuration/transform-traffic/endpoint-designer/#blocklist)/[Allowlist](https://tyk.io/docs/advanced-configuration/transform-traffic/endpoint-designer/#allowlist)/[Ignore](https://tyk.io/docs/advanced-configuration/transform-traffic/endpoint-designer/#ignore) endpoint access - Enforce strict security models on a version-by-version basis to your access points.

Analytics logging - Record detailed usage data on who is using your APIs (raw data only)

[CORS](https://tyk.io/docs/tyk-apis/tyk-gateway-api/api-definition-objects/cors/) - Enable CORS for certain APIs so users can make browser-based requests

[Webhooks](https://tyk.io/docs/basic-config-and-security/report-monitor-trigger-events/webhooks/) - Trigger webhooks against events such as Quota Violations and Authentication failures

[IP AllowListing](https://tyk.io/docs/tyk-apis/tyk-gateway-api/api-definition-objects/ip-whitelisting/) - Block access to non-trusted IP addresses for more secure interactions

[Hitless reloads](https://tyk.io/docs/tyk-configuration-reference/hot-restart-tyk-gateway-process/) - Tyk configurations can be altered dynamically and the service restarted without affecting any active request

[Kubernetes native](https://tyk.io/docs/tyk-oss/ce-helm-chart/) declarative API: using Open Source [Tyk Operator](https://github.com/TykTechnologies/tyk-operator) (more info in OSS section)
![OpenSourceAPIGateway-Diagram](https://github.com/TykTechnologies/tyk/assets/8012032/7466be3f-fb81-4a95-88ac-3b09254c815d)

Tyk Technologies uses the same API Gateway for all it‚Äôs applications. Protecting, securing, and processing APIs for thousands of organizations and businesses around the world. Ideal for Open Banking, building software in the clouds as well as exposing APIs to teams, partners &amp; consumers.


## Tyk OSS Integrations

Tyk Technologies maintains other Open Source Software which can be used in conjunction with Tyk API Gateway:

[Tyk Pump](https://github.com/TykTechnologies/tyk-pump) - Pluggable analytics purger to move Analytics generated by your Tyk nodes to any back-end.

[Tyk Operator](https://github.com/TykTechnologies/tyk-operator) - Brings API Management capabilities to Kubernetes. Configure Ingress, APIs, Security Policies, Authentication, Authorization, Mediation and more - all using Custom Resources and Kubernetes Native primitives

[Tyk Identity Broker](https://github.com/TykTechnologies/tyk-identity-broker) - Tyk Authentication Proxy for third-party login

[Tyk Sync ](https://tyk.io/docs/tyk-sync/)- Command line tool and library to manage and synchronise a Tyk installation with your version control system (VCS).

[Tyk Mserv](https://github.com/TykTechnologies/mserv) - Asset Server and gRPC host


## Documentation
All the documentation for Tyk Gateway and other OSS-related topics can be found at [https://tyk.io/docs/tyk-oss-gateway/](https://tyk.io/docs/tyk-oss-gateway/)


## Community
* [Tyk Community Board](https://community.tyk.io/) - Technical support from the Tyk Community
* [Write a GitHub Issue](https://github.com/TykTechnologies/tyk/issues/new/choose) - Feature requests &amp; bug reports welcome
* [Technical blog](https://tyk.io/blog/) - Tyk announcements and updates
* [Newsletters ](https://pages.tyk.io/newsletter)- Subscribe to our GraphQL &amp; API newsletters
* If you are using Tyk give us a star ‚≠êÔ∏è

## Licensing

Tyk is dual-licensed:

1. Open Source License: The code in the root directory and all subdirectories except the &#039;ee&#039; folder is released under the MPL v2.0. Please see [LICENSE](https://github.com/TykTechnologies/tyk/blob/master/LICENSE) for the full version of the open source license.

2. Commercial License: The code in the &#039;ee&#039; folder is subject to a commercial license. For more information about obtaining a commercial license, please contact our sales team at sales@tyk.io.

## Compiling Tyk Gateway

Compile from Source
```console
git clone https://github.com/TykTechnologies/tyk
go build
```
Go version 1.22 is required to build `master`, the current development version. Tyk is officially supported on `Linux/amd64`, `Linux/i386` and `Linux/arm64`.

To run tests locally use the following command:
```console
go test ./...
```
Note that tests require Redis to be running on the same machine (default port).

To write your own test please use this guide [https://github.com/TykTechnologies/tyk/blob/master/TESTING.md](https://github.com/TykTechnologies/tyk/blob/master/TESTING.md)

## Contributing

For more information about contributing PRs and issues, see [CONTRIBUTING.md](https://github.com/TykTechnologies/tyk/blob/master/CONTRIBUTING.md).

‚Äî
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[1Panel-dev/1Panel]]></title>
            <link>https://github.com/1Panel-dev/1Panel</link>
            <guid>https://github.com/1Panel-dev/1Panel</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[üî• 1Panel provides an intuitive web interface and MCP Server to manage websites, files, containers, databases, and LLMs on a Linux server.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/1Panel-dev/1Panel">1Panel-dev/1Panel</a></h1>
            <p>üî• 1Panel provides an intuitive web interface and MCP Server to manage websites, files, containers, databases, and LLMs on a Linux server.</p>
            <p>Language: Go</p>
            <p>Stars: 31,905</p>
            <p>Forks: 2,819</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://1panel.pro&quot;&gt;&lt;img src=&quot;https://resource.1panel.pro/img/1panel-logo.png&quot; alt=&quot;1Panel&quot; width=&quot;300&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Top-Rated Web-based Linux Server Management Tool&lt;/b&gt;&lt;br&gt;Best VPS control panel&lt;br&gt;Êñ∞‰∏Ä‰ª£ÁöÑ Linux ÊúçÂä°Âô®ËøêÁª¥ÁÆ°ÁêÜÈù¢Êùø&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/2462&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/2462&quot; alt=&quot;1Panel-dev%2F1Panel | Trendshift&quot; style=&quot;width: 240px; height: auto;&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.gnu.org/licenses/gpl-3.0.html&quot;&gt;&lt;img src=&quot;https://shields.io/github/license/1Panel-dev/1Panel?color=%231890FF&quot; alt=&quot;License: GPL v3&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://app.codacy.com/gh/1Panel-dev/1Panel?utm_source=github.com&amp;utm_medium=referral&amp;utm_content=1Panel-dev/1Panel&amp;utm_campaign=Badge_Grade_Dashboard&quot;&gt;&lt;img src=&quot;https://app.codacy.com/project/badge/Grade/da67574fd82b473992781d1386b937ef&quot; alt=&quot;Codacy&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/bUpUqWqdRr&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1318846410149335080?logo=discord&amp;labelColor=%20%235462eb&amp;logoColor=%20%23f5f5f5&amp;color=%20%235462eb&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/1Panel-dev/1Panel/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/1Panel-dev/1Panel&quot; alt=&quot;GitHub release&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/1Panel-dev/1Panel&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/1Panel-dev/1Panel?color=%231890FF&amp;style=flat-square&quot; alt=&quot;Stars&quot;&gt;&lt;/a&gt;&lt;br&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;/README.md&quot;&gt;&lt;img alt=&quot;English&quot; src=&quot;https://img.shields.io/badge/English-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.zh-Hans.md&quot;&gt;&lt;img alt=&quot;‰∏≠Êñá(ÁÆÄ‰Ωì)&quot; src=&quot;https://img.shields.io/badge/‰∏≠Êñá(ÁÆÄ‰Ωì)-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.ja.md&quot;&gt;&lt;img alt=&quot;Êó•Êú¨Ë™û&quot; src=&quot;https://img.shields.io/badge/Êó•Êú¨Ë™û-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.pt-br.md&quot;&gt;&lt;img alt=&quot;Portugu√™s (Brasil)&quot; src=&quot;https://img.shields.io/badge/Portugu√™s (Brasil)-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.ar.md&quot;&gt;&lt;img alt=&quot;ÿßŸÑÿπÿ±ÿ®Ÿäÿ©&quot; src=&quot;https://img.shields.io/badge/ÿßŸÑÿπÿ±ÿ®Ÿäÿ©-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.de.md&quot;&gt;&lt;img alt=&quot;Deutsch&quot; src=&quot;https://img.shields.io/badge/Deutsch-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.es.md&quot;&gt;&lt;img alt=&quot;Espa√±ol&quot; src=&quot;https://img.shields.io/badge/Espa√±ol-d9d9d9&quot;&gt;&lt;/a&gt;&lt;br&gt;
  &lt;a href=&quot;/docs/README.fr.md&quot;&gt;&lt;img alt=&quot;fran√ßais&quot; src=&quot;https://img.shields.io/badge/fran√ßais-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.ko.md&quot;&gt;&lt;img alt=&quot;ÌïúÍµ≠Ïñ¥&quot; src=&quot;https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.id.md&quot;&gt;&lt;img alt=&quot;Bahasa Indonesia&quot; src=&quot;https://img.shields.io/badge/Bahasa Indonesia-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.zh-Hant.md&quot;&gt;&lt;img alt=&quot;‰∏≠Êñá(ÁπÅÈ´î)&quot; src=&quot;https://img.shields.io/badge/‰∏≠Êñá(ÁπÅÈ´î)-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.tr.md&quot;&gt;&lt;img alt=&quot;T√ºrk√ße&quot; src=&quot;https://img.shields.io/badge/T√ºrk√ße-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.ru.md&quot;&gt;&lt;img alt=&quot;–†—É—Å—Å–∫–∏–π&quot; src=&quot;https://img.shields.io/badge/%D0%A0%D1%83%D1%81%D1%81%D0%BA%D0%B8%D0%B9-d9d9d9&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;/docs/README.ms.md&quot;&gt;&lt;img alt=&quot;Bahasa Melayu&quot; src=&quot;https://img.shields.io/badge/Bahasa Melayu-d9d9d9&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

------------------------------

1Panel is an open-source, modern web-based control panel for Linux server management.

- **Efficient Management**: Through a user-friendly web graphical interface, 1Panel enables users to effortlessly manage their Linux servers. Key features include host monitoring, file management, database administration, container management, LLMs management.
- **Rapid Website Deployment**: With deep integration of the popular open-source website building software WordPress, 1Panel streamlines the process of domain binding and SSL certificate configuration, all achievable with just one click.
- **Application Store**: 1Panel curates a wide range of high-quality open-source tools and applications, facilitating easy installation and updates for its users.
- **Security and Reliability**: By leveraging containerization and secure application deployment practices, 1Panel minimizes vulnerability exposure. It further enhances security through integrated firewall management and log auditing capabilities.
- **One-Click Backup &amp; Restore**: Data protection is made simple with 1Panel&#039;s one-click backup and restore functionality, supporting various cloud storage solutions to ensure data integrity and availability.

## Quick Start

Execute the script below and follow the prompts to install 1Panel:

```bash
curl -sSL https://resource.1panel.pro/quick_start.sh -o quick_start.sh &amp;&amp; bash quick_start.sh
```

Please refer to our [documentation](https://docs.1panel.pro/quick_start/) for more details.

‰∏≠ÂõΩÁî®Êà∑ËØ∑‰ΩøÁî®Ëøô‰∏™ [ÂÆâË£ÖËÑöÊú¨](https://1panel.cn/docs/installation/online_installation/)ÔºåÂÖ∂Â∫îÁî®Êï∞ÈáèÊØîÂõΩÈôÖÁâàÊú¨Êõ¥‰∏∞ÂØå„ÄÇ

## Screenshot

![UI Display](https://resource.1panel.pro/img/1panel.png)

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=1Panel-dev/1Panel&amp;type=Date)](https://star-history.com/#1Panel-dev/1Panel&amp;Date)

## Pro Edition

Compared to the OSS Edition, 1Panel Pro Edition provides users with a wealth of enhanced features and technical support services. Enhanced features include WAF enhancement, website tamper protection, website monitoring, GPU monitoring, custom logo and theme color, etc. [Click to view the detailed introduction of the Pro Edition](https://1panel.pro/pricing).

## Security Information

If you discover any security issues, please refer to [SECURITY.md](/SECURITY.md).

## License

Licensed under The GNU General Public License version 3 (GPLv3)  (the &quot;License&quot;); you may not use this file except in compliance with the License. You may obtain a copy of the License at

&lt;https://www.gnu.org/licenses/gpl-3.0.html&gt;

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[syncthing/syncthing]]></title>
            <link>https://github.com/syncthing/syncthing</link>
            <guid>https://github.com/syncthing/syncthing</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[Open Source Continuous File Synchronization]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/syncthing/syncthing">syncthing/syncthing</a></h1>
            <p>Open Source Continuous File Synchronization</p>
            <p>Language: Go</p>
            <p>Stars: 77,368</p>
            <p>Forks: 4,821</p>
            <p>Stars today: 40 stars today</p>
            <h2>README</h2><pre>[![Syncthing][14]][15]

---

[![MPLv2 License](https://img.shields.io/badge/license-MPLv2-blue.svg?style=flat-square)](https://www.mozilla.org/MPL/2.0/)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/88/badge)](https://bestpractices.coreinfrastructure.org/projects/88)
[![Go Report Card](https://goreportcard.com/badge/github.com/syncthing/syncthing)](https://goreportcard.com/report/github.com/syncthing/syncthing)

## Goals

Syncthing is a **continuous file synchronization program**. It synchronizes
files between two or more computers. We strive to fulfill the goals below.
The goals are listed in order of importance, the most important ones first.
This is the summary version of the goal list - for more
commentary, see the full [Goals document][13].

Syncthing should be:

1. **Safe From Data Loss**

   Protecting the user&#039;s data is paramount. We take every reasonable
   precaution to avoid corrupting the user&#039;s files.

2. **Secure Against Attackers**

   Again, protecting the user&#039;s data is paramount. Regardless of our other
   goals, we must never allow the user&#039;s data to be susceptible to
   eavesdropping or modification by unauthorized parties.

3. **Easy to Use**

   Syncthing should be approachable, understandable, and inclusive.

4. **Automatic**

   User interaction should be required only when absolutely necessary.

5. **Universally Available**

   Syncthing should run on every common computer. We are mindful that the
   latest technology is not always available to every individual.

6. **For Individuals**

   Syncthing is primarily about empowering the individual user with safe,
   secure, and easy to use file synchronization.

7. **Everything Else**

   There are many things we care about that don&#039;t make it on to the list. It
   is fine to optimize for these values, as long as they are not in conflict
   with the stated goals above.

## Getting Started

Take a look at the [getting started guide][2].

There are a few examples for keeping Syncthing running in the background
on your system in [the etc directory][3]. There are also several [GUI
implementations][11] for Windows, Mac, and Linux.

## Docker

To run Syncthing in Docker, see [the Docker README][16].

## Getting in Touch

The first and best point of contact is the [Forum][8].
If you&#039;ve found something that is clearly a
bug, feel free to report it in the [GitHub issue tracker][10].

If you believe that you‚Äôve found a Syncthing-related security vulnerability,
please report it by emailing security@syncthing.net. Do not report it in the
Forum or issue tracker.

## Building

Building Syncthing from source is easy. After extracting the source bundle from
a release or checking out git, you just need to run `go run build.go` and the
binaries are created in `./bin`. There&#039;s [a guide][5] with more details on the
build process.

## Signed Releases

Release binaries are GPG signed with the key available from
https://syncthing.net/security/. There is also a built-in automatic
upgrade mechanism (disabled in some distribution channels) which uses a
compiled in ECDSA signature. macOS and Windows binaries are also
code-signed.

## Documentation

Please see the Syncthing [documentation site][6] [[source]][17].

All code is licensed under the [MPLv2 License][7].

[1]: https://docs.syncthing.net/specs/bep-v1.html
[2]: https://docs.syncthing.net/intro/getting-started.html
[3]: https://github.com/syncthing/syncthing/blob/main/etc
[5]: https://docs.syncthing.net/dev/building.html
[6]: https://docs.syncthing.net/
[7]: https://github.com/syncthing/syncthing/blob/main/LICENSE
[8]: https://forum.syncthing.net/
[10]: https://github.com/syncthing/syncthing/issues
[11]: https://docs.syncthing.net/users/contrib.html#gui-wrappers
[13]: https://github.com/syncthing/syncthing/blob/main/GOALS.md
[14]: assets/logo-text-128.png
[15]: https://syncthing.net/
[16]: https://github.com/syncthing/syncthing/blob/main/README-Docker.md
[17]: https://github.com/syncthing/docs
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[trufflesecurity/trufflehog]]></title>
            <link>https://github.com/trufflesecurity/trufflehog</link>
            <guid>https://github.com/trufflesecurity/trufflehog</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Find, verify, and analyze leaked credentials]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/trufflesecurity/trufflehog">trufflesecurity/trufflehog</a></h1>
            <p>Find, verify, and analyze leaked credentials</p>
            <p>Language: Go</p>
            <p>Stars: 23,074</p>
            <p>Forks: 2,125</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;GoReleaser Logo&quot; src=&quot;https://storage.googleapis.com/trufflehog-static-sources/pixel_pig.png&quot; height=&quot;140&quot; /&gt;
  &lt;h2 align=&quot;center&quot;&gt;TruffleHog&lt;/h2&gt;
  &lt;p align=&quot;center&quot;&gt;Find leaked credentials.&lt;/p&gt;
&lt;/p&gt;

---

&lt;div align=&quot;center&quot;&gt;

[![Go Report Card](https://goreportcard.com/badge/github.com/trufflesecurity/trufflehog/v3)](https://goreportcard.com/report/github.com/trufflesecurity/trufflehog/v3)
[![License](https://img.shields.io/badge/license-AGPL--3.0-brightgreen)](/LICENSE)
[![Total Detectors](https://img.shields.io/github/directory-file-count/trufflesecurity/truffleHog/pkg/detectors?label=Total%20Detectors&amp;type=dir)](/pkg/detectors)

&lt;/div&gt;

---

# :mag_right: _Now Scanning_

&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;assets/scanning_logos.svg&quot;&gt;

**...and more**

To learn more about TruffleHog and its features and capabilities, visit our [product page](https://trufflesecurity.com/trufflehog?gclid=CjwKCAjwouexBhAuEiwAtW_Zx5IW87JNj97Ci7heFnA5ar6-DuNzT2Y5nIl9DuZ-FOUqx0Qg3vb9nxoClcEQAvD_BwE).

&lt;/div&gt;

# :globe_with_meridians: TruffleHog Enterprise

Are you interested in continuously monitoring **Git, Jira, Slack, Confluence, Microsoft Teams, Sharepoint, and more..** for credentials? We have an enterprise product that can help! Learn more at &lt;https://trufflesecurity.com/trufflehog-enterprise&gt;.

We take the revenue from the enterprise product to fund more awesome open source projects that the whole community can benefit from.

&lt;/div&gt;

# What is TruffleHog üêΩ

TruffleHog is the most powerful secrets **Discovery, Classification, Validation,** and **Analysis** tool. In this context, secret refers to a credential a machine uses to authenticate itself to another machine. This includes API keys, database passwords, private encryption keys, and more...

## Discovery üîç

TruffleHog can look for secrets in many places including Git, chats, wikis, logs, API testing platforms, object stores, filesystems and more

## Classification üìÅ

TruffleHog classifies over 800 secret types, mapping them back to the specific identity they belong to. Is it an AWS secret? Stripe secret? Cloudflare secret? Postgres password? SSL Private key? Sometimes it&#039;s hard to tell looking at it, so TruffleHog classifies everything it finds.

## Validation ‚úÖ

For every secret TruffleHog can classify, it can also log in to confirm if that secret is live or not. This step is critical to know if there‚Äôs an active present danger or not.

## Analysis üî¨

For the 20 some of the most commonly leaked out credential types, instead of sending one request to check if the secret can log in, TruffleHog can send many requests to learn everything there is to know about the secret. Who created it? What resources can it access? What permissions does it have on those resources?

# :loudspeaker: Join Our Community

Have questions? Feedback? Jump into Slack or Discord and hang out with us.

Join our [Slack Community](https://join.slack.com/t/trufflehog-community/shared_invite/zt-pw2qbi43-Aa86hkiimstfdKH9UCpPzQ)

Join the [Secret Scanning Discord](https://discord.gg/8Hzbrnkr7E)

# :tv: Demo

![GitHub scanning demo](https://storage.googleapis.com/truffle-demos/non-interactive.svg)

```bash
docker run --rm -it -v &quot;$PWD:/pwd&quot; trufflesecurity/trufflehog:latest github --org=trufflesecurity
```

# :floppy_disk: Installation

Several options are available for you:

### MacOS users

```bash
brew install trufflehog
```

### Docker:

&lt;sub&gt;&lt;i&gt;_Ensure Docker engine is running before executing the following commands:_&lt;/i&gt;&lt;/sub&gt;

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Unix

```bash
docker run --rm -it -v &quot;$PWD:/pwd&quot; trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
```

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Windows Command Prompt

```bash
docker run --rm -it -v &quot;%cd:/=\%:/pwd&quot; trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
```

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Windows PowerShell

```bash
docker run --rm -it -v &quot;${PWD}:/pwd&quot; trufflesecurity/trufflehog github --repo https://github.com/trufflesecurity/test_keys
```

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;M1 and M2 Mac

```bash
docker run --platform linux/arm64 --rm -it -v &quot;$PWD:/pwd&quot; trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
```

### Binary releases

```bash
Download and unpack from https://github.com/trufflesecurity/trufflehog/releases
```

### Compile from source

```bash
git clone https://github.com/trufflesecurity/trufflehog.git
cd trufflehog; go install
```

### Using installation script

```bash
curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin
```

### Using installation script, verify checksum signature (requires cosign to be installed)

```bash
curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -v -b /usr/local/bin
```

### Using installation script to install a specific version

```bash
curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin &lt;ReleaseTag like v3.56.0&gt;
```

# :closed_lock_with_key: Verifying the artifacts

Checksums are applied to all artifacts, and the resulting checksum file is signed using cosign.

You need the following tool to verify signature:

- [Cosign](https://docs.sigstore.dev/cosign/system_config/installation/)

Verification steps are as follows:

1. Download the artifact files you want, and the following files from the [releases](https://github.com/trufflesecurity/trufflehog/releases) page.

   - trufflehog\_{version}\_checksums.txt
   - trufflehog\_{version}\_checksums.txt.pem
   - trufflehog\_{version}\_checksums.txt.sig

2. Verify the signature:

   ```shell
   cosign verify-blob &lt;path to trufflehog_{version}_checksums.txt&gt; \
   --certificate &lt;path to trufflehog_{version}_checksums.txt.pem&gt; \
   --signature &lt;path to trufflehog_{version}_checksums.txt.sig&gt; \
   --certificate-identity-regexp &#039;https://github\.com/trufflesecurity/trufflehog/\.github/workflows/.+&#039; \
   --certificate-oidc-issuer &quot;https://token.actions.githubusercontent.com&quot;
   ```

3. Once the signature is confirmed as valid, you can proceed to validate that the SHA256 sums align with the downloaded artifact:

   ```shell
   sha256sum --ignore-missing -c trufflehog_{version}_checksums.txt
   ```

Replace `{version}` with the downloaded files version

Alternatively, if you are using the installation script, pass `-v` option to perform signature verification.
This requires Cosign binary to be installed prior to running the installation script.

# :rocket: Quick Start

## 1: Scan a repo for only verified secrets

Command:

```bash
trufflehog git https://github.com/trufflesecurity/test_keys --results=verified
```

Expected output:

```
üê∑üîëüê∑  TruffleHog. Unearth your secrets. üê∑üîëüê∑

Found verified result üê∑üîë
Detector Type: AWS
Decoder Type: PLAIN
Raw result: AKIAYVP4CIPPERUVIFXG
Line: 4
Commit: fbc14303ffbf8fb1c2c1914e8dda7d0121633aca
File: keys
Email: counter &lt;counter@counters-MacBook-Air.local&gt;
Repository: https://github.com/trufflesecurity/test_keys
Timestamp: 2022-06-16 10:17:40 -0700 PDT
...
```

## 2: Scan a GitHub Org for only verified secrets

```bash
trufflehog github --org=trufflesecurity --results=verified
```

## 3: Scan a GitHub Repo for only verified secrets and get JSON output

Command:

```bash
trufflehog git https://github.com/trufflesecurity/test_keys --results=verified --json
```

Expected output:

```
{&quot;SourceMetadata&quot;:{&quot;Data&quot;:{&quot;Git&quot;:{&quot;commit&quot;:&quot;fbc14303ffbf8fb1c2c1914e8dda7d0121633aca&quot;,&quot;file&quot;:&quot;keys&quot;,&quot;email&quot;:&quot;counter \u003ccounter@counters-MacBook-Air.local\u003e&quot;,&quot;repository&quot;:&quot;https://github.com/trufflesecurity/test_keys&quot;,&quot;timestamp&quot;:&quot;2022-06-16 10:17:40 -0700 PDT&quot;,&quot;line&quot;:4}}},&quot;SourceID&quot;:0,&quot;SourceType&quot;:16,&quot;SourceName&quot;:&quot;trufflehog - git&quot;,&quot;DetectorType&quot;:2,&quot;DetectorName&quot;:&quot;AWS&quot;,&quot;DecoderName&quot;:&quot;PLAIN&quot;,&quot;Verified&quot;:true,&quot;Raw&quot;:&quot;AKIAYVP4CIPPERUVIFXG&quot;,&quot;Redacted&quot;:&quot;AKIAYVP4CIPPERUVIFXG&quot;,&quot;ExtraData&quot;:{&quot;account&quot;:&quot;595918472158&quot;,&quot;arn&quot;:&quot;arn:aws:iam::595918472158:user/canarytokens.com@@mirux23ppyky6hx3l6vclmhnj&quot;,&quot;user_id&quot;:&quot;AIDAYVP4CIPPJ5M54LRCY&quot;},&quot;StructuredData&quot;:null}
...
```

## 4: Scan a GitHub Repo + its Issues and Pull Requests

```bash
trufflehog github --repo=https://github.com/trufflesecurity/test_keys --issue-comments --pr-comments
```

## 5: Scan an S3 bucket for high-confidence results (verified + unknown)

```bash
trufflehog s3 --bucket=&lt;bucket name&gt; --results=verified,unknown
```

## 6: Scan S3 buckets using IAM Roles

```bash
trufflehog s3 --role-arn=&lt;iam role arn&gt;
```

## 7: Scan a Github Repo using SSH authentication in Docker

```bash
docker run --rm -v &quot;$HOME/.ssh:/root/.ssh:ro&quot; trufflesecurity/trufflehog:latest git ssh://github.com/trufflesecurity/test_keys
```

## 8: Scan individual files or directories

```bash
trufflehog filesystem path/to/file1.txt path/to/file2.txt path/to/dir
```

## 9: Scan a local git repo

Clone the git repo. For example [test keys](git@github.com:trufflesecurity/test_keys.git) repo.
```bash
$ git clone git@github.com:trufflesecurity/test_keys.git
```

Run trufflehog from the parent directory (outside the git repo).
```bash
$ trufflehog git file://test_keys --results=verified,unknown
```

To guard against malicious git configs in local scanning (see CVE-2025-41390), TruffleHog clones local git repositories to a temporary directory prior to scanning. This follows [Git&#039;s security best practices](https://git-scm.com/docs/git#_security). If you want to specify a custom path to clone the repository to (instead of tmp), you can use the `--clone-path` flag. If you&#039;d like to skip the local cloning process and scan the repository directly (only do this for trusted repos), you can use the `--trust-local-git-config` flag.

## 10: Scan GCS buckets for only verified secrets

```bash
trufflehog gcs --project-id=&lt;project-ID&gt; --cloud-environment --results=verified
```

## 11: Scan a Docker image for only verified secrets

Use the `--image` flag multiple times to scan multiple images.

```bash
# to scan from a remote registry
trufflehog docker --image trufflesecurity/secrets --results=verified

# to scan from the local docker daemon
trufflehog docker --image docker://new_image:tag --results=verified

# to scan from an image saved as a tarball
trufflehog docker --image file://path_to_image.tar --results=verified
```

## 12: Scan in CI

Set the `--since-commit` flag to your default branch that people merge into (ex: &quot;main&quot;). Set the `--branch` flag to your PR&#039;s branch name (ex: &quot;feature-1&quot;). Depending on the CI/CD platform you use, this value can be pulled in dynamically (ex: [CIRCLE_BRANCH in Circle CI](https://circleci.com/docs/variables/) and [TRAVIS_PULL_REQUEST_BRANCH in Travis CI](https://docs.travis-ci.com/user/environment-variables/)). If the repo is cloned and the target branch is already checked out during the CI/CD workflow, then `--branch HEAD` should be sufficient. The `--fail` flag will return an 183 error code if valid credentials are found.

```bash
trufflehog git file://. --since-commit main --branch feature-1 --results=verified,unknown --fail
```

## 13: Scan a Postman workspace

Use the `--workspace-id`, `--collection-id`, `--environment` flags multiple times to scan multiple targets.

```bash
trufflehog postman --token=&lt;postman api token&gt; --workspace-id=&lt;workspace id&gt;
```

## 14: Scan a Jenkins server

```bash
trufflehog jenkins --url https://jenkins.example.com --username admin --password admin
```

## 15: Scan an Elasticsearch server

### Scan a Local Cluster

There are two ways to authenticate to a local cluster with TruffleHog: (1) username and password, (2) service token.

#### Connect to a local cluster with username and password

```bash
trufflehog elasticsearch --nodes 192.168.14.3 192.168.14.4 --username truffle --password hog
```

#### Connect to a local cluster with a service token

```bash
trufflehog elasticsearch --nodes 192.168.14.3 192.168.14.4 --service-token ‚ÄòAAEWVaWM...Rva2VuaSDZ‚Äô
```

### Scan an Elastic Cloud Cluster

To scan a cluster on Elastic Cloud, you‚Äôll need a Cloud ID and API key.

```bash
trufflehog elasticsearch \
  --cloud-id &#039;search-prod:dXMtY2Vx...YjM1ODNlOWFiZGRlNjI0NA==&#039; \
  --api-key &#039;MlVtVjBZ...ZSYlduYnF1djh3NG5FQQ==&#039;
```

## 16. Scan a GitHub Repository for Cross Fork Object References and Deleted Commits

The following command will enumerate deleted and hidden commits on a GitHub repository and then scan them for secrets. This is an alpha release feature.

```bash
trufflehog github-experimental --repo https://github.com/&lt;USER&gt;/&lt;REPO&gt;.git --object-discovery
```

In addition to the normal TruffleHog output, the `--object-discovery` flag creates two files in a new `$HOME/.trufflehog` directory: `valid_hidden.txt` and `invalid.txt`. These are used to track state during commit enumeration, as well as to provide users with a complete list of all hidden and deleted commits (`valid_hidden.txt`). If you&#039;d like to automatically remove these files after scanning, please add the flag `--delete-cached-data`.

**Note**: Enumerating all valid commits on a repository using this method takes between 20 minutes and a few hours, depending on the size of your repository. We added a progress bar to keep you updated on how long the enumeration will take. The actual secret scanning runs extremely fast.

For more information on Cross Fork Object References, please [read our blog post](https://trufflesecurity.com/blog/anyone-can-access-deleted-and-private-repo-data-github).

## 17. Scan Hugging Face

### Scan a Hugging Face Model, Dataset or Space

```bash
trufflehog huggingface --model &lt;model_id&gt; --space &lt;space_id&gt; --dataset &lt;dataset_id&gt;
```

### Scan all Models, Datasets and Spaces belonging to a Hugging Face Organization or User

```bash
trufflehog huggingface --org &lt;orgname&gt; --user &lt;username&gt;
```

(Optionally) When scanning an organization or user, you can skip an entire class of resources with `--skip-models`, `--skip-datasets`, `--skip-spaces` OR a particular resource with `--ignore-models &lt;model_id&gt;`, `--ignore-datasets &lt;dataset_id&gt;`, `--ignore-spaces &lt;space_id&gt;`.

### Scan Discussion and PR Comments

```bash
trufflehog huggingface --model &lt;model_id&gt; --include-discussions --include-prs
```

## 18. Scan stdin Input

```bash
aws s3 cp s3://example/gzipped/data.gz - | gunzip -c | trufflehog stdin
```

# :question: FAQ

- All I see is `üê∑üîëüê∑  TruffleHog. Unearth your secrets. üê∑üîëüê∑` and the program exits, what gives?
  - That means no secrets were detected
- Why is the scan taking a long time when I scan a GitHub org
  - Unauthenticated GitHub scans have rate limits. To improve your rate limits, include the `--token` flag with a personal access token
- It says a private key was verified, what does that mean?
  - A verified result means TruffleHog confirmed the credential is valid by testing it against the service&#039;s API. For private keys, we&#039;ve confirmed the key can be used live for SSH or SSL authentication. Check out our Driftwood blog post to learn more [Blog post](https://trufflesecurity.com/blog/driftwood-know-if-private-keys-are-sensitive/)
- Is there an easy way to ignore specific secrets?
  - If the scanned source [supports line numbers](https://github.com/trufflesecurity/trufflehog/blob/d6375ba92172fd830abb4247cca15e3176448c5d/pkg/engine/engine.go#L358-L365), then you can add a `trufflehog:ignore` comment on the line containing the secret to ignore that secrets.

# :newspaper: What&#039;s new in v3?

TruffleHog v3 is a complete rewrite in Go with many new powerful features.

- We&#039;ve **added over 700 credential detectors that support active verification against their respective APIs**.
- We&#039;ve also added native **support for scanning GitHub, GitLab, Docker, filesystems, S3, GCS, Circle CI and Travis CI**.
- **Instantly verify private keys** against millions of github users and **billions** of TLS certificates using our [Driftwood](https://trufflesecurity.com/blog/driftwood) technology.
- Scan binaries, documents, and other file formats
- Available as a GitHub Action and a pre-commit hook

## What is credential verification?

For every potential credential that is detected, we&#039;ve painstakingly implemented programmatic verification against the API that we think it belongs to. Verification eliminates false positives and provides three result statuses:

- **verified**: Credential confirmed as valid and active by API testing
- **unverified**: Credential detected but not confirmed valid (may be invalid, expired, or verification disabled)  
- **unknown**: Verification attempted but failed due to errors, such as a network or API failure

For example, the [AWS credential detector](pkg/detectors/aws/aws.go) performs a `GetCallerIdentity` API call against the AWS API to verify if an AWS credential is active.

# :memo: Usage

TruffleHog has a sub-command for each source of data that you may want to scan:

- git
- github
- gitlab
- docker
- s3
- filesystem (files and directories)
- syslog
- circleci
- travisci
- gcs (Google Cloud Storage)
- postman
- jenkins
- elasticsearch
- stdin
- multi-scan

Each subcommand can have options that you can see with the `--help` flag provided to the sub command:

```
$ trufflehog git --help
usage: TruffleHog git [&lt;flags&gt;] &lt;uri&gt;

Find credentials in git repositories.

Flags:
  -h, --help                Show context-sensitive help (also try --help-long and --help-man).
      --log-level=0         Logging verbosity on a scale of 0 (info) to 5 (trace). Can be disabled with &quot;-1&quot;.
      --profile             Enables profiling and sets a pprof and fgprof server on :18066.
  -j, --json                Output in JSON format.
      --json-legacy         Use the pre-v3.0 JSON format. Only works with git, gitlab, and github sources.
      --github-actions      Output in GitHub Actions format.
      --concurrency=20           Number of concurrent workers.
      --no-verification     Don&#039;t verify the results.
      --results=RESULTS          Specifies which type(s) of results to output: verified (confirmed valid by API), unknown (verification failed due to error), unverified (detected but not verified), filtered_unverified (unverified but would have been filtered out). Defaults to all types.
      --allow-verification-overlap
                                 Allow verification of similar credentials across detectors
      --filter-unverified   Only output first unverified result per chunk per detector if there are more than one results.
      --filter-entropy=FILTER-ENTROPY
                                 Filter unverified results with Shannon entropy. Start with 3.0.
      --config=CONFIG            Path to configuration file.
      --print-avg-detector-time
                                 Print the average time spent on each detector.
      --no-update           Don&#039;t check for updates.
      --fail                Exit with code 183 if results are found.
      --verifier=VERIFIER ...    Set custom verification endpoints.
      --custom-verifiers-only   Only use custom verification endpoints.
      --archive-max-size=ARCHIVE-MAX-SIZE
                                 Maximum size of archive to scan. (Byte units eg. 512B, 2KB, 4MB)
      --archive-max-depth=ARCHIVE-MAX-DEPTH
                                 Maximum depth of archive to scan.
      --archive-timeout=ARCHIVE-TIMEOUT
                                 Maximum time to spend extracting an archive.
      --include-detectors=&quot;all&quot;  Comma separated list of detector types to include. Protobuf name or IDs may be used, as well as ranges.
      --exclude-detectors=EXCLUDE-DETECTORS
                                 Comma separated list of detector types to exclude. Protobuf name or IDs may be used, as well as ranges. IDs defined here take precedence over the include list.
      --version             Show application version.
  -i, --include-paths=INCLUDE-PATHS
                                 Path to f

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aldinokemal/go-whatsapp-web-multidevice]]></title>
            <link>https://github.com/aldinokemal/go-whatsapp-web-multidevice</link>
            <guid>https://github.com/aldinokemal/go-whatsapp-web-multidevice</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[GOWA - WhatsApp REST API with support for UI, Webhooks, and MCP. Built with Golang for efficient memory use.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aldinokemal/go-whatsapp-web-multidevice">aldinokemal/go-whatsapp-web-multidevice</a></h1>
            <p>GOWA - WhatsApp REST API with support for UI, Webhooks, and MCP. Built with Golang for efficient memory use.</p>
            <p>Language: Go</p>
            <p>Stars: 2,672</p>
            <p>Forks: 672</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[onsi/ginkgo]]></title>
            <link>https://github.com/onsi/ginkgo</link>
            <guid>https://github.com/onsi/ginkgo</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[A Modern Testing Framework for Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/onsi/ginkgo">onsi/ginkgo</a></h1>
            <p>A Modern Testing Framework for Go</p>
            <p>Language: Go</p>
            <p>Stars: 8,862</p>
            <p>Forks: 684</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>![Ginkgo](https://onsi.github.io/ginkgo/images/ginkgo.png)

[![test](https://github.com/onsi/ginkgo/actions/workflows/test.yml/badge.svg?branch=master)](https://github.com/onsi/ginkgo/actions?query=workflow%3Atest+branch%3Amaster) | [Ginkgo Docs](https://onsi.github.io/ginkgo/)

---

# Ginkgo

Ginkgo is a mature testing framework for Go designed to help you write expressive specs.  Ginkgo builds on top of Go&#039;s `testing` foundation and is complemented by the [Gomega](https://github.com/onsi/gomega) matcher library.  Together, Ginkgo and Gomega let you express the intent behind your specs clearly:

```go
import (
    . &quot;github.com/onsi/ginkgo/v2&quot;
    . &quot;github.com/onsi/gomega&quot;
    ...
)

var _ = Describe(&quot;Checking books out of the library&quot;, Label(&quot;library&quot;), func() {
    var library *libraries.Library
    var book *books.Book
    var valjean *users.User
    BeforeEach(func() {
        library = libraries.NewClient()
        book = &amp;books.Book{
            Title: &quot;Les Miserables&quot;,
            Author: &quot;Victor Hugo&quot;,
        }
        valjean = users.NewUser(&quot;Jean Valjean&quot;)
    })

    When(&quot;the library has the book in question&quot;, func() {
        BeforeEach(func(ctx SpecContext) {
            Expect(library.Store(ctx, book)).To(Succeed())
        })

        Context(&quot;and the book is available&quot;, func() {
            It(&quot;lends it to the reader&quot;, func(ctx SpecContext) {
                Expect(valjean.Checkout(ctx, library, &quot;Les Miserables&quot;)).To(Succeed())
                Expect(valjean.Books()).To(ContainElement(book))
                Expect(library.UserWithBook(ctx, book)).To(Equal(valjean))
            }, SpecTimeout(time.Second * 5))
        })

        Context(&quot;but the book has already been checked out&quot;, func() {
            var javert *users.User
            BeforeEach(func(ctx SpecContext) {
                javert = users.NewUser(&quot;Javert&quot;)
                Expect(javert.Checkout(ctx, library, &quot;Les Miserables&quot;)).To(Succeed())
            })

            It(&quot;tells the user&quot;, func(ctx SpecContext) {
                err := valjean.Checkout(ctx, library, &quot;Les Miserables&quot;)
                Expect(err).To(MatchError(&quot;Les Miserables is currently checked out&quot;))
            }, SpecTimeout(time.Second * 5))

            It(&quot;lets the user place a hold and get notified later&quot;, func(ctx SpecContext) {
                Expect(valjean.Hold(ctx, library, &quot;Les Miserables&quot;)).To(Succeed())
                Expect(valjean.Holds(ctx)).To(ContainElement(book))

                By(&quot;when Javert returns the book&quot;)
                Expect(javert.Return(ctx, library, book)).To(Succeed())

                By(&quot;it eventually informs Valjean&quot;)
                notification := &quot;Les Miserables is ready for pick up&quot;
                Eventually(ctx, valjean.Notifications).Should(ContainElement(notification))

                Expect(valjean.Checkout(ctx, library, &quot;Les Miserables&quot;)).To(Succeed())
                Expect(valjean.Books(ctx)).To(ContainElement(book))
                Expect(valjean.Holds(ctx)).To(BeEmpty())
            }, SpecTimeout(time.Second * 10))
        })  
    })

    When(&quot;the library does not have the book in question&quot;, func() {
        It(&quot;tells the reader the book is unavailable&quot;, func(ctx SpecContext) {
            err := valjean.Checkout(ctx, library, &quot;Les Miserables&quot;)
            Expect(err).To(MatchError(&quot;Les Miserables is not in the library catalog&quot;))
        }, SpecTimeout(time.Second * 5))
    })
})
```

Jump to the [docs](https://onsi.github.io/ginkgo/) to learn more.  It&#039;s easy to [bootstrap](https://onsi.github.io/ginkgo/#bootstrapping-a-suite) and start writing your [first specs](https://onsi.github.io/ginkgo/#adding-specs-to-a-suite).

If you have a question, comment, bug report, feature request, etc. please open a [GitHub issue](https://github.com/onsi/ginkgo/issues/new), or visit the [Ginkgo Slack channel](https://app.slack.com/client/T029RQSE6/CQQ50BBNW).

## Capabilities

Whether writing basic unit specs, complex integration specs, or even performance specs - Ginkgo gives you an expressive Domain-Specific Language (DSL) that will be familiar to users coming from frameworks such as [Quick](https://github.com/Quick/Quick), [RSpec](https://rspec.info), [Jasmine](https://jasmine.github.io), and [Busted](https://lunarmodules.github.io/busted/).  This style of testing is sometimes referred to as &quot;Behavior-Driven Development&quot; (BDD) though Ginkgo&#039;s utility extends beyond acceptance-level testing.

With Ginkgo&#039;s DSL you can use nestable [`Describe`, `Context` and `When` container nodes](https://onsi.github.io/ginkgo/#organizing-specs-with-container-nodes) to help you organize your specs.  [`BeforeEach` and `AfterEach` setup nodes](https://onsi.github.io/ginkgo/#extracting-common-setup-beforeeach) for setup and cleanup.  [`It` and `Specify` subject nodes](https://onsi.github.io/ginkgo/#spec-subjects-it) that hold your assertions. [`BeforeSuite` and `AfterSuite` nodes](https://onsi.github.io/ginkgo/#suite-setup-and-cleanup-beforesuite-and-aftersuite) to prep for and cleanup after a suite... and [much more!](https://onsi.github.io/ginkgo/#writing-specs).

At runtime, Ginkgo can run your specs in reproducibly [random order](https://onsi.github.io/ginkgo/#spec-randomization) and has sophisticated support for [spec parallelization](https://onsi.github.io/ginkgo/#spec-parallelization).  In fact, running specs in parallel is as easy as

```bash
ginkgo -p
```

By following [established patterns for writing parallel specs](https://onsi.github.io/ginkgo/#patterns-for-parallel-integration-specs) you can build even large, complex integration suites that parallelize cleanly and run performantly.  And you don&#039;t have to worry about your spec suite hanging or leaving a mess behind - Ginkgo provides a per-node `context.Context` and the capability to interrupt the spec after a set period of time - and then clean up.

As your suites grow Ginkgo helps you keep your specs organized with [labels](https://onsi.github.io/ginkgo/#spec-labels) and lets you easily run [subsets of specs](https://onsi.github.io/ginkgo/#filtering-specs), either [programmatically](https://onsi.github.io/ginkgo/#focused-specs) or on the [command line](https://onsi.github.io/ginkgo/#combining-filters).  And Ginkgo&#039;s reporting infrastructure generates machine-readable output in a [variety of formats](https://onsi.github.io/ginkgo/#generating-machine-readable-reports) _and_ allows you to build your own [custom reporting infrastructure](https://onsi.github.io/ginkgo/#generating-reports-programmatically).

Ginkgo ships with `ginkgo`, a [command line tool](https://onsi.github.io/ginkgo/#ginkgo-cli-overview) with support for generating, running, filtering, and profiling Ginkgo suites.  You can even have Ginkgo automatically run your specs when it detects a change with `ginkgo watch`, enabling rapid feedback loops during test-driven development.

And that&#039;s just Ginkgo!  [Gomega](https://onsi.github.io/gomega/) brings a rich, mature, family of [assertions and matchers](https://onsi.github.io/gomega/#provided-matchers) to your suites.  With Gomega you can easily mix [synchronous and asynchronous assertions](https://onsi.github.io/ginkgo/#patterns-for-asynchronous-testing) in your specs.  You can even build your own set of expressive domain-specific matchers quickly and easily by composing Gomega&#039;s [existing building blocks](https://onsi.github.io/ginkgo/#building-custom-matchers).

Happy Testing!

## License

Ginkgo is MIT-Licensed

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md)

## Sponsors

Sponsors commit to a [sponsorship](https://github.com/sponsors/onsi) for a year.  If you&#039;re an organization that makes use of Ginkgo please consider becoming a sponsor!

&lt;p style=&quot;font-size:21px; color:black;&quot;&gt;Browser testing via 
    &lt;a href=&quot;https://www.lambdatest.com/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://www.lambdatest.com/blue-logo.png&quot; style=&quot;vertical-align: middle;&quot; width=&quot;250&quot; height=&quot;45&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gitleaks/gitleaks]]></title>
            <link>https://github.com/gitleaks/gitleaks</link>
            <guid>https://github.com/gitleaks/gitleaks</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[Find secrets with Gitleaks üîë]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitleaks/gitleaks">gitleaks/gitleaks</a></h1>
            <p>Find secrets with Gitleaks üîë</p>
            <p>Language: Go</p>
            <p>Stars: 23,828</p>
            <p>Forks: 1,824</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># Gitleaks

```
‚îå‚îÄ‚óã‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚îÇ‚ï≤  ‚îÇ
‚îÇ ‚îÇ ‚óã ‚îÇ
‚îÇ ‚óã ‚ñë ‚îÇ
‚îî‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚îò
```

[license]: ./LICENSE
[badge-license]: https://img.shields.io/github/license/gitleaks/gitleaks.svg
[go-docs-badge]: https://pkg.go.dev/badge/github.com/gitleaks/gitleaks/v8?status
[go-docs]: https://pkg.go.dev/github.com/zricethezav/gitleaks/v8
[badge-build]: https://github.com/gitleaks/gitleaks/actions/workflows/test.yml/badge.svg
[build]: https://github.com/gitleaks/gitleaks/actions/workflows/test.yml
[go-report-card-badge]: https://goreportcard.com/badge/github.com/gitleaks/gitleaks/v8
[go-report-card]: https://goreportcard.com/report/github.com/gitleaks/gitleaks/v8
[dockerhub]: https://hub.docker.com/r/zricethezav/gitleaks
[dockerhub-badge]: https://img.shields.io/docker/pulls/zricethezav/gitleaks.svg
[gitleaks-action]: https://github.com/gitleaks/gitleaks-action
[gitleaks-badge]: https://img.shields.io/badge/protected%20by-gitleaks-blue
[gitleaks-playground-badge]: https://img.shields.io/badge/gitleaks%20-playground-blue
[gitleaks-playground]: https://gitleaks.io/playground


[![GitHub Action Test][badge-build]][build]
[![Docker Hub][dockerhub-badge]][dockerhub]
[![Gitleaks Playground][gitleaks-playground-badge]][gitleaks-playground]
[![Gitleaks Action][gitleaks-badge]][gitleaks-action]
[![GoDoc][go-docs-badge]][go-docs]
[![GoReportCard][go-report-card-badge]][go-report-card]
[![License][badge-license]][license]

Gitleaks is a tool for **detecting** secrets like passwords, API keys, and tokens in git repos, files, and whatever else you wanna throw at it via `stdin`. If you wanna learn more about how the detection engine works check out this blog: [Regex is (almost) all you need](https://lookingatcomputer.substack.com/p/regex-is-almost-all-you-need).

```
‚ûú  ~/code(master) gitleaks git -v

    ‚óã
    ‚îÇ‚ï≤
    ‚îÇ ‚óã
    ‚óã ‚ñë
    ‚ñë    gitleaks


Finding:     &quot;export BUNDLE_ENTERPRISE__CONTRIBSYS__COM=cafebabe:deadbeef&quot;,
Secret:      cafebabe:deadbeef
RuleID:      sidekiq-secret
Entropy:     2.609850
File:        cmd/generate/config/rules/sidekiq.go
Line:        23
Commit:      cd5226711335c68be1e720b318b7bc3135a30eb2
Author:      John
Email:       john@users.noreply.github.com
Date:        2022-08-03T12:31:40Z
Fingerprint: cd5226711335c68be1e720b318b7bc3135a30eb2:cmd/generate/config/rules/sidekiq.go:sidekiq-secret:23
```

### GitHub Sponsors

Sponsor [@zricethezav on GitHub](https://github.com/sponsors/zricethezav/) to get
featured on this README.

## Getting Started

Gitleaks can be installed using Homebrew, Docker, or Go. Gitleaks is also available in binary form for many popular platforms and OS types on the [releases page](https://github.com/gitleaks/gitleaks/releases). In addition, Gitleaks can be implemented as a pre-commit hook directly in your repo or as a GitHub action using [Gitleaks-Action](https://github.com/gitleaks/gitleaks-action).

### Installing

```bash
# MacOS
brew install gitleaks

# Docker (DockerHub)
docker pull zricethezav/gitleaks:latest
docker run -v ${path_to_host_folder_to_scan}:/path zricethezav/gitleaks:latest [COMMAND] [OPTIONS] [SOURCE_PATH]

# Docker (ghcr.io)
docker pull ghcr.io/gitleaks/gitleaks:latest
docker run -v ${path_to_host_folder_to_scan}:/path ghcr.io/gitleaks/gitleaks:latest [COMMAND] [OPTIONS] [SOURCE_PATH]

# From Source (make sure `go` is installed)
git clone https://github.com/gitleaks/gitleaks.git
cd gitleaks
make build
```

### GitHub Action

Check out the official [Gitleaks GitHub Action](https://github.com/gitleaks/gitleaks-action)

```
name: gitleaks
on: [pull_request, push, workflow_dispatch]
jobs:
  scan:
    name: gitleaks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE}} # Only required for Organizations, not personal accounts.
```

### Pre-Commit

1. Install pre-commit from https://pre-commit.com/#install
2. Create a `.pre-commit-config.yaml` file at the root of your repository with the following content:

   ```
   repos:
     - repo: https://github.com/gitleaks/gitleaks
       rev: v8.24.2
       hooks:
         - id: gitleaks
   ```

   for a [native execution of gitleaks](https://github.com/gitleaks/gitleaks/releases) or use the [`gitleaks-docker` pre-commit ID](https://github.com/gitleaks/gitleaks/blob/master/.pre-commit-hooks.yaml) for executing gitleaks using the [official Docker images](#docker)

3. Auto-update the config to the latest repos&#039; versions by executing `pre-commit autoupdate`
4. Install with `pre-commit install`
5. Now you&#039;re all set!

```
‚ûú git commit -m &quot;this commit contains a secret&quot;
Detect hardcoded secrets.................................................Failed
```

Note: to disable the gitleaks pre-commit hook you can prepend `SKIP=gitleaks` to the commit command
and it will skip running gitleaks

```
‚ûú SKIP=gitleaks git commit -m &quot;skip gitleaks check&quot;
Detect hardcoded secrets................................................Skipped
```

## Usage

```
Gitleaks scans code, past or present, for secrets

Usage:
  gitleaks [command]

Available Commands:
  completion  Generate the autocompletion script for the specified shell
  dir         scan directories or files for secrets
  git         scan git repositories for secrets
  help        Help about any command
  stdin       detect secrets from stdin
  version     display gitleaks version

Flags:
  -b, --baseline-path string          path to baseline with issues that can be ignored
  -c, --config string                 config file path
                                      order of precedence:
                                      1. --config/-c
                                      2. env var GITLEAKS_CONFIG
                                      3. env var GITLEAKS_CONFIG_TOML with the file content
                                      4. (target path)/.gitleaks.toml
                                      If none of the four options are used, then gitleaks will use the default config
      --diagnostics string            enable diagnostics (http OR comma-separated list: cpu,mem,trace). cpu=CPU prof, mem=memory prof, trace=exec tracing, http=serve via net/http/pprof
      --diagnostics-dir string        directory to store diagnostics output files when not using http mode (defaults to current directory)
      --enable-rule strings           only enable specific rules by id
      --exit-code int                 exit code when leaks have been encountered (default 1)
  -i, --gitleaks-ignore-path string   path to .gitleaksignore file or folder containing one (default &quot;.&quot;)
  -h, --help                          help for gitleaks
      --ignore-gitleaks-allow         ignore gitleaks:allow comments
  -l, --log-level string              log level (trace, debug, info, warn, error, fatal) (default &quot;info&quot;)
      --max-archive-depth int         allow scanning into nested archives up to this depth (default &quot;0&quot;, no archive traversal is done)
      --max-decode-depth int          allow recursive decoding up to this depth (default &quot;0&quot;, no decoding is done)
      --max-target-megabytes int      files larger than this will be skipped
      --no-banner                     suppress banner
      --no-color                      turn off color for verbose output
      --redact uint[=100]             redact secrets from logs and stdout. To redact only parts of the secret just apply a percent value from 0..100. For example --redact=20 (default 100%)
  -f, --report-format string          output format (json, csv, junit, sarif, template)
  -r, --report-path string            report file
      --report-template string        template file used to generate the report (implies --report-format=template)
      --timeout int                   set a timeout for gitleaks commands in seconds (default &quot;0&quot;, no timeout is set)
  -v, --verbose                       show verbose output from scan
      --version                       version for gitleaks

Use &quot;gitleaks [command] --help&quot; for more information about a command.
```

### Commands

‚ö†Ô∏è v8.19.0 introduced a change that deprecated `detect` and `protect`. Those commands are still available but
are hidden in the `--help` menu. Take a look at this [gist](https://gist.github.com/zricethezav/b325bb93ebf41b9c0b0507acf12810d2) for easy command translations.
If you find v8.19.0 broke an existing command (`detect`/`protect`), please open an issue.

There are three scanning modes: `git`, `dir`, and `stdin`.

#### Git

The `git` command lets you scan local git repos. Under the hood, gitleaks uses the `git log -p` command to scan patches.
You can configure the behavior of `git log -p` with the `log-opts` option.
For example, if you wanted to run gitleaks on a range of commits you could use the following
command: `gitleaks git -v --log-opts=&quot;--all commitA..commitB&quot; path_to_repo`. See the [git log](https://git-scm.com/docs/git-log) documentation for more information.
If there is no target specified as a positional argument, then gitleaks will attempt to scan the current working directory as a git repo.

#### Dir

The `dir` (aliases include `files`, `directory`) command lets you scan directories and files. Example: `gitleaks dir -v path_to_directory_or_file`.
If there is no target specified as a positional argument, then gitleaks will scan the current working directory.

#### Stdin

You can also stream data to gitleaks with the `stdin` command. Example: `cat some_file | gitleaks -v stdin`

### Creating a baseline

When scanning large repositories or repositories with a long history, it can be convenient to use a baseline. When using a baseline,
gitleaks will ignore any old findings that are present in the baseline. A baseline can be any gitleaks report. To create a gitleaks report, run gitleaks with the `--report-path` parameter.

```
gitleaks git --report-path gitleaks-report.json # This will save the report in a file called gitleaks-report.json
```

Once as baseline is created it can be applied when running the detect command again:

```
gitleaks git --baseline-path gitleaks-report.json --report-path findings.json
```

After running the detect command with the --baseline-path parameter, report output (findings.json) will only contain new issues.

## Pre-Commit hook

You can run Gitleaks as a pre-commit hook by copying the example `pre-commit.py` script into
your `.git/hooks/` directory.

## Load Configuration

The order of precedence is:

1. `--config/-c` option:
      ```bash
      gitleaks git --config /home/dev/customgitleaks.toml .
      ```
2. Environment variable `GITLEAKS_CONFIG` with the file path:
      ```bash
      export GITLEAKS_CONFIG=&quot;/home/dev/customgitleaks.toml&quot;
      gitleaks git .
      ```
3. Environment variable `GITLEAKS_CONFIG_TOML` with the file content:
      ```bash
      export GITLEAKS_CONFIG_TOML=`cat customgitleaks.toml`
      gitleaks git .
      ```
4. A `.gitleaks.toml` file within the target path:
      ```bash
      gitleaks git .
      ```

If none of the four options are used, then gitleaks will use the default config.

## Configuration

Gitleaks offers a configuration format you can follow to write your own secret detection rules:

```toml
# Title for the gitleaks configuration file.
title = &quot;Custom Gitleaks configuration&quot;

# You have basically two options for your custom configuration:
#
# 1. define your own configuration, default rules do not apply
#
#    use e.g., the default configuration as starting point:
#    https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml
#
# 2. extend a configuration, the rules are overwritten or extended
#
#    When you extend a configuration the extended rules take precedence over the
#    default rules. I.e., if there are duplicate rules in both the extended
#    configuration and the default configuration the extended rules or
#    attributes of them will override the default rules.
#    Another thing to know with extending configurations is you can chain
#    together multiple configuration files to a depth of 2. Allowlist arrays are
#    appended and can contain duplicates.

# useDefault and path can NOT be used at the same time. Choose one.
[extend]
# useDefault will extend the default gitleaks config built in to the binary
# the latest version is located at:
# https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml
useDefault = true
# or you can provide a path to a configuration to extend from.
# The path is relative to where gitleaks was invoked,
# not the location of the base config.
# path = &quot;common_config.toml&quot;
# If there are any rules you don&#039;t want to inherit, they can be specified here.
disabledRules = [ &quot;generic-api-key&quot;]

# An array of tables that contain information that define instructions
# on how to detect secrets
[[rules]]
# Unique identifier for this rule
id = &quot;awesome-rule-1&quot;

# Short human-readable description of the rule.
description = &quot;awesome rule 1&quot;

# Golang regular expression used to detect secrets. Note Golang&#039;s regex engine
# does not support lookaheads.
regex = &#039;&#039;&#039;one-go-style-regex-for-this-rule&#039;&#039;&#039;

# Int used to extract secret from regex match and used as the group that will have
# its entropy checked if `entropy` is set.
secretGroup = 3

# Float representing the minimum shannon entropy a regex group must have to be considered a secret.
entropy = 3.5

# Golang regular expression used to match paths. This can be used as a standalone rule or it can be used
# in conjunction with a valid `regex` entry.
path = &#039;&#039;&#039;a-file-path-regex&#039;&#039;&#039;

# Keywords are used for pre-regex check filtering. Rules that contain
# keywords will perform a quick string compare check to make sure the
# keyword(s) are in the content being scanned. Ideally these values should
# either be part of the identiifer or unique strings specific to the rule&#039;s regex
# (introduced in v8.6.0)
keywords = [
  &quot;auth&quot;,
  &quot;password&quot;,
  &quot;token&quot;,
]

# Array of strings used for metadata and reporting purposes.
tags = [&quot;tag&quot;,&quot;another tag&quot;]

    # ‚ö†Ô∏è In v8.21.0 `[rules.allowlist]` was replaced with `[[rules.allowlists]]`.
    # This change was backwards-compatible: instances of `[rules.allowlist]` still  work.
    #
    # You can define multiple allowlists for a rule to reduce false positives.
    # A finding will be ignored if _ANY_ `[[rules.allowlists]]` matches.
    [[rules.allowlists]]
    description = &quot;ignore commit A&quot;
    # When multiple criteria are defined the default condition is &quot;OR&quot;.
    # e.g., this can match on |commits| OR |paths| OR |stopwords|.
    condition = &quot;OR&quot;
    commits = [ &quot;commit-A&quot;, &quot;commit-B&quot;]
    paths = [
      &#039;&#039;&#039;go\.mod&#039;&#039;&#039;,
      &#039;&#039;&#039;go\.sum&#039;&#039;&#039;
    ]
    # note: stopwords targets the extracted secret, not the entire regex match
    # like &#039;regexes&#039; does. (stopwords introduced in 8.8.0)
    stopwords = [
      &#039;&#039;&#039;client&#039;&#039;&#039;,
      &#039;&#039;&#039;endpoint&#039;&#039;&#039;,
    ]

    [[rules.allowlists]]
    # The &quot;AND&quot; condition can be used to make sure all criteria match.
    # e.g., this matches if |regexes| AND |paths| are satisfied.
    condition = &quot;AND&quot;
    # note: |regexes| defaults to check the _Secret_ in the finding.
    # Acceptable values for |regexTarget| are &quot;secret&quot; (default), &quot;match&quot;, and &quot;line&quot;.
    regexTarget = &quot;match&quot;
    regexes = [ &#039;&#039;&#039;(?i)parseur[il]&#039;&#039;&#039; ]
    paths = [ &#039;&#039;&#039;package-lock\.json&#039;&#039;&#039; ]

# You can extend a particular rule from the default config. e.g., gitlab-pat
# if you have defined a custom token prefix on your GitLab instance
[[rules]]
id = &quot;gitlab-pat&quot;
# all the other attributes from the default rule are inherited

    [[rules.allowlists]]
    regexTarget = &quot;line&quot;
    regexes = [ &#039;&#039;&#039;MY-glpat-&#039;&#039;&#039; ]


# ‚ö†Ô∏è In v8.25.0 `[allowlist]` was replaced with `[[allowlists]]`.
#
# Global allowlists have a higher order of precedence than rule-specific allowlists.
# If a commit listed in the `commits` field below is encountered then that commit will be skipped and no
# secrets will be detected for said commit. The same logic applies for regexes and paths.
[[allowlists]]
description = &quot;global allow list&quot;
commits = [ &quot;commit-A&quot;, &quot;commit-B&quot;, &quot;commit-C&quot;]
paths = [
  &#039;&#039;&#039;gitleaks\.toml&#039;&#039;&#039;,
  &#039;&#039;&#039;(.*?)(jpg|gif|doc)&#039;&#039;&#039;
]
# note: (global) regexTarget defaults to check the _Secret_ in the finding.
# Acceptable values for regexTarget are &quot;match&quot; and &quot;line&quot;
regexTarget = &quot;match&quot;
regexes = [
  &#039;&#039;&#039;219-09-9999&#039;&#039;&#039;,
  &#039;&#039;&#039;078-05-1120&#039;&#039;&#039;,
  &#039;&#039;&#039;(9[0-9]{2}|666)-\d{2}-\d{4}&#039;&#039;&#039;,
]
# note: stopwords targets the extracted secret, not the entire regex match
# like &#039;regexes&#039; does. (stopwords introduced in 8.8.0)
stopwords = [
  &#039;&#039;&#039;client&#039;&#039;&#039;,
  &#039;&#039;&#039;endpoint&#039;&#039;&#039;,
]

# ‚ö†Ô∏è In v8.25.0, `[[allowlists]]` have a new field called |targetRules|.
#
# Common allowlists can be defined once and assigned to multiple rules using |targetRules|.
# This will only run on the specified rules, not globally.
[[allowlists]]
targetRules = [&quot;awesome-rule-1&quot;, &quot;awesome-rule-2&quot;]
description = &quot;Our test assets trigger false-positives in a couple rules.&quot;
paths = [&#039;&#039;&#039;tests/expected/._\.json$&#039;&#039;&#039;]
```

Refer to the default [gitleaks config](https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml) for examples or follow the [contributing guidelines](https://github.com/gitleaks/gitleaks/blob/master/CONTRIBUTING.md) if you would like to contribute to the default configuration. Additionally, you can check out [this gitleaks blog post](https://blog.gitleaks.io/stop-leaking-secrets-configuration-2-3-aeed293b1fbf) which covers advanced configuration setups.

### Additional Configuration

#### Composite Rules (Multi-part or `required` Rules)
In v8.28.0 Gitleaks introduced composite rules, which are made up of a single &quot;primary&quot; rule and one or more auxiliary or `required` rules. To create a composite rule, add a `[[rules.required]]` table to the primary rule specifying an `id` and optionally `withinLines` and/or `withinColumns` proximity constraints. A fragment is a chunk of content that Gitleaks processes at once (typically a file, part of a file, or git diff), and proximity matching instructs the primary rule to only report a finding if the auxiliary `required` rules also find matches within the specified area of the fragment.

**Proximity matching:** Using the `withinLines` and `withinColumns` fields instructs the primary rule to only report a finding if the auxiliary `required` rules also find matches within the specified proximity. You can set:

- **`withinLines: N`** - required findings must be within N lines (vertically)
- **`withinColumns: N`** - required findings must be within N characters (horizontally)
- **Both** - creates a rectangular search area (both constraints must be satisfied)
- **Neither** - fragment-level matching (required findings can be anywhere in the same fragment)

Here are diagrams illustrating each proximity behavior:

```
p = primary captured secret
a = auxiliary (required) captured secret
fragment = section of data gitleaks is looking at


    *Fragment-level proximity*
    Any required finding in the fragment
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§fragment‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚î§     ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ             ‚îÇa‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÇ‚úì MATCH‚îÇ
   ‚îÇ          ‚îå‚îÄ‚îê‚îî‚îÄ‚îò     ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ‚îå‚îÄ‚îê       ‚îÇp‚îÇ        ‚îÇ
   ‚îÇ‚îÇa‚îÇ    ‚îå‚îÄ‚îê‚îî‚îÄ‚îò        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ‚îî‚îÄ‚îò    ‚îÇa‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÇ‚úì MATCH‚îÇ
   ‚îî‚îÄ‚ñ≤‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ‚úì MATCH‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


   *Column bounded proximity*
   `withinColumns = 3`
          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚î§fragment‚îú‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚î§     ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ    ‚îÇ        ‚îÇa‚îÇ‚óÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÇ+1C ‚úì MATCH‚îÇ
   ‚îÇ          ‚îå‚îÄ‚îê‚îî‚îÄ‚îò     ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
   ‚îÇ‚îå‚îÄ‚îê ‚îÇ     ‚îÇp‚îÇ    ‚îÇ   ‚îÇ
‚îå‚îÄ‚îÄ‚ñ∂‚îÇa‚îÇ  ‚îå‚îÄ‚îê  ‚îî‚îÄ‚îò        ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚îÇ‚îî‚îÄ‚îò ‚îÇ‚îÇa‚îÇ‚óÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÇ-2C ‚úì MATCH‚îÇ
‚îÇ  ‚îÇ       ‚îò             ‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îî‚îÄ‚îÄ -3C ‚îÄ‚îÄ‚îÄ0C‚îÄ‚îÄ‚îÄ +3C ‚îÄ‚îò
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚îÇ -4C ‚úó NO‚îÇ
‚îî‚îÄ‚îÄ‚îÇ  MATCH  ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò


   *Line bounded proximity*
   `withinLines = 4`
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§fragment‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
  +4L‚îÄ ‚îÄ ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÄ ‚îÄ ‚îÄ‚îÇ
 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[fullstorydev/grpcurl]]></title>
            <link>https://github.com/fullstorydev/grpcurl</link>
            <guid>https://github.com/fullstorydev/grpcurl</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[Like cURL, but for gRPC: Command-line tool for interacting with gRPC servers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fullstorydev/grpcurl">fullstorydev/grpcurl</a></h1>
            <p>Like cURL, but for gRPC: Command-line tool for interacting with gRPC servers</p>
            <p>Language: Go</p>
            <p>Stars: 12,189</p>
            <p>Forks: 550</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># gRPCurl
[![Build Status](https://circleci.com/gh/fullstorydev/grpcurl/tree/master.svg?style=svg)](https://circleci.com/gh/fullstorydev/grpcurl/tree/master)
[![Go Report Card](https://goreportcard.com/badge/github.com/fullstorydev/grpcurl)](https://goreportcard.com/report/github.com/fullstorydev/grpcurl)
[![Snap Release Status](https://snapcraft.io/grpcurl/badge.svg)](https://snapcraft.io/grpcurl)

`grpcurl` is a command-line tool that lets you interact with gRPC servers. It&#039;s
basically `curl` for gRPC servers.

The main purpose for this tool is to invoke RPC methods on a gRPC server from the
command-line. gRPC servers use a binary encoding on the wire
([protocol buffers](https://developers.google.com/protocol-buffers/), or &quot;protobufs&quot;
for short). So they are basically impossible to interact with using regular `curl`
(and older versions of `curl` that do not support HTTP/2 are of course non-starters).
This program accepts messages using JSON encoding, which is much more friendly for both
humans and scripts.

With this tool you can also browse the schema for gRPC services, either by querying
a server that supports [server reflection](https://github.com/grpc/grpc/blob/master/src/proto/grpc/reflection/v1/reflection.proto),
by reading proto source files, or by loading in compiled &quot;protoset&quot; files (files that contain
encoded file [descriptor protos](https://github.com/google/protobuf/blob/master/src/google/protobuf/descriptor.proto)).
In fact, the way the tool transforms JSON request data into a binary encoded protobuf
is using that very same schema. So, if the server you interact with does not support
reflection, you will either need the proto source files that define the service or need
protoset files that `grpcurl` can use.

This repo also provides a library package, `github.com/fullstorydev/grpcurl`, that has
functions for simplifying the construction of other command-line tools that dynamically
invoke gRPC endpoints. This code is a great example of how to use the various packages of
the [protoreflect](https://godoc.org/github.com/jhump/protoreflect) library, and shows
off what they can do.

See also the [`grpcurl` talk at GopherCon 2018](https://www.youtube.com/watch?v=dDr-8kbMnaw).

## Features
`grpcurl` supports all kinds of RPC methods, including streaming methods. You can even
operate bi-directional streaming methods interactively by running `grpcurl` from an
interactive terminal and using stdin as the request body!

`grpcurl` supports both secure/TLS servers _and_ plain-text servers (i.e. no TLS) and has
numerous options for TLS configuration. It also supports mutual TLS, where the client is
required to present a client certificate.

As mentioned above, `grpcurl` works seamlessly if the server supports the reflection
service. If not, you can supply the `.proto` source files or you can supply protoset
files (containing compiled descriptors, produced by `protoc`) to `grpcurl`.

## Installation

### Binaries

Download the binary from the [releases](https://github.com/fullstorydev/grpcurl/releases) page.

### Homebrew (macOS)

On macOS, `grpcurl` is available via Homebrew:
```shell
brew install grpcurl
```

### Docker

For platforms that support Docker, you can download an image that lets you run `grpcurl`:
```shell
# Download image
docker pull fullstorydev/grpcurl:latest
# Run the tool
docker run fullstorydev/grpcurl api.grpc.me:443 list
```
Note that there are some pitfalls when using docker:
- If you need to interact with a server listening on the host&#039;s loopback network, you must specify the host as `host.docker.internal` instead of `localhost` (for Mac or Windows) _OR_ have the container use the host network with `-network=&quot;host&quot;` (Linux only).
- If you need to provide proto source files or descriptor sets, you must mount the folder containing the files as a volume (`-v $(pwd):/protos`) and adjust the import paths to container paths accordingly.
- If you want to provide the request message via stdin, using the `-d @` option, you need to use the `-i` flag on the docker command.

### Other Packages

There are numerous other ways to install `grpcurl`, thanks to support from third parties that
have created recipes/packages for it. These include other ways to install `grpcurl` on a variety
of environments, including Windows and myriad Linux distributions.

You can see more details and the full list of other packages for `grpcurl` at _repology.org_:
https://repology.org/project/grpcurl/information

### Snap

You can install `grpcurl` using the snap package:

`snap install grpcurl`

### From Source
If you already have the [Go SDK](https://golang.org/doc/install) installed, you can use the `go`
tool to install `grpcurl`:
```shell
go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest
```

This installs the command into the `bin` sub-folder of wherever your `$GOPATH`
environment variable points. (If you have no `GOPATH` environment variable set,
the default install location is `$HOME/go/bin`). If this directory is already in
your `$PATH`, then you should be good to go.

If you have already pulled down this repo to a location that is not in your
`$GOPATH` and want to build from the sources, you can `cd` into the repo and then
run `make install`.

If you encounter compile errors and are using a version of the Go SDK older than 1.13,
you could have out-dated versions of `grpcurl`&#039;s dependencies. You can update the
dependencies by running `make updatedeps`. Or, if you are using Go 1.11 or 1.12, you
can add `GO111MODULE=on` as a prefix to the commands above, which will also build using
the right versions of dependencies (vs. whatever you may already have in your `GOPATH`).

## Usage
The usage doc for the tool explains the numerous options:
```shell
grpcurl -help
```

In the sections below, you will find numerous examples demonstrating how to use
`grpcurl`.

### Invoking RPCs
Invoking an RPC on a trusted server (e.g. TLS without self-signed key or custom CA)
that requires no client certs and supports server reflection is the simplest thing to
do with `grpcurl`. This minimal invocation sends an empty request body:
```shell
grpcurl grpc.server.com:443 my.custom.server.Service/Method

# no TLS
grpcurl -plaintext grpc.server.com:80 my.custom.server.Service/Method
```

To send a non-empty request, use the `-d` argument. Note that all arguments must come
*before* the server address and method name:
```shell
grpcurl -d &#039;{&quot;id&quot;: 1234, &quot;tags&quot;: [&quot;foo&quot;,&quot;bar&quot;]}&#039; \
    grpc.server.com:443 my.custom.server.Service/Method
```

As can be seen in the example, the supplied body must be in JSON format. The body will
be parsed and then transmitted to the server in the protobuf binary format.

If you want to include `grpcurl` in a command pipeline, such as when using `jq` to
create a request body, you can use `-d @`, which tells `grpcurl` to read the actual
request body from stdin:
```shell
grpcurl -d @ grpc.server.com:443 my.custom.server.Service/Method &lt;&lt;EOM
{
  &quot;id&quot;: 1234,
  &quot;tags&quot;: [
    &quot;foor&quot;,
    &quot;bar&quot;
  ]
}
EOM
```
### Adding Headers/Metadata to Request
Adding of headers / metadata to a rpc request is possible via the `-H name:value` command line option. Multiple headers can be added in a similar fashion.
Example :
```shell
grpcurl -H header1:value1 -H header2:value2 -d &#039;{&quot;id&quot;: 1234, &quot;tags&quot;: [&quot;foo&quot;,&quot;bar&quot;]}&#039; grpc.server.com:443 my.custom.server.Service/Method
```
For more usage guide, check out the help docs via `grpcurl -help`

### Listing Services
To list all services exposed by a server, use the &quot;list&quot; verb. When using `.proto` source
or protoset files instead of server reflection, this lists all services defined in the
source or protoset files.
```shell
# Server supports reflection
grpcurl localhost:8787 list

# Using compiled protoset files
grpcurl -protoset my-protos.bin list

# Using proto sources
grpcurl -import-path ../protos -proto my-stuff.proto list

# Export proto files (use -proto-out-dir to specify the output directory)
grpcurl -plaintext -proto-out-dir &quot;out_protos&quot; &quot;localhost:8787&quot; describe my.custom.server.Service

# Export protoset file (use -protoset-out to specify the output file)
grpcurl -plaintext -protoset-out &quot;out.protoset&quot; &quot;localhost:8787&quot; describe my.custom.server.Service

```

The &quot;list&quot; verb also lets you see all methods in a particular service:
```shell
grpcurl localhost:8787 list my.custom.server.Service
```

### Describing Elements
The &quot;describe&quot; verb will print the type of any symbol that the server knows about
or that is found in a given protoset file. It also prints a description of that
symbol, in the form of snippets of proto source. It won&#039;t necessarily be the
original source that defined the element, but it will be equivalent.

```shell
# Server supports reflection
grpcurl localhost:8787 describe my.custom.server.Service.MethodOne

# Using compiled protoset files
grpcurl -protoset my-protos.bin describe my.custom.server.Service.MethodOne

# Using proto sources
grpcurl -import-path ../protos -proto my-stuff.proto describe my.custom.server.Service.MethodOne
```

## Descriptor Sources
The `grpcurl` tool can operate on a variety of sources for descriptors. The descriptors
are required, in order for `grpcurl` to understand the RPC schema, translate inputs
into the protobuf binary format as well as translate responses from the binary format
into text. The sections below document the supported sources and what command-line flags
are needed to use them.

### Server Reflection

Without any additional command-line flags, `grpcurl` will try to use [server reflection](https://github.com/grpc/grpc/blob/master/src/proto/grpc/reflection/v1/reflection.proto).

Examples for how to set up server reflection can be found [here](https://github.com/grpc/grpc/blob/master/doc/server-reflection.md#known-implementations).

When using reflection, the server address (host:port or path to Unix socket) is required
even for &quot;list&quot; and &quot;describe&quot; operations, so that `grpcurl` can connect to the server
and ask it for its descriptors.

### Proto Source Files
To use `grpcurl` on servers that do not support reflection, you can use `.proto` source
files.

In addition to using `-proto` flags to point `grpcurl` at the relevant proto source file(s),
you may also need to supply `-import-path` flags to tell `grpcurl` the folders from which
dependencies can be imported.

Just like when compiling with `protoc`, you do *not* need to provide an import path for the
location of the standard protos included with `protoc` (which contain various &quot;well-known
types&quot; with a package definition of `google.protobuf`). These files are &quot;known&quot; by `grpcurl`
as a snapshot of their descriptors is built into the `grpcurl` binary.

When using proto sources, you can omit the server address (host:port or path to Unix socket)
when using the &quot;list&quot; and &quot;describe&quot; operations since they only need to consult the proto
source files.

### Protoset Files
You can also use compiled protoset files with `grpcurl`. If you are scripting `grpcurl` and
need to re-use the same proto sources for many invocations, you will see better performance
by using protoset files (since it skips the parsing and compilation steps with each
invocation).

Protoset files contain binary encoded `google.protobuf.FileDescriptorSet` protos. To create
a protoset file, invoke `protoc` with the `*.proto` files that define the service:
```shell
protoc --proto_path=. \
    --descriptor_set_out=myservice.protoset \
    --include_imports \
    my/custom/server/service.proto
```

The `--descriptor_set_out` argument is what tells `protoc` to produce a protoset,
and the `--include_imports` argument is necessary for the protoset to contain
everything that `grpcurl` needs to process and understand the schema.

When using protosets, you can omit the server address (host:port or path to Unix socket)
when using the &quot;list&quot; and &quot;describe&quot; operations since they only need to consult the
protoset files.

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mudler/edgevpn]]></title>
            <link>https://github.com/mudler/edgevpn</link>
            <guid>https://github.com/mudler/edgevpn</guid>
            <pubDate>Thu, 06 Nov 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[‚õµ The immutable, decentralized, statically built p2p VPN without any central server and automatic discovery! Create decentralized introspectable tunnels over p2p with shared tokens]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mudler/edgevpn">mudler/edgevpn</a></h1>
            <p>‚õµ The immutable, decentralized, statically built p2p VPN without any central server and automatic discovery! Create decentralized introspectable tunnels over p2p with shared tokens</p>
            <p>Language: Go</p>
            <p>Stars: 1,632</p>
            <p>Forks: 162</p>
            <p>Stars today: 233 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
	&lt;img src=&quot;https://user-images.githubusercontent.com/2420543/144679248-1f6e4c10-a558-424c-b6f5-b3695269c906.png&quot; width=128
         alt=&quot;logo&quot;&gt;&lt;br&gt;
    EdgeVPN

&lt;br&gt;
&lt;/h1&gt;

&lt;h3 align=&quot;center&quot;&gt;Create Decentralized private networks &lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/licence-GPL3-brightgreen&quot;
         alt=&quot;license&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/mudler/edgevpn/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/mudler/edgevpn&quot;&gt;&lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/badge/made%20with-Go-blue&quot;&gt;
  &lt;img src=&quot;https://goreportcard.com/badge/github.com/mudler/edgevpn&quot; alt=&quot;go report card&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
	 &lt;br&gt;
    Fully Decentralized. Immutable. Portable. Easy to use Statically compiled VPN and a reverse proxy over p2p.&lt;br&gt;
    &lt;b&gt;VPN&lt;/b&gt; -  &lt;b&gt;Reverse Proxy&lt;/b&gt; - &lt;b&gt;Send files securely over p2p&lt;/b&gt; -  &lt;b&gt;Blockchain&lt;/b&gt;
&lt;/p&gt;


EdgeVPN uses libp2p to build private decentralized networks that can be accessed via shared secrets.

It can:

- **Create a VPN** :  Secure VPN between p2p peers
  - Automatically assign IPs to nodes
  - Embedded tiny DNS server to resolve internal/external IPs
  - Create trusted zones to prevent network access if token is leaked
  - For example, the [Kairos](https://github.com/kairos-io/kairos) CNCF project uses it as a layer for creating decentralized clusters with Kubernetes

- **Act as a reverse Proxy** : Share a tcp service like you would do with `ngrok`. EdgeVPN let expose TCP services to the p2p network nodes without establishing a VPN connection: creates reverse proxy and tunnels traffic into the p2p network.

- **Send files via p2p** : Send files over p2p between nodes without establishing a VPN connection.

- **Be used as a library**: Plug a distributed p2p ledger easily in your golang code! For example EdgeVPN powers [LocalAI](https://github.com/mudler/LocalAI)&#039;s P2P features (you can learn more about it [here](https://localai.io/features/distribute/)).

See the [documentation](https://mudler.github.io/edgevpn).

# :camera: Screenshots

Dashboard (Dark mode)            |  Dashboard (Light mode)
:-------------------------:|:-------------------------:
![Screenshot 2021-10-31 at 00-12-16 EdgeVPN - Machines index](https://user-images.githubusercontent.com/2420543/163020448-8e9238c1-3b6d-435d-9b25-7729d8779ebd.png) | ![Screenshot 2021-10-31 at 23-03-26 EdgeVPN - Machines index](https://user-images.githubusercontent.com/2420543/163020460-e18c07d7-8426-4992-aab3-0b2fd90279ae.png)

DNS            |  Machine index
:-------------------------:|:-------------------------:
![Screenshot 2021-10-31 at 23-03-44 EdgeVPN - Services index](https://user-images.githubusercontent.com/2420543/163020465-3d481da4-4912-445e-afc0-2614966dcadf.png) | ![Screenshot 2021-10-31 at 23-03-59 EdgeVPN - Files index](https://user-images.githubusercontent.com/2420543/163020462-7821a622-8c13-4971-8abe-9c5b6b491ae8.png)

Services            |  Blockchain index
:-------------------------:|:-------------------------:
![Screenshot 2021-10-31 at 23-04-12 EdgeVPN - Users connected](https://user-images.githubusercontent.com/2420543/163021285-3c5a980d-2562-4c10-b266-7e99f19d8a87.png) | ![Screenshot 2021-10-31 at 23-04-20 EdgeVPN - Blockchain index](https://user-images.githubusercontent.com/2420543/163020457-77ef6e50-40a6-4e3b-83c4-a81db729bd7d.png)


# :new: GUI

A Desktop GUI application (alpha) for Linux is available [here](https://github.com/mudler/edgevpn-gui)

Dashboard            |  Connections index
:-------------------------:|:-------------------------:
![edgevpn-gui-2](https://user-images.githubusercontent.com/2420543/147854909-a223a7c1-5caa-4e90-b0ac-0ae04dc0949d.png) | ![edgevpn-3](https://user-images.githubusercontent.com/2420543/147854904-09d96991-8752-421a-a301-8f0bdd9d5542.png)
![edgevpn-gui](https://user-images.githubusercontent.com/2420543/147854907-1e4a4715-3181-4dc2-8bc0-d052b3bf46d3.png) | 

# Kubernetes 

Check out [Kairos](https://github.com/kairos-io/kairos) for seeing EdgeVPN in action with Kubernetes!

# :running: Installation

Download the precompiled static release in the [releases page](https://github.com/mudler/edgevpn/releases). You can either install it in your system or just run it.

# :computer: Usage

EdgeVPN works by generating tokens (or a configuration file) that can be shared between different machines, hosts or peers to access to a decentralized secured network between them.

Every token is unique and identifies the network,  no central server setup, or specifying hosts ip is required.

To generate a config run:

```bash
# Generate a new config file and use it later as EDGEVPNCONFIG
$ edgevpn -g &gt; config.yaml
```

OR to generate a portable token:

```bash
$ EDGEVPNTOKEN=$(edgevpn -g -b)
```

Note, tokens are config merely encoded in base64, so this is equivalent:

```bash
$ EDGEVPNTOKEN=$(edgevpn -g | tee config.yaml | base64 -w0)
```

All edgevpn commands implies that you either specify a `EDGEVPNTOKEN` (or `--token` as parameter) or a `EDGEVPNCONFIG` as this is the way for `edgevpn` to establish a network between the nodes. 

The configuration file is the network definition and allows you to connect over to your peers securely.

**Warning** Exposing this file or passing-it by is equivalent to give full control to the network.

## :satellite: As a VPN

To start the VPN, simply run `edgevpn` without any argument.

An example of running edgevpn on multiple hosts:

```bash
# on Node A
$ EDGEVPNTOKEN=.. edgevpn --address 10.1.0.11/24
# on Node B
$ EDGEVPNTOKEN=.. edgevpn --address 10.1.0.12/24
# on Node C ...
$ EDGEVPNTOKEN=.. edgevpn --address 10.1.0.13/24
...
```

... and that&#039;s it! the `--address` is a _virtual_ unique IP for each node, and it is actually the ip where the node will be reachable to from the vpn. You can assign IPs freely to the nodes of the network, while you can override the default `edgevpn0` interface with `IFACE` (or `--interface`)

*Note*: It might take up time to build the connection between nodes. Wait at least 5 mins, it depends on the network behind the hosts.


# :question: Is it for me?

EdgeVPN makes VPN decentralization a first strong requirement. 

Its main use is for edge and low-end devices and especially for development.

The decentralized approach has few cons:

- The underlying network is chatty. It uses a Gossip protocol for synchronizing the routing table and p2p. Every blockchain message is broadcasted to all peers, while the traffic is to the host only.
- Might be not suited for low latency workload.

Keep that in mind before using it for your prod networks!

But it has a strong pro: it just works everywhere libp2p works!

# :question: Why? 

First of all it&#039;s my first experiment with libp2p. Second, I always wanted a more &quot;open&quot; `ngrok` alternative, but I always prefer to have &quot;less infra&quot; as possible to maintain. That&#039;s why building something like this on top of `libp2p` makes sense.

# :warning: Warning!

I&#039;m not a security expert, and this software didn&#039;t went through a full security audit, so don&#039;t use and rely on it for sensible traffic and not even for production environment! I did this mostly for fun while I was experimenting with libp2p. 

## Example use case: network-decentralized [k3s](https://github.com/k3s-io/k3s) test cluster

Let&#039;s see a practical example, you are developing something for kubernetes and you want to try a multi-node setup, but you have machines available that are only behind NAT (pity!) and you would really like to leverage HW.

If you are not really interested in network performance (again, that&#039;s for development purposes only!) then you could use `edgevpn` + [k3s](https://github.com/k3s-io/k3s) in this way:

1) Generate edgevpn config: `edgevpn -g &gt; vpn.yaml`
2) Start the vpn:

   on node A: `sudo IFACE=edgevpn0 ADDRESS=10.1.0.3/24 EDGEVPNCONFIG=vpn.yml edgevpn`
   
   on node B: `sudo IFACE=edgevpn0 ADDRESS=10.1.0.4/24 EDGEVPNCONFIG=vpm.yml edgevpn`
3) Start k3s:
 
   on node A: `k3s server --flannel-iface=edgevpn0`
   
   on node B: `K3S_URL=https://10.1.0.3:6443 K3S_TOKEN=xx k3s agent --flannel-iface=edgevpn0 --node-ip 10.1.0.4`

We have used flannel here, but other CNI should work as well.


# :notebook: As a library

EdgeVPN can be used as a library. It is very portable and offers a functional interface.

To join a node in a network from a token, without starting the vpn:

```golang

import (
    node &quot;github.com/mudler/edgevpn/pkg/node&quot;
)

e := node.New(
    node.Logger(l),
    node.LogLevel(log.LevelInfo),
    node.MaxMessageSize(2 &lt;&lt; 20),
    node.FromBase64( mDNSEnabled, DHTEnabled, token ),
    // ....
  )

e.Start(ctx)

```

or to start a VPN:

```golang

import (
    vpn &quot;github.com/mudler/edgevpn/pkg/vpn&quot;
    node &quot;github.com/mudler/edgevpn/pkg/node&quot;
)

opts, err := vpn.Register(vpnOpts...)
if err != nil {
	return err
}

e := edgevpn.New(append(o, opts...)...)

e.Start(ctx)
```

# üßë‚Äçüíª Projects using EdgeVPN

- [Kairos](https://github.com/kairos-io/kairos) - creates Kubernetes clusters with K3s automatically using EdgeVPN networks


# üêú Contribution

You can improve this project by contributing in following ways:

- report bugs
- fix issues
- request features
- asking questions (just open an issue)

and any other way if not mentioned here.

# :notebook: Credits

- The awesome [libp2p](https://github.com/libp2p) library
- [https://github.com/songgao/water](https://github.com/songgao/water) for tun/tap devices in golang
- [Room example](https://github.com/libp2p/go-libp2p/tree/master/examples/chat-with-rendezvous) (shamelessly parts are copied by)
- Logo originally made by [Uniconlabs](https://www.flaticon.com/authors/uniconlabs) from [www.flaticon.com](https://www.flaticon.com/), modified by me

# :notebook: Troubleshooting

If during bootstrap you see messages like:

```
edgevpn[3679]:             * [/ip4/104.131.131.82/tcp/4001] failed to negotiate stream multiplexer: context deadline exceeded     
```

or

```
edgevpn[9971]: 2021/12/16 20:56:34 failed to sufficiently increase receive buffer size (was: 208 kiB, wanted: 2048 kiB, got: 416 kiB). See https://github.com/lucas-clemente/quic-go/wiki/UDP-Receive-Buffer-Size for details.
```

or generally experiencing poor network performance, it is recommended to increase the maximum buffer size by running:

```
sysctl -w net.core.rmem_max=2500000
```

# :notebook: TODO

- [x] VPN
- [x] Send and receive files via p2p
- [x] Expose remote/local services via p2p tunnelling
- [x] Store arbitrary data on the blockchain
- [x] Allow to persist blockchain on disk

# :notebook: LICENSE

Apache License v2.

```
edgevpn  Copyright (C) 2021 Ettore Di Giacinto
This program comes with ABSOLUTELY NO WARRANTY.
This is free software, and you are welcome to redistribute it
under certain conditions.
```
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>