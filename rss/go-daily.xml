<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Wed, 18 Feb 2026 00:08:30 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[steipete/gogcli]]></title>
            <link>https://github.com/steipete/gogcli</link>
            <guid>https://github.com/steipete/gogcli</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:30 GMT</pubDate>
            <description><![CDATA[Google Suite CLI: Gmail, GCal, GDrive, GContacts.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/steipete/gogcli">steipete/gogcli</a></h1>
            <p>Google Suite CLI: Gmail, GCal, GDrive, GContacts.</p>
            <p>Language: Go</p>
            <p>Stars: 3,855</p>
            <p>Forks: 319</p>
            <p>Stars today: 469 stars today</p>
            <h2>README</h2><pre># üß≠ gogcli ‚Äî Google in your terminal.

![GitHub Repo Banner](https://ghrb.waren.build/banner?header=gogcli%F0%9F%A7%AD&amp;subheader=Google+in+your+terminal&amp;bg=f3f4f6&amp;color=1f2937&amp;support=true)
&lt;!-- Created with GitHub Repo Banner by Waren Gonzaga: https://ghrb.waren.build --&gt;

Fast, script-friendly CLI for Gmail, Calendar, Chat, Classroom, Drive, Docs, Slides, Sheets, Forms, Apps Script, Contacts, Tasks, People, Groups (Workspace), and Keep (Workspace-only). JSON-first output, multiple accounts, and least-privilege auth built in.

## Features

- **Gmail** - search threads and messages, send emails, view attachments, manage labels/drafts/filters/delegation/vacation settings, history, and watch (Pub/Sub push)
- **Email tracking** - track opens for `gog gmail send --track` with a small Cloudflare Worker backend
- **Calendar** - list/create/update events, detect conflicts, manage invitations, check free/busy status, team calendars, propose new times, focus/OOO/working-location events, recurrence + reminders
- **Classroom** - manage courses, roster, coursework/materials, submissions, announcements, topics, invitations, guardians, profiles
- **Chat** - list/find/create spaces, list messages/threads (filter by thread/unread), send messages and DMs (Workspace-only)
- **Drive** - list/search/upload/download files, manage permissions/comments, organize folders, list shared drives
- **Contacts** - search/create/update contacts, access Workspace directory/other contacts
- **Tasks** - manage tasklists and tasks: get/create/add/update/done/undo/delete/clear, repeat schedules
- **Sheets** - read/write/update spreadsheets, insert rows/cols, format cells, read notes, create new sheets (and export via Drive)
- **Forms** - create/get forms and inspect responses
- **Apps Script** - create/get projects, inspect content, and run functions
- **Docs/Slides** - export to PDF/DOCX/PPTX via Drive (plus create/copy, docs-to-text)
- **People** - access profile information
- **Keep (Workspace only)** - list/get/search notes and download attachments (service account + domain-wide delegation)
- **Groups** - list groups you belong to, view group members (Google Workspace)
- **Local time** - quick local/UTC time display for scripts and agents
- **Multiple accounts** - manage multiple Google accounts simultaneously (with aliases)
- **Command allowlist** - restrict top-level commands for sandboxed/agent runs
- **Secure credential storage** using OS keyring or encrypted on-disk keyring (configurable)
- **Auto-refreshing tokens** - authenticate once, use indefinitely
- **Least-privilege auth** - `--readonly` and `--drive-scope` to request fewer scopes
- **Workspace service accounts** - domain-wide delegation auth (preferred when configured)
- **Parseable output** - JSON mode for scripting and automation (Calendar adds day-of-week fields)

## Installation

### Homebrew

```bash
brew install steipete/tap/gogcli
```
### Arch User Repository

```bash
yay -S gogcli
```

### Build from Source

```bash
git clone https://github.com/steipete/gogcli.git
cd gogcli
make
```

Run:

```bash
./bin/gog --help
```

Help:

- `gog --help` shows top-level command groups.
- Drill down with `gog &lt;group&gt; --help` (and deeper subcommands).
- For the full expanded command list: `GOG_HELP=full gog --help`.
- Make shortcut: `make gog -- --help` (or `make gog -- gmail --help`).
- `make gog-help` shows CLI help (note: `make gog --help` is Make‚Äôs own help; use `--`).
- Version: `gog --version` or `gog version`.

## Quick Start

### 1. Get OAuth2 Credentials

Before adding an account, create OAuth2 credentials from Google Cloud Console:

1. Open the Google Cloud Console credentials page: https://console.cloud.google.com/apis/credentials
1. Create a project: https://console.cloud.google.com/projectcreate
2. Enable the APIs you need:
   - Gmail API: https://console.cloud.google.com/apis/api/gmail.googleapis.com
   - Google Calendar API: https://console.cloud.google.com/apis/api/calendar-json.googleapis.com
   - Google Chat API: https://console.cloud.google.com/apis/api/chat.googleapis.com
   - Google Drive API: https://console.cloud.google.com/apis/api/drive.googleapis.com
   - Google Classroom API: https://console.cloud.google.com/apis/api/classroom.googleapis.com
   - People API (Contacts): https://console.cloud.google.com/apis/api/people.googleapis.com
   - Google Tasks API: https://console.cloud.google.com/apis/api/tasks.googleapis.com
   - Google Sheets API: https://console.cloud.google.com/apis/api/sheets.googleapis.com
   - Google Forms API: https://console.cloud.google.com/apis/api/forms.googleapis.com
   - Apps Script API: https://console.cloud.google.com/apis/api/script.googleapis.com
   - Cloud Identity API (Groups): https://console.cloud.google.com/apis/api/cloudidentity.googleapis.com
3. Configure OAuth consent screen: https://console.cloud.google.com/auth/branding
4. If your app is in &quot;Testing&quot;, add test users: https://console.cloud.google.com/auth/audience
5. Create OAuth client:
   - Go to https://console.cloud.google.com/auth/clients
   - Click &quot;Create Client&quot;
   - Application type: &quot;Desktop app&quot;
   - Download the JSON file (usually named `client_secret_....apps.googleusercontent.com.json`)

### 2. Store Credentials

```bash
gog auth credentials ~/Downloads/client_secret_....json
```

For multiple OAuth clients/projects:

```bash
gog --client work auth credentials ~/Downloads/work-client.json
gog auth credentials list
```

### 3. Authorize Your Account

```bash
gog auth add you@gmail.com
```

This will open a browser window for OAuth authorization. The refresh token is stored securely in your system keychain.

Headless / remote server flows (no browser on the server):

Manual interactive flow (recommended):

```bash
gog auth add you@gmail.com --services user --manual
```

- The CLI prints an auth URL. Open it in a local browser.
- After approval, copy the full loopback redirect URL from the browser address bar.
- Paste that URL back into the terminal when prompted.

Split remote flow (`--remote`, useful for two-step/scripted handoff):

```bash
# Step 1: print auth URL (open it locally in a browser)
gog auth add you@gmail.com --services user --remote --step 1

# Step 2: paste the full redirect URL from your browser address bar
gog auth add you@gmail.com --services user --remote --step 2 --auth-url &#039;http://127.0.0.1:&lt;port&gt;/oauth2/callback?code=...&amp;state=...&#039;
```

- The `state` is cached on disk for a short time (about 10 minutes). If it expires, rerun step 1.
- Remote step 2 requires a redirect URL that includes `state` (state check mandatory).

### 4. Test Authentication

```bash
export GOG_ACCOUNT=you@gmail.com
gog gmail labels list
```

## Authentication &amp; Secrets

### Accounts and tokens

`gog` stores your OAuth refresh tokens in a ‚Äúkeyring‚Äù backend. Default is `auto` (best available backend for your OS/environment).

Before you can run `gog auth add`, you must store OAuth client credentials once via `gog auth credentials &lt;credentials.json&gt;` (download a Desktop app OAuth client JSON from the Cloud Console). For multiple clients, use `gog --client &lt;name&gt; auth credentials ...`; tokens are isolated per client.

List accounts:

```bash
gog auth list
```

Verify tokens are usable (helps spot revoked/expired tokens):

```bash
gog auth list --check
```

Accounts can be authorized either via OAuth refresh tokens or Workspace service accounts (domain-wide delegation). If a service account key is configured for an account, it takes precedence over OAuth refresh tokens (see `gog auth list`).

Show current auth state/services for the active account:

```bash
gog auth status
```

### Multiple OAuth clients

Use `--client` (or `GOG_CLIENT`) to select a named OAuth client:

```bash
gog --client work auth credentials ~/Downloads/work.json
gog --client work auth add you@company.com
```

Optional domain mapping for auto-selection:

```bash
gog --client work auth credentials ~/Downloads/work.json --domain example.com
```

How it works:

- Default client is `default` (stored in `credentials.json`).
- Named clients are stored as `credentials-&lt;client&gt;.json`.
- Tokens are isolated per client (`token:&lt;client&gt;:&lt;email&gt;`); defaults are per client too.

Client selection order (when `--client` is not set):

1) `--client` / `GOG_CLIENT`
2) `account_clients` config (email -&gt; client)
3) `client_domains` config (domain -&gt; client)
4) Credentials file named after the email domain (`credentials-example.com.json`)
5) `default`

Config example (JSON5):

```json5
{
  account_clients: { &quot;you@company.com&quot;: &quot;work&quot; },
  client_domains: { &quot;example.com&quot;: &quot;work&quot; },
}
```

List stored credentials:

```bash
gog auth credentials list
```

See `docs/auth-clients.md` for the full client selection and mapping rules.

### Keyring backend: Keychain vs encrypted file

Backends:

- `auto` (default): picks the best backend for the platform.
- `keychain`: macOS Keychain (recommended on macOS; avoids password management).
- `file`: encrypted on-disk keyring (requires a password).

Set backend via command (writes `keyring_backend` into `config.json`):

```bash
gog auth keyring file
gog auth keyring keychain
gog auth keyring auto
```

Show current backend + source (env/config/default) and config path:

```bash
gog auth keyring
```

Non-interactive runs (CI/ssh): file backend requires `GOG_KEYRING_PASSWORD`.

```bash
export GOG_KEYRING_PASSWORD=&#039;...&#039;
gog --no-input auth status
```

Force backend via env (overrides config):

```bash
export GOG_KEYRING_BACKEND=file
```

Precedence: `GOG_KEYRING_BACKEND` env var overrides `config.json`.

## Configuration

### Account Selection

Specify the account using either a flag or environment variable:

```bash
# Via flag
gog gmail search &#039;newer_than:7d&#039; --account you@gmail.com

# Via alias
gog auth alias set work work@company.com
gog gmail search &#039;newer_than:7d&#039; --account work

# Via environment
export GOG_ACCOUNT=you@gmail.com
gog gmail search &#039;newer_than:7d&#039;

# Auto-select (default account or the single stored token)
gog gmail labels list --account auto
```

List configured accounts:

```bash
gog auth list
```

### Output

- Default: human-friendly tables on stdout.
- `--plain`: stable TSV on stdout (tabs preserved; best for piping to tools that expect `\t`).
- `--json`: JSON on stdout (best for scripting).
- Human-facing hints/progress go to stderr.
- Colors are enabled only in rich TTY output and are disabled automatically for `--json` and `--plain`.

### Service Scopes

By default, `gog auth add` requests access to the **user** services (see `gog auth services` for the current list and scopes).

To request fewer scopes:

```bash
gog auth add you@gmail.com --services drive,calendar
```

To request read-only scopes (write operations will fail with 403 insufficient scopes):

```bash
gog auth add you@gmail.com --services drive,calendar --readonly
```

To control Drive‚Äôs scope (default: `full`):

```bash
gog auth add you@gmail.com --services drive --drive-scope full
gog auth add you@gmail.com --services drive --drive-scope readonly
gog auth add you@gmail.com --services drive --drive-scope file
```

Notes:

- `--drive-scope readonly` is enough for listing/downloading/exporting via Drive (write operations will 403).
- `--drive-scope file` is write-capable (limited to files created/opened by this app) and can‚Äôt be combined with `--readonly`.

If you need to add services later and Google doesn&#039;t return a refresh token, re-run with `--force-consent`:

```bash
gog auth add you@gmail.com --services user --force-consent
# Or add just Sheets
gog auth add you@gmail.com --services sheets --force-consent
```

`--services all` is accepted as an alias for `user` for backwards compatibility.

Docs commands are implemented via the Drive API, and `docs` requests both Drive and Docs API scopes.

Service scope matrix (auto-generated; run `go run scripts/gen-auth-services-md.go`):

&lt;!-- auth-services:start --&gt;
| Service | User | APIs | Scopes | Notes |
| --- | --- | --- | --- | --- |
| gmail | yes | Gmail API | `https://www.googleapis.com/auth/gmail.modify`&lt;br&gt;`https://www.googleapis.com/auth/gmail.settings.basic`&lt;br&gt;`https://www.googleapis.com/auth/gmail.settings.sharing` |  |
| calendar | yes | Calendar API | `https://www.googleapis.com/auth/calendar` |  |
| chat | yes | Chat API | `https://www.googleapis.com/auth/chat.spaces`&lt;br&gt;`https://www.googleapis.com/auth/chat.messages`&lt;br&gt;`https://www.googleapis.com/auth/chat.memberships`&lt;br&gt;`https://www.googleapis.com/auth/chat.users.readstate.readonly` |  |
| classroom | yes | Classroom API | `https://www.googleapis.com/auth/classroom.courses`&lt;br&gt;`https://www.googleapis.com/auth/classroom.rosters`&lt;br&gt;`https://www.googleapis.com/auth/classroom.coursework.students`&lt;br&gt;`https://www.googleapis.com/auth/classroom.coursework.me`&lt;br&gt;`https://www.googleapis.com/auth/classroom.courseworkmaterials`&lt;br&gt;`https://www.googleapis.com/auth/classroom.announcements`&lt;br&gt;`https://www.googleapis.com/auth/classroom.topics`&lt;br&gt;`https://www.googleapis.com/auth/classroom.guardianlinks.students`&lt;br&gt;`https://www.googleapis.com/auth/classroom.profile.emails`&lt;br&gt;`https://www.googleapis.com/auth/classroom.profile.photos` |  |
| drive | yes | Drive API | `https://www.googleapis.com/auth/drive` |  |
| docs | yes | Docs API, Drive API | `https://www.googleapis.com/auth/drive`&lt;br&gt;`https://www.googleapis.com/auth/documents` | Export/copy/create via Drive |
| slides | yes | Slides API, Drive API | `https://www.googleapis.com/auth/drive`&lt;br&gt;`https://www.googleapis.com/auth/presentations` | Create/edit presentations |
| contacts | yes | People API | `https://www.googleapis.com/auth/contacts`&lt;br&gt;`https://www.googleapis.com/auth/contacts.other.readonly`&lt;br&gt;`https://www.googleapis.com/auth/directory.readonly` | Contacts + other contacts + directory |
| tasks | yes | Tasks API | `https://www.googleapis.com/auth/tasks` |  |
| sheets | yes | Sheets API, Drive API | `https://www.googleapis.com/auth/drive`&lt;br&gt;`https://www.googleapis.com/auth/spreadsheets` | Export via Drive |
| people | yes | People API | `profile` | OIDC profile scope |
| forms | yes | Forms API | `https://www.googleapis.com/auth/forms.body`&lt;br&gt;`https://www.googleapis.com/auth/forms.responses.readonly` |  |
| appscript | yes | Apps Script API | `https://www.googleapis.com/auth/script.projects`&lt;br&gt;`https://www.googleapis.com/auth/script.deployments`&lt;br&gt;`https://www.googleapis.com/auth/script.processes` |  |
| groups | no | Cloud Identity API | `https://www.googleapis.com/auth/cloud-identity.groups.readonly` | Workspace only |
| keep | no | Keep API | `https://www.googleapis.com/auth/keep.readonly` | Workspace only; service account (domain-wide delegation) |
&lt;!-- auth-services:end --&gt;

### Service Accounts (Workspace only)

A service account is a non-human Google identity that belongs to a Google Cloud project. In Google Workspace, a service account can impersonate a user via **domain-wide delegation** (admin-controlled) and access APIs like Gmail/Calendar/Drive as that user.

In `gog`, service accounts are an **optional auth method** that can be configured per account email. If a service account key is configured for an account, it takes precedence over OAuth refresh tokens (see `gog auth list`).

#### 1) Create a Service Account (Google Cloud)

1. Create (or pick) a Google Cloud project.
2. Enable the APIs you‚Äôll use (e.g. Gmail, Calendar, Drive, Sheets, Docs, People, Tasks, Cloud Identity).
3. Go to **IAM &amp; Admin ‚Üí Service Accounts** and create a service account.
4. In the service account details, enable **Domain-wide delegation**.
5. Create a key (**Keys ‚Üí Add key ‚Üí Create new key ‚Üí JSON**) and download the JSON key file.

#### 2) Allowlist scopes (Google Workspace Admin Console)

Domain-wide delegation is enforced by Workspace admin settings.

1. Open **Admin console ‚Üí Security ‚Üí API controls ‚Üí Domain-wide delegation**.
2. Add a new API client:
   - Client ID: use the service account‚Äôs ‚ÄúClient ID‚Äù from Google Cloud.
   - OAuth scopes: comma-separated list of scopes you want to allow (copy from `gog auth services` and/or your `gog auth add --services ...` usage).

If a scope is missing from the allowlist, service-account token minting can fail (or API calls will 403 with insufficient permissions).

#### 3) Configure `gog` to use the service account

Store the key for the user you want to impersonate:

```bash
gog auth service-account set you@yourdomain.com --key ~/Downloads/service-account.json
```

Verify `gog` is preferring the service account for that account:

```bash
gog --account you@yourdomain.com auth status
gog auth list
```

### Google Keep (Workspace only)

Keep requires Workspace + domain-wide delegation. You can configure it via the generic service-account command above (recommended), or the legacy Keep helper:

```bash
gog auth service-account set you@yourdomain.com --key ~/Downloads/service-account.json
gog keep list --account you@yourdomain.com
gog keep get &lt;noteId&gt; --account you@yourdomain.com
```

### Environment Variables

- `GOG_ACCOUNT` - Default account email or alias to use (avoids repeating `--account`; otherwise uses keyring default or a single stored token)
- `GOG_CLIENT` - OAuth client name (selects stored credentials + token bucket)
- `GOG_JSON` - Default JSON output
- `GOG_PLAIN` - Default plain output
- `GOG_COLOR` - Color mode: `auto` (default), `always`, or `never`
- `GOG_TIMEZONE` - Default output timezone for Calendar/Gmail (IANA name, `UTC`, or `local`)
- `GOG_ENABLE_COMMANDS` - Comma-separated allowlist of top-level commands (e.g., `calendar,tasks`)

### Config File (JSON5)

Find the actual config path in `gog --help` or `gog auth keyring`.

Typical paths:

- macOS: `~/Library/Application Support/gogcli/config.json`
- Linux: `~/.config/gogcli/config.json` (or `$XDG_CONFIG_HOME/gogcli/config.json`)
- Windows: `%AppData%\\gogcli\\config.json`

Example (JSON5 supports comments and trailing commas):

```json5
{
  // Avoid macOS Keychain prompts
  keyring_backend: &quot;file&quot;,
  // Default output timezone for Calendar/Gmail (IANA, UTC, or local)
  default_timezone: &quot;UTC&quot;,
  // Optional account aliases
  account_aliases: {
    work: &quot;work@company.com&quot;,
    personal: &quot;me@gmail.com&quot;,
  },
  // Optional per-account OAuth client selection
  account_clients: {
    &quot;work@company.com&quot;: &quot;work&quot;,
  },
  // Optional domain -&gt; client mapping
  client_domains: {
    &quot;example.com&quot;: &quot;work&quot;,
  },
}
```

### Config Commands

```bash
gog config path
gog config list
gog config keys
gog config get default_timezone
gog config set default_timezone UTC
gog config unset default_timezone
```

### Account Aliases

```bash
gog auth alias set work work@company.com
gog auth alias list
gog auth alias unset work
```

Aliases work anywhere you pass `--account` or `GOG_ACCOUNT` (reserved: `auto`, `default`).

### Command Allowlist (Sandboxing)

```bash
# Only allow calendar + tasks commands for an agent
gog --enable-commands calendar,tasks calendar events --today

# Same via env
export GOG_ENABLE_COMMANDS=calendar,tasks
gog tasks list &lt;tasklistId&gt;
```
 
## Security

### Credential Storage

OAuth credentials are stored securely in your system&#039;s keychain:
- **macOS**: Keychain Access
- **Linux**: Secret Service (GNOME Keyring, KWallet)
- **Windows**: Credential Manager

The CLI uses [github.com/99designs/keyring](https://github.com/99designs/keyring) for secure storage.

If no OS keychain backend is available (e.g., Linux/WSL/container), keyring can fall back to an encrypted on-disk store and may prompt for a password; for non-interactive runs set `GOG_KEYRING_PASSWORD`.

### Keychain Prompts (macOS)

macOS Keychain may prompt more than you‚Äôd expect when the ‚Äúapp identity‚Äù keeps changing (different binary path, `go run` temp builds, rebuilding to new `./bin/gog`, multiple copies). Keychain treats those as different apps, so it asks again.

Options:

- **Default (recommended):** keep using Keychain (secure) and run a stable `gog` binary path to reduce

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[steipete/wacli]]></title>
            <link>https://github.com/steipete/wacli</link>
            <guid>https://github.com/steipete/wacli</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:29 GMT</pubDate>
            <description><![CDATA[WhatsApp CLI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/steipete/wacli">steipete/wacli</a></h1>
            <p>WhatsApp CLI</p>
            <p>Language: Go</p>
            <p>Stars: 442</p>
            <p>Forks: 71</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># üóÉÔ∏è wacli ‚Äî WhatsApp CLI: sync, search, send.

WhatsApp CLI built on top of `whatsmeow`, focused on:

- Best-effort local sync of message history + continuous capture
- Fast offline search
- Sending messages
- Contact + group management

This is a third-party tool that uses the WhatsApp Web protocol via `whatsmeow` and is not affiliated with WhatsApp.

## Status

Core implementation is in place. See `docs/spec.md` for the full design notes.

## Recent updates (0.2.0)

- Messages: search/list includes display text for reactions, replies, and media types.
- Send: `wacli send file --filename` to override the display name.
- Auth: optional `WACLI_DEVICE_LABEL` / `WACLI_DEVICE_PLATFORM` env overrides.

## Install / Build

Choose **one** of the following options.  
If you install via Homebrew, you can skip the local build step.

### Option A: Install via Homebrew (tap)

- `brew install steipete/tap/wacli`

### Option B: Build locally

- `go build -tags sqlite_fts5 -o ./dist/wacli ./cmd/wacli`

Run (local build only):

- `./dist/wacli --help`

## Quick start

Default store directory is `~/.wacli` (override with `--store DIR`).

```bash
# 1) Authenticate (shows QR), then bootstrap sync
pnpm wacli auth
# or: ./dist/wacli auth (after pnpm build)

# 2) Keep syncing (never shows QR; requires prior auth)
pnpm wacli sync --follow

# Diagnostics
pnpm wacli doctor

# Search messages
pnpm wacli messages search &quot;meeting&quot;

# Backfill older messages for a chat (best-effort; requires your primary device online)
pnpm wacli history backfill --chat 1234567890@s.whatsapp.net --requests 10 --count 50

# Download media for a message (after syncing)
./wacli media download --chat 1234567890@s.whatsapp.net --id &lt;message-id&gt;

# Send a message
pnpm wacli send text --to 1234567890 --message &quot;hello&quot;

# Send a file
./wacli send file --to 1234567890 --file ./pic.jpg --caption &quot;hi&quot;
# Or override display name
./wacli send file --to 1234567890 --file /tmp/abc123 --filename report.pdf

# List groups and manage participants
pnpm wacli groups list
pnpm wacli groups rename --jid 123456789@g.us --name &quot;New name&quot;
```

## Prior Art / Credit

This project is heavily inspired by (and learns from) the excellent `whatsapp-cli` by Vicente Reig:

- [`whatsapp-cli`](https://github.com/vicentereig/whatsapp-cli)

## High-level UX

- `wacli auth`: interactive login (shows QR code), then immediately performs initial data sync.
- `wacli sync`: non-interactive sync loop (never shows QR; errors if not authenticated).
- Output is human-readable by default; pass `--json` for machine-readable output.

## Storage

Defaults to `~/.wacli` (override with `--store DIR`).

## Environment overrides

- `WACLI_DEVICE_LABEL`: set the linked device label (shown in WhatsApp).
- `WACLI_DEVICE_PLATFORM`: override the linked device platform (defaults to `CHROME` if unset or invalid).

## Backfilling older history

`wacli sync` stores whatever WhatsApp Web sends opportunistically. To try to fetch *older* messages, use on-demand history sync requests to your **primary device** (your phone).

Important notes:

- This is **best-effort**: WhatsApp may not return full history.
- Your **primary device must be online**.
- Requests are **per chat** (DM or group). `wacli` uses the *oldest locally stored message* in that chat as the anchor.
- Recommended `--count` is `50` per request.

### Backfill one chat

```bash
pnpm wacli history backfill --chat 1234567890@s.whatsapp.net --requests 10 --count 50
```

### Backfill all chats (script)

This loops through chats already known in your local DB:

```bash
pnpm -s wacli -- --json chats list --limit 100000 \
  | jq -r &#039;.[].JID&#039; \
  | while read -r jid; do
      pnpm -s wacli -- history backfill --chat &quot;$jid&quot; --requests 3 --count 50
    done
```

## License

See `LICENSE`.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[quic-go/quic-go]]></title>
            <link>https://github.com/quic-go/quic-go</link>
            <guid>https://github.com/quic-go/quic-go</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:28 GMT</pubDate>
            <description><![CDATA[A production-ready QUIC implementation in pure Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/quic-go/quic-go">quic-go/quic-go</a></h1>
            <p>A production-ready QUIC implementation in pure Go</p>
            <p>Language: Go</p>
            <p>Stars: 11,433</p>
            <p>Forks: 1,521</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; style=&quot;margin-bottom: 15px;&quot;&gt;
  &lt;img src=&quot;./assets/quic-go-logo.png&quot; width=&quot;700&quot; height=&quot;auto&quot;&gt;
&lt;/div&gt;

# A QUIC implementation in pure Go


[![Documentation](https://img.shields.io/badge/docs-quic--go.net-red?style=flat)](https://quic-go.net/docs/)
[![PkgGoDev](https://pkg.go.dev/badge/github.com/quic-go/quic-go)](https://pkg.go.dev/github.com/quic-go/quic-go)
[![Code Coverage](https://img.shields.io/codecov/c/github/quic-go/quic-go/master.svg?style=flat-square)](https://codecov.io/gh/quic-go/quic-go/)
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/quic-go.svg)](https://issues.oss-fuzz.com/issues?q=quic-go)

quic-go is an implementation of the QUIC protocol ([RFC 9000](https://datatracker.ietf.org/doc/html/rfc9000), [RFC 9001](https://datatracker.ietf.org/doc/html/rfc9001), [RFC 9002](https://datatracker.ietf.org/doc/html/rfc9002)) in Go. It has support for HTTP/3 ([RFC 9114](https://datatracker.ietf.org/doc/html/rfc9114)), including QPACK ([RFC 9204](https://datatracker.ietf.org/doc/html/rfc9204)) and HTTP Datagrams ([RFC 9297](https://datatracker.ietf.org/doc/html/rfc9297)).

In addition to these base RFCs, it also implements the following RFCs:

* Unreliable Datagram Extension ([RFC 9221](https://datatracker.ietf.org/doc/html/rfc9221))
* Datagram Packetization Layer Path MTU Discovery (DPLPMTUD, [RFC 8899](https://datatracker.ietf.org/doc/html/rfc8899))
* QUIC Version 2 ([RFC 9369](https://datatracker.ietf.org/doc/html/rfc9369))
* QUIC Event Logging using qlog ([draft-ietf-quic-qlog-main-schema](https://datatracker.ietf.org/doc/draft-ietf-quic-qlog-main-schema/) and [draft-ietf-quic-qlog-quic-events](https://datatracker.ietf.org/doc/draft-ietf-quic-qlog-quic-events/))
* QUIC Stream Resets with Partial Delivery ([draft-ietf-quic-reliable-stream-reset](https://datatracker.ietf.org/doc/html/draft-ietf-quic-reliable-stream-reset-07))

Support for WebTransport over HTTP/3 ([draft-ietf-webtrans-http3](https://datatracker.ietf.org/doc/draft-ietf-webtrans-http3/)) is implemented in [webtransport-go](https://github.com/quic-go/webtransport-go).

Detailed documentation can be found on [quic-go.net](https://quic-go.net/docs/).

## Projects using quic-go

| Project                                                   | Description                                                                                                                                                       | Stars                                                                                               |
| ---------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------- |
| [AdGuardHome](https://github.com/AdguardTeam/AdGuardHome) | Free and open source, powerful network-wide ads &amp; trackers blocking DNS server.                                                                                   | ![GitHub Repo stars](https://img.shields.io/github/stars/AdguardTeam/AdGuardHome?style=flat-square) |
| [algernon](https://github.com/xyproto/algernon)           | Small self-contained pure-Go web server with Lua, Markdown, HTTP/2, QUIC, Redis and PostgreSQL support                                                            | ![GitHub Repo stars](https://img.shields.io/github/stars/xyproto/algernon?style=flat-square)        |
| [caddy](https://github.com/caddyserver/caddy/)            | Fast, multi-platform web server with automatic HTTPS                                                                                                              | ![GitHub Repo stars](https://img.shields.io/github/stars/caddyserver/caddy?style=flat-square)       |
| [cloudflared](https://github.com/cloudflare/cloudflared)  | A tunneling daemon that proxies traffic from the Cloudflare network to your origins                                                                               | ![GitHub Repo stars](https://img.shields.io/github/stars/cloudflare/cloudflared?style=flat-square)  |
| [frp](https://github.com/fatedier/frp)                    | A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet                                                                   | ![GitHub Repo stars](https://img.shields.io/github/stars/fatedier/frp?style=flat-square)            |
| [go-libp2p](https://github.com/libp2p/go-libp2p)          | libp2p implementation in Go, powering [Kubo](https://github.com/ipfs/kubo) (IPFS) and [Lotus](https://github.com/filecoin-project/lotus) (Filecoin), among others | ![GitHub Repo stars](https://img.shields.io/github/stars/libp2p/go-libp2p?style=flat-square)     |
| [gost](https://github.com/go-gost/gost)                   | A simple security tunnel written in Go                                                                                                                        | ![GitHub Repo stars](https://img.shields.io/github/stars/go-gost/gost?style=flat-square)            |
| [Hysteria](https://github.com/apernet/hysteria)           | A powerful, lightning fast and censorship resistant proxy                                                                                                         | ![GitHub Repo stars](https://img.shields.io/github/stars/apernet/hysteria?style=flat-square)        |
| [Mercure](https://github.com/dunglas/mercure)             | An open, easy, fast, reliable and battery-efficient solution for real-time communications                                                                         | ![GitHub Repo stars](https://img.shields.io/github/stars/dunglas/mercure?style=flat-square)         |
| [nodepass](https://github.com/NodePassProject/nodepass) | A secure, efficient TCP/UDP tunneling solution that delivers fast, reliable access across network restrictions using pre-established TCP/QUIC/WebSocket or HTTP/2 connections. | ![GitHub Repo stars](https://img.shields.io/github/stars/NodePassProject/nodepass?style=flat-square)  |
| [OONI Probe](https://github.com/ooni/probe-cli)           | Next generation OONI Probe. Library and CLI tool.                                                                                                                 | ![GitHub Repo stars](https://img.shields.io/github/stars/ooni/probe-cli?style=flat-square)          |
| [reverst](https://github.com/flipt-io/reverst)            | Reverse Tunnels in Go over HTTP/3 and QUIC                                                                                                                        | ![GitHub Repo stars](https://img.shields.io/github/stars/flipt-io/reverst?style=flat-square) |
| [RoadRunner](https://github.com/roadrunner-server/roadrunner) | High-performance PHP application server, process manager written in Go and powered with plugins | ![GitHub Repo stars](https://img.shields.io/github/stars/roadrunner-server/roadrunner?style=flat-square) |
| [syncthing](https://github.com/syncthing/syncthing/)      | Open Source Continuous File Synchronization                                                                                                                       | ![GitHub Repo stars](https://img.shields.io/github/stars/syncthing/syncthing?style=flat-square)     |
| [traefik](https://github.com/traefik/traefik)             | The Cloud Native Application Proxy                                                                                                                                | ![GitHub Repo stars](https://img.shields.io/github/stars/traefik/traefik?style=flat-square)         |
| [v2ray-core](https://github.com/v2fly/v2ray-core)         | A platform for building proxies to bypass network restrictions                                                                                                    | ![GitHub Repo stars](https://img.shields.io/github/stars/v2fly/v2ray-core?style=flat-square)        |
| [YoMo](https://github.com/yomorun/yomo)                   | Streaming Serverless Framework for Geo-distributed System                                                                                                         | ![GitHub Repo stars](https://img.shields.io/github/stars/yomorun/yomo?style=flat-square)            |

If you&#039;d like to see your project added to this list, please send us a PR.

## Release Policy

quic-go always aims to support the latest two Go releases.

## Contributing

We are always happy to welcome new contributors! We have a number of self-contained issues that are suitable for first-time contributors, they are tagged with [help wanted](https://github.com/quic-go/quic-go/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22). If you have any questions, please feel free to reach out by opening an issue or leaving a comment.

## License

The code is licensed under the MIT license. The logo and brand assets are excluded from the MIT license. See [assets/LICENSE.md](https://github.com/quic-go/quic-go/tree/master/assets/LICENSE.md) for the full usage policy and details.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[external-secrets/external-secrets]]></title>
            <link>https://github.com/external-secrets/external-secrets</link>
            <guid>https://github.com/external-secrets/external-secrets</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:27 GMT</pubDate>
            <description><![CDATA[External Secrets Operator reads information from a third-party service like AWS Secrets Manager and automatically injects the values as Kubernetes Secrets.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/external-secrets/external-secrets">external-secrets/external-secrets</a></h1>
            <p>External Secrets Operator reads information from a third-party service like AWS Secrets Manager and automatically injects the values as Kubernetes Secrets.</p>
            <p>Language: Go</p>
            <p>Stars: 6,385</p>
            <p>Forks: 1,203</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;assets/eso-logo-large.png&quot; width=&quot;30%&quot; align=&quot;center&quot; alt=&quot;external-secrets&quot;&gt;
&lt;/p&gt;

# External Secrets

![ci](https://github.com/external-secrets/external-secrets/actions/workflows/ci.yml/badge.svg?branch=main)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5327/badge)](https://bestpractices.coreinfrastructure.org/projects/5947)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/external-secrets/external-secrets/badge)](https://securityscorecards.dev/viewer/?uri=github.com/external-secrets/external-secrets)
[![Go Report Card](https://goreportcard.com/badge/github.com/external-secrets/external-secrets)](https://goreportcard.com/report/github.com/external-secrets/external-secrets)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets?ref=badge_shield)
&lt;a href=&quot;https://artifacthub.io/packages/helm/external-secrets-operator/external-secrets&quot;&gt;&lt;img alt=&quot;Artifact Hub&quot; src=&quot;https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/external-secrets&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://operatorhub.io/operator/external-secrets-operator&quot;&gt;&lt;img alt=&quot;operatorhub.io&quot; src=&quot;https://img.shields.io/badge/operatorhub.io-external--secrets-brightgreen&quot; /&gt;&lt;/a&gt;

**External Secrets Operator** is a Kubernetes operator that integrates external
secret management systems like [AWS Secrets
Manager](https://aws.amazon.com/secrets-manager/), [HashiCorp
Vault](https://www.vaultproject.io/), [Google Secrets
Manager](https://cloud.google.com/secret-manager), [Azure Key
Vault](https://azure.microsoft.com/en-us/services/key-vault/), [IBM Cloud Secrets Manager](https://www.ibm.com/cloud/secrets-manager), [Akeyless](https://akeyless.io), [CyberArk Secrets Manager](https://www.cyberark.com/products/secrets-management/), [Pulumi ESC](https://www.pulumi.com/product/esc/) and many more. The
operator reads information from external APIs and automatically injects the
values into a [Kubernetes
Secret](https://kubernetes.io/docs/concepts/configuration/secret/).

Multiple people and organizations are joining efforts to create a single External Secrets solution based on existing projects. If you are curious about the origins of this project, check out [this issue](https://github.com/external-secrets/kubernetes-external-secrets/issues/47) and [this PR](https://github.com/external-secrets/kubernetes-external-secrets/pull/477).

## Documentation

External Secrets Operator guides and reference documentation is available at [external-secrets.io](https://external-secrets.io). Also see our [stability and support](https://external-secrets.io/main/introduction/stability-support/) policy.

## Contributing

We welcome and encourage contributions to this project! Please read the [Developer](https://www.external-secrets.io/main/contributing/devguide/) and [Contribution process](https://www.external-secrets.io/main/contributing/process/) guides. Also make sure to check the [Code of Conduct](https://www.external-secrets.io/main/contributing/coc/) and adhere to its guidelines.

Also, please take a look our [Contribution Ladder](CONTRIBUTOR_LADDER.md) for a _very_ detailed explanation of what roles and tracks are available for people to try and help this project.

### Sponsoring

Please consider sponsoring this project, there are many ways you can help us with: engineering time, providing infrastructure, donating money, etc. We are open to cooperations, feel free to approach as and we discuss how this could look like. We can keep your contribution anonymized if that&#039;s required (depending on the type of contribution), and anonymous donations are possible inside [Opencollective](https://opencollective.com/external-secrets-org).

## Bi-weekly Development Meeting

We host our development meeting every odd wednesday on [Zoom](https://zoom-lfx.platform.linuxfoundation.org/meeting/92843470602?password=b953d8fb-825b-48ae-8fd7-226e498cc316). We run the meeting with alternating times [8:00 PM Berlin Time](https://dateful.com/time-zone-converter?t=20:00&amp;tz=Europe/Berlin) and [1:00 PM Berlin Time](https://dateful.com/time-zone-converter?t=13:00&amp;tz=Europe/Berlin). Be sure to check the [CNCF Calendar](https://zoom-lfx.platform.linuxfoundation.org/meetings/externalsecretsoperator?view=month) to see when the next meeting is scheduled, we&#039;ll also announce the time in our [Kubernetes Slack channel](https://kubernetes.slack.com/messages/external-secrets).
Meeting notes are recorded on [this google document](https://docs.google.com/document/d/1etFaDlLd01PUWuMlAwCXnpUg85QiTkNjw0SHu-rQjDs/).

Anyone is welcome to join. Feel free to ask questions, request feedback, raise awareness for an issue, or just say hi. ;)

## Security

Please report vulnerabilities by email to cncf-ExternalSecretsOp-maintainers@lists.cncf.io. Also see our [SECURITY.md file](SECURITY.md) for details.

## Software bill of materials
We attach SBOM and provenance file to our GitHub release. Also, they are attached to container images.

## Adopters

Please create a PR and add your company or project to our [ADOPTERS.md file](ADOPTERS.md) if you are using our project!

## Roadmap

You can find the roadmap in our documentation: https://external-secrets.io/main/contributing/roadmap/

## Kicked off by

![](assets/Godaddylogo_2020.png)

## Sponsored by

![External Secrets Inc.](assets/ESI_Logo.svg)
![Container Solutions](assets/CS_logo_1.png)
![Form 3](assets/form3_logo.png)
![Pento ](assets/pento_logo.png)


## License
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Fexternal-secrets%2Fexternal-secrets?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Shopify/toxiproxy]]></title>
            <link>https://github.com/Shopify/toxiproxy</link>
            <guid>https://github.com/Shopify/toxiproxy</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:26 GMT</pubDate>
            <description><![CDATA[‚è∞ üî• A TCP proxy to simulate network and system conditions for chaos and resiliency testing]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Shopify/toxiproxy">Shopify/toxiproxy</a></h1>
            <p>‚è∞ üî• A TCP proxy to simulate network and system conditions for chaos and resiliency testing</p>
            <p>Language: Go</p>
            <p>Stars: 11,842</p>
            <p>Forks: 488</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># Toxiproxy
[![GitHub release](https://img.shields.io/github/release/Shopify/toxiproxy.svg)](https://github.com/Shopify/toxiproxy/releases/latest)
[![Build Status](https://github.com/Shopify/toxiproxy/actions/workflows/test.yml/badge.svg)](https://github.com/Shopify/toxiproxy/actions/workflows/test.yml)

![](http://i.imgur.com/sOaNw0o.png)

Toxiproxy is a framework for simulating network conditions. It&#039;s made
specifically to work in testing, CI and development environments, supporting
deterministic tampering with connections, but with support for randomized chaos
and customization. **Toxiproxy is the tool you need to prove with tests that
your application doesn&#039;t have single points of failure.** We&#039;ve been
successfully using it in all development and test environments at Shopify since
October, 2014. See our [blog post][blog] on resiliency for more information.

Toxiproxy usage consists of two parts. A TCP proxy written in Go (what this
repository contains) and a client communicating with the proxy over HTTP. You
configure your application to make all test connections go through Toxiproxy
and can then manipulate their health via HTTP. See [Usage](#usage)
below on how to set up your project.

For example, to add 1000ms of latency to the response of MySQL from the [Ruby
client](https://github.com/Shopify/toxiproxy-ruby):

```ruby
Toxiproxy[:mysql_master].downstream(:latency, latency: 1000).apply do
  Shop.first # this takes at least 1s
end
```

To take down all Redis instances:

```ruby
Toxiproxy[/redis/].down do
  Shop.first # this will throw an exception
end
```

While the examples in this README are currently in Ruby, there&#039;s nothing
stopping you from creating a client in any other language (see
[Clients](#clients)).

## Table of Contents

- [Toxiproxy](#toxiproxy)
  - [Table of Contents](#table-of-contents)
  - [Why yet another chaotic TCP proxy?](#why-yet-another-chaotic-tcp-proxy)
  - [Clients](#clients)
  - [Example](#example)
  - [Usage](#usage)
    - [1. Installing Toxiproxy](#1-installing-toxiproxy)
      - [Upgrading from Toxiproxy 1.x](#upgrading-from-toxiproxy-1x)
    - [2. Populating Toxiproxy](#2-populating-toxiproxy)
    - [3. Using Toxiproxy](#3-using-toxiproxy)
    - [4. Logging](#4-logging)
    - [Toxics](#toxics)
      - [latency](#latency)
      - [down](#down)
      - [bandwidth](#bandwidth)
      - [slow_close](#slow_close)
      - [timeout](#timeout)
      - [reset_peer](#reset_peer)
      - [slicer](#slicer)
      - [limit_data](#limit_data)
    - [HTTP API](#http-api)
      - [Proxy fields:](#proxy-fields)
      - [Toxic fields:](#toxic-fields)
      - [Endpoints](#endpoints)
      - [Populating Proxies](#populating-proxies)
    - [CLI Example](#cli-example)
    - [Metrics](#metrics)
    - [Frequently Asked Questions](#frequently-asked-questions)
    - [Development](#development)
    - [Release](#release)

## Why yet another chaotic TCP proxy?

The existing ones we found didn&#039;t provide the kind of dynamic API we needed for
integration and unit testing. Linux tools like `nc` and so on are not
cross-platform and require root, which makes them problematic in test,
development and CI environments.

## Clients

* [toxiproxy-ruby](https://github.com/Shopify/toxiproxy-ruby)
* [toxiproxy-go](https://github.com/Shopify/toxiproxy/tree/main/client)
* [toxiproxy-python](https://github.com/douglas/toxiproxy-python)
* [toxiproxy.net](https://github.com/mdevilliers/Toxiproxy.Net)
* [toxiproxy-php-client](https://github.com/ihsw/toxiproxy-php-client)
* [toxiproxy-node-client](https://github.com/ihsw/toxiproxy-node-client)
* [toxiproxy-java](https://github.com/trekawek/toxiproxy-java)
* [toxiproxy-haskell](https://github.com/jpittis/toxiproxy-haskell)
* [toxiproxy-rust](https://github.com/itarato/toxiproxy_rust)
* [toxiproxy-elixir](https://github.com/Jcambass/toxiproxy_ex)

## Example

Let&#039;s walk through an example with a Rails application. Note that Toxiproxy is
in no way tied to Ruby, it&#039;s just been our first use case. You can see the full example at
[sirupsen/toxiproxy-rails-example](https://github.com/sirupsen/toxiproxy-rails-example).
To get started right away, jump down to [Usage](#usage).

For our popular blog, for some reason we&#039;re storing the tags for our posts in
Redis and the posts themselves in MySQL. We might have a `Post` class that
includes some methods to manipulate tags in a [Redis set](http://redis.io/commands#set):

```ruby
class Post &lt; ActiveRecord::Base
  # Return an Array of all the tags.
  def tags
    TagRedis.smembers(tag_key)
  end

  # Add a tag to the post.
  def add_tag(tag)
    TagRedis.sadd(tag_key, tag)
  end

  # Remove a tag from the post.
  def remove_tag(tag)
    TagRedis.srem(tag_key, tag)
  end

  # Return the key in Redis for the set of tags for the post.
  def tag_key
    &quot;post:tags:#{self.id}&quot;
  end
end
```

We&#039;ve decided that erroring while writing to the tag data store
(adding/removing) is OK. However, if the tag data store is down, we should be
able to see the post with no tags. We could simply rescue the
`Redis::CannotConnectError` around the `SMEMBERS` Redis call in the `tags`
method. Let&#039;s use Toxiproxy to test that.

Since we&#039;ve already installed Toxiproxy and it&#039;s running on our machine, we can
skip to step 2. This is where we need to make sure Toxiproxy has a mapping for
Redis tags. To `config/boot.rb` (before any connection is made) we add:

```ruby
require &#039;toxiproxy&#039;

Toxiproxy.populate([
  {
    name: &quot;toxiproxy_test_redis_tags&quot;,
    listen: &quot;127.0.0.1:22222&quot;,
    upstream: &quot;127.0.0.1:6379&quot;
  }
])
```

Then in `config/environments/test.rb` we set the `TagRedis` to be a Redis client
that connects to Redis through Toxiproxy by adding this line:

```ruby
TagRedis = Redis.new(port: 22222)
```

All calls in the test environment now go through Toxiproxy. That means we can
add a unit test where we simulate a failure:

```ruby
test &quot;should return empty array when tag redis is down when listing tags&quot; do
  @post.add_tag &quot;mammals&quot;

  # Take down all Redises in Toxiproxy
  Toxiproxy[/redis/].down do
    assert_equal [], @post.tags
  end
end
```

The test fails with `Redis::CannotConnectError`. Perfect! Toxiproxy took down
the Redis successfully for the duration of the closure. Let&#039;s fix the `tags`
method to be resilient:

```ruby
def tags
  TagRedis.smembers(tag_key)
rescue Redis::CannotConnectError
  []
end
```

The tests pass! We now have a unit test that proves fetching the tags when Redis
is down returns an empty array, instead of throwing an exception. For full
coverage you should also write an integration test that wraps fetching the
entire blog post page when Redis is down.

Full example application is at
[sirupsen/toxiproxy-rails-example](https://github.com/sirupsen/toxiproxy-rails-example).

## Usage

Configuring a project to use Toxiproxy consists of three steps:

1. Installing Toxiproxy
2. Populating Toxiproxy
3. Using Toxiproxy

### 1. Installing Toxiproxy

**Linux**

See [`Releases`](https://github.com/Shopify/toxiproxy/releases) for the latest
binaries and system packages for your architecture.

**Ubuntu**

```bash
$ wget -O toxiproxy-2.1.4.deb https://github.com/Shopify/toxiproxy/releases/download/v2.1.4/toxiproxy_2.1.4_amd64.deb
$ sudo dpkg -i toxiproxy-2.1.4.deb
$ sudo service toxiproxy start
```

**OS X**

With [Homebrew](https://brew.sh/):

```bash
$ brew tap shopify/shopify
$ brew install toxiproxy
```

Or with [MacPorts](https://www.macports.org/):

```bash
$ port install toxiproxy
```

**Windows**

Toxiproxy for Windows is available for download at https://github.com/Shopify/toxiproxy/releases/download/v2.1.4/toxiproxy-server-windows-amd64.exe

**Docker**

Toxiproxy is available on [Github container registry](https://github.com/Shopify/toxiproxy/pkgs/container/toxiproxy).
Old versions `&lt;= 2.1.4` are available on on [Docker Hub](https://hub.docker.com/r/shopify/toxiproxy/).

```bash
$ docker pull ghcr.io/shopify/toxiproxy
$ docker run --rm -it ghcr.io/shopify/toxiproxy
```

If using Toxiproxy from the host rather than other containers, enable host networking with `--net=host`.

```shell
$ docker run --rm --entrypoint=&quot;/toxiproxy-cli&quot; -it ghcr.io/shopify/toxiproxy list
```

**Source**

If you have Go installed, you can build Toxiproxy from source using the make file:
```bash
$ make build
$ ./toxiproxy-server
```

#### Upgrading from Toxiproxy 1.x

In Toxiproxy 2.0 several changes were made to the API that make it incompatible with version 1.x.
In order to use version 2.x of the Toxiproxy server, you will need to make sure your client
library supports the same version. You can check which version of Toxiproxy you are running by
looking at the `/version` endpoint.

See the documentation for your client library for specific library changes. Detailed changes
for the Toxiproxy server can been found in [CHANGELOG.md](./CHANGELOG.md).

### 2. Populating Toxiproxy

When your application boots, it needs to make sure that Toxiproxy knows which
endpoints to proxy where. The main parameters are: name, address for Toxiproxy
to **listen** on and the address of the upstream.

Some client libraries have helpers for this task, which is essentially just
making sure each proxy in a list is created. Example from the Ruby client:

```ruby
# Make sure `shopify_test_redis_master` and `shopify_test_mysql_master` are
# present in Toxiproxy
Toxiproxy.populate([
  {
    name: &quot;shopify_test_redis_master&quot;,
    listen: &quot;127.0.0.1:22220&quot;,
    upstream: &quot;127.0.0.1:6379&quot;
  },
  {
    name: &quot;shopify_test_mysql_master&quot;,
    listen: &quot;127.0.0.1:24220&quot;,
    upstream: &quot;127.0.0.1:3306&quot;
  }
])
```

This code needs to run as early in boot as possible, before any code establishes
a connection through Toxiproxy. Please check your client library for
documentation on the population helpers.

Alternatively use the CLI to create proxies, e.g.:

```bash
toxiproxy-cli create -l localhost:26379 -u localhost:6379 shopify_test_redis_master
```

We recommend a naming such as the above: `&lt;app&gt;_&lt;env&gt;_&lt;data store&gt;_&lt;shard&gt;`.
This makes sure there are no clashes between applications using the same
Toxiproxy.

For large application we recommend storing the Toxiproxy configurations in a
separate configuration file. We use `config/toxiproxy.json`. This file can be
passed to the server using the `-config` option, or loaded by the application
to use with the `populate` function.

An example `config/toxiproxy.json`:

```json
[
  {
    &quot;name&quot;: &quot;web_dev_frontend_1&quot;,
    &quot;listen&quot;: &quot;[::]:18080&quot;,
    &quot;upstream&quot;: &quot;webapp.domain:8080&quot;,
    &quot;enabled&quot;: true
  },
  {
    &quot;name&quot;: &quot;web_dev_mysql_1&quot;,
    &quot;listen&quot;: &quot;[::]:13306&quot;,
    &quot;upstream&quot;: &quot;database.domain:3306&quot;,
    &quot;enabled&quot;: true
  }
]
```

Use ports outside the ephemeral port range to avoid random port conflicts.
It&#039;s `32,768` to `61,000` on Linux by default, see
`/proc/sys/net/ipv4/ip_local_port_range`.

### 3. Using Toxiproxy

To use Toxiproxy, you now need to configure your application to connect through
Toxiproxy. Continuing with our example from step two, we can configure our Redis
client to connect through Toxiproxy:

```ruby
# old straight to redis
redis = Redis.new(port: 6380)

# new through toxiproxy
redis = Redis.new(port: 22220)
```

Now you can tamper with it through the Toxiproxy API. In Ruby:

```ruby
redis = Redis.new(port: 22220)

Toxiproxy[:shopify_test_redis_master].downstream(:latency, latency: 1000).apply do
  redis.get(&quot;test&quot;) # will take 1s
end
```

Or via the CLI:

```bash
toxiproxy-cli toxic add -t latency -a latency=1000 shopify_test_redis_master
```

Please consult your respective client library on usage.

### 4. Logging

There are the following log levels: panic, fatal, error, warn or warning, info, debug and trace.
The level could be updated via environment variable `LOG_LEVEL`.

### Toxics

Toxics manipulate the pipe between the client and upstream. They can be added
and removed from proxies using the [HTTP api](#http-api). Each toxic has its own parameters
to change how it affects the proxy links.

For documentation on implementing custom toxics, see [CREATING_TOXICS.md](./CREATING_TOXICS.md)

#### latency

Add a delay to all data going through the proxy. The delay is equal to `latency` +/- `jitter`.

Attributes:

 - `latency`: time in milliseconds
 - `jitter`: time in milliseconds

#### down

Bringing a service down is not technically a toxic in the implementation of
Toxiproxy. This is done by `POST`ing to `/proxies/{proxy}` and setting the
`enabled` field to `false`.

#### bandwidth

Limit a connection to a maximum number of kilobytes per second.

Attributes:

 - `rate`: rate in KB/s

#### slow_close

Delay the TCP socket from closing until `delay` has elapsed.

Attributes:

 - `delay`: time in milliseconds

#### timeout

Stops all data from getting through, and closes the connection after `timeout`. If
`timeout` is 0, the connection won&#039;t close, and data will be dropped until the
toxic is removed.

Attributes:

 - `timeout`: time in milliseconds

#### reset_peer

Simulate TCP RESET (Connection reset by peer) on the connections by closing the stub Input
immediately or after a `timeout`.

Attributes:

 - `timeout`: time in milliseconds

#### slicer

Slices TCP data up into small bits, optionally adding a delay between each
sliced &quot;packet&quot;.

Attributes:

 - `average_size`: size in bytes of an average packet
 - `size_variation`: variation in bytes of an average packet (should be smaller than average_size)
 - `delay`: time in microseconds to delay each packet by

#### limit_data

Closes connection when transmitted data exceeded limit.

 - `bytes`: number of bytes it should transmit before connection is closed

### HTTP API

All communication with the Toxiproxy daemon from the client happens through the
HTTP interface, which is described here.

Toxiproxy listens for HTTP on port **8474**.

#### Proxy fields:

 - `name`: proxy name (string)
 - `listen`: listen address (string)
 - `upstream`: proxy upstream address (string)
 - `enabled`: true/false (defaults to true on creation)

To change a proxy&#039;s name, it must be deleted and recreated.

Changing the `listen` or `upstream` fields will restart the proxy and drop any active connections.

If `listen` is specified with a port of 0, toxiproxy will pick an ephemeral port. The `listen` field
in the response will be updated with the actual port.

If you change `enabled` to `false`, it will take down the proxy. You can switch it
back to `true` to reenable it.

#### Toxic fields:

 - `name`: toxic name (string, defaults to `&lt;type&gt;_&lt;stream&gt;`)
 - `type`: toxic type (string)
 - `stream`: link direction to affect (defaults to `downstream`)
 - `toxicity`: probability of the toxic being applied to a link (defaults to 1.0, 100%)
 - `attributes`: a map of toxic-specific attributes

See [Toxics](#toxics) for toxic-specific attributes.

The `stream` direction must be either `upstream` or `downstream`. `upstream` applies
the toxic on the `client -&gt; server` connection, while `downstream` applies the toxic
on the `server -&gt; client` connection. This can be used to modify requests and responses
separately.

#### Endpoints

All endpoints are JSON.

 - **GET /proxies** - List existing proxies and their toxics
 - **POST /proxies** - Create a new proxy
 - **POST /populate** - Create or replace a list of proxies
 - **GET /proxies/{proxy}** - Show the proxy with all its active toxics
 - **POST /proxies/{proxy}** - Update a proxy&#039;s fields
 - **DELETE /proxies/{proxy}** - Delete an existing proxy
 - **GET /proxies/{proxy}/toxics** - List active toxics
 - **POST /proxies/{proxy}/toxics** - Create a new toxic
 - **GET /proxies/{proxy}/toxics/{toxic}** - Get an active toxic&#039;s fields
 - **POST /proxies/{proxy}/toxics/{toxic}** - Update an active toxic
 - **DELETE /proxies/{proxy}/toxics/{toxic}** - Remove an active toxic
 - **POST /reset** - Enable all proxies and remove all active toxics
 - **GET /version** - Returns the server version number
 - **GET /metrics** - Returns Prometheus-compatible metrics

#### Populating Proxies

Proxies can be added and configured in bulk using the `/populate` endpoint. This is done by
passing a json array of proxies to toxiproxy. If a proxy with the same name already exists,
it will be compared to the new proxy and replaced if the `upstream` and `listen` address don&#039;t match.

A `/populate` call can be included for example at application start to ensure all required proxies
exist. It is safe to make this call several times, since proxies will be untouched as long as their
fields are consistent with the new data.

### CLI Example

```bash
$ toxiproxy-cli create -l localhost:26379 -u localhost:6379 redis
Created new proxy redis
$ toxiproxy-cli list
Listen          Upstream        Name  Enabled Toxics
======================================================================
127.0.0.1:26379 localhost:6379  redis true    None

Hint: inspect toxics with `toxiproxy-client inspect &lt;proxyName&gt;`
```

```bash
$ redis-cli -p 26379
127.0.0.1:26379&gt; SET omg pandas
OK
127.0.0.1:26379&gt; GET omg
&quot;pandas&quot;
```

```bash
$ toxiproxy-cli toxic add -t latency -a latency=1000 redis
Added downstream latency toxic &#039;latency_downstream&#039; on proxy &#039;redis&#039;
```

```bash
$ redis-cli -p 26379
127.0.0.1:26379&gt; GET omg
&quot;pandas&quot;
(1.00s)
127.0.0.1:26379&gt; DEL omg
(integer) 1
(1.00s)
```

```bash
$ toxiproxy-cli toxic remove -n latency_downstream redis
Removed toxic &#039;latency_downstream&#039; on proxy &#039;redis&#039;
```

```bash
$ redis-cli -p 26379
127.0.0.1:26379&gt; GET omg
(nil)
```

```bash
$ toxiproxy-cli delete redis
Deleted proxy redis
```

```bash
$ redis-cli -p 26379
Could not connect to Redis at 127.0.0.1:26379: Connection refused
```

### Metrics

Toxiproxy exposes Prometheus-compatible metrics via its HTTP API at /metrics.
See [METRICS.md](./METRICS.md) for full descriptions

### Frequently Asked Questions

**How fast is Toxiproxy?** The speed of Toxiproxy depends largely on your hardware,
but you can expect a latency of *&lt; 100¬µs* when no toxics are enabled. When running
with `GOMAXPROCS=4` on a Macbook Pro we achieved *~1000MB/s* throughput, and as high
as *2400MB/s* on a higher end desktop. Basically, you can expect Toxiproxy to move
data around at least as fast the app you&#039;re testing.

**Can Toxiproxy do randomized testing?** Many of the available toxics can be configured
to have randomness, such as `jitter` in the `latency` toxic. There is also a
global `toxicity` parameter that specifies the percentage of connections a toxic
will affect. This is most useful for things like the `timeout` toxic, which would
allow X% of connections to timeout.

**I am not seeing my Toxiproxy actions reflected for MySQL**. MySQL will prefer
the local Unix domain socket for some clients, no matter which port you pass it
if the host is set to `localhost`. Configure your MySQL server to not create a
socket, and use `127.0.0.1` as the host. Remember to remove the old socket
after you restart the server.

**Toxiproxy causes intermittent connection failures**. Use ports outside the
ephemeral port range to avoid random port conflicts. It&#039;s `32,768` to `61,000` on
Linux by default, see `/proc/sys/net/ipv4/ip_local_port_range`.

**Should I run a Toxiproxy for each application?** No, we recommend using the
same Toxiproxy for all applications. To distinguish between services we
recommend naming your proxies with the scheme: `&lt;app&gt;_&lt;env&gt;_&lt;data store&gt;_&lt;shard&gt;`.
For example, `shopify_test_redis_master` or `shopify_development_mysql_1`.

### Development

* `make`. Build a toxiproxy development binary for the current platform.
* `make all`. Build Toxiproxy binaries and packages for all platforms. Requires
  to have Go compiled with cross compilation enabled on Linux and Darwin (amd64)
  as well as [`goreleaser`](https://goreleaser.com/) in your `$PATH` to
  build binaries the Linux package.
* `make test`. Run the Toxiproxy tests.

### Release

See [RELEASE.md](./RELEASE.md)

[blog]: https://shopify.engineering/building-and-testing-resilient-ruby-on-rails-applications
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[zitadel/zitadel]]></title>
            <link>https://github.com/zitadel/zitadel</link>
            <guid>https://github.com/zitadel/zitadel</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:25 GMT</pubDate>
            <description><![CDATA[ZITADEL - Identity infrastructure, simplified for¬†you.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zitadel/zitadel">zitadel/zitadel</a></h1>
            <p>ZITADEL - Identity infrastructure, simplified for¬†you.</p>
            <p>Language: Go</p>
            <p>Stars: 12,984</p>
            <p>Forks: 939</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;./apps/docs/static/logos/zitadel-logo-dark@2x.png#gh-light-mode-only&quot; alt=&quot;Zitadel Logo&quot; max-height=&quot;200px&quot; width=&quot;auto&quot; /&gt;
    &lt;img src=&quot;./apps/docs/static/logos/zitadel-logo-light@2x.png#gh-dark-mode-only&quot; alt=&quot;Zitadel Logo&quot; max-height=&quot;200px&quot; width=&quot;auto&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/zitadel/zitadel&quot; alt=&quot;Open in Dev Container&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&quot; /&gt; &lt;/a&gt;
    &lt;a href=&quot;https://github.com/zitadel/zitadel/blob/main/LICENSE&quot; alt=&quot;License&quot;&gt;
        &lt;img src=&quot;https://badgen.net/github/license/zitadel/zitadel/&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://bestpractices.coreinfrastructure.org/projects/6662&quot;&gt;&lt;img src=&quot;https://bestpractices.coreinfrastructure.org/projects/6662/badge&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/semantic-release/semantic-release&quot; alt=&quot;semantic-release&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/zitadel/zitadel/actions&quot; alt=&quot;ZITADEL Release&quot;&gt;
        &lt;img alt=&quot;GitHub Workflow Status (with event)&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/zitadel/zitadel/build.yml?event=pull_request&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://zitadel.com/docs/support/software-release-cycles-support&quot; alt=&quot;Release&quot;&gt;
        &lt;img src=&quot;https://badgen.net/github/release/zitadel/zitadel/stable&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://goreportcard.com/report/github.com/zitadel/zitadel&quot; alt=&quot;Go Report Card&quot;&gt;
        &lt;img src=&quot;https://goreportcard.com/badge/github.com/zitadel/zitadel&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://codecov.io/gh/zitadel/zitadel&quot; alt=&quot;Code Coverage&quot;&gt;
        &lt;img src=&quot;https://codecov.io/gh/zitadel/zitadel/branch/main/graph/badge.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/zitadel/zitadel/graphs/contributors&quot; alt=&quot;Release&quot;&gt;
        &lt;img alt=&quot;GitHub contributors&quot; src=&quot;https://img.shields.io/github/contributors/zitadel/zitadel&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/YgjEuJzZ3x&quot; alt=&quot;Discord Chat&quot;&gt;
        &lt;img src=&quot;https://badgen.net/discord/online-members/YgjEuJzZ3x&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://openid.net/certification/#OPs&quot; alt=&quot;OpenID Connect Certified&quot;&gt;
        &lt;img src=&quot;./apps/docs/static/logos/oidc-cert.png&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

Are you searching for a user management tool that is quickly set up like Auth0 and open source like Keycloak?

Do you have a project that requires multi-tenant user management with self-service for your customers?

Look no further ‚Äî ZITADEL is the identity infrastructure, simplified for you.

We provide you with a wide range of out-of-the-box features to accelerate your project, including:

:white_check_mark: Multi-tenancy with team management  
:white_check_mark: Secure login  
:white_check_mark: Self-service  
:white_check_mark: OpenID Connect  
:white_check_mark: OAuth2.x  
:white_check_mark: SAML2  
:white_check_mark: LDAP  
:white_check_mark: Passkeys / FIDO2  
:white_check_mark: OTP
:white_check_mark: SCIM 2.0 Server
and an unlimited audit trail is there for you, ready to use.

With ZITADEL, you are assured of a robust and customizable turnkey solution for all your authentication and authorization needs.

---

**[üè° Website](https://zitadel.com) [üí¨ Chat](https://zitadel.com/chat) [üìã Docs](https://zitadel.com/docs/) [üßë‚Äçüíª Blog](https://zitadel.com/blog) [üìû Contact](https://zitadel.com/contact/)**

## Get started

üëâ [Quick Start Guide](https://zitadel.com/docs/guides/start/quickstart)

### Deploy ZITADEL (Self-Hosted)

Deploying ZITADEL locally takes less than 3 minutes. Go ahead and give it a try!

* [Linux](https://zitadel.com/docs/self-hosting/deploy/linux)
* [MacOS](https://zitadel.com/docs/self-hosting/deploy/macos)
* [Docker compose](https://zitadel.com/docs/self-hosting/deploy/compose)
* [Kubernetes](https://zitadel.com/docs/self-hosting/deploy/kubernetes)

See all guides [here](https://zitadel.com/docs/self-hosting/deploy/overview)

&gt; If you are interested to get professional support for your self-hosted ZITADEL [please reach out to us](https://zitadel.com/contact)!

### Setup ZITADEL Cloud (SaaS)

If you want to experience a hands-free ZITADEL, you should use [ZITADEL Cloud](https://zitadel.com).
Available data regions are: 
* üá∫üá∏ United States
* üá™üá∫ European Union
* üá¶üá∫ Australia
* üá®üá≠ Switzerland

ZITADEL Cloud comes with a free tier, providing you with all the same features as the open-source version.
Learn more about the [pay-as-you-go pricing](https://zitadel.com/pricing).

## Adopters

We are grateful to the organizations and individuals who are using ZITADEL. If you are using ZITADEL, please consider adding your name to our [Adopters list](./ADOPTERS.md) by submitting a pull request.

### Example applications

Clone one of our [example applications](https://zitadel.com/docs/sdk-examples/introduction) or deploy them directly to Vercel.

### SDKs

Use our [SDKs](https://zitadel.com/docs/sdk-examples/introduction) for your favorite language and framework.

## Why choose ZITADEL

We built ZITADEL with a complex multi-tenancy architecture in mind and provide the best solution to handle [B2B customers and partners](https://zitadel.com/docs/guides/solution-scenarios/b2b).
Yet it offers everything you need for a customer identity ([CIAM](https://zitadel.com/docs/guides/solution-scenarios/b2c)) use case.

- [API-first approach](https://zitadel.com/docs/apis/introduction)
- [Multi-tenancy](https://zitadel.com/docs/guides/solution-scenarios/b2b) authentication and access management
- [Strong audit trail](https://zitadel.com/docs/concepts/features/audit-trail) thanks to [event sourcing](https://zitadel.com/docs/concepts/eventstore/overview) as storage pattern
- [Actions](https://zitadel.com/docs/guides/manage/console/actions-overview) to react on events with custom code and extended ZITADEL for you needs
- [Branding](https://zitadel.com/docs/guides/manage/customize/branding) for a uniform user experience across multiple organizations
- [Self-service](https://zitadel.com/docs/concepts/features/selfservice) for end-users, business customers, and administrators
- [Postgres](https://www.postgresql.org/) database as reliable and widespread storage option

## Features

Authentication

- Single Sign On (SSO)
- [Passkeys support (FIDO2 / WebAuthN)](https://zitadel.com/docs/concepts/features/passkeys)
- Username / Password
- Multifactor authentication with OTP, U2F, OTP Email, OTP SMS
- [LDAP](https://zitadel.com/docs/guides/integrate/identity-providers/ldap)
- [External enterprise identity providers and social logins](https://zitadel.com/docs/guides/integrate/identity-providers/introduction)
- [Device authorization](https://zitadel.com/docs/guides/solution-scenarios/device-authorization)
- [OpenID Connect certified](https://openid.net/certification/#OPs) =&gt; [OIDC Endpoints](https://zitadel.com/docs/apis/openidoauth/endpoints)
- [SAML 2.0](http://docs.oasis-open.org/security/saml/Post2.0/sstc-saml-tech-overview-2.0.html) =&gt; [SAML Endpoints](https://zitadel.com/docs/apis/saml/endpoints)
- [Custom sessions](https://zitadel.com/docs/guides/integrate/login-ui/username-password) if you need to go beyond OIDC or SAML 
- [Machine-to-machine](https://zitadel.com/docs/guides/integrate/service-accounts/authenticate-service-accounts) with JWT profile, Personal Access Tokens (PAT), and Client Credentials
- [Token exchange and impersonation](https://zitadel.com/docs/guides/integrate/token-exchange)
- [Beta: Hosted Login V2](https://zitadel.com/docs/guides/integrate/login/hosted-login#hosted-login-version-2-beta) our new Login version 2.0

Multi-Tenancy

- [Identity Brokering](https://zitadel.com/docs/guides/integrate/identity-brokering) with templates for popular identity providers
- [Customizable onboarding](https://zitadel.com/docs/guides/solution-scenarios/onboarding) for B2B and their users
- [Delegate role management to third-parties](https://zitadel.com/docs/guides/manage/console/projects-overview)
- [Domain discovery](https://zitadel.com/docs/guides/solution-scenarios/domain-discovery)

Integration

- [GRPC and REST APIs](https://zitadel.com/docs/apis/introduction) for every functionality and resource
- [Actions](https://zitadel.com/docs/guides/manage/console/actions-overview) to call any API, send webhooks, adjust workflows, or customize tokens
- [Role Based Access Control (RBAC)](https://zitadel.com/docs/guides/integrate/retrieve-user-roles)
- [SCIM 2.0 Server](https://zitadel.com/docs/apis/scim2)
- [Examples and SDKs](https://zitadel.com/docs/sdk-examples/introduction)
- [Audit Log and SOC/SIEM](https://zitadel.com/docs/guides/integrate/external-audit-log)
- [User registration and onboarding](https://zitadel.com/docs/guides/integrate/onboarding)
- [Hosted and custom Login user interface](https://zitadel.com/docs/guides/integrate/login/login-users)

Self-Service
- [Self-registration](https://zitadel.com/docs/concepts/features/selfservice#registration) including verification
- [Self-service](https://zitadel.com/docs/concepts/features/selfservice) for end-users, business customers, and administrators
- [Administration UI (Console)](https://zitadel.com/docs/guides/manage/console/console-overview)

Deployment
- [Postgres](https://zitadel.com/docs/self-hosting/manage/database#postgres) (version &gt;= 14)
- [Zero Downtime Updates](https://zitadel.com/docs/concepts/architecture/solution#zero-downtime-updates)
- [High scalability](https://zitadel.com/docs/self-hosting/manage/production)

Track upcoming features on our [roadmap](https://zitadel.com/roadmap) and follow our [changelog](https://zitadel.com/changelog) for recent updates.

## How To Contribute

Find details about how you can contribute in our [Contribution Guide](./CONTRIBUTING.md).
Join our [Discord Chat](https://zitadel.com/chat) to get help.

## Contributors

&lt;a href=&quot;https://github.com/zitadel/zitadel/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=zitadel/zitadel&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks/preview?repo=zitadel/zitadel).

## Showcase

### Quick Start Guide

Secure a React Application using OpenID Connect Authorization Code with PKCE

[![Quick Start Guide](https://user-images.githubusercontent.com/1366906/223662449-f17b734d-405c-4945-a8a1-200440c459e5.gif)](http://www.youtube.com/watch?v=5THbQljoPKg &quot;Quick Start Guide&quot;)

### Login with Passkeys

Use our Login widget to allow easy and secure access to your applications and enjoy all the benefits of Passkeys (FIDO 2 / WebAuthN):

[![Passkeys](https://user-images.githubusercontent.com/1366906/223664178-4132faef-4832-4014-b9ab-90c2a8d15436.gif)](https://www.youtube.com/watch?v=cZjHQYurSjw&amp;list=PLTDa7jTlOyRLdABgD2zL0LGM7rx5GZ1IR&amp;index=2 &quot;Passkeys&quot;)

### Management Console

Use [Console](https://zitadel.com/docs/guides/manage/console/console-overview) or our [APIs](https://zitadel.com/docs/apis/introduction) to set up organizations, projects and applications.

[![Console Showcase](https://user-images.githubusercontent.com/1366906/223663344-67038d5f-4415-4285-ab20-9a4d397e2138.gif)](http://www.youtube.com/watch?v=RPpHktAcCtk &quot;Console Showcase&quot;)

### Login V2

Check out our new Login V2 version in our [documentation](https://zitadel.com/docs/guides/integrate/login/hosted-login#hosted-login-version-2-beta)
![New Login Showcase](https://github.com/user-attachments/assets/cb5c5212-128b-4dc9-b11d-cabfd3f73e26)

## Security

You can find our security policy [here](./SECURITY.md).

[Technical Advisories](https://zitadel.com/docs/support/technical_advisory) are published regarding major issues with the ZITADEL platform that could potentially impact security or stability in production environments.

## License

[here](./LICENSE) are our exact licensing terms.

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See our [license](./LICENSE) for detailed information governing permissions and limitations on use.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[dolthub/dolt]]></title>
            <link>https://github.com/dolthub/dolt</link>
            <guid>https://github.com/dolthub/dolt</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:24 GMT</pubDate>
            <description><![CDATA[Dolt ‚Äì Git for Data]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dolthub/dolt">dolthub/dolt</a></h1>
            <p>Dolt ‚Äì Git for Data</p>
            <p>Language: Go</p>
            <p>Stars: 19,848</p>
            <p>Forks: 624</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;img height=&quot;100&quot; src=&quot;./images/Dolt-Logo@3x.svg&quot;/&gt;

# Dolt is Git for Data!

Dolt is a SQL database that you can fork, clone, branch, merge, push
and pull just like a Git repository. 

Connect to Dolt just like any MySQL database to read or modify schema 
and data. Version control functionality is exposed in SQL via system 
tables, functions, and procedures. 

Or, use the Git-like command line interface to import CSV files, commit 
your changes, push them to a remote, or merge your teammate&#039;s changes.
All the commands you know for Git work exactly the same for Dolt. 

Git versions files. Dolt versions tables. It&#039;s like Git and MySQL had a
baby.

We also built [DoltHub](https://www.dolthub.com), a place to share
Dolt databases. We host public data for free. If you want to host
your own version of DoltHub, we have [DoltLab](https://www.doltlab.com). 
If you want us to run a Dolt server for you, we have [Hosted Dolt](https://hosted.doltdb.com). 

Prefer Postgres instead of MySQL? Try [Doltgres](https://github.com/dolthub/doltgresql), now
in its Beta release.

[Join us on Discord](https://discord.com/invite/RFwfYpu) to say hi and
ask questions, or [check out our roadmap](https://docs.dolthub.com/other/roadmap) 
to see what we&#039;re building next.

# Video Introduction

[![Dolt Explainer Video](https://img.youtube.com/vi/H2iZy0Cme10/maxresdefault.jpg)](https://www.youtube.com/watch?v=H2iZy0Cme10)

# What&#039;s it for?

Lots of things! Dolt is a generally useful tool with countless
applications. But if you want some ideas, [here&#039;s how people are using
it so far](https://dolthub.com/blog/2024-10-15-dolt-use-cases/).

Dolt can be [set up as a replica of your existing MySQL](https://www.dolthub.com/blog/2023-02-17-binlog-replication-preview/)
database using standard MySQL binlog replication. Every write becomes
a Dolt commit. This is a great way to get the version control benefits 
of Dolt and keep an existing MySQL database. 

# Dolt CLI

The `dolt` CLI has the same commands as `git`, with some extras.

```
$ dolt
Valid commands for dolt are
                init - Create an empty Dolt data repository.
              status - Show the working tree status.
                 add - Add table changes to the list of staged table changes.
                diff - Diff a table.
               reset - Remove table changes from the list of staged table changes.
               clean - Remove untracked tables from working set.
              commit - Record changes to the repository.
                 sql - Run a SQL query against tables in repository.
          sql-server - Start a MySQL-compatible server.
                 log - Show commit logs.
              branch - Create, list, edit, delete branches.
            checkout - Checkout a branch or overwrite a table from HEAD.
               merge - Merge a branch.
           conflicts - Commands for viewing and resolving merge conflicts.
         cherry-pick - Apply the changes introduced by an existing commit.
              revert - Undo the changes introduced in a commit.
               clone - Clone from a remote data repository.
               fetch - Update the database from a remote data repository.
                pull - Fetch from a dolt remote data repository and merge.
                push - Push to a dolt remote.
              config - Dolt configuration.
              remote - Manage set of tracked repositories.
              backup - Manage a set of server backups.
               login - Login to a dolt remote host.
               creds - Commands for managing credentials.
                  ls - List tables in the working set.
              schema - Commands for showing and importing table schemas.
               table - Commands for copying, renaming, deleting, and exporting tables.
                 tag - Create, list, delete tags.
               blame - Show what revision and author last modified each row of a table.
         constraints - Commands for handling constraints.
             migrate - Executes a database migration to use the latest Dolt data format.
         read-tables - Fetch table(s) at a specific commit into a new dolt repo
                  gc - Cleans up unreferenced data from the repository.
       filter-branch - Edits the commit history using the provided query.
          merge-base - Find the common ancestor of two commits.
             version - Displays the current Dolt cli version.
                dump - Export all tables in the working set into a file.
```

# Installation

Dolt is a single ~103 megabyte program. 

```bash
dolt $ du -h /Users/timsehn/go/bin/dolt
103M	/Users/timsehn/go/bin/dolt
```

It&#039;s really easy to install. Download it and put it on your `PATH`. 
We have a bunch of ways to make this even easier for most platforms.

## From Latest Release

To install on Linux or Mac based systems run this command in your
terminal:

```
sudo bash -c &#039;curl -L https://github.com/dolthub/dolt/releases/latest/download/install.sh | bash&#039;
```

This will download the latest `dolt` release and put it in
`/usr/local/bin/`, which is probably on your `$PATH`.

The install script needs sudo in order to put `dolt` in `/usr/local/bin`. If you don&#039;t have root
privileges or aren&#039;t comfortable running a script with them, you can download the dolt binary
for your platform from [the latest release](https://github.com/dolthub/dolt/releases), unzip it,
and put the binary somewhere on your `$PATH`.

### Linux

#### Arch Linux

Dolt is packaged in the official repositories for Arch Linux.

```
pacman -S dolt
```

### Mac

#### Homebrew

Dolt is on Homebrew, updated every release.

```
brew install dolt
```
#### MacPorts

On macOS, Dolt can also be installed via a [community-managed port](https://ports.macports.org/port/dolt/) via [MacPorts](https://www.macports.org):

```sh
sudo port install dolt
```

### Windows

Download the latest Microsoft Installer (`.msi` file) in
[releases](https://github.com/dolthub/dolt/releases) and run
it.

For information on running on Windows, see [here](https://docs.dolthub.com/introduction/installation/windows).

#### Chocolatey

You can install `dolt` using [Chocolatey](https://chocolatey.org/):

```sh
choco install dolt
```

#### Docker

There are following official Docker images for Dolt:

* [`dolthub/dolt`](https://hub.docker.com/r/dolthub/dolt) for running Dolt
as CLI tool.
* [`dolthub/dolt-sql-server`](https://hub.docker.com/r/dolthub/dolt-sql-server) for running Dolt in server mode.

## From Source

Make sure you have Go installed, and that `go` is in your path. Dolt has a dependency on [cgo](https://pkg.go.dev/cmd/cgo), so you will need a working C compiler and toolchain as well.

Clone this repository and cd into the `go` directory. Then run:

```
go install ./cmd/dolt
```

The output will be in `$GOPATH/bin`, which defaults to `~/go/bin`. To test your build, try:

```
~/go/bin/dolt version
```

# Configuration

Verify that your installation has succeeded by running `dolt` in your
terminal.

```
$ dolt
Valid commands for dolt are
[...]
```

Configure `dolt` with your user name and email, which you&#039;ll need to
create commits. The commands work exactly the same as git.

```
$ dolt config --global --add user.email YOU@DOMAIN.COM
$ dolt config --global --add user.name &quot;YOUR NAME&quot;
```

# Getting started

## Navigate to the directory where you would like your data stored

Dolt needs a place to store your databases. I&#039;m going to put my databases in `~/dolt`. 

```bash
% cd ~
% mkdir dolt
% cd dolt
```

Any databases you create will be stored in this directory. So, for this example, a directory named `getting_started` will be created here once you run `create database getting_started`. Navigating to `~/dolt/getting_started` will allow you to access this database using the Dolt command line.

NOTE: For this example, the `getting_started` directory will be created after you run `create database getting_started;` in a SQL shell in the [Create a schema section](#create-a-schema). Don&#039;t do anything except make the directory and navigate to it just yet.

## Start a MySQL-compatible database server

Dolt ships with a MySQL compatible database server built in. To start it you use the command `dolt sql-server`. Running this command starts the server on port 3306. 

```bash
dolt sql-server
Starting server with Config HP=&quot;localhost:3306&quot;|T=&quot;28800000&quot;|R=&quot;false&quot;|L=&quot;info&quot;
```

Your terminal will just hang there. This means the server is running. Any errors will be printed in this terminal. Just leave it there and open a new terminal.

## Connect with a MySQL client (up to version 8.4)

In the new terminal, we will now connect to the running database server using a client. Dolt also ships with a MySQL compatible client. 

```bash
% dolt -u root -p &quot;&quot; sql
# Welcome to the Dolt MySQL client.
# Statements must be terminated with &#039;;&#039;.
# &quot;exit&quot; or &quot;quit&quot; (or Ctrl-D) to exit.
mysql&gt;
```

In the other terminal where you ran `dolt sql-server`, you&#039;ll see the following log line.

```
2022-06-06T13:14:32-07:00 INFO [conn 1] NewConnection {DisableClientMultiStatements=false}
```

You are connected!

While we&#039;re here let&#039;s grab a copy of MySQL so we can connect with that client. Head over to the [MySQL Getting Started](https://dev.mysql.com/doc/mysql-getting-started/en/) documentation and install MySQL on your machine. I used [Homebrew](https://brew.sh/) to install MySQL on my Mac: `brew install mysql@8.4`. Alternatively, you can install only the client component by running `brew install mysql-client@8.4`.

NOTE: Make sure you install a MySQL 8.4 release. MySQL 8.4 is the current Long Term Support (LTS) release, meaning this is the stable and supported version of MySQL. MySQL 9.0 is also available, but is an &quot;innovation&quot; release, meaning it has more recent changes and features, but may not be as stable as the LTS release. The 9.0 release changes authentication support and isn&#039;t able to connect to a Dolt SQL server by default. You can install MySQL 8.4 with Homebrew by running `brew install mysql@8.4`. If you do want to use MySQL-9.0, read [our post on how to configure Dolt for `caching_sha2_password` authentication](https://www.dolthub.com/blog/2024-12-11-mysql9-and-caching-sha2-auth-support/). 

MySQL comes with a MySQL server called `mysqld` and a MySQL client called `mysql`. You&#039;re only interested in the client. After following the instructions from MySQL&#039;s documentation, make sure you have a copy of the `mysql` client on your path:

```bash
% mysql --version
mysql  Ver 8.0.29 for macos12.2 on x86_64 (Homebrew)
```

Now, to connect the `mysql` client to Dolt, you are going to force the MySQL client through the TCP interface by passing in a host and port. The default is the socket interface which Dolt supports, but is only available on `localhost`. So, it&#039;s better to show off the TCP interface. The MySQL client also requires you specify a user, in this case `root`.

```bash
% mysql --host 127.0.0.1 --port 3306 -uroot
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.7.9-Vitess 

Copyright (c) 2000, 2022, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type &#039;help;&#039; or &#039;\h&#039; for help. Type &#039;\c&#039; to clear the current input statement.

mysql&gt;
```

Again, to ensure the client actually connected, you should see the following in the `dolt sql-server` terminal 

```
2022-06-06T13:26:55-07:00 INFO [conn 2] NewConnection {DisableClientMultiStatements=false}
```

As you can see, Dolt supports any MySQL-compatible client. Dolt ships with a client but you can use any MySQL client, like the one that comes with MySQL.

## Create a schema

Now we&#039;re actually ready to do something interesting. I&#039;ll stay in the `mysql` client and execute the following SQL statements to create a database called `getting_started`. The `getting_started` database will have three tables: `employees`, `teams`, and `employees_teams`.

```
mysql&gt; create database getting_started;
Query OK, 1 row affected (0.04 sec)

mysql&gt; use getting_started;
Database changed
mysql&gt; create table employees (
    id int, 
    last_name varchar(255), 
    first_name varchar(255), 
    primary key(id));
Query OK, 0 rows affected (0.01 sec)

mysql&gt; create table teams (
    id int, 
    team_name varchar(255), 
    primary key(id)); 
Query OK, 0 rows affected (0.00 sec)

mysql&gt; create table employees_teams(
    team_id int, 
    employee_id int, 
    primary key(team_id, employee_id), 
    foreign key (team_id) references teams(id), 
    foreign key (employee_id) references employees(id));
Query OK, 0 rows affected (0.01 sec)

mysql&gt; show tables;
+---------------------------+
| Tables_in_getting_started |
+---------------------------+
| employees                 |
| employees_teams           |
| teams                     |
+---------------------------+
3 rows in set (0.00 sec)
```

Dolt supports foreign keys, secondary indexes, triggers, check constraints, and stored procedures. It&#039;s a modern, feature-rich SQL database.

## Make a Dolt commit

It&#039;s time to use your first Dolt feature. We&#039;re going to make a Dolt [commit](https://docs.dolthub.com/concepts/dolt/commits). A Dolt commit allows you to time travel and see lineage. Make a Dolt commit whenever you want to restore or compare to this point in time.

Dolt exposes version control functionality through a Git-style interface. On the command line, Dolt commands map exactly to their Git equivalent with the targets being tables instead of files. In SQL, Dolt exposes version control read operations as [system tables](https://docs.dolthub.com/sql-reference/version-control/dolt-system-tables) and version control write operations as [stored procedures](https://docs.dolthub.com/sql-reference/version-control/dolt-sql-procedures). 

The naming of the system tables and stored procedures follows the `dolt_&lt;command&gt;` pattern. So `dolt add` on the CLI becomes `dolt_add` as a stored procedure. Passing options also follows the command line model. For instance, to specify tables to add, send the table names in as options to the `dolt_add` procedure. For named arguments like sending a message into the `dolt_commit` command use two arguments in sequence like `(&#039;-m&#039;, &#039;This is a message&#039;)`. If you know Git, the version control procedures and system tables should feel familiar.

So, we add and commit our new schema like so.

```
mysql&gt; call dolt_add(&#039;teams&#039;, &#039;employees&#039;, &#039;employees_teams&#039;);
+--------+
| status |
+--------+
|      0 |
+--------+
1 row in set (0.03 sec)

mysql&gt; call dolt_commit(&#039;-m&#039;, &#039;Created initial schema&#039;);
+----------------------------------+
| hash                             |
+----------------------------------+
| ne182jemgrlm8jnjmoubfqsstlfi1s98 |
+----------------------------------+
1 row in set (0.02 sec)

mysql&gt; select * from dolt_log;
+----------------------------------+-----------+-----------------+-------------------------+----------------------------+
| commit_hash                      | committer | email           | date                    | message                    |
+----------------------------------+-----------+-----------------+-------------------------+----------------------------+
| ne182jemgrlm8jnjmoubfqsstlfi1s98 | Tim Sehn  | tim@dolthub.com | 2022-06-07 16:35:49.277 | Created initial schema     |
| vluuhvd0bn59598utedt77ed9q5okbcb | Tim Sehn  | tim@dolthub.com | 2022-06-07 16:33:59.531 | Initialize data repository |
+----------------------------------+-----------+-----------------+-------------------------+----------------------------+
2 rows in set (0.01 sec)
```

There you have it. Your schema is created and you have a Dolt commit tracking the creation, as seen in the `dolt_log` system table.

Note, a Dolt commit is different than a standard SQL transaction `COMMIT`. In this case, I am running the database with [`AUTOCOMMIT`](https://dev.mysql.com/doc/refman/5.6/en/innodb-autocommit-commit-rollback.html) on, so each SQL statement is automatically generating a transaction `COMMIT`. If you want system to generate a Dolt commit for every transaction use the system variable, [`@@dolt_transaction_commit`](https://docs.dolthub.com/sql-reference/version-control/dolt-sysvars#dolt_transaction_commit).

## Insert some data

Now, I&#039;m going to populate the database with a few employees here at DoltHub. Then, I&#039;ll assign the employees to two teams: engineering and sales. The CEO wears many hats at a start up so he&#039;ll be assigned to multiple teams.

```
mysql&gt; insert into employees values 
    (0, &#039;Sehn&#039;, &#039;Tim&#039;), 
    (1, &#039;Hendriks&#039;, &#039;Brian&#039;), 
    (2, &#039;Son&#039;,&#039;Aaron&#039;), 
    (3, &#039;Fitzgerald&#039;, &#039;Brian&#039;);
Query OK, 4 rows affected (0.01 sec)

mysql&gt; select * from employees where first_name=&#039;Brian&#039;;
+------+------------+------------+
| id   | last_name  | first_name |
+------+------------+------------+
|    1 | Hendriks   | Brian      |
|    3 | Fitzgerald | Brian      |
+------+------------+------------+
2 rows in set (0.00 sec)

mysql&gt; insert into teams values 
    (0, &#039;Engineering&#039;), 
    (1, &#039;Sales&#039;);
Query OK, 2 rows affected (0.00 sec)

mysql&gt; insert into employees_teams values 
    (0,0), 
    (1,0), 
    (2,0), 
    (0,1), 
    (3,1);
ERROR 1452 (HY000): cannot add or update a child row - Foreign key violation on fk: `rv9ek7ft`, table: `employees_teams`, referenced table: `teams`, key: `[2]`
```

Oops, I violated a constraint. It looks like I created the table with teams before employees. You should always specify your columns when you insert, not rely on natural ordering. Serves me right! Dolt comes with the full power of a modern SQL relational database to ensure data integrity.

```
mysql&gt; insert into employees_teams(employee_id, team_id) values 
    (0,0), 
    (1,0), 
    (2,0), 
    (0,1), 
    (3,1);
Query OK, 5 rows affected (0.01 sec)

mysql&gt; select first_name, last_name, team_name from employees 
    join employees_teams on (employees.id=employees_teams.employee_id) 
    join teams on (teams.id=employees_teams.team_id) 
    where team_name=&#039;Engineering&#039;;
+------------+-----------+-------------+
| first_name | last_name | team_name   |
+------------+-----------+-------------+
| Tim        | Sehn      | Engineering |
| Brian      | Hendriks  | Engineering |
| Aaron      | Son       | Engineering |
+------------+-----------+-------------+
3 rows in set (0.00 sec)
```

Looks like everything is inserted and correct. I was able to list the members of the engineering team using that three table `JOIN`. Dolt supports up to twelve table `JOIN`s. Again, Dolt is a modern SQL relational database paired with Git-style version control.

## Examine the diff

Now, what if you want to see what changed in your working set before you make a commit? You use the `dolt_status` and `dolt_diff_&lt;tablename&gt;` system tables. 

```
mysql&gt; select * from dolt_status;
+-----------------+--------+----------+
| table_name      | staged | status   |
+-----------------+--------+----------+
| teams           |      0 | modified |
| employees       |      0 | modified |
| employees_teams |      0 | modified |
+-----------------+--------+----------+
3 rows in set (0.01 sec)

mysql&gt; select * from dolt_diff_employees;
+--------------+---------------+-------+-----------+----------------+----------------+-----------------+---------+----------------------------------+-------------------------+-----------+
| to_last_name | to_first_name | to_id | to_commit | to_commit_date | from_last_name | from_first_name | from_id | from_commit                      | from_commit_date        | diff_type |
+--------------+---------------+-------+-----------+----------------+----------------+-----------------+---------+----------------------------------+-------------------------+-----------+
| Sehn         | Tim           |     0 | WORKING   | NULL           | NULL           | NULL            |    NULL | ne182jemgrlm8jnjmoubfqsstlfi1s98 | 2022-06-07

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[lharries/whatsapp-mcp]]></title>
            <link>https://github.com/lharries/whatsapp-mcp</link>
            <guid>https://github.com/lharries/whatsapp-mcp</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:23 GMT</pubDate>
            <description><![CDATA[WhatsApp MCP server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lharries/whatsapp-mcp">lharries/whatsapp-mcp</a></h1>
            <p>WhatsApp MCP server</p>
            <p>Language: Go</p>
            <p>Stars: 5,330</p>
            <p>Forks: 884</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># WhatsApp MCP Server

This is a Model Context Protocol (MCP) server for WhatsApp.

With this you can search and read your personal Whatsapp messages (including images, videos, documents, and audio messages), search your contacts and send messages to either individuals or groups. You can also send media files including images, videos, documents, and audio messages.

It connects to your **personal WhatsApp account** directly via the Whatsapp web multidevice API (using the [whatsmeow](https://github.com/tulir/whatsmeow) library). All your messages are stored locally in a SQLite database and only sent to an LLM (such as Claude) when the agent accesses them through tools (which you control).

Here&#039;s an example of what you can do when it&#039;s connected to Claude.

![WhatsApp MCP](./example-use.png)

&gt; To get updates on this and other projects I work on [enter your email here](https://docs.google.com/forms/d/1rTF9wMBTN0vPfzWuQa2BjfGKdKIpTbyeKxhPMcEzgyI/preview)

&gt; *Caution:* as with many MCP servers, the WhatsApp MCP is subject to [the lethal trifecta](https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/). This means that project injection could lead to private data exfiltration.

## Installation

### Prerequisites

- Go
- Python 3.6+
- Anthropic Claude Desktop app (or Cursor)
- UV (Python package manager), install with `curl -LsSf https://astral.sh/uv/install.sh | sh`
- FFmpeg (_optional_) - Only needed for audio messages. If you want to send audio files as playable WhatsApp voice messages, they must be in `.ogg` Opus format. With FFmpeg installed, the MCP server will automatically convert non-Opus audio files. Without FFmpeg, you can still send raw audio files using the `send_file` tool.

### Steps

1. **Clone this repository**

   ```bash
   git clone https://github.com/lharries/whatsapp-mcp.git
   cd whatsapp-mcp
   ```

2. **Run the WhatsApp bridge**

   Navigate to the whatsapp-bridge directory and run the Go application:

   ```bash
   cd whatsapp-bridge
   go run main.go
   ```

   The first time you run it, you will be prompted to scan a QR code. Scan the QR code with your WhatsApp mobile app to authenticate.

   After approximately 20 days, you will might need to re-authenticate.

3. **Connect to the MCP server**

   Copy the below json with the appropriate {{PATH}} values:

   ```json
   {
     &quot;mcpServers&quot;: {
       &quot;whatsapp&quot;: {
         &quot;command&quot;: &quot;{{PATH_TO_UV}}&quot;, // Run `which uv` and place the output here
         &quot;args&quot;: [
           &quot;--directory&quot;,
           &quot;{{PATH_TO_SRC}}/whatsapp-mcp/whatsapp-mcp-server&quot;, // cd into the repo, run `pwd` and enter the output here + &quot;/whatsapp-mcp-server&quot;
           &quot;run&quot;,
           &quot;main.py&quot;
         ]
       }
     }
   }
   ```

   For **Claude**, save this as `claude_desktop_config.json` in your Claude Desktop configuration directory at:

   ```
   ~/Library/Application Support/Claude/claude_desktop_config.json
   ```

   For **Cursor**, save this as `mcp.json` in your Cursor configuration directory at:

   ```
   ~/.cursor/mcp.json
   ```

4. **Restart Claude Desktop / Cursor**

   Open Claude Desktop and you should now see WhatsApp as an available integration.

   Or restart Cursor.

### Windows Compatibility

If you&#039;re running this project on Windows, be aware that `go-sqlite3` requires **CGO to be enabled** in order to compile and work properly. By default, **CGO is disabled on Windows**, so you need to explicitly enable it and have a C compiler installed.

#### Steps to get it working:

1. **Install a C compiler**  
   We recommend using [MSYS2](https://www.msys2.org/) to install a C compiler for Windows. After installing MSYS2, make sure to add the `ucrt64\bin` folder to your `PATH`.  
   ‚Üí A step-by-step guide is available [here](https://code.visualstudio.com/docs/cpp/config-mingw).

2. **Enable CGO and run the app**

   ```bash
   cd whatsapp-bridge
   go env -w CGO_ENABLED=1
   go run main.go
   ```

Without this setup, you&#039;ll likely run into errors like:

&gt; `Binary was compiled with &#039;CGO_ENABLED=0&#039;, go-sqlite3 requires cgo to work.`

## Architecture Overview

This application consists of two main components:

1. **Go WhatsApp Bridge** (`whatsapp-bridge/`): A Go application that connects to WhatsApp&#039;s web API, handles authentication via QR code, and stores message history in SQLite. It serves as the bridge between WhatsApp and the MCP server.

2. **Python MCP Server** (`whatsapp-mcp-server/`): A Python server implementing the Model Context Protocol (MCP), which provides standardized tools for Claude to interact with WhatsApp data and send/receive messages.

### Data Storage

- All message history is stored in a SQLite database within the `whatsapp-bridge/store/` directory
- The database maintains tables for chats and messages
- Messages are indexed for efficient searching and retrieval

## Usage

Once connected, you can interact with your WhatsApp contacts through Claude, leveraging Claude&#039;s AI capabilities in your WhatsApp conversations.

### MCP Tools

Claude can access the following tools to interact with WhatsApp:

- **search_contacts**: Search for contacts by name or phone number
- **list_messages**: Retrieve messages with optional filters and context
- **list_chats**: List available chats with metadata
- **get_chat**: Get information about a specific chat
- **get_direct_chat_by_contact**: Find a direct chat with a specific contact
- **get_contact_chats**: List all chats involving a specific contact
- **get_last_interaction**: Get the most recent message with a contact
- **get_message_context**: Retrieve context around a specific message
- **send_message**: Send a WhatsApp message to a specified phone number or group JID
- **send_file**: Send a file (image, video, raw audio, document) to a specified recipient
- **send_audio_message**: Send an audio file as a WhatsApp voice message (requires the file to be an .ogg opus file or ffmpeg must be installed)
- **download_media**: Download media from a WhatsApp message and get the local file path

### Media Handling Features

The MCP server supports both sending and receiving various media types:

#### Media Sending

You can send various media types to your WhatsApp contacts:

- **Images, Videos, Documents**: Use the `send_file` tool to share any supported media type.
- **Voice Messages**: Use the `send_audio_message` tool to send audio files as playable WhatsApp voice messages.
  - For optimal compatibility, audio files should be in `.ogg` Opus format.
  - With FFmpeg installed, the system will automatically convert other audio formats (MP3, WAV, etc.) to the required format.
  - Without FFmpeg, you can still send raw audio files using the `send_file` tool, but they won&#039;t appear as playable voice messages.

#### Media Downloading

By default, just the metadata of the media is stored in the local database. The message will indicate that media was sent. To access this media you need to use the download_media tool which takes the `message_id` and `chat_jid` (which are shown when printing messages containing the meda), this downloads the media and then returns the file path which can be then opened or passed to another tool.

## Technical Details

1. Claude sends requests to the Python MCP server
2. The MCP server queries the Go bridge for WhatsApp data or directly to the SQLite database
3. The Go accesses the WhatsApp API and keeps the SQLite database up to date
4. Data flows back through the chain to Claude
5. When sending messages, the request flows from Claude through the MCP server to the Go bridge and to WhatsApp

## Troubleshooting

- If you encounter permission issues when running uv, you may need to add it to your PATH or use the full path to the executable.
- Make sure both the Go application and the Python server are running for the integration to work properly.

### Authentication Issues

- **QR Code Not Displaying**: If the QR code doesn&#039;t appear, try restarting the authentication script. If issues persist, check if your terminal supports displaying QR codes.
- **WhatsApp Already Logged In**: If your session is already active, the Go bridge will automatically reconnect without showing a QR code.
- **Device Limit Reached**: WhatsApp limits the number of linked devices. If you reach this limit, you&#039;ll need to remove an existing device from WhatsApp on your phone (Settings &gt; Linked Devices).
- **No Messages Loading**: After initial authentication, it can take several minutes for your message history to load, especially if you have many chats.
- **WhatsApp Out of Sync**: If your WhatsApp messages get out of sync with the bridge, delete both database files (`whatsapp-bridge/store/messages.db` and `whatsapp-bridge/store/whatsapp.db`) and restart the bridge to re-authenticate.

For additional Claude Desktop integration troubleshooting, see the [MCP documentation](https://modelcontextprotocol.io/quickstart/server#claude-for-desktop-integration-issues). The documentation includes helpful tips for checking logs and resolving common issues.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[jesseduffield/lazygit]]></title>
            <link>https://github.com/jesseduffield/lazygit</link>
            <guid>https://github.com/jesseduffield/lazygit</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:22 GMT</pubDate>
            <description><![CDATA[simple terminal UI for git commands]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jesseduffield/lazygit">jesseduffield/lazygit</a></h1>
            <p>simple terminal UI for git commands</p>
            <p>Language: Go</p>
            <p>Stars: 72,502</p>
            <p>Forks: 2,513</p>
            <p>Stars today: 84 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;sup&gt;Special thanks to:&lt;/sup&gt;
&lt;br&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=lazygit_20231023&quot;&gt;
  &lt;div&gt;
    &lt;img src=&quot;https://github.com/warpdotdev/brand-assets/blob/main/Github/Sponsor/Warp-Github-LG-02.png?raw=true&quot; width=&quot;400&quot; alt=&quot;Warp&quot;&gt;
  &lt;/div&gt;
  &lt;b&gt;Warp, the intelligent terminal&lt;/b&gt;
  &lt;br&gt;
  &lt;b&gt;Available for MacOS and Linux&lt;/b&gt;
  &lt;br&gt;
  &lt;div&gt;
    &lt;sup&gt;Visit¬†warp.dev¬†to learn more.&lt;/sup&gt;
  &lt;/div&gt;
&lt;/a&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;a href=&quot;https://tuple.app/lazygit&quot;&gt;
  &lt;div&gt;
    &lt;img src=&quot;../assets/tuple.png&quot; width=&quot;400&quot; alt=&quot;Tuple&quot;&gt;
  &lt;/div&gt;
  &lt;b&gt;Tuple, the premier screen sharing app for developers on macOS and Windows.&lt;/b&gt;
&lt;/a&gt;
&lt;br&gt;
&lt;hr&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.subble.com&quot;&gt;
  &lt;div&gt;
    &lt;img src=&quot;../assets/subble.webp&quot; width=&quot;400&quot; alt=&quot;Subble&quot;&gt;
  &lt;/div&gt;
  &lt;b&gt;I (Jesse) co-founded Subble to save your company time and money by finding unused and over-provisioned SaaS licences. Check it out!&lt;/b&gt;
&lt;/a&gt;
&lt;br&gt;

&lt;hr&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;536&quot; src=&quot;https://user-images.githubusercontent.com/8456633/174470852-339b5011-5800-4bb9-a628-ff230aa8cd4e.png&quot;&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

A simple terminal UI for git commands
&lt;br/&gt;

[![GitHub Releases](https://img.shields.io/github/downloads/jesseduffield/lazygit/total)](https://github.com/jesseduffield/lazygit/releases) [![Go Report Card](https://goreportcard.com/badge/github.com/jesseduffield/lazygit)](https://goreportcard.com/report/github.com/jesseduffield/lazygit) [![Codacy Badge](https://app.codacy.com/project/badge/Grade/f46416b715d74622895657935fcada21)](https://app.codacy.com/gh/jesseduffield/lazygit/dashboard?utm_source=gh&amp;utm_medium=referral&amp;utm_content=&amp;utm_campaign=Badge_grade) [![Codacy Badge](https://app.codacy.com/project/badge/Coverage/f46416b715d74622895657935fcada21)](https://app.codacy.com/gh/jesseduffield/lazygit/dashboard?utm_source=gh&amp;utm_medium=referral&amp;utm_content=&amp;utm_campaign=Badge_coverage) [![golangci-lint](https://img.shields.io/badge/linted%20by-golangci--lint-brightgreen)](https://golangci-lint.run/) [![GitHub tag](https://img.shields.io/github/v/tag/jesseduffield/lazygit?color=blue)](https://github.com/jesseduffield/lazygit/releases/latest) [![homebrew](https://img.shields.io/homebrew/v/lazygit?color=blue)](https://formulae.brew.sh/formula/lazygit)

![commit_and_push](../assets/demo/commit_and_push-compressed.gif)

&lt;/div&gt;

## Sponsors

&lt;p align=&quot;center&quot;&gt;
 Maintenance of this project is made possible by all the &lt;a href=&quot;https://github.com/jesseduffield/lazygit/graphs/contributors&quot;&gt;contributors&lt;/a&gt; and &lt;a href=&quot;https://github.com/sponsors/jesseduffield&quot;&gt;sponsors&lt;/a&gt;. If you&#039;d like to sponsor this project and have your avatar or company logo appear below &lt;a href=&quot;https://github.com/sponsors/jesseduffield&quot;&gt;click here&lt;/a&gt;. üíô
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;!-- sponsors --&gt;&lt;a href=&quot;https://github.com/intabulas&quot;&gt;&lt;img src=&quot;https://github.com/intabulas.png&quot; width=&quot;60px&quot; alt=&quot;Mark Lussier&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/peppy&quot;&gt;&lt;img src=&quot;https://github.com/peppy.png&quot; width=&quot;60px&quot; alt=&quot;Dean Herbert&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/piot&quot;&gt;&lt;img src=&quot;https://github.com/piot.png&quot; width=&quot;60px&quot; alt=&quot;Peter Bjorklund&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/rgwood&quot;&gt;&lt;img src=&quot;https://github.com/rgwood.png&quot; width=&quot;60px&quot; alt=&quot;Reilly Wood&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/oliverguenther&quot;&gt;&lt;img src=&quot;https://github.com/oliverguenther.png&quot; width=&quot;60px&quot; alt=&quot;Oliver G√ºnther&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/pawanjay176&quot;&gt;&lt;img src=&quot;https://github.com/pawanjay176.png&quot; width=&quot;60px&quot; alt=&quot;Pawan Dhananjay&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/naoey&quot;&gt;&lt;img src=&quot;https://github.com/naoey.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/carstengehling&quot;&gt;&lt;img src=&quot;https://github.com/carstengehling.png&quot; width=&quot;60px&quot; alt=&quot;Carsten Gehling&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Xetera&quot;&gt;&lt;img src=&quot;https://github.com/Xetera.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/nartc&quot;&gt;&lt;img src=&quot;https://github.com/nartc.png&quot; width=&quot;60px&quot; alt=&quot;Chau Tran&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/matejcik&quot;&gt;&lt;img src=&quot;https://github.com/matejcik.png&quot; width=&quot;60px&quot; alt=&quot;matejcik&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/lucatume&quot;&gt;&lt;img src=&quot;https://github.com/lucatume.png&quot; width=&quot;60px&quot; alt=&quot;theAverageDev (Luca Tumedei)&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/IvanZuy&quot;&gt;&lt;img src=&quot;https://github.com/IvanZuy.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/nicholascloud&quot;&gt;&lt;img src=&quot;https://github.com/nicholascloud.png&quot; width=&quot;60px&quot; alt=&quot;Nicholas Cloud&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ava1ar&quot;&gt;&lt;img src=&quot;https://github.com/ava1ar.png&quot; width=&quot;60px&quot; alt=&quot;Aliaksandr Stelmachonak&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/pedropombeiro&quot;&gt;&lt;img src=&quot;https://github.com/pedropombeiro.png&quot; width=&quot;60px&quot; alt=&quot;Pedro Pombeiro&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/bburgy&quot;&gt;&lt;img src=&quot;https://github.com/bburgy.png&quot; width=&quot;60px&quot; alt=&quot;Burgy Benjamin&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/JoeKlemmer&quot;&gt;&lt;img src=&quot;https://github.com/JoeKlemmer.png&quot; width=&quot;60px&quot; alt=&quot;Joe Klemmer&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/tobi&quot;&gt;&lt;img src=&quot;https://github.com/tobi.png&quot; width=&quot;60px&quot; alt=&quot;Tobias L√ºtke&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/benbfortis&quot;&gt;&lt;img src=&quot;https://github.com/benbfortis.png&quot; width=&quot;60px&quot; alt=&quot;Ben Beaumont&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jakewarren&quot;&gt;&lt;img src=&quot;https://github.com/jakewarren.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/tgpholly&quot;&gt;&lt;img src=&quot;https://github.com/tgpholly.png&quot; width=&quot;60px&quot; alt=&quot;Holly&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Tommylans&quot;&gt;&lt;img src=&quot;https://github.com/Tommylans.png&quot; width=&quot;60px&quot; alt=&quot;Tom Lanser&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/socketbox&quot;&gt;&lt;img src=&quot;https://github.com/socketbox.png&quot; width=&quot;60px&quot; alt=&quot;Casey Boettcher&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/bitprophet&quot;&gt;&lt;img src=&quot;https://github.com/bitprophet.png&quot; width=&quot;60px&quot; alt=&quot;Jeff Forcier&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/tayleighr&quot;&gt;&lt;img src=&quot;https://github.com/tayleighr.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Novakov&quot;&gt;&lt;img src=&quot;https://github.com/Novakov.png&quot; width=&quot;60px&quot; alt=&quot;Maciej T. Nowak&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jhillyerd&quot;&gt;&lt;img src=&quot;https://github.com/jhillyerd.png&quot; width=&quot;60px&quot; alt=&quot;James Hillyerd&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/nekhaevskiy&quot;&gt;&lt;img src=&quot;https://github.com/nekhaevskiy.png&quot; width=&quot;60px&quot; alt=&quot;Yury&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/reivilibre&quot;&gt;&lt;img src=&quot;https://github.com/reivilibre.png&quot; width=&quot;60px&quot; alt=&quot;Olivier &#039;reivilibre&#039;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/BSteffaniak&quot;&gt;&lt;img src=&quot;https://github.com/BSteffaniak.png&quot; width=&quot;60px&quot; alt=&quot;Braden Steffaniak&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jordan-gillard&quot;&gt;&lt;img src=&quot;https://github.com/jordan-gillard.png&quot; width=&quot;60px&quot; alt=&quot;Jordan Gillard&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/smangels&quot;&gt;&lt;img src=&quot;https://github.com/smangels.png&quot; width=&quot;60px&quot; alt=&quot;Sebastian&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/amslezak&quot;&gt;&lt;img src=&quot;https://github.com/amslezak.png&quot; width=&quot;60px&quot; alt=&quot;Andy Slezak&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mkock&quot;&gt;&lt;img src=&quot;https://github.com/mkock.png&quot; width=&quot;60px&quot; alt=&quot;Martin Kock&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/jessealama&quot;&gt;&lt;img src=&quot;https://github.com/jessealama.png&quot; width=&quot;60px&quot; alt=&quot;Jesse Alama&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/zoroqi&quot;&gt;&lt;img src=&quot;https://github.com/zoroqi.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/danielkokott&quot;&gt;&lt;img src=&quot;https://github.com/danielkokott.png&quot; width=&quot;60px&quot; alt=&quot;Daniel Kokott&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/heijmans&quot;&gt;&lt;img src=&quot;https://github.com/heijmans.png&quot; width=&quot;60px&quot; alt=&quot;Jan Heijmans&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/knowald&quot;&gt;&lt;img src=&quot;https://github.com/knowald.png&quot; width=&quot;60px&quot; alt=&quot;Kevin Nowald&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ethanjli&quot;&gt;&lt;img src=&quot;https://github.com/ethanjli.png&quot; width=&quot;60px&quot; alt=&quot;Ethan Li&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/phubaba&quot;&gt;&lt;img src=&quot;https://github.com/phubaba.png&quot; width=&quot;60px&quot; alt=&quot;Robert Forler&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/neunkasulle&quot;&gt;&lt;img src=&quot;https://github.com/neunkasulle.png&quot; width=&quot;60px&quot; alt=&quot;Jan Zenkner&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/RVxLab&quot;&gt;&lt;img src=&quot;https://github.com/RVxLab.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/FrederickGeek8&quot;&gt;&lt;img src=&quot;https://github.com/FrederickGeek8.png&quot; width=&quot;60px&quot; alt=&quot;Frederick Morlock&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ezdac&quot;&gt;&lt;img src=&quot;https://github.com/ezdac.png&quot; width=&quot;60px&quot; alt=&quot;Maximilian Langenfeld&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/lppassos&quot;&gt;&lt;img src=&quot;https://github.com/lppassos.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/neilcode&quot;&gt;&lt;img src=&quot;https://github.com/neilcode.png&quot; width=&quot;60px&quot; alt=&quot;Neil Lambert&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dhh&quot;&gt;&lt;img src=&quot;https://github.com/dhh.png&quot; width=&quot;60px&quot; alt=&quot;David Heinemeier Hansson&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ethanfischer&quot;&gt;&lt;img src=&quot;https://github.com/ethanfischer.png&quot; width=&quot;60px&quot; alt=&quot;Ethan Fischer&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/poshboytl&quot;&gt;&lt;img src=&quot;https://github.com/poshboytl.png&quot; width=&quot;60px&quot; alt=&quot;Terry Tai&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/roesnera&quot;&gt;&lt;img src=&quot;https://github.com/roesnera.png&quot; width=&quot;60px&quot; alt=&quot;Adam Roesner&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/seven1m&quot;&gt;&lt;img src=&quot;https://github.com/seven1m.png&quot; width=&quot;60px&quot; alt=&quot;Tim Morgan&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/sgoridotla1&quot;&gt;&lt;img src=&quot;https://github.com/sgoridotla1.png&quot; width=&quot;60px&quot; alt=&quot;Max Shypulniak&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ADIX7&quot;&gt;&lt;img src=&quot;https://github.com/ADIX7.png&quot; width=&quot;60px&quot; alt=&quot;Kov√°cs √Åd√°m&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/slowdub&quot;&gt;&lt;img src=&quot;https://github.com/slowdub.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/serranomorante&quot;&gt;&lt;img src=&quot;https://github.com/serranomorante.png&quot; width=&quot;60px&quot; alt=&quot;Patricio Serrano&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/kiriDevs&quot;&gt;&lt;img src=&quot;https://github.com/kiriDevs.png&quot; width=&quot;60px&quot; alt=&quot;Kiri&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/bjornevik&quot;&gt;&lt;img src=&quot;https://github.com/bjornevik.png&quot; width=&quot;60px&quot; alt=&quot;John Even Bj√∏rnevik&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/moberst&quot;&gt;&lt;img src=&quot;https://github.com/moberst.png&quot; width=&quot;60px&quot; alt=&quot;Michael Oberst&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/adam-e-trepanier&quot;&gt;&lt;img src=&quot;https://github.com/adam-e-trepanier.png&quot; width=&quot;60px&quot; alt=&quot;Adam Trepanier&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/arkalon76&quot;&gt;&lt;img src=&quot;https://github.com/arkalon76.png&quot; width=&quot;60px&quot; alt=&quot;Kenth Fagerlund&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Djuuu&quot;&gt;&lt;img src=&quot;https://github.com/Djuuu.png&quot; width=&quot;60px&quot; alt=&quot;Julien Tardot&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/antikytheraton&quot;&gt;&lt;img src=&quot;https://github.com/antikytheraton.png&quot; width=&quot;60px&quot; alt=&quot;Aaron Arredondo&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ellord&quot;&gt;&lt;img src=&quot;https://github.com/ellord.png&quot; width=&quot;60px&quot; alt=&quot;Ellord Tayag&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/EdgarPost&quot;&gt;&lt;img src=&quot;https://github.com/EdgarPost.png&quot; width=&quot;60px&quot; alt=&quot;Edgar Post-Buijs&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/caillou&quot;&gt;&lt;img src=&quot;https://github.com/caillou.png&quot; width=&quot;60px&quot; alt=&quot;Pierre Spring&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mebezac&quot;&gt;&lt;img src=&quot;https://github.com/mebezac.png&quot; width=&quot;60px&quot; alt=&quot;Zac Clay&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/Tom94&quot;&gt;&lt;img src=&quot;https://github.com/Tom94.png&quot; width=&quot;60px&quot; alt=&quot;Thomas M√ºller&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ccssmnn&quot;&gt;&lt;img src=&quot;https://github.com/ccssmnn.png&quot; width=&quot;60px&quot; alt=&quot;Carl Assmann&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ognevsd&quot;&gt;&lt;img src=&quot;https://github.com/ognevsd.png&quot; width=&quot;60px&quot; alt=&quot;Sergey Ognev&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/moodyhunter&quot;&gt;&lt;img src=&quot;https://github.com/moodyhunter.png&quot; width=&quot;60px&quot; alt=&quot;Moody Liu&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/elithper&quot;&gt;&lt;img src=&quot;https://github.com/elithper.png&quot; width=&quot;60px&quot; alt=&quot;Michael Howard&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/LasseBloch&quot;&gt;&lt;img src=&quot;https://github.com/LasseBloch.png&quot; width=&quot;60px&quot; alt=&quot;Lasse Bloch Lauritsen&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/lmarburger&quot;&gt;&lt;img src=&quot;https://github.com/lmarburger.png&quot; width=&quot;60px&quot; alt=&quot;Larry Marburger&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dbrockman&quot;&gt;&lt;img src=&quot;https://github.com/dbrockman.png&quot; width=&quot;60px&quot; alt=&quot;David Brockman&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/slavshik&quot;&gt;&lt;img src=&quot;https://github.com/slavshik.png&quot; width=&quot;60px&quot; alt=&quot;Alexander Slavschik&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/aidalgol&quot;&gt;&lt;img src=&quot;https://github.com/aidalgol.png&quot; width=&quot;60px&quot; alt=&quot;Aidan Gauland&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mbienkowsk&quot;&gt;&lt;img src=&quot;https://github.com/mbienkowsk.png&quot; width=&quot;60px&quot; alt=&quot;Maksym Bie≈Ñkowski&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/soyjimmysaenz&quot;&gt;&lt;img src=&quot;https://github.com/soyjimmysaenz.png&quot; width=&quot;60px&quot; alt=&quot;Jimmy S√°enz Rizo&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/joshuawootonn&quot;&gt;&lt;img src=&quot;https://github.com/joshuawootonn.png&quot; width=&quot;60px&quot; alt=&quot;Joshua Wootonn&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/I4nJ&quot;&gt;&lt;img src=&quot;https://github.com/I4nJ.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/sandviklee&quot;&gt;&lt;img src=&quot;https://github.com/sandviklee.png&quot; width=&quot;60px&quot; alt=&quot;Simon Sandvik Lee&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/glagnar&quot;&gt;&lt;img src=&quot;https://github.com/glagnar.png&quot; width=&quot;60px&quot; alt=&quot;Thomas Gilbert&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/skrzepto&quot;&gt;&lt;img src=&quot;https://github.com/skrzepto.png&quot; width=&quot;60px&quot; alt=&quot;Szymon Mucha&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/unnawut&quot;&gt;&lt;img src=&quot;https://github.com/unnawut.png&quot; width=&quot;60px&quot; alt=&quot;Unnawut Leepaisalsuwanna&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/wortmanb&quot;&gt;&lt;img src=&quot;https://github.com/wortmanb.png&quot; width=&quot;60px&quot; alt=&quot;Bret Wortman&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/simoncdna&quot;&gt;&lt;img src=&quot;https://github.com/simoncdna.png&quot; width=&quot;60px&quot; alt=&quot;Simon Cardona&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/andre-lameirinhas&quot;&gt;&lt;img src=&quot;https://github.com/andre-lameirinhas.png&quot; width=&quot;60px&quot; alt=&quot;Andr√© Lameirinhas&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/SVappsLAB&quot;&gt;&lt;img src=&quot;https://github.com/SVappsLAB.png&quot; width=&quot;60px&quot; alt=&quot;Scott Velez&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/ooojustin&quot;&gt;&lt;img src=&quot;https://github.com/ooojustin.png&quot; width=&quot;60px&quot; alt=&quot;justin&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mayfieldiv&quot;&gt;&lt;img src=&quot;https://github.com/mayfieldiv.png&quot; width=&quot;60px&quot; alt=&quot;Mayfield&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/somaholiday&quot;&gt;&lt;img src=&quot;https://github.com/somaholiday.png&quot; width=&quot;60px&quot; alt=&quot;Soma Holiday&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/bizmythy&quot;&gt;&lt;img src=&quot;https://github.com/bizmythy.png&quot; width=&quot;60px&quot; alt=&quot;bizmyth&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/dessalines&quot;&gt;&lt;img src=&quot;https://github.com/dessalines.png&quot; width=&quot;60px&quot; alt=&quot;Dessalines&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/KKodiac&quot;&gt;&lt;img src=&quot;https://github.com/KKodiac.png&quot; width=&quot;60px&quot; alt=&quot;Sean Hong(ÌôçÏÑ±ÎØº)&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/RADreymann&quot;&gt;&lt;img src=&quot;https://github.com/RADreymann.png&quot; width=&quot;60px&quot; alt=&quot;Alex Dreymann&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/felipeospina21&quot;&gt;&lt;img src=&quot;https://github.com/felipeospina21.png&quot; width=&quot;60px&quot; alt=&quot;Felipe Ospina&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/riccardoNovaglia&quot;&gt;&lt;img src=&quot;https://github.com/riccardoNovaglia.png&quot; width=&quot;60px&quot; alt=&quot;Riccardo Novaglia&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/nitipon-apaisri&quot;&gt;&lt;img src=&quot;https://github.com/nitipon-apaisri.png&quot; width=&quot;60px&quot; alt=&quot;rxz&quot; /&gt;&lt;/a&gt;&lt;!-- sponsors --&gt;
&lt;/p&gt;

## Elevator Pitch

Rant time: You&#039;ve heard it before, git is _powerful_, but what good is that power when everything is so damn hard to do? Interactive rebasing requires you to edit a goddamn TODO file in your editor? _Are you kidding me?_ To stage part of a file you need to use a command line program to step through each hunk and if a hunk can&#039;t be split down any further but contains code you don&#039;t want to stage, you have to edit an arcane patch file _by hand_? _Are you KIDDING me?!_ Sometimes you get asked to stash your changes when switching branches only to realise that after you switch and unstash that there weren&#039;t even any conflicts and it would have been fine to just checkout the branch directly? _YOU HAVE GOT TO BE KIDDING ME!_

If you&#039;re a mere mortal like me and you&#039;re tired of hearing how powerful git is when in your daily life it&#039;s a powerful pain in your ass, lazygit might be for you.

## Table of contents

- [Sponsors](#sponsors)
- [Elevator Pitch](#elevator-pitch)
- [Table of contents](#table-of-contents)
- [Features](#features)
  - [Stage individual lines](#stage-individual-lines)
  - [Interactive Rebase](#interactive-rebase)
  - [Cherry-pick](#cherry-pick)
  - [Bisect](#bisect)
  - [Nuke the working tree](#nuke-the-working-tree)
  - [Amend an old commit](#amend-an-old-commit)
  - [Filter](#filter)
  - [Invoke a custom command](#invoke-a-custom-command)
  - [Worktrees](#worktrees)
  - [Rebase magic (custom patches)](#rebase-magic-custom-patches)
  - [Rebase from marked base commit](#rebase-from-marked-base-commit)
  - [Undo](#undo)
  - [Commit graph](#commit-graph)
  - [Compare two commits](#compare-two-commits)
- [Tutorials](#tutorials)
- [Installation](#installation)
  - [Binary Releases](#binary-releases)
  - [Dev container](#dev-container-feature)
  - [Homebrew](#homebrew)
  - [MacPorts](#macports)
  - [Void Linux](#void-linux)
  - [Scoop (Windows)](#scoop-windows)
  - [gah (Linux and Mac OS)](#gah-linux-and-mac-os)
  - [Arch Linux](#arch-linux)
  - [Fedora / Amazon Linux 2023 / CentOS Stream](#fedora--amazon-linux-2023--centos-stream)
  - [Solus Linux](#solus-linux)
  - [Debian and Ubuntu](#debian-and-ubuntu)
  - [Funtoo Linux](#funtoo-linux)
  - [Gentoo Linux](#gentoo-linux)
  - [openSUSE](#opensuse)
  - [NixOS](#nixos)
  - [Flox](#flox)
  - [FreeBSD](#freebsd)
  - [Termux](#termux)
  - [Conda](#conda)
  - [Go](#go)
  - [Chocolatey (Windows)](#chocolatey-windows)
  - [Winget (Windows 10 1709 or later)](#winget-windows-10-1709-or-later)
  - [Manual](#manual)
- [Usage](#usage)
  - [Keybindings](#keybindings)
  - [Changing Directory On Exit](#changing-directory-on-exit)
  - [Undo/Redo](#undoredo)
- [Configuration](#configuration)
  - [Custom Pagers](#custom-pagers)
  - [Custom Commands](#custom-commands)
  - [Git flow support](#git-flow-support)
- [Contributing](#contributing)
  - [Debugging Locally](#debugging-locally)
- [Donate](#donate)
- [FAQ](#faq)
  - [What do the commit colors represent?](#what-do-the-commit-colors-represent)
- [Shameless Plug](#shameless-plug)
- [Alternatives](#alternatives)

Lazygit is not my fulltime job but it is a hefty part time job so if you want to support the project please consider [sponsoring me](https://github.com/sponsors/jesseduffield)

## Features

### Stage individual lines

Press space on the selected line to stage it, or press `v` to start selecting a range of lines. You can also press `a` to select the entirety of the current hunk.

![stage_lines](../assets/demo/stage_lines-compressed.gif)

### Interactive Rebase

Press `i` to start an interactive rebase. Then squash (`s`), fixup (`f`), drop (`d`), edit (`e`), move up (`ctrl+k`) or move down (`ctrl+j`) any of TODO commits, before continuing the rebase by bringing up the rebase options menu with `m` and then selecting `continue`.

You can also perform any these actions as a once-off (e.g. pressing `s` on a commit to squash it) without explicitly starting a rebase.

This demo also uses shift+down to select a range of commits to move and fixup.

![interactive_rebase](../assets/demo/interactive_rebase-compressed.gif)

### Cherry-pick

Press `shift+c` on a commit to copy it and press `shift+v` to paste (cherry-pick) it.

![cherry_pick](../assets/demo/cherry_pick-compressed.gif)

### Bisect

Press `b` in the commits view to mark a commit as good/bad in order to begin a git bisect.

![bisect](../assets/demo/bisect-compressed.gif)

### Nuke the working tree

For when you really want to just get rid of anything that shows up when you run `git status` (and yes that includes dirty submodules) [kidpix style](https://www.youtube.com/watch?v=N4E2B_k2Bss), press `shift+d` to bring up the reset options menu and then select the &#039;nuke&#039; option.

![Nuke working tree](../assets/demo/nuke_working_tree-compressed.gif)

### Amend an old commit

Pressing `shift+a` on any commit will amend that commit with the currently staged changes (running an interactive rebase in the background).

![amend_old_commit](../assets/demo/amend_old_commit-compressed.gif)

### Filter

You can

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-collector-contrib]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-collector-contrib</link>
            <guid>https://github.com/open-telemetry/opentelemetry-collector-contrib</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:21 GMT</pubDate>
            <description><![CDATA[Contrib repository for the OpenTelemetry Collector]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-collector-contrib">open-telemetry/opentelemetry-collector-contrib</a></h1>
            <p>Contrib repository for the OpenTelemetry Collector</p>
            <p>Language: Go</p>
            <p>Stars: 4,414</p>
            <p>Forks: 3,333</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>---

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt;
    &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector-contrib/build-and-test.yml?branch=main&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector-contrib&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/branch/main/&quot;&gt;
    &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector-contrib?include_prereleases&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;img alt=&quot;Beta&quot; src=&quot;https://img.shields.io/badge/status-beta-informational?style=for-the-badge&amp;logo=data:image/png;base64,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&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/vision.md&quot;&gt;Vision&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/observability.md&quot;&gt;Observability&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

---

# OpenTelemetry Collector Contrib

This is a repository for OpenTelemetry Collector components that are not suitable for the  [core repository](https://github.com/open-telemetry/opentelemetry-collector) of the collector. 

The official distributions, core and contrib, are available as part of the [opentelemetry-collector-releases](https://github.com/open-telemetry/opentelemetry-collector-releases) repository. Some of the components in this repository are part of the &quot;core&quot; distribution, such as the Jaeger and Prometheus components, but most of the components here are only available as part of the &quot;contrib&quot; distribution. Users of the OpenTelemetry Collector are also encouraged to build their own custom distributions with the [OpenTelemetry Collector Builder](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder), using the components they need from the core repository, the contrib repository, and possibly third-party or internal repositories.

Each component has its own support levels, as defined in the following sections. For each signal that a component supports, there&#039;s a stability level, setting the right expectations. It is possible then that a component will be **Stable** for traces but **Alpha** for metrics and **Development** for logs.

## Stability levels

Stability level for components in this repository follow the [definitions](https://github.com/open-telemetry/opentelemetry-collector#stability-levels) from the OpenTelemetry Collector repository.

## Gated features

Some features are hidden behind feature gates before they are part of the main code path for the component. Note that the feature gates themselves might be at different [lifecycle stages](https://github.com/open-telemetry/opentelemetry-collector/tree/main/featuregate#feature-lifecycle).

## Support

Each component is supported either by the community of OpenTelemetry Collector Contrib maintainers, as defined by the GitHub group [@open-telemetry/collector-contrib-maintainer](https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer), or by specific vendors. See the individual README files for information about the specific components.

The OpenTelemetry Collector Contrib maintainers may at any time downgrade specific components if they are deemed unmaintained or if they pose a risk to the repository and/or binary distribution.

Even though the OpenTelemetry Collector Contrib maintainers are ultimately responsible for the components hosted here, actual support will likely be provided by individual contributors, typically a code owner for the specific component.

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md).

### Maintainers

- [Alex Boten](https://github.com/codeboten), Honeycomb
- [Andrzej Stencel](https://github.com/andrzej-stencel), Elastic
- [Antoine Toulme](https://github.com/atoulme), Splunk
- [Bogdan Drutu](https://github.com/bogdandrutu), Snowflake
- [Christos Markou](https://github.com/ChrsMark), Elastic
- [Dmitrii Anoshin](https://github.com/dmitryax), Splunk
- [Edmo Vamerlatti Costa](https://github.com/edmocosta), Elastic
- [Evan Bradley](https://github.com/evan-bradley), Dynatrace
- [Pablo Baeyens](https://github.com/mx-psi), DataDog
- [Sean Marciniak](https://github.com/MovieStoreGuy), Splunk
- [Tyler Helmuth](https://github.com/TylerHelmuth), Honeycomb
- [Yang Song](https://github.com/songy23), DataDog

For more information about the maintainer role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#maintainer).

### Approvers

- [Andrew Wilkins](https://github.com/axw), Elastic
- [Arthur Silva Sens](https://github.com/ArthurSens), Grafana Labs
- [Braydon Kains](https://github.com/braydonk), Google
- [Curtis Robert](https://github.com/crobert-1), Splunk
- [David Ashpole](https://github.com/dashpole), Google
- [Paulo Janotti](https://github.com/pjanotti), Splunk
- [Sam DeHaan](https://github.com/dehaansa), Grafana Labs
- [Vihas Makwana](https://github.com/VihasMakwana), Elastic
- [Ziqi Zhao](https://github.com/fatsheep9146), Alibaba

For more information about the approver role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#approver).

### Triagers

- [Benedikt Bongartz](https://github.com/frzifus), Red Hat
- [Bogdan Stancu](https://github.com/bogdan-st), Adobe
- [Constan√ßa Manteigas](https://github.com/constanca-m), Elastic
- [Douglas Camata](https://github.com/douglascamata), Coralogix
- [Israel Blancas](https://github.com/iblancasa), Coralogix
- [James Moessis](https://github.com/jamesmoessis), Atlassian
- [Jared Tan](https://github.com/JaredTan95), DaoCloud
- [Murphy Chen](https://github.com/Frapschen), DaoCloud
- [Ondrej Dubaj](https://github.com/odubajDT), Dynatrace
- [Paulo Dias](https://github.com/paulojmdias), Five9
- [Roger Coll](https://github.com/rogercoll), Elastic
- Actively seeking contributors to triage issues

For more information about the triager role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#triager).

### Emeritus Maintainers

- [Daniel Jaglowski](https://github.com/djaglowski)
- [Juraci Paix√£o Kr√∂hling](https://github.com/jpkrohling)
- [Tigran Najaryan](https://github.com/tigrannajaryan)

For more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).

### Emeritus Approvers

- [Anthony Mirabella](https://github.com/Aneurysm9)
- [Bryan Aguilar](https://github.com/bryan-aguilar)
- [Matt Wear](https://github.com/mwear)
- [Przemek Maciolek](https://github.com/pmm-sumo)
- [Ruslan Kovalov](https://github.com/kovrus)

For more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).

### Emeritus Triagers

- [Alolita Sharma](https://github.com/alolita)
- [Gabriel Aszalos](https://github.com/gbbr)
- [Goutham Veeramachaneni](https://github.com/gouthamve)
- [Punya Biswal](https://github.com/punya)
- [Steve Flanders](https://github.com/flands)
- [Florian Bacher](https://github.com/bacherfl), Dynatrace

For more information about the emeritus role, see the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md#emeritus-maintainerapprovertriager).

### No Over-Representation

A community member cannot be promoted to be a Collector contrib maintainer if, after their promotion, the resulting maintainers group has more than one-fourth (25%) of the members affiliated with the same employer. Job changes and similar events might result in over-representation, and no new maintainers from the same company can be promoted until representation is balanced again. In the event of confusion or concern, the OpenTelemetry Collector SIG will defer to the CNCF definition of &quot;same employer&quot;.

## PRs and Reviews

When creating a PR please follow the process [described
here](https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md#how-to-structure-prs-to-get-expedient-reviews).

New PRs will be automatically associated with the reviewers based on
[CODEOWNERS](.github/CODEOWNERS). PRs will be also automatically assigned to one of the
maintainers or approvers for facilitation.

The facilitator is responsible for helping the PR author and reviewers to make progress
or if progress cannot be made for closing the PR.

If the reviewers do not have approval rights the facilitator is also responsible
for the official approval that is required for the PR to be merged and if the facilitator
is a maintainer they are responsible for merging the PR as well.

The facilitator is not required to perform a thorough review, but they are encouraged to
enforce Collector best practices and consistency across the codebase and component
behavior. The facilitators will typically rely on codeowner&#039;s detailed review of the code
when making the final approval decision.

Marking the PR with the `ready to merge` label should only happen (by triagers/approvers/maintainers)
once there is at least one approval from an approver, as per the description above. 
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[sqlc-dev/sqlc]]></title>
            <link>https://github.com/sqlc-dev/sqlc</link>
            <guid>https://github.com/sqlc-dev/sqlc</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:20 GMT</pubDate>
            <description><![CDATA[Generate type-safe code from SQL]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sqlc-dev/sqlc">sqlc-dev/sqlc</a></h1>
            <p>Generate type-safe code from SQL</p>
            <p>Language: Go</p>
            <p>Stars: 16,964</p>
            <p>Forks: 995</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># sqlc: A SQL Compiler

![go](https://github.com/sqlc-dev/sqlc/workflows/go/badge.svg)
[![Go Report Card](https://goreportcard.com/badge/github.com/sqlc-dev/sqlc)](https://goreportcard.com/report/github.com/sqlc-dev/sqlc)

sqlc generates **type-safe code** from SQL. Here&#039;s how it works:

1. You write queries in SQL.
1. You run sqlc to generate code with type-safe interfaces to those queries.
1. You write application code that calls the generated code.

Check out [an interactive example](https://play.sqlc.dev/) to see it in action, and the [introductory blog post](https://conroy.org/introducing-sqlc) for the motivation behind sqlc.

## Overview

- [Documentation](https://docs.sqlc.dev)
- [Installation](https://docs.sqlc.dev/en/latest/overview/install.html)
- [Playground](https://play.sqlc.dev)
- [Website](https://sqlc.dev)
- [Downloads](https://downloads.sqlc.dev/)
- [Community](https://discord.gg/EcXzGe5SEs)

## Supported languages

- [sqlc-gen-go](https://github.com/sqlc-dev/sqlc-gen-go)
- [sqlc-gen-kotlin](https://github.com/sqlc-dev/sqlc-gen-kotlin)
- [sqlc-gen-python](https://github.com/sqlc-dev/sqlc-gen-python)
- [sqlc-gen-typescript](https://github.com/sqlc-dev/sqlc-gen-typescript)

Additional languages can be added via [plugins](https://docs.sqlc.dev/en/latest/reference/language-support.html#community-language-support).

## Sponsors

Development is possible thanks to our sponsors. If you would like to support sqlc,
please consider [sponsoring on GitHub](https://github.com/sponsors/kyleconroy).

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://riza.io?utm_source=sqlc+readme&quot;&gt;&lt;img width=400 src=&quot;https://sqlc.dev/sponsors/riza-readme.png&quot; alt=&quot;Riza.io&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://coder.com?utm_source=sqlc+readme&quot;&gt;&lt;img width=200 src=&quot;https://sqlc.dev/sponsors/coder-readme.png&quot; alt=&quot;Coder.com&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://mint.fun?utm_source=sqlc+readme&quot;&gt;&lt;img width=200 src=&quot;https://sqlc.dev/sponsors/mint-readme.png&quot; alt=&quot;Mint.fun&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://mux.com?utm_source=sqlc+readme&quot;&gt;&lt;img width=200 src=&quot;https://sqlc.dev/sponsors/mux-readme.png&quot; alt=&quot;Mux.com&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/Cyberax&quot;&gt;Cyberax&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/NaNuNaNu&quot;&gt;NaNuNaNu&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/Stumble&quot;&gt;Stumble&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/WestfalNamur&quot;&gt;WestfalNamur&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/alecthomas&quot;&gt;alecthomas&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/cameronnewman&quot;&gt;cameronnewman&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/danielbprice&quot;&gt;danielbprice&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/davherrmann&quot;&gt;davherrmann&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/dvob&quot;&gt;dvob&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/gilcrest&quot;&gt;gilcrest&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/gzuidhof&quot;&gt;gzuidhof&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/jeffreylo&quot;&gt;jeffreylo&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/mmcloughlin&quot;&gt;mmcloughlin&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/ryohei1216&quot;&gt;ryohei1216&lt;/a&gt; - 
  &lt;a href=&quot;https://github.com/sgielen&quot;&gt;sgielen&lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[modelcontextprotocol/registry]]></title>
            <link>https://github.com/modelcontextprotocol/registry</link>
            <guid>https://github.com/modelcontextprotocol/registry</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:19 GMT</pubDate>
            <description><![CDATA[A community driven registry service for Model Context Protocol (MCP) servers.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/modelcontextprotocol/registry">modelcontextprotocol/registry</a></h1>
            <p>A community driven registry service for Model Context Protocol (MCP) servers.</p>
            <p>Language: Go</p>
            <p>Stars: 6,427</p>
            <p>Forks: 606</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># MCP Registry

The MCP registry provides MCP clients with a list of MCP servers, like an app store for MCP servers.

[**üì§ Publish my MCP server**](docs/modelcontextprotocol-io/quickstart.mdx) | [**‚ö°Ô∏è Live API docs**](https://registry.modelcontextprotocol.io/docs) | [**üëÄ Ecosystem vision**](docs/design/ecosystem-vision.md) | üìñ **[Full documentation](./docs)**

## Development Status

**2025-10-24 update**: The Registry API has entered an **API freeze (v0.1)** üéâ. For the next month or more, the API will remain stable with no breaking changes, allowing integrators to confidently implement support. This freeze applies to v0.1 while development continues on v0. We&#039;ll use this period to validate the API in real-world integrations and gather feedback to shape v1 for general availability. Thank you to everyone for your contributions and patience‚Äîyour involvement has been key to getting us here!

**2025-09-08 update**: The registry has launched in preview üéâ ([announcement blog post](https://blog.modelcontextprotocol.io/posts/2025-09-08-mcp-registry-preview/)). While the system is now more stable, this is still a preview release and breaking changes or data resets may occur. A general availability (GA) release will follow later. We&#039;d love your feedback in [GitHub discussions](https://github.com/modelcontextprotocol/registry/discussions/new?category=ideas) or in the [#registry-dev Discord](https://discord.com/channels/1358869848138059966/1369487942862504016) ([joining details here](https://modelcontextprotocol.io/community/communication)).

Current key maintainers:
- **Adam Jones** (Anthropic) [@domdomegg](https://github.com/domdomegg)  
- **Tadas Antanavicius** (PulseMCP) [@tadasant](https://github.com/tadasant)
- **Toby Padilla** (GitHub) [@toby](https://github.com/toby)
- **Radoslav (Rado) Dimitrov** (Stacklok) [@rdimitrov](https://github.com/rdimitrov)

## Contributing

We use multiple channels for collaboration - see [modelcontextprotocol.io/community/communication](https://modelcontextprotocol.io/community/communication).

Often (but not always) ideas flow through this pipeline:

- **[Discord](https://modelcontextprotocol.io/community/communication)** - Real-time community discussions
- **[Discussions](https://github.com/modelcontextprotocol/registry/discussions)** - Propose and discuss product/technical requirements
- **[Issues](https://github.com/modelcontextprotocol/registry/issues)** - Track well-scoped technical work  
- **[Pull Requests](https://github.com/modelcontextprotocol/registry/pulls)** - Contribute work towards issues

### Quick start:

#### Pre-requisites

- **Docker**
- **Go 1.24.x**
- **ko** - Container image builder for Go ([installation instructions](https://ko.build/install/))
- **golangci-lint v2.4.0**

#### Running the server

```bash
# Start full development environment
make dev-compose
```

This starts the registry at [`localhost:8080`](http://localhost:8080) with PostgreSQL. The database uses ephemeral storage and is reset each time you restart the containers, ensuring a clean state for development and testing.

**Note:** The registry uses [ko](https://ko.build) to build container images. The `make dev-compose` command automatically builds the registry image with ko and loads it into your local Docker daemon before starting the services.

By default, the registry seeds from the production API with a filtered subset of servers (to keep startup fast). This ensures your local environment mirrors production behavior and all seed data passes validation. For offline development you can seed from a file without validation with `MCP_REGISTRY_SEED_FROM=data/seed.json MCP_REGISTRY_ENABLE_REGISTRY_VALIDATION=false make dev-compose`.

The setup can be configured with environment variables in [docker-compose.yml](./docker-compose.yml) - see [.env.example](./.env.example) for a reference.

&lt;details&gt;
&lt;summary&gt;Alternative: Running a pre-built Docker image&lt;/summary&gt;

Pre-built Docker images are automatically published to GitHub Container Registry:

```bash
# Run latest stable release
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:latest

# Run latest from main branch (continuous deployment)
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:main

# Run specific release version
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:v1.0.0

# Run development build from main branch
docker run -p 8080:8080 ghcr.io/modelcontextprotocol/registry:main-20250906-abc123d
```

**Available tags:** 
- **Releases**: `latest`, `v1.0.0`, `v1.1.0`, etc.
- **Continuous**: `main` (latest main branch build)
- **Development**: `main-&lt;date&gt;-&lt;sha&gt;` (specific commit builds)

&lt;/details&gt;

#### Publishing a server

To publish a server, we&#039;ve built a simple CLI. You can use it with:

```bash
# Build the latest CLI
make publisher

# Use it!
./bin/mcp-publisher --help
```

See [the publisher guide](./docs/modelcontextprotocol-io/quickstart.mdx) for more details.

#### Other commands

```bash
# Run lint, unit tests and integration tests
make check
```

There are also a few more helpful commands for development. Run `make help` to learn more, or look in [Makefile](./Makefile).

&lt;!--
For Claude and other AI tools: Always prefer make targets over custom commands where possible.
--&gt;

## Architecture

### Project Structure

```
‚îú‚îÄ‚îÄ cmd/                     # Application entry points
‚îÇ   ‚îî‚îÄ‚îÄ publisher/           # Server publishing tool
‚îú‚îÄ‚îÄ data/                    # Seed data
‚îú‚îÄ‚îÄ deploy/                  # Deployment configuration (Pulumi)
‚îú‚îÄ‚îÄ docs/                    # Documentation
‚îú‚îÄ‚îÄ internal/                # Private application code
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # HTTP handlers and routing
‚îÇ   ‚îú‚îÄ‚îÄ auth/                # Authentication (GitHub OAuth, JWT, namespace blocking)
‚îÇ   ‚îú‚îÄ‚îÄ config/              # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ database/            # Data persistence (PostgreSQL)
‚îÇ   ‚îú‚îÄ‚îÄ service/             # Business logic
‚îÇ   ‚îú‚îÄ‚îÄ telemetry/           # Metrics and monitoring
‚îÇ   ‚îî‚îÄ‚îÄ validators/          # Input validation
‚îú‚îÄ‚îÄ pkg/                     # Public packages
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # API types and structures
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ v0/              # Version 0 API types
‚îÇ   ‚îî‚îÄ‚îÄ model/               # Data models for server.json
‚îú‚îÄ‚îÄ scripts/                 # Development and testing scripts
‚îú‚îÄ‚îÄ tests/                   # Integration tests
‚îî‚îÄ‚îÄ tools/                   # CLI tools and utilities
    ‚îî‚îÄ‚îÄ validate-*.sh        # Schema validation tools
```

### Authentication

Publishing supports multiple authentication methods:
- **GitHub OAuth** - For publishing by logging into GitHub
- **GitHub OIDC** - For publishing from GitHub Actions
- **DNS verification** - For proving ownership of a domain and its subdomains
- **HTTP verification** - For proving ownership of a domain

The registry validates namespace ownership when publishing. E.g. to publish...:
- `io.github.domdomegg/my-cool-mcp` you must login to GitHub as `domdomegg`, or be in a GitHub Action on domdomegg&#039;s repos
- `me.adamjones/my-cool-mcp` you must prove ownership of `adamjones.me` via DNS or HTTP challenge

## Community Projects

Check out [community projects](docs/community-projects.md) to explore notable registry-related work created by the community.

## More documentation

See the [documentation](./docs) for more details if your question has not been answered here!
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[icereed/paperless-gpt]]></title>
            <link>https://github.com/icereed/paperless-gpt</link>
            <guid>https://github.com/icereed/paperless-gpt</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:18 GMT</pubDate>
            <description><![CDATA[Use LLMs and LLM Vision (OCR) to handle paperless-ngx - Document Digitalization powered by AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/icereed/paperless-gpt">icereed/paperless-gpt</a></h1>
            <p>Use LLMs and LLM Vision (OCR) to handle paperless-ngx - Document Digitalization powered by AI</p>
            <p>Language: Go</p>
            <p>Stars: 1,919</p>
            <p>Forks: 106</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># paperless-gpt

[![License](https://img.shields.io/github/license/icereed/paperless-gpt)](LICENSE)
[![Discord Banner](https://img.shields.io/badge/Join%20us%20on-Discord-blue?logo=discord)](https://discord.gg/fJQppDH2J7)
[![Docker Pulls](https://img.shields.io/docker/pulls/icereed/paperless-gpt)](https://hub.docker.com/r/icereed/paperless-gpt)
[![GitHub Container Registry](https://img.shields.io/badge/GHCR-Package-181717?logo=github)](https://github.com/icereed/paperless-gpt/pkgs/container/paperless-gpt)
[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](CODE_OF_CONDUCT.md)
[![GitHub Sponsors](https://img.shields.io/badge/Sponsor-icereed-ea4aaa?logo=github-sponsors)](https://github.com/sponsors/icereed)


&lt;a href=&quot;https://trendshift.io/repositories/12701&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/12701&quot; alt=&quot;icereed%2Fpaperless-gpt | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

![Screenshot](./paperless-gpt-screenshot.png)

&lt;sub&gt;üí° Maintained by [Icereed](https://github.com/icereed). Proudly supported by [BubbleTax.de](https://bubbletax.de/?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=paperless) ‚Äì automated, BMF-compliant tax reports for Interactive Brokers traders in Germany.&lt;/sub&gt;

---
**paperless-gpt** seamlessly pairs with [paperless-ngx][paperless-ngx] to generate **AI-powered document titles** and **tags**, saving you hours of manual sorting. While other tools may offer AI chat features, **paperless-gpt** stands out by **supercharging OCR with LLMs**-ensuring high accuracy, even with tricky scans. If you&#039;re craving next-level text extraction and effortless document organization, this is your solution.

https://github.com/user-attachments/assets/bd5d38b9-9309-40b9-93ca-918dfa4f3fd4

&gt; **‚ù§Ô∏è Support This Project**  
&gt; If paperless-gpt is helping you organize your documents and saving you time, please consider [sponsoring its development](https://github.com/sponsors/icereed). Your support helps ensure continued improvements and maintenance!

---

## Key Highlights

1. **LLM-Enhanced OCR**  
   Harness Large Language Models (OpenAI or Ollama) for **better-than-traditional** OCR‚Äîturn messy or low-quality scans into context-aware, high-fidelity text.

2. **Use specialized AI OCR services**

   - **LLM OCR**: Use OpenAI or Ollama to extract text from images.
   - **Google Document AI**: Leverage Google&#039;s powerful Document AI for OCR tasks.
   - **Azure Document Intelligence**: Use Microsoft&#039;s enterprise OCR solution.
   - **Docling Server**: Self-hosted OCR and document conversion service

3. **Automatic Title, Tag &amp; Created Date Generation**  
   No more guesswork. Let the AI do the naming and categorizing. You can easily review suggestions and refine them if needed.

4. **Supports reasoning models in Ollama**  
   Greatly enhance accuracy by using a reasoning model like `qwen3:8b`. The perfect tradeoff between privacy and performance! Of course, if you got enough GPUs or NPUs, a bigger model will enhance the experience.

5. **Automatic Correspondent Generation**  
   Automatically identify and generate correspondents from your documents, making it easier to track and organize your communications.

6. **Automatic Custom Field Generation**  
   Extract and populate custom fields from your documents. Configure which fields to target and how they should be filled. This feature must be enabled in the settings, and you must select at least one custom field for it to function. Three write modes are available:
   - **Append**: This is the safest option: It only adds new fields that do not already exist on the document. It will never overwrite an existing field, even if it&#039;s empty.
   - **Update**: Adds new fields and overwrites existing fields with new suggestions. Fields on the document that don&#039;t have a new suggestion are left untouched.
   - **Replace**: Deletes all existing custom fields on the document and replaces them entirely with the suggested fields.

7. **Searchable &amp; Selectable PDFs**  
   Generate PDFs with transparent text layers positioned accurately over each word, making your documents both searchable and selectable while preserving the original appearance.

7. **Extensive Customization**

   - **Customizable Prompts via Web UI**: Tweak and manage all AI prompts for titles, tags, correspondents, and more directly within the web interface under the &quot;Settings&quot; menu. The application uses a safe `default_prompts` and `prompts` directory structure, ensuring your customizations are persistent.
   - **Tagging**: Decide how documents get tagged‚Äîmanually, automatically, or via OCR-based flows.
   - **PDF Processing**: Configure how OCR-enhanced PDFs are handled, with options to save locally or upload to paperless-ngx.

8. **Simple Docker Deployment**  
   A few environment variables, and you&#039;re off! Compose it alongside paperless-ngx with minimal fuss.

9. **Unified Web UI**

   - **Manual Review**: Approve or tweak AI&#039;s suggestions.
   - **Auto Processing**: Focus only on edge cases while the rest is sorted for you.

9. **Ad-hoc Document Analysis**
   Perform ad-hoc analysis on a selection of documents using a custom prompt. Gain quick insights, summaries, or extract specific information from multiple documents at once.

---

## Table of Contents

- [paperless-gpt](#paperless-gpt)
  - [Key Highlights](#key-highlights)
  - [Table of Contents](#table-of-contents)
  - [Getting Started](#getting-started)
    - [Prerequisites](#prerequisites)
    - [Installation](#installation)
      - [Docker Compose](#docker-compose)
      - [Manual Setup](#manual-setup)
  - [OCR Providers](#ocr-providers)
    - [1. LLM-based OCR (Default)](#1-llm-based-ocr-default)
    - [2. Azure Document Intelligence](#2-azure-document-intelligence)
    - [3. Google Document AI](#3-google-document-ai)
    - [4. Docling Server](#4-docling-server)
  - [OCR Processing Modes](#ocr-processing-modes)
    - [Image Mode (Default)](#image-mode-default)
    - [PDF Mode](#pdf-mode)
    - [Whole PDF Mode](#whole-pdf-mode)
    - [Provider Compatibility](#provider-compatibility)
    - [Existing OCR Detection](#existing-ocr-detection)
  - [Enhanced OCR Features](#enhanced-ocr-features)
    - [PDF Text Layer Generation](#pdf-text-layer-generation)
    - [Local File Saving](#local-file-saving)
    - [PDF Upload to paperless-ngx](#pdf-upload-to-paperless-ngx)
    - [Metadata Copying Limitations](#metadata-copying-limitations)
    - [Safety Features](#safety-features)
    - [Usage Recommendations](#usage-recommendations)
  - [Configuration](#configuration)
    - [Environment Variables](#environment-variables)
    - [Custom Prompt Templates](#custom-prompt-templates)
      - [Template Variables](#template-variables)
  - [LLM-Based OCR: Compare for Yourself](#llm-based-ocr-compare-for-yourself)
    - [Example 1](#example-1)
    - [Example 2](#example-2)
    - [How It Works](#how-it-works)
  - [Usage](#usage)
  - [Troubleshooting](#troubleshooting)
    - [Working with Local LLMs](#working-with-local-llms)
      - [Token Management](#token-management)
    - [PDF Processing Issues](#pdf-processing-issues)
    - [Custom Field Generation Issues](#custom-field-generation-issues)
  - [Contributing](#contributing)
  - [Support the Project](#support-the-project)
  - [License](#license)
  - [Star History](#star-history)
  - [Disclaimer](#disclaimer)

---

## Getting Started

### Prerequisites

- [Docker][docker-install] installed.
- A running instance of [paperless-ngx][paperless-ngx].
- Access to an LLM provider:
  - **OpenAI**: An API key with models like `gpt-4o` or `gpt-3.5-turbo`.
  - **Ollama**: A running Ollama server with models like `qwen3:8b`.

### Installation

#### Docker Compose

Here&#039;s an example `docker-compose.yml` to spin up **paperless-gpt** alongside paperless-ngx:

```yaml
services:
  paperless-ngx:
    image: ghcr.io/paperless-ngx/paperless-ngx:latest
    # ... (your existing paperless-ngx config)

  paperless-gpt:
    # Use one of these image sources:
    image: icereed/paperless-gpt:latest # Docker Hub
    # image: ghcr.io/icereed/paperless-gpt:latest  # GitHub Container Registry
    environment:
      PAPERLESS_BASE_URL: &quot;http://paperless-ngx:8000&quot;
      PAPERLESS_API_TOKEN: &quot;your_paperless_api_token&quot;
      PAPERLESS_PUBLIC_URL: &quot;http://paperless.mydomain.com&quot; # Optional
      MANUAL_TAG: &quot;paperless-gpt&quot; # Optional, default: paperless-gpt
      AUTO_TAG: &quot;paperless-gpt-auto&quot; # Optional, default: paperless-gpt-auto
      # LLM Configuration - Choose one:

      # Option 1: Standard OpenAI
      LLM_PROVIDER: &quot;openai&quot;
      LLM_MODEL: &quot;gpt-4o&quot;
      OPENAI_API_KEY: &quot;your_openai_api_key&quot;

      # Option 2: Mistral
      # LLM_PROVIDER: &quot;mistral&quot;
      # LLM_MODEL: &quot;mistral-large-latest&quot;
      # MISTRAL_API_KEY: &quot;your_mistral_api_key&quot;

      # Option 3: Azure OpenAI
      # LLM_PROVIDER: &quot;openai&quot;
      # LLM_MODEL: &quot;your-deployment-name&quot;
      # OPENAI_API_KEY: &quot;your_azure_api_key&quot;
      # OPENAI_API_TYPE: &quot;azure&quot;
      # OPENAI_BASE_URL: &quot;https://your-resource.openai.azure.com&quot;

      # Option 4: Ollama (Local)
      # LLM_PROVIDER: &quot;ollama&quot;
      # LLM_MODEL: &quot;qwen3:8b&quot;
      # OLLAMA_HOST: &quot;http://host.docker.internal:11434&quot;
      # OLLAMA_CONTEXT_LENGTH: &quot;8192&quot; # Sets Ollama NumCtx (context window)
      # TOKEN_LIMIT: 1000 # Recommended for smaller models

      # Option 5: Anthropic/Claude
      # LLM_PROVIDER: &quot;anthropic&quot;
      # LLM_MODEL: &quot;claude-sonnet-4-5&quot;
      # ANTHROPIC_API_KEY: &quot;your_anthropic_api_key&quot;

      # Optional LLM Settings
      # LLM_LANGUAGE: &quot;English&quot; # Optional, default: English

      # OCR Configuration - Choose one:
      # Option 1: LLM-based OCR
      OCR_PROVIDER: &quot;llm&quot; # Default OCR provider
      VISION_LLM_PROVIDER: &quot;ollama&quot; # openai, ollama, mistral, or anthropic
      VISION_LLM_MODEL: &quot;minicpm-v&quot; # minicpm-v (ollama) or gpt-4o (openai) or claude-sonnet-4-5 (anthropic/claude)
      OLLAMA_HOST: &quot;http://host.docker.internal:11434&quot; # If using Ollama

      # OCR Processing Mode
      OCR_PROCESS_MODE: &quot;image&quot; # Optional, default: image, other options: pdf, whole_pdf
      PDF_SKIP_EXISTING_OCR: &quot;false&quot; # Optional, skip OCR for PDFs with existing OCR

      # Option 2: Google Document AI
      # OCR_PROVIDER: &#039;google_docai&#039;       # Use Google Document AI
      # GOOGLE_PROJECT_ID: &#039;your-project&#039;  # Your GCP project ID
      # GOOGLE_LOCATION: &#039;us&#039;              # Document AI region
      # GOOGLE_PROCESSOR_ID: &#039;processor-id&#039; # Your processor ID
      # GOOGLE_APPLICATION_CREDENTIALS: &#039;/app/credentials.json&#039; # Path to service account key

      # Option 3: Azure Document Intelligence
      # OCR_PROVIDER: &#039;azure&#039;              # Use Azure Document Intelligence
      # AZURE_DOCAI_ENDPOINT: &#039;your-endpoint&#039; # Your Azure endpoint URL
      # AZURE_DOCAI_KEY: &#039;your-key&#039;        # Your Azure API key
      # AZURE_DOCAI_MODEL_ID: &#039;prebuilt-read&#039; # Optional, defaults to prebuilt-read
      # AZURE_DOCAI_TIMEOUT_SECONDS: &#039;120&#039;  # Optional, defaults to 120 seconds
      # AZURE_DOCAI_OUTPUT_CONTENT_FORMAT: &#039;text&#039; # Optional, defaults to &#039;text&#039;, other valid option is &#039;markdown&#039;
      # &#039;markdown&#039; requires the &#039;prebuilt-layout&#039; model

      # Enhanced OCR Features
      CREATE_LOCAL_HOCR: &quot;false&quot; # Optional, save hOCR files locally
      LOCAL_HOCR_PATH: &quot;/app/hocr&quot; # Optional, path for hOCR files
      CREATE_LOCAL_PDF: &quot;false&quot; # Optional, save enhanced PDFs locally
      LOCAL_PDF_PATH: &quot;/app/pdf&quot; # Optional, path for PDF files
      PDF_UPLOAD: &quot;false&quot; # Optional, upload enhanced PDFs to paperless-ngx
      PDF_REPLACE: &quot;false&quot; # Optional and DANGEROUS, delete original after upload
      PDF_COPY_METADATA: &quot;true&quot; # Optional, copy metadata from original document
      PDF_OCR_TAGGING: &quot;true&quot; # Optional, add tag to processed documents
      PDF_OCR_COMPLETE_TAG: &quot;paperless-gpt-ocr-complete&quot; # Optional, tag name

      # Option 4: Docling Server
      # OCR_PROVIDER: &#039;docling&#039;              # Use a Docling server
      # DOCLING_URL: &#039;http://your-docling-server:port&#039; # URL of your Docling instance
      # DOCLING_IMAGE_EXPORT_MODE: &quot;placeholder&quot; # Optional, defaults to &quot;embedded&quot;
      # DOCLING_OCR_PIPELINE: &quot;standard&quot; # Optional, defaults to &quot;vlm&quot;
      # DOCLING_OCR_ENGINE: &quot;easyocr&quot; # Optional, defaults to &quot;easyocr&quot; (only used when `DOCLING_OCR_PIPELINE is set to &#039;standard&#039;)


      AUTO_OCR_TAG: &quot;paperless-gpt-ocr-auto&quot; # Optional, default: paperless-gpt-ocr-auto
      OCR_LIMIT_PAGES: &quot;5&quot; # Optional, default: 5. Set to 0 for no limit.
      LOG_LEVEL: &quot;info&quot; # Optional: debug, warn, error
    volumes:
      - ./prompts:/app/prompts # Mount the prompts directory
      # For Google Document AI:
      - ${HOME}/.config/gcloud/application_default_credentials.json:/app/credentials.json
      # For local hOCR and PDF saving:
      - ./hocr:/app/hocr # Only if CREATE_LOCAL_HOCR is true
      - ./pdf:/app/pdf # Only if CREATE_LOCAL_PDF is true
    ports:
      - &quot;8080:8080&quot;
    depends_on:
      - paperless-ngx
```

**Pro Tip**: Replace placeholders with real values and read the logs if something looks off.

#### Manual Setup

1. **Clone the Repository**
   ```bash
   git clone https://github.com/icereed/paperless-gpt.git
   cd paperless-gpt
   ```
2. **Create a `prompts` Directory**
   ```bash
   mkdir prompts
   ```
3. **Build the Docker Image**
   ```bash
   docker build -t paperless-gpt .
   ```
4. **Run the Container**
   ```bash
   docker run -d \
     -e PAPERLESS_BASE_URL=&#039;http://your_paperless_ngx_url&#039; \
     -e PAPERLESS_API_TOKEN=&#039;your_paperless_api_token&#039; \
     -e LLM_PROVIDER=&#039;openai&#039; \
     -e LLM_MODEL=&#039;gpt-4o&#039; \
     -e OPENAI_API_KEY=&#039;your_openai_api_key&#039; \
     -e LLM_LANGUAGE=&#039;English&#039; \
     -e VISION_LLM_PROVIDER=&#039;ollama&#039; \
     -e VISION_LLM_MODEL=&#039;minicpm-v&#039; \
     -e LOG_LEVEL=&#039;info&#039; \
     -v $(pwd)/prompts:/app/prompts \
     -p 8080:8080 \
     paperless-gpt
   ```

---

## OCR Providers

For detailed provider-specific documentation:

- [Mistral AI Integration](docs/mistral_llm.md)

paperless-gpt supports four different OCR providers, each with unique strengths and capabilities:

### 1. LLM-based OCR (Default)

- **Key Features**:
  - Uses vision-capable LLMs like gpt-4o or MiniCPM-V
  - High accuracy with complex layouts and difficult scans
  - Context-aware text recognition
  - Self-correcting capabilities for OCR errors
- **Best For**:
  - Complex or unusual document layouts
  - Poor quality scans
  - Documents with mixed languages
- **Configuration**:
  ```yaml
  OCR_PROVIDER: &quot;llm&quot;
  VISION_LLM_PROVIDER: &quot;openai&quot; # or &quot;ollama&quot;
  VISION_LLM_MODEL: &quot;gpt-4o&quot; # or &quot;minicpm-v&quot;
  ```

### 2. Azure Document Intelligence

- **Key Features**:
  - Enterprise-grade OCR solution
  - Prebuilt models for common document types
  - Layout preservation and table detection
  - Fast processing speeds
- **Best For**:
  - Business documents and forms
  - High-volume processing
  - Documents requiring layout analysis
- **Configuration**:
  ```yaml
  OCR_PROVIDER: &quot;azure&quot;
  AZURE_DOCAI_ENDPOINT: &quot;https://your-endpoint.cognitiveservices.azure.com/&quot;
  AZURE_DOCAI_KEY: &quot;your-key&quot;
  AZURE_DOCAI_MODEL_ID: &quot;prebuilt-read&quot; # optional
  AZURE_DOCAI_TIMEOUT_SECONDS: &quot;120&quot; # optional
  AZURE_DOCAI_OUTPUT_CONTENT_FORMAT:
    &quot;text&quot; # optional, defaults to text, other valid option is &#039;markdown&#039;
    # &#039;markdown&#039; requires the &#039;prebuilt-layout&#039; model
  ```

### 3. Google Document AI

- **Key Features**:
  - Enterprise-grade OCR/HTR solution
  - Specialized document processors
  - Strong form field detection
  - Multi-language support
  - High accuracy on structured documents
  - **Exclusive hOCR generation** for creating searchable PDFs with text layers
  - **Only provider that supports** enhanced PDF generation features
- **Best For**:
  - Forms and structured documents
  - Documents with tables
  - Multi-language documents
  - Handwritten text (HTR)
- **Configuration**:
  ```yaml
  OCR_PROVIDER: &quot;google_docai&quot;
  GOOGLE_PROJECT_ID: &quot;your-project&quot;
  GOOGLE_LOCATION: &quot;us&quot;
  GOOGLE_PROCESSOR_ID: &quot;processor-id&quot;
  CREATE_LOCAL_HOCR: &quot;true&quot; # Optional, for hOCR generation
  LOCAL_HOCR_PATH: &quot;/app/hocr&quot; # Optional, default path
  CREATE_LOCAL_PDF: &quot;true&quot; # Optional, for applying OCR to PDF
  LOCAL_PDF_PATH: &quot;/app/pdf&quot; # Optional, default path
  ```

### 4. Docling Server

- **Key Features**:
  - Self-hosted OCR and document conversion service
  - Supports various input and output formats (including text)
  - Utilizes multiple OCR engines (EasyOCR, Tesseract, etc.)
  - Can be run locally or in a private network
- **Best For**:
  - Users who prefer a self-hosted solution
  - Environments where data privacy is paramount
  - Processing a wide variety of document types
- **Configuration**:
  ```yaml
  OCR_PROVIDER: &quot;docling&quot;
  DOCLING_URL: &quot;http://your-docling-server:port&quot;
  DOCLING_IMAGE_EXPORT_MODE: &quot;placeholder&quot; # Optional, defaults to &quot;embedded&quot;
  DOCLING_OCR_PIPELINE: &quot;standard&quot; # Optional, defaults to &quot;vlm&quot;
  DOCLING_OCR_ENGINE: &quot;macocr&quot; # Optional, defaults to &quot;easyocr&quot; (only used when `DOCLING_OCR_PIPELINE is set to &#039;standard&#039;)
  ```

## OCR Processing Modes

paperless-gpt offers different methods for processing documents, giving you flexibility based on your needs and OCR provider capabilities:

### Image Mode (Default)

- **How it works**: Converts PDF pages to images before processing
- **Best for**: Compatibility with all OCR providers.
- **Configuration**: `OCR_PROCESS_MODE: &quot;image&quot;`

### PDF Mode

- **How it works**: Processes PDF pages directly without image conversion
- **Best for**: Preserving PDF features, potentially faster processing and improved accuracy with some providers
- **Configuration**: `OCR_PROCESS_MODE: &quot;pdf&quot;`

### Whole PDF Mode

- **How it works**: Processes the entire PDF document in a single operation
- **Best for**: Providers that handle multi-page documents efficiently, reduced API calls
- **Configuration**: `OCR_PROCESS_MODE: &quot;whole_pdf&quot;`
- **Note**: Processing large PDFs may cause you to hit the API limit of your OCR provider. If you encounter problems with large documents, consider switching to `pdf` mode, which processes pages individually.

### Provider Compatibility

Different OCR providers support different processing modes:

| Provider | Image Mode | PDF Mode | Whole PDF Mode |
|----------|------------|----------|----------------|
| **LLM-based OCR** (OpenAI/Ollama) | ‚úÖ | ‚ùå | ‚ùå |
| **Azure Document Intelligence** | ‚úÖ | ‚ùå | ‚ùå |
| **Google Document AI** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Mistral OCR** | ‚úÖ | ‚úÖ | ‚úÖ |
| **Docling Server** | ‚úÖ | ‚ùå | ‚ùå |

&gt; **Important**: paperless-gpt will validate your configuration at startup and prevent unsupported mode/provider combinations. If you specify an unsupported mode for your provider, the application will fail to start with a clear error message.

### Existing OCR Detection

When using PDF or whole PDF modes, you can enable automatic detection of existing OCR:

```yaml
environment:
  OCR_PROCESS_MODE: &quot;pdf&quot; # or &quot;whole_pdf&quot;
  PDF_SKIP_EXISTING_OCR: &quot;true&quot; # Skip processing if existing OCR is detected in the PDF
```

&gt; **Note**: Not all OCR providers support all processing modes. Some may work better with certain modes than others. Processing as PDF might use more or fewer API tokens than processing as images, depending on the provider. Results may vary based on document complexity and provider capabilities. It&#039;s recommended to experiment with different modes to find what works best for your specific documents and OCR provider.

## Enhanced OCR Features

paperless-gpt includes powerful OCR enhancements that go beyond basic text extraction:

&gt; **Important Note**: The PDF text layer generation and hOCR features are currently **only supported with Google Document AI** as the OCR provider. These features are not available when using LLM-based OCR or Azure Document Intelligence.

### PDF Text Layer Generation

- **Searchable &amp; Selectable PDFs**: Creates PDFs with transparent text 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[GoogleCloudPlatform/microservices-demo]]></title>
            <link>https://github.com/GoogleCloudPlatform/microservices-demo</link>
            <guid>https://github.com/GoogleCloudPlatform/microservices-demo</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:17 GMT</pubDate>
            <description><![CDATA[Sample cloud-first application with 10 microservices showcasing Kubernetes, Istio, and gRPC.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GoogleCloudPlatform/microservices-demo">GoogleCloudPlatform/microservices-demo</a></h1>
            <p>Sample cloud-first application with 10 microservices showcasing Kubernetes, Istio, and gRPC.</p>
            <p>Language: Go</p>
            <p>Stars: 19,797</p>
            <p>Forks: 9,492</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;!-- &lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/src/frontend/static/icons/Hipster_HeroLogoMaroon.svg&quot; width=&quot;300&quot; alt=&quot;Online Boutique&quot; /&gt;
&lt;/p&gt; --&gt;
![Continuous Integration](https://github.com/GoogleCloudPlatform/microservices-demo/workflows/Continuous%20Integration%20-%20Main/Release/badge.svg)

**Online Boutique** is a cloud-first microservices demo application.  The application is a
web-based e-commerce app where users can browse items, add them to the cart, and purchase them.

Google uses this application to demonstrate how developers can modernize enterprise applications using Google Cloud products, including: [Google Kubernetes Engine (GKE)](https://cloud.google.com/kubernetes-engine), [Cloud Service Mesh (CSM)](https://cloud.google.com/service-mesh), [gRPC](https://grpc.io/), [Cloud Operations](https://cloud.google.com/products/operations), [Spanner](https://cloud.google.com/spanner), [Memorystore](https://cloud.google.com/memorystore), [AlloyDB](https://cloud.google.com/alloydb), and [Gemini](https://ai.google.dev/). This application works on any Kubernetes cluster.

If you‚Äôre using this demo, please **‚òÖStar** this repository to show your interest!

**Note to Googlers:** Please fill out the form at [go/microservices-demo](http://go/microservices-demo).

## Architecture

**Online Boutique** is composed of 11 microservices written in different
languages that talk to each other over gRPC.

[![Architecture of
microservices](/docs/img/architecture-diagram.png)](/docs/img/architecture-diagram.png)

Find **Protocol Buffers Descriptions** at the [`./protos` directory](/protos).

| Service                                              | Language      | Description                                                                                                                       |
| ---------------------------------------------------- | ------------- | --------------------------------------------------------------------------------------------------------------------------------- |
| [frontend](/src/frontend)                           | Go            | Exposes an HTTP server to serve the website. Does not require signup/login and generates session IDs for all users automatically. |
| [cartservice](/src/cartservice)                     | C#            | Stores the items in the user&#039;s shopping cart in Redis and retrieves it.                                                           |
| [productcatalogservice](/src/productcatalogservice) | Go            | Provides the list of products from a JSON file and ability to search products and get individual products.                        |
| [currencyservice](/src/currencyservice)             | Node.js       | Converts one money amount to another currency. Uses real values fetched from European Central Bank. It&#039;s the highest QPS service. |
| [paymentservice](/src/paymentservice)               | Node.js       | Charges the given credit card info (mock) with the given amount and returns a transaction ID.                                     |
| [shippingservice](/src/shippingservice)             | Go            | Gives shipping cost estimates based on the shopping cart. Ships items to the given address (mock)                                 |
| [emailservice](/src/emailservice)                   | Python        | Sends users an order confirmation email (mock).                                                                                   |
| [checkoutservice](/src/checkoutservice)             | Go            | Retrieves user cart, prepares order and orchestrates the payment, shipping and the email notification.                            |
| [recommendationservice](/src/recommendationservice) | Python        | Recommends other products based on what&#039;s given in the cart.                                                                      |
| [adservice](/src/adservice)                         | Java          | Provides text ads based on given context words.                                                                                   |
| [loadgenerator](/src/loadgenerator)                 | Python/Locust | Continuously sends requests imitating realistic user shopping flows to the frontend.                                              |

## Screenshots

| Home Page                                                                                                         | Checkout Screen                                                                                                    |
| ----------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |
| [![Screenshot of store homepage](/docs/img/online-boutique-frontend-1.png)](/docs/img/online-boutique-frontend-1.png) | [![Screenshot of checkout screen](/docs/img/online-boutique-frontend-2.png)](/docs/img/online-boutique-frontend-2.png) |

## Quickstart (GKE)

1. Ensure you have the following requirements:
   - [Google Cloud project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#creating_a_project).
   - Shell environment with `gcloud`, `git`, and `kubectl`.

2. Clone the latest major version.

   ```sh
   git clone --depth 1 --branch v0 https://github.com/GoogleCloudPlatform/microservices-demo.git
   cd microservices-demo/
   ```

   The `--depth 1` argument skips downloading git history.

3. Set the Google Cloud project and region and ensure the Google Kubernetes Engine API is enabled.

   ```sh
   export PROJECT_ID=&lt;PROJECT_ID&gt;
   export REGION=us-central1
   gcloud services enable container.googleapis.com \
     --project=${PROJECT_ID}
   ```

   Substitute `&lt;PROJECT_ID&gt;` with the ID of your Google Cloud project.

4. Create a GKE cluster and get the credentials for it.

   ```sh
   gcloud container clusters create-auto online-boutique \
     --project=${PROJECT_ID} --region=${REGION}
   ```

   Creating the cluster may take a few minutes.

5. Deploy Online Boutique to the cluster.

   ```sh
   kubectl apply -f ./release/kubernetes-manifests.yaml
   ```

6. Wait for the pods to be ready.

   ```sh
   kubectl get pods
   ```

   After a few minutes, you should see the Pods in a `Running` state:

   ```
   NAME                                     READY   STATUS    RESTARTS   AGE
   adservice-76bdd69666-ckc5j               1/1     Running   0          2m58s
   cartservice-66d497c6b7-dp5jr             1/1     Running   0          2m59s
   checkoutservice-666c784bd6-4jd22         1/1     Running   0          3m1s
   currencyservice-5d5d496984-4jmd7         1/1     Running   0          2m59s
   emailservice-667457d9d6-75jcq            1/1     Running   0          3m2s
   frontend-6b8d69b9fb-wjqdg                1/1     Running   0          3m1s
   loadgenerator-665b5cd444-gwqdq           1/1     Running   0          3m
   paymentservice-68596d6dd6-bf6bv          1/1     Running   0          3m
   productcatalogservice-557d474574-888kr   1/1     Running   0          3m
   recommendationservice-69c56b74d4-7z8r5   1/1     Running   0          3m1s
   redis-cart-5f59546cdd-5jnqf              1/1     Running   0          2m58s
   shippingservice-6ccc89f8fd-v686r         1/1     Running   0          2m58s
   ```

7. Access the web frontend in a browser using the frontend&#039;s external IP.

   ```sh
   kubectl get service frontend-external | awk &#039;{print $4}&#039;
   ```

   Visit `http://EXTERNAL_IP` in a web browser to access your instance of Online Boutique.

8. Congrats! You&#039;ve deployed the default Online Boutique. To deploy a different variation of Online Boutique (e.g., with Google Cloud Operations tracing, Istio, etc.), see [Deploy Online Boutique variations with Kustomize](#deploy-online-boutique-variations-with-kustomize).

9. Once you are done with it, delete the GKE cluster.

   ```sh
   gcloud container clusters delete online-boutique \
     --project=${PROJECT_ID} --region=${REGION}
   ```

   Deleting the cluster may take a few minutes.

## Additional deployment options

- **Terraform**: [See these instructions](/terraform) to learn how to deploy Online Boutique using [Terraform](https://www.terraform.io/intro).
- **Istio / Cloud Service Mesh**: [See these instructions](/kustomize/components/service-mesh-istio/README.md) to deploy Online Boutique alongside an Istio-backed service mesh.
- **Non-GKE clusters (Minikube, Kind, etc)**: See the [Development guide](/docs/development-guide.md) to learn how you can deploy Online Boutique on non-GKE clusters.
- **AI assistant using Gemini**: [See these instructions](/kustomize/components/shopping-assistant/README.md) to deploy a Gemini-powered AI assistant that suggests products to purchase based on an image.
- **And more**: The [`/kustomize` directory](/kustomize) contains instructions for customizing the deployment of Online Boutique with other variations.

## Documentation

- [Development](/docs/development-guide.md) to learn how to run and develop this app locally.

## Demos featuring Online Boutique

- [Security hardening of the OnlineBoutique sample apps with the Docker Hardened Images (DHI)](https://medium.com/google-cloud/security-hardening-of-the-onlineboutique-sample-apps-with-docker-hardened-images-dhi-ca1fad348343)
- [alpine, distroless or scratch?](https://medium.com/google-cloud/alpine-distroless-or-scratch-caac35250e0b)
- [Platform Engineering in action: Deploy the Online Boutique sample apps with Score and Humanitec](https://medium.com/p/d99101001e69)
- [The new Kubernetes Gateway API with Istio and Anthos Service Mesh (ASM)](https://medium.com/p/9d64c7009cd)
- [Use Azure Redis Cache with the Online Boutique sample on AKS](https://medium.com/p/981bd98b53f8)
- [Sail Sharp, 8 tips to optimize and secure your .NET containers for Kubernetes](https://medium.com/p/c68ba253844a)
- [Deploy multi-region application with Anthos and Google cloud Spanner](https://medium.com/google-cloud/a2ea3493ed0)
- [Use Google Cloud Memorystore (Redis) with the Online Boutique sample on GKE](https://medium.com/p/82f7879a900d)
- [Use Helm to simplify the deployment of Online Boutique, with a Service Mesh, GitOps, and more!](https://medium.com/p/246119e46d53)
- [How to reduce microservices complexity with Apigee and Anthos Service Mesh](https://cloud.google.com/blog/products/application-modernization/api-management-and-service-mesh-go-together)
- [gRPC health probes with Kubernetes 1.24+](https://medium.com/p/b5bd26253a4c)
- [Use Google Cloud Spanner with the Online Boutique sample](https://medium.com/p/f7248e077339)
- [Seamlessly encrypt traffic from any apps in your Mesh to Memorystore (redis)](https://medium.com/google-cloud/64b71969318d)
- [Strengthen your app&#039;s security with Cloud Service Mesh and Anthos Config Management](https://cloud.google.com/service-mesh/docs/strengthen-app-security)
- [From edge to mesh: Exposing service mesh applications through GKE Ingress](https://cloud.google.com/architecture/exposing-service-mesh-apps-through-gke-ingress)
- [Take the first step toward SRE with Cloud Operations Sandbox](https://cloud.google.com/blog/products/operations/on-the-road-to-sre-with-cloud-operations-sandbox)
- [Deploying the Online Boutique sample application on Cloud Service Mesh](https://cloud.google.com/service-mesh/docs/onlineboutique-install-kpt)
- [Anthos Service Mesh Workshop: Lab Guide](https://codelabs.developers.google.com/codelabs/anthos-service-mesh-workshop)
- [KubeCon EU 2019 - Reinventing Networking: A Deep Dive into Istio&#039;s Multicluster Gateways - Steve Dake, Independent](https://youtu.be/-t2BfT59zJA?t=982)
- Google Cloud Next&#039;18 SF
  - [Day 1 Keynote](https://youtu.be/vJ9OaAqfxo4?t=2416) showing GKE On-Prem
  - [Day 3 Keynote](https://youtu.be/JQPOPV_VH5w?t=815) showing Stackdriver
    APM (Tracing, Code Search, Profiler, Google Cloud Build)
  - [Introduction to Service Management with Istio](https://www.youtube.com/watch?v=wCJrdKdD6UM&amp;feature=youtu.be&amp;t=586)
- [Google Cloud Next&#039;18 London ‚Äì Keynote](https://youtu.be/nIq2pkNcfEI?t=3071)
  showing Stackdriver Incident Response Management
- [Microservices demo showcasing Go Micro](https://github.com/go-micro/demo)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mikefarah/yq]]></title>
            <link>https://github.com/mikefarah/yq</link>
            <guid>https://github.com/mikefarah/yq</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:16 GMT</pubDate>
            <description><![CDATA[yq is a portable command-line YAML, JSON, XML, CSV, TOML, HCL and properties processor]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mikefarah/yq">mikefarah/yq</a></h1>
            <p>yq is a portable command-line YAML, JSON, XML, CSV, TOML, HCL and properties processor</p>
            <p>Language: Go</p>
            <p>Stars: 14,899</p>
            <p>Forks: 744</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># yq

![Build](https://github.com/mikefarah/yq/workflows/Build/badge.svg)  ![Docker Pulls](https://img.shields.io/docker/pulls/mikefarah/yq.svg) ![Github Releases (by Release)](https://img.shields.io/github/downloads/mikefarah/yq/total.svg) ![Go Report](https://goreportcard.com/badge/github.com/mikefarah/yq) ![CodeQL](https://github.com/mikefarah/yq/workflows/CodeQL/badge.svg)


A lightweight and portable command-line YAML, JSON, INI and XML processor. `yq` uses [jq](https://github.com/stedolan/jq) (a popular JSON processor) like syntax but works with yaml files as well as json, kyaml, xml, ini, properties, csv and tsv. It doesn&#039;t yet support everything `jq` does - but it does support the most common operations and functions, and more is being added continuously.

yq is written in Go - so you can download a dependency free binary for your platform and you are good to go! If you prefer there are a variety of package managers that can be used as well as Docker and Podman, all listed below.

## Quick Usage Guide

### Basic Operations

**Read a value:**
```bash
yq &#039;.a.b[0].c&#039; file.yaml
```

**Pipe from STDIN:**
```bash
yq &#039;.a.b[0].c&#039; &lt; file.yaml
```

**Update a yaml file in place:**
```bash
yq -i &#039;.a.b[0].c = &quot;cool&quot;&#039; file.yaml
```

**Update using environment variables:**
```bash
NAME=mike yq -i &#039;.a.b[0].c = strenv(NAME)&#039; file.yaml
```

### Advanced Operations

**Merge multiple files:**
```bash
# merge two files
yq -n &#039;load(&quot;file1.yaml&quot;) * load(&quot;file2.yaml&quot;)&#039;

# merge using globs (note: `ea` evaluates all files at once instead of in sequence)
yq ea &#039;. as $item ireduce ({}; . * $item )&#039; path/to/*.yml
```

**Multiple updates to a yaml file:**
```bash
yq -i &#039;
  .a.b[0].c = &quot;cool&quot; |
  .x.y.z = &quot;foobar&quot; |
  .person.name = strenv(NAME)
&#039; file.yaml
```

**Find and update an item in an array:**
```bash
# Note: requires input file - add your file at the end
yq -i &#039;(.[] | select(.name == &quot;foo&quot;) | .address) = &quot;12 cat st&quot;&#039; data.yaml
```

**Convert between formats:**
```bash
# Convert JSON to YAML (pretty print)
yq -Poy sample.json

# Convert YAML to JSON
yq -o json file.yaml

# Convert XML to YAML
yq -o yaml file.xml
```

See [recipes](https://mikefarah.gitbook.io/yq/recipes) for more examples and the [documentation](https://mikefarah.gitbook.io/yq/) for more information.

Take a look at the discussions for [common questions](https://github.com/mikefarah/yq/discussions/categories/q-a), and [cool ideas](https://github.com/mikefarah/yq/discussions/categories/show-and-tell)

## Install

### [Download the latest binary](https://github.com/mikefarah/yq/releases/latest)

### wget
Use wget to download pre-compiled binaries. Choose your platform and architecture:

**For Linux (example):**
```bash
# Set your platform variables (adjust as needed)
VERSION=v4.2.0
PLATFORM=linux_amd64

# Download compressed binary
wget https://github.com/mikefarah/yq/releases/download/${VERSION}/yq_${PLATFORM}.tar.gz -O - |\
  tar xz &amp;&amp; sudo mv yq_${PLATFORM} /usr/local/bin/yq

# Or download plain binary
wget https://github.com/mikefarah/yq/releases/download/${VERSION}/yq_${PLATFORM} -O /usr/local/bin/yq &amp;&amp;\
    chmod +x /usr/local/bin/yq
```

**Latest version (Linux AMD64):**
```bash
wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/local/bin/yq &amp;&amp;\
    chmod +x /usr/local/bin/yq
```

**Available platforms:** `linux_amd64`, `linux_arm64`, `linux_arm`, `linux_386`, `darwin_amd64`, `darwin_arm64`, `windows_amd64`, `windows_386`, etc.

### MacOS / Linux via Homebrew:
Using [Homebrew](https://brew.sh/)
```
brew install yq
```

### Linux via snap:
```
snap install yq
```

#### Snap notes
`yq` installs with [_strict confinement_](https://docs.snapcraft.io/snap-confinement/6233) in snap, this means it doesn&#039;t have direct access to root files. To read root files you can:

```
sudo cat /etc/myfile | yq &#039;.a.path&#039;
```

And to write to a root file you can either use [sponge](https://linux.die.net/man/1/sponge):
```
sudo cat /etc/myfile | yq &#039;.a.path = &quot;value&quot;&#039; | sudo sponge /etc/myfile
```
or write to a temporary file:
```
sudo cat /etc/myfile | yq &#039;.a.path = &quot;value&quot;&#039; | sudo tee /etc/myfile.tmp
sudo mv /etc/myfile.tmp /etc/myfile
rm /etc/myfile.tmp
```

### Run with Docker or Podman

#### One-time use:
```bash
# Docker - process files in current directory
docker run --rm -v &quot;${PWD}&quot;:/workdir mikefarah/yq &#039;.a.b[0].c&#039; file.yaml

# Podman - same usage as Docker
podman run --rm -v &quot;${PWD}&quot;:/workdir mikefarah/yq &#039;.a.b[0].c&#039; file.yaml
```

**Security note:** You can run `yq` in Docker with restricted privileges:
```bash
docker run --rm --security-opt=no-new-privileges --cap-drop all --network none \
  -v &quot;${PWD}&quot;:/workdir mikefarah/yq &#039;.a.b[0].c&#039; file.yaml
```

#### Pipe data via STDIN:

You&#039;ll need to pass the `-i --interactive` flag to Docker/Podman:

```bash
# Process piped data
docker run -i --rm mikefarah/yq &#039;.this.thing&#039; &lt; myfile.yml

# Same with Podman
podman run -i --rm mikefarah/yq &#039;.this.thing&#039; &lt; myfile.yml
```

#### Run commands interactively:

```bash
docker run --rm -it -v &quot;${PWD}&quot;:/workdir --entrypoint sh mikefarah/yq
```

```bash
podman run --rm -it -v &quot;${PWD}&quot;:/workdir --entrypoint sh mikefarah/yq
```

It can be useful to have a bash function to avoid typing the whole docker command:

```bash
yq() {
  docker run --rm -i -v &quot;${PWD}&quot;:/workdir mikefarah/yq &quot;$@&quot;
}
```

```bash
yq() {
  podman run --rm -i -v &quot;${PWD}&quot;:/workdir mikefarah/yq &quot;$@&quot;
}
```
#### Running as root:

`yq`&#039;s container image no longer runs under root (https://github.com/mikefarah/yq/pull/860). If you&#039;d like to install more things in the container image, or you&#039;re having permissions issues when attempting to read/write files you&#039;ll need to either:


```
docker run --user=&quot;root&quot; -it --entrypoint sh mikefarah/yq
```

```
podman run --user=&quot;root&quot; -it --entrypoint sh mikefarah/yq
```

Or, in your Dockerfile:

```
FROM mikefarah/yq

USER root
RUN apk add --no-cache bash
USER yq
```

#### Missing timezone data
By default, the alpine image yq uses does not include timezone data. If you&#039;d like to use the `tz` operator, you&#039;ll need to include this data:

```
FROM mikefarah/yq

USER root
RUN apk add --no-cache tzdata
USER yq
```

#### Podman with SELinux

If you are using podman with SELinux, you will need to set the shared volume flag `:z` on the volume mount:

```
-v &quot;${PWD}&quot;:/workdir:z
```

### GitHub Action
```
  - name: Set foobar to cool
    uses: mikefarah/yq@master
    with:
      cmd: yq -i &#039;.foo.bar = &quot;cool&quot;&#039; &#039;config.yml&#039;
  - name: Get an entry with a variable that might contain dots or spaces
    id: get_username
    uses: mikefarah/yq@master
    with:
      cmd: yq &#039;.all.children.[&quot;${{ matrix.ip_address }}&quot;].username&#039; ops/inventories/production.yml
  - name: Reuse a variable obtained in another step
    run: echo ${{ steps.get_username.outputs.result }}
```

See https://mikefarah.gitbook.io/yq/usage/github-action for more.

### Go Install:
```
go install github.com/mikefarah/yq/v4@latest
```

## Community Supported Installation methods
As these are supported by the community :heart: - however, they may be out of date with the officially supported releases.

_Please note that the Debian package (previously supported by @rmescandon) is no longer maintained. Please use an alternative installation method._


### X-CMD
Checkout `yq` on x-cmd: https://x-cmd.com/mod/yq

- Instant Results: See the output of your yq filter in real-time.
- Error Handling: Encounter a syntax error? It will display the error message and the results of the closest valid filter

Thanks @edwinjhlee!

### Nix

```
nix profile install nixpkgs#yq-go
```

See [here](https://search.nixos.org/packages?channel=unstable&amp;show=yq-go&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=yq-go)


### Webi

```
webi yq
```

See [webi](https://webinstall.dev/)
Supported by @adithyasunil26 (https://github.com/webinstall/webi-installers/tree/master/yq)

### Arch Linux

```
pacman -S go-yq
```

### Windows:

Using [Chocolatey](https://chocolatey.org)

[![Chocolatey](https://img.shields.io/chocolatey/v/yq.svg)](https://chocolatey.org/packages/yq)
[![Chocolatey](https://img.shields.io/chocolatey/dt/yq.svg)](https://chocolatey.org/packages/yq)
```
choco install yq
```
Supported by @chillum (https://chocolatey.org/packages/yq)

Using [scoop](https://scoop.sh/)
```
scoop install main/yq
```

Using [winget](https://learn.microsoft.com/en-us/windows/package-manager/)
```
winget install --id MikeFarah.yq
```

### MacPorts:
Using [MacPorts](https://www.macports.org/)
```
sudo port selfupdate
sudo port install yq
```
Supported by @herbygillot (https://ports.macports.org/maintainer/github/herbygillot)

### Alpine Linux

Alpine Linux v3.20+ (and Edge):
```
apk add yq-go
```

Alpine Linux up to v3.19:
```
apk add yq
```

Supported by Tuan Hoang (https://pkgs.alpinelinux.org/packages?name=yq-go)

### Flox:

Flox can be used to install yq on Linux, MacOS, and Windows through WSL.

```
flox install yq
```


### MacOS / Linux via gah:
Using [gah](https://github.com/marverix/gah)

```
gah install yq
```

## Features
- [Detailed documentation with many examples](https://mikefarah.gitbook.io/yq/)
- Written in portable go, so you can download a lovely dependency free binary
- Uses similar syntax as `jq` but works with YAML, INI, [JSON](https://mikefarah.gitbook.io/yq/usage/convert) and [XML](https://mikefarah.gitbook.io/yq/usage/xml) files
- Fully supports multi document yaml files
- Supports yaml [front matter](https://mikefarah.gitbook.io/yq/usage/front-matter) blocks (e.g. jekyll/assemble)
- Colorized yaml output
- [Date/Time manipulation and formatting with TZ](https://mikefarah.gitbook.io/yq/operators/datetime)
- [Deep data structures](https://mikefarah.gitbook.io/yq/operators/traverse-read)
- [Sort keys](https://mikefarah.gitbook.io/yq/operators/sort-keys)
- Manipulate yaml [comments](https://mikefarah.gitbook.io/yq/operators/comment-operators), [styling](https://mikefarah.gitbook.io/yq/operators/style), [tags](https://mikefarah.gitbook.io/yq/operators/tag) and [anchors and aliases](https://mikefarah.gitbook.io/yq/operators/anchor-and-alias-operators).
- [Update in place](https://mikefarah.gitbook.io/yq/v/v4.x/commands/evaluate#flags)
- [Complex expressions to select and update](https://mikefarah.gitbook.io/yq/operators/select#select-and-update-matching-values-in-map)
- Keeps yaml formatting and comments when updating (though there are issues with whitespace)
- [Decode/Encode base64 data](https://mikefarah.gitbook.io/yq/operators/encode-decode)
- [Load content from other files](https://mikefarah.gitbook.io/yq/operators/load)
- [Convert to/from json/ndjson](https://mikefarah.gitbook.io/yq/v/v4.x/usage/convert)
- [Convert to/from xml](https://mikefarah.gitbook.io/yq/v/v4.x/usage/xml)
- [Convert to/from hcl (terraform)](https://mikefarah.gitbook.io/yq/v/v4.x/usage/hcl)
- [Convert to/from toml](https://mikefarah.gitbook.io/yq/v/v4.x/usage/toml)
- [Convert to/from properties](https://mikefarah.gitbook.io/yq/v/v4.x/usage/properties)
- [Convert to/from csv/tsv](https://mikefarah.gitbook.io/yq/usage/csv-tsv)
- [General shell completion scripts (bash/zsh/fish/powershell)](https://mikefarah.gitbook.io/yq/v/v4.x/commands/shell-completion)
- [Reduce](https://mikefarah.gitbook.io/yq/operators/reduce) to merge multiple files or sum an array or other fancy things.
- [Github Action](https://mikefarah.gitbook.io/yq/usage/github-action) to use in your automated pipeline (thanks @devorbitus)

## [Usage](https://mikefarah.gitbook.io/yq/)

Check out the [documentation](https://mikefarah.gitbook.io/yq/) for more detailed and advanced usage.

```
Usage:
  yq [flags]
  yq [command]

Examples:

# yq tries to auto-detect the file format based off the extension, and defaults to YAML if it&#039;s unknown (or piping through STDIN)
# Use the &#039;-p/--input-format&#039; flag to specify a format type.
cat file.xml | yq -p xml

# read the &quot;stuff&quot; node from &quot;myfile.yml&quot;
yq &#039;.stuff&#039; &lt; myfile.yml

# update myfile.yml in place
yq -i &#039;.stuff = &quot;foo&quot;&#039; myfile.yml

# print contents of sample.json as idiomatic YAML
yq -P -oy sample.json


Available Commands:
  completion  Generate the autocompletion script for the specified shell
  eval        (default) Apply the expression to each document in each yaml file in sequence
  eval-all    Loads _all_ yaml documents of _all_ yaml files and runs expression once
  help        Help about any command

Flags:
  -C, --colors                          force print with colors
      --csv-auto-parse                  parse CSV YAML/JSON values (default true)
      --csv-separator char              CSV Separator character (default ,)
      --debug-node-info                 debug node info
  -e, --exit-status                     set exit status if there are no matches or null or false is returned
      --expression string               forcibly set the expression argument. Useful when yq argument detection thinks your expression is a file.
      --from-file string                Load expression from specified file.
  -f, --front-matter string             (extract|process) first input as yaml front-matter. Extract will pull out the yaml content, process will run the expression against the yaml content, leaving the remaining data intact
      --header-preprocess               Slurp any header comments and separators before processing expression. (default true)
  -h, --help                            help for yq
  -I, --indent int                      sets indent level for output (default 2)
  -i, --inplace                         update the file in place of first file given.
  -p, --input-format string             [auto|a|yaml|y|json|j|kyaml|ky|props|p|csv|c|tsv|t|xml|x|base64|uri|toml|hcl|h|lua|l|ini|i] parse format for input. (default &quot;auto&quot;)
      --lua-globals                     output keys as top-level global variables
      --lua-prefix string               prefix (default &quot;return &quot;)
      --lua-suffix string               suffix (default &quot;;\n&quot;)
      --lua-unquoted                    output unquoted string keys (e.g. {foo=&quot;bar&quot;})
  -M, --no-colors                       force print with no colors
  -N, --no-doc                          Don&#039;t print document separators (---)
  -0, --nul-output                      Use NUL char to separate values. If unwrap scalar is also set, fail if unwrapped scalar contains NUL char.
  -n, --null-input                      Don&#039;t read input, simply evaluate the expression given. Useful for creating docs from scratch.
  -o, --output-format string            [auto|a|yaml|y|json|j|kyaml|ky|props|p|csv|c|tsv|t|xml|x|base64|uri|toml|hcl|h|shell|s|lua|l|ini|i] output format type. (default &quot;auto&quot;)
  -P, --prettyPrint                     pretty print, shorthand for &#039;... style = &quot;&quot;&#039;
      --properties-array-brackets       use [x] in array paths (e.g. for SpringBoot)
      --properties-separator string     separator to use between keys and values (default &quot; = &quot;)
      --security-disable-env-ops        Disable env related operations.
      --security-disable-file-ops       Disable file related operations (e.g. load)
      --shell-key-separator string      separator for shell variable key paths (default &quot;_&quot;)
  -s, --split-exp string                print each result (or doc) into a file named (exp). [exp] argument must return a string. You can use $index in the expression as the result counter. The necessary directories will be created.
      --split-exp-file string           Use a file to specify the split-exp expression.
      --string-interpolation            Toggles strings interpolation of \(exp) (default true)
      --tsv-auto-parse                  parse TSV YAML/JSON values (default true)
  -r, --unwrapScalar                    unwrap scalar, print the value with no quotes, colors or comments. Defaults to true for yaml (default true)
  -v, --verbose                         verbose mode
  -V, --version                         Print version information and quit
      --xml-attribute-prefix string     prefix for xml attributes (default &quot;+@&quot;)
      --xml-content-name string         name for xml content (if no attribute name is present). (default &quot;+content&quot;)
      --xml-directive-name string       name for xml directives (e.g. &lt;!DOCTYPE thing cat&gt;) (default &quot;+directive&quot;)
      --xml-keep-namespace              enables keeping namespace after parsing attributes (default true)
      --xml-proc-inst-prefix string     prefix for xml processing instructions (e.g. &lt;?xml version=&quot;1&quot;?&gt;) (default &quot;+p_&quot;)
      --xml-raw-token                   enables using RawToken method instead Token. Commonly disables namespace translations. See https://pkg.go.dev/encoding/xml#Decoder.RawToken for details. (default true)
      --xml-skip-directives             skip over directives (e.g. &lt;!DOCTYPE thing cat&gt;)
      --xml-skip-proc-inst              skip over process instructions (e.g. &lt;?xml version=&quot;1&quot;?&gt;)
      --xml-strict-mode                 enables strict parsing of XML. See https://pkg.go.dev/encoding/xml for more details.
      --yaml-fix-merge-anchor-to-spec   Fix merge anchor to match YAML spec. Will default to true in late 2025

Use &quot;yq [command] --help&quot; for more information about a command.
```

## Troubleshooting

### Common Issues

**PowerShell quoting issues:**
```powershell
# Use single quotes for expressions
yq &#039;.a.b[0].c&#039; file.yaml

# Or escape double quotes
yq &quot;.a.b[0].c = \&quot;value\&quot;&quot; file.yaml
```

### Getting Help

- **Check existing issues**: [GitHub Issues](https://github.com/mikefarah/yq/issues)
- **Ask questions**: [GitHub Discussions](https://github.com/mikefarah/yq/discussions)
- **Documentation**: [Complete documentation](https://mikefarah.gitbook.io/yq/)
- **Examples**: [Recipes and examples](https://mikefarah.gitbook.io/yq/recipes)

## Known Issues / Missing Features
- `yq` attempts to preserve comment positions and whitespace as much as possible, but it does not handle all scenarios (see https://github.com/go-yaml/yaml/tree/v3 for details)
- Powershell has its own...[opinions on quoting yq](https://mikefarah.gitbook.io/yq/usage/tips-and-tricks#quotes-in-windows-powershell)
- &quot;yes&quot;, &quot;no&quot; were dropped as boolean values in the yaml 1.2 standard - which is the standard yq assumes.

See [tips and tricks](https://mikefarah.gitbook.io/yq/usage/tips-and-tricks) for more common problems and solutions.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[github/github-mcp-server]]></title>
            <link>https://github.com/github/github-mcp-server</link>
            <guid>https://github.com/github/github-mcp-server</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:15 GMT</pubDate>
            <description><![CDATA[GitHub's official MCP Server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/github-mcp-server">github/github-mcp-server</a></h1>
            <p>GitHub's official MCP Server</p>
            <p>Language: Go</p>
            <p>Stars: 27,021</p>
            <p>Forks: 3,593</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>[![Go Report Card](https://goreportcard.com/badge/github.com/github/github-mcp-server)](https://goreportcard.com/report/github.com/github/github-mcp-server)

# GitHub MCP Server

The GitHub MCP Server connects AI tools directly to GitHub&#039;s platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code files, manage issues and PRs, analyze code, and automate workflows. All through natural language interactions.

### Use Cases

- Repository Management: Browse and query code, search files, analyze commits, and understand project structure across any repository you have access to.
- Issue &amp; PR Automation: Create, update, and manage issues and pull requests. Let AI help triage bugs, review code changes, and maintain project boards.
- CI/CD &amp; Workflow Intelligence: Monitor GitHub Actions workflow runs, analyze build failures, manage releases, and get insights into your development pipeline.
- Code Analysis: Examine security findings, review Dependabot alerts, understand code patterns, and get comprehensive insights into your codebase.
- Team Collaboration: Access discussions, manage notifications, analyze team activity, and streamline processes for your team.

Built for developers who want to connect their AI tools to GitHub context and capabilities, from simple natural language queries to complex multi-step agent workflows.

---

## Remote GitHub MCP Server

[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D&amp;quality=insiders)

The remote GitHub MCP Server is hosted by GitHub and provides the easiest method for getting up and running. If your MCP host does not support remote MCP servers, don&#039;t worry! You can use the [local version of the GitHub MCP Server](https://github.com/github/github-mcp-server?tab=readme-ov-file#local-github-mcp-server) instead.

### Prerequisites

1. A compatible MCP host with remote server support (VS Code 1.101+, Claude Desktop, Cursor, Windsurf, etc.)
2. Any applicable [policies enabled](https://github.com/github/github-mcp-server/blob/main/docs/policies-and-governance.md)

### Install in VS Code

For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start. Make sure you&#039;re using [VS Code 1.101](https://code.visualstudio.com/updates/v1_101) or [later](https://code.visualstudio.com/updates) for remote MCP and OAuth support.

Alternatively, to manually configure VS Code, choose the appropriate JSON block from the examples below and add it to your host configuration:

&lt;table&gt;
&lt;tr&gt;&lt;th&gt;Using OAuth&lt;/th&gt;&lt;th&gt;Using a GitHub PAT&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th align=left colspan=2&gt;VS Code (version 1.101 or greater)&lt;/th&gt;&lt;/tr&gt;
&lt;tr valign=top&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;
    }
  }
}
```

&lt;/td&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer ${input:github_mcp_pat}&quot;
      }
    }
  },
  &quot;inputs&quot;: [
    {
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;id&quot;: &quot;github_mcp_pat&quot;,
      &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
      &quot;password&quot;: true
    }
  ]
}
```

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

### Install in other MCP hosts

- **[Copilot CLI](/docs/installation-guides/install-copilot-cli.md)** - Installation guide for GitHub Copilot CLI
- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot
- **[Claude Applications](/docs/installation-guides/install-claude.md)** - Installation guide for Claude Desktop and Claude Code CLI
- **[Codex](/docs/installation-guides/install-codex.md)** - Installation guide for OpenAI Codex
- **[Cursor](/docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE
- **[Windsurf](/docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE
- **[Rovo Dev CLI](/docs/installation-guides/install-rovo-dev-cli.md)** - Installation guide for Rovo Dev CLI

&gt; **Note:** Each MCP host application needs to configure a GitHub App or OAuth App to support remote access via OAuth. Any host application that supports remote MCP servers should support the remote GitHub server with PAT authentication. Configuration details and support levels vary by host. Make sure to refer to the host application&#039;s documentation for more info.

### Configuration

#### Toolset configuration

See [Remote Server Documentation](docs/remote-server.md) for full details on remote server configuration, toolsets, headers, and advanced usage. This file provides comprehensive instructions and examples for connecting, customizing, and installing the remote GitHub MCP Server in VS Code and other MCP hosts.

When no toolsets are specified, [default toolsets](#default-toolset) are used.

#### Insiders Mode

&gt; **Try new features early!** The remote server offers an insiders version with early access to new features and experimental tools.

&lt;table&gt;
&lt;tr&gt;&lt;th&gt;Using URL Path&lt;/th&gt;&lt;th&gt;Using Header&lt;/th&gt;&lt;/tr&gt;
&lt;tr valign=top&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/insiders&quot;
    }
  }
}
```

&lt;/td&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;,
      &quot;headers&quot;: {
        &quot;X-MCP-Insiders&quot;: &quot;true&quot;
      }
    }
  }
}
```

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

See [Remote Server Documentation](docs/remote-server.md#insiders-mode) for more details and examples.

#### GitHub Enterprise

##### GitHub Enterprise Cloud with data residency (ghe.com)

GitHub Enterprise Cloud can also make use of the remote server.

Example for `https://octocorp.ghe.com` with GitHub PAT token:

```
{
    ...
    &quot;proxima-github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://copilot-api.octocorp.ghe.com/mcp&quot;,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer ${input:github_mcp_pat}&quot;
      }
    },
    ...
}
```

&gt; **Note:** When using OAuth with GitHub Enterprise with VS Code and GitHub Copilot, you also need to configure your VS Code settings to point to your GitHub Enterprise instance - see [Authenticate from VS Code](https://docs.github.com/en/enterprise-cloud@latest/copilot/how-tos/configure-personal-settings/authenticate-to-ghecom)

##### GitHub Enterprise Server

GitHub Enterprise Server does not support remote server hosting. Please refer to [GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)](#github-enterprise-server-and-enterprise-cloud-with-data-residency-ghecom) from the local server configuration.

---

## Local GitHub MCP Server

[![Install with Docker in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D) [![Install with Docker in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D&amp;quality=insiders)

### Prerequisites

1. To run the server in a container, you will need to have [Docker](https://www.docker.com/) installed.
2. Once Docker is installed, you will also need to ensure Docker is running. The Docker image is available at `ghcr.io/github/github-mcp-server`. The image is public; if you get errors on pull, you may have an expired token and need to `docker logout ghcr.io`.
3. Lastly you will need to [Create a GitHub Personal Access Token](https://github.com/settings/personal-access-tokens/new).
The MCP server can use many of the GitHub APIs, so enable the permissions that you feel comfortable granting your AI tools (to learn more about access tokens, please check out the [documentation](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)).

&lt;details&gt;&lt;summary&gt;&lt;b&gt;Handling PATs Securely&lt;/b&gt;&lt;/summary&gt;

### Environment Variables (Recommended)

To keep your GitHub PAT secure and reusable across different MCP hosts:

1. **Store your PAT in environment variables**

   ```bash
   export GITHUB_PAT=your_token_here
   ```

   Or create a `.env` file:

   ```env
   GITHUB_PAT=your_token_here
   ```

2. **Protect your `.env` file**

   ```bash
   # Add to .gitignore to prevent accidental commits
   echo &quot;.env&quot; &gt;&gt; .gitignore
   ```

3. **Reference the token in configurations**

   ```bash
   # CLI usage
   claude mcp update github -e GITHUB_PERSONAL_ACCESS_TOKEN=$GITHUB_PAT

   # In config files (where supported)
   &quot;env&quot;: {
     &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;$GITHUB_PAT&quot;
   }
   ```

&gt; **Note**: Environment variable support varies by host app and IDE. Some applications (like Windsurf) require hardcoded tokens in config files.

### Token Security Best Practices

- **Minimum scopes**: Only grant necessary permissions
  - `repo` - Repository operations
  - `read:packages` - Docker image access
  - `read:org` - Organization team access
- **Separate tokens**: Use different PATs for different projects/environments
- **Regular rotation**: Update tokens periodically
- **Never commit**: Keep tokens out of version control
- **File permissions**: Restrict access to config files containing tokens

  ```bash
  chmod 600 ~/.your-app/config.json
  ```

&lt;/details&gt;

### GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)

The flag `--gh-host` and the environment variable `GITHUB_HOST` can be used to set
the hostname for GitHub Enterprise Server or GitHub Enterprise Cloud with data residency.

- For GitHub Enterprise Server, prefix the hostname with the `https://` URI scheme, as it otherwise defaults to `http://`, which GitHub Enterprise Server does not support.
- For GitHub Enterprise Cloud with data residency, use `https://YOURSUBDOMAIN.ghe.com` as the hostname.

``` json
&quot;github&quot;: {
    &quot;command&quot;: &quot;docker&quot;,
    &quot;args&quot;: [
    &quot;run&quot;,
    &quot;-i&quot;,
    &quot;--rm&quot;,
    &quot;-e&quot;,
    &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
    &quot;-e&quot;,
    &quot;GITHUB_HOST&quot;,
    &quot;ghcr.io/github/github-mcp-server&quot;
    ],
    &quot;env&quot;: {
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;,
        &quot;GITHUB_HOST&quot;: &quot;https://&lt;your GHES or ghe.com domain name&gt;&quot;
    }
}
```

## Installation

### Install in GitHub Copilot on VS Code

For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start.

More about using MCP server tools in VS Code&#039;s [agent mode documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers).

Install in GitHub Copilot on other IDEs (JetBrains, Visual Studio, Eclipse, etc.)

Add the following JSON block to your IDE&#039;s MCP settings.

```json
{
  &quot;mcp&quot;: {
    &quot;inputs&quot;: [
      {
        &quot;type&quot;: &quot;promptString&quot;,
        &quot;id&quot;: &quot;github_token&quot;,
        &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
        &quot;password&quot;: true
      }
    ],
    &quot;servers&quot;: {
      &quot;github&quot;: {
        &quot;command&quot;: &quot;docker&quot;,
        &quot;args&quot;: [
          &quot;run&quot;,
          &quot;-i&quot;,
          &quot;--rm&quot;,
          &quot;-e&quot;,
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
          &quot;ghcr.io/github/github-mcp-server&quot;
        ],
        &quot;env&quot;: {
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;
        }
      }
    }
  }
}
```

Optionally, you can add a similar example (i.e. without the mcp key) to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with other host applications that accept the same format.

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Example JSON block without the MCP key included&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;

```json
{
  &quot;inputs&quot;: [
    {
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;id&quot;: &quot;github_token&quot;,
      &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
      &quot;password&quot;: true
    }
  ],
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;-e&quot;,
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
        &quot;ghcr.io/github/github-mcp-server&quot;
      ],
      &quot;env&quot;: {
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;
      }
    }
  }
}
```

&lt;/details&gt;

### Install in Other MCP Hosts

For other MCP host applications, please refer to our installation guides:

- **[Copilot CLI](docs/installation-guides/install-copilot-cli.md)** - Installation guide for GitHub Copilot CLI
- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot
- **[Claude Code &amp; Claude Desktop](docs/installation-guides/install-claude.md)** - Installation guide for Claude Code and Claude Desktop
- **[Cursor](docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE
- **[Google Gemini CLI](docs/installation-guides/install-gemini-cli.md)** - Installation guide for Google Gemini CLI
- **[Windsurf](docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE

For a complete overview of all installation options, see our **[Installation Guides Index](docs/installation-guides)**.

&gt; **Note:** Any host application that supports local MCP servers should be able to access the local GitHub MCP server. However, the specific configuration process, syntax and stability of the integration will vary by host application. While many may follow a similar format to the examples above, this is not guaranteed. Please refer to your host application&#039;s documentation for the correct MCP configuration syntax and setup process.

### Build from source

If you don&#039;t have Docker, you can use `go build` to build the binary in the
`cmd/github-mcp-server` directory, and use the `github-mcp-server stdio` command with the `GITHUB_PERSONAL_ACCESS_TOKEN` environment variable set to your token. To specify the output location of the build, use the `-o` flag. You should configure your server to use the built executable as its `command`. For example:

```JSON
{
  &quot;mcp&quot;: {
    &quot;servers&quot;: {
      &quot;github&quot;: {
        &quot;command&quot;: &quot;/path/to/github-mcp-server&quot;,
        &quot;args&quot;: [&quot;stdio&quot;],
        &quot;env&quot;: {
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;&lt;YOUR_TOKEN&gt;&quot;
        }
      }
    }
  }
}
```

### CLI utilities

The `github-mcp-server` binary includes a few CLI subcommands that are helpful for debugging and exploring the server.

- `github-mcp-server tool-search &quot;&lt;query&gt;&quot;` searches tools by name, description, and input parameter names. Use `--max-results` to return more matches.
Example (color output requires a TTY; use `docker run -t` (or `-it`) when running in Docker):
```bash
docker run -it --rm ghcr.io/github/github-mcp-server tool-search &quot;issue&quot; --max-results 5
github-mcp-server tool-search &quot;issue&quot; --max-results 5
```

## Tool Configuration

The GitHub MCP Server supports enabling or disabling specific groups of functionalities via the `--toolsets` flag. This allows you to control which GitHub API capabilities are available to your AI tools. Enabling only the toolsets that you need can help the LLM with tool choice and reduce the context size.

_Toolsets are not limited to Tools. Relevant MCP Resources and Prompts are also included where applicable._

When no toolsets are specified, [default toolsets](#default-toolset) are used.

&gt; **Looking for examples?** See the [Server Configuration Guide](./docs/server-configuration.md) for common recipes like minimal setups, read-only mode, and combining tools with toolsets.

#### Specifying Toolsets

To specify toolsets you want available to the LLM, you can pass an allow-list in two ways:

1. **Using Command Line Argument**:

   ```bash
   github-mcp-server --toolsets repos,issues,pull_requests,actions,code_security
   ```

2. **Using Environment Variable**:

   ```bash
   GITHUB_TOOLSETS=&quot;repos,issues,pull_requests,actions,code_security&quot; ./github-mcp-server
   ```

The environment variable `GITHUB_TOOLSETS` takes precedence over the command line argument if both are provided.

#### Specifying Individual Tools

You can also configure specific tools using the `--tools` flag. Tools can be used independently or combined with toolsets and dynamic toolsets discovery for fine-grained control.

1. **Using Command Line Argument**:

   ```bash
   github-mcp-server --tools get_file_contents,issue_read,create_pull_request
   ```

2. **Using Environment Variable**:

   ```bash
   GITHUB_TOOLS=&quot;get_file_contents,issue_read,create_pull_request&quot; ./github-mcp-server
   ```

3. **Combining with Toolsets** (additive):

   ```bash
   github-mcp-server --toolsets repos,issues --tools get_gist
   ```

   This registers all tools from `repos` and `issues` toolsets, plus `get_gist`.

4. **Combining with Dynamic Toolsets** (additive):

   ```bash
   github-mcp-server --tools get_file_contents --dynamic-toolsets
   ```

   This registers `get_file_contents` plus the dynamic toolset tools (`enable_toolset`, `list_available_toolsets`, `get_toolset_tools`).

**Important Notes:**

- Tools, toolsets, and dynamic toolsets can all be used together
- Read-only mode takes priority: write tools are skipped if `--read-only` is set, even if explicitly requested via `--tools`
- Tool names must match exactly (e.g., `get_file_contents`, not `getFileContents`). Invalid tool names will cause the server to fail at startup with an error message
- When tools are renamed, old names are preserved as aliases for backward compatibility. See [Deprecated Tool Aliases](docs/deprecated-tool-aliases.md) for details.

### Using Toolsets With Docker

When using Docker, you can pass the toolsets as environment variables:

```bash
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&lt;your-token&gt; \
  -e GITHUB_TOOLSETS=&quot;repos,issues,pull_requests,actions,code_security&quot; \
  ghcr.io/github/github-mcp-server
```

### Using Tools With Docker

When using Docker, you can pass specific tools as environment variables. You can also combine tools with toolsets:

```bash
# Tools only
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&lt;your-token&gt; \
  -e GITHUB_TOOLS=&quot;get_file_contents,issue_read,create_pull_request&quot; \
  ghcr.io/github/github-mcp-server

# Tools combined with toolsets (additive)
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&lt;your-token&gt; \
  -e GITHUB_TOOLSETS=&quot;repos,issues&quot; \
  -e GITHUB_TOOLS=&quot;get_gist&quot; \
  ghcr.io/github/gi

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ipfs/kubo]]></title>
            <link>https://github.com/ipfs/kubo</link>
            <guid>https://github.com/ipfs/kubo</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:14 GMT</pubDate>
            <description><![CDATA[An IPFS implementation in Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ipfs/kubo">ipfs/kubo</a></h1>
            <p>An IPFS implementation in Go</p>
            <p>Language: Go</p>
            <p>Stars: 16,911</p>
            <p>Forks: 3,140</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://github.com/ipfs/kubo/blob/master/docs/logo/&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/157609/250148884-d6d12db8-fdcf-4be3-8546-2550b69845d8.png&quot; alt=&quot;Kubo logo&quot; title=&quot;Kubo logo&quot; width=&quot;200&quot;&gt;&lt;/a&gt;
  &lt;br&gt;
  Kubo: IPFS Implementation in Go
  &lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot; style=&quot;font-size: 1.2rem;&quot;&gt;The first implementation of IPFS.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ipfs.tech&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/project-IPFS-blue.svg?style=flat-square&quot; alt=&quot;Official Part of IPFS Project&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discuss.ipfs.tech&quot;&gt;&lt;img alt=&quot;Discourse Forum&quot; src=&quot;https://img.shields.io/discourse/posts?server=https%3A%2F%2Fdiscuss.ipfs.tech&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://docs.ipfs.tech/community/&quot;&gt;&lt;img alt=&quot;Matrix&quot; src=&quot;https://img.shields.io/matrix/ipfs-space%3Aipfs.io?server_fqdn=matrix.org&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/ipfs/kubo/actions&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/ipfs/kubo/gobuild.yml?branch=master&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/ipfs/kubo/releases&quot;&gt;&lt;img alt=&quot;GitHub release&quot; src=&quot;https://img.shields.io/github/v/release/ipfs/kubo?filter=!*rc*&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;b&gt;&lt;a href=&quot;#what-is-kubo&quot;&gt;What is Kubo?&lt;/a&gt;&lt;/b&gt; | &lt;b&gt;&lt;a href=&quot;#quick-taste&quot;&gt;Quick Taste&lt;/a&gt;&lt;/b&gt; | &lt;b&gt;&lt;a href=&quot;#install&quot;&gt;Install&lt;/a&gt;&lt;/b&gt; | &lt;b&gt;&lt;a href=&quot;#documentation&quot;&gt;Documentation&lt;/a&gt;&lt;/b&gt; | &lt;b&gt;&lt;a href=&quot;#development&quot;&gt;Development&lt;/a&gt;&lt;/b&gt; | &lt;b&gt;&lt;a href=&quot;#getting-help&quot;&gt;Getting Help&lt;/a&gt;&lt;/b&gt;
&lt;/p&gt;

## What is Kubo?

Kubo was the first [IPFS](https://docs.ipfs.tech/concepts/what-is-ipfs/) implementation and is the [most widely used one today](https://probelab.io/ipfs/topology/#chart-agent-types-avg). It takes an opinionated approach to content-addressing ([CIDs](https://docs.ipfs.tech/concepts/glossary/#cid), [DAGs](https://docs.ipfs.tech/concepts/glossary/#dag)) that maximizes interoperability: [UnixFS](https://docs.ipfs.tech/concepts/glossary/#unixfs) for files and directories, [HTTP Gateways](https://docs.ipfs.tech/concepts/glossary/#gateway) for web browsers, [Bitswap](https://docs.ipfs.tech/concepts/glossary/#bitswap) and [HTTP](https://specs.ipfs.tech/http-gateways/trustless-gateway/) for verifiable data transfer.

**Features:**

- Runs an IPFS node as a network service (LAN [mDNS](https://github.com/libp2p/specs/blob/master/discovery/mdns.md) and WAN [Amino DHT](https://docs.ipfs.tech/concepts/glossary/#dht))
- [Command-line interface](https://docs.ipfs.tech/reference/kubo/cli/) (`ipfs --help`)
- [WebUI](https://github.com/ipfs/ipfs-webui/#readme) for node management
- [HTTP Gateway](https://specs.ipfs.tech/http-gateways/) for trusted and [trustless](https://docs.ipfs.tech/reference/http/gateway/#trustless-verifiable-retrieval) content retrieval
- [HTTP RPC API](https://docs.ipfs.tech/reference/kubo/rpc/) to control the daemon
- [HTTP Routing V1](https://specs.ipfs.tech/routing/http-routing-v1/) client and server for [delegated routing](./docs/delegated-routing.md)
- [Content blocking](./docs/content-blocking.md) for public node operators

**Other IPFS implementations:** [Helia](https://github.com/ipfs/helia) (JavaScript), [more...](https://docs.ipfs.tech/concepts/ipfs-implementations/)

## Quick Taste

After [installing Kubo](#install), verify it works:

```console
$ ipfs init
generating ED25519 keypair...done
peer identity: 12D3KooWGcSLQdLDBi2BvoP8WnpdHvhWPbxpGcqkf93rL2XMZK7R

$ ipfs daemon &amp;
Daemon is ready

$ echo &quot;hello IPFS&quot; | ipfs add -q --cid-version 1
bafkreicouv3sksjuzxb3rbb6rziy6duakk2aikegsmtqtz5rsuppjorxsa

$ ipfs cat bafkreicouv3sksjuzxb3rbb6rziy6duakk2aikegsmtqtz5rsuppjorxsa
hello IPFS
```

Verify this CID is provided by your node to the IPFS network: &lt;https://check.ipfs.network/?cid=bafkreicouv3sksjuzxb3rbb6rziy6duakk2aikegsmtqtz5rsuppjorxsa&gt;

See `ipfs add --help` for all import options. Ready for more? Follow the [command-line quick start](https://docs.ipfs.tech/how-to/command-line-quick-start/).

## Install

Follow the [official installation guide](https://docs.ipfs.tech/install/command-line/), or choose: [prebuilt binary](#official-prebuilt-binaries) | [Docker](#docker) | [package manager](#package-managers) | [from source](#build-from-source).

Prefer a GUI? Try [IPFS Desktop](https://docs.ipfs.tech/install/ipfs-desktop/) and/or [IPFS Companion](https://docs.ipfs.tech/install/ipfs-companion/).

### Minimal System Requirements

Kubo runs on most Linux, macOS, and Windows systems. For optimal performance, we recommend at least 6 GB of RAM and 2 CPU cores (more is ideal, as Kubo is highly parallel).

&gt; [!IMPORTANT]
&gt; Larger pinsets require additional memory, with an estimated ~1 GiB of RAM per 20 million items for reproviding to the Amino DHT.

&gt; [!CAUTION]
&gt; Systems with less than the recommended memory may experience instability, frequent OOM errors or restarts, and missing data announcement (reprovider window), which can make data fully or partially inaccessible to other peers. Running Kubo on underprovisioned hardware is at your own risk.

### Official Prebuilt Binaries

Download from https://dist.ipfs.tech#kubo or [GitHub Releases](https://github.com/ipfs/kubo/releases/latest).

### Docker

Official images are published at https://hub.docker.com/r/ipfs/kubo/: [![Docker Image Version (latest semver)](https://img.shields.io/docker/v/ipfs/kubo?color=blue&amp;label=kubo%20docker%20image&amp;logo=docker&amp;sort=semver&amp;style=flat-square&amp;cacheSeconds=3600)](https://hub.docker.com/r/ipfs/kubo/)

#### üü¢ Release Images

Use these for production deployments.

- `latest` and [`release`](https://hub.docker.com/r/ipfs/kubo/tags?name=release) always point at [the latest stable release](https://github.com/ipfs/kubo/releases/latest)
- [`vN.N.N`](https://hub.docker.com/r/ipfs/kubo/tags?name=v) points at a specific [release tag](https://github.com/ipfs/kubo/releases)

```console
$ docker pull ipfs/kubo:latest
$ docker run --rm -it --net=host ipfs/kubo:latest
```

To [customize your node](https://docs.ipfs.tech/install/run-ipfs-inside-docker/#customizing-your-node), pass config via `-e` or mount scripts in `/container-init.d`.

#### üü† Developer Preview Images

For internal testing, not intended for production.

- [`master-latest`](https://hub.docker.com/r/ipfs/kubo/tags?name=master-latest) points at `HEAD` of [`master`](https://github.com/ipfs/kubo/commits/master/)
- [`master-YYYY-DD-MM-GITSHA`](https://hub.docker.com/r/ipfs/kubo/tags?name=master-2) points at a specific commit

#### üî¥ Internal Staging Images

For testing arbitrary commits and experimental patches (force push to `staging` branch).

- [`staging-latest`](https://hub.docker.com/r/ipfs/kubo/tags?name=staging-latest) points at `HEAD` of [`staging`](https://github.com/ipfs/kubo/commits/staging/)
- [`staging-YYYY-DD-MM-GITSHA`](https://hub.docker.com/r/ipfs/kubo/tags?name=staging-2) points at a specific commit

### Build from Source

![GitHub go.mod Go version](https://img.shields.io/github/go-mod/go-version/ipfs/kubo?label=Requires%20Go&amp;logo=go&amp;style=flat-square&amp;cacheSeconds=3600)

```bash
git clone https://github.com/ipfs/kubo.git
cd kubo
make build    # creates cmd/ipfs/ipfs
make install  # installs to $GOPATH/bin/ipfs
```

See the [Developer Guide](docs/developer-guide.md) for details, Windows instructions, and troubleshooting.

### Package Managers

Kubo is available in community-maintained packages across many operating systems, Linux distributions, and package managers. See [Repology](https://repology.org/project/kubo/versions) for the full list: [![Packaging status](https://repology.org/badge/tiny-repos/kubo.svg)](https://repology.org/project/kubo/versions)

&gt; [!WARNING]
&gt; These packages are maintained by third-party volunteers. The IPFS Project and Kubo maintainers are not responsible for their contents or supply chain security. For increased security, [build from source](#build-from-source).

#### Linux

| Distribution | Install | Version |
|--------------|---------|---------|
| Ubuntu | [PPA](https://launchpad.net/~twdragon/+archive/ubuntu/ipfs): `sudo apt install ipfs-kubo` | [![PPA: twdragon](https://img.shields.io/badge/PPA-twdragon-E95420?logo=ubuntu)](https://launchpad.net/~twdragon/+archive/ubuntu/ipfs) |
| Arch | `pacman -S kubo` | [![Arch package](https://repology.org/badge/version-for-repo/arch/kubo.svg)](https://archlinux.org/packages/extra/x86_64/kubo/) |
| Fedora | [COPR](https://copr.fedorainfracloud.org/coprs/taw/ipfs/): `dnf install kubo` | [![COPR: taw](https://img.shields.io/badge/COPR-taw-51A2DA?logo=fedora)](https://copr.fedorainfracloud.org/coprs/taw/ipfs/) |
| Nix | `nix-env -i kubo` | [![nixpkgs unstable](https://repology.org/badge/version-for-repo/nix_unstable/kubo.svg)](https://search.nixos.org/packages?query=kubo) |
| Gentoo | `emerge -a net-p2p/kubo` | [![Gentoo package](https://repology.org/badge/version-for-repo/gentoo/kubo.svg)](https://packages.gentoo.org/packages/net-p2p/kubo) |
| openSUSE | `zypper install kubo` | [![openSUSE Tumbleweed](https://repology.org/badge/version-for-repo/opensuse_tumbleweed/kubo.svg)](https://software.opensuse.org/package/kubo) |
| Solus | `sudo eopkg install kubo` | [![Solus package](https://repology.org/badge/version-for-repo/solus/kubo.svg)](https://packages.getsol.us/shannon/k/kubo/) |
| Guix | `guix install kubo` | [![Guix package](https://repology.org/badge/version-for-repo/gnuguix/kubo.svg)](https://packages.guix.gnu.org/packages/kubo/) |
| _other_ | [See Repology for the full list](https://repology.org/project/kubo/versions) | |

~~Snap~~ no longer supported ([#8688](https://github.com/ipfs/kubo/issues/8688))

#### macOS

| Manager | Install | Version |
|---------|---------|---------|
| Homebrew | `brew install ipfs` | [![Homebrew](https://repology.org/badge/version-for-repo/homebrew/kubo.svg)](https://formulae.brew.sh/formula/ipfs) |
| MacPorts | `sudo port install ipfs` | [![MacPorts](https://repology.org/badge/version-for-repo/macports/kubo.svg)](https://ports.macports.org/port/ipfs/) |
| Nix | `nix-env -i kubo` | [![nixpkgs unstable](https://repology.org/badge/version-for-repo/nix_unstable/kubo.svg)](https://search.nixos.org/packages?query=kubo) |
| _other_ | [See Repology for the full list](https://repology.org/project/kubo/versions) | |

#### Windows

| Manager | Install | Version |
|---------|---------|---------|
| Scoop | `scoop install kubo` | [![Scoop](https://repology.org/badge/version-for-repo/scoop/kubo.svg)](https://scoop.sh/#/apps?q=kubo) |
| _other_ | [See Repology for the full list](https://repology.org/project/kubo/versions) | |

~~Chocolatey~~ no longer supported ([#9341](https://github.com/ipfs/kubo/issues/9341))

## Documentation

| Topic | Description |
|-------|-------------|
| [Configuration](docs/config.md) | All config options reference |
| [Environment variables](docs/environment-variables.md) | Runtime settings via env vars |
| [Experimental features](docs/experimental-features.md) | Opt-in features in development |
| [HTTP Gateway](docs/gateway.md) | Path, subdomain, and trustless gateway setup |
| [HTTP RPC clients](docs/http-rpc-clients.md) | Client libraries for Go, JS |
| [Delegated routing](docs/delegated-routing.md) | Multi-router and HTTP routing |
| [Metrics &amp; monitoring](docs/metrics.md) | Prometheus metrics |
| [Content blocking](docs/content-blocking.md) | Denylist for public nodes |
| [Customizing](docs/customizing.md) | Unsure if use Plugins, Boxo, or fork? |
| [Debug guide](docs/debug-guide.md) | CPU profiles, memory analysis, tracing |
| [Changelogs](docs/changelogs/) | Release notes for each version |
| [All documentation](https://github.com/ipfs/kubo/tree/master/docs) | Full list of docs |

## Development

See the [Developer Guide](docs/developer-guide.md) for build instructions, testing, and contribution workflow. AI coding agents should follow [AGENTS.md](AGENTS.md).

## Getting Help

- [IPFS Forum](https://discuss.ipfs.tech) - community support, questions, and discussion
- [Community](https://docs.ipfs.tech/community/) - chat, events, and working groups
- [GitHub Issues](https://github.com/ipfs/kubo/issues) - bug reports for Kubo specifically
- [IPFS Docs Issues](https://github.com/ipfs/ipfs-docs/issues) - documentation issues

## Security Issues

See [`SECURITY.md`](SECURITY.md).

## Contributing

[![](https://cdn.rawgit.com/jbenet/contribute-ipfs-gif/master/img/contribute.gif)](https://github.com/ipfs/community/blob/master/CONTRIBUTING.md)

We welcome contributions. See [CONTRIBUTING.md](CONTRIBUTING.md) and the [Developer Guide](docs/developer-guide.md).

This repository follows the IPFS [Code of Conduct](https://github.com/ipfs/community/blob/master/code-of-conduct.md).

## Maintainer Info

&lt;a href=&quot;https://ipshipyard.com/&quot;&gt;&lt;img align=&quot;right&quot; src=&quot;https://github.com/user-attachments/assets/39ed3504-bb71-47f6-9bf8-cb9a1698f272&quot; /&gt;&lt;/a&gt;

&gt; [!NOTE]
&gt; Kubo is maintained by the [Shipyard](https://ipshipyard.com/) team.
&gt;
&gt; [Release Process](https://ipshipyard.notion.site/Kubo-Release-Process-6dba4f5755c9458ab5685eeb28173778)

## License

Dual-licensed under Apache 2.0 and MIT:

- [LICENSE-APACHE](LICENSE-APACHE)
- [LICENSE-MIT](LICENSE-MIT)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[danielmiessler/Fabric]]></title>
            <link>https://github.com/danielmiessler/Fabric</link>
            <guid>https://github.com/danielmiessler/Fabric</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:13 GMT</pubDate>
            <description><![CDATA[Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/danielmiessler/Fabric">danielmiessler/Fabric</a></h1>
            <p>Fabric is an open-source framework for augmenting humans using AI. It provides a modular system for solving specific problems using a crowdsourced set of AI prompts that can be used anywhere.</p>
            <p>Language: Go</p>
            <p>Stars: 39,138</p>
            <p>Forks: 3,904</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://go.warp.dev/fabric&quot; target=&quot;_blank&quot;&gt;
        &lt;sup&gt;Special thanks to:&lt;/sup&gt;
        &lt;br&gt;
        &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png&quot;&gt;
        &lt;br&gt;
        &lt;h&gt;Warp, built for coding with multiple AI agents&lt;/b&gt;
        &lt;br&gt;
        &lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt;
    &lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;./docs/images/fabric-logo-gif.gif&quot; alt=&quot;fabriclogo&quot; width=&quot;400&quot; height=&quot;400&quot;/&gt;

# `fabric`

![Static Badge](https://img.shields.io/badge/mission-human_flourishing_via_AI_augmentation-purple)
&lt;br /&gt;
![GitHub top language](https://img.shields.io/github/languages/top/danielmiessler/fabric)
![GitHub last commit](https://img.shields.io/github/last-commit/danielmiessler/fabric)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/danielmiessler/fabric)

&lt;div align=&quot;center&quot;&gt;
&lt;h4&gt;&lt;code&gt;fabric&lt;/code&gt; is an open-source framework for augmenting humans using AI.&lt;/h4&gt;
&lt;/div&gt;

![Screenshot of fabric](./docs/images/fabric-summarize.png)

&lt;/div&gt;

[Updates](#updates) ‚Ä¢
[What and Why](#what-and-why) ‚Ä¢
[Philosophy](#philosophy) ‚Ä¢
[Installation](#installation) ‚Ä¢
[Usage](#usage) ‚Ä¢
[REST API](#rest-api-server) ‚Ä¢
[Examples](#examples) ‚Ä¢
[Just Use the Patterns](#just-use-the-patterns) ‚Ä¢
[Custom Patterns](#custom-patterns) ‚Ä¢
[Helper Apps](#helper-apps) ‚Ä¢
[Meta](#meta)

&lt;/div&gt;

## What and why

Since the start of modern AI in late 2022 we&#039;ve seen an **_extraordinary_** number of AI applications for accomplishing tasks. There are thousands of websites, chat-bots, mobile apps, and other interfaces for using all the different AI out there.

It&#039;s all really exciting and powerful, but _it&#039;s not easy to integrate this functionality into our lives._

&lt;div class=&quot;align center&quot;&gt;
&lt;h4&gt;In other words, AI doesn&#039;t have a capabilities problem‚Äîit has an &lt;em&gt;integration&lt;/em&gt; problem.&lt;/h4&gt;
&lt;/div&gt;

**Fabric was created to address this by creating and organizing the fundamental units of AI‚Äîthe prompts themselves!**

Fabric organizes prompts by real-world task, allowing people to create, collect, and organize their most important AI solutions in a single place for use in their favorite tools. And if you&#039;re command-line focused, you can use Fabric itself as the interface!

## Updates

For a deep dive into Fabric and its internals, read the documentation in the [docs folder](https://github.com/danielmiessler/Fabric/tree/main/docs). There is
also the extremely useful and regularly updated [DeepWiki](https://deepwiki.com/danielmiessler/Fabric) for Fabric.

&lt;details&gt;
&lt;summary&gt;Click to view recent updates&lt;/summary&gt;

Dear Users,

We&#039;ve been doing so many exciting things here at Fabric, I wanted to give a quick summary here to give you a sense of our development velocity!

Below are the **new features and capabilities** we&#039;ve added (newest first):

### Recent Major Features

- [v1.4.380](https://github.com/danielmiessler/fabric/releases/tag/v1.4.380) (Jan 15, 2026) ‚Äî **Microsoft 365 Copilot Integration**: Added support for corporate Microsoft 365 Copilot, enabling enterprise users to leverage AI grounded in their organization&#039;s Microsoft 365 data (emails, documents, meetings.
- [v1.4.378](https://github.com/danielmiessler/fabric/releases/tag/v1.4.378) (Jan 14, 2026) ‚Äî **Digital Ocean GenAI Support**: Added support for Digital Ocean GenAI, along with a [guide for how to use it](./docs/DigitalOcean-Agents-Setup.md).
- [v1.4.356](https://github.com/danielmiessler/fabric/releases/tag/v1.4.356) (Dec 22, 2025) ‚Äî **Complete Internationalization**: Full i18n support for setup prompts across all 10 languages with intelligent environment variable handling‚Äîmaking Fabric truly accessible worldwide while maintaining configuration consistency.
- [v1.4.350](https://github.com/danielmiessler/fabric/releases/tag/v1.4.350) (Dec 18, 2025) ‚Äî **Interactive API Documentation**: Adds Swagger/OpenAPI UI at `/swagger/index.html` with comprehensive REST API documentation, enhanced developer guides, and improved endpoint discoverability for easier integration.
- [v1.4.338](https://github.com/danielmiessler/fabric/releases/tag/v1.4.338) (Dec 4, 2025) ‚Äî Add Abacus vendor support for Chat-LLM
  models (see [RouteLLM APIs](https://abacus.ai/app/route-llm-apis)).
- [v1.4.337](https://github.com/danielmiessler/fabric/releases/tag/v1.4.337) (Dec 4, 2025) ‚Äî Add &quot;Z AI&quot; vendor support. See the [Z AI overview](https://docs.z.ai/guides/overview/overview) page for more details.
- [v1.4.334](https://github.com/danielmiessler/fabric/releases/tag/v1.4.334) (Nov 26, 2025) ‚Äî **Claude Opus 4.5**: Updates the Anthropic SDK to the latest and adds the new [Claude Opus 4.5](https://www.anthropic.com/news/claude-opus-4-5) to the available models.
- [v1.4.331](https://github.com/danielmiessler/fabric/releases/tag/v1.4.331) (Nov 23, 2025) ‚Äî **Support for GitHub Models**: Adds support for using GitHub Models.
- [v1.4.322](https://github.com/danielmiessler/fabric/releases/tag/v1.4.322) (Nov 5, 2025) ‚Äî **Interactive HTML Concept Maps and Claude Sonnet 4.5**: Adds `create_conceptmap` pattern for visual knowledge representation using Vis.js, introduces WELLNESS category with psychological analysis patterns, and upgrades to Claude Sonnet 4.5
- [v1.4.317](https://github.com/danielmiessler/fabric/releases/tag/v1.4.317) (Sep 21, 2025) ‚Äî **Portuguese Language Variants**: Adds BCP 47 locale normalization with support for Brazilian Portuguese (pt-BR) and European Portuguese (pt-PT) with intelligent fallback chains
- [v1.4.314](https://github.com/danielmiessler/fabric/releases/tag/v1.4.314) (Sep 17, 2025) ‚Äî **Azure OpenAI Migration**: Migrates to official `openai-go/azure` SDK with improved authentication and default API version support
- [v1.4.311](https://github.com/danielmiessler/fabric/releases/tag/v1.4.311) (Sep 13, 2025) ‚Äî **More internationalization support**: Adds de (German), fa (Persian / Farsi), fr (French), it (Italian),
  ja (Japanese), pt (Portuguese), zh (Chinese)
- [v1.4.309](https://github.com/danielmiessler/fabric/releases/tag/v1.4.309) (Sep 9, 2025) ‚Äî **Comprehensive internationalization support**: Includes English and Spanish locale files.
- [v1.4.303](https://github.com/danielmiessler/fabric/releases/tag/v1.4.303) (Aug 29, 2025) ‚Äî **New Binary Releases**: Linux ARM and Windows ARM targets. You can run Fabric on the Raspberry PI and on your Windows Surface!
- [v1.4.294](https://github.com/danielmiessler/fabric/releases/tag/v1.4.294) (Aug 20, 2025) ‚Äî **Venice AI Support**: Added the Venice AI provider. Venice is a Privacy-First, Open-Source AI provider. See their [&quot;About Venice&quot;](https://docs.venice.ai/overview/about-venice) page for details.
- [v1.4.291](https://github.com/danielmiessler/fabric/releases/tag/v1.4.291) (Aug 18, 2025) ‚Äî **Speech To Text**: Add OpenAI speech-to-text support with `--transcribe-file`, `--transcribe-model`, and `--split-media-file` flags.
- [v1.4.287](https://github.com/danielmiessler/fabric/releases/tag/v1.4.287) (Aug 16, 2025) ‚Äî **AI Reasoning**: Add Thinking to Gemini models and introduce `readme_updates` python script
- [v1.4.286](https://github.com/danielmiessler/fabric/releases/tag/v1.4.286) (Aug 14, 2025) ‚Äî **AI Reasoning**: Introduce Thinking Config Across Anthropic and OpenAI Providers
- [v1.4.285](https://github.com/danielmiessler/fabric/releases/tag/v1.4.285) (Aug 13, 2025) ‚Äî **Extended Context**: Enable One Million Token Context Beta Feature for Sonnet-4
- [v1.4.284](https://github.com/danielmiessler/fabric/releases/tag/v1.4.284) (Aug 12, 2025) ‚Äî **Easy Shell Completions Setup**: Introduce One-Liner Curl Install for Completions
- [v1.4.283](https://github.com/danielmiessler/fabric/releases/tag/v1.4.283) (Aug 12, 2025) ‚Äî **Model Management**: Add Vendor Selection Support for Models
- [v1.4.282](https://github.com/danielmiessler/fabric/releases/tag/v1.4.282) (Aug 11, 2025) ‚Äî **Enhanced Shell Completions**: Enhanced Shell Completions for Fabric CLI Binaries
- [v1.4.281](https://github.com/danielmiessler/fabric/releases/tag/v1.4.281) (Aug 11, 2025) ‚Äî **Gemini Search Tool**: Add Web Search Tool Support for Gemini Models
- [v1.4.278](https://github.com/danielmiessler/fabric/releases/tag/v1.4.278) (Aug 9, 2025) ‚Äî **Enhance YouTube Transcripts**: Enhance YouTube Support with Custom yt-dlp Arguments
- [v1.4.277](https://github.com/danielmiessler/fabric/releases/tag/v1.4.277) (Aug 8, 2025) ‚Äî **Desktop Notifications**: Add cross-platform desktop notifications to Fabric CLI
- [v1.4.274](https://github.com/danielmiessler/fabric/releases/tag/v1.4.274) (Aug 7, 2025) ‚Äî **Claude 4.1 Added**: Add Support for Claude Opus 4.1 Model
- [v1.4.271](https://github.com/danielmiessler/fabric/releases/tag/v1.4.271) (Jul 28, 2025) ‚Äî **AI Summarized Release Notes**: Enable AI summary updates for GitHub releases
- [v1.4.268](https://github.com/danielmiessler/fabric/releases/tag/v1.4.268) (Jul 26, 2025) ‚Äî **Gemini TTS Voice Selection**: add Gemini TTS voice selection and listing functionality
- [v1.4.267](https://github.com/danielmiessler/fabric/releases/tag/v1.4.267) (Jul 26, 2025) ‚Äî **Text-to-Speech**: Update Gemini Plugin to New SDK with TTS Support
- [v1.4.258](https://github.com/danielmiessler/fabric/releases/tag/v1.4.258) (Jul 17, 2025) ‚Äî **Onboarding Improved**: Add startup check to initialize config and .env file automatically
- [v1.4.257](https://github.com/danielmiessler/fabric/releases/tag/v1.4.257) (Jul 17, 2025) ‚Äî **OpenAI Routing Control**: Introduce CLI Flag to Disable OpenAI Responses API
- [v1.4.252](https://github.com/danielmiessler/fabric/releases/tag/v1.4.252) (Jul 16, 2025) ‚Äî **Hide Thinking Block**: Optional Hiding of Model Thinking Process with Configurable Tags
- [v1.4.246](https://github.com/danielmiessler/fabric/releases/tag/v1.4.246) (Jul 14, 2025) ‚Äî **Automatic ChangeLog Updates**: Add AI-powered changelog generation with high-performance Go tool and comprehensive caching
- [v1.4.245](https://github.com/danielmiessler/fabric/releases/tag/v1.4.245) (Jul 11, 2025) ‚Äî **Together AI**: Together AI Support with OpenAI Fallback Mechanism Added
- [v1.4.232](https://github.com/danielmiessler/fabric/releases/tag/v1.4.232) (Jul 6, 2025) ‚Äî **Add Custom**: Add Custom Patterns Directory Support
- [v1.4.230](https://github.com/danielmiessler/fabric/releases/tag/v1.4.230) (Jul 5, 2025) ‚Äî **Model Management**: Add advanced image generation parameters for OpenAI models with four new CLI flags
- [v1.4.227](https://github.com/danielmiessler/fabric/releases/tag/v1.4.227) (Jul 4, 2025) ‚Äî **Add Image**: Add Image Generation Support to Fabric
- [v1.4.226](https://github.com/danielmiessler/fabric/releases/tag/v1.4.226) (Jul 4, 2025) ‚Äî **Web Search**: OpenAI Plugin Now Supports Web Search Functionality
- [v1.4.225](https://github.com/danielmiessler/fabric/releases/tag/v1.4.225) (Jul 4, 2025) ‚Äî **Web Search**: Runtime Web Search Control via Command-Line `--search` Flag
- [v1.4.224](https://github.com/danielmiessler/fabric/releases/tag/v1.4.224) (Jul 1, 2025) ‚Äî **Add code_review**: Add code_review pattern and updates in Pattern_Descriptions
- [v1.4.222](https://github.com/danielmiessler/fabric/releases/tag/v1.4.222) (Jul 1, 2025) ‚Äî **OpenAI Plugin**: OpenAI Plugin Migrates to New Responses API
- [v1.4.218](https://github.com/danielmiessler/fabric/releases/tag/v1.4.218) (Jun 27, 2025) ‚Äî **Model Management**: Add Support for OpenAI Search and Research Model Variants
- [v1.4.217](https://github.com/danielmiessler/fabric/releases/tag/v1.4.217) (Jun 26, 2025) ‚Äî **New YouTube**: New YouTube Transcript Endpoint Added to REST API
- [v1.4.212](https://github.com/danielmiessler/fabric/releases/tag/v1.4.212) (Jun 23, 2025) ‚Äî **Add Langdock**: Add Langdock AI and enhance generic OpenAI compatible support
- [v1.4.211](https://github.com/danielmiessler/fabric/releases/tag/v1.4.211) (Jun 19, 2025) ‚Äî **REST API**: REST API and Web UI Now Support Dynamic Pattern Variables
- [v1.4.210](https://github.com/danielmiessler/fabric/releases/tag/v1.4.210) (Jun 18, 2025) ‚Äî **Add Citations**: Add Citation Support to Perplexity Response
- [v1.4.208](https://github.com/danielmiessler/fabric/releases/tag/v1.4.208) (Jun 17, 2025) ‚Äî **Add Perplexity**: Add Perplexity AI Provider with Token Limits Support
- [v1.4.203](https://github.com/danielmiessler/fabric/releases/tag/v1.4.203) (Jun 14, 2025) ‚Äî **Add Amazon Bedrock**: Add support for Amazon Bedrock

These features represent our commitment to making Fabric the most powerful and flexible AI augmentation framework available!

&lt;/details&gt;

## Intro videos

Keep in mind that many of these were recorded when Fabric was Python-based, so remember to use the current [install instructions](#installation) below.

- [Network Chuck](https://www.youtube.com/watch?v=UbDyjIIGaxQ)
- [David Bombal](https://www.youtube.com/watch?v=vF-MQmVxnCs)
- [My Own Intro to the Tool](https://www.youtube.com/watch?v=wPEyyigh10g)
- [More Fabric YouTube Videos](https://www.youtube.com/results?search_query=fabric+ai)

## Navigation

- [`fabric`](#fabric)
  - [What and why](#what-and-why)
  - [Updates](#updates)
    - [Recent Major Features](#recent-major-features)
  - [Intro videos](#intro-videos)
  - [Navigation](#navigation)
  - [Changelog](#changelog)
  - [Philosophy](#philosophy)
    - [Breaking problems into components](#breaking-problems-into-components)
    - [Too many prompts](#too-many-prompts)
  - [Installation](#installation)
    - [One-Line Install (Recommended)](#one-line-install-recommended)
    - [Manual Binary Downloads](#manual-binary-downloads)
    - [Using package managers](#using-package-managers)
      - [macOS (Homebrew)](#macos-homebrew)
      - [Arch Linux (AUR)](#arch-linux-aur)
      - [Windows](#windows)
    - [From Source](#from-source)
    - [Docker](#docker)
    - [Environment Variables](#environment-variables)
    - [Setup](#setup)
    - [Supported AI Providers](#supported-ai-providers)
    - [Per-Pattern Model Mapping](#per-pattern-model-mapping)
    - [Add aliases for all patterns](#add-aliases-for-all-patterns)
      - [Save your files in markdown using aliases](#save-your-files-in-markdown-using-aliases)
    - [Migration](#migration)
    - [Upgrading](#upgrading)
    - [Shell Completions](#shell-completions)
      - [Quick install (no clone required)](#quick-install-no-clone-required)
      - [Zsh Completion](#zsh-completion)
      - [Bash Completion](#bash-completion)
      - [Fish Completion](#fish-completion)
  - [Usage](#usage)
    - [Debug Levels](#debug-levels)
    - [Dry Run Mode](#dry-run-mode)
    - [Extensions](#extensions)
  - [REST API Server](#rest-api-server)
    - [Ollama Compatibility Mode](#ollama-compatibility-mode)
  - [Our approach to prompting](#our-approach-to-prompting)
  - [Examples](#examples)
  - [Just use the Patterns](#just-use-the-patterns)
    - [Prompt Strategies](#prompt-strategies)
      - [Available Strategies](#available-strategies)
  - [Custom Patterns](#custom-patterns)
    - [Setting Up Custom Patterns](#setting-up-custom-patterns)
    - [Using Custom Patterns](#using-custom-patterns)
    - [How It Works](#how-it-works)
  - [Helper Apps](#helper-apps)
    - [`to_pdf`](#to_pdf)
    - [`to_pdf` Installation](#to_pdf-installation)
    - [`code2context`](#code2context)
    - [`generate_changelog`](#generate_changelog)
  - [pbpaste](#pbpaste)
  - [Web Interface (Fabric Web App)](#web-interface-fabric-web-app)
  - [Meta](#meta)
    - [Primary contributors](#primary-contributors)
    - [Contributors](#contributors)
  - [üíú Support This Project](#-support-this-project)

&lt;br /&gt;

## Changelog

Fabric is evolving rapidly.

Stay current with the latest features by reviewing the [CHANGELOG](./CHANGELOG.md) for all recent changes.

## Philosophy

&gt; AI isn&#039;t a thing; it&#039;s a _magnifier_ of a thing. And that thing is **human creativity**.

We believe the purpose of technology is to help humans flourish, so when we talk about AI we start with the **human** problems we want to solve.

### Breaking problems into components

Our approach is to break problems into individual pieces (see below) and then apply AI to them one at a time. See below for some examples.

&lt;img width=&quot;2078&quot; alt=&quot;augmented_challenges&quot; src=&quot;https://github.com/danielmiessler/fabric/assets/50654/31997394-85a9-40c2-879b-b347e4701f06&quot;&gt;

### Too many prompts

Prompts are good for this, but the biggest challenge I faced in 2023‚Äî‚Äîwhich still exists today‚Äîis **the sheer number of AI prompts out there**. We all have prompts that are useful, but it&#039;s hard to discover new ones, know if they are good or not, _and manage different versions of the ones we like_.

One of `fabric`&#039;s primary features is helping people collect and integrate prompts, which we call _Patterns_, into various parts of their lives.

Fabric has Patterns for all sorts of life and work activities, including:

- Extracting the most interesting parts of YouTube videos and podcasts
- Writing an essay in your own voice with just an idea as an input
- Summarizing opaque academic papers
- Creating perfectly matched AI art prompts for a piece of writing
- Rating the quality of content to see if you want to read/watch the whole thing
- Getting summaries of long, boring content
- Explaining code to you
- Turning bad documentation into usable documentation
- Creating social media posts from any content input
- And a million more‚Ä¶

## Installation

### One-Line Install (Recommended)

**Unix/Linux/macOS:**

```bash
curl -fsSL https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.sh | bash
```

**Windows PowerShell:**

```powershell
iwr -useb https://raw.githubusercontent.com/danielmiessler/fabric/main/scripts/installer/install.ps1 | iex
```

&gt; See [scripts/installer/README.md](./scripts/installer/README.md) for custom installation options and troubleshooting.

### Manual Binary Downloads

The latest release binary archives and their expected SHA256 hashes can be found at &lt;https://github.com/danielmiessler/fabric/releases/latest&gt;

### Using package managers

**NOTE:** using Homebrew or the Arch Linux package managers makes `fabric` available as `fabric-ai`, so add
the following alias to your shell startup files to account for this:

```bash
alias fabric=&#039;fabric-ai&#039;
```

#### macOS (Homebrew)

`brew install fabric-ai`

#### Arch Linux (AUR)

`yay -S fabric-ai`

#### Windows

Use the official Microsoft supported `Winget` tool:

`winget install danielmiessler.Fabric`

### From Source

To install Fabric, [make sure Go is installed](https://go.dev/doc/install), and then run the following command.

```bash
# Install Fabric directly from the repo
go install github.com/danielmiessler/fabric/cmd/fabric@latest
```

### Docker

Run Fabric using pre-built Docker images:

```bash
# Use latest image from Docker Hub
docker run --rm -it kayvan/fabric:latest --version

# Use specific version from GHCR
docker run --rm -it ghcr.io/ksylvan/fabric:v1.4.305 --version

# Run setup (first time)
mkdir -p $HOME/.fabric-config
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --setup

# Use Fabric with your patterns
docker run --rm -it -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest -p summarize

# Run the REST API server (see REST API Server section)
docker run --rm -it -p 8080:8080 -v $HOME/.fabric-config:/root/.config/fabric kayvan/fabric:latest --serve
```

**Images available at:**

- Docker Hub: [kayvan/fabric](https://hub.docker.com/repository/docker/kayvan/fabric/general)
- GHCR: [ksylvan/fabric](https://github.com/ksylvan/fabric/pkgs/container/fabric)

See [scripts/docker/README.md](./scripts/docker/README.md) for building custom images and advanced configuration.

### Environment Variables

You may need to set some environment variables in your `~/.bashrc` on linux or `~/.zshr

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[filebrowser/filebrowser]]></title>
            <link>https://github.com/filebrowser/filebrowser</link>
            <guid>https://github.com/filebrowser/filebrowser</guid>
            <pubDate>Wed, 18 Feb 2026 00:08:12 GMT</pubDate>
            <description><![CDATA[üìÇ Web File Browser]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/filebrowser/filebrowser">filebrowser/filebrowser</a></h1>
            <p>üìÇ Web File Browser</p>
            <p>Language: Go</p>
            <p>Stars: 33,468</p>
            <p>Forks: 3,708</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/filebrowser/filebrowser/master/branding/banner.png&quot; width=&quot;550&quot;/&gt;
&lt;/p&gt;

[![Build](https://github.com/filebrowser/filebrowser/actions/workflows/ci.yaml/badge.svg)](https://github.com/filebrowser/filebrowser/actions/workflows/ci.yaml)
[![Go Report Card](https://goreportcard.com/badge/github.com/filebrowser/filebrowser/v2)](https://goreportcard.com/report/github.com/filebrowser/filebrowser/v2)
[![Version](https://img.shields.io/github/release/filebrowser/filebrowser.svg)](https://github.com/filebrowser/filebrowser/releases/latest)

File Browser provides a file managing interface within a specified directory and it can be used to upload, delete, preview and edit your files. It is a **create-your-own-cloud**-kind of software where you can just install it on your server, direct it to a path and access your files through a nice web interface.

## Documentation

Documentation on how to install, configure, and contribute to this project is hosted at [filebrowser.org](https://filebrowser.org).

## Project Status

This project is a finished product which fulfills its goal: be a single binary web File Browser which can be run by anyone anywhere. That means that File Browser is currently on **maintenance-only** mode. Therefore, please note the following:

- It can take a while until someone gets back to you. Please be patient.
- [Issues](https://github.com/filebrowser/filebrowser/issues) are meant to track bugs. Unrelated issues will be converted into [discussions](https://github.com/filebrowser/filebrowser/discussions).
- No new features will be implemented by maintainers. Pull requests for new features will be reviewed on a case by case basis.
- The priority is triaging issues, addressing security issues and reviewing pull requests meant to solve bugs.

## Contributing

Contributions are always welcome. To start contributing to this project, read our [guidelines](CONTRIBUTING.md) first.

## License

[Apache License 2.0](LICENSE) ¬© File Browser Contributors
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>