<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Thu, 26 Jun 2025 00:05:32 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[gitleaks/gitleaks]]></title>
            <link>https://github.com/gitleaks/gitleaks</link>
            <guid>https://github.com/gitleaks/gitleaks</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[Find secrets with Gitleaks üîë]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitleaks/gitleaks">gitleaks/gitleaks</a></h1>
            <p>Find secrets with Gitleaks üîë</p>
            <p>Language: Go</p>
            <p>Stars: 20,512</p>
            <p>Forks: 1,635</p>
            <p>Stars today: 40 stars today</p>
            <h2>README</h2><pre># Gitleaks

```
‚îå‚îÄ‚óã‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚îÇ‚ï≤  ‚îÇ
‚îÇ ‚îÇ ‚óã ‚îÇ
‚îÇ ‚óã ‚ñë ‚îÇ
‚îî‚îÄ‚ñë‚îÄ‚îÄ‚îÄ‚îò
```

[license]: ./LICENSE
[badge-license]: https://img.shields.io/github/license/gitleaks/gitleaks.svg
[go-docs-badge]: https://pkg.go.dev/badge/github.com/gitleaks/gitleaks/v8?status
[go-docs]: https://pkg.go.dev/github.com/zricethezav/gitleaks/v8
[badge-build]: https://github.com/gitleaks/gitleaks/actions/workflows/test.yml/badge.svg
[build]: https://github.com/gitleaks/gitleaks/actions/workflows/test.yml
[go-report-card-badge]: https://goreportcard.com/badge/github.com/gitleaks/gitleaks/v8
[go-report-card]: https://goreportcard.com/report/github.com/gitleaks/gitleaks/v8
[dockerhub]: https://hub.docker.com/r/zricethezav/gitleaks
[dockerhub-badge]: https://img.shields.io/docker/pulls/zricethezav/gitleaks.svg
[gitleaks-action]: https://github.com/gitleaks/gitleaks-action
[gitleaks-badge]: https://img.shields.io/badge/protected%20by-gitleaks-blue
[gitleaks-playground-badge]: https://img.shields.io/badge/gitleaks%20-playground-blue
[gitleaks-playground]: https://gitleaks.io/playground


[![GitHub Action Test][badge-build]][build]
[![Docker Hub][dockerhub-badge]][dockerhub]
[![Gitleaks Playground][gitleaks-playground-badge]][gitleaks-playground]
[![Gitleaks Action][gitleaks-badge]][gitleaks-action]
[![GoDoc][go-docs-badge]][go-docs]
[![GoReportCard][go-report-card-badge]][go-report-card]
[![License][badge-license]][license]


### Join our Discord! [![Discord](https://img.shields.io/discord/1102689410522284044.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/8Hzbrnkr7E)

Gitleaks is a tool for **detecting** secrets like passwords, API keys, and tokens in git repos, files, and whatever else you wanna throw at it via `stdin`. If you wanna learn more about how the detection engine works check out this blog: [Regex is (almost) all you need](https://lookingatcomputer.substack.com/p/regex-is-almost-all-you-need).


```
‚ûú  ~/code(master) gitleaks git -v

    ‚óã
    ‚îÇ‚ï≤
    ‚îÇ ‚óã
    ‚óã ‚ñë
    ‚ñë    gitleaks


Finding:     &quot;export BUNDLE_ENTERPRISE__CONTRIBSYS__COM=cafebabe:deadbeef&quot;,
Secret:      cafebabe:deadbeef
RuleID:      sidekiq-secret
Entropy:     2.609850
File:        cmd/generate/config/rules/sidekiq.go
Line:        23
Commit:      cd5226711335c68be1e720b318b7bc3135a30eb2
Author:      John
Email:       john@users.noreply.github.com
Date:        2022-08-03T12:31:40Z
Fingerprint: cd5226711335c68be1e720b318b7bc3135a30eb2:cmd/generate/config/rules/sidekiq.go:sidekiq-secret:23
```

## Getting Started

Gitleaks can be installed using Homebrew, Docker, or Go. Gitleaks is also available in binary form for many popular platforms and OS types on the [releases page](https://github.com/gitleaks/gitleaks/releases). In addition, Gitleaks can be implemented as a pre-commit hook directly in your repo or as a GitHub action using [Gitleaks-Action](https://github.com/gitleaks/gitleaks-action).

### Installing

```bash
# MacOS
brew install gitleaks

# Docker (DockerHub)
docker pull zricethezav/gitleaks:latest
docker run -v ${path_to_host_folder_to_scan}:/path zricethezav/gitleaks:latest [COMMAND] [OPTIONS] [SOURCE_PATH]

# Docker (ghcr.io)
docker pull ghcr.io/gitleaks/gitleaks:latest
docker run -v ${path_to_host_folder_to_scan}:/path ghcr.io/gitleaks/gitleaks:latest [COMMAND] [OPTIONS] [SOURCE_PATH]

# From Source (make sure `go` is installed)
git clone https://github.com/gitleaks/gitleaks.git
cd gitleaks
make build
```

### GitHub Action

Check out the official [Gitleaks GitHub Action](https://github.com/gitleaks/gitleaks-action)

```
name: gitleaks
on: [pull_request, push, workflow_dispatch]
jobs:
  scan:
    name: gitleaks
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
      - uses: gitleaks/gitleaks-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITLEAKS_LICENSE: ${{ secrets.GITLEAKS_LICENSE}} # Only required for Organizations, not personal accounts.
```

### Pre-Commit

1. Install pre-commit from https://pre-commit.com/#install
2. Create a `.pre-commit-config.yaml` file at the root of your repository with the following content:

   ```
   repos:
     - repo: https://github.com/gitleaks/gitleaks
       rev: v8.24.2
       hooks:
         - id: gitleaks
   ```

   for a [native execution of gitleaks](https://github.com/gitleaks/gitleaks/releases) or use the [`gitleaks-docker` pre-commit ID](https://github.com/gitleaks/gitleaks/blob/master/.pre-commit-hooks.yaml) for executing gitleaks using the [official Docker images](#docker)

3. Auto-update the config to the latest repos&#039; versions by executing `pre-commit autoupdate`
4. Install with `pre-commit install`
5. Now you&#039;re all set!

```
‚ûú git commit -m &quot;this commit contains a secret&quot;
Detect hardcoded secrets.................................................Failed
```

Note: to disable the gitleaks pre-commit hook you can prepend `SKIP=gitleaks` to the commit command
and it will skip running gitleaks

```
‚ûú SKIP=gitleaks git commit -m &quot;skip gitleaks check&quot;
Detect hardcoded secrets................................................Skipped
```

## Usage

```
Usage:
  gitleaks [command]

Available Commands:
  dir         scan directories or files for secrets
  git         scan git repositories for secrets
  help        Help about any command
  stdin       detect secrets from stdin
  version     display gitleaks version

Flags:
  -b, --baseline-path string          path to baseline with issues that can be ignored
  -c, --config string                 config file path
                                      order of precedence:
                                      1. --config/-c
                                      2. env var GITLEAKS_CONFIG
                                      3. env var GITLEAKS_CONFIG_TOML with the file content
                                      4. (target path)/.gitleaks.toml
                                      If none of the four options are used, then gitleaks will use the default config
      --diagnostics string            enable diagnostics (comma-separated list: cpu,mem,trace). cpu=CPU profiling, mem=memory profiling, trace=execution tracing
      --diagnostics-dir string        directory to store diagnostics output files (defaults to current directory)
      --enable-rule strings           only enable specific rules by id
      --exit-code int                 exit code when leaks have been encountered (default 1)
  -i, --gitleaks-ignore-path string   path to .gitleaksignore file or folder containing one (default &quot;.&quot;)
  -h, --help                          help for gitleaks
      --ignore-gitleaks-allow         ignore gitleaks:allow comments
  -l, --log-level string              log level (trace, debug, info, warn, error, fatal) (default &quot;info&quot;)
      --max-decode-depth int          allow recursive decoding up to this depth (default &quot;0&quot;, no decoding is done)
      --max-archive-depth int         allow scanning into nested archives up to this depth (default &quot;0&quot;, no archive traversal is done)
      --max-target-megabytes int      files larger than this will be skipped
      --no-banner                     suppress banner
      --no-color                      turn off color for verbose output
      --redact uint[=100]             redact secrets from logs and stdout. To redact only parts of the secret just apply a percent value from 0..100. For example --redact=20 (default 100%)
  -f, --report-format string          output format (json, csv, junit, sarif, template)
  -r, --report-path string            report file
      --report-template string        template file used to generate the report (implies --report-format=template)
  -v, --verbose                       show verbose output from scan
      --version                       version for gitleaks

Use &quot;gitleaks [command] --help&quot; for more information about a command.
```

### Commands

‚ö†Ô∏è v8.19.0 introduced a change that deprecated `detect` and `protect`. Those commands are still available but
are hidden in the `--help` menu. Take a look at this [gist](https://gist.github.com/zricethezav/b325bb93ebf41b9c0b0507acf12810d2) for easy command translations.
If you find v8.19.0 broke an existing command (`detect`/`protect`), please open an issue.

There are three scanning modes: `git`, `dir`, and `stdin`.

#### Git

The `git` command lets you scan local git repos. Under the hood, gitleaks uses the `git log -p` command to scan patches.
You can configure the behavior of `git log -p` with the `log-opts` option.
For example, if you wanted to run gitleaks on a range of commits you could use the following
command: `gitleaks git -v --log-opts=&quot;--all commitA..commitB&quot; path_to_repo`. See the [git log](https://git-scm.com/docs/git-log) documentation for more information.
If there is no target specified as a positional argument, then gitleaks will attempt to scan the current working directory as a git repo.

#### Dir

The `dir` (aliases include `files`, `directory`) command lets you scan directories and files. Example: `gitleaks dir -v path_to_directory_or_file`.
If there is no target specified as a positional argument, then gitleaks will scan the current working directory.

#### Stdin

You can also stream data to gitleaks with the `stdin` command. Example: `cat some_file | gitleaks -v stdin`

### Creating a baseline

When scanning large repositories or repositories with a long history, it can be convenient to use a baseline. When using a baseline,
gitleaks will ignore any old findings that are present in the baseline. A baseline can be any gitleaks report. To create a gitleaks report, run gitleaks with the `--report-path` parameter.

```
gitleaks git --report-path gitleaks-report.json # This will save the report in a file called gitleaks-report.json
```

Once as baseline is created it can be applied when running the detect command again:

```
gitleaks git --baseline-path gitleaks-report.json --report-path findings.json
```

After running the detect command with the --baseline-path parameter, report output (findings.json) will only contain new issues.

## Pre-Commit hook

You can run Gitleaks as a pre-commit hook by copying the example `pre-commit.py` script into
your `.git/hooks/` directory.

## Load Configuration

The order of precedence is:

1. `--config/-c` option:
      ```bash
      gitleaks git --config /home/dev/customgitleaks.toml .
      ```
2. Environment variable `GITLEAKS_CONFIG` with the file path:
      ```bash
      export GITLEAKS_CONFIG=&quot;/home/dev/customgitleaks.toml&quot;
      gitleaks git .
      ```
3. Environment variable `GITLEAKS_CONFIG_TOML` with the file content:
      ```bash
      export GITLEAKS_CONFIG_TOML=`cat customgitleaks.toml`
      gitleaks git .
      ```
4. A `.gitleaks.toml` file within the target path:
      ```bash
      gitleaks git .
      ```

If none of the four options are used, then gitleaks will use the default config.

## Configuration

Gitleaks offers a configuration format you can follow to write your own secret detection rules:

```toml
# Title for the gitleaks configuration file.
title = &quot;Custom Gitleaks configuration&quot;

# You have basically two options for your custom configuration:
#
# 1. define your own configuration, default rules do not apply
#
#    use e.g., the default configuration as starting point:
#    https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml
#
# 2. extend a configuration, the rules are overwritten or extended
#
#    When you extend a configuration the extended rules take precedence over the
#    default rules. I.e., if there are duplicate rules in both the extended
#    configuration and the default configuration the extended rules or
#    attributes of them will override the default rules.
#    Another thing to know with extending configurations is you can chain
#    together multiple configuration files to a depth of 2. Allowlist arrays are
#    appended and can contain duplicates.

# useDefault and path can NOT be used at the same time. Choose one.
[extend]
# useDefault will extend the default gitleaks config built in to the binary
# the latest version is located at:
# https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml
useDefault = true
# or you can provide a path to a configuration to extend from.
# The path is relative to where gitleaks was invoked,
# not the location of the base config.
# path = &quot;common_config.toml&quot;
# If there are any rules you don&#039;t want to inherit, they can be specified here.
disabledRules = [ &quot;generic-api-key&quot;]

# An array of tables that contain information that define instructions
# on how to detect secrets
[[rules]]
# Unique identifier for this rule
id = &quot;awesome-rule-1&quot;

# Short human-readable description of the rule.
description = &quot;awesome rule 1&quot;

# Golang regular expression used to detect secrets. Note Golang&#039;s regex engine
# does not support lookaheads.
regex = &#039;&#039;&#039;one-go-style-regex-for-this-rule&#039;&#039;&#039;

# Int used to extract secret from regex match and used as the group that will have
# its entropy checked if `entropy` is set.
secretGroup = 3

# Float representing the minimum shannon entropy a regex group must have to be considered a secret.
entropy = 3.5

# Golang regular expression used to match paths. This can be used as a standalone rule or it can be used
# in conjunction with a valid `regex` entry.
path = &#039;&#039;&#039;a-file-path-regex&#039;&#039;&#039;

# Keywords are used for pre-regex check filtering. Rules that contain
# keywords will perform a quick string compare check to make sure the
# keyword(s) are in the content being scanned. Ideally these values should
# either be part of the identiifer or unique strings specific to the rule&#039;s regex
# (introduced in v8.6.0)
keywords = [
  &quot;auth&quot;,
  &quot;password&quot;,
  &quot;token&quot;,
]

# Array of strings used for metadata and reporting purposes.
tags = [&quot;tag&quot;,&quot;another tag&quot;]

    # ‚ö†Ô∏è In v8.21.0 `[rules.allowlist]` was replaced with `[[rules.allowlists]]`.
    # This change was backwards-compatible: instances of `[rules.allowlist]` still  work.
    #
    # You can define multiple allowlists for a rule to reduce false positives.
    # A finding will be ignored if _ANY_ `[[rules.allowlists]]` matches.
    [[rules.allowlists]]
    description = &quot;ignore commit A&quot;
    # When multiple criteria are defined the default condition is &quot;OR&quot;.
    # e.g., this can match on |commits| OR |paths| OR |stopwords|.
    condition = &quot;OR&quot;
    commits = [ &quot;commit-A&quot;, &quot;commit-B&quot;]
    paths = [
      &#039;&#039;&#039;go\.mod&#039;&#039;&#039;,
      &#039;&#039;&#039;go\.sum&#039;&#039;&#039;
    ]
    # note: stopwords targets the extracted secret, not the entire regex match
    # like &#039;regexes&#039; does. (stopwords introduced in 8.8.0)
    stopwords = [
      &#039;&#039;&#039;client&#039;&#039;&#039;,
      &#039;&#039;&#039;endpoint&#039;&#039;&#039;,
    ]

    [[rules.allowlists]]
    # The &quot;AND&quot; condition can be used to make sure all criteria match.
    # e.g., this matches if |regexes| AND |paths| are satisfied.
    condition = &quot;AND&quot;
    # note: |regexes| defaults to check the _Secret_ in the finding.
    # Acceptable values for |regexTarget| are &quot;secret&quot; (default), &quot;match&quot;, and &quot;line&quot;.
    regexTarget = &quot;match&quot;
    regexes = [ &#039;&#039;&#039;(?i)parseur[il]&#039;&#039;&#039; ]
    paths = [ &#039;&#039;&#039;package-lock\.json&#039;&#039;&#039; ]

# You can extend a particular rule from the default config. e.g., gitlab-pat
# if you have defined a custom token prefix on your GitLab instance
[[rules]]
id = &quot;gitlab-pat&quot;
# all the other attributes from the default rule are inherited

    [[rules.allowlists]]
    regexTarget = &quot;line&quot;
    regexes = [ &#039;&#039;&#039;MY-glpat-&#039;&#039;&#039; ]


# ‚ö†Ô∏è In v8.25.0 `[allowlist]` was replaced with `[[allowlists]]`.
#
# Global allowlists have a higher order of precedence than rule-specific allowlists.
# If a commit listed in the `commits` field below is encountered then that commit will be skipped and no
# secrets will be detected for said commit. The same logic applies for regexes and paths.
[[allowlists]]
description = &quot;global allow list&quot;
commits = [ &quot;commit-A&quot;, &quot;commit-B&quot;, &quot;commit-C&quot;]
paths = [
  &#039;&#039;&#039;gitleaks\.toml&#039;&#039;&#039;,
  &#039;&#039;&#039;(.*?)(jpg|gif|doc)&#039;&#039;&#039;
]
# note: (global) regexTarget defaults to check the _Secret_ in the finding.
# Acceptable values for regexTarget are &quot;match&quot; and &quot;line&quot;
regexTarget = &quot;match&quot;
regexes = [
  &#039;&#039;&#039;219-09-9999&#039;&#039;&#039;,
  &#039;&#039;&#039;078-05-1120&#039;&#039;&#039;,
  &#039;&#039;&#039;(9[0-9]{2}|666)-\d{2}-\d{4}&#039;&#039;&#039;,
]
# note: stopwords targets the extracted secret, not the entire regex match
# like &#039;regexes&#039; does. (stopwords introduced in 8.8.0)
stopwords = [
  &#039;&#039;&#039;client&#039;&#039;&#039;,
  &#039;&#039;&#039;endpoint&#039;&#039;&#039;,
]

# ‚ö†Ô∏è In v8.25.0, `[[allowlists]]` have a new field called |targetRules|.
#
# Common allowlists can be defined once and assigned to multiple rules using |targetRules|.
# This will only run on the specified rules, not globally.
[[allowlists]]
targetRules = [&quot;awesome-rule-1&quot;, &quot;awesome-rule-2&quot;]
description = &quot;Our test assets trigger false-positives in a couple rules.&quot;
paths = [&#039;&#039;&#039;tests/expected/._\.json$&#039;&#039;&#039;]
```

Refer to the default [gitleaks config](https://github.com/gitleaks/gitleaks/blob/master/config/gitleaks.toml) for examples or follow the [contributing guidelines](https://github.com/gitleaks/gitleaks/blob/master/CONTRIBUTING.md) if you would like to contribute to the default configuration. Additionally, you can check out [this gitleaks blog post](https://blog.gitleaks.io/stop-leaking-secrets-configuration-2-3-aeed293b1fbf) which covers advanced configuration setups.

### Additional Configuration

#### gitleaks:allow

If you are knowingly committing a test secret that gitleaks will catch you can add a `gitleaks:allow` comment to that line which will instruct gitleaks
to ignore that secret. Ex:

```
class CustomClass:
    discord_client_secret = &#039;8dyfuiRyq=vVc3RRr_edRk-fK__JItpZ&#039;  #gitleaks:allow

```

#### .gitleaksignore

You can ignore specific findings by creating a `.gitleaksignore` file at the root of your repo. In release v8.10.0 Gitleaks added a `Fingerprint` value to the Gitleaks report. Each leak, or finding, has a Fingerprint that uniquely identifies a secret. Add this fingerprint to the `.gitleaksignore` file to ignore that specific secret. See Gitleaks&#039; [.gitleaksignore](https://github.com/gitleaks/gitleaks/blob/master/.gitleaksignore) for an example. Note: this feature is experimental and is subject to change in the future.

#### Decoding

Sometimes secrets are encoded in a way that can make them difficult to find
with just regex. Now you can tell gitleaks to automatically find and decode
encoded text. The flag `--max-decode-depth` enables this feature (the default
value &quot;0&quot; means the feature is disabled by default).

Recursive decoding is supported since decoded text can also contain encoded
text.  The flag `--max-decode-depth` sets the recursion limit. Recursion stops
when there are no new segments of encoded text to decode, so setting a really
high max depth doesn&#039;t mean it will make that many passes. It will only make as
many as it needs to decode the text. Overall, decoding only minimally increases
scan times.

The findings for encoded text differ from normal findings in the following
ways:

- The location points the bounds of the encoded text
  - If the rule matches outside the encoded text, the bounds are adjusted to
    include that as well
- The match and secret contain the decoded value
- Two tags are added `decoded:&lt;encoding&gt;` and `decode-depth:&lt;depth&gt;`

Currently supported encodings:

- **percent** - Any printable ASCII percent encoded values
- **hex** - Any printable ASCII hex encoded values &gt;= 32 characters
- **base64** - Any printable ASCII base64 encoded values &gt;= 16 characters

#### Archive Scanning

Sometimes secrets are packaged within archive files like zip files or tarballs,
making them difficult to discover. Now you can tell gitleaks to automatically
extract and scan the contents of archives. The flag `--max-archive-depth`
enables this feature for both `dir` and `git` scan types. The default value of
&quot;0&quot; means this feature is disabled by default.

Recursive scanning is supported since archives can also contain other archives.
The `--max-archive-depth` flag sets the

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[argoproj/argo-cd]]></title>
            <link>https://github.com/argoproj/argo-cd</link>
            <guid>https://github.com/argoproj/argo-cd</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Declarative Continuous Deployment for Kubernetes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/argoproj/argo-cd">argoproj/argo-cd</a></h1>
            <p>Declarative Continuous Deployment for Kubernetes</p>
            <p>Language: Go</p>
            <p>Stars: 19,920</p>
            <p>Forks: 6,114</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>**Releases:**
[![Release Version](https://img.shields.io/github/v/release/argoproj/argo-cd?label=argo-cd)](https://github.com/argoproj/argo-cd/releases/latest)
[![Artifact HUB](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/argo-cd)](https://artifacthub.io/packages/helm/argo/argo-cd)
[![SLSA 3](https://slsa.dev/images/gh-badge-level3.svg)](https://slsa.dev)

**Code:** 
[![Integration tests](https://github.com/argoproj/argo-cd/workflows/Integration%20tests/badge.svg?branch=master)](https://github.com/argoproj/argo-cd/actions?query=workflow%3A%22Integration+tests%22)
[![codecov](https://codecov.io/gh/argoproj/argo-cd/branch/master/graph/badge.svg)](https://codecov.io/gh/argoproj/argo-cd)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/4486/badge)](https://bestpractices.coreinfrastructure.org/projects/4486)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/argoproj/argo-cd/badge)](https://scorecard.dev/viewer/?uri=github.com/argoproj/argo-cd)

**Social:**
[![Twitter Follow](https://img.shields.io/twitter/follow/argoproj?style=social)](https://twitter.com/argoproj)
[![Slack](https://img.shields.io/badge/slack-argoproj-brightgreen.svg?logo=slack)](https://argoproj.github.io/community/join-slack)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-argoproj-blue.svg?logo=linkedin)](https://www.linkedin.com/company/argoproj/)

# Argo CD - Declarative Continuous Delivery for Kubernetes

## What is Argo CD?

Argo CD is a declarative, GitOps continuous delivery tool for Kubernetes.

![Argo CD UI](docs/assets/argocd-ui.gif)

[![Argo CD Demo](https://img.youtube.com/vi/0WAm0y2vLIo/0.jpg)](https://youtu.be/0WAm0y2vLIo)

## Why Argo CD?

1. Application definitions, configurations, and environments should be declarative and version controlled.
1. Application deployment and lifecycle management should be automated, auditable, and easy to understand.

## Who uses Argo CD?

[Official Argo CD user list](USERS.md)

## Documentation

To learn more about Argo CD [go to the complete documentation](https://argo-cd.readthedocs.io/).
Check live demo at https://cd.apps.argoproj.io/.

## Community

### Contribution, Discussion and Support

 You can reach the Argo CD community and developers via the following channels:

* Q &amp; A : [Github Discussions](https://github.com/argoproj/argo-cd/discussions)
* Chat : [The #argo-cd Slack channel](https://argoproj.github.io/community/join-slack)
* Contributors Office Hours: [Every Thursday](https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com) | [Agenda](https://docs.google.com/document/d/1xkoFkVviB70YBzSEa4bDnu-rUZ1sIFtwKKG1Uw8XsY8)
* User Community meeting: [First Wednesday of the month](https://calendar.google.com/calendar/u/0/embed?src=argoproj@gmail.com) | [Agenda](https://docs.google.com/document/d/1ttgw98MO45Dq7ZUHpIiOIEfbyeitKHNfMjbY5dLLMKQ)


Participation in the Argo CD project is governed by the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md)


### Blogs and Presentations

1. [Awesome-Argo: A Curated List of Awesome Projects and Resources Related to Argo](https://github.com/terrytangyuan/awesome-argo)
1. [Unveil the Secret Ingredients of Continuous Delivery at Enterprise Scale with Argo CD](https://akuity.io/blog/secret-ingredients-of-continuous-delivery-at-enterprise-scale-with-argocd/)
1. [GitOps Without Pipelines With ArgoCD Image Updater](https://youtu.be/avPUQin9kzU)
1. [Combining Argo CD (GitOps), Crossplane (Control Plane), And KubeVela (OAM)](https://youtu.be/eEcgn_gU3SM)
1. [How to Apply GitOps to Everything - Combining Argo CD and Crossplane](https://youtu.be/yrj4lmScKHQ)
1. [Couchbase - How To Run a Database Cluster in Kubernetes Using Argo CD](https://youtu.be/nkPoPaVzExY)
1. [Automation of Everything - How To Combine Argo Events, Workflows &amp; Pipelines, CD, and Rollouts](https://youtu.be/XNXJtxkUKeY)
1. [Environments Based On Pull Requests (PRs): Using Argo CD To Apply GitOps Principles On Previews](https://youtu.be/cpAaI8p4R60)
1. [Argo CD: Applying GitOps Principles To Manage Production Environment In Kubernetes](https://youtu.be/vpWQeoaiRM4)
1. [Creating Temporary Preview Environments Based On Pull Requests With Argo CD And Codefresh](https://codefresh.io/continuous-deployment/creating-temporary-preview-environments-based-pull-requests-argo-cd-codefresh/)
1. [Tutorial: Everything You Need To Become A GitOps Ninja](https://www.youtube.com/watch?v=r50tRQjisxw) 90m tutorial on GitOps and Argo CD.
1. [Comparison of Argo CD, Spinnaker, Jenkins X, and Tekton](https://www.inovex.de/blog/spinnaker-vs-argo-cd-vs-tekton-vs-jenkins-x/)
1. [Simplify and Automate Deployments Using GitOps with IBM Multicloud Manager 3.1.2](https://www.ibm.com/cloud/blog/simplify-and-automate-deployments-using-gitops-with-ibm-multicloud-manager-3-1-2)
1. [GitOps for Kubeflow using Argo CD](https://v0-6.kubeflow.org/docs/use-cases/gitops-for-kubeflow/)
1. [GitOps Toolsets on Kubernetes with CircleCI and Argo CD](https://www.digitalocean.com/community/tutorials/webinar-series-gitops-tool-sets-on-kubernetes-with-circleci-and-argo-cd)
1. [CI/CD in Light Speed with K8s and Argo CD](https://www.youtube.com/watch?v=OdzH82VpMwI&amp;feature=youtu.be)
1. [Machine Learning as Code](https://www.youtube.com/watch?v=VXrGp5er1ZE&amp;t=0s&amp;index=135&amp;list=PLj6h78yzYM2PZf9eA7bhWnIh_mK1vyOfU). Among other things, describes how Kubeflow uses Argo CD to implement GitOPs for ML
1. [Argo CD - GitOps Continuous Delivery for Kubernetes](https://www.youtube.com/watch?v=aWDIQMbp1cc&amp;feature=youtu.be&amp;t=1m4s)
1. [Introduction to Argo CD : Kubernetes DevOps CI/CD](https://www.youtube.com/watch?v=2WSJF7d8dUg&amp;feature=youtu.be)
1. [GitOps Deployment and Kubernetes - using Argo CD](https://medium.com/riskified-technology/gitops-deployment-and-kubernetes-f1ab289efa4b)
1. [Deploy Argo CD with Ingress and TLS in Three Steps: No YAML Yak Shaving Required](https://itnext.io/deploy-argo-cd-with-ingress-and-tls-in-three-steps-no-yaml-yak-shaving-required-bc536d401491)
1. [GitOps Continuous Delivery with Argo and Codefresh](https://codefresh.io/events/cncf-member-webinar-gitops-continuous-delivery-argo-codefresh/)
1. [Stay up to date with Argo CD and Renovate](https://mjpitz.com/blog/2020/12/03/renovate-your-gitops/)
1. [Setting up Argo CD with Helm](https://www.arthurkoziel.com/setting-up-argocd-with-helm/)
1. [Applied GitOps with Argo CD](https://thenewstack.io/applied-gitops-with-argocd/)
1. [Solving configuration drift using GitOps with Argo CD](https://www.cncf.io/blog/2020/12/17/solving-configuration-drift-using-gitops-with-argo-cd/)
1. [Decentralized GitOps over environments](https://blogs.sap.com/2021/05/06/decentralized-gitops-over-environments/)
1. [Getting Started with ArgoCD for GitOps Deployments](https://youtu.be/AvLuplh1skA)
1. [Using Argo CD &amp; Datree for Stable Kubernetes CI/CD Deployments](https://youtu.be/17894DTru2Y)
1. [How to create Argo CD Applications Automatically using ApplicationSet? &quot;Automation of GitOps&quot;](https://amralaayassen.medium.com/how-to-create-argocd-applications-automatically-using-applicationset-automation-of-the-gitops-59455eaf4f72)
1. [Progressive Delivery with Service Mesh ‚Äì Argo Rollouts with Istio](https://www.cncf.io/blog/2022/12/16/progressive-delivery-with-service-mesh-argo-rollouts-with-istio/)

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[livekit/livekit]]></title>
            <link>https://github.com/livekit/livekit</link>
            <guid>https://github.com/livekit/livekit</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[End-to-end stack for WebRTC. SFU media server and SDKs.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/livekit/livekit">livekit/livekit</a></h1>
            <p>End-to-end stack for WebRTC. SFU media server and SDKs.</p>
            <p>Language: Go</p>
            <p>Stars: 13,124</p>
            <p>Forks: 1,214</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>&lt;!--BEGIN_BANNER_IMAGE--&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;/.github/banner_dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;/.github/banner_light.png&quot;&gt;
  &lt;img style=&quot;width:100%;&quot; alt=&quot;The LiveKit icon, the name of the repository and some sample code in the background.&quot; src=&quot;https://raw.githubusercontent.com/livekit/livekit/main/.github/banner_light.png&quot;&gt;
&lt;/picture&gt;

&lt;!--END_BANNER_IMAGE--&gt;

# LiveKit: Real-time video, audio and data for developers

[LiveKit](https://livekit.io) is an open source project that provides scalable, multi-user conferencing based on WebRTC.
It&#039;s designed to provide everything you need to build real-time video audio data capabilities in your applications.

LiveKit&#039;s server is written in Go, using the awesome [Pion WebRTC](https://github.com/pion/webrtc) implementation.

[![GitHub stars](https://img.shields.io/github/stars/livekit/livekit?style=social&amp;label=Star&amp;maxAge=2592000)](https://github.com/livekit/livekit/stargazers/)
[![Slack community](https://img.shields.io/endpoint?url=https%3A%2F%2Flivekit.io%2Fbadges%2Fslack)](https://livekit.io/join-slack)
[![Twitter Follow](https://img.shields.io/twitter/follow/livekit)](https://twitter.com/livekit)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/livekit/livekit)
[![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/livekit/livekit)](https://github.com/livekit/livekit/releases/latest)
[![GitHub Workflow Status](https://img.shields.io/github/actions/workflow/status/livekit/livekit/buildtest.yaml?branch=master)](https://github.com/livekit/livekit/actions/workflows/buildtest.yaml)
[![License](https://img.shields.io/github/license/livekit/livekit)](https://github.com/livekit/livekit/blob/master/LICENSE)

## Features

-   Scalable, distributed WebRTC SFU (Selective Forwarding Unit)
-   Modern, full-featured client SDKs
-   Built for production, supports JWT authentication
-   Robust networking and connectivity, UDP/TCP/TURN
-   Easy to deploy: single binary, Docker or Kubernetes
-   Advanced features including:
    -   [speaker detection](https://docs.livekit.io/home/client/tracks/subscribe/#speaker-detection)
    -   [simulcast](https://docs.livekit.io/home/client/tracks/publish/#video-simulcast)
    -   [end-to-end optimizations](https://blog.livekit.io/livekit-one-dot-zero/)
    -   [selective subscription](https://docs.livekit.io/home/client/tracks/subscribe/#selective-subscription)
    -   [moderation APIs](https://docs.livekit.io/home/server/managing-participants/)
    -   end-to-end encryption
    -   SVC codecs (VP9, AV1)
    -   [webhooks](https://docs.livekit.io/home/server/webhooks/)
    -   [distributed and multi-region](https://docs.livekit.io/home/self-hosting/distributed/)

## Documentation &amp; Guides

https://docs.livekit.io

## Live Demos

-   [LiveKit Meet](https://meet.livekit.io) ([source](https://github.com/livekit-examples/meet))
-   [Spatial Audio](https://spatial-audio-demo.livekit.io/) ([source](https://github.com/livekit-examples/spatial-audio))
-   Livestreaming from OBS Studio ([source](https://github.com/livekit-examples/livestream))
-   [AI voice assistant using ChatGPT](https://livekit.io/kitt) ([source](https://github.com/livekit-examples/kitt))

## Ecosystem

-   [Agents](https://github.com/livekit/agents): build real-time multimodal AI applications with programmable backend participants
-   [Egress](https://github.com/livekit/egress): record or multi-stream rooms and export individual tracks
-   [Ingress](https://github.com/livekit/ingress): ingest streams from external sources like RTMP, WHIP, HLS, or OBS Studio

## SDKs &amp; Tools

### Client SDKs

Client SDKs enable your frontend to include interactive, multi-user experiences.

&lt;table&gt;
  &lt;tr&gt;
    &lt;th&gt;Language&lt;/th&gt;
    &lt;th&gt;Repo&lt;/th&gt;
    &lt;th&gt;
        &lt;a href=&quot;https://docs.livekit.io/home/client/events/#declarative-ui&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Declarative UI&lt;/a&gt;
    &lt;/th&gt;
    &lt;th&gt;Links&lt;/th&gt;
  &lt;/tr&gt;
  &lt;!-- BEGIN Template
  &lt;tr&gt;
    &lt;td&gt;Language&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  END --&gt;
  &lt;!-- JavaScript --&gt;
  &lt;tr&gt;
    &lt;td&gt;JavaScript (TypeScript)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-js&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/livekit-react&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;React&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-js/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;JS example&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-js/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;React example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Swift --&gt;
  &lt;tr&gt;
    &lt;td&gt;Swift (iOS / MacOS)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-swift&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-swift&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;Swift UI&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-swift/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-example-swift&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Kotlin --&gt;
  &lt;tr&gt;
    &lt;td&gt;Kotlin (Android)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-android&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;Compose&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-android/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android/tree/main/sample-app/src/main/java/io/livekit/android/sample&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-android/tree/main/sample-app-compose/src/main/java/io/livekit/android/composesample&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;Compose example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;!-- Flutter --&gt;
  &lt;tr&gt;
    &lt;td&gt;Flutter (all platforms)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-flutter&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;native&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://docs.livekit.io/client-sdk-flutter/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
      |
      &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter/tree/main/example&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;example&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Unity --&gt;
  &lt;tr&gt;
    &lt;td&gt;Unity WebGL&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-unity-web&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-unity-web&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://livekit.github.io/client-sdk-unity-web/&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;docs&lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- React Native --&gt;
  &lt;tr&gt;
    &lt;td&gt;React Native (beta)&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-react-native&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-react-native&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;native&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;!-- Rust --&gt;
  &lt;tr&gt;
    &lt;td&gt;Rust&lt;/td&gt;
    &lt;td&gt;
      &lt;a href=&quot;https://github.com/livekit/client-sdk-rust&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;client-sdk-rust&lt;/a&gt;
    &lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
    &lt;td&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

### Server SDKs

Server SDKs enable your backend to generate [access tokens](https://docs.livekit.io/home/get-started/authentication/),
call [server APIs](https://docs.livekit.io/reference/server/server-apis/), and
receive [webhooks](https://docs.livekit.io/home/server/webhooks/). In addition, the Go SDK includes client capabilities,
enabling you to build automations that behave like end-users.

| Language                | Repo                                                                                    | Docs                                                        |
| :---------------------- | :-------------------------------------------------------------------------------------- | :---------------------------------------------------------- |
| Go                      | [server-sdk-go](https://github.com/livekit/server-sdk-go)                               | [docs](https://pkg.go.dev/github.com/livekit/server-sdk-go) |
| JavaScript (TypeScript) | [server-sdk-js](https://github.com/livekit/server-sdk-js)                               | [docs](https://docs.livekit.io/server-sdk-js/)              |
| Ruby                    | [server-sdk-ruby](https://github.com/livekit/server-sdk-ruby)                           |                                                             |
| Java (Kotlin)           | [server-sdk-kotlin](https://github.com/livekit/server-sdk-kotlin)                       |                                                             |
| Python (community)      | [python-sdks](https://github.com/livekit/python-sdks)                                   |                                                             |
| PHP (community)         | [agence104/livekit-server-sdk-php](https://github.com/agence104/livekit-server-sdk-php) |                                                             |

### Tools

-   [CLI](https://github.com/livekit/livekit-cli) - command line interface &amp; load tester
-   [Docker image](https://hub.docker.com/r/livekit/livekit-server)
-   [Helm charts](https://github.com/livekit/livekit-helm)

## Install

&gt; [!TIP]
&gt; We recommend installing [LiveKit CLI](https://github.com/livekit/livekit-cli) along with the server. It lets you access
&gt; server APIs, create tokens, and generate test traffic.

The following will install LiveKit&#039;s media server:

### MacOS

```shell
brew install livekit
```

### Linux

```shell
curl -sSL https://get.livekit.io | bash
```

### Windows

Download the [latest release here](https://github.com/livekit/livekit/releases/latest)

## Getting Started

### Starting LiveKit

Start LiveKit in development mode by running `livekit-server --dev`. It&#039;ll use a placeholder API key/secret pair.

```
API Key: devkey
API Secret: secret
```

To customize your setup for production, refer to our [deployment docs](https://docs.livekit.io/deploy/)

### Creating access token

A user connecting to a LiveKit room requires an [access token](https://docs.livekit.io/home/get-started/authentication/#creating-a-token). Access
tokens (JWT) encode the user&#039;s identity and the room permissions they&#039;ve been granted. You can generate a token with our
CLI:

```shell
lk token create \
    --api-key devkey --api-secret secret \
    --join --room my-first-room --identity user1 \
    --valid-for 24h
```

### Test with example app

Head over to our [example app](https://example.livekit.io) and enter a generated token to connect to your LiveKit
server. This app is built with our [React SDK](https://github.com/livekit/livekit-react).

Once connected, your video and audio are now being published to your new LiveKit instance!

### Simulating a test publisher

```shell
lk room join \
    --url ws://localhost:7880 \
    --api-key devkey --api-secret secret \
    --identity bot-user1 \
    --publish-demo \
    my-first-room
```

This command publishes a looped demo video to a room. Due to how the video clip was encoded (keyframes every 3s),
there&#039;s a slight delay before the browser has sufficient data to begin rendering frames. This is an artifact of the
simulation.

## Deployment

### Use LiveKit Cloud

LiveKit Cloud is the fastest and most reliable way to run LiveKit. Every project gets free monthly bandwidth and
transcoding credits.

Sign up for [LiveKit Cloud](https://cloud.livekit.io/).

### Self-host

Read our [deployment docs](https://docs.livekit.io/deploy/) for more information.

## Building from source

Pre-requisites:

-   Go 1.23+ is installed
-   GOPATH/bin is in your PATH

Then run

```shell
git clone https://github.com/livekit/livekit
cd livekit
./bootstrap.sh
mage
```

## Contributing

We welcome your contributions toward improving LiveKit! Please join us
[on Slack](http://livekit.io/join-slack) to discuss your ideas and/or PRs.

## License

LiveKit server is licensed under Apache License v2.0.

&lt;!--BEGIN_REPO_NAV--&gt;
&lt;br/&gt;&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;LiveKit Ecosystem&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;LiveKit SDKs&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/client-sdk-js&quot;&gt;Browser&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-swift&quot;&gt;iOS/macOS/visionOS&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-android&quot;&gt;Android&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter&quot;&gt;Flutter&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-react-native&quot;&gt;React Native&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/rust-sdks&quot;&gt;Rust&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/node-sdks&quot;&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/python-sdks&quot;&gt;Python&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-unity&quot;&gt;Unity&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-unity-web&quot;&gt;Unity (WebGL)&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Server APIs&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/node-sdks&quot;&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/server-sdk-go&quot;&gt;Golang&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/server-sdk-ruby&quot;&gt;Ruby&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/server-sdk-kotlin&quot;&gt;Java/Kotlin&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/python-sdks&quot;&gt;Python&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/rust-sdks&quot;&gt;Rust&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/agence104/livekit-server-sdk-php&quot;&gt;PHP (community)&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/pabloFuente/livekit-server-sdk-dotnet&quot;&gt;.NET (community)&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;UI Components&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/components-js&quot;&gt;React&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/components-android&quot;&gt;Android Compose&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/components-swift&quot;&gt;SwiftUI&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Agents Frameworks&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/agents&quot;&gt;Python&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/agents-js&quot;&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/agent-playground&quot;&gt;Playground&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Services&lt;/td&gt;&lt;td&gt;&lt;b&gt;LiveKit server&lt;/b&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/egress&quot;&gt;Egress&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/ingress&quot;&gt;Ingress&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/sip&quot;&gt;SIP&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Resources&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://docs.livekit.io&quot;&gt;Docs&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit-examples&quot;&gt;Example apps&lt;/a&gt; ¬∑ &lt;a href=&quot;https://livekit.io/cloud&quot;&gt;Cloud&lt;/a&gt; ¬∑ &lt;a href=&quot;https://docs.livekit.io/home/self-hosting/deployment&quot;&gt;Self-hosting&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/livekit-cli&quot;&gt;CLI&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--END_REPO_NAV--&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[NVIDIA/nvidia-container-toolkit]]></title>
            <link>https://github.com/NVIDIA/nvidia-container-toolkit</link>
            <guid>https://github.com/NVIDIA/nvidia-container-toolkit</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[Build and run containers leveraging NVIDIA GPUs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NVIDIA/nvidia-container-toolkit">NVIDIA/nvidia-container-toolkit</a></h1>
            <p>Build and run containers leveraging NVIDIA GPUs</p>
            <p>Language: Go</p>
            <p>Stars: 3,354</p>
            <p>Forks: 359</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># NVIDIA Container Toolkit

[![GitHub license](https://img.shields.io/github/license/NVIDIA/nvidia-container-toolkit?style=flat-square)](https://raw.githubusercontent.com/NVIDIA/nvidia-container-toolkit/main/LICENSE)
[![Documentation](https://img.shields.io/badge/documentation-wiki-blue.svg?style=flat-square)](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html)
[![Package repository](https://img.shields.io/badge/packages-repository-b956e8.svg?style=flat-square)](https://nvidia.github.io/libnvidia-container)

![nvidia-container-stack](https://cloud.githubusercontent.com/assets/3028125/12213714/5b208976-b632-11e5-8406-38d379ec46aa.png)

## Introduction

The NVIDIA Container Toolkit allows users to build and run GPU accelerated containers. The toolkit includes a container runtime [library](https://github.com/NVIDIA/libnvidia-container) and utilities to automatically configure containers to leverage NVIDIA GPUs.

Product documentation including an architecture overview, platform support, and installation and usage guides can be found in the [documentation repository](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/overview.html).

## Getting Started

**Make sure you have installed the [NVIDIA driver](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#nvidia-drivers) for your Linux Distribution**
**Note that you do not need to install the CUDA Toolkit on the host system, but the NVIDIA driver needs to be installed**

For instructions on getting started with the NVIDIA Container Toolkit, refer to the [installation guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html#installation-guide).

## Usage

The [user guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/user-guide.html) provides information on the configuration and command line options available when running GPU containers with Docker.

## Issues and Contributing

[Checkout the Contributing document!](CONTRIBUTING.md)

* Please let us know by [filing a new issue](https://github.com/NVIDIA/nvidia-container-toolkit/issues/new)
* You can contribute by creating a [pull request](https://github.com/NVIDIA/nvidia-container-toolkit/compare) to our public GitHub repository
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kitops-ml/kitops]]></title>
            <link>https://github.com/kitops-ml/kitops</link>
            <guid>https://github.com/kitops-ml/kitops</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[An open source DevOps tool for packaging and versioning AI/ML models, datasets, code, and configuration into an OCI artifact.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kitops-ml/kitops">kitops-ml/kitops</a></h1>
            <p>An open source DevOps tool for packaging and versioning AI/ML models, datasets, code, and configuration into an OCI artifact.</p>
            <p>Language: Go</p>
            <p>Stars: 972</p>
            <p>Forks: 107</p>
            <p>Stars today: 38 stars today</p>
            <h2>README</h2><pre>
&lt;img width=&quot;1270&quot; alt=&quot;KitOps&quot; src=&quot;https://github.com/kitops-ml/kitops/assets/10517533/41295471-fe49-4011-adf6-a215f29890c2&quot; id=&quot;top&quot;&gt;


## Standards-based packaging and versioning system for AI/ML projects.

[![LICENSE](https://img.shields.io/badge/License-Apache%202.0-yellow.svg)](https://github.com/myscale/myscaledb/blob/main/LICENSE)
[![Language](https://img.shields.io/badge/Language-go-blue.svg)](https://go.dev/)
[![Discord](https://img.shields.io/discord/1098133460310294528?logo=Discord)](https://discord.gg/Tapeh8agYy)
[![Twitter](https://img.shields.io/twitter/url/http/shields.io.svg?style=social&amp;label=Twitter)](https://twitter.com/kit_ops)
[![Hits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%kitops-ml%2Fkitops&amp;count_bg=%2379C83D&amp;title_bg=%23555555&amp;icon=&amp;icon_color=%23E7E7E7&amp;title=hits&amp;edge_flat=false)](https://hits.seeyoufarm.com)

[![Official Website](&lt;https://img.shields.io/badge/-Visit%20the%20Official%20Website%20%E2%86%92-rgb(255,175,82)?style=for-the-badge&gt;)](https://kitops.org?utm_source=github&amp;utm_medium=kitops-readme)

[![Use Cases](&lt;https://img.shields.io/badge/-KitOps%20Quick%20Start%20%E2%86%92-rgb(122,140,225)?style=for-the-badge&gt;)](https://kitops.org/docs/get-started/?utm_source=github&amp;utm_medium=kitops-readme)

### What is KitOps?

KitOps is a packaging, versioning, and sharing system for AI/ML projects that uses open standards so it works with the AI/ML, development, and DevOps tools you are already using, and can be stored in your enterprise container registry. It&#039;s AI/ML platform engineering teams&#039; preferred solution for securely packaging and versioning assets.

KitOps creates a ModelKit for your AI/ML project which includes everything you need to reproduce it locally or deploy it into production. You can even **selectively unpack a ModelKit** so different team members can save time and storage space by only grabbing what they need for a task. Because ModelKits are immutable, signable, and live in your existing container registry they&#039;re easy for organizations to track, control, and audit.

ModelKits [simplify the handoffs between data scientists, application developers, and SREs](https://www.youtube.com/watch?v=j2qjHf2HzSQ) working with LLMs and other AI/ML models. Teams and enterprises use KitOps as a secure storage throughout the AI/ML project lifecycle.

Use KitOps to speed up and de-risk all types of AI/ML projects:
* Predictive models
* Large language models
* Computer vision models
* Multi-modal models
* Audio models
* etc...

### üá™üá∫ EU AI Act Compliance üîí
For our friends in the EU - ModelKits are the perfect way to create a library of model versions for EU AI Act compliance because they&#039;re tamper-proof, signable, and auditable.


### üòç What&#039;s New? ‚ú®

* üö¢ Create a **[runnable container from a ModelKit](https://tinyurl.com/5b76p5u3)** with one command! Read [KitOps deploy docs](https://kitops.org/docs/deploy/) for details.
* ü•Ç Get the most out of KitOps&#039; ModelKits by using them with the **[Jozu Hub](https://jozu.ml/)** repository. Or, continue using ModelKits with your existing OCI registry (even on-premises and air-gapped).
* üõ†Ô∏è Use KitOps with Dagger pipelines using our modules from the [Daggerverse](https://github.com/kitops-ml/daggerverse).
* ‚õëÔ∏è [KitOps works great with Red Hat](https://developers.redhat.com/articles/2024/09/16/enhance-llms-instructlab-kitops) InstructLab and Quay.io products.


### Features

* üéÅ **[Unified packaging](https://kitops.org/docs/modelkit/intro/):** A ModelKit package includes models, datasets, configurations, and code. Add as much or as little as your project needs.
* üè≠ **[Versioning](https://kitops.org/docs/cli/cli-reference/#kit-tag):** Each ModelKit is tagged so everyone knows which dataset and model work together.
* üîí **[Tamper-proofing](https://kitops.org/docs/modelkit/spec/):** Each ModelKit package includes an SHA digest for itself, and every artifact it holds.
* ü§© **[Selective-unpacking](https://kitops.org/docs/cli/cli-reference/#kit-unpack):** Unpack only what you need from a ModelKit with the `kit unpack --filter` command - just the model, just the dataset and code, or any other combination.
* ü§ñ **[Automation](https://github.com/marketplace/actions/setup-kit-cli):** Pack or unpack a ModelKit locally or as part of your CI/CD workflow for testing, integration, or deployment (e.g. [GitHub Actions](https://github.com/marketplace/actions/setup-kit-cli) or [Dagger](https://github.com/kitops-ml/daggerverse).
* üê≥ **[Deploy containers](https://kitops.org/docs/deploy/):** Generate a basic or custom docker container from any ModelKit.
* üö¢ **[Kubernetes-ready](https://kitops.org/docs/deploy/):** Generate a Kubernetes / KServe deployment config from any ModelKit.
* ü™õ **[LLM fine-tuning](https://dev.to/kitops/fine-tune-your-first-large-language-model-llm-with-lora-llamacpp-and-kitops-in-5-easy-steps-1g7f):** Use KitOps to fine-tune a large language model using LoRA.
* üéØ **[RAG pipelines](https://www.codeproject.com/Articles/5384392/A-Step-by-Step-Guide-to-Building-and-Distributing):** Create a RAG pipeline for tailoring an LLM with KitOps.
* üìù **[Artifact signing](https://kitops.org/docs/next-steps/):** ModelKits and their assets can be signed so you can be confident of their provenance.
* üåà **[Standards-based](https://kitops.org/docs/modelkit/compatibility/):** Store ModelKits in any OCI 1.1-compliant container or artifact registry.
* ü•ß **[Simple syntax](https://kitops.org/docs/kitfile/kf-overview/):** Kitfiles are easy to write and read, using a familiar YAML syntax.
* ü©∞ **[Flexible](https://kitops.org/docs/kitfile/format/#model):** Reference base models using `model parts`, or store key-value pairs (or any YAML-compatible JSON data) in your Kitfile - use it to keep features, hyperparameters, links to MLOps tool experiments, or validation output.
* üèÉ‚Äç‚ôÇÔ∏è‚Äç‚û°Ô∏è **[Run locally](./docs/src/docs/deploy.md#running-llms-locally):** Kit&#039;s Dev Mode lets you run an LLM locally, configure it, and prompt/chat with it instantly.
* ü§ó **Universal:** ModelKits can be used with any AI, ML, or LLM project - even multi-modal models.

### See KitOps in Action

There&#039;s a video of KitOps in action on the [KitOps site](https://kitops.org/).

## üöÄ Try KitOps in under 15 Minutes

1. [Install the CLI](https://kitops.org/docs/cli/installation/) for your platform.
2. Follow the [Getting Started](https://kitops.org/docs/get-started/) docs to learn to pack, unpack, and share a ModelKit.
3. Test drive one of our [ModelKit Quick Starts](https://jozu.ml/organization/jozu-quickstarts) that includes everything you need to run your model including a codebase, dataset, documentation, and of course the model.

For those who prefer to build from the source, follow [these steps](https://kitops.org/docs/cli/installation/#üõ†Ô∏è-install-from-source) to get the latest version from our repository.

## What is in the box?

**[ModelKit](https://kitops.org/docs/modelkit/intro/):** At the heart of KitOps is the ModelKit, an OCI-compliant packaging format for sharing all AI project artifacts: datasets, code, configurations, and models. By standardizing the way these components are packaged, versioned, and shared, ModelKits facilitate a more streamlined and collaborative development process that is compatible with any MLOps or DevOps tool.

**[Kitfile](https://kitops.org/docs/kitfile/kf-overview/):** A ModelKit is defined by a Kitfile - your AI/ML project&#039;s blueprint. It uses YAML to describe where to find each of the artifacts that will be packaged into the ModelKit. The Kitfile outlines what each part of the project is.

**[Kit CLI](https://kitops.org/docs/cli/cli-reference/):** The Kit CLI not only enables users to create, manage, run, and deploy ModelKits -- it lets you pull only the pieces you need. Just need the serialized model for deployment? Use `unpack --model`, or maybe you just want the training datasets? `unpack --datasets`.

## Need Help?

### Join KitOps community

For support, release updates, and general KitOps discussion, please join the [KitOps Discord](https://discord.gg/Tapeh8agYy). Follow [KitOps on X](https://twitter.com/Kit_Ops) for daily updates.

If you need help there are several ways to reach our community and [Maintainers](./MAINTAINERS.md) outlined in our [support doc](./SUPPORT.md)

### Reporting Issues and Suggesting Features

Your insights help KitOps evolve as an open standard for AI/ML. We *deeply value* the issues and feature requests we get from users in our community :sparkling_heart:. To contribute your thoughts,navigate to the **Issues** tab and hitting the **New Issue** green button. Our templates guide you in providing essential details to address your request effectively.

### Joining the KitOps Contributors

We ‚ù§Ô∏è our KitOps community and contributors. To learn more about the many ways you can contribute (you don&#039;t need to be a coder) and how to get started see our [Contributor&#039;s Guide](./CONTRIBUTING.md). Please read our [Governance](./GOVERNANCE.md) and our [Code of Conduct](./CODE-OF-CONDUCT.md) before contributing.

#### üì¢ KitOps Community Calls (bi-weekly)

**Wednesdays @ 13:30 ‚Äì 14:00**
**Time zone**: America/Toronto
**Video call link**: [Google Meet](https://meet.google.com/zfq-uprp-csd)
Or dial: (CA) +1 647-736-3184 PIN: 144 931 404#
More phone numbers: [Phone Numbers](https://tel.meet/zfq-uprp-csd?pin=1283456375953)

### A Community Built on Respect

At KitOps, inclusivity, empathy, and responsibility are at our core. Please read our [Code of Conduct](./CODE-OF-CONDUCT.md) to understand the values guiding our community.

## Roadmap

We [share our roadmap openly](./ROADMAP.md) so anyone in the community can provide feedback and ideas. Let us know what you&#039;d like to see by pinging us on Discord or creating an issue.

---

&lt;div align=&quot;center&quot; style=&quot;align-items: center;&quot;&gt;
        &lt;a href=&quot;#top&quot;&gt;
            &lt;img src=&quot;https://img.shields.io/badge/Back_to_Top-black?style=for-the-badge&amp;logo=github&amp;logoColor=white&quot; alt=&quot;Back to Top&quot;&gt;
        &lt;/a&gt;
&lt;/div&gt;



</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[awslabs/diagram-as-code]]></title>
            <link>https://github.com/awslabs/diagram-as-code</link>
            <guid>https://github.com/awslabs/diagram-as-code</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Diagram-as-code for AWS architecture.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/awslabs/diagram-as-code">awslabs/diagram-as-code</a></h1>
            <p>Diagram-as-code for AWS architecture.</p>
            <p>Language: Go</p>
            <p>Stars: 927</p>
            <p>Forks: 62</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre># Diagram-as-code
This command line interface (CLI) tool enables drawing infrastructure diagrams for Amazon Web Services through YAML code. It facilitates diagram-as-code without relying on image libraries.

The CLI tool promotes code reuse, testing, integration, and automating the diagramming process. It allows managing diagrams with Git by writing human-readable YAML.

Example templates are [here](examples).
Check out the [Introduction Guide](doc/introduction.md) as well for additional information.

&lt;img src=&quot;doc/static/introduction2.png&quot; width=&quot;800&quot;&gt;

![CLI Usage animation](doc/static/command_demo.gif)

## Getting started

### for Gopher (go 1.21 or higher)
```
$ go install github.com/awslabs/diagram-as-code/cmd/awsdac@latest
```

### for macOS user
```
$ brew install awsdac
```

## Usage

```
Usage:
  awsdac &lt;input filename&gt; [flags]

Flags:
  -c, --cfn-template               [beta] Create diagram from CloudFormation template
  -d, --dac-file                   [beta] Generate YAML file in dac (diagram-as-code) format from CloudFormation template
  -h, --help                       help for awsdac
  -o, --output string              Output file name (default &quot;output.png&quot;)
      --override-def-file string   For testing purpose, override DefinitionFiles to another url/local file
  -t, --template                   Processes the input file as a template according to text/template.
  -v, --verbose                    Enable verbose logging
      --version                    version for awsdac
```

### Example

```
$ awsdac examples/alb-ec2.yaml
```

```
$ awsdac privatelink.yaml -o custom-output.png
```

### [Beta] Create a diagram from CloudFormation template

`--cfn-template` option allows you to generate diagrams from CloudFormation templates, providing a visual representation of the resources.
The tool can generate diagrams even if the CloudFormation template is not in a perfect format, enabling you to visualize the resources before actually creating the CloudFormation stack. This means you don&#039;t have to strictly adhere to the CloudFormation syntax constraints.

&gt; **NOTE:** The functionality of generating diagrams from CloudFormation templates is currently in beta. It sometimes works correctly, but we are aware of several known issues where the tool might not produce accurate results. We are actively working on improving the tool and fixing these issues.

```
$ awsdac examples/vpc-subnet-ec2-cfn.yaml --cfn-template
```
(generated from [the example of VPC,Subnet,EC2](examples/vpc-subnet-ec2-cfn.yaml))

&lt;img src=&quot;examples/vpc-subnet-ec2-cfn.png&quot; width=&quot;500&quot;&gt;

There are some patterns where the tool may not work as expected. You can find a list of known issues and their status on the [issue tracker](https://github.com/awslabs/diagram-as-code/labels/cfn-template%20feature).
Your feedback and issue reports are appreciated, as they will help enhance the tool&#039;s performance and accuracy.

#### Use &quot;--dac-file&quot; option

```
$ awsdac examples/vpc-subnet-ec2-cfn.yaml --cfn-template --dac-file
```
CloudFormation templates have various dependencies, and there is no simple parent-child relationship between resources. As a result, generating the desired diagram directly from the existing CloudFormation template formats can be challenging at this stage.
We considered utilizing Metadata or comments within the CloudFormation templates to include additional information. However, this approach would make the templates excessively long, and CloudFormation templates are primarily intended for resource creation and management rather than diagram generation. Additionally, combining different lifecycle components into a single CloudFormation template could make it difficult to manage and maintain.

Therefore, instead of directly generating diagrams from CloudFormation templates, you can create a separate YAML file from CloudFormation template and customize this YAML file.
This customized YAML file can then be used as input for `awsdac` to generate the desired architecture diagrams. By decoupling the diagram generation process from the CloudFormation template structure, this approach offers greater flexibility and customization while leveraging the specialized strengths of `awsdac`.
```
CloudFormation template --[awsdac]--&gt; yaml file in awsdac format --[user custom]--&gt; your desired diagram :)
```

## Features
- **Compliant with AWS architecture guidelines**  
Easily generate diagrams that follow [AWS diagram guidelines](https://aws.amazon.com/architecture/icons).
- **Flexible**  
Automatically adjust the position and size of groups.
- **Lightweight &amp; CI/CD-friendly**  
Start quickly on a container; no dependency on headless browser or GUI.
- **Integrate with your Infrastructure as Code**  
Generate diagrams to align with your IaC code without managing diagrams manually.
- **As a drawing library**  
Use as Golang Library and integrate with other IaC tools, AI, or drawing GUI tools.
- **Extensible**  
Add definition files to create non-AWS diagrams as well.

## Resource types
See [doc/resource-types.md](doc/resource-types.md).

## Resource Link
See [doc/links.md](doc/links.md).

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## License

This project is licensed under the Apache-2.0 License.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[GoogleCloudPlatform/kubectl-ai]]></title>
            <link>https://github.com/GoogleCloudPlatform/kubectl-ai</link>
            <guid>https://github.com/GoogleCloudPlatform/kubectl-ai</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[AI powered Kubernetes Assistant]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GoogleCloudPlatform/kubectl-ai">GoogleCloudPlatform/kubectl-ai</a></h1>
            <p>AI powered Kubernetes Assistant</p>
            <p>Language: Go</p>
            <p>Stars: 6,269</p>
            <p>Forks: 541</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># kubectl-ai

[![Go Report Card](https://goreportcard.com/badge/github.com/GoogleCloudPlatform/kubectl-ai)](https://goreportcard.com/report/github.com/GoogleCloudPlatform/kubectl-ai)
![GitHub License](https://img.shields.io/github/license/GoogleCloudPlatform/kubectl-ai)
[![GitHub stars](https://img.shields.io/github/stars/GoogleCloudPlatform/kubectl-ai.svg)](https://github.com/GoogleCloudPlatform/kubectl-ai/stargazers)

`kubectl-ai` acts as an intelligent interface, translating user intent into
precise Kubernetes operations, making Kubernetes management more accessible and
efficient.

![kubectl-ai demo GIF using: kubectl-ai &quot;how&#039;s nginx app doing in my cluster&quot;](./.github/kubectl-ai.gif)

## Quick Start

First, ensure that kubectl is installed and configured.

### Installation

#### Quick Install (Linux &amp; MacOS only)

```shell
curl -sSL https://raw.githubusercontent.com/GoogleCloudPlatform/kubectl-ai/main/install.sh | bash
```

&lt;details&gt;

&lt;summary&gt;Other Installation Methods&lt;/summary&gt;

#### Manual Installation (Linux, MacOS and Windows)

1. Download the latest release from the [releases page](https://github.com/GoogleCloudPlatform/kubectl-ai/releases/latest) for your target machine.

2. Untar the release, make the binary executable and move it to a directory in your $PATH (as shown below).

```shell
tar -zxvf kubectl-ai_Darwin_arm64.tar.gz
chmod a+x kubectl-ai
sudo mv kubectl-ai /usr/local/bin/
```

#### Install with Krew (Linux/macOS/Windows)
First of all, you need to have krew insatlled, refer to [krew document](https://krew.sigs.k8s.io/docs/user-guide/setup/install/) for more details
Then you can install with krew
```shell
kubectl krew install ai
```
Now you can invoke `kubectl-ai` as a kubectl plugin like this: `kubectl ai`.

#### Install on NixOS
There are multiple ways to install `kubectl-ai` on NixOS. For a permantent installation add the following to your NixOS-Configuration:

```nix
  environment.systemPackages = with pkgs; [
    kubectl-ai
  ];
```
For a temporary installation, you can use the following command:

```
nix-shell -p kubectl-ai
```
&lt;/details&gt;

### Usage

`kubectl-ai` supports AI models from `gemini`, `vertexai`, `azopenai`, `openai`, `grok` and local LLM providers such as `ollama` and `llama.cpp`.

#### Using Gemini (Default)

Set your Gemini API key as an environment variable. If you don&#039;t have a key, get one from [Google AI Studio](https://aistudio.google.com).

```bash
export GEMINI_API_KEY=your_api_key_here
kubectl-ai

# Use different gemini model
kubectl-ai --model gemini-2.5-pro-exp-03-25

# Use 2.5 flash (faster) model
kubectl-ai --quiet --model gemini-2.5-flash-preview-04-17 &quot;check logs for nginx app in hello namespace&quot;
```

&lt;details&gt;

&lt;summary&gt;Use other AI models&lt;/summary&gt;

#### Using AI models running locally (ollama or llama.cpp)

You can use `kubectl-ai` with AI models running locally. `kubectl-ai` supports [ollama](https://ollama.com/) and [llama.cpp](https://github.com/ggml-org/llama.cpp) to use the AI models running locally.

Additionally, the [`modelserving`](modelserving/) directory provides tools and instructions for deploying your own `llama.cpp`-based LLM serving endpoints locally or on a Kubernetes cluster. This allows you to host models like Gemma directly in your environment.

An example of using Google&#039;s `gemma3` model with `ollama`:

```shell
# assuming ollama is already running and you have pulled one of the gemma models
# ollama pull gemma3:12b-it-qat

# if your ollama server is at remote, use OLLAMA_HOST variable to specify the host
# export OLLAMA_HOST=http://192.168.1.3:11434/

# enable-tool-use-shim because models require special prompting to enable tool calling
kubectl-ai --llm-provider ollama --model gemma3:12b-it-qat --enable-tool-use-shim

# you can use `models` command to discover the locally available models
&gt;&gt; models
```

#### Using Grok

You can use X.AI&#039;s Grok model by setting your X.AI API key:

```bash
export GROK_API_KEY=your_xai_api_key_here
kubectl-ai --llm-provider=grok --model=grok-3-beta
```

#### Using Azure OpenAI

You can also use Azure OpenAI deployment by setting your OpenAI API key and specifying the provider:

```bash
export AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
export AZURE_OPENAI_ENDPOINT=https://your_azure_openai_endpoint_here
kubectl-ai --llm-provider=azopenai --model=your_azure_openai_deployment_name_here
# or
az login
kubectl-ai --llm-provider=openai://your_azure_openai_endpoint_here --model=your_azure_openai_deployment_name_here
```

#### Using OpenAI

You can also use OpenAI models by setting your OpenAI API key and specifying the provider:

```bash
export OPENAI_API_KEY=your_openai_api_key_here
kubectl-ai --llm-provider=openai --model=gpt-4.1
```

#### Using OpenAI Compatible API
For example, you can use aliyun qwen-xxx models as follows
```bash
export OPENAI_API_KEY=your_openai_api_key_here
export OPENAI_ENDPOINT=https://dashscope.aliyuncs.com/compatible-mode/v1
kubectl-ai --llm-provider=openai --model=qwen-plus
```
&lt;/details&gt;

Run interactively:

```shell
kubectl-ai
```

The interactive mode allows you to have a chat with `kubectl-ai`, asking multiple questions in sequence while maintaining context from previous interactions. Simply type your queries and press Enter to receive responses. To exit the interactive shell, type `exit` or press Ctrl+C.

Or, run with a task as input:

```shell
kubectl-ai --quiet &quot;fetch logs for nginx app in hello namespace&quot;
```

Combine it with other unix commands:

```shell
kubectl-ai &lt; query.txt
# OR
echo &quot;list pods in the default namespace&quot; | kubectl-ai
```

You can even combine a positional argument with stdin input. The positional argument will be used as a prefix to the stdin content:

```shell
cat error.log | kubectl-ai &quot;explain the error&quot;
```

## Configuration

You can also configure `kubectl-ai` using a YAML configuration file at `~/.config/kubectl-ai/config.yaml`:

```shell
mkdir -p ~/.config/kubectl-ai/
cat &lt;&lt;EOF &gt; ~/.config/kubectl-ai/config.yaml
model: gemini-2.5-flash-preview-04-17
llm-provider: gemini
custom-tools-config: ~/.config/kubectl-ai/tools.yaml
EOF
```

Verify your configuration:

```shell
kubectl-ai --quiet model
```

&lt;details&gt;

&lt;summary&gt;More configuration Options&lt;/summary&gt;

Here&#039;s a complete configuration file with all available options and their default values:

```yaml
# LLM provider configuration
llm-provider: &quot;gemini&quot;               # Default LLM provider
model: &quot;gemini-2.5-pro-preview-06-05&quot; # Default model
skip-verify-ssl: false              # Skip SSL verification for LLM API calls

# Tool and permission settings
custom-tools-config: [&quot;~/.config/kubectl-ai/tools.yaml&quot;]  # Custom tools configuration paths
skip-permissions: false             # Skip confirmation for resource-modifying commands
enable-tool-use-shim: false        # Enable tool use shim for certain models

# MCP configuration
mcp-server: false                  # Run in MCP server mode
mcp-client: false                  # Enable MCP client mode

# Runtime settings
max-iterations: 20                 # Maximum iterations for the agent
quiet: false                       # Run in non-interactive mode
remove-workdir: false             # Remove temporary working directory after execution

# Kubernetes configuration
kubeconfig: &quot;~/.kube/config&quot;      # Path to kubeconfig file

# UI configuration
user-interface: &quot;terminal&quot;         # UI mode: &quot;terminal&quot; or &quot;html&quot;
ui-listen-address: &quot;localhost:8888&quot; # Address for HTML UI server

# Prompt configuration
prompt-template-file-path: &quot;&quot;      # Custom prompt template file
extra-prompt-paths: []            # Additional prompt template paths

# Debug and trace settings
trace-path: &quot;/tmp/kubectl-ai-trace.txt&quot; # Path to trace file
```

&lt;/details&gt;

All these settings can be configured through either:

1. Command line flags (e.g., `--model=gemini-2.5-pro`)
2. Configuration file (`~/.config/kubectl-ai/config.yaml`)
3. Environment variables (e.g., `GEMINI_API_KEY`)

Command line flags take precedence over configuration file settings.

## Tools

`kubectl-ai` leverages LLMs to suggest and execute Kubernetes operations using a set of powerful tools. It comes with built-in tools like `kubectl` and `bash`.

You can also extend its capabilities by defining your own custom tools. By default, `kubectl-ai` looks for your tool configurations in `~/.config/kubectl-ai/tools.yaml`.

To specify tools configuration files or directories containing tools configuration files, use:

```shell
kubectl-ai --custom-tools-config=YOUR_CONFIG
```

You can include multiple tools in a single configuration file, or a directory with multiple configuration files, each dedicated to a single or multiple tools.
Define your custom tools using the following schema:

```yaml
- name: tool_name
  description: &quot;A clear description that helps the LLM understand when to use this tool.&quot;
  command: &quot;your_command&quot; # For example: &#039;gcloud&#039; or &#039;gcloud container clusters&#039;
  command_desc: &quot;Detailed information for the LLM, including command syntax and usage examples.&quot;
```

A custom tool definition for `helm` could look like the following example:

```yaml
- name: helm
  description: &quot;Helm is the Kubernetes package manager and deployment tool. Use it to define, install, upgrade, and roll back applications packaged as Helm charts in a Kubernetes cluster.&quot;
  command: &quot;helm&quot;
  command_desc: |
    Helm command-line interface, with the following core subcommands and usage patterns:    
    - helm install &lt;release-name&gt; &lt;chart&gt; [flags]  
      Install a chart into the cluster.      
    - helm upgrade &lt;release-name&gt; &lt;chart&gt; [flags]  
      Upgrade an existing release to a new chart version or configuration.      
    - helm list [flags]  
      List all releases in one or all namespaces.      
    - helm uninstall &lt;release-name&gt; [flags]  
      Uninstall a release and clean up associated resources.  
    Use `helm --help` or `helm &lt;subcommand&gt; --help` to see full syntax, available flags, and examples for each command.
```

## MCP Client Mode

&gt; **Note:** MCP Client Mode is available in `kubectl-ai` version v0.0.12 and onwards.

`kubectl-ai` can connect to external [MCP](https://modelcontextprotocol.io/examples) Servers to access additional tools in addition to built-in tools.

### Quick Start

Enable MCP client mode:

```bash
kubectl-ai --mcp-client
```

### Configuration

Create or edit `~/.config/kubectl-ai/mcp.yaml` to customize MCP servers:

```yaml
servers:
  # Local MCP server (stdio-based)
  # sequential-thinking: Advanced reasoning and step-by-step analysis
  - name: sequential-thinking
    command: npx
    args:
      - -y
      - &quot;@modelcontextprotocol/server-sequential-thinking&quot;
  
  # Remote MCP server (HTTP-based)
  - name: cloudflare-documentation
    url: https://docs.mcp.cloudflare.com/mcp
    
  # Optional: Remote MCP server with authentication
  - name: custom-api
    url: https://api.example.com/mcp
    auth:
      type: &quot;bearer&quot;
      token: &quot;${MCP_TOKEN}&quot;
```

The system automatically:
- Converts parameter names (snake_case ‚Üí camelCase)
- Handles type conversion (strings ‚Üí numbers/booleans when appropriate)
- Provides fallback behavior for unknown servers

No additional setup required - just use the `--mcp-client` flag and the AI will have access to all configured MCP tools.

üìñ **For detailed configuration options, troubleshooting, and advanced features for MCP Client mode, see the [MCP Client Documentation](pkg/mcp/README.md).**

üìñ **For multi-server orchestration and security automation examples, see the [MCP Client Integration Guide](docs/mcp-client.md).**

## Extras

You can use the following special keywords for specific actions:

* `model`: Display the currently selected model.
* `models`: List all available models.
* `tools`: List all available tools.
* `version`: Display the `kubectl-ai` version.
* `reset`: Clear the conversational context.
* `clear`: Clear the terminal screen.
* `exit` or `quit`: Terminate the interactive shell (Ctrl+C also works).

### Invoking as kubectl plugin

You can also run `kubectl ai`. `kubectl` finds any executable file in your `PATH` whose name begins with `kubectl-` as a [plugin](https://kubernetes.io/docs/tasks/extend-kubectl/kubectl-plugins/).

## MCP Server Mode

`kubectl-ai` can also act as an MCP server that exposes `kubectl` as a tool for other MCP clients (like Claude, Cursor, or VS Code) to interact with your locally configured Kubernetes environment. 

Enable MCP server mode:

```bash
kubectl-ai --mcp-server
```

This allows AI agents and tools to execute kubectl commands in your environment through the Model Context Protocol.

üìñ **For details on configuring kubectl-ai as an MCP server for use with Claude, Cursor, VS Code, and other MCP clients, see the [MCP Server Documentation](./docs/mcp-server.md).**

## k8s-bench

kubectl-ai project includes [k8s-bench](./k8s-bench/README.md) - a benchmark to evaluate performance of different LLM models on kubernetes related tasks. Here is a summary from our last run:

| Model | Success | Fail |
|-------|---------|------|
| gemini-2.5-flash-preview-04-17 | 10 | 0 |
| gemini-2.5-pro-preview-03-25 | 10 | 0 |
| gemma-3-27b-it | 8 | 2 |
| **Total** | 28 | 2 |

See [full report](./k8s-bench.md) for more details.

## Start Contributing

We welcome contributions to `kubectl-ai` from the community. Take a look at our
[contribution guide](contributing.md) to get started.

---

*Note: This is not an officially supported Google product. This project is not
eligible for the [Google Open Source Software Vulnerability Rewards
Program](https://bughunters.google.com/open-source-security).*
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[juicedata/juicefs]]></title>
            <link>https://github.com/juicedata/juicefs</link>
            <guid>https://github.com/juicedata/juicefs</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[JuiceFS is a distributed POSIX file system built on top of Redis and S3.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/juicedata/juicefs">juicedata/juicefs</a></h1>
            <p>JuiceFS is a distributed POSIX file system built on top of Redis and S3.</p>
            <p>Language: Go</p>
            <p>Stars: 11,763</p>
            <p>Forks: 1,047</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/juicedata/juicefs&quot;&gt;&lt;img alt=&quot;JuiceFS Logo&quot; src=&quot;docs/en/images/juicefs-logo-new.svg&quot; width=&quot;50%&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/juicedata/juicefs/releases/latest&quot;&gt;&lt;img alt=&quot;Latest Stable Release&quot; src=&quot;https://img.shields.io/github/v/release/juicedata/juicefs&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/juicedata/juicefs/actions/workflows/unittests.yml&quot;&gt;&lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/unittests.yml?branch=main&amp;label=Unit%20Testing&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/juicedata/juicefs/actions/workflows/integrationtests.yml&quot;&gt;&lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/juicedata/juicefs/integrationtests.yml?branch=main&amp;label=Integration%20Testing&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://goreportcard.com/report/github.com/juicedata/juicefs&quot;&gt;&lt;img alt=&quot;Go Report&quot; src=&quot;https://goreportcard.com/badge/github.com/juicedata/juicefs&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://juicefs.com/docs/community/introduction&quot;&gt;&lt;img alt=&quot;English doc&quot; src=&quot;https://img.shields.io/badge/docs-Doc%20Center-brightgreen&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://go.juicefs.com/slack&quot;&gt;&lt;img alt=&quot;Join Slack&quot; src=&quot;https://badgen.net/badge/Slack/Join%20JuiceFS/0abd59?icon=slack&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

**JuiceFS** is a high-performance [POSIX](https://en.wikipedia.org/wiki/POSIX) file system released under Apache License 2.0, particularly designed for the cloud-native environment. The data, stored via JuiceFS, will be persisted in Object Storage _(e.g. Amazon S3)_, and the corresponding metadata can be persisted in various compatible database engines such as Redis, MySQL, and TiKV based on the scenarios and requirements.

With JuiceFS, massive cloud storage can be directly connected to big data, machine learning, artificial intelligence, and various application platforms in production environments. Without modifying code, the massive cloud storage can be used as efficiently as local storage.

üìñ **Document**: [Quick Start Guide](https://juicefs.com/docs/community/quick_start_guide)

## Highlighted Features

1. **Fully POSIX-compatible**: Use as a local file system, seamlessly docking with existing applications without breaking business workflow.
2. **Fully Hadoop-compatible**: JuiceFS&#039; [Hadoop Java SDK](https://juicefs.com/docs/community/hadoop_java_sdk) is compatible with Hadoop 2.x and Hadoop 3.x as well as a variety of components in the Hadoop ecosystems.
3. **S3-compatible**:  JuiceFS&#039; [S3 Gateway](https://juicefs.com/docs/community/s3_gateway) provides an S3-compatible interface.
4. **Cloud Native**: A [Kubernetes CSI Driver](https://juicefs.com/docs/community/how_to_use_on_kubernetes) is provided for easily using JuiceFS in Kubernetes.
5. **Shareable**: JuiceFS is a shared file storage that can be read and written by thousands of clients.
6. **Strong Consistency**: The confirmed modification will be immediately visible on all the servers mounted with the same file system.
7. **Outstanding Performance**: The latency can be as low as a few milliseconds, and the throughput can be expanded nearly unlimitedly _(depending on the size of the Object Storage)_. [Test results](https://juicefs.com/docs/community/benchmark)
8. **Data Encryption**: Supports data encryption in transit and at rest (please refer to [the guide](https://juicefs.com/docs/community/security/encrypt) for more information).
9. **Global File Locks**: JuiceFS supports both BSD locks (flock) and POSIX record locks (fcntl).
10. **Data Compression**: JuiceFS supports [LZ4](https://lz4.github.io/lz4) or [Zstandard](https://facebook.github.io/zstd) to compress all your data.

---

[Architecture](#architecture) | [Getting Started](#getting-started) | [Advanced Topics](#advanced-topics) | [POSIX Compatibility](#posix-compatibility) | [Performance Benchmark](#performance-benchmark) | [Supported Object Storage](#supported-object-storage) | [Who is using](#who-is-using) | [Roadmap](#roadmap) | [Reporting Issues](#reporting-issues) | [Contributing](#contributing) | [Community](#community) | [Usage Tracking](#usage-tracking) | [License](#license) | [Credits](#credits) | [FAQ](#faq)

---

## Architecture

JuiceFS consists of three parts:

1. **JuiceFS Client**: Coordinates Object Storage and metadata storage engine as well as implementation of file system interfaces such as POSIX, Hadoop, Kubernetes, and S3 gateway.
2. **Data Storage**: Stores data, with supports of a variety of data storage media, e.g., local disk, public or private cloud Object Storage, and HDFS.
3. **Metadata Engine**: Stores the corresponding metadata that contains information of file name, file size, permission group, creation and modification time and directory structure, etc., with supports of different metadata engines, e.g., Redis, MySQL, SQLite and TiKV.

![JuiceFS Architecture](docs/en/images/juicefs-arch-new.png)

JuiceFS can store the metadata of file system on different metadata engines, like Redis, which is a fast, open-source, in-memory key-value data storage, particularly suitable for storing metadata; meanwhile, all the data will be stored in Object Storage through JuiceFS client. [Learn more](https://juicefs.com/docs/community/architecture)

![data-structure-diagram](docs/en/images/data-structure-diagram.svg)

Each file stored in JuiceFS is split into **&quot;Chunk&quot;** s at a fixed size with the default upper limit of 64 MiB. Each Chunk is composed of one or more **&quot;Slice&quot;**(s), and the length of the slice varies depending on how the file is written. Each slice is composed of size-fixed **&quot;Block&quot;** s, which are 4 MiB by default. These blocks will be stored in Object Storage in the end; at the same time, the metadata information of the file and its Chunks, Slices, and Blocks will be stored in metadata engines via JuiceFS. [Learn more](https://juicefs.com/docs/community/architecture/#how-juicefs-store-files)

![How JuiceFS stores your files](docs/en/images/how-juicefs-stores-files.svg)

When using JuiceFS, files will eventually be split into Chunks, Slices and Blocks and stored in Object Storage. Therefore, the source files stored in JuiceFS cannot be found in the file browser of the Object Storage platform; instead, there are only a chunks directory and a bunch of digitally numbered directories and files in the bucket. Don&#039;t panic! This is just the secret of the high-performance operation of JuiceFS!

## Getting Started

Before you begin, make sure you have:

1. One supported metadata engine, see [How to Set Up Metadata Engine](https://juicefs.com/docs/community/databases_for_metadata)
2. One supported Object Storage for storing data blocks, see [Supported Object Storage](https://juicefs.com/docs/community/how_to_setup_object_storage)
3. [JuiceFS Client](https://juicefs.com/docs/community/installation) downloaded and installed

Please refer to [Quick Start Guide](https://juicefs.com/docs/community/quick_start_guide) to start using JuiceFS right away!

### Command Reference

Check out all the command line options in [command reference](https://juicefs.com/docs/community/command_reference).

### Containers

JuiceFS can be used as a persistent volume for Docker and Podman, please check [here](https://juicefs.com/docs/community/juicefs_on_docker) for details.

### Kubernetes

It is also very easy to use JuiceFS on Kubernetes. Please find more information [here](https://juicefs.com/docs/community/how_to_use_on_kubernetes).

### Hadoop Java SDK

If you wanna use JuiceFS in Hadoop, check [Hadoop Java SDK](https://juicefs.com/docs/community/hadoop_java_sdk).

## Advanced Topics

- [Redis Best Practices](https://juicefs.com/docs/community/redis_best_practices)
- [How to Setup Object Storage](https://juicefs.com/docs/community/how_to_setup_object_storage)
- [Cache](https://juicefs.com/docs/community/cache)
- [Fault Diagnosis and Analysis](https://juicefs.com/docs/community/fault_diagnosis_and_analysis)
- [FUSE Mount Options](https://juicefs.com/docs/community/fuse_mount_options)
- [Using JuiceFS on Windows](https://juicefs.com/docs/community/installation#windows)
- [S3 Gateway](https://juicefs.com/docs/community/s3_gateway)

Please refer to [JuiceFS Document Center](https://juicefs.com/docs/community/introduction) for more information.

## POSIX Compatibility

JuiceFS has passed all of the compatibility tests (8813 in total) in the latest [pjdfstest](https://github.com/pjd/pjdfstest) .

```
All tests successful.

Test Summary Report
-------------------
/root/soft/pjdfstest/tests/chown/00.t          (Wstat: 0 Tests: 1323 Failed: 0)
  TODO passed:   693, 697, 708-709, 714-715, 729, 733
Files=235, Tests=8813, 233 wallclock secs ( 2.77 usr  0.38 sys +  2.57 cusr  3.93 csys =  9.65 CPU)
Result: PASS
```

Aside from the POSIX features covered by pjdfstest, JuiceFS also provides:

- **Close-to-open consistency**. Once a file is written _and_ closed, it is guaranteed to view the written data in the following opens and reads from any client. Within the same mount point, all the written data can be read immediately.
- Rename and all other metadata operations are atomic, which are guaranteed by supported metadata engine transaction.
- Opened files remain accessible after unlink from same mount point.
- Mmap (tested with FSx).
- Fallocate with punch hole support.
- Extended attributes (xattr).
- BSD locks (flock).
- POSIX record locks (fcntl).

## Performance Benchmark

### Basic benchmark

JuiceFS provides a subcommand that can run a few basic benchmarks to help you understand how it works in your environment:

![JuiceFS Bench](docs/en/images/juicefs-bench.png)

### Throughput

A sequential read/write benchmark has also been performed on JuiceFS, [EFS](https://aws.amazon.com/efs) and [S3FS](https://github.com/s3fs-fuse/s3fs-fuse) by [fio](https://github.com/axboe/fio).

![Sequential Read Write Benchmark](docs/en/images/sequential-read-write-benchmark.svg)

Above result figure shows that JuiceFS can provide 10X more throughput than the other two (see [more details](https://juicefs.com/docs/community/fio)).

### Metadata IOPS

A simple mdtest benchmark has been performed on JuiceFS, [EFS](https://aws.amazon.com/efs) and [S3FS](https://github.com/s3fs-fuse/s3fs-fuse) by [mdtest](https://github.com/hpc/ior).

![Metadata Benchmark](docs/en/images/metadata-benchmark.svg)

The result shows that JuiceFS can provide significantly more metadata IOPS than the other two (see [more details](https://juicefs.com/docs/community/mdtest)).

### Analyze performance

See [Real-Time Performance Monitoring](https://juicefs.com/docs/community/fault_diagnosis_and_analysis#performance-monitor) if you encountered performance issues.

## Supported Object Storage

- Amazon S3 _(and other S3 compatible Object Storage services)_
- Google Cloud Storage
- Azure Blob Storage
- Alibaba Cloud Object Storage Service (OSS)
- Tencent Cloud Object Storage (COS)
- Qiniu Cloud Object Storage (Kodo)
- QingStor Object Storage
- Ceph RGW
- MinIO
- Local disk
- Redis
- ...

JuiceFS supports numerous Object Storage services. [Learn more](https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage).

## Who is using

JuiceFS is production ready and used by thousands of machines in production. A list of users has been assembled and documented [here](https://juicefs.com/docs/community/adopters). In addition JuiceFS has several collaborative projects that integrate with other open source projects, which we have documented [here](https://juicefs.com/docs/community/integrations). If you are also using JuiceFS, please feel free to let us know, and you are welcome to share your specific experience with everyone.

The storage format is stable, and will be supported by all future releases.

## Roadmap

- User and group quotas
- Snapshots
- Write once read many (WORM)

## Reporting Issues

We use [GitHub Issues](https://github.com/juicedata/juicefs/issues) to track community reported issues. You can also [contact](#community) the community for any questions.

## Contributing

Thank you for your contribution! Please refer to the [JuiceFS Contributing Guide](https://juicefs.com/docs/community/development/contributing_guide) for more information.

## Community

Welcome to join the [Discussions](https://github.com/juicedata/juicefs/discussions) and the [Slack channel](https://go.juicefs.com/slack) to connect with JuiceFS team members and other users.

## Usage Tracking

JuiceFS collects **anonymous** usage data by default to help us better understand how the community is using JuiceFS. Only core metrics (e.g. version number) will be reported, and user data and any other sensitive data will not be included. The related code can be viewed [here](pkg/usage/usage.go).

You could also disable reporting easily by command line option `--no-usage-report`:

```bash
juicefs mount --no-usage-report
```

## License

JuiceFS is open-sourced under Apache License 2.0, see [LICENSE](LICENSE).

## Credits

The design of JuiceFS was inspired by [Google File System](https://research.google/pubs/pub51), [HDFS](https://hadoop.apache.org) and [MooseFS](https://moosefs.com). Thanks for their great work!

## FAQ

### Why doesn&#039;t JuiceFS support XXX Object Storage?

JuiceFS supports many Object Storage services. Please check out [this list](https://juicefs.com/docs/community/how_to_setup_object_storage#supported-object-storage) first. If the Object Storage you want to use is compatible with S3, you could treat it as S3. Otherwise, try reporting any issue.

### Can I use Redis Cluster as metadata engine?

Yes. Since [v1.0.0 Beta3](https://github.com/juicedata/juicefs/releases/tag/v1.0.0-beta3) JuiceFS supports the use of [Redis Cluster](https://redis.io/docs/manual/scaling) as the metadata engine, but it should be noted that Redis Cluster requires that the keys of all operations in a transaction must be in the same hash slot, so a JuiceFS file system can only use one hash slot.

See [&quot;Redis Best Practices&quot;](https://juicefs.com/docs/community/redis_best_practices) for more information.

### What&#039;s the difference between JuiceFS and XXX?

See [&quot;Comparison with Others&quot;](https://juicefs.com/docs/community/comparison/juicefs_vs_alluxio) for more information.

For more FAQs, please see the [full list](https://juicefs.com/docs/community/faq).

## Stargazers over time

[![Star History Chart](https://api.star-history.com/svg?repos=juicedata/juicefs&amp;type=Date)](https://star-history.com/#juicedata/juicefs&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gohugoio/hugo]]></title>
            <link>https://github.com/gohugoio/hugo</link>
            <guid>https://github.com/gohugoio/hugo</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[The world‚Äôs fastest framework for building websites.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gohugoio/hugo">gohugoio/hugo</a></h1>
            <p>The world‚Äôs fastest framework for building websites.</p>
            <p>Language: Go</p>
            <p>Stars: 81,760</p>
            <p>Forks: 7,910</p>
            <p>Stars today: 40 stars today</p>
            <h2>README</h2><pre>[bep]: https://github.com/bep
[bugs]: https://github.com/gohugoio/hugo/issues?q=is%3Aopen+is%3Aissue+label%3ABug
[contributing]: CONTRIBUTING.md
[create a proposal]: https://github.com/gohugoio/hugo/issues/new?labels=Proposal%2C+NeedsTriage&amp;template=feature_request.md
[documentation repository]: https://github.com/gohugoio/hugoDocs
[documentation]: https://gohugo.io/documentation
[dragonfly bsd, freebsd, netbsd, and openbsd]: https://gohugo.io/installation/bsd
[features]: https://gohugo.io/about/features/
[forum]: https://discourse.gohugo.io
[friends]: https://github.com/gohugoio/hugo/graphs/contributors
[go]: https://go.dev/
[hugo modules]: https://gohugo.io/hugo-modules/
[installation]: https://gohugo.io/installation
[issue queue]: https://github.com/gohugoio/hugo/issues
[linux]: https://gohugo.io/installation/linux
[macos]: https://gohugo.io/installation/macos
[prebuilt binary]: https://github.com/gohugoio/hugo/releases/latest
[requesting help]: https://discourse.gohugo.io/t/requesting-help/9132
[spf13]: https://github.com/spf13
[static site generator]: https://en.wikipedia.org/wiki/Static_site_generator
[support]: https://discourse.gohugo.io
[themes]: https://themes.gohugo.io/
[website]: https://gohugo.io
[windows]: https://gohugo.io/installation/windows

&lt;a href=&quot;https://gohugo.io/&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/gohugoio/gohugoioTheme/master/static/images/hugo-logo-wide.svg?sanitize=true&quot; alt=&quot;Hugo&quot; width=&quot;565&quot;&gt;&lt;/a&gt;

A fast and flexible static site generator built with love by [bep], [spf13], and [friends] in [Go].

---

[![GoDoc](https://godoc.org/github.com/gohugoio/hugo?status.svg)](https://godoc.org/github.com/gohugoio/hugo)
[![Tests on Linux, MacOS and Windows](https://github.com/gohugoio/hugo/workflows/Test/badge.svg)](https://github.com/gohugoio/hugo/actions?query=workflow%3ATest)
[![Go Report Card](https://goreportcard.com/badge/github.com/gohugoio/hugo)](https://goreportcard.com/report/github.com/gohugoio/hugo)

[Website] | [Installation] | [Documentation] | [Support] | [Contributing] | &lt;a rel=&quot;me&quot; href=&quot;https://fosstodon.org/@gohugoio&quot;&gt;Mastodon&lt;/a&gt;

## Overview

Hugo is a [static site generator] written in [Go], optimized for speed and designed for flexibility. With its advanced templating system and fast asset pipelines, Hugo renders a complete site in seconds, often less.

Due to its flexible framework, multilingual support, and powerful taxonomy system, Hugo is widely used to create:

- Corporate, government, nonprofit, education, news, event, and project sites
- Documentation sites
- Image portfolios
- Landing pages
- Business, professional, and personal blogs
- Resumes and CVs

Use Hugo&#039;s embedded web server during development to instantly see changes to content, structure, behavior, and presentation. Then deploy the site to your host, or push changes to your Git provider for automated builds and deployment.

Hugo&#039;s fast asset pipelines include:

- Image processing &amp;ndash; Convert, resize, crop, rotate, adjust colors, apply filters, overlay text and images, and extract EXIF data
- JavaScript bundling &amp;ndash; Transpile TypeScript and JSX to JavaScript, bundle, tree shake, minify, create source maps, and perform SRI hashing.
- Sass processing &amp;ndash; Transpile Sass to CSS, bundle, tree shake, minify, create source maps, perform SRI hashing, and integrate with PostCSS
- Tailwind CSS processing &amp;ndash; Compile Tailwind CSS utility classes into standard CSS, bundle, tree shake, optimize, minify, perform SRI hashing, and integrate with PostCSS

And with [Hugo Modules], you can share content, assets, data, translations, themes, templates, and configuration with other projects via public or private Git repositories.

See the [features] section of the documentation for a comprehensive summary of Hugo&#039;s capabilities.

## Sponsors

&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;p float=&quot;left&quot;&gt;
  &lt;a href=&quot;https://www.linode.com/?utm_campaign=hugosponsor&amp;utm_medium=banner&amp;utm_source=hugogithub&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/gohugoio/hugoDocs/master/assets/images/sponsors/linode-logo_standard_light_medium.png&quot; width=&quot;200&quot; alt=&quot;Linode&quot;&gt;&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;
  &lt;a href=&quot;https://www.jetbrains.com/go/?utm_source=OSS&amp;utm_medium=referral&amp;utm_campaign=hugo&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/gohugoio/hugoDocs/master/assets/images/sponsors/goland.svg&quot; width=&quot;200&quot; alt=&quot;The complete IDE crafted for professional Go developers.&quot;&gt;&lt;/a&gt;
  &amp;nbsp;&amp;nbsp;&amp;nbsp;
  &lt;a href=&quot;https://pinme.eth.limo/?s=hugo&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/gohugoio/hugoDocs/master/assets/images/sponsors/logo-pinme.svg&quot; width=&quot;200&quot; alt=&quot;PinMe.&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## Editions

Hugo is available in three editions: standard, extended, and extended/deploy. While the standard edition provides core functionality, the extended and extended/deploy editions offer advanced features.

Feature|extended edition|extended/deploy edition
:--|:-:|:-:
Encode to the WebP format when [processing images]. You can decode WebP images with any edition.|:heavy_check_mark:|:heavy_check_mark:
[Transpile Sass to CSS] using the embedded LibSass transpiler. You can use the [Dart Sass] transpiler with any edition.|:heavy_check_mark:|:heavy_check_mark:
Deploy your site directly to a Google Cloud Storage bucket, an AWS S3 bucket, or an Azure Storage container. See&amp;nbsp;[details].|:x:|:heavy_check_mark:

[dart sass]: https://gohugo.io/functions/css/sass/#dart-sass
[processing images]: https://gohugo.io/content-management/image-processing/
[transpile sass to css]: https://gohugo.io/functions/css/sass/
[details]: https://gohugo.io/hosting-and-deployment/hugo-deploy/

Unless your specific deployment needs require the extended/deploy edition, we recommend the extended edition.

## Installation

Install Hugo from a [prebuilt binary], package manager, or package repository. Please see the installation instructions for your operating system:

- [macOS]
- [Linux]
- [Windows]
- [DragonFly BSD, FreeBSD, NetBSD, and OpenBSD]

## Build from source

Prerequisites to build Hugo from source:

- Standard edition: Go 1.23.0 or later
- Extended edition: Go 1.23.0 or later, and GCC
- Extended/deploy edition: Go 1.23.0 or later, and GCC

Build the standard edition:

```text
go install github.com/gohugoio/hugo@latest
```

Build the extended edition:

```text
CGO_ENABLED=1 go install -tags extended github.com/gohugoio/hugo@latest
```

Build the extended/deploy edition:

```text
CGO_ENABLED=1 go install -tags extended,withdeploy github.com/gohugoio/hugo@latest
```

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=gohugoio/hugo&amp;type=Timeline)](https://star-history.com/#gohugoio/hugo&amp;Timeline)

## Documentation

Hugo&#039;s [documentation] includes installation instructions, a quick start guide, conceptual explanations, reference information, and examples.

Please submit documentation issues and pull requests to the [documentation repository].

## Support

Please **do not use the issue queue** for questions or troubleshooting. Unless you are certain that your issue is a software defect, use the [forum].

Hugo‚Äôs [forum] is an active community of users and developers who answer questions, share knowledge, and provide examples. A quick search of over 20,000 topics will often answer your question. Please be sure to read about [requesting help] before asking your first question.

## Contributing

You can contribute to the Hugo project by:

- Answering questions on the [forum]
- Improving the [documentation]
- Monitoring the [issue queue]
- Creating or improving [themes]
- Squashing [bugs]

Please submit documentation issues and pull requests to the [documentation repository].

If you have an idea for an enhancement or new feature, create a new topic on the [forum] in the &quot;Feature&quot; category. This will help you to:

- Determine if the capability already exists
- Measure interest
- Refine the concept

If there is sufficient interest, [create a proposal]. Do not submit a pull request until the project lead accepts the proposal.

For a complete guide to contributing to Hugo, see the [Contribution Guide](CONTRIBUTING.md).

## Dependencies

Hugo stands on the shoulders of great open source libraries. Run `hugo env --logLevel info` to display a list of dependencies.

&lt;details&gt;
&lt;summary&gt;See current dependencies&lt;/summary&gt;

```text
github.com/BurntSushi/locker=&quot;v0.0.0-20171006230638-a6e239ea1c69&quot;
github.com/PuerkitoBio/goquery=&quot;v1.10.1&quot;
github.com/alecthomas/chroma/v2=&quot;v2.15.0&quot;
github.com/andybalholm/cascadia=&quot;v1.3.3&quot;
github.com/armon/go-radix=&quot;v1.0.1-0.20221118154546-54df44f2176c&quot;
github.com/bep/clocks=&quot;v0.5.0&quot;
github.com/bep/debounce=&quot;v1.2.0&quot;
github.com/bep/gitmap=&quot;v1.6.0&quot;
github.com/bep/goat=&quot;v0.5.0&quot;
github.com/bep/godartsass/v2=&quot;v2.3.2&quot;
github.com/bep/golibsass=&quot;v1.2.0&quot;
github.com/bep/gowebp=&quot;v0.3.0&quot;
github.com/bep/imagemeta=&quot;v0.8.4&quot;
github.com/bep/lazycache=&quot;v0.7.0&quot;
github.com/bep/logg=&quot;v0.4.0&quot;
github.com/bep/mclib=&quot;v1.20400.20402&quot;
github.com/bep/overlayfs=&quot;v0.9.2&quot;
github.com/bep/simplecobra=&quot;v0.5.0&quot;
github.com/bep/tmc=&quot;v0.5.1&quot;
github.com/cespare/xxhash/v2=&quot;v2.3.0&quot;
github.com/clbanning/mxj/v2=&quot;v2.7.0&quot;
github.com/cpuguy83/go-md2man/v2=&quot;v2.0.4&quot;
github.com/disintegration/gift=&quot;v1.2.1&quot;
github.com/dlclark/regexp2=&quot;v1.11.5&quot;
github.com/dop251/goja=&quot;v0.0.0-20250125213203-5ef83b82af17&quot;
github.com/evanw/esbuild=&quot;v0.24.2&quot;
github.com/fatih/color=&quot;v1.18.0&quot;
github.com/frankban/quicktest=&quot;v1.14.6&quot;
github.com/fsnotify/fsnotify=&quot;v1.8.0&quot;
github.com/getkin/kin-openapi=&quot;v0.129.0&quot;
github.com/ghodss/yaml=&quot;v1.0.0&quot;
github.com/go-openapi/jsonpointer=&quot;v0.21.0&quot;
github.com/go-openapi/swag=&quot;v0.23.0&quot;
github.com/go-sourcemap/sourcemap=&quot;v2.1.4+incompatible&quot;
github.com/gobuffalo/flect=&quot;v1.0.3&quot;
github.com/gobwas/glob=&quot;v0.2.3&quot;
github.com/gohugoio/go-i18n/v2=&quot;v2.1.3-0.20230805085216-e63c13218d0e&quot;
github.com/gohugoio/hashstructure=&quot;v0.5.0&quot;
github.com/gohugoio/httpcache=&quot;v0.7.0&quot;
github.com/gohugoio/hugo-goldmark-extensions/extras=&quot;v0.2.0&quot;
github.com/gohugoio/hugo-goldmark-extensions/passthrough=&quot;v0.3.0&quot;
github.com/gohugoio/locales=&quot;v0.14.0&quot;
github.com/gohugoio/localescompressed=&quot;v1.0.1&quot;
github.com/golang/freetype=&quot;v0.0.0-20170609003504-e2365dfdc4a0&quot;
github.com/google/go-cmp=&quot;v0.6.0&quot;
github.com/google/pprof=&quot;v0.0.0-20250208200701-d0013a598941&quot;
github.com/gorilla/websocket=&quot;v1.5.3&quot;
github.com/hairyhenderson/go-codeowners=&quot;v0.7.0&quot;
github.com/hashicorp/golang-lru/v2=&quot;v2.0.7&quot;
github.com/jdkato/prose=&quot;v1.2.1&quot;
github.com/josharian/intern=&quot;v1.0.0&quot;
github.com/kr/pretty=&quot;v0.3.1&quot;
github.com/kr/text=&quot;v0.2.0&quot;
github.com/kyokomi/emoji/v2=&quot;v2.2.13&quot;
github.com/lucasb-eyer/go-colorful=&quot;v1.2.0&quot;
github.com/mailru/easyjson=&quot;v0.7.7&quot;
github.com/makeworld-the-better-one/dither/v2=&quot;v2.4.0&quot;
github.com/marekm4/color-extractor=&quot;v1.2.1&quot;
github.com/mattn/go-colorable=&quot;v0.1.13&quot;
github.com/mattn/go-isatty=&quot;v0.0.20&quot;
github.com/mattn/go-runewidth=&quot;v0.0.9&quot;
github.com/mazznoer/csscolorparser=&quot;v0.1.5&quot;
github.com/mitchellh/mapstructure=&quot;v1.5.1-0.20231216201459-8508981c8b6c&quot;
github.com/mohae/deepcopy=&quot;v0.0.0-20170929034955-c48cc78d4826&quot;
github.com/muesli/smartcrop=&quot;v0.3.0&quot;
github.com/niklasfasching/go-org=&quot;v1.7.0&quot;
github.com/oasdiff/yaml3=&quot;v0.0.0-20241210130736-a94c01f36349&quot;
github.com/oasdiff/yaml=&quot;v0.0.0-20241210131133-6b86fb107d80&quot;
github.com/olekukonko/tablewriter=&quot;v0.0.5&quot;
github.com/pbnjay/memory=&quot;v0.0.0-20210728143218-7b4eea64cf58&quot;
github.com/pelletier/go-toml/v2=&quot;v2.2.3&quot;
github.com/perimeterx/marshmallow=&quot;v1.1.5&quot;
github.com/pkg/browser=&quot;v0.0.0-20240102092130-5ac0b6a4141c&quot;
github.com/pkg/errors=&quot;v0.9.1&quot;
github.com/rivo/uniseg=&quot;v0.4.7&quot;
github.com/rogpeppe/go-internal=&quot;v1.13.1&quot;
github.com/russross/blackfriday/v2=&quot;v2.1.0&quot;
github.com/sass/libsass=&quot;3.6.6&quot;
github.com/spf13/afero=&quot;v1.11.0&quot;
github.com/spf13/cast=&quot;v1.7.1&quot;
github.com/spf13/cobra=&quot;v1.8.1&quot;
github.com/spf13/fsync=&quot;v0.10.1&quot;
github.com/spf13/pflag=&quot;v1.0.6&quot;
github.com/tdewolff/minify/v2=&quot;v2.20.37&quot;
github.com/tdewolff/parse/v2=&quot;v2.7.15&quot;
github.com/tetratelabs/wazero=&quot;v1.8.2&quot;
github.com/webmproject/libwebp=&quot;v1.3.2&quot;
github.com/yuin/goldmark-emoji=&quot;v1.0.4&quot;
github.com/yuin/goldmark=&quot;v1.7.8&quot;
go.uber.org/automaxprocs=&quot;v1.5.3&quot;
golang.org/x/crypto=&quot;v0.33.0&quot;
golang.org/x/exp=&quot;v0.0.0-20250210185358-939b2ce775ac&quot;
golang.org/x/image=&quot;v0.24.0&quot;
golang.org/x/mod=&quot;v0.23.0&quot;
golang.org/x/net=&quot;v0.35.0&quot;
golang.org/x/sync=&quot;v0.11.0&quot;
golang.org/x/sys=&quot;v0.30.0&quot;
golang.org/x/text=&quot;v0.22.0&quot;
golang.org/x/tools=&quot;v0.30.0&quot;
golang.org/x/xerrors=&quot;v0.0.0-20240903120638-7835f813f4da&quot;
gonum.org/v1/plot=&quot;v0.15.0&quot;
google.golang.org/protobuf=&quot;v1.36.5&quot;
gopkg.in/yaml.v2=&quot;v2.4.0&quot;
gopkg.in/yaml.v3=&quot;v3.0.1&quot;
oss.terrastruct.com/d2=&quot;v0.6.9&quot;
oss.terrastruct.com/util-go=&quot;v0.0.0-20241005222610-44c011a04896&quot;
rsc.io/qr=&quot;v0.2.0&quot;
software.sslmate.com/src/go-pkcs12=&quot;v0.2.0&quot;
```
&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes-sigs/kustomize]]></title>
            <link>https://github.com/kubernetes-sigs/kustomize</link>
            <guid>https://github.com/kubernetes-sigs/kustomize</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[Customization of kubernetes YAML configurations]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes-sigs/kustomize">kubernetes-sigs/kustomize</a></h1>
            <p>Customization of kubernetes YAML configurations</p>
            <p>Language: Go</p>
            <p>Stars: 11,514</p>
            <p>Forks: 2,313</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># kustomize

`kustomize` lets you customize raw, template-free YAML
files for multiple purposes, leaving the original YAML
untouched and usable as is.

`kustomize` targets kubernetes; it understands and can
patch [kubernetes style] API objects.  It&#039;s like
[`make`], in that what it does is declared in a file,
and it&#039;s like [`sed`], in that it emits edited text.

This tool is sponsored by [sig-cli] ([KEP]).

 - [Installation instructions](https://kubectl.docs.kubernetes.io/installation/kustomize/)
 - [General documentation](https://kubectl.docs.kubernetes.io/references/kustomize/)
 - [Examples](examples)

[![Build Status](https://prow.k8s.io/badge.svg?jobs=kustomize-presubmit-master)](https://prow.k8s.io/job-history/kubernetes-jenkins/pr-logs/directory/kustomize-presubmit-master)
[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes-sigs/kustomize)](https://goreportcard.com/report/github.com/kubernetes-sigs/kustomize)

## kubectl integration

To find the kustomize version embedded in recent versions of kubectl, run `kubectl version`:

```sh
&gt; kubectl version --client
Client Version: v1.31.0
Kustomize Version: v5.4.2
```

The kustomize build flow at [v2.0.3] was added
to [kubectl v1.14][kubectl announcement].  The kustomize
flow in kubectl remained frozen at v2.0.3 until kubectl v1.21,
which [updated it to v4.0.5][kust-in-kubectl update]. It will
be updated on a regular basis going forward, and such updates
will be reflected in the Kubernetes release notes.

| Kubectl version | Kustomize version |
| --------------- | ----------------- |
| &lt; v1.14         | n/a               |
| v1.14-v1.20     | v2.0.3            |
| v1.21           | v4.0.5            |
| v1.22           | v4.2.0            |
| v1.23           | v4.4.1            |
| v1.24           | v4.5.4            |
| v1.25           | v4.5.7            |
| v1.26           | v4.5.7            |
| v1.27           | v5.0.1            |

[v2.0.3]: https://github.com/kubernetes-sigs/kustomize/releases/tag/v2.0.3
[#2506]: https://github.com/kubernetes-sigs/kustomize/issues/2506
[#1500]: https://github.com/kubernetes-sigs/kustomize/issues/1500
[kust-in-kubectl update]: https://github.com/kubernetes/kubernetes/blob/4d75a6238a6e330337526e0513e67d02b1940b63/CHANGELOG/CHANGELOG-1.21.md#kustomize-updates-in-kubectl

For examples and guides for using the kubectl integration please
see the [kubernetes documentation].

## Usage


### 1) Make a [kustomization] file

In some directory containing your YAML [resource]
files (deployments, services, configmaps, etc.), create a
[kustomization] file.

This file should declare those resources, and any
customization to apply to them, e.g. _add a common
label_.

```

base: kustomization + resources

kustomization.yaml                                      deployment.yaml                                                 service.yaml
+---------------------------------------------+         +-------------------------------------------------------+       +-----------------------------------+
| apiVersion: kustomize.config.k8s.io/v1beta1 |         | apiVersion: apps/v1                                   |       | apiVersion: v1                    |
| kind: Kustomization                         |         | kind: Deployment                                      |       | kind: Service                     |
| labels:                                     |         | metadata:                                             |       | metadata:                         |
| - includeSelectors: true                    |         |   name: myapp                                         |       |   name: myapp                     |
|   pairs:                                    |         | spec:                                                 |       | spec:                             |
|     app: myapp                              |         |   selector:                                           |       |   selector:                       |
| resources:                                  |         |     matchLabels:                                      |       |     app: myapp                    |
|   - deployment.yaml                         |         |       app: myapp                                      |       |   ports:                          |
|   - service.yaml                            |         |   template:                                           |       |     - port: 6060                  |
| configMapGenerator:                         |         |     metadata:                                         |       |       targetPort: 6060            |
|   - name: myapp-map                         |         |       labels:                                         |       +-----------------------------------+
|     literals:                               |         |         app: myapp                                    |
|       - KEY=value                           |         |     spec:                                             |
+---------------------------------------------+         |       containers:                                     |
                                                        |         - name: myapp                                 |
                                                        |           image: myapp                                |
                                                        |           resources:                                  |
                                                        |             limits:                                   |
                                                        |               memory: &quot;128Mi&quot;                         |
                                                        |               cpu: &quot;500m&quot;                             |
                                                        |           ports:                                      |
                                                        |             - containerPort: 6060                     |
                                                        +-------------------------------------------------------+

```

File structure:

&gt; ```
&gt; ~/someApp
&gt; ‚îú‚îÄ‚îÄ deployment.yaml
&gt; ‚îú‚îÄ‚îÄ kustomization.yaml
&gt; ‚îî‚îÄ‚îÄ service.yaml
&gt; ```

The resources in this directory could be a fork of
someone else&#039;s configuration.  If so, you can easily
rebase from the source material to capture
improvements, because you don&#039;t modify the resources
directly.

Generate customized YAML with:

```
kustomize build ~/someApp
```

The YAML can be directly [applied] to a cluster:

&gt; ```
&gt; kustomize build ~/someApp | kubectl apply -f -
&gt; ```


### 2) Create [variants] using [overlays]

Manage traditional [variants] of a configuration - like
_development_, _staging_ and _production_ - using
[overlays] that modify a common [base].

```

overlay: kustomization + patches

kustomization.yaml                                      replica_count.yaml                      cpu_count.yaml
+-----------------------------------------------+       +-------------------------------+       +------------------------------------------+
| apiVersion: kustomize.config.k8s.io/v1beta1   |       | apiVersion: apps/v1           |       | apiVersion: apps/v1                      |
| kind: Kustomization                           |       | kind: Deployment              |       | kind: Deployment                         |
| labels:                                       |       | metadata:                     |       | metadata:                                |
|  - includeSelectors: true                     |       |   name: myapp                 |       |   name: myapp                            |
|    pairs:                                     |       | spec:                         |       | spec:                                    |
|      variant: prod                            |       |   replicas: 80                |       |  template:                               |
| resources:                                    |       +-------------------------------+       |     spec:                                |
|   - ../../base                                |                                               |       containers:                        |
| patches:                                      |                                               |         - name: myapp                    |
|   - path: replica_count.yaml                  |                                               |           resources:                     |
|   - path: cpu_count.yaml                      |                                               |             limits:                      |
+-----------------------------------------------+                                               |               memory: &quot;128Mi&quot;            |
                                                                                                |               cpu: &quot;7000m&quot;               |
                                                                                                +------------------------------------------+
```


File structure:
&gt; ```
&gt; ~/someApp
&gt; ‚îú‚îÄ‚îÄ base
&gt; ‚îÇ   ‚îú‚îÄ‚îÄ deployment.yaml
&gt; ‚îÇ   ‚îú‚îÄ‚îÄ kustomization.yaml
&gt; ‚îÇ   ‚îî‚îÄ‚îÄ service.yaml
&gt; ‚îî‚îÄ‚îÄ overlays
&gt;     ‚îú‚îÄ‚îÄ development
&gt;     ‚îÇ   ‚îú‚îÄ‚îÄ cpu_count.yaml
&gt;     ‚îÇ   ‚îú‚îÄ‚îÄ kustomization.yaml
&gt;     ‚îÇ   ‚îî‚îÄ‚îÄ replica_count.yaml
&gt;     ‚îî‚îÄ‚îÄ production
&gt;         ‚îú‚îÄ‚îÄ cpu_count.yaml
&gt;         ‚îú‚îÄ‚îÄ kustomization.yaml
&gt;         ‚îî‚îÄ‚îÄ replica_count.yaml
&gt; ```

Take the work from step (1) above, move it into a
`someApp` subdirectory called `base`, then
place overlays in a sibling directory.

An overlay is just another kustomization, referring to
the base, and referring to patches to apply to that
base.

This arrangement makes it easy to manage your
configuration with `git`.  The base could have files
from an upstream repository managed by someone else.
The overlays could be in a repository you own.
Arranging the repo clones as siblings on disk avoids
the need for git submodules (though that works fine, if
you are a submodule fan).

Generate YAML with

```sh
kustomize build ~/someApp/overlays/production
```

The YAML can be directly [applied] to a cluster:

&gt; ```sh
&gt; kustomize build ~/someApp/overlays/production | kubectl apply -f -
&gt; ```

## Community

- [file a bug](https://kubectl.docs.kubernetes.io/contributing/kustomize/bugs/)
- [contribute a feature](https://kubectl.docs.kubernetes.io/contributing/kustomize/features/)
- [propose a larger enhancement](https://github.com/kubernetes-sigs/kustomize/tree/master/proposals)

### Code of conduct

Participation in the Kubernetes community
is governed by the [Kubernetes Code of Conduct].

[`make`]: https://www.gnu.org/software/make
[`sed`]: https://www.gnu.org/software/sed
[DAM]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#declarative-application-management
[KEP]: https://github.com/kubernetes/enhancements/blob/master/keps/sig-cli/2377-Kustomize/README.md
[Kubernetes Code of Conduct]: code-of-conduct.md
[applied]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#apply
[base]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#base
[declarative configuration]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#declarative-application-management
[kubectl announcement]: https://kubernetes.io/blog/2019/03/25/kubernetes-1-14-release-announcement
[kubernetes documentation]: https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/
[kubernetes style]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#kubernetes-style-object
[kustomization]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#kustomization
[overlay]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#overlay
[overlays]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#overlay
[release page]: https://github.com/kubernetes-sigs/kustomize/releases
[resource]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#resource
[resources]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#resource
[sig-cli]: https://github.com/kubernetes/community/blob/master/sig-cli/README.md
[variants]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#variant
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[containers/podman]]></title>
            <link>https://github.com/containers/podman</link>
            <guid>https://github.com/containers/podman</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Podman: A tool for managing OCI containers and pods.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/containers/podman">containers/podman</a></h1>
            <p>Podman: A tool for managing OCI containers and pods.</p>
            <p>Language: Go</p>
            <p>Stars: 27,347</p>
            <p>Forks: 2,686</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>![PODMAN logo](https://raw.githubusercontent.com/containers/common/main/logos/podman-logo-full-vert.png)

# Podman: A tool for managing OCI containers and pods
![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/containers/podman)
[![Go Report Card](https://goreportcard.com/badge/github.com/containers/libpod)](https://goreportcard.com/report/github.com/containers/libpod)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10499/badge)](https://www.bestpractices.dev/projects/10499)

&lt;br/&gt;

Podman (the POD MANager) is a tool for managing containers and images, volumes mounted into those containers, and pods made from groups of containers.
Podman runs containers on Linux, but can also be used on Mac and Windows systems using a Podman-managed virtual machine.
Podman is based on libpod, a library for container lifecycle management that is also contained in this repository. The libpod library provides APIs for managing containers, pods, container images, and volumes.

Podman releases a new major or minor release 4 times a year, during the second week of February, May, August, and November. Patch releases are more frequent and may occur at any time to get bugfixes out to users. All releases are PGP signed. Public keys of members of the team approved to make releases are located [here](https://github.com/containers/release-keys/tree/main/podman).

* Continuous Integration:
  * [![Build Status](https://api.cirrus-ci.com/github/containers/podman.svg)](https://cirrus-ci.com/github/containers/podman/main)
  * [GoDoc: ![GoDoc](https://godoc.org/github.com/containers/podman/libpod?status.svg)](https://godoc.org/github.com/containers/podman/libpod)
  * [Downloads](DOWNLOADS.md)

## Overview and scope

At a high level, the scope of Podman and libpod is the following:

* Support for multiple container image formats, including OCI and Docker images.
* Full management of those images, including pulling from various sources (including trust and verification), creating (built via Containerfile or Dockerfile or committed from a container), and pushing to registries and other storage backends.
* Full management of container lifecycle, including creation (both from an image and from an exploded root filesystem), running, checkpointing and restoring (via CRIU), and removal.
* Full management of container networking, using Netavark.
* Support for pods, groups of containers that share resources and are managed together.
* Support for running containers and pods without root or other elevated privileges.
* Resource isolation of containers and pods.
* Support for a Docker-compatible CLI interface, which can both run containers locally and on remote systems.
* No manager daemon, for improved security and lower resource utilization at idle.
* Support for a REST API providing both a Docker-compatible interface and an improved interface exposing advanced Podman functionality.
* Support for running on Windows and Mac via virtual machines run by `podman machine`.

## Roadmap

The future of Podman feature development can be found in its **[roadmap](ROADMAP.md)**.

## Communications

If you think you&#039;ve identified a security issue in the project, please *DO NOT* report the issue publicly via the GitHub issue tracker, mailing list, or IRC.
Instead, send an email with as many details as possible to `security@lists.podman.io`. This is a private mailing list for the core maintainers.

For general questions and discussion, please use Podman&#039;s
[channels](https://podman.io/community/#slack-irc-matrix-and-discord).

For discussions around issues/bugs and features, you can use the GitHub
[issues](https://github.com/containers/podman/issues)
and
[PRs](https://github.com/containers/podman/pulls)
tracking system.

There is also a [mailing list](https://lists.podman.io/archives/) at `lists.podman.io`.
You can subscribe by sending a message to `podman-join@lists.podman.io` with the subject `subscribe`.

## Rootless
Podman can be easily run as a normal user, without requiring a setuid binary.
When run without root, Podman containers use user namespaces to set root in the container to the user running Podman.
Rootless Podman runs locked-down containers with no privileges that the user running the container does not have.
Some of these restrictions can be lifted (via `--privileged`, for example), but rootless containers will never have more privileges than the user that launched them.
If you run Podman as your user and mount in `/etc/passwd` from the host, you still won&#039;t be able to change it, since your user doesn&#039;t have permission to do so.

Almost all normal Podman functionality is available, though there are some [shortcomings](https://github.com/containers/podman/blob/main/rootless.md).
Any recent Podman release should be able to run rootless without any additional configuration, though your operating system may require some additional configuration detailed in the [install guide](https://podman.io/getting-started/installation).

A little configuration by an administrator is required before rootless Podman can be used, the necessary setup is documented [here](https://github.com/containers/podman/blob/main/docs/tutorials/rootless_tutorial.md).

## Podman Desktop

[Podman Desktop](https://podman-desktop.io/) provides a local development environment for Podman and Kubernetes on Linux, Windows, and Mac machines.
It is a full-featured desktop UI frontend for Podman which uses the `podman machine` backend on non-Linux operating systems to run containers.
It supports full container lifecycle management (building, pulling, and pushing images, creating and managing containers, creating and managing pods, and working with Kubernetes YAML).
The project develops on [GitHub](https://github.com/containers/podman-desktop) and contributions are welcome.

## Out of scope

* Specialized signing and pushing of images to various storage backends.
  See [Skopeo](https://github.com/containers/skopeo/) for those tasks.
* Support for the Kubernetes CRI interface for container management.
  The [CRI-O](https://github.com/cri-o/cri-o) daemon specializes in that.

## OCI Projects Plans

Podman uses OCI projects and best of breed libraries for different aspects:
- Runtime: We use the [OCI runtime tools](https://github.com/opencontainers/runtime-tools) to generate OCI runtime configurations that can be used with any OCI-compliant runtime, like [crun](https://github.com/containers/crun/) and [runc](https://github.com/opencontainers/runc/).
- Images: Image management uses the [containers/image](https://github.com/containers/image) library.
- Storage: Container and image storage is managed by [containers/storage](https://github.com/containers/storage).
- Networking: Networking support through use of [Netavark](https://github.com/containers/netavark) and [Aardvark](https://github.com/containers/aardvark-dns).  Rootless networking is handled via [pasta](https://passt.top/passt) or [slirp4netns](https://github.com/rootless-containers/slirp4netns).
- Builds: Builds are supported via [Buildah](https://github.com/containers/buildah).
- Conmon: [Conmon](https://github.com/containers/conmon) is a tool for monitoring OCI runtimes, used by both Podman and CRI-O.
- Seccomp: A unified [Seccomp](https://github.com/containers/common/blob/main/pkg/seccomp/seccomp.json) policy for Podman, Buildah, and CRI-O.

## Podman Information for Developers

For blogs, release announcements and more, please checkout the [podman.io](https://podman.io) website!

**[Installation notes](install.md)**
Information on how to install Podman in your environment.

**[OCI Hooks Support](https://github.com/containers/common/blob/main/pkg/hooks/README.md)**
Information on how Podman configures [OCI Hooks][spec-hooks] to run when launching a container.

**[Podman API](https://docs.podman.io/en/latest/_static/api.html)**
Documentation on the Podman REST API.

**[Podman Commands](https://podman.readthedocs.io/en/latest/Commands.html)**
A list of the Podman commands with links to their man pages and in many cases videos
showing the commands in use.

**[Podman Container Images](https://github.com/containers/image_build/blob/main/podman/README.md)**
Information on the Podman Container Images found on [quay.io](https://quay.io/podman/stable).

**[Podman Troubleshooting Guide](troubleshooting.md)**
A list of common issues and solutions for Podman.

**[Podman Usage Transfer](transfer.md)**
Useful information for ops and dev transfer as it relates to infrastructure that utilizes Podman.  This page
includes tables showing Docker commands and their Podman equivalent commands.

**[Tutorials](docs/tutorials)**
Tutorials on using Podman.

**[Remote Client](https://github.com/containers/podman/blob/main/docs/tutorials/remote_client.md)**
A brief how-to on using the Podman remote client.

**[Basic Setup and Use of Podman in a Rootless environment](https://github.com/containers/podman/blob/main/docs/tutorials/rootless_tutorial.md)**
A tutorial showing the setup and configuration necessary to run Rootless Podman.

**[Release Notes](RELEASE_NOTES.md)**
Release notes for recent Podman versions.

**[Contributing](CONTRIBUTING.md)**
Information about contributing to this project.

[spec-hooks]: https://github.com/opencontainers/runtime-spec/blob/v1.0.2/config.md#posix-platform-hooks

## Buildah and Podman relationship

Buildah and Podman are two complementary open-source projects that are
available on most Linux platforms and both projects reside at
[GitHub.com](https://github.com) with Buildah
[here](https://github.com/containers/buildah) and Podman
[here](https://github.com/containers/podman).  Both, Buildah and Podman are
command line tools that work on Open Container Initiative (OCI) images and
containers.  The two projects differentiate in their specialization.

Buildah specializes in building OCI images.  Buildah&#039;s commands replicate all
of the commands that are found in a Dockerfile.  This allows building images
with and without Dockerfiles while not requiring any root privileges.
Buildah‚Äôs ultimate goal is to provide a lower-level coreutils interface to
build images.  The flexibility of building images without Dockerfiles allows
for the integration of other scripting languages into the build process.
Buildah follows a simple fork-exec model and does not run as a daemon
but it is based on a comprehensive API in golang, which can be vendored
into other tools.

Podman specializes in all of the commands and functions that help you to maintain and modify
OCI images, such as pulling and tagging.  It also allows you to create, run, and maintain those containers
created from those images.  For building container images via Dockerfiles, Podman uses Buildah&#039;s
golang API and can be installed independently from Buildah.

A major difference between Podman and Buildah is their concept of a container.  Podman
allows users to create &quot;traditional containers&quot; where the intent of these containers is
to be long lived.  While Buildah containers are really just created to allow content
to be added back to the container image.  An easy way to think of it is the
`buildah run` command emulates the RUN command in a Dockerfile while the `podman run`
command emulates the `docker run` command in functionality.  Because of this and their underlying
storage differences, you can not see Podman containers from within Buildah or vice versa.

In short, Buildah is an efficient way to create OCI images while Podman allows
you to manage and maintain those images and containers in a production environment using
familiar container cli commands.  For more details, see the
[Container Tools Guide](https://github.com/containers/buildah/tree/main/docs/containertools).

## Podman Hello
```
$ podman run quay.io/podman/hello
Trying to pull quay.io/podman/hello:latest...
Getting image source signatures
Copying blob a6b3126f3807 done
Copying config 25c667d086 done
Writing manifest to image destination
Storing signatures
!... Hello Podman World ...!

         .--&quot;--.
       / -     - \
      / (O)   (O) \
   ~~~| -=(,Y,)=- |
    .---. /`  \   |~~
 ~/  o  o \~~~~.----. ~~
  | =(X)= |~  / (O (O) \
   ~~~~~~~  ~| =(Y_)=-  |
  ~~~~    ~~~|   U      |~~

Project:   https://github.com/containers/podman
Website:   https://podman.io
Documents: https://docs.podman.io
Twitter:   @Podman_io
```
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kgateway-dev/kgateway]]></title>
            <link>https://github.com/kgateway-dev/kgateway</link>
            <guid>https://github.com/kgateway-dev/kgateway</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[The Cloud-Native API Gateway and AI Gateway]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kgateway-dev/kgateway">kgateway-dev/kgateway</a></h1>
            <p>The Cloud-Native API Gateway and AI Gateway</p>
            <p>Language: Go</p>
            <p>Stars: 4,589</p>
            <p>Forks: 523</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo-dark.svg&quot; alt=&quot;kgateway&quot; width=&quot;400&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg&quot; alt=&quot;kgateway&quot; width=&quot;400&quot;&gt;
    &lt;img alt=&quot;kgateway&quot; src=&quot;https://raw.githubusercontent.com/kgateway-dev/kgateway.dev/main/static/logo.svg&quot;&gt;
  &lt;/picture&gt;
  &lt;br/&gt;
  An Envoy-Powered, Kubernetes-Native API Gateway
&lt;/h1&gt;

## About kgateway

Kgateway is:

* **An ingress/edge router for Kubernetes**: Powered by [Envoy](https://www.envoyproxy.io) and programmed with the [Gateway API](https://gateway-api.sigs.k8s.io/), kgateway is a world-leading Cloud Native ingress.
* **An advanced API gateway**: Aggregate web APIs and apply key functions like authentication, authorization and rate limiting in one place
* **A better waypoint proxy for [ambient mesh](https://ambientmesh.io/)**: Use the same stack for east-west management as you do for north-south.
* **An AI gateway for securing LLM usage**: Protect applications, models, and data from inappropriate access or use, whether you&#039;re producing or consuming. Manage traffic to LLM providers, and enrich prompts at a system level.
* **An LLM Gateway utilizing the [Inference Extension](https://gateway-api-inference-extension.sigs.k8s.io/) project**: Intelligently route to AI inference workloads and LLMs in your Kubernetes environment.
* **A model context protocol (MCP) gateway**: Federate MCP tool servers into a single, scalable and secure endpoint.
* **A migration engine for hybrid apps**: Route to backends implemented as microservices, serverless functions or legacy apps. This can help you gradually migrate from legacy code to microservices and serverless, add new functionalities using cloud-native technologies while maintaining a legacy codebase or allow different teams in an organization to choose different architectures.

Kgateway is feature-rich, fast, and flexible. It excels in function-level routing, supports legacy apps, microservices and serverless, offers robust discovery capabilities, integrates seamlessly with open-source projects, and is designed to support hybrid applications with various technologies, architectures, protocols, and clouds.

The project was previously known as Gloo, and has been [production-ready since 2019](https://www.solo.io/blog/announcing-gloo-1-0-a-production-ready-envoy-based-api-gateway). Please see [the migration plan](https://github.com/kgateway-dev/kgateway/issues/10363) for more information and the current status of the change from Gloo to kgateway.

## Get involved
- [Join us on our Slack channel](https://kgateway.dev/slack/)
- [Check out the docs](https://kgateway.dev/docs)
- [Read the kgateway blog](https://kgateway.dev/blog/)
- [Learn more about the community](https://github.com/kgateway-dev/community)
- [Watch a video on our YouTube channel](https://www.youtube.com/@kgateway-dev)
- Follow us on [X](https://x.com/kgatewaydev), [Bluesky](https://bsky.app/profile/kgateway.dev), [Mastodon](https://mastodon.social/@kgateway) or [LinkedIn](https://www.linkedin.com/company/kgateway/)

## Contributing to kgateway
Please refer to the [contributing guide](https://github.com/kgateway-dev/community/blob/main/CONTRIBUTING.md) in the community repo.

The [devel](devel) folder should be the starting point for understanding the code, and contributing to the product.

## Thanks
Kgateway would not be possible without the valuable open source work of projects in the community. We would like to extend a special thank-you to [Envoy](https://www.envoyproxy.io), upon whose shoulders we stand.

## Security
*Reporting security issues* : We take kgateway&#039;s security very seriously. If you&#039;ve found a security issue or a potential security issue in kgateway, please DO NOT file a public GitHub issue. Instead follow [the directions laid out in the kgateway/community repository](https://github.com/kgateway-dev/community/blob/main/CVE.md).

---

&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/cncf/artwork/main/other/cncf-sandbox/horizontal/color/cncf-sandbox-horizontal-color.svg&quot; width=&quot;300&quot; alt=&quot;Cloud Native Computing Foundation logo&quot;/&gt;
    &lt;p&gt;kgateway is a &lt;a href=&quot;https://cncf.io&quot;&gt;Cloud Native Computing Foundation&lt;/a&gt; sandbox project.&lt;/p&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[oras-project/oras]]></title>
            <link>https://github.com/oras-project/oras</link>
            <guid>https://github.com/oras-project/oras</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[OCI registry client - managing content like artifacts, images, packages]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oras-project/oras">oras-project/oras</a></h1>
            <p>OCI registry client - managing content like artifacts, images, packages</p>
            <p>Language: Go</p>
            <p>Stars: 1,784</p>
            <p>Forks: 197</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># ORAS CLI

[![Build Status](https://github.com/oras-project/oras/actions/workflows/build.yml/badge.svg?event=push)](https://github.com/oras-project/oras/actions/workflows/build.yml?query=workflow%3Abuild+event%3Apush)
[![codecov](https://codecov.io/gh/oras-project/oras/branch/main/graph/badge.svg)](https://codecov.io/gh/oras-project/oras)
[![Go Report Card](https://goreportcard.com/badge/oras.land/oras)](https://goreportcard.com/report/oras.land/oras)


&lt;p style=&quot;text-align: left;&quot;&gt;
&lt;a href=&quot;https://oras.land/&quot;&gt;&lt;img src=&quot;https://oras.land/img/oras.svg&quot; alt=&quot;banner&quot; width=&quot;100px&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## Docs

Documentation for the ORAS CLI is located on
the project website: [oras.land/cli](https://oras.land/docs/category/oras-commands)

## Development Environment Setup

Refer to the [development guide](https://oras.land/community/developer_guide) to get started [contributing to ORAS](https://oras.land/community/contributing_guide).

## Code of Conduct

This project has adopted the [CNCF Code of Conduct](https://github.com/cncf/foundation/blob/master/code-of-conduct.md). See [CODE_OF_CONDUCT.md](CODE_OF_CONDUCT.md) for further details.

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aquasecurity/trivy]]></title>
            <link>https://github.com/aquasecurity/trivy</link>
            <guid>https://github.com/aquasecurity/trivy</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aquasecurity/trivy">aquasecurity/trivy</a></h1>
            <p>Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more</p>
            <p>Language: Go</p>
            <p>Stars: 27,246</p>
            <p>Forks: 2,599</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/imgs/logo.png&quot; width=&quot;200&quot;&gt;

[![GitHub Release][release-img]][release]
[![Test][test-img]][test]
[![Go Report Card][go-report-img]][go-report]
[![License: Apache-2.0][license-img]][license]
[![GitHub Downloads][github-downloads-img]][release]
![Docker Pulls][docker-pulls]

[üìñ Documentation][docs]
&lt;/div&gt;

Trivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.
Trivy has *scanners* that look for security issues, and *targets* where it can find those issues.

Targets (what Trivy can scan):

- Container Image
- Filesystem
- Git Repository (remote)
- Virtual Machine Image
- Kubernetes

Scanners (what Trivy can find there):

- OS packages and software dependencies in use (SBOM)
- Known vulnerabilities (CVEs)
- IaC issues and misconfigurations
- Sensitive information and secrets
- Software licenses

Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.

To learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.

## Quick Start

### Get Trivy

Trivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:

- `brew install trivy`
- `docker run aquasec/trivy`
- Download binary from &lt;https://github.com/aquasecurity/trivy/releases/latest/&gt;
- See [Installation] for more

Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:

- [GitHub Actions](https://github.com/aquasecurity/trivy-action)
- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)
- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)
- See [Ecosystem] for more

### Canary builds
There are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) as generated every push to main branch.

Please be aware: canary builds might have critical bugs, it&#039;s not recommended for use in production.

### General usage

```bash
trivy &lt;target&gt; [--scanners &lt;scanner1,scanner2&gt;] &lt;subject&gt;
```

Examples:

```bash
trivy image python:3.4-alpine
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov

&lt;/details&gt;

```bash
trivy fs --scanners vuln,secret,misconfig myproject/
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov

&lt;/details&gt;

```bash
trivy k8s --report summary cluster
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

![k8s summary](docs/imgs/trivy-k8s.png)

&lt;/details&gt;

## FAQ

### How to pronounce the name &quot;Trivy&quot;?

`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.

## Want more? Check out Aqua

If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  
You can find a high level comparison table specific to Trivy users [here](https://trivy.dev/latest/commercial/compare/).
In addition check out the &lt;https://aquasec.com&gt; website for more information about our products and services.
If you&#039;d like to contact Aqua or request a demo, please use this form: &lt;https://www.aquasec.com/demo&gt;

## Community

Trivy is an [Aqua Security][aquasec] open source project.  
Learn about our open source work and portfolio [here][oss].  
Contact us about any matter by opening a GitHub Discussion [here][discussions]

Please ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.

[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml
[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg
[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy
[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy
[release]: https://github.com/aquasecurity/trivy/releases
[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github
[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github
[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;label=docker%20pulls%20%2F%20trivy
[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE
[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[homepage]: https://trivy.dev
[docs]: https://trivy.dev/latest/docs/
[pronunciation]: #how-to-pronounce-the-name-trivy
[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md

[Installation]:https://trivy.dev/latest/getting-started/installation/
[Ecosystem]: https://trivy.dev/latest/ecosystem/
[Scanning Coverage]: https://trivy.dev/latest/docs/coverage/

[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/
[rego]: https://www.openpolicyagent.org/docs/latest/#rego
[sigstore]: https://www.sigstore.dev/

[aquasec]: https://aquasec.com
[oss]: https://www.aquasec.com/products/open-source-projects/
[discussions]: https://github.com/aquasecurity/trivy/discussions
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubeedge/kubeedge]]></title>
            <link>https://github.com/kubeedge/kubeedge</link>
            <guid>https://github.com/kubeedge/kubeedge</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[Kubernetes Native Edge Computing Framework (project under CNCF)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubeedge/kubeedge">kubeedge/kubeedge</a></h1>
            <p>Kubernetes Native Edge Computing Framework (project under CNCF)</p>
            <p>Language: Go</p>
            <p>Stars: 7,119</p>
            <p>Forks: 1,769</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># KubeEdge
[![Go Report Card](https://goreportcard.com/badge/github.com/kubeedge/kubeedge)](https://goreportcard.com/report/github.com/kubeedge/kubeedge)
[![LICENSE](https://img.shields.io/github/license/kubeedge/kubeedge.svg?style=flat-square)](/LICENSE)
[![Releases](https://img.shields.io/github/release/kubeedge/kubeedge/all.svg?style=flat-square)](https://github.com/kubeedge/kubeedge/releases)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3018/badge)](https://bestpractices.coreinfrastructure.org/projects/3018)

&lt;img src=&quot;./docs/images/kubeedge-logo-only.png&quot;&gt;

English | [ÁÆÄ‰Ωì‰∏≠Êñá](./README_zh.md)

KubeEdge is built upon Kubernetes and extends native containerized application orchestration and device management to hosts at the Edge.
It consists of cloud part and edge part, provides core infrastructure support for networking, application deployment and metadata synchronization
between cloud and edge. It also supports **MQTT** which enables edge devices to access through edge nodes.

With KubeEdge it is easy to get and deploy existing complicated machine learning, image recognition, event processing and other high level applications to the Edge.
With business logic running at the Edge, much larger volumes of data can be secured &amp; processed locally where the data is produced.
With data processed at the Edge, the responsiveness is increased dramatically and data privacy is protected.

KubeEdge is a graduation-level hosted project by the [Cloud Native Computing Foundation](https://cncf.io) (CNCF). KubeEdge graduation [announcement](https://www.cncf.io/announcements/2024/10/15/cloud-native-computing-foundation-announces-kubeedge-graduation/) by CNCF.

## Advantages

- **Kubernetes-native support**: Managing edge applications and edge devices in the cloud with fully compatible Kubernetes APIs.
- **Cloud-Edge Reliable Collaboration**: Ensure reliable messages delivery without loss over unstable cloud-edge network.
- **Edge Autonomy**: Ensure edge nodes run autonomously and the applications in edge run normally, when the cloud-edge network is unstable or edge is offline and restarted.
- **Edge Devices Management**: Managing edge devices through Kubernetes native APIs implemented by CRD.
- **Extremely Lightweight Edge Agent**: Extremely lightweight Edge Agent(EdgeCore) to run on resource constrained edge.


## How It Works

KubeEdge consists of cloud part and edge part.

### Architecture

&lt;div  align=&quot;center&quot;&gt;
&lt;img src=&quot;./docs/images/kubeedge_arch.png&quot; width = &quot;85%&quot; align=&quot;center&quot;&gt;
&lt;/div&gt;

### In the Cloud
- [CloudHub](https://kubeedge.io/en/docs/architecture/cloud/cloudhub): a web socket server responsible for watching changes at the cloud side, caching and sending messages to EdgeHub.
- [EdgeController](https://kubeedge.io/en/docs/architecture/cloud/edge_controller): an extended kubernetes controller which manages edge nodes and pods metadata so that the data can be targeted to a specific edge node.
- [DeviceController](https://kubeedge.io/en/docs/architecture/cloud/device_controller): an extended kubernetes controller which manages devices so that the device metadata/status data can be synced between edge and cloud.


### On the Edge
- [EdgeHub](https://kubeedge.io/en/docs/architecture/edge/edgehub): a web socket client responsible for interacting with Cloud Service for the edge computing (like Edge Controller as in the KubeEdge Architecture). This includes syncing cloud-side resource updates to the edge, and reporting edge-side host and device status changes to the cloud.
- [Edged](https://kubeedge.io/en/docs/architecture/edge/edged): an agent that runs on edge nodes and manages containerized applications.
- [EventBus](https://kubeedge.io/en/docs/architecture/edge/eventbus): a MQTT client to interact with MQTT servers (mosquitto), offering publish and subscribe capabilities to other components.
- [ServiceBus](https://kubeedge.io/en/docs/architecture/edge/servicebus): an HTTP client to interact with HTTP servers (REST), offering HTTP client capabilities to components of cloud to reach HTTP servers running at edge.
- [DeviceTwin](https://kubeedge.io/en/docs/architecture/edge/devicetwin): responsible for storing device status and syncing device status to the cloud. It also provides query interfaces for applications.
- [MetaManager](https://kubeedge.io/en/docs/architecture/edge/metamanager): the message processor between edged and edgehub. It is also responsible for storing/retrieving metadata to/from a lightweight database (SQLite).

## Kubernetes compatibility

|                        | Kubernetes 1.25 | Kubernetes 1.26 | Kubernetes 1.27 | Kubernetes 1.28 | Kubernetes 1.29 | Kubernetes 1.30 | 
|------------------------| --------------- |-----------------|-----------------| --------------- | --------------- |-----------------|
| KubeEdge 1.17          | +               | ‚úì               | ‚úì               | ‚úì               | -               | -               |
| KubeEdge 1.18          | +               | +               | ‚úì               | ‚úì               | ‚úì               | -               |
| KubeEdge 1.19          | +               | +               | ‚úì               | ‚úì               | ‚úì               | -               |
| KubeEdge 1.20          | +               | +               | +               | ‚úì               | ‚úì               | ‚úì               |
| KubeEdge 1.21          | +               | +               | +               | ‚úì               | ‚úì               | ‚úì               |
| KubeEdge HEAD (master) | +               | +               | +               | ‚úì               | ‚úì               | ‚úì               |

Key:
* `‚úì` KubeEdge and the Kubernetes version are exactly compatible.
* `+` KubeEdge has features or API objects that may not be present in the Kubernetes version.
* `-` The Kubernetes version has features or API objects that KubeEdge can&#039;t use.

## Guides

Get start with this [doc](https://kubeedge.io/en/docs).

See our documentation on [kubeedge.io](https://kubeedge.io) for more details.

To learn deeply about KubeEdge, try some examples on [examples](https://github.com/kubeedge/examples).

## Roadmap

* [2024 Roadmap](https://github.com/kubeedge/community/blob/master/roadmap.md)

## Meeting

Technical Steering Committees (TSC) Meeting:
- Pacific Time: **Wednesdays at 10:00-11:00 Beijing Time** (biweekly, starting from Feb. 26th 2020).
([Convert to your timezone.](https://www.thetimezoneconverter.com/?t=10%3A00&amp;tz=GMT%2B8&amp;))

Regular Community Meeting:
- Europe Time: **Wednesdays at 16:00-17:30 Beijing Time** (weekly, starting from Feb. 19th 2020).
([Convert to your timezone.](https://www.thetimezoneconverter.com/?t=16%3A30&amp;tz=GMT%2B8&amp;))

Resources:
- [Meeting notes and agenda](https://docs.google.com/document/d/1Sr5QS_Z04uPfRbA7PrXr3aPwCRpx7EtsyHq7mp6CnHs/edit)
- [Meeting recordings](https://www.youtube.com/playlist?list=PLQtlO1kVWGXkRGkjSrLGEPJODoPb8s5FM)
- [Meeting link](https://zoom.us/j/4167237304)
- [Meeting Calendar](https://calendar.google.com/calendar/embed?src=8rjk8o516vfte21qibvlae3lj4%40group.calendar.google.com) | [Subscribe](https://calendar.google.com/calendar?cid=OHJqazhvNTE2dmZ0ZTIxcWlidmxhZTNsajRAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ)

## Contact

If you need support, start with the [troubleshooting guide](https://kubeedge.io/en/docs/developer/troubleshooting), and work your way through the process that we&#039;ve outlined.

If you have questions, feel free to reach out to us in the following ways:

- [mailing list](https://groups.google.com/forum/#!forum/kubeedge)
- [slack](https://kubeedge.io/docs/community/slack)
- [twitter](https://twitter.com/kubeedge)

## Contributing

If you&#039;re interested in being a contributor and want to get involved in
developing the KubeEdge code, please see [CONTRIBUTING](./CONTRIBUTING.md) for
details on submitting patches and the contribution workflow.

## Security

### Security Audit

A third party security audit of KubeEdge has been completed in July 2022. Additionally, the KubeEdge community completed an overall system security analysis of KubeEdge. The detailed reports are as follows.

- [Security audit](https://github.com/kubeedge/community/blob/master/sig-security/sig-security-audit/KubeEdge-security-audit-2022.pdf)

- [Threat model and security protection analysis paper](https://github.com/kubeedge/community/blob/master/sig-security/sig-security-audit/KubeEdge-threat-model-and-security-protection-analysis.md)

### Reporting security vulnerabilities

We encourage security researchers, industry organizations and users to proactively report suspected vulnerabilities to our security team (`cncf-kubeedge-security@lists.cncf.io`), the team will help diagnose the severity of the issue and determine how to address the issue as soon as possible.

For further details please see [Security Policy](https://github.com/kubeedge/community/blob/master/team-security/SECURITY.md) for our security process and how to report vulnerabilities.

## License

KubeEdge is under the Apache 2.0 license. See the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[crossplane/crossplane]]></title>
            <link>https://github.com/crossplane/crossplane</link>
            <guid>https://github.com/crossplane/crossplane</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[The Cloud Native Control Plane]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/crossplane/crossplane">crossplane/crossplane</a></h1>
            <p>The Cloud Native Control Plane</p>
            <p>Language: Go</p>
            <p>Stars: 10,424</p>
            <p>Forks: 1,041</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/3260/badge)](https://www.bestpractices.dev/projects/3260) ![CI](https://github.com/crossplane/crossplane/workflows/CI/badge.svg) [![Go Report Card](https://goreportcard.com/badge/github.com/crossplane/crossplane)](https://goreportcard.com/report/github.com/crossplane/crossplane)

![Crossplane](banner.png)

Crossplane is a framework for building cloud native control planes without
needing to write code. It has a highly extensible backend that enables you to
build a control plane that can orchestrate applications and infrastructure no
matter where they run, and a highly configurable frontend that puts you in
control of the schema of the declarative API it offers.

Crossplane is a [Cloud Native Computing Foundation][cncf] project.

## Get Started

Crossplane&#039;s [Get Started Docs] cover install and cloud provider quickstarts.

## Releases

[![GitHub release](https://img.shields.io/github/release/crossplane/crossplane/all.svg)](https://github.com/crossplane/crossplane/releases) [![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/crossplane)](https://artifacthub.io/packages/helm/crossplane/crossplane)

Currently maintained releases, as well as the next few upcoming releases are
listed below. For more information take a look at the Crossplane [release cycle
documentation].

| Release | Release Date  |   EOL    |
|:-------:|:-------------:|:--------:|
|  v1.18  | Nov 5, 2024   | Aug 2025 |
|  v1.19  | Feb 11, 2025  | Nov 2025 |
|  v1.20  | May 21, 2025  | Feb 2026 |
|  v2.0   | Early Aug &#039;25 | May 2026 |
|  v2.1   | Early Nov &#039;25 | Aug 2026 |
|  v2.2   | Early Feb &#039;26 | Nov 2026 |

You can subscribe to the [community calendar] to track all release dates, and
find the most recent releases on the [releases] page.

## Roadmap

The public roadmap for Crossplane is published as a GitHub project board. Issues
added to the roadmap have been triaged and identified as valuable to the
community, and therefore a priority for the project that we expect to invest in.

The maintainer team regularly triages requests from the community to identify
features and issues of suitable scope and impact to include in this roadmap. The
community is encouraged to show their support for potential roadmap issues by
adding a :+1: reaction, leaving descriptive comments, and attending the
[regular community meetings] to discuss their requirements and use cases.

The maintainer team updates the roadmap on an as needed basis, in response to
demand, priority, and available resources. The public roadmap can be updated at
any time.

Milestones assigned to any issues in the roadmap are intended to give a sense of
overall priority and the expected order of delivery. They should be considered
approximate estimations and are **not** a strict commitment to a specific
delivery timeline.

[Crossplane Roadmap]

## Get Involved

[![Slack](https://img.shields.io/badge/slack-crossplane-red?logo=slack)](https://slack.crossplane.io) [![Bluesky Follow](https://img.shields.io/badge/bluesky-Follow-blue?logo=bluesky)](https://bsky.app/profile/crossplane.io) [![Twitter Follow](https://img.shields.io/twitter/follow/crossplane_io?logo=X&amp;label=Follow&amp;style=flat)](https://twitter.com/intent/follow?screen_name=crossplane_io&amp;user_id=788180534543339520) [![YouTube Channel Subscribers](https://img.shields.io/youtube/channel/subscribers/UC19FgzMBMqBro361HbE46Fw)](https://www.youtube.com/@Crossplane)

Crossplane is a community driven project; we welcome your contribution. To file
a bug, suggest an improvement, or request a new feature please open an [issue
against Crossplane] or the relevant provider. Refer to our [contributing guide]
for more information on how you can help.

* Discuss Crossplane on [Slack] or our [developer mailing list].
* Follow us on [Bluesky], [Twitter], or [LinkedIn], or subscribe to our [newsletter].
* Contact us via [Email].
* Join our regular community meetings.
* Provide feedback on our [roadmap and releases board].

The Crossplane community meeting takes place every 4 weeks on [Thursday at
10:00am Pacific Time][community meeting time]. You can find the up to date
meeting schedule on the [Community Calendar][community calendar].

Anyone who wants to discuss the direction of the project, design and
implementation reviews, or raise general questions with the broader community is
encouraged to join.

* Meeting link: &lt;https://zoom.us/j/425148449?pwd=NEk4N0tHWGpEazhuam1yR28yWHY5QT09&gt;
* [Current agenda and past meeting notes]
* [Past meeting recordings]
* [Community Calendar][community calendar]

### Special Interest Groups (SIG)

Each SIG collaborates in Slack and some groups have regular meetings, you can
find the meetings in the [Community Calendar][community calendar].
- [#sig-cli][sig-cli]
- [#sig-composition-environments][sig-composition-environments-slack]
- [#sig-composition-functions][sig-composition-functions-slack]
- [#sig-deletion-ordering][sig-deletion-ordering-slack]
- [#sig-devex][sig-devex-slack]
- [#sig-docs][sig-docs-slack]
- [#sig-e2e-testing][sig-e2e-testing-slack]
- [#sig-observability][sig-observability-slack]
- [#sig-observe-only][sig-observe-only-slack]
- [#sig-provider-families][sig-provider-families-slack]
- [#sig-secret-stores][sig-secret-stores-slack]
- [#sig-upjet][sig-upjet-slack]

## Adopters

A list of publicly known users of the Crossplane project can be found in [ADOPTERS.md].  We
encourage all users of Crossplane to add themselves to this list - we want to see the community&#039;s
growing success!

## License

Crossplane is under the Apache 2.0 license.

[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcrossplane%2Fcrossplane.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fcrossplane%2Fcrossplane?ref=badge_large)

&lt;!-- Named links --&gt;

[Crossplane]: https://crossplane.io
[release cycle documentation]: https://docs.crossplane.io/knowledge-base/guides/release-cycle
[install]: https://crossplane.io/docs/latest
[Slack]: https://slack.crossplane.io
[developer mailing list]: https://groups.google.com/forum/#!forum/crossplane-dev
[Bluesky]: https://bsky.app/profile/crossplane.io
[Twitter]: https://twitter.com/crossplane_io
[LinkedIn]: https://www.linkedin.com/company/crossplane/
[newsletter]: https://eepurl.com/ivy4v-/
[Email]: mailto:info@crossplane.io
[issue against Crossplane]: https://github.com/crossplane/crossplane/issues
[contributing guide]: contributing/README.md
[community meeting time]: https://www.thetimezoneconverter.com/?t=10:00&amp;tz=PT%20%28Pacific%20Time%29
[Current agenda and past meeting notes]: https://docs.google.com/document/d/1q_sp2jLQsDEOX7Yug6TPOv7Fwrys6EwcF5Itxjkno7Y/edit?usp=sharing
[Past meeting recordings]: https://www.youtube.com/playlist?list=PL510POnNVaaYYYDSICFSNWFqNbx1EMr-M
[roadmap and releases board]: https://github.com/orgs/crossplane/projects/20/views/9?pane=info
[cncf]: https://www.cncf.io/
[Get Started Docs]: https://docs.crossplane.io/latest/getting-started/
[community calendar]: https://calendar.google.com/calendar/embed?src=c_2cdn0hs9e2m05rrv1233cjoj1k%40group.calendar.google.com
[releases]: https://github.com/crossplane/crossplane/releases
[ADOPTERS.md]: ADOPTERS.md
[regular community meetings]: https://github.com/crossplane/crossplane/blob/main/README.md#get-involved
[Crossplane Roadmap]: https://github.com/orgs/crossplane/projects/20/views/9?pane=info
[sig-cli]: https://crossplane.slack.com/archives/C08V9PMLRQA
[sig-composition-environments-slack]: https://crossplane.slack.com/archives/C05BP6QFLUW
[sig-composition-functions-slack]: https://crossplane.slack.com/archives/C031Y29CSAE
[sig-deletion-ordering-slack]: https://crossplane.slack.com/archives/C05BP8W5ALW
[sig-devex-slack]: https://crossplane.slack.com/archives/C05U1LLM3B2
[sig-docs-slack]: https://crossplane.slack.com/archives/C02CAQ52DPU
[sig-e2e-testing-slack]: https://crossplane.slack.com/archives/C05C8CCTVNV
[sig-observability-slack]: https://crossplane.slack.com/archives/C061GNH3LA0
[sig-observe-only-slack]: https://crossplane.slack.com/archives/C04D5988QEA
[sig-provider-families-slack]: https://crossplane.slack.com/archives/C056YAQRV16
[sig-secret-stores-slack]: https://crossplane.slack.com/archives/C05BY7DKFV2
[sig-upjet-slack]: https://crossplane.slack.com/archives/C05T19TB729
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gravitational/teleport]]></title>
            <link>https://github.com/gravitational/teleport</link>
            <guid>https://github.com/gravitational/teleport</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[The easiest, and most secure way to access and protect all of your infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gravitational/teleport">gravitational/teleport</a></h1>
            <p>The easiest, and most secure way to access and protect all of your infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 18,686</p>
            <p>Forks: 1,865</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>Teleport provides connectivity, authentication, access controls and audit for infrastructure.

Here is why you might use Teleport:

* Set up SSO for all of your cloud infrastructure [1].
* Protect access to cloud and on-prem services using mTLS endpoints and short-lived certificates.
* Establish tunnels to access services behind NATs and firewalls.
* Provide an audit log with session recording and replay for various protocols.
* Unify Role-Based Access Control (RBAC) and enforce the principle of least privilege with  [access requests](https://goteleport.com/features/access-requests/).

[1] The open source version supports only GitHub SSO.

Teleport works with SSH, Kubernetes, databases, RDP, and web services.

* Architecture: https://goteleport.com/docs/reference/architecture/
* Getting Started: https://goteleport.com/docs/get-started/

&lt;div align=&quot;center&quot;&gt;
   &lt;a href=&quot;https://goteleport.com/download&quot;&gt;
   &lt;img src=&quot;./assets/img/hero-teleport-platform.png&quot; width=750/&gt;
   &lt;/a&gt;
   &lt;div align=&quot;center&quot; style=&quot;padding: 25px&quot;&gt;
      &lt;a href=&quot;https://goteleport.com/download&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/github/v/release/gravitational/teleport?sort=semver&amp;label=Release&amp;color=651FFF&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://golang.org/&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/github/go-mod/go-version/gravitational/teleport?color=7fd5ea&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://github.com/gravitational/teleport/blob/master/CODE_OF_CONDUCT.md&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Contribute-üôå-green.svg&quot; /&gt;
      &lt;/a&gt;
      &lt;a href=&quot;https://www.gnu.org/licenses/agpl-3.0.en.html&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/AGPL-3.0-red.svg&quot; /&gt;
      &lt;/a&gt;
   &lt;/div&gt;
&lt;/div&gt;
&lt;/br&gt;

## Table of Contents

1. [Introduction](#introduction)
1. [Installing and Running](#installing-and-running)
1. [Docker](#docker)
1. [Building Teleport](#building-teleport)
1. [Why Did We Build Teleport?](#why-did-we-build-teleport)
1. [More Information](#more-information)
1. [Support and Contributing](#support-and-contributing)
1. [Is Teleport Secure and Production Ready?](#is-teleport-secure-and-production-ready)
1. [Who Built Teleport?](#who-built-teleport)
1. [License](#license)

## Introduction

Teleport includes an identity-aware access proxy, a CA that issues short-lived certificates, a unified access control system and a tunneling system to access resources behind the firewall.

We have implemented Teleport as a single Go binary that integrates with multiple protocols and cloud services:

* [SSH nodes](https://goteleport.com/docs/enroll-resources/server-access/introduction/).
* [Kubernetes clusters](https://goteleport.com/docs/enroll-resources/kubernetes-access/introduction/)
* [PostgreSQL, MongoDB, CockroachDB and MySQL databases](https://goteleport.com/docs/enroll-resources/database-access/).
* [Internal Web apps](https://goteleport.com/docs/enroll-resources/application-access/introduction/).
* [Windows Hosts](https://goteleport.com/docs/enroll-resources/desktop-access/introduction/).
* [Networked servers](https://goteleport.com/docs/enroll-resources/server-access/introduction/).

You can set up Teleport as a [Linux daemon](https://goteleport.com/docs/admin-guides/deploy-a-cluster/linux-demo) or a [Kubernetes deployment](https://goteleport.com/docs/admin-guides/deploy-a-cluster/helm-deployments/).

Teleport focuses on best practices for infrastructure security:

- No need to manage shared secrets such as SSH keys or Kubernetes tokens: it uses certificate-based auth with certificate expiration for all protocols.
- Two-factor authentication (2FA) for everything.
- Collaboratively troubleshoot issues through session sharing.
- Single sign-on (SSO) for everything via GitHub Auth, OpenID Connect, or SAML with endpoints like Okta or Microsoft Entra ID.
- Infrastructure introspection: Use Teleport via the CLI or Web UI to view the status of every SSH node, database instance, Kubernetes cluster, or internal web app.

Teleport uses [Go crypto](https://godoc.org/golang.org/x/crypto). It is _fully compatible with OpenSSH_, `sshd` servers, and `ssh` clients, Kubernetes clusters and more.

|Project Links| Description
|---|----
| [Teleport Website](https://goteleport.com/) | The official website of the project. |
| [Documentation](https://goteleport.com/docs/) | Admin guide, user manual and more. |
| [Blog](https://goteleport.com/blog/) | Our blog where we publish Teleport news. |
| [Forum](https://github.com/gravitational/teleport/discussions) | Ask us a setup question, post your tutorial, feedback, or idea on our forum. |
| [Slack](https://goteleport.com/slack) | Need help with your setup? Ping us in our Slack channel. |
| [Cloud-hosted](https://goteleport.com/pricing) | We offer Enterprise with a Cloud-hosted option. For teams that require easy and secure access to their computing environments. |


## Installing and Running

To set up a single-instance Teleport cluster, follow our [getting started
guide](https://goteleport.com/docs/admin-guides/deploy-a-cluster/linux-demo/). You can then register your
servers, Kubernetes clusters, and other infrastructure with your Teleport
cluster.

You can also get started with Teleport Enterprise Cloud, a managed Teleport
deployment that makes it easier to enable secure access to your infrastructure.

[Sign up for a free trial](https://goteleport.com/signup) of Teleport Enterprise
Cloud.

Follow our guide to [registering your first
server](https://goteleport.com/docs/get-started/)
with Teleport Enterprise Cloud.

## Docker

### Deploy Teleport

If you wish to deploy Teleport inside a Docker container see the
[installation guide](https://goteleport.com/docs/installation/#running-teleport-on-docker).

### For Local Testing and Development

To run a full test suite locally, see [the test dependencies list](BUILD_macos.md#local-tests-dependencies)

## Building Teleport

The `teleport` repository contains the Teleport daemon binary (written in Go)
and a web UI written in TypeScript.

If your intention is to build and deploy for use in a production infrastructure
a released tag should be used.  The default branch, `master`, is the current
development branch for an upcoming major version.  Get the latest release tags
listed at https://goteleport.com/download/ and then use that tag in the `git clone`.
For example `git clone https://github.com/gravitational/teleport.git -b v16.0.0` gets release v16.0.0.

### Dockerized Build

It is often easiest to build with Docker, which ensures that all required
tooling is available for the build. To execute a dockerized build, ensure
that docker is installed and running, and execute:

```
make -C build.assets build-binaries
```

### Local Build

#### Dependencies

Ensure you have installed correct versions of necessary dependencies:
* `Go` version from
  [go.mod](https://github.com/gravitational/teleport/blob/master/go.mod#L3)
* If you wish to build the Rust-powered features like Desktop Access, see the
  `Rust` and `Cargo` versions in
  [build.assets/Makefile](https://github.com/gravitational/teleport/blob/master/build.assets/Makefile#L21)
  (search for `RUST_VERSION`)
* For `tsh` version &gt; `10.x` with FIDO2 support, you will need `libfido2` and
  `pkg-config` installed locally
* To build the web UI:
  * [`pnpm`](https://pnpm.io/installation#using-corepack). If you have Node.js installed, run `corepack enable pnpm` to make `pnpm` available.
  * If you prefer not to install/use pnpm, but have docker available, you can run `make docker-ui` instead.
  * The `Rust` and `Cargo` version in [build.assets/Makefile](https://github.com/gravitational/teleport/blob/master/build.assets/versions.mk#L11) (search for `RUST_VERSION`) are required.
  * The [`wasm-pack`](https://github.com/rustwasm/wasm-pack) version in [build.assets/Makefile](https://github.com/gravitational/teleport/blob/master/build.assets/versions.mk#L12) (search for `WASM_PACK_VERSION`) is required.
  * [`binaryen`](https://github.com/WebAssembly/binaryen) (which contains `wasm-opt`) is required to be installed manually
    on linux aarch64 (64-bit ARM). You can check if it&#039;s already installed on your system by running `which wasm-opt`. If not you can install it like `apt-get install binaryen` (for Debian-based Linux). `wasm-pack` will install this automatically on other platforms.

For an example of Dev Environment setup on a Mac, see [these instructions](BUILD_macos.md).

#### Perform a build

&gt;**Important**
&gt;
&gt;* The Go compiler is somewhat sensitive to the amount of memory: you will need
   **at least** 1GB of virtual memory to compile Teleport. A 512MB instance
   without swap will **not** work.
&gt;* This will build the latest version of Teleport, **regardless** of whether it
   is stable. If you want to build the latest stable release, run `git checkout`
   and `git submodule update --recursive` to the corresponding tag (for example,
&gt;* run `git checkout v8.0.0`) **before** performing a build.

Get the source

```shell
git clone https://github.com/gravitational/teleport.git
cd teleport
```

To perform a build

```shell
make full
```

`tsh` dynamically links against libfido2 by default, to support development
environments, as long as the library itself can be found:

```shell
$ brew install libfido2 pkg-config  # Replace with your package manager of choice

$ make build/tsh
&gt; libfido2 found, setting FIDO2=dynamic
&gt; (...)
```

Release binaries are linked statically against libfido2. You may switch the
linking mode using the FIDO2 variable:

```shell
make build/tsh FIDO2=dynamic # dynamic linking
make build/tsh FIDO2=static  # static linking, for an easy setup use `make enter`
                             # or `build.assets/macos/build-fido2-macos.sh`.
make build/tsh FIDO2=off     # doesn&#039;t link libfido2 in any way
```

`tsh` builds with Touch ID support require access to an Apple Developer account.
If you are a Teleport maintainer, ask the team for access.

#### Build output and run locally

If the build succeeds, the installer will place the binaries in the `build` directory.

Before starting, create default data directories:

```shell
sudo mkdir -p -m0700 /var/lib/teleport
sudo chown $USER /var/lib/teleport
```

#### Running Teleport in a hot reload mode

To speed up your development process, you can run Teleport using
[`CompileDaemon`](https://github.com/githubnemo/CompileDaemon). This will build
and run the Teleport binary, and then rebuild and restart it whenever any Go
source files change.

1. Install CompileDaemon:

    ```shell
    go install github.com/githubnemo/CompileDaemon@latest
    ```

    Note that we use `go install` instead of the suggested `go get`, because we
    don&#039;t want CompileDaemon to become a dependency of the project.

1. Build and run the Teleport binary:

    ```shell
    make teleport-hot-reload
    ```

    By default, this runs a `teleport start` command. If you want to customize
    the command, for example by providing a custom config file location, you can
    use the `TELEPORT_ARGS` parameter:

    ```shell
    make teleport-hot-reload TELEPORT_ARGS=&#039;start --config=/path/to/config.yaml&#039;
    ```

Note that you still need to run [`make grpc`](api/proto/README.md) if you modify
any Protocol Buffers files to regenerate the generated Go sources; regenerating
these sources should in turn cause the CompileDaemon to rebuild and restart
Teleport.

### Web UI

The Teleport Web UI resides in the [web](web) directory.

#### Rebuilding Web UI for development

To rebuild the Teleport UI package, run the following command:

```bash
make docker-ui
```

Then you can replace Teleport Web UI files with the files from the newly-generated `/dist` folder.

To enable speedy iterations on the Web UI, you can run a [local web-dev server](web#web-ui).

You can also tell Teleport to load the Web UI assets from the source directory.
To enable this behavior, set the environment variable `DEBUG=1` and rebuild with the default target:

```bash
# Run Teleport as a single-node cluster in development mode:
DEBUG=1 ./build/teleport start -d
```

Keep the server running in this mode, and make your UI changes in `/dist` directory.
For instructions about how to update the Web UI, read [the `web` README](web#readme).

### Managing dependencies

All dependencies are managed using [Go modules](https://blog.golang.org/using-go-modules). Here are the instructions for some common tasks:

#### Add a new dependency

Latest version:

```bash
go get github.com/new/dependency
```

and update the source to use this dependency.


To get a specific version, use `go get github.com/new/dependency@version` instead.

#### Set dependency to a specific version

```bash
go get github.com/new/dependency@version
```

#### Update dependency to the latest version

```bash
go get -u github.com/new/dependency
```

#### Update all dependencies

```bash
go get -u all
```

#### Debugging dependencies

Why is a specific package imported?

`go mod why $pkgname`

Why is a specific module imported?

`go mod why -m $modname`

Why is a specific version of a module imported?

`go mod graph | grep $modname`

### Devbox Build (experimental)

**Note**: Devbox support is still experimental. It&#039;s very possible things may not work as intended.

Teleport can be built using [devbox](https://www.jetpack.io/devbox). To use devbox, follow
the instructions to install devbox [here](https://www.jetpack.io/devbox/docs/quickstart/) and
then run:

`devbox shell`

This will install Teleport&#039;s various build dependencies and drop you into a shell with these
dependencies. From here, you can build Teleport normally.

#### flake.nix

A nix flake is located in `build.assets/flake` that allows for installation of Teleport&#039;s less
common build tooling. If this flake is updated, run:

`devbox install`

in order to make sure the changes in the flake are reflected in the local devbox shell.

## Why did We Build Teleport?

The Teleport creators used to work together at Rackspace. We noticed that most cloud computing users struggle with setting up and configuring infrastructure security because popular tools, while flexible, are complex to understand and expensive to maintain. Additionally, most organizations use multiple infrastructure form factors such as several cloud providers, multiple cloud accounts, servers in colocation, and even smart devices. Some of those devices run on untrusted networks, behind third-party firewalls. This only magnifies complexity and increases operational overhead.

We had a choice, either start a security consulting business or build a solution that&#039;s dead-easy to use and understand. A real-time representation of all of your servers in the same room as you, as if they were magically _teleported_. Thus, Teleport was born!

## More Information

* [Teleport Getting Started](https://goteleport.com/docs/get-started/)
* [Teleport
  Architecture](https://goteleport.com/docs/reference/architecture/)
* [Reference](https://goteleport.com/docs/reference/)
* [FAQ](https://goteleport.com/docs/faq)

## Support and Contributing

We offer a few different options for support. First of all, we try to provide clear and comprehensive documentation. The docs are also in GitHub, so feel free to create a PR or file an issue if you have ideas for improvements. If you still have questions after reviewing our docs, you can also:

* Join [Teleport Discussions](https://github.com/gravitational/teleport/discussions) to ask questions. Our engineers are available there to help you.
* If you want to contribute to Teleport or file a bug report/issue, you can create an issue here in GitHub.
* If you are interested in Teleport Enterprise or more responsive support during a POC, we can also create a dedicated Slack channel for you during your POC. You can [reach out to us through our website](https://goteleport.com/pricing/) to arrange for a POC.

## Is Teleport Secure and Production-Ready?

Yes -- Teleport is production-ready and designed to protect and facilitate
access to the most precious and mission-critical applications.

Teleport has completed several security audits from nationally and
internationally recognized technology security companies.

We publicize some of our audit results, security philosophy and related
information on our [trust page](https://trust.goteleport.com/).

You can see the list of companies that use Teleport in production on the Teleport
[product page](https://goteleport.com/case-study/).

## Who Built Teleport?

Teleport was created by [Gravitational, Inc.](https://goteleport.com). We have
built Teleport by borrowing from our previous experiences at Rackspace. [Learn more
about Teleport and our history](https://goteleport.com/about/).

## License

Teleport is distributed in multiple forms with different licensing implications.

The Teleport API module (all code in this repository under `/api`) is available
under the [Apache 2.0 license](./api/LICENSE).

The remainder of the source code in this repository is available under the
[GNU Affero General Public License](./LICENSE). Users compiling Teleport
from source must comply with the terms of this license.

Teleport Community Edition builds distributed on http://goteleport.com/download
are available under a [modified Apache 2.0 license](./build.assets/LICENSE-community).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes/kube-state-metrics]]></title>
            <link>https://github.com/kubernetes/kube-state-metrics</link>
            <guid>https://github.com/kubernetes/kube-state-metrics</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Add-on agent to generate and expose cluster-level metrics.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes/kube-state-metrics">kubernetes/kube-state-metrics</a></h1>
            <p>Add-on agent to generate and expose cluster-level metrics.</p>
            <p>Language: Go</p>
            <p>Stars: 5,776</p>
            <p>Forks: 2,086</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># Overview

[![Build Status](https://github.com/kubernetes/kube-state-metrics/workflows/continuous-integration/badge.svg)](https://github.com/kubernetes/kube-state-metrics/actions)
[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes/kube-state-metrics)](https://goreportcard.com/report/github.com/kubernetes/kube-state-metrics)
[![Go Reference](https://pkg.go.dev/badge/github.com/kubernetes/kube-state-metrics.svg)](https://pkg.go.dev/github.com/kubernetes/kube-state-metrics)
[![govulncheck](https://github.com/kubernetes/kube-state-metrics/actions/workflows/govulncheck.yml/badge.svg)](https://github.com/kubernetes/kube-state-metrics/actions/workflows/govulncheck.yml)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/8696/badge)](https://www.bestpractices.dev/projects/8696)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/kubernetes/kube-state-metrics/badge)](https://api.securityscorecards.dev/projects/github.com/kubernetes/kube-state-metrics)

kube-state-metrics (KSM) is a simple service that listens to the Kubernetes API
server and generates metrics about the state of the objects. (See examples in
the Metrics section below.) It is not focused on the health of the individual
Kubernetes components, but rather on the health of the various objects inside,
such as deployments, nodes and pods.

kube-state-metrics is about generating metrics from Kubernetes API objects
without modification. This ensures that features provided by kube-state-metrics
have the same grade of stability as the Kubernetes API objects themselves. In
turn, this means that kube-state-metrics in certain situations may not show the
exact same values as kubectl, as kubectl applies certain heuristics to display
comprehensible messages. kube-state-metrics exposes raw data unmodified from the
Kubernetes API, this way users have all the data they require and perform
heuristics as they see fit.

The metrics are exported on the HTTP endpoint `/metrics` on the listening port
(default 8080). They are served as plaintext. They are designed to be consumed
either by Prometheus itself or by a scraper that is compatible with scraping a
Prometheus client endpoint. You can also open `/metrics` in a browser to see
the raw metrics. Note that the metrics exposed on the `/metrics` endpoint
reflect the current state of the Kubernetes cluster. When Kubernetes objects
are deleted they are no longer visible on the `/metrics` endpoint.

&gt; [!NOTE]
&gt; This README is generated from a [template](./README.md.tpl). Please make your changes there and run `make generate-template`.

## Table of Contents

* [Versioning](#versioning)
  * [Kubernetes Version](#kubernetes-version)
  * [Compatibility matrix](#compatibility-matrix)
  * [Resource group version compatibility](#resource-group-version-compatibility)
  * [Container Image](#container-image)
* [Metrics Documentation](#metrics-documentation)
  * [ECMAScript regular expression support for allow and deny lists](#ecmascript-regular-expression-support-for-allow-and-deny-lists)
  * [Conflict resolution in label names](#conflict-resolution-in-label-names)
* [Kube-state-metrics self metrics](#kube-state-metrics-self-metrics)
* [Resource recommendation](#resource-recommendation)
* [Latency](#latency)
* [A note on costing](#a-note-on-costing)
* [kube-state-metrics vs. metrics-server](#kube-state-metrics-vs-metrics-server)
* [Scaling kube-state-metrics](#scaling-kube-state-metrics)
  * [Resource recommendation](#resource-recommendation)
  * [Horizontal sharding](#horizontal-sharding)
    * [Automated sharding](#automated-sharding)
  * [Daemonset sharding for pod metrics](#daemonset-sharding-for-pod-metrics)
* [Setup](#setup)
  * [Building the Docker container](#building-the-docker-container)
* [Usage](#usage)
  * [Kubernetes Deployment](#kubernetes-deployment)
  * [Limited privileges environment](#limited-privileges-environment)
  * [Helm Chart](#helm-chart)
  * [Development](#development)
  * [Developer Contributions](#developer-contributions)
  * [Community](#community)

### Versioning

#### Kubernetes Version

kube-state-metrics uses [`client-go`](https://github.com/kubernetes/client-go) to talk with
Kubernetes clusters. The supported Kubernetes cluster version is determined by `client-go`.
The compatibility matrix for client-go and Kubernetes cluster can be found
[here](https://github.com/kubernetes/client-go#compatibility-matrix).
All additional compatibility is only best effort, or happens to still/already be supported.

#### Compatibility matrix

At most, 5 kube-state-metrics and 5 [kubernetes releases](https://github.com/kubernetes/kubernetes/releases) will be recorded below.
Generally, it is recommended to use the latest release of kube-state-metrics. If you run a very recent version of Kubernetes, you might want to use an unreleased version to have the full range of supported resources. If you run an older version of Kubernetes, you might need to run an older version in order to have full support for all resources. Be aware, that the maintainers will only support the latest release. Older versions might be supported by interested users of the community.

| kube-state-metrics | Kubernetes client-go Version |
|--------------------|:----------------------------:|
| **v2.11.0**        | v1.28                        |
| **v2.12.0**        | v1.29                        |
| **v2.13.0**        | v1.30                        |
| **v2.14.0**        | v1.31                        |
| **v2.15.0**        | v1.32                        |
| **main**           | v1.32                        |

#### Resource group version compatibility

Resources in Kubernetes can evolve, i.e., the group version for a resource may change from alpha to beta and finally GA
in different Kubernetes versions. For now, kube-state-metrics will only use the oldest API available in the latest
release.

#### Container Image

The latest container image can be found at:

* `registry.k8s.io/kube-state-metrics/kube-state-metrics:v2.15.0` (arch: `amd64`, `arm`, `arm64`, `ppc64le` and `s390x`)
* View all multi-architecture images at [here](https://explore.ggcr.dev/?image=registry.k8s.io%2Fkube-state-metrics%2Fkube-state-metrics:v2.15.0)

### Metrics Documentation

Any resources and metrics based on alpha Kubernetes APIs are excluded from any stability guarantee,
which may be changed at any given release.

See the [`docs`](docs) directory for more information on the exposed metrics.

#### Conflict resolution in label names

The `*_labels` family of metrics exposes Kubernetes labels as Prometheus labels.
As [Kubernetes](https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/#syntax-and-character-set)
is more liberal than
[Prometheus](https://prometheus.io/docs/concepts/data_model/#metric-names-and-labels)
in terms of allowed characters in label names,
we automatically convert unsupported characters to underscores.
For example, `app.kubernetes.io/name` becomes `label_app_kubernetes_io_name`.

This conversion can create conflicts when multiple Kubernetes labels like
`foo-bar` and `foo_bar` would be converted to the same Prometheus label `label_foo_bar`.

Kube-state-metrics automatically adds a suffix `_conflictN` to resolve this conflict,
so it converts the above labels to
`label_foo_bar_conflict1` and `label_foo_bar_conflict2`.

If you&#039;d like to have more control over how this conflict is resolved,
you might want to consider addressing this issue on a different level of the stack,
e.g. by standardizing Kubernetes labels using an
[Admission Webhook](https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/)
that ensures that there are no possible conflicts.

#### ECMAScript regular expression support for allow and deny lists

Starting from [#2616](https://github.com/kubernetes/kube-state-metrics/pull/2616/files), kube-state-metrics supports ECMAScript&#039;s `regexp` for allow and deny lists. This was incorporated as a workaround for the limitations of the `regexp` package in Go, which does not support lookarounds due to their non-linear time complexity. Please note that while lookarounds are now supported for allow and deny lists, regular expressions&#039; evaluation time is capped at a minute to prevent performance issues.

### Kube-state-metrics self metrics

kube-state-metrics exposes its own general process metrics under `--telemetry-host` and `--telemetry-port` (default 8081).

kube-state-metrics also exposes list and watch success and error metrics. These can be used to calculate the error rate of list or watch resources.
If you encounter those errors in the metrics, it is most likely a configuration or permission issue, and the next thing to investigate would be looking
at the logs of kube-state-metrics.

Example of the above mentioned metrics:

```
kube_state_metrics_list_total{resource=&quot;*v1.Node&quot;,result=&quot;success&quot;} 1
kube_state_metrics_list_total{resource=&quot;*v1.Node&quot;,result=&quot;error&quot;} 52
kube_state_metrics_watch_total{resource=&quot;*v1beta1.Ingress&quot;,result=&quot;success&quot;} 1
```

kube-state-metrics also exposes some http request metrics, examples of those are:

```
http_request_duration_seconds_bucket{handler=&quot;metrics&quot;,method=&quot;get&quot;,le=&quot;2.5&quot;} 30
http_request_duration_seconds_bucket{handler=&quot;metrics&quot;,method=&quot;get&quot;,le=&quot;5&quot;} 30
http_request_duration_seconds_bucket{handler=&quot;metrics&quot;,method=&quot;get&quot;,le=&quot;10&quot;} 30
http_request_duration_seconds_bucket{handler=&quot;metrics&quot;,method=&quot;get&quot;,le=&quot;+Inf&quot;} 30
http_request_duration_seconds_sum{handler=&quot;metrics&quot;,method=&quot;get&quot;} 0.021113919999999998
http_request_duration_seconds_count{handler=&quot;metrics&quot;,method=&quot;get&quot;} 30
```

kube-state-metrics also exposes build and configuration metrics:

```
kube_state_metrics_build_info{branch=&quot;main&quot;,goversion=&quot;go1.15.3&quot;,revision=&quot;6c9d775d&quot;,version=&quot;v2.0.0-beta&quot;} 1
kube_state_metrics_shard_ordinal{shard_ordinal=&quot;0&quot;} 0
kube_state_metrics_total_shards 1
```

`kube_state_metrics_build_info` is used to expose version and other build information. For more usage about the info pattern,
please check the blog post [here](https://www.robustperception.io/exposing-the-software-version-to-prometheus).
Sharding metrics expose `--shard` and `--total-shards` flags and can be used to validate
run-time configuration, see [`/examples/prometheus-alerting-rules`](./examples/prometheus-alerting-rules).

kube-state-metrics also exposes metrics about it config file and the Custom Resource State config file:

```
kube_state_metrics_config_hash{filename=&quot;crs.yml&quot;,type=&quot;customresourceconfig&quot;} 2.38272279311849e+14
kube_state_metrics_config_hash{filename=&quot;config.yml&quot;,type=&quot;config&quot;} 2.65285922340846e+14
kube_state_metrics_last_config_reload_success_timestamp_seconds{filename=&quot;crs.yml&quot;,type=&quot;customresourceconfig&quot;} 1.6704882592037103e+09
kube_state_metrics_last_config_reload_success_timestamp_seconds{filename=&quot;config.yml&quot;,type=&quot;config&quot;} 1.6704882592035313e+09
kube_state_metrics_last_config_reload_successful{filename=&quot;crs.yml&quot;,type=&quot;customresourceconfig&quot;} 1
kube_state_metrics_last_config_reload_successful{filename=&quot;config.yml&quot;,type=&quot;config&quot;} 1
```

### Scaling kube-state-metrics

#### Resource recommendation

Resource usage for kube-state-metrics changes with the Kubernetes objects (Pods/Nodes/Deployments/Secrets etc.) size of the cluster.
To some extent, the Kubernetes objects in a cluster are in direct proportion to the node number of the cluster.

As a general rule, you should allocate:

* 250MiB memory
* 0.1 cores

Note that if CPU limits are set too low, kube-state-metrics&#039; internal queues will not be able to be worked off quickly enough, resulting in increased memory consumption as the queue length grows. If you experience problems resulting from high memory allocation or CPU throttling, try increasing the CPU limits.

### Latency

In a 100 node cluster scaling test the latency numbers were as follows:

```
&quot;Perc50&quot;: 259615384 ns,
&quot;Perc90&quot;: 475000000 ns,
&quot;Perc99&quot;: 906666666 ns.
```

### A note on costing

By default, kube-state-metrics exposes several metrics for events across your cluster. If you have a large number of frequently-updating resources on your cluster, you may find that a lot of data is ingested into these metrics. This can incur high costs on some cloud providers. Please take a moment to [configure what metrics you&#039;d like to expose](docs/developer/cli-arguments.md), as well as consult the documentation for your Kubernetes environment in order to avoid unexpectedly high costs.

### kube-state-metrics vs. metrics-server

The [metrics-server](https://github.com/kubernetes-incubator/metrics-server)
is a project that has been inspired by
[Heapster](https://github.com/kubernetes-retired/heapster) and is implemented
to serve the goals of core metrics pipelines in [Kubernetes monitoring
architecture](https://github.com/kubernetes/design-proposals-archive/blob/main/instrumentation/monitoring_architecture.md).
It is a cluster level component which periodically scrapes metrics from all
Kubernetes nodes served by Kubelet through Metrics API. The metrics are
aggregated, stored in memory and served in [Metrics API
format](https://git.k8s.io/metrics/pkg/apis/metrics/v1alpha1/types.go). The
metrics-server stores the latest values only and is not responsible for
forwarding metrics to third-party destinations.

kube-state-metrics is focused on generating completely new metrics from
Kubernetes&#039; object state (e.g. metrics based on deployments, replica sets,
etc.). It holds an entire snapshot of Kubernetes state in memory and
continuously generates new metrics based off of it. And just like the
metrics-server it too is not responsible for exporting its metrics anywhere.

Having kube-state-metrics as a separate project also enables access to these
metrics from monitoring systems such as Prometheus.

### Horizontal sharding

In order to shard kube-state-metrics horizontally, some automated sharding capabilities have been implemented. It is configured with the following flags:

* `--shard` (zero indexed)
* `--total-shards`

Sharding is done by taking an md5 sum of the Kubernetes Object&#039;s UID and performing a modulo operation on it with the total number of shards. Each shard decides whether the object is handled by the respective instance of kube-state-metrics or not. Note that this means all instances of kube-state-metrics, even if sharded, will have the network traffic and the resource consumption for unmarshaling objects for all objects, not just the ones they are responsible for. To optimize this further, the Kubernetes API would need to support sharded list/watch capabilities. In the optimal case, memory consumption for each shard will be 1/n compared to an unsharded setup. Typically, kube-state-metrics needs to be memory and latency optimized in order for it to return its metrics rather quickly to Prometheus. One way to reduce the latency between kube-state-metrics and the kube-apiserver is to run KSM with the `--use-apiserver-cache` flag. In addition to reducing the latency, this option will also lead to a reduction in the load on etcd.

Sharding should be used carefully and additional monitoring should be set up in order to ensure that sharding is set up and functioning as expected (eg. instances for each shard out of the total shards are configured).

#### Automated sharding

Automatic sharding allows each shard to discover its nominal position when deployed in a StatefulSet which is useful for automatically configuring sharding. This is an experimental feature and may be broken or removed without notice.

To enable automated sharding, kube-state-metrics must be run by a `StatefulSet` and the pod name and namespace must be handed to the kube-state-metrics process via the `--pod` and `--pod-namespace` flags. Example manifests demonstrating the autosharding functionality can be found in [`/examples/autosharding`](./examples/autosharding).

This way of deploying shards is useful when you want to manage KSM shards through a single Kubernetes resource (a single `StatefulSet` in this case) instead of having one `Deployment` per shard. The advantage can be especially significant when deploying a high number of shards.

The downside of using an auto-sharded setup comes from the rollout strategy supported by `StatefulSet`s. When managed by a `StatefulSet`, pods are replaced one at a time with each pod first getting terminated and then recreated. Besides such rollouts being slower, they will also lead to short downtime for each shard. If a Prometheus scrape happens during a rollout, it can miss some of the metrics exported by kube-state-metrics.

### Daemonset sharding for pod metrics

For pod metrics, they can be sharded per node with the following flag:

* `--node=$(NODE_NAME)`

Each kube-state-metrics pod uses FieldSelector (spec.nodeName) to watch/list pod metrics only on the same node.

A daemonset kube-state-metrics example:

```
apiVersion: apps/v1
kind: DaemonSet
spec:
  template:
    spec:
      containers:
      - image: registry.k8s.io/kube-state-metrics/kube-state-metrics:IMAGE_TAG
        name: kube-state-metrics
        args:
        - --resource=pods
        - --node=$(NODE_NAME)
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              apiVersion: v1
              fieldPath: spec.nodeName
```

To track metrics for unassigned pods, you need to add an additional deployment and set `--track-unscheduled-pods`, as shown in the following example:

```
apiVersion: apps/v1
kind: Deployment
spec:
  template:
    spec:
      containers:
      - image: registry.k8s.io/kube-state-metrics/kube-state-metrics:IMAGE_TAG
        name: kube-state-metrics
        args:
        - --resources=pods
        - --track-unscheduled-pods
```

Other metrics can be sharded via [Horizontal sharding](#horizontal-sharding).

### Setup

Install this project to your `$GOPATH` using `go get`:

```
go get k8s.io/kube-state-metrics
```

#### Building the Docker container

Simply run the following command in this root folder, which will create a
self-contained, statically-linked binary and build a Docker image:

```
make container
```

### Usage

Simply build and run kube-state-metrics inside a Kubernetes pod which has a
service account token that has read-only access to the Kubernetes cluster.

#### For users of prometheus-operator/kube-prometheus stack

The ([`kube-prometheus`](https://github.com/prometheus-operator/kube-prometheus/)) stack installs kube-state-metrics as one of its [components](https://github.com/prometheus-operator/kube-prometheus#kube-prometheus); you do not need to install kube-state-metrics if you&#039;re using the kube-prometheus stack.

If you want to revise the default configuration for kube-prometheus, for example to enable non-default metrics, have a look at [Customizing Kube-Prometheus](https://github.com/prometheus-operator/kube-prometheus/blob/main/docs/customizing.md).

#### Kubernetes Deployment

To deploy this project, you can simply run `kubectl apply -f examples/standard` and a Kubernetes service and deployment will be created. (Note: Adjust the apiVersion of some resource if your kubernetes cluster&#039;s version is not 1.8+, check the yaml file for more information).

To have Prometheus discover kube-state-metrics instances it is advised to create a specific Prometheus scrape config for kube-state-metrics that picks up both metrics endpoints. Annotation based discovery is discouraged as only one of the endpoints would be able to be selected, plus kube-state-metrics in most cases has special authentication and authorization requirements as it essentially grants read access through the metrics endpoint to most information available to it.

**Note:** Google Kubernetes Engine (GKE) Users - GKE has strict role permissions that will prevent the kube-state-metrics roles and role bindings from being created. To work around this, you can give your GCP identity the cluster-admin role by running the following one-liner:

```
kubectl creat

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[docker/compose]]></title>
            <link>https://github.com/docker/compose</link>
            <guid>https://github.com/docker/compose</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[Define and run multi-container applications with Docker]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/compose">docker/compose</a></h1>
            <p>Define and run multi-container applications with Docker</p>
            <p>Language: Go</p>
            <p>Stars: 35,672</p>
            <p>Forks: 5,433</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># Table of Contents
- [Docker Compose v2](#docker-compose-v2)
- [Where to get Docker Compose](#where-to-get-docker-compose)
    + [Windows and macOS](#windows-and-macos)
    + [Linux](#linux)
- [Quick Start](#quick-start)
- [Contributing](#contributing)
- [Legacy](#legacy)
# Docker Compose v2

[![GitHub release](https://img.shields.io/github/v/release/docker/compose.svg?style=flat-square)](https://github.com/docker/compose/releases/latest)
[![PkgGoDev](https://img.shields.io/badge/go.dev-docs-007d9c?style=flat-square&amp;logo=go&amp;logoColor=white)](https://pkg.go.dev/github.com/docker/compose/v2)
[![Build Status](https://img.shields.io/github/actions/workflow/status/docker/compose/ci.yml?label=ci&amp;logo=github&amp;style=flat-square)](https://github.com/docker/compose/actions?query=workflow%3Aci)
[![Go Report Card](https://goreportcard.com/badge/github.com/docker/compose/v2?style=flat-square)](https://goreportcard.com/report/github.com/docker/compose/v2)
[![Codecov](https://codecov.io/gh/docker/compose/branch/main/graph/badge.svg?token=HP3K4Y4ctu)](https://codecov.io/gh/docker/compose)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/docker/compose/badge)](https://api.securityscorecards.dev/projects/github.com/docker/compose)
![Docker Compose](logo.png?raw=true &quot;Docker Compose Logo&quot;)

Docker Compose is a tool for running multi-container applications on Docker
defined using the [Compose file format](https://compose-spec.io).
A Compose file is used to define how one or more containers that make up
your application are configured.
Once you have a Compose file, you can create and start your application with a
single command: `docker compose up`.

# Where to get Docker Compose

### Windows and macOS

Docker Compose is included in
[Docker Desktop](https://www.docker.com/products/docker-desktop/)
for Windows and macOS.

### Linux

You can download Docker Compose binaries from the
[release page](https://github.com/docker/compose/releases) on this repository.

Rename the relevant binary for your OS to `docker-compose` and copy it to `$HOME/.docker/cli-plugins`

Or copy it into one of these folders to install it system-wide:

* `/usr/local/lib/docker/cli-plugins` OR `/usr/local/libexec/docker/cli-plugins`
* `/usr/lib/docker/cli-plugins` OR `/usr/libexec/docker/cli-plugins`

(might require making the downloaded file executable with `chmod +x`)


Quick Start
-----------

Using Docker Compose is a three-step process:
1. Define your app&#039;s environment with a `Dockerfile` so it can be
   reproduced anywhere.
2. Define the services that make up your app in `compose.yaml` so
   they can be run together in an isolated environment.
3. Lastly, run `docker compose up` and Compose will start and run your entire
   app.

A Compose file looks like this:

```yaml
services:
  web:
    build: .
    ports:
      - &quot;5000:5000&quot;
    volumes:
      - .:/code
  redis:
    image: redis
```

Contributing
------------

Want to help develop Docker Compose? Check out our
[contributing documentation](CONTRIBUTING.md).

If you find an issue, please report it on the
[issue tracker](https://github.com/docker/compose/issues/new/choose).

Legacy
-------------

The Python version of Compose is available under the `v1` [branch](https://github.com/docker/compose/tree/v1).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-collector]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-collector</link>
            <guid>https://github.com/open-telemetry/opentelemetry-collector</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[OpenTelemetry Collector]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-collector">open-telemetry/opentelemetry-collector</a></h1>
            <p>OpenTelemetry Collector</p>
            <p>Language: Go</p>
            <p>Stars: 5,335</p>
            <p>Forks: 1,661</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>---

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt;
    &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector/build-and-test.yml?branch=main&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/&quot;&gt;
    &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector?include_prereleases&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.bestpractices.dev/projects/8404&quot;&gt;&lt;img src=&quot;https://www.bestpractices.dev/projects/8404/badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&amp;can=1&amp;q=proj:opentelemetry&quot;&gt;
    &lt;img alt=&quot;Fuzzing Status&quot; src=&quot;https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry.svg&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;docs/vision.md&quot;&gt;Vision&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/configuration/&quot;&gt;Configuration&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector&quot;&gt;Monitoring&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://pkg.go.dev/go.opentelemetry.io/collector&quot;&gt;Package&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

---

# &lt;img src=&quot;https://opentelemetry.io/img/logos/opentelemetry-logo-nav.png&quot; alt=&quot;OpenTelemetry Icon&quot; width=&quot;45&quot; height=&quot;&quot;&gt; OpenTelemetry Collector

The OpenTelemetry Collector offers a vendor-agnostic implementation on how to
receive, process and export telemetry data. In addition, it removes the need
to run, operate and maintain multiple agents/collectors in order to support
open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to
multiple open-source or commercial back-ends.

Objectives:

- Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.
- Performant: Highly stable and performant under varying loads and configurations.
- Observable: An exemplar of an observable service.
- Extensible: Customizable without touching the core code.
- Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.

## Community

The OpenTelemetry Collector SIG is present at the [#otel-collector](https://cloud-native.slack.com/archives/C01N6P7KR6W)
channel on the CNCF Slack and [meets once a week](https://github.com/open-telemetry/community#implementation-sigs) via
video calls. Everyone is invited to join those calls, which typically serves the following purposes:

- meet the humans behind the project
- get an opinion about specific proposals
- look for a sponsor for a proposed component after trying already via GitHub and Slack
- get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously

We rotate our video calls between three time slots, in order to
allow everyone to join at least once every three meetings. The rotation order is as follows:

Tuesday:

- [17:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=1700)

Wednesday:

- [09:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0900)
- [05:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0500)

Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points.
Post a note in #otel-collector-dev on Slack inviting others, specifying the topic to be discussed. Unless there are strong
reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to
identify who would be the other contributors interested on that topic and in which timezones they are.

Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the
relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull
request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous
calls and don&#039;t want them to feel excluded.

## Supported OTLP version

This code base is currently built against using OTLP protocol v1.5.0,
considered Stable. [See the OpenTelemetry Protocol Stability
definition
here.](https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition)

## Stability levels

See [Stability Levels and versioning](docs/component-stability.md) for more details.

## Compatibility

When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as [defined by the Go team](https://go.dev/doc/devel/release#policy).
Removing support for an unsupported Go version is not considered a breaking change.

Support for Go versions on the OpenTelemetry Collector is updated as follows:

1. The first release after the release of a new Go minor version `N` will add build and tests steps for the new Go minor version.
2. The first release after the release of a new Go minor version `N` will remove support for Go version `N-2`.

Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.

## Verifying the images signatures

&gt; [!NOTE]
&gt; To verify a signed artifact or blob, first [install Cosign](https://docs.sigstore.dev/cosign/system_config/installation/), then follow the instructions below.

We are signing the images `otel/opentelemetry-collector` and `otel/opentelemetry-collector-contrib` using [sigstore cosign](https://github.com/sigstore/cosign) tool and to verify the signatures you can run the following command:

```console
$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/&lt;RELEASE_TAG&gt; \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  &lt;OTEL_COLLECTOR_IMAGE&gt;
```

where:

- `&lt;RELEASE_TAG&gt;`: is the release that you want to validate
- `&lt;OTEL_COLLECTOR_IMAGE&gt;`: is the image that you want to check

Example:

```console
$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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&quot;,&quot;integratedTime&quot;:1712809120,&quot;logIndex&quot;:84797936,&quot;logID&quot;:&quot;c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d&quot;}},&quot;Issuer&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;Subject&quot;:&quot;https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0&quot;,&quot;githubWorkflowName&quot;:&quot;Release Contrib&quot;,&quot;githubWorkflowRef&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;githubWorkflowRepository&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;githubWorkflowSha&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;githubWorkflowTrigger&quot;:&quot;push&quot;}},{&quot;critical&quot;:{&quot;identity&quot;:{&quot;docker-reference&quot;:&quot;ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib&quot;},&quot;image&quot;:{&quot;docker-manifest-digest&quot;:&quot;sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a&quot;},&quot;type&quot;:&quot;cosign container image signature&quot;},&quot;optional&quot;:{&quot;1.3.6.1.4.1.57264.1.1&quot;:&quot;https://token.actions.githubusercontent.com&quot;,&quot;1.3.6.1.4.1.57264.1.2&quot;:&quot;push&quot;,&quot;1.3.6.1.4.1.57264.1.3&quot;:&quot;9e20bf5c142e53070ccb8320a20315fffb41469e&quot;,&quot;1.3.6.1.4.1.57264.1.4&quot;:&quot;Release Contrib&quot;,&quot;1.3.6.1.4.1.57264.1.5&quot;:&quot;open-telemetry/opentelemetry-collector-releases&quot;,&quot;1.3.6.1.4.1.57264.1.6&quot;:&quot;refs/tags/v0.98.0&quot;,&quot;Bundle&quot;:{&quot;SignedEntryTimestamp&quot;:&quot;MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=&quot;,&quot;Payload&quot;:{&quot;body&quot;:&quot;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

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gorilla/websocket]]></title>
            <link>https://github.com/gorilla/websocket</link>
            <guid>https://github.com/gorilla/websocket</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[Package gorilla/websocket is a fast, well-tested and widely used WebSocket implementation for Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gorilla/websocket">gorilla/websocket</a></h1>
            <p>Package gorilla/websocket is a fast, well-tested and widely used WebSocket implementation for Go.</p>
            <p>Language: Go</p>
            <p>Stars: 23,699</p>
            <p>Forks: 3,556</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># Gorilla WebSocket

[![GoDoc](https://godoc.org/github.com/gorilla/websocket?status.svg)](https://godoc.org/github.com/gorilla/websocket)
[![CircleCI](https://circleci.com/gh/gorilla/websocket.svg?style=svg)](https://circleci.com/gh/gorilla/websocket)

Gorilla WebSocket is a [Go](http://golang.org/) implementation of the
[WebSocket](http://www.rfc-editor.org/rfc/rfc6455.txt) protocol.


### Documentation

* [API Reference](https://pkg.go.dev/github.com/gorilla/websocket?tab=doc)
* [Chat example](https://github.com/gorilla/websocket/tree/main/examples/chat)
* [Command example](https://github.com/gorilla/websocket/tree/main/examples/command)
* [Client and server example](https://github.com/gorilla/websocket/tree/main/examples/echo)
* [File watch example](https://github.com/gorilla/websocket/tree/main/examples/filewatch)

### Status

The Gorilla WebSocket package provides a complete and tested implementation of
the [WebSocket](http://www.rfc-editor.org/rfc/rfc6455.txt) protocol. The
package API is stable.

### Installation

    go get github.com/gorilla/websocket

### Protocol Compliance

The Gorilla WebSocket package passes the server tests in the [Autobahn Test
Suite](https://github.com/crossbario/autobahn-testsuite) using the application in the [examples/autobahn
subdirectory](https://github.com/gorilla/websocket/tree/main/examples/autobahn).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[casdoor/casdoor]]></title>
            <link>https://github.com/casdoor/casdoor</link>
            <guid>https://github.com/casdoor/casdoor</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[An open-source UI-first Identity and Access Management (IAM) / Single-Sign-On (SSO) platform with web UI supporting OAuth 2.0, OIDC, SAML, CAS, LDAP, SCIM, WebAuthn, TOTP, MFA, Face ID, RADIUS, Google Workspace, Active Directory and Kerberos]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/casdoor/casdoor">casdoor/casdoor</a></h1>
            <p>An open-source UI-first Identity and Access Management (IAM) / Single-Sign-On (SSO) platform with web UI supporting OAuth 2.0, OIDC, SAML, CAS, LDAP, SCIM, WebAuthn, TOTP, MFA, Face ID, RADIUS, Google Workspace, Active Directory and Kerberos</p>
            <p>Language: Go</p>
            <p>Stars: 11,771</p>
            <p>Forks: 1,372</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot; style=&quot;border-bottom: none;&quot;&gt;üì¶‚ö°Ô∏è Casdoor&lt;/h1&gt;
&lt;h3 align=&quot;center&quot;&gt;An open-source UI-first Identity and Access Management (IAM) / Single-Sign-On (SSO) platform with web UI supporting OAuth 2.0, OIDC, SAML, CAS, LDAP, SCIM, WebAuthn, TOTP, MFA and RADIUS&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#badge&quot;&gt;
    &lt;img alt=&quot;semantic-release&quot; src=&quot;https://img.shields.io/badge/%20%20%F0%9F%93%A6%F0%9F%9A%80-semantic--release-e10079.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/r/casbin/casdoor&quot;&gt;
    &lt;img alt=&quot;docker pull casbin/casdoor&quot; src=&quot;https://img.shields.io/docker/pulls/casbin/casdoor.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/casdoor/casdoor/actions/workflows/build.yml&quot;&gt;
    &lt;img alt=&quot;GitHub Workflow Status (branch)&quot; src=&quot;https://github.com/casdoor/casdoor/workflows/Build/badge.svg?style=flat-square&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/casdoor/casdoor/releases/latest&quot;&gt;
    &lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/casdoor/casdoor.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/r/casbin/casdoor&quot;&gt;
    &lt;img alt=&quot;Docker Image Version (latest semver)&quot; src=&quot;https://img.shields.io/badge/Docker%20Hub-latest-brightgreen&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/casdoor/casdoor&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/casdoor/casdoor?style=flat-square&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/casdoor/casdoor/blob/master/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/casdoor/casdoor?style=flat-square&quot; alt=&quot;license&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/casdoor/casdoor/issues&quot;&gt;
    &lt;img alt=&quot;GitHub issues&quot; src=&quot;https://img.shields.io/github/issues/casdoor/casdoor?style=flat-square&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;#&quot;&gt;
    &lt;img alt=&quot;GitHub stars&quot; src=&quot;https://img.shields.io/github/stars/casdoor/casdoor?style=flat-square&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/casdoor/casdoor/network&quot;&gt;
    &lt;img alt=&quot;GitHub forks&quot; src=&quot;https://img.shields.io/github/forks/casdoor/casdoor?style=flat-square&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://crowdin.com/project/casdoor-site&quot;&gt;
    &lt;img alt=&quot;Crowdin&quot; src=&quot;https://badges.crowdin.net/casdoor-site/localized.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/5rPsrAzK7S&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1022748306096537660?style=flat-square&amp;logo=discord&amp;label=discord&amp;color=5865F2&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;sup&gt;Sponsored by&lt;/sup&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://stytch.com/docs?utm_source=oss-sponsorship&amp;utm_medium=paid_sponsorship&amp;utm_campaign=casbin&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://cdn.casbin.org/img/stytch-white.png&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://cdn.casbin.org/img/stytch-charcoal.png&quot;&gt;
      &lt;img src=&quot;https://cdn.casbin.org/img/stytch-charcoal.png&quot; width=&quot;275&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;&lt;br/&gt;
  &lt;a href=&quot;https://stytch.com/docs?utm_source=oss-sponsorship&amp;utm_medium=paid_sponsorship&amp;utm_campaign=casbin&quot;&gt;&lt;b&gt;Build auth with fraud prevention, faster.&lt;/b&gt;&lt;br/&gt; Try Stytch for API-first authentication, user &amp; org management, multi-tenant SSO, MFA, device fingerprinting, and more.&lt;/a&gt;
  &lt;br&gt;
&lt;/p&gt;

## Online demo

- Read-only site: https://door.casdoor.com (any modification operation will fail)
- Writable site: https://demo.casdoor.com (original data will be restored for every 5 minutes)

## Documentation

https://casdoor.org

## Install

- By source code: https://casdoor.org/docs/basic/server-installation
- By Docker: https://casdoor.org/docs/basic/try-with-docker
- By Kubernetes Helm: https://casdoor.org/docs/basic/try-with-helm

## How to connect to Casdoor?

https://casdoor.org/docs/how-to-connect/overview

## Casdoor Public API

- Docs: https://casdoor.org/docs/basic/public-api
- Swagger: https://door.casdoor.com/swagger

## Integrations

https://casdoor.org/docs/category/integrations

## How to contact?

- Discord: https://discord.gg/5rPsrAzK7S
- Contact: https://casdoor.org/help

## Contribute

For casdoor, if you have any questions, you can give Issues, or you can also directly start Pull Requests(but we recommend giving issues first to communicate with the community).

### I18n translation

If you are contributing to casdoor, please note that we use [Crowdin](https://crowdin.com/project/casdoor-site) as translating platform and i18next as translating tool. When you add some words using i18next in the `web/` directory, please remember to add what you have added to the `web/src/locales/en/data.json` file.

## License

[Apache-2.0](https://github.com/casdoor/casdoor/blob/master/LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-go]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-go</link>
            <guid>https://github.com/open-telemetry/opentelemetry-go</guid>
            <pubDate>Thu, 26 Jun 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[OpenTelemetry Go API and SDK]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-go">open-telemetry/opentelemetry-go</a></h1>
            <p>OpenTelemetry Go API and SDK</p>
            <p>Language: Go</p>
            <p>Stars: 5,777</p>
            <p>Forks: 1,178</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># OpenTelemetry-Go

[![ci](https://github.com/open-telemetry/opentelemetry-go/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/open-telemetry/opentelemetry-go/actions/workflows/ci.yml)
[![codecov.io](https://codecov.io/gh/open-telemetry/opentelemetry-go/coverage.svg?branch=main)](https://app.codecov.io/gh/open-telemetry/opentelemetry-go?branch=main)
[![PkgGoDev](https://pkg.go.dev/badge/go.opentelemetry.io/otel)](https://pkg.go.dev/go.opentelemetry.io/otel)
[![Go Report Card](https://goreportcard.com/badge/go.opentelemetry.io/otel)](https://goreportcard.com/report/go.opentelemetry.io/otel)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/open-telemetry/opentelemetry-go/badge)](https://scorecard.dev/viewer/?uri=github.com/open-telemetry/opentelemetry-go)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/9996/badge)](https://www.bestpractices.dev/projects/9996)
[![Fuzzing Status](https://oss-fuzz-build-logs.storage.googleapis.com/badges/opentelemetry-go.svg)](https://issues.oss-fuzz.com/issues?q=project:opentelemetry-go)
[![FOSSA Status](https://app.fossa.com/api/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-go.svg?type=shield&amp;issueType=license)](https://app.fossa.com/projects/custom%2B162%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-go?ref=badge_shield&amp;issueType=license)
[![Slack](https://img.shields.io/badge/slack-@cncf/otel--go-brightgreen.svg?logo=slack)](https://cloud-native.slack.com/archives/C01NPAXACKT)

OpenTelemetry-Go is the [Go](https://golang.org/) implementation of [OpenTelemetry](https://opentelemetry.io/).
It provides a set of APIs to directly measure performance and behavior of your software and send this data to observability platforms.

## Project Status

| Signal  | Status             |
|---------|--------------------|
| Traces  | Stable             |
| Metrics | Stable             |
| Logs    | Beta[^1]           |

Progress and status specific to this repository is tracked in our
[project boards](https://github.com/open-telemetry/opentelemetry-go/projects)
and
[milestones](https://github.com/open-telemetry/opentelemetry-go/milestones).

Project versioning information and stability guarantees can be found in the
[versioning documentation](VERSIONING.md).

[^1]: https://github.com/orgs/open-telemetry/projects/43

### Compatibility

OpenTelemetry-Go ensures compatibility with the current supported versions of
the [Go language](https://golang.org/doc/devel/release#policy):

&gt; Each major Go release is supported until there are two newer major releases.
&gt; For example, Go 1.5 was supported until the Go 1.7 release, and Go 1.6 was supported until the Go 1.8 release.

For versions of Go that are no longer supported upstream, opentelemetry-go will
stop ensuring compatibility with these versions in the following manner:

- A minor release of opentelemetry-go will be made to add support for the new
  supported release of Go.
- The following minor release of opentelemetry-go will remove compatibility
  testing for the oldest (now archived upstream) version of Go. This, and
  future, releases of opentelemetry-go may include features only supported by
  the currently supported versions of Go.

Currently, this project supports the following environments.

| OS       | Go Version | Architecture |
|----------|------------|--------------|
| Ubuntu   | 1.24       | amd64        |
| Ubuntu   | 1.23       | amd64        |
| Ubuntu   | 1.24       | 386          |
| Ubuntu   | 1.23       | 386          |
| Ubuntu   | 1.24       | arm64        |
| Ubuntu   | 1.23       | arm64        |
| macOS 13 | 1.24       | amd64        |
| macOS 13 | 1.23       | amd64        |
| macOS    | 1.24       | arm64        |
| macOS    | 1.23       | arm64        |
| Windows  | 1.24       | amd64        |
| Windows  | 1.23       | amd64        |
| Windows  | 1.24       | 386          |
| Windows  | 1.23       | 386          |

While this project should work for other systems, no compatibility guarantees
are made for those systems currently.

## Getting Started

You can find a getting started guide on [opentelemetry.io](https://opentelemetry.io/docs/languages/go/getting-started/).

OpenTelemetry&#039;s goal is to provide a single set of APIs to capture distributed
traces and metrics from your application and send them to an observability
platform. This project allows you to do just that for applications written in
Go. There are two steps to this process: instrument your application, and
configure an exporter.

### Instrumentation

To start capturing distributed traces and metric events from your application
it first needs to be instrumented. The easiest way to do this is by using an
instrumentation library for your code. Be sure to check out [the officially
supported instrumentation
libraries](https://github.com/open-telemetry/opentelemetry-go-contrib/tree/main/instrumentation).

If you need to extend the telemetry an instrumentation library provides or want
to build your own instrumentation for your application directly you will need
to use the
[Go otel](https://pkg.go.dev/go.opentelemetry.io/otel)
package. The [examples](https://github.com/open-telemetry/opentelemetry-go-contrib/tree/main/examples)
are a good way to see some practical uses of this process.

### Export

Now that your application is instrumented to collect telemetry, it needs an
export pipeline to send that telemetry to an observability platform.

All officially supported exporters for the OpenTelemetry project are contained in the [exporters directory](./exporters).

| Exporter                              | Logs | Metrics | Traces |
|---------------------------------------|:----:|:-------:|:------:|
| [OTLP](./exporters/otlp/)             |  ‚úì   |    ‚úì    |   ‚úì    |
| [Prometheus](./exporters/prometheus/) |      |    ‚úì    |        |
| [stdout](./exporters/stdout/)         |  ‚úì   |    ‚úì    |   ‚úì    |
| [Zipkin](./exporters/zipkin/)         |      |         |   ‚úì    |

## Contributing

See the [contributing documentation](CONTRIBUTING.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>