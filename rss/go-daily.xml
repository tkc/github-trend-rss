<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Sat, 28 Feb 2026 00:05:49 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[DanielLavrushin/b4]]></title>
            <link>https://github.com/DanielLavrushin/b4</link>
            <guid>https://github.com/DanielLavrushin/b4</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:49 GMT</pubDate>
            <description><![CDATA[Network packet processor with a friendly UI for circumventing Deep Packet Inspection (DPI) systems.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DanielLavrushin/b4">DanielLavrushin/b4</a></h1>
            <p>Network packet processor with a friendly UI for circumventing Deep Packet Inspection (DPI) systems.</p>
            <p>Language: Go</p>
            <p>Stars: 838</p>
            <p>Forks: 30</p>
            <p>Stars today: 146 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[xpzouying/xiaohongshu-mcp]]></title>
            <link>https://github.com/xpzouying/xiaohongshu-mcp</link>
            <guid>https://github.com/xpzouying/xiaohongshu-mcp</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:48 GMT</pubDate>
            <description><![CDATA[MCP for xiaohongshu.com]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xpzouying/xiaohongshu-mcp">xpzouying/xiaohongshu-mcp</a></h1>
            <p>MCP for xiaohongshu.com</p>
            <p>Language: Go</p>
            <p>Stars: 9,454</p>
            <p>Forks: 1,476</p>
            <p>Stars today: 126 stars today</p>
            <h2>README</h2><pre># xiaohongshu-mcp

&lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt;
[![All Contributors](https://img.shields.io/badge/all_contributors-25-orange.svg?style=flat-square)](#contributors-)
&lt;!-- ALL-CONTRIBUTORS-BADGE:END --&gt;

[![å–„æ¬¾å·²æ](https://img.shields.io/badge/å–„æ¬¾å·²æ-CNY%201300.00-brightgreen?style=flat-square)](./DONATIONS.md)
[![çˆ±å¿ƒæ±‡èš](https://img.shields.io/badge/çˆ±å¿ƒæ±‡èš-CNY%201069.93-blue?style=flat-square)](./DONATIONS.md)
[![Docker Pulls](https://img.shields.io/docker/pulls/xpzouying/xiaohongshu-mcp?style=flat-square&amp;logo=docker)](https://hub.docker.com/r/xpzouying/xiaohongshu-mcp)

MCP for å°çº¢ä¹¦/xiaohongshu.comã€‚

- æˆ‘çš„åšå®¢æ–‡ç« ï¼š[haha.ai/xiaohongshu-mcp](https://www.haha.ai/xiaohongshu-mcp)

**é‡åˆ°ä»»ä½•é—®é¢˜ï¼ŒåŠ¡å¿…è¦å…ˆçœ‹ [å„ç§ç–‘éš¾æ‚ç—‡](https://github.com/xpzouying/xiaohongshu-mcp/issues/56)**ã€‚

ä¸Šé¢çš„ **ç–‘éš¾æ‚ç—‡** åˆ—è¡¨åï¼Œè¿˜æ˜¯è§£å†³ä¸äº†ä½ çš„éƒ¨ç½²é—®é¢˜ï¼Œé‚£ä¹ˆå¼ºçƒˆæ¨èä½¿ç”¨æˆ‘å†™çš„å¦å¤–ä¸€ä¸ªå·¥å…·ï¼š[xpzouying/x-mcp](https://github.com/xpzouying/x-mcp)ï¼Œè¿™ä¸ªå·¥å…·ä¸éœ€è¦ä½ è¿›è¡Œéƒ¨ç½²ï¼Œåªéœ€è¦é€šè¿‡æµè§ˆå™¨æ’ä»¶å°±èƒ½é©±åŠ¨ä½ çš„ MCPï¼Œå¯¹äºéæŠ€æœ¯åŒå­¦æ¥è¯´æ›´åŠ å‹å¥½ã€‚

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=xpzouying/xiaohongshu-mcp&amp;type=Timeline)](https://www.star-history.com/#xpzouying/xiaohongshu-mcp&amp;Timeline)

## èµèµæ”¯æŒ

æœ¬é¡¹ç›®æ‰€æœ‰çš„èµèµéƒ½ä¼šç”¨äºæ…ˆå–„æèµ ã€‚æ‰€æœ‰çš„æ…ˆå–„æèµ è®°å½•ï¼Œè¯·å‚è€ƒ [DONATIONS.md](./DONATIONS.md)ã€‚

**æèµ æ—¶ï¼Œè¯·å¤‡æ³¨ MCP ä»¥åŠåå­—ã€‚**
å¦‚éœ€æ›´æ­£/æ’¤å›ç½²åï¼Œè¯·å¼€ Issue æˆ–é€šè¿‡é‚®ç®±è”ç³»ã€‚

**æ”¯ä»˜å®ï¼ˆä¸å±•ç¤ºäºŒç»´ç ï¼‰ï¼š**

é€šè¿‡æ”¯ä»˜å®å‘ **xpzouying@gmail.com** èµèµã€‚

**å¾®ä¿¡ï¼š**

&lt;img src=&quot;donate/wechat@2x.png&quot; alt=&quot;WeChat Pay QR&quot; width=&quot;260&quot; /&gt;

## é¡¹ç›®ç®€ä»‹

**ä¸»è¦åŠŸèƒ½**

&gt; ğŸ’¡ **æç¤ºï¼š** ç‚¹å‡»ä¸‹æ–¹åŠŸèƒ½æ ‡é¢˜å¯å±•å¼€æŸ¥çœ‹è§†é¢‘æ¼”ç¤º

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;1. ç™»å½•å’Œæ£€æŸ¥ç™»å½•çŠ¶æ€&lt;/b&gt;&lt;/summary&gt;

ç¬¬ä¸€æ­¥å¿…é¡»ï¼Œå°çº¢ä¹¦éœ€è¦è¿›è¡Œç™»å½•ã€‚å¯ä»¥æ£€æŸ¥å½“å‰ç™»å½•çŠ¶æ€ã€‚

**ç™»å½•æ¼”ç¤ºï¼š**

https://github.com/user-attachments/assets/8b05eb42-d437-41b7-9235-e2143f19e8b7

**æ£€æŸ¥ç™»å½•çŠ¶æ€æ¼”ç¤ºï¼š**

https://github.com/user-attachments/assets/bd9a9a4a-58cb-4421-b8f3-015f703ce1f9

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;2. å‘å¸ƒå›¾æ–‡å†…å®¹&lt;/b&gt;&lt;/summary&gt;

æ”¯æŒå‘å¸ƒå›¾æ–‡å†…å®¹åˆ°å°çº¢ä¹¦ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€å†…å®¹æè¿°å’Œå›¾ç‰‡ã€‚

**å›¾ç‰‡æ”¯æŒæ–¹å¼ï¼š**

æ”¯æŒä¸¤ç§å›¾ç‰‡è¾“å…¥æ–¹å¼ï¼š

1. **HTTP/HTTPS å›¾ç‰‡é“¾æ¥**

   ```
   [&quot;https://example.com/image1.jpg&quot;, &quot;https://example.com/image2.png&quot;]
   ```

2. **æœ¬åœ°å›¾ç‰‡ç»å¯¹è·¯å¾„**ï¼ˆæ¨èï¼‰
   ```
   [&quot;/Users/username/Pictures/image1.jpg&quot;, &quot;/home/user/images/image2.png&quot;]
   ```

**ä¸ºä»€ä¹ˆæ¨èä½¿ç”¨æœ¬åœ°è·¯å¾„ï¼š**

- âœ… ç¨³å®šæ€§æ›´å¥½ï¼Œä¸ä¾èµ–ç½‘ç»œ
- âœ… ä¸Šä¼ é€Ÿåº¦æ›´å¿«
- âœ… é¿å…å›¾ç‰‡é“¾æ¥å¤±æ•ˆé—®é¢˜
- âœ… æ”¯æŒæ›´å¤šå›¾ç‰‡æ ¼å¼

**å‘å¸ƒå›¾æ–‡å¸–å­æ¼”ç¤ºï¼š**

https://github.com/user-attachments/assets/8aee0814-eb96-40af-b871-e66e6bbb6b06

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;3. å‘å¸ƒè§†é¢‘å†…å®¹&lt;/b&gt;&lt;/summary&gt;

æ”¯æŒå‘å¸ƒè§†é¢‘å†…å®¹åˆ°å°çº¢ä¹¦ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€å†…å®¹æè¿°å’Œæœ¬åœ°è§†é¢‘æ–‡ä»¶ã€‚

**è§†é¢‘æ”¯æŒæ–¹å¼ï¼š**

ä»…æ”¯æŒæœ¬åœ°è§†é¢‘æ–‡ä»¶ç»å¯¹è·¯å¾„ï¼š

```
&quot;/Users/username/Videos/video.mp4&quot;
```

**åŠŸèƒ½ç‰¹ç‚¹ï¼š**

- âœ… æ”¯æŒæœ¬åœ°è§†é¢‘æ–‡ä»¶ä¸Šä¼ 
- âœ… è‡ªåŠ¨å¤„ç†è§†é¢‘æ ¼å¼è½¬æ¢
- âœ… æ”¯æŒæ ‡é¢˜ã€å†…å®¹æè¿°å’Œæ ‡ç­¾
- âœ… ç­‰å¾…è§†é¢‘å¤„ç†å®Œæˆåè‡ªåŠ¨å‘å¸ƒ

**æ³¨æ„äº‹é¡¹ï¼š**

- ä»…æ”¯æŒæœ¬åœ°è§†é¢‘æ–‡ä»¶ï¼Œä¸æ”¯æŒ HTTP é“¾æ¥
- è§†é¢‘å¤„ç†æ—¶é—´è¾ƒé•¿ï¼Œè¯·è€å¿ƒç­‰å¾…
- å»ºè®®è§†é¢‘æ–‡ä»¶å¤§å°ä¸è¶…è¿‡ 1GB

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;4. æœç´¢å†…å®¹&lt;/b&gt;&lt;/summary&gt;

æ ¹æ®å…³é”®è¯æœç´¢å°çº¢ä¹¦å†…å®¹ã€‚

**æœç´¢å¸–å­æ¼”ç¤ºï¼š**

https://github.com/user-attachments/assets/03c5077d-6160-4b18-b629-2e40933a1fd3

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;5. è·å–æ¨èåˆ—è¡¨&lt;/b&gt;&lt;/summary&gt;

è·å–å°çº¢ä¹¦é¦–é¡µæ¨èå†…å®¹åˆ—è¡¨ã€‚

**è·å–æ¨èåˆ—è¡¨æ¼”ç¤ºï¼š**

https://github.com/user-attachments/assets/110fc15d-46f2-4cca-bdad-9de5b5b8cc28

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;6. è·å–å¸–å­è¯¦æƒ…ï¼ˆåŒ…æ‹¬äº’åŠ¨æ•°æ®å’Œè¯„è®ºï¼‰&lt;/b&gt;&lt;/summary&gt;

è·å–å°çº¢ä¹¦å¸–å­çš„å®Œæ•´è¯¦æƒ…ï¼ŒåŒ…æ‹¬ï¼š

- å¸–å­å†…å®¹ï¼ˆæ ‡é¢˜ã€æè¿°ã€å›¾ç‰‡ç­‰ï¼‰
- ç”¨æˆ·ä¿¡æ¯
- äº’åŠ¨æ•°æ®ï¼ˆç‚¹èµã€æ”¶è—ã€åˆ†äº«ã€è¯„è®ºæ•°ï¼‰
- è¯„è®ºåˆ—è¡¨åŠå­è¯„è®º

**âš ï¸ é‡è¦æç¤ºï¼š**

- éœ€è¦æä¾›å¸–å­ ID å’Œ xsec_tokenï¼ˆä¸¤ä¸ªå‚æ•°ç¼ºä¸€ä¸å¯ï¼‰
- è¿™ä¸¤ä¸ªå‚æ•°å¯ä»¥ä» Feed åˆ—è¡¨æˆ–æœç´¢ç»“æœä¸­è·å–
- å¿…é¡»å…ˆç™»å½•æ‰èƒ½ä½¿ç”¨æ­¤åŠŸèƒ½

**è·å–å¸–å­è¯¦æƒ…æ¼”ç¤ºï¼š**

https://github.com/user-attachments/assets/76a26130-a216-4371-a6b3-937b8fda092a

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;7. å‘è¡¨è¯„è®ºåˆ°å¸–å­&lt;/b&gt;&lt;/summary&gt;

æ”¯æŒè‡ªåŠ¨å‘è¡¨è¯„è®ºåˆ°å°çº¢ä¹¦å¸–å­ã€‚

**åŠŸèƒ½è¯´æ˜ï¼š**

- è‡ªåŠ¨å®šä½è¯„è®ºè¾“å…¥æ¡†
- è¾“å…¥è¯„è®ºå†…å®¹å¹¶å‘å¸ƒ
- æ”¯æŒ HTTP API å’Œ MCP å·¥å…·è°ƒç”¨

**âš ï¸ é‡è¦æç¤ºï¼š**

- éœ€è¦å…ˆç™»å½•æ‰èƒ½ä½¿ç”¨æ­¤åŠŸèƒ½
- éœ€è¦æä¾›å¸–å­ IDã€xsec_token å’Œè¯„è®ºå†…å®¹
- è¿™äº›å‚æ•°å¯ä»¥ä» Feed åˆ—è¡¨æˆ–æœç´¢ç»“æœä¸­è·å–

**å‘è¡¨è¯„è®ºæ¼”ç¤ºï¼š**

https://github.com/user-attachments/assets/cc385b6c-422c-489b-a5fc-63e92c695b80

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;8. è·å–ç”¨æˆ·ä¸ªäººä¸»é¡µ&lt;/b&gt;&lt;/summary&gt;

è·å–å°çº¢ä¹¦ç”¨æˆ·çš„ä¸ªäººä¸»é¡µä¿¡æ¯ï¼ŒåŒ…æ‹¬ç”¨æˆ·åŸºæœ¬ä¿¡æ¯å’Œç¬”è®°å†…å®¹ã€‚

**åŠŸèƒ½è¯´æ˜ï¼š**

- è·å–ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼ˆæ˜µç§°ã€ç®€ä»‹ã€å¤´åƒç­‰ï¼‰
- è·å–å…³æ³¨æ•°ã€ç²‰ä¸æ•°ã€è·èµé‡ç»Ÿè®¡
- è·å–ç”¨æˆ·å‘å¸ƒçš„ç¬”è®°å†…å®¹åˆ—è¡¨
- æ”¯æŒ HTTP API å’Œ MCP å·¥å…·è°ƒç”¨

**âš ï¸ é‡è¦æç¤ºï¼š**

- éœ€è¦å…ˆç™»å½•æ‰èƒ½ä½¿ç”¨æ­¤åŠŸèƒ½
- éœ€è¦æä¾›ç”¨æˆ· ID å’Œ xsec_token
- è¿™äº›å‚æ•°å¯ä»¥ä» Feed åˆ—è¡¨æˆ–æœç´¢ç»“æœä¸­è·å–

**è¿”å›ä¿¡æ¯åŒ…æ‹¬ï¼š**

- ç”¨æˆ·åŸºæœ¬ä¿¡æ¯ï¼šæ˜µç§°ã€ç®€ä»‹ã€å¤´åƒã€è®¤è¯çŠ¶æ€
- ç»Ÿè®¡æ•°æ®ï¼šå…³æ³¨æ•°ã€ç²‰ä¸æ•°ã€è·èµé‡ã€ç¬”è®°æ•°
- ç¬”è®°åˆ—è¡¨ï¼šç”¨æˆ·å‘å¸ƒçš„æ‰€æœ‰å…¬å¼€ç¬”è®°

&lt;/details&gt;

**å°çº¢ä¹¦åŸºç¡€è¿è¥çŸ¥è¯†**

- **æ ‡é¢˜ï¼šï¼ˆéå¸¸é‡è¦ï¼‰å°çº¢ä¹¦è¦æ±‚æ ‡é¢˜ä¸è¶…è¿‡ 20 ä¸ªå­—**
- **æ­£æ–‡ï¼šï¼ˆéå¸¸é‡è¦ï¼‰ï¼šæ­£æ–‡ä¸èƒ½è¶…è¿‡ 1000 ä¸ªå­—**
- å½“å‰æ”¯æŒå›¾æ–‡å‘é€ä»¥åŠè§†é¢‘å‘é€ï¼šä»æ¨èçš„è§’åº¦çœ‹ï¼Œå›¾æ–‡çš„æµé‡ä¼šæ¯”è§†é¢‘ä»¥åŠçº¯æ–‡å­—çš„æ›´å¥½ã€‚
- ï¼ˆä½ä¼˜å…ˆçº§ï¼‰å¯ä»¥è€ƒè™‘çº¯æ–‡å­—çš„æ”¯æŒã€‚1. ä¸ªäººæ„Ÿè§‰çº¯æ–‡å­—ä¼šå¤§å¤§å¢åŠ è¿è¥çš„å¤æ‚åº¦ï¼›2. çº¯æ–‡å­—åœ¨æˆ‘çš„ä½¿ç”¨åœºæ™¯çš„ä»·å€¼è¾ƒä½ã€‚
- Tagsï¼šç°å·²æ”¯æŒã€‚æ·»åŠ åˆé€‚çš„ Tags èƒ½å¸¦æ¥æ›´å¤šçš„æµé‡ã€‚
- æ ¹æ®æœ¬äººå®æ“ï¼Œå°çº¢ä¹¦æ¯å¤©çš„å‘å¸–é‡åº”è¯¥æ˜¯ **50 ç¯‡**ã€‚
- **ï¼ˆéå¸¸é‡è¦ï¼‰å°çº¢ä¹¦çš„åŒä¸€ä¸ªè´¦å·ä¸å…è®¸åœ¨å¤šä¸ªç½‘é¡µç«¯ç™»å½•**ï¼Œå¦‚æœä½ ç™»å½•äº†å½“å‰ xiaohongshu-mcp åï¼Œå°±ä¸è¦å†åœ¨å…¶ä»–çš„ç½‘é¡µç«¯ç™»å½•è¯¥è´¦å·ï¼Œå¦åˆ™å°±ä¼šæŠŠå½“å‰ MCP çš„è´¦å·â€œè¸¢å‡ºç™»å½•â€ã€‚ä½ å¯ä»¥ä½¿ç”¨ç§»åŠ¨ App ç«¯è¿›è¡ŒæŸ¥çœ‹å½“å‰è´¦å·ä¿¡æ¯ã€‚
- æ›å…‰ä½çš„è¯ï¼Œé¦–å…ˆæŸ¥çœ‹å†…å®¹ä¸­æ˜¯å¦æœ‰è¿ç¦è¯ï¼Œæœä¸€ä¸‹æœ‰å¾ˆå¤šç¬¬ä¸‰æ–¹å…è´¹å·¥å…·ã€‚
- ä¸€å®šä¸è¦å‡ºç°å¼•æµã€çº¯æ¬è¿çš„æƒ…å†µï¼Œå±äºå®˜æ–¹é‡ç‚¹æ‰“å‡»å¯¹è±¡ã€‚

**é£é™©è¯´æ˜**

1. è¯¥é¡¹ç›®æ˜¯åœ¨è‡ªå·±çš„å¦å¤–ä¸€ä¸ªé¡¹ç›®çš„åŸºç¡€ä¸Šå¼€æºå‡ºæ¥çš„ï¼ŒåŸæ¥çš„é¡¹ç›®ç¨³å®šè¿è¡Œä¸€å¹´å¤šï¼Œæ²¡æœ‰å‡ºç°è¿‡å°å·çš„æƒ…å†µï¼Œåªæœ‰å‡ºç°è¿‡ Cookies è¿‡æœŸéœ€è¦é‡æ–°ç™»å½•ã€‚
2. æˆ‘æ˜¯ä½¿ç”¨ Claude Code æ¥å…¥ï¼Œç¨³å®šè‡ªåŠ¨åŒ–è¿è¥æ•°å‘¨åï¼ŒéªŒè¯æ²¡æœ‰é—®é¢˜åå¼€æºã€‚
3. å¦‚æœè´¦å·æ²¡æœ‰å®åè®¤è¯ï¼Œç‰¹åˆ«æ˜¯æ–°å·ï¼Œä¸€èˆ¬ä¼šè§¦å‘ **å®åè®¤è¯** çš„æ¶ˆæ¯æé†’ï¼ˆå‚è§ä¸‹å›¾ï¼‰ã€‚âš ï¸ è¿™ä¸ªä¸æ˜¯å°å·ï¼Œä¸ç”¨ MCP ä¹Ÿä¼šè¦æ±‚å®åè®¤è¯ã€‚å®åè®¤è¯åï¼Œè´¦å·å°±æ­£å¸¸äº†ã€‚å»ºè®®ä½¿ç”¨è¯¥é¡¹ç›®å‰å°±å…ˆå®åã€‚
   &lt;img width=&quot;508&quot; height=&quot;306&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/34383e1b-f666-409f-9870-002655507dc1&quot; /&gt;

è¯¥é¡¹ç›®æ˜¯åŸºäºå­¦ä¹ çš„ç›®çš„ï¼Œç¦æ­¢ä¸€åˆ‡è¿æ³•è¡Œä¸ºã€‚

**å®æ“ç»“æœ**

ç¬¬ä¸€å¤©ç‚¹èµ/æ”¶è—æ•°è¾¾åˆ°äº† 999+ï¼Œ

&lt;img width=&quot;386&quot; height=&quot;278&quot; alt=&quot;CleanShot 2025-09-05 at 01 31 55@2x&quot; src=&quot;https://github.com/user-attachments/assets/4b5a283b-bd38-45b8-b608-8f818997366c&quot; /&gt;

&lt;img width=&quot;350&quot; height=&quot;280&quot; alt=&quot;CleanShot 2025-09-05 at 01 32 49@2x&quot; src=&quot;https://github.com/user-attachments/assets/4481e1e7-3ef6-4bbd-8483-dcee8f77a8f2&quot; /&gt;

ä¸€å‘¨å·¦å³çš„æˆæœ

&lt;img width=&quot;1840&quot; height=&quot;582&quot; alt=&quot;CleanShot 2025-09-05 at 01 33 13@2x&quot; src=&quot;https://github.com/user-attachments/assets/fb367944-dc48-4bbd-8ece-934caa86323e&quot; /&gt;

## 1. ä½¿ç”¨æ•™ç¨‹

### 1.1. å¿«é€Ÿå¼€å§‹ï¼ˆæ¨èï¼‰

**æ–¹å¼ä¸€ï¼šä¸‹è½½é¢„ç¼–è¯‘äºŒè¿›åˆ¶æ–‡ä»¶**

ç›´æ¥ä» [GitHub Releases](https://github.com/xpzouying/xiaohongshu-mcp/releases) ä¸‹è½½å¯¹åº”å¹³å°çš„äºŒè¿›åˆ¶æ–‡ä»¶ï¼š

**ä¸»ç¨‹åºï¼ˆMCP æœåŠ¡ï¼‰ï¼š**

- **macOS Apple Silicon**: `xiaohongshu-mcp-darwin-arm64`
- **macOS Intel**: `xiaohongshu-mcp-darwin-amd64`
- **Windows x64**: `xiaohongshu-mcp-windows-amd64.exe`
- **Linux x64**: `xiaohongshu-mcp-linux-amd64`

**ç™»å½•å·¥å…·ï¼š**

- **macOS Apple Silicon**: `xiaohongshu-login-darwin-arm64`
- **macOS Intel**: `xiaohongshu-login-darwin-amd64`
- **Windows x64**: `xiaohongshu-login-windows-amd64.exe`
- **Linux x64**: `xiaohongshu-login-linux-amd64`

ä½¿ç”¨æ­¥éª¤ï¼š

```bash
# 1. é¦–å…ˆè¿è¡Œç™»å½•å·¥å…·
chmod +x xiaohongshu-login-darwin-arm64
./xiaohongshu-login-darwin-arm64

# 2. ç„¶åå¯åŠ¨ MCP æœåŠ¡
chmod +x xiaohongshu-mcp-darwin-arm64
./xiaohongshu-mcp-darwin-arm64
```

**âš ï¸ é‡è¦æç¤º**ï¼šé¦–æ¬¡è¿è¡Œæ—¶ä¼šè‡ªåŠ¨ä¸‹è½½æ— å¤´æµè§ˆå™¨ï¼ˆçº¦ 150MBï¼‰ï¼Œè¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ã€‚åç»­è¿è¡Œæ— éœ€é‡å¤ä¸‹è½½ã€‚

**æ–¹å¼äºŒï¼šæºç ç¼–è¯‘**

&lt;details&gt;
&lt;summary&gt;æºç ç¼–è¯‘å®‰è£…è¯¦æƒ…&lt;/summary&gt;

ä¾èµ– Golang ç¯å¢ƒï¼Œå®‰è£…æ–¹æ³•è¯·å‚è€ƒ [Golang å®˜æ–¹æ–‡æ¡£](https://go.dev/doc/install)ã€‚

è®¾ç½® Go å›½å†…æºçš„ä»£ç†ï¼Œ

```bash
# é…ç½® GOPROXY ç¯å¢ƒå˜é‡ï¼Œä»¥ä¸‹ä¸‰é€‰ä¸€

# 1. ä¸ƒç‰› CDN
go env -w  GOPROXY=https://goproxy.cn,direct

# 2. é˜¿é‡Œäº‘
go env -w GOPROXY=https://mirrors.aliyun.com/goproxy/,direct

# 3. å®˜æ–¹
go env -w  GOPROXY=https://goproxy.io,direct
```

&lt;/details&gt;

**æ–¹å¼ä¸‰ï¼šä½¿ç”¨ Docker å®¹å™¨ï¼ˆæœ€ç®€å•ï¼‰**

&lt;details&gt;
&lt;summary&gt;Docker éƒ¨ç½²è¯¦æƒ…&lt;/summary&gt;

ä½¿ç”¨ Docker éƒ¨ç½²æ˜¯æœ€ç®€å•çš„æ–¹å¼ï¼Œæ— éœ€å®‰è£…ä»»ä½•å¼€å‘ç¯å¢ƒã€‚

**1. ä» Docker Hub æ‹‰å–é•œåƒï¼ˆæ¨èï¼‰**

æˆ‘ä»¬æä¾›äº†é¢„æ„å»ºçš„ Docker é•œåƒï¼Œå¯ä»¥ç›´æ¥ä» Docker Hub æ‹‰å–ä½¿ç”¨ï¼š

```bash
# æ‹‰å–æœ€æ–°é•œåƒ
docker pull xpzouying/xiaohongshu-mcp
```

Docker Hub åœ°å€ï¼š[https://hub.docker.com/r/xpzouying/xiaohongshu-mcp](https://hub.docker.com/r/xpzouying/xiaohongshu-mcp)

**2. ä½¿ç”¨ Docker Compose å¯åŠ¨ï¼ˆæ¨èï¼‰**

æˆ‘ä»¬æä¾›äº†é…ç½®å¥½çš„ `docker-compose.yml` æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š

```bash
# ä¸‹è½½ docker-compose.yml
wget https://raw.githubusercontent.com/xpzouying/xiaohongshu-mcp/main/docker/docker-compose.yml

# æˆ–è€…å¦‚æœå·²ç»å…‹éš†äº†é¡¹ç›®ï¼Œè¿›å…¥ docker ç›®å½•
cd docker

# å¯åŠ¨æœåŠ¡
docker compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker compose logs -f

# åœæ­¢æœåŠ¡
docker compose stop
```

**3. è‡ªå·±æ„å»ºé•œåƒï¼ˆå¯é€‰ï¼‰**

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•è¿è¡Œ
docker build -t xpzouying/xiaohongshu-mcp .
```

**4. é…ç½®è¯´æ˜**

Docker ç‰ˆæœ¬ä¼šè‡ªåŠ¨ï¼š

- é…ç½® Chrome æµè§ˆå™¨å’Œä¸­æ–‡å­—ä½“
- æŒ‚è½½ `./data` ç”¨äºå­˜å‚¨ cookies
- æŒ‚è½½ `./images` ç”¨äºå­˜å‚¨å‘å¸ƒçš„å›¾ç‰‡
- æš´éœ² 18060 ç«¯å£ä¾› MCP è¿æ¥

è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·å‚è€ƒï¼š[Docker éƒ¨ç½²æŒ‡å—](./docker/README.md)

&lt;/details&gt;

Windows é‡åˆ°é—®é¢˜é¦–å…ˆçœ‹è¿™é‡Œï¼š[Windows å®‰è£…æŒ‡å—](./docs/windows_guide.md)

### 1.2. ç™»å½•

ç¬¬ä¸€æ¬¡éœ€è¦æ‰‹åŠ¨ç™»å½•ï¼Œéœ€è¦ä¿å­˜å°çº¢ä¹¦çš„ç™»å½•çŠ¶æ€ã€‚

**ä½¿ç”¨äºŒè¿›åˆ¶æ–‡ä»¶**ï¼š

```bash
# è¿è¡Œå¯¹åº”å¹³å°çš„ç™»å½•å·¥å…·
./xiaohongshu-login-darwin-arm64
```

**ä½¿ç”¨æºç **ï¼š

```bash
go run cmd/login/main.go
```

### 1.3. å¯åŠ¨ MCP æœåŠ¡

å¯åŠ¨ xiaohongshu-mcp æœåŠ¡ã€‚

**ä½¿ç”¨äºŒè¿›åˆ¶æ–‡ä»¶**ï¼š

```bash
# é»˜è®¤ï¼šæ— å¤´æ¨¡å¼ï¼Œæ²¡æœ‰æµè§ˆå™¨ç•Œé¢
./xiaohongshu-mcp-darwin-arm64

# éæ— å¤´æ¨¡å¼ï¼Œæœ‰æµè§ˆå™¨ç•Œé¢
./xiaohongshu-mcp-darwin-arm64 -headless=false
```

**ä½¿ç”¨æºç **ï¼š

```bash
# é»˜è®¤ï¼šæ— å¤´æ¨¡å¼ï¼Œæ²¡æœ‰æµè§ˆå™¨ç•Œé¢
go run .

# éæ— å¤´æ¨¡å¼ï¼Œæœ‰æµè§ˆå™¨ç•Œé¢
go run . -headless=false
```

**é…ç½®ä»£ç†ï¼ˆå¯é€‰ï¼‰**ï¼š

å¦‚æœéœ€è¦é€šè¿‡ä»£ç†è®¿é—®ï¼Œå¯ä»¥è®¾ç½® `XHS_PROXY` ç¯å¢ƒå˜é‡ï¼š

```bash
# è®¾ç½®ä»£ç†åå¯åŠ¨
XHS_PROXY=http://user:pass@proxy:port ./xiaohongshu-mcp-darwin-arm64

# æˆ–ä½¿ç”¨æºç 
XHS_PROXY=http://proxy:port go run .
```

æ”¯æŒ HTTP/HTTPS/SOCKS5 ä»£ç†ï¼Œæ—¥å¿—ä¸­ä¼šè‡ªåŠ¨éšè—ä»£ç†çš„è®¤è¯ä¿¡æ¯ã€‚

## 1.4. éªŒè¯ MCP

```bash
npx @modelcontextprotocol/inspector
```

![è¿è¡Œ Inspector](./assets/run_inspect.png)

è¿è¡Œåï¼Œæ‰“å¼€çº¢è‰²æ ‡è®°çš„é“¾æ¥ï¼Œé…ç½® MCP inspectorï¼Œè¾“å…¥ `http://localhost:18060/mcp` ï¼Œç‚¹å‡» `Connect` æŒ‰é’®ã€‚

&lt;img width=&quot;915&quot; height=&quot;659&quot; alt=&quot;bf9532dd0b7ba423491accf511a467de&quot; src=&quot;https://github.com/user-attachments/assets/08bc3cef-73e7-42d2-b923-7ba9e6c8af30&quot; /&gt;

**æ³¨æ„ï¼š** å·¦ä¾§è¾¹æ¡†ä¸­çš„é€‰é¡¹æ˜¯å¦æ­£ç¡®ã€‚

æŒ‰ç…§ä¸Šé¢é…ç½® MCP inspector åï¼Œç‚¹å‡» `List Tools` æŒ‰é’®ï¼ŒæŸ¥çœ‹æ‰€æœ‰çš„ Toolsã€‚

## 1.5. ä½¿ç”¨ MCP å‘å¸ƒ

### æ£€æŸ¥ç™»å½•çŠ¶æ€

![æ£€æŸ¥ç™»å½•çŠ¶æ€](./assets/check_login.gif)

### å‘å¸ƒå›¾æ–‡

ç¤ºä¾‹ä¸­æ˜¯ä» https://unsplash.com/ ä¸­éšæœºæ‰¾äº†ä¸ªå›¾ç‰‡åšæµ‹è¯•ã€‚

![å‘å¸ƒå›¾æ–‡](./assets/inspect_mcp_publish.gif)

### æœç´¢å†…å®¹

ä½¿ç”¨æœç´¢åŠŸèƒ½ï¼Œæ ¹æ®å…³é”®è¯æœç´¢å°çº¢ä¹¦å†…å®¹ï¼š

![æœç´¢å†…å®¹](./assets/search_result.png)

## 2. MCP å®¢æˆ·ç«¯æ¥å…¥

æœ¬æœåŠ¡æ”¯æŒæ ‡å‡†çš„ Model Context Protocol (MCP)ï¼Œå¯ä»¥æ¥å…¥å„ç§æ”¯æŒ MCP çš„ AI å®¢æˆ·ç«¯ã€‚

### 2.1. å¿«é€Ÿå¼€å§‹

#### å¯åŠ¨ MCP æœåŠ¡

```bash
# å¯åŠ¨æœåŠ¡ï¼ˆé»˜è®¤æ— å¤´æ¨¡å¼ï¼‰
go run .

# æˆ–è€…æœ‰ç•Œé¢æ¨¡å¼
go run . -headless=false
```

æœåŠ¡å°†è¿è¡Œåœ¨ï¼š`http://localhost:18060/mcp`

#### éªŒè¯æœåŠ¡çŠ¶æ€

```bash
# æµ‹è¯• MCP è¿æ¥
curl -X POST http://localhost:18060/mcp \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{&quot;jsonrpc&quot;:&quot;2.0&quot;,&quot;method&quot;:&quot;initialize&quot;,&quot;params&quot;:{},&quot;id&quot;:1}&#039;
```

#### Claude Code CLI æ¥å…¥

```bash
# æ·»åŠ  HTTP MCP æœåŠ¡å™¨
claude mcp add --transport http xiaohongshu-mcp http://localhost:18060/mcp

# æ£€æŸ¥ MCP æ˜¯å¦æ·»åŠ æˆåŠŸï¼ˆç¡®ä¿ MCP å·²ç»å¯åŠ¨çš„å‰æä¸‹ï¼Œè¿è¡Œä¸‹é¢å‘½ä»¤ï¼‰
claude mcp list
```

### 2.2. æ”¯æŒçš„å®¢æˆ·ç«¯

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Claude Code CLI&lt;/b&gt;&lt;/summary&gt;

å®˜æ–¹å‘½ä»¤è¡Œå·¥å…·ï¼Œå·²åœ¨ä¸Šé¢å¿«é€Ÿå¼€å§‹éƒ¨åˆ†å±•ç¤ºï¼š

```bash
# æ·»åŠ  HTTP MCP æœåŠ¡å™¨
claude mcp add --transport http xiaohongshu-mcp http://localhost:18060/mcp

# æ£€æŸ¥ MCP æ˜¯å¦æ·»åŠ æˆåŠŸï¼ˆç¡®ä¿ MCP å·²ç»å¯åŠ¨çš„å‰æä¸‹ï¼Œè¿è¡Œä¸‹é¢å‘½ä»¤ï¼‰
claude mcp list
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Cursor&lt;/b&gt;&lt;/summary&gt;

#### é…ç½®æ–‡ä»¶çš„æ–¹å¼

åˆ›å»ºæˆ–ç¼–è¾‘ MCP é…ç½®æ–‡ä»¶ï¼š

**é¡¹ç›®çº§é…ç½®**ï¼ˆæ¨èï¼‰ï¼š
åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.cursor/mcp.json`ï¼š

```json
{
  &quot;mcpServers&quot;: {
    &quot;xiaohongshu-mcp&quot;: {
      &quot;url&quot;: &quot;http://localhost:18060/mcp&quot;,
      &quot;description&quot;: &quot;å°çº¢ä¹¦å†…å®¹å‘å¸ƒæœåŠ¡ - MCP Streamable HTTP&quot;
    }
  }
}
```

**å…¨å±€é…ç½®**ï¼š
åœ¨ç”¨æˆ·ç›®å½•åˆ›å»º `~/.cursor/mcp.json` (åŒæ ·å†…å®¹)ã€‚

#### ä½¿ç”¨æ­¥éª¤

1. ç¡®ä¿å°çº¢ä¹¦ MCP æœåŠ¡æ­£åœ¨è¿è¡Œ
2. ä¿å­˜é…ç½®æ–‡ä»¶åï¼Œé‡å¯ Cursor
3. åœ¨ Cursor èŠå¤©ä¸­ï¼Œå·¥å…·åº”è¯¥è‡ªåŠ¨å¯ç”¨
4. å¯ä»¥é€šè¿‡èŠå¤©ç•Œé¢çš„ &quot;Available Tools&quot; æŸ¥çœ‹å·²è¿æ¥çš„ MCP å·¥å…·

**Demo**

æ’ä»¶ MCP æ¥å…¥ï¼š

![cursor_mcp_settings](./assets/cursor_mcp_settings.png)

è°ƒç”¨ MCP å·¥å…·ï¼šï¼ˆä»¥æ£€æŸ¥ç™»å½•çŠ¶æ€ä¸ºä¾‹ï¼‰

![cursor_mcp_check_login](./assets/cursor_mcp_check_login.png)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;VSCode&lt;/b&gt;&lt;/summary&gt;

#### æ–¹æ³•ä¸€ï¼šä½¿ç”¨å‘½ä»¤é¢æ¿é…ç½®

1. æŒ‰ `Ctrl/Cmd + Shift + P` æ‰“å¼€å‘½ä»¤é¢æ¿
2. è¿è¡Œ `MCP: Add Server` å‘½ä»¤
3. é€‰æ‹© `HTTP` æ–¹å¼ã€‚
4. è¾“å…¥åœ°å€ï¼š `http://localhost:18060/mcp`ï¼Œæˆ–è€…ä¿®æ”¹æˆå¯¹åº”çš„ Server åœ°å€ã€‚
5. è¾“å…¥ MCP åå­—ï¼š `xiaohongshu-mcp`ã€‚

#### æ–¹æ³•äºŒï¼šç›´æ¥ç¼–è¾‘é…ç½®æ–‡ä»¶

**å·¥ä½œåŒºé…ç½®**ï¼ˆæ¨èï¼‰ï¼š
åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `.vscode/mcp.json`ï¼š

```json
{
  &quot;servers&quot;: {
    &quot;xiaohongshu-mcp&quot;: {
      &quot;url&quot;: &quot;http://localhost:18060/mcp&quot;,
      &quot;type&quot;: &quot;http&quot;
    }
  },
  &quot;inputs&quot;: []
}
```

**æŸ¥çœ‹é…ç½®**ï¼š

![vscode_config](./assets/vscode_mcp_config.png)

1. ç¡®è®¤è¿è¡ŒçŠ¶æ€ã€‚
2. æŸ¥çœ‹ `tools` æ˜¯å¦æ­£ç¡®æ£€æµ‹ã€‚

**Demo**

ä»¥æœç´¢å¸–å­å†…å®¹ä¸ºä¾‹ï¼š

![vscode_mcp_search](./assets/vscode_search_demo.png)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Google Gemini CLI&lt;/b&gt;&lt;/summary&gt;

åœ¨ `~/.gemini/settings.json` æˆ–é¡¹ç›®ç›®å½• `.gemini/settings.json` ä¸­é…ç½®ï¼š

```json
{
  &quot;mcpServers&quot;: {
    &quot;xiaohongshu&quot;: {
      &quot;httpUrl&quot;: &quot;http://localhost:18060/mcp&quot;,
      &quot;timeout&quot;: 30000
    }
  }
}
```

æ›´å¤šä¿¡æ¯è¯·å‚è€ƒ [Gemini CLI MCP æ–‡æ¡£](https://google-gemini.github.io/gemini-cli/docs/tools/mcp-server.html)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;MCP Inspector&lt;/b&gt;&lt;/summary&gt;

è°ƒè¯•å·¥å…·ï¼Œç”¨äºæµ‹è¯• MCP è¿æ¥ï¼š

```bash
# å¯åŠ¨ MCP Inspector
npx @modelcontextprotocol/inspector

# åœ¨æµè§ˆå™¨ä¸­è¿æ¥åˆ°ï¼šhttp://localhost:18060/mcp
```

ä½¿ç”¨æ­¥éª¤ï¼š

- ä½¿ç”¨ MCP Inspector æµ‹è¯•è¿æ¥
- æµ‹è¯• Ping Server åŠŸèƒ½éªŒè¯è¿æ¥
- æ£€æŸ¥ List Tools æ˜¯å¦è¿”å› 6 ä¸ªå·¥å…·

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Cline&lt;/b&gt;&lt;/summary&gt;

Cline æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ AI ç¼–ç¨‹åŠ©æ‰‹ï¼Œæ”¯æŒ MCP åè®®é›†æˆã€‚

#### é…ç½®æ–¹æ³•

åœ¨ Cline çš„ MCP è®¾ç½®ä¸­æ·»åŠ ä»¥ä¸‹é…ç½®ï¼š

```json
{
  &quot;xiaohongshu-mcp&quot;: {
    &quot;url&quot;: &quot;http://localhost:18060/mcp&quot;,
    &quot;type&quot;: &quot;streamableHttp&quot;,
    &quot;autoApprove&quot;: [],
    &quot;disabled&quot;: false
  }
}
```

#### ä½¿ç”¨æ­¥éª¤

1. ç¡®ä¿å°çº¢ä¹¦ MCP æœåŠ¡æ­£åœ¨è¿è¡Œï¼ˆ`http://localhost:18060/mcp`ï¼‰
2. åœ¨ Cline ä¸­æ‰“å¼€ MCP è®¾ç½®
3. æ·»åŠ ä¸Šè¿°é…ç½®åˆ° MCP æœåŠ¡å™¨åˆ—è¡¨
4. ä¿å­˜é…ç½®å¹¶é‡å¯ Cline
5. åœ¨å¯¹è¯ä¸­å¯ä»¥ç›´æ¥ä½¿ç”¨å°çº¢ä¹¦ç›¸å…³åŠŸèƒ½

#### é…ç½®è¯´æ˜

- `url`: MCP æœåŠ¡åœ°å€
- `type`: ä½¿ç”¨ `streamableHttp` ç±»å‹ä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½
- `autoApprove`: å¯é…ç½®è‡ªåŠ¨æ‰¹å‡†çš„å·¥å…·åˆ—è¡¨ï¼ˆç•™ç©ºè¡¨ç¤ºæ‰‹åŠ¨æ‰¹å‡†ï¼‰
- `disabled`: è®¾ç½®ä¸º `false` å¯ç”¨æ­¤ MCP æœåŠ¡

#### ä½¿ç”¨ç¤ºä¾‹

é…ç½®å®Œæˆåï¼Œå¯ä»¥åœ¨ Cline ä¸­ç›´æ¥ä½¿ç”¨è‡ªç„¶è¯­è¨€æ“ä½œå°çº¢ä¹¦ï¼š

```
å¸®æˆ‘æ£€æŸ¥å°çº¢ä¹¦ç™»å½•çŠ¶æ€
```

```
å¸®æˆ‘å‘å¸ƒä¸€ç¯‡å…³äºæ˜¥å¤©çš„å›¾æ–‡åˆ°å°çº¢ä¹¦ï¼Œä½¿ç”¨è¿™å¼ å›¾ç‰‡ï¼š/path/to/spring.jpg
```

```
æœç´¢å°çº¢ä¹¦ä¸Šå…³äº&quot;ç¾é£Ÿ&quot;çš„å†…å®¹
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;å…¶ä»–æ”¯æŒ HTTP MCP çš„å®¢æˆ·ç«¯&lt;/b&gt;&lt;/summary&gt;

ä»»ä½•æ”¯æŒ HTTP MCP åè®®çš„å®¢æˆ·ç«¯éƒ½å¯ä»¥è¿æ¥åˆ°ï¼š`http://localhost:18060/mcp`

åŸºæœ¬é…ç½®æ¨¡æ¿ï¼š

```json
{
  &quot;name&quot;: &quot;xiaohongshu-mcp&quot;,
  &quot;url&quot;: &quot;http://localhost:18060/mcp&quot;,
  &quot;type&quot;: &quot;http&quot;
}
```

&lt;/details&gt;

### 2.3. å¯ç”¨ MCP å·¥å…·

è¿æ¥æˆåŠŸåï¼Œå¯ä½¿ç”¨ä»¥ä¸‹ MCP å·¥å…·ï¼š

- `check_login_status` - æ£€æŸ¥å°çº¢ä¹¦ç™»å½•çŠ¶æ€ï¼ˆæ— å‚æ•°ï¼‰
- `publish_content` - å‘å¸ƒå›¾æ–‡å†…å®¹åˆ°å°çº¢ä¹¦ï¼ˆå¿…éœ€ï¼štitle, content, imagesï¼‰
  - `images`: æ”¯æŒ HTTP é“¾æ¥æˆ–æœ¬åœ°ç»å¯¹è·¯å¾„ï¼Œæ¨èä½¿ç”¨æœ¬åœ°è·¯å¾„
- `publish_with_video` - å‘å¸ƒè§†é¢‘å†…å®¹åˆ°å°çº¢ä¹¦ï¼ˆå¿…éœ€ï¼štitle, content, videoï¼‰
  - `video`: ä»…æ”¯æŒæœ¬åœ°è§†é¢‘æ–‡ä»¶ç»å¯¹è·¯å¾„
- `list_feeds` - è·å–å°çº¢ä¹¦é¦–é¡µæ¨èåˆ—è¡¨ï¼ˆæ— å‚æ•°ï¼‰
- `search_feeds` - æœç´¢å°çº¢ä¹¦å†…å®¹ï¼ˆéœ€è¦ï¼škeywordï¼‰
- `get_feed_detail` - è·å–å¸–å­è¯¦æƒ…ï¼ˆéœ€è¦ï¼šfeed_id, xsec_tokenï¼‰
- `post_comment_to_feed` - å‘è¡¨è¯„è®ºåˆ°å°çº¢ä¹¦å¸–å­ï¼ˆéœ€è¦ï¼šfeed_id, xsec_token, contentï¼‰
- `user_profile` - è·å–ç”¨æˆ·ä¸ªäººä¸»é¡µä¿¡æ¯ï¼ˆéœ€è¦ï¼šuser_id, xsec_tokenï¼‰

### 2.4. ä½¿ç”¨ç¤ºä¾‹

ä½¿ç”¨ Claude Code å‘å¸ƒå†…å®¹åˆ°å°çº¢ä¹¦ï¼š

**ç¤ºä¾‹ 1ï¼šä½¿ç”¨ HTTP å›¾ç‰‡é“¾æ¥**

```
å¸®æˆ‘å†™ä¸€ç¯‡å¸–å­å‘å¸ƒåˆ°å°çº¢ä¹¦ä¸Šï¼Œ
é…å›¾ä¸ºï¼šhttps://cn.bing.com/th?id=OHR.MaoriRock_EN-US6499689741_UHD.jpg&amp;w=3840
å›¾ç‰‡æ˜¯ï¼š&quot;çº½è¥¿å…°é™¶æ³¢æ¹–çš„NgÄtoroirangiçŸ¿æ¹¾æ¯›åˆ©å²©é›•ï¼ˆÂ© Joppi/Getty Imagesï¼‰&quot;

ä½¿ç”¨ xiaohongshu-mcp è¿›è¡Œå‘å¸ƒã€‚
```

**ç¤ºä¾‹ 2ï¼šä½¿ç”¨æœ¬åœ°å›¾ç‰‡è·¯å¾„ï¼ˆæ¨èï¼‰**

```
å¸®æˆ‘å†™ä¸€ç¯‡å…³äºæ˜¥å¤©çš„å¸–å­å‘å¸ƒåˆ°å°çº¢ä¹¦ä¸Šï¼Œ
ä½¿ç”¨è¿™äº›æœ¬åœ°å›¾ç‰‡ï¼š
- /Users/username/Pictures/spring_flowers.jpg
- /Users/username/Pictures/cherry_blossom.jpg

ä½¿ç”¨ xiaohongshu-mcp è¿›è¡Œå‘å¸ƒã€‚
```

**ç¤ºä¾‹ 3ï¼šå‘å¸ƒè§†é¢‘å†…å®¹**

```
å¸®æˆ‘å†™ä¸€ç¯‡å…³äºç¾é£Ÿåˆ¶ä½œçš„è§†é¢‘å‘å¸ƒåˆ°å°çº¢ä¹¦ä¸Šï¼Œ
ä½¿ç”¨è¿™ä¸ªæœ¬åœ°è§†é¢‘æ–‡ä»¶ï¼š
- /Users/username/Videos/cooking_tutorial.mp4

ä½¿ç”¨ xiaohongshu-mcp çš„è§†é¢‘å‘å¸ƒåŠŸèƒ½ã€‚
```

![claude-cli è¿›è¡Œå‘å¸ƒ](./assets/claude_push.gif)

**å‘å¸ƒç»“æœï¼š**

&lt;img src=&quot;./assets/publish_result.jpeg&quot; alt=&quot;xiaohongshu-mcp å‘å¸ƒç»“æœ&quot; width=&quot;300&quot;&gt;

### 2.5. ğŸ’¬ MCP ä½¿ç”¨å¸¸è§é—®é¢˜è§£ç­”

---

**Q:** ä¸ºä»€ä¹ˆæ£€æŸ¥ç™»å½•ç”¨æˆ·åæ˜¾ç¤º `xiaghgngshu-mcp`ï¼Ÿ
**A:** ç”¨æˆ·åæ˜¯å†™æ­»çš„ã€‚

---

**Q:** æ˜¾ç¤ºå‘å¸ƒæˆåŠŸåï¼Œä½†å®é™…ä¸Šæ²¡æœ‰æ˜¾ç¤ºï¼Ÿ
**A:** æ’æŸ¥æ­¥éª¤å¦‚ä¸‹ï¼š

1. ä½¿ç”¨ **éæ— å¤´æ¨¡å¼** é‡æ–°å‘å¸ƒä¸€æ¬¡ã€‚
2. æ›´æ¢ **ä¸åŒçš„å†…å®¹** é‡æ–°å‘å¸ƒã€‚
3. ç™»å½•ç½‘é¡µç‰ˆå°çº¢ä¹¦ï¼ŒæŸ¥çœ‹è´¦å·æ˜¯å¦è¢« **é£æ§é™åˆ¶ç½‘é¡µç‰ˆå‘å¸ƒ**ã€‚
4. æ£€æŸ¥ **å›¾ç‰‡å¤§å°** æ˜¯å¦è¿‡å¤§ã€‚
5. ç¡®è®¤ **å›¾ç‰‡è·¯å¾„ä¸­æ²¡æœ‰ä¸­æ–‡å­—ç¬¦**ã€‚
6. è‹¥ä½¿ç”¨ç½‘ç»œå›¾ç‰‡åœ°å€ï¼Œè¯·ç¡®è®¤ **å›¾ç‰‡é“¾æ¥å¯æ­£å¸¸è®¿é—®**ã€‚

---

**Q:** åœ¨è®¾å¤‡ä¸Šè¿è¡Œ MCP ç¨‹åºå‡ºç°é—ªé€€å¦‚ä½•è§£å†³ï¼Ÿ
**A:**

1. å»ºè®® **ä»æºç å®‰è£…**ã€‚
2. æˆ–ä½¿ç”¨ **Docker å®‰è£… xiaohongshu-mcp**ï¼Œæ•™ç¨‹å‚è€ƒï¼š
   - [ä½¿ç”¨ Docker å®‰è£… xiaohongshu-mcp](https://github.com/xpzouying/xiaohongshu-mcp#:~:text=%E6%96%B9%E5%BC%8F%E4%B8%89%EF%BC%9A%E4%BD%BF%E7%94%A8%20Docker%20%E5%AE%B9%E5%99%A8%EF%BC%88%E6%9C%80%E7%AE%80%E5%8D%95%EF%BC%89)
   - [X-MCP é¡¹ç›®é¡µé¢](https://github.com/xpzouying/x-mcp/)

---

**Q:** ä½¿ç”¨ `http://localhost:18060/mcp` è¿›è¡Œ MCP éªŒè¯æ—¶æç¤ºæ— æ³•è¿æ¥ï¼Ÿ
**A:**

- åœ¨ **Docker ç¯å¢ƒ** ä¸‹ï¼Œè¯·ä½¿ç”¨
  ğŸ‘‰ [http://host.docker.internal:18060/mcp](http://host.docker.internal:18060/mcp)
- åœ¨ **é Docker ç¯å¢ƒ** ä¸‹ï¼Œè¯·ä½¿ç”¨ **æœ¬æœº IPv4 åœ°å€** è®¿é—®ã€‚

---

## 3. ğŸŒŸ å®æˆ˜æ¡ˆä¾‹å±•ç¤º (Community Showcases)

&gt; ğŸ’¡ **å¼ºçƒˆæ¨èæŸ¥çœ‹**ï¼šè¿™äº›éƒ½æ˜¯ç¤¾åŒºè´¡çŒ®è€…çš„çœŸå®ä½¿ç”¨æ¡ˆä¾‹ï¼ŒåŒ…å«è¯¦ç»†çš„é…ç½®æ­¥éª¤å’Œå®æˆ˜ç»éªŒï¼

### ğŸ“š å®Œæ•´æ•™ç¨‹åˆ—è¡¨

1. **[n8n å®Œæ•´é›†æˆæ•™ç¨‹](./examples/n8n/README.md)** - å·¥ä½œæµè‡ªåŠ¨åŒ–å¹³å°é›†æˆ
2. **[Cherry Studio å®Œæ•´é…ç½®æ•™ç¨‹](./examples/cherrystudio/README.md)** - AI å®¢æˆ·ç«¯å®Œç¾æ¥å…¥
3. **[Claude Code + Kimi K2 æ¥å…¥æ•™ç¨‹](./examples/claude-code/claude-code-kimi-k2.md)** - Claude Code é—¨æ§›å¤ªé«˜ï¼Œé‚£ä¹ˆå°±æ¥å…¥ Kimi å›½äº§å¤§æ¨¡å‹å§ï½
4. **[AnythingLLM å®Œæ•´æŒ‡å—](./examples/anythingLLM/readme.md)** - AnythingLLM æ˜¯ä¸€æ¬¾ all-in-one å¤šæ¨¡æ€ AI å®¢æˆ·ç«¯ï¼Œæ”¯æŒ workflow å®šä¹‰ï¼Œæ”¯æŒå¤šç§å¤§æ¨¡å‹å’Œæ’ä»¶æ‰©å±•ã€‚

&gt; ğŸ¯ **æç¤º**: ç‚¹å‡»ä¸Šæ–¹é“¾æ¥æŸ¥çœ‹è¯¦ç»†çš„å›¾æ–‡æ•™ç¨‹ï¼Œå¿«é€Ÿä¸Šæ‰‹å„ç§é›†æˆæ–¹æ¡ˆï¼
&gt;
&gt; ğŸ“¢ **æ¬¢è¿è´¡çŒ®**: å¦‚æœä½ æœ‰æ–°çš„é›†æˆæ¡ˆä¾‹ï¼Œæ¬¢è¿æäº¤ PR åˆ†äº«ç»™ç¤¾åŒºï¼

## 4. å°çº¢ä¹¦ MCP äº’åŠ©ç¾¤

**é‡è¦ï¼šåœ¨ç¾¤é‡Œé—®é—®é¢˜ä¹‹å‰ï¼Œè¯·ä¸€å®šè¦å…ˆä»”ç»†çœ‹å®Œ README æ–‡æ¡£ä»¥åŠæŸ¥çœ‹ Issuesã€‚**

### å¾®ä¿¡ç¾¤

|                                                 ã€å¾®ä¿¡ç¾¤ 15 ç¾¤ã€‘ï¼šæ‰«ç è¿›å…¥                                                 |
| :------------------------------------------------------------------------------------------------------------------------: |
| &lt;img src=&quot;https://github.com/user-attachments/assets/73e23573-9ac1-414d-9192-f592548e9092&quot; alt=&quot;WechatIMG119&quot; width=&quot;300&quot;&gt; |

### é£ä¹¦ç¾¤

|                                                         é£ä¹¦ 1 ç¾¤                                                         |                                                         é£ä¹¦ 2 ç¾¤                                                         |                                                         é£ä¹¦ 3 ç¾¤                                                         |                                                         é£ä¹¦ 4 ç¾¤                                                         |
| :-----------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------: |
| &lt;img src=&quot;https://github.com/user-attachments/assets/65579771-3543-4661-9b48-def48eed609b&quot; alt=&quot;qr-feishu01&quot; width=&quot;260&quot;&gt; | &lt;img src=&quot;https://github.com/user-attachments/assets/4983ea42-ce5b-4e26-a8c0-33889093b579&quot; alt=&quot;qr-feishu02&quot; width=&quot;260&quot;&gt; | &lt;img src=&quot;https://github.com/user-attachments/assets/c77b45da-6028-4d3a-b421-ccc6c7210695&quot; alt=&quot;qr-feishu03&quot; width=&quot;260&quot;&gt; | &lt;img src=&quot;https://github.com/user-attachments/assets/c42f5595-71cd-4d9b-b7f8-0c333bd25e2b&quot; alt=&quot;qr-feishu04&quot; width=&quot;260&quot;&gt; |

&gt; **æ³¨æ„ï¼š**
&gt;
&gt; 1. å¾®ä¿¡ç¾¤çš„äºŒç»´ç æœ‰æ—¶é—´é™åˆ¶ï¼Œæœ‰æ—¶å€™å¿˜è®°æ›´æ–°ï¼Œéº»çƒ¦ç­‰å¾…æ›´æ–°æˆ–è€…æäº¤ Issue å‚¬æˆ‘æ›´æ–°ã€‚
&gt; 2. é£ä¹¦ç¾¤ï¼Œå¦‚æœæœ‰çš„ç¾¤æ»¡äº†ï¼Œå¯ä»¥å°è¯•æ‰«ä¸€ä¸‹å¦å¤–ä¸€ä¸ªç¾¤ï¼Œæ€»æœ‰å‘ä½ã€‚

## ğŸ™ è‡´è°¢è´¡çŒ®è€… âœ¨

æ„Ÿè°¢ä»¥ä¸‹æ‰€æœ‰ä¸ºæœ¬é¡¹ç›®åšå‡ºè´¡çŒ®çš„æœ‹å‹ï¼ï¼ˆæ’åä¸åˆ†å…ˆåï¼‰

&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://haha.ai&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/3946563?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;zy&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;zy&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/xpzouying/xiaohongshu-mcp/commits?author=xpzouying&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt; &lt;a href=&quot;#ideas-xpzouying&quot; title=&quot;Ideas, Planning, &amp; Feedback&quot;&gt;ğŸ¤”&lt;/a&gt; &lt;a href=&quot;https://github.com/xpzouying/xiaohongshu-mcp/commits?author=xpzouying&quot; title=&quot;Documentation&quot;&gt;ğŸ“–&lt;/a&gt; &lt;a href=&quot;#design-xpzouying&quot; title=&quot;Design&quot;&gt;ğŸ¨&lt;/a&gt; &lt;a href=&quot;#maintenance-xpzouying&quot; title=&quot;Maintenance&quot;&gt;ğŸš§&lt;/a&gt; &lt;a href=&quot;#infra-xpzouying&quot; title=&quot;Infrastructure (Hosting, Build-Tools, etc)&quot;&gt;ğŸš‡&lt;/a&gt; &lt;a href=&quot;https://github.com/xpzouying/xiaohongshu-mcp/pulls?q=is%3Apr+reviewed-by%3Axpzouying&quot; title=&quot;Reviewed Pull Requests&quot;&gt;ğŸ‘€&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;http://www.hwbuluo.com&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/1271815?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;clearwater&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;clearwater&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/xpzouying/xiaohongshu-mcp/commits?author=esperyong&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/laryzhong&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47939471?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Zhongpeng&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Zhongpeng&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/xpzouying/xiaohongshu-mcp/commits?author=laryzhong&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/DTDucas&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/105262836?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Duong Tran&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Duong Tran&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/xpzouying/xiaohongshu-mcp/commits?author=DTDucas&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Angiin&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/17389304?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Angiin&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Angiin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/xpzouying/xiaohongshu-mcp/commits?author=Angiin&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/muhenan&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/43441941?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Henan Mu&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Henan Mu&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/xpzouying/xiaohongshu-mcp/commits?author=muhenan&quot; title=&quot;Code&quot;&gt;ğŸ’»&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[wavetermdev/waveterm]]></title>
            <link>https://github.com/wavetermdev/waveterm</link>
            <guid>https://github.com/wavetermdev/waveterm</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:47 GMT</pubDate>
            <description><![CDATA[An open-source, cross-platform terminal for seamless workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wavetermdev/waveterm">wavetermdev/waveterm</a></h1>
            <p>An open-source, cross-platform terminal for seamless workflows</p>
            <p>Language: Go</p>
            <p>Stars: 17,562</p>
            <p>Forks: 784</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.waveterm.dev&quot;&gt;
	&lt;picture&gt;
		&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./assets/wave-dark.png&quot;&gt;
		&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./assets/wave-light.png&quot;&gt;
		&lt;img alt=&quot;Wave Terminal Logo&quot; src=&quot;./assets/wave-light.png&quot; width=&quot;240&quot;&gt;
	&lt;/picture&gt;
  &lt;/a&gt;
  &lt;br/&gt;
&lt;/p&gt;

# Wave Terminal

&lt;div align=&quot;center&quot;&gt;

[English](README.md) | [í•œêµ­ì–´](README.ko.md)

&lt;/div&gt;

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Fwavetermdev%2Fwaveterm?ref=badge_shield)

Wave is an open-source, AI-integrated terminal for macOS, Linux, and Windows. It works with any AI model. Bring your own API keys for OpenAI, Claude, or Gemini, or run local models via Ollama and LM Studio. No accounts required.

Wave also supports durable SSH sessions that survive network interruptions and restarts, with automatic reconnection. Edit remote files with a built-in graphical editor and preview files inline without leaving the terminal.

![WaveTerm Screenshot](./assets/wave-screenshot.webp)

## Key Features

- Wave AI - Context-aware terminal assistant that reads your terminal output, analyzes widgets, and performs file operations
- Durable SSH Sessions - Remote terminal sessions survive connection interruptions, network changes, and Wave restarts with automatic reconnection
- Flexible drag &amp; drop interface to organize terminal blocks, editors, web browsers, and AI assistants
- Built-in editor for editing remote files with syntax highlighting and modern editor features
- Rich file preview system for remote files (markdown, images, video, PDFs, CSVs, directories)
- Quick full-screen toggle for any block - expand terminals, editors, and previews for better visibility, then instantly return to multi-block view
- AI chat widget with support for multiple models (OpenAI, Claude, Azure, Perplexity, Ollama)
- Command Blocks for isolating and monitoring individual commands
- One-click remote connections with full terminal and file system access
- Secure secret storage using native system backends - store API keys and credentials locally, access them across SSH sessions
- Rich customization including tab themes, terminal styles, and background images
- Powerful `wsh` command system for managing your workspace from the CLI and sharing data between terminal sessions
- Connected file management with `wsh file` - seamlessly copy and sync files between local and remote SSH hosts

## Wave AI

Wave AI is your context-aware terminal assistant with access to your workspace:

- **Terminal Context**: Reads terminal output and scrollback for debugging and analysis
- **File Operations**: Read, write, and edit files with automatic backups and user approval
- **CLI Integration**: Use `wsh ai` to pipe output or attach files directly from the command line
- **BYOK Support**: Bring your own API keys for OpenAI, Claude, Gemini, Azure, and other providers
- **Local Models**: Run local models with Ollama, LM Studio, and other OpenAI-compatible providers
- **Free Beta**: Included AI credits while we refine the experience
- **Coming Soon**: Command execution (with approval)

Learn more in our [Wave AI documentation](https://docs.waveterm.dev/waveai) and [Wave AI Modes documentation](https://docs.waveterm.dev/waveai-modes).

## Installation

Wave Terminal works on macOS, Linux, and Windows.

Platform-specific installation instructions can be found [here](https://docs.waveterm.dev/gettingstarted).

You can also install Wave Terminal directly from: [www.waveterm.dev/download](https://www.waveterm.dev/download).

### Minimum requirements

Wave Terminal runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 1809 or later (x64)
- Linux based on glibc-2.28 or later (Debian 10, RHEL 8, Ubuntu 20.04, etc.) (arm64, x64)

The WSH helper runs on the following platforms:

- macOS 11 or later (arm64, x64)
- Windows 10 or later (x64)
- Linux Kernel 2.6.32 or later (x64), Linux Kernel 3.1 or later (arm64)

## Roadmap

Wave is constantly improving! Our roadmap will be continuously updated with our goals for each release. You can find it [here](./ROADMAP.md).

Want to provide input to our future releases? Connect with us on [Discord](https://discord.gg/XfvZ334gwU) or open a [Feature Request](https://github.com/wavetermdev/waveterm/issues/new/choose)!

## Links

- Homepage &amp;mdash; https://www.waveterm.dev
- Download Page &amp;mdash; https://www.waveterm.dev/download
- Documentation &amp;mdash; https://docs.waveterm.dev
- X &amp;mdash; https://x.com/wavetermdev
- Discord Community &amp;mdash; https://discord.gg/XfvZ334gwU

## Building from Source

See [Building Wave Terminal](BUILD.md).

## Contributing

Wave uses GitHub Issues for issue tracking.

Find more information in our [Contributions Guide](CONTRIBUTING.md), which includes:

- [Ways to contribute](CONTRIBUTING.md#contributing-to-wave-terminal)
- [Contribution guidelines](CONTRIBUTING.md#before-you-start)

## License

Wave Terminal is licensed under the Apache-2.0 License. For more information on our dependencies, see [here](./ACKNOWLEDGEMENTS.md).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Tencent/WeKnora]]></title>
            <link>https://github.com/Tencent/WeKnora</link>
            <guid>https://github.com/Tencent/WeKnora</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:46 GMT</pubDate>
            <description><![CDATA[LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Tencent/WeKnora">Tencent/WeKnora</a></h1>
            <p>LLM-powered framework for deep document understanding, semantic retrieval, and context-aware answers using RAG paradigm.</p>
            <p>Language: Go</p>
            <p>Stars: 13,147</p>
            <p>Forks: 1,514</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;./docs/images/logo.png&quot; alt=&quot;WeKnora Logo&quot; height=&quot;120&quot;/&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/15289&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://trendshift.io/api/badge/repositories/15289&quot; alt=&quot;Tencent%2FWeKnora | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
    &lt;/a&gt;
  &lt;/picture&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://weknora.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;å®˜æ–¹ç½‘ç«™&quot; src=&quot;https://img.shields.io/badge/å®˜æ–¹ç½‘ç«™-WeKnora-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://chatbot.weixin.qq.com&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;å¾®ä¿¡å¯¹è¯å¼€æ”¾å¹³å°&quot; src=&quot;https://img.shields.io/badge/å¾®ä¿¡å¯¹è¯å¼€æ”¾å¹³å°-5ac725&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/Tencent/WeKnora/blob/main/LICENSE&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/License-MIT-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;License&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;./CHANGELOG.md&quot;&gt;
        &lt;img alt=&quot;Version&quot; src=&quot;https://img.shields.io/badge/version-0.3.0-2e6cc4?labelColor=d4eaf7&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
| &lt;b&gt;English&lt;/b&gt; | &lt;a href=&quot;./README_CN.md&quot;&gt;&lt;b&gt;ç®€ä½“ä¸­æ–‡&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;./README_JA.md&quot;&gt;&lt;b&gt;æ—¥æœ¬èª&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;h4 align=&quot;center&quot;&gt;

  [Overview](#-overview) â€¢ [Architecture](#-architecture) â€¢ [Key Features](#-key-features) â€¢ [Getting Started](#-getting-started) â€¢ [API Reference](#-api-reference) â€¢ [Developer Guide](#-developer-guide)
  
  &lt;/h4&gt;
&lt;/p&gt;

# ğŸ’¡ WeKnora - LLM-Powered Document Understanding &amp; Retrieval Framework

## ğŸ“Œ Overview

[**WeKnora**](https://weknora.weixin.qq.com) is an LLM-powered framework designed for deep document understanding and semantic retrieval, especially for handling complex, heterogeneous documents. 

It adopts a modular architecture that combines multimodal preprocessing, semantic vector indexing, intelligent retrieval, and large language model inference. At its core, WeKnora follows the **RAG (Retrieval-Augmented Generation)** paradigm, enabling high-quality, context-aware answers by combining relevant document chunks with model reasoning.

**Website:** https://weknora.weixin.qq.com

## âœ¨ Latest Updates

**v0.3.0 Highlights:**

- ğŸ¢ **Shared Space**: Shared space with member invitations, shared knowledge bases and agents across members, tenant-isolated retrieval
- ğŸ§© **Agent Skills**: Agent skills system with preloaded skills for smart-reasoning agent, sandboxed execution environment for security isolation
- ğŸ¤– **Custom Agents**: Support for creating, configuring, and selecting custom agents with knowledge base selection modes (all/specified/disabled)
- ğŸ“Š **Data Analyst Agent**: Built-in Data Analyst agent with DataSchema tool for CSV/Excel analysis
- ğŸ§  **Thinking Mode**: Support thinking mode for LLM and agents, intelligent filtering of thinking content
- ğŸ” **Web Search Providers**: Added Bing and Google search providers alongside DuckDuckGo
- ğŸ“‹ **Enhanced FAQ**: Batch import dry run, similar questions, matched question in search results, large imports offloaded to object storage
- ğŸ”‘ **API Key Auth**: API Key authentication mechanism with Swagger documentation security
- ğŸ“ **In-Input Selection**: Select knowledge bases and files directly in the input box with @mention display
- â˜¸ï¸ **Helm Chart**: Complete Helm chart for Kubernetes deployment with Neo4j GraphRAG support
- ğŸŒ **i18n**: Added Korean (í•œêµ­ì–´) language support
- ğŸ”’ **Security Hardening**: SSRF-safe HTTP client, enhanced SQL validation, MCP stdio transport security, sandbox-based execution
- âš¡ **Infrastructure**: Qdrant vector DB support, Redis ACL, configurable log level, Ollama embedding optimization, `DISABLE_REGISTRATION` control

**v0.2.0 Highlights:**

- ğŸ¤– **Agent Mode**: New ReACT Agent mode that can call built-in tools, MCP tools, and web search, providing comprehensive summary reports through multiple iterations and reflection
- ğŸ“š **Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with new features including folder import, URL import, tag management, and online entry
- âš™ï¸ **Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior
- ğŸŒ **Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine
- ğŸ”Œ **MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods
- ğŸ¨ **New UI**: Optimized conversation interface with Agent mode/normal mode switching, tool call process display, and comprehensive knowledge base management interface upgrade
- âš¡ **Infrastructure Upgrade**: Introduced MQ async task management, support for automatic database migration, and fast development mode

## ğŸ”’ Security Notice

**Important:** Starting from v0.1.3, WeKnora includes login authentication functionality to enhance system security. For production deployments, we strongly recommend:

- Deploy WeKnora services in internal/private network environments rather than public internet
- Avoid exposing the service directly to public networks to prevent potential information leakage
- Configure proper firewall rules and access controls for your deployment environment
- Regularly update to the latest version for security patches and improvements

## ğŸ—ï¸ Architecture

![weknora-architecture.png](./docs/images/architecture.png)

WeKnora employs a modern modular design to build a complete document understanding and retrieval pipeline. The system primarily includes document parsing, vector processing, retrieval engine, and large model inference as core modules, with each component being flexibly configurable and extendable.

## ğŸ¯ Key Features

- **ğŸ¤– Agent Mode**: Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, MCP tools, and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection
- **ğŸ” Precise Understanding**: Structured content extraction from PDFs, Word documents, images and more into unified semantic views
- **ğŸ§  Intelligent Reasoning**: Leverages LLMs to understand document context and user intent for accurate Q&amp;A and multi-turn conversations
- **ğŸ“š Multi-Type Knowledge Bases**: Support for FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry capabilities
- **ğŸ”§ Flexible Extension**: All components from parsing and embedding to retrieval and generation are decoupled for easy customization
- **âš¡ Efficient Retrieval**: Hybrid retrieval strategies combining keywords, vectors, and knowledge graphs, with cross-knowledge base retrieval support
- **ğŸŒ Web Search**: Support for extensible web search engines with built-in DuckDuckGo search engine
- **ğŸ”Œ MCP Tool Integration**: Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting multiple transport methods
- **âš™ï¸ Conversation Strategy**: Support for configuring Agent models, normal mode models, retrieval thresholds, and Prompts, with precise control over multi-turn conversation behavior
- **ğŸ¯ User-Friendly**: Intuitive web interface and standardized APIs for zero technical barriers
- **ğŸ”’ Secure &amp; Controlled**: Support for local deployment and private cloud, ensuring complete data sovereignty

## ğŸ“Š Application Scenarios

| Scenario | Applications | Core Value |
|---------|----------|----------|
| **Enterprise Knowledge Management** | Internal document retrieval, policy Q&amp;A, operation manual search | Improve knowledge discovery efficiency, reduce training costs |
| **Academic Research Analysis** | Paper retrieval, research report analysis, scholarly material organization | Accelerate literature review, assist research decisions |
| **Product Technical Support** | Product manual Q&amp;A, technical documentation search, troubleshooting | Enhance customer service quality, reduce support burden |
| **Legal &amp; Compliance Review** | Contract clause retrieval, regulatory policy search, case analysis | Improve compliance efficiency, reduce legal risks |
| **Medical Knowledge Assistance** | Medical literature retrieval, treatment guideline search, case analysis | Support clinical decisions, improve diagnosis quality |

## ğŸ§© Feature Matrix

| Module | Support                                                                        | Description                                                                                                                                                        |
|---------|--------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Agent Mode | âœ… ReACT Agent Mode                                                             | Support for using built-in tools to retrieve knowledge bases, MCP tools, and web search, with cross-knowledge base retrieval and multiple iterations               |
| Knowledge Base Types | âœ… FAQ / Document                                                               | Support for creating FAQ and document knowledge base types, with folder import, URL import, tag management, and online entry                                       |
| Document Formats | âœ… PDF / Word / Txt / Markdown / Images (with OCR / Caption)                    | Support for structured and unstructured documents with text extraction from images                                                                                 |
| Model Management | âœ… Centralized configuration, built-in model sharing                            | Centralized model configuration with model selection in knowledge base settings, support for multi-tenant shared built-in models                                   |
| Embedding Models | âœ… Local models, BGE / GTE APIs, etc.                                           | Customizable embedding models, compatible with local deployment and cloud vector generation APIs                                                                   |
| Vector DB Integration | âœ… PostgreSQL (pgvector), Elasticsearch                                         | Support for mainstream vector index backends, flexible switching for different retrieval scenarios                                                                 |
| Retrieval Strategies | âœ… BM25 / Dense Retrieval / GraphRAG                                            | Support for sparse/dense recall and knowledge graph-enhanced retrieval with customizable retrieve-rerank-generate pipelines                                        |
| LLM Integration | âœ… Support for Qwen, DeepSeek, etc., with thinking/non-thinking mode switching  | Compatible with local models (e.g., via Ollama) or external API services with flexible inference configuration                                                     |
| Conversation Strategy | âœ… Agent models, normal mode models, retrieval thresholds, Prompt configuration | Support for configuring Agent models, normal mode models, retrieval thresholds, online Prompt configuration, precise control over multi-turn conversation behavior |
| Web Search | âœ… Extensible search engines, DuckDuckGo / Google                               | Support for extensible web search engines with built-in DuckDuckGo search engine                                                                                   |
| MCP Tools | âœ… uvx, npx launchers, Stdio/HTTP Streamable/SSE                                | Support for extending Agent capabilities through MCP, with built-in uvx and npx launchers, supporting three transport methods                                      |
| QA Capabilities | âœ… Context-aware, multi-turn dialogue, prompt templates                         | Support for complex semantic modeling, instruction control and chain-of-thought Q&amp;A with configurable prompts and context windows                                  |
| E2E Testing | âœ… Retrieval+generation process visualization and metric evaluation             | End-to-end testing tools for evaluating recall hit rates, answer coverage, BLEU/ROUGE and other metrics                                                            |
| Deployment Modes | âœ… Support for local deployment / Docker images                                 | Meets private, offline deployment and flexible operation requirements, with fast development mode support                                                          |
| User Interfaces | âœ… Web UI + RESTful API                                                         | Interactive interface and standard API endpoints, with Agent mode/normal mode switching and tool call process display                                              |
| Task Management | âœ… MQ async tasks, automatic database migration                                 | MQ-based async task state maintenance, support for automatic database schema and data migration during version upgrades                                            |

## ğŸš€ Getting Started

### ğŸ›  Prerequisites

Make sure the following tools are installed on your system:

* [Docker](https://www.docker.com/)
* [Docker Compose](https://docs.docker.com/compose/)
* [Git](https://git-scm.com/)

### ğŸ“¦ Installation

#### â‘  Clone the repository

```bash
# Clone the main repository
git clone https://github.com/Tencent/WeKnora.git
cd WeKnora
```

#### â‘¡ Configure environment variables

```bash
# Copy example env file
cp .env.example .env

# Edit .env and set required values
# All variables are documented in the .env.example comments
```

#### â‘¢ Start the services (include Ollama)

Check the images that need to be started in the .env file.

```bash
./scripts/start_all.sh
```

or

```bash
make start-all
```

#### â‘¢.0 Start ollama services (Optional)

```bash
ollama serve &gt; /dev/null 2&gt;&amp;1 &amp;
```

#### â‘¢.1 Activate different combinations of features

- Minimum core services
```bash
docker compose up -d
```

- All features enabled
```bash
docker-compose --profile full up -d
```

- Tracing logs required
```bash
docker-compose --profile jaeger up -d
```

- Neo4j knowledge graph required
```bash
docker-compose --profile neo4j up -d
```

- Minio file storage service required
```bash
docker-compose --profile minio up -d
```

- Multiple options combination
```bash
docker-compose --profile neo4j --profile minio up -d
```

#### â‘£ Stop the services

```bash
./scripts/start_all.sh --stop
# Or
make stop-all
```

### ğŸŒ Access Services

Once started, services will be available at:

* Web UI: `http://localhost`
* Backend API: `http://localhost:8080`
* Jaeger Tracing: `http://localhost:16686`

### ğŸ”Œ Using WeChat Dialog Open Platform

WeKnora serves as the core technology framework for the [WeChat Dialog Open Platform](https://chatbot.weixin.qq.com), providing a more convenient usage approach:

- **Zero-code Deployment**: Simply upload knowledge to quickly deploy intelligent Q&amp;A services within the WeChat ecosystem, achieving an &quot;ask and answer&quot; experience
- **Efficient Question Management**: Support for categorized management of high-frequency questions, with rich data tools to ensure accurate, reliable, and easily maintainable answers
- **WeChat Ecosystem Integration**: Through the WeChat Dialog Open Platform, WeKnora&#039;s intelligent Q&amp;A capabilities can be seamlessly integrated into WeChat Official Accounts, Mini Programs, and other WeChat scenarios, enhancing user interaction experiences

### ğŸ”— Access WeKnora via MCP Server

#### 1ï¸âƒ£ Clone the repository
```
git clone https://github.com/Tencent/WeKnora
```

#### 2ï¸âƒ£ Configure MCP Server
&gt; It is recommended to directly refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for configuration.

Configure the MCP client to connect to the server:
```json
{
  &quot;mcpServers&quot;: {
    &quot;weknora&quot;: {
      &quot;args&quot;: [
        &quot;path/to/WeKnora/mcp-server/run_server.py&quot;
      ],
      &quot;command&quot;: &quot;python&quot;,
      &quot;env&quot;:{
        &quot;WEKNORA_API_KEY&quot;:&quot;Enter your WeKnora instance, open developer tools, check the request header x-api-key starting with sk&quot;,
        &quot;WEKNORA_BASE_URL&quot;:&quot;http(s)://your-weknora-address/api/v1&quot;
      }
    }
  }
}
```

Run directly using stdio command:
```
pip install weknora-mcp-server
python -m weknora-mcp-server
```

## ğŸ”§ Initialization Configuration Guide

To help users quickly configure various models and reduce trial-and-error costs, we&#039;ve improved the original configuration file initialization method by adding a Web UI interface for model configuration. Before using, please ensure the code is updated to the latest version. The specific steps are as follows:
If this is your first time using this project, you can skip steps â‘ â‘¡ and go directly to steps â‘¢â‘£.

### â‘  Stop the services

```bash
./scripts/start_all.sh --stop
```

### â‘¡ Clear existing data tables (recommended when no important data exists)

```bash
make clean-db
```

### â‘¢ Compile and start services

```bash
./scripts/start_all.sh
```

### â‘£ Access Web UI

http://localhost

On your first visit, you will be automatically redirected to the registration/login page. After completing registration, please create a new knowledge base and finish the relevant settings on its configuration page.

## ğŸ“± Interface Showcase

### Web UI Interface

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;b&gt;Knowledge Base Management&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/knowledgebases.png&quot; alt=&quot;Knowledge Base Management&quot;&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;Conversation Settings&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/settings.png&quot; alt=&quot;Conversation Settings&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td colspan=&quot;2&quot;&gt;&lt;b&gt;Agent Mode Tool Call Process&lt;/b&gt;&lt;br/&gt;&lt;img src=&quot;./docs/images/agent-qa.png&quot; alt=&quot;Agent Mode Tool Call Process&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

**Knowledge Base Management:** Support for creating FAQ and document knowledge base types, with multiple import methods including drag-and-drop, folder import, and URL import. Automatically identifies document structures and extracts core knowledge to establish indexes. Supports tag management and online entry. The system clearly displays processing progress and document status, achieving efficient knowledge base management.

**Agent Mode:** Support for ReACT Agent mode that can use built-in tools to retrieve knowledge bases, call user-configured MCP tools and web search tools to access external services, providing comprehensive summary reports through multiple iterations and reflection. Supports cross-knowledge base retrieval, allowing selection of multiple knowledge bases for simultaneous retrieval.

**Conversation Strategy:** Support for configuring Agent models, normal mode models, retrieval thresholds, and online Prompt configuration, with precise control over multi-turn conversation behavior and retrieval execution methods. The conversation input box supports Agent mode/normal mode switching, enabling/disabling web search, and selecting conversation models.

### Document Knowledge Graph

WeKnora supports transforming documents into knowledge graphs, displaying the relationships between different sections of the documents. Once the knowledge graph feature is enabled, the system analyzes and constructs an internal semantic association network that not only helps users understand document content but also provides structured support for indexing and retrieval, enhancing the relevance and breadth of search results.

For detailed configuration, please refer to the [Knowledge Graph Configuration Guide](./docs/KnowledgeGraph.md).

### MCP Server

Please refer to the [MCP Configuration Guide](./mcp-server/MCP_CONFIG.md) for the necessary setup.

## ğŸ“˜ API Reference

Troubleshooting FAQ: [Troubleshooting FAQ](./docs/QA.md)

Detailed API documentation is available at: [API Docs](./docs/api/README.md)

Product plans and upcoming features: [Roadmap](./docs/ROADMAP.md)

## ğŸ§­ Developer Guide

### âš¡ Fast Development Mode (Recommended)

I

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ollama/ollama]]></title>
            <link>https://github.com/ollama/ollama</link>
            <guid>https://github.com/ollama/ollama</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:45 GMT</pubDate>
            <description><![CDATA[Get up and running with Kimi-K2.5, GLM-5, MiniMax, DeepSeek, gpt-oss, Qwen, Gemma and other models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ollama/ollama">ollama/ollama</a></h1>
            <p>Get up and running with Kimi-K2.5, GLM-5, MiniMax, DeepSeek, gpt-oss, Qwen, Gemma and other models.</p>
            <p>Language: Go</p>
            <p>Stars: 163,618</p>
            <p>Forks: 14,695</p>
            <p>Stars today: 122 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ollama.com&quot;&gt;
    &lt;img src=&quot;https://github.com/ollama/ollama/assets/3325447/0d0b44e2-8f4a-4e99-9b52-a5c1c741c8f7&quot; alt=&quot;ollama&quot; width=&quot;200&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

# Ollama

Start building with open models.

## Download

### macOS

```shell
curl -fsSL https://ollama.com/install.sh | sh
```

or [download manually](https://ollama.com/download/Ollama.dmg)

### Windows

```shell
irm https://ollama.com/install.ps1 | iex
```

or [download manually](https://ollama.com/download/OllamaSetup.exe)

### Linux

```shell
curl -fsSL https://ollama.com/install.sh | sh
```

[Manual install instructions](https://docs.ollama.com/linux#manual-install)

### Docker

The official [Ollama Docker image](https://hub.docker.com/r/ollama/ollama) `ollama/ollama` is available on Docker Hub.

### Libraries

- [ollama-python](https://github.com/ollama/ollama-python)
- [ollama-js](https://github.com/ollama/ollama-js)

### Community

- [Discord](https://discord.gg/ollama)
- [ğ• (Twitter)](https://x.com/ollama)
- [Reddit](https://reddit.com/r/ollama)

## Get started

```
ollama
```

You&#039;ll be prompted to run a model or connect Ollama to your existing agents or applications such as `claude`, `codex`, `openclaw` and more.

### Coding

To launch a specific integration:

```
ollama launch claude
```

Supported integrations include [Claude Code](https://docs.ollama.com/integrations/claude-code), [Codex](https://docs.ollama.com/integrations/codex), [Droid](https://docs.ollama.com/integrations/droid), and [OpenCode](https://docs.ollama.com/integrations/opencode).

### AI assistant

Use [OpenClaw](https://docs.ollama.com/integrations/openclaw) to turn Ollama into a personal AI assistant across WhatsApp, Telegram, Slack, Discord, and more:

```
ollama launch openclaw
```

### Chat with a model

Run and chat with [Gemma 3](https://ollama.com/library/gemma3):

```
ollama run gemma3
```

See [ollama.com/library](https://ollama.com/library) for the full list.

See the [quickstart guide](https://docs.ollama.com/quickstart) for more details.

## REST API

Ollama has a REST API for running and managing models.

```
curl http://localhost:11434/api/chat -d &#039;{
  &quot;model&quot;: &quot;gemma3&quot;,
  &quot;messages&quot;: [{
    &quot;role&quot;: &quot;user&quot;,
    &quot;content&quot;: &quot;Why is the sky blue?&quot;
  }],
  &quot;stream&quot;: false
}&#039;
```

See the [API documentation](https://docs.ollama.com/api) for all endpoints.

### Python

```
pip install ollama
```

```python
from ollama import chat

response = chat(model=&#039;gemma3&#039;, messages=[
  {
    &#039;role&#039;: &#039;user&#039;,
    &#039;content&#039;: &#039;Why is the sky blue?&#039;,
  },
])
print(response.message.content)
```

### JavaScript

```
npm i ollama
```

```javascript
import ollama from &quot;ollama&quot;;

const response = await ollama.chat({
  model: &quot;gemma3&quot;,
  messages: [{ role: &quot;user&quot;, content: &quot;Why is the sky blue?&quot; }],
});
console.log(response.message.content);
```

## Supported backends

- [llama.cpp](https://github.com/ggml-org/llama.cpp) project founded by Georgi Gerganov.

## Documentation

- [CLI reference](https://docs.ollama.com/cli)
- [REST API reference](https://docs.ollama.com/api)
- [Importing models](https://docs.ollama.com/import)
- [Modelfile reference](https://docs.ollama.com/modelfile)
- [Building from source](https://github.com/ollama/ollama/blob/main/docs/development.md)

## Community Integrations

&gt; Want to add your project? Open a pull request.

### Chat Interfaces

#### Web

- [Open WebUI](https://github.com/open-webui/open-webui) - Extensible, self-hosted AI interface
- [Onyx](https://github.com/onyx-dot-app/onyx) - Connected AI workspace
- [LibreChat](https://github.com/danny-avila/LibreChat) - Enhanced ChatGPT clone with multi-provider support
- [Lobe Chat](https://github.com/lobehub/lobe-chat) - Modern chat framework with plugin ecosystem ([docs](https://lobehub.com/docs/self-hosting/examples/ollama))
- [NextChat](https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web) - Cross-platform ChatGPT UI ([docs](https://docs.nextchat.dev/models/ollama))
- [Perplexica](https://github.com/ItzCrazyKns/Perplexica) - AI-powered search engine, open-source Perplexity alternative
- [big-AGI](https://github.com/enricoros/big-AGI) - AI suite for professionals
- [Lollms WebUI](https://github.com/ParisNeo/lollms-webui) - Multi-model web interface
- [ChatOllama](https://github.com/sugarforever/chat-ollama) - Chatbot with knowledge bases
- [Bionic GPT](https://github.com/bionic-gpt/bionic-gpt) - On-premise AI platform
- [Chatbot UI](https://github.com/ivanfioravanti/chatbot-ollama) - ChatGPT-style web interface
- [Hollama](https://github.com/fmaclen/hollama) - Minimal web interface
- [Chatbox](https://github.com/Bin-Huang/Chatbox) - Desktop and web AI client
- [chat](https://github.com/swuecho/chat) - Chat web app for teams
- [Ollama RAG Chatbot](https://github.com/datvodinh/rag-chatbot.git) - Chat with multiple PDFs using RAG
- [Tkinter-based client](https://github.com/chyok/ollama-gui) - Python desktop client

#### Desktop

- [Dify.AI](https://github.com/langgenius/dify) - LLM app development platform
- [AnythingLLM](https://github.com/Mintplex-Labs/anything-llm) - All-in-one AI app for Mac, Windows, and Linux
- [Maid](https://github.com/Mobile-Artificial-Intelligence/maid) - Cross-platform mobile and desktop client
- [Witsy](https://github.com/nbonamy/witsy) - AI desktop app for Mac, Windows, and Linux
- [Cherry Studio](https://github.com/kangfenmao/cherry-studio) - Multi-provider desktop client
- [Ollama App](https://github.com/JHubi1/ollama-app) - Multi-platform client for desktop and mobile
- [PyGPT](https://github.com/szczyglis-dev/py-gpt) - AI desktop assistant for Linux, Windows, and Mac
- [Alpaca](https://github.com/Jeffser/Alpaca) - GTK4 client for Linux and macOS
- [SwiftChat](https://github.com/aws-samples/swift-chat) - Cross-platform including iOS, Android, and Apple Vision Pro
- [Enchanted](https://github.com/AugustDev/enchanted) - Native macOS and iOS client
- [RWKV-Runner](https://github.com/josStorer/RWKV-Runner) - Multi-model desktop runner
- [Ollama Grid Search](https://github.com/dezoito/ollama-grid-search) - Evaluate and compare models
- [macai](https://github.com/Renset/macai) - macOS client for Ollama and ChatGPT
- [AI Studio](https://github.com/MindWorkAI/AI-Studio) - Multi-provider desktop IDE
- [Reins](https://github.com/ibrahimcetin/reins) - Parameter tuning and reasoning model support
- [ConfiChat](https://github.com/1runeberg/confichat) - Privacy-focused with optional encryption
- [LLocal.in](https://github.com/kartikm7/llocal) - Electron desktop client
- [MindMac](https://mindmac.app) - AI chat client for Mac
- [Msty](https://msty.app) - Multi-model desktop client
- [BoltAI for Mac](https://boltai.com) - AI chat client for Mac
- [IntelliBar](https://intellibar.app/) - AI-powered assistant for macOS
- [Kerlig AI](https://www.kerlig.com/) - AI writing assistant for macOS
- [Hillnote](https://hillnote.com) - Markdown-first AI workspace
- [Perfect Memory AI](https://www.perfectmemory.ai/) - Productivity AI personalized by screen and meeting history

#### Mobile

- [Ollama Android Chat](https://github.com/sunshine0523/OllamaServer) - One-click Ollama on Android

&gt; SwiftChat, Enchanted, Maid, Ollama App, Reins, and ConfiChat listed above also support mobile platforms.

### Code Editors &amp; Development

- [Cline](https://github.com/cline/cline) - VS Code extension for multi-file/whole-repo coding
- [Continue](https://github.com/continuedev/continue) - Open-source AI code assistant for any IDE
- [Void](https://github.com/voideditor/void) - Open source AI code editor, Cursor alternative
- [Copilot for Obsidian](https://github.com/logancyang/obsidian-copilot) - AI assistant for Obsidian
- [twinny](https://github.com/rjmacarthy/twinny) - Copilot and Copilot chat alternative
- [gptel Emacs client](https://github.com/karthink/gptel) - LLM client for Emacs
- [Ollama Copilot](https://github.com/bernardo-bruning/ollama-copilot) - Use Ollama as GitHub Copilot
- [Obsidian Local GPT](https://github.com/pfrankov/obsidian-local-gpt) - Local AI for Obsidian
- [Ellama Emacs client](https://github.com/s-kostyaev/ellama) - LLM tool for Emacs
- [orbiton](https://github.com/xyproto/orbiton) - Config-free text editor with Ollama tab completion
- [AI ST Completion](https://github.com/yaroslavyaroslav/OpenAI-sublime-text) - Sublime Text 4 AI assistant
- [VT Code](https://github.com/vinhnx/vtcode) - Rust-based terminal coding agent with Tree-sitter
- [QodeAssist](https://github.com/Palm1r/QodeAssist) - AI coding assistant for Qt Creator
- [AI Toolkit for VS Code](https://aka.ms/ai-tooklit/ollama-docs) - Microsoft-official VS Code extension
- [Open Interpreter](https://docs.openinterpreter.com/language-model-setup/local-models/ollama) - Natural language interface for computers

### Libraries &amp; SDKs

- [LiteLLM](https://github.com/BerriAI/litellm) - Unified API for 100+ LLM providers
- [Semantic Kernel](https://github.com/microsoft/semantic-kernel/tree/main/python/semantic_kernel/connectors/ai/ollama) - Microsoft AI orchestration SDK
- [LangChain4j](https://github.com/langchain4j/langchain4j) - Java LangChain ([example](https://github.com/langchain4j/langchain4j-examples/tree/main/ollama-examples/src/main/java))
- [LangChainGo](https://github.com/tmc/langchaingo/) - Go LangChain ([example](https://github.com/tmc/langchaingo/tree/main/examples/ollama-completion-example))
- [Spring AI](https://github.com/spring-projects/spring-ai) - Spring framework AI support ([docs](https://docs.spring.io/spring-ai/reference/api/chat/ollama-chat.html))
- [LangChain](https://python.langchain.com/docs/integrations/chat/ollama/) and [LangChain.js](https://js.langchain.com/docs/integrations/chat/ollama/) with [example](https://js.langchain.com/docs/tutorials/local_rag/)
- [Ollama for Ruby](https://github.com/crmne/ruby_llm) - Ruby LLM library
- [any-llm](https://github.com/mozilla-ai/any-llm) - Unified LLM interface by Mozilla
- [OllamaSharp for .NET](https://github.com/awaescher/OllamaSharp) - .NET SDK
- [LangChainRust](https://github.com/Abraxas-365/langchain-rust) - Rust LangChain ([example](https://github.com/Abraxas-365/langchain-rust/blob/main/examples/llm_ollama.rs))
- [Agents-Flex for Java](https://github.com/agents-flex/agents-flex) - Java agent framework ([example](https://github.com/agents-flex/agents-flex/tree/main/agents-flex-llm/agents-flex-llm-ollama/src/test/java/com/agentsflex/llm/ollama))
- [Elixir LangChain](https://github.com/brainlid/langchain) - Elixir LangChain
- [Ollama-rs for Rust](https://github.com/pepperoni21/ollama-rs) - Rust SDK
- [LangChain for .NET](https://github.com/tryAGI/LangChain) - .NET LangChain ([example](https://github.com/tryAGI/LangChain/blob/main/examples/LangChain.Samples.OpenAI/Program.cs))
- [chromem-go](https://github.com/philippgille/chromem-go) - Go vector database with Ollama embeddings ([example](https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama))
- [LangChainDart](https://github.com/davidmigloz/langchain_dart) - Dart LangChain
- [LlmTornado](https://github.com/lofcz/llmtornado) - Unified C# interface for multiple inference APIs
- [Ollama4j for Java](https://github.com/ollama4j/ollama4j) - Java SDK
- [Ollama for Laravel](https://github.com/cloudstudio/ollama-laravel) - Laravel integration
- [Ollama for Swift](https://github.com/mattt/ollama-swift) - Swift SDK
- [LlamaIndex](https://docs.llamaindex.ai/en/stable/examples/llm/ollama/) and [LlamaIndexTS](https://ts.llamaindex.ai/modules/llms/available_llms/ollama) - Data framework for LLM apps
- [Haystack](https://github.com/deepset-ai/haystack-integrations/blob/main/integrations/ollama.md) - AI pipeline framework
- [Firebase Genkit](https://firebase.google.com/docs/genkit/plugins/ollama) - Google AI framework
- [Ollama-hpp for C++](https://github.com/jmont-dev/ollama-hpp) - C++ SDK
- [PromptingTools.jl](https://github.com/svilupp/PromptingTools.jl) - Julia LLM toolkit ([example](https://svilupp.github.io/PromptingTools.jl/dev/examples/working_with_ollama))
- [Ollama for R - rollama](https://github.com/JBGruber/rollama) - R SDK
- [Portkey](https://portkey.ai/docs/welcome/integration-guides/ollama) - AI gateway
- [Testcontainers](https://testcontainers.com/modules/ollama/) - Container-based testing
- [LLPhant](https://github.com/theodo-group/LLPhant?tab=readme-ov-file#ollama) - PHP AI framework

### Frameworks &amp; Agents

- [AutoGPT](https://github.com/Significant-Gravitas/AutoGPT/blob/master/docs/content/platform/ollama.md) - Autonomous AI agent platform
- [crewAI](https://github.com/crewAIInc/crewAI) - Multi-agent orchestration framework
- [Strands Agents](https://github.com/strands-agents/sdk-python) - Model-driven agent building by AWS
- [Cheshire Cat](https://github.com/cheshire-cat-ai/core) - AI assistant framework
- [any-agent](https://github.com/mozilla-ai/any-agent) - Unified agent framework interface by Mozilla
- [Stakpak](https://github.com/stakpak/agent) - Open source DevOps agent
- [Hexabot](https://github.com/hexastack/hexabot) - Conversational AI builder
- [Neuro SAN](https://github.com/cognizant-ai-lab/neuro-san-studio) - Multi-agent orchestration ([docs](https://github.com/cognizant-ai-lab/neuro-san-studio/blob/main/docs/user_guide.md#ollama))

### RAG &amp; Knowledge Bases

- [RAGFlow](https://github.com/infiniflow/ragflow) - RAG engine based on deep document understanding
- [R2R](https://github.com/SciPhi-AI/R2R) - Open-source RAG engine
- [MaxKB](https://github.com/1Panel-dev/MaxKB/) - Ready-to-use RAG chatbot
- [Minima](https://github.com/dmayboroda/minima) - On-premises or fully local RAG
- [Chipper](https://github.com/TilmanGriesel/chipper) - AI interface with Haystack RAG
- [ARGO](https://github.com/xark-argo/argo) - RAG and deep research on Mac/Windows/Linux
- [Archyve](https://github.com/nickthecook/archyve) - RAG-enabling document library
- [Casibase](https://casibase.org) - AI knowledge base with RAG and SSO
- [BrainSoup](https://www.nurgo-software.com/products/brainsoup) - Native client with RAG and multi-agent automation

### Bots &amp; Messaging

- [LangBot](https://github.com/RockChinQ/LangBot) - Multi-platform messaging bots with agents and RAG
- [AstrBot](https://github.com/Soulter/AstrBot/) - Multi-platform chatbot with RAG and plugins
- [Discord-Ollama Chat Bot](https://github.com/kevinthedang/discord-ollama) - TypeScript Discord bot
- [Ollama Telegram Bot](https://github.com/ruecat/ollama-telegram) - Telegram bot
- [LLM Telegram Bot](https://github.com/innightwolfsleep/llm_telegram_bot) - Telegram bot for roleplay

### Terminal &amp; CLI

- [aichat](https://github.com/sigoden/aichat) - All-in-one LLM CLI with Shell Assistant, RAG, and AI tools
- [oterm](https://github.com/ggozad/oterm) - Terminal client for Ollama
- [gollama](https://github.com/sammcj/gollama) - Go-based model manager for Ollama
- [tlm](https://github.com/yusufcanb/tlm) - Local shell copilot
- [tenere](https://github.com/pythops/tenere) - TUI for LLMs
- [ParLlama](https://github.com/paulrobello/parllama) - TUI for Ollama
- [llm-ollama](https://github.com/taketwo/llm-ollama) - Plugin for [Datasette&#039;s LLM CLI](https://llm.datasette.io/en/stable/)
- [ShellOracle](https://github.com/djcopley/ShellOracle) - Shell command suggestions
- [LLM-X](https://github.com/mrdjohnson/llm-x) - Progressive web app for LLMs
- [cmdh](https://github.com/pgibler/cmdh) - Natural language to shell commands
- [VT](https://github.com/vinhnx/vt.ai) - Minimal multimodal AI chat app

### Productivity &amp; Apps

- [AppFlowy](https://github.com/AppFlowy-IO/AppFlowy) - AI collaborative workspace, self-hostable Notion alternative
- [Screenpipe](https://github.com/mediar-ai/screenpipe) - 24/7 screen and mic recording with AI-powered search
- [Vibe](https://github.com/thewh1teagle/vibe) - Transcribe and analyze meetings
- [Page Assist](https://github.com/n4ze3m/page-assist) - Chrome extension for AI-powered browsing
- [NativeMind](https://github.com/NativeMindBrowser/NativeMindExtension) - Private, on-device browser AI assistant
- [Ollama Fortress](https://github.com/ParisNeo/ollama_proxy_server) - Security proxy for Ollama
- [1Panel](https://github.com/1Panel-dev/1Panel/) - Web-based Linux server management
- [Writeopia](https://github.com/Writeopia/Writeopia) - Text editor with Ollama integration
- [QA-Pilot](https://github.com/reid41/QA-Pilot) - GitHub code repository understanding
- [Raycast extension](https://github.com/MassimilianoPasquini97/raycast_ollama) - Ollama in Raycast
- [Painting Droid](https://github.com/mateuszmigas/painting-droid) - Painting app with AI integrations
- [Serene Pub](https://github.com/doolijb/serene-pub) - AI roleplaying app
- [Mayan EDMS](https://gitlab.com/mayan-edms/mayan-edms) - Document management with Ollama workflows
- [TagSpaces](https://www.tagspaces.org) - File management with [AI tagging](https://docs.tagspaces.org/ai/)

### Observability &amp; Monitoring

- [Opik](https://www.comet.com/docs/opik/cookbook/ollama) - Debug, evaluate, and monitor LLM applications
- [OpenLIT](https://github.com/openlit/openlit) - OpenTelemetry-native monitoring for Ollama and GPUs
- [Lunary](https://lunary.ai/docs/integrations/ollama) - LLM observability with analytics and PII masking
- [Langfuse](https://langfuse.com/docs/integrations/ollama) - Open source LLM observability
- [HoneyHive](https://docs.honeyhive.ai/integrations/ollama) - AI observability and evaluation for agents
- [MLflow Tracing](https://mlflow.org/docs/latest/llms/tracing/index.html#automatic-tracing) - Open source LLM observability

### Database &amp; Embeddings

- [pgai](https://github.com/timescale/pgai) - PostgreSQL as a vector database ([guide](https://github.com/timescale/pgai/blob/main/docs/vectorizer-quick-start.md))
- [MindsDB](https://github.com/mindsdb/mindsdb/blob/staging/mindsdb/integrations/handlers/ollama_handler/README.md) - Connect Ollama with 200+ data platforms
- [chromem-go](https://github.com/philippgille/chromem-go/blob/v0.5.0/embed_ollama.go) - Embeddable vector database for Go ([example](https://github.com/philippgille/chromem-go/tree/v0.5.0/examples/rag-wikipedia-ollama))
- [Kangaroo](https://github.com/dbkangaroo/kangaroo) - AI-powered SQL client

### Infrastructure &amp; Deployment

#### Cloud

- [Google Cloud](https://cloud.google.com/run/docs/tutorials/gpu-gemma2-with-ollama)
- [Fly.io](https://fly.io/docs/python/do-more/add-ollama/)
- [Koyeb](https://www.koyeb.com/deploy/ollama)
- [Harbor](https://github.com/av/harbor) - Containerized LLM toolkit with Ollama as default backend

#### Package Managers

- [Pacman](https://archlinux.org/packages/extra/x86_64/ollama/)
- [Homebrew](https://formulae.brew.sh/formula/ollama)
- [Nix package](https://search.nixos.org/packages?show=ollama&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=ollama)
- [Helm Chart](https://artifacthub.io/packages/helm/ollama-helm/ollama)
- [Gentoo](https://github.com/gentoo/guru/tree/master/app-misc/ollama)
- [Flox](https://flox.dev/blog/ollama-part-one)
- [Guix channel](https://codeberg.org/tusharhero/ollama-guix)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[fleetdm/fleet]]></title>
            <link>https://github.com/fleetdm/fleet</link>
            <guid>https://github.com/fleetdm/fleet</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:44 GMT</pubDate>
            <description><![CDATA[Open device management]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fleetdm/fleet">fleetdm/fleet</a></h1>
            <p>Open device management</p>
            <p>Language: Go</p>
            <p>Stars: 6,093</p>
            <p>Forks: 796</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;&lt;a href=&quot;https://fleetdm.com&quot;&gt;&lt;img width=&quot;200&quot; alt=&quot;Fleet logo, landscape, dark text, transparent background&quot; src=&quot;https://github.com/user-attachments/assets/5b52c536-f33e-4159-b2a3-d48f31868cd2&quot;&gt;&lt;/a&gt;&lt;/h1&gt;


#### [News](https://fleetdm.com/announcements) &amp;nbsp; Â· &amp;nbsp; [Report a bug](https://github.com/fleetdm/fleet/issues/new) &amp;nbsp; Â· &amp;nbsp; [Handbook](https://fleetdm.com/handbook/company) &amp;nbsp; Â· &amp;nbsp; [Why open source?](https://fleetdm.com/handbook/company/why-this-way#why-open-source) &amp;nbsp; Â· &amp;nbsp; [Art](https://fleetdm.com/logos)


Open-source platform for IT and security teams with thousands of computers.  Designed for APIs, GitOps, webhooks, YAML, and humans.

&lt;a href=&quot;https://fleetdm.com/logos&quot;&gt;&lt;img src=&quot;https://github.com/fleetdm/fleet/assets/618009/f835ec29-1cb9-49ba-a0f3-395ffd9d5c9f&quot; alt=&quot;A glass city in the clouds&quot;/&gt;&lt;/a&gt;


## What&#039;s it for?
Organizations like Fastly and Gusto use Fleet for vulnerability reporting, detection engineering, device management (MDM), device health monitoring, posture-based access control, managing unused software licenses, and more.

#### Explore data
To see what kind of data you can use Fleet to gather, check out the [table reference documentation](https://fleetdm.com/tables).

#### Out-of-the-box policies
Fleet includes out-of-the box support for all [CIS benchmarks for macOS and Windows](https://fleetdm.com/docs/using-fleet/cis-benchmarks), as well as many [simpler queries](https://fleetdm.com/queries).

Take as much or as little as you need for your organization.

#### Supported platforms
Here are the platforms Fleet currently supports:

- Linux (all distros)
- macOS
- Windows
- Chromebooks
- Amazon Web Services (AWS)
- Google Cloud (GCP)
- Azure (Microsoft cloud)
- Data centers
- Containers (kube, etc)
- Linux-based IoT devices

## Lighter than air
Fleet is lightweight and modular.  You can use it for security without using it for MDM, and vice versa.  You can turn off features you are not using.

#### Openness
Fleet is dedicated to flexibility, accessibility, and clarity.  We think [everyone can contribute](https://fleetdm.com/handbook/company#openness) and that tools should be as easy as possible for everyone to understand.

#### Good neighbors
Fleet has no ambition to replace all of your other tools.  (Though it might replace some, if you want it to.)  Ready-to-use, enterprise-friendly integrations exist for Snowflake, Splunk, GitHub Actions, Vanta, Elastic Jira, Zendesk, and more.

Fleet plays well with Munki, Chef, Puppet, and Ansible, as well as with security tools like Crowdstrike and SentinelOne.  For example, you can use the free version of Fleet to quickly report on what hosts are _actually_ running your EDR agent.

#### Free as in free
The free version of Fleet will [always be free](https://fleetdm.com/pricing).  Fleet is [independently backed](https://linkedin.com/company/fleetdm) and actively maintained with the help of many amazing [contributors](https://github.com/fleetdm/fleet/graphs/contributors).

#### Longevity
The [company behind Fleet](https://fleetdm.com/handbook/company) is founded (and majority-owned) by [true believers in open source](https://fleetdm.com/handbook/company/why-this-way#why-open-source).  The company&#039;s business model is influenced by GitLab (NYSE: GTLB), with great investors, happy customers, and the capacity to become profitable at any time.

In keeping with Fleet&#039;s value of openness, [Fleet Device Management&#039;s company handbook](https://fleetdm.com/handbook/company) is public and open source.  You can read about the [history of Fleet and osquery](https://fleetdm.com/handbook/company#history) and our commitment to improving the product.

&lt;!-- &gt; To upgrade from Fleet â‰¤3.2.0, just follow the upgrading steps for the earliest subsequent major release from this repository (it&#039;ll work out of the box until the release of Fleet 5.0). --&gt;


## Is it any good?
Fleet is used in production by IT and security teams with thousands of laptops and servers.  Many deployments support tens of thousands of hosts, and a few large organizations manage deployments as large as 400,000+ hosts.



## Chat
Please join us in [MacAdmins Slack](https://www.macadmins.org/) or in [osquery Slack](https://fleetdm.com/slack).

The Fleet community is full of [kind and helpful people](https://fleetdm.com/handbook/company#empathy).  Whether or not you are a paying customer, if you need help, just ask.


## Contributing &amp;nbsp; [![Go Report Card](https://goreportcard.com/badge/github.com/fleetdm/fleet)](https://goreportcard.com/report/github.com/fleetdm/fleet) &amp;nbsp; [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/5537/badge)](https://bestpractices.coreinfrastructure.org/projects/5537) &amp;nbsp; [![Twitter Follow](https://img.shields.io/twitter/follow/fleetctl.svg?style=social&amp;maxAge=3600)](https://twitter.com/fleetctl) &amp;nbsp; 

The landscape of cybersecurity and IT is too complex.  Let&#039;s open it up.

Contributions are welcome, whether you answer questions on [Slack](https://fleetdm.com/slack) / [GitHub](https://github.com/fleetdm/fleet/issues) / [StackOverflow](https://stackoverflow.com/search?q=osquery) / [LinkedIn](https://linkedin.com/company/fleetdm) / [Twitter](https://twitter.com/fleetctl), improve the documentation or [website](./website), write a tutorial, give a talk at a conference or local meetup, give an [interview on a podcast](https://fleetdm.com/podcasts), troubleshoot reported issues, or [submit a patch](https://fleetdm.com/docs/contributing/contributing).  The Fleet code of conduct is [on GitHub](https://github.com/fleetdm/fleet/blob/main/CODE_OF_CONDUCT.md).

&lt;!-- - Great contributions are motivated by real-world use cases or learning.
- Some of the most valuable contributions might not touch any code at all.
- Small, iterative, simple (boring) changes are the easiest to merge. --&gt;

## What&#039;s next?
To see what Fleet can do, head over to [fleetdm.com](https://fleetdm.com) and try it out for yourself, grab time with one of the maintainers to discuss, or visit the docs and roll it out to your organization.

#### Production deployment
Fleet is simple enough to [spin up for yourself](https://fleetdm.com/docs/get-started/tutorials-and-guides).  Or you can have us [host it for you](https://fleetdm.com/pricing).  Premium features are [available](https://fleetdm.com/pricing) either way.

#### Documentation
Complete documentation for Fleet can be found at [https://fleetdm.com/docs](https://fleetdm.com/docs).


## License
The free version of Fleet is available under the MIT license.  The commercial license is also designed to allow contributions to paid features for users whose employment agreements allow them to contribute to open source projects.  (See LICENSE.md for details.)

&gt; Fleet is built on [osquery](https://github.com/osquery/osquery), [nanoMDM](https://github.com/micromdm/nanomdm), [Nudge](https://github.com/macadmins/nudge), and [swiftDialog](https://github.com/swiftDialog/swiftDialog).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[steveyegge/beads]]></title>
            <link>https://github.com/steveyegge/beads</link>
            <guid>https://github.com/steveyegge/beads</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:43 GMT</pubDate>
            <description><![CDATA[Beads - A memory upgrade for your coding agent]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/steveyegge/beads">steveyegge/beads</a></h1>
            <p>Beads - A memory upgrade for your coding agent</p>
            <p>Language: Go</p>
            <p>Stars: 17,521</p>
            <p>Forks: 1,090</p>
            <p>Stars today: 123 stars today</p>
            <h2>README</h2><pre># bd - Beads

**Distributed, git-backed graph issue tracker for AI agents.**

**Platforms:** macOS, Linux, Windows, FreeBSD

[![License](https://img.shields.io/github/license/steveyegge/beads)](LICENSE)
[![Go Report Card](https://goreportcard.com/badge/github.com/steveyegge/beads)](https://goreportcard.com/report/github.com/steveyegge/beads)
[![Release](https://img.shields.io/github/v/release/steveyegge/beads)](https://github.com/steveyegge/beads/releases)
[![npm version](https://img.shields.io/npm/v/@beads/bd)](https://www.npmjs.com/package/@beads/bd)
[![PyPI](https://img.shields.io/pypi/v/beads-mcp)](https://pypi.org/project/beads-mcp/)

Beads provides a persistent, structured memory for coding agents. It replaces messy markdown plans with a dependency-aware graph, allowing agents to handle long-horizon tasks without losing context.

## âš¡ Quick Start

```bash
# Install beads CLI (system-wide - don&#039;t clone this repo into your project)
curl -fsSL https://raw.githubusercontent.com/steveyegge/beads/main/scripts/install.sh | bash

# Initialize in YOUR project
cd your-project
bd init

# Tell your agent
echo &quot;Use &#039;bd&#039; for task tracking&quot; &gt;&gt; AGENTS.md
```

**Note:** Beads is a CLI tool you install once and use everywhere. You don&#039;t need to clone this repository into your project.

## ğŸ›  Features

* **[Dolt](https://github.com/dolthub/dolt)-Powered:** Version-controlled SQL database with cell-level merge, native branching, and built-in sync via Dolt remotes.
* **Agent-Optimized:** JSON output, dependency tracking, and auto-ready task detection.
* **Zero Conflict:** Hash-based IDs (`bd-a1b2`) prevent merge collisions in multi-agent/multi-branch workflows.
* **Compaction:** Semantic &quot;memory decay&quot; summarizes old closed tasks to save context window.
* **Messaging:** Message issue type with threading (`--thread`), ephemeral lifecycle, and mail delegation.
* **Graph Links:** `relates_to`, `duplicates`, `supersedes`, and `replies_to` for knowledge graphs.

## ğŸ“– Essential Commands

| Command | Action |
| --- | --- |
| `bd ready` | List tasks with no open blockers. |
| `bd create &quot;Title&quot; -p 0` | Create a P0 task. |
| `bd update &lt;id&gt; --claim` | Atomically claim a task (sets assignee + in_progress). |
| `bd dep add &lt;child&gt; &lt;parent&gt;` | Link tasks (blocks, related, parent-child). |
| `bd show &lt;id&gt;` | View task details and audit trail. |

## ğŸ”— Hierarchy &amp; Workflow

Beads supports hierarchical IDs for epics:

* `bd-a3f8` (Epic)
* `bd-a3f8.1` (Task)
* `bd-a3f8.1.1` (Sub-task)

**Stealth Mode:** Run `bd init --stealth` to use Beads locally without committing files to the main repo. Perfect for personal use on shared projects.

**Contributor vs Maintainer:** When working on open-source projects:

* **Contributors** (forked repos): Run `bd init --contributor` to route planning issues to a separate repo (e.g., `~/.beads-planning`). Keeps experimental work out of PRs.
* **Maintainers** (write access): Beads auto-detects maintainer role via SSH URLs or HTTPS with credentials. Only need `git config beads.role maintainer` if using GitHub HTTPS without credentials but you have write access.

## ğŸ“¦ Installation

* **npm:** `npm install -g @beads/bd`
* **Homebrew:** `brew install beads`
* **Go:** `go install github.com/steveyegge/beads/cmd/bd@latest`

**Requirements:** Linux, FreeBSD, macOS, or Windows.

## ğŸŒ Community Tools

See [docs/COMMUNITY_TOOLS.md](docs/COMMUNITY_TOOLS.md) for a curated list of community-built UIs, extensions, and integrationsâ€”including terminal interfaces, web UIs, editor extensions, and native apps.

## ğŸ“ Documentation

* [Installing](docs/INSTALLING.md) | [Agent Workflow](AGENT_INSTRUCTIONS.md) | [Copilot Setup](docs/COPILOT_INTEGRATION.md) | [Articles](ARTICLES.md) | [Sync Branch Mode](docs/PROTECTED_BRANCHES.md) | [Troubleshooting](docs/TROUBLESHOOTING.md) | [FAQ](docs/FAQ.md)
* [![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/steveyegge/beads)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[dolthub/dolt]]></title>
            <link>https://github.com/dolthub/dolt</link>
            <guid>https://github.com/dolthub/dolt</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:42 GMT</pubDate>
            <description><![CDATA[Dolt â€“ Git for Data]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dolthub/dolt">dolthub/dolt</a></h1>
            <p>Dolt â€“ Git for Data</p>
            <p>Language: Go</p>
            <p>Stars: 20,248</p>
            <p>Forks: 640</p>
            <p>Stars today: 47 stars today</p>
            <h2>README</h2><pre>&lt;img height=&quot;100&quot; src=&quot;./images/Dolt-Logo@3x.svg&quot;/&gt;

# Dolt is Git for Data!

Dolt is a SQL database that you can fork, clone, branch, merge, push
and pull just like a Git repository. 

Connect to Dolt just like any MySQL database to read or modify schema 
and data. Version control functionality is exposed in SQL via system 
tables, functions, and procedures. 

Or, use the Git-like command line interface to import CSV files, commit 
your changes, push them to a remote, or merge your teammate&#039;s changes.
All the commands you know for Git work exactly the same for Dolt. 

Git versions files. Dolt versions tables. It&#039;s like Git and MySQL had a
baby.

We also built [DoltHub](https://www.dolthub.com), a place to share
Dolt databases. We host public data for free. If you want to host
your own version of DoltHub, we have [DoltLab](https://www.doltlab.com). 
If you want us to run a Dolt server for you, we have [Hosted Dolt](https://hosted.doltdb.com). 

Prefer Postgres instead of MySQL? Try [Doltgres](https://github.com/dolthub/doltgresql), now
in its Beta release.

[Join us on Discord](https://discord.com/invite/RFwfYpu) to say hi and
ask questions, or [check out our roadmap](https://docs.dolthub.com/other/roadmap) 
to see what we&#039;re building next.

# Video Introduction

[![Dolt Explainer Video](https://img.youtube.com/vi/H2iZy0Cme10/maxresdefault.jpg)](https://www.youtube.com/watch?v=H2iZy0Cme10)

# What&#039;s it for?

Lots of things! Dolt is a generally useful tool with countless
applications. But if you want some ideas, [here&#039;s how people are using
it so far](https://dolthub.com/blog/2024-10-15-dolt-use-cases/).

Dolt can be [set up as a replica of your existing MySQL](https://www.dolthub.com/blog/2023-02-17-binlog-replication-preview/)
database using standard MySQL binlog replication. Every write becomes
a Dolt commit. This is a great way to get the version control benefits 
of Dolt and keep an existing MySQL database. 

# Dolt CLI

The `dolt` CLI has the same commands as `git`, with some extras.

```
$ dolt
Valid commands for dolt are
                init - Create an empty Dolt data repository.
              status - Show the working tree status.
                 add - Add table changes to the list of staged table changes.
                diff - Diff a table.
               reset - Remove table changes from the list of staged table changes.
               clean - Remove untracked tables from working set.
              commit - Record changes to the repository.
                 sql - Run a SQL query against tables in repository.
          sql-server - Start a MySQL-compatible server.
                 log - Show commit logs.
              branch - Create, list, edit, delete branches.
            checkout - Checkout a branch or overwrite a table from HEAD.
               merge - Merge a branch.
           conflicts - Commands for viewing and resolving merge conflicts.
         cherry-pick - Apply the changes introduced by an existing commit.
              revert - Undo the changes introduced in a commit.
               clone - Clone from a remote data repository.
               fetch - Update the database from a remote data repository.
                pull - Fetch from a dolt remote data repository and merge.
                push - Push to a dolt remote.
              config - Dolt configuration.
              remote - Manage set of tracked repositories.
              backup - Manage a set of server backups.
               login - Login to a dolt remote host.
               creds - Commands for managing credentials.
                  ls - List tables in the working set.
              schema - Commands for showing and importing table schemas.
               table - Commands for copying, renaming, deleting, and exporting tables.
                 tag - Create, list, delete tags.
               blame - Show what revision and author last modified each row of a table.
         constraints - Commands for handling constraints.
             migrate - Executes a database migration to use the latest Dolt data format.
         read-tables - Fetch table(s) at a specific commit into a new dolt repo
                  gc - Cleans up unreferenced data from the repository.
       filter-branch - Edits the commit history using the provided query.
          merge-base - Find the common ancestor of two commits.
             version - Displays the current Dolt cli version.
                dump - Export all tables in the working set into a file.
```

# Installation

Dolt is a single ~103 megabyte program. 

```bash
dolt $ du -h /Users/timsehn/go/bin/dolt
103M	/Users/timsehn/go/bin/dolt
```

It&#039;s really easy to install. Download it and put it on your `PATH`. 
We have a bunch of ways to make this even easier for most platforms.

## From Latest Release

To install on Linux or Mac based systems run this command in your
terminal:

```
sudo bash -c &#039;curl -L https://github.com/dolthub/dolt/releases/latest/download/install.sh | bash&#039;
```

This will download the latest `dolt` release and put it in
`/usr/local/bin/`, which is probably on your `$PATH`.

The install script needs sudo in order to put `dolt` in `/usr/local/bin`. If you don&#039;t have root
privileges or aren&#039;t comfortable running a script with them, you can download the dolt binary
for your platform from [the latest release](https://github.com/dolthub/dolt/releases), unzip it,
and put the binary somewhere on your `$PATH`.

### Linux

#### Arch Linux

Dolt is packaged in the official repositories for Arch Linux.

```
pacman -S dolt
```

### Mac

#### Homebrew

Dolt is on Homebrew, updated every release.

```
brew install dolt
```
#### MacPorts

On macOS, Dolt can also be installed via a [community-managed port](https://ports.macports.org/port/dolt/) via [MacPorts](https://www.macports.org):

```sh
sudo port install dolt
```

### Windows

Download the latest Microsoft Installer (`.msi` file) in
[releases](https://github.com/dolthub/dolt/releases) and run
it.

For information on running on Windows, see [here](https://docs.dolthub.com/introduction/installation/windows).

#### Chocolatey

You can install `dolt` using [Chocolatey](https://chocolatey.org/):

```sh
choco install dolt
```

#### Docker

There are following official Docker images for Dolt:

* [`dolthub/dolt`](https://hub.docker.com/r/dolthub/dolt) for running Dolt
as CLI tool.
* [`dolthub/dolt-sql-server`](https://hub.docker.com/r/dolthub/dolt-sql-server) for running Dolt in server mode.

## From Source

Make sure you have Go installed, and that `go` is in your path. Dolt has a dependency on [cgo](https://pkg.go.dev/cmd/cgo), so you will need a working C compiler and toolchain as well.

Clone this repository and cd into the `go` directory. Then run:

```
go install ./cmd/dolt
```

The output will be in `$GOPATH/bin`, which defaults to `~/go/bin`. To test your build, try:

```
~/go/bin/dolt version
```

# Configuration

Verify that your installation has succeeded by running `dolt` in your
terminal.

```
$ dolt
Valid commands for dolt are
[...]
```

Configure `dolt` with your user name and email, which you&#039;ll need to
create commits. The commands work exactly the same as git.

```
$ dolt config --global --add user.email YOU@DOMAIN.COM
$ dolt config --global --add user.name &quot;YOUR NAME&quot;
```

# Getting started

## Navigate to the directory where you would like your data stored

Dolt needs a place to store your databases. I&#039;m going to put my databases in `~/dolt`. 

```bash
% cd ~
% mkdir dolt
% cd dolt
```

Any databases you create will be stored in this directory. So, for this example, a directory named `getting_started` will be created here once you run `create database getting_started`. Navigating to `~/dolt/getting_started` will allow you to access this database using the Dolt command line.

NOTE: For this example, the `getting_started` directory will be created after you run `create database getting_started;` in a SQL shell in the [Create a schema section](#create-a-schema). Don&#039;t do anything except make the directory and navigate to it just yet.

## Start a MySQL-compatible database server

Dolt ships with a MySQL compatible database server built in. To start it you use the command `dolt sql-server`. Running this command starts the server on port 3306. 

```bash
dolt sql-server
Starting server with Config HP=&quot;localhost:3306&quot;|T=&quot;28800000&quot;|R=&quot;false&quot;|L=&quot;info&quot;
```

Your terminal will just hang there. This means the server is running. Any errors will be printed in this terminal. Just leave it there and open a new terminal.

## Connect with a MySQL client (up to version 8.4)

In the new terminal, we will now connect to the running database server using a client. Dolt also ships with a MySQL compatible client. 

```bash
% dolt -u root -p &quot;&quot; sql
# Welcome to the Dolt MySQL client.
# Statements must be terminated with &#039;;&#039;.
# &quot;exit&quot; or &quot;quit&quot; (or Ctrl-D) to exit.
mysql&gt;
```

In the other terminal where you ran `dolt sql-server`, you&#039;ll see the following log line.

```
2022-06-06T13:14:32-07:00 INFO [conn 1] NewConnection {DisableClientMultiStatements=false}
```

You are connected!

While we&#039;re here let&#039;s grab a copy of MySQL so we can connect with that client. Head over to the [MySQL Getting Started](https://dev.mysql.com/doc/mysql-getting-started/en/) documentation and install MySQL on your machine. I used [Homebrew](https://brew.sh/) to install MySQL on my Mac: `brew install mysql@8.4`. Alternatively, you can install only the client component by running `brew install mysql-client@8.4`.

NOTE: Make sure you install a MySQL 8.4 release. MySQL 8.4 is the current Long Term Support (LTS) release, meaning this is the stable and supported version of MySQL. MySQL 9.0 is also available, but is an &quot;innovation&quot; release, meaning it has more recent changes and features, but may not be as stable as the LTS release. The 9.0 release changes authentication support and isn&#039;t able to connect to a Dolt SQL server by default. You can install MySQL 8.4 with Homebrew by running `brew install mysql@8.4`. If you do want to use MySQL-9.0, read [our post on how to configure Dolt for `caching_sha2_password` authentication](https://www.dolthub.com/blog/2024-12-11-mysql9-and-caching-sha2-auth-support/). 

MySQL comes with a MySQL server called `mysqld` and a MySQL client called `mysql`. You&#039;re only interested in the client. After following the instructions from MySQL&#039;s documentation, make sure you have a copy of the `mysql` client on your path:

```bash
% mysql --version
mysql  Ver 8.0.29 for macos12.2 on x86_64 (Homebrew)
```

Now, to connect the `mysql` client to Dolt, you are going to force the MySQL client through the TCP interface by passing in a host and port. The default is the socket interface which Dolt supports, but is only available on `localhost`. So, it&#039;s better to show off the TCP interface. The MySQL client also requires you specify a user, in this case `root`.

```bash
% mysql --host 127.0.0.1 --port 3306 -uroot
Welcome to the MySQL monitor.  Commands end with ; or \g.
Your MySQL connection id is 2
Server version: 5.7.9-Vitess 

Copyright (c) 2000, 2022, Oracle and/or its affiliates.

Oracle is a registered trademark of Oracle Corporation and/or its
affiliates. Other names may be trademarks of their respective
owners.

Type &#039;help;&#039; or &#039;\h&#039; for help. Type &#039;\c&#039; to clear the current input statement.

mysql&gt;
```

Again, to ensure the client actually connected, you should see the following in the `dolt sql-server` terminal 

```
2022-06-06T13:26:55-07:00 INFO [conn 2] NewConnection {DisableClientMultiStatements=false}
```

As you can see, Dolt supports any MySQL-compatible client. Dolt ships with a client but you can use any MySQL client, like the one that comes with MySQL.

## Create a schema

Now we&#039;re actually ready to do something interesting. I&#039;ll stay in the `mysql` client and execute the following SQL statements to create a database called `getting_started`. The `getting_started` database will have three tables: `employees`, `teams`, and `employees_teams`.

```
mysql&gt; create database getting_started;
Query OK, 1 row affected (0.04 sec)

mysql&gt; use getting_started;
Database changed
mysql&gt; create table employees (
    id int, 
    last_name varchar(255), 
    first_name varchar(255), 
    primary key(id));
Query OK, 0 rows affected (0.01 sec)

mysql&gt; create table teams (
    id int, 
    team_name varchar(255), 
    primary key(id)); 
Query OK, 0 rows affected (0.00 sec)

mysql&gt; create table employees_teams(
    team_id int, 
    employee_id int, 
    primary key(team_id, employee_id), 
    foreign key (team_id) references teams(id), 
    foreign key (employee_id) references employees(id));
Query OK, 0 rows affected (0.01 sec)

mysql&gt; show tables;
+---------------------------+
| Tables_in_getting_started |
+---------------------------+
| employees                 |
| employees_teams           |
| teams                     |
+---------------------------+
3 rows in set (0.00 sec)
```

Dolt supports foreign keys, secondary indexes, triggers, check constraints, and stored procedures. It&#039;s a modern, feature-rich SQL database.

## Make a Dolt commit

It&#039;s time to use your first Dolt feature. We&#039;re going to make a Dolt [commit](https://docs.dolthub.com/concepts/dolt/commits). A Dolt commit allows you to time travel and see lineage. Make a Dolt commit whenever you want to restore or compare to this point in time.

Dolt exposes version control functionality through a Git-style interface. On the command line, Dolt commands map exactly to their Git equivalent with the targets being tables instead of files. In SQL, Dolt exposes version control read operations as [system tables](https://docs.dolthub.com/sql-reference/version-control/dolt-system-tables) and version control write operations as [stored procedures](https://docs.dolthub.com/sql-reference/version-control/dolt-sql-procedures). 

The naming of the system tables and stored procedures follows the `dolt_&lt;command&gt;` pattern. So `dolt add` on the CLI becomes `dolt_add` as a stored procedure. Passing options also follows the command line model. For instance, to specify tables to add, send the table names in as options to the `dolt_add` procedure. For named arguments like sending a message into the `dolt_commit` command use two arguments in sequence like `(&#039;-m&#039;, &#039;This is a message&#039;)`. If you know Git, the version control procedures and system tables should feel familiar.

So, we add and commit our new schema like so.

```
mysql&gt; call dolt_add(&#039;teams&#039;, &#039;employees&#039;, &#039;employees_teams&#039;);
+--------+
| status |
+--------+
|      0 |
+--------+
1 row in set (0.03 sec)

mysql&gt; call dolt_commit(&#039;-m&#039;, &#039;Created initial schema&#039;);
+----------------------------------+
| hash                             |
+----------------------------------+
| ne182jemgrlm8jnjmoubfqsstlfi1s98 |
+----------------------------------+
1 row in set (0.02 sec)

mysql&gt; select * from dolt_log;
+----------------------------------+-----------+-----------------+-------------------------+----------------------------+
| commit_hash                      | committer | email           | date                    | message                    |
+----------------------------------+-----------+-----------------+-------------------------+----------------------------+
| ne182jemgrlm8jnjmoubfqsstlfi1s98 | Tim Sehn  | tim@dolthub.com | 2022-06-07 16:35:49.277 | Created initial schema     |
| vluuhvd0bn59598utedt77ed9q5okbcb | Tim Sehn  | tim@dolthub.com | 2022-06-07 16:33:59.531 | Initialize data repository |
+----------------------------------+-----------+-----------------+-------------------------+----------------------------+
2 rows in set (0.01 sec)
```

There you have it. Your schema is created and you have a Dolt commit tracking the creation, as seen in the `dolt_log` system table.

Note, a Dolt commit is different than a standard SQL transaction `COMMIT`. In this case, I am running the database with [`AUTOCOMMIT`](https://dev.mysql.com/doc/refman/5.6/en/innodb-autocommit-commit-rollback.html) on, so each SQL statement is automatically generating a transaction `COMMIT`. If you want system to generate a Dolt commit for every transaction use the system variable, [`@@dolt_transaction_commit`](https://docs.dolthub.com/sql-reference/version-control/dolt-sysvars#dolt_transaction_commit).

## Insert some data

Now, I&#039;m going to populate the database with a few employees here at DoltHub. Then, I&#039;ll assign the employees to two teams: engineering and sales. The CEO wears many hats at a start up so he&#039;ll be assigned to multiple teams.

```
mysql&gt; insert into employees values 
    (0, &#039;Sehn&#039;, &#039;Tim&#039;), 
    (1, &#039;Hendriks&#039;, &#039;Brian&#039;), 
    (2, &#039;Son&#039;,&#039;Aaron&#039;), 
    (3, &#039;Fitzgerald&#039;, &#039;Brian&#039;);
Query OK, 4 rows affected (0.01 sec)

mysql&gt; select * from employees where first_name=&#039;Brian&#039;;
+------+------------+------------+
| id   | last_name  | first_name |
+------+------------+------------+
|    1 | Hendriks   | Brian      |
|    3 | Fitzgerald | Brian      |
+------+------------+------------+
2 rows in set (0.00 sec)

mysql&gt; insert into teams values 
    (0, &#039;Engineering&#039;), 
    (1, &#039;Sales&#039;);
Query OK, 2 rows affected (0.00 sec)

mysql&gt; insert into employees_teams values 
    (0,0), 
    (1,0), 
    (2,0), 
    (0,1), 
    (3,1);
ERROR 1452 (HY000): cannot add or update a child row - Foreign key violation on fk: `rv9ek7ft`, table: `employees_teams`, referenced table: `teams`, key: `[2]`
```

Oops, I violated a constraint. It looks like I created the table with teams before employees. You should always specify your columns when you insert, not rely on natural ordering. Serves me right! Dolt comes with the full power of a modern SQL relational database to ensure data integrity.

```
mysql&gt; insert into employees_teams(employee_id, team_id) values 
    (0,0), 
    (1,0), 
    (2,0), 
    (0,1), 
    (3,1);
Query OK, 5 rows affected (0.01 sec)

mysql&gt; select first_name, last_name, team_name from employees 
    join employees_teams on (employees.id=employees_teams.employee_id) 
    join teams on (teams.id=employees_teams.team_id) 
    where team_name=&#039;Engineering&#039;;
+------------+-----------+-------------+
| first_name | last_name | team_name   |
+------------+-----------+-------------+
| Tim        | Sehn      | Engineering |
| Brian      | Hendriks  | Engineering |
| Aaron      | Son       | Engineering |
+------------+-----------+-------------+
3 rows in set (0.00 sec)
```

Looks like everything is inserted and correct. I was able to list the members of the engineering team using that three table `JOIN`. Dolt supports up to twelve table `JOIN`s. Again, Dolt is a modern SQL relational database paired with Git-style version control.

## Examine the diff

Now, what if you want to see what changed in your working set before you make a commit? You use the `dolt_status` and `dolt_diff_&lt;tablename&gt;` system tables. 

```
mysql&gt; select * from dolt_status;
+-----------------+--------+----------+
| table_name      | staged | status   |
+-----------------+--------+----------+
| teams           |      0 | modified |
| employees       |      0 | modified |
| employees_teams |      0 | modified |
+-----------------+--------+----------+
3 rows in set (0.01 sec)

mysql&gt; select * from dolt_diff_employees;
+--------------+---------------+-------+-----------+----------------+----------------+-----------------+---------+----------------------------------+-------------------------+-----------+
| to_last_name | to_first_name | to_id | to_commit | to_commit_date | from_last_name | from_first_name | from_id | from_commit                      | from_commit_date        | diff_type |
+--------------+---------------+-------+-----------+----------------+----------------+-----------------+---------+----------------------------------+-------------------------+-----------+
| Sehn         | Tim           |     0 | WORKING   | NULL           | NULL           | NULL            |    NULL | ne182jemgrlm8jnjmoubfqsstlfi1s98 | 2022-06-07

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[fatedier/frp]]></title>
            <link>https://github.com/fatedier/frp</link>
            <guid>https://github.com/fatedier/frp</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:41 GMT</pubDate>
            <description><![CDATA[A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fatedier/frp">fatedier/frp</a></h1>
            <p>A fast reverse proxy to help you expose a local server behind a NAT or firewall to the internet.</p>
            <p>Language: Go</p>
            <p>Stars: 104,729</p>
            <p>Forks: 14,912</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre># frp

[![Build Status](https://circleci.com/gh/fatedier/frp.svg?style=shield)](https://circleci.com/gh/fatedier/frp)
[![GitHub release](https://img.shields.io/github/tag/fatedier/frp.svg?label=release)](https://github.com/fatedier/frp/releases)
[![Go Report Card](https://goreportcard.com/badge/github.com/fatedier/frp)](https://goreportcard.com/report/github.com/fatedier/frp)
[![GitHub Releases Stats](https://img.shields.io/github/downloads/fatedier/frp/total.svg?logo=github)](https://somsubhra.github.io/github-release-stats/?username=fatedier&amp;repository=frp)

[README](README.md) | [ä¸­æ–‡æ–‡æ¡£](README_zh.md)

## Sponsors

frp is an open source project with its ongoing development made possible entirely by the support of our awesome sponsors. If you&#039;d like to join them, please consider [sponsoring frp&#039;s development](https://github.com/sponsors/fatedier).

&lt;h3 align=&quot;center&quot;&gt;Gold Sponsors&lt;/h3&gt;
&lt;!--gold sponsors start--&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://requestly.com/?utm_source=github&amp;utm_medium=partnered&amp;utm_campaign=frp&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;480px&quot; src=&quot;https://github.com/user-attachments/assets/24670320-997d-4d62-9bca-955c59fe883d&quot;&gt;
    &lt;br&gt;
    &lt;b&gt;Requestly - Free &amp; Open-Source alternative to Postman&lt;/b&gt;
    &lt;br&gt;
    &lt;sub&gt;All-in-one platform to Test, Mock and Intercept APIs.&lt;/sub&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://jb.gg/frp&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;420px&quot; src=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_jetbrains.jpg&quot;&gt;
	&lt;br&gt;
	&lt;b&gt;The complete IDE crafted for professional Go developers&lt;/b&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/beclab/Olares&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;420px&quot; src=&quot;https://raw.githubusercontent.com/fatedier/frp/dev/doc/pic/sponsor_olares.jpeg&quot;&gt;
	&lt;br&gt;
	&lt;b&gt;The sovereign cloud that puts you in control&lt;/b&gt;
	&lt;br&gt;
	&lt;sub&gt;An open source, self-hosted alternative to public clouds, built for data ownership and privacy&lt;/sub&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;

## Recall.ai - API for meeting recordings

If you&#039;re looking for a meeting recording API, consider checking out [Recall.ai](https://www.recall.ai/?utm_source=github&amp;utm_medium=sponsorship&amp;utm_campaign=fatedier-frp),

an API that records Zoom, Google Meet, Microsoft Teams, in-person meetings, and more.

&lt;/div&gt;
&lt;!--gold sponsors end--&gt;

## What is frp?

frp is a fast reverse proxy that allows you to expose a local server located behind a NAT or firewall to the Internet. It currently supports **TCP** and **UDP**, as well as **HTTP** and **HTTPS** protocols, enabling requests to be forwarded to internal services via domain name.

frp also offers a P2P connect mode.

## Table of Contents

&lt;!-- vim-markdown-toc GFM --&gt;

* [Development Status](#development-status)
    * [About V2](#about-v2)
* [Architecture](#architecture)
* [Example Usage](#example-usage)
    * [Access your computer in a LAN network via SSH](#access-your-computer-in-a-lan-network-via-ssh)
    * [Multiple SSH services sharing the same port](#multiple-ssh-services-sharing-the-same-port)
    * [Accessing Internal Web Services with Custom Domains in LAN](#accessing-internal-web-services-with-custom-domains-in-lan)
    * [Forward DNS query requests](#forward-dns-query-requests)
    * [Forward Unix Domain Socket](#forward-unix-domain-socket)
    * [Expose a simple HTTP file server](#expose-a-simple-http-file-server)
    * [Enable HTTPS for a local HTTP(S) service](#enable-https-for-a-local-https-service)
    * [Expose your service privately](#expose-your-service-privately)
    * [P2P Mode](#p2p-mode)
* [Features](#features)
    * [Configuration Files](#configuration-files)
    * [Using Environment Variables](#using-environment-variables)
    * [Split Configures Into Different Files](#split-configures-into-different-files)
    * [Server Dashboard](#server-dashboard)
    * [Client Admin UI](#client-admin-ui)
    * [Monitor](#monitor)
        * [Prometheus](#prometheus)
    * [Authenticating the Client](#authenticating-the-client)
        * [Token Authentication](#token-authentication)
        * [OIDC Authentication](#oidc-authentication)
    * [Encryption and Compression](#encryption-and-compression)
        * [TLS](#tls)
    * [Hot-Reloading frpc configuration](#hot-reloading-frpc-configuration)
    * [Get proxy status from client](#get-proxy-status-from-client)
    * [Only allowing certain ports on the server](#only-allowing-certain-ports-on-the-server)
    * [Port Reuse](#port-reuse)
    * [Bandwidth Limit](#bandwidth-limit)
        * [For Each Proxy](#for-each-proxy)
    * [TCP Stream Multiplexing](#tcp-stream-multiplexing)
    * [Support KCP Protocol](#support-kcp-protocol)
    * [Support QUIC Protocol](#support-quic-protocol)
    * [Connection Pooling](#connection-pooling)
    * [Load balancing](#load-balancing)
    * [Service Health Check](#service-health-check)
    * [Rewriting the HTTP Host Header](#rewriting-the-http-host-header)
    * [Setting other HTTP Headers](#setting-other-http-headers)
    * [Get Real IP](#get-real-ip)
        * [HTTP X-Forwarded-For](#http-x-forwarded-for)
        * [Proxy Protocol](#proxy-protocol)
    * [Require HTTP Basic Auth (Password) for Web Services](#require-http-basic-auth-password-for-web-services)
    * [Custom Subdomain Names](#custom-subdomain-names)
    * [URL Routing](#url-routing)
    * [TCP Port Multiplexing](#tcp-port-multiplexing)
    * [Connecting to frps via PROXY](#connecting-to-frps-via-proxy)
    * [Port range mapping](#port-range-mapping)
    * [Client Plugins](#client-plugins)
    * [Server Manage Plugins](#server-manage-plugins)
    * [SSH Tunnel Gateway](#ssh-tunnel-gateway)
    * [Virtual Network (VirtualNet)](#virtual-network-virtualnet)
* [Feature Gates](#feature-gates)
    * [Available Feature Gates](#available-feature-gates)
    * [Enabling Feature Gates](#enabling-feature-gates)
    * [Feature Lifecycle](#feature-lifecycle)
* [Related Projects](#related-projects)
* [Contributing](#contributing)
* [Donation](#donation)
    * [GitHub Sponsors](#github-sponsors)
    * [PayPal](#paypal)

&lt;!-- vim-markdown-toc --&gt;

## Development Status

frp is currently under development. You can try the latest release version in the `master` branch, or use the `dev` branch to access the version currently in development.

We are currently working on version 2 and attempting to perform some code refactoring and improvements. However, please note that it will not be compatible with version 1.

We will transition from version 0 to version 1 at the appropriate time and will only accept bug fixes and improvements, rather than big feature requests.

### About V2

The complexity and difficulty of the v2 version are much higher than anticipated. I can only work on its development during fragmented time periods, and the constant interruptions disrupt productivity significantly. Given this situation, we will continue to optimize and iterate on the current version until we have more free time to proceed with the major version overhaul.

The concept behind v2 is based on my years of experience and reflection in the cloud-native domain, particularly in K8s and ServiceMesh. Its core is a modernized four-layer and seven-layer proxy, similar to envoy. This proxy itself is highly scalable, not only capable of implementing the functionality of intranet penetration but also applicable to various other domains. Building upon this highly scalable core, we aim to implement all the capabilities of frp v1 while also addressing the functionalities that were previously unachievable or difficult to implement in an elegant manner. Furthermore, we will maintain efficient development and iteration capabilities.

In addition, I envision frp itself becoming a highly extensible system and platform, similar to how we can provide a range of extension capabilities based on K8s. In K8s, we can customize development according to enterprise needs, utilizing features such as CRD, controller mode, webhook, CSI, and CNI. In frp v1, we introduced the concept of server plugins, which implemented some basic extensibility. However, it relies on a simple HTTP protocol and requires users to start independent processes and manage them on their own. This approach is far from flexible and convenient, and real-world demands vary greatly. It is unrealistic to expect a non-profit open-source project maintained by a few individuals to meet everyone&#039;s needs.

Finally, we acknowledge that the current design of modules such as configuration management, permission verification, certificate management, and API management is not modern enough. While we may carry out some optimizations in the v1 version, ensuring compatibility remains a challenging issue that requires a considerable amount of effort to address.

We sincerely appreciate your support for frp.

## Architecture

![architecture](/doc/pic/architecture.png)

## Example Usage

To begin, download the latest program for your operating system and architecture from the [Release](https://github.com/fatedier/frp/releases) page.

Next, place the `frps` binary and server configuration file on Server A, which has a public IP address.

Finally, place the `frpc` binary and client configuration file on Server B, which is located on a LAN that cannot be directly accessed from the public internet.

Some antiviruses improperly mark frpc as malware and delete it. This is due to frp being a networking tool capable of creating reverse proxies. Antiviruses sometimes flag reverse proxies due to their ability to bypass firewall port restrictions. If you are using antivirus, then you may need to whitelist/exclude frpc in your antivirus settings to avoid accidental quarantine/deletion. See [issue 3637](https://github.com/fatedier/frp/issues/3637) for more details.

### Access your computer in a LAN network via SSH

1. Modify `frps.toml` on server A by setting the `bindPort` for frp clients to connect to:

  ```toml
  # frps.toml
  bindPort = 7000
  ```

2. Start `frps` on server A:

  `./frps -c ./frps.toml`

3. Modify `frpc.toml` on server B and set the `serverAddr` field to the public IP address of your frps server:

  ```toml
  # frpc.toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000

  [[proxies]]
  name = &quot;ssh&quot;
  type = &quot;tcp&quot;
  localIP = &quot;127.0.0.1&quot;
  localPort = 22
  remotePort = 6000
  ```

Note that the `localPort` (listened on the client) and `remotePort` (exposed on the server) are used for traffic going in and out of the frp system, while the `serverPort` is used for communication between frps and frpc.

4. Start `frpc` on server B:

  `./frpc -c ./frpc.toml`

5. To access server B from another machine through server A via SSH (assuming the username is `test`), use the following command:

  `ssh -oPort=6000 test@x.x.x.x`

### Multiple SSH services sharing the same port

This example implements multiple SSH services exposed through the same port using a proxy of type tcpmux. Similarly, as long as the client supports the HTTP Connect proxy connection method, port reuse can be achieved in this way.

1. Deploy frps on a machine with a public IP and modify the frps.toml file. Here is a simplified configuration:

  ```toml
  bindPort = 7000
  tcpmuxHTTPConnectPort = 5002
  ```

2. Deploy frpc on the internal machine A with the following configuration:

  ```toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000

  [[proxies]]
  name = &quot;ssh1&quot;
  type = &quot;tcpmux&quot;
  multiplexer = &quot;httpconnect&quot;
  customDomains = [&quot;machine-a.example.com&quot;]
  localIP = &quot;127.0.0.1&quot;
  localPort = 22
  ```

3. Deploy another frpc on the internal machine B with the following configuration:

  ```toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000

  [[proxies]]
  name = &quot;ssh2&quot;
  type = &quot;tcpmux&quot;
  multiplexer = &quot;httpconnect&quot;
  customDomains = [&quot;machine-b.example.com&quot;]
  localIP = &quot;127.0.0.1&quot;
  localPort = 22
  ```

4. To access internal machine A using SSH ProxyCommand, assuming the username is &quot;test&quot;:

  `ssh -o &#039;proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002&#039; test@machine-a.example.com`

5. To access internal machine B, the only difference is the domain name, assuming the username is &quot;test&quot;:

  `ssh -o &#039;proxycommand socat - PROXY:x.x.x.x:%h:%p,proxyport=5002&#039; test@machine-b.example.com`

### Accessing Internal Web Services with Custom Domains in LAN

Sometimes we need to expose a local web service behind a NAT network to others for testing purposes with our own domain name.

Unfortunately, we cannot resolve a domain name to a local IP. However, we can use frp to expose an HTTP(S) service.

1. Modify `frps.toml` and set the HTTP port for vhost to 8080:

  ```toml
  # frps.toml
  bindPort = 7000
  vhostHTTPPort = 8080
  ```

  If you want to configure an https proxy, you need to set up the `vhostHTTPSPort`.

2. Start `frps`:

  `./frps -c ./frps.toml`

3. Modify `frpc.toml` and set `serverAddr` to the IP address of the remote frps server. Specify the `localPort` of your web service:

  ```toml
  # frpc.toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000

  [[proxies]]
  name = &quot;web&quot;
  type = &quot;http&quot;
  localPort = 80
  customDomains = [&quot;www.example.com&quot;]
  ```

4. Start `frpc`:

  `./frpc -c ./frpc.toml`

5. Map the A record of `www.example.com` to either the public IP of the remote frps server or a CNAME record pointing to your original domain.

6. Visit your local web service using url `http://www.example.com:8080`.

### Forward DNS query requests

1. Modify `frps.toml`:

  ```toml
  # frps.toml
  bindPort = 7000
  ```

2. Start `frps`:

  `./frps -c ./frps.toml`

3. Modify `frpc.toml` and set `serverAddr` to the IP address of the remote frps server. Forward DNS query requests to the Google Public DNS server `8.8.8.8:53`:

  ```toml
  # frpc.toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000

  [[proxies]]
  name = &quot;dns&quot;
  type = &quot;udp&quot;
  localIP = &quot;8.8.8.8&quot;
  localPort = 53
  remotePort = 6000
  ```

4. Start frpc:

  `./frpc -c ./frpc.toml`

5. Test DNS resolution using the `dig` command:

  `dig @x.x.x.x -p 6000 www.google.com`

### Forward Unix Domain Socket

Expose a Unix domain socket (e.g. the Docker daemon socket) as TCP.

Configure `frps` as above.

1. Start `frpc` with the following configuration:

  ```toml
  # frpc.toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000

  [[proxies]]
  name = &quot;unix_domain_socket&quot;
  type = &quot;tcp&quot;
  remotePort = 6000
  [proxies.plugin]
  type = &quot;unix_domain_socket&quot;
  unixPath = &quot;/var/run/docker.sock&quot;
  ```

2. Test the configuration by getting the docker version using `curl`:

  `curl http://x.x.x.x:6000/version`

### Expose a simple HTTP file server

Expose a simple HTTP file server to access files stored in the LAN from the public Internet.

Configure `frps` as described above, then:

1. Start `frpc` with the following configuration:

  ```toml
  # frpc.toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000

  [[proxies]]
  name = &quot;test_static_file&quot;
  type = &quot;tcp&quot;
  remotePort = 6000
  [proxies.plugin]
  type = &quot;static_file&quot;
  localPath = &quot;/tmp/files&quot;
  stripPrefix = &quot;static&quot;
  httpUser = &quot;abc&quot;
  httpPassword = &quot;abc&quot;
  ```

2. Visit `http://x.x.x.x:6000/static/` from your browser and specify correct username and password to view files in `/tmp/files` on the `frpc` machine.

### Enable HTTPS for a local HTTP(S) service

You may substitute `https2https` for the plugin, and point the `localAddr` to a HTTPS endpoint.

1. Start `frpc` with the following configuration:

  ```toml
  # frpc.toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000

  [[proxies]]
  name = &quot;test_https2http&quot;
  type = &quot;https&quot;
  customDomains = [&quot;test.example.com&quot;]

  [proxies.plugin]
  type = &quot;https2http&quot;
  localAddr = &quot;127.0.0.1:80&quot;
  crtPath = &quot;./server.crt&quot;
  keyPath = &quot;./server.key&quot;
  hostHeaderRewrite = &quot;127.0.0.1&quot;
  requestHeaders.set.x-from-where = &quot;frp&quot;
  ```

2. Visit `https://test.example.com`.

### Expose your service privately

To mitigate risks associated with exposing certain services directly to the public network, STCP (Secret TCP) mode requires a preshared key to be used for access to the service from other clients.

Configure `frps` same as above.

1. Start `frpc` on machine B with the following config. This example is for exposing the SSH service (port 22), and note the `secretKey` field for the preshared key, and that the `remotePort` field is removed here:

  ```toml
  # frpc.toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000

  [[proxies]]
  name = &quot;secret_ssh&quot;
  type = &quot;stcp&quot;
  secretKey = &quot;abcdefg&quot;
  localIP = &quot;127.0.0.1&quot;
  localPort = 22
  ```

2. Start another `frpc` (typically on another machine C) with the following config to access the SSH service with a security key (`secretKey` field):

  ```toml
  # frpc.toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000

  [[visitors]]
  name = &quot;secret_ssh_visitor&quot;
  type = &quot;stcp&quot;
  serverName = &quot;secret_ssh&quot;
  secretKey = &quot;abcdefg&quot;
  bindAddr = &quot;127.0.0.1&quot;
  bindPort = 6000
  ```

3. On machine C, connect to SSH on machine B, using this command:

  `ssh -oPort=6000 127.0.0.1`

### P2P Mode

**xtcp** is designed to transmit large amounts of data directly between clients. A frps server is still needed, as P2P here only refers to the actual data transmission.

Note that it may not work with all types of NAT devices. You might want to fallback to stcp if xtcp doesn&#039;t work.

1. Start `frpc` on machine B, and expose the SSH port. Note that the `remotePort` field is removed:

  ```toml
  # frpc.toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000
  # set up a new stun server if the default one is not available.
  # natHoleStunServer = &quot;xxx&quot;

  [[proxies]]
  name = &quot;p2p_ssh&quot;
  type = &quot;xtcp&quot;
  secretKey = &quot;abcdefg&quot;
  localIP = &quot;127.0.0.1&quot;
  localPort = 22
  ```

2. Start another `frpc` (typically on another machine C) with the configuration to connect to SSH using P2P mode:

  ```toml
  # frpc.toml
  serverAddr = &quot;x.x.x.x&quot;
  serverPort = 7000
  # set up a new stun server if the default one is not available.
  # natHoleStunServer = &quot;xxx&quot;

  [[visitors]]
  name = &quot;p2p_ssh_visitor&quot;
  type = &quot;xtcp&quot;
  serverName = &quot;p2p_ssh&quot;
  secretKey = &quot;abcdefg&quot;
  bindAddr = &quot;127.0.0.1&quot;
  bindPort = 6000
  # when automatic tunnel persistence is required, set it to true
  keepTunnelOpen = false
  ```

3. On machine C, connect to SSH on machine B, using this command:

  `ssh -oPort=6000 127.0.0.1`

## Features

### Configuration Files

Since v0.52.0, we support TOML, YAML, and JSON for configuration. Please note that INI is deprecated and will be removed in future releases. New features will only be available in TOML, YAML, or JSON. Users wanting these new features should switch their configuration format accordingly.

Read the full example configuration files to find out even more features not described here.

Examples use TOML format, but you can still use YAML or JSON.

These configuration files is for reference only. Please do not use this configuration directly to run the program as it may have various issues.

[Full configuration file for frps (Server)](./conf/frps_full_example.toml)

[Full configuration file for frpc (Client)](./conf/frpc_full_example.toml)

### Using Environment Variables

Environment variables can be referenced in the configuration file, using Go&#039;s standard format:

```toml
# frpc.toml
serverAddr = &quot;{{ .Envs.FRP_SERVER_ADDR }}&quot;
serverPort = 7000

[[proxies]]
name = &quot;ssh&quot;
type = &quot;tcp&quot;
localIP = &quot;127.0.0.1&quot;
localPort = 22
remotePort = {{ .Envs.FRP_SSH_REMOTE_PORT }}
```

With the config above, variables can be passed into `frpc` program like this:

```
export FRP_SERVER_ADDR=x.x.x.x
export FRP_SSH_REMOTE_PORT=6000
./frpc -c ./frpc.toml
```

`frpc` will render configuration file template using OS environment variables. Remember to prefix your reference with `.Envs`.

### Split Configures Into Different Files

You can split multiple proxy configs into different files and include them in the main file.

```toml
# frpc.toml
serverAddr = &quot;x.x.x.x&quot;
serverPort = 7000
includes = [&quot;./confd/*.toml&quot;]
```

```toml
# ./confd/test.toml

[[proxies]]
name = &quot;ssh&quot;
type = &quot;tcp&quot;
localI

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Wei-Shaw/sub2api]]></title>
            <link>https://github.com/Wei-Shaw/sub2api</link>
            <guid>https://github.com/Wei-Shaw/sub2api</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:40 GMT</pubDate>
            <description><![CDATA[Sub2API-CRS2 ä¸€ç«™å¼å¼€æºä¸­è½¬æœåŠ¡ï¼Œè®© Claudeã€Openai ã€Geminiã€Antigravityè®¢é˜…ç»Ÿä¸€æ¥å…¥ï¼Œæ”¯æŒæ‹¼è½¦å…±äº«ï¼Œæ›´é«˜æ•ˆåˆ†æ‘Šæˆæœ¬ï¼ŒåŸç”Ÿå·¥å…·æ— ç¼ä½¿ç”¨ã€‚]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Wei-Shaw/sub2api">Wei-Shaw/sub2api</a></h1>
            <p>Sub2API-CRS2 ä¸€ç«™å¼å¼€æºä¸­è½¬æœåŠ¡ï¼Œè®© Claudeã€Openai ã€Geminiã€Antigravityè®¢é˜…ç»Ÿä¸€æ¥å…¥ï¼Œæ”¯æŒæ‹¼è½¦å…±äº«ï¼Œæ›´é«˜æ•ˆåˆ†æ‘Šæˆæœ¬ï¼ŒåŸç”Ÿå·¥å…·æ— ç¼ä½¿ç”¨ã€‚</p>
            <p>Language: Go</p>
            <p>Stars: 2,251</p>
            <p>Forks: 441</p>
            <p>Stars today: 97 stars today</p>
            <h2>README</h2><pre># Sub2API

&lt;div align=&quot;center&quot;&gt;

[![Go](https://img.shields.io/badge/Go-1.25.7-00ADD8.svg)](https://golang.org/)
[![Vue](https://img.shields.io/badge/Vue-3.4+-4FC08D.svg)](https://vuejs.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-336791.svg)](https://www.postgresql.org/)
[![Redis](https://img.shields.io/badge/Redis-7+-DC382D.svg)](https://redis.io/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED.svg)](https://www.docker.com/)

**AI API Gateway Platform for Subscription Quota Distribution**

English | [ä¸­æ–‡](README_CN.md)

&lt;/div&gt;

---

## Demo

Try Sub2API online: **https://demo.sub2api.org/**

Demo credentials (shared demo environment; **not** created automatically for self-hosted installs):

| Email | Password |
|-------|----------|
| admin@sub2api.com | admin123 |

## Overview

Sub2API is an AI API gateway platform designed to distribute and manage API quotas from AI product subscriptions (like Claude Code $200/month). Users can access upstream AI services through platform-generated API Keys, while the platform handles authentication, billing, load balancing, and request forwarding.

## Features

- **Multi-Account Management** - Support multiple upstream account types (OAuth, API Key)
- **API Key Distribution** - Generate and manage API Keys for users
- **Precise Billing** - Token-level usage tracking and cost calculation
- **Smart Scheduling** - Intelligent account selection with sticky sessions
- **Concurrency Control** - Per-user and per-account concurrency limits
- **Rate Limiting** - Configurable request and token rate limits
- **Admin Dashboard** - Web interface for monitoring and management

## Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | Go 1.25.7, Gin, Ent |
| Frontend | Vue 3.4+, Vite 5+, TailwindCSS |
| Database | PostgreSQL 15+ |
| Cache/Queue | Redis 7+ |

---

## Documentation

- Dependency Security: `docs/dependency-security.md`

---

## Deployment

### Method 1: Script Installation (Recommended)

One-click installation script that downloads pre-built binaries from GitHub Releases.

#### Prerequisites

- Linux server (amd64 or arm64)
- PostgreSQL 15+ (installed and running)
- Redis 7+ (installed and running)
- Root privileges

#### Installation Steps

```bash
curl -sSL https://raw.githubusercontent.com/Wei-Shaw/sub2api/main/deploy/install.sh | sudo bash
```

The script will:
1. Detect your system architecture
2. Download the latest release
3. Install binary to `/opt/sub2api`
4. Create systemd service
5. Configure system user and permissions

#### Post-Installation

```bash
# 1. Start the service
sudo systemctl start sub2api

# 2. Enable auto-start on boot
sudo systemctl enable sub2api

# 3. Open Setup Wizard in browser
# http://YOUR_SERVER_IP:8080
```

The Setup Wizard will guide you through:
- Database configuration
- Redis configuration
- Admin account creation

#### Upgrade

You can upgrade directly from the **Admin Dashboard** by clicking the **Check for Updates** button in the top-left corner.

The web interface will:
- Check for new versions automatically
- Download and apply updates with one click
- Support rollback if needed

#### Useful Commands

```bash
# Check status
sudo systemctl status sub2api

# View logs
sudo journalctl -u sub2api -f

# Restart service
sudo systemctl restart sub2api

# Uninstall
curl -sSL https://raw.githubusercontent.com/Wei-Shaw/sub2api/main/deploy/install.sh | sudo bash -s -- uninstall -y
```

---

### Method 2: Docker Compose (Recommended)

Deploy with Docker Compose, including PostgreSQL and Redis containers.

#### Prerequisites

- Docker 20.10+
- Docker Compose v2+

#### Quick Start (One-Click Deployment)

Use the automated deployment script for easy setup:

```bash
# Create deployment directory
mkdir -p sub2api-deploy &amp;&amp; cd sub2api-deploy

# Download and run deployment preparation script
curl -sSL https://raw.githubusercontent.com/Wei-Shaw/sub2api/main/deploy/docker-deploy.sh | bash

# Start services
docker-compose -f docker-compose.local.yml up -d

# View logs
docker-compose -f docker-compose.local.yml logs -f sub2api
```

**What the script does:**
- Downloads `docker-compose.local.yml` and `.env.example`
- Generates secure credentials (JWT_SECRET, TOTP_ENCRYPTION_KEY, POSTGRES_PASSWORD)
- Creates `.env` file with auto-generated secrets
- Creates data directories (uses local directories for easy backup/migration)
- Displays generated credentials for your reference

#### Manual Deployment

If you prefer manual setup:

```bash
# 1. Clone the repository
git clone https://github.com/Wei-Shaw/sub2api.git
cd sub2api/deploy

# 2. Copy environment configuration
cp .env.example .env

# 3. Edit configuration (generate secure passwords)
nano .env
```

**Required configuration in `.env`:**

```bash
# PostgreSQL password (REQUIRED)
POSTGRES_PASSWORD=your_secure_password_here

# JWT Secret (RECOMMENDED - keeps users logged in after restart)
JWT_SECRET=your_jwt_secret_here

# TOTP Encryption Key (RECOMMENDED - preserves 2FA after restart)
TOTP_ENCRYPTION_KEY=your_totp_key_here

# Optional: Admin account
ADMIN_EMAIL=admin@example.com
ADMIN_PASSWORD=your_admin_password

# Optional: Custom port
SERVER_PORT=8080
```

**Generate secure secrets:**
```bash
# Generate JWT_SECRET
openssl rand -hex 32

# Generate TOTP_ENCRYPTION_KEY
openssl rand -hex 32

# Generate POSTGRES_PASSWORD
openssl rand -hex 32
```

```bash
# 4. Create data directories (for local version)
mkdir -p data postgres_data redis_data

# 5. Start all services
# Option A: Local directory version (recommended - easy migration)
docker-compose -f docker-compose.local.yml up -d

# Option B: Named volumes version (simple setup)
docker-compose up -d

# 6. Check status
docker-compose -f docker-compose.local.yml ps

# 7. View logs
docker-compose -f docker-compose.local.yml logs -f sub2api
```

#### Deployment Versions

| Version | Data Storage | Migration | Best For |
|---------|-------------|-----------|----------|
| **docker-compose.local.yml** | Local directories | âœ… Easy (tar entire directory) | Production, frequent backups |
| **docker-compose.yml** | Named volumes | âš ï¸ Requires docker commands | Simple setup |

**Recommendation:** Use `docker-compose.local.yml` (deployed by script) for easier data management.

#### Access

Open `http://YOUR_SERVER_IP:8080` in your browser.

If admin password was auto-generated, find it in logs:
```bash
docker-compose -f docker-compose.local.yml logs sub2api | grep &quot;admin password&quot;
```

#### Upgrade

```bash
# Pull latest image and recreate container
docker-compose -f docker-compose.local.yml pull
docker-compose -f docker-compose.local.yml up -d
```

#### Easy Migration (Local Directory Version)

When using `docker-compose.local.yml`, migrate to a new server easily:

```bash
# On source server
docker-compose -f docker-compose.local.yml down
cd ..
tar czf sub2api-complete.tar.gz sub2api-deploy/

# Transfer to new server
scp sub2api-complete.tar.gz user@new-server:/path/

# On new server
tar xzf sub2api-complete.tar.gz
cd sub2api-deploy/
docker-compose -f docker-compose.local.yml up -d
```

#### Useful Commands

```bash
# Stop all services
docker-compose -f docker-compose.local.yml down

# Restart
docker-compose -f docker-compose.local.yml restart

# View all logs
docker-compose -f docker-compose.local.yml logs -f

# Remove all data (caution!)
docker-compose -f docker-compose.local.yml down
rm -rf data/ postgres_data/ redis_data/
```

---

### Method 3: Build from Source

Build and run from source code for development or customization.

#### Prerequisites

- Go 1.21+
- Node.js 18+
- PostgreSQL 15+
- Redis 7+

#### Build Steps

```bash
# 1. Clone the repository
git clone https://github.com/Wei-Shaw/sub2api.git
cd sub2api

# 2. Install pnpm (if not already installed)
npm install -g pnpm

# 3. Build frontend
cd frontend
pnpm install
pnpm run build
# Output will be in ../backend/internal/web/dist/

# 4. Build backend with embedded frontend
cd ../backend
go build -tags embed -o sub2api ./cmd/server

# 5. Create configuration file
cp ../deploy/config.example.yaml ./config.yaml

# 6. Edit configuration
nano config.yaml
```

&gt; **Note:** The `-tags embed` flag embeds the frontend into the binary. Without this flag, the binary will not serve the frontend UI.

**Key configuration in `config.yaml`:**

```yaml
server:
  host: &quot;0.0.0.0&quot;
  port: 8080
  mode: &quot;release&quot;

database:
  host: &quot;localhost&quot;
  port: 5432
  user: &quot;postgres&quot;
  password: &quot;your_password&quot;
  dbname: &quot;sub2api&quot;

redis:
  host: &quot;localhost&quot;
  port: 6379
  password: &quot;&quot;

jwt:
  secret: &quot;change-this-to-a-secure-random-string&quot;
  expire_hour: 24

default:
  user_concurrency: 5
  user_balance: 0
  api_key_prefix: &quot;sk-&quot;
  rate_multiplier: 1.0
```

### Sora Status (Temporarily Unavailable)

&gt; âš ï¸ Sora-related features are temporarily unavailable due to technical issues in upstream integration and media delivery.
&gt; Please do not rely on Sora in production at this time.
&gt; Existing `gateway.sora_*` configuration keys are reserved and may not take effect until these issues are resolved.

Additional security-related options are available in `config.yaml`:

- `cors.allowed_origins` for CORS allowlist
- `security.url_allowlist` for upstream/pricing/CRS host allowlists
- `security.url_allowlist.enabled` to disable URL validation (use with caution)
- `security.url_allowlist.allow_insecure_http` to allow HTTP URLs when validation is disabled
- `security.url_allowlist.allow_private_hosts` to allow private/local IP addresses
- `security.response_headers.enabled` to enable configurable response header filtering (disabled uses default allowlist)
- `security.csp` to control Content-Security-Policy headers
- `billing.circuit_breaker` to fail closed on billing errors
- `server.trusted_proxies` to enable X-Forwarded-For parsing
- `turnstile.required` to require Turnstile in release mode

**âš ï¸ Security Warning: HTTP URL Configuration**

When `security.url_allowlist.enabled=false`, the system performs minimal URL validation by default, **rejecting HTTP URLs** and only allowing HTTPS. To allow HTTP URLs (e.g., for development or internal testing), you must explicitly set:

```yaml
security:
  url_allowlist:
    enabled: false                # Disable allowlist checks
    allow_insecure_http: true     # Allow HTTP URLs (âš ï¸ INSECURE)
```

**Or via environment variable:**

```bash
SECURITY_URL_ALLOWLIST_ENABLED=false
SECURITY_URL_ALLOWLIST_ALLOW_INSECURE_HTTP=true
```

**Risks of allowing HTTP:**
- API keys and data transmitted in **plaintext** (vulnerable to interception)
- Susceptible to **man-in-the-middle (MITM) attacks**
- **NOT suitable for production** environments

**When to use HTTP:**
- âœ… Development/testing with local servers (http://localhost)
- âœ… Internal networks with trusted endpoints
- âœ… Testing account connectivity before obtaining HTTPS
- âŒ Production environments (use HTTPS only)

**Example error without this setting:**
```
Invalid base URL: invalid url scheme: http
```

If you disable URL validation or response header filtering, harden your network layer:
- Enforce an egress allowlist for upstream domains/IPs
- Block private/loopback/link-local ranges
- Enforce TLS-only outbound traffic
- Strip sensitive upstream response headers at the proxy

```bash
# 6. Run the application
./sub2api
```

#### Development Mode

```bash
# Backend (with hot reload)
cd backend
go run ./cmd/server

# Frontend (with hot reload)
cd frontend
pnpm run dev
```

#### Code Generation

When editing `backend/ent/schema`, regenerate Ent + Wire:

```bash
cd backend
go generate ./ent
go generate ./cmd/server
```

---

## Simple Mode

Simple Mode is designed for individual developers or internal teams who want quick access without full SaaS features.

- Enable: Set environment variable `RUN_MODE=simple`
- Difference: Hides SaaS-related features and skips billing process
- Security note: In production, you must also set `SIMPLE_MODE_CONFIRM=true` to allow startup

---

## Antigravity Support

Sub2API supports [Antigravity](https://antigravity.so/) accounts. After authorization, dedicated endpoints are available for Claude and Gemini models.

### Dedicated Endpoints

| Endpoint | Model |
|----------|-------|
| `/antigravity/v1/messages` | Claude models |
| `/antigravity/v1beta/` | Gemini models |

### Claude Code Configuration

```bash
export ANTHROPIC_BASE_URL=&quot;http://localhost:8080/antigravity&quot;
export ANTHROPIC_AUTH_TOKEN=&quot;sk-xxx&quot;
```

### Hybrid Scheduling Mode

Antigravity accounts support optional **hybrid scheduling**. When enabled, the general endpoints `/v1/messages` and `/v1beta/` will also route requests to Antigravity accounts.

&gt; **âš ï¸ Warning**: Anthropic Claude and Antigravity Claude **cannot be mixed within the same conversation context**. Use groups to isolate them properly.

### Known Issues

In Claude Code, Plan Mode cannot exit automatically. (Normally when using the native Claude API, after planning is complete, Claude Code will pop up options for users to approve or reject the plan.)

**Workaround**: Press `Shift + Tab` to manually exit Plan Mode, then type your response to approve or reject the plan.

---

## Project Structure

```
sub2api/
â”œâ”€â”€ backend/                  # Go backend service
â”‚   â”œâ”€â”€ cmd/server/           # Application entry
â”‚   â”œâ”€â”€ internal/             # Internal modules
â”‚   â”‚   â”œâ”€â”€ config/           # Configuration
â”‚   â”‚   â”œâ”€â”€ model/            # Data models
â”‚   â”‚   â”œâ”€â”€ service/          # Business logic
â”‚   â”‚   â”œâ”€â”€ handler/          # HTTP handlers
â”‚   â”‚   â””â”€â”€ gateway/          # API gateway core
â”‚   â””â”€â”€ resources/            # Static resources
â”‚
â”œâ”€â”€ frontend/                 # Vue 3 frontend
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ api/              # API calls
â”‚       â”œâ”€â”€ stores/           # State management
â”‚       â”œâ”€â”€ views/            # Page components
â”‚       â””â”€â”€ components/       # Reusable components
â”‚
â””â”€â”€ deploy/                   # Deployment files
    â”œâ”€â”€ docker-compose.yml    # Docker Compose configuration
    â”œâ”€â”€ .env.example          # Environment variables for Docker Compose
    â”œâ”€â”€ config.example.yaml   # Full config file for binary deployment
    â””â”€â”€ install.sh            # One-click installation script
```

## License

MIT License

---

&lt;div align=&quot;center&quot;&gt;

**If you find this project useful, please give it a star!**

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cloudwego/eino]]></title>
            <link>https://github.com/cloudwego/eino</link>
            <guid>https://github.com/cloudwego/eino</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:39 GMT</pubDate>
            <description><![CDATA[The ultimate LLM/AI application development framework in Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudwego/eino">cloudwego/eino</a></h1>
            <p>The ultimate LLM/AI application development framework in Go.</p>
            <p>Language: Go</p>
            <p>Stars: 9,760</p>
            <p>Forks: 754</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre># Eino

![coverage](https://raw.githubusercontent.com/cloudwego/eino/badges/.badges/main/coverage.svg)
[![Release](https://img.shields.io/github/v/release/cloudwego/eino)](https://github.com/cloudwego/eino/releases)
[![WebSite](https://img.shields.io/website?up_message=cloudwego&amp;url=https%3A%2F%2Fwww.cloudwego.io%2F)](https://www.cloudwego.io/)
[![License](https://img.shields.io/github/license/cloudwego/eino)](https://github.com/cloudwego/eino/blob/main/LICENSE)
[![Go Report Card](https://goreportcard.com/badge/github.com/cloudwego/eino)](https://goreportcard.com/report/github.com/cloudwego/eino)
[![OpenIssue](https://img.shields.io/github/issues/cloudwego/eino)](https://github.com/cloudwego/kitex/eino)
[![ClosedIssue](https://img.shields.io/github/issues-closed/cloudwego/eino)](https://github.com/cloudwego/eino/issues?q=is%3Aissue+is%3Aclosed)
![Stars](https://img.shields.io/github/stars/cloudwego/eino)
![Forks](https://img.shields.io/github/forks/cloudwego/eino)

English | [ä¸­æ–‡](README.zh_CN.md)

# Overview

**Eino[&#039;aino]** is an LLM application development framework in Golang. It draws from LangChain, Google ADK, and other open-source frameworks, and is designed to follow Golang conventions.

Eino provides:
- **[Components](https://github.com/cloudwego/eino-ext)**: reusable building blocks like `ChatModel`, `Tool`, `Retriever`, and `ChatTemplate`, with official implementations for OpenAI, Ollama, and more.
- **Agent Development Kit (ADK)**: build AI agents with tool use, multi-agent coordination, context management, interrupt/resume for human-in-the-loop, and ready-to-use agent patterns.
- **Composition**: connect components into graphs and workflows that can run standalone or be exposed as tools for agents.
- **[Examples](https://github.com/cloudwego/eino-examples)**: working code for common patterns and real-world use cases.

![](.github/static/img/eino/eino_concept.jpeg)

# Quick Start

## ChatModelAgent

Configure a ChatModel, optionally add tools, and you have a working agent:

```Go
chatModel, _ := openai.NewChatModel(ctx, &amp;openai.ChatModelConfig{
    Model:  &quot;gpt-4o&quot;,
    APIKey: os.Getenv(&quot;OPENAI_API_KEY&quot;),
})

agent, _ := adk.NewChatModelAgent(ctx, &amp;adk.ChatModelAgentConfig{
    Model: chatModel,
})

runner := adk.NewRunner(ctx, adk.RunnerConfig{Agent: agent})
iter := runner.Query(ctx, &quot;Hello, who are you?&quot;)
for {
    event, ok := iter.Next()
    if !ok {
        break
    }
    fmt.Println(event.Message.Content)
}
```

Add tools to give the agent capabilities:

```Go
agent, _ := adk.NewChatModelAgent(ctx, &amp;adk.ChatModelAgentConfig{
    Model: chatModel,
    ToolsConfig: adk.ToolsConfig{
        ToolsNodeConfig: compose.ToolsNodeConfig{
            Tools: []tool.BaseTool{weatherTool, calculatorTool},
        },
    },
})
```

The agent handles the ReAct loop internally â€” it decides when to call tools and when to respond.

â†’ [ChatModelAgent examples](https://github.com/cloudwego/eino-examples/tree/main/adk/intro) Â· [docs](https://www.cloudwego.io/docs/eino/core_modules/eino_adk/agent_implementation/chat_model/)

## DeepAgent

For complex tasks, use DeepAgent. It breaks down problems into steps, delegates to sub-agents, and tracks progress:

```Go
deepAgent, _ := deep.New(ctx, &amp;deep.Config{
    ChatModel: chatModel,
    SubAgents: []adk.Agent{researchAgent, codeAgent},
    ToolsConfig: adk.ToolsConfig{
        ToolsNodeConfig: compose.ToolsNodeConfig{
            Tools: []tool.BaseTool{shellTool, pythonTool, webSearchTool},
        },
    },
})

runner := adk.NewRunner(ctx, adk.RunnerConfig{Agent: deepAgent})
iter := runner.Query(ctx, &quot;Analyze the sales data in report.csv and generate a summary chart&quot;)
```

DeepAgent can be configured to coordinate multiple specialized agents, run shell commands, execute Python code, and search the web.

â†’ [DeepAgent example](https://github.com/cloudwego/eino-examples/tree/main/adk/multiagent/deep) Â· [docs](https://www.cloudwego.io/docs/eino/core_modules/eino_adk/agent_implementation/deepagents/)

## Composition

When you need precise control over execution flow, use `compose` to build graphs and workflows:

```Go
graph := compose.NewGraph[*Input, *Output]()
graph.AddLambdaNode(&quot;validate&quot;, validateFn)
graph.AddChatModelNode(&quot;generate&quot;, chatModel)
graph.AddLambdaNode(&quot;format&quot;, formatFn)

graph.AddEdge(compose.START, &quot;validate&quot;)
graph.AddEdge(&quot;validate&quot;, &quot;generate&quot;)
graph.AddEdge(&quot;generate&quot;, &quot;format&quot;)
graph.AddEdge(&quot;format&quot;, compose.END)

runnable, _ := graph.Compile(ctx)
result, _ := runnable.Invoke(ctx, input)
```

Compositions can be exposed as tools for agents, bridging deterministic workflows with autonomous behavior:

```Go
tool, _ := graphtool.NewInvokableGraphTool(graph, &quot;data_pipeline&quot;, &quot;Process and validate data&quot;)

agent, _ := adk.NewChatModelAgent(ctx, &amp;adk.ChatModelAgentConfig{
    Model: chatModel,
    ToolsConfig: adk.ToolsConfig{
        ToolsNodeConfig: compose.ToolsNodeConfig{
            Tools: []tool.BaseTool{tool},
        },
    },
})
```

This lets you build domain-specific pipelines with exact control, then let agents decide when to use them.

â†’ [GraphTool examples](https://github.com/cloudwego/eino-examples/tree/main/adk/common/tool/graphtool) Â· [compose docs](https://www.cloudwego.io/docs/eino/core_modules/chain_and_graph_orchestration/)

# Key Features

## Component Ecosystem

Eino defines component abstractions (ChatModel, Tool, Retriever, Embedding, etc.) with official implementations for OpenAI, Claude, Gemini, Ark, Ollama, Elasticsearch, and more.

â†’ [eino-ext](https://github.com/cloudwego/eino-ext)

## Stream Processing

Eino automatically handles streaming throughout orchestration: concatenating, boxing, merging, and copying streams as data flows between nodes. Components only implement the streaming paradigms that make sense for them; the framework handles the rest.

â†’ [docs](https://www.cloudwego.io/docs/eino/core_modules/chain_and_graph_orchestration/stream_programming_essentials/)

## Callback Aspects

Inject logging, tracing, and metrics at fixed points (OnStart, OnEnd, OnError, OnStartWithStreamInput, OnEndWithStreamOutput) across components, graphs, and agents.

â†’ [docs](https://www.cloudwego.io/docs/eino/core_modules/chain_and_graph_orchestration/callback_manual/)

## Interrupt/Resume

Any agent or tool can pause execution for human input and resume from checkpoint. The framework handles state persistence and routing.

â†’ [docs](https://www.cloudwego.io/docs/eino/core_modules/eino_adk/agent_hitl/) Â· [examples](https://github.com/cloudwego/eino-examples/tree/main/adk/human-in-the-loop)

# Framework Structure

![](.github/static/img/eino/eino_framework.jpeg)

The Eino framework consists of:

- Eino (this repo): Type definitions, streaming mechanism, component abstractions, orchestration, agent implementations, aspect mechanisms

- [EinoExt](https://github.com/cloudwego/eino-ext): Component implementations, callback handlers, usage examples, evaluators, prompt optimizers

- [Eino Devops](https://github.com/cloudwego/eino-ext/tree/main/devops): Visualized development and debugging

- [EinoExamples](https://github.com/cloudwego/eino-examples): Example applications and best practices

## Documentation

- [Eino User Manual](https://www.cloudwego.io/zh/docs/eino/)
- [Eino: Quick Start](https://www.cloudwego.io/zh/docs/eino/quick_start/)

## Dependencies
- Go 1.18 and above.

## Code Style

This repo uses `golangci-lint`. Check locally with:

```bash
golangci-lint run ./...
```

Rules enforced:
- Exported functions, interfaces, packages, etc. should have GoDoc comments
- Code should be formatted with `gofmt -s`
- Import order should follow `goimports` (std -&gt; third party -&gt; local)

## Security

If you discover a potential security issue, notify Bytedance Security via the [security center](https://security.bytedance.com/src) or [vulnerability reporting email](sec@bytedance.com).

Do **not** create a public GitHub issue.

## Contact
- Membership: [COMMUNITY MEMBERSHIP](https://github.com/cloudwego/community/blob/main/COMMUNITY_MEMBERSHIP.md)
- Issues: [Issues](https://github.com/cloudwego/eino/issues)
- Lark: Scan the QR code below with [Feishu](https://www.feishu.cn/en/) to join the CloudWeGo/eino user group.

&amp;ensp;&amp;ensp;&amp;ensp; &lt;img src=&quot;.github/static/img/eino/lark_group_zh.png&quot; alt=&quot;LarkGroup&quot; width=&quot;200&quot;/&gt;

## License

This project is licensed under the [Apache-2.0 License](LICENSE-APACHE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[trufflesecurity/trufflehog]]></title>
            <link>https://github.com/trufflesecurity/trufflehog</link>
            <guid>https://github.com/trufflesecurity/trufflehog</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:38 GMT</pubDate>
            <description><![CDATA[Find, verify, and analyze leaked credentials]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/trufflesecurity/trufflehog">trufflesecurity/trufflehog</a></h1>
            <p>Find, verify, and analyze leaked credentials</p>
            <p>Language: Go</p>
            <p>Stars: 24,747</p>
            <p>Forks: 2,237</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;GoReleaser Logo&quot; src=&quot;https://storage.googleapis.com/trufflehog-static-sources/pixel_pig.png&quot; height=&quot;140&quot; /&gt;
  &lt;h2 align=&quot;center&quot;&gt;TruffleHog&lt;/h2&gt;
  &lt;p align=&quot;center&quot;&gt;Find leaked credentials.&lt;/p&gt;
&lt;/p&gt;

---

&lt;div align=&quot;center&quot;&gt;

[![Go Report Card](https://goreportcard.com/badge/github.com/trufflesecurity/trufflehog/v3)](https://goreportcard.com/report/github.com/trufflesecurity/trufflehog/v3)
[![License](https://img.shields.io/badge/license-AGPL--3.0-brightgreen)](/LICENSE)
[![Total Detectors](https://img.shields.io/github/directory-file-count/trufflesecurity/truffleHog/pkg/detectors?label=Total%20Detectors&amp;type=dir)](/pkg/detectors)

&lt;/div&gt;

---

# :mag_right: _Now Scanning_

&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;assets/scanning_logos.svg&quot;&gt;

**...and more**

To learn more about TruffleHog and its features and capabilities, visit our [product page](https://trufflesecurity.com/trufflehog?gclid=CjwKCAjwouexBhAuEiwAtW_Zx5IW87JNj97Ci7heFnA5ar6-DuNzT2Y5nIl9DuZ-FOUqx0Qg3vb9nxoClcEQAvD_BwE).

&lt;/div&gt;

# :globe_with_meridians: TruffleHog Enterprise

Are you interested in continuously monitoring **Git, Jira, Slack, Confluence, Microsoft Teams, Sharepoint (and more)** for credentials? We have an enterprise product that can help! Learn more at &lt;https://trufflesecurity.com/trufflehog-enterprise&gt;.

We take the revenue from the enterprise product to fund more awesome open source projects that the whole community can benefit from.

&lt;/div&gt;

# What is TruffleHog ğŸ½

TruffleHog is the most powerful secrets **Discovery, Classification, Validation,** and **Analysis** tool. In this context, secret refers to a credential a machine uses to authenticate itself to another machine. This includes API keys, database passwords, private encryption keys, and more.

## Discovery ğŸ”

TruffleHog can look for secrets in many places including Git, chats, wikis, logs, API testing platforms, object stores, filesystems and more.

## Classification ğŸ“

TruffleHog classifies over 800 secret types, mapping them back to the specific identity they belong to. Is it an AWS secret? Stripe secret? Cloudflare secret? Postgres password? SSL Private key? Sometimes it&#039;s hard to tell looking at it, so TruffleHog classifies everything it finds.

## Validation âœ…

For every secret TruffleHog can classify, it can also log in to confirm if that secret is live or not. This step is critical to know if thereâ€™s an active present danger or not.

## Analysis ğŸ”¬

For the 20 some of the most commonly leaked out credential types, instead of sending one request to check if the secret can log in, TruffleHog can send many requests to learn everything there is to know about the secret. Who created it? What resources can it access? What permissions does it have on those resources?

# :loudspeaker: Join Our Community

Have questions? Feedback? Jump into Slack or Discord and hang out with us.

Join our [Slack Community](https://join.slack.com/t/trufflehog-community/shared_invite/zt-pw2qbi43-Aa86hkiimstfdKH9UCpPzQ)

Join the [Secret Scanning Discord](https://discord.gg/8Hzbrnkr7E)

# :tv: Demo

![GitHub scanning demo](https://storage.googleapis.com/truffle-demos/non-interactive.svg)

```bash
docker run --rm -it -v &quot;$PWD:/pwd&quot; trufflesecurity/trufflehog:latest github --org=trufflesecurity
```

# :floppy_disk: Installation

Several options are available for you:

### MacOS users

```bash
brew install trufflehog
```

### Docker:

&lt;sub&gt;&lt;i&gt;_Ensure Docker engine is running before executing the following commands:_&lt;/i&gt;&lt;/sub&gt;

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Unix

```bash
docker run --rm -it -v &quot;$PWD:/pwd&quot; trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
```

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Windows Command Prompt

```bash
docker run --rm -it -v &quot;%cd:/=\%:/pwd&quot; trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
```

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;Windows PowerShell

```bash
docker run --rm -it -v &quot;${PWD}:/pwd&quot; trufflesecurity/trufflehog github --repo https://github.com/trufflesecurity/test_keys
```

#### &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;M1 and M2 Mac

```bash
docker run --platform linux/arm64 --rm -it -v &quot;$PWD:/pwd&quot; trufflesecurity/trufflehog:latest github --repo https://github.com/trufflesecurity/test_keys
```

### Binary releases

```bash
Download and unpack from https://github.com/trufflesecurity/trufflehog/releases
```

### Compile from source

```bash
git clone https://github.com/trufflesecurity/trufflehog.git
cd trufflehog; go install
```

### Using installation script

```bash
curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin
```

### Using installation script, verify checksum signature (requires cosign to be installed)

```bash
curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -v -b /usr/local/bin
```

### Using installation script to install a specific version

```bash
curl -sSfL https://raw.githubusercontent.com/trufflesecurity/trufflehog/main/scripts/install.sh | sh -s -- -b /usr/local/bin &lt;ReleaseTag like v3.56.0&gt;
```

# :closed_lock_with_key: Verifying the artifacts

Checksums are applied to all artifacts, and the resulting checksum file is signed using cosign.

You need the following tool to verify signature:

- [Cosign](https://docs.sigstore.dev/cosign/system_config/installation/)

Verification steps are as follows:

1. Download the artifact files you want, and the following files from the [releases](https://github.com/trufflesecurity/trufflehog/releases) page.

   - trufflehog\_{version}\_checksums.txt
   - trufflehog\_{version}\_checksums.txt.pem
   - trufflehog\_{version}\_checksums.txt.sig

2. Verify the signature:

   ```shell
   cosign verify-blob &lt;path to trufflehog_{version}_checksums.txt&gt; \
   --certificate &lt;path to trufflehog_{version}_checksums.txt.pem&gt; \
   --signature &lt;path to trufflehog_{version}_checksums.txt.sig&gt; \
   --certificate-identity-regexp &#039;https://github\.com/trufflesecurity/trufflehog/\.github/workflows/.+&#039; \
   --certificate-oidc-issuer &quot;https://token.actions.githubusercontent.com&quot;
   ```

3. Once the signature is confirmed as valid, you can proceed to validate that the SHA256 sums align with the downloaded artifact:

   ```shell
   sha256sum --ignore-missing -c trufflehog_{version}_checksums.txt
   ```

Replace `{version}` with the downloaded files version

Alternatively, if you are using the installation script, pass `-v` option to perform signature verification.
This requires Cosign binary to be installed prior to running the installation script.

# :rocket: Quick Start

## 1: Scan a repo for only verified secrets

Command:

```bash
trufflehog git https://github.com/trufflesecurity/test_keys --results=verified
```

Expected output:

```
ğŸ·ğŸ”‘ğŸ·  TruffleHog. Unearth your secrets. ğŸ·ğŸ”‘ğŸ·

Found verified result ğŸ·ğŸ”‘
Detector Type: AWS
Decoder Type: PLAIN
Raw result: AKIAYVP4CIPPERUVIFXG
Line: 4
Commit: fbc14303ffbf8fb1c2c1914e8dda7d0121633aca
File: keys
Email: counter &lt;counter@counters-MacBook-Air.local&gt;
Repository: https://github.com/trufflesecurity/test_keys
Timestamp: 2022-06-16 10:17:40 -0700 PDT
...
```

## 2: Scan a GitHub Org for only verified secrets

```bash
trufflehog github --org=trufflesecurity --results=verified
```

## 3: Scan a GitHub Repo for only verified secrets and get JSON output

Command:

```bash
trufflehog git https://github.com/trufflesecurity/test_keys --results=verified --json
```

Expected output:

```
{&quot;SourceMetadata&quot;:{&quot;Data&quot;:{&quot;Git&quot;:{&quot;commit&quot;:&quot;fbc14303ffbf8fb1c2c1914e8dda7d0121633aca&quot;,&quot;file&quot;:&quot;keys&quot;,&quot;email&quot;:&quot;counter \u003ccounter@counters-MacBook-Air.local\u003e&quot;,&quot;repository&quot;:&quot;https://github.com/trufflesecurity/test_keys&quot;,&quot;timestamp&quot;:&quot;2022-06-16 10:17:40 -0700 PDT&quot;,&quot;line&quot;:4}}},&quot;SourceID&quot;:0,&quot;SourceType&quot;:16,&quot;SourceName&quot;:&quot;trufflehog - git&quot;,&quot;DetectorType&quot;:2,&quot;DetectorName&quot;:&quot;AWS&quot;,&quot;DecoderName&quot;:&quot;PLAIN&quot;,&quot;Verified&quot;:true,&quot;Raw&quot;:&quot;AKIAYVP4CIPPERUVIFXG&quot;,&quot;Redacted&quot;:&quot;AKIAYVP4CIPPERUVIFXG&quot;,&quot;ExtraData&quot;:{&quot;account&quot;:&quot;595918472158&quot;,&quot;arn&quot;:&quot;arn:aws:iam::595918472158:user/canarytokens.com@@mirux23ppyky6hx3l6vclmhnj&quot;,&quot;user_id&quot;:&quot;AIDAYVP4CIPPJ5M54LRCY&quot;},&quot;StructuredData&quot;:null}
...
```

## 4: Scan a GitHub Repo + its Issues and Pull Requests

```bash
trufflehog github --repo=https://github.com/trufflesecurity/test_keys --issue-comments --pr-comments
```

## 5: Scan an S3 bucket for high-confidence results (verified + unknown)

```bash
trufflehog s3 --bucket=&lt;bucket name&gt; --results=verified,unknown
```

## 6: Scan S3 buckets using IAM Roles

```bash
trufflehog s3 --role-arn=&lt;iam role arn&gt;
```

## 7: Scan a Github Repo using SSH authentication in Docker

```bash
docker run --rm -v &quot;$HOME/.ssh:/root/.ssh:ro&quot; trufflesecurity/trufflehog:latest git ssh://github.com/trufflesecurity/test_keys
```

## 8: Scan individual files or directories

```bash
trufflehog filesystem path/to/file1.txt path/to/file2.txt path/to/dir
```

## 9: Scan a local git repo

Clone the git repo. For example [test keys](git@github.com:trufflesecurity/test_keys.git) repo.
```bash
$ git clone git@github.com:trufflesecurity/test_keys.git
```

Run trufflehog from the parent directory (outside the git repo).
```bash
$ trufflehog git file://test_keys --results=verified,unknown
```

To guard against malicious git configs in local scanning (see CVE-2025-41390), TruffleHog clones local git repositories to a temporary directory prior to scanning. This follows [Git&#039;s security best practices](https://git-scm.com/docs/git#_security). If you want to specify a custom path to clone the repository to (instead of tmp), you can use the `--clone-path` flag. If you&#039;d like to skip the local cloning process and scan the repository directly (only do this for trusted repos), you can use the `--trust-local-git-config` flag.

## 10: Scan GCS buckets for only verified secrets

```bash
trufflehog gcs --project-id=&lt;project-ID&gt; --cloud-environment --results=verified
```

## 11: Scan a Docker image for only verified secrets

Use the `--image` flag multiple times to scan multiple images.

```bash
# to scan from a remote registry
trufflehog docker --image trufflesecurity/secrets --results=verified

# to scan from the local docker daemon
trufflehog docker --image docker://new_image:tag --results=verified

# to scan from an image saved as a tarball
trufflehog docker --image file://path_to_image.tar --results=verified
```

## 12: Scan in CI

Set the `--since-commit` flag to your default branch that people merge into (ex: &quot;main&quot;). Set the `--branch` flag to your PR&#039;s branch name (ex: &quot;feature-1&quot;). Depending on the CI/CD platform you use, this value can be pulled in dynamically (ex: [CIRCLE_BRANCH in Circle CI](https://circleci.com/docs/variables/) and [TRAVIS_PULL_REQUEST_BRANCH in Travis CI](https://docs.travis-ci.com/user/environment-variables/)). If the repo is cloned and the target branch is already checked out during the CI/CD workflow, then `--branch HEAD` should be sufficient. The `--fail` flag will return an 183 error code if valid credentials are found.

```bash
trufflehog git file://. --since-commit main --branch feature-1 --results=verified,unknown --fail
```

## 13: Scan a Postman workspace

Use the `--workspace-id`, `--collection-id`, `--environment` flags multiple times to scan multiple targets.

```bash
trufflehog postman --token=&lt;postman api token&gt; --workspace-id=&lt;workspace id&gt;
```

## 14: Scan a Jenkins server

```bash
trufflehog jenkins --url https://jenkins.example.com --username admin --password admin
```

## 15: Scan an Elasticsearch server

### Scan a Local Cluster

There are two ways to authenticate to a local cluster with TruffleHog: (1) username and password, (2) service token.

#### Connect to a local cluster with username and password

```bash
trufflehog elasticsearch --nodes 192.168.14.3 192.168.14.4 --username truffle --password hog
```

#### Connect to a local cluster with a service token

```bash
trufflehog elasticsearch --nodes 192.168.14.3 192.168.14.4 --service-token â€˜AAEWVaWM...Rva2VuaSDZâ€™
```

### Scan an Elastic Cloud Cluster

To scan a cluster on Elastic Cloud, youâ€™ll need a Cloud ID and API key.

```bash
trufflehog elasticsearch \
  --cloud-id &#039;search-prod:dXMtY2Vx...YjM1ODNlOWFiZGRlNjI0NA==&#039; \
  --api-key &#039;MlVtVjBZ...ZSYlduYnF1djh3NG5FQQ==&#039;
```

## 16. Scan a GitHub Repository for Cross Fork Object References and Deleted Commits

The following command will enumerate deleted and hidden commits on a GitHub repository and then scan them for secrets. This is an alpha release feature.

```bash
trufflehog github-experimental --repo https://github.com/&lt;USER&gt;/&lt;REPO&gt;.git --object-discovery
```

In addition to the normal TruffleHog output, the `--object-discovery` flag creates two files in a new `$HOME/.trufflehog` directory: `valid_hidden.txt` and `invalid.txt`. These are used to track state during commit enumeration, as well as to provide users with a complete list of all hidden and deleted commits (`valid_hidden.txt`). If you&#039;d like to automatically remove these files after scanning, please add the flag `--delete-cached-data`.

**Note**: Enumerating all valid commits on a repository using this method takes between 20 minutes and a few hours, depending on the size of your repository. We added a progress bar to keep you updated on how long the enumeration will take. The actual secret scanning runs extremely fast.

For more information on Cross Fork Object References, please [read our blog post](https://trufflesecurity.com/blog/anyone-can-access-deleted-and-private-repo-data-github).

## 17. Scan Hugging Face

### Scan a Hugging Face Model, Dataset or Space

```bash
trufflehog huggingface --model &lt;model_id&gt; --space &lt;space_id&gt; --dataset &lt;dataset_id&gt;
```

### Scan all Models, Datasets and Spaces belonging to a Hugging Face Organization or User

```bash
trufflehog huggingface --org &lt;orgname&gt; --user &lt;username&gt;
```

(Optionally) When scanning an organization or user, you can skip an entire class of resources with `--skip-models`, `--skip-datasets`, `--skip-spaces` OR a particular resource with `--ignore-models &lt;model_id&gt;`, `--ignore-datasets &lt;dataset_id&gt;`, `--ignore-spaces &lt;space_id&gt;`.

### Scan Discussion and PR Comments

```bash
trufflehog huggingface --model &lt;model_id&gt; --include-discussions --include-prs
```

## 18. Scan stdin Input

```bash
aws s3 cp s3://example/gzipped/data.gz - | gunzip -c | trufflehog stdin
```

# :question: FAQ

- All I see is `ğŸ·ğŸ”‘ğŸ·  TruffleHog. Unearth your secrets. ğŸ·ğŸ”‘ğŸ·` and the program exits, what gives?
  - That means no secrets were detected
- Why is the scan taking a long time when I scan a GitHub org
  - Unauthenticated GitHub scans have rate limits. To improve your rate limits, include the `--token` flag with a personal access token
- It says a private key was verified, what does that mean?
  - A verified result means TruffleHog confirmed the credential is valid by testing it against the service&#039;s API. For private keys, we&#039;ve confirmed the key can be used live for SSH or SSL authentication. Check out our Driftwood blog post to learn more [Blog post](https://trufflesecurity.com/blog/driftwood-know-if-private-keys-are-sensitive/)
- Is there an easy way to ignore specific secrets?
  - If the scanned source [supports line numbers](https://github.com/trufflesecurity/trufflehog/blob/d6375ba92172fd830abb4247cca15e3176448c5d/pkg/engine/engine.go#L358-L365), then you can add a `trufflehog:ignore` comment on the line containing the secret to ignore that secrets.

# :newspaper: What&#039;s new in v3?

TruffleHog v3 is a complete rewrite in Go with many new powerful features.

- We&#039;ve **added over 700 credential detectors that support active verification against their respective APIs**.
- We&#039;ve also added native **support for scanning GitHub, GitLab, Docker, filesystems, S3, GCS, Circle CI and Travis CI**.
- **Instantly verify private keys** against millions of github users and **billions** of TLS certificates using our [Driftwood](https://trufflesecurity.com/blog/driftwood) technology.
- Scan binaries, documents, and other file formats
- Available as a GitHub Action and a pre-commit hook

## What is credential verification?

For every potential credential that is detected, we&#039;ve painstakingly implemented programmatic verification against the API that we think it belongs to. Verification eliminates false positives and provides three result statuses:

- **verified**: Credential confirmed as valid and active by API testing
- **unverified**: Credential detected but not confirmed valid (may be invalid, expired, or verification disabled)  
- **unknown**: Verification attempted but failed due to errors, such as a network or API failure

For example, the [AWS credential detector](pkg/detectors/aws/aws.go) performs a `GetCallerIdentity` API call against the AWS API to verify if an AWS credential is active.

# :memo: Usage

TruffleHog has a sub-command for each source of data that you may want to scan:

- git
- github
- gitlab
- docker
- s3
- filesystem (files and directories)
- syslog
- circleci
- travisci
- gcs (Google Cloud Storage)
- postman
- jenkins
- elasticsearch
- stdin
- multi-scan

Each subcommand can have options that you can see with the `--help` flag provided to the sub command:

```
$ trufflehog git --help
usage: TruffleHog git [&lt;flags&gt;] &lt;uri&gt;

Find credentials in git repositories.

Flags:
  -h, --help                Show context-sensitive help (also try --help-long and --help-man).
      --log-level=0         Logging verbosity on a scale of 0 (info) to 5 (trace). Can be disabled with &quot;-1&quot;.
      --profile             Enables profiling and sets a pprof and fgprof server on :18066.
  -j, --json                Output in JSON format.
      --json-legacy         Use the pre-v3.0 JSON format. Only works with git, gitlab, and github sources.
      --github-actions      Output in GitHub Actions format.
      --concurrency=20           Number of concurrent workers.
      --no-verification     Don&#039;t verify the results.
      --results=RESULTS          Specifies which type(s) of results to output: verified (confirmed valid by API), unknown (verification failed due to error), unverified (detected but not verified), filtered_unverified (unverified but would have been filtered out). Defaults to all types.
      --allow-verification-overlap
                                 Allow verification of similar credentials across detectors
      --filter-unverified   Only output first unverified result per chunk per detector if there are more than one results.
      --filter-entropy=FILTER-ENTROPY
                                 Filter unverified results with Shannon entropy. Start with 3.0.
      --config=CONFIG            Path to configuration file.
      --print-avg-detector-time
                                 Print the average time spent on each detector.
      --no-update           Don&#039;t check for updates.
      --fail                Exit with code 183 if results are found.
      --verifier=VERIFIER ...    Set custom verification endpoints.
      --custom-verifiers-only   Only use custom verification endpoints.
      --archive-max-size=ARCHIVE-MAX-SIZE
                                 Maximum size of archive to scan. (Byte units eg. 512B, 2KB, 4MB)
      --archive-max-depth=ARCHIVE-MAX-DEPTH
                                 Maximum depth of archive to scan.
      --archive-timeout=ARCHIVE-TIMEOUT
                                 Maximum time to spend extracting an archive.
      --include-detectors=&quot;all&quot;  Comma separated list of detector types to include. Protobuf name or IDs may be used, as well as ranges.
      --exclude-detectors=EXCLUDE-DETECTORS
                                 Comma separated list of detector types to exclude. Protobuf name or IDs may be used, as well as ranges. IDs defined here take precedence over the include list.
      --version             Show application version.
  -i, --include-paths=INCLUDE-PATHS
                                 Path to fil

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kubernetes-sigs/kustomize]]></title>
            <link>https://github.com/kubernetes-sigs/kustomize</link>
            <guid>https://github.com/kubernetes-sigs/kustomize</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:37 GMT</pubDate>
            <description><![CDATA[Customization of kubernetes YAML configurations]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kubernetes-sigs/kustomize">kubernetes-sigs/kustomize</a></h1>
            <p>Customization of kubernetes YAML configurations</p>
            <p>Language: Go</p>
            <p>Stars: 11,956</p>
            <p>Forks: 2,366</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># kustomize

`kustomize` lets you customize raw, template-free YAML
files for multiple purposes, leaving the original YAML
untouched and usable as is.

`kustomize` targets kubernetes; it understands and can
patch [kubernetes style] API objects.  It&#039;s like
[`make`], in that what it does is declared in a file,
and it&#039;s like [`sed`], in that it emits edited text.

This tool is sponsored by [sig-cli] ([KEP]).

 - [Installation instructions](https://kubectl.docs.kubernetes.io/installation/kustomize/)
 - [General documentation](https://kubectl.docs.kubernetes.io/references/kustomize/)
 - [Examples](examples)

[![Build Status](https://prow.k8s.io/badge.svg?jobs=kustomize-presubmit-master)](https://prow.k8s.io/job-history/kubernetes-jenkins/pr-logs/directory/kustomize-presubmit-master)
[![Go Report Card](https://goreportcard.com/badge/github.com/kubernetes-sigs/kustomize)](https://goreportcard.com/report/github.com/kubernetes-sigs/kustomize)

## kubectl integration

To find the kustomize version embedded in recent versions of kubectl, run `kubectl version`:

```sh
&gt; kubectl version --client
Client Version: v1.31.0
Kustomize Version: v5.4.2
```

The kustomize build flow at [v2.0.3] was added
to [kubectl v1.14][kubectl announcement].  The kustomize
flow in kubectl remained frozen at v2.0.3 until kubectl v1.21,
which [updated it to v4.0.5][kust-in-kubectl update]. It will
be updated on a regular basis going forward, and such updates
will be reflected in the Kubernetes release notes.

| Kubectl version | Kustomize version |
| --------------- | ----------------- |
| &lt; v1.14         | n/a               |
| v1.14-v1.20     | v2.0.3            |
| v1.21           | v4.0.5            |
| v1.22           | v4.2.0            |
| v1.23           | v4.4.1            |
| v1.24           | v4.5.4            |
| v1.25           | v4.5.7            |
| v1.26           | v4.5.7            |
| v1.27           | v5.0.1            |

[v2.0.3]: https://github.com/kubernetes-sigs/kustomize/releases/tag/v2.0.3
[#2506]: https://github.com/kubernetes-sigs/kustomize/issues/2506
[#1500]: https://github.com/kubernetes-sigs/kustomize/issues/1500
[kust-in-kubectl update]: https://github.com/kubernetes/kubernetes/blob/4d75a6238a6e330337526e0513e67d02b1940b63/CHANGELOG/CHANGELOG-1.21.md#kustomize-updates-in-kubectl

For examples and guides for using the kubectl integration please
see the [kubernetes documentation].

## Usage


### 1) Make a [kustomization] file

In some directory containing your YAML [resource]
files (deployments, services, configmaps, etc.), create a
[kustomization] file.

This file should declare those resources, and any
customization to apply to them, e.g. _add a common
label_.

```

base: kustomization + resources

kustomization.yaml                                      deployment.yaml                                                 service.yaml
+---------------------------------------------+         +-------------------------------------------------------+       +-----------------------------------+
| apiVersion: kustomize.config.k8s.io/v1beta1 |         | apiVersion: apps/v1                                   |       | apiVersion: v1                    |
| kind: Kustomization                         |         | kind: Deployment                                      |       | kind: Service                     |
| labels:                                     |         | metadata:                                             |       | metadata:                         |
| - includeSelectors: true                    |         |   name: myapp                                         |       |   name: myapp                     |
|   pairs:                                    |         | spec:                                                 |       | spec:                             |
|     app: myapp                              |         |   selector:                                           |       |   selector:                       |
| resources:                                  |         |     matchLabels:                                      |       |     app: myapp                    |
|   - deployment.yaml                         |         |       app: myapp                                      |       |   ports:                          |
|   - service.yaml                            |         |   template:                                           |       |     - port: 6060                  |
| configMapGenerator:                         |         |     metadata:                                         |       |       targetPort: 6060            |
|   - name: myapp-map                         |         |       labels:                                         |       +-----------------------------------+
|     literals:                               |         |         app: myapp                                    |
|       - KEY=value                           |         |     spec:                                             |
+---------------------------------------------+         |       containers:                                     |
                                                        |         - name: myapp                                 |
                                                        |           image: myapp                                |
                                                        |           resources:                                  |
                                                        |             limits:                                   |
                                                        |               memory: &quot;128Mi&quot;                         |
                                                        |               cpu: &quot;500m&quot;                             |
                                                        |           ports:                                      |
                                                        |             - containerPort: 6060                     |
                                                        +-------------------------------------------------------+

```

File structure:

&gt; ```
&gt; ~/someApp
&gt; â”œâ”€â”€ deployment.yaml
&gt; â”œâ”€â”€ kustomization.yaml
&gt; â””â”€â”€ service.yaml
&gt; ```

The resources in this directory could be a fork of
someone else&#039;s configuration.  If so, you can easily
rebase from the source material to capture
improvements, because you don&#039;t modify the resources
directly.

Generate customized YAML with:

```
kustomize build ~/someApp
```

The YAML can be directly [applied] to a cluster:

&gt; ```
&gt; kustomize build ~/someApp | kubectl apply -f -
&gt; ```


### 2) Create [variants] using [overlays]

Manage traditional [variants] of a configuration - like
_development_, _staging_ and _production_ - using
[overlays] that modify a common [base].

```

overlay: kustomization + patches

kustomization.yaml                                      replica_count.yaml                      cpu_count.yaml
+-----------------------------------------------+       +-------------------------------+       +------------------------------------------+
| apiVersion: kustomize.config.k8s.io/v1beta1   |       | apiVersion: apps/v1           |       | apiVersion: apps/v1                      |
| kind: Kustomization                           |       | kind: Deployment              |       | kind: Deployment                         |
| labels:                                       |       | metadata:                     |       | metadata:                                |
|  - includeSelectors: true                     |       |   name: myapp                 |       |   name: myapp                            |
|    pairs:                                     |       | spec:                         |       | spec:                                    |
|      variant: prod                            |       |   replicas: 80                |       |  template:                               |
| resources:                                    |       +-------------------------------+       |     spec:                                |
|   - ../../base                                |                                               |       containers:                        |
| patches:                                      |                                               |         - name: myapp                    |
|   - path: replica_count.yaml                  |                                               |           resources:                     |
|   - path: cpu_count.yaml                      |                                               |             limits:                      |
+-----------------------------------------------+                                               |               memory: &quot;128Mi&quot;            |
                                                                                                |               cpu: &quot;7000m&quot;               |
                                                                                                +------------------------------------------+
```


File structure:
&gt; ```
&gt; ~/someApp
&gt; â”œâ”€â”€ base
&gt; â”‚   â”œâ”€â”€ deployment.yaml
&gt; â”‚   â”œâ”€â”€ kustomization.yaml
&gt; â”‚   â””â”€â”€ service.yaml
&gt; â””â”€â”€ overlays
&gt;     â”œâ”€â”€ development
&gt;     â”‚   â”œâ”€â”€ cpu_count.yaml
&gt;     â”‚   â”œâ”€â”€ kustomization.yaml
&gt;     â”‚   â””â”€â”€ replica_count.yaml
&gt;     â””â”€â”€ production
&gt;         â”œâ”€â”€ cpu_count.yaml
&gt;         â”œâ”€â”€ kustomization.yaml
&gt;         â””â”€â”€ replica_count.yaml
&gt; ```

Take the work from step (1) above, move it into a
`someApp` subdirectory called `base`, then
place overlays in a sibling directory.

An overlay is just another kustomization, referring to
the base, and referring to patches to apply to that
base.

This arrangement makes it easy to manage your
configuration with `git`.  The base could have files
from an upstream repository managed by someone else.
The overlays could be in a repository you own.
Arranging the repo clones as siblings on disk avoids
the need for git submodules (though that works fine, if
you are a submodule fan).

Generate YAML with

```sh
kustomize build ~/someApp/overlays/production
```

The YAML can be directly [applied] to a cluster:

&gt; ```sh
&gt; kustomize build ~/someApp/overlays/production | kubectl apply -f -
&gt; ```

## Community

- [file a bug](https://kubectl.docs.kubernetes.io/contributing/kustomize/bugs/)
- [contribute a feature](https://kubectl.docs.kubernetes.io/contributing/kustomize/features/)
- [propose a larger enhancement](https://github.com/kubernetes-sigs/kustomize/tree/master/proposals)

### Code of conduct

Participation in the Kubernetes community
is governed by the [Kubernetes Code of Conduct].

[`make`]: https://www.gnu.org/software/make
[`sed`]: https://www.gnu.org/software/sed
[DAM]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#declarative-application-management
[KEP]: https://github.com/kubernetes/enhancements/blob/master/keps/sig-cli/2377-Kustomize/README.md
[Kubernetes Code of Conduct]: code-of-conduct.md
[applied]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#apply
[base]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#base
[declarative configuration]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#declarative-application-management
[kubectl announcement]: https://kubernetes.io/blog/2019/03/25/kubernetes-1-14-release-announcement
[kubernetes documentation]: https://kubernetes.io/docs/tasks/manage-kubernetes-objects/kustomization/
[kubernetes style]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#kubernetes-style-object
[kustomization]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#kustomization
[overlay]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#overlay
[overlays]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#overlay
[release page]: https://github.com/kubernetes-sigs/kustomize/releases
[resource]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#resource
[resources]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#resource
[sig-cli]: https://github.com/kubernetes/community/blob/master/sig-cli/README.md
[variants]: https://kubectl.docs.kubernetes.io/references/kustomize/glossary/#variant
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[containers/skopeo]]></title>
            <link>https://github.com/containers/skopeo</link>
            <guid>https://github.com/containers/skopeo</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:36 GMT</pubDate>
            <description><![CDATA[Work with remote images registries - retrieving information, images, signing content]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/containers/skopeo">containers/skopeo</a></h1>
            <p>Work with remote images registries - retrieving information, images, signing content</p>
            <p>Language: Go</p>
            <p>Stars: 10,502</p>
            <p>Forks: 907</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
   &lt;img src=&quot;https://cdn.rawgit.com/containers/skopeo/main/docs/skopeo.svg&quot; width=&quot;250&quot; alt=&quot;Skopeo&quot;&gt;
&lt;/p&gt;

----
![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/containers/skopeo)
[![Go Report Card](https://goreportcard.com/badge/github.com/containers/skopeo)](https://goreportcard.com/report/github.com/containers/skopeo)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10516/badge)](https://www.bestpractices.dev/projects/10516)

`skopeo` is a command line utility that performs various operations on container images and image repositories.

`skopeo` does not require the user to be running as root to do most of its operations.

`skopeo` does not require a daemon to be running to perform its operations.

`skopeo` can work with [OCI images](https://github.com/opencontainers/image-spec) as well as the original Docker v2 images.

Skopeo works with API V2 container image registries such as [docker.io](https://docker.io) and [quay.io](https://quay.io) registries, private registries, local directories and local OCI-layout directories. Skopeo can perform operations which consist of:

 * Copying an image from and to various storage mechanisms.
   For example you can copy images from one registry to another, without requiring privilege.
 * Inspecting a remote image showing its properties including its layers, without requiring you to pull the image to the host.
 * Deleting an image from an image repository.
 * Syncing an external image repository to an internal registry for air-gapped deployments.
 * When required by the repository, skopeo can pass the appropriate credentials and certificates for authentication.

 Skopeo operates on the following image and repository types:

 * containers-storage:docker-reference
         An image located in a local containers/storage image store.  Both the location and image store are specified in /etc/containers/storage.conf. (This is  the backend for [Podman](https://podman.io), [CRI-O](https://cri-o.io), [Buildah](https://buildah.io) and friends)

 * dir:path
         An existing local directory path storing the manifest, layer tarballs and signatures as individual files. This is a non-standardized format, primarily useful for debugging or noninvasive container inspection.

 * docker://docker-reference
         An image in a registry implementing the &quot;Docker Registry HTTP API V2&quot;. By default, uses the authorization state in `$XDG_RUNTIME_DIR/containers/auth.json`, which is set using `skopeo login`.

 * docker-archive:path[:docker-reference]
         An image is stored in a `docker save`-formatted file.  docker-reference is only used when creating such a file, and it must not contain a digest.

 * docker-daemon:docker-reference
         An image docker-reference stored in the docker daemon internal storage.  docker-reference must contain either a tag or a digest.  Alternatively, when reading images, the format can also be docker-daemon:algo:digest (an image ID).

 * oci:path:tag
         An image tag in a directory compliant with &quot;Open Container Image Layout Specification&quot; at path.

[Obtaining skopeo](./install.md)
-

For a detailed description how to install or build skopeo, see
[install.md](./install.md).

Skopeo is also available as a Container Image on [quay.io](https://quay.io/skopeo/stable).  For more information, see the [Skopeo Image](https://github.com/containers/image_build/blob/main/skopeo/README.md) page.

## Inspecting a repository
`skopeo` is able to _inspect_ a repository on a container registry and fetch images layers.
The _inspect_ command fetches the repository&#039;s manifest and it is able to show you a `docker inspect`-like
json output about a whole repository or a tag. This tool, in contrast to `docker inspect`, helps you gather useful information about
a repository or a tag before pulling it (using disk space).  The inspect command can show you which tags are available for the given 
repository, the labels the image has, the creation date and operating system of the image and more.  

Examples:

#### Show properties of fedora:latest
```console
$ skopeo inspect docker://registry.fedoraproject.org/fedora:latest
{
    &quot;Name&quot;: &quot;registry.fedoraproject.org/fedora&quot;,
    &quot;Digest&quot;: &quot;sha256:0f65bee641e821f8118acafb44c2f8fe30c2fc6b9a2b3729c0660376391aa117&quot;,
    &quot;RepoTags&quot;: [
        &quot;34-aarch64&quot;,
        &quot;34&quot;,
        &quot;latest&quot;,
        ...
    ],
    &quot;Created&quot;: &quot;2022-11-24T13:54:18Z&quot;,
    &quot;DockerVersion&quot;: &quot;1.10.1&quot;,
    &quot;Labels&quot;: {
        &quot;license&quot;: &quot;MIT&quot;,
        &quot;name&quot;: &quot;fedora&quot;,
        &quot;vendor&quot;: &quot;Fedora Project&quot;,
        &quot;version&quot;: &quot;37&quot;
    },
    &quot;Architecture&quot;: &quot;amd64&quot;,
    &quot;Os&quot;: &quot;linux&quot;,
    &quot;Layers&quot;: [
        &quot;sha256:2a0fc6bf62e155737f0ace6142ee686f3c471c1aab4241dc3128904db46288f0&quot;
    ],
    &quot;LayersData&quot;: [
        {
            &quot;MIMEType&quot;: &quot;application/vnd.docker.image.rootfs.diff.tar.gzip&quot;,
            &quot;Digest&quot;: &quot;sha256:2a0fc6bf62e155737f0ace6142ee686f3c471c1aab4241dc3128904db46288f0&quot;,
            &quot;Size&quot;: 71355009,
            &quot;Annotations&quot;: null
        }
    ],
    &quot;Env&quot;: [
        &quot;DISTTAG=f37container&quot;,
        &quot;FGC=f37&quot;,
        &quot;container=oci&quot;
    ]
}
```

#### Show container configuration from `fedora:latest`

```console
$ skopeo inspect --config docker://registry.fedoraproject.org/fedora:latest  | jq
{
  &quot;created&quot;: &quot;2020-04-29T06:48:16Z&quot;,
  &quot;architecture&quot;: &quot;amd64&quot;,
  &quot;os&quot;: &quot;linux&quot;,
  &quot;config&quot;: {
    &quot;Env&quot;: [
      &quot;DISTTAG=f32container&quot;,
      &quot;FGC=f32&quot;,
      &quot;container=oci&quot;
    ],
    &quot;Cmd&quot;: [
      &quot;/bin/bash&quot;
    ],
    &quot;Labels&quot;: {
      &quot;license&quot;: &quot;MIT&quot;,
      &quot;name&quot;: &quot;fedora&quot;,
      &quot;vendor&quot;: &quot;Fedora Project&quot;,
      &quot;version&quot;: &quot;32&quot;
    }
  },
  &quot;rootfs&quot;: {
    &quot;type&quot;: &quot;layers&quot;,
    &quot;diff_ids&quot;: [
      &quot;sha256:a4c0fa2b217d3fd63d51e55a6fd59432e543d499c0df2b1acd48fbe424f2ddd1&quot;
    ]
  },
  &quot;history&quot;: [
    {
      &quot;created&quot;: &quot;2020-04-29T06:48:16Z&quot;,
      &quot;comment&quot;: &quot;Created by Image Factory&quot;
    }
  ]
}
```
#### Show unverified image&#039;s digest
```console
$ skopeo inspect docker://registry.fedoraproject.org/fedora:latest | jq &#039;.Digest&#039;
&quot;sha256:655721ff613ee766a4126cb5e0d5ae81598e1b0c3bcf7017c36c4d72cb092fe9&quot;
```

## Copying images

`skopeo` can copy container images between various storage mechanisms, including:
* Container registries

  -  The Quay, Docker Hub, OpenShift, GCR, Artifactory ...

* Container Storage backends

  -  [github.com/containers/storage](https://github.com/containers/storage) (Backend for [Podman](https://podman.io), [CRI-O](https://cri-o.io), [Buildah](https://buildah.io) and friends)

  -  Docker daemon storage

* Local directories

* Local OCI-layout directories

```console
$ skopeo copy docker://quay.io/buildah/stable docker://registry.internal.company.com/buildah
$ skopeo copy oci:busybox_ocilayout:latest dir:existingemptydirectory
```

## Deleting images
```console
$ skopeo delete docker://localhost:5000/imagename:latest
```

## Syncing registries
```console
$ skopeo sync --src docker --dest dir registry.example.com/busybox /media/usb
```

## Authenticating to a registry

#### Private registries with authentication
skopeo uses credentials from the --creds (for skopeo inspect|delete) or --src-creds|--dest-creds (for skopeo copy) flags, if set; otherwise it uses configuration set by skopeo login, podman login, buildah login, or docker login.

```console
$ skopeo login --username USER myregistrydomain.com:5000
Password:
$ skopeo inspect docker://myregistrydomain.com:5000/busybox
{&quot;Tag&quot;:&quot;latest&quot;,&quot;Digest&quot;:&quot;sha256:473bb2189d7b913ed7187a33d11e743fdc2f88931122a44d91a301b64419f092&quot;,&quot;RepoTags&quot;:[&quot;latest&quot;],&quot;Comment&quot;:&quot;&quot;,&quot;Created&quot;:&quot;2016-01-15T18:06:41.282540103Z&quot;,&quot;ContainerConfig&quot;:{&quot;Hostname&quot;:&quot;aded96b43f48&quot;,&quot;Domainname&quot;:&quot;&quot;,&quot;User&quot;:&quot;&quot;,&quot;AttachStdin&quot;:false,&quot;AttachStdout&quot;:false,&quot;AttachStderr&quot;:false,&quot;Tty&quot;:false,&quot;OpenStdin&quot;:false,&quot;StdinOnce&quot;:false,&quot;Env&quot;:null,&quot;Cmd&quot;:[&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;#(nop) CMD [\&quot;sh\&quot;]&quot;],&quot;Image&quot;:&quot;9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33&quot;,&quot;Volumes&quot;:null,&quot;WorkingDir&quot;:&quot;&quot;,&quot;Entrypoint&quot;:null,&quot;OnBuild&quot;:null,&quot;Labels&quot;:null},&quot;DockerVersion&quot;:&quot;1.8.3&quot;,&quot;Author&quot;:&quot;&quot;,&quot;Config&quot;:{&quot;Hostname&quot;:&quot;aded96b43f48&quot;,&quot;Domainname&quot;:&quot;&quot;,&quot;User&quot;:&quot;&quot;,&quot;AttachStdin&quot;:false,&quot;AttachStdout&quot;:false,&quot;AttachStderr&quot;:false,&quot;Tty&quot;:false,&quot;OpenStdin&quot;:false,&quot;StdinOnce&quot;:false,&quot;Env&quot;:null,&quot;Cmd&quot;:[&quot;sh&quot;],&quot;Image&quot;:&quot;9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33&quot;,&quot;Volumes&quot;:null,&quot;WorkingDir&quot;:&quot;&quot;,&quot;Entrypoint&quot;:null,&quot;OnBuild&quot;:null,&quot;Labels&quot;:null},&quot;Architecture&quot;:&quot;amd64&quot;,&quot;Os&quot;:&quot;linux&quot;}
$ skopeo logout myregistrydomain.com:5000
```

#### Using --creds directly

```console
$ skopeo inspect --creds=testuser:testpassword docker://myregistrydomain.com:5000/busybox
{&quot;Tag&quot;:&quot;latest&quot;,&quot;Digest&quot;:&quot;sha256:473bb2189d7b913ed7187a33d11e743fdc2f88931122a44d91a301b64419f092&quot;,&quot;RepoTags&quot;:[&quot;latest&quot;],&quot;Comment&quot;:&quot;&quot;,&quot;Created&quot;:&quot;2016-01-15T18:06:41.282540103Z&quot;,&quot;ContainerConfig&quot;:{&quot;Hostname&quot;:&quot;aded96b43f48&quot;,&quot;Domainname&quot;:&quot;&quot;,&quot;User&quot;:&quot;&quot;,&quot;AttachStdin&quot;:false,&quot;AttachStdout&quot;:false,&quot;AttachStderr&quot;:false,&quot;Tty&quot;:false,&quot;OpenStdin&quot;:false,&quot;StdinOnce&quot;:false,&quot;Env&quot;:null,&quot;Cmd&quot;:[&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;#(nop) CMD [\&quot;sh\&quot;]&quot;],&quot;Image&quot;:&quot;9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33&quot;,&quot;Volumes&quot;:null,&quot;WorkingDir&quot;:&quot;&quot;,&quot;Entrypoint&quot;:null,&quot;OnBuild&quot;:null,&quot;Labels&quot;:null},&quot;DockerVersion&quot;:&quot;1.8.3&quot;,&quot;Author&quot;:&quot;&quot;,&quot;Config&quot;:{&quot;Hostname&quot;:&quot;aded96b43f48&quot;,&quot;Domainname&quot;:&quot;&quot;,&quot;User&quot;:&quot;&quot;,&quot;AttachStdin&quot;:false,&quot;AttachStdout&quot;:false,&quot;AttachStderr&quot;:false,&quot;Tty&quot;:false,&quot;OpenStdin&quot;:false,&quot;StdinOnce&quot;:false,&quot;Env&quot;:null,&quot;Cmd&quot;:[&quot;sh&quot;],&quot;Image&quot;:&quot;9e77fef7a1c9f989988c06620dabc4020c607885b959a2cbd7c2283c91da3e33&quot;,&quot;Volumes&quot;:null,&quot;WorkingDir&quot;:&quot;&quot;,&quot;Entrypoint&quot;:null,&quot;OnBuild&quot;:null,&quot;Labels&quot;:null},&quot;Architecture&quot;:&quot;amd64&quot;,&quot;Os&quot;:&quot;linux&quot;}
```

```console
$ skopeo copy --src-creds=testuser:testpassword docker://myregistrydomain.com:5000/private oci:local_oci_image
```

Contributing
-

Please read the [contribution guide](CONTRIBUTING.md) if you want to collaborate in the project.

## Commands
| Command                                            | Description                                                                                  |
| -------------------------------------------------- | ---------------------------------------------------------------------------------------------|
| [skopeo-copy(1)](/docs/skopeo-copy.1.md)           | Copy an image (manifest, filesystem layers, signatures) from one location to another.        |
| [skopeo-delete(1)](/docs/skopeo-delete.1.md)       | Mark the image-name for later deletion by the registry&#039;s garbage collector.                                                                |
| [skopeo-generate-sigstore-key(1)](/docs/skopeo-generate-sigstore-key.1.md)    | Generate a sigstore public/private key pair.  |
| [skopeo-inspect(1)](/docs/skopeo-inspect.1.md)     | Return  low-level  information about image-name in a registry.                                |
| [skopeo-list-tags(1)](/docs/skopeo-list-tags.1.md) | Return a list of tags for the transport-specific image repository.                               |
| [skopeo-login(1)](/docs/skopeo-login.1.md)         | Login to a container registry.                                                               |
| [skopeo-logout(1)](/docs/skopeo-logout.1.md)       | Logout of a container registry.                                                              |
| [skopeo-manifest-digest(1)](/docs/skopeo-manifest-digest.1.md)    | Compute a manifest digest for a manifest-file and write it to standard output.   |
| [skopeo-standalone-sign(1)](/docs/skopeo-standalone-sign.1.md)    | Debugging tool - Sign an image locally without uploading.                     |
| [skopeo-standalone-verify(1)](/docs/skopeo-standalone-verify.1.md)| Debugging tool - Verify an image signature from local files.                  |
| [skopeo-sync(1)](/docs/skopeo-sync.1.md)           | Synchronize images between registry repositories and local directories.                      |

License
-
skopeo is licensed under the Apache License, Version 2.0. See
[LICENSE](LICENSE) for the full license text.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mark3labs/mcp-go]]></title>
            <link>https://github.com/mark3labs/mcp-go</link>
            <guid>https://github.com/mark3labs/mcp-go</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:35 GMT</pubDate>
            <description><![CDATA[A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mark3labs/mcp-go">mark3labs/mcp-go</a></h1>
            <p>A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.</p>
            <p>Language: Go</p>
            <p>Stars: 8,240</p>
            <p>Forks: 773</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;!-- omit in toc --&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;./logo.png&quot; alt=&quot;MCP Go Logo&quot;&gt;

[![Build](https://github.com/mark3labs/mcp-go/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/mark3labs/mcp-go/actions/workflows/ci.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/mark3labs/mcp-go?cache)](https://goreportcard.com/report/github.com/mark3labs/mcp-go)
[![GoDoc](https://pkg.go.dev/badge/github.com/mark3labs/mcp-go.svg)](https://pkg.go.dev/github.com/mark3labs/mcp-go)

&lt;strong&gt;A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.&lt;/strong&gt;

&lt;br&gt;

[![Tutorial](http://img.youtube.com/vi/qoaeYMrXJH0/0.jpg)](http://www.youtube.com/watch?v=qoaeYMrXJH0 &quot;Tutorial&quot;)

&lt;br&gt;

Discuss the SDK on [Discord](https://discord.gg/RqSS2NQVsY)

&lt;/div&gt;


```go
package main

import (
    &quot;context&quot;
    &quot;fmt&quot;

    &quot;github.com/mark3labs/mcp-go/mcp&quot;
    &quot;github.com/mark3labs/mcp-go/server&quot;
)

func main() {
    // Create a new MCP server
    s := server.NewMCPServer(
        &quot;Demo ğŸš€&quot;,
        &quot;1.0.0&quot;,
        server.WithToolCapabilities(false),
    )

    // Add tool
    tool := mcp.NewTool(&quot;hello_world&quot;,
        mcp.WithDescription(&quot;Say hello to someone&quot;),
        mcp.WithString(&quot;name&quot;,
            mcp.Required(),
            mcp.Description(&quot;Name of the person to greet&quot;),
        ),
    )

    // Add tool handler
    s.AddTool(tool, helloHandler)

    // Start the stdio server
    if err := server.ServeStdio(s); err != nil {
        fmt.Printf(&quot;Server error: %v\n&quot;, err)
    }
}

func helloHandler(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    name, err := request.RequireString(&quot;name&quot;)
    if err != nil {
        return mcp.NewToolResultError(err.Error()), nil
    }

    return mcp.NewToolResultText(fmt.Sprintf(&quot;Hello, %s!&quot;, name)), nil
}
```

That&#039;s it!

MCP Go handles all the complex protocol details and server management, so you can focus on building great tools. It aims to be high-level and easy to use.

### Key features:
* **Fast**: High-level interface means less code and faster development
* **Simple**: Build MCP servers with minimal boilerplate
* **Complete***: MCP Go aims to provide a full implementation of the core MCP specification

(\*emphasis on *aims*)

ğŸš¨ ğŸš§ ğŸ—ï¸ *MCP Go is under active development, as is the MCP specification itself. Core features are working but some advanced capabilities are still in progress.* 


&lt;!-- omit in toc --&gt;
## Table of Contents

- [Installation](#installation)
- [Quickstart](#quickstart)
- [What is MCP?](#what-is-mcp)
- [Core Concepts](#core-concepts)
  - [Server](#server)
  - [Resources](#resources)
  - [Tools](#tools)
  - [Prompts](#prompts)
- [Examples](#examples)
- [Extras](#extras)
  - [Transports](#transports)
  - [Session Management](#session-management)
    - [Basic Session Handling](#basic-session-handling)
    - [Per-Session Tools](#per-session-tools)
    - [Tool Filtering](#tool-filtering)
    - [Working with Context](#working-with-context)
  - [Request Hooks](#request-hooks)
  - [Tool Handler Middleware](#tool-handler-middleware)
  - [Regenerating Server Code](#regenerating-server-code)

## Installation

```bash
go get github.com/mark3labs/mcp-go
```

## Quickstart

Let&#039;s create a simple MCP server that exposes a calculator tool and some data:

```go
package main

import (
    &quot;context&quot;
    &quot;fmt&quot;

    &quot;github.com/mark3labs/mcp-go/mcp&quot;
    &quot;github.com/mark3labs/mcp-go/server&quot;
)

func main() {
    // Create a new MCP server
    s := server.NewMCPServer(
        &quot;Calculator Demo&quot;,
        &quot;1.0.0&quot;,
        server.WithToolCapabilities(false),
        server.WithRecovery(),
    )

    // Add a calculator tool
    calculatorTool := mcp.NewTool(&quot;calculate&quot;,
        mcp.WithDescription(&quot;Perform basic arithmetic operations&quot;),
        mcp.WithString(&quot;operation&quot;,
            mcp.Required(),
            mcp.Description(&quot;The operation to perform (add, subtract, multiply, divide)&quot;),
            mcp.Enum(&quot;add&quot;, &quot;subtract&quot;, &quot;multiply&quot;, &quot;divide&quot;),
        ),
        mcp.WithNumber(&quot;x&quot;,
            mcp.Required(),
            mcp.Description(&quot;First number&quot;),
        ),
        mcp.WithNumber(&quot;y&quot;,
            mcp.Required(),
            mcp.Description(&quot;Second number&quot;),
        ),
    )

    // Add the calculator handler
    s.AddTool(calculatorTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
        // Using helper functions for type-safe argument access
        op, err := request.RequireString(&quot;operation&quot;)
        if err != nil {
            return mcp.NewToolResultError(err.Error()), nil
        }
        
        x, err := request.RequireFloat(&quot;x&quot;)
        if err != nil {
            return mcp.NewToolResultError(err.Error()), nil
        }
        
        y, err := request.RequireFloat(&quot;y&quot;)
        if err != nil {
            return mcp.NewToolResultError(err.Error()), nil
        }

        var result float64
        switch op {
        case &quot;add&quot;:
            result = x + y
        case &quot;subtract&quot;:
            result = x - y
        case &quot;multiply&quot;:
            result = x * y
        case &quot;divide&quot;:
            if y == 0 {
                return mcp.NewToolResultError(&quot;cannot divide by zero&quot;), nil
            }
            result = x / y
        }

        return mcp.NewToolResultText(fmt.Sprintf(&quot;%.2f&quot;, result)), nil
    })

    // Start the server
    if err := server.ServeStdio(s); err != nil {
        fmt.Printf(&quot;Server error: %v\n&quot;, err)
    }
}
```

## What is MCP?

The [Model Context Protocol (MCP)](https://modelcontextprotocol.io) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way. Think of it like a web API, but specifically designed for LLM interactions.

MCP servers can:
- Expose data through **Resources** (think of these sort of like GET endpoints; they are used to load information into the LLM&#039;s context)
- Provide functionality through **Tools** (sort of like POST endpoints; they are used to execute code or otherwise produce a side effect)
- Define interaction patterns through **Prompts** (reusable templates for LLM interactions)
- And more!

mcp-go implements the Model Context Protocol specification version 2025-11-25, with backward compatibility for versions 2025-06-18, 2025-03-26, and 2024-11-05.

## Core Concepts


### Server

&lt;details&gt;
&lt;summary&gt;Show Server Examples&lt;/summary&gt;

The server is your core interface to the MCP protocol. It handles connection management, protocol compliance, and message routing:

```go
// Create a basic server
s := server.NewMCPServer(
    &quot;My Server&quot;,  // Server name
    &quot;1.0.0&quot;,     // Version
)

// Start the server using stdio
if err := server.ServeStdio(s); err != nil {
    log.Fatalf(&quot;Server error: %v&quot;, err)
}
```

&lt;/details&gt;

### Resources

&lt;details&gt;
&lt;summary&gt;Show Resource Examples&lt;/summary&gt;
Resources are how you expose data to LLMs. They can be anything - files, API responses, database queries, system information, etc. Resources can be:

- Static (fixed URI)
- Dynamic (using URI templates)

Here&#039;s a simple example of a static resource:

```go
// Static resource example - exposing a README file
resource := mcp.NewResource(
    &quot;docs://readme&quot;,
    &quot;Project README&quot;,
    mcp.WithResourceDescription(&quot;The project&#039;s README file&quot;), 
    mcp.WithMIMEType(&quot;text/markdown&quot;),
)

// Add resource with its handler
s.AddResource(resource, func(ctx context.Context, request mcp.ReadResourceRequest) ([]mcp.ResourceContents, error) {
    content, err := os.ReadFile(&quot;README.md&quot;)
    if err != nil {
        return nil, err
    }
    
    return []mcp.ResourceContents{
        mcp.TextResourceContents{
            URI:      &quot;docs://readme&quot;,
            MIMEType: &quot;text/markdown&quot;,
            Text:     string(content),
        },
    }, nil
})
```

And here&#039;s an example of a dynamic resource using a template:

```go
// Dynamic resource example - user profiles by ID
template := mcp.NewResourceTemplate(
    &quot;users://{id}/profile&quot;,
    &quot;User Profile&quot;,
    mcp.WithTemplateDescription(&quot;Returns user profile information&quot;),
    mcp.WithTemplateMIMEType(&quot;application/json&quot;),
)

// Add template with its handler
s.AddResourceTemplate(template, func(ctx context.Context, request mcp.ReadResourceRequest) ([]mcp.ResourceContents, error) {
    // Extract ID from the URI using regex matching
    // The server automatically matches URIs to templates
    userID := extractIDFromURI(request.Params.URI)
    
    profile, err := getUserProfile(userID)  // Your DB/API call here
    if err != nil {
        return nil, err
    }
    
    return []mcp.ResourceContents{
        mcp.TextResourceContents{
            URI:      request.Params.URI,
            MIMEType: &quot;application/json&quot;,
            Text:     profile,
        },
    }, nil
})
```

The examples are simple but demonstrate the core concepts. Resources can be much more sophisticated - serving multiple contents, integrating with databases or external APIs, etc.
&lt;/details&gt;

### Tools

&lt;details&gt;
&lt;summary&gt;Show Tool Examples&lt;/summary&gt;

Tools let LLMs take actions through your server. Unlike resources, tools are expected to perform computation and have side effects. They&#039;re similar to POST endpoints in a REST API.

#### Task-Augmented Tools

Task-augmented tools execute asynchronously and return results via polling. This is useful for long-running operations that would otherwise block or time out. Task tools support three modes:

- **TaskSupportForbidden** (default): The tool cannot be invoked as a task
- **TaskSupportOptional**: The tool can be invoked as a task or synchronously
- **TaskSupportRequired**: The tool must be invoked as a task

```go
// Example: A tool that requires task execution
processBatchTool := mcp.NewTool(&quot;process_batch&quot;,
    mcp.WithDescription(&quot;Process a batch of items asynchronously&quot;),
    mcp.WithTaskSupport(mcp.TaskSupportRequired),
    mcp.WithArray(&quot;items&quot;,
        mcp.Description(&quot;Array of items to process&quot;),
        mcp.WithStringItems(),
        mcp.Required(),
    ),
)

// Task tool handler returns CreateTaskResult instead of CallToolResult
s.AddTaskTool(processBatchTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CreateTaskResult, error) {
    items := request.GetStringSlice(&quot;items&quot;, []string{})
    
    // Long-running work here
    for i, item := range items {
        select {
        case &lt;-ctx.Done():
            // Task was cancelled
            return nil, ctx.Err()
        default:
            // Process item...
            processItem(item)
        }
    }
    
    // Return result - task ID and metadata are managed by the server
    return &amp;mcp.CreateTaskResult{
        Task: mcp.Task{
            // Task fields (ID, status, etc.) are populated by the server
        },
    }, nil
})

// Enable task capabilities when creating the server
s := server.NewMCPServer(
    &quot;Task Server&quot;,
    &quot;1.0.0&quot;,
    server.WithTaskCapabilities(
        true, // listTasks: allows clients to list all tasks
        true, // cancel: allows clients to cancel running tasks
        true, // toolCallTasks: enables task augmentation for tools
    ),
    server.WithMaxConcurrentTasks(10), // Optional: limit concurrent running tasks
)
```

Task execution flow:
1. Client calls tool with task parameter
2. Server immediately returns task ID
3. Tool executes asynchronously in the background
4. Client polls `tasks/result` to retrieve the result
5. Server sends task status notifications on completion

For optional task tools, the same tool can be called synchronously (without task parameter) or asynchronously (with task parameter):

```go
// Tool with optional task support
analyzeTool := mcp.NewTool(&quot;analyze_data&quot;,
    mcp.WithDescription(&quot;Analyze data - can run sync or async&quot;),
    mcp.WithTaskSupport(mcp.TaskSupportOptional),
    mcp.WithString(&quot;data&quot;, mcp.Required()),
)

// Use AddTaskTool for hybrid tools that support both modes
s.AddTaskTool(analyzeTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CreateTaskResult, error) {
    // This handler runs when called as a task
    data := request.GetString(&quot;data&quot;, &quot;&quot;)
    result := analyzeData(data)
    
    return &amp;mcp.CreateTaskResult{
        Task: mcp.Task{},
    }, nil
})

// The server automatically handles both sync and async invocations
// When called without task param: executes handler and returns immediately
// When called with task param: executes handler asynchronously
```

##### Limiting Concurrent Tasks

To prevent resource exhaustion, you can limit the number of concurrent running tasks:

```go
s := server.NewMCPServer(
    &quot;Task Server&quot;,
    &quot;1.0.0&quot;,
    server.WithTaskCapabilities(true, true, true),
    server.WithMaxConcurrentTasks(10), // Allow up to 10 concurrent running tasks
)
```

When the limit is reached, new task creation requests will fail with an error. Completed, failed, or cancelled tasks don&#039;t count toward the limit - only tasks in &quot;working&quot; status. If `WithMaxConcurrentTasks` is not specified or set to 0, there is no limit on concurrent tasks.

For traditional synchronous tools that execute and return results immediately:

Simple calculation example:
```go
calculatorTool := mcp.NewTool(&quot;calculate&quot;,
    mcp.WithDescription(&quot;Perform basic arithmetic calculations&quot;),
    mcp.WithString(&quot;operation&quot;,
        mcp.Required(),
        mcp.Description(&quot;The arithmetic operation to perform&quot;),
        mcp.Enum(&quot;add&quot;, &quot;subtract&quot;, &quot;multiply&quot;, &quot;divide&quot;),
    ),
    mcp.WithNumber(&quot;x&quot;,
        mcp.Required(),
        mcp.Description(&quot;First number&quot;),
    ),
    mcp.WithNumber(&quot;y&quot;,
        mcp.Required(),
        mcp.Description(&quot;Second number&quot;),
    ),
)

s.AddTool(calculatorTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    args := request.GetArguments()
    op := args[&quot;operation&quot;].(string)
    x := args[&quot;x&quot;].(float64)
    y := args[&quot;y&quot;].(float64)

    var result float64
    switch op {
    case &quot;add&quot;:
        result = x + y
    case &quot;subtract&quot;:
        result = x - y
    case &quot;multiply&quot;:
        result = x * y
    case &quot;divide&quot;:
        if y == 0 {
            return mcp.NewToolResultError(&quot;cannot divide by zero&quot;), nil
        }
        result = x / y
    }
    
    return mcp.FormatNumberResult(result), nil
})
```

HTTP request example:
```go
httpTool := mcp.NewTool(&quot;http_request&quot;,
    mcp.WithDescription(&quot;Make HTTP requests to external APIs&quot;),
    mcp.WithString(&quot;method&quot;,
        mcp.Required(),
        mcp.Description(&quot;HTTP method to use&quot;),
        mcp.Enum(&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;),
    ),
    mcp.WithString(&quot;url&quot;,
        mcp.Required(),
        mcp.Description(&quot;URL to send the request to&quot;),
        mcp.Pattern(&quot;^https?://.*&quot;),
    ),
    mcp.WithString(&quot;body&quot;,
        mcp.Description(&quot;Request body (for POST/PUT)&quot;),
    ),
)

s.AddTool(httpTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    args := request.GetArguments()
    method := args[&quot;method&quot;].(string)
    url := args[&quot;url&quot;].(string)
    body := &quot;&quot;
    if b, ok := args[&quot;body&quot;].(string); ok {
        body = b
    }

    // Create and send request
    var req *http.Request
    var err error
    if body != &quot;&quot; {
        req, err = http.NewRequest(method, url, strings.NewReader(body))
    } else {
        req, err = http.NewRequest(method, url, nil)
    }
    if err != nil {
        return mcp.NewToolResultErrorFromErr(&quot;unable to create request&quot;, err), nil
    }

    client := &amp;http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return mcp.NewToolResultErrorFromErr(&quot;unable to execute request&quot;, err), nil
    }
    defer resp.Body.Close()

    // Return response
    respBody, err := io.ReadAll(resp.Body)
    if err != nil {
        return mcp.NewToolResultErrorFromErr(&quot;unable to read request response&quot;, err), nil
    }

    return mcp.NewToolResultText(fmt.Sprintf(&quot;Status: %d\nBody: %s&quot;, resp.StatusCode, string(respBody))), nil
})
```

Tools can be used for any kind of computation or side effect:
- Database queries
- File operations  
- External API calls
- Calculations
- System operations

Each tool should:
- Have a clear description
- Validate inputs
- Handle errors gracefully 
- Return structured responses
- Use appropriate result types

&lt;/details&gt;

### Prompts

&lt;details&gt;
&lt;summary&gt;Show Prompt Examples&lt;/summary&gt;

Prompts are reusable templates that help LLMs interact with your server effectively. They&#039;re like &quot;best practices&quot; encoded into your server. Here are some examples:

```go
// Simple greeting prompt
s.AddPrompt(mcp.NewPrompt(&quot;greeting&quot;,
    mcp.WithPromptDescription(&quot;A friendly greeting prompt&quot;),
    mcp.WithArgument(&quot;name&quot;,
        mcp.ArgumentDescription(&quot;Name of the person to greet&quot;),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    name := request.Params.Arguments[&quot;name&quot;]
    if name == &quot;&quot; {
        name = &quot;friend&quot;
    }
    
    return mcp.NewGetPromptResult(
        &quot;A friendly greeting&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewTextContent(fmt.Sprintf(&quot;Hello, %s! How can I help you today?&quot;, name)),
            ),
        },
    ), nil
})

// Code review prompt with embedded resource
s.AddPrompt(mcp.NewPrompt(&quot;code_review&quot;,
    mcp.WithPromptDescription(&quot;Code review assistance&quot;),
    mcp.WithArgument(&quot;pr_number&quot;,
        mcp.ArgumentDescription(&quot;Pull request number to review&quot;),
        mcp.RequiredArgument(),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    prNumber := request.Params.Arguments[&quot;pr_number&quot;]
    if prNumber == &quot;&quot; {
        return nil, fmt.Errorf(&quot;pr_number is required&quot;)
    }
    
    return mcp.NewGetPromptResult(
        &quot;Code review assistance&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleUser,
                mcp.NewTextContent(&quot;Review the changes and provide constructive feedback.&quot;),
            ),
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewEmbeddedResource(mcp.ResourceContents{
                    URI: fmt.Sprintf(&quot;git://pulls/%s/diff&quot;, prNumber),
                    MIMEType: &quot;text/x-diff&quot;,
                }),
            ),
        },
    ), nil
})

// Database query builder prompt
s.AddPrompt(mcp.NewPrompt(&quot;query_builder&quot;,
    mcp.WithPromptDescription(&quot;SQL query builder assistance&quot;),
    mcp.WithArgument(&quot;table&quot;,
        mcp.ArgumentDescription(&quot;Name of the table to query&quot;),
        mcp.RequiredArgument(),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    tableName := request.Params.Arguments[&quot;table&quot;]
    if tableName == &quot;&quot; {
        return nil, fmt.Errorf(&quot;table name is required&quot;)
    }
    
    return mcp.NewGetPromptResult(
        &quot;SQL query builder assistance&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleUser,
                mcp.NewTextContent(&quot;Help construct efficient and safe queries for the provided schema.&quot;),
            ),
            mcp.NewPromptMessage(
                mcp.RoleUser,
                mcp.NewEmbeddedResource(mcp.ResourceContents{
                    URI: fmt.Sprintf(&quot;db://schema/%s&quot;, tableName),
                    MIMEType: &quot;application/json&quot;,
                }),
            ),
        },
    ), nil
})
```

Prompts can include:
- System instructions
- Required arguments
- Embedded resources
- Multiple messages
- Different content types (text, images, etc.)
- Custom URI schemes

&lt;/details&gt;

## Examples

For examples, see the [`examples/`](examples/) directory.

Key examples include:
- [`examples/task_tool/`](examples/task_tool/) - Demonstrates task-augmented tools with TaskSupportRequired and TaskSupportOptional modes
- Additional examples covering resources, prompts, and more i

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[moby/moby]]></title>
            <link>https://github.com/moby/moby</link>
            <guid>https://github.com/moby/moby</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:34 GMT</pubDate>
            <description><![CDATA[The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/moby/moby">moby/moby</a></h1>
            <p>The Moby Project - a collaborative project for the container ecosystem to assemble container-based systems</p>
            <p>Language: Go</p>
            <p>Stars: 71,448</p>
            <p>Forks: 18,911</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>The Moby Project
================

[![PkgGoDev](https://pkg.go.dev/badge/github.com/moby/moby/v2)](https://pkg.go.dev/github.com/moby/moby/v2)
![GitHub License](https://img.shields.io/github/license/moby/moby)
[![Go Report Card](https://goreportcard.com/badge/github.com/moby/moby/v2)](https://goreportcard.com/report/github.com/moby/moby/v2)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/moby/moby/badge)](https://scorecard.dev/viewer/?uri=github.com/moby/moby)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10989/badge)](https://www.bestpractices.dev/projects/10989)


![Moby Project logo](docs/static_files/moby-project-logo.png &quot;The Moby Project&quot;)

Moby is an open-source project created by Docker to enable and accelerate software containerization.

It provides a &quot;Lego set&quot; of toolkit components, the framework for assembling them into custom container-based systems, and a place for all container enthusiasts and professionals to experiment and exchange ideas.
Components include container build tools, a container registry, orchestration tools, a runtime and more, and these can be used as building blocks in conjunction with other tools and projects.

## Principles

Moby is an open project guided by strong principles, aiming to be modular, flexible and without too strong an opinion on user experience.
It is open to the community to help set its direction.

- Modular: the project includes lots of components that have well-defined functions and APIs that work together.
- Batteries included but swappable: Moby includes enough components to build fully featured container systems, but its modular architecture ensures that most of the components can be swapped by different implementations.
- Usable security: Moby provides secure defaults without compromising usability.
- Developer focused: The APIs are intended to be functional and useful to build powerful tools.
They are not necessarily intended as end user tools but as components aimed at developers.
Documentation and UX is aimed at developers not end users.

## Audience

The Moby Project is intended for engineers, integrators and enthusiasts looking to modify, hack, fix, experiment, invent and build systems based on containers.
It is not for people looking for a commercially supported system, but for people who want to work and learn with open source code.

## Relationship with Docker

The components and tools in the Moby Project are initially the open source components that Docker and the community have built for the Docker Project.
New projects can be added if they fit with the community goals. Docker is committed to using Moby as the upstream for the Docker Product.
However, other projects are also encouraged to use Moby as an upstream, and to reuse the components in diverse ways, and all these uses will be treated in the same way. External maintainers and contributors are welcomed.

The Moby project is not intended as a location for support or feature requests for Docker products, but as a place for contributors to work on open source code, fix bugs, and make the code more useful.
The releases are supported by the maintainers, community and users, on a best efforts basis only. For customers who want enterprise or commercial support, [Docker Desktop](https://www.docker.com/products/docker-desktop/) and [Mirantis Container Runtime](https://www.mirantis.com/software/mirantis-container-runtime/) are the appropriate products for these use cases.

-----

Legal
=====

*Brought to you courtesy of our legal counsel. For more context,
please see the [NOTICE](https://github.com/moby/moby/blob/master/NOTICE) document in this repo.*

Use and transfer of Moby may be subject to certain restrictions by the
United States and other governments.

It is your responsibility to ensure that your use and/or transfer does not
violate applicable laws.

For more information, please see https://www.bis.doc.gov

Licensing
=========
Moby is licensed under the Apache License, Version 2.0. See
[LICENSE](https://github.com/moby/moby/blob/master/LICENSE) for the full
license text.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cosmos/cosmos-sdk]]></title>
            <link>https://github.com/cosmos/cosmos-sdk</link>
            <guid>https://github.com/cosmos/cosmos-sdk</guid>
            <pubDate>Sat, 28 Feb 2026 00:05:33 GMT</pubDate>
            <description><![CDATA[â›“ï¸ A Framework for Building High Value Public Blockchains âœ¨]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cosmos/cosmos-sdk">cosmos/cosmos-sdk</a></h1>
            <p>â›“ï¸ A Framework for Building High Value Public Blockchains âœ¨</p>
            <p>Language: Go</p>
            <p>Stars: 6,940</p>
            <p>Forks: 4,148</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;left&quot;&gt;
  &lt;h1&gt; Cosmos SDK &lt;/h1&gt;
&lt;/div&gt;

![banner](docs/static/img/banner.svg)

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/cosmos/cosmos-sdk/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;License: Apache-2.0&quot; src=&quot;https://img.shields.io/github/license/cosmos/cosmos-sdk.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pkg.go.dev/github.com/cosmos/cosmos-sdk&quot;&gt;
    &lt;img src=&quot;https://pkg.go.dev/badge/github.com/cosmos/cosmos-sdk.svg&quot; alt=&quot;Go Reference&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/cosmos/cosmos-sdk&quot;&gt;
    &lt;img alt=&quot;Go report card&quot; src=&quot;https://goreportcard.com/badge/github.com/cosmos/cosmos-sdk&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.com/invite/interchain&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/669268347736686612.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://sourcegraph.com/github.com/cosmos/cosmos-sdk?badge&quot;&gt;
    &lt;img alt=&quot;Imported by&quot; src=&quot;https://sourcegraph.com/github.com/cosmos/cosmos-sdk/-/badge.svg&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

The Cosmos SDK is a modular, open-source blockchain SDK for building secure, high-performance Layer 1 chains with full customizability used by 200+ chains in production.   Developers can use the Cosmos SDK to easily and quickly spin up custom blockchains that can natively interoperate.

The Cosmos SDK is tailored for building secure, sovereign application-specific blockchains. Developers building with the Cosmos SDK can use predefined modules that cover standard blockchain functionality or create custom modules for their specific use case. This composable architecture enables robust customization. The SDK provides abstractions for permissioning, governance, state management, account abstraction, tokenization processes, application logic, and more.

Cosmos SDK blockchains get interoperability out-of-the-box via a native integration with the [Inter-Blockchain Communication Protocol (IBC)](https://github.com/cosmos/ibc-go). ibc-go is implemented as a Go module in the Cosmos SDK. 

While the Cosmos SDK is plug-and-play with any consensus engine, we recommend using [CometBFT](https://github.com/cometbft/cometbft) for a fast, battle-tested, high-throughput, configurable BFT state machine. CometBFT is developed as part of the Cosmos Stack and its releases are updated alongside the SDK.

**WARNING**: The Cosmos SDK has mostly stabilized, but we are still making some breaking changes.

## Quick Start

To learn how the Cosmos SDK works from a high-level perspective, see the Cosmos SDK [High-Level Intro](https://docs.cosmos.network/main/intro/overview).

If you want to get started quickly and learn how to build on top of Cosmos SDK, visit [Cosmos SDK Tutorials](https://tutorials.cosmos.network). You can also fork the tutorial&#039;s repository to get started building your own Cosmos SDK application.

Note: We advise to always use the latest maintained [Go version](https://go.dev/dl/) for building Cosmos SDK applications.

## Modules

The Cosmos SDK maintains a set of modules that can be included in your blockchain application.  For more information
on modules, see our [introduction doc](./x/README.md).

## Enterprise Modules

In addition to the core SDK modules, we maintain enterprise-grade modules designed for specialized use cases such as permissioned networks and consortium chains. These modules are located in the `enterprise/` directory and have different licensing terms than the core SDK.

## Maintainers
[Cosmos Labs](https://cosmoslabs.io/) maintains the core components of the stack: Cosmos SDK, CometBFT, IBC, Cosmos EVM, and various developer tools and frameworks. The detailed maintenance policy can be found [here](https://github.com/cosmos/security/blob/main/POLICY.md). In addition to developing and maintaining the Cosmos Stack, Cosmos Labs provides advisory and engineering services for blockchain solutions. [Get in touch with Cosmos Labs](https://www.cosmoslabs.io/contact).

Cosmos Labs is a wholly-owned subsidiary of the [Interchain Foundation](https://interchain.io/), the Swiss nonprofit responsible for treasury management, funding public goods, and supporting governance for Cosmos. 

The Cosmos Stack is supported by a robust community of open-source contributors. 

## History
The Cosmos SDK was first released in 2019, and the first blockchain to use the SDK in production was the [Cosmos Hub](https://hub.cosmos.network/main). Today, the Cosmos SDK is a popular, battle-tested, open-source framework used by hundreds of chains.

The Cosmos Hub still receives the most up-to-date Cosmos SDK versions. The Cosmos Hub application, `gaia`, has its own [cosmos/gaia repository](https://github.com/cosmos/gaia). 

## Developer Community and Support

The issue list of this repo is exclusively for bug reports and feature requests. We have active, helpful communities on Discord, Telegram, and Slack.

**| Need Help? | Support &amp; Community: [Discord](https://discord.com/invite/interchain) - [Telegram](https://t.me/CosmosOG) - [Talk to an Expert](https://cosmos.network/interest-form) - [Join the #Cosmos-tech Slack Channel](https://forms.gle/A8jawLgB8zuL1FN36) |**

## Documentation and Resources
**View the Cosmos SDK documentation: https://docs.cosmos.network/**

### Cosmos Stack Libraries

- [CometBFT](https://github.com/cometbft/cometbft) - High-performance, 10k+ TPS configurable BFT consensus engine.
- [The Inter-Blockchain Communication Protocol (IBC)](https://github.com/cosmos/ibc-go/) - A blockchain interoperability protocol that allows blockchains to transfer any type of data encoded in bytes.
- [Cosmos EVM](https://github.com/cosmos/evm) - Native EVM layer for Cosmos SDK chains. 

## Disambiguation

This Cosmos SDK project is not related to the [React-Cosmos](https://github.com/react-cosmos/react-cosmos) project (yet). Many thanks to Evan Coury and Ovidiu (@skidding) for this Github organization name. As per our agreement, this disambiguation notice will stay here.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>