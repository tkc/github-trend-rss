<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Thu, 10 Apr 2025 00:05:29 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[googleapis/google-cloud-go]]></title>
            <link>https://github.com/googleapis/google-cloud-go</link>
            <guid>https://github.com/googleapis/google-cloud-go</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[Google Cloud Client Libraries for Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/googleapis/google-cloud-go">googleapis/google-cloud-go</a></h1>
            <p>Google Cloud Client Libraries for Go.</p>
            <p>Language: Go</p>
            <p>Stars: 3,989</p>
            <p>Forks: 1,387</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># Google Cloud Client Libraries for Go

[![Go Reference](https://pkg.go.dev/badge/cloud.google.com/go.svg)](https://pkg.go.dev/cloud.google.com/go)

Go packages for [Google Cloud Platform](https://cloud.google.com) services.

## Installation

```bash
go get cloud.google.com/go/firestore@latest # Replace firestore with the package you want to use.
```

**NOTE:** Some of these packages are under development, and may occasionally
make backwards-incompatible changes.

## Supported APIs

For an updated list of all of our released APIs please see our
[reference docs](https://cloud.google.com/go/docs/reference).

## [Go Versions Supported](#supported-versions)

Our libraries are compatible with the two most recent major Go
releases, the same [policy](https://go.dev/doc/devel/release#policy) the Go
programming language follows. This means the currently supported versions are:

- Go 1.23
- Go 1.24

## Authentication

By default, each client library will use [Application Default Credentials](https://developers.google.com/identity/protocols/application-default-credentials)
(ADC) to automatically configure the credentials used in calling the API endpoint.
When using the libraries in a Google Cloud Platform environment such as Compute
Engine, Kubernetes Engine, or App Engine, no additional authentication steps are
necessary. See [Authentication methods at Google](https://cloud.google.com/docs/authentication)
and [Authenticate for using client libraries](https://cloud.google.com/docs/authentication/client-libraries)
for more information.

```go
client, err := storage.NewClient(ctx)
```

For applications running elsewhere, such as your local development environment,
you can use the `gcloud auth application-default login` command from the
[Google Cloud CLI](https://cloud.google.com/cli) to set user credentials in
your local filesystem. Application Default Credentials will automatically detect
these credentials. See [Set up ADC for a local development
environment](https://cloud.google.com/docs/authentication/set-up-adc-local-dev-environment)
for more information.

Alternately, you may need to provide an explicit path to your credentials. To authenticate
using a [service account](https://cloud.google.com/docs/authentication#service-accounts)
key file, either set the `GOOGLE_APPLICATION_CREDENTIALS` environment variable to the path
to your key file, or programmatically pass
[`option.WithCredentialsFile`](https://pkg.go.dev/google.golang.org/api/option#WithCredentialsFile)
to the `NewClient` function of the desired package. For example:

```go
client, err := storage.NewClient(ctx, option.WithCredentialsFile(&quot;path/to/keyfile.json&quot;))
```

You can exert even more control over authentication by using the
[credentials](https://pkg.go.dev/cloud.google.com/go/auth/credentials) package to
create an [auth.Credentials](https://pkg.go.dev/cloud.google.com/go/auth#Credentials).
Then pass [`option.WithAuthCredentials`](https://pkg.go.dev/google.golang.org/api/option#WithAuthCredentials)
to the `NewClient` function:

```go
creds, err := credentials.DetectDefault(&amp;credentials.DetectOptions{...})
...
client, err := storage.NewClient(ctx, option.WithAuthCredentials(creds))
```

## Contributing

Contributions are welcome. Please, see the
[CONTRIBUTING](https://github.com/GoogleCloudPlatform/google-cloud-go/blob/main/CONTRIBUTING.md)
document for details.

Please note that this project is released with a Contributor Code of Conduct.
By participating in this project you agree to abide by its terms.
See [Contributor Code of Conduct](https://github.com/GoogleCloudPlatform/google-cloud-go/blob/main/CONTRIBUTING.md#contributor-code-of-conduct)
for more information.

## Links

- [Go on Google Cloud](https://cloud.google.com/go/home)
- [Getting started with Go on Google Cloud](https://cloud.google.com/go/getting-started)
- [App Engine Quickstart](https://cloud.google.com/appengine/docs/standard/go/quickstart)
- [Cloud Functions Quickstart](https://cloud.google.com/functions/docs/quickstart-go)
- [Cloud Run Quickstart](https://cloud.google.com/run/docs/quickstarts/build-and-deploy#go)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[netbirdio/netbird]]></title>
            <link>https://github.com/netbirdio/netbird</link>
            <guid>https://github.com/netbirdio/netbird</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Connect your devices into a secure WireGuard®-based overlay network with SSO, MFA and granular access controls.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/netbirdio/netbird">netbirdio/netbird</a></h1>
            <p>Connect your devices into a secure WireGuard®-based overlay network with SSO, MFA and granular access controls.</p>
            <p>Language: Go</p>
            <p>Stars: 13,126</p>
            <p>Forks: 626</p>
            <p>Stars today: 195 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;br/&gt;
  &lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;234&quot; src=&quot;docs/media/logo-full.png&quot;/&gt;
&lt;/p&gt;
  &lt;p&gt;
   &lt;a href=&quot;https://img.shields.io/badge/license-BSD--3-blue)&quot;&gt;
       &lt;img src=&quot;https://sonarcloud.io/api/project_badges/measure?project=netbirdio_netbird&amp;metric=alert_status&quot; /&gt;
     &lt;/a&gt; 
     &lt;a href=&quot;https://github.com/netbirdio/netbird/blob/main/LICENSE&quot;&gt;
       &lt;img src=&quot;https://img.shields.io/badge/license-BSD--3-blue&quot; /&gt;
     &lt;/a&gt; 
    &lt;br&gt;
    &lt;a href=&quot;https://join.slack.com/t/netbirdio/shared_invite/zt-31rofwmxc-27akKd0Le0vyRpBcwXkP0g&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/slack-@netbird-red.svg?logo=slack&quot;/&gt;
     &lt;/a&gt;  
     &lt;br&gt;
    &lt;a href=&quot;https://gurubase.io/g/netbird&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20NetBird%20Guru-006BFF&quot;/&gt;
     &lt;/a&gt;    
  &lt;/p&gt;
&lt;/div&gt;


&lt;p align=&quot;center&quot;&gt;
&lt;strong&gt;
  Start using NetBird at &lt;a href=&quot;https://netbird.io/pricing&quot;&gt;netbird.io&lt;/a&gt;
  &lt;br/&gt;
  See &lt;a href=&quot;https://netbird.io/docs/&quot;&gt;Documentation&lt;/a&gt;
  &lt;br/&gt;
   Join our &lt;a href=&quot;https://join.slack.com/t/netbirdio/shared_invite/zt-31rofwmxc-27akKd0Le0vyRpBcwXkP0g&quot;&gt;Slack channel&lt;/a&gt;
  &lt;br/&gt;
 
&lt;/strong&gt;
&lt;br&gt;
&lt;a href=&quot;https://github.com/netbirdio/kubernetes-operator&quot;&gt;
    New: NetBird Kubernetes Operator
  &lt;/a&gt; 
&lt;/p&gt;

&lt;br&gt;

**NetBird combines a configuration-free peer-to-peer private network and a centralized access control system in a single platform, making it easy to create secure private networks for your organization or home.**

**Connect.** NetBird creates a WireGuard-based overlay network that automatically connects your machines over an encrypted tunnel, leaving behind the hassle of opening ports, complex firewall rules, VPN gateways, and so forth.

**Secure.** NetBird enables secure remote access by applying granular access policies while allowing you to manage them intuitively from a single place. Works universally on any infrastructure.

### Open-Source Network Security in a Single Platform


![netbird_2](https://github.com/netbirdio/netbird/assets/700848/46bc3b73-508d-4a0e-bb9a-f465d68646ab)

### NetBird on Lawrence Systems (Video)
[![Watch the video](https://img.youtube.com/vi/Kwrff6h0rEw/0.jpg)](https://www.youtube.com/watch?v=Kwrff6h0rEw)

### Key features

| Connectivity                                                                                                                 | Management                                                                                               | Security                                                                                                                              | Automation                                                                                                                               | Platforms                                                                               |
|------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------|
| &lt;ul&gt;&lt;li&gt; - \[x] Kernel WireGuard &lt;/ul&gt;&lt;/li&gt;                                                                                  | &lt;ul&gt;&lt;li&gt; - \[x] [Admin Web UI](https://github.com/netbirdio/dashboard) &lt;/ul&gt;&lt;/li&gt;                        | &lt;ul&gt;&lt;li&gt; - \[x] [SSO &amp; MFA support](https://docs.netbird.io/how-to/installation#running-net-bird-with-sso-login) &lt;/ul&gt;&lt;/li&gt;           | &lt;ul&gt;&lt;li&gt; - \[x] [Public API](https://docs.netbird.io/api) &lt;/ul&gt;&lt;/li&gt;                                                                     | &lt;ul&gt;&lt;li&gt; - \[x] Linux &lt;/ul&gt;&lt;/li&gt;                                                        |
| &lt;ul&gt;&lt;li&gt; - \[x] Peer-to-peer connections &lt;/ul&gt;&lt;/li&gt;                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] Auto peer discovery and configuration &lt;/ul&gt;&lt;/li&gt;                                         | &lt;ul&gt;&lt;li&gt; - \[x] [Access control - groups &amp; rules](https://docs.netbird.io/how-to/manage-network-access) &lt;/ul&gt;&lt;/li&gt;                    | &lt;ul&gt;&lt;li&gt; - \[x] [Setup keys for bulk network provisioning](https://docs.netbird.io/how-to/register-machines-using-setup-keys) &lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt; - \[x] Mac &lt;/ul&gt;&lt;/li&gt;                                                          |
| &lt;ul&gt;&lt;li&gt; - \[x] Connection relay fallback &lt;/ul&gt;&lt;/li&gt;                                                                         | &lt;ul&gt;&lt;li&gt; - \[x] [IdP integrations](https://docs.netbird.io/selfhosted/identity-providers) &lt;/ul&gt;&lt;/li&gt;     | &lt;ul&gt;&lt;li&gt; - \[x] [Activity logging](https://docs.netbird.io/how-to/monitor-system-and-network-activity) &lt;/ul&gt;&lt;/li&gt;                     | &lt;ul&gt;&lt;li&gt; - \[x] [Self-hosting quickstart script](https://docs.netbird.io/selfhosted/selfhosted-quickstart) &lt;/ul&gt;&lt;/li&gt;                    | &lt;ul&gt;&lt;li&gt; - \[x] Windows &lt;/ul&gt;&lt;/li&gt;                                                      |
| &lt;ul&gt;&lt;li&gt; - \[x] [Routes to external networks](https://docs.netbird.io/how-to/routing-traffic-to-private-networks) &lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt; - \[x] [Private DNS](https://docs.netbird.io/how-to/manage-dns-in-your-network) &lt;/ul&gt;&lt;/li&gt;      | &lt;ul&gt;&lt;li&gt; - \[x] [Device posture checks](https://docs.netbird.io/how-to/manage-posture-checks) &lt;/ul&gt;&lt;/li&gt;                              | &lt;ul&gt;&lt;li&gt; - \[x] IdP groups sync with JWT &lt;/ul&gt;&lt;/li&gt;                                                                                      | &lt;ul&gt;&lt;li&gt; - \[x] Android &lt;/ul&gt;&lt;/li&gt;                                                      |
| &lt;ul&gt;&lt;li&gt; - \[x] NAT traversal with BPF &lt;/ul&gt;&lt;/li&gt;                                                                            | &lt;ul&gt;&lt;li&gt; - \[x] [Multiuser support](https://docs.netbird.io/how-to/add-users-to-your-network) &lt;/ul&gt;&lt;/li&gt; | &lt;ul&gt;&lt;li&gt; -  \[x] Peer-to-peer encryption &lt;/ul&gt;&lt;/li&gt;                                                                                   |                                                                                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] iOS &lt;/ul&gt;&lt;/li&gt;                                                          |
|                                                                                                                              |                                                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] [Quantum-resistance with Rosenpass](https://netbird.io/knowledge-hub/the-first-quantum-resistant-mesh-vpn) &lt;/ul&gt;&lt;/li&gt; |                                                                                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] OpenWRT &lt;/ul&gt;&lt;/li&gt;                                                      |
|                                                                                                                              |                                                                                                          | &lt;ui&gt;&lt;li&gt; - \[x] [Periodic re-authentication](https://docs.netbird.io/how-to/enforce-periodic-user-authentication)&lt;/ul&gt;&lt;/li&gt;           |                                                                                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] [Serverless](https://docs.netbird.io/how-to/netbird-on-faas) &lt;/ul&gt;&lt;/li&gt; |
|                                                                                                                              |                                                                                                          |                                                                                                                                       |                                                                                                                                          | &lt;ul&gt;&lt;li&gt; - \[x] Docker &lt;/ul&gt;&lt;/li&gt;                                                       |

### Quickstart with NetBird Cloud

- Download and install NetBird at [https://app.netbird.io/install](https://app.netbird.io/install)
- Follow the steps to sign-up with Google, Microsoft, GitHub or your email address.
- Check NetBird [admin UI](https://app.netbird.io/).
- Add more machines.

### Quickstart with self-hosted NetBird

&gt; This is the quickest way to try self-hosted NetBird. It should take around 5 minutes to get started if you already have a public domain and a VM.
Follow the [Advanced guide with a custom identity provider](https://docs.netbird.io/selfhosted/selfhosted-guide#advanced-guide-with-a-custom-identity-provider) for installations with different IDPs.

**Infrastructure requirements:**
- A Linux VM with at least **1CPU** and **2GB** of memory.
- The VM should be publicly accessible on TCP ports **80** and **443** and UDP ports: **3478**, **49152-65535**.
- **Public domain** name pointing to the VM.

**Software requirements:**
- Docker installed on the VM with the docker-compose plugin ([Docker installation guide](https://docs.docker.com/engine/install/)) or docker with docker-compose in version 2 or higher.
- [jq](https://jqlang.github.io/jq/) installed. In most distributions
  Usually available in the official repositories and can be installed with `sudo apt install jq` or `sudo yum install jq`
- [curl](https://curl.se/) installed.
  Usually available in the official repositories and can be installed with `sudo apt install curl` or `sudo yum install curl`

**Steps**
- Download and run the installation script:
```bash
export NETBIRD_DOMAIN=netbird.example.com; curl -fsSL https://github.com/netbirdio/netbird/releases/latest/download/getting-started-with-zitadel.sh | bash
```
- Once finished, you can manage the resources via `docker-compose`

### A bit on NetBird internals
-  Every machine in the network runs [NetBird Agent (or Client)](client/) that manages WireGuard.
-  Every agent connects to [Management Service](management/) that holds network state, manages peer IPs, and distributes network updates to agents (peers).
-  NetBird agent uses WebRTC ICE implemented in [pion/ice library](https://github.com/pion/ice) to discover connection candidates when establishing a peer-to-peer connection between machines.
-  Connection candidates are discovered with the help of [STUN](https://en.wikipedia.org/wiki/STUN) servers.
-  Agents negotiate a connection through [Signal Service](signal/) passing p2p encrypted messages with candidates.
-  Sometimes the NAT traversal is unsuccessful due to strict NATs (e.g. mobile carrier-grade NAT) and a p2p connection isn&#039;t possible. When this occurs the system falls back to a relay server called [TURN](https://en.wikipedia.org/wiki/Traversal_Using_Relays_around_NAT), and a secure WireGuard tunnel is established via the TURN server. 
 
[Coturn](https://github.com/coturn/coturn) is the one that has been successfully used for STUN and TURN in NetBird setups.

&lt;p float=&quot;left&quot; align=&quot;middle&quot;&gt;
  &lt;img src=&quot;https://docs.netbird.io/docs-static/img/architecture/high-level-dia.png&quot; width=&quot;700&quot;/&gt;
&lt;/p&gt;

See a complete [architecture overview](https://docs.netbird.io/about-netbird/how-netbird-works#architecture) for details.

### Community projects
-  [NetBird installer script](https://github.com/physk/netbird-installer)
-  [NetBird ansible collection by Dominion Solutions](https://galaxy.ansible.com/ui/repo/published/dominion_solutions/netbird/)

**Note**: The `main` branch may be in an *unstable or even broken state* during development.
For stable versions, see [releases](https://github.com/netbirdio/netbird/releases).

### Support acknowledgement

In November 2022, NetBird joined the [StartUpSecure program](https://www.forschung-it-sicherheit-kommunikationssysteme.de/foerderung/bekanntmachungen/startup-secure) sponsored by The Federal Ministry of Education and Research of The Federal Republic of Germany. Together with [CISPA Helmholtz Center for Information Security](https://cispa.de/en) NetBird brings the security best practices and simplicity to private networking.

![CISPA_Logo_BLACK_EN_RZ_RGB (1)](https://user-images.githubusercontent.com/700848/203091324-c6d311a0-22b5-4b05-a288-91cbc6cdcc46.png)

### Testimonials
We use open-source technologies like [WireGuard®](https://www.wireguard.com/), [Pion ICE (WebRTC)](https://github.com/pion/ice), [Coturn](https://github.com/coturn/coturn), and [Rosenpass](https://rosenpass.eu). We very much appreciate the work these guys are doing and we&#039;d greatly appreciate if you could support them in any way (e.g., by giving a star or a contribution).

### Legal
 _WireGuard_ and the _WireGuard_ logo are [registered trademarks](https://www.wireguard.com/trademark-policy/) of Jason A. Donenfeld.

</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[gin-gonic/gin]]></title>
            <link>https://github.com/gin-gonic/gin</link>
            <guid>https://github.com/gin-gonic/gin</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance -- up to 40 times faster. If you need smashing performance, get yourself some Gin.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gin-gonic/gin">gin-gonic/gin</a></h1>
            <p>Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance -- up to 40 times faster. If you need smashing performance, get yourself some Gin.</p>
            <p>Language: Go</p>
            <p>Stars: 81,531</p>
            <p>Forks: 8,167</p>
            <p>Stars today: 113 stars today</p>
            <h2>README</h2><pre># Gin Web Framework

&lt;img align=&quot;right&quot; width=&quot;159px&quot; src=&quot;https://raw.githubusercontent.com/gin-gonic/logo/master/color.png&quot;&gt;

[![Build Status](https://github.com/gin-gonic/gin/workflows/Run%20Tests/badge.svg?branch=master)](https://github.com/gin-gonic/gin/actions?query=branch%3Amaster)
[![codecov](https://codecov.io/gh/gin-gonic/gin/branch/master/graph/badge.svg)](https://codecov.io/gh/gin-gonic/gin)
[![Go Report Card](https://goreportcard.com/badge/github.com/gin-gonic/gin)](https://goreportcard.com/report/github.com/gin-gonic/gin)
[![Go Reference](https://pkg.go.dev/badge/github.com/gin-gonic/gin?status.svg)](https://pkg.go.dev/github.com/gin-gonic/gin?tab=doc)
[![Sourcegraph](https://sourcegraph.com/github.com/gin-gonic/gin/-/badge.svg)](https://sourcegraph.com/github.com/gin-gonic/gin?badge)
[![Open Source Helpers](https://www.codetriage.com/gin-gonic/gin/badges/users.svg)](https://www.codetriage.com/gin-gonic/gin)
[![Release](https://img.shields.io/github/release/gin-gonic/gin.svg?style=flat-square)](https://github.com/gin-gonic/gin/releases)
[![TODOs](https://badgen.net/https/api.tickgit.com/badgen/github.com/gin-gonic/gin)](https://www.tickgit.com/browse?repo=github.com/gin-gonic/gin)

Gin is a web framework written in [Go](https://go.dev/). It features a martini-like API with performance that is up to 40 times faster thanks to [httprouter](https://github.com/julienschmidt/httprouter).
If you need performance and good productivity, you will love Gin.

**Gin&#039;s key features are:**

- Zero allocation router
- Speed
- Middleware support
- Crash-free
- JSON validation
- Route grouping
- Error management
- Built-in rendering
- Extensible

## Getting started

### Prerequisites

Gin requires [Go](https://go.dev/) version [1.23](https://go.dev/doc/devel/release#go1.23.0) or above.

### Getting Gin

With [Go&#039;s module support](https://go.dev/wiki/Modules#how-to-use-modules), `go [build|run|test]` automatically fetches the necessary dependencies when you add the import in your code:

```sh
import &quot;github.com/gin-gonic/gin&quot;
```

Alternatively, use `go get`:

```sh
go get -u github.com/gin-gonic/gin
```

### Running Gin

A basic example:

```go
package main

import (
  &quot;net/http&quot;

  &quot;github.com/gin-gonic/gin&quot;
)

func main() {
  r := gin.Default()
  r.GET(&quot;/ping&quot;, func(c *gin.Context) {
    c.JSON(http.StatusOK, gin.H{
      &quot;message&quot;: &quot;pong&quot;,
    })
  })
  r.Run() // listen and serve on 0.0.0.0:8080 (for windows &quot;localhost:8080&quot;)
}
```

To run the code, use the `go run` command, like:

```sh
go run example.go
```

Then visit [`0.0.0.0:8080/ping`](http://0.0.0.0:8080/ping) in your browser to see the response!

### See more examples

#### Quick Start

Learn and practice with the [Gin Quick Start](docs/doc.md), which includes API examples and builds tag.

#### Examples

A number of ready-to-run examples demonstrating various use cases of Gin are available in the [Gin examples](https://github.com/gin-gonic/examples) repository.

## Documentation

See the [API documentation on go.dev](https://pkg.go.dev/github.com/gin-gonic/gin).

The documentation is also available on [gin-gonic.com](https://gin-gonic.com) in several languages:

- [English](https://gin-gonic.com/docs/)
- [简体中文](https://gin-gonic.com/zh-cn/docs/)
- [繁體中文](https://gin-gonic.com/zh-tw/docs/)
- [日本語](https://gin-gonic.com/ja/docs/)
- [Español](https://gin-gonic.com/es/docs/)
- [한국어](https://gin-gonic.com/ko-kr/docs/)
- [Turkish](https://gin-gonic.com/tr/docs/)
- [Persian](https://gin-gonic.com/fa/docs/)
- [Português](https://gin-gonic.com/pt/docs/)

### Articles

- [Tutorial: Developing a RESTful API with Go and Gin](https://go.dev/doc/tutorial/web-service-gin)

## Benchmarks

Gin uses a custom version of [HttpRouter](https://github.com/julienschmidt/httprouter), [see all benchmarks](/BENCHMARKS.md).

| Benchmark name                 |       (1) |             (2) |          (3) |             (4) |
| ------------------------------ | --------: | --------------: | -----------: | --------------: |
| BenchmarkGin_GithubAll         | **43550** | **27364 ns/op** |   **0 B/op** | **0 allocs/op** |
| BenchmarkAce_GithubAll         |     40543 |     29670 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkAero_GithubAll        |     57632 |     20648 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkBear_GithubAll        |      9234 |    216179 ns/op |   86448 B/op |   943 allocs/op |
| BenchmarkBeego_GithubAll       |      7407 |    243496 ns/op |   71456 B/op |   609 allocs/op |
| BenchmarkBone_GithubAll        |       420 |   2922835 ns/op |  720160 B/op |  8620 allocs/op |
| BenchmarkChi_GithubAll         |      7620 |    238331 ns/op |   87696 B/op |   609 allocs/op |
| BenchmarkDenco_GithubAll       |     18355 |     64494 ns/op |   20224 B/op |   167 allocs/op |
| BenchmarkEcho_GithubAll        |     31251 |     38479 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkGocraftWeb_GithubAll  |      4117 |    300062 ns/op |  131656 B/op |  1686 allocs/op |
| BenchmarkGoji_GithubAll        |      3274 |    416158 ns/op |   56112 B/op |   334 allocs/op |
| BenchmarkGojiv2_GithubAll      |      1402 |    870518 ns/op |  352720 B/op |  4321 allocs/op |
| BenchmarkGoJsonRest_GithubAll  |      2976 |    401507 ns/op |  134371 B/op |  2737 allocs/op |
| BenchmarkGoRestful_GithubAll   |       410 |   2913158 ns/op |  910144 B/op |  2938 allocs/op |
| BenchmarkGorillaMux_GithubAll  |       346 |   3384987 ns/op |  251650 B/op |  1994 allocs/op |
| BenchmarkGowwwRouter_GithubAll |     10000 |    143025 ns/op |   72144 B/op |   501 allocs/op |
| BenchmarkHttpRouter_GithubAll  |     55938 |     21360 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkHttpTreeMux_GithubAll |     10000 |    153944 ns/op |   65856 B/op |   671 allocs/op |
| BenchmarkKocha_GithubAll       |     10000 |    106315 ns/op |   23304 B/op |   843 allocs/op |
| BenchmarkLARS_GithubAll        |     47779 |     25084 ns/op |       0 B/op |     0 allocs/op |
| BenchmarkMacaron_GithubAll     |      3266 |    371907 ns/op |  149409 B/op |  1624 allocs/op |
| BenchmarkMartini_GithubAll     |       331 |   3444706 ns/op |  226551 B/op |  2325 allocs/op |
| BenchmarkPat_GithubAll         |       273 |   4381818 ns/op | 1483152 B/op | 26963 allocs/op |
| BenchmarkPossum_GithubAll      |     10000 |    164367 ns/op |   84448 B/op |   609 allocs/op |
| BenchmarkR2router_GithubAll    |     10000 |    160220 ns/op |   77328 B/op |   979 allocs/op |
| BenchmarkRivet_GithubAll       |     14625 |     82453 ns/op |   16272 B/op |   167 allocs/op |
| BenchmarkTango_GithubAll       |      6255 |    279611 ns/op |   63826 B/op |  1618 allocs/op |
| BenchmarkTigerTonic_GithubAll  |      2008 |    687874 ns/op |  193856 B/op |  4474 allocs/op |
| BenchmarkTraffic_GithubAll     |       355 |   3478508 ns/op |  820744 B/op | 14114 allocs/op |
| BenchmarkVulcan_GithubAll      |      6885 |    193333 ns/op |   19894 B/op |   609 allocs/op |

- (1): Total Repetitions achieved in constant time, higher means more confident result
- (2): Single Repetition Duration (ns/op), lower is better
- (3): Heap Memory (B/op), lower is better
- (4): Average Allocations per Repetition (allocs/op), lower is better

## Middleware

You can find many useful Gin middlewares at [gin-contrib](https://github.com/gin-contrib).

## Uses

Here are some awesome projects that are using the [Gin](https://github.com/gin-gonic/gin) web framework.

- [gorush](https://github.com/appleboy/gorush): A push notification server.
- [fnproject](https://github.com/fnproject/fn): A container native, cloud agnostic serverless platform.
- [photoprism](https://github.com/photoprism/photoprism): Personal photo management powered by Google TensorFlow.
- [lura](https://github.com/luraproject/lura): Ultra performant API Gateway with middleware.
- [picfit](https://github.com/thoas/picfit): An image resizing server.
- [dkron](https://github.com/distribworks/dkron): Distributed, fault tolerant job scheduling system.

## Contributing

Gin is the work of hundreds of contributors. We appreciate your help!

Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details on submitting patches and the contribution workflow.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[open-telemetry/opentelemetry-collector-contrib]]></title>
            <link>https://github.com/open-telemetry/opentelemetry-collector-contrib</link>
            <guid>https://github.com/open-telemetry/opentelemetry-collector-contrib</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[Contrib repository for the OpenTelemetry Collector]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/open-telemetry/opentelemetry-collector-contrib">open-telemetry/opentelemetry-collector-contrib</a></h1>
            <p>Contrib repository for the OpenTelemetry Collector</p>
            <p>Language: Go</p>
            <p>Stars: 3,473</p>
            <p>Forks: 2,670</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>---

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://opentelemetry.io/docs/collector/getting-started/&quot;&gt;Getting Started&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md&quot;&gt;Getting Involved&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://cloud-native.slack.com/archives/C01N6P7KR6W&quot;&gt;Getting In Touch&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/actions/workflows/build-and-test.yml?query=branch%3Amain&quot;&gt;
    &lt;img alt=&quot;Build Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/open-telemetry/opentelemetry-collector-contrib/build-and-test.yml?branch=main&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector-contrib&quot;&gt;
    &lt;img alt=&quot;Go Report Card&quot; src=&quot;https://goreportcard.com/badge/github.com/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/open-telemetry/opentelemetry-collector-contrib/branch/main/&quot;&gt;
    &lt;img alt=&quot;Codecov Status&quot; src=&quot;https://img.shields.io/codecov/c/github/open-telemetry/opentelemetry-collector-contrib?style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector-contrib/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest by date including pre-releases)&quot; src=&quot;https://img.shields.io/github/v/release/open-telemetry/opentelemetry-collector-contrib?include_prereleases&amp;style=for-the-badge&quot;&gt;
  &lt;/a&gt;
  &lt;img alt=&quot;Beta&quot; src=&quot;https://img.shields.io/badge/status-beta-informational?style=for-the-badge&amp;logo=data:image/png;base64,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&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/vision.md&quot;&gt;Vision&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/observability.md&quot;&gt;Observability&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://github.com/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md&quot;&gt;Security&lt;/a&gt;
    &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
  &lt;/strong&gt;
&lt;/p&gt;

---

# OpenTelemetry Collector Contrib

This is a repository for OpenTelemetry Collector components that are not suitable for the  [core repository](https://github.com/open-telemetry/opentelemetry-collector) of the collector. 

The official distributions, core and contrib, are available as part of the [opentelemetry-collector-releases](https://github.com/open-telemetry/opentelemetry-collector-releases) repository. Some of the components in this repository are part of the &quot;core&quot; distribution, such as the Jaeger and Prometheus components, but most of the components here are only available as part of the &quot;contrib&quot; distribution. Users of the OpenTelemetry Collector are also encouraged to build their own custom distributions with the [OpenTelemetry Collector Builder](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder), using the components they need from the core repository, the contrib repository, and possibly third-party or internal repositories.

Each component has its own support levels, as defined in the following sections. For each signal that a component supports, there&#039;s a stability level, setting the right expectations. It is possible then that a component will be **Stable** for traces but **Alpha** for metrics and **Development** for logs.

## Stability levels

Stability level for components in this repository follow the [definitions](https://github.com/open-telemetry/opentelemetry-collector#stability-levels) from the OpenTelemetry Collector repository.

## Gated features

Some features are hidden behind feature gates before they are part of the main code path for the component. Note that the feature gates themselves might be at different [lifecycle stages](https://github.com/open-telemetry/opentelemetry-collector/tree/main/featuregate#feature-lifecycle).

## Support

Each component is supported either by the community of OpenTelemetry Collector Contrib maintainers, as defined by the GitHub group [@open-telemetry/collector-contrib-maintainer](https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer), or by specific vendors. See the individual README files for information about the specific components.

The OpenTelemetry Collector Contrib maintainers may at any time downgrade specific components if they are deemed unmaintained or if they pose a risk to the repository and/or binary distribution.

Even though the OpenTelemetry Collector Contrib maintainers are ultimately responsible for the components hosted here, actual support will likely be provided by individual contributors, typically a code owner for the specific component.

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md).

Triagers ([@open-telemetry/collector-contrib-triagers](https://github.com/orgs/open-telemetry/teams/collector-contrib-triagers))

- [Benedikt Bongartz](https://github.com/frzifus), Red Hat
- [Braydon Kains](https://github.com/braydonk), Google
- [Florian Bacher](https://github.com/bacherfl), Dynatrace
- [James Moessis](https://github.com/jamesmoessis), Atlassian
- [Jared Tan](https://github.com/JaredTan95), DaoCloud
- [Murphy Chen](https://github.com/Frapschen), DaoCloud
- [Paulo Janotti](https://github.com/pjanotti), Splunk
- [Vihas Makwana](https://github.com/VihasMakwana), Elastic
- Actively seeking contributors to triage issues

Emeritus Triagers:

- [Alolita Sharma](https://github.com/alolita)
- [Gabriel Aszalos](https://github.com/gbbr)
- [Goutham Veeramachaneni](https://github.com/gouthamve)
- [Punya Biswal](https://github.com/punya)
- [Steve Flanders](https://github.com/flands)

Approvers ([@open-telemetry/collector-contrib-approvers](https://github.com/orgs/open-telemetry/teams/collector-contrib-approvers)):

- [Arthur Silva Sens](https://github.com/ArthurSens), Grafana Labs
- [Christos Markou](https://github.com/ChrsMark), Elastic
- [Curtis Robert](https://github.com/crobert-1), Splunk
- [David Ashpole](https://github.com/dashpole), Google (on leave)
- [Edmo Vamerlatti Costa](https://github.com/edmocosta), Elastic
- [Matt Wear](https://github.com/mwear), Lightstep
- [Sam DeHaan](https://github.com/dehaansa), Grafana Labs
- [Ziqi Zhao](https://github.com/fatsheep9146), Alibaba

Emeritus Approvers:

- [Anthony Mirabella](https://github.com/Aneurysm9)
- [Bryan Aguilar](https://github.com/bryan-aguilar)
- [Przemek Maciolek](https://github.com/pmm-sumo)
- [Ruslan Kovalov](https://github.com/kovrus)

Maintainers ([@open-telemetry/collector-contrib-maintainer](https://github.com/orgs/open-telemetry/teams/collector-contrib-maintainer)):

- [Alex Boten](https://github.com/codeboten), Honeycomb
- [Andrzej Stencel](https://github.com/andrzej-stencel), Elastic
- [Antoine Toulme](https://github.com/atoulme), Splunk
- [Bogdan Drutu](https://github.com/bogdandrutu), Snowflake
- [Daniel Jaglowski](https://github.com/djaglowski), observIQ
- [Dmitrii Anoshin](https://github.com/dmitryax), Splunk
- [Evan Bradley](https://github.com/evan-bradley), Dynatrace
- [Juraci Paixão Kröhling](https://github.com/jpkrohling), OllyGarden
- [Pablo Baeyens](https://github.com/mx-psi), DataDog
- [Sean Marciniak](https://github.com/MovieStoreGuy), Splunk
- [Tyler Helmuth](https://github.com/TylerHelmuth), Honeycomb
- [Yang Song](https://github.com/songy23), DataDog

Emeritus Maintainers

- [Tigran Najaryan](https://github.com/tigrannajaryan)

Learn more about roles in the [community repository](https://github.com/open-telemetry/community/blob/main/guides/contributor/membership.md).

### No Over-Representation

A community member cannot be promoted to be a Collector contrib maintainer if, after their promotion, the resulting maintainers group has more than one-fourth (25%) of the members affiliated with the same employer. Job changes and similar events might result in over-representation, and no new maintainers from the same company can be promoted until representation is balanced again. In the event of confusion or concern, the OpenTelemetry Collector SIG will defer to the CNCF definition of &quot;same employer&quot;.

## PRs and Reviews

When creating a PR please follow the process [described
here](https://github.com/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md#how-to-structure-prs-to-get-expedient-reviews).

New PRs will be automatically associated with the reviewers based on
[CODEOWNERS](.github/CODEOWNERS). PRs will be also automatically assigned to one of the
maintainers or approvers for facilitation.

The facilitator is responsible for helping the PR author and reviewers to make progress
or if progress cannot be made for closing the PR.

If the reviewers do not have approval rights the facilitator is also responsible
for the official approval that is required for the PR to be merged and if the facilitator
is a maintainer they are responsible for merging the PR as well.

The facilitator is not required to perform a thorough review, but they are encouraged to
enforce Collector best practices and consistency across the codebase and component
behavior. The facilitators will typically rely on codeowner&#039;s detailed review of the code
when making the final approval decision. 
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mikefarah/yq]]></title>
            <link>https://github.com/mikefarah/yq</link>
            <guid>https://github.com/mikefarah/yq</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[yq is a portable command-line YAML, JSON, XML, CSV, TOML and properties processor]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mikefarah/yq">mikefarah/yq</a></h1>
            <p>yq is a portable command-line YAML, JSON, XML, CSV, TOML and properties processor</p>
            <p>Language: Go</p>
            <p>Stars: 13,155</p>
            <p>Forks: 637</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre># yq

![Build](https://github.com/mikefarah/yq/workflows/Build/badge.svg)  ![Docker Pulls](https://img.shields.io/docker/pulls/mikefarah/yq.svg) ![Github Releases (by Release)](https://img.shields.io/github/downloads/mikefarah/yq/total.svg) ![Go Report](https://goreportcard.com/badge/github.com/mikefarah/yq) ![CodeQL](https://github.com/mikefarah/yq/workflows/CodeQL/badge.svg)


a lightweight and portable command-line YAML, JSON and XML processor. `yq` uses [jq](https://github.com/stedolan/jq) like syntax but works with yaml files as well as json, xml, properties, csv and tsv. It doesn&#039;t yet support everything `jq` does - but it does support the most common operations and functions, and more is being added continuously.

yq is written in go - so you can download a dependency free binary for your platform and you are good to go! If you prefer there are a variety of package managers that can be used as well as Docker and Podman, all listed below.

## Quick Usage Guide

Read a value:
```bash
yq &#039;.a.b[0].c&#039; file.yaml
```

Pipe from STDIN:
```bash
yq &#039;.a.b[0].c&#039; &lt; file.yaml
```

Update a yaml file, in place
```bash
yq -i &#039;.a.b[0].c = &quot;cool&quot;&#039; file.yaml
```

Update using environment variables
```bash
NAME=mike yq -i &#039;.a.b[0].c = strenv(NAME)&#039; file.yaml
```

Merge multiple files
```bash
# merge two files
yq -n &#039;load(&quot;file1.yaml&quot;) * load(&quot;file2.yaml&quot;)&#039;

# merge using globs:
# note the use of `ea` to evaluate all the files at once
# instead of in sequence
yq ea &#039;. as $item ireduce ({}; . * $item )&#039; path/to/*.yml
```

Multiple updates to a yaml file
```bash
yq -i &#039;
  .a.b[0].c = &quot;cool&quot; |
  .x.y.z = &quot;foobar&quot; |
  .person.name = strenv(NAME)
&#039; file.yaml
```

Find and update an item in an array:
```bash
yq &#039;(.[] | select(.name == &quot;foo&quot;) | .address) = &quot;12 cat st&quot;&#039;
```

Convert JSON to YAML
```bash
yq -Poy sample.json
```

See [recipes](https://mikefarah.gitbook.io/yq/recipes) for more examples and the [documentation](https://mikefarah.gitbook.io/yq/) for more information.

Take a look at the discussions for [common questions](https://github.com/mikefarah/yq/discussions/categories/q-a), and [cool ideas](https://github.com/mikefarah/yq/discussions/categories/show-and-tell)

## Install

### [Download the latest binary](https://github.com/mikefarah/yq/releases/latest)

### wget
Use wget to download, gzipped pre-compiled binaries:


For instance, VERSION=v4.2.0 and BINARY=yq_linux_amd64

#### Compressed via tar.gz
```bash
wget https://github.com/mikefarah/yq/releases/download/${VERSION}/${BINARY}.tar.gz -O - |\
  tar xz &amp;&amp; mv ${BINARY} /usr/bin/yq
```

#### Plain binary

```bash
wget https://github.com/mikefarah/yq/releases/download/${VERSION}/${BINARY} -O /usr/bin/yq &amp;&amp;\
    chmod +x /usr/bin/yq
```

#### Latest version

```bash
wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/bin/yq &amp;&amp;\
    chmod +x /usr/bin/yq
```

### MacOS / Linux via Homebrew:
Using [Homebrew](https://brew.sh/)
```
brew install yq
```

### Linux via snap:
```
snap install yq
```

#### Snap notes
`yq` installs with [_strict confinement_](https://docs.snapcraft.io/snap-confinement/6233) in snap, this means it doesn&#039;t have direct access to root files. To read root files you can:

```
sudo cat /etc/myfile | yq &#039;.a.path&#039;
```

And to write to a root file you can either use [sponge](https://linux.die.net/man/1/sponge):
```
sudo cat /etc/myfile | yq &#039;.a.path = &quot;value&quot;&#039; | sudo sponge /etc/myfile
```
or write to a temporary file:
```
sudo cat /etc/myfile | yq &#039;.a.path = &quot;value&quot;&#039; | sudo tee /etc/myfile.tmp
sudo mv /etc/myfile.tmp /etc/myfile
rm /etc/myfile.tmp
```

### Run with Docker or Podman
#### Oneshot use:

```bash
docker run --rm -v &quot;${PWD}&quot;:/workdir mikefarah/yq [command] [flags] [expression ]FILE...
```

Note that you can run `yq` in docker without network access and other privileges if you desire,
namely `--security-opt=no-new-privileges --cap-drop all --network none`.

```bash
podman run --rm -v &quot;${PWD}&quot;:/workdir mikefarah/yq [command] [flags] [expression ]FILE...
```

#### Pipe in via STDIN:

You&#039;ll need to pass the `-i\--interactive` flag to docker:

```bash
docker run -i --rm mikefarah/yq &#039;.this.thing&#039; &lt; myfile.yml
```

```bash
podman run -i --rm mikefarah/yq &#039;.this.thing&#039; &lt; myfile.yml
```

#### Run commands interactively:

```bash
docker run --rm -it -v &quot;${PWD}&quot;:/workdir --entrypoint sh mikefarah/yq
```

```bash
podman run --rm -it -v &quot;${PWD}&quot;:/workdir --entrypoint sh mikefarah/yq
```

It can be useful to have a bash function to avoid typing the whole docker command:

```bash
yq() {
  docker run --rm -i -v &quot;${PWD}&quot;:/workdir mikefarah/yq &quot;$@&quot;
}
```

```bash
yq() {
  podman run --rm -i -v &quot;${PWD}&quot;:/workdir mikefarah/yq &quot;$@&quot;
}
```
#### Running as root:

`yq`&#039;s container image no longer runs under root (https://github.com/mikefarah/yq/pull/860). If you&#039;d like to install more things in the container image, or you&#039;re having permissions issues when attempting to read/write files you&#039;ll need to either:


```
docker run --user=&quot;root&quot; -it --entrypoint sh mikefarah/yq
```

```
podman run --user=&quot;root&quot; -it --entrypoint sh mikefarah/yq
```

Or, in your Dockerfile:

```
FROM mikefarah/yq

USER root
RUN apk add --no-cache bash
USER yq
```

#### Missing timezone data
By default, the alpine image yq uses does not include timezone data. If you&#039;d like to use the `tz` operator, you&#039;ll need to include this data:

```
FROM mikefarah/yq

USER root
RUN apk add --no-cache tzdata
USER yq
```

#### Podman with SELinux

If you are using podman with SELinux, you will need to set the shared volume flag `:z` on the volume mount:

```
-v &quot;${PWD}&quot;:/workdir:z
```

### GitHub Action
```
  - name: Set foobar to cool
    uses: mikefarah/yq@master
    with:
      cmd: yq -i &#039;.foo.bar = &quot;cool&quot;&#039; &#039;config.yml&#039;
  - name: Get an entry with a variable that might contain dots or spaces
    id: get_username
    uses: mikefarah/yq@master
    with:
      cmd: yq &#039;.all.children.[&quot;${{ matrix.ip_address }}&quot;].username&#039; ops/inventories/production.yml
  - name: Reuse a variable obtained in another step
    run: echo ${{ steps.get_username.outputs.result }}
```

See https://mikefarah.gitbook.io/yq/usage/github-action for more.

### Go Install:
```
go install github.com/mikefarah/yq/v4@latest
```

## Community Supported Installation methods
As these are supported by the community :heart: - however, they may be out of date with the officially supported releases.

_Please note that the Debian package (previously supported by @rmescandon) is no longer maintained. Please use an alternative installation method._


### X-CMD
Checkout `yq` on x-cmd: https://x-cmd.com/mod/yq

- Instant Results: See the output of your yq filter in real-time.
- Error Handling: Encounter a syntax error? It will display the error message and the results of the closest valid filter

Thanks @edwinjhlee!

### Nix

```
nix profile install nixpkgs#yq-go
```

See [here](https://search.nixos.org/packages?channel=unstable&amp;show=yq-go&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=yq-go)


### Webi

```
webi yq
```

See [webi](https://webinstall.dev/)
Supported by @adithyasunil26 (https://github.com/webinstall/webi-installers/tree/master/yq)

### Arch Linux

```
pacman -S go-yq
```

### Windows:

Using [Chocolatey](https://chocolatey.org)

[![Chocolatey](https://img.shields.io/chocolatey/v/yq.svg)](https://chocolatey.org/packages/yq)
[![Chocolatey](https://img.shields.io/chocolatey/dt/yq.svg)](https://chocolatey.org/packages/yq)
```
choco install yq
```
Supported by @chillum (https://chocolatey.org/packages/yq)

Using [scoop](https://scoop.sh/)
```
scoop install main/yq
```

Using [winget](https://learn.microsoft.com/en-us/windows/package-manager/)
```
winget install --id MikeFarah.yq
```

### Mac:
Using [MacPorts](https://www.macports.org/)
```
sudo port selfupdate
sudo port install yq
```
Supported by @herbygillot (https://ports.macports.org/maintainer/github/herbygillot)

### Alpine Linux

Alpine Linux v3.20+ (and Edge):
```
apk add yq-go
```

Alpine Linux up to v3.19:
```
apk add yq
```

Supported by Tuan Hoang (https://pkgs.alpinelinux.org/packages?name=yq-go)

### Flox:

Flox can be used to install yq on Linux, MacOS, and Windows through WSL.

```
flox install yq
```

## Features
- [Detailed documentation with many examples](https://mikefarah.gitbook.io/yq/)
- Written in portable go, so you can download a lovely dependency free binary
- Uses similar syntax as `jq` but works with YAML, [JSON](https://mikefarah.gitbook.io/yq/usage/convert) and [XML](https://mikefarah.gitbook.io/yq/usage/xml) files
- Fully supports multi document yaml files
- Supports yaml [front matter](https://mikefarah.gitbook.io/yq/usage/front-matter) blocks (e.g. jekyll/assemble)
- Colorized yaml output
- [Date/Time manipulation and formatting with TZ](https://mikefarah.gitbook.io/yq/operators/datetime)
- [Deeply data structures](https://mikefarah.gitbook.io/yq/operators/traverse-read)
- [Sort keys](https://mikefarah.gitbook.io/yq/operators/sort-keys)
- Manipulate yaml [comments](https://mikefarah.gitbook.io/yq/operators/comment-operators), [styling](https://mikefarah.gitbook.io/yq/operators/style), [tags](https://mikefarah.gitbook.io/yq/operators/tag) and [anchors and aliases](https://mikefarah.gitbook.io/yq/operators/anchor-and-alias-operators).
- [Update in place](https://mikefarah.gitbook.io/yq/v/v4.x/commands/evaluate#flags)
- [Complex expressions to select and update](https://mikefarah.gitbook.io/yq/operators/select#select-and-update-matching-values-in-map)
- Keeps yaml formatting and comments when updating (though there are issues with whitespace)
- [Decode/Encode base64 data](https://mikefarah.gitbook.io/yq/operators/encode-decode)
- [Load content from other files](https://mikefarah.gitbook.io/yq/operators/load)
- [Convert to/from json/ndjson](https://mikefarah.gitbook.io/yq/v/v4.x/usage/convert)
- [Convert to/from xml](https://mikefarah.gitbook.io/yq/v/v4.x/usage/xml)
- [Convert to/from properties](https://mikefarah.gitbook.io/yq/v/v4.x/usage/properties)
- [Convert to/from csv/tsv](https://mikefarah.gitbook.io/yq/usage/csv-tsv)
- [General shell completion scripts (bash/zsh/fish/powershell)](https://mikefarah.gitbook.io/yq/v/v4.x/commands/shell-completion)
- [Reduce](https://mikefarah.gitbook.io/yq/operators/reduce) to merge multiple files or sum an array or other fancy things.
- [Github Action](https://mikefarah.gitbook.io/yq/usage/github-action) to use in your automated pipeline (thanks @devorbitus)

## [Usage](https://mikefarah.gitbook.io/yq/)

Check out the [documentation](https://mikefarah.gitbook.io/yq/) for more detailed and advanced usage.

```
Usage:
  yq [flags]
  yq [command]

Examples:

# yq defaults to &#039;eval&#039; command if no command is specified. See &quot;yq eval --help&quot; for more examples.
yq &#039;.stuff&#039; &lt; myfile.yml # outputs the data at the &quot;stuff&quot; node from &quot;myfile.yml&quot;

yq -i &#039;.stuff = &quot;foo&quot;&#039; myfile.yml # update myfile.yml in place


Available Commands:
  completion       Generate the autocompletion script for the specified shell
  eval             (default) Apply the expression to each document in each yaml file in sequence
  eval-all         Loads _all_ yaml documents of _all_ yaml files and runs expression once
  help             Help about any command

Flags:
  -C, --colors                        force print with colors
  -e, --exit-status                   set exit status if there are no matches or null or false is returned
  -f, --front-matter string           (extract|process) first input as yaml front-matter. Extract will pull out the yaml content, process will run the expression against the yaml content, leaving the remaining data intact
      --header-preprocess             Slurp any header comments and separators before processing expression. (default true)
  -h, --help                          help for yq
  -I, --indent int                    sets indent level for output (default 2)
  -i, --inplace                       update the file in place of first file given.
  -p, --input-format string           [yaml|y|xml|x] parse format for input. Note that json is a subset of yaml. (default &quot;yaml&quot;)
  -M, --no-colors                     force print with no colors
  -N, --no-doc                        Don&#039;t print document separators (---)
  -n, --null-input                    Don&#039;t read input, simply evaluate the expression given. Useful for creating docs from scratch.
  -o, --output-format string          [yaml|y|json|j|props|p|xml|x] output format type. (default &quot;yaml&quot;)
  -P, --prettyPrint                   pretty print, shorthand for &#039;... style = &quot;&quot;&#039;
  -s, --split-exp string              print each result (or doc) into a file named (exp). [exp] argument must return a string. You can use $index in the expression as the result counter.
      --unwrapScalar                  unwrap scalar, print the value with no quotes, colors or comments (default true)
  -v, --verbose                       verbose mode
  -V, --version                       Print version information and quit
      --xml-attribute-prefix string   prefix for xml attributes (default &quot;+&quot;)
      --xml-content-name string       name for xml content (if no attribute name is present). (default &quot;+content&quot;)

Use &quot;yq [command] --help&quot; for more information about a command.
```
## Known Issues / Missing Features
- `yq` attempts to preserve comment positions and whitespace as much as possible, but it does not handle all scenarios (see https://github.com/go-yaml/yaml/tree/v3 for details)
- Powershell has its own...[opinions on quoting yq](https://mikefarah.gitbook.io/yq/usage/tips-and-tricks#quotes-in-windows-powershell)
- &quot;yes&quot;, &quot;no&quot; were dropped as boolean values in the yaml 1.2 standard - which is the standard yq assumes.

See [tips and tricks](https://mikefarah.gitbook.io/yq/usage/tips-and-tricks) for more common problems and solutions.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[go-git/go-git]]></title>
            <link>https://github.com/go-git/go-git</link>
            <guid>https://github.com/go-git/go-git</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[A highly extensible Git implementation in pure Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/go-git/go-git">go-git/go-git</a></h1>
            <p>A highly extensible Git implementation in pure Go.</p>
            <p>Language: Go</p>
            <p>Stars: 6,387</p>
            <p>Forks: 774</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>![go-git logo](https://cdn.rawgit.com/src-d/artwork/02036484/go-git/files/go-git-github-readme-header.png)
[![GoDoc](https://godoc.org/github.com/go-git/go-git/v5?status.svg)](https://pkg.go.dev/github.com/go-git/go-git/v5) [![Build Status](https://github.com/go-git/go-git/workflows/Test/badge.svg)](https://github.com/go-git/go-git/actions) [![Go Report Card](https://goreportcard.com/badge/github.com/go-git/go-git)](https://goreportcard.com/report/github.com/go-git/go-git)

*go-git* is a highly extensible git implementation library written in **pure Go**.

It can be used to manipulate git repositories at low level *(plumbing)* or high level *(porcelain)*, through an idiomatic Go API. It also supports several types of storage, such as in-memory filesystems, or custom implementations, thanks to the [`Storer`](https://pkg.go.dev/github.com/go-git/go-git/v5/plumbing/storer) interface.

It&#039;s being actively developed since 2015 and is being used extensively by [Keybase](https://keybase.io/blog/encrypted-git-for-everyone), [Gitea](https://gitea.io/en-us/) or [Pulumi](https://github.com/search?q=org%3Apulumi+go-git&amp;type=Code), and by many other libraries and tools.

Project Status
--------------

After the [legal issues](https://github.com/src-d/go-git/issues/1295#issuecomment-592965250) with the [`src-d`](https://github.com/src-d) organization, the lack of update for four months and the requirement to make a hard fork, the project is **now back to normality**.

The project is currently actively maintained by individual contributors, including several of the original authors, but also backed by a new company, [gitsight](https://github.com/gitsight), where `go-git` is a critical component used at scale.


Comparison with git
-------------------

*go-git* aims to be fully compatible with [git](https://github.com/git/git), all the *porcelain* operations are implemented to work exactly as *git* does.

*git* is a humongous project with years of development by thousands of contributors, making it challenging for *go-git* to implement all the features. You can find a comparison of *go-git* vs *git* in the [compatibility documentation](COMPATIBILITY.md).


Installation
------------

The recommended way to install *go-git* is:

```go
import &quot;github.com/go-git/go-git/v5&quot; // with go modules enabled (GO111MODULE=on or outside GOPATH)
import &quot;github.com/go-git/go-git&quot; // with go modules disabled
```


Examples
--------

&gt; Please note that the `CheckIfError` and `Info` functions  used in the examples are from the [examples package](https://github.com/go-git/go-git/blob/master/_examples/common.go#L19) just to be used in the examples.


### Basic example

A basic example that mimics the standard `git clone` command

```go
// Clone the given repository to the given directory
Info(&quot;git clone https://github.com/go-git/go-git&quot;)

_, err := git.PlainClone(&quot;/tmp/foo&quot;, false, &amp;git.CloneOptions{
    URL:      &quot;https://github.com/go-git/go-git&quot;,
    Progress: os.Stdout,
})

CheckIfError(err)
```

Outputs:
```
Counting objects: 4924, done.
Compressing objects: 100% (1333/1333), done.
Total 4924 (delta 530), reused 6 (delta 6), pack-reused 3533
```

### In-memory example

Cloning a repository into memory and printing the history of HEAD, just like `git log` does


```go
// Clones the given repository in memory, creating the remote, the local
// branches and fetching the objects, exactly as:
Info(&quot;git clone https://github.com/go-git/go-billy&quot;)

r, err := git.Clone(memory.NewStorage(), nil, &amp;git.CloneOptions{
    URL: &quot;https://github.com/go-git/go-billy&quot;,
})

CheckIfError(err)

// Gets the HEAD history from HEAD, just like this command:
Info(&quot;git log&quot;)

// ... retrieves the branch pointed by HEAD
ref, err := r.Head()
CheckIfError(err)


// ... retrieves the commit history
cIter, err := r.Log(&amp;git.LogOptions{From: ref.Hash()})
CheckIfError(err)

// ... just iterates over the commits, printing it
err = cIter.ForEach(func(c *object.Commit) error {
	fmt.Println(c)
	return nil
})
CheckIfError(err)
```

Outputs:
```
commit ded8054fd0c3994453e9c8aacaf48d118d42991e
Author: Santiago M. Mola &lt;santi@mola.io&gt;
Date:   Sat Nov 12 21:18:41 2016 +0100

    index: ReadFrom/WriteTo returns IndexReadError/IndexWriteError. (#9)

commit df707095626f384ce2dc1a83b30f9a21d69b9dfc
Author: Santiago M. Mola &lt;santi@mola.io&gt;
Date:   Fri Nov 11 13:23:22 2016 +0100

    readwriter: fix bug when writing index. (#10)

    When using ReadWriter on an existing siva file, absolute offset for
    index entries was not being calculated correctly.
...
```

You can find this [example](_examples/log/main.go) and many others in the [examples](_examples) folder.

Contribute
----------

[Contributions](https://github.com/go-git/go-git/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22) are more than welcome, if you are interested please take a look to
our [Contributing Guidelines](CONTRIBUTING.md).

License
-------
Apache License Version 2.0, see [LICENSE](LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[krillinai/KrillinAI]]></title>
            <link>https://github.com/krillinai/KrillinAI</link>
            <guid>https://github.com/krillinai/KrillinAI</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[A video translation and dubbing tool powered by LLMs, offering professional-grade translations and one-click full-process deployment. It can generate content optimized for platforms like YouTube，TikTok, and Shorts. 基于AI大模型的视频翻译和配音工具，专业级翻译，一键部署全流程，可以生成适配抖音，小红书，哔哩哔哩，视频号，TikTok，Youtube Shorts等形态的内容]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/krillinai/KrillinAI">krillinai/KrillinAI</a></h1>
            <p>A video translation and dubbing tool powered by LLMs, offering professional-grade translations and one-click full-process deployment. It can generate content optimized for platforms like YouTube，TikTok, and Shorts. 基于AI大模型的视频翻译和配音工具，专业级翻译，一键部署全流程，可以生成适配抖音，小红书，哔哩哔哩，视频号，TikTok，Youtube Shorts等形态的内容</p>
            <p>Language: Go</p>
            <p>Stars: 1,373</p>
            <p>Forks: 121</p>
            <p>Stars today: 238 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/logo.png&quot; alt=&quot;KrillinAI&quot; height=&quot;90&quot;&gt;


  # AI Audio&amp;Video Translation and Dubbing Tool

&lt;a href=&quot;https://trendshift.io/repositories/13360&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13360&quot; alt=&quot;krillinai%2FKrillinAI | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

  **[English](./README.md) | [简体中文](./docs/README_zh.md) |[日本語](./docs/README_jp.md)｜[한국어](./docs/README_kr.md)｜[Русский](./docs/README_rus.md)**

  [![Twitter](https://img.shields.io/badge/Twitter-KrillinAI-orange?logo=twitter)](https://x.com/KrillinAI)
[![Bilibili](https://img.shields.io/badge/dynamic/json?label=Bilibili&amp;query=%24.data.follower&amp;suffix=%20followers&amp;url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Frelation%2Fstat%3Fvmid%3D242124650&amp;logo=bilibili&amp;color=00A1D6&amp;labelColor=FE7398&amp;logoColor=FFFFFF)](https://space.bilibili.com/242124650)
[![QQ 群](https://img.shields.io/badge/QQ%20群-754069680-green?logo=tencent-qq)](https://jq.qq.com/?_wv=1027&amp;k=754069680)

&lt;/div&gt;

### 📢 New Release for Win &amp; Mac Desktop Version – Welcome to Test and Provide Feedback

## Overview

Krillin AI is an all-in-one solution for effortless video localization and enhancement. This minimalist yet powerful tool handles everything from translation, dubbing to voice cloning，formatting—seamlessly converting videos between landscape and portrait modes for optimal display across all content platforms(YouTube, TikTok, Bilibili, Douyin, WeChat Channel, RedNote, Kuaishou). With its end-to-end workflow, Krillin AI transforms raw footage into polished, platform-ready content in just a few clicks.

## Key Features:
🎯 **One-Click Start** - Launch your workflow instantly,New desktop version available—easier to use!

📥 **Video download** - yt-dlp and local file uploading supported

📜 **Precise Subtitles** - Whisper-powered high-accuracy recognition

🧠 **Smart Segmentation** - LLM-based subtitle chunking &amp; alignment

🌍 **Professional Translation** - Paragraph-level translation for consistency 

🔄 **Term Replacement** - One-click domain-specific vocabulary swap 

🎙️ **Dubbing and Voice Cloning** - CosyVoice selected or cloning voices

🎬 **Video Composition** - Auto-formatting for horizontal/vertical layouts

## Showcase
The following picture demonstrates the effect after the subtitle file, which was generated through a one-click operation after importing a 46-minute local video, was inserted into the track. There was no manual adjustment involved at all. There are no missing or overlapping subtitles, the sentence segmentation is natural, and the translation quality is also quite high.
![Alignment](./docs/images/alignment.png)

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;33%&quot;&gt;

### Subtitle Translation
---
https://github.com/user-attachments/assets/bba1ac0a-fe6b-4947-b58d-ba99306d0339

&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;

### Dubbing
---
https://github.com/user-attachments/assets/0b32fad3-c3ad-4b6a-abf0-0865f0dd2385

&lt;/td&gt;

&lt;td width=&quot;33%&quot;&gt;

### Portrait
---
https://github.com/user-attachments/assets/c2c7b528-0ef8-4ba9-b8ac-f9f92f6d4e71

&lt;/td&gt;

&lt;/tr&gt;
&lt;/table&gt;

## 🌍 Language Support
Input languages: Chinese, English, Japanese, German, Turkish supported (more languages being added)  
Translation languages: 56 languages supported, including English, Chinese, Russian, Spanish, French, etc.

## Interface Preview
![ui preview](./docs/images/ui_desktop.png)

## 🚀 Quick Start
### Basic Steps
First, download the Release executable file that matches your device&#039;s system. Follow the instructions below to choose between the desktop or non-desktop version, then place the software in an empty folder. Running the program will generate some directories, so keeping it in an empty folder makes management easier.

[For the desktop version (release files with &quot;desktop&quot; in the name), refer here]  
_The desktop version is newly released to address the difficulty beginners face in editing configuration files correctly. It still has some bugs and is being continuously updated._  

Double-click the file to start using it.

[For the non-desktop version (release files without &quot;desktop&quot; in the name), refer here]  
_The non-desktop version is the original release, with more complex configuration but stable functionality. It is also suitable for server deployment, as it provides a web-based UI._  

Create a `config` folder in the directory, then create a `config.toml` file inside it. Copy the contents of the `config-example.toml` file from the source code&#039;s `config` directory into your `config.toml` and fill in your configuration details. (If you want to use OpenAI models but don’t know how to get a key, you can join the group for free trial access.)

Double-click the executable or run it in the terminal to start the service.

Open your browser and enter http://127.0.0.1:8888 to begin using it. (Replace 8888 with the port number you specified in the config file.)

### To: macOS Users
[For the desktop version, i.e., release files with &quot;desktop&quot; in the name, refer here]  
The current packaging method for the desktop version cannot support direct double-click execution or DMG installation due to signing issues. Manual trust configuration is required as follows:

1. Open the directory containing the executable file (assuming the filename is KrillinAI_1.0.0_desktop_macOS_arm64) in Terminal

2. Execute the following commands sequentially:

```
sudo xattr -cr ./KrillinAI_1.0.0_desktop_macOS_arm64  
sudo chmod +x ./KrillinAI_1.0.0_desktop_macOS_arm64  
./KrillinAI_1.0.0_desktop_macOS_arm64  
```

[For the non-desktop version, i.e., release files without &quot;desktop&quot; in the name, refer here]  
This software is not signed, so after completing the file configuration in the &quot;Basic Steps,&quot; you will need to manually trust the application on macOS. Follow these steps:
1. Open the terminal and navigate to the directory where the executable file (assuming the file name is `KrillinAI_1.0.0_macOS_arm64`) is located.
2. Execute the following commands in sequence:
```
sudo xattr -rd com.apple.quarantine ./KrillinAI_1.0.0_macOS_arm64
sudo chmod +x ./KrillinAI_1.0.0_macOS_arm64
./KrillinAI_1.0.0_macOS_arm64
```
This will start the service.

### Docker Deployment
This project supports Docker deployment. Please refer to the [Docker Deployment Instructions](./docs/docker.md).

### Cookie Configuration Instructions

If you encounter video download failures, please refer to the [Cookie Configuration Instructions](./docs/get_cookies.md) to configure your cookie information.

### Configuration Help
The quickest and most convenient configuration method:
* Select `openai` for both `transcription_provider` and `llm_provider`. In this way, you only need to fill in `openai.apikey` in the following three major configuration item categories, namely `openai`, `local_model`, and `aliyun`, and then you can conduct subtitle translation. (Fill in `app.proxy`, `model` and `openai.base_url` as per your own situation.)

The configuration method for using the local speech recognition model (macOS is not supported for the time being) (a choice that takes into account cost, speed, and quality):
* Fill in `fasterwhisper` for `transcription_provider` and `openai` for `llm_provider`. In this way, you only need to fill in `openai.apikey` and `local_model.faster_whisper` in the following three major configuration item categories, namely `openai` and `local_model`, and then you can conduct subtitle translation. The local model will be downloaded automatically. (The same applies to `app.proxy` and `openai.base_url` as mentioned above.)

The following usage situations require the configuration of Alibaba Cloud:
* If `llm_provider` is filled with `aliyun`, it indicates that the large model service of Alibaba Cloud will be used. Consequently, the configuration of the `aliyun.bailian` item needs to be set up.
* If `transcription_provider` is filled with `aliyun`, or if the &quot;voice dubbing&quot; function is enabled when starting a task, the voice service of Alibaba Cloud will be utilized. Therefore, the configuration of the `aliyun.speech` item needs to be filled in.
* If the &quot;voice dubbing&quot; function is enabled and local audio files are uploaded for voice timbre cloning at the same time, the OSS cloud storage service of Alibaba Cloud will also be used. Hence, the configuration of the `aliyun.oss` item needs to be filled in.
Configuration Guide: [Alibaba Cloud Configuration Instructions](./docs/aliyun.md)

## Frequently Asked Questions
Please refer to [Frequently Asked Questions](./docs/faq.md)

## Contribution Guidelines

- Do not submit unnecessary files like `.vscode`, `.idea`, etc. Please make good use of `.gitignore` to filter them.
- Do not submit `config.toml`; instead, submit `config-example.toml`.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=krillinai/KrillinAI&amp;type=Date)](https://star-history.com/#krillinai/KrillinAI&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[caddyserver/caddy]]></title>
            <link>https://github.com/caddyserver/caddy</link>
            <guid>https://github.com/caddyserver/caddy</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Fast and extensible multi-platform HTTP/1-2-3 web server with automatic HTTPS]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/caddyserver/caddy">caddyserver/caddy</a></h1>
            <p>Fast and extensible multi-platform HTTP/1-2-3 web server with automatic HTTPS</p>
            <p>Language: Go</p>
            <p>Stars: 62,875</p>
            <p>Forks: 4,231</p>
            <p>Stars today: 110 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://caddyserver.com&quot;&gt;
		&lt;picture&gt;
			&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://user-images.githubusercontent.com/1128849/210187358-e2c39003-9a5e-4dd5-a783-6deb6483ee72.svg&quot;&gt;
			&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://user-images.githubusercontent.com/1128849/210187356-dfb7f1c5-ac2e-43aa-bb23-fc014280ae1f.svg&quot;&gt;
			&lt;img src=&quot;https://user-images.githubusercontent.com/1128849/210187356-dfb7f1c5-ac2e-43aa-bb23-fc014280ae1f.svg&quot; alt=&quot;Caddy&quot; width=&quot;550&quot;&gt;
		&lt;/picture&gt;
	&lt;/a&gt;
	&lt;br&gt;
	&lt;h3 align=&quot;center&quot;&gt;a &lt;a href=&quot;https://zerossl.com&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/55066419/208327323-2770dc16-ec09-43a0-9035-c5b872c2ad7f.svg&quot; height=&quot;28&quot; style=&quot;vertical-align: -7.7px&quot; valign=&quot;middle&quot;&gt;&lt;/a&gt; project&lt;/h3&gt;
&lt;/p&gt;
&lt;hr&gt;
&lt;h3 align=&quot;center&quot;&gt;Every site on HTTPS&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;Caddy is an extensible server platform that uses TLS by default.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://github.com/caddyserver/caddy/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://github.com/caddyserver/caddy/actions/workflows/ci.yml/badge.svg&quot;&gt;&lt;/a&gt;
	&lt;a href=&quot;https://pkg.go.dev/github.com/caddyserver/caddy/v2&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/godoc-reference-%23007d9c.svg&quot;&gt;&lt;/a&gt;
	&lt;br&gt;
	&lt;a href=&quot;https://x.com/caddyserver&quot; title=&quot;@caddyserver on Twitter&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/caddyserver&quot; alt=&quot;@caddyserver on Twitter&quot;&gt;&lt;/a&gt;
	&lt;a href=&quot;https://caddy.community&quot; title=&quot;Caddy Forum&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/community-forum-ff69b4.svg&quot; alt=&quot;Caddy Forum&quot;&gt;&lt;/a&gt;
	&lt;br&gt;
	&lt;a href=&quot;https://sourcegraph.com/github.com/caddyserver/caddy?badge&quot; title=&quot;Caddy on Sourcegraph&quot;&gt;&lt;img src=&quot;https://sourcegraph.com/github.com/caddyserver/caddy/-/badge.svg&quot; alt=&quot;Caddy on Sourcegraph&quot;&gt;&lt;/a&gt;
	&lt;a href=&quot;https://cloudsmith.io/~caddy/repos/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/OSS%20hosting%20by-cloudsmith-blue?logo=cloudsmith&quot; alt=&quot;Cloudsmith&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://github.com/caddyserver/caddy/releases&quot;&gt;Releases&lt;/a&gt; ·
	&lt;a href=&quot;https://caddyserver.com/docs/&quot;&gt;Documentation&lt;/a&gt; ·
	&lt;a href=&quot;https://caddy.community&quot;&gt;Get Help&lt;/a&gt;
&lt;/p&gt;



### Menu

- [Features](#features)
- [Install](#install)
- [Build from source](#build-from-source)
	- [For development](#for-development)
	- [With version information and/or plugins](#with-version-information-andor-plugins)
- [Quick start](#quick-start)
- [Overview](#overview)
- [Full documentation](#full-documentation)
- [Getting help](#getting-help)
- [About](#about)

&lt;p align=&quot;center&quot;&gt;
	&lt;b&gt;Powered by&lt;/b&gt;
	&lt;br&gt;
	&lt;a href=&quot;https://github.com/caddyserver/certmagic&quot;&gt;
		&lt;picture&gt;
			&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://user-images.githubusercontent.com/55066419/206946718-740b6371-3df3-4d72-a822-47e4c48af999.png&quot;&gt;
			&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://user-images.githubusercontent.com/1128849/49704830-49d37200-fbd5-11e8-8385-767e0cd033c3.png&quot;&gt;
			&lt;img src=&quot;https://user-images.githubusercontent.com/1128849/49704830-49d37200-fbd5-11e8-8385-767e0cd033c3.png&quot; alt=&quot;CertMagic&quot; width=&quot;250&quot;&gt;
		&lt;/picture&gt;
	&lt;/a&gt;
&lt;/p&gt;


## [Features](https://caddyserver.com/features)

- **Easy configuration** with the [Caddyfile](https://caddyserver.com/docs/caddyfile)
- **Powerful configuration** with its [native JSON config](https://caddyserver.com/docs/json/)
- **Dynamic configuration** with the [JSON API](https://caddyserver.com/docs/api)
- [**Config adapters**](https://caddyserver.com/docs/config-adapters) if you don&#039;t like JSON
- **Automatic HTTPS** by default
	- [ZeroSSL](https://zerossl.com) and [Let&#039;s Encrypt](https://letsencrypt.org) for public names
	- Fully-managed local CA for internal names &amp; IPs
	- Can coordinate with other Caddy instances in a cluster
	- Multi-issuer fallback
	- Encrypted ClientHello (ECH) support
- **Stays up when other servers go down** due to TLS/OCSP/certificate-related issues
- **Production-ready** after serving trillions of requests and managing millions of TLS certificates
- **Scales to hundreds of thousands of sites** as proven in production
- **HTTP/1.1, HTTP/2, and HTTP/3** all supported by default
- **Highly extensible** [modular architecture](https://caddyserver.com/docs/architecture) lets Caddy do anything without bloat
- **Runs anywhere** with **no external dependencies** (not even libc)
- Written in Go, a language with higher **memory safety guarantees** than other servers
- Actually **fun to use**
- So much more to [discover](https://caddyserver.com/features)

## Install

The simplest, cross-platform way to get started is to download Caddy from [GitHub Releases](https://github.com/caddyserver/caddy/releases) and place the executable file in your PATH.

See [our online documentation](https://caddyserver.com/docs/install) for other install instructions.

## Build from source

Requirements:

- [Go 1.24.0 or newer](https://golang.org/dl/)

### For development

_**Note:** These steps [will not embed proper version information](https://github.com/golang/go/issues/29228). For that, please follow the instructions in the next section._

```bash
$ git clone &quot;https://github.com/caddyserver/caddy.git&quot;
$ cd caddy/cmd/caddy/
$ go build
```

When you run Caddy, it may try to bind to low ports unless otherwise specified in your config. If your OS requires elevated privileges for this, you will need to give your new binary permission to do so. On Linux, this can be done easily with: `sudo setcap cap_net_bind_service=+ep ./caddy`

If you prefer to use `go run` which only creates temporary binaries, you can still do this with the included `setcap.sh` like so:

```bash
$ go run -exec ./setcap.sh main.go
```

If you don&#039;t want to type your password for `setcap`, use `sudo visudo` to edit your sudoers file and allow your user account to run that command without a password, for example:

```
username ALL=(ALL:ALL) NOPASSWD: /usr/sbin/setcap
```

replacing `username` with your actual username. Please be careful and only do this if you know what you are doing! We are only qualified to document how to use Caddy, not Go tooling or your computer, and we are providing these instructions for convenience only; please learn how to use your own computer at your own risk and make any needful adjustments.

### With version information and/or plugins

Using [our builder tool, `xcaddy`](https://github.com/caddyserver/xcaddy)...

```
$ xcaddy build
```

...the following steps are automated:

1. Create a new folder: `mkdir caddy`
2. Change into it: `cd caddy`
3. Copy [Caddy&#039;s main.go](https://github.com/caddyserver/caddy/blob/master/cmd/caddy/main.go) into the empty folder. Add imports for any custom plugins you want to add.
4. Initialize a Go module: `go mod init caddy`
5. (Optional) Pin Caddy version: `go get github.com/caddyserver/caddy/v2@version` replacing `version` with a git tag, commit, or branch name.
6. (Optional) Add plugins by adding their import: `_ &quot;import/path/here&quot;`
7. Compile: `go build -tags=nobadger,nomysql,nopgx`




## Quick start

The [Caddy website](https://caddyserver.com/docs/) has documentation that includes tutorials, quick-start guides, reference, and more.

**We recommend that all users -- regardless of experience level -- do our [Getting Started](https://caddyserver.com/docs/getting-started) guide to become familiar with using Caddy.**

If you&#039;ve only got a minute, [the website has several quick-start tutorials](https://caddyserver.com/docs/quick-starts) to choose from! However, after finishing a quick-start tutorial, please read more documentation to understand how the software works. 🙂




## Overview

Caddy is most often used as an HTTPS server, but it is suitable for any long-running Go program. First and foremost, it is a platform to run Go applications. Caddy &quot;apps&quot; are just Go programs that are implemented as Caddy modules. Two apps -- `tls` and `http` -- ship standard with Caddy.

Caddy apps instantly benefit from [automated documentation](https://caddyserver.com/docs/json/), graceful on-line [config changes via API](https://caddyserver.com/docs/api), and unification with other Caddy apps.

Although [JSON](https://caddyserver.com/docs/json/) is Caddy&#039;s native config language, Caddy can accept input from [config adapters](https://caddyserver.com/docs/config-adapters) which can essentially convert any config format of your choice into JSON: Caddyfile, JSON 5, YAML, TOML, NGINX config, and more.

The primary way to configure Caddy is through [its API](https://caddyserver.com/docs/api), but if you prefer config files, the [command-line interface](https://caddyserver.com/docs/command-line) supports those too.

Caddy exposes an unprecedented level of control compared to any web server in existence. In Caddy, you are usually setting the actual values of the initialized types in memory that power everything from your HTTP handlers and TLS handshakes to your storage medium. Caddy is also ridiculously extensible, with a powerful plugin system that makes vast improvements over other web servers.

To wield the power of this design, you need to know how the config document is structured. Please see [our documentation site](https://caddyserver.com/docs/) for details about [Caddy&#039;s config structure](https://caddyserver.com/docs/json/).

Nearly all of Caddy&#039;s configuration is contained in a single config document, rather than being scattered across CLI flags and env variables and a configuration file as with other web servers. This makes managing your server config more straightforward and reduces hidden variables/factors.


## Full documentation

Our website has complete documentation:

**https://caddyserver.com/docs/**

The docs are also open source. You can contribute to them here: https://github.com/caddyserver/website



## Getting help

- We advise companies using Caddy to secure a support contract through [Ardan Labs](https://www.ardanlabs.com) before help is needed.

- A [sponsorship](https://github.com/sponsors/mholt) goes a long way! We can offer private help to sponsors. If Caddy is benefitting your company, please consider a sponsorship. This not only helps fund full-time work to ensure the longevity of the project, it provides your company the resources, support, and discounts you need; along with being a great look for your company to your customers and potential customers!

- Individuals can exchange help for free on our community forum at https://caddy.community. Remember that people give help out of their spare time and good will. The best way to get help is to give it first!

Please use our [issue tracker](https://github.com/caddyserver/caddy/issues) only for bug reports and feature requests, i.e. actionable development items (support questions will usually be referred to the forums).



## About

Matthew Holt began developing Caddy in 2014 while studying computer science at Brigham Young University. (The name &quot;Caddy&quot; was chosen because this software helps with the tedious, mundane tasks of serving the Web, and is also a single place for multiple things to be organized together.) It soon became the first web server to use HTTPS automatically and by default, and now has hundreds of contributors and has served trillions of HTTPS requests.

**The name &quot;Caddy&quot; is trademarked.** The name of the software is &quot;Caddy&quot;, not &quot;Caddy Server&quot; or &quot;CaddyServer&quot;. Please call it &quot;Caddy&quot; or, if you wish to clarify, &quot;the Caddy web server&quot;. Caddy is a registered trademark of Stack Holdings GmbH.

- _Project on X: [@caddyserver](https://x.com/caddyserver)_
- _Author on X: [@mholt6](https://x.com/mholt6)_

Caddy is a project of [ZeroSSL](https://zerossl.com), a Stack Holdings company.

Debian package repository hosting is graciously provided by [Cloudsmith](https://cloudsmith.com). Cloudsmith is the only fully hosted, cloud-native, universal package management solution, that enables your organization to create, store and share packages in any format, to any place, with total confidence.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[kopia/kopia]]></title>
            <link>https://github.com/kopia/kopia</link>
            <guid>https://github.com/kopia/kopia</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Cross-platform backup tool for Windows, macOS & Linux with fast, incremental backups, client-side end-to-end encryption, compression and data deduplication. CLI and GUI included.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kopia/kopia">kopia/kopia</a></h1>
            <p>Cross-platform backup tool for Windows, macOS & Linux with fast, incremental backups, client-side end-to-end encryption, compression and data deduplication. CLI and GUI included.</p>
            <p>Language: Go</p>
            <p>Stars: 9,226</p>
            <p>Forks: 447</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>Kopia
=====

![Kopia](icons/kopia.svg)
[![Build Status](https://github.com/kopia/kopia/workflows/Build/badge.svg)](https://github.com/kopia/kopia/actions?query=workflow%3ABuild)
[![Slack](https://img.shields.io/badge/discuss-slack-blue.svg)](https://slack.kopia.io/) 
[![GoDoc](https://godoc.org/github.com/kopia/kopia/repo?status.svg)](https://godoc.org/github.com/kopia/kopia/repo)
[![Coverage Status](https://codecov.io/gh/kopia/kopia/branch/master/graph/badge.svg?token=CRK4RMRFSH)](https://codecov.io/gh/kopia/kopia)[![Go Report Card](https://goreportcard.com/badge/github.com/kopia/kopia)](https://goreportcard.com/report/github.com/kopia/kopia)
[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-v2.0%20adopted-ff69b4.svg)](CODE_OF_CONDUCT.md)
[![Docker Pulls](https://img.shields.io/docker/pulls/kopia/kopia)](https://hub.docker.com/r/kopia/kopia/tags?page=1&amp;ordering=name)
[![Downloads](https://img.shields.io/github/downloads/kopia/kopia/total.svg)](https://github.com/kopia/kopia/releases)
[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20Kopia%20Guru-006BFF)](https://gurubase.io/g/kopia)

&gt; _n._
&gt;
&gt; 1. _[copy, replica](https://en.wikipedia.org/wiki/Replica) (Polish)_
&gt; 2. _[lance, spear](https://en.wikipedia.org/wiki/Kopia)_
&gt; 3. _[fast and secure backup tool](https://kopia.io)_


Kopia is a fast and secure open-source backup/restore tool that allows you to create [encrypted](https://kopia.io/docs/features/#end-to-end-zero-knowledge-encryption) snapshots of your data and save the snapshots to [remote or cloud storage](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage) of your choice, [to network-attached storage or server](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage), or [locally on your machine](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage). Kopia does not &#039;image&#039; your whole machine. Rather, Kopia allows you to backup/restore any and all files/directories that you deem are important or critical.

Kopia has both [CLI (command-line interface)](https://kopia.io/docs/features/#both-command-line-and-graphical-user-interfaces) and [GUI (graphical user interface)](https://kopia.io/docs/features/#both-command-line-and-graphical-user-interfaces) versions, making it the perfect tool for both advanced and regular users. You can read more about Kopia&#039;s unique [features](https://kopia.io/docs/features/) -- which include [compression](https://kopia.io/docs/features/#compression), [deduplication](https://kopia.io/docs/features/#backup-files-and-directories-using-snapshots), [end-to-end &#039;zero knowledge&#039; encryption](https://kopia.io/docs/features/#end-to-end-zero-knowledge-encryption), and [error correction](https://kopia.io/docs/features/#error-correction) -- to get a better understanding of how Kopia works.

When ready, head to the [installation](https://kopia.io/docs/installation/) page to download and install Kopia, and make sure to read the [Getting Started Guide](https://kopia.io/docs/getting-started/) for a step-by-step walkthrough of how to use Kopia.

Pick the Cloud Storage Provider You Want
---

Kopia supports saving your [encrypted](https://kopia.io/docs/features/#end-to-end-zero-knowledge-encryption) and [compressed](https://kopia.io/docs/features/#compression) snapshots to all of the following [storage locations](https://kopia.io/docs/features/#save-snapshots-to-cloud-network-or-local-storage):

* **Amazon S3** and any **cloud storage that is compatible with S3**
* **Azure Blob Storage**
* **Backblaze B2**
* **Google Cloud Storage**
* Any remote server or cloud storage that supports **WebDAV**
* Any remote server or cloud storage that supports **SFTP**
* Some of the cloud storage options supported by **Rclone**
  * Requires you to download and setup Rclone in addition to Kopia, but after that Kopia manages/runs Rclone for you
  * Rclone support is experimental: not all the cloud storage products supported by Rclone have been tested to work with Kopia, and some may not work with Kopia; Kopia has been tested to work with **Dropbox**, **OneDrive**, and **Google Drive** through Rclone
* Your local machine and any network-attached storage or server
* Your own server by setting up a [Kopia Repository Server](https://kopia.io/docs/repository-server/)

And Kopia uses [data deduplication](https://kopia.io/docs/features/#backup-files-and-directories-using-snapshots) to save you money! Read the [repositories help page](https://kopia.io/docs/repositories/) for more information on supported storage locations.

With Kopia you are in full control of where to store your snapshots, that is, you pick the storage provider you want to use. You must provision and pay for the storage provider for whatever storage locations you want to use, and then tell Kopia what those storage locations are. You can even use multiple storage locations for different backup repositories if you want. Kopia also supports backing up multiple machines to the same storage location.

Kopia in Action
---

Using Kopia via command-line interface:

[![asciicast](https://asciinema.org/a/ykx6uzEhKY3451fWEnX9nm9uo.svg)](https://asciinema.org/a/ykx6uzEhKY3451fWEnX9nm9uo)

Using Kopia via graphical user interface (note: the video is of an older version of Kopia and the interface is different in the current version of Kopia, but the main principles of the interface are the same):

[![Kopia UI Tutorial](https://img.youtube.com/vi/sHJjSpasWIo/0.jpg)](https://www.youtube.com/watch?v=sHJjSpasWIo)

Getting Started
---
See [Kopia Documentation](https://kopia.io/docs/) for more information.

Building Kopia
---
See [Build Infrastructure](BUILD.md) for more information on building Kopia and working with the source code.

Licensing
---
Kopia is licensed under the Apache License, Version 2.0. See [LICENSE](LICENSE) for the full license text.

Contribution Guidelines
---
Kopia is open source and contributions are welcome. For more information on how to contribute see the [Contribution Guidelines](https://kopia.io/docs/contribution-guidelines/).

Reporting Security Issues
---
If you find a security issue you&#039;d like to disclose privately, please contact `security@kopia.io` or via direct message to maintainers on [Slack](https://slack.kopia.io).

[![Netlify Status](https://api.netlify.com/api/v1/badges/6b5c1fe4-a0da-4e7e-939b-ff1105251985/deploy-status)](https://app.netlify.com/sites/kopia/deploys)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[cilium/cilium]]></title>
            <link>https://github.com/cilium/cilium</link>
            <guid>https://github.com/cilium/cilium</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[eBPF-based Networking, Security, and Observability]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cilium/cilium">cilium/cilium</a></h1>
            <p>eBPF-based Networking, Security, and Observability</p>
            <p>Language: Go</p>
            <p>Stars: 21,341</p>
            <p>Forks: 3,155</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[qax-os/excelize]]></title>
            <link>https://github.com/qax-os/excelize</link>
            <guid>https://github.com/qax-os/excelize</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Go language library for reading and writing Microsoft Excel™ (XLAM / XLSM / XLSX / XLTM / XLTX) spreadsheets]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qax-os/excelize">qax-os/excelize</a></h1>
            <p>Go language library for reading and writing Microsoft Excel™ (XLAM / XLSM / XLSX / XLTM / XLTX) spreadsheets</p>
            <p>Language: Go</p>
            <p>Stars: 18,919</p>
            <p>Forks: 1,760</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;650&quot; src=&quot;./excelize.svg&quot; alt=&quot;Excelize logo&quot;&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/xuri/excelize/actions/workflows/go.yml&quot;&gt;&lt;img src=&quot;https://github.com/xuri/excelize/actions/workflows/go.yml/badge.svg&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://codecov.io/gh/qax-os/excelize&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/qax-os/excelize/branch/master/graph/badge.svg&quot; alt=&quot;Code Coverage&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://goreportcard.com/report/github.com/xuri/excelize/v2&quot;&gt;&lt;img src=&quot;https://goreportcard.com/badge/github.com/xuri/excelize/v2&quot; alt=&quot;Go Report Card&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://pkg.go.dev/github.com/xuri/excelize/v2&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/go.dev-reference-007d9c?logo=go&amp;logoColor=white&quot; alt=&quot;go.dev&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://opensource.org/licenses/BSD-3-Clause&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-bsd-orange.svg&quot; alt=&quot;Licenses&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://www.paypal.com/paypalme/xuri&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Donate-PayPal-green.svg&quot; alt=&quot;Donate&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

# Excelize

## Introduction

Excelize is a library written in pure Go providing a set of functions that allow you to write to and read from XLAM / XLSM / XLSX / XLTM / XLTX files. Supports reading and writing spreadsheet documents generated by Microsoft Excel&amp;trade; 2007 and later. Supports complex components by high compatibility, and provided streaming API for generating or reading data from a worksheet with huge amounts of data. This library needs Go version 1.23 or later. The full docs can be seen using go&#039;s built-in documentation tool, or online at [go.dev](https://pkg.go.dev/github.com/xuri/excelize/v2) and [docs reference](https://xuri.me/excelize/).

## Basic Usage

### Installation

```bash
go get github.com/xuri/excelize
```

- If your packages are managed using [Go Modules](https://go.dev/blog/using-go-modules), please install with following command.

```bash
go get github.com/xuri/excelize/v2
```

### Create spreadsheet

Here is a minimal example usage that will create spreadsheet file.

```go
package main

import (
    &quot;fmt&quot;

    &quot;github.com/xuri/excelize/v2&quot;
)

func main() {
    f := excelize.NewFile()
    defer func() {
        if err := f.Close(); err != nil {
            fmt.Println(err)
        }
    }()
    // Create a new sheet.
    index, err := f.NewSheet(&quot;Sheet2&quot;)
    if err != nil {
        fmt.Println(err)
        return
    }
    // Set value of a cell.
    f.SetCellValue(&quot;Sheet2&quot;, &quot;A2&quot;, &quot;Hello world.&quot;)
    f.SetCellValue(&quot;Sheet1&quot;, &quot;B2&quot;, 100)
    // Set active sheet of the workbook.
    f.SetActiveSheet(index)
    // Save spreadsheet by the given path.
    if err := f.SaveAs(&quot;Book1.xlsx&quot;); err != nil {
        fmt.Println(err)
    }
}
```

### Reading spreadsheet

The following constitutes the bare to read a spreadsheet document.

```go
package main

import (
    &quot;fmt&quot;

    &quot;github.com/xuri/excelize/v2&quot;
)

func main() {
    f, err := excelize.OpenFile(&quot;Book1.xlsx&quot;)
    if err != nil {
        fmt.Println(err)
        return
    }
    defer func() {
        // Close the spreadsheet.
        if err := f.Close(); err != nil {
            fmt.Println(err)
        }
    }()
    // Get value from cell by given worksheet name and cell reference.
    cell, err := f.GetCellValue(&quot;Sheet1&quot;, &quot;B2&quot;)
    if err != nil {
        fmt.Println(err)
        return
    }
    fmt.Println(cell)
    // Get all the rows in the Sheet1.
    rows, err := f.GetRows(&quot;Sheet1&quot;)
    if err != nil {
        fmt.Println(err)
        return
    }
    for _, row := range rows {
        for _, colCell := range row {
            fmt.Print(colCell, &quot;\t&quot;)
        }
        fmt.Println()
    }
}
```

### Add chart to spreadsheet file

With Excelize chart generation and management is as easy as a few lines of code. You can build charts based on data in your worksheet or generate charts without any data in your worksheet at all.

&lt;p align=&quot;center&quot;&gt;&lt;img width=&quot;650&quot; src=&quot;./test/images/chart.png&quot; alt=&quot;Excelize&quot;&gt;&lt;/p&gt;

```go
package main

import (
    &quot;fmt&quot;

    &quot;github.com/xuri/excelize/v2&quot;
)

func main() {
    f := excelize.NewFile()
    defer func() {
        if err := f.Close(); err != nil {
            fmt.Println(err)
        }
    }()
    for idx, row := range [][]interface{}{
        {nil, &quot;Apple&quot;, &quot;Orange&quot;, &quot;Pear&quot;}, {&quot;Small&quot;, 2, 3, 3},
        {&quot;Normal&quot;, 5, 2, 4}, {&quot;Large&quot;, 6, 7, 8},
    } {
        cell, err := excelize.CoordinatesToCellName(1, idx+1)
        if err != nil {
            fmt.Println(err)
            return
        }
        f.SetSheetRow(&quot;Sheet1&quot;, cell, &amp;row)
    }
    if err := f.AddChart(&quot;Sheet1&quot;, &quot;E1&quot;, &amp;excelize.Chart{
        Type: excelize.Col3DClustered,
        Series: []excelize.ChartSeries{
            {
                Name:       &quot;Sheet1!$A$2&quot;,
                Categories: &quot;Sheet1!$B$1:$D$1&quot;,
                Values:     &quot;Sheet1!$B$2:$D$2&quot;,
            },
            {
                Name:       &quot;Sheet1!$A$3&quot;,
                Categories: &quot;Sheet1!$B$1:$D$1&quot;,
                Values:     &quot;Sheet1!$B$3:$D$3&quot;,
            },
            {
                Name:       &quot;Sheet1!$A$4&quot;,
                Categories: &quot;Sheet1!$B$1:$D$1&quot;,
                Values:     &quot;Sheet1!$B$4:$D$4&quot;,
            }},
        Title: []excelize.RichTextRun{
            {
                Text: &quot;Fruit 3D Clustered Column Chart&quot;,
            },
        },
    }); err != nil {
        fmt.Println(err)
        return
    }
    // Save spreadsheet by the given path.
    if err := f.SaveAs(&quot;Book1.xlsx&quot;); err != nil {
        fmt.Println(err)
    }
}
```

### Add picture to spreadsheet file

```go
package main

import (
    &quot;fmt&quot;
    _ &quot;image/gif&quot;
    _ &quot;image/jpeg&quot;
    _ &quot;image/png&quot;

    &quot;github.com/xuri/excelize/v2&quot;
)

func main() {
    f, err := excelize.OpenFile(&quot;Book1.xlsx&quot;)
    if err != nil {
        fmt.Println(err)
        return
    }
    defer func() {
        // Close the spreadsheet.
        if err := f.Close(); err != nil {
            fmt.Println(err)
        }
    }()
    // Insert a picture.
    if err := f.AddPicture(&quot;Sheet1&quot;, &quot;A2&quot;, &quot;image.png&quot;, nil); err != nil {
        fmt.Println(err)
    }
    // Insert a picture to worksheet with scaling.
    if err := f.AddPicture(&quot;Sheet1&quot;, &quot;D2&quot;, &quot;image.jpg&quot;,
        &amp;excelize.GraphicOptions{ScaleX: 0.5, ScaleY: 0.5}); err != nil {
        fmt.Println(err)
    }
    // Insert a picture offset in the cell with printing support.
    enable, disable := true, false
    if err := f.AddPicture(&quot;Sheet1&quot;, &quot;H2&quot;, &quot;image.gif&quot;,
        &amp;excelize.GraphicOptions{
            PrintObject:     &amp;enable,
            LockAspectRatio: false,
            OffsetX:         15,
            OffsetY:         10,
            Locked:          &amp;disable,
        }); err != nil {
        fmt.Println(err)
    }
    // Save the spreadsheet with the origin path.
    if err = f.Save(); err != nil {
        fmt.Println(err)
    }
}
```

## Contributing

Contributions are welcome! Open a pull request to fix a bug, or open an issue to discuss a new feature or change. XML is compliant with [part 1 of the 5th edition of the ECMA-376 Standard for Office Open XML](https://www.ecma-international.org/publications-and-standards/standards/ecma-376/).

## Licenses

This program is under the terms of the BSD 3-Clause License. See [https://opensource.org/licenses/BSD-3-Clause](https://opensource.org/licenses/BSD-3-Clause).

The Excel logo is a trademark of [Microsoft Corporation](https://aka.ms/trademarks-usage). This artwork is an adaptation.

gopher.{ai,svg,png} was created by [Takuya Ueda](https://twitter.com/tenntenn). Licensed under the [Creative Commons 3.0 Attributions license](http://creativecommons.org/licenses/by/3.0/).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[ethereum-optimism/optimism]]></title>
            <link>https://github.com/ethereum-optimism/optimism</link>
            <guid>https://github.com/ethereum-optimism/optimism</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[Optimism is Ethereum, scaled.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ethereum-optimism/optimism">ethereum-optimism/optimism</a></h1>
            <p>Optimism is Ethereum, scaled.</p>
            <p>Language: Go</p>
            <p>Stars: 6,034</p>
            <p>Forks: 3,534</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>
&lt;div align=&quot;center&quot;&gt;
  &lt;br /&gt;
  &lt;br /&gt;
  &lt;a href=&quot;https://optimism.io&quot;&gt;&lt;img alt=&quot;Optimism&quot; src=&quot;https://raw.githubusercontent.com/ethereum-optimism/brand-kit/main/assets/svg/OPTIMISM-R.svg&quot; width=600&gt;&lt;/a&gt;
  &lt;br /&gt;
  &lt;h3&gt;&lt;a href=&quot;https://optimism.io&quot;&gt;Optimism&lt;/a&gt; is Ethereum, scaled.&lt;/h3&gt;
  &lt;br /&gt;
&lt;/div&gt;

## What is Optimism?

[Optimism](https://www.optimism.io/) is a project dedicated to scaling Ethereum&#039;s technology and expanding its ability to coordinate people from across the world to build effective decentralized economies and governance systems. The [Optimism Collective](https://app.optimism.io/announcement) builds open-source software for running L2 blockchains and aims to address key governance and economic challenges in the wider cryptocurrency ecosystem. Optimism operates on the principle of **impact=profit**, the idea that individuals who positively impact the Collective should be proportionally rewarded with profit. **Change the incentives and you change the world.**

In this repository, you&#039;ll find numerous core components of the OP Stack, the decentralized software stack maintained by the Optimism Collective that powers Optimism and forms the backbone of blockchains like [OP Mainnet](https://explorer.optimism.io/) and [Base](https://base.org). Designed to be &quot;aggressively open source,&quot; the OP Stack encourages you to explore, modify, extend, and test the code as needed. Although not all elements of the OP Stack are contained here, many of its essential components can be found within this repository. By collaborating on free, open software and shared standards, the Optimism Collective aims to prevent siloed software development and rapidly accelerate the development of the Ethereum ecosystem. Come contribute, build the future, and redefine power, together.

## Documentation

- If you want to build on top of OP Mainnet, refer to the [Optimism Community Hub](https://community.optimism.io)
- If you want to build your own OP Stack based blockchain, refer to the [OP Stack docs](https://stack.optimism.io)
- If you want to contribute to the OP Stack, check out the [Protocol Specs](./specs)

## Community

General discussion happens most frequently on the [Optimism discord](https://discord.gg/optimism).
Governance discussion can also be found on the [Optimism Governance Forum](https://gov.optimism.io/).

## Contributing

Read through [CONTRIBUTING.md](./CONTRIBUTING.md) for a general overview of the contributing process for this repository.
Use the [Developer Quick Start](./CONTRIBUTING.md#development-quick-start) to get your development environment set up to start working on the Optimism Monorepo.
Then check out the list of [Good First Issues](https://github.com/ethereum-optimism/optimism/contribute) to find something fun to work on!

## Security Policy and Vulnerability Reporting

Please refer to the canonical [Security Policy](https://github.com/ethereum-optimism/.github/blob/master/SECURITY.md) document for detailed information about how to report vulnerabilities in this codebase.
Bounty hunters are encouraged to check out [the Optimism Immunefi bug bounty program](https://immunefi.com/bounty/optimism/).
The Optimism Immunefi program offers up to $2,000,042 for in-scope critical vulnerabilities.

## The Bedrock Upgrade

OP Mainnet is currently preparing for [its next major upgrade, Bedrock](https://dev.optimism.io/introducing-optimism-bedrock/).
You can find detailed specifications for the Bedrock upgrade within the [specs folder](./specs) in this repository.

Please note that a significant number of packages and folders within this repository are part of the Bedrock upgrade and are NOT currently running in production.
Refer to the Directory Structure section below to understand which packages are currently running in production and which are intended for use as part of the Bedrock upgrade.

## Directory Structure

&lt;pre&gt;
~~ Production ~~
├── &lt;a href=&quot;./packages&quot;&gt;packages&lt;/a&gt;
│   ├── &lt;a href=&quot;./packages/common-ts&quot;&gt;common-ts&lt;/a&gt;: Common tools for building apps in TypeScript
│   ├── &lt;a href=&quot;./packages/contracts-bedrock&quot;&gt;contracts-bedrock&lt;/a&gt;: Bedrock smart contracts.
│   ├── &lt;a href=&quot;./packages/contracts-periphery&quot;&gt;contracts-periphery&lt;/a&gt;: Peripheral contracts for Optimism
│   ├── &lt;a href=&quot;./packages/core-utils&quot;&gt;core-utils&lt;/a&gt;: Low-level utilities that make building Optimism easier
│   ├── &lt;a href=&quot;./packages/chain-mon&quot;&gt;chain-mon&lt;/a&gt;: Chain monitoring services
│   ├── &lt;a href=&quot;./packages/fault-detector&quot;&gt;fault-detector&lt;/a&gt;: Service for detecting Sequencer faults
│   ├── &lt;a href=&quot;./packages/replica-healthcheck&quot;&gt;replica-healthcheck&lt;/a&gt;: Service for monitoring the health of a replica node
│   └── &lt;a href=&quot;./packages/sdk&quot;&gt;sdk&lt;/a&gt;: provides a set of tools for interacting with Optimism
├── &lt;a href=&quot;./op-bindings&quot;&gt;op-bindings&lt;/a&gt;: Go bindings for Bedrock smart contracts.
├── &lt;a href=&quot;./op-batcher&quot;&gt;op-batcher&lt;/a&gt;: L2-Batch Submitter, submits bundles of batches to L1
├── &lt;a href=&quot;./op-bootnode&quot;&gt;op-bootnode&lt;/a&gt;: Standalone op-node discovery bootnode
├── &lt;a href=&quot;./op-chain-ops&quot;&gt;op-chain-ops&lt;/a&gt;: State surgery utilities
├── &lt;a href=&quot;./op-challenger&quot;&gt;op-challenger&lt;/a&gt;: Dispute game challenge agent
├── &lt;a href=&quot;./op-e2e&quot;&gt;op-e2e&lt;/a&gt;: End-to-End testing of all bedrock components in Go
├── &lt;a href=&quot;./op-exporter&quot;&gt;op-exporter&lt;/a&gt;: Prometheus exporter client
├── &lt;a href=&quot;./op-heartbeat&quot;&gt;op-heartbeat&lt;/a&gt;: Heartbeat monitor service
├── &lt;a href=&quot;./op-node&quot;&gt;op-node&lt;/a&gt;: rollup consensus-layer client
├── &lt;a href=&quot;./op-program&quot;&gt;op-program&lt;/a&gt;: Fault proof program
├── &lt;a href=&quot;./op-proposer&quot;&gt;op-proposer&lt;/a&gt;: L2-Output Submitter, submits proposals to L1
├── &lt;a href=&quot;./op-service&quot;&gt;op-service&lt;/a&gt;: Common codebase utilities
├── &lt;a href=&quot;./op-signer&quot;&gt;op-signer&lt;/a&gt;: Client signer
├── &lt;a href=&quot;./op-wheel&quot;&gt;op-wheel&lt;/a&gt;: Database utilities
├── &lt;a href=&quot;./ops-bedrock&quot;&gt;ops-bedrock&lt;/a&gt;: Bedrock devnet work
├── &lt;a href=&quot;./proxyd&quot;&gt;proxyd&lt;/a&gt;: Configurable RPC request router and proxy
└── &lt;a href=&quot;./specs&quot;&gt;specs&lt;/a&gt;: Specs of the rollup starting at the Bedrock upgrade

~~ Pre-BEDROCK ~~
├── &lt;a href=&quot;./packages&quot;&gt;packages&lt;/a&gt;
│   ├── &lt;a href=&quot;./packages/common-ts&quot;&gt;common-ts&lt;/a&gt;: Common tools for building apps in TypeScript
│   ├── &lt;a href=&quot;./packages/contracts-periphery&quot;&gt;contracts-periphery&lt;/a&gt;: Peripheral contracts for Optimism
│   ├── &lt;a href=&quot;./packages/core-utils&quot;&gt;core-utils&lt;/a&gt;: Low-level utilities that make building Optimism easier
│   ├── &lt;a href=&quot;./packages/chain-mon&quot;&gt;chain-mon&lt;/a&gt;: Chain monitoring services
│   ├── &lt;a href=&quot;./packages/fault-detector&quot;&gt;fault-detector&lt;/a&gt;: Service for detecting Sequencer faults
│   ├── &lt;a href=&quot;./packages/replica-healthcheck&quot;&gt;replica-healthcheck&lt;/a&gt;: Service for monitoring the health of a replica node
│   └── &lt;a href=&quot;./packages/sdk&quot;&gt;sdk&lt;/a&gt;: provides a set of tools for interacting with Optimism
├── &lt;a href=&quot;./indexer&quot;&gt;indexer&lt;/a&gt;: indexes and syncs transactions
├── &lt;a href=&quot;./op-exporter&quot;&gt;op-exporter&lt;/a&gt;: A prometheus exporter to collect/serve metrics from an Optimism node
├── &lt;a href=&quot;./proxyd&quot;&gt;proxyd&lt;/a&gt;: Configurable RPC request router and proxy
└── &lt;a href=&quot;./technical-documents&quot;&gt;technical-documents&lt;/a&gt;: audits and post-mortem documents
&lt;/pre&gt;

## Branching Model

### Active Branches

| Branch          | Status                                                                           |
| --------------- | -------------------------------------------------------------------------------- |
| [master](https://github.com/ethereum-optimism/optimism/tree/master/)                   | Accepts PRs from `develop` when intending to deploy to production.                  |
| [develop](https://github.com/ethereum-optimism/optimism/tree/develop/)                 | Accepts PRs that are compatible with `master` OR from `release/X.X.X` branches.                    |
| release/X.X.X                                                                          | Accepts PRs for all changes, particularly those not backwards compatible with `develop` and `master`. |

### Overview

This repository generally follows [this Git branching model](https://nvie.com/posts/a-successful-git-branching-model/).
Please read the linked post if you&#039;re planning to make frequent PRs into this repository.

### Production branch

The production branch is `master`.
The `master` branch contains the code for latest &quot;stable&quot; releases.
Updates from `master` **always** come from the `develop` branch.

### Development branch

The primary development branch is [`develop`](https://github.com/ethereum-optimism/optimism/tree/develop/).
`develop` contains the most up-to-date software that remains backwards compatible with the latest experimental [network deployments](https://community.optimism.io/docs/useful-tools/networks/).
If you&#039;re making a backwards compatible change, please direct your pull request towards `develop`.

**Changes to contracts within `packages/contracts-bedrock/contracts` are usually NOT considered backwards compatible and SHOULD be made against a release candidate branch**.
Some exceptions to this rule exist for cases in which we absolutely must deploy some new contract after a release candidate branch has already been fully deployed.
If you&#039;re changing or adding a contract and you&#039;re unsure about which branch to make a PR into, default to using the latest release candidate branch.
See below for info about release candidate branches.

### Release candidate branches

Branches marked `release/X.X.X` are **release candidate branches**.
Changes that are not backwards compatible and all changes to contracts within `packages/contracts-bedrock/contracts` MUST be directed towards a release candidate branch.
Release candidates are merged into `develop` and then into `master` once they&#039;ve been fully deployed.
We may sometimes have more than one active `release/X.X.X` branch if we&#039;re in the middle of a deployment.
See table in the **Active Branches** section above to find the right branch to target.

## Releases

### Changesets

We use [changesets](https://github.com/changesets/changesets) to mark packages for new releases.
When merging commits to the `develop` branch you MUST include a changeset file if your change would require that a new version of a package be released.

To add a changeset, run the command `pnpm changeset` in the root of this monorepo.
You will be presented with a small prompt to select the packages to be released, the scope of the release (major, minor, or patch), and the reason for the release.
Comments within changeset files will be automatically included in the changelog of the package.

### Triggering Releases

Releases can be triggered using the following process:

1. Create a PR that merges the `develop` branch into the `master` branch.
2. Wait for the auto-generated `Version Packages` PR to be opened (may take several minutes).
3. Change the base branch of the auto-generated `Version Packages` PR from `master` to `develop` and merge into `develop`.
4. Create a second PR to merge the `develop` branch into the `master` branch.

After merging the second PR into the `master` branch, packages will be automatically released to their respective locations according to the set of changeset files in the `develop` branch at the start of the process.
Please carry this process out exactly as listed to avoid `develop` and `master` falling out of sync.

**NOTE**: PRs containing changeset files merged into `develop` during the release process can cause issues with changesets that can require manual intervention to fix.
It&#039;s strongly recommended to avoid merging PRs into develop during an active release.

## License

All other files within this repository are licensed under the [MIT License](https://github.com/ethereum-optimism/optimism/blob/master/LICENSE) unless stated otherwise.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[grafana/mcp-grafana]]></title>
            <link>https://github.com/grafana/mcp-grafana</link>
            <guid>https://github.com/grafana/mcp-grafana</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[MCP server for Grafana]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/grafana/mcp-grafana">grafana/mcp-grafana</a></h1>
            <p>MCP server for Grafana</p>
            <p>Language: Go</p>
            <p>Stars: 432</p>
            <p>Forks: 30</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre># Grafana MCP server

A [Model Context Protocol][mcp] (MCP) server for Grafana.

This provides access to your Grafana instance and the surrounding ecosystem.

## Features

- [x] Search for dashboards
- [x] Get dashboard by UID
- [x] List and fetch datasource information
- [ ] Query datasources
  - [x] Prometheus
  - [x] Loki
    - [x] Log queries
    - [x] Metric queries
  - [ ] Tempo
  - [ ] Pyroscope
- [x] Query Prometheus metadata
  - [x] Metric metadata
  - [x] Metric names
  - [x] Label names
  - [x] Label values
- [x] Query Loki metadata
  - [x] Label names
  - [x] Label values
  - [x] Stats
- [x] Search, create, update and close incidents
- [ ] Start Sift investigations and view the results
- [ ] Alerting
  - [x] List and fetch alert rule information
  - [ ] Get alert rule statuses (firing/normal/error/etc.)
  - [ ] Create and change alert rules
  - [ ] List contact points
  - [ ] Create and change contact points
- [x] Access Grafana OnCall functionality
  - [x] List and manage schedules
  - [x] Get shift details
  - [x] Get current on-call users
  - [x] List teams and users
  - [ ] List alert groups

The list of tools is configurable, so you can choose which tools you want to make available to the MCP client.
This is useful if you don&#039;t use certain functionality or if you don&#039;t want to take up too much of the context window.

### Tools

| Tool                              | Category    | Description                                                        |
|-----------------------------------|-------------|--------------------------------------------------------------------|
| `search_dashboards`               | Search      | Search for dashboards                                              |
| `get_dashboard_by_uid`            | Dashboard   | Get a dashboard by uid                                             |
| `list_datasources`                | Datasources | List datasources                                                   |
| `get_datasource_by_uid`           | Datasources | Get a datasource by uid                                            |
| `get_datasource_by_name`          | Datasources | Get a datasource by name                                           |
| `query_prometheus`                | Prometheus  | Execute a query against a Prometheus datasource                    |
| `list_prometheus_metric_metadata` | Prometheus  | List metric metadata                                               |
| `list_prometheus_metric_names`    | Prometheus  | List available metric names                                        |
| `list_prometheus_label_names`     | Prometheus  | List label names matching a selector                               |
| `list_prometheus_label_values`    | Prometheus  | List values for a specific label                                   |
| `list_incidents`                  | Incident    | List incidents in Grafana Incident                                 |
| `create_incident`                 | Incident    | Create an incident in Grafana Incident                             |
| `add_activity_to_incident`        | Incident    | Add an activity item to an incident in Grafana Incident            |
| `resolve_incident`                | Incident    | Resolve an incident in Grafana Incident                            |
| `query_loki_logs`                 | Loki        | Query and retrieve logs using LogQL (either log or metric queries) |
| `list_loki_label_names`           | Loki        | List all available label names in logs                             |
| `list_loki_label_values`          | Loki        | List values for a specific log label                               |
| `query_loki_stats`                | Loki        | Get statistics about log streams                                   |
| `list_alert_rules`                | Alerting    | List alert rules                                                   |
| `get_alert_rule_by_uid`           | Alerting    | Get alert rule by UID                                              |
| `list_oncall_schedules`           | OnCall      | List schedules from Grafana OnCall                                 |
| `get_oncall_shift`                | OnCall      | Get details for a specific OnCall shift                           |
| `get_current_oncall_users`        | OnCall      | Get users currently on-call for a specific schedule                |
| `list_oncall_teams`               | OnCall      | List teams from Grafana OnCall                                     |
| `list_oncall_users`               | OnCall      | List users from Grafana OnCall                                     |

## Usage

1. Create a service account in Grafana with enough permissions to use the tools you want to use,
   generate a service account token, and copy it to the clipboard for use in the configuration file.
   Follow the [Grafana documentation][service-account] for details.

2. Download the latest release of `mcp-grafana` from the [releases page](https://github.com/grafana/mcp-grafana/releases) and place it in your `$PATH`.

   If you have a Go toolchain installed you can also build and install it from source, using the `GOBIN` environment variable
   to specify the directory where the binary should be installed. This should also be in your `PATH`.

   ```bash
   GOBIN=&quot;$HOME/go/bin&quot; go install github.com/grafana/mcp-grafana/cmd/mcp-grafana@latest
   ```

3. Add the server configuration to your client configuration file. For example, for Claude Desktop:

   ```json
   {
     &quot;mcpServers&quot;: {
       &quot;grafana&quot;: {
         &quot;command&quot;: &quot;mcp-grafana&quot;,
         &quot;args&quot;: [],
         &quot;env&quot;: {
           &quot;GRAFANA_URL&quot;: &quot;http://localhost:3000&quot;,
           &quot;GRAFANA_API_KEY&quot;: &quot;&lt;your service account token&gt;&quot;
         }
       }
     }
   }
   ```

&gt; Note: if you see `Error: spawn mcp-grafana ENOENT` in Claude Desktop, you need to specify the full path to `mcp-grafana`.

## Development

Contributions are welcome! Please open an issue or submit a pull request if you have any suggestions or improvements.

This project is written in Go. Install Go following the instructions for your platform.

To run the server, use:

```bash
make run
```

You can also run the server using the SSE transport inside Docker. To build the image, use

```
make build-image
```

And to run the image, use:

```
docker run -it --rm -p 8000:8000 mcp-grafana:latest
```

### Testing

There are three types of tests available:

1. Unit Tests (no external dependencies required):
```bash
make test-unit
```

You can also run unit tests with:
```bash
make test
```

2. Integration Tests (requires docker containers to be up and running):
```bash
make test-integration
```

3. Cloud Tests (requires cloud Grafana instance and credentials):
```bash
make test-cloud
```
&gt; Note: Cloud tests are automatically configured in CI. For local development, you&#039;ll need to set up your own Grafana Cloud instance and credentials.

More comprehensive integration tests will require a Grafana instance to be running locally on port 3000; you can start one with Docker Compose:

```bash
docker-compose up -d
```

The integration tests can be run with:

```bash
make test-all
```

If you&#039;re adding more tools, please add integration tests for them. The existing tests should be a good starting point.

### Linting

To lint the code, run:

```bash
make lint
```

## License

This project is licensed under the [Apache License, Version 2.0](LICENSE).

[mcp]: https://modelcontextprotocol.io/
[service-account]: https://grafana.com/docs/grafana/latest/administration/service-accounts/
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/consul]]></title>
            <link>https://github.com/hashicorp/consul</link>
            <guid>https://github.com/hashicorp/consul</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/consul">hashicorp/consul</a></h1>
            <p>Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 28,872</p>
            <p>Forks: 4,465</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;
  &lt;img src=&quot;./website/public/img/logo.svg&quot; align=&quot;left&quot; height=&quot;46px&quot; alt=&quot;Consul logo&quot;/&gt;
  &lt;span&gt;Consul&lt;/span&gt;
&lt;/h1&gt;

[![License: BUSL-1.1](https://img.shields.io/badge/License-BUSL--1.1-yellow.svg)](LICENSE)
[![Docker Pulls](https://img.shields.io/docker/pulls/hashicorp/consul.svg)](https://hub.docker.com/r/hashicorp/consul)
[![Go Report Card](https://goreportcard.com/badge/github.com/hashicorp/consul)](https://goreportcard.com/report/github.com/hashicorp/consul)

Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure.

* Website: https://www.consul.io
* Tutorials: [HashiCorp Learn](https://learn.hashicorp.com/consul)
* Forum: [Discuss](https://discuss.hashicorp.com/c/consul)

Consul provides several key features:

* **Multi-Datacenter** - Consul is built to be datacenter aware, and can
  support any number of regions without complex configuration.

* **Service Mesh** - Consul Service Mesh enables secure service-to-service
  communication with automatic TLS encryption and identity-based authorization. Applications
  can use sidecar proxies in a service mesh configuration to establish TLS
  connections for inbound and outbound connections with Transparent Proxy.

* **API Gateway** - Consul API Gateway manages access to services within Consul Service Mesh, 
  allow users to define traffic and authorization policies to services deployed within the mesh.  

* **Service Discovery** - Consul makes it simple for services to register
  themselves and to discover other services via a DNS or HTTP interface.
  External services such as SaaS providers can be registered as well.

* **Health Checking** - Health Checking enables Consul to quickly alert
  operators about any issues in a cluster. The integration with service
  discovery prevents routing traffic to unhealthy hosts and enables service
  level circuit breakers.

* **Dynamic App Configuration** - An HTTP API that allows users to store indexed objects within Consul,
  for storing configuration parameters and application metadata.

Consul runs on Linux, macOS, FreeBSD, Solaris, and Windows and includes an
optional [browser based UI](https://demo.consul.io). A commercial version
called [Consul Enterprise](https://www.consul.io/docs/enterprise) is also
available.

**Please note**: We take Consul&#039;s security and our users&#039; trust very seriously. If you
believe you have found a security issue in Consul, please [responsibly disclose](https://www.hashicorp.com/security#vulnerability-reporting)
by contacting us at security@hashicorp.com.

## Quick Start

A few quick start guides are available on the Consul website:

* **Standalone binary install:** https://learn.hashicorp.com/collections/consul/get-started-vms
* **Minikube install:** https://learn.hashicorp.com/tutorials/consul/kubernetes-minikube
* **Kind install:** https://learn.hashicorp.com/tutorials/consul/kubernetes-kind
* **Kubernetes install:** https://learn.hashicorp.com/tutorials/consul/kubernetes-deployment-guide
* **Deploy HCP Consul:** https://learn.hashicorp.com/tutorials/consul/hcp-gs-deploy 

## Documentation

Full, comprehensive documentation is available on the Consul website: https://consul.io/docs

## Contributing

Thank you for your interest in contributing! Please refer to [CONTRIBUTING.md](https://github.com/hashicorp/consul/blob/main/.github/CONTRIBUTING.md)
for guidance. For contributions specifically to the browser based UI, please
refer to the UI&#039;s [README.md](https://github.com/hashicorp/consul/blob/main/ui/packages/consul-ui/README.md)
for guidance.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[docker/compose]]></title>
            <link>https://github.com/docker/compose</link>
            <guid>https://github.com/docker/compose</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Define and run multi-container applications with Docker]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/compose">docker/compose</a></h1>
            <p>Define and run multi-container applications with Docker</p>
            <p>Language: Go</p>
            <p>Stars: 35,139</p>
            <p>Forks: 5,368</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># Table of Contents
- [Docker Compose v2](#docker-compose-v2)
- [Where to get Docker Compose](#where-to-get-docker-compose)
    + [Windows and macOS](#windows-and-macos)
    + [Linux](#linux)
- [Quick Start](#quick-start)
- [Contributing](#contributing)
- [Legacy](#legacy)
# Docker Compose v2

[![GitHub release](https://img.shields.io/github/v/release/docker/compose.svg?style=flat-square)](https://github.com/docker/compose/releases/latest)
[![PkgGoDev](https://img.shields.io/badge/go.dev-docs-007d9c?style=flat-square&amp;logo=go&amp;logoColor=white)](https://pkg.go.dev/github.com/docker/compose/v2)
[![Build Status](https://img.shields.io/github/actions/workflow/status/docker/compose/ci.yml?label=ci&amp;logo=github&amp;style=flat-square)](https://github.com/docker/compose/actions?query=workflow%3Aci)
[![Go Report Card](https://goreportcard.com/badge/github.com/docker/compose/v2?style=flat-square)](https://goreportcard.com/report/github.com/docker/compose/v2)
[![Codecov](https://codecov.io/gh/docker/compose/branch/main/graph/badge.svg?token=HP3K4Y4ctu)](https://codecov.io/gh/docker/compose)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/docker/compose/badge)](https://api.securityscorecards.dev/projects/github.com/docker/compose)
![Docker Compose](logo.png?raw=true &quot;Docker Compose Logo&quot;)

Docker Compose is a tool for running multi-container applications on Docker
defined using the [Compose file format](https://compose-spec.io).
A Compose file is used to define how one or more containers that make up
your application are configured.
Once you have a Compose file, you can create and start your application with a
single command: `docker compose up`.

# Where to get Docker Compose

### Windows and macOS

Docker Compose is included in
[Docker Desktop](https://www.docker.com/products/docker-desktop/)
for Windows and macOS.

### Linux

You can download Docker Compose binaries from the
[release page](https://github.com/docker/compose/releases) on this repository.

Rename the relevant binary for your OS to `docker-compose` and copy it to `$HOME/.docker/cli-plugins`

Or copy it into one of these folders to install it system-wide:

* `/usr/local/lib/docker/cli-plugins` OR `/usr/local/libexec/docker/cli-plugins`
* `/usr/lib/docker/cli-plugins` OR `/usr/libexec/docker/cli-plugins`

(might require making the downloaded file executable with `chmod +x`)


Quick Start
-----------

Using Docker Compose is a three-step process:
1. Define your app&#039;s environment with a `Dockerfile` so it can be
   reproduced anywhere.
2. Define the services that make up your app in `compose.yaml` so
   they can be run together in an isolated environment.
3. Lastly, run `docker compose up` and Compose will start and run your entire
   app.

A Compose file looks like this:

```yaml
services:
  web:
    build: .
    ports:
      - &quot;5000:5000&quot;
    volumes:
      - .:/code
  redis:
    image: redis
```

Contributing
------------

Want to help develop Docker Compose? Check out our
[contributing documentation](CONTRIBUTING.md).

If you find an issue, please report it on the
[issue tracker](https://github.com/docker/compose/issues/new/choose).

Legacy
-------------

The Python version of Compose is available under the `v1` [branch](https://github.com/docker/compose/tree/v1).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hr3lxphr6j/bililive-go]]></title>
            <link>https://github.com/hr3lxphr6j/bililive-go</link>
            <guid>https://github.com/hr3lxphr6j/bililive-go</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[一个直播录制工具]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hr3lxphr6j/bililive-go">hr3lxphr6j/bililive-go</a></h1>
            <p>一个直播录制工具</p>
            <p>Language: Go</p>
            <p>Stars: 4,496</p>
            <p>Forks: 569</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># Bililive-go
[![CI](https://github.com/hr3lxphr6j/bililive-go/actions/workflows/tests.yaml/badge.svg?branch=master)](https://github.com/hr3lxphr6j/bililive-go/actions/workflows/tests.yaml)
[![Go Report Card](https://goreportcard.com/badge/github.com/hr3lxphr6j/bililive-go)](https://goreportcard.com/report/github.com/hr3lxphr6j/bililive-go)
[![Github release](https://img.shields.io/github/release/hr3lxphr6j/bililive-go.svg)](https://github.com/hr3lxphr6j/bililive-go/releases/latest)
[![Docker Pulls](https://img.shields.io/docker/pulls/chigusa/bililive-go.svg)](https://hub.docker.com/r/chigusa/bililive-go/)
[![Bilibili](https://img.shields.io/badge/%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9-%E6%9C%AA%E6%9D%A5%E7%A7%91%E6%8A%80%E7%8E%8B%E8%80%81%E8%8F%8A%E5%BD%95%E6%92%AD%E7%BB%84-ebb8d0.svg)](https://space.bilibili.com/18578203/)

Bililive-go是一个支持多种直播平台的直播录制工具   

![image](docs/screenshot.webp)

## 支持网站

&lt;table&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;th&gt;站点&lt;/th&gt;
        &lt;th&gt;url&lt;/th&gt;
        &lt;th&gt;支持情况&lt;/th&gt;
        &lt;th&gt;cookie&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;Acfun直播&lt;/td&gt;
        &lt;td&gt;live.acfun.cn&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;哔哩哔哩直播&lt;/td&gt;
        &lt;td&gt;live.bilibili.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;战旗直播&lt;/td&gt;
        &lt;td&gt;www.zhanqi.tv&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;斗鱼直播&lt;/td&gt;
        &lt;td&gt;www.douyu.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;火猫直播&lt;/td&gt;
        &lt;td&gt;www.huomao.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;龙珠直播&lt;/td&gt;
        &lt;td&gt;longzhu.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;虎牙直播&lt;/td&gt;
        &lt;td&gt;www.huya.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;CC直播&lt;/td&gt;
        &lt;td&gt;cc.163.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;一直播&lt;/td&gt;
        &lt;td&gt;www.yizhibo.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;OPENREC&lt;/td&gt;
        &lt;td&gt;www.openrec.tv&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;企鹅电竞&lt;/td&gt;
        &lt;td&gt;egame.qq.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;浪live&lt;/td&gt;
        &lt;td&gt;play.lang.live &amp; www.lang.live&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;花椒&lt;/td&gt;
        &lt;td&gt;www.huajiao.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;抖音直播&lt;/td&gt;
        &lt;td&gt;live.douyin.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;猫耳&lt;/td&gt;
        &lt;td&gt;fm.missevan.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;克拉克拉&lt;/td&gt;
        &lt;td&gt;www.hongdoufm.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;YY直播&lt;/td&gt;
        &lt;td&gt;www.yy.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr align=&quot;center&quot;&gt;
        &lt;td&gt;微博直播&lt;/td&gt;
        &lt;td&gt;weibo.com&lt;/td&gt;
        &lt;td&gt;滋瓷&lt;/td&gt;
        &lt;td&gt;&lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;

### cookie 在 config.yml 中的设置方法

cookie的设置以域名为单位。比如想在录制抖音直播时使用 cookie，那么 `config.yml` 中可以像下面这样写：
```
cookies:
  live.douyin.com: __ac_nonce=123456789012345678903;name=value
```
这里 name 和 value 只是随便举的例子，用来说明当添加超过一条 cookie 的键值对时应该用分号隔开。
至于具体应该添加哪些键，就需要用户针对不同网站自己获取了。

## 在网页中修改设置

点击网页左边的 `设置` 可以在线修改项目的配置文件，之后点击页面下面的 `保存设置` 按钮保存设置。
如果保存后窗口提醒设置保存成功，那就是配置文件已经被写入磁盘了。如果是保存失败，那可能是配置文件格式问题或者遇到程序 bug，总之磁盘上的配置文件没变。

在网页中即使保存配置成功也不一定表示相应的配置会立即生效。
有些配置需要停止监控后再重新开始监控才会生效，有些配置也许要重启程序才会生效。

## 网页播放器

点击对应直播间行右边的 `文件` 链接可以跳转到对应直播间的录播目录中。  
当然你点左边的 `文件` 一路找过去也行。

https://github.com/hr3lxphr6j/bililive-go/assets/2352900/6453900c-6321-417b-94f2-d65ec2ab3d7e

## Grafana 面板

docker compose 用户可以取消项目根目录下 `docker-compose.yml` 文件中 prometheus 和 grafana 部分的注释以启用统计面板。  
这里是 [设置说明](docs/grafana.md)

非 docker compose 用户需要自行部署 prometheus 和 grafana。  
这里是 [一些建议](docs/grafana.md#%E6%89%8B%E5%8A%A8%E5%AE%89%E8%A3%85%E7%AC%94%E8%AE%B0)

![image](https://github.com/hr3lxphr6j/bililive-go/raw/master/docs/dashboard.webp)


## 依赖
* [ffmpeg](https://ffmpeg.org/)

## 安装和使用

### Windows
https://github.com/hr3lxphr6j/bililive-go/wiki/Install-Windows

### macOS
https://github.com/hr3lxphr6j/bililive-go/wiki/Install-macOS

### Linux
https://github.com/hr3lxphr6j/bililive-go/wiki/Install-Linux

### docker

使用 https://hub.docker.com/r/chigusa/bililive-go 镜像创建容器运行。

例如：
```
docker run --restart=always -v ~/config.yml:/etc/bililive-go/config.yml -v ~/Videos:/srv/bililive -p 8080:8080 -d chigusa/bililive-go
```

### docker compose

使用项目根目录下的 `docker-compose.yml` 配置文件启动 docker compose 运行。

例如：
```
docker compose up
```
此时默认使用 `config.docker.yml` 文件作为程序的配置文件，`Videos/` 目录作为录制视频的输出目录。

NAS 用户使用系统自带 GUI 创建 docker compose 的情况请参考群晖用 docker compose 安装 bgo 的 [图文说明](./docs/Synology-related.md#如何用-docker-compose-安装-bgo)

## 常见问题
[docs/FAQ.md](docs/FAQ.md)

## 开发环境搭建（linux系统）
```
一、环境准备
  1. 前端环境
    1）前往https://nodejs.org/zh-cn/下载当前版本node（18.12.1）
    2）命令行运行 node -v 若控制台输出版本号则前端环境搭建成功
  2.后端环境
    1)下载golang安装 版本号1.19
      国际: https://golang.org/dl/
      国内: https://golang.google.cn/dl/
    2)命令行运行 go 若控制台输出各类提示命令 则安装成功 输入 go version 确认版本
  3.安装 ffmpeg (以centos7为例)
    1) yum install -y epel-release rpm
    2) rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7
    3) yum repolist
    4) rpm --import http://li.nux.ro/download/nux/RPM-GPG-KEY-nux.ro
    5) rpm -Uvh http://li.nux.ro/download/nux/dextop/el7/x86_64/nux-dextop-release-0-1.el7.nux.noarch.rpm
    6) yum repolist
    7) yum install -y ffmpeg
二、克隆代码并编译(linux环境)    
   1. git clone https://github.com/hr3lxphr6j/bililive-go.git
   2. cd bililive-go
   3. make build-web
   4. make 
三、linux编译其他环境(以windows 为例)
   1. GOOS=windows GOARCH=amd64 CGO_ENABLED=0 UPX_ENABLE=0 TAGS=dev GCFLAGS=&quot;all=-N -l&quot; ./src/hack/build.sh bililive
   2.如果不需要调试，可以改成
      GOOS=windows GOARCH=amd64 CGO_ENABLED=0 UPX_ENABLE=0 TAGS=release ./src/hack/build.sh bililive
```

## Wiki
[Wiki](https://github.com/hr3lxphr6j/bililive-go/wiki)

## API
[API doc](https://github.com/hr3lxphr6j/bililive-go/blob/master/docs/API.md)

## 参考
- [you-get](https://github.com/soimort/you-get)
- [ykdl](https://github.com/zhangn1985/ykdl)
- [youtube-dl](https://github.com/ytdl-org/youtube-dl)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[redis/go-redis]]></title>
            <link>https://github.com/redis/go-redis</link>
            <guid>https://github.com/redis/go-redis</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[Redis Go client]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/redis/go-redis">redis/go-redis</a></h1>
            <p>Redis Go client</p>
            <p>Language: Go</p>
            <p>Stars: 20,726</p>
            <p>Forks: 2,428</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># Redis client for Go

[![build workflow](https://github.com/redis/go-redis/actions/workflows/build.yml/badge.svg)](https://github.com/redis/go-redis/actions)
[![PkgGoDev](https://pkg.go.dev/badge/github.com/redis/go-redis/v9)](https://pkg.go.dev/github.com/redis/go-redis/v9?tab=doc)
[![Documentation](https://img.shields.io/badge/redis-documentation-informational)](https://redis.uptrace.dev/)
[![codecov](https://codecov.io/github/redis/go-redis/graph/badge.svg?token=tsrCZKuSSw)](https://codecov.io/github/redis/go-redis)
[![Chat](https://discordapp.com/api/guilds/752070105847955518/widget.png)](https://discord.gg/rWtp5Aj)

&gt; go-redis is the official Redis client library for the Go programming language. It offers a straightforward interface for interacting with Redis servers. 

## Supported versions

In `go-redis` we are aiming to support the last three releases of Redis. Currently, this means we do support:
- [Redis 7.2](https://raw.githubusercontent.com/redis/redis/7.2/00-RELEASENOTES) - using Redis Stack 7.2 for modules support
- [Redis 7.4](https://raw.githubusercontent.com/redis/redis/7.4/00-RELEASENOTES) - using Redis Stack 7.4 for modules support
- [Redis 8.0](https://raw.githubusercontent.com/redis/redis/8.0/00-RELEASENOTES) - using Redis CE 8.0 where modules are included

Although the `go.mod` states it requires at minimum `go 1.18`, our CI is configured to run the tests against all three
versions of Redis and latest two versions of Go ([1.23](https://go.dev/doc/devel/release#go1.23.0),
[1.24](https://go.dev/doc/devel/release#go1.24.0)). We observe that some modules related test may not pass with
Redis Stack 7.2 and some commands are changed with Redis CE 8.0.
Please do refer to the documentation and the tests if you experience any issues. We do plan to update the go version
in the `go.mod` to `go 1.24` in one of the next releases.

## How do I Redis?

[Learn for free at Redis University](https://university.redis.com/)

[Build faster with the Redis Launchpad](https://launchpad.redis.com/)

[Try the Redis Cloud](https://redis.com/try-free/)

[Dive in developer tutorials](https://developer.redis.com/)

[Join the Redis community](https://redis.com/community/)

[Work at Redis](https://redis.com/company/careers/jobs/)

## Documentation

- [English](https://redis.uptrace.dev)
- [简体中文](https://redis.uptrace.dev/zh/)

## Resources

- [Discussions](https://github.com/redis/go-redis/discussions)
- [Chat](https://discord.gg/rWtp5Aj)
- [Reference](https://pkg.go.dev/github.com/redis/go-redis/v9)
- [Examples](https://pkg.go.dev/github.com/redis/go-redis/v9#pkg-examples)

## Ecosystem

- [Redis Mock](https://github.com/go-redis/redismock)
- [Distributed Locks](https://github.com/bsm/redislock)
- [Redis Cache](https://github.com/go-redis/cache)
- [Rate limiting](https://github.com/go-redis/redis_rate)

This client also works with [Kvrocks](https://github.com/apache/incubator-kvrocks), a distributed
key value NoSQL database that uses RocksDB as storage engine and is compatible with Redis protocol.

## Features

- Redis commands except QUIT and SYNC.
- Automatic connection pooling.
- [Pub/Sub](https://redis.uptrace.dev/guide/go-redis-pubsub.html).
- [Pipelines and transactions](https://redis.uptrace.dev/guide/go-redis-pipelines.html).
- [Scripting](https://redis.uptrace.dev/guide/lua-scripting.html).
- [Redis Sentinel](https://redis.uptrace.dev/guide/go-redis-sentinel.html).
- [Redis Cluster](https://redis.uptrace.dev/guide/go-redis-cluster.html).
- [Redis Ring](https://redis.uptrace.dev/guide/ring.html).
- [Redis Performance Monitoring](https://redis.uptrace.dev/guide/redis-performance-monitoring.html).
- [Redis Probabilistic [RedisStack]](https://redis.io/docs/data-types/probabilistic/)

## Installation

go-redis supports 2 last Go versions and requires a Go version with
[modules](https://github.com/golang/go/wiki/Modules) support. So make sure to initialize a Go
module:

```shell
go mod init github.com/my/repo
```

Then install go-redis/**v9**:

```shell
go get github.com/redis/go-redis/v9
```

## Quickstart

```go
import (
    &quot;context&quot;
    &quot;fmt&quot;

    &quot;github.com/redis/go-redis/v9&quot;
)

var ctx = context.Background()

func ExampleClient() {
    rdb := redis.NewClient(&amp;redis.Options{
        Addr:     &quot;localhost:6379&quot;,
        Password: &quot;&quot;, // no password set
        DB:       0,  // use default DB
    })

    err := rdb.Set(ctx, &quot;key&quot;, &quot;value&quot;, 0).Err()
    if err != nil {
        panic(err)
    }

    val, err := rdb.Get(ctx, &quot;key&quot;).Result()
    if err != nil {
        panic(err)
    }
    fmt.Println(&quot;key&quot;, val)

    val2, err := rdb.Get(ctx, &quot;key2&quot;).Result()
    if err == redis.Nil {
        fmt.Println(&quot;key2 does not exist&quot;)
    } else if err != nil {
        panic(err)
    } else {
        fmt.Println(&quot;key2&quot;, val2)
    }
    // Output: key value
    // key2 does not exist
}
```

The above can be modified to specify the version of the RESP protocol by adding the `protocol`
option to the `Options` struct:

```go
    rdb := redis.NewClient(&amp;redis.Options{
        Addr:     &quot;localhost:6379&quot;,
        Password: &quot;&quot;, // no password set
        DB:       0,  // use default DB
        Protocol: 3, // specify 2 for RESP 2 or 3 for RESP 3
    })

```

### Connecting via a redis url

go-redis also supports connecting via the
[redis uri specification](https://github.com/redis/redis-specifications/tree/master/uri/redis.txt).
The example below demonstrates how the connection can easily be configured using a string, adhering
to this specification.

```go
import (
    &quot;github.com/redis/go-redis/v9&quot;
)

func ExampleClient() *redis.Client {
    url := &quot;redis://user:password@localhost:6379/0?protocol=3&quot;
    opts, err := redis.ParseURL(url)
    if err != nil {
        panic(err)
    }

    return redis.NewClient(opts)
}

```

### Instrument with OpenTelemetry

```go
import (
    &quot;github.com/redis/go-redis/v9&quot;
    &quot;github.com/redis/go-redis/extra/redisotel/v9&quot;
    &quot;errors&quot;
)

func main() {
    ...
    rdb := redis.NewClient(&amp;redis.Options{...})

    if err := errors.Join(redisotel.InstrumentTracing(rdb), redisotel.InstrumentMetrics(rdb)); err != nil {
        log.Fatal(err)
    }
```


### Advanced Configuration

go-redis supports extending the client identification phase to allow projects to send their own custom client identification.

#### Default Client Identification

By default, go-redis automatically sends the client library name and version during the connection process. This feature is available in redis-server as of version 7.2. As a result, the command is &quot;fire and forget&quot;, meaning it should fail silently, in the case that the redis server does not support this feature.

#### Disabling Identity Verification

When connection identity verification is not required or needs to be explicitly disabled, a `DisableIdentity` configuration option exists.
Initially there was a typo and the option was named `DisableIndentity` instead of `DisableIdentity`. The misspelled option is marked as Deprecated and will be removed in V10 of this library.
Although both options will work at the moment, the correct option is `DisableIdentity`. The deprecated option will be removed in V10 of this library, so please use the correct option name to avoid any issues.

To disable verification, set the `DisableIdentity` option to `true` in the Redis client options:

```go
rdb := redis.NewClient(&amp;redis.Options{
    Addr:            &quot;localhost:6379&quot;,
    Password:        &quot;&quot;,
    DB:              0,
    DisableIdentity: true, // Disable set-info on connect
})
```

#### Unstable RESP3 Structures for RediSearch Commands
When integrating Redis with application functionalities using RESP3, it&#039;s important to note that some response structures aren&#039;t final yet. This is especially true for more complex structures like search and query results. We recommend using RESP2 when using the search and query capabilities, but we plan to stabilize the RESP3-based API-s in the coming versions. You can find more guidance in the upcoming release notes.

To enable unstable RESP3, set the option in your client configuration:

```go
redis.NewClient(&amp;redis.Options{
			UnstableResp3: true,
		})
```
**Note:** When UnstableResp3 mode is enabled, it&#039;s necessary to use RawResult() and RawVal() to retrieve a raw data.
          Since, raw response is the only option for unstable search commands Val() and Result() calls wouldn&#039;t have any affect on them:

```go
res1, err := client.FTSearchWithArgs(ctx, &quot;txt&quot;, &quot;foo bar&quot;, &amp;redis.FTSearchOptions{}).RawResult()
val1 := client.FTSearchWithArgs(ctx, &quot;txt&quot;, &quot;foo bar&quot;, &amp;redis.FTSearchOptions{}).RawVal()
```

#### Redis-Search Default Dialect

In the Redis-Search module, **the default dialect is 2**. If needed, you can explicitly specify a different dialect using the appropriate configuration in your queries.

**Important**: Be aware that the query dialect may impact the results returned. If needed, you can revert to a different dialect version by passing the desired dialect in the arguments of the command you want to execute.
For example:
```
	res2, err := rdb.FTSearchWithArgs(ctx,
		&quot;idx:bicycle&quot;,
		&quot;@pickup_zone:[CONTAINS $bike]&quot;,
		&amp;redis.FTSearchOptions{
			Params: map[string]interface{}{
				&quot;bike&quot;: &quot;POINT(-0.1278 51.5074)&quot;,
			},
			DialectVersion: 3,
		},
	).Result()
```
You can find further details in the [query dialect documentation](https://redis.io/docs/latest/develop/interact/search-and-query/advanced-concepts/dialects/).

## Contributing
We welcome contributions to the go-redis library! If you have a bug fix, feature request, or improvement, please open an issue or pull request on GitHub.
We appreciate your help in making go-redis better for everyone.
If you are interested in contributing to the go-redis library, please check out our [contributing guidelines](CONTRIBUTING.md) for more information on how to get started.

## Look and feel

Some corner cases:

```go
// SET key value EX 10 NX
set, err := rdb.SetNX(ctx, &quot;key&quot;, &quot;value&quot;, 10*time.Second).Result()

// SET key value keepttl NX
set, err := rdb.SetNX(ctx, &quot;key&quot;, &quot;value&quot;, redis.KeepTTL).Result()

// SORT list LIMIT 0 2 ASC
vals, err := rdb.Sort(ctx, &quot;list&quot;, &amp;redis.Sort{Offset: 0, Count: 2, Order: &quot;ASC&quot;}).Result()

// ZRANGEBYSCORE zset -inf +inf WITHSCORES LIMIT 0 2
vals, err := rdb.ZRangeByScoreWithScores(ctx, &quot;zset&quot;, &amp;redis.ZRangeBy{
    Min: &quot;-inf&quot;,
    Max: &quot;+inf&quot;,
    Offset: 0,
    Count: 2,
}).Result()

// ZINTERSTORE out 2 zset1 zset2 WEIGHTS 2 3 AGGREGATE SUM
vals, err := rdb.ZInterStore(ctx, &quot;out&quot;, &amp;redis.ZStore{
    Keys: []string{&quot;zset1&quot;, &quot;zset2&quot;},
    Weights: []int64{2, 3}
}).Result()

// EVAL &quot;return {KEYS[1],ARGV[1]}&quot; 1 &quot;key&quot; &quot;hello&quot;
vals, err := rdb.Eval(ctx, &quot;return {KEYS[1],ARGV[1]}&quot;, []string{&quot;key&quot;}, &quot;hello&quot;).Result()

// custom command
res, err := rdb.Do(ctx, &quot;set&quot;, &quot;key&quot;, &quot;value&quot;).Result()
```

## Run the test

go-redis will start a redis-server and run the test cases.

The paths of redis-server bin file and redis config file are defined in `main_test.go`:

```go
var (
	redisServerBin, _  = filepath.Abs(filepath.Join(&quot;testdata&quot;, &quot;redis&quot;, &quot;src&quot;, &quot;redis-server&quot;))
	redisServerConf, _ = filepath.Abs(filepath.Join(&quot;testdata&quot;, &quot;redis&quot;, &quot;redis.conf&quot;))
)
```

For local testing, you can change the variables to refer to your local files, or create a soft link
to the corresponding folder for redis-server and copy the config file to `testdata/redis/`:

```shell
ln -s /usr/bin/redis-server ./go-redis/testdata/redis/src
cp ./go-redis/testdata/redis.conf ./go-redis/testdata/redis/
```

Lastly, run:

```shell
go test
```

Another option is to run your specific tests with an already running redis. The example below, tests
against a redis running on port 9999.:

```shell
REDIS_PORT=9999 go test &lt;your options&gt;
```

## See also

- [Golang ORM](https://bun.uptrace.dev) for PostgreSQL, MySQL, MSSQL, and SQLite
- [Golang PostgreSQL](https://bun.uptrace.dev/postgres/)
- [Golang HTTP router](https://bunrouter.uptrace.dev/)
- [Golang ClickHouse ORM](https://github.com/uptrace/go-clickhouse)

## Contributors

&gt; The go-redis project was originally initiated by :star: [**uptrace/uptrace**](https://github.com/uptrace/uptrace).
&gt; Uptrace is an open-source APM tool that supports distributed tracing, metrics, and logs. You can
&gt; use it to monitor applications and set up automatic alerts to receive notifications via email,
&gt; Slack, Telegram, and others.
&gt;
&gt; See [OpenTelemetry](https://github.com/redis/go-redis/tree/master/example/otel) example which
&gt; demonstrates how you can use Uptrace to monitor go-redis.

Thanks to all the people who already contributed!

&lt;a href=&quot;https://github.com/redis/go-redis/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=redis/go-redis&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[mark3labs/mcp-go]]></title>
            <link>https://github.com/mark3labs/mcp-go</link>
            <guid>https://github.com/mark3labs/mcp-go</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mark3labs/mcp-go">mark3labs/mcp-go</a></h1>
            <p>A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.</p>
            <p>Language: Go</p>
            <p>Stars: 2,761</p>
            <p>Forks: 226</p>
            <p>Stars today: 120 stars today</p>
            <h2>README</h2><pre>&lt;!-- omit in toc --&gt;
# MCP Go 🚀
[![Build](https://github.com/mark3labs/mcp-go/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/mark3labs/mcp-go/actions/workflows/ci.yml)
[![Go Report Card](https://goreportcard.com/badge/github.com/mark3labs/mcp-go?cache)](https://goreportcard.com/report/github.com/mark3labs/mcp-go)
[![GoDoc](https://pkg.go.dev/badge/github.com/mark3labs/mcp-go.svg)](https://pkg.go.dev/github.com/mark3labs/mcp-go)

&lt;div align=&quot;center&quot;&gt;

&lt;strong&gt;A Go implementation of the Model Context Protocol (MCP), enabling seamless integration between LLM applications and external data sources and tools.&lt;/strong&gt;

&lt;br&gt;

[![Tutorial](http://img.youtube.com/vi/qoaeYMrXJH0/0.jpg)](http://www.youtube.com/watch?v=qoaeYMrXJH0 &quot;Tutorial&quot;)

&lt;/div&gt;

```go
package main

import (
    &quot;context&quot;
    &quot;errors&quot;
    &quot;fmt&quot;

    &quot;github.com/mark3labs/mcp-go/mcp&quot;
    &quot;github.com/mark3labs/mcp-go/server&quot;
)

func main() {
    // Create MCP server
    s := server.NewMCPServer(
        &quot;Demo 🚀&quot;,
        &quot;1.0.0&quot;,
    )

    // Add tool
    tool := mcp.NewTool(&quot;hello_world&quot;,
        mcp.WithDescription(&quot;Say hello to someone&quot;),
        mcp.WithString(&quot;name&quot;,
            mcp.Required(),
            mcp.Description(&quot;Name of the person to greet&quot;),
        ),
    )

    // Add tool handler
    s.AddTool(tool, helloHandler)

    // Start the stdio server
    if err := server.ServeStdio(s); err != nil {
        fmt.Printf(&quot;Server error: %v\n&quot;, err)
    }
}

func helloHandler(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    name, ok := request.Params.Arguments[&quot;name&quot;].(string)
    if !ok {
        return nil, errors.New(&quot;name must be a string&quot;)
    }

    return mcp.NewToolResultText(fmt.Sprintf(&quot;Hello, %s!&quot;, name)), nil
}
```

That&#039;s it!

MCP Go handles all the complex protocol details and server management, so you can focus on building great tools. It aims to be high-level and easy to use.

### Key features:
* **Fast**: High-level interface means less code and faster development
* **Simple**: Build MCP servers with minimal boilerplate
* **Complete***: MCP Go aims to provide a full implementation of the core MCP specification

(\*emphasis on *aims*)

🚨 🚧 🏗️ *MCP Go is under active development, as is the MCP specification itself. Core features are working but some advanced capabilities are still in progress.* 


&lt;!-- omit in toc --&gt;
## Table of Contents

- [Installation](#installation)
- [Quickstart](#quickstart)
- [What is MCP?](#what-is-mcp)
- [Core Concepts](#core-concepts)
  - [Server](#server)
  - [Resources](#resources)
  - [Tools](#tools)
  - [Prompts](#prompts)
- [Examples](#examples)
- [Contributing](#contributing)
  - [Prerequisites](#prerequisites)
  - [Installation](#installation-1)
  - [Testing](#testing)
  - [Opening a Pull Request](#opening-a-pull-request)

## Installation

```bash
go get github.com/mark3labs/mcp-go
```

## Quickstart

Let&#039;s create a simple MCP server that exposes a calculator tool and some data:

```go
package main

import (
    &quot;context&quot;
    &quot;errors&quot;
    &quot;fmt&quot;

    &quot;github.com/mark3labs/mcp-go/mcp&quot;
    &quot;github.com/mark3labs/mcp-go/server&quot;
)

func main() {
    // Create a new MCP server
    s := server.NewMCPServer(
        &quot;Calculator Demo&quot;,
        &quot;1.0.0&quot;,
        server.WithResourceCapabilities(true, true),
        server.WithLogging(),
    )

    // Add a calculator tool
    calculatorTool := mcp.NewTool(&quot;calculate&quot;,
        mcp.WithDescription(&quot;Perform basic arithmetic operations&quot;),
        mcp.WithString(&quot;operation&quot;,
            mcp.Required(),
            mcp.Description(&quot;The operation to perform (add, subtract, multiply, divide)&quot;),
            mcp.Enum(&quot;add&quot;, &quot;subtract&quot;, &quot;multiply&quot;, &quot;divide&quot;),
        ),
        mcp.WithNumber(&quot;x&quot;,
            mcp.Required(),
            mcp.Description(&quot;First number&quot;),
        ),
        mcp.WithNumber(&quot;y&quot;,
            mcp.Required(),
            mcp.Description(&quot;Second number&quot;),
        ),
    )

    // Add the calculator handler
    s.AddTool(calculatorTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
        op := request.Params.Arguments[&quot;operation&quot;].(string)
        x := request.Params.Arguments[&quot;x&quot;].(float64)
        y := request.Params.Arguments[&quot;y&quot;].(float64)

        var result float64
        switch op {
        case &quot;add&quot;:
            result = x + y
        case &quot;subtract&quot;:
            result = x - y
        case &quot;multiply&quot;:
            result = x * y
        case &quot;divide&quot;:
            if y == 0 {
                return nil, errors.New(&quot;Cannot divide by zero&quot;)
            }
            result = x / y
        }

        return mcp.NewToolResultText(fmt.Sprintf(&quot;%.2f&quot;, result)), nil
    })

    // Start the server
    if err := server.ServeStdio(s); err != nil {
        fmt.Printf(&quot;Server error: %v\n&quot;, err)
    }
}
```
## What is MCP?

The [Model Context Protocol (MCP)](https://modelcontextprotocol.io) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way. Think of it like a web API, but specifically designed for LLM interactions. MCP servers can:

- Expose data through **Resources** (think of these sort of like GET endpoints; they are used to load information into the LLM&#039;s context)
- Provide functionality through **Tools** (sort of like POST endpoints; they are used to execute code or otherwise produce a side effect)
- Define interaction patterns through **Prompts** (reusable templates for LLM interactions)
- And more!


## Core Concepts


### Server

&lt;details&gt;
&lt;summary&gt;Show Server Examples&lt;/summary&gt;

The server is your core interface to the MCP protocol. It handles connection management, protocol compliance, and message routing:

```go
// Create a basic server
s := server.NewMCPServer(
    &quot;My Server&quot;,  // Server name
    &quot;1.0.0&quot;,     // Version
)

// Start the server using stdio
if err := server.ServeStdio(s); err != nil {
    log.Fatalf(&quot;Server error: %v&quot;, err)
}
```

&lt;/details&gt;

### Resources

&lt;details&gt;
&lt;summary&gt;Show Resource Examples&lt;/summary&gt;
Resources are how you expose data to LLMs. They can be anything - files, API responses, database queries, system information, etc. Resources can be:

- Static (fixed URI)
- Dynamic (using URI templates)

Here&#039;s a simple example of a static resource:

```go
// Static resource example - exposing a README file
resource := mcp.NewResource(
    &quot;docs://readme&quot;,
    &quot;Project README&quot;,
    mcp.WithResourceDescription(&quot;The project&#039;s README file&quot;), 
    mcp.WithMIMEType(&quot;text/markdown&quot;),
)

// Add resource with its handler
s.AddResource(resource, func(ctx context.Context, request mcp.ReadResourceRequest) ([]mcp.ResourceContents, error) {
    content, err := os.ReadFile(&quot;README.md&quot;)
    if err != nil {
        return nil, err
    }
    
    return []mcp.ResourceContents{
        mcp.TextResourceContents{
            URI:      &quot;docs://readme&quot;,
            MIMEType: &quot;text/markdown&quot;,
            Text:     string(content),
        },
    }, nil
})
```

And here&#039;s an example of a dynamic resource using a template:

```go
// Dynamic resource example - user profiles by ID
template := mcp.NewResourceTemplate(
    &quot;users://{id}/profile&quot;,
    &quot;User Profile&quot;,
    mcp.WithTemplateDescription(&quot;Returns user profile information&quot;),
    mcp.WithTemplateMIMEType(&quot;application/json&quot;),
)

// Add template with its handler
s.AddResourceTemplate(template, func(ctx context.Context, request mcp.ReadResourceRequest) ([]mcp.ResourceContents, error) {
    // Extract ID from the URI using regex matching
    // The server automatically matches URIs to templates
    userID := extractIDFromURI(request.Params.URI)
    
    profile, err := getUserProfile(userID)  // Your DB/API call here
    if err != nil {
        return nil, err
    }
    
    return []mcp.ResourceContents{
        mcp.TextResourceContents{
            URI:      request.Params.URI,
            MIMEType: &quot;application/json&quot;,
            Text:     profile,
        },
    }, nil
})
```

The examples are simple but demonstrate the core concepts. Resources can be much more sophisticated - serving multiple contents, integrating with databases or external APIs, etc.
&lt;/details&gt;

### Tools

&lt;details&gt;
&lt;summary&gt;Show Tool Examples&lt;/summary&gt;

Tools let LLMs take actions through your server. Unlike resources, tools are expected to perform computation and have side effects. They&#039;re similar to POST endpoints in a REST API.

Simple calculation example:
```go
calculatorTool := mcp.NewTool(&quot;calculate&quot;,
    mcp.WithDescription(&quot;Perform basic arithmetic calculations&quot;),
    mcp.WithString(&quot;operation&quot;,
        mcp.Required(),
        mcp.Description(&quot;The arithmetic operation to perform&quot;),
        mcp.Enum(&quot;add&quot;, &quot;subtract&quot;, &quot;multiply&quot;, &quot;divide&quot;),
    ),
    mcp.WithNumber(&quot;x&quot;,
        mcp.Required(),
        mcp.Description(&quot;First number&quot;),
    ),
    mcp.WithNumber(&quot;y&quot;,
        mcp.Required(),
        mcp.Description(&quot;Second number&quot;),
    ),
)

s.AddTool(calculatorTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    op := request.Params.Arguments[&quot;operation&quot;].(string)
    x := request.Params.Arguments[&quot;x&quot;].(float64)
    y := request.Params.Arguments[&quot;y&quot;].(float64)

    var result float64
    switch op {
    case &quot;add&quot;:
        result = x + y
    case &quot;subtract&quot;:
        result = x - y
    case &quot;multiply&quot;:
        result = x * y
    case &quot;divide&quot;:
        if y == 0 {
            return nil, errors.New(&quot;Division by zero is not allowed&quot;)
        }
        result = x / y
    }
    
    return mcp.FormatNumberResult(result), nil
})
```

HTTP request example:
```go
httpTool := mcp.NewTool(&quot;http_request&quot;,
    mcp.WithDescription(&quot;Make HTTP requests to external APIs&quot;),
    mcp.WithString(&quot;method&quot;,
        mcp.Required(),
        mcp.Description(&quot;HTTP method to use&quot;),
        mcp.Enum(&quot;GET&quot;, &quot;POST&quot;, &quot;PUT&quot;, &quot;DELETE&quot;),
    ),
    mcp.WithString(&quot;url&quot;,
        mcp.Required(),
        mcp.Description(&quot;URL to send the request to&quot;),
        mcp.Pattern(&quot;^https?://.*&quot;),
    ),
    mcp.WithString(&quot;body&quot;,
        mcp.Description(&quot;Request body (for POST/PUT)&quot;),
    ),
)

s.AddTool(httpTool, func(ctx context.Context, request mcp.CallToolRequest) (*mcp.CallToolResult, error) {
    method := request.Params.Arguments[&quot;method&quot;].(string)
    url := request.Params.Arguments[&quot;url&quot;].(string)
    body := &quot;&quot;
    if b, ok := request.Params.Arguments[&quot;body&quot;].(string); ok {
        body = b
    }

    // Create and send request
    var req *http.Request
    var err error
    if body != &quot;&quot; {
        req, err = http.NewRequest(method, url, strings.NewReader(body))
    } else {
        req, err = http.NewRequest(method, url, nil)
    }
    if err != nil {
        return nil, fmt.Errorf(&quot;Failed to create request: %v&quot;, err)
    }

    client := &amp;http.Client{}
    resp, err := client.Do(req)
    if err != nil {
        return nil, fmt.Errorf(&quot;Request failed: %v&quot;, err)
    }
    defer resp.Body.Close()

    // Return response
    respBody, err := io.ReadAll(resp.Body)
    if err != nil {
        return nil, fmt.Errorf(&quot;Failed to read response: %v&quot;, err)
    }

    return mcp.NewToolResultText(fmt.Sprintf(&quot;Status: %d\nBody: %s&quot;, resp.StatusCode, string(respBody))), nil
})
```

Tools can be used for any kind of computation or side effect:
- Database queries
- File operations  
- External API calls
- Calculations
- System operations

Each tool should:
- Have a clear description
- Validate inputs
- Handle errors gracefully 
- Return structured responses
- Use appropriate result types

&lt;/details&gt;

### Prompts

&lt;details&gt;
&lt;summary&gt;Show Prompt Examples&lt;/summary&gt;

Prompts are reusable templates that help LLMs interact with your server effectively. They&#039;re like &quot;best practices&quot; encoded into your server. Here are some examples:

```go
// Simple greeting prompt
s.AddPrompt(mcp.NewPrompt(&quot;greeting&quot;,
    mcp.WithPromptDescription(&quot;A friendly greeting prompt&quot;),
    mcp.WithArgument(&quot;name&quot;,
        mcp.ArgumentDescription(&quot;Name of the person to greet&quot;),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    name := request.Params.Arguments[&quot;name&quot;]
    if name == &quot;&quot; {
        name = &quot;friend&quot;
    }
    
    return mcp.NewGetPromptResult(
        &quot;A friendly greeting&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewTextContent(fmt.Sprintf(&quot;Hello, %s! How can I help you today?&quot;, name)),
            ),
        },
    ), nil
})

// Code review prompt with embedded resource
s.AddPrompt(mcp.NewPrompt(&quot;code_review&quot;,
    mcp.WithPromptDescription(&quot;Code review assistance&quot;),
    mcp.WithArgument(&quot;pr_number&quot;,
        mcp.ArgumentDescription(&quot;Pull request number to review&quot;),
        mcp.RequiredArgument(),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    prNumber := request.Params.Arguments[&quot;pr_number&quot;]
    if prNumber == &quot;&quot; {
        return nil, fmt.Errorf(&quot;pr_number is required&quot;)
    }
    
    return mcp.NewGetPromptResult(
        &quot;Code review assistance&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleSystem,
                mcp.NewTextContent(&quot;You are a helpful code reviewer. Review the changes and provide constructive feedback.&quot;),
            ),
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewEmbeddedResource(mcp.ResourceContents{
                    URI: fmt.Sprintf(&quot;git://pulls/%s/diff&quot;, prNumber),
                    MIMEType: &quot;text/x-diff&quot;,
                }),
            ),
        },
    ), nil
})

// Database query builder prompt
s.AddPrompt(mcp.NewPrompt(&quot;query_builder&quot;,
    mcp.WithPromptDescription(&quot;SQL query builder assistance&quot;),
    mcp.WithArgument(&quot;table&quot;,
        mcp.ArgumentDescription(&quot;Name of the table to query&quot;),
        mcp.RequiredArgument(),
    ),
), func(ctx context.Context, request mcp.GetPromptRequest) (*mcp.GetPromptResult, error) {
    tableName := request.Params.Arguments[&quot;table&quot;]
    if tableName == &quot;&quot; {
        return nil, fmt.Errorf(&quot;table name is required&quot;)
    }
    
    return mcp.NewGetPromptResult(
        &quot;SQL query builder assistance&quot;,
        []mcp.PromptMessage{
            mcp.NewPromptMessage(
                mcp.RoleSystem,
                mcp.NewTextContent(&quot;You are a SQL expert. Help construct efficient and safe queries.&quot;),
            ),
            mcp.NewPromptMessage(
                mcp.RoleAssistant,
                mcp.NewEmbeddedResource(mcp.ResourceContents{
                    URI: fmt.Sprintf(&quot;db://schema/%s&quot;, tableName),
                    MIMEType: &quot;application/json&quot;,
                }),
            ),
        },
    ), nil
})
```

Prompts can include:
- System instructions
- Required arguments
- Embedded resources
- Multiple messages
- Different content types (text, images, etc.)
- Custom URI schemes

&lt;/details&gt;

## Examples

For examples, see the `examples/` directory.

## Extras

### Request Hooks

Hook into the request lifecycle by creating a `Hooks` object with your
selection among the possible callbacks.  This enables telemetry across all
functionality, and observability of various facts, for example the ability
to count improperly-formatted requests, or to log the agent identity during
initialization.

Add the `Hooks` to the server at the time of creation using the
`server.WithHooks` option.

## Contributing

&lt;details&gt;

&lt;summary&gt;&lt;h3&gt;Open Developer Guide&lt;/h3&gt;&lt;/summary&gt;

### Prerequisites

Go version &gt;= 1.23

### Installation

Create a fork of this repository, then clone it:

```bash
git clone https://github.com/mark3labs/mcp-go.git
cd mcp-go
```

### Testing

Please make sure to test any new functionality. Your tests should be simple and atomic and anticipate change rather than cement complex patterns.

Run tests from the root directory:

```bash
go test -v &#039;./...&#039;
```

### Opening a Pull Request

Fork the repository and create a new branch:

```bash
git checkout -b my-branch
```

Make your changes and commit them:


```bash
git add . &amp;&amp; git commit -m &quot;My changes&quot;
```

Push your changes to your fork:


```bash
git push origin my-branch
```

Feel free to reach out in a GitHub issue or discussion if you have any questions!

&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[containers/podman]]></title>
            <link>https://github.com/containers/podman</link>
            <guid>https://github.com/containers/podman</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[Podman: A tool for managing OCI containers and pods.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/containers/podman">containers/podman</a></h1>
            <p>Podman: A tool for managing OCI containers and pods.</p>
            <p>Language: Go</p>
            <p>Stars: 26,227</p>
            <p>Forks: 2,587</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre>![PODMAN logo](https://raw.githubusercontent.com/containers/common/main/logos/podman-logo-full-vert.png)

# Podman: A tool for managing OCI containers and pods
![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/containers/podman)
[![Go Report Card](https://goreportcard.com/badge/github.com/containers/libpod)](https://goreportcard.com/report/github.com/containers/libpod)

&lt;br/&gt;

Podman (the POD MANager) is a tool for managing containers and images, volumes mounted into those containers, and pods made from groups of containers.
Podman runs containers on Linux, but can also be used on Mac and Windows systems using a Podman-managed virtual machine.
Podman is based on libpod, a library for container lifecycle management that is also contained in this repository. The libpod library provides APIs for managing containers, pods, container images, and volumes.

Podman releases a new major or minor release 4 times a year, during the second week of February, May, August, and November. Patch releases are more frequent and may occur at any time to get bugfixes out to users. All releases are PGP signed. Public keys of members of the team approved to make releases are located [here](https://github.com/containers/release-keys/tree/main/podman).

* Continuous Integration:
  * [![Build Status](https://api.cirrus-ci.com/github/containers/podman.svg)](https://cirrus-ci.com/github/containers/podman/main)
  * [GoDoc: ![GoDoc](https://godoc.org/github.com/containers/podman/libpod?status.svg)](https://godoc.org/github.com/containers/podman/libpod)
  * [Downloads](DOWNLOADS.md)

## Overview and scope

At a high level, the scope of Podman and libpod is the following:

* Support for multiple container image formats, including OCI and Docker images.
* Full management of those images, including pulling from various sources (including trust and verification), creating (built via Containerfile or Dockerfile or committed from a container), and pushing to registries and other storage backends.
* Full management of container lifecycle, including creation (both from an image and from an exploded root filesystem), running, checkpointing and restoring (via CRIU), and removal.
* Full management of container networking, using Netavark.
* Support for pods, groups of containers that share resources and are managed together.
* Support for running containers and pods without root or other elevated privileges.
* Resource isolation of containers and pods.
* Support for a Docker-compatible CLI interface, which can both run containers locally and on remote systems.
* No manager daemon, for improved security and lower resource utilization at idle.
* Support for a REST API providing both a Docker-compatible interface and an improved interface exposing advanced Podman functionality.
* Support for running on Windows and Mac via virtual machines run by `podman machine`.

## Roadmap

The future of Podman feature development can be found in its **[roadmap](ROADMAP.md)**.

## Communications

If you think you&#039;ve identified a security issue in the project, please *DO NOT* report the issue publicly via the GitHub issue tracker, mailing list, or IRC.
Instead, send an email with as many details as possible to `security@lists.podman.io`. This is a private mailing list for the core maintainers.

For general questions and discussion, please use Podman&#039;s
[channels](https://podman.io/community/#slack-irc-matrix-and-discord).

For discussions around issues/bugs and features, you can use the GitHub
[issues](https://github.com/containers/podman/issues)
and
[PRs](https://github.com/containers/podman/pulls)
tracking system.

There is also a [mailing list](https://lists.podman.io/archives/) at `lists.podman.io`.
You can subscribe by sending a message to `podman-join@lists.podman.io` with the subject `subscribe`.

## Rootless
Podman can be easily run as a normal user, without requiring a setuid binary.
When run without root, Podman containers use user namespaces to set root in the container to the user running Podman.
Rootless Podman runs locked-down containers with no privileges that the user running the container does not have.
Some of these restrictions can be lifted (via `--privileged`, for example), but rootless containers will never have more privileges than the user that launched them.
If you run Podman as your user and mount in `/etc/passwd` from the host, you still won&#039;t be able to change it, since your user doesn&#039;t have permission to do so.

Almost all normal Podman functionality is available, though there are some [shortcomings](https://github.com/containers/podman/blob/main/rootless.md).
Any recent Podman release should be able to run rootless without any additional configuration, though your operating system may require some additional configuration detailed in the [install guide](https://podman.io/getting-started/installation).

A little configuration by an administrator is required before rootless Podman can be used, the necessary setup is documented [here](https://github.com/containers/podman/blob/main/docs/tutorials/rootless_tutorial.md).

## Podman Desktop

[Podman Desktop](https://podman-desktop.io/) provides a local development environment for Podman and Kubernetes on Linux, Windows, and Mac machines.
It is a full-featured desktop UI frontend for Podman which uses the `podman machine` backend on non-Linux operating systems to run containers.
It supports full container lifecycle management (building, pulling, and pushing images, creating and managing containers, creating and managing pods, and working with Kubernetes YAML).
The project develops on [GitHub](https://github.com/containers/podman-desktop) and contributions are welcome.

## Out of scope

* Specialized signing and pushing of images to various storage backends.
  See [Skopeo](https://github.com/containers/skopeo/) for those tasks.
* Support for the Kubernetes CRI interface for container management.
  The [CRI-O](https://github.com/cri-o/cri-o) daemon specializes in that.

## OCI Projects Plans

Podman uses OCI projects and best of breed libraries for different aspects:
- Runtime: We use the [OCI runtime tools](https://github.com/opencontainers/runtime-tools) to generate OCI runtime configurations that can be used with any OCI-compliant runtime, like [crun](https://github.com/containers/crun/) and [runc](https://github.com/opencontainers/runc/).
- Images: Image management uses the [containers/image](https://github.com/containers/image) library.
- Storage: Container and image storage is managed by [containers/storage](https://github.com/containers/storage).
- Networking: Networking support through use of [Netavark](https://github.com/containers/netavark) and [Aardvark](https://github.com/containers/aardvark-dns).  Rootless networking is handled via [pasta](https://passt.top/passt) or [slirp4netns](https://github.com/rootless-containers/slirp4netns).
- Builds: Builds are supported via [Buildah](https://github.com/containers/buildah).
- Conmon: [Conmon](https://github.com/containers/conmon) is a tool for monitoring OCI runtimes, used by both Podman and CRI-O.
- Seccomp: A unified [Seccomp](https://github.com/containers/common/blob/main/pkg/seccomp/seccomp.json) policy for Podman, Buildah, and CRI-O.

## Podman Information for Developers

For blogs, release announcements and more, please checkout the [podman.io](https://podman.io) website!

**[Installation notes](install.md)**
Information on how to install Podman in your environment.

**[OCI Hooks Support](https://github.com/containers/common/blob/main/pkg/hooks/README.md)**
Information on how Podman configures [OCI Hooks][spec-hooks] to run when launching a container.

**[Podman API](https://docs.podman.io/en/latest/_static/api.html)**
Documentation on the Podman REST API.

**[Podman Commands](https://podman.readthedocs.io/en/latest/Commands.html)**
A list of the Podman commands with links to their man pages and in many cases videos
showing the commands in use.

**[Podman Container Images](https://github.com/containers/image_build/blob/main/podman/README.md)**
Information on the Podman Container Images found on [quay.io](https://quay.io/podman/stable).

**[Podman Troubleshooting Guide](troubleshooting.md)**
A list of common issues and solutions for Podman.

**[Podman Usage Transfer](transfer.md)**
Useful information for ops and dev transfer as it relates to infrastructure that utilizes Podman.  This page
includes tables showing Docker commands and their Podman equivalent commands.

**[Tutorials](docs/tutorials)**
Tutorials on using Podman.

**[Remote Client](https://github.com/containers/podman/blob/main/docs/tutorials/remote_client.md)**
A brief how-to on using the Podman remote client.

**[Basic Setup and Use of Podman in a Rootless environment](https://github.com/containers/podman/blob/main/docs/tutorials/rootless_tutorial.md)**
A tutorial showing the setup and configuration necessary to run Rootless Podman.

**[Release Notes](RELEASE_NOTES.md)**
Release notes for recent Podman versions.

**[Contributing](CONTRIBUTING.md)**
Information about contributing to this project.

[spec-hooks]: https://github.com/opencontainers/runtime-spec/blob/v1.0.2/config.md#posix-platform-hooks

## Buildah and Podman relationship

Buildah and Podman are two complementary open-source projects that are
available on most Linux platforms and both projects reside at
[GitHub.com](https://github.com) with Buildah
[here](https://github.com/containers/buildah) and Podman
[here](https://github.com/containers/podman).  Both, Buildah and Podman are
command line tools that work on Open Container Initiative (OCI) images and
containers.  The two projects differentiate in their specialization.

Buildah specializes in building OCI images.  Buildah&#039;s commands replicate all
of the commands that are found in a Dockerfile.  This allows building images
with and without Dockerfiles while not requiring any root privileges.
Buildah’s ultimate goal is to provide a lower-level coreutils interface to
build images.  The flexibility of building images without Dockerfiles allows
for the integration of other scripting languages into the build process.
Buildah follows a simple fork-exec model and does not run as a daemon
but it is based on a comprehensive API in golang, which can be vendored
into other tools.

Podman specializes in all of the commands and functions that help you to maintain and modify
OCI images, such as pulling and tagging.  It also allows you to create, run, and maintain those containers
created from those images.  For building container images via Dockerfiles, Podman uses Buildah&#039;s
golang API and can be installed independently from Buildah.

A major difference between Podman and Buildah is their concept of a container.  Podman
allows users to create &quot;traditional containers&quot; where the intent of these containers is
to be long lived.  While Buildah containers are really just created to allow content
to be added back to the container image.  An easy way to think of it is the
`buildah run` command emulates the RUN command in a Dockerfile while the `podman run`
command emulates the `docker run` command in functionality.  Because of this and their underlying
storage differences, you can not see Podman containers from within Buildah or vice versa.

In short, Buildah is an efficient way to create OCI images while Podman allows
you to manage and maintain those images and containers in a production environment using
familiar container cli commands.  For more details, see the
[Container Tools Guide](https://github.com/containers/buildah/tree/main/docs/containertools).

## Podman Hello
```
$ podman run quay.io/podman/hello
Trying to pull quay.io/podman/hello:latest...
Getting image source signatures
Copying blob a6b3126f3807 done
Copying config 25c667d086 done
Writing manifest to image destination
Storing signatures
!... Hello Podman World ...!

         .--&quot;--.
       / -     - \
      / (O)   (O) \
   ~~~| -=(,Y,)=- |
    .---. /`  \   |~~
 ~/  o  o \~~~~.----. ~~
  | =(X)= |~  / (O (O) \
   ~~~~~~~  ~| =(Y_)=-  |
  ~~~~    ~~~|   U      |~~

Project:   https://github.com/containers/podman
Website:   https://podman.io
Documents: https://docs.podman.io
Twitter:   @Podman_io
```
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[oauth2-proxy/oauth2-proxy]]></title>
            <link>https://github.com/oauth2-proxy/oauth2-proxy</link>
            <guid>https://github.com/oauth2-proxy/oauth2-proxy</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oauth2-proxy/oauth2-proxy">oauth2-proxy/oauth2-proxy</a></h1>
            <p>A reverse proxy that provides authentication with Google, Azure, OpenID Connect and many more identity providers.</p>
            <p>Language: Go</p>
            <p>Stars: 10,869</p>
            <p>Forks: 1,673</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>[![Continuous Integration](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yaml/badge.svg)](https://github.com/oauth2-proxy/oauth2-proxy/actions/workflows/ci.yaml)
[![Go Report Card](https://goreportcard.com/badge/github.com/oauth2-proxy/oauth2-proxy)](https://goreportcard.com/report/github.com/oauth2-proxy/oauth2-proxy)
[![GoDoc](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy?status.svg)](https://godoc.org/github.com/oauth2-proxy/oauth2-proxy)
[![MIT licensed](https://img.shields.io/badge/license-MIT-blue.svg)](./LICENSE)
[![Maintainability](https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/maintainability)](https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/maintainability)
[![Test Coverage](https://api.codeclimate.com/v1/badges/a58ff79407212e2beacb/test_coverage)](https://codeclimate.com/github/oauth2-proxy/oauth2-proxy/test_coverage)

![OAuth2 Proxy](docs/static/img/logos/OAuth2_Proxy_horizontal.svg)

OAuth2-Proxy is a flexible, open-source tool that can act as either a standalone reverse proxy or a middleware component integrated into existing reverse proxy or load balancer setups. It provides a simple and secure way to protect your web applications with OAuth2 / OIDC authentication. As a reverse proxy, it intercepts requests to your application and redirects users to an OAuth2 provider for authentication. As a middleware, it can be seamlessly integrated into your existing infrastructure to handle authentication for multiple applications.

OAuth2-Proxy supports a lot of OAuth2 as well as OIDC providers. Either through a generic OIDC client or a specific implementation for Google, Microsoft Entra ID, GitHub, login.gov and others. Through specialised provider implementations oauth2-proxy can extract more details about the user like preferred usernames and groups. Those details can then be forwarded as HTTP headers to your upstream applications.

![Simplified Architecture](docs/static/img/simplified-architecture.svg)

## Get Started

OAuth2-Proxy&#039;s [Installation Docs](https://oauth2-proxy.github.io/oauth2-proxy/installation) cover how to install and configure your setup. Additionally you can take a further look at the [example setup files](https://github.com/oauth2-proxy/oauth2-proxy/tree/master/contrib/local-environment).

## Releases

### Binaries
We publish oauth2-proxy as compiled binaries on GitHub for all major architectures as well as more exotic ones like `ppc64le` as well as `s390x`.

Check out the [latest release](https://github.com/oauth2-proxy/oauth2-proxy/releases/latest).

### Images

From `v7.6.0` and up the base image has been changed from Alpine to [GoogleContainerTools/distroless](https://github.com/GoogleContainerTools/distroless).
This image comes with even fewer installed dependencies and thus should improve security. The image therefore is also slightly smaller than Alpine.
For debugging purposes (and those who really need it. e.g. `armv6`) we still provide images based on Alpine. The tags of these images are suffixed with `-alpine`.

Since 2023-11-18 we build nightly images directly from the `master` branch and provide them at `quay.io/oauth2-proxy/oauth2-proxy-nightly`.
These images are considered unstable and therefore should **NOT** be used for production purposes unless you know what you&#039;re doing.

## Sponsors

![Microsoft](https://upload.wikimedia.org/wikipedia/commons/9/96/Microsoft_logo_%282012%29.svg)
Microsoft Azure credits for open source projects

Would you like to sponsor the project then please contact us at [sponsors@oauth2-proxy.dev](mailto:sponsors@oauth2-proxy.dev)

## Getting Involved
[![Slack](https://img.shields.io/badge/slack-Gopher_%23oauth2--proxy-red?logo=slack)](https://gophers.slack.com/archives/CM2RSS25N)

Join the #oauth2-proxy [Slack channel](https://gophers.slack.com/archives/CM2RSS25N) to chat with other users of oauth2-proxy or reach out to the maintainers directly. Use the [public invite link](https://invite.slack.golangbridge.org/) to get an invite for the Gopher Slack space.

OAuth2-Proxy is a community-driven project. We rely on the contribut️ions of our users to continually improve it. While review times can vary, we appreciate your patience and understanding. As a volunteer-driven project, we strive to keep this project stable and might take longer to merge changes.

If you want to contribute to the project. Please see our [Contributing](https://oauth2-proxy.github.io/oauth2-proxy/community/contribution) guide.

Who uses OAuth2-Proxy? Have a look at our new [ADOPTERS](ADOPTERS.md) file and
feel free to open a PR to add your organisation.

Thanks to all the people who already contributed ❤

&lt;a href=&quot;https://github.com/oauth2-proxy/oauth2-proxy/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=oauth2-proxy/oauth2-proxy&amp;columns=15&amp;max=75&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/github/contributors/oauth2-proxy/oauth2-proxy&quot; /&gt;
&lt;/a&gt;

Made with [contrib.rocks](https://contrib.rocks).

## Security

If you believe you have found a vulnerability within OAuth2 Proxy or any of its dependencies, please do **NOT** open an issue or PR on GitHub, please do **NOT** post any details publicly.

Security disclosures **MUST** be done in private. If you have found an issue that you would like to bring to the attention of the maintainers, please compose an email and send it to the list of people listed in our [MAINTAINERS](MAINTAINERS) file.

For more details read our full [Security Docs](https://oauth2-proxy.github.io/oauth2-proxy/community/security#security-disclosures)

### Security Notice for v6.0.0 and older

If you are running a version older than v6.0.0 we **strongly recommend** to the current version.

See [open redirect vulnerability](https://github.com/oauth2-proxy/oauth2-proxy/security/advisories/GHSA-5m6c-jp6f-2vcv) for details.

## Repository History

**2018-11-27:** This repository was forked from [bitly/OAuth2_Proxy](https://github.com/bitly/oauth2_proxy). Versions v3.0.0 and up are from this fork and will have diverged from any changes in the original fork. A list of changes can be seen in the [CHANGELOG](CHANGELOG.md).

**2020-03-29:** This project was formerly hosted as `pusher/oauth2_proxy` but has been renamed to `oauth2-proxy/oauth2-proxy`. Going forward, all images shall be available at `quay.io/oauth2-proxy/oauth2-proxy` and binaries will be named `oauth2-proxy`.

## License

OAuth2-Proxy is distributed under [The MIT License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[segmentio/kafka-go]]></title>
            <link>https://github.com/segmentio/kafka-go</link>
            <guid>https://github.com/segmentio/kafka-go</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[Kafka library in Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/segmentio/kafka-go">segmentio/kafka-go</a></h1>
            <p>Kafka library in Go</p>
            <p>Language: Go</p>
            <p>Stars: 7,888</p>
            <p>Forks: 802</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># kafka-go [![CircleCI](https://circleci.com/gh/segmentio/kafka-go.svg?style=shield)](https://circleci.com/gh/segmentio/kafka-go) [![Go Report Card](https://goreportcard.com/badge/github.com/segmentio/kafka-go)](https://goreportcard.com/report/github.com/segmentio/kafka-go) [![GoDoc](https://godoc.org/github.com/segmentio/kafka-go?status.svg)](https://godoc.org/github.com/segmentio/kafka-go)

## Motivations

We rely on both Go and Kafka a lot at Segment. Unfortunately, the state of the Go
client libraries for Kafka at the time of this writing was not ideal. The available
options were:

- [sarama](https://github.com/Shopify/sarama), which is by far the most popular
but is quite difficult to work with. It is poorly documented, the API exposes
low level concepts of the Kafka protocol, and it doesn&#039;t support recent Go features
like [contexts](https://golang.org/pkg/context/). It also passes all values as
pointers which causes large numbers of dynamic memory allocations, more frequent
garbage collections, and higher memory usage.

- [confluent-kafka-go](https://github.com/confluentinc/confluent-kafka-go) is a
cgo based wrapper around [librdkafka](https://github.com/edenhill/librdkafka),
which means it introduces a dependency to a C library on all Go code that uses
the package. It has much better documentation than sarama but still lacks support
for Go contexts.

- [goka](https://github.com/lovoo/goka) is a more recent Kafka client for Go
which focuses on a specific usage pattern. It provides abstractions for using Kafka
as a message passing bus between services rather than an ordered log of events, but
this is not the typical use case of Kafka for us at Segment. The package also
depends on sarama for all interactions with Kafka.

This is where `kafka-go` comes into play. It provides both low and high level
APIs for interacting with Kafka, mirroring concepts and implementing interfaces of
the Go standard library to make it easy to use and integrate with existing
software.

#### Note:

In order to better align with our newly adopted Code of Conduct, the kafka-go
project has renamed our default branch to `main`. For the full details of our
Code Of Conduct see [this](./CODE_OF_CONDUCT.md) document.

## Kafka versions

`kafka-go` is currently tested with Kafka versions 0.10.1.0 to 2.7.1.
While it should also be compatible with later versions, newer features available
in the Kafka API may not yet be implemented in the client.

## Go versions

`kafka-go` requires Go version 1.15 or later.

## Connection [![GoDoc](https://godoc.org/github.com/segmentio/kafka-go?status.svg)](https://godoc.org/github.com/segmentio/kafka-go#Conn)

The `Conn` type is the core of the `kafka-go` package. It wraps around a raw
network connection to expose a low-level API to a Kafka server.

Here are some examples showing typical use of a connection object:
```go
// to produce messages
topic := &quot;my-topic&quot;
partition := 0

conn, err := kafka.DialLeader(context.Background(), &quot;tcp&quot;, &quot;localhost:9092&quot;, topic, partition)
if err != nil {
    log.Fatal(&quot;failed to dial leader:&quot;, err)
}

conn.SetWriteDeadline(time.Now().Add(10*time.Second))
_, err = conn.WriteMessages(
    kafka.Message{Value: []byte(&quot;one!&quot;)},
    kafka.Message{Value: []byte(&quot;two!&quot;)},
    kafka.Message{Value: []byte(&quot;three!&quot;)},
)
if err != nil {
    log.Fatal(&quot;failed to write messages:&quot;, err)
}

if err := conn.Close(); err != nil {
    log.Fatal(&quot;failed to close writer:&quot;, err)
}
```
```go
// to consume messages
topic := &quot;my-topic&quot;
partition := 0

conn, err := kafka.DialLeader(context.Background(), &quot;tcp&quot;, &quot;localhost:9092&quot;, topic, partition)
if err != nil {
    log.Fatal(&quot;failed to dial leader:&quot;, err)
}

conn.SetReadDeadline(time.Now().Add(10*time.Second))
batch := conn.ReadBatch(10e3, 1e6) // fetch 10KB min, 1MB max

b := make([]byte, 10e3) // 10KB max per message
for {
    n, err := batch.Read(b)
    if err != nil {
        break
    }
    fmt.Println(string(b[:n]))
}

if err := batch.Close(); err != nil {
    log.Fatal(&quot;failed to close batch:&quot;, err)
}

if err := conn.Close(); err != nil {
    log.Fatal(&quot;failed to close connection:&quot;, err)
}
```

### To Create Topics
By default kafka has the `auto.create.topics.enable=&#039;true&#039;` (`KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=&#039;true&#039;` in the bitnami/kafka kafka docker image). If this value is set to `&#039;true&#039;` then topics will be created as a side effect of `kafka.DialLeader` like so:
```go
// to create topics when auto.create.topics.enable=&#039;true&#039;
conn, err := kafka.DialLeader(context.Background(), &quot;tcp&quot;, &quot;localhost:9092&quot;, &quot;my-topic&quot;, 0)
if err != nil {
    panic(err.Error())
}
```

If `auto.create.topics.enable=&#039;false&#039;` then you will need to create topics explicitly like so:
```go
// to create topics when auto.create.topics.enable=&#039;false&#039;
topic := &quot;my-topic&quot;

conn, err := kafka.Dial(&quot;tcp&quot;, &quot;localhost:9092&quot;)
if err != nil {
    panic(err.Error())
}
defer conn.Close()

controller, err := conn.Controller()
if err != nil {
    panic(err.Error())
}
var controllerConn *kafka.Conn
controllerConn, err = kafka.Dial(&quot;tcp&quot;, net.JoinHostPort(controller.Host, strconv.Itoa(controller.Port)))
if err != nil {
    panic(err.Error())
}
defer controllerConn.Close()


topicConfigs := []kafka.TopicConfig{
    {
        Topic:             topic,
        NumPartitions:     1,
        ReplicationFactor: 1,
    },
}

err = controllerConn.CreateTopics(topicConfigs...)
if err != nil {
    panic(err.Error())
}
```

### To Connect To Leader Via a Non-leader Connection
```go
// to connect to the kafka leader via an existing non-leader connection rather than using DialLeader
conn, err := kafka.Dial(&quot;tcp&quot;, &quot;localhost:9092&quot;)
if err != nil {
    panic(err.Error())
}
defer conn.Close()
controller, err := conn.Controller()
if err != nil {
    panic(err.Error())
}
var connLeader *kafka.Conn
connLeader, err = kafka.Dial(&quot;tcp&quot;, net.JoinHostPort(controller.Host, strconv.Itoa(controller.Port)))
if err != nil {
    panic(err.Error())
}
defer connLeader.Close()
```

### To list topics
```go
conn, err := kafka.Dial(&quot;tcp&quot;, &quot;localhost:9092&quot;)
if err != nil {
    panic(err.Error())
}
defer conn.Close()

partitions, err := conn.ReadPartitions()
if err != nil {
    panic(err.Error())
}

m := map[string]struct{}{}

for _, p := range partitions {
    m[p.Topic] = struct{}{}
}
for k := range m {
    fmt.Println(k)
}
```


Because it is low level, the `Conn` type turns out to be a great building block
for higher level abstractions, like the `Reader` for example.

## Reader [![GoDoc](https://godoc.org/github.com/segmentio/kafka-go?status.svg)](https://godoc.org/github.com/segmentio/kafka-go#Reader)

A `Reader` is another concept exposed by the `kafka-go` package, which intends
to make it simpler to implement the typical use case of consuming from a single
topic-partition pair.
A `Reader` also automatically handles reconnections and offset management, and
exposes an API that supports asynchronous cancellations and timeouts using Go
contexts.

Note that it is important to call `Close()` on a `Reader` when a process exits.
The kafka server needs a graceful disconnect to stop it from continuing to
attempt to send messages to the connected clients. The given example will not
call `Close()` if the process is terminated with SIGINT (ctrl-c at the shell) or
SIGTERM (as docker stop or a kubernetes restart does). This can result in a
delay when a new reader on the same topic connects (e.g. new process started
or new container running). Use a `signal.Notify` handler to close the reader on
process shutdown.

```go
// make a new reader that consumes from topic-A, partition 0, at offset 42
r := kafka.NewReader(kafka.ReaderConfig{
    Brokers:   []string{&quot;localhost:9092&quot;,&quot;localhost:9093&quot;, &quot;localhost:9094&quot;},
    Topic:     &quot;topic-A&quot;,
    Partition: 0,
    MaxBytes:  10e6, // 10MB
})
r.SetOffset(42)

for {
    m, err := r.ReadMessage(context.Background())
    if err != nil {
        break
    }
    fmt.Printf(&quot;message at offset %d: %s = %s\n&quot;, m.Offset, string(m.Key), string(m.Value))
}

if err := r.Close(); err != nil {
    log.Fatal(&quot;failed to close reader:&quot;, err)
}
```

### Consumer Groups

```kafka-go``` also supports Kafka consumer groups including broker managed offsets.
To enable consumer groups, simply specify the GroupID in the ReaderConfig.

ReadMessage automatically commits offsets when using consumer groups.

```go
// make a new reader that consumes from topic-A
r := kafka.NewReader(kafka.ReaderConfig{
    Brokers:   []string{&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;},
    GroupID:   &quot;consumer-group-id&quot;,
    Topic:     &quot;topic-A&quot;,
    MaxBytes:  10e6, // 10MB
})

for {
    m, err := r.ReadMessage(context.Background())
    if err != nil {
        break
    }
    fmt.Printf(&quot;message at topic/partition/offset %v/%v/%v: %s = %s\n&quot;, m.Topic, m.Partition, m.Offset, string(m.Key), string(m.Value))
}

if err := r.Close(); err != nil {
    log.Fatal(&quot;failed to close reader:&quot;, err)
}
```

There are a number of limitations when using consumer groups:

* ```(*Reader).SetOffset``` will return an error when GroupID is set
* ```(*Reader).Offset``` will always return ```-1``` when GroupID is set
* ```(*Reader).Lag``` will always return ```-1``` when GroupID is set
* ```(*Reader).ReadLag``` will return an error when GroupID is set
* ```(*Reader).Stats``` will return a partition of ```-1``` when GroupID is set

### Explicit Commits

```kafka-go``` also supports explicit commits.  Instead of calling ```ReadMessage```,
call ```FetchMessage``` followed by ```CommitMessages```.

```go
ctx := context.Background()
for {
    m, err := r.FetchMessage(ctx)
    if err != nil {
        break
    }
    fmt.Printf(&quot;message at topic/partition/offset %v/%v/%v: %s = %s\n&quot;, m.Topic, m.Partition, m.Offset, string(m.Key), string(m.Value))
    if err := r.CommitMessages(ctx, m); err != nil {
        log.Fatal(&quot;failed to commit messages:&quot;, err)
    }
}
```

When committing messages in consumer groups, the message with the highest offset
for a given topic/partition determines the value of the committed offset for
that partition. For example, if messages at offset 1, 2, and 3 of a single
partition were retrieved by call to `FetchMessage`, calling `CommitMessages`
with message offset 3 will also result in committing the messages at offsets 1
and 2 for that partition.

### Managing Commits

By default, CommitMessages will synchronously commit offsets to Kafka.  For
improved performance, you can instead periodically commit offsets to Kafka
by setting CommitInterval on the ReaderConfig.


```go
// make a new reader that consumes from topic-A
r := kafka.NewReader(kafka.ReaderConfig{
    Brokers:        []string{&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;},
    GroupID:        &quot;consumer-group-id&quot;,
    Topic:          &quot;topic-A&quot;,
    MaxBytes:       10e6, // 10MB
    CommitInterval: time.Second, // flushes commits to Kafka every second
})
```

## Writer [![GoDoc](https://godoc.org/github.com/segmentio/kafka-go?status.svg)](https://godoc.org/github.com/segmentio/kafka-go#Writer)

To produce messages to Kafka, a program may use the low-level `Conn` API, but
the package also provides a higher level `Writer` type which is more appropriate
to use in most cases as it provides additional features:

- Automatic retries and reconnections on errors.
- Configurable distribution of messages across available partitions.
- Synchronous or asynchronous writes of messages to Kafka.
- Asynchronous cancellation using contexts.
- Flushing of pending messages on close to support graceful shutdowns.
- Creation of a missing topic before publishing a message. *Note!* it was the default behaviour up to the version `v0.4.30`.

```go
// make a writer that produces to topic-A, using the least-bytes distribution
w := &amp;kafka.Writer{
	Addr:     kafka.TCP(&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;),
	Topic:   &quot;topic-A&quot;,
	Balancer: &amp;kafka.LeastBytes{},
}

err := w.WriteMessages(context.Background(),
	kafka.Message{
		Key:   []byte(&quot;Key-A&quot;),
		Value: []byte(&quot;Hello World!&quot;),
	},
	kafka.Message{
		Key:   []byte(&quot;Key-B&quot;),
		Value: []byte(&quot;One!&quot;),
	},
	kafka.Message{
		Key:   []byte(&quot;Key-C&quot;),
		Value: []byte(&quot;Two!&quot;),
	},
)
if err != nil {
    log.Fatal(&quot;failed to write messages:&quot;, err)
}

if err := w.Close(); err != nil {
    log.Fatal(&quot;failed to close writer:&quot;, err)
}
```

### Missing topic creation before publication

```go
// Make a writer that publishes messages to topic-A.
// The topic will be created if it is missing.
w := &amp;Writer{
    Addr:                   kafka.TCP(&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;),
    Topic:                  &quot;topic-A&quot;,
    AllowAutoTopicCreation: true,
}

messages := []kafka.Message{
    {
        Key:   []byte(&quot;Key-A&quot;),
        Value: []byte(&quot;Hello World!&quot;),
    },
    {
        Key:   []byte(&quot;Key-B&quot;),
        Value: []byte(&quot;One!&quot;),
    },
    {
        Key:   []byte(&quot;Key-C&quot;),
        Value: []byte(&quot;Two!&quot;),
    },
}

var err error
const retries = 3
for i := 0; i &lt; retries; i++ {
    ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
    defer cancel()
    
    // attempt to create topic prior to publishing the message
    err = w.WriteMessages(ctx, messages...)
    if errors.Is(err, kafka.LeaderNotAvailable) || errors.Is(err, context.DeadlineExceeded) {
        time.Sleep(time.Millisecond * 250)
        continue
    }

    if err != nil {
        log.Fatalf(&quot;unexpected error %v&quot;, err)
    }
    break
}

if err := w.Close(); err != nil {
    log.Fatal(&quot;failed to close writer:&quot;, err)
}
```

### Writing to multiple topics

Normally, the `WriterConfig.Topic` is used to initialize a single-topic writer.
By excluding that particular configuration, you are given the ability to define
the topic on a per-message basis by setting `Message.Topic`.

```go
w := &amp;kafka.Writer{
	Addr:     kafka.TCP(&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;),
    // NOTE: When Topic is not defined here, each Message must define it instead.
	Balancer: &amp;kafka.LeastBytes{},
}

err := w.WriteMessages(context.Background(),
    // NOTE: Each Message has Topic defined, otherwise an error is returned.
	kafka.Message{
        Topic: &quot;topic-A&quot;,
		Key:   []byte(&quot;Key-A&quot;),
		Value: []byte(&quot;Hello World!&quot;),
	},
	kafka.Message{
        Topic: &quot;topic-B&quot;,
		Key:   []byte(&quot;Key-B&quot;),
		Value: []byte(&quot;One!&quot;),
	},
	kafka.Message{
        Topic: &quot;topic-C&quot;,
		Key:   []byte(&quot;Key-C&quot;),
		Value: []byte(&quot;Two!&quot;),
	},
)
if err != nil {
    log.Fatal(&quot;failed to write messages:&quot;, err)
}

if err := w.Close(); err != nil {
    log.Fatal(&quot;failed to close writer:&quot;, err)
}
```

**NOTE:** These 2 patterns are mutually exclusive, if you set `Writer.Topic`,
you must not also explicitly define `Message.Topic` on the messages you are
writing. The opposite applies when you do not define a topic for the writer.
The `Writer` will return an error if it detects this ambiguity.

### Compatibility with other clients

#### Sarama

If you&#039;re switching from Sarama and need/want to use the same algorithm for message partitioning, you can either use 
the `kafka.Hash` balancer or the `kafka.ReferenceHash` balancer:
* `kafka.Hash` = `sarama.NewHashPartitioner`
* `kafka.ReferenceHash` = `sarama.NewReferenceHashPartitioner`

The `kafka.Hash` and `kafka.ReferenceHash` balancers would route messages to the same partitions that the two 
aforementioned Sarama partitioners would route them to.

```go
w := &amp;kafka.Writer{
	Addr:     kafka.TCP(&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;),
	Topic:    &quot;topic-A&quot;,
	Balancer: &amp;kafka.Hash{},
}
```

#### librdkafka and confluent-kafka-go

Use the ```kafka.CRC32Balancer``` balancer to get the same behaviour as librdkafka&#039;s
default ```consistent_random``` partition strategy.

```go
w := &amp;kafka.Writer{
	Addr:     kafka.TCP(&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;),
	Topic:    &quot;topic-A&quot;,
	Balancer: kafka.CRC32Balancer{},
}
```

#### Java

Use the ```kafka.Murmur2Balancer``` balancer to get the same behaviour as the canonical
Java client&#039;s default partitioner.  Note: the Java class allows you to directly specify
the partition which is not permitted.

```go
w := &amp;kafka.Writer{
	Addr:     kafka.TCP(&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;),
	Topic:    &quot;topic-A&quot;,
	Balancer: kafka.Murmur2Balancer{},
}
```

### Compression

Compression can be enabled on the `Writer` by setting the `Compression` field:

```go
w := &amp;kafka.Writer{
	Addr:        kafka.TCP(&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;),
	Topic:       &quot;topic-A&quot;,
	Compression: kafka.Snappy,
}
```

The `Reader` will by determine if the consumed messages are compressed by
examining the message attributes.  However, the package(s) for all expected
codecs must be imported so that they get loaded correctly.

_Note: in versions prior to 0.4 programs had to import compression packages to
install codecs and support reading compressed messages from kafka. This is no
longer the case and import of the compression packages are now no-ops._

## TLS Support

For a bare bones Conn type or in the Reader/Writer configs you can specify a dialer option for TLS support. If the TLS field is nil, it will not connect with TLS.
*Note:* Connecting to a Kafka cluster with TLS enabled without configuring TLS on the Conn/Reader/Writer can manifest in opaque io.ErrUnexpectedEOF errors.


### Connection

```go
dialer := &amp;kafka.Dialer{
    Timeout:   10 * time.Second,
    DualStack: true,
    TLS:       &amp;tls.Config{...tls config...},
}

conn, err := dialer.DialContext(ctx, &quot;tcp&quot;, &quot;localhost:9093&quot;)
```

### Reader

```go
dialer := &amp;kafka.Dialer{
    Timeout:   10 * time.Second,
    DualStack: true,
    TLS:       &amp;tls.Config{...tls config...},
}

r := kafka.NewReader(kafka.ReaderConfig{
    Brokers:        []string{&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;},
    GroupID:        &quot;consumer-group-id&quot;,
    Topic:          &quot;topic-A&quot;,
    Dialer:         dialer,
})
```

### Writer


Direct Writer creation

```go
w := kafka.Writer{
    Addr: kafka.TCP(&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;), 
    Topic:   &quot;topic-A&quot;,
    Balancer: &amp;kafka.Hash{},
    Transport: &amp;kafka.Transport{
        TLS: &amp;tls.Config{},
      },
    }
```

Using `kafka.NewWriter`

```go
dialer := &amp;kafka.Dialer{
    Timeout:   10 * time.Second,
    DualStack: true,
    TLS:       &amp;tls.Config{...tls config...},
}

w := kafka.NewWriter(kafka.WriterConfig{
	Brokers: []string{&quot;localhost:9092&quot;, &quot;localhost:9093&quot;, &quot;localhost:9094&quot;},
	Topic:   &quot;topic-A&quot;,
	Balancer: &amp;kafka.Hash{},
	Dialer:   dialer,
})
```
Note that `kafka.NewWriter` and `kafka.WriterConfig` are deprecated and will be removed in a future release.

## SASL Support

You can specify an option on the `Dialer` to use SASL authentication. The `Dialer` can be used directly to open a `Conn` or it can be passed to a `Reader` or `Writer` via their respective configs. If the `SASLMechanism` field is `nil`, it will not authenticate with SASL.

### SASL Authentication Types

#### [Plain](https://godoc.org/github.com/segmentio/kafka-go/sasl/plain#Mechanism)
```go
mechanism := plain.Mechanism{
    Username: &quot;username&quot;,
    Password: &quot;password&quot;,
}
```

#### [SCRAM](https://godoc.org/github.com/segmentio/kafka-go/sasl/scram#Mechanism)
```go
mechanism, err := scram.Mechanism(scram.SHA512, &quot;username&quot;, &quot;password&quot;)
if err != nil {
    panic(err)
}
```

### Connection

```go
mechanism, err := scram.Mechanism(scram.SHA512, &quot;username&quot;, &quot;password&quot;)
if err != nil {
    panic(err)
}

dialer := &amp;kafka.Dialer{
    Timeout:       10 * time.Second,
    DualStack:     true,
    SASLMechanism: mechanism,
}

conn, err := dialer.DialContext(ctx, &quot;tcp&quot;, &quot;localhost:9093&quot;)
```


### Reader

```go
mechanism, err := scram.Mechanism(scram.SHA512, &quot;username&quot;, &quot;password&quot;)
if err != nil {
    panic(err)
}

dialer := &amp;kafka.Dialer{
    Timeout:       10 * time.Second,
    DualStack:     true,
    SASLMechanism: mechanism,
}

r := kafka.NewReader(kafka.ReaderConfig{
    Brokers:        []string{

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[docker/buildx]]></title>
            <link>https://github.com/docker/buildx</link>
            <guid>https://github.com/docker/buildx</guid>
            <pubDate>Thu, 10 Apr 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[Docker CLI plugin for extended build capabilities with BuildKit]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/buildx">docker/buildx</a></h1>
            <p>Docker CLI plugin for extended build capabilities with BuildKit</p>
            <p>Language: Go</p>
            <p>Stars: 3,842</p>
            <p>Forks: 526</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># buildx

[![GitHub release](https://img.shields.io/github/release/docker/buildx.svg?style=flat-square)](https://github.com/docker/buildx/releases/latest)
[![PkgGoDev](https://img.shields.io/badge/go.dev-docs-007d9c?style=flat-square&amp;logo=go&amp;logoColor=white)](https://pkg.go.dev/github.com/docker/buildx)
[![Build Status](https://img.shields.io/github/actions/workflow/status/docker/buildx/build.yml?branch=master&amp;label=build&amp;logo=github&amp;style=flat-square)](https://github.com/docker/buildx/actions?query=workflow%3Abuild)
[![Go Report Card](https://goreportcard.com/badge/github.com/docker/buildx?style=flat-square)](https://goreportcard.com/report/github.com/docker/buildx)
[![codecov](https://img.shields.io/codecov/c/github/docker/buildx?logo=codecov&amp;style=flat-square)](https://codecov.io/gh/docker/buildx)

`buildx` is a Docker CLI plugin for extended build capabilities with
[BuildKit](https://github.com/moby/buildkit).

Key features:

- Familiar UI from `docker build`
- Full BuildKit capabilities with container driver
- Multiple builder instance support
- Multi-node builds for cross-platform images
- Compose build support
- High-level build constructs (`bake`)
- In-container driver support (both Docker and Kubernetes)

# Table of Contents

- [Installing](#installing)
  - [Windows and macOS](#windows-and-macos)
  - [Linux packages](#linux-packages)
  - [Manual download](#manual-download)
  - [Dockerfile](#dockerfile)
- [Set buildx as the default builder](#set-buildx-as-the-default-builder)
- [Building](#building)
- [Getting started](#getting-started)
  - [Building with buildx](#building-with-buildx)
  - [Working with builder instances](#working-with-builder-instances)
  - [Building multi-platform images](#building-multi-platform-images)
- [Reference](docs/reference/buildx.md)
  - [`buildx bake`](docs/reference/buildx_bake.md)
  - [`buildx build`](docs/reference/buildx_build.md)
  - [`buildx create`](docs/reference/buildx_create.md)
  - [`buildx du`](docs/reference/buildx_du.md)
  - [`buildx imagetools`](docs/reference/buildx_imagetools.md)
    - [`buildx imagetools create`](docs/reference/buildx_imagetools_create.md)
    - [`buildx imagetools inspect`](docs/reference/buildx_imagetools_inspect.md)
  - [`buildx inspect`](docs/reference/buildx_inspect.md)
  - [`buildx ls`](docs/reference/buildx_ls.md)
  - [`buildx prune`](docs/reference/buildx_prune.md)
  - [`buildx rm`](docs/reference/buildx_rm.md)
  - [`buildx stop`](docs/reference/buildx_stop.md)
  - [`buildx use`](docs/reference/buildx_use.md)
  - [`buildx version`](docs/reference/buildx_version.md)
- [Contributing](#contributing)

For more information on how to use Buildx, see
[Docker Build docs](https://docs.docker.com/build/).

# Installing

Using `buildx` with Docker requires Docker engine 19.03 or newer.

&gt; [!WARNING]
&gt; Using an incompatible version of Docker may result in unexpected behavior,
&gt; and will likely cause issues, especially when using Buildx builders with more
&gt; recent versions of BuildKit.

## Windows and macOS

Docker Buildx is included in [Docker Desktop](https://docs.docker.com/desktop/)
for Windows and macOS.

## Linux packages

Docker Engine package repositories contain Docker Buildx packages when installed according to the
[Docker Engine install documentation](https://docs.docker.com/engine/install/). Install the
`docker-buildx-plugin` package to install the Buildx plugin.

## Manual download

&gt; [!IMPORTANT]
&gt; This section is for unattended installation of the buildx component. These
&gt; instructions are mostly suitable for testing purposes. We do not recommend
&gt; installing buildx using manual download in production environments as they
&gt; will not be updated automatically with security updates.
&gt;
&gt; On Windows and macOS, we recommend that you install [Docker Desktop](https://docs.docker.com/desktop/)
&gt; instead. For Linux, we recommend that you follow the [instructions specific for your distribution](#linux-packages).

You can also download the latest binary from the [GitHub releases page](https://github.com/docker/buildx/releases/latest).

Rename the relevant binary and copy it to the destination matching your OS:

| OS       | Binary name          | Destination folder                       |
| -------- | -------------------- | -----------------------------------------|
| Linux    | `docker-buildx`      | `$HOME/.docker/cli-plugins`              |
| macOS    | `docker-buildx`      | `$HOME/.docker/cli-plugins`              |
| Windows  | `docker-buildx.exe`  | `%USERPROFILE%\.docker\cli-plugins`      |

Or copy it into one of these folders for installing it system-wide.

On Unix environments:

* `/usr/local/lib/docker/cli-plugins` OR `/usr/local/libexec/docker/cli-plugins`
* `/usr/lib/docker/cli-plugins` OR `/usr/libexec/docker/cli-plugins`

On Windows:

* `C:\ProgramData\Docker\cli-plugins`
* `C:\Program Files\Docker\cli-plugins`

&gt; [!NOTE]
&gt; On Unix environments, it may also be necessary to make it executable with `chmod +x`:
&gt; ```shell
&gt; $ chmod +x ~/.docker/cli-plugins/docker-buildx
&gt; ```

## Dockerfile

Here is how to install and use Buildx inside a Dockerfile through the
[`docker/buildx-bin`](https://hub.docker.com/r/docker/buildx-bin) image:

```dockerfile
# syntax=docker/dockerfile:1
FROM docker
COPY --from=docker/buildx-bin /buildx /usr/libexec/docker/cli-plugins/docker-buildx
RUN docker buildx version
```

# Set buildx as the default builder

Running the command [`docker buildx install`](docs/reference/buildx_install.md)
sets up docker builder command as an alias to `docker buildx build`. This
results in the ability to have `docker build` use the current buildx builder.

To remove this alias, run [`docker buildx uninstall`](docs/reference/buildx_uninstall.md).

# Building

```console
# Buildx 0.6+
$ docker buildx bake &quot;https://github.com/docker/buildx.git&quot;
$ mkdir -p ~/.docker/cli-plugins
$ mv ./bin/build/buildx ~/.docker/cli-plugins/docker-buildx

# Docker 19.03+
$ DOCKER_BUILDKIT=1 docker build --platform=local -o . &quot;https://github.com/docker/buildx.git&quot;
$ mkdir -p ~/.docker/cli-plugins
$ mv buildx ~/.docker/cli-plugins/docker-buildx

# Local
$ git clone https://github.com/docker/buildx.git &amp;&amp; cd buildx
$ make install
```

# Getting started

## Building with buildx

Buildx is a Docker CLI plugin that extends the `docker build` command with the
full support of the features provided by [Moby BuildKit](https://github.com/moby/buildkit)
builder toolkit. It provides the same user experience as `docker build` with
many new features like creating scoped builder instances and building against
multiple nodes concurrently.

After installation, buildx can be accessed through the `docker buildx` command
with Docker 19.03.  `docker buildx build` is the command for starting a new
build. With Docker versions older than 19.03 buildx binary can be called
directly to access the `docker buildx` subcommands.

```console
$ docker buildx build .
[+] Building 8.4s (23/32)
 =&gt; ...
```

Buildx will always build using the BuildKit engine and does not require
`DOCKER_BUILDKIT=1` environment variable for starting builds.

The `docker buildx build` command supports features available for `docker build`,
including features such as outputs configuration, inline build caching, and
specifying target platform. In addition, Buildx also supports new features that
are not yet available for regular `docker build` like building manifest lists,
distributed caching, and exporting build results to OCI image tarballs.

Buildx is flexible and can be run in different configurations that are exposed
through various &quot;drivers&quot;. Each driver defines how and where a build should
run, and have different feature sets.

We currently support the following drivers:
- The `docker` driver ([guide](https://docs.docker.com/build/drivers/docker/), [reference](https://docs.docker.com/engine/reference/commandline/buildx_create/#driver))
- The `docker-container` driver ([guide](https://docs.docker.com/build/drivers/docker-container/), [reference](https://docs.docker.com/engine/reference/commandline/buildx_create/#driver))
- The `kubernetes` driver ([guide](https://docs.docker.com/build/drivers/kubernetes/), [reference](https://docs.docker.com/engine/reference/commandline/buildx_create/#driver))
- The `remote` driver ([guide](https://docs.docker.com/build/drivers/remote/))

For more information on drivers, see the [drivers guide](https://docs.docker.com/build/drivers/).

## Working with builder instances

By default, buildx will initially use the `docker` driver if it is supported,
providing a very similar user experience to the native `docker build`. Note that
you must use a local shared daemon to build your applications.

Buildx allows you to create new instances of isolated builders. This can be
used for getting a scoped environment for your CI builds that does not change
the state of the shared daemon or for isolating the builds for different
projects. You can create a new instance for a set of remote nodes, forming a
build farm, and quickly switch between them.

You can create new instances using the [`docker buildx create`](docs/reference/buildx_create.md)
command. This creates a new builder instance with a single node based on your
current configuration.

To use a remote node you can specify the `DOCKER_HOST` or the remote context name
while creating the new builder. After creating a new instance, you can manage its
lifecycle using the [`docker buildx inspect`](docs/reference/buildx_inspect.md),
[`docker buildx stop`](docs/reference/buildx_stop.md), and
[`docker buildx rm`](docs/reference/buildx_rm.md) commands. To list all
available builders, use [`buildx ls`](docs/reference/buildx_ls.md). After
creating a new builder you can also append new nodes to it.

To switch between different builders, use [`docker buildx use &lt;name&gt;`](docs/reference/buildx_use.md).
After running this command, the build commands will automatically use this
builder.

Docker also features a [`docker context`](https://docs.docker.com/engine/reference/commandline/context/)
command that can be used for giving names for remote Docker API endpoints.
Buildx integrates with `docker context` so that all of your contexts
automatically get a default builder instance. While creating a new builder
instance or when adding a node to it you can also set the context name as the
target.

## Building multi-platform images

BuildKit is designed to work well for building for multiple platforms and not
only for the architecture and operating system that the user invoking the build
happens to run.

When you invoke a build, you can set the `--platform` flag to specify the target
platform for the build output, (for example, `linux/amd64`, `linux/arm64`, or
`darwin/amd64`).

When the current builder instance is backed by the `docker-container` or
`kubernetes` driver, you can specify multiple platforms together. In this case,
it builds a manifest list which contains images for all specified architectures.
When you use this image in [`docker run`](https://docs.docker.com/engine/reference/commandline/run/)
or [`docker service`](https://docs.docker.com/engine/reference/commandline/service/),
Docker picks the correct image based on the node&#039;s platform.

You can build multi-platform images using three different strategies that are
supported by Buildx and Dockerfiles:

1. Using the QEMU emulation support in the kernel
2. Building on multiple native nodes using the same builder instance
3. Using a stage in Dockerfile to cross-compile to different architectures

QEMU is the easiest way to get started if your node already supports it (for
example. if you are using Docker Desktop). It requires no changes to your
Dockerfile and BuildKit automatically detects the secondary architectures that
are available. When BuildKit needs to run a binary for a different architecture,
it automatically loads it through a binary registered in the `binfmt_misc`
handler.

For QEMU binaries registered with `binfmt_misc` on the host OS to work
transparently inside containers they must be registered with the `fix_binary`
flag. This requires a kernel &gt;= 4.8 and binfmt-support &gt;= 2.1.7. You can check
for proper registration by checking if `F` is among the flags in
`/proc/sys/fs/binfmt_misc/qemu-*`. While Docker Desktop comes preconfigured
with `binfmt_misc` support for additional platforms, for other installations
it likely needs to be installed using [`tonistiigi/binfmt`](https://github.com/tonistiigi/binfmt)
image.

```console
$ docker run --privileged --rm tonistiigi/binfmt --install all
```

Using multiple native nodes provide better support for more complicated cases
that are not handled by QEMU and generally have better performance. You can
add additional nodes to the builder instance using the `--append` flag.

Assuming contexts `node-amd64` and `node-arm64` exist in `docker context ls`;

```console
$ docker buildx create --use --name mybuild node-amd64
mybuild
$ docker buildx create --append --name mybuild node-arm64
$ docker buildx build --platform linux/amd64,linux/arm64 .
```

Finally, depending on your project, the language that you use may have good
support for cross-compilation. In that case, multi-stage builds in Dockerfiles
can be effectively used to build binaries for the platform specified with
`--platform` using the native architecture of the build node. A list of build
arguments like `BUILDPLATFORM` and `TARGETPLATFORM` is available automatically
inside your Dockerfile and can be leveraged by the processes running as part
of your build.

```dockerfile
# syntax=docker/dockerfile:1
FROM --platform=$BUILDPLATFORM golang:alpine AS build
ARG TARGETPLATFORM
ARG BUILDPLATFORM
RUN echo &quot;I am running on $BUILDPLATFORM, building for $TARGETPLATFORM&quot; &gt; /log
FROM alpine
COPY --from=build /log /log
```

You can also use [`tonistiigi/xx`](https://github.com/tonistiigi/xx) Dockerfile
cross-compilation helpers for more advanced use-cases.

## High-level build options

See [High-level builds with Bake](https://docs.docker.com/build/bake/) for more details.

# Contributing

Want to contribute to Buildx? Awesome! You can find information about
contributing to this project in the [CONTRIBUTING.md](/.github/CONTRIBUTING.md)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>