<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for go - Go Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for go.</description>
        <lastBuildDate>Tue, 09 Dec 2025 00:05:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[safing/portmaster]]></title>
            <link>https://github.com/safing/portmaster</link>
            <guid>https://github.com/safing/portmaster</guid>
            <pubDate>Tue, 09 Dec 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[üèî Love Freedom - ‚ùå Block Mass Surveillance]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/safing/portmaster">safing/portmaster</a></h1>
            <p>üèî Love Freedom - ‚ùå Block Mass Surveillance</p>
            <p>Language: Go</p>
            <p>Stars: 11,227</p>
            <p>Forks: 395</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># Get Peace of Mind &lt;br&gt; with [Easy Privacy](https://safing.io/)

Portmaster is a free and open-source application firewall that does the heavy lifting for you.
Restore privacy and take back control over all your computer&#039;s network activity.

With great defaults your privacy improves without any effort. And if you want to configure and control everything down to the last detail - Portmaster has you covered too. Developed in the EU üá™üá∫, Austria.

__[Download for Free](https://safing.io/download/)__

__[About Us](https://safing.io/about/)__

![Portmaster User Interface](https://safing.io/assets/img/page-specific/landing/portmaster-thumbnail.png?)

_seen on:_  

[&lt;img src=&quot;https://safing.io/assets/img/external/heise_online.svg&quot; height=&quot;35&quot;&gt;](https://www.heise.de/tests/Datenschutz-Firewall-Portmaster-im-Test-9611687.html)
&amp;nbsp;&amp;nbsp;&amp;nbsp;
[![ghacks.net](https://safing.io/assets/img/external/ghacks.png)](https://www.ghacks.net/2022/11/08/portmaster-1-0-released-open-source-application-firewall/)
&amp;nbsp;&amp;nbsp;&amp;nbsp;
[![Techlore](https://safing.io/assets/img/external/techlore.png)](https://www.youtube.com/watch?v=E8cTRhGtmcM)
&amp;nbsp;&amp;nbsp;&amp;nbsp;
[![Lifehacker](https://safing.io/assets/img/external/logos/lifehacker.webp)](https://lifehacker.com/the-lesser-known-apps-everyone-should-install-on-a-new-1850223434)

## [Features](https://safing.io/features/)

1. Monitor All Network Activity
2. Full Control: Block Anything
3. Automatically Block Trackers &amp; Malware
4. Set Global &amp; Per‚ÄëApp Settings
5. Secure DNS (Doh/DoT)
6. Record and Search Network Activity ([$](https://safing.io/pricing/))
7. Per-App Bandwidth Usage ([$](https://safing.io/pricing/))
8. [SPN, our Next-Gen Privacy Network](https://safing.io/spn/) ([$$](https://safing.io/pricing/))

# Technical Introduction

Portmaster is a privacy suite for your Windows and Linux desktop.

### Base Technology

- Portmaster integrates into network stack using nfqueue on Linux and a kernel driver (WFP) on Windows.
- Packets are intercepted at the raw packet level - every packet is seen and can be stopped.
- Ownership of connections is found using eBPF and `/proc` on Linux and a kernel driver and the IP Helper API (`iphlpapi.dll`) on Windows.
- Most settings can be defined per app, which can be matched in different ways.
- Support for special processes with weird or concealed paths/actors:
  - Snap, AppImage and Script support on Linux
  - Windows Store apps and svchost.exe system services support on Windows
- Everything is 100% local on your device. (except the SPN, naturally)
  - Updates are fully signed and downloaded automatically.
  - Intelligence data (block lists, geoip) is downloaded and applied automatically.
- The Portmaster Core Service runs as a system service, the UI elements (App, Notifier) run in user context.
- The main UI still uses electron as a wrapper :/ - but this will change in the future. You can also open the UI in the browser

### Feature: Secure DNS

- Portmaster intercepts &quot;astray&quot; DNS queries and reroutes them to itself for seamless integration.
- DNS queries are resolved by the default or configured DoT/DoH resolvers.
- Full support for split horizon and horizon validation to defend against rebinding attacks.

### Feature: Privacy Filter

- Define allowed network scopes: Localhost, LAN, Internet, P2P, Inbound.
- Easy rules based on Internet entities: Domain, IP, Country and more.
- Filter Lists block common malware, ad, tracker domains etc.

### Feature: Network History ($)

- Record connections and their details in a local database and search all of it later
- Auto-delete old history or delete on demand

### Feature: Bandwidth Visibility ($)

- Monitor bandwidth usage per connection and app

### Feature: SPN - Safing Privacy Network ($$)

- A Privacy Network aimed at use cases &quot;between&quot; VPN and Tor.
- Uses onion encryption over multiple hops just like Tor.
- Routes are chosen to cover most distance within the network to increase privacy.
- Exits are chosen near the destination server. This automatically geo-unblocks in many cases.
- Exclude apps and domains/entities from using SPN.
- Change routing algorithm and focus per app.
- Nodes are hosted by Safing (company behind Portmaster) and the community.
- Speeds are pretty decent (&gt;100MBit/s).
- Further Reading: [SPN Whitepaper](https://safing.io/files/whitepaper/Gate17.pdf)

## Documentation

All details and guides in the dedicated [wiki](https://wiki.safing.io/)

- [Getting Started](https://wiki.safing.io/en/Portmaster/App)
- Install
  - [on Windows](https://wiki.safing.io/en/Portmaster/Install/Windows)
  - [on Linux](https://wiki.safing.io/en/Portmaster/Install/Linux)
- [Contribute](https://wiki.safing.io/en/Contribute)
- [VPN Compatibility](https://wiki.safing.io/en/Portmaster/App/Compatibility#vpn-compatibly)
- [Software Compatibility](https://wiki.safing.io/en/Portmaster/App/Compatibility)
- [Architecture](https://wiki.safing.io/en/Portmaster/Architecture)
- [Settings Handbook](https://docs.safing.io/portmaster/settings)
- [Portmaster Developer API](https://docs.safing.io/portmaster/api)

# Build Portmaster Yourself (WIP)

1. [Install Earthly CLI](https://earthly.dev/get-earthly)
2. [Install Docker Engine](https://docs.docker.com/engine/install/)
3. Run `earthly +release`
4. Find artifacts in `./dist`
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[XTLS/Xray-core]]></title>
            <link>https://github.com/XTLS/Xray-core</link>
            <guid>https://github.com/XTLS/Xray-core</guid>
            <pubDate>Tue, 09 Dec 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[Xray, Penetrates Everything. Also the best v2ray-core. Where the magic happens. An open platform for various uses.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/XTLS/Xray-core">XTLS/Xray-core</a></h1>
            <p>Xray, Penetrates Everything. Also the best v2ray-core. Where the magic happens. An open platform for various uses.</p>
            <p>Language: Go</p>
            <p>Stars: 33,219</p>
            <p>Forks: 4,777</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre># Project X

[Project X](https://github.com/XTLS) originates from XTLS protocol, providing a set of network tools such as [Xray-core](https://github.com/XTLS/Xray-core) and [REALITY](https://github.com/XTLS/REALITY).

[README](https://github.com/XTLS/Xray-core#readme) is open, so feel free to submit your project [here](https://github.com/XTLS/Xray-core/pulls).

## Sponsors

[![Remnawave](https://github.com/user-attachments/assets/a22d34ae-01ee-441c-843a-85356748ed1e)](https://docs.rw)

[![Happ](https://github.com/user-attachments/assets/14055dab-e8bb-48bd-89e8-962709e4098e)](https://happ.su)

[**Sponsor Xray-core**](https://github.com/XTLS/Xray-core/issues/3668)

## Donation &amp; NFTs

### [Collect a Project X NFT to support the development of Project X!](https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1)

[&lt;img alt=&quot;Project X NFT&quot; width=&quot;150px&quot; src=&quot;https://raw2.seadn.io/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/7fa9ce900fb39b44226348db330e32/8b7fa9ce900fb39b44226348db330e32.svg&quot; /&gt;](https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1)

- **TRX(Tron)/USDT/USDC: `TNrDh5VSfwd4RPrwsohr6poyNTfFefNYan`**
- **TON: `UQApeV-u2gm43aC1uP76xAC1m6vCylstaN1gpfBmre_5IyTH`**
- **BTC: `1JpqcziZZuqv3QQJhZGNGBVdCBrGgkL6cT`**
- **XMR: `4ABHQZ3yJZkBnLoqiKvb3f8eqUnX4iMPb6wdant5ZLGQELctcerceSGEfJnoCk6nnyRZm73wrwSgvZ2WmjYLng6R7sR67nq`**
- **SOL/USDT/USDC: `3x5NuXHzB5APG6vRinPZcsUv5ukWUY1tBGRSJiEJWtZa`**
- **ETH/USDT/USDC: `0xDc3Fe44F0f25D13CACb1C4896CD0D321df3146Ee`**
- **Project X NFT: https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/1**
- **VLESS NFT: https://opensea.io/collection/vless**
- **REALITY NFT: https://opensea.io/item/ethereum/0x5ee362866001613093361eb8569d59c4141b76d1/2**
- **Related links: [VLESS Post-Quantum Encryption](https://github.com/XTLS/Xray-core/pull/5067), [XHTTP: Beyond REALITY](https://github.com/XTLS/Xray-core/discussions/4113), [Announcement of NFTs by Project X](https://github.com/XTLS/Xray-core/discussions/3633)**

## License

[Mozilla Public License Version 2.0](https://github.com/XTLS/Xray-core/blob/main/LICENSE)

## Documentation

[Project X Official Website](https://xtls.github.io)

## Telegram

[Project X](https://t.me/projectXray)

[Project X Channel](https://t.me/projectXtls)

[Project VLESS](https://t.me/projectVless) (–†—É—Å—Å–∫–∏–π)

[Project XHTTP](https://t.me/projectXhttp) (Persian)

## Installation

- Linux Script
  - [XTLS/Xray-install](https://github.com/XTLS/Xray-install) (**Official**)
  - [tempest](https://github.com/team-cloudchaser/tempest) (supports [`systemd`](https://systemd.io) and [OpenRC](https://github.com/OpenRC/openrc); Linux-only)
- Docker
  - [ghcr.io/xtls/xray-core](https://ghcr.io/xtls/xray-core) (**Official**)
  - [teddysun/xray](https://hub.docker.com/r/teddysun/xray)
  - [wulabing/xray_docker](https://github.com/wulabing/xray_docker)
- Web Panel - **WARNING: Please DO NOT USE plain HTTP panels like 3X-UI**, as they are believed to be bribed by Iran GFW for supporting plain HTTP by default and refused to change (https://github.com/XTLS/Xray-core/pull/3884#issuecomment-2439595331), which has already put many users&#039; data security in danger in the past few years. **If you are already using 3X-UI, please switch to the following panels, which are verified to support HTTPS and SSH port forwarding only:**
  - [Remnawave](https://github.com/remnawave/panel)
  - [X-Panel](https://github.com/xeefei/X-Panel)
  - [PasarGuard](https://github.com/PasarGuard/panel)
  - [Marzban](https://github.com/Gozargah/Marzban)
  - [Xray-UI](https://github.com/qist/xray-ui)
  - [Hiddify](https://github.com/hiddify/Hiddify-Manager)
- One Click
  - [Xray-REALITY](https://github.com/zxcvos/Xray-script), [xray-reality](https://github.com/sajjaddg/xray-reality), [reality-ezpz](https://github.com/aleskxyz/reality-ezpz)
  - [Xray_bash_onekey](https://github.com/hello-yunshu/Xray_bash_onekey), [XTool](https://github.com/LordPenguin666/XTool), [VPainLess](https://github.com/vpainless/vpainless)
  - [v2ray-agent](https://github.com/mack-a/v2ray-agent), [Xray_onekey](https://github.com/wulabing/Xray_onekey), [ProxySU](https://github.com/proxysu/ProxySU)
- Magisk
  - [Xray4Magisk](https://github.com/Asterisk4Magisk/Xray4Magisk)
  - [Xray_For_Magisk](https://github.com/E7KMbb/Xray_For_Magisk)
- Homebrew
  - `brew install xray`

## Usage

- Example
  - [VLESS-XTLS-uTLS-REALITY](https://github.com/XTLS/REALITY#readme)
  - [VLESS-TCP-XTLS-Vision](https://github.com/XTLS/Xray-examples/tree/main/VLESS-TCP-XTLS-Vision)
  - [All-in-One-fallbacks-Nginx](https://github.com/XTLS/Xray-examples/tree/main/All-in-One-fallbacks-Nginx)
- Xray-examples
  - [XTLS/Xray-examples](https://github.com/XTLS/Xray-examples)
  - [chika0801/Xray-examples](https://github.com/chika0801/Xray-examples)
  - [lxhao61/integrated-examples](https://github.com/lxhao61/integrated-examples)
- Tutorial
  - [XTLS Vision](https://github.com/chika0801/Xray-install)
  - [REALITY (English)](https://cscot.pages.dev/2023/03/02/Xray-REALITY-tutorial/)
  - [XTLS-Iran-Reality (English)](https://github.com/SasukeFreestyle/XTLS-Iran-Reality)
  - [Xray REALITY with &#039;steal oneself&#039; (English)](https://computerscot.github.io/vless-xtls-utls-reality-steal-oneself.html)
  - [Xray with WireGuard inbound (English)](https://g800.pages.dev/wireguard)

## GUI Clients

- OpenWrt
  - [PassWall](https://github.com/xiaorouji/openwrt-passwall), [PassWall 2](https://github.com/xiaorouji/openwrt-passwall2)
  - [ShadowSocksR Plus+](https://github.com/fw876/helloworld)
  - [luci-app-xray](https://github.com/yichya/luci-app-xray) ([openwrt-xray](https://github.com/yichya/openwrt-xray))
- Asuswrt-Merlin
  - [XRAYUI](https://github.com/DanielLavrushin/asuswrt-merlin-xrayui)
- Windows
  - [v2rayN](https://github.com/2dust/v2rayN)
  - [Furious](https://github.com/LorenEteval/Furious)
  - [Invisible Man - Xray](https://github.com/InvisibleManVPN/InvisibleMan-XRayClient)
  - [AnyPortal](https://github.com/AnyPortal/AnyPortal)
- Android
  - [v2rayNG](https://github.com/2dust/v2rayNG)
  - [X-flutter](https://github.com/XTLS/X-flutter)
  - [SaeedDev94/Xray](https://github.com/SaeedDev94/Xray)
  - [SimpleXray](https://github.com/lhear/SimpleXray)
  - [AnyPortal](https://github.com/AnyPortal/AnyPortal)
- iOS &amp; macOS arm64 &amp; tvOS
  - [Happ](https://apps.apple.com/app/happ-proxy-utility/id6504287215) ([tvOS](https://apps.apple.com/us/app/happ-proxy-utility-for-tv/id6748297274))
  - [Streisand](https://apps.apple.com/app/streisand/id6450534064)
  - [OneXray](https://github.com/OneXray/OneXray)
- macOS arm64 &amp; x64
  - [Happ](https://apps.apple.com/app/happ-proxy-utility/id6504287215)
  - [V2rayU](https://github.com/yanue/V2rayU)
  - [V2RayXS](https://github.com/tzmax/V2RayXS)
  - [Furious](https://github.com/LorenEteval/Furious)
  - [OneXray](https://github.com/OneXray/OneXray)
  - [GoXRay](https://github.com/goxray/desktop)
  - [AnyPortal](https://github.com/AnyPortal/AnyPortal)
  - [v2rayN](https://github.com/2dust/v2rayN)
- Linux
  - [v2rayA](https://github.com/v2rayA/v2rayA)
  - [Furious](https://github.com/LorenEteval/Furious)
  - [GorzRay](https://github.com/ketetefid/GorzRay)
  - [GoXRay](https://github.com/goxray/desktop)
  - [AnyPortal](https://github.com/AnyPortal/AnyPortal)
  - [v2rayN](https://github.com/2dust/v2rayN)

## Others that support VLESS, XTLS, REALITY, XUDP, PLUX...

- iOS &amp; macOS arm64 &amp; tvOS
  - [Shadowrocket](https://apps.apple.com/app/shadowrocket/id932747118)
  - [Loon](https://apps.apple.com/us/app/loon/id1373567447)
- Xray Tools
  - [xray-knife](https://github.com/lilendian0x00/xray-knife)
  - [xray-checker](https://github.com/kutovoys/xray-checker)
- Xray Wrapper
  - [XTLS/libXray](https://github.com/XTLS/libXray)
  - [xtls-sdk](https://github.com/remnawave/xtls-sdk)
  - [xtlsapi](https://github.com/hiddify/xtlsapi)
  - [AndroidLibXrayLite](https://github.com/2dust/AndroidLibXrayLite)
  - [Xray-core-python](https://github.com/LorenEteval/Xray-core-python)
  - [xray-api](https://github.com/XVGuardian/xray-api)
- [XrayR](https://github.com/XrayR-project/XrayR)
  - [XrayR-release](https://github.com/XrayR-project/XrayR-release)
  - [XrayR-V2Board](https://github.com/missuo/XrayR-V2Board)
- Cores
  - [Amnezia VPN](https://github.com/amnezia-vpn)
  - [mihomo](https://github.com/MetaCubeX/mihomo)
  - [sing-box](https://github.com/SagerNet/sing-box)

## Contributing

[Code of Conduct](https://github.com/XTLS/Xray-core/blob/main/CODE_OF_CONDUCT.md)

[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/XTLS/Xray-core)

## Credits

- [Xray-core v1.0.0](https://github.com/XTLS/Xray-core/releases/tag/v1.0.0) was forked from [v2fly-core 9a03cc5](https://github.com/v2fly/v2ray-core/commit/9a03cc5c98d04cc28320fcee26dbc236b3291256), and we have made &amp; accumulated a huge number of enhancements over time, check [the release notes for each version](https://github.com/XTLS/Xray-core/releases).
- For third-party projects used in [Xray-core](https://github.com/XTLS/Xray-core), check your local or [the latest go.mod](https://github.com/XTLS/Xray-core/blob/main/go.mod).

## One-line Compilation

### Windows (PowerShell)

```powershell
$env:CGO_ENABLED=0
go build -o xray.exe -trimpath -buildvcs=false -ldflags=&quot;-s -w -buildid=&quot; -v ./main
```

### Linux / macOS

```bash
CGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -ldflags=&quot;-s -w -buildid=&quot; -v ./main
```

### Reproducible Releases

Make sure that you are using the same Go version, and remember to set the git commit id (7 bytes):

```bash
CGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -gcflags=&quot;all=-l=4&quot; -ldflags=&quot;-X github.com/xtls/xray-core/core.build=REPLACE -s -w -buildid=&quot; -v ./main
```

If you are compiling a 32-bit MIPS/MIPSLE target, use this command instead:

```bash
CGO_ENABLED=0 go build -o xray -trimpath -buildvcs=false -gcflags=&quot;-l=4&quot; -ldflags=&quot;-X github.com/xtls/xray-core/core.build=REPLACE -s -w -buildid=&quot; -v ./main
```

## Stargazers over time

[![Stargazers over time](https://starchart.cc/XTLS/Xray-core.svg)](https://starchart.cc/XTLS/Xray-core)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[filebrowser/filebrowser]]></title>
            <link>https://github.com/filebrowser/filebrowser</link>
            <guid>https://github.com/filebrowser/filebrowser</guid>
            <pubDate>Tue, 09 Dec 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[üìÇ Web File Browser]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/filebrowser/filebrowser">filebrowser/filebrowser</a></h1>
            <p>üìÇ Web File Browser</p>
            <p>Language: Go</p>
            <p>Stars: 32,348</p>
            <p>Forks: 3,594</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/filebrowser/filebrowser/master/branding/banner.png&quot; width=&quot;550&quot;/&gt;
&lt;/p&gt;

[![Build](https://github.com/filebrowser/filebrowser/actions/workflows/ci.yaml/badge.svg)](https://github.com/filebrowser/filebrowser/actions/workflows/ci.yaml)
[![Go Report Card](https://goreportcard.com/badge/github.com/filebrowser/filebrowser/v2)](https://goreportcard.com/report/github.com/filebrowser/filebrowser/v2)
[![Version](https://img.shields.io/github/release/filebrowser/filebrowser.svg)](https://github.com/filebrowser/filebrowser/releases/latest)

File Browser provides a file managing interface within a specified directory and it can be used to upload, delete, preview and edit your files. It is a **create-your-own-cloud**-kind of software where you can just install it on your server, direct it to a path and access your files through a nice web interface.

## Documentation

Documentation on how to install, configure, and contribute to this project is hosted at [filebrowser.org](https://filebrowser.org).

## Project Status

This project is a finished product which fulfills its goal: be a single binary web File Browser which can be run by anyone anywhere. That means that File Browser is currently on **maintenance-only** mode. Therefore, please note the following:

- It can take a while until someone gets back to you. Please be patient.
- [Issues](https://github.com/filebrowser/filebrowser/issues) are meant to track bugs. Unrelated issues will be converted into [discussions](https://github.com/filebrowser/filebrowser/discussions).
- No new features will be implemented by maintainers. Pull requests for new features will be reviewed on a case by case basis.
- The priority is triaging issues, addressing security issues and reviewing pull requests meant to solve bugs.

## Contributing

Contributions are always welcome. To start contributing to this project, read our [guidelines](CONTRIBUTING.md) first.

## License

[Apache License 2.0](LICENSE) ¬© File Browser Contributors
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[inngest/inngest]]></title>
            <link>https://github.com/inngest/inngest</link>
            <guid>https://github.com/inngest/inngest</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[The leading workflow orchestration platform. Run stateful step functions and AI workflows on serverless, servers, or the edge.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/inngest/inngest">inngest/inngest</a></h1>
            <p>The leading workflow orchestration platform. Run stateful step functions and AI workflows on serverless, servers, or the edge.</p>
            <p>Language: Go</p>
            <p>Stars: 4,303</p>
            <p>Forks: 211</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre># [![Inngest](https://github.com/inngest/.github/raw/main/profile/github-readme-banner-2025-06-20.png)](https://www.inngest.com)

[![Latest release](https://img.shields.io/github/v/release/inngest/inngest?include_prereleases&amp;sort=semver)](https://github.com/inngest/inngest/releases)
[![Test Status](https://img.shields.io/github/actions/workflow/status/inngest/inngest/go.yaml?branch=main&amp;label=tests)](https://github.com/inngest/inngest/actions?query=branch%3Amain)
[![Discord](https://img.shields.io/discord/842170679536517141?label=discord)](https://www.inngest.com/discord)
[![Twitter Follow](https://img.shields.io/twitter/follow/inngest?style=social)](https://twitter.com/inngest)

[Inngest](https://www.inngest.com/?ref=github-inngest-readme)&#039;s durable functions replace queues, state management, and scheduling to enable any developer to write reliable step functions faster without touching infrastructure.

1. Write durable functions using any of [**our language SDKs**](#sdks)
2. Run the [**Inngest Dev Server**](#getting-started) for a complete local development experience, with production parity.
3. Deploy your functions to your own infrastructure
4. Sync your application&#039;s functions with the [**Inngest Platform**](https://www.inngest.com/?ref=github-inngest-readme) or a [self-hosted Inngest server](#self-hosting).
5. Inngest invokes your functions securely via HTTPS whenever triggering events are received.

### An example durable function

Inngest Functions enable developers to run reliable background logic, from background jobs to complex workflows. An Inngest Function is composed of three key parts that provide robust support for retrying, scheduling, and coordinating complex sequences of operations:

- [**Triggers**](https://www.inngest.com/docs/features/events-triggers?ref=github-inngest-readme) - Events, Cron schedules or webhook events that trigger the function.
- [**Flow Control**](https://www.inngest.com/docs/guides/flow-control?ref=github-inngest-readme) - Configure how the function runs are enqueued and executed including concurrency, throttling, debouncing, rate limiting, and prioritization.
- [**Steps**](/docs/features/inngest-functions/steps-workflows?ref=github-inngest-readme) - Steps are fundamental building blocks of Inngest, turning your Inngest Functions into reliable workflows that can runs for months and recover from failures.

Here is an example function that limits concurrency for each unique user id and performs two steps that will be retried on error:

```typescript
export default inngest.createFunction(
  {
    id: &quot;import-product-images&quot;,
    concurrency: {
      key: &quot;event.data.userId&quot;,
      limit: 10
    }
  },
  { event: &quot;shop/product.imported&quot; },
  async ({ event, step }) =&gt; {
    // Here goes the business logic
    // By wrapping code in steps, each will be retried automatically on failure
    const s3Urls = await step.run(&quot;copy-images-to-s3&quot;, async () =&gt; {
      return copyAllImagesToS3(event.data.imageURLs);
    });
    // You can include numerous steps in your function
    await step.run(&quot;resize-images&quot;, async () =&gt; {
      await resizer.bulk({ urls: s3Urls, quality: 0.9, maxWidth: 1024 });
    })
  };
);

// Elsewhere in your code (e.g. in your API endpoint):
await inngest.send({
  name: &quot;shop/product.imported&quot;,
  data: {
    userId: &quot;01J8G44701QYGE0DH65PZM8DPM&quot;,
    imageURLs: [
      &quot;https://useruploads.acme.com/q2345678/1094.jpg&quot;,
      &quot;https://useruploads.acme.com/q2345678/1095.jpg&quot;
    ],
  },
});
```

## Learn more

- [Getting started](#getting-started)
- [SDKs](#sdks)
- [Project Architecture](#project-architecture)
- [Self-hosting](#self-hosting)
- [Community](#community)

## Getting started

Run the Inngest Dev Server using our CLI:

```
npx inngest-cli@latest dev
```

Open the Inngest Dev Server dashboard at http://localhost:8288:

![Screenshot of the Inngest dashboard served by the Inngest Dev Server](.github/assets/dashboard-screenshot-2024-09-23.png)

Follow our [Next.js](https://www.inngest.com/docs/getting-started/nextjs-quick-start?ref=github-inngest-readme), [Node.js](https://www.inngest.com/docs/getting-started/nodejs-quick-start?ref=github-inngest-readme) or [Python](https://www.inngest.com/docs/getting-started/python-quick-start?ref=github-inngest-readme) quick start guides.

## SDKs

- **TypeScript / JavaScript** ([inngest-js](https://github.com/inngest/inngest-js)) - [Reference](https://www.inngest.com/docs/reference/typescript?ref=github-inngest-readme)
- **Python** ([inngest-py](https://github.com/inngest/inngest-py)) - [Reference](https://www.inngest.com/docs/reference/python?ref=github-inngest-readme)
- **Go** ([inngestgo](https://github.com/inngest/inngestgo)) - [Reference](https://pkg.go.dev/github.com/inngest/inngestgo)
- **Kotlin / Java** ([inngest-kt](https://github.com/inngest/inngest-kt))

## Project Architecture

To understand how self-hosting works, it&#039;s valuable to understand the architecture and system components at a high level. We&#039;ll take a look at a simplified architecture diagram and walk through the system.

&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;.github/assets/architecture-2024-09-23.png&quot; alt=&quot;System Architecture&quot; width=&quot;660&quot; /&gt;
&lt;/p&gt;

- **Event API** - Receives events from SDKs via HTTP requests. Authenticates client requests via [Event Keys](https://www.inngest.com/docs/events/creating-an-event-key?ref=github-inngest-readme). The Event API publishes event payloads to an internal event stream.
- **Event stream** - Acts as buffer between the _Event API_ and the _Runner_.
- **Runner** - Consumes incoming events and performs several actions:
  - Scheduling of new ‚Äúfunction runs‚Äù (aka jobs) given the event type, creating initial run state in the _State store_ database. Runs are added to queues given the function&#039;s flow control configuration.
  - Resume functions paused via [`waitForEvent`](https://www.inngest.com/docs/features/inngest-functions/steps-workflows/wait-for-event?ref=github-inngest-readme) with matching expressions.
  - Cancels running functions with matching [`cancelOn`](https://www.inngest.com/docs/features/inngest-functions/cancellation/cancel-on-events?ref=github-inngest-readme) expressions
  - Writes ingested events to a database for historical record and future replay.
- **Queue** - A multi-tenant aware, multi-tier queue designed for fairness and various [flow control](https://www.inngest.com/docs/guides/flow-control?ref=github-inngest-readme) methods (concurrency, throttling, prioritization, debouncing, rate limiting) and [batching](https://www.inngest.com/docs/guides/batching?ref=github-inngest-readme).
- **Executor** - Responsible for executing functions, from initial execution, step execution, writing incremental function run state to the _State store_, and retries after failures.
- **State store (database)** - Persists data for pending and ongoing function runs. Data includes initial triggering event(s), step output and step errors.
- **Database** - Persists system data and history including Apps, Functions, Events, Function run results.
- **API** - GraphQL and REST APIs for programmatic access and management of system resources.
- **Dashboard UI** - The UI to manage apps, functions and view function run history.

&lt;br /&gt;

## Community

- [**Join our Discord community for support, to give us feedback, or chat with us**](https://www.inngest.com/discord).
- [Post a question or idea to our GitHub discussion board](https://github.com/orgs/inngest/discussions)
- [Read the documentation](https://www.inngest.com/docs?ref=github-inngest-readme)
- [Explore our public roadmap](http://roadmap.inngest.com/)
- [Follow us on Twitter](https://twitter.com/inngest)
- [Join our mailing list](https://www.inngest.com/mailing-list) for release notes and project updates

## Contributing

We embrace contributions in many forms, including documentation, typos, bug reports or fixes. Check out our [contributing guide](/docs/CONTRIBUTING.md) to get started. Each of our open source [SDKs](#sdks) are open to contributions as well.

Additionally, Inngest&#039;s website documentation is available for contribution in [the `inngest/website` repo](https://github.com/inngest/website).

## Self-hosting

Self-hosting the Inngest server is possible and easy to get started with. Learn more about self-hosting Inngest in [our docs guide](https://www.inngest.com/docs/self-hosting?ref=github-inngest-readme).

## License

The Inngest server and CLI are available under the Server Side Public License and delayed open source publication (DOSP) under Apache 2.0. [View the license here](/LICENSE.md).

All Inngest [SDKs](#sdks) are all available under the Apache 2.0 license.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[jorgerojas26/lazysql]]></title>
            <link>https://github.com/jorgerojas26/lazysql</link>
            <guid>https://github.com/jorgerojas26/lazysql</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[A cross-platform TUI database management tool written in Go.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jorgerojas26/lazysql">jorgerojas26/lazysql</a></h1>
            <p>A cross-platform TUI database management tool written in Go.</p>
            <p>Language: Go</p>
            <p>Stars: 2,918</p>
            <p>Forks: 125</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![MIT License][license-shield]][license-url]
[![LinkedIn][linkedin-shield]][linkedin-url]

&lt;!-- PROJECT LOGO --&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;!-- &lt;a href=&quot;https://github.com/jorgerojas26/lazysql&quot;&gt; --&gt;
  &lt;!--   &lt;img src=&quot;images/logo.png&quot; alt=&quot;Logo&quot; width=&quot;80&quot; height=&quot;80&quot;&gt; --&gt;
  &lt;!-- &lt;/a&gt; --&gt;

  &lt;h3 align=&quot;center&quot;&gt;LAZYSQL&lt;/h3&gt;

  &lt;p align=&quot;center&quot;&gt;
        A cross-platform TUI database management tool written in Go.
  &lt;/p&gt;
&lt;/div&gt;

&lt;!-- TABLE OF CONTENTS --&gt;
&lt;details&gt;
  &lt;summary&gt;Table of Contents&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;
      &lt;a href=&quot;#about-the-project&quot;&gt;About The Project&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&quot;#built-with&quot;&gt;Built With&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#features&quot;&gt;Features&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;
      &lt;a href=&quot;#getting-started&quot;&gt;Getting Started&lt;/a&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;a href=&quot;#installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
      &lt;/ul&gt;
    &lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#usage&quot;&gt;Usage&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#commands&quot;&gt;Commands&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#keybindings&quot;&gt;Keybindings&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#roadmap&quot;&gt;Roadmap&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#contact&quot;&gt;Contact&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#acknowledgments&quot;&gt;Acknowledgments&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

&lt;!-- ABOUT THE PROJECT --&gt;

## About The Project

![Product Name Screen Shot][product-screenshot1]
![Product Name Screen Shot][product-screenshot2]

This project is heavily inspired by [Lazygit](https://github.com/jesseduffield/lazygit), which I think is the best TUI client for Git.

I wanted to have a tool like that, but for SQL. I didn&#039;t find one that fits my needs, so I created one myself.

I live in the terminal, so if you are like me, this tool can become handy for you too.

This is my first Open Source project, also, this is my first Go project. I am not a brilliant programmer. I am just a typical JavaScript developer that wanted to learn a new language, I also wanted a TUI SQL Client, so blanca y en botella, leche! (white and bottled).

This project is in ALPHA stage, please feel free to complain about my spaghetti code.

I use Lazysql daily in my full-time job as a full-stack javascript developer in its current (buggy xD) state. So, the plan is to improve and fix my little boy as a side-project in my free time.

### Built With

![Golang][golang-shield]
![Golang][tview-shield]

## Features

- [x] Cross-platform (macOS, Windows, Linux)
- [x] Vim Keybindings
- [x] Can manage multiple connections (Backspace)
- [x] Tabs
- [x] SQL Editor (CTRL + e)

&lt;!-- GETTING STARTED --&gt;

## Getting Started

### Installation

#### Homebrew (macOS/Linux)

```bash
$ brew install lazysql
```

#### Install with go package manager

```bash
go install github.com/jorgerojas26/lazysql@latest
```

#### Binary Releases

For Windows, macOS or Linux, you can download a binary release [here](https://github.com/jorgerojas26/lazysql/releases)

#### Third party (maintained by the community)

Arch Linux users can install it from the AUR with:

```bash
paru -S lazysql

```

or

```bash
yay -S lazysql

```

or install it manual with:

```bash
git clone https://aur.archlinux.org/lazysql.git
cd lazysql
makepkg -si
```

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

&lt;!-- USAGE EXAMPLES --&gt;

## Configuration

If the `XDG_CONFIG_HOME` environment variable is set, the configuration file will be located at:

- `${XDG_CONFIG_HOME}/lazysql/config.toml`

If not, the configuration file will be located at:

- Windows: `%APPDATA%\lazysql\config.toml`
- macOS: `~/Library/Application Support/lazysql/config.toml`
- Linux: `~/.config/lazysql/config.toml`

The configuration file is a TOML file and can be used to define multiple connections.

### Example configuration

```toml
[[database]]
Name = &#039;Production database&#039;
Provider = &#039;postgres&#039;
DBName = &#039;foo&#039;
URL = &#039;postgres://${user}:urlencodedpassword@localhost:${port}/foo&#039;
ReadOnly = true
Commands = [
  { Command = &#039;ssh -tt remote-bastion -L ${port}:localhost:5432&#039;, WaitForPort = &#039;${port}&#039; },
  { Command = &#039;whoami&#039;, SaveOutputTo = &#039;user&#039; },
]
[[database]]
Name = &#039;Development database&#039;
Provider = &#039;postgres&#039;
DBName = &#039;foo&#039;
URL = &#039;postgres://postgres:urlencodedpassword@localhost:5432/foo&#039;
[application]
DefaultPageSize = 300
DisableSidebar = false
SidebarOverlay = false
```

The `ReadOnly` field (optional, defaults to `false`) can be set to `true` to enable read-only mode for a connection. When enabled, all mutation queries (INSERT, UPDATE, DELETE, DROP, etc.) will be blocked.

The `[application]` section is used to define some app settings. Not all settings are available yet, this is a work in progress.

## Usage

&gt; For a list of keyboard shortcuts press `?`

Open the TUI with:
```console
$ lazysql
```

To launch lazysql with the ability to pick from the saved connections.
```console
$ lazysql [connection_url]
```

To launch lazysql and connect to database at [connection_url].

```console
$ lazysql --read-only [connection_url]
```

To launch lazysql in read-only mode.

### Connect to a DB

1. Start `lazysql`
2. Create a new connection (press `n`)
3. Provide a name for the connection as well as the URL to connect to (see &lt;a href=&quot;#example-connection-urls&quot;&gt;example connection URL&lt;/a&gt;)
4. Connect to the DB (press `&lt;Enter&gt;`)

If you already have a connection set up:
1. Start `lazysql`
2. Select the right connection (press `j` and `h` for navigation)
3. Connect to the DB (press `c` or `&lt;Enter&gt;`)

### Create a table

There is currently no way to create a table from the TUI.
However you can run the query to create the table as a SQL-Query,
inside the &lt;a href=&quot;#execute-sql-queries&quot;&gt;SQL Editor&lt;/a&gt;.

You can update the tree by pressing `R`, so you can see your newly created table.

### Execute SQL queries

1. Press `&lt;Ctrl+E&gt;` to open the built-in SQL Editor
2. Write the SQL query
3. Press `&lt;Ctrl+R&gt;` to execute the SQL query

&gt; To switch back to the table-tree press `H`
&gt;
&gt; After executing a `SELECT`-query a table will be displayed under the SQL-Editor
&gt; with the query-result. \
&gt; To switch focus back to SQL-Editor press `/`

### Open/view a table

1. Expand the table-tree by pressing `e` or `&lt;Enter&gt;`
2. Select the table you want to view
    - next node `j`
    - previous node `k`
    - last node `G`
    - first node `g`
3. Press `&lt;Enter&gt;` to open the table

&gt; To switch back to the table-tree press `H` \
&gt; To switch back to the table press `L`

### Filter rows

1. [Open a table](#openview-a-table)
2. Press `/` to focus the filter input
3. Write a `WHERE`-clause to filter the table
4. Press `&lt;Enter&gt;` to submit your filter

&gt; To remove the filter, focus the filter input (press `/`) and press `&lt;Esc&gt;`.

### Insert a row

1. [Open a table](#openview-a-table)
2. Press `1` to switch to the record tab
3. Press `o` to insert a new row
4. Fill out all columns
5. Press `&lt;Ctrl+S&gt;` to save the changes

### Edit a column

1. [Open a table](#openview-a-table)
2. Press `1` to switch to the record tab
3. Move to the column you want to edit
4. Press `c` to edit, Press `&lt;Enter&gt;` to submit
5. Press `&lt;Ctrl+S&gt;` to save the changes

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

## Support

- [x] MySQL
- [x] PostgreSQL
- [x] SQLite
- [x] MSSQL
- [ ] MongoDB

Support for multiple RDBMS is a work in progress.

&lt;!-- COMMANDS --&gt;

## Commands

In some cases, mostly when connecting to remote databases, it might be necessary to run a custom command
before being able to connect to the database. For example when you can only access the database through
a remote bastion, you would probably first need to open an SSH tunnel by running the following command
in a separate terminal:

```bash
ssh remote-bastion -L 5432:localhost:5432
```

In order to make it easier to run these commands, lazysql supports running custom commands before connecting
to the database. You can define these commands in the configuration file like this:

```toml
[[database]]
Name = &#039;server&#039;
Provider = &#039;postgres&#039;
DBName = &#039;foo&#039;
URL = &#039;postgres://${user}:password@localhost:${port}/foo&#039;
Commands = [
  { Command = &#039;ssh -tt remote-bastion -L ${port}:localhost:5432&#039;, WaitForPort = &#039;${port}&#039; },
  { Command = &#039;whoami&#039;, SaveOutputTo = &#039;user&#039; },
]
```

The `Command` field is required and can contain any command that you would normally run in your terminal.
The `WaitForPort` field is optional and can be used to wait for a specific port to be open before continuing.
The `SaveOutputTo` field is optional and can be used to make user-defined variables. The output (`stdout`) from the command will be saved into the variable, and the variable can be used in the URL or future commands via the `${VARIABLE}` syntax.

When you define the `${port}` variable in the URL field, lazysql will automatically replace it with a random
free port number. This port number will then be used in the connection URL and is available in the `Commands`
field so that you can use it to configure the command.

You can even chain commands to, for example, connect to a remote server and then to a postgres container
running in a remote k8s cluster:

```toml
[[database]]
Name = &#039;container&#039;
Provider = &#039;postgres&#039;
DBName = &#039;foo&#039;
URL = &#039;postgres://postgres:password@localhost:${port}/foo&#039;
Commands = [
  { Command = &#039;ssh -tt remote-bastion -L 6443:localhost:6443&#039;, WaitForPort = &#039;6443&#039; },
  { Command = &#039;kubectl port-forward service/postgres ${port}:5432 --kubeconfig /path/to/kube.conf&#039;, WaitForPort = &#039;${port}&#039; }
]
```

&lt;!-- KEYBINDINGS --&gt;

## Keybindings

### Global

| Key       | Action                         |
| --------- | ------------------------------ |
| q         | Quit                           |
| CTRL + e  | Open SQL editor                |
| Backspace | Return to connection selection |
| ?         | Show keybindings popup         |

### Table

| Key      | Action                               |
| -------- | ------------------------------------ |
| c        | Edit table cell                      |
| d        | Delete row                           |
| o        | Add row                              |
| /        | Focus the filter input or SQL editor |
| CTRL + s | Commit changes                       |
| &gt;        | Next page                            |
| &lt;        | Previous page                        |
| K        | Sort ASC                             |
| J        | Sort DESC                            |
| H        | Focus tree panel                     |
| {        | Focus previous tab                   |
| }        | Focus next tab                       |
| X        | Close current tab                    |
| R        | Refresh the current table            |

### Tree

| Key    | Action                         |
| ------ | ------------------------------ |
| L      | Focus table panel              |
| G      | Focus last database tree node  |
| g      | Focus first database tree node |
| CTRL+u | Scroll 5 items up              |
| CTRL+d | Scroll 5 items down            |

### SQL Editor

| Key          | Action                            |
| ------------ | --------------------------------- |
| CTRL + R     | Run the SQL statement             |
| CTRL + Space | Open external editor (Linux only) |

Specific editor for lazysql can be set by `$SQL_EDITOR`.

Specific terminal for opening editor can be set by `$SQL_TERMINAL`

## Example connection URLs

```
postgres://user:pass@localhost/dbname
pg://user:pass@localhost/dbname?sslmode=disable
mysql://user:pass@localhost/dbname
mysql:/var/run/mysqld/mysqld.sock
sqlserver://user:pass@remote-host.com/dbname
mssql://user:pass@remote-host.com/instance/dbname
ms://user:pass@remote-host.com:port/instance/dbname?keepAlive=10
oracle://user:pass@somehost.com/sid
sap://user:pass@localhost/dbname
file:myfile.sqlite3?loc=auto
/path/to/sqlite/file/test.db
odbc+postgres://user:pass@localhost:port/dbname?option1=
```

&lt;!-- ROADMAP --&gt;

## Roadmap

- [ ] Support for NoSQL databases
- [ ] Columns and indexes creation through TUI
- [x] Table tree input filter
- [ ] Custom keybindings
- [x] Show keybindings on a modal
- [x] Rewrite row `create`, `update` and `delete` logic

See the [open issues](https://github.com/jorgerojas26/lazysql/issues) for a full list of proposed features (and known issues).

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

## Clipboard support

We use [atotto/clipboard](https://github.com/atotto/clipboard?tab=readme-ov-file#clipboard-for-go) to copy to clipboard.

Platforms:

- OSX
- Windows 7 (probably work on other Windows)
- Linux, Unix (requires &#039;xclip&#039; or &#039;xsel&#039; command to be installed)

&lt;!-- CONTRIBUTING --&gt;

## Contributing

Contributions, issues, and pull requests are welcome!

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

&lt;!-- LICENSE --&gt;

## License

Distributed under the MIT License. See `LICENSE.txt` for more information.

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

&lt;!-- CONTACT --&gt;

## Contact

Jorge Rojas - [LinkedIn](https://www.linkedin.com/in/jorgerojas26/) - jorgeluisrojasb@gmail.com

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

## Alternatives

- [Mitzasql](https://github.com/vladbalmos/mitzasql)
- [Gobang](https://github.com/TaKO8Ki/gobang)

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/jorgerojas26/lazysql?style=for-the-badge
[contributors-url]: https://github.com/jorgerojas26/lazysql/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/jorgerojas26/lazysql?style=for-the-badge
[forks-url]: https://github.com/jorgerojas26/lazysql/network/members
[stars-shield]: https://img.shields.io/github/stars/jorgerojas26/lazysql?style=for-the-badge
[stars-url]: https://github.com/jorgerojas26/lazysql/stargazers
[issues-shield]: https://img.shields.io/github/issues/jorgerojas26/lazysql?style=for-the-badge
[issues-url]: https://github.com/jorgerojas26/lazysql/issues
[license-shield]: https://img.shields.io/github/license/jorgerojas26/lazysql.svg?style=for-the-badge
[license-url]: https://github.com/jorgerojas26/lazysql/blob/main/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;logo=linkedin&amp;colorB=555
[linkedin-url]: https://linkedin.com/in/jorgerojas26
[product-screenshot1]: images/lazysql-connection-selection.png
[product-screenshot2]: images/lazysql.png
[golang-shield]: https://img.shields.io/badge/Golang-gray?style=for-the-badge&amp;logo=go
[tview-shield]: https://img.shields.io/badge/tview-gray?style=for-the-badge&amp;logo=go
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[nezhahq/nezha]]></title>
            <link>https://github.com/nezhahq/nezha</link>
            <guid>https://github.com/nezhahq/nezha</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[Self-hosted, lightweight server and website monitoring and O&M tool]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nezhahq/nezha">nezhahq/nezha</a></h1>
            <p>Self-hosted, lightweight server and website monitoring and O&M tool</p>
            <p>Language: Go</p>
            <p>Stars: 9,509</p>
            <p>Forks: 1,559</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;img width=&quot;360&quot; style=&quot;max-width:80%&quot; src=&quot;.github/brand.svg&quot; title=&quot;Âì™ÂêíÁõëÊéß Nezha Monitoring&quot;&gt;
  &lt;br&gt;
  &lt;small&gt;&lt;i&gt;LOGO designed by &lt;a href=&quot;https://xio.ng&quot; target=&quot;_blank&quot;&gt;ÁÜäÂ§ß&lt;/a&gt; .&lt;/i&gt;&lt;/small&gt;
  &lt;br&gt;&lt;br&gt;
&lt;img alt=&quot;GitHub release (with filter)&quot; src=&quot;https://img.shields.io/github/v/release/nezhahq/nezha?color=brightgreen&amp;style=for-the-badge&amp;logo=github&amp;label=Dashboard&quot;&gt;&amp;nbsp;&lt;img src=&quot;https://img.shields.io/github/v/release/nezhahq/agent?color=brightgreen&amp;label=Agent&amp;style=for-the-badge&amp;logo=github&quot;&gt;&amp;nbsp;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/nezhahq/agent/agent.yml?label=Agent%20CI&amp;logo=github&amp;style=for-the-badge&quot;&gt;&amp;nbsp;&lt;a href=&quot;https://hosted.weblate.org/engage/nezha/&quot;&gt;&lt;img src=&quot;https://img.shields.io/weblate/progress/nezha?color=brightgreen&amp;label=Translated&amp;style=for-the-badge&amp;logo=weblate&quot; alt=&quot;Translation status&quot; /&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;p&gt;:trollface: &lt;b&gt;Nezha Monitoring: Self-hostable, lightweight, servers and websites monitoring and O&amp;M tool.&lt;/b&gt;&lt;/p&gt;
  &lt;p&gt;Supports &lt;b&gt;monitoring&lt;/b&gt; system status, HTTP (SSL certificate change, upcoming expiration, expired), TCP, Ping and supports &lt;b&gt;push alerts&lt;/b&gt;, run scheduled tasks and &lt;b&gt;web terminal&lt;/b&gt;.&lt;/p&gt;
&lt;/div&gt;

\&gt;&gt; Official Forum | ÂÆòÊñπËÆ∫Âùõ: [ÊúâÁÇπÊÑèÊÄù](https://lajilao.com/c/nezha)&lt;br&gt;
\&gt;&gt; Telegram Channel: [Âì™ÂêíÁõëÊéßÔºà‰∏≠ÊñáÈÄöÁü•È¢ëÈÅìÔºâ](https://t.me/nezhanews)&lt;br&gt;

\&gt;&gt; [Use Cases | Êàë‰ª¨ÁöÑÁî®Êà∑](https://www.google.com/search?q=%22%E5%93%AA%E5%90%92%E7%9B%91%E6%8E%A7+Nezha+Monitoring%22) (Google) &lt;br&gt;
&lt;sub&gt;\&gt;&gt; Telegram Group: [Nezha Monitoring Global (English Only)](https://t.me/nezhamonitoring_global), [Âì™ÂêíÁõëÊéßÔºà‰∏≠ÊñáÁæ§ÁªÑÔºâ](https://t.me/nezhamonitoring)&lt;/sub&gt;


## User Guide

- [English](https://nezhahq.github.io/en_US/index.html)
- [‰∏≠ÊñáÊñáÊ°£](https://nezhahq.github.io/index.html)

## Contributing

### Translation

&lt;a href=&quot;https://hosted.weblate.org/engage/nezha/&quot;&gt;
&lt;img src=&quot;https://hosted.weblate.org/widget/nezha/multi-blue.svg&quot; alt=&quot;Translation status&quot; /&gt;
&lt;/a&gt;

Is Nezha not in your language, or the translation is incorrect or incomplete? Get involved in the translations on [Hosted Weblate](https://hosted.weblate.org/engage/nezha/).

## Screenshots

| Áî®Êà∑ÂâçÂè∞ [@hamster1963](https://github.com/hamster1963) | ÁÆ°ÁêÜÂêéÂè∞ [@nezhahq](https://github.com/nezhahq) |
|---|---|
| ![user](.github/user-frontend.20241128.png)  | ![admin](.github/admin-frontend.20241220.jpg)  |
| [hamster1963/nezha-dash](https://github.com/hamster1963/nezha-dash)  | [nezhahq/admin-frontend](https://github.com/nezhahq/admin-frontend)  |

add your theme to [service/singleton/frontend-templates.yaml](service/singleton/frontend-templates.yaml)

## Contributors

&lt;!--GAMFC_DELIMITER--&gt;&lt;a href=&quot;https://github.com/naiba&quot; title=&quot;naiba&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/29243953?v=4&quot; width=&quot;50;&quot; alt=&quot;naiba&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/uubulb&quot; title=&quot;UUBulb&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/35923940?v=4&quot; width=&quot;50;&quot; alt=&quot;UUBulb&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/AkkiaS7&quot; title=&quot;Akkia&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/68485070?v=4&quot; width=&quot;50;&quot; alt=&quot;Akkia&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Erope&quot; title=&quot;ÂçñÂ•≥Â≠©ÁöÑÂ∞èÁÅ´Êü¥&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/44471469?v=4&quot; width=&quot;50;&quot; alt=&quot;ÂçñÂ•≥Â≠©ÁöÑÂ∞èÁÅ´Êü¥&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/nap0o&quot; title=&quot;nap0o&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/144927971?v=4&quot; width=&quot;50;&quot; alt=&quot;nap0o&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/dysf888&quot; title=&quot;ÈªëÊ≠å&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47450409?v=4&quot; width=&quot;50;&quot; alt=&quot;ÈªëÊ≠å&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/xykt&quot; title=&quot;xykt&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/152045469?v=4&quot; width=&quot;50;&quot; alt=&quot;xykt&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/MikoyChinese&quot; title=&quot;MikoyChinese&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/22676744?v=4&quot; width=&quot;50;&quot; alt=&quot;MikoyChinese&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/weblate&quot; title=&quot;Weblate (bot)&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/1607653?v=4&quot; width=&quot;50;&quot; alt=&quot;Weblate (bot)&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/JackieSung4ev&quot; title=&quot;JackieSung4ev&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/24974735?v=4&quot; width=&quot;50;&quot; alt=&quot;JackieSung4ev&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/cantoblanco&quot; title=&quot;Kris&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/116849421?v=4&quot; width=&quot;50;&quot; alt=&quot;Kris&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/lemoeo&quot; title=&quot;Lemoe&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/18618627?v=4&quot; width=&quot;50;&quot; alt=&quot;Lemoe&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/spiritLHLS&quot; title=&quot;spiritlhl&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/103393591?v=4&quot; width=&quot;50;&quot; alt=&quot;spiritlhl&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/liuyanxi975&quot; title=&quot;ÂàòÈ¢úÊ∫™&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/24417037?v=4&quot; width=&quot;50;&quot; alt=&quot;ÂàòÈ¢úÊ∫™&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/CosmosZ-code&quot; title=&quot;CosmosZ-code&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/81398224?v=4&quot; width=&quot;50;&quot; alt=&quot;CosmosZ-code&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/lvgj-stack&quot; title=&quot;Ko no dio&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/38449861?v=4&quot; width=&quot;50;&quot; alt=&quot;Ko no dio&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/hhhkkk520&quot; title=&quot;Kris&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/52115472?v=4&quot; width=&quot;50;&quot; alt=&quot;Kris&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Mmx233&quot; title=&quot;Mmx233&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/36563672?v=4&quot; width=&quot;50;&quot; alt=&quot;Mmx233&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/rootmelo92118&quot; title=&quot;rootmelo92118&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/32770959?v=4&quot; width=&quot;50;&quot; alt=&quot;rootmelo92118&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Moraxyc&quot; title=&quot;Moraxyc Xu&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/69713071?v=4&quot; width=&quot;50;&quot; alt=&quot;Moraxyc Xu&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/1ridic&quot; title=&quot;1ridic&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/88495501?v=4&quot; width=&quot;50;&quot; alt=&quot;1ridic&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/hamster1963&quot; title=&quot;‰ªìÈº†&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/71394853?v=4&quot; width=&quot;50;&quot; alt=&quot;‰ªìÈº†&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/zhucaidan&quot; title=&quot;zhucaidan&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/47970938?v=4&quot; width=&quot;50;&quot; alt=&quot;zhucaidan&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/iilemon&quot; title=&quot;Sean&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/33201711?v=4&quot; width=&quot;50;&quot; alt=&quot;Sean&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/lyj0309&quot; title=&quot;lyj&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/50474995?v=4&quot; width=&quot;50;&quot; alt=&quot;lyj&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/fscarmen&quot; title=&quot;fscarmen&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/62703343?v=4&quot; width=&quot;50;&quot; alt=&quot;fscarmen&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ch8o&quot; title=&quot;no-name-now&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/9103372?v=4&quot; width=&quot;50;&quot; alt=&quot;no-name-now&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/MemoryShadow&quot; title=&quot;JSker9&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/31596045?v=4&quot; width=&quot;50;&quot; alt=&quot;JSker9&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/HsukqiLee&quot; title=&quot;Hsukqi Lee&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/79034142?v=4&quot; width=&quot;50;&quot; alt=&quot;Hsukqi Lee&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/DarcJC&quot; title=&quot;Darc Z.&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/53445798?v=4&quot; width=&quot;50;&quot; alt=&quot;Darc Z.&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Creling&quot; title=&quot;Creling&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/43109504?v=4&quot; width=&quot;50;&quot; alt=&quot;Creling&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/coreff&quot; title=&quot;Core F&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/38347122?v=4&quot; width=&quot;50;&quot; alt=&quot;Core F&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/adminsama&quot; title=&quot;adminsama&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/60880076?v=4&quot; width=&quot;50;&quot; alt=&quot;adminsama&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/acgpiano&quot; title=&quot;Acgpiano&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/15900800?v=4&quot; width=&quot;50;&quot; alt=&quot;Acgpiano&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/eya46&quot; title=&quot;eya46&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/61458340?v=4&quot; width=&quot;50;&quot; alt=&quot;eya46&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/guoyongchang&quot; title=&quot;guoyongchang&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/10484506?v=4&quot; width=&quot;50;&quot; alt=&quot;guoyongchang&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/hiDandelion&quot; title=&quot;hiDandelion&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/77157418?v=4&quot; width=&quot;50;&quot; alt=&quot;hiDandelion&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/honeok&quot; title=&quot;honeok&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/100125733?v=4&quot; width=&quot;50;&quot; alt=&quot;honeok&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/yuanweize&quot; title=&quot;IYUANWEIZE&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/30067203?v=4&quot; width=&quot;50;&quot; alt=&quot;IYUANWEIZE&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/igophper&quot; title=&quot;igophper&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/34326532?v=4&quot; width=&quot;50;&quot; alt=&quot;igophper&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/lvyaoting&quot; title=&quot;lvyaoting&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/166296299?v=4&quot; width=&quot;50;&quot; alt=&quot;lvyaoting&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/quanljh&quot; title=&quot;quanljh&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/38105306?v=4&quot; width=&quot;50;&quot; alt=&quot;quanljh&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/unclezs&quot; title=&quot;unclezs&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/42318775?v=4&quot; width=&quot;50;&quot; alt=&quot;unclezs&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ysicing&quot; title=&quot;ÁºòÁîü&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/8605565?v=4&quot; width=&quot;50;&quot; alt=&quot;ÁºòÁîü&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/yanhao98&quot; title=&quot;‰∏•Êµ©&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/37316281?v=4&quot; width=&quot;50;&quot; alt=&quot;‰∏•Êµ©&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/arkylin&quot; title=&quot;Âáå&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/35104502?v=4&quot; width=&quot;50;&quot; alt=&quot;Âáå&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/yumusb&quot; title=&quot;Ê¶ÜÊú®&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/43062104?v=4&quot; width=&quot;50;&quot; alt=&quot;Ê¶ÜÊú®&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/colour93&quot; title=&quot;93&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/64313711?v=4&quot; width=&quot;50;&quot; alt=&quot;93&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/hmsjy2017&quot; title=&quot;Tony&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/42692274?v=4&quot; width=&quot;50;&quot; alt=&quot;Tony&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/TomyJan&quot; title=&quot;TomyJan&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/67973160?v=4&quot; width=&quot;50;&quot; alt=&quot;TomyJan&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/nickfox-taterli&quot; title=&quot;Tater Li&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/19658596?v=4&quot; width=&quot;50;&quot; alt=&quot;Tater Li&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/IamTaoChen&quot; title=&quot;Tao Chen&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/42793494?v=4&quot; width=&quot;50;&quot; alt=&quot;Tao Chen&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Septrum101&quot; title=&quot;Spetrum&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/11692994?v=4&quot; width=&quot;50;&quot; alt=&quot;Spetrum&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/dreamingsleeping&quot; title=&quot;Nanjing Hopefun Network Technology Co. Ltd.&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/13828658?v=4&quot; width=&quot;50;&quot; alt=&quot;Nanjing Hopefun Network Technology Co. Ltd.&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/silver-ymz&quot; title=&quot;Mingzhuo Yin&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/78400701?v=4&quot; width=&quot;50;&quot; alt=&quot;Mingzhuo Yin&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/MartijnLindeman&quot; title=&quot;Martijn Lindeman&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/78365708?v=4&quot; width=&quot;50;&quot; alt=&quot;Martijn Lindeman&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/funnyzak&quot; title=&quot;Leon&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/2562087?v=4&quot; width=&quot;50;&quot; alt=&quot;Leon&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/KorenKrita&quot; title=&quot;KorenKrita&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/22239339?v=4&quot; width=&quot;50;&quot; alt=&quot;KorenKrita&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/techotaku&quot; title=&quot;Ian Li&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/1948179?v=4&quot; width=&quot;50;&quot; alt=&quot;Ian Li&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/GreenTeodoro839&quot; title=&quot;YiPing Zhang&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/77104800?v=4&quot; width=&quot;50;&quot; alt=&quot;YiPing Zhang&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Es-dese&quot; title=&quot;Esdese&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/71542548?v=4&quot; width=&quot;50;&quot; alt=&quot;Esdese&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/wwng2333&quot; title=&quot;:D&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/17147265?v=4&quot; width=&quot;50;&quot; alt=&quot;:D&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/wellcoming&quot; title=&quot;Coming&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/74850890?v=4&quot; width=&quot;50;&quot; alt=&quot;Coming&quot;/&gt;&lt;/a&gt;&lt;!--GAMFC_DELIMITER_END--&gt;

## Special Thanks
- [IPInfo](https://ipinfo.io/) for providing an accurate GeoIP Database.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=nezhahq/nezha&amp;type=Timeline)](https://star-history.com/#nezhahq/nezha&amp;Timeline)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[aquasecurity/trivy]]></title>
            <link>https://github.com/aquasecurity/trivy</link>
            <guid>https://github.com/aquasecurity/trivy</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aquasecurity/trivy">aquasecurity/trivy</a></h1>
            <p>Find vulnerabilities, misconfigurations, secrets, SBOM in containers, Kubernetes, code repositories, clouds and more</p>
            <p>Language: Go</p>
            <p>Stars: 30,305</p>
            <p>Forks: 2,843</p>
            <p>Stars today: 48 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;docs/imgs/logo.png&quot; width=&quot;200&quot;&gt;

[![GitHub Release][release-img]][release]
[![Test][test-img]][test]
[![Go Report Card][go-report-img]][go-report]
[![License: Apache-2.0][license-img]][license]
[![GitHub Downloads][github-downloads-img]][release]
![Docker Pulls][docker-pulls]

[üìñ Documentation][docs]
&lt;/div&gt;

Trivy ([pronunciation][pronunciation]) is a comprehensive and versatile security scanner.
Trivy has *scanners* that look for security issues, and *targets* where it can find those issues.

Targets (what Trivy can scan):

- Container Image
- Filesystem
- Git Repository (remote)
- Virtual Machine Image
- Kubernetes

Scanners (what Trivy can find there):

- OS packages and software dependencies in use (SBOM)
- Known vulnerabilities (CVEs)
- IaC issues and misconfigurations
- Sensitive information and secrets
- Software licenses

Trivy supports most popular programming languages, operating systems, and platforms. For a complete list, see the [Scanning Coverage] page.

To learn more, go to the [Trivy homepage][homepage] for feature highlights, or to the [Documentation site][docs] for detailed information.

## Quick Start

### Get Trivy

Trivy is available in most common distribution channels. The full list of installation options is available in the [Installation] page. Here are a few popular examples:

- `brew install trivy`
- `docker run aquasec/trivy`
- Download binary from &lt;https://github.com/aquasecurity/trivy/releases/latest/&gt;
- See [Installation] for more

Trivy is integrated with many popular platforms and applications. The complete list of integrations is available in the [Ecosystem] page. Here are a few popular examples:

- [GitHub Actions](https://github.com/aquasecurity/trivy-action)
- [Kubernetes operator](https://github.com/aquasecurity/trivy-operator)
- [VS Code plugin](https://github.com/aquasecurity/trivy-vscode-extension)
- See [Ecosystem] for more

### Canary builds
There are canary builds ([Docker Hub](https://hub.docker.com/r/aquasec/trivy/tags?page=1&amp;name=canary), [GitHub](https://github.com/aquasecurity/trivy/pkgs/container/trivy/75776514?tag=canary), [ECR](https://gallery.ecr.aws/aquasecurity/trivy#canary) images and [binaries](https://github.com/aquasecurity/trivy/actions/workflows/canary.yaml)) generated with every push to the main branch.

Please be aware: canary builds might have critical bugs, so they are not recommended for use in production.

### General usage

```bash
trivy &lt;target&gt; [--scanners &lt;scanner1,scanner2&gt;] &lt;subject&gt;
```

Examples:

```bash
trivy image python:3.4-alpine
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013513-95f18734-233d-45d3-aaf5-d6aec687db0e.mov

&lt;/details&gt;

```bash
trivy fs --scanners vuln,secret,misconfig myproject/
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

https://user-images.githubusercontent.com/1161307/171013917-b1f37810-f434-465c-b01a-22de036bd9b3.mov

&lt;/details&gt;

```bash
trivy k8s --report summary cluster
```

&lt;details&gt;
&lt;summary&gt;Result&lt;/summary&gt;

![k8s summary](docs/imgs/trivy-k8s.png)

&lt;/details&gt;

## FAQ

### How to pronounce the name &quot;Trivy&quot;?

`tri` is pronounced like **tri**gger, `vy` is pronounced like en**vy**.

## Want more? Check out Aqua

If you liked Trivy, you will love Aqua which builds on top of Trivy to provide even more enhanced capabilities for a complete security management offering.  
You can find a high level comparison table specific to Trivy users [here](https://trivy.dev/docs/latest/commercial/compare/).
In addition check out the &lt;https://aquasec.com&gt; website for more information about our products and services.
If you&#039;d like to contact Aqua or request a demo, please use this form: &lt;https://www.aquasec.com/demo&gt;

## Community

Trivy is an [Aqua Security][aquasec] open source project.  
Learn about our open source work and portfolio [here][oss].  
Contact us about any matter by opening a GitHub Discussion [here][discussions]

Please ensure to abide by our [Code of Conduct][code-of-conduct] during all interactions.

[test]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml
[test-img]: https://github.com/aquasecurity/trivy/actions/workflows/test.yaml/badge.svg
[go-report]: https://goreportcard.com/report/github.com/aquasecurity/trivy
[go-report-img]: https://goreportcard.com/badge/github.com/aquasecurity/trivy
[release]: https://github.com/aquasecurity/trivy/releases
[release-img]: https://img.shields.io/github/release/aquasecurity/trivy.svg?logo=github
[github-downloads-img]: https://img.shields.io/github/downloads/aquasecurity/trivy/total?logo=github
[docker-pulls]: https://img.shields.io/docker/pulls/aquasec/trivy?logo=docker&amp;label=docker%20pulls%20%2F%20trivy
[license]: https://github.com/aquasecurity/trivy/blob/main/LICENSE
[license-img]: https://img.shields.io/badge/License-Apache%202.0-blue.svg
[homepage]: https://trivy.dev
[docs]: https://trivy.dev/docs/latest/
[pronunciation]: #how-to-pronounce-the-name-trivy
[code-of-conduct]: https://github.com/aquasecurity/community/blob/main/CODE_OF_CONDUCT.md

[Installation]:https://trivy.dev/docs/latest/getting-started/installation/
[Ecosystem]: https://trivy.dev/docs/latest/ecosystem/
[Scanning Coverage]: https://trivy.dev/docs/latest/coverage/

[alpine]: https://ariadne.space/2021/06/08/the-vulnerability-remediation-lifecycle-of-alpine-containers/
[rego]: https://www.openpolicyagent.org/docs/latest/#rego
[sigstore]: https://www.sigstore.dev/

[aquasec]: https://aquasec.com
[oss]: https://www.aquasec.com/products/open-source-projects/
[discussions]: https://github.com/aquasecurity/trivy/discussions
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[psviderski/uncloud]]></title>
            <link>https://github.com/psviderski/uncloud</link>
            <guid>https://github.com/psviderski/uncloud</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[A lightweight tool for deploying and managing containerised applications across a network of Docker hosts. Bridging the gap between Docker and Kubernetes ‚ú®]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/psviderski/uncloud">psviderski/uncloud</a></h1>
            <p>A lightweight tool for deploying and managing containerised applications across a network of Docker hosts. Bridging the gap between Docker and Kubernetes ‚ú®</p>
            <p>Language: Go</p>
            <p>Stars: 4,053</p>
            <p>Forks: 103</p>
            <p>Stars today: 93 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./website/landing/images/logo-title.svg#gh-light-mode-only&quot; alt=&quot;Uncloud logo&quot;/&gt;
  &lt;img src=&quot;./website/landing/images/logo-title-dark.svg#gh-dark-mode-only&quot; alt=&quot;Uncloud logo&quot;/&gt;
  &lt;p&gt;&lt;strong&gt;‚ñ∏ Docker simplicity. Multi-machine power ‚óÇ&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;https://uncloud.run/docs&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-blue.svg?style=for-the-badge&amp;logo=gitbook&amp;logoColor=white&quot; alt=&quot;Documentation&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/eR35KQJhPu&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/discord-5865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Join Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://x.com/psviderski&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/follow-black?style=for-the-badge&amp;logo=X&amp;logoColor=while&quot; alt=&quot;Follow on X&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/sponsors/psviderski&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Donate-EA4AAA.svg?style=for-the-badge&amp;logo=githubsponsors&amp;logoColor=white&quot; alt=&quot;Donate&quot;&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

Uncloud is a lightweight clustering and container orchestration tool that lets you deploy and manage web apps across
cloud VMs and bare metal with minimised cluster management overhead. It creates a secure WireGuard mesh network between
your Docker hosts and provides automatic service discovery, load balancing, ingress with HTTPS, and simple CLI commands
to manage your apps.

Unlike traditional orchestrators, there&#039;s no central control plane and quorum to maintain. Each machine maintains a
synchronised copy of the cluster state through peer-to-peer communication, keeping cluster operations functional even if
some machines go offline.

Uncloud is the solution for developers who want the flexibility of self-hosted infrastructure without the operational
complexity of Kubernetes.

## ‚ú® Features

* **Deploy anywhere**: Combine cloud VMs, dedicated servers, and bare metal into a unified computing environment,
  regardless of location or provider.
* **Docker Compose**: Familiar [Docker Compose](https://compose-spec.io/) format for defining services and volumes. No
  need to learn a new bespoke DSL.
* **Zero-downtime deployments**: Rolling updates without service interruption. Automatic rollback on failure is coming
  soon.
* **[Unregistry](https://github.com/psviderski/unregistry) integration**: Build and push your Docker images directly to
  your machines without an external registry. It will transfer only the missing layers, making it fast and efficient.
* **Service discovery**: Built-in DNS server resolves service names to container IPs.
* **Persistent storage**: Run stateful services with Docker volumes managed across machines.
* **Zero-config private network**: Automatic WireGuard mesh with peer discovery and NAT traversal. Containers get unique
  IPs for direct cross-machine communication.
* **No control plane**: Fully decentralised design eliminates single points of failure and reduces operational overhead.
* **Imperative over declarative**: Favoring imperative operations over state reconciliation simplifies both the mental
  model and troubleshooting.
* **Managed DNS**: Automatic DNS records `*.&lt;id&gt;.cluster.uncloud.run` for services with public access via managed
  [Uncloud DNS](https://github.com/psviderski/uncloud-dns) service.
* **Automatic HTTPS**: Built-in Caddy reverse proxy handles TLS certificate provisioning and renewal using Let&#039;s
  Encrypt.
* **Docker-like CLI**: Familiar commands for managing both infrastructure and applications.
* **Remote management**: Control your entire infrastructure through SSH access to any single machine in the cluster.

## üé¨ Quick demo

The screenshot below demonstrates how I use Uncloud to deploy https://uncloud.run website to 2 remote machines from
the [`compose.yaml`](website/compose.yaml) file on my local machine.

It exposes the container port `8000/tcp` as HTTPS on the domain `uncloud.run`, served by the Caddy reverse proxy on the
remote machines. All managed by Uncloud.

![Uncloud compose deployment demo](.github/images/compose-deploy.jpg)

Here is a more advanced use case. Deploy a highly available web app with automatic HTTPS across multiple regions and
on-premises in just a couple minutes.

&lt;a href=&quot;https://uncloud.wistia.com/medias/k47uwt9uau?wvideo=k47uwt9uau&quot;&gt;
&lt;img src=&quot;https://embed-ssl.wistia.com/deliveries/3cf7014a48b93afc556444bed3e39a8c.jpg?image_crop_resized=900x526&amp;image_play_button_rounded=true&amp;image_play_button_size=2x&amp;image_play_button_color=18181Be0&quot; alt=&quot;Uncloud demo&quot; width=&quot;450&quot; height=&quot;263&quot; /&gt;
&lt;/a&gt;

&lt;br&gt;
&lt;br&gt;

&gt; **üìö Want more examples?** Check out the [**uncloud-recipes**](https://github.com/psviderski/uncloud-recipes)
&gt; repository for community recipes and templates for deploying popular services on Uncloud.

## üí´ Why Uncloud?

Modern cloud platforms like Heroku and Render offer amazing developer experiences but at a premium price. Traditional
container orchestrators like Kubernetes provide power and flexibility but require significant operational expertise. I
believe there&#039;s a sweet spot in between ‚Äî a pragmatic solution for the majority of us who aren&#039;t running at Google
scale. You should be able to:

* **Own your infrastructure and data**: Whether driven by costs, compliance, or flexibility, run applications on any
  combination of cloud VMs and personal hardware while controlling your data and maintaining the cloud-like experience
  you love.
* **Stay simple as you grow**: Start with a single machine and add more whenever you need without changing your
  workflow. No worrying about highly-available control planes or complex YAML configurations.
* **Build with proven primitives**: Get production-grade networking, deployment primitives, service discovery, load
  balancing, and ingress with HTTPS out of the box without becoming a distributed systems expert.
* **Support sustainable computing** üåø: Minimise system overhead to maximise resources available for your applications.

Uncloud&#039;s goal is to make deployment and management of containerised applications feel as seamless as using a cloud
platform, whether you&#039;re running on a $5 VPS, a spare Mac mini, or a rack of bare metal servers.

## üöÄ Quick start

1. Install Uncloud CLI:

   ```bash
   brew install psviderski/tap/uncloud

   # or using curl (macOS/Linux)
   curl -fsS https://get.uncloud.run/install.sh | sh
   ```

   See [Installation](https://uncloud.run/docs/getting-started/install-cli) for more options.

2. Initialise your first machine:

   ```bash
   uc machine init root@your-server-ip
   ```

3. Deploy your app from a Docker image and publish its container port 8000 as HTTPS using `app.example.com` domain:

   ```bash
   uc run -p app.example.com:8000/https image/my-app
   ```

4. Create a DNS A record in your DNS provider (Cloudflare, Namecheap, etc.) that points `app.example.com` to your
   server&#039;s IP address. Allow a few minutes for DNS propagation.

   That&#039;s it! Your app is now running and accessible at https://app.example.com ‚ú®

5. Clean up when you&#039;re done:

   ```bash
   uc ls
   # Copy the service name from the output and run the rm command:
   uc rm my-app-name
   ```

   If you want to fully uninstall Uncloud on a machine, run:

   ```bash
   uncloud-uninstall
   ```

View the [Documentation](https://uncloud.run/docs) for more information.

## ‚öôÔ∏è How it works

Check out the [design document](misc/design.md) to understand Uncloud&#039;s design philosophy and goals.

Here is a diagram of an Uncloud multi-provider cluster of 3 machines:

![Diagram: multi-provider cluster of 3 machines](website/landing/images/diagram.webp)

&lt;details&gt;
&lt;summary&gt;Peek under the hood to see what happens when you run certain commands.&lt;/summary&gt;

**When you initialise a new cluster on a machine:**

```bash
$ uc machine init --name oracle-vm ubuntu@152.67.101.197

Downloading Uncloud install script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/install.sh
‚è≥ Running Uncloud install script...
‚úì Docker is already installed.
‚è≥ Installing Docker...
...
‚úì Docker installed successfully.
‚úì Linux user and group &#039;uncloud&#039; created.
‚úì Linux user &#039;ubuntu&#039; added to group &#039;uncloud&#039;.
‚è≥ Installing Uncloud binaries...
‚è≥ Downloading uncloudd binary: https://github.com/psviderski/uncloud/releases/latest/download/uncloudd_linux_arm64.tar.gz
‚úì uncloudd binary installed: /usr/local/bin/uncloudd
‚è≥ Downloading uninstall script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/uninstall.sh
‚úì uncloud-uninstall script installed: /usr/local/bin/uncloud-uninstall
‚úì Systemd unit file created: /etc/systemd/system/uncloud.service
Created symlink /etc/systemd/system/multi-user.target.wants/uncloud.service ‚Üí /etc/systemd/system/uncloud.service.
‚è≥ Downloading uncloud-corrosion binary: https://github.com/psviderski/corrosion/releases/latest/download/corrosion-aarch64-unknown-linux-gnu.tar.gz
‚úì uncloud-corrosion binary installed: /usr/local/bin/uncloud-corrosion
‚úì Systemd unit file created: /etc/systemd/system/uncloud-corrosion.service
‚è≥ Starting Uncloud machine daemon (uncloud.service)...
‚úì Uncloud machine daemon started.
‚úì Uncloud installed on the machine successfully! üéâ
Cluster &quot;default&quot; initialised with machine &quot;oracle-vm&quot;
Waiting for the machine to be ready...

Reserved cluster domain: xuw3xd.cluster.uncloud.run
[+] Deploying service caddy 1/1
 ‚úî Container caddy-c47x on oracle-vm  Started                                                                                                                                          0.9s

Updating cluster domain records in Uncloud DNS to point to machines running caddy service...
[+] Verifying internet access to caddy service 1/1
 ‚úî Machine oracle-vm (152.67.101.197)  Reachable                                                                                                                                       0.1s

DNS records updated to use only the internet-reachable machines running caddy service:
  *.xuw3xd.cluster.uncloud.run  A ‚Üí 152.67.101.197
```

1. The CLI SSHs into the machine and installs Docker, the `uncloudd` machine daemon and
   [corrosion](https://github.com/superfly/corrosion) service, managed by systemd.
2. Generates a unique WireGuard key pair, allocates a dedicated subnet `10.210.0.0/24` for the machine and its
   containers, and configures `uncloudd` accordingly. All subsequent communication happens with `uncloudd`
   through its gRPC API over SSH.
3. Configures and starts `corrosion`, a CRDT-based distributed SQLite database to share cluster state between machines.
4. Creates a Docker bridge network connected to the WireGuard interface.
5. This machine becomes an entry point for the newly created cluster which is stored in the cluster config under
   `~/.config/uncloud` on your local machine.

**When you add another machine:**

```bash
$ uc machine add --name hetzner-server root@5.223.45.199
Downloading Uncloud install script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/install.sh
‚è≥ Running Uncloud install script...
‚úì Docker is already installed.
‚úì Linux user and group &#039;uncloud&#039; created.
‚è≥ Installing Uncloud binaries...
‚è≥ Downloading uncloudd binary: https://github.com/psviderski/uncloud/releases/latest/download/uncloudd_linux_amd64.tar.gz
‚úì uncloudd binary installed: /usr/local/bin/uncloudd
‚è≥ Downloading uninstall script: https://raw.githubusercontent.com/psviderski/uncloud/refs/heads/main/scripts/uninstall.sh
‚úì uncloud-uninstall script installed: /usr/local/bin/uncloud-uninstall
‚úì Systemd unit file created: /etc/systemd/system/uncloud.service
Created symlink /etc/systemd/system/multi-user.target.wants/uncloud.service ‚Üí /etc/systemd/system/uncloud.service.
‚è≥ Downloading uncloud-corrosion binary: https://github.com/psviderski/corrosion/releases/latest/download/corrosion-x86_64-unknown-linux-gnu.tar.gz
‚úì uncloud-corrosion binary installed: /usr/local/bin/uncloud-corrosion
‚úì Systemd unit file created: /etc/systemd/system/uncloud-corrosion.service
‚è≥ Starting Uncloud machine daemon (uncloud.service)...
‚úì Uncloud machine daemon started.
‚úì Uncloud installed on the machine successfully! üéâ
Machine &quot;hetzner-server&quot; added to cluster
Waiting for the machine to be ready...

[+] Deploying service caddy 1/1
 ‚úî Container caddy-d36c on hetzner-server  Started                                                                                                                                     1.0s

Updating cluster domain records in Uncloud DNS to point to machines running caddy service...
[+] Verifying internet access to caddy service 2/2
 ‚úî Machine hetzner-server (5.223.45.199)  Reachable                                                                                                                                    0.2s
 ‚úî Machine oracle-vm (152.67.101.197)     Reachable                                                                                                                                    0.1s

DNS records updated to use only the internet-reachable machines running caddy service:
  *.xuw3xd.cluster.uncloud.run  A ‚Üí 152.67.101.197, 5.223.45.199

$ uc machine ls
NAME             STATE   ADDRESS         PUBLIC IP        WIREGUARD ENDPOINTS
oracle-vm        Up      10.210.0.1/24   152.67.101.197   10.0.0.95:51820, 152.67.101.197:51820
hetzner-server   Up      10.210.1.1/24   5.223.45.199     5.223.45.199:51820, [2a01:4ff:2f0:128b::1]:51820
```

1. The second machine gets provisioned just like the first. A non-root SSH user will need `sudo` access.
2. Allocates a new subnet `10.210.1.0/24` for the second machine and its containers.
3. Registers the second machine in the cluster state and exchanges WireGuard keys with the first machine.
4. Both machines establish a WireGuard tunnel between each other, allowing Docker containers connected to the bridge
   network to communicate directly across machines.
5. Configures and starts `corrosion` on the second machine to sync the cluster state.
6. The second machine is added as an alternative entry point in the cluster config.
7. If one of the machines goes offline, the other machine can still serve cluster operations.

If one more machine is added, the process repeats with a new subnet. The new machine needs to establish a WireGuard
connection with only one of the existing machines. Other machines will learn about it through the shared cluster state
and automatically establish a WireGuard tunnel with it.

**When you run a service:**

```bash
$ uc run -p app.example.com:8000/https image/my-app

[+] Running service my-app-1b3b (replicated mode) 1/1
 ‚úî Container my-app-1b3b-tcex on oracle-vm  Started

my-app-1b3b endpoints:
 ‚Ä¢ https://app.example.com ‚Üí :8000
 ‚Ä¢ https://my-app-1b3b.xuw3xd.cluster.uncloud.run ‚Üí :8000
```

1. CLI picks a machine to run your container.
2. `uncloudd` that the CLI communicates with uses [`grpc-proxy`](https://github.com/siderolabs/grpc-proxy) to forward
   the request to the target machine to launch a container there.
3. `uncloudd` on the target machine starts the Docker container in the bridge network and stores its info in the
   cluster&#039;s distributed state.
4. The container gets a cluster-unique IP address from the bridge network (in the `10.210.X.2-254` range) and becomes
   accessible from other machines in the cluster.
5. Caddy reverse proxy which runs in [`global`](https://github.com/compose-spec/compose-spec/blob/main/deploy.md#mode)
   mode on each machine watches the cluster state for new services and updates its configuration to route traffic to the
   new container.

Look ma, no control plane or master nodes to maintain! Just a simple overlay network and eventually consistent state
sync that lets machines work together. Want to check on things or make changes? Connect to any machine either implicitly
using the CLI or directly over SSH. They all have the complete cluster state and can control everything. It&#039;s like each
machine is a full backup of your control plane.
&lt;/details&gt;

## üèó Project status

Uncloud is currently in active development and is **not ready for production use**. Features may change significantly
and there may be breaking changes between releases.

We&#039;d love your input! Here&#039;s how you can contribute:

* üêõ Found a bug? [Open an issue](https://github.com/psviderski/uncloud/issues)
* üí° Have questions, ideas, or need help?
    * Start a discussion or join an existing one in
      the [Discussions](https://github.com/psviderski/uncloud/discussions).
    * Join our [Discord community](https://discord.gg/eR35KQJhPu) where we discuss features, roadmap, implementation
      details, and help each other out.

## üôè Inspiration &amp; Acknowledgements

I&#039;m grateful to the following projects that inspired Uncloud&#039;s design and implementation:

* [Kamal](https://kamal-deploy.org/) ‚Äî for proving that even in the declarative era of Kubernetes there is a place for
  simple deployment tools that use imperative commands without complex orchestration. Kamal powers the multi-billion
  dollar company [37signals](https://37signals.com/) where it was created, and that&#039;s truly inspiring!
* [Fly.io](https://fly.io/) ‚Äî for inspiring my vision for what self-hosted infrastructure should feel like, proving that
  developer experience and powerful infrastructure can coexist beautifully.
* [Tailscale](https://tailscale.com/) ‚Äî for pioneering the vision of decentralised flat mesh networking with an amazing
  user experience that feels like magic.
* [Talos Linux](https://github.com/siderolabs/talos)
  and [KubeSpan](https://www.talos.dev/v1.10/talos-guides/network/kubespan/) ‚Äî for the machine API design using
  [grpc-proxy](https://github.com/siderolabs/grpc-proxy) and for its elegant approach to secure WireGuard-based overlay
  networking with zero configuration.
* [Docker Swarm Classic](https://github.com/docker-archive/classicswarm) and
  [Rancher 1.x](http://rancher-com-website-main-elb-elb-1798790864.us-west-2.elb.amazonaws.com/docs/rancher/v1.6/en/)
  ‚Äî for showing the power of simplicity and pragmatism in container orchestration and that not every problem needs the
  complexity of Kubernetes.

Special thanks to the [Corrosion](https://github.com/superfly/corrosion) project by Fly.io for providing the distributed
SQLite database used to share Uncloud&#039;s cluster state.

## üì´ Stay updated

* Join our [Discord server](https://discord.gg/eR35KQJhPu) for real-time discussions, support, and updates.
* Follow [@psviderski](https://x.com/psviderski) on X/Twitter.
* Subscribe to [my newsletter](https://uncloud.run/#subscribe) to follow the progress, get early insights into new
  features, and be the first to know when it&#039;s ready for production use.
* Watch this repository for releases.

## üíñ Sponsors

These companies and projects are helping Uncloud with their generous sponsorship and/or services:

&lt;!-- Sentry --&gt;
&lt;a href=&quot;https://sentry.io/welcome/&quot;&gt;
  &lt;img height=&quot;100&quot; alt=&quot;Sentry&quot; src=&quot;https://github.com/user-attachments/assets/6c1439c0-d20d-40dc-a669-c9aa94651dfa&quot; /&gt;
&lt;/a&gt;

## ‚ù§Ô∏è Contributors

&lt;a href=&quot;https://trendshift.io/repositories/14069&quot;&gt;
    &lt;img alt=&quot;Trendshift&quot; src=&quot;https://trendshift.io/api/badge/repositories/14069&quot; /&gt;
&lt;/a&gt;

Thank you [@cedws](https://github.com/cedws) for being the first contributor to Uncloud! üéâ

&lt;a href=&quot;https://github.com/psviderski/uncloud/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=psviderski/uncloud&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[base/node]]></title>
            <link>https://github.com/base/node</link>
            <guid>https://github.com/base/node</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[Everything required to run your own Base node]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/base/node">base/node</a></h1>
            <p>Everything required to run your own Base node</p>
            <p>Language: Go</p>
            <p>Stars: 68,675</p>
            <p>Forks: 3,083</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>![Base](logo.webp)

# Base Node

Base is a secure, low-cost, developer-friendly Ethereum L2 built on Optimism&#039;s [OP Stack](https://docs.optimism.io/). This repository contains Docker builds to run your own node on the Base network.

[![Website base.org](https://img.shields.io/website-up-down-green-red/https/base.org.svg)](https://base.org)
[![Docs](https://img.shields.io/badge/docs-up-green)](https://docs.base.org/)
[![Discord](https://img.shields.io/discord/1067165013397213286?label=discord)](https://base.org/discord)
[![Twitter Base](https://img.shields.io/twitter/follow/Base?style=social)](https://x.com/Base)
[![Farcaster Base](https://img.shields.io/badge/Farcaster_Base-3d8fcc)](https://farcaster.xyz/base)

## Quick Start

1. Ensure you have an Ethereum L1 full node RPC available
2. Choose your network:
   - For mainnet: Use `.env.mainnet`
   - For testnet: Use `.env.sepolia`
3. Configure your L1 endpoints in the appropriate `.env` file:
   ```bash
   OP_NODE_L1_ETH_RPC=&lt;your-preferred-l1-rpc&gt;
   OP_NODE_L1_BEACON=&lt;your-preferred-l1-beacon&gt;
   OP_NODE_L1_BEACON_ARCHIVER=&lt;your-preferred-l1-beacon-archiver&gt;
   ```
4. Start the node:

   ```bash
   # For mainnet (default):
   docker compose up --build

   # For testnet:
   NETWORK_ENV=.env.sepolia docker compose up --build

   # To use a specific client (optional):
   CLIENT=reth docker compose up --build

   # For testnet with a specific client:
   NETWORK_ENV=.env.sepolia CLIENT=reth docker compose up --build
   ```

### Supported Clients

- `reth` (default)
- `geth`
- `nethermind`

## Requirements

### Minimum Requirements

- Modern Multicore CPU
- 32GB RAM (64GB Recommended)
- NVMe SSD drive
- Storage: (2 \* [current chain size](https://base.org/stats) + [snapshot size](https://basechaindata.vercel.app) + 20% buffer) (to accommodate future growth)
- Docker and Docker Compose

### Production Hardware Specifications

The following are the hardware specifications we use in production:

#### Reth Archive Node (recommended)

- **Instance**: AWS i7i.12xlarge
- **Storage**: RAID 0 of all local NVMe drives (`/dev/nvme*`)
- **Filesystem**: ext4

#### Geth Full Node

- **Instance**: AWS i7i.12xlarge
- **Storage**: RAID 0 of all local NVMe drives (`/dev/nvme*`)
- **Filesystem**: ext4

&gt; [!NOTE]
To run the node using a supported client, you can use the following command:
`CLIENT=supported_client docker compose up --build`
 
Supported clients:
 - reth (runs vanilla node by default, Flashblocks mode enabled by providing RETH_FB_WEBSOCKET_URL, see [Reth Node README](./reth/README.md))
 - geth
 - nethermind

## Configuration

### Required Settings

- L1 Configuration:
  - `OP_NODE_L1_ETH_RPC`: Your Ethereum L1 node RPC endpoint
  - `OP_NODE_L1_BEACON`: Your L1 beacon node endpoint
  - `OP_NODE_L1_BEACON_ARCHIVER`: Your L1 beacon archiver endpoint
  - `OP_NODE_L1_RPC_KIND`: The type of RPC provider being used (default: &quot;debug_geth&quot;). Supported values:
    - `alchemy`: Alchemy RPC provider
    - `quicknode`: QuickNode RPC provider
    - `infura`: Infura RPC provider
    - `parity`: Parity RPC provider
    - `nethermind`: Nethermind RPC provider
    - `debug_geth`: Debug Geth RPC provider
    - `erigon`: Erigon RPC provider
    - `basic`: Basic RPC provider (standard receipt fetching only)
    - `any`: Any available RPC method
    - `standard`: Standard RPC methods including newer optimized methods

### Network Settings

- Mainnet:
  - `RETH_CHAIN=base`
  - `OP_NODE_NETWORK=base-mainnet`
  - Sequencer: `https://mainnet-sequencer.base.org`

### Performance Settings

- Cache Settings:
  - `GETH_CACHE=&quot;20480&quot;` (20GB)
  - `GETH_CACHE_DATABASE=&quot;20&quot;` (4GB)
  - `GETH_CACHE_GC=&quot;12&quot;`
  - `GETH_CACHE_SNAPSHOT=&quot;24&quot;`
  - `GETH_CACHE_TRIE=&quot;44&quot;`

### Optional Features

- EthStats Monitoring (uncomment to enable)
- Trusted RPC Mode (uncomment to enable)
- Snap Sync (experimental)

For full configuration options, see the `.env.mainnet` file.

## Snapshots

Snapshots are available to help you sync your node more quickly. See [docs.base.org](https://docs.base.org/chain/run-a-base-node#snapshots) for links and more details on how to restore from a snapshot.

## Supported Networks

| Network | Status |
| ------- | ------ |
| Mainnet | ‚úÖ     |
| Testnet | ‚úÖ     |

## Troubleshooting

For support please join our [Discord](https://discord.gg/buildonbase) post in `üõ†ÔΩúnode-operators`. You can alternatively open a new GitHub issue.

## Disclaimer

THE NODE SOFTWARE IS PROVIDED &quot;AS IS&quot; WITHOUT WARRANTY OF ANY KIND. We make no guarantees about asset protection or security. Usage is subject to applicable laws and regulations.

For more information, visit [docs.base.org](https://docs.base.org/).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[v2fly/domain-list-community]]></title>
            <link>https://github.com/v2fly/domain-list-community</link>
            <guid>https://github.com/v2fly/domain-list-community</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[Community managed domain list. Generate geosite.dat for V2Ray.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/v2fly/domain-list-community">v2fly/domain-list-community</a></h1>
            <p>Community managed domain list. Generate geosite.dat for V2Ray.</p>
            <p>Language: Go</p>
            <p>Stars: 6,909</p>
            <p>Forks: 1,138</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># Domain list community

This project manages a list of domains, to be used as geosites for routing purpose in Project V.

## Purpose of this project

This project is not opinionated. In other words, it does NOT endorse, claim or imply that a domain should be blocked or proxied. It can be used to generate routing rules on demand.

## Download links

- **dlc.dat**Ôºö[https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat](https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat)
- **dlc.dat.sha256sum**Ôºö[https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum](https://github.com/v2fly/domain-list-community/releases/latest/download/dlc.dat.sha256sum)

## Usage example

Each file in the `data` directory can be used as a rule in this format: `geosite:filename`.

```json
&quot;routing&quot;: {
  &quot;domainStrategy&quot;: &quot;IPIfNonMatch&quot;,
  &quot;rules&quot;: [
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Reject&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-ads-all&quot;,
        &quot;geosite:category-porn&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Direct&quot;,
      &quot;domain&quot;: [
        &quot;domain:icloud.com&quot;,
        &quot;domain:icloud-content.com&quot;,
        &quot;domain:cdn-apple.com&quot;,
        &quot;geosite:cn&quot;,
        &quot;geosite:private&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-1&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-anticensorship&quot;,
        &quot;geosite:category-media&quot;,
        &quot;geosite:category-vpnservices&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-2&quot;,
      &quot;domain&quot;: [
        &quot;geosite:category-dev&quot;
      ]
    },
    {
      &quot;type&quot;: &quot;field&quot;,
      &quot;outboundTag&quot;: &quot;Proxy-3&quot;,
      &quot;domain&quot;: [
        &quot;geosite:geolocation-!cn&quot;
      ]
    }
  ]
}
```

## Generate `dlc.dat` manually

- Install `golang` and `git`
- Clone project code: `git clone https://github.com/v2fly/domain-list-community.git`
- Navigate to project root directory: `cd domain-list-community`
- Install project dependencies: `go mod download`
- Generate `dlc.dat` (without `datapath` option means to use domain lists in `data` directory of current working directory):
  - `go run ./`
  - `go run ./ --datapath=/path/to/your/custom/data/directory`

Run `go run ./ --help` for more usage information.

## Structure of data

All data are under `data` directory. Each file in the directory represents a sub-list of domains, named by the file name. File content is in the following format.

```
# comments
include:another-file
domain:google.com @attr1 @attr2
keyword:google
regexp:www\.google\.com$
full:www.google.com
```

**Syntax:**

&gt; The following types of rules are **NOT** fully compatible with the ones that defined by user in V2Ray config file. Do **Not** copy and paste directly.

* Comment begins with `#`. It may begin anywhere in the file. The content in the line after `#` is treated as comment and ignored in production.
* Inclusion begins with `include:`, followed by the file name of an existing file in the same directory.
* Subdomain begins with `domain:`, followed by a valid domain name. The prefix `domain:` may be omitted.
* Keyword begins with `keyword:`, followed by a string.
* Regular expression begins with `regexp:`, followed by a valid regular expression (per Golang&#039;s standard).
* Full domain begins with `full:`, followed by a complete and valid domain name.
* Domains (including `domain`, `keyword`, `regexp` and `full`) may have one or more attributes. Each attribute begins with `@` and followed by the name of the attribute.

&gt; **Note:** Adding new `regexp` and `keyword` rules is discouraged because it is easy to use them incorrectly, and proxy software cannot efficiently match these types of rules.

## How it works

The entire `data` directory will be built into an external `geosite` file for Project V. Each file in the directory represents a section in the generated file.

To generate a section:

1. Remove all the comments in the file.
2. Replace `include:` lines with the actual content of the file.
3. Omit all empty lines.
4. Generate each `domain:` line into a [sub-domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/config.proto#L21).
5. Generate each `keyword:` line into a [plain domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/config.proto#L17).
6. Generate each `regexp:` line into a [regex domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/config.proto#L19).
7. Generate each `full:` line into a [full domain routing rule](https://github.com/v2fly/v2ray-core/blob/master/app/router/config.proto#L23).

## How to organize domains

### File name

Theoretically any string can be used as the name, as long as it is a valid file name. In practice, we prefer names for determinic group of domains, such as the owner (usually a company name) of the domains, e.g., &quot;google&quot;, &quot;netflix&quot;. Names with unclear scope are generally unrecommended, such as &quot;evil&quot;, or &quot;local&quot;.

### Attributes

Attribute is useful for sub-group of domains, especially for filtering purpose. For example, the list of `google` domains may contains its main domains, as well as domains that serve ads. The ads domains may be marked by attribute `@ads`, and can be used as `geosite:google@ads` in V2Ray routing.

## Contribution guideline

* Fork this repo, make modifications to your own repo, file a PR.
* Please begin with small size PRs, say modification in a single file.
* A PR must be reviewed and approved by another member.
* A script will verify your pull request to test whether your PR is correct or not every time you update the PR. Only the PR which passes the test will be merged. Please go to the Action label to get detailed information if you didn&#039;t pass it. We also provide the file which has been generated to make you test.
* After a few successful PRs, you may apply for manager access to this repository.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[docker/cagent]]></title>
            <link>https://github.com/docker/cagent</link>
            <guid>https://github.com/docker/cagent</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Agent Builder and Runtime by Docker Engineering]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/docker/cagent">docker/cagent</a></h1>
            <p>Agent Builder and Runtime by Docker Engineering</p>
            <p>Language: Go</p>
            <p>Stars: 1,712</p>
            <p>Forks: 186</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># ü§ñ `cagent` ü§ñ

&gt; A powerful, easy-to-use, customizable multi-agent runtime that orchestrates AI
&gt; agents with specialized capabilities and tools, and the interactions between
&gt; agents.

![cagent in action](docs/demo.gif)

## ‚ú® What is `cagent`? ‚ú®

`cagent` lets you create and run intelligent AI agents, where each agent has
specialized knowledge, tools and capabilities.

Think of it as allowing you to quickly build, share and run a team of virtual
experts that collaborate to solve complex problems for you.

And it&#039;s dead easy to use!

‚ö†Ô∏è Note: `cagent` is in active development, **breaking changes are to be
expected** ‚ö†Ô∏è

### Your First Agent

Example [basic_agent.yaml](/examples/basic_agent.yaml):

Creating agents with cagent is straightforward. They are described in a short .yaml
file, like this one:

```yaml
agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses.
```

Run it in a terminal with `cagent run basic_agent.yaml`.

Many more examples can be found [here](/examples/README.md)!

### Improving an agent with MCP tools

`cagent` supports MCP servers, enabling agents to use a wide variety of external
tools and services.

It supports three transport types: `stdio`, `http` and `sse`.

Giving an agent access to tools via MCP is a quick way to greatly improve its
capabilities, the quality of its results and its general usefulness.

Get started quickly with the [Docker MCP
Toolkit](https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/) and
[catalog](https://docs.docker.com/ai/mcp-catalog-and-toolkit/catalog/)

Here, we&#039;re giving the same basic agent from the example above access to a
**containerized** `duckduckgo` mcp server and its tools by using Docker&#039;s MCP
Gateway:

```yaml
agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses.
    toolsets:
      - type: mcp
        ref: docker:duckduckgo # stdio transport
```

When using a containerized server via the Docker MCP gateway, you can configure
any required settings/secrets/authentication using the [Docker MCP
Toolkit](https://docs.docker.com/ai/mcp-catalog-and-toolkit/toolkit/#example-use-the-github-official-mcp-server)
in Docker Desktop.

Aside from the containerized MCP servers the Docker MCP Gateway provides, any
standard MCP server can be used with cagent!

Here&#039;s an example similar to the above but adding `read_file` and `write_file`
tools from the `rust-mcp-filesystem` MCP server:

```yaml
agents:
  root:
    model: openai/gpt-5-mini
    description: A helpful AI assistant
    instruction: |
      You are a knowledgeable assistant that helps users with various tasks.
      Be helpful, accurate, and concise in your responses. Write your search results to disk.
    toolsets:
      - type: mcp
        ref: docker:duckduckgo
      - type: mcp
        command: rust-mcp-filesystem # installed with `cargo install rust-mcp-filesystem`
        args: [&quot;--allow-write&quot;, &quot;.&quot;]
        tools: [&quot;read_file&quot;, &quot;write_file&quot;] # Optional: specific tools only
        env:
          - &quot;RUST_LOG=debug&quot;
```

See [the USAGE docs](./docs/USAGE.md#tool-configuration) for more detailed
information and examples

### Exposing agents as MCP tools

`cagent` can expose agents as MCP tools via the `cagent mcp` command, allowing other MCP clients to use your agents.

Each agent in your configuration becomes an MCP tool with its description.

```bash
# Start MCP server with local file
cagent mcp ./examples/dev-team.yaml

# Or use an OCI artifact
cagent mcp agentcatalog/pirate
```

This exposes each agent as a tool (e.g., `root`, `designer`, `awesome_engineer`) that MCP clients can call:

```json
{
  &quot;method&quot;: &quot;tools/call&quot;,
  &quot;params&quot;: {
    &quot;name&quot;: &quot;designer&quot;,
    &quot;arguments&quot;: {
      &quot;message&quot;: &quot;Design a login page&quot;
    }
  }
}
```

See [MCP Mode documentation](./docs/MCP-MODE.md) for detailed instructions on exposing your agents through MCP with Claude Desktop, Claude Code, and other MCP clients.

### üéØ Key Features

- **üèóÔ∏è Multi-agent architecture** - Create specialized agents for different
  domains.
- **üîß Rich tool ecosystem** - Agents can use external tools and APIs via the
  MCP protocol.
- **üîÑ Smart delegation** - Agents can automatically route tasks to the most
  suitable specialist.
- **üìù YAML configuration** - Declarative model and agent configuration.
- **üí≠ Advanced reasoning** - Built-in &quot;think&quot;, &quot;todo&quot; and &quot;memory&quot; tools for
  complex problem-solving.
- **üîç RAG (Retrieval-Augmented Generation)** - Pluggable retrieval strategies
  (BM25, chunked-embeddings, semantic-embeddings) with hybrid retrieval, result fusion and reranking support.
- **üåê Multiple AI providers** - Support for OpenAI, Anthropic, Gemini, xAI,
  Mistral, Nebius and [Docker Model
  Runner](https://docs.docker.com/ai/model-runner/).

## üöÄ Quick Start üöÄ

### Installation

#### Using Homebrew

Install `cagent` with a single command using [homebrew](https://brew.sh/)!

```sh
$ brew install cagent
```

#### Using binary releases

[Prebuilt binaries](https://github.com/docker/cagent/releases) for Windows,
macOS and Linux can be found on the release page of the [project&#039;s GitHub
repository](https://github.com/docker/cagent/releases)

Once you&#039;ve downloaded the appropriate binary for your platform, you may need to
give it executable permissions. On macOS and Linux, this is done with the
following command:

```sh
# linux amd64 build example
chmod +x /path/to/downloads/cagent-linux-amd64
```

You can then rename the binary to `cagent` and configure your `PATH` to be able
to find it (configuration varies by platform).

### **Set your API keys**

Based on the models you configure your agents to use, you will need to set the
corresponding provider API key accordingly, all these keys are optional, you
will likely need at least one of these, though:

```bash
# For OpenAI models
export OPENAI_API_KEY=your_api_key_here

# For Anthropic models
export ANTHROPIC_API_KEY=your_api_key_here

# For Gemini models
export GOOGLE_API_KEY=your_api_key_here

# For xAI models
export XAI_API_KEY=your_api_key_here

# For Nebius models
export NEBIUS_API_KEY=your_api_key_here

# For Mistral models
export MISTRAL_API_KEY=your_api_key_here
```

### Run Agents!

```bash
# Run an agent!
cagent run ./examples/pirate.yaml

# or specify a different starting agent from the config, useful for agent teams
cagent run ./examples/pirate.yaml -a root

# or run directly from an image reference here I&#039;m pulling the pirate agent from the creek repository
cagent run creek/pirate
```

### Multi-agent team example

```yaml
agents:
  root:
    model: claude
    description: &quot;Main coordinator agent that delegates tasks and manages workflow&quot;
    instruction: |
      You are the root coordinator agent. Your job is to:
      1. Understand user requests and break them down into manageable tasks
      2. Delegate appropriate tasks to your helper agent
      3. Coordinate responses and ensure tasks are completed properly
      4. Provide final responses to the user
      When you receive a request, analyze what needs to be done and decide whether to:
      - Handle it yourself if it&#039;s simple
      - Delegate to the helper agent if it requires specific assistance
      - Break complex requests into multiple sub-tasks
    sub_agents: [&quot;helper&quot;]

  helper:
    model: claude
    description: &quot;Assistant agent that helps with various tasks as directed by the root agent&quot;
    instruction: |
      You are a helpful assistant agent. Your role is to:
      1. Complete specific tasks assigned by the root agent
      2. Provide detailed and accurate responses
      3. Ask for clarification if tasks are unclear
      4. Report back to the root agent with your results

      Focus on being thorough and helpful in whatever task you&#039;re given.

models:
  claude:
    provider: anthropic
    model: claude-sonnet-4-0
    max_tokens: 64000
```

You&#039;ll find a curated list of agents examples, spread into 3 categories,
[Basic](https://github.com/docker/cagent/tree/main/examples#basic-configurations),
[Advanced](https://github.com/docker/cagent/tree/main/examples#advanced-configurations)
and
[multi-agents](https://github.com/docker/cagent/tree/main/examples#multi-agent-configurations)
in the `/examples/` directory.

### DMR (Docker Model Runner) provider options

When using the `dmr` provider, you can use the `provider_opts` key for DMR
runtime-specific (e.g. llama.cpp/vllm) options and speculative decoding:

```yaml
models:
  local-qwen:
    provider: dmr
    model: ai/qwen3
    max_tokens: 8192
    provider_opts:
      # general flags passed to the underlying model runtime
      runtime_flags: [&quot;--ngl=33&quot;, &quot;--repeat-penalty=1.2&quot;, ...] # or comma/space-separated string
      # speculative decoding for faster inference
      speculative_draft_model: ai/qwen3:1B
      speculative_num_tokens: 5
      speculative_acceptance_rate: 0.8
```

The default base_url `cagent` will use for DMR providers is
`http://localhost:12434/engines/llama.cpp/v1`. DMR itself might need to be
enabled via [Docker Desktop&#039;s
settings](https://docs.docker.com/ai/model-runner/get-started/#enable-dmr-in-docker-desktop)
on macOS and Windows, and via the command-line on [Docker CE on
Linux](https://docs.docker.com/ai/model-runner/get-started/#enable-dmr-in-docker-engine).

See the [DMR Provider documentation](docs/USAGE.md#dmr-docker-model-runner-provider-usage) for more details on runtime flags and speculative decoding options.

## RAG (Retrieval-Augmented Generation)

Give your agents access to your documents with cagent&#039;s modular RAG system. It supports multiple retrieval strategies that can be used individually or combined for hybrid search.

### Quick RAG Example

```yaml
models:
  embedder:
    provider: openai
    model: text-embedding-3-small

rag:
  my_knowledge_base:
    docs: [./documents, ./pdfs]
    strategies:
      - type: chunked-embeddings
        model: embedder
        threshold: 0.5
        chunking:
          size: 1000
          overlap: 100
    results:
      limit: 5

agents:
  root:
    model: openai/gpt-4o
    instruction: |
      You are an assistant with access to an internal knowledge base.
      Use the knowledge base to gather context before answering user questions
    rag: [my_knowledge_base]
```

### Hybrid Retrieval (Chunked-Embeddings + BM25)

Combine semantic search (chunked-embeddings) with keyword search (BM25) for best results:

```yaml
rag:
  hybrid_search:
    docs: [./shared_docs]
    
    strategies:
      - type: chunked-embeddings
        model: embedder
        threshold: 0.5
        limit: 20
        chunking:
          size: 1000
          overlap: 100
      
      - type: bm25
        k1: 1.5
        b: 0.75
        threshold: 0.3
        limit: 15
        chunking:
          size: 1000
          overlap: 100
    
    results:
      fusion:
        strategy: rrf  # Reciprocal Rank Fusion
        k: 60
      deduplicate: true
      limit: 5

agents:
  root:
    model: openai/gpt-4o
    rag: [hybrid_search]
```

**Features:**
- **Multiple strategies**: Vector embeddings, semantic embeddings, BM25 (keyword), or combinations
- **Parallel execution**: Strategies run concurrently for fast results
- **Pluggable fusion**: RRF, weighted, or max score combining
- **Result reranking**: Re-score results with specialized models for improved relevance
- **Per-strategy configuration**: Different thresholds, limits, and documents
- **Auto file watching**: Reindex automatically on file changes

### Result Reranking

Improve search quality by re-scoring retrieved results with a reranking model:

```yaml
rag:
  knowledge_base:
    docs: [./documents]
    strategies:
      - type: chunked-embeddings
        model: openai/text-embedding-3-small
        limit: 20  # Retrieve more candidates for reranking
    
    results:
      reranking:
        model: openai/gpt-4.1-mini   # Any chat model or DMR reranker
        top_k: 10                   # Only rerank top 10 (optional)
        threshold: 0.3              # Filter low-scoring results (optional)
        criteria: |                 # Domain-specific relevance guidance (optional, not used with DMR reranking specific models)
          Prioritize recent documentation and practical examples.
          Documents from official sources are more relevant.
      limit: 5  # Final top results after reranking
```

**Supported providers:** DMR (native `/rerank` endpoint), OpenAI, Anthropic, Gemini (via structured outputs)  
**Note:** Temperature defaults to 0.0 for more deterministic scoring when not explicitly set.

See the [RAG documentation in USAGE.md](docs/USAGE.md#rag-configuration) for complete details, examples, and debugging guides.

## Quickly generate agents and agent teams with `cagent new`

Using the command `cagent new` you can quickly generate agents or multi-agent
teams using a single prompt!  
`cagent` has a built-in agent dedicated to this task.

To use the feature, you must have an Anthropic, OpenAI or Google API key
available in your environment or specify a local model to run with DMR (Docker
Model Runner).

You can choose what provider and model gets used by passing the `--model
provider/modelname` flag to `cagent new`

If `--model` is unspecified, `cagent new` will automatically choose between
these three providers in order based on the first api key it finds in your
environment.

```sh
export ANTHROPIC_API_KEY=your_api_key_here  # first choice. default model claude-sonnet-4-0
export OPENAI_API_KEY=your_api_key_here     # if anthropic key not set. default model gpt-5-mini
export GOOGLE_API_KEY=your_api_key_here     # if anthropic and openai keys are not set. default model gemini-2.5-flash
```

`--max-tokens` can be specified to override the context limit used.  
When using DMR, the default is 16k to limit memory usage. With all other
providers the default is 64k

`--max-iterations` can be specified to override how many times the agent is
allowed to loop when doing tool calling etc. When using DMR, the default is set
to 20 (small local models have the highest chance of getting confused and
looping endlessly). For all other providers, the default is 0 (unlimited).

Example of provider, model, context size and max iterations overriding:

```sh
# Use GPT-5 via OpenAI
cagent new --model openai/gpt-5

# Use a local model (ai/gemma3-qat:12B) via DMR
cagent new --model dmr/ai/gemma3-qat:12B

# Override the max_tokens used during generation, default is 64k, 16k when using the dmr provider
cagent new --model openai/gpt-5-mini --max-tokens 32000

# Override max_iterations to limit how much the model can loop autonomously when tool calling
cagent new --model dmr/ai/gemma3n:2B-F16 --max-iterations 15
```

---

```
$ cagent new

------- Welcome to cagent! -------
(Ctrl+C to stop the agent and exit)

What should your agent/agent team do? (describe its purpose):

&gt; I need an agent team that connects to &lt;some-service&gt; and does...
```

## Pushing and pulling agents from Docker Hub

### `cagent push`

Agent configurations can be packaged and shared to Docker Hub using the `cagent
push` command

```sh
cagent push ./&lt;agent-file&gt;.yaml namespace/reponame
```

`cagent` will automatically build an OCI image and push it to the desired
repository using your Docker credentials

### `cagent pull`

Pulling agents from Docker Hub is also just one `cagent pull` command away.

```sh
cagent pull creek/pirate
```

`cagent` will pull the image, extract the .yaml file and place it in your working
directory for ease of use.

`cagent run creek.yaml` will run your newly pulled agent

## Usage

More details on the usage and configuration of `cagent` can be found in
[USAGE.md](/docs/USAGE.md)

## Telemetry

We track anonymous usage data to improve the tool. See
[TELEMETRY.md](/docs/TELEMETRY.md) for details.

## Contributing

Want to hack on `cagent`, or help us fix bugs and build out some features? üîß

Read the information on how to build from source and contribute to the project
in [CONTRIBUTING.md](/docs/CONTRIBUTING.md)

## DogFooding: using `cagent` to code on `cagent`

A smart way to improve `cagent`&#039;s codebase and feature set is to do it with the
help of a `cagent` agent!

We have one that we use and that you should use too:

```sh
cd cagent
cagent run ./golang_developer.yaml
```

This agent is an _expert Golang developer specializing in the cagent multi-agent
AI system architecture_.

Ask it anything about `cagent`. It can be questions about the current code or
about improvements to the code. It can also fix issues and implement new
features!

## Share your feedback

We‚Äôd love to hear your thoughts on this project. You can find us on
[Slack](https://dockercommunity.slack.com/archives/C09DASHHRU4)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[AdguardTeam/AdGuardHome]]></title>
            <link>https://github.com/AdguardTeam/AdGuardHome</link>
            <guid>https://github.com/AdguardTeam/AdGuardHome</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[Network-wide ads & trackers blocking DNS server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AdguardTeam/AdGuardHome">AdguardTeam/AdGuardHome</a></h1>
            <p>Network-wide ads & trackers blocking DNS server</p>
            <p>Language: Go</p>
            <p>Stars: 31,332</p>
            <p>Forks: 2,184</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>&amp;nbsp;
&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;doc/adguard_home_darkmode.svg&quot;&gt;
    &lt;img alt=&quot;AdGuard Home&quot; src=&quot;doc/adguard_home_lightmode.svg&quot; width=&quot;300px&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;
&lt;h3 align=&quot;center&quot;&gt;Privacy protection center for you and your devices&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
  Free and open source, powerful network-wide ads &amp; trackers blocking DNS server.
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://adguard.com/&quot;&gt;AdGuard.com&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/AdguardTeam/AdGuardHome/wiki&quot;&gt;Wiki&lt;/a&gt; |
  &lt;a href=&quot;https://reddit.com/r/Adguard&quot;&gt;Reddit&lt;/a&gt; |
  &lt;a href=&quot;https://twitter.com/AdGuard&quot;&gt;Twitter&lt;/a&gt; |
  &lt;a href=&quot;https://t.me/adguard_en&quot;&gt;Telegram&lt;/a&gt;
  &lt;br/&gt;&lt;br/&gt;
  &lt;a href=&quot;https://codecov.io/github/AdguardTeam/AdGuardHome?branch=master&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/codecov/c/github/AdguardTeam/AdGuardHome/master.svg&quot; alt=&quot;Code Coverage&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://goreportcard.com/report/AdguardTeam/AdGuardHome&quot;&gt;
    &lt;img src=&quot;https://goreportcard.com/badge/github.com/AdguardTeam/AdGuardHome&quot; alt=&quot;Go Report Card&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/r/adguard/adguardhome&quot;&gt;
    &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/adguard/adguardhome.svg?maxAge=604800&quot;/&gt;
  &lt;/a&gt;
  &lt;br/&gt;
  &lt;a href=&quot;https://github.com/AdguardTeam/AdGuardHome/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/release/AdguardTeam/AdGuardHome/all.svg&quot; alt=&quot;Latest release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://snapcraft.io/adguard-home&quot;&gt;
    &lt;img alt=&quot;adguard-home&quot; src=&quot;https://snapcraft.io/adguard-home/badge.svg&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://cdn.adtidy.org/public/Adguard/Common/adguard_home.gif&quot; width=&quot;800&quot;/&gt;
&lt;/p&gt;
&lt;hr/&gt;

AdGuard Home is a network-wide software for blocking ads and tracking. After you set it up, it&#039;ll cover ALL your home devices, and you don&#039;t need any client-side software for that.

It operates as a DNS server that re-routes tracking domains to a ‚Äúblack hole‚Äù, thus preventing your devices from connecting to those servers. It&#039;s based on software we use for our public [AdGuard DNS] servers, and both share a lot of code.

[AdGuard DNS]: https://adguard-dns.io/

- [Getting Started](#getting-started)
    - [Automated install (Linux/Unix/MacOS/FreeBSD/OpenBSD)](#automated-install-linux-and-mac)
    - [Alternative methods](#alternative-methods)
    - [Guides](#guides)
    - [API](#api)
- [Comparing AdGuard Home to other solutions](#comparison)
    - [How is this different from public AdGuard DNS servers?](#comparison-adguard-dns)
    - [How does AdGuard Home compare to Pi-Hole](#comparison-pi-hole)
    - [How does AdGuard Home compare to traditional ad blockers](#comparison-adblock)
    - [Known limitations](#comparison-limitations)
- [How to build from source](#how-to-build)
    - [Prerequisites](#prerequisites)
    - [Building](#building)
- [Contributing](#contributing)
    - [Test unstable versions](#test-unstable-versions)
    - [Reporting issues](#reporting-issues)
    - [Help with translations](#translate)
    - [Other](#help-other)
- [Projects that use AdGuard Home](#uses)
- [Acknowledgments](#acknowledgments)
- [Privacy](#privacy)

## &lt;a href=&quot;#getting-started&quot; id=&quot;getting-started&quot; name=&quot;getting-started&quot;&gt;Getting Started&lt;/a&gt;

### &lt;a href=&quot;#automated-install-linux-and-mac&quot; id=&quot;automated-install-linux-and-mac&quot; name=&quot;automated-install-linux-and-mac&quot;&gt;Automated install (Linux/Unix/MacOS/FreeBSD/OpenBSD)&lt;/a&gt;

To install with `curl` run the following command:

```sh
curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v
```

To install with `wget` run the following command:

```sh
wget --no-verbose -O - https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v
```

To install with `fetch` run the following command:

```sh
fetch -o - https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -v
```

The script also accepts some options:

- `-c &lt;channel&gt;` to use specified channel;
- `-r` to reinstall AdGuard Home;
- `-u` to uninstall AdGuard Home;
- `-v` for verbose output.

Note that options `-r` and `-u` are mutually exclusive.

### &lt;a href=&quot;#alternative-methods&quot; id=&quot;alternative-methods&quot; name=&quot;alternative-methods&quot;&gt;Alternative methods&lt;/a&gt;

#### &lt;a href=&quot;#manual-installation&quot; id=&quot;manual-installation&quot; name=&quot;manual-installation&quot;&gt;Manual installation&lt;/a&gt;

Please read the **[Getting Started][wiki-start]** article on our Wiki to learn how to install AdGuard Home manually, and how to configure your devices to use it.

#### &lt;a href=&quot;#docker&quot; id=&quot;docker&quot; name=&quot;docker&quot;&gt;Docker&lt;/a&gt;

You can use our official Docker image on [Docker Hub].

#### &lt;a href=&quot;#snap-store&quot; id=&quot;snap-store&quot; name=&quot;snap-store&quot;&gt;Snap Store&lt;/a&gt;

If you&#039;re running **Linux,** there&#039;s a secure and easy way to install AdGuard Home: get it from the [Snap Store].

[Docker Hub]: https://hub.docker.com/r/adguard/adguardhome
[Snap Store]: https://snapcraft.io/adguard-home
[wiki-start]: https://adguard-dns.io/kb/adguard-home/getting-started/

### &lt;a href=&quot;#guides&quot; id=&quot;guides&quot; name=&quot;guides&quot;&gt;Guides&lt;/a&gt;

See our [Wiki][wiki].

[wiki]: https://github.com/AdguardTeam/AdGuardHome/wiki

### &lt;a href=&quot;#api&quot; id=&quot;api&quot; name=&quot;api&quot;&gt;API&lt;/a&gt;

If you want to integrate with AdGuard Home, you can use our [REST API][openapi]. Alternatively, you can use this [python client][pyclient], which is used to build the [AdGuard Home Hass.io Add-on][hassio].

[hassio]:   https://www.home-assistant.io/integrations/adguard/
[openapi]:  https://github.com/AdguardTeam/AdGuardHome/tree/master/openapi
[pyclient]: https://pypi.org/project/adguardhome/

## &lt;a href=&quot;#comparison&quot; id=&quot;comparison&quot; name=&quot;comparison&quot;&gt;Comparing AdGuard Home to other solutions&lt;/a&gt;

### &lt;a href=&quot;#comparison-adguard-dns&quot; id=&quot;comparison-adguard-dns&quot; name=&quot;comparison-adguard-dns&quot;&gt;How is this different from public AdGuard DNS servers?&lt;/a&gt;

Running your own AdGuard Home server allows you to do much more than using a public DNS server. It&#039;s a completely different level. See for yourself:

- Choose what exactly the server blocks and permits.

- Monitor your network activity.

- Add your own custom filtering rules.

- **Most importantly, it&#039;s your own server, and you are the only one who&#039;s in control.**

### &lt;a href=&quot;#comparison-pi-hole&quot; id=&quot;comparison-pi-hole&quot; name=&quot;comparison-pi-hole&quot;&gt;How does AdGuard Home compare to Pi-Hole&lt;/a&gt;

At this point, AdGuard Home has a lot in common with Pi-Hole. Both block ads and trackers using the so-called ‚ÄúDNS sinkholing‚Äù method and both allow customizing what&#039;s blocked.

&gt; [!NOTE]
&gt; We&#039;re not going to stop here. DNS sinkholing is not a bad starting point, but this is just the beginning.

AdGuard Home provides a lot of features out-of-the-box with no need to install and configure additional software. We want it to be simple to the point when even casual users can set it up with minimal effort.

&gt; [!NOTE]
&gt; Some of the listed features can be added to Pi-Hole by installing additional software or by manually using SSH terminal and reconfiguring one of the utilities Pi-Hole consists of. However, in our opinion, this cannot be legitimately counted as a Pi-Hole&#039;s feature.

| Feature                                                                 | AdGuard&amp;nbsp;Home | Pi-Hole                                                   |
|-------------------------------------------------------------------------|-------------------|-----------------------------------------------------------|
| Blocking ads and trackers                                               | ‚úÖ                | ‚úÖ                                                        |
| Customizing blocklists                                                  | ‚úÖ                | ‚úÖ                                                        |
| Built-in DHCP server                                                    | ‚úÖ                | ‚úÖ                                                        |
| HTTPS for the Admin interface                                           | ‚úÖ                | Kind of, but you&#039;ll need to manually configure lighttpd   |
| Encrypted DNS upstream servers (DNS-over-HTTPS, DNS-over-TLS, DNSCrypt) | ‚úÖ                | ‚ùå (requires additional software)                         |
| Cross-platform                                                          | ‚úÖ                | ‚ùå (not natively, only via Docker)                        |
| Running as a DNS-over-HTTPS or DNS-over-TLS server                      | ‚úÖ                | ‚ùå (requires additional software)                         |
| Blocking phishing and malware domains                                   | ‚úÖ                | ‚ùå (requires non-default blocklists)                      |
| Parental control (blocking adult domains)                               | ‚úÖ                | ‚ùå (requires non-default blocklists)                      |
| Force Safe search on search engines                                     | ‚úÖ                | ‚ùå                                                        |
| Per-client (device) configuration                                       | ‚úÖ                | ‚úÖ                                                        |
| Access settings (choose who can use AGH DNS)                            | ‚úÖ                | ‚ùå                                                        |
| Running [without root privileges][wiki-noroot]                          | ‚úÖ                | ‚ùå                                                        |

[wiki-noroot]: https://adguard-dns.io/kb/adguard-home/getting-started/#running-without-superuser

### &lt;a href=&quot;#comparison-adblock&quot; id=&quot;comparison-adblock&quot; name=&quot;comparison-adblock&quot;&gt;How does AdGuard Home compare to traditional ad blockers&lt;/a&gt;

It depends.

DNS sinkholing is capable of blocking a big percentage of ads, but it lacks the flexibility and the power of traditional ad blockers. You can get a good impression about the difference between these methods by reading [this article][blog-adaway], which compares AdGuard for Android (a traditional ad blocker) to hosts-level ad blockers (which are almost identical to DNS-based blockers in their capabilities). This level of protection is enough for some users.

Additionally, using a DNS-based blocker can help to block ads, tracking and analytics requests on other types of devices, such as SmartTVs, smart speakers or other kinds of IoT devices (on which you can&#039;t install traditional ad blockers).

### &lt;a href=&quot;#comparison-limitations&quot; id=&quot;comparison-limitations&quot; name=&quot;comparison-limitations&quot;&gt;Known limitations&lt;/a&gt;

Here are some examples of what cannot be blocked by a DNS-level blocker:

- YouTube, Twitch ads;

- Facebook, Twitter, Instagram sponsored posts.

Essentially, any advertising that shares a domain with content cannot be blocked by a DNS-level blocker.

Is there a chance to handle this in the future?  DNS will never be enough to do this. Our only option is to use a content blocking proxy like what we do in the standalone AdGuard applications. We&#039;re [going to bring][issue-1228] this feature support to AdGuard Home in the future. Unfortunately, even in this case, there still will be cases when this won&#039;t be enough or would require quite a complicated configuration.

[blog-adaway]: https://adguard.com/blog/adguard-vs-adaway-dns66.html
[issue-1228]:  https://github.com/AdguardTeam/AdGuardHome/issues/1228

## &lt;a href=&quot;#how-to-build&quot; id=&quot;how-to-build&quot; name=&quot;how-to-build&quot;&gt;How to build from source&lt;/a&gt;

### &lt;a href=&quot;#prerequisites&quot; id=&quot;prerequisites&quot; name=&quot;prerequisites&quot;&gt;Prerequisites&lt;/a&gt;

Run `make init` to prepare the development environment.

You will need this to build AdGuard Home:

- [Go](https://golang.org/dl/) v1.25 or later;
- [Node.js](https://nodejs.org/en/download/) v24.10.0 or later;
- [npm](https://www.npmjs.com/) v10.8 or later;

### &lt;a href=&quot;#building&quot; id=&quot;building&quot; name=&quot;building&quot;&gt;Building&lt;/a&gt;

Open your terminal and execute these commands:

```sh
git clone https://github.com/AdguardTeam/AdGuardHome
cd AdGuardHome
make
```

&gt; [!WARNING]
&gt; The non-standard `-j` flag is currently not supported, so building with `make -j 4` or setting your `MAKEFLAGS` to include, for example, `-j 4` is likely to break the build. If you do have your `MAKEFLAGS` set to that, and you don&#039;t want to change it, you can override it by running `make -j 1`.

Check the [`Makefile`][src-makefile] to learn about other commands.

#### &lt;a href=&quot;#building-cross&quot; id=&quot;building-cross&quot; name=&quot;building-cross&quot;&gt;Building for a different platform&lt;/a&gt;

You can build AdGuard Home for any OS/ARCH that Go supports. In order to do this, specify `GOOS` and `GOARCH` environment variables as macros when running `make`.

For example:

```sh
env GOOS=&#039;linux&#039; GOARCH=&#039;arm64&#039; make
```

or:

```sh
make GOOS=&#039;linux&#039; GOARCH=&#039;arm64&#039;
```

#### &lt;a href=&quot;#preparing-releases&quot; id=&quot;preparing-releases&quot; name=&quot;preparing-releases&quot;&gt;Preparing releases&lt;/a&gt;

You&#039;ll need [`snapcraft`] to prepare a release build. Once installed, run the following command:

```sh
make build-release CHANNEL=&#039;...&#039; VERSION=&#039;...&#039;
```

See the [`build-release` target documentation][targ-release].

#### &lt;a href=&quot;#docker-image&quot; id=&quot;docker-image&quot; name=&quot;docker-image&quot;&gt;Docker image&lt;/a&gt;

Run `make build-docker` to build the Docker image locally (the one that we publish to DockerHub). Please note, that we&#039;re using [Docker Buildx][buildx] to build our official image.

You may need to prepare before using these builds:

- (Linux-only) Install Qemu:

  ```sh
  docker run --rm --privileged multiarch/qemu-user-static --reset -p yes --credential yes
  ```

- Prepare the builder:

  ```sh
  docker buildx create --name buildx-builder --driver docker-container --use
  ```

See the [`build-docker` target documentation][targ-docker].

#### &lt;a href=&quot;#debugging-the-frontend&quot; id=&quot;debugging-the-frontend&quot; name=&quot;debugging-the-frontend&quot;&gt;Debugging the frontend&lt;/a&gt;

When you need to debug the frontend without recompiling the production version every time, for example to check how your labels would look on a form, you can run the frontend build a development environment.

1. In a separate terminal, run:

   ```sh
   ( cd ./client/ &amp;&amp; env NODE_ENV=&#039;development&#039; npm run watch )
   ```

2. Run your `AdGuardHome` binary with the `--local-frontend` flag, which instructs AdGuard Home to ignore the built-in frontend files and use those from the `./build/` directory.

3. Now any changes you make in the `./client/` directory should be recompiled and become available on the web UI. Make sure that you disable the browser cache to make sure that you actually get the recompiled version.

[`snapcraft`]:  https://snapcraft.io/
[buildx]:       https://docs.docker.com/buildx/working-with-buildx/
[src-makefile]: https://github.com/AdguardTeam/AdGuardHome/blob/master/Makefile
[targ-docker]:  https://github.com/AdguardTeam/AdGuardHome/tree/master/scripts#build-dockersh-build-a-multi-architecture-docker-image
[targ-release]: https://github.com/AdguardTeam/AdGuardHome/tree/master/scripts#build-releasesh-build-a-release-for-all-platforms

#### &lt;a href=&quot;#e2e-frontend-tests&quot; id=&quot;e2e-frontend-tests&quot; name=&quot;e2e-frontend-tests&quot;&gt;End-to-End (E2E) Frontend Tests&lt;/a&gt;

AdGuard Home uses [Playwright](https://playwright.dev) for E2E testing. Tests are located in `tests/e2e`.

**Running Tests:**
- `npm run test:e2e` ‚Äì run all tests (headless).
- `npm run test:e2e:interactive` ‚Äì run tests interactively.
- `npm run test:e2e:debug` ‚Äì run tests in debug mode.
- `npm run test:e2e:codegen` ‚Äì generate new test code.

**Setup:**
1. Run `npm install` to install dependencies.
2. Run `npx playwright install` to set up required browsers.

&gt; **Warning:** Playwright will download and install its own browser binaries for testing, which may differ from the browsers installed on your system.

## &lt;a href=&quot;#contributing&quot; id=&quot;contributing&quot; name=&quot;contributing&quot;&gt;Contributing&lt;/a&gt;

You are welcome to fork this repository, make your changes and [submit a pull request][pr]. Please make sure you follow our [code guidelines][guide] though.

Please note that we don&#039;t expect people to contribute to both UI and backend parts of the program simultaneously. Ideally, the backend part is implemented first, i.e. configuration, API, and the functionality itself. The UI part can be implemented later in a different pull request by a different person.

[guide]: https://github.com/AdguardTeam/CodeGuidelines/
[pr]:    https://github.com/AdguardTeam/AdGuardHome/pulls

### &lt;a href=&quot;#test-unstable-versions&quot; id=&quot;test-unstable-versions&quot; name=&quot;test-unstable-versions&quot;&gt;Test unstable versions&lt;/a&gt;

There are two update channels that you can use:

- `beta`: beta versions of AdGuard Home. More or less stable versions, usually released every two weeks or more often.

- `edge`: the newest version of AdGuard Home from the development branch. New updates are pushed to this channel daily.

There are three options how you can install an unstable version:

1. [Snap Store]: look for the `beta` and `edge` channels.

2. [Docker Hub]: look for the `beta` and `edge` tags.

3. Standalone builds. Use the automated installation script or look for the available builds [on the Wiki][wiki-platf].

   Script to install a beta version:

   ```sh
   curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -c beta
   ```

   Script to install an edge version:

   ```sh
   curl -s -S -L https://raw.githubusercontent.com/AdguardTeam/AdGuardHome/master/scripts/install.sh | sh -s -- -c edge
   ```

[wiki-platf]: https://github.com/AdguardTeam/AdGuardHome/wiki/Platforms

### &lt;a href=&quot;#reporting-issues&quot; id=&quot;reporting-issues&quot; name=&quot;reporting-issues&quot;&gt;Report issues&lt;/a&gt;

If you run into any problem or have a suggestion, head to [this page][iss] and click on the ‚ÄúNew issue‚Äù button. Please follow the instructions in the issue form carefully and don&#039;t forget to start by searching for duplicates.

[iss]: https://github.com/AdguardTeam/AdGuardHome/issues

### &lt;a href=&quot;#translate&quot; id=&quot;translate&quot; name=&quot;translate&quot;&gt;Help with translations&lt;/a&gt;

If you want to help with AdGuard Home translations, please learn more about translating AdGuard products [in our Knowledge Base][kb-trans]. You can contribute to the [AdGuardHome project on CrowdIn][crowdin].

[crowdin]:  https://crowdin.com/project/adguard-applications/en#/adguard-home
[kb-trans]: https://kb.adguard.com/en/general/adguard-translations

### &lt;a href=&quot;#help-other&quot; id=&quot;help-other&quot; name=&quot;help-other&quot;&gt;Other&lt;/a&gt;

Another way you can contribute is by [looking for issues][iss-help] marked as `help wanted`, asking if the issue is up for grabs, and sending a PR fixing the bug or implementing the feature.

[iss-help]: https://github.com/AdguardTeam/AdGuardHome/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22

## &lt;a href=&quot;#uses&quot; id=&quot;uses&quot; name=&quot;uses&quot;&gt;Projects that use AdGuard Home&lt;/a&gt;

Please note that these projects are not affiliated with AdGuard, but are made by third-party developers and fans.

- [AdGuard Home Remote](https://apps.apple.com/app/apple-store/id1543143740): iOS app by [Joost](https://rocketscience-it.nl/).

- [Python library](https://github.com/frenck/python-adguardhome) by [@frenck](https://github.com/frenck).

- [Home Assistant add-on](https://github.com/hassio-addons/addon-adguard-home) by [@frenck](https://github.com/frenck).

- [OpenWrt LUCI app](https://github.com/kongfl888/luci-app-adguardhome) by [@kongfl888](https://github.com/kongfl888) (originally by [@rufengsuixing](https://github.com/rufengsuixing)).

- [AdGuardHome sync](https://github.com/bakito/adguardhome-sync) by [@bakito](https://github.com/bakito).

- [Terminal-based, real-time traffic monitoring and statistics for your AdGuard Home instance](https://github.com/Lissy93/AdGuardian-Term) by [@Lissy93](https://github.com/Lissy93)

- [AdGuard Home on GLInet routers](https://forum.gl-inet.com/t/adguardhome-on-gl-routers/10664) by [Gl-Inet](https://gl-inet.com/).

- [Cloudr

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[Jguer/yay]]></title>
            <link>https://github.com/Jguer/yay</link>
            <guid>https://github.com/Jguer/yay</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[Yet another Yogurt - An AUR Helper written in Go]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Jguer/yay">Jguer/yay</a></h1>
            <p>Yet another Yogurt - An AUR Helper written in Go</p>
            <p>Language: Go</p>
            <p>Stars: 12,772</p>
            <p>Forks: 391</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![yay](https://img.shields.io/aur/version/yay?color=1793d1&amp;label=yay&amp;logo=arch-linux&amp;style=for-the-badge)](https://aur.archlinux.org/packages/yay/)
[![yay-bin](https://img.shields.io/aur/version/yay-bin?color=1793d1&amp;label=yay-bin&amp;logo=arch-linux&amp;style=for-the-badge)](https://aur.archlinux.org/packages/yay-bin/)
[![yay-git](https://img.shields.io/aur/version/yay-git?color=1793d1&amp;label=yay-git&amp;logo=arch-linux&amp;style=for-the-badge)](https://aur.archlinux.org/packages/yay-git/)
![AUR votes](https://img.shields.io/aur/votes/yay?color=333333&amp;style=for-the-badge)
[![GitHub license](https://img.shields.io/github/license/jguer/yay?color=333333&amp;style=for-the-badge)](https://github.com/Jguer/yay/blob/master/LICENSE)

# Yay

Yet Another Yogurt - An AUR Helper Written in Go

### Help translate yay: [Transifex](https://app.transifex.com/yay-1/yay/)

## Features

- Advanced dependency solving
- PKGBUILD downloading from ABS or AUR
- Completions for AUR packages
- Query user up-front for all input (prior to starting builds)
- Narrow search (`yay linux header` will first search `linux` and then narrow on `header`)
- Find matching package providers during search and allow selection
- Remove make dependencies at the end of the build process
- Build local PKGBUILDs with AUR dependencies
- Un/Vote for packages

[![asciicast](https://asciinema.org/a/399431.svg)](https://asciinema.org/a/399431)

[![asciicast](https://asciinema.org/a/399433.svg)](https://asciinema.org/a/399433)

## Installation

If you are migrating from another AUR helper, you can simply install Yay with that helper.

&gt; [!WARNING]  
&gt; We are using `sudo` in these examples, you can switch that out for a different privilege escalation tool.

### Source

The initial installation of Yay can be done by cloning the PKGBUILD and
building with makepkg:

We make sure we have the `base-devel` package group installed.

```sh
sudo pacman -S --needed git base-devel
git clone https://aur.archlinux.org/yay.git
cd yay
makepkg -si
```

If you want to do all of this at once, we can chain the commands like so:

```sh
sudo pacman -S --needed git base-devel &amp;&amp; git clone https://aur.archlinux.org/yay.git &amp;&amp; cd yay &amp;&amp; makepkg -si
```

### Binary

If you do not want to compile yay yourself you can use the builds generated by
GitHub Actions.

```sh
sudo pacman -S --needed git base-devel
git clone https://aur.archlinux.org/yay-bin.git
cd yay-bin
makepkg -si
```

If you want to do all of this at once, we can chain the commands like so:

```sh
sudo pacman -S --needed git base-devel &amp;&amp; git clone https://aur.archlinux.org/yay-bin.git &amp;&amp; cd yay-bin &amp;&amp; makepkg -si
```

### Other distributions

If you&#039;re using Manjaro or [another distribution that packages `yay`](https://repology.org/project/yay/versions)
you can simply install yay using pacman (as root):

```sh
pacman -S --needed git base-devel yay
```
&gt; [!WARNING]  
&gt; distributions sometimes lag updating yay on their repositories.

## First Use

#### Development packages upgrade

- Use `yay -Y --gendb` to generate a development package database for `*-git`
  packages that were installed without yay.
  This command should only be run once.

- `yay -Syu --devel` will then check for development package updates

- Use `yay -Y --devel --save` to make development package updates permanently
  enabled (`yay` and `yay -Syu` will then always check dev packages)

## Examples of Custom Operations

| Command                           | Description                                                                                                |
| --------------------------------- | ---------------------------------------------------------------------------------------------------------- |
| `yay`                             | Alias to `yay -Syu`.                                                                                       |
| `yay &lt;Search Term&gt;`               | Present package-installation selection menu.                                                               |
| `yay -Bi &lt;dir&gt;`                   | Install dependencies and build a local PKGBUILD.                                                           |
| `yay -G &lt;AUR Package&gt;`            | Download PKGBUILD from ABS or AUR. (yay v12.0+)                                                            |
| `yay -Gp &lt;AUR Package&gt;`           | Print to stdout PKGBUILD from ABS or AUR.                                                                  |
| `yay -Ps`                         | Print system statistics.                                                                                   |
| `yay -Syu --devel`                | Perform system upgrade, but also check for development package updates.                                    |
| `yay -Syu --timeupdate`           | Perform system upgrade and use PKGBUILD modification time (not version number) to determine update.        |
| `yay -Wu &lt;AUR Package&gt;`           | Unvote for package (Requires setting `AUR_USERNAME` and `AUR_PASSWORD` environment variables) (yay v11.3+) |
| `yay -Wv &lt;AUR Package&gt;`           | Vote for package (Requires setting `AUR_USERNAME` and `AUR_PASSWORD` environment variables). (yay v11.3+)  |
| `yay -Y --combinedupgrade --save` | Make combined upgrade the default mode.                                                                    |
| `yay -Y --gendb`                  | Generate development package database used for devel update.                                               |
| `yay -Yc`                         | Clean unneeded dependencies.                                                                               |

## Frequently Asked Questions

- **Yay does not display colored output. How do I fix it?**

  Make sure you have the `Color` option in your `/etc/pacman.conf`
  (see issue [#123](https://github.com/Jguer/yay/issues/123)).

- **Sometimes diffs are printed to the terminal, and other times they are paged via less. How do I fix this?**

  Yay uses `git diff` to display diffs, which by default tells less not to
  page if the output can fit into one terminal length. This behavior can be
  overridden by exporting your own flags (`export LESS=SRX`).

- **Yay is not asking me to edit PKGBUILDS, and I don&#039;t like the diff menu! What can I do?**

  `yay --editmenu --diffmenu=false --save`

- **How can I tell Yay to act only on AUR packages, or only on repo packages?**

  `yay -{OPERATION} --aur`
  `yay -{OPERATION} --repo`

- **A `Flagged Out Of Date AUR Packages` message is displayed. Why doesn&#039;t Yay update them?**

  This message does not mean that updated AUR packages are available. It means
  the packages have been flagged out of date on the AUR, but
  their maintainers have not yet updated the `PKGBUILD`s
  (see [outdated AUR packages](https://wiki.archlinux.org/index.php/Arch_User_Repository#Foo_in_the_AUR_is_outdated.3B_what_should_I_do.3F)).

- **Yay doesn&#039;t install dependencies added to a PKGBUILD during installation.**

  Yay resolves all dependencies ahead of time. You are free to edit the
  PKGBUILD in any way, but any problems you cause are your own and should not be
  reported unless they can be reproduced with the original PKGBUILD.

- **I know my `-git` package has updates but yay doesn&#039;t offer to update it**

  Yay uses a hash cache for development packages. Normally it is updated at the end of the package install with the message `Found git repo`.
  If you transition between aur helpers and did not install the devel package using yay at some point, it is possible it never got added to the cache. `yay -Y --gendb` will fix the current version of every devel package and start checking from there.

- **I want to help out!**

  Check [CONTRIBUTING.md](./CONTRIBUTING.md) for more information.

## Support

All support related to Yay should be requested via GitHub issues. Since Yay is not
officially supported by Arch Linux, support should not be sought out on the
forums, AUR comments or other official channels.

A broken AUR package should be reported as a comment on the package&#039;s AUR page.
A package may only be considered broken if it fails to build with makepkg.

Reports should be made using makepkg and include the full output as well as any
other relevant information. Never make reports using Yay or any other external
tools.

## Images

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Jguer/jguer.github.io/refs/heads/master/yay/yay.png&quot; width=&quot;42%&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Jguer/jguer.github.io/refs/heads/master/yay/yay-s.png&quot; width=&quot;42%&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Jguer/jguer.github.io/refs/heads/master/yay/yay-y.png&quot; width=&quot;42%&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Jguer/jguer.github.io/refs/heads/master/yay/yay-ps.png&quot; width=&quot;42%&quot;&gt;
&lt;/p&gt;

### Other AUR helpers/tools

- [paru](https://github.com/morganamilo/paru)
- [aurutils](https://github.com/AladW/aurutils)
- [pikaur](https://github.com/actionless/pikaur)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[SagerNet/sing-box]]></title>
            <link>https://github.com/SagerNet/sing-box</link>
            <guid>https://github.com/SagerNet/sing-box</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[The universal proxy platform]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/SagerNet/sing-box">SagerNet/sing-box</a></h1>
            <p>The universal proxy platform</p>
            <p>Language: Go</p>
            <p>Stars: 28,722</p>
            <p>Forks: 3,358</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre>&gt; Sponsored by [Warp](https://go.warp.dev/sing-box), built for coding with multiple AI agents

&lt;a href=&quot;https://go.warp.dev/sing-box&quot;&gt;
&lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://github.com/warpdotdev/brand-assets/raw/refs/heads/main/Github/Sponsor/Warp-Github-LG-02.png&quot;&gt;
&lt;/a&gt;

---

# sing-box

The universal proxy platform.

[![Packaging status](https://repology.org/badge/vertical-allrepos/sing-box.svg)](https://repology.org/project/sing-box/versions)

## Documentation

https://sing-box.sagernet.org

## License

```
Copyright (C) 2022 by nekohasekai &lt;contact-sagernet@sekai.icu&gt;

This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.

This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.

You should have received a copy of the GNU General Public License
along with this program. If not, see &lt;http://www.gnu.org/licenses/&gt;.

In addition, no derivative work may use the name or imply association
with this application without prior consent.
```</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[github/github-mcp-server]]></title>
            <link>https://github.com/github/github-mcp-server</link>
            <guid>https://github.com/github/github-mcp-server</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:48 GMT</pubDate>
            <description><![CDATA[GitHub's official MCP Server]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/github-mcp-server">github/github-mcp-server</a></h1>
            <p>GitHub's official MCP Server</p>
            <p>Language: Go</p>
            <p>Stars: 25,017</p>
            <p>Forks: 3,160</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>[![Go Report Card](https://goreportcard.com/badge/github.com/github/github-mcp-server)](https://goreportcard.com/report/github.com/github/github-mcp-server)

# GitHub MCP Server

The GitHub MCP Server connects AI tools directly to GitHub&#039;s platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code files, manage issues and PRs, analyze code, and automate workflows. All through natural language interactions.

### Use Cases

- Repository Management: Browse and query code, search files, analyze commits, and understand project structure across any repository you have access to.
- Issue &amp; PR Automation: Create, update, and manage issues and pull requests. Let AI help triage bugs, review code changes, and maintain project boards.
- CI/CD &amp; Workflow Intelligence: Monitor GitHub Actions workflow runs, analyze build failures, manage releases, and get insights into your development pipeline.
- Code Analysis: Examine security findings, review Dependabot alerts, understand code patterns, and get comprehensive insights into your codebase.
- Team Collaboration: Access discussions, manage notifications, analyze team activity, and streamline processes for your team.

Built for developers who want to connect their AI tools to GitHub context and capabilities, from simple natural language queries to complex multi-step agent workflows.

---

## Remote GitHub MCP Server

[![Install in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D) [![Install in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;config=%7B%22type%22%3A%20%22http%22%2C%22url%22%3A%20%22https%3A%2F%2Fapi.githubcopilot.com%2Fmcp%2F%22%7D&amp;quality=insiders)

The remote GitHub MCP Server is hosted by GitHub and provides the easiest method for getting up and running. If your MCP host does not support remote MCP servers, don&#039;t worry! You can use the [local version of the GitHub MCP Server](https://github.com/github/github-mcp-server?tab=readme-ov-file#local-github-mcp-server) instead.

### Prerequisites

1. A compatible MCP host with remote server support (VS Code 1.101+, Claude Desktop, Cursor, Windsurf, etc.)
2. Any applicable [policies enabled](https://github.com/github/github-mcp-server/blob/main/docs/policies-and-governance.md)

### Install in VS Code

For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start. Make sure you&#039;re using [VS Code 1.101](https://code.visualstudio.com/updates/v1_101) or [later](https://code.visualstudio.com/updates) for remote MCP and OAuth support.

Alternatively, to manually configure VS Code, choose the appropriate JSON block from the examples below and add it to your host configuration:

&lt;table&gt;
&lt;tr&gt;&lt;th&gt;Using OAuth&lt;/th&gt;&lt;th&gt;Using a GitHub PAT&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;th align=left colspan=2&gt;VS Code (version 1.101 or greater)&lt;/th&gt;&lt;/tr&gt;
&lt;tr valign=top&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;
    }
  }
}
```

&lt;/td&gt;
&lt;td&gt;

```json
{
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://api.githubcopilot.com/mcp/&quot;,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer ${input:github_mcp_pat}&quot;
      }
    }
  },
  &quot;inputs&quot;: [
    {
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;id&quot;: &quot;github_mcp_pat&quot;,
      &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
      &quot;password&quot;: true
    }
  ]
}
```

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

### Install in other MCP hosts
- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot
- **[Claude Applications](/docs/installation-guides/install-claude.md)** - Installation guide for Claude Web, Claude Desktop and Claude Code CLI
- **[Cursor](/docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE
- **[Windsurf](/docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE

&gt; **Note:** Each MCP host application needs to configure a GitHub App or OAuth App to support remote access via OAuth. Any host application that supports remote MCP servers should support the remote GitHub server with PAT authentication. Configuration details and support levels vary by host. Make sure to refer to the host application&#039;s documentation for more info.

### Configuration

#### Toolset configuration

See [Remote Server Documentation](docs/remote-server.md) for full details on remote server configuration, toolsets, headers, and advanced usage. This file provides comprehensive instructions and examples for connecting, customizing, and installing the remote GitHub MCP Server in VS Code and other MCP hosts.

When no toolsets are specified, [default toolsets](#default-toolset) are used.

#### GitHub Enterprise

##### GitHub Enterprise Cloud with data residency (ghe.com)

GitHub Enterprise Cloud can also make use of the remote server.

Example for `https://octocorp.ghe.com` with GitHub PAT token:
```
{
    ...
    &quot;proxima-github&quot;: {
      &quot;type&quot;: &quot;http&quot;,
      &quot;url&quot;: &quot;https://copilot-api.octocorp.ghe.com/mcp&quot;,
      &quot;headers&quot;: {
        &quot;Authorization&quot;: &quot;Bearer ${input:github_mcp_pat}&quot;
      }
    },
    ...
}
```

&gt; **Note:** When using OAuth with GitHub Enterprise with VS Code and GitHub Copilot, you also need to configure your VS Code settings to point to your GitHub Enterprise instance - see [Authenticate from VS Code](https://docs.github.com/en/enterprise-cloud@latest/copilot/how-tos/configure-personal-settings/authenticate-to-ghecom)

##### GitHub Enterprise Server

GitHub Enterprise Server does not support remote server hosting. Please refer to [GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)](#github-enterprise-server-and-enterprise-cloud-with-data-residency-ghecom) from the local server configuration.

---

## Local GitHub MCP Server

[![Install with Docker in VS Code](https://img.shields.io/badge/VS_Code-Install_Server-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D) [![Install with Docker in VS Code Insiders](https://img.shields.io/badge/VS_Code_Insiders-Install_Server-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=github&amp;inputs=%5B%7B%22id%22%3A%22github_token%22%2C%22type%22%3A%22promptString%22%2C%22description%22%3A%22GitHub%20Personal%20Access%20Token%22%2C%22password%22%3Atrue%7D%5D&amp;config=%7B%22command%22%3A%22docker%22%2C%22args%22%3A%5B%22run%22%2C%22-i%22%2C%22--rm%22%2C%22-e%22%2C%22GITHUB_PERSONAL_ACCESS_TOKEN%22%2C%22ghcr.io%2Fgithub%2Fgithub-mcp-server%22%5D%2C%22env%22%3A%7B%22GITHUB_PERSONAL_ACCESS_TOKEN%22%3A%22%24%7Binput%3Agithub_token%7D%22%7D%7D&amp;quality=insiders)

### Prerequisites

1. To run the server in a container, you will need to have [Docker](https://www.docker.com/) installed.
2. Once Docker is installed, you will also need to ensure Docker is running. The image is public; if you get errors on pull, you may have an expired token and need to `docker logout ghcr.io`.
3. Lastly you will need to [Create a GitHub Personal Access Token](https://github.com/settings/personal-access-tokens/new).
The MCP server can use many of the GitHub APIs, so enable the permissions that you feel comfortable granting your AI tools (to learn more about access tokens, please check out the [documentation](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens)).

&lt;details&gt;&lt;summary&gt;&lt;b&gt;Handling PATs Securely&lt;/b&gt;&lt;/summary&gt;

### Environment Variables (Recommended)
To keep your GitHub PAT secure and reusable across different MCP hosts:

1. **Store your PAT in environment variables**
   ```bash
   export GITHUB_PAT=your_token_here
   ```
   Or create a `.env` file:
   ```env
   GITHUB_PAT=your_token_here
   ```

2. **Protect your `.env` file**
   ```bash
   # Add to .gitignore to prevent accidental commits
   echo &quot;.env&quot; &gt;&gt; .gitignore
   ```

3. **Reference the token in configurations**
   ```bash
   # CLI usage
   claude mcp update github -e GITHUB_PERSONAL_ACCESS_TOKEN=$GITHUB_PAT

   # In config files (where supported)
   &quot;env&quot;: {
     &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;$GITHUB_PAT&quot;
   }
   ```

&gt; **Note**: Environment variable support varies by host app and IDE. Some applications (like Windsurf) require hardcoded tokens in config files.

### Token Security Best Practices

- **Minimum scopes**: Only grant necessary permissions
  - `repo` - Repository operations
  - `read:packages` - Docker image access
  - `read:org` - Organization team access
- **Separate tokens**: Use different PATs for different projects/environments
- **Regular rotation**: Update tokens periodically
- **Never commit**: Keep tokens out of version control
- **File permissions**: Restrict access to config files containing tokens
  ```bash
  chmod 600 ~/.your-app/config.json
  ```

&lt;/details&gt;

### GitHub Enterprise Server and Enterprise Cloud with data residency (ghe.com)

The flag `--gh-host` and the environment variable `GITHUB_HOST` can be used to set
the hostname for GitHub Enterprise Server or GitHub Enterprise Cloud with data residency.

- For GitHub Enterprise Server, prefix the hostname with the `https://` URI scheme, as it otherwise defaults to `http://`, which GitHub Enterprise Server does not support.
- For GitHub Enterprise Cloud with data residency, use `https://YOURSUBDOMAIN.ghe.com` as the hostname.
``` json
&quot;github&quot;: {
    &quot;command&quot;: &quot;docker&quot;,
    &quot;args&quot;: [
    &quot;run&quot;,
    &quot;-i&quot;,
    &quot;--rm&quot;,
    &quot;-e&quot;,
    &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
    &quot;-e&quot;,
    &quot;GITHUB_HOST&quot;,
    &quot;ghcr.io/github/github-mcp-server&quot;
    ],
    &quot;env&quot;: {
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;,
        &quot;GITHUB_HOST&quot;: &quot;https://&lt;your GHES or ghe.com domain name&gt;&quot;
    }
}
```

## Installation

### Install in GitHub Copilot on VS Code

For quick installation, use one of the one-click install buttons above. Once you complete that flow, toggle Agent mode (located by the Copilot Chat text input) and the server will start.

More about using MCP server tools in VS Code&#039;s [agent mode documentation](https://code.visualstudio.com/docs/copilot/chat/mcp-servers).

Install in GitHub Copilot on other IDEs (JetBrains, Visual Studio, Eclipse, etc.)

Add the following JSON block to your IDE&#039;s MCP settings.

```json
{
  &quot;mcp&quot;: {
    &quot;inputs&quot;: [
      {
        &quot;type&quot;: &quot;promptString&quot;,
        &quot;id&quot;: &quot;github_token&quot;,
        &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
        &quot;password&quot;: true
      }
    ],
    &quot;servers&quot;: {
      &quot;github&quot;: {
        &quot;command&quot;: &quot;docker&quot;,
        &quot;args&quot;: [
          &quot;run&quot;,
          &quot;-i&quot;,
          &quot;--rm&quot;,
          &quot;-e&quot;,
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
          &quot;ghcr.io/github/github-mcp-server&quot;
        ],
        &quot;env&quot;: {
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;
        }
      }
    }
  }
}
```

Optionally, you can add a similar example (i.e. without the mcp key) to a file called `.vscode/mcp.json` in your workspace. This will allow you to share the configuration with other host applications that accept the same format.

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Example JSON block without the MCP key included&lt;/b&gt;&lt;/summary&gt;
&lt;br&gt;

```json
{
  &quot;inputs&quot;: [
    {
      &quot;type&quot;: &quot;promptString&quot;,
      &quot;id&quot;: &quot;github_token&quot;,
      &quot;description&quot;: &quot;GitHub Personal Access Token&quot;,
      &quot;password&quot;: true
    }
  ],
  &quot;servers&quot;: {
    &quot;github&quot;: {
      &quot;command&quot;: &quot;docker&quot;,
      &quot;args&quot;: [
        &quot;run&quot;,
        &quot;-i&quot;,
        &quot;--rm&quot;,
        &quot;-e&quot;,
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;,
        &quot;ghcr.io/github/github-mcp-server&quot;
      ],
      &quot;env&quot;: {
        &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;${input:github_token}&quot;
      }
    }
  }
}
```

&lt;/details&gt;

### Install in Other MCP Hosts

For other MCP host applications, please refer to our installation guides:

- **[GitHub Copilot in other IDEs](/docs/installation-guides/install-other-copilot-ides.md)** - Installation for JetBrains, Visual Studio, Eclipse, and Xcode with GitHub Copilot
- **[Claude Code &amp; Claude Desktop](docs/installation-guides/install-claude.md)** - Installation guide for Claude Code and Claude Desktop
- **[Cursor](docs/installation-guides/install-cursor.md)** - Installation guide for Cursor IDE
- **[Google Gemini CLI](docs/installation-guides/install-gemini-cli.md)** - Installation guide for Google Gemini CLI
- **[Windsurf](docs/installation-guides/install-windsurf.md)** - Installation guide for Windsurf IDE

For a complete overview of all installation options, see our **[Installation Guides Index](docs/installation-guides)**.

&gt; **Note:** Any host application that supports local MCP servers should be able to access the local GitHub MCP server. However, the specific configuration process, syntax and stability of the integration will vary by host application. While many may follow a similar format to the examples above, this is not guaranteed. Please refer to your host application&#039;s documentation for the correct MCP configuration syntax and setup process.

### Build from source

If you don&#039;t have Docker, you can use `go build` to build the binary in the
`cmd/github-mcp-server` directory, and use the `github-mcp-server stdio` command with the `GITHUB_PERSONAL_ACCESS_TOKEN` environment variable set to your token. To specify the output location of the build, use the `-o` flag. You should configure your server to use the built executable as its `command`. For example:

```JSON
{
  &quot;mcp&quot;: {
    &quot;servers&quot;: {
      &quot;github&quot;: {
        &quot;command&quot;: &quot;/path/to/github-mcp-server&quot;,
        &quot;args&quot;: [&quot;stdio&quot;],
        &quot;env&quot;: {
          &quot;GITHUB_PERSONAL_ACCESS_TOKEN&quot;: &quot;&lt;YOUR_TOKEN&gt;&quot;
        }
      }
    }
  }
}
```

## Tool Configuration

The GitHub MCP Server supports enabling or disabling specific groups of functionalities via the `--toolsets` flag. This allows you to control which GitHub API capabilities are available to your AI tools. Enabling only the toolsets that you need can help the LLM with tool choice and reduce the context size.

_Toolsets are not limited to Tools. Relevant MCP Resources and Prompts are also included where applicable._

When no toolsets are specified, [default toolsets](#default-toolset) are used.

&gt; **Looking for examples?** See the [Server Configuration Guide](./docs/server-configuration.md) for common recipes like minimal setups, read-only mode, and combining tools with toolsets.

#### Specifying Toolsets

To specify toolsets you want available to the LLM, you can pass an allow-list in two ways:

1. **Using Command Line Argument**:

   ```bash
   github-mcp-server --toolsets repos,issues,pull_requests,actions,code_security
   ```

2. **Using Environment Variable**:
   ```bash
   GITHUB_TOOLSETS=&quot;repos,issues,pull_requests,actions,code_security&quot; ./github-mcp-server
   ```

The environment variable `GITHUB_TOOLSETS` takes precedence over the command line argument if both are provided.

#### Specifying Individual Tools

You can also configure specific tools using the `--tools` flag. Tools can be used independently or combined with toolsets and dynamic toolsets discovery for fine-grained control.

1. **Using Command Line Argument**:

   ```bash
   github-mcp-server --tools get_file_contents,issue_read,create_pull_request
   ```

2. **Using Environment Variable**:
   ```bash
   GITHUB_TOOLS=&quot;get_file_contents,issue_read,create_pull_request&quot; ./github-mcp-server
   ```

3. **Combining with Toolsets** (additive):
   ```bash
   github-mcp-server --toolsets repos,issues --tools get_gist
   ```
   This registers all tools from `repos` and `issues` toolsets, plus `get_gist`.

4. **Combining with Dynamic Toolsets** (additive):
   ```bash
   github-mcp-server --tools get_file_contents --dynamic-toolsets
   ```
   This registers `get_file_contents` plus the dynamic toolset tools (`enable_toolset`, `list_available_toolsets`, `get_toolset_tools`).

**Important Notes:**
- Tools, toolsets, and dynamic toolsets can all be used together
- Read-only mode takes priority: write tools are skipped if `--read-only` is set, even if explicitly requested via `--tools`
- Tool names must match exactly (e.g., `get_file_contents`, not `getFileContents`). Invalid tool names will cause the server to fail at startup with an error message

### Using Toolsets With Docker

When using Docker, you can pass the toolsets as environment variables:

```bash
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&lt;your-token&gt; \
  -e GITHUB_TOOLSETS=&quot;repos,issues,pull_requests,actions,code_security,experiments&quot; \
  ghcr.io/github/github-mcp-server
```

### Using Tools With Docker

When using Docker, you can pass specific tools as environment variables. You can also combine tools with toolsets:

```bash
# Tools only
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&lt;your-token&gt; \
  -e GITHUB_TOOLS=&quot;get_file_contents,issue_read,create_pull_request&quot; \
  ghcr.io/github/github-mcp-server

# Tools combined with toolsets (additive)
docker run -i --rm \
  -e GITHUB_PERSONAL_ACCESS_TOKEN=&lt;your-token&gt; \
  -e GITHUB_TOOLSETS=&quot;repos,issues&quot; \
  -e GITHUB_TOOLS=&quot;get_gist&quot; \
  ghcr.io/github/github-mcp-server
```

### Special toolsets

#### &quot;all&quot; toolset

The special toolset `all` can be provided to enable all available toolsets regardless of any other configuration:

```bash
./github-mcp-server --toolsets all
```

Or using the environment variable:

```bash
GITHUB_TOOLSETS=&quot;all&quot; ./github-mcp-server
```

#### &quot;default&quot; toolset
The default toolset `default` is the configuration that gets passed to the server if no toolsets are specified.

The default configuration is:
- context
- repos
- issues
- pull_requests
- users

To keep the default configuration and add additional toolsets:

```bash
GITHUB_TOOLSETS=&quot;default,stargazers&quot; ./github-mcp-server
```

### Available Toolsets

The following sets of tools are available:

&lt;!-- START AUTOMATED TOOLSETS --&gt;
| Toolset                 | Description                                                   |
| ----------------------- | ------------------------------------------------------------- |
| `context`               | **Strongly recommended**: Tools that provide context about the current user and GitHub context you are operating in |
| `actions` | GitHub Actions workflows and CI/CD operations |
| `code_security` | Code security related tools, such as GitHub Code Scanning |
| `dependabot` | Dependabot tools |
| `discussions` | GitHub Discussions related tools |
| `experiments` | Experimental features that are not considered stable yet |
| `gists` | GitHub Gist related tools |
| `git` | GitHub Git API related tools for low-level Git operations |
| `issues` | GitHub Issues related tools |
| `labels` | GitHub Labels related tools |
| `notifications` | GitHub Notifications related tools |
| `orgs` | GitHub Organization related tools |
| `projects` | GitHub Projects related tools |
| `pull_requests` | GitHub Pull Request related tools |
| `repos` | GitHub Repository related tools |
| `secret_protection` | Secret protection relat

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[vmware-tanzu/velero]]></title>
            <link>https://github.com/vmware-tanzu/velero</link>
            <guid>https://github.com/vmware-tanzu/velero</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:47 GMT</pubDate>
            <description><![CDATA[Backup and migrate Kubernetes applications and their persistent volumes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vmware-tanzu/velero">vmware-tanzu/velero</a></h1>
            <p>Backup and migrate Kubernetes applications and their persistent volumes</p>
            <p>Language: Go</p>
            <p>Stars: 9,667</p>
            <p>Forks: 1,499</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>![100]

[![Build Status][1]][2] [![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/3811/badge)](https://bestpractices.coreinfrastructure.org/projects/3811)
![GitHub release (latest SemVer)](https://img.shields.io/github/v/release/vmware-tanzu/velero)

## Overview

Velero (formerly Heptio Ark) gives you tools to back up and restore your Kubernetes cluster resources and persistent volumes. You can run Velero with a public cloud platform or on-premises. 

Velero lets you:

* Take backups of your cluster and restore in case of loss.
* Migrate cluster resources to other clusters.
* Replicate your production cluster to development and testing clusters.

Velero consists of:

* A server that runs on your cluster
* A command-line client that runs locally

## Documentation

[The documentation][29] provides a getting started guide and information about building from source, architecture, extending Velero and more.

Please use the version selector at the top of the site to ensure you are using the appropriate documentation for your version of Velero.

## Troubleshooting

If you encounter issues, review the [troubleshooting docs][30], [file an issue][4], or talk to us on the [#velero channel][25] on the Kubernetes Slack server.

## Contributing

If you are ready to jump in and test, add code, or help with documentation, follow the instructions on our [Start contributing][31] documentation for guidance on how to setup Velero for development.

## Changelog

See [the list of releases][6] to find out about feature changes.

### Velero compatibility matrix

The following is a list of the supported Kubernetes versions for each Velero version.

| Velero version | Expected Kubernetes version compatibility | Tested on Kubernetes version        |
|----------------|-------------------------------------------|-------------------------------------|
| 1.17           | 1.18-latest                               | 1.31.7, 1.32.3, 1.33.1, and 1.34.0          |
| 1.16           | 1.18-latest                               | 1.31.4, 1.32.3, and 1.33.0          |
| 1.15           | 1.18-latest                               | 1.28.8, 1.29.8, 1.30.4 and 1.31.1   |
| 1.14           | 1.18-latest                               | 1.27.9, 1.28.9, and 1.29.4          |
| 1.13           | 1.18-latest                               | 1.26.5, 1.27.3, 1.27.8, and 1.28.3  |
| 1.12           | 1.18-latest                               | 1.25.7, 1.26.5, 1.26.7, and 1.27.3  |
| 1.11           | 1.18-latest                               | 1.23.10, 1.24.9, 1.25.5, and 1.26.1 |

Velero supports IPv4, IPv6, and dual stack environments. Support for this was tested against Velero v1.8.

The Velero maintainers are continuously working to expand testing coverage, but are not able to test every combination of Velero and supported Kubernetes versions for each Velero release. The table above is meant to track the current testing coverage and the expected supported Kubernetes versions for each Velero version.

If you are interested in using a different version of Kubernetes with a given Velero version, we&#039;d recommend that you perform testing before installing or upgrading your environment. For full information around capabilities within a release, also see the Velero [release notes](https://github.com/vmware-tanzu/velero/releases) or Kubernetes [release notes](https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG). See the Velero [support page](https://velero.io/docs/latest/support-process/) for information about supported versions of Velero.

For each release, Velero maintainers run the test to ensure the upgrade path from n-2 minor release.  For example, before the release of v1.10.x, the test will verify that the backup created by v1.9.x and v1.8.x can be restored using the build to be tagged as v1.10.x.

[1]: https://github.com/vmware-tanzu/velero/workflows/Main%20CI/badge.svg
[2]: https://github.com/vmware-tanzu/velero/actions?query=workflow%3A&quot;Main+CI&quot;
[4]: https://github.com/vmware-tanzu/velero/issues
[6]: https://github.com/vmware-tanzu/velero/releases
[9]: https://kubernetes.io/docs/setup/
[10]: https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-with-homebrew-on-macos
[11]: https://kubernetes.io/docs/tasks/tools/install-kubectl/#tabset-1
[12]: https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/dns/README.md
[14]: https://github.com/kubernetes/kubernetes
[24]: https://groups.google.com/forum/#!forum/projectvelero
[25]: https://kubernetes.slack.com/messages/velero
[29]: https://velero.io/docs/
[30]: https://velero.io/docs/troubleshooting
[31]: https://velero.io/docs/start-contributing
[100]: https://velero.io/docs/main/img/velero.png
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[moby/buildkit]]></title>
            <link>https://github.com/moby/buildkit</link>
            <guid>https://github.com/moby/buildkit</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:46 GMT</pubDate>
            <description><![CDATA[concurrent, cache-efficient, and Dockerfile-agnostic builder toolkit]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/moby/buildkit">moby/buildkit</a></h1>
            <p>concurrent, cache-efficient, and Dockerfile-agnostic builder toolkit</p>
            <p>Language: Go</p>
            <p>Stars: 9,558</p>
            <p>Forks: 1,339</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![asciicinema example](https://asciinema.org/a/gPEIEo1NzmDTUu2bEPsUboqmU.png)](https://asciinema.org/a/gPEIEo1NzmDTUu2bEPsUboqmU)

# BuildKit &lt;!-- omit in toc --&gt;

[![GitHub Release](https://img.shields.io/github/release/moby/buildkit.svg?style=flat-square)](https://github.com/moby/buildkit/releases/latest)
[![PkgGoDev](https://img.shields.io/badge/go.dev-docs-007d9c?style=flat-square&amp;logo=go&amp;logoColor=white)](https://pkg.go.dev/github.com/moby/buildkit/client/llb)
[![CI BuildKit Status](https://img.shields.io/github/actions/workflow/status/moby/buildkit/buildkit.yml?label=buildkit&amp;logo=github&amp;style=flat-square)](https://github.com/moby/buildkit/actions?query=workflow%3Abuildkit)
[![CI Frontend Status](https://img.shields.io/github/actions/workflow/status/moby/buildkit/frontend.yml?label=frontend&amp;logo=github&amp;style=flat-square)](https://github.com/moby/buildkit/actions?query=workflow%3Afrontend)
[![Go Report Card](https://goreportcard.com/badge/github.com/moby/buildkit?style=flat-square)](https://goreportcard.com/report/github.com/moby/buildkit)
[![Codecov](https://img.shields.io/codecov/c/github/moby/buildkit?logo=codecov&amp;style=flat-square)](https://codecov.io/gh/moby/buildkit)

BuildKit is a toolkit for converting source code to build artifacts in an efficient, expressive and repeatable manner.

Key features:

-   Automatic garbage collection
-   Extendable frontend formats
-   Concurrent dependency resolution
-   Efficient instruction caching
-   Build cache import/export
-   Nested build job invocations
-   Distributable workers
-   Multiple output formats
-   Pluggable architecture
-   Execution without root privileges

Read the proposal from https://github.com/moby/moby/issues/32925

Introductory blog post https://blog.mobyproject.org/introducing-buildkit-17e056cc5317

Join `#buildkit` channel on [Docker Community Slack](https://dockr.ly/comm-slack)

&gt; [!NOTE]
&gt; If you are visiting this repo for the usage of BuildKit-only Dockerfile features
&gt; like `RUN --mount=type=(bind|cache|tmpfs|secret|ssh)`, please refer to the
&gt; [Dockerfile reference](https://docs.docker.com/engine/reference/builder/).

&gt; [!NOTE]
&gt; `docker build` [uses Buildx and BuildKit by default](https://docs.docker.com/build/architecture/) since Docker Engine 23.0.
&gt; You don&#039;t need to read this document unless you want to use the full-featured
&gt; standalone version of BuildKit.

&lt;!-- START doctoc generated TOC please keep comment here to allow auto update --&gt;
&lt;!-- DON&#039;T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE --&gt;

- [Used by](#used-by)
- [Quick start](#quick-start)
  - [Linux Setup](#linux-setup)
  - [Windows Setup](#windows-setup)
  - [macOS Setup](#macos-setup)
  - [Build from source](#build-from-source)
  - [Exploring LLB](#exploring-llb)
  - [Exploring Dockerfiles](#exploring-dockerfiles)
    - [Building a Dockerfile with `buildctl`](#building-a-dockerfile-with-buildctl)
    - [Building a Dockerfile using external frontend](#building-a-dockerfile-using-external-frontend)
  - [Output](#output)
    - [Image/Registry](#imageregistry)
    - [Local directory](#local-directory)
    - [Docker tarball](#docker-tarball)
    - [OCI tarball](#oci-tarball)
    - [containerd image store](#containerd-image-store)
- [Cache](#cache)
  - [Garbage collection](#garbage-collection)
  - [Export cache](#export-cache)
    - [Inline (push image and cache together)](#inline-push-image-and-cache-together)
    - [Registry (push image and cache separately)](#registry-push-image-and-cache-separately)
    - [Local directory](#local-directory-1)
    - [GitHub Actions cache (experimental)](#github-actions-cache-experimental)
    - [S3 cache (experimental)](#s3-cache-experimental)
    - [Azure Blob Storage cache (experimental)](#azure-blob-storage-cache-experimental)
  - [Consistent hashing](#consistent-hashing)
- [Metadata](#metadata)
- [Systemd socket activation](#systemd-socket-activation)
- [Expose BuildKit as a TCP service](#expose-buildkit-as-a-tcp-service)
  - [Load balancing](#load-balancing)
- [Containerizing BuildKit](#containerizing-buildkit)
  - [Podman](#podman)
  - [Nerdctl](#nerdctl)
  - [Kubernetes](#kubernetes)
  - [Daemonless](#daemonless)
- [OpenTelemetry support](#opentelemetry-support)
- [Running BuildKit without root privileges](#running-buildkit-without-root-privileges)
- [Building multi-platform images](#building-multi-platform-images)
  - [Configuring `buildctl`](#configuring-buildctl)
    - [Color Output Controls](#color-output-controls)
    - [Number of log lines (for active steps in tty mode)](#number-of-log-lines-for-active-steps-in-tty-mode)
- [Contributing](#contributing)

&lt;!-- END doctoc generated TOC please keep comment here to allow auto update --&gt;

## Used by

BuildKit is used by the following projects:

-   [Moby &amp; Docker](https://github.com/moby/moby/pull/37151) (`DOCKER_BUILDKIT=1 docker build`)
-   [img](https://github.com/genuinetools/img)
-   [OpenFaaS Cloud](https://github.com/openfaas/openfaas-cloud)
-   [container build interface](https://github.com/containerbuilding/cbi)
-   [Tekton Pipelines](https://github.com/tektoncd/catalog) (formerly [Knative Build Templates](https://github.com/knative/build-templates))
-   [the Sanic build tool](https://github.com/distributed-containers-inc/sanic)
-   [vab](https://github.com/stellarproject/vab)
-   [Rio](https://github.com/rancher/rio)
-   [kim](https://github.com/rancher/kim)
-   [PouchContainer](https://github.com/alibaba/pouch)
-   [Docker buildx](https://github.com/docker/buildx)
-   [Okteto Cloud](https://okteto.com/)
-   [Earthly earthfiles](https://github.com/vladaionescu/earthly)
-   [Gitpod](https://github.com/gitpod-io/gitpod)
-   [Dagger](https://dagger.io)
-   [envd](https://github.com/tensorchord/envd/)
-   [Depot](https://depot.dev)
-   [Namespace](https://namespace.so)
-   [Unikraft](https://unikraft.org)
-   [DevZero](https://devzero.io)
-   [dacc](https://github.com/r2d4/dacc)

## Quick start

:information_source: For Kubernetes deployments, see [`examples/kubernetes`](./examples/kubernetes).

BuildKit is composed of the `buildkitd` daemon and the `buildctl` client.
While the `buildctl` client is available for Linux, macOS, and Windows, the `buildkitd` daemon is only available for Linux and *Windows currently.

The latest binaries of BuildKit are available [here](https://github.com/moby/buildkit/releases) for Linux, macOS, and Windows.


### Linux Setup

The `buildkitd` daemon requires the following components to be installed:
-   [runc](https://github.com/opencontainers/runc) or [crun](https://github.com/containers/crun)
-   [containerd](https://github.com/containerd/containerd) (if you want to use containerd worker)

**Starting the `buildkitd` daemon:**
You need to run `buildkitd` as the root user on the host.

```bash
$ sudo buildkitd
```

To run `buildkitd` as a non-root user, see [`docs/rootless.md`](docs/rootless.md).

The buildkitd daemon supports two worker backends: OCI (runc) and containerd.

By default, the OCI (runc) worker is used. You can set `--oci-worker=false --containerd-worker=true` to use the containerd worker.

We are open to adding more backends.

To start the buildkitd daemon using systemd socket activation, you can install the buildkit systemd unit files.
See [Systemd socket activation](#systemd-socket-activation)

The buildkitd daemon listens gRPC API on `/run/buildkit/buildkitd.sock` by default, but you can also use TCP sockets.
See [Expose BuildKit as a TCP service](#expose-buildkit-as-a-tcp-service).

### Windows Setup

See instructions and notes at [`docs/windows.md`](./docs/windows.md).

### macOS Setup

[Homebrew formula](https://formulae.brew.sh/formula/buildkit) (unofficial) is available for macOS.
```console
$ brew install buildkit
```

The Homebrew formula does not contain the daemon (`buildkitd`).

For example, [Lima](https://lima-vm.io) can be used for launching the daemon inside a Linux VM.
```console
brew install lima
limactl start template://buildkit
export BUILDKIT_HOST=&quot;unix://$HOME/.lima/buildkit/sock/buildkitd.sock&quot;
```

### Build from source

To build BuildKit from source, see [`.github/CONTRIBUTING.md`](./.github/CONTRIBUTING.md).

For a `buildctl` reference, see [this document](./docs/reference/buildctl.md).

### Exploring LLB

BuildKit builds are based on a binary intermediate format called LLB that is used for defining the dependency graph for processes running part of your build. tl;dr: LLB is to Dockerfile what LLVM IR is to C.

-   Marshaled as Protobuf messages
-   Concurrently executable
-   Efficiently cacheable
-   Vendor-neutral (i.e. non-Dockerfile languages can be easily implemented)

See [`solver/pb/ops.proto`](./solver/pb/ops.proto) for the format definition, and see [`./examples/README.md`](./examples/README.md) for example LLB applications.

Currently, the following high-level languages have been implemented for LLB:

-   Dockerfile (See [Exploring Dockerfiles](#exploring-dockerfiles))
-   [Buildpacks](https://github.com/tonistiigi/buildkit-pack)
-   [Mockerfile](https://matt-rickard.com/building-a-new-dockerfile-frontend/)
-   [Gockerfile](https://github.com/po3rin/gockerfile)
-   [bldr (Pkgfile)](https://github.com/talos-systems/bldr/)
-   [HLB](https://github.com/openllb/hlb)
-   [Earthfile (Earthly)](https://github.com/earthly/earthly)
-   [Cargo Wharf (Rust)](https://github.com/denzp/cargo-wharf)
-   [Nix](https://github.com/reproducible-containers/buildkit-nix)
-   [mopy (Python)](https://github.com/cmdjulian/mopy)
-   [envd (starlark)](https://github.com/tensorchord/envd/)
-   [Blubber](https://gitlab.wikimedia.org/repos/releng/blubber)
-   [Bass](https://github.com/vito/bass)
-   [kraft.yaml (Unikraft)](https://github.com/unikraft/kraftkit/tree/staging/tools/dockerfile-llb-frontend)
-   [r2d4/llb (JSON Gateway)](https://github.com/r2d4/llb)
-   [Mass√©](https://github.com/marxarelli/masse)
-   [DALEC](https://github.com/project-dalec/dalec)
-   (open a PR to add your own language)

### Exploring Dockerfiles

Frontends are components that run inside BuildKit and convert any build definition to LLB. There is a special frontend called gateway (`gateway.v0`) that allows using any image as a frontend.

During development, Dockerfile frontend (`dockerfile.v0`) is also part of the BuildKit repo. In the future, this will be moved out, and Dockerfiles can be built using an external image.

#### Building a Dockerfile with `buildctl`

```bash
buildctl build \
    --frontend=dockerfile.v0 \
    --local context=. \
    --local dockerfile=.
# or
buildctl build \
    --frontend=dockerfile.v0 \
    --local context=. \
    --local dockerfile=. \
    --opt target=foo \
    --opt build-arg:foo=bar
```

`--local` exposes local source files from client to the builder. `context` and `dockerfile` are the names Dockerfile frontend looks for build context and Dockerfile location.

If the Dockerfile has a different filename it can be specified with `--opt filename=./Dockerfile-alternative`.

#### Building a Dockerfile using external frontend

External versions of the Dockerfile frontend are pushed to https://hub.docker.com/r/docker/dockerfile-upstream and https://hub.docker.com/r/docker/dockerfile and can be used with the gateway frontend. The source for the external frontend is currently located in `./frontend/dockerfile/cmd/dockerfile-frontend` but will move out of this repository in the future ([#163](https://github.com/moby/buildkit/issues/163)). For automatic build from master branch of this repository `docker/dockerfile-upstream:master` or `docker/dockerfile-upstream:master-labs` image can be used.

```bash
buildctl build \
    --frontend gateway.v0 \
    --opt source=docker/dockerfile \
    --local context=. \
    --local dockerfile=.
buildctl build \
    --frontend gateway.v0 \
    --opt source=docker/dockerfile \
    --opt context=https://github.com/moby/moby.git \
    --opt build-arg:APT_MIRROR=cdn-fastly.deb.debian.org
```

### Output

By default, the build result and intermediate cache will only remain internally in BuildKit. An output needs to be specified to retrieve the result.

#### Image/Registry

```bash
buildctl build ... --output type=image,name=docker.io/username/image,push=true
```

To export the image to multiple registries:

```bash
buildctl build ... --output type=image,\&quot;name=docker.io/username/image,docker.io/username2/image2\&quot;,push=true
```

To export the cache embed with the image and pushing them to registry together, type `registry` is required to import the cache, you should specify `--export-cache type=inline` and `--import-cache type=registry,ref=...`. To export the cache to a local directly, you should specify `--export-cache type=local`.
Details in [Export cache](#export-cache).

```bash
buildctl build ...\
  --output type=image,name=docker.io/username/image,push=true \
  --export-cache type=inline \
  --import-cache type=registry,ref=docker.io/username/image
```

Keys supported by image output:
* `name=&lt;value&gt;`: specify image name(s)
* `push=true`: push after creating the image
* `push-by-digest=true`: push unnamed image
* `registry.insecure=true`: push to insecure HTTP registry
* `oci-mediatypes=true`: use OCI mediatypes in configuration JSON instead of Docker&#039;s
* `oci-artifact=false`: use OCI artifact format for attestations
* `unpack=true`: unpack image after creation (for use with containerd)
* `dangling-name-prefix=&lt;value&gt;`: name image with `prefix@&lt;digest&gt;`, used for anonymous images
* `name-canonical=true`: add additional canonical name `name@&lt;digest&gt;`
* `compression=&lt;uncompressed|gzip|estargz|zstd&gt;`: choose compression type for layers newly created and cached, gzip is default value. estargz should be used with `oci-mediatypes=true`.
* `compression-level=&lt;value&gt;`: compression level for gzip, estargz (0-9) and zstd (0-22)
* `rewrite-timestamp=true`: rewrite the file timestamps to the `SOURCE_DATE_EPOCH` value.
   See [`docs/build-repro.md`](docs/build-repro.md) for how to specify the `SOURCE_DATE_EPOCH` value.
* `force-compression=true`: forcefully apply `compression` option to all layers (including already existing layers)
* `store=true`: store the result images to the worker&#039;s (e.g. containerd) image store as well as ensures that the image has all blobs in the content store (default `true`). Ignored if the worker doesn&#039;t have image store (e.g. OCI worker).
* `annotation.&lt;key&gt;=&lt;value&gt;`: attach an annotation with the respective `key` and `value` to the built image
  * Using the extended syntaxes, `annotation-&lt;type&gt;.&lt;key&gt;=&lt;value&gt;`, `annotation[&lt;platform&gt;].&lt;key&gt;=&lt;value&gt;` and both combined with `annotation-&lt;type&gt;[&lt;platform&gt;].&lt;key&gt;=&lt;value&gt;`, allows configuring exactly where to attach the annotation.
  * `&lt;type&gt;` specifies what object to attach to, and can be any of `manifest` (the default), `manifest-descriptor`, `index` and `index-descriptor`
  * `&lt;platform&gt;` specifies which objects to attach to (by default, all), and is the same key passed into the `platform` opt, see [`docs/multi-platform.md`](docs/multi-platform.md).
  * See [`docs/annotations.md`](docs/annotations.md) for more details.

If credentials are required, `buildctl` will attempt to read Docker configuration file `$DOCKER_CONFIG/config.json`.
`$DOCKER_CONFIG` defaults to `~/.docker`.

#### Local directory

The local client will copy the files directly to the client. This is useful if BuildKit is being used for building something else than container images.

```bash
buildctl build ... --output type=local,dest=path/to/output-dir
```

To export specific files use multi-stage builds with a scratch stage and copy the needed files into that stage with `COPY --from`.

```dockerfile
...
FROM scratch as testresult

COPY --from=builder /usr/src/app/testresult.xml .
...
```

```bash
buildctl build ... --opt target=testresult --output type=local,dest=path/to/output-dir
```

With a [multi-platform build](docs/multi-platform.md), a subfolder matching
each target platform will be created in the destination directory:

```dockerfile
FROM busybox AS build
ARG TARGETOS
ARG TARGETARCH
RUN mkdir /out &amp;&amp; echo foo &gt; /out/hello-$TARGETOS-$TARGETARCH

FROM scratch
COPY --from=build /out /
```

```bash
$ buildctl build \
  --frontend dockerfile.v0 \
  --opt platform=linux/amd64,linux/arm64 \
  --output type=local,dest=./bin/release

$ tree ./bin
./bin/
‚îî‚îÄ‚îÄ release
    ‚îú‚îÄ‚îÄ linux_amd64
    ‚îÇ   ‚îî‚îÄ‚îÄ hello-linux-amd64
    ‚îî‚îÄ‚îÄ linux_arm64
        ‚îî‚îÄ‚îÄ hello-linux-arm64
```

You can set `platform-split=false` to merge files from all platforms together
into same directory:

```bash
$ buildctl build \
  --frontend dockerfile.v0 \
  --opt platform=linux/amd64,linux/arm64 \
  --output type=local,dest=./bin/release,platform-split=false

$ tree ./bin
./bin/
‚îî‚îÄ‚îÄ release
    ‚îú‚îÄ‚îÄ hello-linux-amd64
    ‚îî‚îÄ‚îÄ hello-linux-arm64
```

Tar exporter is similar to local exporter but transfers the files through a tarball.

```bash
buildctl build ... --output type=tar,dest=out.tar
buildctl build ... --output type=tar &gt; out.tar
```

#### Docker tarball

```bash
# exported tarball is also compatible with OCI spec
buildctl build ... --output type=docker,name=myimage | docker load
```

#### OCI tarball

```bash
buildctl build ... --output type=oci,dest=path/to/output.tar
buildctl build ... --output type=oci &gt; output.tar
```

#### containerd image store

The containerd worker needs to be used

```bash
buildctl build ... --output type=image,name=docker.io/username/image
ctr --namespace=buildkit images ls
```

To change the containerd namespace, you need to change `worker.containerd.namespace` in [`/etc/buildkit/buildkitd.toml`](./docs/buildkitd.toml.md).

## Cache

To show local build cache (`/var/lib/buildkit`):

```bash
buildctl du -v
```

To prune local build cache:
```bash
buildctl prune
```

### Garbage collection

See [`./docs/buildkitd.toml.md`](./docs/buildkitd.toml.md).

### Export cache

BuildKit supports the following cache exporters:
* `inline`: embed the cache into the image, and push them to the registry together
* `registry`: push the image and the cache separately
* `local`: export to a local directory
* `gha`: export to GitHub Actions cache

In most case you want to use the `inline` cache exporter.
However, note that the `inline` cache exporter only supports `min` cache mode. 
To enable `max` cache mode, push the image and the cache separately by using `registry` cache exporter.

`inline` and `registry` exporters both store the cache in the registry. For importing the cache, `type=registry` is sufficient for both, as specifying the cache format is not necessary.

#### Inline (push image and cache together)

```bash
buildctl build ... \
  --output type=image,name=docker.io/username/image,push=true \
  --export-cache type=inline \
  --import-cache type=registry,ref=docker.io/username/image
```

Note that the inline cache is not imported unless [`--import-cache type=registry,ref=...`](#registry-push-image-and-cache-separately) is provided.

Inline cache embeds cache metadata into the image config. The layers in the image will be left untouched compared to the image with no cache information.

:information_source: Docker-integrated BuildKit (`DOCKER_BUILDKIT=1 docker build`) and `docker buildx`requires 
`--build-arg BUILDKIT_INLINE_CACHE=1` to be specified to enable the `inline` cache exporter.
However, the standalone `buildctl` does NOT require `--opt build-arg:BUILDKIT_INLINE_CACHE=1` and the build-arg is simply ignored.

#### Registry (push image and cache separately)

```bash
buildctl build ... \
  --output type=image,name=localhost:5000/myrepo:image,push=true \
  --export-cache type=registry,ref=localhost:5000/myrepo:buildcache \
  --import-cache type=registry,ref=localhost:5000/myrepo:buildcache
```

`--export-cache` options:
* `type=registry`
* `mode=&lt;min|max&gt;`: specify cache layers to export (default: `min`)
  * `min`: only export layers for the resulting image
  * `max`: export all the layers of all intermediate steps
* `ref=&lt;ref&gt;`: specify repository re

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[heroiclabs/nakama]]></title>
            <link>https://github.com/heroiclabs/nakama</link>
            <guid>https://github.com/heroiclabs/nakama</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:45 GMT</pubDate>
            <description><![CDATA[Distributed server for social and realtime games and apps.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/heroiclabs/nakama">heroiclabs/nakama</a></h1>
            <p>Distributed server for social and realtime games and apps.</p>
            <p>Language: Go</p>
            <p>Stars: 11,768</p>
            <p>Forks: 1,313</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://heroiclabs.com&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img src=&quot;./.github/nakama.png&quot; alt=&quot;Nakama - Distributed server for social and realtime games and apps&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://heroiclabs.com/docs/nakama/getting-started/install/&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/heroiclabs/nakama.svg?colorA=18181B&amp;colorB=825df2&quot; alt=&quot;Version&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://hub.docker.com/r/heroiclabs/nakama&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/heroiclabs/nakama?colorA=18181B&amp;colorB=825df2&amp;label=downloads&quot; alt=&quot;Downloads&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/heroiclabs/nakama/blob/master/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/heroiclabs/nakama.svg?colorA=18181B&amp;colorB=825df2&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://forum.heroiclabs.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Nakama%20Forum-18181B?logo=discourse&quot; alt=&quot;Nakama Forum&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://heroiclabs.com/docs&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Nakama%20Docs-18181B?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzU3IiBoZWlnaHQ9IjU3OSIgdmlld0JveD0iMCAwIDM1NyA1NzkiIGZpbGw9Im5vbmUiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyI+CjxwYXRoIGZpbGwtcnVsZT0iZXZlbm9kZCIgY2xpcC1ydWxlPSJldmVub2RkIiBkPSJNMTI3Ljc1NyAzMzYuNDQ2QzExNC4yMjUgMzM2Ljc0MyAxMDcuNzA1IDMxOS45MDYgMTAzLjk1MiAzMDguNzE0QzEwNy4yMTIgMzA4LjgxMyAxMTAuNDcxIDMwOS4wMTEgMTEzLjYzMiAzMDkuMzA4QzEyMC44NDMgMzEwLjEwMSAxMjguMDU0IDMxMi4xODEgMTMyLjY5NiAzMTguMjIyQzEzOS4xMTcgMzI2LjQ0MyAxMzMuODgyIDMzNi4zNDcgMTI3Ljg1NiAzMzYuNDQ2TTIyOS43OTYgMzM2LjQ0NkMyNDMuMzI4IDMzNi43NDMgMjQ5Ljg0OCAzMTkuOTA2IDI1My42MDEgMzA4LjcxNEMyNTAuMzQxIDMwOC44MTMgMjQ3LjA4MiAzMDkuMDExIDI0My45MjEgMzA5LjMwOEMyMzYuNzEgMzEwLjEwMSAyMjkuNDk5IDMxMi4xODEgMjI0Ljg1NyAzMTguMjIyQzIxOC40MzYgMzI2LjQ0MyAyMjMuNjcxIDMzNi4zNDcgMjI5LjY5NyAzMzYuNDQ2SDIyOS43OTZaTTE3OC4xMzQgNTMzLjQ0MUwxNzguNzI3IDUzNC4xMzRMMTc5LjQxOSA1MzMuNDQxQzE5NC42MyA1MTMuMDM4IDE5Ny42OTMgNDc0LjExNCAxNzguNzI3IDQ1NS41OTRDMTYwLjA1OCA0NzUuMjA0IDE2Mi41MjcgNTEyLjU0MyAxNzguMTM0IDUzMy40NDFaTTE3Ny45MzcgMC41OTQyNTJMMTc4LjcyNyAwTDE3OS41MTcgMC41OTQyNTJDMTk4Ljk3NyAxNC4xNjMgMjEzLjIwMSAyOC4zMjYgMjI3LjEyOSA0Ny44MzczQzI3MS44NzUgMTEwLjIzNCAzMDAuOTE2IDIxMC41NjMgMjkxLjczIDI4NC45NDRDMzEyLjk2NyAyOTQuMTU1IDMyOS41NjIgMzA5LjQwNyAzNDAuNzI0IDMyOC4yMjVDMzU4LjcwMSAzNTguNjMxIDM2Ni4wMTEgNDIwLjAzNyAzNDAuMzI5IDQ1MS45MjlDMzA3LjgzMSA0MzQuMDAyIDI2MC44MTIgNDE5Ljc0IDIxNC4xODkgNDMyLjkxM0wyMDQuODA1IDQzNi45NzRDMjI5Ljc5NiA0NzAuNTQ5IDIyOS45OTMgNTE1LjUxNCAyMDcuMDc3IDU0OS4wODlDMTk3LjI5NyA1NjMuNDUgMTg5Ljk4OCA1NjcuODA4IDE3OC40MzEgNTc5QzE2Ni42NzYgNTY4LjcgMTU4Ljg3MyA1NjIuMzYxIDE0OS43ODUgNTQ5LjA4OUMxMjYuOTY3IDUxNS41MTQgMTI3LjA2NiA0NzAuNTQ5IDE1Mi4wNTcgNDM2Ljk3NEwxNDIuNzcyIDQzMi45MTNDOTYuMTQ4NCA0MTkuNzQgNDkuMTI5OCA0MzQuMDAyIDE2LjYzMTcgNDUxLjkyOUMtOC45NTE4OCA0MjAuMDM3IC0xLjc0MTA1IDM1OC42MzEgMTYuMjM2NiAzMjguMjI1QzI3LjM5ODYgMzA5LjMwOCA0NC4wOTIxIDI5NC4wNTYgNjUuMjMwNyAyODQuOTQ0QzU2LjA0NDMgMjEwLjU2MyA4NS4wODUyIDExMC4yMzQgMTI5LjgzMiA0Ny44MzczQzE0My44NTggMjguMzI2IDE1Ny45ODQgMTQuMTYzIDE3Ny40NDMgMC41OTQyNTJIMTc3LjkzN1pNMzIyLjg0NSA0MDkuMjQyQzMyNy4wOTIgMzg3LjA1NiAzMjMuNzM0IDM2My4zODUgMzEyLjg2OCAzNDQuOTY0QzMwNi4xNTEgMzMzLjY3MyAyOTYuNjY5IDMyNC4zNjMgMjg0LjcxNiAzMTcuOTI1QzI4MS41NTUgMzI3LjgyOSAyNzcuNTA2IDMzNi44NDIgMjcyLjQ2OCAzNDQuODY1QzI1Ny4zNTUgMzY5LjEzIDIyMy41NzMgMzc4LjQ0IDIwMi4zMzUgMzU3LjY0MUMxNzIuOTk4IDMyOC44MiAxOTQuNTMyIDI3NC4wNDkgMjUzLjEwNyAyNzUuOTMxTDI2MC4xMjEgMjc2LjYyNUMyNjcuNTI5IDIwMi4zNDMgMjMzLjU0OSA5Mi40MDYzIDE3OC42MjggNDIuMjkxQzEyMy43MDggOTIuNTA1MyA4OS44MjY1IDIwMi4zNDMgOTcuMTM2MiAyNzYuNjI1TDEwNC4xNDkgMjc1LjkzMUMxNjIuNzI1IDI3NC4wNDkgMTg0LjM1NyAzMjguNzIxIDE1NC45MjIgMzU3LjY0MUMxMzMuNzgzIDM3OC40NCA5OS45MDE5IDM2OS4xMyA4NC43ODg4IDM0NC44NjVDNzkuNzUxMiAzMzYuODQyIDc1LjcwMTIgMzI3LjczIDcyLjU0MDMgMzE3LjkyNUM2MC41ODgxIDMyNC4zNjMgNTEuMTA1NCAzMzMuNzcyIDQ0LjM4ODUgMzQ0Ljk2NEMzMy41MjI4IDM2My4zODUgMzAuMTY0NCAzODcuMDU2IDM0LjQxMTggNDA5LjI0MkM4Ni4yNzA1IDM5MC4yMjYgMTI4LjM1IDM5MC43MjEgMTc4LjUzIDQxMi4zMTJDMjI4LjgwOCAzOTAuNjIyIDI3MC43ODkgMzkwLjIyNiAzMjIuNjQ3IDQwOS4yNDJIMzIyLjg0NVoiIGZpbGw9IndoaXRlIi8+Cjwvc3ZnPgo=&quot; alt=&quot;Nakama Documentation&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## Features

* **Users** - Register/login new users via social networks, email, or device ID.
* **Storage** - Store user records, settings, and other objects in collections.
* **Social** - Users can connect with friends, and join groups. Builtin social graph to see how users can be connected.
* **Chat** - 1-on-1, group, and global chat between users. Persist messages for chat history.
* **Multiplayer** - Realtime, or turn-based active and passive multiplayer.
* **Leaderboards** - Dynamic, seasonal, get top members, or members around a user. Have as many as you need.
* **Tournaments** - Invite players to compete together over prizes. Link many together to create leagues.
* **Parties** - Add team play to a game. Users can form a party and communicate with party members.
* **Purchase Validation** - Validate in-app purchases and subscriptions.
* **In-App Notifications** - Send messages and notifications to connected client sockets.
* **Runtime code** - Extend the server with custom logic written in Lua, TypeScript/JavaScript, or native Go code.
* **Matchmaker**, **dashboard**, **metrics**, and [more](https://heroiclabs.com/docs).

Build scalable games and apps with a production ready server used by ambitious game studios and app developers [all around the world](https://heroiclabs.com/customers/). Have a look at the [documentation](https://heroiclabs.com/docs) and join the [developer community](https://forum.heroiclabs.com) for more info.

## Getting Started

The server is simple to setup and run for local development and can be deployed to any cloud provider. See the [deployment notes](#deployment) for recommendations on how to deploy the project for production. Nakama server requires CockroachDB or another Postgres wire-compatible server as it&#039;s database.

### Docker

&lt;a href=&quot;https://heroiclabs.com/docs/install-docker-quickstart/&quot;&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/en/f/f4/Docker_logo.svg&quot; width=&quot;170&quot;&gt;&lt;/a&gt;

The fastest way to run the server and the database is with Docker. Setup Docker and start the daemon.

1. Set up a [docker-compose file](https://heroiclabs.com/docs/nakama/getting-started/install/docker/#running-nakama) and place it in a folder for your project.

2. Run `docker-compose -f ./docker-compose.yml up` to download container images and run the servers.

For more detailed instructions have a look at our [Docker quickstart](https://heroiclabs.com/docs/nakama/getting-started/install/docker) guide.

Nakama Docker images are maintained on [Docker Hub](https://hub.docker.com/r/heroiclabs/nakama/tags) and [prerelease](https://hub.docker.com/r/heroiclabs/nakama-prerelease/tags) images are occasionally published for cutting edge features of the server.

### Binaries

You can run the servers with native binaries for your platform.

1. Download the server from our [releases](https://github.com/heroiclabs/nakama/releases) page and the [database](https://www.cockroachlabs.com/docs/stable/install-cockroachdb.html).

2. Follow the database [instructions](https://www.cockroachlabs.com/docs/stable/start-a-local-cluster.html#before-you-begin) to start it.

3. Run a migration which will setup or upgrade the database schema:

   ```shell
   nakama migrate up --database.address &quot;root@127.0.0.1:26257&quot;
   ```

4. Start Nakama and connect to the database:

   ```shell
   nakama --database.address &quot;root@127.0.0.1:26257&quot;
   ```

When connected you&#039;ll see server output which describes all settings the server uses for [configuration](https://heroiclabs.com/docs/nakama/getting-started/configuration).

&gt; {&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2018-04-29T10:14:41.249+0100&quot;,&quot;msg&quot;:&quot;Node&quot;,&quot;name&quot;:&quot;nakama&quot;,&quot;version&quot;:&quot;2.0.0+7e18b09&quot;,&quot;runtime&quot;:&quot;go1.10.1&quot;,&quot;cpu&quot;:4} &lt;br/&gt;
&gt; {&quot;level&quot;:&quot;info&quot;,&quot;ts&quot;:&quot;2018-04-29T10:14:41.249+0100&quot;,&quot;msg&quot;:&quot;Database connections&quot;,&quot;dsns&quot;:[&quot;root@127.0.0.1:26257&quot;]} &lt;br/&gt;
&gt; ...

## Usage

Nakama supports a variety of protocols optimized for various gameplay or app use cases. For request/response it can use GRPC or the HTTP1.1+JSON fallback (REST). For realtime communication you can use WebSockets or rUDP.

For example with the REST API to authenticate a user account with a device identifier.

```shell
curl &quot;127.0.0.1:7350/v2/account/authenticate/device?create=true&quot; \
  --user &quot;defaultkey:&quot; \
  --data &#039;{&quot;id&quot;: &quot;someuniqueidentifier&quot;}&#039;
```

Response:

&gt; { &lt;br&gt;
&gt;     &quot;token&quot;:&quot;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE1MjQ5OTU2NDksInVpZCI6Ijk5Y2Q1YzUyLWE5ODgtNGI2NC04YThhLTVmMTM5YTg4MTgxMiIsInVzbiI6InhBb1RxTUVSdFgifQ.-3_rXNYx3Q4jKuS7RkxeMWBzMNAm0vl93QxzRI8p_IY&quot; &lt;br&gt;
&gt; }

There&#039;s a number of official [client libraries](https://github.com/heroiclabs) available on GitHub with [documentation](https://heroiclabs.com/docs). The current platform/language support includes: .NET (in C#), Unity engine, JavaScript, Java (with Android), Unreal engine, Godot, Defold, and Swift (with iOS). If you&#039;d like to contribute a client or request one let us know.

## Nakama Console

The server provides a web UI which teams can use to inspect various data stored through the server APIs, view lightweight service metrics, manage player data, update storage objects, restrict access to production with permission profiles, and gain visibility into realtime features like active multiplayer matches. There is no separate installation required as it is embedded as part of the single server binary.

You can navigate to it on your browser on [http://127.0.0.1:7351](http://127.0.0.1:7351).


&lt;details open&gt;
&lt;summary&gt;View Screenshots&lt;/summary&gt;
  &lt;img src=&quot;.github/dashboard.png&quot; alt=&quot;Nakama Console dashboard view&quot; title=&quot;Dashboard view&quot;&gt;
  &lt;img src=&quot;.github/players.png&quot; alt=&quot;Nakama Console players view&quot; title=&quot;Players view&quot;&gt;
  &lt;img src=&quot;.github/api-explorer.png&quot; alt=&quot;Nakama Console API explorer view&quot; title=&quot;API explorer view&quot;&gt;
  &lt;img src=&quot;.github/storage.png&quot; alt=&quot;Nakama Console storage view&quot; title=&quot;Storage object view&quot;&gt;
  &lt;img src=&quot;.github/modules.png&quot; alt=&quot;Nakama Console modules view&quot; title=&quot;Runtime modules view&quot;&gt;
&lt;/details&gt;

## Deployment

Nakama can be deployed to any cloud provider such as Google Cloud, Azure, AWS, Digital Ocean, Heroku, or your own private cloud. You should setup and provision separate nodes for Nakama and CockroachDB.

The recommended minimum production infrastructure for CockroachDB is outlined in [these docs](https://www.cockroachlabs.com/docs/stable/recommended-production-settings.html#basic-hardware-recommendations) and Nakama can be run on instance types as small as &quot;g1-small&quot; on Google Cloud although we recommend a minimum of &quot;n1-standard-1&quot; in production. The specific hardware requirements will depend on what features of the server are used. Reach out to us for help and advice on what servers to run.

### Heroic Cloud

You can support development, new features, and maintainance of the server by using the Heroic Labs&#039; [Heroic Cloud](https://heroiclabs.com/heroic-cloud/) for deployment. This service handles the uptime, replication, backups, logs, data upgrades, and all other tasks involved with production server environments.

Have a look at our [Heroic Cloud](https://heroiclabs.com/heroic-cloud/) service for more details.

## Contribute

The development roadmap is managed as GitHub issues and pull requests are welcome. If you&#039;re interested to add a feature which is not mentioned on the issue tracker please open one to create a discussion or drop in and discuss it in the [community forum](https://forum.heroiclabs.com).

### Simple Builds

All dependencies required for a build are vendored as part of the Go project. We recommend a modern release of the Go toolchain and do not store the codebase in the old GOPATH.

1. Download the source tree.

   ```shell
   git clone &quot;https://github.com/heroiclabs/nakama&quot; nakama
   cd nakama
   ```

2. Build the project from source.

   ```shell
   go build -trimpath -mod=vendor
   ./nakama --version
   ```

### Full Source Builds

The codebase uses Protocol Buffers, GRPC, GRPC-Gateway, and the OpenAPI spec as part of the project. These dependencies are generated as sources and committed to the repository to simplify builds for contributors.

To build the codebase and generate all sources follow these steps.

1. Install the toolchain.

   ```shell
   go install \
       &quot;google.golang.org/protobuf/cmd/protoc-gen-go&quot; \
       &quot;google.golang.org/grpc/cmd/protoc-gen-go-grpc&quot; \
       &quot;github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-grpc-gateway&quot; \
       &quot;github.com/grpc-ecosystem/grpc-gateway/v2/protoc-gen-openapiv2&quot;
   ```

2. Re-generate the protocol buffers and gateway code.

   ```shell
   buf generate apigrpc -o apigrpc
   buf generate console -o console
   ```

3. Build the codebase.

   ```shell
   go build -trimpath -mod=vendor
   ```

### Testing

In order to run all the unit and integration tests run:

```shell
docker-compose -f ./docker-compose-tests.yml up --build --abort-on-container-exit; docker-compose -f ./docker-compose-tests.yml down -v
```

This will create an isolated environment with Nakama and database instances, run
all the tests, and drop the environment afterwards.

### License

This project is licensed under the [Apache-2 License](https://github.com/heroiclabs/nakama/blob/master/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[microsoft/typescript-go]]></title>
            <link>https://github.com/microsoft/typescript-go</link>
            <guid>https://github.com/microsoft/typescript-go</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:44 GMT</pubDate>
            <description><![CDATA[Staging repo for development of native port of TypeScript]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/typescript-go">microsoft/typescript-go</a></h1>
            <p>Staging repo for development of native port of TypeScript</p>
            <p>Language: Go</p>
            <p>Stars: 23,178</p>
            <p>Forks: 755</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre># TypeScript 7

[Not sure what this is? Read the announcement post!](https://devblogs.microsoft.com/typescript/typescript-native-port/)

## Preview

A preview build is available on npm as [`@typescript/native-preview`](https://www.npmjs.com/package/@typescript/native-preview).

```sh
npm install @typescript/native-preview
npx tsgo # Use this as you would tsc.
```

A preview VS Code extension is [available on the VS Code marketplace](https://marketplace.visualstudio.com/items?itemName=TypeScriptTeam.native-preview).

To use this, set this in your VS Code settings:

```json
{
    &quot;typescript.experimental.useTsgo&quot;: true
}
```

## What Works So Far?

This is still a work in progress and is not yet at full feature parity with TypeScript. Bugs may exist. Please check this list carefully before logging a new issue or assuming an intentional change.

| Feature | Status | Notes |
|---------|--------|-------|
| Program creation | done | Same files and module resolution as TS 5.9. Not all resolution modes supported yet. |
| Parsing/scanning | done | Exact same syntax errors as TS 5.9 |
| Commandline and `tsconfig.json` parsing | done | Done, though `tsconfig` errors may not be as helpful. |
| Type resolution | done | Same types as TS 5.9. |
| Type checking | done | Same errors, locations, and messages as TS 5.9. Types printback in errors may display differently. |
| JavaScript-specific inference and JSDoc | in progress | Mostly complete, but intentionally lacking some features. Declaration emit not complete. |
| JSX | done | - |
| Declaration emit | in progress | Most common features are in place, but some edge cases and feature flags are still unhandled. |
| Emit (JS output) | in progress | `target: esnext` well-supported, other targets may have gaps. |
| Watch mode | prototype | Watches files and rebuilds, but no incremental rechecking. Not optimized. |
| Build mode / project references | done | - |
| Incremental build | done | - |
| Language service (LSP) | in progress | Most functionality. More features coming soon. |
| API | not ready | - |

Definitions:

 * **done** aka &quot;believed done&quot;: We&#039;re not currently aware of any deficits or major left work to do. OK to log bugs
 * **in progress**: currently being worked on; some features may work and some might not. OK to log panics, but nothing else please
 * **prototype**: proof-of-concept only; do not log bugs
 * **not ready**: either haven&#039;t even started yet, or far enough from ready that you shouldn&#039;t bother messing with it yet

## Other Notes

Long-term, we expect that this repo and its contents will be merged into `microsoft/TypeScript`.
As a result, the repo and issue tracker for typescript-go will eventually be closed, so treat discussions/issues accordingly.

For a list of intentional changes with respect to TypeScript 5.9, see CHANGES.md.

## Contributing

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit [Contributor License Agreements](https://cla.opensource.microsoft.com).

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
[Microsoft&#039;s Trademark &amp; Brand Guidelines](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party&#039;s policies.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[trustwallet/assets]]></title>
            <link>https://github.com/trustwallet/assets</link>
            <guid>https://github.com/trustwallet/assets</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:43 GMT</pubDate>
            <description><![CDATA[A comprehensive, up-to-date collection of information about several thousands (!) of crypto tokens.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/trustwallet/assets">trustwallet/assets</a></h1>
            <p>A comprehensive, up-to-date collection of information about several thousands (!) of crypto tokens.</p>
            <p>Language: Go</p>
            <p>Stars: 5,154</p>
            <p>Forks: 26,125</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># Trust Wallet Assets Info

![Check](https://github.com/trustwallet/assets/workflows/Check/badge.svg)

## Overview

Trust Wallet token repository is a comprehensive, up-to-date collection of information about several thousands (!) of crypto tokens.

[Trust Wallet](https://trustwallet.com) uses token logos from this source, alongside a number of other projects.

The repository contains token info from several blockchains, info on dApps, staking validators, etc.
For every token a logo and optional additional information is available (such data is not available on-chain).

Such a large collection can be maintained only through a community effort, so _feel free to add your token_.

&lt;center&gt;&lt;img src=&#039;https://trustwallet.com/assets/images/media/assets/horizontal_blue.png&#039; height=&quot;200&quot;&gt;&lt;/center&gt;

## How to add token

Please note that __brand new tokens are not accepted__,
the projects have to be sound, with information available, and __non-minimal circulation__
(for limit details see &lt;https://developer.trustwallet.com/listing-new-assets/requirements&gt;).

### Assets App

The [Assets web app](https://assets.trustwallet.com) can be used for most new token additions (Github account is needed).

### Quick starter

Details of the repository structure and contribution guidelines are listed on the
[Developers site](https://developer.trustwallet.com/listing-new-assets/new-asset).
Here is a quick starter summary for the most common use case.


## Documentation

For details, see the [Developers site](https://developer.trustwallet.com):

- [Contribution guidelines](https://developer.trustwallet.com/listing-new-assets/repository_details)

- [FAQ](https://developer.trustwallet.com/listing-new-assets/faq)

## Scripts

There are several scripts available for maintainers:

- `make check` -- Execute validation checks; also used in continuous integration.
- `make fix` -- Perform automatic fixes where possible
- `make update-auto` -- Run automatic updates from external sources, executed regularly (GitHub action)
- `make add-token asset_id=c60_t0x4Fabb145d64652a948d72533023f6E7A623C7C53` -- Create `info.json` file as asset template.
- `make add-tokenlist asset_id=c60_t0x4Fabb145d64652a948d72533023f6E7A623C7C53` -- Adds a token to tokenlist.json.
- `make add-tokenlist-extended asset_id=c60_t0x4Fabb145d64652a948d72533023f6E7A623C7C53` -- Adds a token to tokenlist-extended.json.

## On Checks

This repo contains a set of scripts for verification of all the information. Implemented as Golang scripts, available through `make check`, and executed in CI build; checks the whole repo.
There are similar check logic implemented:

- in assets-management app; for checking changed token files in PRs, or when creating a PR.  Checks diffs, can be run from browser environment.
- in merge-fee-bot, which runs as a GitHub app shows result in PR comment. Executes in a non-browser environment.

## Trading pair maintenance

Info on supported trading pairs are stored in `tokenlist.json` files.
Trading pairs can be updated --
from Uniswap/Ethereum and PancakeSwap/Smartchain -- using update script (and checking in changes).
Minimal limit values for trading pair inclusion are set in the [config file](https://github.com/trustwallet/assets/blob/master/.github/assets.config.yaml).
There are also options for force-include and force-exclude in the config.

## Disclaimer

Trust Wallet team allows anyone to submit new assets to this repository. However, this does not mean that we are in direct partnership with all of the projects.

Trust Wallet team will reject projects that are deemed as scam or fraudulent after careful review.
Trust Wallet team reserves the right to change the terms of asset submissions at any time due to changing market conditions, risk of fraud, or any other factors we deem relevant.

Additionally, spam-like behavior, including but not limited to mass distribution of tokens to random addresses will result in the asset being flagged as spam and possible removal from the repository.

## License

The scripts and documentation in this project are released under the [MIT License](LICENSE)
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
        <item>
            <title><![CDATA[hashicorp/consul]]></title>
            <link>https://github.com/hashicorp/consul</link>
            <guid>https://github.com/hashicorp/consul</guid>
            <pubDate>Tue, 09 Dec 2025 00:04:42 GMT</pubDate>
            <description><![CDATA[Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hashicorp/consul">hashicorp/consul</a></h1>
            <p>Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure.</p>
            <p>Language: Go</p>
            <p>Stars: 29,589</p>
            <p>Forks: 4,549</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;
  &lt;img src=&quot;./website/public/img/logo.svg&quot; align=&quot;left&quot; height=&quot;46px&quot; alt=&quot;Consul logo&quot;/&gt;
  &lt;span&gt;Consul&lt;/span&gt;
&lt;/h1&gt;

[![License: BUSL-1.1](https://img.shields.io/badge/License-BUSL--1.1-yellow.svg)](LICENSE)
[![Docker Pulls](https://img.shields.io/docker/pulls/hashicorp/consul.svg)](https://hub.docker.com/r/hashicorp/consul)
[![Go Report Card](https://goreportcard.com/badge/github.com/hashicorp/consul)](https://goreportcard.com/report/github.com/hashicorp/consul)

Consul is a distributed, highly available, and data center aware solution to connect and configure applications across dynamic, distributed infrastructure.

* Documentation and Tutorials: [https://developer.hashicorp.com/consul]
* Forum: [Discuss](https://discuss.hashicorp.com/c/consul)

Consul provides several key features:

* **Multi-Datacenter** - Consul is built to be datacenter aware, and can
  support any number of regions without complex configuration.

* **Service Mesh** - Consul Service Mesh enables secure service-to-service
  communication with automatic TLS encryption and identity-based authorization. Applications
  can use sidecar proxies in a service mesh configuration to establish TLS
  connections for inbound and outbound connections with Transparent Proxy.

* **API Gateway** - Consul API Gateway manages access to services within Consul Service Mesh, 
  allow users to define traffic and authorization policies to services deployed within the mesh.  

* **Service Discovery** - Consul makes it simple for services to register
  themselves and to discover other services via a DNS or HTTP interface.
  External services such as SaaS providers can be registered as well.

* **Health Checking** - Health Checking enables Consul to quickly alert
  operators about any issues in a cluster. The integration with service
  discovery prevents routing traffic to unhealthy hosts and enables service
  level circuit breakers.

* **Dynamic App Configuration** - An HTTP API that allows users to store indexed objects within Consul,
  for storing configuration parameters and application metadata.

Consul runs on Linux, macOS, FreeBSD, Solaris, and Windows and includes an
optional [browser based UI](https://demo.consul.io). A commercial version
called [Consul Enterprise](https://developer.hashicorp.com/consul/docs/enterprise) is also
available.

**Please note**: We take Consul&#039;s security and our users&#039; trust very seriously. If you
believe you have found a security issue in Consul, please [responsibly disclose](https://www.hashicorp.com/security#vulnerability-reporting)
by contacting us at security@hashicorp.com.

## Quick Start

A few quick start guides are available on the Consul website:

* **Standalone binary install:** https://learn.hashicorp.com/collections/consul/get-started-vms
* **Minikube install:** https://learn.hashicorp.com/tutorials/consul/kubernetes-minikube
* **Kind install:** https://learn.hashicorp.com/tutorials/consul/kubernetes-kind
* **Kubernetes install:** https://learn.hashicorp.com/tutorials/consul/kubernetes-deployment-guide
* **Deploy HCP Consul:** https://learn.hashicorp.com/tutorials/consul/hcp-gs-deploy 

## Documentation

Full, comprehensive documentation is available on the Consul website: https://developer.hashicorp.com/consul/docs

## Contributing

Thank you for your interest in contributing! Please refer to [CONTRIBUTING.md](https://github.com/hashicorp/consul/blob/main/.github/CONTRIBUTING.md)
for guidance. For contributions specifically to the browser based UI, please
refer to the UI&#039;s [README.md](https://github.com/hashicorp/consul/blob/main/ui/packages/consul-ui/README.md)
for guidance.
</pre>
          ]]></content:encoded>
            <category>Go</category>
        </item>
    </channel>
</rss>