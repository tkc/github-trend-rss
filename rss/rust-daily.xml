<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Tue, 10 Jun 2025 00:05:50 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[tensorzero/tensorzero]]></title>
            <link>https://github.com/tensorzero/tensorzero</link>
            <guid>https://github.com/tensorzero/tensorzero</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:50 GMT</pubDate>
            <description><![CDATA[TensorZero creates a feedback loop for optimizing LLM applications ‚Äî turning production data into smarter, faster, and cheaper models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tensorzero/tensorzero">tensorzero/tensorzero</a></h1>
            <p>TensorZero creates a feedback loop for optimizing LLM applications ‚Äî turning production data into smarter, faster, and cheaper models.</p>
            <p>Language: Rust</p>
            <p>Stars: 5,953</p>
            <p>Forks: 368</p>
            <p>Stars today: 996 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9&quot; width=128 height=128&gt;

# TensorZero

&lt;p&gt;&lt;picture&gt;&lt;img src=&quot;https://www.tensorzero.com/github-trending-badge.svg&quot; alt=&quot;#1 Repository Of The Day&quot;&gt;&lt;/picture&gt;&lt;/p&gt;

**TensorZero creates a feedback loop for optimizing LLM applications ‚Äî turning production data into smarter, faster, and cheaper models.**

1. Integrate our model gateway
2. Send metrics or feedback
3. Optimize prompts, models, and inference strategies
4. Watch your LLMs improve over time

It provides a **data &amp; learning flywheel for LLMs** by unifying:

- [x] **Inference:** one API for all LLMs, with &lt;1ms P99 overhead
- [x] **Observability:** inference &amp; feedback ‚Üí your database
- [x] **Optimization:** from prompts to fine-tuning and RL
- [x] **Evaluations:** compare prompts, models, inference strategies
- [x] **Experimentation:** built-in A/B testing, routing, fallbacks

---

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/&quot; target=&quot;_blank&quot;&gt;Website&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs&quot; target=&quot;_blank&quot;&gt;Docs&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.x.com/tensorzero&quot; target=&quot;_blank&quot;&gt;Twitter&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/slack&quot; target=&quot;_blank&quot;&gt;Slack&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/discord&quot; target=&quot;_blank&quot;&gt;Discord&lt;/a&gt;&lt;/b&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/quickstart&quot; target=&quot;_blank&quot;&gt;Quick Start (5min)&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/tutorial&quot; target=&quot;_blank&quot;&gt;Comprehensive Tutorial&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/deployment&quot; target=&quot;_blank&quot;&gt;Deployment Guide&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/api-reference&quot; target=&quot;_blank&quot;&gt;API Reference&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/deployment&quot; target=&quot;_blank&quot;&gt;Configuration Reference&lt;/a&gt;&lt;/b&gt;
&lt;/p&gt;

---

&lt;table&gt;
  &lt;tr&gt;
    &lt;td width=&quot;30%&quot; valign=&quot;top&quot;&gt;&lt;b&gt;What is TensorZero?&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;70%&quot; valign=&quot;top&quot;&gt;TensorZero is an open-source framework for building production-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluations, and experimentation.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;30%&quot; valign=&quot;top&quot;&gt;&lt;b&gt;How is TensorZero different from other LLM frameworks?&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;70%&quot; valign=&quot;top&quot;&gt;
      1. TensorZero enables you to optimize complex LLM applications based on production metrics and human feedback.&lt;br&gt;
      2. TensorZero supports the needs of industrial-scale LLM applications: low latency, high throughput, type safety, self-hosted, GitOps, customizability, etc.&lt;br&gt;
      3. TensorZero unifies the entire LLMOps stack, creating compounding benefits. For example, LLM evaluations can be used for fine-tuning models alongside AI judges.
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;30%&quot; valign=&quot;top&quot;&gt;&lt;b&gt;Can I use TensorZero with ___?&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;70%&quot; valign=&quot;top&quot;&gt;Yes. Every major programming language is supported. You can use TensorZero with our Python client, any OpenAI SDK, or our HTTP API.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;30%&quot; valign=&quot;top&quot;&gt;&lt;b&gt;Is TensorZero production-ready?&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;70%&quot; valign=&quot;top&quot;&gt;Yes. Here&#039;s a case study: &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms&quot;&gt;Automating Code Changelogs at a Large Bank with LLMs&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;30%&quot; valign=&quot;top&quot;&gt;&lt;b&gt;How much does TensorZero cost?&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;70%&quot; valign=&quot;top&quot;&gt;Nothing. TensorZero is 100% self-hosted and open-source. There are no paid features.&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;30%&quot; valign=&quot;top&quot;&gt;&lt;b&gt;Who is building TensorZero?&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;70%&quot; valign=&quot;top&quot;&gt;Our technical team includes a former Rust compiler maintainer, machine learning researchers (Stanford, CMU, Oxford, Columbia) with thousands of citations, and the chief product officer of a decacorn startup. We&#039;re backed by the same investors as leading open-source projects (e.g. ClickHouse, CockroachDB) and AI labs (e.g. OpenAI, Anthropic).&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;30%&quot; valign=&quot;top&quot;&gt;&lt;b&gt;How do I get started?&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;70%&quot; valign=&quot;top&quot;&gt;You can adopt TensorZero incrementally. Our &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/quickstart&quot;&gt;Quick Start&lt;/a&gt;&lt;/b&gt; goes from a vanilla OpenAI wrapper to a production-ready LLM application with observability and fine-tuning in just 5 minutes.&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

---

## Features

### üåê LLM Gateway

&gt; **Integrate with TensorZero once and access every major LLM provider.**

&lt;table&gt;
  &lt;tr&gt;&lt;/tr&gt; &lt;!-- flip highlight order --&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Model Providers&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Features&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;
      &lt;p&gt;
        The TensorZero Gateway natively supports:
      &lt;/p&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/anthropic&quot;&gt;Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock&quot;&gt;AWS Bedrock&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker&quot;&gt;AWS SageMaker&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/azure&quot;&gt;Azure OpenAI Service&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/deepseek&quot;&gt;DeepSeek&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/fireworks&quot;&gt;Fireworks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic&quot;&gt;GCP Vertex AI Anthropic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini&quot;&gt;GCP Vertex AI Gemini&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini&quot;&gt;Google AI Studio (Gemini API)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic&quot;&gt;Hyperbolic&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/mistral&quot;&gt;Mistral&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/openai&quot;&gt;OpenAI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/together&quot;&gt;Together&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/vllm&quot;&gt;vLLM&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/xai&quot;&gt;xAI&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
      &lt;/ul&gt;
      &lt;p&gt;
        &lt;em&gt;
          Need something else?
          Your provider is most likely supported because TensorZero integrates with &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible&quot;&gt;any OpenAI-compatible API (e.g. Ollama)&lt;/a&gt;&lt;/b&gt;.
          &lt;/em&gt;
      &lt;/p&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;left&quot; valign=&quot;top&quot;&gt;
      &lt;p&gt;
        The TensorZero Gateway supports advanced features like:
      &lt;/p&gt;
      &lt;ul&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks&quot;&gt;Retries &amp; Fallbacks&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations&quot;&gt;Inference-Time Optimizations&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/prompt-templates-schemas&quot;&gt;Prompt Templates &amp; Schemas&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/tutorial#experimentation&quot;&gt;Experimentation (A/B Testing)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/configuration-reference&quot;&gt;Configuration-as-Code (GitOps)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/batch-inference&quot;&gt;Batch Inference&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/multimodal-inference&quot;&gt;Multimodal Inference (VLMs)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/inference-caching&quot;&gt;Inference Caching&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/metrics-feedback&quot;&gt;Metrics &amp; Feedback&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/episodes&quot;&gt;Multi-Step LLM Workflows (Episodes)&lt;/a&gt;&lt;/b&gt;&lt;/li&gt;
        &lt;li&gt;&lt;em&gt;&amp; a lot more...&lt;/em&gt;&lt;/li&gt;
      &lt;/ul&gt;
      &lt;p&gt;
        The TensorZero Gateway is written in Rust ü¶Ä with &lt;b&gt;performance&lt;/b&gt; in mind (&amp;lt;1ms p99 latency overhead @ 10k QPS).
        See &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/benchmarks&quot;&gt;Benchmarks&lt;/a&gt;&lt;/b&gt;.&lt;br&gt;
      &lt;/p&gt;
      &lt;p&gt;
        You can run inference using the &lt;b&gt;TensorZero client&lt;/b&gt; (recommended), the &lt;b&gt;OpenAI client&lt;/b&gt;, or the &lt;b&gt;HTTP API&lt;/b&gt;.
      &lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;br&gt;

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;Usage: Python &amp;mdash; TensorZero Client (Recommended)&lt;/b&gt;&lt;/summary&gt;

You can access any provider using the TensorZero Python client.

1. `pip install tensorzero`
2. Optional: Set up the TensorZero configuration.
3. Run inference:

```python
from tensorzero import TensorZeroGateway  # or AsyncTensorZeroGateway


with TensorZeroGateway.build_embedded(clickhouse_url=&quot;...&quot;, config_file=&quot;...&quot;) as client:
    response = client.inference(
        model_name=&quot;openai::gpt-4o-mini&quot;,
        # Try other providers easily: &quot;anthropic::claude-3-7-sonnet-20250219&quot;
        input={
            &quot;messages&quot;: [
                {
                    &quot;role&quot;: &quot;user&quot;,
                    &quot;content&quot;: &quot;Write a haiku about artificial intelligence.&quot;,
                }
            ]
        },
    )
```

See **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Usage: Python &amp;mdash; OpenAI Client&lt;/b&gt;&lt;/summary&gt;

You can access any provider using the OpenAI Python client with TensorZero.

1. `pip install tensorzero`
2. Optional: Set up the TensorZero configuration.
3. Run inference:

```python
from openai import OpenAI  # or AsyncOpenAI
from tensorzero import patch_openai_client

client = OpenAI()

patch_openai_client(
    client,
    clickhouse_url=&quot;http://chuser:chpassword@localhost:8123/tensorzero&quot;,
    config_file=&quot;config/tensorzero.toml&quot;,
    async_setup=False,
)

response = client.chat.completions.create(
    model=&quot;tensorzero::model_name::openai::gpt-4o-mini&quot;,
    # Try other providers easily: &quot;tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219&quot;
    messages=[
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: &quot;Write a haiku about artificial intelligence.&quot;,
        }
    ],
)
```

See **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Usage: JavaScript / TypeScript (Node) &amp;mdash; OpenAI Client&lt;/b&gt;&lt;/summary&gt;

You can access any provider using the OpenAI Node client with TensorZero.

1. Deploy `tensorzero/gateway` using Docker.
   **[Detailed instructions ‚Üí](https://www.tensorzero.com/docs/gateway/deployment)**
2. Set up the TensorZero configuration.
3. Run inference:

```ts
import OpenAI from &quot;openai&quot;;

const client = new OpenAI({
  baseURL: &quot;http://localhost:3000/openai/v1&quot;,
});

const response = await client.chat.completions.create({
  model: &quot;tensorzero::model_name::openai::gpt-4o-mini&quot;,
  // Try other providers easily: &quot;tensorzero::model_name::anthropic::claude-3-7-sonnet-20250219&quot;
  messages: [
    {
      role: &quot;user&quot;,
      content: &quot;Write a haiku about artificial intelligence.&quot;,
    },
  ],
});
```

See **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Usage: Other Languages &amp; Platforms &amp;mdash; HTTP API&lt;/b&gt;&lt;/summary&gt;

TensorZero supports virtually any programming language or platform via its HTTP API.

1. Deploy `tensorzero/gateway` using Docker.
   **[Detailed instructions ‚Üí](https://www.tensorzero.com/docs/gateway/deployment)**
2. Optional: Set up the TensorZero configuration.
3. Run inference:

```bash
curl -X POST &quot;http://localhost:3000/inference&quot; \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{
    &quot;model_name&quot;: &quot;openai::gpt-4o-mini&quot;,
    &quot;input&quot;: {
      &quot;messages&quot;: [
        {
          &quot;role&quot;: &quot;user&quot;,
          &quot;content&quot;: &quot;Write a haiku about artificial intelligence.&quot;
        }
      ]
    }
  }&#039;
```

See **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.

&lt;/details&gt;

&lt;br&gt;

### üìà LLM Optimization

&gt; **Send production metrics and human feedback to easily optimize your prompts, models, and inference strategies &amp;mdash; using the UI or programmatically.**

#### Model Optimization

Optimize closed-source and open-source models using supervised fine-tuning (SFT) and preference fine-tuning (DPO).

&lt;table&gt;
  &lt;tr&gt;&lt;/tr&gt; &lt;!-- flip highlight order --&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Supervised Fine-tuning &amp;mdash; UI&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Preference Fine-tuning (DPO) &amp;mdash; Jupyter Notebook&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/cf7acf66-732b-43b3-af2a-5eba1ce40f6f&quot;&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/a67a0634-04a7-42b0-b934-9130cb7cdf51&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

#### Inference-Time Optimization

Boost performance by dynamically updating your prompts with relevant examples, combining responses from multiple inferences, and more.

&lt;table&gt;
  &lt;tr&gt;&lt;/tr&gt; &lt;!-- flip highlight order --&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling&quot;&gt;Best-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#mixture-of-n-sampling&quot;&gt;Mixture-of-N Sampling&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/c0edfa4c-713c-4996-9964-50c0d26e6970&quot;&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/75b5bf05-4c1f-43c4-b158-d69d1b8d05be&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl&quot;&gt;Dynamic In-Context Learning (DICL)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#chain-of-thought-cot&quot;&gt;Chain-of-Thought (CoT)&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/d8489e92-ce93-46ac-9aab-289ce19bb67d&quot;&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/ea13d73c-76a4-4e0c-a35b-0c648f898311&quot; height=&quot;320&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

_More coming soon..._

&lt;br&gt;

#### Prompt Optimization

Optimize your prompts programmatically using research-driven optimization techniques.

&lt;table&gt;
  &lt;tr&gt;&lt;/tr&gt; &lt;!-- flip highlight order --&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#best-of-n-sampling&quot;&gt;MIPROv2&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;&lt;a href=&quot;https://github.com/tensorzero/tensorzero/tree/main/examples/gsm8k-custom-recipe-dspy&quot;&gt;DSPy Integration&lt;/a&gt;&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/d81a7c37-382f-4c46-840f-e6c2593301db&quot; alt=&quot;MIPROv2 diagram&quot;&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;
      TensorZero comes with several optimization recipes, but you can also easily create your own.
      This example shows how to optimize a TensorZero function using an arbitrary tool ‚Äî here, DSPy, a popular library for automated prompt engineering.
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

_More coming soon..._

&lt;br&gt;

### üîç LLM Observability

&gt; **Zoom in to debug individual API calls, or zoom out to monitor metrics across models and prompts over time &amp;mdash; all using the open-source TensorZero UI.**

&lt;table&gt;
  &lt;tr&gt;&lt;/tr&gt; &lt;!-- flip highlight order --&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Observability ¬ª Inference&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Observability ¬ª Function&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/2cc3cc9a-f33f-4e94-b8de-07522326f80a&quot;&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/00ae6605-8fa0-4efd-8238-ae8ea589860f&quot;&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;br&gt;

### üìä LLM Evaluations

&gt; **Compare prompts, models, and inference strategies using TensorZero Evaluations &amp;mdash; with support for heuristics and LLM judges.**

&lt;table&gt;
  &lt;tr&gt;&lt;/tr&gt; &lt;!-- flip highlight order --&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Evaluation ¬ª UI&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Evaluation ¬ª CLI&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699&quot;&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;left&quot; valign=&quot;middle&quot;&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100
exact_match: 0.83 ¬± 0.03
semantic_match: 0.98 ¬± 0.01
item_count: 7.15 ¬± 0.39&lt;/code&gt;&lt;/pre&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Demo

&gt; **Watch LLMs get better at data extraction in real-time with TensorZero!**
&gt;
&gt; **[Dynamic in-context learning (DICL)](https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl)** is a powerful inference-time optimization available out of the box with TensorZero.
&gt; It enhances LLM performance by automatically incorporating relevant historical examples into the prompt, without the need for model fine-tuning.

https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb

## LLM Engineering with TensorZero

&lt;br&gt;
&lt;p align=&quot;center&quot; &gt;
  &lt;a href=&quot;https://www.tensorzero.com/docs&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/e8bc699b-6378-4c2a-9cc1-6d189025e270&quot;&gt;
      &lt;img alt=&quot;TensorZero Flywheel&quot; src=&quot;https://github.com/user-attachments/assets/34a92c18-242e-4d76-a99c-861283de68a6&quot; width=720&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;

1. The **[TensorZero Gateway](https://www.tensorzero.com/docs/gateway/)** is a high-performance model gateway written in Rust ü¶Ä that provides a unified API interface for all major LLM providers, allowing for seamless cross-platform integration and fallbacks.
2. It handles structured schema-based inference with &amp;lt;1ms P99 latency overhead (see **[Benchmarks](https://www.tensorzero.com/docs/gateway/benchmarks)**) and built-in observability, experimentation, and **[inference-time optimizations](https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations)**.
3. It also collects downstream metrics and feedback associated with these inferences, with first-class support for multi-step LLM sy

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[eythaann/Seelen-UI]]></title>
            <link>https://github.com/eythaann/Seelen-UI</link>
            <guid>https://github.com/eythaann/Seelen-UI</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:49 GMT</pubDate>
            <description><![CDATA[The Fully Customizable Desktop Environment for Windows 10/11.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eythaann/Seelen-UI">eythaann/Seelen-UI</a></h1>
            <p>The Fully Customizable Desktop Environment for Windows 10/11.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,484</p>
            <p>Forks: 247</p>
            <p>Stars today: 107 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gfx-rs/wgpu]]></title>
            <link>https://github.com/gfx-rs/wgpu</link>
            <guid>https://github.com/gfx-rs/wgpu</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:48 GMT</pubDate>
            <description><![CDATA[A cross-platform, safe, pure-Rust graphics API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gfx-rs/wgpu">gfx-rs/wgpu</a></h1>
            <p>A cross-platform, safe, pure-Rust graphics API.</p>
            <p>Language: Rust</p>
            <p>Stars: 14,318</p>
            <p>Forks: 1,067</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre># wgpu
&lt;img align=&quot;right&quot; width=&quot;20%&quot; src=&quot;logo.png&quot;&gt;

[![Matrix Space](https://img.shields.io/static/v1?label=Space&amp;message=%23Wgpu&amp;color=blue&amp;logo=matrix)](https://matrix.to/#/#Wgpu:matrix.org)
[![Dev Matrix](https://img.shields.io/static/v1?label=devs&amp;message=%23wgpu&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu:matrix.org)
[![User Matrix](https://img.shields.io/static/v1?label=users&amp;message=%23wgpu-users&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu-users:matrix.org)
[![Build Status](https://img.shields.io/github/actions/workflow/status/gfx-rs/wgpu/ci.yml?branch=trunk&amp;logo=github&amp;label=CI)](https://github.com/gfx-rs/wgpu/actions)
[![codecov.io](https://img.shields.io/codecov/c/github/gfx-rs/wgpu?logo=codecov&amp;logoColor=fff&amp;label=codecov&amp;token=84qJTesmeS)](https://codecov.io/gh/gfx-rs/wgpu)

`wgpu` is a cross-platform, safe, pure-rust graphics API. It runs natively on Vulkan, Metal, D3D12, and OpenGL; and on top of WebGL2 and WebGPU on wasm.

The API is based on the [WebGPU standard][webgpu]. It serves as the core of the WebGPU integration in Firefox, Servo, and Deno.

[webgpu]: https://gpuweb.github.io/gpuweb/

## Quick Links

| Docs                  | Examples                  | Changelog               |
|:---------------------:|:-------------------------:|:-----------------------:|
| [v25][rel-docs]       | [v25][rel-examples]       | [v25][rel-change]       |
| [`trunk`][trunk-docs] | [`trunk`][trunk-examples] | [`trunk`][trunk-change] |

Contributors are welcome! See [CONTRIBUTING.md][contrib] for more information.

[rel-docs]: https://docs.rs/wgpu/
[rel-examples]: https://github.com/gfx-rs/wgpu/tree/v25/examples#readme
[rel-change]: https://github.com/gfx-rs/wgpu/releases
[trunk-docs]: https://wgpu.rs/doc/wgpu/
[trunk-examples]: https://github.com/gfx-rs/wgpu/tree/trunk/examples#readme
[trunk-change]: https://github.com/gfx-rs/wgpu/blob/trunk/CHANGELOG.md#unreleased
[contrib]: CONTRIBUTING.md

## Repo Overview

The repository hosts the following libraries:

- [![Crates.io](https://img.shields.io/crates/v/wgpu.svg?label=wgpu)](https://crates.io/crates/wgpu) [![docs.rs](https://docs.rs/wgpu/badge.svg)](https://docs.rs/wgpu/) - User facing Rust API.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-core.svg?label=wgpu-core)](https://crates.io/crates/wgpu-core) [![docs.rs](https://docs.rs/wgpu-core/badge.svg)](https://docs.rs/wgpu-core/) - Internal safe implementation.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-hal.svg?label=wgpu-hal)](https://crates.io/crates/wgpu-hal) [![docs.rs](https://docs.rs/wgpu-hal/badge.svg)](https://docs.rs/wgpu-hal/) - Internal unsafe GPU API abstraction layer.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-types.svg?label=wgpu-types)](https://crates.io/crates/wgpu-types) [![docs.rs](https://docs.rs/wgpu-types/badge.svg)](https://docs.rs/wgpu-types/) - Rust types shared between all crates.
- [![Crates.io](https://img.shields.io/crates/v/naga.svg?label=naga)](https://crates.io/crates/naga) [![docs.rs](https://docs.rs/naga/badge.svg)](https://docs.rs/naga/) - Stand-alone shader translation library.
- [![Crates.io](https://img.shields.io/crates/v/deno_webgpu.svg?label=deno_webgpu)](https://crates.io/crates/deno_webgpu) - WebGPU implementation for the Deno JavaScript/TypeScript runtime

The following binaries:

- [![Crates.io](https://img.shields.io/crates/v/naga-cli.svg?label=naga-cli)](https://crates.io/crates/naga-cli) - Tool for translating shaders between different languages using `naga`.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-info.svg?label=wgpu-info)](https://crates.io/crates/wgpu-info) - Tool for getting information on GPUs in the system.
- `cts_runner` - WebGPU Conformance Test Suite runner using `deno_webgpu`.
- `player` - standalone application for replaying the API traces.

For an overview of all the components in the gfx-rs ecosystem, see [the big picture](./docs/big-picture.png).

## Getting Started

### Play with our Examples

Go to &lt;https://wgpu.rs/examples/&gt; to play with our examples in your browser. Requires a browser supporting WebGPU for the WebGPU examples.

### Rust

Rust examples can be found at [examples](examples). You can run the examples natively with `cargo run --bin wgpu-examples &lt;example&gt;`.

If you are new to wgpu and graphics programming, we recommend starting with https://sotrh.github.io/learn-wgpu/.

To run the examples in a browser, run `cargo xtask run-wasm`.
Then open `http://localhost:8000` in your browser, and you can choose an example to run.
Naturally, in order to display any of the WebGPU based examples, you need to make sure your browser supports it.

### C/C++

To use wgpu in C/C++, you need [wgpu-native](https://github.com/gfx-rs/wgpu-native).

If you are looking for a wgpu C++ tutorial, look at the following:

- https://eliemichel.github.io/LearnWebGPU/

### Others

If you want to use wgpu in other languages, there are many bindings to wgpu-native from languages such as Python, D, Julia, Kotlin, and more. See [the list](https://github.com/gfx-rs/wgpu-native#bindings).

## Community

We have the Matrix space [![Matrix Space](https://img.shields.io/static/v1?label=Space&amp;message=%23Wgpu&amp;color=blue&amp;logo=matrix)](https://matrix.to/#/#Wgpu:matrix.org) with a few different rooms that form the wgpu community:

- [![Wgpu Matrix](https://img.shields.io/static/v1?label=wgpu-devs&amp;message=%23wgpu&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu:matrix.org) - discussion of the wgpu&#039;s development.
- [![Naga Matrix](https://img.shields.io/static/v1?label=naga-devs&amp;message=%23naga&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#naga:matrix.org) - discussion of the naga&#039;s development.
- [![User Matrix](https://img.shields.io/static/v1?label=wgpu-users&amp;message=%23wgpu-users&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu-users:matrix.org) - discussion of using the library and the surrounding ecosystem.
- [![Random Matrix](https://img.shields.io/static/v1?label=random&amp;message=%23wgpu-random&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu-random:matrix.org) - discussion of everything else.

## Wiki

We have a [wiki](https://github.com/gfx-rs/wgpu/wiki) that serves as a knowledge base.

## Extension Specifications

While the core of wgpu is based on the WebGPU standard, we also support extensions that allow for features that the standard does not have yet.
For high-level documentation on how to use these extensions, see the individual specifications:

üß™EXPERIMENTALüß™ APIs are subject to change and may allow undefined behavior if used incorrectly.

- üß™EXPERIMENTALüß™ [Ray Tracing](./docs/api-specs/ray_tracing.md).

## Supported Platforms

| API    | Windows            | Linux/Android      | macOS/iOS          | Web (wasm)         |
| ------ | ------------------ | ------------------ | ------------------ | ------------------ |
| Vulkan |         ‚úÖ         |         ‚úÖ         |         üåã         |                    |
| Metal  |                    |                    |         ‚úÖ         |                    |
| DX12   |         ‚úÖ         |                    |                    |                    |
| OpenGL |    üÜó (GL 3.3+)    |  üÜó (GL ES 3.0+)   |         üìê         |    üÜó (WebGL2)     |
| WebGPU |                    |                    |                    |         ‚úÖ         |

‚úÖ = First Class Support  
üÜó = Downlevel/Best Effort Support  
üìê = Requires the [ANGLE](#angle) translation layer (GL ES 3.0 only)  
üåã = Requires the [MoltenVK](https://vulkan.lunarg.com/sdk/home#mac) translation layer  
üõ†Ô∏è = Unsupported, though open to contributions

### Shader Support

wgpu supports shaders in [WGSL](https://gpuweb.github.io/gpuweb/wgsl/), SPIR-V, and GLSL.
Both [HLSL](https://github.com/Microsoft/DirectXShaderCompiler) and [GLSL](https://github.com/KhronosGroup/glslang)
have compilers to target SPIR-V. All of these shader languages can be used with any backend as we handle all of the conversions. Additionally, support for these shader inputs is not going away.

While WebGPU does not support any shading language other than WGSL, we will automatically convert your
non-WGSL shaders if you&#039;re running on WebGPU.

WGSL is always supported by default, but GLSL and SPIR-V need features enabled to compile in support.

Note that the WGSL specification is still under development,
so the [draft specification][wgsl spec] does not exactly describe what `wgpu` supports.
See [below](#tracking-the-webgpu-and-wgsl-draft-specifications) for details.

To enable SPIR-V shaders, enable the `spirv` feature of wgpu.
To enable GLSL shaders, enable the `glsl` feature of wgpu.

### Angle

[Angle](http://angleproject.org) is a translation layer from GLES to other backends developed by Google.
We support running our GLES3 backend over it in order to reach platforms DX11 support, which aren&#039;t accessible otherwise.
In order to run with Angle, the &quot;angle&quot; feature has to be enabled, and Angle libraries placed in a location visible to the application.
These binaries can be downloaded from [gfbuild-angle](https://github.com/DileSoft/gfbuild-angle) artifacts, [manual compilation](https://github.com/google/angle/blob/main/doc/DevSetup.md) may be required on Macs with Apple silicon.

On Windows, you generally need to copy them into the working directory, in the same directory as the executable, or somewhere in your path.
On Linux, you can point to them using `LD_LIBRARY_PATH` environment.

### MSRV policy

Due to complex dependants, we have two MSRV policies:

- `naga`, `wgpu-core`, `wgpu-hal`, and `wgpu-types`&#039;s MSRV is **1.76**.
- The rest of the workspace has an MSRV of **1.84**.

It is enforced on CI (in &quot;/.github/workflows/ci.yml&quot;) with the `CORE_MSRV` and `REPO_MSRV` variables.
This version can only be upgraded in breaking releases, though we release a breaking version every three months.

The `naga`, `wgpu-core`, `wgpu-hal`, and `wgpu-types` crates should never
require an MSRV ahead of Firefox&#039;s MSRV for nightly builds, as
determined by the value of `MINIMUM_RUST_VERSION` in
[`python/mozboot/mozboot/util.py`][util].

[util]: https://searchfox.org/mozilla-central/source/python/mozboot/mozboot/util.py

## Environment Variables

All testing and example infrastructure share the same set of environment variables that determine which Backend/GPU it will run on.

- `WGPU_ADAPTER_NAME` with a substring of the name of the adapter you want to use (ex. `1080` will match `NVIDIA GeForce 1080ti`).
- `WGPU_BACKEND` with a comma-separated list of the backends you want to use (`vulkan`, `metal`, `dx12`, or `gl`).
- `WGPU_POWER_PREF` with the power preference to choose when a specific adapter name isn&#039;t specified (`high`, `low` or `none`)
- `WGPU_DX12_COMPILER` with the DX12 shader compiler you wish to use (`dxc`, `static-dxc`, or `fxc`). Note that `dxc` requires `dxcompiler.dll` (min v1.8.2502) to be in the working directory, and `static-dxc` requires the `static-dxc` crate feature to be enabled. Otherwise, it will fall back to `fxc`.
- `WGPU_GLES_MINOR_VERSION` with the minor OpenGL ES 3 version number to request (`0`, `1`, `2` or `automatic`).
- `WGPU_ALLOW_UNDERLYING_NONCOMPLIANT_ADAPTER` with a boolean whether non-compliant drivers are enumerated (`0` for false, `1` for true).

When running the CTS, use the variables `DENO_WEBGPU_ADAPTER_NAME`, `DENO_WEBGPU_BACKEND`, `DENO_WEBGPU_POWER_PREFERENCE`.

## Testing

We have multiple methods of testing, each of which tests different qualities about wgpu. We automatically run our tests on CI. The current state of CI testing:

| Platform/Backend | Tests              | Notes                 |
| ---------------- | ------------------ | --------------------- |
| Windows/DX12     | :heavy_check_mark: | using WARP            |
| Windows/OpenGL   | :heavy_check_mark: | using llvmpipe        |
| MacOS/Metal      | :heavy_check_mark: | using hardware runner |
| Linux/Vulkan     | :heavy_check_mark: | using lavapipe        |
| Linux/OpenGL ES  | :heavy_check_mark: | using llvmpipe        |
| Chrome/WebGL     | :heavy_check_mark: | using swiftshader     |
| Chrome/WebGPU    | :x:                | not set up            |

### Core Test Infrastructure

We use a tool called [`cargo nextest`](https://github.com/nextest-rs/nextest) to run our tests.
To install it, run `cargo install cargo-nextest`.

To run the test suite:

```
cargo xtask test
```

To run the test suite on WebGL (currently incomplete):

```
cd wgpu
wasm-pack test --headless --chrome --no-default-features --features webgl --workspace
```

This will automatically run the tests using a packaged browser. Remove `--headless` to run the tests with whatever browser you wish at `http://localhost:8000`.

If you are a user and want a way to help contribute to wgpu, we always need more help writing test cases.

### WebGPU Conformance Test Suite

WebGPU includes a Conformance Test Suite to validate that implementations are
working correctly. We run cases from the CTS against wgpu using
[Deno](https://deno.com/). A [default list of enabled
tests](./cts_runner/test.lst) is automatically run on pull requests in CI.

To run the default set of CTS tests locally, run:

```
cargo xtask cts
```

You can also specify a test selector on the command line:

```
cargo xtask cts &#039;webgpu:api,operation,command_buffer,basic:*&#039;
```

Or supply your own test list in a file:

```
cargo xtask cts -f your_tests.lst
```

To find the full list of tests, go to the
[web version of the CTS](https://gpuweb.github.io/cts/standalone/?runnow=0&amp;worker=0&amp;debug=0&amp;q=webgpu:*).

The version of the CTS used by `cargo xtask cts` is specified in
[`cts_runner/revision.txt`](./cts_runner/revision.txt).

## Tracking the WebGPU and WGSL draft specifications

The `wgpu` crate is meant to be an idiomatic Rust translation of the [WebGPU API][webgpu spec].
That specification, along with its shading language, [WGSL][wgsl spec],
are both still in the &quot;Working Draft&quot; phase,
and while the general outlines are stable,
details change frequently.
Until the specification is stabilized, the `wgpu` crate and the version of WGSL it implements
will likely differ from what is specified,
as the implementation catches up.

Exactly which WGSL features `wgpu` supports depends on how you are using it:

- When running as native code, `wgpu` uses the [Naga][naga] crate
  to translate WGSL code into the shading language of your platform&#039;s native GPU API.
  Naga has [a milestone][naga wgsl milestone]
  for catching up to the WGSL specification,
  but in general, there is no up-to-date summary
  of the differences between Naga and the WGSL spec.

- When running in a web browser (by compilation to WebAssembly)
  without the `&quot;webgl&quot;` feature enabled,
  `wgpu` relies on the browser&#039;s own WebGPU implementation.
  WGSL shaders are simply passed through to the browser,
  so that determines which WGSL features you can use.

- When running in a web browser with `wgpu`&#039;s `&quot;webgl&quot;` feature enabled,
  `wgpu` uses Naga to translate WGSL programs into GLSL.
  This uses the same version of Naga as if you were running `wgpu` as native code.

[webgpu spec]: https://www.w3.org/TR/webgpu/
[wgsl spec]: https://gpuweb.github.io/gpuweb/wgsl/
[naga]: https://github.com/gfx-rs/naga/
[naga wgsl milestone]: https://github.com/gfx-rs/naga/milestone/4

## Coordinate Systems

wgpu uses the coordinate systems of D3D and Metal:

| Render                                              | Texture                                               |
| --------------------------------------------------- | ----------------------------------------------------- |
| ![render_coordinates](./docs/render_coordinates.png) | ![texture_coordinates](./docs/texture_coordinates.png) |
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[antinomyhq/forge]]></title>
            <link>https://github.com/antinomyhq/forge</link>
            <guid>https://github.com/antinomyhq/forge</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:47 GMT</pubDate>
            <description><![CDATA[AI enabled pair programmer for Claude, GPT, O Series, Grok, Deepseek, Gemini and 300+ models]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/antinomyhq/forge">antinomyhq/forge</a></h1>
            <p>AI enabled pair programmer for Claude, GPT, O Series, Grok, Deepseek, Gemini and 300+ models</p>
            <p>Language: Rust</p>
            <p>Stars: 2,739</p>
            <p>Forks: 890</p>
            <p>Stars today: 99 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;‚öíÔ∏è Forge: AI-Enhanced Terminal Development Environment&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;A comprehensive coding agent that integrates AI capabilities with your development environment&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;code&gt;npm install -g @antinomyhq/forge&lt;/code&gt;&lt;/p&gt;

[![CI Status](https://img.shields.io/github/actions/workflow/status/antinomyhq/forge/ci.yml?style=for-the-badge)](https://github.com/antinomyhq/forge/actions)
[![GitHub Release](https://img.shields.io/github/v/release/antinomyhq/forge?style=for-the-badge)](https://github.com/antinomyhq/forge/releases)
[![Discord](https://img.shields.io/discord/1044859667798568962?style=for-the-badge&amp;cacheSeconds=120&amp;logo=discord)](https://discord.gg/kRZBPpkgwq)
[![CLA assistant](https://cla-assistant.io/readme/badge/antinomyhq/forge?style=for-the-badge)](https://cla-assistant.io/antinomyhq/forge)

![Code-Forge Demo](https://assets.antinomy.ai/images/forge_demo_2x.gif)

---

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Table&amp;nbsp;of&amp;nbsp;Contents&lt;/strong&gt;&lt;/summary&gt;

- [Quickstart](#quickstart)
- [Usage Examples](#usage-examples)
- [Interactive Mode Examples](#interactive-mode-examples)
- [Why Forge?](#why-forge)
- [Command-Line Options](#command-line-options)
- [Advanced Configuration](#advanced-configuration)
  - [Provider Configuration](#provider-configuration)
  - [forge.yaml Configuration Options](#forgeyaml-configuration-options)
- [Documentation](#documentation)
- [Community](#community)
- [Support Us](#support-us)

&lt;/details&gt;

---

## Quickstart

Install globally:

```bash
npm install -g @antinomyhq/forge
```

Sign up at [Antinomy.ai](https://app.antinomy.ai/app/) to enable the Forge provider.

Then set up your Forge provider key:

```bash
# .env
FORGE_KEY=ForgeKey
```

Run Forge in interactive mode:

```bash
forge
```

That&#039;s it! Forge is now ready to assist you with your development tasks.

## Usage Examples

Forge can be used in different ways depending on your needs. Here are some common usage patterns:

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Code Understanding&lt;/strong&gt;&lt;/summary&gt;

```
&gt; Can you explain how the authentication system works in this codebase?
```

Forge will analyze your project&#039;s structure, identify authentication-related files, and provide a detailed explanation of the authentication flow, including the relationships between different components.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Implementing New Features&lt;/strong&gt;&lt;/summary&gt;

```
&gt; I need to add a dark mode toggle to our React application. How should I approach this?
```

Forge will suggest the best approach based on your current codebase, explain the steps needed, and even scaffold the necessary components and styles for you.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Debugging Assistance&lt;/strong&gt;&lt;/summary&gt;

```
&gt; I&#039;m getting this error: &quot;TypeError: Cannot read property &#039;map&#039; of undefined&quot;. What might be causing it?
```

Forge will analyze the error, suggest potential causes based on your code, and propose different solutions to fix the issue.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Code Reviews&lt;/strong&gt;&lt;/summary&gt;

```
&gt; Please review the code in src/components/UserProfile.js and suggest improvements
```

Forge will analyze the code, identify potential issues, and suggest improvements for readability, performance, security, and maintainability.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Learning New Technologies&lt;/strong&gt;&lt;/summary&gt;

```
&gt; I want to integrate GraphQL into this Express application. Can you explain how to get started?
```

Forge will provide a tailored tutorial on integrating GraphQL with Express, using your specific project structure as context.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Database Schema Design&lt;/strong&gt;&lt;/summary&gt;

```
&gt; I need to design a database schema for a blog with users, posts, comments, and categories
```

Forge will suggest an appropriate schema design, including tables/collections, relationships, indexes, and constraints based on your project&#039;s existing database technology.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Refactoring Legacy Code&lt;/strong&gt;&lt;/summary&gt;

```
&gt; Help me refactor this class-based component to use React Hooks
```

Forge can help modernize your codebase by walking you through refactoring steps and implementing them with your approval.
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Git Operations&lt;/strong&gt;&lt;/summary&gt;

```
&gt; I need to merge branch &#039;feature/user-profile&#039; into main but there are conflicts
```

Forge can guide you through resolving git conflicts, explaining the differences and suggesting the best way to reconcile them.
&lt;/details&gt;

## Why Forge?

Forge is designed for developers who want to enhance their workflow with AI assistance while maintaining full control over their development environment.

- **Zero configuration** - Just add your API key and you&#039;re ready to go
- **Seamless integration** - Works right in your terminal, where you already work
- **Multi-provider support** - Use OpenAI, Anthropic, or other LLM providers
- **Secure by design** - Your code stays on your machine
- **Open-source** - Transparent, extensible, and community-driven

Forge helps you code faster, solve complex problems, and learn new technologies without leaving your terminal.

## Command-Line Options

Here&#039;s a quick reference of Forge&#039;s command-line options:

| Option                          | Description                                                |
| ------------------------------- | ---------------------------------------------------------- |
| `-p, --prompt &lt;PROMPT&gt;`         | Direct prompt to process without entering interactive mode |
| `-c, --command &lt;COMMAND&gt;`       | Path to a file containing initial commands to execute      |
| `-w, --workflow &lt;WORKFLOW&gt;`     | Path to a file containing the workflow to execute          |
| `-e, --event &lt;EVENT&gt;`           | Dispatch an event to the workflow                          |
| `--conversation &lt;CONVERSATION&gt;` | Path to a file containing the conversation to execute      |
| `-r, --restricted`              | Enable restricted shell mode for enhanced security         |
| `--verbose`                     | Enable verbose output mode                                 |
| `-h, --help`                    | Print help information                                     |
| `-V, --version`                 | Print version                                              |

## Advanced Configuration

### Provider Configuration

Forge supports multiple AI providers. Below are setup instructions for each supported provider:

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Antinomy.ai (Recommended)&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
FORGE_KEY=ForgeKey
```

To use Antinomy&#039;s provider with Forge:
1. Visit [https://app.antinomy.ai/](https://app.antinomy.ai/)
2. Login with your existing credentials or create a new account
3. Once logged in, your account will automatically enable the Forge Provider

_No changes in `forge.yaml` required_

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;OpenRouter&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
OPENROUTER_API_KEY=&lt;your_openrouter_api_key&gt;
```

_No changes in `forge.yaml` required_

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
OPENAI_API_KEY=&lt;your_openai_api_key&gt;
```

```yaml
# forge.yaml
model: o3-mini-high
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
ANTHROPIC_API_KEY=&lt;your_anthropic_api_key&gt;
```

```yaml
# forge.yaml
model: claude-3.7-sonnet
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Google Vertex AI&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
PROJECT_ID=&lt;your_project_id&gt;
LOCATION=&lt;your_location&gt;
OPENAI_API_KEY=&lt;vertex_ai_key&gt;
OPENAI_URL=https://${LOCATION}-aiplatform.googleapis.com/v1beta1/projects/${PROJECT_ID}/locations/${LOCATION}/endpoints/openapi
```

```yaml
# forge.yaml
model: publishers/anthropic/models/claude-3-7-sonnet
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;OpenAI-Compatible Providers&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
OPENAI_API_KEY=&lt;your_provider_api_key&gt;
OPENAI_URL=&lt;your_provider_url&gt;
```

```yaml
# forge.yaml
model: &lt;provider-specific-model&gt;
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Groq&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
OPENAI_API_KEY=&lt;your_groq_api_key&gt;
OPENAI_URL=https://api.groq.com/openai/v1
```

```yaml
# forge.yaml
model: deepseek-r1-distill-llama-70b
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Amazon Bedrock&lt;/strong&gt;&lt;/summary&gt;

To use Amazon Bedrock models with Forge, you&#039;ll need to first set up the [Bedrock Access Gateway](https://github.com/aws-samples/bedrock-access-gateway):

1. **Set up Bedrock Access Gateway**:

   - Follow the deployment steps in the [Bedrock Access Gateway repo](https://github.com/aws-samples/bedrock-access-gateway)
   - Create your own API key in Secrets Manager
   - Deploy the CloudFormation stack
   - Note your API Base URL from the CloudFormation outputs

2. **Create these files in your project directory**:

   ```bash
   # .env
   OPENAI_API_KEY=&lt;your_bedrock_gateway_api_key&gt;
   OPENAI_URL=&lt;your_bedrock_gateway_base_url&gt;
   ```

   ```yaml
   # forge.yaml
   model: anthropic.claude-3-opus
   ```

   &lt;/details&gt;

### forge.yaml Configuration Options

The `forge.yaml` file supports several advanced configuration options that let you customize Forge&#039;s behavior.

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Custom Rules&lt;/strong&gt;&lt;/summary&gt;

Add your own guidelines that all agents should follow when generating responses.

```yaml
# forge.yaml
custom_rules: |
  1. Always add comprehensive error handling to any code you write.
  2. Include unit tests for all new functions.
  3. Follow our team&#039;s naming convention: camelCase for variables, PascalCase for classes.
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Commands&lt;/strong&gt;&lt;/summary&gt;

Define custom commands as shortcuts for repetitive prompts:

```yaml
# forge.yaml
commands:
  - name: &quot;refactor&quot;
    description: &quot;Refactor selected code&quot;
    prompt: &quot;Please refactor this code to improve readability and performance&quot;
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/summary&gt;

Specify the default AI model to use for all agents in the workflow.

```yaml
# forge.yaml
model: &quot;claude-3.7-sonnet&quot;
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Max Walker Depth&lt;/strong&gt;&lt;/summary&gt;

Control how deeply Forge traverses your project directory structure when gathering context.

```yaml
# forge.yaml
max_walker_depth: 3 # Limit directory traversal to 3 levels deep
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Temperature&lt;/strong&gt;&lt;/summary&gt;

Adjust the creativity and randomness in AI responses. Lower values (0.0-0.3) produce more focused, deterministic outputs, while higher values (0.7-2.0) generate more diverse and creative results.

```yaml
# forge.yaml
temperature: 0.7 # Balanced creativity and focus
```

&lt;/details&gt;

---

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt;&lt;/summary&gt;

The MCP feature allows AI agents to communicate with external tools and services. This implementation follows Anthropic&#039;s [Model Context Protocol](https://docs.anthropic.com/en/docs/claude-code/tutorials#set-up-model-context-protocol-mcp) design.

### MCP Configuration

Configure MCP servers using the CLI:

```bash
# List all MCP servers
forge mcp list

# Add a new server
forge mcp add

# Add a server using JSON format
forge mcp add-json

# Get server details
forge mcp get

# Remove a server
forge mcp remove
```

Or manually create a `.mcp.json` file with the following structure:

```json
{
  &quot;mcp_servers&quot;: {
    &quot;server_name&quot;: {
      &quot;command&quot;: &quot;command_to_execute&quot;,
      &quot;args&quot;: [&quot;arg1&quot;, &quot;arg2&quot;],
      &quot;env&quot;: {&quot;ENV_VAR&quot;: &quot;value&quot;}
    },
    &quot;another_server&quot;: {
      &quot;url&quot;: &quot;http://localhost:3000/events&quot;
    }
  }
}
```

MCP configurations are read from two locations (in order of precedence):

1. Local configuration (project-specific)
2. User configuration (user-specific)

### Example Use Cases

MCP can be used for various integrations:

- Web browser automation
- External API interactions
- Tool integration
- Custom service connections

### Usage in Multi-Agent Workflows

MCP tools can be used as part of multi-agent workflows, allowing specialized agents to interact with external systems as part of a collaborative problem-solving approach.

&lt;/details&gt;

---

## Documentation

For comprehensive documentation on all features and capabilities, please visit the [documentation site](https://github.com/antinomyhq/forge/tree/main/docs).

---

## Community

Join our vibrant Discord community to connect with other Forge users and contributors, get help with your projects, share ideas, and provide feedback!

[![Discord](https://img.shields.io/discord/1044859667798568962?style=for-the-badge&amp;cacheSeconds=120&amp;logo=discord)](https://discord.gg/kRZBPpkgwq)

---

## Support Us

Your support drives Forge&#039;s continued evolution! By starring our GitHub repository, you:

- Help others discover this powerful tool üîç
- Motivate our development team üí™
- Enable us to prioritize new features üõ†Ô∏è
- Strengthen our open-source community üå±
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[skyzh/mini-lsm]]></title>
            <link>https://github.com/skyzh/mini-lsm</link>
            <guid>https://github.com/skyzh/mini-lsm</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:46 GMT</pubDate>
            <description><![CDATA[A course of building an LSM-Tree storage engine (database) in a week.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/skyzh/mini-lsm">skyzh/mini-lsm</a></h1>
            <p>A course of building an LSM-Tree storage engine (database) in a week.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,450</p>
            <p>Forks: 509</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>![banner](./mini-lsm-book/src/mini-lsm-logo.png)

# LSM in a Week

[![CI (main)](https://github.com/skyzh/mini-lsm/actions/workflows/main.yml/badge.svg)](https://github.com/skyzh/mini-lsm/actions/workflows/main.yml)

Build a simple key-value storage engine in a week! And extend your LSM engine on the second + third week.

## [Book](https://skyzh.github.io/mini-lsm)

The Mini-LSM book is available at [https://skyzh.github.io/mini-lsm](https://skyzh.github.io/mini-lsm). You may follow this guide and implement the Mini-LSM storage engine. We have 3 weeks (parts) of the course, each of them consists of 7 days (chapters).

## Community

You may join skyzh&#039;s Discord server and study with the mini-lsm community.

[![Join skyzh&#039;s Discord Server](mini-lsm-book/src/discord-badge.svg)](https://skyzh.dev/join/discord)

**Add Your Solution**

If you finished at least one full week of this course, you can add your solution to the community solution list at [SOLUTIONS.md](./SOLUTIONS.md). You can submit a pull request and we might do a quick review of your code in return of your hard work.

## Development

**For Students**

You should modify code in `mini-lsm-starter` directory.

```
cargo x install-tools
cargo x copy-test --week 1 --day 1
cargo x scheck
cargo run --bin mini-lsm-cli
cargo run --bin compaction-simulator
```

**For Course Developers**

You should modify `mini-lsm` and `mini-lsm-mvcc`

```
cargo x install-tools
cargo x check
cargo x book
```

If you changed public API in the reference solution, you might also need to synchronize it to the starter crate.
To do this, use `cargo x sync`.

## Code Structure

* mini-lsm: the final solution code for &lt;= week 2
* mini-lsm-mvcc: the final solution code for week 3 MVCC
* mini-lsm-starter: the starter code
* mini-lsm-book: the course

We have another repo mini-lsm-solution-checkpoint at [https://github.com/skyzh/mini-lsm-solution-checkpoint](https://github.com/skyzh/mini-lsm-solution-checkpoint). In this repo, each commit corresponds to a chapter in the course. We will not update the solution checkpoint very often.

## Demo

You can run the reference solution by yourself to gain an overview of the system before you start.

```
cargo run --bin mini-lsm-cli-ref
cargo run --bin mini-lsm-cli-mvcc-ref
```

And we have a compaction simulator to experiment with your compaction algorithm implementation,

```
cargo run --bin compaction-simulator-ref
cargo run --bin compaction-simulator-mvcc-ref
```

## Course Structure

We have 3 weeks + 1 extra week (in progress) for this course.

* Week 1: Storage Format + Engine Skeleton
* Week 2: Compaction and Persistence
* Week 3: Multi-Version Concurrency Control
* The Extra Week / Rest of Your Life: Optimizations (unlikely to be available in 2025...)

![Course Roadmap](./mini-lsm-book/src/lsm-tutorial/00-full-overview.svg)

| Week + Chapter | Topic                                                       |
| -------------- | ----------------------------------------------------------- |
| 1.1            | Memtable                                                    |
| 1.2            | Merge Iterator                                              |
| 1.3            | Block                                                       |
| 1.4            | Sorted String Table (SST)                                   |
| 1.5            | Read Path                                                   |
| 1.6            | Write Path                                                  |
| 1.7            | SST Optimizations: Prefix Key Encoding + Bloom Filters      |
| 2.1            | Compaction Implementation                                   |
| 2.2            | Simple Compaction Strategy (Traditional Leveled Compaction) |
| 2.3            | Tiered Compaction Strategy (RocksDB Universal Compaction)   |
| 2.4            | Leveled Compaction Strategy (RocksDB Leveled Compaction)    |
| 2.5            | Manifest                                                    |
| 2.6            | Write-Ahead Log (WAL)                                       |
| 2.7            | Batch Write and Checksums                                   |
| 3.1            | Timestamp Key Encoding                                      |
| 3.2            | Snapshot Read - Memtables and Timestamps                    |
| 3.3            | Snapshot Read - Transaction API                             |
| 3.4            | Watermark and Garbage Collection                            |
| 3.5            | Transactions and Optimistic Concurrency Control             |
| 3.6            | Serializable Snapshot Isolation                             |
| 3.7            | Compaction Filters                                          |

## Related Projects

mini-lsm inspired several projects used in production.

* [SlateDB](https://slatedb.io/docs/architecture/) is an LSM engine over the object storage system.
* [Tonbo](https://tonbo.io/about) stores parquet files directly on the object storage and organizes them in an LSM tree structure.

## License

The Mini-LSM starter code and solution are under [Apache 2.0 license](LICENSE). The author reserves the full copyright of the course materials (markdown files and figures).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[juspay/hyperswitch]]></title>
            <link>https://github.com/juspay/hyperswitch</link>
            <guid>https://github.com/juspay/hyperswitch</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:45 GMT</pubDate>
            <description><![CDATA[An open source payments switch written in Rust to make payments fast, reliable and affordable]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/juspay/hyperswitch">juspay/hyperswitch</a></h1>
            <p>An open source payments switch written in Rust to make payments fast, reliable and affordable</p>
            <p>Language: Rust</p>
            <p>Stars: 20,230</p>
            <p>Forks: 3,243</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/imgs/hyperswitch-logo-dark.svg#gh-dark-mode-only&quot; alt=&quot;Hyperswitch-Logo&quot; width=&quot;40%&quot; /&gt;
  &lt;img src=&quot;./docs/imgs/hyperswitch-logo-light.svg#gh-light-mode-only&quot; alt=&quot;Hyperswitch-Logo&quot; width=&quot;40%&quot; /&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Open-Source Payments Orchestration&lt;/h1&gt;

&lt;div align=&quot;center&quot; &gt;
Single API to access the payments ecosystem and its features
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/actions?query=workflow%3ACI+branch%3Amain&quot;&gt;
    &lt;img src=&quot;https://github.com/juspay/hyperswitch/workflows/CI-push/badge.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/juspay/hyperswitch&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Made_in-Rust-orange&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Uncomment when we reach &gt;50% coverage --&gt;
  &lt;!-- &lt;a href=&quot;https://codecov.io/github/juspay/hyperswitch&quot; &gt;
    &lt;img src=&quot;https://codecov.io/github/juspay/hyperswitch/graph/badge.svg&quot;/&gt;
  &lt;/a&gt; --&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.linkedin.com/company/hyperswitch/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-hyperswitch-blue?logo=linkedin&amp;labelColor=grey&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://x.com/hyperswitchio&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-%40hyperswitchio-white?logo=x&amp;labelColor=grey&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://join.slack.com/t/hyperswitch-io/shared_invite/zt-2jqxmpsbm-WXUENx022HjNEy~Ark7Orw&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/chat-on_slack-blue?logo=slack&amp;labelColor=grey&amp;color=%233f0e40&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/juspay/hyperswitch&quot;&gt;
    &lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;hr&gt;

## Table of Contents

1. [Introduction](#introduction)
2. [Try Hyperswitch](#try-hyperswitch)
3. [Architectural Overview](#architectural-overview)
4. [Community &amp; Contributions](#community-and-contributions)
5. [Feature requests &amp; Bugs](#feature-requests)  
6. [Our Vision](#our-vision)  
7. [Versioning](#versioning)  
8. [Copyright and License](#copyright-and-license)

&lt;a href=&quot;#introduction&quot;&gt;
  &lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;/a&gt;
Juspay, founded in 2012, is a global leader in payment orchestration and checkout solutions, trusted by 400+ leading enterprises and brands worldwide. Hyperswitch is Juspay&#039;s new generation of composable, commercial open-source payments platform for merchant and brands. It is an enterprise-grade, transparent and modular payments platform designed to provide digital businesses access to the best payments infrastructure.

Here are the key components of Hyperswitch that deliver the whole solution:

* [Hyperswitch Backend](https://github.com/juspay/hyperswitch): Hyperswitch backend enables seamless payment processing with comprehensive support for various payment flows - authorization, authentication, void and capture workflows along with robust management of post-payment processes like refunds and chargeback handling. Additionally, Hyperswitch supports non-payment use cases by enabling connections with external FRM or authentication providers as part of the payment flow. The backend optimizes payment routing with customizable workflows, including success rate-based routing, rule-based routing, volume distribution, fallback handling, and intelligent retry mechanisms for failed payments based on specific error codes.

* [SDK (Frontend)](https://github.com/juspay/hyperswitch-web): The SDK, available for web, [Android, and iOS](https://github.com/juspay/hyperswitch-client-core), unifies the payment experience across various methods such as cards, wallets, BNPL, bank transfers, and more, while supporting the diverse payment flows of underlying PSPs. When paired with the locker, it surfaces the user&#039;s saved payment methods.    

* [Control Center](https://github.com/juspay/hyperswitch-control-center): The Control Center enables users to manage the entire payments stack without any coding. It allows the creation of workflows for routing, payment retries, and defining conditions to invoke 3DS, fraud risk management (FRM), and surcharge modules. The Control Center provides access to transaction, refund, and chargeback operations across all integrated PSPs, transaction-level logs for initial debugging, and detailed analytics and insights into payment performance.

Read more at [Hyperswitch docs](https://docs.hyperswitch.io/).

&lt;a href=&quot;#try-hyperswitch&quot;&gt;
  &lt;h2 id=&quot;try-hyperswitch&quot;&gt;Try Hyperswitch&lt;/h2&gt;
&lt;/a&gt;

### 1. Local Setup

#### One-Click Setup (Recommended)

You can run Hyperswitch on your system with a single command using our one-click setup script:

```shell
git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch
cd hyperswitch
scripts/setup.sh
```

The above script will:
- Check for prerequisites (Docker Compose/Podman)
- Set up necessary configurations
- Let you select a deployment profile:
  - **Standard**: Recommended - App server + Control Center + Web SDK.
  - **Full**: Standard + Monitoring + Scheduler.
  - **Standalone App Server**: Core services only (Hyperswitch server, PostgreSQL, Redis)
- Start the selected services
- Check service health
- Provide access information

The next step is to [configure a connector][configure-a-connector] with the Hyperswitch Control Center and [try a payment][try-a-payment].

Check out the [local setup guide][local-setup-guide] for more details on setting up the entire stack or component wise.


### 2. Deployment on cloud

The fastest and easiest way to try Hyperswitch on AWS is via our CDK scripts

1. Click on the following button for a quick standalone deployment on AWS, suitable for prototyping.
   No code or setup is required in your system and the deployment is covered within the AWS free-tier setup.

   &lt;a href=&quot;https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=HyperswitchBootstarp&amp;templateURL=https://hyperswitch-synth.s3.eu-central-1.amazonaws.com/hs-starter-config.yaml&quot;&gt;&lt;img src=&quot;https://github.com/juspay/hyperswitch/blob/main/docs/imgs/aws_button.png?raw=true&quot; height=&quot;35&quot;&gt;&lt;/a&gt;

2. Sign-in to your AWS console.

3. Follow the instructions provided on the console to successfully deploy Hyperswitch. This takes 30-45mins and gives the following output 

| Service| Host|
|----------------------------------------------|----------------------------------------------|
| App server running on                        | `http://hyperswitch-&lt;host-id.region&gt;.elb.amazonaws.com` |
| HyperloaderJS Hosted at                      | `http://&lt;cloudfront.host-id&gt;/0.103.1/v0/HyperLoader.js` |
| Control center server running on             | `http://hyperswitch-control-center-&lt;host-id.region&gt;.elb.amazonaws.com`, Login with Email: `test@gmail.com` |
| Hyperswitch Demo Store running on            | `http://hyperswitch-sdk-demo-&lt;host-id.region&gt;.elb.amazonaws.com` |
| Logs server running on                       | `http://hyperswitch-logs-&lt;host-id.region&gt;.elb.amazonaws.com`, Login with username: `admin`, password: `admin` |

We support deployment on GCP and Azure via Helm charts which takes 30-45mins. You can read more at [Hyperswitch docs](https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm). 

### 3. Hosted Sandbox

You can experience the product by signing up for our [hosted sandbox](https://app.hyperswitch.io/). The signup process accepts any email ID and provides access to the entire Control Center. You can set up connectors, define workflows for routing and retries, and even try payments from the dashboard.

&lt;a href=&quot;#architectural-overview&quot;&gt;
  &lt;h2 id=&quot;architectural-overview&quot;&gt;Architectural Overview&lt;/h2&gt;
&lt;/a&gt;
&lt;img src=&quot;./docs/imgs/features.png&quot; /&gt;
&lt;img src=&quot;./docs/imgs/non-functional-features.png&quot; /&gt;

&lt;img src=&quot;./docs/imgs/hyperswitch-architecture-v1.png&quot; /&gt;

[docs-link-for-enterprise]: https://docs.hyperswitch.io/hyperswitch-cloud/quickstart
[docs-link-for-developers]: https://docs.hyperswitch.io/hyperswitch-open-source/overview
[contributing-guidelines]: docs/CONTRIBUTING.md
[dashboard-link]: https://app.hyperswitch.io/
[website-link]: https://hyperswitch.io/
[learning-resources]: https://docs.hyperswitch.io/learn-more/payment-flows
[local-setup-guide]: /docs/try_local_system.md
[docker-compose-scheduler-monitoring]: /docs/try_local_system.md#running-additional-services
[configure-a-connector]: https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/using-hyperswitch-control-center#add-a-payment-processor
[try-a-payment]: https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/test-a-payment

&lt;a href=&quot;community-and-contributions&quot;&gt;
  &lt;h2 id=&quot;community-and-contributions&quot;&gt;Community &amp; Contributions&lt;/h2&gt;
&lt;/a&gt;

If you have any questions, feel free to drop them in our [Slack community](https://join.slack.com/t/hyperswitch-io/shared_invite/zt-2jqxmpsbm-WXUENx022HjNEy~Ark7Orw).

We welcome contributors from around the world to help build Hyperswitch. To get started, please read our [contribution guidelines](contributing-guidelines).

&lt;a href=&quot;feature-requests&quot;&gt;
  &lt;h2 id=&quot;feature-requests&quot;&gt;Feature requests &amp; Bugs&lt;/h2&gt;
&lt;/a&gt;

For new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our [GitHub Discussions](https://github.com/juspay/hyperswitch/discussions)

For reporting a bug, please read the issue guidelines and search for [existing and closed issues]. If your problem or idea is not addressed yet, please [open a new issue].

[existing and closed issues]: https://github.com/juspay/hyperswitch/issues
[open a new issue]: https://github.com/juspay/hyperswitch/issues/new/choose

&lt;a href=&quot;our-vision&quot;&gt;
  &lt;h2 id=&quot;our-vision&quot;&gt;Our Vision&lt;/h2&gt;
&lt;/a&gt;

&gt; Linux for Payments

Payments are evolving rapidly worldwide, with hundreds of processors, fraud detection systems, authentication modules, and new payment methods and flows emerging. Businesses building or managing their own payment stacks often face similar challenges, struggle with comparable issues, and find it hard to innovate at the desired pace.

Hyperswitch serves as a well-architected designed reference platform, built on best-in-class design principles, empowering businesses to own and customize their payment stack. It provides a reusable core payments stack that can be tailored to specific requirements while relying on the Hyperswitch team for enhancements, support, and continuous innovation.

### Our Values

1. Embrace Payments Diversity: It will drive innovation in the ecosystem in
   multiple ways.
2. Make it Open Source: Increases trust; Improves the quality and reusability of
   software.
3. Be community driven: It enables participatory design and development.
4. Build it like Systems Software: This sets a high bar for Reliability,
   Security and Performance SLAs.
5. Maximise Value Creation: For developers, customers &amp; partners.

This project is being created and maintained by [Juspay](https://juspay.io)

&lt;a href=&quot;#versioning&quot;&gt;
  &lt;h2 id=&quot;versioning&quot;&gt;Versioning&lt;/h2&gt;
&lt;/a&gt;

Check the [CHANGELOG.md](./CHANGELOG.md) file for details.

&lt;a href=&quot;#copyright-and-license&quot;&gt;
  &lt;h2 id=&quot;copyright-and-license&quot;&gt;Copyright and License&lt;/h2&gt;
&lt;/a&gt;

This product is licensed under the [Apache 2.0 License](LICENSE).


&lt;a href=&quot;team-behind-hyperswitch&quot;&gt;
  &lt;h2 id=&quot;team-behind-hyperswitch&quot;&gt;Team behind Hyperswitch&lt;/h2&gt;
&lt;/a&gt;

The core team of 150+ engineers building Hyperswitch. Keep up the great work! ü•Ç

&lt;a href=&quot;https://github.com/juspay/hyperswitch/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=juspay/hyperswitch&quot; alt=&quot;Contributors&quot;/&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[openobserve/openobserve]]></title>
            <link>https://github.com/openobserve/openobserve</link>
            <guid>https://github.com/openobserve/openobserve</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:44 GMT</pubDate>
            <description><![CDATA[üöÄ 10x easier, üöÄ 140x lower storage cost, üöÄ high performance, üöÄ petabyte scale - Elasticsearch/Splunk/Datadog alternative for üöÄ (logs, metrics, traces, RUM, Error tracking, Session replay).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openobserve/openobserve">openobserve/openobserve</a></h1>
            <p>üöÄ 10x easier, üöÄ 140x lower storage cost, üöÄ high performance, üöÄ petabyte scale - Elasticsearch/Splunk/Datadog alternative for üöÄ (logs, metrics, traces, RUM, Error tracking, Session replay).</p>
            <p>Language: Rust</p>
            <p>Stars: 15,450</p>
            <p>Forks: 587</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://openobserve.ai&quot;&gt;&lt;img src=&quot;https://openobserve.ai/img/logo/logo_horizontal.svg&quot; alt=&quot;OpenObserve&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;em&gt;üöÄ 10x easier, üöÄ 140x lower storage cost, üöÄ high performance, üöÄ petabyte scale - Elasticsearch/Splunk/Datadog alternative for üöÄ (logs, metrics, traces).&lt;/em&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/openobserve/openobserve&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/last-commit/openobserve/openobserve&quot; alt=&quot;Last Commit&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/openobserve/openobserve/stargazers&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/openobserve/openobserve&quot; alt=&quot;GitHub Stars&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/openobserve/openobserve/issues&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/issues/openobserve/openobserve&quot; alt=&quot;GitHub Issues&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/openobserve/openobserve/graphs/contributors&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/contributors/openobserve/openobserve&quot; alt=&quot;Contributors&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/openobserve/openobserve/releases&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/openobserve/openobserve&quot; alt=&quot;GitHub Release&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;

OpenObserve (O2 for short) is a cloud-native observability platform built specifically for logs, metrics, traces, analytics, RUM (Real User Monitoring - Performance, Errors, Session Replay) designed to work at petabyte scale.

It is straightforward and easy to operate, in contrast to Elasticsearch, which requires understanding and tuning numerous settings. Get OpenObserve up and running in under 2 minutes.

OpenObserve serves as a seamless replacement for Elasticsearch for users who ingest data using APIs and perform searches. OpenObserve comes with its own user interface, eliminating the need for separate installation.

You can reduce your log storage costs by ~140x compared to Elasticsearch by using OpenObserve. Below, we present the results from pushing logs from our production Kubernetes cluster to both Elasticsearch and OpenObserve using Fluent Bit.

![OpenObserve Vs Elasticsearch](./screenshots/zo_vs_es.png)

## üé• Introduction Video

[![OpenObserve Introduction](./screenshots/o2_intro.webp)](https://www.youtube.com/watch?v=4VwuC1tpRP4)

## üåü Features:

- **Logs, Metrics, Traces**: Comprehensive support for various data types.
- **OpenTelemetry Support**: Full compatibility with OTLP for logs, metrics, and traces.
- **Real User Monitoring (RUM)**: Includes performance tracking, error logging, and session replay.
- **Dashboards, Reports, Alerts**: Features over 18 different chart types for comprehensive data visualization for on-the-fly analysis and reporting along with alerting.
- **Pipelines**: Enrich, redact, reduce, normalize data on the fly. Stream processing for logs to metrics and more.
- **Advanced Embedded GUI**: Intuitive and user-friendly interface.
- **SQL and PromQL Support**: Query logs and traces with SQL, and metrics with SQL and PromQL.
- **Single Binary or HA Installation**: Install using a single binary for small deployments or in HA mode for large deployments.
- **Versatile Storage Options**: Supports local disk, S3, MinIO, GCS, Azure Blob Storage.
- **High Availability and Clustering**: Ensures reliable and scalable performance.
- **Dynamic Schema**: Adapts to your data structure seamlessly.
- **Built-in Authentication**: Secure and ready to use.
- **Ease of Operation**: Designed for simplicity and efficiency.
- **Seamless Upgrades**: Hassle-free updates.
- **Multilingual UI**: Supports 11 languages, including English, Spanish, German, French, Chinese, and more.

For a full list of features, check the [documentation](https://openobserve.ai/docs/#project-status-features-and-roadmap).

## ‚ö°Ô∏è Quick start

### üê≥ Docker:
```bash
docker run -d \
      --name openobserve \
      -v $PWD/data:/data \
      -p 5080:5080 \
      -e ZO_ROOT_USER_EMAIL=&quot;root@example.com&quot; \
      -e ZO_ROOT_USER_PASSWORD=&quot;Complexpass#123&quot; \
      public.ecr.aws/zinclabs/openobserve:latest
```

### üêô Docker Compose:
```yaml
services:
  openobserve:
    image: public.ecr.aws/zinclabs/openobserve:latest
    restart: unless-stopped
    environment:
      ZO_ROOT_USER_EMAIL: &quot;root@example.com&quot;
      ZO_ROOT_USER_PASSWORD: &quot;Complexpass#123&quot;
    ports:
      - &quot;5080:5080&quot;
    volumes:
      - data:/data
volumes:
  data:
```

For other ways to quickly install OpenObserve or use OpenObserve cloud, check [quickstart documentation](https://openobserve.ai/docs/quickstart).

For installing OpenObserve in HA mode, check [HA deployment documentation](https://openobserve.ai/docs/ha_deployment/).

&lt;!-- ## Enterprise Vs Open source Vs Cloud edition

OpenObserve is available in three different editions:


| Feature | Open Source (Self hosted) | Enterprise (Self hosted) | Cloud |
| --- | --- | --- | --- | 
| Logs | ‚úÖ | ‚úÖ | ‚úÖ |
| Metrics | ‚úÖ | ‚úÖ | ‚úÖ |
| Traces | ‚úÖ | ‚úÖ | ‚úÖ |
| RUM | ‚úÖ | ‚úÖ | ‚úÖ |
| Alerts | ‚úÖ | ‚úÖ | ‚úÖ |
| Dashboards | ‚úÖ | ‚úÖ | ‚úÖ |
| Reports | ‚úÖ | ‚úÖ | ‚úÖ |
| VRL functions | ‚úÖ | ‚úÖ | ‚úÖ |
| Pipelines | ‚úÖ | ‚úÖ | ‚úÖ |
| High Availability | ‚úÖ | ‚úÖ | ‚úÖ |
| Multitenancy (Organizations) | ‚úÖ | ‚úÖ | ‚úÖ |
| Dynamic schema and schema evolution | ‚úÖ | ‚úÖ | ‚úÖ |
| Advanced multilingual GUI | ‚úÖ | ‚úÖ | ‚úÖ |
| Single Sign On | ‚ùå | ‚úÖ | ‚úÖ |
| Role Based Access Control (RBAC) | ‚ùå | ‚úÖ | ‚úÖ |
| Federated search / Super cluster | ‚ùå | ‚úÖ | ‚ùå |
| Query management | ‚ùå | ‚úÖ | ‚ùå |
| Workload management (QoS) | ‚ùå | ‚úÖ | ‚ùå |
| Audit trail | ‚ùå | ‚úÖ | ‚ùå |
| Ability to influence roadmap | ‚ùå | ‚úÖ | ‚úÖ on enterprise plan |
| License | AGPL | Enterprise | Cloud |
| Support | Community | Enterprise | Cloud |
| Cost | Free | If self hosted, free for up to 200 GB/Day data ingested &lt;br&gt; Paid thereafter  | Free 200 GB/Month data ingested &lt;br&gt; Paid thereafter | --&gt;


## üì∑ Screenshots

### Home

![Home](./screenshots/zo_home.png)

### Logs

![Logs](./screenshots/logs.png)

### Traces (OpenTelemetry)

Trace details page
![Traces using OpenTelemetry](./screenshots/traces.png)

Golden metrics based on traces
![Traces golden metrics](./screenshots/traces-overall.png)

### Visualizations and Dashboards

![Dashboard](./screenshots/dashboard.png)
![Dashboard](./screenshots/dashboard2.png)
![Create panel](./screenshots/create-panel.png)
![Map](./screenshots/map.png)

### Front end monitoring

Performance analytics
![Performance](./screenshots/performance.png)

Session replay
![Session replay](./screenshots/session-replay.png)

Error tracking
![Error tracking](./screenshots/error-tracking.png)


### Alerts

![Alerts](./screenshots/alerts.png)


### Streams

![Streams](./screenshots/streams.png)

### Ingestion

![Ingestion](./screenshots/ingestion1.png)

### Pipeline

Pipeline
![Pipeline](./screenshots/pipeline.png)

Function
![Function](./screenshots/function.png)


### IAM

SSO (Single Sign On)
![SSO](./screenshots/sso.png)

RBAC (Role Based Access Control)
![RBAC](./screenshots/iam_rbac.png)


### SBOM

Software Bill of Materials for OpenObserve

#### Rust

SBOM can be found [here](./openobserve.cdx.xml). You can analyze it using [dependency track](https://dependencytrack.org/).

In order to generate the SBOM, you can use the following commands:

Install cargo-cyclonedx:

````bash
cargo install cargo-cyclonedx
````

Generate the SBOM:
```bash
cargo-cyclonedx cyclonedx
```

#### JavaScript

SBOM can be found [here](./web/sbom.json ). You can analyze it using [dependency track](https://dependencytrack.org/).

In order to generate the SBOM, you can use the following commands:

Install cyclonedx-npm:

````bash
npm install --global @cyclonedx/cyclonedx-npm
````

Generate the SBOM:
```bash
cd web
cyclonedx-npm &gt; sbom.json         
```


## ‚öñÔ∏è License

OpenObserve is licensed under the AGPL-3.0 license. For more details, see the [LICENSE](https://github.com/openobserve/openobserve/blob/main/LICENSE).

## üåç Community

### üîó Join OpenObserve community on Slack

[![Slack](./screenshots/slack.png)](https://short.openobserve.ai/community)

Easiest way to get support is to join the [Slack channel](https://short.openobserve.ai/community).

### üì± Join OpenObserve community on WeChat

&lt;img src=&quot;./screenshots/wechat_qr.jpg&quot; width=&quot;300&quot;&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[YaLTeR/niri]]></title>
            <link>https://github.com/YaLTeR/niri</link>
            <guid>https://github.com/YaLTeR/niri</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:43 GMT</pubDate>
            <description><![CDATA[A scrollable-tiling Wayland compositor.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/YaLTeR/niri">YaLTeR/niri</a></h1>
            <p>A scrollable-tiling Wayland compositor.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,984</p>
            <p>Forks: 263</p>
            <p>Stars today: 134 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;niri&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;A scrollable-tiling Wayland compositor.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://matrix.to/#/#niri:matrix.org&quot;&gt;&lt;img alt=&quot;Matrix&quot; src=&quot;https://img.shields.io/badge/matrix-%23niri-blue?logo=matrix&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;GitHub License&quot; src=&quot;https://img.shields.io/github/license/YaLTeR/niri&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/releases&quot;&gt;&lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/YaLTeR/niri?logo=github&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/wiki/Getting-Started&quot;&gt;Getting Started&lt;/a&gt; | &lt;a href=&quot;https://github.com/YaLTeR/niri/wiki/Configuration:-Introduction&quot;&gt;Configuration&lt;/a&gt; | &lt;a href=&quot;https://github.com/YaLTeR/niri/discussions/325&quot;&gt;Setup&amp;nbsp;Showcase&lt;/a&gt;
&lt;/p&gt;

![niri with a few windows open](https://github.com/user-attachments/assets/535e6530-2f44-4b84-a883-1240a3eee6e9)

## About

Windows are arranged in columns on an infinite strip going to the right.
Opening a new window never causes existing windows to resize.

Every monitor has its own separate window strip.
Windows can never &quot;overflow&quot; onto an adjacent monitor.

Workspaces are dynamic and arranged vertically.
Every monitor has an independent set of workspaces, and there&#039;s always one empty workspace present all the way down.

The workspace arrangement is preserved across disconnecting and connecting monitors where it makes sense.
When a monitor disconnects, its workspaces will move to another monitor, but upon reconnection they will move back to the original monitor.

## Features

- Built from the ground up for scrollable tiling
- [Dynamic workspaces](https://github.com/YaLTeR/niri/wiki/Workspaces) like in GNOME
- An [Overview](https://github.com/user-attachments/assets/379a5d1f-acdb-4c11-b36c-e85fd91f0995) that zooms out workspaces and windows
- Built-in screenshot UI
- Monitor and window screencasting through xdg-desktop-portal-gnome
    - You can [block out](https://github.com/YaLTeR/niri/wiki/Configuration:-Window-Rules#block-out-from) sensitive windows from screencasts
    - [Dynamic cast target](https://github.com/YaLTeR/niri/wiki/Screencasting#dynamic-screencast-target) that can change what it shows on the go
- [Touchpad](https://github.com/YaLTeR/niri/assets/1794388/946a910e-9bec-4cd1-a923-4a9421707515) and [mouse](https://github.com/YaLTeR/niri/assets/1794388/8464e65d-4bf2-44fa-8c8e-5883355bd000) gestures
- Group windows into [tabs](https://github.com/YaLTeR/niri/wiki/Tabs)
- Configurable layout: gaps, borders, struts, window sizes
- [Gradient borders](https://github.com/YaLTeR/niri/wiki/Configuration:-Layout#gradients) with Oklab and Oklch support
- [Animations](https://github.com/YaLTeR/niri/assets/1794388/ce178da2-af9e-4c51-876f-8709c241d95e) with support for [custom shaders](https://github.com/YaLTeR/niri/assets/1794388/27a238d6-0a22-4692-b794-30dc7a626fad)
- Live-reloading config

## Video Demo

https://github.com/YaLTeR/niri/assets/1794388/bce834b0-f205-434e-a027-b373495f9729

## Status

Niri is stable for day-to-day use and does most things expected of a Wayland compositor.
Many people are daily-driving niri, and are happy to help in our [Matrix channel].

Give it a try!
Follow the instructions on the [Getting Started](https://github.com/YaLTeR/niri/wiki/Getting-Started) wiki page.
Have your [waybar]s and [fuzzel]s ready: niri is not a complete desktop environment.

Here are some points you may have questions about:

- **Multi-monitor**: yes, a core part of the design from the very start. Mixed DPI works.
- **Fractional scaling**: yes, plus all niri UI stays pixel-perfect.
- **NVIDIA**: seems to work fine.
- **Floating windows**: yes, starting from niri 25.01.
- **Input devices**: niri supports tablets, touchpads, and touchscreens.
You can map the tablet to a specific monitor, or use [OpenTabletDriver].
We have touchpad gestures, but no touchscreen gestures yet.
- **Wlr protocols**: yes, we have most of the important ones like layer-shell, gamma-control, screencopy.
You can check on [wayland.app](https://wayland.app) at the bottom of each protocol&#039;s page.
- **Performance**: while I run niri on beefy machines, I try to stay conscious of performance.
I&#039;ve seen someone use it fine on an Eee¬†PC¬†900 from¬†2008, of all things.
- **Xwayland**: no built-in support, but xwayland-satellite is [easy to set up](https://github.com/YaLTeR/niri/wiki/Xwayland#using-xwayland-satellite) and works very well.
    - Steam and games, including Proton: work perfectly through xwayland-satellite.
    - JetBrains IDEs, Ghidra: work well through xwayland-satellite.
    - Discord and other Electron apps: work well through xwayland-satellite.
    - Chromium and VSCode: work perfectly natively on Wayland with the right flags.
    - X11 apps that want to position windows or bars at specific screen coordinates: won&#039;t work well; you can run them in a nested compositor like [labwc](https://github.com/YaLTeR/niri/wiki/Xwayland#using-the-labwc-wayland-compositor) or [rootful Xwayland](https://github.com/YaLTeR/niri/wiki/Xwayland#directly-running-xwayland-in-rootful-mode).
    - Display scaling (integer or fractional) keeps X11 apps crisp, but you need the latest xwayland-satellite.
    For games, you can run them in [gamescope] at native resolution, even with display scaling.

## Inspiration

Niri is heavily inspired by [PaperWM] which implements scrollable tiling on top of GNOME Shell.

One of the reasons that prompted me to try writing my own compositor is being able to properly separate the monitors.
Being a GNOME Shell extension, PaperWM has to work against Shell&#039;s global window coordinate space to prevent windows from overflowing.

## Tile Scrollably Elsewhere

Here are some other projects which implement a similar workflow:

- [PaperWM]: scrollable tiling on top of GNOME Shell.
- [karousel]: scrollable tiling on top of KDE.
- [scroll](https://github.com/dawsers/scroll) and [papersway]: scrollable tiling on top of sway/i3.
- [hyprscrolling] and [hyprslidr]: scrollable tiling on top of Hyprland.
- [PaperWM.spoon]: scrollable tiling on top of macOS.

## Media

[niri: Making a Wayland compositor in Rust](https://youtu.be/Kmz8ODolnDg?list=PLRdS-n5seLRqrmWDQY4KDqtRMfIwU0U3T)

My talk from the 2024 Moscow RustCon about niri, and how I do randomized property testing and profiling, and measure input latency.
The talk is in Russian, but I prepared full English subtitles that you can find in YouTube&#039;s subtitle language selector.

## Contact

We have a Matrix chat, feel free to join and ask a question: https://matrix.to/#/#niri:matrix.org

[PaperWM]: https://github.com/paperwm/PaperWM
[waybar]: https://github.com/Alexays/Waybar
[fuzzel]: https://codeberg.org/dnkl/fuzzel
[karousel]: https://github.com/peterfajdiga/karousel
[papersway]: https://spwhitton.name/tech/code/papersway/
[hyprscrolling]: https://github.com/hyprwm/hyprland-plugins/tree/main/hyprscrolling
[hyprslidr]: https://gitlab.com/magus/hyprslidr
[PaperWM.spoon]: https://github.com/mogenson/PaperWM.spoon
[Matrix channel]: https://matrix.to/#/#niri:matrix.org
[OpenTabletDriver]: https://opentabletdriver.net/
[gamescope]: https://github.com/ValveSoftware/gamescope
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lancedb/lancedb]]></title>
            <link>https://github.com/lancedb/lancedb</link>
            <guid>https://github.com/lancedb/lancedb</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:42 GMT</pubDate>
            <description><![CDATA[Developer-friendly, embedded retrieval engine for multimodal AI. Search More; Manage Less.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lancedb/lancedb">lancedb/lancedb</a></h1>
            <p>Developer-friendly, embedded retrieval engine for multimodal AI. Search More; Manage Less.</p>
            <p>Language: Rust</p>
            <p>Stars: 6,590</p>
            <p>Forks: 487</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://cloud.lancedb.com&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/92dad0a2-2a37-4ce1-b783-0d1b4f30a00c&quot; alt=&quot;LanceDB Cloud Public Beta&quot; width=&quot;100%&quot; style=&quot;max-width: 100%;&quot;&gt;
&lt;/a&gt;
&lt;div align=&quot;center&quot;&gt;

[![LanceDB](docs/src/assets/hero-header.png)](https://lancedb.com)
[![Website](https://img.shields.io/badge/-Website-100000?style=for-the-badge&amp;labelColor=645cfb&amp;color=645cfb)](https://lancedb.com/)
[![Blog](https://img.shields.io/badge/Blog-100000?style=for-the-badge&amp;labelColor=645cfb&amp;color=645cfb)](https://blog.lancedb.com/)
[![Discord](https://img.shields.io/badge/-Discord-100000?style=for-the-badge&amp;logo=discord&amp;logoColor=white&amp;labelColor=645cfb&amp;color=645cfb)](https://discord.gg/zMM32dvNtd)
[![Twitter](https://img.shields.io/badge/-Twitter-100000?style=for-the-badge&amp;logo=x&amp;logoColor=white&amp;labelColor=645cfb&amp;color=645cfb)](https://twitter.com/lancedb)
[![LinkedIn](https://img.shields.io/badge/-LinkedIn-100000?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&amp;labelColor=645cfb&amp;color=645cfb)](https://www.linkedin.com/company/lancedb/)


&lt;img src=&quot;docs/src/assets/lancedb.png&quot; alt=&quot;LanceDB&quot; width=&quot;50%&quot;&gt;

# **The Multimodal AI Lakehouse**

[**How to Install** ](#how-to-install) ‚ú¶ [**Detailed Documentation**](https://lancedb.github.io/lancedb/) ‚ú¶ [**Tutorials and Recipes**](https://github.com/lancedb/vectordb-recipes/tree/main) ‚ú¶  [**Contributors**](#contributors) 

**The ultimate multimodal data platform for AI/ML applications.** 

LanceDB is designed for fast, scalable, and production-ready vector search. It is built on top of the Lance columnar format. You can store, index, and search over petabytes of multimodal data and vectors with ease. 
LanceDB is a central location where developers can build, train and analyze their AI workloads.

&lt;/div&gt;

&lt;br&gt;

## **Demo: Multimodal Search by Keyword, Vector or with SQL**
&lt;img max-width=&quot;750px&quot; alt=&quot;LanceDB Multimodal Search&quot; src=&quot;https://github.com/lancedb/lancedb/assets/917119/09c5afc5-7816-4687-bae4-f2ca194426ec&quot;&gt;

## **Star LanceDB to get updates!**

&lt;details&gt;
&lt;summary&gt;‚≠ê Click here ‚≠ê  to see how fast we&#039;re growing!&lt;/summary&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=lancedb/lancedb&amp;theme=dark&amp;type=Date&quot;&gt;
  &lt;img width=&quot;100%&quot; src=&quot;https://api.star-history.com/svg?repos=lancedb/lancedb&amp;theme=dark&amp;type=Date&quot;&gt;
&lt;/picture&gt;
&lt;/details&gt;

## **Key Features**:

- **Fast Vector Search**: Search billions of vectors in milliseconds with state-of-the-art indexing.
- **Comprehensive Search**: Support for vector similarity search, full-text search and SQL.
- **Multimodal Support**: Store, query and filter vectors, metadata and multimodal data (text, images, videos, point clouds, and more).
- **Advanced Features**: Zero-copy, automatic versioning, manage versions of your data without needing extra infrastructure. GPU support in building vector index.

### **Products**:
- **Open Source &amp; Local**: 100% open source, runs locally or in your cloud. No vendor lock-in.
- **Cloud and Enterprise**: Production-scale vector search with no servers to manage. Complete data sovereignty and security.

### **Ecosystem**:
- **Columnar Storage**: Built on the Lance columnar format for efficient storage and analytics.
- **Seamless Integration**: Python, Node.js, Rust, and REST APIs for easy integration. Native Python and Javascript/Typescript support.
- **Rich Ecosystem**: Integrations with [**LangChain** ü¶úÔ∏èüîó](https://python.langchain.com/docs/integrations/vectorstores/lancedb/), [**LlamaIndex** ü¶ô](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/LanceDBIndexDemo.html), Apache-Arrow, Pandas, Polars, DuckDB and more on the way.

## **How to Install**:

Follow the [Quickstart](https://lancedb.github.io/lancedb/basic/) doc to set up LanceDB locally. 

**API &amp; SDK:** We also support Python, Typescript and Rust SDKs

| Interface | Documentation |
|-----------|---------------|
| Python SDK | https://lancedb.github.io/lancedb/python/python/ |
| Typescript SDK | https://lancedb.github.io/lancedb/js/globals/ |
| Rust SDK | https://docs.rs/lancedb/latest/lancedb/index.html |
| REST API | https://docs.lancedb.com/api-reference/introduction |

## **Join Us and Contribute**

We welcome contributions from everyone! Whether you&#039;re a developer, researcher, or just someone who wants to help out. 

If you have any suggestions or feature requests, please feel free to open an issue on GitHub or discuss it on our [**Discord**](https://discord.gg/G5DcmnZWKB) server.

[**Check out the GitHub Issues**](https://github.com/lancedb/lancedb/issues) if you would like to work on the features that are planned for the future. If you have any suggestions or feature requests, please feel free to open an issue on GitHub. 

## **Contributors**

&lt;a href=&quot;https://github.com/lancedb/lancedb/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=lancedb/lancedb&quot; /&gt;
&lt;/a&gt;


## **Stay in Touch With Us**
&lt;div align=&quot;center&quot;&gt;

&lt;/br&gt;

[![Website](https://img.shields.io/badge/-Website-100000?style=for-the-badge&amp;labelColor=645cfb&amp;color=645cfb)](https://lancedb.com/)
[![Blog](https://img.shields.io/badge/Blog-100000?style=for-the-badge&amp;labelColor=645cfb&amp;color=645cfb)](https://blog.lancedb.com/)
[![Discord](https://img.shields.io/badge/-Discord-100000?style=for-the-badge&amp;logo=discord&amp;logoColor=white&amp;labelColor=645cfb&amp;color=645cfb)](https://discord.gg/zMM32dvNtd)
[![Twitter](https://img.shields.io/badge/-Twitter-100000?style=for-the-badge&amp;logo=x&amp;logoColor=white&amp;labelColor=645cfb&amp;color=645cfb)](https://twitter.com/lancedb)
[![LinkedIn](https://img.shields.io/badge/-LinkedIn-100000?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&amp;labelColor=645cfb&amp;color=645cfb)](https://www.linkedin.com/company/lancedb/)

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[typst/typst]]></title>
            <link>https://github.com/typst/typst</link>
            <guid>https://github.com/typst/typst</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:41 GMT</pubDate>
            <description><![CDATA[A new markup-based typesetting system that is powerful and easy to learn.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/typst/typst">typst/typst</a></h1>
            <p>A new markup-based typesetting system that is powerful and easy to learn.</p>
            <p>Language: Rust</p>
            <p>Stars: 41,798</p>
            <p>Forks: 1,122</p>
            <p>Stars today: 59 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Typst&quot; src=&quot;https://user-images.githubusercontent.com/17899797/226108480-722b770e-6313-40d7-84f2-26bebb55a281.png&quot;&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://typst.app/docs/&quot;&gt;
    &lt;img alt=&quot;Documentation&quot; src=&quot;https://img.shields.io/website?down_message=offline&amp;label=docs&amp;up_color=007aff&amp;up_message=online&amp;url=https%3A%2F%2Ftypst.app%2Fdocs&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://typst.app/&quot;&gt;
    &lt;img alt=&quot;Typst App&quot; src=&quot;https://img.shields.io/website?down_message=offline&amp;label=typst.app&amp;up_color=239dad&amp;up_message=online&amp;url=https%3A%2F%2Ftypst.app&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/2uDybryKPe&quot;&gt;
    &lt;img alt=&quot;Discord Server&quot; src=&quot;https://img.shields.io/discord/1054443721975922748?color=5865F2&amp;label=discord&amp;labelColor=555&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/typst/typst/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;Apache-2 License&quot; src=&quot;https://img.shields.io/badge/license-Apache%202-brightgreen&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://typst.app/jobs/&quot;&gt;
    &lt;img alt=&quot;Jobs at Typst&quot; src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ftypst.app%2Fassets%2Fdata%2Fshields.json&amp;query=%24.jobs.text&amp;label=jobs&amp;color=%23A561FF&amp;cacheSeconds=1800&quot;
  &gt;&lt;/a&gt;
&lt;/p&gt;

Typst is a new markup-based typesetting system that is designed to be as powerful
as LaTeX while being much easier to learn and use. Typst has:

- Built-in markup for the most common formatting tasks
- Flexible functions for everything else
- A tightly integrated scripting system
- Math typesetting, bibliography management, and more
- Fast compile times thanks to incremental compilation
- Friendly error messages in case something goes wrong

This repository contains the Typst compiler and its CLI, which is everything you
need to compile Typst documents locally. For the best writing experience,
consider signing up to our [collaborative online editor][app] for free.

## Example
A [gentle introduction][tutorial] to Typst is available in our documentation.
However, if you want to see the power of Typst encapsulated in one image, here
it is:
&lt;p align=&quot;center&quot;&gt;
 &lt;img alt=&quot;Example&quot; width=&quot;900&quot; src=&quot;https://user-images.githubusercontent.com/17899797/228031796-ced0e452-fcee-4ae9-92da-b9287764ff25.png&quot;&gt;
&lt;/p&gt;


Let&#039;s dissect what&#039;s going on:

- We use _set rules_ to configure element properties like the size of pages or
  the numbering of headings. By setting the page height to `auto`, it scales to
  fit the content. Set rules accommodate the most common configurations. If you
  need full control, you can also use [show rules][show] to completely redefine
  the appearance of an element.

- We insert a heading with the `= Heading` syntax. One equals sign creates a top
  level heading, two create a subheading and so on. Typst has more lightweight
  markup like this, see the [syntax] reference for a full list.

- [Mathematical equations][math] are enclosed in dollar signs. By adding extra
  spaces around the contents of an equation, we can put it into a separate block.
  Multi-letter identifiers are interpreted as Typst definitions and functions
  unless put into quotes. This way, we don&#039;t need backslashes for things like
  `floor` and `sqrt`. And `phi.alt` applies the `alt` modifier to the `phi` to
  select a particular symbol variant.

- Now, we get to some [scripting]. To input code into a Typst document, we can
  write a hash followed by an expression. We define two variables and a
  recursive function to compute the n-th fibonacci number. Then, we display the
  results in a center-aligned table. The table function takes its cells
  row-by-row. Therefore, we first pass the formulas `$F_1$` to `$F_8$` and then
  the computed fibonacci numbers. We apply the spreading operator (`..`) to both
  because they are arrays and we want to pass the arrays&#039; items as individual
  arguments.

&lt;details&gt;
  &lt;summary&gt;Text version of the code example.&lt;/summary&gt;

  ```typst
  #set page(width: 10cm, height: auto)
  #set heading(numbering: &quot;1.&quot;)

  = Fibonacci sequence
  The Fibonacci sequence is defined through the
  recurrence relation $F_n = F_(n-1) + F_(n-2)$.
  It can also be expressed in _closed form:_

  $ F_n = round(1 / sqrt(5) phi.alt^n), quad
    phi.alt = (1 + sqrt(5)) / 2 $

  #let count = 8
  #let nums = range(1, count + 1)
  #let fib(n) = (
    if n &lt;= 2 { 1 }
    else { fib(n - 1) + fib(n - 2) }
  )

  The first #count numbers of the sequence are:

  #align(center, table(
    columns: count,
    ..nums.map(n =&gt; $F_#n$),
    ..nums.map(n =&gt; str(fib(n))),
  ))
  ```
&lt;/details&gt;

## Installation
Typst&#039;s CLI is available from different sources:

- You can get sources and pre-built binaries for the latest release of Typst
  from the [releases page][releases]. Download the archive for your platform and
  place it in a directory that is in your `PATH`. To stay up to date with future
  releases, you can simply run `typst update`.

- You can install Typst through different package managers. Note that the
  versions in the package managers might lag behind the latest release.
  - Linux:
      - View [Typst on Repology][repology]
      - View [Typst&#039;s Snap][snap]
  - macOS: `brew install typst`
  - Windows: `winget install --id Typst.Typst`

- If you have a [Rust][rust] toolchain installed, you can install
  - the latest released Typst version with
    `cargo install --locked typst-cli`
  - a development version with
    `cargo install --git https://github.com/typst/typst --locked typst-cli`

- Nix users can
  - use the `typst` package with `nix-shell -p typst`
  - build and run a development version with
    `nix run github:typst/typst -- --version`.

- Docker users can run a prebuilt image with
  `docker run ghcr.io/typst/typst:latest --help`.

## Usage
Once you have installed Typst, you can use it like this:
```sh
# Creates `file.pdf` in working directory.
typst compile file.typ

# Creates PDF file at the desired path.
typst compile path/to/source.typ path/to/output.pdf
```

You can also watch source files and automatically recompile on changes. This is
faster than compiling from scratch each time because Typst has incremental
compilation.
```sh
# Watches source files and recompiles on changes.
typst watch file.typ
```

Typst further allows you to add custom font paths for your project and list all
of the fonts it discovered:
```sh
# Adds additional directories to search for fonts.
typst compile --font-path path/to/fonts file.typ

# Lists all of the discovered fonts in the system and the given directory.
typst fonts --font-path path/to/fonts

# Or via environment variable (Linux syntax).
TYPST_FONT_PATHS=path/to/fonts typst fonts
```

For other CLI subcommands and options, see below:
```sh
# Prints available subcommands and options.
typst help

# Prints detailed usage of a subcommand.
typst help watch
```

If you prefer an integrated IDE-like experience with autocompletion and instant
preview, you can also check out [Typst&#039;s free web app][app].

## Community
The main places where the community gathers are our [Forum][forum] and our
[Discord server][discord]. The Forum is a great place to ask questions, help
others, and share cool things you created with Typst. The Discord server is more
suitable for quicker questions, discussions about contributing, or just to chat.
We&#039;d be happy to see you there!

[Typst Universe][universe] is where the community shares templates and packages.
If you want to share your own creations, you can submit them to our
[package repository][packages].

If you had a bad experience in our community, please [reach out to us][contact].

## Contributing
We love to see contributions from the community. If you experience bugs, feel
free to open an issue. If you would like to implement a new feature or bug fix,
please follow the steps outlined in the [contribution guide][contributing].

To build Typst yourself, first ensure that you have the
[latest stable Rust][rust] installed. Then, clone this repository and build the
CLI with the following commands:

```sh
git clone https://github.com/typst/typst
cd typst
cargo build --release
```

The optimized binary will be stored in `target/release/`.

Another good way to contribute is by [sharing packages][packages] with the
community.

## Pronunciation and Spelling
IPA: /ta…™pst/. &quot;Ty&quot; like in **Ty**pesetting and &quot;pst&quot; like in Hi**pst**er. When
writing about Typst, capitalize its name as a proper noun, with a capital &quot;T&quot;.

## Design Principles
All of Typst has been designed with three key goals in mind: Power,
simplicity, and performance. We think it&#039;s time for a system that matches the
power of LaTeX, is easy to learn and use, all while being fast enough to realize
instant preview. To achieve these goals, we follow three core design principles:

- **Simplicity through Consistency:**
  If you know how to do one thing in Typst, you should be able to transfer that
  knowledge to other things. If there are multiple ways to do the same thing,
  one of them should be at a different level of abstraction than the other. E.g.
  it&#039;s okay that `= Introduction` and `#heading[Introduction]` do the same thing
  because the former is just syntax sugar for the latter.

- **Power through Composability:**
  There are two ways to make something flexible: Have a knob for everything or
  have a few knobs that you can combine in many ways. Typst is designed with the
  second way in mind. We provide systems that you can compose in ways we&#039;ve
  never even thought of. TeX is also in the second category, but it&#039;s a bit
  low-level and therefore people use LaTeX instead. But there, we don&#039;t really
  have that much composability. Instead, there&#039;s a package for everything
  (`\usepackage{knob}`).

- **Performance through Incrementality:**
  All Typst language features must accommodate for incremental compilation.
  Luckily we have [`comemo`], a system for incremental compilation which does
  most of the hard work in the background.

[docs]: https://typst.app/docs/
[app]: https://typst.app/
[discord]: https://discord.gg/2uDybryKPe
[forum]: https://forum.typst.app/
[universe]: https://typst.app/universe/
[tutorial]: https://typst.app/docs/tutorial/
[show]: https://typst.app/docs/reference/styling/#show-rules
[math]: https://typst.app/docs/reference/math/
[syntax]: https://typst.app/docs/reference/syntax/
[scripting]: https://typst.app/docs/reference/scripting/
[rust]: https://rustup.rs/
[releases]: https://github.com/typst/typst/releases/
[repology]: https://repology.org/project/typst/versions
[contact]: https://typst.app/contact
[architecture]: https://github.com/typst/typst/blob/main/docs/dev/architecture.md
[contributing]: https://github.com/typst/typst/blob/main/CONTRIBUTING.md
[packages]: https://github.com/typst/packages/
[`comemo`]: https://github.com/typst/comemo/
[snap]: https://snapcraft.io/typst
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[modrinth/code]]></title>
            <link>https://github.com/modrinth/code</link>
            <guid>https://github.com/modrinth/code</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:40 GMT</pubDate>
            <description><![CDATA[The Modrinth monorepo containing all code which powers Modrinth!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/modrinth/code">modrinth/code</a></h1>
            <p>The Modrinth monorepo containing all code which powers Modrinth!</p>
            <p>Language: Rust</p>
            <p>Stars: 1,429</p>
            <p>Forks: 281</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># ![Modrinth Monorepo Cover](/.github/assets/monorepo_cover.png)

![Issues](https://img.shields.io/github/issues-raw/Modrinth/code?color=c78aff&amp;label=issues&amp;style=for-the-badge)
![Pull Requests](https://img.shields.io/github/issues-pr-raw/Modrinth/code?color=c78aff&amp;label=PRs&amp;style=for-the-badge)
![Contributors](https://img.shields.io/github/contributors/Modrinth/code?color=c78aff&amp;label=contributors&amp;style=for-the-badge)
![Lines](https://img.shields.io/endpoint?url=https://ghloc.vercel.app/api/modrinth/code/badge?style=flat&amp;logoColor=white&amp;color=c78aff&amp;style=for-the-badge)
![Commit Activity](https://img.shields.io/github/commit-activity/m/Modrinth/code?color=c78aff&amp;label=commits&amp;style=for-the-badge)
![Last Commit](https://img.shields.io/github/last-commit/Modrinth/code?color=c78aff&amp;label=last%20commit&amp;style=for-the-badge)

## Modrinth Monorepo

Welcome to the Modrinth Monorepo, the primary codebase for the Modrinth web interface and app. It contains ![Lines](https://img.shields.io/endpoint?url=https://ghloc.vercel.app/api/modrinth/olympus/badge?logoColor=white&amp;color=black&amp;label=) lines of code and has ![Contributors](https://img.shields.io/github/contributors/Modrinth/code?color=black&amp;label=) contributors!

If you&#039;re not a developer and you&#039;ve stumbled upon this repository, you can access the web interface on the [Modrinth website](https://modrinth.com) and download the latest release of the app [here](https://modrinth.com/app).

## Development

This repository contains two primary packages. For detailed development information, please refer to their respective READMEs:

- [Web Interface](apps/frontend/README.md)
- [Desktop App](apps/app/README.md)

## Contributing

We welcome contributions! Before submitting any contributions, please read our [contributing guidelines](https://docs.modrinth.com/contributing/getting-started/).

If you plan to fork this repository for your own purposes, please review our [copying guidelines](COPYING.md).

## Security

If you discover a security vulnerability within our codebase, please follow our [responsible disclosure guidelines](https://modrinth.com/legal/security).

## Support

If you need help with the Modrinth web interface or app, please visit our [support page](https://support.modrinth.com). For general inquiries, you can also join our [Discord server](https://discord.modrinth.com).

## License

All packages in this repository are licensed under their respective licenses. Refer to the LICENSE file in each package for more information.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[LGFae/swww]]></title>
            <link>https://github.com/LGFae/swww</link>
            <guid>https://github.com/LGFae/swww</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:39 GMT</pubDate>
            <description><![CDATA[A Solution to your Wayland Wallpaper Woes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/LGFae/swww">LGFae/swww</a></h1>
            <p>A Solution to your Wayland Wallpaper Woes</p>
            <p>Language: Rust</p>
            <p>Stars: 3,010</p>
            <p>Forks: 87</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># A Solution to your Wayland Wallpaper Woes
### Efficient animated wallpaper daemon for wayland, controlled at runtime

![animated gif demonstration](https://i.imgur.com/Leuh6wm.gif)
![image transition demonstration](../demos/assets/grow.gif)

## Dependencies

 - a compositor that implements the wlr-layer-shell (typically wlroots based compositors)
 - [lz4](https://github.com/lz4/lz4) (for compressing frames when animating)

**Note that this means `swww` will not run on Gnome, because it does not implement the `wlr-layer-shell` protocol**.

## Build

&lt;a href=&quot;https://repology.org/project/swww/versions&quot;&gt;
    &lt;img src=&quot;https://repology.org/badge/vertical-allrepos/swww.svg&quot; alt=&quot;Packaging status&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

### Dependencies:

 - wayland-client and wayland-protocol `.xml` files installed in your system (`pkg-config` must be able to find it)
 - Up to date stable rustc compiler and cargo (specifically, MSRV is 1.82.0)

To build, clone this repository and run:
```
cargo build --release
```
Then, put **both binaries** `target/release/swww` and
`target/release/swww-daemon` in your  path. Optionally, autocompletion scripts
for bash, zsh, fish and elvish are offered in the `completions` directory.

#### Man pages:

In order to generate the man pages, **you must have `scdoc` installed**. Run

```
./doc/gen.sh
```

The man pages will be in `doc/generated`. To install them, you must move them to
to the appropriate location in your system. You should be able to figure out
where that is by running `manpath`.

### Nix

NixOS users can directly use this repository to get the latest swww for their system.

Add in your `flake.nix`:

```nix
  inputs.swww.url = &quot;github:LGFae/swww&quot;;
```

Pass inputs to your modules using `specialArgs` and
Then in `configuration.nix`:

```nix
  environment.systemPackages = [
    inputs.swww.packages.${pkgs.system}.swww
  ];
```

## Features

 - Display animated gifs on your desktop
 - Display any image in the formats:
   * jpeg
   * png
   * gif
   * pnm
   * tga
   * tiff
   * webp
   * bmp
   * farbfeld
 - Clear the screen with an arbitrary rrggbb color
 - Smooth transition effect when you switch images
 - Do all of that without having to shutdown and reinitialize the daemon

## Why

There are two main reasons that compelled me to make this: the first is that
[`oguri`](https://github.com/vilhalmer/oguri) is unmaintained and archived,
despite there being serious problems with excess of memory use while displaying
certain gifs (see [this](https://github.com/vilhalmer/oguri/issues/38), for
example). The best alternative I&#039;ve found for `oguri` was
[`mpvpaper`](https://github.com/GhostNaN/mpvpaper), but if felt overkill for my
purposes.

Comparing to `oguri`, `swww` uses less cpu power to animate once it has cached
all the frames in the animation. It should also be **significantly** more
memory efficient.

The second is that, to my knowledge, there is no wallpaper daemon for wayland
that allows you to change the wallpaper at runtime. That is, in order to, for
example, cycle through the images of a directory, you&#039;d have to kill the daemon
and restart it. Not only does it make simple shell scripts a pain to write, it
makes switching from one image to the next to happen very abruptly.

## Usage

Start by initializing the daemon:
```
swww-daemon
```
Then, in a different terminal, simply pass the image you want to display:
```
swww img &lt;path/to/img&gt;

# You can also specify outputs:
swww img -o &lt;outputs&gt; &lt;path/to/img&gt;

# Control how smoothly the transition will happen, as well as its frame rate.
# --transition-step: smaller values = smoother. Default is 2 if --transition-type is `simple`, and 90 if it is not.
# --transition-fps: Default = 30.
swww img &lt;path/to/img&gt; --transition-step &lt;1 to 255&gt; --transition-fps &lt;1 to 255&gt;

# There are also many different transition effects:
swww img &lt;path/to/img&gt; --transition-type center

# Note you may also control the above by setting up the SWWW_TRANSITION_FPS,
# SWWW_TRANSITION_STEP, and SWWW_TRANSITION environment variables.

# To see all options, run
swww img --help
```
If you would like to know the valid values for *\&lt;outputs\&gt;*, you can query the
daemon. This will also tell you what the current image being displayed is, as
well as the dimensions detected for the outputs. If you need more detailed
information, I would recommend using
[`wlr-randr`](https://sr.ht/~emersion/wlr-randr/).
```
swww query
```
Finally, to stop the daemon, kill it:
```
swww kill
```
For a more complete description, run `swww --help` or `swww &lt;subcommand&gt;
--help`.

Finally, to get a feel for what you can do with some shell scripting, check out
the [example_scripts](/example_scripts/) folder. It can help you get started.

## Transitions

#### Example wipe transition:

&gt; wipe transition with angle set to 30 deg

![top transition demonstration](../demos/assets/wipe.gif)

The `left`, `right`, `top` and `bottom` transitions all work similarly.

#### Example outer transition

![outer transition demonstration](../demos/assets/outer.gif)

The `center` transition is the opposite: it starts from the center and goes
towards the edges.

There is also `simple`, which simply fades into the new image, `any`, which
starts at a random point with either `center` of `outer` transitions, and `random`,
which selects a transition effect at random.

## Troubleshooting

### The image looks tilted and in grayscale on my laptop

See #233. Current workaround is to use `swww-daemon --format xrgb` when starting
the daemon.

### High cpu usage during caching of a gif&#039;s frames

`swww` will use a non-insignificant amount of cpu power while caching the
images. This will be specially noticeable if the images need to be resized
before being displayed. So, if you have a very large gif, I would recommend
resizing it **before** sending it to `swww`. That would make the caching phase
much faster, and thus ultimately reduce power consumption. I can personally
recommend [`gifsicle`](https://github.com/kohler/gifsicle) for this purpose.

### Wallpaper disappears when reconnecting monitor

`swww` used to cache its images so that it could reload the current the last
displayed image automatically. This lead to many problems and also proved to be
very annoying to keep working with when we updated to
[`sctk 0.17`](https://github.com/Smithay/client-toolkit). So I decided to nuke
it.

If you want a wallpaper to be set automatically when you reconnect to a monitor,
you should use a combination of scripts and a program that lets you run commands
when a new output is connected, like [`kanshi`](https://sr.ht/~emersion/kanshi/).

## About new features

Broadly speaking, **NEW FEATURES WILL NOT BE ADDED, UNLESS THEY ARE EGREGIOUSLY
SIMPLE**. I made `swww` with the specific usecase of making shell scripts in
mind. So, for example, stuff like timed wallpapers, or a setup that loads a
different image at different times of the day, and so on, should all be done by
combining `swww` with other programs (see the [example_scripts](/example_scripts/) for some
examples).

If you really want some new feature within `swww` itself, I would recommend
forking the repository.

## Alternatives

`swww` isn&#039;t really the simplest, mostest minimalest software you could find
for managing wallpapers. If you are looking for something simpler, have a look
at the [awesome-wayland repository list of wallpaper programs
](https://github.com/natpen/awesome-wayland#wallpaper). I can personally
recommend:

 - [`wbg`](https://codeberg.org/dnkl/wbg) - probably the simplest of them all.
 Strongly recommend if you just care about setting a single png as your
 permanent wallpaper on something like a laptop.
 - [`swaybg`](https://github.com/swaywm/swaybg) - made by the wlroots gods
 themselves.
 - [`mpvpaper`](https://github.com/GhostNaN/mpvpaper) - if you want to display
 videos as your wallpapers. This is also what I used for gifs before making
 `swww`.
 - [`kitty`](https://sw.kovidgoyal.net/kitty/) - you can use the kitty terminal emulator with its [panel](https://sw.kovidgoyal.net/kitty/kittens/panel/) kitten to have the output of an arbitrary TUI program such as htop or btop or similar as your desktop wallpaper.

## Acknowledgments

A huge thanks to everyone involved in the [smithay](https://github.com/Smithay)
project. Making this program would not have been possible without it. In fact,
the first versions of swww were quite literally copy pasted from the
[layer shell example in the client-toolkit
](https://github.com/Smithay/client-toolkit/blob/master/examples/layer_shell.rs).

A big thank-you also to [HakierGrzonzo](https://github.com/HakierGrzonzo), for
setting up the AUR package.

### Wallpapers used in this README

Pixel Art, by Waneella - https://www.patreon.com/waneella

Gradient - https://www.behance.net/gallery/86128681/Free-Unicorn-Vector-Gradients

Silhouette of Skyway - https://unsplash.com/photos/silhouette-of-skyway-UUJzCuHUfYI
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[alacritty/alacritty]]></title>
            <link>https://github.com/alacritty/alacritty</link>
            <guid>https://github.com/alacritty/alacritty</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:38 GMT</pubDate>
            <description><![CDATA[A cross-platform, OpenGL terminal emulator.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/alacritty/alacritty">alacritty/alacritty</a></h1>
            <p>A cross-platform, OpenGL terminal emulator.</p>
            <p>Language: Rust</p>
            <p>Stars: 59,112</p>
            <p>Forks: 3,121</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;200&quot; alt=&quot;Alacritty Logo&quot; src=&quot;https://raw.githubusercontent.com/alacritty/alacritty/master/extra/logo/compat/alacritty-term%2Bscanlines.png&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Alacritty - A fast, cross-platform, OpenGL terminal emulator&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Alacritty - A fast, cross-platform, OpenGL terminal emulator&quot;
       src=&quot;https://raw.githubusercontent.com/alacritty/alacritty/master/extra/promo/alacritty-readme.png&quot;&gt;
&lt;/p&gt;

## About

Alacritty is a modern terminal emulator that comes with sensible defaults, but
allows for extensive [configuration](#configuration). By integrating with other
applications, rather than reimplementing their functionality, it manages to
provide a flexible set of [features](./docs/features.md) with high performance.
The supported platforms currently consist of BSD, Linux, macOS and Windows.

The software is considered to be at a **beta** level of readiness; there are
a few missing features and bugs to be fixed, but it is already used by many as
a daily driver.

Precompiled binaries are available from the [GitHub releases page](https://github.com/alacritty/alacritty/releases).

Join [`#alacritty`] on libera.chat if you have questions or looking for a quick help.

[`#alacritty`]: https://web.libera.chat/gamja/?channels=#alacritty

## Features

You can find an overview over the features available in Alacritty [here](./docs/features.md).

## Further information

- [Announcing Alacritty, a GPU-Accelerated Terminal Emulator](https://jwilm.io/blog/announcing-alacritty/) January 6, 2017
- [A talk about Alacritty at the Rust Meetup January 2017](https://www.youtube.com/watch?v=qHOdYO3WUTk) January 19, 2017
- [Alacritty Lands Scrollback, Publishes Benchmarks](https://jwilm.io/blog/alacritty-lands-scrollback/) September 17, 2018

## Installation

Alacritty can be installed by using various package managers on Linux, BSD,
macOS and Windows.

Prebuilt binaries for macOS and Windows can also be downloaded from the
[GitHub releases page](https://github.com/alacritty/alacritty/releases).

For everyone else, the detailed instructions to install Alacritty can be found
[here](INSTALL.md).

### Requirements

- At least OpenGL ES 2.0
- [Windows] ConPTY support (Windows 10 version 1809 or higher)

## Configuration

You can find the documentation for Alacritty&#039;s configuration in `man 5
alacritty`, or by looking at [the website] if you do not have the manpages
installed.

[the website]: https://alacritty.org/config-alacritty.html

Alacritty doesn&#039;t create the config file for you, but it looks for one in the
following locations:

1. `$XDG_CONFIG_HOME/alacritty/alacritty.toml`
2. `$XDG_CONFIG_HOME/alacritty.toml`
3. `$HOME/.config/alacritty/alacritty.toml`
4. `$HOME/.alacritty.toml`

On Windows, the config file will be looked for in:

* `%APPDATA%\alacritty\alacritty.toml`

## Contributing

A guideline about contributing to Alacritty can be found in the
[`CONTRIBUTING.md`](CONTRIBUTING.md) file.

## FAQ

**_Is it really the fastest terminal emulator?_**

Benchmarking terminal emulators is complicated. Alacritty uses
[vtebench](https://github.com/alacritty/vtebench) to quantify terminal emulator
throughput and manages to consistently score better than the competition using
it. If you have found an example where this is not the case, please report a
bug.

Other aspects like latency or framerate and frame consistency are more difficult
to quantify. Some terminal emulators also intentionally slow down to save
resources, which might be preferred by some users.

If you have doubts about Alacritty&#039;s performance or usability, the best way to
quantify terminal emulators is always to test them with **your** specific
usecases.

**_Why isn&#039;t feature X implemented?_**

Alacritty has many great features, but not every feature from every other
terminal. This could be for a number of reasons, but sometimes it&#039;s just not a
good fit for Alacritty. This means you won&#039;t find things like tabs or splits
(which are best left to a window manager or [terminal multiplexer][tmux]) nor
niceties like a GUI config editor.

[tmux]: https://github.com/tmux/tmux

## License

Alacritty is released under the [Apache License, Version 2.0].

[Apache License, Version 2.0]: https://github.com/alacritty/alacritty/blob/master/LICENSE-APACHE
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[fish-shell/fish-shell]]></title>
            <link>https://github.com/fish-shell/fish-shell</link>
            <guid>https://github.com/fish-shell/fish-shell</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:37 GMT</pubDate>
            <description><![CDATA[The user-friendly command line shell.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fish-shell/fish-shell">fish-shell/fish-shell</a></h1>
            <p>The user-friendly command line shell.</p>
            <p>Language: Rust</p>
            <p>Stars: 30,058</p>
            <p>Forks: 2,067</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[mainmatter/100-exercises-to-learn-rust]]></title>
            <link>https://github.com/mainmatter/100-exercises-to-learn-rust</link>
            <guid>https://github.com/mainmatter/100-exercises-to-learn-rust</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[A self-paced course to learn Rust, one exercise at a time.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mainmatter/100-exercises-to-learn-rust">mainmatter/100-exercises-to-learn-rust</a></h1>
            <p>A self-paced course to learn Rust, one exercise at a time.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,826</p>
            <p>Forks: 1,558</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># Learn Rust, one exercise at a time

You&#039;ve heard about Rust, but you never had the chance to try it out?\
This course is for you!

You&#039;ll learn Rust by solving 100 exercises.\
You&#039;ll go from knowing nothing about Rust to being able to start
writing your own programs, one exercise at a time.

&gt; [!NOTE]
&gt; This course has been written by [Mainmatter](https://mainmatter.com/rust-consulting/).\
&gt; It&#039;s one of the trainings in [our portfolio of Rust workshops](https://mainmatter.com/services/workshops/rust/).\
&gt; Check out our [landing page](https://mainmatter.com/rust-consulting/) if you&#039;re looking for Rust consulting or
&gt; training!

## Getting started

Go to [rust-exercises.com](https://rust-exercises.com) and follow the instructions there
to get started with the course.

## Requirements

- **Rust** (follow instructions [here](https://www.rust-lang.org/tools/install)).\
  If `rustup` is already installed on your system, run `rustup update` (or another appropriate command depending on how
  you installed Rust on your system)
  to make sure you&#039;re running on the latest stable version.
- _(Optional but recommended)_ An IDE with Rust autocompletion support.
  We recommend one of the following:
  - [RustRover](https://www.jetbrains.com/rust/);
  - [Visual Studio Code](https://code.visualstudio.com) with
    the [`rust-analyzer`](https://marketplace.visualstudio.com/items?itemName=matklad.rust-analyzer) extension.

## Solutions

You can find the solutions to the exercises in
the [`solutions` branch](https://github.com/mainmatter/100-exercises-to-learn-rust/tree/solutions) of this repository.

# License

Copyright ¬© 2024- Mainmatter GmbH (https://mainmatter.com), released under the
[Creative Commons Attribution-NonCommercial 4.0 International license](https://creativecommons.org/licenses/by-nc/4.0/).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[servo/servo]]></title>
            <link>https://github.com/servo/servo</link>
            <guid>https://github.com/servo/servo</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/servo/servo">servo/servo</a></h1>
            <p>Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.</p>
            <p>Language: Rust</p>
            <p>Stars: 30,720</p>
            <p>Forks: 3,187</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># The Servo Parallel Browser Engine Project

Servo is a prototype web browser engine written in the
[Rust](https://github.com/rust-lang/rust) language. It is currently developed on
64-bit macOS, 64-bit Linux, 64-bit Windows, 64-bit OpenHarmony, and Android.

Servo welcomes contribution from everyone. Check out:

- The [Servo Book](https://book.servo.org) for documentation
- [servo.org](https://servo.org/) for news and guides

Coordination of Servo development happens:
- Here in the Github Issues
- On the [Servo Zulip](https://servo.zulipchat.com/)
- In video calls advertised in the [Servo Project](https://github.com/servo/project/issues) repo.

## Getting started

For more detailed build instructions, see the Servo book under [Setting up your environment], [Building Servo], [Building for Android] and [Building for OpenHarmony].

[Setting up your environment]: https://book.servo.org/hacking/setting-up-your-environment.html
[Building Servo]: https://book.servo.org/hacking/building-servo.html
[Building for Android]: https://book.servo.org/hacking/building-for-android.html
[Building for OpenHarmony]: https://book.servo.org/hacking/building-for-openharmony.html

### macOS

- Download and install [Xcode](https://developer.apple.com/xcode/) and [`brew`](https://brew.sh/).
- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` 
- Install `rustup`: `curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh`
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `./mach bootstrap`
- Build servoshell: `./mach build`

### Linux

- Install `curl`:
  - Arch: `sudo pacman -S --needed curl`
  - Debian, Ubuntu: `sudo apt install curl`
  - Fedora: `sudo dnf install curl`
  - Gentoo: `sudo emerge net-misc/curl`
- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` 
- Install `rustup`: `curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh`
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `./mach bootstrap`
- Build servoshell: `./mach build`

### Windows

- Download [`uv`](https://docs.astral.sh/uv/getting-started/installation/#standalone-installer), [`choco`](https://chocolatey.org/install#individual), and [`rustup`](https://win.rustup.rs/)
  - Be sure to select *Quick install via the Visual Studio Community installer*
- In the Visual Studio Installer, ensure the following components are installed:
  - **Windows 10 SDK (10.0.19041.0)** (`Microsoft.VisualStudio.Component.Windows10SDK.19041`)
  - **MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)** (`Microsoft.VisualStudio.Component.VC.Tools.x86.x64`)
  - **C++ ATL for latest v143 build tools (x86 &amp; x64)** (`Microsoft.VisualStudio.Component.VC.ATL`)
  - **C++ MFC for latest v143 build tools (x86 &amp; x64)** (`Microsoft.VisualStudio.Component.VC.ATLMFC`)
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `.\mach bootstrap`
- Build servoshell: `.\mach build`

### Android

- Ensure that the following environment variables are set:
  - `ANDROID_SDK_ROOT`
  - `ANDROID_NDK_ROOT`: `$ANDROID_SDK_ROOT/ndk/26.2.11394342/`
 `ANDROID_SDK_ROOT` can be any directory (such as `~/android-sdk`).
  All of the Android build dependencies will be installed there.
- Install the latest version of the [Android command-line
  tools](https://developer.android.com/studio#command-tools) to
  `$ANDROID_SDK_ROOT/cmdline-tools/latest`.
- Run the following command to install the necessary components:
  ```shell
  sudo $ANDROID_SDK_ROOT/cmdline-tools/latest/bin/sdkmanager --install \
   &quot;build-tools;34.0.0&quot; \
   &quot;emulator&quot; \
   &quot;ndk;26.2.11394342&quot; \
   &quot;platform-tools&quot; \
   &quot;platforms;android-33&quot; \
   &quot;system-images;android-33;google_apis;x86_64&quot;
  ```
- Follow the instructions above for the platform you are building on

### OpenHarmony

- Follow the instructions above for the platform you are building on to prepare the environment.
- Depending on the target distribution (e.g. `HarmonyOS NEXT` vs pure `OpenHarmony`) the build configuration will differ slightly.
- Ensure that the following environment variables are set
  - `DEVECO_SDK_HOME` (Required when targeting `HarmonyOS NEXT`)
  - `OHOS_BASE_SDK_HOME` (Required when targeting `OpenHarmony`)
  - `OHOS_SDK_NATIVE` (e.g. `${DEVECO_SDK_HOME}/default/openharmony/native` or `${OHOS_BASE_SDK_HOME}/${API_VERSION}/native`)
  - `SERVO_OHOS_SIGNING_CONFIG`: Path to json file containing a valid signing configuration for the demo app.
- Review the detailed instructions at [Building for OpenHarmony].
- The target distribution can be modified by passing `--flavor=&lt;default|harmonyos&gt;` to `mach &lt;build|package|install&gt;.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[dtolnay/cxx]]></title>
            <link>https://github.com/dtolnay/cxx</link>
            <guid>https://github.com/dtolnay/cxx</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[Safe interop between Rust and C++]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dtolnay/cxx">dtolnay/cxx</a></h1>
            <p>Safe interop between Rust and C++</p>
            <p>Language: Rust</p>
            <p>Stars: 6,319</p>
            <p>Forks: 365</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>CXX &amp;mdash; safe FFI between Rust and C++
=========================================

[&lt;img alt=&quot;github&quot; src=&quot;https://img.shields.io/badge/github-dtolnay/cxx-8da0cb?style=for-the-badge&amp;labelColor=555555&amp;logo=github&quot; height=&quot;20&quot;&gt;](https://github.com/dtolnay/cxx)
[&lt;img alt=&quot;crates.io&quot; src=&quot;https://img.shields.io/crates/v/cxx.svg?style=for-the-badge&amp;color=fc8d62&amp;logo=rust&quot; height=&quot;20&quot;&gt;](https://crates.io/crates/cxx)
[&lt;img alt=&quot;docs.rs&quot; src=&quot;https://img.shields.io/badge/docs.rs-cxx-66c2a5?style=for-the-badge&amp;labelColor=555555&amp;logo=docs.rs&quot; height=&quot;20&quot;&gt;](https://docs.rs/cxx)
[&lt;img alt=&quot;build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/dtolnay/cxx/ci.yml?branch=master&amp;style=for-the-badge&quot; height=&quot;20&quot;&gt;](https://github.com/dtolnay/cxx/actions?query=branch%3Amaster)

This library provides a **safe** mechanism for calling C++ code from Rust and
Rust code from C++, not subject to the many ways that things can go wrong when
using bindgen or cbindgen to generate unsafe C-style bindings.

This doesn&#039;t change the fact that 100% of C++ code is unsafe. When auditing a
project, you would be on the hook for auditing all the unsafe Rust code and
*all* the C++ code. The core safety claim under this new model is that auditing
just the C++ side would be sufficient to catch all problems, i.e. the Rust side
can be 100% safe.

```toml
[dependencies]
cxx = &quot;1.0&quot;

[build-dependencies]
cxx-build = &quot;1.0&quot;
```

*Compiler support: requires rustc 1.73+ and c++11 or newer*&lt;br&gt;
*[Release notes](https://github.com/dtolnay/cxx/releases)*

&lt;br&gt;

## Guide

Please see **&lt;https://cxx.rs&gt;** for a tutorial, reference material, and example
code.

&lt;br&gt;

## Overview

The idea is that we define the signatures of both sides of our FFI boundary
embedded together in one Rust module (the next section shows an example). From
this, CXX receives a complete picture of the boundary to perform static analyses
against the types and function signatures to uphold both Rust&#039;s and C++&#039;s
invariants and requirements.

If everything checks out statically, then CXX uses a pair of code generators to
emit the relevant `extern &quot;C&quot;` signatures on both sides together with any
necessary static assertions for later in the build process to verify
correctness. On the Rust side this code generator is simply an attribute
procedural macro. On the C++ side it can be a small Cargo build script if your
build is managed by Cargo, or for other build systems like Bazel or Buck we
provide a command line tool which generates the header and source file and
should be easy to integrate.

The resulting FFI bridge operates at zero or negligible overhead, i.e. no
copying, no serialization, no memory allocation, no runtime checks needed.

The FFI signatures are able to use native types from whichever side they please,
such as Rust&#039;s `String` or C++&#039;s `std::string`, Rust&#039;s `Box` or C++&#039;s
`std::unique_ptr`, Rust&#039;s `Vec` or C++&#039;s `std::vector`, etc in any combination.
CXX guarantees an ABI-compatible signature that both sides understand, based on
builtin bindings for key standard library types to expose an idiomatic API on
those types to the other language. For example when manipulating a C++ string
from Rust, its `len()` method becomes a call of the `size()` member function
defined by C++; when manipulating a Rust string from C++, its `size()` member
function calls Rust&#039;s `len()`.

&lt;br&gt;

## Example

In this example we are writing a Rust application that wishes to take advantage
of an existing C++ client for a large-file blobstore service. The blobstore
supports a `put` operation for a discontiguous buffer upload. For example we
might be uploading snapshots of a circular buffer which would tend to consist of
2 chunks, or fragments of a file spread across memory for some other reason.

A runnable version of this example is provided under the *demo* directory of
this repo. To try it out, run `cargo run` from that directory.

```rust
#[cxx::bridge]
mod ffi {
    // Any shared structs, whose fields will be visible to both languages.
    struct BlobMetadata {
        size: usize,
        tags: Vec&lt;String&gt;,
    }

    extern &quot;Rust&quot; {
        // Zero or more opaque types which both languages can pass around but
        // only Rust can see the fields.
        type MultiBuf;

        // Functions implemented in Rust.
        fn next_chunk(buf: &amp;mut MultiBuf) -&gt; &amp;[u8];
    }

    unsafe extern &quot;C++&quot; {
        // One or more headers with the matching C++ declarations. Our code
        // generators don&#039;t read it but it gets #include&#039;d and used in static
        // assertions to ensure our picture of the FFI boundary is accurate.
        include!(&quot;demo/include/blobstore.h&quot;);

        // Zero or more opaque types which both languages can pass around but
        // only C++ can see the fields.
        type BlobstoreClient;

        // Functions implemented in C++.
        fn new_blobstore_client() -&gt; UniquePtr&lt;BlobstoreClient&gt;;
        fn put(&amp;self, parts: &amp;mut MultiBuf) -&gt; u64;
        fn tag(&amp;self, blobid: u64, tag: &amp;str);
        fn metadata(&amp;self, blobid: u64) -&gt; BlobMetadata;
    }
}
```

Now we simply provide Rust definitions of all the things in the `extern &quot;Rust&quot;`
block and C++ definitions of all the things in the `extern &quot;C++&quot;` block, and get
to call back and forth safely.

Here are links to the complete set of source files involved in the demo:

- [demo/src/main.rs](demo/src/main.rs)
- [demo/build.rs](demo/build.rs)
- [demo/include/blobstore.h](demo/include/blobstore.h)
- [demo/src/blobstore.cc](demo/src/blobstore.cc)

To look at the code generated in both languages for the example by the CXX code
generators:

```console
   # run Rust code generator and print to stdout
   # (requires https://github.com/dtolnay/cargo-expand)
$ cargo expand --manifest-path demo/Cargo.toml

   # run C++ code generator and print to stdout
$ cargo run --manifest-path gen/cmd/Cargo.toml -- demo/src/main.rs
```

&lt;br&gt;

## Details

As seen in the example, the language of the FFI boundary involves 3 kinds of
items:

- **Shared structs** &amp;mdash; their fields are made visible to both languages.
  The definition written within cxx::bridge is the single source of truth.

- **Opaque types** &amp;mdash; their fields are secret from the other language.
  These cannot be passed across the FFI by value but only behind an indirection,
  such as a reference `&amp;`, a Rust `Box`, or a `UniquePtr`. Can be a type alias
  for an arbitrarily complicated generic language-specific type depending on
  your use case.

- **Functions** &amp;mdash; implemented in either language, callable from the other
  language.

Within the `extern &quot;Rust&quot;` part of the CXX bridge we list the types and
functions for which Rust is the source of truth. These all implicitly refer to
the `super` module, the parent module of the CXX bridge. You can think of the
two items listed in the example above as being like `use super::MultiBuf` and
`use super::next_chunk` except re-exported to C++. The parent module will either
contain the definitions directly for simple things, or contain the relevant
`use` statements to bring them into scope from elsewhere.

Within the `extern &quot;C++&quot;` part, we list types and functions for which C++ is the
source of truth, as well as the header(s) that declare those APIs. In the future
it&#039;s possible that this section could be generated bindgen-style from the
headers but for now we need the signatures written out; static assertions will
verify that they are accurate.

Your function implementations themselves, whether in C++ or Rust, *do not* need
to be defined as `extern &quot;C&quot;` ABI or no\_mangle. CXX will put in the right shims
where necessary to make it all work.

&lt;br&gt;

## Comparison vs bindgen and cbindgen

Notice that with CXX there is repetition of all the function signatures: they
are typed out once where the implementation is defined (in C++ or Rust) and
again inside the cxx::bridge module, though compile-time assertions guarantee
these are kept in sync. This is different from [bindgen] and [cbindgen] where
function signatures are typed by a human once and the tool consumes them in one
language and emits them in the other language.

[bindgen]: https://github.com/rust-lang/rust-bindgen
[cbindgen]: https://github.com/eqrion/cbindgen/

This is because CXX fills a somewhat different role. It is a lower level tool
than bindgen or cbindgen in a sense; you can think of it as being a replacement
for the concept of `extern &quot;C&quot;` signatures as we know them, rather than a
replacement for a bindgen. It would be reasonable to build a higher level
bindgen-like tool on top of CXX which consumes a C++ header and/or Rust module
(and/or IDL like Thrift) as source of truth and generates the cxx::bridge,
eliminating the repetition while leveraging the static analysis safety
guarantees of CXX.

But note in other ways CXX is higher level than the bindgens, with rich support
for common standard library types. Frequently with bindgen when we are dealing
with an idiomatic C++ API we would end up manually wrapping that API in C-style
raw pointer functions, applying bindgen to get unsafe raw pointer Rust
functions, and replicating the API again to expose those idiomatically in Rust.
That&#039;s a much worse form of repetition because it is unsafe all the way through.

By using a CXX bridge as the shared understanding between the languages, rather
than `extern &quot;C&quot;` C-style signatures as the shared understanding, common FFI use
cases become expressible using 100% safe code.

It would also be reasonable to mix and match, using CXX bridge for the 95% of
your FFI that is straightforward and doing the remaining few oddball signatures
the old fashioned way with bindgen and cbindgen, if for some reason CXX&#039;s static
restrictions get in the way. Please file an issue if you end up taking this
approach so that we know what ways it would be worthwhile to make the tool more
expressive.

&lt;br&gt;

## Cargo-based setup

For builds that are orchestrated by Cargo, you will use a build script that runs
CXX&#039;s C++ code generator and compiles the resulting C++ code along with any
other C++ code for your crate.

The canonical build script is as follows. The indicated line returns a
[`cc::Build`] instance (from the usual widely used `cc` crate) on which you can
set up any additional source files and compiler flags as normal.

[`cc::Build`]: https://docs.rs/cc/1.0/cc/struct.Build.html

```toml
# Cargo.toml

[build-dependencies]
cxx-build = &quot;1.0&quot;
```

```rust
// build.rs

fn main() {
    cxx_build::bridge(&quot;src/main.rs&quot;)  // returns a cc::Build
        .file(&quot;src/demo.cc&quot;)
        .std(&quot;c++11&quot;)
        .compile(&quot;cxxbridge-demo&quot;);

    println!(&quot;cargo:rerun-if-changed=src/main.rs&quot;);
    println!(&quot;cargo:rerun-if-changed=src/demo.cc&quot;);
    println!(&quot;cargo:rerun-if-changed=include/demo.h&quot;);
}
```

&lt;br&gt;

## Non-Cargo setup

For use in non-Cargo builds like Bazel or Buck, CXX provides an alternate way of
invoking the C++ code generator as a standalone command line tool. The tool is
packaged as the `cxxbridge-cmd` crate on crates.io or can be built from the
*gen/cmd* directory of this repo.

```bash
$ cargo install cxxbridge-cmd

$ cxxbridge src/main.rs --header &gt; path/to/mybridge.h
$ cxxbridge src/main.rs &gt; path/to/mybridge.cc
```

&lt;br&gt;

## Safety

Be aware that the design of this library is intentionally restrictive and
opinionated! It isn&#039;t a goal to be powerful enough to handle arbitrary
signatures in either language. Instead this project is about carving out a
reasonably expressive set of functionality about which we can make useful safety
guarantees today and maybe extend over time. You may find that it takes some
practice to use CXX bridge effectively as it won&#039;t work in all the ways that you
are used to.

Some of the considerations that go into ensuring safety are:

- By design, our paired code generators work together to control both sides of
  the FFI boundary. Ordinarily in Rust writing your own `extern &quot;C&quot;` blocks is
  unsafe because the Rust compiler has no way to know whether the signatures
  you&#039;ve written actually match the signatures implemented in the other
  language. With CXX we achieve that visibility and know what&#039;s on the other
  side.

- Our static analysis detects and prevents passing types by value that shouldn&#039;t
  be passed by value from C++ to Rust, for example because they may contain
  internal pointers that would be screwed up by Rust&#039;s move behavior.

- To many people&#039;s surprise, it is possible to have a struct in Rust and a
  struct in C++ with exactly the same layout / fields / alignment / everything,
  and still not the same ABI when passed by value. This is a longstanding
  bindgen bug that leads to segfaults in absolutely correct-looking code
  ([rust-lang/rust-bindgen#778]). CXX knows about this and can insert the
  necessary zero-cost workaround transparently where needed, so go ahead and
  pass your structs by value without worries. This is made possible by owning
  both sides of the boundary rather than just one.

- Template instantiations: for example in order to expose a UniquePtr\&lt;T\&gt; type
  in Rust backed by a real C++ unique\_ptr, we have a way of using a Rust trait
  to connect the behavior back to the template instantiations performed by the
  other language.

[rust-lang/rust-bindgen#778]: https://github.com/rust-lang/rust-bindgen/issues/778

&lt;br&gt;

## Builtin types

In addition to all the primitive types (i32 &amp;lt;=&amp;gt; int32_t), the following
common types may be used in the fields of shared structs and the arguments and
returns of functions.

&lt;table&gt;
&lt;tr&gt;&lt;th&gt;name in Rust&lt;/th&gt;&lt;th&gt;name in C++&lt;/th&gt;&lt;th&gt;restrictions&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;String&lt;/td&gt;&lt;td&gt;rust::String&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;amp;str&lt;/td&gt;&lt;td&gt;rust::Str&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;amp;[T]&lt;/td&gt;&lt;td&gt;rust::Slice&amp;lt;const T&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;cannot hold opaque C++ type&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&amp;amp;mut [T]&lt;/td&gt;&lt;td&gt;rust::Slice&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;cannot hold opaque C++ type&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://docs.rs/cxx/1.0/cxx/struct.CxxString.html&quot;&gt;CxxString&lt;/a&gt;&lt;/td&gt;&lt;td&gt;std::string&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;cannot be passed by value&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Box&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;rust::Box&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;cannot hold opaque C++ type&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://docs.rs/cxx/1.0/cxx/struct.UniquePtr.html&quot;&gt;UniquePtr&amp;lt;T&amp;gt;&lt;/a&gt;&lt;/td&gt;&lt;td&gt;std::unique_ptr&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;cannot hold opaque Rust type&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://docs.rs/cxx/1.0/cxx/struct.SharedPtr.html&quot;&gt;SharedPtr&amp;lt;T&amp;gt;&lt;/a&gt;&lt;/td&gt;&lt;td&gt;std::shared_ptr&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;cannot hold opaque Rust type&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;[T; N]&lt;/td&gt;&lt;td&gt;std::array&amp;lt;T, N&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;cannot hold opaque C++ type&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Vec&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;rust::Vec&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;cannot hold opaque C++ type&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;a href=&quot;https://docs.rs/cxx/1.0/cxx/struct.CxxVector.html&quot;&gt;CxxVector&amp;lt;T&amp;gt;&lt;/a&gt;&lt;/td&gt;&lt;td&gt;std::vector&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;cannot be passed by value, cannot hold opaque Rust type&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;*mut T, *const T&lt;/td&gt;&lt;td&gt;T*, const T*&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;fn with a raw pointer argument must be declared unsafe to call&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;fn(T, U) -&amp;gt; V&lt;/td&gt;&lt;td&gt;rust::Fn&amp;lt;V(T, U)&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;only passing from Rust to C++ is implemented so far&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Result&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;throw/catch&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;allowed as return type only&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

The C++ API of the `rust` namespace is defined by the *include/cxx.h* file in
this repo. You will need to include this header in your C++ code when working
with those types.

The following types are intended to be supported &quot;soon&quot; but are just not
implemented yet. I don&#039;t expect any of these to be hard to make work but it&#039;s a
matter of designing a nice API for each in its non-native language.

&lt;table&gt;
&lt;tr&gt;&lt;th&gt;name in Rust&lt;/th&gt;&lt;th&gt;name in C++&lt;/th&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;BTreeMap&amp;lt;K, V&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;tbd&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;HashMap&amp;lt;K, V&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;tbd&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Arc&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;tbd&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Option&amp;lt;T&amp;gt;&lt;/td&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;tbd&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;tbd&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;std::map&amp;lt;K, V&amp;gt;&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;&lt;sup&gt;&lt;i&gt;tbd&lt;/i&gt;&lt;/sup&gt;&lt;/td&gt;&lt;td&gt;std::unordered_map&amp;lt;K, V&amp;gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&lt;br&gt;

## Remaining work

This is still early days for CXX; I am releasing it as a minimum viable product
to collect feedback on the direction and invite collaborators. Please check the
open issues.

Especially please report issues if you run into trouble building or linking any
of this stuff. I&#039;m sure there are ways to make the build aspects friendlier or
more robust.

Finally, I know more about Rust library design than C++ library design so I
would appreciate help making the C++ APIs in this project more idiomatic where
anyone has suggestions.

&lt;br&gt;

#### License

&lt;sup&gt;
Licensed under either of &lt;a href=&quot;LICENSE-APACHE&quot;&gt;Apache License, Version
2.0&lt;/a&gt; or &lt;a href=&quot;LICENSE-MIT&quot;&gt;MIT license&lt;/a&gt; at your option.
&lt;/sup&gt;

&lt;br&gt;

&lt;sub&gt;
Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in this project by you, as defined in the Apache-2.0 license,
shall be dual licensed as above, without any additional terms or conditions.
&lt;/sub&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/rust-bindgen]]></title>
            <link>https://github.com/rust-lang/rust-bindgen</link>
            <guid>https://github.com/rust-lang/rust-bindgen</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[Automatically generates Rust FFI bindings to C (and some C++) libraries.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/rust-bindgen">rust-lang/rust-bindgen</a></h1>
            <p>Automatically generates Rust FFI bindings to C (and some C++) libraries.</p>
            <p>Language: Rust</p>
            <p>Stars: 4,825</p>
            <p>Forks: 748</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>[![crates.io](https://img.shields.io/crates/v/bindgen.svg)](https://crates.io/crates/bindgen)
[![docs.rs](https://docs.rs/bindgen/badge.svg)](https://docs.rs/bindgen/)

# `bindgen`

**`bindgen` automatically generates Rust FFI bindings to C (and some C++) libraries.**

For example, given the C header `doggo.h`:

```c
typedef struct Doggo {
    int many;
    char wow;
} Doggo;

void eleven_out_of_ten_majestic_af(Doggo* pupper);
```

`bindgen` produces Rust FFI code allowing you to call into the `doggo` library&#039;s
functions and use its types:

```rust
/* automatically generated by rust-bindgen 0.99.9 */

#[repr(C)]
pub struct Doggo {
    pub many: ::std::os::raw::c_int,
    pub wow: ::std::os::raw::c_char,
}

extern &quot;C&quot; {
    pub fn eleven_out_of_ten_majestic_af(pupper: *mut Doggo);
}
```

## Users Guide

[üìö Read the `bindgen` users guide here! üìö](https://rust-lang.github.io/rust-bindgen)

## MSRV

The `bindgen` minimum supported Rust version is **1.70.0**.

The `bindgen-cli` minimum supported Rust version is **1.70.0**.

No MSRV bump policy has been established yet, so MSRV may increase in any release.

The MSRV is the minimum Rust version that can be used to *compile* each crate. However, `bindgen` and `bindgen-cli` can generate bindings that are compatible with Rust versions below the current MSRV.

Most of the time, the `bindgen-cli` crate will have a more recent MSRV than `bindgen` as crates such as `clap` require it. 

## API Reference

[API reference documentation is on docs.rs](https://docs.rs/bindgen)

## Environment Variables

In addition to the [library API](https://docs.rs/bindgen) and [executable command-line API][bindgen-cmdline],
`bindgen` can be controlled through environment variables.

End-users should set these environment variables to modify `bindgen`&#039;s behavior without modifying the source code of direct consumers of `bindgen`.

- `BINDGEN_EXTRA_CLANG_ARGS`: extra arguments to pass to `clang`
    - Arguments are whitespace-separated
    - Use shell-style quoting to pass through whitespace
    - Examples:
        - Specify alternate sysroot: `--sysroot=/path/to/sysroot`
        - Add include search path with spaces: `-I&quot;/path/with spaces&quot;`
- `BINDGEN_EXTRA_CLANG_ARGS_&lt;TARGET&gt;`: similar to `BINDGEN_EXTRA_CLANG_ARGS`,
   but used to set per-target arguments to pass to clang. Useful to set system include
   directories in a target-specific way in cross-compilation environments with multiple targets.
   Has precedence over `BINDGEN_EXTRA_CLANG_ARGS`.

Additionally, `bindgen` uses `libclang` to parse C and C++ header files.
To modify how `bindgen` searches for `libclang`, see the [`clang-sys` documentation][clang-sys-env].
For more details on how `bindgen` uses `libclang`, see the [`bindgen` users guide][bindgen-book-clang].

## Releases

We don&#039;t follow a specific release calendar, but if you need a release please
file an issue requesting that (ping `@emilio` for increased effectiveness).

## Contributing

[See `CONTRIBUTING.md` for hacking on `bindgen`!](./CONTRIBUTING.md)

[bindgen-cmdline]: https://rust-lang.github.io/rust-bindgen/command-line-usage.html
[clang-sys-env]: https://github.com/KyleMayes/clang-sys#environment-variables
[bindgen-book-clang]: https://rust-lang.github.io/rust-bindgen/requirements.html#clang
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[louis-e/arnis]]></title>
            <link>https://github.com/louis-e/arnis</link>
            <guid>https://github.com/louis-e/arnis</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[Generate any location from the real world in Minecraft Java Edition with a high level of detail.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/louis-e/arnis">louis-e/arnis</a></h1>
            <p>Generate any location from the real world in Minecraft Java Edition with a high level of detail.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,339</p>
            <p>Forks: 464</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;456&quot; height=&quot;125&quot; src=&quot;https://github.com/louis-e/arnis/blob/main/gui-src/images/logo.png?raw=true&quot;&gt;
&lt;/p&gt;

# Arnis [![CI Build Status](https://github.com/louis-e/arnis/actions/workflows/ci-build.yml/badge.svg)](https://github.com/louis-e/arnis/actions) [&lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/louis-e/arnis&quot; /&gt;](https://github.com/louis-e/arnis/releases) [&lt;img alt=&quot;GitHub Downloads (all assets, all releases&quot; src=&quot;https://img.shields.io/github/downloads/louis-e/arnis/total&quot; /&gt;](https://github.com/louis-e/arnis/releases)

Arnis creates complex and accurate Minecraft Java Edition worlds that reflect real-world geography and architecture using OpenStreetMap.

###### ‚ö†Ô∏è This Github page is the official project website. Do not download Arnis from any other website.

## :desktop_computer: Example
![Minecraft Preview](https://github.com/louis-e/arnis/blob/main/gitassets/mc.gif?raw=true)

Arnis is designed to handle large-scale data and generate rich, immersive environments that bring real-world cities, landmarks, and natural features into Minecraft. Whether you&#039;re looking to replicate your hometown, explore urban environments, or simply build something unique and realistic, Arnis generates your vision.

## :keyboard: Usage
&lt;img width=&quot;60%&quot; src=&quot;https://github.com/louis-e/arnis/blob/main/gitassets/gui.png?raw=true&quot;&gt;&lt;br&gt;
Download the [latest release](https://github.com/louis-e/arnis/releases/) or [compile](#trophy-open-source) the project on your own.
 
Choose your area using the rectangle tool and select your Minecraft world - then simply click on &#039;Start Generation&#039;!

&gt; The world will always be generated starting from the Minecraft coordinates 0 0 0 (/tp 0 0 0). This is the top left of your selected area.
Minecraft version 1.16.5 and below is currently not supported, but we are working on it! For the best results, use Minecraft version 1.21.4 or above.
If you choose to select an own world, be aware that Arnis will overwrite certain areas.

[[Arch Linux AUR package](https://aur.archlinux.org/packages/arnis)]

## üìö Documentation

Full documentation is available in the [GitHub Wiki](https://github.com/louis-e/arnis/wiki/), covering topics such as technical explanations, FAQs, contribution guidelines and roadmaps.

## :trophy: Open Source
#### Key objectives of this project
- **Modularity**: Ensure that all components (e.g., data fetching, processing, and world generation) are cleanly separated into distinct modules for better maintainability and scalability.
- **Performance Optimization**: We aim to keep a good performance and speed of the world generation process.
- **Comprehensive Documentation**: Detailed in-code documentation for a clear structure and logic.
- **User-Friendly Experience**: Focus on making the project easy to use for end users.
- **Cross-Platform Support**: We want this project to run smoothly on Windows, macOS, and Linux.

#### How to contribute
This project is open source and welcomes contributions from everyone! Whether you&#039;re interested in fixing bugs, improving performance, adding new features, or enhancing documentation, your input is valuable. Simply fork the repository, make your changes, and submit a pull request. Please respect the above mentioned key objectives. Contributions of all levels are appreciated, and your efforts help improve this tool for everyone.

Build and run it using: ```cargo run --release --no-default-features -- --path=&quot;C:/YOUR_PATH/.minecraft/saves/worldname&quot; --bbox=&quot;min_lng,min_lat,max_lng,max_lat&quot;```&lt;br&gt;
For the GUI: ```cargo run --release```&lt;br&gt;

&gt; You can use the parameter --debug to get a more detailed output of the processed values, which can be helpful for debugging and development.

After your pull request was merged, I will take care of regularly creating update releases which will include your changes.

## :star: Star History

&lt;a href=&quot;https://star-history.com/#louis-e/arnis&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=louis-e/arnis&amp;Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=louis-e/arnis&amp;Date&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=louis-e/arnis&amp;Date&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## :copyright: License Information
Copyright (c) 2022-2025 Louis Erbkamm (louis-e)

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.[^3]

Download Arnis only from the official source (https://github.com/louis-e/arnis/). Every other website providing a download and claiming to be affiliated with the project is unofficial and may be malicious.

The logo was made by @nxfx21.


[^1]: https://en.wikipedia.org/wiki/OpenStreetMap

[^2]: https://en.wikipedia.org/wiki/Arnis,_Germany

[^3]: https://github.com/louis-e/arnis/blob/main/LICENSE
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[GreptimeTeam/greptimedb]]></title>
            <link>https://github.com/GreptimeTeam/greptimedb</link>
            <guid>https://github.com/GreptimeTeam/greptimedb</guid>
            <pubDate>Tue, 10 Jun 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Open-source, cloud-native, unified observability database for metrics, logs and traces, supporting SQL/PromQL/Streaming. Available on GreptimeCloud.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GreptimeTeam/greptimedb">GreptimeTeam/greptimedb</a></h1>
            <p>Open-source, cloud-native, unified observability database for metrics, logs and traces, supporting SQL/PromQL/Streaming. Available on GreptimeCloud.</p>
            <p>Language: Rust</p>
            <p>Stars: 5,284</p>
            <p>Forks: 381</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://cdn.jsdelivr.net/gh/GreptimeTeam/greptimedb@main/docs/logo-text-padding.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://cdn.jsdelivr.net/gh/GreptimeTeam/greptimedb@main/docs/logo-text-padding-dark.png&quot;&gt;
    &lt;img alt=&quot;GreptimeDB Logo&quot; src=&quot;https://cdn.jsdelivr.net/gh/GreptimeTeam/greptimedb@main/docs/logo-text-padding.png&quot; width=&quot;400px&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;h2 align=&quot;center&quot;&gt;Real-Time &amp; Cloud-Native Observability  Database&lt;br/&gt;for metrics, logs, and traces&lt;/h2&gt;

&gt;  Delivers sub-second querying at PB scale and exceptional cost efficiency from edge to cloud.

&lt;div align=&quot;center&quot;&gt;
&lt;h3 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://greptime.com/product/cloud&quot;&gt;GreptimeCloud&lt;/a&gt; |
  &lt;a href=&quot;https://docs.greptime.com/&quot;&gt;User Guide&lt;/a&gt; |
  &lt;a href=&quot;https://greptimedb.rs/&quot;&gt;API Docs&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/issues/5446&quot;&gt;Roadmap 2025&lt;/a&gt;
&lt;/h4&gt;

&lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/releases/latest&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/v/release/GreptimeTeam/greptimedb.svg&quot; alt=&quot;Version&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/releases/latest&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/release-date/GreptimeTeam/greptimedb.svg&quot; alt=&quot;Releases&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://hub.docker.com/r/greptime/greptimedb/&quot;&gt;
&lt;img src=&quot;https://img.shields.io/docker/pulls/greptime/greptimedb.svg&quot; alt=&quot;Docker Pulls&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/actions/workflows/develop.yml&quot;&gt;
&lt;img src=&quot;https://github.com/GreptimeTeam/greptimedb/actions/workflows/develop.yml/badge.svg&quot; alt=&quot;GitHub Actions&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://codecov.io/gh/GrepTimeTeam/greptimedb&quot;&gt;
&lt;img src=&quot;https://codecov.io/gh/GrepTimeTeam/greptimedb/branch/main/graph/badge.svg?token=FITFDI3J3C&quot; alt=&quot;Codecov&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/greptimeTeam/greptimedb/blob/main/LICENSE&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/license/greptimeTeam/greptimedb&quot; alt=&quot;License&quot;/&gt;
&lt;/a&gt;

&lt;br/&gt;

&lt;a href=&quot;https://greptime.com/slack&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/slack-GreptimeDB-0abd59?logo=slack&amp;style=for-the-badge&quot; alt=&quot;Slack&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://twitter.com/greptime&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/twitter-follow_us-1d9bf0.svg?style=for-the-badge&quot; alt=&quot;Twitter&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://www.linkedin.com/company/greptime/&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/linkedin-connect_with_us-0a66c2.svg?style=for-the-badge&quot; alt=&quot;LinkedIn&quot;/&gt;
&lt;/a&gt;
&lt;/div&gt;

- [Introduction](#introduction)
- [‚≠ê Key Features](#features)
- [Quick Comparison](#quick-comparison)
- [Architecture](#architecture)
- [Try GreptimeDB](#try-greptimedb)
- [Getting Started](#getting-started)
- [Build From Source](#build-from-source)
- [Tools &amp; Extensions](#tools--extensions)
- [Project Status](#project-status)
- [Community](#community)
- [License](#license)
- [Commercial Support](#commercial-support)
- [Contributing](#contributing)
- [Acknowledgement](#acknowledgement)

## Introduction

**GreptimeDB** is an open-source, cloud-native database purpose-built for the unified collection and analysis of observability data (metrics, logs, and traces). Whether you‚Äôre operating on the edge, in the cloud, or across hybrid environments, GreptimeDB empowers real-time insights at massive scale ‚Äî all in one system.

## Features

|   Feature  | Description |
| --------- | ----------- |
| [Unified Observability Data](https://docs.greptime.com/user-guide/concepts/why-greptimedb) | Store metrics, logs, and traces as timestamped, contextual wide events. Query via [SQL](https://docs.greptime.com/user-guide/query-data/sql), [PromQL](https://docs.greptime.com/user-guide/query-data/promql), and [streaming](https://docs.greptime.com/user-guide/flow-computation/overview). |
| [High Performance &amp; Cost Effective](https://docs.greptime.com/user-guide/manage-data/data-index) | Written in Rust, with a distributed query engine, [rich indexing](https://docs.greptime.com/user-guide/manage-data/data-index), and optimized columnar storage, delivering sub-second responses at PB scale. |
| [Cloud-Native Architecture](https://docs.greptime.com/user-guide/concepts/architecture) | Designed for [Kubernetes](https://docs.greptime.com/user-guide/deployments/deploy-on-kubernetes/greptimedb-operator-management), with compute/storage separation, native object storage (AWS S3, Azure Blob, etc.) and seamless cross-cloud access. |
| [Developer-Friendly](https://docs.greptime.com/user-guide/protocols/overview) | Access via SQL/PromQL interfaces, REST API, MySQL/PostgreSQL protocols, and popular ingestion [protocols](https://docs.greptime.com/user-guide/protocols/overview). |
| [Flexible Deployment](https://docs.greptime.com/user-guide/deployments/overview) | Deploy anywhere: edge (including ARM/[Android](https://docs.greptime.com/user-guide/deployments/run-on-android)) or cloud, with unified APIs and efficient data sync. |

Learn more in [Why GreptimeDB](https://docs.greptime.com/user-guide/concepts/why-greptimedb) and [Observability 2.0 and the Database for It](https://greptime.com/blogs/2025-04-25-greptimedb-observability2-new-database).

## Quick Comparison

| Feature                         | GreptimeDB            | Traditional TSDB   | Log Stores      |
|----------------------------------|-----------------------|--------------------|-----------------|
| Data Types                      | Metrics, Logs, Traces | Metrics only       | Logs only       |
| Query Language                  | SQL, PromQL, Streaming|  Custom/PromQL     | Custom/DSL      |
| Deployment                      | Edge + Cloud          | Cloud/On-prem      | Mostly central  |
| Indexing &amp; Performance          | PB-Scale, Sub-second  | Varies             | Varies          |
| Integration                     | REST, SQL, Common protocols | Varies     | Varies          |

**Performance:**
* [GreptimeDB tops JSONBench&#039;s billion-record cold run test!](https://greptime.com/blogs/2025-03-18-jsonbench-greptimedb-performance)
* [TSBS Benchmark](https://github.com/GreptimeTeam/greptimedb/tree/main/docs/benchmarks/tsbs)

Read [more benchmark reports](https://docs.greptime.com/user-guide/concepts/features-that-you-concern#how-is-greptimedbs-performance-compared-to-other-solutions).

## Architecture

* Read the [architecture](https://docs.greptime.com/contributor-guide/overview/#architecture) document.
* [DeepWiki](https://deepwiki.com/GreptimeTeam/greptimedb/1-overview) provides an in-depth look at GreptimeDB:
  &lt;img alt=&quot;GreptimeDB System Overview&quot; src=&quot;docs/architecture.png&quot;&gt;

## Try GreptimeDB

### 1. [Live Demo](https://greptime.com/playground)

Experience GreptimeDB directly in your browser.

### 2. [GreptimeCloud](https://console.greptime.cloud/)

Start instantly with a free cluster.

### 3. Docker (Local Quickstart)

```shell
docker pull greptime/greptimedb
```

```shell
docker run -p 127.0.0.1:4000-4003:4000-4003 \
  -v &quot;$(pwd)/greptimedb_data:/greptimedb_data&quot; \
  --name greptime --rm \
  greptime/greptimedb:latest standalone start \
  --http-addr 0.0.0.0:4000 \
  --rpc-bind-addr 0.0.0.0:4001 \
  --mysql-addr 0.0.0.0:4002 \
  --postgres-addr 0.0.0.0:4003
```
Dashboard: [http://localhost:4000/dashboard](http://localhost:4000/dashboard)
[Full Install Guide](https://docs.greptime.com/getting-started/installation/overview)

**Troubleshooting:**
* Cannot connect to the database? Ensure that ports `4000`, `4001`, `4002`, and `4003` are not blocked by a firewall or used by other services.
* Failed to start? Check the container logs with `docker logs greptime` for further details.

## Getting Started

- [Quickstart](https://docs.greptime.com/getting-started/quick-start)
- [User Guide](https://docs.greptime.com/user-guide/overview)
- [Demo Scenes](https://github.com/GreptimeTeam/demo-scene)
- [FAQ](https://docs.greptime.com/faq-and-others/faq)

## Build From Source

**Prerequisites:**
* [Rust toolchain](https://www.rust-lang.org/tools/install) (nightly)
* [Protobuf compiler](https://grpc.io/docs/protoc-installation/) (&gt;= 3.15)
* C/C++ building essentials, including `gcc`/`g++`/`autoconf` and glibc library (eg. `libc6-dev` on Ubuntu and `glibc-devel` on Fedora)
* Python toolchain (optional): Required only if using some test scripts.

**Build and Run:**
```bash
make
cargo run -- standalone start
```

## Tools &amp; Extensions

- **Kubernetes:** [GreptimeDB Operator](https://github.com/GrepTimeTeam/greptimedb-operator)
- **Helm Charts:** [Greptime Helm Charts](https://github.com/GreptimeTeam/helm-charts)
- **Dashboard:** [Web UI](https://github.com/GreptimeTeam/dashboard)
- **SDKs/Ingester:** [Go](https://github.com/GreptimeTeam/greptimedb-ingester-go), [Java](https://github.com/GreptimeTeam/greptimedb-ingester-java), [C++](https://github.com/GreptimeTeam/greptimedb-ingester-cpp), [Erlang](https://github.com/GreptimeTeam/greptimedb-ingester-erl), [Rust](https://github.com/GreptimeTeam/greptimedb-ingester-rust), [JS](https://github.com/GreptimeTeam/greptimedb-ingester-js)
- **Grafana**: [Official Dashboard](https://github.com/GreptimeTeam/greptimedb/blob/main/grafana/README.md)

## Project Status

&gt; **Status:** Beta.
&gt; **GA (v1.0):** Targeted for mid 2025.

- Being used in production by early adopters
- Stable, actively maintained, with regular releases ([version info](https://docs.greptime.com/nightly/reference/about-greptimedb-version))
- Suitable for evaluation and pilot deployments

For production use, we recommend using the latest stable release.
[![Star History Chart](https://api.star-history.com/svg?repos=GreptimeTeam/GreptimeDB&amp;type=Date)](https://www.star-history.com/#GreptimeTeam/GreptimeDB&amp;Date)

If you find this project useful, a ‚≠ê would mean a lot to us!
&lt;img alt=&quot;Known Users&quot; src=&quot;https://greptime.com/logo/img/users.png&quot;/&gt;

## Community

We invite you to engage and contribute!

- [Slack](https://greptime.com/slack)
- [Discussions](https://github.com/GreptimeTeam/greptimedb/discussions)
- [Official Website](https://greptime.com/)
- [Blog](https://greptime.com/blogs/)
- [LinkedIn](https://www.linkedin.com/company/greptime/)
- [Twitter](https://twitter.com/greptime)

## License

GreptimeDB is licensed under the [Apache License 2.0](https://apache.org/licenses/LICENSE-2.0.txt).

## Commercial Support

Running GreptimeDB in your organization?
We offer enterprise add-ons, services, training, and consulting.
[Contact us](https://greptime.com/contactus) for details.

## Contributing

- Read our [Contribution Guidelines](https://github.com/GreptimeTeam/greptimedb/blob/main/CONTRIBUTING.md).
- Explore [Internal Concepts](https://docs.greptime.com/contributor-guide/overview.html) and [DeepWiki](https://deepwiki.com/GreptimeTeam/greptimedb).
- Pick up a [good first issue](https://github.com/GreptimeTeam/greptimedb/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) and join the #contributors [Slack](https://greptime.com/slack) channel.

## Acknowledgement

Special thanks to all contributors! See [AUTHORS.md](https://github.com/GreptimeTeam/greptimedb/blob/main/AUTHOR.md).

- Uses [Apache Arrow‚Ñ¢](https://arrow.apache.org/) (memory model)
- [Apache Parquet‚Ñ¢](https://parquet.apache.org/) (file storage)
- [Apache Arrow DataFusion‚Ñ¢](https://arrow.apache.org/datafusion/) (query engine)
- [Apache OpenDAL‚Ñ¢](https://opendal.apache.org/) (data access abstraction)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>