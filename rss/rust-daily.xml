<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Mon, 02 Mar 2026 00:07:07 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[ruvnet/wifi-densepose]]></title>
            <link>https://github.com/ruvnet/wifi-densepose</link>
            <guid>https://github.com/ruvnet/wifi-densepose</guid>
            <pubDate>Mon, 02 Mar 2026 00:07:07 GMT</pubDate>
            <description><![CDATA[WiFi DensePose turns commodity WiFi signals into real-time human pose estimation, vital sign monitoring, and presence detection â€” all without a single pixel of video.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ruvnet/wifi-densepose">ruvnet/wifi-densepose</a></h1>
            <p>WiFi DensePose turns commodity WiFi signals into real-time human pose estimation, vital sign monitoring, and presence detection â€” all without a single pixel of video.</p>
            <p>Language: Rust</p>
            <p>Stars: 17,228</p>
            <p>Forks: 1,930</p>
            <p>Stars today: 4,539 stars today</p>
            <h2>README</h2><pre># WiFi DensePose

**See through walls with WiFi.** No cameras. No wearables. Just radio waves.

WiFi DensePose turns commodity WiFi signals into real-time human pose estimation, vital sign monitoring, and presence detection â€” all without a single pixel of video. By analyzing Channel State Information (CSI) disturbances caused by human movement, the system reconstructs body position, breathing rate, and heartbeat using physics-based signal processing and machine learning.

[![Rust 1.85+](https://img.shields.io/badge/rust-1.85+-orange.svg)](https://www.rust-lang.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Tests: 542+](https://img.shields.io/badge/tests-542%2B-brightgreen.svg)](https://github.com/ruvnet/wifi-densepose)
[![Docker: 132 MB](https://img.shields.io/badge/docker-132%20MB-blue.svg)](https://hub.docker.com/r/ruvnet/wifi-densepose)
[![Vital Signs](https://img.shields.io/badge/vital%20signs-breathing%20%2B%20heartbeat-red.svg)](#vital-sign-detection)
[![ESP32 Ready](https://img.shields.io/badge/ESP32--S3-CSI%20streaming-purple.svg)](#esp32-s3-hardware-pipeline)
[![crates.io](https://img.shields.io/crates/v/wifi-densepose-ruvector.svg)](https://crates.io/crates/wifi-densepose-ruvector)

&gt; | What | How | Speed |
&gt; |------|-----|-------|
&gt; | **Pose estimation** | CSI subcarrier amplitude/phase â†’ DensePose UV maps | 54K fps (Rust) |
&gt; | **Breathing detection** | Bandpass 0.1-0.5 Hz â†’ FFT peak | 6-30 BPM |
&gt; | **Heart rate** | Bandpass 0.8-2.0 Hz â†’ FFT peak | 40-120 BPM |
&gt; | **Presence sensing** | RSSI variance + motion band power | &lt; 1ms latency |
&gt; | **Through-wall** | Fresnel zone geometry + multipath modeling | Up to 5m depth |

```bash
# 30 seconds to live sensing â€” no toolchain required
docker pull ruvnet/wifi-densepose:latest
docker run -p 3000:3000 ruvnet/wifi-densepose:latest
# Open http://localhost:3000
```

&gt; [!NOTE]
&gt; **CSI-capable hardware required.** Pose estimation, vital signs, and through-wall sensing rely on Channel State Information (CSI) â€” per-subcarrier amplitude and phase data that standard consumer WiFi does not expose. You need CSI-capable hardware (ESP32-S3 or a research NIC) for full functionality. Consumer WiFi laptops can only provide RSSI-based presence detection, which is significantly less capable.

&gt; **Hardware options** for live CSI capture:
&gt;
&gt; | Option | Hardware | Cost | Full CSI | Capabilities |
&gt; |--------|----------|------|----------|-------------|
&gt; | **ESP32 Mesh** (recommended) | 3-6x ESP32-S3 + WiFi router | ~$54 | Yes | Pose, breathing, heartbeat, motion, presence |
&gt; | **Research NIC** | Intel 5300 / Atheros AR9580 | ~$50-100 | Yes | Full CSI with 3x3 MIMO |
&gt; | **Any WiFi** | Windows, macOS, or Linux laptop | $0 | No | RSSI-only: coarse presence and motion |
&gt;
&gt; No hardware? Verify the signal processing pipeline with the deterministic reference signal: `python v1/data/proof/verify.py`

---

## ğŸ“– Documentation

| Document | Description |
|----------|-------------|
| [User Guide](docs/user-guide.md) | Step-by-step guide: installation, first run, API usage, hardware setup, training |
| [WiFi-Mat User Guide](docs/wifi-mat-user-guide.md) | Disaster response module: search &amp; rescue, START triage |
| [Build Guide](docs/build-guide.md) | Building from source (Rust and Python) |
| [Architecture Decisions](docs/adr/) | 27 ADRs covering signal processing, training, hardware, security, domain generalization |

---

## ğŸš€ Key Features

### Sensing

See people, breathing, and heartbeats through walls â€” using only WiFi signals already in the room.

| | Feature | What It Means |
|---|---------|---------------|
| ğŸ”’ | **Privacy-First** | Tracks human pose using only WiFi signals â€” no cameras, no video, no images stored |
| ğŸ’“ | **Vital Signs** | Detects breathing rate (6-30 breaths/min) and heart rate (40-120 bpm) without any wearable |
| ğŸ‘¥ | **Multi-Person** | Tracks multiple people simultaneously, each with independent pose and vitals â€” no hard software limit (physics: ~3-5 per AP with 56 subcarriers, more with multi-AP) |
| ğŸ§± | **Through-Wall** | WiFi passes through walls, furniture, and debris â€” works where cameras cannot |
| ğŸš‘ | **Disaster Response** | Detects trapped survivors through rubble and classifies injury severity (START triage) |

### Intelligence

The system learns on its own and gets smarter over time â€” no hand-tuning, no labeled data required.

| | Feature | What It Means |
|---|---------|---------------|
| ğŸ§  | **Self-Learning** | Teaches itself from raw WiFi data â€” no labeled training sets, no cameras needed to bootstrap ([ADR-024](docs/adr/ADR-024-contrastive-csi-embedding-model.md)) |
| ğŸ¯ | **AI Signal Processing** | Attention networks, graph algorithms, and smart compression replace hand-tuned thresholds â€” adapts to each room automatically ([RuVector](https://github.com/ruvnet/ruvector)) |
| ğŸŒ | **Works Everywhere** | Train once, deploy in any room â€” adversarial domain generalization strips environment bias so models transfer across rooms, buildings, and hardware ([ADR-027](docs/adr/ADR-027-cross-environment-domain-generalization.md)) |

### Performance &amp; Deployment

Fast enough for real-time use, small enough for edge devices, simple enough for one-command setup.

| | Feature | What It Means |
|---|---------|---------------|
| âš¡ | **Real-Time** | Analyzes WiFi signals in under 100 microseconds per frame â€” fast enough for live monitoring |
| ğŸ¦€ | **810x Faster** | Complete Rust rewrite: 54,000 frames/sec pipeline, 132 MB Docker image, 542+ tests |
| ğŸ³ | **One-Command Setup** | `docker pull ruvnet/wifi-densepose:latest` â€” live sensing in 30 seconds, no toolchain needed |
| ğŸ“¦ | **Portable Models** | Trained models package into a single `.rvf` file â€” runs on edge, cloud, or browser (WASM) |

---

## ğŸ”¬ How It Works

WiFi routers flood every room with radio waves. When a person moves â€” or even breathes â€” those waves scatter differently. WiFi DensePose reads that scattering pattern and reconstructs what happened:

```
WiFi Router â†’ radio waves pass through room â†’ hit human body â†’ scatter
    â†“
ESP32 / WiFi NIC captures 56+ subcarrier amplitudes &amp; phases (CSI) at 20 Hz
    â†“
Signal Processing cleans noise, removes interference, extracts motion signatures
    â†“
AI Backbone (RuVector) applies attention, graph algorithms, and compression
    â†“
Neural Network maps processed signals â†’ 17 body keypoints + vital signs
    â†“
Output: real-time pose, breathing rate, heart rate, presence, room fingerprint
```

No training cameras required â€” the [Self-Learning system (ADR-024)](docs/adr/ADR-024-contrastive-csi-embedding-model.md) bootstraps from raw WiFi data alone. [MERIDIAN (ADR-027)](docs/adr/ADR-027-cross-environment-domain-generalization.md) ensures the model works in any room, not just the one it trained in.

---

## ğŸ¢ Use Cases &amp; Applications

WiFi sensing works anywhere WiFi exists. No new hardware in most cases â€” just software on existing access points or a $8 ESP32 add-on. Because there are no cameras, deployments avoid privacy regulations (GDPR video, HIPAA imaging) by design.

**Scaling:** Each AP distinguishes ~3-5 people (56 subcarriers). Multi-AP multiplies linearly â€” a 4-AP retail mesh covers ~15-20 occupants. No hard software limit; the practical ceiling is signal physics.

| | Why WiFi sensing wins | Traditional alternative |
|---|----------------------|----------------------|
| ğŸ”’ | **No video, no GDPR/HIPAA imaging rules** | Cameras require consent, signage, data retention policies |
| ğŸ§± | **Works through walls, shelving, debris** | Cameras need line-of-sight per room |
| ğŸŒ™ | **Works in total darkness** | Cameras need IR or visible light |
| ğŸ’° | **$0-$8 per zone** (existing WiFi or ESP32) | Camera systems: $200-$2,000 per zone |
| ğŸ”Œ | **WiFi already deployed everywhere** | PIR/radar sensors require new wiring per room |

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ¥ Everyday&lt;/strong&gt; â€” Healthcare, retail, office, hospitality (commodity WiFi)&lt;/summary&gt;

| Use Case | What It Does | Hardware | Key Metric |
|----------|-------------|----------|------------|
| **Elderly care / assisted living** | Fall detection, nighttime activity monitoring, breathing rate during sleep â€” no wearable compliance needed | 1 ESP32-S3 per room ($8) | Fall alert &lt;2s |
| **Hospital patient monitoring** | Continuous breathing + heart rate for non-critical beds without wired sensors; nurse alert on anomaly | 1-2 APs per ward | Breathing: 6-30 BPM |
| **Emergency room triage** | Automated occupancy count + wait-time estimation; detect patient distress (abnormal breathing) in waiting areas | Existing hospital WiFi | Occupancy accuracy &gt;95% |
| **Retail occupancy &amp; flow** | Real-time foot traffic, dwell time by zone, queue length â€” no cameras, no opt-in, GDPR-friendly | Existing store WiFi + 1 ESP32 | Dwell resolution ~1m |
| **Office space utilization** | Which desks/rooms are actually occupied, meeting room no-shows, HVAC optimization based on real presence | Existing enterprise WiFi | Presence latency &lt;1s |
| **Hotel &amp; hospitality** | Room occupancy without door sensors, minibar/bathroom usage patterns, energy savings on empty rooms | Existing hotel WiFi | 15-30% HVAC savings |
| **Restaurants &amp; food service** | Table turnover tracking, kitchen staff presence, restroom occupancy displays â€” no cameras in dining areas | Existing WiFi | Queue wait Â±30s |
| **Parking garages** | Pedestrian presence in stairwells and elevators where cameras have blind spots; security alert if someone lingers | Existing WiFi | Through-concrete walls |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸŸï¸ Specialized&lt;/strong&gt; â€” Events, fitness, education, civic (CSI-capable hardware)&lt;/summary&gt;

| Use Case | What It Does | Hardware | Key Metric |
|----------|-------------|----------|------------|
| **Smart home automation** | Room-level presence triggers (lights, HVAC, music) that work through walls â€” no dead zones, no motion-sensor timeouts | 2-3 ESP32-S3 nodes ($24) | Through-wall range ~5m |
| **Fitness &amp; sports** | Rep counting, posture correction, breathing cadence during exercise â€” no wearable, no camera in locker rooms | 3+ ESP32-S3 mesh | Pose: 17 keypoints |
| **Childcare &amp; schools** | Naptime breathing monitoring, playground headcount, restricted-area alerts â€” privacy-safe for minors | 2-4 ESP32-S3 per zone | Breathing: Â±1 BPM |
| **Event venues &amp; concerts** | Crowd density mapping, crush-risk detection via breathing compression, emergency evacuation flow tracking | Multi-AP mesh (4-8 APs) | Density per mÂ² |
| **Stadiums &amp; arenas** | Section-level occupancy for dynamic pricing, concession staffing, emergency egress flow modeling | Enterprise AP grid | 15-20 per AP mesh |
| **Houses of worship** | Attendance counting without facial recognition â€” privacy-sensitive congregations, multi-room campus tracking | Existing WiFi | Zone-level accuracy |
| **Warehouse &amp; logistics** | Worker safety zones, forklift proximity alerts, occupancy in hazardous areas â€” works through shelving and pallets | Industrial AP mesh | Alert latency &lt;500ms |
| **Civic infrastructure** | Public restroom occupancy (no cameras possible), subway platform crowding, shelter headcount during emergencies | Municipal WiFi + ESP32 | Real-time headcount |
| **Museums &amp; galleries** | Visitor flow heatmaps, exhibit dwell time, crowd bottleneck alerts â€” no cameras near artwork (flash/theft risk) | Existing WiFi | Zone dwell Â±5s |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ¤– Robotics &amp; Industrial&lt;/strong&gt; â€” Autonomous systems, manufacturing, android spatial awareness&lt;/summary&gt;

WiFi sensing gives robots and autonomous systems a spatial awareness layer that works where LIDAR and cameras fail â€” through dust, smoke, fog, and around corners. The CSI signal field acts as a &quot;sixth sense&quot; for detecting humans in the environment without requiring line-of-sight.

| Use Case | What It Does | Hardware | Key Metric |
|----------|-------------|----------|------------|
| **Cobot safety zones** | Detect human presence near collaborative robots â€” auto-slow or stop before contact, even behind obstructions | 2-3 ESP32-S3 per cell | Presence latency &lt;100ms |
| **Warehouse AMR navigation** | Autonomous mobile robots sense humans around blind corners, through shelving racks â€” no LIDAR occlusion | ESP32 mesh along aisles | Through-shelf detection |
| **Android / humanoid spatial awareness** | Ambient human pose sensing for social robots â€” detect gestures, approach direction, and personal space without cameras always on | Onboard ESP32-S3 module | 17-keypoint pose |
| **Manufacturing line monitoring** | Worker presence at each station, ergonomic posture alerts, headcount for shift compliance â€” works through equipment | Industrial AP per zone | Pose + breathing |
| **Construction site safety** | Exclusion zone enforcement around heavy machinery, fall detection from scaffolding, personnel headcount | Ruggedized ESP32 mesh | Alert &lt;2s, through-dust |
| **Agricultural robotics** | Detect farm workers near autonomous harvesters in dusty/foggy field conditions where cameras are unreliable | Weatherproof ESP32 nodes | Range ~10m open field |
| **Drone landing zones** | Verify landing area is clear of humans â€” WiFi sensing works in rain, dust, and low light where downward cameras fail | Ground ESP32 nodes | Presence: &gt;95% accuracy |
| **Clean room monitoring** | Personnel tracking without cameras (particle contamination risk from camera fans) â€” gown compliance via pose | Existing cleanroom WiFi | No particulate emission |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ”¥ Extreme&lt;/strong&gt; â€” Through-wall, disaster, defense, underground&lt;/summary&gt;

These scenarios exploit WiFi&#039;s ability to penetrate solid materials â€” concrete, rubble, earth â€” where no optical or infrared sensor can reach. The WiFi-Mat disaster module (ADR-001) is specifically designed for this tier.

| Use Case | What It Does | Hardware | Key Metric |
|----------|-------------|----------|------------|
| **Search &amp; rescue (WiFi-Mat)** | Detect survivors through rubble/debris via breathing signature, START triage color classification, 3D localization | Portable ESP32 mesh + laptop | Through 30cm concrete |
| **Firefighting** | Locate occupants through smoke and walls before entry; breathing detection confirms life signs remotely | Portable mesh on truck | Works in zero visibility |
| **Prison &amp; secure facilities** | Cell occupancy verification, distress detection (abnormal vitals), perimeter sensing â€” no camera blind spots | Dedicated AP infrastructure | 24/7 vital signs |
| **Military / tactical** | Through-wall personnel detection, room clearing confirmation, hostage vital signs at standoff distance | Directional WiFi + custom FW | Range: 5m through wall |
| **Border &amp; perimeter security** | Detect human presence in tunnels, behind fences, in vehicles â€” passive sensing, no active illumination to reveal position | Concealed ESP32 mesh | Passive / covert |
| **Mining &amp; underground** | Worker presence in tunnels where GPS/cameras fail, breathing detection after collapse, headcount at safety points | Ruggedized ESP32 mesh | Through rock/earth |
| **Maritime &amp; naval** | Below-deck personnel tracking through steel bulkheads (limited range, requires tuning), man-overboard detection | Ship WiFi + ESP32 | Through 1-2 bulkheads |
| **Wildlife research** | Non-invasive animal activity monitoring in enclosures or dens â€” no light pollution, no visual disturbance | Weatherproof ESP32 nodes | Zero light emission |

&lt;/details&gt;

---

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ§  Self-Learning WiFi AI (ADR-024)&lt;/strong&gt; â€” Adaptive recognition, self-optimization, and intelligent anomaly detection&lt;/summary&gt;

Every WiFi signal that passes through a room creates a unique fingerprint of that space. WiFi-DensePose already reads these fingerprints to track people, but until now it threw away the internal &quot;understanding&quot; after each reading. The Self-Learning WiFi AI captures and preserves that understanding as compact, reusable vectors â€” and continuously optimizes itself for each new environment.

**What it does in plain terms:**
- Turns any WiFi signal into a 128-number &quot;fingerprint&quot; that uniquely describes what&#039;s happening in a room
- Learns entirely on its own from raw WiFi data â€” no cameras, no labeling, no human supervision needed
- Recognizes rooms, detects intruders, identifies people, and classifies activities using only WiFi
- Runs on an $8 ESP32 chip (the entire model fits in 55 KB of memory)
- Produces both body pose tracking AND environment fingerprints in a single computation

**Key Capabilities**

| What | How it works | Why it matters |
|------|-------------|----------------|
| **Self-supervised learning** | The model watches WiFi signals and teaches itself what &quot;similar&quot; and &quot;different&quot; look like, without any human-labeled data | Deploy anywhere â€” just plug in a WiFi sensor and wait 10 minutes |
| **Room identification** | Each room produces a distinct WiFi fingerprint pattern | Know which room someone is in without GPS or beacons |
| **Anomaly detection** | An unexpected person or event creates a fingerprint that doesn&#039;t match anything seen before | Automatic intrusion and fall detection as a free byproduct |
| **Person re-identification** | Each person disturbs WiFi in a slightly different way, creating a personal signature | Track individuals across sessions without cameras |
| **Environment adaptation** | MicroLoRA adapters (1,792 parameters per room) fine-tune the model for each new space | Adapts to a new room with minimal data â€” 93% less than retraining from scratch |
| **Memory preservation** | EWC++ regularization remembers what was learned during pretraining | Switching to a new task doesn&#039;t erase prior knowledge |
| **Hard-negative mining** | Training focuses on the most confusing examples to learn faster | Better accuracy with the same amount of training data |

**Architecture**

```
WiFi Signal [56 channels] â†’ Transformer + Graph Neural Network
                                  â”œâ†’ 128-dim environment fingerprint (for search + identification)
                                  â””â†’ 17-joint body pose (for human tracking)
```

**Quick Start**

```bash
# Step 1: Learn from raw WiFi data (no labels needed)
cargo run -p wifi-densepose-sensing-server -- --pretrain --dataset data/csi/ --pretrain-epochs 50

# Step 2: Fine-tune with pose labels for full capability
cargo run -p wifi-densepose-sensing-server -- --train --dataset data/mmfi/ --epochs 100 --save-rvf model.rvf

# Step 3: Use the model â€” extract fingerprints from live WiFi
cargo run -p wifi-densepose-sensing-server -- --model model.rvf --embed

# Step 4: Search â€” find similar environments or detect anomalies
cargo run -p wifi-densepose-sensing-server -- --model model.rvf --build-index env
```

**Training Modes**

| Mode | What you need | What you get |
|------|--------------|-------------|
| Self-Supervised | Just raw WiFi data | A model that understands WiFi signal structure |
| Supervised | WiFi data + body pose labels | Full pose tracking + environment fingerprints |
| Cross-Modal | WiFi data + camera footage | Fingerprints aligned with visual understanding |

**Fingerprint Index Types**

| Index | What it stores | Real-world use |
|-------|---------------|----------------|
| `env_fingerprint` | Average room fingerprint | &quot;Is this the kitchen or the bedroom?&quot; |
| `activity_pattern` | Activity boundaries | &quot;Is someone cooking, sleeping, or exercising?&quot; |
| `temporal_baseline` | Normal conditions | &quot;Something unusual just happened in this room&quot; |
| `person_track` | Individual movement signatures | &quot;Person A just entered the living room&quot; |

**Model Size**

| Component | Parameters | Memory (on ESP32) |
|-----------|-----------|-------------------|
| Transformer backbone | ~28,000 | 28 KB |
| Embedding projection head | ~25,000 | 25 KB |
| Per-room MicroLoRA adapter | ~1,800 | 2 KB |
| **Total** | **~55,000** | **55 KB** (of 520 KB

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[longbridge/gpui-component]]></title>
            <link>https://github.com/longbridge/gpui-component</link>
            <guid>https://github.com/longbridge/gpui-component</guid>
            <pubDate>Mon, 02 Mar 2026 00:07:06 GMT</pubDate>
            <description><![CDATA[Rust GUI components for building fantastic cross-platform desktop application by using GPUI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/longbridge/gpui-component">longbridge/gpui-component</a></h1>
            <p>Rust GUI components for building fantastic cross-platform desktop application by using GPUI.</p>
            <p>Language: Rust</p>
            <p>Stars: 10,518</p>
            <p>Forks: 478</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># GPUI Component

[![Build Status](https://github.com/longbridge/gpui-component/actions/workflows/ci.yml/badge.svg)](https://github.com/longbridge/gpui-component/actions/workflows/ci.yml) [![Docs](https://docs.rs/gpui-component/badge.svg)](https://docs.rs/gpui-component/) [![Crates.io](https://img.shields.io/crates/v/gpui-component.svg)](https://crates.io/crates/gpui-component)

UI components for building fantastic desktop applications using [GPUI](https://gpui.rs).

## Features

- **Richness**: 60+ cross-platform desktop UI components.
- **Native**: Inspired by macOS and Windows controls, combined with shadcn/ui design for a modern experience.
- **Ease of Use**: Stateless `RenderOnce` components, simple and user-friendly.
- **Customizable**: Built-in `Theme` and `ThemeColor`, supporting multi-theme and variable-based configurations.
- **Versatile**: Supports sizes like `xs`, `sm`, `md`, and `lg`.
- **Flexible Layout**: Dock layout for panel arrangements, resizing, and freeform (Tiles) layouts.
- **High Performance**: Virtualized Table and List components for smooth large-data rendering.
- **Content Rendering**: Native support for Markdown and simple HTML.
- **Charting**: Built-in charts for visualizing your data.
- **Editor**: High performance code editor (support up to 200K lines) with LSP (diagnostics, completion, hover, etc).
- **Syntax Highlighting**: Syntax highlighting for editor and markdown components using Tree Sitter.

## Showcase

Here is the first application: [Longbridge Pro](https://longbridge.com/desktop), built using GPUI Component.

&lt;img width=&quot;1763&quot; alt=&quot;Image&quot; src=&quot;https://github.com/user-attachments/assets/e1ecb9c3-2dd3-431e-bd97-5a819c30e551&quot; /&gt;

## Usage

```toml
gpui = &quot;0.2.2&quot;
gpui-component = &quot;0.5.1&quot;
```

### Basic Example

```rs
use gpui::*;
use gpui_component::{button::*, *};

pub struct HelloWorld;
impl Render for HelloWorld {
    fn render(&amp;mut self, _: &amp;mut Window, _: &amp;mut Context&lt;Self&gt;) -&gt; impl IntoElement {
        div()
            .v_flex()
            .gap_2()
            .size_full()
            .items_center()
            .justify_center()
            .child(&quot;Hello, World!&quot;)
            .child(
                Button::new(&quot;ok&quot;)
                    .primary()
                    .label(&quot;Let&#039;s Go!&quot;)
                    .on_click(|_, _, _| println!(&quot;Clicked!&quot;)),
            )
    }
}

fn main() {
    let app = Application::new();

    app.run(move |cx| {
        // This must be called before using any GPUI Component features.
        gpui_component::init(cx);

        cx.spawn(async move |cx| {
            cx.open_window(WindowOptions::default(), |window, cx| {
                let view = cx.new(|_| HelloWorld);
                // This first level on the window, should be a Root.
                cx.new(|cx| Root::new(view, window, cx))
            })?;

            Ok::&lt;_, anyhow::Error&gt;(())
        })
        .detach();
    });
}
```

### Icons

GPUI Component has an `Icon` element, but it does not include SVG files by default.

The example uses [Lucide](https://lucide.dev) icons, but you can use any icons you like. Just name the SVG files as defined in [IconName](https://github.com/longbridge/gpui-component/blob/main/crates/ui/src/icon.rs#L86). You can add any icons you need to your project.

## Development

We have a gallery of applications built with GPUI Component.

```bash
cargo run
```

More examples can be found in the `examples` directory. You can run them with `cargo run --example &lt;example_name&gt;`.

Check out [CONTRIBUTING.md](CONTRIBUTING.md) for more details.

## Compare to others

| Features              | GPUI Component                 | [Iced]             | [egui]                | [Qt 6]                                            |
| --------------------- | ------------------------------ | ------------------ | --------------------- | ------------------------------------------------- |
| Language              | Rust                           | Rust               | Rust                  | C++/QML                                           |
| Core Render           | GPUI                           | wgpu               | wgpu                  | QT                                                |
| License               | Apache 2.0                     | MIT                | MIT/Apache 2.0        | [Commercial/LGPL](https://www.qt.io/qt-licensing) |
| Min Binary Size [^1]  | 12MB                           | 11MB               | 5M                    | 20MB [^2]                                         |
| Cross-Platform        | Yes                            | Yes                | Yes                   | Yes                                               |
| Documentation         | Simple                         | Simple             | Simple                | Good                                              |
| Web                   | No                             | Yes                | Yes                   | Yes                                               |
| UI Style              | Modern                         | Basic              | Basic                 | Basic                                             |
| CJK Support           | Yes                            | Yes                | Bad                   | Yes                                               |
| Chart                 | Yes                            | No                 | No                    | Yes                                               |
| Table (Large dataset) | Yes&lt;br&gt;(Virtual Rows, Columns) | No                 | Yes&lt;br&gt;(Virtual Rows) | Yes&lt;br&gt;(Virtual Rows, Columns)                    |
| Table Column Resize   | Yes                            | No                 | Yes                   | Yes                                               |
| Text base             | Rope                           | [COSMIC Text] [^3] | trait TextBuffer [^4] | [QTextDocument]                                   |
| CodeEditor            | Simple                         | Simple             | Simple                | Basic API                                         |
| Dock Layout           | Yes                            | Yes                | Yes                   | Yes                                               |
| Syntax Highlight      | [Tree Sitter]                  | [Syntect]          | [Syntect]             | [QSyntaxHighlighter]                              |
| Markdown Rendering    | Yes                            | Yes                | Basic                 | No                                                |
| Markdown mix HTML     | Yes                            | No                 | No                    | No                                                |
| HTML Rendering        | Basic                          | No                 | No                    | Basic                                             |
| Text Selection        | TextView                       | No                 | Any Label             | Yes                                               |
| Custom Theme          | Yes                            | Yes                | Yes                   | Yes                                               |
| Built Themes          | Yes                            | No                 | No                    | No                                                |
| I18n                  | Yes                            | Yes                | Yes                   | Yes                                               |

&gt; Please submit an issue or PR if any mistakes or outdated are found.

[Iced]: https://github.com/iced-rs/iced
[egui]: https://github.com/emilk/egui
[QT 6]: https://www.qt.io/product/qt6
[Tree Sitter]: https://tree-sitter.github.io/tree-sitter/
[Syntect]: https://github.com/trishume/syntect
[QSyntaxHighlighter]: https://doc.qt.io/qt-6/qsyntaxhighlighter.html
[QTextDocument]: https://doc.qt.io/qt-6/qtextdocument.html
[COSMIC Text]: https://github.com/pop-os/cosmic-text

[^1]: Release builds by use simple hello world example.

[^2]: [Reducing Binary Size of Qt Applications](https://www.qt.io/blog/reducing-binary-size-of-qt-applications-part-3-more-platforms)

[^3]: Iced Editor: &lt;https://github.com/iced-rs/iced/blob/db5a1f6353b9f8520c4f9633d1cdc90242c2afe1/graphics/src/text/editor.rs#L65-L68&gt;

[^4]: egui TextBuffer: &lt;https://github.com/emilk/egui/blob/0a81372cfd3a4deda640acdecbbaf24bf78bb6a2/crates/egui/src/widgets/text_edit/text_buffer.rs#L20&gt;

## License

Apache-2.0

- UI design based on [shadcn/ui](https://ui.shadcn.com).
- Icons from [Lucide](https://lucide.dev).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lbjlaq/Antigravity-Manager]]></title>
            <link>https://github.com/lbjlaq/Antigravity-Manager</link>
            <guid>https://github.com/lbjlaq/Antigravity-Manager</guid>
            <pubDate>Mon, 02 Mar 2026 00:07:05 GMT</pubDate>
            <description><![CDATA[Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).ä¸“ä¸šçš„ Antigravity è´¦å·ç®¡ç†ä¸åˆ‡æ¢å·¥å…·ã€‚ä¸º Antigravity æä¾›ä¸€é”®æ— ç¼è´¦å·åˆ‡æ¢åŠŸèƒ½ã€‚]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lbjlaq/Antigravity-Manager">lbjlaq/Antigravity-Manager</a></h1>
            <p>Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).ä¸“ä¸šçš„ Antigravity è´¦å·ç®¡ç†ä¸åˆ‡æ¢å·¥å…·ã€‚ä¸º Antigravity æä¾›ä¸€é”®æ— ç¼è´¦å·åˆ‡æ¢åŠŸèƒ½ã€‚</p>
            <p>Language: Rust</p>
            <p>Stars: 24,896</p>
            <p>Forks: 2,771</p>
            <p>Stars today: 110 stars today</p>
            <h2>README</h2><pre># Antigravity Tools ğŸš€
&gt; ä¸“ä¸šçº§ AI è´¦å·ç®¡ç†ä¸åè®®ä»£ç†ç³»ç»Ÿ (v4.1.27)
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;public/icon.png&quot; alt=&quot;Antigravity Logo&quot; width=&quot;120&quot; height=&quot;120&quot; style=&quot;border-radius: 24px; box-shadow: 0 10px 30px rgba(0,0,0,0.15);&quot;&gt;

  &lt;h3&gt;æ‚¨çš„ä¸ªäººé«˜æ€§èƒ½ AI è°ƒåº¦ç½‘å…³&lt;/h3&gt;
  &lt;p&gt;ä¸ä»…ä»…æ˜¯è´¦å·ç®¡ç†ï¼Œæ›´æ˜¯æ‰“ç ´ API è°ƒç”¨å£å’çš„ç»ˆæè§£å†³æ–¹æ¡ˆã€‚&lt;/p&gt;
  
  &lt;p&gt;
    &lt;a href=&quot;https://github.com/lbjlaq/Antigravity-Manager&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Version-4.1.27-blue?style=flat-square&quot; alt=&quot;Version&quot;&gt;
    &lt;/a&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Tauri-v2-orange?style=flat-square&quot; alt=&quot;Tauri&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Backend-Rust-red?style=flat-square&quot; alt=&quot;Rust&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Frontend-React-61DAFB?style=flat-square&quot; alt=&quot;React&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-CC--BY--NC--SA--4.0-lightgrey?style=flat-square&quot; alt=&quot;License&quot;&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;#-æ ¸å¿ƒåŠŸèƒ½&quot;&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/a&gt; â€¢ 
    &lt;a href=&quot;#-ç•Œé¢å¯¼è§ˆ&quot;&gt;ç•Œé¢å¯¼è§ˆ&lt;/a&gt; â€¢ 
    &lt;a href=&quot;#-æŠ€æœ¯æ¶æ„&quot;&gt;æŠ€æœ¯æ¶æ„&lt;/a&gt; â€¢ 
    &lt;a href=&quot;#-å®‰è£…æŒ‡å—&quot;&gt;å®‰è£…æŒ‡å—&lt;/a&gt; â€¢ 
    &lt;a href=&quot;#-å¿«é€Ÿæ¥å…¥&quot;&gt;å¿«é€Ÿæ¥å…¥&lt;/a&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;strong&gt;ç®€ä½“ä¸­æ–‡&lt;/strong&gt; | 
    &lt;a href=&quot;./README_EN.md&quot;&gt;English&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

---

**Antigravity Tools** æ˜¯ä¸€ä¸ªä¸“ä¸ºå¼€å‘è€…å’Œ AI çˆ±å¥½è€…è®¾è®¡çš„å…¨åŠŸèƒ½æ¡Œé¢åº”ç”¨ã€‚å®ƒå°†å¤šè´¦å·ç®¡ç†ã€åè®®è½¬æ¢å’Œæ™ºèƒ½è¯·æ±‚è°ƒåº¦å®Œç¾ç»“åˆï¼Œä¸ºæ‚¨æä¾›ä¸€ä¸ªç¨³å®šã€æé€Ÿä¸”æˆæœ¬ä½å»‰çš„ **æœ¬åœ° AI ä¸­è½¬ç«™**ã€‚

é€šè¿‡æœ¬åº”ç”¨ï¼Œæ‚¨å¯ä»¥å°†å¸¸è§çš„ Web ç«¯ Session (Google/Anthropic) è½¬åŒ–ä¸ºæ ‡å‡†åŒ–çš„ API æ¥å£ï¼Œæ¶ˆé™¤ä¸åŒå‚å•†é—´çš„åè®®é¸¿æ²Ÿã€‚

## ğŸ’– èµåŠ©å•† (Sponsors)

| èµåŠ©å•† (Sponsor) | ç®€ä»‹ (Description) |
| :---: | :--- |
| &lt;img src=&quot;docs/images/packycode_logo.png&quot; width=&quot;200&quot; alt=&quot;PackyCode Logo&quot;&gt; | æ„Ÿè°¢ **PackyCode** å¯¹æœ¬é¡¹ç›®çš„èµåŠ©ï¼PackyCode æ˜¯ä¸€å®¶å¯é é«˜æ•ˆçš„ API ä¸­è½¬æœåŠ¡å•†ï¼Œæä¾› Claude Codeã€Codexã€Gemini ç­‰å¤šç§æœåŠ¡çš„ä¸­è½¬ã€‚PackyCode ä¸ºæœ¬é¡¹ç›®çš„ç”¨æˆ·æä¾›äº†ç‰¹åˆ«ä¼˜æƒ ï¼šä½¿ç”¨[æ­¤é“¾æ¥](https://www.packyapi.com/register?aff=Ctrler)æ³¨å†Œï¼Œå¹¶åœ¨å……å€¼æ—¶è¾“å…¥ **â€œCtrlerâ€** ä¼˜æƒ ç å³å¯äº«å— **ä¹æŠ˜ä¼˜æƒ **ã€‚ |
| &lt;img src=&quot;docs/images/AICodeMirror.jpg&quot; width=&quot;200&quot; alt=&quot;AICodeMirror Logo&quot;&gt; | æ„Ÿè°¢ AICodeMirror èµåŠ©äº†æœ¬é¡¹ç›®ï¼AICodeMirror æä¾› Claude Code / Codex / Gemini CLI å®˜æ–¹é«˜ç¨³å®šä¸­è½¬æœåŠ¡ï¼Œæ”¯æŒä¼ä¸šçº§é«˜å¹¶å‘ã€æé€Ÿå¼€ç¥¨ã€7Ã—24 ä¸“å±æŠ€æœ¯æ”¯æŒã€‚ Claude Code / Codex / Gemini å®˜æ–¹æ¸ é“ä½è‡³ 3.8 / 0.2 / 0.9 æŠ˜ï¼Œå……å€¼æ›´æœ‰æŠ˜ä¸ŠæŠ˜ï¼AICodeMirror ä¸º Antigravity-Manager çš„ç”¨æˆ·æä¾›äº†ç‰¹åˆ«ç¦åˆ©ï¼Œé€šè¿‡[æ­¤é“¾æ¥](https://www.aicodemirror.com/register?invitecode=MV5XUM)æ³¨å†Œçš„ç”¨æˆ·ï¼Œå¯äº«å—é¦–å……8æŠ˜ï¼Œä¼ä¸šå®¢æˆ·æœ€é«˜å¯äº« 7.5 æŠ˜ï¼ |

### â˜• æ”¯æŒé¡¹ç›® (Support)

å¦‚æœæ‚¨è§‰å¾—æœ¬é¡¹ç›®å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œæ¬¢è¿æ‰“èµä½œè€…ï¼

&lt;a href=&quot;https://www.buymeacoffee.com/Ctrler&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://cdn.buymeacoffee.com/buttons/v2/default-green.png&quot; alt=&quot;è¯·æˆ‘å–æ¯å’–å•¡&quot; style=&quot;height: 60px !important; width: 217px !important;&quot;&gt;&lt;/a&gt;

| æ”¯ä»˜å® (Alipay) | å¾®ä¿¡æ”¯ä»˜ (WeChat) | Buy Me a Coffee |
| :---: | :---: | :---: |
| ![Alipay](./docs/images/donate_alipay.png) | ![WeChat](./docs/images/donate_wechat.png) | ![Coffee](./docs/images/donate_coffee.png) |

## ğŸŒŸ æ·±åº¦åŠŸèƒ½è§£æ (Detailed Features)

### 1. ğŸ›ï¸ æ™ºèƒ½è´¦å·ä»ªè¡¨ç›˜ (Smart Dashboard)
*   **å…¨å±€å®æ—¶ç›‘æ§**: ä¸€çœ¼æ´å¯Ÿæ‰€æœ‰è´¦å·çš„å¥åº·çŠ¶å†µï¼ŒåŒ…æ‹¬ Gemini Proã€Gemini Flashã€Claude ä»¥åŠ Gemini ç»˜å›¾çš„ **å¹³å‡å‰©ä½™é…é¢**ã€‚
*   **æœ€ä½³è´¦å·æ¨è (Smart Recommendation)**: ç³»ç»Ÿä¼šæ ¹æ®å½“å‰æ‰€æœ‰è´¦å·çš„é…é¢å†—ä½™åº¦ï¼Œå®æ—¶ç®—æ³•ç­›é€‰å¹¶æ¨èâ€œæœ€ä½³è´¦å·â€ï¼Œæ”¯æŒ **ä¸€é”®åˆ‡æ¢**ã€‚
*   **æ´»è·ƒè´¦å·å¿«ç…§**: ç›´è§‚æ˜¾ç¤ºå½“å‰æ´»è·ƒè´¦å·çš„å…·ä½“é…é¢ç™¾åˆ†æ¯”åŠæœ€ååŒæ­¥æ—¶é—´ã€‚

### 2. ğŸ” å¼ºå¤§çš„è´¦å·ç®¡å®¶ (Account Management)
*   **OAuth 2.0 æˆæƒï¼ˆè‡ªåŠ¨/æ‰‹åŠ¨ï¼‰**: æ·»åŠ è´¦å·æ—¶ä¼šæå‰ç”Ÿæˆå¯å¤åˆ¶çš„æˆæƒé“¾æ¥ï¼Œæ”¯æŒåœ¨ä»»æ„æµè§ˆå™¨å®Œæˆæˆæƒï¼›å›è°ƒæˆåŠŸååº”ç”¨ä¼šè‡ªåŠ¨å®Œæˆå¹¶ä¿å­˜ï¼ˆå¿…è¦æ—¶å¯ç‚¹å‡»â€œæˆ‘å·²æˆæƒï¼Œç»§ç»­â€æ‰‹åŠ¨æ”¶å°¾ï¼‰ã€‚
*   **å¤šç»´åº¦å¯¼å…¥**: æ”¯æŒå•æ¡ Token å½•å…¥ã€JSON æ‰¹é‡å¯¼å…¥ï¼ˆå¦‚æ¥è‡ªå…¶ä»–å·¥å…·çš„å¤‡ä»½ï¼‰ï¼Œä»¥åŠä» V1 æ—§ç‰ˆæœ¬æ•°æ®åº“è‡ªåŠ¨çƒ­è¿ç§»ã€‚
*   **ç½‘å…³çº§è§†å›¾**: æ”¯æŒâ€œåˆ—è¡¨â€ä¸â€œç½‘æ ¼â€åŒè§†å›¾åˆ‡æ¢ã€‚æä¾› 403 å°ç¦æ£€æµ‹ï¼Œè‡ªåŠ¨æ ‡æ³¨å¹¶è·³è¿‡æƒé™å¼‚å¸¸çš„è´¦å·ã€‚

### 3. ğŸ”Œ åè®®è½¬æ¢ä¸ä¸­ç»§ (API Proxy)
*   **å…¨åè®®é€‚é… (Multi-Sink)**:
    *   **OpenAI æ ¼å¼**: æä¾› `/v1/chat/completions` ç«¯ç‚¹ï¼Œå…¼å®¹ 99% çš„ç°æœ‰ AI åº”ç”¨ã€‚
    *   **Anthropic æ ¼å¼**: æä¾›åŸç”Ÿ `/v1/messages` æ¥å£ï¼Œæ”¯æŒ **Claude Code CLI** çš„å…¨åŠŸèƒ½ï¼ˆå¦‚æ€æ€ç»´é“¾ã€ç³»ç»Ÿæç¤ºè¯ï¼‰ã€‚
    *   **Gemini æ ¼å¼**: æ”¯æŒ Google å®˜æ–¹ SDK ç›´æ¥è°ƒç”¨ã€‚
*   **æ™ºèƒ½çŠ¶æ€è‡ªæ„ˆ**: å½“è¯·æ±‚é‡åˆ° `429 (Too Many Requests)` æˆ– `401 (Expire)` æ—¶ï¼Œåç«¯ä¼šæ¯«ç§’çº§è§¦å‘ **è‡ªåŠ¨é‡è¯•ä¸é™é»˜è½®æ¢**ï¼Œç¡®ä¿ä¸šåŠ¡ä¸ä¸­æ–­ã€‚

### 4. ğŸ”€ æ¨¡å‹è·¯ç”±ä¸­å¿ƒ (Model Router)
*   **ç³»åˆ—åŒ–æ˜ å°„**: æ‚¨å¯ä»¥å°†å¤æ‚çš„åŸå§‹æ¨¡å‹ ID å½’ç±»åˆ°â€œè§„æ ¼å®¶æ—â€ï¼ˆå¦‚å°†æ‰€æœ‰ GPT-4 è¯·æ±‚ç»Ÿä¸€è·¯ç”±åˆ° `gemini-3-pro-high`ï¼‰ã€‚
*   **ä¸“å®¶çº§é‡å®šå‘**: æ”¯æŒè‡ªå®šä¹‰æ­£åˆ™è¡¨è¾¾å¼çº§æ¨¡å‹æ˜ å°„ï¼Œç²¾å‡†æ§åˆ¶æ¯ä¸€ä¸ªè¯·æ±‚çš„è½åœ°æ¨¡å‹ã€‚
*   **æ™ºèƒ½åˆ†çº§è·¯ç”± (Tiered Routing)**: [æ–°] ç³»ç»Ÿæ ¹æ®è´¦å·ç±»å‹ï¼ˆUltra/Pro/Freeï¼‰å’Œé…é¢é‡ç½®é¢‘ç‡è‡ªåŠ¨ä¼˜å…ˆçº§æ’åºï¼Œä¼˜å…ˆæ¶ˆè€—é«˜é€Ÿé‡ç½®è´¦å·ï¼Œç¡®ä¿é«˜é¢‘è°ƒç”¨ä¸‹çš„æœåŠ¡ç¨³å®šæ€§ã€‚
*   **åå°ä»»åŠ¡é™é»˜é™çº§**: [æ–°] è‡ªåŠ¨è¯†åˆ« Claude CLI ç­‰å·¥å…·ç”Ÿæˆçš„åå°è¯·æ±‚ï¼ˆå¦‚æ ‡é¢˜ç”Ÿæˆï¼‰ï¼Œæ™ºèƒ½é‡å®šå‘è‡³ Flash æ¨¡å‹ï¼Œä¿æŠ¤é«˜çº§æ¨¡å‹é…é¢ä¸è¢«æµªè´¹ã€‚

### 5. ğŸ¨ å¤šæ¨¡æ€ä¸ Imagen 3 æ”¯æŒ
*   **é«˜çº§ç”»è´¨æ§åˆ¶**: æ”¯æŒé€šè¿‡ OpenAI `size` (å¦‚ `1024x1024`, `16:9`) å‚æ•°è‡ªåŠ¨æ˜ å°„åˆ° Imagen 3 çš„ç›¸åº”è§„æ ¼ã€‚
*   **è¶…å¼º Body æ”¯æŒ**: åç«¯æ”¯æŒé«˜è¾¾ **100MB** (å¯é…ç½®) çš„ Payloadï¼Œå¤„ç† 4K é«˜æ¸…å›¾è¯†åˆ«ç»°ç»°æœ‰ä½™ã€‚

## ğŸ“¸ ç•Œé¢å¯¼è§ˆ (GUI Overview)

| | |
| :---: | :---: |
| ![ä»ªè¡¨ç›˜ - å…¨å±€é…é¢ç›‘æ§ä¸ä¸€é”®åˆ‡æ¢](docs/images/dashboard-light.png) &lt;br&gt; ä»ªè¡¨ç›˜ | ![è´¦å·åˆ—è¡¨ - é«˜å¯†åº¦é…é¢å±•ç¤ºä¸ 403 æ™ºèƒ½æ ‡æ³¨](docs/images/accounts-light.png) &lt;br&gt; è´¦å·åˆ—è¡¨ |
| ![å…³äºé¡µé¢ - å…³äº Antigravity Tools](docs/images/about-dark.png) &lt;br&gt; å…³äºé¡µé¢ | ![API åä»£ - æœåŠ¡æ§åˆ¶](docs/images/v3/proxy-settings.png) &lt;br&gt; API åä»£ |
| ![ç³»ç»Ÿè®¾ç½® - é€šç”¨é…ç½®](docs/images/settings-dark.png) &lt;br&gt; ç³»ç»Ÿè®¾ç½® | |

### ğŸ’¡ ä½¿ç”¨æ¡ˆä¾‹ (Usage Examples)

| | |
| :---: | :---: |
| ![Claude Code è”ç½‘æœç´¢ - ç»“æ„åŒ–æ¥æºä¸å¼•æ–‡æ˜¾ç¤º](docs/images/usage/claude-code-search.png) &lt;br&gt; Claude Code è”ç½‘æœç´¢ | ![Cherry Studio æ·±åº¦é›†æˆ - åŸç”Ÿå›æ˜¾æœç´¢å¼•æ–‡ä¸æ¥æºé“¾æ¥](docs/images/usage/cherry-studio-citations.png) &lt;br&gt; Cherry Studio æ·±åº¦é›†æˆ |
| ![Imagen 3 é«˜çº§ç»˜å›¾ - å®Œç¾è¿˜åŸ Prompt æ„å¢ƒä¸ç»†èŠ‚](docs/images/usage/image-gen-nebula.png) &lt;br&gt; Imagen 3 é«˜çº§ç»˜å›¾ | ![Kilo Code æ¥å…¥ - å¤šè´¦å·æé€Ÿè½®æ¢ä¸æ¨¡å‹ç©¿é€](docs/images/usage/kilo-code-integration.png) &lt;br&gt; Kilo Code æ¥å…¥ |

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„ (Architecture)

```mermaid
graph TD
    Client([å¤–éƒ¨åº”ç”¨: Claude Code/NextChat]) --&gt;|OpenAI/Anthropic| Gateway[Antigravity Axum Server]
    Gateway --&gt; Middleware[ä¸­é—´ä»¶: é‰´æƒ/é™æµ/æ—¥å¿—]
    Middleware --&gt; Router[Model Router: ID æ˜ å°„]
    Router --&gt; Dispatcher[è´¦å·åˆ†å‘å™¨: è½®è¯¢/æƒé‡]
    Dispatcher --&gt; Mapper[åè®®è½¬æ¢å™¨: Request Mapper]
    Mapper --&gt; Upstream[ä¸Šæ¸¸è¯·æ±‚: Google/Anthropic API]
    Upstream --&gt; ResponseMapper[å“åº”è½¬æ¢å™¨: Response Mapper]
    ResponseMapper --&gt; Client
```

##  å®‰è£…æŒ‡å— (Installation)

### é€‰é¡¹ A: ç»ˆç«¯å®‰è£… (æ¨è)

#### è·¨å¹³å°ä¸€é”®å®‰è£…è„šæœ¬

è‡ªåŠ¨æ£€æµ‹æ“ä½œç³»ç»Ÿã€æ¶æ„å’ŒåŒ…ç®¡ç†å™¨ï¼Œä¸€æ¡å‘½ä»¤å®Œæˆä¸‹è½½ä¸å®‰è£…ã€‚

**Linux / macOS:**
```bash
curl -fsSL https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/v4.1.27/install.sh | bash
```

**Windows (PowerShell):**
```powershell
irm https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/main/install.ps1 | iex
```

&gt; **æ”¯æŒçš„æ ¼å¼**: Linux (`.deb` / `.rpm` / `.AppImage`) | macOS (`.dmg`) | Windows (NSIS `.exe`)
&gt;
&gt; **é«˜çº§ç”¨æ³•**: å®‰è£…æŒ‡å®šç‰ˆæœ¬ `curl -fsSL ... | bash -s -- --version 4.1.27`ï¼Œé¢„è§ˆæ¨¡å¼ `curl -fsSL ... | bash -s -- --dry-run`

#### macOS - Homebrew
å¦‚æœæ‚¨å·²å®‰è£… [Homebrew](https://brew.sh/)ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š

```bash
# 1. è®¢é˜…æœ¬ä»“åº“çš„ Tap
brew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager

# 2. å®‰è£…åº”ç”¨
brew install --cask antigravity-tools
```
&gt; **æç¤º**: å¦‚æœé‡åˆ°æƒé™é—®é¢˜ï¼Œå»ºè®®æ·»åŠ  `--no-quarantine` å‚æ•°ã€‚

#### Arch Linux
æ‚¨å¯ä»¥é€‰æ‹©é€šè¿‡ä¸€é”®å®‰è£…è„šæœ¬æˆ– Homebrew è¿›è¡Œå®‰è£…ï¼š

**æ–¹å¼ 1ï¼šä¸€é”®å®‰è£…è„šæœ¬ (æ¨è)**
```bash
curl -sSL https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/main/deploy/arch/install.sh | bash
```

**æ–¹å¼ 2ï¼šé€šè¿‡ Homebrew** (å¦‚æœæ‚¨å·²å®‰è£… [Linuxbrew](https://sh.brew.sh/))
```bash
brew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager
brew install --cask antigravity-tools
```

#### å…¶ä»– Linux å‘è¡Œç‰ˆ
å®‰è£…åä¼šè‡ªåŠ¨å°† AppImage æ·»åŠ åˆ°äºŒè¿›åˆ¶è·¯å¾„å¹¶é…ç½®å¯æ‰§è¡Œæƒé™ã€‚

### é€‰é¡¹ B: æ‰‹åŠ¨ä¸‹è½½
å‰å¾€ [GitHub Releases](https://github.com/lbjlaq/Antigravity-Manager/releases) ä¸‹è½½å¯¹åº”ç³»ç»Ÿçš„åŒ…ï¼š
*   **macOS**: `.dmg` (æ”¯æŒ Apple Silicon &amp; Intel)
*   **Windows**: `.msi` æˆ– ä¾¿æºç‰ˆ `.zip`
*   **Linux**: `.deb` æˆ– `AppImage`

### é€‰é¡¹ C: Docker éƒ¨ç½² (æ¨èç”¨äº NAS/æœåŠ¡å™¨)
å¦‚æœæ‚¨å¸Œæœ›åœ¨å®¹å™¨åŒ–ç¯å¢ƒä¸­è¿è¡Œï¼Œæˆ‘ä»¬æä¾›äº†åŸç”Ÿçš„ Docker é•œåƒã€‚è¯¥é•œåƒå†…ç½®äº†å¯¹ v4.0.2 åŸç”Ÿ Headless æ¶æ„çš„æ”¯æŒï¼Œå¯è‡ªåŠ¨æ‰˜ç®¡å‰ç«¯é™æ€èµ„æºï¼Œå¹¶é€šè¿‡æµè§ˆå™¨ç›´æ¥è¿›è¡Œç®¡ç†ã€‚

```bash
# æ–¹å¼ 1: ç›´æ¥è¿è¡Œ (æ¨è)
# - API_KEY: å¿…å¡«ã€‚ç”¨äºæ‰€æœ‰åè®®çš„ AI è¯·æ±‚é‰´å®šã€‚
# - WEB_PASSWORD: å¯é€‰ã€‚ç”¨äºç®¡ç†åå°ç™»å½•ã€‚è‹¥ä¸è®¾ç½®åˆ™é»˜è®¤ä½¿ç”¨ API_KEYã€‚
docker run -d --name antigravity-manager \
  -p 8045:8045 \
  -e API_KEY=sk-your-api-key \
  -e WEB_PASSWORD=your-login-password \
  -e ABV_MAX_BODY_SIZE=104857600 \
  -v ~/.antigravity_tools:/root/.antigravity_tools \
  lbjlaq/antigravity-manager:latest

# å¿˜è®°å¯†é’¥ï¼Ÿæ‰§è¡Œ docker logs antigravity-manager æˆ– grep -E &#039;&quot;api_key&quot;|&quot;admin_password&quot;&#039; ~/.antigravity_tools/gui_config.json

#### ğŸ” é‰´æƒé€»è¾‘è¯´æ˜
*   **åœºæ™¯ Aï¼šä»…è®¾ç½®äº† `API_KEY`**
    - **Web ç™»å½•**ï¼šä½¿ç”¨ `API_KEY` è¿›å…¥åå°ã€‚
    - **API è°ƒç”¨**ï¼šä½¿ç”¨ `API_KEY` è¿›è¡Œ AI è¯·æ±‚é‰´æƒã€‚
*   **åœºæ™¯ Bï¼šåŒæ—¶è®¾ç½®äº† `API_KEY` å’Œ `WEB_PASSWORD` (æ¨è)**
    - **Web ç™»å½•**ï¼š**å¿…é¡»**ä½¿ç”¨ `WEB_PASSWORD`ï¼Œä½¿ç”¨ API Key å°†è¢«æ‹’ç»ï¼ˆæ›´å®‰å…¨ï¼‰ã€‚
    - **API è°ƒç”¨**ï¼šç»Ÿä¸€ä½¿ç”¨ `API_KEY`ã€‚è¿™æ ·æ‚¨å¯ä»¥å°† API Key åˆ†å‘ç»™æˆå‘˜ï¼Œè€Œä¿ç•™å¯†ç ä»…ä¾›ç®¡ç†å‘˜ä½¿ç”¨ã€‚

#### ğŸ†™ æ—§ç‰ˆæœ¬å‡çº§æŒ‡å¼•
å¦‚æœæ‚¨æ˜¯ä» v4.0.1 åŠæ›´æ—©ç‰ˆæœ¬å‡çº§ï¼Œç³»ç»Ÿé»˜è®¤æœªè®¾ç½® `WEB_PASSWORD`ã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»»ä¸€æ–¹å¼è®¾ç½®ï¼š
1.  **Web UI ç•Œé¢ (æ¨è)**ï¼šä½¿ç”¨åŸæœ‰ `API_KEY` ç™»å½•åï¼Œåœ¨ **API åä»£è®¾ç½®** é¡µé¢æ‰‹åŠ¨è®¾ç½®å¹¶ä¿å­˜ã€‚æ–°å¯†ç å°†æŒä¹…åŒ–å­˜å‚¨åœ¨ `gui_config.json` ä¸­ã€‚
2.  **ç¯å¢ƒå˜é‡ (Docker)**ï¼šåœ¨å¯åŠ¨å®¹å™¨æ—¶å¢åŠ  `-e WEB_PASSWORD=æ‚¨çš„æ–°å¯†ç `ã€‚**æ³¨æ„ï¼šç¯å¢ƒå˜é‡å…·æœ‰æœ€é«˜ä¼˜å…ˆçº§ï¼Œå°†è¦†ç›– UI ä¸­çš„ä»»ä½•ä¿®æ”¹ã€‚**
3.  **é…ç½®æ–‡ä»¶ (æŒä¹…åŒ–)**ï¼šç›´æ¥ä¿®æ”¹ `~/.antigravity_tools/gui_config.json`ï¼Œåœ¨ `proxy` å¯¹è±¡ä¸­ä¿®æ”¹æˆ–æ·»åŠ  `&quot;admin_password&quot;: &quot;æ‚¨çš„æ–°å¯†ç &quot;` å­—æ®µã€‚
    - *æ³¨ï¼š`WEB_PASSWORD` æ˜¯ç¯å¢ƒå˜é‡åï¼Œ`admin_password` æ˜¯é…ç½®æ–‡ä»¶ä¸­çš„ JSON é”®åã€‚*

&gt; [!TIP]
&gt; **å¯†ç ä¼˜å…ˆçº§é€»è¾‘ (Priority)**:
&gt; - **ç¬¬ä¸€ä¼˜å…ˆçº§ (ç¯å¢ƒå˜é‡)**: `ABV_WEB_PASSWORD` æˆ– `WEB_PASSWORD`ã€‚åªè¦è®¾ç½®äº†ç¯å¢ƒå˜é‡ï¼Œç³»ç»Ÿå°†å§‹ç»ˆä½¿ç”¨å®ƒã€‚
&gt; - **ç¬¬äºŒä¼˜å…ˆçº§ (é…ç½®æ–‡ä»¶)**: `gui_config.json` ä¸­çš„ `admin_password` å­—æ®µã€‚UI çš„â€œä¿å­˜â€æ“ä½œä¼šæ›´æ–°æ­¤å€¼ã€‚
&gt; - **ä¿åº•å›é€€ (å‘åå…¼å®¹)**: è‹¥ä¸Šè¿°å‡æœªè®¾ç½®ï¼Œåˆ™å›é€€ä½¿ç”¨ `API_KEY` ä½œä¸ºç™»å½•å¯†ç ã€‚

# æ–¹å¼ 2: ä½¿ç”¨ Docker Compose
# 1. è¿›å…¥é¡¹ç›®çš„ docker ç›®å½•
cd docker
# 2. å¯åŠ¨æœåŠ¡
docker compose up -d
```
&gt; **è®¿é—®åœ°å€**: `http://localhost:8045` (ç®¡ç†åå°) | `http://localhost:8045/v1` (API Base)
&gt; **ç³»ç»Ÿè¦æ±‚**:
&gt; - **å†…å­˜**: å»ºè®® **1GB** (æœ€å° 256MB)ã€‚
&gt; - **æŒä¹…åŒ–**: éœ€æŒ‚è½½ `/root/.antigravity_tools` ä»¥ä¿å­˜æ•°æ®ã€‚
&gt; - **æ¶æ„**: æ”¯æŒ x86_64 å’Œ ARM64ã€‚
&gt; **è¯¦æƒ…è§**: [Docker éƒ¨ç½²æŒ‡å— (docker)](./docker/README.md)

---

Copyright Â© 2024-2026 [lbjlaq](https://github.com/lbjlaq)

### ğŸ› ï¸ å¸¸è§é—®é¢˜æ’æŸ¥ (Troubleshooting)

#### macOS æç¤ºâ€œåº”ç”¨å·²æŸåï¼Œæ— æ³•æ‰“å¼€â€ï¼Ÿ
ç”±äº macOS çš„å®‰å…¨æœºåˆ¶ï¼Œé App Store ä¸‹è½½çš„åº”ç”¨å¯èƒ½ä¼šè§¦å‘æ­¤æç¤ºã€‚æ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¿«é€Ÿä¿®å¤ï¼š

1.  **å‘½ä»¤è¡Œä¿®å¤** (æ¨è):
    æ‰“å¼€ç»ˆç«¯ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
    ```bash
    sudo xattr -rd com.apple.quarantine &quot;/Applications/Antigravity Tools.app&quot;
    ```
2.  **Homebrew å®‰è£…æŠ€å·§**:
    å¦‚æœæ‚¨ä½¿ç”¨ brew å®‰è£…ï¼Œå¯ä»¥æ·»åŠ  `--no-quarantine` å‚æ•°æ¥è§„é¿æ­¤é—®é¢˜ï¼š
    ```bash
    brew install --cask --no-quarantine antigravity-tools
    ```

## ğŸ”Œ å¿«é€Ÿæ¥å…¥ç¤ºä¾‹

### ğŸ” OAuth æˆæƒæµç¨‹ï¼ˆæ·»åŠ è´¦å·ï¼‰
1. æ‰“å¼€â€œAccounts / è´¦å·â€ â†’ â€œæ·»åŠ è´¦å·â€ â†’ â€œOAuthâ€ã€‚
2. å¼¹çª—ä¼šåœ¨ç‚¹å‡»æŒ‰é’®å‰é¢„ç”Ÿæˆæˆæƒé“¾æ¥ï¼›ç‚¹å‡»é“¾æ¥å³å¯å¤åˆ¶åˆ°ç³»ç»Ÿå‰ªè´´æ¿ï¼Œç„¶åç”¨ä½ å¸Œæœ›çš„æµè§ˆå™¨æ‰“å¼€å¹¶å®Œæˆæˆæƒã€‚
3. æˆæƒå®Œæˆåæµè§ˆå™¨ä¼šæ‰“å¼€æœ¬åœ°å›è°ƒé¡µå¹¶æ˜¾ç¤ºâ€œâœ… æˆæƒæˆåŠŸ!â€ã€‚
4. åº”ç”¨ä¼šè‡ªåŠ¨ç»§ç»­å®Œæˆæˆæƒå¹¶ä¿å­˜è´¦å·ï¼›å¦‚æœªè‡ªåŠ¨å®Œæˆï¼Œå¯ç‚¹å‡»â€œæˆ‘å·²æˆæƒï¼Œç»§ç»­â€æ‰‹åŠ¨å®Œæˆã€‚

&gt; æç¤ºï¼šæˆæƒé“¾æ¥åŒ…å«ä¸€æ¬¡æ€§å›è°ƒç«¯å£ï¼Œè¯·å§‹ç»ˆä½¿ç”¨å¼¹çª—é‡Œç”Ÿæˆçš„æœ€æ–°é“¾æ¥ï¼›å¦‚æœæˆæƒæ—¶åº”ç”¨æœªè¿è¡Œæˆ–å¼¹çª—å·²å…³é—­ï¼Œæµè§ˆå™¨å¯èƒ½ä¼šæç¤º `localhost refused connection`ã€‚

### å¦‚ä½•æ¥å…¥ Claude Code CLI?
1.  å¯åŠ¨ Antigravityï¼Œå¹¶åœ¨â€œAPI åä»£â€é¡µé¢å¼€å¯æœåŠ¡ã€‚
2.  åœ¨ç»ˆç«¯æ‰§è¡Œï¼š
```bash
export ANTHROPIC_API_KEY=&quot;sk-antigravity&quot;
export ANTHROPIC_BASE_URL=&quot;http://127.0.0.1:8045&quot;
claude
```

### å¦‚ä½•æ¥å…¥ OpenCode?
1.  è¿›å…¥ **API åä»£**é¡µé¢ â†’ **å¤–éƒ¨ Providers** â†’ ç‚¹å‡» **OpenCode Sync** å¡ç‰‡ã€‚
2.  ç‚¹å‡» **Sync** æŒ‰é’®ï¼Œå°†è‡ªåŠ¨ç”Ÿæˆ `~/.config/opencode/opencode.json` é…ç½®æ–‡ä»¶ï¼š
    - åˆ›å»ºç‹¬ç«‹ provider `antigravity-manager`ï¼ˆä¸è¦†ç›– google/anthropic åŸç”Ÿé…ç½®ï¼‰
    - å¯é€‰ï¼šå‹¾é€‰ **Sync accounts** å¯¼å‡º `antigravity-accounts.json`ï¼ˆplugin-compatible v3 æ ¼å¼ï¼‰ï¼Œä¾› OpenCode æ’ä»¶ç›´æ¥å¯¼å…¥
3.  ç‚¹å‡» **Clear Config** å¯ä¸€é”®æ¸…é™¤ Manager é…ç½®å¹¶æ¸…ç† legacy æ®‹ç•™ï¼›ç‚¹å‡» **Restore** å¯ä»å¤‡ä»½æ¢å¤ã€‚
4.  Windows ç”¨æˆ·è·¯å¾„ä¸º `C:\Users\&lt;ç”¨æˆ·å&gt;\.config\opencode\`ï¼ˆä¸ `~/.config/opencode` è§„åˆ™ä¸€è‡´ï¼‰ã€‚

**å¿«é€ŸéªŒè¯å‘½ä»¤ï¼š**
```bash
# æµ‹è¯• antigravity-manager providerï¼ˆæ”¯æŒ --variantï¼‰
opencode run &quot;test&quot; --model antigravity-manager/claude-sonnet-4-5-thinking --variant high

# è‹¥å·²å®‰è£… opencode-antigravity-auth æ’ä»¶ï¼ŒéªŒè¯ google provider ä»å¯ç‹¬ç«‹å·¥ä½œ
opencode run &quot;test&quot; --model google/antigravity-claude-sonnet-4-5-thinking --variant max
```

### å¦‚ä½•æ¥å…¥ Kilo Code?
1.  **åè®®é€‰æ‹©**: å»ºè®®ä¼˜å…ˆä½¿ç”¨ **Gemini åè®®**ã€‚
2.  **Base URL**: å¡«å†™ `http://127.0.0.1:8045`ã€‚
3.  **æ³¨æ„**: 
    - **OpenAI åè®®é™åˆ¶**: Kilo Code åœ¨ä½¿ç”¨ OpenAI æ¨¡å¼æ—¶ï¼Œå…¶è¯·æ±‚è·¯å¾„ä¼šå åŠ äº§ç”Ÿ `/v1/chat/completions/responses` è¿™ç§éæ ‡å‡†è·¯å¾„ï¼Œå¯¼è‡´ Antigravity è¿”å› 404ã€‚å› æ­¤è¯·åŠ¡å¿…å¡«å…¥ Base URL åé€‰æ‹© Gemini æ¨¡å¼ã€‚
    - **æ¨¡å‹æ˜ å°„**: Kilo Code ä¸­çš„æ¨¡å‹åç§°å¯èƒ½ä¸ Antigravity é»˜è®¤è®¾ç½®ä¸ä¸€è‡´ï¼Œå¦‚é‡åˆ°æ— æ³•è¿æ¥ï¼Œè¯·åœ¨â€œæ¨¡å‹æ˜ å°„â€é¡µé¢è®¾ç½®è‡ªå®šä¹‰æ˜ å°„ï¼Œå¹¶æŸ¥çœ‹**æ—¥å¿—æ–‡ä»¶**è¿›è¡Œè°ƒè¯•ã€‚

### å¦‚ä½•åœ¨ Python ä¸­ä½¿ç”¨?
```python
import openai

client = openai.OpenAI(
    api_key=&quot;sk-antigravity&quot;,
    base_url=&quot;http://127.0.0.1:8045/v1&quot;
)

response = client.chat.completions.create(
    model=&quot;gemini-3-flash&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä½ å¥½ï¼Œè¯·è‡ªæˆ‘ä»‹ç»&quot;}]
)
print(response.choices[0].message.content)
```

### å¦‚ä½•ä½¿ç”¨å›¾ç‰‡ç”Ÿæˆ (Imagen 3)?

#### æ–¹å¼ä¸€ï¼šOpenAI Images API (æ¨è)
```python
import openai

client = openai.OpenAI(
    api_key=&quot;sk-antigravity&quot;,
    base_url=&quot;http://127.0.0.1:8045/v1&quot;
)

# ç”Ÿæˆå›¾ç‰‡
response = client.images.generate(
    model=&quot;gemini-3-pro-image&quot;,
    prompt=&quot;ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚ï¼Œèµ›åšæœ‹å…‹ï¼Œéœ“è™¹ç¯&quot;,
    size=&quot;1920x1080&quot;,      # æ”¯æŒä»»æ„ WIDTHxHEIGHT æ ¼å¼ï¼Œè‡ªåŠ¨è®¡ç®—å®½é«˜æ¯”
    quality=&quot;hd&quot;,          # &quot;standard&quot; | &quot;hd&quot; | &quot;medium&quot;
    n=1,
    response_format=&quot;b64_json&quot;
)

# ä¿å­˜å›¾ç‰‡
import base64
image_data = base64.b64decode(response.data[0].b64_json)
with open(&quot;output.png&quot;, &quot;wb&quot;) as f:
    f.write(image_data)
```

**æ”¯æŒçš„å‚æ•°**ï¼š
- **`size`**: ä»»æ„ `WIDTHxHEIGHT` æ ¼å¼ï¼ˆå¦‚ `1280x720`, `1024x1024`, `1920x1080`ï¼‰ï¼Œè‡ªåŠ¨è®¡ç®—å¹¶æ˜ å°„åˆ°æ ‡å‡†å®½é«˜æ¯”ï¼ˆ21:9, 16:9, 9:16, 4:3, 3:4, 1:1ï¼‰
- **`quality`**: 
  - `&quot;hd&quot;` â†’ 4K åˆ†è¾¨ç‡ï¼ˆé«˜è´¨é‡ï¼‰
  - `&quot;medium&quot;` â†’ 2K åˆ†è¾¨ç‡ï¼ˆä¸­ç­‰è´¨é‡ï¼‰
  - `&quot;standard&quot;` â†’ é»˜è®¤åˆ†è¾¨ç‡ï¼ˆæ ‡å‡†è´¨é‡ï¼‰
- **`n`**: ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-10ï¼‰
- **`response_format`**: `&quot;b64_json&quot;` æˆ– `&quot;url&quot;`ï¼ˆData URIï¼‰

#### æ–¹å¼äºŒï¼šChat API + å‚æ•°è®¾ç½® (âœ¨ æ–°å¢)

**æ‰€æœ‰åè®®**ï¼ˆOpenAIã€Claudeï¼‰çš„ Chat API ç°åœ¨éƒ½æ”¯æŒç›´æ¥ä¼ é€’ `size` å’Œ `quality` å‚æ•°ï¼š

```python
# OpenAI Chat API
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image&quot;,
    size=&quot;1920x1080&quot;,      # âœ… æ”¯æŒä»»æ„ WIDTHxHEIGHT æ ¼å¼
    quality=&quot;hd&quot;,          # âœ… &quot;standard&quot; | &quot;hd&quot; | &quot;medium&quot;
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚&quot;}]
)
```

```bash
# Claude Messages API
curl -X POST http://127.0.0.1:8045/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-antigravity&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gemini-3-pro-image&quot;,
    &quot;size&quot;: &quot;1280x720&quot;,
    &quot;quality&quot;: &quot;hd&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸€åªå¯çˆ±çš„çŒ«å’ª&quot;}]
  }&#039;
```

```

**å‚æ•°ä¼˜å…ˆçº§**: `imageSize` å‚æ•° &gt; `quality` å‚æ•° &gt; æ¨¡å‹åç¼€

**âœ¨ æ–°å¢ `imageSize` å‚æ•°æ”¯æŒ**:

é™¤äº† `quality` å‚æ•°å¤–,ç°åœ¨è¿˜æ”¯æŒç›´æ¥ä½¿ç”¨ Gemini åŸç”Ÿçš„ `imageSize` å‚æ•°:

```python
# ä½¿ç”¨ imageSize å‚æ•°(æœ€é«˜ä¼˜å…ˆçº§)
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image&quot;,
    size=&quot;16:9&quot;,           # å®½é«˜æ¯”
    imageSize=&quot;4K&quot;,        # âœ¨ ç›´æ¥æŒ‡å®šåˆ†è¾¨ç‡: &quot;1K&quot; | &quot;2K&quot; | &quot;4K&quot;
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚&quot;}]
)
```

```bash
# Claude Messages API ä¹Ÿæ”¯æŒ imageSize
curl -X POST http://127.0.0.1:8045/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-antigravity&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gemini-3-pro-image&quot;,
    &quot;size&quot;: &quot;1280x720&quot;,
    &quot;imageSize&quot;: &quot;4K&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸€åªå¯çˆ±çš„çŒ«å’ª&quot;}]
  }&#039;
```

**å‚æ•°è¯´æ˜**:
- **`imageSize`**: ç›´æ¥æŒ‡å®šåˆ†è¾¨ç‡ (`&quot;1K&quot;` / `&quot;2K&quot;` / `&quot;4K&quot;`)
- **`quality`**: é€šè¿‡è´¨é‡ç­‰çº§æ¨æ–­åˆ†è¾¨ç‡ (`&quot;standard&quot;` â†’ 1K, `&quot;medium&quot;` â†’ 2K, `&quot;hd&quot;` â†’ 4K)
- **ä¼˜å…ˆçº§**: å¦‚æœåŒæ—¶æŒ‡å®š `imageSize` å’Œ `quality`,ç³»ç»Ÿä¼šä¼˜å…ˆä½¿ç”¨ `imageSize`


#### æ–¹å¼ä¸‰ï¼šChat æ¥å£ + æ¨¡å‹åç¼€
```python
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image-16-9-4k&quot;,  # æ ¼å¼ï¼šgemini-3-pro-image-[æ¯”ä¾‹]-[è´¨é‡]
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚&quot;}]
)
```

**æ¨¡å‹åç¼€è¯´æ˜**ï¼š
- **å®½é«˜æ¯”**: `-16-9`, `-9-16`, `-4-3`, `-3-4`, `-21-9`, `-1-1`
- **è´¨é‡**: `-4k` (4K), `-2k` (2K), ä¸åŠ åç¼€ï¼ˆæ ‡å‡†ï¼‰
- **ç¤ºä¾‹**: `gemini-3-pro-image-16-9-4k` â†’ 16:9 æ¯”ä¾‹ + 4K åˆ†è¾¨ç‡

#### æ–¹å¼å››ï¼šCherry Studio ç­‰å®¢æˆ·ç«¯è®¾ç½®
åœ¨æ”¯æŒ OpenAI åè®®çš„å®¢æˆ·ç«¯ï¼ˆå¦‚ Cherry Studioï¼‰ä¸­ï¼Œå¯ä»¥é€šè¿‡**æ¨¡å‹è®¾ç½®**é¡µé¢é…ç½®å›¾ç‰‡ç”Ÿæˆå‚æ•°ï¼š

1. **è¿›å…¥æ¨¡å‹è®¾ç½®**ï¼šé€‰æ‹© `gemini-3-pro-image` æ¨¡å‹
2. **é…ç½®å‚æ•°**ï¼š
   - **Size (å°ºå¯¸)**: è¾“å…¥ä»»æ„ `WIDTHxHEIGHT` æ ¼å¼ï¼ˆå¦‚ `1920x1080`, `1024x1024`ï¼‰
   - **Quality (è´¨é‡)**: é€‰æ‹© `standard` / `hd` / `medium`
   - **Number (æ•°é‡)**: è®¾ç½®ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-10ï¼‰
3. **å‘é€è¯·æ±‚**ï¼šç›´æ¥åœ¨å¯¹è¯æ¡†ä¸­è¾“å…¥å›¾ç‰‡æè¿°å³å¯

**å‚æ•°æ˜ å°„è§„åˆ™**ï¼š
- `size: &quot;1920x1080&quot;` â†’ è‡ªåŠ¨è®¡ç®—ä¸º `16:9` å®½é«˜æ¯”
- `quality: &quot;hd&quot;` â†’ æ˜ å°„ä¸º `4K` åˆ†è¾¨ç‡
- `quality: &quot;medium&quot;` â†’ æ˜ å°„ä¸º `2K` åˆ†è¾¨ç‡


## ğŸ“ å¼€å‘è€…ä¸ç¤¾åŒº

*   **ç‰ˆæœ¬æ¼”è¿› (Changelog)**:
    *   **v4.1.27 (2026-03-01)**:
        -   **[æ ¸å¿ƒä¼˜åŒ–] ä»£ç†é…ç½®åˆå§‹åŒ–ä¸å·¥å…·å›¾ç‰‡ä¿ç•™ä¿®å¤ (Issue #2156)**:
            -   **è¡¥å…¨é»˜è®¤é…ç½®**: ä¿®å¤äº† `ProxyConfig` é»˜è®¤åˆå§‹åŒ–æ—¶ç¼ºå¤± `global_system_prompt`ã€`proxy_pool` å’Œ `image_thinking_mode` å­—æ®µå¯¼è‡´çš„ç¼–è¯‘å¤±è´¥é—®é¢˜ã€‚
            -   **æ¨¡å¼åŒ¹é…å®Œå–„**: è¡¥å……äº† `OpenAIContentBlock` æšä¸¾åŒ¹é…ä¸­çš„æœªçŸ¥ç±»å‹å…œåº•åˆ†æ”¯ (`_ =&gt; {}`)ï¼Œæ¶ˆé™¤éç©·å°½åŒ¹é…çš„ç¼–è¯‘è­¦å‘Š/é”™è¯¯ã€‚
            -   **å›¾ç‰‡æ— æ¡ä»¶ä¿ç•™**: ç§»é™¤å†—ä½™çš„ `preserve_tool_result_images` å¼€å…³ï¼Œç°å·²å¼ºåˆ¶ä¿ç•™ `tool_result` ä¸­çš„å›¾ç‰‡æ•°æ®ç»“æ„ï¼Œè½¬ä¸ºå¤§æ¨¡å‹æ”¯æŒçš„ `inlineData` ç»“æ„ï¼Œå¤§å¹…ç®€åŒ–é€»è¾‘ã€‚
        -   **[åŠŸèƒ½å¢å¼º] ä¿®æ”¹ docker-compose.yml çš„é…ç½® (PR #2185)**:
            -   **å‘½åç©ºé—´æ›´æ–°**: å°†æ„å»ºçš„é»˜è®¤é•œåƒåç§°ä» `antigravity-manager` æ›´æ–°ä¸º `lbjlaq/antigravity-manager`ã€‚
            -   **ç¯å¢ƒå˜é‡å ä½ç¬¦**: ä¸ºç¯å¢ƒå˜é‡æ·»åŠ äº†å¸¦é»˜è®¤å€¼çš„å ä½ç¬¦è¯­æ³•ï¼Œå…è®¸ç”¨æˆ·é€šè¿‡å®¿ä¸»æœºçš„ç¯å¢ƒå˜é‡æˆ– `.env` æ–‡ä»¶æ¥çµæ´»è¦†ç›–é»˜è®¤é…ç½®ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] OpenCode thinking budget å‚æ•°å…¨é¢å…¼å®¹ (Issue #2186)**:
            -   **æ¶æ„æ”¯æŒ**ï¼šè§£å†³äº† Vercel AI SDK (`@ai-sdk/anthropic`) é…åˆ OpenCode ä½¿ç”¨æ—¶ï¼Œå› åŸç”Ÿè›‡å½¢å‘½å `budget_tokens` å¯¼è‡´ç³»ç»Ÿæ— æ³•å¯åŠ¨å¹¶æŠ›å‡º `AI_UnsupportedFunctionalityError: &#039;thinking requires a budget&#039;` çš„é—®é¢˜ã€‚
            -   **åŒå­—æ®µè¾“å‡º**ï¼šåœ¨å‘ OpenCode / Claude CLI ç­‰å¤–éƒ¨å®¢æˆ·ç«¯åŒæ­¥æ¨¡å‹é…ç½®æ—¶ï¼Œè‡ªåŠ¨åŒæ—¶è¾“å‡ºæ ‡å‡†çš„ `budget_tokens` ä¸å°é©¼å³°çš„ `budgetTokens` å­—æ®µã€‚
            -   **æœåŠ¡ç«¯é€‚é…**ï¼šåç«¯é…ç½®è§£æå™¨ç°å·²åŸç”Ÿæ”¯æŒè¿™ä¸¤ç§å‘½åå˜ä½“ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³å…è´¹è´¦å·é…é¢è€—å°½åçš„æ— é™é‡è¯•ä¸è·¯ç”±æ­»é”é—®é¢˜ (Issue #2184)**ï¼š
            -   **é—®é¢˜æ ¹æº**ï¼šä¿®è¡¥äº† Google API `fetchAvailableModels` æ¥å£åœ¨ç‰¹å®šè´Ÿè½½ä¸‹æ— æ³•æ­£ç¡®è¿”å› `remainingFraction` çš„ç¼ºé™·ã€‚ç”±äºç¼ºå¤± `project` æ ‡è¯†ï¼Œå¯¼è‡´æ¥å£é”™è¯¯åœ°ä¸ºå·²è€—å°½é…é¢ï¼ˆHTTP 429ï¼‰çš„è´¦å·è¿”å› `1.0`ï¼ˆ100%ï¼‰ï¼Œè¿›è€Œå¯¼è‡´æ™ºèƒ½è·¯ç”±ç®—æ³•å°†è¯·æ±‚æŒç»­åˆ†é…ç»™ä¸å¯ç”¨è´¦å·ï¼Œå¼•å‘é•¿æ—¶é—´é‡è¯•åŠé…é¢æ˜¾ç¤ºé”™è¯¯ã€‚
            -   **è´Ÿè½½ä¿®å¤**ï¼šä¿®æ”¹é…é¢åˆ·æ–°è¯·æ±‚ï¼Œåœ¨è´Ÿè½½ä¸­ç²¾å‡†æ³¨å…¥æ­£ç¡®çš„ `{&quot;project&quot;: project_id}` ç»“æ„ã€‚æ¢å¤äº†é…é¢ä¿¡æ¯çš„å‡†ç¡®æ„ŸçŸ¥ï¼Œå¹¶åœ¨æœªç ´ååŸç”Ÿå­—æ®µï¼ˆå¦‚ `supportsThinking`ï¼‰çš„å‰æä¸‹å®ç°äº†æ¥å£å®Œå…¨å…¼å®¹ã€‚
            -   **è‡ªæ„ˆæ¢å¤**ï¼šé€šè¿‡è¯»å–çœŸå®é…é¢ï¼Œç³»ç»Ÿç°å·²èƒ½å¤Ÿå®æ—¶è¯†åˆ«å…è´¹è´¦å·çš„è€—å°½çŠ¶æ€å¹¶å°†å…¶å¯ç”¨åº¦ç½®ä¸º 0%ï¼Œæ— ç¼è§¦å‘å¤šè´¦å·è‡ªæ„ˆè½®è¯¢ï¼ˆSmart Status Self-healingï¼‰ï¼Œè§£å†³è¯·æ±‚å—é˜»ä¸é•¿ç­‰å¾…é—®é¢˜ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³é¦–é¡µ Gemini ç»˜å›¾å¹³å‡é…é¢æ˜¾ç¤ºä¸º 0 çš„é—®é¢˜ (Issue #2160)**ï¼š
            -   **åŒ¹é…æ›´æ–°**ï¼šå°† Dashboard ä¸­çš„ç»˜å›¾æ¨¡å‹åŒ¹é…é€»è¾‘ä»ç¡¬ç¼–ç çš„ `gemini-3-pro-image` æ›´æ–°ä¸ºåŒ…å«æœ€æ–°çš„ `gemini-3.1-flash-image`ã€‚
            -   **é…ç½®åŒæ­¥**ï¼šåœ¨ `modelConfig.ts` ä¸­è¡¥å…¨äº†æ–°ç‰ˆç»˜å›¾æ¨¡å‹çš„ UI å®šä¹‰ï¼Œç¡®ä¿å›¾æ ‡å’Œæ ‡ç­¾æ­£å¸¸æ¸²æŸ“ã€‚
        -   **[æ ¸å¿ƒåŠŸèƒ½] å…¨åè®®åŠ¨æ€æ¨¡å‹è§„æ ¼ (Model Specs) é›†æˆ (Issue #2176)**ï¼š
            -   **åŠ¨æ€å¼•æ“**ï¼šå®ç°äº†â€œåŠ¨æ€ä¼˜å…ˆã€é™æ€å…œåº•â€çš„è§„æ ¼å¼•æ“ï¼Œä¼˜å…ˆè¯†åˆ« API è¿”å›çš„ `max_output_tokens` ç­‰ç¡¬é™é¢æ•°æ®ã€‚
            -   **é™æ€èµ„æº**ï¼šå¼•å…¥ `model_specs.json` é›†ä¸­ç®¡ç† 30+ ç§æ¨¡å‹çš„é»˜è®¤å‚æ•°ï¼Œå½»åº•å‘Šåˆ«æ˜ å°„å™¨ä¸­çš„ç¡¬ç¼–ç é€»è¾‘ã€‚
            -   **åè®®æ³¨å…¥**ï¼šç»Ÿä¸€äº† OpenAIã€Claude å’Œ Gemini åè®®å¤„ç†å™¨å¯¹ Token é™é¢çš„æ³¨å…¥æ–¹å¼ï¼Œå¢å¼ºäº†è·¨ç‰ˆæœ¬å…¼å®¹æ€§ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] æ·±åº¦è§£å†³ Claude -&gt; Gemini 3 è·¯å¾„ä¸‹çš„ 400 INVALID_ARGUMENT å¼‚å¸¸**ï¼š
            -   **è‡ªé€‚åº”è¯†åˆ«**ï¼šä¿®æ­£äº†è‡ªé€‚åº”æ¨¡å¼é€»è¾‘ï¼Œç¡®ä¿æ˜ å°„åçš„ Gemini 3 æ¨¡å‹èƒ½æ­£ç¡®ä½¿ç”¨ `thinkingLevel` æ”¯æŒï¼Œè€Œéå¤±æ•ˆçš„ budget é€»è¾‘ã€‚
            -   **å†²çªè§„é¿**ï¼šå®ç°äº†å‚æ•°æ’ä»–æ€§æ£€æŸ¥ï¼Œåœ¨å¼€å¯åˆ†çº§æ€ç»´æ—¶è‡ªåŠ¨å‰¥ç¦»ä¸å…¼å®¹çš„ `thinkingBudget`ã€‚
            -   **Token æº¢å‡ºä¿æŠ¤**ï¼šä¸º `maxOutputTokens` è‡ªåŠ¨æå‡è¡¥é½é€»è¾‘å¢åŠ äº† `65536` çš„æ¨¡å‹ç¡¬ä¸Šé™ä¿æŠ¤ï¼Œæ ¹é™¤å‚æ•°è¶Šç•Œå¯¼è‡´çš„è¯·æ±‚å¤±è´¥ã€‚
    *   **v4.1.26 (2026-02-27)**:
        -   **[åŠŸèƒ½å¢å¼º] ä¼˜åŒ–é…é¢åˆ·æ–°é€»è¾‘ï¼Œæ”¯æŒåŒæ­¥ç¦ç”¨è´¦å·**:
            -   **é€»è¾‘æ”¾å®½**: â€œåˆ·æ–°æ‰€æœ‰â€å’Œâ€œæ‰¹é‡åˆ·æ–°â€ç°åœ¨ä¸å†è·³è¿‡æ ‡è®°ä¸º `disabled` æˆ– `proxy_disabled` çš„è´¦å·ã€‚
            -   **è‡ªåŠ¨æ¢å¤**: å…è®¸é€šè¿‡åˆ·æ–°æ“ä½œå°è¯•é‡æ–°æ¿€æ´»å›  Token è¿‡æœŸæˆ–ä¸´æ—¶é”™è¯¯è€Œè¢«ç¦ç”¨çš„è´¦å·ï¼Œæå‡äº†å¤šè´¦å·ç®¡ç†çš„çµæ´»æ€§ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ Windows ç³»ç»Ÿä¸‹åå°ä»»åŠ¡å¯¼è‡´ cmd é»‘æ¡†é—ªçƒçš„é—®é¢˜**:
            -   **é™é»˜æ‰§è¡Œ**: é€šè¿‡ä¸º `std::process::Command` å°è£…æ³¨å…¥ `CREATE_NO_WINDOW` æ ‡å¿—ï¼Œè§£å†³äº†åœ¨ Windows ç«¯åº”ç”¨åº•å±‚ç»„ä»¶ï¼ˆå¦‚ç‰ˆæœ¬æ¢æµ‹ã€é‡å¯æ›´æ–°ç­‰ï¼‰è°ƒç”¨ç³»ç»Ÿå‘½ä»¤æ—¶å¼•å‘çš„å‘½ä»¤è¡Œçª—å£ä¸€é—ªè€Œè¿‡çš„è§†è§‰å¹²æ‰°ï¼Œç¡®ä¿å…¨è¿‡ç¨‹æ— è¾¹æ¡†é™é»˜æ‰§è¡Œã€‚
    *   **v4.1.25 (2026-02-27)**:
        -   **[æ ¸å¿ƒåŠŸèƒ½] åŠ¨æ€ç”»å›¾æ¨¡å‹ä¸æ–°æ¶æ„æ”¯æŒ**:
            -   **åŠ¨æ€è§£æ**: ç§»é™¤äº†é’ˆå¯¹ `gemini-3-pro-image` çš„ç¡¬ç¼–ç é™åˆ¶ã€‚é€šè¿‡æ–°å¢çš„ `clean_image_model_name` æ™ºèƒ½æ¸…æ´—åç¼€ï¼ˆå¦‚ `-4k`, `-16x9`ï¼‰ï¼Œå…¨é¢å…¼å®¹å¦‚ `gemini-3.1-flash-image` ç­‰ä»»æ„æœªæ¥æ–°å¢çš„ç”»å›¾æ¨¡å‹ã€‚
            -   **é…é¢è‡ªé€‚åº”**: ä¼˜åŒ–äº† `normalize_to_standard_id`ï¼Œä½¿ç”¨ `image` å…³é”®è¯å®½æ³›åŒ¹é…ï¼Œç¡®ä¿æ–°æ¨¡å‹ä¹Ÿèƒ½æ­£ç¡®è§¦å‘é…é¢ä¿æŠ¤æœºåˆ¶ã€‚
        -   **[æ ¸å¿ƒåŠŸèƒ½] èŠå¤©æ¥å£ (Chat Completions) ç”»å›¾æ‹¦æˆªæ”¯æŒ**:
            -   **è·¨ç•Œèåˆ**: OpenAI å’Œ Claude åè®®çš„å¯¹è¯æµç°åœ¨èƒ½æ™ºèƒ½æ¢æµ‹ç”»åƒç”Ÿæˆæ„å›¾ã€‚å½“ä½¿ç”¨å¸¦æœ‰ `image` çš„æ¨¡å‹åæ—¶ï¼Œç³»ç»Ÿä¼šå°†å¸¸è§„æ–‡æœ¬ç”Ÿæˆè¯·æ±‚é™é»˜è½¬ç§»ç»™é«˜çº§ç”»å›¾å¼•æ“ã€‚
            -   **æµå¼å›æ˜¾**: ç”Ÿæˆå®Œæˆåï¼Œé€šè¿‡ Markdown æ ¼å¼ï¼ˆ`![Generated Image](url)`ï¼‰ä»¥ SSE æµå¼è¿”å›å›¾ç‰‡é“¾æ¥ï¼Œå®Œç¾é€‚é…æ‰€æœ‰æ”¯æŒ Markdown çš„èŠå¤©å®¢æˆ·ç«¯ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] å½»åº•ä¿®å¤ç”»å›¾é‡å®šå‘ 404 ä¸å‚æ•°ç©¿é€å¤±æ•ˆ**:
            -   **404 ç§»é™¤**: ç§»é™¤äº†åº•å±‚è°ƒç”¨ä¸­æ®‹ç•™çš„æ—§æ¨¡å‹ç¡¬ç¼–ç ï¼Œæ ¹é™¤å› æ¨¡å‹ä¿¡æ¯ä¸ä¸€è‡´å¯¼è‡´çš„ 404 Not Found å´©æºƒåŠè´¦å·å—æŸã€‚
            -   **ç²¾å‡†å‚æ•°ç»§æ‰¿**: ä¿®å¤äº†æœªä¼ å‚æ•°æ—¶ç³»ç»Ÿå¼ºåˆ¶å¡å…¥é»˜è®¤ `1024x1024` çš„è¡Œä¸ºã€‚ç°åœ¨ï¼Œå¦‚æœæ¨¡å‹åå¸¦æœ‰åç¼€ï¼ˆå¦‚ `gemini-3-pro-image-16x9-4k`ï¼‰ï¼Œåå°ä¼šä¸¥æ ¼ä¼˜å…ˆè§£æåç¼€åˆ†è¾¨ç‡è¿›è¡Œç©¿é€ç»˜å›¾ã€‚
    *   **v4.1.24 (2026-02-26)**:
        -   **[åŠŸèƒ½è°ƒæ•´] ç¦ç”¨è‡ªåŠ¨é¢„çƒ­è°ƒåº¦ç¨‹åºï¼Œä¿ç•™æ‰‹åŠ¨é¢„çƒ­**:
            -   **å˜æ›´è¯´æ˜**: ä¸ºäº†å‡å°‘ä¸å¿…è¦çš„åå°èµ„æºå ç”¨ï¼Œæœ¬ç‰ˆæœ¬å·²æ³¨é‡Šæ‰è‡ªåŠ¨é¢„çƒ­ï¼ˆSmart Warmupï¼‰çš„åå°è°ƒåº¦é€»è¾‘ã€‚
            -   **è®¾ç½®éšè—**: è®¾ç½®é¡µé¢ä¸­çš„â€œæ™ºèƒ½é¢„çƒ­â€é…ç½®é¡¹å·²éšè—ã€‚
            -   **æ‰‹åŠ¨ä¿ç•™**: è´¦å·ç®¡ç†é¡µé¢çš„æ‰‹åŠ¨é¢„çƒ­åŠŸèƒ½ä¿æŒä¸å˜ï¼Œä»å¯æ­£å¸¸ä½¿ç”¨ã€‚
            -   **æ¢å¤æŒ‡å¼•**: å¦‚æœæ‚¨éœ€è¦è‡ªåŠ¨é¢„çƒ­åŠŸèƒ½ï¼Œå¯ä»¥è‡ªè¡Œæ‹‰å–æœ¬é¡¹ç›®æºä»£ç ï¼Œåœ¨ `src-tauri/src/lib.rs` ä¸­å–æ¶ˆ `start_scheduler` çš„æ³¨é‡Šå¹¶è§£é™¤ `Settings.tsx` ä¸­ç›¸å…³ UI çš„æ³¨é‡Šåé‡æ–°ç¼–è¯‘ä½¿ç”¨ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] æ™ºèƒ½ç‰ˆæœ¬æŒ‡çº¹é€‰æ‹©ä¸å¯åŠ¨ Panic ä¿®å¤ (Issue #2123)**:
            -   **é—®é¢˜æ ¹æº**: 1) `constants.rs` ä¸­çš„ `KNOWN_STABLE_VERSION` ç¡¬ç¼–ç äº†ä½ç‰ˆæœ¬å·ï¼Œå½“æœ¬åœ° IDE æ£€æµ‹å¤±è´¥æ—¶å›é€€è¯¥ç‰ˆæœ¬ä½œä¸ºè¯·æ±‚å¤´ï¼Œå¯¼è‡´ Google æ‹’ç» Gemini 3.1 Pro æ¨¡å‹ã€‚2) æ–°å¢çš„è¿œç«¯ç‰ˆæœ¬ç½‘ç»œè°ƒç”¨ç›´æ¥åœ¨ `LazyLock` åˆå§‹åŒ–ï¼ˆTokio å¼‚æ­¥ä¸Šä¸‹æ–‡ï¼‰ä¸­æ‰§è¡Œï¼Œå¯¼è‡´ `Cannot block the current thread` ä¸¥é‡å´©æºƒã€‚
            -   **ä¿®å¤æ–¹æ¡ˆ**: 1) å¼•å…¥&quot;æ™ºèƒ½æœ€å¤§ç‰ˆæœ¬&quot;ç­–ç•¥ `max(æœ¬åœ°ç‰ˆæœ¬, è¿œç«¯ç‰ˆæœ¬, 4.1.27)`ï¼Œå§‹ç»ˆå–æœ€é«˜å€¼ã€‚2) å°†ç½‘ç»œæ¢æµ‹é€»è¾‘ç§»è‡³ç‹¬ç«‹ OS çº¿ç¨‹å¹¶é…åˆ `mpsc` é€šé“ï¼Œå®‰å…¨é¿å¼€å¼‚æ­¥è¿è¡Œæ—¶é™åˆ¶ã€‚ä¿è¯æ— è®ºæœ¬åœ°ç‰ˆæœ¬æ–°æ—§ï¼ŒæŒ‡çº¹å‡ä¸ä½äºä¸Šæ¸¸è¦æ±‚ï¼Œä¸”åº”ç”¨èƒ½ç¨³å®šå¯åŠ¨ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] åŠ¨æ€æ¨¡å‹ maxOutputTokens é™é¢ç³»ç»Ÿ (æ›¿ä»£ PR #2119 ç¡¬ç¼–ç æ–¹æ¡ˆ)**:
            -   **é—®é¢˜æ ¹æº**: éƒ¨åˆ†å®¢æˆ·ç«¯å‘é€çš„ `maxOutputTokens` è¶…è¿‡æ¨¡å‹ç‰©ç†ä¸Šé™ï¼ˆå¦‚ Flash é™åˆ¶ 64kï¼‰ï¼Œå¯¼è‡´ä¸Šæ¸¸è¿”å› 400 é”™è¯¯ã€‚
            -   **ä¸‰å±‚é™é¢æ¶æ„**:
                -   **ç¬¬ä¸€å±‚ï¼ˆåŠ¨æ€ä¼˜å…ˆï¼‰**: å®æ—¶è¯»å–è´¦å· `quota.models` æ•°æ®ã€‚
                -   **ç¬¬äºŒå±‚ï¼ˆé™æ€é»˜è®¤è¡¨ï¼‰**: `model_limits.rs` å†…ç½®å·²çŸ¥é™é¢ï¼ˆå¦‚ Flash 65536ï¼‰ã€‚
                -   **ç¬¬ä¸‰å±‚ï¼ˆå…¨å±€å…œåº•ï¼‰**: é»˜è®¤ 131072ã€‚
            -   **å®ç°ç»†èŠ‚**: åœ¨ `wrap_request()` ä¸­æ³¨å…¥è£å‰ªé€»è¾‘ï¼Œç¡®ä¿è¯·æ±‚å‚æ•°åˆæ³•ã€‚
    *   **v4.1.23 (2026-02-25)**:
        -   **[å®‰å…¨å¢å¼º] ä¼˜åŒ–ä¸åŸç”Ÿå¯¹é½åº”ç”¨å±‚ä¸åº•å±‚ç‰¹å¾æŒ‡çº¹ï¼Œæå‡è¯·æ±‚ç¨³å®šæ€§ä¸é˜²æ‹¦æˆªèƒ½åŠ›ã€‚**
        -   **[æ ¸å¿ƒä¿®å¤] å°† v1beta thinkingLevel è½¬æ¢ä¸º v1internal thinkingBudget (PR #2095)**:
            -   **é—®é¢˜æ ¹æº**: OpenClawã€Clin

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[git-ai-project/git-ai]]></title>
            <link>https://github.com/git-ai-project/git-ai</link>
            <guid>https://github.com/git-ai-project/git-ai</guid>
            <pubDate>Mon, 02 Mar 2026 00:07:04 GMT</pubDate>
            <description><![CDATA[A Git extension for tracking the AI-generated code in your repos]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/git-ai-project/git-ai">git-ai-project/git-ai</a></h1>
            <p>A Git extension for tracking the AI-generated code in your repos</p>
            <p>Language: Rust</p>
            <p>Stars: 1,191</p>
            <p>Forks: 87</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># git-ai   &lt;a href=&quot;https://discord.gg/XJStYvkb5U&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/discord-join-5865F2?logo=discord&amp;logoColor=white&quot; /&gt;&lt;/a&gt;        

&lt;img src=&quot;https://github.com/git-ai-project/git-ai/raw/main/assets/docs/git-ai.png&quot; align=&quot;right&quot;
     alt=&quot;Git AI Logo&quot; width=&quot;200&quot; height=&quot;200&quot;&gt;

Git AI is an open source git extension that tracks AI-generated code in your repositories.

Once installed, it automatically links every AI-written line to the agent, model, and transcripts that generated it â€” so you never lose the intent, requirements, and architecture decisions behind your code.

**AI attribution on every commit:**

`git commit`
```
[hooks-doctor 0afe44b2] wsl compat check
 2 files changed, 81 insertions(+), 3 deletions(-)
you  â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ ai
     6%             mixed   2%             92%
```

**AI Blame shows the model, agent, and session behind every line:**

`git-ai blame /src/log_fmt/authorship_log.rs`
```bash

cb832b7 (Aidan Cunniffe      2025-12-13 08:16:29 -0500  133) pub fn execute_diff(
cb832b7 (Aidan Cunniffe      2025-12-13 08:16:29 -0500  134)     repo: &amp;Repository,
cb832b7 (Aidan Cunniffe      2025-12-13 08:16:29 -0500  135)     spec: DiffSpec,
cb832b7 (Aidan Cunniffe      2025-12-13 08:16:29 -0500  136)     format: DiffFormat,
cb832b7 (Aidan Cunniffe      2025-12-13 08:16:29 -0500  137) ) -&gt; Result&lt;String, GitAiError&gt; {
fe2c4c8 (claude [session_id] 2025-12-02 19:25:13 -0500  138)     // Resolve commits to get from/to SHAs
fe2c4c8 (claude [session_id] 2025-12-02 19:25:13 -0500  139)     let (from_commit, to_commit) = match spec {
fe2c4c8 (claude [session_id] 2025-12-02 19:25:13 -0500  140)         DiffSpec::TwoCommit(start, end) =&gt; {
fe2c4c8 (claude [session_id] 2025-12-02 19:25:13 -0500  141)             // Resolve both commits
fe2c4c8 (claude [session_id] 2025-12-02 19:25:13 -0500  142)             let from = resolve_commit(repo, &amp;start)?;...
```


### Supported Agents

&lt;img src=&quot;assets/docs/badges/claude_code.svg&quot; alt=&quot;Claude Code&quot; height=&quot;30&quot; /&gt;  &lt;img src=&quot;assets/docs/badges/codex-black.svg&quot; alt=&quot;Codex&quot; height=&quot;30&quot; /&gt;  &lt;img src=&quot;assets/docs/badges/cursor.svg&quot; alt=&quot;Cursor&quot; height=&quot;30&quot; /&gt;  &lt;img src=&quot;assets/docs/badges/opencode.svg&quot; alt=&quot;OpenCode&quot; height=&quot;30&quot; /&gt;  &lt;img src=&quot;assets/docs/badges/gemini.svg&quot; alt=&quot;Gemini&quot; height=&quot;30&quot; /&gt;  &lt;img src=&quot;assets/docs/badges/copilot.svg&quot; alt=&quot;GitHub Copilot&quot; height=&quot;30&quot; /&gt;  &lt;img src=&quot;assets/docs/badges/continue.svg&quot; alt=&quot;Continue&quot; height=&quot;30&quot; /&gt;  &lt;img src=&quot;assets/docs/badges/droid.svg&quot; alt=&quot;Droid&quot; height=&quot;30&quot; /&gt;  &lt;img src=&quot;assets/docs/badges/junie_white.svg&quot; alt=&quot;Junie&quot; height=&quot;30&quot; /&gt;  &lt;img src=&quot;assets/docs/badges/rovodev.svg&quot; alt=&quot;Rovo Dev&quot; height=&quot;30&quot; /&gt;

&gt; [+ Add support for another agent](https://usegitai.com/docs/cli/add-your-agent)


## Install

Mac, Linux, Windows (WSL)

```bash
curl -sSL https://usegitai.com/install.sh | bash
```

Windows (non-WSL)

```powershell
powershell -NoProfile -ExecutionPolicy Bypass -Command &quot;irm https://usegitai.com/install.ps1 | iex&quot;
```

That&#039;s it â€” **no per-repo setup required.** Prompt and commit as normal. Git AI tracks attribution automatically.


## Our Choices
- **No workflow changes** â€” Just prompt and commit. Git AI tracks AI code accurately without cluttering your git history.
- **&quot;Detecting&quot; AI code is an anti-pattern** â€” Git AI does not guess whether a hunk is AI-generated. Supported agents report exactly which lines they wrote, giving you the most accurate attribution possible.
- **Local-first** â€” Works 100% offline, no login required.
- **Git native and open standard** â€” Git AI uses an [open standard](https://github.com/git-ai-project/git-ai/blob/main/specs/git_ai_standard_v3.0.0.md) for tracking AI-generated code with Git Notes.
- **Transcripts stay out of Git** â€” Git Notes link to transcripts stored locally, in the Git AI Cloud, or in a self-hosted prompt store -- keeping your repos lean, free of sensitive information, and giving you control over your data.


&lt;table style=&quot;table-layout:fixed; width:100%&quot;&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot; width=&quot;50%&quot;&gt;Solo&lt;/th&gt;
&lt;th align=&quot;center&quot; width=&quot;50%&quot;&gt;For Teams&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/git-ai-project/git-ai/raw/new-readme/assets/docs/solo-player.svg&quot; alt=&quot;Solo â€” everything stays on your machine&quot; width=&quot;400&quot;&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;img src=&quot;https://github.com/git-ai-project/git-ai/raw/new-readme/assets/docs/for-teams.svg&quot; alt=&quot;For teams â€” shared context across your team&quot; width=&quot;400&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;

- AI Authorship stored in Git Notes, with pointers to transcripts stored in local SQLite
- Transcripts only stored locally, on computer
- Restart any transcript
- Measure AI authorship across commits with `git-ai stats`

&lt;/td&gt;
&lt;td valign=&quot;top&quot;&gt;

- AI Authorship stored in Git Notes, with pointers to cloud or self-hosted transcript store with built-in access control, secret redaction, and PII filtering
- Agents and engineers can read transcripts and summaries for any block of AI-generated code
- Restart any transcript, by any contributor
- Advanced cross-agent dashboards to measure AI adoption, code durability, and compare agents across your team 

**[Click here to get early access](https://calendly.com/d/cxjh-z79-ktm/meeting-with-git-ai-authors)**

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

# Understand Why with the `/ask` Skill

See something you don&#039;t understand? The `/ask` skill lets you talk to the agent that wrote the code about its instructions, decisions, and the intent of the engineer who assigned the task.

Git AI adds the `/ask` skill to `~/.agents/skills/` and `~/.claude/skills/` at install time, so you can invoke it from Cursor, Claude Code, Copilot, Codex, and others just by typing `/ask`:

```
/ask Why didn&#039;t we use the SDK here?
```

Agents with access to the original intent and source code understand the &quot;why.&quot; Agents that can only read the code can tell you what it does, but not why:

| Reading Code + Transcript (`/ask`) | Only Reading Code (not using Git AI) |
|---|---|
| When Aidan was building telemetry, he instructed the agent not to block the exit of our CLI flushing telemetry. Instead of using the Sentry SDK directly, we came up with a pattern that writes events locally first via `append_envelope()`, then flushes them in the background via a detached subprocess. This keeps the hot path fast and ships telemetry async after the fact. | `src/commands/flush_logs.rs` is a 5-line wrapper that delegates to `src/observability/flush.rs` (~700 lines). The `commands/` layer handles CLI dispatch; `observability/` handles Sentry, PostHog, metrics upload, and log processing. Parallel modules like `flush_cas`, `flush_logs`, `flush_metrics_db` follow the same thin-dispatch pattern. |


# Make Your Agents Smarter
Agents make fewer mistakes and produce more maintainable code when they understand the requirements and decisions behind the code they build on. The best way to provide this context is to give agents the same `/ask` tool you use yourself. Tell your agents to use `/ask` in plan mode:

`Claude|AGENTS.md`
```markdown
- In plan mode, always use the /ask skill to read the code and the original transcript that generated it. Understanding intent will help you write a better plan.
```



# AI Blame

Git AI blame is a drop-in replacement for `git blame` that shows AI attribution for each line. It supports [all standard `git blame` flags](https://git-scm.com/docs/git-blame).

```bash
git-ai blame /src/log_fmt/authorship_log.rs
```

```bash
cb832b7 (Aidan Cunniffe 2025-12-13 08:16:29 -0500  133) pub fn execute_diff(
cb832b7 (Aidan Cunniffe 2025-12-13 08:16:29 -0500  134)     repo: &amp;Repository,
cb832b7 (Aidan Cunniffe 2025-12-13 08:16:29 -0500  135)     spec: DiffSpec,
cb832b7 (Aidan Cunniffe 2025-12-13 08:16:29 -0500  136)     format: DiffFormat,
cb832b7 (Aidan Cunniffe 2025-12-13 08:16:29 -0500  137) ) -&gt; Result&lt;String, GitAiError&gt; {
fe2c4c8 (claude         2025-12-02 19:25:13 -0500  138)     // Resolve commits to get from/to SHAs
fe2c4c8 (claude         2025-12-02 19:25:13 -0500  139)     let (from_commit, to_commit) = match spec {
fe2c4c8 (claude         2025-12-02 19:25:13 -0500  140)         DiffSpec::TwoCommit(start, end) =&gt; {
fe2c4c8 (claude         2025-12-02 19:25:13 -0500  141)             // Resolve both commits
fe2c4c8 (claude         2025-12-02 19:25:13 -0500  142)             let from = resolve_commit(repo, &amp;start)?;
fe2c4c8 (claude         2025-12-02 19:25:13 -0500  143)             let to = resolve_commit(repo, &amp;end)?;
fe2c4c8 (claude         2025-12-02 19:25:13 -0500  144)             (from, to)
fe2c4c8 (claude         2025-12-02 19:25:13 -0500  145)         }
```

### IDE Plugins

AI blame decorations in the gutter, color-coded by agent session. Hover over a line to see the raw prompt or summary.

&lt;table style=&quot;table-layout:fixed; width:100%&quot;&gt;
&lt;tr&gt;
&lt;th width=&quot;35%&quot;&gt;Supported Editors&lt;/th&gt;
&lt;th width=&quot;65%&quot;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td valign=&quot;top&quot;&gt;

- [VS Code](https://marketplace.visualstudio.com/items?itemName=git-ai.git-ai-vscode)
- [Cursor](https://marketplace.visualstudio.com/items?itemName=git-ai.git-ai-vscode)
- [Windsurf](https://marketplace.visualstudio.com/items?itemName=git-ai.git-ai-vscode)
- [Antigravity](https://marketplace.visualstudio.com/items?itemName=git-ai.git-ai-vscode)
- [Emacs magit](https://github.com/jwiegley/magit-ai)
- *Built support for another editor? [Open a PR](https://github.com/git-ai-project/git-ai/pulls)*

&lt;/td&gt;
&lt;td&gt;
&lt;img width=&quot;100%&quot; alt=&quot;Git AI VS Code extension showing color-coded AI blame in the gutter&quot; src=&quot;https://github.com/user-attachments/assets/94e332e7-5d96-4e5c-8757-63ac0e2f88e0&quot; /&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

# Cross Agent Observability

Git AI collects cross-agent telemetry from prompt to production. Track how much AI code gets accepted, committed, through code review, and into production â€” so you can identify which tools and practices work best for your team.

```bash
git-ai stats --json
```

Learn more: [Stats command reference docs](https://usegitai.com/docs/cli/reference#stats)

```json
{
  &quot;human_additions&quot;: 28,
  &quot;mixed_additions&quot;: 5,
  &quot;ai_additions&quot;: 76,
  &quot;ai_accepted&quot;: 47,
  &quot;total_ai_additions&quot;: 120,
  &quot;total_ai_deletions&quot;: 34,
  &quot;time_waiting_for_ai&quot;: 240,
  &quot;tool_model_breakdown&quot;: {
    &quot;claude_code/claude-sonnet-4-5-20250929&quot;: {
      &quot;ai_additions&quot;: 76,
      &quot;mixed_additions&quot;: 5,
      &quot;ai_accepted&quot;: 47,
      &quot;total_ai_additions&quot;: 120,
      &quot;total_ai_deletions&quot;: 34,
      &quot;time_waiting_for_ai&quot;: 240
    }
  }
}
```

For team-wide visibility, [Git AI Enterprise](https://usegitai.com/enterprise) aggregates data at the PR, repository, and organization level:

- **AI code composition** â€” Track what percentage of code is AI-generated across your org.
- **Full lifecycle tracking** â€” See how much AI code is accepted, committed, rewritten during code review, and deployed to production. Measure how durable that code is once it ships and whether it causes alerts or incidents.
- **Team workflows** â€” Identify who uses background agents effectively, who runs agents in parallel, and what teams getting the most lift from AI do differently.
- **Agent readiness** â€” Measure the effectiveness of agents in your repos. Track the impact of skills, rules, MCPs, and `AGENTS.md` changes across repos and task types.
- **Agent and model comparison** â€” Compare acceptance rates and output quality by agent and model.

**[Get early access](https://calendly.com/d/cxjh-z79-ktm/meeting-with-git-ai-authors)**

![Git AI Enterprise dashboard showing AI code metrics across repositories](https://github.com/git-ai-project/git-ai/raw/main/assets/docs/dashboard.png)

&lt;details&gt;
&lt;summary&gt;How does Git AI work?&lt;/summary&gt;


- Agents report what code they wrote via pre/post edit hooks.
- Git AI stores each edit as a checkpoint â€” a small diff in `.git/ai/` that records whether the change is AI-generated or human-authored. Checkpoints accumulate as you work.
- On commit, Git AI processes all checkpoints into an Authorship Log that links line ranges to agent sessions, then attaches the log to the commit via a Git Note.
- Git AI preserves attribution across rebases, merges, squashes, stash/pops, cherry-picks, and amends by transparently rewriting Authorship Logs whenever history changes.

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Git Note&lt;/b&gt; &lt;code&gt;refs/notes/ai #&amp;lt;commitsha&amp;gt;&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;b&gt;`hooks/post_clone_hook.rs`&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;

```
hooks/post_clone_hook.rs
  a1b2c3d4e5f6a7b8 6-8
  c9d0e1f2a3b4c5d6 16,21,25
---
{
  &quot;schema_version&quot;: &quot;authorship/3.0.0&quot;,
  &quot;git_ai_version&quot;: &quot;0.1.4&quot;,
  &quot;base_commit_sha&quot;: &quot;f4a8b2c...&quot;,
  &quot;prompts&quot;: {
    &quot;a1b2c3d4e5f6a7b8&quot;: {
      &quot;agent_id&quot;: {
        &quot;tool&quot;: &quot;copilot&quot;,
        &quot;model&quot;: &quot;codex-5.2&quot;
      },
      &quot;human_author&quot;: &quot;Alice Person &lt;alice@example.com&gt;&quot;,
      &quot;messages&quot;: [],
      &quot;total_additions&quot;: 8,
      &quot;total_deletions&quot;: 0,
      &quot;accepted_lines&quot;: 3,
      &quot;overriden_lines&quot;: 0,
      &quot;messages_url&quot;: &quot;https://your-prompt-store.dev/cas/a1b2c3d4...&quot;
    },
    &quot;c9d0e1f2a3b4c5d6&quot;: {
      &quot;agent_id&quot;: {
        &quot;tool&quot;: &quot;cursor&quot;,
        &quot;model&quot;: &quot;sonnet-4.5&quot;
      },
      &quot;human_author&quot;: &quot;Jeff Coder &lt;jeff@example.com&gt;&quot;,
      &quot;messages&quot;: [],
      &quot;total_additions&quot;: 5,
      &quot;total_deletions&quot;: 2,
      &quot;accepted_lines&quot;: 3,
      &quot;overriden_lines&quot;: 0,
      &quot;messages_url&quot;: &quot;https://your-prompt-store.dev/cas/c9d0e1f2...&quot;
    }
  }
}
```

&lt;/td&gt;
&lt;td&gt;

```rust
 1  pub fn post_clone_hook(
 2      parsed_args: &amp;ParsedGitInvocation,
 3      exit_status: std::process::ExitStatus,
 4  ) -&gt; Option&lt;()&gt; {
 5
 6      if !exit_status.success() {
 7          return None;
 8      }
 9
10      let target_dir =
11          extract_clone_target_directory(&amp;parsed_args.command_args)?;
12
13      let repository =
14          find_repository_in_path(&amp;target_dir).ok()?;
15
16      print!(&quot;Fetching authorship notes from origin&quot;);
17
18      match fetch_authorship_notes(&amp;repository, &quot;origin&quot;) {
19          Ok(()) =&gt; {
20              debug_log(&quot;successfully fetched&quot;);
21              print!(&quot;, done.\n&quot;);
22          }
23          Err(e) =&gt; {
24              debug_log(&amp;format!(&quot;fetch failed: {}&quot;, e));
25              print!(&quot;, failed.\n&quot;);
26          }
27      }
28
29      Some(())
30  }
```

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

The note format is defined in the [Git AI Standard v3.0.0](https://github.com/git-ai-project/git-ai/blob/main/specs/git_ai_standard_v3.0.0.md).

&lt;/details&gt;

# License
Apache 2.0
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[agrinman/tunnelto]]></title>
            <link>https://github.com/agrinman/tunnelto</link>
            <guid>https://github.com/agrinman/tunnelto</guid>
            <pubDate>Mon, 02 Mar 2026 00:07:03 GMT</pubDate>
            <description><![CDATA[Expose your local web server to the internet with a public URL.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/agrinman/tunnelto">agrinman/tunnelto</a></h1>
            <p>Expose your local web server to the internet with a public URL.</p>
            <p>Language: Rust</p>
            <p>Stars: 6,032</p>
            <p>Forks: 459</p>
            <p>Stars today: 49 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot; &gt;
&lt;img width=&quot;540px&quot; src=&quot;https://repository-images.githubusercontent.com/249120770/7ea6d180-b4ba-11ea-96ab-6c3b987aac9d&quot; align=&quot;center&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;    
  &lt;a href=&quot;https://github.com/agrinman/tunnelto/actions?query=workflow%3A%22Build+and+Release%22&quot;&gt;&lt;img src=&quot;https://github.com/agrinman/wormhole/workflows/Build%20and%20Release/badge.svg&quot; alt=&quot;BuildRelease&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://crates.io/crates/wormhole-tunnel&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/v/tunnelto&quot; alt=&quot;crate&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/agrinman/tunnelto/packages/295195&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/v/agrinman/wormhole?label=Docker&quot; alt=&quot;GitHub Docker Registry&quot;&gt;&lt;/a&gt; 
  &lt;a href=&quot;https://twitter.com/alexgrinman&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/alexgrinman?label=%40AlexGrinman&quot; alt=&quot;crate&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

# `tunnelto`
`tunnelto` lets you expose your locally running web server via a public URL.
Written in Rust. Built completely with async-io on top of tokio.

1. [Install](#install)
2. [Usage Instructions](#usage)
3. [Host it yourself](#host-it-yourself)

# Install
## Brew (macOS)
```bash
brew install agrinman/tap/tunnelto
```

## Cargo
```bash
cargo install tunnelto
```

## Everywhere
Or **Download a release for your target OS here**: [tunnelto/releases](https://github.com/agrinman/tunnelto/releases)

# Usage
## Quick Start
```shell script
tunnelto --port 8000
```
The above command opens a tunnel and forwards traffic to `localhost:8000`.

## More Options:
```shell script
tunnelto 0.1.14

USAGE:
    tunnelto [FLAGS] [OPTIONS] [SUBCOMMAND]

FLAGS:
    -h, --help       Prints help information
    -V, --version    Prints version information
    -v, --verbose    A level of verbosity, and can be used multiple times

OPTIONS:
        --dashboard-address &lt;dashboard-address&gt;    Sets the address of the local introspection dashboard
    -k, --key &lt;key&gt;                                Sets an API authentication key to use for this tunnel
        --host &lt;local-host&gt;
            Sets the HOST (i.e. localhost) to forward incoming tunnel traffic to [default: localhost]

    -p, --port &lt;port&gt;
            Sets the port to forward incoming tunnel traffic to on the target host

        --scheme &lt;scheme&gt;
            Sets the SCHEME (i.e. http or https) to forward incoming tunnel traffic to [default: http]

    -s, --subdomain &lt;sub-domain&gt;                   Specify a sub-domain for this tunnel

SUBCOMMANDS:
    help        Prints this message or the help of the given subcommand(s)
    set-auth    Store the API Authentication key
```

# Host it yourself
1. Compile the server for the musl target. See the `musl_build.sh` for a way to do this trivially with Docker!
2. See `Dockerfile` for a simple alpine based image that runs that server binary.
3. Deploy the image where ever you want.

## Testing Locally
```shell script
# Run the Server: xpects TCP traffic on 8080 and control websockets on 5000
ALLOWED_HOSTS=&quot;localhost&quot; cargo run --bin tunnelto_server

# Run a local tunnelto client talking to your local tunnelto_server
CTRL_HOST=&quot;localhost&quot; CTRL_PORT=5000 CTRL_TLS_OFF=1 cargo run --bin tunnelto -- -p 8000

# Test it out!
# Remember 8080 is our local tunnelto TCP server
curl -H &#039;&lt;subdomain&gt;.localhost&#039; &quot;http://localhost:8080/some_path?with=somequery&quot;
```
See `tunnelto_server/src/config.rs` for the environment variables for configuration.

## Caveats for hosting it yourself
The implementation does not support multiple running servers (i.e. centralized coordination).
Therefore, if you deploy multiple instances of the server, it will only work if the client connects to the same instance
as the remote TCP stream.

The [version hosted by us](https://tunnelto.dev) is a proper distributed system running on the the fabulous [fly.io](https://fly.io) service. 
In short, fly.io makes this super easy with their [Private Networking](https://fly.io/docs/reference/privatenetwork/) feature.
See `tunnelto_server/src/network/mod.rs` for the implementation details of our gossip mechanism.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[DioxusLabs/dioxus]]></title>
            <link>https://github.com/DioxusLabs/dioxus</link>
            <guid>https://github.com/DioxusLabs/dioxus</guid>
            <pubDate>Mon, 02 Mar 2026 00:07:02 GMT</pubDate>
            <description><![CDATA[Fullstack app framework for web, desktop, and mobile.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DioxusLabs/dioxus">DioxusLabs/dioxus</a></h1>
            <p>Fullstack app framework for web, desktop, and mobile.</p>
            <p>Language: Rust</p>
            <p>Stars: 34,954</p>
            <p>Forks: 1,563</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;p&gt;
    &lt;p align=&quot;center&quot; &gt;
      &lt;!-- &lt;img src=&quot;./notes/header-light-updated.svg#gh-light-mode-only&quot; &gt;
      &lt;img src=&quot;./notes/header-dark-updated.svg#gh-dark-mode-only&quot; &gt; --&gt;
      &lt;!-- &lt;a href=&quot;https://dioxuslabs.com&quot;&gt;
          &lt;img src=&quot;./notes/flat-splash.avif&quot;&gt;
      &lt;/a&gt; --&gt;
      &lt;img src=&quot;./notes/splash-header-darkmode.svg#gh-dark-mode-only&quot; style=&quot;width: 80%; height: auto;&quot;&gt;
      &lt;img src=&quot;./notes/splash-header.svg#gh-light-mode-only&quot; style=&quot;width: 80%; height: auto;&quot;&gt;
      &lt;img src=&quot;./notes/image-splash.avif&quot;&gt;
      &lt;br&gt;
    &lt;/p&gt;
&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Crates version --&gt;
  &lt;a href=&quot;https://crates.io/crates/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/dioxus.svg?style=flat-square&quot;
    alt=&quot;Crates.io version&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Downloads --&gt;
  &lt;a href=&quot;https://crates.io/crates/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/d/dioxus.svg?style=flat-square&quot;
      alt=&quot;Download&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- docs --&gt;
  &lt;a href=&quot;https://docs.rs/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square&quot;
      alt=&quot;docs.rs docs&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- CI --&gt;
  &lt;a href=&quot;https://github.com/jkelleyrtp/dioxus/actions&quot;&gt;
    &lt;img src=&quot;https://github.com/dioxuslabs/dioxus/actions/workflows/main.yml/badge.svg&quot;
      alt=&quot;CI status&quot; /&gt;
  &lt;/a&gt;

  &lt;!--Awesome --&gt;
  &lt;a href=&quot;https://dioxuslabs.com/awesome&quot;&gt;
    &lt;img src=&quot;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg&quot; alt=&quot;Awesome Page&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Discord --&gt;
  &lt;a href=&quot;https://discord.gg/XgGxMSkvUM&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/899851952891002890.svg?logo=discord&amp;style=flat-square&quot; alt=&quot;Discord Link&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;
    &lt;a href=&quot;https://dioxuslabs.com&quot;&gt; Website &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/tree/main/examples&quot;&gt; Examples &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://dioxuslabs.com/learn/0.7/tutorial&quot;&gt; Tutorial &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/notes/translations/zh-cn/README.md&quot;&gt; ä¸­æ–‡ &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/notes/translations/pt-br/README.md&quot;&gt; PT-BR &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/notes/translations/ja-jp/README.md&quot;&gt; æ—¥æœ¬èª &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/notes/translations/tr-tr&quot;&gt; TÃ¼rkÃ§e &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/notes/translations/ko-kr&quot;&gt; í•œêµ­ì–´ &lt;/a&gt;
  &lt;/h3&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/releases/tag/v0.7.0&quot;&gt;âœ¨ Dioxus 0.7 is out!!! âœ¨&lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;

Build for web, desktop, and mobile, and more with a single codebase. Zero-config setup, integrated hot-reloading, and signals-based state management. Add backend functionality with Server Functions and bundle with our CLI.

```rust
fn app() -&gt; Element {
    let mut count = use_signal(|| 0);

    rsx! {
        h1 { &quot;High-Five counter: {count}&quot; }
        button { onclick: move |_| count += 1, &quot;Up high!&quot; }
        button { onclick: move |_| count -= 1, &quot;Down low!&quot; }
    }
}
```

## â­ï¸ Unique features:

- Cross-platform apps in three lines of code (web, desktop, mobile, server, and more)
- [Ergonomic state management](https://dioxuslabs.com/blog/release-050) combines the best of React, Solid, and Svelte
- Built-in featureful, type-safe, fullstack web framework
- Integrated bundler for deploying to the web, macOS, Linux, and Windows
- Subsecond Rust hot-patching and asset hot-reloading
- And more! [Take a tour of Dioxus](https://dioxuslabs.com/learn/0.7/).

## Instant hot-reloading

With one command, `dx serve` and your app is running. Edit your markup, styles, and see changes in milliseconds. Use our experimental `dx serve --hotpatch` to update Rust code in real time.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/hotreload-video.webp&quot;&gt;
  &lt;!-- &lt;video src=&quot;https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov&quot; width=&quot;500&quot;&gt;&lt;/video&gt; --&gt;
  &lt;!-- &lt;video src=&quot;https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov&quot; width=&quot;500&quot;&gt;&lt;/video&gt; --&gt;
&lt;/div&gt;

## Build Beautiful Apps

Dioxus apps are styled with HTML and CSS. Use the built-in TailwindCSS support or load your favorite CSS library. Easily call into native code (objective-c, JNI, Web-Sys) for a perfect native touch.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/ebou2.avif&quot;&gt;
&lt;/div&gt;



## Truly fullstack applications

Dioxus deeply integrates with [axum](https://github.com/tokio-rs/axum) to provide powerful fullstack capabilities for both clients and servers. Pick from a wide array of built-in batteries like WebSockets, SSE, Streaming, File Upload/Download, Server-Side-Rendering, Forms, Middleware, and Hot-Reload, or go fully custom and integrate your existing axum backend.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/fullstack-websockets.avif&quot; width=&quot;700&quot;&gt;
&lt;/div&gt;

## Experimental Native Renderer

Render using web-sys, webview, server-side-rendering, liveview, or even with our experimental WGPU-based renderer. Embed Dioxus in Bevy, WGPU, or even run on embedded Linux!

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/native-blitz-wgpu.webp&quot;&gt;
&lt;/div&gt;


## First-party primitive components

Get started quickly with a complete set of primitives modeled after shadcn/ui and Radix-Primitives.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/primitive-components.avif&quot; width=&quot;700&quot;&gt;
&lt;/div&gt;

## First-class Android and iOS support

Dioxus is the fastest way to build native mobile apps with Rust. Simply run `dx serve --platform android` and your app is running in an emulator or on device in seconds. Call directly into JNI and Native APIs.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/android_and_ios2.avif&quot; width=&quot;500&quot;&gt;
&lt;/div&gt;



## Bundle for web, desktop, and mobile

Simply run `dx bundle` and your app will be built and bundled with maximization optimizations. On the web, take advantage of [`.avif` generation, `.wasm` compression, minification](https://dioxuslabs.com/learn/0.7/tutorial/assets), and more. Build WebApps weighing [less than 50kb](https://github.com/ealmloff/tiny-dioxus/) and desktop/mobile apps less than 5mb.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/bundle.gif&quot;&gt;
&lt;/div&gt;


## Fantastic documentation

We&#039;ve put a ton of effort into building clean, readable, and comprehensive documentation. All html elements and listeners are documented with MDN docs, and our Docs runs continuous integration with Dioxus itself to ensure that the docs are always up to date. Check out the [Dioxus website](https://dioxuslabs.com/learn/0.7/) for guides, references, recipes, and more. Fun fact: we use the Dioxus website as a testbed for new Dioxus features - [check it out!](https://github.com/dioxusLabs/docsite)

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/docs.avif&quot;&gt;
&lt;/div&gt;


## Modular and Customizable

Build your own renderer. Use our modular components like RSX, VirtualDom, Blitz, Taffy, and Subsecond.

## Community

Dioxus is a community-driven project, with a very active [Discord](https://discord.gg/XgGxMSkvUM) and [GitHub](https://github.com/DioxusLabs/dioxus/issues) community. We&#039;re always looking for help, and we&#039;re happy to answer questions and help you get started. [Our SDK](https://github.com/DioxusLabs/dioxus-std) is community-run and we even have a [GitHub organization](https://github.com/dioxus-community/) for the best Dioxus crates that receive free upgrades and support.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/dioxus-community.avif&quot;&gt;
&lt;/div&gt;

## Full-time core team

Dioxus has grown from a side project to a small team of fulltime engineers. Thanks to the generous support of FutureWei, Satellite.im, the GitHub Accelerator program, we&#039;re able to work on Dioxus full-time. Our long term goal is for Dioxus to become self-sustaining by providing paid high-quality enterprise tools. If your company is interested in adopting Dioxus and would like to work with us, please reach out!

## Supported Platforms

&lt;div align=&quot;center&quot;&gt;
  &lt;table style=&quot;width:100%&quot;&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Web&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render directly to the DOM using WebAssembly&lt;/li&gt;
          &lt;li&gt;Pre-render with SSR and rehydrate on the client&lt;/li&gt;
          &lt;li&gt;Simple &quot;hello world&quot; at about 50kb, comparable to React&lt;/li&gt;
          &lt;li&gt;Built-in dev server and hot reloading for quick iteration&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Desktop&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render using Webview or - experimentally - with WGPU or &lt;a href=&quot;https://freyaui.dev&quot;&gt;Freya&lt;/a&gt; (Skia) &lt;/li&gt;
          &lt;li&gt;Zero-config setup. Simply `cargo run` or `dx serve` to build your app &lt;/li&gt;
          &lt;li&gt;Full support for native system access without IPC &lt;/li&gt;
          &lt;li&gt;Supports macOS, Linux, and Windows. Portable &lt;3mb binaries &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Mobile&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render using Webview or - experimentally - with WGPU or Skia &lt;/li&gt;
          &lt;li&gt;Build .ipa and .apk files for iOS and Android &lt;/li&gt;
          &lt;li&gt;Call directly into Java and Objective-C with minimal overhead&lt;/li&gt;
          &lt;li&gt;From &quot;hello world&quot; to running on device in seconds&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Server-side Rendering&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Suspense, hydration, and server-side rendering&lt;/li&gt;
          &lt;li&gt;Quickly drop in backend functionality with server functions&lt;/li&gt;
          &lt;li&gt;Extractors, middleware, and routing integrations&lt;/li&gt;
          &lt;li&gt;Static-site generation and incremental regeneration&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## Running the examples

&gt; The examples in the main branch of this repository target the git version of dioxus and the CLI. If you are looking for examples that work with the latest stable release of dioxus, check out the [0.6 branch](https://github.com/DioxusLabs/dioxus/tree/v0.6/examples).

The examples in the top level of this repository can be run with:

```sh
cargo run --example &lt;example&gt;
```

However, we encourage you to download the dioxus-cli to test out features like hot-reloading. To install the most recent binary CLI, you can use cargo binstall.

```sh
cargo binstall dioxus-cli@0.7.0 --force
```

If this CLI is out-of-date, you can install it directly from git

```sh
cargo install --git https://github.com/DioxusLabs/dioxus dioxus-cli --locked
```

With the CLI, you can also run examples with the web platform. You will need to disable the default desktop feature and enable the web feature with this command:

```sh
dx serve --example &lt;example&gt; --platform web -- --no-default-features
```

## Contributing

- Check out the website [section on contributing](https://dioxuslabs.com/learn/0.7/beyond/contributing).
- Report issues on our [issue tracker](https://github.com/dioxuslabs/dioxus/issues).
- [Join](https://discord.gg/XgGxMSkvUM) the discord and ask questions!

&lt;a href=&quot;https://github.com/dioxuslabs/dioxus/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=dioxuslabs/dioxus&amp;max=30&amp;columns=10&quot; /&gt;
&lt;/a&gt;

## License

This project is licensed under either the [MIT license] or the [Apache-2 License].

[apache-2 license]: https://github.com/DioxusLabs/dioxus/blob/master/LICENSE-APACHE
[mit license]: https://github.com/DioxusLabs/dioxus/blob/master/LICENSE-MIT

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Dioxus by you, shall be licensed as MIT or Apache-2, without any additional
terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[Polymarket/rs-clob-client]]></title>
            <link>https://github.com/Polymarket/rs-clob-client</link>
            <guid>https://github.com/Polymarket/rs-clob-client</guid>
            <pubDate>Mon, 02 Mar 2026 00:07:01 GMT</pubDate>
            <description><![CDATA[Polymarket Rust CLOB Client]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Polymarket/rs-clob-client">Polymarket/rs-clob-client</a></h1>
            <p>Polymarket Rust CLOB Client</p>
            <p>Language: Rust</p>
            <p>Stars: 541</p>
            <p>Forks: 151</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>![Polymarket](assets/logo.png)

# Polymarket Rust Client

[![Crates.io](https://img.shields.io/crates/v/polymarket-client-sdk.svg)](https://crates.io/crates/polymarket-client-sdk)
[![CI](https://github.com/Polymarket/rs-clob-client/actions/workflows/ci.yml/badge.svg)](https://github.com/Polymarket/rs-clob-client/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/Polymarket/rs-clob-client/graph/badge.svg?token=FW1BYWWFJ2)](https://codecov.io/gh/Polymarket/rs-clob-client)

An ergonomic Rust client for interacting with Polymarket services, primarily the Central Limit Order Book (CLOB).
This crate provides strongly typed request builders, authenticated endpoints, `alloy` support and more.

## Table of Contents

- [Overview](#overview)
- [Getting Started](#getting-started)
- [Feature Flags](#feature-flags)
- [Re-exported Types](#re-exported-types)
- [Examples](#examples)
  - [CLOB Client](#clob-client)
  - [WebSocket Streaming](#websocket-streaming)
  - [Optional APIs](#optional-apis)
- [Additional CLOB Capabilities](#additional-clob-capabilities)
- [Setting Token Allowances](#token-allowances)
- [Minimum Supported Rust Version (MSRV)](#minimum-supported-rust-version-msrv)
- [Contributing](#contributing)
- [About Polymarket](#about-polymarket)

## Overview

- **Typed CLOB requests** (orders, trades, markets, balances, and more)
- **Dual authentication flows**
    - Normal authenticated flow
    - [Builder](https://docs.polymarket.com/developers/builders/builder-intro) authentication flow
- **Type-level state machine**
    - Prevents using authenticated endpoints before authenticating
    - Compile-time enforcement of correct transitions
- **Signer support** via `alloy::signers::Signer`
    - Including remote signers, e.g. AWS KMS
- **Zero-cost abstractions** â€” no dynamic dispatch in hot paths
- **Order builders** for easy construction &amp; signing
- **Full `serde` support**
- **Async-first design** with `reqwest`


## Getting started

Add the crate to your `Cargo.toml`:

```toml
[dependencies]
polymarket-client-sdk = &quot;0.3&quot;
```

or

```bash
cargo add polymarket-client-sdk
```

Then run any of the examples
```bash
cargo run --example unauthenticated
```

## Feature Flags

The crate is modular with optional features for different Polymarket APIs:

| Feature      | Description                                                                                                                                    |
|--------------|------------------------------------------------------------------------------------------------------------------------------------------------|
| `clob`       | Core CLOB client for order placement, market data, and authentication                                                                          |
| `tracing`    | Structured logging via [`tracing`](https://docs.rs/tracing) for HTTP requests, auth flows, and caching                                         |
| `ws`         | WebSocket client for real-time orderbook, price, and user event streaming                                                                      |
| `rtds`       | Real-time data streams for crypto prices (Binance, Chainlink) and comments                                                                     |
| `data`       | Data API client for positions, trades, leaderboards, and analytics                                                                             |
| `gamma`      | Gamma API client for market/event discovery, search, and metadata                                                                              |
| `bridge`     | Bridge API client for cross-chain deposits (EVM, Solana, Bitcoin)                                                                              |
| `rfq`        | RFQ API (within CLOB) for submitting and querying quotes                                                                                       |
| `heartbeats` | Clob feature that automatically sends heartbeat messages to the Polymarket server, if the client disconnects all open orders will be cancelled |
| `ctf`        | CTF API client to perform split/merge/redeem on binary and neg risk markets

Enable features in your `Cargo.toml`:

```toml
[dependencies]
polymarket-client-sdk = { version = &quot;0.3&quot;, features = [&quot;ws&quot;, &quot;data&quot;] }
```

## Re-exported Types

This SDK re-exports commonly used types from external crates so you don&#039;t need to add them to your `Cargo.toml`:

### From `types` module

```rust
use polymarket_client_sdk::types::{
    Address, ChainId, Signature, address,  // from alloy::primitives
    DateTime, NaiveDate, Utc,              // from chrono
    Decimal, dec,                          // from rust_decimal + rust_decimal_macros
};
```

### From `auth` module

```rust
use polymarket_client_sdk::auth::{
    LocalSigner, Signer,          // from alloy::signers (LocalSigner + trait)
    Uuid, ApiKey,                 // from uuid (ApiKey = Uuid)
    SecretString, ExposeSecret,   // from secrecy
    builder::Url,                 // from url (for remote builder config)
};
```

### From `error` module

```rust
use polymarket_client_sdk::error::{
    StatusCode, Method,           // from reqwest (for error inspection)
};
```

This allows you to work with the SDK without managing version compatibility for these common dependencies.

## Examples

See `examples/` for the complete set. Below are hand-picked examples for common use cases.

### CLOB Client

#### Unauthenticated client (read-only)
```rust,ignore
use polymarket_client_sdk::clob::Client;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let client = Client::default();

    let ok = client.ok().await?;
    println!(&quot;Ok: {ok}&quot;);

    Ok(())
}
```

#### Authenticated client

Set `POLYMARKET_PRIVATE_KEY` as an environment variable with your private key.

##### [EOA](https://www.binance.com/en/academy/glossary/externally-owned-account-eoa) wallets
If using MetaMask or hardware wallet, you must first set token allowances. See [Token Allowances](#token-allowances) section below.

```rust,ignore
use std::str::FromStr as _;

use alloy::signers::Signer as _;
use alloy::signers::local::LocalSigner;
use polymarket_client_sdk::{POLYGON, PRIVATE_KEY_VAR};
use polymarket_client_sdk::clob::{Client, Config};

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let private_key = std::env::var(PRIVATE_KEY_VAR).expect(&quot;Need a private key&quot;);
    let signer = LocalSigner::from_str(&amp;private_key)?.with_chain_id(Some(POLYGON));
    let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
        .authentication_builder(&amp;signer)
        .authenticate()
        .await?;

    let ok = client.ok().await?;
    println!(&quot;Ok: {ok}&quot;);

    let api_keys = client.api_keys().await?;
    println!(&quot;API keys: {api_keys:?}&quot;);

    Ok(())
}
```

##### Proxy/Safe wallets
For proxy/Safe wallets, the funder address is **automatically derived** using CREATE2 from your signer&#039;s EOA address:

```rust,ignore
let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
    .authentication_builder(&amp;signer)
    .signature_type(SignatureType::GnosisSafe)  // Funder auto-derived via CREATE2
    .authenticate()
    .await?;
```

The SDK computes the deterministic wallet address that Polymarket deploys for your EOA. This is the same address
shown on polymarket.com when you log in with a browser wallet.

If you need to override the derived address (e.g., for advanced use cases), you can explicitly provide it:

```rust,ignore
let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
    .authentication_builder(&amp;signer)
    .funder(address!(&quot;&lt;your-polymarket-wallet-address&gt;&quot;))
    .signature_type(SignatureType::GnosisSafe)
    .authenticate()
    .await?;
```

You can also derive these addresses manually:

```rust,ignore
use polymarket_client_sdk::{derive_safe_wallet, derive_proxy_wallet, POLYGON};

// For browser wallet users (GnosisSafe)
let safe_address = derive_safe_wallet(signer.address(), POLYGON);

// For Magic/email wallet users (Proxy)
let proxy_address = derive_proxy_wallet(signer.address(), POLYGON);
```

##### Funder Address
The **funder address** is the actual address that holds your funds on Polymarket. When using proxy wallets (email wallets
like Magic or browser extension wallets), the signing key differs from the address holding the funds. The SDK automatically
derives the correct funder address using CREATE2 when you specify `SignatureType::Proxy` or `SignatureType::GnosisSafe`.
You can override this with `.funder(address)` if needed.

##### Signature Types
The **signature_type** parameter tells the system how to verify your signatures:
- `signature_type=0` (default): Standard EOA (Externally Owned Account) signatures - includes MetaMask, hardware wallets,
   and any wallet where you control the private key directly
- `signature_type=1`: Email/Magic wallet signatures (delegated signing)
- `signature_type=2`: Browser wallet proxy signatures (when using a proxy contract, not direct wallet connections)

See [SignatureType](src/clob/types/mod.rs#L182) for more information.

##### Place a market order

```rust,ignore
use std::str::FromStr as _;

use alloy::signers::Signer as _;
use alloy::signers::local::LocalSigner;
use polymarket_client_sdk::{POLYGON, PRIVATE_KEY_VAR};
use polymarket_client_sdk::clob::{Client, Config};
use polymarket_client_sdk::clob::types::{Amount, OrderType, Side};
use polymarket_client_sdk::types::Decimal;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let private_key = std::env::var(PRIVATE_KEY_VAR).expect(&quot;Need a private key&quot;);
    let signer = LocalSigner::from_str(&amp;private_key)?.with_chain_id(Some(POLYGON));
    let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
        .authentication_builder(&amp;signer)
        .authenticate()
        .await?;

    let order = client
        .market_order()
        .token_id(&quot;&lt;token-id&gt;&quot;)
        .amount(Amount::usdc(Decimal::ONE_HUNDRED)?)
        .side(Side::Buy)
        .order_type(OrderType::FOK)
        .build()
        .await?;
    let signed_order = client.sign(&amp;signer, order).await?;
    let response = client.post_order(signed_order).await?;
    println!(&quot;Order response: {:?}&quot;, response);

    Ok(())
}
```

##### Place a limit order

```rust,ignore
use std::str::FromStr as _;

use alloy::signers::Signer as _;
use alloy::signers::local::LocalSigner;
use polymarket_client_sdk::{POLYGON, PRIVATE_KEY_VAR};
use polymarket_client_sdk::clob::{Client, Config};
use polymarket_client_sdk::clob::types::Side;
use polymarket_client_sdk::types::Decimal;
use rust_decimal_macros::dec;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let private_key = std::env::var(PRIVATE_KEY_VAR).expect(&quot;Need a private key&quot;);
    let signer = LocalSigner::from_str(&amp;private_key)?.with_chain_id(Some(POLYGON));
    let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
        .authentication_builder(&amp;signer)
        .authenticate()
        .await?;

    let order = client
        .limit_order()
        .token_id(&quot;&lt;token-id&gt;&quot;)
        .size(Decimal::ONE_HUNDRED)
        .price(dec!(0.1))
        .side(Side::Buy)
        .build()
        .await?;
    let signed_order = client.sign(&amp;signer, order).await?;
    let response = client.post_order(signed_order).await?;
    println!(&quot;Order response: {:?}&quot;, response);

    Ok(())
}
```

#### Builder-authenticated client

For institutional/third-party app integrations with remote signing:
```rust,ignore
use std::str::FromStr as _;

use alloy::signers::Signer as _;
use alloy::signers::local::LocalSigner;
use polymarket_client_sdk::auth::builder::Config as BuilderConfig;
use polymarket_client_sdk::{POLYGON, PRIVATE_KEY_VAR};
use polymarket_client_sdk::clob::{Client, Config};
use polymarket_client_sdk::clob::types::SignatureType;
use polymarket_client_sdk::clob::types::request::TradesRequest;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let private_key = std::env::var(PRIVATE_KEY_VAR).expect(&quot;Need a private key&quot;);
    let signer = LocalSigner::from_str(&amp;private_key)?.with_chain_id(Some(POLYGON));
    let builder_config = BuilderConfig::remote(&quot;http://localhost:3000/sign&quot;, None)?; // Or your signing server

    let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
        .authentication_builder(&amp;signer)
        .signature_type(SignatureType::Proxy)  // Funder auto-derived via CREATE2
        .authenticate()
        .await?;

    let client = client.promote_to_builder(builder_config).await?;

    let ok = client.ok().await?;
    println!(&quot;Ok: {ok}&quot;);

    let api_keys = client.api_keys().await?;
    println!(&quot;API keys: {api_keys:?}&quot;);

    let builder_trades = client.builder_trades(&amp;TradesRequest::default(), None).await?;
    println!(&quot;Builder trades: {builder_trades:?}&quot;);

    Ok(())
}
```

### WebSocket Streaming

Real-time orderbook and user event streaming. Requires the `ws` feature.

```toml
polymarket-client-sdk = { version = &quot;0.3&quot;, features = [&quot;ws&quot;] }
```

```rust,ignore
use futures::StreamExt as _;
use polymarket_client_sdk::clob::ws::Client;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let client = Client::default();

    // Subscribe to orderbook updates for specific assets
    let asset_ids = vec![&quot;&lt;asset-id&gt;&quot;.to_owned()];
    let stream = client.subscribe_orderbook(asset_ids)?;
    let mut stream = Box::pin(stream);

    while let Some(book_result) = stream.next().await {
        let book = book_result?;
        println!(&quot;Orderbook update for {}: {} bids, {} asks&quot;,
            book.asset_id, book.bids.len(), book.asks.len());
    }
    Ok(())
}
```

Available streams:
- `subscribe_orderbook()` - Bid/ask levels for assets
- `subscribe_prices()` - Price change events
- `subscribe_midpoints()` - Calculated midpoint prices
- `subscribe_orders()` - User order updates (authenticated)
- `subscribe_trades()` - User trade executions (authenticated)

See [`examples/clob/ws/`](examples/clob/ws/) for more WebSocket examples including authenticated user streams.

### Optional APIs

#### Data API
Trading analytics, positions, and leaderboards. Requires the `data` feature.

```rust,ignore
use polymarket_client_sdk::data::Client;
use polymarket_client_sdk::data::types::request::PositionsRequest;
use polymarket_client_sdk::types::address;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let client = Client::default();
    let user = address!(&quot;0x0000000000000000000000000000000000000000&quot;); // Your address

    let request = PositionsRequest::builder().user(user).limit(10)?.build();
    let positions = client.positions(&amp;request).await?;
    println!(&quot;Open positions: {:?}&quot;, positions);
    Ok(())
}
```

See [`examples/data.rs`](examples/data.rs) for trades, leaderboards, activity, and more.

#### Gamma API
Market and event discovery. Requires the `gamma` feature.

```rust,ignore
use polymarket_client_sdk::gamma::Client;
use polymarket_client_sdk::gamma::types::request::{EventsRequest, SearchRequest};

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let client = Client::default();

    // Find active events
    let request = EventsRequest::builder().active(true).limit(5).build();
    let events = client.events(&amp;request).await?;
    println!(&quot;Found {} events&quot;, events.len());

    // Search for markets
    let search = SearchRequest::builder().q(&quot;bitcoin&quot;).build();
    let results = client.search(&amp;search).await?;
    println!(&quot;Search results: {:?}&quot;, results);
    Ok(())
}
```

See [`examples/gamma.rs`](examples/gamma/client.rs) for tags, series, comments, and sports endpoints.

#### Bridge API
Cross-chain deposits from EVM chains, Solana, and Bitcoin. Requires the `bridge` feature.

```rust,ignore
use polymarket_client_sdk::bridge::Client;
use polymarket_client_sdk::bridge::types::DepositRequest;
use polymarket_client_sdk::types::address;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let client = Client::default();

    // Get deposit addresses for your wallet
    let request = DepositRequest::builder()
        .address(address!(&quot;0x0000000000000000000000000000000000000000&quot;)) // Your address
        .build();
    let response = client.deposit(&amp;request).await?;

    println!(&quot;EVM: {}&quot;, response.address.evm);
    println!(&quot;Solana: {}&quot;, response.address.svm);
    println!(&quot;Bitcoin: {}&quot;, response.address.btc);
    Ok(())
}
```

See [`examples/bridge.rs`](examples/bridge.rs) for supported assets and minimum deposits.

## Additional CLOB Capabilities

Beyond basic order placement, the CLOB client supports:

- **Rewards &amp; Earnings** - Query maker rewards, daily earnings, and reward percentages
- **Streaming Pagination** - `stream_data()` for iterating through large result sets
- **Batch Operations** - `post_orders()` and `cancel_orders()` for multiple orders at once
- **Order Scoring** - Check if orders qualify for maker rewards
- **Notifications** - Manage trading notifications
- **Balance Management** - Query and refresh balance/allowance caches
- **Geoblock Detection** - Check if trading is available in your region

See [`examples/clob/authenticated.rs`](examples/clob/authenticated.rs) for comprehensive usage.

## Token Allowances

### Do I need to set allowances?
MetaMask and EOA users must set token allowances.
If you are using a proxy or [Safe](https://help.safe.global/en/articles/40869-what-is-safe)-type wallet, then you do not.

### What are allowances?
Think of allowances as permissions. Before Polymarket can move your funds to execute trades, you need to give the
exchange contracts permission to access your USDC and conditional tokens.

### Quick Setup
You need to approve two types of tokens:
1. **USDC** (for deposits and trading)
2. **Conditional Tokens** (the outcome tokens you trade)

Each needs approval for the exchange contracts to work properly.

### Setting Allowances
Use [examples/approvals.rs](examples/approvals.rs) to approve the right contracts. Run once to approve USDC. Then change
the `TOKEN_TO_APPROVE` and run for each conditional token.

**Pro tip**: You only need to set these once per wallet. After that, you can trade freely.

## Minimum Supported Rust Version (MSRV)

**MSRV: Rust [1.88](https://releases.rs/docs/1.88.0/)**

Older versions *may* compile, but are not supported.

This project aims to maintain compatibility with a Rust version that is at least six months old.

Version updates may occur more frequently than the policy guideline states if external forces require it. For example,
a CVE in a downstream dependency requiring an MSRV bump would be considered an acceptable reason to violate the six-month
guideline.


## Contributing
We encourage contributions from the community. Check out our [contributing guidelines](.github/CONTRIBUTING.md) for
instructions on how to contribute to this SDK.


## About Polymarket
[Polymarket](https://docs.polymarket.com/polymarket-learn/get-started/what-is-polymarket) is the worldâ€™s largest prediction market, allowing you to stay informed and profit from your knowledge by
betting on future events across various topics.
Studies show prediction markets are often more accurate than pundits because they combine news, polls, and expert
opinions into a single value that represents the marketâ€™s view of an eventâ€™s odds. Our markets reflect accurate, unbiased,
and real-time probabilities for the events that matter most to you. Markets seek truth.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gfx-rs/wgpu]]></title>
            <link>https://github.com/gfx-rs/wgpu</link>
            <guid>https://github.com/gfx-rs/wgpu</guid>
            <pubDate>Mon, 02 Mar 2026 00:07:00 GMT</pubDate>
            <description><![CDATA[A cross-platform, safe, pure-Rust graphics API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gfx-rs/wgpu">gfx-rs/wgpu</a></h1>
            <p>A cross-platform, safe, pure-Rust graphics API.</p>
            <p>Language: Rust</p>
            <p>Stars: 16,522</p>
            <p>Forks: 1,221</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre># wgpu
&lt;img align=&quot;right&quot; width=&quot;20%&quot; src=&quot;logo.png&quot;&gt;

[![Build Status](https://img.shields.io/github/actions/workflow/status/gfx-rs/wgpu/ci.yml?branch=trunk&amp;logo=github&amp;label=CI)](https://github.com/gfx-rs/wgpu/actions)
[![codecov.io](https://img.shields.io/codecov/c/github/gfx-rs/wgpu?logo=codecov&amp;logoColor=fff&amp;label=codecov&amp;token=84qJTesmeS)](https://codecov.io/gh/gfx-rs/wgpu)

`wgpu` is a cross-platform, safe, pure-Rust graphics API. It runs natively on Vulkan, Metal, D3D12, and OpenGL; and on top of WebGL2 and WebGPU on wasm.

The API is based on the [WebGPU standard][webgpu], but is a fully native Rust library. It serves as the core of the WebGPU integration in Firefox, Servo, and Deno.

## Getting Started

See our examples online at &lt;https://wgpu.rs/examples/&gt;. You can see the Rust sources at [examples](examples) and run them directly with `cargo run --bin wgpu-examples &lt;example&gt;`.

### Learning `wgpu`

If you are new to `wgpu` and graphics programming, we recommend starting with [Learn Wgpu].
&lt;!-- Note, &quot;Learn Wgpu&quot; is using the capitalization style in their header, NOT our styling --&gt;

Additionally, [WebGPU Fundamentals] is a tutorial for WebGPU which is very similar to our API, minus differences between Rust and Javascript.

[Learn Wgpu]: https://sotrh.github.io/learn-wgpu/
[WebGPU Fundamentals]: https://webgpufundamentals.org/

### Wiki

We have a [wiki](https://github.com/gfx-rs/wgpu/wiki) which has information on useful architecture patterns, debugging tips, and more getting started information. 

### Need Help? Want to Contribute? 

The wgpu community uses Matrix and Discord to discuss.

- [![`#wgpu:matrix.org`](https://img.shields.io/static/v1?label=wgpu-devs&amp;message=%23wgpu&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu:matrix.org) - discussion of wgpu&#039;s development.
- [![`#wgpu-users:matrix.org`](https://img.shields.io/static/v1?label=wgpu-users&amp;message=%23wgpu-users&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu-users:matrix.org) - discussion of using the library and the surrounding ecosystem.
- [![#wgpu on the Rust Gamedev Discord](https://img.shields.io/discord/676678179678715904?logo=discord&amp;logoColor=E0E3FF&amp;label=%23wgpu&amp;color=5865F2)
](https://discord.gg/X3MYBNXUMJ) - Dedicated support channel on the Rust Gamedev Discord.


### Other Languages

To use wgpu in C or dozens of other languages, look at [wgpu-native](https://github.com/gfx-rs/wgpu-native). These are C bindings to wgpu and has an up-to-date list of libraries bringing support to other languages. 

[Learn WebGPU (for C++)] is a good resource for learning how to use wgpu-native from C++.

[Learn WebGPU (for C++)]: https://eliemichel.github.io/LearnWebGPU/
[webgpu]: https://gpuweb.github.io/gpuweb/

## Quick Links

| Docs                  | Examples                  | Changelog               |
|:---------------------:|:-------------------------:|:-----------------------:|
| [v28][rel-docs]       | [v28][rel-examples]       | [v28][rel-change]       |
| [`trunk`][trunk-docs] | [`trunk`][trunk-examples] | [`trunk`][trunk-change] |

Contributors are welcome! See [CONTRIBUTING.md][contrib] for more information.

[rel-docs]: https://docs.rs/wgpu/
[rel-examples]: https://github.com/gfx-rs/wgpu/tree/v28/examples#readme
[rel-change]: https://github.com/gfx-rs/wgpu/releases
[trunk-docs]: https://wgpu.rs/doc/wgpu/
[trunk-examples]: https://github.com/gfx-rs/wgpu/tree/trunk/examples#readme
[trunk-change]: https://github.com/gfx-rs/wgpu/blob/trunk/CHANGELOG.md#unreleased
[contrib]: CONTRIBUTING.md

## Supported Platforms

| API    | Windows            | Linux/Android      | macOS/iOS          | Web (wasm)         |
| ------ | ------------------ | ------------------ | ------------------ | ------------------ |
| Vulkan |         âœ…         |         âœ…         |         ğŸŒ‹         |                    |
| Metal  |                    |                    |         âœ…         |                    |
| DX12   |         âœ…         |                    |                    |                    |
| OpenGL |    ğŸ†— (GL 3.3+)    |  ğŸ†— (GL ES 3.0+)   |         ğŸ“         |    ğŸ†— (WebGL2)     |
| WebGPU |                    |                    |                    |         âœ…         |

âœ… = First Class Support  
ğŸ†— = Downlevel/Best Effort Support  
ğŸ“ = Requires the [ANGLE](https://github.com/gfx-rs/wgpu/wiki/Running-on-ANGLE) translation layer (GL ES 3.0 only)  
ğŸŒ‹ = Requires the [MoltenVK](https://vulkan.lunarg.com/sdk/home#mac) translation layer  
ğŸ› ï¸ = Unsupported, though open to contributions

## Environment Variables

Testing, examples, and `::from_env()` methods use a standardized set of environment variables to control wgpu&#039;s behavior.

- `WGPU_BACKEND` with a comma-separated list of the backends you want to use (`vulkan`, `metal`, `dx12`, or `gl`).
- `WGPU_ADAPTER_NAME` with a case-insensitive substring of the name of the adapter you want to use (ex. `1080` will match `NVIDIA GeForce 1080ti`).
- `WGPU_DX12_COMPILER` with the DX12 shader compiler you wish to use (`dxc`, `static-dxc`, or `fxc`). Note that `dxc` requires `dxcompiler.dll` (min v1.8.2502) to be in the working directory, and `static-dxc` requires the `static-dxc` crate feature to be enabled. Otherwise, it will fall back to `fxc`.

See the [documentation](https://docs.rs/wgpu/latest/wgpu/index.html?search=env) for more environment variables.

When running the CTS, use the variables `DENO_WEBGPU_ADAPTER_NAME`, `DENO_WEBGPU_BACKEND`, `DENO_WEBGPU_POWER_PREFERENCE`.

## Repo Overview

For an overview of all the components in the gfx-rs ecosystem, see [the big picture](./docs/big-picture.png).

## MSRV policy

TL;DR: If you&#039;re using `wgpu`, our MSRV is **1.87**. If you&#039;re running our tests or examples, our MSRV is **1.93**.

We will avoid bumping the MSRV of `wgpu` without good reason, and such a change is considered breaking.

&lt;details&gt;
&lt;summary&gt; Specific Details &lt;/summary&gt;

Due to complex dependants, we have three MSRV policies:

- `wgpu`&#039;s MSRV is **1.87**
- `wgpu-core` (and hence `wgpu-hal`, `naga`, and `wgpu-types`)&#039;s MSRV is **1.87**.
- The rest of the workspace has an MSRV of **1.93**.

It is enforced on CI (in &quot;/.github/workflows/ci.yml&quot;) with the `WGPU_MSRV`, `CORE_MSRV`, and `REPO_MSRV` variables, respectively.
This version can only be upgraded in breaking releases, though we release a breaking version every three months.

The following rules apply:
- The `wgpu-core` crate should never require an MSRV ahead of Firefox&#039;s MSRV for nightly builds, as
determined by the value of `MINIMUM_RUST_VERSION` in [`python/mozboot/mozboot/util.py`][moz-msrv].
- The `wgpu` crate should never require an MSRV ahead of Servo&#039;s MSRV, as determined by the value of
their rust-version declaration in [`Cargo.toml`][servo-msrv]
- The repository MSRV should never require an MSRV higher than `stable - 3`. For example, if stable is
at 1.97, the repository MSRV should be no higher than 1.94. This is to allow people who are using a decently-updated
OS-provided rust to be able to build our repository. Consider cross checking with [NixOS][nixos-msrv], though this
is not required.

[moz-msrv]: https://searchfox.org/mozilla-central/source/python/mozboot/mozboot/util.py
[servo-msrv]: https://github.com/servo/servo/blob/main/Cargo.toml#L23
[nixos-msrv]: https://search.nixos.org/packages?show=rustc

&lt;/details&gt;

## Testing and Environment Variables

[Information about testing](./docs/testing.md), including where tests of various kinds live, and how to run the tests.

## Tracking the WebGPU and WGSL draft specifications

The `wgpu` crate is meant to be an idiomatic Rust translation of the [WebGPU API][webgpu spec].
That specification, along with its shading language, [WGSL][wgsl spec],
are both still in the &quot;Working Draft&quot; phase,
and while the general outlines are stable,
details change frequently.
Until the specification is stabilized, the `wgpu` crate and the version of WGSL it implements
will likely differ from what is specified,
as the implementation catches up.

Exactly which WGSL features `wgpu` supports depends on how you are using it:

- When running as native code, `wgpu` uses [Naga][naga]
  to translate WGSL code into the shading language of your platform&#039;s native GPU API.
  Naga is working on catching up to the WGSL specification,
  with [bugs][naga bugs] tracking various issues,
  but there is no concise summary of differences from the specification.

- When running in a web browser (by compilation to WebAssembly)
  without the `&quot;webgl&quot;` feature enabled,
  `wgpu` relies on the browser&#039;s own WebGPU implementation.
  WGSL shaders are simply passed through to the browser,
  so that determines which WGSL features you can use.

- When running in a web browser with `wgpu`&#039;s `&quot;webgl&quot;` feature enabled,
  `wgpu` uses Naga to translate WGSL programs into GLSL.
  This uses the same version of Naga as if you were running `wgpu` as native code.

[webgpu spec]: https://www.w3.org/TR/webgpu/
[wgsl spec]: https://gpuweb.github.io/gpuweb/wgsl/
[naga]: https://github.com/gfx-rs/wgpu/tree/trunk/naga/
[naga bugs]: https://github.com/gfx-rs/wgpu/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22naga%22

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[GraphiteEditor/Graphite]]></title>
            <link>https://github.com/GraphiteEditor/Graphite</link>
            <guid>https://github.com/GraphiteEditor/Graphite</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:59 GMT</pubDate>
            <description><![CDATA[Open source comprehensive 2D content creation tool suite for graphic design, digital art, and interactive real-time motion graphics â€” featuring node-based procedural editing]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GraphiteEditor/Graphite">GraphiteEditor/Graphite</a></h1>
            <p>Open source comprehensive 2D content creation tool suite for graphic design, digital art, and interactive real-time motion graphics â€” featuring node-based procedural editing</p>
            <p>Language: Rust</p>
            <p>Stars: 24,468</p>
            <p>Forks: 1,099</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>

&lt;a href=&quot;https://graphite.art/&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/9366c148-4405-484f-909a-9a3526eb9209&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/791508ab-bcd5-4e31-a3b9-1187cfd7a2f6&quot;&gt;
&lt;img alt=&quot;Graphite logo&quot; src=&quot;https://github.com/user-attachments/assets/791508ab-bcd5-4e31-a3b9-1187cfd7a2f6&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;

# Your procedural toolbox for 2D content creation

**Graphite is a free, open source vector and raster graphics engine, [available now](https://editor.graphite.art) in alpha. Get creative with a fully nondestructive editing workflow that combines layer-based compositing with node-based generative design.**

Having begun life as a vector editor, Graphite continues evolving into a generalized, all-in-one graphics toolbox that&#039;s built more like a game engine than a conventional creative app. The editor&#039;s tools wrap its node graph core, providing user-friendly workflows for vector, raster, and beyond. Photo editing, motion graphics, digital painting, desktop publishing, and VFX compositing are additional competencies on the planned [roadmap](https://graphite.art/features/#roadmap) making Graphite into a highly versatile content creation tool.

Learn more from the [website](https://graphite.art/), subscribe to the [newsletter](https://graphite.art/#newsletter), consider [volunteering](https://graphite.art/volunteer/) or [donating](https://graphite.art/donate/), and remember to give this repository a â­!

&lt;br /&gt;
&lt;a href=&quot;https://discord.graphite.art/&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/ad185fac-3b48-446d-863c-2bcb0724abee&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/aa23f503-f3bf-444a-9080-8eaa19fa2fa8&quot;&gt;
&lt;img alt=&quot;Discord&quot; src=&quot;https://github.com/user-attachments/assets/aa23f503-f3bf-444a-9080-8eaa19fa2fa8&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://www.reddit.com/r/graphite/&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/d8c05686-2eb9-4ac1-8149-728c12b4e71a&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/6f32329a-4d6f-42d8-9a2f-42977c0b3c05&quot;&gt;
&lt;img alt=&quot;Reddit&quot; src=&quot;https://github.com/user-attachments/assets/6f32329a-4d6f-42d8-9a2f-42977c0b3c05&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://bsky.app/profile/graphiteeditor.bsky.social&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/c736d80c-e9bf-4591-a7e0-a7723057a906&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/3db9b0a1-5ab7-4bff-bfd3-8a4ade7b98bd&quot;&gt;
&lt;img alt=&quot;Bluesky&quot; src=&quot;https://github.com/user-attachments/assets/3db9b0a1-5ab7-4bff-bfd3-8a4ade7b98bd&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://twitter.com/graphiteeditor&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/115f04cc-e3c2-4f90-ac35-eb9edd3ca9be&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/4ed4185d-a622-418c-bbf4-a0419e690ca9&quot;&gt;
&lt;img alt=&quot;Twitter&quot; src=&quot;https://github.com/user-attachments/assets/4ed4185d-a622-418c-bbf4-a0419e690ca9&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://www.youtube.com/@GraphiteEditor&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/cbc02fad-5cbc-4715-a8e5-860198e989c7&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/d13b484d-97a8-4d9e-bbe4-c60348b3f676&quot;&gt;
&lt;img alt=&quot;YouTube&quot; src=&quot;https://github.com/user-attachments/assets/d13b484d-97a8-4d9e-bbe4-c60348b3f676&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

https://github.com/user-attachments/assets/f4604aea-e8f1-45ce-9218-46ddc666f11d

## Support our mission â¤ï¸

Graphite is 100% community built and funded. Please become a part of keeping the project alive and thriving with a [donation](https://graphite.art/donate/) if you share a belief in our **mission**:

&gt; Graphite strives to unshackle the creativity of every budding artist and seasoned professional by building the best comprehensive art and design tool that&#039;s accessible to all.
&gt; 
&gt; Mission success will come when Graphite is an industry standard. A cohesive product vision and focus on innovation over imitation is the strategy that will make that possible.

## Screenshots

![Made using nondestructive boolean operations and procedural polka dot patterns](https://github.com/user-attachments/assets/decb7011-18c2-4c68-82af-d1fa5064244a)

![Mandelbrot fractal filled with a noise pattern, procedurally generated and infinitely scalable](https://github.com/user-attachments/assets/9e023997-185b-4f43-a724-797d308d9e7b)

![Design for a magazine spread, a preview of the upcoming focus on desktop publishing](https://github.com/user-attachments/assets/90eca551-5868-4f8d-9016-33958bf96345)

## Contributing/building the code

Are you a graphics programmer or Rust developer? Graphite aims to be one of the most approachable projects for putting your engineering skills to use in the world of open source. See [instructions here](https://graphite.art/volunteer/guide/) for setting up the project and getting started.

*By submitting code for inclusion in the project, you are agreeing to license your changes under the Apache 2.0 license, and that you have the authority to do so. Some directories may have other licenses, like dual-licensed MIT/Apache 2.0, and code submissions to those directories mean you agree to the applicable license(s).*
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cloudflare/quiche]]></title>
            <link>https://github.com/cloudflare/quiche</link>
            <guid>https://github.com/cloudflare/quiche</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:58 GMT</pubDate>
            <description><![CDATA[ğŸ¥§ Savoury implementation of the QUIC transport protocol and HTTP/3]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudflare/quiche">cloudflare/quiche</a></h1>
            <p>ğŸ¥§ Savoury implementation of the QUIC transport protocol and HTTP/3</p>
            <p>Language: Rust</p>
            <p>Stars: 11,296</p>
            <p>Forks: 945</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>![quiche](quiche.svg)

[![crates.io](https://img.shields.io/crates/v/quiche.svg)](https://crates.io/crates/quiche)
[![docs.rs](https://docs.rs/quiche/badge.svg)](https://docs.rs/quiche)
[![license](https://img.shields.io/github/license/cloudflare/quiche.svg)](https://opensource.org/licenses/BSD-2-Clause)
![build](https://img.shields.io/github/actions/workflow/status/cloudflare/quiche/stable.yml?branch=master)

[quiche] is an implementation of the QUIC transport protocol and HTTP/3 as
specified by the [IETF]. It provides a low level API for processing QUIC packets
and handling connection state. The application is responsible for providing I/O
(e.g. sockets handling) as well as an event loop with support for timers.

For more information on how quiche came about and some insights into its design
you can read a [post] on Cloudflare&#039;s blog that goes into some more detail.

[quiche]: https://docs.quic.tech/quiche/
[ietf]: https://quicwg.org/
[post]: https://blog.cloudflare.com/enjoy-a-slice-of-quic-and-rust/

Who uses quiche?
----------------

### Cloudflare

quiche powers Cloudflare edge network&#039;s [HTTP/3 support][cloudflare-http3]. The
[cloudflare-quic.com](https://cloudflare-quic.com) website can be used for
testing and experimentation.

### Android

Android&#039;s DNS resolver uses quiche to [implement DNS over HTTP/3][android-http3].

### curl

quiche can be [integrated into curl][curl-http3] to provide support for HTTP/3.

[cloudflare-http3]: https://blog.cloudflare.com/http3-the-past-present-and-future/
[android-http3]: https://security.googleblog.com/2022/07/dns-over-http3-in-android.html
[curl-http3]: https://github.com/curl/curl/blob/master/docs/HTTP3.md#quiche-version

Getting Started
---------------

### Command-line apps

Before diving into the quiche API, here are a few examples on how to use the
quiche tools provided as part of the [quiche-apps](apps/) crate. These are not
suitable for production environments; see [disclaimers and
notes](#disclaimers-and-notes).

After cloning the project according to the command mentioned in the [building](#building) section, the client can be run as follows:

```bash
 $ cargo run --bin quiche-client -- https://cloudflare-quic.com/
```

while the server can be run as follows:

```bash
 $ cargo run --bin quiche-server -- --cert apps/src/bin/cert.crt --key apps/src/bin/cert.key
```

(note that the certificate provided is self-signed and should not be used in
production)

Use the `--help` command-line flag to get a more detailed description of each
tool&#039;s options.

### Configuring connections

The first step in establishing a QUIC connection using quiche is creating a
[`Config`] object:

```rust
let mut config = quiche::Config::new(quiche::PROTOCOL_VERSION)?;
config.set_application_protos(&amp;[b&quot;example-proto&quot;]);

// Additional configuration specific to application and use case...
```

The [`Config`] object controls important aspects of the QUIC connection such
as QUIC version, ALPN IDs, flow control, congestion control, idle timeout
and other properties or features.

QUIC is a general-purpose transport protocol and there are several
configuration properties where there is no reasonable default value. For
example, the permitted number of concurrent streams of any particular type
is dependent on the application running over QUIC, and other use-case
specific concerns.

quiche defaults several properties to zero, applications most likely need
to set these to something else to satisfy their needs using the following:

- [`set_initial_max_streams_bidi()`]
- [`set_initial_max_streams_uni()`]
- [`set_initial_max_data()`]
- [`set_initial_max_stream_data_bidi_local()`]
- [`set_initial_max_stream_data_bidi_remote()`]
- [`set_initial_max_stream_data_uni()`]

[`Config`] also holds TLS configuration. This can be changed by mutators on
the an existing object, or by constructing a TLS context manually and
creating a configuration using [`with_boring_ssl_ctx_builder()`].

A configuration object can be shared among multiple connections.

### Connection setup

On the client-side the [`connect()`] utility function can be used to create
a new connection, while [`accept()`] is for servers:

```rust
// Client connection.
let conn = quiche::connect(Some(&amp;server_name), &amp;scid, local, peer, &amp;mut config)?;

// Server connection.
let conn = quiche::accept(&amp;scid, None, local, peer, &amp;mut config)?;
```

### Handling incoming packets

Using the connection&#039;s [`recv()`] method the application can process
incoming packets that belong to that connection from the network:

```rust
let to = socket.local_addr().unwrap();

loop {
    let (read, from) = socket.recv_from(&amp;mut buf).unwrap();

    let recv_info = quiche::RecvInfo { from, to };

    let read = match conn.recv(&amp;mut buf[..read], recv_info) {
        Ok(v) =&gt; v,

        Err(e) =&gt; {
            // An error occurred, handle it.
            break;
        },
    };
}
```

### Generating outgoing packets

Outgoing packet are generated using the connection&#039;s [`send()`] method
instead:

```rust
loop {
    let (write, send_info) = match conn.send(&amp;mut out) {
        Ok(v) =&gt; v,

        Err(quiche::Error::Done) =&gt; {
            // Done writing.
            break;
        },

        Err(e) =&gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;out[..write], &amp;send_info.to).unwrap();
}
```

When packets are sent, the application is responsible for maintaining a
timer to react to time-based connection events. The timer expiration can be
obtained using the connection&#039;s [`timeout()`] method.

```rust
let timeout = conn.timeout();
```

The application is responsible for providing a timer implementation, which
can be specific to the operating system or networking framework used. When
a timer expires, the connection&#039;s [`on_timeout()`] method should be called,
after which additional packets might need to be sent on the network:

```rust
// Timeout expired, handle it.
conn.on_timeout();

// Send more packets as needed after timeout.
loop {
    let (write, send_info) = match conn.send(&amp;mut out) {
        Ok(v) =&gt; v,

        Err(quiche::Error::Done) =&gt; {
            // Done writing.
            break;
        },

        Err(e) =&gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;out[..write], &amp;send_info.to).unwrap();
}
```

#### Pacing

It is recommended that applications [pace] sending of outgoing packets to
avoid creating packet bursts that could cause short-term congestion and
losses in the network.

quiche exposes pacing hints for outgoing packets through the [`at`] field
of the [`SendInfo`] structure that is returned by the [`send()`] method.
This field represents the time when a specific packet should be sent into
the network.

Applications can use these hints by artificially delaying the sending of
packets through platform-specific mechanisms (such as the [`SO_TXTIME`]
socket option on Linux), or custom methods (for example by using user-space
timers).

[pace]: https://datatracker.ietf.org/doc/html/rfc9002#section-7.7
[`SO_TXTIME`]: https://man7.org/linux/man-pages/man8/tc-etf.8.html

### Sending and receiving stream data

After some back and forth, the connection will complete its handshake and
will be ready for sending or receiving application data.

Data can be sent on a stream by using the [`stream_send()`] method:

```rust
if conn.is_established() {
    // Handshake completed, send some data on stream 0.
    conn.stream_send(0, b&quot;hello&quot;, true)?;
}
```

The application can check whether there are any readable streams by using
the connection&#039;s [`readable()`] method, which returns an iterator over all
the streams that have outstanding data to read.

The [`stream_recv()`] method can then be used to retrieve the application
data from the readable stream:

```rust
if conn.is_established() {
    // Iterate over readable streams.
    for stream_id in conn.readable() {
        // Stream is readable, read until there&#039;s no more data.
        while let Ok((read, fin)) = conn.stream_recv(stream_id, &amp;mut buf) {
            println!(&quot;Got {} bytes on stream {}&quot;, read, stream_id);
        }
    }
}
```

### HTTP/3

The quiche [HTTP/3 module] provides a high level API for sending and
receiving HTTP requests and responses on top of the QUIC transport protocol.

[`Config`]: https://docs.quic.tech/quiche/struct.Config.html
[`set_initial_max_streams_bidi()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_bidi
[`set_initial_max_streams_uni()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_uni
[`set_initial_max_data()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_data
[`set_initial_max_stream_data_bidi_local()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_local
[`set_initial_max_stream_data_bidi_remote()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_remote
[`set_initial_max_stream_data_uni()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_uni
[`with_boring_ssl_ctx_builder()`]: https://docs.quic.tech/quiche/struct.Config.html#method.with_boring_ssl_ctx_builder
[`connect()`]: https://docs.quic.tech/quiche/fn.connect.html
[`accept()`]: https://docs.quic.tech/quiche/fn.accept.html
[`recv()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.recv
[`send()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.send
[`timeout()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.timeout
[`on_timeout()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.on_timeout
[`stream_send()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.stream_send
[`readable()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.readable
[`stream_recv()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.stream_recv
[HTTP/3 module]: https://docs.quic.tech/quiche/h3/index.html

Have a look at the [quiche/examples/] directory for more complete examples on
how to use the quiche API, including examples on how to use quiche in C/C++
applications (see below for more information).

[examples/]: quiche/examples/

Calling quiche from C/C++
-------------------------

quiche exposes a [thin C API] on top of the Rust API that can be used to more
easily integrate quiche into C/C++ applications (as well as in other languages
that allow calling C APIs via some form of FFI). The C API follows the same
design of the Rust one, modulo the constraints imposed by the C language itself.

When running ``cargo build``, a static library called ``libquiche.a`` will be
built automatically alongside the Rust one. This is fully stand-alone and can
be linked directly into C/C++ applications.

Note that in order to enable the FFI API, the ``ffi`` feature must be enabled (it
is disabled by default), by passing ``--features ffi`` to ``cargo``.

[thin C API]: https://github.com/cloudflare/quiche/blob/master/quiche/include/quiche.h

Building
--------

quiche requires Rust 1.85 or later to build. The latest stable Rust release can
be installed using [rustup](https://rustup.rs/).

Once the Rust build environment is setup, the quiche source code can be fetched
using git:

```bash
 $ git clone --recursive https://github.com/cloudflare/quiche
```

and then built using cargo:

```bash
 $ cargo build --examples
```

cargo can also be used to run the testsuite:

```bash
 $ cargo test
```

Note that [BoringSSL], which is used to implement QUIC&#039;s cryptographic handshake
based on TLS, needs to be built and linked to quiche. This is done automatically
when building quiche using cargo, but requires the `cmake` command to be
available during the build process. On Windows you also need
[NASM](https://www.nasm.us/). The [official BoringSSL
documentation](https://github.com/google/boringssl/blob/master/BUILDING.md) has
more details.

In alternative you can use your own custom build of BoringSSL by configuring
the BoringSSL directory with the ``QUICHE_BSSL_PATH`` environment variable:

```bash
 $ QUICHE_BSSL_PATH=&quot;/path/to/boringssl&quot; cargo build --examples
```

Alternatively you can use [OpenSSL/quictls]. To enable quiche to use this vendor
the ``openssl`` feature can be added to the ``--feature`` list. Be aware that
``0-RTT`` is not supported if this vendor is used.

[BoringSSL]: https://boringssl.googlesource.com/boringssl/

[OpenSSL/quictls]: https://github.com/quictls/openssl

### Building for Android

Building quiche for Android (NDK version 19 or higher, 21 recommended), can be
done using [cargo-ndk] (v2.0 or later).

First the [Android NDK] needs to be installed, either using Android Studio or
directly, and the `ANDROID_NDK_HOME` environment variable needs to be set to the
NDK installation path, e.g.:

```bash
 $ export ANDROID_NDK_HOME=/usr/local/share/android-ndk
```

Then the Rust toolchain for the Android architectures needed can be installed as
follows:

```bash
 $ rustup target add aarch64-linux-android armv7-linux-androideabi i686-linux-android x86_64-linux-android
```

Note that the minimum API level is 21 for all target architectures.

[cargo-ndk] (v2.0 or later) also needs to be installed:

```bash
 $ cargo install cargo-ndk
```

Finally the quiche library can be built using the following procedure. Note that
the `-t &lt;architecture&gt;` and `-p &lt;NDK version&gt;` options are mandatory.

```bash
 $ cargo ndk -t arm64-v8a -p 21 -- build --features ffi
```

See [build_android_ndk19.sh] for more information.

[Android NDK]: https://developer.android.com/ndk
[cargo-ndk]: https://docs.rs/crate/cargo-ndk
[build_android_ndk19.sh]: https://github.com/cloudflare/quiche/blob/master/tools/android/build_android_ndk19.sh

### Building for iOS

To build quiche for iOS, you need the following:

- Install Xcode command-line tools. You can install them with Xcode or with the
  following command:

```bash
 $ xcode-select --install
```

- Install the Rust toolchain for iOS architectures:

```bash
 $ rustup target add aarch64-apple-ios x86_64-apple-ios
```

- Install `cargo-lipo`:

```bash
 $ cargo install cargo-lipo
```

To build libquiche, run the following command:

```bash
 $ cargo lipo --features ffi
```

or

```bash
 $ cargo lipo --features ffi --release
```

iOS build is tested in Xcode 10.1 and Xcode 11.2.

### Building Docker images

In order to build the Docker images, simply run the following command:

```bash
 $ make docker-build
```

You can find the quiche Docker images on the following Docker Hub repositories:

- [cloudflare/quiche](https://hub.docker.com/repository/docker/cloudflare/quiche)
- [cloudflare/quiche-qns](https://hub.docker.com/repository/docker/cloudflare/quiche-qns)

The `latest` tag will be updated whenever quiche master branch updates.

**cloudflare/quiche**

Provides a server and client installed in /usr/local/bin.

**cloudflare/quiche-qns**

Provides the script to test quiche within the [quic-interop-runner](https://github.com/marten-seemann/quic-interop-runner).

Disclaimers and Notes
---------

âš ï¸ This repository includes a number of client and server example
applications that are provided to demonstrate simple usage of the quiche library
API. They are not intended to be used in production environments; no
performance, security or reliability guarantees are provided.


Copyright
---------

Copyright (C) 2018-2019, Cloudflare, Inc.

See [COPYING] for the license.

[COPYING]: https://github.com/cloudflare/quiche/tree/master/COPYING
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[prefix-dev/pixi]]></title>
            <link>https://github.com/prefix-dev/pixi</link>
            <guid>https://github.com/prefix-dev/pixi</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:57 GMT</pubDate>
            <description><![CDATA[Package management made easy]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prefix-dev/pixi">prefix-dev/pixi</a></h1>
            <p>Package management made easy</p>
            <p>Language: Rust</p>
            <p>Stars: 6,469</p>
            <p>Forks: 446</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;
  &lt;a href=&quot;https://github.com/prefix-dev/pixi/&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;https://github.com/user-attachments/assets/fb67afa5-1c2a-4f47-9b8e-d60648557bfc&quot; type=&quot;image/png&quot;&gt;
      &lt;source srcset=&quot;https://github.com/user-attachments/assets/fa2e98c2-0913-4098-9579-8f2efff7f814&quot; type=&quot;image/webp&quot;&gt;
      &lt;img src=&quot;https://github.com/user-attachments/assets/fb67afa5-1c2a-4f47-9b8e-d60648557bfc&quot; alt=&quot;banner&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;h1 align=&quot;center&quot;&gt;

![License][license-badge]
[![Project Chat][chat-badge]][chat-url]
[![Pixi Badge][pixi-badge]][pixi-url]


[license-badge]: https://img.shields.io/badge/license-BSD--3--Clause-blue?style=flat-square
[chat-badge]: https://img.shields.io/discord/1082332781146800168.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2&amp;style=flat-square
[chat-url]: https://discord.gg/kKV8ZxyzY4
[pixi-badge]:https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/prefix-dev/pixi/main/assets/badge/v0.json&amp;style=flat-square
[pixi-url]: https://pixi.sh

&lt;/h1&gt;

# Pixi: Package Management Made Easy

## Overview

`pixi` is a cross-platform, multi-language package manager and workflow tool built on the foundation of the conda ecosystem. It provides developers with an exceptional experience similar to popular package managers like [`cargo`](https://doc.rust-lang.org/cargo/) or [`npm`](https://docs.npmjs.com), but for any language.

Developed with â¤ï¸ at [prefix.dev](https://prefix.dev).
[![Real-time pixi_demo](https://github.com/prefix-dev/pixi/assets/12893423/0fc8f8c8-ac13-4c14-891b-dc613f25475b)](https://asciinema.org/a/636482)

## Highlights

- Supports **multiple languages** including Python, C++, and R using Conda packages. You can find available packages on [prefix.dev](https://prefix.dev).
- Compatible with all major operating systems: Linux, Windows, macOS (including Apple Silicon).
- Always includes an up-to-date [**lock file**](https://pixi.sh/latest/workspace/lockfile/).
- Provides a clean and simple Cargo-like **command-line interface**.
- Allows you to install tools **per-project** or **system-wide**.
- Entirely written in **Rust** and built on top of the **[rattler](https://github.com/conda/rattler)** library.

## Getting Started

- âš¡ [Installation](#installation)
- âš™ï¸ [Examples](/examples)
- ğŸ“š [Documentation](https://pixi.sh/)
- ğŸ˜ [Contributing](#contributing)
- ğŸ”¨ [Built using Pixi](#built-using-pixi)
- ğŸš€ [GitHub Action](https://github.com/prefix-dev/setup-pixi)

## Status

Pixi is ready for production!
We are working hard to keep file-format changes compatible with the previous
versions so that you can rely on Pixi with peace of mind.

Some notable features we envision for upcoming releases are:

- **Build and publish** your project as a Conda package.
- Support for **dependencies from source**.
- More powerful &quot;global installation&quot; of packages towards a deterministic setup of global packages on multiple machines.

## Installation

`pixi` can be installed on macOS, Linux, and Windows. The provided scripts will automatically download the latest version of `pixi`, extract it, and move the `pixi` binary to `~/.pixi/bin`. If this directory does not exist, the script will create it.

### macOS and Linux

To install Pixi on macOS and Linux, open a terminal and run the following command:

```bash
curl -fsSL https://pixi.sh/install.sh | sh
# or with brew
brew install pixi
```

The script will also update your `~/.bashrc` to include `~/.pixi/bin` in your `PATH`, allowing you to invoke the `pixi` command from anywhere.
You might need to restart your terminal or source your shell for the changes to take effect.

Starting with macOS Catalina [zsh is the default login shell and interactive shell](https://support.apple.com/en-us/102360). Therefore, you might want to use `zsh` instead of `bash` in the install command:

```zsh
curl -fsSL https://pixi.sh/install.sh | zsh
```

The script will also update your `~/.zshrc` to include `~/.pixi/bin` in your `PATH`, allowing you to invoke the `pixi` command from anywhere.

### Windows

To install Pixi on Windows, open a PowerShell terminal (you may need to run it as an administrator) and run the following command:

```powershell
powershell -ExecutionPolicy ByPass -c &quot;irm -useb https://pixi.sh/install.ps1 | iex&quot;
```
Changing the [execution policy](https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_execution_policies?view=powershell-7.4#powershell-execution-policies) allows running a script from the internet.
Check the script you would be running with:
```powershell
powershell -c &quot;irm -useb https://pixi.sh/install.ps1 | more&quot;
```

The script will inform you once the installation is successful and add the `~/.pixi/bin` directory to your `PATH`, which will allow you to run the `pixi` command from any location.
Or with `winget`

```shell
winget install prefix-dev.pixi
```

### Autocompletion

To get autocompletion follow the instructions for your shell.
Afterwards, restart the shell or source the shell config file.

#### Bash (default on most Linux systems)

Add the following to the end of `~/.bashrc`:

```bash
# ~/.bashrc

eval &quot;$(pixi completion --shell bash)&quot;
```
#### Zsh (default on macOS)

Add the following to the end of `~/.zshrc`:


```zsh
# ~/.zshrc

eval &quot;$(pixi completion --shell zsh)&quot;
```

#### PowerShell (pre-installed on all Windows systems)

Add the following to the end of `Microsoft.PowerShell_profile.ps1`.
You can check the location of this file by querying the `$PROFILE` variable in PowerShell.
Typically the path is `~\Documents\PowerShell\Microsoft.PowerShell_profile.ps1` or
`~/.config/powershell/Microsoft.PowerShell_profile.ps1` on -Nix.

```pwsh
(&amp; pixi completion --shell powershell) | Out-String | Invoke-Expression
```

#### Fish

Add the following to the end of `~/.config/fish/config.fish`:

```fish
# ~/.config/fish/config.fish

pixi completion --shell fish | source
```

#### Nushell

Add the following to your Nushell config file (find it by running `$nu.config-path` in Nushell):

```nushell
mkdir $&quot;($nu.data-dir)/vendor/autoload&quot;
pixi completion --shell nushell | save --force $&quot;($nu.data-dir)/vendor/autoload/pixi-completions.nu&quot;
```

#### Elvish

Add the following to the end of `~/.elvish/rc.elv`:

```elv
# ~/.elvish/rc.elv

eval (pixi completion --shell elvish | slurp)
```

### Distro Packages

[![Packaging status](https://repology.org/badge/vertical-allrepos/pixi.svg)](https://repology.org/project/pixi/versions)

#### Arch Linux

You can install `pixi` from the [extra repository](https://archlinux.org/packages/extra/x86_64/pixi/) using [pacman](https://wiki.archlinux.org/title/Pacman):

```shell
pacman -S pixi
```

#### Alpine Linux

`pixi` is available for [Alpine Edge](https://pkgs.alpinelinux.org/packages?name=pixi&amp;branch=edge). It can be installed via [apk](https://wiki.alpinelinux.org/wiki/Alpine_Package_Keeper) after enabling the [testing repository](https://wiki.alpinelinux.org/wiki/Repositories).

```shell
apk add pixi
```

## Build/install from source

`pixi` is 100% written in Rust and therefore it can be installed, built and tested with cargo.
To start using `pixi` from a source build run:

```shell
cargo install --locked --git https://github.com/prefix-dev/pixi.git pixi
```

We don&#039;t publish to `crates.io` anymore, so you need to install it from the repository.
The reason for this is that we depend on some unpublished crates which disallows us to publish to `crates.io`.

If you install pixi that way, it isn&#039;t necessarily the first in your PATH.
The one installed by the installation script might take precedence.
Therefore, we recommend running the following task instead for local development:

```shell
pixi run install-as pixid
```

This way, a new binary called `pixid` will be available without any name conflicts with other Pixi installations on your system.

## Uninstall

To uninstall, the Pixi binary should be removed.
Delete `pixi` from the `$PIXI_DIR` which is default to `~/.pixi/bin/pixi`

So on Linux its:

```shell
rm ~/.pixi/bin/pixi
```

and on Windows:

```shell
$PIXI_BIN = &quot;$Env:LocalAppData\pixi\bin\pixi&quot;; Remove-Item -Path $PIXI_BIN
```

After this command you can still use the tools you installed with `pixi`.
To remove these as well just remove the whole `~/.pixi` directory and remove the directory from your path.

# Usage

The cli looks as follows:

```bash
âœ pixi
Pixi [version 0.59.0] - Developer Workflow and Environment Management for Multi-Platform, Language-Agnostic
Workspaces.

Pixi is a versatile developer workflow tool designed to streamline the management of your workspace&#039;s dependencies,
tasks, and environments.
Built on top of the Conda ecosystem, Pixi offers seamless integration with the PyPI ecosystem.

Basic Usage:
    Initialize pixi for a workspace:
    $ pixi init
    $ pixi add python numpy pytest

    Run a task:
    $ pixi task add test &#039;pytest -s&#039;
    $ pixi run test

Found a Bug or Have a Feature Request?
Open an issue at: https://github.com/prefix-dev/pixi/issues

Need Help?
Ask a question on the Prefix Discord server: https://discord.gg/kKV8ZxyzY4

For more information, see the documentation at: https://pixi.sh

Usage: pixi [OPTIONS] [COMMAND]

Commands:
  add         Adds dependencies to the workspace [aliases: a]
  auth        Login to prefix.dev or anaconda.org servers to access private channels
  build       Workspace configuration
  clean       Cleanup the environments
  completion  Generates a completion script for a shell
  config      Configuration management
  exec        Run a command and install it in a temporary environment [aliases: x]
  global      Subcommand for global package management actions [aliases: g]
  info        Information about the system, workspace and environments for the current machine
  init        Creates a new workspace
  import      Imports a file into an environment in an existing workspace.
  install     Install an environment, both updating the lockfile and installing the environment [aliases: i]
  list        List the packages of the current workspace [aliases: ls]
  lock        Solve environment and update the lock file without installing the environments
  reinstall   Re-install an environment, both updating the lockfile and re-installing the environment
  remove      Removes dependencies from the workspace [aliases: rm]
  run         Runs task in the pixi environment [aliases: r]
  search      Search a conda package
  shell       Start a shell in a pixi environment, run `exit` to leave the shell [aliases: s]
  shell-hook  Print the pixi environment activation script
  task        Interact with tasks in the workspace
  tree        Show a tree of workspace dependencies [aliases: t]
  update      The `update` command checks if there are newer versions of the dependencies and updates the `pixi.lock`
              file and environments accordingly
  upgrade     Checks if there are newer versions of the dependencies and upgrades them in the lockfile and manifest
              file
  upload      Upload a conda package
  workspace   Modify the workspace configuration file through the command line
  help        Print this message or the help of the given subcommand(s)

Options:
  -V, --version  Print version

Global Options:
  -h, --help           Display help information
  -v, --verbose...     Increase logging verbosity (-v for warnings, -vv for info, -vvv for debug, -vvvv for trace)
  -q, --quiet...       Decrease logging verbosity (quiet mode)
      --color &lt;COLOR&gt;  Whether the log needs to be colored [env: PIXI_COLOR=] [default: auto] [possible values:
                       always, never, auto]
      --no-progress    Hide all progress bars, always turned on if stderr is not a terminal [env: PIXI_NO_PROGRESS=]
      --list           List all installed commands (built-in and extensions)
```

## Creating a Pixi workspace

Initialize a new workspace and navigate to the workspace directory

```
pixi init myworkspace
cd myworkspace
```

Add the dependencies you want to use

```
pixi add cowpy
```

Run the installed package in its environment

```bash
pixi run cowpy &quot;Thanks for using pixi&quot;
```

Activate a shell in the environment

```shell
pixi shell
cowpy &quot;Thanks for using pixi&quot;
exit
```

Check out https://pixi.sh/dev/first_workspace/ for a more detailed introduction to workspaces.

## Installing a conda package globally

You can also globally install conda packages into their own environment.
This behavior is similar to [`pipx`](https://github.com/pypa/pipx) or [`condax`](https://github.com/mariusvniekerk/condax).

```bash
pixi global install cowpy
```

## Use in GitHub Actions

You can use Pixi in GitHub Actions to install dependencies and run commands.
It supports automatic caching of your environments.

```yml
- uses: prefix-dev/setup-pixi@v0.8.1
- run: pixi exec cowpy &quot;Thanks for using pixi&quot;
```

See the [documentation](https://pixi.sh/latest/advanced/github_actions) for more details.

&lt;a name=&quot;contributing&quot;&gt;&lt;/a&gt;

## Contributing ğŸ˜

We would absolutely love for you to contribute to Pixi!
Whether you want to start an issue, fix a bug you encountered, or suggest an
improvement, every contribution is greatly appreciated.

If you&#039;re just getting started with our project or stepping into the Rust
ecosystem for the first time, we&#039;ve got your back!
We recommend beginning with issues labeled as `good first issue`.
These are carefully chosen tasks that provide a smooth entry point into
contributing.These issues are typically more straightforward and are a great way
to get familiar with the project.

Got questions or ideas, or just want to chat? Join our lively conversations on
Discord.
We&#039;re very active and would be happy to welcome you to our
community. [Join our discord server today!][chat-url]

&lt;a name=&quot;pixibuilt&quot;&gt;&lt;/a&gt;

## Built using Pixi

To see what&#039;s being built with `pixi` check out the [Community](/docs/misc/Community.md) page.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[slint-ui/slint]]></title>
            <link>https://github.com/slint-ui/slint</link>
            <guid>https://github.com/slint-ui/slint</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:56 GMT</pubDate>
            <description><![CDATA[Slint is an open-source declarative GUI toolkit to build native user interfaces for Rust, C++, JavaScript, or Python apps.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/slint-ui/slint">slint-ui/slint</a></h1>
            <p>Slint is an open-source declarative GUI toolkit to build native user interfaces for Rust, C++, JavaScript, or Python apps.</p>
            <p>Language: Rust</p>
            <p>Stars: 21,858</p>
            <p>Forks: 827</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>
![Slint](./logo/slint-logo-full-light.svg#gh-light-mode-only) ![Slint](./logo/slint-logo-full-dark.svg#gh-dark-mode-only)

[![Build Status](https://github.com/slint-ui/slint/workflows/CI/badge.svg)](https://github.com/slint-ui/slint/actions)
[![REUSE status](https://api.reuse.software/badge/github.com/slint-ui/slint)](https://api.reuse.software/info/github.com/slint-ui/slint)
[![Discussions](https://img.shields.io/github/discussions/slint-ui/slint)](https://github.com/slint-ui/slint/discussions)

**Slint** is an open-source declarative GUI toolkit for building native user interfaces for embedded systems, desktops, and mobile platforms.

Write your UI once in `.slint`, a simple markup language. Connect it to business logic written in Rust, C++, JavaScript, or Python.

## Why Slint?

The name *Slint* is derived from our design goals:

- **Scalable**: Slint should support responsive UI design, allow cross-platform
    usage across operating systems and processor architectures and support
    multiple programming languages.
- **Lightweight**: Slint should require minimal resources, in terms of memory
    and processing power, and yet deliver a smooth, smartphone-like user
    experience on any device.
- **Intuitive**: Designers and developers should feel productive while enjoying
    the GUI design and development process. The design creation tools should be
    intuitive to use for the designers. Similarly for the developers, the APIs
    should be consistent and easy to use, no matter which programming language
    they choose.
- **Native**: GUI built with Slint should match the end users&#039; expectations of a
    native application irrespective of the platform - desktop, mobile, web or
    embedded system. The UI design should be compiled to machine code and provide
    flexibility that only a native application can offer: Access full operating
    system APIs, utilize all CPU and GPU cores, connect to any peripheral.

Beyond the design goals, hereâ€™s what makes Slint stand out:

- **Independent UI Design**: Use a declarative language similar to separate your UI from business logic. Designers can work in parallel with developers.
- **Tooling**: Iterate quickly with our Live Preview &amp; editor integrations. Integrate from Figma with the [Figma to Slint plugin](https://www.figma.com/community/plugin/1474418299182276871/figma-to-slint).
- **Stable APIs**: Slint follows a stable 1.x API. We evolve carefully without breaking your code.

See what others have built: [#MadeWithSlint](https://madewithslint.com)

## Examples

### Embedded

| RaspberryPi                          | STM32                         | RP2040                         |
| ------------------------------------ | ----------------------------- | ------------------------------ |
| [Video of Slint on Raspberry Pi][#1] | [Video of Slint on STM32][#2] | [Video of Slint on RP2040][#3] |

### Desktop

| Windows                                     | macOS                                     | Linux                                     |
| ------------------------------------------- | ----------------------------------------- | ----------------------------------------- |
| ![Screenshot of the Gallery on Windows][#4] | ![Screenshot of the Gallery on macOS][#5] | ![Screenshot of the Gallery on Linux][#6] |

### Web using WebAssembly

| Printer Demo                                | Slide Puzzle                                 | Energy Monitor                                       | Widget Gallery                                | Weather demo                                  |
| ------------------------------------------- | -------------------------------------------- | ---------------------------------------------------- | --------------------------------------------- | --------------------------------------------- |
| [![Screenshot of the Printer Demo][#7]][#8] | [![Screenshot of the Slide Puzzle][#9]][#10] | [![Screenshot of the Energy Monitor Demo][#11]][#12] | [![Screenshot of the Gallery Demo][#13]][#14] | [![Screenshot of the weather Demo][#29]][#30] |

More examples and demos in the [examples folder](examples#examples)

## Get Started

### Hello World

The UI is defined in a Domain Specific Language that is declarative, easy to use,
intuitive, and provides a powerful way to describe graphical elements, their
placement, their hierarchy, property bindings, and the flow of data through the
different states.

Here&#039;s the obligatory &quot;Hello World&quot;:

```slint
export component HelloWorld inherits Window {
    width: 400px;
    height: 400px;

    Text {
       y: parent.width / 2;
       x: parent.x + 200px;
       text: &quot;Hello, world&quot;;
       color: blue;
    }
}
```

### Documentation

For more details, check out the [Slint Language Documentation](https://slint.dev/docs/slint).

The [examples](examples) folder contains examples and demos, showing how to
use the Slint markup language and how to interact with a Slint user interface
from supported programming languages.

The `docs` folder contains a lot more information, including
[build instructions](docs/building.md), and
[internal developer docs](docs/development.md).

Refer to the README of each language directory in the `api` folder:

- [C++](api/cpp) ([Documentation][#15] | [Getting Started Template][#17])
- [Rust](api/rs/slint) [![Crates.io][#18]][#19] ([Documentation][#20] | [Tutorial Video][#22] | [Getting Started Template][#23])
- [JavaScript/NodeJS (Beta)](api/node) [![npm][#24]][#25] ([Documentation][#26] | [Getting Started Template][#28])
- [Python (Beta)](api/python/slint) [![pypi][#31]][#32] ([Documentation][#33] | [Getting Started Template][#34])

## Architecture

An application is composed of the business logic written in Rust, C++, or
JavaScript and the `.slint` user interface design markup, which is compiled to
native code.

![Architecture Overview](https://slint.dev/resources/architecture.drawio.svg)

### Compiler

The `.slint` files are compiled ahead of time. The expressions in the `.slint`
are pure functions that the compiler can optimize. For example, the compiler
could choose to &quot;inline&quot; properties and remove those that are constant or
unchanged.

The compiler uses the typical compiler phases of lexing, parsing, optimization,
and finally code generation. It provides different back-ends for code generation
in the target language. The C++ code generator produces a C++ header file, the
Rust generator produces Rust code, and so on. An interpreter for dynamic
languages is also included.

### Runtime

The runtime library consists of an engine that supports properties declared in
the `.slint` language. Components with their elements, items, and properties are
laid out in a single memory region, to reduce memory allocations.

Rendering backends and styles are configurable at compile time:

- The `femtovg` renderer uses OpenGL ES 2.0 for rendering.
- The `skia` renderer uses [Skia](https://skia.org) for rendering.
- The `software` renderer uses the CPU with no additional dependencies.

NOTE: When Qt is installed on the system, the `qt` style becomes available,
using Qt&#039;s QStyle to achieve native looking widgets.

### Tooling

We have a few tools to help with the development of .slint files:

- A [**LSP Server**](./tools/lsp) that adds features like auto-complete and live
  preview of the .slint files to many editors.
- It is bundled in a [**Visual Studio Code Extension**](./editors/vscode)
  available from the market place.
- A [**slint-viewer**](./tools/viewer) tool which displays the .slint files. The
  `--auto-reload` argument makes it easy to preview your UI while you are
  working on it (when using the LSP preview is not possible).
- [**SlintPad**](https://slintpad.com/), an online editor to try out .slint syntax
  without installing anything ([sources](./tools/slintpad)).
- A [**Figma to Slint**](https://www.figma.com/community/plugin/1474418299182276871/figma-to-slint) plugin.

Please check our [Editors README](./editors/README.md) for tips on how to
configure your favorite editor to work well with Slint.

## License

You can use Slint under ***any*** of the following licenses, at your choice:

1. Build proprietary desktop, mobile, or web applications for free with the [Royalty-free License](LICENSES/LicenseRef-Slint-Royalty-free-2.0.md),
2. Build open source embedded, desktop, mobile, or web applications for free with the [GNU GPLv3](LICENSES/GPL-3.0-only.txt),
3. Build proprietary embedded, desktop, mobile, or web applications with the [Paid license](LICENSES/LicenseRef-Slint-Software-3.0.md).

See the [Slint licensing options on the website](https://slint.dev/pricing.html) and the [Licensing FAQ](FAQ.md#licensing).

## Contributions

We welcome your contributions: in the form of code, bug reports or feedback.
For contribution guidelines see [CONTRIBUTING.md](CONTRIBUTING.md).

## Frequently Asked Questions

Please see our separate [FAQ](FAQ.md).

## About us (SixtyFPS GmbH)

We are passionate about software - API design, cross-platform software
development and user interface components. Our aim is to make developing user
interfaces fun for everyone: from Python, JavaScript, C++, or Rust developers all the
way to UI/UX designers. We believe that software grows organically and keeping
it open source is the best way to sustain that growth. Our team members are
located remotely in Germany, Finland, and US.

### Stay up to date

- Follow [@slint_ui](https://twitter.com/slint_ui) on X/Twitter.
- Follow [@slint@fosstodon.org](https://mastodon.social/@slint@fosstodon.org) on Mastodon.
- Follow [@slint-ui](https://www.linkedin.com/company/slint-ui/) on LinkedIn.
- Follow [@slint.dev](https://bsky.app/profile/slint.dev) on Bluesky
- Subscribe to our [YouTube channel](https://www.youtube.com/@Slint-UI)

### Contact us

Feel free to join [Github discussions](https://github.com/slint-ui/slint/discussions)
for general chat or questions. Use [Github issues](https://github.com/slint-ui/slint/issues)
to report public suggestions or bugs.

We chat in [our Mattermost instance](https://chat.slint.dev) where you are
welcome to listen in or ask your questions.

You can of course also contact us privately via email to [info@slint.dev](mailto://info@slint.dev).

[#1]: https://www.youtube.com/watch?v=_BDbNHrjK7g
[#2]: https://www.youtube.com/watch?v=NNNOJJsOAis
[#3]: https://www.youtube.com/watch?v=dkBwNocItGs
[#4]: https://slint.dev/resources/gallery_win_screenshot.png &quot;Gallery&quot;
[#5]: https://slint.dev/resources/gallery_mac_screenshot.png &quot;Gallery&quot;
[#6]: https://slint.dev/resources/gallery_linux_screenshot.png &quot;Gallery&quot;
[#7]: https://slint.dev/resources/printerdemo_screenshot.png &quot;Printer Demo&quot;
[#8]: https://slint.dev/demos/printerdemo/
[#9]: https://slint.dev/resources/puzzle_screenshot.png &quot;Slide Puzzle&quot;
[#10]: https://slint.dev/demos/slide_puzzle/
[#11]: https://slint.dev/resources/energy-monitor-screenshot.png &quot;Energy Monitor Demo&quot;
[#12]: https://slint.dev/demos/energy-monitor/
[#13]: https://slint.dev/resources/gallery_screenshot.png &quot;Gallery Demo&quot;
[#14]: https://slint.dev/demos/gallery/
[#15]: https://slint.dev/latest/docs/cpp
[#17]: https://github.com/slint-ui/slint-cpp-template
[#18]: https://img.shields.io/crates/v/slint
[#19]: https://crates.io/crates/slint
[#20]: https://slint.dev/latest/docs/rust/slint/
[#22]: https://youtu.be/WBcv4V-whHk
[#23]: https://github.com/slint-ui/slint-rust-template
[#24]: https://img.shields.io/npm/v/slint-ui
[#25]: https://www.npmjs.com/package/slint-ui
[#26]: https://slint.dev/latest/docs/node
[#28]: https://github.com/slint-ui/slint-nodejs-template
[#29]: ./demos/weather-demo/docs/img/desktop-preview.png &quot;Weather Demo&quot;
[#30]: https://slint.dev/demos/weather-demo/
[#31]: https://img.shields.io/pypi/v/slint
[#32]: https://pypi.org/project/slint/
[#33]: http://snapshots.slint.dev/master/docs/python/
[#34]: https://github.com/slint-ui/slint-python-template
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[j178/prek]]></title>
            <link>https://github.com/j178/prek</link>
            <guid>https://github.com/j178/prek</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:55 GMT</pubDate>
            <description><![CDATA[âš¡ Better `pre-commit`, re-engineered in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/j178/prek">j178/prek</a></h1>
            <p>âš¡ Better `pre-commit`, re-engineered in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 6,598</p>
            <p>Forks: 177</p>
            <p>Stars today: 91 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;h1&gt;
  &lt;img width=&quot;180&quot; alt=&quot;prek&quot; src=&quot;https://raw.githubusercontent.com/j178/prek/master/docs/assets/logo.webp&quot; /&gt;
  &lt;br/&gt;prek
&lt;/h1&gt;

[![prek](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/j178/prek/master/docs/assets/badge-v0.json)](https://github.com/j178/prek)
[![codecov](https://codecov.io/github/j178/prek/graph/badge.svg?token=MP6TY24F43)](https://codecov.io/github/j178/prek)
[![GitHub Downloads](https://img.shields.io/github/downloads/j178/prek/total?logo=github)](https://github.com/j178/prek/releases)
[![PyPI Downloads](https://img.shields.io/pypi/dm/prek?logo=python)](https://pepy.tech/projects/prek)
[![Discord](https://img.shields.io/discord/1403581202102878289?logo=discord)](https://discord.gg/3NRJUqJz86)

&lt;/div&gt;

&lt;!-- --8&lt;-- [start: description] --&gt;

[pre-commit](https://pre-commit.com/) is a framework to run hooks written in many languages, and it manages the
language toolchain and dependencies for running the hooks.

*prek* is a reimagined version of pre-commit, built in Rust.
It is designed to be a faster, dependency-free and drop-in alternative for it,
while also providing some additional long-requested features.

&lt;!-- --8&lt;-- [end: description] --&gt;

&gt; [!NOTE]
&gt; Although prek is pretty new, itâ€™s already powering realâ€‘world projects like [CPython](https://github.com/python/cpython), [Apache Airflow](https://github.com/apache/airflow), [FastAPI](https://github.com/fastapi/fastapi), and more projects are picking it upâ€”see [Who is using prek?](#who-is-using-prek). If youâ€™re looking for an alternative to `pre-commit`, please give it a tryâ€”weâ€™d love your feedback!
&gt;
&gt; Please note that some languages are not yet supported for full dropâ€‘in parity with `pre-commit`. See [Language Support](https://prek.j178.dev/languages/) for current status.

&lt;!-- --8&lt;-- [start:features] --&gt;

## Features

- A single binary with no dependencies, does not require Python or any other runtime.
- [Faster](https://prek.j178.dev/benchmark/) than `pre-commit` and more efficient in disk space usage.
- Fully compatible with the original pre-commit configurations and hooks.
- Built-in support for monorepos (i.e. [workspace mode](https://prek.j178.dev/workspace/)).
- Integration with [`uv`](https://github.com/astral-sh/uv) for managing Python virtual environments and dependencies.
- Improved toolchain installations for Python, Node.js, Bun, Go, Rust and Ruby, shared between hooks.
- [Built-in](https://prek.j178.dev/builtin/) Rust-native implementation of some common hooks.

&lt;!-- --8&lt;-- [end:features] --&gt;

## Table of contents

- [Installation](#installation)
- [Quick start](#quick-start)
- [Why prek?](#why-prek)
- [Who is using prek?](#who-is-using-prek)
- [Acknowledgements](#acknowledgements)

## Installation

&lt;details&gt;
&lt;summary&gt;Standalone installer&lt;/summary&gt;

prek provides a standalone installer script to download and install the tool,

On Linux and macOS:

&lt;!-- --8&lt;-- [start: linux-standalone-install] --&gt;

```bash
curl --proto &#039;=https&#039; --tlsv1.2 -LsSf https://github.com/j178/prek/releases/download/v0.3.4/prek-installer.sh | sh
```

&lt;!-- --8&lt;-- [end: linux-standalone-install] --&gt;

On Windows:

&lt;!-- --8&lt;-- [start: windows-standalone-install] --&gt;

```powershell
powershell -ExecutionPolicy ByPass -c &quot;irm https://github.com/j178/prek/releases/download/v0.3.4/prek-installer.ps1 | iex&quot;
```

&lt;!-- --8&lt;-- [end: windows-standalone-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;PyPI&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: pypi-install] --&gt;

prek is published as Python binary wheel to PyPI, you can install it using `pip`, `uv` (recommended), or `pipx`:

```bash
# Using uv (recommended)
uv tool install prek

# Using uvx (install and run in one command)
uvx prek

# Adding prek to the project dev-dependencies
uv add --dev prek

# Using pip
pip install prek

# Using pipx
pipx install prek
```

&lt;!-- --8&lt;-- [end: pypi-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Homebrew&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: homebrew-install] --&gt;

```bash
brew install prek
```

&lt;!-- --8&lt;-- [end: homebrew-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;mise&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: mise-install] --&gt;

To use prek with [mise](https://mise.jdx.dev) ([v2025.8.11](https://github.com/jdx/mise/releases/tag/v2025.8.11) or later):

```bash
mise use prek
```

&lt;!-- --8&lt;-- [end: mise-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Cargo binstall&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: cargo-binstall] --&gt;

Install pre-compiled binaries from GitHub using [cargo-binstall](https://github.com/cargo-bins/cargo-binstall):

```bash
cargo binstall prek
```

&lt;!-- --8&lt;-- [end: cargo-binstall] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Cargo&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: cargo-install] --&gt;

Build from source using Cargo (Rust 1.89+ is required):

```bash
cargo install --locked prek
```

&lt;!-- --8&lt;-- [end: cargo-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;npmjs&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: npmjs-install] --&gt;

prek is published as a [Node.js package](https://www.npmjs.com/package/@j178/prek)
and can be installed with any npm-compatible package manager:

```bash
# As a dev dependency
npm add -D @j178/prek
pnpm add -D @j178/prek
bun add -D @j178/prek

# Or install globally
npm install -g @j178/prek
pnpm add -g @j178/prek
bun install -g @j178/prek

# Or run directly without installing
npx @j178/prek --version
bunx @j178/prek --version
```

&lt;!-- --8&lt;-- [end: npmjs-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Nix&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: nix-install] --&gt;

prek is available via [Nixpkgs](https://search.nixos.org/packages?channel=unstable&amp;show=prek&amp;query=prek).

```shell
# Choose what&#039;s appropriate for your use case.
# One-off in a shell:
nix-shell -p prek

# NixOS or non-NixOS without flakes:
nix-env -iA nixos.prek

# Non-NixOS with flakes:
nix profile install nixpkgs#prek
```

&lt;!-- --8&lt;-- [end: nix-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Conda&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: conda-forge-install] --&gt;

prek is available as `prek` via [conda-forge](https://anaconda.org/conda-forge/prek).

```shell
conda install conda-forge::prek
```

&lt;!-- --8&lt;-- [end: conda-forge-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Scoop (Windows)&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: scoop-install] --&gt;

prek is available via [Scoop](https://scoop.sh/#/apps?q=prek).

```powershell
scoop install main/prek
```

&lt;!-- --8&lt;-- [end: scoop-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Winget (Windows)&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: winget-install] --&gt;

prek is available via [winget](https://learn.microsoft.com/en-us/windows/package-manager/winget/).

```powershell
winget install --id j178.Prek
```

&lt;!-- --8&lt;-- [end: winget-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;MacPorts&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: macports-install] --&gt;

prek is available via [MacPorts](https://ports.macports.org/port/prek/).

```bash
sudo port install prek
```

&lt;!-- --8&lt;-- [end: macports-install] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;GitHub Releases&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: pre-built-binaries] --&gt;

Pre-built binaries are available for download from the [GitHub releases](https://github.com/j178/prek/releases) page.

&lt;!-- --8&lt;-- [end: pre-built-binaries] --&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;GitHub Actions&lt;/summary&gt;

&lt;!-- --8&lt;-- [start: github-actions] --&gt;

prek can be used in GitHub Actions via the [j178/prek-action](https://github.com/j178/prek-action) repository.

Example workflow:

```yaml
name: Prek checks
on: [push, pull_request]

jobs:
  prek:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
      - uses: j178/prek-action@v1
```

This action installs prek and runs `prek run --all-files` on your repository.

prek is also available via [`taiki-e/install-action`](https://github.com/taiki-e/install-action) for installing various tools.

&lt;!-- --8&lt;-- [end: github-actions] --&gt;

&lt;/details&gt;

&lt;!-- --8&lt;-- [start: self-update] --&gt;

If installed via the standalone installer, prek can update itself to the latest version:

```bash
prek self update
```

&lt;!-- --8&lt;-- [end: self-update] --&gt;

## Quick start

- **I already use pre-commit:** follow the short migration checklist in the [quickstart guide](https://prek.j178.dev/quickstart/#already-using-pre-commit) to swap in `prek` safely.
- **I&#039;m new to pre-commit-style tools:** learn the basicsâ€”creating a config, running hooks, and installing git hooksâ€”in the [beginner quickstart walkthrough](https://prek.j178.dev/quickstart/#new-to-pre-commit-style-workflows).

&lt;!-- --8&lt;-- [start: why] --&gt;

## Why prek?

### prek is faster

- It is [multiple times faster](https://prek.j178.dev/benchmark/) than `pre-commit` and takes up half the disk space.
- It redesigned how hook environments and toolchains are managed, they are all shared between hooks, which reduces the disk space usage and speeds up the installation process.
- Repositories are cloned in parallel, and hooks are installed in parallel if their dependencies are disjoint.
- Hooks can run in parallel by priority (hooks with the same [`priority`](https://prek.j178.dev/configuration/#priority) may run concurrently), reducing end-to-end runtime.
- It uses [`uv`](https://github.com/astral-sh/uv) for creating Python virtualenvs and installing dependencies, which is known for its speed and efficiency.
- It implements some common hooks in Rust, [built in prek](https://prek.j178.dev/builtin/), which are faster than their Python counterparts.
- It supports `repo: builtin` for offline, zero-setup hooks, which is not available in `pre-commit`.

### prek provides a better user experience

- No need to install Python or any other runtime, just download a single binary.
- No hassle with your Python version or virtual environments, prek automatically installs the required Python version and creates a virtual environment for you.
- Built-in support for [workspaces](https://prek.j178.dev/workspace/) (or monorepos), each subproject can have its own `.pre-commit-config.yaml` file.
- [`prek run`](https://prek.j178.dev/cli/#prek-run) has some nifty improvements over `pre-commit run`, such as:
    - `prek run --directory &lt;dir&gt;` runs hooks for files in the specified directory, no need to use `git ls-files -- &lt;dir&gt; | xargs pre-commit run --files` anymore.
    - `prek run --last-commit` runs hooks for files changed in the last commit.
    - `prek run [HOOK] [HOOK]` selects and runs multiple hooks.
- [`prek list`](https://prek.j178.dev/cli/#prek-list) command lists all available hooks, their ids, and descriptions, providing a better overview of the configured hooks.
- [`prek auto-update`](https://prek.j178.dev/cli/#prek-auto-update) supports `--cooldown-days` to mitigate open source supply chain attacks.
- prek provides shell completions for `prek run &lt;hook_id&gt;` command, making it easier to run specific hooks without remembering their ids.

For more detailed improvements prek offers, take a look at [Difference from pre-commit](https://prek.j178.dev/diff/).

## Who is using prek?

prek is pretty new, but it is already being used or recommend by some projects and organizations:

- [apache/airflow](https://github.com/apache/airflow/issues/44995)
- [python/cpython](https://github.com/python/cpython/issues/143148)
- [pdm-project/pdm](https://github.com/pdm-project/pdm/pull/3593)
- [fastapi/fastapi](https://github.com/fastapi/fastapi/pull/14572)
- [fastapi/typer](https://github.com/fastapi/typer/pull/1453)
- [fastapi/asyncer](https://github.com/fastapi/asyncer/pull/437)
- [astral-sh/ruff](https://github.com/astral-sh/ruff/pull/22505)
- [astral-sh/ty](https://github.com/astral-sh/ty/pull/2469)
- [openclaw/openclaw](https://github.com/openclaw/openclaw/pull/1720)
- [home-assistant/core](https://github.com/home-assistant/core/pull/160427)
- [DetachHead/basedpyright](https://github.com/DetachHead/basedpyright/pull/1413)
- [OpenLineage/OpenLineage](https://github.com/OpenLineage/OpenLineage/pull/3965)
- [authlib/authlib](https://github.com/authlib/authlib/pull/804)
- [django/djangoproject.com](https://github.com/django/djangoproject.com/pull/2252)
- [Future-House/paper-qa](https://github.com/Future-House/paper-qa/pull/1098)
- [requests-cache/requests-cache](https://github.com/requests-cache/requests-cache/pull/1116)
- [Goldziher/kreuzberg](https://github.com/Goldziher/kreuzberg/pull/142)
- [python-attrs/attrs](https://github.com/python-attrs/attrs/commit/c95b177682e76a63478d29d040f9cb36a8d31915)
- [jlowin/fastmcp](https://github.com/jlowin/fastmcp/pull/2309)
- [apache/iceberg-python](https://github.com/apache/iceberg-python/pull/2533)
- [apache/iggy](https://github.com/apache/iggy/pull/2383)
- [apache/lucene](https://github.com/apache/lucene/pull/15629)
- [jcrist/msgspec](https://github.com/jcrist/msgspec/pull/918)
- [python-humanize/humanize](https://github.com/python-humanize/humanize/pull/276)
- [MoonshotAI/kimi-cli](https://github.com/MoonshotAI/kimi-cli/pull/535)
- [simple-icons/simple-icons](https://github.com/simple-icons/simple-icons/pull/14245)
- [ast-grep/ast-grep](https://github.com/ast-grep/ast-grep.github.io/commit/e30818144b2967a7f9172c8cf2f4596bba219bf5)
- [commitizen-tools/commitizen](https://github.com/commitizen-tools/commitizen)
- [cocoindex-io/cocoindex](https://github.com/cocoindex-io/cocoindex/pull/1564)
- [cachix/devenv](https://github.com/cachix/devenv/pull/2304)
- [copper-project/copper-rs](https://github.com/copper-project/copper-rs/pull/783)
- [bramstroker/homeassistant-powercalc](https://github.com/bramstroker/homeassistant-powercalc/pull/3978)

&lt;!-- --8&lt;-- [end: why] --&gt;

## Acknowledgements

This project is heavily inspired by the original [pre-commit](https://pre-commit.com/) tool, and it wouldn&#039;t be possible without the hard work
of the maintainers and contributors of that project.

And a special thanks to the [Astral](https://github.com/astral-sh) team for their remarkable projects, particularly [uv](https://github.com/astral-sh/uv),
from which I&#039;ve learned a lot on how to write efficient and idiomatic Rust code.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[servo/servo]]></title>
            <link>https://github.com/servo/servo</link>
            <guid>https://github.com/servo/servo</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:54 GMT</pubDate>
            <description><![CDATA[Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/servo/servo">servo/servo</a></h1>
            <p>Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.</p>
            <p>Language: Rust</p>
            <p>Stars: 35,634</p>
            <p>Forks: 3,492</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre># The Servo Parallel Browser Engine Project

Servo is a prototype web browser engine written in the
[Rust](https://github.com/rust-lang/rust) language. It is currently developed on
64-bit macOS, 64-bit Linux, 64-bit Windows, 64-bit OpenHarmony, and Android.

Servo welcomes contribution from everyone. Check out:

- The [Servo Book](https://book.servo.org) for documentation
- [servo.org](https://servo.org/) for news and guides

Coordination of Servo development happens:
- Here in the Github Issues
- On the [Servo Zulip](https://servo.zulipchat.com/)
- In video calls advertised in the [Servo Project](https://github.com/servo/project/issues) repo.

## Getting started

For more detailed build instructions, see the Servo Book under [Getting the Code] and [Building Servo].

[Getting the Code]: https://book.servo.org/building/getting-the-code.html
[Building Servo]: https://book.servo.org/building/building.html

### macOS

- Download and install [Xcode](https://developer.apple.com/xcode/) and [`brew`](https://brew.sh/).
- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` 
- Install `rustup`: `curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh`
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `./mach bootstrap`
- Build servoshell: `./mach build`

### Linux

- Install `curl`:
  - Arch: `sudo pacman -S --needed curl`
  - Debian, Ubuntu: `sudo apt install curl`
  - Fedora: `sudo dnf install curl`
  - Gentoo: `sudo emerge net-misc/curl`
- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` 
- Install `rustup`: `curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh`
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `./mach bootstrap`
- Build servoshell: `./mach build`

### Windows

- Download [`uv`](https://docs.astral.sh/uv/getting-started/installation/#standalone-installer), [`choco`](https://chocolatey.org/install#individual), and [`rustup`](https://win.rustup.rs/)
  - Be sure to select *Quick install via the Visual Studio Community installer*
- In the Visual Studio Installer, ensure the following components are installed:
  - **Windows 10/11 SDK (anything &gt;= 10.0.19041.0)** (`Microsoft.VisualStudio.Component.Windows{10, 11}SDK.{&gt;=19041}`)
  - **MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)** (`Microsoft.VisualStudio.Component.VC.Tools.x86.x64`)
  - **C++ ATL for latest v143 build tools (x86 &amp; x64)** (`Microsoft.VisualStudio.Component.VC.ATL`)
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `.\mach bootstrap`
- Build servoshell: `.\mach build`

### Android

- Ensure that the following environment variables are set:
  - `ANDROID_SDK_ROOT`
  - `ANDROID_NDK_ROOT`: `$ANDROID_SDK_ROOT/ndk/28.2.13676358/`
 `ANDROID_SDK_ROOT` can be any directory (such as `~/android-sdk`).
  All of the Android build dependencies will be installed there.
- Install the latest version of the [Android command-line
  tools](https://developer.android.com/studio#command-tools) to
  `$ANDROID_SDK_ROOT/cmdline-tools/latest`.
- Run the following command to install the necessary components:
  ```shell
  sudo $ANDROID_SDK_ROOT/cmdline-tools/latest/bin/sdkmanager --install \
   &quot;build-tools;34.0.0&quot; \
   &quot;emulator&quot; \
   &quot;ndk;28.2.13676358&quot; \
   &quot;platform-tools&quot; \
   &quot;platforms;android-33&quot; \
   &quot;system-images;android-33;google_apis;x86_64&quot;
  ```
- Follow the instructions above for the platform you are building on

### OpenHarmony

- Follow the instructions above for the platform you are building on to prepare the environment.
- Depending on the target distribution (e.g. `HarmonyOS NEXT` vs pure `OpenHarmony`) the build configuration will differ slightly.
- Ensure that the following environment variables are set
  - `DEVECO_SDK_HOME` (Required when targeting `HarmonyOS NEXT`)
  - `OHOS_BASE_SDK_HOME` (Required when targeting `OpenHarmony`)
  - `OHOS_SDK_NATIVE` (e.g. `${DEVECO_SDK_HOME}/default/openharmony/native` or `${OHOS_BASE_SDK_HOME}/${API_VERSION}/native`)
  - `SERVO_OHOS_SIGNING_CONFIG`: Path to json file containing a valid signing configuration for the demo app.
- Review the detailed instructions at [Building for OpenHarmony].
- The target distribution can be modified by passing `--flavor=&lt;default|harmonyos&gt;` to `mach &lt;build|package|install&gt;`.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[pydantic/monty]]></title>
            <link>https://github.com/pydantic/monty</link>
            <guid>https://github.com/pydantic/monty</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:53 GMT</pubDate>
            <description><![CDATA[A minimal, secure Python interpreter written in Rust for use by AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pydantic/monty">pydantic/monty</a></h1>
            <p>A minimal, secure Python interpreter written in Rust for use by AI</p>
            <p>Language: Rust</p>
            <p>Stars: 5,854</p>
            <p>Forks: 223</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;h1&gt;Monty&lt;/h1&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;A minimal, secure Python interpreter written in Rust for use by AI.&lt;/h3&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/pydantic/monty/actions/workflows/ci.yml?query=branch%3Amain&quot;&gt;&lt;img src=&quot;https://github.com/pydantic/monty/actions/workflows/ci.yml/badge.svg&quot; alt=&quot;CI&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://codspeed.io/pydantic/monty?utm_source=badge&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/CodSpeed-Performance%20Tracked-blue?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj48cGF0aCBkPSJNOCAwTDAgOEw4IDE2TDE2IDhMOCAwWiIgZmlsbD0id2hpdGUiLz48L3N2Zz4=&quot; alt=&quot;Codspeed&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://codecov.io/gh/pydantic/monty&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/pydantic/monty/graph/badge.svg?token=HX4RDQX5OG&quot; alt=&quot;Coverage&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://pypi.python.org/pypi/pydantic-monty&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/pydantic-monty.svg&quot; alt=&quot;PyPI&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/pydantic/monty&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/pydantic-monty.svg&quot; alt=&quot;versions&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/pydantic/monty/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/pydantic/monty.svg?v=2&quot; alt=&quot;license&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://logfire.pydantic.dev/docs/join-slack/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Slack-Join%20Slack-4A154B?logo=slack&quot; alt=&quot;Join Slack&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

---

**Experimental** - This project is still in development, and not ready for the prime time.

A minimal, secure Python interpreter written in Rust for use by AI.

Monty avoids the cost, latency, complexity and general faff of using a full container based sandbox for running LLM generated code.

Instead, it lets you safely run Python code written by an LLM embedded in your agent, with startup times measured in single digit microseconds not hundreds of milliseconds.

What Monty **can** do:
* Run a reasonable subset of Python code - enough for your agent to express what it wants to do
* Completely block access to the host environment: filesystem, env variables and network access are all implemented via external function calls the developer can control
* Call functions on the host - only functions you give it access to
* Run typechecking - monty supports full modern python type hints and comes with [ty](https://docs.astral.sh/ty/) included in a single binary to run typechecking
* Be snapshotted to bytes at external function calls, meaning you can store the interpreter state in a file or database, and resume later
* Startup extremely fast (&lt;1Î¼s to go from code to execution result), and has runtime performance that is similar to CPython (generally between 5x faster and 5x slower)
* Be called from Rust, Python, or Javascript - because Monty has no dependencies on cpython, you can use it anywhere you can run Rust
* Control resource usage - Monty can track memory usage, allocations, stack depth, and execution time and cancel execution if it exceeds preset limits
* Collect stdout and stderr and return it to the caller
* Run async or sync code on the host via async or sync code on the host

What Monty **cannot** do:
* Use the standard library (except a few select modules: `sys`, `typing`, `asyncio`, `dataclasses` (soon), `json` (soon))
* Use third party libraries (like Pydantic), support for external python library is not a goal
* define classes (support should come soon)
* use match statements (again, support should come soon)

---

In short, Monty is extremely limited and designed for **one** use case:

**To run code written by agents.**

For motivation on why you might want to do this, see:
* [Codemode](https://blog.cloudflare.com/code-mode/) from Cloudflare
* [Programmatic Tool Calling](https://platform.claude.com/docs/en/agents-and-tools/tool-use/programmatic-tool-calling) from Anthropic
* [Code Execution with MCP](https://www.anthropic.com/engineering/code-execution-with-mcp) from Anthropic
* [Smol Agents](https://github.com/huggingface/smolagents) from Hugging Face

In very simple terms, the idea of all the above is that LLMs can work faster, cheaper and more reliably if they&#039;re asked to write Python (or Javascript) code, instead of relying on traditional tool calling. Monty makes that possible without the complexity of a sandbox or risk of running code directly on the host.

**Note:** Monty will (soon) be used to implement `codemode` in [Pydantic AI](https://github.com/pydantic/pydantic-ai)

## Usage

Monty can be called from Python, JavaScript/TypeScript or Rust.

### Python

To install:

```bash
uv add pydantic-monty
```

(Or `pip install pydantic-monty` for the boomers)

Usage:

```python
from typing import Any

import pydantic_monty

code = &quot;&quot;&quot;
async def agent(prompt: str, messages: Messages):
    while True:
        print(f&#039;messages so far: {messages}&#039;)
        output = await call_llm(prompt, messages)
        if isinstance(output, str):
            return output
        messages.extend(output)

await agent(prompt, [])
&quot;&quot;&quot;

type_definitions = &quot;&quot;&quot;
from typing import Any

Messages = list[dict[str, Any]]

async def call_llm(prompt: str, messages: Messages) -&gt; str | Messages:
    raise NotImplementedError()

prompt: str = &#039;&#039;
&quot;&quot;&quot;

m = pydantic_monty.Monty(
    code,
    inputs=[&#039;prompt&#039;],
    external_functions=[&#039;call_llm&#039;],
    script_name=&#039;agent.py&#039;,
    type_check=True,
    type_check_stubs=type_definitions,
)


Messages = list[dict[str, Any]]


async def call_llm(prompt: str, messages: Messages) -&gt; str | Messages:
    if len(messages) &lt; 2:
        return [{&#039;role&#039;: &#039;system&#039;, &#039;content&#039;: &#039;example response&#039;}]
    else:
        return f&#039;example output, message count {len(messages)}&#039;


async def main():
    output = await pydantic_monty.run_monty_async(
        m,
        inputs={&#039;prompt&#039;: &#039;testing&#039;},
        external_functions={&#039;call_llm&#039;: call_llm},
    )
    print(output)
    #&gt; example output, message count 2


if __name__ == &#039;__main__&#039;:
    import asyncio

    asyncio.run(main())
```

#### Iterative Execution with External Functions

Use `start()` and `resume()` to handle external function calls iteratively,
giving you control over each call:

```python
import pydantic_monty

code = &quot;&quot;&quot;
data = fetch(url)
len(data)
&quot;&quot;&quot;

m = pydantic_monty.Monty(code, inputs=[&#039;url&#039;], external_functions=[&#039;fetch&#039;])

# Start execution - pauses when fetch() is called
result = m.start(inputs={&#039;url&#039;: &#039;https://example.com&#039;})

print(type(result))
#&gt; &lt;class &#039;pydantic_monty.MontySnapshot&#039;&gt;
print(result.function_name)  # fetch
#&gt; fetch
print(result.args)
#&gt; (&#039;https://example.com&#039;,)

# Perform the actual fetch, then resume with the result
result = result.resume(return_value=&#039;hello world&#039;)

print(type(result))
#&gt; &lt;class &#039;pydantic_monty.MontyComplete&#039;&gt;
print(result.output)
#&gt; 11
```

#### Serialization

Both `Monty` and `MontySnapshot` can be serialized to bytes and restored later.
This allows caching parsed code or suspending execution across process boundaries:

```python
import pydantic_monty

# Serialize parsed code to avoid re-parsing
m = pydantic_monty.Monty(&#039;x + 1&#039;, inputs=[&#039;x&#039;])
data = m.dump()

# Later, restore and run
m2 = pydantic_monty.Monty.load(data)
print(m2.run(inputs={&#039;x&#039;: 41}))
#&gt; 42

# Serialize execution state mid-flight
m = pydantic_monty.Monty(&#039;fetch(url)&#039;, inputs=[&#039;url&#039;], external_functions=[&#039;fetch&#039;])
progress = m.start(inputs={&#039;url&#039;: &#039;https://example.com&#039;})
state = progress.dump()

# Later, restore and resume (e.g., in a different process)
progress2 = pydantic_monty.MontySnapshot.load(state)
result = progress2.resume(return_value=&#039;response data&#039;)
print(result.output)
#&gt; response data
```

### Rust

```rust
use monty::{MontyRun, MontyObject, NoLimitTracker, PrintWriter};

let code = r#&quot;
def fib(n):
    if n &lt;= 1:
        return n
    return fib(n - 1) + fib(n - 2)

fib(x)
&quot;#;

let runner = MontyRun::new(code.to_owned(), &quot;fib.py&quot;, vec![&quot;x&quot;.to_owned()], vec![]).unwrap();
let result = runner.run(vec![MontyObject::Int(10)], NoLimitTracker, &amp;mut PrintWriter::Stdout).unwrap();
assert_eq!(result, MontyObject::Int(55));
```

#### Serialization

`MontyRun` and `RunProgress` can be serialized using the `dump()` and `load()` methods:

```rust
use monty::{MontyRun, MontyObject, NoLimitTracker, PrintWriter};

// Serialize parsed code
let runner = MontyRun::new(&quot;x + 1&quot;.to_owned(), &quot;main.py&quot;, vec![&quot;x&quot;.to_owned()], vec![]).unwrap();
let bytes = runner.dump().unwrap();

// Later, restore and run
let runner2 = MontyRun::load(&amp;bytes).unwrap();
let result = runner2.run(vec![MontyObject::Int(41)], NoLimitTracker, &amp;mut PrintWriter::Stdout).unwrap();
assert_eq!(result, MontyObject::Int(42));
```

## PydanticAI Integration

Monty will power code-mode in
[Pydantic AI](https://github.com/pydantic/pydantic-ai). Instead of making
sequential tool calls, the LLM writes Python code that calls your tools
as functions and Monty executes it safely.

```python test=&quot;skip&quot;
import asyncio
import json

import logfire
from httpx import AsyncClient
from pydantic_ai import Agent, RunContext
from pydantic_ai.toolsets.code_mode import CodeModeToolset
from pydantic_ai.toolsets.function import FunctionToolset
from typing_extensions import TypedDict

logfire.configure()
logfire.instrument_pydantic_ai()


class LatLng(TypedDict):
    lat: float
    lng: float


weather_toolset: FunctionToolset[AsyncClient] = FunctionToolset()


@weather_toolset.tool
async def get_lat_lng(
    ctx: RunContext[AsyncClient], location_description: str
) -&gt; LatLng:
    &quot;&quot;&quot;Get the latitude and longitude of a location.&quot;&quot;&quot;
    # NOTE: the response here will be random, and is not related to the location description.
    r = await ctx.deps.get(
        &#039;https://demo-endpoints.pydantic.workers.dev/latlng&#039;,
        params={&#039;location&#039;: location_description},
    )
    r.raise_for_status()
    return json.loads(r.content)


@weather_toolset.tool
async def get_temp(ctx: RunContext[AsyncClient], lat: float, lng: float) -&gt; float:
    &quot;&quot;&quot;Get the temp at a location.&quot;&quot;&quot;
    # NOTE: the responses here will be random, and are not related to the lat and lng.
    r = await ctx.deps.get(
        &#039;https://demo-endpoints.pydantic.workers.dev/number&#039;,
        params={&#039;min&#039;: 10, &#039;max&#039;: 30},
    )
    r.raise_for_status()
    return float(r.text)


@weather_toolset.tool
async def get_weather_description(
    ctx: RunContext[AsyncClient], lat: float, lng: float
) -&gt; str:
    &quot;&quot;&quot;Get the weather description at a location.&quot;&quot;&quot;
    # NOTE: the responses here will be random, and are not related to the lat and lng.
    r = await ctx.deps.get(
        &#039;https://demo-endpoints.pydantic.workers.dev/weather&#039;,
        params={&#039;lat&#039;: lat, &#039;lng&#039;: lng},
    )
    r.raise_for_status()
    return r.text


agent = Agent(
    &#039;gateway/anthropic:claude-sonnet-4-5&#039;,
    # toolsets=[weather_toolset],
    toolsets=[CodeModeToolset(weather_toolset)],
    deps_type=AsyncClient,
)


async def main():
    async with AsyncClient() as client:
        await agent.run(&#039;Compare the weather of London, Paris, and Tokyo.&#039;, deps=client)


if __name__ == &#039;__main__&#039;:
    asyncio.run(main())
```

# Alternatives

There are generally two responses when you show people Monty:

1. Oh my god, this solves so many problems, I want it.
2. Why not X?

Where X is some alternative technology. Oddly often these responses are combined, suggesting people have not yet found an alternative that works for them, but are incredulous that there&#039;s really no good alternative to creating an entire Python implementation from scratch.

I&#039;ll try to run through the most obvious alternatives, and why there aren&#039;t right for what we wanted.

NOTE: all these technologies are impressive and have widespread uses, this commentary on their limitations for our use case should not be seen as a criticism. Most of these solutions were not conceived with the goal of providing an LLM sandbox, which is why they&#039;re not necessary great at it.

| Tech               | Language completeness | Security     | Start latency  | FOSS       | Setup complexity | File mounting  | Snapshotting |
|--------------------|-----------------------|--------------|----------------|------------|------------------|----------------|--------------|
| Monty              | partial               | strict       | 0.06ms         | free / OSS | easy             | easy           | easy         |
| Docker             | full                  | good         | 195ms          | free / OSS | intermediate     | easy           | intermediate |
| Pyodide            | full                  | poor         | 2800ms         | free / OSS | intermediate     | easy           | hard         |
| starlark-rust      | very limited          | good         | 1.7ms          | free / OSS | easy             | not available? | impossible?  |
| WASI / Wasmer      | partial, almost full  | strict       | 66ms           | free *     | intermediate     | easy           | intermediate |
| sandboxing service | full                  | strict       | 1033ms         | not free   | intermediate     | hard           | intermediate |
| YOLO Python        | full                  | non-existent | 0.1ms / 30ms   | free / OSS | easy             | easy / scary   | hard         |

See [./scripts/startup_performance.py](scripts/startup_performance.py) for the script used to calculate the startup performance numbers.

Details on each row below:

### Monty

- **Language completeness**: No classes (yet), limited stdlib, no third-party libraries
- **Security**: Explicitly controlled filesystem, network, and env access, strict limits on execution time and memory usage
- **Start latency**: Starts in microseconds
- **Setup complexity**: just `pip install pydantic-monty` or `npm install @pydantic/monty`, ~4.5MB download
- **File mounting**: Strictly controlled, see [#85](https://github.com/pydantic/monty/pull/85)
- **Snapshotting**: Monty&#039;s pause and resume functionality with `dump()` and `load()` makes it trivial to pause, resume and fork execution

### Docker

- **Language completeness**: Full CPython with any library
- **Security**: Process and filesystem isolation, network policies, but container escapes exist, memory limitation is possible
- **Start latency**: Container startup overhead (~195ms measured)
- **Setup complexity**: Requires Docker daemon, container images, orchestration, `python:3.14-alpine` is 50MB - docker can&#039;t be installed from PyPI
- **File mounting**: Volume mounts work well
- **Snapshotting**: Possible with durable execution solutions like Temporal, or snapshotting an image and saving it as a Docker image.

### Pyodide

- **Language completeness**: Full CPython compiled to WASM, almost all libraries available
- **Security**: Relies on browser/WASM sandbox - not designed for server-side isolation, python code can run arbitrary code in the JS runtime, only deno allows isolation, memory limits are hard/impossible to enforce with deno
- **Start latency**: WASM runtime loading is slow (~2800ms cold start)
- **Setup complexity**: Need to load WASM runtime, handle async initialization, pyodide NPM package is ~12MB, deno is ~50MB - Pyodide can&#039;t be called with just PyPI packages
- **File mounting**: Virtual filesystem via browser APIs
- **Snapshotting**: Possible with durable execution solutions like Temporal presumably, but hard

### starlark-rust

See [starlark-rust](https://github.com/facebook/starlark-rust).

- **Language completeness**: Configuration language, not Python - no classes, exceptions, async
- **Security**: Deterministic and hermetic by design
- **Start latency**: runs embedded in the process like Monty, hence impressive startup time
- **Setup complexity**: Usable in python via [starlark-pyo3](https://github.com/inducer/starlark-pyo3)
- **File mounting**: No file handling by design AFAIK?
- **Snapshotting**: Impossible AFAIK?

### WASI / Wasmer

Running Python in WebAssembly via [Wasmer](https://wasmer.io/).

- **Language completeness**: Full CPython, pure Python external packages work via mounting, external packages with C bindings don&#039;t work
- **Security**: In principle WebAssembly should provide strong sandboxing guarantees.
- **Start latency**: The [wasmer](https://pypi.org/project/wasmer/) python package hasn&#039;t been updated for 3 years and I couldn&#039;t find docs on calling Python in wasmer from Python, so I called it via subprocess. Start latency was 66ms.
- **Setup complexity**: wasmer download is 100mb, the &quot;python/python&quot; package is 50mb.
- **FOSS**: I marked this as &quot;free *&quot; since the cost is zero but not everything seems to be open source. As of 2026-02-10 the [`python/python` wasmer package](https://wasmer.io/python/python) package has no readme, no license, no source link and no indication of how it&#039;s built, the recently uploaded versions show size as &quot;0B&quot; although the download is ~50MB - the build process for the Python binary is not clear and transparent. _(If I&#039;m wrong here, please create an issue to correct correct me)_
- **File mounting**: Supported
- **Snapshotting**: Supported via journaling

### sandboxing service

Services like [Daytona](https://daytona.io), [E2B](https://e2b.dev), [Modal](https://modal.com).

There are similar challenges, more setup complexity but lower network latency for setting up your own sandbox setup with k8s.

- **Language completeness**: Full CPython with any library
- **Security**: Professionally managed container isolation
- **Start latency**: Network round-trip and container startup time. I got ~1s cold start time with Daytona EU from London, Daytona advertise sub 90ms latency, presumably that&#039;s for an existing container, not clear if it includes network latency
- **FOSS**: Pay per execution or compute time, some implementations are open source
- **Setup complexity**: API integration, auth tokens - fine for startups but generally a non-start for enterprises
- **File mounting**: Upload/download via API calls
- **Snapshotting**: Possible with durable execution solutions like Temporal, also the services offer some solutions for this, I think based con docker containers

### YOLO Python

Running Python directly via `exec()` (~0.1ms) or subprocess (~30ms).

- **Language completeness**: Full CPython with any library
- **Security**: None - full filesystem, network, env vars, system commands
- **Start latency**: Near-zero for `exec()`, ~30ms for subprocess
- **Setup complexity**: None
- **File mounting**: Direct filesystem access (that&#039;s the problem)
- **Snapshotting**: Possible with durable execution solutions like Temporal
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tree-sitter/tree-sitter]]></title>
            <link>https://github.com/tree-sitter/tree-sitter</link>
            <guid>https://github.com/tree-sitter/tree-sitter</guid>
            <pubDate>Mon, 02 Mar 2026 00:06:52 GMT</pubDate>
            <description><![CDATA[An incremental parsing system for programming tools]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tree-sitter/tree-sitter">tree-sitter/tree-sitter</a></h1>
            <p>An incremental parsing system for programming tools</p>
            <p>Language: Rust</p>
            <p>Stars: 23,998</p>
            <p>Forks: 2,441</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># tree-sitter

[![DOI](https://zenodo.org/badge/14164618.svg)](https://zenodo.org/badge/latestdoi/14164618)
[![discord][discord]](https://discord.gg/w7nTvsVJhm)
[![matrix][matrix]](https://matrix.to/#/#tree-sitter-chat:matrix.org)

Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source file and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:

- **General** enough to parse any programming language
- **Fast** enough to parse on every keystroke in a text editor
- **Robust** enough to provide useful results even in the presence of syntax errors
- **Dependency-free** so that the runtime library (which is written in pure C) can be embedded in any application

## Links
- [Documentation](https://tree-sitter.github.io)
- [Rust binding](lib/binding_rust/README.md)
- [Wasm binding](lib/binding_web/README.md)
- [Command-line interface](crates/cli/README.md)

[discord]: https://img.shields.io/discord/1063097320771698699?logo=discord&amp;label=discord
[matrix]: https://img.shields.io/matrix/tree-sitter-chat%3Amatrix.org?logo=matrix&amp;label=matrix
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>