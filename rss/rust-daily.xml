<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Wed, 09 Jul 2025 00:05:34 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[rustfs/rustfs]]></title>
            <link>https://github.com/rustfs/rustfs</link>
            <guid>https://github.com/rustfs/rustfs</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[üöÄ High-performance distributed object storage for MinIO alternative.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustfs/rustfs">rustfs/rustfs</a></h1>
            <p>üöÄ High-performance distributed object storage for MinIO alternative.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,131</p>
            <p>Forks: 155</p>
            <p>Stars today: 1,369 stars today</p>
            <h2>README</h2><pre>[![RustFS](https://rustfs.com/images/rustfs-github.png)](https://rustfs.com)

&lt;p align=&quot;center&quot;&gt;RustFS is a high-performance distributed object storage software built using Rust&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/rustfs/rustfs/actions/workflows/ci.yml&quot;&gt;&lt;img alt=&quot;CI&quot; src=&quot;https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/rustfs/rustfs/actions/workflows/docker.yml&quot;&gt;&lt;img alt=&quot;Build and Push Docker Images&quot; src=&quot;https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/m/rustfs/rustfs&quot;/&gt;
  &lt;img alt=&quot;Github Last Commit&quot; src=&quot;https://img.shields.io/github/last-commit/rustfs/rustfs&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.rustfs.com/en/introduction.html&quot;&gt;Getting Started&lt;/a&gt;
  ¬∑ &lt;a href=&quot;https://docs.rustfs.com/en/&quot;&gt;Docs&lt;/a&gt;
  ¬∑ &lt;a href=&quot;https://github.com/rustfs/rustfs/issues&quot;&gt;Bug reports&lt;/a&gt;
  ¬∑ &lt;a href=&quot;https://github.com/rustfs/rustfs/discussions&quot;&gt;Discussions&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
English | &lt;a href=&quot;https://github.com/rustfs/rustfs/blob/main/README_ZH.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;
&lt;/p&gt;

RustFS is a high-performance distributed object storage software built using Rust, one of the most popular languages worldwide. Along with MinIO, it shares a range of advantages such as simplicity, S3 compatibility, open-source nature, support for data lakes, AI, and big data. Furthermore, it has a better and more user-friendly open-source license in comparison to other storage systems, being constructed under the Apache license. As Rust serves as its foundation, RustFS provides faster speed and safer distributed features for high-performance object storage.

## Features

- **High Performance**: Built with Rust, ensuring speed and efficiency.
- **Distributed Architecture**: Scalable and fault-tolerant design for large-scale deployments.
- **S3 Compatibility**: Seamless integration with existing S3-compatible applications.
- **Data Lake Support**: Optimized for big data and AI workloads.
- **Open Source**: Licensed under Apache 2.0, encouraging community contributions and transparency.
- **User-Friendly**: Designed with simplicity in mind, making it easy to deploy and manage.

## RustFS vs MinIO

Stress test server parameters

|  Type  |  parameter   | Remark |
| - | - | - |
|CPU | 2 Core | Intel Xeon(Sapphire Rapids) Platinum 8475B , 2.7/3.2 GHz|   |
|Memory| 4GB | ¬†   |
|Network | 15Gbp | ¬†    |
|Driver  | 40GB x 4 |   IOPS 3800 / Driver |

&lt;https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a&gt;

### RustFS vs Other object storage

| RustFS | Other object storage|
| - | - |
| Powerful Console | Simple and useless Console |
| Developed based on Rust language, memory is safer | Developed in Go or C, with potential issues like memory GC/leaks |
| Does not report logs to third-party countries  | Reporting logs to other third countries may violate national security laws |
| Licensed under Apache, more business-friendly  | AGPL V3 License and other License, polluted open source and License traps, infringement of intellectual property rights |
| Comprehensive S3 support, works with domestic and international cloud providers  | Full support for S3, but no local cloud vendor support |
| Rust-based development, strong support for secure and innovative devices  | Poor support for edge gateways and secure innovative devices|
| Stable commercial prices, free community support | High pricing, with costs up to $250,000 for 1PiB |
| No risk | Intellectual property risks and risks of prohibited uses |

## Quickstart

To get started with RustFS, follow these steps:

1.  **One-click installation script (Option 1)‚Äã‚Äã**

   ```bash
   curl -O  https://rustfs.com/install_rustfs.sh &amp;&amp; bash install_rustfs.sh
   ```

2. **Docker Quick Start (Option 2)‚Äã‚Äã**

  ```bash
   podman run -d -p 9000:9000 -p 9001:9001 -v /data:/data quay.io/rustfs/rustfs
   ```


3. **Access the Console**: Open your web browser and navigate to `http://localhost:9001` to access the RustFS console, default username and password is `rustfsadmin` .
4. **Create a Bucket**: Use the console to create a new bucket for your objects.
5. **Upload Objects**: You can upload files directly through the console or use S3-compatible APIs to interact with your RustFS instance.

## Documentation

For detailed documentation, including configuration options, API references, and advanced usage, please visit our [Documentation](https://docs.rustfs.com).

## Getting Help

If you have any questions or need assistance, you can:

- Check the [FAQ](https://github.com/rustfs/rustfs/discussions/categories/q-a) for common issues and solutions.
- Join our [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) to ask questions and share your experiences.
- Open an issue on our [GitHub Issues](https://github.com/rustfs/rustfs/issues) page for bug reports or feature requests.

## Links

- [Documentation](https://docs.rustfs.com) - The manual you should read
- [Changelog](https://github.com/rustfs/rustfs/releases) - What we broke and fixed
- [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) - Where the community lives

## Contact

- **Bugs**: [GitHub Issues](https://github.com/rustfs/rustfs/issues)
- **Business**: &lt;hello@rustfs.com&gt;
- **Jobs**: &lt;jobs@rustfs.com&gt;
- **General Discussion**: [GitHub Discussions](https://github.com/rustfs/rustfs/discussions)
- **Contributing**: [CONTRIBUTING.md](CONTRIBUTING.md)

## Contributors

RustFS is a community-driven project, and we appreciate all contributions. Check out the [Contributors](https://github.com/rustfs/rustfs/graphs/contributors) page to see the amazing people who have helped make RustFS better.

&lt;a href=&quot;https://github.com/rustfs/rustfs/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=rustfs/rustfs&quot; /&gt;
&lt;/a&gt;

## License

[Apache 2.0](https://opensource.org/licenses/Apache-2.0)

**RustFS** is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[smallcloudai/refact]]></title>
            <link>https://github.com/smallcloudai/refact</link>
            <guid>https://github.com/smallcloudai/refact</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[AI Agent that handles engineering tasks end-to-end: integrates with developers‚Äô tools, plans, executes, and iterates until it achieves a successful result.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/smallcloudai/refact">smallcloudai/refact</a></h1>
            <p>AI Agent that handles engineering tasks end-to-end: integrates with developers‚Äô tools, plans, executes, and iterates until it achieves a successful result.</p>
            <p>Language: Rust</p>
            <p>Stars: 2,811</p>
            <p>Forks: 233</p>
            <p>Stars today: 311 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://docs.refact.ai/_astro/logo-dark.CCzD55EA.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://docs.refact.ai/_astro/logo-light.CblxRz3x.svg&quot;&gt;
    &lt;!-- Fallback if neither preference is set --&gt;
    &lt;img alt=&quot;Refact.ai logo&quot; src=&quot;https://docs.refact.ai/_astro/logo-dark.CCzD55EA.svg&quot; width=&quot;200&quot;&gt;
  &lt;/picture&gt;
  &lt;h1 align=&quot;center&quot;&gt;Refact - Open Sourced AI Software Development Agent&lt;/h1&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/smallcloudai/refact/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/smallcloudai/refact?style=for-the-badge&amp;color=blue&quot; alt=&quot;Stargazers&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/Kts7CYg99R&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20Us-purple?logo=discord&amp;logoColor=white&amp;style=for-the-badge&quot; alt=&quot;Join our Discord community&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://docs.refact.ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/documentation-blue?logo=googledocs&amp;logoColor=FFE165&amp;style=for-the-badge&quot; alt=&quot;Check out the documentation&quot;&gt;&lt;/a&gt;
  
&lt;/div&gt;



Refact.ai is the #1 open-source AI Agent in SWE-bench verified that handles engineering tasks end-to-end. It deeply understands your codebases and integrates with your tools, databases, and browsers to automate complex, multi-step tasks.


## üöÄ Seamless Integration with Your Workflow  

Refact Agent works effortlessly with the tools and databases you already use:  


- **üìÅ Version Control:** GitHub, GitLab  
- **üóÑÔ∏è Databases:** PostgreSQL, MySQL  
- **üõ†Ô∏è Debugging:** Pdb  
- **üê≥ Containerization:** Docker  

### ‚ö° Why Choose Refact Agent?  

- ‚úÖ **Deploy On-Premise:** For maximum security, choose our self-hosted AI Agent version and run it on your own infrastructure.
- üß† **Access State-of-the-Art Models:** Use Claude 4, GPT-4o, or GPT-4o mini with AI Agent or for chat queries.
- üîë **Bring Your Own Key (BYOK):** Connect your API key and use any LLM: Gemini, Grok, OpenAI, Deepseek, and others.
- üí¨ **Integrated IDE Chat:** Integrate with GitHub, PostgreSQL, Docker, and more. Refact.ai Agent accesses your resources and handles related operations autonomously, mimicking your workflow.
- ‚ö° **Free, Unlimited, Context-Aware Auto-Completion:** Code faster with smart AI suggestions.  
- üõ†Ô∏è **Supports 25+ Programming Languages:** Python, JavaScript, Java, Rust, TypeScript, PHP, C++, C#, Go, and many more!  

### üéâ  Hear from our Community

Our Ambassadors shared remarkable stories of how they transform weeks of coding into minutes with Refact.ai Agent!

1Ô∏è. How Refact.ai built 99.9% of an IoT cloud app [Read](https://www.linkedin.com/posts/refactai_refactai-agent-activity-7308103386451578881-FO23/)

2Ô∏è. How AI-coded prototypes help UX teams deliver real value [Read](https://medium.com/@siarheimardovich/how-ai-coded-prototypes-help-ux-teams-deliver-real-value-b51eb2ea5167)

3Ô∏è. 80 hours of building from scratch ‚Äî instead done in 30 minutes [Read more](https://www.linkedin.com/posts/refactai_refactai-users-stories-activity-7310996174864289793-692-/)

4Ô∏è. 3 weeks of waiting for a functional GUI? Built in just 14 minutes [Read more](https://www.linkedin.com/posts/refactai_refactai-users-stories-activity-7310996174864289793-692-/)

5. Built an automated SEO Content Generator in 60 minutes with Refact.ai [Read more](https://refact.ai/blog/2025/automated-seo-content-generator-in-60-minutes/)



üìú [View Full List of Supported Models](https://docs.refact.ai/supported-models/) 

&gt; üì¢  **Using AI for work? Let‚Äôs bring it to your company!** 
&gt; 
&gt; [Fill out this form](https://refact.ai/contact/?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=enterprise) ‚Äî Our AI Agent will be tailored to your company‚Äôs data, learning from feedback, and helping organize knowledge for **better collaboration** with your team.


## üìö Table of Contents

- üöÄ [Core Features and Functionality](#-core-features-and-functionality)
- ü§ñ [Which Tasks Can Refact Help You With?](#-which-tasks-can-refact-help-you-with)
- ‚öôÔ∏è [QuickStart](#%EF%B8%8F-quickstart)
- üê≥ [Running Refact Self-Hosted in a Docker Container](#-running-refact-self-hosted-in-a-docker-container)
- üîå [Getting Started with Plugins](#-getting-started-with-plugins)
- üìñ [Documentation](#-documentation)
- ü•á [Contribution](#-contribution)
- üéâ [Join the Community](#-join-the-community)

## üöÄ Core Features and Functionality

 ‚úÖ **Unlimited accurate auto-completion** with context awareness ‚Äì Powered by Qwen2.5-Coder-1.5B, utilizing Retrieval-Augmented Generation (RAG).  

![auto-completion](https://lh7-rt.googleusercontent.com/docsz/AD_4nXfClhl11Ul0YQjDTZJvrfhsj3bqK_VIz6bFfbTRc62dsMOz4LK4u72i9-gLTQDIgm0yChmFe57hvUxSoI2fQ5DSntna7_Ch0qbGx5zcB-othfwKnoYkbt3M3YgGFlrqFszuDEBhUw?key=zllGjEBckkx13bRZ6JIqX6qr)

 ‚úÖ **Integrated in-IDE Chat** ‚Äì AI deeply understands your code and provides relevant, intelligent answers.  

 ‚úÖ **Integrated with Tools** ‚Äì Works with GitHub, GitLab, PostgreSQL, MySQL, Pdb, Docker, and shell commands.  

![integrations](https://lh7-rt.googleusercontent.com/docsz/AD_4nXc4DWYXF73AgPWAaFFGLTqEprWwA0im8R_A1QMo4QW4pTnSi1MCoP9L8udMZb5FPyN-CdgefaxJFGpX2ndn5nkjGBF2b_hZBNHogM7IM6SPvUIvUd9iE1lYIq7q-TB2qKzSGLk00A?key=zllGjEBckkx13bRZ6JIqX6qr)

 ‚úÖ **State-of-the-Art Models** ‚Äì Use Claude 4, GPT-4o, or GPT-4o mini with AI Agent or for chat queries.

 ‚úÖ **Bring Your Own Key (BYOK)** ‚Äì Use your own API keys for external LLMs.  

![BYOK](https://lh7-rt.googleusercontent.com/docsz/AD_4nXe1UDsuaER6WMxAnKEwz15T3OPslkpSo2vNGMGaNoEiZOJvAptY8yEvND_rI23q_5Sof1DceexyrW5x6oUwcpVr5KQvWUByrN_TnLGVY2HG_0sg8uWnRb14jKAes2MBDPM37EQO?key=zllGjEBckkx13bRZ6JIqX6qr)


## ü§ñ Which Tasks Can Refact Help You With?

- üèó **Generate code** from natural language prompts (even with typos).  

- üîÑ **Refactor code** for better quality and readability.  

- üìñ **Explain code** to quickly understand unfamiliar code.  

- üêû **Debug code** to detect and fix errors faster.  

- üß™ **Generate unit tests** for reliable code.  

- üìå **Code Review** with AI-assisted suggestions.  

- üìú **Create Documentation** to keep knowledge up to date. 
 
- üè∑ **Generate Docstrings** for structured documentation.  



## ‚öôÔ∏è QuickStart

You can install the Refact repository without Docker:
```bash
pip install .
```

For GPU with CUDA capability &gt;= 8.0 and flash-attention v2 support:
```bash
FLASH_ATTENTION_FORCE_BUILD=TRUE MAX_JOBS=4 INSTALL_OPTIONAL=TRUE pip install .
```



## üê≥ Running Refact Self-Hosted in a Docker Container

The easiest way to run the self-hosted server is using a pre-built Docker image.  
See `CONTRIBUTING.md` for installation without a Docker container.


### üîå Getting Started with Plugins

1. **Download Refact** for VS Code or JetBrains.  
2. **Set up a custom inference URL:**  
   ```
   http://127.0.0.1:8008
   ```
3. **Configure the plugin settings:**  
   - **JetBrains:** Settings &gt; Tools &gt; Refact.ai &gt; Advanced &gt; Inference URL  
   - **VSCode:** Extensions &gt; Refact.ai Assistant &gt; Settings &gt; Address URL  



## üìñ Documentation

For detailed guidance and best practices, check out our [documentation.](https://docs.refact.ai/)


## ü•á Contribution

Want to contribute to our project? We&#039;re always open to new ideas and features!  
- **Check out GitHub Issues** ‚Äì See what we&#039;re working on or suggest your own ideas.  
- **Read our Contributing Guide** ‚Äì Check out `Contributing.md` to get started.  

Your contributions help shape the future of Refact Agent! üöÄ


### ‚≠ê Star History
![image (4)](https://github.com/user-attachments/assets/48440c6e-b0cd-4421-880e-44924bd21693)

### üéâ Join the Community

We&#039;re all about open-source and empowering developers with AI tools. Our vision is to build the future of programming. Join us and be part of the journey!

üì¢ **[Join our Discord server](https://refact.ai/community/)** ‚Äì A community-run space for discussion, questions, and feedback.



**Made with ‚ù§Ô∏è by developers who automate the boring, so you can focus on building the future.**
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[GyulyVGC/sniffnet]]></title>
            <link>https://github.com/GyulyVGC/sniffnet</link>
            <guid>https://github.com/GyulyVGC/sniffnet</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[Comfortably monitor your Internet traffic üïµÔ∏è‚Äç‚ôÇÔ∏è]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GyulyVGC/sniffnet">GyulyVGC/sniffnet</a></h1>
            <p>Comfortably monitor your Internet traffic üïµÔ∏è‚Äç‚ôÇÔ∏è</p>
            <p>Language: Rust</p>
            <p>Stars: 27,252</p>
            <p>Forks: 879</p>
            <p>Stars today: 345 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;picture&gt;
&lt;img alt=&quot;&quot; title=&quot;Sniffnet&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/header_repository.png&quot; width=&quot;95%&quot;/&gt;
&lt;/picture&gt;

&lt;a href=&quot;#download&quot;&gt;&lt;img alt=&quot;&quot; title=&quot;Download&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/download.svg&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/GyulyVGC/sniffnet/blob/main/ROADMAP.md&quot;&gt;&lt;img alt=&quot;&quot; title=&quot;Roadmap&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/roadmap.svg&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://sniffnet.net&quot;&gt;&lt;img alt=&quot;&quot; title=&quot;Website&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/website.svg&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/GyulyVGC/sniffnet/wiki&quot;&gt;&lt;img alt=&quot;&quot; title=&quot;Wiki&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/wiki.svg&quot;/&gt;&lt;/a&gt;

Application to comfortably monitor your Internet traffic.&lt;br&gt;
Cross-platform. Intuitive. Reliable.

Translated in:&lt;br&gt;
üá®üá≥ üá©üá™ üá´üá∑ üá∑üá∫ üáµüáπ üá™üá¶ üáÆüáπ üáµüá± [+&amp;nbsp;14&amp;nbsp;more&amp;nbsp;languages](https://github.com/GyulyVGC/sniffnet/issues/60)
&lt;/div&gt;

&lt;p&gt;
&lt;picture&gt;
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/hr.png&quot; width=&quot;100%&quot;/&gt;
&lt;/picture&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img alt=&quot;&quot; title=&quot;Overview page&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/overview.png&quot; width=&quot;95%&quot;/&gt;
&lt;img alt=&quot;&quot; title=&quot;Inspect page&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/inspect.png&quot; width=&quot;47%&quot;/&gt;
&lt;img alt=&quot;&quot; title=&quot;Notifications page&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/notifications.png&quot; width=&quot;47%&quot;/&gt;
&lt;img alt=&quot;&quot; title=&quot;Custom theme&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/deep_cosmos.png&quot; width=&quot;47%&quot;/&gt;
&lt;img alt=&quot;&quot; title=&quot;Thumbnail mode&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/thumbnail.png&quot; width=&quot;47%&quot;/&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;picture&gt;
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/hr.png&quot; width=&quot;100%&quot;/&gt;
&lt;/picture&gt;
&lt;/p&gt;


## _Support Sniffnet&#039;s development_ üíñ

&lt;i&gt;Sniffnet is completely free, open-source software which needs lots of effort and time to develop and maintain.&lt;/i&gt;

&lt;i&gt;If you appreciate Sniffnet, [consider sponsoring](https://github.com/sponsors/GyulyVGC):
your support will enable a constant growth with [new features and functionalities](https://github.com/GyulyVGC/sniffnet/blob/main/ROADMAP.md).&lt;br&gt;
Do you want to help the project in an alternative way? You can also head to the [official store](https://grindhouse.dev/collections/sniffnet) and put your hands on some cool merchandise!&lt;/i&gt;

&lt;i&gt;A special mention goes to these awesome organizations and folks who are sponsoring Sniffnet:&lt;/i&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/github&quot; title=&quot;GitHub&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/github?v=4&quot; width=&quot;60px&quot; alt=&quot;GitHub&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://nlnet.nl&quot; title=&quot;NLnet&quot;&gt;&lt;img src=&quot;https://nlnet.nl/logo/logo.svg&quot; width=&quot;60px&quot; alt=&quot;NLnet&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://ipinfo.io&quot; title=&quot;IPinfo&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/ipinfo?v=4&quot; width=&quot;60px&quot; alt=&quot;IPinfo&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/Cthulu201&quot; title=&quot;Cthulu201&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Cthulu201?v=4&quot; width=&quot;60px&quot; alt=&quot;Cthulu201&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/0x0177b11f&quot; title=&quot;Tiansheng Li&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/0x0177b11f?v=4&quot; width=&quot;60px&quot; alt=&quot;Tiansheng Li&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/ZEROF&quot; title=&quot;ZEROF&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/ZEROF?v=4&quot; width=&quot;60px&quot; alt=&quot;ZEROF&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://www.janwalter.org/&quot; title=&quot;Jan Walter&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/wahn?v=4&quot; width=&quot;60px&quot; alt=&quot;Jan Walter&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;


## Download

|                                                                        &lt;a href=&quot;#download&quot;&gt;&lt;img alt=&quot;Windows&quot; title=&quot;Windows&quot; height=&quot;35px&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/windows.svg&quot;/&gt;&lt;/a&gt;                                                                         |                           &lt;a href=&quot;#download&quot;&gt;&lt;img alt=&quot;macOS&quot; title=&quot;macOS&quot; height=&quot;35px&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/macos.svg&quot;/&gt;&lt;/a&gt;                            |                                                                                                                          &lt;a href=&quot;#download&quot;&gt;&lt;img alt=&quot;Linux (.deb)&quot; title=&quot;Linux (.deb)&quot; height=&quot;35px&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/linux_deb.svg&quot;/&gt;&lt;/a&gt;                                                                                                                           |                                                              &lt;a href=&quot;#download&quot;&gt;&lt;img alt=&quot;Linux (.rpm)&quot; title=&quot;Linux (.rpm)&quot; height=&quot;35px&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/linux_rpm.svg&quot;/&gt;&lt;/a&gt;                                                               |
|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[64&amp;#8209;bit](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_Windows_64-bit.msi)&amp;nbsp;\|&amp;nbsp;[32&amp;#8209;bit](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_Windows_32-bit.msi)&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; | [Intel](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_macOS_Intel.dmg)&amp;nbsp;\|&amp;nbsp;[Apple&amp;nbsp;silicon](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_macOS_AppleSilicon.dmg) | [amd64](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_amd64.deb)&amp;nbsp;\|&amp;nbsp;[arm64](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_arm64.deb)&amp;nbsp;\|&amp;nbsp;[i386](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_i386.deb)&amp;nbsp;\|&amp;nbsp;[armhf](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_armhf.deb) | &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[x86_64](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxRPM_x86_64.rpm)&amp;nbsp;\|&amp;nbsp;[aarch64](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxRPM_aarch64.rpm)&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; |

Links in the table above will download the latest version of Sniffnet directly from [GitHub releases](https://github.com/GyulyVGC/sniffnet/releases). &lt;br&gt;
Not what you&#039;re looking for? Check out [alternative installation methods](https://github.com/GyulyVGC/sniffnet/wiki/Alternative-installation-methods).

&gt; [!NOTE]
&gt;
&gt; Remember to also install the [required dependencies](https://github.com/GyulyVGC/sniffnet/wiki/Required-dependencies) for your operating system.

## Features

- üíª choose a **network adapter** of your PC to inspect
- üè∑Ô∏è select a set of **filters** to apply to the observed traffic
- üìñ view overall **statistics** about your Internet traffic
- üìà view **real-time charts** about traffic intensity
- üìå keep an eye on your network even when the application is **minimized**
- üìÅ **import** and **export** comprehensive capture reports as **PCAP files**
- üîé identify **6000+ upper layer services**, protocols, trojans, and worms
- üåê find out **domain name** and **ASN** of the hosts you are exchanging traffic with
- üè† identify connections in your **local network**
- üåç discover the **geographical location** of remote hosts
- ‚≠ê save your **favorite** network hosts
- üïµÔ∏è‚Äç‚ôÇÔ∏è search and **inspect** each of your network connections in real time
- üîâ set custom **notifications** to inform you when defined network events occur
- üé® choose the **style** that fits you the most, including custom themes support
- ...and more!

## User manual

Do you want to **learn more**? &lt;br&gt;
Check out the [**Sniffnet Wiki**](https://github.com/GyulyVGC/sniffnet/wiki), a comprehensive manual to help you
thoroughly master the application from a basic setup to the most advanced functionalities. &lt;br&gt;
The Wiki includes step-by-step guides, tips, examples of usage, and answers to frequent questions.

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/GyulyVGC/sniffnet/wiki&quot;&gt;
&lt;img alt=&quot;&quot; title=&quot;Sniffnet Wiki&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/logos/wiki/wikilogo.svg&quot; width=&quot;300px&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

## Troubleshooting

&lt;details&gt;

  &lt;summary&gt;See details&lt;/summary&gt;

### Missing dependencies

Most of the errors that may arise are likely due to your system missing dependencies
required to correctly analyze a network adapter. &lt;br&gt;
Check the [required dependencies page](https://github.com/GyulyVGC/sniffnet/wiki/Required-dependencies) 
for instructions on how to proceed depending on your operating system.

### Rendering problems

In some circumstances, especially if you are running on an old architecture or your graphical drivers are not updated,
the `wgpu` default renderer used by [iced](https://github.com/iced-rs/iced)
may manifest bugs (the interface glitches, color gradients are unsupported, or some icons are completely black). &lt;br&gt;
In these cases you can set an environment variable to switch to the `tiny-skia` renderer,
a CPU-only software renderer that should work properly on every environment:

```sh
ICED_BACKEND=tiny-skia
```

### ***In any case, don&#039;t hesitate to [open an issue](https://github.com/GyulyVGC/sniffnet/issues/new/choose), and I will do my best to help you!***

&lt;/details&gt;


## Acknowledgements

- A big shout-out to [all the contributors](https://github.com/GyulyVGC/sniffnet/blob/main/CONTRIBUTORS.md) of Sniffnet!
- The graphical user interface has been realized with [iced](https://github.com/iced-rs/iced), a cross-platform GUI library for Rust focused on simplicity and type-safety
- IP geolocation and ASN data are provided by [MaxMind](https://www.maxmind.com)
- Last but not least, thanks to [every single stargazer](https://github.com/GyulyVGC/sniffnet/stargazers): all forms of support made it possible to keep improving Sniffnet!


## Stay in the loop

Wait... there&#039;s more!&lt;br&gt;Sniffnet is rapidly evolving, and new features are added on a regular basis.&lt;br&gt;
Follow the &lt;a href=&quot;https://sniffnet.net/news&quot;&gt;&lt;b&gt;news&lt;/b&gt;&lt;/a&gt; and Sniffnet socials to never miss an update.

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://bsky.app/profile/sniffnet.net&quot;&gt;&lt;img width=&quot;48&quot; height=&quot;48&quot; alt=&quot;Bluesky&quot; title=&quot;Bluesky&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/bluesky.svg&quot;/&gt;&lt;/a&gt;&amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/sniffnet&quot;&gt;&lt;img width=&quot;48&quot; height=&quot;48&quot; alt=&quot;LinkedIn&quot; title=&quot;LinkedIn&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/linkedin.svg&quot;/&gt;&lt;/a&gt;&amp;nbsp;
    &lt;a href=&quot;https://mastodon.social/@sniffnet&quot;&gt;&lt;img width=&quot;48&quot; height=&quot;48&quot; alt=&quot;Mastodon&quot; title=&quot;Mastodon&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/mastodon.svg&quot;/&gt;&lt;/a&gt;&amp;nbsp;
    &lt;a href=&quot;https://t.me/sniffnet&quot;&gt;&lt;img width=&quot;48&quot; height=&quot;48&quot; alt=&quot;Telegram&quot; title=&quot;Telegram&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/telegram.svg&quot;/&gt;&lt;/a&gt;&amp;nbsp;
    &lt;a href=&quot;https://x.com/sniffnet&quot;&gt;&lt;img width=&quot;48&quot; height=&quot;48&quot; alt=&quot;Twitter / X&quot; title=&quot;Twitter / X&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/x.svg&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vosen/ZLUDA]]></title>
            <link>https://github.com/vosen/ZLUDA</link>
            <guid>https://github.com/vosen/ZLUDA</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[CUDA on non-NVIDIA GPUs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vosen/ZLUDA">vosen/ZLUDA</a></h1>
            <p>CUDA on non-NVIDIA GPUs</p>
            <p>Language: Rust</p>
            <p>Stars: 12,441</p>
            <p>Forks: 778</p>
            <p>Stars today: 75 stars today</p>
            <h2>README</h2><pre>[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.gg/sg6BNzXuc7)

# ZLUDA

ZLUDA is a drop-in replacement for CUDA on non-NVIDIA GPU. ZLUDA allows to run unmodified CUDA applications using non-NVIDIA GPUs with near-native performance.

ZLUDA supports AMD Radeon RX 5000 series and newer GPUs (both desktop and integrated).

![GeekBench 5.5.1 chart](geekbench.svg)

ZLUDA is work in progress. Follow development here and say hi on [Discord](https://discord.gg/sg6BNzXuc7). For more details see the announcement: https://vosen.github.io/ZLUDA/blog/zludas-third-life/

## Usage
**Warning**: This version ZLUDA is under heavy development (more [here](https://vosen.github.io/ZLUDA/blog/zludas-third-life/)) and right now only supports Geekbench. ZLUDA probably will not work with your application just yet.

### Windows
You should have recent AMD GPU driver (&quot;AMD Software: Adrenalin Edition&quot;) installed.\
To run your application you should etiher:
* (Recommended approach) Copy ZLUDA-provided `nvcuda.dll` and `nvml.dll` from `target\release` (if built from sources) or `zluda` (if downloaded a zip package) into a path which your application uses to load CUDA. Paths vary application to application, but usually it&#039;s the directory where the .exe file is located
* Use ZLUDA launcher like below. ZLUDA launcher is known to be buggy and incomplete:
    ```
    &lt;ZLUDA_DIRECTORY&gt;\zluda_with.exe -- &lt;APPLICATION&gt; &lt;APPLICATIONS_ARGUMENTS&gt;
    ```

### Linux

Run your application like this:
```
LD_LIBRARY_PATH=&lt;ZLUDA_DIRECTORY&gt; &lt;APPLICATION&gt; &lt;APPLICATIONS_ARGUMENTS&gt;
```

where `&lt;ZLUDA_DIRECTORY&gt;` is the directory which contains ZLUDA-provided `libcuda.so`: `target/release` if you built from sources or `zluda` if you downloaded prebuilt package.

### MacOS

Not supported

## Building

### Dependencies

* Git
* CMake
* Python 3
* Rust compiler (recent version)
* C++ compiler
* (Optional, but recommended) [Ninja build system](https://ninja-build.org/)

### Build steps

* Git clone the repo (make sure to use `--recursive` option to fetch submodules):  
`git clone --recursive https://github.com/vosen/ZLUDA.git`  
* Enter freshly cloned `ZLUDA` directory and build with cargo (this takes a while):  
`cargo xtask --release`

## Contributing

ZLUDA project has a commercial backing and _does not_ accept donations.
ZLUDA project accepts pull requests and other non-monetary contributions.

If you want to contribute a code fix or documentation update feel free to open a Pull Request.

### Getting started

There&#039;s no architecture document (yet). Two most important crates in ZLUDA are `ptx` (PTX compiler) and `zluda` (AMD GPU runtime). A good starting point to tinkering the project is to run one of the `ptx` unit tests under a debugger and understand what it is doing. `cargo test -p ptx -- ::add_hip` is a simple test that adds two numbers.

Github issues tagged with [&quot;help wanted&quot;](https://github.com/vosen/ZLUDA/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22) are tasks that are self-containted. Their level of difficulty varies, they are not always good beginner tasks, but they defined unambiguously.

If you have questions feel free to ask on [#devtalk channel on Discord](https://discord.com/channels/1273316903783497778/1303329281409159270).


## License

This software is dual-licensed under either the Apache 2.0 license or the MIT license. See [LICENSE-APACHE](LICENSE-APACHE) or [LICENSE-MIT](LICENSE-MIT) for details
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[DioxusLabs/dioxus]]></title>
            <link>https://github.com/DioxusLabs/dioxus</link>
            <guid>https://github.com/DioxusLabs/dioxus</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[Fullstack app framework for web, desktop, and mobile.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DioxusLabs/dioxus">DioxusLabs/dioxus</a></h1>
            <p>Fullstack app framework for web, desktop, and mobile.</p>
            <p>Language: Rust</p>
            <p>Stars: 29,388</p>
            <p>Forks: 1,216</p>
            <p>Stars today: 49 stars today</p>
            <h2>README</h2><pre>&lt;p&gt;
    &lt;p align=&quot;center&quot; &gt;
      &lt;!-- &lt;img src=&quot;./notes/header-light-updated.svg#gh-light-mode-only&quot; &gt;
      &lt;img src=&quot;./notes/header-dark-updated.svg#gh-dark-mode-only&quot; &gt; --&gt;
      &lt;!-- &lt;a href=&quot;https://dioxuslabs.com&quot;&gt;
          &lt;img src=&quot;./notes/flat-splash.avif&quot;&gt;
      &lt;/a&gt; --&gt;
      &lt;img src=&quot;./notes/splash-header-darkmode.svg#gh-dark-mode-only&quot; style=&quot;width: 80%; height: auto;&quot;&gt;
      &lt;img src=&quot;./notes/splash-header.svg#gh-light-mode-only&quot; style=&quot;width: 80%; height: auto;&quot;&gt;
      &lt;img src=&quot;./notes/image-splash.avif&quot;&gt;
      &lt;br&gt;
    &lt;/p&gt;
&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Crates version --&gt;
  &lt;a href=&quot;https://crates.io/crates/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/dioxus.svg?style=flat-square&quot;
    alt=&quot;Crates.io version&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Downloads --&gt;
  &lt;a href=&quot;https://crates.io/crates/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/d/dioxus.svg?style=flat-square&quot;
      alt=&quot;Download&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- docs --&gt;
  &lt;a href=&quot;https://docs.rs/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square&quot;
      alt=&quot;docs.rs docs&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- CI --&gt;
  &lt;a href=&quot;https://github.com/jkelleyrtp/dioxus/actions&quot;&gt;
    &lt;img src=&quot;https://github.com/dioxuslabs/dioxus/actions/workflows/main.yml/badge.svg&quot;
      alt=&quot;CI status&quot; /&gt;
  &lt;/a&gt;

  &lt;!--Awesome --&gt;
  &lt;a href=&quot;https://dioxuslabs.com/awesome&quot;&gt;
    &lt;img src=&quot;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg&quot; alt=&quot;Awesome Page&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Discord --&gt;
  &lt;a href=&quot;https://discord.gg/XgGxMSkvUM&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/899851952891002890.svg?logo=discord&amp;style=flat-square&quot; alt=&quot;Discord Link&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;
    &lt;a href=&quot;https://dioxuslabs.com&quot;&gt; Website &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/tree/main/examples&quot;&gt; Examples &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://dioxuslabs.com/learn/0.6/guide&quot;&gt; Guide &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/zh-cn/README.md&quot;&gt; ‰∏≠Êñá &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/pt-br/README.md&quot;&gt; PT-BR &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/ja-jp/README.md&quot;&gt; Êó•Êú¨Ë™û &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/tr-tr&quot;&gt; T√ºrk√ße &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/ko-kr&quot;&gt; ÌïúÍµ≠Ïñ¥ &lt;/a&gt;
  &lt;/h3&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/releases/tag/v0.7.0-alpha.0&quot;&gt;‚ú® Dioxus 0.7 is in alpha - test it out! ‚ú®&lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;

Build for web, desktop, and mobile, and more with a single codebase. Zero-config setup, integrated hot-reloading, and signals-based state management. Add backend functionality with Server Functions and bundle with our CLI.

```rust
fn app() -&gt; Element {
    let mut count = use_signal(|| 0);

    rsx! {
        h1 { &quot;High-Five counter: {count}&quot; }
        button { onclick: move |_| count += 1, &quot;Up high!&quot; }
        button { onclick: move |_| count -= 1, &quot;Down low!&quot; }
    }
}
```

## ‚≠êÔ∏è Unique features:

- Cross-platform apps in three lines of code (web, desktop, mobile, server, and more)
- [Ergonomic state management](https://dioxuslabs.com/blog/release-050) combines the best of React, Solid, and Svelte
- Built-in featureful, type-safe, fullstack web framework
- Integrated bundler for deploying to the web, macOS, Linux, and Windows
- Subsecond Rust hot-patching and asset hot-reloading
- And more! [Take a tour of Dioxus](https://dioxuslabs.com/learn/0.6/).

## Instant hot-reloading

With one command, `dx serve` and your app is running. Edit your markup, styles, and even Rust code and see changes in milliseconds.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/hotreload-video.webp&quot;&gt;
  &lt;!-- &lt;video src=&quot;https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov&quot; width=&quot;500&quot;&gt;&lt;/video&gt; --&gt;
  &lt;!-- &lt;video src=&quot;https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov&quot; width=&quot;500&quot;&gt;&lt;/video&gt; --&gt;
&lt;/div&gt;

## Productive, typesafe, fullstack web framework

Directly call your backend from your frontend with our built-in type-safe RPC using [`server_fn`](http://crates.io/crates/server_fn). Supports streaming, suspense, bundle splitting, websockets, and more.

```rust
fn app() -&gt; Element {
  let mut fortune = use_signal(|| &quot;Fetch a fortune!&quot;);
  rsx! {
    h1 { &quot;{fortune}&quot; }
    button {
      onclick: move |_| async move {
        fortune.set(fetch_fortune().await.unwrap());
      }
    }
  }
}

#[server]
async fn fetch_fortune() -&gt; ServerFnResult&lt;String&gt; {
  &quot;Dioxus is super productive!&quot;.to_string()
}
```

## First-party primitive components

Get started quickly with a complete set of primitives modeled after shadcn/ui and Radix-Primitives.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/primitive-components.avif&quot;&gt;
&lt;/div&gt;

## First-class Android and iOS support

Dioxus is the fastest way to build native mobile apps with Rust. Simply run `dx serve --platform android` and your app is running in an emulator or on device in seconds. Call directly into JNI and Native APIs.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/android_and_ios2.avif&quot; width=&quot;500&quot;&gt;
&lt;/div&gt;

## Bundle for web, desktop, and mobile

Simply run `dx bundle` and your app will be built and bundled with maximization optimizations. On the web, take advantage of [`.avif` generation, `.wasm` compression, minification](https://dioxuslabs.com/learn/0.6/guides/assets), and more. Build WebApps weighing [less than 50kb](https://github.com/ealmloff/tiny-dioxus/) and desktop/mobile apps less than 5mb.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/bundle.gif&quot;&gt;
&lt;/div&gt;


## Fantastic documentation

We&#039;ve put a ton of effort into building clean, readable, and comprehensive documentation. All html elements and listeners are documented with MDN docs, and our Docs runs continuous integration with Dioxus itself to ensure that the docs are always up to date. Check out the [Dioxus website](https://dioxuslabs.com/learn/0.6/) for guides, references, recipes, and more. Fun fact: we use the Dioxus website as a testbed for new Dioxus features - [check it out!](https://github.com/dioxusLabs/docsite)

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/docs.avif&quot;&gt;
&lt;/div&gt;

## Community

Dioxus is a community-driven project, with a very active [Discord](https://discord.gg/XgGxMSkvUM) and [GitHub](https://github.com/DioxusLabs/dioxus/issues) community. We&#039;re always looking for help, and we&#039;re happy to answer questions and help you get started. [Our SDK](https://github.com/DioxusLabs/dioxus-std) is community-run and we even have a [GitHub organization](https://github.com/dioxus-community/) for the best Dioxus crates that receive free upgrades and support.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/dioxus-community.avif&quot;&gt;
&lt;/div&gt;

## Full-time core team

Dioxus has grown from a side project to a small team of fulltime engineers. Thanks to the generous support of FutureWei, Satellite.im, the GitHub Accelerator program, we&#039;re able to work on Dioxus full-time. Our long term goal is for Dioxus to become self-sustaining by providing paid high-quality enterprise tools. If your company is interested in adopting Dioxus and would like to work with us, please reach out!

## Supported Platforms

&lt;div align=&quot;center&quot;&gt;
  &lt;table style=&quot;width:100%&quot;&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Web&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render directly to the DOM using WebAssembly&lt;/li&gt;
          &lt;li&gt;Pre-render with SSR and rehydrate on the client&lt;/li&gt;
          &lt;li&gt;Simple &quot;hello world&quot; at about 50kb, comparable to React&lt;/li&gt;
          &lt;li&gt;Built-in dev server and hot reloading for quick iteration&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Desktop&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render using Webview or - experimentally - with WGPU or &lt;a href=&quot;https://freyaui.dev&quot;&gt;Freya&lt;/a&gt; (Skia) &lt;/li&gt;
          &lt;li&gt;Zero-config setup. Simply `cargo run` or `dx serve` to build your app &lt;/li&gt;
          &lt;li&gt;Full support for native system access without IPC &lt;/li&gt;
          &lt;li&gt;Supports macOS, Linux, and Windows. Portable &lt;3mb binaries &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Mobile&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render using Webview or - experimentally - with WGPU or Skia &lt;/li&gt;
          &lt;li&gt;Build .ipa and .apk files for iOS and Android &lt;/li&gt;
          &lt;li&gt;Call directly into Java and Objective-C with minimal overhead&lt;/li&gt;
          &lt;li&gt;From &quot;hello world&quot; to running on device in seconds&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Server-side Rendering&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Suspense, hydration, and server-side rendering&lt;/li&gt;
          &lt;li&gt;Quickly drop in backend functionality with server functions&lt;/li&gt;
          &lt;li&gt;Extractors, middleware, and routing integrations&lt;/li&gt;
          &lt;li&gt;Static-site generation and incremental regeneration&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## Running the examples

&gt; The examples in the main branch of this repository target the git version of dioxus and the CLI. If you are looking for examples that work with the latest stable release of dioxus, check out the [0.6 branch](https://github.com/DioxusLabs/dioxus/tree/v0.6/examples).

The examples in the top level of this repository can be run with:

```sh
cargo run --example &lt;example&gt;
```

However, we encourage you to download the dioxus-cli. If you are running the git version of dioxus, you can install the matching version of the CLI with:

```sh
cargo install --git https://github.com/DioxusLabs/dioxus dioxus-cli --locked
```

With the CLI, you can also run examples with the web platform. You just need to disable the default desktop feature and enable the web feature with this command:

```sh
dx serve --example &lt;example&gt; --platform web -- --no-default-features
```

## Dioxus vs other frameworks

We love all frameworks and enjoy watching innovation in the Rust ecosystem. In fact, many of our projects are shared with other frameworks. For example, our flex-box library [Taffy](https://github.com/DioxusLabs/taffy) is used by [Bevy](https://bevyengine.org/), [Zed](https://zed.dev/), [Lapce](https://lapce.dev/), [Iced](https://github.com/iced-rs/iced), and many more.

Dioxus places an emphasis on a few key points that make it different from other frameworks:

- **React-like**: we rely on concepts like components, props, and hooks to build UIs, with our state management being closer to Svelte than to SolidJS.
- **HTML and CSS**: we lean completely into HTML and CSS, quirks and all.
- **Renderer-agnostic**: you can swap out the renderer for any platform you want thanks to [our fast VirtualDOM](https://dioxuslabs.com/blog/templates-diffing).
- **Collaborative**: whenever possible, we spin out crates like [Taffy](https://github.com/DioxusLabs/taffy), [manganis](https://github.com/DioxusLabs/manganis), [include_mdbook](https://github.com/DioxusLabs/include_mdbook), and [blitz](http://github.com/dioxusLabs/blitz) so the ecosystem can grow together.

### Dioxus vs Tauri

Tauri is a framework for building desktop mobile apps where your frontend is written in a web-based framework like React, Vue, Svelte, etc. Whenever you need to do native work, you can write Rust functions and call them from your frontend.

- **Natively Rust**: Tauri&#039;s architecture limits your UI to either JavaScript or WebAssembly. With Dioxus, your Rust code is running natively on the user&#039;s machine, letting you do things like spawning threads, accessing the filesystem, without any IPC bridge. This drastically simplifies your app&#039;s architecture and makes it easier to build. You can build a Tauri app with Dioxus-Web as a frontend if you&#039;d like.

- **Different scopes**: Tauri needs to support JavaScript and its complex build tooling, limiting the scope of what you can do with it. Since Dioxus is exclusively focused on Rust, we&#039;re able to provide extra utilities like Server Functions, advanced bundling, and a native renderer.

- **Shared DNA**: While Tauri and Dioxus are separate projects, they do share libraries like Tao and Wry: windowing and webview libraries maintained by the Tauri team.

### Dioxus vs Leptos

Leptos is a library for building fullstack web-apps, similar to SolidJS and SolidStart. The two libraries share similar goals on the web, but have several key differences:

- **Reactivity model**: Leptos uses signals to drive both reactivity and rendering, while Dioxus uses signals just for reactivity. For managing re-renders, Dioxus uses a highly optimized VirtualDOM to support desktop and mobile architectures. Both Dioxus and Leptos are extremely fast and comparable to the fastest web frameworks.

- **Different scopes**: Dioxus provides renderers for web, desktop, mobile, LiveView, and more. We also maintain community libraries and a cross-platform SDK. Leptos has a tighter focus on the fullstack web with features that Dioxus doesn&#039;t have like islands, `&lt;Form /&gt;` components, and other web-specific utilities.

- **Different DSLs**: Dioxus uses its own custom Rust-like DSL for building UIs while Leptos uses an HTML-like syntax. We chose this to retain compatibility with IDE features like code-folding and syntax highlighting. Generally, Dioxus leans into more &quot;magic&quot; with its DSL including automatic formatting of strings and hot-reloading of simple Rust expressions.

```rust
// dioxus
rsx! {
  div {
    class: &quot;my-class&quot;,
    enabled: true,
    &quot;Hello, {name}&quot;
  }
}

// leptos
view! {
  &lt;div class=&quot;my-class&quot; enabled={true}&gt;
    &quot;Hello &quot;
    {name}
  &lt;/div&gt;
}
```

### Dioxus vs Yew

Yew is a framework for building reactive web apps that initially served as an inspiration for Dioxus. Yew is tightly integrated with the web but has limited utilities for server-side-rendering or alternative rendering engines. Dioxus was built as a redesign of Yew with a focus on cross-platform support, fantastic developer tooling, improved ergonomics, and a complete full-stack web story.

- **Full-stack capabilities**: Yew was initially designed for SPAs and remains deeply integrated with the web platform. Dioxus, in contrast, was built from the ground up for fullstack and cross-platform development, enabling seamless app creation across web, desktop, mobile, and server applications.

- **Developer Tooling**: Dioxus offers a richer set of built-in developer tools, such as autoformatting, hot-reloading, and an integrated bundler, helping streamline the development experience.

- **Ongoing support**: Dioxus is very actively maintained, with new features and bug fixes being fixed on a daily or weekly basis.

### Dioxus vs egui

egui is a cross-platform GUI library for Rust powering tools like [Rerun.io](https://www.rerun.io).

- **Immediate vs Retained**: egui is designed to be re-rendered on every frame. This is suitable for games and other interactive applications, but it does not retain style and layout state between frames. Dioxus is a retained UI framework, meaning that the UI is built once and then modified between frames. This enables Dioxus to use native web technologies like HTML and CSS with better battery life and performance.

- **Customizable**: egui brings its own styling and layout solution while Dioxus expects you to use the built-in HTML and CSS. This enables dioxus apps to use any CSS library like Tailwind or Material UI.

- **State management**: egui&#039;s state management is based on a single global state object. Dioxus encourages encapsulation of state by using components and props, making components more reusable.

### Dioxus vs Iced

Iced is a cross-platform GUI library inspired by Elm. Iced renders natively with WGPU and supports the web using DOM nodes.

- **Elm state management**: Iced uses Elm&#039;s state management model, which is based on message passing and reducers. This is simply a different state management model than Dioxus and can be rather verbose at times.

- **Native Feel**: Since Dioxus uses a webview as its renderer, it automatically gets native text input, paste handling, and other native features like accessibility. Iced&#039;s renderer currently doesn&#039;t implement these features, making it feel less native.

- **WGPU**: Dioxus&#039; WGPU renderer is currently quite immature and not yet ready for production use. Iced&#039;s WGPU renderer is much more mature and is being used in production. This enables certain types of apps that need GPU access to be built with Iced that can&#039;t currently be built with Dioxus.

### Dioxus vs Electron

Dioxus and Electron are two entirely different projects with similar goals. Electron makes it possible for developers to build cross-platform desktop apps using web technologies like HTML, CSS, and JavaScript.

- **Lightweight**: Dioxus uses the system&#039;s native WebView - or optionally, a WGPU renderer - to render the UI. This makes a typical Dioxus app about 15mb on macOS in comparison to Electron&#039;s 100mb. Electron also ships an embedded chromium instance which cannot share system resources with the host OS in the same way as Dioxus.

- **Maturity**: Electron is a mature project with a large community and a lot of tooling. Dioxus is still quite young in comparison to Electron. Expect to run into features like deep-linking that require extra work to implement.

## Contributing

- Check out the website [section on contributing](https://dioxuslabs.com/learn/0.6/contributing).
- Report issues on our [issue tracker](https://github.com/dioxuslabs/dioxus/issues).
- [Join](https://discord.gg/XgGxMSkvUM) the discord and ask questions!

&lt;a href=&quot;https://github.com/dioxuslabs/dioxus/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=dioxuslabs/dioxus&amp;max=30&amp;columns=10&quot; /&gt;
&lt;/a&gt;

## License

This project is licensed under either the [MIT license] or the [Apache-2 License].

[apache-2 license]: https://github.com/DioxusLabs/dioxus/blob/master/LICENSE-APACHE
[mit license]: https://github.com/DioxusLabs/dioxus/blob/master/LICENSE-MIT

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Dioxus by you, shall be licensed as MIT or Apache-2, without any additional
terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 15,632</p>
            <p>Forks: 1,312</p>
            <p>Stars today: 74 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# codename goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/7GaTvbDwga&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;&gt;
     &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.

# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)


# Goose Around with Us
- [Discord](https://discord.gg/block-opensource)
- [YouTube](https://www.youtube.com/@blockopensource)
- [LinkedIn](https://www.linkedin.com/company/block-opensource)
- [Twitter/X](https://x.com/blockopensource)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustdesk/rustdesk]]></title>
            <link>https://github.com/rustdesk/rustdesk</link>
            <guid>https://github.com/rustdesk/rustdesk</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustdesk/rustdesk">rustdesk/rustdesk</a></h1>
            <p>An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.</p>
            <p>Language: Rust</p>
            <p>Stars: 92,298</p>
            <p>Forks: 13,412</p>
            <p>Stars today: 136 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;res/logo-header.svg&quot; alt=&quot;RustDesk - Your remote desktop&quot;&gt;&lt;br&gt;
  &lt;a href=&quot;#raw-steps-to-build&quot;&gt;Build&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#how-to-build-with-docker&quot;&gt;Docker&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#file-structure&quot;&gt;Structure&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#snapshot&quot;&gt;Snapshot&lt;/a&gt;&lt;br&gt;
  [&lt;a href=&quot;docs/README-UA.md&quot;&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href=&quot;docs/README-CS.md&quot;&gt;ƒçesky&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ZH.md&quot;&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href=&quot;docs/README-HU.md&quot;&gt;Magyar&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ES.md&quot;&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FA.md&quot;&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FR.md&quot;&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DE.md&quot;&gt;Deutsch&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PL.md&quot;&gt;Polski&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ID.md&quot;&gt;Indonesian&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FI.md&quot;&gt;Suomi&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ML.md&quot;&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href=&quot;docs/README-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NL.md&quot;&gt;Nederlands&lt;/a&gt;] | [&lt;a href=&quot;docs/README-IT.md&quot;&gt;Italiano&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PTBR.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href=&quot;docs/README-EO.md&quot;&gt;Esperanto&lt;/a&gt;] | [&lt;a href=&quot;docs/README-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href=&quot;docs/README-AR.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href=&quot;docs/README-VN.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DA.md&quot;&gt;Dansk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-GR.md&quot;&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href=&quot;docs/README-TR.md&quot;&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NO.md&quot;&gt;Norsk&lt;/a&gt;]&lt;br&gt;
  &lt;b&gt;We need your help to translate this README, &lt;a href=&quot;https://github.com/rustdesk/rustdesk/tree/master/src/lang&quot;&gt;RustDesk UI&lt;/a&gt; and &lt;a href=&quot;https://github.com/rustdesk/doc.rustdesk.com&quot;&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt;
&lt;/p&gt;

&gt; [!Caution]
&gt; **Misuse Disclaimer:** &lt;br&gt;
&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.


Chat with us: [Discord](https://discord.gg/nDceKgxnkV) | [Twitter](https://twitter.com/rustdesk) | [Reddit](https://www.reddit.com/r/rustdesk) | [YouTube](https://www.youtube.com/@rustdesk)

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/I2I04VU09)

Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, [set up your own](https://rustdesk.com/server), or [write your own rendezvous/relay server](https://github.com/rustdesk/rustdesk-server-demo).

![image](https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png)

RustDesk welcomes contribution from everyone. See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for help getting started.

[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)

[**BINARY DOWNLOAD**](https://github.com/rustdesk/rustdesk/releases)

[**NIGHTLY BUILD**](https://github.com/rustdesk/rustdesk/releases/tag/nightly)

[&lt;img src=&quot;https://f-droid.org/badge/get-it-on.png&quot;
    alt=&quot;Get it on F-Droid&quot;
    height=&quot;80&quot;&gt;](https://f-droid.org/en/packages/com.carriez.flutter_hbb)
[&lt;img src=&quot;https://flathub.org/api/badge?svg&amp;locale=en&quot;
    alt=&quot;Get it on Flathub&quot;
    height=&quot;80&quot;&gt;](https://flathub.org/apps/com.rustdesk.RustDesk)

## Dependencies

Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our [CI](https://github.com/rustdesk/rustdesk/blob/master/.github/workflows/flutter-build.yml) for building Flutter version.

Please download Sciter dynamic library yourself.

[Windows](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll) |
[Linux](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so) |
[macOS](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib)

## Raw Steps to build

- Prepare your Rust development env and C++ build env

- Install [vcpkg](https://github.com/microsoft/vcpkg), and set `VCPKG_ROOT` env variable correctly

  - Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static
  - Linux/macOS: vcpkg install libvpx libyuv opus aom

- run `cargo run`

## [Build](https://rustdesk.com/docs/en/dev/build/)

## How to Build on Linux

### Ubuntu 18 (Debian 10)

```sh
sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
```

### openSUSE Tumbleweed

```sh
sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
```

### Fedora 28 (CentOS 8)

```sh
sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
```

### Arch (Manjaro)

```sh
sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
```

### Install vcpkg

```sh
git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
```

### Fix libvpx (For Fedora)

```sh
cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i &#039;s/CFLAGS+=-I/CFLAGS+=-fPIC -I/g&#039; Makefile
sed -i &#039;s/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g&#039; Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
```

### Build

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
```

## How to build with Docker

Begin by cloning the repository and building the Docker container:

```sh
git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t &quot;rustdesk-builder&quot; .
```

Then, each time you need to build the application, run the following command:

```sh
docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=&quot;$(id -u)&quot; -e PGID=&quot;$(id -g)&quot; rustdesk-builder
```

Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the `&lt;OPTIONAL-ARGS&gt;` position. For instance, if you wanted to build an optimized release version, you would run the command above followed by `--release`. The resulting executable will be available in the target folder on your system, and can be run with:

```sh
target/debug/rustdesk
```

Or, if you&#039;re running a release executable:

```sh
target/release/rustdesk
```

Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as `install` or `run` are not currently supported via this method as they would install or run the program inside the container instead of the host.

## File Structure

- **[libs/hbb_common](https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common)**: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions
- **[libs/scrap](https://github.com/rustdesk/rustdesk/tree/master/libs/scrap)**: screen capture
- **[libs/enigo](https://github.com/rustdesk/rustdesk/tree/master/libs/enigo)**: platform specific keyboard/mouse control
- **[libs/clipboard](https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard)**: file copy and paste implementation for Windows, Linux, macOS.
- **[src/ui](https://github.com/rustdesk/rustdesk/tree/master/src/ui)**: obsolete Sciter UI (deprecated)
- **[src/server](https://github.com/rustdesk/rustdesk/tree/master/src/server)**: audio/clipboard/input/video services, and network connections
- **[src/client.rs](https://github.com/rustdesk/rustdesk/tree/master/src/client.rs)**: start a peer connection
- **[src/rendezvous_mediator.rs](https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs)**: Communicate with [rustdesk-server](https://github.com/rustdesk/rustdesk-server), wait for remote direct (TCP hole punching) or relayed connection
- **[src/platform](https://github.com/rustdesk/rustdesk/tree/master/src/platform)**: platform specific code
- **[flutter](https://github.com/rustdesk/rustdesk/tree/master/flutter)**: Flutter code for desktop and mobile
- **[flutter/web/js](https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js)**: JavaScript for Flutter web client

## Screenshots

![Connection Manager](https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651)

![Connected to a Windows PC](https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea)

![File Transfer](https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad)

![TCP Tunneling](https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[bevyengine/bevy]]></title>
            <link>https://github.com/bevyengine/bevy</link>
            <guid>https://github.com/bevyengine/bevy</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[A refreshingly simple data-driven game engine built in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bevyengine/bevy">bevyengine/bevy</a></h1>
            <p>A refreshingly simple data-driven game engine built in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 40,470</p>
            <p>Forks: 3,979</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre># [![Bevy](assets/branding/bevy_logo_light_dark_and_dimmed.svg)](https://bevy.org)

[![License](https://img.shields.io/badge/license-MIT%2FApache-blue.svg)](https://github.com/bevyengine/bevy#license)
[![Crates.io](https://img.shields.io/crates/v/bevy.svg)](https://crates.io/crates/bevy)
[![Downloads](https://img.shields.io/crates/d/bevy.svg)](https://crates.io/crates/bevy)
[![Docs](https://docs.rs/bevy/badge.svg)](https://docs.rs/bevy/latest/bevy/)
[![CI](https://github.com/bevyengine/bevy/workflows/CI/badge.svg)](https://github.com/bevyengine/bevy/actions)
[![Discord](https://img.shields.io/discord/691052431525675048.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/bevy)

## What is Bevy?

Bevy is a refreshingly simple data-driven game engine built in Rust. It is free and open-source forever!

## WARNING

Bevy is still in the early stages of development. Important features are missing. Documentation is sparse. A new version of Bevy containing breaking changes to the API is released [approximately once every 3 months](https://bevy.org/news/bevy-0-6/#the-train-release-schedule). We provide [migration guides](https://bevy.org/learn/migration-guides/), but we can&#039;t guarantee migrations will always be easy. Use only if you are willing to work in this environment.

**MSRV:** Bevy relies heavily on improvements in the Rust language and compiler.
As a result, the Minimum Supported Rust Version (MSRV) is generally close to &quot;the latest stable release&quot; of Rust.

## Design Goals

* **Capable**: Offer a complete 2D and 3D feature set
* **Simple**: Easy for newbies to pick up, but infinitely flexible for power users
* **Data Focused**: Data-oriented architecture using the Entity Component System paradigm
* **Modular**: Use only what you need. Replace what you don&#039;t like
* **Fast**: App logic should run quickly, and when possible, in parallel
* **Productive**: Changes should compile quickly ... waiting isn&#039;t fun

## About

* **[Features](https://bevy.org):** A quick overview of Bevy&#039;s features.
* **[News](https://bevy.org/news/)**: A development blog that covers our progress, plans and shiny new features.

## Docs

* **[Quick Start Guide](https://bevy.org/learn/quick-start/introduction):** Bevy&#039;s official Quick Start Guide. The best place to start learning Bevy.
* **[Bevy Rust API Docs](https://docs.rs/bevy):** Bevy&#039;s Rust API docs, which are automatically generated from the doc comments in this repo.
* **[Official Examples](https://github.com/bevyengine/bevy/tree/latest/examples):** Bevy&#039;s dedicated, runnable examples, which are great for digging into specific concepts.
* **[Community-Made Learning Resources](https://bevy.org/assets/#learning)**: More tutorials, documentation, and examples made by the Bevy community.

## Community

Before contributing or participating in discussions with the community, you should familiarize yourself with our [**Code of Conduct**](./CODE_OF_CONDUCT.md).

* **[Discord](https://discord.gg/bevy):** Bevy&#039;s official discord server.
* **[Reddit](https://reddit.com/r/bevy):** Bevy&#039;s official subreddit.
* **[GitHub Discussions](https://github.com/bevyengine/bevy/discussions):** The best place for questions about Bevy, answered right here!
* **[Bevy Assets](https://bevy.org/assets/):** A collection of awesome Bevy projects, tools, plugins and learning materials.

### Contributing

If you&#039;d like to help build Bevy, check out the **[Contributor&#039;s Guide](https://bevy.org/learn/contribute/introduction)**.
For simple problems, feel free to [open an issue](https://github.com/bevyengine/bevy/issues) or
[PR](https://github.com/bevyengine/bevy/pulls) and tackle it yourself!

For more complex architecture decisions and experimental mad science, please open an [RFC](https://github.com/bevyengine/rfcs) (Request For Comments) so we can brainstorm together effectively!

## Getting Started

We recommend checking out the [Quick Start Guide](https://bevy.org/learn/quick-start/introduction) for a brief introduction.

Follow the [Setup guide](https://bevy.org/learn/quick-start/getting-started/setup) to ensure your development environment is set up correctly.
Once set up, you can quickly try out the [examples](https://github.com/bevyengine/bevy/tree/latest/examples) by cloning this repo and running the following commands:

```sh
# Switch to the correct version (latest release, default is main development branch)
git checkout latest
# Runs the &quot;breakout&quot; example
cargo run --example breakout
```

To draw a window with standard functionality enabled, use:

```rust
use bevy::prelude::*;

fn main() {
  App::new()
    .add_plugins(DefaultPlugins)
    .run();
}
```

### Fast Compiles

Bevy can be built just fine using default configuration on stable Rust. However for really fast iterative compiles, you should enable the &quot;fast compiles&quot; setup by [following the instructions here](https://bevy.org/learn/quick-start/getting-started/setup).

## [Bevy Cargo Features][cargo_features]

This [list][cargo_features] outlines the different cargo features supported by Bevy. These allow you to customize the Bevy feature set for your use-case.

[cargo_features]: docs/cargo_features.md

## Thanks

Bevy is the result of the hard work of many people. A huge thanks to all Bevy contributors, the many open source projects that have come before us, the [Rust gamedev ecosystem](https://arewegameyet.rs/), and the many libraries we build on.

A huge thanks to Bevy&#039;s [generous sponsors](https://bevy.org). Bevy will always be free and open source, but it isn&#039;t free to make. Please consider [sponsoring our work](https://bevy.org/donate/) if you like what we&#039;re building.

&lt;!-- This next line need to stay exactly as is. It is required for BrowserStack sponsorship. --&gt;
This project is tested with BrowserStack.

## License

Bevy is free, open source and permissively licensed!
Except where noted (below and/or in individual files), all code in this repository is dual-licensed under either:

* MIT License ([LICENSE-MIT](LICENSE-MIT) or [http://opensource.org/licenses/MIT](http://opensource.org/licenses/MIT))
* Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0))

at your option.
This means you can select the license you prefer!
This dual-licensing approach is the de-facto standard in the Rust ecosystem and there are [very good reasons](https://github.com/bevyengine/bevy/issues/2373) to include both.

Some of the engine&#039;s code carries additional copyright notices and license terms due to their external origins.
These are generally BSD-like, but exact details vary by crate:
If the README of a crate contains a &#039;License&#039; header (or similar), the additional copyright notices and license terms applicable to that crate will be listed.
The above licensing requirement still applies to contributions to those crates, and sections of those crates will carry those license terms.
The [license](https://doc.rust-lang.org/cargo/reference/manifest.html#the-license-and-license-file-fields) field of each crate will also reflect this.
For example, [`bevy_mikktspace`](./crates/bevy_mikktspace/README.md#license-agreement) has code under the Zlib license (as well as a copyright notice when choosing the MIT license).

The [assets](assets) included in this repository (for our [examples](./examples/README.md)) typically fall under different open licenses.
These will not be included in your game (unless copied in by you), and they are not distributed in the published bevy crates.
See [CREDITS.md](CREDITS.md) for the details of the licenses of those files.

### Your contributions

Unless you explicitly state otherwise,
any contribution intentionally submitted for inclusion in the work by you,
as defined in the Apache-2.0 license,
shall be dual licensed as above,
without any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[szabodanika/microbin]]></title>
            <link>https://github.com/szabodanika/microbin</link>
            <guid>https://github.com/szabodanika/microbin</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[A secure, configurable file-sharing and URL shortening web app written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/szabodanika/microbin">szabodanika/microbin</a></h1>
            <p>A secure, configurable file-sharing and URL shortening web app written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,401</p>
            <p>Forks: 209</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre>
![Screenshot](.github/index.png)

# MicroBin

![Build](https://github.com/szabodanika/microbin/actions/workflows/rust.yml/badge.svg)
[![crates.io](https://img.shields.io/crates/v/microbin.svg)](https://crates.io/crates/microbin)
[![Docker Image](https://github.com/szabodanika/microbin/actions/workflows/release.yml/badge.svg)](https://hub.docker.com/r/danielszabo99/microbin)
[![Docker Pulls](https://img.shields.io/docker/pulls/danielszabo99/microbin?label=Docker%20pulls)](https://img.shields.io/docker/pulls/danielszabo99/microbin?label=Docker%20pulls)

MicroBin is a super tiny, feature-rich, configurable, self-contained and self-hosted paste bin web application. It is very easy to set up and use, and will only require a few megabytes of memory and disk storage. It takes only a couple minutes to set it up, why not give it a try now?

### Check out the Public Test Server at [pub.microbin.eu](https://pub.microbin.eu)!

### Or host MicroBin yourself

Run our quick docker setup script ([DockerHub](https://hub.docker.com/r/danielszabo99/microbin)):
```bash
bash &lt;(curl -s https://microbin.eu/docker.sh)
```

Or install it manually from [Cargo](https://crates.io/crates/microbin):

```bash
cargo install microbin;
curl -L -O https://raw.githubusercontent.com/szabodanika/microbin/master/.env;
source .env;
microbin
```

On our website [microbin.eu](https://microbin.eu), you will find the following:

- [Screenshots](https://microbin.eu/screenshots/)
- [Guide and Documentation](https://microbin.eu/docs/intro)
- [Donations and Sponsorships](https://microbin.eu/sponsorship)
- [Roadmap](https://microbin.eu/roadmap)

## Features

- Entirely self-contained executable, MicroBin is a single file!
- Server-side and client-side encryption
- File uploads (e.g. `server.com/file/pig-dog-cat`)
- Raw text serving (e.g. `server.com/raw/pig-dog-cat`)
- QR code support
- URL shortening and redirection
- Animal names instead of random numbers for upload identifiers (64 animals)
- SQLite and JSON database support
- Private and public, editable and uneditable, automatically and never expiring uploads
- Automatic dark mode and custom styling support with very little CSS and only vanilla JS (see [`water.css`](https://github.com/kognise/water.css))
- And much more!

## What is an upload?

In MicroBin, an upload can be:

- A text that you want to paste from one machine to another, e.g. some code,
- A file that you want to share, e.g. a video that is too large for Discord, a zip with a code project in it or an image,
- A URL redirection.

## When is MicroBin useful?

You can use MicroBin:

- To send long texts to other people,
- To send large files to other people,
- To share secrets or sensitive documents securely,
- As a URL shortener/redirect service,
- To serve content on the web, eg . configuration files for testing, images, or any other file content using the Raw functionality,
- To move files between your desktop and a server you access from the console,
- As a &quot;postbox&quot; service where people can upload their files or texts, but they cannot see or remove what others sent you,
- Or even to take quick notes.

...and many other things, why not get creative?

MicroBin and MicroBin.eu are available under the [BSD 3-Clause License](LICENSE).

¬© D√°niel Szab√≥ 2022-2024
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[foundry-rs/foundry]]></title>
            <link>https://github.com/foundry-rs/foundry</link>
            <guid>https://github.com/foundry-rs/foundry</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/foundry-rs/foundry">foundry-rs/foundry</a></h1>
            <p>Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 9,123</p>
            <p>Forks: 2,026</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;.github/assets/banner.png&quot; alt=&quot;Foundry banner&quot; /&gt;

&amp;nbsp;

[![Github Actions][gha-badge]][gha-url] [![Telegram Chat][tg-badge]][tg-url] [![Telegram Support][tg-support-badge]][tg-support-url]
![Foundry](https://img.shields.io/badge/Foundry-grey?style=flat&amp;logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAElElEQVR4nH1VUUhUaRg9984YdzBpkqR0Z210rIESIXSabEbcHgydrpNRRj00kWaztj0U1MOW0MOIbD300IvLMqBpMTGYxdoqyoRNDUESBDWwUuPugCSSsTM7u0Oj1/+efdiMcmnP2/fDd77D4f/OB6xCa2urQZbllVICYGtqanK1tLS4AdgAyAAgyzJaW1sNq/ulT4twOGw4fPiwAGDp7Ow8VV1d7bVarRWxWCw/k8mgsbExm0wmZ+Lx+M/Xr1//CcAsSVmSJH01McLhsAEAnE5nx+Tk5B/xeJxOp5N9fX2sqqqixWLhnTt36HA4GIvFGI1GU3V1df5Pe/9D1t7eHkgkEuzo6GBPT49WWloq7Ha7fujQITocDu7atUs3m83i6tWr2okTJ/jixQuePn265zPScDhskGUZe/fubXv8+DFv3rypbdiwQaxbt46RSIT79u3j0NAQb926RVVVOT4+TqvVyvz8fD0YDC5NTk6ysbHxlCRJ/5KSlAAURyKRTFNTkwAg7t69S5/Px76+Pq7GyMgI9+/fz9HRUQIQO3bsEKOjo38DsJCUJADw+/0BVVW7otHo8ps3b4yvXr3CxMQETCYTTCYTNE0DAOTl5SGXy0FRFOzZswdmsxkVFRXLNTU1xmg0+kNvb+/3AGAcGBiI7969Wwcg6urq+OTJE967d49btmzh9PT0R3WJRIKBQIDBYJBTU1NsaGggAGGz2fTe3t5fAeQZAWwuLi4uP3nypOT1emEwGFBeXo7a2losLCygoaEB/f39MJlMCIVCkCQJBw8ehNVqhcfjQXNzs1RSUiKtX7++DEAZqqqq3KFQiABYUFDAM2fOkCQXFxdJkvfv32dhYSG9Xi+vXbvG2dnZj4oDgQCLioqoKAqHhobodDq/Mc7NzUklJSUIBoOw2WzYtm0blpeXsWbNGkxMTODp06doa2vD4OAgNm7cCIvFApLQdR3nzp3Dzp078fLlSxQVFeHdu3cAgIpHjx69/zBUX5k+MDBAt9vNY8eOsbu7m6lUigcOHKDL5WImkyHJz9TGYrEcALsMIPn69esZTdMIgM+ePUNXVxdu376NsrIyuN1uXLp0CWazGcPDw3C5XFBVFWfPnkVNTQ18Pp+ezWY5MzPzO4DfAABHjhzpJslUKqVdvHiR4+PjbG9vZy6XI0kuLS0xmUxSCEGS9Pv9LC0tpdFoZGVlpSaEoM/nuwIAKx/7q5GRkb9CoZBQVVWcP3+ez58/J0mm02kODg7ywoULjMViTKfTtNvtXLt2LTdt2qTncrnlsbGxLICvSUqfrl5HJBLh1NTUkhBCJ8mFhQX29/dTVVUWFBTwwYMH1HWdly9fpqIoeiKRWJqfn2d1dXWnLMuf7zMAHD16tGd+fn7FZy2bzYrKykodAAFQVVV9cXFRkNTevn3Lubk5trS0XPnfxHE4HN8ODw+nV/yanp6mx+Ohx+P5aIMQgmNjY3/W1tZ+t5rsSwG7+fjx4/76+vrm7du32woLC00AkE6n38fj8ZmHDx/+cuPGjR8BJL8YsCtYdQIMALYqilKvKEo9APuHty+egH8A3GfFDJXmxmMAAAAASUVORK5CYII%3D&amp;link=https%3A%2F%2Fbook.getfoundry.sh%2F)

[gha-badge]: https://img.shields.io/github/actions/workflow/status/foundry-rs/foundry/test.yml?branch=master
[gha-url]: https://github.com/foundry-rs/foundry/actions
[tg-badge]: https://img.shields.io/endpoint?color=neon&amp;logo=telegram&amp;label=chat&amp;style=flat-square&amp;url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ffoundry_rs
[tg-url]: https://t.me/foundry_rs
[tg-support-badge]: https://img.shields.io/endpoint?color=neon&amp;logo=telegram&amp;label=support&amp;style=flat-square&amp;url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ffoundry_support
[tg-support-url]: https://t.me/foundry_support

**[Install](https://getfoundry.sh/getting-started/installation)**
| [Docs][foundry-docs]
| [Developer Guidelines](./docs/dev/README.md)
| [Contributing](./CONTRIBUTING.md)

&lt;/div&gt;

---

### Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.

Foundry consists of:

- [**Forge**](#forge): Build, test, fuzz, debug and deploy [Solidity][solidity] contracts, like Hardhat, Brownie, Ape.
- [**Cast**](#cast): A Swiss Army knife for interacting with EVM smart contracts, sending transactions and getting chain data.
- [**Anvil**](#anvil): Fast local Ethereum development node, akin to Hardhat Network, Tenderly.
- [**Chisel**](#chisel): Fast, utilitarian, and verbose Solidity REPL.

**Need help getting started with Foundry? Read the [üìñ Foundry Docs][foundry-docs]!**

![Demo](.github/assets/demo.gif)

## Features

- **High-Performance Compilation**

  - **Fast and Flexible**: Automatically detects and installs the required Solidity compiler version.
  - **Solidity and Vyper Support**: Fully supports both Solidity and Vyper out-of-the-box.
  - **Incremental Compilation**: Re-compiles only changed files, saving time.
  - **Parallelized Pipeline**: Leverages multi-core systems for ultra-fast builds.
  - **Broad Compatibility**: Supports non-standard directory structures, including [Hardhat repos](https://twitter.com/gakonst/status/1461289225337421829).

- **Advanced Testing**

  - **No Context Switching**: Write tests directly in Solidity.
  - **Fuzz Testing**: Quickly identify edge cases with input shrinking and counter-example generation.
  - **Invariant Testing**: Ensure complex system properties hold across a wide range of inputs.
  - **Debugging Made Easy**: Use [forge-std](https://github.com/foundry-rs/forge-std)&#039;s `console.sol` for flexible debug logging.
  - **Interactive Debugger**: Step through your Solidity code with Foundry&#039;s interactive debugger, making it easy to pinpoint issues.

- **Powerful Runtime Features**

  - **RPC Forking**: Fast and efficient remote RPC forking backed by [Alloy][alloy].
  - **Lightweight &amp; Portable**: No dependency on Nix or other package managers for installation.

- **Streamlined CI/CD**

  - **Optimized CI**: Accelerate builds, run tests and execute scripts using [Foundry&#039;s GitHub action][foundry-gha].

## Installation

Getting started is very easy:

Install `foundryup`:

```
curl -L https://foundry.paradigm.xyz | bash
```

Next, run `foundryup`.

It will automatically install the latest version of the precompiled binaries: [`forge`](#forge), [`cast`](#cast), [`anvil`](#anvil), and [`chisel`](#chisel).

```
foundryup
```

**Done!**

For additional details see the [installation guide](https://getfoundry.sh/getting-started/installation) in the [Foundry Docs][foundry-docs].

If you&#039;re experiencing any issues while installing, check out [Getting Help](#getting-help) and the [FAQ](https://getfoundry.sh/faq).

## How Fast?

Forge is quite fast at both compiling (leveraging `solc` with [foundry-compilers]) and testing.

See the benchmarks below. Older benchmarks against [DappTools][dapptools] can be found in the [v0.2.0 announcement post][benchmark-post] and in the [Convex Shutdown Simulation][convex] repository.

### Testing Benchmarks

| Project                                       | Type                 | [Forge 1.0][foundry-1.0] | [Forge 0.2][foundry-0.2] | DappTools | Speedup        |
| --------------------------------------------- | -------------------- | ------------------------ | ------------------------ | --------- | -------------- |
| [vectorized/solady][solady]                   | Unit / Fuzz          | 0.9s                     | 2.3s                     | -         | 2.6x           |
| [morpho-org/morpho-blue][morpho-blue]         | Invariant            | 0.7s                     | 1m43s                    | -         | 147.1x         |
| [morpho-org/morpho-blue-oracles][morpho-blue] | Integration (Cold)   | 6.1s                     | 6.3s                     | -         | 1.04x          |
| [morpho-org/morpho-blue-oracles][morpho-blue] | Integration (Cached) | 0.6s                     | 0.9s                     | -         | 1.50x          |
| [transmissions11/solmate][solmate]            | Unit / Fuzz          | 2.7s                     | 2.8s                     | 6m34s     | 1.03x / 140.0x |
| [reflexer-labs/geb][geb]                      | Unit / Fuzz          | 0.2s                     | 0.4s                     | 23s       | 2.0x / 57.5x   |

_In the above benchmarks, compilation was always skipped_

**Takeaway: Forge dramatically outperforms the competition, delivering blazing-fast execution speeds while continuously expanding its robust feature set.**

### Compilation Benchmarks

&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/assets/build_benchmark_solady_dark.png&quot; width=&quot;600px&quot;&gt;
    &lt;img src=&quot;.github/assets/build_benchmark_solady_light.png&quot; width=&quot;600px&quot;&gt;
  &lt;/picture&gt;

&lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/assets/build_benchmark_openzeppelin_dark.png&quot; width=&quot;600px&quot;&gt;
    &lt;img src=&quot;.github/assets/build_benchmark_openzeppelin_light.png&quot; width=&quot;600px&quot;&gt;
  &lt;/picture&gt;

&amp;nbsp;

&lt;/div&gt;

**Takeaway: Forge compilation is consistently faster than Hardhat by a factor of `2.1x` to `5.2x`, depending on the amount of caching involved.**

## Forge

Forge helps you build, test, fuzz, debug and deploy Solidity contracts.

The best way to understand Forge is to simply try it (in less than 30 seconds!).

First, let&#039;s initialize a new `counter` example repository:

```sh
forge init counter
```

Next `cd` into `counter` and build :

```sh
forge build
```

```console
[‚†ä] Compiling...
[‚†î] Compiling 27 files with Solc 0.8.28
[‚†í] Solc 0.8.28 finished in 452.13ms
Compiler run successful!
```

Let&#039;s [test](https://getfoundry.sh/forge/tests#tests) our contracts:

```sh
forge test
```

```console
[‚†ä] Compiling...
No files changed, compilation skipped

Ran 2 tests for test/Counter.t.sol:CounterTest
[PASS] testFuzz_SetNumber(uint256) (runs: 256, Œº: 31121, ~: 31277)
[PASS] test_Increment() (gas: 31293)
Suite result: ok. 2 passed; 0 failed; 0 skipped; finished in 5.35ms (4.86ms CPU time)

Ran 1 test suite in 5.91ms (5.35ms CPU time): 2 tests passed, 0 failed, 0 skipped (2 total tests)
```

Finally, let&#039;s run our deployment script:

```sh
forge script script/Counter.s.sol
```

```console
[‚†ä] Compiling...
No files changed, compilation skipped
Script ran successfully.
Gas used: 109037

If you wish to simulate on-chain transactions pass a RPC URL.
```

Run `forge --help` to explore the full list of available subcommands and their usage.

More documentation can be found in the [forge](https://getfoundry.sh/forge/overview) section of the Foundry Docs.

## Cast

Cast is a Swiss Army knife for interacting with Ethereum applications from the command line.

Here are a few examples of what you can do:

**Check the latest block on Ethereum Mainnet**:

```sh
cast block-number --rpc-url https://eth.merkle.io
```

**Check the Ether balance of `vitalik.eth`**

```sh
cast balance vitalik.eth --ether --rpc-url https://eth.merkle.io
```

**Replay and trace a transaction**

```sh
cast run 0x9c32042f5e997e27e67f82583839548eb19dc78c4769ad6218657c17f2a5ed31 --rpc-url https://eth.merkle.io
```

Optionally, pass `--etherscan-api-key &lt;API_KEY&gt;` to decode transaction traces using verified source maps, providing more detailed and human-readable information.

---

Run `cast --help` to explore the full list of available subcommands and their usage.

More documentation can be found in the [cast](https://getfoundry.sh/cast/overview) section of the Foundry Docs.

## Anvil

Anvil is a fast local Ethereum development node.

Let&#039;s fork Ethereum mainnet at the latest block:

```sh
anvil --fork-url https://eth.merkle.io
```

You can use those same `cast` subcommands against your `anvil` instance:

```sh
cast block-number
```

---

Run `anvil --help` to explore the full list of available features and their usage.

More documentation can be found in the [anvil](https://getfoundry.sh/anvil/overview) section of the Foundry Docs.

## Chisel

Chisel is a fast, utilitarian, and verbose Solidity REPL.

To use Chisel, simply type `chisel`.

```sh
chisel
```

From here, start writing Solidity code! Chisel will offer verbose feedback on each input.

Create a variable `a` and query it:

```console
‚ûú uint256 a = 123;
‚ûú a
Type: uint256
‚îú Hex: 0x7b
‚îú Hex (full word): 0x000000000000000000000000000000000000000000000000000000000000007b
‚îî Decimal: 123
```

Finally, run `!source` to see `a` was applied:

```solidity
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.28;

import {Vm} from &quot;forge-std/Vm.sol&quot;;

contract REPL {
    Vm internal constant vm = Vm(address(uint160(uint256(keccak256(&quot;hevm cheat code&quot;)))));

    /// @notice REPL contract entry point
    function run() public {
        uint256 a = 123;
    }
}
```

---

Run `chisel --help` to explore the full list of available features and their usage.

More documentation can be found in the [chisel](https://getfoundry.sh/chisel/overview) section of the Foundry Docs.

## Configuration

Foundry is highly configurable, allowing you to tailor it to your needs. Configuration is managed via a file called [`foundry.toml`](./crates/config) located in the root of your project or any parent directory. For a full list of configuration options, refer to the [config package documentation](./crates/config/README.md#all-options).

**Profiles and Namespaces**

- Configuration can be organized into **profiles**, which are arbitrarily namespaced for flexibility.
- The default profile is named `default`. Learn more in the [Default Profile section](./crates/config/README.md#default-profile).
- To select a different profile, set the `FOUNDRY_PROFILE` environment variable.
- Override specific settings using environment variables prefixed with `FOUNDRY_` (e.g., `FOUNDRY_SRC`).

---

You can find additional [setup and configurations guides](https://getfoundry.sh/config/overview) in the [Foundry Docs][foundry-docs] and in the [config crate](./crates/config/README.md):

- [Configuring with `foundry.toml`](https://getfoundry.sh/config/overview)
- [Setting up VSCode][vscode-setup]
- [Shell autocompletions][shell-setup]

## Contributing

See our [contributing guidelines](./CONTRIBUTING.md).

## Getting Help

First, see if the answer to your question can be found in the [Foundy Docs][foundry-docs], or in the relevant crate.

If the answer is not there:

- Join the [support Telegram][tg-support-url] to get help, or
- Open a [discussion](https://github.com/foundry-rs/foundry/discussions/new) with your question, or
- Open an issue with [the bug](https://github.com/foundry-rs/foundry/issues/new)

If you want to contribute, or follow along with contributor discussion, you can use our [main telegram](https://t.me/foundry_rs) to chat with us about the development of Foundry!

## License

Licensed under either of [Apache License](./LICENSE-APACHE), Version
2.0 or [MIT License](./LICENSE-MIT) at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in these crates by you, as defined in the Apache-2.0 license,
shall be dual licensed as above, without any additional terms or conditions.

## Acknowledgements

- Foundry is a clean-room rewrite of the testing framework [DappTools][dapptools]. None of this would have been possible without the DappHub team&#039;s work over the years.
- [Matthias Seitz](https://twitter.com/mattsse_): Created [ethers-solc] (now [foundry-compilers]) which is the backbone of our compilation pipeline, as well as countless contributions to ethers, in particular the `abigen` macros.
- [Rohit Narurkar](https://twitter.com/rohitnarurkar): Created the Rust Solidity version manager [svm-rs](https://github.com/roynalnaruto/svm-rs) which we use to auto-detect and manage multiple Solidity versions.
- [Brock Elmore](https://twitter.com/brockjelmore): For extending the VM&#039;s cheatcodes and implementing [structured call tracing](https://github.com/foundry-rs/foundry/pull/192), a critical feature for debugging smart contract calls.
- All the other [contributors](https://github.com/foundry-rs/foundry/graphs/contributors) to the [ethers-rs](https://github.com/gakonst/ethers-rs), [alloy][alloy] &amp; [foundry](https://github.com/foundry-rs/foundry) repositories and chatrooms.

[solidity]: https://soliditylang.org/
[foundry-docs]: https://getfoundry.sh
[foundry-gha]: https://github.com/foundry-rs/foundry-toolchain
[foundry-compilers]: https://github.com/foundry-rs/compilers
[ethers-solc]: https://github.com/gakonst/ethers-rs/tree/master/ethers-solc/
[solady]: https://github.com/Vectorized/solady
[openzeppelin]: https://github.com/OpenZeppelin/openzeppelin-contracts/tree/release-v5.1
[morpho-blue]: https://github.com/morpho-org/morpho-blue
[foundry-compilers]: https://github.com/foundry-rs/compilers
[solmate]: https://github.com/transmissions11/solmate/
[geb]: https://github.com/reflexer-labs/geb
[benchmark-post]: https://www.paradigm.xyz/2022/03/foundry-02#blazing-fast-compilation--testing
[convex]: https://github.com/mds1/convex-shutdown-simulation
[vscode-setup]: https://getfoundry.sh/config/vscode.html
[shell-setup]: https://getfoundry.sh/config/shell-autocompletion.html
[foundry-0.2]: https://github.com/foundry-rs/foundry/releases/tag/nightly-5b7e4cb3c882b28f3c32ba580de27ce7381f415a
[foundry-1.0]: https://github.com/foundry-rs/foundry/releases/tag/nightly-59f354c179f4e7f6d7292acb3d068815c79286d1
[dapptools]: https://github.com/dapphub/dapptools
[alloy]: https://github.com/alloy-rs/alloy
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BoundaryML/baml]]></title>
            <link>https://github.com/BoundaryML/baml</link>
            <guid>https://github.com/BoundaryML/baml</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[The AI framework that adds the engineering to prompt engineering (Python/TS/Ruby/Java/C#/Rust/Go compatible)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BoundaryML/baml">BoundaryML/baml</a></h1>
            <p>The AI framework that adds the engineering to prompt engineering (Python/TS/Ruby/Java/C#/Rust/Go compatible)</p>
            <p>Language: Rust</p>
            <p>Stars: 4,473</p>
            <p>Forks: 196</p>
            <p>Stars today: 45 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://boundaryml.com?utm_source=github&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;fern/assets/baml-lamb-white.png&quot;&gt;
    &lt;img src=&quot;fern/assets/baml-lamb-white.png&quot; height=&quot;64&quot; id=&quot;top&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![BAML Version](https://img.shields.io/pypi/v/baml-py?color=006dad&amp;label=BAML%20Version)](https://pypi.org/project/baml-py/)


## BAML: Basically a Made-up Language
&lt;h4&gt;

[Homepage](https://www.boundaryml.com/) | [Docs](https://docs.boundaryml.com) | [BAML AI Chat](https://www.boundaryml.com/chat) | [Discord](https://discord.gg/BTNBeXGuaS)



&lt;/h4&gt;


&lt;/div&gt;

BAML is a simple prompting language for building reliable **AI workflows and agents**.

BAML makes prompt engineering easy by turning it into _schema engineering_ -- where you mostly focus on the models of your prompt -- to get more reliable outputs. 
You don&#039;t need to write your whole app in BAML, only the prompts! You can wire-up your LLM Functions in any language of your choice! See our quickstarts for [Python](https://docs.boundaryml.com/guide/installation-language/python), [TypeScript](https://docs.boundaryml.com/guide/installation-language/typescript), [Ruby](https://docs.boundaryml.com/guide/installation-language/ruby) and [Go, and more](https://docs.boundaryml.com/guide/installation-language/rest-api-other-languages).

BAML comes with all batteries included -- with full typesafety, streaming, retries, wide model support, even when they don&#039;t support native [tool-calling APIs](#enable-reliable-tool-calling-with-any-model-even-when-they-dont-support-it)

**Try BAML**: [Prompt Fiddle](https://www.promptfiddle.com) ‚Ä¢ [Interactive App Examples](https://baml-examples.vercel.app/)


## The core BAML principle: LLM Prompts are functions

The fundamental building block in BAML is a function. Every prompt is a function that takes in parameters and returns a type.

```rust
function ChatAgent(message: Message[], tone: &quot;happy&quot; | &quot;sad&quot;) -&gt; string
```

Every function additionally defines which models it uses and what its prompt is.

```rust
function ChatAgent(message: Message[], tone: &quot;happy&quot; | &quot;sad&quot;) -&gt; StopTool | ReplyTool {
    client &quot;openai/gpt-4o-mini&quot;

    prompt #&quot;
        Be a {{ tone }} bot.

        {{ ctx.output_format }}

        {% for m in message %}
        {{ _.role(m.role) }}
        {{ m.content }}
        {% endfor %}
    &quot;#
}

class Message {
    role string
    content string
}

class ReplyTool {
  response string
}

class StopTool {
  action &quot;stop&quot; @description(#&quot;
    when it might be a good time to end the conversation
  &quot;#)
}
```

## BAML Functions can be called from any language
Below we call the ChatAgent function we defined in BAML through Python. BAML&#039;s Rust compiler generates a &quot;baml_client&quot; to access and call them.

```python
from baml_client import b
from baml_client.types import Message, StopTool

messages = [Message(role=&quot;assistant&quot;, content=&quot;How can I help?&quot;)]

while True:
  print(messages[-1].content)
  user_reply = input()
  messages.append(Message(role=&quot;user&quot;, content=user_reply))
  tool = b.ChatAgent(messages, &quot;happy&quot;)
  if isinstance(tool, StopTool):
    print(&quot;Goodbye!&quot;)
    break
  else:
    messages.append(Message(role=&quot;assistant&quot;, content=tool.response))
```
You can write any kind of agent or workflow using chained BAML functions. An agent is a while loop that calls a Chat BAML Function with some state.

And if you need to stream, add a couple more lines:
```python
stream = b.stream.ChatAgent(messages, &quot;happy&quot;)
# partial is a Partial type with all Optional fields
for tool in stream:
    if isinstance(tool, StopTool):
      ...
    
final = stream.get_final_response()
```
And get fully type-safe outputs for each chunk in the stream.

## Test prompts 10x faster, right in your IDE
BAML comes with native tooling for VSCode (jetbrains + neovim coming soon). 

**Visualize full prompt (including any multi-modal assets), and the API request**. BAML gives you full transparency and control of the prompt.

![raw-curl](https://github.com/user-attachments/assets/c0b34db9-80cd-45a7-a356-6b5ab4a9c5b7)

**Using AI is all about iteration speed.**

If testing your pipeline takes 2 minutes, you can only test 10 ideas in 20 minutes.

If you reduce it to 5 seconds, you can test 240 ideas in the same amount of time.
![resume-attempt2-smaller2](https://github.com/user-attachments/assets/6fc6b8a6-ffed-4cfc-80b8-78bc8a3d66a6)

The playground also allows you to run tests in parallel -- for even faster iteration speeds üöÄ.

No need to login to websites, and no need to manually define json schemas.

## Enable reliable tool-calling with any model
BAML works even when the models don&#039;t support native tool-calling APIs. We created the SAP (schema-aligned parsing) algorithm to support the flexible outputs LLMs can provide, like markdown within a JSON blob or chain-of-thought prior to answering. [Read more about SAP](https://www.boundaryml.com/blog/schema-aligned-parsing)

With BAML, your structured outputs work in Day-1 of a model release. No need to figure out whether a model supports parallel tool calls, or whether it supports recursive schemas, or `anyOf` or `oneOf` etc.

See it in action with: **[Deepseek-R1](https://www.boundaryml.com/blog/deepseek-r1-function-calling)** and [OpenAI O1](https://www.boundaryml.com/blog/openai-o1).



## Switch from 100s of models in a couple lines
```diff
function Extract() -&gt; Resume {
+  client openai/o3-mini
  prompt #&quot;
    ....
  &quot;#
}
```
[Retry policies](https://docs.boundaryml.com/ref/llm-client-strategies/retry-policy) ‚Ä¢ [fallbacks](https://docs.boundaryml.com/ref/llm-client-strategies/fallback) ‚Ä¢ [model rotations](https://docs.boundaryml.com/ref/llm-client-strategies/round-robin). All statically defined.
![Fallback Retry](https://www.boundaryml.com/blog/2025-01-24-ai-agents-need-a-new-syntax/06-fallback-retry.gif)
Want to do pick models at runtime? Check out the [Client Registry](https://docs.boundaryml.com/guide/baml-advanced/llm-client-registry).

We support: [OpenAI](https://docs.boundaryml.com/ref/llm-client-providers/open-ai) ‚Ä¢ [Anthropic](https://docs.boundaryml.com/ref/llm-client-providers/anthropic) ‚Ä¢ [Gemini](https://docs.boundaryml.com/ref/llm-client-providers/google-ai-gemini) ‚Ä¢ [Vertex](https://docs.boundaryml.com/ref/llm-client-providers/google-vertex) ‚Ä¢ [Bedrock](https://docs.boundaryml.com/ref/llm-client-providers/aws-bedrock) ‚Ä¢ [Azure OpenAI](https://docs.boundaryml.com/ref/llm-client-providers/open-ai-from-azure) ‚Ä¢ [Anything OpenAI Compatible](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic) ([Ollama](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-ollama), [OpenRouter](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-open-router), [VLLM](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-v-llm), [LMStudio](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-lm-studio), [TogetherAI](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-together-ai), and more)

## Build beautiful streaming UIs
BAML generates a ton of utilities for NextJS, Python (and any language) to make streaming UIs easy.
![recipe-generator](https://github.com/user-attachments/assets/cf82495b-21fc-40bf-ae98-93eef923d620)

BAML&#039;s streaming interfaces are fully type-safe. Check out the [Streaming Docs](https://docs.boundaryml.com/guide/baml-basics/streaming), and our [React hooks](https://docs.boundaryml.com/guide/framework-integration/react-next-js/quick-start)

## Fully Open-Source, and offline
- 100% open-source (Apache 2)
- 100% private. AGI will not require an internet connection, neither will BAML
    - No network requests beyond model calls you explicitly set
    - Not stored or used for any training data
- BAML files can be saved locally on your machine and checked into Github for easy diffs.
- Built in Rust. So fast, you can&#039;t even tell it&#039;s there.

## BAML&#039;s Design Philosophy

Everything is fair game when making new syntax. If you can code it, it can be yours. This is our design philosophy to help restrict ideas:

- **1:** Avoid invention when possible
    - Yes, prompts need versioning ‚Äî we have a great versioning tool: git
    - Yes, you need to save prompts ‚Äî we have a great storage tool: filesystems
- **2:** Any file editor and any terminal should be enough to use it
- **3:** Be fast
- **4:** A first year university student should be able to understand it

## Why a new programming language

We used to write websites like this:

```python
def home():
    return &quot;&lt;button onclick=\&quot;() =&gt; alert(\\\&quot;hello!\\\&quot;)\&quot;&gt;Click&lt;/button&gt;&quot;
```

And now we do this:

```jsx
function Home() {
  return &lt;button onClick={() =&gt; setCount(prev =&gt; prev + 1)}&gt;
          {count} clicks!
         &lt;/button&gt;
}
```

New syntax can be incredible at expressing new ideas. Plus the idea of maintaining hundreds of f-strings for prompts kind of disgusts us ü§Æ. Strings are bad for maintainable codebases. We prefer structured strings.

The goal of BAML is to give you the expressiveness of English, but the structure of code.

Full [blog post](https://www.boundaryml.com/blog/ai-agents-need-new-syntax) by us.


## Conclusion

As models get better, we&#039;ll continue expecting even more out of them. But what will never change is that we&#039;ll want a way to write maintainable code that uses those models. The current way we all just assemble strings is very reminiscent of the early days PHP/HTML soup in web development. We hope some of the ideas we shared today can make a tiny dent in helping us all shape the way we all code tomorrow.

## FAQ
|   |   |
| - | - |
| Do I need to write my whole app in BAML? | Nope, only the prompts! BAML translates definitions into the language of your choice! [Python](https://docs.boundaryml.com/guide/installation-language/python), [TypeScript](https://docs.boundaryml.com/guide/installation-language/typescript), [Ruby](https://docs.boundaryml.com/guide/installation-language/ruby) and [more](https://docs.boundaryml.com/guide/installation-language/rest-api-other-languages). |
| Is BAML stable? | Yes, many companies use it in production! We ship updates weekly! |
| Why a new language? | [Jump to section](#why-a-new-programming-language) |


## Contributing
Checkout our [guide on getting started](/CONTRIBUTING.md)

## Citation

You can cite the BAML repo as follows:
```bibtex
@software{baml,
  author = {Vaibhav Gupta, Aaron Villalpando and Boundary ML team},
  title = {BAML},
  url = {https://github.com/boundaryml/baml},
  year = {2024}
}
```

---

Made with ‚ù§Ô∏è by Boundary

HQ in Seattle, WA

P.S. We&#039;re hiring for software engineers that love rust. [Email us](founders@boundaryml.com) or reach out on [discord](https://discord.gg/ENtBB6kkXH)!

&lt;div align=&quot;left&quot; style=&quot;align-items: left;&quot;&gt;
        &lt;a href=&quot;#top&quot;&gt;
            &lt;img src=&quot;https://img.shields.io/badge/Back%20to%20Top-000000?style=for-the-badge&amp;logo=github&amp;logoColor=white&quot; alt=&quot;Back to Top&quot;&gt;
        &lt;/a&gt;
&lt;/div&gt;

&lt;img src=&quot;https://imgs.xkcd.com/comics/standards.png&quot; alt_text=&quot;hi&quot; /&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[witnessmenow/ESP32-Cheap-Yellow-Display]]></title>
            <link>https://github.com/witnessmenow/ESP32-Cheap-Yellow-Display</link>
            <guid>https://github.com/witnessmenow/ESP32-Cheap-Yellow-Display</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[Building a community around a cheap ESP32 Display with a touch screen]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/witnessmenow/ESP32-Cheap-Yellow-Display">witnessmenow/ESP32-Cheap-Yellow-Display</a></h1>
            <p>Building a community around a cheap ESP32 Display with a touch screen</p>
            <p>Language: Rust</p>
            <p>Stars: 2,775</p>
            <p>Forks: 281</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># ESP32-Cheap-Yellow-Display

There is an ESP32 with a built in 320 x 240 2.8&quot; LCD display with a touch screen called the &quot;ESP32-2432S028R&quot;, since this doesn&#039;t roll of the tongue, I propose it should be renamed the &quot;Cheap Yellow Display&quot; or CYD for short. This display is only about $15 delivered so I think it&#039;s really good value.

![image](https://github.com/witnessmenow/ESP32-Cheap-Yellow-Display/assets/1562562/76c3d481-2523-4b6f-881c-2e29f9368cd0)

## Features

The CYD has the following features:

- ESP32 (With Wifi and Bluetooth)
- 320 x 240 LCD Display (2.8&quot;)
- Touch Screen (Resistive)
- USB for powering and programming
- SD Card Slot, LED and some additional pins broken out

## Who is it good for?

I think it&#039;s useful for the following types of people:

- **People just getting started with working hardware** - as everything is already connected, there is no soldering or additional components required
- **People who are familiar with working with hardware, but are lazy** - (like me) Sometimes you just want to build a project without having to assemble any hardware
- **People who aren&#039;t really looking to learn anything, but just want to build some cool things** - More about this later.

## What is the purpose of this page?

So this is pretty nice hardware and a cheap price, but the software instructions/support around it is pretty poor. Just a single link to a zip file on a random website.

A couple of years ago I released the [ESP32 Trinity](https://github.com/witnessmenow/ESP32-Trinity), which is an open source ESP32 board for controlling Matrix panels. I think the main benefit people get out of the work I did on the Trinty is not the hardware, but the documentation, example code and ready to go projects.

I&#039;m no longer creating hardware products, but I think it would be interesting if we could create the same kind of community around this display, where people can share examples and projects made for this display.

## How do I know if a display is a CYD?
![CYD decision tree](http://www.plantuml.com/plantuml/png/RP0nJyCm48Nt_8gZNIb3fge3LD2b2q92235UamDRE7PaNuhyxxda7DGgJBs-zxtSE-yJO-IXSzKD6-e8UeVMLyQs1DJrdA6br4JRims-4fW9LiS4bY6JS-47qBTWC052QvEayyCAvA-wS-8vi01F7mS8SVevOxJeUK9zu55QzzP_Nw-exxPmz8tHJzRRsJq4cdo3Pu98oIQsCd4O6WDIbyXF4LN-JNMsYG7UNXyXUAUTLHDfqVeMJWClUfSPrY_OOyPtO_ivUPcfnoMV3iyXJh4cj_MGJd8lEleQkvQKi9TYUT_DvbukXnraIfTQURMT39Nu8kcrXInIwQYO-gCyNwgm6al-ZneTNIRqjLokqS2UV3jqxXS0)

## Where to buy?

Buy from wherever works out cheapest for you:

- [Aliexpress\*](https://s.click.aliexpress.com/e/_DkSpIjB)
- [Aliexpress\*](https://s.click.aliexpress.com/e/_DkcmuCh)
- [Aliexpress](https://www.aliexpress.com/item/1005004502250619.html)
- [Makerfabs](https://www.makerfabs.com/sunton-esp32-2-8-inch-tft-with-touch.html) - Seems to come with a 16GB SD card. Makerfabs also stock my [ESP32 Trinity](https://github.com/witnessmenow/ESP32-Trinity) (NOTE there will be import due in the EU from makerfabs)

\* = Affiliate Link

## Getting Started With Your CYD

For details on how to get started with your CYD, please check out the [Setup and Configuration](/SETUP.md) page

## Code Examples

### The Basics

A collection of examples demonstrating how to use the different features of the CYD, this is a good place to get started. [Check them out here.](/Examples/Basics)

### Alternative Display Libraries

The basics examples are based on the TFT_eSPI display library, but the CYD also works with other display libraries too. Here is some example code if you prefer to use an alternative Arduino library. [Check them out here.](/Examples/AlternativeLibraries)

### ESPHome

Some examples for using the CYD in ESPHome. [Check them out here.](/Examples/ESPHome)

## Additional Info and Links

### Discord

Join the CYD discussion on [my Discord channel](https://discord.gg/nnezpvq)

### 3DPrinting

Some examples of 3D printed stands and cases. [Check them out here.](/3dModels)

### Pin Information

[This page](/PINS.md) contains information about what pins are used where, and what ones are free to use.

### Add-ons

[This page](/ADDONS.md) contains information about additional hardware add-ons that can add functionality to your CYD

### Troubleshooting

[This page](/TROUBLESHOOTING.md) contains information about how to troubleshoot your CYD device

### Hardware Mods

[This page](/Mods/README.md) contains information about some hardware mods that can be performed on the CYD to improve or change some of its functionality

### Media and Video Mentions

[This page](/MEDIA.md) lists any times the CYD project was mentioned somewhere!

## License Info

This project is licensed as MIT as per the [license file](/LICENSE)

The one exception to this is the [OriginalDocumentation](/OriginalDocumentation/) folder, that I do not have the right to license

## Other Languages

Some members of the community have ported some of this information to other languages! 

Please note: I can&#039;t gaurantee the accuracy of the translation, how up to date they are or the content on them in general.

- [French / Fran√ßaise](https://github.com/usini/ESP32-Cheap-Yellow-Display-Documentation-FR)
- [German / Deutsch](https://github.com/paelzer/ESP32-Cheap-Yellow-Display-Documentation-DE)

If you would like to contribure a translation, please name the repo with the language name or code in the repo name and you can link it here.

## Help Support what I do!

[If you enjoy my work, please consider becoming a Github sponsor!](https://github.com/sponsors/witnessmenow/)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[huggingface/candle]]></title>
            <link>https://github.com/huggingface/candle</link>
            <guid>https://github.com/huggingface/candle</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Minimalist ML framework for Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/candle">huggingface/candle</a></h1>
            <p>Minimalist ML framework for Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 17,555</p>
            <p>Forks: 1,140</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># candle
[![discord server](https://dcbadge.vercel.app/api/server/hugging-face-879548962464493619)](https://discord.gg/hugging-face-879548962464493619)
[![Latest version](https://img.shields.io/crates/v/candle-core.svg)](https://crates.io/crates/candle-core)
[![Documentation](https://docs.rs/candle-core/badge.svg)](https://docs.rs/candle-core)
[![License](https://img.shields.io/github/license/base-org/node?color=blue)](https://github.com/huggingface/candle/blob/main/LICENSE-MIT)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square)](https://github.com/huggingface/candle/blob/main/LICENSE-APACHE)

Candle is a minimalist ML framework for Rust with a focus on performance (including GPU support) 
and ease of use. Try our online demos: 
[whisper](https://huggingface.co/spaces/lmz/candle-whisper),
[LLaMA2](https://huggingface.co/spaces/lmz/candle-llama2),
[T5](https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm),
[yolo](https://huggingface.co/spaces/lmz/candle-yolo),
[Segment
Anything](https://huggingface.co/spaces/radames/candle-segment-anything-wasm).

## Get started

Make sure that you have [`candle-core`](https://github.com/huggingface/candle/tree/main/candle-core) correctly installed as described in [**Installation**](https://huggingface.github.io/candle/guide/installation.html).

Let&#039;s see how to run a simple matrix multiplication.
Write the following to your `myapp/src/main.rs` file:
```rust
use candle_core::{Device, Tensor};

fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let device = Device::Cpu;

    let a = Tensor::randn(0f32, 1., (2, 3), &amp;device)?;
    let b = Tensor::randn(0f32, 1., (3, 4), &amp;device)?;

    let c = a.matmul(&amp;b)?;
    println!(&quot;{c}&quot;);
    Ok(())
}
```

`cargo run` should display a tensor of shape `Tensor[[2, 4], f32]`.


Having installed `candle` with Cuda support, simply define the `device` to be on GPU:

```diff
- let device = Device::Cpu;
+ let device = Device::new_cuda(0)?;
```

For more advanced examples, please have a look at the following section.

## Check out our examples

These online demos run entirely in your browser:
- [yolo](https://huggingface.co/spaces/lmz/candle-yolo): pose estimation and
  object recognition.
- [whisper](https://huggingface.co/spaces/lmz/candle-whisper): speech recognition.
- [LLaMA2](https://huggingface.co/spaces/lmz/candle-llama2): text generation.
- [T5](https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm): text generation.
- [Phi-1.5, and Phi-2](https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm): text generation.
- [Segment Anything Model](https://huggingface.co/spaces/radames/candle-segment-anything-wasm): Image segmentation.
- [BLIP](https://huggingface.co/spaces/radames/Candle-BLIP-Image-Captioning): image captioning.

We also provide some command line based examples using state of the art models:

- [LLaMA v1, v2, and v3](./candle-examples/examples/llama/): general LLM, includes
  the SOLAR-10.7B variant.
- [Falcon](./candle-examples/examples/falcon/): general LLM.
- [Codegeex4](./candle-examples/examples/codegeex4-9b/): Code completion, code interpreter, web search, function calling, repository-level
- [GLM4](./candle-examples/examples/glm4/): Open Multilingual Multimodal Chat LMs by THUDM
- [Gemma v1 and v2](./candle-examples/examples/gemma/): 2b and 7b+/9b general LLMs from Google Deepmind.
- [RecurrentGemma](./candle-examples/examples/recurrent-gemma/): 2b and 7b
  Griffin based models from Google that mix attention with a RNN like state.
- [Phi-1, Phi-1.5, Phi-2, and Phi-3](./candle-examples/examples/phi/): 1.3b,
  2.7b, and 3.8b general LLMs with performance on par with 7b models.
- [StableLM-3B-4E1T](./candle-examples/examples/stable-lm/): a 3b general LLM
  pre-trained on 1T tokens of English and code datasets. Also supports
  StableLM-2, a 1.6b LLM trained on 2T tokens, as well as the code variants.
- [Mamba](./candle-examples/examples/mamba/): an inference only
  implementation of the Mamba state space model.
- [Mistral7b-v0.1](./candle-examples/examples/mistral/): a 7b general LLM with
  better performance than all publicly available 13b models as of 2023-09-28.
- [Mixtral8x7b-v0.1](./candle-examples/examples/mixtral/): a sparse mixture of
  experts 8x7b general LLM with better performance than a Llama 2 70B model with
  much faster inference.
- [StarCoder](./candle-examples/examples/bigcode/) and
  [StarCoder2](./candle-examples/examples/starcoder2/): LLM specialized to code generation.
- [Qwen1.5](./candle-examples/examples/qwen/): Bilingual (English/Chinese) LLMs.
- [RWKV v5 and v6](./candle-examples/examples/rwkv/): An RNN with transformer level LLM
  performance.
- [Replit-code-v1.5](./candle-examples/examples/replit-code/): a 3.3b LLM specialized for code completion.
- [Yi-6B / Yi-34B](./candle-examples/examples/yi/): two bilingual
  (English/Chinese) general LLMs with 6b and 34b parameters.
- [Quantized LLaMA](./candle-examples/examples/quantized/): quantized version of
  the LLaMA model using the same quantization techniques as
  [llama.cpp](https://github.com/ggerganov/llama.cpp).

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/quantized/assets/aoc.gif&quot; width=&quot;600&quot;&gt;
  
- [Stable Diffusion](./candle-examples/examples/stable-diffusion/): text to
  image generative model, support for the 1.5, 2.1, SDXL 1.0 and Turbo versions.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/stable-diffusion/assets/stable-diffusion-xl.jpg&quot; width=&quot;200&quot;&gt;

- [Wuerstchen](./candle-examples/examples/wuerstchen/): another text to
  image generative model.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/wuerstchen/assets/cat.jpg&quot; width=&quot;200&quot;&gt;

- [yolo-v3](./candle-examples/examples/yolo-v3/) and
  [yolo-v8](./candle-examples/examples/yolo-v8/): object detection and pose
  estimation models.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.od.jpg&quot; width=&quot;200&quot;&gt;&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.pose.jpg&quot; width=&quot;200&quot;&gt;
- [segment-anything](./candle-examples/examples/segment-anything/): image
  segmentation model with prompt.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/segment-anything/assets/sam_merged.jpg&quot; width=&quot;200&quot;&gt;

- [SegFormer](./candle-examples/examples/segformer/): transformer based semantic segmentation model.
- [Whisper](./candle-examples/examples/whisper/): speech recognition model.
- [EnCodec](./candle-examples/examples/encodec/): high-quality audio compression
  model using residual vector quantization.
- [MetaVoice](./candle-examples/examples/metavoice/): foundational model for
  text-to-speech.
- [Parler-TTS](./candle-examples/examples/parler-tts/): large text-to-speech
  model.
- [T5](./candle-examples/examples/t5), [Bert](./candle-examples/examples/bert/),
  [JinaBert](./candle-examples/examples/jina-bert/) : useful for sentence embeddings.
- [DINOv2](./candle-examples/examples/dinov2/): computer vision model trained
  using self-supervision (can be used for imagenet classification, depth
  evaluation, segmentation).
- [VGG](./candle-examples/examples/vgg/),
  [RepVGG](./candle-examples/examples/repvgg): computer vision models.
- [BLIP](./candle-examples/examples/blip/): image to text model, can be used to
  generate captions for an image.
- [CLIP](./candle-examples/examples/clip/): multi-model vision and language
  model.
- [TrOCR](./candle-examples/examples/trocr/): a transformer OCR model, with
  dedicated submodels for hand-writing and printed recognition.
- [Marian-MT](./candle-examples/examples/marian-mt/): neural machine translation
  model, generates the translated text from the input text.
- [Moondream](./candle-examples/examples/moondream/): tiny computer-vision model 
  that can answer real-world questions about images.

Run them using commands like:
```
cargo run --example quantized --release
```

In order to use **CUDA** add `--features cuda` to the example command line. If
you have cuDNN installed, use `--features cudnn` for even more speedups.

There are also some wasm examples for whisper and
[llama2.c](https://github.com/karpathy/llama2.c). You can either build them with
`trunk` or try them online:
[whisper](https://huggingface.co/spaces/lmz/candle-whisper),
[llama2](https://huggingface.co/spaces/lmz/candle-llama2),
[T5](https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm),
[Phi-1.5, and Phi-2](https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm),
[Segment Anything Model](https://huggingface.co/spaces/radames/candle-segment-anything-wasm).

For LLaMA2, run the following command to retrieve the weight files and start a
test server:
```bash
cd candle-wasm-examples/llama2-c
wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/model.bin
wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/tokenizer.json
trunk serve --release --port 8081
```
And then head over to
[http://localhost:8081/](http://localhost:8081/).

&lt;!--- ANCHOR: useful_libraries ---&gt;

## Useful External Resources
- [`candle-tutorial`](https://github.com/ToluClassics/candle-tutorial): A
  very detailed tutorial showing how to convert a PyTorch model to Candle.
- [`candle-lora`](https://github.com/EricLBuehler/candle-lora): Efficient and
  ergonomic LoRA implementation for Candle. `candle-lora` has      
  out-of-the-box LoRA support for many models from Candle, which can be found
  [here](https://github.com/EricLBuehler/candle-lora/tree/master/candle-lora-transformers/examples).
- [`optimisers`](https://github.com/KGrewal1/optimisers): A collection of optimisers
  including SGD with momentum, AdaGrad, AdaDelta, AdaMax, NAdam, RAdam, and RMSprop.
- [`candle-vllm`](https://github.com/EricLBuehler/candle-vllm): Efficient platform for inference and
  serving local LLMs including an OpenAI compatible API server.
- [`candle-ext`](https://github.com/mokeyish/candle-ext): An extension library to Candle that provides PyTorch functions not currently available in Candle.
- [`candle-coursera-ml`](https://github.com/vishpat/candle-coursera-ml): Implementation of ML algorithms from Coursera&#039;s [Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction) course.
- [`kalosm`](https://github.com/floneum/floneum/tree/master/interfaces/kalosm): A multi-modal meta-framework in Rust for interfacing with local pre-trained models with support for controlled generation, custom samplers, in-memory vector databases, audio transcription, and more.
- [`candle-sampling`](https://github.com/EricLBuehler/candle-sampling): Sampling techniques for Candle.
- [`gpt-from-scratch-rs`](https://github.com/jeroenvlek/gpt-from-scratch-rs): A port of Andrej Karpathy&#039;s _Let&#039;s build GPT_ tutorial on YouTube showcasing the Candle API on a toy problem.
- [`candle-einops`](https://github.com/tomsanbear/candle-einops): A pure rust implementation of the python [einops](https://github.com/arogozhnikov/einops) library.
- [`atoma-infer`](https://github.com/atoma-network/atoma-infer): A Rust library for fast inference at scale, leveraging FlashAttention2 for efficient attention computation, PagedAttention for efficient KV-cache memory management, and multi-GPU support. It is OpenAI api compatible.
- [`llms-from-scratch-rs`](https://github.com/nerdai/llms-from-scratch-rs): A comprehensive Rust translation of the code from Sebastian Raschka&#039;s Build an LLM from Scratch book.

If you have an addition to this list, please submit a pull request.

&lt;!--- ANCHOR_END: useful_libraries ---&gt;

&lt;!--- ANCHOR: features ---&gt;

## Features

- Simple syntax, looks and feels like PyTorch.
    - Model training.
    - Embed user-defined ops/kernels, such as [flash-attention v2](https://github.com/huggingface/candle/blob/89ba005962495f2bfbda286e185e9c3c7f5300a3/candle-flash-attn/src/lib.rs#L152).
- Backends.
    - Optimized CPU backend with optional MKL support for x86 and Accelerate for macs.
    - CUDA backend for efficiently running on GPUs, multiple GPU distribution via NCCL.
    - WASM support, run your models in a browser.
- Included models.
    - Language Models.
        - LLaMA v1, v2, and v3 with variants such as SOLAR-10.7B.
        - Falcon.
        - StarCoder, StarCoder2.
        - Phi 1, 1.5, 2, and 3.
        - Mamba, Minimal Mamba
        - Gemma v1 2b and 7b+, v2 2b and 9b.
        - Mistral 7b v0.1.
        - Mixtral 8x7b v0.1.
        - StableLM-3B-4E1T, StableLM-2-1.6B, Stable-Code-3B.
        - Replit-code-v1.5-3B.
        - Bert.
        - Yi-6B and Yi-34B.
        - Qwen1.5, Qwen1.5 MoE.
        - RWKV v5 and v6.
    - Quantized LLMs.
        - Llama 7b, 13b, 70b, as well as the chat and code variants.
        - Mistral 7b, and 7b instruct.
        - Mixtral 8x7b.
        - Zephyr 7b a and b (Mistral-7b based).
        - OpenChat 3.5 (Mistral-7b based).
    - Text to text.
        - T5 and its variants: FlanT5, UL2, MADLAD400 (translation), CoEdit (Grammar correction).
        - Marian MT (Machine Translation).
    - Text to image.
        - Stable Diffusion v1.5, v2.1, XL v1.0.
        - Wurstchen v2.
    - Image to text.
        - BLIP.
        - TrOCR.
    - Audio.
        - Whisper, multi-lingual speech-to-text.
        - EnCodec, audio compression model.
        - MetaVoice-1B, text-to-speech model.
        - Parler-TTS, text-to-speech model.
    - Computer Vision Models.
        - DINOv2, ConvMixer, EfficientNet, ResNet, ViT, VGG, RepVGG, ConvNeXT,
          ConvNeXTv2, MobileOne, EfficientVit (MSRA), MobileNetv4, Hiera, FastViT.
        - yolo-v3, yolo-v8.
        - Segment-Anything Model (SAM).
        - SegFormer.
- File formats: load models from safetensors, npz, ggml, or PyTorch files.
- Serverless (on CPU), small and fast deployments.
- Quantization support using the llama.cpp quantized types.

&lt;!--- ANCHOR_END: features ---&gt;

## How to use

&lt;!--- ANCHOR: cheatsheet ---&gt;
Cheatsheet:

|            | Using PyTorch                            | Using Candle                                                     |
|------------|------------------------------------------|------------------------------------------------------------------|
| Creation   | `torch.Tensor([[1, 2], [3, 4]])`         | `Tensor::new(&amp;[[1f32, 2.], [3., 4.]], &amp;Device::Cpu)?`           |
| Creation   | `torch.zeros((2, 2))`                    | `Tensor::zeros((2, 2), DType::F32, &amp;Device::Cpu)?`               |
| Indexing   | `tensor[:, :4]`                          | `tensor.i((.., ..4))?`                                           |
| Operations | `tensor.view((2, 2))`                    | `tensor.reshape((2, 2))?`                                        |
| Operations | `a.matmul(b)`                            | `a.matmul(&amp;b)?`                                                  |
| Arithmetic | `a + b`                                  | `&amp;a + &amp;b`                                                        |
| Device     | `tensor.to(device=&quot;cuda&quot;)`               | `tensor.to_device(&amp;Device::new_cuda(0)?)?`                            |
| Dtype      | `tensor.to(dtype=torch.float16)`         | `tensor.to_dtype(&amp;DType::F16)?`                                  |
| Saving     | `torch.save({&quot;A&quot;: A}, &quot;model.bin&quot;)`      | `candle::safetensors::save(&amp;HashMap::from([(&quot;A&quot;, A)]), &quot;model.safetensors&quot;)?` |
| Loading    | `weights = torch.load(&quot;model.bin&quot;)`      | `candle::safetensors::load(&quot;model.safetensors&quot;, &amp;device)`        |

&lt;!--- ANCHOR_END: cheatsheet ---&gt;


## Structure

- [candle-core](./candle-core): Core ops, devices, and `Tensor` struct definition
- [candle-nn](./candle-nn/): Tools to build real models
- [candle-examples](./candle-examples/): Examples of using the library in realistic settings
- [candle-kernels](./candle-kernels/): CUDA custom kernels
- [candle-datasets](./candle-datasets/): Datasets and data loaders.
- [candle-transformers](./candle-transformers): transformers-related utilities.
- [candle-flash-attn](./candle-flash-attn): Flash attention v2 layer.
- [candle-onnx](./candle-onnx/): ONNX model evaluation.

## FAQ

### Why should I use Candle?

&lt;!--- ANCHOR: goals ---&gt;

Candle&#039;s core goal is to *make serverless inference possible*. Full machine learning frameworks like PyTorch
are very large, which makes creating instances on a cluster slow. Candle allows deployment of lightweight
binaries.

Secondly, Candle lets you *remove Python* from production workloads. Python overhead can seriously hurt performance,
and the [GIL](https://www.backblaze.com/blog/the-python-gil-past-present-and-future/) is a notorious source of headaches.

Finally, Rust is cool! A lot of the HF ecosystem already has Rust crates, like [safetensors](https://github.com/huggingface/safetensors) and [tokenizers](https://github.com/huggingface/tokenizers).

&lt;!--- ANCHOR_END: goals ---&gt;

### Other ML frameworks

- [dfdx](https://github.com/coreylowman/dfdx) is a formidable crate, with shapes being included
  in types. This prevents a lot of headaches by getting the compiler to complain about shape mismatches right off the bat.
  However, we found that some features still require nightly, and writing code can be a bit daunting for non rust experts.

  We&#039;re leveraging and contributing to other core crates for the runtime so hopefully both crates can benefit from each
  other.

- [burn](https://github.com/burn-rs/burn) is a general crate that can leverage multiple backends so you can choose the best
  engine for your workload.

- [tch-rs](https://github.com/LaurentMazare/tch-rs.git) Bindings to the torch library in Rust. Extremely versatile, but they 
  bring in the entire torch library into the runtime. The main contributor of `tch-rs` is also involved in the development
  of `candle`.

### Common Errors

#### Missing symbols when compiling with the mkl feature.

If you get some missing symbols when compiling binaries/tests using the mkl
or accelerate features, e.g. for mkl you get:
```
  = note: /usr/bin/ld: (....o): in function `blas::sgemm&#039;:
          .../blas-0.22.0/src/lib.rs:1944: undefined reference to `sgemm_&#039; collect2: error: ld returned 1 exit status

  = note: some `extern` functions couldn&#039;t be found; some native libraries may need to be installed or have their path specified
  = note: use the `-l` flag to specify native libraries to link
  = note: use the `cargo:rustc-link-lib` directive to specify the native libraries to link with Cargo
```
or for accelerate:
```
Undefined symbols for architecture arm64:
            &quot;_dgemm_&quot;, referenced from:
                candle_core::accelerate::dgemm::h1b71a038552bcabe in libcandle_core...
            &quot;_sgemm_&quot;, referenced from:
                candle_core::accelerate::sgemm::h2cf21c592cba3c47 in libcandle_core...
          ld: symbol(s) not found for architecture arm64
```

This is likely due to a missing linker flag that was needed to enable the mkl library. You
can try adding the following for mkl at the top of your binary:
```rust
extern crate intel_mkl_src;
```
or for accelerate:
```rust
extern crate accelerate_src;
```

#### Cannot run the LLaMA examples: access to source requires login credentials

```
Error: request error: https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/tokenizer.json: status code 401
```

This is likely because you&#039;re not permissioned for the LLaMA-v2 model. To fix
this, you have to register on the huggingface-hub, accept the [LLaMA-v2 model
conditions](https://huggingface.co/meta-llama/Llama-2-7b-hf), and set up your
authentication token. See issue
[#350](https://github.com/huggingface/candle/issues/350) for more details.

#### Missing cute/cutlass headers when compiling flash-attn

```
  In file included from kernels/flash_fwd_launch_template.h:11:0,
                   from kernels/flash_fwd_hdim224_fp16_sm80.cu:5:
  kernels/flash_fwd_kernel.h:8:10: fatal error: cute

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/ruff]]></title>
            <link>https://github.com/astral-sh/ruff</link>
            <guid>https://github.com/astral-sh/ruff</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[An extremely fast Python linter and code formatter, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/ruff">astral-sh/ruff</a></h1>
            <p>An extremely fast Python linter and code formatter, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 40,652</p>
            <p>Forks: 1,428</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;!-- Begin section: Overview --&gt;

# Ruff

[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![image](https://img.shields.io/pypi/v/ruff.svg)](https://pypi.python.org/pypi/ruff)
[![image](https://img.shields.io/pypi/l/ruff.svg)](https://github.com/astral-sh/ruff/blob/main/LICENSE)
[![image](https://img.shields.io/pypi/pyversions/ruff.svg)](https://pypi.python.org/pypi/ruff)
[![Actions status](https://github.com/astral-sh/ruff/workflows/CI/badge.svg)](https://github.com/astral-sh/ruff/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.com/invite/astral-sh)

[**Docs**](https://docs.astral.sh/ruff/) | [**Playground**](https://play.ruff.rs/)

An extremely fast Python linter and code formatter, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://user-images.githubusercontent.com/1309177/232603514-c95e9b0f-6b31-43de-9a80-9e844173fd6a.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://user-images.githubusercontent.com/1309177/232603516-4fb4892d-585c-4b20-b810-3db9161831e4.svg&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://user-images.githubusercontent.com/1309177/232603516-4fb4892d-585c-4b20-b810-3db9161831e4.svg&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Linting the CPython codebase from scratch.&lt;/i&gt;
&lt;/p&gt;

- ‚ö°Ô∏è 10-100x faster than existing linters (like Flake8) and formatters (like Black)
- üêç Installable via `pip`
- üõ†Ô∏è `pyproject.toml` support
- ü§ù Python 3.13 compatibility
- ‚öñÔ∏è Drop-in parity with [Flake8](https://docs.astral.sh/ruff/faq/#how-does-ruffs-linter-compare-to-flake8), isort, and [Black](https://docs.astral.sh/ruff/faq/#how-does-ruffs-formatter-compare-to-black)
- üì¶ Built-in caching, to avoid re-analyzing unchanged files
- üîß Fix support, for automatic error correction (e.g., automatically remove unused imports)
- üìè Over [800 built-in rules](https://docs.astral.sh/ruff/rules/), with native re-implementations
    of popular Flake8 plugins, like flake8-bugbear
- ‚å®Ô∏è First-party [editor integrations](https://docs.astral.sh/ruff/editors) for [VS Code](https://github.com/astral-sh/ruff-vscode) and [more](https://docs.astral.sh/ruff/editors/setup)
- üåé Monorepo-friendly, with [hierarchical and cascading configuration](https://docs.astral.sh/ruff/configuration/#config-file-discovery)

Ruff aims to be orders of magnitude faster than alternative tools while integrating more
functionality behind a single, common interface.

Ruff can be used to replace [Flake8](https://pypi.org/project/flake8/) (plus dozens of plugins),
[Black](https://github.com/psf/black), [isort](https://pypi.org/project/isort/),
[pydocstyle](https://pypi.org/project/pydocstyle/), [pyupgrade](https://pypi.org/project/pyupgrade/),
[autoflake](https://pypi.org/project/autoflake/), and more, all while executing tens or hundreds of
times faster than any individual tool.

Ruff is extremely actively developed and used in major open-source projects like:

- [Apache Airflow](https://github.com/apache/airflow)
- [Apache Superset](https://github.com/apache/superset)
- [FastAPI](https://github.com/tiangolo/fastapi)
- [Hugging Face](https://github.com/huggingface/transformers)
- [Pandas](https://github.com/pandas-dev/pandas)
- [SciPy](https://github.com/scipy/scipy)

...and [many more](#whos-using-ruff).

Ruff is backed by [Astral](https://astral.sh). Read the [launch post](https://astral.sh/blog/announcing-astral-the-company-behind-ruff),
or the original [project announcement](https://notes.crmarsh.com/python-tooling-could-be-much-much-faster).

## Testimonials

[**Sebasti√°n Ram√≠rez**](https://twitter.com/tiangolo/status/1591912354882764802), creator
of [FastAPI](https://github.com/tiangolo/fastapi):

&gt; Ruff is so fast that sometimes I add an intentional bug in the code just to confirm it&#039;s actually
&gt; running and checking the code.

[**Nick Schrock**](https://twitter.com/schrockn/status/1612615862904827904), founder of [Elementl](https://www.elementl.com/),
co-creator of [GraphQL](https://graphql.org/):

&gt; Why is Ruff a gamechanger? Primarily because it is nearly 1000x faster. Literally. Not a typo. On
&gt; our largest module (dagster itself, 250k LOC) pylint takes about 2.5 minutes, parallelized across 4
&gt; cores on my M1. Running ruff against our _entire_ codebase takes .4 seconds.

[**Bryan Van de Ven**](https://github.com/bokeh/bokeh/pull/12605), co-creator
of [Bokeh](https://github.com/bokeh/bokeh/), original author
of [Conda](https://docs.conda.io/en/latest/):

&gt; Ruff is ~150-200x faster than flake8 on my machine, scanning the whole repo takes ~0.2s instead of
&gt; ~20s. This is an enormous quality of life improvement for local dev. It&#039;s fast enough that I added
&gt; it as an actual commit hook, which is terrific.

[**Timothy Crosley**](https://twitter.com/timothycrosley/status/1606420868514877440),
creator of [isort](https://github.com/PyCQA/isort):

&gt; Just switched my first project to Ruff. Only one downside so far: it&#039;s so fast I couldn&#039;t believe
&gt; it was working till I intentionally introduced some errors.

[**Tim Abbott**](https://github.com/astral-sh/ruff/issues/465#issuecomment-1317400028), lead
developer of [Zulip](https://github.com/zulip/zulip):

&gt; This is just ridiculously fast... `ruff` is amazing.

&lt;!-- End section: Overview --&gt;

## Table of Contents

For more, see the [documentation](https://docs.astral.sh/ruff/).

1. [Getting Started](#getting-started)
1. [Configuration](#configuration)
1. [Rules](#rules)
1. [Contributing](#contributing)
1. [Support](#support)
1. [Acknowledgements](#acknowledgements)
1. [Who&#039;s Using Ruff?](#whos-using-ruff)
1. [License](#license)

## Getting Started&lt;a id=&quot;getting-started&quot;&gt;&lt;/a&gt;

For more, see the [documentation](https://docs.astral.sh/ruff/).

### Installation

Ruff is available as [`ruff`](https://pypi.org/project/ruff/) on PyPI.

Invoke Ruff directly with [`uvx`](https://docs.astral.sh/uv/):

```shell
uvx ruff check   # Lint all files in the current directory.
uvx ruff format  # Format all files in the current directory.
```

Or install Ruff with `uv` (recommended), `pip`, or `pipx`:

```shell
# With uv.
uv tool install ruff@latest  # Install Ruff globally.
uv add --dev ruff            # Or add Ruff to your project.

# With pip.
pip install ruff

# With pipx.
pipx install ruff
```

Starting with version `0.5.0`, Ruff can be installed with our standalone installers:

```shell
# On macOS and Linux.
curl -LsSf https://astral.sh/ruff/install.sh | sh

# On Windows.
powershell -c &quot;irm https://astral.sh/ruff/install.ps1 | iex&quot;

# For a specific version.
curl -LsSf https://astral.sh/ruff/0.12.2/install.sh | sh
powershell -c &quot;irm https://astral.sh/ruff/0.12.2/install.ps1 | iex&quot;
```

You can also install Ruff via [Homebrew](https://formulae.brew.sh/formula/ruff), [Conda](https://anaconda.org/conda-forge/ruff),
and with [a variety of other package managers](https://docs.astral.sh/ruff/installation/).

### Usage

To run Ruff as a linter, try any of the following:

```shell
ruff check                          # Lint all files in the current directory (and any subdirectories).
ruff check path/to/code/            # Lint all files in `/path/to/code` (and any subdirectories).
ruff check path/to/code/*.py        # Lint all `.py` files in `/path/to/code`.
ruff check path/to/code/to/file.py  # Lint `file.py`.
ruff check @arguments.txt           # Lint using an input file, treating its contents as newline-delimited command-line arguments.
```

Or, to run Ruff as a formatter:

```shell
ruff format                          # Format all files in the current directory (and any subdirectories).
ruff format path/to/code/            # Format all files in `/path/to/code` (and any subdirectories).
ruff format path/to/code/*.py        # Format all `.py` files in `/path/to/code`.
ruff format path/to/code/to/file.py  # Format `file.py`.
ruff format @arguments.txt           # Format using an input file, treating its contents as newline-delimited command-line arguments.
```

Ruff can also be used as a [pre-commit](https://pre-commit.com/) hook via [`ruff-pre-commit`](https://github.com/astral-sh/ruff-pre-commit):

```yaml
- repo: https://github.com/astral-sh/ruff-pre-commit
  # Ruff version.
  rev: v0.12.2
  hooks:
    # Run the linter.
    - id: ruff-check
      args: [ --fix ]
    # Run the formatter.
    - id: ruff-format
```

Ruff can also be used as a [VS Code extension](https://github.com/astral-sh/ruff-vscode) or with [various other editors](https://docs.astral.sh/ruff/editors/setup).

Ruff can also be used as a [GitHub Action](https://github.com/features/actions) via
[`ruff-action`](https://github.com/astral-sh/ruff-action):

```yaml
name: Ruff
on: [ push, pull_request ]
jobs:
  ruff:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/ruff-action@v3
```

### Configuration&lt;a id=&quot;configuration&quot;&gt;&lt;/a&gt;

Ruff can be configured through a `pyproject.toml`, `ruff.toml`, or `.ruff.toml` file (see:
[_Configuration_](https://docs.astral.sh/ruff/configuration/), or [_Settings_](https://docs.astral.sh/ruff/settings/)
for a complete list of all configuration options).

If left unspecified, Ruff&#039;s default configuration is equivalent to the following `ruff.toml` file:

```toml
# Exclude a variety of commonly ignored directories.
exclude = [
    &quot;.bzr&quot;,
    &quot;.direnv&quot;,
    &quot;.eggs&quot;,
    &quot;.git&quot;,
    &quot;.git-rewrite&quot;,
    &quot;.hg&quot;,
    &quot;.ipynb_checkpoints&quot;,
    &quot;.mypy_cache&quot;,
    &quot;.nox&quot;,
    &quot;.pants.d&quot;,
    &quot;.pyenv&quot;,
    &quot;.pytest_cache&quot;,
    &quot;.pytype&quot;,
    &quot;.ruff_cache&quot;,
    &quot;.svn&quot;,
    &quot;.tox&quot;,
    &quot;.venv&quot;,
    &quot;.vscode&quot;,
    &quot;__pypackages__&quot;,
    &quot;_build&quot;,
    &quot;buck-out&quot;,
    &quot;build&quot;,
    &quot;dist&quot;,
    &quot;node_modules&quot;,
    &quot;site-packages&quot;,
    &quot;venv&quot;,
]

# Same as Black.
line-length = 88
indent-width = 4

# Assume Python 3.9
target-version = &quot;py39&quot;

[lint]
# Enable Pyflakes (`F`) and a subset of the pycodestyle (`E`) codes by default.
select = [&quot;E4&quot;, &quot;E7&quot;, &quot;E9&quot;, &quot;F&quot;]
ignore = []

# Allow fix for all enabled rules (when `--fix`) is provided.
fixable = [&quot;ALL&quot;]
unfixable = []

# Allow unused variables when underscore-prefixed.
dummy-variable-rgx = &quot;^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$&quot;

[format]
# Like Black, use double quotes for strings.
quote-style = &quot;double&quot;

# Like Black, indent with spaces, rather than tabs.
indent-style = &quot;space&quot;

# Like Black, respect magic trailing commas.
skip-magic-trailing-comma = false

# Like Black, automatically detect the appropriate line ending.
line-ending = &quot;auto&quot;
```

Note that, in a `pyproject.toml`, each section header should be prefixed with `tool.ruff`. For
example, `[lint]` should be replaced with `[tool.ruff.lint]`.

Some configuration options can be provided via dedicated command-line arguments, such as those
related to rule enablement and disablement, file discovery, and logging level:

```shell
ruff check --select F401 --select F403 --quiet
```

The remaining configuration options can be provided through a catch-all `--config` argument:

```shell
ruff check --config &quot;lint.per-file-ignores = {&#039;some_file.py&#039; = [&#039;F841&#039;]}&quot;
```

To opt in to the latest lint rules, formatter style changes, interface updates, and more, enable
[preview mode](https://docs.astral.sh/ruff/rules/) by setting `preview = true` in your configuration
file or passing `--preview` on the command line. Preview mode enables a collection of unstable
features that may change prior to stabilization.

See `ruff help` for more on Ruff&#039;s top-level commands, or `ruff help check` and `ruff help format`
for more on the linting and formatting commands, respectively.

## Rules&lt;a id=&quot;rules&quot;&gt;&lt;/a&gt;

&lt;!-- Begin section: Rules --&gt;

**Ruff supports over 800 lint rules**, many of which are inspired by popular tools like Flake8,
isort, pyupgrade, and others. Regardless of the rule&#039;s origin, Ruff re-implements every rule in
Rust as a first-party feature.

By default, Ruff enables Flake8&#039;s `F` rules, along with a subset of the `E` rules, omitting any
stylistic rules that overlap with the use of a formatter, like `ruff format` or
[Black](https://github.com/psf/black).

If you&#039;re just getting started with Ruff, **the default rule set is a great place to start**: it
catches a wide variety of common errors (like unused imports) with zero configuration.

&lt;!-- End section: Rules --&gt;

Beyond the defaults, Ruff re-implements some of the most popular Flake8 plugins and related code
quality tools, including:

- [autoflake](https://pypi.org/project/autoflake/)
- [eradicate](https://pypi.org/project/eradicate/)
- [flake8-2020](https://pypi.org/project/flake8-2020/)
- [flake8-annotations](https://pypi.org/project/flake8-annotations/)
- [flake8-async](https://pypi.org/project/flake8-async)
- [flake8-bandit](https://pypi.org/project/flake8-bandit/) ([#1646](https://github.com/astral-sh/ruff/issues/1646))
- [flake8-blind-except](https://pypi.org/project/flake8-blind-except/)
- [flake8-boolean-trap](https://pypi.org/project/flake8-boolean-trap/)
- [flake8-bugbear](https://pypi.org/project/flake8-bugbear/)
- [flake8-builtins](https://pypi.org/project/flake8-builtins/)
- [flake8-commas](https://pypi.org/project/flake8-commas/)
- [flake8-comprehensions](https://pypi.org/project/flake8-comprehensions/)
- [flake8-copyright](https://pypi.org/project/flake8-copyright/)
- [flake8-datetimez](https://pypi.org/project/flake8-datetimez/)
- [flake8-debugger](https://pypi.org/project/flake8-debugger/)
- [flake8-django](https://pypi.org/project/flake8-django/)
- [flake8-docstrings](https://pypi.org/project/flake8-docstrings/)
- [flake8-eradicate](https://pypi.org/project/flake8-eradicate/)
- [flake8-errmsg](https://pypi.org/project/flake8-errmsg/)
- [flake8-executable](https://pypi.org/project/flake8-executable/)
- [flake8-future-annotations](https://pypi.org/project/flake8-future-annotations/)
- [flake8-gettext](https://pypi.org/project/flake8-gettext/)
- [flake8-implicit-str-concat](https://pypi.org/project/flake8-implicit-str-concat/)
- [flake8-import-conventions](https://github.com/joaopalmeiro/flake8-import-conventions)
- [flake8-logging](https://pypi.org/project/flake8-logging/)
- [flake8-logging-format](https://pypi.org/project/flake8-logging-format/)
- [flake8-no-pep420](https://pypi.org/project/flake8-no-pep420)
- [flake8-pie](https://pypi.org/project/flake8-pie/)
- [flake8-print](https://pypi.org/project/flake8-print/)
- [flake8-pyi](https://pypi.org/project/flake8-pyi/)
- [flake8-pytest-style](https://pypi.org/project/flake8-pytest-style/)
- [flake8-quotes](https://pypi.org/project/flake8-quotes/)
- [flake8-raise](https://pypi.org/project/flake8-raise/)
- [flake8-return](https://pypi.org/project/flake8-return/)
- [flake8-self](https://pypi.org/project/flake8-self/)
- [flake8-simplify](https://pypi.org/project/flake8-simplify/)
- [flake8-slots](https://pypi.org/project/flake8-slots/)
- [flake8-super](https://pypi.org/project/flake8-super/)
- [flake8-tidy-imports](https://pypi.org/project/flake8-tidy-imports/)
- [flake8-todos](https://pypi.org/project/flake8-todos/)
- [flake8-type-checking](https://pypi.org/project/flake8-type-checking/)
- [flake8-use-pathlib](https://pypi.org/project/flake8-use-pathlib/)
- [flynt](https://pypi.org/project/flynt/) ([#2102](https://github.com/astral-sh/ruff/issues/2102))
- [isort](https://pypi.org/project/isort/)
- [mccabe](https://pypi.org/project/mccabe/)
- [pandas-vet](https://pypi.org/project/pandas-vet/)
- [pep8-naming](https://pypi.org/project/pep8-naming/)
- [pydocstyle](https://pypi.org/project/pydocstyle/)
- [pygrep-hooks](https://github.com/pre-commit/pygrep-hooks)
- [pylint-airflow](https://pypi.org/project/pylint-airflow/)
- [pyupgrade](https://pypi.org/project/pyupgrade/)
- [tryceratops](https://pypi.org/project/tryceratops/)
- [yesqa](https://pypi.org/project/yesqa/)

For a complete enumeration of the supported rules, see [_Rules_](https://docs.astral.sh/ruff/rules/).

## Contributing&lt;a id=&quot;contributing&quot;&gt;&lt;/a&gt;

Contributions are welcome and highly appreciated. To get started, check out the
[**contributing guidelines**](https://docs.astral.sh/ruff/contributing/).

You can also join us on [**Discord**](https://discord.com/invite/astral-sh).

## Support&lt;a id=&quot;support&quot;&gt;&lt;/a&gt;

Having trouble? Check out the existing issues on [**GitHub**](https://github.com/astral-sh/ruff/issues),
or feel free to [**open a new one**](https://github.com/astral-sh/ruff/issues/new).

You can also ask for help on [**Discord**](https://discord.com/invite/astral-sh).

## Acknowledgements&lt;a id=&quot;acknowledgements&quot;&gt;&lt;/a&gt;

Ruff&#039;s linter draws on both the APIs and implementation details of many other
tools in the Python ecosystem, especially [Flake8](https://github.com/PyCQA/flake8), [Pyflakes](https://github.com/PyCQA/pyflakes),
[pycodestyle](https://github.com/PyCQA/pycodestyle), [pydocstyle](https://github.com/PyCQA/pydocstyle),
[pyupgrade](https://github.com/asottile/pyupgrade), and [isort](https://github.com/PyCQA/isort).

In some cases, Ruff includes a &quot;direct&quot; Rust port of the corresponding tool.
We&#039;re grateful to the maintainers of these tools for their work, and for all
the value they&#039;ve provided to the Python community.

Ruff&#039;s formatter is built on a fork of Rome&#039;s [`rome_formatter`](https://github.com/rome/tools/tree/main/crates/rome_formatter),
and again draws on both API and implementation details from [Rome](https://github.com/rome/tools),
[Prettier](https://github.com/prettier/prettier), and [Black](https://github.com/psf/black).

Ruff&#039;s import resolver is based on the import resolution algorithm from [Pyright](https://github.com/microsoft/pyright).

Ruff is also influenced by a number of tools outside the Python ecosystem, like
[Clippy](https://github.com/rust-lang/rust-clippy) and [ESLint](https://github.com/eslint/eslint).

Ruff is the beneficiary of a large number of [contributors](https://github.com/astral-sh/ruff/graphs/contributors).

Ruff is released under the MIT license.

## Who&#039;s Using Ruff?&lt;a id=&quot;whos-using-ruff&quot;&gt;&lt;/a&gt;

Ruff is used by a number of major open-source projects and companies, including:

- [Albumentations](https://github.com/albumentations-team/albumentations)
- Amazon ([AWS SAM](https://github.com/aws/serverless-application-model))
- [Anki](https://apps.ankiweb.net/)
- Anthropic ([Python SDK](https://github.com/anthropics/anthropic-sdk-python))
- [Apache Airflow](https://github.com/apache/airflow)
- AstraZeneca ([Magnus](https://github.com/AstraZeneca/magnus-core))
- [Babel](https://github.com/python-babel/babel)
- Benchling ([Refac](https://github.com/benchling/refac))
- [Bokeh](https://github.com/bokeh/bokeh)
- CrowdCent ([NumerBlox](https://github.com/crowdcent/numerblox)) &lt;!-- typos: ignore --&gt;
- [Cryptography (PyCA)](https://github.com/pyca/cryptography)
- CERN ([Indico](https://getindico.io/))
- [DVC](https://github.com/iterative/dvc)
- [Dagger](https://github.com/dagger/dagger)
- [Dagster](https://github.com/dagster-io/dagster)
- Databricks ([MLflow](https://github.com/mlflow/mlflow))
- [Dify](https://github.com/langgenius/dify)
- [FastAPI](https://github.com/tiangolo/fastapi)
- [Godot](https://github.com/godotengine/godot)
- [Gradio](https://github.com/gradio-app/gradio)
- [Great Expectations](https://github.com/great-expectations/great_expectations)
- [HTTPX](https://github.com/encode/httpx)
- [Hatch](https://github.com/pypa/hatch)
- [Home Assistant](https://github.com/home-assistant/core)
- Hugging Face ([Transformers](https://github.com/huggingface/transformers),
    [Datasets](https://github.com/huggingface/datasets),
    [Diffusers](https://github.com/huggingface/diffusers))
- IBM ([Qiskit](https://github.com/Qiskit/qiskit))
- ING Bank ([popmon](https://github.com/ing-bank/popmon), [probatus](https://github.com/ing-bank/probatus))
- [Ibis](https://github.com/ibis-project/ibis)
- [ivy](https://github.com/

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tracel-ai/burn]]></title>
            <link>https://github.com/tracel-ai/burn</link>
            <guid>https://github.com/tracel-ai/burn</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[Burn is a next generation Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tracel-ai/burn">tracel-ai/burn</a></h1>
            <p>Burn is a next generation Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.</p>
            <p>Language: Rust</p>
            <p>Stars: 11,499</p>
            <p>Forks: 613</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp&quot; width=&quot;350px&quot;/&gt;

[![Discord](https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;&amp;logo=discord)](https://discord.gg/uPEBbYYDB6)
[![Current Crates.io Version](https://img.shields.io/crates/v/burn.svg)](https://crates.io/crates/burn)
[![Minimum Supported Rust Version](https://img.shields.io/crates/msrv/burn)](https://crates.io/crates/burn)
[![Documentation](https://img.shields.io/badge/docs-latest-blue)](https://burn.dev/docs/burn)
[![Test Status](https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg)](https://github.com/tracel-ai/burn/actions/workflows/test.yml)
[![CodeCov](https://codecov.io/gh/tracel-ai/burn/branch/main/graph/badge.svg)](https://codecov.io/gh/tracel-ai/burn)
[![license](https://shields.io/badge/license-MIT%2FApache--2.0-blue)](#license)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/tracel-ai/burn)

[&lt;img src=&quot;https://www.runblaze.dev/ci-blaze-powered.png&quot; width=&quot;125px&quot;/&gt;](https://www.runblaze.dev)

---

**Burn is a next generation Deep Learning Framework that doesn&#039;t compromise on &lt;br /&gt;
flexibility, efficiency and portability.**

&lt;br/&gt;
&lt;/div&gt;

&lt;div align=&quot;left&quot;&gt;

## Performance

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-blazingly-fast.png&quot; height=&quot;96px&quot;/&gt;

Because we believe the goal of a deep learning framework is to convert computation into useful
intelligence, we have made performance a core pillar of Burn. We strive to achieve top efficiency by
leveraging multiple optimization techniques described below.

**Click on each section for more details** üëá

&lt;/div&gt;

&lt;br /&gt;

&lt;details&gt;
&lt;summary&gt;
Automatic kernel fusion üí•
&lt;/summary&gt;
&lt;br /&gt;

Using Burn means having your models optimized on any backend. When possible, we provide a way to
automatically and dynamically create custom kernels that minimize data relocation between different
memory spaces, extremely useful when moving memory is the bottleneck.

As an example, you could write your own GELU activation function with the high level tensor api (see
Rust code snippet below).

```rust
fn gelu_custom&lt;B: Backend, const D: usize&gt;(x: Tensor&lt;B, D&gt;) -&gt; Tensor&lt;B, D&gt; {
    let x = x.clone() * ((x / SQRT_2).erf() + 1);
    x / 2
}
```

Then, at runtime, a custom low-level kernel will be automatically created for your specific
implementation and will rival a handcrafted GPU implementation. The kernel consists of about 60
lines of WGSL [WebGPU Shading Language](&quot;https://www.w3.org/TR/WGSL/https://www.w3.org/TR/WGSL/&quot;),
an extremely verbose lower level shader language you probably don&#039;t want to program your deep
learning models in!

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Asynchronous execution ‚ù§Ô∏è‚Äçüî•
&lt;/summary&gt;
&lt;br /&gt;

For [first-party backends](#backends), an asynchronous execution style
is used, which allows to perform various optimizations, such as the previously mentioned automatic
kernel fusion.

Asynchronous execution also ensures that the normal execution of the framework does not block the
model computations, which implies that the framework overhead won&#039;t impact the speed of execution
significantly. Conversely, the intense computations in the model do not interfere with the
responsiveness of the framework. For more information about our asynchronous backends, see
[this blog post](https://burn.dev/blog/creating-high-performance-asynchronous-backends-with-burn-compute).

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Thread-safe building blocks ü¶û
&lt;/summary&gt;
&lt;br /&gt;

Burn emphasizes thread safety by leveraging the
[ownership system of Rust](https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html).
With Burn, each module is the owner of its weights. It is therefore possible to send a module to
another thread for computing the gradients, then send the gradients to the main thread that can
aggregate them, and _voil√†_, you get multi-device training.

This is a very different approach from what PyTorch does, where backpropagation actually mutates the
_grad_ attribute of each tensor parameter. This is not a thread-safe operation and therefore
requires lower level synchronization primitives, see
[distributed training](https://pytorch.org/docs/stable/distributed.html) for reference. Note that
this is still very fast, but not compatible across different backends and quite hard to implement.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Intelligent memory management ü¶Ä
&lt;/summary&gt;
&lt;br /&gt;

One of the main roles of a deep learning framework is to reduce the amount of memory necessary to
run models. The naive way of handling memory is that each tensor has its own memory space, which is
allocated when the tensor is created then deallocated as the tensor gets out of scope. However,
allocating and deallocating data is very costly, so a memory pool is often required to achieve good
throughput. Burn offers an infrastructure that allows for easily creating and selecting memory
management strategies for backends. For more details on memory management in Burn, see
[this blog post](https://burn.dev/blog/creating-high-performance-asynchronous-backends-with-burn-compute).

Another very important memory optimization of Burn is that we keep track of when a tensor can be
mutated in-place just by using the ownership system well. Even though it is a rather small memory
optimization on its own, it adds up considerably when training or running inference with larger
models and contributes to reduce the memory usage even more. For more information, see
[this blog post about tensor handling](https://burn.dev/blog/burn-rusty-approach-to-tensor-handling).

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Automatic kernel selection üéØ
&lt;/summary&gt;
&lt;br /&gt;

A good deep learning framework should ensure that models run smoothly on all hardware. However, not
all hardware share the same behavior in terms of execution speed. For instance, a matrix
multiplication kernel can be launched with many different parameters, which are highly sensitive to
the size of the matrices and the hardware. Using the wrong configuration could reduce the speed of
execution by a large factor (10 times or even more in extreme cases), so choosing the right kernels
becomes a priority.

With our home-made backends, we run benchmarks automatically and choose the best configuration for
the current hardware and matrix sizes with a reasonable caching strategy.

This adds a small overhead by increasing the warmup execution time, but stabilizes quickly after a
few forward and backward passes, saving lots of time in the long run. Note that this feature isn&#039;t
mandatory, and can be disabled when cold starts are a priority over optimized throughput.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Hardware specific features üî•
&lt;/summary&gt;
&lt;br /&gt;

It is no secret that deep learning is mostly relying on matrix multiplication as its core operation,
since this is how fully-connected neural networks are modeled.

More and more, hardware manufacturers optimize their chips specifically for matrix multiplication
workloads. For instance, Nvidia has its _Tensor Cores_ and today most cellphones have AI specialized
chips. As of this moment, we support Tensor Cores with our LibTorch, Candle, CUDA, Metal and WGPU/SPIR-V
backends, but not other accelerators yet. We hope
[this issue](https://github.com/gpuweb/gpuweb/issues/4195) gets resolved at some point to bring
support to our WGPU backend.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Custom Backend Extension üéí
&lt;/summary&gt;
&lt;br /&gt;

Burn aims to be the most flexible deep learning framework. While it&#039;s crucial to maintain
compatibility with a wide variety of backends, Burn also provides the ability to extend the
functionalities of a backend implementation to suit your personal modeling requirements.

This versatility is advantageous in numerous ways, such as supporting custom operations like flash
attention or manually writing your own kernel for a specific backend to enhance performance. See
[this section](https://burn.dev/burn-book/advanced/backend-extension/index.html) in the Burn Book üî•
for more details.

&lt;/details&gt;

&lt;br /&gt;

## Backend

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png&quot; height=&quot;96px&quot;/&gt;

Burn strives to be as fast as possible on as many hardwares as possible, with robust implementations.
We believe this flexibility is crucial for modern needs where you may train your models in the cloud,
then deploy on customer hardwares, which vary from user to user.

&lt;/div&gt;

&lt;br /&gt;

**Supported Backends**

| Backend  | Devices                      | Class       |
| -------- | ---------------------------- | ----------- |
| CUDA     | NVIDIA GPUs                  | First-Party |
| ROCm     | AMD GPUs                     | First-Party |
| Metal    | Apple GPUs                   | First-Party |
| Vulkan   | Most GPUs on Linux &amp; Windows | First-Party |
| Wgpu     | Most GPUs                    | First-Party |
| NdArray  | Most CPUs                    | Third-Party |
| LibTorch | Most GPUs &amp; CPUs             | Third-Party |
| Candle   | Nvidia, Apple GPUs &amp; CPUs    | Third-Party |

&lt;br /&gt;

Compared to other frameworks, Burn has a very different approach to supporting many backends. By
design, most code is generic over the Backend trait, which allows us to build Burn with swappable
backends. This makes composing backend possible, augmenting them with additional functionalities
such as autodifferentiation and automatic kernel fusion.

&lt;details&gt;
&lt;summary&gt;
Autodiff: Backend decorator that brings backpropagation to any backend üîÑ
&lt;/summary&gt;
&lt;br /&gt;

Contrary to the aforementioned backends, Autodiff is actually a backend _decorator_. This means that
it cannot exist by itself; it must encapsulate another backend.

The simple act of wrapping a base backend with Autodiff transparently equips it with
autodifferentiation support, making it possible to call backward on your model.

```rust
use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&lt;Wgpu&gt;;

    let x: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default);
    let y: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;grads).unwrap();
    println!(&quot;{y_grad}&quot;);
}
```

Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend
that does not support autodiff (for inference), as this method is only offered by an Autodiff
backend.

See the [Autodiff Backend README](./crates/burn-autodiff/README.md) for more details.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Fusion: Backend decorator that brings kernel fusion to all first-party backends
&lt;/summary&gt;
&lt;br /&gt;

This backend decorator enhances a backend with kernel fusion, provided that the inner backend
supports it. Note that you can compose this backend with other backend decorators such as Autodiff.
For now, only the WGPU and CUDA backends have support for fused kernels.

```rust
use burn::backend::{Autodiff, Fusion, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&lt;Fusion&lt;Wgpu&gt;&gt;;

    let x: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default);
    let y: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;grads).unwrap();
    println!(&quot;{y_grad}&quot;);
}

```

Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory
bound operations, which will work gracefully with the fusion backend to make your code run even
faster during training, see [this issue](https://github.com/tracel-ai/burn/issues/936).

See the [Fusion Backend README](./crates/burn-fusion/README.md) for more details.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Router (Beta): Backend decorator that composes multiple backends into a single one
&lt;/summary&gt;
&lt;br /&gt;

That backend simplifies hardware operability, if for instance you want to execute some operations on the CPU and other operations on the GPU.

```rust
use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&lt;(Wgpu, NdArray)&gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;device_0);
    let tensor_cpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;device_1);
}

```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations
&lt;/summary&gt;
&lt;br /&gt;

That backend has two parts, one client and one server.
The client sends tensor operations over the network to a remote compute backend.
You can use any first-party backend as server in a single line of code:

```rust
fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&lt;burn::backend::Cuda&gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&lt;RemoteDevice&gt;;

    let device = RemoteDevice::new(&quot;ws://localhost:3000&quot;);
    let tensor_gpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], Distribution::Default, &amp;device);
}

```

&lt;/details&gt;

&lt;br /&gt;

## Training &amp; Inference

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png&quot; height=&quot;96px&quot;/&gt;

The whole deep learning workflow is made easy with Burn, as you can monitor your training progress
with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU
clusters.

Burn was built from the ground up with training and inference in mind. It&#039;s also worth noting how
Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to
deployment, eliminating the need for code changes.

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;br /&gt;

&lt;a href=&quot;https://www.youtube.com/watch?v=N9RM5CQbNQc&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png&quot; alt=&quot;Burn Train TUI&quot; width=&quot;75%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;br /&gt;

**Click on the following sections to expand üëá**

&lt;details&gt;
&lt;summary&gt;
Training Dashboard üìà
&lt;/summary&gt;
&lt;br /&gt;

As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on
the [Ratatui](https://github.com/ratatui-org/ratatui) crate allows users to follow their training
with ease without having to connect to any external application.

You can visualize your training and validation metrics updating in real-time and analyze the
lifelong progression or recent history of any registered metrics using only the arrow keys. Break
from the training loop without crashing, allowing potential checkpoints to be fully written or
important pieces of code to complete without interruption üõ°

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
ONNX Support üê´
&lt;/summary&gt;
&lt;br /&gt;

ONNX (Open Neural Network Exchange) is an open-standard format that exports both the architecture
and the weights of a deep learning model.

Burn supports the importation of models that follow the ONNX standard so you can easily port a model
you have written in another framework like TensorFlow or PyTorch to Burn to benefit from all the
advantages our framework offers.

Our ONNX support is further described in
[this section of the Burn Book üî•](https://burn.dev/burn-book/import/onnx-model.html).

&gt; **Note**: This crate is in active development and currently supports a
&gt; [limited set of ONNX operators](./crates/burn-import/SUPPORTED-ONNX-OPS.md).

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Importing PyTorch or Safetensors Models üöö
&lt;/summary&gt;
&lt;br /&gt;

You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models. This makes it easy to reuse existing models while benefiting from Burn&#039;s performance and deployment features.

Learn more:

- [Import pre-trained PyTorch models into Burn](https://burn.dev/burn-book/import/pytorch-model.html)
- [Load models from Safetensors format](https://burn.dev/burn-book/import/safetensors-model.html)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Inference in the Browser üåê
&lt;/summary&gt;
&lt;br /&gt;

Several of our backends can compile to Web Assembly: Candle and NdArray for CPU, and WGPU for GPU.
This means that you can run inference directly within a browser. We provide several examples of
this:

- [MNIST](./examples/mnist-inference-web) where you can draw digits and a small convnet tries to
  find which one it is! 2Ô∏è‚É£ 7Ô∏è‚É£ üò∞
- [Image Classification](./examples/image-classification-web) where you can upload images and
  classify them! üåÑ

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Embedded: &lt;i&gt;no_std&lt;/i&gt; support ‚öôÔ∏è
&lt;/summary&gt;
&lt;br /&gt;

Burn&#039;s core components support [no_std](https://docs.rust-embedded.org/book/intro/no-std.html). This
means it can run in bare metal environment such as embedded devices without an operating system.

&gt; As of now, only the NdArray backend can be used in a _no_std_ environment.

&lt;/details&gt;

&lt;br /&gt;

### Benchmarks

To evaluate performance across different backends and track improvements over time, we provide a
dedicated benchmarking suite.

Run and compare benchmarks using [burn-bench](https://github.com/tracel-ai/burn-bench).

&gt; ‚ö†Ô∏è **Warning**
&gt; When using one of the `wgpu` backends, you may encounter compilation errors related to recursive type evaluation. This is due to complex type nesting within the `wgpu` dependency chain.
&gt; To resolve this issue, add the following line at the top of your `main.rs` or `lib.rs` file:
&gt;
&gt; ```rust
&gt; #![recursion_limit = &quot;256&quot;]
&gt; ```
&gt;
&gt; The default recursion limit (128) is often just below the required depth (typically 130-150) due to deeply nested associated types and trait bounds.

## Getting Started

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png&quot; height=&quot;96px&quot;/&gt;

Just heard of Burn? You are at the right place! Just continue reading this section and we hope you
can get on board really quickly.

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;
The Burn Book üî•
&lt;/summary&gt;
&lt;br /&gt;

To begin working effectively with Burn, it is crucial to understand its key components and
philosophy. This is why we highly recommend new users to read the first sections of
[The Burn Book üî•](https://burn.dev/burn-book/). It provides detailed examples and explanations
covering every facet of the framework, including building blocks like tensors, modules, and
optimizers, all the way to advanced usage, like coding your own GPU kernels.

&gt; The project is constantly evolving, and we try as much as possible to keep the book up to date
&gt; with new additions. However, we might miss some details sometimes, so if you see something weird,
&gt; let us know! We also gladly accept Pull Requests üòÑ

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Examples üôè
&lt;/summary&gt;
&lt;br /&gt;

Let&#039;s start with a code snippet that shows how intuitive the framework is to use! In the following,
we declare a neural network module with some parameters along with its forward pass.

```rust
use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&lt;B: Backend&gt; {
    linear_inner: nn::Linear&lt;B&gt;,
    linear_outer: nn::Linear&lt;B&gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&lt;B: Backend&gt; PositionWiseFeedForward&lt;B&gt; {
    pub fn forward&lt;const D: usize&gt;(&amp;self, input: Tensor&lt;B, D&gt;) -&gt; 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gdt050579/AppCUI-rs]]></title>
            <link>https://github.com/gdt050579/AppCUI-rs</link>
            <guid>https://github.com/gdt050579/AppCUI-rs</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[AppCUI ‚Äì A feature-rich and cross-platform TUI/CUI framework for Rust, enabling modern terminal-based applications on Windows, Linux, and macOS. Includes built-in UI components like buttons, menus, list views, tree views, checkboxes, and more. Perfect for building fast and interactive CLI tools and text-based interfaces]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gdt050579/AppCUI-rs">gdt050579/AppCUI-rs</a></h1>
            <p>AppCUI ‚Äì A feature-rich and cross-platform TUI/CUI framework for Rust, enabling modern terminal-based applications on Windows, Linux, and macOS. Includes built-in UI components like buttons, menus, list views, tree views, checkboxes, and more. Perfect for building fast and interactive CLI tools and text-based interfaces</p>
            <p>Language: Rust</p>
            <p>Stars: 186</p>
            <p>Forks: 2</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre># AppCUI-rs

&lt;img src=&quot;https://raw.githubusercontent.com/gdt050579/AppCUI-rs/main/docs/chapter-1/img/logo.png&quot; align=&quot;center&quot; /&gt;

```                                                              
‚Øà ùóîùóΩùóΩùóñùó®ùóú-ùóøùòÄ üñ≥
```

![Windows Build Status](https://github.com/gdt050579/AppCUI-rs/actions/workflows/windows.yml/badge.svg)
![Linux Build Status](https://github.com/gdt050579/AppCUI-rs/actions/workflows/linux.yml/badge.svg)
![MacOS Build Status](https://github.com/gdt050579/AppCUI-rs/actions/workflows/macos.yml/badge.svg)
![Code Coverage](https://gist.githubusercontent.com/gdt050579/f7d7e7d56b2725a3b33a265e8a9d8e9c/raw/coverage.svg)
![License](https://img.shields.io/github/license/gdt050579/AppCUI-rs)
[![Crates.io](https://img.shields.io/crates/v/appcui.svg)](https://crates.io/crates/appcui)
[![Docs.rs](https://docs.rs/appcui/badge.svg)](https://docs.rs/appcui)

AppCUI is a simple, easy-to-use and cross-platform library for creating text-based user interfaces in Rust:
* [Book](https://gdt050579.github.io/AppCUI-rs/)
* [Documentation](https://docs.rs/appcui)


## ‚ú® Features
- [x] multiple out-of-the-box controls (buttons, labels, text boxes, check boxes, radio buttons, list views, tree views, combo boxes, date/time pickers, color pickers, etc.). 
- [x] menus and toolbars
- [x] multi-platform support (Windows via API, Linux via ncurses, MacOS via termios)
- [x] multi-threading support
- [x] timers
- [x] mouse support
- [x] clipboard support
- [x] color themes
- [x] support for Unicode characters
- [x] predefined dialogs (message box, input box, color picker, save &amp; open dialogs, folder navigator, etc)
- [x] true colors support (24 bits per pixel) for terminals that supports it.

## üì∏ Screenshots 

&lt;img src=&quot;https://github.com/gdt050579/AppCUI-rs/raw/main/docs/chapter-1/img/appcui-rs-demo.gif&quot; align=&quot;center&quot; /&gt;

## üñ•Ô∏è Backends

AppCUI supports various backends based on the operating system it is being used for:

* **Windows Console** - based on Win32 low level API, design for clasical windows console
* **Windows VT** - based on ANSI sequances, designed for modern windows virtual terminals
* **NCurses** - based on NCurses API for linux envinronments
* **Termios** - based on ANSI sequances and low level APIs for MAC OSX
* **Web Terminal** - designed for Web implementation (based on webgl)
* **CrossTerm** - based on the `crossterm` crate, but enabled via a feature flag

More on the supported backends can be found [here](docs/chapter-2/backends.md)


## üöÄ Quick Start

Add the following to your `Cargo.toml`:

```toml
[dependencies]
appcui = &quot;*&quot;
```

Then create a new Rust project and add the following code:

```rust
use appcui::prelude::*;

fn main() -&gt; Result&lt;(), appcui::system::Error&gt; {
    let mut app = App::new().build()?;
    let mut win = window!(&quot;Test,d:c,w:30,h:9&quot;);
    win.add(label!(&quot;&#039;Hello World !&#039;,d:c,w:13,h:1&quot;));
    app.add_window(win);
    app.run();
    Ok(())
}
```

Then run the project with `cargo run`. You should see a window with the title `Test` and the text `Hello World !` in the center.

## üß™ Examples

- üåç [Hello World](examples/hello_world/)
- üßÆ [Calculator](examples/calculator/)
- üé® [Color Picker](examples/colorpicker/)
- üìã [Menus](examples/menus/)

Check out the [examples](examples) folder for more examples.

## üõ†Ô∏è A more complex example

Am example that creates a window with a button that when pressed increases a counter.

```rust
use appcui::prelude::*;

// Create a window that handles button events and has a counter
#[Window(events = ButtonEvents)]
struct CounterWindow {
    counter: i32
}

impl CounterWindow {
    fn new() -&gt; Self {
        let mut w = Self {
            // set up the window title and position
            base: window!(&quot;&#039;Counter window&#039;,d:c,w:30,h:5&quot;),
            // initial counter is 1
            counter: 1            
        };
        // add a single button with the caption &quot;1&quot; (like the counter)
        w.add(button!(&quot;&#039;1&#039;,d:b,w:20&quot;));
        w
    }
}
impl ButtonEvents for CounterWindow {
    // When the button is pressed, this function will be called
    // with the handle of the button that was pressed
    // Since we only have one button, we don&#039;t need to store its handle 
    // in the struct, as we will receive the handle via the on_pressed method
    fn on_pressed(&amp;mut self, handle: Handle&lt;Button&gt;) -&gt; EventProcessStatus {
        // increase the counter
        self.counter += 1;
        // create a text that containe the new counter
        let text = format!(&quot;{}&quot;,self.counter);
        // aquire a mutable reference to the button using its handle
        if let Some(button) = self.control_mut(handle) {
            // set the caption of the button to th new text
            button.set_caption(&amp;text);
        }
        // Tell the AppCUI framework that we have processed this event
        // This allows AppCUI to repaint the button
        EventProcessStatus::Processed
    }
}

fn main() -&gt; Result&lt;(), appcui::system::Error&gt; {
    // create a new application
    let mut a = App::new().build()?;
    // add a new window (of type CounterWindow) to the application
    a.add_window(CounterWindow::new());
    // Run AppCUI framework (this wil start the window loop and messaage passing)
    a.run();
    Ok(())
}
```

## üõ£Ô∏è Roadmap

- [x] Basic set of widgets and support for Windows, Linux and MacOS
- [x] WebGL support
- [ ] OpenGL / SDL / Vulkan support
- [ ] TextArea support for code highlighting

## ü§ù Contributing

Contributions, issues, and feature requests are welcome!  
Check out [CONTRIBUTING.md](CONTRIBUTING.md) to get started.

Join the discussion in [GitHub Discussions](https://github.com/gdt050579/AppCUI-rs/discussions).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 60,767</p>
            <p>Forks: 1,736</p>
            <p>Stars today: 120 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- üöÄ A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`,
  and more.
- ‚ö°Ô∏è [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- üóÇÔ∏è Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- ‚ùáÔ∏è [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- üêç [Installs and manages](#python-versions) Python versions.
- üõ†Ô∏è [Runs and installs](#tools) tools published as Python packages.
- üî© Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a
  familiar CLI.
- üè¢ Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- üíæ Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- ‚è¨ Installable without Rust or Python via `curl` or `pip`.
- üñ•Ô∏è Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Platform support

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

## Versioning policy

See uv&#039;s [versioning policy](https://docs.astral.sh/uv/reference/versioning/) document.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv/blob/main/CONTRIBUTING.md) to get started.

## FAQ

#### How do you pronounce uv?

It&#039;s pronounced as &quot;you - vee&quot; ([`/juÀê viÀê/`](https://en.wikipedia.org/wiki/Help:IPA/English#Key))

#### How should I stylize uv?

Just &quot;uv&quot;, please. See the [style guide](./STYLE.md#styling-uv) for details.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[boundless-xyz/boundless]]></title>
            <link>https://github.com/boundless-xyz/boundless</link>
            <guid>https://github.com/boundless-xyz/boundless</guid>
            <pubDate>Wed, 09 Jul 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Monorepo for Boundless, the universal ZK protocol]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/boundless-xyz/boundless">boundless-xyz/boundless</a></h1>
            <p>Monorepo for Boundless, the universal ZK protocol</p>
            <p>Language: Rust</p>
            <p>Stars: 81</p>
            <p>Forks: 67</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;Boundless_Logo black.png&quot; alt=&quot;Boundless Logo&quot; width=&quot;200&quot;&gt;
&lt;/p&gt;

# Boundless

This repository contains the core primitives for Boundless.

&gt; **Note:** If you are a builder looking to build an application on Boundless, you should start with the [Boundless Foundry Template](https://github.com/boundless-xyz/boundless-foundry-template) and the [Boundless Builder Docs](https://docs.beboundless.xyz/developers/quick-start).

&gt; **Note:** If you are a prover looking to get started, please refer to the [Boundless Prover Quick Start Guide](https://docs.beboundless.xyz/provers/quick-start).

## Repository Structure

The repository is structured as a monorepo and contains Rust crates and Solidity contracts. Some key components:

- **Boundless Core Contracts**: The core smart contracts for Boundless. [./contracts](./contracts)
- **Boundless SDK**: Rust SDK for interacting with Boundless. [./crates/boundless-market](./crates/boundless-market)
- **Boundless CLI**: Command-line interface for interacting with Boundless. [./crates/boundless-cli](./crates/boundless-cli)
- **Boundless Broker**: Our sample prover implementation. [./crates/broker](./crates/broker)
- **Boundless zkVM Guests**: The zkVM guests required for generating proofs on Boundless. [./crates/guest](./crates/guest) and [./crates/assessor](./crates/assessor)

## Developing

If you don&#039;t already have Rust installed, start by [installing Rust and rustup](https://doc.rust-lang.org/cargo/getting-started/installation.html).

Then download the RISC Zero toolchain and install it using rzup:

```sh
curl -L https://risczero.com/install | bash
```

Next we can install the RISC Zero toolchain by running rzup install:

```sh
rzup install
```

You can verify the installation was successful by running:

```sh
cargo risczero --version
```

If you don&#039;t already have Forge installed, you can install it using Foundry:

```sh
curl -L https://foundry.paradigm.xyz | bash
foundryup
```

To build the Solidity contracts, run:

```sh
forge build
```

To build the Rust crates, run:

```sh
cargo build
```

## Documentation

You can find the documentation in the [documentation](./documentation) folder.

To build it and serve it locally, run the following commands:

```sh
bun install
bun run docs
```

Then open your browser and navigate to `http://localhost:5173`.

## Audits

See https://github.com/boundless-xyz/boundless-security

## License

See [LICENSE](./LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>