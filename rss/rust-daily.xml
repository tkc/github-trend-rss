<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Sat, 14 Jun 2025 00:05:35 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[YaLTeR/niri]]></title>
            <link>https://github.com/YaLTeR/niri</link>
            <guid>https://github.com/YaLTeR/niri</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[A scrollable-tiling Wayland compositor.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/YaLTeR/niri">YaLTeR/niri</a></h1>
            <p>A scrollable-tiling Wayland compositor.</p>
            <p>Language: Rust</p>
            <p>Stars: 8,385</p>
            <p>Forks: 274</p>
            <p>Stars today: 146 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;niri&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;A scrollable-tiling Wayland compositor.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://matrix.to/#/#niri:matrix.org&quot;&gt;&lt;img alt=&quot;Matrix&quot; src=&quot;https://img.shields.io/badge/matrix-%23niri-blue?logo=matrix&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;GitHub License&quot; src=&quot;https://img.shields.io/github/license/YaLTeR/niri&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/releases&quot;&gt;&lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/YaLTeR/niri?logo=github&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/wiki/Getting-Started&quot;&gt;Getting Started&lt;/a&gt; | &lt;a href=&quot;https://github.com/YaLTeR/niri/wiki/Configuration:-Introduction&quot;&gt;Configuration&lt;/a&gt; | &lt;a href=&quot;https://github.com/YaLTeR/niri/discussions/325&quot;&gt;Setup&amp;nbsp;Showcase&lt;/a&gt;
&lt;/p&gt;

![niri with a few windows open](https://github.com/user-attachments/assets/535e6530-2f44-4b84-a883-1240a3eee6e9)

## About

Windows are arranged in columns on an infinite strip going to the right.
Opening a new window never causes existing windows to resize.

Every monitor has its own separate window strip.
Windows can never &quot;overflow&quot; onto an adjacent monitor.

Workspaces are dynamic and arranged vertically.
Every monitor has an independent set of workspaces, and there&#039;s always one empty workspace present all the way down.

The workspace arrangement is preserved across disconnecting and connecting monitors where it makes sense.
When a monitor disconnects, its workspaces will move to another monitor, but upon reconnection they will move back to the original monitor.

## Features

- Built from the ground up for scrollable tiling
- [Dynamic workspaces](https://github.com/YaLTeR/niri/wiki/Workspaces) like in GNOME
- An [Overview](https://github.com/user-attachments/assets/379a5d1f-acdb-4c11-b36c-e85fd91f0995) that zooms out workspaces and windows
- Built-in screenshot UI
- Monitor and window screencasting through xdg-desktop-portal-gnome
    - You can [block out](https://github.com/YaLTeR/niri/wiki/Configuration:-Window-Rules#block-out-from) sensitive windows from screencasts
    - [Dynamic cast target](https://github.com/YaLTeR/niri/wiki/Screencasting#dynamic-screencast-target) that can change what it shows on the go
- [Touchpad](https://github.com/YaLTeR/niri/assets/1794388/946a910e-9bec-4cd1-a923-4a9421707515) and [mouse](https://github.com/YaLTeR/niri/assets/1794388/8464e65d-4bf2-44fa-8c8e-5883355bd000) gestures
- Group windows into [tabs](https://github.com/YaLTeR/niri/wiki/Tabs)
- Configurable layout: gaps, borders, struts, window sizes
- [Gradient borders](https://github.com/YaLTeR/niri/wiki/Configuration:-Layout#gradients) with Oklab and Oklch support
- [Animations](https://github.com/YaLTeR/niri/assets/1794388/ce178da2-af9e-4c51-876f-8709c241d95e) with support for [custom shaders](https://github.com/YaLTeR/niri/assets/1794388/27a238d6-0a22-4692-b794-30dc7a626fad)
- Live-reloading config

## Video Demo

https://github.com/YaLTeR/niri/assets/1794388/bce834b0-f205-434e-a027-b373495f9729

## Status

Niri is stable for day-to-day use and does most things expected of a Wayland compositor.
Many people are daily-driving niri, and are happy to help in our [Matrix channel].

Give it a try!
Follow the instructions on the [Getting Started](https://github.com/YaLTeR/niri/wiki/Getting-Started) wiki page.
Have your [waybar]s and [fuzzel]s ready: niri is not a complete desktop environment.

Here are some points you may have questions about:

- **Multi-monitor**: yes, a core part of the design from the very start. Mixed DPI works.
- **Fractional scaling**: yes, plus all niri UI stays pixel-perfect.
- **NVIDIA**: seems to work fine.
- **Floating windows**: yes, starting from niri 25.01.
- **Input devices**: niri supports tablets, touchpads, and touchscreens.
You can map the tablet to a specific monitor, or use [OpenTabletDriver].
We have touchpad gestures, but no touchscreen gestures yet.
- **Wlr protocols**: yes, we have most of the important ones like layer-shell, gamma-control, screencopy.
You can check on [wayland.app](https://wayland.app) at the bottom of each protocol&#039;s page.
- **Performance**: while I run niri on beefy machines, I try to stay conscious of performance.
I&#039;ve seen someone use it fine on an Eee PC 900 from 2008, of all things.
- **Xwayland**: no built-in support, but xwayland-satellite is [easy to set up](https://github.com/YaLTeR/niri/wiki/Xwayland#using-xwayland-satellite) and works very well.
    - Steam and games, including Proton: work perfectly through xwayland-satellite.
    - JetBrains IDEs, Ghidra: work well through xwayland-satellite.
    - Discord and other Electron apps: work well through xwayland-satellite.
    - Chromium and VSCode: work perfectly natively on Wayland with the right flags.
    - X11 apps that want to position windows or bars at specific screen coordinates: won&#039;t work well; you can run them in a nested compositor like [labwc](https://github.com/YaLTeR/niri/wiki/Xwayland#using-the-labwc-wayland-compositor) or [rootful Xwayland](https://github.com/YaLTeR/niri/wiki/Xwayland#directly-running-xwayland-in-rootful-mode).
    - Display scaling (integer or fractional) keeps X11 apps crisp, but you need the latest xwayland-satellite.
    For games, you can run them in [gamescope] at native resolution, even with display scaling.

## Inspiration

Niri is heavily inspired by [PaperWM] which implements scrollable tiling on top of GNOME Shell.

One of the reasons that prompted me to try writing my own compositor is being able to properly separate the monitors.
Being a GNOME Shell extension, PaperWM has to work against Shell&#039;s global window coordinate space to prevent windows from overflowing.

## Tile Scrollably Elsewhere

Here are some other projects which implement a similar workflow:

- [PaperWM]: scrollable tiling on top of GNOME Shell.
- [karousel]: scrollable tiling on top of KDE.
- [scroll](https://github.com/dawsers/scroll) and [papersway]: scrollable tiling on top of sway/i3.
- [hyprscrolling] and [hyprslidr]: scrollable tiling on top of Hyprland.
- [PaperWM.spoon]: scrollable tiling on top of macOS.

## Media

[niri: Making a Wayland compositor in Rust](https://youtu.be/Kmz8ODolnDg?list=PLRdS-n5seLRqrmWDQY4KDqtRMfIwU0U3T)

My talk from the 2024 Moscow RustCon about niri, and how I do randomized property testing and profiling, and measure input latency.
The talk is in Russian, but I prepared full English subtitles that you can find in YouTube&#039;s subtitle language selector.

## Contact

We have a Matrix chat, feel free to join and ask a question: https://matrix.to/#/#niri:matrix.org

[PaperWM]: https://github.com/paperwm/PaperWM
[waybar]: https://github.com/Alexays/Waybar
[fuzzel]: https://codeberg.org/dnkl/fuzzel
[karousel]: https://github.com/peterfajdiga/karousel
[papersway]: https://spwhitton.name/tech/code/papersway/
[hyprscrolling]: https://github.com/hyprwm/hyprland-plugins/tree/main/hyprscrolling
[hyprslidr]: https://gitlab.com/magus/hyprslidr
[PaperWM.spoon]: https://github.com/mogenson/PaperWM.spoon
[Matrix channel]: https://matrix.to/#/#niri:matrix.org
[OpenTabletDriver]: https://opentabletdriver.net/
[gamescope]: https://github.com/ValveSoftware/gamescope
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[oxc-project/oxc]]></title>
            <link>https://github.com/oxc-project/oxc</link>
            <guid>https://github.com/oxc-project/oxc</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[⚓ A collection of JavaScript tools written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oxc-project/oxc">oxc-project/oxc</a></h1>
            <p>⚓ A collection of JavaScript tools written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 14,917</p>
            <p>Forks: 586</p>
            <p>Stars today: 52 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;OXC Logo&quot; src=&quot;https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/preview-universal.png&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![MIT licensed][license-badge]][license-url]
[![Build Status][ci-badge]][ci-url]
[![Code Coverage][code-coverage-badge]][code-coverage-url]
[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/oxc-project/oxc)
[![Sponsors][sponsors-badge]][sponsors-url]

[![Discord chat][discord-badge]][discord-url]
[![Playground][playground-badge]][playground-url]
[![Website][website-badge]][website-url]

&lt;/div&gt;

## ⚓ Oxc

The Oxidation Compiler is creating a collection of high-performance tools for JavaScript and TypeScript.

Oxc is building a parser, linter, formatter, transformer, minifier, resolver ... all written in Rust.

See more at [oxc.rs](https://oxc.rs)!

## VoidZero Inc.

Oxc is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/blog).

If you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!

## 🙋Who&#039;s using Oxc?

- [Rolldown] uses the [oxc][docs-oxc-url] crate for parsing and transformation.
- [Nova engine](https://trynova.dev) uses the [oxc][docs-oxc-url] crate for parsing.
- [Rolldown][rolldown], [Biome][biome] and [swc-node](https://github.com/swc-project/swc-node) uses the [oxc_resolver][docs-resolver-url] crate for module resolution.
- Projects and companies like [Preact](https://github.com/preactjs/preact/blob/4c20c23c16dd60f380ce9fe98afc93041a7e1562/oxlint.json), [Shopify](https://oxc.rs/blog/2023-12-12-announcing-oxlint.html#_50-100-times-faster-than-eslint), ByteDance and Shopee uses oxlint for linting.
- ...[and many more](https://oxc.rs/docs/guide/projects.html)

## ⚡️ Linter Quick Start

The linter is ready to catch mistakes for you. It comes with 93 rules turned on by default (out of 430+ in total) and no configuration is required.

To get started, run [oxlint][npm-oxlint] or via `npx`:

```bash
npx oxlint@latest
```

To give you an idea of its capabilities, here is an example from the [vscode] repository, which finishes linting 4800+ files in 0.7 seconds.

&lt;p float=&quot;left&quot; align=&quot;left&quot;&gt;
  &lt;img src=&quot;https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/linter-screenshot.png&quot; width=&quot;60%&quot;&gt;
&lt;/p&gt;

## ⚡️ Performance

- The parser aims to be the fastest Rust-based ready-for-production parser.
- The linter is more than 50 times faster than [ESLint], and scales with the number of CPU cores.

&lt;p float=&quot;left&quot; align=&quot;middle&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Boshen/bench-javascript-parser-written-in-rust/main/bar-graph.svg&quot; width=&quot;49%&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Boshen/bench-javascript-linter/main/bar-graph.svg&quot; width=&quot;49%&quot;&gt;
&lt;/p&gt;

## ⌨️ Rust, Node.js and Wasm Usage

### Rust

Individual crates are published, you may use them to build your own JavaScript tools.

- The umbrella crate [oxc][docs-oxc-url] exports all public crates from this repository.
- The AST and parser crates [oxc_ast][docs-ast-url] and [oxc_parser][docs-parser-url] are production ready.
- The resolver crate [oxc_resolver][docs-resolver-url] for module resolution is also production ready.
- Example usages of these crates can be found in their respective `crates/*/examples` directory.

While Rust has gained a reputation for its comparatively slower compilation speed,
we have dedicated significant effort to fine-tune the Rust compilation speed.
Our aim is to minimize any impact on your development workflow,
ensuring that developing your own Oxc based tools remains a smooth and efficient experience.

This is demonstrated by our [CI runs](https://github.com/oxc-project/oxc/actions/workflows/ci.yml?query=branch%3Amain),
where warm runs complete in 3 minutes.

### Node.js

- via napi: [oxc-parser][npm-napi-parser], [oxc-transform][npm-napi-transform]

### Wasm

- [@oxc-parser/wasm](https://www.npmjs.com/package/@oxc-parser/wasm)

---

## 🎯 Tools

- [AST and Parser](#-ast-and-parser)
- [Linter](#-linter)
- [Resolver](#-resolver)
- [Minifier](#-minifier)
- [Formatter](#-formatter)
- [Transformer](#-transformer)

### 🔸 AST and Parser

Oxc maintains its own AST and parser, which is by far the fastest and most conformant JavaScript and TypeScript (including JSX and TSX) parser written in Rust.

As the parser often represents a key performance bottleneck in JavaScript tooling,
any minor improvements can have a cascading effect on our downstream tools.
By developing our parser, we have the opportunity to explore and implement well-researched performance techniques.

While many existing JavaScript tools rely on [estree] as their AST specification,
a notable drawback is its abundance of ambiguous nodes.
This ambiguity often leads to confusion during development with [estree].

The Oxc AST differs slightly from the [estree] AST by removing ambiguous nodes and introducing distinct types.
For example, instead of using a generic [estree] `Identifier`,
the Oxc AST provides specific types such as `BindingIdentifier`, `IdentifierReference`, and `IdentifierName`.
This clear distinction greatly enhances the development experience by aligning more closely with the ECMAScript specification.

#### 🏆 Parser Performance

Our [benchmark][parser-benchmark] reveals that the Oxc parser surpasses the speed of the [swc] parser by approximately 3 times and the [Biome][biome] parser by 5 times.

&lt;details&gt;
  &lt;summary&gt;How is it so fast?&lt;/summary&gt;
  &lt;ul&gt;
    &lt;li&gt;AST is allocated in a memory arena (&lt;a href=&quot;https://crates.io/crates/bumpalo&quot;&gt;bumpalo&lt;/a&gt;) for fast AST memory allocation and deallocation.&lt;/li&gt;
    &lt;li&gt;Short strings are inlined by &lt;a href=&quot;https://crates.io/crates/compact_str&quot;&gt;CompactString&lt;/a&gt;.&lt;/li&gt;
    &lt;li&gt;No other heap allocations are done except the above two.&lt;/li&gt;
    &lt;li&gt;Scope binding, symbol resolution and some syntax errors are not done in the parser, they are delegated to the semantic analyzer.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/details&gt;

### 🔸 Linter

The linter embraces convention over configuration, eliminating the need for extensive configuration and plugin setup.
Unlike other linters like [ESLint], which often require intricate configurations and plugin installations (e.g. [@typescript-eslint]),
our linter only requires a single command that you can immediately run on your codebase:

```bash
npx oxlint@latest
```

#### 🏆 Linter Performance

The linter is 50 - 100 times faster than [ESLint] depending on the number of rules and number of CPU cores used.
It completes in less than a second for most codebases with a few hundred files and completes in a few seconds for
larger monorepos. See [bench-javascript-linter](https://github.com/Boshen/bench-javascript-linter) for details.

As an upside, the binary is approximately 5MB, whereas [ESLint] and its associated plugin dependencies can easily exceed 100.

You may also download the linter binary from the [latest release tag](https://github.com/oxc-project/oxc/releases/latest) as a standalone binary,
this lets you run the linter without a Node.js installation in your CI.

&lt;details&gt;
  &lt;summary&gt;How is it so fast?&lt;/summary&gt;
  &lt;ul&gt;
    &lt;li&gt;Oxc parser is used.&lt;/li&gt;
    &lt;li&gt;AST visit is a fast operation due to linear memory scan from the memory arena.&lt;/li&gt;
    &lt;li&gt;Files are linted in a multi-threaded environment, so scales with the total number of CPU cores.&lt;/li&gt;
    &lt;li&gt;Every single lint rule is tuned for performance.&lt;/li&gt;
  &lt;/ul&gt;
&lt;/details&gt;

### 🔸 Resolver

Module resolution plays a crucial role in JavaScript tooling, especially for tasks like multi-file analysis or bundling. However, it can often become a performance bottleneck.
To address this, we developed [oxc_resolver][docs-resolver-url].

The resolver is production-ready and is currently being used in [Rolldown][rolldown]. Usage and examples can be found in its own [repository](https://github.com/oxc-project/oxc_resolver).

### 🔸 Transformer

A transformer is responsible for turning higher versions of ECMAScript to a lower version that can be used in older browsers.

TypeScript and React transforms are complete. See [Milestone 2](https://github.com/oxc-project/oxc/issues/2859) for current goals.

[oxc-transform][npm-napi-transform] can be used for experimentation.

### 🔸 Isolated Declarations

[TypeScript Isolated Declarations Emit](https://devblogs.microsoft.com/typescript/announcing-typescript-5-5/#isolated-declarations) without using the TypeScript compiler.

Our [benchmark](https://github.com/oxc-project/bench-transformer) indicates that our implementation is at least 20 times faster than the TypeScript compiler.

The [npm package](https://www.npmjs.com/package/oxc-transform) or [crate](https://crates.io/crates/oxc_isolated_declarations) can be used for this task.

### 🔸 Minifier

JavaScript minification plays a crucial role in optimizing website performance as it reduces the amount of data sent to users,
resulting in faster page loads.
This holds tremendous economic value, particularly for e-commerce websites, where every second can equate to millions of dollars.

However, existing minifiers typically require a trade-off between compression quality and speed.
You have to choose between the slowest for the best compression or the fastest for less compression.
But what if we could develop a faster minifier without compromising on compression?

We are actively working on a prototype that aims to achieve this goal,
by porting all test cases from well-known minifiers such as [google-closure-compiler], [terser], [esbuild], and [tdewolff-minify].

Preliminary results indicate that we are on track to achieve our objectives.
With the Oxc minifier, you can expect faster minification times without sacrificing compression quality.

### 🔸 Formatter

While [prettier] has established itself as the de facto code formatter for JavaScript, there is a significant demand in the developer community for a less opinionated alternative. Recognizing this need, our ambition is to undertake research and development to create a new JavaScript formatter that offers increased flexibility and customization options.

The [prototype](https://github.com/oxc-project/oxc/tree/main/crates/oxc_formatter) is currently work in progress.

---

## 🧪Test Infrastructure

In Oxc, correctness and reliability are taken extremely seriously.

We spend half of our time on strengthening the test infrastructure to prevent problems from propagating to downstream tools.

[Test Infrastructure](https://oxc.rs/docs/learn/architecture/test.html) documents our test procedures:

- Conformance suite on Test262, Babel, TypeScript
- Lots of fuzzing
- Linter snapshot diagnostics
- oxlint ecosystem ci
- Idempotency testing
- Code coverage
- End to end 3000 top npm packages

---

## ✍️ Contribute

See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidance.

Check out some of the [good first issues](https://github.com/oxc-project/oxc/contribute) or ask us on [Discord][discord-url].

If you are unable to contribute by code, you can still participate by:

- Add a [GitHub Star](https://github.com/oxc-project/oxc/stargazers) to the project.
- Join us on [Discord][discord-url].
- [Follow me on twitter](https://twitter.com/boshen_c) and tweet about this project.

## 📚 Learning Resources

- My small tutorial on [how to write a JavaScript Parser in Rust](https://oxc.rs/docs/learn/parser_in_rust/intro.html)
- My small article [Pursuit of Performance on Building a JavaScript Compiler](https://oxc.rs/docs/learn/performance.html)
- [And more](https://oxc.rs/docs/learn/references.html)

## 🤝 Credits

This project was incubated with the assistance of these exceptional mentors and their projects:

- [Biome][biome] - [@ematipico](https://github.com/ematipico)
- [Ruff][ruff] - [@charliermarsh](https://github.com/charliermarsh), [@MichaReiser](https://github.com/MichaReiser)
- [quick-lint-js](https://github.com/quick-lint/quick-lint-js) - [@strager](https://github.com/strager)
- [elm-review](https://package.elm-lang.org/packages/jfmengels/elm-review/latest) - [@jfmengels](https://github.com/jfmengels)

Special thanks go to

- [@domonji](https://github.com/domonji) for bootstrapping this project together, and also completing the TypeScript parser.
- [@tongtong-lu](https://github.com/tongtong-lu) and [@guan-wy](https://github.com/guan-wy) for designing the [project logo](https://github.com/oxc-project/oxc-assets).

## ❤ Who&#039;s [Sponsoring Oxc](https://github.com/sponsors/Boshen)?

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/sponsors/Boshen&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/Boshen/sponsors/main/sponsors.svg&quot; alt=&quot;My sponsors&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## 📖 License

Oxc is free and open-source software licensed under the [MIT License](./LICENSE).

Oxc ports or copies code from other open source projects, their licenses are listed in [**Third-party library licenses**](./THIRD-PARTY-LICENSE).

[discord-badge]: https://img.shields.io/discord/1079625926024900739?logo=discord&amp;label=Discord
[discord-url]: https://discord.gg/9uXCAwqQZW
[license-badge]: https://img.shields.io/badge/license-MIT-blue.svg
[license-url]: https://github.com/oxc-project/oxc/blob/main/LICENSE
[ci-badge]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml/badge.svg?event=push&amp;branch=main
[ci-url]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml?query=event%3Apush+branch%3Amain
[npm-badge]: https://img.shields.io/npm/v/oxlint/latest?color=brightgreen
[npm-url]: https://www.npmjs.com/package/oxlint/v/latest
[code-size-badge]: https://img.shields.io/github/languages/code-size/oxc-project/oxc
[code-size-url]: https://github.com/oxc-project/oxc
[code-coverage-badge]: https://codecov.io/github/oxc-project/oxc/branch/main/graph/badge.svg
[code-coverage-url]: https://codecov.io/gh/oxc-project/oxc
[sponsors-badge]: https://img.shields.io/github/sponsors/Boshen
[sponsors-url]: https://github.com/sponsors/Boshen
[playground-badge]: https://img.shields.io/badge/Playground-blue?color=9BE4E0
[playground-url]: https://playground.oxc.rs/
[website-badge]: https://img.shields.io/badge/Website-blue
[website-url]: https://oxc.rs
[crate-oxc-url]: https://crates.io/crates/oxc
[crate-ast-url]: https://crates.io/crates/oxc_ast
[crate-parser-url]: https://crates.io/crates/oxc_parser
[docs-oxc-url]: https://docs.rs/oxc
[docs-ast-url]: https://docs.rs/oxc_ast
[docs-parser-url]: https://docs.rs/oxc_parser
[docs-resolver-url]: https://docs.rs/oxc_resolver
[Boshen]: https://github.com/boshen
[CompactString]: https://github.com/ParkMyCar/compact_str
[ESLint]: https://eslint.org/
[acorn]: https://github.com/acornjs/acorn
[babel]: https://babel.dev
[bumpalo]: https://docs.rs/bumpalo
[contributors]: https://github.com/oxc-project/oxc/graphs/contributors
[enhanced-resolve]: https://github.com/webpack/enhanced-resolve
[esbuild]: https://esbuild.github.io/
[eslint-plugin-import]: https://www.npmjs.com/package/eslint-plugin-import
[eslint-plugin-jest]: https://www.npmjs.com/package/eslint-plugin-jest
[estree]: https://github.com/estree/estree
[google-closure-compiler]: https://github.com/google/closure-compiler
[minification-benchmarks]: https://github.com/privatenumber/minification-benchmarks
[npm-napi-parser]: https://www.npmjs.com/package/oxc-parser
[npm-napi-transform]: https://www.npmjs.com/package/oxc-transform
[npm-oxlint]: https://www.npmjs.com/package/oxlint
[parser-benchmark]: https://github.com/Boshen/bench-javascript-parser-written-in-rust
[prettier]: https://prettier.io
[biome]: https://biomejs.dev/
[ruff]: https://beta.ruff.rs
[swc]: https://swc.rs
[tdewolff-minify]: https://github.com/tdewolff/minify
[terser]: https://terser.org
[vscode]: https://github.com/microsoft/vscode
[@typescript-eslint]: https://typescript-eslint.io
[rolldown]: https://rolldown.rs
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rivet-gg/rivet]]></title>
            <link>https://github.com/rivet-gg/rivet</link>
            <guid>https://github.com/rivet-gg/rivet</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[🔩 The open-source serverless platform. Easily deploy & scale AI agents, complex workloads, and backends — all on a frictionless platform that runs anywhere.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rivet-gg/rivet">rivet-gg/rivet</a></h1>
            <p>🔩 The open-source serverless platform. Easily deploy & scale AI agents, complex workloads, and backends — all on a frictionless platform that runs anywhere.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,876</p>
            <p>Forks: 99</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://rivet.gg&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./.github/media/icon-text-white.svg&quot; alt=&quot;Rivet&quot;&gt;
      &lt;img src=&quot;./.github/media/icon-text-black.svg&quot; alt=&quot;Rivet&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;The open-source serverless platform.&lt;/h3&gt;
&lt;h4 align=&quot;center&quot;&gt;
  Easily deploy and scale AI agents, real-time applications, game servers, and complex backends on a frictionless platform that runs anywhere.
&lt;/h4&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;!-- &lt;a href=&quot;https://github.com/rivet-gg/rivet/graphs/commit-activity&quot;&gt;&lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/m/rivet-gg/rivet?style=flat-square&quot;/&gt;&lt;/a&gt; --&gt;
  &lt;a href=&quot;https://github.com/rivet-gg/rivet/discussions&quot;&gt;&lt;img alt=&quot;GitHub Discussions&quot; src=&quot;https://img.shields.io/github/discussions/rivet-gg/rivet?logo=github&amp;logoColor=fff&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://rivet.gg/discord&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/822914074136018994?color=7389D8&amp;label&amp;logo=discord&amp;logoColor=ffffff&quot;/&gt;&lt;/a&gt;
   &lt;a href=&quot;https://twitter.com/rivet_gg&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/rivet_gg&quot; alt=&quot;Rivet Twitter&quot; /&gt;&lt;/a&gt;
   &lt;a href=&quot;https://bsky.app/profile/rivet.gg&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Follow%20%40rivet.gg-4C1?color=0285FF&amp;logo=bluesky&amp;logoColor=ffffff&quot; alt=&quot;Rivet Bluesky&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;/LICENSE&quot;&gt;&lt;img alt=&quot;License Apache-2.0&quot; src=&quot;https://img.shields.io/github/license/rivet-gg/rivet?logo=open-source-initiative&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

![Code snippets](./.github/media/code.png)

## Overview

Rivet is a developer-focused serverless infrastructure platform that unifies stateless functions, stateful actors, and containerized workloads. It provides simple primitives to build your backend without managing servers. Leverage Rivet Actors to create resilient, long-lived services that maintain in-memory state between requests.

Whether you’re building AI-driven services, collaborative apps, multiplayer games, or any cloud backend, Rivet’s technology provides the performance and scalability you need in a portable, open-source package.


## Key Characteristics

- **Open Source &amp; Portable**  
  Run the Rivet platform on any infrastructure – use the fully-managed Rivet Cloud or deploy it on your own servers and cloud.

- **Unified Primitives**  
  Develop using stateless **Functions** (for request/response APIs), stateful **Actors** (for persistent, real-time services), or sandboxed **Containers** (for heavy or untrusted workloads). All are managed together or alone with a consistent CLI and tooling.

---

## Features

- **Stateful Persistence**  
  Rivet Actors preserve data in memory with automatic durability to disk. This provides persistent memory-like state – you get the speed of in-memory access with the safety of persistent storage. Ideal for dynamic, fast-moving app state (caches, game lobbies, collaborative document data, etc.).

- **Remote Procedure Calls (RPC)**  
  Lightweight built-in messaging for clients and services. Rivet offers type-safe RPC calls and broadcast events between clients and actors, simplifying real-time communication without external message brokers.

- **No Cold Starts**  
  Services hibernate on idle and wake instantly on demand. Long-running actors “sleep” when inactive and recover state immediately on the next request. Instant cold-start recovery and consistently low latency for end-users.

- **Edge Distribution**  
  Deploy backend code closer to your users. Rivet distributes actors and functions across global edge regions for ultra-low latency. Supports HTTP, WebSocket, TCP, and UDP protocols without requiring external proxies.

- **Unlimited Execution &amp; Container Support**  
  No arbitrary execution time limits – run long-lived processes or background jobs as needed. Rivet supports anything that runs in a Docker container. If it works in Docker, it works on Rivet.

- **Fault Tolerance**  
  Actor state is persisted so that if an instance crashes or is rescheduled, it can recover its exact state with zero downtime. Combined with intelligent routing, Rivet ensures high availability.

- **Local Development**  
  Develop and test locally with ease. Spin up a full Rivet cluster with `rivet dev` or Docker Compose. Iterate locally before deploying to production.

  ### Use cases

-   AI agents
-   Multi-tenant applications
-   Local-first apps
-   Collaborative applications
-   Sandboxed Code Execution
-   Game Servers
-   Yjs Sync &amp; Storage
-   Chat Apps

---

## Getting Started

### Quickstart (TypeScript)

_See the [full quickstart guide](https://rivet.gg/docs/actors) for a comprehensive walkthrough._

**Step 1: Create Actor**

```sh
npx create-actor@latest -p rivet -t counter
```

**Step 2: Deploy Actor**

```sh
cd your-project
npm run deploy

```

**Step 3: Monitor**

Visit the [Rivet Hub](https://hub.rivet.gg) to create &amp; test your actors.

### Documentation

-   [**Documentation**](https://rivet.gg/docs): Read about how to use Rivet
-   [**Examples**](./examples/): See existing Rivet projects
-   [**Contributing**](./CONTRIBUTING.md): Learn to contribute to Rivet

### Running Rivet

-   **Self-Hosting**
    -   [**Local Dev &amp; Single Container**](https://rivet.gg/docs/self-hosting/single-container): Great for local development, fast single-node deployments, and testing Rivet
    -   [**Docker Compose**](https://rivet.gg/docs/self-hosting/docker-compose): Great for hobbyist &amp; single-node deployments
    -   [**Manual**](https://rivet.gg/docs/self-hosting/manual-deployment): Run on your own VMs without Docker
-   [**Rivet Cloud**](https://hub.rivet.gg): Fastest, most affordable, and most reliable way to deploy Rivet Actors with zero infrastructure maintenance
-   [**Rivet Enterprise**](https://rivet.gg/sales): Get a demo or have your questions answered about Rivet

## Community &amp; Support

-   Join our [**Discord**](https://rivet.gg/discord)
-   Follow us on [**X**](https://x.com/rivet_gg)
-   Follow us on [**Bluesky**](https://bsky.app/profile/rivet-gg.bsky.social)
-   File bug reports in [**GitHub Issues**](https://github.com/rivet-gg/rivet/issues)
-   Post questions &amp; ideas in [**GitHub Discussions**](https://github.com/rivet-gg/rivet/discussions)

## Technologies

-   **Rust**
-   **V8 &amp; Deno**: Actor isolate runtime
-   **FoundationDB**: Actor state
-   **CockroachDB**: OLTP
-   **ClickHouse**: Developer-facing monitoring
-   **Valkey**: Caching
-   **NATS**: Pub/sub
-   **Traefik**: Load balancers &amp; tunnels

&lt;!-- ### Diagram

![Architecture](./.github/media/architecture.png) --&gt;

## Project layout

```
docker/                      Docker-related files
    dev-full/                Full development environment setup
    monolith/                Monolithic Docker setup
    universal/               Universal multi-stage builder image
docs/                        Documentation
docs-internal/               Internal documentation
examples/                    Example projects
frontend/                    Rivet Hub &amp; other frontend components
packages/                    Project packages
    api/                     API package
    common/                  Common utilities
    infra/                   Infrastructure-related code
    services/                Service implementations
    toolchain/               Toolchain-related code
resources/                   Misc resources supporting Rivet
scripts/                     Scripts for various tasks
sdks/                        SDKs
    actor/                   Actor SDK
    api/                     Low-level SDK for calling API
site/                        Website &amp; documentation
```

## License

Apache 2.0
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[eythaann/Seelen-UI]]></title>
            <link>https://github.com/eythaann/Seelen-UI</link>
            <guid>https://github.com/eythaann/Seelen-UI</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[The Fully Customizable Desktop Environment for Windows 10/11.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eythaann/Seelen-UI">eythaann/Seelen-UI</a></h1>
            <p>The Fully Customizable Desktop Environment for Windows 10/11.</p>
            <p>Language: Rust</p>
            <p>Stars: 8,670</p>
            <p>Forks: 272</p>
            <p>Stars today: 74 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[GraphiteEditor/Graphite]]></title>
            <link>https://github.com/GraphiteEditor/Graphite</link>
            <guid>https://github.com/GraphiteEditor/Graphite</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[2D vector & raster editor that melds traditional layers & tools with a modern node-based, non-destructive, procedural workflow.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GraphiteEditor/Graphite">GraphiteEditor/Graphite</a></h1>
            <p>2D vector & raster editor that melds traditional layers & tools with a modern node-based, non-destructive, procedural workflow.</p>
            <p>Language: Rust</p>
            <p>Stars: 12,702</p>
            <p>Forks: 610</p>
            <p>Stars today: 187 stars today</p>
            <h2>README</h2><pre>

&lt;a href=&quot;https://graphite.rs/&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/9366c148-4405-484f-909a-9a3526eb9209&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/791508ab-bcd5-4e31-a3b9-1187cfd7a2f6&quot;&gt;
&lt;img alt=&quot;Graphite logo&quot; src=&quot;https://github.com/user-attachments/assets/791508ab-bcd5-4e31-a3b9-1187cfd7a2f6&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;

# Your procedural toolbox for 2D content creation

**Graphite is a free, open source vector and raster graphics engine, [available now](https://editor.graphite.rs) in alpha. Get creative with a fully nondestructive editing workflow that combines layer-based compositing with node-based generative design.**

Having begun life as a vector editor, Graphite continues evolving into a generalized, all-in-one graphics toolbox that&#039;s built more like a game engine than a conventional creative app. The editor&#039;s tools wrap its node graph core, providing user-friendly workflows for vector, raster, and beyond. Photo editing, motion graphics, digital painting, desktop publishing, and VFX compositing are additional competencies from the [roadmap](https://graphite.rs/features/#roadmap) making Graphite into a highly versatile content creation tool.

Learn more from the [website](https://graphite.rs/), subscribe to the [newsletter](https://graphite.rs/#newsletter), consider [volunteering](https://graphite.rs/volunteer/) or [donating](https://graphite.rs/donate/), and remember to give this repository a ⭐!

&lt;br /&gt;
&lt;a href=&quot;https://discord.graphite.rs/&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/ad185fac-3b48-446d-863c-2bcb0724abee&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/aa23f503-f3bf-444a-9080-8eaa19fa2fa8&quot;&gt;
&lt;img alt=&quot;Discord&quot; src=&quot;https://github.com/user-attachments/assets/aa23f503-f3bf-444a-9080-8eaa19fa2fa8&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://www.reddit.com/r/graphite/&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/d8c05686-2eb9-4ac1-8149-728c12b4e71a&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/6f32329a-4d6f-42d8-9a2f-42977c0b3c05&quot;&gt;
&lt;img alt=&quot;Reddit&quot; src=&quot;https://github.com/user-attachments/assets/6f32329a-4d6f-42d8-9a2f-42977c0b3c05&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://bsky.app/profile/graphiteeditor.bsky.social&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/c736d80c-e9bf-4591-a7e0-a7723057a906&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/3db9b0a1-5ab7-4bff-bfd3-8a4ade7b98bd&quot;&gt;
&lt;img alt=&quot;Bluesky&quot; src=&quot;https://github.com/user-attachments/assets/3db9b0a1-5ab7-4bff-bfd3-8a4ade7b98bd&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://twitter.com/graphiteeditor&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/115f04cc-e3c2-4f90-ac35-eb9edd3ca9be&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/4ed4185d-a622-418c-bbf4-a0419e690ca9&quot;&gt;
&lt;img alt=&quot;Twitter&quot; src=&quot;https://github.com/user-attachments/assets/4ed4185d-a622-418c-bbf4-a0419e690ca9&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://www.youtube.com/@GraphiteEditor&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/cbc02fad-5cbc-4715-a8e5-860198e989c7&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/d13b484d-97a8-4d9e-bbe4-c60348b3f676&quot;&gt;
&lt;img alt=&quot;YouTube&quot; src=&quot;https://github.com/user-attachments/assets/d13b484d-97a8-4d9e-bbe4-c60348b3f676&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

## Screenshots

![&quot;Isometric Fountain&quot; vector artwork](https://static.graphite.rs/content/index/gui-demo-node-graph-isometric-fountain.png)

![&quot;Marbled Mandelbrot&quot; fractal raster artwork](https://static.graphite.rs/content/index/gui-demo-fractal__3.png)

## Contributing/building the code

Are you a graphics programmer or Rust developer? Graphite aims to be one of the most approachable projects for putting your engineering skills to use in the world of open source. See [instructions here](https://graphite.rs/volunteer/guide/) for setting up the project and getting started.

*By submitting code for inclusion in the project, you are agreeing to license your changes under the Apache 2.0 license, and that you have the authority to do so. Some directories may have other licenses, like dual-licensed MIT/Apache 2.0, and code submissions to those directories mean you agree to the applicable license(s).*

## Support our mission ❤️

Graphite is 100% community built and funded. Please become a part of keeping our project alive and thriving with a [donation](https://graphite.rs/donate/) if you share a belief in our mission:

&gt; Graphite strives to unshackle the creativity of every budding artist and seasoned professional by building the best comprehensive art and design tool that&#039;s accessible to all.
&gt; 
&gt; Mission success will come when Graphite is an industry standard. A cohesive product vision and focus on innovation over imitation is the strategy that will make that possible.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[jdx/mise]]></title>
            <link>https://github.com/jdx/mise</link>
            <guid>https://github.com/jdx/mise</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[dev tools, env vars, task runner]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jdx/mise">jdx/mise</a></h1>
            <p>dev tools, env vars, task runner</p>
            <p>Language: Rust</p>
            <p>Stars: 16,033</p>
            <p>Forks: 530</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;h1&gt;&lt;a href=&quot;https://mise.jdx.dev&quot;&gt;
  &lt;img src=&quot;https://github.com/jdx/mise/assets/216188/27a8ea18-9383-4d86-a445-305b9a6248c1&quot; alt=&quot;mise-logo&quot; width=&quot;400&quot; /&gt;&lt;br /&gt;
  mise-en-place
&lt;/a&gt;&lt;/h1&gt;
&lt;!-- &lt;a href=&quot;https://mise.jdx.dev&quot;&gt;&lt;picture&gt; --&gt;
&lt;!--   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; width=&quot;617&quot; srcset=&quot;./docs/logo-dark@2x.png&quot;&gt; --&gt;
&lt;!--   &lt;img alt=&quot;mise logo&quot; width=&quot;617&quot; src=&quot;./docs/logo-light@2x.png&quot;&gt; --&gt;
&lt;!-- &lt;/picture&gt;&lt;/a&gt; --&gt;
&lt;a href=&quot;https://crates.io/crates/mise&quot;&gt;&lt;img alt=&quot;Crates.io&quot; src=&quot;https://img.shields.io/crates/v/mise?style=for-the-badge&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/jdx/mise/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;GitHub&quot; src=&quot;https://img.shields.io/github/license/jdx/mise?color=%2344CC11&amp;style=for-the-badge&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/jdx/mise/actions/workflows/test.yml&quot;&gt;&lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/jdx/mise/test.yml?style=for-the-badge&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://discord.gg/mABnUDvP57&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1066429325269794907?color=%23738ADB&amp;style=for-the-badge&quot;&gt;&lt;/a&gt;
&lt;p&gt;&lt;em&gt;The front-end to your dev env.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;

## What is it?

- Like [asdf](https://asdf-vm.com) (or [nvm](https://github.com/nvm-sh/nvm) or [pyenv](https://github.com/pyenv/pyenv) but for any language) it manages [dev tools](https://mise.jdx.dev/dev-tools/) like node, python, cmake, terraform, and [hundreds more](https://mise.jdx.dev/registry.html).
- Like [direnv](https://github.com/direnv/direnv) it manages [environment variables](https://mise.jdx.dev/environments/) for different project directories.
- Like [make](https://www.gnu.org/software/make/manual/make.html) it manages [tasks](https://mise.jdx.dev/tasks/) used to build and test projects.

## Demo

The following demo shows how to install and use `mise` to manage multiple versions of `node` on the same system.
Note that calling `which node` gives us a real path to node, not a shim.

It also shows that you can use `mise` to install and many other tools such as `jq`, `terraform`, or `go`.

[![demo](./docs/tapes/demo.gif)](https://mise.jdx.dev/demo.html)

See [demo transcript](https://mise.jdx.dev/demo.html).

## Quickstart

### Install mise

See [Getting started](https://mise.jdx.dev/getting-started.html) for more options.

```sh-session
$ curl https://mise.run | sh
$ ~/.local/bin/mise --version
2025.6.4 macos-arm64 (a1b2d3e 2025-06-13)
```

Hook mise into your shell (pick the right one for your shell):

```sh-session
# note this assumes mise is located at ~/.local/bin/mise
# which is what https://mise.run does by default
echo &#039;eval &quot;$(~/.local/bin/mise activate bash)&quot;&#039; &gt;&gt; ~/.bashrc
echo &#039;eval &quot;$(~/.local/bin/mise activate zsh)&quot;&#039; &gt;&gt; ~/.zshrc
echo &#039;~/.local/bin/mise activate fish | source&#039; &gt;&gt; ~/.config/fish/config.fish
echo &#039;~/.local/bin/mise activate mise activate pwsh | Out-String | Invoke-Expression&#039; &gt;&gt; ~/.config/powershell/Microsoft.PowerShell_profile.ps1
```

### Execute commands with specific tools

```sh-session
$ mise exec node@22 -- node -v
mise node@22.x.x ✓ installed
v22.x.x
```

### Install tools

```sh-session
$ mise use --global node@22 go@1
$ node -v
v22.x.x
$ go version
go version go1.x.x macos/arm64
```

See [dev tools](https://mise.jdx.dev/dev-tools/) for more examples.

### Manage environment variables

```toml
# mise.toml
[env]
SOME_VAR = &quot;foo&quot;
```

```sh-session
$ mise set SOME_VAR=bar
$ echo $SOME_VAR
bar
```

Note that `mise` can also [load `.env` files](https://mise.jdx.dev/environments/#env-directives).

### Run tasks

```toml
# mise.toml
[tasks.build]
description = &quot;build the project&quot;
run = &quot;echo building...&quot;
```

```sh-session
$ mise run build
building...
```

See [tasks](https://mise.jdx.dev/tasks/) for more information.

### Example mise project

Here is a combined example to give you an idea of how you can use mise to manage your a project&#039;s tools, environment, and tasks.

```toml
# mise.toml
[tools]
terraform = &quot;1&quot;
aws-cli = &quot;2&quot;

[env]
TF_WORKSPACE = &quot;development&quot;
AWS_REGION = &quot;us-west-2&quot;
AWS_PROFILE = &quot;dev&quot;

[tasks.plan]
description = &quot;Run terraform plan with configured workspace&quot;
run = &quot;&quot;&quot;
terraform init
terraform workspace select $TF_WORKSPACE
terraform plan
&quot;&quot;&quot;

[tasks.validate]
description = &quot;Validate AWS credentials and terraform config&quot;
run = &quot;&quot;&quot;
aws sts get-caller-identity
terraform validate
&quot;&quot;&quot;

[tasks.deploy]
description = &quot;Deploy infrastructure after validation&quot;
depends = [&quot;validate&quot;, &quot;plan&quot;]
run = &quot;terraform apply -auto-approve&quot;
```

Run it with:

```sh-session
mise install # install tools specified in mise.toml
mise run deploy
```

Find more examples in the [mise cookbook](https://mise.jdx.dev/mise-cookbook/).

## Full Documentation

See [mise.jdx.dev](https://mise.jdx.dev)

## Contributors

[![Contributors](https://contrib.rocks/image?repo=jdx/mise)](https://github.com/jdx/mise/graphs/contributors)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[juspay/hyperswitch]]></title>
            <link>https://github.com/juspay/hyperswitch</link>
            <guid>https://github.com/juspay/hyperswitch</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[An open source payments switch written in Rust to make payments fast, reliable and affordable]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/juspay/hyperswitch">juspay/hyperswitch</a></h1>
            <p>An open source payments switch written in Rust to make payments fast, reliable and affordable</p>
            <p>Language: Rust</p>
            <p>Stars: 20,740</p>
            <p>Forks: 3,406</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/imgs/hyperswitch-logo-dark.svg#gh-dark-mode-only&quot; alt=&quot;Hyperswitch-Logo&quot; width=&quot;40%&quot; /&gt;
  &lt;img src=&quot;./docs/imgs/hyperswitch-logo-light.svg#gh-light-mode-only&quot; alt=&quot;Hyperswitch-Logo&quot; width=&quot;40%&quot; /&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Composable Open-Source Payments Infrastructure&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/gifs/quickstart.gif&quot; alt=&quot;Quickstart demo&quot; /&gt;
&lt;/p&gt;


&lt;!-- @import &quot;[TOC]&quot; {cmd=&quot;toc&quot; depthFrom=1 depthTo=6 orderedList=false} --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/actions?query=workflow%3ACI+branch%3Amain&quot;&gt;
    &lt;img src=&quot;https://github.com/juspay/hyperswitch/workflows/CI-push/badge.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/juspay/hyperswitch&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Made_in-Rust-orange&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.linkedin.com/company/hyperswitch/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-hyperswitch-blue?logo=linkedin&amp;labelColor=grey&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://x.com/hyperswitchio&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-%40hyperswitchio-white?logo=x&amp;labelColor=grey&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://join.slack.com/t/hyperswitch-io/shared_invite/zt-2jqxmpsbm-WXUENx022HjNEy~Ark7Orw&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/chat-on_slack-blue?logo=slack&amp;labelColor=grey&amp;color=%233f0e40&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;hr/&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;📁 Table of Contents&lt;/strong&gt;&lt;/summary&gt;

- [What Can I Do with Hyperswitch?](#-what-can-i-do-with-hyperswitch)
- [Quickstart (Local Setup)](#-quickstart-local-setup)
- [Cloud Deployment](#cloud-deployment)
- [Hosted Sandbox (No Setup Required)](#hosted-sandbox-no-setup-required)
- [Why Hyperswitch?](#-why-hyperswitch)
- [Architectural Overview](#architectural-overview)
- [Our Vision](#our-vision)
- [Community &amp; Contributions](#community--contributions)
- [Feature Requests &amp; Bugs](#feature-requests--bugs)
- [Versioning](#versioning)
- [License](#copyright-and-license)
- [Team Behind Hyperswitch](#team-behind-hyperswitch)

&lt;/details&gt;

&lt;summary&gt;&lt;h2&gt; What Can I Do with Hyperswitch?&lt;/h2&gt;&lt;/summary&gt;

Hyperswitch offers a modular, open-source payments infrastructure designed for flexibility and control. Apart from our Payment Suite offering, this solution allows businesses to pick and integrate only the modules they need on top of their existing payment stack — without unnecessary complexity or vendor lock-in.

Each module is independent and purpose-built to optimize different aspects of payment processing.

&lt;h3&gt; Learn More About The Payment Modules &lt;/h3&gt;
&lt;details&gt;

- **Cost Observability**  
  Advanced observability tools to audit, monitor, and optimize your payment costs. Detect hidden fees, downgrades, and penalties with self-serve dashboards and actionable insights.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/ai-powered-cost-observability)_

- **Revenue Recovery**  
  Combat passive churn with intelligent retry strategies tuned by card bin, region, method, and more. Offers fine-grained control over retry algorithms, penalty budgets, and recovery transparency.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/revenue-recovery)_

- **Vault**  
  A PCI-compliant vault service to store cards, tokens, wallets, and bank credentials. Provides a unified, secure, and reusable store of customer-linked payment methods.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/vault)_

- **Intelligent Routing**  
  Route each transaction to the PSP with the highest predicted auth rate. Reduce retries, avoid downtime, and minimize latency while maximizing first attempt success.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/intelligent-routing)_

- **Reconciliation**  
  Automate 2-way and 3-way reconciliation with backdated support, staggered scheduling, and customizable outputs. Reduces manual ops effort and increases audit confidence.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/reconciliation)_

- **Alternate Payment Methods**  
  Drop-in widgets for PayPal, Apple Pay, Google Pay, Samsung Pay, Pay by Bank, and BNPL providers like Klarna. Maximizes conversions with seamless one-click checkout.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/enable-alternate-payment-method-widgets)_

&lt;/details&gt;

## Quickstart 

&lt;h3&gt; Local Setup via Docker &lt;/h3&gt;

```bash
# One-click local setup

git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch

cd hyperswitch

scripts/setup.sh
```
&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;This script: &lt;/strong&gt;&lt;/summary&gt;

  - Detects Docker/Podman  
  - Offers multiple deployment profiles:
    - **Standard**: App server + Control Center  
    - **Full**: Includes monitoring + schedulers  
    - **Minimal**: Standalone App server  
  - Provides access links when done

  If you need further help, check out our [video tutorial](https://docs.hyperswitch.io/hyperswitch-open-source/overview/unified-local-setup-using-docker).  

  👉 After setup, [configure a connector](https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/using-hyperswitch-control-center#add-a-payment-processor) and [test a payment](https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/test-a-payment).
&lt;/details&gt;


&lt;h3&gt;Hosted Sandbox (No Setup Required)&lt;/h3&gt;

Hyperswitch offers a fully hosted sandbox environment that requires no setup. You can explore the Control Center, configure payment connectors, and test payments directly from the UI.

   &lt;a href=&quot;https://app.hyperswitch.io&quot;&gt;
     &lt;img src=&quot;https://github.com/juspay/hyperswitch/blob/main/docs/imgs/try-the-sandbox.png?raw=true&quot; height=&quot;35&quot;&gt;
   &lt;/a&gt;


&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt; What you can do in the Hosted Sandbox&lt;/strong&gt;&lt;/summary&gt;

  - Access the full Control Center  
  - Configure payment connectors  
  - View logs, routing rules, and retry strategies  
  - Try payments directly from the UI  
&lt;/details&gt;

&lt;h3&gt;&lt;strong&gt;Cloud Deployment&lt;/strong&gt;&lt;/h3&gt;

You can deploy to AWS, GCP, or Azure using Helm or CDK scripts. Fastest path:

Click to deploy via AWS:

   &lt;a href=&quot;https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=HyperswitchBootstarp&amp;templateURL=https://hyperswitch-synth.s3.eu-central-1.amazonaws.com/hs-starter-config.yaml&quot;&gt;
     &lt;img src=&quot;https://github.com/juspay/hyperswitch/blob/main/docs/imgs/aws_button.png?raw=true&quot; height=&quot;35&quot;&gt;
   &lt;/a&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Cloud Deployment Instructions&lt;/strong&gt;&lt;/summary&gt;

  1. Click the AWS deployment button above to launch the stack.  
  2. Follow the guided steps in the AWS Console (approx. 30–45 mins).  

  ✅ This setup provisions Hyperswitch on your cloud account using CloudFormation.  

  📘 For full instructions and Helm-based deployments, check out the  
  &lt;a href=&quot;https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm&quot;&gt;Cloud Install Guide&lt;/a&gt;.
&lt;/details&gt;


&lt;a href=&quot;#architectural-overview&quot;&gt;
  &lt;h2 id=&quot;architectural-overview&quot;&gt;Architectural Overview&lt;/h2&gt;
&lt;/a&gt;
&lt;img src=&quot;./docs/imgs/features.png&quot; /&gt;
&lt;img src=&quot;./docs/imgs/non-functional-features.png&quot; /&gt;
&lt;img src=&quot;./docs/imgs/hyperswitch-architecture-v1.png&quot; /&gt;

## Why Hyperswitch?

Hyperswitch is a commercial open-source payments stack purpose-built for scale, flexibility, and developer experience. Designed with a modular architecture, Hyperswitch lets you pick only the components you need—whether it’s routing, retries, vaulting, or observability—without vendor lock-in or bloated integrations.

Built in Rust for performance and reliability, Hyperswitch supports global payment methods (cards, wallets, BNPL, UPI, Pay by Bank), exposes smart routing and retry logic, and provides a visual workflow builder in the Control Center. Whether you&#039;re integrating a full payment suite or augmenting an existing stack with a single module, Hyperswitch meets you where you are.

&lt;strong&gt;“Linux for Payments”&lt;/strong&gt; — Hyperswitch is a well-architected reference for teams who want to own their payments stack.

We believe in:

- &lt;strong&gt; Embracing Payment Diversity:&lt;/strong&gt; Innovation comes from enabling choice—across payment methods, processors, and flows.

- &lt;strong&gt; Open Source by Default:&lt;/strong&gt; Transparency drives trust and builds better, reusable software.

- &lt;strong&gt; Community-Driven Development:&lt;/strong&gt; Our roadmap is shaped by real-world use cases and contributors. 

- &lt;strong&gt; Systems-Level Engineering:&lt;/strong&gt; We hold ourselves to a high bar for reliability, security, and performance.

- &lt;strong&gt; Maximizing Value Creation:&lt;/strong&gt; For developers, customers, and partners alike.

- &lt;strong&gt; Community-Driven, Enterprise-Tested:&lt;/strong&gt; Hyperswitch is built in the open with real-world feedback from developers and contributors, and maintained by Juspay, the team powering payment infrastructure for 400+ leading enterprises worldwide.

## Contributing

We welcome contributors from around the world to help build Hyperswitch. Whether you&#039;re fixing bugs, improving documentation, or adding new features, your help is appreciated.

Please read our [contributing guidelines](https://github.com/juspay/hyperswitch/blob/main/docs/CONTRIBUTING.md) to get started.

Join the conversation on [Slack](https://join.slack.com/t/hyperswitch-io/shared_invite/zt-2jqxmpsbm-WXUENx022HjNEy~Ark7Orw) or explore open issues on [GitHub](https://github.com/juspay/hyperswitch/issues).

&lt;a href=&quot;#feature-requests&quot;&gt;
  &lt;h2 id=&quot;feature-requests&quot;&gt;Feature requests &amp; Bugs&lt;/h2&gt;
&lt;/a&gt;

For new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our [GitHub Discussions](https://github.com/juspay/hyperswitch/discussions)

For reporting a bug, please read the issue guidelines and search for [existing and closed issues](https://github.com/juspay/hyperswitch/issues). If your problem or idea is not addressed yet, please [open a new issue](https://github.com/juspay/hyperswitch/issues/new/choose).

&lt;a href=&quot;#versioning&quot;&gt;
  &lt;h2 id=&quot;versioning&quot;&gt;Versioning&lt;/h2&gt;
&lt;/a&gt;

Check the [CHANGELOG.md](./CHANGELOG.md) file for details.

&lt;a href=&quot;#copyright-and-license&quot;&gt;
  &lt;h2 id=&quot;copyright-and-license&quot;&gt;Copyright and License&lt;/h2&gt;
&lt;/a&gt;

This product is licensed under the [Apache 2.0 License](LICENSE).

&lt;a href=&quot;#team-behind-hyperswitch&quot;&gt;
  &lt;h2 id=&quot;team-behind-hyperswitch&quot;&gt;Team behind Hyperswitch&lt;/h2&gt;
&lt;/a&gt;

The core team of 150+ engineers building Hyperswitch. Keep up the great work! 🥂

&lt;a href=&quot;https://github.com/juspay/hyperswitch/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=juspay/hyperswitch&quot; alt=&quot;Contributors&quot;/&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[starship/starship]]></title>
            <link>https://github.com/starship/starship</link>
            <guid>https://github.com/starship/starship</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[☄🌌️ The minimal, blazing-fast, and infinitely customizable prompt for any shell!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/starship/starship">starship/starship</a></h1>
            <p>☄🌌️ The minimal, blazing-fast, and infinitely customizable prompt for any shell!</p>
            <p>Language: Rust</p>
            <p>Stars: 49,306</p>
            <p>Forks: 2,134</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img
    width=&quot;400&quot;
    src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/logo.png&quot;
    alt=&quot;Starship – Cross-shell prompt&quot;
  /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/starship/starship/actions&quot;
    &gt;&lt;img
      src=&quot;https://img.shields.io/github/actions/workflow/status/starship/starship/workflow.yml?branch=master&amp;label=workflow&amp;style=flat-square&quot;
      alt=&quot;GitHub Actions workflow status&quot;
  /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://crates.io/crates/starship&quot;
    &gt;&lt;img
      src=&quot;https://img.shields.io/crates/v/starship?style=flat-square&quot;
      alt=&quot;Crates.io version&quot;
  /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://repology.org/project/starship/versions&quot;
    &gt;&lt;img
      src=&quot;https://img.shields.io/repology/repositories/starship?label=in%20repositories&amp;style=flat-square&quot;
      alt=&quot;Packaging status&quot;/&gt;&lt;/a
  &gt;&lt;br /&gt;
  &lt;a href=&quot;https://discord.gg/starship&quot;
    &gt;&lt;img
      src=&quot;https://img.shields.io/discord/567163873606500352?label=discord&amp;logoColor=white&amp;style=flat-square&quot;
      alt=&quot;Chat on Discord&quot;
  /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/StarshipPrompt&quot;
    &gt;&lt;img
      src=&quot;https://img.shields.io/badge/twitter-@StarshipPrompt-1DA1F3?style=flat-square&quot;
      alt=&quot;Follow @StarshipPrompt on Twitter&quot;
  /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://stand-with-ukraine.pp.ua&quot;
    &gt;&lt;img
      src=&quot;https://raw.githubusercontent.com/vshymanskyy/StandWithUkraine/main/badges/StandWithUkraineFlat.svg&quot;
      alt=&quot;Stand With Ukraine&quot;
  /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://starship.rs&quot;&gt;Website&lt;/a&gt;
  ·
  &lt;a href=&quot;#🚀-installation&quot;&gt;Installation&lt;/a&gt;
  ·
  &lt;a href=&quot;https://starship.rs/config/&quot;&gt;Configuration&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/starship/starship/blob/master/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-us.png&quot;
      alt=&quot;English&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/de-DE/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-de.png&quot;
      alt=&quot;Deutsch&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/es-ES/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-es.png&quot;
      alt=&quot;Español&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/fr-FR/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-fr.png&quot;
      alt=&quot;Français&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/id-ID/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-id.png&quot;
      alt=&quot;Bahasa Indonesia&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/it-IT/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-it.png&quot;
      alt=&quot;Italiano&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/ja-JP/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-jp.png&quot;
      alt=&quot;日本語&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/pt-BR/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-br.png&quot;
      alt=&quot;Português do Brasil&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/ru-RU/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-ru.png&quot;
      alt=&quot;Русский&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/uk-UA/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-ua.png&quot;
      alt=&quot;Українська&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/vi-VN/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-vn.png&quot;
      alt=&quot;Tiếng Việt&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/zh-CN/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-cn.png&quot;
      alt=&quot;简体中文&quot;
  /&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a
    href=&quot;https://github.com/starship/starship/blob/master/docs/zh-TW/guide/README.md&quot;
    &gt;&lt;img
      height=&quot;20&quot;
      src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/flag-tw.png&quot;
      alt=&quot;繁體中文&quot;
  /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h1&gt;&lt;/h1&gt;

&lt;img
  src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/demo.gif&quot;
  alt=&quot;Starship with iTerm2 and the Snazzy theme&quot;
  width=&quot;50%&quot;
  align=&quot;right&quot;
/&gt;

**The minimal, blazing-fast, and infinitely customizable prompt for any shell!**

- **Fast:** it&#039;s fast – _really really_ fast! 🚀
- **Customizable:** configure every aspect of your prompt.
- **Universal:** works on any shell, on any operating system.
- **Intelligent:** shows relevant information at a glance.
- **Feature rich:** support for all your favorite tools.
- **Easy:** quick to install – start using it in minutes.

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://starship.rs/config/&quot;&gt;&lt;strong&gt;Explore the Starship docs&amp;nbsp;&amp;nbsp;▶&lt;/strong&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;a name=&quot;🚀-installation&quot;&gt;&lt;/a&gt;

## 🚀 Installation

### Prerequisites

- A [Nerd Font](https://www.nerdfonts.com/) installed and enabled in your terminal (for example, try the [FiraCode Nerd Font](https://www.nerdfonts.com/font-downloads)).

### Step 1. Install Starship

Select your operating system from the list below to view installation instructions:

&lt;details&gt;
&lt;summary&gt;Android&lt;/summary&gt;

Install Starship using any of the following package managers:

| Repository | Instructions           |
| ---------- | ---------------------- |
| [Termux]   | `pkg install starship` |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;BSD&lt;/summary&gt;

Install Starship using any of the following package managers:

| Distribution | Repository      | Instructions                      |
| ------------ | --------------- | --------------------------------- |
| **_Any_**    | **[crates.io]** | `cargo install starship --locked` |
| FreeBSD      | [FreshPorts]    | `pkg install starship`            |
| NetBSD       | [pkgsrc]        | `pkgin install starship`          |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Linux&lt;/summary&gt;

Install the latest version for your system:

```sh
curl -sS https://starship.rs/install.sh | sh
```

Alternatively, install Starship using any of the following package managers:

| Distribution       | Repository              | Instructions                                                  |
| ------------------ | ----------------------- | ------------------------------------------------------------- |
| **_Any_**          | **[crates.io]**         | `cargo install starship --locked`                             |
| _Any_              | [conda-forge]           | `conda install -c conda-forge starship`                       |
| _Any_              | [Linuxbrew]             | `brew install starship`                                       |
| Alpine Linux 3.13+ | [Alpine Linux Packages] | `apk add starship`                                            |
| Arch Linux         | [Arch Linux Extra]      | `pacman -S starship`                                          |
| CentOS 7+          | [Copr]                  | `dnf copr enable atim/starship` &lt;br /&gt; `dnf install starship` |
| Debian 13+         | [Debian Main]           | `apt install starship`                                        |
| Gentoo             | [Gentoo Packages]       | `emerge app-shells/starship`                                  |
| Manjaro            |                         | `pacman -S starship`                                          |
| NixOS              | [nixpkgs]               | `nix-env -iA nixpkgs.starship`                                |
| openSUSE           | [OSS]                   | `zypper in starship`                                          |
| Ubuntu 25.04+      | [Ubuntu Universe]       | `apt install starship`                                        |
| Void Linux         | [Void Linux Packages]   | `xbps-install -S starship`                                    |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;macOS&lt;/summary&gt;

Install the latest version for your system:

```sh
curl -sS https://starship.rs/install.sh | sh
```

Alternatively, install Starship using any of the following package managers:

| Repository      | Instructions                            |
| --------------- | --------------------------------------- |
| **[crates.io]** | `cargo install starship --locked`       |
| [conda-forge]   | `conda install -c conda-forge starship` |
| [Homebrew]      | `brew install starship`                 |
| [MacPorts]      | `port install starship`                 |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Windows&lt;/summary&gt;

Install the latest version for your system with the MSI-installers from the [releases section](https://github.com/starship/starship/releases/latest).

Install Starship using any of the following package managers:

| Repository      | Instructions                            |
| --------------- | --------------------------------------- |
| **[crates.io]** | `cargo install starship --locked`       |
| [Chocolatey]    | `choco install starship`                |
| [conda-forge]   | `conda install -c conda-forge starship` |
| [Scoop]         | `scoop install starship`                |
| [winget]        | `winget install --id Starship.Starship` |

&lt;/details&gt;

### Step 2. Set up your shell to use Starship

Configure your shell to initialize starship. Select yours from the list below:

&lt;details&gt;
&lt;summary&gt;Bash&lt;/summary&gt;

Add the following to the end of `~/.bashrc`:

```sh
eval &quot;$(starship init bash)&quot;
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Cmd&lt;/summary&gt;

You need to use [Clink](https://chrisant996.github.io/clink/clink.html) (v1.2.30+) with Cmd.
Create a file at this path `%LocalAppData%\clink\starship.lua` with the following contents:

```lua
load(io.popen(&#039;starship init cmd&#039;):read(&quot;*a&quot;))()
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Elvish&lt;/summary&gt;

Add the following to the end of `~/.elvish/rc.elv`:

```sh
eval (starship init elvish)
```

Note: Only Elvish v0.18+ is supported

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Fish&lt;/summary&gt;

Add the following to the end of `~/.config/fish/config.fish`:

```fish
starship init fish | source
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Ion&lt;/summary&gt;

Add the following to the end of `~/.config/ion/initrc`:

```sh
eval $(starship init ion)
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Nushell&lt;/summary&gt;

Add the following to the end of your Nushell configuration (find it by running `$nu.config-path` in Nushell):

```sh
mkdir ($nu.data-dir | path join &quot;vendor/autoload&quot;)
starship init nu | save -f ($nu.data-dir | path join &quot;vendor/autoload/starship.nu&quot;)
```

Note: Only Nushell v0.96+ is supported

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;PowerShell&lt;/summary&gt;

Add the following to the end of your PowerShell configuration (find it by running `$PROFILE`):

```powershell
Invoke-Expression (&amp;starship init powershell)
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Tcsh&lt;/summary&gt;

Add the following to the end of `~/.tcshrc`:

```sh
eval `starship init tcsh`
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Xonsh&lt;/summary&gt;

Add the following to the end of `~/.xonshrc`:

```python
execx($(starship init xonsh))
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Zsh&lt;/summary&gt;

Add the following to the end of `~/.zshrc`:

```sh
eval &quot;$(starship init zsh)&quot;
```

&lt;/details&gt;

### Step 3. Configure Starship

Start a new shell instance, and you should see your beautiful new shell prompt.
If you&#039;re happy with the defaults, enjoy!

If you&#039;re looking to further customize Starship:

- **[Configuration](https://starship.rs/config/)** – learn how to configure Starship to tweak your prompt to your liking

- **[Presets](https://starship.rs/presets/)** – get inspired by the pre-built configuration of others

## 🤝 Contributing

We are always looking for contributors of **all skill levels**! If you&#039;re looking to ease your way into the project, try out a [good first issue](https://github.com/starship/starship/labels/🌱%20good%20first%20issue).

If you are fluent in a non-English language, we greatly appreciate any help keeping our docs translated and up-to-date in other languages. If you would like to help, translations can be contributed on the [Starship Crowdin](https://translate.starship.rs/).

If you are interested in helping contribute to starship, please take a look at our [Contributing Guide](https://github.com/starship/starship/blob/master/CONTRIBUTING.md). Also, feel free to drop into our [Discord server](https://discord.gg/8Jzqu3T) and say hi. 👋

## 💭 Inspired By

Please check out these previous works that helped inspire the creation of starship. 🙏

- **[denysdovhan/spaceship-prompt](https://github.com/denysdovhan/spaceship-prompt)** – A ZSH prompt for astronauts.

- **[denysdovhan/robbyrussell-node](https://github.com/denysdovhan/robbyrussell-node)** – Cross-shell robbyrussell theme written in JavaScript.

- **[reujab/silver](https://github.com/reujab/silver)** – A cross-shell customizable powerline-like prompt with icons.

## ❤️ Sponsors

Support this project by [becoming a sponsor](https://github.com/sponsors/starship). Your name or logo will show up here with a link to your website.

## 🔒 Code Signing Policy

Free code signing provided by [SignPath.io], certificate by [SignPath Foundation].

Code Signing Roles:

- Reviewers: [Astronauts](https://github.com/orgs/starship/teams/astronauts)
- Approvers and Authors: [Mission Control](https://github.com/orgs/starship/teams/mission-control)

This program will not transfer any information to other networked systems unless specifically requested by the user or the person installing or operating it.

&lt;p align=&quot;center&quot;&gt;
    &lt;br&gt;
    &lt;img width=&quot;100&quot; src=&quot;https://raw.githubusercontent.com/starship/starship/master/media/icon.png&quot; alt=&quot;Starship rocket icon&quot;&gt;
&lt;/p&gt;

## 📝 License

Copyright © 2019-present, [Starship Contributors](https://github.com/starship/starship/graphs/contributors).&lt;br&gt;
This project is [ISC](https://github.com/starship/starship/blob/master/LICENSE) licensed.

[alpine linux packages]: https://pkgs.alpinelinux.org/packages?name=starship
[arch linux extra]: https://archlinux.org/packages/extra/x86_64/starship
[chocolatey]: https://community.chocolatey.org/packages/starship
[conda-forge]: https://anaconda.org/conda-forge/starship
[copr]: https://copr.fedorainfracloud.org/coprs/atim/starship
[crates.io]: https://crates.io/crates/starship
[debian main]: https://sources.debian.org/src/starship/1.22.1-1/
[freshports]: https://www.freshports.org/shells/starship
[gentoo packages]: https://packages.gentoo.org/packages/app-shells/starship
[linuxbrew]: https://formulae.brew.sh/formula/starship
[homebrew]: https://formulae.brew.sh/formula/starship
[macports]: https://ports.macports.org/port/starship
[nixpkgs]: https://github.com/NixOS/nixpkgs/blob/master/pkgs/by-name/st/starship/package.nix
[OSS]: https://software.opensuse.org/package/starship
[pkgsrc]: https://pkgsrc.se/shells/starship
[scoop]: https://github.com/ScoopInstaller/Main/blob/master/bucket/starship.json
[SignPath Foundation]: https://signpath.org
[SignPath.io]: https://signpath.io
[termux]: https://github.com/termux/termux-packages/tree/master/packages/starship
[ubuntu universe]: https://packages.ubuntu.com/source/plucky/starship
[void linux packages]: https://github.com/void-linux/void-packages/tree/master/srcpkgs/starship
[winget]: https://github.com/microsoft/winget-pkgs/tree/master/manifests/s/Starship/Starship
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[garyttierney/me3]]></title>
            <link>https://github.com/garyttierney/me3</link>
            <guid>https://github.com/garyttierney/me3</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[A framework for modding and instrumenting games.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/garyttierney/me3">garyttierney/me3</a></h1>
            <p>A framework for modding and instrumenting games.</p>
            <p>Language: Rust</p>
            <p>Stars: 179</p>
            <p>Forks: 12</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

&lt;br /&gt;
&lt;div align=&quot;center&quot;&gt;


  &lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;distribution/assets/me3.png&quot; /&gt;
  &lt;/p&gt;
  &lt;h2 align=&quot;center&quot;&gt;me&lt;sup&gt;3&lt;/sup&gt;&lt;/h2&gt;

  &lt;p align=&quot;center&quot;&gt;
    A framework for modifying and instrumenting games.
    &lt;br /&gt;
    &lt;a href=&quot;https://me3.readthedocs.io/&quot;&gt;&lt;strong&gt;Explore the docs »&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://github.com/garyttierney/me3/discussions/categories/bug-reports&quot;&gt;Report Bug&lt;/a&gt;
    ·
    &lt;a href=&quot;https://github.com/garyttierney/me3/discussions/categories/ideas&quot;&gt;Request Feature&lt;/a&gt;
  &lt;/p&gt;

[![Discussions][discussions-shield]][discussions-url]
[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![MIT + Apache-2.0 License][license-shield]][license-url]

&lt;/div&gt;


- [About The Project](#about-the-project)
- [Installation](#installation)
- [Developer Quickstart](#developer-quickstart)
  - [Prerequisites](#prerequisites)
  - [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)
- [Contact](#contact)
- [Acknowledgments](#acknowledgments)

&lt;!-- ABOUT THE PROJECT --&gt;

## About The Project

me3 is a tool that extends the functionality of FROMSOTWARE games running on Windows and Linux via Proton.

Currently it supports the following titles:

- ELDEN RING
- ELDEN RING: NIGHTREIGN
- Armored Core VI: Fires of Rubicon

## Installation

&gt; [!IMPORTANT]
&gt; Follow the [user guide](https://me3.readthedocs.io/en/latest/#quickstart)

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

&lt;!-- GETTING STARTED --&gt;

## Developer Quickstart

### Prerequisites

- Cargo
  - Windows: download and run [rustup‑init.exe][rustup-installer] then follow the onscreen instructions.
  - Linux:

    ```bash
    curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
    ```

- Visual Studio C++ Build Tools
  - Windows: download and run [vs_BuildTools.exe][buildtools-installer] then follow the onscreen instructions.
  - Linux: Acquire the Windows SDK using `xwin`

    ```bash
    cargo install xwin &amp;&amp; xwin --accept-license splat --output ~/.xwin
    ```

    And configure Cargo to link with lld-link and use the binaries from xwin in `~/.cargo/config.toml`

    ```toml
    [target.x86_64-pc-windows-msvc]
    linker = &quot;lld-link&quot;
    runner = &quot;wine&quot;
    rustflags = [
      &quot;-Lnative=/home/gtierney/.xwin/crt/lib/x86_64&quot;,
      &quot;-Lnative=/home/gtierney/.xwin/sdk/lib/um/x86_64&quot;,
      &quot;-Lnative=/home/gtierney/.xwin/sdk/lib/ucrt/x86_64&quot;
    ]
    ```

### Usage

1. Clone the repo

   ```sh
   git clone https://github.com/garyttierney/me3.git
   ```

2. Build the binaries

   ```sh
   cargo build [--release]
   ```

3. Attach the sample host DLL to your game

   ```sh
   cargo run -p me3-cli -- launch -g elden-ring
   ```

   &lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

&lt;!-- CONTRIBUTING --&gt;

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md)

&lt;!-- LICENSE --&gt;

## License

With the exception of the [me3 logo](distribution/assets/me3.ico), this project is distributed under the terms of both the Apache Software License 2.0 and MIT License. See [LICENSE-APACHE] and [LICENSE-MIT] for more information.

The me3 logo is not available under any license - all rights are reserved.

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

&lt;!-- CONTACT --&gt;

## Contact

Project Link: [https://github.com/garyttierney/me3](https://github.com/garyttierney/me3)

Discussions Board: [https://github.com/garyttierney/me3/discussions](https://github.com/garyttierney/me3/discussions)

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

&lt;!-- ACKNOWLEDGMENTS --&gt;

## Acknowledgments

&lt;!-- markdown-link-check-disable --&gt;
- [Mod Engine](https://github.com/katalash/ModEngine/tree/master/DS3ModEngine) - prior art for runtime modification of FROMSOFTWARE games.
- [Mod Organizer 2](https://github.com/ModOrganizer2/modorganizer/) - inspiration for the VFS framework.
- [Elden Ring Reforged](https://www.nexusmods.com/eldenring/mods/541) - provided invaluable feedback on the end-user perspective
- [Dassav](https://github.com/dasaav-dsv) - work on compatibility across a variety of FROMSOFTWARE titles.
- [Skadi](https://twitter.com/Skadi_sbw) - [me3 icon](./distribution/assets/me3.png) artwork
&lt;!-- markdown-link-check-enable --&gt;

&lt;p align=&quot;right&quot;&gt;(&lt;a href=&quot;#readme-top&quot;&gt;back to top&lt;/a&gt;)&lt;/p&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[rustup-installer]: https://static.rust-lang.org/dist/rust-1.87.0-x86_64-pc-windows-msvc.msi
[buildtools-installer]: https://aka.ms/vs/17/release/vs_BuildTools.exe
[discussions-shield]: https://img.shields.io/github/discussions/garyttierney/me3
[discussions-url]: https://github.com/garyttierney/me3/discussions
[contributors-shield]: https://img.shields.io/github/contributors/garyttierney/me3.svg?style=flat
[contributors-url]: https://github.com/garyttierney/me3/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/garyttierney/me3.svg?style=flat
[forks-url]: https://github.com/garyttierney/me3/network/members
[license-shield]: https://img.shields.io/badge/license-MIT%2FApache--2.0-green?style=flat
[license-url]: https://github.com/garyttierney/me3/blob/main/LICENSE-APACHE
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[huggingface/text-embeddings-inference]]></title>
            <link>https://github.com/huggingface/text-embeddings-inference</link>
            <guid>https://github.com/huggingface/text-embeddings-inference</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[A blazing fast inference solution for text embeddings models]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/text-embeddings-inference">huggingface/text-embeddings-inference</a></h1>
            <p>A blazing fast inference solution for text embeddings models</p>
            <p>Language: Rust</p>
            <p>Stars: 3,685</p>
            <p>Forks: 271</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# Text Embeddings Inference

&lt;a href=&quot;https://github.com/huggingface/text-embeddings-inference&quot;&gt;
  &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/huggingface/text-embeddings-inference?style=social&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://huggingface.github.io/text-embeddings-inference&quot;&gt;
  &lt;img alt=&quot;Swagger API documentation&quot; src=&quot;https://img.shields.io/badge/API-Swagger-informational&quot;&gt;
&lt;/a&gt;

A blazing fast inference solution for text embeddings models.

Benchmark for [BAAI/bge-base-en-v1.5](https://huggingface.co/BAAI/bge-base-en-v1.5) on an Nvidia A10 with a sequence
length of 512 tokens:

&lt;p&gt;
  &lt;img src=&quot;assets/bs1-lat.png&quot; width=&quot;400&quot; /&gt;
  &lt;img src=&quot;assets/bs1-tp.png&quot; width=&quot;400&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;img src=&quot;assets/bs32-lat.png&quot; width=&quot;400&quot; /&gt;
  &lt;img src=&quot;assets/bs32-tp.png&quot; width=&quot;400&quot; /&gt;
&lt;/p&gt;

&lt;/div&gt;

## Table of contents

- [Get Started](#get-started)
    - [Supported Models](#supported-models)
    - [Docker](#docker)
    - [Docker Images](#docker-images)
    - [API Documentation](#api-documentation)
    - [Using a private or gated model](#using-a-private-or-gated-model)
    - [Air gapped deployment](#air-gapped-deployment)
    - [Using Re-rankers models](#using-re-rankers-models)
    - [Using Sequence Classification models](#using-sequence-classification-models)
    - [Using SPLADE pooling](#using-splade-pooling)
    - [Distributed Tracing](#distributed-tracing)
    - [gRPC](#grpc)
- [Local Install](#local-install)
- [Docker Build](#docker-build)
    - [Apple M1/M2 Arm](#apple-m1m2-arm64-architectures)
- [Examples](#examples)

Text Embeddings Inference (TEI) is a toolkit for deploying and serving open source text embeddings and sequence
classification models. TEI enables high-performance extraction for the most popular models, including FlagEmbedding,
Ember, GTE and E5. TEI implements many features such as:

* No model graph compilation step
* Metal support for local execution on Macs
* Small docker images and fast boot times. Get ready for true serverless!
* Token based dynamic batching
* Optimized transformers code for inference using [Flash Attention](https://github.com/HazyResearch/flash-attention),
  [Candle](https://github.com/huggingface/candle)
  and [cuBLASLt](https://docs.nvidia.com/cuda/cublas/#using-the-cublaslt-api)
* [Safetensors](https://github.com/huggingface/safetensors) weight loading
* [ONNX](https://github.com/onnx/onnx) weight loading
* Production ready (distributed tracing with Open Telemetry, Prometheus metrics)

## Get Started

### Supported Models

#### Text Embeddings

Text Embeddings Inference currently supports Nomic, BERT, CamemBERT, XLM-RoBERTa models with absolute positions, JinaBERT
model with Alibi positions and Mistral, Alibaba GTE, Qwen2 models with Rope positions, MPNet, ModernBERT, and Qwen3.

Below are some examples of the currently supported models:

| MTEB Rank | Model Size          | Model Type  | Model ID                                                                                         |
|-----------|---------------------|-------------|--------------------------------------------------------------------------------------------------|
| 2         | 8B (Very Expensive) | Qwen3       | [Qwen/Qwen3-Embedding-8B](https://hf.co/Qwen/Qwen3-Embedding-8B)                                 |
| 4         | 0.6B                | Qwen3       | [Qwen/Qwen3-Embedding-0.6B](https://hf.co/Qwen/Qwen3-Embedding-0.6B)                             |
| 6         | 7B (Very Expensive) | Qwen2       | [Alibaba-NLP/gte-Qwen2-7B-instruct](https://hf.co/Alibaba-NLP/gte-Qwen2-7B-instruct)             |
| 7         | 0.5B                | XLM-RoBERTa | [intfloat/multilingual-e5-large-instruct](https://hf.co/intfloat/multilingual-e5-large-instruct) |
| 14        | 1.5B (Expensive)    | Qwen2       | [Alibaba-NLP/gte-Qwen2-1.5B-instruct](https://hf.co/Alibaba-NLP/gte-Qwen2-1.5B-instruct)         |
| 17        | 7B (Very Expensive) | Mistral     | [Salesforce/SFR-Embedding-2_R](https://hf.co/Salesforce/SFR-Embedding-2_R)                       |
| 34        | 0.5B                | XLM-RoBERTa | [Snowflake/snowflake-arctic-embed-l-v2.0](https://hf.co/Snowflake/snowflake-arctic-embed-l-v2.0) |
| 40        | 0.3B                | Alibaba GTE | [Snowflake/snowflake-arctic-embed-m-v2.0](https://hf.co/Snowflake/snowflake-arctic-embed-m-v2.0) |
| 51        | 0.3B                | Bert        | [WhereIsAI/UAE-Large-V1](https://hf.co/WhereIsAI/UAE-Large-V1)                                   |
| N/A       | 0.4B                | Alibaba GTE | [Alibaba-NLP/gte-large-en-v1.5](https://hf.co/Alibaba-NLP/gte-large-en-v1.5)                     |
| N/A       | 0.4B                | ModernBERT  | [answerdotai/ModernBERT-large](https://hf.co/answerdotai/ModernBERT-large)                       |
| N/A       | 0.3B                | NomicBert   | [nomic-ai/nomic-embed-text-v2-moe](https://hf.co/nomic-ai/nomic-embed-text-v2-moe)               |
| N/A       | 0.1B                | NomicBert   | [nomic-ai/nomic-embed-text-v1](https://hf.co/nomic-ai/nomic-embed-text-v1)                       |
| N/A       | 0.1B                | NomicBert   | [nomic-ai/nomic-embed-text-v1.5](https://hf.co/nomic-ai/nomic-embed-text-v1.5)                   |
| N/A       | 0.1B                | JinaBERT    | [jinaai/jina-embeddings-v2-base-en](https://hf.co/jinaai/jina-embeddings-v2-base-en)             |
| N/A       | 0.1B                | JinaBERT    | [jinaai/jina-embeddings-v2-base-code](https://hf.co/jinaai/jina-embeddings-v2-base-code)         |
| N/A       | 0.1B                | MPNet       | [sentence-transformers/all-mpnet-base-v2](https://hf.co/sentence-transformers/all-mpnet-base-v2) |

To explore the list of best performing text embeddings models, visit the
[Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard).

#### Sequence Classification and Re-Ranking

Text Embeddings Inference currently supports CamemBERT, and XLM-RoBERTa Sequence Classification models with absolute positions.

Below are some examples of the currently supported models:

| Task               | Model Type  | Model ID                                                                                                        |
|--------------------|-------------|-----------------------------------------------------------------------------------------------------------------|
| Re-Ranking         | XLM-RoBERTa | [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large)                                       |
| Re-Ranking         | XLM-RoBERTa | [BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base)                                         |
| Re-Ranking         | GTE         | [Alibaba-NLP/gte-multilingual-reranker-base](https://huggingface.co/Alibaba-NLP/gte-multilingual-reranker-base) |
| Re-Ranking         | ModernBert  | [Alibaba-NLP/gte-reranker-modernbert-base](https://huggingface.co/Alibaba-NLP/gte-reranker-modernbert-base) |
| Sentiment Analysis | RoBERTa     | [SamLowe/roberta-base-go_emotions](https://huggingface.co/SamLowe/roberta-base-go_emotions)                     |

### Docker

```shell
model=BAAI/bge-large-en-v1.5
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id $model
```

And then you can make requests like

```bash
curl 127.0.0.1:8080/embed \
    -X POST \
    -d &#039;{&quot;inputs&quot;:&quot;What is Deep Learning?&quot;}&#039; \
    -H &#039;Content-Type: application/json&#039;
```

**Note:** To use GPUs, you need to install
the [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html).
NVIDIA drivers on your machine need to be compatible with CUDA version 12.2 or higher.

To see all options to serve your models:

```console
$ text-embeddings-router --help
Text Embedding Webserver

Usage: text-embeddings-router [OPTIONS]

Options:
      --model-id &lt;MODEL_ID&gt;
          The name of the model to load. Can be a MODEL_ID as listed on &lt;https://hf.co/models&gt; like `BAAI/bge-large-en-v1.5`. Or it can be a local directory containing the necessary files as saved by `save_pretrained(...)` methods of transformers

          [env: MODEL_ID=]
          [default: BAAI/bge-large-en-v1.5]

      --revision &lt;REVISION&gt;
          The actual revision of the model if you&#039;re referring to a model on the hub. You can use a specific commit id or a branch like `refs/pr/2`

          [env: REVISION=]

      --tokenization-workers &lt;TOKENIZATION_WORKERS&gt;
          Optionally control the number of tokenizer workers used for payload tokenization, validation and truncation. Default to the number of CPU cores on the machine

          [env: TOKENIZATION_WORKERS=]

      --dtype &lt;DTYPE&gt;
          The dtype to be forced upon the model

          [env: DTYPE=]
          [possible values: float16, float32]

      --pooling &lt;POOLING&gt;
          Optionally control the pooling method for embedding models.

          If `pooling` is not set, the pooling configuration will be parsed from the model `1_Pooling/config.json` configuration.

          If `pooling` is set, it will override the model pooling configuration

          [env: POOLING=]

          Possible values:
          - cls:        Select the CLS token as embedding
          - mean:       Apply Mean pooling to the model embeddings
          - splade:     Apply SPLADE (Sparse Lexical and Expansion) to the model embeddings. This option is only available if the loaded model is a `ForMaskedLM` Transformer model
          - last-token: Select the last token as embedding

      --max-concurrent-requests &lt;MAX_CONCURRENT_REQUESTS&gt;
          The maximum amount of concurrent requests for this particular deployment. Having a low limit will refuse clients requests instead of having them wait for too long and is usually good to handle backpressure correctly

          [env: MAX_CONCURRENT_REQUESTS=]
          [default: 512]

      --max-batch-tokens &lt;MAX_BATCH_TOKENS&gt;
          **IMPORTANT** This is one critical control to allow maximum usage of the available hardware.

          This represents the total amount of potential tokens within a batch.

          For `max_batch_tokens=1000`, you could fit `10` queries of `total_tokens=100` or a single query of `1000` tokens.

          Overall this number should be the largest possible until the model is compute bound. Since the actual memory overhead depends on the model implementation, text-embeddings-inference cannot infer this number automatically.

          [env: MAX_BATCH_TOKENS=]
          [default: 16384]

      --max-batch-requests &lt;MAX_BATCH_REQUESTS&gt;
          Optionally control the maximum number of individual requests in a batch

          [env: MAX_BATCH_REQUESTS=]

      --max-client-batch-size &lt;MAX_CLIENT_BATCH_SIZE&gt;
          Control the maximum number of inputs that a client can send in a single request

          [env: MAX_CLIENT_BATCH_SIZE=]
          [default: 32]

      --auto-truncate
          Automatically truncate inputs that are longer than the maximum supported size

          Unused for gRPC servers

          [env: AUTO_TRUNCATE=]

      --default-prompt-name &lt;DEFAULT_PROMPT_NAME&gt;
          The name of the prompt that should be used by default for encoding. If not set, no prompt will be applied.

          Must be a key in the `sentence-transformers` configuration `prompts` dictionary.

          For example if ``default_prompt_name`` is &quot;query&quot; and the ``prompts`` is {&quot;query&quot;: &quot;query: &quot;, ...}, then the sentence &quot;What is the capital of France?&quot; will be encoded as &quot;query: What is the capital of France?&quot; because the prompt text will be prepended before any text to encode.

          The argument &#039;--default-prompt-name &lt;DEFAULT_PROMPT_NAME&gt;&#039; cannot be used with &#039;--default-prompt &lt;DEFAULT_PROMPT&gt;`

          [env: DEFAULT_PROMPT_NAME=]

      --default-prompt &lt;DEFAULT_PROMPT&gt;
          The prompt that should be used by default for encoding. If not set, no prompt will be applied.

          For example if ``default_prompt`` is &quot;query: &quot; then the sentence &quot;What is the capital of France?&quot; will be encoded as &quot;query: What is the capital of France?&quot; because the prompt text will be prepended before any text to encode.

          The argument &#039;--default-prompt &lt;DEFAULT_PROMPT&gt;&#039; cannot be used with &#039;--default-prompt-name &lt;DEFAULT_PROMPT_NAME&gt;`

          [env: DEFAULT_PROMPT=]

      --hf-token &lt;HF_TOKEN&gt;
          Your Hugging Face Hub token

          [env: HF_TOKEN=]

      --hostname &lt;HOSTNAME&gt;
          The IP address to listen on

          [env: HOSTNAME=]
          [default: 0.0.0.0]

      -p, --port &lt;PORT&gt;
          The port to listen on

          [env: PORT=]
          [default: 3000]

      --uds-path &lt;UDS_PATH&gt;
          The name of the unix socket some text-embeddings-inference backends will use as they communicate internally with gRPC

          [env: UDS_PATH=]
          [default: /tmp/text-embeddings-inference-server]

      --huggingface-hub-cache &lt;HUGGINGFACE_HUB_CACHE&gt;
          The location of the huggingface hub cache. Used to override the location if you want to provide a mounted disk for instance

          [env: HUGGINGFACE_HUB_CACHE=]

      --payload-limit &lt;PAYLOAD_LIMIT&gt;
          Payload size limit in bytes

          Default is 2MB

          [env: PAYLOAD_LIMIT=]
          [default: 2000000]

      --api-key &lt;API_KEY&gt;
          Set an api key for request authorization.

          By default the server responds to every request. With an api key set, the requests must have the Authorization header set with the api key as Bearer token.

          [env: API_KEY=]

      --json-output
          Outputs the logs in JSON format (useful for telemetry)

          [env: JSON_OUTPUT=]

      --disable-spans
          [env: DISABLE_SPANS=]

      --otlp-endpoint &lt;OTLP_ENDPOINT&gt;
          The grpc endpoint for opentelemetry. Telemetry is sent to this endpoint as OTLP over gRPC. e.g. `http://localhost:4317`

          [env: OTLP_ENDPOINT=]

      --otlp-service-name &lt;OTLP_SERVICE_NAME&gt;
          The service name for opentelemetry. e.g. `text-embeddings-inference.server`

          [env: OTLP_SERVICE_NAME=]
          [default: text-embeddings-inference.server]

      --prometheus-port &lt;PROMETHEUS_PORT&gt;
          The Prometheus port to listen on

          [env: PROMETHEUS_PORT=]
          [default: 9000]

      --cors-allow-origin &lt;CORS_ALLOW_ORIGIN&gt;
          Unused for gRPC servers

          [env: CORS_ALLOW_ORIGIN=]

      -h, --help
          Print help (see a summary with &#039;-h&#039;)

      -V, --version
          Print version
```

### Docker Images

Text Embeddings Inference ships with multiple Docker images that you can use to target a specific backend:

| Architecture                        | Image                                                                   |
|-------------------------------------|-------------------------------------------------------------------------|
| CPU                                 | ghcr.io/huggingface/text-embeddings-inference:cpu-1.7                   |
| Volta                               | NOT SUPPORTED                                                           |
| Turing (T4, RTX 2000 series, ...)   | ghcr.io/huggingface/text-embeddings-inference:turing-1.7 (experimental) |
| Ampere 80 (A100, A30)               | ghcr.io/huggingface/text-embeddings-inference:1.7                       |
| Ampere 86 (A10, A40, ...)           | ghcr.io/huggingface/text-embeddings-inference:86-1.7                    |
| Ada Lovelace (RTX 4000 series, ...) | ghcr.io/huggingface/text-embeddings-inference:89-1.7                    |
| Hopper (H100)                       | ghcr.io/huggingface/text-embeddings-inference:hopper-1.7 (experimental) |

**Warning**: Flash Attention is turned off by default for the Turing image as it suffers from precision issues.
You can turn Flash Attention v1 ON by using the `USE_FLASH_ATTENTION=True` environment variable.

### API documentation

You can consult the OpenAPI documentation of the `text-embeddings-inference` REST API using the `/docs` route.
The Swagger UI is also available
at: [https://huggingface.github.io/text-embeddings-inference](https://huggingface.github.io/text-embeddings-inference).

### Using a private or gated model

You have the option to utilize the `HF_TOKEN` environment variable for configuring the token employed by
`text-embeddings-inference`. This allows you to gain access to protected resources.

For example:

1. Go to https://huggingface.co/settings/tokens
2. Copy your cli READ token
3. Export `HF_TOKEN=&lt;your cli READ token&gt;`

or with Docker:

```shell
model=&lt;your private model&gt;
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run
token=&lt;your cli READ token&gt;

docker run --gpus all -e HF_TOKEN=$token -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id $model
```

### Air gapped deployment

To deploy Text Embeddings Inference in an air-gapped environment, first download the weights and then mount them inside
the container using a volume.

For example:

```shell
# (Optional) create a `models` directory
mkdir models
cd models

# Make sure you have git-lfs installed (https://git-lfs.com)
git lfs install
git clone https://huggingface.co/Alibaba-NLP/gte-base-en-v1.5

# Set the models directory as the volume path
volume=$PWD

# Mount the models directory inside the container with a volume and set the model ID
docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id /data/gte-base-en-v1.5
```

### Using Re-rankers models

`text-embeddings-inference` v0.4.0 added support for CamemBERT, RoBERTa, XLM-RoBERTa, and GTE Sequence Classification models.
Re-rankers models are Sequence Classification cross-encoders models with a single class that scores the similarity
between a query and a text.

See [this blogpost](https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83) by
the LlamaIndex team to understand how you can use re-rankers models in your RAG pipeline to improve
downstream performance.

```shell
model=BAAI/bge-reranker-large
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id $model
```

And then you can rank the similarity between a query and a list of texts with:

```bash
curl 127.0.0.1:8080/rerank \
    -X POST \
    -d &#039;{&quot;query&quot;: &quot;What is Deep Learning?&quot;, &quot;texts&quot;: [&quot;Deep Learning is not...&quot;, &quot;Deep learning is...&quot;]}&#039; \
    -H &#039;Content-Type: application/json&#039;
```

### Using Sequence Classification models

You can also use classic Sequence Classification models like `SamLowe/roberta-base-go_emotions`:

```shell
model=SamLowe/roberta-base-go_emotions
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id $model
```

Once you have deployed the model you can use the `predict` endpoint to get the emotions most associated with an input:

```bash
curl 127.0.0.1:8080/predict \
    -X POST \
    -d &#039;{&quot;inputs&quot;:&quot;I like you.&quot;}&#039; \
    -H &#039;Content-Type: application/json&#039;
```

### Using SPLADE pooling

You can choose to activate SPLADE pooling for Bert and Distilbert MaskedLM architectures:

```shell
model=naver/efficient-splade-VI-BT-large-query
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id $model -

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[unionlabs/union]]></title>
            <link>https://github.com/unionlabs/union</link>
            <guid>https://github.com/unionlabs/union</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[The trust-minimized, zero-knowledge bridging protocol, designed for censorship resistance, extremely high security, and usage in decentralized finance.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/unionlabs/union">unionlabs/union</a></h1>
            <p>The trust-minimized, zero-knowledge bridging protocol, designed for censorship resistance, extremely high security, and usage in decentralized finance.</p>
            <p>Language: Rust</p>
            <p>Stars: 67,399</p>
            <p>Forks: 3,254</p>
            <p>Stars today: 199 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./.github/images/union-logo-white.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./.github/images/union-logo-black.svg&quot;&gt;
    &lt;img alt=&quot;Union&quot;
         src=&quot;./.github/images/union-logo-black.svg&quot;
         width=&quot;100%&quot;&gt;
  &lt;/picture&gt;
&lt;/div&gt;

&lt;br/&gt;

&lt;div align=&quot;center&quot;&gt;

[![built with garnix](https://img.shields.io/endpoint.svg?url=https%3A%2F%2Fgarnix.io%2Fapi%2Fbadges%2Funionlabs%2Funion%3Fbranch%3Dmain)](https://garnix.io)
[![Docs](https://img.shields.io/badge/docs-main-blue)][docs]
[![Discord badge]](https://discord.union.build)
[![Twitter handle]][twitter badge]

&lt;/div&gt;

Union is the hyper-efficient zero-knowledge infrastructure layer for general message passing, asset transfers, NFTs, and DeFi. Its based on [Consensus Verification] and has no dependencies on trusted third parties, oracles, multi-signatures or MPC. It implements [IBC] for compatibility with [Cosmos] chains and connects to EVM chains like [Ethereum], [Berachain (beacon-kit)](https://github.com/berachain/beacon-kit), [Arbitrum], and more.

The upgradability of contracts on other chains, connections, token configurations, and evolution of the protocol will all be controlled by decentralized governance, aligning the priorities of Union with its users, validators, and operators.

## Components

| Component                                             | Description                                          | Language(s)           |
| ----------------------------------------------------- | ---------------------------------------------------- | --------------------- |
| [`uniond`](./uniond/README.md)                        | The Union node implementation, using [`CometBLS`]    | [Go]                  |
| [`galoisd`](./galoisd)                                | The zero-knowledge prover implementation             | [Go] [Gnark]          |
| [`voyager`](./voyager)                                | Modular hyper-performant cross-ecosystem relayer     | [Rust]                |
| [`hubble`](./hubble)                                  | Multi-ecosystem, GMP-enabled chain indexer           | [Rust]                |
| [`cosmwasm`](./cosmwasm)                              | [CosmWasm] smart contract stack                      | [Rust]                |
| [`light-clients`](./cosmwasm/ibc-union/lightclient)   | [Light Clients] for various ecosystems               | [Rust]                |
| [`unionvisor`](./unionvisor/README.md)                | Node supervisor intended for production usage        | [Rust]                |
| [`drip`](./drip)                                      | Faucet for [Cosmos] chains: [app.union.build/faucet] | [Rust]                |
| [`evm`](./evm)                                        | [EVM] smart contract stack                           | [Solidity]            |
| [`app`](./app2)                                       | [app.union.build]                                    | [TypeScript] [Svelte] |
| [`site`](./site)                                      | [union.build]                                        | [TypeScript] [Astro]  |
| [`TypeScript SDK`](./typescript-sdk)                  | TypeScript SDK for interacting with Union            | [TypeScript]          |

## Quickstart

Install [Nix] to _[reproducibly build](https://en.wikipedia.org/wiki/Reproducible_builds) any component_, and to enter a dev shell with _all dependencies_:

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf -L https://install.determinate.systems/nix | sh -s -- install
```

_(Note that some components can only be built on Linux. If you are using macOS, we recommend using [OrbStack] to easily set up a [NixOS] VM within two minutes. Most Union developers use macOS with [OrbStack], and there is no need to install Nix inside of the [NixOS] VM.)_

You can now _reproducibly_ build any of Union&#039;s components from source:

```sh
nix build .#uniond -L
nix build .#voyager -L
nix build .#app -L

# to see all packages, run:
nix flake show
```

The result of whatever you build will be in `result/`

You can now also enter our dev shell, which has all of the dependencies (`cargo`, `rustc`, `node`, `go`, etc.) you need to work on any component:
_(Don&#039;t worry, this will not affect your system outside of this repo)_

```sh
nix develop
```

Run the following to format the entire repo and check your spelling before each PR:

```sh
nix run .#pre-commit -L
```

Check the `#developers` channel on [Union&#039;s discord](https://discord.union.build) if you need any help with this.

## Docs

The official docs are hosted [here][docs]. Each individual component also has accompanying developer documentation for contributors, which you can find in each `README.md`.

[app.union.build]: https://app.union.build
[app.union.build/faucet]: https://app.union.build/faucet
[arbitrum]: https://github.com/OffchainLabs/arbitrum
[astro]: https://astro.build
[consensus verification]: https://union.build/docs/concepts/consensus-verification/
[cosmos]: https://cosmos.network
[cosmwasm]: https://cosmwasm.com/
[discord badge]: https://img.shields.io/discord/1158939416870522930?logo=discord
[docs]: https://docs.union.build &quot;Official Union Docs&quot;
[ethereum]: https://ethereum.org
[evm]: https://ethereum.org/en/developers/docs/evm/
[gnark]: https://github.com/ConsenSys/gnark
[go]: https://go.dev/
[ibc]: https://github.com/cosmos/ibc &quot;cosmos/ibc&quot;
[light clients]: https://a16zcrypto.com/posts/article/an-introduction-to-light-clients/
[nix]: https://zero-to-nix.com/
[nixos]: https://nixos.org
[orbstack]: https://orbstack.dev/
[rust]: https://www.rust-lang.org/
[solidity]: https://soliditylang.org/
[svelte]: https://svelte.dev
[twitter badge]: https://twitter.com/intent/follow?screen_name=union_build
[twitter handle]: https://img.shields.io/twitter/follow/union_build.svg?style=social&amp;label=Follow
[typescript]: https://www.typescriptlang.org/
[union.build]: https://union.build
[`cometbls`]: https://github.com/unionlabs/cometbls
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nushell/nushell]]></title>
            <link>https://github.com/nushell/nushell</link>
            <guid>https://github.com/nushell/nushell</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[A new type of shell]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nushell/nushell">nushell/nushell</a></h1>
            <p>A new type of shell</p>
            <p>Language: Rust</p>
            <p>Stars: 35,396</p>
            <p>Forks: 1,846</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># Nushell &lt;!-- omit in toc --&gt;
[![Crates.io](https://img.shields.io/crates/v/nu.svg)](https://crates.io/crates/nu)
[![Build Status](https://img.shields.io/github/actions/workflow/status/nushell/nushell/ci.yml?branch=main)](https://github.com/nushell/nushell/actions)
[![Nightly Build](https://github.com/nushell/nushell/actions/workflows/nightly-build.yml/badge.svg)](https://github.com/nushell/nushell/actions/workflows/nightly-build.yml)
[![Discord](https://img.shields.io/discord/601130461678272522.svg?logo=discord)](https://discord.gg/NtAbbGn)
[![The Changelog #363](https://img.shields.io/badge/The%20Changelog-%23363-61c192.svg)](https://changelog.com/podcast/363)
[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/nushell/nushell)](https://github.com/nushell/nushell/graphs/commit-activity)
[![GitHub contributors](https://img.shields.io/github/contributors/nushell/nushell)](https://github.com/nushell/nushell/graphs/contributors)

A new type of shell.

![Example of nushell](assets/nushell-autocomplete6.gif &quot;Example of nushell&quot;)

## Table of Contents &lt;!-- omit in toc --&gt;

- [Status](#status)
- [Learning About Nu](#learning-about-nu)
- [Installation](#installation)
- [Configuration](#configuration)
- [Philosophy](#philosophy)
  - [Pipelines](#pipelines)
  - [Opening files](#opening-files)
  - [Plugins](#plugins)
- [Goals](#goals)
- [Officially Supported By](#officially-supported-by)
- [Contributing](#contributing)
- [License](#license)

## Status

This project has reached a minimum-viable-product level of quality. Many people use it as their daily driver, but it may be unstable for some commands. Nu&#039;s design is subject to change as it matures.

## Learning About Nu

The [Nushell book](https://www.nushell.sh/book/) is the primary source of Nushell documentation. You can find [a full list of Nu commands in the book](https://www.nushell.sh/commands/), and we have many examples of using Nu in our [cookbook](https://www.nushell.sh/cookbook/).

We&#039;re also active on [Discord](https://discord.gg/NtAbbGn); come and chat with us!

## Installation

To quickly install Nu:

```bash
# Linux and macOS
brew install nushell
# Windows
winget install nushell
```

To use `Nu` in GitHub Action, check [setup-nu](https://github.com/marketplace/actions/setup-nu) for more detail.

Detailed installation instructions can be found in the [installation chapter of the book](https://www.nushell.sh/book/installation.html). Nu is available via many package managers:

[![Packaging status](https://repology.org/badge/vertical-allrepos/nushell.svg?columns=3)](https://repology.org/project/nushell/versions)

For details about which platforms the Nushell team actively supports, see [our platform support policy](devdocs/PLATFORM_SUPPORT.md).

## Configuration

The default configurations can be found at [sample_config](crates/nu-utils/src/default_files)
which are the configuration files one gets when they startup Nushell for the first time.

It sets all of the default configuration to run Nushell.  From here one can
then customize this file for their specific needs.

To see where *config.nu* is located on your system simply type this command.

```rust
$nu.config-path
```

Please see our [book](https://www.nushell.sh) for all of the Nushell documentation.


## Philosophy

Nu draws inspiration from projects like PowerShell, functional programming languages, and modern CLI tools.
Rather than thinking of files and data as raw streams of text, Nu looks at each input as something with structure.
For example, when you list the contents of a directory what you get back is a table of rows, where each row represents an item in that directory.
These values can be piped through a series of steps, in a series of commands called a &#039;pipeline&#039;.

### Pipelines

In Unix, it&#039;s common to pipe between commands to split up a sophisticated command over multiple steps.
Nu takes this a step further and builds heavily on the idea of _pipelines_.
As in the Unix philosophy, Nu allows commands to output to stdout and read from stdin.
Additionally, commands can output structured data (you can think of this as a third kind of stream).
Commands that work in the pipeline fit into one of three categories:

-   Commands that produce a stream (e.g., `ls`)
-   Commands that filter a stream (e.g., `where type == &quot;dir&quot;`)
-   Commands that consume the output of the pipeline (e.g., `table`)

Commands are separated by the pipe symbol (`|`) to denote a pipeline flowing left to right.

```shell
ls | where type == &quot;dir&quot; | table
# =&gt; ╭────┬──────────┬──────┬─────────┬───────────────╮
# =&gt; │ #  │   name   │ type │  size   │   modified    │
# =&gt; ├────┼──────────┼──────┼─────────┼───────────────┤
# =&gt; │  0 │ .cargo   │ dir  │     0 B │ 9 minutes ago │
# =&gt; │  1 │ assets   │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  2 │ crates   │ dir  │ 4.0 KiB │ 2 weeks ago   │
# =&gt; │  3 │ docker   │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  4 │ docs     │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  5 │ images   │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  6 │ pkg_mgrs │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  7 │ samples  │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  8 │ src      │ dir  │ 4.0 KiB │ 2 weeks ago   │
# =&gt; │  9 │ target   │ dir  │     0 B │ a day ago     │
# =&gt; │ 10 │ tests    │ dir  │ 4.0 KiB │ 2 weeks ago   │
# =&gt; │ 11 │ wix      │ dir  │     0 B │ 2 weeks ago   │
# =&gt; ╰────┴──────────┴──────┴─────────┴───────────────╯
```

Because most of the time you&#039;ll want to see the output of a pipeline, `table` is assumed.
We could have also written the above:

```shell
ls | where type == &quot;dir&quot;
```

Being able to use the same commands and compose them differently is an important philosophy in Nu.
For example, we could use the built-in `ps` command to get a list of the running processes, using the same `where` as above.

```shell
ps | where cpu &gt; 0
# =&gt; ╭───┬───────┬───────────┬───────┬───────────┬───────────╮
# =&gt; │ # │  pid  │   name    │  cpu  │    mem    │  virtual  │
# =&gt; ├───┼───────┼───────────┼───────┼───────────┼───────────┤
# =&gt; │ 0 │  2240 │ Slack.exe │ 16.40 │ 178.3 MiB │ 232.6 MiB │
# =&gt; │ 1 │ 16948 │ Slack.exe │ 16.32 │ 205.0 MiB │ 197.9 MiB │
# =&gt; │ 2 │ 17700 │ nu.exe    │  3.77 │  26.1 MiB │   8.8 MiB │
# =&gt; ╰───┴───────┴───────────┴───────┴───────────┴───────────╯
```

### Opening files

Nu can load file and URL contents as raw text or structured data (if it recognizes the format).
For example, you can load a .toml file as structured data and explore it:

```shell
open Cargo.toml
# =&gt; ╭──────────────────┬────────────────────╮
# =&gt; │ bin              │ [table 1 row]      │
# =&gt; │ dependencies     │ {record 25 fields} │
# =&gt; │ dev-dependencies │ {record 8 fields}  │
# =&gt; │ features         │ {record 10 fields} │
# =&gt; │ package          │ {record 13 fields} │
# =&gt; │ patch            │ {record 1 field}   │
# =&gt; │ profile          │ {record 3 fields}  │
# =&gt; │ target           │ {record 3 fields}  │
# =&gt; │ workspace        │ {record 1 field}   │
# =&gt; ╰──────────────────┴────────────────────╯
```

We can pipe this into a command that gets the contents of one of the columns:

```shell
open Cargo.toml | get package
# =&gt; ╭───────────────┬────────────────────────────────────╮
# =&gt; │ authors       │ [list 1 item]                      │
# =&gt; │ default-run   │ nu                                 │
# =&gt; │ description   │ A new type of shell                │
# =&gt; │ documentation │ https://www.nushell.sh/book/       │
# =&gt; │ edition       │ 2018                               │
# =&gt; │ exclude       │ [list 1 item]                      │
# =&gt; │ homepage      │ https://www.nushell.sh             │
# =&gt; │ license       │ MIT                                │
# =&gt; │ metadata      │ {record 1 field}                   │
# =&gt; │ name          │ nu                                 │
# =&gt; │ repository    │ https://github.com/nushell/nushell │
# =&gt; │ rust-version  │ 1.60                               │
# =&gt; │ version       │ 0.72.0                             │
# =&gt; ╰───────────────┴────────────────────────────────────╯
```

And if needed we can drill down further:

```shell
open Cargo.toml | get package.version
# =&gt; 0.72.0
```

### Plugins

Nu supports plugins that offer additional functionality to the shell and follow the same structured data model that built-in commands use. There are a few examples in the `crates/nu_plugins_*` directories.

Plugins are binaries that are available in your path and follow a `nu_plugin_*` naming convention.
These binaries interact with nu via a simple JSON-RPC protocol where the command identifies itself and passes along its configuration, making it available for use.
If the plugin is a filter, data streams to it one element at a time, and it can stream data back in return via stdin/stdout.
If the plugin is a sink, it is given the full vector of final data and is given free reign over stdin/stdout to use as it pleases.

The [awesome-nu repo](https://github.com/nushell/awesome-nu#plugins) lists a variety of nu-plugins while the [showcase repo](https://github.com/nushell/showcase) *shows* off informative blog posts that have been written about Nushell along with videos that highlight technical
topics that have been presented.

## Goals

Nu adheres closely to a set of goals that make up its design philosophy. As features are added, they are checked against these goals.

-   First and foremost, Nu is cross-platform. Commands and techniques should work across platforms and Nu has [first-class support for Windows, macOS, and Linux](devdocs/PLATFORM_SUPPORT.md).

-   Nu ensures compatibility with existing platform-specific executables.

-   Nu&#039;s workflow and tools should have the usability expected of modern software in 2022 (and beyond).

-   Nu views data as either structured or unstructured. It is a structured shell like PowerShell.

-   Finally, Nu views data functionally. Rather than using mutation, pipelines act as a means to load, change, and save data without mutable state.

## Officially Supported By

Please submit an issue or PR to be added to this list.

-   [zoxide](https://github.com/ajeetdsouza/zoxide)
-   [starship](https://github.com/starship/starship)
-   [oh-my-posh](https://ohmyposh.dev)
-   [Couchbase Shell](https://couchbase.sh)
-   [virtualenv](https://github.com/pypa/virtualenv)
-   [atuin](https://github.com/ellie/atuin)
-   [clap](https://github.com/clap-rs/clap/tree/master/clap_complete_nushell)
-   [Dorothy](http://github.com/bevry/dorothy)
-   [Direnv](https://github.com/direnv/direnv/blob/master/docs/hook.md#nushell)
-   [x-cmd](https://x-cmd.com/mod/nu)
-   [vfox](https://github.com/version-fox/vfox)

## Contributing

See [Contributing](CONTRIBUTING.md) for details. Thanks to all the people who already contributed!

&lt;a href=&quot;https://github.com/nushell/nushell/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=nushell/nushell&amp;max=750&amp;columns=20&quot; /&gt;
&lt;/a&gt;

## License

The project is made available under the MIT license. See the `LICENSE` file for more information.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BurntSushi/ripgrep]]></title>
            <link>https://github.com/BurntSushi/ripgrep</link>
            <guid>https://github.com/BurntSushi/ripgrep</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[ripgrep recursively searches directories for a regex pattern while respecting your gitignore]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BurntSushi/ripgrep">BurntSushi/ripgrep</a></h1>
            <p>ripgrep recursively searches directories for a regex pattern while respecting your gitignore</p>
            <p>Language: Rust</p>
            <p>Stars: 53,039</p>
            <p>Forks: 2,146</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>ripgrep (rg)
------------
ripgrep is a line-oriented search tool that recursively searches the current
directory for a regex pattern. By default, ripgrep will respect gitignore rules
and automatically skip hidden files/directories and binary files. (To disable
all automatic filtering by default, use `rg -uuu`.) ripgrep has first class
support on Windows, macOS and Linux, with binary downloads available for [every
release](https://github.com/BurntSushi/ripgrep/releases). ripgrep is similar to
other popular search tools like The Silver Searcher, ack and grep.

[![Build status](https://github.com/BurntSushi/ripgrep/workflows/ci/badge.svg)](https://github.com/BurntSushi/ripgrep/actions)
[![Crates.io](https://img.shields.io/crates/v/ripgrep.svg)](https://crates.io/crates/ripgrep)
[![Packaging status](https://repology.org/badge/tiny-repos/ripgrep.svg)](https://repology.org/project/ripgrep/badges)

Dual-licensed under MIT or the [UNLICENSE](https://unlicense.org).


### CHANGELOG

Please see the [CHANGELOG](CHANGELOG.md) for a release history.

### Documentation quick links

* [Installation](#installation)
* [User Guide](GUIDE.md)
* [Frequently Asked Questions](FAQ.md)
* [Regex syntax](https://docs.rs/regex/1/regex/#syntax)
* [Configuration files](GUIDE.md#configuration-file)
* [Shell completions](FAQ.md#complete)
* [Building](#building)
* [Translations](#translations)


### Screenshot of search results

[![A screenshot of a sample search with ripgrep](https://burntsushi.net/stuff/ripgrep1.png)](https://burntsushi.net/stuff/ripgrep1.png)


### Quick examples comparing tools

This example searches the entire
[Linux kernel source tree](https://github.com/BurntSushi/linux)
(after running `make defconfig &amp;&amp; make -j8`) for `[A-Z]+_SUSPEND`, where
all matches must be words. Timings were collected on a system with an Intel
i9-12900K 5.2 GHz.

Please remember that a single benchmark is never enough! See my
[blog post on ripgrep](https://blog.burntsushi.net/ripgrep/)
for a very detailed comparison with more benchmarks and analysis.

| Tool | Command | Line count | Time |
| ---- | ------- | ---------- | ---- |
| ripgrep (Unicode) | `rg -n -w &#039;[A-Z]+_SUSPEND&#039;` | 536 | **0.082s** (1.00x) |
| [hypergrep](https://github.com/p-ranav/hypergrep) | `hgrep -n -w &#039;[A-Z]+_SUSPEND&#039;` | 536 | 0.167s (2.04x) |
| [git grep](https://www.kernel.org/pub/software/scm/git/docs/git-grep.html) | `git grep -P -n -w &#039;[A-Z]+_SUSPEND&#039;` | 536 | 0.273s (3.34x) |
| [The Silver Searcher](https://github.com/ggreer/the_silver_searcher) | `ag -w &#039;[A-Z]+_SUSPEND&#039;` | 534 | 0.443s (5.43x) |
| [ugrep](https://github.com/Genivia/ugrep) | `ugrep -r --ignore-files --no-hidden -I -w &#039;[A-Z]+_SUSPEND&#039;` | 536 | 0.639s (7.82x) |
| [git grep](https://www.kernel.org/pub/software/scm/git/docs/git-grep.html) | `LC_ALL=C git grep -E -n -w &#039;[A-Z]+_SUSPEND&#039;` | 536 | 0.727s (8.91x) |
| [git grep (Unicode)](https://www.kernel.org/pub/software/scm/git/docs/git-grep.html) | `LC_ALL=en_US.UTF-8 git grep -E -n -w &#039;[A-Z]+_SUSPEND&#039;` | 536 | 2.670s (32.70x) |
| [ack](https://github.com/beyondgrep/ack3) | `ack -w &#039;[A-Z]+_SUSPEND&#039;` | 2677 | 2.935s (35.94x) |

Here&#039;s another benchmark on the same corpus as above that disregards gitignore
files and searches with a whitelist instead. The corpus is the same as in the
previous benchmark, and the flags passed to each command ensure that they are
doing equivalent work:

| Tool | Command | Line count | Time |
| ---- | ------- | ---------- | ---- |
| ripgrep | `rg -uuu -tc -n -w &#039;[A-Z]+_SUSPEND&#039;` | 447 | **0.063s** (1.00x) |
| [ugrep](https://github.com/Genivia/ugrep) | `ugrep -r -n --include=&#039;*.c&#039; --include=&#039;*.h&#039; -w &#039;[A-Z]+_SUSPEND&#039;` | 447 | 0.607s (9.62x) |
| [GNU grep](https://www.gnu.org/software/grep/) | `grep -E -r -n --include=&#039;*.c&#039; --include=&#039;*.h&#039; -w &#039;[A-Z]+_SUSPEND&#039;` | 447 | 0.674s (10.69x) |

Now we&#039;ll move to searching on single large file. Here is a straight-up
comparison between ripgrep, ugrep and GNU grep on a file cached in memory
(~13GB, [`OpenSubtitles.raw.en.gz`](http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.raw.en.gz), decompressed):

| Tool | Command | Line count | Time |
| ---- | ------- | ---------- | ---- |
| ripgrep (Unicode) | `rg -w &#039;Sherlock [A-Z]\w+&#039;` | 7882 | **1.042s** (1.00x) |
| [ugrep](https://github.com/Genivia/ugrep) | `ugrep -w &#039;Sherlock [A-Z]\w+&#039;` | 7882 | 1.339s (1.28x) |
| [GNU grep (Unicode)](https://www.gnu.org/software/grep/) | `LC_ALL=en_US.UTF-8 egrep -w &#039;Sherlock [A-Z]\w+&#039;` | 7882 | 6.577s (6.31x) |

In the above benchmark, passing the `-n` flag (for showing line numbers)
increases the times to `1.664s` for ripgrep and `9.484s` for GNU grep. ugrep
times are unaffected by the presence or absence of `-n`.

Beware of performance cliffs though:

| Tool | Command | Line count | Time |
| ---- | ------- | ---------- | ---- |
| ripgrep (Unicode) | `rg -w &#039;[A-Z]\w+ Sherlock [A-Z]\w+&#039;` | 485 | **1.053s** (1.00x) |
| [GNU grep (Unicode)](https://www.gnu.org/software/grep/) | `LC_ALL=en_US.UTF-8 grep -E -w &#039;[A-Z]\w+ Sherlock [A-Z]\w+&#039;` | 485 | 6.234s (5.92x) |
| [ugrep](https://github.com/Genivia/ugrep) | `ugrep -w &#039;[A-Z]\w+ Sherlock [A-Z]\w+&#039;` | 485 | 28.973s (27.51x) |

And performance can drop precipitously across the board when searching big
files for patterns without any opportunities for literal optimizations:

| Tool | Command | Line count | Time |
| ---- | ------- | ---------- | ---- |
| ripgrep | `rg &#039;[A-Za-z]{30}&#039;` | 6749 | **15.569s** (1.00x) |
| [ugrep](https://github.com/Genivia/ugrep) | `ugrep -E &#039;[A-Za-z]{30}&#039;` | 6749 | 21.857s (1.40x) |
| [GNU grep](https://www.gnu.org/software/grep/) | `LC_ALL=C grep -E &#039;[A-Za-z]{30}&#039;` | 6749 | 32.409s (2.08x) |
| [GNU grep (Unicode)](https://www.gnu.org/software/grep/) | `LC_ALL=en_US.UTF-8 grep -E &#039;[A-Za-z]{30}&#039;` | 6795 | 8m30s (32.74x) |

Finally, high match counts also tend to both tank performance and smooth
out the differences between tools (because performance is dominated by how
quickly one can handle a match and not the algorithm used to detect the match,
generally speaking):

| Tool | Command | Line count | Time |
| ---- | ------- | ---------- | ---- |
| ripgrep | `rg the` | 83499915 | **6.948s** (1.00x) |
| [ugrep](https://github.com/Genivia/ugrep) | `ugrep the` | 83499915 | 11.721s (1.69x) |
| [GNU grep](https://www.gnu.org/software/grep/) | `LC_ALL=C grep the` | 83499915 | 15.217s (2.19x) |

### Why should I use ripgrep?

* It can replace many use cases served by other search tools
  because it contains most of their features and is generally faster. (See
  [the FAQ](FAQ.md#posix4ever) for more details on whether ripgrep can truly
  replace grep.)
* Like other tools specialized to code search, ripgrep defaults to
  [recursive search](GUIDE.md#recursive-search) and does [automatic
  filtering](GUIDE.md#automatic-filtering). Namely, ripgrep won&#039;t search files
  ignored by your `.gitignore`/`.ignore`/`.rgignore` files, it won&#039;t search
  hidden files and it won&#039;t search binary files. Automatic filtering can be
  disabled with `rg -uuu`.
* ripgrep can [search specific types of files](GUIDE.md#manual-filtering-file-types).
  For example, `rg -tpy foo` limits your search to Python files and `rg -Tjs
  foo` excludes JavaScript files from your search. ripgrep can be taught about
  new file types with custom matching rules.
* ripgrep supports many features found in `grep`, such as showing the context
  of search results, searching multiple patterns, highlighting matches with
  color and full Unicode support. Unlike GNU grep, ripgrep stays fast while
  supporting Unicode (which is always on).
* ripgrep has optional support for switching its regex engine to use PCRE2.
  Among other things, this makes it possible to use look-around and
  backreferences in your patterns, which are not supported in ripgrep&#039;s default
  regex engine. PCRE2 support can be enabled with `-P/--pcre2` (use PCRE2
  always) or `--auto-hybrid-regex` (use PCRE2 only if needed). An alternative
  syntax is provided via the `--engine (default|pcre2|auto)` option.
* ripgrep has [rudimentary support for replacements](GUIDE.md#replacements),
  which permit rewriting output based on what was matched.
* ripgrep supports [searching files in text encodings](GUIDE.md#file-encoding)
  other than UTF-8, such as UTF-16, latin-1, GBK, EUC-JP, Shift_JIS and more.
  (Some support for automatically detecting UTF-16 is provided. Other text
  encodings must be specifically specified with the `-E/--encoding` flag.)
* ripgrep supports searching files compressed in a common format (brotli,
  bzip2, gzip, lz4, lzma, xz, or zstandard) with the `-z/--search-zip` flag.
* ripgrep supports
  [arbitrary input preprocessing filters](GUIDE.md#preprocessor)
  which could be PDF text extraction, less supported decompression, decrypting,
  automatic encoding detection and so on.
* ripgrep can be configured via a
  [configuration file](GUIDE.md#configuration-file).

In other words, use ripgrep if you like speed, filtering by default, fewer
bugs and Unicode support.


### Why shouldn&#039;t I use ripgrep?

Despite initially not wanting to add every feature under the sun to ripgrep,
over time, ripgrep has grown support for most features found in other file
searching tools. This includes searching for results spanning across multiple
lines, and opt-in support for PCRE2, which provides look-around and
backreference support.

At this point, the primary reasons not to use ripgrep probably consist of one
or more of the following:

* You need a portable and ubiquitous tool. While ripgrep works on Windows,
  macOS and Linux, it is not ubiquitous and it does not conform to any
  standard such as POSIX. The best tool for this job is good old grep.
* There still exists some other feature (or bug) not listed in this README that
  you rely on that&#039;s in another tool that isn&#039;t in ripgrep.
* There is a performance edge case where ripgrep doesn&#039;t do well where another
  tool does do well. (Please file a bug report!)
* ripgrep isn&#039;t possible to install on your machine or isn&#039;t available for your
  platform. (Please file a bug report!)


### Is it really faster than everything else?

Generally, yes. A large number of benchmarks with detailed analysis for each is
[available on my blog](https://blog.burntsushi.net/ripgrep/).

Summarizing, ripgrep is fast because:

* It is built on top of
  [Rust&#039;s regex engine](https://github.com/rust-lang/regex).
  Rust&#039;s regex engine uses finite automata, SIMD and aggressive literal
  optimizations to make searching very fast. (PCRE2 support can be opted into
  with the `-P/--pcre2` flag.)
* Rust&#039;s regex library maintains performance with full Unicode support by
  building UTF-8 decoding directly into its deterministic finite automaton
  engine.
* It supports searching with either memory maps or by searching incrementally
  with an intermediate buffer. The former is better for single files and the
  latter is better for large directories. ripgrep chooses the best searching
  strategy for you automatically.
* Applies your ignore patterns in `.gitignore` files using a
  [`RegexSet`](https://docs.rs/regex/1/regex/struct.RegexSet.html).
  That means a single file path can be matched against multiple glob patterns
  simultaneously.
* It uses a lock-free parallel recursive directory iterator, courtesy of
  [`crossbeam`](https://docs.rs/crossbeam) and
  [`ignore`](https://docs.rs/ignore).


### Feature comparison

Andy Lester, author of [ack](https://beyondgrep.com/), has published an
excellent table comparing the features of ack, ag, git-grep, GNU grep and
ripgrep: https://beyondgrep.com/feature-comparison/

Note that ripgrep has grown a few significant new features recently that
are not yet present in Andy&#039;s table. This includes, but is not limited to,
configuration files, passthru, support for searching compressed files,
multiline search and opt-in fancy regex support via PCRE2.


### Playground

If you&#039;d like to try ripgrep before installing, there&#039;s an unofficial
[playground](https://codapi.org/ripgrep/) and an [interactive
tutorial](https://codapi.org/try/ripgrep/).

If you have any questions about these, please open an issue in the [tutorial
repo](https://github.com/nalgeon/tryxinyminutes).


### Installation

The binary name for ripgrep is `rg`.

**[Archives of precompiled binaries for ripgrep are available for Windows,
macOS and Linux.](https://github.com/BurntSushi/ripgrep/releases)** Linux and
Windows binaries are static executables. Users of platforms not explicitly
mentioned below are advised to download one of these archives.

If you&#039;re a **macOS Homebrew** or a **Linuxbrew** user, then you can install
ripgrep from homebrew-core:

```
$ brew install ripgrep
```

If you&#039;re a **MacPorts** user, then you can install ripgrep from the
[official ports](https://www.macports.org/ports.php?by=name&amp;substr=ripgrep):

```
$ sudo port install ripgrep
```

If you&#039;re a **Windows Chocolatey** user, then you can install ripgrep from the
[official repo](https://chocolatey.org/packages/ripgrep):

```
$ choco install ripgrep
```

If you&#039;re a **Windows Scoop** user, then you can install ripgrep from the
[official bucket](https://github.com/ScoopInstaller/Main/blob/master/bucket/ripgrep.json):

```
$ scoop install ripgrep
```

If you&#039;re a **Windows Winget** user, then you can install ripgrep from the
[winget-pkgs](https://github.com/microsoft/winget-pkgs/tree/master/manifests/b/BurntSushi/ripgrep)
repository:

```
$ winget install BurntSushi.ripgrep.MSVC
```

If you&#039;re an **Arch Linux** user, then you can install ripgrep from the official repos:

```
$ sudo pacman -S ripgrep
```

If you&#039;re a **Gentoo** user, you can install ripgrep from the
[official repo](https://packages.gentoo.org/packages/sys-apps/ripgrep):

```
$ sudo emerge sys-apps/ripgrep
```

If you&#039;re a **Fedora** user, you can install ripgrep from official
repositories.

```
$ sudo dnf install ripgrep
```

If you&#039;re an **openSUSE** user, ripgrep is included in **openSUSE Tumbleweed**
and **openSUSE Leap** since 15.1.

```
$ sudo zypper install ripgrep
```

If you&#039;re a **RHEL/CentOS 7/8** user, you can install ripgrep from
[copr](https://copr.fedorainfracloud.org/coprs/carlwgeorge/ripgrep/):

```
$ sudo yum install -y yum-utils
$ sudo yum-config-manager --add-repo=https://copr.fedorainfracloud.org/coprs/carlwgeorge/ripgrep/repo/epel-7/carlwgeorge-ripgrep-epel-7.repo
$ sudo yum install ripgrep
```

If you&#039;re a **Nix** user, you can install ripgrep from
[nixpkgs](https://github.com/NixOS/nixpkgs/blob/master/pkgs/tools/text/ripgrep/default.nix):

```
$ nix-env --install ripgrep
```

If you&#039;re a **Flox** user, you can install ripgrep as follows:

```
$ flox install ripgrep
```

If you&#039;re a **Guix** user, you can install ripgrep from the official
package collection:

```
$ guix install ripgrep
```

If you&#039;re a **Debian** user (or a user of a Debian derivative like **Ubuntu**),
then ripgrep can be installed using a binary `.deb` file provided in each
[ripgrep release](https://github.com/BurntSushi/ripgrep/releases).

```
$ curl -LO https://github.com/BurntSushi/ripgrep/releases/download/14.1.0/ripgrep_14.1.1-1_amd64.deb
$ sudo dpkg -i ripgrep_14.1.1-1_amd64.deb
```

If you run Debian stable, ripgrep is [officially maintained by
Debian](https://tracker.debian.org/pkg/rust-ripgrep), although its version may
be older than the `deb` package available in the previous step.

```
$ sudo apt-get install ripgrep
```

If you&#039;re an **Ubuntu Cosmic (18.10)** (or newer) user, ripgrep is
[available](https://launchpad.net/ubuntu/+source/rust-ripgrep) using the same
packaging as Debian:

```
$ sudo apt-get install ripgrep
```

(N.B. Various snaps for ripgrep on Ubuntu are also available, but none of them
seem to work right and generate a number of very strange bug reports that I
don&#039;t know how to fix and don&#039;t have the time to fix. Therefore, it is no
longer a recommended installation option.)

If you&#039;re an **ALT** user, you can install ripgrep from the
[official repo](https://packages.altlinux.org/en/search?name=ripgrep):

```
$ sudo apt-get install ripgrep
```

If you&#039;re a **FreeBSD** user, then you can install ripgrep from the
[official ports](https://www.freshports.org/textproc/ripgrep/):

```
$ sudo pkg install ripgrep
```

If you&#039;re an **OpenBSD** user, then you can install ripgrep from the
[official ports](https://openports.se/textproc/ripgrep):

```
$ doas pkg_add ripgrep
```

If you&#039;re a **NetBSD** user, then you can install ripgrep from
[pkgsrc](https://pkgsrc.se/textproc/ripgrep):

```
$ sudo pkgin install ripgrep
```

If you&#039;re a **Haiku x86_64** user, then you can install ripgrep from the
[official ports](https://github.com/haikuports/haikuports/tree/master/sys-apps/ripgrep):

```
$ sudo pkgman install ripgrep
```

If you&#039;re a **Haiku x86_gcc2** user, then you can install ripgrep from the
same port as Haiku x86_64 using the x86 secondary architecture build:

```
$ sudo pkgman install ripgrep_x86
```

If you&#039;re a **Void Linux** user, then you can install ripgrep from the
[official repository](https://voidlinux.org/packages/?arch=x86_64&amp;q=ripgrep):

```
$ sudo xbps-install -Syv ripgrep
```

If you&#039;re a **Rust programmer**, ripgrep can be installed with `cargo`.

* Note that the minimum supported version of Rust for ripgrep is **1.72.0**,
  although ripgrep may work with older versions.
* Note that the binary may be bigger than expected because it contains debug
  symbols. This is intentional. To remove debug symbols and therefore reduce
  the file size, run `strip` on the binary.

```
$ cargo install ripgrep
```

Alternatively, one can use [`cargo
binstall`](https://github.com/cargo-bins/cargo-binstall) to install a ripgrep
binary directly from GitHub:

```
$ cargo binstall ripgrep
```


### Building

ripgrep is written in Rust, so you&#039;ll need to grab a
[Rust installation](https://www.rust-lang.org/) in order to compile it.
ripgrep compiles with Rust 1.72.0 (stable) or newer. In general, ripgrep tracks
the latest stable release of the Rust compiler.

To build ripgrep:

```
$ git clone https://github.com/BurntSushi/ripgrep
$ cd ripgrep
$ cargo build --release
$ ./target/release/rg --version
0.1.3
```

**NOTE:** In the past, ripgrep supported a `simd-accel` Cargo feature when
using a Rust nightly compiler. This only benefited UTF-16 transcoding.
Since it required unstable features, this build mode was prone to breakage.
Because of that, support for it has been removed. If you want SIMD
optimizations for UTF-16 transcoding, then you&#039;ll have to petition the
[`encoding_rs`](https://github.com/hsivonen/encoding_rs) project to use stable
APIs.

Finally, optional PCRE2 support can be built with ripgrep by enabling the
`pcre2` feature:

```
$ cargo build --release --features &#039;pcre2&#039;
```

Enabling the PCRE2 feature works with a stable Rust compiler and will
attempt to automatically find and link with your system&#039;s PCRE2 library via
`pkg-config`. If one doesn&#039;t exist, then ripgrep will build PCRE2 from source
using your system&#039;s C compiler and then statically link it into the final
executable. Static linking can be forced even when there is an available PCRE2
system library by either building ripgrep with the MUSL target or by setting
`PCRE2_SYS_STATIC=1`.

ripgrep can be built with the MUSL target on Linux by first installing the MUSL
library on your system (consult your friendly neighborhood package manager).
Then you just need to add MUSL support to your Rust toolchain and rebuild
ripgrep, which yields a fully static executable:

```
$ rustup target add x86_64-unknown-linux-musl
$ cargo build --release --target x86_64-unknown-linux-musl
```

Applying the `--features` flag from above works as expected. If you want to
build a static executable with MUSL and with PCRE2, then you will need to have
`musl-gcc` installed, which might be in a separate package from the actual
MUSL library, depending on your Linux distribution.


### Running tests

ripgrep is relatively well-test

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[solana-labs/solana]]></title>
            <link>https://github.com/solana-labs/solana</link>
            <guid>https://github.com/solana-labs/solana</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/solana-labs/solana">solana-labs/solana</a></h1>
            <p>Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.</p>
            <p>Language: Rust</p>
            <p>Stars: 14,178</p>
            <p>Forks: 4,902</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># PLEASE READ: This repo is now a public archive

This repo still exists in archived form, feel free to fork any reference
implementations it still contains.

See Agave, the Solana validator implementation from Anza: https://github.com/anza-xyz/agave

---

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://solana.com&quot;&gt;
    &lt;img alt=&quot;Solana&quot; src=&quot;https://i.imgur.com/IKyzQ6T.png&quot; width=&quot;250&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

[![Solana crate](https://img.shields.io/crates/v/solana-core.svg)](https://crates.io/crates/solana-core)
[![Solana documentation](https://docs.rs/solana-core/badge.svg)](https://docs.rs/solana-core)
[![Build status](https://badge.buildkite.com/8cc350de251d61483db98bdfc895b9ea0ac8ffa4a32ee850ed.svg?branch=master)](https://buildkite.com/solana-labs/solana/builds?branch=master)
[![codecov](https://codecov.io/gh/solana-labs/solana/branch/master/graph/badge.svg)](https://codecov.io/gh/solana-labs/solana)

# Building

## **1. Install rustc, cargo and rustfmt.**

```bash
$ curl https://sh.rustup.rs -sSf | sh
$ source $HOME/.cargo/env
$ rustup component add rustfmt
```

When building the master branch, please make sure you are using the latest stable rust version by running:

```bash
$ rustup update
```

When building a specific release branch, you should check the rust version in `ci/rust-version.sh` and if necessary, install that version by running:

```bash
$ rustup install VERSION
```

Note that if this is not the latest rust version on your machine, cargo commands may require an [override](https://rust-lang.github.io/rustup/overrides.html) in order to use the correct version.

On Linux systems you may need to install libssl-dev, pkg-config, zlib1g-dev, protobuf etc.

On Ubuntu:

```bash
$ sudo apt-get update
$ sudo apt-get install libssl-dev libudev-dev pkg-config zlib1g-dev llvm clang cmake make libprotobuf-dev protobuf-compiler
```

On Fedora:

```bash
$ sudo dnf install openssl-devel systemd-devel pkg-config zlib-devel llvm clang cmake make protobuf-devel protobuf-compiler perl-core
```

## **2. Download the source code.**

```bash
$ git clone https://github.com/solana-labs/solana.git
$ cd solana
```

## **3. Build.**

```bash
$ ./cargo build
```

# Testing

**Run the test suite:**

```bash
$ ./cargo test
```

### Starting a local testnet

Start your own testnet locally, instructions are in the [online docs](https://docs.solanalabs.com/clusters/benchmark).

### Accessing the remote development cluster

- `devnet` - stable public cluster for development accessible via
  devnet.solana.com. Runs 24/7. Learn more about the [public clusters](https://docs.solanalabs.com/clusters)

# Benchmarking

First, install the nightly build of rustc. `cargo bench` requires the use of the
unstable features only available in the nightly build.

```bash
$ rustup install nightly
```

Run the benchmarks:

```bash
$ cargo +nightly bench
```

# Release Process

The release process for this project is described [here](RELEASE.md).

# Code coverage

To generate code coverage statistics:

```bash
$ scripts/coverage.sh
$ open target/cov/lcov-local/index.html
```

Why coverage? While most see coverage as a code quality metric, we see it primarily as a developer
productivity metric. When a developer makes a change to the codebase, presumably it&#039;s a _solution_ to
some problem. Our unit-test suite is how we encode the set of _problems_ the codebase solves. Running
the test suite should indicate that your change didn&#039;t _infringe_ on anyone else&#039;s solutions. Adding a
test _protects_ your solution from future changes. Say you don&#039;t understand why a line of code exists,
try deleting it and running the unit-tests. The nearest test failure should tell you what problem
was solved by that code. If no test fails, go ahead and submit a Pull Request that asks, &quot;what
problem is solved by this code?&quot; On the other hand, if a test does fail and you can think of a
better way to solve the same problem, a Pull Request with your solution would most certainly be
welcome! Likewise, if rewriting a test can better communicate what code it&#039;s protecting, please
send us that patch!

# Disclaimer

All claims, content, designs, algorithms, estimates, roadmaps,
specifications, and performance measurements described in this project
are done with the Solana Labs, Inc. (“SL”) good faith efforts. It is up to
the reader to check and validate their accuracy and truthfulness.
Furthermore, nothing in this project constitutes a solicitation for
investment.

Any content produced by SL or developer resources that SL provides are
for educational and inspirational purposes only. SL does not encourage,
induce or sanction the deployment, integration or use of any such
applications (including the code comprising the Solana blockchain
protocol) in violation of applicable laws or regulations and hereby
prohibits any such deployment, integration or use. This includes the use of
any such applications by the reader (a) in violation of export control
or sanctions laws of the United States or any other applicable
jurisdiction, (b) if the reader is located in or ordinarily resident in
a country or territory subject to comprehensive sanctions administered
by the U.S. Office of Foreign Assets Control (OFAC), or (c) if the
reader is or is working on behalf of a Specially Designated National
(SDN) or a person subject to similar blocking or denied party
prohibitions.

The reader should be aware that U.S. export control and sanctions laws prohibit
U.S. persons (and other persons that are subject to such laws) from transacting
with persons in certain countries and territories or that are on the SDN list.
Accordingly, there is a risk to individuals that other persons using any of the
code contained in this repo, or a derivation thereof, may be sanctioned persons
and that transactions with such persons would be a violation of U.S. export
controls and sanctions law.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[EFForg/rayhunter]]></title>
            <link>https://github.com/EFForg/rayhunter</link>
            <guid>https://github.com/EFForg/rayhunter</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Rust tool to detect cell site simulators on an orbic mobile hotspot]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EFForg/rayhunter">EFForg/rayhunter</a></h1>
            <p>Rust tool to detect cell site simulators on an orbic mobile hotspot</p>
            <p>Language: Rust</p>
            <p>Stars: 2,090</p>
            <p>Forks: 158</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>![Rayhunter Logo - An Orca taking a bite out of a cellular signal bar](https://www.eff.org/files/styles/media_browser_preview/public/banner_library/rayhunter-banner.png)

# Rayhunter

![Tests](https://github.com/EFForg/rayhunter/actions/workflows/check-and-test.yml/badge.svg)

Rayhunter is an IMSI Catcher Catcher for the Orbic mobile hotspot. To learn more, check out the [Rayhunter Book](https://efforg.github.io/rayhunter/).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[eclipse-zenoh/zenoh]]></title>
            <link>https://github.com/eclipse-zenoh/zenoh</link>
            <guid>https://github.com/eclipse-zenoh/zenoh</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[zenoh unifies data in motion, data in-use, data at rest and computations. It carefully blends traditional pub/sub with geo-distributed storages, queries and computations, while retaining a level of time and space efficiency that is well beyond any of the mainstream stacks.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eclipse-zenoh/zenoh">eclipse-zenoh/zenoh</a></h1>
            <p>zenoh unifies data in motion, data in-use, data at rest and computations. It carefully blends traditional pub/sub with geo-distributed storages, queries and computations, while retaining a level of time and space efficiency that is well beyond any of the mainstream stacks.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,900</p>
            <p>Forks: 196</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://raw.githubusercontent.com/eclipse-zenoh/zenoh/master/zenoh-dragon.png&quot; height=&quot;150&quot;&gt;

[![CI](https://github.com/eclipse-zenoh/zenoh/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/eclipse-zenoh/zenoh/actions?query=workflow%3ACI+branch%3Amain++)
[![Documentation Status](https://readthedocs.org/projects/zenoh-rust/badge/?version=latest)](https://zenoh-rust.readthedocs.io/en/latest/?badge=latest)
[![codecov](https://codecov.io/github/eclipse-zenoh/zenoh/branch/main/graph/badge.svg?token=F8T4C8WPZD)](https://codecov.io/github/eclipse-zenoh/zenoh)
[![Discussion](https://img.shields.io/badge/discussion-on%20github-blue)](https://github.com/eclipse-zenoh/roadmap/discussions)
[![Discord](https://img.shields.io/badge/chat-on%20discord-blue)](https://discord.gg/2GJ958VuHs)
[![License](https://img.shields.io/badge/License-EPL%202.0-blue)](https://choosealicense.com/licenses/epl-2.0/)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

# Eclipse Zenoh

The Eclipse Zenoh: Zero Overhead Pub/sub, Store/Query and Compute.

Zenoh (pronounce _/zeno/_) unifies data in motion, data at rest and computations. It carefully blends traditional pub/sub with geo-distributed storages, queries and computations, while retaining a level of time and space efficiency that is well beyond any of the mainstream stacks.

Check the website [zenoh.io](http://zenoh.io) and the [roadmap](https://github.com/eclipse-zenoh/roadmap) for more detailed information.

-------------------------------

## Getting Started

Zenoh is extremely easy to learn, the best place to master the fundamentals is our [getting started guide](https://zenoh.io/docs/getting-started/first-app/).

-------------------------------

## How to install it

To install the latest release of the Zenoh router (`zenohd`) and its default plugins (REST API plugin and Storages Manager plugin) you can do as follows:

### Manual installation (all platforms)

All release packages can be downloaded from [https://download.eclipse.org/zenoh/zenoh/latest/](https://download.eclipse.org/zenoh/zenoh/latest/).

Each subdirectory has the name of the Rust target. See the platforms each target corresponds to on [https://doc.rust-lang.org/stable/rustc/platform-support.html](https://doc.rust-lang.org/stable/rustc/platform-support.html).

Choose your platform and download the `.zip` file.
Unzip it where you want, and run the extracted `zenohd` binary.

### Linux Debian

Add Eclipse Zenoh private repository to the sources list, and install the `zenoh` package:

```bash
echo &quot;deb [trusted=yes] https://download.eclipse.org/zenoh/debian-repo/ /&quot; | sudo tee -a /etc/apt/sources.list.d/zenoh.list &gt; /dev/null
sudo apt update
sudo apt install zenoh
```

Then you can start run `zenohd`.

### MacOS

Tap our brew package repository and install the `zenoh` formula:

```bash
brew tap eclipse-zenoh/homebrew-zenoh
brew install zenoh
```

Then you can start run `zenohd`.

-------------------------------

## Rust API

* [Docs.rs for Zenoh](https://docs.rs/zenoh/latest/zenoh/)

-------------------------------

## How to build it

Install [Cargo and Rust](https://doc.rust-lang.org/cargo/getting-started/installation.html). Zenoh can be successfully compiled with Rust stable (&gt;= 1.75.0), so no special configuration is required from your side. If you already have the Rust toolchain installed, make sure it is up-to-date with:

```bash
rustup update
```

To build Zenoh, just type the following command after having followed the previous instructions:

```bash
cargo build --release --all-targets
```

Zenoh&#039;s router is built as `target/release/zenohd`. All the examples are built into the `target/release/examples` directory. They can all work in peer-to-peer, or interconnected via the zenoh router.

-------------------------------

## Quick tests of your build

### Peer-to-peer tests

* **pub/sub**
  * run: `./target/release/examples/z_sub`
  * in another shell run: `./target/release/examples/z_put`
  * the subscriber should receive the publication.

* **get/queryable**
  * run: `./target/release/examples/z_queryable`
  * in another shell run: `./target/release/examples/z_get`
  * the queryable should display the log in its listener, and the get should receive the queryable result.

### Routed tests

&gt; [!NOTE]
&gt; **Windows users**: to properly execute the commands below in PowerShell you need to escape `&quot;` characters as `\&quot;`.

* **put / store / get**
  * run the Zenoh router with a memory storage:

    ```sh
    ./target/release/zenohd --cfg=&#039;plugins/storage_manager/storages/demo:{key_expr:&quot;demo/example/**&quot;,volume:&quot;memory&quot;}&#039;
    ```

  * in another shell run:
  
    ```sh
    ./target/release/examples/z_put`
    ```

  * then run

    ```sh
    ./target/release/examples/z_get
    ```

  * the get should receive the stored publication.

* **REST API using `curl` tool**
  * run the Zenoh router with a memory storage:

    ```sh
    ./target/release/zenohd --cfg=&#039;plugins/storage_manager/storages/demo:{key_expr:&quot;demo/example/**&quot;,volume:&quot;memory&quot;}&#039;
    ```

  * in another shell, do a publication via the REST API:

    ```sh
    curl -X PUT -d &#039;&quot;Hello World!&quot;&#039; http://localhost:8000/demo/example/test
    ```

  * get it back via the REST API:

    ```sh
    curl http://localhost:8000/demo/example/test
    ```

* **router admin space via the REST API**
  * run the Zenoh router with permission to perform config changes via the admin space, and with a memory storage:

    ```sh
    ./target/release/zenohd --rest-http-port=8000 --adminspace-permissions=rw --cfg=&#039;plugins/storage_manager/storages/demo:{key_expr:&quot;demo/example/**&quot;,volume:&quot;memory&quot;}&#039;
    ```

  * in another shell, get info of the zenoh router via the zenoh admin space (you may use `jq` for pretty json formatting):

    ```sh
    curl -s http://localhost:8000/@/local/router | jq
    ```

  * get the volumes of the router (only memory by default):

    ```sh
    curl -s &#039;http://localhost:8000/@/local/router/**/volumes/*&#039; | jq
    ```

  * get the storages of the local router (the memory storage configured at startup on &#039;/demo/example/**&#039; should be present):

    ```sh
    curl -s &#039;http://localhost:8000/@/local/router/**/storages/*&#039; | jq
    ```

  * add another memory storage on `/demo/mystore/**`:

    ```sh
    curl -X PUT -H &#039;content-type:application/json&#039; -d &#039;{&quot;key_expr&quot;:&quot;demo/mystore/**&quot;,&quot;volume&quot;:&quot;memory&quot;}&#039; http://localhost:8000/@/local/router/config/plugins/storage_manager/storages/mystore
    ```

  * check it has been created:
  
    ```sh
    curl -s &#039;http://localhost:8000/@/local/router/**/storages/*&#039; | jq
    ```

### Configuration options

A Zenoh configuration file can be provided via CLI to all Zenoh examples and the Zenoh router.

* `-c, --config &lt;FILE&gt;`: a [JSON5](https://json5.org) configuration file. [DEFAULT_CONFIG.json5](DEFAULT_CONFIG.json5) shows the schema of this file and the available options.

See other examples of Zenoh usage in [examples/](examples)

&gt; [!NOTE]
&gt; **Zenoh Runtime Configuration**: Starting from version 0.11.0-rc, Zenoh allows for configuring the number of worker threads and other advanced options of the runtime. For guidance on utilizing it, please refer to the [doc](https://docs.rs/zenoh-runtime/latest/zenoh_runtime/enum.ZRuntime.html).

-------------------------------

## Zenoh router command line arguments

`zenohd` accepts the following arguments:

* `--adminspace-permissions &lt;[r|w|rw|none]&gt;`: Configure the read and/or write permissions on the admin space. Default is read only.
* `-c, --config &lt;FILE&gt;`: a [JSON5](https://json5.org) configuration file. [DEFAULT_CONFIG.json5](DEFAULT_CONFIG.json5) shows the schema of this file. All properties of this configuration are optional, so you may not need such a large configuration for your use-case.
* `--cfg &lt;KEY&gt;:&lt;VALUE&gt;`: allows you to change specific parts of the configuration right after it has been constructed. VALUE must be a valid JSON5 value, and key must be a path through the configuration file, where each element is separated by a `/`. When inserting in parts of the config that are arrays, you may use indexes, or may use `+` to indicate that you want to append your value to the array. `--cfg` passed values will always override any previously existing value for their key in the configuration.
* `-l, --listen &lt;ENDPOINT&gt;...`: An endpoint on which this router will listen for incoming sessions.
  Repeat this option to open several listeners. By default, `tcp/[::]:7447` is used. The following endpoints are currently supported:
  * TCP: `tcp/&lt;host_name_or_IPv4_or_IPv6&gt;:&lt;port&gt;`
  * UDP: `udp/&lt;host_name_or_IPv4_or_IPv6&gt;:&lt;port&gt;`
  * [TCP+TLS](https://zenoh.io/docs/manual/tls/): `tls/&lt;host_name&gt;:&lt;port&gt;`
  * [QUIC](https://zenoh.io/docs/manual/quic/): `quic/&lt;host_name&gt;:&lt;port&gt;`
* `-e, --connect &lt;ENDPOINT&gt;...`: An endpoint this router will try to connect to. Repeat this option to connect to several peers or routers.
* `--no-multicast-scouting`: By default zenohd replies to multicast scouting messages for being discovered by peers and clients.
  This option disables this feature.
* `-i, --id &lt;hex_string&gt;`: The identifier (as an hexadecimal string - e.g.: A0B23...) that zenohd must use.
   **WARNING**: this identifier must be unique in the system! If not set, a random unsigned 128bit integer will be used.
* `--no-timestamp`: By default zenohd adds a HLC-generated Timestamp to each routed Data if there isn&#039;t already one.
  This option disables this feature.
* `-P, --plugin [&lt;PLUGIN_NAME&gt; | &lt;PLUGIN_NAME&gt;:&lt;LIBRARY_PATH&gt;]...`: A [plugin](https://zenoh.io/docs/manual/plugins/) that must be loaded. Accepted values:
  * a plugin name; zenohd will search for a library named `libzenoh_plugin_&lt;name&gt;.so` on Unix, `libzenoh_plugin_&lt;PLUGIN_NAME&gt;.dylib` on MacOS or `zenoh_plugin_&lt;PLUGIN_NAME&gt;.dll` on Windows.
  * `&quot;&lt;PLUGIN_NAME&gt;:&lt;LIBRARY_PATH&gt;&quot;`; the plugin will be loaded from library file at `&lt;LIBRARY_PATH&gt;`.

  Repeat this option to load several plugins.
* `--plugin-search-dir &lt;DIRECTORY&gt;...`: A directory where to search for [plugins](https://zenoh.io/docs/manual/plugins/) libraries to load.
  Repeat this option to specify several search directories&#039;. By default, the plugins libraries will be searched in:
  `&#039;/usr/local/lib:/usr/lib:~/.zenoh/lib:.&#039;`
* `--rest-http-port &lt;rest-http-port&gt;`: Configures the [REST plugin](https://zenoh.io/docs/manual/plugin-http/)&#039;s HTTP port. Accepted values:
  * a port number
  * a string with format `&lt;local_ip&gt;:&lt;port_number&gt;` (to bind the HTTP server to a specific interface)
  * `&quot;None&quot;` to deactivate the REST plugin

  If not specified, the REST plugin will be active on any interface (`[::]`) and port `8000`.

-------------------------------

## Plugins

&gt; [!WARNING]
&gt; As Rust doesn&#039;t have a stable ABI, the plugins should be
built with the exact same Rust version as `zenohd`, and using for `zenoh` dependency the same version (or commit number) as `zenohd` with the same
set of features. A plugin compiled with different Rust version or with different set of `zenoh` crate features will be rejected when `zenohd` attempts to load it. Otherwise, incompatibilities in memory mapping of structures shared between `zenohd` and the library could lead to a `&quot;SIGSEGV&quot;` crash.

By default the Zenoh router is delivered or built with 2 plugins. These may be configured through a configuration file, or through individual changes to the configuration via the `--cfg` CLI option or via zenoh puts on individual parts of the configuration.

**[REST plugin](https://zenoh.io/docs/manual/plugin-http/)** (exposing a REST API):
This plugin converts GET and PUT REST requests into Zenoh gets and puts respectively.

Note that to activate the REST plugin on `zenohd` the CLI argument should be passed: `--rest-http-port=8000` (or any other port of your choice).

**[Storages plugin](https://zenoh.io/docs/manual/plugin-storage-manager/)** (managing [backends and storages](https://zenoh.io/docs/manual/plugin-storage-manager/#backends-and-volumes))
This plugin allows you to easily define storages. These will store key-value pairs they subscribed to, and send the most recent ones when queried. Check out [DEFAULT_CONFIG.json5](DEFAULT_CONFIG.json5) for info on how to configure them.

-------------------------------

## Troubleshooting

In case of troubles, please first check on [this page](https://zenoh.io/docs/getting-started/troubleshooting/) if the trouble and cause are already known.
Otherwise, you can ask a question on the [zenoh Discord server](https://discord.gg/vSDSpqnbkm), or [create an issue](https://github.com/eclipse-zenoh/zenoh/issues).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vectordotdev/vector]]></title>
            <link>https://github.com/vectordotdev/vector</link>
            <guid>https://github.com/vectordotdev/vector</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[A high-performance observability data pipeline.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vectordotdev/vector">vectordotdev/vector</a></h1>
            <p>A high-performance observability data pipeline.</p>
            <p>Language: Rust</p>
            <p>Stars: 19,713</p>
            <p>Forks: 1,767</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://vector.dev/docs/setup/quickstart/&quot;&gt;Quickstart&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/docs/&quot;&gt;Docs&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/guides/&quot;&gt;Guides&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/components/&quot;&gt;Integrations&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://chat.vector.dev&quot;&gt;Chat&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/releases/latest/download/&quot;&gt;Download&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://rust-doc.vector.dev/&quot;&gt;Rust Crate Docs&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;website/static/img/diagram.svg&quot; alt=&quot;Vector&quot;&gt;
&lt;/p&gt;

## What is Vector?

Vector is a high-performance, end-to-end (agent &amp; aggregator) observability data
pipeline that puts you in control of your observability data.
[Collect][docs.sources], [transform][docs.transforms], and [route][docs.sinks]
all your logs and metrics to any vendors you want today and any other
vendors you may want tomorrow. Vector enables dramatic cost reduction, novel
data enrichment, and data security where you need it, not where it is most
convenient for your vendors. Additionally, it is open source and up to 10x
faster than every alternative in the space.

To get started, follow our [**quickstart guide**][docs.quickstart] or [**install
Vector**][docs.installation].

### Principles

* **Reliable** - Built in [Rust][urls.rust], Vector&#039;s primary design goal is reliability.
* **End-to-end** - Deploys as an [agent][docs.roles#agent] or [aggregator][docs.roles#aggregator]. Vector is a complete platform.
* **Unified** - [Logs][docs.data-model.log], [metrics][docs.data-model.metric] (beta), and traces (coming soon). One tool for all of your data.

### Use cases

* Reduce total observability costs.
* Transition vendors without disrupting workflows.
* Enhance data quality and improve insights.
* Consolidate agents and eliminate agent fatigue.
* Improve overall observability performance and reliability.

### Community

* Vector is relied on by startups and enterprises like **Atlassian**, **T-Mobile**,
  **Comcast**, **Zendesk**, **Discord**, **Fastly**, **CVS**, **Trivago**,
  **Tuple**, **Douban**, **Visa**, **Mambu**, **Blockfi**, **Claranet**,
  **Instacart**, **Forcepoint**, and [many more][urls.production_users].
* Vector is **downloaded over 100,000 times per day**.
* Vector&#039;s largest user **processes over 30TB daily**.
* Vector has **over 100 contributors** and growing.

## [Documentation](https://vector.dev/docs/)

### About

* [**Concepts**][docs.about.concepts]
* [**Under the hood**][docs.about.under-the-hood]
  * [**Architecture**][docs.under-the-hood.architecture] - [data model][docs.architecture.data-model] ([log][docs.data-model.log], [metric][docs.data-model.metric]), [pipeline model][docs.architecture.pipeline-model], [concurrency model][docs.architecture.concurrency-model], [runtime model][docs.architecture.runtime-model]
  * [**Networking**][docs.under-the-hood.networking] - [ARC][docs.networking.adaptive-request-concurrency]
  * [**Guarantees**][docs.under-the-hood.guarantees]

### Setup

* [**Quickstart**][docs.setup.quickstart]
* [**Installation**][docs.setup.installation] - [operating systems][docs.installation.operating_systems], [package managers][docs.installation.package_managers], [platforms][docs.installation.platforms] ([Kubernetes][docs.platforms.kubernetes]), [manual][docs.installation.manual]
* [**Deployment**][docs.deployment] - [roles][docs.deployment.roles], [topologies][docs.deployment.topologies]

### Reference

* **Configuration**
  * [**Sources**][docs.configuration.sources] - [docker_logs][docs.sources.docker_logs], [file][docs.sources.file], [http][docs.sources.http], [journald][docs.sources.journald], [kafka][docs.sources.kafka], [socket][docs.sources.socket], and [many more...][docs.sources]
  * [**Transforms**][docs.configuration.transforms] - [dedupe][docs.transforms.dedupe], [filter][docs.transforms.filter], [log_to_metric][docs.transforms.log_to_metric], [lua][docs.transforms.lua], [remap][docs.transforms.remap],
    and [many more...][docs.transforms]
  * [**Sinks**][docs.configuration.sinks] - [aws_cloudwatch_logs][docs.sinks.aws_cloudwatch_logs], [aws_s3][docs.sinks.aws_s3], [clickhouse][docs.sinks.clickhouse], [elasticsearch][docs.sinks.elasticsearch], [gcp_cloud_storage][docs.sinks.gcp_cloud_storage], and [many more...][docs.sinks]
  * [**Enrichment Tables**][docs.configuration.enrichment_tables]
  * [**Unit tests**][docs.configuration.tests]
* [**Remap Language**][docs.reference.vrl]
* [**API**][docs.reference.api]
* [**CLI**][docs.reference.cli]

### Administration

* [**Management**][docs.administration.management]
* [**Monitoring &amp; observing**][docs.administration.monitoring]
* [**Upgrading**][docs.administration.upgrading]
* [**Validating**][docs.administration.validating]

### Resources

* [**Community**][urls.vector_community] - [chat][urls.vector_chat], [calendar][urls.vector_calendar], [@vectordotdev][urls.vector_twitter]
* [**Releases**][urls.vector_releases]
* **Policies** - [Code of Conduct][urls.vector_code_of_conduct], [Privacy][urls.vector_privacy_policy], [Releases][urls.vector_releases_policy], [Security][urls.vector_security_policy], [Versioning][urls.vector_versioning_policy]

## Comparisons

### Performance

The following performance tests demonstrate baseline performance between
common protocols with the exception of the Regex Parsing test.

| Test                                                                                                                   | Vector          | Filebeat | FluentBit       | FluentD   | Logstash  | SplunkUF        | SplunkHF |
| ---------------------------------------------------------------------------------------------------------------------- | --------------- | -------- | --------------- | --------- | --------- | --------------- | -------- |
| [TCP to Blackhole](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance) | _**86mib/s**_   | n/a      | 64.4mib/s       | 27.7mib/s | 40.6mib/s | n/a             | n/a      |
| [File to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance)           | _**76.7mib/s**_ | 7.8mib/s | 35mib/s         | 26.1mib/s | 3.1mib/s  | 40.1mib/s       | 39mib/s  |
| [Regex Parsing](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance)       | 13.2mib/s       | n/a      | _**20.5mib/s**_ | 2.6mib/s  | 4.6mib/s  | n/a             | 7.8mib/s |
| [TCP to HTTP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance)           | _**26.7mib/s**_ | n/a      | 19.6mib/s       | &lt;1mib/s   | 2.7mib/s  | n/a             | n/a      |
| [TCP to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance)             | 69.9mib/s       | 5mib/s   | 67.1mib/s       | 3.9mib/s  | 10mib/s   | _**70.4mib/s**_ | 7.6mib/s |

To learn more about our performance tests, please see the [Vector test harness][urls.vector_test_harness].

### Correctness

The following correctness tests are not exhaustive, but they demonstrate
fundamental differences in quality and attention to detail:

| Test                                                                                                                                 | Vector | Filebeat | FluentBit | FluentD | Logstash | Splunk UF | Splunk HF |
| ------------------------------------------------------------------------------------------------------------------------------------ | ------ | -------- | --------- | ------- | -------- | --------- | --------- |
| [Disk Buffer Persistence](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness) | **✓**  | ✓        |           |         | ⚠        | ✓         | ✓         |
| [File Rotate (create)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness)         | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |
| [File Rotate (copytruncate)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness) | **✓**  |          |           |         |          | ✓         | ✓         |
| [File Truncation](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness)                   | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |
| [Process (SIGHUP)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness)                         | **✓**  |          |           |         | ⚠        | ✓         | ✓         |
| [JSON (wrapped)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness)                     | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |

To learn more about our correctness tests, please see the [Vector test harness][urls.vector_test_harness].

### Features

Vector is an end-to-end, unified, open data platform.

|                     | **Vector** | Beats | Fluentbit | Fluentd | Logstash | Splunk UF | Splunk HF | Telegraf |
| ------------------- | ---------- | ----- | --------- | ------- | -------- | --------- | --------- | -------- |
| **End-to-end**      | **✓**      |       |           |         |          |           |           | ✓        |
| Agent               | **✓**      | ✓     | ✓         |         |          | ✓         |           | ✓        |
| Aggregator          | **✓**      |       |           | ✓       | ✓        |           | ✓         | ✓        |
| **Unified**         | **✓**      |       |           |         |          |           |           | ✓        |
| Logs                | **✓**      | ✓     | ✓         | ✓       | ✓        | ✓         | ✓         | ✓        |
| Metrics             | **✓**      | ⚠     | ⚠         | ⚠       | ⚠        | ⚠         | ⚠         | ✓        |
| Traces              | 🚧         |       |           |         |          |           |           |          |
| **Open**            | **✓**      |       | ✓         | ✓       |          |           |           | ✓        |
| Open-source         | **✓**      | ✓     | ✓         | ✓       | ✓        |           |           | ✓        |
| Vendor-neutral      | **✓**      |       | ✓         | ✓       |          |           |           | ✓        |
| **Reliability**     | **✓**      |       |           |         |          |           |           |          |
| Memory-safe         | **✓**      |       |           |         |          |           |           | ✓        |
| Delivery guarantees | **✓**      |       |           |         |          | ✓         | ✓         |          |
| Multi-core          | **✓**      | ✓     | ✓         | ✓       | ✓        | ✓         | ✓         | ✓        |


⚠ = Not interoperable, metrics are represented as structured logs

---

&lt;p align=&quot;center&quot;&gt;
  Developed with ❤️ by &lt;strong&gt;&lt;a href=&quot;https://datadoghq.com&quot;&gt;Datadog&lt;/a&gt;&lt;/strong&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/security/policy&quot;&gt;Security Policy&lt;/a&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/blob/master/PRIVACY.md&quot;&gt;Privacy Policy&lt;/a&gt;
&lt;/p&gt;

[docs.about.concepts]: https://vector.dev/docs/about/concepts/
[docs.about.under-the-hood]: https://vector.dev/docs/about/under-the-hood/
[docs.administration.monitoring]: https://vector.dev/docs/administration/monitoring/
[docs.administration.management]: https://vector.dev/docs/administration/management/
[docs.administration.upgrading]: https://vector.dev/docs/administration/upgrading/
[docs.administration.validating]: https://vector.dev/docs/administration/validating/
[docs.architecture.concurrency-model]: https://vector.dev/docs/about/under-the-hood/architecture/concurrency-model/
[docs.architecture.data-model]: https://vector.dev/docs/about/under-the-hood/architecture/data-model/
[docs.architecture.pipeline-model]: https://vector.dev/docs/about/under-the-hood/architecture/pipeline-model/
[docs.architecture.runtime-model]: https://vector.dev/docs/about/under-the-hood/architecture/runtime-model/
[docs.configuration.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.configuration.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.configuration.tests]: https://vector.dev/docs/reference/configuration/tests/
[docs.configuration.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.configuration.enrichment_tables]: https://vector.dev/docs/reference/configuration/global-options/#enrichment_tables
[docs.data-model.log]: https://vector.dev/docs/about/under-the-hood/architecture/data-model/log/
[docs.data-model.metric]: https://vector.dev/docs/about/under-the-hood/architecture/data-model/metric/
[docs.deployment.roles]: https://vector.dev/docs/setup/deployment/roles/
[docs.deployment.topologies]: https://vector.dev/docs/setup/deployment/topologies/
[docs.deployment]: https://vector.dev/docs/setup/deployment/
[docs.installation.manual]: https://vector.dev/docs/setup/installation/manual/
[docs.installation.operating_systems]: https://vector.dev/docs/setup/installation/operating-systems/
[docs.installation.package_managers]: https://vector.dev/docs/setup/installation/package-managers/
[docs.installation.platforms]: https://vector.dev/docs/setup/installation/platforms/
[docs.installation]: https://vector.dev/docs/setup/installation/
[docs.networking.adaptive-request-concurrency]: https://vector.dev/docs/about/under-the-hood/networking/arc/
[docs.platforms.kubernetes]: https://vector.dev/docs/setup/installation/platforms/kubernetes/
[docs.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.reference.api]: https://vector.dev/docs/reference/api/
[docs.reference.cli]: https://vector.dev/docs/reference/cli/
[docs.reference.vrl]: https://vector.dev/docs/reference/vrl/
[docs.roles#agent]: https://vector.dev/docs/setup/deployment/roles/#agent
[docs.roles#aggregator]: https://vector.dev/docs/setup/deployment/roles/#aggregator
[docs.setup.installation]: https://vector.dev/docs/setup/installation/
[docs.setup.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.sinks.aws_cloudwatch_logs]: https://vector.dev/docs/reference/configuration/sinks/aws_cloudwatch_logs/
[docs.sinks.aws_s3]: https://vector.dev/docs/reference/configuration/sinks/aws_s3/
[docs.sinks.clickhouse]: https://vector.dev/docs/reference/configuration/sinks/clickhouse/
[docs.sinks.elasticsearch]: https://vector.dev/docs/reference/configuration/sinks/elasticsearch/
[docs.sinks.gcp_cloud_storage]: https://vector.dev/docs/reference/configuration/sinks/gcp_cloud_storage/
[docs.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.sources.docker_logs]: https://vector.dev/docs/reference/configuration/sources/docker_logs/
[docs.sources.file]: https://vector.dev/docs/reference/configuration/sources/file/
[docs.sources.http]: https://vector.dev/docs/reference/configuration/sources/http/
[docs.sources.journald]: https://vector.dev/docs/reference/configuration/sources/journald/
[docs.sources.kafka]: https://vector.dev/docs/reference/configuration/sources/kafka/
[docs.sources.socket]: https://vector.dev/docs/reference/configuration/sources/socket/
[docs.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.transforms.dedupe]: https://vector.dev/docs/reference/configuration/transforms/dedupe/
[docs.transforms.filter]: https://vector.dev/docs/reference/configuration/transforms/filter/
[docs.transforms.log_to_metric]: https://vector.dev/docs/reference/configuration/transforms/log_to_metric/
[docs.transforms.lua]: https://vector.dev/docs/reference/configuration/transforms/lua/
[docs.transforms.remap]: https://vector.dev/docs/reference/configuration/transforms/remap/
[docs.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.under-the-hood.architecture]: https://vector.dev/docs/about/under-the-hood/architecture/
[docs.under-the-hood.guarantees]: https://vector.dev/docs/about/under-the-hood/guarantees/
[docs.under-the-hood.networking]: https://vector.dev/docs/about/under-the-hood/networking/
[urls.production_users]: https://github.com/vectordotdev/vector/issues/790
[urls.rust]: https://www.rust-lang.org/
[urls.vector_calendar]: https://calendar.vector.dev
[urls.vector_chat]: https://chat.vector.dev
[urls.vector_code_of_conduct]: https://github.com/vectordotdev/vector/blob/master/CODE_OF_CONDUCT.md
[urls.vector_community]: https://vector.dev/community/
[urls.vector_privacy_policy]: https://github.com/vectordotdev/vector/blob/master/PRIVACY.md
[urls.vector_release_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASING.md
[urls.vector_releases]: https://vector.dev/releases/
[urls.vector_releases_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASES.md
[urls.vector_security_policy]: https://github.com/vectordotdev/vector/security/policy
[urls.vector_test_harness]: https://github.com/vectordotdev/vector-test-harness/
[urls.vector_twitter]: https://twitter.com/vectordotdev
[urls.vector_versioning_policy]: https://github.com/vectordotdev/vector/blob/master/VERSIONING.md
[urls.vote_feature]: https://github.com/vectordotdev/vector/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22type%3A+feature%22

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[mainmatter/100-exercises-to-learn-rust]]></title>
            <link>https://github.com/mainmatter/100-exercises-to-learn-rust</link>
            <guid>https://github.com/mainmatter/100-exercises-to-learn-rust</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[A self-paced course to learn Rust, one exercise at a time.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mainmatter/100-exercises-to-learn-rust">mainmatter/100-exercises-to-learn-rust</a></h1>
            <p>A self-paced course to learn Rust, one exercise at a time.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,888</p>
            <p>Forks: 1,565</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># Learn Rust, one exercise at a time

You&#039;ve heard about Rust, but you never had the chance to try it out?\
This course is for you!

You&#039;ll learn Rust by solving 100 exercises.\
You&#039;ll go from knowing nothing about Rust to being able to start
writing your own programs, one exercise at a time.

&gt; [!NOTE]
&gt; This course has been written by [Mainmatter](https://mainmatter.com/rust-consulting/).\
&gt; It&#039;s one of the trainings in [our portfolio of Rust workshops](https://mainmatter.com/services/workshops/rust/).\
&gt; Check out our [landing page](https://mainmatter.com/rust-consulting/) if you&#039;re looking for Rust consulting or
&gt; training!

## Getting started

Go to [rust-exercises.com](https://rust-exercises.com) and follow the instructions there
to get started with the course.

## Requirements

- **Rust** (follow instructions [here](https://www.rust-lang.org/tools/install)).\
  If `rustup` is already installed on your system, run `rustup update` (or another appropriate command depending on how
  you installed Rust on your system)
  to make sure you&#039;re running on the latest stable version.
- _(Optional but recommended)_ An IDE with Rust autocompletion support.
  We recommend one of the following:
  - [RustRover](https://www.jetbrains.com/rust/);
  - [Visual Studio Code](https://code.visualstudio.com) with
    the [`rust-analyzer`](https://marketplace.visualstudio.com/items?itemName=matklad.rust-analyzer) extension.

## Solutions

You can find the solutions to the exercises in
the [`solutions` branch](https://github.com/mainmatter/100-exercises-to-learn-rust/tree/solutions) of this repository.

# License

Copyright © 2024- Mainmatter GmbH (https://mainmatter.com), released under the
[Creative Commons Attribution-NonCommercial 4.0 International license](https://creativecommons.org/licenses/by-nc/4.0/).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[greenbone/openvas-scanner]]></title>
            <link>https://github.com/greenbone/openvas-scanner</link>
            <guid>https://github.com/greenbone/openvas-scanner</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[This repository contains the scanner component for Greenbone Community Edition.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/greenbone/openvas-scanner">greenbone/openvas-scanner</a></h1>
            <p>This repository contains the scanner component for Greenbone Community Edition.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,891</p>
            <p>Forks: 680</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>![Greenbone Logo](https://www.greenbone.net/wp-content/uploads/gb_new-logo_horizontal_rgb_small.png)

# OpenVAS Scanner

[![GitHub releases](https://img.shields.io/github/release/greenbone/openvas-scanner.svg)](https://github.com/greenbone/openvas-scanner/releases)
[![Docker Pulls](https://img.shields.io/docker/pulls/greenbone/openvas-scanner.svg)](https://hub.docker.com/r/greenbone/openvas-scanner/)
[![Docker Image Size](https://img.shields.io/docker/image-size/greenbone/openvas-scanner.svg?maxAge=2592000)](https://hub.docker.com/r/greenbone/openvas-scanner/)
[![CI](https://github.com/greenbone/openvas-scanner/actions/workflows/control.yml/badge.svg?branch=main)](https://github.com/greenbone/openvas-scanner/actions/workflows/control.yml?query=branch%3Amain)

This is the OpenVAS Scanner of the Greenbone Community Edition.

It is used for the Greenbone Enterprise appliances and is a full-featured
scan engine that executes a continuously updated and extended feed of
Vulnerability Tests (VTs).

## Releases

All [release files](https://github.com/greenbone/openvas/releases) are signed with
the [Greenbone Community Feed integrity key](https://community.greenbone.net/t/gcf-managing-the-digital-signatures/101).
This gpg key can be downloaded at https://www.greenbone.net/GBCommunitySigningKey.asc
and the fingerprint is `8AE4 BE42 9B60 A59B 311C  2E73 9823 FAA6 0ED1 E580`.

## Installation

This module can be configured, built and installed with following commands:

    cmake .
    make install

For detailed installation requirements and instructions, please see the file
[INSTALL.md](INSTALL.md). The file also contains instructions for setting up
`openvas` and for making the scanner available to other GVM modules.

If you are not familiar or comfortable building from source code, we recommend
that you use the Greenbone Enterprise TRIAL, a prepared virtual
machine with a readily available setup. Information regarding the virtual machine
is available at &lt;https://www.greenbone.net/en/testnow&gt;.

## Rust Implementation

This repository also consists of a [rust project](rust/README.md) aiming to replace the current scanner stack
(openvas-scanner, ospd-openvas, notus-scanner). It simplifies the use of the scanner and centralizes
everything needed for scanning. Currently it uses the openvas-scanner as scan engine.

## Docker, [Greenbone Community Containers](https://greenbone.github.io/docs/latest/22.4/container/)

If you want to use the docker files provided in this repository you can pull them from the [Greenbone registry](registry.community.greenbone.net/community/openvas-scanner:stable). You can also locally build them using:
```
docker build -t &lt;image-name&gt; -f .docker/prod.Dockerfile .
```
For more information about building docker images, see 
[official man](https://docs.docker.com/engine/reference/commandline/build/).
We also provide a [fully containerized 
solution](https://greenbone.github.io/docs/latest/22.4/container/)
for the Greenbone Community Edition.

&gt; Please beware: The Greenbone Community Container are currently under development.

## Support

For any question on the usage of `openvas` please use the [Greenbone
Community Portal](https://community.greenbone.net/). If you found a problem
with the software, please [create an
issue](https://github.com/greenbone/openvas-scanner/issues) on GitHub. If you
are a Greenbone customer you may alternatively or additionally forward your
issue to the Greenbone Support Portal.

## Maintainer

This project is maintained by [Greenbone AG](https://www.greenbone.net/).

## Contributing

Your contributions are highly appreciated. Please [create a pull
request](https://github.com/greenbone/openvas-scanner/pulls) on GitHub.
Remember to commit the contribution agreement as explained in [RELICENSING](https://github.com/greenbone/openvas-scanner/tree/main/RELICENSE) folder with your first PR.
Bigger changes should be discussed with the development team via the [issues section at GitHub](https://github.com/greenbone/openvas-scanner/issues) first.

## License

This repository consists of two scanner implementation, one in programming language C and one in programming language Rust.

This module except for the Rust-implementation in directory rust/ is licensed under the GNU General Public License v2.0 only. Single files, however, are licensed either under the GNU General Public License v2.0 only or under GNU General Public License v2.0 or later, please see the [license-details.md](license-details.md) file for details.

The Rust-implementation in directory rust/ is licensed under the GNU General Public License v2.0 or later with OpenSSL exception. Single files, however, are additionally licensed under MIT.

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/rustlings]]></title>
            <link>https://github.com/rust-lang/rustlings</link>
            <guid>https://github.com/rust-lang/rustlings</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[🦀 Small exercises to get you used to reading and writing Rust code!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/rustlings">rust-lang/rustlings</a></h1>
            <p>🦀 Small exercises to get you used to reading and writing Rust code!</p>
            <p>Language: Rust</p>
            <p>Stars: 58,774</p>
            <p>Forks: 10,644</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># [Rustlings](https://rustlings.rust-lang.org) 🦀

Small exercises to get you used to reading and writing [Rust](https://www.rust-lang.org) code - _Recommended in parallel to reading [the official Rust book](https://doc.rust-lang.org/book) 📚️_

Visit the **website** for a demo, info about setup and more:

## ➡️ [rustlings.rust-lang.org](https://rustlings.rust-lang.org) ⬅️
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[leptos-rs/leptos]]></title>
            <link>https://github.com/leptos-rs/leptos</link>
            <guid>https://github.com/leptos-rs/leptos</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Build fast web applications with Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/leptos-rs/leptos">leptos-rs/leptos</a></h1>
            <p>Build fast web applications with Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 18,590</p>
            <p>Forks: 769</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
    &lt;source srcset=&quot;https://raw.githubusercontent.com/leptos-rs/leptos/main/docs/logos/Leptos_logo_pref_dark_RGB.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/leptos-rs/leptos/main/docs/logos/Leptos_logo_RGB.svg&quot; alt=&quot;Leptos Logo&quot;&gt;
&lt;/picture&gt;

[![crates.io](https://img.shields.io/crates/v/leptos.svg)](https://crates.io/crates/leptos)
[![docs.rs](https://docs.rs/leptos/badge.svg)](https://docs.rs/leptos)
![Crates.io MSRV](https://img.shields.io/crates/msrv/leptos)
[![Discord](https://img.shields.io/discord/1031524867910148188?color=%237289DA&amp;label=discord)](https://discord.gg/YdRAhS7eQB)
[![Matrix](https://img.shields.io/badge/Matrix-leptos-grey?logo=matrix&amp;labelColor=white&amp;logoColor=black)](https://matrix.to/#/#leptos:matrix.org)

[Website](https://leptos.dev) | [Book](https://leptos-rs.github.io/leptos/) | [Docs.rs](https://docs.rs/leptos/latest/leptos/) | [Playground](https://codesandbox.io/p/sandbox/leptos-rtfggt?file=%2Fsrc%2Fmain.rs%3A1%2C1) | [Discord](https://discord.gg/YdRAhS7eQB)

You can find a list of useful libraries and example projects at [`awesome-leptos`](https://github.com/leptos-rs/awesome-leptos).

# Leptos

```rust
use leptos::*;

#[component]
pub fn SimpleCounter(initial_value: i32) -&gt; impl IntoView {
    // create a reactive signal with the initial value
    let (value, set_value) = signal(initial_value);

    // create event handlers for our buttons
    // note that `value` and `set_value` are `Copy`, so it&#039;s super easy to move them into closures
    let clear = move |_| set_value(0);
    let decrement = move |_| set_value.update(|value| *value -= 1);
    let increment = move |_| set_value.update(|value| *value += 1);

    // create user interfaces with the declarative `view!` macro
    view! {
        &lt;div&gt;
            &lt;button on:click=clear&gt;Clear&lt;/button&gt;
            &lt;button on:click=decrement&gt;-1&lt;/button&gt;
            // text nodes can be quoted or unquoted
            &lt;span&gt;&quot;Value: &quot; {value} &quot;!&quot;&lt;/span&gt;
            &lt;button on:click=increment&gt;+1&lt;/button&gt;
        &lt;/div&gt;
    }
}

// we also support a builder syntax rather than the JSX-like `view` macro
#[component]
pub fn SimpleCounterWithBuilder(initial_value: i32) -&gt; impl IntoView {
    use leptos::html::*;

    let (value, set_value) = signal(initial_value);
    let clear = move |_| set_value(0);
    let decrement = move |_| set_value.update(|value| *value -= 1);
    let increment = move |_| set_value.update(|value| *value += 1);

    // the `view` macro above expands to this builder syntax
    div().child((
        button().on(ev::click, clear).child(&quot;Clear&quot;),
        button().on(ev::click, decrement).child(&quot;-1&quot;),
        span().child((&quot;Value: &quot;, value, &quot;!&quot;)),
        button().on(ev::click, increment).child(&quot;+1&quot;)
    ))
}

// Easy to use with Trunk (trunkrs.dev) or with a simple wasm-bindgen setup
pub fn main() {
    mount_to_body(|| view! {
        &lt;SimpleCounter initial_value=3 /&gt;
    })
}
```

## About the Framework

Leptos is a full-stack, isomorphic Rust web framework leveraging fine-grained reactivity to build declarative user interfaces.

## What does that mean?

- **Full-stack**: Leptos can be used to build apps that run in the browser (client-side rendering), on the server (server-side rendering), or by rendering HTML on the server and then adding interactivity in the browser (server-side rendering with hydration). This includes support for HTTP streaming of both data ([`Resource`s](https://docs.rs/leptos/latest/leptos/struct.Resource.html)) and HTML (out-of-order or in-order streaming of [`&lt;Suspense/&gt;`](https://docs.rs/leptos/latest/leptos/fn.Suspense.html) components.)
- **Isomorphic**: Leptos provides primitives to write isomorphic [server functions](https://docs.rs/leptos_server/0.2.5/leptos_server/index.html), i.e., functions that can be called with the “same shape” on the client or server, but only run on the server. This means you can write your server-only logic (database requests, authentication etc.) alongside the client-side components that will consume it, and call server functions as if they were running in the browser, without needing to create and maintain a separate REST or other API.
- **Web**: Leptos is built on the Web platform and Web standards. The [router](https://docs.rs/leptos_router/latest/leptos_router/) is designed to use Web fundamentals (like links and forms) and build on top of them rather than trying to replace them.
- **Framework**: Leptos provides most of what you need to build a modern web app: a reactive system, templating library, and a router that works on both the server and client side.
- **Fine-grained reactivity**: The entire framework is built from reactive primitives. This allows for extremely performant code with minimal overhead: when a reactive signal’s value changes, it can update a single text node, toggle a single class, or remove an element from the DOM without any other code running. (So, no virtual DOM overhead!)
- **Declarative**: Tell Leptos how you want the page to look, and let the framework tell the browser how to do it.

## Learn more

Here are some resources for learning more about Leptos:

- [Book](https://leptos-rs.github.io/leptos/) (work in progress)
- [Examples](https://github.com/leptos-rs/leptos/tree/main/examples)
- [API Documentation](https://docs.rs/leptos/latest/leptos/)
- [Common Bugs](https://github.com/leptos-rs/leptos/tree/main/docs/COMMON_BUGS.md) (and how to fix them!)

## `nightly` Note

Most of the examples assume you’re using `nightly` version of Rust and the `nightly` feature of Leptos. To use `nightly` Rust, you can either set your toolchain globally or on per-project basis.

To set `nightly` as a default toolchain for all projects (and add the ability to compile Rust to WebAssembly, if you haven’t already):

```
rustup toolchain install nightly
rustup default nightly
rustup target add wasm32-unknown-unknown
```

If you&#039;d like to use `nightly` only in your Leptos project however, add [`rust-toolchain.toml`](https://rust-lang.github.io/rustup/overrides.html#the-toolchain-file) file with the following content:

```toml
[toolchain]
channel = &quot;nightly&quot;
targets = [&quot;wasm32-unknown-unknown&quot;]
```

The `nightly` feature enables the function call syntax for accessing and setting signals, as opposed to `.get()` and `.set()`. This leads to a consistent mental model in which accessing a reactive value of any kind (a signal, memo, or derived signal) is always represented as a function call. This is only possible with nightly Rust and the `nightly` feature.

## `cargo-leptos`

[`cargo-leptos`](https://github.com/leptos-rs/cargo-leptos) is a build tool that&#039;s designed to make it easy to build apps that run on both the client and the server, with seamless integration. The best way to get started with a real Leptos project right now is to use `cargo-leptos` and our starter templates for [Actix](https://github.com/leptos-rs/start) or [Axum](https://github.com/leptos-rs/start-axum).

```bash
cargo install cargo-leptos
cargo leptos new --git https://github.com/leptos-rs/start
cd [your project name]
cargo leptos watch
```

Open browser to [http://localhost:3000/](http://localhost:3000/).

## FAQs

### What’s up with the name?

_Leptos_ (λεπτός) is an ancient Greek word meaning “thin, light, refined, fine-grained.” To me, a classicist and not a dog owner, it evokes the lightweight reactive system that powers the framework. I&#039;ve since learned the same word is at the root of the medical term “leptospirosis,” a blood infection that affects humans and animals... My bad. No dogs were harmed in the creation of this framework.

### Is it production ready?

People usually mean one of three things by this question.

1. **Are the APIs stable?** i.e., will I have to rewrite my whole app from Leptos 0.1 to 0.2 to 0.3 to 0.4, or can I write it now and benefit from new features and updates as new versions come?

The APIs are basically settled. We’re adding new features, but we’re very happy with where the type system and patterns have landed. I would not expect major breaking changes to your code to adapt to future releases, in terms of architecture.

2. **Are there bugs?**

Yes, I’m sure there are. You can see from the state of our issue tracker over time that there aren’t that _many_ bugs and they’re usually resolved pretty quickly. But for sure, there may be moments where you encounter something that requires a fix at the framework level, which may not be immediately resolved.

3. **Am I a consumer or a contributor?**

This may be the big one: “production ready” implies a certain orientation to a library: that you can basically use it, without any special knowledge of its internals or ability to contribute. Everyone has this at some level in their stack: for example I (@gbj) don’t have the capacity or knowledge to contribute to something like `wasm-bindgen` at this point: I simply rely on it to work.

There are several people in the community using Leptos right now for internal apps at work, who have also become significant contributors. I think this is the right level of production use for now. There may be missing features that you need, and you may end up building them! But for internal apps, if you’re willing to build and contribute missing pieces along the way, the framework is definitely usable right now.

### Can I use this for native GUI?

Sure! Obviously the `view` macro is for generating DOM nodes but you can use the reactive system to drive any native GUI toolkit that uses the same kind of object-oriented, event-callback-based framework as the DOM pretty easily. The principles are the same:

- Use signals, derived signals, and memos to create your reactive system
- Create GUI widgets
- Use event listeners to update signals
- Create effects to update the UI

The 0.7 update originally set out to create a &quot;generic rendering&quot; approach that would allow us to reuse most of the same view logic to do all of the above. Unfortunately, this has had to be shelved for now due to difficulties encountered by the Rust compiler when building larger-scale applications with the number of generics spread throughout the codebase that this required. It&#039;s an approach I&#039;m looking forward to exploring again in the future; feel free to reach out if you&#039;re interested in this kind of work.

### How is this different from Yew?

Yew is the most-used library for Rust web UI development, but there are several differences between Yew and Leptos, in philosophy, approach, and performance.

- **VDOM vs. fine-grained:** Yew is built on the virtual DOM (VDOM) model: state changes cause components to re-render, generating a new virtual DOM tree. Yew diffs this against the previous VDOM, and applies those patches to the actual DOM. Component functions rerun whenever state changes. Leptos takes an entirely different approach. Components run once, creating (and returning) actual DOM nodes and setting up a reactive system to update those DOM nodes.
- **Performance:** This has huge performance implications: Leptos is simply much faster at both creating and updating the UI than Yew is.
- **Server integration:** Yew was created in an era in which browser-rendered single-page apps (SPAs) were the dominant paradigm. While Leptos supports client-side rendering, it also focuses on integrating with the server side of your application via server functions and multiple modes of serving HTML, including out-of-order streaming.

### How is this different from Dioxus?

Like Leptos, Dioxus is a framework for building UIs using web technologies. However, there are significant differences in approach and features.

- **VDOM vs. fine-grained:** While Dioxus has a performant virtual DOM (VDOM), it still uses coarse-grained/component-scoped reactivity: changing a stateful value reruns the component function and diffs the old UI against the new one. Leptos components use a different mental model, creating (and returning) actual DOM nodes and setting up a reactive system to update those DOM nodes.
- **Web vs. desktop priorities:** Dioxus uses Leptos server functions in its fullstack mode, but does not have the same `&lt;Suspense&gt;`-based support for things like streaming HTML rendering, or share the same focus on holistic web performance. Leptos tends to prioritize holistic web performance (streaming HTML rendering, smaller WASM binary sizes, etc.), whereas Dioxus has an unparalleled experience when building desktop apps, because your application logic runs as a native Rust binary.

### How is this different from Sycamore?

Sycamore and Leptos are both heavily influenced by SolidJS. At this point, Leptos has a larger community and ecosystem and is more actively developed. Other differences:

- **Templating DSLs:** Sycamore uses a custom templating language for its views, while Leptos uses a JSX-like template format.
- **`&#039;static` signals:** One of Leptos’s main innovations was the creation of `Copy + &#039;static` signals, which have excellent ergonomics. Sycamore is in the process of adopting the same pattern, but this is not yet released.
- **Perseus vs. server functions:** The Perseus metaframework provides an opinionated way to build Sycamore apps that include server functionality. Leptos instead provides primitives like server functions in the core of the framework.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[kata-containers/kata-containers]]></title>
            <link>https://github.com/kata-containers/kata-containers</link>
            <guid>https://github.com/kata-containers/kata-containers</guid>
            <pubDate>Sat, 14 Jun 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kata-containers/kata-containers">kata-containers/kata-containers</a></h1>
            <p>Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/</p>
            <p>Language: Rust</p>
            <p>Stars: 6,314</p>
            <p>Forks: 1,119</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/6e4619c416ff4bd19e1c087f27a43eea/www-images-prod/openstack-logo/kata/SVG/kata-1.svg&quot; width=&quot;900&quot;&gt;

[![CI | Publish Kata Containers payload](https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml/badge.svg)](https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml) [![Kata Containers Nightly CI](https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml/badge.svg)](https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml)

# Kata Containers

Welcome to Kata Containers!

This repository is the home of the Kata Containers code for the 2.0 and newer
releases.

If you want to learn about Kata Containers, visit the main
[Kata Containers website](https://katacontainers.io).

## Introduction

Kata Containers is an open source project and community working to build a
standard implementation of lightweight Virtual Machines (VMs) that feel and
perform like containers, but provide the workload isolation and security
advantages of VMs.

## License

The code is licensed under the Apache 2.0 license.
See [the license file](LICENSE) for further details.

## Platform support

Kata Containers currently runs on 64-bit systems supporting the following
technologies:

| Architecture | Virtualization technology |
|-|-|
| `x86_64`, `amd64` | [Intel](https://www.intel.com) VT-x, AMD SVM |
| `aarch64` (&quot;`arm64`&quot;)| [ARM](https://www.arm.com) Hyp |
| `ppc64le` | [IBM](https://www.ibm.com) Power |
| `s390x` | [IBM](https://www.ibm.com) Z &amp; LinuxONE SIE |

### Hardware requirements

The [Kata Containers runtime](src/runtime) provides a command to
determine if your host system is capable of running and creating a
Kata Container:

```bash
$ kata-runtime check
```

&gt; **Notes:**
&gt;
&gt; - This command runs a number of checks including connecting to the
&gt;   network to determine if a newer release of Kata Containers is
&gt;   available on GitHub. If you do not wish this to check to run, add
&gt;   the `--no-network-checks` option.
&gt;
&gt; - By default, only a brief success / failure message is printed.
&gt;   If more details are needed, the `--verbose` flag can be used to display the
&gt;   list of all the checks performed.
&gt;
&gt; - If the command is run as the `root` user additional checks are
&gt;   run (including checking if another incompatible hypervisor is running).
&gt;   When running as `root`, network checks are automatically disabled.

## Getting started

See the [installation documentation](docs/install).

## Documentation

See the [official documentation](docs) including:

- [Installation guides](docs/install)
- [Developer guide](docs/Developer-Guide.md)
- [Design documents](docs/design)
  - [Architecture overview](docs/design/architecture)
  - [Architecture 3.0 overview](docs/design/architecture_3.0/)

## Configuration

Kata Containers uses a single
[configuration file](src/runtime/README.md#configuration)
which contains a number of sections for various parts of the Kata
Containers system including the [runtime](src/runtime), the
[agent](src/agent) and the [hypervisor](#hypervisors).

## Hypervisors

See the [hypervisors document](docs/hypervisors.md) and the
[Hypervisor specific configuration details](src/runtime/README.md#hypervisor-specific-configuration).

## Community

To learn more about the project, its community and governance, see the
[community repository](https://github.com/kata-containers/community). This is
the first place to go if you wish to contribute to the project.

## Getting help

See the [community](#community) section for ways to contact us.

### Raising issues

Please raise an issue
[in this repository](https://github.com/kata-containers/kata-containers/issues).

&gt; **Note:**
&gt; If you are reporting a security issue, please follow the [vulnerability reporting process](https://github.com/kata-containers/community#vulnerability-handling)

## Developers

See the [developer guide](docs/Developer-Guide.md).

### Components

### Main components

The table below lists the core parts of the project:

| Component | Type | Description |
|-|-|-|
| [runtime](src/runtime) | core | Main component run by a container manager and providing a containerd shimv2 runtime implementation. |
| [runtime-rs](src/runtime-rs) | core | The Rust version runtime. |
| [agent](src/agent) | core | Management process running inside the virtual machine / POD that sets up the container environment. |
| [`dragonball`](src/dragonball) | core | An optional built-in VMM brings out-of-the-box Kata Containers experience with optimizations on container workloads |
| [documentation](docs) | documentation | Documentation common to all components (such as design and install documentation). |
| [tests](tests) | tests | Excludes unit tests which live with the main code. |

### Additional components

The table below lists the remaining parts of the project:

| Component | Type | Description |
|-|-|-|
| [packaging](tools/packaging) | infrastructure | Scripts and metadata for producing packaged binaries&lt;br/&gt;(components, hypervisors, kernel and rootfs). |
| [kernel](https://www.kernel.org) | kernel | Linux kernel used by the hypervisor to boot the guest image. Patches are stored [here](tools/packaging/kernel). |
| [osbuilder](tools/osbuilder) | infrastructure | Tool to create &quot;mini O/S&quot; rootfs and initrd images and kernel for the hypervisor. |
| [kata-debug](tools/packaging/kata-debug/README.md) | infrastructure | Utility tool to gather Kata Containers debug information from Kubernetes clusters. |
| [`agent-ctl`](src/tools/agent-ctl) | utility | Tool that provides low-level access for testing the agent. |
| [`kata-ctl`](src/tools/kata-ctl) | utility | Tool that provides advanced commands and debug facilities. |
| [`trace-forwarder`](src/tools/trace-forwarder) | utility | Agent tracing helper. |
| [`runk`](src/tools/runk) | utility | Standard OCI container runtime based on the agent. |
| [`ci`](.github/workflows) | CI | Continuous Integration configuration files and scripts. |
| [`ocp-ci`](ci/openshift-ci/README.md) | CI | Continuous Integration configuration for the OpenShift pipelines. |
| [`katacontainers.io`](https://github.com/kata-containers/www.katacontainers.io) | Source for the [`katacontainers.io`](https://www.katacontainers.io) site. |
| [`Webhook`](tools/testing/kata-webhook/README.md) | utility | Example of a simple admission controller webhook to annotate pods with the Kata runtime class |

### Packaging and releases

Kata Containers is now
[available natively for most distributions](docs/install/README.md#packaged-installation-methods).

## General tests

See the [tests documentation](tests/README.md).

## Metrics tests

See the [metrics documentation](tests/metrics/README.md).

## Glossary of Terms

See the [glossary of terms](https://github.com/kata-containers/kata-containers/wiki/Glossary) related to Kata Containers.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>