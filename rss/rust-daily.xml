<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Thu, 25 Dec 2025 00:05:45 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[EFForg/rayhunter]]></title>
            <link>https://github.com/EFForg/rayhunter</link>
            <guid>https://github.com/EFForg/rayhunter</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:45 GMT</pubDate>
            <description><![CDATA[Rust tool to detect cell site simulators on an orbic mobile hotspot]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EFForg/rayhunter">EFForg/rayhunter</a></h1>
            <p>Rust tool to detect cell site simulators on an orbic mobile hotspot</p>
            <p>Language: Rust</p>
            <p>Stars: 3,806</p>
            <p>Forks: 279</p>
            <p>Stars today: 64 stars today</p>
            <h2>README</h2><pre># Rayhunter
![Tests](https://github.com/EFForg/rayhunter/actions/workflows/main.yml/badge.svg)

![Rayhunter Logo - An Orca taking a bite out of a cellular signal bar](https://www.eff.org/files/styles/media_browser_preview/public/banner_library/rayhunter-banner.png)

Rayhunter is a project for detecting IMSI catchers, also known as cell-site simulators or stingrays. It was first designed to run on a cheap mobile hotspot called the Orbic RC400L, but thanks to community efforts, it can [support some other devices as well](https://efforg.github.io/rayhunter/supported-devices.html).
It&#039;s also designed to be as easy to install and use as possible, regardless of your level of technical skills, and to minimize false positives. 

&amp;rarr;  Check out the [installation guide](https://efforg.github.io/rayhunter/installation.html) to get started.

&amp;rarr; To learn more about the aim of the project, and about IMSI catchers in general, please check out our [introductory blog post](https://www.eff.org/deeplinks/2025/03/meet-rayhunter-new-open-source-tool-eff-detect-cellular-spying). 

&amp;rarr; For discussion, help, or to join the mattermost channel and get involved with the project and community check out the [many ways listed here](https://efforg.github.io/rayhunter/support-feedback-community.html)!

&amp;rarr; To learn more about the project in general check out the [Rayhunter Book](https://efforg.github.io/rayhunter/).

**LEGAL DISCLAIMER:** Use this program at your own risk. We believe running this program does not currently violate any laws or regulations in the United States. However, we are not responsible for civil or criminal liability resulting from the use of this software. If you are located outside of the US please consult with an attorney in your country to help you assess the legal risks of running this program.

*Good Hunting!*
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BloopAI/vibe-kanban]]></title>
            <link>https://github.com/BloopAI/vibe-kanban</link>
            <guid>https://github.com/BloopAI/vibe-kanban</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:44 GMT</pubDate>
            <description><![CDATA[Kanban board to manage your AI coding agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BloopAI/vibe-kanban">BloopAI/vibe-kanban</a></h1>
            <p>Kanban board to manage your AI coding agents</p>
            <p>Language: Rust</p>
            <p>Stars: 6,733</p>
            <p>Forks: 687</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vibekanban.com&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;frontend/public/vibe-kanban-logo-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;frontend/public/vibe-kanban-logo.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;frontend/public/vibe-kanban-logo.svg&quot; alt=&quot;Vibe Kanban Logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Get 10X more out of Claude Code, Gemini CLI, Codex, Amp and other coding agents...&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/vibe-kanban&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/vibe-kanban?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/BloopAI/vibe-kanban/blob/main/.github/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/BloopAI/vibe-kanban/.github%2Fworkflows%2Fpublish.yml&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/BloopAI/vibe-kanban&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://jobs.polymer.co/vibe-kanban?source=github&quot;&gt;&lt;strong&gt;We&#039;re hiring!&lt;/strong&gt;&lt;/a&gt;
&lt;/h1&gt;

![](frontend/public/vibe-kanban-screenshot-overview.png)

## Overview

AI coding agents are increasingly writing the world&#039;s code and human engineers now spend the majority of their time planning, reviewing, and orchestrating tasks. Vibe Kanban streamlines this process, enabling you to:

- Easily switch between different coding agents
- Orchestrate the execution of multiple coding agents in parallel or in sequence
- Quickly review work and start dev servers
- Track the status of tasks that your coding agents are working on
- Centralise configuration of coding agent MCP configs
- Open projects remotely via SSH when running Vibe Kanban on a remote server

You can watch a video overview [here](https://youtu.be/TFT3KnZOOAk).

## Installation

Make sure you have authenticated with your favourite coding agent. A full list of supported coding agents can be found in the [docs](https://vibekanban.com/docs). Then in your terminal run:

```bash
npx vibe-kanban
```

## Documentation

Please head to the [website](https://vibekanban.com/docs) for the latest documentation and user guides.

## Support

We use [GitHub Discussions](https://github.com/BloopAI/vibe-kanban/discussions) for feature requests. Please open a discussion to create a feature request. For bugs please open an issue on this repo.

## Contributing

We would prefer that ideas and changes are first raised with the core team via [GitHub Discussions](https://github.com/BloopAI/vibe-kanban/discussions) or [Discord](https://discord.gg/AC4nwVtJM3), where we can discuss implementation details and alignment with the existing roadmap. Please do not open PRs without first discussing your proposal with the team.

## Development

### Prerequisites

- [Rust](https://rustup.rs/) (latest stable)
- [Node.js](https://nodejs.org/) (&gt;=18)
- [pnpm](https://pnpm.io/) (&gt;=8)

Additional development tools:
```bash
cargo install cargo-watch
cargo install sqlx-cli
```

Install dependencies:
```bash
pnpm i
```

### Running the dev server

```bash
pnpm run dev
```

This will start the backend. A blank DB will be copied from the `dev_assets_seed` folder.

### Building the frontend

To build just the frontend:

```bash
cd frontend
pnpm build
```

### Build from source

1. Run `build-npm-package.sh`
2. In the `npx-cli` folder run `npm pack`
3. You can run your build with `npx [GENERATED FILE].tgz`


### Environment Variables

The following environment variables can be configured at build time or runtime:

| Variable | Type | Default | Description |
|----------|------|---------|-------------|
| `POSTHOG_API_KEY` | Build-time | Empty | PostHog analytics API key (disables analytics if empty) |
| `POSTHOG_API_ENDPOINT` | Build-time | Empty | PostHog analytics endpoint (disables analytics if empty) |
| `PORT` | Runtime | Auto-assign | **Production**: Server port. **Dev**: Frontend port (backend uses PORT+1) |
| `BACKEND_PORT` | Runtime | `0` (auto-assign) | Backend server port (dev mode only, overrides PORT+1) |
| `FRONTEND_PORT` | Runtime | `3000` | Frontend dev server port (dev mode only, overrides PORT) |
| `HOST` | Runtime | `127.0.0.1` | Backend server host |
| `DISABLE_WORKTREE_ORPHAN_CLEANUP` | Runtime | Not set | Disable git worktree cleanup (for debugging) |

**Build-time variables** must be set when running `pnpm run build`. **Runtime variables** are read when the application starts.

### Remote Deployment

When running Vibe Kanban on a remote server (e.g., via systemctl, Docker, or cloud hosting), you can configure your editor to open projects via SSH:

1. **Access via tunnel**: Use Cloudflare Tunnel, ngrok, or similar to expose the web UI
2. **Configure remote SSH** in Settings ‚Üí Editor Integration:
   - Set **Remote SSH Host** to your server hostname or IP
   - Set **Remote SSH User** to your SSH username (optional)
3. **Prerequisites**:
   - SSH access from your local machine to the remote server
   - SSH keys configured (passwordless authentication)
   - VSCode Remote-SSH extension

When configured, the &quot;Open in VSCode&quot; buttons will generate URLs like `vscode://vscode-remote/ssh-remote+user@host/path` that open your local editor and connect to the remote server.

See the [documentation](https://vibekanban.com/docs/configuration-customisation/global-settings#remote-ssh-configuration) for detailed setup instructions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[qdrant/qdrant]]></title>
            <link>https://github.com/qdrant/qdrant</link>
            <guid>https://github.com/qdrant/qdrant</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:43 GMT</pubDate>
            <description><![CDATA[Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qdrant/qdrant">qdrant/qdrant</a></h1>
            <p>Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/</p>
            <p>Language: Rust</p>
            <p>Stars: 27,818</p>
            <p>Forks: 1,951</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre>## How to interview using this template

Open ONLY the `shared/` folder within VSCode and in the Extensions Marketplace find `CodeTogether Live`. Install it.

Inside the extension, you&#039;ll have to click on &#039;Host New Session&#039; and then &#039;Start&#039;.

You now have a link in your clipboard, which you should share with the candidate.

Don&#039;t forget to run `npm run vite.dev` inside your editor terminal, since this is not currently possible from the browser editor (link) with the free version of the extension.

The locally running server will display localhost:5173 as well as a the project within the network, which the user can access remotely to see the SPA in action, something like: `10.5.52.144:5173`.

The candidate should be sharing their screen while they read and later approach the challenge!

## React TemplateÔºà‚ö°Ô∏èÔºâ

‚ö°Ô∏è A minimal React Vite starter template.

### Feature

- ‚ö°Ô∏è Fast - Build tools based on vite.
- üëª Small - Based on the smallest runnable build.
- üíÑ Prettier - Integrated Prettier to help you format the code.
- ‚úÖ Safety - Https is enabled by default.
- üòé Reliable - Integrated eslint and commitlint.
- ü§ñ Intelligent - Integrated renovate to help you maintain the dependent version.

### Preview

[![qekup8.png](https://s1.ax1x.com/2022/03/20/qekup8.png)](https://imgtu.com/i/qekup8)

### Getting Started

```bash
npx degit lzm0x219/template-vite-react myapp

cd myapp

git init
```

#### Prerequisites

- `npm` and/or `pnpm` should be installed.
- `git` should be installed (recommended v2.4.11 or higher)

#### Available scripts

##### `npm run vite.dev`

Runs the app in development mode.
Open https://localhost:5173 to view it in the browser.

The page will automatically reload if you make changes to the code.
You will see the build errors and lint warnings in the console.

##### `npm run vite.build`

Builds the app for production to the `dist` folder.
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.

Your app is ready to be deployed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[aome510/spotify-player]]></title>
            <link>https://github.com/aome510/spotify-player</link>
            <guid>https://github.com/aome510/spotify-player</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:42 GMT</pubDate>
            <description><![CDATA[A Spotify player in the terminal with full feature parity]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aome510/spotify-player">aome510/spotify-player</a></h1>
            <p>A Spotify player in the terminal with full feature parity</p>
            <p>Language: Rust</p>
            <p>Stars: 5,996</p>
            <p>Forks: 301</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># spotify_player

## Table of Contents

- [Introduction](#introduction)
- [Examples](#examples)
- [Installation](#installation)
- [Features](#features)
  - [Spotify Connect](#spotify-connect)
  - [Streaming](#streaming)
  - [Media Control](#media-control)
  - [Image](#image)
  - [Notify](#notify)
  - [Mouse support](#mouse-support)
  - [Daemon](#daemon)
  - [Fuzzy search](#fuzzy-search)
  - [CLI commands](#cli-commands)
- [Commands](#commands)
- [Configurations](#configurations)
- [Caches](#caches)
  - [Logging](#logging)
- [Acknowledgement](#acknowledgement)

## Introduction

`spotify_player` is a fast, easy to use, and configurable terminal music player.

**Features**

- Minimalist UI with an intuitive paging and popup system.
- Highly [configurable](docs/config.md)
- Feature parity with the official Spotify application.
- Support remote control with [Spotify Connect](#spotify-connect).
- Support [streaming](#streaming) songs directly from the terminal.
- Support synced lyrics.
- Support [cross-platform media control](#media-control).
- Support [image rendering](#image).
- Support [desktop notification](#notify).
- Support running the application as [a daemon](#daemon)
- Offer a wide range of [CLI commands](#cli-commands)

## Examples

A demo of `spotify_player` `v0.5.0-pre-release` on [youtube](https://www.youtube.com/watch/Jbfe9GLNWbA) or on [asciicast](https://asciinema.org/a/446913):

Checkout [examples/README.md](./examples/README.md) for more examples.

## Installation

By default, the application&#039;s installed binary is `spotify_player`.

### Requirements

A Spotify Premium account is **required**.

#### Dependencies

##### Windows and MacOS

- [Rust and cargo](https://www.rust-lang.org/tools/install) as the build dependencies

##### Linux

- [Rust and cargo](https://www.rust-lang.org/tools/install) as the build dependencies
- install `openssl`, `alsa-lib` (`streaming` feature), `libdbus` (`media-control` feature).

  - For example, on Debian based systems, run the below command to install application&#039;s dependencies:

    ```shell
    sudo apt install libssl-dev libasound2-dev libdbus-1-dev
    ```

  - On RHEL/Fedora based systems, run the below command to install application&#039;s dependencies :

    ```shell
    sudo dnf install openssl-devel alsa-lib-devel dbus-devel
    ```

    or if you&#039;re using `yum`:

    ```shell
    sudo yum install openssl-devel alsa-lib-devel dbus-devel
    ```

### Binaries

Application&#039;s prebuilt binaries can be found in the [Releases Page](https://github.com/aome510/spotify-player/releases).

**Note**: to run the application, Linux systems need to install additional dependencies as specified in the [Dependencies section](#linux).

### Homebrew

Run `brew install spotify_player` to install the application.

### Scoop

Run `scoop install spotify-player` to install the application.

### Cargo

Run `cargo install spotify_player --locked` to install the application from [crates.io](https://crates.io/crates/spotify_player).

### Arch Linux

Run `pacman -S spotify-player` to install the application.

**Note**: Defaults to PulseAudio / Pipewire audio backend. For a different one, please consider modifying the [official PKGBUILD](https://gitlab.archlinux.org/archlinux/packaging/packages/spotify-player) and rebuilding it manually. See [Audio Backends](#audio-backend) for a list of options.

### Void Linux

Run `xbps-install -S spotify-player` to install the application.

### FreeBSD

Run `pkg install spotify-player` to install the `spotify_player` binary from FreeBSD ports.

### NetBSD

Using the package manager, run `pkgin install spotify-player` to install from the official repositories.

Building from source,

```
cd /usr/pkgsrc/audio/spotify-player
make install
```

### NixOS

[spotify-player](https://search.nixos.org/packages?channel=unstable&amp;show=spotify-player&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=spotify-player) is available as a Nix package and can be installed via `nix-shell -p spotify-player` or as part of your system configuration.

If you want to build the source locally you can run `nix-shell` in the root of a checkout of the source code. The provided `shell.nix` file will install the build prerequisites.

### Docker

**Note**: [streaming](#streaming) feature is disabled when using the docker image.

You can download the binary image of the latest build from the `master` branch by running

```
docker pull aome510/spotify_player:latest
```

then run

```
docker run --rm -it aome510/spotify_player:latest
```

to run the application.

You can also use your local config folder to configure the application or your local cache folder to store the application&#039;s cache data when running the docker image:

```
docker run --rm \
-v $APP_CONFIG_FOLDER:/app/config/ \
-v $APP_CACHE_FOLDER:/app/cache/ \
-it aome510/spotify_player:latest
```

## Features

### Spotify Connect

To enable a full [Spotify connect](https://www.spotify.com/us/connect/) support, users will need to enable a _&quot;user-provided client integration&quot;_.

This integration can be done by following [this documentation](https://developer.spotify.com/documentation/general/guides/authorization/app-settings/) to register a Spotify app and then specifying the app&#039;s `client_id` in the [general configuration file](docs/config.md#general). **NOTE**: please make sure that you specify `http://127.0.0.1:8989/login` (default value of `login_redirect_uri` config option) in the **Redirect URI** section when creating the app.

Upon running `spotify_player` with a user-provided `client_id`, user will be prompted to authenticate the app described earlier. **NOTE** that this prompt is different from the prompt to authenticate `spotify_player`. Upon accepting the authentication request, `spotify_player` will retrieve an access token of the app to finish setting up the integration.

After the user-provided client is successfully integrated, press **D** (default shortcut for `SwitchDevice` command) to get the list of available devices, then press **enter** (default shortcut for `ChooseSelected` command) to connect to the selected device.

### Streaming

`spotify_player` supports streaming, which needs to be built/installed with `streaming` feature (**enabled** by default) **and** with an audio backend (`rodio-backend` by default). The streaming feature allows to `spotify_player` to play music directly from terminal.

The application uses [librespot](https://github.com/librespot-org/librespot) library to create an integrated Spotify client while running. The integrated client will register a Spotify speaker device under the `spotify-player` name, which is accessible on the [Spotify connect](#spotify-connect) device list.

#### Audio backend

`spotify_player` uses [rodio](https://github.com/RustAudio/rodio) as the default [audio backend](https://github.com/librespot-org/librespot/wiki/Audio-Backends). List of available audio backends:

- `alsa-backend`
- `pulseaudio-backend`
- `rodio-backend`
- `portaudio-backend`
- `jackaudio-backend`
- `rodiojack-backend`
- `sdl-backend`
- `gstreamer-backend`

User can change the audio backend when building/installing the application by specifying the `--features` option. For example, to install `spotify_player` with `pulseaudio-backend`, run

```shell
cargo install spotify_player --no-default-features --features pulseaudio-backend
```

**Note**:

- needs to specify `--no-default-features` here because `rodio-backend` is one of the default features.
- user will need to install additional dependencies depending on the selected audio backend. More details can be found in the [Librespot documentation](https://github.com/librespot-org/librespot/wiki/Compiling#general-dependencies).

The `streaming` feature can be also disabled upon installing by running

```shell
cargo install spotify_player --no-default-features
```

### Media Control

To enable media control support, `spotify_player` needs to be built/installed with `media-control` feature (**enabled** by default) and set the `enable_media_control` config option to `true` in the [general configuration file](docs/config.md#media-control).

Media control support is implemented using [MPRIS DBus](https://wiki.archlinux.org/title/MPRIS) on Linux and OS window event listener on Windows and MacOS.

### Image

To enable image rendering support, `spotify_player` needs to be built/installed with `image` feature (**disabled** by default). To install the application with `image` feature included, run:

```shell
cargo install spotify_player --features image
```

`spotify_player` supports rendering image in a full resolution if the application is run on either [Kitty](https://sw.kovidgoyal.net/kitty/graphics-protocol/) or [iTerm2](https://iterm2.com/documentation-images.html). Otherwise, the image will be displayed as [block characters](https://en.wikipedia.org/wiki/Block_Elements).

`spotify_player` also supports rendering images with `sixel` behind `sixel` feature flag, which also enables `image` feature:

```shell
cargo install spotify_player --features sixel
```

**Notes**:

- Not all terminals supported by [libsixel](https://github.com/saitoha/libsixel) are supported by `spotify_player` as it relies on a [third-party library](https://github.com/atanunq/viuer) for image rendering. A possible list of supported terminals can be found in [here](https://github.com/atanunq/viuer/blob/dc81f44a97727e04be0b000712e9233c92116ff8/src/printer/sixel.rs#L83-L95).
- Images rendered by `sixel` can have a _weird_ scale. It&#039;s recommended to tweak the `cover_img_scale` config option to get the best result as the scaling works differently with different terminals and fonts.

Examples of image rendering:

- iTerm2:

![iTerm2](https://user-images.githubusercontent.com/40011582/172966798-0aadc431-b0c3-4433-adf3-7526684fc2a0.png)

- Kitty:

![kitty](https://user-images.githubusercontent.com/40011582/172967028-8cfb2daa-1642-499a-a5bf-8ed77f2b3fac.png)

- Sixel (`foot` terminal, `cover_img_scale=1.8`):

![sixel](https://user-images.githubusercontent.com/40011582/219880331-58ac1c30-bbb0-4c99-a6cc-e5b7c9c81455.png)

- Others:

![others](https://user-images.githubusercontent.com/40011582/172967325-d2098037-e19e-440a-a38a-5b076253ecb1.png)

#### Pixelate

If your terminal supports high-res images, but you like the pixelated look you can enable the `pixelate` feature, which also enables the `image` feature:

```shell
cargo install spotify_player --features pixelate
```

The amount of pixels can be tweaked via the `cover_img_pixels` config option.

| `cover_img_pixels` | `8`                                                                                                                 | `16`                                                                                                                  | `32`                                                                                                                  | `64`                                                                                                                  |
| ------------------ | ------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| example            | &lt;img width=&quot;100&quot; alt=&quot;8x8&quot; src=&quot;https://github.com/user-attachments/assets/4137aaea-ce28-4019-8cd5-2d14327e72e4&quot; /&gt; | &lt;img width=&quot;100&quot; alt=&quot;16x16&quot; src=&quot;https://github.com/user-attachments/assets/0ca94748-093a-468c-8fb3-1f5639666eb6&quot; /&gt; | &lt;img width=&quot;100&quot; alt=&quot;32x32&quot; src=&quot;https://github.com/user-attachments/assets/f5d0f2da-0439-47e4-91c9-3a2aa73ac90c&quot; /&gt; | &lt;img width=&quot;100&quot; alt=&quot;64x64&quot; src=&quot;https://github.com/user-attachments/assets/d06ef731-38fa-424d-9672-313f56c193d0&quot; /&gt; |

To temporarily disable the `pixelate` feature just set `cover_img_pixels` to a high value like `512`.

### Notify

To enable desktop notification support, `spotify_player` needs to be built/installed with `notify` feature (**disabled** by default). To install the application with `notify` feature included, run:

```shell
cargo install spotify_player --features notify
```

**Note**: the notification support in `MacOS` and `Windows` are quite restricted compared to `Linux`.

### Mouse support

Currently, the only supported use case for mouse is to seek to a position of the current playback by left-clicking to such position in the playback&#039;s progress bar.

### Daemon

To enable a [daemon](&lt;https://en.wikipedia.org/wiki/Daemon_(computing)&gt;) support, `spotify_player` needs to be built/installed with `daemon` feature (**disabled** by default). To install the application with `daemon` feature included, run:

```shell
cargo install spotify_player --features daemon
```

You can run the application as a daemon by specifying the `-d` or `--daemon` option: `spotify_player -d`.

**Notes**:

- `daemon` feature is not supported on Windows
- `daemon` feature requires the `streaming` feature to be enabled and the application to be built with [an audio backend](#audio-backend)
- because of the OS&#039;s restrictions, `daemon` feature doesn&#039;t work with the `media-control` feature on MacOS, which is **enabled by default**. In other words, if you want to use the `daemon` feature on MacOS, you must install the application with `media-control` feature **disabled**:

  ```shell
  cargo install spotify_player --no-default-features --features daemon,rodio-backend
  ```

### Fuzzy search

To enable [fuzzy search](https://en.wikipedia.org/wiki/Approximate_string_matching) support, `spotify_player` needs to be built/installed with `fzf` feature (**disabled** by default).

### CLI Commands

`spotify_player` offers several CLI commands to interact with Spotify:

- `get`: Get Spotify data (playlist/album/artist data, user&#039;s data, etc)
- `playback`: Interact with the playback (start a playback, play-pause, next, etc)
- `search`: Search spotify
- `connect`: Connect to a Spotify device
- `like`: Like currently playing track
- `authenticate`: Authenticate the application
- `playlist`: Playlist editing (new, delete, import, fork, etc)

For more details, run `spotify_player -h` or `spotify_player {command} -h`, in which `{command}` is a CLI command.

**Notes**

- When using the CLI for the first time, you&#039;ll need to run `spotify_player authenticate` to authenticate the application beforehand.
- Under the hood, CLI command is handled by sending requests to a `spotify_player` client socket running on port `client_port`, [a general application configuration](https://github.com/aome510/spotify-player/blob/master/docs/config.md#general) with a default value of `8080`. If there is no running application&#039;s instance, a new client will be created upon handling the CLI commands, which increases the latency of the command.

#### Scripting

The `spotify_player` command-line interface makes scripting easy.
With the `search` subcommand, you can search Spotify and retrieve data in JSON format, enabling queries with tools like [jq](https://jqlang.github.io/jq/).

Here‚Äôs an example of starting playback for the first track from a search query:

```sh
read -p &quot;Search spotify: &quot; query
spotify_player playback start track --id $(spotify_player search &quot;$query&quot; | jq &#039;.tracks.[0].id&#039; | xargs)
```

## Commands

To go to the shortcut help page, press `?` or `C-h` (default shortcuts for `OpenCommandHelp` command).

**Tips**:

- you can search in the shortcut help page (and some other pages) using `Search` command
- `RefreshPlayback` can be used to manually update the playback status.
- `RestartIntegratedClient` is useful when user wants to switch to another audio device (headphone, earphone, etc) without restarting the application, as the integrated client will be re-initialized with the new device.

List of supported commands:

| Command                         | Description                                                                                        | Default shortcuts  |
| ------------------------------- | -------------------------------------------------------------------------------------------------- | ------------------ |
| `NextTrack`                     | next track                                                                                         | `n`                |
| `PreviousTrack`                 | previous track                                                                                     | `p`                |
| `ResumePause`                   | resume/pause based on the current playback                                                         | `space`            |
| `PlayRandom`                    | play a random track in the current context                                                         | `.`                |
| `Repeat`                        | cycle the repeat mode                                                                              | `C-r`              |
| `ToggleFakeTrackRepeatMode`     | toggle fake track repeat mode                                                                      | `M-r`              |
| `Shuffle`                       | toggle the shuffle mode                                                                            | `C-s`              |
| `VolumeChange`                  | change playback volume by an offset (default shortcuts use 5%)                                     | `+`, `-`           |
| `Mute`                          | toggle playback volume between 0% and previous level                                               | `_`                |
| `SeekForward`                   | seek forward by a duration in seconds (defaults to `seek_duration_secs`)                           | `&gt;`                |
| `SeekBackward`                  | seek backward by a duration in seconds (defaults to `seek_duration_secs`)                          | `&lt;`                |
| `Quit`                          | quit the application                                                                               | `C-c`, `q`         |
| `ClosePopup`                    | close a popup                                                                                      | `esc`              |
| `SelectNextOrScrollDown`        | select the next item in a list/table or scroll down (supports vim-style count: 5j)                 | `j`, `C-n`, `down` |
| `SelectPreviousOrScrollUp`      | select the previous item in a list/table or scroll up (supports vim-style count: 10k)              | `k`, `C-p`, `up`   |
| `PageSelectNextOrScrollDown`    | select the next page item in a list/table or scroll a page down (supports vim-style count: 3C-f)   | `page_down`, `C-f` |
| `PageSelectPreviousOrScrollUp`  | select the previous page item in a list/table or scroll a page up (supports vim-style count: 2C-b) | `page_up`, `C-b`   |
| `SelectFirstOrScrollToTop`      | select the first item in a list/table or scroll to the top                                         | `g g`, `home`      |
| `SelectLastOrScrollToBottom`    | select the last item in a list/table or scroll to the bottom                                       | `G`, `end`         |
| `ChooseSelected`                | choose the selected item                                                                           | `enter`            |
| `RefreshPlayback`               | manually refresh the current playback                                                              | `r`                |
| `RestartIntegratedClient`       | restart the integrated client (`streaming` feature only)                                           | `R`                |
| `ShowActionsOnSelectedItem`     | open a popup showing actions on a selected item                

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/miri]]></title>
            <link>https://github.com/rust-lang/miri</link>
            <guid>https://github.com/rust-lang/miri</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:41 GMT</pubDate>
            <description><![CDATA[An interpreter for Rust's mid-level intermediate representation]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/miri">rust-lang/miri</a></h1>
            <p>An interpreter for Rust's mid-level intermediate representation</p>
            <p>Language: Rust</p>
            <p>Stars: 5,737</p>
            <p>Forks: 423</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># Miri

Miri is an [Undefined Behavior][reference-ub] detection tool for Rust. It can run binaries and test
suites of cargo projects and detect unsafe code that fails to uphold its safety requirements. For
instance:

* Out-of-bounds memory accesses and use-after-free
* Invalid use of uninitialized data
* Violation of intrinsic preconditions (an [`unreachable_unchecked`] being
  reached, calling [`copy_nonoverlapping`] with overlapping ranges, ...)
* Not sufficiently aligned memory accesses and references
* Violation of basic type invariants (a `bool` that is not 0 or 1, for example,
  or an invalid enum discriminant)
* Data races and emulation of *some* weak memory effects, i.e.,
  atomic reads can return outdated values
* **Experimental**: Violations of the [Stacked Borrows] rules governing aliasing
  for reference types
* **Experimental**: Violations of the [Tree Borrows] aliasing rules, as an optional
  alternative to [Stacked Borrows]

On top of that, Miri will also tell you about memory leaks: when there is memory
still allocated at the end of the execution, and that memory is not reachable
from a global `static`, Miri will raise an error.

You can use Miri to emulate programs on other targets, e.g. to ensure that
byte-level data manipulation works correctly both on little-endian and
big-endian systems. See
[cross-interpretation](#cross-interpretation-running-for-different-targets)
below.

Miri has already discovered many [real-world bugs](#bugs-found-by-miri). If you
found a bug with Miri, we&#039;d appreciate if you tell us and we&#039;ll add it to the
list!

By default, Miri ensures a fully deterministic execution and isolates the
program from the host system. Some APIs that would usually access the host, such
as gathering entropy for random number generators, environment variables, and
clocks, are replaced by deterministic &quot;fake&quot; implementations. Set
`MIRIFLAGS=&quot;-Zmiri-disable-isolation&quot;` to access the real system APIs instead.
(In particular, the &quot;fake&quot; system RNG APIs make Miri **not suited for
cryptographic use**! Do not generate keys using Miri.)

All that said, be aware that Miri does **not catch every violation of the Rust specification** in
your program, not least because there is no such specification. Miri uses its own approximation of
what is and is not Undefined Behavior in Rust. To the best of our knowledge, all Undefined Behavior
that has the potential to affect a program&#039;s correctness *is* being detected by Miri (modulo
[bugs][I-misses-ub]), but you should consult [the Reference][reference-ub] for the official
definition of Undefined Behavior. Miri will be updated with the Rust compiler to protect against UB
as it is understood by the current compiler, but it makes no promises about future versions of
rustc.

Further caveats that Miri users should be aware of:

* If the program relies on unspecified details of how data is laid out, it will
  still run fine in Miri -- but might break (including causing UB) on different
  compiler versions or different platforms. (You can use `-Zrandomize-layout`
  to detect some of these cases.)
* Program execution is non-deterministic when it depends, for example, on where
  exactly in memory allocations end up, or on the exact interleaving of
  concurrent threads. Miri tests one of many possible executions of your
  program, but it will miss bugs that only occur in a different possible execution.
  You can alleviate this to some extent by running Miri with different
  values for `-Zmiri-seed`, but that will still by far not explore all possible executions.
* Miri runs the program as a platform-independent interpreter, so the program
  has no access to most platform-specific APIs or FFI. A few APIs have been
  implemented (such as printing to stdout, accessing environment variables, and
  basic file system access) but most have not: for example, Miri currently does
  not support networking. System API support varies between targets; if you run
  on Windows it is a good idea to use `--target x86_64-unknown-linux-gnu` to get
  better support.
* Weak memory emulation is not complete: there are legal behaviors that Miri will never produce.
  However, Miri produces many behaviors that are hard to observe on real hardware, so it can help
  quite a bit in finding weak memory concurrency bugs. To be really sure about complicated atomic
  code, use specialized tools such as [loom](https://github.com/tokio-rs/loom).

Moreover, Miri fundamentally cannot ensure that your code is *sound*. [Soundness] is the property of
never causing undefined behavior when invoked from arbitrary safe code, even in combination with
other sound code. In contrast, Miri can just tell you if *a particular way of interacting with your
code* (e.g., a test suite) causes any undefined behavior *in a particular execution* (of which there
may be many, e.g. when concurrency or other forms of non-determinism are involved). When Miri finds
UB, your code is definitely unsound, but when Miri does not find UB, then you may just have to test
more inputs or more possible non-deterministic choices.

[rust]: https://www.rust-lang.org/
[mir]: https://github.com/rust-lang/rfcs/blob/master/text/1211-mir.md
[`unreachable_unchecked`]: https://doc.rust-lang.org/stable/std/hint/fn.unreachable_unchecked.html
[`copy_nonoverlapping`]: https://doc.rust-lang.org/stable/std/ptr/fn.copy_nonoverlapping.html
[Stacked Borrows]: https://github.com/rust-lang/unsafe-code-guidelines/blob/master/wip/stacked-borrows.md
[Tree Borrows]: https://perso.crans.org/vanille/treebor/
[Soundness]: https://rust-lang.github.io/unsafe-code-guidelines/glossary.html#soundness-of-code--of-a-library
[reference-ub]: https://doc.rust-lang.org/reference/behavior-considered-undefined.html
[I-misses-ub]: https://github.com/rust-lang/miri/labels/I-misses-UB


## Using Miri

Install Miri on Rust nightly via `rustup`:

```sh
rustup +nightly component add miri
```

All the following commands assume the nightly toolchain is pinned via `rustup override set nightly`.
Alternatively, use `cargo +nightly` for each of the following commands.

Now you can run your project in Miri:

- To run all tests in your project through Miri, use `cargo miri test`.
- If you have a binary project, you can run it through Miri using `cargo miri run`.

The first time you run Miri, it will perform some extra setup and install some
dependencies. It will ask you for confirmation before installing anything.

`cargo miri run/test` supports the exact same flags as `cargo run/test`. For
example, `cargo miri test filter` only runs the tests containing `filter` in
their name.

You can pass [flags][miri-flags] to Miri via `MIRIFLAGS`. For example,
`MIRIFLAGS=&quot;-Zmiri-disable-stacked-borrows&quot; cargo miri run` runs the program
without checking the aliasing of references.

When compiling code via `cargo miri`, the `cfg(miri)` config flag is set for code
that will be interpreted under Miri. You can use this to ignore test cases that fail
under Miri because they do things Miri does not support:

```rust
#[test]
#[cfg_attr(miri, ignore)]
fn does_not_work_on_miri() {
    tokio::run(futures::future::ok::&lt;_, ()&gt;(()));
}
```

There is no way to list all the infinite things Miri cannot do, but the
interpreter will explicitly tell you when it finds something unsupported:

```
error: unsupported operation: can&#039;t call foreign function: bind
    ...
    = help: this is likely not a bug in the program; it indicates that the program \
            performed an operation that Miri does not support
```

### Cross-interpretation: running for different targets

Miri can not only run a binary or test suite for your host target, it can also
perform cross-interpretation for arbitrary foreign targets: `cargo miri run
--target x86_64-unknown-linux-gnu` will run your program as if it was a Linux
program, no matter your host OS. This is particularly useful if you are using
Windows, as the Linux target is much better supported than Windows targets.

You can also use this to test platforms with different properties than your host
platform. For example `cargo miri test --target s390x-unknown-linux-gnu`
will run your test suite on a big-endian target, which is useful for testing
endian-sensitive code.

### Testing multiple different executions

Certain parts of the execution are picked randomly by Miri, such as the exact base address
allocations are stored at and the interleaving of concurrently executing threads. Sometimes, it can
be useful to explore multiple different execution, e.g. to make sure that your code does not depend
on incidental &quot;super-alignment&quot; of new allocations and to test different thread interleavings.
This can be done with the `-Zmiri-many-seeds` flag:

```
MIRIFLAGS=&quot;-Zmiri-many-seeds&quot; cargo miri test # tries the seeds in 0..64
MIRIFLAGS=&quot;-Zmiri-many-seeds=0..16&quot; cargo miri test
```

The default of 64 different seeds can be quite slow, so you often want to specify a smaller range.

### Running Miri on CI

When running Miri on CI, use the following snippet to install a nightly toolchain with the Miri
component:

```sh
rustup toolchain install nightly --component miri
rustup override set nightly

cargo miri test
```

Here is an example job for GitHub Actions:

```yaml
  miri:
    name: &quot;Miri&quot;
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Install Miri
        run: |
          rustup toolchain install nightly --component miri
          rustup override set nightly
          cargo miri setup
      - name: Test with Miri
        run: cargo miri test
```

The explicit `cargo miri setup` helps to keep the output of the actual test step
clean.

### Supported targets

Miri does not support all targets supported by Rust. The good news, however, is
that no matter your host OS/platform, it is easy to run code for *any* target
using `--target`!

The following targets are tested on CI and thus should always work (to the
degree documented below):

- All Rust [Tier 1 targets](https://doc.rust-lang.org/rustc/platform-support.html) are supported by
  Miri. They are all checked on Miri&#039;s CI, and some (at least one per OS) are even checked on every
  Rust PR, so the shipped Miri should always work on these targets.
- `s390x-unknown-linux-gnu` is supported as our &quot;big-endian target of choice&quot;.
- For every other target with OS `linux`, `macos`, or `windows`, Miri should generally work, but we
  make no promises and we don&#039;t run tests for such targets.
- We have unofficial support (not maintained by the Miri team itself) for some further operating systems.
  - `solaris` / `illumos`: maintained by @devnexen. Supports the entire test suite.
  - `freebsd`: maintained by @YohDeadfall and @LorrensP-2158466. Supports the entire test suite.
  - `android`: **maintainer wanted**. Basic OS APIs and concurrency work, but file system access is not supported.
- For targets on other operating systems, Miri might fail before even reaching the `main` function.

However, even for targets that we do support, the degree of support for accessing platform APIs
(such as the file system) differs between targets: generally, Linux targets have the best support,
and macOS targets are usually on par. Windows is supported less well.

### Running tests in parallel

Though it implements Rust threading, Miri itself is a single-threaded interpreter.
This means that when running `cargo miri test`, you will probably see a dramatic
increase in the amount of time it takes to run your whole test suite due to the
inherent interpreter slowdown and a loss of parallelism.

You can get your test suite&#039;s parallelism back by running `cargo miri nextest run -jN`
(note that you will need [`cargo-nextest`](https://nexte.st) installed).
This works because `cargo-nextest` collects a list of all tests then launches a
separate `cargo miri run` for each test. For more information about nextest, see the
[`cargo-nextest` Miri documentation](https://nexte.st/book/miri.html).

Note: This one-test-per-process model means that `cargo miri test` is able to detect data
races where two tests race on a shared resource, but `cargo miri nextest run` will not detect
such races.

Note: `cargo-nextest` does not support doctests, see https://github.com/nextest-rs/nextest/issues/16

### Directly invoking the `miri` driver

The recommended way to invoke Miri is via `cargo miri`. Directly invoking the underlying `miri`
driver is not supported, which is why that binary is not even installed into the PATH. However, if
you need to run Miri on many small tests and want to invoke it directly like you would invoke
`rustc`, that is still possible with a bit of extra effort:

```sh
# one-time setup
cargo +nightly miri setup
SYSROOT=$(cargo +nightly miri setup --print-sysroot)
# per file
~/.rustup/toolchains/nightly-x86_64-unknown-linux-gnu/bin/miri --sysroot &quot;$SYSROOT&quot; file.rs
```

### Common Problems

When using the above instructions, you may encounter a number of confusing compiler
errors.

#### &quot;note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace&quot;

You may see this when trying to get Miri to display a backtrace. By default, Miri
doesn&#039;t expose any environment to the program, so running
`RUST_BACKTRACE=1 cargo miri test` will not do what you expect.

To get a backtrace, you need to disable isolation
[using `-Zmiri-disable-isolation`][miri-flags]:

```sh
RUST_BACKTRACE=1 MIRIFLAGS=&quot;-Zmiri-disable-isolation&quot; cargo miri test
```

#### &quot;found crate `std` compiled by an incompatible version of rustc&quot;

You may be running `cargo miri` with a different compiler version than the one
used to build the custom libstd that Miri uses, and Miri failed to detect that.
Try running `cargo miri clean`.


## Miri `-Z` flags and environment variables
[miri-flags]: #miri--z-flags-and-environment-variables

Miri adds its own set of `-Z` flags, which are usually set via the `MIRIFLAGS`
environment variable. We first document the most relevant and most commonly used flags:

* `-Zmiri-backtrace=&lt;0|1|full&gt;` configures how Miri prints backtraces: `1` is the default,
  where backtraces are printed in pruned form; `full` prints backtraces without pruning, and `0`
  disables backtraces entirely.
* `-Zmiri-deterministic-concurrency` makes Miri&#039;s concurrency-related behavior fully deterministic.
  Strictly speaking, Miri is always fully deterministic when isolation is enabled (the default
  mode), but this determinism is achieved by using an RNG with a fixed seed. Seemingly harmless
  changes to the program, or just running it for a different target architecture, can thus lead to
  completely different program behavior down the line. This flag disables the use of an RNG for
  concurrency-related decisions. Therefore, Miri cannot find bugs that only occur under some
  specific circumstances, but Miri&#039;s behavior will also be more stable across versions and targets.
  This is equivalent to `-Zmiri-fixed-schedule -Zmiri-compare-exchange-weak-failure-rate=0.0
  -Zmiri-address-reuse-cross-thread-rate=0.0 -Zmiri-disable-weak-memory-emulation`.
* `-Zmiri-disable-isolation` disables host isolation. As a consequence,
  the program has access to host resources such as environment variables, file
  systems, and randomness.
  This overwrites a previous `-Zmiri-isolation-error`.
* `-Zmiri-disable-leak-backtraces` disables backtraces reports for memory leaks. By default, a
  backtrace is captured for every allocation when it is created, just in case it leaks. This incurs
  some memory overhead to store data that is almost never used. This flag is implied by
  `-Zmiri-ignore-leaks`.
* `-Zmiri-env-forward=&lt;var&gt;` forwards the `var` environment variable to the interpreted program. Can
  be used multiple times to forward several variables. Execution will still be deterministic if the
  value of forwarded variables stays the same. Has no effect if `-Zmiri-disable-isolation` is set.
* `-Zmiri-env-set=&lt;var&gt;=&lt;value&gt;` sets the `var` environment variable to `value` in the interpreted program.
  It can be used to pass environment variables without needing to alter the host environment. It can
  be used multiple times to set several variables. If `-Zmiri-disable-isolation` or `-Zmiri-env-forward`
  is set, values set with this option will have priority over values from the host environment.
* `-Zmiri-ignore-leaks` disables the memory leak checker, and also allows some
  remaining threads to exist when the main thread exits.
* `-Zmiri-isolation-error=&lt;action&gt;` configures Miri&#039;s response to operations
  requiring host access while isolation is enabled. `abort`, `hide`, `warn`,
  and `warn-nobacktrace` are the supported actions. The default is to `abort`,
  which halts the machine. Some (but not all) operations also support continuing
  execution with a &quot;permission denied&quot; error being returned to the program.
  `warn` prints a full backtrace each time that happens; `warn-nobacktrace` is less
  verbose and shown at most once per operation. `hide` hides the warning entirely.
  This overwrites a previous `-Zmiri-disable-isolation`.
* `-Zmiri-many-seeds=[&lt;from&gt;]..&lt;to&gt;` runs the program multiple times with different seeds for Miri&#039;s
  RNG. With different seeds, Miri will make different choices to resolve non-determinism such as the
  order in which concurrent threads are scheduled, or the exact addresses assigned to allocations.
  This is useful to find bugs that only occur under particular interleavings of concurrent threads,
  or that otherwise depend on non-determinism. If the `&lt;from&gt;` part is skipped, it defaults to `0`.
  Can be used without a value; in that case the range defaults to `0..64`.
* `-Zmiri-many-seeds-keep-going` tells Miri to really try all the seeds in the given range, even if
  a failing seed has already been found. This is useful to determine which fraction of seeds fails.
* `-Zmiri-max-extra-rounding-error` tells Miri to always apply the maximum error to float operations
  that do not have a guaranteed precision. The sign of the error is still non-deterministic.
* `-Zmiri-no-extra-rounding-error` stops Miri from adding extra rounding errors to float operations
  that do not have a guaranteed precision.
* `-Zmiri-no-short-fd-operations` stops Miri from artificially forcing `read`/`write` operations
  to only process a part of their buffer. Note that whenever Miri uses host operations to
  implement `read`/`write` (e.g. for file-backed file descriptors), the host system can still
  introduce short reads/writes.
* `-Zmiri-num-cpus` states the number of available CPUs to be reported by miri. By default, the
  number of available CPUs is `1`. Note that this flag does not affect how miri handles threads in
  any way.
* `-Zmiri-permissive-provenance` disables the warning for integer-to-pointer casts and
  [`ptr::with_exposed_provenance`](https://doc.rust-lang.org/nightly/std/ptr/fn.with_exposed_provenance.html).
  This will necessarily miss some bugs as those operations are not efficiently and accurately
  implementable in a sanitizer, but it will only miss bugs that concern memory/pointers which is
  subject to these operations.
* `-Zmiri-report-progress` makes Miri print the current stacktrace every now and then, so you can
  tell what it is doing when a program just keeps running. You can customize how frequently the
  report is printed via `-Zmiri-report-progress=&lt;blocks&gt;`, which prints the report every N basic
  blocks.
* `-Zmiri-seed=&lt;num&gt;` configures the seed of the RNG that Miri uses to resolve non-determinism. This
  RNG is used to pick base addresses for allocations, to determine preemption and failure of
  `compare_exchange_weak`, and to control store buffering for weak memory emulation. When isolation
  is enabled (the default), this is also used to emulate system entropy. The default seed is 0. You
  can increase test coverage by running Miri multiple times with different seeds.
* `-Zmiri-strict-provenance` enables [strict
  provenance](https://doc.rust-lang.org/nightly/std/ptr/index.

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/rust]]></title>
            <link>https://github.com/rust-lang/rust</link>
            <guid>https://github.com/rust-lang/rust</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:40 GMT</pubDate>
            <description><![CDATA[Empowering everyone to build reliable and efficient software.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/rust">rust-lang/rust</a></h1>
            <p>Empowering everyone to build reliable and efficient software.</p>
            <p>Language: Rust</p>
            <p>Stars: 108,799</p>
            <p>Forks: 14,226</p>
            <p>Stars today: 59 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-dark.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-light.svg&quot;&gt;
    &lt;img alt=&quot;The Rust Programming Language: A language empowering everyone to build reliable and efficient software&quot;
         src=&quot;https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-light.svg&quot;
         width=&quot;50%&quot;&gt;
  &lt;/picture&gt;

[Website][Rust] | [Getting started] | [Learn] | [Documentation] | [Contributing]
&lt;/div&gt;

This is the main source code repository for [Rust]. It contains the compiler,
standard library, and documentation.

[Rust]: https://www.rust-lang.org/
[Getting Started]: https://www.rust-lang.org/learn/get-started
[Learn]: https://www.rust-lang.org/learn
[Documentation]: https://www.rust-lang.org/learn#learn-use
[Contributing]: CONTRIBUTING.md

## Why Rust?

- **Performance:** Fast and memory-efficient, suitable for critical services, embedded devices, and easily integrated with other languages.

- **Reliability:** Our rich type system and ownership model ensure memory and thread safety, reducing bugs at compile-time.

- **Productivity:** Comprehensive documentation, a compiler committed to providing great diagnostics, and advanced tooling including package manager and build tool ([Cargo]), auto-formatter ([rustfmt]), linter ([Clippy]) and editor support ([rust-analyzer]).

[Cargo]: https://github.com/rust-lang/cargo
[rustfmt]: https://github.com/rust-lang/rustfmt
[Clippy]: https://github.com/rust-lang/rust-clippy
[rust-analyzer]: https://github.com/rust-lang/rust-analyzer

## Quick Start

Read [&quot;Installation&quot;] from [The Book].

[&quot;Installation&quot;]: https://doc.rust-lang.org/book/ch01-01-installation.html
[The Book]: https://doc.rust-lang.org/book/index.html

## Installing from Source

If you really want to install from source (though this is not recommended), see
[INSTALL.md](INSTALL.md).

## Getting Help

See https://www.rust-lang.org/community for a list of chat platforms and forums.

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md).

## License

Rust is primarily distributed under the terms of both the MIT license and the
Apache License (Version 2.0), with portions covered by various BSD-like
licenses.

See [LICENSE-APACHE](LICENSE-APACHE), [LICENSE-MIT](LICENSE-MIT), and
[COPYRIGHT](COPYRIGHT) for details.

## Trademark

[The Rust Foundation][rust-foundation] owns and protects the Rust and Cargo
trademarks and logos (the &quot;Rust Trademarks&quot;).

If you want to use these names or brands, please read the
[Rust language trademark policy][trademark-policy].

Third-party logos may be subject to third-party copyrights and trademarks. See
[Licenses][policies-licenses] for details.

[rust-foundation]: https://rustfoundation.org/
[trademark-policy]: https://rustfoundation.org/policy/rust-trademark-policy/
[policies-licenses]: https://www.rust-lang.org/policies/licenses
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[farion1231/cc-switch]]></title>
            <link>https://github.com/farion1231/cc-switch</link>
            <guid>https://github.com/farion1231/cc-switch</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:39 GMT</pubDate>
            <description><![CDATA[A cross-platform desktop All-in-One assistant tool for Claude Code, Codex & Gemini CLI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/farion1231/cc-switch">farion1231/cc-switch</a></h1>
            <p>A cross-platform desktop All-in-One assistant tool for Claude Code, Codex & Gemini CLI.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,556</p>
            <p>Forks: 508</p>
            <p>Stars today: 127 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# All-in-One Assistant for Claude Code, Codex &amp; Gemini CLI

[![Version](https://img.shields.io/badge/version-3.8.2-blue.svg)](https://github.com/farion1231/cc-switch/releases)
[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)
[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)
[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)

&lt;a href=&quot;https://trendshift.io/repositories/15372&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15372&quot; alt=&quot;farion1231%2Fcc-switch | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

English | [‰∏≠Êñá](README_ZH.md) | [Êó•Êú¨Ë™û](README_JA.md) | [Changelog](CHANGELOG.md)

&lt;/div&gt;

## ‚ù§Ô∏èSponsor

![Zhipu GLM](assets/partners/banners/glm-en.jpg)

This project is sponsored by Z.ai, supporting us with their GLM CODING PLAN.GLM CODING PLAN is a subscription service designed for AI coding, starting at just $3/month. It provides access to their flagship GLM-4.6 model across 10+ popular AI coding tools (Claude Code, Cline, Roo Code, etc.), offering developers top-tier, fast, and stable coding experiences.Get 10% OFF the GLM CODING PLAN with [this link](https://z.ai/subscribe?ic=8JVLJQFSKB)!

---

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;img src=&quot;assets/partners/logos/packycode.png&quot; alt=&quot;PackyCode&quot; width=&quot;150&quot;&gt;&lt;/td&gt;
&lt;td&gt;Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using &lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;this link&lt;/a&gt; and enter the &quot;cc-switch&quot; promo code during recharge to get 10% off.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;img src=&quot;assets/partners/logos/sds-en.png&quot; alt=&quot;ShanDianShuo&quot; width=&quot;150&quot;&gt;&lt;/td&gt;
&lt;td&gt;Thanks to ShanDianShuo for sponsoring this project! ShanDianShuo is a local-first AI voice input: Millisecond latency, data stays on device, 4x faster than typing, AI-powered correction, Privacy-first, completely free. Doubles your coding efficiency with Claude Code! &lt;a href=&quot;https://www.shandianshuo.cn&quot;&gt;Free download&lt;/a&gt; for Mac/Win&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;img src=&quot;assets/partners/logos/aigocode.png&quot; alt=&quot;AIGoCode&quot; width=&quot;150&quot;&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses.AIGoCode has prepared a special benefit for CC Switch users: if you register via &lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;this link&lt;/a&gt;, you‚Äôll receive an extra 10% bonus credit on your first top-up!
&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

## Screenshots

|                  Main Interface                   |                  Add Provider                  |
| :-----------------------------------------------: | :--------------------------------------------: |
| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |

## Features

### Current Version: v3.8.2 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.8.0-en.md)

**v3.8.0 Major Update (2025-11-28)**

**Persistence Architecture Upgrade &amp; Brand New UI**

- **SQLite + JSON Dual-layer Architecture**
  - Migrated from JSON file storage to SQLite + JSON dual-layer structure
  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite
  - Device-level data (window state, local paths) stored in JSON
  - Lays the foundation for future cloud sync functionality
  - Schema version management for database migrations

- **Brand New User Interface**
  - Completely redesigned interface layout
  - Unified component styles and smoother animations
  - Optimized visual hierarchy
  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility

- **Japanese Language Support**
  - Added Japanese interface support (now supports Chinese/English/Japanese)

- **Auto Launch on Startup**
  - One-click enable/disable in settings
  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)

- **Skills Recursive Scanning**
  - Support for multi-level directory structures
  - Allow same-named skills from different repositories

- **Critical Bug Fixes**
  - Fixed custom endpoints lost when updating providers
  - Fixed Gemini configuration write issues
  - Fixed Linux WebKitGTK rendering issues

**v3.7.0 Highlights**

**Six Core Features, 18,000+ Lines of New Code**

- **Gemini CLI Integration**
  - Third supported AI CLI (Claude Code / Codex / Gemini)
  - Dual-file configuration support (`.env` + `settings.json`)
  - Complete MCP server management
  - Presets: Google Official (OAuth) / PackyCode / Custom

- **Claude Skills Management System**
  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)
  - One-click install/uninstall to `~/.claude/skills/`
  - Custom repository support + subdirectory scanning
  - Complete lifecycle management (discover/install/update)

- **Prompts Management System**
  - Multi-preset system prompt management (unlimited presets, quick switching)
  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)
  - Markdown editor (CodeMirror 6 + real-time preview)
  - Smart backfill protection, preserves manual modifications

- **MCP v3.7.0 Unified Architecture**
  - Single panel manages MCP servers across three applications
  - New SSE (Server-Sent Events) transport type
  - Smart JSON parser + Codex TOML format auto-correction
  - Unified import/export + bidirectional sync

- **Deep Link Protocol**
  - `ccswitch://` protocol registration (all platforms)
  - One-click import provider configs via shared links
  - Security validation + lifecycle integration

- **Environment Variable Conflict Detection**
  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)
  - Visual conflict indicators + resolution suggestions
  - Override warnings + backup before changes

**Core Capabilities**

- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations
- **Speed Testing**: Measure API endpoint latency with visual quality indicators
- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)
- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)
- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations

**v3.6 Highlights**

- Provider duplication &amp; drag-and-drop sorting
- Multi-endpoint management &amp; custom config directory (cloud sync ready)
- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)
- WSL environment support with auto-sync on directory change
- 100% hooks test coverage &amp; complete architecture refactoring

**System Features**

- System tray with quick switching
- Single instance daemon
- Built-in auto-updater
- Atomic writes with rollback protection

## Download &amp; Installation

### System Requirements

- **Windows**: Windows 10 and above
- **macOS**: macOS 10.15 (Catalina) and above
- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions

### Windows Users

Download the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.

### macOS Users

**Method 1: Install via Homebrew (Recommended)**

```bash
brew tap farion1231/ccswitch
brew install --cask cc-switch
```

Update:

```bash
brew upgrade --cask cc-switch
```

**Method 2: Manual Download**

Download `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.

&gt; **Note**: Since the author doesn&#039;t have an Apple Developer account, you may see an &quot;unidentified developer&quot; warning on first launch. Please close it first, then go to &quot;System Settings&quot; ‚Üí &quot;Privacy &amp; Security&quot; ‚Üí click &quot;Open Anyway&quot;, and you&#039;ll be able to open it normally afterwards.

### ArchLinux Áî®Êà∑

**Install via paru (Recommended)**

```bash
paru -S cc-switch-bin
```

### Linux Users

Download the latest `CC-Switch-v{version}-Linux.deb` package or `CC-Switch-v{version}-Linux.AppImage` from the [Releases](../../releases) page.

## Quick Start

### Basic Usage

1. **Add Provider**: Click &quot;Add Provider&quot; ‚Üí Choose preset or create custom configuration
2. **Switch Provider**:
   - Main UI: Select provider ‚Üí Click &quot;Enable&quot;
   - System Tray: Click provider name directly (instant effect)
3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes
4. **Back to Official**: Select the &quot;Official Login&quot; preset (Claude/Codex) or &quot;Google Official&quot; preset (Gemini), restart the corresponding client, then follow its login/OAuth flow

### MCP Management

- **Location**: Click &quot;MCP&quot; button in top-right corner
- **Add Server**:
  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)
  - Support stdio / http / sse transport types
  - Configure independent MCP servers for different apps
- **Enable/Disable**: Toggle switches to control which servers sync to live config
- **Sync**: Enabled servers auto-sync to each app&#039;s live files
- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files

### Skills Management (v3.7.0 New)

- **Location**: Click &quot;Skills&quot; button in top-right corner
- **Discover Skills**:
  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)
  - Add custom repositories (supports subdirectory scanning)
- **Install Skills**: Click &quot;Install&quot; to one-click install to `~/.claude/skills/`
- **Uninstall Skills**: Click &quot;Uninstall&quot; to safely remove and clean up state
- **Manage Repositories**: Add/remove custom GitHub repositories

### Prompts Management (v3.7.0 New)

- **Location**: Click &quot;Prompts&quot; button in top-right corner
- **Create Presets**:
  - Create unlimited system prompt presets
  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)
- **Switch Presets**: Select preset ‚Üí Click &quot;Activate&quot; to apply immediately
- **Sync Mechanism**:
  - Claude: `~/.claude/CLAUDE.md`
  - Codex: `~/.codex/AGENTS.md`
  - Gemini: `~/.gemini/GEMINI.md`
- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications

### Configuration Files

**Claude Code**

- Live config: `~/.claude/settings.json` (or `claude.json`)
- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`
- MCP servers: `~/.claude.json` ‚Üí `mcpServers`

**Codex**

- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)
- API key field: `OPENAI_API_KEY` in `auth.json`
- MCP servers: `~/.codex/config.toml` ‚Üí `[mcp_servers]` tables

**Gemini**

- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)
- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`
- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.
- MCP servers: `~/.gemini/settings.json` ‚Üí `mcpServers`
- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI

**CC Switch Storage (v3.8.0 New Architecture)**

- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)
- Local settings: `~/.cc-switch/settings.json` (device-level settings)
- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)

### Cloud Sync Setup

1. Go to Settings ‚Üí &quot;Custom Configuration Directory&quot;
2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)
3. Restart app to apply
4. Repeat on other devices to enable cross-device sync

&gt; **Note**: First launch auto-imports existing Claude/Codex configs as default provider.

## Architecture Overview

### Design Principles

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (React + TS)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Components  ‚îÇ  ‚îÇ    Hooks     ‚îÇ  ‚îÇ  TanStack Query  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (UI)      ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Logic) ‚îÇ‚îÄ‚îÄ‚îÇ   (Cache/Sync)   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ Tauri IPC
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Backend (Tauri + Rust)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Commands   ‚îÇ  ‚îÇ   Services   ‚îÇ  ‚îÇ  Models/Config   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ (API Layer) ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Layer) ‚îÇ‚îÄ‚îÄ‚îÇ     (Data)       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Core Design Patterns**

- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)
- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings
- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider
- **Atomic Writes**: Temp file + rename pattern prevents config corruption
- **Concurrency Safe**: Mutex-protected database connection avoids race conditions
- **Layered Architecture**: Clear separation (Commands ‚Üí Services ‚Üí DAO ‚Üí Database)

**Key Components**

- **ProviderService**: Provider CRUD, switching, backfill, sorting
- **McpService**: MCP server management, import/export, live file sync
- **ConfigService**: Config import/export, backup rotation
- **SpeedtestService**: API endpoint latency measurement

**v3.6 Refactoring**

- Backend: 5-phase refactoring (error handling ‚Üí command split ‚Üí tests ‚Üí services ‚Üí concurrency)
- Frontend: 4-stage refactoring (test infra ‚Üí hooks ‚Üí components ‚Üí cleanup)
- Testing: 100% hooks coverage + integration tests (vitest + MSW)

## Development

### Environment Requirements

- Node.js 18+
- pnpm 8+
- Rust 1.85+
- Tauri CLI 2.8+

### Development Commands

```bash
# Install dependencies
pnpm install

# Dev mode (hot reload)
pnpm dev

# Type check
pnpm typecheck

# Format code
pnpm format

# Check code format
pnpm format:check

# Run frontend unit tests
pnpm test:unit

# Run tests in watch mode (recommended for development)
pnpm test:unit:watch

# Build application
pnpm build

# Build debug version
pnpm tauri build --debug
```

### Rust Backend Development

```bash
cd src-tauri

# Format Rust code
cargo fmt

# Run clippy checks
cargo clippy

# Run backend tests
cargo test

# Run specific tests
cargo test test_name

# Run tests with test-hooks feature
cargo test --features test-hooks
```

### Testing Guide (v3.6 New)

**Frontend Testing**:

- Uses **vitest** as test framework
- Uses **MSW (Mock Service Worker)** to mock Tauri API calls
- Uses **@testing-library/react** for component testing

**Test Coverage**:

- Hooks unit tests (100% coverage)
  - `useProviderActions` - Provider operations
  - `useMcpActions` - MCP management
  - `useSettings` series - Settings management
  - `useImportExport` - Import/export
- Integration tests
  - App main application flow
  - SettingsDialog complete interaction
  - MCP panel functionality

**Running Tests**:

```bash
# Run all tests
pnpm test:unit

# Watch mode (auto re-run)
pnpm test:unit:watch

# With coverage report
pnpm test:unit --coverage
```

## Tech Stack

**Frontend**: React 18 ¬∑ TypeScript ¬∑ Vite ¬∑ TailwindCSS 4 ¬∑ TanStack Query v5 ¬∑ react-i18next ¬∑ react-hook-form ¬∑ zod ¬∑ shadcn/ui ¬∑ @dnd-kit

**Backend**: Tauri 2.8 ¬∑ Rust ¬∑ serde ¬∑ tokio ¬∑ thiserror ¬∑ tauri-plugin-updater/process/dialog/store/log

**Testing**: vitest ¬∑ MSW ¬∑ @testing-library/react

## Project Structure

```
‚îú‚îÄ‚îÄ src/                      # Frontend (React + TypeScript)
‚îÇ   ‚îú‚îÄ‚îÄ components/           # UI components (providers/settings/mcp/ui)
‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Custom hooks (business logic)
‚îÇ   ‚îú‚îÄ‚îÄ lib/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api/              # Tauri API wrapper (type-safe)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ query/            # TanStack Query config
‚îÇ   ‚îú‚îÄ‚îÄ i18n/locales/         # Translations (zh/en)
‚îÇ   ‚îú‚îÄ‚îÄ config/               # Presets (providers/mcp)
‚îÇ   ‚îî‚îÄ‚îÄ types/                # TypeScript definitions
‚îú‚îÄ‚îÄ src-tauri/                # Backend (Rust)
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îú‚îÄ‚îÄ commands/         # Tauri command layer (by domain)
‚îÇ       ‚îú‚îÄ‚îÄ services/         # Business logic layer
‚îÇ       ‚îú‚îÄ‚îÄ app_config.rs     # Config data models
‚îÇ       ‚îú‚îÄ‚îÄ provider.rs       # Provider domain models
‚îÇ       ‚îú‚îÄ‚îÄ mcp.rs            # MCP sync &amp; validation
‚îÇ       ‚îî‚îÄ‚îÄ lib.rs            # App entry &amp; tray menu
‚îú‚îÄ‚îÄ tests/                    # Frontend tests
‚îÇ   ‚îú‚îÄ‚îÄ hooks/                # Unit tests
‚îÇ   ‚îî‚îÄ‚îÄ components/           # Integration tests
‚îî‚îÄ‚îÄ assets/                   # Screenshots &amp; partner resources
```

## Changelog

See [CHANGELOG.md](CHANGELOG.md) for version update details.

## Legacy Electron Version

[Releases](../../releases) retains v2.0.3 legacy Electron version

If you need legacy Electron code, you can pull the electron-legacy branch

## Contributing

Issues and suggestions are welcome!

Before submitting PRs, please ensure:

- Pass type check: `pnpm typecheck`
- Pass format check: `pnpm format:check`
- Pass unit tests: `pnpm test:unit`
- üí° For new features, please open an issue for discussion before submitting a PR

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=farion1231/cc-switch&amp;type=Date)](https://www.star-history.com/#farion1231/cc-switch&amp;Date)

## License

MIT ¬© Jason Young
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[firecracker-microvm/firecracker]]></title>
            <link>https://github.com/firecracker-microvm/firecracker</link>
            <guid>https://github.com/firecracker-microvm/firecracker</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:38 GMT</pubDate>
            <description><![CDATA[Secure and fast microVMs for serverless computing.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/firecracker-microvm/firecracker">firecracker-microvm/firecracker</a></h1>
            <p>Secure and fast microVMs for serverless computing.</p>
            <p>Language: Rust</p>
            <p>Stars: 31,513</p>
            <p>Forks: 2,181</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/fc_logo_full_transparent-bg_white-fg.png&quot;&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/images/fc_logo_full_transparent-bg.png&quot;&gt;
   &lt;img alt=&quot;Firecracker Logo Title&quot; width=&quot;750&quot; src=&quot;docs/images/fc_logo_full_transparent-bg.png&quot;&gt;
&lt;/picture&gt;

Our mission is to enable secure, multi-tenant, minimal-overhead execution of
container and function workloads.

Read more about the Firecracker Charter [here](CHARTER.md).

## What is Firecracker?

Firecracker is an open source virtualization technology that is purpose-built
for creating and managing secure, multi-tenant container and function-based
services that provide serverless operational models. Firecracker runs workloads
in lightweight virtual machines, called microVMs, which combine the security and
isolation properties provided by hardware virtualization technology with the
speed and flexibility of containers.

## Overview

The main component of Firecracker is a virtual machine monitor (VMM) that uses
the Linux Kernel Virtual Machine (KVM) to create and run microVMs. Firecracker
has a minimalist design. It excludes unnecessary devices and guest-facing
functionality to reduce the memory footprint and attack surface area of each
microVM. This improves security, decreases the startup time, and increases
hardware utilization. Firecracker has also been integrated in container
runtimes, for example
[Kata Containers](https://github.com/kata-containers/kata-containers) and
[Flintlock](https://github.com/liquidmetal-dev/flintlock).

Firecracker was developed at Amazon Web Services to accelerate the speed and
efficiency of services like [AWS Lambda](https://aws.amazon.com/lambda/) and
[AWS Fargate](https://aws.amazon.com/fargate/). Firecracker is open sourced
under [Apache version 2.0](LICENSE).

To read more about Firecracker, check out
[firecracker-microvm.io](https://firecracker-microvm.github.io).

## Getting Started

To get started with Firecracker, download the latest
[release](https://github.com/firecracker-microvm/firecracker/releases) binaries
or build it from source.

You can build Firecracker on any Unix/Linux system that has Docker running (we
use a development container) and `bash` installed, as follows:

```bash
git clone https://github.com/firecracker-microvm/firecracker
cd firecracker
tools/devtool build
toolchain=&quot;$(uname -m)-unknown-linux-musl&quot;
```

The Firecracker binary will be placed at
`build/cargo_target/${toolchain}/debug/firecracker`. For more information on
building, testing, and running Firecracker, go to the
[quickstart guide](docs/getting-started.md).

The overall security of Firecracker microVMs, including the ability to meet the
criteria for safe multi-tenant computing, depends on a well configured Linux
host operating system. A configuration that we believe meets this bar is
included in [the production host setup document](docs/prod-host-setup.md).

## Contributing

Firecracker is already running production workloads within AWS, but it&#039;s still
Day 1 on the journey guided by our [mission](CHARTER.md). There&#039;s a lot more to
build and we welcome all contributions.

To contribute to Firecracker, check out the development setup section in the
[getting started guide](docs/getting-started.md) and then the Firecracker
[contribution guidelines](CONTRIBUTING.md).

## Releases

New Firecracker versions are released via the GitHub repository
[releases](https://github.com/firecracker-microvm/firecracker/releases) page,
typically every two or three months. A history of changes is recorded in our
[changelog](CHANGELOG.md).

The Firecracker release policy is detailed [here](docs/RELEASE_POLICY.md).

## Design

Firecracker&#039;s overall architecture is described in
[the design document](docs/design.md).

## Features &amp; Capabilities

Firecracker consists of a single micro Virtual Machine Manager process that
exposes an API endpoint to the host once started. The API is
[specified in OpenAPI format](src/firecracker/swagger/firecracker.yaml). Read
more about it in the [API docs](docs/api_requests).

The **API endpoint** can be used to:

- Configure the microvm by:
  - Setting the number of vCPUs (the default is 1).
  - Setting the memory size (the default is 128 MiB).
  - Configuring a [CPU template](docs/cpu_templates/cpu-templates.md).
- Add one or more network interfaces to the microVM.
- Add one or more read-write or read-only disks to the microVM, each represented
  by a file-backed block device.
- Trigger a block device re-scan while the guest is running. This enables the
  guest OS to pick up size changes to the block device&#039;s backing file.
- Change the backing file for a block device, before or after the guest boots.
- Configure rate limiters for virtio devices which can limit the bandwidth,
  operations per second, or both.
- Configure the logging and metric system.
- `[BETA]` Configure the data tree of the guest-facing metadata service. The
  service is only available to the guest if this resource is configured.
- Add a [vsock socket](docs/vsock.md) to the microVM.
- Add a [entropy device](docs/entropy.md) to the microVM.
- Add a [pmem device](docs/pmem.md) to the microVM.
- Configure and manage [memory hotplugging](docs/memory-hotplug.md).
- Start the microVM using a given kernel image, root file system, and boot
  arguments.
- [x86_64 only] Stop the microVM.

**Built-in Capabilities**:

- Demand fault paging and CPU oversubscription enabled by default.
- Advanced, thread-specific seccomp filters for enhanced security.
- [Jailer](docs/jailer.md) process for starting Firecracker in production
  scenarios; applies a cgroup/namespace isolation barrier and then drops
  privileges.

## Tested platforms

We test all combinations of:

| Instance                               | Host OS &amp; Kernel | Guest Rootfs | Guest Kernel |
| :------------------------------------- | :--------------- | :----------- | :----------- |
| m5n.metal (Intel Cascade Lake)         | al2 linux_5.10   | ubuntu 24.04 | linux_5.10   |
| m6i.metal (Intel Ice Lake)             | al2023 linux_6.1 |              | linux_6.1    |
| m7i.metal-24xl (Intel Sapphire Rapids) |                  |              |              |
| m7i.metal-48xl (Intel Sapphire Rapids) |                  |              |              |
| m6a.metal (AMD Milan)                  |                  |              |              |
| m7a.metal-48xl (AMD Genoa)             |                  |              |              |
| m6g.metal (Graviton 2)                 |                  |              |              |
| m7g.metal (Graviton 3)                 |                  |              |              |
| m8g.metal-24xl (Graviton 4)            |                  |              |              |
| m8g.metal-48xl (Graviton 4)            |                  |              |              |

## Known issues and Limitations

- The `pl031` RTC device on aarch64 does not support interrupts, so guest
  programs which use an RTC alarm (e.g. `hwclock`) will not work.

## Performance

Firecracker&#039;s performance characteristics are listed as part of the
[specification documentation](SPECIFICATION.md). All specifications are a part
of our commitment to supporting container and function workloads in serverless
operational models, and are therefore enforced via continuous integration
testing.

## Policy for Security Disclosures

The security of Firecracker is our top priority. If you suspect you have
uncovered a vulnerability, contact us privately, as outlined in our
[security policy document](SECURITY.md); we will immediately prioritize your
disclosure.

## FAQ &amp; Contact

Frequently asked questions are collected in our [FAQ doc](FAQ.md).

You can get in touch with the Firecracker community in the following ways:

- Security-related issues, see our [security policy document](SECURITY.md).
- Chat with us on our
  [Slack workspace](https://join.slack.com/t/firecracker-microvm/shared_invite/zt-2tc0mfxpc-tU~HYAYSzLDl5XGGJU3YIg)
  _Note: most of the maintainers are on a European time zone._
- Open a GitHub issue in this repository.
- Email the maintainers at
  [firecracker-maintainers@amazon.com](mailto:firecracker-maintainers@amazon.com).

When communicating within the Firecracker community, please mind our
[code of conduct](CODE_OF_CONDUCT.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[spacedriveapp/spacedrive]]></title>
            <link>https://github.com/spacedriveapp/spacedrive</link>
            <guid>https://github.com/spacedriveapp/spacedrive</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:37 GMT</pubDate>
            <description><![CDATA[Spacedrive is an open source cross-platform file explorer, powered by a virtual distributed filesystem written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/spacedriveapp/spacedrive">spacedriveapp/spacedrive</a></h1>
            <p>Spacedrive is an open source cross-platform file explorer, powered by a virtual distributed filesystem written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 36,235</p>
            <p>Forks: 1,157</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;150&quot; height=&quot;150&quot; src=&quot;packages/assets/images/AppLogoV2.png&quot; alt=&quot;Spacedrive Logo&quot;&gt;
  &lt;h1 align=&quot;center&quot;&gt;Spacedrive&lt;/h1&gt;
  &lt;p align=&quot;center&quot;&gt;
  	A file manager built on a virtual distributed filesystem
    &lt;br /&gt;
    &lt;a href=&quot;https://spacedrive.com&quot;&gt;&lt;strong&gt;spacedrive.com&lt;/strong&gt;&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://v2.spacedrive.com&quot;&gt;&lt;strong&gt;v2 Documentation&lt;/strong&gt;&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://discord.gg/gTaF2Z44f5&quot;&gt;&lt;strong&gt;Discord&lt;/strong&gt;&lt;/a&gt;
  &lt;/p&gt;
  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://discord.gg/gTaF2Z44f5&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/discord/949090953497567312?label=Discord&amp;color=5865F2&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.gnu.org/licenses/agpl-3.0&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/static/v1?label=Licence&amp;message=AGPL%20v3&amp;color=000&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/spacedriveapp/spacedrive&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/static/v1?label=Core&amp;message=Rust&amp;color=DEA584&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/spacedriveapp/spacedrive/tree/main/extensions&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/static/v1?label=Ecosystem&amp;message=WASM&amp;color=63B17A&quot; /&gt;
    &lt;/a&gt;
  &lt;/p&gt;
&lt;/p&gt;

Spacedrive is an open source cross-platform file manager, powered by a virtual distributed filesystem (VDFS) written in Rust.

Organize files across multiple devices, clouds, and platforms from a single interface. Tag once, access everywhere. Never lose track of where your files are.

&gt; [!IMPORTANT]
&gt; Hi, Jamie here! This is Spacedrive v2 (December 2025)‚Äîa complete ground-up rewrite.
&gt;
&gt; After development of the original alpha version stopped in January this year, left with the hard lessons of the incomplete alpha, I set out to completely rebuild Spacedrive from the ground up. The first release **2.0.0-pre.1** is coming before Christmas.
&gt;
&gt; For now I am open sourcing the code, with complete history from my private fork intact for early testing and preparation for an actual release.
&gt;
&gt; If you&#039;re looking for the previous version, see the [v1 branch](https://github.com/spacedriveapp/spacedrive/tree/v1).

## The Problem

Computing was designed for a single-device world. The file managers we use today‚ÄîFinder, Explorer, Files‚Äîwere built when your data lived in one place: the computer in front of you.

The shift to multi-device computing forced us into cloud ecosystems. Want your files everywhere? Upload them to someone else&#039;s servers. The convenience came at a cost: **data ownership**. This wasn&#039;t accidental‚Äîcentralization was the path of least resistance for solving multi-device sync.

Now AI is accelerating this trend. Cloud services offer intelligent file analysis and semantic search, but only if you upload your data to their infrastructure. As we generate more data and AI becomes more capable, we&#039;re giving away more and more to access basic computing conveniences.

**The current system isn&#039;t built for a world where:**
- You own multiple devices with underutilized compute and storage
- Local AI models are becoming competitive with cloud alternatives
- Privacy and data sovereignty matter
- You shouldn&#039;t have to choose between convenience and control

## The Vision

Spacedrive is infrastructure for the next era of computing. It&#039;s an architecture designed for multi-device environments from the ground up‚Äînot cloud services retrofitted with offline support, but local-first sync that scales to the cloud when you want it.

As local AI models improve, Spacedrive becomes the fabric that enables the same insights cloud services offer today, but running on hardware you already own, on data that never leaves your control. This is a long-term project correcting computing&#039;s trajectory toward centralization.

The file explorer interface is deliberate. Everyone understands it. It&#039;s seen the least innovation in decades. And it has the most potential when you bake distributed computing, content awareness, and local AI into something universally familiar.

## How It Works

Spacedrive treats files as **first-class objects with content identity**, not paths. A photo on your laptop and the same photo on your NAS are recognized as one piece of content. This enables:

- **Content-aware deduplication** - Track redundancy across all devices
- **Semantic search** - Find files in under 100ms across millions of entries
- **Transactional operations** - Preview conflicts, space savings, and outcomes before execution
- **Peer-to-peer sync** - No servers, no consensus protocols, no single point of failure
- **Offline-first** - Full functionality without internet, syncs when devices reconnect

Files stay where they are. Spacedrive just makes them universally addressable with rich metadata and cross-device intelligence.

---

## Architecture

Spacedrive is built on four core principles:

### 1. Virtual Distributed Filesystem (VDFS)

Files and folders become first-class objects with rich metadata, independent of their physical location. Every file gets a universal address (`SdPath`) that works across devices. Content-aware addressing means you can reference files by what they contain, not just where they live.

### 2. Content Identity System

Adaptive hashing (BLAKE3 with strategic sampling for large files) creates a unique fingerprint for every piece of content. This enables:

- **Deduplication**: Recognize identical files across devices
- **Redundancy tracking**: Know where your backups are
- **Content-based operations**: &quot;Copy this file from wherever it&#039;s available&quot;

### 3. Transactional Actions

Every file operation can be previewed before execution. See exactly what will happen‚Äîspace savings, conflicts, estimated time‚Äîthen approve or cancel. Operations become durable jobs that survive network interruptions and device restarts.

### 4. Leaderless Sync

Peer-to-peer synchronization without central coordinators. Device-specific data (your filesystem index) uses state replication. Shared metadata (tags, ratings) uses a lightweight HLC-ordered log with deterministic conflict resolution. No leader election, no single point of failure.

---

## Core Features

| Feature                 | Description                                                                  |
| ----------------------- | ---------------------------------------------------------------------------- |
| **Cross-Platform**      | macOS, Windows, Linux, iOS, Android                                          |
| **Multi-Device Index**  | Unified view of files across all your devices                                |
| **Content Addressing**  | Find optimal file copies automatically (local-first, then LAN, then cloud)   |
| **Smart Deduplication** | Identify identical files regardless of name or location                      |
| **Cloud Integration**   | Index S3, Google Drive, Dropbox as first-class volumes                       |
| **P2P Networking**      | Direct device connections with automatic NAT traversal (Iroh + QUIC)         |
| **Semantic Tags**       | Graph-based tagging with hierarchies, aliases, and contextual disambiguation |
| **Action Preview**      | Simulate any operation before execution                                      |
| **Offline-First**       | Full functionality without internet, syncs when devices reconnect            |
| **Local Backup**        | P2P backup between your own devices (iOS photo backup available now)         |
| **Extension System**    | WASM-based plugins for domain-specific functionality                         |

---

## Tech Stack

**Core**

- **Rust** - Entire VDFS implementation (~183k lines)
- **SQLite + SeaORM** - Local-first database with type-safe queries
- **Iroh** - P2P networking with QUIC transport and hole-punching
- **BLAKE3** - Fast cryptographic hashing for content identity
- **WASM** - Sandboxed extension runtime

**Apps**

- **CLI** - Command-line interface
- **Server** - Headless daemon for Docker deployment
- **Tauri** - Cross-platform desktop (macOS, Windows, Linux) with React frontend
- **Web** - Web interface and shared UI components
- **Mobile** - Cross-platform mobile React Native mobile app (coming soon)
- **Prototypes** - Native Swift apps (iOS, macOS) and GPUI media viewer for exploration

**Architecture Patterns**

- Event-driven design with centralized EventBus
- CQRS: Actions (mutations) and Queries (reads) with preview-commit-verify
- Durable jobs with MessagePack serialization
- Domain-separated sync with clear data ownership boundaries

---

## Project Structure

```
spacedrive/
‚îú‚îÄ‚îÄ core/              # Rust VDFS implementation
‚îÇ   ‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ domain/    # Core models (Entry, Library, Device, Tag)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ops/       # CQRS operations (actions &amp; queries)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ infra/     # Infrastructure (DB, events, jobs, sync)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service/   # High-level services (network, file sharing)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ location/  # Location management and indexing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ library/   # Library lifecycle and operations
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ volume/    # Volume detection and fingerprinting
‚îú‚îÄ‚îÄ apps/
‚îÇ   ‚îú‚îÄ‚îÄ cli/           # CLI for managing libraries and running daemon
‚îÇ   ‚îú‚îÄ‚îÄ server/        # Headless server daemon
‚îÇ   ‚îú‚îÄ‚îÄ tauri/         # Cross-platform desktop app (macOS, Windows, Linux)
‚îÇ   ‚îú‚îÄ‚îÄ ios/           # Native prototype (private)
‚îÇ   ‚îú‚îÄ‚îÄ macos/         # Native prototype (private)
‚îÇ   ‚îî‚îÄ‚îÄ gpui-photo-grid/  # GPUI media viewer prototype
‚îú‚îÄ‚îÄ extensions/        # WASM extensions
‚îú‚îÄ‚îÄ crates/            # Shared Rust utilities
‚îî‚îÄ‚îÄ docs/              # Architecture documentation
```

---

## Extensions

Spacedrive&#039;s WASM-based extension system enables specialized functionality while maintaining security and portability.

Note: This is a heavy WIP, but will be complete in the first 2.0.0-pre.1 release.

### Professional Extensions

| Extension     | Purpose                         | Key Features                                                                | Status      |
| ------------- | ------------------------------- | --------------------------------------------------------------------------- | ----------- |
| **Photos**    | AI-powered photo management     | Face recognition, place identification, moments, scene classification       | In Progress |
| **Chronicle** | Research &amp; knowledge management | Document analysis, knowledge graphs, AI summaries                           | In Progress |
| **Atlas**     | Dynamic CRM &amp; team knowledge    | Runtime schemas, contact tracking, deal pipelines                           | In Progress |
| **Studio**    | Digital asset management        | Scene detection, transcription, proxy generation                            | Planned     |
| **Ledger**    | Financial intelligence          | Receipt OCR, expense tracking, tax preparation                              | Planned     |
| **Guardian**  | Backup &amp; redundancy monitoring  | Content identity tracking, zero-redundancy alerts, smart backup suggestions | Planned     |
| **Cipher**    | Security &amp; encryption           | Password manager, file encryption, breach alerts                            | Planned     |

### Open Source Archive Extensions

| Extension           | Purpose                 | Provides Data For        | Status  |
| ------------------- | ----------------------- | ------------------------ | ------- |
| **Email Archive**   | Gmail/Outlook backup    | Atlas, Ledger, Chronicle | Planned |
| **Chrome History**  | Browsing history backup | Chronicle                | Planned |
| **Spotify Archive** | Listening history       | Analytics                | Planned |
| **GPS Tracker**     | Location timeline       | Photos, Analytics        | Planned |
| **Tweet Archive**   | Twitter backup          | Chronicle, Analytics     | Planned |
| **GitHub Tracker**  | Repository tracking     | Chronicle                | Planned |

---

## Getting Started

### Prerequisites

- **Rust** 1.81+ ([rustup](https://rustup.rs/))
- **Bun** 1.3+ ([bun.sh](https://bun.sh)) - For Tauri desktop app

### Quick Start with Desktop App (Tauri)

Spacedrive runs as a daemon (`sd-daemon`) that manages your libraries and P2P connections. The Tauri desktop app can launch its own daemon instance, or connect to a daemon started by the CLI.

```bash
# Clone the repository
git clone https://github.com/spacedriveapp/spacedrive
cd spacedrive

# Install dependencies
bun install
cargo run -p xtask -- setup  # generates .cargo/config.toml with aliases
cargo build # builds all core and apps (including the daemon and cli)

# Copy dependencies into the debug Folder ( probably windows only )
Copy-Item -Path &quot;apps\.deps\lib\*.dll&quot; -Destination &quot;target\debug&quot; -ErrorAction SilentlyContinue
Copy-Item -Path &quot;apps\.deps\bin\*.dll&quot; -Destination &quot;target\debug&quot; -ErrorAction SilentlyContinue

# Run the desktop app (automatically starts daemon)
cd apps/tauri
bun run tauri:dev
```

### Quick Start with CLI

The CLI can manage libraries and run a persistent daemon that other apps connect to:

```bash
# Build and run the CLI
cargo run -p sd-cli -- --help

# Start the daemon (runs in background)
cargo run -p sd-cli -- daemon start

# Create a library
cargo run -p sd-cli -- library create &quot;My Library&quot;

# Add a location to index
cargo run -p sd-cli -- location add ~/Documents

# Search indexed files
cargo run -p sd-cli -- search .

# Now launch Tauri app - it will connect to the running daemon
```

### Native Prototypes

Experimental native apps are available in `apps/ios/`, `apps/macos/`, and `apps/gpui-photo-grid/` but are not documented for public use. These prototypes explore platform-specific optimizations and alternative UI approaches.

### Running Tests

Spacedrive has a comprehensive test suite covering single-device operations and multi-device networking scenarios.

```bash
# Run all tests
cargo test --workspace

# Run specific test
cargo test test_device_pairing --nocapture

# Run with detailed logging
RUST_LOG=debug cargo test test_name --nocapture

# Run core tests only
cargo test -p sd-core
```

See the [Testing Guide](https://v2.spacedrive.com/core/testing) for detailed documentation on:

- Integration test framework
- Multi-device subprocess testing
- Event monitoring patterns
- Test helpers and utilities

All integration tests are in `core/tests/` including device pairing, sync, file transfer, and job execution tests.

### Development Commands

```bash
# Run all tests
cargo test

# Run tests for specific package
cargo test -p sd-core

# Build CLI in release mode
cargo build -p sd-cli --release

# Format code
cargo fmt

# Run lints
cargo clippy
```

---

## Privacy &amp; Security

Spacedrive is **local-first**. Your data stays on your devices.

- **End-to-End Encryption**: All P2P traffic encrypted via QUIC/TLS
- **At-Rest Encryption**: Libraries can be encrypted on disk (SQLCipher)
- **No Telemetry**: Zero tracking or analytics in the open source version
- **Self-Hostable**: Run your own relay servers and cloud cores
- **Data Sovereignty**: You control where your data lives

Optional cloud integration (Spacedrive Cloud) is available for backup and remote access, but it&#039;s never required. The cloud service runs unmodified Spacedrive core as a standard P2P device‚Äîno special privileges, no custom APIs.

---

## Documentation

- **[v2 Documentation](https://v2.spacedrive.com)** - Complete guides and API reference
- **[Whitepaper](whitepaper/spacedrive.pdf)** - Technical architecture (work in progress)
- **[Contributing Guide](CONTRIBUTING.md)** - How to contribute
- **[Architecture Docs](docs/core/architecture.md)** - Detailed system design
- **[Extension SDK](docs/sdk.md)** - Build your own extensions

---

## Get Involved

- **Star the repo** to support the project
- **Join [Discord](https://discord.gg/gTaF2Z44f5)** to chat with developers and community
- **Read the [v2 Documentation](https://v2.spacedrive.com)** for guides and API reference
- **Read the [Whitepaper](whitepaper/spacedrive.pdf)** for the full technical vision
- **Build an Extension** - Check out the [SDK docs](docs/sdk.md)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[apache/datafusion]]></title>
            <link>https://github.com/apache/datafusion</link>
            <guid>https://github.com/apache/datafusion</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[Apache DataFusion SQL Query Engine]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/apache/datafusion">apache/datafusion</a></h1>
            <p>Apache DataFusion SQL Query Engine</p>
            <p>Language: Rust</p>
            <p>Stars: 8,191</p>
            <p>Forks: 1,836</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;!---
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  &quot;License&quot;); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing,
  software distributed under the License is distributed on an
  &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  KIND, either express or implied.  See the License for the
  specific language governing permissions and limitations
  under the License.
--&gt;

# Apache DataFusion

[![Crates.io][crates-badge]][crates-url]
[![Apache licensed][license-badge]][license-url]
[![Build Status][actions-badge]][actions-url]
![Commit Activity][commit-activity-badge]
[![Open Issues][open-issues-badge]][open-issues-url]
[![Pending PRs][pending-pr-badge]][pending-pr-url]
[![Discord chat][discord-badge]][discord-url]
[![Linkedin][linkedin-badge]][linkedin-url]
![Crates.io MSRV][msrv-badge]

[crates-badge]: https://img.shields.io/crates/v/datafusion.svg
[crates-url]: https://crates.io/crates/datafusion
[license-badge]: https://img.shields.io/badge/license-Apache%20v2-blue.svg
[license-url]: https://github.com/apache/datafusion/blob/main/LICENSE.txt
[actions-badge]: https://github.com/apache/datafusion/actions/workflows/rust.yml/badge.svg
[actions-url]: https://github.com/apache/datafusion/actions?query=branch%3Amain
[discord-badge]: https://img.shields.io/badge/Chat-Discord-purple
[discord-url]: https://discord.com/invite/Qw5gKqHxUM
[commit-activity-badge]: https://img.shields.io/github/commit-activity/m/apache/datafusion
[open-issues-badge]: https://img.shields.io/github/issues-raw/apache/datafusion
[open-issues-url]: https://github.com/apache/datafusion/issues
[pending-pr-badge]: https://img.shields.io/github/issues-search/apache/datafusion?query=is%3Apr+is%3Aopen+draft%3Afalse+review%3Arequired+status%3Asuccess&amp;label=Pending%20PRs&amp;logo=github
[pending-pr-url]: https://github.com/apache/datafusion/pulls?q=is%3Apr+is%3Aopen+draft%3Afalse+review%3Arequired+status%3Asuccess+sort%3Aupdated-desc
[linkedin-badge]: https://img.shields.io/badge/Follow-Linkedin-blue
[linkedin-url]: https://www.linkedin.com/company/apache-datafusion/
[msrv-badge]: https://img.shields.io/crates/msrv/datafusion?label=Min%20Rust%20Version

[Website](https://datafusion.apache.org/) |
[API Docs](https://docs.rs/datafusion/latest/datafusion/) |
[Chat](https://discord.com/channels/885562378132000778/885562378132000781)

&lt;a href=&quot;https://datafusion.apache.org/&quot;&gt;
  &lt;img src=&quot;https://github.com/apache/datafusion/raw/HEAD/docs/source/_static/images/2x_bgwhite_original.png&quot; width=&quot;512&quot; alt=&quot;logo&quot;/&gt;
&lt;/a&gt;

DataFusion is an extensible query engine written in [Rust] that
uses [Apache Arrow] as its in-memory format.

This crate provides libraries and binaries for developers building fast and
feature rich database and analytic systems, customized to particular workloads.
See [use cases] for examples. The following related subprojects target end users:

- [DataFusion Python](https://github.com/apache/datafusion-python/) offers a Python interface for SQL and DataFrame
  queries.
- [DataFusion Comet](https://github.com/apache/datafusion-comet/) is an accelerator for Apache Spark based on
  DataFusion.

&quot;Out of the box,&quot;
DataFusion offers [SQL](https://datafusion.apache.org/user-guide/sql/index.html) and [Dataframe](https://datafusion.apache.org/user-guide/dataframe.html) APIs, excellent [performance],
built-in support for CSV, Parquet, JSON, and Avro, extensive customization, and
a great community.

DataFusion features a full query planner, a columnar, streaming, multi-threaded,
vectorized execution engine, and partitioned data sources. You can
customize DataFusion at almost all points including additional data sources,
query languages, functions, custom operators and more.
See the [Architecture] section for more details.

[rust]: http://rustlang.org
[apache arrow]: https://arrow.apache.org
[use cases]: https://datafusion.apache.org/user-guide/introduction.html#use-cases
[python bindings]: https://github.com/apache/datafusion-python
[performance]: https://benchmark.clickhouse.com/
[architecture]: https://datafusion.apache.org/contributor-guide/architecture.html

Here are links to some important information

- [Project Site](https://datafusion.apache.org/)
- [Installation](https://datafusion.apache.org/user-guide/cli/installation.html)
- [Rust Getting Started](https://datafusion.apache.org/user-guide/example-usage.html)
- [Rust DataFrame API](https://datafusion.apache.org/user-guide/dataframe.html)
- [Rust API docs](https://docs.rs/datafusion/latest/datafusion)
- [Rust Examples](https://github.com/apache/datafusion/tree/main/datafusion-examples)
- [Python DataFrame API](https://arrow.apache.org/datafusion-python/)
- [Architecture](https://docs.rs/datafusion/latest/datafusion/index.html#architecture)

## What can you do with this crate?

DataFusion is great for building projects such as domain specific query engines, new database platforms and data pipelines, query languages and more.
It lets you start quickly from a fully working engine, and then customize those features specific to your use. [Click Here](https://datafusion.apache.org/user-guide/introduction.html#known-users) to see a list known users.

## Contributing to DataFusion

Please see the [contributor guide] and [communication] pages for more information.

[contributor guide]: https://datafusion.apache.org/contributor-guide
[communication]: https://datafusion.apache.org/contributor-guide/communication.html

## Crate features

This crate has several [features] which can be specified in your `Cargo.toml`.

[features]: https://doc.rust-lang.org/cargo/reference/features.html

Default features:

- `nested_expressions`: functions for working with nested type function such as `array_to_string`
- `compression`: reading files compressed with `xz2`, `bzip2`, `flate2`, and `zstd`
- `crypto_expressions`: cryptographic functions such as `md5` and `sha256`
- `datetime_expressions`: date and time functions such as `to_timestamp`
- `encoding_expressions`: `encode` and `decode` functions
- `parquet`: support for reading the [Apache Parquet] format
- `sql`: Support for sql parsing / planning
- `regex_expressions`: regular expression functions, such as `regexp_match`
- `unicode_expressions`: Include unicode aware functions such as `character_length`
- `unparser`: enables support to reverse LogicalPlans back into SQL
- `recursive_protection`: uses [recursive](https://docs.rs/recursive/latest/recursive/) for stack overflow protection.

Optional features:

- `avro`: support for reading the [Apache Avro] format
- `backtrace`: include backtrace information in error messages
- `parquet_encryption`: support for using [Parquet Modular Encryption]
- `serde`: enable arrow-schema&#039;s `serde` feature

[apache avro]: https://avro.apache.org/
[apache parquet]: https://parquet.apache.org/
[parquet modular encryption]: https://parquet.apache.org/docs/file-format/data-pages/encryption/

## DataFusion API Evolution and Deprecation Guidelines

Public methods in Apache DataFusion evolve over time: while we try to maintain a
stable API, we also improve the API over time. As a result, we typically
deprecate methods before removing them, according to the [deprecation guidelines].

[deprecation guidelines]: https://datafusion.apache.org/contributor-guide/api-health.html

## Dependencies and `Cargo.lock`

Following the [guidance] on committing `Cargo.lock` files, this project commits
its `Cargo.lock` file.

CI uses the committed `Cargo.lock` file, and dependencies are updated regularly
using [Dependabot] PRs.

[guidance]: https://blog.rust-lang.org/2023/08/29/committing-lockfiles.html
[dependabot]: https://docs.github.com/en/code-security/dependabot/working-with-dependabot
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[UwUDev/ygege]]></title>
            <link>https://github.com/UwUDev/ygege</link>
            <guid>https://github.com/UwUDev/ygege</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[High-performance indexer for YGG Torrent written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/UwUDev/ygege">UwUDev/ygege</a></h1>
            <p>High-performance indexer for YGG Torrent written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 219</p>
            <p>Forks: 19</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;website/img/ygege-logo-text.png&quot; alt=&quot;Logo Yg√©g√©&quot; width=&quot;400&quot;/&gt;
&lt;/p&gt;

&lt;div align=&quot;right&quot;&gt;
  &lt;details&gt;
    &lt;summary&gt;üåê Language&lt;/summary&gt;
    &lt;div&gt;
      &lt;div align=&quot;center&quot;&gt;
        &lt;a href=&quot;README.md&quot;&gt;Fran√ßais&lt;/a&gt;
        | &lt;a href=&quot;README-en.md&quot;&gt;English&lt;/a&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/details&gt;
&lt;/div&gt;

Indexeur haute performance pour YGG Torrent √©crit en Rust 

## https://discord.gg/rcsgdzNrvJ

&lt;!--
&gt; [!CAUTION]
&gt; Suite a la nouvelle mise en place de la limite de 5 torrents gratuits par jour sur YGG Torrent, Yg√©g√© n&#039;est plus en mesure de fonctionner correctement. Je travaille actuellement sur une solution pour contourner cette limitation. Votre aide est possible meme si vous ne savez pas coder en Rust ni coder du tout. N&#039;hesitez pas a aller voir le discord pour plus d&#039;infos: https://discord.gg/rcsgdzNrvJ
&gt;
&gt; Edit: Ils ont patch√©s les 2 bypass et forcent le captcha turnstile... Merci de ne plus cr√©er d&#039;isssues a ce sujet (erreur 403)
--&gt;

**Caract√©ristiques principales** :
- R√©solution automatique du domaine actuel de YGG Torrent
- Bypass Cloudflare automatis√© (sans r√©solution manuelle)
- Recherche quasi instantan√©e
- Reconnexion transparente aux sessions expir√©es
- Caching des sessions
- Contournement des DNS menteurs
- Consommation m√©moire faible (14.7Mo en mode release sur Linux)
- Recherche de torrents tr√®s modulaire (par nom, seed, leech, commentaires, date de publication, etc.)
- Recuperation des informations compl√©mentaires sur les torrents (description, taille, nombre de seeders, leechers, etc.)
- Pas de d√©pendances externes
- Pas de drivers de navigateur

## Pr√©requis pour la compilation
- Rust 1.85.0+
- OpenSSL 3+
- Toutes les d√©pendances requises pour la compilation de [wreq](https://crates.io/crates/wreq)

# Installation

Une image Docker pr√™te √† l&#039;emploi est disponible pour Yg√©g√©.
Pour commencer le d√©ploiement et la configuration de Docker, consultez le [Guide d√©di√© √† Docker](https://ygege.lila.ws/installation/docker-guide).

## Docker

Pour cr√©er une image Docker personnalis√©e avec vos propres optimisations, consultez le [Guide de cr√©ation Docker](https://ygege.lila.ws/installation/docker-guide).

## Installation manuelle

Pour compiler l&#039;application √† partir des sources, suivez le [Guide d&#039;installation manuel](https://ygege.lila.ws/installation/source-guide).

Pour les fans de Docker, n&#039;h√©sitez pas √† contribuer au projet en m&#039;aidant √† cr√©er une image Docker.

## Configuration IMDB et TMDB

Pour activer la r√©cup√©ration des m√©tadonn√©es IMDB et TMDB, veuillez suivre les instructions du [guide d&#039;assistance TMDB et IMDB](https://ygege.lila.ws/tmdb-imdb).

## Int√©gration √† Prowlarr

Yg√©g√© peut √™tre utilis√© comme indexeur personnalis√© pour Prowlarr. Pour le mettre en place, trouvez votre r√©pertoire AppData (situ√© dans la page `/system/status` de Prowlarr) et copiez le fichier `ygege.yml` du repo dans le dossier `{votre chemin appdata prowlarr}/Definitions/Custom`, vous aurez probablement besoin de cr√©er le dossier `Custom`.

Une fois que c&#039;est fait, red√©marrez Prowlarr et allez dans les param√®tres des indexeurs, vous devriez voir Yg√©g√© dans la liste des indexeurs disponibles.

&gt; [!NOTE]
&gt; Prowlarr ne permet pas de personnaliser le &quot;Base URL&quot;. Par d√©faut, utilisez `http://localhost:8715/`. Pour les configurations Docker Compose, utilisez `http://ygege:8715/`. Alternativement, utilisez ygege-dns-redirect.local avec un DNS personnalis√© ou en √©ditant le fichier hosts.

## Int√©gration √† Jackett

Yg√©g√© peut √™tre utilis√© comme indexeur personnalis√© pour Jackett. Pour le mettre en place, localisez votre r√©pertoire AppData Jackett et copiez le fichier `ygege.yml` du d√©p√¥t dans le dossier `{votre chemin appdata jackett}/cardigann/definitions/`. Vous devrez peut-√™tre cr√©er le sous-dossier `cardigann/definitions/` s&#039;il n&#039;existe pas.

&gt; [!NOTE]
&gt; L&#039;image Docker LinuxServer Jackett fournit une structure de dossiers bien organis√©e. Si vous utilisez une autre image Docker, adaptez les chemins en cons√©quence.

Une fois termin√©, red√©marrez Jackett et acc√©dez aux param√®tres des indexeurs. Vous devriez voir Yg√©g√© dans la liste des indexeurs disponibles.

## Contournement Cloudflare
Pour contourner le d√©fi de Cloudflare, Yg√©g√© n&#039;utilise pas de navigateur ni de services tiers.

Une r√®gle Cloudflare est appliqu√©e sur le site YGG Torrent pour emp√™cher l&#039;apparition du challenge Cloudflare via le cookie `account_created=true` cens√© garantir que l&#039;utilisateur a un compte valide et est connect√©.

Mais ce n&#039;est pas si simple, Cloudflare vous surveille toujours et d√©tecte les faux clients HTTPS et les faux navigateurs.

Pour contourner cela, Yg√©g√© utilise la librairie [wreq](https://crates.io/crates/wreq) qui est un client HTTP bas√© sur `reqwest` et `tokio` permettant de reproduire 1:1 l&#039;√©change TLS et HTTP/2 avec le serveur afin de simuler un vrai navigateur.

J&#039;ai aussi remarqu√© que cela ne passait plus √† partir de Chrome 133, s√ªrement √† cause de l&#039;integration de HTTP/3 dans Chrome qui n&#039;est pas encore simul√©e par `wreq`.

Je recommande aux curieux [cet article](https://fingerprint.com/blog/what-is-tls-fingerprinting-transport-layer-security/) qui explique comment fonctionne le fingerprinting TLS et [cet autre article](https://www.trickster.dev/post/understanding-http2-fingerprinting/) qui explique comment fonctionne le fingerprinting HTTP/2 et comment il est possible de le contourner.

## Test de performance

Query pour la recherche:
- Nom: `Vaiana 2`
- Tri: `seeders`
- Ordre: `descendant`

|                                     | Nombre de tests | Temps total de tous les tests | Temps moyen par test |
|-------------------------------------|-----------------|-------------------------------|----------------------|
| R√©solution du domaine actuel de YGG |        25       |           3220,378ms          |      128,81512ms     |
| Nouvelle connection YGG             |        10       |          4881.71361ms         |     488.1713616ms    |
| Restoration de session YGG          |        10       |         2064.672142ms         |     206.4672142ms    |
| Recherche                           |       100       |         17621.045874ms        |    176,21045874ms    |

# Documentation

## Documentation utilisateur

La documentation compl√®te est disponible sur [ygege.lila.ws](https://ygege.lila.ws) :
- [Guide de d√©marrage](https://ygege.lila.ws/getting-started)
- [Installation](https://ygege.lila.ws/installation/docker-guide)
- [Configuration](https://ygege.lila.ws/configuration)
- [Int√©grations (Prowlarr/Jackett)](https://ygege.lila.ws/integrations/prowlarr)
- [Documentation de l&#039;API](https://ygege.lila.ws/api)
- [FAQ](https://ygege.lila.ws/faq)

## Documentation d√©veloppeur

Pour contribuer au projet ou comprendre le fonctionnement interne :
- [Guide de contribution](docs/contribution-fr.md)
- [Pipeline CI/CD](docs/ci_implementation-fr.md)
- [Workflow de preview des PRs](docs/preview_workflow-fr.md)
- [Workflow de release](docs/release_workflow-fr.md)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[oxc-project/oxc]]></title>
            <link>https://github.com/oxc-project/oxc</link>
            <guid>https://github.com/oxc-project/oxc</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[‚öì A collection of high-performance JavaScript tools.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oxc-project/oxc">oxc-project/oxc</a></h1>
            <p>‚öì A collection of high-performance JavaScript tools.</p>
            <p>Language: Rust</p>
            <p>Stars: 17,994</p>
            <p>Forks: 755</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;OXC Logo&quot; src=&quot;https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/preview-universal.png&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![MIT licensed][license-badge]][license-url]
[![Build Status][ci-badge]][ci-url]
[![Code Coverage][code-coverage-badge]][code-coverage-url]
[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/oxc-project/oxc)
[![Sponsors][sponsors-badge]][sponsors-url]

[![Discord chat][discord-badge]][discord-url]
[![Playground][playground-badge]][playground-url]
[![Website][website-badge]][website-url]

&lt;/div&gt;

## ‚öì Oxc

_/o ä …õks siÀê/_

The Oxidation Compiler is a collection of high-performance tools for JavaScript and TypeScript written in Rust.

Oxc is part of [VoidZero](https://voidzero.dev/)&#039;s vision for a unified, high-performance toolchain for JavaScript. It powers [Rolldown](https://rolldown.rs) ([Vite]&#039;s future bundler) and enables the next generation of ultra-fast development tools that work seamlessly together.

For more information, check out our website at [oxc.rs](https://oxc.rs).

&lt;sub&gt;\* Oxidation is the chemical process that creates rust&lt;/sub&gt;

## üèóÔ∏è Design Principles

- **Performance**: Through rigorous performance engineering.
- **Correctness**: Through conformance testing to standards and similar projects.
- **Developer Experience**: Clear APIs, comprehensive documentation, and sensible configuration.
- **Modular composability**: Use individual components independently or compose them into complete toolchains.

Read more about our [architecture](https://oxc.rs/docs/learn/architecture/parser.html) and [performance philosophy](https://oxc.rs/docs/learn/performance).

## üì¶ Tools &amp; Packages

| Tool        | npm                                                          | crates.io                                                   |
| ----------- | ------------------------------------------------------------ | ----------------------------------------------------------- |
| Linter      | [oxlint](https://www.npmjs.com/package/oxlint)               | -                                                           |
| Formatter   | [oxfmt](https://www.npmjs.com/package/oxfmt)                 | -                                                           |
| Parser      | [oxc-parser](https://www.npmjs.com/package/oxc-parser)       | [oxc_parser](https://crates.io/crates/oxc_parser)           |
| Transformer | [oxc-transform](https://www.npmjs.com/package/oxc-transform) | [oxc_transformer](https://crates.io/crates/oxc_transformer) |
| Minifier    | [oxc-minify](https://www.npmjs.com/package/oxc-minify)       | [oxc_minifier](https://crates.io/crates/oxc_minifier)       |
| Resolver    | [oxc-resolver](https://www.npmjs.com/package/oxc-resolver)   | [oxc_resolver](https://crates.io/crates/oxc_resolver)       |

See [documentation](https://oxc.rs/) for detailed usage guides for each tool.

## ‚ö°Ô∏è Quick Start

### Linter

The production-ready linter catches mistakes for you with sensible defaults and optional configuration:

```bash
npx oxlint@latest
```

To give you an idea of its capabilities, here is an example from the [vscode] repository, which finishes linting 4800+ files in 0.7 seconds:

&lt;p float=&quot;left&quot; align=&quot;left&quot;&gt;
  &lt;img src=&quot;https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/linter-screenshot.png&quot; width=&quot;60%&quot;&gt;
&lt;/p&gt;

‚Üí [oxlint documentation](https://oxc.rs/docs/guide/usage/linter/cli.html)

### Formatter

Fast, opinionated code formatter compatible with [Prettier]:

```bash
npx oxfmt@latest
```

‚Üí [Formatter documentation](https://oxc.rs/docs/guide/usage/formatter)

### Parser (Node.js)

The fastest JavaScript/TypeScript parser written in Rust:

```bash
npm install oxc-parser
```

```js
import { parseSync } from &#039;oxc-parser&#039;;
const result = parseSync(&#039;const x = 1;&#039;);
```

‚Üí [Parser documentation](https://oxc.rs/docs/guide/usage/parser)

### Transformer (Node.js)

TypeScript, React, and modern JavaScript transformation:

```bash
npm install oxc-transform
```

```js
import { transform } from &#039;oxc-transform&#039;;
const result = transform(&#039;source.tsx&#039;, code, { typescript: true });
```

‚Üí [Transformer documentation](https://oxc.rs/docs/guide/usage/transformer)

### Minifier (Node.js)

High-performance JavaScript minifier:

```bash
npm install oxc-minify
```

```js
import { minify } from &#039;oxc-minify&#039;;
const result = minify(code, { mangle: true });
```

‚Üí [Minifier documentation](https://oxc.rs/docs/guide/usage/minifier)

### Rust

Individual crates are published for building your own JavaScript tools:

```toml
[dependencies]
oxc = &quot;0.x&quot;
```

‚Üí [Rust documentation](https://docs.rs/oxc)

## VoidZero Inc.

Oxc is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/blog).

If you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!

## üôã Who&#039;s using Oxc?

[Rolldown] and [Nuxt] use Oxc for parsing. [Rolldown] also uses Oxc for transformation and minification. [Nova], [swc-node], and [knip] use [oxc_resolver][docs-resolver-url] for module resolution. [Preact], [Shopify], [ByteDance], and [Shopee] use oxlint for linting.

[See more projects using Oxc ‚Üí](https://oxc.rs/docs/guide/projects.html)

## ‚úçÔ∏è Contribute

Check out some of the [good first issues](https://github.com/oxc-project/oxc/contribute) or ask us on [Discord][discord-url].

See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidance, or read the complete [contributing guide on our website ‚Üí](https://oxc.rs/docs/contribute/introduction.html)

If you are unable to contribute by code, you can still participate by:

- Add a [GitHub Star](https://github.com/oxc-project/oxc/stargazers) to the project
- Join us on [Discord][discord-url]
- [Follow me on X](https://x.com/boshen_c) and post about this project

## ü§ù Credits

This project was incubated with the assistance of these exceptional mentors and their projects:

- [Biome][biome] - [@ematipico](https://github.com/ematipico)
- [Ruff][ruff] - [@charliermarsh](https://github.com/charliermarsh), [@MichaReiser](https://github.com/MichaReiser)
- [quick-lint-js](https://github.com/quick-lint/quick-lint-js) - [@strager](https://github.com/strager)
- [elm-review](https://package.elm-lang.org/packages/jfmengels/elm-review/latest) - [@jfmengels](https://github.com/jfmengels)

Special thanks go to:

- [@domonji](https://github.com/domonji) for bootstrapping this project together and also completing the TypeScript parser
- [@tongtong-lu](https://github.com/tongtong-lu) and [@guan-wy](https://github.com/guan-wy) for designing the [project logo](https://github.com/oxc-project/oxc-assets)

## ‚ù§ Who&#039;s [Sponsoring Oxc](https://github.com/sponsors/Boshen)?

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/sponsors/Boshen&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/Boshen/sponsors/main/sponsors.svg&quot; alt=&quot;My sponsors&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## üìñ License

Oxc is free and open-source software licensed under the [MIT License](./LICENSE).

Oxc ports or copies code from other open source projects, their licenses are listed in [**Third-party library licenses**](./THIRD-PARTY-LICENSE).

[discord-badge]: https://img.shields.io/discord/1079625926024900739?logo=discord&amp;label=Discord
[discord-url]: https://discord.gg/9uXCAwqQZW
[license-badge]: https://img.shields.io/badge/license-MIT-blue.svg
[license-url]: https://github.com/oxc-project/oxc/blob/main/LICENSE
[ci-badge]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml/badge.svg?event=push&amp;branch=main
[ci-url]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml?query=event%3Apush+branch%3Amain
[code-coverage-badge]: https://codecov.io/gh/oxc-project/oxc/graph/badge.svg?token=FVHEH0BQLJ
[code-coverage-url]: https://codecov.io/gh/oxc-project/oxc
[sponsors-badge]: https://img.shields.io/github/sponsors/Boshen
[sponsors-url]: https://github.com/sponsors/Boshen
[playground-badge]: https://img.shields.io/badge/Playground-blue?color=9BE4E0
[playground-url]: https://playground.oxc.rs/
[website-badge]: https://img.shields.io/badge/Website-blue
[website-url]: https://oxc.rs
[docs-resolver-url]: https://docs.rs/oxc_resolver
[biome]: https://biomejs.dev/
[ruff]: https://beta.ruff.rs
[vscode]: https://github.com/microsoft/vscode
[rolldown]: https://rolldown.rs
[vite]: https://vitejs.dev/
[nuxt]: https://nuxt.com/
[nova]: https://trynova.dev/
[swc-node]: https://github.com/swc-project/swc-node
[knip]: https://github.com/webpro/knip
[preact]: https://preactjs.com/
[shopify]: https://shopify.com/
[bytedance]: https://www.bytedance.com/
[shopee]: https://shopee.com/
[prettier]: https://prettier.io/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[librespot-org/librespot]]></title>
            <link>https://github.com/librespot-org/librespot</link>
            <guid>https://github.com/librespot-org/librespot</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[Open Source Spotify client library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/librespot-org/librespot">librespot-org/librespot</a></h1>
            <p>Open Source Spotify client library</p>
            <p>Language: Rust</p>
            <p>Stars: 6,473</p>
            <p>Forks: 788</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>[![Build Status](https://github.com/librespot-org/librespot/workflows/build/badge.svg)](https://github.com/librespot-org/librespot/actions)
[![Gitter chat](https://badges.gitter.im/librespot-org/librespot.png)](https://gitter.im/librespot-org/spotify-connect-resources)
[![Crates.io](https://img.shields.io/crates/v/librespot.svg)](https://crates.io/crates/librespot)

Current maintainers are [listed on GitHub](https://github.com/orgs/librespot-org/people).

# librespot
*librespot* is an open source client library for Spotify. It enables applications to use Spotify&#039;s service to control and play music via various backends, and to act as a Spotify Connect receiver. It is an alternative to the official and [now deprecated](https://pyspotify.mopidy.com/en/latest/#libspotify-s-deprecation) closed-source `libspotify`. Additionally, it will provide extra features which are not available in the official library.

_Note: librespot only works with Spotify Premium. This will remain the case. We will not support any features to make librespot compatible with free accounts, such as limited skips and adverts._

## Quick start
We&#039;re available on [crates.io](https://crates.io/crates/librespot) as the _librespot_ package. Simply run `cargo install librespot` to install librespot on your system. Check the wiki for more info and possible [usage options](https://github.com/librespot-org/librespot/wiki/Options).

After installation, you can run librespot from the CLI using a command such as `librespot -n &quot;Librespot Speaker&quot; -b 160` to create a speaker called _Librespot Speaker_ serving 160 kbps audio.

## This fork
As the origin by [plietar](https://github.com/plietar/) is no longer actively maintained, this organisation and repository have been set up so that the project may be maintained and upgraded in the future.

# Documentation
Documentation is currently a work in progress, contributions are welcome!

There is some brief documentation on how the protocol works in the [docs](https://github.com/librespot-org/librespot/tree/master/docs) folder.

[COMPILING.md](https://github.com/librespot-org/librespot/blob/master/COMPILING.md) contains detailed instructions on setting up a development environment, and compiling librespot. More general usage and compilation information is available on the [wiki](https://github.com/librespot-org/librespot/wiki).
[CONTRIBUTING.md](https://github.com/librespot-org/librespot/blob/master/CONTRIBUTING.md) also contains our contributing guidelines.

If you wish to learn more about how librespot works overall, the best way is to simply read the code, and ask any questions you have in our [Gitter Room](https://gitter.im/librespot-org/spotify-connect-resources).

# Issues &amp; Discussions
**We have recently started using Github discussions for general questions and feature requests, as they are a more natural medium for such cases, and allow for upvoting to prioritize feature development. Check them out [here](https://github.com/librespot-org/librespot/discussions). Bugs and issues with the underlying library should still be reported as issues.**

If you run into a bug when using librespot, please search the existing issues before opening a new one. Chances are, we&#039;ve encountered it before, and have provided a resolution. If not, please open a new one, and where possible, include the backtrace librespot generates on crashing, along with anything we can use to reproduce the issue, e.g. the Spotify URI of the song that caused the crash.

# Building
A quick walkthrough of the build process is outlined below, while a detailed compilation guide can be found [here](https://github.com/librespot-org/librespot/blob/master/COMPILING.md).

## Additional Dependencies
We recently switched to using [Rodio](https://github.com/tomaka/rodio) for audio playback by default, hence for macOS and Windows, you should just be able to clone and build librespot (with the command below).
For Linux, you will need to run the additional commands below, depending on your distro.

On Debian/Ubuntu, the following command will install these dependencies:
```shell
sudo apt-get install build-essential libasound2-dev
```

On Fedora systems, the following command will install these dependencies:
```shell
sudo dnf install alsa-lib-devel make gcc
```

librespot currently offers the following selection of [audio backends](https://github.com/librespot-org/librespot/wiki/Audio-Backends):
```
Rodio (default)
ALSA
GStreamer
PortAudio
PulseAudio
JACK
JACK over Rodio
SDL
Pipe
Subprocess
```
Please check [COMPILING.md](COMPILING.md) for detailed information on TLS, audio, and discovery backend dependencies, or the [Compiling](https://github.com/librespot-org/librespot/wiki/Compiling#general-dependencies) entry on the wiki for additional backend specific dependencies.

Once you&#039;ve installed the dependencies and cloned this repository you can build *librespot* with the default features using Cargo.
```shell
cargo build --release
```

By default, this builds with native-tls (system TLS), rodio audio backend, and libmdns discovery. See [COMPILING.md](COMPILING.md) for information on selecting different TLS, audio, and discovery backends.

# Packages

librespot is also available via official package system on various operating systems such as Linux, FreeBSD, NetBSD. [Repology](https://repology.org/project/librespot/versions) offers a good overview.

[![Packaging status](https://repology.org/badge/vertical-allrepos/librespot.svg)](https://repology.org/project/librespot/versions)

## Usage
A sample program implementing a headless Spotify Connect receiver is provided.
Once you&#039;ve built *librespot*, run it using :
```shell
target/release/librespot --name DEVICENAME
```

The above is a minimal example. Here is a more fully fledged one:
```shell
target/release/librespot -n &quot;Librespot&quot; -b 320 -c ./cache --enable-volume-normalisation --initial-volume 75 --device-type avr
```
The above command will create a receiver named ```Librespot```, with bitrate set to 320 kbps, initial volume at 75%, with volume normalisation enabled, and the device displayed in the app as an Audio/Video Receiver. A folder named ```cache``` will be created/used in the current directory, and be used to cache audio data and credentials.

A full list of runtime options is available [here](https://github.com/librespot-org/librespot/wiki/Options).

_Please Note: When using the cache feature, an authentication blob is stored for your account in the cache directory. For security purposes, we recommend that you set directory permissions on the cache directory to `700`._

## Contact
Come and hang out on gitter if you need help or want to offer some:
https://gitter.im/librespot-org/spotify-connect-resources

## Disclaimer
Using this code to connect to Spotify&#039;s API is probably forbidden by them.
Use at your own risk.

## License
Everything in this repository is licensed under the MIT license.

## Related Projects
This is a non exhaustive list of projects that either use or have modified librespot. If you&#039;d like to include yours, submit a PR.

- [librespot-golang](https://github.com/librespot-org/librespot-golang) - A golang port of librespot.
- [plugin.audio.spotify](https://github.com/marcelveldt/plugin.audio.spotify) - A Kodi plugin for Spotify.
- [raspotify](https://github.com/dtcooper/raspotify) - A Spotify Connect client that mostly Just Works‚Ñ¢
- [Spotifyd](https://github.com/Spotifyd/spotifyd) - A stripped down librespot UNIX daemon.
- [rpi-audio-receiver](https://github.com/nicokaiser/rpi-audio-receiver) - easy Raspbian install scripts for Spotifyd, Bluetooth, Shairport and other audio receivers
- [Spotcontrol](https://github.com/badfortrains/spotcontrol) - A golang implementation of a Spotify Connect controller. No Playback functionality.
- [librespot-java](https://github.com/devgianlu/librespot-java) - A Java port of librespot.
- [ncspot](https://github.com/hrkfdn/ncspot) - Cross-platform ncurses Spotify client.
- [ansible-role-librespot](https://github.com/xMordax/ansible-role-librespot/tree/master) - Ansible role that will build, install and configure Librespot.
- [Spot](https://github.com/xou816/spot) - Gtk/Rust native Spotify client for the GNOME desktop.
- [Snapcast](https://github.com/badaix/snapcast) - synchronised multi-room audio player that uses librespot as its source for Spotify content
- [MuPiBox](https://mupibox.de/) - Portable music box for Spotify and local media based on Raspberry Pi. Operated via touchscreen. Suitable for children and older people.
- [RoPieee](https://ropieee.org) - An easy-to-use Raspberry Pi image for network audio streaming solutions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nushell/nushell]]></title>
            <link>https://github.com/nushell/nushell</link>
            <guid>https://github.com/nushell/nushell</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[A new type of shell]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nushell/nushell">nushell/nushell</a></h1>
            <p>A new type of shell</p>
            <p>Language: Rust</p>
            <p>Stars: 37,619</p>
            <p>Forks: 1,986</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># Nushell &lt;!-- omit in toc --&gt;
[![Crates.io](https://img.shields.io/crates/v/nu.svg)](https://crates.io/crates/nu)
[![Build Status](https://img.shields.io/github/actions/workflow/status/nushell/nushell/ci.yml?branch=main)](https://github.com/nushell/nushell/actions)
[![Nightly Build](https://github.com/nushell/nushell/actions/workflows/nightly-build.yml/badge.svg)](https://github.com/nushell/nushell/actions/workflows/nightly-build.yml)
[![Discord](https://img.shields.io/discord/601130461678272522.svg?logo=discord)](https://discord.gg/NtAbbGn)
[![The Changelog #363](https://img.shields.io/badge/The%20Changelog-%23363-61c192.svg)](https://changelog.com/podcast/363)
[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/nushell/nushell)](https://github.com/nushell/nushell/graphs/commit-activity)
[![GitHub contributors](https://img.shields.io/github/contributors/nushell/nushell)](https://github.com/nushell/nushell/graphs/contributors)

A new type of shell.

![Example of nushell](assets/nushell-autocomplete6.gif &quot;Example of nushell&quot;)

## Table of Contents &lt;!-- omit in toc --&gt;

- [Status](#status)
- [Learning About Nu](#learning-about-nu)
- [Installation](#installation)
- [Configuration](#configuration)
- [Philosophy](#philosophy)
  - [Pipelines](#pipelines)
  - [Opening files](#opening-files)
  - [Plugins](#plugins)
- [Goals](#goals)
- [Officially Supported By](#officially-supported-by)
- [Contributing](#contributing)
- [License](#license)

## Status

This project has reached a minimum-viable-product level of quality. Many people use it as their daily driver, but it may be unstable for some commands. Nu&#039;s design is subject to change as it matures.

## Learning About Nu

The [Nushell book](https://www.nushell.sh/book/) is the primary source of Nushell documentation. You can find [a full list of Nu commands in the book](https://www.nushell.sh/commands/), and we have many examples of using Nu in our [cookbook](https://www.nushell.sh/cookbook/).

We&#039;re also active on [Discord](https://discord.gg/NtAbbGn); come and chat with us!

## Installation

To quickly install Nu:

```bash
# Linux and macOS
brew install nushell
# Windows
winget install nushell
```

To use `Nu` in GitHub Action, check [setup-nu](https://github.com/marketplace/actions/setup-nu) for more detail.

Detailed installation instructions can be found in the [installation chapter of the book](https://www.nushell.sh/book/installation.html). Nu is available via many package managers:

[![Packaging status](https://repology.org/badge/vertical-allrepos/nushell.svg?columns=3)](https://repology.org/project/nushell/versions)

For details about which platforms the Nushell team actively supports, see [our platform support policy](devdocs/PLATFORM_SUPPORT.md).

## Configuration

The default configurations can be found at [sample_config](crates/nu-utils/src/default_files)
which are the configuration files one gets when they startup Nushell for the first time.

It sets all of the default configuration to run Nushell.  From here one can
then customize this file for their specific needs.

To see where *config.nu* is located on your system simply type this command.

```rust
$nu.config-path
```

Please see our [book](https://www.nushell.sh) for all of the Nushell documentation.


## Philosophy

Nu draws inspiration from projects like PowerShell, functional programming languages, and modern CLI tools.
Rather than thinking of files and data as raw streams of text, Nu looks at each input as something with structure.
For example, when you list the contents of a directory what you get back is a table of rows, where each row represents an item in that directory.
These values can be piped through a series of steps, in a series of commands called a &#039;pipeline&#039;.

### Pipelines

In Unix, it&#039;s common to pipe between commands to split up a sophisticated command over multiple steps.
Nu takes this a step further and builds heavily on the idea of _pipelines_.
As in the Unix philosophy, Nu allows commands to output to stdout and read from stdin.
Additionally, commands can output structured data (you can think of this as a third kind of stream).
Commands that work in the pipeline fit into one of three categories:

-   Commands that produce a stream (e.g., `ls`)
-   Commands that filter a stream (e.g., `where type == &quot;dir&quot;`)
-   Commands that consume the output of the pipeline (e.g., `table`)

Commands are separated by the pipe symbol (`|`) to denote a pipeline flowing left to right.

```shell
ls | where type == &quot;dir&quot; | table
# =&gt; ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
# =&gt; ‚îÇ #  ‚îÇ   name   ‚îÇ type ‚îÇ  size   ‚îÇ   modified    ‚îÇ
# =&gt; ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
# =&gt; ‚îÇ  0 ‚îÇ .cargo   ‚îÇ dir  ‚îÇ     0 B ‚îÇ 9 minutes ago ‚îÇ
# =&gt; ‚îÇ  1 ‚îÇ assets   ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  2 ‚îÇ crates   ‚îÇ dir  ‚îÇ 4.0 KiB ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  3 ‚îÇ docker   ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  4 ‚îÇ docs     ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  5 ‚îÇ images   ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  6 ‚îÇ pkg_mgrs ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  7 ‚îÇ samples  ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  8 ‚îÇ src      ‚îÇ dir  ‚îÇ 4.0 KiB ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  9 ‚îÇ target   ‚îÇ dir  ‚îÇ     0 B ‚îÇ a day ago     ‚îÇ
# =&gt; ‚îÇ 10 ‚îÇ tests    ‚îÇ dir  ‚îÇ 4.0 KiB ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ 11 ‚îÇ wix      ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

Because most of the time you&#039;ll want to see the output of a pipeline, `table` is assumed.
We could have also written the above:

```shell
ls | where type == &quot;dir&quot;
```

Being able to use the same commands and compose them differently is an important philosophy in Nu.
For example, we could use the built-in `ps` command to get a list of the running processes, using the same `where` as above.

```shell
ps | where cpu &gt; 0
# =&gt; ‚ï≠‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
# =&gt; ‚îÇ # ‚îÇ  pid  ‚îÇ   name    ‚îÇ  cpu  ‚îÇ    mem    ‚îÇ  virtual  ‚îÇ
# =&gt; ‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
# =&gt; ‚îÇ 0 ‚îÇ  2240 ‚îÇ Slack.exe ‚îÇ 16.40 ‚îÇ 178.3 MiB ‚îÇ 232.6 MiB ‚îÇ
# =&gt; ‚îÇ 1 ‚îÇ 16948 ‚îÇ Slack.exe ‚îÇ 16.32 ‚îÇ 205.0 MiB ‚îÇ 197.9 MiB ‚îÇ
# =&gt; ‚îÇ 2 ‚îÇ 17700 ‚îÇ nu.exe    ‚îÇ  3.77 ‚îÇ  26.1 MiB ‚îÇ   8.8 MiB ‚îÇ
# =&gt; ‚ï∞‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

### Opening files

Nu can load file and URL contents as raw text or structured data (if it recognizes the format).
For example, you can load a .toml file as structured data and explore it:

```shell
open Cargo.toml
# =&gt; ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
# =&gt; ‚îÇ bin              ‚îÇ [table 1 row]      ‚îÇ
# =&gt; ‚îÇ dependencies     ‚îÇ {record 25 fields} ‚îÇ
# =&gt; ‚îÇ dev-dependencies ‚îÇ {record 8 fields}  ‚îÇ
# =&gt; ‚îÇ features         ‚îÇ {record 10 fields} ‚îÇ
# =&gt; ‚îÇ package          ‚îÇ {record 13 fields} ‚îÇ
# =&gt; ‚îÇ patch            ‚îÇ {record 1 field}   ‚îÇ
# =&gt; ‚îÇ profile          ‚îÇ {record 3 fields}  ‚îÇ
# =&gt; ‚îÇ target           ‚îÇ {record 3 fields}  ‚îÇ
# =&gt; ‚îÇ workspace        ‚îÇ {record 1 field}   ‚îÇ
# =&gt; ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

We can pipe this into a command that gets the contents of one of the columns:

```shell
open Cargo.toml | get package
# =&gt; ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
# =&gt; ‚îÇ authors       ‚îÇ [list 1 item]                      ‚îÇ
# =&gt; ‚îÇ default-run   ‚îÇ nu                                 ‚îÇ
# =&gt; ‚îÇ description   ‚îÇ A new type of shell                ‚îÇ
# =&gt; ‚îÇ documentation ‚îÇ https://www.nushell.sh/book/       ‚îÇ
# =&gt; ‚îÇ edition       ‚îÇ 2018                               ‚îÇ
# =&gt; ‚îÇ exclude       ‚îÇ [list 1 item]                      ‚îÇ
# =&gt; ‚îÇ homepage      ‚îÇ https://www.nushell.sh             ‚îÇ
# =&gt; ‚îÇ license       ‚îÇ MIT                                ‚îÇ
# =&gt; ‚îÇ metadata      ‚îÇ {record 1 field}                   ‚îÇ
# =&gt; ‚îÇ name          ‚îÇ nu                                 ‚îÇ
# =&gt; ‚îÇ repository    ‚îÇ https://github.com/nushell/nushell ‚îÇ
# =&gt; ‚îÇ rust-version  ‚îÇ 1.60                               ‚îÇ
# =&gt; ‚îÇ version       ‚îÇ 0.72.0                             ‚îÇ
# =&gt; ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

And if needed we can drill down further:

```shell
open Cargo.toml | get package.version
# =&gt; 0.72.0
```

### Plugins

Nu supports plugins that offer additional functionality to the shell and follow the same structured data model that built-in commands use. There are a few examples in the `crates/nu_plugins_*` directories.

Plugins are binaries that are available in your path and follow a `nu_plugin_*` naming convention.
These binaries interact with nu via a simple JSON-RPC protocol where the command identifies itself and passes along its configuration, making it available for use.
If the plugin is a filter, data streams to it one element at a time, and it can stream data back in return via stdin/stdout.
If the plugin is a sink, it is given the full vector of final data and is given free reign over stdin/stdout to use as it pleases.

The [awesome-nu repo](https://github.com/nushell/awesome-nu#plugins) lists a variety of nu-plugins while the [showcase repo](https://github.com/nushell/showcase) *shows* off informative blog posts that have been written about Nushell along with videos that highlight technical
topics that have been presented.

## Goals

Nu adheres closely to a set of goals that make up its design philosophy. As features are added, they are checked against these goals.

-   First and foremost, Nu is cross-platform. Commands and techniques should work across platforms and Nu has [first-class support for Windows, macOS, and Linux](devdocs/PLATFORM_SUPPORT.md).

-   Nu ensures compatibility with existing platform-specific executables.

-   Nu&#039;s workflow and tools should have the usability expected of modern software in 2022 (and beyond).

-   Nu views data as either structured or unstructured. It is a structured shell like PowerShell.

-   Finally, Nu views data functionally. Rather than using mutation, pipelines act as a means to load, change, and save data without mutable state.

## Officially Supported By

Please submit an issue or PR to be added to this list.

-   [zoxide](https://github.com/ajeetdsouza/zoxide)
-   [starship](https://github.com/starship/starship)
-   [oh-my-posh](https://ohmyposh.dev)
-   [Couchbase Shell](https://couchbase.sh)
-   [virtualenv](https://github.com/pypa/virtualenv)
-   [atuin](https://github.com/ellie/atuin)
-   [clap](https://github.com/clap-rs/clap/tree/master/clap_complete_nushell)
-   [Dorothy](http://github.com/bevry/dorothy)
-   [Direnv](https://github.com/direnv/direnv/blob/master/docs/hook.md#nushell)
-   [x-cmd](https://x-cmd.com/mod/nu)
-   [vfox](https://github.com/version-fox/vfox)
-   [Windmill](https://www.windmill.dev/docs/getting_started/scripts_quickstart/bash)

## Contributing

See [Contributing](CONTRIBUTING.md) for details. Thanks to all the people who already contributed!

&lt;a href=&quot;https://github.com/nushell/nushell/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=nushell/nushell&amp;max=750&amp;columns=20&quot; /&gt;
&lt;/a&gt;

## License

The project is made available under the MIT license. See the `LICENSE` file for more information.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[influxdata/influxdb]]></title>
            <link>https://github.com/influxdata/influxdb</link>
            <guid>https://github.com/influxdata/influxdb</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Scalable datastore for metrics, events, and real-time analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/influxdb">influxdata/influxdb</a></h1>
            <p>Scalable datastore for metrics, events, and real-time analytics</p>
            <p>Language: Rust</p>
            <p>Stars: 31,010</p>
            <p>Forks: 3,681</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
 &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/influxdb-logo.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/influxdb-logo-dark.png&quot;&gt;
    &lt;img src=&quot;assets/influxdb-logo.png&quot; alt=&quot;InfluxDB Logo&quot; width=&quot;600&quot;&gt;
  &lt;/picture&gt;
 &lt;p&gt;
&lt;/div&gt;

InfluxDB Core is a database built to collect, process, transform, and store event and time series data. It is ideal for use cases that require real-time ingest and fast query response times to build user interfaces, monitoring, and automation solutions.

Common use cases include:

- Monitoring sensor data
- Server monitoring
- Application performance monitoring
- Network monitoring
- Financial market and trading analytics
- Behavioral analytics

InfluxDB is optimized for scenarios where near real-time data monitoring is essential and queries 
need to return quickly to support user experiences such as dashboards and interactive user interfaces.

InfluxDB 3 Core‚Äôs feature highlights include:

- Diskless architecture with object storage support (or local disk with no dependencies)
- Fast query response times (under 10ms for last-value queries, or 30ms for distinct metadata)
- Embedded Python VM for plugins and triggers
- Parquet file persistence
- Compatibility with InfluxDB 1.x and 2.x write APIs
- Compatability with InfluxDB 1.x query API (InfluxQL)
- SQL query engine with support for FlightSQL and HTTP query API

## Project Status

InfluxDB 3 Core is GA as of April 15, 2025! We plan to have monthly point releases for the following six months, with patch releases as needed. We will move to a quarterly cadence after that for 3-4 releases, after which we&#039;ll reevaluate our release schedule.

Join the [InfluxDB3 Discord](https://discord.gg/vZe2w2Ds8B) 
or the public channels below to share your feedback, feature requests, and bug reports.

See the [InfluxDB 3 Core &amp; Enterprise GA release announcement here](https://www.influxdata.com/blog/influxdb-3-oss-ga/) 
or dig into the [InfluxDB 3 getting started guide here](https://docs.influxdata.com/influxdb3/core/get-started/).

## Learn InfluxDB
[Documentation](https://docs.influxdata.com/) | [Community Forum](https://community.influxdata.com/) | [Community Slack](https://www.influxdata.com/slack/) | [Blog](https://www.influxdata.com/blog/) | [InfluxDB University](https://university.influxdata.com/) | [YouTube](https://www.youtube.com/@influxdata8893)

Try **InfluxDB Cloud** for free and get started fast with no local setup required. Click [here](https://cloud2.influxdata.com/signup) to start building your application on InfluxDB Cloud.


## Installation
We have nightly and versioned Docker images, Debian packages, RPM packages, and tarballs of InfluxDB available on the [InfluxData downloads page](https://portal.influxdata.com/downloads/). We also provide the InfluxDB command line interface (CLI) client as a separate binary available at the same location.

- For v1 installation, use the [main 1.x branch](https://github.com/influxdata/influxdb/tree/master-1.x) or [install InfluxDB OSS directly](https://docs.influxdata.com/influxdb/v1/introduction/install/#installing-influxdb-oss).
- For v2 installation, use the [main 2.x branch](https://github.com/influxdata/influxdb/tree/main-2.x).
- For InfluxDB 3 Core see the [InfluxDB 3 Core getting started guide](https://docs.influxdata.com/influxdb3/core/get-started/).
- For InfluxDB 3 Enterprise see the [InfluxDB 3 Enterprise getting started guide](https://docs.influxdata.com/influxdb3/enterprise/get-started/).

If you are interested in building from source, see the [building from source](CONTRIBUTING.md#building-from-source) guide for contributors.

To begin using InfluxDB, visit our [Getting Started with InfluxDB](https://docs.influxdata.com/influxdb/v1/introduction/get-started/) documentation.


## License
The open source software we build is licensed under the permissive MIT or Apache 2 licenses at the user&#039;s choosing. We‚Äôve long held the view that our open source code should be truly open and our commercial code should be separate and closed. 


## Interested in joining the team building InfluxDB?
Check out current job openings at [www.influxdata.com/careers](https://www.influxdata.com/careers) today!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[dani-garcia/vaultwarden]]></title>
            <link>https://github.com/dani-garcia/vaultwarden</link>
            <guid>https://github.com/dani-garcia/vaultwarden</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dani-garcia/vaultwarden">dani-garcia/vaultwarden</a></h1>
            <p>Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs</p>
            <p>Language: Rust</p>
            <p>Stars: 52,337</p>
            <p>Forks: 2,434</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre>![Vaultwarden Logo](./resources/vaultwarden-logo-auto.svg)

An alternative server implementation of the Bitwarden Client API, written in Rust and compatible with [official Bitwarden clients](https://bitwarden.com/download/) [[disclaimer](#disclaimer)], perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.

---

[![GitHub Release](https://img.shields.io/github/release/dani-garcia/vaultwarden.svg?style=for-the-badge&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/releases/latest)
[![ghcr.io Pulls](https://img.shields.io/badge/dynamic/json?style=for-the-badge&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;url=https%3A%2F%2Fipitio.github.io%2Fbackage%2Fdani-garcia%2Fvaultwarden%2Fvaultwarden.json&amp;query=%24.downloads&amp;label=ghcr.io%20pulls&amp;cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden)
[![Docker Pulls](https://img.shields.io/docker/pulls/vaultwarden/server.svg?style=for-the-badge&amp;logo=docker&amp;logoColor=fff&amp;color=005AA4&amp;label=docker.io%20pulls)](https://hub.docker.com/r/vaultwarden/server)
[![Quay.io](https://img.shields.io/badge/quay.io-download-005AA4?style=for-the-badge&amp;logo=redhat&amp;cacheSeconds=14400)](https://quay.io/repository/vaultwarden/server) &lt;br&gt;
[![Contributors](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)
[![Forks](https://img.shields.io/github/forks/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/network/members)
[![Stars](https://img.shields.io/github/stars/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/stargazers)
[![Issues Open](https://img.shields.io/github/issues/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues)
[![Issues Closed](https://img.shields.io/github/issues-closed/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues?q=is%3Aissue+is%3Aclosed)
[![AGPL-3.0 Licensed](https://img.shields.io/github/license/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=vaultwarden&amp;color=944000&amp;cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/blob/main/LICENSE.txt) &lt;br&gt;
[![Dependency Status](https://img.shields.io/badge/dynamic/xml?url=https%3A%2F%2Fdeps.rs%2Frepo%2Fgithub%2Fdani-garcia%2Fvaultwarden%2Fstatus.svg&amp;query=%2F*%5Blocal-name()%3D&#039;svg&#039;%5D%2F*%5Blocal-name()%3D&#039;g&#039;%5D%5B2%5D%2F*%5Blocal-name()%3D&#039;text&#039;%5D%5B4%5D&amp;style=flat-square&amp;logo=rust&amp;label=dependencies&amp;color=005AA4)](https://deps.rs/repo/github/dani-garcia/vaultwarden)
[![GHA Release](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/release.yml?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;label=Release%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/release.yml)
[![GHA Build](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/build.yml?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;label=Build%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/build.yml) &lt;br&gt;
[![Matrix Chat](https://img.shields.io/matrix/vaultwarden:matrix.org.svg?style=flat-square&amp;logo=matrix&amp;logoColor=fff&amp;color=953B00&amp;cacheSeconds=14400)](https://matrix.to/#/#vaultwarden:matrix.org)
[![GitHub Discussions](https://img.shields.io/github/discussions/dani-garcia/vaultwarden?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=953B00&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/discussions)
[![Discourse Discussions](https://img.shields.io/discourse/topics?server=https%3A%2F%2Fvaultwarden.discourse.group%2F&amp;style=flat-square&amp;logo=discourse&amp;color=953B00)](https://vaultwarden.discourse.group/)

&gt; [!IMPORTANT]
&gt; **When using this server, please report any bugs or suggestions directly to us (see [Get in touch](#get-in-touch)), regardless of whatever clients you are using (mobile, desktop, browser...). DO NOT use the official Bitwarden support channels.**

&lt;br&gt;

## Features

A nearly complete implementation of the Bitwarden Client API is provided, including:

 * [Personal Vault](https://bitwarden.com/help/managing-items/)
 * [Send](https://bitwarden.com/help/about-send/)
 * [Attachments](https://bitwarden.com/help/attachments/)
 * [Website icons](https://bitwarden.com/help/website-icons/)
 * [Personal API Key](https://bitwarden.com/help/personal-api-key/)
 * [Organizations](https://bitwarden.com/help/getting-started-organizations/)
   - [Collections](https://bitwarden.com/help/about-collections/),
     [Password Sharing](https://bitwarden.com/help/sharing/),
     [Member Roles](https://bitwarden.com/help/user-types-access-control/),
     [Groups](https://bitwarden.com/help/about-groups/),
     [Event Logs](https://bitwarden.com/help/event-logs/),
     [Admin Password Reset](https://bitwarden.com/help/admin-reset/),
     [Directory Connector](https://bitwarden.com/help/directory-sync/),
     [Policies](https://bitwarden.com/help/policies/)
 * [Multi/Two Factor Authentication](https://bitwarden.com/help/bitwarden-field-guide-two-step-login/)
   - [Authenticator](https://bitwarden.com/help/setup-two-step-login-authenticator/),
     [Email](https://bitwarden.com/help/setup-two-step-login-email/),
     [FIDO2 WebAuthn](https://bitwarden.com/help/setup-two-step-login-fido/),
     [YubiKey](https://bitwarden.com/help/setup-two-step-login-yubikey/),
     [Duo](https://bitwarden.com/help/setup-two-step-login-duo/)
 * [Emergency Access](https://bitwarden.com/help/emergency-access/)
 * [Vaultwarden Admin Backend](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-admin-page)
 * [Modified Web Vault client](https://github.com/dani-garcia/bw_web_builds) (Bundled within our containers)

&lt;br&gt;

## Usage

&gt; [!IMPORTANT]
&gt; The web-vault requires the use a secure context for the [Web Crypto API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API).
&gt; That means it will only work via `http://localhost:8000` (using the port from the example below) or if you [enable HTTPS](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-HTTPS).

The recommended way to install and use Vaultwarden is via our container images which are published to [ghcr.io](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden), [docker.io](https://hub.docker.com/r/vaultwarden/server) and [quay.io](https://quay.io/repository/vaultwarden/server).
See [which container image to use](https://github.com/dani-garcia/vaultwarden/wiki/Which-container-image-to-use) for an explanation of the provided tags.

There are also [community driven packages](https://github.com/dani-garcia/vaultwarden/wiki/Third-party-packages) which can be used, but those might be lagging behind the latest version or might deviate in the way Vaultwarden is configured, as described in our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).

Alternatively, you can also [build Vaultwarden](https://github.com/dani-garcia/vaultwarden/wiki/Building-binary) yourself.

While Vaultwarden is based upon the [Rocket web framework](https://rocket.rs) which has built-in support for TLS our recommendation would be that you setup a reverse proxy (see [proxy examples](https://github.com/dani-garcia/vaultwarden/wiki/Proxy-examples)).

&gt; [!TIP]
&gt;**For more detailed examples on how to install, use and configure Vaultwarden you can check our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).**

### Docker/Podman CLI

Pull the container image and mount a volume from the host for persistent storage.&lt;br&gt;
You can replace `docker` with `podman` if you prefer to use podman.

```shell
docker pull vaultwarden/server:latest
docker run --detach --name vaultwarden \
  --env DOMAIN=&quot;https://vw.domain.tld&quot; \
  --volume /vw-data/:/data/ \
  --restart unless-stopped \
  --publish 127.0.0.1:8000:80 \
  vaultwarden/server:latest
```

This will preserve any persistent data under `/vw-data/`, you can adapt the path to whatever suits you.

### Docker Compose

To use Docker compose you need to create a `compose.yaml` which will hold the configuration to run the Vaultwarden container.

```yaml
services:
  vaultwarden:
    image: vaultwarden/server:latest
    container_name: vaultwarden
    restart: unless-stopped
    environment:
      DOMAIN: &quot;https://vw.domain.tld&quot;
    volumes:
      - ./vw-data/:/data/
    ports:
      - 127.0.0.1:8000:80
```

&lt;br&gt;

## Get in touch

Have a question, suggestion or need help? Join our community on [Matrix](https://matrix.to/#/#vaultwarden:matrix.org), [GitHub Discussions](https://github.com/dani-garcia/vaultwarden/discussions) or [Discourse Forums](https://vaultwarden.discourse.group/).

Encountered a bug or crash? Please search our issue tracker and discussions to see if it&#039;s already been reported. If not, please [start a new discussion](https://github.com/dani-garcia/vaultwarden/discussions) or [create a new issue](https://github.com/dani-garcia/vaultwarden/issues/). Ensure you&#039;re using the latest version of Vaultwarden and there aren&#039;t any similar issues open or closed!

&lt;br&gt;

## Contributors

Thanks for your contribution to the project!

[![Contributors Count](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden?style=for-the-badge&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)&lt;br&gt;
[![Contributors Avatars](https://contributors-img.web.app/image?repo=dani-garcia/vaultwarden)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)

&lt;br&gt;

## Disclaimer

**This project is not associated with [Bitwarden](https://bitwarden.com/) or Bitwarden, Inc.**

However, one of the active maintainers for Vaultwarden is employed by Bitwarden and is allowed to contribute to the project on their own time. These contributions are independent of Bitwarden and are reviewed by other maintainers.

The maintainers work together to set the direction for the project, focusing on serving the self-hosting community, including individuals, families, and small organizations, while ensuring the project&#039;s sustainability.

**Please note:** We cannot be held liable for any data loss that may occur while using Vaultwarden. This includes passwords, attachments, and other information handled by the application. We highly recommend performing regular backups of your files and database. However, should you experience data loss, we encourage you to contact us immediately.

&lt;br&gt;

## Bitwarden_RS

This project was known as Bitwarden_RS and has been renamed to separate itself from the official Bitwarden server in the hopes of avoiding confusion and trademark/branding issues.&lt;br&gt;
Please see [#1642 - v1.21.0 release and project rename to Vaultwarden](https://github.com/dani-garcia/vaultwarden/discussions/1642) for more explanation.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[GreptimeTeam/greptimedb]]></title>
            <link>https://github.com/GreptimeTeam/greptimedb</link>
            <guid>https://github.com/GreptimeTeam/greptimedb</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[Open-source, cloud-native, unified observability database for metrics, logs and traces, supporting SQL/PromQL/Streaming.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GreptimeTeam/greptimedb">GreptimeTeam/greptimedb</a></h1>
            <p>Open-source, cloud-native, unified observability database for metrics, logs and traces, supporting SQL/PromQL/Streaming.</p>
            <p>Language: Rust</p>
            <p>Stars: 5,834</p>
            <p>Forks: 436</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://cdn.jsdelivr.net/gh/GreptimeTeam/greptimedb@main/docs/logo-text-padding.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://cdn.jsdelivr.net/gh/GreptimeTeam/greptimedb@main/docs/logo-text-padding-dark.png&quot;&gt;
    &lt;img alt=&quot;GreptimeDB Logo&quot; src=&quot;https://cdn.jsdelivr.net/gh/GreptimeTeam/greptimedb@main/docs/logo-text-padding.png&quot; width=&quot;400px&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;h2 align=&quot;center&quot;&gt;Real-Time &amp; Cloud-Native Observability  Database&lt;br/&gt;for metrics, logs, and traces&lt;/h2&gt;

&gt;  Delivers sub-second querying at PB scale and exceptional cost efficiency from edge to cloud.

&lt;div align=&quot;center&quot;&gt;
&lt;h3 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.greptime.com/user-guide/overview/&quot;&gt;User Guide&lt;/a&gt; |
  &lt;a href=&quot;https://greptimedb.rs/&quot;&gt;API Docs&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/issues/5446&quot;&gt;Roadmap 2025&lt;/a&gt;
&lt;/h4&gt;

&lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/releases/latest&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/v/release/GreptimeTeam/greptimedb.svg&quot; alt=&quot;Version&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/releases/latest&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/release-date/GreptimeTeam/greptimedb.svg&quot; alt=&quot;Releases&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://hub.docker.com/r/greptime/greptimedb/&quot;&gt;
&lt;img src=&quot;https://img.shields.io/docker/pulls/greptime/greptimedb.svg&quot; alt=&quot;Docker Pulls&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/actions/workflows/develop.yml&quot;&gt;
&lt;img src=&quot;https://github.com/GreptimeTeam/greptimedb/actions/workflows/develop.yml/badge.svg&quot; alt=&quot;GitHub Actions&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://codecov.io/gh/GrepTimeTeam/greptimedb&quot;&gt;
&lt;img src=&quot;https://codecov.io/gh/GrepTimeTeam/greptimedb/branch/main/graph/badge.svg?token=FITFDI3J3C&quot; alt=&quot;Codecov&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/greptimeTeam/greptimedb/blob/main/LICENSE&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/license/greptimeTeam/greptimedb&quot; alt=&quot;License&quot;/&gt;
&lt;/a&gt;

&lt;br/&gt;

&lt;a href=&quot;https://greptime.com/slack&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/slack-GreptimeDB-0abd59?logo=slack&amp;style=for-the-badge&quot; alt=&quot;Slack&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://twitter.com/greptime&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/twitter-follow_us-1d9bf0.svg?style=for-the-badge&quot; alt=&quot;Twitter&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://www.linkedin.com/company/greptime/&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/linkedin-connect_with_us-0a66c2.svg?style=for-the-badge&quot; alt=&quot;LinkedIn&quot;/&gt;
&lt;/a&gt;
&lt;/div&gt;

- [Introduction](#introduction)
- [‚≠ê Key Features](#features)
- [Quick Comparison](#quick-comparison)
- [Architecture](#architecture)
- [Try GreptimeDB](#try-greptimedb)
- [Getting Started](#getting-started)
- [Build From Source](#build-from-source)
- [Tools &amp; Extensions](#tools--extensions)
- [Project Status](#project-status)
- [Community](#community)
- [License](#license)
- [Commercial Support](#commercial-support)
- [Contributing](#contributing)
- [Acknowledgement](#acknowledgement)

## Introduction

**GreptimeDB** is an open-source, cloud-native database that unifies metrics, logs, and traces, enabling real-time observability at any scale ‚Äî across edge, cloud, and hybrid environments.

## Features

|   Feature  | Description |
| --------- | ----------- |
| [All-in-One Observability](https://docs.greptime.com/user-guide/concepts/why-greptimedb) | OpenTelemetry-native platform unifying metrics, logs, and traces. Query via [SQL](https://docs.greptime.com/user-guide/query-data/sql), [PromQL](https://docs.greptime.com/user-guide/query-data/promql), and [Flow](https://docs.greptime.com/user-guide/flow-computation/overview). |
| [High Performance](https://docs.greptime.com/user-guide/manage-data/data-index) | Written in Rust with [rich indexing](https://docs.greptime.com/user-guide/manage-data/data-index) (inverted, fulltext, skipping, vector), delivering sub-second responses at PB scale. |
| [Cost Efficiency](https://docs.greptime.com/user-guide/concepts/architecture) | 50x lower operational and storage costs with compute-storage separation and native object storage (S3, Azure Blob, etc.). |
| [Cloud-Native &amp; Scalable](https://docs.greptime.com/user-guide/deployments-administration/deploy-on-kubernetes/greptimedb-operator-management) | Purpose-built for [Kubernetes](https://docs.greptime.com/user-guide/deployments-administration/deploy-on-kubernetes/greptimedb-operator-management) with unlimited cross-cloud scaling, handling hundreds of thousands of concurrent requests. |
| [Developer-Friendly](https://docs.greptime.com/user-guide/protocols/overview) | SQL/PromQL interfaces, built-in web dashboard, REST API, MySQL/PostgreSQL protocol compatibility, and native [OpenTelemetry](https://docs.greptime.com/user-guide/ingest-data/for-observability/opentelemetry/) support. |
| [Flexible Deployment](https://docs.greptime.com/user-guide/deployments-administration/overview) | Deploy anywhere from ARM-based edge devices (including [Android](https://docs.greptime.com/user-guide/deployments-administration/run-on-android)) to cloud, with unified APIs and efficient data sync. |

  ‚úÖ **Perfect for:**
  - Unified observability stack replacing Prometheus + Loki + Tempo
  - Large-scale metrics with high cardinality (millions to billions of time series)
  - Large-scale observability platform requiring cost efficiency and scalability
  - IoT and edge computing with resource and bandwidth constraints

Learn more in [Why GreptimeDB](https://docs.greptime.com/user-guide/concepts/why-greptimedb) and [Observability 2.0 and the Database for It](https://greptime.com/blogs/2025-04-25-greptimedb-observability2-new-database).

## Quick Comparison

| Feature                         | GreptimeDB            | Traditional TSDB   | Log Stores      |
|----------------------------------|-----------------------|--------------------|-----------------|
| Data Types                      | Metrics, Logs, Traces | Metrics only       | Logs only       |
| Query Language                  | SQL, PromQL |  Custom/PromQL     | Custom/DSL      |
| Deployment                      | Edge + Cloud          | Cloud/On-prem      | Mostly central  |
| Indexing &amp; Performance          | PB-Scale, Sub-second  | Varies             | Varies          |
| Integration                     | REST API, SQL, Common protocols | Varies     | Varies          |

**Performance:**
* [GreptimeDB tops JSONBench&#039;s billion-record cold run test!](https://greptime.com/blogs/2025-03-18-jsonbench-greptimedb-performance)
* [TSBS Benchmark](https://github.com/GreptimeTeam/greptimedb/tree/main/docs/benchmarks/tsbs)

Read [more benchmark reports](https://docs.greptime.com/user-guide/concepts/features-that-you-concern#how-is-greptimedbs-performance-compared-to-other-solutions).

## Architecture

GreptimeDB can run in two modes:
* **Standalone Mode** - Single binary for development and small deployments
* **Distributed Mode** - Separate components for production scale:
  - Frontend: Query processing and protocol handling
  - Datanode: Data storage and retrieval
  - Metasrv: Metadata management and coordination
  
Read the [architecture](https://docs.greptime.com/contributor-guide/overview/#architecture) document. [DeepWiki](https://deepwiki.com/GreptimeTeam/greptimedb/1-overview) provides an in-depth look at GreptimeDB:
  &lt;img alt=&quot;GreptimeDB System Overview&quot; src=&quot;docs/architecture.png&quot;&gt;

## Try GreptimeDB

```shell
docker pull greptime/greptimedb
```

```shell
docker run -p 127.0.0.1:4000-4003:4000-4003 \
  -v &quot;$(pwd)/greptimedb_data:/greptimedb_data&quot; \
  --name greptime --rm \
  greptime/greptimedb:latest standalone start \
  --http-addr 0.0.0.0:4000 \
  --rpc-bind-addr 0.0.0.0:4001 \
  --mysql-addr 0.0.0.0:4002 \
  --postgres-addr 0.0.0.0:4003
```
Dashboard: [http://localhost:4000/dashboard](http://localhost:4000/dashboard)

Read more in the [full Install Guide](https://docs.greptime.com/getting-started/installation/overview).

**Troubleshooting:**
* Cannot connect to the database? Ensure that ports `4000`, `4001`, `4002`, and `4003` are not blocked by a firewall or used by other services.
* Failed to start? Check the container logs with `docker logs greptime` for further details.

## Getting Started

- [Quickstart](https://docs.greptime.com/getting-started/quick-start)
- [User Guide](https://docs.greptime.com/user-guide/overview)
- [Demo Scenes](https://github.com/GreptimeTeam/demo-scene)
- [FAQ](https://docs.greptime.com/faq-and-others/faq)

## Build From Source

**Prerequisites:**
* [Rust toolchain](https://www.rust-lang.org/tools/install) (nightly)
* [Protobuf compiler](https://grpc.io/docs/protoc-installation/) (&gt;= 3.15)
* C/C++ building essentials, including `gcc`/`g++`/`autoconf` and glibc library (eg. `libc6-dev` on Ubuntu and `glibc-devel` on Fedora)
* Python toolchain (optional): Required only if using some test scripts.

**Build and Run:**
```bash
make
cargo run -- standalone start
```

## Tools &amp; Extensions

- **Kubernetes**: [GreptimeDB Operator](https://github.com/GrepTimeTeam/greptimedb-operator)
- **Helm Charts**: [Greptime Helm Charts](https://github.com/GreptimeTeam/helm-charts)
- **Dashboard**: [Web UI](https://github.com/GreptimeTeam/dashboard)
- **gRPC Ingester**: [Go](https://github.com/GreptimeTeam/greptimedb-ingester-go), [Java](https://github.com/GreptimeTeam/greptimedb-ingester-java), [C++](https://github.com/GreptimeTeam/greptimedb-ingester-cpp), [Erlang](https://github.com/GreptimeTeam/greptimedb-ingester-erl), [Rust](https://github.com/GreptimeTeam/greptimedb-ingester-rust)
- **Grafana Data Source**: [GreptimeDB Grafana data source plugin](https://github.com/GreptimeTeam/greptimedb-grafana-datasource)
- **Grafana Dashboard**: [Official Dashboard for monitoring](https://github.com/GreptimeTeam/greptimedb/blob/main/grafana/README.md)

## Project Status

&gt; **Status:** Beta ‚Äî marching toward v1.0 GA!
&gt; **GA (v1.0):** January 10, 2026

- Deployed in production by open-source projects and commercial users
- Stable, actively maintained, with regular releases ([version info](https://docs.greptime.com/nightly/reference/about-greptimedb-version))
- Suitable for evaluation and pilot deployments

GreptimeDB v1.0 represents a major milestone toward maturity ‚Äî marking stable APIs, production readiness, and proven performance.

**Roadmap:** Beta1 (Nov 10) ‚Üí Beta2 (Nov 24) ‚Üí RC1 (Dec 8) ‚Üí GA (Jan 10, 2026), please read [v1.0 highlights and release plan](https://greptime.com/blogs/2025-11-05-greptimedb-v1-highlights) for details.

For production use, we recommend using the latest stable release.
[![Star History Chart](https://api.star-history.com/svg?repos=GreptimeTeam/GreptimeDB&amp;type=Date)](https://www.star-history.com/#GreptimeTeam/GreptimeDB&amp;Date)

If you find this project useful, a ‚≠ê would mean a lot to us!
&lt;img alt=&quot;Known Users&quot; src=&quot;https://greptime.com/logo/img/users.png&quot;/&gt;

## Community

We invite you to engage and contribute!

- [Slack](https://greptime.com/slack)
- [Discussions](https://github.com/GreptimeTeam/greptimedb/discussions)
- [Official Website](https://greptime.com/)
- [Blog](https://greptime.com/blogs/)
- [LinkedIn](https://www.linkedin.com/company/greptime/)
- [X (Twitter)](https://X.com/greptime)
- [YouTube](https://www.youtube.com/@greptime)

## License

GreptimeDB is licensed under the [Apache License 2.0](https://apache.org/licenses/LICENSE-2.0.txt).

## Commercial Support

Running GreptimeDB in your organization?
We offer enterprise add-ons, services, training, and consulting.
[Contact us](https://greptime.com/contactus) for details.

## Contributing

- Read our [Contribution Guidelines](https://github.com/GreptimeTeam/greptimedb/blob/main/CONTRIBUTING.md).
- Explore [Internal Concepts](https://docs.greptime.com/contributor-guide/overview.html) and [DeepWiki](https://deepwiki.com/GreptimeTeam/greptimedb).
- Pick up a [good first issue](https://github.com/GreptimeTeam/greptimedb/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) and join the #contributors [Slack](https://greptime.com/slack) channel.

## Acknowledgement

Special thanks to all contributors! See [AUTHORS.md](https://github.com/GreptimeTeam/greptimedb/blob/main/AUTHOR.md).

- Uses [Apache Arrow‚Ñ¢](https://arrow.apache.org/) (memory model)
- [Apache Parquet‚Ñ¢](https://parquet.apache.org/) (file storage)
- [Apache DataFusion‚Ñ¢](https://arrow.apache.org/datafusion/) (query engine)
- [Apache OpenDAL‚Ñ¢](https://opendal.apache.org/) (data access abstraction)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[eclipse-iceoryx/iceoryx2]]></title>
            <link>https://github.com/eclipse-iceoryx/iceoryx2</link>
            <guid>https://github.com/eclipse-iceoryx/iceoryx2</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Eclipse iceoryx2‚Ñ¢ - true zero-copy inter-process-communication with a Rust core]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eclipse-iceoryx/iceoryx2">eclipse-iceoryx/iceoryx2</a></h1>
            <p>Eclipse iceoryx2‚Ñ¢ - true zero-copy inter-process-communication with a Rust core</p>
            <p>Language: Rust</p>
            <p>Stars: 1,906</p>
            <p>Forks: 106</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable --&gt;

[![CI](https://github.com/eclipse-iceoryx/iceoryx2/workflows/CI/badge.svg)](https://github.com/eclipse-iceoryx/iceoryx2/actions/workflows/build-test.yml?query=branch%3Amain++)
[![Codecov](https://codecov.io/gh/eclipse-iceoryx/iceoryx2/branch/main/graph/badge.svg?branch=main)](https://codecov.io/gh/eclipse-iceoryx/iceoryx2?branch=main)
[![Examples](https://img.shields.io/badge/Examples-gray)](examples/)
[![FAQ](https://img.shields.io/badge/FAQ-gray)](FAQ.md)
[![Gitter](https://badges.gitter.im/eclipse-iceoryx/iceoryx.svg)](https://gitter.im/eclipse/iceoryx)
[![Developer Meetup](https://img.shields.io/badge/Developer_Meetup-gray?style=social)](https://github.com/eclipse-iceoryx/iceoryx2/wiki/Developer-Meetup)
[![Roadmap](https://img.shields.io/badge/Roadmap-gray)](ROADMAP.md)

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://github.com/eclipse-iceoryx/iceoryx2/assets/56729169/3230a125-19e5-4e98-a752-da026a086782&quot; width=&quot;50%&quot;&gt;
&lt;/p&gt;

&lt;!-- markdownlint-enable --&gt;

# iceoryx2 - Zero-Copy Lock-Free IPC with a Rust Core

* [Introduction](#introduction)
* [Performance](#performance)
    * [Comparision Of Mechanisms](#comparision-of-mechanisms)
        * [Benchmark-System](#benchmark-system)
    * [Comparision Of Architectures](#comparision-of-architectures)
* [Documentation](#documentation)
    * [User Documentation](#user-documentation)
    * [Contributor Documentation](#contributor-documentation)
    * [API References](#api-references)
* [Supported Platforms](#supported-platforms)
* [Language Bindings](#language-bindings)
* [Commercial Support](#commercial-support)
* [Thanks To All Contributors](#thanks-to-all-contributors)

## Introduction

Welcome to iceoryx2, the efficient, and ultra-low latency inter-process
communication middleware. This library is designed to provide you with fast and
reliable zero-copy and lock-free inter-process communication mechanisms.

So if you want to communicate efficiently between multiple processes or
applications iceoryx2 is for you. With iceoryx2, you can:

* Send huge amounts of data using a publish/subscribe, request/response,
  pipeline (planned) or blackboard pattern (planned), making it ideal
  for scenarios where large datasets need to be shared.
* Exchange signals through events, enabling quick and reliable signaling between
  processes.

iceoryx2 is based on a service-oriented architecture (SOA) and facilitates
seamless inter-process communication (IPC).

It is all about providing a seamless experience for inter-process communication,
featuring versatile messaging patterns. Whether you&#039;re diving into
publish-subscribe, events, request-response, or the promise of upcoming features
like pipelines, and blackboard, iceoryx2 has you covered.

One of the features of iceoryx2 is its consistently low transmission latency
regardless of payload size, ensuring a predictable and reliable communication
experience.

iceoryx2&#039;s origins can be traced back to
[iceoryx](https://github.com/eclipse-iceoryx/iceoryx). By overcoming past
technical debts and refining the architecture, iceoryx2 enables the modularity
we&#039;ve always desired.

In the near future, iceoryx2 is poised to support at least the same feature set
and platforms as [iceoryx](https://github.com/eclipse-iceoryx/iceoryx), ensuring
a seamless transition and offering enhanced capabilities for your inter-process
communication needs. So, if you&#039;re looking for lightning-fast, cross-platform
communication that doesn&#039;t compromise on performance or modularity, iceoryx2 is
your answer.

Feel free to join the [Gitter Chat](https://gitter.im/eclipse/iceoryx) or
the [Developer Meetup](https://github.com/eclipse-iceoryx/iceoryx2/wiki/Developer-Meetup)
if you want to have a chat with the developers of iceoryx.

## Performance

### Comparision Of Mechanisms

![benchmark of different mechanism](https://raw.githubusercontent.com/eclipse-iceoryx/iceoryx2/refs/heads/main/internal/plots/benchmark_mechanism.svg)

#### Benchmark-System

* **CPU:** Intel i7 13700h
* **OS:** Linux 6.10.10-arch1-1 #1 SMP PREEMPT_DYNAMIC
* **Compiler:**
    * rustc 1.81.0
    * gcc 14.2.1 20240910

### Comparision Of Architectures

![benchmark on different systems](https://raw.githubusercontent.com/eclipse-iceoryx/iceoryx2/refs/heads/main/internal/plots/benchmark_architecture.svg)

## Documentation

### User Documentation

* [The iceoryx2 Book](https://ekxide.github.io/iceoryx2-book) (by [ekxide](https://ekxide.io))
* [Examples](examples)
* [Release Notes](doc/release-notes)
* [User FAQ](FAQ.md)

### Contributor Documentation

* [Contributor FAQ](FAQ_ICEORYX_DEVS.md)

### API References

* [Rust API Reference](https://docs.rs/iceoryx2/latest/iceoryx2/)
* [Python API Reference](https://eclipse-iceoryx.github.io/iceoryx2/python/latest/)
* [C++ API Reference](https://eclipse-iceoryx.github.io/iceoryx2/cxx/latest/)
* [C API Reference](https://eclipse-iceoryx.github.io/iceoryx2/c/latest/)

## Supported Platforms

The support levels can be adjusted when required.

| Operating System | State                    | Current Support Level | Target Support Level |
| ---------------- | :----------------------- | :-------------------: | -------------------: |
| Android          | proof-of-concept[^1]     |           -           |               tier 1 |
| Bare Metal       | proof-of-concept[^2]     |           -           |               tier 1 |
| FreeBSD          | done                     |        tier 2         |               tier 1 |
| FreeRTOS         | planned                  |           -           |               tier 2 |
| ThreadX          | planned                  |           -           |               tier 2 |
| iOS              | planned                  |           -           |               tier 2 |
| Linux (x86_64)   | done                     |        tier 2         |               tier 1 |
| Linux (aarch64)  | done                     |        tier 2         |               tier 1 |
| Linux (32-bit)   | done                     |        tier 2         |               tier 1 |
| Mac OS           | done                     |        tier 2         |               tier 2 |
| QNX 7.1          | done                     |        tier 3         |               tier 1 |
| QNX 8.0          | done                     |        tier 3         |               tier 1 |
| VxWorks          | proof-of-concept[^3]     |           -           |               tier 1 |
| WatchOS          | planned                  |           -           |               tier 2 |
| Windows          | done                     |        tier 2         |               tier 2 |

[^1]: A proof-of-concept for Android platform support is available. Currently
      only local, inter-thread communication works.
[^2]: A proof-of-concept with `no_std` bare-metal support is available. The event
      messaging-pattern does not yet work and the memory usage is not yet optimized.
[^3]: A proof-of-concept for VxWorks platform support is available on [this
      branch](https://github.com/ekxide/iceoryx2/blob/vxworks-mvp/doc/development-setup/vxworks.md)
      on the [ekxide](https://ekxide.io) fork

* **tier 1** - All safety and security features are working.
* **tier 2** - Works with a restricted security and safety feature set.
* **tier 3** - Not tested in our CI, so may or may not compile and run.

&lt;!-- markdownlint-disable MD027 --&gt;
&gt; [!NOTE]
&gt; Some commercial operating systems require expensive licenses and the support
&gt; for these platforms relies on funding for the license costs.
&lt;!-- markdownlint-enable MD027 --&gt;

&lt;!-- markdownlint-disable MD027 --&gt;
&gt; [!NOTE]
&gt; Yocto recipes are available at [meta-iceoryx2](https://github.com/eclipse-iceoryx/meta-iceoryx2)
&lt;!-- markdownlint-enable MD027 --&gt;

## Language Bindings

| Language |     State                                                         |
| :------- | ----------------------------------------------------------------: |
| C / C++  |     done                                                          |
| Python   |     done                                                          |
| Go       |  planned                                                          |
| C#       |    [done](https://github.com/eclipse-iceoryx/iceoryx2-csharp)[^4] |
| Java     |  planned                                                          |
| Kotlin   |  planned                                                          |
| Lua      |  planned                                                          |
| Swift    |  planned                                                          |
| Zig      |  planned                                                          |

[^4]: C# bindings are available in a separate repository. May not be up to date
      with `main`.

## Commercial Support

&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;

&lt;table width=&quot;100%&quot;&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;33%&quot;&gt;
        &lt;a href=&quot;https://ekxide.io&quot;&gt;
        &lt;img src=&quot;https://github.com/eclipse-iceoryx/iceoryx2/assets/56729169/c3ce8370-6cef-4c31-8259-93ddaa61c43e&quot; alt=&quot;ekxide IO GmbH&quot;/&gt;&lt;br /&gt;
        &lt;/a&gt;
        &lt;a href=&quot;mailto:info@ekxide.io&quot;&gt;info@ekxide.io&lt;/a&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;commercial extensions and tooling&lt;/li&gt;
          &lt;li&gt;custom feature development&lt;/li&gt;
          &lt;li&gt;training and consulting&lt;/li&gt;
          &lt;li&gt;integration support&lt;/li&gt;
          &lt;li&gt;engineering services around the iceoryx ecosystem&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- markdownlint-restore --&gt;
&lt;!-- prettier-ignore-end --&gt;

## Thanks To All Contributors

Thanks to everyone who has contributed to iceoryx2. Without their passion and
dedication, the project wouldn&#039;t thrive. A list of people who have committed
code can be found on [github](https://github.com/eclipse-iceoryx/iceoryx2/graphs/contributors).
However, contributions are not limited to code - testing the software, reporting
bugs, and spreading the word about iceoryx2 are all equally valuable. A big
thank you as well to those &#039;invisible&#039; contributors who play a crucial role
behind the scenes.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cocoindex-io/cocoindex]]></title>
            <link>https://github.com/cocoindex-io/cocoindex</link>
            <guid>https://github.com/cocoindex-io/cocoindex</guid>
            <pubDate>Thu, 25 Dec 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cocoindex-io/cocoindex">cocoindex-io/cocoindex</a></h1>
            <p>Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!</p>
            <p>Language: Rust</p>
            <p>Stars: 5,051</p>
            <p>Forks: 384</p>
            <p>Stars today: 75 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/github.svg&quot; alt=&quot;CocoIndex&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Data transformation for AI&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;

[![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex)
[![Documentation](https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;logoColor=00B9FF)](https://cocoindex.io/docs/getting_started/quickstart)
[![License](https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white)](https://opensource.org/licenses/Apache-2.0)
[![PyPI version](https://img.shields.io/pypi/v/cocoindex?color=5B5BD6)](https://pypi.org/project/cocoindex/)
&lt;!--[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex) --&gt;
[![PyPI Downloads](https://static.pepy.tech/badge/cocoindex/month)](https://pepy.tech/projects/cocoindex)
[![CI](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml)
[![release](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml)
[![Discord](https://img.shields.io/discord/1314801574169673738?logo=discord&amp;color=5B5BD6&amp;logoColor=white)](https://discord.com/invite/zpA9S2DR7s)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/13939&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13939&quot; alt=&quot;cocoindex-io%2Fcocoindex | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box.  Exceptional developer velocity. Production-ready at day 0.

‚≠ê Drop a star to help us grow!

&lt;div align=&quot;center&quot;&gt;

&lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
[Deutsch](https://readme-i18n.com/cocoindex-io/cocoindex?lang=de) |
[English](https://readme-i18n.com/cocoindex-io/cocoindex?lang=en) |
[Espa√±ol](https://readme-i18n.com/cocoindex-io/cocoindex?lang=es) |
[fran√ßais](https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr) |
[Êó•Êú¨Ë™û](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja) |
[ÌïúÍµ≠Ïñ¥](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko) |
[Portugu√™s](https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt) |
[–†—É—Å—Å–∫–∏–π](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru) |
[‰∏≠Êñá](https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh)

&lt;/div&gt;

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/transformation.svg&quot; alt=&quot;CocoIndex Transformation&quot;&gt;
&lt;/p&gt;

&lt;/br&gt;

CocoIndex makes it effortless to transform data with AI, and keep source data and target in sync. Whether you‚Äôre building a vector index, creating knowledge graphs for context engineering or performing any custom data transformations ‚Äî goes beyond SQL.

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;CocoIndex Features&quot; src=&quot;https://cocoindex.io/images/venn2.svg&quot; /&gt;
&lt;/p&gt;

&lt;/br&gt;

## Exceptional velocity

Just declare transformation in dataflow with ~100 lines of python

```python
# import
data[&#039;content&#039;] = flow_builder.add_source(...)

# transform
data[&#039;out&#039;] = data[&#039;content&#039;]
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
```

CocoIndex follows the idea of [Dataflow](https://en.wikipedia.org/wiki/Dataflow_programming) programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.

**Particularly**, developers don&#039;t explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.

## Plug-and-Play Building Blocks

Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components - as easy as assembling building blocks.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/components.svg&quot; alt=&quot;CocoIndex Features&quot;&gt;
&lt;/p&gt;

## Data Freshness

CocoIndex keep source data and target in sync effortlessly.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6&quot; alt=&quot;Incremental Processing&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

It has out-of-box support for incremental indexing:

- minimal recomputation on source or logic change.
- (re-)processing necessary portions; reuse cache when possible

## Quick Start

If you&#039;re new to CocoIndex, we recommend checking out

- üìñ [Documentation](https://cocoindex.io/docs)
- ‚ö°  [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart)
- üé¨ [Quick Start Video Tutorial](https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT)

### Setup

1. Install CocoIndex Python library

```sh
pip install -U cocoindex
```

2. [Install Postgres](https://cocoindex.io/docs/getting_started/installation#-install-postgres) if you don&#039;t have one. CocoIndex uses it for incremental processing.

3. (Optional) Install Claude Code skill for enhanced development experience. Run these commands in [Claude Code](https://claude.com/claude-code):

```
/plugin marketplace add cocoindex-io/cocoindex-claude
/plugin install cocoindex-skills@cocoindex
```

## Define data flow

Follow [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart) to define your first indexing flow. An example flow looks like:

```python
@cocoindex.flow_def(name=&quot;TextEmbedding&quot;)
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope[&quot;documents&quot;] = flow_builder.add_source(cocoindex.sources.LocalFile(path=&quot;markdown_files&quot;))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope[&quot;documents&quot;].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc[&quot;chunks&quot;] = doc[&quot;content&quot;].transform(
            cocoindex.functions.SplitRecursively(),
            language=&quot;markdown&quot;, chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc[&quot;chunks&quot;].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk[&quot;embedding&quot;] = chunk[&quot;text&quot;].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model=&quot;sentence-transformers/all-MiniLM-L6-v2&quot;))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc[&quot;filename&quot;], location=chunk[&quot;location&quot;],
                                   text=chunk[&quot;text&quot;], embedding=chunk[&quot;embedding&quot;])

    # Export collected data to a vector index.
    doc_embeddings.export(
        &quot;doc_embeddings&quot;,
        cocoindex.targets.Postgres(),
        primary_key_fields=[&quot;filename&quot;, &quot;location&quot;],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name=&quot;embedding&quot;,
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
```

It defines an index flow like this:

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;400&quot; alt=&quot;Data Flow&quot; src=&quot;https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463&quot; /&gt;
&lt;/p&gt;

## üöÄ Examples and demo

| Example | Description |
|---------|-------------|
| [Text Embedding](examples/text_embedding) | Index text documents with embeddings for semantic search |
| [Code Embedding](examples/code_embedding) | Index code embeddings for semantic search |
| [PDF Embedding](examples/pdf_embedding) | Parse PDF and index text embeddings for semantic search |
| [PDF Elements Embedding](examples/pdf_elements_embedding) | Extract text and images from PDFs; embed text with SentenceTransformers and images with CLIP; store in Qdrant for multimodal search |
| [Manuals LLM Extraction](examples/manuals_llm_extraction) | Extract structured information from a manual using LLM |
| [Amazon S3 Embedding](examples/amazon_s3_embedding) | Index text documents from Amazon S3 |
| [Azure Blob Storage Embedding](examples/azure_blob_embedding) | Index text documents from Azure Blob Storage |
| [Google Drive Text Embedding](examples/gdrive_text_embedding) | Index text documents from Google Drive |
| [Meeting Notes to Knowledge Graph](examples/meeting_notes_graph) | Extract structured meeting info from Google Drive and build a knowledge graph |
| [Docs to Knowledge Graph](examples/docs_to_knowledge_graph) | Extract relationships from Markdown documents and build a knowledge graph |
| [Embeddings to Qdrant](examples/text_embedding_qdrant) | Index documents in a Qdrant collection for semantic search |
| [Embeddings to LanceDB](examples/text_embedding_lancedb) | Index documents in a LanceDB collection for semantic search |
| [FastAPI Server with Docker](examples/fastapi_server_docker) | Run the semantic search server in a Dockerized FastAPI setup |
| [Product Recommendation](examples/product_recommendation) | Build real-time product recommendations with LLM and graph database|
| [Image Search with Vision API](examples/image_search) | Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend|
| [Face Recognition](examples/face_recognition) | Recognize faces in images and build embedding index |
| [Paper Metadata](examples/paper_metadata) | Index papers in PDF files, and build metadata tables for each paper |
| [Multi Format Indexing](examples/multi_format_indexing) | Build visual document index from PDFs and images with ColPali for semantic search |
| [Custom Source HackerNews](examples/custom_source_hn) | Index HackerNews threads and comments, using *CocoIndex Custom Source* |
| [Custom Output Files](examples/custom_output_files) | Convert markdown files to HTML files and save them to a local directory, using *CocoIndex Custom Targets* |
| [Patient intake form extraction](examples/patient_intake_extraction) | Use LLM to extract structured data from patient intake forms with different formats |
| [HackerNews Trending Topics](examples/hn_trending_topics) | Extract trending topics from HackerNews threads and comments, using *CocoIndex Custom Source* and LLM |
| [Patient Intake Form Extraction with BAML](examples/patient_intake_extraction_baml) | Extract structured data from patient intake forms using BAML |
| [Patient Intake Form Extraction with DSPy](examples/patient_intake_extraction_dspy) | Extract structured data from patient intake forms using DSPy |

More coming and stay tuned üëÄ!

## üìñ Documentation

For detailed documentation, visit [CocoIndex Documentation](https://cocoindex.io/docs), including a [Quickstart guide](https://cocoindex.io/docs/getting_started/quickstart).

## ü§ù Contributing

We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our [contributing guide](https://cocoindex.io/docs/about/contributing).

## üë• Community

Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it&#039;s code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.

Join our community here:

- üåü [Star us on GitHub](https://github.com/cocoindex-io/cocoindex)
- üëã [Join our Discord community](https://discord.com/invite/zpA9S2DR7s)
- ‚ñ∂Ô∏è [Subscribe to our YouTube channel](https://www.youtube.com/@cocoindex-io)
- üìú [Read our blog posts](https://cocoindex.io/blogs/)

## Support us

We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo [![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex) to stay tuned and help us grow.

## License

CocoIndex is Apache 2.0 licensed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>