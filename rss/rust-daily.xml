<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Fri, 12 Dec 2025 00:05:36 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 23,777</p>
            <p>Forks: 2,132</p>
            <p>Stars today: 443 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/goose-oss&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;&gt;
     &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.

[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)

# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)
- [Responsible AI-Assisted Coding Guide](https://github.com/block/goose/blob/main/HOWTOAI.md)
- [Governance](https://github.com/block/goose/blob/main/GOVERNANCE.md)

## Need Help?
- [Diagnostics &amp; Reporting](https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting)
- [Known Issues](https://block.github.io/goose/docs/troubleshooting/known-issues)

# a little goose humor ü¶¢

&gt; Why did the developer choose goose as their AI agent?
&gt; 
&gt; Because it always helps them &quot;migrate&quot; their code to production! üöÄ

# goose around with us  
- [Discord](https://discord.gg/goose-oss)
- [YouTube](https://www.youtube.com/@goose-oss)
- [LinkedIn](https://www.linkedin.com/company/goose-oss)
- [Twitter/X](https://x.com/goose_oss)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tempoxyz/tempo]]></title>
            <link>https://github.com/tempoxyz/tempo</link>
            <guid>https://github.com/tempoxyz/tempo</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[the blockchain for payments]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tempoxyz/tempo">tempoxyz/tempo</a></h1>
            <p>the blockchain for payments</p>
            <p>Language: Rust</p>
            <p>Stars: 332</p>
            <p>Forks: 58</p>
            <p>Stars today: 52 stars today</p>
            <h2>README</h2><pre>&lt;br&gt;
&lt;br&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://tempo.xyz&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/tempoxyz/.github/refs/heads/main/assets/combomark-dark.svg&quot;&gt;
      &lt;img alt=&quot;tempo combomark&quot; src=&quot;https://raw.githubusercontent.com/tempoxyz/.github/refs/heads/main/assets/combomark-bright.svg&quot; width=&quot;auto&quot; height=&quot;120&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;
&lt;br&gt;

# Tempo

The blockchain for payments at scale.

[Tempo](https://docs.tempo.xyz/) is a blockchain designed specifically for stablecoin payments. Its architecture focuses on high throughput, low cost, and features that financial institutions, payment service providers, and fintech platforms expect from modern payment infrastructure.

You can get started today by integrating with the [Tempo testnet](https://docs.tempo.xyz/quickstart/integrate-tempo), [building on Tempo](https://docs.tempo.xyz/guide/use-accounts), [running a Tempo node](https://docs.tempo.xyz/guide/node), reading the [Tempo protocol specs](https://docs.tempo.xyz/protocol) or by [building with Tempo SDKs](https://docs.tempo.xyz/sdk).

## What makes Tempo different

- [TIP‚Äë20 token standard](https://docs.tempo.xyz/protocol/tip20/overview) (enshrined ERC‚Äë20 extensions)

  - Predictable payment throughput via dedicated payment lanes reserved for TIP‚Äë20 transfers (eliminates noisy‚Äëneighbor contention).
  - Native reconciliation with on‚Äëtransfer memos and commitment patterns (hash/locator) for off‚Äëchain PII and large data.
  - Built‚Äëin compliance through [TIP‚Äë403 Policy Registry](https://docs.tempo.xyz/protocol/tip403/overview): single policy shared across multiple tokens, updated once and enforced everywhere.

- Low, predictable fees in [stablecoins](https://docs.tempo.xyz/learn/stablecoins)

  - Users pay gas directly in USD-stablecoins at launch; the [Fee AMM](https://docs.tempo.xyz/protocol/fees/fee-amm#fee-amm-overview) automatically converts to the validator‚Äôs preferred stablecoin.
  - TIP‚Äë20 transfers target sub‚Äëmillidollar costs (&lt;$0.001).

- [Tempo Transactions](https://docs.tempo.xyz/guide/tempo-transaction) (native ‚Äúsmart accounts‚Äù)

  - Batched payments: atomic multi‚Äëoperation payouts (payroll, settlements, refunds).
  - Fee sponsorship: apps can pay users&#039; gas to streamline onboarding and flows.
  - Scheduled payments: protocol‚Äëlevel time windows for recurring and timed disbursements.
  - Modern authentication: passkeys via WebAuthn/P256 (biometric sign‚Äëin, secure enclave, cross‚Äëdevice sync).

- Performance and finality

  - Built on the [Reth SDK](https://github.com/paradigmxyz/reth), the most performant and flexible EVM (Ethereum Virtual Machine) execution client.
  - Simplex Consensus (via [Commonware](https://commonware.xyz/)): fast, sub‚Äësecond finality in normal conditions; graceful degradation under adverse networks.

- Coming soon

  - On‚Äëchain FX and non‚ÄëUSD stablecoin support for direct on‚Äëchain liquidity; pay fees in more currencies.
  - Native private token standard: opt‚Äëin privacy for balances/transfers coexisting with issuer compliance and auditability.

## What makes Tempo familiar

- Fully compatible with the Ethereum Virtual Machine (EVM), targeting the Osaka hardfork.
- Deploy and interact with smart contracts using the same tools, languages, and frameworks used on Ethereum, such as Solidity, Foundry, and Hardhat.
- All Ethereum JSON-RPC methods work out of the box.

While the execution environment mirrors Ethereum&#039;s, Tempo introduces some differences optimized for payments, described [here](https://docs.tempo.xyz/quickstart/evm-compatibility).

## Getting Started

### As a user

You can connect to Tempo&#039;s public testnet using the following details:

| Property           | Value                           |
| ------------------ | ------------------------------- |
| **Network Name**   | Tempo Testnet (Andantino)       |
| **Currency**       | `USD`                           |
| **Chain ID**       | `42429`                         |
| **HTTP URL**       | `https://rpc.testnet.tempo.xyz` |
| **WebSocket URL**  | `wss://rpc.testnet.tempo.xyz`   |
| **Block Explorer** | `https://explore.tempo.xyz`     |

Next, grab some stablecoins to test with from Tempo&#039;s [Faucet](https://docs.tempo.xyz/quickstart/faucet#faucet).

Alternatively, use [`cast`](https://github.com/tempoxyz/tempo-foundry):

```bash
cast rpc tempo_fundAddress &lt;ADDRESS&gt; --rpc-url https://rpc.testnet.tempo.xyz
```

### As an operator

We provide three different installation paths: installing a pre-built binary, building from source or using our provided Docker image.

- [Pre-built Binary](https://docs.tempo.xyz/guide/node/installation#pre-built-binary)
- [Build from Source](https://docs.tempo.xyz/guide/node/installation#build-from-source)
- [Docker](https://docs.tempo.xyz/guide/node/installation#docker)

See the [Tempo documentation](https://docs.tempo.xyz/guide/node) for instructions on how to install and run Tempo.

### As a developer

Tempo has several SDKs to help you get started building on Tempo:

- [TypeScript](https://docs.tempo.xyz/sdk/typescript)
- [Rust](https://docs.tempo.xyz/sdk/rust)
- [Go](https://docs.tempo.xyz/sdk/go)
- [Foundry](https://docs.tempo.xyz/sdk/foundry)

Want to contribute?

First, clone the repository:

```
git clone https://github.com/tempoxyz/tempo
cd tempo
```

Next, install [`just`](https://github.com/casey/just?tab=readme-ov-file#packages).

Install the dependencies:

```bash
just
```

Build Tempo:

```bash
just build-all
```

Run the tests:

```bash
cargo nextest run
```

Start a `localnet`:

```bash
just localnet
```

## Contributing

Our contributor guidelines can be found in [`CONTRIBUTING.md`](https://github.com/tempoxyz/tempo?tab=contributing-ov-file).

## Security

See [`SECURITY.md`](https://github.com/tempoxyz/tempo?tab=security-ov-file). Note: Tempo is still undergoing audit and does not have an active bug bounty. Submissions will not be eligible for a bounty until audits have concluded.

## License

Licensed under either of [Apache License](./LICENSE-APACHE), Version
2.0 or [MIT License](./LICENSE-MIT) at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in these crates by you, as defined in the Apache-2.0 license,
shall be dual licensed as above, without any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustdesk/rustdesk]]></title>
            <link>https://github.com/rustdesk/rustdesk</link>
            <guid>https://github.com/rustdesk/rustdesk</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustdesk/rustdesk">rustdesk/rustdesk</a></h1>
            <p>An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.</p>
            <p>Language: Rust</p>
            <p>Stars: 103,927</p>
            <p>Forks: 15,338</p>
            <p>Stars today: 84 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;res/logo-header.svg&quot; alt=&quot;RustDesk - Your remote desktop&quot;&gt;&lt;br&gt;
  &lt;a href=&quot;#raw-steps-to-build&quot;&gt;Build&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#how-to-build-with-docker&quot;&gt;Docker&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#file-structure&quot;&gt;Structure&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#snapshot&quot;&gt;Snapshot&lt;/a&gt;&lt;br&gt;
  [&lt;a href=&quot;docs/README-UA.md&quot;&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href=&quot;docs/README-CS.md&quot;&gt;ƒçesky&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ZH.md&quot;&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href=&quot;docs/README-HU.md&quot;&gt;Magyar&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ES.md&quot;&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FA.md&quot;&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FR.md&quot;&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DE.md&quot;&gt;Deutsch&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PL.md&quot;&gt;Polski&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ID.md&quot;&gt;Indonesian&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FI.md&quot;&gt;Suomi&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ML.md&quot;&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href=&quot;docs/README-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NL.md&quot;&gt;Nederlands&lt;/a&gt;] | [&lt;a href=&quot;docs/README-IT.md&quot;&gt;Italiano&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PTBR.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href=&quot;docs/README-EO.md&quot;&gt;Esperanto&lt;/a&gt;] | [&lt;a href=&quot;docs/README-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href=&quot;docs/README-AR.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href=&quot;docs/README-VN.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DA.md&quot;&gt;Dansk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-GR.md&quot;&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href=&quot;docs/README-TR.md&quot;&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NO.md&quot;&gt;Norsk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RO.md&quot;&gt;Rom√¢nƒÉ&lt;/a&gt;]&lt;br&gt;
  &lt;b&gt;We need your help to translate this README, &lt;a href=&quot;https://github.com/rustdesk/rustdesk/tree/master/src/lang&quot;&gt;RustDesk UI&lt;/a&gt; and &lt;a href=&quot;https://github.com/rustdesk/doc.rustdesk.com&quot;&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt;
&lt;/p&gt;

&gt; [!Caution]
&gt; **Misuse Disclaimer:** &lt;br&gt;
&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.


Chat with us: [Discord](https://discord.gg/nDceKgxnkV) | [Twitter](https://twitter.com/rustdesk) | [Reddit](https://www.reddit.com/r/rustdesk) | [YouTube](https://www.youtube.com/@rustdesk)

[![RustDesk Server Pro](https://img.shields.io/badge/RustDesk%20Server%20Pro-Advanced%20Features-blue)](https://rustdesk.com/pricing.html)

Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, [set up your own](https://rustdesk.com/server), or [write your own rendezvous/relay server](https://github.com/rustdesk/rustdesk-server-demo).

![image](https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png)

RustDesk welcomes contribution from everyone. See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for help getting started.

[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)

[**BINARY DOWNLOAD**](https://github.com/rustdesk/rustdesk/releases)

[**NIGHTLY BUILD**](https://github.com/rustdesk/rustdesk/releases/tag/nightly)

[&lt;img src=&quot;https://f-droid.org/badge/get-it-on.png&quot;
    alt=&quot;Get it on F-Droid&quot;
    height=&quot;80&quot;&gt;](https://f-droid.org/en/packages/com.carriez.flutter_hbb)
[&lt;img src=&quot;https://flathub.org/api/badge?svg&amp;locale=en&quot;
    alt=&quot;Get it on Flathub&quot;
    height=&quot;80&quot;&gt;](https://flathub.org/apps/com.rustdesk.RustDesk)

## Dependencies

Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our [CI](https://github.com/rustdesk/rustdesk/blob/master/.github/workflows/flutter-build.yml) for building Flutter version.

Please download Sciter dynamic library yourself.

[Windows](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll) |
[Linux](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so) |
[macOS](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib)

## Raw Steps to build

- Prepare your Rust development env and C++ build env

- Install [vcpkg](https://github.com/microsoft/vcpkg), and set `VCPKG_ROOT` env variable correctly

  - Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static
  - Linux/macOS: vcpkg install libvpx libyuv opus aom

- run `cargo run`

## [Build](https://rustdesk.com/docs/en/dev/build/)

## How to Build on Linux

### Ubuntu 18 (Debian 10)

```sh
sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
```

### openSUSE Tumbleweed

```sh
sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
```

### Fedora 28 (CentOS 8)

```sh
sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
```

### Arch (Manjaro)

```sh
sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
```

### Install vcpkg

```sh
git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
```

### Fix libvpx (For Fedora)

```sh
cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i &#039;s/CFLAGS+=-I/CFLAGS+=-fPIC -I/g&#039; Makefile
sed -i &#039;s/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g&#039; Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
```

### Build

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
```

## How to build with Docker

Begin by cloning the repository and building the Docker container:

```sh
git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t &quot;rustdesk-builder&quot; .
```

Then, each time you need to build the application, run the following command:

```sh
docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=&quot;$(id -u)&quot; -e PGID=&quot;$(id -g)&quot; rustdesk-builder
```

Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the `&lt;OPTIONAL-ARGS&gt;` position. For instance, if you wanted to build an optimized release version, you would run the command above followed by `--release`. The resulting executable will be available in the target folder on your system, and can be run with:

```sh
target/debug/rustdesk
```

Or, if you&#039;re running a release executable:

```sh
target/release/rustdesk
```

Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as `install` or `run` are not currently supported via this method as they would install or run the program inside the container instead of the host.

## File Structure

- **[libs/hbb_common](https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common)**: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions
- **[libs/scrap](https://github.com/rustdesk/rustdesk/tree/master/libs/scrap)**: screen capture
- **[libs/enigo](https://github.com/rustdesk/rustdesk/tree/master/libs/enigo)**: platform specific keyboard/mouse control
- **[libs/clipboard](https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard)**: file copy and paste implementation for Windows, Linux, macOS.
- **[src/ui](https://github.com/rustdesk/rustdesk/tree/master/src/ui)**: obsolete Sciter UI (deprecated)
- **[src/server](https://github.com/rustdesk/rustdesk/tree/master/src/server)**: audio/clipboard/input/video services, and network connections
- **[src/client.rs](https://github.com/rustdesk/rustdesk/tree/master/src/client.rs)**: start a peer connection
- **[src/rendezvous_mediator.rs](https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs)**: Communicate with [rustdesk-server](https://github.com/rustdesk/rustdesk-server), wait for remote direct (TCP hole punching) or relayed connection
- **[src/platform](https://github.com/rustdesk/rustdesk/tree/master/src/platform)**: platform specific code
- **[flutter](https://github.com/rustdesk/rustdesk/tree/master/flutter)**: Flutter code for desktop and mobile
- **[flutter/web/js](https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js)**: JavaScript for Flutter web client

## Screenshots

![Connection Manager](https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651)

![Connected to a Windows PC](https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea)

![File Transfer](https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad)

![TCP Tunneling](https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cocoindex-io/cocoindex]]></title>
            <link>https://github.com/cocoindex-io/cocoindex</link>
            <guid>https://github.com/cocoindex-io/cocoindex</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cocoindex-io/cocoindex">cocoindex-io/cocoindex</a></h1>
            <p>Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!</p>
            <p>Language: Rust</p>
            <p>Stars: 3,676</p>
            <p>Forks: 296</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/github.svg&quot; alt=&quot;CocoIndex&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Data transformation for AI&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;

[![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex)
[![Documentation](https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;logoColor=00B9FF)](https://cocoindex.io/docs/getting_started/quickstart)
[![License](https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white)](https://opensource.org/licenses/Apache-2.0)
[![PyPI version](https://img.shields.io/pypi/v/cocoindex?color=5B5BD6)](https://pypi.org/project/cocoindex/)
&lt;!--[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex) --&gt;
[![PyPI Downloads](https://static.pepy.tech/badge/cocoindex/month)](https://pepy.tech/projects/cocoindex)
[![CI](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml)
[![release](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml)
[![Discord](https://img.shields.io/discord/1314801574169673738?logo=discord&amp;color=5B5BD6&amp;logoColor=white)](https://discord.com/invite/zpA9S2DR7s)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/13939&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13939&quot; alt=&quot;cocoindex-io%2Fcocoindex | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box.  Exceptional developer velocity. Production-ready at day 0.

‚≠ê Drop a star to help us grow!

&lt;div align=&quot;center&quot;&gt;

&lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
[Deutsch](https://readme-i18n.com/cocoindex-io/cocoindex?lang=de) |
[English](https://readme-i18n.com/cocoindex-io/cocoindex?lang=en) |
[Espa√±ol](https://readme-i18n.com/cocoindex-io/cocoindex?lang=es) |
[fran√ßais](https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr) |
[Êó•Êú¨Ë™û](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja) |
[ÌïúÍµ≠Ïñ¥](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko) |
[Portugu√™s](https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt) |
[–†—É—Å—Å–∫–∏–π](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru) |
[‰∏≠Êñá](https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh)

&lt;/div&gt;

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/transformation.svg&quot; alt=&quot;CocoIndex Transformation&quot;&gt;
&lt;/p&gt;

&lt;/br&gt;

CocoIndex makes it effortless to transform data with AI, and keep source data and target in sync. Whether you‚Äôre building a vector index, creating knowledge graphs for context engineering or performing any custom data transformations ‚Äî goes beyond SQL.

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;CocoIndex Features&quot; src=&quot;https://cocoindex.io/images/venn2.svg&quot; /&gt;
&lt;/p&gt;

&lt;/br&gt;

## Exceptional velocity

Just declare transformation in dataflow with ~100 lines of python

```python
# import
data[&#039;content&#039;] = flow_builder.add_source(...)

# transform
data[&#039;out&#039;] = data[&#039;content&#039;]
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
```

CocoIndex follows the idea of [Dataflow](https://en.wikipedia.org/wiki/Dataflow_programming) programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.

**Particularly**, developers don&#039;t explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.

## Plug-and-Play Building Blocks

Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components - as easy as assembling building blocks.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/components.svg&quot; alt=&quot;CocoIndex Features&quot;&gt;
&lt;/p&gt;

## Data Freshness

CocoIndex keep source data and target in sync effortlessly.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6&quot; alt=&quot;Incremental Processing&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

It has out-of-box support for incremental indexing:

- minimal recomputation on source or logic change.
- (re-)processing necessary portions; reuse cache when possible

## Quick Start

If you&#039;re new to CocoIndex, we recommend checking out

- üìñ [Documentation](https://cocoindex.io/docs)
- ‚ö°  [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart)
- üé¨ [Quick Start Video Tutorial](https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT)

### Setup

1. Install CocoIndex Python library

```sh
pip install -U cocoindex
```

2. [Install Postgres](https://cocoindex.io/docs/getting_started/installation#-install-postgres) if you don&#039;t have one. CocoIndex uses it for incremental processing.

3. (Optional) Install Claude Code skill for enhanced development experience. Run these commands in [Claude Code](https://claude.com/claude-code):

```
/plugin marketplace add cocoindex-io/cocoindex-claude
/plugin install cocoindex-skills@cocoindex
```

## Define data flow

Follow [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart) to define your first indexing flow. An example flow looks like:

```python
@cocoindex.flow_def(name=&quot;TextEmbedding&quot;)
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope[&quot;documents&quot;] = flow_builder.add_source(cocoindex.sources.LocalFile(path=&quot;markdown_files&quot;))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope[&quot;documents&quot;].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc[&quot;chunks&quot;] = doc[&quot;content&quot;].transform(
            cocoindex.functions.SplitRecursively(),
            language=&quot;markdown&quot;, chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc[&quot;chunks&quot;].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk[&quot;embedding&quot;] = chunk[&quot;text&quot;].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model=&quot;sentence-transformers/all-MiniLM-L6-v2&quot;))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc[&quot;filename&quot;], location=chunk[&quot;location&quot;],
                                   text=chunk[&quot;text&quot;], embedding=chunk[&quot;embedding&quot;])

    # Export collected data to a vector index.
    doc_embeddings.export(
        &quot;doc_embeddings&quot;,
        cocoindex.targets.Postgres(),
        primary_key_fields=[&quot;filename&quot;, &quot;location&quot;],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name=&quot;embedding&quot;,
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
```

It defines an index flow like this:

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;400&quot; alt=&quot;Data Flow&quot; src=&quot;https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463&quot; /&gt;
&lt;/p&gt;

## üöÄ Examples and demo

| Example | Description |
|---------|-------------|
| [Text Embedding](examples/text_embedding) | Index text documents with embeddings for semantic search |
| [Code Embedding](examples/code_embedding) | Index code embeddings for semantic search |
| [PDF Embedding](examples/pdf_embedding) | Parse PDF and index text embeddings for semantic search |
| [PDF Elements Embedding](examples/pdf_elements_embedding) | Extract text and images from PDFs; embed text with SentenceTransformers and images with CLIP; store in Qdrant for multimodal search |
| [Manuals LLM Extraction](examples/manuals_llm_extraction) | Extract structured information from a manual using LLM |
| [Amazon S3 Embedding](examples/amazon_s3_embedding) | Index text documents from Amazon S3 |
| [Azure Blob Storage Embedding](examples/azure_blob_embedding) | Index text documents from Azure Blob Storage |
| [Google Drive Text Embedding](examples/gdrive_text_embedding) | Index text documents from Google Drive |
| [Meeting Notes to Knowledge Graph](examples/meeting_notes_graph) | Extract structured meeting info from Google Drive and build a knowledge graph |
| [Docs to Knowledge Graph](examples/docs_to_knowledge_graph) | Extract relationships from Markdown documents and build a knowledge graph |
| [Embeddings to Qdrant](examples/text_embedding_qdrant) | Index documents in a Qdrant collection for semantic search |
| [Embeddings to LanceDB](examples/text_embedding_lancedb) | Index documents in a LanceDB collection for semantic search |
| [FastAPI Server with Docker](examples/fastapi_server_docker) | Run the semantic search server in a Dockerized FastAPI setup |
| [Product Recommendation](examples/product_recommendation) | Build real-time product recommendations with LLM and graph database|
| [Image Search with Vision API](examples/image_search) | Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend|
| [Face Recognition](examples/face_recognition) | Recognize faces in images and build embedding index |
| [Paper Metadata](examples/paper_metadata) | Index papers in PDF files, and build metadata tables for each paper |
| [Multi Format Indexing](examples/multi_format_indexing) | Build visual document index from PDFs and images with ColPali for semantic search |
| [Custom Source HackerNews](examples/custom_source_hn) | Index HackerNews threads and comments, using *CocoIndex Custom Source* |
| [Custom Output Files](examples/custom_output_files) | Convert markdown files to HTML files and save them to a local directory, using *CocoIndex Custom Targets* |
| [Patient intake form extraction](examples/patient_intake_extraction) | Use LLM to extract structured data from patient intake forms with different formats |
| [HackerNews Trending Topics](examples/hn_trending_topics) | Extract trending topics from HackerNews threads and comments, using *CocoIndex Custom Source* and LLM |
| [Patient Intake Form Extraction with BAML](examples/patient_intake_extraction_baml) | Extract structured data from patient intake forms using BAML |
| [Patient Intake Form Extraction with DSPy](examples/patient_intake_extraction_dspy) | Extract structured data from patient intake forms using DSPy |

More coming and stay tuned üëÄ!

## üìñ Documentation

For detailed documentation, visit [CocoIndex Documentation](https://cocoindex.io/docs), including a [Quickstart guide](https://cocoindex.io/docs/getting_started/quickstart).

## ü§ù Contributing

We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our [contributing guide](https://cocoindex.io/docs/about/contributing).

## üë• Community

Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it&#039;s code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.

Join our community here:

- üåü [Star us on GitHub](https://github.com/cocoindex-io/cocoindex)
- üëã [Join our Discord community](https://discord.com/invite/zpA9S2DR7s)
- ‚ñ∂Ô∏è [Subscribe to our YouTube channel](https://www.youtube.com/@cocoindex-io)
- üìú [Read our blog posts](https://cocoindex.io/blogs/)

## Support us

We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo [![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex) to stay tuned and help us grow.

## License

CocoIndex is Apache 2.0 licensed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tursodatabase/turso]]></title>
            <link>https://github.com/tursodatabase/turso</link>
            <guid>https://github.com/tursodatabase/turso</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[Turso is an in-process SQL database, compatible with SQLite.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tursodatabase/turso">tursodatabase/turso</a></h1>
            <p>Turso is an in-process SQL database, compatible with SQLite.</p>
            <p>Language: Rust</p>
            <p>Stars: 15,038</p>
            <p>Forks: 624</p>
            <p>Stars today: 52 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/turso.png&quot; alt=&quot;Turso Database&quot; width=&quot;800&quot;/&gt;
  &lt;h1 align=&quot;center&quot;&gt;Turso Database&lt;/h1&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  An in-process SQL database, compatible with SQLite.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a title=&quot;Build Status&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/actions/workflows/rust.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/tursodatabase/turso/rust.yml?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;Releases&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/tursodatabase/turso?style=flat-square&amp;color=9CF&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;Rust&quot; target=&quot;_blank&quot; href=&quot;https://crates.io/crates/turso&quot;&gt;&lt;img alt=&quot;Crate&quot; src=&quot;https://img.shields.io/crates/v/turso&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;JavaScript&quot; target=&quot;_blank&quot; href=&quot;https://www.npmjs.com/package/@tursodatabase/database&quot;&gt;&lt;img alt=&quot;NPM&quot; src=&quot;https://img.shields.io/npm/v/@tursodatabase/database&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;Python&quot; target=&quot;_blank&quot; href=&quot;https://pypi.org/project/pyturso/&quot;&gt;&lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/pypi/v/pyturso&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;Java&quot; target=&quot;_blank&quot; href=&quot;https://central.sonatype.com/artifact/tech.turso/turso&quot;&gt;&lt;img alt=&quot;Maven Central&quot; src=&quot;https://img.shields.io/maven-central/v/tech.turso/turso&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;MIT&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/blob/main/LICENSE.md&quot;&gt;&lt;img src=&quot;http://img.shields.io/badge/license-MIT-orange.svg?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a title=&quot;GitHub Pull Requests&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/pulls&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr-closed/tursodatabase/turso.svg?style=flat-square&amp;color=FF9966&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;GitHub Commits&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/commits/main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/commit-activity/m/tursodatabase/turso.svg?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;Last Commit&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/commits/main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/last-commit/tursodatabase/turso.svg?style=flat-square&amp;color=FF9900&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a title=&quot;Developer&#039;s Discord&quot; target=&quot;_blank&quot; href=&quot;https://discord.gg/jgjmyYgHwB&quot;&gt;&lt;img alt=&quot;Chat with the Core Developers on Discord&quot; src=&quot;https://img.shields.io/discord/1258658826257961020?label=Discord&amp;logo=Discord&amp;style=social&amp;label=Core%20Developers&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a title=&quot;Users&#039;s Discord&quot; target=&quot;_blank&quot; href=&quot;https://tur.so/discord&quot;&gt;&lt;img alt=&quot;Chat with other users of Turso (and Turso Cloud) on Discord&quot; src=&quot;https://img.shields.io/discord/933071162680958986?label=Discord&amp;logo=Discord&amp;style=social&amp;label=Users&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

---

## About

Turso Database is an in-process SQL database written in Rust, compatible with SQLite.

&gt; **‚ö†Ô∏è Warning:** This software is in BETA. It may still contain bugs and unexpected behavior. Use caution with production data and ensure you have backups.

## Features and Roadmap

* **SQLite compatibility** for SQL dialect, file formats, and the C API [see [document](COMPAT.md) for details]
* **Change data capture (CDC)** for real-time tracking of database changes.
* **Multi-language support** for
  * [Go](https://github.com/tursodatabase/turso-go)
  * [JavaScript](bindings/javascript)
  * [Java](bindings/java)
  * [Python](bindings/python)
  * [Rust](bindings/rust)
  * [WebAssembly](bindings/javascript)
* **Asynchronous I/O** support on Linux with `io_uring`
* **Cross-platform** support for Linux, macOS, Windows and browsers (through WebAssembly)
* **Vector support** support including exact search and vector manipulation
* **Improved schema management** including extended `ALTER` support and faster schema changes.

The database has the following experimental features:

* **`BEGIN CONCURRENT`** for improved write throughput using multi-version concurrency control (MVCC).
* **Encryption at rest** for protecting the data locally.
* **Incremental computation** using DBSP for incremental view mainatenance and query subscriptions.

The following features are on our current roadmap:

* **Vector indexing** for fast approximate vector search, similar to [libSQL vector search](https://turso.tech/vector).

## Getting Started

Please see the [Turso Database Manual](docs/manual.md) for more information.

&lt;details&gt;
&lt;summary&gt;üíª Command Line&lt;/summary&gt;
&lt;br&gt;
You can install the latest `turso` release with:

```shell
curl --proto &#039;=https&#039; --tlsv1.2 -LsSf \
  https://github.com/tursodatabase/turso/releases/latest/download/turso_cli-installer.sh | sh
```

Then launch the interactive shell:

```shell
$ tursodb
```

This will start the Turso interactive shell where you can execute SQL statements:

```console
Turso
Enter &quot;.help&quot; for usage hints.
Connected to a transient in-memory database.
Use &quot;.open FILENAME&quot; to reopen on a persistent database
turso&gt; CREATE TABLE users (id INT, username TEXT);
turso&gt; INSERT INTO users VALUES (1, &#039;alice&#039;);
turso&gt; INSERT INTO users VALUES (2, &#039;bob&#039;);
turso&gt; SELECT * FROM users;
1|alice
2|bob
```

You can also build and run the latest development version with:

```shell
cargo run
```

If you like docker, we got you covered. Simply run this in the root folder:

```bash
make docker-cli-build &amp;&amp; \
make docker-cli-run
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ü¶Ä Rust&lt;/summary&gt;
&lt;br&gt;

```console
cargo add turso
```

Example usage:

```rust
let db = Builder::new_local(&quot;sqlite.db&quot;).build().await?;
let conn = db.connect()?;

let res = conn.query(&quot;SELECT * FROM users&quot;, ()).await?;
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;‚ú® JavaScript&lt;/summary&gt;
&lt;br&gt;

```console
npm i @tursodatabase/database
```

Example usage:

```js
import { connect } from &#039;@tursodatabase/database&#039;;

const db = await connect(&#039;sqlite.db&#039;);
const stmt = db.prepare(&#039;SELECT * FROM users&#039;);
const users = stmt.all();
console.log(users);
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üêç Python&lt;/summary&gt;
&lt;br&gt;

```console
uv pip install pyturso
```

Example usage:

```python
import turso

con = turso.connect(&quot;sqlite.db&quot;)
cur = con.cursor()
res = cur.execute(&quot;SELECT * FROM users&quot;)
print(res.fetchone())
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ü¶´ Go&lt;/summary&gt;
&lt;br&gt;

```console
go get github.com/tursodatabase/turso-go
go install github.com/tursodatabase/turso-go
```

Example usage:
```go
import (
    &quot;database/sql&quot;
    _ &quot;github.com/tursodatabase/turso-go&quot;
)

conn, _ = sql.Open(&quot;turso&quot;, &quot;sqlite.db&quot;)
defer conn.Close()

stmt, _ := conn.Prepare(&quot;select * from users&quot;)
defer stmt.Close()

rows, _ = stmt.Query()
for rows.Next() {
    var id int
    var username string
    _ := rows.Scan(&amp;id, &amp;username)
    fmt.Printf(&quot;User: ID: %d, Username: %s\n&quot;, id, username)
}
```
&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;‚òïÔ∏è Java&lt;/summary&gt;
&lt;br&gt;

We integrated Turso Database into JDBC. For detailed instructions on how to use Turso Database with java, please refer to
the [README.md under bindings/java](bindings/java/README.md).
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ü§ñ MCP Server Mode&lt;/summary&gt;
&lt;br&gt;


The Turso CLI includes a built-in [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) server that allows AI assistants to interact with your databases.

Start the MCP server with:

```shell
tursodb your_database.db --mcp
```

### Configuration

Add Turso to your MCP client configuration:

```json
{
  &quot;mcpServers&quot;: {
    &quot;turso&quot;: {
      &quot;command&quot;: &quot;/path/to/.turso/tursodb&quot;,
      &quot;args&quot;: [&quot;/path/to/your/database.db&quot;, &quot;--mcp&quot;]
    }
  }
}
```

### Available Tools

The MCP server provides nine tools for database interaction:

1. **`open_database`** - Open a new database
2. **`current_database`** - Describe the current database
3. **`list_tables`** - List all tables in the database
4. **`describe_table`** - Describe the structure of a specific table
5. **`execute_query`** - Execute read-only SELECT queries
6. **`insert_data`** - Insert new data into tables
7. **`update_data`** - Update existing data in tables
8. **`delete_data`** - Delete data from tables
9. **`schema_change`** - Execute schema modification statements (CREATE TABLE, ALTER TABLE, DROP TABLE)

Once connected, you can ask your AI assistant:

- &quot;Show me all tables in the database&quot;
- &quot;What&#039;s the schema for the users table?&quot;
- &quot;Find all posts with more than 100 upvotes&quot;
- &quot;Insert a new user with name &#039;Alice&#039; and email &#039;alice@example.com&#039;&quot;

### MCP Clients

&lt;details&gt;
&lt;summary&gt;Claude Code&lt;/summary&gt;

If you&#039;re using [Claude Code](https://claude.ai/code), you can easily connect to your Turso MCP server using the built-in MCP management commands:

#### Quick Setup

1. **Add the MCP server** to Claude Code:

   ```bash
   claude mcp add my-database -- tursodb ./path/to/your/database.db --mcp
   ```

2. **Restart Claude Code** to activate the connection

3. **Start querying** your database through natural language!

#### Command Breakdown

```bash
claude mcp add my-database -- tursodb ./path/to/your/database.db --mcp
#              ‚Üë            ‚Üë       ‚Üë                           ‚Üë
#              |            |       |                           |
#              Name         |       Database path               MCP flag
#                          Separator
```

- **`my-database`** - Choose any name for your MCP server
- **`--`** - Required separator between Claude options and your command
- **`tursodb`** - The Turso database CLI
- **`./path/to/your/database.db`** - Path to your SQLite database file
- **`--mcp`** - Enables MCP server mode

#### Example Usage

```bash
# For a local project database
cd /your/project
claude mcp add my-project-db -- tursodb ./data/app.db --mcp

# For an absolute path
claude mcp add analytics-db -- tursodb /Users/you/databases/analytics.db --mcp

# For a specific project (local scope)
claude mcp add project-db --local -- tursodb ./database.db --mcp
```

#### Managing MCP Servers

```bash
# List all configured MCP servers
claude mcp list

# Get details about a specific server
claude mcp get my-database

# Remove an MCP server
claude mcp remove my-database
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Claude Desktop&lt;/summary&gt;

For Claude Desktop, add the configuration to your `claude_desktop_config.json` file:

```json
{
  &quot;mcpServers&quot;: {
    &quot;turso&quot;: {
      &quot;command&quot;: &quot;/path/to/.turso/tursodb&quot;,
      &quot;args&quot;: [&quot;./path/to/your/database.db.db&quot;, &quot;--mcp&quot;]
    }
  }
}
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Cursor&lt;/summary&gt;

For Cursor, configure MCP in your settings:

1. Open Cursor settings
2. Navigate to Extensions ‚Üí MCP
3. Add a new server with:
   - **Name**: `turso`
   - **Command**: `/path/to/.turso/tursodb`
   - **Args**: `[&quot;./path/to/your/database.db.db&quot;, &quot;--mcp&quot;]`

Alternatively, you can add it to your Cursor configuration file directly.

&lt;/details&gt;

### Direct JSON-RPC Usage

The MCP server runs as a single process that handles multiple JSON-RPC requests over stdin/stdout. Here&#039;s how to interact with it directly:

#### Example with In-Memory Database

```bash
cat &lt;&lt; &#039;EOF&#039; | tursodb --mcp
{&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;id&quot;: 1, &quot;method&quot;: &quot;initialize&quot;, &quot;params&quot;: {&quot;protocolVersion&quot;: &quot;2024-11-05&quot;, &quot;capabilities&quot;: {}, &quot;clientInfo&quot;: {&quot;name&quot;: &quot;client&quot;, &quot;version&quot;: &quot;1.0&quot;}}}
{&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;id&quot;: 2, &quot;method&quot;: &quot;tools/call&quot;, &quot;params&quot;: {&quot;name&quot;: &quot;schema_change&quot;, &quot;arguments&quot;: {&quot;query&quot;: &quot;CREATE TABLE users (id INTEGER, name TEXT, email TEXT)&quot;}}}
{&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;id&quot;: 3, &quot;method&quot;: &quot;tools/call&quot;, &quot;params&quot;: {&quot;name&quot;: &quot;list_tables&quot;, &quot;arguments&quot;: {}}}
{&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;id&quot;: 4, &quot;method&quot;: &quot;tools/call&quot;, &quot;params&quot;: {&quot;name&quot;: &quot;insert_data&quot;, &quot;arguments&quot;: {&quot;query&quot;: &quot;INSERT INTO users VALUES (1, &#039;Alice&#039;, &#039;alice@example.com&#039;)&quot;}}}
{&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;id&quot;: 5, &quot;method&quot;: &quot;tools/call&quot;, &quot;params&quot;: {&quot;name&quot;: &quot;execute_query&quot;, &quot;arguments&quot;: {&quot;query&quot;: &quot;SELECT * FROM users&quot;}}}
EOF
```

#### Example with Existing Database

```bash
# Working with an existing database file
cat &lt;&lt; &#039;EOF&#039; | tursodb mydb.db --mcp
{&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;id&quot;: 1, &quot;method&quot;: &quot;initialize&quot;, &quot;params&quot;: {&quot;protocolVersion&quot;: &quot;2024-11-05&quot;, &quot;capabilities&quot;: {}, &quot;clientInfo&quot;: {&quot;name&quot;: &quot;client&quot;, &quot;version&quot;: &quot;1.0&quot;}}}
{&quot;jsonrpc&quot;: &quot;2.0&quot;, &quot;id&quot;: 2, &quot;method&quot;: &quot;tools/call&quot;, &quot;params&quot;: {&quot;name&quot;: &quot;list_tables&quot;, &quot;arguments&quot;: {}}}
EOF
```

&lt;/details&gt;

## Contributing

We&#039;d love to have you contribute to Turso Database! Please check out the [contribution guide] to get started.

### Found a data corruption bug? Get up to $1,000.00

SQLite is loved because it is the most reliable database in the world. The next evolution of SQLite has
to match or surpass this level of reliability. Turso is built with [Deterministic Simulation Testing](simulator/)
from the ground up, and is also tested by [Antithesis](https://antithesis.com).

Even during Alpha, if you find a bug that leads to a data corruption and demonstrate
how our simulator failed to catch it, you can get up to $1,000.00. As the project matures we will
increase the size of the prize, and the scope of the bugs.

List of rewarded cases:

* B-Tree interior cell replacement issue in btrees with depth &gt;=3 ([#2106](https://github.com/tursodatabase/turso/issues/2106))
* Don&#039;t allow autovacuum to be flipped on non-empty databases ([#3830](https://github.com/tursodatabase/turso/pull/3830))

More details [here](https://turso.algora.io).

Turso core staff are not eligible.

## FAQ

### Is Turso Database ready for production use?

Turso Database is currently under heavy development and is **not** ready for production use.

### How is Turso Database different from Turso&#039;s libSQL?

Turso Database is a project to build the next evolution of SQLite in Rust, with a strong open contribution focus and features like native async support, vector search, and more. The libSQL project is also an attempt to evolve SQLite in a similar direction, but through a fork rather than a rewrite.

Rewriting SQLite in Rust started as an unassuming experiment, and due to its incredible success, replaces libSQL as our intended direction. At this point, libSQL is production ready, Turso Database is not - although it is evolving rapidly. More details [here](https://turso.tech/blog/we-will-rewrite-sqlite-and-we-are-going-all-in).

## Publications

* Pekka Enberg, Sasu Tarkoma, Jon Crowcroft Ashwin Rao (2024). Serverless Runtime / Database Co-Design With Asynchronous I/O. In _EdgeSys ‚Äò24_. [[PDF]](https://penberg.org/papers/penberg-edgesys24.pdf)
* Pekka Enberg, Sasu Tarkoma, and Ashwin Rao (2023). Towards Database and Serverless Runtime Co-Design. In _CoNEXT-SW ‚Äô23_. [[PDF](https://penberg.org/papers/penberg-conext-sw-23.pdf)] [[Slides](https://penberg.org/papers/penberg-conext-sw-23-slides.pdf)]

## License

This project is licensed under the [MIT license].

### Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Turso Database by you, shall be licensed as MIT, without any additional
terms or conditions.

[contribution guide]: CONTRIBUTING.md
[MIT license]: LICENSE.md

## Partners

Thanks to all the partners of Turso!

&lt;a href=&quot;https://antithesis.com/&quot;&gt;&lt;img src=&quot;assets/antithesis.jpg&quot; width=&quot;400&quot;&gt;&lt;/a&gt;

&lt;a href=&quot;https://blacksmith.sh&quot;&gt;&lt;img src=&quot;assets/blacksmith.svg&quot; width=&quot;400&quot;&gt;&lt;/a&gt;

&lt;a href=&quot;https://nyrkio.com/&quot;&gt;&lt;img src=&quot;assets/turso-nyrkio.png&quot; width=&quot;400&quot;&gt;&lt;/a&gt;

## Contributors

Thanks to all the contributors to Turso Database!

&lt;a href=&quot;https://github.com/tursodatabase/turso/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=tursodatabase/turso&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[launchbadge/sqlx]]></title>
            <link>https://github.com/launchbadge/sqlx</link>
            <guid>https://github.com/launchbadge/sqlx</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[üß∞ The Rust SQL Toolkit. An async, pure Rust SQL crate featuring compile-time checked queries without a DSL. Supports PostgreSQL, MySQL, and SQLite.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/launchbadge/sqlx">launchbadge/sqlx</a></h1>
            <p>üß∞ The Rust SQL Toolkit. An async, pure Rust SQL crate featuring compile-time checked queries without a DSL. Supports PostgreSQL, MySQL, and SQLite.</p>
            <p>Language: Rust</p>
            <p>Stars: 16,127</p>
            <p>Forks: 1,525</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;SQLx&lt;/h1&gt;
&lt;div align=&quot;center&quot;&gt;
 &lt;strong&gt;
   üß∞ The Rust SQL Toolkit
 &lt;/strong&gt;
&lt;/div&gt;

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Github Actions --&gt;
  &lt;a href=&quot;https://github.com/launchbadge/sqlx/actions/workflows/sqlx.yml?query=branch%3Amain&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/launchbadge/sqlx/sqlx.yml?branch=main&amp;style=flat-square&quot; alt=&quot;actions status&quot; /&gt;&lt;/a&gt;
  &lt;!-- Version --&gt;
  &lt;a href=&quot;https://crates.io/crates/sqlx&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/sqlx.svg?style=flat-square&quot;
    alt=&quot;Crates.io version&quot; /&gt;&lt;/a&gt;
  &lt;!-- Discord --&gt;
  &lt;a href=&quot;https://discord.gg/uuruzJ7&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/discord/665528275556106240?style=flat-square&quot; alt=&quot;chat&quot; /&gt;&lt;/a&gt;
  &lt;!-- Docs --&gt;
  &lt;a href=&quot;https://docs.rs/sqlx&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square&quot; alt=&quot;docs.rs docs&quot; /&gt;&lt;/a&gt;
  &lt;!-- Downloads --&gt;
  &lt;a href=&quot;https://crates.io/crates/sqlx&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/d/sqlx.svg?style=flat-square&quot; alt=&quot;Download&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h4&gt;
    &lt;a href=&quot;#install&quot;&gt;
      Install
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;#usage&quot;&gt;
      Usage
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://docs.rs/sqlx&quot;&gt;
      Docs
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/launchbadge/sqlx/wiki/Ecosystem&quot;&gt;
      Ecosystem
    &lt;/a&gt;    
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://discord.gg/uuruzJ7&quot;&gt;
      Discord
    &lt;/a&gt;
  &lt;/h4&gt;
&lt;/div&gt;

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;small&gt;Built with ‚ù§Ô∏è by &lt;a href=&quot;https://launchbadge.com&quot;&gt;The LaunchBadge team&lt;/a&gt;&lt;/small&gt;
&lt;/div&gt;

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;h5&gt;Have a question? Be sure to &lt;a href=&quot;FAQ.md&quot;&gt;check the FAQ first!&lt;/a&gt;&lt;/h5&gt;
&lt;/div&gt;

&lt;br /&gt;

SQLx is an async, pure Rust&lt;sub&gt;‚Ä†&lt;/sub&gt; SQL crate featuring compile-time checked queries without a DSL.

-   **Truly Asynchronous**. Built from the ground-up using async/await for maximum concurrency.

-   **Compile-time checked queries** (if you want). See [SQLx is not an ORM](#sqlx-is-not-an-orm).

-   **Database Agnostic**. Support for [PostgreSQL], [MySQL], [MariaDB], [SQLite].
    -   [MSSQL] was supported prior to version 0.7, but has been removed pending a full rewrite of the driver as part of our [SQLx Pro initiative].

-   **Pure Rust**. The Postgres and MySQL/MariaDB drivers are written in pure Rust using **zero** unsafe&lt;sub&gt;‚Ä†‚Ä†&lt;/sub&gt; code.

-   **Runtime Agnostic**. Works on different runtimes ([`async-std`] / [`tokio`] / [`actix`]) and TLS backends ([`native-tls`], [`rustls`]).

&lt;small&gt;&lt;small&gt;

‚Ä† The SQLite driver uses the libsqlite3 C library as SQLite is an embedded database (the only way
we could be pure Rust for SQLite is by porting _all_ of SQLite to Rust).

‚Ä†‚Ä† SQLx uses `#![forbid(unsafe_code)]` unless the `sqlite` feature is enabled.
The SQLite driver directly invokes the SQLite3 API via `libsqlite3-sys`, which requires `unsafe`.

&lt;/small&gt;&lt;/small&gt;

[postgresql]: http://postgresql.org/
[sqlite]: https://sqlite.org/
[mysql]: https://www.mysql.com/
[mariadb]: https://www.mariadb.org/
[mssql]: https://www.microsoft.com/en-us/sql-server
[SQLx Pro initiative]: https://github.com/launchbadge/sqlx/discussions/1616

---

-   Cross-platform. Being native Rust, SQLx will compile anywhere Rust is supported.

-   Built-in connection pooling with `sqlx::Pool`.

-   Row streaming. Data is read asynchronously from the database and decoded on demand.

-   Automatic statement preparation and caching. When using the high-level query API (`sqlx::query`), statements are
    prepared and cached per connection.

-   Simple (unprepared) query execution including fetching results into the same `Row` types used by
    the high-level API. Supports batch execution and returns results from all statements.

-   Transport Layer Security (TLS) where supported ([MySQL], [MariaDB] and [PostgreSQL]).

-   Asynchronous notifications using `LISTEN` and `NOTIFY` for [PostgreSQL].

-   Nested transactions with support for save points.

-   `Any` database driver for changing the database driver at runtime. An `AnyPool` connects to the driver indicated by the URL scheme.

## Install

SQLx is compatible with the [`async-std`], [`tokio`], and [`actix`] runtimes; and, the [`native-tls`] and [`rustls`] TLS backends. When adding the dependency, you must choose a runtime feature that is `runtime` + `tls`.

[`async-std`]: https://github.com/async-rs/async-std
[`tokio`]: https://github.com/tokio-rs/tokio
[`actix`]: https://github.com/actix/actix-net
[`native-tls`]: https://crates.io/crates/native-tls
[`rustls`]: https://crates.io/crates/rustls

```toml
# Cargo.toml
[dependencies]
# PICK ONE OF THE FOLLOWING:

# tokio (no TLS)
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot; ] }
# tokio + native-tls
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-native-tls&quot; ] }
# tokio + rustls with ring and WebPKI CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-rustls-ring-webpki&quot; ] }
# tokio + rustls with ring and platform&#039;s native CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-rustls-ring-native-roots&quot; ] }
# tokio + rustls with aws-lc-rs
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-rustls-aws-lc-rs&quot; ] }

# async-std (no TLS)
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot; ] }
# async-std + native-tls
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-native-tls&quot; ] }
# async-std + rustls with ring and WebPKI CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-rustls-ring-webpki&quot; ] }
# async-std + rustls with ring and platform&#039;s native CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-rustls-ring-native-roots&quot; ] }
# async-std + rustls with aws-lc-rs
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-rustls-aws-lc-rs&quot; ] }
```

#### Cargo Feature Flags

For backward-compatibility reasons, the runtime and TLS features can either be chosen together as a single feature,
or separately.

For forward compatibility, you should use the separate runtime and TLS features as the combination features may
be removed in the future.

-   `runtime-async-std`: Use the `async-std` runtime without enabling a TLS backend.

-   `runtime-tokio`: Use the `tokio` runtime without enabling a TLS backend.

    - Actix-web is fully compatible with Tokio and so a separate runtime feature is no longer needed.

-   `tls-native-tls`: Use the `native-tls` TLS backend (OpenSSL on *nix, SChannel on Windows, Secure Transport on macOS).

-   `tls-rustls`: Use the `rustls` TLS backend (cross-platform backend, only supports TLS 1.2 and 1.3).

-   `postgres`: Add support for the Postgres database server.

-   `mysql`: Add support for the MySQL/MariaDB database server.

-   `mssql`: Add support for the MSSQL database server.

-   `sqlite`: Add support for the self-contained [SQLite](https://sqlite.org/) database engine with SQLite bundled and statically-linked.

-   `sqlite-unbundled`: The same as above (`sqlite`), but link SQLite from the system instead of the bundled version.
    * Allows updating SQLite independently of SQLx or using forked versions.
    * You must have SQLite installed on the system or provide a path to the library at build time.
       See [the `rusqlite` README](https://github.com/rusqlite/rusqlite?tab=readme-ov-file#notes-on-building-rusqlite-and-libsqlite3-sys) for details.
    * May result in link errors if the SQLite version is too old. Version `3.20.0` or newer is recommended.
    * Can increase build time due to the use of bindgen.

-   `sqlite-preupdate-hook`: enables SQLite&#039;s [preupdate hook](https://sqlite.org/c3ref/preupdate_count.html) API.
    * Exposed as a separate feature because it&#039;s generally not enabled by default.
    * Using this feature with `sqlite-unbundled` may cause linker failures if the system SQLite version does not support it.

-   `any`: Add support for the `Any` database driver, which can proxy to a database driver at runtime.

-   `derive`: Add support for the derive family macros, those are `FromRow`, `Type`, `Encode`, `Decode`.

-   `macros`: Add support for the `query*!` macros, which allows compile-time checked queries.

-   `migrate`: Add support for the migration management and `migrate!` macro, which allow compile-time embedded migrations.

-   `uuid`: Add support for UUID.

-   `chrono`: Add support for date and time types from `chrono`.

-   `time`: Add support for date and time types from `time` crate (alternative to `chrono`, which is preferred by `query!` macro, if both enabled)

-   `bstr`: Add support for `bstr::BString`.

-   `bigdecimal`: Add support for `NUMERIC` using the `bigdecimal` crate.

-   `rust_decimal`: Add support for `NUMERIC` using the `rust_decimal` crate.

-   `ipnet`: Add support for `INET` and `CIDR` (in postgres) using the `ipnet` crate.

-   `ipnetwork`: Add support for `INET` and `CIDR` (in postgres) using the `ipnetwork` crate.

-   `json`: Add support for `JSON` and `JSONB` (in postgres) using the `serde_json` crate.

-   Offline mode is now always enabled. See [sqlx-cli/README.md][readme-offline].

[readme-offline]: sqlx-cli/README.md#enable-building-in-offline-mode-with-query

## SQLx is not an ORM!

SQLx supports **compile-time checked queries**. It does not, however, do this by providing a Rust
API or DSL (domain-specific language) for building queries. Instead, it provides macros that take
regular SQL as input and ensure that it is valid for your database. The way this works is that
SQLx connects to your development DB at compile time to have the database itself verify (and return
some info on) your SQL queries. This has some potentially surprising implications:

- Since SQLx never has to parse the SQL string itself, any syntax that the development DB accepts
  can be used (including things added by database extensions)
- Due to the different amount of information databases let you retrieve about queries, the extent of
  SQL verification you get from the query macros depends on the database

**If you are looking for an (asynchronous) ORM,** you can check out our new [Ecosystem wiki page](https://github.com/launchbadge/sqlx/wiki/Ecosystem#orms)!

[`ormx`]: https://crates.io/crates/ormx
[`SeaORM`]: https://github.com/SeaQL/sea-orm
## Usage

See the `examples/` folder for more in-depth usage.

### Quickstart

```rust
use sqlx::postgres::PgPoolOptions;
// use sqlx::mysql::MySqlPoolOptions;
// etc.

#[async_std::main] // Requires the `attributes` feature of `async-std`
// or #[tokio::main]
// or #[actix_web::main]
async fn main() -&gt; Result&lt;(), sqlx::Error&gt; {
    // Create a connection pool
    //  for MySQL/MariaDB, use MySqlPoolOptions::new()
    //  for SQLite, use SqlitePoolOptions::new()
    //  etc.
    let pool = PgPoolOptions::new()
        .max_connections(5)
        .connect(&quot;postgres://postgres:password@localhost/test&quot;).await?;

    // Make a simple query to return the given parameter (use a question mark `?` instead of `$1` for MySQL/MariaDB)
    let row: (i64,) = sqlx::query_as(&quot;SELECT $1&quot;)
        .bind(150_i64)
        .fetch_one(&amp;pool).await?;

    assert_eq!(row.0, 150);

    Ok(())
}
```


### Connecting

A single connection can be established using any of the database connection types and calling `connect()`.

```rust
use sqlx::Connection;

let conn = SqliteConnection::connect(&quot;sqlite::memory:&quot;).await?;
```

Generally, you will want to instead create a connection pool (`sqlx::Pool`) for the application to
regulate how many server-side connections it&#039;s using.

```rust
let pool = MySqlPool::connect(&quot;mysql://user:pass@host/database&quot;).await?;
```

### Querying

In SQL, queries can be separated into prepared (parameterized) or unprepared (simple). Prepared queries have their
query plan _cached_, use a binary mode of communication (lower bandwidth and faster decoding), and utilize parameters
to avoid SQL injection. Unprepared queries are simple and intended only for use where a prepared statement
will not work, such as various database commands (e.g., `PRAGMA` or `SET` or `BEGIN`).

SQLx supports all operations with both types of queries. In SQLx, a `&amp;str` is treated as an unprepared query,
and a `Query` or `QueryAs` struct is treated as a prepared query.

```rust
// low-level, Executor trait
conn.execute(&quot;BEGIN&quot;).await?; // unprepared, simple query
conn.execute(sqlx::query(&quot;DELETE FROM table&quot;)).await?; // prepared, cached query
```

We should prefer to use the high-level `query` interface whenever possible. To make this easier, there are finalizers
on the type to avoid the need to wrap with an executor.

```rust
sqlx::query(&quot;DELETE FROM table&quot;).execute(&amp;mut conn).await?;
sqlx::query(&quot;DELETE FROM table&quot;).execute(&amp;pool).await?;
```

The `execute` query finalizer returns the number of affected rows, if any, and drops all received results.
In addition, there are `fetch`, `fetch_one`, `fetch_optional`, and `fetch_all` to receive results.

The `Query` type returned from `sqlx::query` will return `Row&lt;&#039;conn&gt;` from the database. Column values can be accessed
by ordinal or by name with `row.get()`. As the `Row` retains an immutable borrow on the connection, only one
`Row` may exist at a time.

The `fetch` query finalizer returns a stream-like type that iterates through the rows in the result sets.

```rust
// provides `try_next`
use futures_util::TryStreamExt;
// provides `try_get`
use sqlx::Row;

let mut rows = sqlx::query(&quot;SELECT * FROM users WHERE email = ?&quot;)
    .bind(email)
    .fetch(&amp;mut conn);

while let Some(row) = rows.try_next().await? {
    // map the row into a user-defined domain type
    let email: &amp;str = row.try_get(&quot;email&quot;)?;
}
```

To assist with mapping the row into a domain type, one of two idioms may be used:

```rust
let mut stream = sqlx::query(&quot;SELECT * FROM users&quot;)
    .map(|row: PgRow| {
        // map the row into a user-defined domain type
    })
    .fetch(&amp;mut conn);
```

```rust
#[derive(sqlx::FromRow)]
struct User { name: String, id: i64 }

let mut stream = sqlx::query_as::&lt;_, User&gt;(&quot;SELECT * FROM users WHERE email = ? OR name = ?&quot;)
    .bind(user_email)
    .bind(user_name)
    .fetch(&amp;mut conn);
```

Instead of a stream of results, we can use `fetch_one` or `fetch_optional` to request one required or optional result
from the database.

### Compile-time verification

We can use the macro, `sqlx::query!` to achieve compile-time syntactic and semantic verification of the SQL, with
an output to an anonymous record type where each SQL column is a Rust field (using raw identifiers where needed).

```rust
let countries = sqlx::query!(
        &quot;
SELECT country, COUNT(*) as count
FROM users
GROUP BY country
WHERE organization = ?
        &quot;,
        organization
    )
    .fetch_all(&amp;pool) // -&gt; Vec&lt;{ country: String, count: i64 }&gt;
    .await?;

// countries[0].country
// countries[0].count
```

Differences from `query()`:

-   The input (or bind) parameters must be given all at once (and they are compile-time validated to be
    the right number and the right type).

-   The output type is an anonymous record. In the above example the type would be similar to:

    ```rust
    { country: String, count: i64 }
    ```

-   The `DATABASE_URL` environment variable must be set at build time to a database which it can prepare
    queries against; the database does not have to contain any data but must be the same
    kind (MySQL, Postgres, etc.) and have the same schema as the database you will be connecting to at runtime.

    For convenience, you can use [a `.env` file][dotenv]&lt;sup&gt;1&lt;/sup&gt; to set DATABASE_URL so that you don&#039;t have to pass it every time:

    ```
    DATABASE_URL=mysql://localhost/my_database
    ```

[dotenv]: https://github.com/dotenv-rs/dotenv#examples

The biggest downside to `query!()` is that the output type cannot be named (due to Rust not
officially supporting anonymous records). To address that, there is a `query_as!()` macro that is
mostly identical except that you can name the output type.

```rust
// no traits are needed
struct Country { country: String, count: i64 }

let countries = sqlx::query_as!(Country,
        &quot;
SELECT country, COUNT(*) as count
FROM users
GROUP BY country
WHERE organization = ?
        &quot;,
        organization
    )
    .fetch_all(&amp;pool) // -&gt; Vec&lt;Country&gt;
    .await?;

// countries[0].country
// countries[0].count
```

To avoid the need of having a development database around to compile the project even when no
modifications (to the database-accessing parts of the code) are done, you can enable &quot;offline mode&quot;
to cache the results of the SQL query analysis using the `sqlx` command-line tool. See
[sqlx-cli/README.md](./sqlx-cli/README.md#enable-building-in-offline-mode-with-query).

Compile-time verified queries do quite a bit of work at compile time. Incremental actions like
`cargo check` and `cargo build` can be significantly faster when using an optimized build by
putting the following in your `Cargo.toml` (More information in the
[Profiles section](https://doc.rust-lang.org/cargo/reference/profiles.html) of The Cargo Book)

```toml
[profile.dev.package.sqlx-macros]
opt-level = 3
```

&lt;sup&gt;1&lt;/sup&gt; The `dotenv` crate itself appears abandoned as of [December 2021](https://github.com/dotenv-rs/dotenv/issues/74)
so we now use the `dotenvy` crate instead. The file format is the same.

## Safety

This crate uses `#![forbid(unsafe_code)]` to ensure everything is implemented in 100% Safe Rust.

If the `sqlite` feature is enabled, this is downgraded to `#![deny(unsafe_code)]` with `#![allow(unsafe_code)]` on the
`sqlx::sqlite` module. There are several places where we interact with the C SQLite API. We try to document each call for the invariants we&#039;re assuming. We absolutely welcome auditing of, and feedback on, our unsafe code usage.

## License

Licensed under either of

-   Apache License, Version 2.0
    ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
-   MIT license
    ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your option.

## Contribution

Unless you explicitly state otherwise, any Contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[a2x/cs2-dumper]]></title>
            <link>https://github.com/a2x/cs2-dumper</link>
            <guid>https://github.com/a2x/cs2-dumper</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[Counter-Strike: 2 Offset Dumper]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/a2x/cs2-dumper">a2x/cs2-dumper</a></h1>
            <p>Counter-Strike: 2 Offset Dumper</p>
            <p>Language: Rust</p>
            <p>Stars: 1,627</p>
            <p>Forks: 251</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># cs2-dumper

An external offset/interface dumper for Counter-Strike 2, with support for both Windows &amp; Linux. Powered
by [memflow](https://github.com/memflow/memflow).

The native Linux version is available in the [linux](https://github.com/a2x/cs2-dumper/tree/linux) branch (currently
outdated).

For a work-in-progress offline version, check out the [cs2-analyzer](https://github.com/a2x/cs2-analyzer) repository or
view its included web demo [here](https://a2x.github.io/cs2-analyzer).

## Getting Started

You can download the latest release from [Releases](https://github.com/a2x/cs2-dumper/releases) or compile it yourself.
Note that compiling it yourself requires your Rust compiler version to be at least 1.74.0 or newer.

## Usage

1. Ensure the game is running (Being in the main menu should suffice).
2. Run the `cs2-dumper` executable.

_Note:_ If you run the executable without specifying an optional memflow connector name, it will automatically use the
[memflow-native](https://github.com/memflow/memflow-native) OS layer to read the memory of the game process. If you
wish to use an existing memflow connector instead, such as **pcileech** or **kvm**, you can pass the `connector` and
optional `connector-args` arguments to the program. These connectors can be installed and managed using
the [memflowup](https://github.com/memflow/memflowup) tool.

E.g (for pcileech). `cs2-dumper -c pcileech -a :device=FPGA -vv`

Certain connectors, such as the [kvm](https://github.com/memflow/memflow-kvm) connector on Linux or
the [pcileech](https://github.com/memflow/memflow-pcileech) / [winio](https://github.com/a2x/memflow-winio)
connectors on Windows, require elevated privileges to work. So either run the `cs2-dumper` executable with `sudo` on
Linux or as an administrator on Windows.

### Available Arguments

- `-c, --connector &lt;connector&gt;`: The name of the memflow connector to use.
- `-a, --connector-args &lt;connector-args&gt;`: Additional arguments to pass to the memflow connector.
- `-f, --file-types &lt;file-types&gt;`: The types of files to generate. Default: `cs`, `hpp`,  `json`, `rs`.
- `-i, --indent-size &lt;indent-size&gt;`: The number of spaces to use per indentation level. Default: `4`.
- `-o, --output &lt;output&gt;`: The output directory to write the generated files to. Default: `output`.
- `-p, --process-name &lt;process-name&gt;`: The name of the game process. Default: `cs2.exe`.
- `-v...`: Increase logging verbosity. Can be specified multiple times.
- `-h, --help`: Print help.
- `-V, --version`: Print version.

## Running Tests

To run the few basic provided tests, use the following command: `cargo test -- --nocapture`.

## License

Licensed under the MIT license ([LICENSE](./LICENSE)).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 74,711</p>
            <p>Forks: 2,329</p>
            <p>Stars today: 101 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- üöÄ A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`,
  and more.
- ‚ö°Ô∏è [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- üóÇÔ∏è Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- ‚ùáÔ∏è [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- üêç [Installs and manages](#python-versions) Python versions.
- üõ†Ô∏è [Runs and installs](#tools) tools published as Python packages.
- üî© Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a
  familiar CLI.
- üè¢ Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- üíæ Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- ‚è¨ Installable without Rust or Python via `curl` or `pip`.
- üñ•Ô∏è Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.12 3.13 3.14
Installed 3 versions in 972ms
 + cpython-3.12.12-macos-aarch64-none (python3.12)
 + cpython-3.13.9-macos-aarch64-none (python3.13)
 + cpython-3.14.0-macos-aarch64-none (python3.14)

```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Platform support

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

## Versioning policy

See uv&#039;s [versioning policy](https://docs.astral.sh/uv/reference/versioning/) document.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv/blob/main/CONTRIBUTING.md) to get started.

## FAQ

#### How do you pronounce uv?

It&#039;s pronounced as &quot;you - vee&quot; ([`/juÀê viÀê/`](https://en.wikipedia.org/wiki/Help:IPA/English#Key))

#### How should I stylize uv?

Just &quot;uv&quot;, please. See the [style guide](./STYLE.md#styling-uv) for details.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[linera-io/linera-protocol]]></title>
            <link>https://github.com/linera-io/linera-protocol</link>
            <guid>https://github.com/linera-io/linera-protocol</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Main repository for the Linera protocol]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/linera-io/linera-protocol">linera-io/linera-protocol</a></h1>
            <p>Main repository for the Linera protocol</p>
            <p>Language: Rust</p>
            <p>Stars: 31,924</p>
            <p>Forks: 2,236</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/linera-io/linera-protocol/assets/1105398/fe08c941-93af-4114-bb83-bcc0eaec95f9&quot; width=&quot;250&quot; height=&quot;85&quot; /&gt;

[![License](https://img.shields.io/github/license/linera-io/linera-protocol)](LICENSE)
[![Build Status for Docker](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml)
[![Build Status for Rust](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml)
[![Build Status for Documentation](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml)
[![Twitter](https://img.shields.io/twitter/follow/linera_io)](https://x.com/linera_io)
[![Discord](https://img.shields.io/discord/984941796272521226)](https://discord.com/invite/linera)

&lt;!-- [![Build Status for Kubernetes](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml) --&gt;

[Linera](https://linera.io) is a decentralized blockchain infrastructure designed for highly scalable,
secure, low-latency Web3 applications.

## Documentation

Visit our [developer page](https://linera.dev) and read our
[whitepaper](https://linera.io/whitepaper) to learn more about the Linera protocol.

## Repository Structure

The main crates and directories of this repository can be summarized as follows: (listed
from low to high levels in the dependency graph)

* [`linera-base`](https://linera-io.github.io/linera-protocol/linera_base/index.html) Base
  definitions, including cryptography.

* [`linera-version`](https://linera-io.github.io/linera-protocol/linera_version/index.html)
  A library to manage version info in binaries and services.

* [`linera-views`](https://linera-io.github.io/linera-protocol/linera_views/index.html) A
  library mapping complex data structures onto a key-value store. The corresponding
  procedural macros are implemented in `linera-views-derive`.

* [`linera-execution`](https://linera-io.github.io/linera-protocol/linera_execution/index.html)
  Persistent data and the corresponding logic for runtime and execution of Linera
  applications.

* [`linera-chain`](https://linera-io.github.io/linera-protocol/linera_chain/index.html)
  Persistent data and the corresponding logic for chains of blocks, certificates, and
  cross-chain messaging.

* [`linera-storage`](https://linera-io.github.io/linera-protocol/linera_storage/index.html)
  Defines the storage abstractions for the protocol on top of `linera-chain`.

* [`linera-core`](https://linera-io.github.io/linera-protocol/linera_core/index.html) The
  core Linera protocol, including client and server logic, node synchronization, etc.

* [`linera-rpc`](https://linera-io.github.io/linera-protocol/linera_rpc/index.html)
  Defines the data-type for RPC messages (currently all client &amp;#x2194; proxy &amp;#x2194;
  chain &amp;#x2194; chain interactions), and track the corresponding data schemas.

* [`linera-client`](https://linera-io.github.io/linera-protocol/linera_client/index.html)
  Library for writing Linera clients.  Used for the command-line
  client and the node service in `linera-service`, as well as the Web
  client in [`linera-web`](https://github.com/linera-io/linera-web/).

* [`linera-service`](https://linera-io.github.io/linera-protocol/linera_service/index.html)
  Executable for clients (aka CLI wallets), proxy (aka validator frontend) and servers.

* [`linera-sdk`](https://linera-io.github.io/linera-protocol/linera_sdk/index.html) The
  library to develop Linera applications written in Rust for the Wasm virtual machine. The
  corresponding procedural macros are implemented in `linera-sdk-derive`.

* [`examples`](./examples) Examples of Linera applications written in Rust.

## Prerequisites

See [`INSTALL.md`](./INSTALL.md) for software requirements to develop in this repo.

## Quickstart with the Linera CLI tool

The following commands set up a local test network and run some transfers between the
microchains owned by a single wallet.

```bash
# Make sure to compile the Linera binaries and add them in the $PATH.
# cargo build -p linera-storage-service -p linera-service --bins
export PATH=&quot;$PWD/target/debug:$PATH&quot;

# Import the optional helper function `linera_spawn`.
source /dev/stdin &lt;&lt;&lt;&quot;$(linera net helper 2&gt;/dev/null)&quot;

# Run a local test network with the default parameters and a number of microchains
# owned by the default wallet. This also defines `LINERA_TMP_DIR`.
linera_spawn \
linera net up --with-faucet --faucet-port 8080

# Remember the URL of the faucet.
FAUCET_URL=http://localhost:8080

# If you&#039;re using a testnet, start here and run this instead:
#   LINERA_TMP_DIR=$(mktemp -d)
#   FAUCET_URL=https://faucet.testnet-XXX.linera.net  # for some value XXX

# Set the path of the future wallet.
export LINERA_WALLET=&quot;$LINERA_TMP_DIR/wallet.json&quot;
export LINERA_KEYSTORE=&quot;$LINERA_TMP_DIR/keystore.json&quot;
export LINERA_STORAGE=&quot;rocksdb:$LINERA_TMP_DIR/client.db&quot;

# Initialize a new user wallet.
linera wallet init --faucet $FAUCET_URL

# Request chains.
INFO1=($(linera wallet request-chain --faucet $FAUCET_URL))
INFO2=($(linera wallet request-chain --faucet $FAUCET_URL))
CHAIN1=&quot;${INFO1[0]}&quot;
ACCOUNT1=&quot;${INFO1[1]}&quot;
CHAIN2=&quot;${INFO2[0]}&quot;
ACCOUNT2=&quot;${INFO2[1]}&quot;

# Show the different chains tracked by the wallet.
linera wallet show

# Query the chain balance of some of the chains.
linera query-balance &quot;$CHAIN1&quot;
linera query-balance &quot;$CHAIN2&quot;

# Transfer 10 units then 5 back.
linera transfer 10 --from &quot;$CHAIN1&quot; --to &quot;$CHAIN2&quot;
linera transfer 5 --from &quot;$CHAIN2&quot; --to &quot;$CHAIN1&quot;

# Query balances again.
linera query-balance &quot;$CHAIN1&quot;
linera query-balance &quot;$CHAIN2&quot;

# Now let&#039;s fund the user balances.
linera transfer 5 --from &quot;$CHAIN1&quot; --to &quot;$CHAIN1:$ACCOUNT1&quot;
linera transfer 2 --from &quot;$CHAIN1:$ACCOUNT1&quot; --to &quot;$CHAIN2:$ACCOUNT2&quot;

# Query user balances again.
linera query-balance &quot;$CHAIN1:$ACCOUNT1&quot;
linera query-balance &quot;$CHAIN2:$ACCOUNT2&quot;
```

More complex examples may be found in our [developer manual](https://linera.dev) as well
as the [example applications](./examples) in this repository.

## Contributing

We welcome contributions from the community! If you&#039;d like to contribute to the Linera protocol:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m &#039;Add some amazing feature&#039;`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

For detailed guidelines, see our [contribution guide](./CONTRIBUTING.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[bevyengine/bevy]]></title>
            <link>https://github.com/bevyengine/bevy</link>
            <guid>https://github.com/bevyengine/bevy</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[A refreshingly simple data-driven game engine built in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bevyengine/bevy">bevyengine/bevy</a></h1>
            <p>A refreshingly simple data-driven game engine built in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 43,444</p>
            <p>Forks: 4,271</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># [![Bevy](https://bevy.org/assets/bevy_logo_light_dark_and_dimmed.svg)](https://bevy.org)

[![License](https://img.shields.io/badge/license-MIT%2FApache-blue.svg)](https://github.com/bevyengine/bevy#license)
[![Crates.io](https://img.shields.io/crates/v/bevy.svg)](https://crates.io/crates/bevy)
[![Downloads](https://img.shields.io/crates/d/bevy.svg)](https://crates.io/crates/bevy)
[![Docs](https://docs.rs/bevy/badge.svg)](https://docs.rs/bevy/latest/bevy/)
[![CI](https://github.com/bevyengine/bevy/workflows/CI/badge.svg)](https://github.com/bevyengine/bevy/actions)
[![Discord](https://img.shields.io/discord/691052431525675048.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/bevy)

## What is Bevy?

Bevy is a refreshingly simple data-driven game engine built in Rust. It is free and open-source forever!

## WARNING

Bevy is still in the early stages of development. Important features are missing. Documentation is sparse. A new version of Bevy containing breaking changes to the API is released [approximately once every 3 months](https://bevy.org/news/bevy-0-6/#the-train-release-schedule). We provide [migration guides](https://bevy.org/learn/migration-guides/), but we can&#039;t guarantee migrations will always be easy. Use only if you are willing to work in this environment.

**MSRV:** Bevy relies heavily on improvements in the Rust language and compiler.
As a result, the Minimum Supported Rust Version (MSRV) is generally close to &quot;the latest stable release&quot; of Rust.

## Design Goals

* **Capable**: Offer a complete 2D and 3D feature set
* **Simple**: Easy for newbies to pick up, but infinitely flexible for power users
* **Data Focused**: Data-oriented architecture using the Entity Component System paradigm
* **Modular**: Use only what you need. Replace what you don&#039;t like
* **Fast**: App logic should run quickly, and when possible, in parallel
* **Productive**: Changes should compile quickly ... waiting isn&#039;t fun

## About

* **[Features](https://bevy.org):** A quick overview of Bevy&#039;s features.
* **[News](https://bevy.org/news/)**: A development blog that covers our progress, plans and shiny new features.

## Docs

* **[Quick Start Guide](https://bevy.org/learn/quick-start/introduction):** Bevy&#039;s official Quick Start Guide. The best place to start learning Bevy.
* **[Bevy Rust API Docs](https://docs.rs/bevy):** Bevy&#039;s Rust API docs, which are automatically generated from the doc comments in this repo.
* **[Official Examples](https://github.com/bevyengine/bevy/tree/latest/examples):** Bevy&#039;s dedicated, runnable examples, which are great for digging into specific concepts.
* **[Community-Made Learning Resources](https://bevy.org/assets/#learning)**: More tutorials, documentation, and examples made by the Bevy community.

## Community

Before contributing or participating in discussions with the community, you should familiarize yourself with our [**Code of Conduct**](./CODE_OF_CONDUCT.md).

* **[Discord](https://discord.gg/bevy):** Bevy&#039;s official discord server.
* **[Reddit](https://reddit.com/r/bevy):** Bevy&#039;s official subreddit.
* **[GitHub Discussions](https://github.com/bevyengine/bevy/discussions):** The best place for questions about Bevy, answered right here!
* **[Bevy Assets](https://bevy.org/assets/):** A collection of awesome Bevy projects, tools, plugins and learning materials.

### Contributing

If you&#039;d like to help build Bevy, check out the **[Contributor&#039;s Guide](https://bevy.org/learn/contribute/introduction)**.
For simple problems, feel free to [open an issue](https://github.com/bevyengine/bevy/issues) or
[PR](https://github.com/bevyengine/bevy/pulls) and tackle it yourself!

For more complex architecture decisions and experimental mad science, please open an [RFC](https://github.com/bevyengine/rfcs) (Request For Comments) so we can brainstorm together effectively!

## Getting Started

We recommend checking out the [Quick Start Guide](https://bevy.org/learn/quick-start/introduction) for a brief introduction.

Follow the [Setup guide](https://bevy.org/learn/quick-start/getting-started/setup) to ensure your development environment is set up correctly.
Once set up, you can quickly try out the [examples](https://github.com/bevyengine/bevy/tree/latest/examples) by cloning this repo and running the following commands:

```sh
# Switch to the correct version (latest release, default is main development branch)
git checkout latest
# Runs the &quot;breakout&quot; example
cargo run --example breakout
```

To draw a window with standard functionality enabled, use:

```rust
use bevy::prelude::*;

fn main() {
    App::new()
        .add_plugins(DefaultPlugins)
        .run();
}
```

### Fast Compiles

Bevy can be built just fine using default configuration on stable Rust. However for really fast iterative compiles, you should enable the &quot;fast compiles&quot; setup by [following the instructions here](https://bevy.org/learn/quick-start/getting-started/setup).

## [Bevy Cargo Features][cargo_features]

This [list][cargo_features] outlines the different cargo features supported by Bevy. These allow you to customize the Bevy feature set for your use-case.

[cargo_features]: docs/cargo_features.md

## Thanks

Bevy is the result of the hard work of many people. A huge thanks to all Bevy contributors, the many open source projects that have come before us, the [Rust gamedev ecosystem](https://arewegameyet.rs/), and the many libraries we build on.

A huge thanks to Bevy&#039;s [generous sponsors](https://bevy.org). Bevy will always be free and open source, but it isn&#039;t free to make. Please consider [sponsoring our work](https://bevy.org/donate/) if you like what we&#039;re building.

&lt;!-- This next line need to stay exactly as is. It is required for BrowserStack sponsorship. --&gt;
This project is tested with BrowserStack.

## License

Bevy is free, open source and permissively licensed!
Except where noted (below and/or in individual files), all code in this repository is dual-licensed under either:

* MIT License ([LICENSE-MIT](LICENSE-MIT) or [http://opensource.org/licenses/MIT](http://opensource.org/licenses/MIT))
* Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0))

at your option.
This means you can select the license you prefer!
This dual-licensing approach is the de-facto standard in the Rust ecosystem and there are [very good reasons](https://github.com/bevyengine/bevy/issues/2373) to include both.

Some of the engine&#039;s code carries additional copyright notices and license terms due to their external origins.
These are generally BSD-like, but exact details vary by crate:
If the README of a crate contains a &#039;License&#039; header (or similar), the additional copyright notices and license terms applicable to that crate will be listed.
The above licensing requirement still applies to contributions to those crates, and sections of those crates will carry those license terms.
The [license](https://doc.rust-lang.org/cargo/reference/manifest.html#the-license-and-license-file-fields) field of each crate will also reflect this.

The [assets](assets) included in this repository (for our [examples](./examples/README.md)) typically fall under different open licenses.
These will not be included in your game (unless copied in by you), and they are not distributed in the published bevy crates.
See [CREDITS.md](CREDITS.md) for the details of the licenses of those files.

### Your contributions

Unless you explicitly state otherwise,
any contribution intentionally submitted for inclusion in the work by you,
as defined in the Apache-2.0 license,
shall be dual licensed as above,
without any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[modelcontextprotocol/rust-sdk]]></title>
            <link>https://github.com/modelcontextprotocol/rust-sdk</link>
            <guid>https://github.com/modelcontextprotocol/rust-sdk</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[The official Rust SDK for the Model Context Protocol]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/modelcontextprotocol/rust-sdk">modelcontextprotocol/rust-sdk</a></h1>
            <p>The official Rust SDK for the Model Context Protocol</p>
            <p>Language: Rust</p>
            <p>Stars: 2,687</p>
            <p>Forks: 415</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;div align = &quot;right&quot;&gt;
&lt;a href=&quot;docs/readme/README.zh-cn.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá(ÂæÖÊõ¥Êñ∞)&lt;/a&gt;
&lt;/div&gt;

# RMCP
[![Crates.io Version](https://img.shields.io/crates/v/rmcp)](https://crates.io/crates/rmcp)
&lt;!-- ![Release status](https://github.com/modelcontextprotocol/rust-sdk/actions/workflows/release.yml/badge.svg) --&gt;
&lt;!-- [![docs.rs](todo)](todo) --&gt;
![Coverage](docs/coverage.svg)

An official Rust Model Context Protocol SDK implementation with tokio async runtime.

This repository contains the following crates:

- [rmcp](crates/rmcp): The core crate providing the RMCP protocol implementation (If you want to get more information, please visit [rmcp](crates/rmcp/README.md))
- [rmcp-macros](crates/rmcp-macros): A procedural macro crate for generating RMCP tool implementations (If you want to get more information, please visit [rmcp-macros](crates/rmcp-macros/README.md))

## Usage

### Import the crate

```toml
rmcp = { version = &quot;0.8.0&quot;, features = [&quot;server&quot;] }
## or dev channel
rmcp = { git = &quot;https://github.com/modelcontextprotocol/rust-sdk&quot;, branch = &quot;main&quot; }
```
### Third Dependencies
Basic dependencies:
- [tokio required](https://github.com/tokio-rs/tokio)
- [serde required](https://github.com/serde-rs/serde)
Json Schema generation(Must follow the 2020-12 version):
- [shemars required](https://github.com/GREsau/schemars)


### Build a Client
&lt;details&gt;
&lt;summary&gt;Start a client&lt;/summary&gt;

```rust, ignore
use rmcp::{ServiceExt, transport::{TokioChildProcess, ConfigureCommandExt}};
use tokio::process::Command;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let client = ().serve(TokioChildProcess::new(Command::new(&quot;npx&quot;).configure(|cmd| {
        cmd.arg(&quot;-y&quot;).arg(&quot;@modelcontextprotocol/server-everything&quot;);
    }))?).await?;
    Ok(())
}
```
&lt;/details&gt;

### Build a Server

&lt;details&gt;
&lt;summary&gt;Build a transport&lt;/summary&gt;

```rust, ignore
use tokio::io::{stdin, stdout};
let transport = (stdin(), stdout());
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Build a service&lt;/summary&gt;

You can easily build a service by using [`ServerHandler`](crates/rmcp/src/handler/server.rs) or [`ClientHandler`](crates/rmcp/src/handler/client.rs).

```rust, ignore
let service = common::counter::Counter::new();
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Start the server&lt;/summary&gt;

```rust, ignore
// this call will finish the initialization process
let server = service.serve(transport).await?;
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Interact with the server&lt;/summary&gt;

Once the server is initialized, you can send requests or notifications:

```rust, ignore
// request
let roots = server.list_roots().await?;

// or send notification
server.notify_cancelled(...).await?;
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Waiting for service shutdown&lt;/summary&gt;

```rust, ignore
let quit_reason = server.waiting().await?;
// or cancel it
let quit_reason = server.cancel().await?;
```
&lt;/details&gt;


## Examples

See [examples](examples/README.md)

## OAuth Support

See [oauth_support](docs/OAUTH_SUPPORT.md) for details.

## Related Resources

- [MCP Specification](https://spec.modelcontextprotocol.io/specification/2024-11-05/)
- [Schema](https://github.com/modelcontextprotocol/specification/blob/main/schema/2024-11-05/schema.ts)

## Related Projects

### Extending `rmcp`

- [rmcp-actix-web](https://gitlab.com/lx-industries/rmcp-actix-web) - An `actix_web` backend for `rmcp`
- [rmcp-openapi](https://gitlab.com/lx-industries/rmcp-openapi) - Transform OpenAPI definition endpoints into MCP tools

### Built with `rmcp`

- [rustfs-mcp](https://github.com/rustfs/rustfs/tree/main/crates/mcp) - High-performance MCP server providing S3-compatible object storage operations for AI/LLM integration
- [containerd-mcp-server](https://github.com/jokemanfire/mcp-containerd) - A containerd-based MCP server implementation
- [rmcp-openapi-server](https://gitlab.com/lx-industries/rmcp-openapi/-/tree/main/crates/rmcp-openapi-server) - High-performance MCP server that exposes OpenAPI definition endpoints as MCP tools
- [nvim-mcp](https://github.com/linw1995/nvim-mcp) - A MCP server to interact with Neovim
- [terminator](https://github.com/mediar-ai/terminator) - AI-powered desktop automation MCP server with cross-platform support and &gt;95% success rate
- [stakpak-agent](https://github.com/stakpak/agent) - Security-hardened terminal agent for DevOps with MCP over mTLS, streaming, secret tokenization, and async task management
- [video-transcriber-mcp-rs](https://github.com/nhatvu148/video-transcriber-mcp-rs) - High-performance MCP server for transcribing videos from 1000+ platforms using whisper.cpp
- [NexusCore MCP](https://github.com/sjkim1127/Nexuscore_MCP) - Advanced malware analysis &amp; dynamic instrumentation MCP server with Frida integration and stealth unpacking capabilities


## Development

### Tips for Contributors

See [docs/CONTRIBUTE.MD](docs/CONTRIBUTE.MD) to get some tips for contributing.

### Using Dev Container

If you want to use dev container, see [docs/DEVCONTAINER.md](docs/DEVCONTAINER.md) for instructions on using Dev Container for development.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[uutils/coreutils]]></title>
            <link>https://github.com/uutils/coreutils</link>
            <guid>https://github.com/uutils/coreutils</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Cross-platform Rust rewrite of the GNU coreutils]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/uutils/coreutils">uutils/coreutils</a></h1>
            <p>Cross-platform Rust rewrite of the GNU coreutils</p>
            <p>Language: Rust</p>
            <p>Stars: 22,282</p>
            <p>Forks: 1,663</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable MD033 MD041 MD002 --&gt;
&lt;!-- markdownlint-disable commands-show-output no-duplicate-heading --&gt;
&lt;!-- spell-checker:ignore markdownlint ; (options) DESTDIR UTILNAME manpages reimplementation oranda libclang --&gt;
&lt;div class=&quot;oranda-hide&quot;&gt;
&lt;div align=&quot;center&quot;&gt;

![uutils logo](docs/src/logo.svg)

# uutils coreutils

[![Crates.io](https://img.shields.io/crates/v/coreutils.svg)](https://crates.io/crates/coreutils)
[![Discord](https://img.shields.io/badge/discord-join-7289DA.svg?logo=discord&amp;longCache=true&amp;style=flat)](https://discord.gg/wQVJbvJ)
[![License](http://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/uutils/coreutils/blob/main/LICENSE)
[![dependency status](https://deps.rs/repo/github/uutils/coreutils/status.svg)](https://deps.rs/repo/github/uutils/coreutils)

[![CodeCov](https://codecov.io/gh/uutils/coreutils/branch/main/graph/badge.svg)](https://codecov.io/gh/uutils/coreutils)
![MSRV](https://img.shields.io/badge/MSRV-1.85.0-brightgreen)
[![Weblate](https://hosted.weblate.org/widget/rust-coreutils/svg-badge.svg)](https://hosted.weblate.org/projects/rust-coreutils/)

&lt;/div&gt;

---

&lt;/div&gt;

uutils coreutils is a cross-platform reimplementation of the GNU coreutils in
[Rust](http://www.rust-lang.org). While all programs have been implemented, some
options might be missing or different behavior might be experienced.

&lt;div class=&quot;oranda-hide&quot;&gt;

To install it:

```shell
cargo install coreutils
~/.cargo/bin/coreutils
```

&lt;/div&gt;

&lt;!-- markdownlint-disable-next-line MD026 --&gt;

## Goals

uutils coreutils aims to be a drop-in replacement for the GNU utils. Differences with GNU
are treated as bugs.

Our key objectives include:
- Matching GNU&#039;s output (stdout and error code) exactly
- Better error messages
- Providing comprehensive internationalization support (UTF-8)
- Improved performances
- [Extensions](docs/src/extensions.md) when relevant (example: --progress)

uutils aims to work on as many platforms as possible, to be able to use the same
utils on Linux, macOS, Windows and other platforms. This ensures, for example,
that scripts can be easily transferred between platforms.

&lt;div class=&quot;oranda-hide&quot;&gt;

## Documentation
uutils has both user and developer documentation available:

- [User Manual](https://uutils.github.io/coreutils/docs/)
- [Developer Documentation](https://docs.rs/crate/coreutils/)

Both can also be generated locally, the instructions for that can be found in
the [coreutils docs](https://github.com/uutils/uutils.github.io) repository.

Use [weblate/rust-coreutils](https://hosted.weblate.org/projects/rust-coreutils/) to translate the Rust coreutils into your language.

&lt;!-- ANCHOR: build (this mark is needed for mdbook) --&gt;

## Requirements

- Rust (`cargo`, `rustc`)
- GNU Make (optional)

### Rust Version

uutils follows Rust&#039;s release channels and is tested against stable, beta and
nightly. The current Minimum Supported Rust Version (MSRV) is `1.85.0`.

## Building

There are currently two methods to build the uutils binaries: either Cargo or
GNU Make.

&gt; Building the full package, including all documentation, requires both Cargo
&gt; and GNU Make on a Unix platform.

For either method, we first need to fetch the repository:

```shell
git clone https://github.com/uutils/coreutils
cd coreutils
```

### Cargo

Building uutils using Cargo is easy because the process is the same as for every
other Rust program:

```shell
cargo build --release
```

Replace `--release` with `--profile=release-fast` or `--profile=release-small` to use all optimizations or save binary size.

This command builds the most portable common core set of uutils into a multicall
(BusyBox-type) binary, named &#039;coreutils&#039;, on most Rust-supported platforms.

Additional platform-specific uutils are often available. Building these expanded
sets of uutils for a platform (on that platform) is as simple as specifying it
as a feature:

```shell
cargo build --release --features macos
# or ...
cargo build --release --features windows
# or ...
cargo build --release --features unix
```

To build SELinux-specific features, including `chcon` and `runcon`, ensure that `libselinux` 
and `libclang` are installed on your system. Then, run the following command:
```
cargo build --release --features unix,feat_selinux
```

If you don&#039;t want to build every utility available on your platform into the
final binary, you can also specify which ones you want to build manually. For
example:

```shell
cargo build --features &quot;base32 cat echo rm&quot; --no-default-features
```

If you want to build the utilities as individual binaries, that is also possible:

```shell
cargo build --release --bins --workspace --exclude coreutils --exclude uu_runcon --exclude uu_chcon
```
Each utility is contained in its own package within the main repository, named &quot;uu_UTILNAME&quot;. To
build selected individual utilities, use the `--package` [aka `-p`] option. For example:

```shell
cargo build -p uu_base32 -p uu_cat -p uu_echo -p uu_rm
```

### GNU Make

Building using `make` is a simple process as well.

To simply build all available utilities (with debug profile):

```shell
make
```

In release-fast mode:

```shell
make PROFILE=release-fast
```

To build all but a few of the available utilities:

```shell
make SKIP_UTILS=&#039;UTILITY_1 UTILITY_2&#039;
```

To build only a few of the available utilities:

```shell
make UTILS=&#039;UTILITY_1 UTILITY_2&#039;
```

## Installation

### Install with Cargo

Likewise, installing can simply be done using:

```shell
cargo install --path . --locked
```

This command will install uutils into Cargo&#039;s _bin_ folder (_e.g._
`$HOME/.cargo/bin`).

This does not install files necessary for shell completion or manpages. For
manpages or shell completion to work, use `GNU Make` or see
`Manually install shell completions`/`Manually install manpages`.

### Install with GNU Make

To install all available utilities:

```shell
make install
```

To install all utilities with all possible optimizations:

```shell
make PROFILE=release-fast install
```

To install using `sudo` switch `-E` must be used:

```shell
sudo -E make install
```

To install all but a few of the available utilities:

```shell
make SKIP_UTILS=&#039;UTILITY_1 UTILITY_2&#039; install
```

To install only a few of the available utilities:

```shell
make UTILS=&#039;UTILITY_1 UTILITY_2&#039; install
```

To install every program with a prefix (e.g. uu-echo uu-cat):

```shell
make PROG_PREFIX=uu- install
```

`PROG_PREFIX` requires separator `-`, `_`, or `=`.

To install the multicall binary:

```shell
make MULTICALL=y install
```

Set install parent directory (default value is /usr/local):

```shell
# DESTDIR is also supported
make PREFIX=/my/path install
```

Installing with `make` installs shell completions for all installed utilities
for `bash`, `fish` and `zsh`. Completions for `elvish` and `powershell` can also
be generated; See `Manually install shell completions`.

To skip installation of completions and manpages:

```shell
make COMPLETIONS=n MANPAGES=n install
```

### Manually install shell completions

The `uudoc` binary generates completions for the `bash`, `elvish`,
`fish`, `powershell` and `zsh` shells to stdout.

Install `uudoc` by
```shell
cargo install --bin uudoc --features uudoc --path .
```

Then use the installed binary:
```shell
uudoc completion &lt;utility&gt; &lt;shell&gt;
```

So, to install completions for `ls` on `bash` to
`/usr/local/share/bash-completion/completions/ls`, run:

```shell
uudoc completion ls bash &gt; /usr/local/share/bash-completion/completions/ls.bash
```

Completion for prefixed `cp` with `uu-` on `zsh` is generated by
```shell
env PROG_PREFIX=uu- uudoc completion cp zsh
```

### Manually install manpages

To generate manpages, the syntax is:

```bash
uudoc manpage &lt;utility&gt;
```

So, to install the manpage for `ls` to `/usr/local/share/man/man1/ls.1` run:

```bash
uudoc manpage ls &gt; /usr/local/share/man/man1/ls.1
```

## Un-installation

Un-installation differs depending on how you have installed uutils. If you used
Cargo to install, use Cargo to uninstall. If you used GNU Make to install, use
Make to uninstall.

### Uninstall with Cargo

To uninstall uutils:

```shell
cargo uninstall coreutils
```

### Uninstall with GNU Make

To uninstall all utilities:

```shell
make uninstall
```

To uninstall every program with a set prefix:

```shell
make PROG_PREFIX=uu- uninstall
```

To uninstall the multicall binary:

```shell
make MULTICALL=y uninstall
```

To uninstall from a custom parent directory:

```shell
# DESTDIR is also supported
make PREFIX=/my/path uninstall
```

&lt;!-- ANCHOR_END: build (this mark is needed for mdbook) --&gt;

## GNU test suite compatibility

Below is the evolution of how many GNU tests uutils passes. A more detailed
breakdown of the GNU test results of the main branch can be found
[in the user manual](https://uutils.github.io/coreutils/docs/test_coverage.html).

See &lt;https://github.com/orgs/uutils/projects/1&gt; for the main meta bugs
(many are missing).

![Evolution over time](https://github.com/uutils/coreutils-tracking/blob/main/gnu-results.svg?raw=true)

&lt;/div&gt; &lt;!-- close oranda-hide div --&gt;

## Contributing

To contribute to uutils, please see [CONTRIBUTING](CONTRIBUTING.md).

## License

uutils is licensed under the MIT License - see the `LICENSE` file for details

GNU Coreutils is licensed under the GPL 3.0 or later.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ratatui/ratatui]]></title>
            <link>https://github.com/ratatui/ratatui</link>
            <guid>https://github.com/ratatui/ratatui</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[A Rust crate for cooking up terminal user interfaces (TUIs) üë®‚Äçüç≥üêÄ https://ratatui.rs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ratatui/ratatui">ratatui/ratatui</a></h1>
            <p>A Rust crate for cooking up terminal user interfaces (TUIs) üë®‚Äçüç≥üêÄ https://ratatui.rs</p>
            <p>Language: Rust</p>
            <p>Stars: 16,601</p>
            <p>Forks: 530</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;details&gt;
&lt;summary&gt;Table of Contents&lt;/summary&gt;

- [Quickstart](#quickstart)
- [Documentation](#documentation)
- [Templates](#templates)
- [Built with Ratatui](#built-with-ratatui)
- [Alternatives](#alternatives)
- [Contributing](#contributing)
- [Acknowledgements](#acknowledgements)
- [License](#license)

&lt;/details&gt;

![Release header](https://github.com/ratatui/ratatui/blob/b23480adfa9430697071c906c7ba4d4f9bd37a73/assets/release-header.png?raw=true)

&lt;div align=&quot;center&quot;&gt;

[![Crate Badge]][Crate] [![Repo Badge]][Repo] [![Docs Badge]][Docs] [![License Badge]][License]  \
[![CI Badge]][CI] [![Deps Badge]][Deps] [![Codecov Badge]][Codecov] [![Sponsors Badge]][Sponsors]  \
[Ratatui Website] ¬∑ [Docs] ¬∑ [Widget Examples] ¬∑ [App Examples] ¬∑ [Changelog]  \
[Breaking Changes] ¬∑ [Contributing] ¬∑ [Report a bug] ¬∑ [Request a Feature]

&lt;/div&gt;

[Ratatui][Ratatui Website] (_Àår√¶.t…ôÀàtu.i_) is a Rust crate for cooking up terminal user interfaces
(TUIs). It provides a simple and flexible way to create text-based user interfaces in the terminal,
which can be used for command-line applications, dashboards, and other interactive console programs.

## Quickstart

Ratatui has [templates] available to help you get started quickly. You can use the
[`cargo-generate`] command to create a new project with Ratatui:

```shell
cargo install --locked cargo-generate
cargo generate ratatui/templates
```

Selecting the Hello World template produces the following application:

```rust
use color_eyre::Result;
use crossterm::event::{self, Event};
use ratatui::{DefaultTerminal, Frame};

fn main() -&gt; Result&lt;()&gt; {
    color_eyre::install()?;
    let terminal = ratatui::init();
    let result = run(terminal);
    ratatui::restore();
    result
}

fn run(mut terminal: DefaultTerminal) -&gt; Result&lt;()&gt; {
    loop {
        terminal.draw(render)?;
        if matches!(event::read()?, Event::Key(_)) {
            break Ok(());
        }
    }
}

fn render(frame: &amp;mut Frame) {
    frame.render_widget(&quot;hello world&quot;, frame.area());
}
```

## Documentation

- [Docs] - the full API documentation for the library on docs.rs.
- [Ratatui Website] - explains the library&#039;s concepts and provides step-by-step tutorials.
- [Ratatui Forum] - a place to ask questions and discuss the library.
- [Widget Examples] - a collection of examples that demonstrate how to use the library.
- [App Examples] - a collection of more complex examples that demonstrate how to build apps.
- [ARCHITECTURE.md] - explains the crate organization and modular workspace structure.
- [Changelog] - generated by [git-cliff] utilizing [Conventional Commits].
- [Breaking Changes] - a list of breaking changes in the library.

You can also watch the [EuroRust 2024 talk] to learn about common concepts in Ratatui and what&#039;s
possible to build with it.

## Templates

If you&#039;re looking to get started quickly, you can use one of the available templates from the
[templates] repository using [`cargo-generate`]:

```shell
cargo generate ratatui/templates
```

## Built with Ratatui

[![Awesome](https://awesome.re/badge-flat2.svg)][awesome-ratatui]

Check out the [showcase] section of the website, or the [awesome-ratatui] repository for a curated
list of awesome apps and libraries built with Ratatui!

## Alternatives

- [Cursive](https://crates.io/crates/cursive) - a ncurses-based TUI library.
- [iocraft](https://crates.io/crates/iocraft) - a declarative TUI library.

## Contributing

[![Discord Badge]][Discord Server] [![Matrix Badge]][Matrix] [![Forum Badge]][Ratatui Forum]

Feel free to join our [Discord server](https://discord.gg/pMCEU9hNEj) for discussions and questions!
There is also a [Matrix](https://matrix.org/) bridge available at
[#ratatui:matrix.org](https://matrix.to/#/#ratatui:matrix.org). We have also recently launched the
[Ratatui Forum].

We rely on GitHub for [bugs][Report a bug] and [feature requests][Request a Feature].

Please make sure you read the [contributing](./CONTRIBUTING.md) guidelines before [creating a pull
request][Create a Pull Request]. We accept AI generated code, but please read the [AI Contributions]
guidelines to ensure compliance.

If you&#039;d like to show your support, you can add the Ratatui badge to your project&#039;s README:

```md
[![Built With Ratatui](https://img.shields.io/badge/Built_With_Ratatui-000?logo=ratatui&amp;logoColor=fff)](https://ratatui.rs/)
```

[![Built With Ratatui](https://img.shields.io/badge/Built_With_Ratatui-000?logo=ratatui&amp;logoColor=fff)](https://ratatui.rs/)

## Acknowledgements

Ratatui was forked from the [tui-rs] crate in 2023 in order to continue its development. None of
this could be possible without [Florian Dehau] who originally created [tui-rs] which inspired many
Rust TUIs.

Special thanks to [Pavel Fomchenkov] for his work in designing an awesome logo for the Ratatui
project and organization.

## License

This project is licensed under the [MIT License][License].

[Repo]: https://github.com/ratatui/ratatui
[Ratatui Website]: https://ratatui.rs/
[Ratatui Forum]: https://forum.ratatui.rs
[Docs]: https://docs.rs/ratatui
[Widget Examples]: https://github.com/ratatui/ratatui/tree/main/ratatui-widgets/examples
[App Examples]: https://github.com/ratatui/ratatui/tree/main/examples
[ARCHITECTURE.md]: https://github.com/ratatui/ratatui/blob/main/ARCHITECTURE.md
[Changelog]: https://github.com/ratatui/ratatui/blob/main/CHANGELOG.md
[git-cliff]: https://git-cliff.org
[Conventional Commits]: https://www.conventionalcommits.org
[Breaking Changes]: https://github.com/ratatui/ratatui/blob/main/BREAKING-CHANGES.md
[EuroRust 2024 talk]: https://www.youtube.com/watch?v=hWG51Mc1DlM
[Report a bug]: https://github.com/ratatui/ratatui/issues/new?labels=bug&amp;projects=&amp;template=bug_report.md
[Request a Feature]: https://github.com/ratatui/ratatui/issues/new?labels=enhancement&amp;projects=&amp;template=feature_request.md
[Create a Pull Request]: https://github.com/ratatui/ratatui/compare
[Contributing]: https://github.com/ratatui/ratatui/blob/main/CONTRIBUTING.md
[AI Contributions]: https://github.com/ratatui/ratatui/blob/main/CONTRIBUTING.md#ai-generated-content
[Crate]: https://crates.io/crates/ratatui
[tui-rs]: https://crates.io/crates/tui
[Sponsors]: https://github.com/sponsors/ratatui
[Crate Badge]: https://img.shields.io/crates/v/ratatui?logo=rust&amp;style=flat-square&amp;color=E05D44
[Repo Badge]: https://img.shields.io/badge/repo-ratatui/ratatui-1370D3?style=flat-square&amp;logo=github
[License Badge]: https://img.shields.io/crates/l/ratatui?style=flat-square&amp;color=1370D3
[CI Badge]: https://img.shields.io/github/actions/workflow/status/ratatui/ratatui/ci.yml?style=flat-square&amp;logo=github
[CI]: https://github.com/ratatui/ratatui/actions/workflows/ci.yml
[Codecov Badge]: https://img.shields.io/codecov/c/github/ratatui/ratatui?logo=codecov&amp;style=flat-square&amp;token=BAQ8SOKEST&amp;color=C43AC3
[Codecov]: https://app.codecov.io/gh/ratatui/ratatui
[Deps Badge]: https://deps.rs/repo/github/ratatui/ratatui/status.svg?path=ratatui&amp;style=flat-square
[Deps]: https://deps.rs/repo/github/ratatui/ratatui?path=ratatui
[Discord Badge]: https://img.shields.io/discord/1070692720437383208?label=discord&amp;logo=discord&amp;style=flat-square&amp;color=1370D3&amp;logoColor=1370D3
[Discord Server]: https://discord.gg/pMCEU9hNEj
[Docs Badge]: https://img.shields.io/badge/docs-ratatui-1370D3?style=flat-square&amp;logo=rust
[Matrix Badge]: https://img.shields.io/matrix/ratatui-general%3Amatrix.org?style=flat-square&amp;logo=matrix&amp;label=Matrix&amp;color=C43AC3
[Matrix]: https://matrix.to/#/#ratatui:matrix.org
[Forum Badge]: https://img.shields.io/discourse/likes?server=https%3A%2F%2Fforum.ratatui.rs&amp;style=flat-square&amp;logo=discourse&amp;label=forum&amp;color=C43AC3
[Sponsors Badge]: https://img.shields.io/github/sponsors/ratatui?logo=github&amp;style=flat-square&amp;color=1370D3
[templates]: https://github.com/ratatui/templates/
[showcase]: https://ratatui.rs/showcase/
[awesome-ratatui]: https://github.com/ratatui/awesome-ratatui
[Pavel Fomchenkov]: https://github.com/nawok
[Florian Dehau]: https://github.com/fdehau
[`cargo-generate`]: https://crates.io/crates/cargo-generate
[License]: ./LICENSE
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zama-ai/fhevm]]></title>
            <link>https://github.com/zama-ai/fhevm</link>
            <guid>https://github.com/zama-ai/fhevm</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zama-ai/fhevm">zama-ai/fhevm</a></h1>
            <p>FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications</p>
            <p>Language: Rust</p>
            <p>Stars: 26,297</p>
            <p>Forks: 2,673</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/.gitbook/assets/fhevm-header-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/.gitbook/assets/fhevm-header-light.png&quot;&gt;
  &lt;img width=500 alt=&quot;fhevm&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;

&lt;hr/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;fhevm-whitepaper.pdf&quot;&gt; üìÉ Read white paper&lt;/a&gt; |&lt;a href=&quot;https://docs.zama.ai/protocol&quot;&gt; üìí Documentation&lt;/a&gt; | &lt;a href=&quot;https://zama.ai/community&quot;&gt; üíõ Community support&lt;/a&gt; | &lt;a href=&quot;https://github.com/zama-ai/awesome-zama&quot;&gt; üìö FHE resources by Zama&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/zama-ai/fhevm/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/zama-ai/fhevm?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/zama-ai/fhevm/blob/main/LICENSE&quot;&gt;
    &lt;!-- markdown-link-check-disable-next-line --&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-BSD--3--Clause--Clear-%23ffb243?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/zama-ai/bounty-program&quot;&gt;
    &lt;!-- markdown-link-check-disable-next-line --&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Contribute-Zama%20Bounty%20Program-%23ffd208?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://slsa.dev&quot;&gt;&lt;img alt=&quot;SLSA 3&quot; src=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;


## About

### What is FHEVM?

**FHEVM** is the core framework of the *Zama Confidential Blockchain Protocol*. It enables confidential smart contracts on EVM-compatible blockchains by leveraging Fully Homomorphic Encryption (FHE), allowing encrypted data to be processed directly onchain.

FHEVM ensures both confidentiality and composability, with the following guarantees:
- **End-to-end encryption of transactions and state:** Data included in transactions is encrypted and never visible to anyone.
- **Composability and data availability on-chain:** States are updated while remaining encrypted at all times.
- **No impact on existing dApps and state:** Encrypted state co-exists alongside public one, and doesn&#039;t impact existing dApps.
&lt;br&gt;&lt;/br&gt;

### Table of contents

- [About](#about)
  - [What is FHEVM?](#what-is-fhevm)
  - [Project structure](#project-structure)
  - [Main features](#main-features)
  - [Use cases](#use-cases)
- [Resources](#resources)
- [Working with FHEVM](#working-with-fhevm)
  - [Citations](#citations)
  - [Contributing](#contributing)
  - [License](#license)
  - [FAQ](#faq)
- [Support](#support)
  &lt;br&gt;&lt;/br&gt;
### Project structure
The directories of this repository are organized in the following way:

###### FHEVM Contracts

- **`gateway-contracts/`**: Smart contracts managing the gateway between on-chain and off-chain components.

- **`host-contracts/`**: Smart Contracts deployed on the host chain for orchestrating FHE workflows.

###### FHEVM Compute Engines

- **`coprocessor/`**: Rust-based coprocessor implementation for FHE operations.

- **`kms-connector/`**: Interface for integrating with Key Management Services (KMS) to handle encryption keys securely.

###### FHEVM Utilities
- **`charts/`**: Helm charts and deployment configurations for the stack.

- **`golden-container-images/`**: Docker golden images for Node.js and Rust environments used as base images by the stack.

- **`test-suite/`**: Integration with docker-compose and tests covering end-to-end FHEVM stack behavior.



  &lt;br&gt;&lt;/br&gt;
### Main features

- **Privacy by design:** Building decentralized apps with full privacy and confidentiality on Ethereum, leveraging FHE.
- **Solidity integration:** Write FHEVM contracts like any standard Solidity contract using Solidity. Compatible with existing toolchains ‚Äî such as Hardhat and Foundry (*coming soon*).
- **Programmable privacy:**  Define exactly what data is encrypted and write the access control logic directly in your smart contracts.
- **High precision encrypted integers :** Up to 256 bits of precision for integers.
- **Full range of operators:** All typical operators are available: `+`, `-`, `*`, `/`, `&lt;`, `&gt;`, `==`, ternary-if, boolean operations‚Ä¶. Consecutive FHE operations are not limited.
- **Security:** The underlying FHE crypto-scheme of FHEVM is quantum-resistant. Decryption is managed via a key management system (KMS) using multi-party computation (MPC), ensuring security even if some parties are compromised or misbehaving.
- **Symbolic execution of FHE computations:** All FHE operations are executed symbolically on the host chain, significantly reducing execution time. The actual computations on encrypted data are offloaded asynchronously to our coprocessor, allowing for faster, efficient, and scalable processing.

_Learn more about FHEVM features in the [documentation](https://docs.zama.ai/protocol) and in our [whitepaper](https://github.com/zama-ai/fhevm/blob/main/fhevm-whitepaper.pdf)._
&lt;br&gt;&lt;/br&gt;

### Use cases

FHEVM is built for developers to write confidential smart contracts without the need to learn cryptography. Leveraging FHEVM, you can unlock a myriad of new use cases such as DeFi, gaming, and more. For instance:

- **Confidential transfers**: Keep balances and amounts private, without using mixers.
- **Tokenization**: Swap tokens and RWAs on-chain without others seeing the amounts.
- **Blind auctions**: Bid on items without revealing the amount or the winner.
- **On-chain games**: Keep moves, selections, cards, or items hidden until ready to reveal.
- **Confidential voting**: Prevents bribery and blackmailing by keeping votes private.
- **Encrypted DIDs**: Store identities on-chain and generate attestations without ZK.

_Learn more use cases in the [list of examples](https://docs.zama.ai/protocol/examples)._
&lt;br&gt;&lt;/br&gt;


## Resources
- [Documentation](https://docs.zama.ai/protocol) ‚Äî Official documentation of FHEVM.
- [Whitepaper](./fhevm-whitepaper.pdf) ‚Äî Technical overview of FHEVM&#039;s cryptographic design.
- [Examples](https://docs.zama.ai/protocol/examples) ‚Äî Examples of building confidential smart contracts.
- [Awesome Zama ‚Äì FHEVM](https://github.com/zama-ai/awesome-zama?tab=readme-ov-file#fhevm) ‚Äî Curated articles, talks, and ecosystem projects.

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#about&quot; &gt; ‚Üë Back to top &lt;/a&gt;
&lt;/p&gt;

## Working with FHEVM
### Citations

To cite FHEVM or the whitepaper in academic papers, please use the following entries:

```text
@Misc{FHEVM,
title={{FHEVM: A full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications},
author={Zama},
year={2025},
note={\url{https://github.com/zama-ai/fhevm}},
}
```

### Contributing

There are two ways to contribute to FHEVM:

- [Open issues](https://github.com/zama-ai/fhevm/issues/new/choose) to report bugs and typos, or to suggest new ideas
- Request to become an official contributor by emailing hello@zama.ai.

Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do!
&lt;br&gt;&lt;/br&gt;

### License

This software is distributed under the **BSD-3-Clause-Clear** license. Read [this](LICENSE) for more details.

### FAQ

**Is Zama‚Äôs technology free to use?**

&gt; Zama‚Äôs libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama&#039;s open source code, companies must purchase Zama‚Äôs commercial patent license.
&gt;
&gt; Everything we do is open source, and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in [this blog post](https://www.zama.ai/post/open-source).

**What do I need to do if I want to use Zama‚Äôs technology for commercial purposes?**

&gt; To commercially use Zama‚Äôs technology you need to be granted Zama‚Äôs patent license. Please contact us at hello@zama.ai for more information.

**Do you file IP on your technology?**

&gt; Yes, all Zama‚Äôs technologies are patented.

**Can you customize a solution for my specific use case?**

&gt; We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at hello@zama.ai.

## Support

&lt;a target=&quot;_blank&quot; href=&quot;https://community.zama.ai&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/.gitbook/assets/support-banner-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/.gitbook/assets/support-banner-light.png&quot;&gt;
  &lt;img alt=&quot;Support&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;

üåü If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development.

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#about&quot; &gt; ‚Üë Back to top &lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[openai/codex]]></title>
            <link>https://github.com/openai/codex</link>
            <guid>https://github.com/openai/codex</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Lightweight coding agent that runs in your terminal]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/codex">openai/codex</a></h1>
            <p>Lightweight coding agent that runs in your terminal</p>
            <p>Language: Rust</p>
            <p>Stars: 52,325</p>
            <p>Forks: 6,683</p>
            <p>Stars today: 63 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install --cask codex&lt;/code&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer.
&lt;/br&gt;
&lt;/br&gt;If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href=&quot;https://developers.openai.com/codex/ide&quot;&gt;install in your IDE&lt;/a&gt;
&lt;/br&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href=&quot;https://chatgpt.com/codex&quot;&gt;chatgpt.com/codex&lt;/a&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./.github/codex-cli-splash.png&quot; alt=&quot;Codex CLI splash&quot; width=&quot;80%&quot; /&gt;
  &lt;/p&gt;

---

## Quickstart

### Installing and running Codex CLI

Install globally with your preferred package manager. If you use npm:

```shell
npm install -g @openai/codex
```

Alternatively, if you use Homebrew:

```shell
brew install --cask codex
```

Then simply run `codex` to get started:

```shell
codex
```

If you&#039;re running into upgrade issues with Homebrew, see the [FAQ entry on brew upgrade codex](./docs/faq.md#brew-upgrade-codex-isnt-upgrading-me).

&lt;details&gt;
&lt;summary&gt;You can also go to the &lt;a href=&quot;https://github.com/openai/codex/releases/latest&quot;&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt;

Each GitHub Release contains many executables, but in practice, you likely want one of these:

- macOS
  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`
  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`
- Linux
  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`
  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`

Each archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.

&lt;/details&gt;

### Using Codex with your ChatGPT plan

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./.github/codex-cli-login.png&quot; alt=&quot;Codex CLI login&quot; width=&quot;80%&quot; /&gt;
  &lt;/p&gt;

Run `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what&#039;s included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).

You can also use Codex with an API key, but this requires [additional setup](./docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key). If you previously used an API key for usage-based billing, see the [migration steps](./docs/authentication.md#migrating-from-usage-based-billing-api-key). If you&#039;re having trouble with login, please comment on [this issue](https://github.com/openai/codex/issues/1243).

### Model Context Protocol (MCP)

Codex can access MCP servers. To configure them, refer to the [config docs](./docs/config.md#mcp_servers).

### Configuration

Codex CLI supports a rich set of configuration options, with preferences stored in `~/.codex/config.toml`. For full configuration options, see [Configuration](./docs/config.md).

### Execpolicy

See the [Execpolicy quickstart](./docs/execpolicy.md) to set up rules that govern what commands Codex can execute.

### Docs &amp; FAQ

- [**Getting started**](./docs/getting-started.md)
  - [CLI usage](./docs/getting-started.md#cli-usage)
  - [Slash Commands](./docs/slash_commands.md)
  - [Running with a prompt as input](./docs/getting-started.md#running-with-a-prompt-as-input)
  - [Example prompts](./docs/getting-started.md#example-prompts)
  - [Custom prompts](./docs/prompts.md)
  - [Memory with AGENTS.md](./docs/getting-started.md#memory-with-agentsmd)
- [**Configuration**](./docs/config.md)
  - [Example config](./docs/example-config.md)
- [**Sandbox &amp; approvals**](./docs/sandbox.md)
- [**Execpolicy quickstart**](./docs/execpolicy.md)
- [**Authentication**](./docs/authentication.md)
  - [Auth methods](./docs/authentication.md#forcing-a-specific-auth-method-advanced)
  - [Login on a &quot;Headless&quot; machine](./docs/authentication.md#connecting-on-a-headless-machine)
- **Automating Codex**
  - [GitHub Action](https://github.com/openai/codex-action)
  - [TypeScript SDK](./sdk/typescript/README.md)
  - [Non-interactive mode (`codex exec`)](./docs/exec.md)
- [**Advanced**](./docs/advanced.md)
  - [Tracing / verbose logging](./docs/advanced.md#tracing--verbose-logging)
  - [Model Context Protocol (MCP)](./docs/advanced.md#model-context-protocol-mcp)
- [**Zero data retention (ZDR)**](./docs/zdr.md)
- [**Contributing**](./docs/contributing.md)
- [**Install &amp; build**](./docs/install.md)
  - [System Requirements](./docs/install.md#system-requirements)
  - [DotSlash](./docs/install.md#dotslash)
  - [Build from source](./docs/install.md#build-from-source)
- [**FAQ**](./docs/faq.md)
- [**Open source fund**](./docs/open-source-fund.md)

---

## License

This repository is licensed under the [Apache-2.0 License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zed-industries/zed]]></title>
            <link>https://github.com/zed-industries/zed</link>
            <guid>https://github.com/zed-industries/zed</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zed-industries/zed">zed-industries/zed</a></h1>
            <p>Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.</p>
            <p>Language: Rust</p>
            <p>Stars: 71,272</p>
            <p>Forks: 6,231</p>
            <p>Stars today: 72 stars today</p>
            <h2>README</h2><pre># Zed

[![Zed](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/zed-industries/zed/main/assets/badge/v0.json)](https://zed.dev)
[![CI](https://github.com/zed-industries/zed/actions/workflows/run_tests.yml/badge.svg)](https://github.com/zed-industries/zed/actions/workflows/run_tests.yml)

Welcome to Zed, a high-performance, multiplayer code editor from the creators of [Atom](https://github.com/atom/atom) and [Tree-sitter](https://github.com/tree-sitter/tree-sitter).

---

### Installation

On macOS, Linux, and Windows you can [download Zed directly](https://zed.dev/download) or [install Zed via your local package manager](https://zed.dev/docs/linux#installing-via-a-package-manager).

Other platforms are not yet available:

- Web ([tracking issue](https://github.com/zed-industries/zed/issues/5396))

### Developing Zed

- [Building Zed for macOS](./docs/src/development/macos.md)
- [Building Zed for Linux](./docs/src/development/linux.md)
- [Building Zed for Windows](./docs/src/development/windows.md)
- [Running Collaboration Locally](./docs/src/development/local-collaboration.md)

### Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for ways you can contribute to Zed.

Also... we&#039;re hiring! Check out our [jobs](https://zed.dev/jobs) page for open roles.

### Licensing

License information for third party dependencies must be correctly provided for CI to pass.

We use [`cargo-about`](https://github.com/EmbarkStudios/cargo-about) to automatically comply with open source licenses. If CI is failing, check the following:

- Is it showing a `no license specified` error for a crate you&#039;ve created? If so, add `publish = false` under `[package]` in your crate&#039;s Cargo.toml.
- Is the error `failed to satisfy license requirements` for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license&#039;s requirements. If you&#039;re unsure, ask a lawyer. Once you&#039;ve verified that this system is acceptable add the license&#039;s SPDX identifier to the `accepted` array in `script/licenses/zed-licenses.toml`.
- Is `cargo-about` unable to find the license for a dependency? If so, add a clarification field at the end of `script/licenses/zed-licenses.toml`, as specified in the [cargo-about book](https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/rustlings]]></title>
            <link>https://github.com/rust-lang/rustlings</link>
            <guid>https://github.com/rust-lang/rustlings</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[ü¶Ä Small exercises to get you used to reading and writing Rust code!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/rustlings">rust-lang/rustlings</a></h1>
            <p>ü¶Ä Small exercises to get you used to reading and writing Rust code!</p>
            <p>Language: Rust</p>
            <p>Stars: 60,961</p>
            <p>Forks: 11,033</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre># [Rustlings](https://rustlings.rust-lang.org) ü¶Ä

Small exercises to get you used to reading and writing [Rust](https://www.rust-lang.org) code - _Recommended in parallel to reading [the official Rust book](https://doc.rust-lang.org/book) üìöÔ∏è_

Visit the **website** for a demo, info about setup and more:

## ‚û°Ô∏è [rustlings.rust-lang.org](https://rustlings.rust-lang.org) ‚¨ÖÔ∏è
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[databendlabs/databend]]></title>
            <link>https://github.com/databendlabs/databend</link>
            <guid>https://github.com/databendlabs/databend</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[ùóîùóú-ùó°ùóÆùòÅùó∂ùòÉùó≤ ùóóùóÆùòÅùóÆ ùó™ùóÆùóøùó≤ùóµùóºùòÇùòÄùó≤. Blazing analytics, fast search, geo insights, vector AI. Built for multimodal analytics, Open-source Snowflake alternative. https://databend.com]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/databendlabs/databend">databendlabs/databend</a></h1>
            <p>ùóîùóú-ùó°ùóÆùòÅùó∂ùòÉùó≤ ùóóùóÆùòÅùóÆ ùó™ùóÆùóøùó≤ùóµùóºùòÇùòÄùó≤. Blazing analytics, fast search, geo insights, vector AI. Built for multimodal analytics, Open-source Snowflake alternative. https://databend.com</p>
            <p>Language: Rust</p>
            <p>Stars: 9,030</p>
            <p>Forks: 841</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;Databend&lt;/h1&gt;
&lt;h3 align=&quot;center&quot;&gt;The All-in-One Cloud Data Warehouse for Analytics &amp; AI&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;Built in &lt;strong&gt;Rust&lt;/strong&gt; for blazing fast, cost-efficient analytics.&lt;br&gt; Open-source, &lt;strong&gt;Snowflake-compatible&lt;/strong&gt;, and designed to unify BI, Search, and AI on object storage.&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://databend.com/&quot;&gt;‚òÅÔ∏è Try Cloud&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;#-quick-start&quot;&gt;üöÄ Quick Start&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://docs.databend.com/&quot;&gt;üìñ Documentation&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://link.databend.com/join-slack&quot;&gt;üí¨ Slack&lt;/a&gt;

&lt;br&gt;&lt;br&gt;

&lt;a href=&quot;https://github.com/databendlabs/databend/actions/workflows/release.yml&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/datafuselabs/databend/release.yml?branch=main&quot; alt=&quot;CI Status&quot; /&gt;
&lt;/a&gt;
&lt;img src=&quot;https://img.shields.io/badge/Platform-Linux%2C%20macOS%2C%20ARM-green.svg?style=flat&quot; alt=&quot;Platform&quot; /&gt;

&lt;/div&gt;

&lt;br&gt;

&lt;img src=&quot;https://github.com/user-attachments/assets/4c288d5c-9365-44f7-8cde-b2c7ebe15622&quot; alt=&quot;databend&quot; width=&quot;100%&quot; /&gt;

## üí° Why Databend?

Databend is an open-source, **All-in-One multimodal database** built in Rust. It seamlessly unifies **Analytics**, **AI**, **Search**, and **Geo** workloads into a single platform, enabling high-performance processing directly on top of object storage.

| | |
| :--- | :--- |
| **üìä BI &amp; Analytics**&lt;br&gt;Supercharge your analytics with a high-performance, vectorized SQL query engine. | **‚ú® Vector Search**&lt;br&gt;Power AI and RAG applications with built-in, high-speed vector similarity search. |
| **üìÑ JSON Search**&lt;br&gt;Seamlessly query and analyze semi-structured data with powerful JSON optimization. | **üåç Geo Search**&lt;br&gt;Efficiently store, index, and query geospatial data for location intelligence. |
| **üîÑ ETL Pipeline**&lt;br&gt;Streamline data ingestion and transformation with built-in Streams and Tasks. | **üåø Branching**&lt;br&gt;Create isolated Copy-on-Write branches instantly for dev, test, or experiments. |

![Databend Architecture](https://github.com/user-attachments/assets/288dea8d-0243-4c45-8d18-d4d402b08075)

## ‚ö° Quick Start

### 1. Cloud (Recommended)
[Start for free on Databend Cloud](https://docs.databend.com/guides/cloud/) - Production-ready in 60 seconds.

### 2. Local (Python)
Ideal for development and testing:

```bash
pip install databend
```

```python
import databend
ctx = databend.SessionContext()
ctx.sql(&quot;SELECT &#039;Hello, Databend!&#039;&quot;).show()
```

### 3. Docker
Run the full warehouse locally:

```bash
docker run -p 8000:8000 datafuselabs/databend
```

## üöÄ Use Cases

- **BI &amp; Analytics**: High-speed SQL on massive datasets. See [Query Processing](https://docs.databend.com/guides/query/sql-analytics).
- **AI &amp; Vectors**: Built-in vector search and embedding management. See [Vector Database](https://docs.databend.com/guides/query/vector-db).
- **Full-Text Search**: Fast indexing and retrieval on text and semi-structured data (JSON). See [JSON Search](https://docs.databend.com/guides/query/json-search).
- **Geospatial**: Advanced geo-analytics and mapping. See [Geospatial Analysis](https://docs.databend.com/guides/query/geo-analytics).
- **Stream &amp; Task**: Continuous data ingestion and transformation. See [Real-Time ETL](https://docs.databend.com/guides/query/lakehouse-etl).

## ü§ù Community &amp; Support

- [üìñ Documentation](https://docs.databend.com/)
- [üí¨ Join Slack](https://link.databend.com/join-slack)
- [üêõ Issue Tracker](https://github.com/databendlabs/databend/issues)
- [üó∫Ô∏è Roadmap](https://github.com/databendlabs/databend/issues/14167)

**Contributors are immortalized in the `system.contributors` table! üèÜ**

## üìÑ License

[Apache 2.0](licenses/Apache-2.0.txt) + [Elastic 2.0](licenses/Elastic.txt) | [Licensing FAQ](https://docs.databend.com/guides/products/dee/license)

---

&lt;div align=&quot;center&quot;&gt;
&lt;strong&gt;Redefining what&#039;s possible with data&lt;/strong&gt;&lt;br&gt;
&lt;a href=&quot;https://databend.com&quot;&gt;üåê Website&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://x.com/DatabendLabs&quot;&gt;üê¶ Twitter&lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ai-dynamo/dynamo]]></title>
            <link>https://github.com/ai-dynamo/dynamo</link>
            <guid>https://github.com/ai-dynamo/dynamo</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[A Datacenter Scale Distributed Inference Serving Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo</a></h1>
            <p>A Datacenter Scale Distributed Inference Serving Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 5,629</p>
            <p>Forks: 737</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

![Dynamo banner](./docs/images/frontpage-banner.png)

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)
[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)

| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/2486)** | **[Support matrix](https://github.com/ai-dynamo/dynamo/blob/main/docs/reference/support-matrix.md)** | **[Docs](https://docs.nvidia.com/dynamo/latest/index.html)** | **[Recipes](https://github.com/ai-dynamo/dynamo/tree/main/recipes)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Prebuilt containers](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** | **[Blogs](https://developer.nvidia.com/blog/tag/nvidia-dynamo)**

# NVIDIA Dynamo

High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.

## Framework Support Matrix

| Feature                                                                                           | [vLLM](docs/backends/vllm/README.md) | [SGLang](docs/backends/sglang/README.md) | [TensorRT-LLM](docs/backends/trtllm/README.md) |
| ------------------------------------------------------------------------------------------------- | ---- | ------ | ------------ |
| [**Disaggregated Serving**](/docs/design_docs/disagg_serving.md)                                 | ‚úÖ   | ‚úÖ     | ‚úÖ           |
| [**KV-Aware Routing**](/docs/router/kv_cache_routing.md)                                    | ‚úÖ   | ‚úÖ     | ‚úÖ           |
| [**SLA-Based Planner**](docs/planner/sla_planner.md)                                        | ‚úÖ   | ‚úÖ     | ‚úÖ           |
| [**KVBM**](docs/kvbm/kvbm_architecture.md)                                               | ‚úÖ   | üöß     | ‚úÖ           |

## Latest News

- [11/13] [Dynamo Office Hours Playlist](https://www.youtube.com/playlist?list=PL5B692fm6--tgryKu94h2Zb7jTFM3Go4X)
- [10/16] [How Baseten achieved 2x faster inference with NVIDIA Dynamo](https://www.baseten.co/blog/how-baseten-achieved-2x-faster-inference-with-nvidia-dynamo/#qwen3-coder-benchmarks-with-kv-routing)
- [10/13] [NVIDIA Blackwell Leads on New SemiAnalysis InferenceMax Benchmarks](https://developer.nvidia.com/blog/nvidia-blackwell-leads-on-new-semianalysis-inferencemax-benchmarks/)
- [09/09] [Dynamo + NVIDIA Blackwell Ultra Sets New MLPerf Inference Benchmark Record](https://blogs.nvidia.com/blog/mlperf-inference-blackwell-ultra/)
- [08/05] Deploy `openai/gpt-oss-120b` with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo [‚û°Ô∏è link](./docs/backends/trtllm/gpt-oss.md)

## The Era of Multi-GPU, Multi-Node

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-gpu-vertical.png&quot; alt=&quot;Multi Node Multi-GPU topology&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs‚Äîand sometimes many servers‚Äîbut it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.

Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:

- **Disaggregated prefill &amp; decode inference** ‚Äì Maximizes GPU throughput and facilitates trade off between throughput and latency.
- **Dynamic GPU scheduling** ‚Äì Optimizes performance based on fluctuating demand
- **LLM-aware request routing** ‚Äì Eliminates unnecessary KV cache re-computation
- **Accelerated data transfer** ‚Äì Reduces inference response time using NIXL.
- **KV cache offloading** ‚Äì Leverages multiple memory hierarchies for higher system throughput

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-architecture.png&quot; alt=&quot;Dynamo architecture&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.

# Installation

The following examples require a few system level packages.
Recommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/reference/support-matrix.md](docs/reference/support-matrix.md)

## 1. Initial setup

The Dynamo team recommends the `uv` Python package manager, although any way works. Install uv:

```
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Install Python development headers

Backend engines require Python development headers for JIT compilation. Install them with:

```bash
sudo apt install python3-dev
```

### Install etcd (optional) and NATS (required)

To coordinate across a data center, Dynamo relies on etcd and NATS. These will be used in production. To run Dynamo locally etcd is optional.

- [etcd](https://etcd.io/) can be run directly as `./etcd`.
- [nats](https://nats.io/) needs jetstream enabled: `nats-server -js`.

To quickly setup etcd &amp; NATS, you can also run:

```bash
# At the root of the repository:
docker compose -f deploy/docker-compose.yml up -d
```

To run locally without etcd, pass `--store-kv file` to both the frontend and workers. The directory used for key-value data can be configured via the `DYN_FILE_KV` environment variable (example: `export DYN_FILE_KV=/data/kv/dynamo`). Defaults to `$TMPDIR/dynamo_store_kv`.


## 2. Select an engine

We publish Python wheels specialized for each of our supported engines: vllm, sglang, and trtllm. The examples that follow use SGLang; continue reading for other engines.

```
uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install &quot;ai-dynamo[sglang]&quot;  #replace with [vllm], [trtllm], etc.
```

## 3. Run Dynamo

### Sanity check (optional)

Before trying out Dynamo, you can verify your system configuration and dependencies:

```bash
./deploy/sanity_check.py
```

This is a quick check for system resources, development tools, LLM frameworks, and Dynamo components.

### Running an LLM API server

Dynamo provides a simple way to spin up a local set of inference components including:

- **OpenAI Compatible Frontend** ‚Äì High performance OpenAI compatible http api server written in Rust.
- **Basic and Kv Aware Router** ‚Äì Route and load balance traffic to a set of workers.
- **Workers** ‚Äì Set of pre-configured LLM serving engines.

```
# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
# Pass --store-kv to use the filesystem instead of etcd. The workers and frontend must share a disk.
python -m dynamo.frontend --http-port 8000 [--tls-cert-path cert.pem] [--tls-key-path key.pem] [--store-kv file]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
# Pass --store-kv to use the filesystem instead of etcd. The workers and frontend must share a disk.
python -m dynamo.sglang --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B [--store-kv file]
```

#### Send a Request

```bash
curl localhost:8000/v1/chat/completions   -H &quot;Content-Type: application/json&quot;   -d &#039;{
    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,
    &quot;messages&quot;: [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello, how are you?&quot;
    }
    ],
    &quot;stream&quot;:false,
    &quot;max_tokens&quot;: 300
  }&#039; | jq
```

Rerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.

### Deploying Dynamo

- Follow the [Quickstart Guide](docs/kubernetes/README.md) to deploy on Kubernetes.
- Check out [Backends](examples/backends) to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)
- Run some [Examples](examples) to learn about building components in Dynamo and exploring various integrations.

### Benchmarking Dynamo

Dynamo provides comprehensive benchmarking tools to evaluate and optimize your deployments:

- **[Benchmarking Guide](docs/benchmarks/benchmarking.md)** ‚Äì Compare deployment topologies (aggregated vs. disaggregated vs. vanilla vLLM) using AIPerf
- **[SLA-Driven Dynamo Deployments](docs/planner/sla_planner_quickstart.md)** ‚Äì Optimize your deployment to meet SLA requirements

# Engines

Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (`python -m dynamo.frontend [--interactive]`).

## vLLM

```
uv pip install ai-dynamo[vllm]
```

Run the backend/worker like this:

```
python -m dynamo.vllm --help
```

vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass `--context-length &lt;value&gt;`.

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

## SGLang

```
# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
```

Run the backend/worker like this:

```
python -m dynamo.sglang --help
```

You can pass any sglang flags directly to this worker, see https://docs.sglang.ai/advanced_features/server_arguments.html . See there to use multiple GPUs.

## TensorRT-LLM

It is recommended to use [NGC PyTorch Container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) for running the TensorRT-LLM engine.

&gt; [!Note]
&gt; Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using.
&gt; For example, if you are using `tensorrt-llm==1.1.0rc5`, use the PyTorch container image version `25.06`.
&gt; To find the correct PyTorch container version for your desired `tensorrt-llm` release, visit the [TensorRT-LLM Dockerfile.multi](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docker/Dockerfile.multi) on GitHub. Switch to the branch that matches your `tensorrt-llm` version, and look for the `BASE_TAG` line to identify the recommended PyTorch container tag.

&gt; [!Important]
&gt; Launch container with the following additional settings `--shm-size=1g --ulimit memlock=-1`

### Install prerequisites

```
# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install &quot;cuda-python&gt;=12,&lt;13&quot;

sudo apt-get -y install libopenmpi-dev
```

&gt; [!Tip]
&gt; You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation [here](https://nvidia.github.io/TensorRT-LLM/installation/linux.html).

### After installing the pre-requisites above, install Dynamo

```
uv pip install ai-dynamo[trtllm]
```

Run the backend/worker like this:

```
python -m dynamo.trtllm --help
```

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

# Developing Locally

## 1. Install libraries

**Ubuntu:**

```
sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
```

**macOS:**

- [Homebrew](https://brew.sh/)

```
# if brew is not installed on your system, install it
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
```

- [Xcode](https://developer.apple.com/xcode/)

```
brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
```

If Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.

## 2. Install Rust

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
```

## 3. Create a Python virtual env:

Follow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don&#039;t have `uv` installed. Once uv is installed, create a virtual environment and activate it.

- Install uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

- Create a virtual environment

```bash
uv venv dynamo
source dynamo/bin/activate
```

## 4. Install build tools

```
uv pip install pip maturin
```

[Maturin](https://github.com/PyO3/maturin) is the Rust&lt;-&gt;Python bindings build tool.

## 5. Build the Rust bindings

```
cd lib/bindings/python
maturin develop --uv
```

## 6. Install the wheel

```
cd $PROJECT_ROOT
uv pip install -e .
```

You should now be able to run `python -m dynamo.frontend`.

Remember that nats and etcd must typically be running (see earlier).

Set the environment variable `DYN_LOG` to adjust the logging level; for example, `export DYN_LOG=debug`. It has the same syntax as `RUST_LOG`.

If you use vscode or cursor, we have a .devcontainer folder built on [Microsofts Extension](https://code.visualstudio.com/docs/devcontainers/containers). For instructions see the [ReadMe](.devcontainer/README.md) for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lance-format/lance]]></title>
            <link>https://github.com/lance-format/lance</link>
            <guid>https://github.com/lance-format/lance</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Open Lakehouse Format for Multimodal AI. Convert from Parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lance-format/lance">lance-format/lance</a></h1>
            <p>Open Lakehouse Format for Multimodal AI. Convert from Parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..</p>
            <p>Language: Rust</p>
            <p>Stars: 5,816</p>
            <p>Forks: 497</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;

&lt;img width=&quot;257&quot; alt=&quot;Lance Logo&quot; src=&quot;https://user-images.githubusercontent.com/917119/199353423-d3e202f7-0269-411d-8ff2-e747e419e492.png&quot;&gt;

**The Open Lakehouse Format for Multimodal AI**&lt;br/&gt;
**High-performance vector search, full-text search, random access, and feature engineering capabilities for the lakehouse.**&lt;br/&gt;
**Compatible with Pandas, DuckDB, Polars, PyArrow, Ray, Spark, and more integrations on the way.**

&lt;a href=&quot;https://lance.org&quot;&gt;Documentation&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://lance.org/community&quot;&gt;Community&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://discord.gg/lance&quot;&gt;Discord&lt;/a&gt;

[CI]: https://github.com/lance-format/lance/actions/workflows/rust.yml
[CI Badge]: https://github.com/lance-format/lance/actions/workflows/rust.yml/badge.svg
[Docs]: https://lance.org
[Docs Badge]: https://img.shields.io/badge/docs-passing-brightgreen
[crates.io]: https://crates.io/crates/lance
[crates.io badge]: https://img.shields.io/crates/v/lance.svg
[Python versions]: https://pypi.org/project/pylance/
[Python versions badge]: https://img.shields.io/pypi/pyversions/pylance

[![CI Badge]][CI]
[![Docs Badge]][Docs]
[![crates.io badge]][crates.io]
[![Python versions badge]][Python versions]

&lt;/p&gt;
&lt;/div&gt;

&lt;hr /&gt;

Lance is an open lakehouse format for multimodal AI. It contains a file format, table format, and catalog spec that allows you to build a complete lakehouse on top of object storage to power your AI workflows. Lance is perfect for:

1. Building search engines and feature stores with hybrid search capabilities.
2. Large-scale ML training requiring high performance IO and random access.
3. Storing, querying, and managing multimodal data including images, videos, audio, text, and embeddings.

The key features of Lance include:

* **Expressive hybrid search:** Combine vector similarity search, full-text search (BM25), and SQL analytics on the same dataset with accelerated secondary indices.

* **Lightning-fast random access:** 100x faster than Parquet or Iceberg for random access without sacrificing scan performance.

* **Native multimodal data support:** Store images, videos, audio, text, and embeddings in a single unified format with efficient blob encoding and lazy loading.

* **Data evolution:** Efficiently add columns with backfilled values without full table rewrites, perfect for ML feature engineering.

* **Zero-copy versioning:** ACID transactions, time travel, and automatic versioning without needing extra infrastructure.

* **Rich ecosystem integrations:** Apache Arrow, Pandas, Polars, DuckDB, Apache Spark, Ray, Trino, Apache Flink, and open catalogs (Apache Polaris, Unity Catalog, Apache Gravitino).

For more details, see the full [Lance format specification](https://lance.org/format).

&gt; [!TIP]
&gt; Lance is in active development and we welcome contributions. Please see our [contributing guide](https://lance.org/community/contributing/) for more information.

## Quick Start

**Installation**

```shell
pip install pylance
```

To install a preview release:

```shell
pip install --pre --extra-index-url https://pypi.fury.io/lance-format/pylance
```

&gt; [!NOTE]
&gt; For versions prior to 1.0.0-beta.4, you can find them at https://pypi.fury.io/lancedb/pylance

&gt; [!TIP]
&gt; Preview releases are released more often than full releases and contain the
&gt; latest features and bug fixes. They receive the same level of testing as full releases.
&gt; We guarantee they will remain published and available for download for at
&gt; least 6 months. When you want to pin to a specific version, prefer a stable release.

**Converting to Lance**

```python
import lance

import pandas as pd
import pyarrow as pa
import pyarrow.dataset

df = pd.DataFrame({&quot;a&quot;: [5], &quot;b&quot;: [10]})
uri = &quot;/tmp/test.parquet&quot;
tbl = pa.Table.from_pandas(df)
pa.dataset.write_dataset(tbl, uri, format=&#039;parquet&#039;)

parquet = pa.dataset.dataset(uri, format=&#039;parquet&#039;)
lance.write_dataset(parquet, &quot;/tmp/test.lance&quot;)
```

**Reading Lance data**
```python
dataset = lance.dataset(&quot;/tmp/test.lance&quot;)
assert isinstance(dataset, pa.dataset.Dataset)
```

**Pandas**
```python
df = dataset.to_table().to_pandas()
df
```

**DuckDB**
```python
import duckdb

# If this segfaults, make sure you have duckdb v0.7+ installed
duckdb.query(&quot;SELECT * FROM dataset LIMIT 10&quot;).to_df()
```

**Vector search**

Download the sift1m subset

```shell
wget ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz
tar -xzf sift.tar.gz
```

Convert it to Lance

```python
import lance
from lance.vector import vec_to_table
import numpy as np
import struct

nvecs = 1000000
ndims = 128
with open(&quot;sift/sift_base.fvecs&quot;, mode=&quot;rb&quot;) as fobj:
    buf = fobj.read()
    data = np.array(struct.unpack(&quot;&lt;128000000f&quot;, buf[4 : 4 + 4 * nvecs * ndims])).reshape((nvecs, ndims))
    dd = dict(zip(range(nvecs), data))

table = vec_to_table(dd)
uri = &quot;vec_data.lance&quot;
sift1m = lance.write_dataset(table, uri, max_rows_per_group=8192, max_rows_per_file=1024*1024)
```

Build the index

```python
sift1m.create_index(&quot;vector&quot;,
                    index_type=&quot;IVF_PQ&quot;,
                    num_partitions=256,  # IVF
                    num_sub_vectors=16)  # PQ
```

Search the dataset

```python
# Get top 10 similar vectors
import duckdb

dataset = lance.dataset(uri)

# Sample 100 query vectors. If this segfaults, make sure you have duckdb v0.7+ installed
sample = duckdb.query(&quot;SELECT vector FROM dataset USING SAMPLE 100&quot;).to_df()
query_vectors = np.array([np.array(x) for x in sample.vector])

# Get nearest neighbors for all of them
rs = [dataset.to_table(nearest={&quot;column&quot;: &quot;vector&quot;, &quot;k&quot;: 10, &quot;q&quot;: q})
      for q in query_vectors]
```

## Directory structure

| Directory          | Description              |
|--------------------|--------------------------|
| [rust](./rust)     | Core Rust implementation |
| [python](./python) | Python bindings (PyO3)   |
| [java](./java)     | Java bindings (JNI)      |
| [docs](./docs)     | Documentation source     |

## Benchmarks

### Vector search

We used the SIFT dataset to benchmark our results with 1M vectors of 128D

1. For 100 randomly sampled query vectors, we get &lt;1ms average response time (on a 2023 m2 MacBook Air)

![avg_latency.png](docs/src/images/avg_latency.png)

2. ANNs are always a trade-off between recall and performance

![avg_latency.png](docs/src/images/recall_vs_latency.png)

### Vs. parquet

We create a Lance dataset using the Oxford Pet dataset to do some preliminary performance testing of Lance as compared to Parquet and raw image/XMLs. For analytics queries, Lance is 50-100x better than reading the raw metadata. For batched random access, Lance is 100x better than both parquet and raw files.

![](docs/src/images/lance_perf.png)

## Why Lance for AI/ML workflows?

The machine learning development cycle involves multiple stages:

```mermaid
graph LR
    A[Collection] --&gt; B[Exploration];
    B --&gt; C[Analytics];
    C --&gt; D[Feature Engineer];
    D --&gt; E[Training];
    E --&gt; F[Evaluation];
    F --&gt; C;
    E --&gt; G[Deployment];
    G --&gt; H[Monitoring];
    H --&gt; A;
```

Traditional lakehouse formats were designed for SQL analytics and struggle with AI/ML workloads that require:
- **Vector search** for similarity and semantic retrieval
- **Fast random access** for sampling and interactive exploration
- **Multimodal data** storage (images, videos, audio alongside embeddings)
- **Data evolution** for feature engineering without full table rewrites
- **Hybrid search** combining vectors, full-text, and SQL predicates

While existing formats (Parquet, Iceberg, Delta Lake) excel at SQL analytics, they require additional specialized systems for AI capabilities. Lance brings these AI-first features directly into the lakehouse format.

A comparison of different formats across ML development stages:

|                     | Lance | Parquet &amp; ORC | JSON &amp; XML | TFRecord | Database | Warehouse |
|---------------------|-------|---------------|------------|----------|----------|-----------|
| Analytics           | Fast  | Fast          | Slow       | Slow     | Decent   | Fast      |
| Feature Engineering | Fast  | Fast          | Decent     | Slow     | Decent   | Good      |
| Training            | Fast  | Decent        | Slow       | Fast     | N/A      | N/A       |
| Exploration         | Fast  | Slow          | Fast       | Slow     | Fast     | Decent    |
| Infra Support       | Rich  | Rich          | Decent     | Limited  | Rich     | Rich      |

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[stakpak/agent]]></title>
            <link>https://github.com/stakpak/agent</link>
            <guid>https://github.com/stakpak/agent</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[DevOps agent that won't accidentally tweet your AWS credentials ü¶Ä]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stakpak/agent">stakpak/agent</a></h1>
            <p>DevOps agent that won't accidentally tweet your AWS credentials ü¶Ä</p>
            <p>Language: Rust</p>
            <p>Stars: 612</p>
            <p>Forks: 71</p>
            <p>Stars today: 69 stars today</p>
            <h2>README</h2><pre>

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source srcset=&quot;assets/stakpak-light.png&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
    &lt;img src=&quot;assets/stakpak-dark.png&quot; width=&quot;400&quot; /&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;Open source AI DevOps Agent in Your Terminal&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
Infrastructure shouldn‚Äôt be this hard. Stakpak lets developers secure, deploy, and run infra from the terminal.
&lt;/p&gt;

&lt;br /&gt;

&lt;!-- Badges Section --&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;!-- Built With Ratatui --&gt;
  &lt;a href=&quot;https://ratatui.rs/&quot;&gt;&lt;img src=&quot;https://ratatui.rs/built-with-ratatui/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;!-- License --&gt;
  &lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-blue.svg?style=flat-square&quot; /&gt;
  &lt;!-- Release (latest GitHub tag) --&gt;
  &lt;img src=&quot;https://img.shields.io/github/v/release/stakpak/agent?style=flat-square&quot; /&gt;
  &lt;!-- Build CI status (GitHub Actions) --&gt;
  &lt;img src=&quot;https://github.com/stakpak/agent/actions/workflows/ci.yml/badge.svg?style=flat-square&quot; /&gt;
  &lt;!-- Downloads (GitHub releases total) --&gt;
  &lt;img src=&quot;https://img.shields.io/github/downloads/stakpak/agent/total?style=flat-square&quot; /&gt;
  &lt;!-- Documentation --&gt;
  &lt;a href=&quot;https://stakpak.gitbook.io/docs/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-Documentation-0A84FF?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;!-- Discord Community --&gt;
  &lt;a href=&quot;https://discord.gg/QTZjETP7GB&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20Community-5865F2?logo=discord&amp;logoColor=white&amp;style=flat-square&quot; /&gt;&lt;/a&gt;

:star: Help us reach more developers and grow the Stakpak community. Star this repo!

![til](./assets/stakpak-overview.gif)

&lt;/p&gt;

You can&#039;t trust most AI agents with your DevOps. One mistake, and your production is toast.
Stakpak is built different:
- **Secret Substitution** - The LLM works with your credentials without ever seeing them
- **Warden Guardrails** - Network-level policies block destructive operations before they run
- **DevOps Playbooks Baked-in** - Curated library of DevOps knowledge in Stakpak Rulebooks

Generate infrastructure code, debug Kubernetes, configure CI/CD, automate deployments, without giving an LLM the keys to production.


## üîí Security Hardened

- **Mutual TLS (mTLS)** - End-to-end encrypted MCP
- **Dynamic Secret Substitution** - AI can read/write/compare secrets without seeing actual values
- **Secure Password Generation** - Generate cryptographically secure passwords with configurable complexity
- **Privacy Mode** - Redacts sensitive data like IP addresses and AWS account IDs

## üõ†Ô∏è Built for DevOps Work

- **Asynchronous Task Management** - Run background commands like port forwarding and servers with proper tracking and cancellation
- **Real-time Progress Streaming** - Long-running processes (Docker builds, deployments) stream progress updates in real-time
- **Infrastructure Code Indexing** - Automatic local indexing and semantic search for Terraform, Kubernetes, Dockerfile, and GitHub Actions
- **Documentation Research Agent** - Built-in web search for technical documentation, cloud providers, and development frameworks
- **Subagents** - Specialized research agents for code exploration and sandboxed analysis with different tool access levels (enabled with `--enable-subagents` flag)
- **Bulk Message Approval** - Approve multiple tool calls at once for efficient workflow execution
- **Reversible File Operations** - All file modifications are automatically backed up with recovery capabilities

## üß† Adaptive Intelligence

- **Rule Books** - Customize agent behavior with internal standard operating procedures, playbooks, and organizational policies
- **Persistent Knowledge** - Agent learns from interactions, remembers incidents, resources, and environment details to adapt to your workflow

## Installation

### All installation options (Linux, MacOs, Windows)

[Check the docs](https://stakpak.gitbook.io/docs/get-started/installing-stakpak-cli)

### Homebrew (Linux &amp; MacOS)

```bash
brew tap stakpak/stakpak
brew install stakpak
```

To update it you can use

```bash
brew update
brew upgrade stakpak
```

### Binary Release

Download the latest binary for your platform from our [GitHub Releases](https://github.com/stakpak/agent/releases).

### Docker

This image includes the most popular CLI tools the agent might need for everyday DevOps tasks like docker, kubectl, aws cli, gcloud, azure cli, and more.

```bash
docker pull ghcr.io/stakpak/agent:latest
```

## Usage
You can [use your own Anthropic or OpenAI API keys](#option-b-running-without-a-stakpak-api-key), [custom OpenAI compatible endpoint](#option-b-running-without-a-stakpak-api-key), or [a Stakpak API key](#option-a-running-with-a-stakpak-api-key).

### Option A: Running with a Stakpak API Key (no card required)

Just run `stakpak` and follow the instructions which will create a new API key for you.
```bash
stakpak
```

&gt; Brave users may encounter issues with automatic redirects to localhost ports during the API key creation flow. If this happens to you:
&gt;
&gt; Copy your new key from the browser paste it in your terminal

#### You could also set the environment variable `STAKPAK_API_KEY`

```bash
export STAKPAK_API_KEY=&lt;mykey&gt;
```

#### Or save your API key to `~/.stakpak/config.toml`

```bash
stakpak login --api-key $STAKPAK_API_KEY
```

#### View current account (Optional)

```bash
stakpak account
```

### Option B: Running Without a Stakpak API Key

Create `~/.stakpak/config.toml` with one of these configurations:

**Option 1: Bring Your Own Keys (BYOK)** - Use your Anthropic/OpenAI API keys:
```toml
[profiles.byok]
provider = &quot;local&quot;

# customize models
smart_model = &quot;claude-sonnet-4-5&quot;
eco_model = &quot;claude-haiku-4-5&quot;

[profiles.byok.anthropic]
api_key = &quot;sk-ant-...&quot;

[profiles.byok.openai]
api_key = &quot;sk-...&quot;

[profiles.byok.gemini]
api_key = &quot;sk-...&quot;

[settings]
```

**Option 2: Bring Your Own LLM** - Point to a local OpenAI-compatible endpoint (e.g. LM Studio):
```toml
[profiles.offline]
provider = &quot;local&quot;
smart_model = &quot;qwen/qwen3-coder-30b&quot;
eco_model = &quot;qwen/qwen3-coder-30b&quot;

[profiles.offline.openai]
api_endpoint = &quot;http://127.0.0.1:1234/v1/chat/completions&quot;
api_key = &quot;&quot;

[settings]
```

Then run with your profile:
```bash
stakpak --profile byok
# or
stakpak --profile offline
```

### Start Stakpak Agent TUI

```bash
# Open the TUI
stakpak
# Resume execution from a checkpoint
stakpak -c &lt;checkpoint-id&gt;
```

### Start Stakpak Agent TUI with Docker

```bash
docker run -it --entrypoint stakpak ghcr.io/stakpak/agent:latest
# for containerization tasks (you need to mount the Docker socket)
docker run -it \
   -v &quot;/var/run/docker.sock&quot;:&quot;/var/run/docker.sock&quot; \
   -v &quot;{your app path}&quot;:&quot;/agent/&quot; \
   --entrypoint stakpak ghcr.io/stakpak/agent:latest
```

### MCP Modes

You can use Stakpak as a secure MCP proxy or expose its security-hardened tools through an [MCP](https://modelcontextprotocol.io/) server.

#### MCT Server Tools

- **Local Mode (`--tool-mode local`)** - File operations and command execution only (no API key required)
- **Remote Mode (`--tool-mode remote`)** - AI-powered code generation and search tools (API key required)
- **Combined Mode (`--tool-mode combined`)** - Both local and remote tools (default, API key required)

#### Start MCP Server

```bash
# Local tools only (no API key required, mTLS enabled by default)
stakpak mcp start --tool-mode local

# Remote tools only (AI tools optimized for DevOps)
stakpak mcp start --tool-mode remote

# Combined mode (default - all tools with full security)
stakpak mcp start

# Disable mTLS (NOT recommended for production)
stakpak mcp start --disable-mcp-mtls
```

Additional flags for the MCP server:

- `--disable-secret-redaction` ‚Äì **not recommended**; prints secrets in plaintext to the console
- `--privacy-mode` ‚Äì redacts additional private data like IP addresses and AWS account IDs
- `--enable-slack-tools` ‚Äì enables experimental Slack tools

#### MCP Proxy Server

Stakpak also includes an MCP proxy server that can multiplex connections to multiple upstream MCP servers using a configuration file.

```bash
# Start MCP proxy with automatic config discovery
stakpak mcp proxy

# Start MCP proxy with explicit config file
stakpak mcp proxy --config-file ~/.stakpak/mcp.toml

# Disable secret redaction (NOT recommended ‚Äì secrets will be printed in logs)
stakpak mcp proxy --disable-secret-redaction

# Enable privacy mode to redact IPs, account IDs, etc.
stakpak mcp proxy --privacy-mode
```

### Agent Client Protocol (ACP)

ACP is a standardized protocol that enables AI agents to integrate directly with code editors like Zed, providing seamless AI-powered development assistance.

#### What ACP Offers with Stakpak

- **Real-time AI Chat** - Natural language conversations with context-aware AI assistance
- **Live Code Analysis** - AI can read, understand, and modify your codebase in real-time
- **Tool Execution** - AI can run commands, edit files, search code, and perform development tasks
- **Session Persistence** - Maintains conversation context across editor sessions
- **Streaming Responses** - Real-time AI responses with live progress updates
- **Agent Plans** - Visual task breakdown and progress tracking

#### Installation &amp; Setup

1. **Install Stakpak** (if not already installed)
2. **Configure Zed Editor** - Add to `~/.config/zed/settings.json`:

```json
{
  &quot;agent_servers&quot;: {
    &quot;Stakpak&quot;: {
      &quot;command&quot;: &quot;stakpak&quot;,
      &quot;args&quot;: [&quot;acp&quot;],
      &quot;env&quot;: {}
    }
  }
}
```

3. **Start ACP Agent**:

```bash
stakpak acp
```

4. **Use in Zed** - Click Assistant (‚ú®) ‚Üí `+` ‚Üí `New stakpak thread`

### Rulebook Management

Manage your standard operating procedures (SOPs), playbooks, and runbooks with Stakpak Rulebooks. Rulebooks customize agent behavior and provide context-specific guidance.

```bash
# List all rulebooks
stakpak rulebooks get
# or use the short alias
stakpak rb get

# Get a specific rulebook
stakpak rb get stakpak://my-org/deployment-guide.md

# Create or update a rulebook from a markdown file
stakpak rb apply my-rulebook.md

# Delete a rulebook
stakpak rb delete stakpak://my-org/old-guide.md
```

#### Rulebook Format

Rulebooks are markdown files with YAML frontmatter:

```markdown
---
uri: stakpak://my-org/deployment-guide.md
description: Standard deployment procedures for production
tags:
  - deployment
  - production
  - sop
---

# Deployment Guide

Your deployment procedures and guidelines here...
```

## Platform Testing

### Windows

Comprehensive testing report for Windows CLI functionality, including installation, configuration, and integration with WSL2 and Docker.

[View Windows Testing Report](platform-testing/windows-testing-report.md)

---

## ‚≠ê Like what we&#039;re building?

If our Agent saves you time or makes your DevOps life easier,  
**consider giving us a star on GitHub ‚Äî it really helps!**

## [![Star on GitHub](https://img.shields.io/github/stars/stakpak/agent?style=social)](https://github.com/stakpak/agent/stargazers)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ajeetdsouza/zoxide]]></title>
            <link>https://github.com/ajeetdsouza/zoxide</link>
            <guid>https://github.com/ajeetdsouza/zoxide</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[A smarter cd command. Supports all major shells.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ajeetdsouza/zoxide">ajeetdsouza/zoxide</a></h1>
            <p>A smarter cd command. Supports all major shells.</p>
            <p>Language: Rust</p>
            <p>Stars: 31,727</p>
            <p>Forks: 708</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-configure-file {
  &quot;MD013&quot;: {
    &quot;code_blocks&quot;: false,
    &quot;tables&quot;: false
  },
  &quot;MD033&quot;: false,
  &quot;MD041&quot;: false
} --&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;sup&gt;Special thanks to:&lt;/sup&gt;

&lt;!-- markdownlint-disable-next-line MD013 --&gt;
&lt;div&gt;&lt;a href=&quot;https://go.warp.dev/zoxide&quot;&gt;&lt;img alt=&quot;Sponsored by Warp&quot; width=&quot;230&quot; src=&quot;https://raw.githubusercontent.com/warpdotdev/brand-assets/refs/heads/main/Github/Sponsor/Warp-Github-LG-03.png&quot; /&gt;&lt;/a&gt;&lt;/div&gt;
&lt;div&gt;&lt;sup&gt;&lt;b&gt;Warp, built for coding with multiple AI agents.&lt;/b&gt;&lt;/sup&gt;&lt;/div&gt;
&lt;div&gt;&lt;sup&gt;Available for macOS, Linux, and Windows.&lt;/sup&gt;&lt;/div&gt;
&lt;div&gt;&lt;sup&gt;
  Visit
  &lt;a href=&quot;https://go.warp.dev/zoxide&quot;&gt;&lt;u&gt;warp.dev&lt;/u&gt;&lt;/a&gt;
  to learn more.
&lt;/sup&gt;&lt;/div&gt;

&lt;hr /&gt;

# zoxide

[![crates.io][crates.io-badge]][crates.io]
[![Downloads][downloads-badge]][releases]
[![Built with Nix][builtwithnix-badge]][builtwithnix]

zoxide is a **smarter cd command**, inspired by z and autojump.

It remembers which directories you use most frequently, so you can &quot;jump&quot; to
them in just a few keystrokes.&lt;br /&gt;
zoxide works on all major shells.

[Getting started](#getting-started) ‚Ä¢
[Installation](#installation) ‚Ä¢
[Configuration](#configuration) ‚Ä¢
[Integrations](#third-party-integrations)

&lt;/div&gt;

## Getting started

![Tutorial][tutorial]

```sh
z foo              # cd into highest ranked directory matching foo
z foo bar          # cd into highest ranked directory matching foo and bar
z foo /            # cd into a subdirectory starting with foo

z ~/foo            # z also works like a regular cd command
z foo/             # cd into relative path
z ..               # cd one level up
z -                # cd into previous directory

zi foo             # cd with interactive selection (using fzf)

z foo&lt;SPACE&gt;&lt;TAB&gt;  # show interactive completions (zoxide v0.8.0+, bash 4.4+/fish/zsh only)
```

Read more about the matching algorithm [here][algorithm-matching].

## Installation

zoxide can be installed in 4 easy steps:

1. **Install binary**

   zoxide runs on most major platforms. If your platform isn&#039;t listed below,
   please [open an issue][issues].

   &lt;details&gt;
   &lt;summary&gt;Linux / WSL&lt;/summary&gt;

   &gt; The recommended way to install zoxide is via the install script:
   &gt;
   &gt; ```sh
   &gt; curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh
   &gt; ```
   &gt;
   &gt; Or, you can use a package manager:
   &gt;
   &gt; | Distribution        | Repository                  | Instructions                                                                                          |
   &gt; | ------------------- | --------------------------- | ----------------------------------------------------------------------------------------------------- |
   &gt; | **_Any_**           | **[crates.io]**             | `cargo install zoxide --locked`                                                                       |
   &gt; | _Any_               | [asdf]                      | `asdf plugin add zoxide https://github.com/nyrst/asdf-zoxide.git` &lt;br /&gt; `asdf install zoxide latest` |
   &gt; | _Any_               | [conda-forge]               | `conda install -c conda-forge zoxide`                                                                 |
   &gt; | _Any_               | [guix]                      | `guix install zoxide`                                                                                 |
   &gt; | _Any_               | [Linuxbrew]                 | `brew install zoxide`                                                                                 |
   &gt; | _Any_               | [nixpkgs]                   | `nix-env -iA nixpkgs.zoxide`                                                                          |
   &gt; | Alpine Linux 3.13+  | [Alpine Linux Packages]     | `apk add zoxide`                                                                                      |
   &gt; | Arch Linux          | [Arch Linux Extra]          | `pacman -S zoxide`                                                                                    |
   &gt; | ~Debian~[^1]    | ~[Debian Packages]~         | ~`apt install zoxide`~                                                                                    |
   &gt; | Devuan 4.0+         | [Devuan Packages]           | `apt install zoxide`                                                                                  |
   &gt; | Exherbo Linux       | [Exherbo packages]          | `cave resolve -x repository/rust` &lt;br /&gt; `cave resolve -x zoxide`                                     |
   &gt; | Fedora 32+          | [Fedora Packages]           | `dnf install zoxide`                                                                                  |
   &gt; | Gentoo              | [Gentoo Packages]           | `emerge app-shells/zoxide`                                                                            |
   &gt; | Manjaro             |                             | `pacman -S zoxide`                                                                                    |
   &gt; | openSUSE Tumbleweed | [openSUSE Factory]          | `zypper install zoxide`                                                                               |
   &gt; | ~Parrot OS~[^1]     |                             | ~`apt install zoxide`~                                                                                |
   &gt; | ~Raspbian~[^1]  | ~[Raspbian Packages]~       | ~`apt install zoxide`~                                                                                    |
   &gt; | Rhino Linux         | [Pacstall Packages]         | `pacstall -I zoxide-deb`                                                                              |
   &gt; | Slackware 15.0+     | [SlackBuilds]               | [Instructions][slackbuilds-howto]                                                                     |
   &gt; | Solus               | [Solus Packages]            | `eopkg install zoxide`                                                                                |
   &gt; | ~Ubuntu~[^1]        | ~[Ubuntu Packages]~         | ~`apt install zoxide`~                                                                                |
   &gt; | Void Linux          | [Void Linux Packages]       | `xbps-install -S zoxide`                                                                              |

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;macOS&lt;/summary&gt;

   &gt; To install zoxide, use a package manager:
   &gt;
   &gt; | Repository      | Instructions                                                                                          |
   &gt; | --------------- | ----------------------------------------------------------------------------------------------------- |
   &gt; | **[crates.io]** | `cargo install zoxide --locked`                                                                       |
   &gt; | **[Homebrew]**  | `brew install zoxide`                                                                                 |
   &gt; | [asdf]          | `asdf plugin add zoxide https://github.com/nyrst/asdf-zoxide.git` &lt;br /&gt; `asdf install zoxide latest` |
   &gt; | [conda-forge]   | `conda install -c conda-forge zoxide`                                                                 |
   &gt; | [MacPorts]      | `port install zoxide`                                                                                 |
   &gt; | [nixpkgs]       | `nix-env -iA nixpkgs.zoxide`                                                                          |
   &gt;
   &gt; Or, run this command in your terminal:
   &gt;
   &gt; ```sh
   &gt; curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh
   &gt; ```

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;Windows&lt;/summary&gt;

   &gt; zoxide works with PowerShell, as well as shells running in Cygwin, Git
   &gt; Bash, and MSYS2.
   &gt;
   &gt; The recommended way to install zoxide is via `winget`:
   &gt;
   &gt; ```sh
   &gt; winget install ajeetdsouza.zoxide
   &gt; ```
   &gt;
   &gt; Or, you can use an alternative package manager:
   &gt;
   &gt; | Repository      | Instructions                          |
   &gt; | --------------- | ------------------------------------- |
   &gt; | **[crates.io]** | `cargo install zoxide --locked`       |
   &gt; | [Chocolatey]    | `choco install zoxide`                |
   &gt; | [conda-forge]   | `conda install -c conda-forge zoxide` |
   &gt; | [Scoop]         | `scoop install zoxide`                |
   &gt;
   &gt; If you&#039;re using Cygwin, Git Bash, or MSYS2, you can also use the install script:
   &gt;
   &gt; ```sh
   &gt; curl -sSfL https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | sh
   &gt; ```

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;BSD&lt;/summary&gt;

   &gt; To install zoxide, use a package manager:
   &gt;
   &gt; | Distribution  | Repository      | Instructions                    |
   &gt; | ------------- | --------------- | ------------------------------- |
   &gt; | **_Any_**     | **[crates.io]** | `cargo install zoxide --locked` |
   &gt; | DragonFly BSD | [DPorts]        | `pkg install zoxide`            |
   &gt; | FreeBSD       | [FreshPorts]    | `pkg install zoxide`            |
   &gt; | NetBSD        | [pkgsrc]        | `pkgin install zoxide`          |
   &gt;
   &gt; Or, run this command in your terminal:
   &gt;
   &gt; ```sh
   &gt; curl -sS https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | bash
   &gt; ```

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;Android&lt;/summary&gt;

   &gt; To install zoxide, use a package manager:
   &gt;
   &gt; | Repository | Instructions         |
   &gt; | ---------- | -------------------- |
   &gt; | [Termux]   | `pkg install zoxide` |
   &gt;
   &gt; Or, run this command in your terminal:
   &gt;
   &gt; ```sh
   &gt; curl -sS https://raw.githubusercontent.com/ajeetdsouza/zoxide/main/install.sh | bash
   &gt; ```

   &lt;/details&gt;

2. **Setup zoxide on your shell**

   To start using zoxide, add it to your shell.

   &lt;details&gt;
   &lt;summary&gt;Bash&lt;/summary&gt;

   &gt; Add this to the &lt;ins&gt;**end**&lt;/ins&gt; of your config file (usually `~/.bashrc`):
   &gt;
   &gt; ```sh
   &gt; eval &quot;$(zoxide init bash)&quot;
   &gt; ```

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;Elvish&lt;/summary&gt;

   &gt; Add this to the &lt;ins&gt;**end**&lt;/ins&gt; of your config file (usually `~/.elvish/rc.elv`):
   &gt;
   &gt; ```sh
   &gt; eval (zoxide init elvish | slurp)
   &gt; ```
   &gt;
   &gt; **Note**
   &gt; zoxide only supports elvish v0.18.0 and above.

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;Fish&lt;/summary&gt;

   &gt; Add this to the &lt;ins&gt;**end**&lt;/ins&gt; of your config file (usually
   &gt; `~/.config/fish/config.fish`):
   &gt;
   &gt; ```sh
   &gt; zoxide init fish | source
   &gt; ```

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;Nushell&lt;/summary&gt;

   &gt; Add this to the &lt;ins&gt;**end**&lt;/ins&gt; of your env file (find it by running `$nu.env-path`
   &gt; in Nushell):
   &gt;
   &gt; ```sh
   &gt; zoxide init nushell | save -f ~/.zoxide.nu
   &gt; ```
   &gt;
   &gt; Now, add this to the &lt;ins&gt;**end**&lt;/ins&gt; of your config file (find it by running
   &gt; `$nu.config-path` in Nushell):
   &gt;
   &gt; ```sh
   &gt; source ~/.zoxide.nu
   &gt; ```
   &gt;
   &gt; **Note**
   &gt; zoxide only supports Nushell v0.89.0+.

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;PowerShell&lt;/summary&gt;

   &gt; Add this to the &lt;ins&gt;**end**&lt;/ins&gt; of your config file (find it by running
   &gt; `echo $profile` in PowerShell):
   &gt;
   &gt; ```powershell
   &gt; Invoke-Expression (&amp; { (zoxide init powershell | Out-String) })
   &gt; ```

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;Tcsh&lt;/summary&gt;

   &gt; Add this to the &lt;ins&gt;**end**&lt;/ins&gt; of your config file (usually `~/.tcshrc`):
   &gt;
   &gt; ```sh
   &gt; zoxide init tcsh &gt; ~/.zoxide.tcsh
   &gt; source ~/.zoxide.tcsh
   &gt; ```

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;Xonsh&lt;/summary&gt;

   &gt; Add this to the &lt;ins&gt;**end**&lt;/ins&gt; of your config file (usually `~/.xonshrc`):
   &gt;
   &gt; ```python
   &gt; execx($(zoxide init xonsh), &#039;exec&#039;, __xonsh__.ctx, filename=&#039;zoxide&#039;)
   &gt; ```

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;Zsh&lt;/summary&gt;

   &gt; Add this to the &lt;ins&gt;**end**&lt;/ins&gt; of your config file (usually `~/.zshrc`):
   &gt;
   &gt; ```sh
   &gt; eval &quot;$(zoxide init zsh)&quot;
   &gt; ```
   &gt;
   &gt; For completions to work, the above line must be added _after_ `compinit` is
   &gt; called. You may have to rebuild your completions cache by running
   &gt; `rm ~/.zcompdump*; compinit`.

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;Any POSIX shell&lt;/summary&gt;

   &gt; Add this to the &lt;ins&gt;**end**&lt;/ins&gt; of your config file:
   &gt;
   &gt; ```sh
   &gt; eval &quot;$(zoxide init posix --hook prompt)&quot;
   &gt; ```

   &lt;/details&gt;

3. **Install fzf** &lt;sup&gt;(optional)&lt;/sup&gt;

   [fzf] is a command-line fuzzy finder, used by zoxide for completions /
   interactive selection. It can be installed from [here][fzf-installation].

   &gt; **Note**
   &gt; The minimum supported fzf version is v0.51.0.

4. **Import your data** &lt;sup&gt;(optional)&lt;/sup&gt;

   If you currently use any of these plugins, you may want to import your data
   into zoxide:

   &lt;details&gt;
   &lt;summary&gt;autojump&lt;/summary&gt;

   &gt; Run this command in your terminal:
   &gt;
   &gt; ```sh
   &gt; zoxide import --from=autojump &quot;/path/to/autojump/db&quot;
   &gt; ```
   &gt;
   &gt; The path usually varies according to your system:
   &gt;
   &gt; | OS      | Path                                                                                 | Example                                                |
   &gt; | ------- | ------------------------------------------------------------------------------------ | ------------------------------------------------------ |
   &gt; | Linux   | `$XDG_DATA_HOME/autojump/autojump.txt` or `$HOME/.local/share/autojump/autojump.txt` | `/home/alice/.local/share/autojump/autojump.txt`       |
   &gt; | macOS   | `$HOME/Library/autojump/autojump.txt`                                                | `/Users/Alice/Library/autojump/autojump.txt`           |
   &gt; | Windows | `%APPDATA%\autojump\autojump.txt`                                                    | `C:\Users\Alice\AppData\Roaming\autojump\autojump.txt` |

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;fasd, z, z.lua, zsh-z&lt;/summary&gt;

   &gt; Run this command in your terminal:
   &gt;
   &gt; ```sh
   &gt; zoxide import --from=z &quot;path/to/z/db&quot;
   &gt; ```
   &gt;
   &gt; The path usually varies according to your system:
   &gt;
   &gt; | Plugin           | Path                                                                                |
   &gt; | ---------------- | ----------------------------------------------------------------------------------- |
   &gt; | fasd             | `$_FASD_DATA` or `$HOME/.fasd`                                                      |
   &gt; | z (bash/zsh)     | `$_Z_DATA` or `$HOME/.z`                                                            |
   &gt; | z (fish)         | `$Z_DATA` or `$XDG_DATA_HOME/z/data` or `$HOME/.local/share/z/data`                 |
   &gt; | z.lua (bash/zsh) | `$_ZL_DATA` or `$HOME/.zlua`                                                        |
   &gt; | z.lua (fish)     | `$XDG_DATA_HOME/zlua/zlua.txt` or `$HOME/.local/share/zlua/zlua.txt` or `$_ZL_DATA` |
   &gt; | zsh-z            | `$ZSHZ_DATA` or `$_Z_DATA` or `$HOME/.z`                                            |

   &lt;/details&gt;

   &lt;details&gt;
   &lt;summary&gt;ZLocation&lt;/summary&gt;

   &gt; Run this command in PowerShell:
   &gt;
   &gt; ```powershell
   &gt; $db = New-TemporaryFile
   &gt; (Get-ZLocation).GetEnumerator() | ForEach-Object { Write-Output ($_.Name+&#039;|&#039;+$_.Value+&#039;|0&#039;) } | Out-File $db
   &gt; zoxide import --from=z $db
   &gt; ```

   &lt;/details&gt;

## Configuration

### Flags

When calling `zoxide init`, the following flags are available:

- `--cmd`
  - Changes the prefix of the `z` and `zi` commands.
  - `--cmd j` would change the commands to (`j`, `ji`).
  - `--cmd cd` would replace the `cd` command.
- `--hook &lt;HOOK&gt;`
  - Changes how often zoxide increments a directory&#039;s score:

    | Hook            | Description                       |
    | --------------- | --------------------------------- |
    | `none`          | Never                             |
    | `prompt`        | At every shell prompt             |
    | `pwd` (default) | Whenever the directory is changed |

- `--no-cmd`
  - Prevents zoxide from defining the `z` and `zi` commands.
  - These functions will still be available in your shell as `__zoxide_z` and
    `__zoxide_zi`, should you choose to redefine them.

### Environment variables

Environment variables[^2] can be used for configuration. They must be set before
`zoxide init` is called.

- `_ZO_DATA_DIR`
  - Specifies the directory in which the database is stored.
  - The default value varies across OSes:

    | OS          | Path                                     | Example                                    |
    | ----------- | ---------------------------------------- | ------------------------------------------ |
    | Linux / BSD | `$XDG_DATA_HOME` or `$HOME/.local/share` | `/home/alice/.local/share`                 |
    | macOS       | `$HOME/Library/Application Support`      | `/Users/Alice/Library/Application Support` |
    | Windows     | `%LOCALAPPDATA%`                         | `C:\Users\Alice\AppData\Local`             |

- `_ZO_ECHO`
  - When set to 1, `z` will print the matched directory before navigating to
    it.
- `_ZO_EXCLUDE_DIRS`
  - Excludes the specified directories from the database.
  - This is provided as a list of [globs][glob], separated by OS-specific
    characters:

    | OS                  | Separator | Example                 |
    | ------------------- | --------- | ----------------------- |
    | Linux / macOS / BSD | `:`       | `$HOME:$HOME/private/*` |
    | Windows             | `;`       | `$HOME;$HOME/private/*` |

  - By default, this is set to `&quot;$HOME&quot;`.
- `_ZO_FZF_OPTS`
  - Custom options to pass to [fzf] during interactive selection. See
    [`man fzf`][fzf-man] for the list of options.
- `_ZO_MAXAGE`
  - Configures the [aging algorithm][algorithm-aging], which limits the maximum
    number of entries in the database.
  - By default, this is set to 10000.
- `_ZO_RESOLVE_SYMLINKS`
  - When set to 1, `z` will resolve symlinks before adding directories to the
    database.

## Third-party integrations

| Application           | Description                                  | Plugin                     |
| --------------------- | -------------------------------------------- | -------------------------- |
| [aerc]                | Email client                                 | Natively supported         |
| [alfred]              | macOS launcher                               | [alfred-zoxide]            |
| [clink]               | Improved cmd.exe for Windows                 | [clink-zoxide]             |
| [emacs]               | Text editor                                  | [zoxide.el]                |
| [felix]               | File manager                                 | Natively supported         |
| [joshuto]             | File manager                                 | Natively supported         |
| [lf]                  | File manager                                 | See the [wiki][lf-wiki]    |
| [nnn]                 | File manager                                 | [nnn-autojump]             |
| [ranger]              | File manager                                 | [ranger-zoxide]            |
| [raycast]             | macOS launcher                               | [raycast-zoxide]           |
| [rfm]                 | File manager                                 | Natively supported         |
| [sesh]                | `tmux` session manager                       | Natively supported         |
| [telescope.nvim]      | Fuzzy finder for Neovim                      | [telescope-zoxide]         |
| [tmux-session-wizard] | `tmux` session manager                       | Natively supported         |
| [tmux-sessionx]       | `tmux` session manager                       | Natively supported         |
| [vim] / [neovim]      | Text editor                                  | [zoxide.vim]               |
| [xplr]                | File manager                                 | [zoxide.xplr]              |
| [xxh]                 | Transports shell configuration over SSH      | [xxh-plugin-prerun-zoxide] |
| [yazi]                | File manager                                 | Natively

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[EasyTier/EasyTier]]></title>
            <link>https://github.com/EasyTier/EasyTier</link>
            <guid>https://github.com/EasyTier/EasyTier</guid>
            <pubDate>Fri, 12 Dec 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[A simple, decentralized mesh VPN with WireGuard support.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EasyTier/EasyTier">EasyTier/EasyTier</a></h1>
            <p>A simple, decentralized mesh VPN with WireGuard support.</p>
            <p>Language: Rust</p>
            <p>Stars: 8,562</p>
            <p>Forks: 794</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre># EasyTier

[![Github release](https://img.shields.io/github/v/tag/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/releases)
[![GitHub](https://img.shields.io/github/license/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/blob/main/LICENSE)
[![GitHub last commit](https://img.shields.io/github/last-commit/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/commits/main)
[![GitHub issues](https://img.shields.io/github/issues/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/issues)
[![GitHub Core Actions](https://github.com/EasyTier/EasyTier/actions/workflows/core.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/core.yml)
[![GitHub GUI Actions](https://github.com/EasyTier/EasyTier/actions/workflows/gui.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/gui.yml)
[![GitHub Test Actions](https://github.com/EasyTier/EasyTier/actions/workflows/test.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/test.yml)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/EasyTier/EasyTier)

[ÁÆÄ‰Ωì‰∏≠Êñá](/README_CN.md) | [English](/README.md)

&gt; ‚ú® A simple, secure, decentralized virtual private network solution powered by Rust and Tokio

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;assets/config-page.png&quot; width=&quot;300&quot; alt=&quot;config page&quot;&gt;
&lt;img src=&quot;assets/running-page.png&quot; width=&quot;300&quot; alt=&quot;running page&quot;&gt;
&lt;/p&gt;

üìö **[Full Documentation](https://easytier.cn/en/)** | üñ•Ô∏è **[Web Console](https://easytier.cn/web)** | üìù **[Download Releases](https://github.com/EasyTier/EasyTier/releases)** | üß© **[Third Party Tools](https://easytier.cn/en/guide/installation_gui.html#third-party-graphical-interfaces)** | ‚ù§Ô∏è **[Sponsor](#sponsor)**

## Features

### Core Features

- üîí **Decentralized**: Nodes are equal and independent, no centralized services required  
- üöÄ **Easy to Use**: Multiple operation methods via web, client, and command line  
- üåç **Cross-Platform**: Supports Win/MacOS/Linux/FreeBSD/Android and X86/ARM/MIPS architectures  
- üîê **Secure**: AES-GCM or WireGuard encryption, prevents man-in-the-middle attacks  

### Advanced Capabilities

- üîå **Efficient NAT Traversal**: Supports UDP and IPv6 traversal, works with NAT4-NAT4 networks  
- üåê **Subnet Proxy**: Nodes can share subnets for other nodes to access  
- üîÑ **Intelligent Routing**: Latency priority and automatic route selection for best network experience  
- ‚ö° **High Performance**: Zero-copy throughout the entire link, supports TCP/UDP/WSS/WG protocols  

### Network Optimization

- üìä **UDP Loss Resistance**: KCP/QUIC proxy optimizes latency and bandwidth in high packet loss environments  
- üîß **Web Management**: Easy configuration and monitoring through web interface  
- üõ†Ô∏è **Zero Config**: Simple deployment with statically linked executables  

## Quick Start

### üì• Installation

Choose the installation method that best suits your needs:

```bash
# 1. Download pre-built binary (Recommended, All platforms supported)
# Visit https://github.com/EasyTier/EasyTier/releases

# 2. Install via cargo (Latest development version)
cargo install --git https://github.com/EasyTier/EasyTier.git easytier

# 3. Install via Docker
# See https://easytier.cn/en/guide/installation.html#installation-methods

# 4. Linux Quick Install
wget -O- https://raw.githubusercontent.com/EasyTier/EasyTier/main/script/install.sh | sudo bash -s install

# 5. MacOS via Homebrew
brew tap brewforge/chinese
brew install --cask easytier-gui

# 6. OpenWrt Luci Web UI
# Visit https://github.com/EasyTier/luci-app-easytier

# 7. (Optional) Install shell completions:
easytier-core --gen-autocomplete fish &gt; ~/.config/fish/completions/easytier-core.fish
easytier-cli gen-autocomplete fish &gt; ~/.config/fish/completions/easytier-cli.fish

```

### üöÄ Basic Usage

#### Quick Networking with Shared Nodes

EasyTier supports quick networking using shared public nodes. When you don&#039;t have a public IP, you can use the free shared nodes provided by the EasyTier community. Nodes will automatically attempt NAT traversal and establish P2P connections. When P2P fails, data will be relayed through shared nodes.

The currently deployed shared public node is `tcp://public.easytier.cn:11010`.

When using shared nodes, each node entering the network needs to provide the same `--network-name` and `--network-secret` parameters as the unique identifier of the network.

Taking two nodes as an example (Please use more complex network name to avoid conflicts):

1. Run on Node A:

```bash
# Run with administrator privileges
sudo easytier-core -d --network-name abc --network-secret abc -p tcp://public.easytier.cn:11010
```

2. Run on Node B:

```bash
# Run with administrator privileges
sudo easytier-core -d --network-name abc --network-secret abc -p tcp://public.easytier.cn:11010
```

After successful execution, you can check the network status using `easytier-cli`:

```text
| ipv4         | hostname       | cost  | lat_ms | loss_rate | rx_bytes | tx_bytes | tunnel_proto | nat_type | id         | version         |
| ------------ | -------------- | ----- | ------ | --------- | -------- | -------- | ------------ | -------- | ---------- | --------------- |
| 10.126.126.1 | abc-1          | Local | *      | *         | *        | *        | udp          | FullCone | 439804259  | 2.4.5-70e69a38~ |
| 10.126.126.2 | abc-2          | p2p   | 3.452  | 0         | 17.33 kB | 20.42 kB | udp          | FullCone | 390879727  | 2.4.5-70e69a38~ |
|              | PublicServer_a | p2p   | 27.796 | 0.000     | 50.01 kB | 67.46 kB | tcp          | Unknown  | 3771642457 | 2.4.5-70e69a38~ |
```

You can test connectivity between nodes:

```bash
# Test connectivity
ping 10.126.126.1
ping 10.126.126.2
```

Note: If you cannot ping through, it may be that the firewall is blocking incoming traffic. Please turn off the firewall or add allow rules.

To improve availability, you can connect to multiple shared nodes simultaneously:

```bash
# Connect to multiple shared nodes
sudo easytier-core -d --network-name abc --network-secret abc -p tcp://public.easytier.cn:11010 -p udp://public.easytier.cn:11010
```

Once your network is set up successfully, you can easily configure it to start automatically on system boot. Refer to the [One-Click Register Service guide](https://easytier.cn/en/guide/network/oneclick-install-as-service.html) for step-by-step instructions on registering EasyTier as a system service.

#### Decentralized Networking

EasyTier is fundamentally decentralized, with no distinction between server and client. As long as one device can communicate with any node in the virtual network, it can join the virtual network. Here&#039;s how to set up a decentralized network:

1. Start First Node (Node A):

```bash
# Start the first node
sudo easytier-core -i 10.144.144.1
```

After startup, this node will listen on the following ports by default:
- TCP: 11010
- UDP: 11010
- WebSocket: 11011
- WebSocket SSL: 11012
- WireGuard: 11013

2. Connect Second Node (Node B):

```bash
# Connect to the first node using its public IP
sudo easytier-core -i 10.144.144.2 -p udp://FIRST_NODE_PUBLIC_IP:11010
```

3. Verify Connection:

```bash
# Test connectivity
ping 10.144.144.2

# View connected peers
easytier-cli peer

# View routing information
easytier-cli route

# View local node information
easytier-cli node
```

For more nodes to join the network, they can connect to any existing node in the network using the `-p` parameter:

```bash
# Connect to any existing node using its public IP
sudo easytier-core -i 10.144.144.3 -p udp://ANY_EXISTING_NODE_PUBLIC_IP:11010
```

### üîç Advanced Features

#### Subnet Proxy

Assuming the network topology is as follows, Node B wants to share its accessible subnet 10.1.1.0/24 with other nodes:

```mermaid
flowchart LR

subgraph Node A Public IP 22.1.1.1
nodea[EasyTier&lt;br/&gt;10.144.144.1]
end

subgraph Node B
nodeb[EasyTier&lt;br/&gt;10.144.144.2]
end

id1[[10.1.1.0/24]]

nodea &lt;--&gt; nodeb &lt;-.-&gt; id1
```

To share a subnet, add the `-n` parameter when starting EasyTier:

```bash
# Share subnet 10.1.1.0/24 with other nodes
sudo easytier-core -i 10.144.144.2 -n 10.1.1.0/24
```

Subnet proxy information will automatically sync to each node in the virtual network, and each node will automatically configure the corresponding route. You can verify the subnet proxy setup:

1. Check if the routing information has been synchronized (the proxy_cidrs column shows the proxied subnets):

```bash
# View routing information
easytier-cli route
```

![Routing Information](/assets/image-3.png)

2. Test if you can access nodes in the proxied subnet:

```bash
# Test connectivity to proxied subnet
ping 10.1.1.2
```

#### WireGuard Integration

EasyTier can act as a WireGuard server, allowing any device with a WireGuard client (including iOS and Android) to access the EasyTier network. Here&#039;s an example setup:

```mermaid
flowchart LR

ios[[iPhone&lt;br/&gt;WireGuard Installed]]

subgraph Node A Public IP 22.1.1.1
nodea[EasyTier&lt;br/&gt;10.144.144.1]
end

subgraph Node B
nodeb[EasyTier&lt;br/&gt;10.144.144.2]
end

id1[[10.1.1.0/24]]

ios &lt;-.-&gt; nodea &lt;--&gt; nodeb &lt;-.-&gt; id1
```

1. Start EasyTier with WireGuard portal enabled:

```bash
# Listen on 0.0.0.0:11013 and use 10.14.14.0/24 subnet for WireGuard clients
sudo easytier-core -i 10.144.144.1 --vpn-portal wg://0.0.0.0:11013/10.14.14.0/24
```

2. Get WireGuard client configuration:

```bash
# Get WireGuard client configuration
easytier-cli vpn-portal
```

3. In the output configuration:
   - Set `Interface.Address` to an available IP from the WireGuard subnet
   - Set `Peer.Endpoint` to the public IP/domain of your EasyTier node
   - Import the modified configuration into your WireGuard client

#### Self-Hosted Public Shared Node

You can run your own public shared node to help other nodes discover each other. A public shared node is just a regular EasyTier network (with same network name and secret) that other networks can connect to.

To run a public shared node:

```bash
# No need to specify IPv4 address for public shared nodes
sudo easytier-core --network-name mysharednode --network-secret mysharednode
```

## Related Projects

- [ZeroTier](https://www.zerotier.com/): A global virtual network for connecting devices.
- [TailScale](https://tailscale.com/): A VPN solution aimed at simplifying network configuration.

### Contact Us

- üí¨ **[Telegram Group](https://t.me/easytier)**
- üë• **[QQ Group]**
  - No.1 [949700262](https://qm.qq.com/q/wFoTUChqZW)
  - No.2 [837676408](https://qm.qq.com/q/4V33DrfgHe)
  - No.3 [957189589](https://qm.qq.com/q/YNyTQjwlai)

## License

EasyTier is released under the [LGPL-3.0](https://github.com/EasyTier/EasyTier/blob/main/LICENSE).

## Sponsor

CDN acceleration and security protection for this project are sponsored by Tencent EdgeOne.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://edgeone.ai/?from=github&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/edgeone.png&quot; width=&quot;200&quot; alt=&quot;EdgeOne Logo&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

Special thanks to [Langlang Cloud](https://langlangy.cn/?i26c5a5)  and [RainCloud](https://www.rainyun.com/NjM0NzQ1_) for sponsoring our public servers.

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://langlangy.cn/?i26c5a5&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;assets/langlang.png&quot; width=&quot;200&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://langlangy.cn/?i26c5a5&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;assets/raincloud.png&quot; width=&quot;200&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;


If you find EasyTier helpful, please consider sponsoring us. Software development and maintenance require a lot of time and effort, and your sponsorship will help us better maintain and improve EasyTier.

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;assets/wechat.png&quot; width=&quot;200&quot;&gt;
&lt;img src=&quot;assets/alipay.png&quot; width=&quot;200&quot;&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>