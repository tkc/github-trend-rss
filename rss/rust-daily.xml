<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Mon, 17 Nov 2025 00:05:30 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[jj-vcs/jj]]></title>
            <link>https://github.com/jj-vcs/jj</link>
            <guid>https://github.com/jj-vcs/jj</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[A Git-compatible VCS that is both simple and powerful]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jj-vcs/jj">jj-vcs/jj</a></h1>
            <p>A Git-compatible VCS that is both simple and powerful</p>
            <p>Language: Rust</p>
            <p>Stars: 22,305</p>
            <p>Forks: 786</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;div class=&quot;title-block&quot; style=&quot;text-align: center;&quot; align=&quot;center&quot;&gt;

# Jujutsu‚Äîa version control system

&lt;p&gt;&lt;img title=&quot;jj logo&quot; src=&quot;docs/images/jj-logo.svg&quot; width=&quot;320&quot; height=&quot;320&quot;&gt;&lt;/p&gt;

[![Release](https://img.shields.io/github/v/release/martinvonz/jj)](https://github.com/jj-vcs/jj/releases)
[![Release date](https://img.shields.io/github/release-date/martinvonz/jj)](https://github.com/jj-vcs/jj/releases)
&lt;br/&gt;
[![License](https://img.shields.io/github/license/martinvonz/jj)](https://github.com/jj-vcs/jj/blob/main/LICENSE)
[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN)
[![IRC](https://img.shields.io/badge/irc-%23jujutsu-blue.svg)](https://web.libera.chat/?channel=#jujutsu)

**[Homepage] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Installation] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Getting Started] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Development Roadmap] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Contributing](#contributing)**

[Homepage]: https://jj-vcs.github.io/jj
[Installation]: https://jj-vcs.github.io/jj/latest/install-and-setup
[Getting Started]: https://jj-vcs.github.io/jj/latest/tutorial
[Development Roadmap]: https://jj-vcs.github.io/jj/latest/roadmap

&lt;/div&gt;

## Introduction

Jujutsu is a powerful [version control system](https://en.wikipedia.org/wiki/Version_control)
for software projects. You use it to get a copy of your code, track changes
to the code, and finally publish those changes for others to see and use.
It is designed from the ground up to be easy to use‚Äîwhether you&#039;re new or
experienced, working on brand new projects alone, or large scale software
projects with large histories and teams.

Jujutsu is unlike most other systems, because internally it abstracts the user
interface and version control algorithms from the *storage systems* used to
serve your content. This allows it to serve as a VCS with many possible physical
backends, that may have their own data or networking models‚Äîlike [Mercurial] or
[Breezy], or hybrid systems like Google&#039;s cloud-based design, [Piper/CitC].

[Mercurial]: https://www.mercurial-scm.org/
[Breezy]: https://www.breezy-vcs.org/
[Piper/CitC]: https://youtu.be/W71BTkUbdqE?t=645

Today, we use Git repositories as a storage layer to serve and track content,
making it **compatible with many of your favorite Git-based tools, right now!**
All core developers use Jujutsu to develop Jujutsu, right here on GitHub. But it
should hopefully work with your favorite Git forges, too.

We combine many distinct design choices and concepts from other version control
systems into a single tool. Some of those sources of inspiration include:

- **Git**: We make an effort to [be fast][perf]‚Äîwith a snappy UX, efficient
  algorithms, correct data structures, and good-old-fashioned attention to
  detail. The default storage backend uses Git repositories for &quot;physical
  storage&quot;, for wide interoperability and ease of onboarding.

- **Mercurial &amp; Sapling**: There are many Mercurial-inspired features, such as
  the [revset] language to select commits. There is [no explicit index][no-index]
  or staging area. Branches are &quot;anonymous&quot; like Mercurial, so you don&#039;t need
  to make up a name for each small change. Primitives for rewriting history are
  powerful and simple. Formatting output is done with a robust template language
  that can be configured by the user.

- **Darcs**: Jujutsu keeps track of conflicts as [first-class
  objects][conflicts] in its model; they are first-class in the same way commits
  are, while alternatives like Git simply think of conflicts as textual diffs.
  While not as rigorous as systems like Darcs (which is based on a formalized
  theory of patches, as opposed to snapshots), the effect is that many forms of
  conflict resolution can be performed and propagated automatically.

[perf]: https://github.com/jj-vcs/jj/discussions/49
[revset]: https://jj-vcs.github.io/jj/latest/revsets/
[no-index]: https://jj-vcs.github.io/jj/latest/git-comparison/#the-index
[conflicts]: https://jj-vcs.github.io/jj/latest/conflicts/

And it adds several innovative, useful features of its own:

- **Working-copy-as-a-commit**: Changes to files are [recorded automatically][wcc]
  as normal commits, and amended on every subsequent change. This &quot;snapshot&quot;
  design simplifies the user-facing data model (commits are the only visible
  object), simplifies internal algorithms, and completely subsumes features like
  Git&#039;s stashes or the index/staging-area.

- **Operation log &amp; undo**: Jujutsu records every operation that is performed on the
  repository, from commits, to pulls, to pushes. This makes debugging problems like
  &quot;what just happened?&quot; or &quot;how did I end up here?&quot; easier, *especially* when
  you&#039;re helping your coworker answer those questions about their repository!
  And because everything is recorded, you can undo that mistake you just made
  with ease. Version control has finally entered [the 1960s][undo-history]!

- **Automatic rebase and conflict resolution**: When you modify a commit, every
  descendent is automatically rebased on top of the freshly-modified one. This
  makes &quot;patch-based&quot; workflows a breeze. If you resolve a conflict in a commit,
  the _resolution_ of that conflict is also propagated through descendants as
  well. In effect, this is a completely transparent version of `git rebase
  --update-refs` combined with `git rerere`, supported by design.

&gt; [!WARNING]
&gt; The following features are available for use, but experimental; they may have
&gt; bugs, backwards incompatible storage changes, and user-interface changes!

- **Safe, concurrent replication**: Have you ever wanted to store your version
  controlled repositories inside a Dropbox folder? Or continuously backup
  repositories to S3? No? Well, now you can!

  The fundamental problem with using filesystems like Dropbox and backup tools
  like `rsync` on your typical Git/Mercurial repositories is that they rely
  on *local filesystem operations* being atomic, serialized, and non-concurrent
  with respect to other reads and writes‚Äîwhich is _not_ true when operating on
  distributed file systems, or when operations like concurrent file copies (for
  backup) happen while lock files are being held.

  Jujutsu is instead designed to be [safe under concurrent scenarios][conc-safety];
  simply using rsync or Dropbox and then using that resulting repository
  should never result in a repository in a *corrupt state*. The worst that
  _should_ happen is that it will expose conflicts between the local and remote
  state, leaving you to resolve them.

[wcc]: https://jj-vcs.github.io/jj/latest/working-copy/
[undo-history]: https://en.wikipedia.org/wiki/Undo#History
[conc-safety]: https://jj-vcs.github.io/jj/latest/technical/concurrency/

The command-line tool is called `jj` for now because it&#039;s easy to type and easy
to replace (rare in English). The project is called &quot;Jujutsu&quot; because it matches
&quot;jj&quot;.

Jujutsu is relatively young, with lots of work to still be done. If you have any
questions, or want to talk about future plans, please join us on Discord
[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN),
start a [GitHub Discussion](https://github.com/jj-vcs/jj/discussions), or
send an IRC message to [`#jujutsu` on Libera
Chat](https://web.libera.chat/?channel=#jujutsu). The developers monitor all of
these channels[^bridge].

[^bridge]: To be more precise, the `#jujutsu` Libera IRC channel is bridged to
one of the channels on jj&#039;s Discord. Some of the developers stay on Discord and
use the bridge to follow IRC.

### News and Updates üì£

- **December 2024**: The `jj` Repository has moved to the `jj-vcs` GitHub
  organization.
- **November 2024**: Version 0.24 is released which adds `jj file annotate`,
  which is equivalent to `git blame` or `hg annotate`.
- **September 2024**: Martin gave a [presentation about Jujutsu][merge-vid-2024] at
  Git Merge 2024.
- **Feb 2024**: Version 0.14 is released, which deprecates [&quot;jj checkout&quot; and &quot;jj merge&quot;](CHANGELOG.md#0140---2024-02-07),
  as well as `jj init --git`, which is now just called `jj git init`.
- **Oct 2023**: Version 0.10.0 is released! Now includes a bundled merge and
  diff editor for all platforms, &quot;immutable revsets&quot; to avoid accidentally
  `edit`-ing the wrong revisions, and lots of polish.
- **Jan 2023**: Martin gave a presentation about Google&#039;s plans for Jujutsu at
  Git Merge 2022!
  See the [slides][merge-slides] or the [recording][merge-talk].

### Related Media

- **Mar 2024**: Chris Krycho started [a YouTube series about Jujutsu][krycho-yt].
- **Feb 2024**: Chris Krycho published an article about Jujutsu called [jj init][krycho]
  and Steve Klabnik followed up with the [Jujutsu Tutorial][klabnik].
- **Jan 2024**: Jujutsu was featured in an LWN.net article called
  [Jujutsu: a new, Git-compatible version control system][lwn].
- **Jan 2023**: Martin&#039;s Talk about Jujutsu at Git Merge 2022, [video][merge-talk]
  and the associated [slides][merge-slides].

The wiki also contains a more extensive list of [media references][wiki-media].

[krycho-yt]: https://www.youtube.com/playlist?list=PLelyiwKWHHAq01Pvmpf6x7J0y-yQpmtxp
[krycho]: https://v5.chriskrycho.com/essays/jj-init/
[klabnik]: https://steveklabnik.github.io/jujutsu-tutorial/
[lwn]: https://lwn.net/Articles/958468/
[merge-talk]: https://www.youtube.com/watch?v=bx_LGilOuE4
[merge-slides]: https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view
[merge-vid-2024]: https://www.youtube.com/watch?v=LV0JzI8IcCY
[wiki-media]: https://github.com/jj-vcs/jj/wiki/Media

## Getting started

&gt; [!IMPORTANT]
&gt; Jujutsu is an **experimental version control system**. While Git compatibility
&gt; is stable, and most developers use it daily for all their needs, there may
&gt; still be work-in-progress features, suboptimal UX, and workflow gaps that make
&gt; it unusable for your particular use.

Follow the [installation
instructions](https://jj-vcs.github.io/jj/latest/install-and-setup) to
obtain and configure `jj`.

The best way to get started is probably to go through [the
tutorial](https://jj-vcs.github.io/jj/latest/tutorial). Also see the [Git
comparison](https://jj-vcs.github.io/jj/latest/git-comparison), which
includes a table of `jj` vs. `git` commands.

As you become more familiar with Jujutsu, the following resources may be helpful:

- The [FAQ](https://jj-vcs.github.io/jj/latest/FAQ).
- The [Glossary](https://jj-vcs.github.io/jj/latest/glossary).
- The `jj help` command (e.g. `jj help rebase`).
- The `jj help -k &lt;keyword&gt;` command (e.g. `jj help -k config`). Use `jj help --help`
  to see what keywords are available.

If you are using a **prerelease** version of `jj`, you would want to consult
[the docs for the prerelease (main branch)
version](https://jj-vcs.github.io/jj/prerelease/). You can also get there
from the docs for the latest release by using the website&#039;s version switcher. The version switcher is visible in
the header of the website when you scroll to the top of any page.

## Features

### Compatible with Git

Jujutsu is designed so that the underlying data and storage model is abstract.
Today, only the Git backend is production-ready. The Git backend uses the
[gitoxide](https://github.com/Byron/gitoxide) Rust library.

[backends]: https://jj-vcs.github.io/jj/latest/glossary#backend

The Git backend is fully featured and maintained, and allows you to use Jujutsu
with any Git remote. The commits you create will look like regular Git commits.
You can fetch branches from a regular Git remote and push branches to the
remote. You can always switch back to Git.

Here is how you can explore a GitHub repository with `jj`.

&lt;img src=&quot;demos/git_compat.png&quot; /&gt;

You can even have a [colocated local
workspace](https://jj-vcs.github.io/jj/latest/git-compatibility#colocated-jujutsugit-repos)
where you can use both `jj` and `git` commands interchangeably.

### The working copy is automatically committed

Jujutsu uses a real commit to represent the working copy. Checking out a commit
results a new working-copy commit on top of the target commit. Almost all
commands automatically amend the working-copy commit.

The working-copy being a commit means that commands never fail because the
working copy is dirty (no &quot;error: Your local changes to the following
files...&quot;), and there is no need for `git stash`. Also, because the working copy
is a commit, commands work the same way on the working-copy commit as on any
other commit, so you can set the commit message before you&#039;re done with the
changes.

&lt;img src=&quot;demos/working_copy.png&quot; /&gt;

### The repo is the source of truth

With Jujutsu, the working copy plays a smaller role than with Git. Commands
snapshot the working copy before they start, then they update the repo, and then
the working copy is updated (if the working-copy commit was modified). Almost
all commands (even checkout!) operate on the commits in the repo, leaving the
common functionality of snapshotting and updating of the working copy to
centralized code. For example, `jj restore` (similar to `git restore`) can
restore from any commit and into any commit, and `jj describe` can set the
commit message of any commit (defaults to the working-copy commit).

### Entire repo is under version control

All operations you perform in the repo are recorded, along with a snapshot of
the repo state after the operation. This means that you can easily restore to
an earlier repo state, simply undo your operations one-by-one or even _revert_ a
particular operation which does not have to be the most recent one.

&lt;img src=&quot;demos/operation_log.png&quot; /&gt;

### Conflicts can be recorded in commits

If an operation results in
[conflicts](https://jj-vcs.github.io/jj/latest/glossary#conflict),
information about those conflicts will be recorded in the commit(s). The
operation will succeed. You can then resolve the conflicts later. One
consequence of this design is that there&#039;s no need to continue interrupted
operations. Instead, you get a single workflow for resolving conflicts,
regardless of which command caused them. This design also lets Jujutsu rebase
merge commits correctly (unlike both Git and Mercurial).

Basic conflict resolution:

&lt;img src=&quot;demos/resolve_conflicts.png&quot; /&gt;

Juggling conflicts:

&lt;img src=&quot;demos/juggle_conflicts.png&quot; /&gt;

### Automatic rebase

Whenever you modify a commit, any descendants of the old commit will be rebased
onto the new commit. Thanks to the conflict design described above, that can be
done even if there are conflicts. Bookmarks pointing to rebased commits will be
updated. So will the working copy if it points to a rebased commit.

### Comprehensive support for rewriting history

Besides the usual rebase command, there&#039;s `jj describe` for editing the
description (commit message) of an arbitrary commit. There&#039;s also `jj diffedit`,
which lets you edit the changes in a commit without checking it out. To split
a commit into two, use `jj split`. You can even move part of the changes in a
commit to any other commit using `jj squash -i --from X --into Y`.

## Status

The tool is fairly feature-complete, but some important features like support
for Git submodules are not yet completed. There
are also several performance bugs. It&#039;s likely that workflows and setups
different from what the core developers use are not well supported, e.g. there
is no native support for email-based workflows.

Today, all core developers use `jj` to work on `jj`. I (Martin von Zweigbergk)
have almost exclusively used `jj` to develop the project itself since early
January 2021. I haven&#039;t had to re-clone from source (I don&#039;t think I&#039;ve even had
to restore from backup).

There *will* be changes to workflows and backward-incompatible changes to the
on-disk formats before version 1.0.0. For any format changes, we&#039;ll try to
implement transparent upgrades (as we&#039;ve done with recent changes), or provide
upgrade commands or scripts if requested.

## Related work

There are several tools trying to solve similar problems as Jujutsu. See
[related work](https://jj-vcs.github.io/jj/latest/related-work) for details.

## Contributing

We welcome outside contributions, and there&#039;s plenty of things to do, so
don&#039;t be shy. Please ask if you want a pointer on something you can help with,
and hopefully we can all figure something out.

We do have [a few policies and
suggestions](https://jj-vcs.github.io/jj/prerelease/contributing/)
for contributors. The broad TL;DR:

- Bug reports are very welcome!
- Every commit that lands in the `main` branch is code reviewed.
- Please behave yourself, and obey the Community Guidelines.
- There **is** a mandatory CLA you must agree to. Importantly, it **does not**
  transfer copyright ownership to Google or anyone else; it simply gives us the
  right to safely redistribute and use your changes.

### Mandatory Google Disclaimer

I (Martin von Zweigbergk, &lt;martinvonz@google.com&gt;) started Jujutsu as a hobby
project in late 2019, and it has evolved into my full-time project at Google,
with several other Googlers (now) assisting development in various capacities.
That said, **this is not a Google product**.

## License

Jujutsu is available as Open Source Software, under the Apache 2.0 license. See
[`LICENSE`](./LICENSE) for details about copyright and redistribution.

The `jj` logo was contributed by J. Jennings and is licensed under a Creative
Commons License, see [`docs/images/LICENSE`](docs/images/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[librespot-org/librespot]]></title>
            <link>https://github.com/librespot-org/librespot</link>
            <guid>https://github.com/librespot-org/librespot</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[Open Source Spotify client library]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/librespot-org/librespot">librespot-org/librespot</a></h1>
            <p>Open Source Spotify client library</p>
            <p>Language: Rust</p>
            <p>Stars: 6,203</p>
            <p>Forks: 777</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![Build Status](https://github.com/librespot-org/librespot/workflows/build/badge.svg)](https://github.com/librespot-org/librespot/actions)
[![Gitter chat](https://badges.gitter.im/librespot-org/librespot.png)](https://gitter.im/librespot-org/spotify-connect-resources)
[![Crates.io](https://img.shields.io/crates/v/librespot.svg)](https://crates.io/crates/librespot)

Current maintainers are [listed on GitHub](https://github.com/orgs/librespot-org/people).

# librespot
*librespot* is an open source client library for Spotify. It enables applications to use Spotify&#039;s service to control and play music via various backends, and to act as a Spotify Connect receiver. It is an alternative to the official and [now deprecated](https://pyspotify.mopidy.com/en/latest/#libspotify-s-deprecation) closed-source `libspotify`. Additionally, it will provide extra features which are not available in the official library.

_Note: librespot only works with Spotify Premium. This will remain the case. We will not support any features to make librespot compatible with free accounts, such as limited skips and adverts._

## Quick start
We&#039;re available on [crates.io](https://crates.io/crates/librespot) as the _librespot_ package. Simply run `cargo install librespot` to install librespot on your system. Check the wiki for more info and possible [usage options](https://github.com/librespot-org/librespot/wiki/Options).

After installation, you can run librespot from the CLI using a command such as `librespot -n &quot;Librespot Speaker&quot; -b 160` to create a speaker called _Librespot Speaker_ serving 160 kbps audio.

## This fork
As the origin by [plietar](https://github.com/plietar/) is no longer actively maintained, this organisation and repository have been set up so that the project may be maintained and upgraded in the future.

# Documentation
Documentation is currently a work in progress, contributions are welcome!

There is some brief documentation on how the protocol works in the [docs](https://github.com/librespot-org/librespot/tree/master/docs) folder.

[COMPILING.md](https://github.com/librespot-org/librespot/blob/master/COMPILING.md) contains detailed instructions on setting up a development environment, and compiling librespot. More general usage and compilation information is available on the [wiki](https://github.com/librespot-org/librespot/wiki).
[CONTRIBUTING.md](https://github.com/librespot-org/librespot/blob/master/CONTRIBUTING.md) also contains our contributing guidelines.

If you wish to learn more about how librespot works overall, the best way is to simply read the code, and ask any questions you have in our [Gitter Room](https://gitter.im/librespot-org/spotify-connect-resources).

# Issues &amp; Discussions
**We have recently started using Github discussions for general questions and feature requests, as they are a more natural medium for such cases, and allow for upvoting to prioritize feature development. Check them out [here](https://github.com/librespot-org/librespot/discussions). Bugs and issues with the underlying library should still be reported as issues.**

If you run into a bug when using librespot, please search the existing issues before opening a new one. Chances are, we&#039;ve encountered it before, and have provided a resolution. If not, please open a new one, and where possible, include the backtrace librespot generates on crashing, along with anything we can use to reproduce the issue, e.g. the Spotify URI of the song that caused the crash.

# Building
A quick walkthrough of the build process is outlined below, while a detailed compilation guide can be found [here](https://github.com/librespot-org/librespot/blob/master/COMPILING.md).

## Additional Dependencies
We recently switched to using [Rodio](https://github.com/tomaka/rodio) for audio playback by default, hence for macOS and Windows, you should just be able to clone and build librespot (with the command below).
For Linux, you will need to run the additional commands below, depending on your distro.

On Debian/Ubuntu, the following command will install these dependencies:
```shell
sudo apt-get install build-essential libasound2-dev
```

On Fedora systems, the following command will install these dependencies:
```shell
sudo dnf install alsa-lib-devel make gcc
```

librespot currently offers the following selection of [audio backends](https://github.com/librespot-org/librespot/wiki/Audio-Backends):
```
Rodio (default)
ALSA
GStreamer
PortAudio
PulseAudio
JACK
JACK over Rodio
SDL
Pipe
Subprocess
```
Please check [COMPILING.md](COMPILING.md) for detailed information on TLS, audio, and discovery backend dependencies, or the [Compiling](https://github.com/librespot-org/librespot/wiki/Compiling#general-dependencies) entry on the wiki for additional backend specific dependencies.

Once you&#039;ve installed the dependencies and cloned this repository you can build *librespot* with the default features using Cargo.
```shell
cargo build --release
```

By default, this builds with native-tls (system TLS), rodio audio backend, and libmdns discovery. See [COMPILING.md](COMPILING.md) for information on selecting different TLS, audio, and discovery backends.

# Packages

librespot is also available via official package system on various operating systems such as Linux, FreeBSD, NetBSD. [Repology](https://repology.org/project/librespot/versions) offers a good overview.

[![Packaging status](https://repology.org/badge/vertical-allrepos/librespot.svg)](https://repology.org/project/librespot/versions)

## Usage
A sample program implementing a headless Spotify Connect receiver is provided.
Once you&#039;ve built *librespot*, run it using :
```shell
target/release/librespot --name DEVICENAME
```

The above is a minimal example. Here is a more fully fledged one:
```shell
target/release/librespot -n &quot;Librespot&quot; -b 320 -c ./cache --enable-volume-normalisation --initial-volume 75 --device-type avr
```
The above command will create a receiver named ```Librespot```, with bitrate set to 320 kbps, initial volume at 75%, with volume normalisation enabled, and the device displayed in the app as an Audio/Video Receiver. A folder named ```cache``` will be created/used in the current directory, and be used to cache audio data and credentials.

A full list of runtime options is available [here](https://github.com/librespot-org/librespot/wiki/Options).

_Please Note: When using the cache feature, an authentication blob is stored for your account in the cache directory. For security purposes, we recommend that you set directory permissions on the cache directory to `700`._

## Contact
Come and hang out on gitter if you need help or want to offer some:
https://gitter.im/librespot-org/spotify-connect-resources

## Disclaimer
Using this code to connect to Spotify&#039;s API is probably forbidden by them.
Use at your own risk.

## License
Everything in this repository is licensed under the MIT license.

## Related Projects
This is a non exhaustive list of projects that either use or have modified librespot. If you&#039;d like to include yours, submit a PR.

- [librespot-golang](https://github.com/librespot-org/librespot-golang) - A golang port of librespot.
- [plugin.audio.spotify](https://github.com/marcelveldt/plugin.audio.spotify) - A Kodi plugin for Spotify.
- [raspotify](https://github.com/dtcooper/raspotify) - A Spotify Connect client that mostly Just Works‚Ñ¢
- [Spotifyd](https://github.com/Spotifyd/spotifyd) - A stripped down librespot UNIX daemon.
- [rpi-audio-receiver](https://github.com/nicokaiser/rpi-audio-receiver) - easy Raspbian install scripts for Spotifyd, Bluetooth, Shairport and other audio receivers
- [Spotcontrol](https://github.com/badfortrains/spotcontrol) - A golang implementation of a Spotify Connect controller. No Playback functionality.
- [librespot-java](https://github.com/devgianlu/librespot-java) - A Java port of librespot.
- [ncspot](https://github.com/hrkfdn/ncspot) - Cross-platform ncurses Spotify client.
- [ansible-role-librespot](https://github.com/xMordax/ansible-role-librespot/tree/master) - Ansible role that will build, install and configure Librespot.
- [Spot](https://github.com/xou816/spot) - Gtk/Rust native Spotify client for the GNOME desktop.
- [Snapcast](https://github.com/badaix/snapcast) - synchronised multi-room audio player that uses librespot as its source for Spotify content
- [MuPiBox](https://mupibox.de/) - Portable music box for Spotify and local media based on Raspberry Pi. Operated via touchscreen. Suitable for children and older people.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[greenbone/openvas-scanner]]></title>
            <link>https://github.com/greenbone/openvas-scanner</link>
            <guid>https://github.com/greenbone/openvas-scanner</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[This repository contains the scanner component for Greenbone Community Edition.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/greenbone/openvas-scanner">greenbone/openvas-scanner</a></h1>
            <p>This repository contains the scanner component for Greenbone Community Edition.</p>
            <p>Language: Rust</p>
            <p>Stars: 4,178</p>
            <p>Forks: 729</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>![Greenbone Logo](https://www.greenbone.net/wp-content/uploads/gb_new-logo_horizontal_rgb_small.png)

# OpenVAS Scanner

[![GitHub releases](https://img.shields.io/github/release/greenbone/openvas-scanner.svg)](https://github.com/greenbone/openvas-scanner/releases)
[![Docker Pulls](https://img.shields.io/docker/pulls/greenbone/openvas-scanner.svg)](https://hub.docker.com/r/greenbone/openvas-scanner/)
[![Docker Image Size](https://img.shields.io/docker/image-size/greenbone/openvas-scanner.svg?maxAge=2592000)](https://hub.docker.com/r/greenbone/openvas-scanner/)
[![CI](https://github.com/greenbone/openvas-scanner/actions/workflows/control.yml/badge.svg?branch=main)](https://github.com/greenbone/openvas-scanner/actions/workflows/control.yml?query=branch%3Amain)

This is the OpenVAS Scanner of the Greenbone Community Edition.

It is used for the Greenbone Enterprise appliances and is a full-featured
scan engine that executes a continuously updated and extended feed of
Vulnerability Tests (VTs).

## Releases

All [release files](https://github.com/greenbone/openvas/releases) are signed with
the [Greenbone Community Feed integrity key](https://community.greenbone.net/t/gcf-managing-the-digital-signatures/101).
This gpg key can be downloaded at https://www.greenbone.net/GBCommunitySigningKey.asc
and the fingerprint is `8AE4 BE42 9B60 A59B 311C  2E73 9823 FAA6 0ED1 E580`.

## Installation

This module can be configured, built and installed with following commands:

    cmake .
    make install

For detailed installation requirements and instructions, please see the file
[INSTALL.md](INSTALL.md). The file also contains instructions for setting up
`openvas` and for making the scanner available to other GVM modules.

If you are not familiar or comfortable building from source code, we recommend
that you use the Greenbone Enterprise TRIAL, a prepared virtual
machine with a readily available setup. Information regarding the virtual machine
is available at &lt;https://www.greenbone.net/en/testnow&gt;.

## Rust Implementation

This repository also consists of a [rust project](rust/README.md) aiming to replace the current scanner stack
(openvas-scanner, ospd-openvas, notus-scanner). It simplifies the use of the scanner and centralizes
everything needed for scanning. Currently it uses the openvas-scanner as scan engine.

## Docker, [Greenbone Community Containers](https://greenbone.github.io/docs/latest/22.4/container/)

If you want to use the docker files provided in this repository you can pull them from the [Greenbone registry](registry.community.greenbone.net/community/openvas-scanner:stable). You can also locally build them using:
```
docker build -t &lt;image-name&gt; -f .docker/prod.Dockerfile .
```
For more information about building docker images, see 
[official man](https://docs.docker.com/engine/reference/commandline/build/).
We also provide a [fully containerized 
solution](https://greenbone.github.io/docs/latest/22.4/container/)
for the Greenbone Community Edition.

&gt; Please beware: The Greenbone Community Container are currently under development.

## Support

For any question on the usage of `openvas` please use the [Greenbone
Community Portal](https://community.greenbone.net/). If you found a problem
with the software, please [create an
issue](https://github.com/greenbone/openvas-scanner/issues) on GitHub. If you
are a Greenbone customer you may alternatively or additionally forward your
issue to the Greenbone Support Portal.

## Maintainer

This project is maintained by [Greenbone AG](https://www.greenbone.net/).

## Contributing

Your contributions are highly appreciated. Please [create a pull
request](https://github.com/greenbone/openvas-scanner/pulls) on GitHub.
Remember to commit the contribution agreement as explained in [RELICENSING](https://github.com/greenbone/openvas-scanner/tree/main/RELICENSE) folder with your first PR.
Bigger changes should be discussed with the development team via the [issues section at GitHub](https://github.com/greenbone/openvas-scanner/issues) first.

## License

This repository consists of two scanner implementation, one in programming language C and one in programming language Rust.

This module except for the Rust-implementation in directory rust/ is licensed under the GNU General Public License v2.0 only. Single files, however, are licensed either under the GNU General Public License v2.0 only or under GNU General Public License v2.0 or later, please see the [license-details.md](license-details.md) file for details.

The Rust-implementation in directory rust/ is licensed under the GNU General Public License v2.0 or later with OpenSSL exception. Single files, however, are additionally licensed under MIT.

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[YaLTeR/niri]]></title>
            <link>https://github.com/YaLTeR/niri</link>
            <guid>https://github.com/YaLTeR/niri</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[A scrollable-tiling Wayland compositor.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/YaLTeR/niri">YaLTeR/niri</a></h1>
            <p>A scrollable-tiling Wayland compositor.</p>
            <p>Language: Rust</p>
            <p>Stars: 15,061</p>
            <p>Forks: 533</p>
            <p>Stars today: 47 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;&lt;img alt=&quot;niri&quot; src=&quot;https://github.com/user-attachments/assets/07d05cd0-d5dc-4a28-9a35-51bae8f119a0&quot;&gt;&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;A scrollable-tiling Wayland compositor.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://matrix.to/#/#niri:matrix.org&quot;&gt;&lt;img alt=&quot;Matrix&quot; src=&quot;https://img.shields.io/badge/matrix-%23niri-blue?logo=matrix&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;GitHub License&quot; src=&quot;https://img.shields.io/github/license/YaLTeR/niri&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/releases&quot;&gt;&lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/YaLTeR/niri?logo=github&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://yalter.github.io/niri/Getting-Started.html&quot;&gt;Getting Started&lt;/a&gt; | &lt;a href=&quot;https://yalter.github.io/niri/Configuration%3A-Introduction.html&quot;&gt;Configuration&lt;/a&gt; | &lt;a href=&quot;https://github.com/YaLTeR/niri/discussions/325&quot;&gt;Setup&amp;nbsp;Showcase&lt;/a&gt;
&lt;/p&gt;

![niri with a few windows open](https://github.com/user-attachments/assets/535e6530-2f44-4b84-a883-1240a3eee6e9)

## About

Windows are arranged in columns on an infinite strip going to the right.
Opening a new window never causes existing windows to resize.

Every monitor has its own separate window strip.
Windows can never &quot;overflow&quot; onto an adjacent monitor.

Workspaces are dynamic and arranged vertically.
Every monitor has an independent set of workspaces, and there&#039;s always one empty workspace present all the way down.

The workspace arrangement is preserved across disconnecting and connecting monitors where it makes sense.
When a monitor disconnects, its workspaces will move to another monitor, but upon reconnection they will move back to the original monitor.

## Features

- Built from the ground up for scrollable tiling
- [Dynamic workspaces](https://yalter.github.io/niri/Workspaces.html) like in GNOME
- An [Overview](https://github.com/user-attachments/assets/379a5d1f-acdb-4c11-b36c-e85fd91f0995) that zooms out workspaces and windows
- Built-in screenshot UI
- Monitor and window screencasting through xdg-desktop-portal-gnome
    - You can [block out](https://yalter.github.io/niri/Configuration%3A-Window-Rules.html#block-out-from) sensitive windows from screencasts
    - [Dynamic cast target](https://yalter.github.io/niri/Screencasting.html#dynamic-screencast-target) that can change what it shows on the go
- [Touchpad](https://github.com/YaLTeR/niri/assets/1794388/946a910e-9bec-4cd1-a923-4a9421707515) and [mouse](https://github.com/YaLTeR/niri/assets/1794388/8464e65d-4bf2-44fa-8c8e-5883355bd000) gestures
- Group windows into [tabs](https://yalter.github.io/niri/Tabs.html)
- Configurable layout: gaps, borders, struts, window sizes
- [Gradient borders](https://yalter.github.io/niri/Configuration%3A-Layout.html#gradients) with Oklab and Oklch support
- [Animations](https://github.com/YaLTeR/niri/assets/1794388/ce178da2-af9e-4c51-876f-8709c241d95e) with support for [custom shaders](https://github.com/YaLTeR/niri/assets/1794388/27a238d6-0a22-4692-b794-30dc7a626fad)
- Live-reloading config
- Works with [screen readers](https://yalter.github.io/niri/Accessibility.html)

## Video Demo

https://github.com/YaLTeR/niri/assets/1794388/bce834b0-f205-434e-a027-b373495f9729

Also check out this video from Brodie Robertson that showcases a lot of the niri functionality: [Niri Is My New Favorite Wayland Compositor](https://youtu.be/DeYx2exm04M)

## Status

Niri is stable for day-to-day use and does most things expected of a Wayland compositor.
Many people are daily-driving niri, and are happy to help in our [Matrix channel].

Give it a try!
Follow the instructions on the [Getting Started](https://yalter.github.io/niri/Getting-Started.html) page.
Have your [waybar]s and [fuzzel]s ready: niri is not a complete desktop environment.
Also check out [awesome-niri], a list of niri-related links and projects.

Here are some points you may have questions about:

- **Multi-monitor**: yes, a core part of the design from the very start. Mixed DPI works.
- **Fractional scaling**: yes, plus all niri UI stays pixel-perfect.
- **NVIDIA**: seems to work fine.
- **Floating windows**: yes, starting from niri 25.01.
- **Input devices**: niri supports tablets, touchpads, and touchscreens.
You can map the tablet to a specific monitor, or use [OpenTabletDriver].
We have touchpad gestures, but no touchscreen gestures yet.
- **Wlr protocols**: yes, we have most of the important ones like layer-shell, gamma-control, screencopy.
You can check on [wayland.app](https://wayland.app) at the bottom of each protocol&#039;s page.
- **Performance**: while I run niri on beefy machines, I try to stay conscious of performance.
I&#039;ve seen someone use it fine on an Eee¬†PC¬†900 from¬†2008, of all things.
- **Xwayland**: [integrated](https://yalter.github.io/niri/Xwayland.html#using-xwayland-satellite) via xwayland-satellite starting from niri 25.08.

## Media

[niri: Making a Wayland compositor in Rust](https://youtu.be/Kmz8ODolnDg?list=PLRdS-n5seLRqrmWDQY4KDqtRMfIwU0U3T) ¬∑ *December 2024*

My talk from the 2024 Moscow RustCon about niri, and how I do randomized property testing and profiling, and measure input latency.
The talk is in Russian, but I prepared full English subtitles that you can find in YouTube&#039;s subtitle language selector.

[An interview with Ivan, the developer behind Niri](https://www.trommelspeicher.de/podcast/special_the_developer_behind_niri) ¬∑ *June 2025*

An interview by a German tech podcast Das Triumvirat (in English).
We talk about niri development and history, and my experience building and maintaining niri.

[A tour of the niri scrolling-tiling Wayland compositor](https://lwn.net/Articles/1025866/) ¬∑ *July 2025*

An LWN article with a nice overview and introduction to niri.

## Contributing

If you&#039;d like to help with niri, there are plenty of both coding- and non-coding-related ways to do so.
See [CONTRIBUTING.md](https://github.com/YaLTeR/niri/blob/main/CONTRIBUTING.md) for an overview.

## Inspiration

Niri is heavily inspired by [PaperWM] which implements scrollable tiling on top of GNOME Shell.

One of the reasons that prompted me to try writing my own compositor is being able to properly separate the monitors.
Being a GNOME Shell extension, PaperWM has to work against Shell&#039;s global window coordinate space to prevent windows from overflowing.

## Tile Scrollably Elsewhere

Here are some other projects which implement a similar workflow:

- [PaperWM]: scrollable tiling on top of GNOME Shell.
- [karousel]: scrollable tiling on top of KDE.
- [scroll](https://github.com/dawsers/scroll) and [papersway]: scrollable tiling on top of sway/i3.
- [hyprscrolling] and [hyprslidr]: scrollable tiling on top of Hyprland.
- [PaperWM.spoon]: scrollable tiling on top of macOS.

## Contact

Our main communication channel is a Matrix chat, feel free to join and ask a question: https://matrix.to/#/#niri:matrix.org

We also have a community Discord server: https://discord.gg/vT8Sfjy7sx

[PaperWM]: https://github.com/paperwm/PaperWM
[waybar]: https://github.com/Alexays/Waybar
[fuzzel]: https://codeberg.org/dnkl/fuzzel
[awesome-niri]: https://github.com/Vortriz/awesome-niri
[karousel]: https://github.com/peterfajdiga/karousel
[papersway]: https://spwhitton.name/tech/code/papersway/
[hyprscrolling]: https://github.com/hyprwm/hyprland-plugins/tree/main/hyprscrolling
[hyprslidr]: https://gitlab.com/magus/hyprslidr
[PaperWM.spoon]: https://github.com/mogenson/PaperWM.spoon
[Matrix channel]: https://matrix.to/#/#niri:matrix.org
[OpenTabletDriver]: https://opentabletdriver.net/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ai-dynamo/dynamo]]></title>
            <link>https://github.com/ai-dynamo/dynamo</link>
            <guid>https://github.com/ai-dynamo/dynamo</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[A Datacenter Scale Distributed Inference Serving Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo</a></h1>
            <p>A Datacenter Scale Distributed Inference Serving Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 5,482</p>
            <p>Forks: 691</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

![Dynamo banner](./docs/images/frontpage-banner.png)

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)
[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)

| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/2486)** | **[Support matrix](https://github.com/ai-dynamo/dynamo/blob/main/docs/reference/support-matrix.md)** | **[Documentation](https://docs.nvidia.com/dynamo/latest/index.html)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Prebuilt containers](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** | **[Blogs](https://developer.nvidia.com/blog/tag/nvidia-dynamo)**

# NVIDIA Dynamo

High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.

## Latest News

- [08/05] Deploy `openai/gpt-oss-120b` with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo [‚û°Ô∏è link](./docs/backends/trtllm/gpt-oss.md)

## The Era of Multi-GPU, Multi-Node

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-gpu-vertical.png&quot; alt=&quot;Multi Node Multi-GPU topology&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs‚Äîand sometimes many servers‚Äîbut it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.

Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:

- **Disaggregated prefill &amp; decode inference** ‚Äì Maximizes GPU throughput and facilitates trade off between throughput and latency.
- **Dynamic GPU scheduling** ‚Äì Optimizes performance based on fluctuating demand
- **LLM-aware request routing** ‚Äì Eliminates unnecessary KV cache re-computation
- **Accelerated data transfer** ‚Äì Reduces inference response time using NIXL.
- **KV cache offloading** ‚Äì Leverages multiple memory hierarchies for higher system throughput

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-architecture.png&quot; alt=&quot;Dynamo architecture&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

## Framework Support Matrix

| Feature                                                                                           | vLLM | SGLang | TensorRT-LLM |
| ------------------------------------------------------------------------------------------------- | ---- | ------ | ------------ |
| [**Disaggregated Serving**](/docs/design_docs/disagg_serving.md)                                 | ‚úÖ   | ‚úÖ     | ‚úÖ           |
| [**Conditional Disaggregation**](/docs/design_docs/disagg_serving.md#conditional-disaggregation) | üöß   | üöß     | üöß           |
| [**KV-Aware Routing**](/docs/router/kv_cache_routing.md)                                    | ‚úÖ   | ‚úÖ     | ‚úÖ           |
| [**Load Based Planner**](docs/planner/load_planner.md)                                      | üöß   | üöß     | üöß           |
| [**SLA-Based Planner**](docs/planner/sla_planner.md)                                        | ‚úÖ   | ‚úÖ     | ‚úÖ           |
| [**KVBM**](docs/kvbm/kvbm_architecture.md)                                               | ‚úÖ   | üöß     | ‚úÖ           |

To learn more about each framework and their capabilities, check out each framework&#039;s README!

- **[vLLM](docs/backends/vllm/README.md)**
- **[SGLang](docs/backends/sglang/README.md)**
- **[TensorRT-LLM](docs/backends/trtllm/README.md)**

Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.

# Installation

The following examples require a few system level packages.
Recommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/reference/support-matrix.md](docs/reference/support-matrix.md)

## 1. Initial setup

The Dynamo team recommends the `uv` Python package manager, although any way works. Install uv:

```
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Install Python development headers

Backend engines require Python development headers for JIT compilation. Install them with:

```bash
sudo apt install python3-dev
```

### Install etcd (optional) and NATS (required)

To coordinate across a data center, Dynamo relies on etcd and NATS. These will be used in production. To run Dynamo locally etcd is optional.

- [etcd](https://etcd.io/) can be run directly as `./etcd`.
- [nats](https://nats.io/) needs jetstream enabled: `nats-server -js`.

To quickly setup etcd &amp; NATS, you can also run:

```bash
# At the root of the repository:
docker compose -f deploy/docker-compose.yml up -d
```

To run locally without etcd, pass `--store-kv file` to both the frontend and workers. The directory used for key-value data can be configured via the `DYN_FILE_KV` environment variable (example: `export DYN_FILE_KV=/data/kv/dynamo`). Defaults to `$TMPDIR/dynamo_store_kv`.


## 2. Select an engine

We publish Python wheels specialized for each of our supported engines: vllm, sglang, and trtllm. The examples that follow use SGLang; continue reading for other engines.

```
uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install &quot;ai-dynamo[sglang]&quot;  #replace with [vllm], [trtllm], etc.
```

## 3. Run Dynamo

### Sanity check (optional)

Before trying out Dynamo, you can verify your system configuration and dependencies:

```bash
./deploy/sanity_check.py
```

This is a quick check for system resources, development tools, LLM frameworks, and Dynamo components.

### Running an LLM API server

Dynamo provides a simple way to spin up a local set of inference components including:

- **OpenAI Compatible Frontend** ‚Äì High performance OpenAI compatible http api server written in Rust.
- **Basic and Kv Aware Router** ‚Äì Route and load balance traffic to a set of workers.
- **Workers** ‚Äì Set of pre-configured LLM serving engines.

```
# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
# Pass --store-kv to use the filesystem instead of etcd. The workers and frontend must share a disk.
python -m dynamo.frontend --http-port 8000 [--tls-cert-path cert.pem] [--tls-key-path key.pem] [--store-kv file]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
# Pass --store-kv to use the filesystem instead of etcd. The workers and frontend must share a disk.
python -m dynamo.sglang --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B [--store-kv file]
```

#### Send a Request

```bash
curl localhost:8000/v1/chat/completions   -H &quot;Content-Type: application/json&quot;   -d &#039;{
    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,
    &quot;messages&quot;: [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello, how are you?&quot;
    }
    ],
    &quot;stream&quot;:false,
    &quot;max_tokens&quot;: 300
  }&#039; | jq
```

Rerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.

### Deploying Dynamo

- Follow the [Quickstart Guide](docs/kubernetes/README.md) to deploy on Kubernetes.
- Check out [Backends](examples/backends) to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)
- Run some [Examples](examples) to learn about building components in Dynamo and exploring various integrations.

### Benchmarking Dynamo

Dynamo provides comprehensive benchmarking tools to evaluate and optimize your deployments:

- **[Benchmarking Guide](docs/benchmarks/benchmarking.md)** ‚Äì Compare deployment topologies (aggregated vs. disaggregated vs. vanilla vLLM) using AIPerf
- **[SLA-Driven Dynamo Deployments](docs/planner/sla_planner_quickstart.md)** ‚Äì Optimize your deployment to meet SLA requirements

# Engines

Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (`python -m dynamo.frontend [--interactive]`).

## vLLM

```
uv pip install ai-dynamo[vllm]
```

Run the backend/worker like this:

```
python -m dynamo.vllm --help
```

vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass `--context-length &lt;value&gt;`.

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

## SGLang

```
# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
```

Run the backend/worker like this:

```
python -m dynamo.sglang --help
```

You can pass any sglang flags directly to this worker, see https://docs.sglang.ai/advanced_features/server_arguments.html . See there to use multiple GPUs.

## TensorRT-LLM

It is recommended to use [NGC PyTorch Container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) for running the TensorRT-LLM engine.

&gt; [!Note]
&gt; Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using.
&gt; For example, if you are using `tensorrt-llm==1.1.0rc5`, use the PyTorch container image version `25.06`.
&gt; To find the correct PyTorch container version for your desired `tensorrt-llm` release, visit the [TensorRT-LLM Dockerfile.multi](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docker/Dockerfile.multi) on GitHub. Switch to the branch that matches your `tensorrt-llm` version, and look for the `BASE_TAG` line to identify the recommended PyTorch container tag.

&gt; [!Important]
&gt; Launch container with the following additional settings `--shm-size=1g --ulimit memlock=-1`

### Install prerequisites

```
# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install &quot;cuda-python&gt;=12,&lt;13&quot;

sudo apt-get -y install libopenmpi-dev
```

&gt; [!Tip]
&gt; You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation [here](https://nvidia.github.io/TensorRT-LLM/installation/linux.html).

### After installing the pre-requisites above, install Dynamo

```
uv pip install ai-dynamo[trtllm]
```

Run the backend/worker like this:

```
python -m dynamo.trtllm --help
```

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

# Developing Locally

## 1. Install libraries

**Ubuntu:**

```
sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
```

**macOS:**

- [Homebrew](https://brew.sh/)

```
# if brew is not installed on your system, install it
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
```

- [Xcode](https://developer.apple.com/xcode/)

```
brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
```

If Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.

## 2. Install Rust

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
```

## 3. Create a Python virtual env:

Follow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don&#039;t have `uv` installed. Once uv is installed, create a virtual environment and activate it.

- Install uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

- Create a virtual environment

```bash
uv venv dynamo
source dynamo/bin/activate
```

## 4. Install build tools

```
uv pip install pip maturin
```

[Maturin](https://github.com/PyO3/maturin) is the Rust&lt;-&gt;Python bindings build tool.

## 5. Build the Rust bindings

```
cd lib/bindings/python
maturin develop --uv
```

## 6. Install the wheel

```
cd $PROJECT_ROOT
uv pip install -e .
```

You should now be able to run `python -m dynamo.frontend`.

Remember that nats and etcd must typically be running (see earlier).

Set the environment variable `DYN_LOG` to adjust the logging level; for example, `export DYN_LOG=debug`. It has the same syntax as `RUST_LOG`.

If you use vscode or cursor, we have a .devcontainer folder built on [Microsofts Extension](https://code.visualstudio.com/docs/devcontainers/containers). For instructions see the [ReadMe](.devcontainer/README.md) for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[longbridge/gpui-component]]></title>
            <link>https://github.com/longbridge/gpui-component</link>
            <guid>https://github.com/longbridge/gpui-component</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Rust GUI components for building fantastic cross-platform desktop application by using GPUI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/longbridge/gpui-component">longbridge/gpui-component</a></h1>
            <p>Rust GUI components for building fantastic cross-platform desktop application by using GPUI.</p>
            <p>Language: Rust</p>
            <p>Stars: 8,042</p>
            <p>Forks: 310</p>
            <p>Stars today: 58 stars today</p>
            <h2>README</h2><pre># GPUI Component

[![Build Status](https://github.com/longbridge/gpui-component/actions/workflows/ci.yml/badge.svg)](https://github.com/longbridge/gpui-component/actions/workflows/ci.yml) [![Docs](https://docs.rs/gpui-component/badge.svg)](https://docs.rs/gpui-component/) [![Crates.io](https://img.shields.io/crates/v/gpui-component.svg)](https://crates.io/crates/gpui-component)

UI components for building fantastic desktop applications using [GPUI](https://gpui.rs).

## Features

- **Richness**: 60+ cross-platform desktop UI components.
- **Native**: Inspired by macOS and Windows controls, combined with shadcn/ui design for a modern experience.
- **Ease of Use**: Stateless `RenderOnce` components, simple and user-friendly.
- **Customizable**: Built-in `Theme` and `ThemeColor`, supporting multi-theme and variable-based configurations.
- **Versatile**: Supports sizes like `xs`, `sm`, `md`, and `lg`.
- **Flexible Layout**: Dock layout for panel arrangements, resizing, and freeform (Tiles) layouts.
- **High Performance**: Virtualized Table and List components for smooth large-data rendering.
- **Content Rendering**: Native support for Markdown and simple HTML.
- **Charting**: Built-in charts for visualizing your data.
- **Editor**: High performance code editor (support up to 200K lines) with LSP (diagnostics, completion, hover, etc).
- **Syntax Highlighting**: Syntax highlighting for editor and markdown components using Tree Sitter.

## Showcase

Here is the first application: [Longbridge Pro](https://longbridge.com/desktop), built using GPUI Component.

&lt;img width=&quot;1763&quot; alt=&quot;Image&quot; src=&quot;https://github.com/user-attachments/assets/e1ecb9c3-2dd3-431e-bd97-5a819c30e551&quot; /&gt;

We built multi-theme support in the application. This feature is not included in GPUI Component itself, but is based on the `Theme` feature, so it&#039;s easy to implement.

## Usage

GPUI and GPUI Component are still in development, so you need to add dependencies by git.

```toml
gpui = &quot;0.2.2&quot;
gpui-component = &quot;0.4.0-preview2&quot;
```

### Basic Example

```rs
use gpui::*;
use gpui_component::{button::*, *};

pub struct HelloWorld;
impl Render for HelloWorld {
    fn render(&amp;mut self, _: &amp;mut Window, _: &amp;mut Context&lt;Self&gt;) -&gt; impl IntoElement {
        div()
            .v_flex()
            .gap_2()
            .size_full()
            .items_center()
            .justify_center()
            .child(&quot;Hello, World!&quot;)
            .child(
                Button::new(&quot;ok&quot;)
                    .primary()
                    .label(&quot;Let&#039;s Go!&quot;)
                    .on_click(|_, _, _| println!(&quot;Clicked!&quot;)),
            )
    }
}

fn main() {
    let app = Application::new();

    app.run(move |cx| {
        // This must be called before using any GPUI Component features.
        gpui_component::init(cx);

        cx.spawn(async move |cx| {
            cx.open_window(WindowOptions::default(), |window, cx| {
                let view = cx.new(|_| HelloWorld);
                // This first level on the window, should be a Root.
                cx.new(|cx| Root::new(view, window, cx))
            })?;

            Ok::&lt;_, anyhow::Error&gt;(())
        })
        .detach();
    });
}
```

### WebView

&gt; Still early and experimental; there are a lot of limitations.

GPUI Component has a `WebView` element based on [Wry](https://github.com/tauri-apps/wry). This is an optional feature, which you can enable with a feature flag.

```toml
gpui-component = { version = &quot;0.4.0-preview2&quot;, features = [&quot;webview&quot;] }
wry = { version = &quot;0.53.3, package = &quot;lb-wry&quot; }
```

More usage examples can be found in the [story](https://github.com/longbridge/gpui-component/tree/main/crates/story) directory.

### Icons

GPUI Component has an `Icon` element, but it does not include SVG files by default.

The example uses [Lucide](https://lucide.dev) icons, but you can use any icons you like. Just name the SVG files as defined in [IconName](https://github.com/longbridge/gpui-component/blob/main/crates/ui/src/icon.rs#L86). You can add any icons you need to your project.

## Development

We have a gallery of applications built with GPUI Component.

```bash
cargo run
```

More examples can be found in the `examples` directory. You can run them with `cargo run --example &lt;example_name&gt;`.

Check out [CONTRIBUTING.md](CONTRIBUTING.md) for more details.

## Compare to others

| Features              | GPUI Component                 | [Iced]             | [egui]                | [Qt 6]                                            |
| --------------------- | ------------------------------ | ------------------ | --------------------- | ------------------------------------------------- |
| Language              | Rust                           | Rust               | Rust                  | C++/QML                                           |
| Core Render           | GPUI                           | wgpu               | wgpu                  | QT                                                |
| License               | Apache 2.0                     | MIT                | MIT/Apache 2.0        | [Commercial/LGPL](https://www.qt.io/qt-licensing) |
| Min Binary Size [^1]  | 12MB                           | 11MB               | 5M                    | 20MB [^2]                                         |
| Cross-Platform        | Yes                            | Yes                | Yes                   | Yes                                               |
| Documentation         | Simple                         | Simple             | Simple                | Good                                              |
| Web                   | No                             | Yes                | Yes                   | Yes                                               |
| UI Style              | Modern                         | Basic              | Basic                 | Basic                                             |
| CJK Support           | Yes                            | Yes                | Bad                   | Yes                                               |
| Chart                 | Yes                            | No                 | No                    | Yes                                               |
| Table (Large dataset) | Yes&lt;br&gt;(Virtual Rows, Columns) | No                 | Yes&lt;br&gt;(Virtual Rows) | Yes&lt;br&gt;(Virtual Rows, Columns)                    |
| Table Column Resize   | Yes                            | No                 | Yes                   | Yes                                               |
| Text base             | Rope                           | [COSMIC Text] [^3] | trait TextBuffer [^4] | [QTextDocument]                                   |
| CodeEditor            | Simple                         | Simple             | Simple                | Basic API                                         |
| Dock Layout           | Yes                            | Yes                | Yes                   | Yes                                               |
| Syntax Highlight      | [Tree Sitter]                  | [Syntect]          | [Syntect]             | [QSyntaxHighlighter]                              |
| Markdown Rendering    | Yes                            | Yes                | Basic                 | No                                                |
| Markdown mix HTML     | Yes                            | No                 | No                    | No                                                |
| HTML Rendering        | Basic                          | No                 | No                    | Basic                                             |
| Text Selection        | TextView                       | No                 | Any Label             | Yes                                               |
| Custom Theme          | Yes                            | Yes                | Yes                   | Yes                                               |
| Built Themes          | Yes                            | No                 | No                    | No                                                |
| I18n                  | Yes                            | Yes                | Yes                   | Yes                                               |

&gt; Please submit an issue or PR if any mistakes or outdated are found.

[Iced]: https://github.com/iced-rs/iced
[egui]: https://github.com/emilk/egui
[QT 6]: https://www.qt.io/product/qt6
[Tree Sitter]: https://tree-sitter.github.io/tree-sitter/
[Syntect]: https://github.com/trishume/syntect
[QSyntaxHighlighter]: https://doc.qt.io/qt-6/qsyntaxhighlighter.html
[QTextDocument]: https://doc.qt.io/qt-6/qtextdocument.html
[COSMIC Text]: https://github.com/pop-os/cosmic-text

[^1]: Release builds by use simple hello world example.

[^2]: [Reducing Binary Size of Qt Applications](https://www.qt.io/blog/reducing-binary-size-of-qt-applications-part-3-more-platforms)

[^3]: Iced Editor: https://github.com/iced-rs/iced/blob/db5a1f6353b9f8520c4f9633d1cdc90242c2afe1/graphics/src/text/editor.rs#L65-L68

[^4]: egui TextBuffer: https://github.com/emilk/egui/blob/0a81372cfd3a4deda640acdecbbaf24bf78bb6a2/crates/egui/src/widgets/text_edit/text_buffer.rs#L20

## License

Apache-2.0

- UI design based on [shadcn/ui](https://ui.shadcn.com).
- Icons from [Lucide](https://lucide.dev).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[Eventual-Inc/Daft]]></title>
            <link>https://github.com/Eventual-Inc/Daft</link>
            <guid>https://github.com/Eventual-Inc/Daft</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[Distributed query engine providing simple and reliable data processing for any modality and scale]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Eventual-Inc/Daft">Eventual-Inc/Daft</a></h1>
            <p>Distributed query engine providing simple and reliable data processing for any modality and scale</p>
            <p>Language: Rust</p>
            <p>Stars: 4,762</p>
            <p>Forks: 342</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[linebender/vello]]></title>
            <link>https://github.com/linebender/vello</link>
            <guid>https://github.com/linebender/vello</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[A GPU compute-centric 2D renderer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/linebender/vello">linebender/vello</a></h1>
            <p>A GPU compute-centric 2D renderer.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,437</p>
            <p>Forks: 193</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;!--

This repo-level readme needs restructuring, pending some Linebender templating decisions.
https://xi.zulipchat.com/#narrow/channel/419691-linebender/topic/Bikeshedding.20badges/with/452312397

For now, prefer updating the package-level readmes, e.g. vello/README.md.

--&gt;

&lt;div align=&quot;center&quot;&gt;

# Vello

**A GPU compute-centric 2D renderer**

[![Linebender Zulip](https://img.shields.io/badge/Linebender-%23vello-blue?logo=Zulip)](https://xi.zulipchat.com/#narrow/channel/197075-vello)
[![dependency status](https://deps.rs/repo/github/linebender/vello/status.svg)](https://deps.rs/repo/github/linebender/vello)
[![Apache 2.0 or MIT license.](https://img.shields.io/badge/license-Apache--2.0_OR_MIT-blue.svg)](#license)
[![wgpu version](https://img.shields.io/badge/wgpu-v27.0.1-orange.svg)](https://crates.io/crates/wgpu)

[![Crates.io](https://img.shields.io/crates/v/vello.svg)](https://crates.io/crates/vello)
[![Docs](https://docs.rs/vello/badge.svg)](https://docs.rs/vello)
[![Build status](https://github.com/linebender/vello/workflows/CI/badge.svg)](https://github.com/linebender/vello/actions)

&lt;/div&gt;

Vello is a 2D graphics rendering engine written in Rust, with a focus on GPU compute.
It can draw large 2D scenes with interactive or near-interactive performance, using [`wgpu`] for GPU access.

Quickstart to run an example program:

```shell
cargo run -p with_winit
```

![image](https://github.com/linebender/vello/assets/8573618/cc2b742e-2135-4b70-8051-c49aeddb5d19)

It is used as the rendering backend for [Xilem], a Rust GUI toolkit.

&gt; [!WARNING]
&gt; Vello can currently be considered in an alpha state. In particular, we&#039;re still working on the following:
&gt;
&gt; - [Implementing blur and filter effects](https://github.com/linebender/vello/issues/476).
&gt; - [Conflations artifacts](https://github.com/linebender/vello/issues/49).
&gt; - [GPU memory allocation strategy](https://github.com/linebender/vello/issues/366)
&gt; - [Glyph caching](https://github.com/linebender/vello/issues/204)

Significant changes are documented in [the changelog].

## Motivation

Vello is meant to fill the same place in the graphics stack as other vector graphics renderers like [Skia](https://skia.org/), [Cairo](https://www.cairographics.org/), and its predecessor project [Piet](https://github.com/linebender/piet).
On a basic level, that means it provides tools to render shapes, images, gradients, text, etc, using a PostScript-inspired API, the same that powers SVG files and [the browser `&lt;canvas&gt;` element](https://developer.mozilla.org/en-US/docs/Web/API/CanvasRenderingContext2D).

Vello&#039;s selling point is that it gets better performance than other renderers by better leveraging the GPU.
In traditional PostScript-style renderers, some steps of the render process like sorting and clipping either need to be handled in the CPU or done through the use of intermediary textures.
Vello avoids this by using prefix-sum algorithms to parallelize work that usually needs to happen in sequence, so that work can be offloaded to the GPU with minimal use of temporary buffers.

This means that Vello needs a GPU with support for compute shaders to run.

## Getting started

Vello is meant to be integrated deep in UI render stacks.
While drawing in a Vello scene is easy, actually rendering that scene to a surface requires setting up a wgpu context, which is a non-trivial task.

To use Vello as the renderer for your PDF reader / GUI toolkit / etc, your code will have to look roughly like this:

```rust
use vello::{
    kurbo::{Affine, Circle},
    peniko::{Color, Fill},
    *,
};

// Initialize wgpu and get handles
let (width, height) = ...;
let device: wgpu::Device = ...;
let queue: wgpu::Queue = ...;
let mut renderer = Renderer::new(
   &amp;device,
   RendererOptions::default()
).expect(&quot;Failed to create renderer&quot;);
// Create scene and draw stuff in it
let mut scene = vello::Scene::new();
scene.fill(
   vello::peniko::Fill::NonZero,
   vello::Affine::IDENTITY,
   vello::Color::from_rgb8(242, 140, 168),
   None,
   &amp;vello::Circle::new((420.0, 200.0), 120.0),
);
// Draw more stuff
scene.push_layer(...);
scene.fill(...);
scene.stroke(...);
scene.pop_layer(...);
let texture = device.create_texture(&amp;...);

// Render to a wgpu Texture
renderer
   .render_to_texture(
      &amp;device,
      &amp;queue,
      &amp;scene,
      &amp;texture,
      &amp;vello::RenderParams {
         base_color: palette::css::BLACK, // Background color
         width,
         height,
         antialiasing_method: AaConfig::Msaa16,
      },
   )
   .expect(&quot;Failed to render to a texture&quot;);
// Do things with `texture`, such as blitting it to the Surface using
// wgpu::util::TextureBlitter
```

See the [`examples`](https://github.com/linebender/vello/tree/main/examples) directory for code that integrates with frameworks like winit.

## Performance

We&#039;ve observed 177 fps for the paris-30k test scene on an M1 Max, at a resolution of 1600 pixels square, which is excellent performance and represents something of a best case for the engine.

More formal benchmarks are on their way.

## Integrations

### SVG

A separate Linebender integration for rendering SVG files is available through [`vello_svg`](https://github.com/linebender/vello_svg).

### Lottie

A separate Linebender integration for playing Lottie animations is available through [`velato`](https://github.com/linebender/velato).

### Bevy

A separate Linebender integration for rendering raw scenes or Lottie and SVG files in [Bevy] through [`bevy_vello`](https://github.com/linebender/bevy_vello).

## Examples

Our examples are provided in separate packages in the [`examples`](https://github.com/linebender/vello/tree/main/examples) directory.
This allows them to have independent dependencies and faster builds.
Examples must be selected using the `--package` (or `-p`) Cargo flag.

### Winit

Our [winit] example ([examples/with_winit](https://github.com/linebender/vello/tree/main/examples/with_winit)) demonstrates rendering to a [winit] window.
By default, this renders the [GhostScript Tiger] as well as all SVG files you add in the [examples/assets/downloads](https://github.com/linebender/vello/tree/main/examples/assets/downloads) directory.
A custom list of SVG file paths (and directories to render all SVG files from) can be provided as arguments instead.
It also includes a collection of test scenes showing the capabilities of `vello`, which can be shown with `--test-scenes`.

```shell
cargo run -p with_winit
```

&lt;!-- ### Headless --&gt;

## Platforms

We aim to target all environments which can support WebGPU with the [default limits](https://www.w3.org/TR/webgpu/#limits).
We defer to [`wgpu`] for this support.
Other platforms are more tricky, and may require special building/running procedures.

### Web

Because Vello relies heavily on compute shaders, we rely on the emerging WebGPU standard to run on the web.
Browser support for WebGPU is still evolving.
Vello has been tested using production versions of Chrome, but WebGPU support in Firefox and Safari is still experimental.
It may be necessary to use development browsers and explicitly enable WebGPU.

The following command builds and runs a web version of the [winit demo](#winit).
This uses [`cargo-run-wasm`](https://github.com/rukai/cargo-run-wasm) to build the example for web, and host a local server for it

```shell
# Make sure the Rust toolchain supports the wasm32 target
rustup target add wasm32-unknown-unknown

# The binary name must also be explicitly provided as it differs from the package name
cargo run_wasm -p with_winit --bin with_winit_bin
```

There is also a web demo [available here](https://linebender.github.io/vello) on supporting web browsers.

&gt; [!WARNING]
&gt; The web is not currently a primary target for Vello, and WebGPU implementations are incomplete, so you might run into issues running this example.

### Android

The [`with_winit`](#winit) example supports running on Android, using [cargo apk](https://crates.io/crates/cargo-apk).

```shell
cargo apk run -p with_winit --lib
```

&gt; [!TIP]
&gt; cargo apk doesn&#039;t support running in release mode without configuration.
&gt; See [their crates page docs](https://crates.io/crates/cargo-apk) (around `package.metadata.android.signing.&lt;profile&gt;`).
&gt;
&gt; See also [cargo-apk#16](https://github.com/rust-mobile/cargo-apk/issues/16).
&gt; To run in release mode, you must add the following to `examples/with_winit/Cargo.toml` (changing `$HOME` to your home directory):

```toml
[package.metadata.android.signing.release]
path = &quot;$HOME/.android/debug.keystore&quot;
keystore_password = &quot;android&quot;
```

&gt; [!NOTE]
&gt; As `cargo apk` does not allow passing command line arguments or environment variables to the app when ran, these can be embedded into the
&gt; program at compile time (currently for Android only)
&gt; `with_winit` currently supports the environment variables:
&gt;
&gt; - `VELLO_STATIC_LOG`, which is equivalent to `RUST_LOG`
&gt; - `VELLO_STATIC_ARGS`, which is equivalent to passing in command line arguments

For example (with unix shell environment variable syntax):

```sh
VELLO_STATIC_LOG=&quot;vello=trace&quot; VELLO_STATIC_ARGS=&quot;--test-scenes&quot; cargo apk run -p with_winit --lib
```

## Minimum supported Rust Version (MSRV)

This version of Vello has been verified to compile with **Rust 1.86** and later.

Future versions of Vello might increase the Rust version requirement.
It will not be treated as a breaking change and as such can even happen with small patch releases.

&lt;details&gt;
&lt;summary&gt;Click here if compiling fails.&lt;/summary&gt;

As time has passed, some of Vello&#039;s dependencies could have released versions with a higher Rust requirement.
If you encounter a compilation issue due to a dependency and don&#039;t want to upgrade your Rust toolchain, then you could downgrade the dependency.

```sh
# Use the problematic dependency&#039;s name and version
cargo update -p package_name --precise 0.1.1
```

&lt;/details&gt;

## Community

Discussion of Vello development happens in the [Linebender Zulip](https://xi.zulipchat.com/), specifically the [#vello channel](https://xi.zulipchat.com/#narrow/channel/197075-vello).
All public content can be read without logging in.

Contributions are welcome by pull request.
The [Rust code of conduct] applies.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache 2.0 license, shall be licensed as noted in the [License](#license) section, without any additional terms or conditions.

## History

Vello was previously known as `piet-gpu`.
This prior incarnation used a custom cross-API hardware abstraction layer, called `piet-gpu-hal`, instead of [`wgpu`].

An archive of this version can be found in the branches [`custom-hal-archive-with-shaders`] and [`custom-hal-archive`].
This succeeded the previous prototype, [piet-metal], and included work adapted from [piet-dx12].

The decision to lay down `piet-gpu-hal` in favor of WebGPU is discussed in detail in the blog post [Requiem for piet-gpu-hal].

A [vision](https://github.com/linebender/vello/tree/main/doc/vision.md) document dated December 2020 explained the longer-term goals of the project, and how we might get there.
Many of these items are out-of-date or completed, but it still may provide some useful background.

## Related projects

Vello takes inspiration from many other rendering projects, including:

- [Pathfinder](https://github.com/servo/pathfinder)
- [Spinel](https://fuchsia.googlesource.com/fuchsia/+/refs/heads/master/src/graphics/lib/compute/spinel/)
- [Forma](https://github.com/google/forma)
- [Massively Parallel Vector Graphics](https://w3.impa.br/~diego/projects/GanEtAl14/)
- [Random-access rendering of general vector graphics](https://hhoppe.com/proj/ravg/)

## License

Licensed under either of

- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or &lt;http://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;http://opensource.org/licenses/MIT&gt;)

at your option.

In addition, all files in the [`vello_shaders/shader`](https://github.com/linebender/vello/tree/main/vello_shaders/shader) and [`vello_shaders/src/cpu`](https://github.com/linebender/vello/tree/main/vello_shaders/src/cpu) directories and subdirectories thereof are alternatively licensed under the Unlicense ([vello_shaders/shader/UNLICENSE](https://github.com/linebender/vello/tree/main/vello_shaders/shader/UNLICENSE) or &lt;http://unlicense.org/&gt;).
For clarity, these files are also licensed under either of the above licenses.
The intent is for this research to be used in as broad a context as possible.

The files in subdirectories of the [`examples/assets`](https://github.com/linebender/vello/tree/main/examples/assets) directory are licensed solely under their respective licenses, available in the `LICENSE` file in their directories.

[piet-metal]: https://github.com/linebender/piet-metal
[`wgpu`]: https://wgpu.rs/
[Xilem]: https://github.com/linebender/xilem/
[Rust code of conduct]: https://www.rust-lang.org/policies/code-of-conduct
[`custom-hal-archive-with-shaders`]: https://github.com/linebender/piet-gpu/tree/custom-hal-archive-with-shaders
[`custom-hal-archive`]: https://github.com/linebender/piet-gpu/tree/custom-hal-archive
[piet-dx12]: https://github.com/bzm3r/piet-dx12
[GhostScript tiger]: https://commons.wikimedia.org/wiki/File:Ghostscript_Tiger.svg
[winit]: https://github.com/rust-windowing/winit
[Bevy]: https://bevyengine.org/
[Requiem for piet-gpu-hal]: https://raphlinus.github.io/rust/gpu/2023/01/07/requiem-piet-gpu-hal.html
[the changelog]: https://github.com/linebender/vello/tree/main/CHANGELOG.md
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BloopAI/vibe-kanban]]></title>
            <link>https://github.com/BloopAI/vibe-kanban</link>
            <guid>https://github.com/BloopAI/vibe-kanban</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Kanban board to manage your AI coding agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BloopAI/vibe-kanban">BloopAI/vibe-kanban</a></h1>
            <p>Kanban board to manage your AI coding agents</p>
            <p>Language: Rust</p>
            <p>Stars: 5,928</p>
            <p>Forks: 594</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vibekanban.com&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;frontend/public/vibe-kanban-logo-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;frontend/public/vibe-kanban-logo.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;frontend/public/vibe-kanban-logo.svg&quot; alt=&quot;Vibe Kanban Logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Get 10X more out of Claude Code, Gemini CLI, Codex, Amp and other coding agents...&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/vibe-kanban&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/vibe-kanban?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/BloopAI/vibe-kanban/blob/main/.github/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/BloopAI/vibe-kanban/.github%2Fworkflows%2Fpublish.yml&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/BloopAI/vibe-kanban&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

![](frontend/public/vibe-kanban-screenshot-overview.png)

## Overview

AI coding agents are increasingly writing the world&#039;s code and human engineers now spend the majority of their time planning, reviewing, and orchestrating tasks. Vibe Kanban streamlines this process, enabling you to:

- Easily switch between different coding agents
- Orchestrate the execution of multiple coding agents in parallel or in sequence
- Quickly review work and start dev servers
- Track the status of tasks that your coding agents are working on
- Centralise configuration of coding agent MCP configs
- Open projects remotely via SSH when running Vibe Kanban on a remote server

You can watch a video overview [here](https://youtu.be/TFT3KnZOOAk).

## Installation

Make sure you have authenticated with your favourite coding agent. A full list of supported coding agents can be found in the [docs](https://vibekanban.com/docs). Then in your terminal run:

```bash
npx vibe-kanban
```

## Documentation

Please head to the [website](https://vibekanban.com/docs) for the latest documentation and user guides.

## Support

We use [GitHub Discussions](https://github.com/BloopAI/vibe-kanban/discussions) for feature requests. Please open a discussion to create a feature request. For bugs please open an issue on this repo.

## Contributing

We would prefer that ideas and changes are first raised with the core team via [GitHub Discussions](https://github.com/BloopAI/vibe-kanban/discussions) or Discord, where we can discuss implementation details and alignment with the existing roadmap. Please do not open PRs without first discussing your proposal with the team.

## Development

### Prerequisites

- [Rust](https://rustup.rs/) (latest stable)
- [Node.js](https://nodejs.org/) (&gt;=18)
- [pnpm](https://pnpm.io/) (&gt;=8)

Additional development tools:
```bash
cargo install cargo-watch
cargo install sqlx-cli
```

Install dependencies:
```bash
pnpm i
```

### Running the dev server

```bash
pnpm run dev
```

This will start the backend. A blank DB will be copied from the `dev_assets_seed` folder.

### Building the frontend

To build just the frontend:

```bash
cd frontend
pnpm build
```

### Build from source

1. Run `build-npm-package.sh`
2. In the `npx-cli` folder run `npm pack`
3. You can run your build with `npx [GENERATED FILE].tgz`


### Environment Variables

The following environment variables can be configured at build time or runtime:

| Variable | Type | Default | Description |
|----------|------|---------|-------------|
| `POSTHOG_API_KEY` | Build-time | Empty | PostHog analytics API key (disables analytics if empty) |
| `POSTHOG_API_ENDPOINT` | Build-time | Empty | PostHog analytics endpoint (disables analytics if empty) |
| `BACKEND_PORT` | Runtime | `0` (auto-assign) | Backend server port |
| `FRONTEND_PORT` | Runtime | `3000` | Frontend development server port |
| `HOST` | Runtime | `127.0.0.1` | Backend server host |
| `DISABLE_WORKTREE_ORPHAN_CLEANUP` | Runtime | Not set | Disable git worktree cleanup (for debugging) |

**Build-time variables** must be set when running `pnpm run build`. **Runtime variables** are read when the application starts.

### Remote Deployment

When running Vibe Kanban on a remote server (e.g., via systemctl, Docker, or cloud hosting), you can configure your editor to open projects via SSH:

1. **Access via tunnel**: Use Cloudflare Tunnel, ngrok, or similar to expose the web UI
2. **Configure remote SSH** in Settings ‚Üí Editor Integration:
   - Set **Remote SSH Host** to your server hostname or IP
   - Set **Remote SSH User** to your SSH username (optional)
3. **Prerequisites**:
   - SSH access from your local machine to the remote server
   - SSH keys configured (passwordless authentication)
   - VSCode Remote-SSH extension

When configured, the &quot;Open in VSCode&quot; buttons will generate URLs like `vscode://vscode-remote/ssh-remote+user@host/path` that open your local editor and connect to the remote server.

See the [documentation](https://vibekanban.com/docs/configuration-customisation/global-settings#remote-ssh-configuration) for detailed setup instructions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[supabase/etl]]></title>
            <link>https://github.com/supabase/etl</link>
            <guid>https://github.com/supabase/etl</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Stream your Postgres data anywhere in real-time. Simple Rust building blocks for change data capture (CDC) pipelines.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/supabase/etl">supabase/etl</a></h1>
            <p>Stream your Postgres data anywhere in real-time. Simple Rust building blocks for change data capture (CDC) pipelines.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,875</p>
            <p>Forks: 107</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://supabase.com&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;ETL by Supabase&quot; width=&quot;100%&quot; src=&quot;docs/assets/etl-logo-extended.png&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;

  &lt;h1 align=&quot;center&quot;&gt;ETL&lt;/h1&gt;

  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/supabase/etl/actions/workflows/ci.yml&quot;&gt;
      &lt;img alt=&quot;CI&quot; src=&quot;https://github.com/supabase/etl/actions/workflows/ci.yml/badge.svg?branch=main&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://coveralls.io/github/supabase/etl?branch=main&quot;&gt;
      &lt;img alt=&quot;Coverage Status&quot; src=&quot;https://coveralls.io/repos/github/supabase/etl/badge.svg?branch=main&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/supabase/etl/actions/workflows/docs.yml&quot;&gt;
      &lt;img alt=&quot;Docs&quot; src=&quot;https://github.com/supabase/etl/actions/workflows/docs.yml/badge.svg?branch=main&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/supabase/etl/actions/workflows/docker-build.yml&quot;&gt;
      &lt;img alt=&quot;Docker Build&quot; src=&quot;https://github.com/supabase/etl/actions/workflows/docker-build.yml/badge.svg?branch=main&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/supabase/etl/actions/workflows/audit.yml&quot;&gt;
      &lt;img alt=&quot;Security Audit&quot; src=&quot;https://github.com/supabase/etl/actions/workflows/audit.yml/badge.svg?branch=main&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;LICENSE&quot;&gt;
      &lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
    &lt;/a&gt;
    &lt;br /&gt;
    Build real-time Postgres replication applications in Rust
    &lt;br /&gt;
    &lt;a href=&quot;https://supabase.github.io/etl&quot;&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/supabase/etl/tree/main/etl-examples&quot;&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/supabase/etl/issues&quot;&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;/p&gt;

ETL is a Rust framework by [Supabase](https://supabase.com) for building high‚Äëperformance, real‚Äëtime data replication apps on Postgres. It sits on top of Postgres [logical replication](https://www.postgresql.org/docs/current/protocol-logical-replication.html) and gives you a clean, Rust‚Äënative API for streaming changes to your own destinations.

## Highlights

- **Real‚Äëtime replication**: stream changes in real time to your own destinations.
- **High performance**: configurable batching and parallelism to maximize throughput.
- **Fault-tolerant**: robust error handling and retry logic built-in.
- **Extensible**: implement your own custom destinations and state/schema stores.
- **Rust native**: typed and ergonomic Rust API.

## Requirements

**PostgreSQL Version:** ETL officially supports and tests against **PostgreSQL 14, 15, 16, and 17**.

- **PostgreSQL 15+** is recommended for access to advanced publication features including:
  - Column-level filtering
  - Row-level filtering with `WHERE` clauses
  - `FOR ALL TABLES IN SCHEMA` syntax

For detailed configuration instructions, see the [Configure Postgres documentation](https://supabase.github.io/etl/how-to/configure-postgres/).

## Get Started

Install via Git while we prepare for a crates.io release:

```toml
[dependencies]
etl = { git = &quot;https://github.com/supabase/etl&quot; }
```

Quick example using the in‚Äëmemory destination:

```rust
use etl::{
    config::{BatchConfig, PgConnectionConfig, PipelineConfig, TlsConfig},
    destination::memory::MemoryDestination,
    pipeline::Pipeline,
    store::both::memory::MemoryStore,
};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let pg = PgConnectionConfig {
        host: &quot;localhost&quot;.into(),
        port: 5432,
        name: &quot;mydb&quot;.into(),
        username: &quot;postgres&quot;.into(),
        password: Some(&quot;password&quot;.into()),
        tls: TlsConfig { enabled: false, trusted_root_certs: String::new() },
    };

    let store = MemoryStore::new();
    let destination = MemoryDestination::new();

    let config = PipelineConfig {
        id: 1,
        publication_name: &quot;my_publication&quot;.into(),
        pg_connection: pg,
        batch: BatchConfig { max_size: 1000, max_fill_ms: 5000 },
        table_error_retry_delay_ms: 10_000,
        table_error_retry_max_attempts: 5,
        max_table_sync_workers: 4,
    };

    let mut pipeline = Pipeline::new(config, store, destination);
    pipeline.start().await?;
    // pipeline.wait().await?; // Optional: block until completion

    Ok(())
}
```

For tutorials and deeper guidance, see the [Documentation](https://supabase.github.io/etl) or jump into the [examples](etl-examples/README.md).

## Destinations

ETL is designed to be extensible. You can implement your own destinations to send data to any destination you like, however it comes with a few built in destinations:

- BigQuery

Out-of-the-box destinations are available in the `etl-destinations` crate:

```toml
[dependencies]
etl = { git = &quot;https://github.com/supabase/etl&quot; }
etl-destinations = { git = &quot;https://github.com/supabase/etl&quot;, features = [&quot;bigquery&quot;] }
```

## License

Apache‚Äë2.0. See `LICENSE` for details.

---

&lt;p align=&quot;center&quot;&gt;
  Made with ‚ù§Ô∏è by the &lt;a href=&quot;https://supabase.com&quot;&gt;Supabase&lt;/a&gt; team
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[erebe/wstunnel]]></title>
            <link>https://github.com/erebe/wstunnel</link>
            <guid>https://github.com/erebe/wstunnel</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[Tunnel all your traffic over Websocket or HTTP2 - Bypass firewalls/DPI - Static binary available]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/erebe/wstunnel">erebe/wstunnel</a></h1>
            <p>Tunnel all your traffic over Websocket or HTTP2 - Bypass firewalls/DPI - Static binary available</p>
            <p>Language: Rust</p>
            <p>Stars: 5,970</p>
            <p>Forks: 481</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/erebe/wstunnel/raw/main/docs/logo_wstunnel.png&quot; alt=&quot;wstunnel logo&quot; height=&quot;400&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;https://ko-fi.com/P5P4QCHMO&quot;&gt;&lt;img src=&quot;https://ko-fi.com/img/githubbutton_sm.svg&quot;/&gt;&lt;/a&gt;
  &lt;br/&gt;
&lt;/p&gt;

## Summary

* [Description](#description)
* [Demo server](#demo)
* [Command line](#cmd)
* [Examples](#examples)
* [Release](#release)
* [Note](#note)
* [Benchmark](#bench)
* [How to build](#build)

## Description &lt;a name=&quot;description&quot;&gt;&lt;/a&gt;

Most of the time when you are using a public network, you are behind some kind of firewall or proxy. One of their
purpose is to constrain you to only use certain kind of protocols and consult only a subset of the web. Nowadays, the
most widespread protocol is http and is de facto allowed by third party equipment.

Wstunnel uses the websocket protocol which is compatible with http in order to bypass firewalls and proxies. Wstunnel
allows you to tunnel whatever traffic you want and access whatever resources/site you need.

My inspiration came from [this project](https://www.npmjs.com/package/wstunnel) but as I don&#039;t want to install npm and
nodejs to use this tool, I remade it in ~~Haskell~~ Rust and improved it.

**What to expect:**

* Easy to use
* Good error messages and debug information
* Static forward (reverse) tunneling (TCP, UDP, Unix socket, Stdio)
* Dynamic (reverse) tunneling (Socks5 proxy, HTTP proxy and Transparent Proxy)
* Support for using http proxy (when behind one) as gateway
* Support of proxy protocol
* Support for tls/https server with certificates auto-reload (with embedded self-signed certificate, or your own)
* Support of mTLS with certificates auto-reload - [documentation here](https://github.com/erebe/wstunnel/blob/main/docs/using_mtls.md)
* Support IPv6
* Support for Websocket and HTTP2 as transport protocol (websocket is more performant)
* **Standalone binaries** (so just cp it where you want) [here](https://github.com/erebe/wstunnel/releases)

## Sponsors &lt;a name=&quot;sponsors&quot;&gt;&lt;/a&gt;

Part of Wstunnel development has been sponsored by
&lt;p align=&quot;center&quot;&gt;
   &lt;a href=&quot;https://serviceplanet.nl&quot;&gt;
    &lt;img width=&quot;200&quot; height=&quot;100&quot; src=&quot;https://github.com/erebe/wstunnel/raw/main/docs/logo_serviceplanet.png&quot; alt=&quot;service planet logo&quot;/&gt;
   &lt;/a&gt;&lt;/p&gt;

## Note &lt;a name=&quot;note&quot;&gt;&lt;/a&gt;

v7.0.0 is a complete rewrite of wstunnel in Rust and is not compatible with previous version.
Previous code in Haskell can be found on branch https://github.com/erebe/wstunnel/tree/haskell

What to expect from previous version:

* More throughput and less jitter due to Haskell GC. Most of you will not care, as it was performant enough already. But
  you can now saturate a gigabit ethernet card with a single connection
* Command line is more homogeneous/has better UX. All tunnel can be specified multiple times
* Tunnel protocol tries to look like normal traffic, to avoid being flagged
* Support of reverse tunneling
* New bug, it is a rewrite (‚ïØ&#039;‚ñ°&#039;)‚ïØÔ∏µ ‚îª‚îÅ‚îª ¬Ø\\_(„ÉÑ)_/¬Ø
* Mainly for me to ease the maintenance of the project. I don&#039;t do a lot of haskell nowadays and it was harder for me to
  keep maintening the project over time, as I get lost in touch of the Haskell ecosystem and new release.
* Armv7 build (aka raspberry pi), as new version of GHC (Haskell compiler) dropped its support


## Demo server &lt;a name=&quot;demo&quot;&gt;&lt;/a&gt;

If you just want to try out that you can bypass your proxy/firewall.
You can give it a try with wstunnel demo server.

```bash
# In a terminal start wstunnel client
# You can set as tls-sni-override whatever domain you want. The tunnel is the only one that is going to be allowed. 
wstunnel client -L &#039;tcp://4443:localhost:444?proxy_protocol&#039; -P demo --tls-sni-override=google.fr wss://49.13.58.9

# on another terminal, run curl and it should return you this greetings
curl -k https://localhost:4443
&gt; Memento mori !
```


## Command line &lt;a name=&quot;cmd&quot;&gt;&lt;/a&gt;

```
Usage: wstunnel client [OPTIONS] &lt;ws[s]|http[s]://wstunnel.server.com[:port]&gt;

Arguments:
  &lt;ws[s]|http[s]://wstunnel.server.com[:port]&gt;
          Address of the wstunnel server
          You can either use websocket or http2 as transport protocol. Use websocket if you are unsure.
          Example: For websocket with TLS wss://wstunnel.example.com or without ws://wstunnel.example.com
                   For http2 with TLS https://wstunnel.example.com or without http://wstunnel.example.com
          
          *WARNING* HTTP2 as transport protocol is harder to make it works because:
            - If you are behind a (reverse) proxy/CDN they are going to buffer the whole request before forwarding it to the server
              Obviously, this is not going to work for tunneling traffic
            - if you have wstunnel behind a reverse proxy, most of them (i.e: nginx) are going to turn http2 request into http1
              This is not going to work, because http1 does not support streaming naturally
          The only way to make it works with http2 is to have wstunnel directly exposed to the internet without any reverse proxy in front of it

Options:
  -L, --local-to-remote &lt;{tcp,udp,socks5,stdio,unix}://[BIND:]PORT:HOST:PORT&gt;
          Listen on local and forwards traffic from remote. Can be specified multiple times
          examples:
          &#039;tcp://1212:google.com:443&#039;      =&gt;       listen locally on tcp on port 1212 and forward to google.com on port 443
          &#039;tcp://2:n.lan:4?proxy_protocol&#039; =&gt;       listen locally on tcp on port 2 and forward to n.lan on port 4
                                                    Send a proxy protocol header v2 when establishing connection to n.lan
          
          &#039;udp://1212:1.1.1.1:53&#039;          =&gt;       listen locally on udp on port 1212 and forward to cloudflare dns 1.1.1.1 on port 53
          &#039;udp://1212:1.1.1.1:53?timeout_sec=10&#039;    timeout_sec on udp force close the tunnel after 10sec. Set it to 0 to disable the timeout [default: 30]
          
          &#039;socks5://[::1]:1212&#039;            =&gt;       listen locally with socks5 on port 1212 and forward dynamically requested tunnel
          &#039;socks5://[::1]:1212?login=admin&amp;password=admin&#039; =&gt; listen locally with socks5 on port 1212 and only accept connection with login=admin and password=admin
          
          &#039;http://[::1]:1212&#039;              =&gt;       start a http proxy on port 1212 and forward dynamically requested tunnel
          &#039;http://[::1]:1212?login=admin&amp;password=admin&#039; =&gt; start a http proxy on port 1212 and only accept connection with login=admin and password=admin

          &#039;tproxy+tcp://[::1]:1212&#039;        =&gt;       listen locally on tcp on port 1212 as a *transparent proxy* and forward dynamically requested tunnel
          &#039;tproxy+udp://[::1]:1212?timeout_sec=10&#039;  listen locally on udp on port 1212 as a *transparent proxy* and forward dynamically requested tunnel
                                                    linux only and requires sudo/CAP_NET_ADMIN
          
          &#039;stdio://google.com:443&#039;         =&gt;       listen for data from stdio, mainly for `ssh -o ProxyCommand=&quot;wstunnel client --log-lvl=off -L stdio://%h:%p ws://localhost:8080&quot; my-server`
          
          &#039;unix:///tmp/wstunnel.sock:g.com:443&#039; =&gt;  listen for data from unix socket of path /tmp/wstunnel.sock and forward to g.com:443

  -R, --remote-to-local &lt;{tcp,udp,socks5,unix}://[BIND:]PORT:HOST:PORT&gt;
          Listen on remote and forwards traffic from local. Can be specified multiple times. Only tcp is supported
          examples:
          &#039;tcp://1212:google.com:443&#039;      =&gt;     listen on server for incoming tcp cnx on port 1212 and forward to google.com on port 443 from local machine
          &#039;udp://1212:1.1.1.1:53&#039;          =&gt;     listen on server for incoming udp on port 1212 and forward to cloudflare dns 1.1.1.1 on port 53 from local machine
          &#039;socks5://[::1]:1212&#039;            =&gt;     listen on server for incoming socks5 request on port 1212 and forward dynamically request from local machine
          &#039;http://[::1]:1212&#039;              =&gt;     listen on server for incoming http proxy request on port 1212 and forward dynamically request from local machine (login/password is supported)
          &#039;unix://wstunnel.sock:g.com:443&#039; =&gt;     listen on server for incoming data from unix socket of path wstunnel.sock and forward to g.com:443 from local machine

      --no-color &lt;NO_COLOR&gt;
          Disable color output in logs
          
          [env: NO_COLOR=]

      --socket-so-mark &lt;INT&gt;
          (linux only) Mark network packet with SO_MARK sockoption with the specified value.
          You need to use {root, sudo, capabilities} to run wstunnel when using this option

  -c, --connection-min-idle &lt;INT&gt;
          Client will maintain a pool of open connection to the server, in order to speed up the connection process.
          This option set the maximum number of connection that will be kept open.
          This is useful if you plan to create/destroy a lot of tunnel (i.e: with socks5 to navigate with a browser)
          It will avoid the latency of doing tcp + tls handshake with the server
          
          [default: 0]

      --nb-worker-threads &lt;INT&gt;
          *WARNING* The flag does nothing, you need to set the env variable *WARNING*
          Control the number of threads that will be used.
          By default, it is equal the number of cpus
          
          [env: TOKIO_WORKER_THREADS=]

      --log-lvl &lt;LOG_LEVEL&gt;
          Control the log verbosity. i.e: TRACE, DEBUG, INFO, WARN, ERROR, OFF
          for more details: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html#example-syntax
          
          [env: RUST_LOG=]
          [default: INFO]

      --tls-sni-override &lt;DOMAIN_NAME&gt;
          Domain name that will be used as SNI during TLS handshake
          Warning: If you are behind a CDN (i.e: Cloudflare) you must set this domain also in the http HOST header.
                   or it will be flagged as fishy and your request rejected

      --tls-sni-disable
          Disable sending SNI during TLS handshake
          Warning: Most reverse proxies rely on it

      --tls-ech-enable
          Enable ECH (encrypted sni) during TLS handshake to wstunnel server.
          Warning: Ech DNS config is not refreshed over time. It is retrieved only once at startup of the program

      --tls-verify-certificate
          Enable TLS certificate verification.
          Disabled by default. The client will happily connect to any server with self-signed certificate.

  -p, --http-proxy &lt;USER:PASS@HOST:PORT&gt;
          If set, will use this http proxy to connect to the server
          
          [env: HTTP_PROXY=]

      --http-proxy-login &lt;LOGIN&gt;
          If set, will use this login to connect to the http proxy. Override the one from --http-proxy
          
          [env: WSTUNNEL_HTTP_PROXY_LOGIN=]

      --http-proxy-password &lt;PASSWORD&gt;
          If set, will use this password to connect to the http proxy. Override the one from --http-proxy
          
          [env: WSTUNNEL_HTTP_PROXY_PASSWORD=]

  -P, --http-upgrade-path-prefix &lt;HTTP_UPGRADE_PATH_PREFIX&gt;
          Use a specific prefix that will show up in the http path during the upgrade request.
          Useful if you need to route requests server side but don&#039;t have vhosts
          
          [env: WSTUNNEL_HTTP_UPGRADE_PATH_PREFIX=]
          [default: v1]

      --http-upgrade-credentials &lt;USER[:PASS]&gt;
          Pass authorization header with basic auth credentials during the upgrade request.
          If you need more customization, you can use the http_headers option.

      --websocket-ping-frequency-sec &lt;seconds&gt;
          Frequency at which the client will send websocket ping to the server.
          
          [default: 30]

      --websocket-mask-frame
          Enable the masking of websocket frames. Default is false
          Enable this option only if you use unsecure (non TLS) websocket server, and you see some issues. Otherwise, it is just overhead.

  -H, --http-headers &lt;HEADER_NAME: HEADER_VALUE&gt;
          Send custom headers in the upgrade request
          Can be specified multiple time

      --http-headers-file &lt;FILE_PATH&gt;
          Send custom headers in the upgrade request reading them from a file.
          It overrides http_headers specified from command line.
          File is read everytime and file format must contain lines with `HEADER_NAME: HEADER_VALUE`

      --tls-certificate &lt;FILE_PATH&gt;
          [Optional] Certificate (pem) to present to the server when connecting over TLS (HTTPS).
          Used when the server requires clients to authenticate themselves with a certificate (i.e. mTLS).
          The certificate will be automatically reloaded if it changes

      --tls-private-key &lt;FILE_PATH&gt;
          [Optional] The private key for the corresponding certificate used with mTLS.
          The certificate will be automatically reloaded if it changes

      --dns-resolver &lt;DNS_RESOLVER&gt;
          Dns resolver to use to lookup ips of domain name. Can be specified multiple time
          Example:
           dns://1.1.1.1 for using udp
           dns+https://1.1.1.1?sni=cloudflare-dns.com for using dns over HTTPS
           dns+tls://8.8.8.8?sni=dns.google for using dns over TLS
          For Dns over HTTPS/TLS if an HTTP proxy is configured, it will be used also
          To use libc resolver, use
          system://0.0.0.0

          **WARN** On windows you may want to specify explicitly the DNS resolver to avoid excessive DNS queries
```

```
SERVER
Usage: wstunnel server [OPTIONS] &lt;ws[s]://0.0.0.0[:port]&gt;

Arguments:
  &lt;ws[s]://0.0.0.0[:port]&gt;
          Address of the wstunnel server to bind to
          Example: With TLS wss://0.0.0.0:8080 or without ws://[::]:8080
          
          The server is capable of detecting by itself if the request is websocket or http2. So you don&#039;t need to specify it.

Options:
      --socket-so-mark &lt;INT&gt;
          (linux only) Mark network packet with SO_MARK sockoption with the specified value.
          You need to use {root, sudo, capabilities} to run wstunnel when using this option

      --websocket-ping-frequency-sec &lt;seconds&gt;
          Frequency at which the server will send websocket ping to client.

      --no-color &lt;NO_COLOR&gt;
          Disable color output in logs
          
          [env: NO_COLOR=]

      --websocket-mask-frame
          Enable the masking of websocket frames. Default is false
          Enable this option only if you use unsecure (non TLS) websocket server, and you see some issues. Otherwise, it is just overhead.

      --nb-worker-threads &lt;INT&gt;
          *WARNING* The flag does nothing, you need to set the env variable *WARNING*
          Control the number of threads that will be used.
          By default, it is equal the number of cpus
          
          [env: TOKIO_WORKER_THREADS=]

      --restrict-to &lt;DEST:PORT&gt;
          Server will only accept connection from the specified tunnel information.
          Can be specified multiple time
          Example: --restrict-to &quot;google.com:443&quot; --restrict-to &quot;localhost:22&quot;

      --dns-resolver &lt;DNS_RESOLVER&gt;
          Dns resolver to use to lookup ips of domain name
          This option is not going to work if you use transparent proxy
          Can be specified multiple time
          Example:
           dns://1.1.1.1 for using udp
           dns+https://1.1.1.1?sni=loudflare-dns.com for using dns over HTTPS
           dns+tls://8.8.8.8?sni=dns.google for using dns over TLS
          To use libc resolver, use
          system://0.0.0.0

      --log-lvl &lt;LOG_LEVEL&gt;
          Control the log verbosity. i.e: TRACE, DEBUG, INFO, WARN, ERROR, OFF
          for more details: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html#example-syntax
          
          [env: RUST_LOG=]
          [default: INFO]

  -r, --restrict-http-upgrade-path-prefix &lt;RESTRICT_HTTP_UPGRADE_PATH_PREFIX&gt;
          Server will only accept connection from if this specific path prefix is used during websocket upgrade.
          Useful if you specify in the client a custom path prefix, and you want the server to only allow this one.
          The path prefix act as a secret to authenticate clients
          Disabled by default. Accept all path prefix. Can be specified multiple time
          
          [env: WSTUNNEL_RESTRICT_HTTP_UPGRADE_PATH_PREFIX=]

      --restrict-config &lt;RESTRICT_CONFIG&gt;
          Path to the location of the restriction yaml config file.
          Restriction file is automatically reloaded if it changes

      --tls-certificate &lt;FILE_PATH&gt;
          [Optional] Use custom certificate (pem) instead of the default embedded self-signed certificate.
          The certificate will be automatically reloaded if it changes

      --tls-private-key &lt;FILE_PATH&gt;
          [Optional] Use a custom tls key (pem, ec, rsa) that the server will use instead of the default embedded one
          The private key will be automatically reloaded if it changes

      --tls-client-ca-certs &lt;FILE_PATH&gt;
          [Optional] Enables mTLS (client authentication with certificate). Argument must be PEM file
          containing one or more certificates of CA&#039;s of which the certificate of clients needs to be signed with.
          The ca will be automatically reloaded if it changes
          
    -p, --http-proxy &lt;USER:PASS@HOST:PORT&gt;
          If set, will use this http proxy to connect to the client

          [env: HTTP_PROXY=]

      --http-proxy-login &lt;LOGIN&gt;
          If set, will use this login to connect to the http proxy. Override the one from --http-proxy

          [env: WSTUNNEL_HTTP_PROXY_LOGIN=]

      --http-proxy-password &lt;PASSWORD&gt;
          If set, will use this password to connect to the http proxy. Override the one from --http-proxy

          [env: WSTUNNEL_HTTP_PROXY_PASSWORD=]
```

## Release &lt;a name=&quot;release&quot;&gt;&lt;/a&gt;

Static binaries are available in [release section](https://github.com/erebe/wstunnel/releases)

docker image are available at https://github.com/erebe/wstunnel/pkgs/container/wstunnel

```bash
docker pull ghcr.io/erebe/wstunnel:latest
```

## Examples &lt;a name=&quot;examples&quot;&gt;&lt;/a&gt;

* [Understand command line syntax](#syntax)
* [Simplest one with socks5 - Good for browsing internet](#simple)
* [Proxy SSH](#ssh)
* [Bypass a corporate proxy](#corporate)
* [Proxy Wireguard traffic](#wireguard)
* [Android](#android)
* [Proxy easily any traffic with transparent proxy (linux only)](#tproxy)
* [Reverse tunneling](#reverse)
* [How to secure access of your wstunnel server](#secure)
* [Use HTTP2 instead of websocket for transport protocol](#http2)
* [Maximize your stealthiness/Make your traffic discrete](#stealth)

### Understand command line syntax &lt;a name=&quot;syntax&quot;&gt;&lt;/a&gt;

Wstunnel command line mimic ssh tunnel syntax.
You can take reference to [this article](https://iximiuz.com/en/posts/ssh-tunnels/), or this diagram to understand
&lt;img src=&quot;https://iximiuz.com/ssh-tunnels/ssh-tunnels.png&quot;&gt;

---

### Simplest one &lt;a name=&quot;simple&quot;&gt;&lt;/a&gt;

On your remote host, start the wstunnel&#039;s server by typing this command in your terminal

```bash
wstunnel server wss://[::]:8080
```

This will create a websocket server listening on any interface on port 8080.
On the client side use this command to forward traffic through the websocket tunnel

```bash
wstunnel client -L socks5://127.0.0.1:8888 --connection-min-idle 5 wss://myRemoteHost:8080
```

This command will create a socks5 server listening on port 8888 of the loopback interface and will forward traffic
dynamically.
`connection-min-idle 10` is going an optimization to create a pool of 10 connection connected to the server, to speed-up
the establishement of new tunnels.

With firefox you can setup a proxy using this tunnel, by setting in networking preferences 127.0.0.1:8888 and selecting
socks5 proxy.
Be sure to check the option `Proxy DNS when using SOCKS v5` fo

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nushell/nushell]]></title>
            <link>https://github.com/nushell/nushell</link>
            <guid>https://github.com/nushell/nushell</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[A new type of shell]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nushell/nushell">nushell/nushell</a></h1>
            <p>A new type of shell</p>
            <p>Language: Rust</p>
            <p>Stars: 37,275</p>
            <p>Forks: 1,968</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># Nushell &lt;!-- omit in toc --&gt;
[![Crates.io](https://img.shields.io/crates/v/nu.svg)](https://crates.io/crates/nu)
[![Build Status](https://img.shields.io/github/actions/workflow/status/nushell/nushell/ci.yml?branch=main)](https://github.com/nushell/nushell/actions)
[![Nightly Build](https://github.com/nushell/nushell/actions/workflows/nightly-build.yml/badge.svg)](https://github.com/nushell/nushell/actions/workflows/nightly-build.yml)
[![Discord](https://img.shields.io/discord/601130461678272522.svg?logo=discord)](https://discord.gg/NtAbbGn)
[![The Changelog #363](https://img.shields.io/badge/The%20Changelog-%23363-61c192.svg)](https://changelog.com/podcast/363)
[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/nushell/nushell)](https://github.com/nushell/nushell/graphs/commit-activity)
[![GitHub contributors](https://img.shields.io/github/contributors/nushell/nushell)](https://github.com/nushell/nushell/graphs/contributors)

A new type of shell.

![Example of nushell](assets/nushell-autocomplete6.gif &quot;Example of nushell&quot;)

## Table of Contents &lt;!-- omit in toc --&gt;

- [Status](#status)
- [Learning About Nu](#learning-about-nu)
- [Installation](#installation)
- [Configuration](#configuration)
- [Philosophy](#philosophy)
  - [Pipelines](#pipelines)
  - [Opening files](#opening-files)
  - [Plugins](#plugins)
- [Goals](#goals)
- [Officially Supported By](#officially-supported-by)
- [Contributing](#contributing)
- [License](#license)

## Status

This project has reached a minimum-viable-product level of quality. Many people use it as their daily driver, but it may be unstable for some commands. Nu&#039;s design is subject to change as it matures.

## Learning About Nu

The [Nushell book](https://www.nushell.sh/book/) is the primary source of Nushell documentation. You can find [a full list of Nu commands in the book](https://www.nushell.sh/commands/), and we have many examples of using Nu in our [cookbook](https://www.nushell.sh/cookbook/).

We&#039;re also active on [Discord](https://discord.gg/NtAbbGn); come and chat with us!

## Installation

To quickly install Nu:

```bash
# Linux and macOS
brew install nushell
# Windows
winget install nushell
```

To use `Nu` in GitHub Action, check [setup-nu](https://github.com/marketplace/actions/setup-nu) for more detail.

Detailed installation instructions can be found in the [installation chapter of the book](https://www.nushell.sh/book/installation.html). Nu is available via many package managers:

[![Packaging status](https://repology.org/badge/vertical-allrepos/nushell.svg?columns=3)](https://repology.org/project/nushell/versions)

For details about which platforms the Nushell team actively supports, see [our platform support policy](devdocs/PLATFORM_SUPPORT.md).

## Configuration

The default configurations can be found at [sample_config](crates/nu-utils/src/default_files)
which are the configuration files one gets when they startup Nushell for the first time.

It sets all of the default configuration to run Nushell.  From here one can
then customize this file for their specific needs.

To see where *config.nu* is located on your system simply type this command.

```rust
$nu.config-path
```

Please see our [book](https://www.nushell.sh) for all of the Nushell documentation.


## Philosophy

Nu draws inspiration from projects like PowerShell, functional programming languages, and modern CLI tools.
Rather than thinking of files and data as raw streams of text, Nu looks at each input as something with structure.
For example, when you list the contents of a directory what you get back is a table of rows, where each row represents an item in that directory.
These values can be piped through a series of steps, in a series of commands called a &#039;pipeline&#039;.

### Pipelines

In Unix, it&#039;s common to pipe between commands to split up a sophisticated command over multiple steps.
Nu takes this a step further and builds heavily on the idea of _pipelines_.
As in the Unix philosophy, Nu allows commands to output to stdout and read from stdin.
Additionally, commands can output structured data (you can think of this as a third kind of stream).
Commands that work in the pipeline fit into one of three categories:

-   Commands that produce a stream (e.g., `ls`)
-   Commands that filter a stream (e.g., `where type == &quot;dir&quot;`)
-   Commands that consume the output of the pipeline (e.g., `table`)

Commands are separated by the pipe symbol (`|`) to denote a pipeline flowing left to right.

```shell
ls | where type == &quot;dir&quot; | table
# =&gt; ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
# =&gt; ‚îÇ #  ‚îÇ   name   ‚îÇ type ‚îÇ  size   ‚îÇ   modified    ‚îÇ
# =&gt; ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
# =&gt; ‚îÇ  0 ‚îÇ .cargo   ‚îÇ dir  ‚îÇ     0 B ‚îÇ 9 minutes ago ‚îÇ
# =&gt; ‚îÇ  1 ‚îÇ assets   ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  2 ‚îÇ crates   ‚îÇ dir  ‚îÇ 4.0 KiB ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  3 ‚îÇ docker   ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  4 ‚îÇ docs     ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  5 ‚îÇ images   ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  6 ‚îÇ pkg_mgrs ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  7 ‚îÇ samples  ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  8 ‚îÇ src      ‚îÇ dir  ‚îÇ 4.0 KiB ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ  9 ‚îÇ target   ‚îÇ dir  ‚îÇ     0 B ‚îÇ a day ago     ‚îÇ
# =&gt; ‚îÇ 10 ‚îÇ tests    ‚îÇ dir  ‚îÇ 4.0 KiB ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚îÇ 11 ‚îÇ wix      ‚îÇ dir  ‚îÇ     0 B ‚îÇ 2 weeks ago   ‚îÇ
# =&gt; ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

Because most of the time you&#039;ll want to see the output of a pipeline, `table` is assumed.
We could have also written the above:

```shell
ls | where type == &quot;dir&quot;
```

Being able to use the same commands and compose them differently is an important philosophy in Nu.
For example, we could use the built-in `ps` command to get a list of the running processes, using the same `where` as above.

```shell
ps | where cpu &gt; 0
# =&gt; ‚ï≠‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
# =&gt; ‚îÇ # ‚îÇ  pid  ‚îÇ   name    ‚îÇ  cpu  ‚îÇ    mem    ‚îÇ  virtual  ‚îÇ
# =&gt; ‚îú‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
# =&gt; ‚îÇ 0 ‚îÇ  2240 ‚îÇ Slack.exe ‚îÇ 16.40 ‚îÇ 178.3 MiB ‚îÇ 232.6 MiB ‚îÇ
# =&gt; ‚îÇ 1 ‚îÇ 16948 ‚îÇ Slack.exe ‚îÇ 16.32 ‚îÇ 205.0 MiB ‚îÇ 197.9 MiB ‚îÇ
# =&gt; ‚îÇ 2 ‚îÇ 17700 ‚îÇ nu.exe    ‚îÇ  3.77 ‚îÇ  26.1 MiB ‚îÇ   8.8 MiB ‚îÇ
# =&gt; ‚ï∞‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

### Opening files

Nu can load file and URL contents as raw text or structured data (if it recognizes the format).
For example, you can load a .toml file as structured data and explore it:

```shell
open Cargo.toml
# =&gt; ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
# =&gt; ‚îÇ bin              ‚îÇ [table 1 row]      ‚îÇ
# =&gt; ‚îÇ dependencies     ‚îÇ {record 25 fields} ‚îÇ
# =&gt; ‚îÇ dev-dependencies ‚îÇ {record 8 fields}  ‚îÇ
# =&gt; ‚îÇ features         ‚îÇ {record 10 fields} ‚îÇ
# =&gt; ‚îÇ package          ‚îÇ {record 13 fields} ‚îÇ
# =&gt; ‚îÇ patch            ‚îÇ {record 1 field}   ‚îÇ
# =&gt; ‚îÇ profile          ‚îÇ {record 3 fields}  ‚îÇ
# =&gt; ‚îÇ target           ‚îÇ {record 3 fields}  ‚îÇ
# =&gt; ‚îÇ workspace        ‚îÇ {record 1 field}   ‚îÇ
# =&gt; ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

We can pipe this into a command that gets the contents of one of the columns:

```shell
open Cargo.toml | get package
# =&gt; ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
# =&gt; ‚îÇ authors       ‚îÇ [list 1 item]                      ‚îÇ
# =&gt; ‚îÇ default-run   ‚îÇ nu                                 ‚îÇ
# =&gt; ‚îÇ description   ‚îÇ A new type of shell                ‚îÇ
# =&gt; ‚îÇ documentation ‚îÇ https://www.nushell.sh/book/       ‚îÇ
# =&gt; ‚îÇ edition       ‚îÇ 2018                               ‚îÇ
# =&gt; ‚îÇ exclude       ‚îÇ [list 1 item]                      ‚îÇ
# =&gt; ‚îÇ homepage      ‚îÇ https://www.nushell.sh             ‚îÇ
# =&gt; ‚îÇ license       ‚îÇ MIT                                ‚îÇ
# =&gt; ‚îÇ metadata      ‚îÇ {record 1 field}                   ‚îÇ
# =&gt; ‚îÇ name          ‚îÇ nu                                 ‚îÇ
# =&gt; ‚îÇ repository    ‚îÇ https://github.com/nushell/nushell ‚îÇ
# =&gt; ‚îÇ rust-version  ‚îÇ 1.60                               ‚îÇ
# =&gt; ‚îÇ version       ‚îÇ 0.72.0                             ‚îÇ
# =&gt; ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

And if needed we can drill down further:

```shell
open Cargo.toml | get package.version
# =&gt; 0.72.0
```

### Plugins

Nu supports plugins that offer additional functionality to the shell and follow the same structured data model that built-in commands use. There are a few examples in the `crates/nu_plugins_*` directories.

Plugins are binaries that are available in your path and follow a `nu_plugin_*` naming convention.
These binaries interact with nu via a simple JSON-RPC protocol where the command identifies itself and passes along its configuration, making it available for use.
If the plugin is a filter, data streams to it one element at a time, and it can stream data back in return via stdin/stdout.
If the plugin is a sink, it is given the full vector of final data and is given free reign over stdin/stdout to use as it pleases.

The [awesome-nu repo](https://github.com/nushell/awesome-nu#plugins) lists a variety of nu-plugins while the [showcase repo](https://github.com/nushell/showcase) *shows* off informative blog posts that have been written about Nushell along with videos that highlight technical
topics that have been presented.

## Goals

Nu adheres closely to a set of goals that make up its design philosophy. As features are added, they are checked against these goals.

-   First and foremost, Nu is cross-platform. Commands and techniques should work across platforms and Nu has [first-class support for Windows, macOS, and Linux](devdocs/PLATFORM_SUPPORT.md).

-   Nu ensures compatibility with existing platform-specific executables.

-   Nu&#039;s workflow and tools should have the usability expected of modern software in 2022 (and beyond).

-   Nu views data as either structured or unstructured. It is a structured shell like PowerShell.

-   Finally, Nu views data functionally. Rather than using mutation, pipelines act as a means to load, change, and save data without mutable state.

## Officially Supported By

Please submit an issue or PR to be added to this list.

-   [zoxide](https://github.com/ajeetdsouza/zoxide)
-   [starship](https://github.com/starship/starship)
-   [oh-my-posh](https://ohmyposh.dev)
-   [Couchbase Shell](https://couchbase.sh)
-   [virtualenv](https://github.com/pypa/virtualenv)
-   [atuin](https://github.com/ellie/atuin)
-   [clap](https://github.com/clap-rs/clap/tree/master/clap_complete_nushell)
-   [Dorothy](http://github.com/bevry/dorothy)
-   [Direnv](https://github.com/direnv/direnv/blob/master/docs/hook.md#nushell)
-   [x-cmd](https://x-cmd.com/mod/nu)
-   [vfox](https://github.com/version-fox/vfox)
-   [Windmill](https://www.windmill.dev/docs/getting_started/scripts_quickstart/bash)

## Contributing

See [Contributing](CONTRIBUTING.md) for details. Thanks to all the people who already contributed!

&lt;a href=&quot;https://github.com/nushell/nushell/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=nushell/nushell&amp;max=750&amp;columns=20&quot; /&gt;
&lt;/a&gt;

## License

The project is made available under the MIT license. See the `LICENSE` file for more information.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[fish-shell/fish-shell]]></title>
            <link>https://github.com/fish-shell/fish-shell</link>
            <guid>https://github.com/fish-shell/fish-shell</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[The user-friendly command line shell.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fish-shell/fish-shell">fish-shell/fish-shell</a></h1>
            <p>The user-friendly command line shell.</p>
            <p>Language: Rust</p>
            <p>Stars: 31,578</p>
            <p>Forks: 2,168</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[MystenLabs/sui]]></title>
            <link>https://github.com/MystenLabs/sui</link>
            <guid>https://github.com/MystenLabs/sui</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Sui, a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the Move programming language]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/MystenLabs/sui">MystenLabs/sui</a></h1>
            <p>Sui, a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the Move programming language</p>
            <p>Language: Rust</p>
            <p>Stars: 7,467</p>
            <p>Forks: 11,675</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/MystenLabs/sui/refs/heads/main/docs/site/static/img/logo.svg&quot; alt=&quot;Logo&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;
&lt;/p&gt;

# Welcome to Sui

[![Github release](https://img.shields.io/github/v/release/MystenLabs/sui.svg?sort=semver)](https://github.com/MystenLabs/sui/releases/latest)
[![License](https://img.shields.io/github/license/MystenLabs/sui)](https://github.com/MystenLabs/sui/blob/main/LICENSE)

[Sui](https://sui.io) is a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the [Move programming language](https://github.com/MystenLabs/awesome-move).

## Sui Highlights

Sui offers the following benefits and capabilities:

 * Unmatched scalability, instant settlement
 * A safe smart contract language accessible to mainstream developers
 * Ability to define rich and composable on-chain assets
 * Better user experience for web3 apps

Sui is the only blockchain today that can scale with the growth of web3 while achieving industry-leading performance, cost, programmability, and usability. Sui demonstrates capacity beyond the transaction processing capabilities of established systems ‚Äì traditional and blockchain alike. Sui is the first internet-scale programmable blockchain platform, a foundational layer for web3.

## Sui Architecture

```mermaid
flowchart LR
    CC(CLI Client) --&gt; ClientService
    RC(Rest Client) --&gt; ClientService
    RPCC(RPC Client) --&gt; ClientService
    ClientService --&gt; AuthorityAggregator
    AuthorityAggregator --&gt; AC1[AuthorityClient] &amp; AC2[AuthorityClient]
    subgraph Authority1
      AS[AuthorityState]
    end
    subgraph Authority2
      AS2[AuthorityState]
    end
    AC1 &lt;==&gt;|Network TCP| Authority1
    AC2 &lt;==&gt;|Network TCP| Authority2
```

## Sui Overview

Sui is a smart contract platform maintained by a permissionless set of authorities that play a role similar to validators or miners in other blockchain systems.

Sui offers scalability and unprecedented low-latency for common use cases. Sui makes the vast majority of transactions processable in parallel, which makes better use of processing resources, and offers the option to increase throughput with more resources. Sui forgoes consensus to instead use simpler and lower-latency primitives for common use cases, such as payment transactions and asset transfers. This is unprecedented in the blockchain world and enables a number of new latency-sensitive distributed applications, ranging from gaming to retail payment at physical points of sale.

Sui is written in [Rust](https://www.rust-lang.org) and supports smart contracts written in the [Move programming language](https://github.com/move-language/move) to define assets that may have an owner. Move programs define operations on these assets including custom rules for their creation, the transfer of these assets to new owners, and operations that mutate assets.

Sui has a native token called SUI, with a fixed supply. The SUI token is used to pay for gas, and is also used as [delegated stake on authorities](https://learn.bybit.com/blockchain/delegated-proof-of-stake-dpos/) within an epoch. The voting power of authorities within this epoch is a function of this delegated stake. Authorities are periodically reconfigured according to the stake delegated to them. In any epoch, the set of authorities is [Byzantine fault tolerant](https://pmg.csail.mit.edu/papers/osdi99.pdf). At the end of the epoch, fees collected through all transactions processed are distributed to authorities according to their contribution to the operation of the system. Authorities can in turn share some of the fees as rewards to users that delegated stakes to them.

Sui is supported by several cutting-edge [peer-reviewed studies](https://github.com/MystenLabs/sui/blob/main/docs/content/concepts/research-papers.mdx) and extensive years of open-source development.

## More About Sui

Use the following links to learn more about Sui and the Sui ecosystem:

 * Learn more about working with Sui in the [Sui Documentation](https://docs.sui.io/).
 * Join the Sui community on [Sui Discord](https://discord.gg/sui).
 * Find out more about the Sui ecosystem on the [Sui Resources](https://sui.io/resources/) page.
 * Review information about Sui governance, [decentralization](https://suifoundation.org/decentralization), and [Developer Grants Program](https://sui.io/grants-hub) on the [Sui Foundation](https://sui.io/about) site.


 ## How to Contribute

 See the [Contributing Guide](CONTRIBUTING.md) for details on how to contribute to Sui.

 ## Code of Conduct

 See the [Code of Conduct](CODE_OF_CONDUCT.MD) for details on our code of conduct.

 ## License

 See the [LICENSE](LICENSE) file for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[Schniz/fnm]]></title>
            <link>https://github.com/Schniz/fnm</link>
            <guid>https://github.com/Schniz/fnm</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[üöÄ Fast and simple Node.js version manager, built in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Schniz/fnm">Schniz/fnm</a></h1>
            <p>üöÄ Fast and simple Node.js version manager, built in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 22,678</p>
            <p>Forks: 590</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  Fast Node Manager (&lt;code&gt;fnm&lt;/code&gt;)
  &lt;img alt=&quot;Amount of downloads&quot; src=&quot;https://img.shields.io/github/downloads/Schniz/fnm/total.svg?style=flat&quot; /&gt;
  &lt;a href=&quot;https://github.com/Schniz/fnm/actions&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/Schniz/fnm/rust.yml?branch=master&amp;label=workflow&quot; alt=&quot;GitHub Actions workflow status&quot; /&gt;&lt;/a&gt;
&lt;/h1&gt;

&gt; üöÄ Fast and simple Node.js version manager, built in Rust

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/fnm.svg&quot; alt=&quot;Blazing fast!&quot;&gt;
&lt;/div&gt;

## Features

üåé Cross-platform support (macOS, Windows, Linux)

‚ú® Single file, easy installation, instant startup

üöÄ Built with speed in mind

üìÇ Works with `.node-version` and `.nvmrc` files

## Installation

### Using a script (macOS/Linux)

For `bash`, `zsh` and `fish` shells, there&#039;s an [automatic installation script](./.ci/install.sh).

First ensure that `curl` and `unzip` are already installed on your operating system. Then execute:

```sh
curl -fsSL https://fnm.vercel.app/install | bash
```

#### Upgrade

On macOS, it is as simple as `brew upgrade fnm`.

On other operating systems, upgrading `fnm` is almost the same as installing it. To prevent duplication in your shell config file, pass `--skip-shell` to the install command:

```sh
curl -fsSL https://fnm.vercel.app/install | bash -s -- --skip-shell
```

#### Parameters

`--install-dir`

Set a custom directory for fnm to be installed. The default is `$XDG_DATA_HOME/fnm` (if `$XDG_DATA_HOME` is not defined it falls back to `$HOME/.local/share/fnm` on linux and `$HOME/Library/Application Support/fnm` on MacOS).

&gt; **Note:** On macOS, this option is only meaningful when using `--force-install` since Homebrew is the default installation method.

`--skip-shell`

Skip appending shell specific loader to shell config file, based on the current user shell, defined in `$SHELL`. e.g. for Bash, `$HOME/.bashrc`. `$HOME/.zshrc` for Zsh. For Fish - `$HOME/.config/fish/conf.d/fnm.fish`

`--force-install`

macOS installations using the installation script are deprecated in favor of the Homebrew formula, but this forces the script to install using it anyway.

Example:

```sh
curl -fsSL https://fnm.vercel.app/install | bash -s -- --install-dir &quot;./.fnm&quot; --skip-shell
```

### Manually

#### Using Homebrew (macOS/Linux)

```sh
brew install fnm
```

Then, [set up your shell for fnm](#shell-setup)

#### Using Winget (Windows)

```sh
winget install Schniz.fnm
```

#### Using Scoop (Windows)

```sh
scoop install fnm
```

Then, [set up your shell for fnm](#shell-setup)

#### Using Chocolatey (Windows)

```sh
choco install fnm
```

Then, [set up your shell for fnm](#shell-setup)

#### Using Cargo (Linux/macOS/Windows)

```sh
cargo install fnm
```

Then, [set up your shell for fnm](#shell-setup)

#### Using a release binary (Linux/macOS/Windows)

- Download the [latest release binary](https://github.com/Schniz/fnm/releases) for your system
- Make it available globally on `PATH` environment variable
- [Set up your shell for fnm](#shell-setup)

### Removing

To remove fnm (üò¢), just delete the `.fnm` folder in your home directory. You should also edit your shell configuration to remove any references to fnm (ie. read [Shell Setup](#shell-setup), and do the opposite).

## Completions

fnm ships its completions with the binary:

```sh
fnm completions --shell &lt;SHELL&gt;
```

Where `&lt;SHELL&gt;` can be one of the supported shells:

- `bash`
- `zsh`
- `fish`
- `powershell`

Please follow your shell instructions to install them.

### Shell Setup

Environment variables need to be setup before you can start using fnm.
This is done by evaluating the output of `fnm env`.

&gt; [!NOTE]
&gt; Check out the [Configuration](./docs/configuration.md) section to enable highly
&gt; recommended features, like automatic version switching.

Adding a `.node-version` to your project is as simple as:

```bash
$ node --version
v14.18.3
$ node --version &gt; .node-version
```

Check out the following guides for the shell you use:

#### Bash

Add the following to your `.bashrc` profile:

```bash
eval &quot;$(fnm env --use-on-cd --shell bash)&quot;
```

#### Zsh

Add the following to your `.zshrc` profile:

```zsh
eval &quot;$(fnm env --use-on-cd --shell zsh)&quot;
```

#### Fish shell

Create `~/.config/fish/conf.d/fnm.fish` and add this line to it:

```fish
fnm env --use-on-cd --shell fish | source
```

#### PowerShell

Add the following to the end of your profile file:

```powershell
fnm env --use-on-cd --shell powershell | Out-String | Invoke-Expression
```

- For macOS/Linux, the profile is located at `~/.config/powershell/Microsoft.PowerShell_profile.ps1`
- For Windows location is either:
  - `%userprofile%\Documents\WindowsPowerShell\Microsoft.PowerShell_profile.ps1` Powershell 5
  - `%userprofile%\Documents\PowerShell\Microsoft.PowerShell_profile.ps1` Powershell 6+
- To create the profile file you can run this in PowerShell:
  ```powershell
  if (-not (Test-Path $profile)) { New-Item $profile -Force }
  ```
- To edit your profile run this in PowerShell:
  ```powershell
  Invoke-Item $profile
  ```

#### Windows Command Prompt aka Batch aka WinCMD

fnm is also supported but is not entirely covered. You can set up a startup script for [cmd.exe]( https://superuser.com/a/144348) or [Windows Terminal](https://superuser.com/a/1855283) and append the following lines:

```batch
@echo off
:: for /F will launch a new instance of cmd so we create a guard to prevent an infnite loop
if not defined FNM_AUTORUN_GUARD (
    set &quot;FNM_AUTORUN_GUARD=AutorunGuard&quot;
    FOR /f &quot;tokens=*&quot; %%z IN (&#039;fnm env --use-on-cd&#039;) DO CALL %%z
)
```

#### Usage with Cmder

Usage is very similar to the normal WinCMD install, apart for a few tweaks to allow being called from the cmder startup script. The example **assumes** that the `CMDER_ROOT` environment variable is **set** to the **root directory** of your Cmder installation.
Then you can do something like this:

- Make a .cmd file to invoke it

```batch
:: %CMDER_ROOT%\bin\fnm_init.cmd
@echo off
FOR /f &quot;tokens=*&quot; %%z IN (&#039;fnm env --use-on-cd&#039;) DO CALL %%z
```

- Add it to the startup script

```batch
:: %CMDER_ROOT%\config\user_profile.cmd
call &quot;%CMDER_ROOT%\bin\fnm_init.cmd&quot;
```

You can replace `%CMDER_ROOT%` with any other convenient path too.

## [Configuration](./docs/configuration.md)

[See the available configuration options for an extended configuration documentation](./docs/configuration.md)

## [Usage](./docs/commands.md)

[See the available commands for an extended usage documentation](./docs/commands.md)

## Contributing

PRs welcome :tada:

### Developing:

```sh
# Install Rust
git clone https://github.com/Schniz/fnm.git
cd fnm/
cargo build
```

### Running Binary:

```sh
cargo run -- --help # Will behave like `fnm --help`
```

### Running Tests:

```sh
cargo test
```
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[influxdata/influxdb]]></title>
            <link>https://github.com/influxdata/influxdb</link>
            <guid>https://github.com/influxdata/influxdb</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Scalable datastore for metrics, events, and real-time analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/influxdb">influxdata/influxdb</a></h1>
            <p>Scalable datastore for metrics, events, and real-time analytics</p>
            <p>Language: Rust</p>
            <p>Stars: 30,826</p>
            <p>Forks: 3,668</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
 &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/influxdb-logo.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/influxdb-logo-dark.png&quot;&gt;
    &lt;img src=&quot;assets/influxdb-logo.png&quot; alt=&quot;InfluxDB Logo&quot; width=&quot;600&quot;&gt;
  &lt;/picture&gt;
 &lt;p&gt;
&lt;/div&gt;

InfluxDB Core is a database built to collect, process, transform, and store event and time series data. It is ideal for use cases that require real-time ingest and fast query response times to build user interfaces, monitoring, and automation solutions.

Common use cases include:

- Monitoring sensor data
- Server monitoring
- Application performance monitoring
- Network monitoring
- Financial market and trading analytics
- Behavioral analytics

InfluxDB is optimized for scenarios where near real-time data monitoring is essential and queries 
need to return quickly to support user experiences such as dashboards and interactive user interfaces.

InfluxDB 3 Core‚Äôs feature highlights include:

- Diskless architecture with object storage support (or local disk with no dependencies)
- Fast query response times (under 10ms for last-value queries, or 30ms for distinct metadata)
- Embedded Python VM for plugins and triggers
- Parquet file persistence
- Compatibility with InfluxDB 1.x and 2.x write APIs
- Compatability with InfluxDB 1.x query API (InfluxQL)
- SQL query engine with support for FlightSQL and HTTP query API

## Project Status

InfluxDB 3 Core is GA as of April 15, 2025! We plan to have monthly point releases for the following six months, with patch releases as needed. We will move to a quarterly cadence after that for 3-4 releases, after which we&#039;ll reevaluate our release schedule.

Join the [InfluxDB3 Discord](https://discord.gg/vZe2w2Ds8B) 
or the public channels below to share your feedback, feature requests, and bug reports.

See the [InfluxDB 3 Core &amp; Enterprise GA release announcement here](https://www.influxdata.com/blog/influxdb-3-oss-ga/) 
or dig into the [InfluxDB 3 getting started guide here](https://docs.influxdata.com/influxdb3/core/get-started/).

## Learn InfluxDB
[Documentation](https://docs.influxdata.com/) | [Community Forum](https://community.influxdata.com/) | [Community Slack](https://www.influxdata.com/slack/) | [Blog](https://www.influxdata.com/blog/) | [InfluxDB University](https://university.influxdata.com/) | [YouTube](https://www.youtube.com/@influxdata8893)

Try **InfluxDB Cloud** for free and get started fast with no local setup required. Click [here](https://cloud2.influxdata.com/signup) to start building your application on InfluxDB Cloud.


## Installation
We have nightly and versioned Docker images, Debian packages, RPM packages, and tarballs of InfluxDB available on the [InfluxData downloads page](https://portal.influxdata.com/downloads/). We also provide the InfluxDB command line interface (CLI) client as a separate binary available at the same location.

- For v1 installation, use the [main 1.x branch](https://github.com/influxdata/influxdb/tree/master-1.x) or [install InfluxDB OSS directly](https://docs.influxdata.com/influxdb/v1/introduction/install/#installing-influxdb-oss).
- For v2 installation, use the [main 2.x branch](https://github.com/influxdata/influxdb/tree/main-2.x).
- For InfluxDB 3 Core see the [InfluxDB 3 Core getting started guide](https://docs.influxdata.com/influxdb3/core/get-started/).
- For InfluxDB 3 Enterprise see the [InfluxDB 3 Enterprise getting started guide](https://docs.influxdata.com/influxdb3/enterprise/get-started/).

If you are interested in building from source, see the [building from source](CONTRIBUTING.md#building-from-source) guide for contributors.

To begin using InfluxDB, visit our [Getting Started with InfluxDB](https://docs.influxdata.com/influxdb/v1/introduction/get-started/) documentation.


## License
The open source software we build is licensed under the permissive MIT or Apache 2 licenses at the user&#039;s choosing. We‚Äôve long held the view that our open source code should be truly open and our commercial code should be separate and closed. 


## Interested in joining the team building InfluxDB?
Check out current job openings at [www.influxdata.com/careers](https://www.influxdata.com/careers) today!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustdesk/rustdesk]]></title>
            <link>https://github.com/rustdesk/rustdesk</link>
            <guid>https://github.com/rustdesk/rustdesk</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustdesk/rustdesk">rustdesk/rustdesk</a></h1>
            <p>An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.</p>
            <p>Language: Rust</p>
            <p>Stars: 102,573</p>
            <p>Forks: 15,060</p>
            <p>Stars today: 56 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;res/logo-header.svg&quot; alt=&quot;RustDesk - Your remote desktop&quot;&gt;&lt;br&gt;
  &lt;a href=&quot;#raw-steps-to-build&quot;&gt;Build&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#how-to-build-with-docker&quot;&gt;Docker&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#file-structure&quot;&gt;Structure&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#snapshot&quot;&gt;Snapshot&lt;/a&gt;&lt;br&gt;
  [&lt;a href=&quot;docs/README-UA.md&quot;&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href=&quot;docs/README-CS.md&quot;&gt;ƒçesky&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ZH.md&quot;&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href=&quot;docs/README-HU.md&quot;&gt;Magyar&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ES.md&quot;&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FA.md&quot;&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FR.md&quot;&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DE.md&quot;&gt;Deutsch&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PL.md&quot;&gt;Polski&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ID.md&quot;&gt;Indonesian&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FI.md&quot;&gt;Suomi&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ML.md&quot;&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href=&quot;docs/README-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NL.md&quot;&gt;Nederlands&lt;/a&gt;] | [&lt;a href=&quot;docs/README-IT.md&quot;&gt;Italiano&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PTBR.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href=&quot;docs/README-EO.md&quot;&gt;Esperanto&lt;/a&gt;] | [&lt;a href=&quot;docs/README-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href=&quot;docs/README-AR.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href=&quot;docs/README-VN.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DA.md&quot;&gt;Dansk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-GR.md&quot;&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href=&quot;docs/README-TR.md&quot;&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NO.md&quot;&gt;Norsk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RO.md&quot;&gt;Rom√¢nƒÉ&lt;/a&gt;]&lt;br&gt;
  &lt;b&gt;We need your help to translate this README, &lt;a href=&quot;https://github.com/rustdesk/rustdesk/tree/master/src/lang&quot;&gt;RustDesk UI&lt;/a&gt; and &lt;a href=&quot;https://github.com/rustdesk/doc.rustdesk.com&quot;&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt;
&lt;/p&gt;

&gt; [!Caution]
&gt; **Misuse Disclaimer:** &lt;br&gt;
&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.


Chat with us: [Discord](https://discord.gg/nDceKgxnkV) | [Twitter](https://twitter.com/rustdesk) | [Reddit](https://www.reddit.com/r/rustdesk) | [YouTube](https://www.youtube.com/@rustdesk)

[![RustDesk Server Pro](https://img.shields.io/badge/RustDesk%20Server%20Pro-Advanced%20Features-blue)](https://rustdesk.com/pricing.html)

Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, [set up your own](https://rustdesk.com/server), or [write your own rendezvous/relay server](https://github.com/rustdesk/rustdesk-server-demo).

![image](https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png)

RustDesk welcomes contribution from everyone. See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for help getting started.

[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)

[**BINARY DOWNLOAD**](https://github.com/rustdesk/rustdesk/releases)

[**NIGHTLY BUILD**](https://github.com/rustdesk/rustdesk/releases/tag/nightly)

[&lt;img src=&quot;https://f-droid.org/badge/get-it-on.png&quot;
    alt=&quot;Get it on F-Droid&quot;
    height=&quot;80&quot;&gt;](https://f-droid.org/en/packages/com.carriez.flutter_hbb)
[&lt;img src=&quot;https://flathub.org/api/badge?svg&amp;locale=en&quot;
    alt=&quot;Get it on Flathub&quot;
    height=&quot;80&quot;&gt;](https://flathub.org/apps/com.rustdesk.RustDesk)

## Dependencies

Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our [CI](https://github.com/rustdesk/rustdesk/blob/master/.github/workflows/flutter-build.yml) for building Flutter version.

Please download Sciter dynamic library yourself.

[Windows](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll) |
[Linux](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so) |
[macOS](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib)

## Raw Steps to build

- Prepare your Rust development env and C++ build env

- Install [vcpkg](https://github.com/microsoft/vcpkg), and set `VCPKG_ROOT` env variable correctly

  - Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static
  - Linux/macOS: vcpkg install libvpx libyuv opus aom

- run `cargo run`

## [Build](https://rustdesk.com/docs/en/dev/build/)

## How to Build on Linux

### Ubuntu 18 (Debian 10)

```sh
sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
```

### openSUSE Tumbleweed

```sh
sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
```

### Fedora 28 (CentOS 8)

```sh
sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
```

### Arch (Manjaro)

```sh
sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
```

### Install vcpkg

```sh
git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
```

### Fix libvpx (For Fedora)

```sh
cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i &#039;s/CFLAGS+=-I/CFLAGS+=-fPIC -I/g&#039; Makefile
sed -i &#039;s/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g&#039; Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
```

### Build

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
```

## How to build with Docker

Begin by cloning the repository and building the Docker container:

```sh
git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t &quot;rustdesk-builder&quot; .
```

Then, each time you need to build the application, run the following command:

```sh
docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=&quot;$(id -u)&quot; -e PGID=&quot;$(id -g)&quot; rustdesk-builder
```

Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the `&lt;OPTIONAL-ARGS&gt;` position. For instance, if you wanted to build an optimized release version, you would run the command above followed by `--release`. The resulting executable will be available in the target folder on your system, and can be run with:

```sh
target/debug/rustdesk
```

Or, if you&#039;re running a release executable:

```sh
target/release/rustdesk
```

Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as `install` or `run` are not currently supported via this method as they would install or run the program inside the container instead of the host.

## File Structure

- **[libs/hbb_common](https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common)**: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions
- **[libs/scrap](https://github.com/rustdesk/rustdesk/tree/master/libs/scrap)**: screen capture
- **[libs/enigo](https://github.com/rustdesk/rustdesk/tree/master/libs/enigo)**: platform specific keyboard/mouse control
- **[libs/clipboard](https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard)**: file copy and paste implementation for Windows, Linux, macOS.
- **[src/ui](https://github.com/rustdesk/rustdesk/tree/master/src/ui)**: obsolete Sciter UI (deprecated)
- **[src/server](https://github.com/rustdesk/rustdesk/tree/master/src/server)**: audio/clipboard/input/video services, and network connections
- **[src/client.rs](https://github.com/rustdesk/rustdesk/tree/master/src/client.rs)**: start a peer connection
- **[src/rendezvous_mediator.rs](https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs)**: Communicate with [rustdesk-server](https://github.com/rustdesk/rustdesk-server), wait for remote direct (TCP hole punching) or relayed connection
- **[src/platform](https://github.com/rustdesk/rustdesk/tree/master/src/platform)**: platform specific code
- **[flutter](https://github.com/rustdesk/rustdesk/tree/master/flutter)**: Flutter code for desktop and mobile
- **[flutter/web/js](https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js)**: JavaScript for Flutter web client

## Screenshots

![Connection Manager](https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651)

![Connected to a Windows PC](https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea)

![File Transfer](https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad)

![TCP Tunneling](https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 72,923</p>
            <p>Forks: 2,232</p>
            <p>Stars today: 65 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- üöÄ A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`,
  and more.
- ‚ö°Ô∏è [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- üóÇÔ∏è Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- ‚ùáÔ∏è [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- üêç [Installs and manages](#python-versions) Python versions.
- üõ†Ô∏è [Runs and installs](#tools) tools published as Python packages.
- üî© Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a
  familiar CLI.
- üè¢ Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- üíæ Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- ‚è¨ Installable without Rust or Python via `curl` or `pip`.
- üñ•Ô∏è Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Platform support

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

## Versioning policy

See uv&#039;s [versioning policy](https://docs.astral.sh/uv/reference/versioning/) document.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv/blob/main/CONTRIBUTING.md) to get started.

## FAQ

#### How do you pronounce uv?

It&#039;s pronounced as &quot;you - vee&quot; ([`/juÀê viÀê/`](https://en.wikipedia.org/wiki/Help:IPA/English#Key))

#### How should I stylize uv?

Just &quot;uv&quot;, please. See the [style guide](./STYLE.md#styling-uv) for details.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[SeaQL/sea-orm]]></title>
            <link>https://github.com/SeaQL/sea-orm</link>
            <guid>https://github.com/SeaQL/sea-orm</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[üêö An async & dynamic ORM for Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/SeaQL/sea-orm">SeaQL/sea-orm</a></h1>
            <p>üêö An async & dynamic ORM for Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 8,955</p>
            <p>Forks: 627</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

  &lt;img alt=&quot;SeaORM&quot; src=&quot;https://www.sea-ql.org/blog/img/SeaORM 2.0 Banner.png&quot;/&gt;

  &lt;h1&gt;&lt;/h1&gt;
  &lt;h3&gt;SeaORM is a powerful ORM for building web services in Rust&lt;/h3&gt;

  [![crate](https://img.shields.io/crates/v/sea-orm.svg)](https://crates.io/crates/sea-orm)
  [![build status](https://github.com/SeaQL/sea-orm/actions/workflows/rust.yml/badge.svg)](https://github.com/SeaQL/sea-orm/actions/workflows/rust.yml)
  [![GitHub stars](https://img.shields.io/github/stars/SeaQL/sea-orm.svg?style=social&amp;label=Star&amp;maxAge=1)](https://github.com/SeaQL/sea-orm/stargazers/)
  &lt;br&gt;Support us with a ‚≠ê !

&lt;/div&gt;

# üêö SeaORM

[‰∏≠ÊñáÊñáÊ°£](https://github.com/SeaQL/sea-orm/blob/master/README-zh.md)

### Advanced Relations

Model complex relationships 1-1, 1‚ÄëN, M‚ÄëN, and even self‚Äëreferential in a high-level, conceptual way.

### Familiar Concepts

Inspired by popular ORMs in the Python, Ruby, and Node.js ecosystem, SeaORM offers a developer experience that feels instantly recognizable.

### Feature Rich

SeaORM is a batteries-included ORM with filters, pagination, and nested queries to accelerate building REST, GraphQL, and gRPC APIs.

### Production Ready

With 250k+ weekly downloads, SeaORM is production-ready, trusted by startups and enterprises worldwide.

## Getting Started

[![Discord](https://img.shields.io/discord/873880840487206962?label=Discord)](https://discord.com/invite/uCPdDXzbdv)
Join our Discord server to chat with others!

+ [Documentation](https://www.sea-ql.org/SeaORM)

Integration examples:

+ [Actix Example](https://github.com/SeaQL/sea-orm/tree/master/examples/actix_example)
+ [Axum Example](https://github.com/SeaQL/sea-orm/tree/master/examples/axum_example)
+ [GraphQL Example](https://github.com/SeaQL/sea-orm/tree/master/examples/graphql_example)
+ [jsonrpsee Example](https://github.com/SeaQL/sea-orm/tree/master/examples/jsonrpsee_example)
+ [Loco Example](https://github.com/SeaQL/sea-orm/tree/master/examples/loco_example) / [Loco REST Starter](https://github.com/SeaQL/sea-orm/tree/master/examples/loco_starter)
+ [Poem Example](https://github.com/SeaQL/sea-orm/tree/master/examples/poem_example)
+ [Rocket Example](https://github.com/SeaQL/sea-orm/tree/master/examples/rocket_example) / [Rocket OpenAPI Example](https://github.com/SeaQL/sea-orm/tree/master/examples/rocket_okapi_example)
+ [Salvo Example](https://github.com/SeaQL/sea-orm/tree/master/examples/salvo_example)
+ [Tonic Example](https://github.com/SeaQL/sea-orm/tree/master/examples/tonic_example)
+ [Seaography Example (Bakery)](https://github.com/SeaQL/sea-orm/tree/master/examples/seaography_example) / [Seaography Example (Sakila)](https://github.com/SeaQL/seaography/tree/main/examples/sqlite)

If you want a simple, clean example that fits in a single file that demonstrates the best of SeaORM, you can try:
+ [Quickstart](https://github.com/SeaQL/sea-orm/blob/master/examples/quickstart/src/main.rs)

Let&#039;s have a quick walk through of the unique features of SeaORM.

## Expressive Entity format
You don&#039;t have to write this by hand! Entity files can be generated from an existing database using `sea-orm-cli`,
following is generated with `--entity-format dense` *(new in 2.0)*.
```rust
mod user {
    use sea_orm::entity::prelude::*;

    #[sea_orm::model]
    #[derive(Clone, Debug, PartialEq, Eq, DeriveEntityModel)]
    #[sea_orm(table_name = &quot;user&quot;)]
    pub struct Model {
        #[sea_orm(primary_key)]
        pub id: i32,
        pub name: String,
        #[sea_orm(unique)]
        pub email: String,
        #[sea_orm(has_one)]
        pub profile: HasOne&lt;super::profile::Entity&gt;,
        #[sea_orm(has_many)]
        pub posts: HasMany&lt;super::post::Entity&gt;,
    }
}
mod post {
    use sea_orm::entity::prelude::*;

    #[sea_orm::model]
    #[derive(Clone, Debug, PartialEq, Eq, DeriveEntityModel)]
    #[sea_orm(table_name = &quot;post&quot;)]
    pub struct Model {
        #[sea_orm(primary_key)]
        pub id: i32,
        pub user_id: i32,
        pub body: String,
        #[sea_orm(belongs_to, from = &quot;user_id&quot;, to = &quot;id&quot;)]
        pub author: HasOne&lt;super::user::Entity&gt;,
        #[sea_orm(has_many, via = &quot;post_tag&quot;)] // M-N relation with junction
        pub tags: HasMany&lt;super::tag::Entity&gt;,
    }
}
```

## Smart Entity Loader
The Entity Loader intelligently uses join for 1-1 and data loader for 1-N relations,
eliminating the N+1 problem even when performing nested queries.
```rust
// join paths:
// user -&gt; profile
// user -&gt; post
//         post -&gt; post_tag -&gt; tag
let smart_user = user::Entity::load()
    .filter_by_id(42) // shorthand for .filter(user::COLUMN.id.eq(42))
    .with(profile::Entity) // 1-1 uses join
    .with((post::Entity, tag::Entity)) // 1-N uses data loader
    .one(db)
    .await?
    .unwrap();

// 3 queries are executed under the hood:
// 1. SELECT FROM user JOIN profile WHERE id = $
// 2. SELECT FROM post WHERE user_id IN (..)
// 3. SELECT FROM tag JOIN post_tag WHERE post_id IN (..)

smart_user
    == user::ModelEx {
        id: 42,
        name: &quot;Bob&quot;.into(),
        email: &quot;bob@sea-ql.org&quot;.into(),
        profile: HasOne::Loaded(
            profile::ModelEx {
                picture: &quot;image.jpg&quot;.into(),
            }
            .into(),
        ),
        posts: HasMany::Loaded(vec![post::ModelEx {
            title: &quot;Nice weather&quot;.into(),
            tags: HasMany::Loaded(vec![tag::ModelEx {
                tag: &quot;diary&quot;.into(),
            }]),
        }]),
    };
```

## Schema first or Entity first? Your choice

SeaORM provides a powerful migration system that lets you create tables, modify schemas, and seed data with ease.

With SeaORM 2.0, you also get a first-class [Entity First Workflow](https://www.sea-ql.org/blog/2025-10-30-sea-orm-2.0/):
simply define new entities or add columns to existing ones,
and SeaORM will automatically detect the changes and create the new tables, columns, unique keys, and foreign keys.

```rust
// SeaORM resolves foreign key dependencies and creates the tables in topological order.
// Requires the `entity-registry` and `schema-sync` feature flags.
db.get_schema_registry(&quot;my_crate::entity::*&quot;).sync(db).await;
```

## Ergonomic Raw SQL

Let SeaORM handle 95% of your transactional queries.
For the remaining cases that are too complex to express,
SeaORM still offers convenient support for writing raw SQL.
```rust
let user = Item { name: &quot;Bob&quot; }; // nested parameter access
let ids = [2, 3, 4]; // expanded by the `..` operator

let user: Option&lt;user::Model&gt; = user::Entity::find()
    .from_raw_sql(raw_sql!(
        Sqlite,
        r#&quot;SELECT &quot;id&quot;, &quot;name&quot; FROM &quot;user&quot;
           WHERE &quot;name&quot; LIKE {user.name}
           AND &quot;id&quot; in ({..ids})
        &quot;#
    ))
    .one(db)
    .await?;
```

## Basics

### Select
SeaORM models 1-N and M-N relationships at the Entity level,
letting you traverse many-to-many links through a junction table in a single call.
```rust
// find all models
let cakes: Vec&lt;cake::Model&gt; = Cake::find().all(db).await?;

// find and filter
let chocolate: Vec&lt;cake::Model&gt; = Cake::find()
    .filter(Cake::COLUMN.name.contains(&quot;chocolate&quot;))
    .all(db)
    .await?;

// find one model
let cheese: Option&lt;cake::Model&gt; = Cake::find_by_id(1).one(db).await?;
let cheese: cake::Model = cheese.unwrap();

// find related models (lazy)
let fruit: Option&lt;fruit::Model&gt; = cheese.find_related(Fruit).one(db).await?;

// find related models (eager): for 1-1 relations
let cake_with_fruit: Vec&lt;(cake::Model, Option&lt;fruit::Model&gt;)&gt; =
    Cake::find().find_also_related(Fruit).all(db).await?;

// find related models (eager): works for both 1-N and M-N relations
let cake_with_fillings: Vec&lt;(cake::Model, Vec&lt;filling::Model&gt;)&gt; = Cake::find()
    .find_with_related(Filling) // for M-N relations, two joins are performed
    .all(db) // rows are automatically consolidated by left entity
    .await?;
```
### Nested Select

Partial models prevent overfetching by letting you querying only the fields
you need; it also makes writing deeply nested relational queries simple.
```rust
use sea_orm::DerivePartialModel;

#[derive(DerivePartialModel)]
#[sea_orm(entity = &quot;cake::Entity&quot;)]
struct CakeWithFruit {
    id: i32,
    name: String,
    #[sea_orm(nested)]
    fruit: Option&lt;fruit::Model&gt;, // this can be a regular or another partial model
}

let cakes: Vec&lt;CakeWithFruit&gt; = Cake::find()
    .left_join(fruit::Entity) // no need to specify join condition
    .into_partial_model() // only the columns in the partial model will be selected
    .all(db)
    .await?;
```

### Insert
SeaORM&#039;s ActiveModel lets you work directly with Rust data structures and
persist them through a simple API.
It&#039;s easy to insert large batches of rows from different data sources.
```rust
let apple = fruit::ActiveModel {
    name: Set(&quot;Apple&quot;.to_owned()),
    ..Default::default() // no need to set primary key
};

let pear = fruit::ActiveModel {
    name: Set(&quot;Pear&quot;.to_owned()),
    ..Default::default()
};

// insert one: Active Record style
let apple = apple.insert(db).await?;
apple.id == 1;

// insert one: repository style
let result = Fruit::insert(apple).exec(db).await?;
result.last_insert_id == 1;

// insert many returning last insert id
let result = Fruit::insert_many([apple, pear]).exec(db).await?;
result.last_insert_id == Some(2);
```

### Insert (advanced)
You can take advantage of database specific features to perform upsert and idempotent insert.
```rust
// insert many with returning (if supported by database)
let models: Vec&lt;fruit::Model&gt; = Fruit::insert_many([apple, pear])
    .exec_with_returning(db)
    .await?;
models[0]
    == fruit::Model {
        id: 1, // database assigned value
        name: &quot;Apple&quot;.to_owned(),
        cake_id: None,
    };

// insert with ON CONFLICT on primary key do nothing, with MySQL specific polyfill
let result = Fruit::insert_many([apple, pear])
    .on_conflict_do_nothing()
    .exec(db)
    .await?;

matches!(result, TryInsertResult::Conflicted);
```

### Update
ActiveModel avoids race conditions by updating only the fields you&#039;ve changed,
never overwriting untouched columns.
You can also craft complex bulk update queries with a fluent query building API.
```rust
use sea_orm::sea_query::{Expr, Value};

let pear: Option&lt;fruit::Model&gt; = Fruit::find_by_id(1).one(db).await?;
let mut pear: fruit::ActiveModel = pear.unwrap().into();

pear.name = Set(&quot;Sweet pear&quot;.to_owned()); // update value of a single field

// update one: only changed columns will be updated
let pear: fruit::Model = pear.update(db).await?;

// update many: UPDATE &quot;fruit&quot; SET &quot;cake_id&quot; = &quot;cake_id&quot; + 2
//               WHERE &quot;fruit&quot;.&quot;name&quot; LIKE &#039;%Apple%&#039;
Fruit::update_many()
    .col_expr(fruit::COLUMN.cake_id, fruit::COLUMN.cake_id.add(2))
    .filter(fruit::COLUMN.name.contains(&quot;Apple&quot;))
    .exec(db)
    .await?;
```
### Save
You can perform &quot;insert or update&quot; operation with ActiveModel, making it easy to compose transactional operations.
```rust
let banana = fruit::ActiveModel {
    id: NotSet,
    name: Set(&quot;Banana&quot;.to_owned()),
    ..Default::default()
};

// create, because primary key `id` is `NotSet`
let mut banana = banana.save(db).await?;

banana.id == Unchanged(2);
banana.name = Set(&quot;Banana Mongo&quot;.to_owned());

// update, because primary key `id` is present
let banana = banana.save(db).await?;
```
### Delete
The same ActiveModel API consistent with insert and update.
```rust
// delete one: Active Record style
let orange: Option&lt;fruit::Model&gt; = Fruit::find_by_id(1).one(db).await?;
let orange: fruit::Model = orange.unwrap();
orange.delete(db).await?;

// delete one: repository style
let orange = fruit::ActiveModel {
    id: Set(2),
    ..Default::default()
};
fruit::Entity::delete(orange).exec(db).await?;

// delete many: DELETE FROM &quot;fruit&quot; WHERE &quot;fruit&quot;.&quot;name&quot; LIKE &#039;%Orange%&#039;
fruit::Entity::delete_many()
    .filter(fruit::COLUMN.name.contains(&quot;Orange&quot;))
    .exec(db)
    .await?;

```
### Raw SQL Query
The `raw_sql!` macro is like the `format!` macro but without the risk of SQL injection.
It supports nested parameter interpolation, array and tuple expansion, and even repeating group,
offering great flexibility in crafting complex queries.

```rust
#[derive(FromQueryResult)]
struct CakeWithBakery {
    name: String,
    #[sea_orm(nested)]
    bakery: Option&lt;Bakery&gt;,
}

#[derive(FromQueryResult)]
struct Bakery {
    #[sea_orm(alias = &quot;bakery_name&quot;)]
    name: String,
}

let cake_ids = [2, 3, 4]; // expanded by the `..` operator

// can use many APIs with raw SQL, including nested select
let cake: Option&lt;CakeWithBakery&gt; = CakeWithBakery::find_by_statement(raw_sql!(
    Sqlite,
    r#&quot;SELECT &quot;cake&quot;.&quot;name&quot;, &quot;bakery&quot;.&quot;name&quot; AS &quot;bakery_name&quot;
       FROM &quot;cake&quot;
       LEFT JOIN &quot;bakery&quot; ON &quot;cake&quot;.&quot;bakery_id&quot; = &quot;bakery&quot;.&quot;id&quot;
       WHERE &quot;cake&quot;.&quot;id&quot; IN ({..cake_ids})&quot;#
))
.one(db)
.await?;
```

## üß≠ Seaography: instant GraphQL API

[Seaography](https://github.com/SeaQL/seaography) is a GraphQL framework built for SeaORM.
Seaography allows you to build GraphQL resolvers quickly.
With just a few commands, you can launch a fullly-featured GraphQL server from SeaORM entities,
complete with filter, pagination, relational queries and mutations!

Look at the [Seaography Example](https://github.com/SeaQL/sea-orm/tree/master/examples/seaography_example) to learn more.

&lt;img src=&quot;https://raw.githubusercontent.com/SeaQL/sea-orm/master/examples/seaography_example/Seaography%20example.png&quot;/&gt;

## üñ•Ô∏è SeaORM Pro: Professional Admin Panel

[SeaORM Pro](https://github.com/SeaQL/sea-orm-pro/) is an admin panel solution allowing you to quickly and easily launch an admin panel for your application - frontend development skills not required, but certainly nice to have!

SeaORM Pro has been updated to support the latest features in SeaORM 2.0.

Features:

+ Full CRUD
+ Built on React + GraphQL
+ Built-in GraphQL resolver
+ Customize the UI with TOML config
+ Role Based Access Control *(new in 2.0)*

Read the [Getting Started](https://www.sea-ql.org/sea-orm-pro/docs/install-and-config/getting-started/) guide to learn more.

![](https://raw.githubusercontent.com/SeaQL/sea-orm/refs/heads/master/docs/sea-orm-pro-dark.png#gh-dark-mode-only)
![](https://raw.githubusercontent.com/SeaQL/sea-orm/refs/heads/master/docs/sea-orm-pro-light.png#gh-light-mode-only)

## SQL Server Support

[SQL Server for SeaORM](https://www.sea-ql.org/SeaORM-X/) offers the same SeaORM API for MSSQL. We ported all test cases and examples, complemented by MSSQL specific documentation. If you are building enterprise software, you can [request commercial access](https://forms.office.com/r/1MuRPJmYBR). It is currently based on SeaORM 1.0, but we will offer free upgrade to existing users when SeaORM 2.0 is finalized.

## Releases

SeaORM 2.0 has reached its release candidate phase. We&#039;d love for you to try it out and help shape the final release by [sharing your feedback](https://github.com/SeaQL/sea-orm/discussions/).

+ [Change Log](https://github.com/SeaQL/sea-orm/tree/master/CHANGELOG.md)

SeaORM 2.0 is shaping up to be our most significant release yet - with a few breaking changes, plenty of enhancements, and a clear focus on developer experience.

+ [A Sneak Peek at SeaORM 2.0](https://www.sea-ql.org/blog/2025-09-16-sea-orm-2.0/)
+ [SeaORM 2.0: A closer look](https://www.sea-ql.org/blog/2025-09-24-sea-orm-2.0/)
+ [Role Based Access Control in SeaORM 2.0](https://www.sea-ql.org/blog/2025-09-30-sea-orm-rbac/)
+ [Seaography 2.0: A Powerful and Extensible GraphQL Framework](https://www.sea-ql.org/blog/2025-10-08-seaography/)
+ [SeaORM 2.0: New Entity Format](https://www.sea-ql.org/blog/2025-10-20-sea-orm-2.0/)
+ [SeaORM 2.0: Entity First Workflow](https://www.sea-ql.org/blog/2025-10-30-sea-orm-2.0/)
+ [SeaORM 2.0: Strongly-Typed Column](https://www.sea-ql.org/blog/2025-11-11-sea-orm-2.0/)

If you make extensive use of SeaQuery, we recommend checking out our blog post on SeaQuery 1.0 release:

+ [The road to SeaQuery 1.0](https://www.sea-ql.org/blog/2025-08-30-sea-query-1.0/)

## License

Licensed under either of

-   Apache License, Version 2.0
    ([LICENSE-APACHE](LICENSE-APACHE) or &lt;http://www.apache.org/licenses/LICENSE-2.0&gt;)
-   MIT license
    ([LICENSE-MIT](LICENSE-MIT) or &lt;http://opensource.org/licenses/MIT&gt;)

at your option.

## Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.

We invite you to participate, contribute and together help build Rust&#039;s future.

A big shout out to our contributors!

[![Contributors](https://opencollective.com/sea-orm/contributors.svg?width=1000&amp;button=false)](https://github.com/SeaQL/sea-orm/graphs/contributors)

## Who&#039;s using SeaORM?

Here is a short list of awesome open source software built with SeaORM. Feel free to [submit yours](https://github.com/SeaQL/sea-orm/blob/master/COMMUNITY.md#built-with-seaorm)!

| Project | GitHub | Tagline |
|---------|--------|---------|
| [Zed](https://github.com/zed-industries/zed) | ![GitHub stars](https://img.shields.io/github/stars/zed-industries/zed.svg?style=social) | A high-performance, multiplayer code editor |
| [OpenObserve](https://github.com/openobserve/openobserve) | ![GitHub stars](https://img.shields.io/github/stars/openobserve/openobserve.svg?style=social) | Open-source observability platform |
| [RisingWave](https://github.com/risingwavelabs/risingwave) | ![GitHub stars](https://img.shields.io/github/stars/risingwavelabs/risingwave.svg?style=social) | Stream processing and management platform |
| [LLDAP](https://github.com/nitnelave/lldap) | ![GitHub stars](https://img.shields.io/github/stars/nitnelave/lldap.svg?style=social) | A light LDAP server for user management |
| [Warpgate](https://github.com/warp-tech/warpgate) | ![GitHub stars](https://img.shields.io/github/stars/warp-tech/warpgate.svg?style=social) | Smart SSH bastion that works with any SSH client |
| [Svix](https://github.com/svix/svix-webhooks) | ![GitHub stars](https://img.shields.io/github/stars/svix/svix-webhooks.svg?style=social) | The enterprise ready webhooks service |
| [Ryot](https://github.com/IgnisDa/ryot) | ![GitHub stars](https://img.shields.io/github/stars/ignisda/ryot.svg?style=social) | The only self hosted tracker you will ever need |
| [Lapdev](https://github.com/lapce/lapdev) | ![GitHub stars](https://img.shields.io/github/stars/lapce/lapdev.svg?style=social) | Self-hosted remote development enviroment |
| [System Initiative](https://github.com/systeminit/si) | ![GitHub stars](https://img.shields.io/github/stars/systeminit/si.svg?style=social) | DevOps Automation Platform |
| [OctoBase](https://github.com/toeverything/OctoBase) | ![GitHub stars](https://img.shields.io/github/stars/toeverything/OctoBase.svg?style=social) | A light-weight, scalable, offline collaborative data backend |

## Sponsorship

[SeaQL.org](https://www.sea-ql.org/) is an independent open-source organization run by passionate developers.
If you feel generous, a small donation via [GitHub Sponsor](https://github.com/sponsors/SeaQL) will be greatly appreciated, and goes a long way towards sustaining the organization.

### Gold Sponsors

&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://qdx.co/&quot;&gt;
  &lt;img src=&quot;https://www.sea-ql.org/static/sponsors/QDX.svg&quot; width=&quot;138&quot;/&gt;
&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;&lt;/table&gt;

[QDX](https://qdx.co/) pioneers quantum dynamics-powered drug discovery, leveraging AI and supercomputing to accelerate molecular modeling.
We&#039;re immensely grateful to QDX for sponsoring the development of SeaORM, the SQL toolkit that powers their data intensive applications.

### Silver Sponsors

We&#039;re grateful to our silver sponsors: Digital Ocean, for sponsoring our servers. And JetBrains, for sponsoring our IDE.

&lt;table&gt;&lt;tr&gt;
&lt;td&gt;&lt;a href=&quot;https://www.digitalocean.com/&quot;&gt;
  &lt;img src=&quot;https://www.sea-ql.org/static/sponsors/DigitalOcean.svg&quot; width=&quot;125&quot;&gt;
&lt;/a&gt;&lt;/td&gt;

&lt;td&gt;&lt;a href=&quot;https://www.jet

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ankitects/anki]]></title>
            <link>https://github.com/ankitects/anki</link>
            <guid>https://github.com/ankitects/anki</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[Anki is a smart spaced repetition flashcard program]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ankitects/anki">ankitects/anki</a></h1>
            <p>Anki is a smart spaced repetition flashcard program</p>
            <p>Language: Rust</p>
            <p>Stars: 24,749</p>
            <p>Forks: 2,597</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># Anki¬Æ

[![Build status](https://badge.buildkite.com/c9edf020a4aec976f9835e54751cc5409d843adbb66d043bd3.svg?branch=main)](https://buildkite.com/ankitects/anki-ci)

This repo contains the source code for the computer version of
[Anki](https://apps.ankiweb.net).

# About

Anki is a spaced repetition program. Please see the [website](https://apps.ankiweb.net) to learn more.

# Getting Started

### Anki Betas

If you&#039;d like to try development builds of Anki but don&#039;t feel comfortable
building the code, please see [Anki betas](https://betas.ankiweb.net/)

### Developing

For more information on building and developing, please see [Development](./docs/development.md).

### Contributing

Want to contribute to Anki? Check out the [Contribution Guidelines](./docs/contributing.md).

### Anki Contributors

[CONTRIBUTORS](./CONTRIBUTORS)

# License

Anki&#039;s license: [LICENSE](./LICENSE)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[regolith-labs/ore]]></title>
            <link>https://github.com/regolith-labs/ore</link>
            <guid>https://github.com/regolith-labs/ore</guid>
            <pubDate>Mon, 17 Nov 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[It's time to mine.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/regolith-labs/ore">regolith-labs/ore</a></h1>
            <p>It's time to mine.</p>
            <p>Language: Rust</p>
            <p>Stars: 754</p>
            <p>Forks: 265</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># ORE

ORE is a crypto mining protocol.


## API
- [`Consts`](api/src/consts.rs) ‚Äì¬†Program constants.
- [`Error`](api/src/error.rs) ‚Äì¬†Custom program errors.
- [`Event`](api/src/error.rs) ‚Äì¬†Custom program events.
- [`Instruction`](api/src/instruction.rs) ‚Äì¬†Declared instructions and arguments.

## Instructions

#### Mining
- [`Automate`](program/src/automate.rs) - Configures a new automation.
- [`Checkpoint`](program/src/checkpoint.rs) - Checkpoints rewards from an prior round.
- [`ClaimORE`](program/src/claim_ore.rs) - Claims ORE mining rewards.
- [`ClaimSOL`](program/src/claim_sol.rs) - Claims SOL mining rewards.
- [`Deploy`](program/src/deploy.rs) ‚Äì Deploys SOL to claim space on the board.
- [`Initialize`](program/src/initialize.rs) - Initializes program variables.
- [`Log`](program/src/log.rs) ‚Äì Logs non-truncatable event data.
- [`Reset`](program/src/reset.rs) - Resets the board for a new round.
- [`Reset`](program/src/reset.rs) - Resets the board for a new round.

#### Staking
- [`Deposit`](program/src/deposit.rs) - Deposits ORE into a stake account.
- [`Withdraw`](program/src/withdraw.rs) - Withdraws ORE from a stake account.
- [`ClaimSeeker`](program/src/claim_seeker.rs) - Claims a Seeker genesis token. 
- [`ClaimYield`](program/src/claim_yield.rs) - Claims staking yield.

#### Admin
- [`Bury`](program/src/bury.rs) - Executes a buy-and-bury transaction.
- [`Wrap`](program/src/wrap.rs) - Wraps SOL in the treasury for swap transactions. 
- [`SetAdmin`](program/src/set_admin.rs) - Re-assigns the admin authority.
- [`SetFeeCollector`](program/src/set_admin.rs) - Updates the fee collection address.
- [`SetFeeRate`](program/src/set_admin.rs) - Updates the fee charged per swap.

## State
- [`Automation`](api/src/state/automation.rs) - Tracks automation configs. 
- [`Board`](api/src/state/board.rs) - Tracks the current round number and timestamps.
- [`Config`](api/src/state/config.rs) - Global program configs.
- [`Miner`](api/src/state/miner.rs) - Tracks a miner&#039;s game state.
- [`Round`](api/src/state/round.rs) - Tracks the game state of a given round.
- [`Seeker`](api/src/state/seeker.rs) - Tracks whether a Seeker token has been claimed.
- [`Stake`](api/src/state/stake.rs) - Manages a user&#039;s staking activity.
- [`Treasury`](api/src/state/treasury.rs) - Mints, burns, and escrows ORE tokens. 


## Tests

To run the test suite, use the Solana toolchain: 

```
cargo test-sbf
```

For line coverage, use llvm-cov:

```
cargo llvm-cov
```
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>