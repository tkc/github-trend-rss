<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Thu, 28 Aug 2025 00:06:02 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[firecracker-microvm/firecracker]]></title>
            <link>https://github.com/firecracker-microvm/firecracker</link>
            <guid>https://github.com/firecracker-microvm/firecracker</guid>
            <pubDate>Thu, 28 Aug 2025 00:06:02 GMT</pubDate>
            <description><![CDATA[Secure and fast microVMs for serverless computing.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/firecracker-microvm/firecracker">firecracker-microvm/firecracker</a></h1>
            <p>Secure and fast microVMs for serverless computing.</p>
            <p>Language: Rust</p>
            <p>Stars: 29,411</p>
            <p>Forks: 2,034</p>
            <p>Stars today: 104 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/fc_logo_full_transparent-bg_white-fg.png&quot;&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/images/fc_logo_full_transparent-bg.png&quot;&gt;
   &lt;img alt=&quot;Firecracker Logo Title&quot; width=&quot;750&quot; src=&quot;docs/images/fc_logo_full_transparent-bg.png&quot;&gt;
&lt;/picture&gt;

Our mission is to enable secure, multi-tenant, minimal-overhead execution of
container and function workloads.

Read more about the Firecracker Charter [here](CHARTER.md).

## What is Firecracker?

Firecracker is an open source virtualization technology that is purpose-built
for creating and managing secure, multi-tenant container and function-based
services that provide serverless operational models. Firecracker runs workloads
in lightweight virtual machines, called microVMs, which combine the security and
isolation properties provided by hardware virtualization technology with the
speed and flexibility of containers.

## Overview

The main component of Firecracker is a virtual machine monitor (VMM) that uses
the Linux Kernel Virtual Machine (KVM) to create and run microVMs. Firecracker
has a minimalist design. It excludes unnecessary devices and guest-facing
functionality to reduce the memory footprint and attack surface area of each
microVM. This improves security, decreases the startup time, and increases
hardware utilization. Firecracker has also been integrated in container
runtimes, for example
[Kata Containers](https://github.com/kata-containers/kata-containers) and
[Flintlock](https://github.com/liquidmetal-dev/flintlock).

Firecracker was developed at Amazon Web Services to accelerate the speed and
efficiency of services like [AWS Lambda](https://aws.amazon.com/lambda/) and
[AWS Fargate](https://aws.amazon.com/fargate/). Firecracker is open sourced
under [Apache version 2.0](LICENSE).

To read more about Firecracker, check out
[firecracker-microvm.io](https://firecracker-microvm.github.io).

## Getting Started

To get started with Firecracker, download the latest
[release](https://github.com/firecracker-microvm/firecracker/releases) binaries
or build it from source.

You can build Firecracker on any Unix/Linux system that has Docker running (we
use a development container) and `bash` installed, as follows:

```bash
git clone https://github.com/firecracker-microvm/firecracker
cd firecracker
tools/devtool build
toolchain=&quot;$(uname -m)-unknown-linux-musl&quot;
```

The Firecracker binary will be placed at
`build/cargo_target/${toolchain}/debug/firecracker`. For more information on
building, testing, and running Firecracker, go to the
[quickstart guide](docs/getting-started.md).

The overall security of Firecracker microVMs, including the ability to meet the
criteria for safe multi-tenant computing, depends on a well configured Linux
host operating system. A configuration that we believe meets this bar is
included in [the production host setup document](docs/prod-host-setup.md).

## Contributing

Firecracker is already running production workloads within AWS, but it&#039;s still
Day 1 on the journey guided by our [mission](CHARTER.md). There&#039;s a lot more to
build and we welcome all contributions.

To contribute to Firecracker, check out the development setup section in the
[getting started guide](docs/getting-started.md) and then the Firecracker
[contribution guidelines](CONTRIBUTING.md).

## Releases

New Firecracker versions are released via the GitHub repository
[releases](https://github.com/firecracker-microvm/firecracker/releases) page,
typically every two or three months. A history of changes is recorded in our
[changelog](CHANGELOG.md).

The Firecracker release policy is detailed [here](docs/RELEASE_POLICY.md).

## Design

Firecracker&#039;s overall architecture is described in
[the design document](docs/design.md).

## Features &amp; Capabilities

Firecracker consists of a single micro Virtual Machine Manager process that
exposes an API endpoint to the host once started. The API is
[specified in OpenAPI format](src/firecracker/swagger/firecracker.yaml). Read
more about it in the [API docs](docs/api_requests).

The **API endpoint** can be used to:

- Configure the microvm by:
  - Setting the number of vCPUs (the default is 1).
  - Setting the memory size (the default is 128 MiB).
  - Configuring a [CPU template](docs/cpu_templates/cpu-templates.md).
- Add one or more network interfaces to the microVM.
- Add one or more read-write or read-only disks to the microVM, each represented
  by a file-backed block device.
- Trigger a block device re-scan while the guest is running. This enables the
  guest OS to pick up size changes to the block device&#039;s backing file.
- Change the backing file for a block device, before or after the guest boots.
- Configure rate limiters for virtio devices which can limit the bandwidth,
  operations per second, or both.
- Configure the logging and metric system.
- `[BETA]` Configure the data tree of the guest-facing metadata service. The
  service is only available to the guest if this resource is configured.
- Add a [vsock socket](docs/vsock.md) to the microVM.
- Add a [entropy device](docs/entropy.md) to the microVM.
- Start the microVM using a given kernel image, root file system, and boot
  arguments.
- [x86_64 only] Stop the microVM.

**Built-in Capabilities**:

- Demand fault paging and CPU oversubscription enabled by default.
- Advanced, thread-specific seccomp filters for enhanced security.
- [Jailer](docs/jailer.md) process for starting Firecracker in production
  scenarios; applies a cgroup/namespace isolation barrier and then drops
  privileges.

## Tested platforms

We test all combinations of:

| Instance                               | Host OS &amp; Kernel | Guest Rootfs | Guest Kernel |
| :------------------------------------- | :--------------- | :----------- | :----------- |
| m5n.metal (Intel Cascade Lake)         | al2 linux_5.10   | ubuntu 24.04 | linux_5.10   |
| m6i.metal (Intel Ice Lake)             | al2023 linux_6.1 |              | linux_6.1    |
| m7i.metal-24xl (Intel Sapphire Rapids) |                  |              |              |
| m7i.metal-48xl (Intel Sapphire Rapids) |                  |              |              |
| m6a.metal (AMD Milan)                  |                  |              |              |
| m7a.metal-48xl (AMD Genoa)             |                  |              |              |
| m6g.metal (Graviton 2)                 |                  |              |              |
| m7g.metal (Graviton 3)                 |                  |              |              |
| m8g.metal-24xl (Graviton 4)            |                  |              |              |
| m8g.metal-48xl (Graviton 4)            |                  |              |              |

## Known issues and Limitations

- The `pl031` RTC device on aarch64 does not support interrupts, so guest
  programs which use an RTC alarm (e.g. `hwclock`) will not work.

## Performance

Firecracker&#039;s performance characteristics are listed as part of the
[specification documentation](SPECIFICATION.md). All specifications are a part
of our commitment to supporting container and function workloads in serverless
operational models, and are therefore enforced via continuous integration
testing.

## Policy for Security Disclosures

The security of Firecracker is our top priority. If you suspect you have
uncovered a vulnerability, contact us privately, as outlined in our
[security policy document](SECURITY.md); we will immediately prioritize your
disclosure.

## FAQ &amp; Contact

Frequently asked questions are collected in our [FAQ doc](FAQ.md).

You can get in touch with the Firecracker community in the following ways:

- Security-related issues, see our [security policy document](SECURITY.md).
- Chat with us on our
  [Slack workspace](https://join.slack.com/t/firecracker-microvm/shared_invite/zt-2tc0mfxpc-tU~HYAYSzLDl5XGGJU3YIg)
  _Note: most of the maintainers are on a European time zone._
- Open a GitHub issue in this repository.
- Email the maintainers at
  [firecracker-maintainers@amazon.com](mailto:firecracker-maintainers@amazon.com).

When communicating within the Firecracker community, please mind our
[code of conduct](CODE_OF_CONDUCT.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[eythaann/Seelen-UI]]></title>
            <link>https://github.com/eythaann/Seelen-UI</link>
            <guid>https://github.com/eythaann/Seelen-UI</guid>
            <pubDate>Thu, 28 Aug 2025 00:06:01 GMT</pubDate>
            <description><![CDATA[The Fully Customizable Desktop Environment for Windows 10/11.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eythaann/Seelen-UI">eythaann/Seelen-UI</a></h1>
            <p>The Fully Customizable Desktop Environment for Windows 10/11.</p>
            <p>Language: Rust</p>
            <p>Stars: 11,463</p>
            <p>Forks: 349</p>
            <p>Stars today: 526 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gitbutlerapp/gitbutler]]></title>
            <link>https://github.com/gitbutlerapp/gitbutler</link>
            <guid>https://github.com/gitbutlerapp/gitbutler</guid>
            <pubDate>Thu, 28 Aug 2025 00:06:00 GMT</pubDate>
            <description><![CDATA[The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitbutlerapp/gitbutler">gitbutlerapp/gitbutler</a></h1>
            <p>The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte</p>
            <p>Language: Rust</p>
            <p>Stars: 16,037</p>
            <p>Forks: 658</p>
            <p>Stars today: 38 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
   &lt;img align=&quot;center&quot; width=&quot;128px&quot; src=&quot;crates/gitbutler-tauri/icons/128x128@2x.png&quot; /&gt;
	&lt;h1 align=&quot;center&quot;&gt;&lt;b&gt;GitButler&lt;/b&gt;&lt;/h1&gt;
	&lt;p align=&quot;center&quot;&gt;
		Git branch management tool, built from the ground up for modern workflows
    &lt;br /&gt;
    &lt;a href=&quot;https://gitbutler.com&quot;&gt;&lt;strong&gt;gitbutler.com »&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;b&gt;Download for &lt;/b&gt;
    macOS (&lt;a href=&quot;https://app.gitbutler.com/downloads/release/darwin/aarch64/dmg&quot;&gt;Apple Silicon&lt;/a&gt; |
      &lt;a href=&quot;https://app.gitbutler.com/downloads/release/darwin/x86_64/dmg&quot;&gt;Intel&lt;/a&gt;) ·
		Linux (&lt;a href=&quot;https://app.gitbutler.com/downloads/release/linux/x86_64/gz&quot;&gt;AppImage&lt;/a&gt; |
       &lt;a href=&quot;https://app.gitbutler.com/downloads/release/linux/x86_64/deb&quot;&gt;deb&lt;/a&gt;)
      ·
		Windows (&lt;a href=&quot;https://app.gitbutler.com/downloads/release/windows/x86_64/msi&quot;&gt;msi&lt;/a&gt;)
    &lt;br /&gt;
    &lt;br /&gt;
    (Unstable Nightly releases can be found &lt;a href=&quot;https://app.gitbutler.com/downloads&quot;&gt;here&lt;/a&gt;)
  &lt;/p&gt;
&lt;/div&gt;

&lt;br/&gt;

![gitbutler_client](https://github.com/user-attachments/assets/bf9bdb33-a979-47a0-b2b2-8fff5ea53afb)

[![CI][s0]][l0] [![BADGE][s6]][l6] [![TWEET][s1]][l1] [![DISCORD][s2]][l2] [![INSTA][s3]][l3] [![YOUTUBE][s5]][l5] [![DEEPWIKI][s7]][l7]

[s0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml/badge.svg
[l0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml
[s1]: https://img.shields.io/badge/Twitter-black?logo=x&amp;logoColor=white
[l1]: https://twitter.com/intent/follow?screen_name=gitbutler
[s2]: https://img.shields.io/discord/1060193121130000425?label=Discord&amp;color=5865F2
[l2]: https://discord.gg/MmFkmaJ42D
[s3]: https://img.shields.io/badge/Instagram-E4405F?logo=instagram&amp;logoColor=white
[l3]: https://www.instagram.com/gitbutler/
[s5]: https://img.shields.io/youtube/channel/subscribers/UCEwkZIHGqsTGYvX8wgD0LoQ
[l5]: https://www.youtube.com/@gitbutlerapp
[s6]: https://img.shields.io/badge/GitButler-%23B9F4F2?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMzkiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCAzOSAyOCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTI1LjIxNDUgMTIuMTk5N0wyLjg3MTA3IDEuMzg5MTJDMS41NDI5NSAwLjc0NjUzMiAwIDEuNzE0MDYgMCAzLjE4OTQ3VjI0LjgxMDVDMCAyNi4yODU5IDEuNTQyOTUgMjcuMjUzNSAyLjg3MTA3IDI2LjYxMDlMMjUuMjE0NSAxNS44MDAzQzI2LjcxOTcgMTUuMDcyMSAyNi43MTk3IDEyLjkyNzkgMjUuMjE0NSAxMi4xOTk3WiIgZmlsbD0iYmxhY2siLz4KPHBhdGggZD0iTTEzLjc4NTUgMTIuMTk5N0wzNi4xMjg5IDEuMzg5MTJDMzcuNDU3MSAwLjc0NjUzMiAzOSAxLjcxNDA2IDM5IDMuMTg5NDdWMjQuODEwNUMzOSAyNi4yODU5IDM3LjQ1NzEgMjcuMjUzNSAzNi4xMjg5IDI2LjYxMDlMMTMuNzg1NSAxNS44MDAzQzEyLjI4MDMgMTUuMDcyMSAxMi4yODAzIDEyLjkyNzkgMTMuNzg1NSAxMi4xOTk3WiIgZmlsbD0idXJsKCNwYWludDBfcmFkaWFsXzMxMF8xMjkpIi8%2BCjxkZWZzPgo8cmFkaWFsR3JhZGllbnQgaWQ9InBhaW50MF9yYWRpYWxfMzEwXzEyOSIgY3g9IjAiIGN5PSIwIiByPSIxIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIgZ3JhZGllbnRUcmFuc2Zvcm09InRyYW5zbGF0ZSgxNi41NzAxIDE0KSBzY2FsZSgxOS44NjQxIDE5LjgzODMpIj4KPHN0b3Agb2Zmc2V0PSIwLjMwMTA1NiIgc3RvcC1vcGFjaXR5PSIwIi8%2BCjxzdG9wIG9mZnNldD0iMSIvPgo8L3JhZGlhbEdyYWRpZW50Pgo8L2RlZnM%2BCjwvc3ZnPgo%3D
[l6]: https://gitbutler.com/
[s7]: https://deepwiki.com/badge.svg
[l7]: https://deepwiki.com/gitbutlerapp/gitbutler

![Alt](https://repobeats.axiom.co/api/embed/fb23382bcf57c609832661874d3019a43555d6ae.svg &#039;Repobeats analytics for GitButler&#039;)

GitButler is a git client that lets you work on multiple branches at the same time.
It allows you to quickly organize file changes into separate branches while still having them applied to your working directory.
You can then push branches individually to your remote, or directly create pull requests.

In a nutshell, it&#039;s a more flexible version of `git add -p` and `git rebase -i`, allowing you to efficiently multitask across branches.

## How Does It Work?

GitButler keeps track of uncommitted changes in a layer on top of Git. Changes to files or parts of files can be grouped into what we call virtual branches. Whenever you are happy with the contents of a virtual branch, you can push it to a remote. GitButler makes sure that the state of other virtual branches is kept separate.

## How Do GB&#039;s Virtual Branches Differ From Git Branches?

The branches that we know and love in Git are separate universes, and switching between them is a full context switch. GitButler allows you to work with multiple branches in parallel in the same working directory. This effectively means having the content of multiple branches available at the same time.

GitButler is aware of changes before they are committed. This allows it to keep a record of which virtual branch each individual diff belongs to. Effectively, this means that you can separate out individual branches with their content at any time to push them to a remote or to unapply them from your working directory.

And finally, while in Git it is preferable that you create your desired branch ahead of time, using GitButler you can move changes between virtual branches at any point during development.

## Why GitButler?

We love Git. Our own [@schacon](https://github.com/schacon) has even published the [Pro Git](https://git-scm.com/book/en/v2) book. At the same time, Git&#039;s user interface hasn&#039;t been fundamentally changed for 15 years. While it was written for Linux kernel devs sending patches to each other over mailing lists, most developers today have different workflows and needs.

Instead of trying to fit the semantics of the Git CLI into a graphical interface, we are starting with the developer workflow and mapping it back to Git.

## Tech

GitButler is a [Tauri](https://tauri.app/)-based application. Its UI is written in [Svelte](https://svelte.dev/) using [TypeScript](https://www.typescriptlang.org) and its backend is written in [Rust](https://www.rust-lang.org/).

## Main Features

- **Virtual Branches**
  - Organize work on multiple branches simultaneously, rather than constantly switching branches
  - Automatically create new branches when needed
- **Easy Commit Management**
  - Undo, Amend and Squash commits by dragging and dropping
- **Undo Timeline**
  - Logs all operations and changes and allows you to easily undo or revert any operation
- **GitHub Integration**
  - Authenticate to GitHub to open Pull Requests, list branches and statuses and more
- **Easy SSH Key Management**
  - GitButler can generate an SSH key to upload to GitHub automatically
- **AI Tooling**
  - Automatically write commit messages based on your work in progress
  - Automatically create descriptive branch names
- **Commit Signing**
  - Easy commit signing with GPG or SSH

## Example Uses

### Fixing a Bug While Working on a Feature

&gt; Say that while developing a feature, you encounter a bug that you wish to fix. It&#039;s often desirable that you ship the fix as a separate contribution (Pull request).

Using Git you can stash your changes and switch to another branch, where you can commit, and push your fix.

_With GitButler_ you simply assign your fix to a separate virtual branch, which you can individually push (or directly create a PR). An additional benefit is that you can retain the fix in your working directory while waiting for CI and/or code review.

### Trying Someone Else&#039;s Branch Together With My Work in Progress

&gt; Say you want to test a branch from someone else for the purpose of code review.

Using Git trying out someone else&#039;s branch is a full context switch away from your own work.
_With GitButler_ you can apply and unapply (add / remove) any remote branch directly into your working directory.

## Documentation

You can find our end user documentation at: https://docs.gitbutler.com

## Bugs and Feature Requests

If you have a bug or feature request, feel free to open an [issue](https://github.com/gitbutlerapp/gitbutler/issues/new),
or [join our Discord server](https://discord.gg/MmFkmaJ42D).

## AI Commit Message Generation

Commit message generation is an opt-in feature. You can enable it while adding your repository for the first time or later in the project settings.

Currently, GitButler uses OpenAI&#039;s API for diff summarization, which means that if enabled, code diffs would be sent to OpenAI&#039;s servers.

Our goal is to make this feature more modular such that in the future you can modify the prompt as well as plug a different LLM endpoints (including local ones).

## Contributing

So you want to help out? Please check out the [CONTRIBUTING.md](CONTRIBUTING.md)
document.

If you want to skip right to getting the code to actually compile, take a look
at the [DEVELOPMENT.md](DEVELOPMENT.md) file.

Want to show your support? Add a GitButler badge to your project&#039;s README:

```md
[![GitButler](https://img.shields.io/badge/GitButler-%23B9F4F2?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMzkiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCAzOSAyOCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTI1LjIxNDUgMTIuMTk5N0wyLjg3MTA3IDEuMzg5MTJDMS41NDI5NSAwLjc0NjUzMiAwIDEuNzE0MDYgMCAzLjE4OTQ3VjI0LjgxMDVDMCAyNi4yODU5IDEuNTQyOTUgMjcuMjUzNSAyLjg3MTA3IDI2LjYxMDlMMjUuMjE0NSAxNS44MDAzQzI2LjcxOTcgMTUuMDcyMSAyNi43MTk3IDEyLjkyNzkgMjUuMjE0NSAxMi4xOTk3WiIgZmlsbD0iYmxhY2siLz4KPHBhdGggZD0iTTEzLjc4NTUgMTIuMTk5N0wzNi4xMjg5IDEuMzg5MTJDMzcuNDU3MSAwLjc0NjUzMiAzOSAxLjcxNDA2IDM5IDMuMTg5NDdWMjQuODEwNUMzOSAyNi4yODU5IDM3LjQ1NzEgMjcuMjUzNSAzNi4xMjg5IDI2LjYxMDlMMTMuNzg1NSAxNS44MDAzQzEyLjI4MDMgMTUuMDcyMSAxMi4yODAzIDEyLjkyNzkgMTMuNzg1NSAxMi4xOTk3WiIgZmlsbD0idXJsKCNwYWludDBfcmFkaWFsXzMxMF8xMjkpIi8%2BCjxkZWZzPgo8cmFkaWFsR3JhZGllbnQgaWQ9InBhaW50MF9yYWRpYWxfMzEwXzEyOSIgY3g9IjAiIGN5PSIwIiByPSIxIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIgZ3JhZGllbnRUcmFuc2Zvcm09InRyYW5zbGF0ZSgxNi41NzAxIDE0KSBzY2FsZSgxOS44NjQxIDE5LjgzODMpIj4KPHN0b3Agb2Zmc2V0PSIwLjMwMTA1NiIgc3RvcC1vcGFjaXR5PSIwIi8%2BCjxzdG9wIG9mZnNldD0iMSIvPgo8L3JhZGlhbEdyYWRpZW50Pgo8L2RlZnM%2BCjwvc3ZnPgo%3D)](https://gitbutler.com/)
```

[![BADGE][s6]][l6]
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[openai/codex]]></title>
            <link>https://github.com/openai/codex</link>
            <guid>https://github.com/openai/codex</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:59 GMT</pubDate>
            <description><![CDATA[Lightweight coding agent that runs in your terminal]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/codex">openai/codex</a></h1>
            <p>Lightweight coding agent that runs in your terminal</p>
            <p>Language: Rust</p>
            <p>Stars: 36,827</p>
            <p>Forks: 4,230</p>
            <p>Stars today: 231 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;OpenAI Codex CLI&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install codex&lt;/code&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer.&lt;/br&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, see &lt;a href=&quot;https://chatgpt.com/codex&quot;&gt;chatgpt.com/codex&lt;/a&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./.github/codex-cli-splash.png&quot; alt=&quot;Codex CLI splash&quot; width=&quot;80%&quot; /&gt;
  &lt;/p&gt;

---

## Quickstart

### Installing and running Codex CLI

Install globally with your preferred package manager:

```shell
npm install -g @openai/codex  # Alternatively: `brew install codex`
```

Then simply run `codex` to get started:

```shell
codex
```

&lt;details&gt;
&lt;summary&gt;You can also go to the &lt;a href=&quot;https://github.com/openai/codex/releases/latest&quot;&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt;

Each GitHub Release contains many executables, but in practice, you likely want one of these:

- macOS
  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`
  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`
- Linux
  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`
  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`

Each archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.

&lt;/details&gt;

### Using Codex with your ChatGPT plan

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./.github/codex-cli-login.png&quot; alt=&quot;Codex CLI login&quot; width=&quot;80%&quot; /&gt;
  &lt;/p&gt;

Run `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what&#039;s included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).

You can also use Codex with an API key, but this requires [additional setup](./docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key). If you previously used an API key for usage-based billing, see the [migration steps](./docs/authentication.md#migrating-from-usage-based-billing-api-key). If you&#039;re having trouble with login, please comment on [this issue](https://github.com/openai/codex/issues/1243).

### Model Context Protocol (MCP)

Codex CLI supports [MCP servers](./docs/advanced.md#model-context-protocol-mcp). Enable by adding an `mcp_servers` section to your `~/.codex/config.toml`.


### Configuration

Codex CLI supports a rich set of configuration options, with preferences stored in `~/.codex/config.toml`. For full configuration options, see [Configuration](./docs/config.md).

---

### Docs &amp; FAQ

- [**Getting started**](./docs/getting-started.md)
  - [CLI usage](./docs/getting-started.md#cli-usage)
  - [Running with a prompt as input](./docs/getting-started.md#running-with-a-prompt-as-input)
  - [Example prompts](./docs/getting-started.md#example-prompts)
  - [Memory with AGENTS.md](./docs/getting-started.md#memory--project-docs)
  - [Configuration](./docs/config.md)
- [**Sandbox &amp; approvals**](./docs/sandbox.md)
- [**Authentication**](./docs/authentication.md)
  - [Auth methods](./docs/authentication.md#forcing-a-specific-auth-method-advanced)
  - [Login on a &quot;Headless&quot; machine](./docs/authentication.md#connecting-on-a-headless-machine)
- [**Advanced**](./docs/advanced.md)
  - [Non-interactive / CI mode](./docs/advanced.md#non-interactive--ci-mode)
  - [Tracing / verbose logging](./docs/advanced.md#tracing--verbose-logging)
  - [Model Context Protocol (MCP)](./docs/advanced.md#model-context-protocol-mcp)
- [**Zero data retention (ZDR)**](./docs/zdr.md)
- [**Contributing**](./docs/contributing.md)
- [**Install &amp; build**](./docs/install.md)
  - [System Requirements](./docs/install.md#system-requirements)
  - [DotSlash](./docs/install.md#dotslash)
  - [Build from source](./docs/install.md#build-from-source)
- [**FAQ**](./docs/faq.md)
- [**Open source fund**](./docs/open-source-fund.md)

---

## License

This repository is licensed under the [Apache-2.0 License](LICENSE).

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[paritytech/polkadot-sdk]]></title>
            <link>https://github.com/paritytech/polkadot-sdk</link>
            <guid>https://github.com/paritytech/polkadot-sdk</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:58 GMT</pubDate>
            <description><![CDATA[The Parity Polkadot Blockchain SDK]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paritytech/polkadot-sdk">paritytech/polkadot-sdk</a></h1>
            <p>The Parity Polkadot Blockchain SDK</p>
            <p>Language: Rust</p>
            <p>Stars: 2,409</p>
            <p>Forks: 995</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![SDK Logo](./docs/images/Polkadot_Logo_Horizontal_Pink_White.png#gh-dark-mode-only)
![SDK Logo](./docs/images/Polkadot_Logo_Horizontal_Pink_Black.png#gh-light-mode-only)

# Polkadot SDK

![GitHub stars](https://img.shields.io/github/stars/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub
forks](https://img.shields.io/github/forks/paritytech/polkadot-sdk)

&lt;!-- markdownlint-disable-next-line MD013 --&gt;
[![StackExchange](https://img.shields.io/badge/StackExchange-Community%20&amp;%20Support-222222?logo=stackexchange)](https://substrate.stackexchange.com/)&amp;nbsp;&amp;nbsp;![GitHub contributors](https://img.shields.io/github/contributors/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub commit activity](https://img.shields.io/github/commit-activity/m/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub last commit](https://img.shields.io/github/last-commit/paritytech/polkadot-sdk)

&gt; The Polkadot SDK repository provides all the components needed to start building on the
&gt; [Polkadot](https://polkadot.com/) network, a multi-chain blockchain platform that enables
&gt; different blockchains to interoperate and share information in a secure and scalable way.

&lt;/div&gt;

## ⚡ Quickstart
If you want to get an example node running quickly you can execute the following getting started script:

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/scripts/getting-started.sh | bash
```

## 👩🏽‍💻 Building

In order to build this project you need to install some dependencies, follow the instructions in [this guide](https://docs.polkadot.com/develop/parachains/install-polkadot-sdk).

## 📚 Documentation

* [Polkadot Documentation Portal](https://docs.polkadot.com)
* [🦀 rust-docs](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/index.html): Where we keep track of
the API docs of our Rust crates. Includes:
  * [Introduction](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/index.html)
	to each component of the Polkadot SDK: Substrate, FRAME, Cumulus, and XCM
  * [Guides](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/guides/index.html),
	namely how to build your first FRAME pallet
  * [Templates](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/templates/index.html)
    for starting a new project.
  * [External Resources](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/external_resources/index.html)
* Have a question? You can ask in the Polkadot SDK Developers Chat.
Messages from either of these channels are bridged to the other, so you can use whichever one you like.
  * [Telegram](https://t.me/substratedevs)
  * [Matrix](https://matrix.to/#/#substratedevs:matrix.org)
  * [Discord](https://discord.com/channels/722223075629727774/997505821955076196)
  * [Polkadot and Substrate StackExchange](https://substrate.stackexchange.com/)

## 🚀 Releases

&lt;!-- markdownlint-disable-next-line MD013 --&gt;
![Current Stable Release](https://raw.githubusercontent.com/paritytech/release-registry/main/badges/polkadot-sdk-latest.svg)&amp;nbsp;&amp;nbsp;![Next Stable Release](https://raw.githubusercontent.com/paritytech/release-registry/main/badges/polkadot-sdk-next.svg)

The Polkadot SDK is released every three months as a `Polkadot stableYYMM` release. Each stable release is supported for
one year with patches. See the next upcoming versions in the [Release
Registry](https://github.com/paritytech/release-registry/) and more docs in [RELEASE.md](./docs/RELEASE.md).

You can use [`psvm`](https://github.com/paritytech/psvm) to update all dependencies to a specific
version without needing to manually select the correct version for each crate.

## 🛠️ Tooling

[Polkadot SDK Version Manager](https://github.com/paritytech/psvm):
A simple tool to manage and update the Polkadot SDK dependencies in any Cargo.toml file.
It will automatically update the Polkadot SDK dependencies to their correct crates.io version.

## 🔐 Security

The security policy and procedures can be found in
[docs/contributor/SECURITY.md](./docs/contributor/SECURITY.md).

## 🤍 Contributing &amp; Code of Conduct

Ensure you follow our [contribution guidelines](./docs/contributor/CONTRIBUTING.md). In every
interaction and contribution, this project adheres to the [Contributor Covenant Code of
Conduct](./docs/contributor/CODE_OF_CONDUCT.md).

### 👾 Ready to Contribute?

Take a look at the issues labeled with [`mentor`](https://github.com/paritytech/polkadot-sdk/labels/C1-mentor)
(or alternatively [this](https://mentor.tasty.limo/) page, created by one of the maintainers) label to get started!
We always recognize valuable contributions by proposing an on-chain tip to the Polkadot network as a token of our
appreciation.

## Polkadot Fellowship

Development in this repo usually goes hand in hand with the `fellowship` organization. In short,
this repository provides all the SDK pieces needed to build both Polkadot and its parachains. But,
the actual Polkadot runtime lives in the `fellowship/runtimes` repository. Read more about the
fellowship, this separation, the RFC process
[here](https://polkadot-fellows.github.io/dashboard/).

## History

This repository is the amalgamation of 3 separate repositories that used to make up Polkadot SDK,
namely Substrate, Polkadot and Cumulus. Read more about the merge and its history
[here](https://polkadot-public.notion.site/Polkadot-SDK-FAQ-fbc4cecc2c46443fb37b9eeec2f0d85f).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[sxyazi/yazi]]></title>
            <link>https://github.com/sxyazi/yazi</link>
            <guid>https://github.com/sxyazi/yazi</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:57 GMT</pubDate>
            <description><![CDATA[💥 Blazing fast terminal file manager written in Rust, based on async I/O.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sxyazi/yazi">sxyazi/yazi</a></h1>
            <p>💥 Blazing fast terminal file manager written in Rust, based on async I/O.</p>
            <p>Language: Rust</p>
            <p>Stars: 27,836</p>
            <p>Forks: 592</p>
            <p>Stars today: 39 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;sup&gt;Special thanks to:&lt;/sup&gt;
  &lt;br&gt;&lt;br&gt;
  &lt;a href=&quot;https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=yazi&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;300&quot; src=&quot;https://github.com/user-attachments/assets/c7f141e7-9751-407d-bb0e-d6f2c487b34f&quot;&gt;
    &lt;br&gt;
    &lt;b&gt;Warp, the intelligent terminal&lt;/b&gt;
    &lt;br&gt;
    &lt;sup&gt;Yazi&#039;s AI-powered terminal of choice!&lt;br&gt;Available for macOS, Linux and Windows&lt;/sup&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

## Yazi - ⚡️ Blazing Fast Terminal File Manager

Yazi (means &quot;duck&quot;) is a terminal file manager written in Rust, based on non-blocking async I/O. It aims to provide an efficient, user-friendly, and customizable file management experience.

💡 A new article explaining its internal workings: [Why is Yazi Fast?](https://yazi-rs.github.io/blog/why-is-yazi-fast)

- 🚀 **Full Asynchronous Support**: All I/O operations are asynchronous, CPU tasks are spread across multiple threads, making the most of available resources.
- 💪 **Powerful Async Task Scheduling and Management**: Provides real-time progress updates, task cancellation, and internal task priority assignment.
- 🖼️ **Built-in Support for Multiple Image Protocols**: Also integrated with Überzug++ and Chafa, covering almost all terminals.
- 🌟 **Built-in Code Highlighting and Image Decoding**: Combined with the pre-loading mechanism, greatly accelerates image and normal file loading.
- 🔌 **Concurrent Plugin System**: UI plugins (rewriting most of the UI), functional plugins, custom previewer/preloader/spotter/fetcher; Just some pieces of Lua.
- 📡 **Data Distribution Service**: Built on a client-server architecture (no additional server process required), integrated with a Lua-based publish-subscribe model, achieving cross-instance communication and state persistence.
- 📦 **Package Manager**: Install plugins and themes with one command, keeping them up-to-date, or pin them to a specific version.
- 🧰 Integration with ripgrep, fd, fzf, zoxide
- 💫 Vim-like input/pick/confirm/which/notify component, auto-completion for cd paths
- 🏷️ Multi-Tab Support, Cross-directory selection, Scrollable Preview (for videos, PDFs, archives, code, directories, etc.)
- 🔄 Bulk Renaming, Archive Extraction, Visual Mode, File Chooser, [Git Integration](https://github.com/yazi-rs/plugins/tree/main/git.yazi), [Mount Manager](https://github.com/yazi-rs/plugins/tree/main/mount.yazi)
- 🎨 Theme System, Mouse Support, Trash Bin, Custom Layouts, Virtual Filesystem, CSI u, OSC 52
- ... and more!

https://github.com/sxyazi/yazi/assets/17523360/92ff23fa-0cd5-4f04-b387-894c12265cc7

## Project status

Public beta, can be used as a daily driver.

Yazi is currently in heavy development, expect breaking changes.

## Documentation

- Usage: https://yazi-rs.github.io/docs/installation
- Features: https://yazi-rs.github.io/features

## Discussion

- Discord Server (English mainly): https://discord.gg/qfADduSdJu
- Telegram Group (Chinese mainly): https://t.me/yazi_rs

## Image Preview

| Platform                                                                     | Protocol                               | Support                                               |
| ---------------------------------------------------------------------------- | -------------------------------------- | ----------------------------------------------------- |
| [kitty](https://github.com/kovidgoyal/kitty) (&gt;= 0.28.0)                     | [Kitty unicode placeholders][kgp]      | ✅ Built-in                                           |
| [iTerm2](https://iterm2.com)                                                 | [Inline images protocol][iip]          | ✅ Built-in                                           |
| [WezTerm](https://github.com/wez/wezterm)                                    | [Inline images protocol][iip]          | ✅ Built-in                                           |
| [Konsole](https://invent.kde.org/utilities/konsole)                          | [Kitty old protocol][kgp-old]          | ✅ Built-in                                           |
| [foot](https://codeberg.org/dnkl/foot)                                       | [Sixel graphics format][sixel]         | ✅ Built-in                                           |
| [Ghostty](https://github.com/ghostty-org/ghostty)                            | [Kitty unicode placeholders][kgp]      | ✅ Built-in                                           |
| [Windows Terminal](https://github.com/microsoft/terminal) (&gt;= v1.22.10352.0) | [Sixel graphics format][sixel]         | ✅ Built-in                                           |
| [st with Sixel patch](https://github.com/bakkeby/st-flexipatch)              | [Sixel graphics format][sixel]         | ✅ Built-in                                           |
| [Warp](https://www.warp.dev) (macOS/Linux only)                              | [Inline images protocol][iip]          | ✅ Built-in                                           |
| [Tabby](https://github.com/Eugeny/tabby)                                     | [Inline images protocol][iip]          | ✅ Built-in                                           |
| [VSCode](https://github.com/microsoft/vscode)                                | [Inline images protocol][iip]          | ✅ Built-in                                           |
| [Rio](https://github.com/raphamorim/rio)                                     | [Inline images protocol][iip]          | ✅ Built-in                                           |
| [Black Box](https://gitlab.gnome.org/raggesilver/blackbox)                   | [Sixel graphics format][sixel]         | ✅ Built-in                                           |
| [Hyper](https://github.com/vercel/hyper)                                     | [Inline images protocol][iip]          | ✅ Built-in                                           |
| [Bobcat](https://github.com/ismail-yilmaz/Bobcat)                            | [Inline images protocol][iip]          | ✅ Built-in                                           |
| X11 / Wayland                                                                | Window system protocol                 | ☑️ [Überzug++][ueberzug] required                     |
| Fallback                                                                     | [ASCII art (Unicode block)][ascii-art] | ☑️ [Chafa][chafa] required                            |

See https://yazi-rs.github.io/docs/image-preview for details.

&lt;!-- Protocols --&gt;

[kgp]: https://sw.kovidgoyal.net/kitty/graphics-protocol/#unicode-placeholders
[kgp-old]: https://github.com/sxyazi/yazi/blob/main/yazi-adapter/src/drivers/kgp_old.rs
[iip]: https://iterm2.com/documentation-images.html
[sixel]: https://www.vt100.net/docs/vt3xx-gp/chapter14.html
[ascii-art]: https://en.wikipedia.org/wiki/ASCII_art

&lt;!-- Dependencies --&gt;

[ueberzug]: https://github.com/jstkdng/ueberzugpp
[chafa]: https://hpjansson.org/chafa/

## License

Yazi is MIT-licensed. For more information check the [LICENSE](LICENSE) file.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[idootop/open-xiaoai]]></title>
            <link>https://github.com/idootop/open-xiaoai</link>
            <guid>https://github.com/idootop/open-xiaoai</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:56 GMT</pubDate>
            <description><![CDATA[让小爱音箱「听见你的声音」，解锁无限可能。]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/idootop/open-xiaoai">idootop/open-xiaoai</a></h1>
            <p>让小爱音箱「听见你的声音」，解锁无限可能。</p>
            <p>Language: Rust</p>
            <p>Stars: 939</p>
            <p>Forks: 95</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># Open-XiaoAI

让小爱音箱「听见你的声音」，解锁无限可能。

![](./docs/images/cover.jpg)

## 简介

2017 年，当全球首款千万级销量的智能音箱诞生时，我们以为触摸到了未来。但很快发现，这些设备被困在「指令-响应」的牢笼里：

- 它听得见分贝，却听不懂情感
- 它能执行命令，却不会主动思考
- 它有千万用户，却只有一套思维

我们曾幻想中的&quot;贾维斯&quot;级人工智能，在现实场景中沦为&quot;天气预报+音乐播放器&quot;。

**真正的智能不应被预设的代码逻辑所束缚，而应像生命体般在交互中进化。**

在上一个 [MiGPT](https://github.com/idootop/mi-gpt) 项目中，我们已经实现将 ChatGPT 接入到小爱音箱。

这一次 [Open-XiaoAI](https://github.com/idootop/open-xiaoai) 再次进化，直接接管小爱音箱的“耳朵”和“嘴巴”，

通过多模态大模型和 AI Agent，将小爱音箱的潜力完全释放，解锁无限可能。

**未来由你定义!**

## 你的声音 + 小爱音箱 = 无限可能

👉 [小爱音箱接入小智 AI 演示视频](https://www.bilibili.com/video/BV1TxJhzvEhz)

[![](./docs/images/xiaozhi.jpg)](https://www.bilibili.com/video/BV1TxJhzvEhz)

👉 [小爱音箱自定义唤醒词演示视频](https://www.bilibili.com/video/BV1YfVUz5EMj)

[![](./docs/images/kws.jpg)](https://www.bilibili.com/video/BV1YfVUz5EMj)

👉 [小爱音箱接入 MiGPT 演示视频](https://www.bilibili.com/video/BV1N1421y7qn)

[![](./docs/images/migpt.jpg)](https://www.bilibili.com/video/BV1N1421y7qn)

## 快速开始

&gt; [!IMPORTANT]
&gt; 本教程仅适用于 **小爱音箱 Pro（LX06）** 和 **Xiaomi 智能音箱 Pro（OH2P）** 这两款机型，**其他型号**的小爱音箱请勿直接使用！🚨

本项目由 Client 端 + Server 端两部分组成，你可以按照以下顺序运行该项目：

1. 刷机更新小爱音箱补丁固件，开启并 SSH 连接到小爱音箱 👉 [教程](docs/flash.md)
2. 在小爱音箱上安装运行 Client 端补丁程序 👉 [教程](packages/client-rust/README.md)
3. 运行以下演示程序，体验小爱音箱的全新能力 ✨
   - 👉 [小爱音箱接入小智 AI](examples/xiaozhi/README.md)
   - 👉 [小爱音箱自定义唤醒词](examples/kws/README.md)
   - 👉 [小爱音箱接入 MiGPT（完美版）](examples/migpt/README.md)
   - 👉 [小爱音箱接入 Gemini Live API](examples/gemini/README.md)

以上皆为抛砖引玉，你也可以亲手编写自己想要的功能，一切由你定义！

## 相关项目

&gt; [!TIP]
&gt; 技术的意义在于分享与共创。如果你打算或正在使用本项目做些有趣的事情，
&gt; 欢迎提交 PR 或 issue 分享你的项目和创意。✨

如果你不想刷机，或者不是小爱音箱 Pro，下面的项目或许对你有用：

- https://github.com/idootop/mi-gpt
- https://github.com/idootop/migpt-next
- https://github.com/yihong0618/xiaogpt
- https://github.com/hanxi/xiaomusic

## 参考链接

如果你想要了解更多技术细节，下面的链接可能对你有用：

- https://github.com/yihong0618/gitblog/issues/258
- https://github.com/jialeicui/open-lx01
- https://github.com/duhow/xiaoai-patch
- https://javabin.cn/2021/xiaoai_fm.html
- https://xuanxuanblingbling.github.io/iot/2022/09/16/mi/

## 免责声明

1. **适用范围**
   本项目为开源非营利项目，仅供学术研究或个人测试用途。严禁用于商业服务、网络攻击、数据窃取、系统破坏等违反《网络安全法》及使用者所在地司法管辖区的法律规定的场景。
2. **非官方声明**
   本项目由第三方开发者独立开发，与小米集团及其关联方（下称&quot;权利方&quot;）无任何隶属/合作关系，亦未获其官方授权/认可或技术支持。项目中涉及的商标、固件、云服务的所有权利归属小米集团。若权利方主张权益，使用者应立即主动停止使用并删除本项目。

继续下载或运行本项目，即表示您已完整阅读并同意[用户协议](agreement.md)，否则请立即终止使用并彻底删除本项目。

## License

[MIT](LICENSE) License © 2024-PRESENT Del Wang
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[iced-rs/iced]]></title>
            <link>https://github.com/iced-rs/iced</link>
            <guid>https://github.com/iced-rs/iced</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:55 GMT</pubDate>
            <description><![CDATA[A cross-platform GUI library for Rust, inspired by Elm]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/iced-rs/iced">iced-rs/iced</a></h1>
            <p>A cross-platform GUI library for Rust, inspired by Elm</p>
            <p>Language: Rust</p>
            <p>Stars: 27,442</p>
            <p>Forks: 1,356</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;docs/logo.svg&quot; width=&quot;140px&quot; /&gt;

# Iced

[![Documentation](https://docs.rs/iced/badge.svg)][documentation]
[![Crates.io](https://img.shields.io/crates/v/iced.svg)](https://crates.io/crates/iced)
[![License](https://img.shields.io/crates/l/iced.svg)](https://github.com/iced-rs/iced/blob/master/LICENSE)
[![Downloads](https://img.shields.io/crates/d/iced.svg)](https://crates.io/crates/iced)
[![Test Status](https://img.shields.io/github/actions/workflow/status/iced-rs/iced/test.yml?branch=master&amp;event=push&amp;label=test)](https://github.com/iced-rs/iced/actions)
[![Discourse](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fdiscourse.iced.rs%2Fsite%2Fstatistics.json&amp;query=%24.users_count&amp;suffix=%20users&amp;label=discourse&amp;color=5e7ce2)](https://discourse.iced.rs/)
[![Discord Server](https://img.shields.io/discord/628993209984614400?label=&amp;labelColor=6A7EC2&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8)](https://discord.gg/3xZJ65GAhd)

A cross-platform GUI library for Rust focused on simplicity and type-safety.
Inspired by [Elm].

&lt;a href=&quot;https://github.com/squidowl/halloy&quot;&gt;
  &lt;img src=&quot;https://iced.rs/showcase/halloy.gif&quot; width=&quot;460px&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/hecrj/icebreaker&quot;&gt;
  &lt;img src=&quot;https://iced.rs/showcase/icebreaker.gif&quot; width=&quot;360px&quot;&gt;
&lt;/a&gt;

&lt;/div&gt;

## Features

* Simple, easy-to-use, batteries-included API
* Type-safe, reactive programming model
* [Cross-platform support] (Windows, macOS, Linux, and the Web)
* Responsive layout
* Built-in widgets (including [text inputs], [scrollables], and more!)
* Custom widget support (create your own!)
* [Debug overlay with performance metrics]
* First-class support for async actions (use futures!)
* Modular ecosystem split into reusable parts:
  * A [renderer-agnostic native runtime] enabling integration with existing systems
  * Two built-in renderers leveraging [`wgpu`] and [`tiny-skia`]
    * [`iced_wgpu`] supporting Vulkan, Metal and DX12
    * [`iced_tiny_skia`] offering a software alternative as a fallback
  * A [windowing shell]

__Iced is currently experimental software.__ [Take a look at the roadmap] and
[check out the issues].

[Cross-platform support]: https://raw.githubusercontent.com/iced-rs/iced/master/docs/images/todos_desktop.jpg
[text inputs]: https://iced.rs/examples/text_input.mp4
[scrollables]: https://iced.rs/examples/scrollable.mp4
[Debug overlay with performance metrics]: https://iced.rs/examples/debug.mp4
[renderer-agnostic native runtime]: runtime/
[`wgpu`]: https://github.com/gfx-rs/wgpu
[`tiny-skia`]: https://github.com/RazrFalcon/tiny-skia
[`iced_wgpu`]: wgpu/
[`iced_tiny_skia`]: tiny_skia/
[windowing shell]: winit/
[Take a look at the roadmap]: ROADMAP.md
[check out the issues]: https://github.com/iced-rs/iced/issues

## Overview

Inspired by [The Elm Architecture], Iced expects you to split user interfaces
into four different concepts:

* __State__ — the state of your application
* __Messages__ — user interactions or meaningful events that you care
  about
* __View logic__ — a way to display your __state__ as widgets that
  may produce __messages__ on user interaction
* __Update logic__ — a way to react to __messages__ and update your
  __state__

We can build something to see how this works! Let&#039;s say we want a simple counter
that can be incremented and decremented using two buttons.

We start by modelling the __state__ of our application:

```rust
#[derive(Default)]
struct Counter {
    value: i32,
}
```

Next, we need to define the possible user interactions of our counter:
the button presses. These interactions are our __messages__:

```rust
#[derive(Debug, Clone, Copy)]
pub enum Message {
    Increment,
    Decrement,
}
```

Now, let&#039;s show the actual counter by putting it all together in our
__view logic__:

```rust
use iced::widget::{button, column, text, Column};

impl Counter {
    pub fn view(&amp;self) -&gt; Column&lt;Message&gt; {
        // We use a column: a simple vertical layout
        column![
            // The increment button. We tell it to produce an
            // `Increment` message when pressed
            button(&quot;+&quot;).on_press(Message::Increment),

            // We show the value of the counter here
            text(self.value).size(50),

            // The decrement button. We tell it to produce a
            // `Decrement` message when pressed
            button(&quot;-&quot;).on_press(Message::Decrement),
        ]
    }
}
```

Finally, we need to be able to react to any produced __messages__ and change our
__state__ accordingly in our __update logic__:

```rust
impl Counter {
    // ...

    pub fn update(&amp;mut self, message: Message) {
        match message {
            Message::Increment =&gt; {
                self.value += 1;
            }
            Message::Decrement =&gt; {
                self.value -= 1;
            }
        }
    }
}
```

And that&#039;s everything! We just wrote a whole user interface. Let&#039;s run it:

```rust
fn main() -&gt; iced::Result {
    iced::run(&quot;A cool counter&quot;, Counter::update, Counter::view)
}
```

Iced will automatically:

  1. Take the result of our __view logic__ and layout its widgets.
  1. Process events from our system and produce __messages__ for our
     __update logic__.
  1. Draw the resulting user interface.

Read the [book], the [documentation], and the [examples] to learn more!

## Implementation details

Iced was originally born as an attempt at bringing the simplicity of [Elm] and
[The Elm Architecture] into [Coffee], a 2D game library I am working on.

The core of the library was implemented during May 2019 in [this pull request].
[The first alpha version] was eventually released as
[a renderer-agnostic GUI library]. The library did not provide a renderer and
implemented the current [tour example] on top of [`ggez`], a game library.

Since then, the focus has shifted towards providing a batteries-included,
end-user-oriented GUI library, while keeping the ecosystem modular.

[this pull request]: https://github.com/hecrj/coffee/pull/35
[The first alpha version]: https://github.com/iced-rs/iced/tree/0.1.0-alpha
[a renderer-agnostic GUI library]: https://www.reddit.com/r/rust/comments/czzjnv/iced_a_rendereragnostic_gui_library_focused_on/
[tour example]: examples/README.md#tour
[`ggez`]: https://github.com/ggez/ggez

## Contributing / Feedback

If you want to contribute, please read our [contributing guidelines] for more details.

Feedback is also welcome! You can create a new topic in [our Discourse forum] or
come chat to [our Discord server].

## Sponsors

The development of Iced is sponsored by the [Cryptowatch] team at [Kraken.com]

[book]: https://book.iced.rs/
[documentation]: https://docs.rs/iced/
[examples]: https://github.com/iced-rs/iced/tree/master/examples#examples
[Coffee]: https://github.com/hecrj/coffee
[Elm]: https://elm-lang.org/
[The Elm Architecture]: https://guide.elm-lang.org/architecture/
[the current issues]: https://github.com/iced-rs/iced/issues
[contributing guidelines]: https://github.com/iced-rs/iced/blob/master/CONTRIBUTING.md
[our Discourse forum]: https://discourse.iced.rs/
[our Discord server]: https://discord.gg/3xZJ65GAhd
[Cryptowatch]: https://cryptowat.ch/charts
[Kraken.com]: https://kraken.com/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nushell/nushell]]></title>
            <link>https://github.com/nushell/nushell</link>
            <guid>https://github.com/nushell/nushell</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:54 GMT</pubDate>
            <description><![CDATA[A new type of shell]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nushell/nushell">nushell/nushell</a></h1>
            <p>A new type of shell</p>
            <p>Language: Rust</p>
            <p>Stars: 36,212</p>
            <p>Forks: 1,914</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># Nushell &lt;!-- omit in toc --&gt;
[![Crates.io](https://img.shields.io/crates/v/nu.svg)](https://crates.io/crates/nu)
[![Build Status](https://img.shields.io/github/actions/workflow/status/nushell/nushell/ci.yml?branch=main)](https://github.com/nushell/nushell/actions)
[![Nightly Build](https://github.com/nushell/nushell/actions/workflows/nightly-build.yml/badge.svg)](https://github.com/nushell/nushell/actions/workflows/nightly-build.yml)
[![Discord](https://img.shields.io/discord/601130461678272522.svg?logo=discord)](https://discord.gg/NtAbbGn)
[![The Changelog #363](https://img.shields.io/badge/The%20Changelog-%23363-61c192.svg)](https://changelog.com/podcast/363)
[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/nushell/nushell)](https://github.com/nushell/nushell/graphs/commit-activity)
[![GitHub contributors](https://img.shields.io/github/contributors/nushell/nushell)](https://github.com/nushell/nushell/graphs/contributors)

A new type of shell.

![Example of nushell](assets/nushell-autocomplete6.gif &quot;Example of nushell&quot;)

## Table of Contents &lt;!-- omit in toc --&gt;

- [Status](#status)
- [Learning About Nu](#learning-about-nu)
- [Installation](#installation)
- [Configuration](#configuration)
- [Philosophy](#philosophy)
  - [Pipelines](#pipelines)
  - [Opening files](#opening-files)
  - [Plugins](#plugins)
- [Goals](#goals)
- [Officially Supported By](#officially-supported-by)
- [Contributing](#contributing)
- [License](#license)

## Status

This project has reached a minimum-viable-product level of quality. Many people use it as their daily driver, but it may be unstable for some commands. Nu&#039;s design is subject to change as it matures.

## Learning About Nu

The [Nushell book](https://www.nushell.sh/book/) is the primary source of Nushell documentation. You can find [a full list of Nu commands in the book](https://www.nushell.sh/commands/), and we have many examples of using Nu in our [cookbook](https://www.nushell.sh/cookbook/).

We&#039;re also active on [Discord](https://discord.gg/NtAbbGn); come and chat with us!

## Installation

To quickly install Nu:

```bash
# Linux and macOS
brew install nushell
# Windows
winget install nushell
```

To use `Nu` in GitHub Action, check [setup-nu](https://github.com/marketplace/actions/setup-nu) for more detail.

Detailed installation instructions can be found in the [installation chapter of the book](https://www.nushell.sh/book/installation.html). Nu is available via many package managers:

[![Packaging status](https://repology.org/badge/vertical-allrepos/nushell.svg?columns=3)](https://repology.org/project/nushell/versions)

For details about which platforms the Nushell team actively supports, see [our platform support policy](devdocs/PLATFORM_SUPPORT.md).

## Configuration

The default configurations can be found at [sample_config](crates/nu-utils/src/default_files)
which are the configuration files one gets when they startup Nushell for the first time.

It sets all of the default configuration to run Nushell.  From here one can
then customize this file for their specific needs.

To see where *config.nu* is located on your system simply type this command.

```rust
$nu.config-path
```

Please see our [book](https://www.nushell.sh) for all of the Nushell documentation.


## Philosophy

Nu draws inspiration from projects like PowerShell, functional programming languages, and modern CLI tools.
Rather than thinking of files and data as raw streams of text, Nu looks at each input as something with structure.
For example, when you list the contents of a directory what you get back is a table of rows, where each row represents an item in that directory.
These values can be piped through a series of steps, in a series of commands called a &#039;pipeline&#039;.

### Pipelines

In Unix, it&#039;s common to pipe between commands to split up a sophisticated command over multiple steps.
Nu takes this a step further and builds heavily on the idea of _pipelines_.
As in the Unix philosophy, Nu allows commands to output to stdout and read from stdin.
Additionally, commands can output structured data (you can think of this as a third kind of stream).
Commands that work in the pipeline fit into one of three categories:

-   Commands that produce a stream (e.g., `ls`)
-   Commands that filter a stream (e.g., `where type == &quot;dir&quot;`)
-   Commands that consume the output of the pipeline (e.g., `table`)

Commands are separated by the pipe symbol (`|`) to denote a pipeline flowing left to right.

```shell
ls | where type == &quot;dir&quot; | table
# =&gt; ╭────┬──────────┬──────┬─────────┬───────────────╮
# =&gt; │ #  │   name   │ type │  size   │   modified    │
# =&gt; ├────┼──────────┼──────┼─────────┼───────────────┤
# =&gt; │  0 │ .cargo   │ dir  │     0 B │ 9 minutes ago │
# =&gt; │  1 │ assets   │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  2 │ crates   │ dir  │ 4.0 KiB │ 2 weeks ago   │
# =&gt; │  3 │ docker   │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  4 │ docs     │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  5 │ images   │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  6 │ pkg_mgrs │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  7 │ samples  │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  8 │ src      │ dir  │ 4.0 KiB │ 2 weeks ago   │
# =&gt; │  9 │ target   │ dir  │     0 B │ a day ago     │
# =&gt; │ 10 │ tests    │ dir  │ 4.0 KiB │ 2 weeks ago   │
# =&gt; │ 11 │ wix      │ dir  │     0 B │ 2 weeks ago   │
# =&gt; ╰────┴──────────┴──────┴─────────┴───────────────╯
```

Because most of the time you&#039;ll want to see the output of a pipeline, `table` is assumed.
We could have also written the above:

```shell
ls | where type == &quot;dir&quot;
```

Being able to use the same commands and compose them differently is an important philosophy in Nu.
For example, we could use the built-in `ps` command to get a list of the running processes, using the same `where` as above.

```shell
ps | where cpu &gt; 0
# =&gt; ╭───┬───────┬───────────┬───────┬───────────┬───────────╮
# =&gt; │ # │  pid  │   name    │  cpu  │    mem    │  virtual  │
# =&gt; ├───┼───────┼───────────┼───────┼───────────┼───────────┤
# =&gt; │ 0 │  2240 │ Slack.exe │ 16.40 │ 178.3 MiB │ 232.6 MiB │
# =&gt; │ 1 │ 16948 │ Slack.exe │ 16.32 │ 205.0 MiB │ 197.9 MiB │
# =&gt; │ 2 │ 17700 │ nu.exe    │  3.77 │  26.1 MiB │   8.8 MiB │
# =&gt; ╰───┴───────┴───────────┴───────┴───────────┴───────────╯
```

### Opening files

Nu can load file and URL contents as raw text or structured data (if it recognizes the format).
For example, you can load a .toml file as structured data and explore it:

```shell
open Cargo.toml
# =&gt; ╭──────────────────┬────────────────────╮
# =&gt; │ bin              │ [table 1 row]      │
# =&gt; │ dependencies     │ {record 25 fields} │
# =&gt; │ dev-dependencies │ {record 8 fields}  │
# =&gt; │ features         │ {record 10 fields} │
# =&gt; │ package          │ {record 13 fields} │
# =&gt; │ patch            │ {record 1 field}   │
# =&gt; │ profile          │ {record 3 fields}  │
# =&gt; │ target           │ {record 3 fields}  │
# =&gt; │ workspace        │ {record 1 field}   │
# =&gt; ╰──────────────────┴────────────────────╯
```

We can pipe this into a command that gets the contents of one of the columns:

```shell
open Cargo.toml | get package
# =&gt; ╭───────────────┬────────────────────────────────────╮
# =&gt; │ authors       │ [list 1 item]                      │
# =&gt; │ default-run   │ nu                                 │
# =&gt; │ description   │ A new type of shell                │
# =&gt; │ documentation │ https://www.nushell.sh/book/       │
# =&gt; │ edition       │ 2018                               │
# =&gt; │ exclude       │ [list 1 item]                      │
# =&gt; │ homepage      │ https://www.nushell.sh             │
# =&gt; │ license       │ MIT                                │
# =&gt; │ metadata      │ {record 1 field}                   │
# =&gt; │ name          │ nu                                 │
# =&gt; │ repository    │ https://github.com/nushell/nushell │
# =&gt; │ rust-version  │ 1.60                               │
# =&gt; │ version       │ 0.72.0                             │
# =&gt; ╰───────────────┴────────────────────────────────────╯
```

And if needed we can drill down further:

```shell
open Cargo.toml | get package.version
# =&gt; 0.72.0
```

### Plugins

Nu supports plugins that offer additional functionality to the shell and follow the same structured data model that built-in commands use. There are a few examples in the `crates/nu_plugins_*` directories.

Plugins are binaries that are available in your path and follow a `nu_plugin_*` naming convention.
These binaries interact with nu via a simple JSON-RPC protocol where the command identifies itself and passes along its configuration, making it available for use.
If the plugin is a filter, data streams to it one element at a time, and it can stream data back in return via stdin/stdout.
If the plugin is a sink, it is given the full vector of final data and is given free reign over stdin/stdout to use as it pleases.

The [awesome-nu repo](https://github.com/nushell/awesome-nu#plugins) lists a variety of nu-plugins while the [showcase repo](https://github.com/nushell/showcase) *shows* off informative blog posts that have been written about Nushell along with videos that highlight technical
topics that have been presented.

## Goals

Nu adheres closely to a set of goals that make up its design philosophy. As features are added, they are checked against these goals.

-   First and foremost, Nu is cross-platform. Commands and techniques should work across platforms and Nu has [first-class support for Windows, macOS, and Linux](devdocs/PLATFORM_SUPPORT.md).

-   Nu ensures compatibility with existing platform-specific executables.

-   Nu&#039;s workflow and tools should have the usability expected of modern software in 2022 (and beyond).

-   Nu views data as either structured or unstructured. It is a structured shell like PowerShell.

-   Finally, Nu views data functionally. Rather than using mutation, pipelines act as a means to load, change, and save data without mutable state.

## Officially Supported By

Please submit an issue or PR to be added to this list.

-   [zoxide](https://github.com/ajeetdsouza/zoxide)
-   [starship](https://github.com/starship/starship)
-   [oh-my-posh](https://ohmyposh.dev)
-   [Couchbase Shell](https://couchbase.sh)
-   [virtualenv](https://github.com/pypa/virtualenv)
-   [atuin](https://github.com/ellie/atuin)
-   [clap](https://github.com/clap-rs/clap/tree/master/clap_complete_nushell)
-   [Dorothy](http://github.com/bevry/dorothy)
-   [Direnv](https://github.com/direnv/direnv/blob/master/docs/hook.md#nushell)
-   [x-cmd](https://x-cmd.com/mod/nu)
-   [vfox](https://github.com/version-fox/vfox)

## Contributing

See [Contributing](CONTRIBUTING.md) for details. Thanks to all the people who already contributed!

&lt;a href=&quot;https://github.com/nushell/nushell/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=nushell/nushell&amp;max=750&amp;columns=20&quot; /&gt;
&lt;/a&gt;

## License

The project is made available under the MIT license. See the `LICENSE` file for more information.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BoundaryML/baml]]></title>
            <link>https://github.com/BoundaryML/baml</link>
            <guid>https://github.com/BoundaryML/baml</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:53 GMT</pubDate>
            <description><![CDATA[The AI framework that adds the engineering to prompt engineering (Python/TS/Ruby/Java/C#/Rust/Go compatible)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BoundaryML/baml">BoundaryML/baml</a></h1>
            <p>The AI framework that adds the engineering to prompt engineering (Python/TS/Ruby/Java/C#/Rust/Go compatible)</p>
            <p>Language: Rust</p>
            <p>Stars: 5,442</p>
            <p>Forks: 242</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://boundaryml.com?utm_source=github&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;fern/assets/baml-lamb-white.png&quot;&gt;
    &lt;img src=&quot;fern/assets/baml-lamb-white.png&quot; height=&quot;64&quot; id=&quot;top&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![BAML Version](https://img.shields.io/pypi/v/baml-py?color=006dad&amp;label=BAML%20Version)](https://pypi.org/project/baml-py/)

## BAML: Basically a Made-up Language
&lt;h4&gt;

[Homepage](https://www.boundaryml.com/) | [Docs](https://docs.boundaryml.com) | [BAML AI Chat](https://www.boundaryml.com/chat) | [Discord](https://discord.gg/BTNBeXGuaS)



&lt;/h4&gt;


&lt;/div&gt;

BAML is a simple prompting language for building reliable **AI workflows and agents**.

BAML makes prompt engineering easy by turning it into _schema engineering_ -- where you mostly focus on the models of your prompt -- to get more reliable outputs. 
You don&#039;t need to write your whole app in BAML, only the prompts! You can wire-up your LLM Functions in any language of your choice! See our quickstarts for [Python](https://docs.boundaryml.com/guide/installation-language/python), [TypeScript](https://docs.boundaryml.com/guide/installation-language/typescript), [Ruby](https://docs.boundaryml.com/guide/installation-language/ruby) and [Go, and more](https://docs.boundaryml.com/guide/installation-language/rest-api-other-languages).

BAML comes with all batteries included -- with full typesafety, streaming, retries, wide model support, even when they don&#039;t support native [tool-calling APIs](#enable-reliable-tool-calling-with-any-model-even-when-they-dont-support-it)

**Try BAML**: [Prompt Fiddle](https://www.promptfiddle.com) • [Interactive App Examples](https://baml-examples.vercel.app/)


## The core BAML principle: LLM Prompts are functions

The fundamental building block in BAML is a function. Every prompt is a function that takes in parameters and returns a type.

```rust
function ChatAgent(message: Message[], tone: &quot;happy&quot; | &quot;sad&quot;) -&gt; string
```

Every function additionally defines which models it uses and what its prompt is.

```rust
function ChatAgent(message: Message[], tone: &quot;happy&quot; | &quot;sad&quot;) -&gt; StopTool | ReplyTool {
    client &quot;openai/gpt-4o-mini&quot;

    prompt #&quot;
        Be a {{ tone }} bot.

        {{ ctx.output_format }}

        {% for m in message %}
        {{ _.role(m.role) }}
        {{ m.content }}
        {% endfor %}
    &quot;#
}

class Message {
    role string
    content string
}

class ReplyTool {
  response string
}

class StopTool {
  action &quot;stop&quot; @description(#&quot;
    when it might be a good time to end the conversation
  &quot;#)
}
```

## BAML Functions can be called from any language
Below we call the ChatAgent function we defined in BAML through Python. BAML&#039;s Rust compiler generates a &quot;baml_client&quot; to access and call them.

```python
from baml_client import b
from baml_client.types import Message, StopTool

messages = [Message(role=&quot;assistant&quot;, content=&quot;How can I help?&quot;)]

while True:
  print(messages[-1].content)
  user_reply = input()
  messages.append(Message(role=&quot;user&quot;, content=user_reply))
  tool = b.ChatAgent(messages, &quot;happy&quot;)
  if isinstance(tool, StopTool):
    print(&quot;Goodbye!&quot;)
    break
  else:
    messages.append(Message(role=&quot;assistant&quot;, content=tool.response))
```
You can write any kind of agent or workflow using chained BAML functions. An agent is a while loop that calls a Chat BAML Function with some state.

And if you need to stream, add a couple more lines:
```python
stream = b.stream.ChatAgent(messages, &quot;happy&quot;)
# partial is a Partial type with all Optional fields
for tool in stream:
    if isinstance(tool, StopTool):
      ...
    
final = stream.get_final_response()
```
And get fully type-safe outputs for each chunk in the stream.

## Test prompts 10x faster, right in your IDE
BAML comes with native tooling for VSCode (jetbrains + neovim coming soon). 

**Visualize full prompt (including any multi-modal assets), and the API request**. BAML gives you full transparency and control of the prompt.

![raw-curl](https://github.com/user-attachments/assets/c0b34db9-80cd-45a7-a356-6b5ab4a9c5b7)

**Using AI is all about iteration speed.**

If testing your pipeline takes 2 minutes, you can only test 10 ideas in 20 minutes.

If you reduce it to 5 seconds, you can test 240 ideas in the same amount of time.
![resume-attempt2-smaller2](https://github.com/user-attachments/assets/6fc6b8a6-ffed-4cfc-80b8-78bc8a3d66a6)

The playground also allows you to run tests in parallel -- for even faster iteration speeds 🚀.

No need to login to websites, and no need to manually define json schemas.

## Enable reliable tool-calling with any model
BAML works even when the models don&#039;t support native tool-calling APIs. We created the SAP (schema-aligned parsing) algorithm to support the flexible outputs LLMs can provide, like markdown within a JSON blob or chain-of-thought prior to answering. [Read more about SAP](https://www.boundaryml.com/blog/schema-aligned-parsing)

With BAML, your structured outputs work in Day-1 of a model release. No need to figure out whether a model supports parallel tool calls, or whether it supports recursive schemas, or `anyOf` or `oneOf` etc.

See it in action with: **[Deepseek-R1](https://www.boundaryml.com/blog/deepseek-r1-function-calling)** and [OpenAI O1](https://www.boundaryml.com/blog/openai-o1).



## Switch from 100s of models in a couple lines
```diff
function Extract() -&gt; Resume {
+  client openai/o3-mini
  prompt #&quot;
    ....
  &quot;#
}
```
[Retry policies](https://docs.boundaryml.com/ref/llm-client-strategies/retry-policy) • [fallbacks](https://docs.boundaryml.com/ref/llm-client-strategies/fallback) • [model rotations](https://docs.boundaryml.com/ref/llm-client-strategies/round-robin). All statically defined.
![Fallback Retry](https://www.boundaryml.com/blog/2025-01-24-ai-agents-need-a-new-syntax/06-fallback-retry.gif)
Want to do pick models at runtime? Check out the [Client Registry](https://docs.boundaryml.com/guide/baml-advanced/llm-client-registry).

We support: [OpenAI](https://docs.boundaryml.com/ref/llm-client-providers/open-ai) • [Anthropic](https://docs.boundaryml.com/ref/llm-client-providers/anthropic) • [Gemini](https://docs.boundaryml.com/ref/llm-client-providers/google-ai-gemini) • [Vertex](https://docs.boundaryml.com/ref/llm-client-providers/google-vertex) • [Bedrock](https://docs.boundaryml.com/ref/llm-client-providers/aws-bedrock) • [Azure OpenAI](https://docs.boundaryml.com/ref/llm-client-providers/open-ai-from-azure) • [Anything OpenAI Compatible](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic) ([Ollama](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-ollama), [OpenRouter](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-open-router), [VLLM](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-v-llm), [LMStudio](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-lm-studio), [TogetherAI](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-together-ai), and more)

## Build beautiful streaming UIs
BAML generates a ton of utilities for NextJS, Python (and any language) to make streaming UIs easy.
![recipe-generator](https://github.com/user-attachments/assets/cf82495b-21fc-40bf-ae98-93eef923d620)

BAML&#039;s streaming interfaces are fully type-safe. Check out the [Streaming Docs](https://docs.boundaryml.com/guide/baml-basics/streaming), and our [React hooks](https://docs.boundaryml.com/guide/framework-integration/react-next-js/quick-start)

## Fully Open-Source, and offline
- 100% open-source (Apache 2)
- 100% private. AGI will not require an internet connection, neither will BAML
    - No network requests beyond model calls you explicitly set
    - Not stored or used for any training data
- BAML files can be saved locally on your machine and checked into Github for easy diffs.
- Built in Rust. So fast, you can&#039;t even tell it&#039;s there.

## BAML&#039;s Design Philosophy

Everything is fair game when making new syntax. If you can code it, it can be yours. This is our design philosophy to help restrict ideas:

- **1:** Avoid invention when possible
    - Yes, prompts need versioning — we have a great versioning tool: git
    - Yes, you need to save prompts — we have a great storage tool: filesystems
- **2:** Any file editor and any terminal should be enough to use it
- **3:** Be fast
- **4:** A first year university student should be able to understand it

## Why a new programming language

We used to write websites like this:

```python
def home():
    return &quot;&lt;button onclick=\&quot;() =&gt; alert(\\\&quot;hello!\\\&quot;)\&quot;&gt;Click&lt;/button&gt;&quot;
```

And now we do this:

```jsx
function Home() {
  return &lt;button onClick={() =&gt; setCount(prev =&gt; prev + 1)}&gt;
          {count} clicks!
         &lt;/button&gt;
}
```

New syntax can be incredible at expressing new ideas. Plus the idea of maintaining hundreds of f-strings for prompts kind of disgusts us 🤮. Strings are bad for maintainable codebases. We prefer structured strings.

The goal of BAML is to give you the expressiveness of English, but the structure of code.

Full [blog post](https://www.boundaryml.com/blog/ai-agents-need-new-syntax) by us.


## Conclusion

As models get better, we&#039;ll continue expecting even more out of them. But what will never change is that we&#039;ll want a way to write maintainable code that uses those models. The current way we all just assemble strings is very reminiscent of the early days PHP/HTML soup in web development. We hope some of the ideas we shared today can make a tiny dent in helping us all shape the way we all code tomorrow.

## FAQ
|   |   |
| - | - |
| Do I need to write my whole app in BAML? | Nope, only the prompts! BAML translates definitions into the language of your choice! [Python](https://docs.boundaryml.com/guide/installation-language/python), [TypeScript](https://docs.boundaryml.com/guide/installation-language/typescript), [Ruby](https://docs.boundaryml.com/guide/installation-language/ruby) and [more](https://docs.boundaryml.com/guide/installation-language/rest-api-other-languages). |
| Is BAML stable? | Yes, many companies use it in production! We ship updates weekly! |
| Why a new language? | [Jump to section](#why-a-new-programming-language) |


## Contributing
Checkout our [guide on getting started](/CONTRIBUTING.md)

## Citation

You can cite the BAML repo as follows:
```bibtex
@software{baml,
  author = {Vaibhav Gupta, Aaron Villalpando and Boundary ML team},
  title = {BAML},
  url = {https://github.com/boundaryml/baml},
  year = {2024}
}
```

---

Made with ❤️ by Boundary

HQ in Seattle, WA

P.S. We&#039;re hiring for software engineers that love rust. [Email us](founders@boundaryml.com) or reach out on [discord](https://discord.gg/ENtBB6kkXH)!

&lt;div align=&quot;left&quot; style=&quot;align-items: left;&quot;&gt;
        &lt;a href=&quot;#top&quot;&gt;
            &lt;img src=&quot;https://img.shields.io/badge/Back%20to%20Top-000000?style=for-the-badge&amp;logo=github&amp;logoColor=white&quot; alt=&quot;Back to Top&quot;&gt;
        &lt;/a&gt;
&lt;/div&gt;

&lt;img src=&quot;https://imgs.xkcd.com/comics/standards.png&quot; alt_text=&quot;hi&quot; /&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[aome510/spotify-player]]></title>
            <link>https://github.com/aome510/spotify-player</link>
            <guid>https://github.com/aome510/spotify-player</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:52 GMT</pubDate>
            <description><![CDATA[A Spotify player in the terminal with full feature parity]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aome510/spotify-player">aome510/spotify-player</a></h1>
            <p>A Spotify player in the terminal with full feature parity</p>
            <p>Language: Rust</p>
            <p>Stars: 5,251</p>
            <p>Forks: 249</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># spotify_player

## Table of Contents

- [Introduction](#introduction)
- [Examples](#examples)
- [Installation](#installation)
- [Features](#features)
  - [Spotify Connect](#spotify-connect)
  - [Streaming](#streaming)
  - [Media Control](#media-control)
  - [Image](#image)
  - [Notify](#notify)
  - [Mouse support](#mouse-support)
  - [Daemon](#daemon)
  - [Fuzzy search](#fuzzy-search)
  - [CLI commands](#cli-commands)
- [Commands](#commands)
- [Configurations](#configurations)
- [Caches](#caches)
  - [Logging](#logging)
- [Acknowledgement](#acknowledgement)

## Introduction

`spotify_player` is a fast, easy to use, and configurable terminal music player.

**Features**

- Minimalist UI with an intuitive paging and popup system.
- Highly [configurable](docs/config.md)
- Feature parity with the official Spotify application.
- Support remote control with [Spotify Connect](#spotify-connect).
- Support [streaming](#streaming) songs directly from the terminal.
- Support synced lyrics.
- Support [cross-platform media control](#media-control).
- Support [image rendering](#image).
- Support [desktop notification](#notify).
- Support running the application as [a daemon](#daemon)
- Offer a wide range of [CLI commands](#cli-commands)

## Examples

A demo of `spotify_player` `v0.5.0-pre-release` on [youtube](https://www.youtube.com/watch/Jbfe9GLNWbA) or on [asciicast](https://asciinema.org/a/446913):

Checkout [examples/README.md](./examples/README.md) for more examples.

## Installation

By default, the application&#039;s installed binary is `spotify_player`.

### Requirements

A Spotify Premium account is **required**.

#### Dependencies

##### Windows and MacOS

- [Rust and cargo](https://www.rust-lang.org/tools/install) as the build dependencies

##### Linux

- [Rust and cargo](https://www.rust-lang.org/tools/install) as the build dependencies
- install `openssl`, `alsa-lib` (`streaming` feature), `libdbus` (`media-control` feature).

  - For example, on Debian based systems, run the below command to install application&#039;s dependencies:

    ```shell
    sudo apt install libssl-dev libasound2-dev libdbus-1-dev
    ```

  - On RHEL/Fedora based systems, run the below command to install application&#039;s dependencies :

    ```shell
    sudo dnf install openssl-devel alsa-lib-devel dbus-devel
    ```

    or if you&#039;re using `yum`:

    ```shell
    sudo yum install openssl-devel alsa-lib-devel dbus-devel
    ```

### Binaries

Application&#039;s prebuilt binaries can be found in the [Releases Page](https://github.com/aome510/spotify-player/releases).

**Note**: to run the application, Linux systems need to install additional dependencies as specified in the [Dependencies section](#linux).

### Homebrew

Run `brew install spotify_player` to install the application.

### Scoop

Run `scoop install spotify-player` to install the application.

### Cargo

Run `cargo install spotify_player --locked` to install the application from [crates.io](https://crates.io/crates/spotify_player).

### Arch Linux

Run `pacman -S spotify-player` to install the application.

**Note**: Defaults to PulseAudio / Pipewire audio backend. For a different one, please consider modifying the [official PKGBUILD](https://gitlab.archlinux.org/archlinux/packaging/packages/spotify-player) and rebuilding it manually. See [Audio Backends](#audio-backend) for a list of options.

### Void Linux

Run `xbps-install -S spotify-player` to install the application.

### FreeBSD

Run `pkg install spotify-player` to install the `spotify_player` binary from FreeBSD ports.

### NetBSD

Using the package manager, run `pkgin install spotify-player` to install from the official repositories.

Building from source,

```
cd /usr/pkgsrc/audio/spotify-player
make install
```

### NixOS

[spotify-player](https://search.nixos.org/packages?channel=unstable&amp;show=spotify-player&amp;from=0&amp;size=50&amp;sort=relevance&amp;type=packages&amp;query=spotify-player) is available as a Nix package and can be installed via `nix-shell -p spotify-player` or as part of your system configuration.

If you want to build the source locally you can run `nix-shell` in the root of a checkout of the source code. The provided `shell.nix` file will install the build prerequisites.

### Docker

**Note**: [streaming](#streaming) feature is disabled when using the docker image.

You can download the binary image of the latest build from the `master` branch by running

```
docker pull aome510/spotify_player:latest
```

then run

```
docker run --rm -it aome510/spotify_player:latest
```

to run the application.

You can also use your local config folder to configure the application or your local cache folder to store the application&#039;s cache data when running the docker image:

```
docker run --rm \
-v $APP_CONFIG_FOLDER:/app/config/ \
-v $APP_CACHE_FOLDER:/app/cache/ \
-it aome510/spotify_player:latest
```

## Features

### Spotify Connect

To enable a full [Spotify connect](https://www.spotify.com/us/connect/) support, users will need to enable a _&quot;user-provided client integration&quot;_.

This integration can be done by following [this documentation](https://developer.spotify.com/documentation/general/guides/authorization/app-settings/) to register a Spotify app and then specifying the app&#039;s `client_id` in the [general configuration file](docs/config.md#general).

Upon running `spotify_player` with a user-provided `client_id`, user will be prompted to authenticate the app described earlier. **NOTE** that this prompt is different from the prompt to authenticate `spotify_player`. Upon accepting the authentication request, `spotify_player` will retrieve an access token of the app to finish setting up the integration.

After the user-provided client is successfully integrated, press **D** (default shortcut for `SwitchDevice` command) to get the list of available devices, then press **enter** (default shortcut for `ChooseSelected` command) to connect to the selected device.

### Streaming

`spotify_player` supports streaming, which needs to be built/installed with `streaming` feature (**enabled** by default) **and** with an audio backend (`rodio-backend` by default). The streaming feature allows to `spotify_player` to play music directly from terminal.

The application uses [librespot](https://github.com/librespot-org/librespot) library to create an integrated Spotify client while running. The integrated client will register a Spotify speaker device under the `spotify-player` name, which is accessible on the [Spotify connect](#spotify-connect) device list.

#### Audio backend

`spotify_player` uses [rodio](https://github.com/RustAudio/rodio) as the default [audio backend](https://github.com/librespot-org/librespot/wiki/Audio-Backends). List of available audio backends:

- `alsa-backend`
- `pulseaudio-backend`
- `rodio-backend`
- `portaudio-backend`
- `jackaudio-backend`
- `rodiojack-backend`
- `sdl-backend`
- `gstreamer-backend`

User can change the audio backend when building/installing the application by specifying the `--features` option. For example, to install `spotify_player` with `pulseaudio-backend`, run

```shell
cargo install spotify_player --no-default-features --features pulseaudio-backend
```

**Note**:

- needs to specify `--no-default-features` here because `rodio-backend` is one of the default features.
- user will need to install additional dependencies depending on the selected audio backend. More details can be found in the [Librespot documentation](https://github.com/librespot-org/librespot/wiki/Compiling#general-dependencies).

The `streaming` feature can be also disabled upon installing by running

```shell
cargo install spotify_player --no-default-features
```

### Media Control

To enable media control support, `spotify_player` needs to be built/installed with `media-control` feature (**enabled** by default) and set the `enable_media_control` config option to `true` in the [general configuration file](docs/config.md#media-control).

Media control support is implemented using [MPRIS DBus](https://wiki.archlinux.org/title/MPRIS) on Linux and OS window event listener on Windows and MacOS.

### Image

To enable image rendering support, `spotify_player` needs to be built/installed with `image` feature (**disabled** by default). To install the application with `image` feature included, run:

```shell
cargo install spotify_player --features image
```

`spotify_player` supports rendering image in a full resolution if the application is run on either [Kitty](https://sw.kovidgoyal.net/kitty/graphics-protocol/) or [iTerm2](https://iterm2.com/documentation-images.html). Otherwise, the image will be displayed as [block characters](https://en.wikipedia.org/wiki/Block_Elements).

`spotify_player` also supports rendering images with `sixel` behind `sixel` feature flag, which also enables `image` feature:

```shell
cargo install spotify_player --features sixel
```

**Notes**:

- Not all terminals supported by [libsixel](https://github.com/saitoha/libsixel) are supported by `spotify_player` as it relies on a [third-party library](https://github.com/atanunq/viuer) for image rendering. A possible list of supported terminals can be found in [here](https://github.com/atanunq/viuer/blob/dc81f44a97727e04be0b000712e9233c92116ff8/src/printer/sixel.rs#L83-L95).
- Images rendered by `sixel` can have a _weird_ scale. It&#039;s recommended to tweak the `cover_img_scale` config option to get the best result as the scaling works differently with different terminals and fonts.

Examples of image rendering:

- iTerm2:

![iTerm2](https://user-images.githubusercontent.com/40011582/172966798-0aadc431-b0c3-4433-adf3-7526684fc2a0.png)

- Kitty:

![kitty](https://user-images.githubusercontent.com/40011582/172967028-8cfb2daa-1642-499a-a5bf-8ed77f2b3fac.png)

- Sixel (`foot` terminal, `cover_img_scale=1.8`):

![sixel](https://user-images.githubusercontent.com/40011582/219880331-58ac1c30-bbb0-4c99-a6cc-e5b7c9c81455.png)

- Others:

![others](https://user-images.githubusercontent.com/40011582/172967325-d2098037-e19e-440a-a38a-5b076253ecb1.png)

#### Pixelate

If your terminal supports high-res images, but you like the pixelated look you can enable the `pixelate` feature, which also enables the `image` feature:

```shell
cargo install spotify_player --features pixelate
```

The amount of pixels can be tweaked via the `cover_img_pixels` config option.

| `cover_img_pixels` | `8`                                                                                                                 | `16`                                                                                                                  | `32`                                                                                                                  | `64`                                                                                                                  |
| ------------------ | ------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------- |
| example            | &lt;img width=&quot;100&quot; alt=&quot;8x8&quot; src=&quot;https://github.com/user-attachments/assets/4137aaea-ce28-4019-8cd5-2d14327e72e4&quot; /&gt; | &lt;img width=&quot;100&quot; alt=&quot;16x16&quot; src=&quot;https://github.com/user-attachments/assets/0ca94748-093a-468c-8fb3-1f5639666eb6&quot; /&gt; | &lt;img width=&quot;100&quot; alt=&quot;32x32&quot; src=&quot;https://github.com/user-attachments/assets/f5d0f2da-0439-47e4-91c9-3a2aa73ac90c&quot; /&gt; | &lt;img width=&quot;100&quot; alt=&quot;64x64&quot; src=&quot;https://github.com/user-attachments/assets/d06ef731-38fa-424d-9672-313f56c193d0&quot; /&gt; |

To temporarily disable the `pixelate` feature just set `cover_img_pixels` to a high value like `512`.

### Notify

To enable desktop notification support, `spotify_player` needs to be built/installed with `notify` feature (**disabled** by default). To install the application with `notify` feature included, run:

```shell
cargo install spotify_player --features notify
```

**Note**: the notification support in `MacOS` and `Windows` are quite restricted compared to `Linux`.

### Mouse support

Currently, the only supported use case for mouse is to seek to a position of the current playback by left-clicking to such position in the playback&#039;s progress bar.

### Daemon

To enable a [daemon](&lt;https://en.wikipedia.org/wiki/Daemon_(computing)&gt;) support, `spotify_player` needs to be built/installed with `daemon` feature (**disabled** by default). To install the application with `daemon` feature included, run:

```shell
cargo install spotify_player --features daemon
```

You can run the application as a daemon by specifying the `-d` or `--daemon` option: `spotify_player -d`.

**Notes**:

- `daemon` feature is not supported on Windows
- `daemon` feature requires the `streaming` feature to be enabled and the application to be built with [an audio backend](#audio-backend)
- because of the OS&#039;s restrictions, `daemon` feature doesn&#039;t work with the `media-control` feature on MacOS, which is **enabled by default**. In other words, if you want to use the `daemon` feature on MacOS, you must install the application with `media-control` feature **disabled**:

  ```shell
  cargo install spotify_player --no-default-features --features daemon,rodio-backend
  ```

### Fuzzy search

To enable [fuzzy search](https://en.wikipedia.org/wiki/Approximate_string_matching) support, `spotify_player` needs to be built/installed with `fzf` feature (**disabled** by default).

### CLI Commands

`spotify_player` offers several CLI commands to interact with Spotify:

- `get`: Get Spotify data (playlist/album/artist data, user&#039;s data, etc)
- `playback`: Interact with the playback (start a playback, play-pause, next, etc)
- `search`: Search spotify
- `connect`: Connect to a Spotify device
- `like`: Like currently playing track
- `authenticate`: Authenticate the application
- `playlist`: Playlist editing (new, delete, import, fork, etc)

For more details, run `spotify_player -h` or `spotify_player {command} -h`, in which `{command}` is a CLI command.

**Notes**

- When using the CLI for the first time, you&#039;ll need to run `spotify_player authenticate` to authenticate the application beforehand.
- Under the hood, CLI command is handled by sending requests to a `spotify_player` client socket running on port `client_port`, [a general application configuration](https://github.com/aome510/spotify-player/blob/master/docs/config.md#general) with a default value of `8080`. If there is no running application&#039;s instance, a new client will be created upon handling the CLI commands, which increases the latency of the command.

#### Scripting

The `spotify_player` command-line interface makes scripting easy.
With the `search` subcommand, you can search Spotify and retrieve data in JSON format, enabling queries with tools like [jq](https://jqlang.github.io/jq/).

Here’s an example of starting playback for the first track from a search query:

```sh
read -p &quot;Search spotify: &quot; query
spotify_player playback start track --id $(spotify_player search &quot;$query&quot; | jq &#039;.tracks.[0].id&#039; | xargs)
```

## Commands

To go to the shortcut help page, press `?` or `C-h` (default shortcuts for `OpenCommandHelp` command).

**Tips**:

- you can search in the shortcut help page (and some other pages) using `Search` command
- `RefreshPlayback` can be used to manually update the playback status.
- `RestartIntegratedClient` is useful when user wants to switch to another audio device (headphone, earphone, etc) without restarting the application, as the integrated client will be re-initialized with the new device.

List of supported commands:

| Command                         | Description                                                                                        | Default shortcuts  |
| ------------------------------- | -------------------------------------------------------------------------------------------------- | ------------------ |
| `NextTrack`                     | next track                                                                                         | `n`                |
| `PreviousTrack`                 | previous track                                                                                     | `p`                |
| `ResumePause`                   | resume/pause based on the current playback                                                         | `space`            |
| `PlayRandom`                    | play a random track in the current context                                                         | `.`                |
| `Repeat`                        | cycle the repeat mode                                                                              | `C-r`              |
| `ToggleFakeTrackRepeatMode`     | toggle fake track repeat mode                                                                      | `M-r`              |
| `Shuffle`                       | toggle the shuffle mode                                                                            | `C-s`              |
| `VolumeChange`                  | change playback volume by an offset (default shortcuts use 5%)                                     | `+`, `-`           |
| `Mute`                          | toggle playback volume between 0% and previous level                                               | `_`                |
| `SeekForward`                   | seek forward by 5s                                                                                 | `&gt;`                |
| `SeekBackward`                  | seek backward by 5s                                                                                | `&lt;`                |
| `Quit`                          | quit the application                                                                               | `C-c`, `q`         |
| `ClosePopup`                    | close a popup                                                                                      | `esc`              |
| `SelectNextOrScrollDown`        | select the next item in a list/table or scroll down (supports vim-style count: 5j)                 | `j`, `C-n`, `down` |
| `SelectPreviousOrScrollUp`      | select the previous item in a list/table or scroll up (supports vim-style count: 10k)              | `k`, `C-p`, `up`   |
| `PageSelectNextOrScrollDown`    | select the next page item in a list/table or scroll a page down (supports vim-style count: 3C-f)   | `page_down`, `C-f` |
| `PageSelectPreviousOrScrollUp`  | select the previous page item in a list/table or scroll a page up (supports vim-style count: 2C-b) | `page_up`, `C-b`   |
| `SelectFirstOrScrollToTop`      | select the first item in a list/table or scroll to the top                                         | `g g`, `home`      |
| `SelectLastOrScrollToBottom`    | select the last item in a list/table or scroll to the bottom                                       | `G`, `end`         |
| `ChooseSelected`                | choose the selected item                                                                           | `enter`            |
| `RefreshPlayback`               | manually refresh the current playback                                                              | `r`                |
| `RestartIntegratedClient`       | restart the integrated client (`streaming` feature only)                                           | `R`                |
| `ShowActionsOnSelectedItem`     | open a popup showing actions on a selected item                                                    | `g a`, `C-space`   |
| `ShowActionsOnCurrentTrack`     | open a popup showing actions on the current track                                       

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[solana-foundation/anchor]]></title>
            <link>https://github.com/solana-foundation/anchor</link>
            <guid>https://github.com/solana-foundation/anchor</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:51 GMT</pubDate>
            <description><![CDATA[⚓ Solana Program Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/solana-foundation/anchor">solana-foundation/anchor</a></h1>
            <p>⚓ Solana Program Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 4,556</p>
            <p>Forks: 1,662</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img height=&quot;170x&quot; src=&quot;https://pbs.twimg.com/media/FVUVaO9XEAAulvK?format=png&amp;name=small&quot; /&gt;

  &lt;h1&gt;Anchor&lt;/h1&gt;

  &lt;p&gt;
    &lt;strong&gt;Solana Program Framework&lt;/strong&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;https://github.com/coral-xyz/anchor/actions&quot;&gt;&lt;img alt=&quot;Build Status&quot; src=&quot;https://github.com/coral-xyz/anchor/actions/workflows/tests.yaml/badge.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://anchor-lang.com&quot;&gt;&lt;img alt=&quot;Tutorials&quot; src=&quot;https://img.shields.io/badge/docs-tutorials-blueviolet&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/NHHGSXAnXk&quot;&gt;&lt;img alt=&quot;Discord Chat&quot; src=&quot;https://img.shields.io/discord/889577356681945098?color=blueviolet&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/github/license/coral-xyz/anchor?color=blueviolet&quot; /&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

[Anchor](https://www.anchor-lang.com/) is a framework providing several convenient developer tools for writing Solana programs (sometimes called &#039;smart contracts&#039;).

- Rust eDSL for writing Solana programs
- [IDL](https://en.wikipedia.org/wiki/Interface_description_language) specification
- TypeScript package for generating clients from IDL
- CLI and workspace management for developing complete applications

Anchor is the most popular framework for Solana programs.

&gt; [!NOTE]
&gt; If you&#039;re familiar with developing in Ethereum&#039;s [Solidity](https://docs.soliditylang.org/en/), [Truffle](https://www.trufflesuite.com/), [web3.js](https://github.com/ethereum/web3.js), then using Anchor will be familiar. Although the DSL syntax and semantics are targeted at Solana, the high level flow of writing RPC request handlers, emitting an IDL, and generating clients from IDL is the same.

## Getting Started

For a quickstart guide and in depth tutorials, see the [Anchor book](https://book.anchor-lang.com) and the [Anchor documentation](https://anchor-lang.com).

To jump straight to examples, go [here](https://github.com/coral-xyz/anchor/tree/master/examples). For the latest Rust and TypeScript API documentation, see [docs.rs](https://docs.rs/anchor-lang) and the [typedoc](https://www.anchor-lang.com/docs/clients/typescript).

## Packages

| Package                 | Description                                              | Version                                                                                                                          | Docs                                                                                                            |
| :---------------------- | :------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------- |
| `anchor-lang`           | Rust primitives for writing programs on Solana           | [![Crates.io](https://img.shields.io/crates/v/anchor-lang?color=blue)](https://crates.io/crates/anchor-lang)                     | [![Docs.rs](https://docs.rs/anchor-lang/badge.svg)](https://docs.rs/anchor-lang)                                |
| `anchor-spl`            | CPI clients for SPL programs on Solana                   | [![crates](https://img.shields.io/crates/v/anchor-spl?color=blue)](https://crates.io/crates/anchor-spl)                          | [![Docs.rs](https://docs.rs/anchor-spl/badge.svg)](https://docs.rs/anchor-spl)                                  |
| `anchor-client`         | Rust client for Anchor programs                          | [![crates](https://img.shields.io/crates/v/anchor-client?color=blue)](https://crates.io/crates/anchor-client)                    | [![Docs.rs](https://docs.rs/anchor-client/badge.svg)](https://docs.rs/anchor-client)                            |
| `@coral-xyz/anchor`     | TypeScript client for Anchor programs                    | [![npm](https://img.shields.io/npm/v/@coral-xyz/anchor.svg?color=blue)](https://www.npmjs.com/package/@coral-xyz/anchor)         | [![Docs](https://img.shields.io/badge/docs-typedoc-blue)](https://coral-xyz.github.io/anchor/ts/index.html)     |
| `@coral-xyz/anchor-cli` | CLI to support building and managing an Anchor workspace | [![npm](https://img.shields.io/npm/v/@coral-xyz/anchor-cli.svg?color=blue)](https://www.npmjs.com/package/@coral-xyz/anchor-cli) | [![Docs](https://img.shields.io/badge/docs-typedoc-blue)](https://coral-xyz.github.io/anchor/cli/commands.html) |

## Note

- **Anchor is in active development, so all APIs are subject to change.**
- **This code is unaudited. Use at your own risk.**

## Examples

Here&#039;s a counter program, where only the designated `authority`
can increment the count.

```rust
use anchor_lang::prelude::*;

declare_id!(&quot;Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS&quot;);

#[program]
mod counter {
    use super::*;

    pub fn initialize(ctx: Context&lt;Initialize&gt;, start: u64) -&gt; Result&lt;()&gt; {
        let counter = &amp;mut ctx.accounts.counter;
        counter.authority = *ctx.accounts.authority.key;
        counter.count = start;
        Ok(())
    }

    pub fn increment(ctx: Context&lt;Increment&gt;) -&gt; Result&lt;()&gt; {
        let counter = &amp;mut ctx.accounts.counter;
        counter.count += 1;
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Initialize&lt;&#039;info&gt; {
    #[account(init, payer = authority, space = 48)]
    pub counter: Account&lt;&#039;info, Counter&gt;,
    pub authority: Signer&lt;&#039;info&gt;,
    pub system_program: Program&lt;&#039;info, System&gt;,
}

#[derive(Accounts)]
pub struct Increment&lt;&#039;info&gt; {
    #[account(mut, has_one = authority)]
    pub counter: Account&lt;&#039;info, Counter&gt;,
    pub authority: Signer&lt;&#039;info&gt;,
}

#[account]
pub struct Counter {
    pub authority: Pubkey,
    pub count: u64,
}
```

For more, see the [examples](https://github.com/coral-xyz/anchor/tree/master/examples)
and [tests](https://github.com/coral-xyz/anchor/tree/master/tests) directories.

## License

Anchor is licensed under [Apache 2.0](./LICENSE).

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Anchor by you, as defined in the Apache-2.0 license, shall be
licensed as above, without any additional terms or conditions.

## Contribution

Thank you for your interest in contributing to Anchor!
Please see the [CONTRIBUTING.md](./CONTRIBUTING.md) to learn how.

### Thanks ❤️

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/coral-xyz/anchor/graphs/contributors&quot;&gt;
    &lt;img src=&quot;https://contrib.rocks/image?repo=coral-xyz/anchor&quot; width=&quot;100%&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[microsoft/edit]]></title>
            <link>https://github.com/microsoft/edit</link>
            <guid>https://github.com/microsoft/edit</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:50 GMT</pubDate>
            <description><![CDATA[We all edit.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/edit">microsoft/edit</a></h1>
            <p>We all edit.</p>
            <p>Language: Rust</p>
            <p>Stars: 12,144</p>
            <p>Forks: 537</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># ![Application Icon for Edit](./assets/edit.svg) Edit

A simple editor for simple needs.

This editor pays homage to the classic [MS-DOS Editor](https://en.wikipedia.org/wiki/MS-DOS_Editor), but with a modern interface and input controls similar to VS Code. The goal is to provide an accessible editor that even users largely unfamiliar with terminals can easily use.

![Screenshot of Edit with the About dialog in the foreground](./assets/edit_hero_image.png)

## Installation

[![Packaging status](https://repology.org/badge/vertical-allrepos/microsoft-edit.svg?exclude_unsupported=1)](https://repology.org/project/microsoft-edit/versions)

You can also download binaries from [our Releases page](https://github.com/microsoft/edit/releases/latest).

### Windows

You can install the latest version with WinGet:
```powershell
winget install Microsoft.Edit
```

## Build Instructions

* [Install Rust](https://www.rust-lang.org/tools/install)
* Install the nightly toolchain: `rustup install nightly`
  * Alternatively, set the environment variable `RUSTC_BOOTSTRAP=1`
* Clone the repository
* For a release build, run: `cargo build --config .cargo/release.toml --release`

### Build Configuration

During compilation you can set various environment variables to configure the build. The following table lists the available configuration options:

Environment variable | Description
--- | ---
`EDIT_CFG_ICU*` | See [ICU library name (SONAME)](#icu-library-name-soname) for details.
`EDIT_CFG_LANGUAGES` | A comma-separated list of languages to include in the build. See [i18n/edit.toml](i18n/edit.toml) for available languages.

## Notes to Package Maintainers

### Package Naming

The canonical executable name is &quot;edit&quot; and the alternative name is &quot;msedit&quot;.
We&#039;re aware of the potential conflict of &quot;edit&quot; with existing commands and recommend alternatively naming packages and executables &quot;msedit&quot;.
Names such as &quot;ms-edit&quot; should be avoided.
Assigning an &quot;edit&quot; alias is recommended, if possible.

### ICU library name (SONAME)

This project _optionally_ depends on the ICU library for its Search and Replace functionality.
By default, the project will look for a SONAME without version suffix:
* Windows: `icuuc.dll`
* macOS: `libicuuc.dylib`
* UNIX, and other OS: `libicuuc.so`

If your installation uses a different SONAME, please set the following environment variable at build time:
* `EDIT_CFG_ICUUC_SONAME`:
  For instance, `libicuuc.so.76`.
* `EDIT_CFG_ICUI18N_SONAME`:
  For instance, `libicui18n.so.76`.

Additionally, this project assumes that the ICU exports are exported without `_` prefix and without version suffix, such as `u_errorName`.
If your installation uses versioned exports, please set:
* `EDIT_CFG_ICU_CPP_EXPORTS`:
  If set to `true`, it&#039;ll look for C++ symbols such as `_u_errorName`.
  Enabled by default on macOS.
* `EDIT_CFG_ICU_RENAMING_VERSION`:
  If set to a version number, such as `76`, it&#039;ll look for symbols such as `u_errorName_76`.

Finally, you can set the following environment variables:
* `EDIT_CFG_ICU_RENAMING_AUTO_DETECT`:
  If set to `true`, the executable will try to detect the `EDIT_CFG_ICU_RENAMING_VERSION` value at runtime.
  The way it does this is not officially supported by ICU and as such is not recommended to be relied upon.
  Enabled by default on UNIX (excluding macOS) if no other options are set.

To test your settings, run `cargo test` again but with the `--ignored` flag. For instance:
```sh
cargo test -- --ignored
```
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vosen/ZLUDA]]></title>
            <link>https://github.com/vosen/ZLUDA</link>
            <guid>https://github.com/vosen/ZLUDA</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:49 GMT</pubDate>
            <description><![CDATA[CUDA on non-NVIDIA GPUs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vosen/ZLUDA">vosen/ZLUDA</a></h1>
            <p>CUDA on non-NVIDIA GPUs</p>
            <p>Language: Rust</p>
            <p>Stars: 12,960</p>
            <p>Forks: 816</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.gg/sg6BNzXuc7)

# ZLUDA

ZLUDA is a drop-in replacement for CUDA on non-NVIDIA GPUs. ZLUDA allows running unmodified CUDA applications using non-NVIDIA GPUs with near-native performance.

ZLUDA supports AMD Radeon RX 5000 series and newer GPUs (both desktop and integrated).

![GeekBench 5.5.1 chart](geekbench.svg)

ZLUDA is a work in progress. Follow development here and say hi on [Discord](https://discord.gg/sg6BNzXuc7). For more details, see the announcement: https://vosen.github.io/ZLUDA/blog/zludas-third-life/

## Usage
**Warning**: This version ZLUDA is under heavy development (more [here](https://vosen.github.io/ZLUDA/blog/zludas-third-life/)) and right now only supports Geekbench. ZLUDA probably will not work with your application just yet.

### Windows
You should have a recent AMD GPU driver (&quot;AMD Software: Adrenalin Edition&quot;) installed.\
To run your application, you should either:
* (Recommended approach) Copy ZLUDA-provided `nvcuda.dll` and `nvml.dll` from `target\release` (if built from sources) or `zluda` (if downloaded a zip package) into a path which your application uses to load CUDA. Paths vary application to application, but usually it&#039;s the directory where the .exe file is located
* Use ZLUDA launcher like below. ZLUDA launcher is known to be buggy and incomplete:
    ```
    &lt;ZLUDA_DIRECTORY&gt;\zluda_with.exe -- &lt;APPLICATION&gt; &lt;APPLICATIONS_ARGUMENTS&gt;
    ```

### Linux

Run your application like this:
```
LD_LIBRARY_PATH=&lt;ZLUDA_DIRECTORY&gt; &lt;APPLICATION&gt; &lt;APPLICATIONS_ARGUMENTS&gt;
```

where `&lt;ZLUDA_DIRECTORY&gt;` is the directory which contains ZLUDA-provided `libcuda.so`: `target/release` if you built from sources or `zluda` if you downloaded a prebuilt package.

### MacOS

Not supported

## Building

### Dependencies

* Git
* CMake
* Python 3
* Rust compiler (recent version)
* C++ compiler
* (Optional, but recommended) [Ninja build system](https://ninja-build.org/)

### Build steps

* Git clone the repo (make sure to use `--recursive` option to fetch submodules):  
`git clone --recursive https://github.com/vosen/ZLUDA.git`  
* Enter freshly cloned `ZLUDA` directory and build with cargo (this takes a while):  
`cargo xtask --release`

## Contributing

ZLUDA project has a commercial backing and _does not_ accept donations.
ZLUDA project accepts pull requests and other non-monetary contributions.

If you want to contribute a code fix or documentation update, feel free to open a Pull Request.

### Getting started

There&#039;s no architecture document (yet). The two most important crates in ZLUDA are `ptx` (PTX compiler) and `zluda` (AMD GPU runtime). A good starting point to tinkering with the project is to run one of the `ptx` unit tests under a debugger and understand what it is doing. `cargo test -p ptx -- ::add_amdgpu` is a simple test that adds two numbers.

Github issues tagged with [&quot;help wanted&quot;](https://github.com/vosen/ZLUDA/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22) are tasks that are self-contained. Their level of difficulty varies, and they are not always good beginner tasks, but they are defined unambiguously.

If you have questions, feel free to ask on [#devtalk channel on Discord](https://discord.com/channels/1273316903783497778/1303329281409159270).


## License

This software is dual-licensed under either the Apache 2.0 license or the MIT license. See [LICENSE-APACHE](LICENSE-APACHE) or [LICENSE-MIT](LICENSE-MIT) for details
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[kitao/pyxel]]></title>
            <link>https://github.com/kitao/pyxel</link>
            <guid>https://github.com/kitao/pyxel</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:48 GMT</pubDate>
            <description><![CDATA[A retro game engine for Python]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kitao/pyxel">kitao/pyxel</a></h1>
            <p>A retro game engine for Python</p>
            <p>Language: Rust</p>
            <p>Stars: 16,602</p>
            <p>Forks: 895</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;docs/images/pyxel_logo_152x64.png&quot;&gt;

[![Downloads](https://static.pepy.tech/personalized-badge/pyxel?period=total&amp;units=international_system&amp;left_color=grey&amp;right_color=blue&amp;left_text=PyPI%20downloads)](https://pypi.org/project/pyxel/)
[![GitHub Repo stars](https://img.shields.io/github/stars/kitao/pyxel?style=social)](https://github.com/kitao/pyxel)
[![GitHub forks](https://img.shields.io/github/forks/kitao/pyxel?style=social)](https://github.com/kitao/pyxel)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kitao?label=Sponsor%20me&amp;logo=github%20sponsors&amp;style=social)](https://github.com/sponsors/kitao)

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/H2H27VDKD)

[ [English](README.md) | [中文](docs/README.cn.md) | [Deutsch](docs/README.de.md) | [Español](docs/README.es.md) | [Français](docs/README.fr.md) | [Italiano](docs/README.it.md) | [日本語](docs/README.ja.md) | [한국어](docs/README.ko.md) | [Português](docs/README.pt.md) | [Русский](docs/README.ru.md) | [Türkçe](docs/README.tr.md) | [Українська](docs/README.uk.md) ]

**Pyxel** (/ˈpɪksəl/) is a retro game engine for Python.

With simple specifications inspired by retro gaming consoles, such as displaying only 16 colors and supporting 4 sound channels, you can easily enjoy making pixel-art-style games.

[&lt;img src=&quot;docs/images/pyxel_thanks.png&quot; width=&quot;460&quot;&gt;](https://github.com/kitao/pyxel/wiki/Pyxel-User-Examples) [&lt;img src=&quot;docs/images/pyxel_book.png&quot; width=&quot;180&quot;&gt;](https://gihyo.jp/book/2025/978-4-297-14657-3)

The development of Pyxel is driven by user feedback. Please give Pyxel a star on GitHub!

&lt;p&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/10_platformer.html&quot;&gt;
&lt;img src=&quot;docs/images/10_platformer.gif&quot; width=&quot;290&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/30sec_of_daylight.html&quot;&gt;
&lt;img src=&quot;docs/images/30sec_of_daylight.gif&quot; width=&quot;350&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/02_jump_game.html&quot;&gt;
&lt;img src=&quot;docs/images/02_jump_game.gif&quot; width=&quot;330&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/megaball.html&quot;&gt;
&lt;img src=&quot;docs/images/megaball.gif&quot; width=&quot;310&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/image_editor.html&quot;&gt;
&lt;img src=&quot;docs/images/image_tilemap_editor.gif&quot; width=&quot;320&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/sound_editor.html&quot;&gt;
&lt;img src=&quot;docs/images/sound_music_editor.gif&quot; width=&quot;320&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;

Pyxel&#039;s specifications and APIs are inspired by [PICO-8](https://www.lexaloffle.com/pico-8.php) and [TIC-80](https://tic80.com/).

Pyxel is open source under the [MIT License](LICENSE) and free to use. Let&#039;s start making retro games with Pyxel!

## Specifications

- Runs on Windows, Mac, Linux, and Web
- Programming in Python
- Customizable screen size
- 16-color palette
- 3 256x256-sized image banks
- 8 256x256-sized tilemaps
- 4 channels with 64 definable sounds
- 8 music tracks combining any sounds
- Keyboard, mouse, and gamepad inputs
- Image and sound editing tools
- User-extensible colors, channels, and banks

### Color Palette

&lt;img src=&quot;docs/images/05_color_palette.png&quot;&gt;

&lt;img src=&quot;docs/images/pyxel_palette.png&quot;&gt;

## How to Install

### Windows

After installing [Python3](https://www.python.org/) (version 3.8 or higher), run the following command:

```sh
pip install -U pyxel
```

When installing Python using the official installer, make sure to check the `Add Python 3.x to PATH` option to enable the `pyxel` command.

### Mac

After installing [Homebrew](https://brew.sh/), run the following commands:

```sh
brew install pipx
pipx ensurepath
pipx install pyxel
```

To upgrade Pyxel after installation, run `pipx upgrade pyxel`.

### Linux

After installing the SDL2 package (`libsdl2-dev` for Ubuntu), [Python3](https://www.python.org/) (version 3.8 or higher), and `python3-pip`, run the following command:

```sh
sudo pip3 install -U pyxel
```

If the previous command fails, consider building Pyxel from source by following the instructions in the [Makefile](Makefile).

### Web

The web version of Pyxel does not require Python or Pyxel installation and runs on PCs, smartphones, and tablets with supported web browsers.

For detailed instructions, please refer to [this page](docs/pyxel-web-en.md).

### Try Examples

After installing Pyxel, you can copy the examples to the current directory with the following command:

```sh
pyxel copy_examples
```

The following examples will be copied to your current directory:

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;01_hello_pyxel.py&lt;/td&gt;
&lt;td&gt;Simplest application&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/01_hello_pyxel.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/01_hello_pyxel.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;02_jump_game.py&lt;/td&gt;
&lt;td&gt;Jump game with Pyxel resource file&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/02_jump_game.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/02_jump_game.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;03_draw_api.py&lt;/td&gt;
&lt;td&gt;Demonstration of drawing APIs&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/03_draw_api.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/03_draw_api.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;04_sound_api.py&lt;/td&gt;
&lt;td&gt;Demonstration of sound APIs&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/04_sound_api.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/04_sound_api.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;05_color_palette.py&lt;/td&gt;
&lt;td&gt;Color palette list&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/05_color_palette.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/05_color_palette.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;06_click_game.py&lt;/td&gt;
&lt;td&gt;Mouse click game&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/06_click_game.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/06_click_game.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;07_snake.py&lt;/td&gt;
&lt;td&gt;Snake game with BGM&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/07_snake.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/07_snake.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;08_triangle_api.py&lt;/td&gt;
&lt;td&gt;Demonstration of triangle drawing APIs&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/08_triangle_api.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/08_triangle_api.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;09_shooter.py&lt;/td&gt;
&lt;td&gt;Shoot&#039;em up game with screen transitions and MML&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/09_shooter.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/09_shooter.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;10_platformer.py&lt;/td&gt;
&lt;td&gt;Side-scrolling platform game with map&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/10_platformer.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/10_platformer.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;11_offscreen.py&lt;/td&gt;
&lt;td&gt;Offscreen rendering with Image class&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/11_offscreen.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/11_offscreen.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;12_perlin_noise.py&lt;/td&gt;
&lt;td&gt;Perlin noise animation&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/12_perlin_noise.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/12_perlin_noise.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;13_bitmap_font.py&lt;/td&gt;
&lt;td&gt;Drawing a bitmap font&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/13_bitmap_font.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/13_bitmap_font.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;14_synthesizer.py&lt;/td&gt;
&lt;td&gt;Synthesizer using audio expansion features&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/14_synthesizer.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/14_synthesizer.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;15_tiled_map_file.py&lt;/td&gt;
&lt;td&gt;Loading and drawing a Tile Map File (.tmx)&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/15_tiled_map_file.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/15_tiled_map_file.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;16_transform.py&lt;/td&gt;
&lt;td&gt;Image rotation and scaling&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/16_transform.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/16_transform.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;99_flip_animation.py&lt;/td&gt;
&lt;td&gt;Animation with flip function (non-web platforms only)&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/docs/images/99_flip_animation.gif&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/pyxel/blob/main/python/pyxel/examples/99_flip_animation.py&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;30sec_of_daylight.pyxapp&lt;/td&gt;
&lt;td&gt;1st Pyxel Jam winning game by &lt;a href=&quot;https://x.com/helpcomputer0&quot;&gt;Adam&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/30sec_of_daylight.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/30SecondsOfDaylight&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;megaball.pyxapp&lt;/td&gt;
&lt;td&gt;Arcade ball physics game by &lt;a href=&quot;https://x.com/helpcomputer0&quot;&gt;Adam&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/megaball.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/kitao/megaball&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;8bit-bgm-gen.pyxapp&lt;/td&gt;
&lt;td&gt;Background music generator by &lt;a href=&quot;https://x.com/frenchbread1222&quot;&gt;frenchbread&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/8bit-bgm-gen.html&quot;&gt;Demo&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/shiromofufactory/8bit-bgm-generator&quot;&gt;Code&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

The examples can be executed with the following commands:

```sh
cd pyxel_examples
pyxel run 01_hello_pyxel.py
pyxel play 30sec_of_daylight.pyxapp
```

## How to Use

### Create Application

In your Python script, import the Pyxel module, specify the window size with the `init` function, and then start the Pyxel application with the `run` function.

```python
import pyxel

pyxel.init(160, 120)

def update():
    if pyxel.btnp(pyxel.KEY_Q):
        pyxel.quit()

def draw():
    pyxel.cls(0)
    pyxel.rect(10, 10, 20, 20, 11)

pyxel.run(update, draw)
```

The arguments of the `run` function are the `update` function, which processes frame updates, and the `draw` function, which handles screen drawing.

In an actual application, it is recommended to wrap Pyxel code in a class, as shown below:

```python
import pyxel

class App:
    def __init__(self):
        pyxel.init(160, 120)
        self.x = 0
        pyxel.run(self.update, self.draw)

    def update(self):
        self.x = (self.x + 1) % pyxel.width

    def draw(self):
        pyxel.cls(0)
        pyxel.rect(self.x, 0, 8, 8, 9)

App()
```

For creating simple graphics without animation, you can use the `show` function to simplify your code.

```python
import pyxel

pyxel.init(120, 120)
pyxel.cls(1)
pyxel.circb(60, 60, 40, 7)
pyxel.show()
```

### Run Application

A created script can be executed using the `python` command:

```sh
python PYTHON_SCRIPT_FILE
```

It can also be run with the `pyxel run` command:

```sh
pyxel run PYTHON_SCRIPT_FILE
```

Additionally, the `pyxel watch` command monitors changes in a specified directory and automatically re-runs the program when changes are detected:

```sh
pyxel watch WATCH_DIR PYTHON_SCRIPT_FILE
```

Directory monitoring can be stopped by pressing `Ctrl(Command)+C`.

### Special Key Controls

The following special key actions are available while a Pyxel application is running:

- `Esc`&lt;br&gt;
  Quit the application
- `Alt(Option)+R`&lt;br&gt;
  Reset the application
- `Alt(Option)+1`&lt;br&gt;
  Save the screenshot to the desktop
- `Alt(Option)+2`&lt;br&gt;
  Reset the recording start time of the screen capture video
- `Alt(Option)+3`&lt;br&gt;
  Save a screen capture video to the desktop (up to 10 seconds)
- `Alt(Option)+8` or `A+B+X+Y+DL` on gamepad&lt;br&gt;
  Toggles screen scaling between maximum and integer
- `Alt(Option)+9` or `A+B+X+Y+DR` on gamepad&lt;br&gt;
  Switch between screen modes (Crisp/Smooth/Retro)
- `Alt(Option)+0` or `A+B+X+Y+DU` on gamepad&lt;br&gt;
  Toggle the performance monitor (fps/`update` time/`draw` time)
- `Alt(Option)+Enter` or `A+B+X+Y+DD` on gamepad&lt;br&gt;
  Toggle fullscreen
- `Shift+Alt(Option)+1/2/3`&lt;br&gt;
  Save image bank 0, 1, or 2 to the desktop
- `Shift+Alt(Option)+0`&lt;br&gt;
  Save the current color palette to the desktop

### How to Create Resources

Pyxel Editor can create images and sounds used in a Pyxel application.

You can start Pyxel Editor with the following command:

```sh
pyxel edit PYXEL_RESOURCE_FILE
```

If the specified Pyxel resource file (.pyxres) exists, it will be loaded. If it does not exist, a new file with the specified name will be created. If the resource file is omitted, a new file named `my_resource.pyxres` will be created.

After starting Pyxel Editor, you can switch to another resource file by dragging and dropping it onto Pyxel Editor.

The created resource file can be loaded using the `load` function.

Pyxel Editor has the following editing modes.

**Image Editor**

The mode for editing the image in each **image bank**.

&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/image_editor.html&quot;&gt;
&lt;img src=&quot;docs/images/image_editor.gif&quot;&gt;
&lt;/a&gt;

You can drag and drop an image file (PNG/GIF/JPEG) into the image editor to load the image into the currently selected image bank.

**Tilemap Editor**

The mode for editing **tilemaps** that arrange images from the image banks in a tile pattern.

&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/tilemap_editor.html&quot;&gt;
&lt;img src=&quot;docs/images/tilemap_editor.gif&quot;&gt;
&lt;/a&gt;

Drag and drop a TMX file (Tiled Map File) onto the tilemap editor to load its layer 0 into the currently selected tilemap.

**Sound Editor**

The mode for editing **sounds** used for melodies and sound effects.

&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/sound_editor.html&quot;&gt;
&lt;img src=&quot;docs/images/sound_editor.gif&quot;&gt;
&lt;/a&gt;

**Music Editor**

The mode for editing **musics** in which the sounds are arranged in order of playback.

&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/music_editor.html&quot;&gt;
&lt;img src=&quot;docs/images/music_editor.gif&quot;&gt;
&lt;/a&gt;

### Other Resource Creation Methods

Pyxel images and tilemaps can also be created using the following methods:

- Create an image from a list of strings using the `Image.set` function or the `Tilemap.set` function
- Load an image file (PNG/GIF/JPEG) in Pyxel palette with `Image.load` function

Pyxel sounds can also be created using the following method:

- Create a sound from strings with `Sound.set` function or `Music.set` function

Refer to the API reference for the usage of these functions.

### How to Distribute Applications

Pyxel supports a dedicated application distribution file format (Pyxel application file) that is cross-platform.

A Pyxel application file (.pyxapp) is created using the `pyxel package` command:

```sh
pyxel package APP_DIR STARTUP_SCRIPT_FILE
```

If you need to include resources or additional modules, place them in the application directory.

Metadata can be displayed at runtime by specifying it in the following format within the startup script. Fields other than `title` and `author` are optional.

```python
# title: Pyxel Platformer
# author: Takashi Kitao
# desc: A Pyxel platformer example
# site: https://github.com/kitao/pyxel
# license: MIT
# version: 1.0
```

The created application file can be run using the `pyxel play` command:

```sh
pyxel play PYXEL_APP_FILE
```

A Pyxel application file can also be converted to an executable or an HTML file using the `pyxel app2exe` or `pyxel app2html` commands.

## API Reference

### System

- `width`, `height`&lt;br&gt;
  The width and height of the screen

- `frame_count`&lt;br&gt;
  The number of the elapsed frames

- `init(width, height, [title], [fps], [quit_key], [display_scale], [capture_scale], [capture_sec])`&lt;br&gt;
  Initialize the Pyxel application with the screen size (`width`, `height`). The following options can be specified: the window title with `title`, the frame rate with `fps`, the key to quit the application with `quit_key`, the display scale with `display_scale`, the screen capture scale with `capture_scale`, and the maximum recording time of the screen capture video with `capture_sec`.&lt;br&gt;
  Example: `pyxel.init(160, 120, title=&quot;My Pyxel App&quot;, fps=60, quit_key=pyxel.KEY_NONE, capture_scale=3, capture_sec=0)`

- `run(update, draw)`&lt;br&gt;
  Start the Pyxel application and call the `update` function for frame update and the `draw` function for drawing.

- `show()`&lt;br&gt;
  Show the screen and wait until the `Esc` key is pressed.

- `flip()`&lt;br&gt;
  Refresh the screen by one frame. The application exits when the `Esc` key is pressed. This function is not available in the web version.

- `quit()`&lt;br&gt;
  Quit the Pyxel application.

- `reset()`&lt;br&gt;
  Reset the Pyxel application.

### Resource

- `load(filename, [exclude_images], [exclude_tilemaps], [exclude_sounds], [exclude_musics])`&lt;br&gt;
  Load the resource file (.pyxres). If an option is set to `True`, the corresponding resource will be excluded from loading. If a palette file (.pyxpal) with the same name exists in the same location as the resource file, the palette display colors will also be updated. The palette file contains hexadecimal entries for the display colors (e.g. `1100ff`), separated by newlines. The palette file can also be used to change the colors displayed in Pyxel Editor.

- `user_data_dir(vendor_name, app_name)`&lt;br&gt;
  Returns the user data directory created based on `vendor_name` and `app_name`. If the directory does not exist, it will be created automatically. It is used to store high scores, game progress, and similar data.&lt;br&gt;
  Example: `print(pyxel.user_data_dir(&quot;Takashi Kitao&quot;, &quot;Pyxel Shooter&quot;))`

### Input

- `mouse_x`, `mouse_y`&lt;br&gt;
  The current position of the mouse cursor

- `mouse_wheel`&lt;br&gt;
  The current value of the mouse wheel

- `btn(key)`&lt;br&gt;
  Return `True` if the `key` is pressed, otherwise return `False`. ([Key definition list](python/pyxel/__init__.pyi))

- `btnp(key, [hold], [repeat])`&lt;br&gt;
  Return `True` if the `key` is pressed in that frame, otherwise return `False`. If `hold` and `repeat` are specified, after the `key` has been held down for `hold` frames or more, `True` is returned every `repeat` frames.

- `btnr(key)`&lt;br&gt;
  Return `True` if the `key` is released in that frame, otherwise return `False`.

- `mouse(visible)`&lt;br&gt;
  Show the mouse cursor if `visible` is `True`, and hide it if `visible` is `False`. The cursor&#039;s position continues to update even when it is hidden.

### Graphics

- `colors`&lt;br&gt;
  List of the palette display colors. The display color is specified by a 24-bit numerical value. Use `colors.from_list` and `colors.to_list` to directly assign and retrieve Python lists.&lt;br&gt;
  Example: `old_colors = pyxel.colors.to_list(); pyxel.colors.from_list([0x111111, 0x222222, 0x333333]); pyxel.colors[15] = 0x112233`

- `images`&lt;br&gt;
  List of the image banks (instances of the Image class) (0-2)&lt;br&gt;
  Example: `pyxel.images[0].load(0, 0, &quot;title.png&quot;)`

- `tilemaps`&lt;br&gt;
  List of the tilemaps (instances of the Tilemap class) (0-7)

- `clip(x, y, w, h)`&lt;br&gt;
  Set the drawing area of the screen from (`x`, `y`) with a width of `w` and a height of `h`. Call `clip()` to reset the drawing area to full screen.

- `camera(x, y)`&lt;br&gt;
  Change the upper-left corner coordinates of the screen to (`x`, `y`). Call `camera()` to reset the upper-left corner coordinates to (`0`, `0`).

- `pal(

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[warp-tech/warpgate]]></title>
            <link>https://github.com/warp-tech/warpgate</link>
            <guid>https://github.com/warp-tech/warpgate</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:47 GMT</pubDate>
            <description><![CDATA[Fully transparent SSH, HTTPS, MySQL and Postgres bastion/PAM that doesn't need additional client-side software]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/warp-tech/warpgate">warp-tech/warpgate</a></h1>
            <p>Fully transparent SSH, HTTPS, MySQL and Postgres bastion/PAM that doesn't need additional client-side software</p>
            <p>Language: Rust</p>
            <p>Stars: 5,384</p>
            <p>Forks: 177</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/89be835b-ff96-46df-94c7-ae2d176615e3&quot; /&gt;
&lt;/p&gt;

&lt;br/&gt;


&lt;p align=&quot;center&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/readme/brand-dark.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;warpgate-web/public/assets/brand.svg&quot;&gt;
  &lt;img alt=&quot;Shows a black logo in light color mode and a white one in dark color mode.&quot; src=&quot;.github/readme/brand-dark.svg&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;

&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/warp-tech/warpgate/releases/latest&quot;&gt;&lt;img alt=&quot;GitHub All Releases&quot; src=&quot;https://img.shields.io/github/downloads/warp-tech/warpgate/total.svg?label=DOWNLOADS&amp;logo=github&amp;style=for-the-badge&amp;color=8f8&quot;&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&quot;https://nightly.link/warp-tech/warpgate/workflows/build/main&quot;&gt;&lt;img src=&quot;https://shields.io/badge/-Nightly%20Builds-fa5?logo=hackthebox&amp;logoColor=444&amp;style=for-the-badge&quot;/&gt;&lt;/a&gt; &amp;nbsp; &lt;a href=&quot;https://discord.gg/Vn7BjmzhtF&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1280890060195233934?style=for-the-badge&amp;color=acc&amp;logo=discord&amp;logoColor=white&amp;label=Discord&quot;&gt;&lt;/a&gt;
&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ko-fi.com/J3J8KWTF&quot;&gt;
    &lt;img src=&quot;https://cdn.ko-fi.com/cdn/kofi3.png?v=2&quot; width=&quot;150&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

---

Warpgate is a smart &amp; fully transparent SSH, HTTPS, MySQL and PostgreSQL bastion host that doesn&#039;t require a client app or an SSH wrapper.

* Set it up in your DMZ, add user accounts and easily assign them to specific hosts and URLs within the network.
* Warpgate will record every session for you to view (live) and replay later through a built-in admin web UI.
* Not a jump host - forwards connection straight to the target in a way that&#039;s fully transparent to the client.
* Native 2FA and SSO support (TOTP &amp; OpenID Connect)
* Single binary with no dependencies.
* Written in 100% safe Rust.

## Getting started &amp; downloads

* See the [Getting started](https://warpgate.null.page/getting-started/) docs page (or [Getting started on Docker](https://warpgate.null.page/getting-started-on-docker/)).
* [Release / beta binaries](https://github.com/warp-tech/warpgate/releases)
* [Nightly builds](https://nightly.link/warp-tech/warpgate/workflows/build/main)

&lt;center&gt;
      &lt;img width=&quot;783&quot; alt=&quot;image&quot; src=&quot;https://user-images.githubusercontent.com/161476/162640762-a91a2816-48c0-44d9-8b03-5b1e2cb42d51.png&quot;&gt;
&lt;/center&gt;

&lt;table&gt;
  &lt;tr&gt;
  &lt;td&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/c9a6a372-198e-4f46-ab86-8c420dc24bca&quot;&gt;
  &lt;/td&gt;
  &lt;td&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/a2166426-e865-4aba-9600-520954bcfe7f&quot;&gt;
  &lt;/td&gt;
  &lt;td&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/366a5afb-aa86-4902-9080-eb2f40bf162c&quot;&gt;
  &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Reporting security issues

Please use GitHub&#039;s [vulnerability reporting system](https://github.com/warp-tech/warpgate/security/policy).

## Project Status

The project is ready for production.

## How it works

Warpgate is a service that you deploy on the bastion/DMZ host, which will accept SSH, HTTPS, MySQL and PostgreSQL connections and provide an (optional) web admin UI.

Run `warpgate setup` to interactively generate a config file, including port bindings. See [Getting started](https://warpgate.null.page/getting-started/) for details.

It receives connections with specifically formatted credentials, authenticates the user locally, connects to the target itself, and then connects both parties together while (optionally) recording the session.

When connecting through HTTPS, Warpgate presents a selection of available targets, and will then proxy all traffic in a session to the selected target. You can switch between targets at any time.

You manage the target and user lists and assign them to each other through the admin UI, and the session history is stored in an SQLite database (default: in `/var/lib/warpgate`).

You can also use the admin web interface to view the live session list, review session recordings, logs and more.

## Contributing / building from source

* You&#039;ll need Rust, NodeJS and NPM
* Clone the repo
* [Just](https://github.com/casey/just) is used to run tasks - install it: `cargo install just`
* Install the admin UI deps: `just npm`
* Build the frontend: `just npm run build`
* Build Warpgate: `cargo build` (optionally `--release`)

The binary is in `target/{debug|release}`.

### Tech stack

* Rust 🦀
  * HTTP: `poem-web`
  * Database: SQLite via `sea-orm` + `sqlx`
  * SSH: `russh`
* Typescript
  * Svelte
  * Bootstrap

### Backend API

* Warpgate admin and user facing APIs use autogenerated OpenAPI schemas and SDKs. To update the SDKs after changing the query/response structures, run `just openapi-all`.

## Contributors ✨

Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):

&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Eugeny&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/161476?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Eugeny&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Eugeny&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Eugeny/warpgate/commits?author=Eugeny&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://the-empire.systems/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/18178614?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Spencer Heywood&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Spencer Heywood&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Eugeny/warpgate/commits?author=heywoodlh&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/apiening&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/2064875?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Andreas Piening&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Andreas Piening&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Eugeny/warpgate/commits?author=apiening&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/Gurkengewuerz&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/10966337?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Niklas&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Niklas&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Eugeny/warpgate/commits?author=Gurkengewuerz&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/notnooblord&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/11678665?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Nooblord&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Nooblord&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Eugeny/warpgate/commits?author=notnooblord&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://shea.nz/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/51303984?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;Shea Smith&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Shea Smith&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Eugeny/warpgate/commits?author=SheaSmith&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
      &lt;td align=&quot;center&quot; valign=&quot;top&quot; width=&quot;14.28%&quot;&gt;&lt;a href=&quot;https://github.com/samtoxie&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/7732658?v=4?s=100&quot; width=&quot;100px;&quot; alt=&quot;samtoxie&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;samtoxie&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/Eugeny/warpgate/commits?author=samtoxie&quot; title=&quot;Code&quot;&gt;💻&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- markdownlint-restore --&gt;
&lt;!-- prettier-ignore-end --&gt;

&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt;

This project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[influxdata/influxdb]]></title>
            <link>https://github.com/influxdata/influxdb</link>
            <guid>https://github.com/influxdata/influxdb</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:46 GMT</pubDate>
            <description><![CDATA[Scalable datastore for metrics, events, and real-time analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/influxdb">influxdata/influxdb</a></h1>
            <p>Scalable datastore for metrics, events, and real-time analytics</p>
            <p>Language: Rust</p>
            <p>Stars: 30,542</p>
            <p>Forks: 3,640</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
 &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/influxdb-logo.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/influxdb-logo-dark.png&quot;&gt;
    &lt;img src=&quot;assets/influxdb-logo.png&quot; alt=&quot;InfluxDB Logo&quot; width=&quot;600&quot;&gt;
  &lt;/picture&gt;
 &lt;p&gt;
&lt;/div&gt;

InfluxDB Core is a database built to collect, process, transform, and store event and time series data. It is ideal for use cases that require real-time ingest and fast query response times to build user interfaces, monitoring, and automation solutions.

Common use cases include:

- Monitoring sensor data
- Server monitoring
- Application performance monitoring
- Network monitoring
- Financial market and trading analytics
- Behavioral analytics

InfluxDB is optimized for scenarios where near real-time data monitoring is essential and queries 
need to return quickly to support user experiences such as dashboards and interactive user interfaces.

InfluxDB 3 Core’s feature highlights include:

- Diskless architecture with object storage support (or local disk with no dependencies)
- Fast query response times (under 10ms for last-value queries, or 30ms for distinct metadata)
- Embedded Python VM for plugins and triggers
- Parquet file persistence
- Compatibility with InfluxDB 1.x and 2.x write APIs
- Compatability with InfluxDB 1.x query API (InfluxQL)
- SQL query engine with support for FlightSQL and HTTP query API

## Project Status

InfluxDB 3 Core is GA as of April 15, 2025! We plan to have monthly point releases for the following six months, with patch releases as needed. We will move to a quarterly cadence after that for 3-4 releases, after which we&#039;ll reevaluate our release schedule.

Join the [InfluxDB3 Discord](https://discord.gg/vZe2w2Ds8B) 
or the public channels below to share your feedback, feature requests, and bug reports.

See the [InfluxDB 3 Core &amp; Enterprise GA release announcement here](https://www.influxdata.com/blog/influxdb-3-oss-ga/) 
or dig into the [InfluxDB 3 getting started guide here](https://docs.influxdata.com/influxdb3/core/get-started/).

## Learn InfluxDB
[Documentation](https://docs.influxdata.com/) | [Community Forum](https://community.influxdata.com/) | [Community Slack](https://www.influxdata.com/slack/) | [Blog](https://www.influxdata.com/blog/) | [InfluxDB University](https://university.influxdata.com/) | [YouTube](https://www.youtube.com/@influxdata8893)

Try **InfluxDB Cloud** for free and get started fast with no local setup required. Click [here](https://cloud2.influxdata.com/signup) to start building your application on InfluxDB Cloud.


## Installation
We have nightly and versioned Docker images, Debian packages, RPM packages, and tarballs of InfluxDB available on the [InfluxData downloads page](https://portal.influxdata.com/downloads/). We also provide the InfluxDB command line interface (CLI) client as a separate binary available at the same location.

- For v1 installation, use the [main 1.x branch](https://github.com/influxdata/influxdb/tree/master-1.x) or [install InfluxDB OSS directly](https://docs.influxdata.com/influxdb/v1/introduction/install/#installing-influxdb-oss).
- For v2 installation, use the [main 2.x branch](https://github.com/influxdata/influxdb/tree/main-2.x).
- For InfluxDB 3 Core see the [InfluxDB 3 Core getting started guide](https://docs.influxdata.com/influxdb3/core/get-started/).
- For InfluxDB 3 Enterprise see the [InfluxDB 3 Enterprise getting started guide](https://docs.influxdata.com/influxdb3/enterprise/get-started/).

If you are interested in building from source, see the [building from source](CONTRIBUTING.md#building-from-source) guide for contributors.

To begin using InfluxDB, visit our [Getting Started with InfluxDB](https://docs.influxdata.com/influxdb/v1/introduction/get-started/) documentation.


## License
The open source software we build is licensed under the permissive MIT or Apache 2 licenses at the user&#039;s choosing. We’ve long held the view that our open source code should be truly open and our commercial code should be separate and closed. 


## Interested in joining the team building InfluxDB?
Check out current job openings at [www.influxdata.com/careers](https://www.influxdata.com/careers) today!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gfx-rs/wgpu]]></title>
            <link>https://github.com/gfx-rs/wgpu</link>
            <guid>https://github.com/gfx-rs/wgpu</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:45 GMT</pubDate>
            <description><![CDATA[A cross-platform, safe, pure-Rust graphics API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gfx-rs/wgpu">gfx-rs/wgpu</a></h1>
            <p>A cross-platform, safe, pure-Rust graphics API.</p>
            <p>Language: Rust</p>
            <p>Stars: 14,984</p>
            <p>Forks: 1,121</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># wgpu
&lt;img align=&quot;right&quot; width=&quot;20%&quot; src=&quot;logo.png&quot;&gt;

[![Matrix Space](https://img.shields.io/static/v1?label=Space&amp;message=%23Wgpu&amp;color=blue&amp;logo=matrix)](https://matrix.to/#/#Wgpu:matrix.org)
[![Dev Matrix](https://img.shields.io/static/v1?label=devs&amp;message=%23wgpu&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu:matrix.org)
[![User Matrix](https://img.shields.io/static/v1?label=users&amp;message=%23wgpu-users&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu-users:matrix.org)
[![Build Status](https://img.shields.io/github/actions/workflow/status/gfx-rs/wgpu/ci.yml?branch=trunk&amp;logo=github&amp;label=CI)](https://github.com/gfx-rs/wgpu/actions)
[![codecov.io](https://img.shields.io/codecov/c/github/gfx-rs/wgpu?logo=codecov&amp;logoColor=fff&amp;label=codecov&amp;token=84qJTesmeS)](https://codecov.io/gh/gfx-rs/wgpu)

`wgpu` is a cross-platform, safe, pure-rust graphics API. It runs natively on Vulkan, Metal, D3D12, and OpenGL; and on top of WebGL2 and WebGPU on wasm.

The API is based on the [WebGPU standard][webgpu]. It serves as the core of the WebGPU integration in Firefox, Servo, and Deno.

[webgpu]: https://gpuweb.github.io/gpuweb/

## Quick Links

| Docs                  | Examples                  | Changelog               |
|:---------------------:|:-------------------------:|:-----------------------:|
| [v26][rel-docs]       | [v26][rel-examples]       | [v26][rel-change]       |
| [`trunk`][trunk-docs] | [`trunk`][trunk-examples] | [`trunk`][trunk-change] |

Contributors are welcome! See [CONTRIBUTING.md][contrib] for more information.

[rel-docs]: https://docs.rs/wgpu/
[rel-examples]: https://github.com/gfx-rs/wgpu/tree/v26/examples#readme
[rel-change]: https://github.com/gfx-rs/wgpu/releases
[trunk-docs]: https://wgpu.rs/doc/wgpu/
[trunk-examples]: https://github.com/gfx-rs/wgpu/tree/trunk/examples#readme
[trunk-change]: https://github.com/gfx-rs/wgpu/blob/trunk/CHANGELOG.md#unreleased
[contrib]: CONTRIBUTING.md

## Repo Overview

The repository hosts the following libraries:

- [![Crates.io](https://img.shields.io/crates/v/wgpu.svg?label=wgpu)](https://crates.io/crates/wgpu) [![docs.rs](https://docs.rs/wgpu/badge.svg)](https://docs.rs/wgpu/) - User facing Rust API.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-core.svg?label=wgpu-core)](https://crates.io/crates/wgpu-core) [![docs.rs](https://docs.rs/wgpu-core/badge.svg)](https://docs.rs/wgpu-core/) - Internal safe implementation.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-hal.svg?label=wgpu-hal)](https://crates.io/crates/wgpu-hal) [![docs.rs](https://docs.rs/wgpu-hal/badge.svg)](https://docs.rs/wgpu-hal/) - Internal unsafe GPU API abstraction layer.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-types.svg?label=wgpu-types)](https://crates.io/crates/wgpu-types) [![docs.rs](https://docs.rs/wgpu-types/badge.svg)](https://docs.rs/wgpu-types/) - Rust types shared between all crates.
- [![Crates.io](https://img.shields.io/crates/v/naga.svg?label=naga)](https://crates.io/crates/naga) [![docs.rs](https://docs.rs/naga/badge.svg)](https://docs.rs/naga/) - Stand-alone shader translation library.
- [![Crates.io](https://img.shields.io/crates/v/deno_webgpu.svg?label=deno_webgpu)](https://crates.io/crates/deno_webgpu) - WebGPU implementation for the Deno JavaScript/TypeScript runtime

The following binaries:

- [![Crates.io](https://img.shields.io/crates/v/naga-cli.svg?label=naga-cli)](https://crates.io/crates/naga-cli) - Tool for translating shaders between different languages using `naga`.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-info.svg?label=wgpu-info)](https://crates.io/crates/wgpu-info) - Tool for getting information on GPUs in the system.
- `cts_runner` - WebGPU Conformance Test Suite runner using `deno_webgpu`.
- `player` - standalone application for replaying the API traces.

For an overview of all the components in the gfx-rs ecosystem, see [the big picture](./docs/big-picture.png).

## Getting Started

### Play with our Examples

Go to &lt;https://wgpu.rs/examples/&gt; to play with our examples in your browser. Requires a browser supporting WebGPU for the WebGPU examples.

### Rust

Rust examples can be found at [examples](examples). You can run the examples natively with `cargo run --bin wgpu-examples &lt;example&gt;`.

If you are new to wgpu and graphics programming, we recommend starting with https://sotrh.github.io/learn-wgpu/.

To run the examples in a browser, run `cargo xtask run-wasm`.
Then open `http://localhost:8000` in your browser, and you can choose an example to run.
Naturally, in order to display any of the WebGPU based examples, you need to make sure your browser supports it.

### C/C++

To use wgpu in C/C++, you need [wgpu-native](https://github.com/gfx-rs/wgpu-native).

If you are looking for a wgpu C++ tutorial, look at the following:

- https://eliemichel.github.io/LearnWebGPU/

### Others

If you want to use wgpu in other languages, there are many bindings to wgpu-native from languages such as Python, D, Julia, Kotlin, and more. See [the list](https://github.com/gfx-rs/wgpu-native#bindings).

## Community

We have the Matrix space [![Matrix Space](https://img.shields.io/static/v1?label=Space&amp;message=%23Wgpu&amp;color=blue&amp;logo=matrix)](https://matrix.to/#/#Wgpu:matrix.org) with a few different rooms that form the wgpu community:

- [![Wgpu Matrix](https://img.shields.io/static/v1?label=wgpu-devs&amp;message=%23wgpu&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu:matrix.org) - discussion of the wgpu&#039;s development.
- [![Naga Matrix](https://img.shields.io/static/v1?label=naga-devs&amp;message=%23naga&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#naga:matrix.org) - discussion of the naga&#039;s development.
- [![User Matrix](https://img.shields.io/static/v1?label=wgpu-users&amp;message=%23wgpu-users&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu-users:matrix.org) - discussion of using the library and the surrounding ecosystem.
- [![Random Matrix](https://img.shields.io/static/v1?label=random&amp;message=%23wgpu-random&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu-random:matrix.org) - discussion of everything else.

## Wiki

We have a [wiki](https://github.com/gfx-rs/wgpu/wiki) that serves as a knowledge base.

## Extension Specifications

While the core of wgpu is based on the WebGPU standard, we also support extensions that allow for features that the standard does not have yet.
For high-level documentation on how to use these extensions, see the individual specifications:

🧪EXPERIMENTAL🧪 APIs are subject to change and may allow undefined behavior if used incorrectly.

- 🧪EXPERIMENTAL🧪 [Ray Tracing](./docs/api-specs/ray_tracing.md).
- 🧪EXPERIMENTAL🧪 [Mesh Shading](./docs/api-specs/mesh_shading.md).

## Supported Platforms

| API    | Windows            | Linux/Android      | macOS/iOS          | Web (wasm)         |
| ------ | ------------------ | ------------------ | ------------------ | ------------------ |
| Vulkan |         ✅         |         ✅         |         🌋         |                    |
| Metal  |                    |                    |         ✅         |                    |
| DX12   |         ✅         |                    |                    |                    |
| OpenGL |    🆗 (GL 3.3+)    |  🆗 (GL ES 3.0+)   |         📐         |    🆗 (WebGL2)     |
| WebGPU |                    |                    |                    |         ✅         |

✅ = First Class Support  
🆗 = Downlevel/Best Effort Support  
📐 = Requires the [ANGLE](#angle) translation layer (GL ES 3.0 only)  
🌋 = Requires the [MoltenVK](https://vulkan.lunarg.com/sdk/home#mac) translation layer  
🛠️ = Unsupported, though open to contributions

### Shader Support

wgpu supports shaders in [WGSL](https://gpuweb.github.io/gpuweb/wgsl/), SPIR-V, and GLSL.
Both [HLSL](https://github.com/Microsoft/DirectXShaderCompiler) and [GLSL](https://github.com/KhronosGroup/glslang)
have compilers to target SPIR-V. All of these shader languages can be used with any backend as we handle all of the conversions. Additionally, support for these shader inputs is not going away.

While WebGPU does not support any shading language other than WGSL, we will automatically convert your
non-WGSL shaders if you&#039;re running on WebGPU.

WGSL is always supported by default, but GLSL and SPIR-V need features enabled to compile in support.

Note that the WGSL specification is still under development,
so the [draft specification][wgsl spec] does not exactly describe what `wgpu` supports.
See [below](#tracking-the-webgpu-and-wgsl-draft-specifications) for details.

To enable SPIR-V shaders, enable the `spirv` feature of wgpu.
To enable GLSL shaders, enable the `glsl` feature of wgpu.

### Angle

[Angle](http://angleproject.org) is a translation layer from GLES to other backends developed by Google.
We support running our GLES3 backend over it in order to reach platforms DX11 support, which aren&#039;t accessible otherwise.
In order to run with Angle, the &quot;angle&quot; feature has to be enabled, and Angle libraries placed in a location visible to the application.
These binaries can be downloaded from [gfbuild-angle](https://github.com/DileSoft/gfbuild-angle) artifacts, [manual compilation](https://github.com/google/angle/blob/main/doc/DevSetup.md) may be required on Macs with Apple silicon.

On Windows, you generally need to copy them into the working directory, in the same directory as the executable, or somewhere in your path.
On Linux, you can point to them using `LD_LIBRARY_PATH` environment.

### MSRV policy

Due to complex dependants, we have two MSRV policies:

- `naga`, `wgpu-core`, `wgpu-hal`, and `wgpu-types`&#039;s MSRV is **1.82**.
- The rest of the workspace has an MSRV of **1.88**.

It is enforced on CI (in &quot;/.github/workflows/ci.yml&quot;) with the `CORE_MSRV` and `REPO_MSRV` variables.
This version can only be upgraded in breaking releases, though we release a breaking version every three months.

The `naga`, `wgpu-core`, `wgpu-hal`, and `wgpu-types` crates should never
require an MSRV ahead of Firefox&#039;s MSRV for nightly builds, as
determined by the value of `MINIMUM_RUST_VERSION` in
[`python/mozboot/mozboot/util.py`][util].

[util]: https://searchfox.org/mozilla-central/source/python/mozboot/mozboot/util.py

## Environment Variables

All testing and example infrastructure share the same set of environment variables that determine which Backend/GPU it will run on.

- `WGPU_ADAPTER_NAME` with a substring of the name of the adapter you want to use (ex. `1080` will match `NVIDIA GeForce 1080ti`).
- `WGPU_BACKEND` with a comma-separated list of the backends you want to use (`vulkan`, `metal`, `dx12`, or `gl`).
- `WGPU_POWER_PREF` with the power preference to choose when a specific adapter name isn&#039;t specified (`high`, `low` or `none`)
- `WGPU_DX12_COMPILER` with the DX12 shader compiler you wish to use (`dxc`, `static-dxc`, or `fxc`). Note that `dxc` requires `dxcompiler.dll` (min v1.8.2502) to be in the working directory, and `static-dxc` requires the `static-dxc` crate feature to be enabled. Otherwise, it will fall back to `fxc`.
- `WGPU_GLES_MINOR_VERSION` with the minor OpenGL ES 3 version number to request (`0`, `1`, `2` or `automatic`).
- `WGPU_ALLOW_UNDERLYING_NONCOMPLIANT_ADAPTER` with a boolean whether non-compliant drivers are enumerated (`0` for false, `1` for true).

When running the CTS, use the variables `DENO_WEBGPU_ADAPTER_NAME`, `DENO_WEBGPU_BACKEND`, `DENO_WEBGPU_POWER_PREFERENCE`.

## Testing

We have multiple methods of testing, each of which tests different qualities about wgpu. We automatically run our tests on CI. The current state of CI testing:

| Platform/Backend | Tests              | Notes                 |
| ---------------- | ------------------ | --------------------- |
| Windows/DX12     | :heavy_check_mark: | using WARP            |
| Windows/OpenGL   | :heavy_check_mark: | using llvmpipe        |
| MacOS/Metal      | :heavy_check_mark: | using hardware runner |
| Linux/Vulkan     | :heavy_check_mark: | using lavapipe        |
| Linux/OpenGL ES  | :heavy_check_mark: | using llvmpipe        |
| Chrome/WebGL     | :heavy_check_mark: | using swiftshader     |
| Chrome/WebGPU    | :x:                | not set up            |

### Core Test Infrastructure

We use a tool called [`cargo nextest`](https://github.com/nextest-rs/nextest) to run our tests.
To install it, run `cargo install cargo-nextest`.

To run the test suite:

```
cargo xtask test
```

To run the test suite on WebGL (currently incomplete):

```
cd wgpu
wasm-pack test --headless --chrome --no-default-features --features webgl --workspace
```

This will automatically run the tests using a packaged browser. Remove `--headless` to run the tests with whatever browser you wish at `http://localhost:8000`.

If you are a user and want a way to help contribute to wgpu, we always need more help writing test cases.

### WebGPU Conformance Test Suite

WebGPU includes a Conformance Test Suite to validate that implementations are
working correctly. We run cases from the CTS against wgpu using
[Deno](https://deno.com/). A [default list of enabled
tests](./cts_runner/test.lst) is automatically run on pull requests in CI.

To run the default set of CTS tests locally, run:

```
cargo xtask cts
```

You can also specify a test selector on the command line:

```
cargo xtask cts &#039;webgpu:api,operation,command_buffer,basic:*&#039;
```

Or supply your own test list in a file:

```
cargo xtask cts -f your_tests.lst
```

To find the full list of tests, go to the
[web version of the CTS](https://gpuweb.github.io/cts/standalone/?runnow=0&amp;worker=0&amp;debug=0&amp;q=webgpu:*).

The version of the CTS used by `cargo xtask cts` is specified in
[`cts_runner/revision.txt`](./cts_runner/revision.txt).

## Tracking the WebGPU and WGSL draft specifications

The `wgpu` crate is meant to be an idiomatic Rust translation of the [WebGPU API][webgpu spec].
That specification, along with its shading language, [WGSL][wgsl spec],
are both still in the &quot;Working Draft&quot; phase,
and while the general outlines are stable,
details change frequently.
Until the specification is stabilized, the `wgpu` crate and the version of WGSL it implements
will likely differ from what is specified,
as the implementation catches up.

Exactly which WGSL features `wgpu` supports depends on how you are using it:

- When running as native code, `wgpu` uses the [Naga][naga] crate
  to translate WGSL code into the shading language of your platform&#039;s native GPU API.
  Naga has [a milestone][naga wgsl milestone]
  for catching up to the WGSL specification,
  but in general, there is no up-to-date summary
  of the differences between Naga and the WGSL spec.

- When running in a web browser (by compilation to WebAssembly)
  without the `&quot;webgl&quot;` feature enabled,
  `wgpu` relies on the browser&#039;s own WebGPU implementation.
  WGSL shaders are simply passed through to the browser,
  so that determines which WGSL features you can use.

- When running in a web browser with `wgpu`&#039;s `&quot;webgl&quot;` feature enabled,
  `wgpu` uses Naga to translate WGSL programs into GLSL.
  This uses the same version of Naga as if you were running `wgpu` as native code.

[webgpu spec]: https://www.w3.org/TR/webgpu/
[wgsl spec]: https://gpuweb.github.io/gpuweb/wgsl/
[naga]: https://github.com/gfx-rs/naga/
[naga wgsl milestone]: https://github.com/gfx-rs/naga/milestone/4

## Coordinate Systems

wgpu uses the coordinate systems of D3D and Metal:

| Render                                              | Texture                                               |
| --------------------------------------------------- | ----------------------------------------------------- |
| ![render_coordinates](./docs/render_coordinates.png) | ![texture_coordinates](./docs/texture_coordinates.png) |
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[get-convex/convex-backend]]></title>
            <link>https://github.com/get-convex/convex-backend</link>
            <guid>https://github.com/get-convex/convex-backend</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:44 GMT</pubDate>
            <description><![CDATA[The open-source reactive database for app developers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/get-convex/convex-backend">get-convex/convex-backend</a></h1>
            <p>The open-source reactive database for app developers</p>
            <p>Language: Rust</p>
            <p>Stars: 6,802</p>
            <p>Forks: 363</p>
            <p>Stars today: 62 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://static.convex.dev/logo/convex-logo-light.svg&quot; width=&quot;600&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://static.convex.dev/logo/convex-logo.svg&quot; width=&quot;600&quot;&gt;
  &lt;img alt=&quot;Convex logo&quot; src=&quot;https://static.convex.dev/logo/convex-logo.svg&quot; width=&quot;600&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;

[Convex](https://convex.dev) is the open-source reactive database designed to
make life easy for web app developers, whether human or LLM. Fetch data and
perform business logic with strong consistency by writing pure TypeScript.

Convex provides a database, a place to write your server functions, and client
libraries. It makes it easy to build and scale dynamic live-updating apps.
[Read the docs to learn more](https://docs.convex.dev/understanding/).

Development of the Convex backend is led by the Convex team. We
[welcome bug fixes](./CONTRIBUTING.md) and
[love receiving feedback](https://discord.gg/convex). We keep this repository
synced with any internal development work within a handful of days.

## Getting Started

Visit our [documentation](https://docs.convex.dev/) to learn more about Convex
and follow our getting started guides.

The easiest way to build with Convex is through our
[cloud platform](https://www.convex.dev/plans), which includes a generous free
tier and lets you focus on building your application without worrying about
infrastructure. Many small applications and side-projects can operate entirely
on the free tier with zero cost and zero maintenance.

## Self Hosting

The self-hosted product includes most features of the cloud product, including
the dashboard and CLI. Self-hosted Convex works well with a variety of tools
including Neon, Fly.io, Vercel, Netlify, RDS, Sqlite, Postgres, and more.

You can either use Docker (recommended) or a prebuilt binary to self host
Convex. Check out our [self-hosting guide](./self-hosted/README.md) for detailed
instructions. Community support for self-hosting is available in the
`#self-hosted` channel on [Discord](https://discord.gg/convex).

## Community &amp; Support

- Join our [Discord community](https://discord.gg/convex) for help and
  discussions.
- Report issues when building and using the open source Convex backend through
  [GitHub Issues](https://github.com/get-convex/convex-backend/issues)

## Building from source

See [BUILD.md](./BUILD.md).

## Disclaimers

- If you choose to self-host, we recommend following the self-hosting guide. If
  you are instead building from source, make sure to change your instance secret
  and admin key from the defaults in the repo.
- Convex is battle tested most thoroughly on Linux and Mac. On Windows, it has
  less experience. If you run into issues, please message us on
  [Discord](https://convex.dev/community) in the `#self-hosted` channel.
- Convex self-hosted builds contain a beacon to help Convex improve the product.
  The information is minimal and anonymous and helpful to Convex, but if you
  really want to disable it, you can set the `--disable-beacon` flag on the
  backend binary. The beacon&#039;s messages print in the log and only include
  - A random identifier for your deployment (not used elsewhere)
  - Migration version of your database
  - Git rev of the backend
  - Uptime of the backend

## Repository layout

- `crates/` contains Rust code

  - Main binary
    - `local_backend/` is an application server on top of the `Runtime`. This is
      the serving edge for the Convex cloud.

- `npm-packages/` contains both our public and internal TypeScript packages.
  - Internal packages
    - `udf-runtime/` sets up the user-defined functions JS environment for
      queries and mutations
    - `udf-tests/` is a collection of functions used in testing the isolate
      layer
    - `system-udfs/` contains functions used by the Convex system e.g. the CLI
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[noir-lang/noir]]></title>
            <link>https://github.com/noir-lang/noir</link>
            <guid>https://github.com/noir-lang/noir</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:43 GMT</pubDate>
            <description><![CDATA[Noir is a domain specific language for zero knowledge proofs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/noir-lang/noir">noir-lang/noir</a></h1>
            <p>Noir is a domain specific language for zero knowledge proofs</p>
            <p>Language: Rust</p>
            <p>Stars: 1,153</p>
            <p>Forks: 320</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;./noir-logo.png&quot; alt=&quot;The Noir Programming Language&quot; width=&quot;35%&quot;&gt;
  &lt;/picture&gt;

[Website][Noir] | [Getting started] | [Documentation] | [Contributing]
&lt;/div&gt;



# The Noir Programming Language

[![Non-deterministic fuzz tests](https://github.com/noir-lang/noir/actions/workflows/nightly-fuzz-test.yml/badge.svg)](https://github.com/noir-lang/noir/actions/workflows/nightly-fuzz-test.yml)

Noir is a Domain Specific Language for SNARK proving systems. It has been designed to use any ACIR compatible proving system.

**This implementation is in early development. It has not been reviewed or audited. It is not suitable to be used in production. Expect bugs!**

## Quick Start

Read the [installation section][Getting started] from the [Noir docs][Documentation].

Once you have read through the documentation, you can visit [Awesome Noir](https://github.com/noir-lang/awesome-noir) to run some of the examples that others have created.

## Getting Help

Join the Noir [forum][Forum] or [Discord][Discord]

## Contributing

See [CONTRIBUTING.md][CONTRIBUTING].

## Future Work

The current focus is to gather as much feedback as possible while in the alpha phase. The main focuses of Noir are _safety_ and _developer experience_. If you find a feature that does not seem to be in line with these goals, please open an issue!

## Minimum Rust version

This workspace&#039;s minimum supported rustc version is 1.85.0.

## License

Noir is free and open source. It is distributed under a dual license. (MIT/APACHE)

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in this repository by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.

[Noir]: https://www.noir-lang.org/
[Getting Started]: https://noir-lang.org/docs/getting_started/quick_start/
[Forum]: https://forum.aztec.network/c/noir
[Discord]: https://discord.gg/JtqzkdeQ6G
[Documentation]: https://noir-lang.org/docs/
[Contributing]: CONTRIBUTING.md
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[louis-e/arnis]]></title>
            <link>https://github.com/louis-e/arnis</link>
            <guid>https://github.com/louis-e/arnis</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:42 GMT</pubDate>
            <description><![CDATA[Generate any location from the real world in Minecraft Java Edition with a high level of detail.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/louis-e/arnis">louis-e/arnis</a></h1>
            <p>Generate any location from the real world in Minecraft Java Edition with a high level of detail.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,681</p>
            <p>Forks: 556</p>
            <p>Stars today: 71 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://github.com/louis-e/arnis/blob/main/gitassets/banner.png?raw=true&quot; width=&quot;100%&quot; alt=&quot;Banner&quot;&gt;

# Arnis [![CI Build Status](https://github.com/louis-e/arnis/actions/workflows/ci-build.yml/badge.svg)](https://github.com/louis-e/arnis/actions) [&lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/louis-e/arnis&quot; /&gt;](https://github.com/louis-e/arnis/releases) [&lt;img alt=&quot;GitHub Downloads (all assets, all releases&quot; src=&quot;https://img.shields.io/github/downloads/louis-e/arnis/total&quot; /&gt;](https://github.com/louis-e/arnis/releases) [![Download here](https://img.shields.io/badge/Download-here-green)](https://github.com/louis-e/arnis/releases) [![Discord](https://img.shields.io/discord/1326192999738249267?label=Discord&amp;color=%237289da)](https://discord.gg/mA2g69Fhxq)

Arnis creates complex and accurate Minecraft Java Edition worlds that reflect real-world geography, topography, and architecture.

This free and open source project is designed to handle large-scale geographic data from the real world and generate detailed Minecraft worlds. The algorithm processes geospatial data from OpenStreetMap as well as elevation data to create an accurate Minecraft representation of terrain and architecture.
Generate your hometown, big cities, and natural landscapes with ease!

![Minecraft Preview](https://raw.githubusercontent.com/louis-e/arnis/refs/heads/main/gitassets/preview.jpg)
&lt;i&gt;This Github page is the official project website. Do not download Arnis from any other website.&lt;/i&gt;

## :keyboard: Usage
&lt;img width=&quot;60%&quot; src=&quot;https://github.com/louis-e/arnis/blob/main/gitassets/gui.png?raw=true&quot;&gt;&lt;br&gt;
Download the [latest release](https://github.com/louis-e/arnis/releases/) or [compile](#trophy-open-source) the project on your own.

Choose your area on the map using the rectangle tool and select your Minecraft world - then simply click on &lt;i&gt;Start Generation&lt;/i&gt;!
Additionally, you can customize various generation settings, such as world scale, spawn point, or building interior generation.

## 📚 Documentation

&lt;img src=&quot;https://github.com/louis-e/arnis/blob/main/gitassets/documentation.png?raw=true&quot; width=&quot;100%&quot; alt=&quot;Banner&quot;&gt;

Full documentation is available in the [GitHub Wiki](https://github.com/louis-e/arnis/wiki/), covering topics such as technical explanations, FAQs, contribution guidelines and roadmaps.

## :trophy: Open Source
#### Key objectives of this project
- **Modularity**: Ensure that all components (e.g., data fetching, processing, and world generation) are cleanly separated into distinct modules for better maintainability and scalability.
- **Performance Optimization**: We aim to keep a good performance and speed of the world generation process.
- **Comprehensive Documentation**: Detailed in-code documentation for a clear structure and logic.
- **User-Friendly Experience**: Focus on making the project easy to use for end users.
- **Cross-Platform Support**: We want this project to run smoothly on Windows, macOS, and Linux.

#### How to contribute
This project is open source and welcomes contributions from everyone! Whether you&#039;re interested in fixing bugs, improving performance, adding new features, or enhancing documentation, your input is valuable. Simply fork the repository, make your changes, and submit a pull request. Please respect the above mentioned key objectives. Contributions of all levels are appreciated, and your efforts help improve this tool for everyone.

Command line Build: ```cargo run --no-default-features -- --terrain --path=&quot;C:/YOUR_PATH/.minecraft/saves/worldname&quot; --bbox=&quot;min_lat,min_lng,max_lat,max_lng&quot;```&lt;br&gt;
GUI Build: ```cargo run```&lt;br&gt;

After your pull request was merged, I will take care of regularly creating update releases which will include your changes.

## :star: Star History

&lt;a href=&quot;https://star-history.com/#louis-e/arnis&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=louis-e/arnis&amp;Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=louis-e/arnis&amp;Date&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=louis-e/arnis&amp;Date&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## :newspaper: Academic &amp; Press Recognition

&lt;img src=&quot;https://github.com/louis-e/arnis/blob/main/gitassets/recognition.png?raw=true&quot; width=&quot;100%&quot; alt=&quot;Banner&quot;&gt;

Arnis has been recognized in various academic and press publications after gaining a lot of attention in December 2024.

[Floodcraft: Game-based Interactive Learning Environment using Minecraft for Flood Mitigation and Preparedness for K-12 Education](https://www.researchgate.net/publication/384644535_Floodcraft_Game-based_Interactive_Learning_Environment_using_Minecraft_for_Flood_Mitigation_and_Preparedness_for_K-12_Education)

[Hackaday: Bringing OpenStreetMap Data into Minecraft](https://hackaday.com/2024/12/30/bringing-openstreetmap-data-into-minecraft/)

[TomsHardware: Minecraft Tool Lets You Create Scale Replicas of Real-World Locations](https://www.tomshardware.com/video-games/pc-gaming/minecraft-tool-lets-you-create-scale-replicas-of-real-world-locations-arnis-uses-geospatial-data-from-openstreetmap-to-generate-minecraft-maps)

[XDA Developers: Hometown Minecraft Map: Arnis](https://www.xda-developers.com/hometown-minecraft-map-arnis/)

## :copyright: License Information
Copyright (c) 2022-2025 Louis Erbkamm (louis-e)

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.[^3]

Download Arnis only from the official source (https://github.com/louis-e/arnis/). Every other website providing a download and claiming to be affiliated with the project is unofficial and may be malicious.

The logo was made by @nxfx21.


[^1]: https://en.wikipedia.org/wiki/OpenStreetMap

[^2]: https://en.wikipedia.org/wiki/Arnis,_Germany

[^3]: https://github.com/louis-e/arnis/blob/main/LICENSE
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[huggingface/text-embeddings-inference]]></title>
            <link>https://github.com/huggingface/text-embeddings-inference</link>
            <guid>https://github.com/huggingface/text-embeddings-inference</guid>
            <pubDate>Thu, 28 Aug 2025 00:05:41 GMT</pubDate>
            <description><![CDATA[A blazing fast inference solution for text embeddings models]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/text-embeddings-inference">huggingface/text-embeddings-inference</a></h1>
            <p>A blazing fast inference solution for text embeddings models</p>
            <p>Language: Rust</p>
            <p>Stars: 3,947</p>
            <p>Forks: 299</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# Text Embeddings Inference

&lt;a href=&quot;https://github.com/huggingface/text-embeddings-inference&quot;&gt;
  &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/huggingface/text-embeddings-inference?style=social&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://huggingface.github.io/text-embeddings-inference&quot;&gt;
  &lt;img alt=&quot;Swagger API documentation&quot; src=&quot;https://img.shields.io/badge/API-Swagger-informational&quot;&gt;
&lt;/a&gt;

A blazing fast inference solution for text embeddings models.

Benchmark for [BAAI/bge-base-en-v1.5](https://huggingface.co/BAAI/bge-base-en-v1.5) on an Nvidia A10 with a sequence
length of 512 tokens:

&lt;p&gt;
  &lt;img src=&quot;assets/bs1-lat.png&quot; width=&quot;400&quot; /&gt;
  &lt;img src=&quot;assets/bs1-tp.png&quot; width=&quot;400&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;img src=&quot;assets/bs32-lat.png&quot; width=&quot;400&quot; /&gt;
  &lt;img src=&quot;assets/bs32-tp.png&quot; width=&quot;400&quot; /&gt;
&lt;/p&gt;

&lt;/div&gt;

## Table of contents

- [Get Started](#get-started)
    - [Supported Models](#supported-models)
    - [Docker](#docker)
    - [Docker Images](#docker-images)
    - [API Documentation](#api-documentation)
    - [Using a private or gated model](#using-a-private-or-gated-model)
    - [Air gapped deployment](#air-gapped-deployment)
    - [Using Re-rankers models](#using-re-rankers-models)
    - [Using Sequence Classification models](#using-sequence-classification-models)
    - [Using SPLADE pooling](#using-splade-pooling)
    - [Distributed Tracing](#distributed-tracing)
    - [gRPC](#grpc)
- [Local Install](#local-install)
- [Docker Build](#docker-build)
    - [Apple M1/M2 Arm](#apple-m1m2-arm64-architectures)
- [Examples](#examples)

Text Embeddings Inference (TEI) is a toolkit for deploying and serving open source text embeddings and sequence
classification models. TEI enables high-performance extraction for the most popular models, including FlagEmbedding,
Ember, GTE and E5. TEI implements many features such as:

* No model graph compilation step
* Metal support for local execution on Macs
* Small docker images and fast boot times. Get ready for true serverless!
* Token based dynamic batching
* Optimized transformers code for inference using [Flash Attention](https://github.com/HazyResearch/flash-attention),
  [Candle](https://github.com/huggingface/candle)
  and [cuBLASLt](https://docs.nvidia.com/cuda/cublas/#using-the-cublaslt-api)
* [Safetensors](https://github.com/huggingface/safetensors) weight loading
* [ONNX](https://github.com/onnx/onnx) weight loading
* Production ready (distributed tracing with Open Telemetry, Prometheus metrics)

## Get Started

### Supported Models

#### Text Embeddings

Text Embeddings Inference currently supports Nomic, BERT, CamemBERT, XLM-RoBERTa models with absolute positions, JinaBERT
model with Alibi positions and Mistral, Alibaba GTE, Qwen2 models with Rope positions, MPNet, ModernBERT, and Qwen3.

Below are some examples of the currently supported models:

| MTEB Rank | Model Size          | Model Type  | Model ID                                                                                         |
|-----------|---------------------|-------------|--------------------------------------------------------------------------------------------------|
| 2         | 8B (Very Expensive) | Qwen3       | [Qwen/Qwen3-Embedding-8B](https://hf.co/Qwen/Qwen3-Embedding-8B)                                 |
| 4         | 0.6B                | Qwen3       | [Qwen/Qwen3-Embedding-0.6B](https://hf.co/Qwen/Qwen3-Embedding-0.6B)                             |
| 6         | 7B (Very Expensive) | Qwen2       | [Alibaba-NLP/gte-Qwen2-7B-instruct](https://hf.co/Alibaba-NLP/gte-Qwen2-7B-instruct)             |
| 7         | 0.5B                | XLM-RoBERTa | [intfloat/multilingual-e5-large-instruct](https://hf.co/intfloat/multilingual-e5-large-instruct) |
| 14        | 1.5B (Expensive)    | Qwen2       | [Alibaba-NLP/gte-Qwen2-1.5B-instruct](https://hf.co/Alibaba-NLP/gte-Qwen2-1.5B-instruct)         |
| 17        | 7B (Very Expensive) | Mistral     | [Salesforce/SFR-Embedding-2_R](https://hf.co/Salesforce/SFR-Embedding-2_R)                       |
| 34        | 0.5B                | XLM-RoBERTa | [Snowflake/snowflake-arctic-embed-l-v2.0](https://hf.co/Snowflake/snowflake-arctic-embed-l-v2.0) |
| 40        | 0.3B                | Alibaba GTE | [Snowflake/snowflake-arctic-embed-m-v2.0](https://hf.co/Snowflake/snowflake-arctic-embed-m-v2.0) |
| 51        | 0.3B                | Bert        | [WhereIsAI/UAE-Large-V1](https://hf.co/WhereIsAI/UAE-Large-V1)                                   |
| N/A       | 0.4B                | Alibaba GTE | [Alibaba-NLP/gte-large-en-v1.5](https://hf.co/Alibaba-NLP/gte-large-en-v1.5)                     |
| N/A       | 0.4B                | ModernBERT  | [answerdotai/ModernBERT-large](https://hf.co/answerdotai/ModernBERT-large)                       |
| N/A       | 0.3B                | NomicBert   | [nomic-ai/nomic-embed-text-v2-moe](https://hf.co/nomic-ai/nomic-embed-text-v2-moe)               |
| N/A       | 0.1B                | NomicBert   | [nomic-ai/nomic-embed-text-v1](https://hf.co/nomic-ai/nomic-embed-text-v1)                       |
| N/A       | 0.1B                | NomicBert   | [nomic-ai/nomic-embed-text-v1.5](https://hf.co/nomic-ai/nomic-embed-text-v1.5)                   |
| N/A       | 0.1B                | JinaBERT    | [jinaai/jina-embeddings-v2-base-en](https://hf.co/jinaai/jina-embeddings-v2-base-en)             |
| N/A       | 0.1B                | JinaBERT    | [jinaai/jina-embeddings-v2-base-code](https://hf.co/jinaai/jina-embeddings-v2-base-code)         |
| N/A       | 0.1B                | MPNet       | [sentence-transformers/all-mpnet-base-v2](https://hf.co/sentence-transformers/all-mpnet-base-v2) |

To explore the list of best performing text embeddings models, visit the
[Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard).

#### Sequence Classification and Re-Ranking

Text Embeddings Inference currently supports CamemBERT, and XLM-RoBERTa Sequence Classification models with absolute positions.

Below are some examples of the currently supported models:

| Task               | Model Type  | Model ID                                                                                                        |
|--------------------|-------------|-----------------------------------------------------------------------------------------------------------------|
| Re-Ranking         | XLM-RoBERTa | [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large)                                       |
| Re-Ranking         | XLM-RoBERTa | [BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base)                                         |
| Re-Ranking         | GTE         | [Alibaba-NLP/gte-multilingual-reranker-base](https://huggingface.co/Alibaba-NLP/gte-multilingual-reranker-base) |
| Re-Ranking         | ModernBert  | [Alibaba-NLP/gte-reranker-modernbert-base](https://huggingface.co/Alibaba-NLP/gte-reranker-modernbert-base) |
| Sentiment Analysis | RoBERTa     | [SamLowe/roberta-base-go_emotions](https://huggingface.co/SamLowe/roberta-base-go_emotions)                     |

### Docker

```shell
model=Qwen/Qwen3-Embedding-0.6B
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8 --model-id $model
```

And then you can make requests like

```bash
curl 127.0.0.1:8080/embed \
    -X POST \
    -d &#039;{&quot;inputs&quot;:&quot;What is Deep Learning?&quot;}&#039; \
    -H &#039;Content-Type: application/json&#039;
```

**Note:** To use GPUs, you need to install
the [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html).
NVIDIA drivers on your machine need to be compatible with CUDA version 12.2 or higher.

To see all options to serve your models:

```console
$ text-embeddings-router --help
Text Embedding Webserver

Usage: text-embeddings-router [OPTIONS]

Options:
      --model-id &lt;MODEL_ID&gt;
          The name of the model to load. Can be a MODEL_ID as listed on &lt;https://hf.co/models&gt; like `BAAI/bge-large-en-v1.5`. Or it can be a local directory containing the necessary files as saved by `save_pretrained(...)` methods of transformers

          [env: MODEL_ID=]
          [default: BAAI/bge-large-en-v1.5]

      --revision &lt;REVISION&gt;
          The actual revision of the model if you&#039;re referring to a model on the hub. You can use a specific commit id or a branch like `refs/pr/2`

          [env: REVISION=]

      --tokenization-workers &lt;TOKENIZATION_WORKERS&gt;
          Optionally control the number of tokenizer workers used for payload tokenization, validation and truncation. Default to the number of CPU cores on the machine

          [env: TOKENIZATION_WORKERS=]

      --dtype &lt;DTYPE&gt;
          The dtype to be forced upon the model

          [env: DTYPE=]
          [possible values: float16, float32]

      --pooling &lt;POOLING&gt;
          Optionally control the pooling method for embedding models.

          If `pooling` is not set, the pooling configuration will be parsed from the model `1_Pooling/config.json` configuration.

          If `pooling` is set, it will override the model pooling configuration

          [env: POOLING=]

          Possible values:
          - cls:        Select the CLS token as embedding
          - mean:       Apply Mean pooling to the model embeddings
          - splade:     Apply SPLADE (Sparse Lexical and Expansion) to the model embeddings. This option is only available if the loaded model is a `ForMaskedLM` Transformer model
          - last-token: Select the last token as embedding

      --max-concurrent-requests &lt;MAX_CONCURRENT_REQUESTS&gt;
          The maximum amount of concurrent requests for this particular deployment. Having a low limit will refuse clients requests instead of having them wait for too long and is usually good to handle backpressure correctly

          [env: MAX_CONCURRENT_REQUESTS=]
          [default: 512]

      --max-batch-tokens &lt;MAX_BATCH_TOKENS&gt;
          **IMPORTANT** This is one critical control to allow maximum usage of the available hardware.

          This represents the total amount of potential tokens within a batch.

          For `max_batch_tokens=1000`, you could fit `10` queries of `total_tokens=100` or a single query of `1000` tokens.

          Overall this number should be the largest possible until the model is compute bound. Since the actual memory overhead depends on the model implementation, text-embeddings-inference cannot infer this number automatically.

          [env: MAX_BATCH_TOKENS=]
          [default: 16384]

      --max-batch-requests &lt;MAX_BATCH_REQUESTS&gt;
          Optionally control the maximum number of individual requests in a batch

          [env: MAX_BATCH_REQUESTS=]

      --max-client-batch-size &lt;MAX_CLIENT_BATCH_SIZE&gt;
          Control the maximum number of inputs that a client can send in a single request

          [env: MAX_CLIENT_BATCH_SIZE=]
          [default: 32]

      --auto-truncate
          Automatically truncate inputs that are longer than the maximum supported size

          Unused for gRPC servers

          [env: AUTO_TRUNCATE=]

      --default-prompt-name &lt;DEFAULT_PROMPT_NAME&gt;
          The name of the prompt that should be used by default for encoding. If not set, no prompt will be applied.

          Must be a key in the `sentence-transformers` configuration `prompts` dictionary.

          For example if ``default_prompt_name`` is &quot;query&quot; and the ``prompts`` is {&quot;query&quot;: &quot;query: &quot;, ...}, then the sentence &quot;What is the capital of France?&quot; will be encoded as &quot;query: What is the capital of France?&quot; because the prompt text will be prepended before any text to encode.

          The argument &#039;--default-prompt-name &lt;DEFAULT_PROMPT_NAME&gt;&#039; cannot be used with &#039;--default-prompt &lt;DEFAULT_PROMPT&gt;`

          [env: DEFAULT_PROMPT_NAME=]

      --default-prompt &lt;DEFAULT_PROMPT&gt;
          The prompt that should be used by default for encoding. If not set, no prompt will be applied.

          For example if ``default_prompt`` is &quot;query: &quot; then the sentence &quot;What is the capital of France?&quot; will be encoded as &quot;query: What is the capital of France?&quot; because the prompt text will be prepended before any text to encode.

          The argument &#039;--default-prompt &lt;DEFAULT_PROMPT&gt;&#039; cannot be used with &#039;--default-prompt-name &lt;DEFAULT_PROMPT_NAME&gt;`

          [env: DEFAULT_PROMPT=]

      --dense-path &lt;DENSE_PATH&gt;
          Optionally, define the path to the Dense module required for some embedding models.

          Some embedding models require an extra `Dense` module which contains a single Linear layer and an activation function. By default, those `Dense` modules are stored under the `2_Dense` directory, but there might be cases where different `Dense` modules are provided, to convert the pooled embeddings into different dimensions, available as `2_Dense_&lt;dims&gt;` e.g. https://huggingface.co/NovaSearch/stella_en_400M_v5.

          Note that this argument is optional, only required to be set if the path to the `Dense` module is other than `2_Dense`. And it also applies when leveraging the `candle` backend.

          [env: DENSE_PATH=]
          [default: 2_Dense]

      --hf-token &lt;HF_TOKEN&gt;
          Your Hugging Face Hub token

          [env: HF_TOKEN=]

      --hostname &lt;HOSTNAME&gt;
          The IP address to listen on

          [env: HOSTNAME=]
          [default: 0.0.0.0]

      -p, --port &lt;PORT&gt;
          The port to listen on

          [env: PORT=]
          [default: 3000]

      --uds-path &lt;UDS_PATH&gt;
          The name of the unix socket some text-embeddings-inference backends will use as they communicate internally with gRPC

          [env: UDS_PATH=]
          [default: /tmp/text-embeddings-inference-server]

      --huggingface-hub-cache &lt;HUGGINGFACE_HUB_CACHE&gt;
          The location of the huggingface hub cache. Used to override the location if you want to provide a mounted disk for instance

          [env: HUGGINGFACE_HUB_CACHE=]

      --payload-limit &lt;PAYLOAD_LIMIT&gt;
          Payload size limit in bytes

          Default is 2MB

          [env: PAYLOAD_LIMIT=]
          [default: 2000000]

      --api-key &lt;API_KEY&gt;
          Set an api key for request authorization.

          By default the server responds to every request. With an api key set, the requests must have the Authorization header set with the api key as Bearer token.

          [env: API_KEY=]

      --json-output
          Outputs the logs in JSON format (useful for telemetry)

          [env: JSON_OUTPUT=]

      --disable-spans
          [env: DISABLE_SPANS=]

      --otlp-endpoint &lt;OTLP_ENDPOINT&gt;
          The grpc endpoint for opentelemetry. Telemetry is sent to this endpoint as OTLP over gRPC. e.g. `http://localhost:4317`

          [env: OTLP_ENDPOINT=]

      --otlp-service-name &lt;OTLP_SERVICE_NAME&gt;
          The service name for opentelemetry. e.g. `text-embeddings-inference.server`

          [env: OTLP_SERVICE_NAME=]
          [default: text-embeddings-inference.server]

      --prometheus-port &lt;PROMETHEUS_PORT&gt;
          The Prometheus port to listen on

          [env: PROMETHEUS_PORT=]
          [default: 9000]

      --cors-allow-origin &lt;CORS_ALLOW_ORIGIN&gt;
          Unused for gRPC servers

          [env: CORS_ALLOW_ORIGIN=]

  -h, --help
          Print help (see a summary with &#039;-h&#039;)

  -V, --version
          Print version
```

### Docker Images

Text Embeddings Inference ships with multiple Docker images that you can use to target a specific backend:

| Architecture                        | Image                                                                   |
|-------------------------------------|-------------------------------------------------------------------------|
| CPU                                 | ghcr.io/huggingface/text-embeddings-inference:cpu-1.8                   |
| Volta                               | NOT SUPPORTED                                                           |
| Turing (T4, RTX 2000 series, ...)   | ghcr.io/huggingface/text-embeddings-inference:turing-1.8 (experimental) |
| Ampere 80 (A100, A30)               | ghcr.io/huggingface/text-embeddings-inference:1.8                       |
| Ampere 86 (A10, A40, ...)           | ghcr.io/huggingface/text-embeddings-inference:86-1.8                    |
| Ada Lovelace (RTX 4000 series, ...) | ghcr.io/huggingface/text-embeddings-inference:89-1.8                    |
| Hopper (H100)                       | ghcr.io/huggingface/text-embeddings-inference:hopper-1.8 (experimental) |

**Warning**: Flash Attention is turned off by default for the Turing image as it suffers from precision issues.
You can turn Flash Attention v1 ON by using the `USE_FLASH_ATTENTION=True` environment variable.

### API documentation

You can consult the OpenAPI documentation of the `text-embeddings-inference` REST API using the `/docs` route.
The Swagger UI is also available
at: [https://huggingface.github.io/text-embeddings-inference](https://huggingface.github.io/text-embeddings-inference).

### Using a private or gated model

You have the option to utilize the `HF_TOKEN` environment variable for configuring the token employed by
`text-embeddings-inference`. This allows you to gain access to protected resources.

For example:

1. Go to https://huggingface.co/settings/tokens
2. Copy your cli READ token
3. Export `HF_TOKEN=&lt;your cli READ token&gt;`

or with Docker:

```shell
model=&lt;your private model&gt;
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run
token=&lt;your cli READ token&gt;

docker run --gpus all -e HF_TOKEN=$token -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8 --model-id $model
```

### Air gapped deployment

To deploy Text Embeddings Inference in an air-gapped environment, first download the weights and then mount them inside
the container using a volume.

For example:

```shell
# (Optional) create a `models` directory
mkdir models
cd models

# Make sure you have git-lfs installed (https://git-lfs.com)
git lfs install
git clone https://huggingface.co/Qwen/Qwen3-Embedding-0.6B

# Set the models directory as the volume path
volume=$PWD

# Mount the models directory inside the container with a volume and set the model ID
docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8 --model-id /data/Qwen3-Embedding-0.6B
```

### Using Re-rankers models

`text-embeddings-inference` v0.4.0 added support for CamemBERT, RoBERTa, XLM-RoBERTa, and GTE Sequence Classification models.
Re-rankers models are Sequence Classification cross-encoders models with a single class that scores the similarity
between a query and a text.

See [this blogpost](https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83) by
the LlamaIndex team to understand how you can use re-rankers models in your RAG pipeline to improve
downstream performance.

```shell
model=BAAI/bge-reranker-large
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.8 --model-id $model
```

And then you can rank the similarity between a query and a list of texts with:

```bash
curl 127.0.0.1:8080/rerank \
    -X POST \
    -d &#039;{&quot;query&quot;: &quot;What is Deep Learning?&quot;, &quot;texts&quot;: [&quot;Deep Learning is not...&quot;, &quot;Deep learning is...&quot;]}&#039; \
    -H &#039;Content-Type: application/json&#039;
```

### Using Sequence Classification models

You can also use classic Sequence Classification models like `SamLowe/roberta-base-go_emotions`:

```shell
model=SamLowe/roberta-base-go_emotions
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run



... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>