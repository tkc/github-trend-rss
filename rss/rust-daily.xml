<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Fri, 12 Sep 2025 00:05:33 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[tokio-rs/tokio]]></title>
            <link>https://github.com/tokio-rs/tokio</link>
            <guid>https://github.com/tokio-rs/tokio</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[A runtime for writing reliable asynchronous applications with Rust. Provides I/O, networking, scheduling, timers, ...]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tokio-rs/tokio">tokio-rs/tokio</a></h1>
            <p>A runtime for writing reliable asynchronous applications with Rust. Provides I/O, networking, scheduling, timers, ...</p>
            <p>Language: Rust</p>
            <p>Stars: 29,553</p>
            <p>Forks: 2,756</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># Tokio

A runtime for writing reliable, asynchronous, and slim applications with
the Rust programming language. It is:

* **Fast**: Tokio&#039;s zero-cost abstractions give you bare-metal
  performance.

* **Reliable**: Tokio leverages Rust&#039;s ownership, type system, and
  concurrency model to reduce bugs and ensure thread safety.

* **Scalable**: Tokio has a minimal footprint, and handles backpressure
  and cancellation naturally.

[![Crates.io][crates-badge]][crates-url]
[![MIT licensed][mit-badge]][mit-url]
[![Build Status][actions-badge]][actions-url]
[![Discord chat][discord-badge]][discord-url]

[crates-badge]: https://img.shields.io/crates/v/tokio.svg
[crates-url]: https://crates.io/crates/tokio
[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg
[mit-url]: https://github.com/tokio-rs/tokio/blob/master/LICENSE
[actions-badge]: https://github.com/tokio-rs/tokio/workflows/CI/badge.svg
[actions-url]: https://github.com/tokio-rs/tokio/actions?query=workflow%3ACI+branch%3Amaster
[discord-badge]: https://img.shields.io/discord/500028886025895936.svg?logo=discord&amp;style=flat-square
[discord-url]: https://discord.gg/tokio

[Website](https://tokio.rs) |
[Guides](https://tokio.rs/tokio/tutorial) |
[API Docs](https://docs.rs/tokio/latest/tokio) |
[Chat](https://discord.gg/tokio)

## Overview

Tokio is an event-driven, non-blocking I/O platform for writing
asynchronous applications with the Rust programming language. At a high
level, it provides a few major components:

* A multithreaded, work-stealing based task [scheduler].
* A reactor backed by the operating system&#039;s event queue (epoll, kqueue,
  IOCP, etc.).
* Asynchronous [TCP and UDP][net] sockets.

These components provide the runtime components necessary for building
an asynchronous application.

[net]: https://docs.rs/tokio/latest/tokio/net/index.html
[scheduler]: https://docs.rs/tokio/latest/tokio/runtime/index.html

## Example

A basic TCP echo server with Tokio.

Make sure you activated the full features of the tokio crate on Cargo.toml:

```toml
[dependencies]
tokio = { version = &quot;1.47.1&quot;, features = [&quot;full&quot;] }
```
Then, on your main.rs:

```rust,no_run
use tokio::net::TcpListener;
use tokio::io::{AsyncReadExt, AsyncWriteExt};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let listener = TcpListener::bind(&quot;127.0.0.1:8080&quot;).await?;

    loop {
        let (mut socket, _) = listener.accept().await?;

        tokio::spawn(async move {
            let mut buf = [0; 1024];

            // In a loop, read data from the socket and write the data back.
            loop {
                let n = match socket.read(&amp;mut buf).await {
                    // socket closed
                    Ok(0) =&gt; return,
                    Ok(n) =&gt; n,
                    Err(e) =&gt; {
                        eprintln!(&quot;failed to read from socket; err = {:?}&quot;, e);
                        return;
                    }
                };

                // Write the data back
                if let Err(e) = socket.write_all(&amp;buf[0..n]).await {
                    eprintln!(&quot;failed to write to socket; err = {:?}&quot;, e);
                    return;
                }
            }
        });
    }
}
```

More examples can be found [here][examples]. For a larger &quot;real world&quot; example, see the
[mini-redis] repository.

[examples]: https://github.com/tokio-rs/tokio/tree/master/examples
[mini-redis]: https://github.com/tokio-rs/mini-redis/

To see a list of the available features flags that can be enabled, check our
[docs][feature-flag-docs].

## Getting Help

First, see if the answer to your question can be found in the [Guides] or the
[API documentation]. If the answer is not there, there is an active community in
the [Tokio Discord server][chat]. We would be happy to try to answer your
question. You can also ask your question on [the discussions page][discussions].

[Guides]: https://tokio.rs/tokio/tutorial
[API documentation]: https://docs.rs/tokio/latest/tokio
[chat]: https://discord.gg/tokio
[discussions]: https://github.com/tokio-rs/tokio/discussions
[feature-flag-docs]: https://docs.rs/tokio/#feature-flags

## Contributing

:balloon: Thanks for your help improving the project! We are so happy to have
you! We have a [contributing guide][guide] to help you get involved in the Tokio
project.

[guide]: https://github.com/tokio-rs/tokio/blob/master/CONTRIBUTING.md

## Related Projects

In addition to the crates in this repository, the Tokio project also maintains
several other libraries, including:

* [`axum`]: A web application framework that focuses on ergonomics and modularity.

* [`hyper`]: A fast and correct HTTP/1.1 and HTTP/2 implementation for Rust.

* [`tonic`]: A gRPC over HTTP/2 implementation focused on high performance, interoperability, and flexibility.

* [`warp`]: A super-easy, composable, web server framework for warp speeds.

* [`tower`]: A library of modular and reusable components for building robust networking clients and servers.

* [`tracing`] (formerly `tokio-trace`): A framework for application-level tracing and async-aware diagnostics.

* [`mio`]: A low-level, cross-platform abstraction over OS I/O APIs that powers `tokio`.

* [`bytes`]: Utilities for working with bytes, including efficient byte buffers.

* [`loom`]: A testing tool for concurrent Rust code.

[`axum`]: https://github.com/tokio-rs/axum
[`warp`]: https://github.com/seanmonstar/warp
[`hyper`]: https://github.com/hyperium/hyper
[`tonic`]: https://github.com/hyperium/tonic
[`tower`]: https://github.com/tower-rs/tower
[`loom`]: https://github.com/tokio-rs/loom
[`tracing`]: https://github.com/tokio-rs/tracing
[`mio`]: https://github.com/tokio-rs/mio
[`bytes`]: https://github.com/tokio-rs/bytes

## Changelog

The Tokio repository contains multiple crates. Each crate has its own changelog.

 * `tokio` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio/CHANGELOG.md)
 * `tokio-util` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-util/CHANGELOG.md)
 * `tokio-stream` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-stream/CHANGELOG.md)
 * `tokio-macros` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-macros/CHANGELOG.md)
 * `tokio-test` - [view changelog](https://github.com/tokio-rs/tokio/blob/master/tokio-test/CHANGELOG.md)

## Supported Rust Versions

&lt;!--
When updating this, also update:
- .github/workflows/ci.yml
- CONTRIBUTING.md
- README.md
- tokio/README.md
- tokio/Cargo.toml
- tokio-util/Cargo.toml
- tokio-test/Cargo.toml
- tokio-stream/Cargo.toml
--&gt;

Tokio will keep a rolling MSRV (minimum supported rust version) policy of **at
least** 6 months. When increasing the MSRV, the new Rust version must have been
released at least six months ago. The current MSRV is 1.70.

Note that the MSRV is not increased automatically, and only as part of a minor
release. The MSRV history for past minor releases can be found below:

 * 1.39 to now  - Rust 1.70
 * 1.30 to 1.38 - Rust 1.63
 * 1.27 to 1.29 - Rust 1.56
 * 1.17 to 1.26 - Rust 1.49
 * 1.15 to 1.16 - Rust 1.46
 * 1.0 to 1.14 - Rust 1.45

Note that although we try to avoid the situation where a dependency transitively
increases the MSRV of Tokio, we do not guarantee that this does not happen.
However, every minor release will have some set of versions of dependencies that
works with the MSRV of that minor release.

## Release schedule

Tokio doesn&#039;t follow a fixed release schedule, but we typically make one minor
release each month. We make patch releases for bugfixes as necessary.

## Bug patching policy

For the purposes of making patch releases with bugfixes, we have designated
certain minor releases as LTS (long term support) releases. Whenever a bug
warrants a patch release with a fix for the bug, it will be backported and
released as a new patch release for each LTS minor version. Our current LTS
releases are:

 * `1.43.x` - LTS release until March 2026. (MSRV 1.70)
 * `1.47.x` - LTS release until September 2026. (MSRV 1.70)

Each LTS release will continue to receive backported fixes for at least a year.
If you wish to use a fixed minor release in your project, we recommend that you
use an LTS release.

To use a fixed minor version, you can specify the version with a tilde. For
example, to specify that you wish to use the newest `1.43.x` patch release, you
can use the following dependency specification:
```text
tokio = { version = &quot;~1.43&quot;, features = [...] }
```

### Previous LTS releases

 * `1.8.x` - LTS release until February 2022.
 * `1.14.x` - LTS release until June 2022.
 * `1.18.x` - LTS release until June 2023.
 * `1.20.x` - LTS release until September 2023.
 * `1.25.x` - LTS release until March 2024.
 * `1.32.x` - LTS release until September 2024.
 * `1.36.x` - LTS release until March 2025.
 * `1.38.x` - LTS release until July 2025.

## License

This project is licensed under the [MIT license].

[MIT license]: https://github.com/tokio-rs/tokio/blob/master/LICENSE

### Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Tokio by you, shall be licensed as MIT, without any additional
terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[qdrant/qdrant]]></title>
            <link>https://github.com/qdrant/qdrant</link>
            <guid>https://github.com/qdrant/qdrant</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qdrant/qdrant">qdrant/qdrant</a></h1>
            <p>Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/</p>
            <p>Language: Rust</p>
            <p>Stars: 25,851</p>
            <p>Forks: 1,808</p>
            <p>Stars today: 35 stars today</p>
            <h2>README</h2><pre>## How to interview using this template

Open ONLY the `shared/` folder within VSCode and in the Extensions Marketplace find `CodeTogether Live`. Install it.

Inside the extension, you&#039;ll have to click on &#039;Host New Session&#039; and then &#039;Start&#039;.

You now have a link in your clipboard, which you should share with the candidate.

Don&#039;t forget to run `npm run vite.dev` inside your editor terminal, since this is not currently possible from the browser editor (link) with the free version of the extension.

The locally running server will display localhost:5173 as well as a the project within the network, which the user can access remotely to see the SPA in action, something like: `10.5.52.144:5173`.

The candidate should be sharing their screen while they read and later approach the challenge!

## React Template（⚡️）

⚡️ A minimal React Vite starter template.

### Feature

- ⚡️ Fast - Build tools based on vite.
- 👻 Small - Based on the smallest runnable build.
- 💄 Prettier - Integrated Prettier to help you format the code.
- ✅ Safety - Https is enabled by default.
- 😎 Reliable - Integrated eslint and commitlint.
- 🤖 Intelligent - Integrated renovate to help you maintain the dependent version.

### Preview

[![qekup8.png](https://s1.ax1x.com/2022/03/20/qekup8.png)](https://imgtu.com/i/qekup8)

### Getting Started

```bash
npx degit lzm0x219/template-vite-react myapp

cd myapp

git init
```

#### Prerequisites

- `npm` and/or `pnpm` should be installed.
- `git` should be installed (recommended v2.4.11 or higher)

#### Available scripts

##### `npm run vite.dev`

Runs the app in development mode.
Open https://localhost:5173 to view it in the browser.

The page will automatically reload if you make changes to the code.
You will see the build errors and lint warnings in the console.

##### `npm run vite.build`

Builds the app for production to the `dist` folder.
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.

Your app is ready to be deployed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[firecracker-microvm/firecracker]]></title>
            <link>https://github.com/firecracker-microvm/firecracker</link>
            <guid>https://github.com/firecracker-microvm/firecracker</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Secure and fast microVMs for serverless computing.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/firecracker-microvm/firecracker">firecracker-microvm/firecracker</a></h1>
            <p>Secure and fast microVMs for serverless computing.</p>
            <p>Language: Rust</p>
            <p>Stars: 30,357</p>
            <p>Forks: 2,070</p>
            <p>Stars today: 31 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/fc_logo_full_transparent-bg_white-fg.png&quot;&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/images/fc_logo_full_transparent-bg.png&quot;&gt;
   &lt;img alt=&quot;Firecracker Logo Title&quot; width=&quot;750&quot; src=&quot;docs/images/fc_logo_full_transparent-bg.png&quot;&gt;
&lt;/picture&gt;

Our mission is to enable secure, multi-tenant, minimal-overhead execution of
container and function workloads.

Read more about the Firecracker Charter [here](CHARTER.md).

## What is Firecracker?

Firecracker is an open source virtualization technology that is purpose-built
for creating and managing secure, multi-tenant container and function-based
services that provide serverless operational models. Firecracker runs workloads
in lightweight virtual machines, called microVMs, which combine the security and
isolation properties provided by hardware virtualization technology with the
speed and flexibility of containers.

## Overview

The main component of Firecracker is a virtual machine monitor (VMM) that uses
the Linux Kernel Virtual Machine (KVM) to create and run microVMs. Firecracker
has a minimalist design. It excludes unnecessary devices and guest-facing
functionality to reduce the memory footprint and attack surface area of each
microVM. This improves security, decreases the startup time, and increases
hardware utilization. Firecracker has also been integrated in container
runtimes, for example
[Kata Containers](https://github.com/kata-containers/kata-containers) and
[Flintlock](https://github.com/liquidmetal-dev/flintlock).

Firecracker was developed at Amazon Web Services to accelerate the speed and
efficiency of services like [AWS Lambda](https://aws.amazon.com/lambda/) and
[AWS Fargate](https://aws.amazon.com/fargate/). Firecracker is open sourced
under [Apache version 2.0](LICENSE).

To read more about Firecracker, check out
[firecracker-microvm.io](https://firecracker-microvm.github.io).

## Getting Started

To get started with Firecracker, download the latest
[release](https://github.com/firecracker-microvm/firecracker/releases) binaries
or build it from source.

You can build Firecracker on any Unix/Linux system that has Docker running (we
use a development container) and `bash` installed, as follows:

```bash
git clone https://github.com/firecracker-microvm/firecracker
cd firecracker
tools/devtool build
toolchain=&quot;$(uname -m)-unknown-linux-musl&quot;
```

The Firecracker binary will be placed at
`build/cargo_target/${toolchain}/debug/firecracker`. For more information on
building, testing, and running Firecracker, go to the
[quickstart guide](docs/getting-started.md).

The overall security of Firecracker microVMs, including the ability to meet the
criteria for safe multi-tenant computing, depends on a well configured Linux
host operating system. A configuration that we believe meets this bar is
included in [the production host setup document](docs/prod-host-setup.md).

## Contributing

Firecracker is already running production workloads within AWS, but it&#039;s still
Day 1 on the journey guided by our [mission](CHARTER.md). There&#039;s a lot more to
build and we welcome all contributions.

To contribute to Firecracker, check out the development setup section in the
[getting started guide](docs/getting-started.md) and then the Firecracker
[contribution guidelines](CONTRIBUTING.md).

## Releases

New Firecracker versions are released via the GitHub repository
[releases](https://github.com/firecracker-microvm/firecracker/releases) page,
typically every two or three months. A history of changes is recorded in our
[changelog](CHANGELOG.md).

The Firecracker release policy is detailed [here](docs/RELEASE_POLICY.md).

## Design

Firecracker&#039;s overall architecture is described in
[the design document](docs/design.md).

## Features &amp; Capabilities

Firecracker consists of a single micro Virtual Machine Manager process that
exposes an API endpoint to the host once started. The API is
[specified in OpenAPI format](src/firecracker/swagger/firecracker.yaml). Read
more about it in the [API docs](docs/api_requests).

The **API endpoint** can be used to:

- Configure the microvm by:
  - Setting the number of vCPUs (the default is 1).
  - Setting the memory size (the default is 128 MiB).
  - Configuring a [CPU template](docs/cpu_templates/cpu-templates.md).
- Add one or more network interfaces to the microVM.
- Add one or more read-write or read-only disks to the microVM, each represented
  by a file-backed block device.
- Trigger a block device re-scan while the guest is running. This enables the
  guest OS to pick up size changes to the block device&#039;s backing file.
- Change the backing file for a block device, before or after the guest boots.
- Configure rate limiters for virtio devices which can limit the bandwidth,
  operations per second, or both.
- Configure the logging and metric system.
- `[BETA]` Configure the data tree of the guest-facing metadata service. The
  service is only available to the guest if this resource is configured.
- Add a [vsock socket](docs/vsock.md) to the microVM.
- Add a [entropy device](docs/entropy.md) to the microVM.
- Start the microVM using a given kernel image, root file system, and boot
  arguments.
- [x86_64 only] Stop the microVM.

**Built-in Capabilities**:

- Demand fault paging and CPU oversubscription enabled by default.
- Advanced, thread-specific seccomp filters for enhanced security.
- [Jailer](docs/jailer.md) process for starting Firecracker in production
  scenarios; applies a cgroup/namespace isolation barrier and then drops
  privileges.

## Tested platforms

We test all combinations of:

| Instance                               | Host OS &amp; Kernel | Guest Rootfs | Guest Kernel |
| :------------------------------------- | :--------------- | :----------- | :----------- |
| m5n.metal (Intel Cascade Lake)         | al2 linux_5.10   | ubuntu 24.04 | linux_5.10   |
| m6i.metal (Intel Ice Lake)             | al2023 linux_6.1 |              | linux_6.1    |
| m7i.metal-24xl (Intel Sapphire Rapids) |                  |              |              |
| m7i.metal-48xl (Intel Sapphire Rapids) |                  |              |              |
| m6a.metal (AMD Milan)                  |                  |              |              |
| m7a.metal-48xl (AMD Genoa)             |                  |              |              |
| m6g.metal (Graviton 2)                 |                  |              |              |
| m7g.metal (Graviton 3)                 |                  |              |              |
| m8g.metal-24xl (Graviton 4)            |                  |              |              |
| m8g.metal-48xl (Graviton 4)            |                  |              |              |

## Known issues and Limitations

- The `pl031` RTC device on aarch64 does not support interrupts, so guest
  programs which use an RTC alarm (e.g. `hwclock`) will not work.

## Performance

Firecracker&#039;s performance characteristics are listed as part of the
[specification documentation](SPECIFICATION.md). All specifications are a part
of our commitment to supporting container and function workloads in serverless
operational models, and are therefore enforced via continuous integration
testing.

## Policy for Security Disclosures

The security of Firecracker is our top priority. If you suspect you have
uncovered a vulnerability, contact us privately, as outlined in our
[security policy document](SECURITY.md); we will immediately prioritize your
disclosure.

## FAQ &amp; Contact

Frequently asked questions are collected in our [FAQ doc](FAQ.md).

You can get in touch with the Firecracker community in the following ways:

- Security-related issues, see our [security policy document](SECURITY.md).
- Chat with us on our
  [Slack workspace](https://join.slack.com/t/firecracker-microvm/shared_invite/zt-2tc0mfxpc-tU~HYAYSzLDl5XGGJU3YIg)
  _Note: most of the maintainers are on a European time zone._
- Open a GitHub issue in this repository.
- Email the maintainers at
  [firecracker-maintainers@amazon.com](mailto:firecracker-maintainers@amazon.com).

When communicating within the Firecracker community, please mind our
[code of conduct](CODE_OF_CONDUCT.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[bytecodealliance/wasmtime]]></title>
            <link>https://github.com/bytecodealliance/wasmtime</link>
            <guid>https://github.com/bytecodealliance/wasmtime</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[A lightweight WebAssembly runtime that is fast, secure, and standards-compliant]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytecodealliance/wasmtime">bytecodealliance/wasmtime</a></h1>
            <p>A lightweight WebAssembly runtime that is fast, secure, and standards-compliant</p>
            <p>Language: Rust</p>
            <p>Stars: 16,860</p>
            <p>Forks: 1,502</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;h1&gt;&lt;code&gt;wasmtime&lt;/code&gt;&lt;/h1&gt;

  &lt;p&gt;
    &lt;strong&gt;A standalone runtime for
    &lt;a href=&quot;https://webassembly.org/&quot;&gt;WebAssembly&lt;/a&gt;&lt;/strong&gt;
  &lt;/p&gt;

  &lt;strong&gt;A &lt;a href=&quot;https://bytecodealliance.org/&quot;&gt;Bytecode Alliance&lt;/a&gt; project&lt;/strong&gt;

  &lt;p&gt;
    &lt;a href=&quot;https://github.com/bytecodealliance/wasmtime/actions?query=workflow%3ACI&quot;&gt;&lt;img src=&quot;https://github.com/bytecodealliance/wasmtime/workflows/CI/badge.svg&quot; alt=&quot;build status&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://bytecodealliance.zulipchat.com/#narrow/stream/217126-wasmtime&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/zulip-join_chat-brightgreen.svg&quot; alt=&quot;zulip chat&quot; /&gt;&lt;/a&gt;
    &lt;img src=&quot;https://img.shields.io/badge/rustc-stable+-green.svg&quot; alt=&quot;supported rustc stable&quot; /&gt;
    &lt;a href=&quot;https://docs.rs/wasmtime&quot;&gt;&lt;img src=&quot;https://docs.rs/wasmtime/badge.svg&quot; alt=&quot;Documentation Status&quot; /&gt;&lt;/a&gt;
  &lt;/p&gt;

  &lt;h3&gt;
    &lt;a href=&quot;https://bytecodealliance.github.io/wasmtime/&quot;&gt;Guide&lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://bytecodealliance.github.io/wasmtime/contributing.html&quot;&gt;Contributing&lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://wasmtime.dev/&quot;&gt;Website&lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://bytecodealliance.zulipchat.com/#narrow/stream/217126-wasmtime&quot;&gt;Chat&lt;/a&gt;
  &lt;/h3&gt;
&lt;/div&gt;

## Installation

The Wasmtime CLI can be installed on Linux and macOS (locally) with a small install
script:

```console
curl https://wasmtime.dev/install.sh -sSf | bash
```
This script installs into `$WASMTIME_HOME` (defaults to `$HOME/.wasmtime`), and executable is placed in `$WASMTIME_HOME/bin`.

After running the install script above, follow the on-screen instructions.

Windows or otherwise interested users can download installers and
binaries directly from the [GitHub
Releases](https://github.com/bytecodealliance/wasmtime/releases) page.

For additional installation options, refer to the [online book CLI installation page](https://docs.wasmtime.dev/cli-install.html).

Documentation on Wasmtime&#039;s currently supported versions can be found [in the
online book
documentation](https://docs.wasmtime.dev/stability-release.html#current-versions).

## Example

If you&#039;ve got the [Rust compiler
installed](https://www.rust-lang.org/tools/install) then you can take some Rust
source code:

```rust
fn main() {
    println!(&quot;Hello, world!&quot;);
}
```

and compile it into a WebAssembly component with:

```console
rustup target add wasm32-wasip2
rustc hello.rs --target wasm32-wasip2
```

Once compiled, you can run your component:

```console
wasmtime hello.wasm
```

You should see the following output:

```text
Hello, world!
```

(Note: make sure you installed Rust using the [`rustup`][rustup] method in the official
instructions above, and do not have a copy of the Rust toolchain installed on
your system in some other way as well (e.g. the system package manager). Otherwise, the `rustup target add...`
command may not install the target for the correct copy of Rust.)

[rustup]: https://rustup.rs

## Features

* **Fast**. Wasmtime is built on the optimizing [Cranelift] code generator to
  quickly generate high-quality machine code either at runtime or
  ahead-of-time. Wasmtime is optimized for efficient instantiation, low-overhead
  calls between the embedder and wasm, and scalability of concurrent instances.

* **[Secure]**. Wasmtime&#039;s development is strongly focused on correctness and
  security. Building on top of Rust&#039;s runtime safety guarantees, each Wasmtime
  feature goes through careful review and consideration via an [RFC
  process]. Once features are designed and implemented, they undergo 24/7
  fuzzing donated by [Google&#039;s OSS Fuzz]. As features stabilize they become part
  of a [release][release policy], and when things go wrong we have a
  well-defined [security policy] in place to quickly mitigate and patch any
  issues. We follow best practices for defense-in-depth and integrate
  protections and mitigations for issues like Spectre. Finally, we&#039;re working to
  push the state-of-the-art by collaborating with academic researchers to
  formally verify critical parts of Wasmtime and Cranelift.

* **[Configurable]**. Wasmtime uses sensible defaults, but can also be
  configured to provide more fine-grained control over things like CPU and
  memory consumption. Whether you want to run Wasmtime in a tiny environment or
  on massive servers with many concurrent instances, we&#039;ve got you covered.

* **[WASI]**. Wasmtime supports a rich set of APIs for interacting with the host
  environment through the [WASI standard](https://wasi.dev).

* **[Standards Compliant]**. Wasmtime passes the [official WebAssembly test
  suite](https://github.com/WebAssembly/testsuite), implements the [official C
  API of wasm](https://github.com/WebAssembly/wasm-c-api), and implements
  [future proposals to WebAssembly](https://github.com/WebAssembly/proposals) as
  well. Wasmtime developers are intimately engaged with the WebAssembly
  standards process all along the way too.

[Wasmtime]: https://github.com/bytecodealliance/wasmtime
[Cranelift]: https://cranelift.dev/
[Google&#039;s OSS Fuzz]: https://google.github.io/oss-fuzz/
[security policy]: https://bytecodealliance.org/security
[RFC process]: https://github.com/bytecodealliance/rfcs
[release policy]: https://docs.wasmtime.dev/stability-release.html
[Secure]: https://docs.wasmtime.dev/security.html
[Configurable]: https://docs.rs/wasmtime/latest/wasmtime/struct.Config.html
[WASI]: https://docs.rs/wasmtime-wasi/latest/wasmtime_wasi/
[Standards Compliant]: https://docs.wasmtime.dev/stability-tiers.html

## Language Support

You can use Wasmtime from a variety of different languages through embeddings of
the implementation.

Languages supported by the Bytecode Alliance:

* **[Rust]** - the [`wasmtime` crate]
* **[C]** - the [`wasm.h`, `wasi.h`, and `wasmtime.h` headers][c-headers], [CMake](crates/c-api/CMakeLists.txt)
* **C++** - the [`wasmtime.hh` header][c-headers]
* **[Python]** - the [`wasmtime` PyPI package]
* **[.NET]** - the [`Wasmtime` NuGet package]
* **[Go]** - the [`wasmtime-go` repository]
* **[Ruby]** - the [`wasmtime` gem]

Languages supported by the community:

* **[Elixir]** - the [`wasmex` hex package]
* **Perl** - the [`Wasm` Perl package&#039;s `Wasm::Wasmtime`]

[Rust]: https://bytecodealliance.github.io/wasmtime/lang-rust.html
[C]: https://bytecodealliance.github.io/wasmtime/lang-c.html
[`wasmtime` crate]: https://crates.io/crates/wasmtime
[c-headers]: https://bytecodealliance.github.io/wasmtime/c-api/
[Python]: https://bytecodealliance.github.io/wasmtime/lang-python.html
[`wasmtime` PyPI package]: https://pypi.org/project/wasmtime/
[.NET]: https://bytecodealliance.github.io/wasmtime/lang-dotnet.html
[`Wasmtime` NuGet package]: https://www.nuget.org/packages/Wasmtime
[Go]: https://bytecodealliance.github.io/wasmtime/lang-go.html
[`wasmtime-go` repository]: https://pkg.go.dev/github.com/bytecodealliance/wasmtime-go
[Ruby]: https://bytecodealliance.github.io/wasmtime/lang-ruby.html
[`wasmtime` gem]: https://rubygems.org/gems/wasmtime
[Elixir]: https://docs.wasmtime.dev/lang-elixir.html
[`wasmex` hex package]: https://hex.pm/packages/wasmex
[`Wasm` Perl package&#039;s `Wasm::Wasmtime`]: https://metacpan.org/pod/Wasm::Wasmtime

## Documentation

[📚 Read the Wasmtime guide here! 📚][guide]

The [wasmtime guide][guide] is the best starting point to learn about what
Wasmtime can do for you or help answer your questions about Wasmtime. If you&#039;re
curious in contributing to Wasmtime, [it can also help you do
that][contributing]!

[contributing]: https://bytecodealliance.github.io/wasmtime/contributing.html
[guide]: https://bytecodealliance.github.io/wasmtime

---

It&#039;s Wasmtime.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[wezterm/wezterm]]></title>
            <link>https://github.com/wezterm/wezterm</link>
            <guid>https://github.com/wezterm/wezterm</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[A GPU-accelerated cross-platform terminal emulator and multiplexer written by @wez and implemented in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wezterm/wezterm">wezterm/wezterm</a></h1>
            <p>A GPU-accelerated cross-platform terminal emulator and multiplexer written by @wez and implemented in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 21,798</p>
            <p>Forks: 993</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre># Wez&#039;s Terminal

&lt;img height=&quot;128&quot; alt=&quot;WezTerm Icon&quot; src=&quot;https://raw.githubusercontent.com/wezterm/wezterm/main/assets/icon/wezterm-icon.svg&quot; align=&quot;left&quot;&gt; *A GPU-accelerated cross-platform terminal emulator and multiplexer written by &lt;a href=&quot;https://github.com/wez&quot;&gt;@wez&lt;/a&gt; and implemented in &lt;a href=&quot;https://www.rust-lang.org/&quot;&gt;Rust&lt;/a&gt;*

User facing docs and guide at: https://wezterm.org/

![Screenshot](docs/screenshots/two.png)

*Screenshot of wezterm on macOS, running vim*

## Installation

https://wezterm.org/installation

## Getting help

This is a spare time project, so please bear with me.  There are a couple of channels for support:

* You can use the [GitHub issue tracker](https://github.com/wezterm/wezterm/issues) to see if someone else has a similar issue, or to file a new one.
* Start or join a thread in our [GitHub Discussions](https://github.com/wezterm/wezterm/discussions); if you have general
  questions or want to chat with other wezterm users, you&#039;re welcome here!
* There is a [Matrix room via Element.io](https://app.element.io/#/room/#wezterm:matrix.org)
  for (potentially!) real time discussions.

The GitHub Discussions and Element/Gitter rooms are better suited for questions
than bug reports, but don&#039;t be afraid to use whichever you are most comfortable
using and we&#039;ll work it out.

## Supporting the Project

If you use and like WezTerm, please consider sponsoring it: your support helps
to cover the fees required to maintain the project and to validate the time
spent working on it!

[Read more about sponsoring](https://wezterm.org/sponsor.html).

* [![Sponsor WezTerm](https://img.shields.io/github/sponsors/wez?label=Sponsor%20WezTerm&amp;logo=github&amp;style=for-the-badge)](https://github.com/sponsors/wez)
* [Patreon](https://patreon.com/WezFurlong)
* [Ko-Fi](https://ko-fi.com/wezfurlong)
* [Liberapay](https://liberapay.com/wez)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[stalwartlabs/stalwart]]></title>
            <link>https://github.com/stalwartlabs/stalwart</link>
            <guid>https://github.com/stalwartlabs/stalwart</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[All-in-one Mail & Collaboration server. Secure, scalable and fluent in every protocol (IMAP, JMAP, SMTP, CalDAV, CardDAV, WebDAV).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stalwartlabs/stalwart">stalwartlabs/stalwart</a></h1>
            <p>All-in-one Mail & Collaboration server. Secure, scalable and fluent in every protocol (IMAP, JMAP, SMTP, CalDAV, CardDAV, WebDAV).</p>
            <p>Language: Rust</p>
            <p>Stars: 9,563</p>
            <p>Forks: 487</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://stalw.art&quot;&gt;
    &lt;img src=&quot;./img/logo-red.svg&quot; height=&quot;150&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  Secure, scalable mail &amp; collaboration server with comprehensive protocol support 🛡️ &lt;br/&gt;(IMAP, JMAP, SMTP, CalDAV, CardDAV, WebDAV)
&lt;/h3&gt;

&lt;br&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/stalwartlabs/stalwart/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/stalwartlabs/stalwart/ci.yml?style=flat-square&quot; alt=&quot;continuous integration&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.gnu.org/licenses/agpl-3.0&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-AGPL_v3-blue.svg?label=license&amp;style=flat-square&quot; alt=&quot;License: AGPL v3&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://stalw.art/docs/install/get-started&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/read_the-docs-red?style=flat-square&quot; alt=&quot;Documentation&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mastodon.social/@stalwartlabs&quot;&gt;&lt;img src=&quot;https://img.shields.io/mastodon/follow/109929667531941122?style=flat-square&amp;logo=mastodon&amp;color=%236364ff&amp;label=Follow%20on%20Mastodon&quot; alt=&quot;Mastodon&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://twitter.com/stalwartlabs&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/stalwartlabs?style=flat-square&amp;logo=x&amp;label=Follow%20on%20Twitter&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.com/servers/stalwart-923615863037390889&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/923615863037390889?label=Join%20Discord&amp;logo=discord&amp;style=flat-square&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.reddit.com/r/stalwartlabs/&quot;&gt;&lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/stalwartlabs?label=Join%20%2Fr%2Fstalwartlabs&amp;logo=reddit&amp;style=flat-square&quot; alt=&quot;Reddit&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## Features

**Stalwart** is an open-source mail &amp; collaboration server with JMAP, IMAP4, POP3, SMTP, CalDAV, CardDAV and WebDAV support and a wide range of modern features. It is written in Rust and designed to be secure, fast, robust and scalable.

Key features:

- **Email** server with complete protocol support:
  - JMAP: 
    * [JMAP for Mail](https://datatracker.ietf.org/doc/html/rfc8621) server.
    * [JMAP for Sieve Scripts](https://www.ietf.org/archive/id/draft-ietf-jmap-sieve-22.html).
    * [WebSocket](https://datatracker.ietf.org/doc/html/rfc8887), [Blob Management](https://www.rfc-editor.org/rfc/rfc9404.html) and [Quotas](https://www.rfc-editor.org/rfc/rfc9425.html) extensions.
  - IMAP:
    * [IMAP4rev2](https://datatracker.ietf.org/doc/html/rfc9051) and [IMAP4rev1](https://datatracker.ietf.org/doc/html/rfc3501) server.
    * [ManageSieve](https://datatracker.ietf.org/doc/html/rfc5804) server.
    * Numerous [extensions](https://stalw.art/docs/development/rfcs#imap4-and-extensions) supported.
  - POP3:
    - [POP3](https://datatracker.ietf.org/doc/html/rfc1939) server.
    - [STLS](https://datatracker.ietf.org/doc/html/rfc2595) and [SASL](https://datatracker.ietf.org/doc/html/rfc5034) support as well as other [extensions](https://datatracker.ietf.org/doc/html/rfc2449).
  - SMTP:
    * SMTP server with built-in [DMARC](https://datatracker.ietf.org/doc/html/rfc7489), [DKIM](https://datatracker.ietf.org/doc/html/rfc6376), [SPF](https://datatracker.ietf.org/doc/html/rfc7208) and [ARC](https://datatracker.ietf.org/doc/html/rfc8617) support for message authentication.
    * Strong transport security through [DANE](https://datatracker.ietf.org/doc/html/rfc6698), [MTA-STS](https://datatracker.ietf.org/doc/html/rfc8461) and [SMTP TLS](https://datatracker.ietf.org/doc/html/rfc8460) reporting.
    * Inbound throttling and filtering with granular configuration rules, sieve scripting, MTA hooks and milter integration.
    * Distributed virtual queues with delayed delivery, priority delivery, quotas, routing rules and throttling support.
    * Envelope rewriting and message modification.
- **Collaboration** server:
  - Calendaring with [CalDAV](https://datatracker.ietf.org/doc/html/rfc4791), [CalDAV Scheduling](https://datatracker.ietf.org/doc/html/rfc6638) and e-mail alarms support.
  - Contact management with [CardDAV](https://datatracker.ietf.org/doc/html/rfc6352) support.
  - File storage with [WebDAV](https://datatracker.ietf.org/doc/html/rfc4918) support.
  - Sharing with [WebDAV ACL](https://datatracker.ietf.org/doc/html/rfc3744) support for fine-grained access control.
- **Spam** and **Phishing** built-in filter:
  - Comprehensive set of filtering **rules** on par with popular solutions.
  - LLM-driven spam filtering and message analysis.
  - Statistical **spam classifier** with automatic training capabilities and address book integration.
  - DNS Blocklists (**DNSBLs**) checking of IP addresses, domains, and hashes.
  - Collaborative digest-based spam filtering with **Pyzor**.
  - **Phishing** protection against homographic URL attacks, sender spoofing and other techniques.
  - Trusted **reply** tracking to recognize and prioritize genuine e-mail replies.
  - Sender **reputation** monitoring by IP address, ASN, domain and email address.
  - **Greylisting** to temporarily defer unknown senders.
  - **Spam traps** to set up decoy email addresses that catch and analyze spam.
- **Flexible**:
  - Pluggable storage backends with **RocksDB**, **FoundationDB**, **PostgreSQL**, **mySQL**, **SQLite**, **S3-Compatible**, **Azure**, **Redis** and **ElasticSearch** support.
  - Full-text search available in 17 languages.
  - Sieve scripting language with support for all [registered extensions](https://www.iana.org/assignments/sieve-extensions/sieve-extensions.xhtml).
  - Email aliases, mailing lists, subaddressing and catch-all addresses support.
  - Automatic account configuration and discovery with [autoconfig](https://www.ietf.org/id/draft-bucksch-autoconfig-02.html) and [autodiscover](https://learn.microsoft.com/en-us/exchange/architecture/client-access/autodiscover?view=exchserver-2019). 
  - Multi-tenancy support with domain and tenant isolation.
  - Disk quotas per user and tenant.
- **Secure and robust**:
  - Encryption at rest with **S/MIME** or **OpenPGP**.
  - Automatic TLS certificate provisioning with [ACME](https://datatracker.ietf.org/doc/html/rfc8555) using `TLS-ALPN-01`, `DNS-01` or `HTTP-01` challenges.
  - Automated blocking of IP addresses that attack, abuse or scan the server for exploits.
  - Rate limiting.
  - Security audited (read the [report](https://stalw.art/blog/security-audit)).
  - Memory safe (thanks to Rust).
- **Scalable and fault-tolerant**:
  - Designed to handle growth seamlessly, from small setups to large-scale deployments of thousands of nodes.
  - Built with **fault tolerance** and **high availability** in mind, recovers from hardware or software failures with minimal operational impact. 
  - Peer-to-peer cluster coordination or with **Kafka**, **Redpanda**, **NATS** or **Redis**.
  - **Kubernetes**, **Apache Mesos** and **Docker Swarm** support for automated scaling and container orchestration.
  - Read replicas, sharded blob storage and in-memory data stores for high performance and low latency.
- **Authentication and Authorization**:
  - **OpenID Connect** authentication.
  - OAuth 2.0 authorization with [authorization code](https://www.rfc-editor.org/rfc/rfc8628) and [device authorization](https://www.rfc-editor.org/rfc/rfc8628) flows.
  - **LDAP**, **OIDC**, **SQL** or built-in authentication backend support.
  - Two-factor authentication with Time-based One-Time Passwords (`2FA-TOTP`) 
  - Application passwords (App Passwords).
  - Roles and permissions.
  - Access Control Lists (ACLs).
- **Observability**:
  - Logging and tracing with **OpenTelemetry**, journald, log files and console support.
  - Metrics with **OpenTelemetry** and **Prometheus** integration.
  - Webhooks for event-driven automation.
  - Alerts with email and webhook notifications.
  - Live tracing and metrics.
- **Web-based administration**:
  - Dashboard with real-time statistics and monitoring.
  - Account, domain, group and mailing list management.
  - SMTP queue management for messages and outbound DMARC and TLS reports.
  - Report visualization interface for received DMARC, TLS-RPT and Failure (ARF) reports.
  - Configuration of every aspect of the mail server.
  - Log viewer with search and filtering capabilities.
  - Self-service portal for password reset and encryption-at-rest key management.

## Screenshots

&lt;img src=&quot;./img/screencast-setup.gif&quot;&gt;

## Presentation

**Want a deeper dive?** Need to explain to your boss why Stalwart is the perfect fit? Whether you&#039;re evaluating options, making a case to your team, or simply curious about how it all works under the hood, these slides walk you through the key features, architecture, and benefits of Stalwart. Browse the [slides](https://stalw.art/slides) to see what makes it stand out.

## Get Started

Install Stalwart on your server by following the instructions for your platform:

- [Linux / MacOS](https://stalw.art/docs/install/platform/linux)
- [Windows](https://stalw.art/docs/install/platform/windows)
- [Docker](https://stalw.art/docs/install/platform/docker)

All documentation is available at [stalw.art/docs](https://stalw.art/docs/install/get-started).

## Support

If you are having problems running Stalwart, you found a bug or just have a question, do not hesitate to reach us on [GitHub Discussions](https://github.com/stalwartlabs/stalwart/discussions), [Reddit](https://www.reddit.com/r/stalwartlabs) or [Discord](https://discord.com/servers/stalwart-923615863037390889).
Additionally you may purchase an [Enterprise License](https://stalw.art/enterprise) to obtain priority support from Stalwart Labs LLC.

## Sponsorship

Your support is crucial in helping us continue to improve the project, add new features, and maintain the highest level of quality. By [becoming a sponsor](https://opencollective.com/stalwart), you help fund the development and future of Stalwart. As a thank-you, sponsors who contribute $5 per month or more will automatically receive a [Enterprise edition](https://stalw.art/enterprise/) license. And, sponsors who contribute $30 per month or more, also have access to [Premium Support](https://stalw.art/support) from Stalwart Labs.

These are some of our open-source sponsors:

&lt;!-- sponsors --&gt;&lt;a href=&quot;https://github.com/kbjr&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;kbjr.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: James Brumond&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/MailRoute&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;MailRoute.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: MailRoute, Inc.&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/JAMflow-Cloud&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;JAMflow-Cloud.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: JAMflow Cloud&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/starsong-consulting&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;starsong-consulting.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Starsong GmbH&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/mingfu-design&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;mingfu-design.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Ming Fu Design Ltd. 明孚設計有限公司&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/tamwuff&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;tamwuff.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: Tamino&quot; /&gt;&lt;/a&gt;&lt;a href=&quot;https://github.com/panascais&quot;&gt;&lt;img src=&quot;https:&amp;#x2F;&amp;#x2F;github.com&amp;#x2F;panascais.png&quot; width=&quot;60px&quot; alt=&quot;User avatar: panascais&quot; /&gt;&lt;/a&gt;&lt;!-- sponsors --&gt;

&lt;br/&gt;If you would like to support our work, please consider [becoming a sponsor](https://opencollective.com/stalwart).

## Roadmap

- [ ] JMAP for Calendars, Contacts and File Storage support
- [ ] Webmail client

See the [enhancement requests](https://github.com/stalwartlabs/stalwart/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3Aenhancement) page for a full list of proposed features by the community.

## Funding

Part of the development of this project was funded through:

- [NGI0 Entrust Fund](https://nlnet.nl/entrust), a fund established by [NLnet](https://nlnet.nl/) with financial support from the European Commission&#039;s [Next Generation Internet](https://ngi.eu/) programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 101069594.
- [NGI Zero Core](https://nlnet.nl/NGI0/), a fund established by [NLnet](https://nlnet.nl/) with financial support from the European Commission&#039;s programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 101092990.

If you find the project useful you can help by [becoming a sponsor](https://opencollective.com/stalwart). Thank you!

## License

This project is dual-licensed under the **GNU Affero General Public License v3.0** (AGPL-3.0; as published by the Free Software Foundation) and the **Stalwart Enterprise License v1 (SELv1)**:

- The [GNU Affero General Public License v3.0](./LICENSES/AGPL-3.0-only.txt) is a free software license that ensures your freedom to use, modify, and distribute the software, with the condition that any modified versions of the software must also be distributed under the same license. 
- The [Stalwart Enterprise License v1 (SELv1)](./LICENSES/LicenseRef-SEL.txt) is a proprietary license designed for commercial use. It offers additional features and greater flexibility for businesses that do not wish to comply with the AGPL-3.0 license requirements. 

Each file in this project contains a license notice at the top, indicating the applicable license(s). The license notice follows the [REUSE guidelines](https://reuse.software/) to ensure clarity and consistency. The full text of each license is available in the [LICENSES](./LICENSES/) directory.

## Copyright

Copyright (C) 2020, Stalwart Labs LLC
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[j178/prek]]></title>
            <link>https://github.com/j178/prek</link>
            <guid>https://github.com/j178/prek</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[⚡ Better `pre-commit`, re-engineered in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/j178/prek">j178/prek</a></h1>
            <p>⚡ Better `pre-commit`, re-engineered in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 1,254</p>
            <p>Forks: 45</p>
            <p>Stars today: 84 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# prek

&lt;img width=&quot;220&quot; alt=&quot;prek&quot; src=&quot;./docs/assets/logo.png&quot; /&gt;

[![CI](https://github.com/j178/prek/actions/workflows/ci.yml/badge.svg)](https://github.com/j178/prek/actions/workflows/ci.yml)
[![codecov](https://codecov.io/github/j178/prek/graph/badge.svg?token=MP6TY24F43)](https://codecov.io/github/j178/prek)
[![GitHub Downloads](https://img.shields.io/github/downloads/j178/prek/total?logo=github)](https://github.com/j178/prek/releases)
[![PyPI Downloads](https://img.shields.io/pypi/dm/prek?logo=python)](https://pepy.tech/projects/prek)
[![Discord](https://img.shields.io/discord/1403581202102878289?logo=discord)](https://discord.gg/3NRJUqJz86)

&lt;/div&gt;

[pre-commit](https://pre-commit.com/) is a framework to run hooks written in many languages, and it manages the
language toolchain and dependencies for running the hooks.

*prek* is a reimagined version of pre-commit, built in Rust.
It is designed to be a faster, dependency-free and drop-in alternative for it,
while also providing some additional long-requested features.

&gt; [!WARNING]
&gt; prek is not production-ready yet. Some subcommands and languages are not implemented. See the current gaps for drop-in parity: [TODO](https://prek.j178.dev/todo/).
&gt;
&gt; It&#039;s already being adopted by [some projects](#who-is-using-prek), please give it a try - we&#039;d love your feedback!

## Features

- 🚀 A single binary with no dependencies, does not require Python or any other runtime.
- ⚡ About [10x faster](https://prek.j178.dev/benchmark/) than `pre-commit` and uses only a third of disk space.
- 🔄 Fully compatible with the original pre-commit configurations and hooks.
- 🏗️ Built-in support for monorepos (i.e. [workspace mode](https://prek.j178.dev/workspace/)).
- 🐍 Integration with [`uv`](https://github.com/astral-sh/uv) for managing Python virtual environments and dependencies.
- 🛠️ Improved toolchain installations for Python, Node.js, Go, Rust and Ruby, shared between hooks.
- 📦 [Built-in](https://prek.j178.dev/builtin/) Rust-native implementation of some common hooks.

## How to migrate

prek is designed as a drop-in replacement:

- [Install prek](#installation)
- Replace `pre-commit` with `prek` in your commands
- Your existing `.pre-commit-config.yaml` works unchanged

```console
$ prek run
trim trailing whitespace.................................................Passed
fix end of files.........................................................Passed
typos....................................................................Passed
cargo fmt................................................................Passed
cargo clippy.............................................................Passed
```

For configuring `.pre-commit-config.yaml` and writing hooks, you can refer to the [pre-commit documentation](https://pre-commit.com/) as prek is fully compatible with it.

## Why prek?

### prek is way faster

- It is about [10x faster](https://prek.j178.dev/benchmark/) than `pre-commit` and uses only a third of disk space.
- It redesigned how hook environments and toolchains are managed, they are all shared between hooks, which reduces the disk space usage and speeds up the installation process.
- Repositories are cloned in parallel, and hooks are installed in parallel if their dependencies are disjoint.
- It uses [`uv`](https://github.com/astral-sh/uv) for creating Python virtualenvs and installing dependencies, which is known for its speed and efficiency.
- It implements some common hooks in Rust, [built in prek](https://prek.j178.dev/builtin/), which are faster than their Python counterparts.

### prek provides a better user experience

- No need to install Python or any other runtime, just download a single binary.
- No hassle with your Python version or virtual environments, prek automatically installs the required Python version and creates a virtual environment for you.
- Built-in support for workspaces (or monorepos), each subproject can have its own `.pre-commit-config.yaml` file.
- `prek run` has some nifty improvements over `pre-commit run`, such as:
    - `prek run --directory &lt;dir&gt;` runs hooks for files in the specified directory, no need to use `git ls-files -- &lt;dir&gt; | xargs pre-commit run --files` anymore.
    - `prek run --last-commit` runs hooks for files changed in the last commit.
    - `prek run [HOOK] [HOOK]` selects and runs multiple hooks.
- `prek list` command lists all available hooks, their ids, and descriptions, providing a better overview of the configured hooks.
- prek provides shell completions for `prek run &lt;hook_id&gt;` command, making it easier to run specific hooks without remembering their ids.

For more detailed improvements prek offers, take a look at [Difference from pre-commit](https://prek.j178.dev/diff/).

## Who is using prek?

prek is pretty new, but it is already being used or recommend by some projects and organizations:

- [Airflow](https://github.com/apache/airflow/issues/44995)
- [PDM](https://github.com/pdm-project/pdm/pull/3593)
- [basedpyright](https://github.com/DetachHead/basedpyright/pull/1413)
- [OpenLineage](https://github.com/OpenLineage/OpenLineage/pull/3965)
- [Authlib](https://github.com/authlib/authlib/pull/804)

## Installation

&lt;details&gt;
&lt;summary&gt;Standalone installer&lt;/summary&gt;

prek provides a standalone installer script to download and install the tool,

On Linux and macOS:

```bash
curl --proto &#039;=https&#039; --tlsv1.2 -LsSf https://github.com/j178/prek/releases/download/v0.2.0-alpha.5/prek-installer.sh | sh
```

On Windows:

```powershell
powershell -ExecutionPolicy ByPass -c &quot;irm https://github.com/j178/prek/releases/download/v0.2.0-alpha.5/prek-installer.ps1 | iex&quot;
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;PyPI&lt;/summary&gt;

prek is published as Python binary wheel to PyPI, you can install it using `pip`, `uv` (recommended), or `pipx`:

```console
pip install prek

# or

uv tool install prek

# or

pipx install prek
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Homebrew&lt;/summary&gt;

```bash
brew install prek
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;mise&lt;/summary&gt;

To use prek with [mise](https://mise.jdx.dev):

```bash
mise use prek
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Cargo&lt;/summary&gt;

Build from source using Cargo (Rust 1.89+ is required):

```bash
cargo install --locked --git https://github.com/j178/prek
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;GitHub Releases&lt;/summary&gt;

prek release artifacts can be downloaded directly from the [GitHub releases](https://github.com/j178/prek/releases).
&lt;/details&gt;

If installed via the standalone installer, prek can update itself to the latest version:

```bash
prek self update
```

## Acknowledgements

This project is heavily inspired by the original [pre-commit](https://pre-commit.com/) tool, and it wouldn&#039;t be possible without the hard work
of the maintainers and contributors of that project.

And a special thanks to the [Astral](https://github.com/astral-sh) team for their remarkable projects, particularly [uv](https://github.com/astral-sh/uv),
from which I&#039;ve learned a lot on how to write efficient and idiomatic Rust code.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lancedb/lance]]></title>
            <link>https://github.com/lancedb/lance</link>
            <guid>https://github.com/lancedb/lance</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[Modern columnar data format for ML and LLMs implemented in Rust. Convert from parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lancedb/lance">lancedb/lance</a></h1>
            <p>Modern columnar data format for ML and LLMs implemented in Rust. Convert from parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..</p>
            <p>Language: Rust</p>
            <p>Stars: 5,342</p>
            <p>Forks: 459</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;

&lt;img width=&quot;257&quot; alt=&quot;Lance Logo&quot; src=&quot;https://user-images.githubusercontent.com/917119/199353423-d3e202f7-0269-411d-8ff2-e747e419e492.png&quot;&gt;

**Modern columnar data format for ML. Convert from Parquet in 2-lines of code for 100x faster random access, zero-cost schema evolution, rich secondary indices, versioning, and more.&lt;br/&gt;**
**Compatible with Pandas, DuckDB, Polars, Pyarrow, and Ray with more integrations on the way.**

&lt;a href=&quot;https://lancedb.github.io/lance/&quot;&gt;Documentation&lt;/a&gt; •
&lt;a href=&quot;https://blog.lancedb.com/&quot;&gt;Blog&lt;/a&gt; •
&lt;a href=&quot;https://discord.gg/zMM32dvNtd&quot;&gt;Discord&lt;/a&gt; •
&lt;a href=&quot;https://x.com/lancedb&quot;&gt;X&lt;/a&gt;

[CI]: https://github.com/lancedb/lance/actions/workflows/rust.yml
[CI Badge]: https://github.com/lancedb/lance/actions/workflows/rust.yml/badge.svg
[Docs]: https://lancedb.github.io/lance/
[Docs Badge]: https://img.shields.io/badge/docs-passing-brightgreen
[crates.io]: https://crates.io/crates/lance
[crates.io badge]: https://img.shields.io/crates/v/lance.svg
[Python versions]: https://pypi.org/project/pylance/
[Python versions badge]: https://img.shields.io/pypi/pyversions/pylance

[![CI Badge]][CI]
[![Docs Badge]][Docs]
[![crates.io badge]][crates.io]
[![Python versions badge]][Python versions]

&lt;/p&gt;
&lt;/div&gt;

&lt;hr /&gt;

Lance is a modern columnar data format that is optimized for ML workflows and datasets. Lance is perfect for:

1. Building search engines and feature stores.
2. Large-scale ML training requiring high performance IO and shuffles.
3. Storing, querying, and inspecting deeply nested data for robotics or large blobs like images, point clouds, and more.

The key features of Lance include:

* **High-performance random access:** 100x faster than Parquet without sacrificing scan performance.

* **Vector search:** find nearest neighbors in milliseconds and combine OLAP-queries with vector search.

* **Zero-copy, automatic versioning:** manage versions of your data without needing extra infrastructure.

* **Ecosystem integrations:** Apache Arrow, Pandas, Polars, DuckDB, Ray, Spark and more on the way.

&gt; [!TIP]
&gt; Lance is in active development and we welcome contributions. Please see our [contributing guide](https://lancedb.github.io/lance/community/contributing) for more information.

## Quick Start

**Installation**

```shell
pip install pylance
```

To install a preview release:

```shell
pip install --pre --extra-index-url https://pypi.fury.io/lancedb/ pylance
```

&gt; [!TIP]
&gt; Preview releases are released more often than full releases and contain the
&gt; latest features and bug fixes. They receive the same level of testing as full releases.
&gt; We guarantee they will remain published and available for download for at
&gt; least 6 months. When you want to pin to a specific version, prefer a stable release.

**Converting to Lance**

```python
import lance

import pandas as pd
import pyarrow as pa
import pyarrow.dataset

df = pd.DataFrame({&quot;a&quot;: [5], &quot;b&quot;: [10]})
uri = &quot;/tmp/test.parquet&quot;
tbl = pa.Table.from_pandas(df)
pa.dataset.write_dataset(tbl, uri, format=&#039;parquet&#039;)

parquet = pa.dataset.dataset(uri, format=&#039;parquet&#039;)
lance.write_dataset(parquet, &quot;/tmp/test.lance&quot;)
```

**Reading Lance data**
```python
dataset = lance.dataset(&quot;/tmp/test.lance&quot;)
assert isinstance(dataset, pa.dataset.Dataset)
```

**Pandas**
```python
df = dataset.to_table().to_pandas()
df
```

**DuckDB**
```python
import duckdb

# If this segfaults, make sure you have duckdb v0.7+ installed
duckdb.query(&quot;SELECT * FROM dataset LIMIT 10&quot;).to_df()
```

**Vector search**

Download the sift1m subset

```shell
wget ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz
tar -xzf sift.tar.gz
```

Convert it to Lance

```python
import lance
from lance.vector import vec_to_table
import numpy as np
import struct

nvecs = 1000000
ndims = 128
with open(&quot;sift/sift_base.fvecs&quot;, mode=&quot;rb&quot;) as fobj:
    buf = fobj.read()
    data = np.array(struct.unpack(&quot;&lt;128000000f&quot;, buf[4 : 4 + 4 * nvecs * ndims])).reshape((nvecs, ndims))
    dd = dict(zip(range(nvecs), data))

table = vec_to_table(dd)
uri = &quot;vec_data.lance&quot;
sift1m = lance.write_dataset(table, uri, max_rows_per_group=8192, max_rows_per_file=1024*1024)
```

Build the index

```python
sift1m.create_index(&quot;vector&quot;,
                    index_type=&quot;IVF_PQ&quot;,
                    num_partitions=256,  # IVF
                    num_sub_vectors=16)  # PQ
```

Search the dataset

```python
# Get top 10 similar vectors
import duckdb

dataset = lance.dataset(uri)

# Sample 100 query vectors. If this segfaults, make sure you have duckdb v0.7+ installed
sample = duckdb.query(&quot;SELECT vector FROM dataset USING SAMPLE 100&quot;).to_df()
query_vectors = np.array([np.array(x) for x in sample.vector])

# Get nearest neighbors for all of them
rs = [dataset.to_table(nearest={&quot;column&quot;: &quot;vector&quot;, &quot;k&quot;: 10, &quot;q&quot;: q})
      for q in query_vectors]
```

## Directory structure

| Directory          | Description              |
|--------------------|--------------------------|
| [rust](./rust)     | Core Rust implementation |
| [python](./python) | Python bindings (PyO3)   |
| [java](./java)     | Java bindings (JNI)      |
| [docs](./docs)     | Documentation source     |

## What makes Lance different

Here we will highlight a few aspects of Lance’s design. For more details, see the full [Lance design document](https://lancedb.github.io/lance/format).

**Vector index**: Vector index for similarity search over embedding space.
Support both CPUs (``x86_64`` and ``arm``) and GPU (``Nvidia (cuda)`` and ``Apple Silicon (mps)``).

**Encodings**: To achieve both fast columnar scan and sub-linear point queries, Lance uses custom encodings and layouts.

**Nested fields**: Lance stores each subfield as a separate column to support efficient filters like “find images where detected objects include cats”.

**Versioning**: A Manifest can be used to record snapshots. Currently we support creating new versions automatically via appends, overwrites, and index creation.

**Fast updates** (ROADMAP): Updates will be supported via write-ahead logs.

**Rich secondary indices**: Support `BTree`, `Bitmap`, `Full text search`, `Label list`,
`NGrams`, and more.

## Benchmarks

### Vector search

We used the SIFT dataset to benchmark our results with 1M vectors of 128D

1. For 100 randomly sampled query vectors, we get &lt;1ms average response time (on a 2023 m2 MacBook Air)

![avg_latency.png](docs/src/images/avg_latency.png)

2. ANNs are always a trade-off between recall and performance

![avg_latency.png](docs/src/images/recall_vs_latency.png)

### Vs. parquet

We create a Lance dataset using the Oxford Pet dataset to do some preliminary performance testing of Lance as compared to Parquet and raw image/XMLs. For analytics queries, Lance is 50-100x better than reading the raw metadata. For batched random access, Lance is 100x better than both parquet and raw files.

![](docs/src/images/lance_perf.png)

## Why are you building yet another data format?!

The machine learning development cycle involves the steps:

```mermaid
graph LR
    A[Collection] --&gt; B[Exploration];
    B --&gt; C[Analytics];
    C --&gt; D[Feature Engineer];
    D --&gt; E[Training];
    E --&gt; F[Evaluation];
    F --&gt; C;
    E --&gt; G[Deployment];
    G --&gt; H[Monitoring];
    H --&gt; A;
```

People use different data representations to varying stages for the performance or limited by the tooling available.
Academia mainly uses XML / JSON for annotations and zipped images/sensors data for deep learning, which
is difficult to integrate into data infrastructure and slow to train over cloud storage.
While industry uses data lakes (Parquet-based techniques, i.e., Delta Lake, Iceberg) or data warehouses (AWS Redshift
or Google BigQuery) to collect and analyze data, they have to convert the data into training-friendly formats, such
as [Rikai](https://github.com/eto-ai/rikai)/[Petastorm](https://github.com/uber/petastorm)
or [TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord).
Multiple single-purpose data transforms, as well as syncing copies between cloud storage to local training
instances have become a common practice.

While each of the existing data formats excels at the workload it was originally designed for, we need a new data format
tailored for multistage ML development cycles to reduce and data silos.

A comparison of different data formats in each stage of ML development cycle.

|                     | Lance | Parquet &amp; ORC | JSON &amp; XML | TFRecord | Database | Warehouse |
|---------------------|-------|---------------|------------|----------|----------|-----------|
| Analytics           | Fast  | Fast          | Slow       | Slow     | Decent   | Fast      |
| Feature Engineering | Fast  | Fast          | Decent     | Slow     | Decent   | Good      |
| Training            | Fast  | Decent        | Slow       | Fast     | N/A      | N/A       |
| Exploration         | Fast  | Slow          | Fast       | Slow     | Fast     | Decent    |
| Infra Support       | Rich  | Rich          | Decent     | Limited  | Rich     | Rich      |

## Community Highlights

Lance is currently used in production by:
* [LanceDB](https://github.com/lancedb/lancedb), a serverless, low-latency vector database for ML applications
* [LanceDB Enterprise](https://docs.lancedb.com/enterprise/introduction), hyperscale LanceDB with enterprise SLA.
* Leading multimodal Gen AI companies for training over petabyte-scale multimodal data.
* Self-driving car company for large-scale storage, retrieval and processing of multi-modal data.
* E-commerce company for billion-scale+ vector personalized search.
* and more.

## Presentations, Blogs and Talks

* [Designing a Table Format for ML Workloads](https://blog.lancedb.com/designing-a-table-format-for-ml-workloads/), Feb 2025.
* [Transforming Multimodal Data Management with LanceDB, Ray Summit](https://www.youtube.com/watch?v=xmTFEzAh8ho), Oct 2024.
* [Lance v2: A columnar container format for modern data](https://blog.lancedb.com/lance-v2/), Apr 2024.
* [Lance Deep Dive](https://drive.google.com/file/d/1Orh9rK0Mpj9zN_gnQF1eJJFpAc6lStGm/view?usp=drive_link). July 2023.
* [Lance: A New Columnar Data Format](https://docs.google.com/presentation/d/1a4nAiQAkPDBtOfXFpPg7lbeDAxcNDVKgoUkw3cUs2rE/edit#slide=id.p), [Scipy 2022, Austin, TX](https://www.scipy2022.scipy.org/posters). July, 2022.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vercel/turborepo]]></title>
            <link>https://github.com/vercel/turborepo</link>
            <guid>https://github.com/vercel/turborepo</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Build system optimized for JavaScript and TypeScript, written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vercel/turborepo">vercel/turborepo</a></h1>
            <p>Build system optimized for JavaScript and TypeScript, written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 28,649</p>
            <p>Forks: 2,086</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://turborepo.com&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://user-images.githubusercontent.com/4060187/196936123-f6e1db90-784d-4174-b774-92502b718836.png&quot;&gt;
      &lt;img src=&quot;https://user-images.githubusercontent.com/4060187/196936104-5797972c-ab10-4834-bd61-0d1e5f442c9c.png&quot; height=&quot;128&quot;&gt;
    &lt;/picture&gt;
    &lt;h1 align=&quot;center&quot;&gt;Turborepo&lt;/h1&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Vercel logo&quot; href=&quot;https://vercel.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&amp;logo=Vercel&amp;labelColor=000&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;NPM version&quot; href=&quot;https://www.npmjs.com/package/turbo&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/npm/v/turbo.svg?style=for-the-badge&amp;labelColor=000000&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;License&quot; href=&quot;https://github.com/vercel/turborepo/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/npm/l/turbo.svg?style=for-the-badge&amp;labelColor=000000&amp;color=&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;Join the community on GitHub&quot; href=&quot;https://github.com/vercel/turborepo/discussions&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&amp;logo=turborepo&amp;labelColor=000000&amp;logoWidth=20&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Turborepo is a high-performance build system for JavaScript and TypeScript codebases, written in Rust.

## Getting Started

Visit https://turborepo.com to get started with Turborepo.

## Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for more information.

## Community

The Turborepo community can be found on [GitHub Discussions](https://github.com/vercel/turborepo/discussions), where you can ask questions, voice ideas, and share your projects.

To chat with other community members, you can join [Vercel Community&#039;s `#turborepo` tag](https://vercel.community/tag/turborepo).

Our [Code of Conduct](https://github.com/vercel/turborepo/blob/main/CODE_OF_CONDUCT.md) applies to all Turborepo community channels.

## Who is using Turborepo?

Turborepo is used by the world&#039;s leading companies. Check out the [Turborepo Showcase](https://turborepo.com/showcase) to learn more.

## Updates

Follow [@turborepo](https://x.com/turborepo) on X for project updates.

## Authors

**Turborepo**

- Jared Palmer ([@jaredpalmer](https://x.com/jaredpalmer))

## Security

If you believe you have found a security vulnerability in Turborepo, we encourage you to responsibly disclose this and not open a public issue. We will investigate all legitimate reports. Email `security@vercel.com` to disclose any security vulnerabilities.

https://vercel.com/security
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vectordotdev/vector]]></title>
            <link>https://github.com/vectordotdev/vector</link>
            <guid>https://github.com/vectordotdev/vector</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[A high-performance observability data pipeline.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vectordotdev/vector">vectordotdev/vector</a></h1>
            <p>A high-performance observability data pipeline.</p>
            <p>Language: Rust</p>
            <p>Stars: 20,281</p>
            <p>Forks: 1,852</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>[![Nightly](https://github.com/vectordotdev/vector/actions/workflows/nightly.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/nightly.yml)
[![E2E Test Suite](https://github.com/vectordotdev/vector/actions/workflows/e2e.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/e2e.yml)
[![Component Features](https://github.com/vectordotdev/vector/actions/workflows/component_features.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/component_features.yml)

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;website/static/img/diagram.svg&quot; alt=&quot;Vector&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://vector.dev/docs/setup/quickstart/&quot;&gt;Quickstart&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/docs/&quot;&gt;Docs&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/guides/&quot;&gt;Guides&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/components/&quot;&gt;Integrations&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://chat.vector.dev&quot;&gt;Chat&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/releases/latest/download/&quot;&gt;Download&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://rust-doc.vector.dev/&quot;&gt;Rust Crate Docs&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

## What is Vector?

Vector is a high-performance, end-to-end (agent &amp; aggregator) observability data
pipeline that puts you in control of your observability data.
[Collect][docs.sources], [transform][docs.transforms], and [route][docs.sinks]
all your logs and metrics to any vendors you want today and any other
vendors you may want tomorrow. Vector enables dramatic cost reduction, novel
data enrichment, and data security where you need it, not where it is most
convenient for your vendors. Additionally, it is open source and up to 10x
faster than every alternative in the space.

To get started, follow our [**quickstart guide**][docs.quickstart] or [**install
Vector**][docs.installation].

Vector is maintained by Datadog&#039;s [Community Open Source Engineering team](https://opensource.datadoghq.com/about/#the-community-open-source-engineering-team).

### Principles

* **Reliable** - Built in [Rust][urls.rust], Vector&#039;s primary design goal is reliability.
* **End-to-end** - Deploys as an [agent][docs.roles#agent] or [aggregator][docs.roles#aggregator]. Vector is a complete platform.
* **Unified** - [Logs][docs.data-model.log], [metrics][docs.data-model.metric] (beta), and traces (coming soon). One tool for all of your data.

### Use cases

* Reduce total observability costs.
* Transition vendors without disrupting workflows.
* Enhance data quality and improve insights.
* Consolidate agents and eliminate agent fatigue.
* Improve overall observability performance and reliability.

### Community

* Vector is relied on by startups and enterprises like **Atlassian**, **T-Mobile**,
  **Comcast**, **Zendesk**, **Discord**, **Fastly**, **CVS**, **Trivago**,
  **Tuple**, **Douban**, **Visa**, **Mambu**, **Blockfi**, **Claranet**,
  **Instacart**, **Forcepoint**, and [many more][urls.production_users].
* Vector is **downloaded over 100,000 times per day**.
* Vector&#039;s largest user **processes over 500TB daily**.
* Vector has **over 500 contributors** and growing.

## Documentation

All user documentation is available at **[vector.dev/docs](https://vector.dev/docs)**.

Other Resources:

* [**Vector Calendar**][urls.vector_calendar]
* **Policies**:
  * [**Code of Conduct**][urls.vector_code_of_conduct]
  * [**Contributing**][urls.vector_contributing_policy]
  * [**Privacy**][urls.vector_privacy_policy]
  * [**Releases**][urls.vector_releases_policy]
  * [**Versioning**][urls.vector_versioning_policy]
  * [**Security**][urls.vector_security_policy]

## Comparisons

### Performance

The following performance tests demonstrate baseline performance between
common protocols with the exception of the Regex Parsing test.

| Test                                                                                                                   | Vector          | Filebeat | FluentBit       | FluentD   | Logstash  | SplunkUF        | SplunkHF |
| ---------------------------------------------------------------------------------------------------------------------- | --------------- | -------- | --------------- | --------- | --------- | --------------- | -------- |
| [TCP to Blackhole](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance) | _**86mib/s**_   | n/a      | 64.4mib/s       | 27.7mib/s | 40.6mib/s | n/a             | n/a      |
| [File to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance)           | _**76.7mib/s**_ | 7.8mib/s | 35mib/s         | 26.1mib/s | 3.1mib/s  | 40.1mib/s       | 39mib/s  |
| [Regex Parsing](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance)       | 13.2mib/s       | n/a      | _**20.5mib/s**_ | 2.6mib/s  | 4.6mib/s  | n/a             | 7.8mib/s |
| [TCP to HTTP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance)           | _**26.7mib/s**_ | n/a      | 19.6mib/s       | &lt;1mib/s   | 2.7mib/s  | n/a             | n/a      |
| [TCP to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance)             | 69.9mib/s       | 5mib/s   | 67.1mib/s       | 3.9mib/s  | 10mib/s   | _**70.4mib/s**_ | 7.6mib/s |

To learn more about our performance tests, please see the [Vector test harness][urls.vector_test_harness].

### Correctness

The following correctness tests are not exhaustive, but they demonstrate
fundamental differences in quality and attention to detail:

| Test                                                                                                                                 | Vector | Filebeat | FluentBit | FluentD | Logstash | Splunk UF | Splunk HF |
| ------------------------------------------------------------------------------------------------------------------------------------ | ------ | -------- | --------- | ------- | -------- | --------- | --------- |
| [Disk Buffer Persistence](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness) | **✓**  | ✓        |           |         | ⚠        | ✓         | ✓         |
| [File Rotate (create)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness)         | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |
| [File Rotate (copytruncate)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness) | **✓**  |          |           |         |          | ✓         | ✓         |
| [File Truncation](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness)                   | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |
| [Process (SIGHUP)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness)                         | **✓**  |          |           |         | ⚠        | ✓         | ✓         |
| [JSON (wrapped)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness)                     | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |

To learn more about our correctness tests, please see the [Vector test harness][urls.vector_test_harness].

### Features

Vector is an end-to-end, unified, open data platform.

|                     | **Vector** | Beats | Fluentbit | Fluentd | Logstash | Splunk UF | Splunk HF | Telegraf |
| ------------------- | ---------- | ----- | --------- | ------- | -------- | --------- | --------- | -------- |
| **End-to-end**      | **✓**      |       |           |         |          |           |           | ✓        |
| Agent               | **✓**      | ✓     | ✓         |         |          | ✓         |           | ✓        |
| Aggregator          | **✓**      |       |           | ✓       | ✓        |           | ✓         | ✓        |
| **Unified**         | **✓**      |       |           |         |          |           |           | ✓        |
| Logs                | **✓**      | ✓     | ✓         | ✓       | ✓        | ✓         | ✓         | ✓        |
| Metrics             | **✓**      | ⚠     | ⚠         | ⚠       | ⚠        | ⚠         | ⚠         | ✓        |
| Traces              | 🚧         |       |           |         |          |           |           |          |
| **Open**            | **✓**      |       | ✓         | ✓       |          |           |           | ✓        |
| Open-source         | **✓**      | ✓     | ✓         | ✓       | ✓        |           |           | ✓        |
| Vendor-neutral      | **✓**      |       | ✓         | ✓       |          |           |           | ✓        |
| **Reliability**     | **✓**      |       |           |         |          |           |           |          |
| Memory-safe         | **✓**      |       |           |         |          |           |           | ✓        |
| Delivery guarantees | **✓**      |       |           |         |          | ✓         | ✓         |          |
| Multi-core          | **✓**      | ✓     | ✓         | ✓       | ✓        | ✓         | ✓         | ✓        |


⚠ = Not interoperable, metrics are represented as structured logs

---

&lt;p align=&quot;center&quot;&gt;
  Developed with ❤️ by &lt;strong&gt;&lt;a href=&quot;https://datadoghq.com&quot;&gt;Datadog&lt;/a&gt;&lt;/strong&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/security/policy&quot;&gt;Security Policy&lt;/a&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/blob/master/PRIVACY.md&quot;&gt;Privacy Policy&lt;/a&gt;
&lt;/p&gt;

[docs.about.concepts]: https://vector.dev/docs/introduction/concepts/
[docs.about.introduction]: https://vector.dev/docs/introduction/
[docs.administration.monitoring]: https://vector.dev/docs/administration/monitoring/
[docs.administration.management]: https://vector.dev/docs/administration/management/
[docs.administration.upgrading]: https://vector.dev/docs/administration/upgrading/
[docs.administration.validating]: https://vector.dev/docs/administration/validating/
[docs.architecture.concurrency-model]: https://vector.dev/docs/architecture/concurrency-model/
[docs.architecture.data-model]: https://vector.dev/docs/architecture/data-model/
[docs.architecture.pipeline-model]: https://vector.dev/docs/architecture/pipeline-model/
[docs.architecture.runtime-model]: https://vector.dev/docs/architecture/runtime-model/
[docs.configuration.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.configuration.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.configuration.tests]: https://vector.dev/docs/reference/configuration/tests/
[docs.configuration.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.configuration.enrichment_tables]: https://vector.dev/docs/reference/configuration/global-options/#enrichment_tables
[docs.data-model.log]: https://vector.dev/docs/architecture/data-model/log/
[docs.data-model.metric]: https://vector.dev/docs/architecture/data-model/metric/
[docs.deployment.roles]: https://vector.dev/docs/setup/deployment/roles/
[docs.deployment.topologies]: https://vector.dev/docs/setup/deployment/topologies/
[docs.deployment]: https://vector.dev/docs/setup/deployment/
[docs.installation.manual]: https://vector.dev/docs/setup/installation/manual/
[docs.installation.operating_systems]: https://vector.dev/docs/setup/installation/operating-systems/
[docs.installation.package_managers]: https://vector.dev/docs/setup/installation/package-managers/
[docs.installation.platforms]: https://vector.dev/docs/setup/installation/platforms/
[docs.installation]: https://vector.dev/docs/setup/installation/
[docs.architecture.adaptive-request-concurrency]: https://vector.dev/docs/architecture/arc/
[docs.platforms.kubernetes]: https://vector.dev/docs/setup/installation/platforms/kubernetes/
[docs.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.reference.api]: https://vector.dev/docs/reference/api/
[docs.reference.cli]: https://vector.dev/docs/reference/cli/
[docs.reference.vrl]: https://vector.dev/docs/reference/vrl/
[docs.roles#agent]: https://vector.dev/docs/setup/deployment/roles/#agent
[docs.roles#aggregator]: https://vector.dev/docs/setup/deployment/roles/#aggregator
[docs.setup.installation]: https://vector.dev/docs/setup/installation/
[docs.setup.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.sinks.aws_cloudwatch_logs]: https://vector.dev/docs/reference/configuration/sinks/aws_cloudwatch_logs/
[docs.sinks.aws_s3]: https://vector.dev/docs/reference/configuration/sinks/aws_s3/
[docs.sinks.clickhouse]: https://vector.dev/docs/reference/configuration/sinks/clickhouse/
[docs.sinks.elasticsearch]: https://vector.dev/docs/reference/configuration/sinks/elasticsearch/
[docs.sinks.gcp_cloud_storage]: https://vector.dev/docs/reference/configuration/sinks/gcp_cloud_storage/
[docs.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.sources.docker_logs]: https://vector.dev/docs/reference/configuration/sources/docker_logs/
[docs.sources.file]: https://vector.dev/docs/reference/configuration/sources/file/
[docs.sources.http]: https://vector.dev/docs/reference/configuration/sources/http/
[docs.sources.journald]: https://vector.dev/docs/reference/configuration/sources/journald/
[docs.sources.kafka]: https://vector.dev/docs/reference/configuration/sources/kafka/
[docs.sources.socket]: https://vector.dev/docs/reference/configuration/sources/socket/
[docs.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.transforms.dedupe]: https://vector.dev/docs/reference/configuration/transforms/dedupe/
[docs.transforms.filter]: https://vector.dev/docs/reference/configuration/transforms/filter/
[docs.transforms.log_to_metric]: https://vector.dev/docs/reference/configuration/transforms/log_to_metric/
[docs.transforms.lua]: https://vector.dev/docs/reference/configuration/transforms/lua/
[docs.transforms.remap]: https://vector.dev/docs/reference/configuration/transforms/remap/
[docs.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.introduction.architecture]: https://vector.dev/docs/architecture/
[docs.introduction.guarantees]: https://vector.dev/docs/introduction/guarantees/
[docs.introduction.architecture]: https://vector.dev/docs/architecture/
[urls.production_users]: https://github.com/vectordotdev/vector/issues/790
[urls.rust]: https://www.rust-lang.org/
[urls.vector_calendar]: https://calendar.vector.dev
[urls.vector_chat]: https://chat.vector.dev
[urls.vector_code_of_conduct]: https://github.com/vectordotdev/vector/blob/master/CODE_OF_CONDUCT.md
[urls.vector_contributing_policy]: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md
[urls.vector_community]: https://vector.dev/community/
[urls.vector_privacy_policy]: https://github.com/vectordotdev/vector/blob/master/PRIVACY.md
[urls.vector_release_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASING.md
[urls.vector_releases]: https://vector.dev/releases/
[urls.vector_releases_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASES.md
[urls.vector_security_policy]: https://github.com/vectordotdev/vector/security/policy
[urls.vector_test_harness]: https://github.com/vectordotdev/vector-test-harness/
[urls.vector_twitter]: https://twitter.com/vectordotdev
[urls.vector_versioning_policy]: https://github.com/vectordotdev/vector/blob/master/VERSIONING.md
[urls.vote_feature]: https://github.com/vectordotdev/vector/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22type%3A+feature%22
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustfs/rustfs]]></title>
            <link>https://github.com/rustfs/rustfs</link>
            <guid>https://github.com/rustfs/rustfs</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[🚀 High-performance distributed object storage for MinIO alternative.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustfs/rustfs">rustfs/rustfs</a></h1>
            <p>🚀 High-performance distributed object storage for MinIO alternative.</p>
            <p>Language: Rust</p>
            <p>Stars: 8,313</p>
            <p>Forks: 418</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>[![RustFS](https://rustfs.com/images/rustfs-github.png)](https://rustfs.com)

&lt;p align=&quot;center&quot;&gt;RustFS is a high-performance distributed object storage software built using Rust&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/rustfs/rustfs/actions/workflows/ci.yml&quot;&gt;&lt;img alt=&quot;CI&quot; src=&quot;https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/rustfs/rustfs/actions/workflows/docker.yml&quot;&gt;&lt;img alt=&quot;Build and Push Docker Images&quot; src=&quot;https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/m/rustfs/rustfs&quot;/&gt;
  &lt;img alt=&quot;Github Last Commit&quot; src=&quot;https://img.shields.io/github/last-commit/rustfs/rustfs&quot;/&gt;
  &lt;a href=&quot;https://hellogithub.com/repository/rustfs/rustfs&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=b95bcb72bdc340b68f16fdf6790b7d5b&amp;claim_uid=MsbvjYeLDKAH457&amp;theme=small&quot; alt=&quot;Featured｜HelloGitHub&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.rustfs.com/introduction.html&quot;&gt;Getting Started&lt;/a&gt;
  · &lt;a href=&quot;https://docs.rustfs.com/&quot;&gt;Docs&lt;/a&gt;
  · &lt;a href=&quot;https://github.com/rustfs/rustfs/issues&quot;&gt;Bug reports&lt;/a&gt;
  · &lt;a href=&quot;https://github.com/rustfs/rustfs/discussions&quot;&gt;Discussions&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
English | &lt;a href=&quot;https://github.com/rustfs/rustfs/blob/main/README_ZH.md&quot;&gt;简体中文&lt;/a&gt; |
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=de&quot;&gt;Deutsch&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=es&quot;&gt;Español&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=fr&quot;&gt;français&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=ja&quot;&gt;日本語&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=ko&quot;&gt;한국어&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=pt&quot;&gt;Português&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=ru&quot;&gt;Русский&lt;/a&gt;
&lt;/p&gt;

RustFS is a high-performance distributed object storage software built using Rust, one of the most popular languages worldwide. Along with MinIO, it shares a range of advantages such as simplicity, S3 compatibility, open-source nature, support for data lakes, AI, and big data. Furthermore, it has a better and more user-friendly open-source license in comparison to other storage systems, being constructed under the Apache license. As Rust serves as its foundation, RustFS provides faster speed and safer distributed features for high-performance object storage.

&gt; ⚠️ **RustFS is under rapid development. Do NOT use in production environments!**

## Features

- **High Performance**: Built with Rust, ensuring speed and efficiency.
- **Distributed Architecture**: Scalable and fault-tolerant design for large-scale deployments.
- **S3 Compatibility**: Seamless integration with existing S3-compatible applications.
- **Data Lake Support**: Optimized for big data and AI workloads.
- **Open Source**: Licensed under Apache 2.0, encouraging community contributions and transparency.
- **User-Friendly**: Designed with simplicity in mind, making it easy to deploy and manage.

## RustFS vs MinIO

Stress test server parameters

|  Type  |  parameter   | Remark |
| - | - | - |
|CPU | 2 Core | Intel Xeon(Sapphire Rapids) Platinum 8475B , 2.7/3.2 GHz|   |
|Memory| 4GB |     |
|Network | 15Gbp |      |
|Driver  | 40GB x 4 |   IOPS 3800 / Driver |

&lt;https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a&gt;

### RustFS vs Other object storage

| RustFS | Other object storage|
| - | - |
| Powerful Console | Simple and useless Console |
| Developed based on Rust language, memory is safer | Developed in Go or C, with potential issues like memory GC/leaks |
| Does not report logs to third-party countries  | Reporting logs to other third countries may violate national security laws |
| Licensed under Apache, more business-friendly  | AGPL V3 License and other License, polluted open source and License traps, infringement of intellectual property rights |
| Comprehensive S3 support, works with domestic and international cloud providers  | Full support for S3, but no local cloud vendor support |
| Rust-based development, strong support for secure and innovative devices  | Poor support for edge gateways and secure innovative devices|
| Stable commercial prices, free community support | High pricing, with costs up to $250,000 for 1PiB |
| No risk | Intellectual property risks and risks of prohibited uses |

## Quickstart

To get started with RustFS, follow these steps:

1. **One-click installation script (Option 1)​​**

   ```bash
   curl -O  https://rustfs.com/install_rustfs.sh &amp;&amp; bash install_rustfs.sh
   ```

2. **Docker Quick Start (Option 2)​​**

  ```bash
   # create data and logs directories
   mkdir -p data logs

   # using latest alpha version
   docker run -d -p 9000:9000 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:alpha

   # Specific version
   docker run -d -p 9000:9000 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:1.0.0.alpha.45
   ```

3. **Build from Source (Option 3) - Advanced Users**

   For developers who want to build RustFS Docker images from source with multi-architecture support:

   ```bash
   # Build multi-architecture images locally
   ./docker-buildx.sh --build-arg RELEASE=latest

   # Build and push to registry
   ./docker-buildx.sh --push

   # Build specific version
   ./docker-buildx.sh --release v1.0.0 --push

   # Build for custom registry
   ./docker-buildx.sh --registry your-registry.com --namespace yourname --push
   ```

   The `docker-buildx.sh` script supports:
   - **Multi-architecture builds**: `linux/amd64`, `linux/arm64`
   - **Automatic version detection**: Uses git tags or commit hashes
   - **Registry flexibility**: Supports Docker Hub, GitHub Container Registry, etc.
   - **Build optimization**: Includes caching and parallel builds

   You can also use Make targets for convenience:

   ```bash
   make docker-buildx                    # Build locally
   make docker-buildx-push               # Build and push
   make docker-buildx-version VERSION=v1.0.0  # Build specific version
   make help-docker                      # Show all Docker-related commands
   ```

4. **Access the Console**: Open your web browser and navigate to `http://localhost:9000` to access the RustFS console, default username and password is `rustfsadmin` .
5. **Create a Bucket**: Use the console to create a new bucket for your objects.
6. **Upload Objects**: You can upload files directly through the console or use S3-compatible APIs to interact with your RustFS instance.

## Documentation

For detailed documentation, including configuration options, API references, and advanced usage, please visit our [Documentation](https://docs.rustfs.com).

## Getting Help

If you have any questions or need assistance, you can:

- Check the [FAQ](https://github.com/rustfs/rustfs/discussions/categories/q-a) for common issues and solutions.
- Join our [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) to ask questions and share your experiences.
- Open an issue on our [GitHub Issues](https://github.com/rustfs/rustfs/issues) page for bug reports or feature requests.

## Links

- [Documentation](https://docs.rustfs.com) - The manual you should read
- [Changelog](https://github.com/rustfs/rustfs/releases) - What we broke and fixed
- [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) - Where the community lives

## Contact

- **Bugs**: [GitHub Issues](https://github.com/rustfs/rustfs/issues)
- **Business**: &lt;hello@rustfs.com&gt;
- **Jobs**: &lt;jobs@rustfs.com&gt;
- **General Discussion**: [GitHub Discussions](https://github.com/rustfs/rustfs/discussions)
- **Contributing**: [CONTRIBUTING.md](CONTRIBUTING.md)

## Contributors

RustFS is a community-driven project, and we appreciate all contributions. Check out the [Contributors](https://github.com/rustfs/rustfs/graphs/contributors) page to see the amazing people who have helped make RustFS better.

&lt;a href=&quot;https://github.com/rustfs/rustfs/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://opencollective.com/rustfs/contributors.svg?width=890&amp;limit=500&amp;button=false&quot; /&gt;
&lt;/a&gt;

## License

[Apache 2.0](https://opensource.org/licenses/Apache-2.0)

**RustFS** is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[bluealloy/revm]]></title>
            <link>https://github.com/bluealloy/revm</link>
            <guid>https://github.com/bluealloy/revm</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Rust implementation of the Ethereum Virtual Machine.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bluealloy/revm">bluealloy/revm</a></h1>
            <p>Rust implementation of the Ethereum Virtual Machine.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,980</p>
            <p>Forks: 792</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>### Revm

[![CI](https://github.com/bluealloy/revm/actions/workflows/ci.yml/badge.svg)][gh-ci]
[![License](https://img.shields.io/badge/License-MIT-orange.svg)][mit-license]
[![crates.io](https://img.shields.io/crates/v/revm.svg)](https://crates.io/crates/revm)
[![Chat][tg-badge]][tg-url]

Revm is a highly efficient and stable implementation of the Ethereum Virtual Machine (EVM) written in Rust.

![banner](https://raw.githubusercontent.com/bluealloy/revm/refs/heads/main/assets/logo/revm-banner.png)

[mit-license]: https://opensource.org/license/mit/
[gh-ci]: https://github.com/bluealloy/revm/actions/workflows/ci.yml
[tg-url]: https://t.me/+Ig4WDWOzikA3MzA0
[tg-badge]: https://img.shields.io/badge/chat-telegram-blue

Known for its robustness, it stands as one of the most popular libraries and a critical component of the Ethereum ecosystem. Revm plays a crucial role across various projects, being widely utilized by almost all tooling and block builders. It is integrated into Reth, multiple Layer 2 variants and other clients and serving as a standard for zkVMs.

Revm offers two primary applications: firstly, it functions as an executor where users can set up block info and process mainnet transactions; secondly, it acts as a framework that facilitates the extension and support of different EVM variants such as op-revm.

### How to use:

Here is a straightforward example of using the Execution API: It allows us to create an Ethereum Virtual Machine (EVM) and execute transactions. Additionally, it can be utilized to generate traces with the inspector or more complex example of foundry cheatcodes.

```rust,ignore
let mut evm = Context::mainnet().with_block(block).build_mainnet();
let out = evm.transact(tx);

// or you can use powerful inspection tool to trace it
let mut evm = evm.with_inspector(tracer);
let out = evm.inspect_tx(tx);
```

The Evm Framework API is somewhat complex to use, but this document provides a detailed explanation. It enables users to extend logic, incorporate various context types, and offers built-in support for inspection. For a practical example, you can refer to the [op-revm crate](https://github.com/op-rs/op-revm).

### Users:

As previously noted, there are several groups of projects that utilize this technology:

* **Major block builders**.
* **Clients**: [Reth](https://github.com/paradigmxyz/reth), [Helios](https://github.com/a16z/helios), [Trin](https://github.com/ethereum/trin),..
* **Tooling**: [Foundry](https://github.com/foundry-rs/foundry/), [Hardhat](https://github.com/NomicFoundation/hardhat),..
* **L2s**: [Optimism](https://github.com/bluealloy/revm/tree/main/crates/op-revm), [Coinbase](https://www.base.org/), [Scroll](https://github.com/scroll-tech/revm),..
* **zkVM**: [Risc0](https://github.com/risc0/risc0-ethereum), [Succinct](https://github.com/succinctlabs/rsp),..

The full list of projects that use Revm is available in the [awesome-revm](https://bluealloy.github.io/revm/awesome.html) section of the book.

### How to, dev section

The [book](https://bluealloy.github.io/revm/) and [`Architecture and API`](https://bluealloy.github.io/revm/architecture.html) page is the best starting resource.

Some quick links can be found here. Some point to code documentation or the book. code docs are there to explain usage of a particular part of the code where the book is to get more of an overview of the architecture or how components/projects fit together.

* [How to build and use revm](https://bluealloy.github.io/revm/dev.html)
* [Architecture overview](https://bluealloy.github.io/revm/architecture.html)
* [Structure of the project](https://github.com/bluealloy/revm/tree/main/crates) (list of crates and their versions)
* [How to use Revm Framework](https://github.com/bluealloy/revm/tree/main/examples/my_evm) (MyEvm example)
* [Release procedure and changelogs explanation](https://bluealloy.github.io/revm/release_procedure.html)
* [How to use revme](https://github.com/bluealloy/revm/tree/main/bins/revme) (Revm binary with few commands)
* [How to run Ethereum tests](https://bluealloy.github.io/revm/revme.html#running-eth-tests)
* If there is more need for explanations please open a PR request.

## Supported Rust Versions (MSRV)

Revm always aims to stay up-to-date with the latest stable Rust release.

The Minimum Supported Rust Version (MSRV) may be updated at any time, so we can take advantage of new features and improvements in Rust.

### Community:
For questions please open a github issue or join the public [telegram group](https://t.me/+Ig4WDWOzikA3MzA0)

### Licence
Revm is licensed under MIT Licence.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in these crates by you, shall be licensed as above, without any additional terms or conditions.

If `gmp` feature flag is used, GPL code gets compiled, if enabled please make sure to follow this license.

### Security

For any security questions or findings, please reach out to me directly via email at [dragan0rakita@gmail.com](mailto:dragan0rakita@gmail.com) or contact me on Keybase under the username @draganrakita.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tauri-apps/tauri]]></title>
            <link>https://github.com/tauri-apps/tauri</link>
            <guid>https://github.com/tauri-apps/tauri</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Build smaller, faster, and more secure desktop and mobile applications with a web frontend.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tauri-apps/tauri">tauri-apps/tauri</a></h1>
            <p>Build smaller, faster, and more secure desktop and mobile applications with a web frontend.</p>
            <p>Language: Rust</p>
            <p>Stars: 96,459</p>
            <p>Forks: 3,062</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;.github/splash.png&quot; alt=&quot;Tauri&quot; /&gt;

[![status](https://img.shields.io/badge/status-stable-blue.svg)](https://github.com/tauri-apps/tauri/tree/dev)
[![License](https://img.shields.io/badge/License-MIT%20or%20Apache%202-green.svg)](https://opencollective.com/tauri)
[![test core](https://img.shields.io/github/actions/workflow/status/tauri-apps/tauri/test-core.yml?label=test%20core&amp;logo=github)](https://github.com/tauri-apps/tauri/actions/workflows/test-core.yml)
[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri.svg?type=shield)](https://app.fossa.com/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri?ref=badge_shield)
[![Chat Server](https://img.shields.io/badge/chat-discord-7289da.svg)](https://discord.com/invite/tauri)
[![website](https://img.shields.io/badge/website-tauri.app-purple.svg)](https://tauri.app)
[![https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg](https://good-labs.github.io/greater-good-affirmation/assets/images/badge.svg)](https://good-labs.github.io/greater-good-affirmation)
[![support](https://img.shields.io/badge/sponsor-Open%20Collective-blue.svg)](https://opencollective.com/tauri)

## Introduction

Tauri is a framework for building tiny, blazingly fast binaries for all major desktop platforms. Developers can integrate any front-end framework that compiles to HTML, JS and CSS for building their user interface. The backend of the application is a rust-sourced binary with an API that the front-end can interact with.

The user interface in Tauri apps currently leverages [`tao`](https://docs.rs/tao) as a window handling library on macOS, Windows, Linux, Android and iOS. To render your application, Tauri uses [WRY](https://github.com/tauri-apps/wry), a library which provides a unified interface to the system webview, leveraging WKWebView on macOS &amp; iOS, WebView2 on Windows, WebKitGTK on Linux and Android System WebView on Android.

To learn more about the details of how all of these pieces fit together, please consult this [ARCHITECTURE.md](https://github.com/tauri-apps/tauri/blob/dev/ARCHITECTURE.md) document.

## Getting Started

If you are interested in making a tauri app, please visit the [documentation website](https://tauri.app).

The quickest way to get started is to install the [prerequisites](https://v2.tauri.app/start/prerequisites/) for your system and create a new project with [`create-tauri-app`](https://github.com/tauri-apps/create-tauri-app/#usage). For example with `npm`:

```sh
npm create tauri-app@latest
```

## Features

The list of Tauri&#039;s features includes, but is not limited to:

- Built-in app bundler to create app bundles in formats like `.app`, `.dmg`, `.deb`, `.rpm`, `.AppImage` and Windows installers like `.exe` (via NSIS) and `.msi` (via WiX).
- Built-in self updater (desktop only)
- System tray icons
- Native notifications
- Native WebView Protocol (tauri doesn&#039;t create a localhost http(s) server to serve the WebView contents)
- GitHub action for streamlined CI
- VS Code extension

### Platforms

Tauri currently supports development and distribution on the following platforms:

| Platform   | Versions                                                                                                        |
| :--------- | :-------------------------------------------------------------------------------------------------------------- |
| Windows    | 7 and above                                                                                                     |
| macOS      | 10.15 and above                                                                                                 |
| Linux      | webkit2gtk 4.0 for Tauri v1 (for example Ubuntu 18.04). webkit2gtk 4.1 for Tauri v2 (for example Ubuntu 22.04). |
| iOS/iPadOS | 9 and above                                                                                                     |
| Android    | 7 and above (currently 8 and above)                                                                             |

## Contributing

Before you start working on something, it&#039;s best to check if there is an existing issue first. It&#039;s also a good idea to stop by the Discord server and confirm with the team if it makes sense or if someone else is already working on it.

Please make sure to read the [Contributing Guide](./.github/CONTRIBUTING.md) before making a pull request.

Thank you to everyone contributing to Tauri!

### Documentation

Documentation in a polyglot system is a tricky proposition. To this end, we prefer to use inline documentation in the Rust &amp; JS source code as much as possible. Check out the hosting repository for the documentation site for further information: &lt;https://github.com/tauri-apps/tauri-docs&gt;

## Partners

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot; valign=&quot;middle&quot;&gt;
        &lt;a href=&quot;https://crabnebula.dev&quot; target=&quot;_blank&quot;&gt;
          &lt;img src=&quot;.github/sponsors/crabnebula.svg&quot; alt=&quot;CrabNebula&quot; width=&quot;283&quot;&gt;
        &lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

For the complete list of sponsors please visit our [website](https://tauri.app#sponsors) and [Open Collective](https://opencollective.com/tauri).

## Organization

Tauri aims to be a sustainable collective based on principles that guide [sustainable free and open software communities](https://sfosc.org). To this end it has become a Programme within the [Commons Conservancy](https://commonsconservancy.org/), and you can contribute financially via [Open Collective](https://opencollective.com/tauri).

## Licenses

Code: (c) 2015 - Present - The Tauri Programme within The Commons Conservancy.

MIT or MIT/Apache 2.0 where applicable.

Logo: CC-BY-NC-ND

- Original Tauri Logo Designs by [Alve Larsson](https://alve.io/), [Daniel Thompson-Yvetot](https://github.com/nothingismagick) and [Guillaume Chau](https://github.com/akryum)

[![FOSSA Status](https://app.fossa.com/api/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri.svg?type=large)](https://app.fossa.com/projects/git%2Bgithub.com%2Ftauri-apps%2Ftauri?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[foundry-rs/foundry]]></title>
            <link>https://github.com/foundry-rs/foundry</link>
            <guid>https://github.com/foundry-rs/foundry</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/foundry-rs/foundry">foundry-rs/foundry</a></h1>
            <p>Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 9,421</p>
            <p>Forks: 2,128</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;.github/assets/banner.png&quot; alt=&quot;Foundry banner&quot; /&gt;

&amp;nbsp;

[![Github Actions][gha-badge]][gha-url] [![Telegram Chat][tg-badge]][tg-url] [![Telegram Support][tg-support-badge]][tg-support-url]
![Foundry](https://img.shields.io/badge/Foundry-grey?style=flat&amp;logo=data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAElElEQVR4nH1VUUhUaRg9984YdzBpkqR0Z210rIESIXSabEbcHgydrpNRRj00kWaztj0U1MOW0MOIbD300IvLMqBpMTGYxdoqyoRNDUESBDWwUuPugCSSsTM7u0Oj1/+efdiMcmnP2/fDd77D4f/OB6xCa2urQZbllVICYGtqanK1tLS4AdgAyAAgyzJaW1sNq/ulT4twOGw4fPiwAGDp7Ow8VV1d7bVarRWxWCw/k8mgsbExm0wmZ+Lx+M/Xr1//CcAsSVmSJH01McLhsAEAnE5nx+Tk5B/xeJxOp5N9fX2sqqqixWLhnTt36HA4GIvFGI1GU3V1df5Pe/9D1t7eHkgkEuzo6GBPT49WWloq7Ha7fujQITocDu7atUs3m83i6tWr2okTJ/jixQuePn265zPScDhskGUZe/fubXv8+DFv3rypbdiwQaxbt46RSIT79u3j0NAQb926RVVVOT4+TqvVyvz8fD0YDC5NTk6ysbHxlCRJ/5KSlAAURyKRTFNTkwAg7t69S5/Px76+Pq7GyMgI9+/fz9HRUQIQO3bsEKOjo38DsJCUJADw+/0BVVW7otHo8ps3b4yvXr3CxMQETCYTTCYTNE0DAOTl5SGXy0FRFOzZswdmsxkVFRXLNTU1xmg0+kNvb+/3AGAcGBiI7969Wwcg6urq+OTJE967d49btmzh9PT0R3WJRIKBQIDBYJBTU1NsaGggAGGz2fTe3t5fAeQZAWwuLi4uP3nypOT1emEwGFBeXo7a2losLCygoaEB/f39MJlMCIVCkCQJBw8ehNVqhcfjQXNzs1RSUiKtX7++DEAZqqqq3KFQiABYUFDAM2fOkCQXFxdJkvfv32dhYSG9Xi+vXbvG2dnZj4oDgQCLioqoKAqHhobodDq/Mc7NzUklJSUIBoOw2WzYtm0blpeXsWbNGkxMTODp06doa2vD4OAgNm7cCIvFApLQdR3nzp3Dzp078fLlSxQVFeHdu3cAgIpHjx69/zBUX5k+MDBAt9vNY8eOsbu7m6lUigcOHKDL5WImkyHJz9TGYrEcALsMIPn69esZTdMIgM+ePUNXVxdu376NsrIyuN1uXLp0CWazGcPDw3C5XFBVFWfPnkVNTQ18Pp+ezWY5MzPzO4DfAABHjhzpJslUKqVdvHiR4+PjbG9vZy6XI0kuLS0xmUxSCEGS9Pv9LC0tpdFoZGVlpSaEoM/nuwIAKx/7q5GRkb9CoZBQVVWcP3+ez58/J0mm02kODg7ywoULjMViTKfTtNvtXLt2LTdt2qTncrnlsbGxLICvSUqfrl5HJBLh1NTUkhBCJ8mFhQX29/dTVVUWFBTwwYMH1HWdly9fpqIoeiKRWJqfn2d1dXWnLMuf7zMAHD16tGd+fn7FZy2bzYrKykodAAFQVVV9cXFRkNTevn3Lubk5trS0XPnfxHE4HN8ODw+nV/yanp6mx+Ohx+P5aIMQgmNjY3/W1tZ+t5rsSwG7+fjx4/76+vrm7du32woLC00AkE6n38fj8ZmHDx/+cuPGjR8BJL8YsCtYdQIMALYqilKvKEo9APuHty+egH8A3GfFDJXmxmMAAAAASUVORK5CYII%3D&amp;link=https%3A%2F%2Fbook.getfoundry.sh%2F)

[gha-badge]: https://img.shields.io/github/actions/workflow/status/foundry-rs/foundry/test.yml?branch=master
[gha-url]: https://github.com/foundry-rs/foundry/actions
[tg-badge]: https://img.shields.io/endpoint?color=neon&amp;logo=telegram&amp;label=chat&amp;style=flat-square&amp;url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ffoundry_rs
[tg-url]: https://t.me/foundry_rs
[tg-support-badge]: https://img.shields.io/endpoint?color=neon&amp;logo=telegram&amp;label=support&amp;style=flat-square&amp;url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Ffoundry_support
[tg-support-url]: https://t.me/foundry_support

**[Install](https://getfoundry.sh/getting-started/installation)**
| [Docs][foundry-docs]
| [Developer Guidelines](./docs/dev/README.md)
| [Contributing](./CONTRIBUTING.md)
| [Crate Docs](https://foundry-rs.github.io/foundry)

&lt;/div&gt;

---

### Foundry is a blazing fast, portable and modular toolkit for Ethereum application development written in Rust.

Foundry consists of:

- [**Forge**](#forge): Build, test, fuzz, debug and deploy [Solidity][solidity] contracts, like Hardhat, Brownie, Ape.
- [**Cast**](#cast): A Swiss Army knife for interacting with EVM smart contracts, sending transactions and getting chain data.
- [**Anvil**](#anvil): Fast local Ethereum development node, akin to Hardhat Network, Tenderly.
- [**Chisel**](#chisel): Fast, utilitarian, and verbose Solidity REPL.

**Need help getting started with Foundry? Read the [📖 Foundry Docs][foundry-docs]!**

![Demo](.github/assets/demo.gif)

## Features

- **High-Performance Compilation**

  - **Fast and Flexible**: Automatically detects and installs the required Solidity compiler version.
  - **Solidity and Vyper Support**: Fully supports both Solidity and Vyper out-of-the-box.
  - **Incremental Compilation**: Re-compiles only changed files, saving time.
  - **Parallelized Pipeline**: Leverages multi-core systems for ultra-fast builds.
  - **Broad Compatibility**: Supports non-standard directory structures, including [Hardhat repos](https://twitter.com/gakonst/status/1461289225337421829).

- **Advanced Testing**

  - **No Context Switching**: Write tests directly in Solidity.
  - **Fuzz Testing**: Quickly identify edge cases with input shrinking and counter-example generation.
  - **Invariant Testing**: Ensure complex system properties hold across a wide range of inputs.
  - **Debugging Made Easy**: Use [forge-std](https://github.com/foundry-rs/forge-std)&#039;s `console.sol` for flexible debug logging.
  - **Interactive Debugger**: Step through your Solidity code with Foundry&#039;s interactive debugger, making it easy to pinpoint issues.

- **Powerful Runtime Features**

  - **RPC Forking**: Fast and efficient remote RPC forking backed by [Alloy][alloy].
  - **Lightweight &amp; Portable**: No dependency on Nix or other package managers for installation.

- **Streamlined CI/CD**

  - **Optimized CI**: Accelerate builds, run tests and execute scripts using [Foundry&#039;s GitHub action][foundry-gha].

## Installation

Getting started is very easy:

Install `foundryup`:

```
curl -L https://foundry.paradigm.xyz | bash
```

Next, run `foundryup`.

It will automatically install the latest version of the precompiled binaries: [`forge`](#forge), [`cast`](#cast), [`anvil`](#anvil), and [`chisel`](#chisel).

```
foundryup
```

**Done!**

For additional details see the [installation guide](https://getfoundry.sh/getting-started/installation) in the [Foundry Docs][foundry-docs].

If you&#039;re experiencing any issues while installing, check out [Getting Help](#getting-help) and the [FAQ](https://getfoundry.sh/faq).

## How Fast?

Forge is quite fast at both compiling (leveraging `solc` with [foundry-compilers]) and testing.

See the benchmarks below. Older benchmarks against [DappTools][dapptools] can be found in the [v0.2.0 announcement post][benchmark-post] and in the [Convex Shutdown Simulation][convex] repository.

### Testing Benchmarks

| Project                                       | Type                 | [Forge 1.0][foundry-1.0] | [Forge 0.2][foundry-0.2] | DappTools | Speedup        |
| --------------------------------------------- | -------------------- | ------------------------ | ------------------------ | --------- | -------------- |
| [vectorized/solady][solady]                   | Unit / Fuzz          | 0.9s                     | 2.3s                     | -         | 2.6x           |
| [morpho-org/morpho-blue][morpho-blue]         | Invariant            | 0.7s                     | 1m43s                    | -         | 147.1x         |
| [morpho-org/morpho-blue-oracles][morpho-blue] | Integration (Cold)   | 6.1s                     | 6.3s                     | -         | 1.04x          |
| [morpho-org/morpho-blue-oracles][morpho-blue] | Integration (Cached) | 0.6s                     | 0.9s                     | -         | 1.50x          |
| [transmissions11/solmate][solmate]            | Unit / Fuzz          | 2.7s                     | 2.8s                     | 6m34s     | 1.03x / 140.0x |
| [reflexer-labs/geb][geb]                      | Unit / Fuzz          | 0.2s                     | 0.4s                     | 23s       | 2.0x / 57.5x   |

_In the above benchmarks, compilation was always skipped_

**Takeaway: Forge dramatically outperforms the competition, delivering blazing-fast execution speeds while continuously expanding its robust feature set.**

### Compilation Benchmarks

&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/assets/build_benchmark_solady_dark.png&quot; width=&quot;600px&quot;&gt;
    &lt;img src=&quot;.github/assets/build_benchmark_solady_light.png&quot; width=&quot;600px&quot;&gt;
  &lt;/picture&gt;

&lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/assets/build_benchmark_openzeppelin_dark.png&quot; width=&quot;600px&quot;&gt;
    &lt;img src=&quot;.github/assets/build_benchmark_openzeppelin_light.png&quot; width=&quot;600px&quot;&gt;
  &lt;/picture&gt;

&amp;nbsp;

&lt;/div&gt;

**Takeaway: Forge compilation is consistently faster than Hardhat by a factor of `2.1x` to `5.2x`, depending on the amount of caching involved.**

## Forge

Forge helps you build, test, fuzz, debug and deploy Solidity contracts.

The best way to understand Forge is to simply try it (in less than 30 seconds!).

First, let&#039;s initialize a new `counter` example repository:

```sh
forge init counter
```

Next `cd` into `counter` and build :

```sh
forge build
```

```console
[⠊] Compiling...
[⠔] Compiling 27 files with Solc 0.8.28
[⠒] Solc 0.8.28 finished in 452.13ms
Compiler run successful!
```

Let&#039;s [test](https://getfoundry.sh/forge/tests#tests) our contracts:

```sh
forge test
```

```console
[⠊] Compiling...
No files changed, compilation skipped

Ran 2 tests for test/Counter.t.sol:CounterTest
[PASS] testFuzz_SetNumber(uint256) (runs: 256, μ: 31121, ~: 31277)
[PASS] test_Increment() (gas: 31293)
Suite result: ok. 2 passed; 0 failed; 0 skipped; finished in 5.35ms (4.86ms CPU time)

Ran 1 test suite in 5.91ms (5.35ms CPU time): 2 tests passed, 0 failed, 0 skipped (2 total tests)
```

Finally, let&#039;s run our deployment script:

```sh
forge script script/Counter.s.sol
```

```console
[⠊] Compiling...
No files changed, compilation skipped
Script ran successfully.
Gas used: 109037

If you wish to simulate on-chain transactions pass a RPC URL.
```

Run `forge --help` to explore the full list of available subcommands and their usage.

More documentation can be found in the [forge](https://getfoundry.sh/forge/overview) section of the Foundry Docs.

## Cast

Cast is a Swiss Army knife for interacting with Ethereum applications from the command line.

Here are a few examples of what you can do:

**Check the latest block on Ethereum Mainnet**:

```sh
cast block-number --rpc-url https://eth.merkle.io
```

**Check the Ether balance of `vitalik.eth`**

```sh
cast balance vitalik.eth --ether --rpc-url https://eth.merkle.io
```

**Replay and trace a transaction**

```sh
cast run 0x9c32042f5e997e27e67f82583839548eb19dc78c4769ad6218657c17f2a5ed31 --rpc-url https://eth.merkle.io
```

Optionally, pass `--etherscan-api-key &lt;API_KEY&gt;` to decode transaction traces using verified source maps, providing more detailed and human-readable information.

---

Run `cast --help` to explore the full list of available subcommands and their usage.

More documentation can be found in the [cast](https://getfoundry.sh/cast/overview) section of the Foundry Docs.

## Anvil

Anvil is a fast local Ethereum development node.

Let&#039;s fork Ethereum mainnet at the latest block:

```sh
anvil --fork-url https://eth.merkle.io
```

You can use those same `cast` subcommands against your `anvil` instance:

```sh
cast block-number
```

---

Run `anvil --help` to explore the full list of available features and their usage.

More documentation can be found in the [anvil](https://getfoundry.sh/anvil/overview) section of the Foundry Docs.

## Chisel

Chisel is a fast, utilitarian, and verbose Solidity REPL.

To use Chisel, simply type `chisel`.

```sh
chisel
```

From here, start writing Solidity code! Chisel will offer verbose feedback on each input.

Create a variable `a` and query it:

```console
➜ uint256 a = 123;
➜ a
Type: uint256
├ Hex: 0x7b
├ Hex (full word): 0x000000000000000000000000000000000000000000000000000000000000007b
└ Decimal: 123
```

Finally, run `!source` to see `a` was applied:

```solidity
// SPDX-License-Identifier: UNLICENSED
pragma solidity ^0.8.28;

import {Vm} from &quot;forge-std/Vm.sol&quot;;

contract REPL {
    Vm internal constant vm = Vm(address(uint160(uint256(keccak256(&quot;hevm cheat code&quot;)))));

    /// @notice REPL contract entry point
    function run() public {
        uint256 a = 123;
    }
}
```

---

Run `chisel --help` to explore the full list of available features and their usage.

More documentation can be found in the [chisel](https://getfoundry.sh/chisel/overview) section of the Foundry Docs.

## Configuration

Foundry is highly configurable, allowing you to tailor it to your needs. Configuration is managed via a file called [`foundry.toml`](./crates/config) located in the root of your project or any parent directory. For a full list of configuration options, refer to the [config package documentation](./crates/config/README.md#all-options).

**Profiles and Namespaces**

- Configuration can be organized into **profiles**, which are arbitrarily namespaced for flexibility.
- The default profile is named `default`. Learn more in the [Default Profile section](./crates/config/README.md#default-profile).
- To select a different profile, set the `FOUNDRY_PROFILE` environment variable.
- Override specific settings using environment variables prefixed with `FOUNDRY_` (e.g., `FOUNDRY_SRC`).

---

You can find additional [setup and configurations guides](https://getfoundry.sh/config/overview) in the [Foundry Docs][foundry-docs] and in the [config crate](./crates/config/README.md):

- [Configuring with `foundry.toml`](https://getfoundry.sh/config/overview)
- [Setting up VSCode][vscode-setup]
- [Shell autocompletions][shell-setup]

## Contributing

See our [contributing guidelines](./CONTRIBUTING.md).

## Getting Help

First, see if the answer to your question can be found in the [Foundry Docs][foundry-docs], or in the relevant crate.

If the answer is not there:

- Join the [support Telegram][tg-support-url] to get help, or
- Open a [discussion](https://github.com/foundry-rs/foundry/discussions/new) with your question, or
- Open an issue with [the bug](https://github.com/foundry-rs/foundry/issues/new)

If you want to contribute, or follow along with contributor discussion, you can use our [main telegram](https://t.me/foundry_rs) to chat with us about the development of Foundry!

## License

Licensed under either of [Apache License](./LICENSE-APACHE), Version
2.0 or [MIT License](./LICENSE-MIT) at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in these crates by you, as defined in the Apache-2.0 license,
shall be dual licensed as above, without any additional terms or conditions.

## Acknowledgements

- Foundry is a clean-room rewrite of the testing framework [DappTools][dapptools]. None of this would have been possible without the DappHub team&#039;s work over the years.
- [Matthias Seitz](https://twitter.com/mattsse_): Created [ethers-solc] (now [foundry-compilers]) which is the backbone of our compilation pipeline, as well as countless contributions to ethers, in particular the `abigen` macros.
- [Rohit Narurkar](https://twitter.com/rohitnarurkar): Created the Rust Solidity version manager [svm-rs](https://github.com/roynalnaruto/svm-rs) which we use to auto-detect and manage multiple Solidity versions.
- [Brock Elmore](https://twitter.com/brockjelmore): For extending the VM&#039;s cheatcodes and implementing [structured call tracing](https://github.com/foundry-rs/foundry/pull/192), a critical feature for debugging smart contract calls.
- All the other [contributors](https://github.com/foundry-rs/foundry/graphs/contributors) to the [ethers-rs](https://github.com/gakonst/ethers-rs), [alloy][alloy] &amp; [foundry](https://github.com/foundry-rs/foundry) repositories and chatrooms.

[solidity]: https://soliditylang.org/
[foundry-docs]: https://getfoundry.sh
[foundry-gha]: https://github.com/foundry-rs/foundry-toolchain
[foundry-compilers]: https://github.com/foundry-rs/compilers
[ethers-solc]: https://github.com/gakonst/ethers-rs/tree/master/ethers-solc/
[solady]: https://github.com/Vectorized/solady
[openzeppelin]: https://github.com/OpenZeppelin/openzeppelin-contracts/tree/release-v5.1
[morpho-blue]: https://github.com/morpho-org/morpho-blue
[foundry-compilers]: https://github.com/foundry-rs/compilers
[solmate]: https://github.com/transmissions11/solmate/
[geb]: https://github.com/reflexer-labs/geb
[benchmark-post]: https://www.paradigm.xyz/2022/03/foundry-02#blazing-fast-compilation--testing
[convex]: https://github.com/mds1/convex-shutdown-simulation
[vscode-setup]: https://getfoundry.sh/config/vscode.html
[shell-setup]: https://getfoundry.sh/config/shell-autocompletion.html
[foundry-0.2]: https://github.com/foundry-rs/foundry/releases/tag/nightly-5b7e4cb3c882b28f3c32ba580de27ce7381f415a
[foundry-1.0]: https://github.com/foundry-rs/foundry/releases/tag/nightly-59f354c179f4e7f6d7292acb3d068815c79286d1
[dapptools]: https://github.com/dapphub/dapptools
[alloy]: https://github.com/alloy-rs/alloy
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[neondatabase/neon]]></title>
            <link>https://github.com/neondatabase/neon</link>
            <guid>https://github.com/neondatabase/neon</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Neon: Serverless Postgres. We separated storage and compute to offer autoscaling, code-like database branching, and scale to zero.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/neondatabase/neon">neondatabase/neon</a></h1>
            <p>Neon: Serverless Postgres. We separated storage and compute to offer autoscaling, code-like database branching, and scale to zero.</p>
            <p>Language: Rust</p>
            <p>Stars: 19,687</p>
            <p>Forks: 770</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>[![Neon](https://github.com/neondatabase/neon/assets/11527560/f15a17f0-836e-40c5-b35d-030606a6b660)](https://neon.tech)



# Neon

Neon is a serverless open-source alternative to AWS Aurora Postgres. It separates storage and compute and substitutes the PostgreSQL storage layer by redistributing data across a cluster of nodes.

## Quick start
Try the [Neon Free Tier](https://neon.tech/github) to create a serverless Postgres instance. Then connect to it with your preferred Postgres client (psql, dbeaver, etc) or use the online [SQL Editor](https://neon.tech/docs/get-started-with-neon/query-with-neon-sql-editor/). See [Connect from any application](https://neon.tech/docs/connect/connect-from-any-app/) for connection instructions.

Alternatively, compile and run the project [locally](#running-local-installation).

## Architecture overview

A Neon installation consists of compute nodes and the Neon storage engine. Compute nodes are stateless PostgreSQL nodes backed by the Neon storage engine.

The Neon storage engine consists of two major components:
- Pageserver: Scalable storage backend for the compute nodes.
- Safekeepers: The safekeepers form a redundant WAL service that received WAL from the compute node, and stores it durably until it has been processed by the pageserver and uploaded to cloud storage.

See developer documentation in [SUMMARY.md](/docs/SUMMARY.md) for more information.

## Running a local development environment

Neon can be run on a workstation for small experiments and to test code changes, by
following these instructions.

#### Installing dependencies on Linux
1. Install build dependencies and other applicable packages

* On Ubuntu or Debian, this set of packages should be sufficient to build the code:
```bash
apt install build-essential libtool libreadline-dev zlib1g-dev flex bison libseccomp-dev \
libssl-dev clang pkg-config libpq-dev cmake postgresql-client protobuf-compiler \
libprotobuf-dev libcurl4-openssl-dev openssl python3-poetry lsof libicu-dev
```
* On Fedora, these packages are needed:
```bash
dnf install flex bison readline-devel zlib-devel openssl-devel \
  libseccomp-devel perl clang cmake postgresql postgresql-contrib protobuf-compiler \
  protobuf-devel libcurl-devel openssl poetry lsof libicu-devel libpq-devel python3-devel \
  libffi-devel
```
* On Arch based systems, these packages are needed:
```bash
pacman -S base-devel readline zlib libseccomp openssl clang \
postgresql-libs cmake postgresql protobuf curl lsof
```

Building Neon requires 3.15+ version of `protoc` (protobuf-compiler). If your distribution provides an older version, you can install a newer version from [here](https://github.com/protocolbuffers/protobuf/releases).

2. [Install Rust](https://www.rust-lang.org/tools/install)
```
# recommended approach from https://www.rust-lang.org/tools/install
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

#### Installing dependencies on macOS (12.3.1)
1. Install XCode and dependencies
```
xcode-select --install
brew install protobuf openssl flex bison icu4c pkg-config m4

# add openssl to PATH, required for ed25519 keys generation in neon_local
echo &#039;export PATH=&quot;$(brew --prefix openssl)/bin:$PATH&quot;&#039; &gt;&gt; ~/.zshrc
```

If you get errors about missing `m4` you may have to install it manually:
```
brew install m4
brew link --force m4
```

2. [Install Rust](https://www.rust-lang.org/tools/install)
```
# recommended approach from https://www.rust-lang.org/tools/install
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

3. Install PostgreSQL Client
```
# from https://stackoverflow.com/questions/44654216/correct-way-to-install-psql-without-full-postgres-on-macos
brew install libpq
brew link --force libpq
```

#### Rustc version

The project uses [rust toolchain file](./rust-toolchain.toml) to define the version it&#039;s built with in CI for testing and local builds.

This file is automatically picked up by [`rustup`](https://rust-lang.github.io/rustup/overrides.html#the-toolchain-file) that installs (if absent) and uses the toolchain version pinned in the file.

rustup users who want to build with another toolchain can use the [`rustup override`](https://rust-lang.github.io/rustup/overrides.html#directory-overrides) command to set a specific toolchain for the project&#039;s directory.

non-rustup users most probably are not getting the same toolchain automatically from the file, so are responsible to manually verify that their toolchain matches the version in the file.
Newer rustc versions most probably will work fine, yet older ones might not be supported due to some new features used by the project or the crates.

#### Building on Linux

1. Build neon and patched postgres
```
# Note: The path to the neon sources can not contain a space.

git clone --recursive https://github.com/neondatabase/neon.git
cd neon

# The preferred and default is to make a debug build. This will create a
# demonstrably slower build than a release build. For a release build,
# use &quot;BUILD_TYPE=release make -j`nproc` -s&quot;
# Remove -s for the verbose build log

make -j`nproc` -s
```

#### Building on OSX

1. Build neon and patched postgres
```
# Note: The path to the neon sources can not contain a space.

git clone --recursive https://github.com/neondatabase/neon.git
cd neon

# The preferred and default is to make a debug build. This will create a
# demonstrably slower build than a release build. For a release build,
# use &quot;BUILD_TYPE=release make -j`sysctl -n hw.logicalcpu` -s&quot;
# Remove -s for the verbose build log

make -j`sysctl -n hw.logicalcpu` -s
```

#### Dependency installation notes
To run the `psql` client, install the `postgresql-client` package or modify `PATH` and `LD_LIBRARY_PATH` to include `pg_install/bin` and `pg_install/lib`, respectively.

To run the integration tests or Python scripts (not required to use the code), install
Python (3.11 or higher), and install the python3 packages using `./scripts/pysync` (requires [poetry&gt;=1.8](https://python-poetry.org/)) in the project directory.


#### Running neon database
1. Start pageserver and postgres on top of it (should be called from repo root):
```sh
# Create repository in .neon with proper paths to binaries and data
# Later that would be responsibility of a package install script
&gt; cargo neon init
Initializing pageserver node 1 at &#039;127.0.0.1:64000&#039; in &quot;.neon&quot;

# start pageserver, safekeeper, and broker for their intercommunication
&gt; cargo neon start
Starting neon broker at 127.0.0.1:50051.
storage_broker started, pid: 2918372
Starting pageserver node 1 at &#039;127.0.0.1:64000&#039; in &quot;.neon&quot;.
pageserver started, pid: 2918386
Starting safekeeper at &#039;127.0.0.1:5454&#039; in &#039;.neon/safekeepers/sk1&#039;.
safekeeper 1 started, pid: 2918437

# create initial tenant and use it as a default for every future neon_local invocation
&gt; cargo neon tenant create --set-default
tenant 9ef87a5bf0d92544f6fafeeb3239695c successfully created on the pageserver
Created an initial timeline &#039;de200bd42b49cc1814412c7e592dd6e9&#039; at Lsn 0/16B5A50 for tenant: 9ef87a5bf0d92544f6fafeeb3239695c
Setting tenant 9ef87a5bf0d92544f6fafeeb3239695c as a default one

# create postgres compute node
&gt; cargo neon endpoint create main

# start postgres compute node
&gt; cargo neon endpoint start main
Starting new endpoint main (PostgreSQL v14) on timeline de200bd42b49cc1814412c7e592dd6e9 ...
Starting postgres at &#039;postgresql://cloud_admin@127.0.0.1:55432/postgres&#039;

# check list of running postgres instances
&gt; cargo neon endpoint list
 ENDPOINT  ADDRESS          TIMELINE                          BRANCH NAME  LSN        STATUS
 main      127.0.0.1:55432  de200bd42b49cc1814412c7e592dd6e9  main         0/16B5BA8  running
```

2. Now, it is possible to connect to postgres and run some queries:
```text
&gt; psql -p 55432 -h 127.0.0.1 -U cloud_admin postgres
postgres=# CREATE TABLE t(key int primary key, value text);
CREATE TABLE
postgres=# insert into t values(1,1);
INSERT 0 1
postgres=# select * from t;
 key | value
-----+-------
   1 | 1
(1 row)
```

3. And create branches and run postgres on them:
```sh
# create branch named migration_check
&gt; cargo neon timeline branch --branch-name migration_check
Created timeline &#039;b3b863fa45fa9e57e615f9f2d944e601&#039; at Lsn 0/16F9A00 for tenant: 9ef87a5bf0d92544f6fafeeb3239695c. Ancestor timeline: &#039;main&#039;

# check branches tree
&gt; cargo neon timeline list
(L) main [de200bd42b49cc1814412c7e592dd6e9]
(L) ┗━ @0/16F9A00: migration_check [b3b863fa45fa9e57e615f9f2d944e601]

# create postgres on that branch
&gt; cargo neon endpoint create migration_check --branch-name migration_check

# start postgres on that branch
&gt; cargo neon endpoint start migration_check
Starting new endpoint migration_check (PostgreSQL v14) on timeline b3b863fa45fa9e57e615f9f2d944e601 ...
Starting postgres at &#039;postgresql://cloud_admin@127.0.0.1:55434/postgres&#039;

# check the new list of running postgres instances
&gt; cargo neon endpoint list
 ENDPOINT         ADDRESS          TIMELINE                          BRANCH NAME      LSN        STATUS
 main             127.0.0.1:55432  de200bd42b49cc1814412c7e592dd6e9  main             0/16F9A38  running
 migration_check  127.0.0.1:55434  b3b863fa45fa9e57e615f9f2d944e601  migration_check  0/16F9A70  running

# this new postgres instance will have all the data from &#039;main&#039; postgres,
# but all modifications would not affect data in original postgres
&gt; psql -p 55434 -h 127.0.0.1 -U cloud_admin postgres
postgres=# select * from t;
 key | value
-----+-------
   1 | 1
(1 row)

postgres=# insert into t values(2,2);
INSERT 0 1

# check that the new change doesn&#039;t affect the &#039;main&#039; postgres
&gt; psql -p 55432 -h 127.0.0.1 -U cloud_admin postgres
postgres=# select * from t;
 key | value
-----+-------
   1 | 1
(1 row)
```

4. If you want to run tests afterwards (see below), you must stop all the running pageserver, safekeeper, and postgres instances
   you have just started. You can terminate them all with one command:
```sh
&gt; cargo neon stop
```

More advanced usages can be found at [Local Development Control Plane (`neon_local`))](./control_plane/README.md).

#### Handling build failures

If you encounter errors during setting up the initial tenant, it&#039;s best to stop everything (`cargo neon stop`) and remove the `.neon` directory. Then fix the problems, and start the setup again.

## Running tests

### Rust unit tests

We are using [`cargo-nextest`](https://nexte.st/) to run the tests in Github Workflows.
Some crates do not support running plain `cargo test` anymore, prefer `cargo nextest run` instead.
You can install `cargo-nextest` with `cargo install cargo-nextest`.

### Integration tests

Ensure your dependencies are installed as described [here](https://github.com/neondatabase/neon#dependency-installation-notes).

```sh
git clone --recursive https://github.com/neondatabase/neon.git

CARGO_BUILD_FLAGS=&quot;--features=testing&quot; make

./scripts/pytest
```

By default, this runs both debug and release modes, and all supported postgres versions. When
testing locally, it is convenient to run just one set of permutations, like this:

```sh
DEFAULT_PG_VERSION=17 BUILD_TYPE=release ./scripts/pytest
```

## Flamegraphs

You may find yourself in need of flamegraphs for software in this repository.
You can use [`flamegraph-rs`](https://github.com/flamegraph-rs/flamegraph) or the original [`flamegraph.pl`](https://github.com/brendangregg/FlameGraph). Your choice!

&gt;[!IMPORTANT]
&gt; If you&#039;re using `lld` or `mold`, you need the `--no-rosegment` linker argument.
&gt; It&#039;s a [general thing with Rust / lld / mold](https://crbug.com/919499#c16), not specific to this repository.
&gt; See [this PR for further instructions](https://github.com/neondatabase/neon/pull/6764).

## Cleanup

For cleaning up the source tree from build artifacts, run `make clean` in the source directory.

For removing every artifact from build and configure steps, run `make distclean`, and also consider removing the cargo binaries in the `target` directory, as well as the database in the `.neon` directory. Note that removing the `.neon` directory will remove your database, with all data in it. You have been warned!

## Documentation

[docs](/docs) Contains a top-level overview of all available markdown documentation.

- [sourcetree.md](/docs/sourcetree.md) contains overview of source tree layout.

To view your `rustdoc` documentation in a browser, try running `cargo doc --no-deps --open`

See also README files in some source directories, and `rustdoc` style documentation comments.

Other resources:

- [SELECT &#039;Hello, World&#039;](https://neon.tech/blog/hello-world/): Blog post by Nikita Shamgunov on the high level architecture
- [Architecture decisions in Neon](https://neon.tech/blog/architecture-decisions-in-neon/): Blog post by Heikki Linnakangas
- [Neon: Serverless PostgreSQL!](https://www.youtube.com/watch?v=rES0yzeERns): Presentation on storage system by Heikki Linnakangas in the CMU Database Group seminar series

### Postgres-specific terms

Due to Neon&#039;s very close relation with PostgreSQL internals, numerous specific terms are used.
The same applies to certain spelling: i.e. we use MB to denote 1024 * 1024 bytes, while MiB would be technically more correct, it&#039;s inconsistent with what PostgreSQL code and its documentation use.

To get more familiar with this aspect, refer to:

- [Neon glossary](/docs/glossary.md)
- [PostgreSQL glossary](https://www.postgresql.org/docs/14/glossary.html)
- Other PostgreSQL documentation and sources (Neon fork sources can be found [here](https://github.com/neondatabase/postgres))

## Join the development

- Read [CONTRIBUTING.md](/CONTRIBUTING.md) to learn about project code style and practices.
- To get familiar with a source tree layout, use [sourcetree.md](/docs/sourcetree.md).
- To learn more about PostgreSQL internals, check http://www.interdb.jp/pg/index.html
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/cargo]]></title>
            <link>https://github.com/rust-lang/cargo</link>
            <guid>https://github.com/rust-lang/cargo</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[The Rust package manager]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/cargo">rust-lang/cargo</a></h1>
            <p>The Rust package manager</p>
            <p>Language: Rust</p>
            <p>Stars: 14,000</p>
            <p>Forks: 2,645</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># Cargo

Cargo downloads your Rust project’s dependencies and compiles your project.

**To start using Cargo**, learn more at [The Cargo Book].

**To start developing Cargo itself**, read the [Cargo Contributor Guide].

[The Cargo Book]: https://doc.rust-lang.org/cargo/
[Cargo Contributor Guide]: https://rust-lang.github.io/cargo/contrib/

&gt; The Cargo binary distributed through with Rust is maintained by the Cargo
&gt; team for use by the wider ecosystem.
&gt; For all other uses of this crate (as a binary or library) this is maintained
&gt; by the Cargo team, primarily for use by Cargo and not intended for external
&gt; use (except as a transitive dependency). This crate may make major changes to
&gt; its APIs.

## Code Status

[![CI](https://github.com/rust-lang/cargo/actions/workflows/main.yml/badge.svg?branch=auto-cargo)](https://github.com/rust-lang/cargo/actions/workflows/main.yml)

Code documentation: &lt;https://doc.rust-lang.org/nightly/nightly-rustc/cargo/&gt;

## Compiling from Source

### Requirements

Cargo requires the following tools and packages to build:

* `cargo` and `rustc`
* A C compiler [for your platform](https://github.com/rust-lang/cc-rs#compile-time-requirements)
* `git` (to clone this repository)

**Other requirements:**

The following are optional based on your platform and needs.

* `pkg-config` — This is used to help locate system packages, such as `libssl` headers/libraries. This may not be required in all cases, such as using vendored OpenSSL, or on Windows.
* OpenSSL — Only needed on Unix-like systems and only if the `vendored-openssl` Cargo feature is not used.

  This requires the development headers, which can be obtained from the `libssl-dev` package on Ubuntu or `openssl-devel` with apk or yum or the `openssl` package from Homebrew on macOS.

  If using the `vendored-openssl` Cargo feature, then a static copy of OpenSSL will be built from source instead of using the system OpenSSL.
  This may require additional tools such as `perl` and `make`.

  On macOS, common installation directories from Homebrew, MacPorts, or pkgsrc will be checked. Otherwise it will fall back to `pkg-config`.

  On Windows, the system-provided Schannel will be used instead.

  LibreSSL is also supported.

**Optional system libraries:**

The build will automatically use vendored versions of the following libraries. However, if they are provided by the system and can be found with `pkg-config`, then the system libraries will be used instead:

* [`libcurl`](https://curl.se/libcurl/) — Used for network transfers.
* [`libgit2`](https://libgit2.org/) — Used for fetching git dependencies.
* [`libssh2`](https://www.libssh2.org/) — Used for SSH access to git repositories.
* [`libz`](https://zlib.net/) (AKA zlib) — Used by the above C libraries for data compression. (Rust code uses [`zlib-rs`](https://github.com/trifectatechfoundation/zlib-rs) instead.)

It is recommended to use the vendored versions as they are the versions that are tested to work with Cargo.

### Compiling

First, you&#039;ll want to check out this repository

```
git clone https://github.com/rust-lang/cargo.git
cd cargo
```

With `cargo` already installed, you can simply run:

```
cargo build --release
```

## Adding new subcommands to Cargo

Cargo is designed to be extensible with new subcommands without having to modify
Cargo itself. See [the Wiki page][third-party-subcommands] for more details and
a list of known community-developed subcommands.

[third-party-subcommands]: https://github.com/rust-lang/cargo/wiki/Third-party-cargo-subcommands


## Releases

Cargo releases coincide with Rust releases.
High level release notes are available as part of [Rust&#039;s release notes][rel].
Detailed release notes are available in the [changelog].

[rel]: https://github.com/rust-lang/rust/blob/master/RELEASES.md
[changelog]: https://doc.rust-lang.org/nightly/cargo/CHANGELOG.html

## Reporting issues

Found a bug? We&#039;d love to know about it!

Please report all issues on the GitHub [issue tracker][issues].

[issues]: https://github.com/rust-lang/cargo/issues

## Contributing

See the **[Cargo Contributor Guide]** for a complete introduction
to contributing to Cargo.

## License

Cargo is primarily distributed under the terms of both the MIT license
and the Apache License (Version 2.0).

See [LICENSE-APACHE](LICENSE-APACHE) and [LICENSE-MIT](LICENSE-MIT) for details.

### Third party software

This product includes software developed by the OpenSSL Project
for use in the OpenSSL Toolkit (https://www.openssl.org/).

In binary form, this product includes software that is licensed under the
terms of the GNU General Public License, version 2, with a linking exception,
which can be obtained from the [upstream repository][1].

See [LICENSE-THIRD-PARTY](LICENSE-THIRD-PARTY) for details.

[1]: https://github.com/libgit2/libgit2

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[EFForg/rayhunter]]></title>
            <link>https://github.com/EFForg/rayhunter</link>
            <guid>https://github.com/EFForg/rayhunter</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Rust tool to detect cell site simulators on an orbic mobile hotspot]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EFForg/rayhunter">EFForg/rayhunter</a></h1>
            <p>Rust tool to detect cell site simulators on an orbic mobile hotspot</p>
            <p>Language: Rust</p>
            <p>Stars: 2,814</p>
            <p>Forks: 207</p>
            <p>Stars today: 66 stars today</p>
            <h2>README</h2><pre># Rayhunter
![Tests](https://github.com/EFForg/rayhunter/actions/workflows/main.yml/badge.svg)

![Rayhunter Logo - An Orca taking a bite out of a cellular signal bar](https://www.eff.org/files/styles/media_browser_preview/public/banner_library/rayhunter-banner.png)

Rayhunter is a project for detecting IMSI catchers, also known as cell-site simulators or stingrays. It was first designed to run on a cheap mobile hotspot called the Orbic RC400L, but thanks to community efforts can [support some other devices as well](https://efforg.github.io/rayhunter/supported-devices.html).
It&#039;s also designed to be as easy to install and use as possible, regardless of your level of technical skills, and to minimize false positives. 

&amp;rarr;  Check out the [installation guide](https://efforg.github.io/rayhunter/installation.html) to get started.

&amp;rarr; To learn more about the aim of the project, and about IMSI catchers in general, please check out our [introductory blog post](https://www.eff.org/deeplinks/2025/03/meet-rayhunter-new-open-source-tool-eff-detect-cellular-spying). 

&amp;rarr; For discussion, help, or to join the mattermost channel and get involved with the project and community check out the [many ways listed here](https://efforg.github.io/rayhunter/support-feedback-community.html)!

&amp;rarr; To learn more about the project in general check out the [Rayhunter Book](https://efforg.github.io/rayhunter/).

**LEGAL DISCLAIMER:** Use this program at your own risk. We believe running this program does not currently violate any laws or regulations in the United States. However, we are not responsible for civil or criminal liability resulting from the use of this software. If you are located outside of the US please consult with an attorney in your country to help you assess the legal risks of running this program.

*Good Hunting!*
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ithacaxyz/relay]]></title>
            <link>https://github.com/ithacaxyz/relay</link>
            <guid>https://github.com/ithacaxyz/relay</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[Transparent cross-chain transaction routing for EIP-7702 accounts]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ithacaxyz/relay">ithacaxyz/relay</a></h1>
            <p>Transparent cross-chain transaction routing for EIP-7702 accounts</p>
            <p>Language: Rust</p>
            <p>Stars: 74</p>
            <p>Forks: 11</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># Ithaca Relay

A transparent cross-chain transaction router for EIP-7702 accounts, specifically built for [Porto](https://github.com/ithacaxyz/porto).

## Table of Contents

- [Running](#running)
- [Testing](#testing)
    - [End-to-End](#end-to-end)
- [Deploying](#deploying)

## Running

To run the relay, you can either use Docker or run the binary directly.

### Prerequisites

The relay depends on the following things being available on the chains it connects to:

- [EIP-7702](https://eips.ethereum.org/EIPS/eip-7702) is enabled.
- [EIP-1559](https://eips.ethereum.org/EIPS/eip-1559) is enabled.
- [`eth_simulateV1`](https://geth.ethereum.org/docs/interacting-with-geth/rpc/ns-eth#eth-simulate-v1) is enabled, *or* [`debug_traceCall`](https://geth.ethereum.org/docs/interacting-with-geth/rpc/ns-debug#debugtracecall) with log collection support.
- The [RIP-7212](https://github.com/ethereum/RIPs/blob/master/RIPS/rip-7212.md) secp256r1 precompile is available, *or* a [shim](https://vectorized.github.io/solady/#/utils/p256?id=p256) is deployed[^1].
- [Multicall3](https://www.multicall3.com/)
- `PUSH0`

Additionally, the relay can also leverage several things for faster confirmations and increased reliability, including:

- [Flashblocks](https://docs.base.org/base-chain/flashblocks/apps)
- Using sequencer endpoints

These things must be enabled in the configuration.

[^1]: If the secp256r1 precompile is enabled, the address `0x0000000000001Ab2e8006Fd8B71907bf06a5BDEE` must additionally be a contract. This acts as a canary signalling the Solady P256 library that the precompile exists. If the canary is not deployed, the shim will be tried first. See [Solady&#039;s P256 library](https://github.com/Vectorized/solady/blob/a096f4fb0f65d1c6d6677ea6b13e9d41cb0bf798/src/utils/P256.sol#L19-L25).

### Deployment

1. Deploy the [delegation and orchestrator contracts](https://github.com/ithacaxyz/account) on the destination chain.
1. Deploy or identify at least one token to accept as fee token(s).
1. Generate two private keys, one for transaction signing, and one for quote signing. You can do this with `cast wallet new`.

Run the relay, passing in the following flags. In the example below, the binary will be run directly with `cargo`:

```sh
cargo run --bin relay -- \
    --endpoint $RPC_URL \ # You can pass this multiple times
    --fee-token $FEE_TOKEN_ADDR \ # You can pass this multiple times
    --signers-mnemonic $SIGNING_KEY_MNEMONIC \
    --config $CONFIG_PATH
```

The relay reads its configuration from the file located at `--config` (default `relay.yaml`). If it does not exist, it will be created from CLI arguments.

The precedence for config is: CLI &gt; environment variables &gt; configuration file.

#### Configuration examples

Below are some example configs with explanations on how they work. For a complete config for running the relay locally, see [`relay.example.yaml`](./relay.example.yaml).

##### Minimal

A minimal configuration for a single chain.

```yaml
fee_recipient: &quot;0x0000000000000000000000000000000000000000&quot;

orchestrator: &quot;0x&quot;
delegation_proxy: &quot;0x&quot;
simulator: &quot;0x&quot;
escrow: &quot;0x&quot;
funder: &quot;0x&quot;

chains:
  # The key is either a chain ID, or a chain name.
  ethereum:
    endpoint: &quot;wss://eth.rpc.com/&quot;
    assets:
      ethereum:
        # Address 0 denotes the native asset and it must be present, even if it is not a fee token.
        address: &quot;0x0000000000000000000000000000000000000000&quot;
        fee_token: true
      usd-coin:
        address: &quot;0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48&quot;
        fee_token: true
```

##### Interop

A minimal configuration for interop between two chains, i.e. liquidity can move between them.

```yaml
fee_recipient: &quot;0x0000000000000000000000000000000000000000&quot;

orchestrator: &quot;0x&quot;
delegation_proxy: &quot;0x&quot;
simulator: &quot;0x&quot;
escrow: &quot;0x&quot;
funder: &quot;0x&quot;

chains:
  ethereum:
    endpoint: &quot;wss://eth.rpc.com/&quot;
    # Settler address is required for chains with interop-enabled assets
    settler_address: &quot;0x1234567890123456789012345678901234567890&quot;
    assets:
      ethereum:
        address: &quot;0x0000000000000000000000000000000000000000&quot;
        fee_token: true
        # Assets with this flag can be relayed across chains.
        interop: true
      usd-coin:
        address: &quot;0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48&quot;
        fee_token: true
        interop: true
  optimism:
    endpoint: &quot;wss://op.rpc.com/&quot;
    # Each chain can have its own settler address
    settler_address: &quot;0x0987654321098765432109876543210987654321&quot;
    assets:
      ethereum:
        address: &quot;0x0000000000000000000000000000000000000000&quot;
        fee_token: true
        interop: true
      usd-coin:
        address: &quot;0x0b2C639c533813f4Aa9D7837CAf62653d097Ff85&quot;
        fee_token: true
        interop: true

# For interop to work, a settler must be configured. This example uses the simple settler.
interop:
  settler:
    wait_verification_timeout: 100000
    simple:
      # Note: settler_address has been moved to per-chain configuration
      private_key: &quot;0x...&quot;  # Optional: private key for simple settler
```

##### Cross environment

A minimal configuration where the relay supports two chains, but they are not interopable, i.e. liquidity cannot move between them. This is useful if you want to support the same accounts on two different environments (testnet and mainnet).

```yaml
fee_recipient: &quot;0x0000000000000000000000000000000000000000&quot;

orchestrator: &quot;0x&quot;
delegation_proxy: &quot;0x&quot;
simulator: &quot;0x&quot;
escrow: &quot;0x&quot;
funder: &quot;0x&quot;

pricefeed:
  coingecko:
    # Remaps asset UIDs to CoinGecko coin IDs.
    #
    # If not specified, the UID is used as the coin ID.
    #
    # See &lt;https://docs.coingecko.com/reference/coins-list&gt;
    remapping:
      teth: &quot;ethereum&quot;
      tusdc: &quot;usd-coin&quot;

chains:
  ethereum:
    endpoint: &quot;wss://eth.rpc.com/&quot;
    assets:
      ethereum:
        address: &quot;0x0000000000000000000000000000000000000000&quot;
        fee_token: true
      usd-coin:
        address: &quot;0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48&quot;
        fee_token: true
  # Sepolia and Base Sepolia can still interop.
  # Notice how Ether and USDC have different identifiers. This prevents them from being
  # relayed across chains on different environments.
  sepolia:
    endpoint: &quot;wss://sepolia.rpc.com/&quot;
    # Settler address for Sepolia testnet
    settler_address: &quot;0xabcdef1234567890abcdef1234567890abcdef12&quot;
    assets:
      teth:
        address: &quot;0x0000000000000000000000000000000000000000&quot;
        fee_token: true
        interop: true
      tusdc:
        address: &quot;0x1c7D4B196Cb0C7B01d743Fbc6116a902379C7238&quot;
        fee_token: true
        interop: true
  base-sepolia:
    endpoint: &quot;wss://base-sepolia.rpc.com/&quot;
    # Settler address for Base Sepolia testnet
    settler_address: &quot;0x1234567890abcdef1234567890abcdef12345678&quot;
    assets:
      teth:
        address: &quot;0x0000000000000000000000000000000000000000&quot;
        fee_token: true
        interop: true
      tusdc:
        address: &quot;0x5fd84259d66Cd46123540766Be93DFE6D43130D7&quot;
        fee_token: true
        interop: true

interop:
  settler:
    wait_verification_timeout: 100000
    simple:
      # Note: settler_address has been moved to per-chain configuration
      private_key: &quot;0x...&quot;  # Optional: private key for simple settler
```

##### Chain-specific fee Configuration

A configuration which has different chain-specific fee settings

```yaml
fee_recipient: &quot;0x0000000000000000000000000000000000000000&quot;

orchestrator: &quot;0x&quot;
delegation_proxy: &quot;0x&quot;
simulator: &quot;0x&quot;
escrow: &quot;0x&quot;
funder: &quot;0x&quot;

chains:
  ethereum:
    endpoint: &quot;wss://eth.rpc.com/&quot;
    settler_address: &quot;0x1234567890123456789012345678901234567890&quot;
    assets:
      ethereum:
        address: &quot;0x0000000000000000000000000000000000000000&quot;
        fee_token: true
        interop: true
      usd-coin:
        address: &quot;0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48&quot;
        fee_token: true
        interop: true
    fees:
        # This will be used to calculate the minimum signer balance, it represents the min gas the
        # signer should be able to pay for
        signer_balance_config: 
            type: gas
            value: 10000000
        minimum_fee: 100
  optimism:
    endpoint: &quot;wss://op.rpc.com/&quot;
    settler_address: &quot;0x0987654321098765432109876543210987654321&quot;
    assets:
      ethereum:
        address: &quot;0x0000000000000000000000000000000000000000&quot;
        fee_token: true
        interop: true
      usd-coin:
        address: &quot;0x0b2C639c533813f4Aa9D7837CAf62653d097Ff85&quot;
        fee_token: true
        interop: true
    fees:
        # If a signer balance is below this value, it will become paused. This is in wei
        signer_balance_config:
            type: balance
            value: 10000000000
        # optional, the minimum fee to set in wei
        minimum_fee: 100
        # optional, the amount to multiply the min signer balance when determining how much to fund
        # the account by when it is paused. The default is 3
        top_up_multiplier: 2

interop:
  settler:
    wait_verification_timeout: 100000
    simple:
      # Note: settler_address has been moved to per-chain configuration
      private_key: &quot;0x...&quot;  # Optional: private key for simple settler
```


## Testing

```sh
cargo test
```

### End-to-End

End-to-end tests use [ithacaxyz/account](https://github.com/ithacaxyz/account) under a git submodule located at `tests/account`. These tests depend on building certain these contracts.

#### Prerequisites

- Make sure [`forge`](https://getfoundry.sh/) is installed and available in your PATH.
- Make sure [`cargo-nextest`](https://nextest.rs) is installed an available in your PATH.
- Pull `ithacaxyz/account`

   ```bash
   git submodule update --init --recursive
   ```

#### Running

From the repository root, use the xtask command which automatically builds contracts and runs tests:

```bash
cargo e2e
```

You can pass additional arguments to `cargo test`:

```bash
cargo e2e -- --nocapture --test-threads=1
```

##### Environment Variables

Both approaches support the following environment variables with `.env` support:
- `TEST_CONTRACTS`: Directory for contract artifacts (defaults to `tests/account/out`).
- `TEST_EXTERNAL_ANVIL`: Use an external node for chain 0 instead of spawning Anvil (alias for `TEST_EXTERNAL_ANVIL_0`).
- `TEST_EXTERNAL_ANVIL_N`: Use an external node for chain N (e.g., `TEST_EXTERNAL_ANVIL_0`, `TEST_EXTERNAL_ANVIL_1`).
  - Note: `TEST_EXTERNAL_ANVIL_0` takes precedence over `TEST_EXTERNAL_ANVIL` if both are set.
- `TEST_FORK_URL` / `TEST_FORK_BLOCK_NUMBER`: Fork settings for locally spawned Anvil instances.
- `TEST_EOA_PRIVATE_KEY`: Private key for the EOA signer (defaults to `EOA_PRIVATE_KEY`).
- `TEST_ORCHESTRATOR`: Address for Orchestrator contract; deploys a mock if unset.
- `TEST_PROXY`: Address for proxy contract; deploys a mock if unset.
- `TEST_ERC20`: Address for the payment ERC20 token; deploys a mock if unset.
- `TEST_ERC721`: Address for the ERC721 token; deploys a mock if unset.

Example multi-chain test setup:
```bash
# Chain 0: External Anvil
TEST_EXTERNAL_ANVIL_0=&quot;http://localhost:8545&quot; \
# Chain 1: Spawns locally (no external specified)
# Chain 2: Different external Anvil
TEST_EXTERNAL_ANVIL_2=&quot;http://localhost:8547&quot; \
cargo test test_multichain
```

## Deploying

A docker image is built and pushed to GitHub Packages (`ghcr.io/ithacaxyz/relay`) when a git tag (`vx.y.z`) is pushed to the repository. 
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[FoxIO-LLC/ja4]]></title>
            <link>https://github.com/FoxIO-LLC/ja4</link>
            <guid>https://github.com/FoxIO-LLC/ja4</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[JA4+ is a suite of network fingerprinting standards]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/FoxIO-LLC/ja4">FoxIO-LLC/ja4</a></h1>
            <p>JA4+ is a suite of network fingerprinting standards</p>
            <p>Language: Rust</p>
            <p>Stars: 1,493</p>
            <p>Forks: 138</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;ja4+_transparent_logo.png&quot; alt=&quot;logo&quot; width=&quot;250&quot;/&gt;
&lt;/p&gt;

# JA4+ Network Fingerprinting &lt;!-- omit from toc --&gt;

JA4+ is a suite of network fingerprinting methods by [FoxIO](https://foxio.io/) that are easy to use and easy to share. These methods are both human and machine readable to facilitate more effective threat-hunting and analysis. The use-cases for these fingerprints include scanning for threat actors, malware detection, session hijacking prevention, compliance automation, location tracking, DDoS detection, grouping of threat actors, reverse shell detection, and many more.

For a quick explainer on JA4+ and to use as a reference during analysis see:  
[JA4+ Cheat Sheet](https://x.com/4A4133/status/1887269972545839559)

For in-depth detail, please read our blogs on how JA4+ works, why it works, and examples of what can be detected/prevented with it:  
[JA4+ Network Fingerprinting](https://blog.foxio.io/ja4%2B-network-fingerprinting) (JA4/S/H/L/X/SSH)  
[JA4T: TCP Fingerprinting](https://blog.foxio.io/ja4t-tcp-fingerprinting) (JA4T/TS/TScan)  
[Investigating Surfshark and NordVPN with JA4T](https://blog.foxio.io/investigating-surfshark-and-nordvpn-with-ja4t) (JA4T)

If you love JA4+, consider getting a t-shirt or hoodie:  
[JA4+ Shirts, Hoodies, and Stickers](https://store.foxio.io/)

## Table of contents &lt;!-- omit from toc --&gt;

- [Current methods and implementation details](#current-methods-and-implementation-details)
- [Implementations](#implementations)
- [Tools that support JA4+](#tools-that-support-ja4)
- [Examples](#examples)
- [Plugins](#plugins)
- [Binaries](#binaries)
  - [Release Assets](#release-assets)
  - [Installing tshark](#installing-tshark)
    - [Linux](#linux)
    - [macOS](#macos)
    - [Windows](#windows)
  - [Running JA4+](#running-ja4)
- [Database](#database)
- [Release Process](#release-process)
  - [How to Create a Release](#how-to-create-a-release)
- [JA4+ Details](#ja4-details)
- [Licensing](#licensing)
- [Q\&amp;A](#qa)
- [JA4+ was created by](#ja4-was-created-by)

## Current methods and implementation details

| Full Name | Short Name | Description |
|---|---|---|
| JA4 | JA4 | TLS Client Fingerprinting |
| JA4Server | JA4S | TLS Server Response / Session Fingerprinting |
| JA4HTTP | JA4H | HTTP Client Fingerprinting |
| JA4Latency | JA4L | Client to Server Latency Measurment / Light Distance |
| JA4LatencyServer | JA4LS | Server to Client Latency Measurement / Light Distance |
| JA4X509 | JA4X | X509 TLS Certificate Fingerprinting |
| JA4SSH | JA4SSH | SSH Traffic Fingerprinting |
| JA4TCP | JA4T | TCP Client Fingerprinting |
| JA4TCPServer | JA4TS | TCP Server Response Fingerprinting |
| [JA4TCPScan](https://github.com/FoxIO-LLC/ja4tscan) | [JA4TScan](https://github.com/FoxIO-LLC/ja4tscan) | [Active TCP Fingerprint Scanner](https://github.com/FoxIO-LLC/ja4tscan) |

The full name or short name can be used interchangeably. Additional JA4+ methods are in the works...

To understand how to read JA4+ fingerprints, see [Technical Details](./technical_details/README.md)

## Implementations

This repo includes JA4+ in

- [Python](./python/README.md)
- [Rust](./rust/README.md)
- [C, as a Wireshark plugin](./wireshark/README.md).
- [Zeek](./zeek/README.md)

## Tools that support JA4+

| Tool/Vendor | JA4+ Support |
|-------------|--------------|
| [Wireshark](https://github.com/FoxIO-LLC/ja4/tree/main/wireshark) | JA4+ |
| [Zeek](https://github.com/FoxIO-LLC/ja4/tree/main/zeek) | JA4+ |
| [Arkime](https://arkime.com/settings#ja4plus) | JA4+ |
| [Suricata](https://docs.suricata.io/en/latest/rules/ja-keywords.html#ja4-hash) | JA4+ (under development) |
| [GreyNoise](https://www.greynoise.io/) | JA4+ |
| [Hunt](https://hunt.io/) | JA4+ |
| [Driftnet](https://driftnet.io/) | JA4+ |
| [GoLang](https://github.com/driftnet-io/go-ja4x) | JA4X |
| [nzyme](https://www.nzyme.org/) | JA4+ (under development) |
| [Netresec&#039;s CapLoader](https://www.netresec.com/?page=Blog&amp;month=2023-11&amp;post=CapLoader-1-9-6-Released) | JA4+ (under development) |
| [Netresec&#039;s NetworkMiner](https://www.netresec.com/?page=NetworkMiner) | JA4+ (under development) |
| [NGINX](https://github.com/FoxIO-LLC/ja4-nginx-module) | JA4+ |
| [F5 BIG-IP](https://github.com/f5devcentral/f5-ja4) | JA4+ |
| [nfdump](https://github.com/phaag/nfdump) | JA4+ |
| [ntop&#039;s ntopng](https://github.com/ntop/ntopng) | JA4+ |
| [ntop&#039;s nDPI](https://github.com/ntop/nDPI) | JA4 |
| [Team Cymru](https://www.team-cymru.com/) | JA4+ |
| [NetQuest](https://netquestcorp.com/) | JA4+ |
| [Censys](https://censys.com/) | JA4+ |
| [Exploit.org&#039;s Netryx](https://github.com/OWASP/www-project-netryx) | JA4 and JA4H |
| [Cloudflare](https://developers.cloudflare.com/bots/concepts/ja3-ja4-fingerprint/) | JA4 |
| [Fastly](https://www.fastly.com/documentation/reference/vcl/variables/client-connection/tls-client-ja4/) | JA4+ (ask for it) |
| [MISP](https://www.misp-project.org/) | JA4+ |
| [OCSF](https://schema.ocsf.io/1.3.0-dev/objects/ja4_fingerprint?extensions=) | JA4+ |
| [Vercel](https://vercel.com/docs/security/tls-fingerprints) | JA4 |
| [Seika](https://seika.io/) | JA4+ |
| [VirusTotal](https://www.virustotal.com/) | JA4 |
| [AWS Cloudfront](https://aws.amazon.com/about-aws/whats-new/2024/10/amazon-cloudfront-ja4-fingerprinting/) | JA4 |
| [ELLIO](https://ellio.tech/) | JA4+ |
| [Webscout](https://webscout.io/) | JA4+ |
| [Rama](https://github.com/plabayo/rama) | JA4 and JA4H |
| [Vectra](https://www.vectra.ai/) | JA4+ |
| [AWS WAF](https://aws.amazon.com/about-aws/whats-new/2025/03/aws-waf-ja4-fingerprinting-aggregation-ja3-ja4-fingerprints-rate-based-rules/) | JA4 |
| [Tacticly](https://tactic.ly/) | JA4+ |
| [Palo Alto Networks](https://www.paloaltonetworks.com/cortex/cortex-xpanse) | JA4+ |
| [ngrok](https://ngrok.com/docs/traffic-policy/variables/connection/#conntlsja4_fingerprint) | JA4 |
| [Vertex Synapse](https://vertex.link/) | JA4 and JA4S |
| [Google Cloud Armor](https://cloud.google.com/armor/docs/rules-language-reference#allow_or_deny_traffic_based_on_a_known_ja4_fingerprint) | JA4 |
| [Fortinet](https://docs.fortinet.com/document/fortindr-cloud/25.2.c/user-guide/393114/event-fields#SSL) | JA4 |
| [AppOmni](https://appomni.com/) | JA4+ |
| [IntelliGenesis](https://intelligenesisllc.com/) | JA4+ |
| [HAProxy](https://www.haproxy.org/) | [JA4](https://github.com/O-X-L/haproxy-ja4-fingerprint) and [JA4H](https://github.com/O-X-L/haproxy-ja4h-fingerprint) plugins by [OXL](https://www.o-x-l.com/) |
| [SentinelOne](https://www.sentinelone.com/) | JA4 |
| [Akamai](https://techdocs.akamai.com/application-security/reference/get-ja4-fingerprint-settings) | JA4 |
| [Alibaba Cloud](https://www.alibabacloud.com/help/en/anti-ddos/anti-ddos-pro-and-premium/user-guide/fields-included-in-full-logs) | JA4 |
| [Huawei Cloud](https://support.huaweicloud.com/intl/en-us/usermanual-waf/waf_01_3157.html) | JA4 |
| [Google Cloud LBs](https://cloud.google.com/release-notes#July_28_2025) | JA4 |
| [eSentire](https://www.esentire.com/) | JA4+ |

with more to be announced...  

## Examples

| Application |JA4+ Fingerprints |
|----|----|
| Chrome | ```JA4=t13d1516h2_8daaf6152771_02713d6af862``` (TCP) &lt;br/&gt; ```JA4=q13d0312h3_55b375c5d22e_06cda9e17597``` (QUIC) &lt;br/&gt; ```JA4=t13d1517h2_8daaf6152771_b0da82dd1658``` (pre-shared key) &lt;br/&gt; ```JA4=t13d1517h2_8daaf6152771_b1ff8ab2d16f``` (no key) |
| IcedID Malware Dropper | ```JA4H=ge11cn020000_9ed1ff1f7b03_cd8dafe26982``` |
| IcedID Malware | ```JA4=t13d201100_2b729b4bf6f3_9e7b989ebec8``` &lt;br/&gt; ```JA4S=t120300_c030_5e2616a54c73``` |
| Sliver Malware | ```JA4=t13d190900_9dc949149365_97f8aa674fd9``` &lt;br/&gt; ```JA4S=t130200_1301_a56c5b993250``` &lt;br/&gt; ```JA4X=000000000000_4f24da86fad6_bf0f0589fc03``` &lt;br/&gt; ```JA4X=000000000000_7c32fa18c13e_bf0f0589fc03``` |
| Cobalt Strike | ```JA4H=ge11cn060000_4e59edc1297a_4da5efaf0cbd``` &lt;br/&gt; ```JA4X=2166164053c1_2166164053c1_30d204a01551``` |
| SoftEther VPN | ```JA4=t13d880900_fcb5b95cb75a_b0d3b4ac2a14``` (client) &lt;br/&gt; ```JA4S=t130200_1302_a56c5b993250``` &lt;br/&gt; ```JA4X=d55f458d5a6c_d55f458d5a6c_0fc8c171b6ae``` |
| Qakbot | ```JA4X=2bab15409345_af684594efb4_000000000000``` |
| Pikabot | ```JA4X=1a59268f55e5_1a59268f55e5_795797892f9c``` |
| Darkgate | ```JA4H=po10nn060000_cdb958d032b0``` |
| LummaC2 | ```JA4H=po11nn050000_d253db9d024b``` |
| Evilginx | ```JA4=t13d191000_9dc949149365_e7c285222651``` |
| Reverse SSH Shell | ```JA4SSH=c76s76_c71s59_c0s70``` |
| Windows 10 | ```JA4T=64240_2-1-3-1-1-4_1460_8``` |
| Epson Printer | ```JA4TScan=28960_2-4-8-1-3_1460_3_1-4-8-16``` |

For more examples, see [ja4plus-mapping.csv](./ja4plus-mapping.csv)  
For a complete database, see [ja4db.com](https://ja4db.com/)

## Plugins

[Wireshark](https://github.com/FoxIO-LLC/ja4/tree/main/wireshark)  
[Zeek](https://github.com/FoxIO-LLC/ja4/tree/main/zeek)  
[Arkime](https://arkime.com/settings#ja4plus)

## Binaries

JA4 binaries are built from the [Rust implementation](rust/README.md) of the suite. To ensure full functionality, `tshark` (version 4.0.6 or later) is required. Download the latest JA4 binaries from the [Releases](https://github.com/FoxIO-LLC/ja4/releases) page. The release versions for the Rust implementation follow [Semantic Versioning](https://semver.org/) and are marked as `vX.Y.Z`, unlike Wireshark plugin releases.

### Release Assets


Release assets are named according to the component and platform:

- **Rust:**
  - `ja4-vX.Y.Z-&lt;architecture&gt;-&lt;platform&gt;.tar.gz` (e.g., `ja4-v0.18.5-x86_64-unknown-linux-musl.tar.gz`)
- **Python:**
  - `ja4-python-vX.Y.Z.tar.gz` (contains the full `python/` directory)
- **Wireshark:**
  - `ja4.so.linux`, `ja4.so.macos`, `ja4.dll` (attached to a release named like `wireshark-vX.Y.Z`)

Choose the appropriate file for your system and component.

### Installing tshark

#### Linux

Install it using your package manager (the name of the package `tshark` or `wireshark-cli` depends on the distribution). For example, on Ubuntu:

```sh
sudo apt install tshark
```

#### macOS

1. [Download](https://www.wireshark.org/download.html) and install Wireshark (includes `tshark`).
2. Add `tshark` to your `PATH`:
   ```sh
   sudo ln -s /Applications/Wireshark.app/Contents/MacOS/tshark /usr/local/bin/tshark
   ```

#### Windows

1. [Download](https://www.wireshark.org/download.html) and install Wireshark (includes `tshark.exe`).
2. Locate `tshark.exe` (usually in `C:\Program Files\Wireshark\tshark.exe`).
3. Add the folder containing `tshark.exe` to your system `PATH`:
   - Open **System Properties** &gt; **Environment Variables** &gt; **Edit Path**.

### Running JA4+

Once `tshark` and the JA4+ binaries are available, run JA4+ using the following command:

- On Linux and macOS:
  ```sh
  ./ja4 [options] [pcap]
  ```
- On Windows, open **Command Prompt** and run:
  ```cmd
  ja4 [options] [pcap]
  ```

For more details on running JA4+ and its advanced configurations, refer to the [Rust implementation README](rust/README.md), which provides information on its features, usage scenarios, and customization options.

## Database

The official JA4+ database of fingerprints, associated applications and recommended detection logic is here: [ja4db.com](https://ja4db.com/)  
This database is under very active development. Expect orders of magnitude more fingerprint combinations and data over the next few months.

A sample [ja4plus-mapping.csv](./ja4plus-mapping.csv) is also available for quick reference.

## Release Process


JA4+ uses GitHub Actions to automate releases for its Rust, Python, Wireshark, and Zeek components. Releases are created by pushing a tag with a specific prefix to the repository, except for Zeek, which uses a pure semantic version (semver) tag. Release assets are named as follows:

- **Rust:** `ja4-vX.Y.Z-&lt;architecture&gt;-&lt;platform&gt;.tar.gz`
- **Python:** `ja4-python-vX.Y.Z.tar.gz`
- **Wireshark:** `ja4.so.linux`, `ja4.so.macos`, `ja4.dll` (in a release named like `wireshark-vX.Y.Z`)

The following workflows are available:

- **Rust Release:**  
  Push a tag starting with `rust-`, e.g., `rust-v0.18.5`, to trigger a release of the Rust binaries. The workflow will build and upload release assets automatically.

- **Python Release:**  
  Push a tag starting with `python-`, e.g., `python-v0.1.0`, to trigger a release of the Python implementation. The workflow will create a tarball of the `python/` directory and publish it as a release asset.

- **Wireshark Plugin Release:**  
  Push a tag starting with `wireshark-`, e.g., `wireshark-v2025.09.03`, to trigger a release of the Wireshark plugin binaries for all supported platforms.

- **Zeek Release:**  
  Push a tag that is a pure semantic version (e.g., `v1.2.3`), with no prefix, to trigger a Zeek release. This will automatically create a release on [packages.zeek.org](https://packages.zeek.org/).

### How to Create a Release

1. Ensure your changes are merged into the `main` branch.

2. Create and push a tag for the component you want to release:
   - For Rust, Python, or Wireshark, use the appropriate prefix (e.g., `rust-v0.18.5`, `python-v0.1.0`, `wireshark-v2025.09.03`).
   - For Zeek, use a pure semver tag (e.g., `v1.2.3`).

   Example:
   ```sh
   git tag v1.2.3
   git push origin v1.2.3
   ```
   (For Zeek)

   Or, for Rust:
   ```sh
   git tag rust-v0.18.5
   git push origin rust-v0.18.5
   ```

3. The corresponding GitHub Actions workflow will run and publish the release assets automatically. For Zeek, the release will appear on [packages.zeek.org](https://packages.zeek.org/).

## JA4+ Details

JA4+ is a set of simple yet powerful network fingerprints for multiple protocols that are both human and machine readable, facilitating improved threat-hunting and security analysis. If you are unfamiliar with network fingerprinting, I encourage you to read my blogs releasing JA3 [here](https://medium.com/salesforce-engineering/tls-fingerprinting-with-ja3-and-ja3s-247362855967), JARM [here](https://medium.com/salesforce-engineering/easily-identify-malicious-servers-on-the-internet-with-jarm-e095edac525a), and this excellent blog by Fastly on the [State of TLS Fingerprinting](https://www.fastly.com/blog/the-state-of-tls-fingerprinting-whats-working-what-isnt-and-whats-next) which outlines the history of the aforementioned along with their problems. JA4+ brings dedicated support, keeping the methods up-to-date as the industry changes.

All JA4+ fingerprints have an a_b_c format, delimiting the different sections that make up the fingerprint. This allows for hunting and detection utilizing just ab or ac or c only. If one wanted to just do analysis on incoming cookies into their app, they would look at JA4H_c only. This new locality-preserving format facilitates deeper and richer analysis while remaining simple, easy to use, and allowing for extensibility.

For example, GreyNoise is an internet listener that identifies internet scanners and is implementing JA4+ into their product. They have an actor who scans the internet with a constantly changing single TLS cipher. This generates a massive amount of completely different JA3 fingerprints but with JA4, only the b part of the JA4 fingerprint changes, parts a and c remain the same. As such, GreyNoise can track the actor by looking at the JA4_ac fingerprint (joining a+c, dropping b).

For a list of JA4+ methods and their descriptions, see [Current methods and implementation details](#current-methods-and-implementation-details).

To understand how to read JA4+ fingerprints, see [Technical Details](./technical_details/README.md).

## Licensing

*JA4: TLS Client Fingerprinting* is [open-source, BSD 3-Clause](./LICENSE-JA4), same as JA3. FoxIO does not have patent claims and is not planning to pursue patent coverage for JA4 TLS Client Fingerprinting. This allows any company or tool currently utilizing JA3 to immediately upgrade to JA4 without delay.

**JA4S, JA4L, JA4LS, JA4H, JA4X, JA4SSH, JA4T, JA4TS, JA4TScan and all future additions, (collectively referred to as JA4+)** are licensed under the [FoxIO License 1.1](./LICENSE). This license is permissive for most use cases, including for academic and internal business purposes, but is not permissive for monetization. If, for example, a company would like to use JA4+ internally to help secure their own company, that is permitted. If, for example, a vendor would like to sell JA4+ fingerprinting as part of their product offering, they would need to request an OEM license from us.

All JA4+ methods are patent pending.  
JA4+ is a trademark of FoxIO

JA4+ can and is being implemented into open source tools, see the [License FAQ](./License%20FAQ.md) for details.

This licensing allows us to provide JA4+ to the world in a way that is open and immediately usable, but also provides us with a way to fund continued support, research into new methods, and the development of the JA4+ Database. We want everyone to have the ability to utilize JA4+ and are happy to work with vendors and open source projects to help make that happen.

## Q&amp;A

Q: Why are you sorting the ciphers? Doesn’t the ordering matter?  
A: It does but in our research we’ve found that applications and libraries choose a unique cipher list more than unique ordering. This also reduces the effectiveness of “cipher stunting,” a tactic of randomizing cipher ordering to prevent JA3 detection.

Q: Why are you sorting the extensions?  
A: Earlier in 2023, Google [updated Chromium](https://chromestatus.com/feature/5124606246518784) browsers to randomize their extension ordering. Much like cipher stunting, this was a tactic to prevent JA3 detection and “make the TLS ecosystem more robust to changes.” Google was worried server implementers would assume the Chrome fingerprint would never change and end up building logic around it, which would cause issues whenever Google went to update Chrome.

So I want to make this clear: JA4 fingerprints will change as application TLS libraries are updated, about once a year. Do not assume fingerprints will remain constant in an environment where applications are updated. In any case, sorting the extensions gets around this and adding in Signature Algorithms preserves uniqueness.

Q: Doesn&#039;t TLS 1.3 make fingerprinting TLS clients harder?  
A: No, it makes it easier! Since TLS 1.3, clients have had a much larger set of extensions and even though TLS1.3 only supports a few ciphers, browsers and applications still support many more.

## JA4+ was created by

[John Althouse](https://www.linkedin.com/in/johnalthouse/), with feedback from:

Josh Atkins  
Jeff Atkinson  
Joshua Alexander  
W.  
Joe Martin  
Ben Higgins  
Andrew Morris  
Chris Ueland  
Ben Schofield  
Matthias Vallentin  
Valeriy Vorotyntsev  
Timothy Noel  
Gary Lipsky

Michael Barbine

And engineers working at GreyNoise, Hunt, Google, ExtraHop, F5, Driftnet and others.

Contact John Althouse at john@foxio.io for licensing and questions.

&lt;sub&gt;&lt;sup&gt;Copyright (c) 2025, FoxIO&lt;/sup&gt;&lt;/sub&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[pythops/impala]]></title>
            <link>https://github.com/pythops/impala</link>
            <guid>https://github.com/pythops/impala</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[🛜 TUI for managing wifi on Linux]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pythops/impala">pythops/impala</a></h1>
            <p>🛜 TUI for managing wifi on Linux</p>
            <p>Language: Rust</p>
            <p>Stars: 1,313</p>
            <p>Forks: 25</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[web-infra-dev/rspack]]></title>
            <link>https://github.com/web-infra-dev/rspack</link>
            <guid>https://github.com/web-infra-dev/rspack</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[The fast Rust-based web bundler with webpack-compatible API 🦀️]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/web-infra-dev/rspack">web-infra-dev/rspack</a></h1>
            <p>The fast Rust-based web bundler with webpack-compatible API 🦀️</p>
            <p>Language: Rust</p>
            <p>Stars: 11,985</p>
            <p>Forks: 778</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
  &lt;img alt=&quot;Rspack Banner&quot; src=&quot;https://assets.rspack.rs/rspack/rspack-banner.png&quot;&gt;
&lt;/picture&gt;

# Rspack

&lt;p&gt;
  &lt;a href=&quot;https://discord.gg/79ZZ66GH9E&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/chat-discord-blue?style=flat-square&amp;logo=discord&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;discord channel&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@rspack/core?activeTab=readme&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@rspack/core?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://crates.io/crates/rspack_core&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/v/rspack_core?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;crates version&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://npmcharts.com/compare/@rspack/core?minimal=true&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dm/@rspack/core.svg?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;downloads&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://nodejs.org/en/about/previous-releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/node/v/@rspack/core.svg?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;node version&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/web-infra-dev/rspack/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue.svg?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;license&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://codspeed.io/web-infra-dev/rspack&quot;&gt;&lt;img src=&quot;https://img.shields.io/endpoint?url=https%3A%2F%2Fcodspeed.io%2Fbadge.json&amp;style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;codspeed&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

English | [简体中文](./README.zh-CN.md)

Rspack is a high performance JavaScript bundler written in Rust. It offers strong compatibility with the webpack ecosystem, allowing for seamless replacement of webpack, and provides lightning fast build speeds.

## ✨ Features

- 🚀 **Fast Startup**: Based on Rust, the build speed is extremely fast, bringing you the ultimate development experience.
- ⚡ **Lightning HMR**: With a built-in incremental compilation mechanism, HMR is extremely fast and fully capable of developing large-scale projects.
- 📦 **Webpack Compatible**: Compatible with plugins and loaders in the webpack ecosystem, seamlessly integrating excellent libraries built by the community.
- 🎨 **Module Federation**: Provide first-class support for Module Federation to facilitate the development of large-scale web applications.
- 🛠️ **Production Optimization**: Various optimization strategies are built in by default, such as tree shaking, minification, etc.
- 🎯 **Framework Agnostic**: Not bound to any frontend framework, ensuring enough flexibility.

Read [Introduction](https://rspack.rs/guide/start/introduction) for details.

## 🦀 Rstack

Rstack is a unified JavaScript toolchain centered on Rspack, with high performance and consistent architecture.

| Name                                                  | Description              | Version                                                                                                                                                                          |
| ----------------------------------------------------- | ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [Rspack](https://github.com/web-infra-dev/rspack)     | Bundler                  | &lt;a href=&quot;https://npmjs.com/package/@rspack/core&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@rspack/core?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;     |
| [Rsbuild](https://github.com/web-infra-dev/rsbuild)   | Build tool               | &lt;a href=&quot;https://npmjs.com/package/@rsbuild/core&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@rsbuild/core?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;   |
| [Rslib](https://github.com/web-infra-dev/rslib)       | Library development tool | &lt;a href=&quot;https://npmjs.com/package/@rslib/core&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@rslib/core?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;       |
| [Rspress](https://github.com/web-infra-dev/rspress)   | Static site generator    | &lt;a href=&quot;https://npmjs.com/package/@rspress/core&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@rspress/core?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;   |
| [Rsdoctor](https://github.com/web-infra-dev/rsdoctor) | Build analyzer           | &lt;a href=&quot;https://npmjs.com/package/@rsdoctor/core&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@rsdoctor/core?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt; |
| [Rstest](https://github.com/web-infra-dev/rstest)     | Testing framework        | &lt;a href=&quot;https://npmjs.com/package/@rstest/core&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@rstest/core?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;     |
| [Rslint](https://github.com/web-infra-dev/rslint)     | Linter                   | &lt;a href=&quot;https://npmjs.com/package/@rslint/core&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/v/@rslint/core?style=flat-square&amp;colorA=564341&amp;colorB=EDED91&quot; alt=&quot;npm version&quot; /&gt;&lt;/a&gt;     |

## Getting started

&lt;p&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://stackblitz.com/fork/github/rspack-contrib/rspack-stackblitz-example&quot;&gt;
    &lt;img
      alt=&quot;Open in StackBlitz&quot;
      src=&quot;https://developer.stackblitz.com/img/open_in_stackblitz.svg&quot;
    /&gt;
  &lt;/a&gt;
&lt;/p&gt;

See [Quick start](https://rspack.rs/guide/start/quick-start).

## Contribution

Please read the [contributing guide](./CONTRIBUTING.md) and let&#039;s build Rspack together.

### Code of conduct

This repo has adopted the ByteDance Open Source Code of Conduct. Please check [Code of conduct](./CODE_OF_CONDUCT.md) for more details.

## Community

Come chat with us on [Discord](https://discord.gg/79ZZ66GH9E)! Rspack team and Rspack users are active there, and we&#039;re always looking for contributions.

## Links

| Name                                                                                 | Description                                                                   |
| ------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------- |
| [awesome-rspack](https://github.com/web-infra-dev/awesome-rspack)                    | A curated list of awesome things related to Rspack                            |
| [Rspack 1.x documentation](https://rspack.rs/)                                       | Documentation for Rspack 1.x (latest)                                         |
| [Rspack 0.x documentation](https://v0.rspack.rs/)                                    | Documentation for Rspack 0.x version                                          |
| [rspack-dev-server](https://github.com/web-infra-dev/rspack-dev-server)              | Dev server for Rspack                                                         |
| [rstack-examples](https://github.com/rspack-contrib/rstack-examples)                 | Examples showcasing Rstack                                                    |
| [rspack-sources](https://github.com/web-infra-dev/rspack-sources)                    | Rust port of [webpack-sources](https://www.npmjs.com/package/webpack-sources) |
| [rstack-design-resources](https://github.com/rspack-contrib/rstack-design-resources) | Design resources for Rstack                                                   |

## Contributors

&lt;a href=&quot;https://github.com/web-infra-dev/rspack/graphs/contributors&quot;&gt;&lt;img src=&quot;https://opencollective.com/rspack/contributors.svg?width=890&amp;button=false&quot; /&gt;&lt;/a&gt;

## Benchmark

See [Benchmark](https://ecosystem-benchmark.rspack.rs/).

## Credits

Thanks to:

- [The webpack team and community](https://webpack.js.org/) for creating a great bundler and ecosystem from which we draw a lot of inspiration.
- [@sokra](https://github.com/sokra) for the great work on the [webpack](https://github.com/webpack/webpack) project.
- [@ScriptedAlchemy](https://github.com/ScriptedAlchemy) for creating Module Federation and helping Rspack connect with the community.
- The [SWC](https://github.com/swc-project/swc) project created by [@kdy1](https://github.com/kdy1), which powers Rspack&#039;s code parsing, transformation and minification.
- The [esbuild](https://github.com/evanw/esbuild) project created by [@evanw](https://github.com/evanw), which inspired the concurrent architecture of Rspack.
- The [NAPI-RS](https://github.com/napi-rs/napi-rs) project created by [@Brooooooklyn](https://github.com/Brooooooklyn), which powers Rspack&#039;s node-binding implementation.
- The [Parcel](https://github.com/parcel-bundler/parcel) project created by [@devongovett](https://github.com/devongovett) which is the pioneer of rust bundler and inspired Rspack&#039;s incremental rebuild design.
- The [Vite](https://github.com/vitejs/vite) project created by [Evan You](https://github.com/yyx990803) which inspired Rspack&#039;s compatibility design of webpack&#039;s ecosystem.
- The `rolldown-legacy` project created by old Rolldown team, It&#039;s the predecessor of the [rolldown](https://github.com/rolldown) project, which explores the possibility of making a performant bundler in Rust with Rollup-compatible API. It inspires the design principles of Rspack.
- The [html-webpack-plugin](https://github.com/jantimon/html-webpack-plugin) project created by [@jantimon](https://github.com/jantimon), `@rspack/html-plugin` is a fork of [html-webpack-plugin](https://github.com/jantimon/html-webpack-plugin) to avoid some webpack API usage not supported in Rspack.
- The [Turbopack](https://github.com/vercel/turbo) project which inspired the AST path logic of Rspack.
- The [react-refresh-webpack-plugin](https://github.com/pmmmwh/react-refresh-webpack-plugin) created by [@pmmmwh](https://github.com/pmmmwh), which inspires implement [react refresh rspack plugin](https://github.com/rspack-contrib/rspack-plugin-react-refresh).
- The [prefresh](https://github.com/preactjs/prefresh) created by [@Jovi De Croock](https://github.com/JoviDeCroock), which inspires implement [preact refresh rspack plugin](https://github.com/rspack-contrib/rspack-plugin-preact-refresh).
- The [mini-css-extract-plugin](https://github.com/webpack-contrib/mini-css-extract-plugin) project created by [@sokra](https://github.com/sokra) which inspired implement css extract plugin.
- The [copy-webpack-plugin](https://github.com/webpack-contrib/copy-webpack-plugin) project created by [@kevlened](https://github.com/kevlened) which inspired implement copy rspack plugin.
- The [webpack-subresource-integrity](https://github.com/waysact/webpack-subresource-integrity) project created by [@jscheid](https://github.com/jscheid), which inspires implement subresource integrity rspack plugin.
- The [circular-dependency-plugin](https://github.com/aackerman/circular-dependency-plugin) project created by [@aackerman](https://github.com/aackerman), which inspres implement circular dependency rspack plugin.
- The [tracing-chrome](https://github.com/thoren-d/tracing-chrome) project created by [thoren-d](https://github.com/thoren-d), which inspires the implementation of Rspack tracing.

## License

Rspack is [MIT licensed](https://github.com/web-infra-dev/rspack/blob/main/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ast-grep/ast-grep]]></title>
            <link>https://github.com/ast-grep/ast-grep</link>
            <guid>https://github.com/ast-grep/ast-grep</guid>
            <pubDate>Fri, 12 Sep 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[⚡A CLI tool for code structural search, lint and rewriting. Written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ast-grep/ast-grep">ast-grep/ast-grep</a></h1>
            <p>⚡A CLI tool for code structural search, lint and rewriting. Written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 10,277</p>
            <p>Forks: 267</p>
            <p>Stars today: 56 stars today</p>
            <h2>README</h2><pre>&lt;p align=center&gt;
  &lt;img src=&quot;https://ast-grep.github.io/logo.svg&quot; alt=&quot;ast-grep&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
   &lt;img src=&quot;https://github.com/ast-grep/ast-grep/actions/workflows/coverage.yaml/badge.svg&quot; alt=&quot;coverage badge&quot;/&gt;
   &lt;a href=&quot;https://app.codecov.io/gh/ast-grep/ast-grep&quot;&gt;&lt;img src=&quot;https://codecov.io/gh/ast-grep/ast-grep/branch/main/graph/badge.svg?token=37VX8H2EWV&quot;/&gt;&lt;/a&gt;
   &lt;a href=&quot;https://discord.gg/4YZjf6htSQ&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1107749847722889217?label=Discord&quot;&gt;&lt;/a&gt;
   &lt;a href=&quot;https://repology.org/project/ast-grep/versions&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Repology&quot; src=&quot;https://repology.org/badge/tiny-repos/ast-grep.svg&quot;&gt;&lt;/a&gt;
   &lt;img src=&quot;https://img.shields.io/github/stars/ast-grep/ast-grep?style=social&quot; alt=&quot;Badge&quot;/&gt;
   &lt;img src=&quot;https://img.shields.io/github/forks/ast-grep/ast-grep?style=social&quot; alt=&quot;Badge&quot;/&gt;
   &lt;img alt=&quot;GitHub Sponsors&quot; src=&quot;https://img.shields.io/github/sponsors/HerringtonDarkholme?style=social&quot;&gt;
   &lt;a href=&quot;https://gurubase.io/g/ast-grep&quot;&gt;&lt;img alt=&quot;Gurubase&quot; src=&quot;https://img.shields.io/badge/Gurubase-Ask%20ast--grep%20Guru-006BFF&quot;&gt;&lt;/a&gt;
&lt;/p&gt;


## ast-grep(sg)

ast-grep(sg) is a CLI tool for code structural search, lint, and rewriting.

## Introduction
ast-grep is an [abstract syntax tree](https://dev.to/balapriya/abstract-syntax-tree-ast-explained-in-plain-english-1h38) based tool to search code by pattern code. Think of it as your old-friend [`grep`](https://en.wikipedia.org/wiki/Grep#:~:text=grep%20is%20a%20command%2Dline,which%20has%20the%20same%20effect.), but matching AST nodes instead of text.
You can write patterns as if you are writing ordinary code. It will match all code that has the same syntactical structure.
You can use `$` sign + upper case letters as a [wildcard](https://en.wikipedia.org/wiki/Wildcard_character), e.g. `$MATCH`, to match any single AST node. Think of it as [regular expression dot](https://regexone.com/lesson/wildcards_dot) `.`, except it is not textual.

Try the [online playground](https://ast-grep.github.io/playground.html) for a taste!

## Screenshot
![demo](https://ast-grep.github.io/image/search-replace.png)

See more screenshots on the [website](https://ast-grep.github.io/).

## Installation
You can install it from [npm](https://docs.npmjs.com/downloading-and-installing-node-js-and-npm), [pip](https://pypi.org/), [cargo](https://doc.rust-lang.org/cargo/getting-started/installation.html),  [cargo-binstall](https://github.com/cargo-bins/cargo-binstall), [homebrew](https://brew.sh/), [scoop](https://scoop.sh/) or [MacPorts](https://www.macports.org)!

```bash
npm install --global @ast-grep/cli
pip install ast-grep-cli
brew install ast-grep
```


&lt;details&gt;
&lt;summary&gt;Click for more installation methods&lt;/summary&gt;

```bash
cargo install ast-grep --locked
cargo binstall ast-grep

# install via scoop, thank @brian6932
scoop install main/ast-grep

# install via MacPorts
sudo port install ast-grep

# try ast-grep in nix-shell
nix-shell -p ast-grep
```
&lt;/details&gt;

Or you can build ast-grep from source. You need to install rustup, clone the repository and then
```bash
cargo install --path ./crates/cli --locked
```
[Packages](https://repology.org/project/ast-grep/versions) are available on other platforms too.


## Command line usage example

ast-grep has following form.
```
ast-grep --pattern &#039;var code = $PATTERN&#039; --rewrite &#039;let code = new $PATTERN&#039; --lang ts
```

### Example

* [Rewrite code in null coalescing operator](https://twitter.com/Hchan_mgn/status/1547061516993699841?s=20&amp;t=ldDoj4U2nq-FRKQkU5GWXA)

```bash
ast-grep -p &#039;$A &amp;&amp; $A()&#039; -l ts -r &#039;$A?.()&#039;
```

* [Rewrite](https://twitter.com/Hchan_mgn/status/1561802312846278657) [Zodios](https://github.com/ecyrbe/zodios#migrate-to-v8)
```bash
ast-grep -p &#039;new Zodios($URL,  $CONF as const,)&#039; -l ts -r &#039;new Zodios($URL, $CONF)&#039; -i
```

* [Implement eslint rule using YAML.](https://twitter.com/Hchan_mgn/status/1560108625460355073)


## Sponsor
![Sponsors](https://raw.githubusercontent.com/HerringtonDarkholme/sponsors/main/sponsorkit/sponsors.svg)

If you find ast-grep interesting and useful for your work, please [buy me a coffee](https://github.com/sponsors/HerringtonDarkholme)
so I can spend more time on the project!

## Feature Highlight

ast-grep&#039;s core is an algorithm to search and replace code based on abstract syntax tree produced by tree-sitter.
It can help you to do lightweight static analysis and massive scale code manipulation in an intuitive way.

Key highlights:

* An intuitive pattern to find and replace AST.
ast-grep&#039;s pattern looks like ordinary code you would write every day (you could say the pattern is isomorphic to code).

* jQuery like API for AST traversal and manipulation.

* YAML configuration to write new linting rules or code modification.

* Written in compiled language, with tree-sitter based parsing and utilizing multiple cores.

* Beautiful command line interface :)

ast-grep&#039;s vision is to democratize abstract syntax tree magic and to liberate one from cumbersome AST programming!

* If you are an open-source library author, ast-grep can help your library users adopt breaking changes more easily.
* if you are a tech lead in your team, ast-grep can help you enforce code best practice tailored to your business need.
* If you are a security researcher, ast-grep can help you write rules much faster.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>