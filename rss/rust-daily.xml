<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Mon, 29 Sep 2025 00:05:41 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[typst/typst]]></title>
            <link>https://github.com/typst/typst</link>
            <guid>https://github.com/typst/typst</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:41 GMT</pubDate>
            <description><![CDATA[A new markup-based typesetting system that is powerful and easy to learn.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/typst/typst">typst/typst</a></h1>
            <p>A new markup-based typesetting system that is powerful and easy to learn.</p>
            <p>Language: Rust</p>
            <p>Stars: 46,096</p>
            <p>Forks: 1,237</p>
            <p>Stars today: 152 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Typst&quot; src=&quot;https://user-images.githubusercontent.com/17899797/226108480-722b770e-6313-40d7-84f2-26bebb55a281.png&quot;&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://typst.app/docs/&quot;&gt;
    &lt;img alt=&quot;Documentation&quot; src=&quot;https://img.shields.io/website?down_message=offline&amp;label=docs&amp;up_color=007aff&amp;up_message=online&amp;url=https%3A%2F%2Ftypst.app%2Fdocs&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://typst.app/&quot;&gt;
    &lt;img alt=&quot;Typst App&quot; src=&quot;https://img.shields.io/website?down_message=offline&amp;label=typst.app&amp;up_color=239dad&amp;up_message=online&amp;url=https%3A%2F%2Ftypst.app&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/2uDybryKPe&quot;&gt;
    &lt;img alt=&quot;Discord Server&quot; src=&quot;https://img.shields.io/discord/1054443721975922748?color=5865F2&amp;label=discord&amp;labelColor=555&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/typst/typst/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;Apache-2 License&quot; src=&quot;https://img.shields.io/badge/license-Apache%202-brightgreen&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://typst.app/jobs/&quot;&gt;
    &lt;img alt=&quot;Jobs at Typst&quot; src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ftypst.app%2Fassets%2Fdata%2Fshields.json&amp;query=%24.jobs.text&amp;label=jobs&amp;color=%23A561FF&amp;cacheSeconds=1800&quot;
  &gt;&lt;/a&gt;
&lt;/p&gt;

Typst is a new markup-based typesetting system that is designed to be as powerful
as LaTeX while being much easier to learn and use. Typst has:

- Built-in markup for the most common formatting tasks
- Flexible functions for everything else
- A tightly integrated scripting system
- Math typesetting, bibliography management, and more
- Fast compile times thanks to incremental compilation
- Friendly error messages in case something goes wrong

This repository contains the Typst compiler and its CLI, which is everything you
need to compile Typst documents locally. For the best writing experience,
consider signing up to our [collaborative online editor][app] for free.

## Example
A [gentle introduction][tutorial] to Typst is available in our documentation.
However, if you want to see the power of Typst encapsulated in one image, here
it is:
&lt;p align=&quot;center&quot;&gt;
 &lt;img alt=&quot;Example&quot; width=&quot;900&quot; src=&quot;https://user-images.githubusercontent.com/17899797/228031796-ced0e452-fcee-4ae9-92da-b9287764ff25.png&quot;&gt;
&lt;/p&gt;


Let&#039;s dissect what&#039;s going on:

- We use _set rules_ to configure element properties like the size of pages or
  the numbering of headings. By setting the page height to `auto`, it scales to
  fit the content. Set rules accommodate the most common configurations. If you
  need full control, you can also use [show rules][show] to completely redefine
  the appearance of an element.

- We insert a heading with the `= Heading` syntax. One equals sign creates a top
  level heading, two create a subheading and so on. Typst has more lightweight
  markup like this, see the [syntax] reference for a full list.

- [Mathematical equations][math] are enclosed in dollar signs. By adding extra
  spaces around the contents of an equation, we can put it into a separate block.
  Multi-letter identifiers are interpreted as Typst definitions and functions
  unless put into quotes. This way, we don&#039;t need backslashes for things like
  `floor` and `sqrt`. And `phi.alt` applies the `alt` modifier to the `phi` to
  select a particular symbol variant.

- Now, we get to some [scripting]. To input code into a Typst document, we can
  write a hash followed by an expression. We define two variables and a
  recursive function to compute the n-th fibonacci number. Then, we display the
  results in a center-aligned table. The table function takes its cells
  row-by-row. Therefore, we first pass the formulas `$F_1$` to `$F_8$` and then
  the computed fibonacci numbers. We apply the spreading operator (`..`) to both
  because they are arrays and we want to pass the arrays&#039; items as individual
  arguments.

&lt;details&gt;
  &lt;summary&gt;Text version of the code example.&lt;/summary&gt;

  ```typst
  #set page(width: 10cm, height: auto)
  #set heading(numbering: &quot;1.&quot;)

  = Fibonacci sequence
  The Fibonacci sequence is defined through the
  recurrence relation $F_n = F_(n-1) + F_(n-2)$.
  It can also be expressed in _closed form:_

  $ F_n = round(1 / sqrt(5) phi.alt^n), quad
    phi.alt = (1 + sqrt(5)) / 2 $

  #let count = 8
  #let nums = range(1, count + 1)
  #let fib(n) = (
    if n &lt;= 2 { 1 }
    else { fib(n - 1) + fib(n - 2) }
  )

  The first #count numbers of the sequence are:

  #align(center, table(
    columns: count,
    ..nums.map(n =&gt; $F_#n$),
    ..nums.map(n =&gt; str(fib(n))),
  ))
  ```
&lt;/details&gt;

## Installation
Typst&#039;s CLI is available from different sources:

- You can get sources and pre-built binaries for the latest release of Typst
  from the [releases page][releases]. Download the archive for your platform and
  place it in a directory that is in your `PATH`. To stay up to date with future
  releases, you can simply run `typst update`.

- You can install Typst through different package managers. Note that the
  versions in the package managers might lag behind the latest release.
  - Linux:
      - View [Typst on Repology][repology]
      - View [Typst&#039;s Snap][snap]
  - macOS: `brew install typst`
  - Windows: `winget install --id Typst.Typst`

- If you have a [Rust][rust] toolchain installed, you can install
  - the latest released Typst version with
    `cargo install --locked typst-cli`
  - a development version with
    `cargo install --git https://github.com/typst/typst --locked typst-cli`

- Nix users can
  - use the `typst` package with `nix-shell -p typst`
  - build and run a development version with
    `nix run github:typst/typst -- --version`.

- Docker users can run a prebuilt image with
  `docker run ghcr.io/typst/typst:latest --help`.

## Usage
Once you have installed Typst, you can use it like this:
```sh
# Creates `file.pdf` in working directory.
typst compile file.typ

# Creates PDF file at the desired path.
typst compile path/to/source.typ path/to/output.pdf
```

You can also watch source files and automatically recompile on changes. This is
faster than compiling from scratch each time because Typst has incremental
compilation.
```sh
# Watches source files and recompiles on changes.
typst watch file.typ
```

Typst further allows you to add custom font paths for your project and list all
of the fonts it discovered:
```sh
# Adds additional directories to search for fonts.
typst compile --font-path path/to/fonts file.typ

# Lists all of the discovered fonts in the system and the given directory.
typst fonts --font-path path/to/fonts

# Or via environment variable (Linux syntax).
TYPST_FONT_PATHS=path/to/fonts typst fonts
```

For other CLI subcommands and options, see below:
```sh
# Prints available subcommands and options.
typst help

# Prints detailed usage of a subcommand.
typst help watch
```

If you prefer an integrated IDE-like experience with autocompletion and instant 
preview, you can also check out our [free web app][app]. Alternatively, there is 
a community-created language server called 
[Tinymist](https://myriad-dreamin.github.io/tinymist/) which is integrated into 
various editor extensions.

## Community
The main places where the community gathers are our [Forum][forum] and our
[Discord server][discord]. The Forum is a great place to ask questions, help
others, and share cool things you created with Typst. The Discord server is more
suitable for quicker questions, discussions about contributing, or just to chat.
We&#039;d be happy to see you there!

[Typst Universe][universe] is where the community shares templates and packages.
If you want to share your own creations, you can submit them to our
[package repository][packages].

If you had a bad experience in our community, please [reach out to us][contact].

## Contributing
We love to see contributions from the community. If you experience bugs, feel
free to open an issue. If you would like to implement a new feature or bug fix,
please follow the steps outlined in the [contribution guide][contributing].

To build Typst yourself, first ensure that you have the
[latest stable Rust][rust] installed. Then, clone this repository and build the
CLI with the following commands:

```sh
git clone https://github.com/typst/typst
cd typst
cargo build --release
```

The optimized binary will be stored in `target/release/`.

Another good way to contribute is by [sharing packages][packages] with the
community.

## Pronunciation and Spelling
IPA: /taɪpst/. &quot;Ty&quot; like in **Ty**pesetting and &quot;pst&quot; like in Hi**pst**er. When
writing about Typst, capitalize its name as a proper noun, with a capital &quot;T&quot;.

## Design Principles
All of Typst has been designed with three key goals in mind: Power,
simplicity, and performance. We think it&#039;s time for a system that matches the
power of LaTeX, is easy to learn and use, all while being fast enough to realize
instant preview. To achieve these goals, we follow three core design principles:

- **Simplicity through Consistency:**
  If you know how to do one thing in Typst, you should be able to transfer that
  knowledge to other things. If there are multiple ways to do the same thing,
  one of them should be at a different level of abstraction than the other. E.g.
  it&#039;s okay that `= Introduction` and `#heading[Introduction]` do the same thing
  because the former is just syntax sugar for the latter.

- **Power through Composability:**
  There are two ways to make something flexible: Have a knob for everything or
  have a few knobs that you can combine in many ways. Typst is designed with the
  second way in mind. We provide systems that you can compose in ways we&#039;ve
  never even thought of. TeX is also in the second category, but it&#039;s a bit
  low-level and therefore people use LaTeX instead. But there, we don&#039;t really
  have that much composability. Instead, there&#039;s a package for everything
  (`\usepackage{knob}`).

- **Performance through Incrementality:**
  All Typst language features must accommodate for incremental compilation.
  Luckily we have [`comemo`], a system for incremental compilation which does
  most of the hard work in the background.

## Acknowledgements

We&#039;d like to thank everyone who is supporting Typst&#039;s development, be it via
[GitHub sponsors] or elsewhere. In particular, special thanks[^1] go to:

- [Posit](https://posit.co/blog/posit-and-typst/) for financing a full-time
  compiler engineer
- [NLnet](https://nlnet.nl/) for supporting work on Typst via multiple grants
  through the [NGI Zero Core](https://nlnet.nl/core) fund:
  - Work on [HTML export](https://nlnet.nl/project/Typst-HTML/)
  - Work on [PDF accessibility](https://nlnet.nl/project/Typst-Accessibility/)
- [Science &amp; Startups](https://www.science-startups.berlin/) for having financed
  Typst development from January through June 2023 via the Berlin Startup
  Scholarship
- [Zerodha](https://zerodha.tech/blog/1-5-million-pdfs-in-25-minutes/) for their
  generous one-time sponsorship

[^1]: This list only includes contributions for our open-source work that exceed
    or are expected to exceed €10K.

[docs]: https://typst.app/docs/
[app]: https://typst.app/
[discord]: https://discord.gg/2uDybryKPe
[forum]: https://forum.typst.app/
[universe]: https://typst.app/universe/
[tutorial]: https://typst.app/docs/tutorial/
[show]: https://typst.app/docs/reference/styling/#show-rules
[math]: https://typst.app/docs/reference/math/
[syntax]: https://typst.app/docs/reference/syntax/
[scripting]: https://typst.app/docs/reference/scripting/
[rust]: https://rustup.rs/
[releases]: https://github.com/typst/typst/releases/
[repology]: https://repology.org/project/typst/versions
[contact]: https://typst.app/contact
[architecture]: https://github.com/typst/typst/blob/main/docs/dev/architecture.md
[contributing]: https://github.com/typst/typst/blob/main/CONTRIBUTING.md
[packages]: https://github.com/typst/packages/
[`comemo`]: https://github.com/typst/comemo/
[snap]: https://snapcraft.io/typst
[GitHub sponsors]: https://github.com/sponsors/typst/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zama-ai/fhevm]]></title>
            <link>https://github.com/zama-ai/fhevm</link>
            <guid>https://github.com/zama-ai/fhevm</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:40 GMT</pubDate>
            <description><![CDATA[FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zama-ai/fhevm">zama-ai/fhevm</a></h1>
            <p>FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications</p>
            <p>Language: Rust</p>
            <p>Stars: 21,034</p>
            <p>Forks: 905</p>
            <p>Stars today: 144 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/.gitbook/assets/fhevm-header-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/.gitbook/assets/fhevm-header-light.png&quot;&gt;
  &lt;img width=500 alt=&quot;fhevm&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;

&lt;hr/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;fhevm-whitepaper.pdf&quot;&gt; 📃 Read white paper&lt;/a&gt; |&lt;a href=&quot;https://docs.zama.ai/protocol&quot;&gt; 📒 Documentation&lt;/a&gt; | &lt;a href=&quot;https://zama.ai/community&quot;&gt; 💛 Community support&lt;/a&gt; | &lt;a href=&quot;https://github.com/zama-ai/awesome-zama&quot;&gt; 📚 FHE resources by Zama&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/zama-ai/fhevm/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/zama-ai/fhevm?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/zama-ai/fhevm/blob/main/LICENSE&quot;&gt;
    &lt;!-- markdown-link-check-disable-next-line --&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-BSD--3--Clause--Clear-%23ffb243?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/zama-ai/bounty-program&quot;&gt;
    &lt;!-- markdown-link-check-disable-next-line --&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Contribute-Zama%20Bounty%20Program-%23ffd208?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://slsa.dev&quot;&gt;&lt;img alt=&quot;SLSA 3&quot; src=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;


## About

### What is FHEVM?

**FHEVM** is the core framework of the *Zama Confidential Blockchain Protocol*. It enables confidential smart contracts on EVM-compatible blockchains by leveraging Fully Homomorphic Encryption (FHE), allowing encrypted data to be processed directly onchain.

FHEVM ensures both confidentiality and composability, with the following guarantees:
- **End-to-end encryption of transactions and state:** Data included in transactions is encrypted and never visible to anyone.
- **Composability and data availability on-chain:** States are updated while remaining encrypted at all times.
- **No impact on existing dApps and state:** Encrypted state co-exists alongside public one, and doesn&#039;t impact existing dApps.
&lt;br&gt;&lt;/br&gt;

### Table of contents

- [About](#about)
  - [What is FHEVM?](#what-is-fhevm)
  - [Project structure](#project-structure)
  - [Main features](#main-features)
  - [Use cases](#use-cases)
- [Resources](#resources)
- [Working with FHEVM](#working-with-fhevm)
  - [Citations](#citations)
  - [Contributing](#contributing)
  - [License](#license)
  - [FAQ](#faq)
- [Support](#support)
  &lt;br&gt;&lt;/br&gt;
### Project structure
The directories of this repository are organized in the following way:

###### FHEVM Contracts

- **`gateway-contracts/`**: Smart contracts managing the gateway between on-chain and off-chain components.

- **`host-contracts/`**: Smart Contracts deployed on the host chain for orchestrating FHE workflows.

###### FHEVM Compute Engines

- **`coprocessor/`**: Rust-based coprocessor implementation for FHE operations.

- **`kms-connector/`**: Interface for integrating with Key Management Services (KMS) to handle encryption keys securely.

###### FHEVM Utilities
- **`charts/`**: Helm charts and deployment configurations for the stack.

- **`golden-container-images/`**: Docker golden images for Node.js and Rust environments used as base images by the stack.

- **`test-suite/`**: Integration with docker-compose and tests covering end-to-end FHEVM stack behavior.



  &lt;br&gt;&lt;/br&gt;
### Main features

- **Privacy by design:** Building decentralized apps with full privacy and confidentiality on Ethereum, leveraging FHE.
- **Solidity integration:** Write FHEVM contracts like any standard Solidity contract using Solidity. Compatible with existing toolchains — such as Hardhat and Foundry (*coming soon*).
- **Programmable privacy:**  Define exactly what data is encrypted and write the access control logic directly in your smart contracts.
- **High precision encrypted integers :** Up to 256 bits of precision for integers.
- **Full range of operators:** All typical operators are available: `+`, `-`, `*`, `/`, `&lt;`, `&gt;`, `==`, ternary-if, boolean operations…. Consecutive FHE operations are not limited.
- **Security:** The underlying FHE crypto-scheme of FHEVM is quantum-resistant. Decryption is managed via a key management system (KMS) using multi-party computation (MPC), ensuring security even if some parties are compromised or misbehaving.
- **Symbolic execution of FHE computations:** All FHE operations are executed symbolically on the host chain, significantly reducing execution time. The actual computations on encrypted data are offloaded asynchronously to our coprocessor, allowing for faster, efficient, and scalable processing.

_Learn more about FHEVM features in the [documentation](https://docs.zama.ai/protocol) and in our [whitepaper](https://github.com/zama-ai/fhevm/blob/main/fhevm-whitepaper.pdf)._
&lt;br&gt;&lt;/br&gt;

### Use cases

FHEVM is built for developers to write confidential smart contracts without the need to learn cryptography. Leveraging FHEVM, you can unlock a myriad of new use cases such as DeFi, gaming, and more. For instance:

- **Confidential transfers**: Keep balances and amounts private, without using mixers.
- **Tokenization**: Swap tokens and RWAs on-chain without others seeing the amounts.
- **Blind auctions**: Bid on items without revealing the amount or the winner.
- **On-chain games**: Keep moves, selections, cards, or items hidden until ready to reveal.
- **Confidential voting**: Prevents bribery and blackmailing by keeping votes private.
- **Encrypted DIDs**: Store identities on-chain and generate attestations without ZK.

_Learn more use cases in the [list of examples](https://docs.zama.ai/protocol/examples)._
&lt;br&gt;&lt;/br&gt;


## Resources
- [Documentation](https://docs.zama.ai/protocol) — Official documentation of FHEVM.
- [Whitepaper](./fhevm-whitepaper.pdf) — Technical overview of FHEVM&#039;s cryptographic design.
- [Examples](https://docs.zama.ai/protocol/examples) — Examples of building confidential smart contracts.
- [Awesome Zama – FHEVM](https://github.com/zama-ai/awesome-zama?tab=readme-ov-file#fhevm) — Curated articles, talks, and ecosystem projects.

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#about&quot; &gt; ↑ Back to top &lt;/a&gt;
&lt;/p&gt;

## Working with FHEVM
### Citations

To cite FHEVM or the whitepaper in academic papers, please use the following entries:

```text
@Misc{FHEVM,
title={{FHEVM: A full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications},
author={Zama},
year={2025},
note={\url{https://github.com/zama-ai/fhevm}},
}
```

### Contributing

There are two ways to contribute to FHEVM:

- [Open issues](https://github.com/zama-ai/fhevm/issues/new/choose) to report bugs and typos, or to suggest new ideas
- Request to become an official contributor by emailing hello@zama.ai.

Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do!
&lt;br&gt;&lt;/br&gt;

### License

This software is distributed under the **BSD-3-Clause-Clear** license. Read [this](LICENSE) for more details.

### FAQ

**Is Zama’s technology free to use?**

&gt; Zama’s libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama&#039;s open source code, companies must purchase Zama’s commercial patent license.
&gt;
&gt; Everything we do is open source, and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in [this blog post](https://www.zama.ai/post/open-source).

**What do I need to do if I want to use Zama’s technology for commercial purposes?**

&gt; To commercially use Zama’s technology you need to be granted Zama’s patent license. Please contact us at hello@zama.ai for more information.

**Do you file IP on your technology?**

&gt; Yes, all Zama’s technologies are patented.

**Can you customize a solution for my specific use case?**

&gt; We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at hello@zama.ai.

## Support

&lt;a target=&quot;_blank&quot; href=&quot;https://community.zama.ai&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/.gitbook/assets/support-banner-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/.gitbook/assets/support-banner-light.png&quot;&gt;
  &lt;img alt=&quot;Support&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;

🌟 If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development.

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#about&quot; &gt; ↑ Back to top &lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BloopAI/vibe-kanban]]></title>
            <link>https://github.com/BloopAI/vibe-kanban</link>
            <guid>https://github.com/BloopAI/vibe-kanban</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:39 GMT</pubDate>
            <description><![CDATA[Kanban board to manage your AI coding agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BloopAI/vibe-kanban">BloopAI/vibe-kanban</a></h1>
            <p>Kanban board to manage your AI coding agents</p>
            <p>Language: Rust</p>
            <p>Stars: 5,213</p>
            <p>Forks: 502</p>
            <p>Stars today: 77 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vibekanban.com&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;frontend/public/vibe-kanban-logo-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;frontend/public/vibe-kanban-logo.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;frontend/public/vibe-kanban-logo.svg&quot; alt=&quot;Vibe Kanban Logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Get 10X more out of Claude Code, Gemini CLI, Codex, Amp and other coding agents...&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/vibe-kanban&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/vibe-kanban?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/BloopAI/vibe-kanban/blob/main/.github/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/BloopAI/vibe-kanban/.github%2Fworkflows%2Fpublish.yml&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/BloopAI/vibe-kanban&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

![](frontend/public/vibe-kanban-screenshot-overview.png)

## Overview

AI coding agents are increasingly writing the world&#039;s code and human engineers now spend the majority of their time planning, reviewing, and orchestrating tasks. Vibe Kanban streamlines this process, enabling you to:

- Easily switch between different coding agents
- Orchestrate the execution of multiple coding agents in parallel or in sequence
- Quickly review work and start dev servers
- Track the status of tasks that your coding agents are working on
- Centralise configuration of coding agent MCP configs

You can watch a video overview [here](https://youtu.be/TFT3KnZOOAk).

## Installation

Make sure you have authenticated with your favourite coding agent. A full list of supported coding agents can be found in the [docs](https://vibekanban.com/docs). Then in your terminal run:

```bash
npx vibe-kanban
```

## Documentation

Please head to the [website](https://vibekanban.com/docs) for the latest documentation and user guides.

## Support

Please open an issue on this repo if you find any bugs or have any feature requests.

## Contributing

We would prefer that ideas and changes are raised with the core team via GitHub issues, where we can discuss implementation details and alignment with the existing roadmap. Please do not open PRs without first discussing your proposal with the team.

## Development

### Prerequisites

- [Rust](https://rustup.rs/) (latest stable)
- [Node.js](https://nodejs.org/) (&gt;=18)
- [pnpm](https://pnpm.io/) (&gt;=8)

Additional development tools:
```bash
cargo install cargo-watch
cargo install sqlx-cli
```

Install dependencies:
```bash
pnpm i
```

### Running the dev server

```bash
pnpm run dev
```

This will start the backend. A blank DB will be copied from the `dev_assets_seed` folder.

### Building the frontend

To build just the frontend:

```bash
cd frontend
pnpm build
```

### Build from source

1. Run `build-npm-package.sh`
2. In the `npx-cli` folder run `npm pack`
3. You can run your build with `npx [GENERATED FILE].tgz`


### Environment Variables

The following environment variables can be configured at build time or runtime:

| Variable | Type | Default | Description |
|----------|------|---------|-------------|
| `GITHUB_CLIENT_ID` | Build-time | `Ov23li9bxz3kKfPOIsGm` | GitHub OAuth app client ID for authentication |
| `POSTHOG_API_KEY` | Build-time | Empty | PostHog analytics API key (disables analytics if empty) |
| `POSTHOG_API_ENDPOINT` | Build-time | Empty | PostHog analytics endpoint (disables analytics if empty) |
| `BACKEND_PORT` | Runtime | `0` (auto-assign) | Backend server port |
| `FRONTEND_PORT` | Runtime | `3000` | Frontend development server port |
| `HOST` | Runtime | `127.0.0.1` | Backend server host |
| `DISABLE_WORKTREE_ORPHAN_CLEANUP` | Runtime | Not set | Disable git worktree cleanup (for debugging) |

**Build-time variables** must be set when running `pnpm run build`. **Runtime variables** are read when the application starts.

#### Custom GitHub OAuth App (Optional)

By default, Vibe Kanban uses Bloop AI&#039;s GitHub OAuth app for authentication. To use your own GitHub app for self-hosting or custom branding:

1. Create a GitHub OAuth App at [GitHub Developer Settings](https://github.com/settings/developers)
2. Enable &quot;Device Flow&quot; in the app settings
3. Set scopes to include `user:email,repo`
4. Build with your client ID:
   ```bash
   GITHUB_CLIENT_ID=your_client_id_here pnpm run build
   ```
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cloudflare/pingora]]></title>
            <link>https://github.com/cloudflare/pingora</link>
            <guid>https://github.com/cloudflare/pingora</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:38 GMT</pubDate>
            <description><![CDATA[A library for building fast, reliable and evolvable network services.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudflare/pingora">cloudflare/pingora</a></h1>
            <p>A library for building fast, reliable and evolvable network services.</p>
            <p>Language: Rust</p>
            <p>Stars: 25,152</p>
            <p>Forks: 1,472</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># Pingora

![Pingora banner image](./docs/assets/pingora_banner.png)

## What is Pingora
Pingora is a Rust framework to [build fast, reliable and programmable networked systems](https://blog.cloudflare.com/pingora-open-source).

Pingora is battle tested as it has been serving more than 40 million Internet requests per second for [more than a few years](https://blog.cloudflare.com/how-we-built-pingora-the-proxy-that-connects-cloudflare-to-the-internet).

## Feature highlights
* Async Rust: fast and reliable
* HTTP 1/2 end to end proxy
* TLS over OpenSSL, BoringSSL or rustls(experimental).
* gRPC and websocket proxying
* Graceful reload
* Customizable load balancing and failover strategies
* Support for a variety of observability tools

## Reasons to use Pingora
* **Security** is your top priority: Pingora is a more memory safe alternative for services that are written in C/C++
* Your service is **performance-sensitive**: Pingora is fast and efficient
* Your service requires extensive **customization**: The APIs Pingora proxy framework provides are highly programmable

# Getting started

See our [quick starting guide](./docs/quick_start.md) to see how easy it is to build a load balancer.

Our [user guide](./docs/user_guide/index.md) covers more topics such as how to configure and run Pingora servers, as well as how to build custom HTTP servers and proxy logic on top of Pingora&#039;s framework.

API docs are also available for all the crates.

# Notable crates in this workspace
* Pingora: the &quot;public facing&quot; crate to build networked systems and proxies
* Pingora-core: this crate defines the protocols, functionalities and basic traits
* Pingora-proxy: the logic and APIs to build HTTP proxies
* Pingora-error: the common error type used across Pingora crates
* Pingora-http: the HTTP header definitions and APIs
* Pingora-openssl &amp; pingora-boringssl: SSL related extensions and APIs
* Pingora-ketama: the [Ketama](https://github.com/RJ/ketama) consistent algorithm
* Pingora-limits: efficient counting algorithms
* Pingora-load-balancing: load balancing algorithm extensions for pingora-proxy
* Pingora-memory-cache: Async in-memory caching with cache lock to prevent cache stampede
* Pingora-timeout: A more efficient async timer system
* TinyUfo: The caching algorithm behind pingora-memory-cache

Note that Pingora proxy integration with caching should be considered experimental, and as such APIs related to caching are currently highly volatile.

# System requirements

## Systems
Linux is our tier 1 environment and main focus.

We will try our best for most code to compile for Unix environments. This is for developers and users to have an easier time developing with Pingora in Unix-like environments like macOS (though some features might be missing)

Windows support is preliminary by community&#039;s best effort only.

Both x86_64 and aarch64 architectures will be supported.

## Rust version

Pingora keeps a rolling MSRV (minimum supported Rust version) policy of 6 months. This means we will accept PRs that upgrade the MSRV as long as the new Rust version used is at least 6 months old.

Our current MSRV is effectively 1.82.

Previously Pingora advertised an MSRV of 1.72. Older Rust versions may still be able to compile via `cargo update` pinning dependencies such as `backtrace@0.3.74`. The advertised MSRV in config files will be officially bumped to 1.82 in an upcoming release.

Building with the optional feature `boringssl` with Boring &gt;= 4.14 requires Rust 1.80.

## Build Requirements

Some of the crates in this repository have dependencies on additional tools and
libraries that must be satisfied in order to build them:

* Make sure that [Clang] is installed on your system (for boringssl)
* Make sure that [Perl 5] is installed on your system (for openssl)

[Clang]:https://clang.llvm.org/
[Perl 5]:https://www.perl.org/

# Contributing
Please see our [contribution guidelines](./.github/CONTRIBUTING.md).

# License
This project is Licensed under [Apache License, Version 2.0](./LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[topjohnwu/Magisk]]></title>
            <link>https://github.com/topjohnwu/Magisk</link>
            <guid>https://github.com/topjohnwu/Magisk</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:37 GMT</pubDate>
            <description><![CDATA[The Magic Mask for Android]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/topjohnwu/Magisk">topjohnwu/Magisk</a></h1>
            <p>The Magic Mask for Android</p>
            <p>Language: Rust</p>
            <p>Stars: 56,066</p>
            <p>Forks: 15,411</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[davidlattimore/wild]]></title>
            <link>https://github.com/davidlattimore/wild</link>
            <guid>https://github.com/davidlattimore/wild</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[A very fast linker for Linux]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/davidlattimore/wild">davidlattimore/wild</a></h1>
            <p>A very fast linker for Linux</p>
            <p>Language: Rust</p>
            <p>Stars: 2,706</p>
            <p>Forks: 67</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre># Wild linker

Wild is a linker with the goal of being very fast for iterative development.

The plan is to eventually make it incremental, however that isn&#039;t yet implemented. It is however
already pretty fast even without incremental linking.

## Installation

### From GitHub releases

Download a tarball from the [releases page](https://github.com/davidlattimore/wild/releases). Unpack
it and copy the `wild` binary somewhere on your path.

### Cargo binstall

If you have [cargo-binstall](https://github.com/cargo-bins/cargo-binstall), you can install wild as
follows:

```sh
cargo binstall wild-linker
```

### Build latest release from crates.io

```sh
cargo install --locked wild-linker
```

### Build from git head

To build and install the latest, unreleased code:

```sh
cargo install --locked --bin wild --git https://github.com/davidlattimore/wild.git wild-linker
```

### Nix

See [nix/nix.md](nix/nix.md)

## Using as your default linker

If you&#039;d like to use Wild as your default linker for building Rust code, you can put the following
in `~/.cargo/config.toml`.

```toml
[target.x86_64-unknown-linux-gnu]
linker = &quot;clang&quot;
rustflags = [&quot;-C&quot;, &quot;link-arg=--ld-path=wild&quot;]
```

## Using wild in CI

If you&#039;d like to use Wild as your linker for Rust code in CI, see
[wild-action](https://github.com/davidlattimore/wild-action).

## Q&amp;A

### Why another linker?

Mold is already very fast, however it doesn&#039;t do incremental linking and the author has stated that
they don&#039;t intend to. Wild doesn&#039;t do incremental linking yet, but that is the end-goal. By writing
Wild in Rust, it&#039;s hoped that the complexity of incremental linking will be achievable.

### What&#039;s working?

The following platforms / architectures are currently supported:

* x86-64 on Linux
* ARM64 on Linux
* RISC-V (riscv64gc) on Linux (initial support: [#678](https://github.com/davidlattimore/wild/issues/678))

The following is working with the caveat that there may be bugs:

* Output to statically linked, non-relocatable binaries
* Output to statically linked, position-independent binaries (static-PIE)
* Output to dynamically linked binaries
* Output to shared objects (.so files)
* Rust proc-macros, when linked with Wild work
* Most of the top downloaded crates on crates.io have been tested with Wild and pass their tests
* Debug info
* GNU jobserver support
* Very basic linker script support (section mapping, keeping sections, alignment, defining start /
  stop symbols).

### What isn&#039;t yet supported?

Lots of stuff. Here are some of the larger things that aren&#039;t yet done, roughly sorted by current
priority:

* Incremental linking
* Support for more architectures
* Support for a wider range of linker flags
* More complex linker scripts
* Mac support
* Windows support
* LTO

### How can I verify that Wild was used to link a binary?

Install `readelf`, then run:

```sh
readelf  -p .comment my-executable
```

Look for a line like:

```
Linker: Wild version 0.1.0
```

Or if you don&#039;t want to install readelf, you can probably get away with:

```sh
strings my-executable | grep &#039;Linker:&#039;
```

### Where did the name come from?

It&#039;s somewhat of a tradition for linkers to end with the letters &quot;ld&quot;. e.g. &quot;GNU ld, &quot;gold&quot;, &quot;lld&quot;,
&quot;mold&quot;. Since the end-goal is for the linker to be incremental, an &quot;I&quot; is added. Let&#039;s say the &quot;W&quot;
stands for &quot;Wild&quot;, since recursive acronyms are popular in open-source projects.

## Benchmarks

The goal of Wild is to eventually be very fast via incremental linking. However, we also want to be
as fast as we can be for non-incremental linking and for the initial link when incremental linking
is enabled.

See [BENCHMARKING.md](BENCHMARKING.md) for more details on running benchmarks.

All benchmarks are run with output to a tmpfs.

### Linking clang on x86-64

This benchmark was run on David Lattimore&#039;s laptop (2020 model System76 Lemur pro), which has 4
cores (8 threads) and 42 GB of RAM.

Wild currently doesn&#039;t perform great beyond 8 threads. This is something we&#039;ve been investigating
and hope to improve soon.

First, without debug info:

```
❯ OUT=/home/david/ttt throttle-count hyperfine --warmup 1 -N -n lld-18 &#039;./run-with ld.lld --strip-debug&#039; -n mold-2.36-no-fork &#039;./run-with mold --no-fork --strip-debug&#039; -n wild-0.4.0-no-fork &#039;./run-with wild --no-fork --strip-debug&#039; -n mold-2.36 &#039;./run-with mold --strip-debug&#039; -n wild-0.4.0 &#039;./run-with wild --strip-debug&#039;
temp: +40.0°C
Benchmark 1: lld-18
  Time (mean ± σ):     514.1 ms ±   5.1 ms    [User: 1000.1 ms, System: 451.9 ms]
  Range (min … max):   507.1 ms … 523.4 ms    10 runs
 
Benchmark 2: mold-2.36-no-fork
  Time (mean ± σ):     388.5 ms ±   5.3 ms    [User: 1986.9 ms, System: 436.2 ms]
  Range (min … max):   379.0 ms … 396.8 ms    10 runs
 
Benchmark 3: wild-0.4.0-no-fork
  Time (mean ± σ):     244.4 ms ±   3.2 ms    [User: 1087.5 ms, System: 313.0 ms]
  Range (min … max):   240.3 ms … 251.7 ms    12 runs
 
Benchmark 4: mold-2.36
  Time (mean ± σ):     365.7 ms ±   8.5 ms    [User: 9.4 ms, System: 3.1 ms]
  Range (min … max):   358.1 ms … 384.9 ms    10 runs
 
Benchmark 5: wild-0.4.0
  Time (mean ± σ):     220.5 ms ±   3.4 ms    [User: 2.6 ms, System: 2.0 ms]
  Range (min … max):   214.1 ms … 226.1 ms    13 runs
 
Summary
  &#039;wild-0.4.0&#039; ran
    1.11 ± 0.02 times faster than &#039;wild-0.4.0-no-fork&#039;
    1.66 ± 0.05 times faster than &#039;mold-2.36&#039;
    1.76 ± 0.04 times faster than &#039;mold-2.36-no-fork&#039;
    2.33 ± 0.04 times faster than &#039;lld-18&#039;
Throttle pkg: 0 core: 0 ms: 0 temp: +59.0°C
```

Note, the user and system CPU times for mold and wild when run with default flags are meaningless,
since these linkers fork by default and hyperfine doesn&#039;t see the CPU usage of the forked
subprocess. For accurate CPU usage, see the no-fork variants. For later benchmarks, we always
include `--no-fork` for these linkers. This makes each of these linkers slower by about 10%.

GNU ld is excluded from the benchmarks because its speed is so totally different to the other
linkers that it makes it hard to compare. But for reference, here is the time for GNU ld for this
benchmark:

```
Benchmark 1: GNU-ld-2.38
  Time (mean ± σ):      8.414 s ±  0.323 s    [User: 7.291 s, System: 1.121 s]
  Range (min … max):    7.601 s …  8.668 s    10 runs
```

Now with debug info:

```
❯ OUT=/home/david/ttt throttle-count hyperfine --warmup 1 -N -n lld-18 &#039;./run-with ld.lld&#039; -n mold-2.36 &#039;./run-with mold --no-fork&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork&#039;
temp: +42.0°C
Benchmark 1: lld-18
  Time (mean ± σ):     11.350 s ±  0.209 s    [User: 70.592 s, System: 6.677 s]
  Range (min … max):   11.085 s … 11.621 s    10 runs
 
Benchmark 2: mold-2.36
  Time (mean ± σ):     11.826 s ±  0.607 s    [User: 73.569 s, System: 5.435 s]
  Range (min … max):   11.130 s … 12.721 s    10 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ± σ):      8.800 s ±  0.197 s    [User: 49.397 s, System: 8.273 s]
  Range (min … max):    8.588 s …  9.136 s    10 runs
 
Summary
  &#039;wild-0.4.0&#039; ran
    1.29 ± 0.04 times faster than &#039;lld-18&#039;
    1.34 ± 0.08 times faster than &#039;mold-2.36&#039;
Throttle pkg: 18454 core: 5916 ms: 328 temp: +77.0°C
```

Note, despite setting my fans to maximum before the start of the benchmark, I did get some thermal
throttling in this run. However, the standard deviations look pretty tight, so I don&#039;t think it
really invalidated the results.

The big takeaway from this benchmark is that debug info can make your link times really slow, so if
you don&#039;t need it, turn it off. If you do need it, try to use split debug info or unpacked debug
info. The situation with debug info is especially bad for C++ codebases like clang, probably due to
header files causing lots of the same information to be repeated.

### Linking rustc-driver.so on x86-64

Without debug info:

```
❯ OUT=/home/david/ttt throttle-count hyperfine --warmup 1 -N -n lld-18 &#039;./run-with ld.lld --strip-debug&#039; -n mold-2.36 &#039;./run-with mold --no-fork --strip-debug&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork --strip-debug&#039;
temp: +47.0°C
Benchmark 1: lld-18
  Time (mean ± σ):      1.485 s ±  0.009 s    [User: 2.247 s, System: 0.771 s]
  Range (min … max):    1.471 s …  1.499 s    10 runs
 
Benchmark 2: mold-2.36
  Time (mean ± σ):     819.9 ms ±   6.6 ms    [User: 3815.0 ms, System: 715.4 ms]
  Range (min … max):   810.3 ms … 829.3 ms    10 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ± σ):     476.6 ms ±  46.6 ms    [User: 2080.9 ms, System: 514.6 ms]
  Range (min … max):   436.7 ms … 553.7 ms    10 runs
 
Summary
  &#039;wild-0.4.0&#039; ran
    1.72 ± 0.17 times faster than &#039;mold-2.36&#039;
    3.12 ± 0.31 times faster than &#039;lld-18&#039;
Throttle pkg: 0 core: 0 ms: 0 temp: +62.0°C
```

With debug info:

```
❯ OUT=/home/david/ttt throttle-count hyperfine --warmup 1 -N -n lld-18 &#039;./run-with ld.lld&#039; -n mold-2.36 &#039;./run-with mold --no-fork&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork&#039;
temp: +47.0°C
Benchmark 1: lld-18
  Time (mean ± σ):      1.663 s ±  0.022 s    [User: 3.244 s, System: 1.024 s]
  Range (min … max):    1.633 s …  1.710 s    10 runs
 
Benchmark 2: mold-2.36
  Time (mean ± σ):      1.120 s ±  0.016 s    [User: 5.126 s, System: 1.005 s]
  Range (min … max):    1.101 s …  1.149 s    10 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ± σ):     646.3 ms ±  10.0 ms    [User: 3016.3 ms, System: 807.9 ms]
  Range (min … max):   626.0 ms … 657.5 ms    10 runs
 
Summary
  &#039;wild-0.4.0&#039; ran
    1.73 ± 0.04 times faster than &#039;mold-2.36&#039;
    2.57 ± 0.05 times faster than &#039;lld-18&#039;
Throttle pkg: 0 core: 0 ms: 0 temp: +62.0°C
```

### Linking clang on aarch64 (Raspberry Pi 5)

```
OUT=/run/user/1000/ttt hyperfine --warmup 2 -n lld-19 &#039;./run-with ld.lld-19 --strip-debug&#039; -n mold-2.36 &#039;./run-with mold --no-fork --strip-debug&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork --strip-debug&#039;
Benchmark 1: lld-19
  Time (mean ± σ):      1.170 s ±  0.005 s    [User: 2.046 s, System: 0.233 s]
  Range (min … max):    1.165 s …  1.177 s    10 runs
 
Benchmark 2: mold-2.36
  Time (mean ± σ):     919.3 ms ±   2.7 ms    [User: 3120.7 ms, System: 304.4 ms]
  Range (min … max):   915.5 ms … 923.7 ms    10 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ± σ):     423.1 ms ±   5.5 ms    [User: 1352.9 ms, System: 147.1 ms]
  Range (min … max):   419.1 ms … 438.0 ms    10 runs
 
Summary
  wild-0.4.0 ran
    2.17 ± 0.03 times faster than mold-2.36
    2.76 ± 0.04 times faster than lld-19
```

### Linking wild on aarch64 (Raspberry Pi 5)

Without debug info:

```
OUT=/run/user/1000/ttt hyperfine -N --warmup 2 -n lld-19 &#039;./run-with ld.lld-19 --strip-debug&#039; -n mold-2.36 &#039;./run-with mold --no-fork --strip-debug&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork --strip-debug&#039;
Benchmark 1: lld-19
  Time (mean ± σ):     225.7 ms ±   2.6 ms    [User: 321.5 ms, System: 52.5 ms]
  Range (min … max):   222.8 ms … 232.7 ms    13 runs
 
Benchmark 2: mold-2.36
  Time (mean ± σ):     152.2 ms ±   0.7 ms    [User: 496.0 ms, System: 46.8 ms]
  Range (min … max):   150.5 ms … 153.5 ms    19 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ± σ):      78.3 ms ±   0.8 ms    [User: 227.9 ms, System: 30.6 ms]
  Range (min … max):    76.9 ms …  80.3 ms    38 runs
 
Summary
  wild-0.4.0 ran
    1.94 ± 0.02 times faster than mold-2.36
    2.88 ± 0.04 times faster than lld-19
```

With debug info:

```
OUT=/run/user/1000/ttt hyperfine --warmup 2 -n lld-19 &#039;./run-with ld.lld-19&#039; -n mold-2.36 &#039;./run-with mold --no-fork&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork&#039;
Benchmark 1: lld-19
  Time (mean ± σ):     325.0 ms ±   4.5 ms    [User: 664.0 ms, System: 66.3 ms]
  Range (min … max):   319.2 ms … 333.7 ms    10 runs
 
Benchmark 2: mold-2.36
  Time (mean ± σ):     262.3 ms ±   2.7 ms    [User: 890.9 ms, System: 75.3 ms]
  Range (min … max):   259.1 ms … 269.6 ms    11 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ± σ):     183.2 ms ±   3.1 ms    [User: 588.5 ms, System: 64.5 ms]
  Range (min … max):   179.8 ms … 192.3 ms    16 runs
 
Summary
  wild-0.4.0 ran
    1.43 ± 0.03 times faster than mold-2.36
    1.77 ± 0.04 times faster than lld-19
```

## Linking Rust code

The following is a `cargo test` command-line that can be used to build and test a crate using Wild.
This has been run successfully on a few popular crates (e.g. ripgrep, serde, tokio, rand, bitflags).
It assumes that the &quot;wild&quot; binary is on your path. It also depends on the Clang compiler being
installed, since GCC doesn&#039;t allow using an arbitrary linker.

```sh
RUSTFLAGS=&quot;-Clinker=clang -Clink-args=--ld-path=wild&quot; cargo test
```

## Contributing

For more information on contributing to `wild` see [CONTRIBUTING.md](CONTRIBUTING.md).

For a high-level overview of Wild&#039;s design, see [DESIGN.md](DESIGN.md).

## Chat server

We have a Zulip server for Wild-related chat. You can join
[here](https://wild.zulipchat.com/join/bbopdeg6howwjpaiyowngyde/).

## Further reading

Many of the posts on [David&#039;s blog](https://davidlattimore.github.io/) are about various aspects of
the Wild linker.

## Sponsorship

If you&#039;d like to [sponsor this work](https://github.com/sponsors/davidlattimore), that would be very
much appreciated. The more sponsorship I get the longer I can continue to work on this project full
time.

## License

Licensed under either of [Apache License, Version 2.0](LICENSE-APACHE) or [MIT license](LICENSE-MIT)
at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in
Wild by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any
additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[YaLTeR/niri]]></title>
            <link>https://github.com/YaLTeR/niri</link>
            <guid>https://github.com/YaLTeR/niri</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[A scrollable-tiling Wayland compositor.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/YaLTeR/niri">YaLTeR/niri</a></h1>
            <p>A scrollable-tiling Wayland compositor.</p>
            <p>Language: Rust</p>
            <p>Stars: 11,773</p>
            <p>Forks: 432</p>
            <p>Stars today: 40 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;&lt;img alt=&quot;niri&quot; src=&quot;https://github.com/user-attachments/assets/07d05cd0-d5dc-4a28-9a35-51bae8f119a0&quot;&gt;&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;A scrollable-tiling Wayland compositor.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://matrix.to/#/#niri:matrix.org&quot;&gt;&lt;img alt=&quot;Matrix&quot; src=&quot;https://img.shields.io/badge/matrix-%23niri-blue?logo=matrix&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;GitHub License&quot; src=&quot;https://img.shields.io/github/license/YaLTeR/niri&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/releases&quot;&gt;&lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/YaLTeR/niri?logo=github&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://yalter.github.io/niri/Getting-Started.html&quot;&gt;Getting Started&lt;/a&gt; | &lt;a href=&quot;https://yalter.github.io/niri/Configuration%3A-Introduction.html&quot;&gt;Configuration&lt;/a&gt; | &lt;a href=&quot;https://github.com/YaLTeR/niri/discussions/325&quot;&gt;Setup&amp;nbsp;Showcase&lt;/a&gt;
&lt;/p&gt;

![niri with a few windows open](https://github.com/user-attachments/assets/535e6530-2f44-4b84-a883-1240a3eee6e9)

## About

Windows are arranged in columns on an infinite strip going to the right.
Opening a new window never causes existing windows to resize.

Every monitor has its own separate window strip.
Windows can never &quot;overflow&quot; onto an adjacent monitor.

Workspaces are dynamic and arranged vertically.
Every monitor has an independent set of workspaces, and there&#039;s always one empty workspace present all the way down.

The workspace arrangement is preserved across disconnecting and connecting monitors where it makes sense.
When a monitor disconnects, its workspaces will move to another monitor, but upon reconnection they will move back to the original monitor.

## Features

- Built from the ground up for scrollable tiling
- [Dynamic workspaces](https://yalter.github.io/niri/Workspaces.html) like in GNOME
- An [Overview](https://github.com/user-attachments/assets/379a5d1f-acdb-4c11-b36c-e85fd91f0995) that zooms out workspaces and windows
- Built-in screenshot UI
- Monitor and window screencasting through xdg-desktop-portal-gnome
    - You can [block out](https://yalter.github.io/niri/Configuration%3A-Window-Rules.html#block-out-from) sensitive windows from screencasts
    - [Dynamic cast target](https://yalter.github.io/niri/Screencasting.html#dynamic-screencast-target) that can change what it shows on the go
- [Touchpad](https://github.com/YaLTeR/niri/assets/1794388/946a910e-9bec-4cd1-a923-4a9421707515) and [mouse](https://github.com/YaLTeR/niri/assets/1794388/8464e65d-4bf2-44fa-8c8e-5883355bd000) gestures
- Group windows into [tabs](https://yalter.github.io/niri/Tabs.html)
- Configurable layout: gaps, borders, struts, window sizes
- [Gradient borders](https://yalter.github.io/niri/Configuration%3A-Layout.html#gradients) with Oklab and Oklch support
- [Animations](https://github.com/YaLTeR/niri/assets/1794388/ce178da2-af9e-4c51-876f-8709c241d95e) with support for [custom shaders](https://github.com/YaLTeR/niri/assets/1794388/27a238d6-0a22-4692-b794-30dc7a626fad)
- Live-reloading config
- Works with [screen readers](https://yalter.github.io/niri/Accessibility.html)

## Video Demo

https://github.com/YaLTeR/niri/assets/1794388/bce834b0-f205-434e-a027-b373495f9729

Also check out this video from Brodie Robertson that showcases a lot of the niri functionality: [Niri Is My New Favorite Wayland Compositor](https://youtu.be/DeYx2exm04M)

## Status

Niri is stable for day-to-day use and does most things expected of a Wayland compositor.
Many people are daily-driving niri, and are happy to help in our [Matrix channel].

Give it a try!
Follow the instructions on the [Getting Started](https://yalter.github.io/niri/Getting-Started.html) page.
Have your [waybar]s and [fuzzel]s ready: niri is not a complete desktop environment.
Also check out [awesome-niri], a list of niri-related links and projects.

Here are some points you may have questions about:

- **Multi-monitor**: yes, a core part of the design from the very start. Mixed DPI works.
- **Fractional scaling**: yes, plus all niri UI stays pixel-perfect.
- **NVIDIA**: seems to work fine.
- **Floating windows**: yes, starting from niri 25.01.
- **Input devices**: niri supports tablets, touchpads, and touchscreens.
You can map the tablet to a specific monitor, or use [OpenTabletDriver].
We have touchpad gestures, but no touchscreen gestures yet.
- **Wlr protocols**: yes, we have most of the important ones like layer-shell, gamma-control, screencopy.
You can check on [wayland.app](https://wayland.app) at the bottom of each protocol&#039;s page.
- **Performance**: while I run niri on beefy machines, I try to stay conscious of performance.
I&#039;ve seen someone use it fine on an Eee PC 900 from 2008, of all things.
- **Xwayland**: [integrated](https://yalter.github.io/niri/Xwayland.html#using-xwayland-satellite) via xwayland-satellite starting from niri 25.08.

## Media

[niri: Making a Wayland compositor in Rust](https://youtu.be/Kmz8ODolnDg?list=PLRdS-n5seLRqrmWDQY4KDqtRMfIwU0U3T) · *December 2024*

My talk from the 2024 Moscow RustCon about niri, and how I do randomized property testing and profiling, and measure input latency.
The talk is in Russian, but I prepared full English subtitles that you can find in YouTube&#039;s subtitle language selector.

[An interview with Ivan, the developer behind Niri](https://www.trommelspeicher.de/podcast/special_the_developer_behind_niri) · *June 2025*

An interview by a German tech podcast Das Triumvirat (in English).
We talk about niri development and history, and my experience building and maintaining niri.

[A tour of the niri scrolling-tiling Wayland compositor](https://lwn.net/Articles/1025866/) · *July 2025*

An LWN article with a nice overview and introduction to niri.

## Contributing

If you&#039;d like to help with niri, there are plenty of both coding- and non-coding-related ways to do so.
See [CONTRIBUTING.md](https://github.com/YaLTeR/niri/blob/main/CONTRIBUTING.md) for an overview.

## Inspiration

Niri is heavily inspired by [PaperWM] which implements scrollable tiling on top of GNOME Shell.

One of the reasons that prompted me to try writing my own compositor is being able to properly separate the monitors.
Being a GNOME Shell extension, PaperWM has to work against Shell&#039;s global window coordinate space to prevent windows from overflowing.

## Tile Scrollably Elsewhere

Here are some other projects which implement a similar workflow:

- [PaperWM]: scrollable tiling on top of GNOME Shell.
- [karousel]: scrollable tiling on top of KDE.
- [scroll](https://github.com/dawsers/scroll) and [papersway]: scrollable tiling on top of sway/i3.
- [hyprscrolling] and [hyprslidr]: scrollable tiling on top of Hyprland.
- [PaperWM.spoon]: scrollable tiling on top of macOS.

## Contact

Our main communication channel is a Matrix chat, feel free to join and ask a question: https://matrix.to/#/#niri:matrix.org

We also have a community Discord server: https://discord.gg/vT8Sfjy7sx

[PaperWM]: https://github.com/paperwm/PaperWM
[waybar]: https://github.com/Alexays/Waybar
[fuzzel]: https://codeberg.org/dnkl/fuzzel
[awesome-niri]: https://github.com/Vortriz/awesome-niri
[karousel]: https://github.com/peterfajdiga/karousel
[papersway]: https://spwhitton.name/tech/code/papersway/
[hyprscrolling]: https://github.com/hyprwm/hyprland-plugins/tree/main/hyprscrolling
[hyprslidr]: https://gitlab.com/magus/hyprslidr
[PaperWM.spoon]: https://github.com/mogenson/PaperWM.spoon
[Matrix channel]: https://matrix.to/#/#niri:matrix.org
[OpenTabletDriver]: https://opentabletdriver.net/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cloudflare/workers-rs]]></title>
            <link>https://github.com/cloudflare/workers-rs</link>
            <guid>https://github.com/cloudflare/workers-rs</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[Write Cloudflare Workers in 100% Rust via WebAssembly]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudflare/workers-rs">cloudflare/workers-rs</a></h1>
            <p>Write Cloudflare Workers in 100% Rust via WebAssembly</p>
            <p>Language: Rust</p>
            <p>Stars: 3,089</p>
            <p>Forks: 346</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>![workers-rs](.github/logo.png)
[![crates.io](https://img.shields.io/crates/v/worker)](https://crates.io/crates/worker)
[![docs.rs](https://img.shields.io/docsrs/worker)](https://docs.rs/worker)

**Work-in-progress** ergonomic Rust bindings to Cloudflare Workers environment. Write your entire worker in Rust!

Read the [Notes and FAQ](#notes-and-faq)

## Example Usage

```rust
use worker::*;

#[event(fetch)]
pub async fn main(mut req: Request, env: Env, _ctx: worker::Context) -&gt; Result&lt;Response&gt; {
    console_log!(
        &quot;{} {}, located at: {:?}, within: {}&quot;,
        req.method().to_string(),
        req.path(),
        req.cf().unwrap().coordinates().unwrap_or_default(),
        req.cf().unwrap().region().unwrap_or(&quot;unknown region&quot;.into())
    );

    if !matches!(req.method(), Method::Post) {
        return Response::error(&quot;Method Not Allowed&quot;, 405);
    }

    if let Some(file) = req.form_data().await?.get(&quot;file&quot;) {
        return match file {
            FormEntry::File(buf) =&gt; {
                Response::ok(&amp;format!(&quot;size = {}&quot;, buf.bytes().await?.len()))
            }
            _ =&gt; Response::error(&quot;`file` part of POST form must be a file&quot;, 400),
        };
    }

    Response::error(&quot;Bad Request&quot;, 400)
}
```

## Getting Started

The project uses [wrangler](https://github.com/cloudflare/workers-sdk/tree/main/packages/wrangler) for running and publishing your Worker.

Use [cargo generate](https://github.com/cargo-generate/cargo-generate) to start from a template:

```bash
cargo generate cloudflare/workers-rs
```

There are several templates to chose from. You should see a new project layout with a `src/lib.rs`. 
Start there! Use any local or remote crates and modules (as long as they compile to the `wasm32-unknown-unknown` target).

Once you&#039;re ready to run your project, run your worker locally:

```bash
npx wrangler dev
```

Finally, go live:

```bash
# configure your routes, zones &amp; more in your worker&#039;s `wrangler.toml` file
npx wrangler deploy
```

If you would like to have `wrangler` installed on your machine, see instructions in [wrangler repository](https://github.com/cloudflare/workers-sdk/tree/main/packages/wrangler).

## `http` Feature

`worker` `0.0.21` introduced an `http` feature flag which starts to replace custom types with widely used types from the [`http`](https://docs.rs/http/latest/http/) crate.

This makes it much easier to use crates which use these standard types such as `axum` and `hyper`. 

This currently does a few things:

1. Introduce `Body`, which implements `http_body::Body` and is a simple wrapper around `web_sys::ReadableStream`. 
1. The `req` argument when using the `[event(fetch)]` macro becomes `http::Request&lt;worker::Body&gt;`.
1. The expected return type for the fetch handler is `http::Response&lt;B&gt;` where `B` can be any `http_body::Body&lt;Data=Bytes&gt;`.
1. The argument for `Fetcher::fetch_request` is `http::Request&lt;worker::Body&gt;`. 
1. The return type of `Fetcher::fetch_request` is `Result&lt;http::Response&lt;worker::Body&gt;&gt;`.

The end result is being able to use frameworks like `axum` directly (see [example](./examples/axum)): 

```rust
pub async fn root() -&gt; &amp;&#039;static str {
    &quot;Hello Axum!&quot;
}

fn router() -&gt; Router {
    Router::new().route(&quot;/&quot;, get(root))
}

#[event(fetch)]
async fn fetch(
    req: HttpRequest,
    _env: Env,
    _ctx: Context,
) -&gt; Result&lt;http::Response&lt;axum::body::Body&gt;&gt; {
    Ok(router().call(req).await?)
}
```

We also implement `try_from` between `worker::Request` and `http::Request&lt;worker::Body&gt;`, and between `worker::Response` and `http::Response&lt;worker::Body&gt;`. This allows you to convert your code incrementally if it is tightly coupled to the original types.

### Or use the `Router`:

Parameterize routes and access the parameter values from within a handler. Each handler function takes a
`Request`, and a `RouteContext`. The `RouteContext` has shared data, route params, `Env` bindings, and more.

```rust
use serde::{Deserialize, Serialize};
use worker::*;

#[event(fetch)]
pub async fn main(req: Request, env: Env, _ctx: worker::Context) -&gt; Result&lt;Response&gt; {

    // Create an instance of the Router, which can use parameters (/user/:name) or wildcard values
    // (/file/*pathname). Alternatively, use `Router::with_data(D)` and pass in arbitrary data for
    // routes to access and share using the `ctx.data()` method.
    let router = Router::new();

    // useful for JSON APIs
    #[derive(Deserialize, Serialize)]
    struct Account {
        id: u64,
        // ...
    }
    router
        .get_async(&quot;/account/:id&quot;, |_req, ctx| async move {
            if let Some(id) = ctx.param(&quot;id&quot;) {
                let accounts = ctx.kv(&quot;ACCOUNTS&quot;)?;
                return match accounts.get(id).json::&lt;Account&gt;().await? {
                    Some(account) =&gt; Response::from_json(&amp;account),
                    None =&gt; Response::error(&quot;Not found&quot;, 404),
                };
            }

            Response::error(&quot;Bad Request&quot;, 400)
        })
        // handle files and fields from multipart/form-data requests
        .post_async(&quot;/upload&quot;, |mut req, _ctx| async move {
            let form = req.form_data().await?;
            if let Some(entry) = form.get(&quot;file&quot;) {
                match entry {
                    FormEntry::File(file) =&gt; {
                        let bytes = file.bytes().await?;
                    }
                    FormEntry::Field(_) =&gt; return Response::error(&quot;Bad Request&quot;, 400),
                }
                // ...

                if let Some(permissions) = form.get(&quot;permissions&quot;) {
                    // permissions == &quot;a,b,c,d&quot;
                }
                // or call `form.get_all(&quot;permissions&quot;)` if using multiple entries per field
            }

            Response::error(&quot;Bad Request&quot;, 400)
        })
        // read/write binary data
        .post_async(&quot;/echo-bytes&quot;, |mut req, _ctx| async move {
            let data = req.bytes().await?;
            if data.len() &lt; 1024 {
                return Response::error(&quot;Bad Request&quot;, 400);
            }

            Response::from_bytes(data)
        })
        .run(req, env).await
}
```

## Durable Object, KV, Secret, &amp; Variable Bindings

All &quot;bindings&quot; to your script (Durable Object &amp; KV Namespaces, Secrets, Variables and Version) are
accessible from the `env` parameter provided to both the entrypoint (`main` in this example), and to
the route handler callback (in the `ctx` argument), if you use the `Router` from the `worker` crate.

```rust
use worker::*;

#[event(fetch, respond_with_errors)]
pub async fn main(req: Request, env: Env, _ctx: worker::Context) -&gt; Result&lt;Response&gt; {
    utils::set_panic_hook();

    let router = Router::new();

    router
        .on_async(&quot;/durable&quot;, |_req, ctx| async move {
            let namespace = ctx.durable_object(&quot;CHATROOM&quot;)?;
            let stub = namespace.id_from_name(&quot;A&quot;)?.get_stub()?;
            // `fetch_with_str` requires a valid Url to make request to DO. But we can make one up!
            stub.fetch_with_str(&quot;http://fake_url.com/messages&quot;).await
        })
        .get(&quot;/secret&quot;, |_req, ctx| {
            Response::ok(ctx.secret(&quot;CF_API_TOKEN&quot;)?.to_string())
        })
        .get(&quot;/var&quot;, |_req, ctx| {
            Response::ok(ctx.var(&quot;BUILD_NUMBER&quot;)?.to_string())
        })
        .post_async(&quot;/kv&quot;, |_req, ctx| async move {
            let kv = ctx.kv(&quot;SOME_NAMESPACE&quot;)?;

            kv.put(&quot;key&quot;, &quot;value&quot;)?.execute().await?;

            Response::empty()
        })
        .run(req, env).await
}
```

For more information about how to configure these bindings, see:

- https://developers.cloudflare.com/workers/cli-wrangler/configuration#keys
- https://developers.cloudflare.com/workers/learning/using-durable-objects#configuring-durable-object-bindings
- https://developers.cloudflare.com/workers/runtime-apis/bindings/version-metadata/

## Durable Objects

### Define a Durable Object in Rust

To define a Durable Object using the `worker` crate you need to implement the `DurableObject` trait
on your own struct. Additionally, the `#[durable_object]` attribute macro must be applied to the struct definition.

```rust
use worker::{durable_object, State, Env, Result, Request, Response};

#[durable_object]
pub struct Chatroom {
    users: Vec&lt;User&gt;,
    messages: Vec&lt;Message&gt;,
    state: State,
    env: Env, // access `Env` across requests, use inside `fetch`
}

impl DurableObject for Chatroom {
    fn new(state: State, env: Env) -&gt; Self {
        Self {
            users: vec![],
            messages: vec![],
            state: state,
            env,
        }
    }

    async fn fetch(&amp;self, _req: Request) -&gt; Result&lt;Response&gt; {
        // do some work when a worker makes a request to this DO
        Response::ok(&amp;format!(&quot;{} active users.&quot;, self.users.len()))
    }
}
```

You&#039;ll need to &quot;migrate&quot; your worker script when it&#039;s published so that it is aware of this new
Durable Object, and include a binding in your `wrangler.toml`.

- Include the Durable Object binding type in you `wrangler.toml` file:

```toml
# ...

[durable_objects]
bindings = [
  { name = &quot;CHATROOM&quot;, class_name = &quot;Chatroom&quot; } # the `class_name` uses the Rust struct identifier name
]

[[migrations]]
tag = &quot;v1&quot; # Should be unique for each entry
new_classes = [&quot;Chatroom&quot;] # Array of new classes
```

### SQLite Storage in Durable Objects

Durable Objects can use SQLite for persistent storage, providing a relational database interface. To enable SQLite storage, you need to use `new_sqlite_classes` in your migration and access the SQL storage through `state.storage().sql()`.

```rust
use worker::{durable_object, State, Env, Result, Request, Response, SqlStorage};

#[durable_object]
pub struct SqlCounter {
    sql: SqlStorage,
}

impl DurableObject for SqlCounter {
    fn new(state: State, _env: Env) -&gt; Self {
        let sql = state.storage().sql();
        // Create table if it does not exist
        sql.exec(&quot;CREATE TABLE IF NOT EXISTS counter(value INTEGER);&quot;, None)
            .expect(&quot;create table&quot;);
        Self { sql }
    }

    async fn fetch(&amp;self, _req: Request) -&gt; Result&lt;Response&gt; {
        #[derive(serde::Deserialize)]
        struct Row {
            value: i32,
        }

        // Read current value
        let rows: Vec&lt;Row&gt; = self
            .sql
            .exec(&quot;SELECT value FROM counter LIMIT 1;&quot;, None)?
            .to_array()?;
        let current = rows.get(0).map(|r| r.value).unwrap_or(0);
        let next = current + 1;

        // Update counter
        self.sql.exec(&quot;DELETE FROM counter;&quot;, None)?;
        self.sql
            .exec(&quot;INSERT INTO counter(value) VALUES (?);&quot;, vec![next.into()])?;

        Response::ok(format!(&quot;SQL counter is now {}&quot;, next))
    }
}
```

Configure your `wrangler.toml` to enable SQLite storage:

```toml
# ...

[durable_objects]
bindings = [
  { name = &quot;SQL_COUNTER&quot;, class_name = &quot;SqlCounter&quot; }
]

[[migrations]]
tag = &quot;v1&quot; # Should be unique for each entry
new_sqlite_classes = [&quot;SqlCounter&quot;] # Use new_sqlite_classes for SQLite-enabled objects
```

- For more information about migrating your Durable Object as it changes, see the docs here:
  https://developers.cloudflare.com/workers/learning/using-durable-objects#durable-object-migrations-in-wranglertoml

## Queues

### Enabling queues
As queues are in beta you need to enable the `queue` feature flag.

Enable it by adding it to the worker dependency in your `Cargo.toml`:
```toml
worker = {version = &quot;...&quot;, features = [&quot;queue&quot;]}
```

### Example worker consuming and producing messages:
```rust
use worker::*;
use serde::{Deserialize, Serialize};
#[derive(Serialize, Debug, Clone, Deserialize)]
pub struct MyType {
    foo: String,
    bar: u32,
}

// Consume messages from a queue
#[event(queue)]
pub async fn main(message_batch: MessageBatch&lt;MyType&gt;, env: Env, _ctx: Context) -&gt; Result&lt;()&gt; {
    // Get a queue with the binding &#039;my_queue&#039;
    let my_queue = env.queue(&quot;my_queue&quot;)?;

    // Deserialize the message batch
    let messages = message_batch.messages()?;

    // Loop through the messages
    for message in messages {
        // Log the message and meta data
        console_log!(
            &quot;Got message {:?}, with id {} and timestamp: {}&quot;,
            message.body(),
            message.id(),
            message.timestamp().to_string()
        );

        // Send the message body to the other queue
        my_queue.send(message.body()).await?;

        // Ack individual message
        message.ack();

        // Retry individual message
        message.retry();
    }

    // Retry all messages
    message_batch.retry_all();
    // Ack all messages
    message_batch.ack_all();
    Ok(())
}
```
You&#039;ll need to ensure you have the correct bindings in your `wrangler.toml`:
```toml
# ...
[[queues.consumers]]
queue = &quot;myqueueotherqueue&quot;
max_batch_size = 10
max_batch_timeout = 30


[[queues.producers]]
queue = &quot;myqueue&quot;
binding = &quot;my_queue&quot;
```

## RPC Support

`workers-rs` has experimental support for [Workers RPC](https://developers.cloudflare.com/workers/runtime-apis/rpc/).
For now, this relies on JavaScript bindings and may require some manual usage of `wasm-bindgen`. 

Not all features of RPC are supported yet (or have not been tested), including:
- Function arguments and return values
- Class instances
- Stub forwarding

### RPC Server

Writing an RPC server with `workers-rs` is relatively simple. Simply export methods using `wasm-bindgen`. These
will be automatically detected by `worker-build` and made available to other Workers. See
[example](./examples/rpc-server).

### RPC Client

Creating types and bindings for invoking another Worker&#039;s RPC methods is a bit more involved. You will need to
write more complex `wasm-bindgen` bindings and some boilerplate to make interacting with the RPC methods more
idiomatic. See [example](./examples/rpc-client/src/calculator.rs).

With manually written bindings, it should be possible to support non-primitive argument and return types, using
`serde-wasm-bindgen`. 

### Generating Client Bindings

There are many routes that can be taken to describe RPC interfaces. Under the hood, Workers RPC uses
[Cap&#039;N Proto](https://capnproto.org/). A possible future direction is for Wasm guests to include Cap&#039;N Proto
serde support and speak directly to the RPC protocol, bypassing JavaScript. This would likely involve defining 
the RPC interface in Cap&#039;N Proto schema and generating Rust code from that.

Another popular interface schema in the WebAssembly community is
[WIT](https://github.com/WebAssembly/component-model/blob/main/design/mvp/WIT.md). This is a lightweight format
designed for the WebAssembly Component model. `workers-rs` includes an **experimental** code generator which 
allows you to describe your RPC interface using WIT and generate JavaScript bindings as shown in the 
[rpc-client example](./examples/rpc-client/wit/calculator.wit). The easiest way to use this code generator is using a [build script](./examples/rpc-client/build.rs) as shown in the example.
This code generator is pre-alpha, with no support guarantee, and implemented only for primitive types at this time. 

## Testing with Miniflare

In order to test your Rust worker locally, the best approach is to use
[Miniflare](https://github.com/cloudflare/miniflare). However, because Miniflare
is a Node package, you will need to write your end-to-end tests in JavaScript or
TypeScript in your project. The official documentation for writing tests using
Miniflare is [available here](https://miniflare.dev). This documentation
being focused on JavaScript / TypeScript codebase, you will need to configure
as follows to make it work with your Rust-based, WASM-generated worker:

### Step 1: Add Wrangler and Miniflare to your `devDependencies`

```sh
npm install --save-dev wrangler miniflare
```

### Step 2: Build your worker before running the tests

Make sure that your worker is built before running your tests by calling the
following in your build chain:

```sh
wrangler deploy --dry-run
```

By default, this should build your worker under the `./build/` directory at the
root of your project.

### Step 3: Configure your Miniflare instance in your JavaScript / TypeScript tests

To instantiate the `Miniflare` testing instance in your tests, make sure to
configure its `scriptPath` option to the relative path of where your JavaScript
worker entrypoint was generated, and its `moduleRules` so that it is able to
resolve the `*.wasm` file imported from that JavaScript worker:

```js
// test.mjs
import assert from &quot;node:assert&quot;;
import { Miniflare } from &quot;miniflare&quot;;

const mf = new Miniflare({
  scriptPath: &quot;./build/worker/shim.mjs&quot;,
  modules: true,
  modulesRules: [
    { type: &quot;CompiledWasm&quot;, include: [&quot;**/*.wasm&quot;], fallthrough: true }
  ]
});

const res = await mf.dispatchFetch(&quot;http://localhost&quot;);
assert(res.ok);
assert.strictEqual(await res.text(), &quot;Hello, World!&quot;);
```

## D1 Databases

### Enabling D1 databases
As D1 databases are in alpha, you&#039;ll need to enable the `d1` feature on the `worker` crate.

```toml
worker = { version = &quot;x.y.z&quot;, features = [&quot;d1&quot;] }
```

### Example usage
```rust
use worker::*;

#[derive(Deserialize)]
struct Thing {
	thing_id: String,
	desc: String,
	num: u32,
}

#[event(fetch, respond_with_errors)]
pub async fn main(request: Request, env: Env, _ctx: Context) -&gt; Result&lt;Response&gt; {
	Router::new()
		.get_async(&quot;/:id&quot;, |_, ctx| async move {
			let id = ctx.param(&quot;id&quot;).unwrap()?;
			let d1 = ctx.env.d1(&quot;things-db&quot;)?;
			let statement = d1.prepare(&quot;SELECT * FROM things WHERE thing_id = ?1&quot;);
			let query = statement.bind(&amp;[id])?;
			let result = query.first::&lt;Thing&gt;(None).await?;
			match result {
				Some(thing) =&gt; Response::from_json(&amp;thing),
				None =&gt; Response::error(&quot;Not found&quot;, 404),
			}
		})
		.run(request, env)
		.await
}
```


# Notes and FAQ

It is exciting to see how much is possible with a framework like this, by expanding the options
developers have when building on top of the Workers platform. However, there is still much to be
done. Expect a few rough edges, some unimplemented APIs, and maybe a bug or two here and there. It’s
worth calling out here that some things that may have worked in your Rust code might not work here -
it’s all WebAssembly at the end of the day, and if your code or third-party libraries don’t target
`wasm32-unknown-unknown`, they can’t be used on Workers. Additionally, you’ve got to leave your
threaded async runtimes at home; meaning no Tokio or async_std support. However, async/await syntax
is still available and supported out of the box when you use the `worker` crate.

We fully intend to support this crate and continue to build out its missing features, but your help
and feedback is a must. We don’t like to build in a vacuum, and we’re in an incredibly fortunate
position to have brilliant customers like you who can help steer us towards an even better product.

So give it a try, leave some feedback, and star the repo to encourage us to dedicate more time and
resources to this kind of project.

If this is interesting to you and you want to help out, we’d be happy to get outside contributors
started. We know there are improvements to be made such as compatibility with popular Rust HTTP
ecosystem types (we have an example conversion for [Headers](https://github.com/cloudflare/workers-rs/blob/3d5876a1aca0a649209152d1ffd52dae7bccda87/libworker/src/headers.rs#L131-L167) if you want to make one), implementing additional Web APIs, utility crates,
and more. In fact, we’re always on the lookout for great engineers, and hiring for many open roles -
please [take a look](https://www.cloudflare.com/careers/).

### FAQ

1. Can I deploy a Worker that uses `tokio` or `async_std` runtimes?

- Currently no. All crates in your Worker project must compile to `wasm32-unknown-unknown` target,
  which is more limited in some ways than targets for x86 and ARM64. However, you should still be able to use runtime-agnostic primitives from those crates such 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[MystenLabs/sui]]></title>
            <link>https://github.com/MystenLabs/sui</link>
            <guid>https://github.com/MystenLabs/sui</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[Sui, a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the Move programming language]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/MystenLabs/sui">MystenLabs/sui</a></h1>
            <p>Sui, a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the Move programming language</p>
            <p>Language: Rust</p>
            <p>Stars: 7,360</p>
            <p>Forks: 11,622</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/MystenLabs/sui/refs/heads/main/docs/site/static/img/logo.svg&quot; alt=&quot;Logo&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;
&lt;/p&gt;

# Welcome to Sui

[![Github release](https://img.shields.io/github/v/release/MystenLabs/sui.svg?sort=semver)](https://github.com/MystenLabs/sui/releases/latest)
[![License](https://img.shields.io/github/license/MystenLabs/sui)](https://github.com/MystenLabs/sui/blob/main/LICENSE)

[Sui](https://sui.io) is a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the [Move programming language](https://github.com/MystenLabs/awesome-move).

## Sui Highlights

Sui offers the following benefits and capabilities:

 * Unmatched scalability, instant settlement
 * A safe smart contract language accessible to mainstream developers
 * Ability to define rich and composable on-chain assets
 * Better user experience for web3 apps

Sui is the only blockchain today that can scale with the growth of web3 while achieving industry-leading performance, cost, programmability, and usability. Sui demonstrates capacity beyond the transaction processing capabilities of established systems – traditional and blockchain alike. Sui is the first internet-scale programmable blockchain platform, a foundational layer for web3.

## Sui Architecture

```mermaid
flowchart LR
    CC(CLI Client) --&gt; ClientService
    RC(Rest Client) --&gt; ClientService
    RPCC(RPC Client) --&gt; ClientService
    ClientService --&gt; AuthorityAggregator
    AuthorityAggregator --&gt; AC1[AuthorityClient] &amp; AC2[AuthorityClient]
    subgraph Authority1
      AS[AuthorityState]
    end
    subgraph Authority2
      AS2[AuthorityState]
    end
    AC1 &lt;==&gt;|Network TCP| Authority1
    AC2 &lt;==&gt;|Network TCP| Authority2
```

## Sui Overview

Sui is a smart contract platform maintained by a permissionless set of authorities that play a role similar to validators or miners in other blockchain systems.

Sui offers scalability and unprecedented low-latency for common use cases. Sui makes the vast majority of transactions processable in parallel, which makes better use of processing resources, and offers the option to increase throughput with more resources. Sui forgoes consensus to instead use simpler and lower-latency primitives for common use cases, such as payment transactions and asset transfers. This is unprecedented in the blockchain world and enables a number of new latency-sensitive distributed applications, ranging from gaming to retail payment at physical points of sale.

Sui is written in [Rust](https://www.rust-lang.org) and supports smart contracts written in the [Move programming language](https://github.com/move-language/move) to define assets that may have an owner. Move programs define operations on these assets including custom rules for their creation, the transfer of these assets to new owners, and operations that mutate assets.

Sui has a native token called SUI, with a fixed supply. The SUI token is used to pay for gas, and is also used as [delegated stake on authorities](https://learn.bybit.com/blockchain/delegated-proof-of-stake-dpos/) within an epoch. The voting power of authorities within this epoch is a function of this delegated stake. Authorities are periodically reconfigured according to the stake delegated to them. In any epoch, the set of authorities is [Byzantine fault tolerant](https://pmg.csail.mit.edu/papers/osdi99.pdf). At the end of the epoch, fees collected through all transactions processed are distributed to authorities according to their contribution to the operation of the system. Authorities can in turn share some of the fees as rewards to users that delegated stakes to them.

Sui is supported by several cutting-edge [peer-reviewed studies](https://github.com/MystenLabs/sui/blob/main/docs/content/concepts/research-papers.mdx) and extensive years of open-source development.

## More About Sui

Use the following links to learn more about Sui and the Sui ecosystem:

 * Learn more about working with Sui in the [Sui Documentation](https://docs.sui.io/).
 * Join the Sui community on [Sui Discord](https://discord.gg/sui).
 * Find out more about the Sui ecosystem on the [Sui Resources](https://sui.io/resources/) page.
 * Review information about Sui governance, [decentralization](https://suifoundation.org/decentralization), and [Developer Grants Program](https://sui.io/grants-hub) on the [Sui Foundation](https://sui.io/about) site.


 ## How to Contribute

 See the [Contributing Guide](CONTRIBUTING.md) for details on how to contribute to Sui.

 ## Code of Conduct

 See the [Code of Conduct](CODE_OF_CONDUCT.MD) for details on our code of conduct.

 ## License

 See the [LICENSE](LICENSE) file for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 19,962</p>
            <p>Forks: 1,767</p>
            <p>Stars today: 44 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/7GaTvbDwga&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;&gt;
     &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

## 🎉 Hacktoberfest 2025 🎉

`goose` is a participating project in Hacktoberfest 2025! We’re so excited for your contributions, and have created a wide variety of issues so that anyone can contribute. Whether you&#039;re a seasoned developer or a first-time open source contributor, there&#039;s something for everyone.

### To get started:
1. Read the [contributing guide](https://github.com/block/goose/blob/main/CONTRIBUTING.md).
2. Read the [code of conduct](https://github.com/block/.github/blob/main/CODE_OF_CONDUCT.md).
3. Read the [full Responsible AI-Assisted Coding Guide](./ai-assisted-coding-guide.md).
4. Choose a task from this project&#039;s Hacktoberfest issues in our [Project Hub](https://github.com/block/goose/issues/4705) and follow the instructions. Each issue has the 🏷️ `hacktoberfest` label.

Have questions? Connecting with us in our [Discord community](https://discord.gg/block-opensource) in the `#hacktoberfest` project channel.

---

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.

[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)

# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)


# a little goose humor 🦢

&gt; Why did the developer choose goose as their AI agent?
&gt; 
&gt; Because it always helps them &quot;migrate&quot; their code to production! 🚀

# goose around with us
- [Discord](https://discord.gg/block-opensource)
- [YouTube](https://www.youtube.com/@goose-oss)
- [LinkedIn](https://www.linkedin.com/company/goose-oss)
- [Twitter/X](https://x.com/goose_oss)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[btjawa/BiliTools]]></title>
            <link>https://github.com/btjawa/BiliTools</link>
            <guid>https://github.com/btjawa/BiliTools</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[A cross-platform bilibili toolbox. 跨平台哔哩哔哩工具箱，支持下载视频、番剧等等各类资源]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/btjawa/BiliTools">btjawa/BiliTools</a></h1>
            <p>A cross-platform bilibili toolbox. 跨平台哔哩哔哩工具箱，支持下载视频、番剧等等各类资源</p>
            <p>Language: Rust</p>
            <p>Stars: 3,721</p>
            <p>Forks: 250</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;.github/logo.svg&quot; width=500 /&gt;

&lt;h1&gt;BiliTools - 哔哩哔哩工具箱&lt;/h1&gt;

&lt;a href=&quot;https://trendshift.io/repositories/13286&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://trendshift.io/api/badge/repositories/13286&quot; alt=&quot;btjawa%2FBiliTools | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
&lt;/a&gt;

&lt;div&gt;
&lt;a href=&quot;https://github.com/btjawa/BiliTools/stargazers&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/btjawa/BiliTools&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/btjawa/BiliTools/forks&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/btjawa/BiliTools&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/btjawa/BiliTools/actions/workflows/release.yml&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/btjawa/BiliTools/release.yml&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/btjawa/BiliTools/releases/latest&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/btjawa/BiliTools&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/btjawa/BiliTools/blob/master/LICENSE&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/btjawa/BiliTools&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

简体中文 | [English](./README_EN.md) | [日本語](./README_JA.md) | [ChangeLog](./CHANGELOG.md) | [Contributing](./CONTRIBUTING.md) | [CODE_OF_CONDUCT](./CODE_OF_CONDUCT.md)
&lt;/div&gt;

&lt;hr /&gt;

💡 一个简约、轻量的哔哩哔哩工具箱，基于 [Tauri](https://github.com/tauri-apps/tauri) 构建。

- 📖 使用文档：[https://bilitools.btjawa.top](https://bilitools.btjawa.top) 

- 🧾 其他信息：[https://btjawa.top/bilitools](https://btjawa.top/bilitools)

- 🚀 下载页：[Releases](https://github.com/btjawa/BiliTools/releases)

安装说明、使用向导与常见问题等，请参见文档

| 暗色 | 亮色 |
| ---- | ---- |
| ![Dark](.github/dark.png) | ![Light](.github/light.png) |

&gt; [!IMPORTANT]
&gt; 本项目基于用户账号解析资源，因此你需要订阅大会员、或是购买对应内容后才能解析对应资源


## 🧪 支持功能

| 资源     | 状态       | 备注 |
| -------- | ---------- | ---- |
| 视频     | ✅ 已完成 | &lt;ul&gt;&lt;li&gt;支持合集 / 分P / 互动、番剧 / 课程 / 电影&lt;/li&gt;&lt;li&gt;支持 DASH、MP4、FLV&lt;/li&gt;&lt;li&gt;支持 4K、8K、HDR、杜比视界&lt;/li&gt;&lt;/ul&gt; |
| 音频     | ✅ 已完成 | &lt;ul&gt;&lt;li&gt;支持 AVC、HEVC、AV1&lt;/li&gt;&lt;li&gt;支持 杜比全景声、Hi-Res&lt;/li&gt;&lt;/ul&gt; |
| 实时弹幕 | ✅ 已完成 | &lt;ul&gt;&lt;li&gt;ASS / XML 格式&lt;/li&gt;&lt;li&gt;可解析弹幕池中几乎所有弹幕&lt;/li&gt;&lt;/ul&gt; |
| 历史弹幕 | ✅ 已完成 | ASS / XML 格式 |
| 音乐     | ✅ 已完成 | 支持无损 FLAC、320Kbps 音乐 / 歌单 |
| 封面     | ✅ 已完成 | 支持番剧 / 电影海报 / 合集封面 / 课程预览等等 |
| 字幕     | ✅ 已完成 | SRT 格式 |
| 用户投稿 | ✅ 已完成 | 支持用户投稿视频 / 图文 / 专栏 / 动态 / 音频 |
| 稍后再看 | ✅ 已完成 | 支持列表与单项 |
| 收藏夹   | ✅ 已完成 | 支持任意用户收藏夹 |
| NFO刮削  | ✅ 已完成 | 合集/剧集刮削、单集刮削 |
| 元数据   | ✅ 已完成 | 支持 `ID3v2` / `Vorbis Comments` |
| AI总结   | ✅ 已完成 | Markdown格式，来自哔哩哔哩 `AI 小助手` |

| 账号相关 | 状态       |
| -------- | ---------- |
| 扫码登录 | ✅ 已完成 |
| 密码登录 | ✅ 已完成 |
| 短信登录 | ✅ 已完成 |
| 刷新登录 | ✅ 已完成 |
| 参数签名 | ✅ 已完成 |
| 风控验证 | ✅ 已完成 |
| 指纹验证 | ✅ 已完成 |

| 其他       | 状态       |
| ---------- | ---------- |
| 明暗主题   | ✅ 已完成 |
| 监听剪切板 | ✅ 已完成 |
| HTTP 代理  | ✅ 已完成 |
| 过滤 PCDN  | ✅ 已完成 |
| 音频转 MP3 | ✅ 已完成 |
| 命名格式   | ✅ 已完成 |
| 历史记录   | ✅ 已完成 |

## 🛠️ 参与贡献

&gt; [!TIP]
&gt; 本项目将于 `v1.4.0` 正式版发布后进入稳定状态，暂缓更新。

欢迎各位为本项目做出贡献，让本项目变得更好！请参考 [Contributing](./CONTRIBUTING.md) 进行贡献~

在提交 Issue 时，请提供足够的信息，以便于维护者分析并解决你的问题

## 🌎 多语言支持

我们主要维护 **简体中文 (zh-CN)**，同时该语言将作为其他语言的翻译源

鉴于精力问题，大部分翻译将首先由人工智能完成，随后人工进行润色

| 代码  | 状态       |
| ------| ---------- |
| zh-CN | ✅ 已完成 |
| zh-HK | ✅ 已完成 |
| en-US | ✅ 已完成 |
| ja-JP | ✅ 已完成 |

## ⚡ 赞助

如果你喜欢，并想助力这个项目，请考虑到 [爱发电](https://afdian.com/a/BTJ_Shiroi) 请我喝杯咖啡~

你的支持将是 [我](https://github.com/btjawa) 持续维护的一大动力！

## 💫 鸣谢

&lt;a href=&quot;https://github.com/btjawa/BiliTools/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=btjawa/BiliTools&amp;max=100&quot; /&gt;
&lt;/a&gt;

&lt;br /&gt;

- [tauri](https://github.com/tauri-apps/tauri) Build smaller, faster, and more secure desktop and mobile applications with a web frontend.

- [aria2](https://github.com/aria2/aria2) aria2 is a lightweight multi-protocol &amp; multi-source, cross platform download utility.
- [FFmpeg](https://git.ffmpeg.org/ffmpeg.git) FFmpeg is a collection of libraries and tools to process multimedia content.
- [DanmakuFactory](https://github.com/hihkm/DanmakuFactory) 支持特殊弹幕的xml转ass格式转换工具
- [bilibili-API-collect](https://github.com/SocialSisterYi/bilibili-API-collect) 哔哩哔哩-API收集整理

- [Vercel](https://github.com/vercel/vercel) Develop. Preview. Ship.

&lt;a href=&quot;https://www.star-history.com/#btjawa/BiliTools&amp;Date&quot; alt=&quot;Star History Chart&quot;&gt;
&lt;picture&gt;
&lt;source
    media=&quot;(prefers-color-scheme: dark)&quot;
    srcset=&quot;https://api.star-history.com/svg?repos=btjawa/BiliTools&amp;type=Date&amp;theme=dark&quot;
/&gt;
&lt;source
    media=&quot;(prefers-color-scheme: light)&quot;
    srcset=&quot;https://api.star-history.com/svg?repos=btjawa/BiliTools&amp;type=Date&quot;
/&gt;
&lt;img
    alt=&quot;Star History Chart&quot;
    src=&quot;https://api.star-history.com/svg?repos=btjawa/BiliTools&amp;type=Date&quot;
/&gt;
&lt;/picture&gt;
&lt;/a&gt;

## 声明

&gt; [!IMPORTANT]
&gt; 本项目遵守 [GPL-3.0-or-later](/LICENSE) 开源协议，免费开源：&lt;br&gt;
&gt; **任何形式的二次分发必须继续开源、遵守相同协议、保留原作者及版权信息**

&lt;hr /&gt;

**本项目旨在学习技术与测试代码，切勿滥用！**

我们**强烈反对且不纵容**任何形式的盗版、非法转载、黑产及其他违法用途或行为。

- 因使用本项目而产生的任何后果（包括但不限于非法用途、账号风控或其他损失），均由用户个人承担，**与[本人](https://github.com/btjawa)无关，概不负责**
- 本项目 **开源免费**，作者未从中获得经济收益
- 本项目不会绕过身份验证机制、破解付费资源或实施其他非法行为
- 本项目产生与获取的所有数据将使用 `SQLite` 格式明文存储于用户本地：

&gt; Windows: `%APPDATA%\com.btjawa.bilitools`&lt;br&gt;
&gt; macOS: `$HOME/Library/Application Support/com.btjawa.bilitools`&lt;br&gt;
&gt; Linux: `$HOME/.local/share/com.btjawa.bilitools`

- “哔哩哔哩” 及 “Bilibili” 名称、LOGO及相关图形是上海幻电信息科技有限公司的注册商标或商标。
- 本项目为独立的第三方工具，与哔哩哔哩及其关联公司无任何关联、合作、授权或背书等关系。
- 使用本项目获取的内容，其版权归原权利人所有，请遵守相关法律法规及平台服务协议。
- 如有侵权，可随时 [联系](mailto:btj2407@gmail.com) 处理。
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[embassy-rs/embassy]]></title>
            <link>https://github.com/embassy-rs/embassy</link>
            <guid>https://github.com/embassy-rs/embassy</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[Modern embedded framework, using Rust and async.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/embassy-rs/embassy">embassy-rs/embassy</a></h1>
            <p>Modern embedded framework, using Rust and async.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,497</p>
            <p>Forks: 1,186</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># Embassy

Embassy is the next-generation framework for embedded applications. Write safe, correct, and energy-efficient embedded code faster, using the Rust programming language, its async facilities, and the Embassy libraries.

## [Documentation](https://embassy.dev/book/index.html) - [API reference](https://docs.embassy.dev/) - [Website](https://embassy.dev/) - [Chat](https://matrix.to/#/#embassy-rs:matrix.org)

## Rust + async ❤️ embedded

The Rust programming language is blazingly fast and memory-efficient, with no runtime, garbage collector, or OS. It catches a wide variety of bugs at compile time, thanks to its full memory- and thread-safety, and expressive type system.

Rust&#039;s [async/await](https://rust-lang.github.io/async-book/) allows for unprecedentedly easy and efficient multitasking in embedded systems. Tasks get transformed at compile time into state machines that get run cooperatively. It requires no dynamic memory allocation and runs on a single stack, so no per-task stack size tuning is required. It obsoletes the need for a traditional RTOS with kernel context switching, and is [faster and smaller than one!](https://tweedegolf.nl/en/blog/65/async-rust-vs-rtos-showdown)

## Batteries included

- **Hardware Abstraction Layers**
    - HALs implement safe, idiomatic Rust APIs to use the hardware capabilities, so raw register manipulation is not needed. The Embassy project maintains HALs for select hardware, but you can still use HALs from other projects with Embassy.
    - [embassy-stm32](https://docs.embassy.dev/embassy-stm32/), for all STM32 microcontroller families.
    - [embassy-nrf](https://docs.embassy.dev/embassy-nrf/), for the Nordic Semiconductor nRF52, nRF53, nRF54 and nRF91 series.
    - [embassy-rp](https://docs.embassy.dev/embassy-rp/), for the Raspberry Pi RP2040 and RP23xx microcontrollers.
    - [embassy-mspm0](https://docs.embassy.dev/embassy-mspm0/), for the Texas Instruments MSPM0 microcontrollers.
    - [esp-rs](https://github.com/esp-rs), for the Espressif Systems ESP32 series of chips.
        - Embassy HAL support for Espressif chips, as well as Async Wi-Fi, Bluetooth, and ESP-NOW, is being developed in the [esp-rs/esp-hal](https://github.com/esp-rs/esp-hal) repository.
    - [ch32-hal](https://github.com/ch32-rs/ch32-hal), for the WCH 32-bit RISC-V(CH32V) series of chips.
    - [mpfs-hal](https://github.com/AlexCharlton/mpfs-hal), for the Microchip PolarFire SoC.
    - [py32-hal](https://github.com/py32-rs/py32-hal), for the Puya Semiconductor PY32 series of microcontrollers.

- **Time that Just Works** -
  No more messing with hardware timers. [embassy_time](https://docs.embassy.dev/embassy-time) provides Instant, Duration, and Timer types that are globally available and never overflow.

- **Real-time ready** -
  Tasks on the same async executor run cooperatively, but you can create multiple executors with different priorities so that higher priority tasks preempt lower priority ones. See the [example](https://github.com/embassy-rs/embassy/blob/master/examples/nrf52840/src/bin/multiprio.rs).

- **Low-power ready** -
  Easily build devices with years of battery life. The async executor automatically puts the core to sleep when there&#039;s no work to do. Tasks are woken by interrupts, there is no busy-loop polling while waiting.

- **Networking** -
  The [embassy-net](https://docs.embassy.dev/embassy-net/) network stack implements extensive networking functionality, including Ethernet, IP, TCP, UDP, ICMP, and DHCP. Async drastically simplifies managing timeouts and serving multiple connections concurrently.

- **Bluetooth**
    - The [trouble](https://github.com/embassy-rs/trouble) crate provides a Bluetooth Low Energy 4.x and 5.x Host that runs on any microcontroller implementing the [bt-hci](https://github.com/embassy-rs/bt-hci) traits (currently
      `nRF52`, `rp2040`, `rp23xx` and `esp32` and `serial` controllers are supported).
    - The [nrf-softdevice](https://github.com/embassy-rs/nrf-softdevice) crate provides Bluetooth Low Energy 4.x and 5.x support for nRF52 microcontrollers.
    - The [embassy-stm32-wpan](https://github.com/embassy-rs/embassy/tree/main/embassy-stm32-wpan) crate provides Bluetooth Low Energy 5.x support for stm32wb microcontrollers.

- **LoRa** -
  The [lora-rs](https://github.com/lora-rs/lora-rs) project provides an async LoRa and LoRaWAN stack that works well on Embassy.

- **USB** -
  [embassy-usb](https://docs.embassy.dev/embassy-usb/) implements a device-side USB stack. Implementations for common classes such as USB serial (CDC ACM) and USB HID are available, and a rich builder API allows building your own.

- **Bootloader and DFU** -
  [embassy-boot](https://github.com/embassy-rs/embassy/tree/master/embassy-boot) is a lightweight bootloader supporting firmware application upgrades in a power-fail-safe way, with trial boots and rollbacks.

## Sneak peek

```rust,ignore
use defmt::info;
use embassy_executor::Spawner;
use embassy_time::{Duration, Timer};
use embassy_nrf::gpio::{AnyPin, Input, Level, Output, OutputDrive, Pin, Pull};
use embassy_nrf::{Peri, Peripherals};

// Declare async tasks
#[embassy_executor::task]
async fn blink(pin: Peri&lt;&#039;static, AnyPin&gt;) {
    let mut led = Output::new(pin, Level::Low, OutputDrive::Standard);

    loop {
        // Timekeeping is globally available, no need to mess with hardware timers.
        led.set_high();
        Timer::after_millis(150).await;
        led.set_low();
        Timer::after_millis(150).await;
    }
}

// Main is itself an async task as well.
#[embassy_executor::main]
async fn main(spawner: Spawner) {
    let p = embassy_nrf::init(Default::default());

    // Spawned tasks run in the background, concurrently.
    spawner.spawn(blink(p.P0_13.into()).unwrap());

    let mut button = Input::new(p.P0_11, Pull::Up);
    loop {
        // Asynchronously wait for GPIO events, allowing other tasks
        // to run, or the core to sleep.
        button.wait_for_low().await;
        info!(&quot;Button pressed!&quot;);
        button.wait_for_high().await;
        info!(&quot;Button released!&quot;);
    }
}
```

## Examples

Examples are found in the
`examples/` folder separated by the chip manufacturer they are designed to run on. For example:

* `examples/nrf52840` run on the
  `nrf52840-dk` board (PCA10056) but should be easily adaptable to other nRF52 chips and boards.
* `examples/nrf5340` run on the `nrf5340-dk` board (PCA10095).
* `examples/stm32xx` for the various STM32 families.
* `examples/rp` are for the RP2040 chip.
* `examples/std` are designed to run locally on your PC.

### Running examples

- Install `probe-rs` following the instructions at &lt;https://probe.rs&gt;.
- Change directory to the sample&#039;s base directory. For example:

```bash
cd examples/nrf52840
```

- Ensure `Cargo.toml` sets the right feature for the name of the chip you are programming.
  If this name is incorrect, the example may fail to run or immediately crash
  after being programmed.

- Ensure `.cargo/config.toml` contains the name of the chip you are programming.

- Run the example

For example:

```bash
cargo run --release --bin blinky
```

For more help getting started, see [Getting Started][1] and [Running the Examples][2].

## Developing Embassy with Rust Analyzer-based editors

The [Rust Analyzer](https://rust-analyzer.github.io/) is used by [Visual Studio Code](https://code.visualstudio.com/)
and others. Given the multiple targets that Embassy serves, there is no Cargo workspace file. Instead, the Rust Analyzer
must be told of the target project to work with. In the case of Visual Studio Code,
please refer to the `.vscode/settings.json` file&#039;s `rust-analyzer.linkedProjects`setting.

## Minimum supported Rust version (MSRV)

Embassy is guaranteed to compile on stable Rust 1.75 and up. It *might*
compile with older versions, but that may change in any new patch release.

## Why the name?

EMBedded ASYnc! :)

## License

Embassy is licensed under either of

- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;http://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;http://opensource.org/licenses/MIT&gt;)

at your option.

## Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.

[1]: https://github.com/embassy-rs/embassy/wiki/Getting-Started
[2]: https://github.com/embassy-rs/embassy/wiki/Running-the-Examples
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[servo/servo]]></title>
            <link>https://github.com/servo/servo</link>
            <guid>https://github.com/servo/servo</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/servo/servo">servo/servo</a></h1>
            <p>Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.</p>
            <p>Language: Rust</p>
            <p>Stars: 31,619</p>
            <p>Forks: 3,258</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre># The Servo Parallel Browser Engine Project

Servo is a prototype web browser engine written in the
[Rust](https://github.com/rust-lang/rust) language. It is currently developed on
64-bit macOS, 64-bit Linux, 64-bit Windows, 64-bit OpenHarmony, and Android.

Servo welcomes contribution from everyone. Check out:

- The [Servo Book](https://book.servo.org) for documentation
- [servo.org](https://servo.org/) for news and guides

Coordination of Servo development happens:
- Here in the Github Issues
- On the [Servo Zulip](https://servo.zulipchat.com/)
- In video calls advertised in the [Servo Project](https://github.com/servo/project/issues) repo.

## Getting started

For more detailed build instructions, see the Servo book under [Setting up your environment], [Building Servo], [Building for Android] and [Building for OpenHarmony].

[Setting up your environment]: https://book.servo.org/hacking/setting-up-your-environment.html
[Building Servo]: https://book.servo.org/hacking/building-servo.html
[Building for Android]: https://book.servo.org/hacking/building-for-android.html
[Building for OpenHarmony]: https://book.servo.org/hacking/building-for-openharmony.html

### macOS

- Download and install [Xcode](https://developer.apple.com/xcode/) and [`brew`](https://brew.sh/).
- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` 
- Install `rustup`: `curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh`
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `./mach bootstrap`
- Build servoshell: `./mach build`

### Linux

- Install `curl`:
  - Arch: `sudo pacman -S --needed curl`
  - Debian, Ubuntu: `sudo apt install curl`
  - Fedora: `sudo dnf install curl`
  - Gentoo: `sudo emerge net-misc/curl`
- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` 
- Install `rustup`: `curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh`
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `./mach bootstrap`
- Build servoshell: `./mach build`

### Windows

- Download [`uv`](https://docs.astral.sh/uv/getting-started/installation/#standalone-installer), [`choco`](https://chocolatey.org/install#individual), and [`rustup`](https://win.rustup.rs/)
  - Be sure to select *Quick install via the Visual Studio Community installer*
- In the Visual Studio Installer, ensure the following components are installed:
  - **Windows 10/11 SDK (anything &gt;= 10.0.19041.0)** (`Microsoft.VisualStudio.Component.Windows{10, 11}SDK.{&gt;=19041}`)
  - **MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)** (`Microsoft.VisualStudio.Component.VC.Tools.x86.x64`)
  - **C++ ATL for latest v143 build tools (x86 &amp; x64)** (`Microsoft.VisualStudio.Component.VC.ATL`)
  - **C++ MFC for latest v143 build tools (x86 &amp; x64)** (`Microsoft.VisualStudio.Component.VC.ATLMFC`)
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `.\mach bootstrap`
- Build servoshell: `.\mach build`

### Android

- Ensure that the following environment variables are set:
  - `ANDROID_SDK_ROOT`
  - `ANDROID_NDK_ROOT`: `$ANDROID_SDK_ROOT/ndk/26.2.11394342/`
 `ANDROID_SDK_ROOT` can be any directory (such as `~/android-sdk`).
  All of the Android build dependencies will be installed there.
- Install the latest version of the [Android command-line
  tools](https://developer.android.com/studio#command-tools) to
  `$ANDROID_SDK_ROOT/cmdline-tools/latest`.
- Run the following command to install the necessary components:
  ```shell
  sudo $ANDROID_SDK_ROOT/cmdline-tools/latest/bin/sdkmanager --install \
   &quot;build-tools;34.0.0&quot; \
   &quot;emulator&quot; \
   &quot;ndk;26.2.11394342&quot; \
   &quot;platform-tools&quot; \
   &quot;platforms;android-33&quot; \
   &quot;system-images;android-33;google_apis;x86_64&quot;
  ```
- Follow the instructions above for the platform you are building on

### OpenHarmony

- Follow the instructions above for the platform you are building on to prepare the environment.
- Depending on the target distribution (e.g. `HarmonyOS NEXT` vs pure `OpenHarmony`) the build configuration will differ slightly.
- Ensure that the following environment variables are set
  - `DEVECO_SDK_HOME` (Required when targeting `HarmonyOS NEXT`)
  - `OHOS_BASE_SDK_HOME` (Required when targeting `OpenHarmony`)
  - `OHOS_SDK_NATIVE` (e.g. `${DEVECO_SDK_HOME}/default/openharmony/native` or `${OHOS_BASE_SDK_HOME}/${API_VERSION}/native`)
  - `SERVO_OHOS_SIGNING_CONFIG`: Path to json file containing a valid signing configuration for the demo app.
- Review the detailed instructions at [Building for OpenHarmony].
- The target distribution can be modified by passing `--flavor=&lt;default|harmonyos&gt;` to `mach &lt;build|package|install&gt;`.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[esp-rs/esp-hal]]></title>
            <link>https://github.com/esp-rs/esp-hal</link>
            <guid>https://github.com/esp-rs/esp-hal</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[no_std Hardware Abstraction Layers for ESP32 microcontrollers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/esp-rs/esp-hal">esp-rs/esp-hal</a></h1>
            <p>no_std Hardware Abstraction Layers for ESP32 microcontrollers</p>
            <p>Language: Rust</p>
            <p>Stars: 1,440</p>
            <p>Forks: 335</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./resources/esp-rs.svg&quot; alt=&quot;esp-rs logo&quot; width=&quot;100px&quot; /&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;esp-hal&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/esp-rs/esp-hal/ci.yml?labelColor=1C2C2E&amp;label=CI&amp;logo=github&amp;style=flat-square&quot; alt=&quot;GitHub Actions Workflow Status&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/esp-rs/esp-hal/hil.yml?labelColor=1C2C2E&amp;label=HIL&amp;logo=github&amp;style=flat-square&amp;event=merge_group&quot; alt=&quot;GitHub Actions Workflow Status&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/badge/license-MIT%2FApache--2.0-blue?labelColor=1C2C2E&amp;style=flat-square&quot; alt=&quot;MIT/Apache-2.0 licensed&quot; /&gt;
  &lt;a href=&quot;https://matrix.to/#/#esp-rs:matrix.org&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/matrix/esp-rs:matrix.org?labelColor=1C2C2E&amp;label=join%20matrix&amp;color=BEC5C9&amp;logo=matrix&amp;style=flat-square&quot; alt=&quot;Matrix&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

Bare-metal (`no_std`) hardware abstraction layer for Espressif devices. Currently supports, to varying degrees, the following devices:

- ESP32 Series: _ESP32_
- ESP32-C Series: _ESP32-C2, ESP32-C3, ESP32-C6_
- ESP32-H Series: _ESP32-H2_
- ESP32-S Series: _ESP32-S2, ESP32-S3_

Additionally provides limited support for programming the low-power RISC-V cores found on the _ESP32-C6_, _ESP32-S2_, and _ESP32-S3_ via the [esp-lp-hal] package.

For additional information regarding any of the crates in this repository, please refer to the relevant crate&#039;s `README.md` file. If you have any questions, comments, or concerns, please [open an issue], [start a new discussion], or join us on [Matrix].

If you are currently using (or considering using) `esp-hal` in a production environment and have any feedback or require support, please feel free to contact us at &lt;rust.support@espressif.com&gt;.

&gt; [!NOTE]
&gt;
&gt; This repository includes crates that are at various stages of maturity and stability. While many functionalities have already been implemented and are usable for most tasks, certain advanced or less common features may still be under development. Each crate may offer different levels of functionality and guarantees.

[esp-lp-hal]: https://github.com/esp-rs/esp-hal/tree/main/esp-lp-hal
[esp-idf-svc]: https://github.com/esp-rs/esp-idf-svc
[open an issue]: https://github.com/esp-rs/esp-hal/issues/new
[start a new discussion]: https://github.com/esp-rs/esp-hal/discussions/new
[matrix]: https://matrix.to/#/#esp-rs:matrix.org

## Getting Started

For information relating to the development of Rust applications on ESP devices, please first read [The Rust on ESP Book].

For information about the HAL and how to use it in your own projects, please refer to the [documentation].

When browsing the examples, we recommend viewing the tag for the `esp-hal` release you are using to ensure compatibility, e.g. [esp-hal-v1.0.0-beta.0], as the `main` branch is used for development and APIs may have changed in the meantime.

[The Rust on ESP Book]: https://docs.espressif.com/projects/rust/book/
[documentation]: https://docs.espressif.com/projects/rust/
[esp-hal-v1.0.0-beta.0]: https://github.com/esp-rs/esp-hal/tree/esp-hal-v1.0.0-beta.0/examples

## Resources

- [The Rust Programming Language](https://doc.rust-lang.org/book/)
- [The Embedded Rust Book](https://docs.rust-embedded.org/book/index.html)
- [The Embedonomicon](https://docs.rust-embedded.org/embedonomicon/)
- [The Rust on ESP Book](https://docs.espressif.com/projects/rust/esp-hal/latest/)
- [Embedded Rust (no_std) on Espressif](https://docs.espressif.com/projects/rust/no_std-training/)

## Contributing

We have a number of living documents to aid contributing to the project, please give these a read before modifying code:

- [DEVELOPER-GUIDELINES](https://github.com/esp-rs/esp-hal/blob/main/documentation/DEVELOPER-GUIDELINES.md)
- [CONTRIBUTING-GUIDE](https://github.com/esp-rs/esp-hal/blob/main/documentation/CONTRIBUTING.md)

## License

All packages within this repository are licensed under either of:

- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your option.

### Contribution notice

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in
the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without
any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[helix-editor/helix]]></title>
            <link>https://github.com/helix-editor/helix</link>
            <guid>https://github.com/helix-editor/helix</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[A post-modern modal text editor.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/helix-editor/helix">helix-editor/helix</a></h1>
            <p>A post-modern modal text editor.</p>
            <p>Language: Rust</p>
            <p>Stars: 40,081</p>
            <p>Forks: 3,052</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;h1&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;logo_dark.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;logo_light.svg&quot;&gt;
  &lt;img alt=&quot;Helix&quot; height=&quot;128&quot; src=&quot;logo_light.svg&quot;&gt;
&lt;/picture&gt;
&lt;/h1&gt;

[![Build status](https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg)](https://github.com/helix-editor/helix/actions)
[![GitHub Release](https://img.shields.io/github/v/release/helix-editor/helix)](https://github.com/helix-editor/helix/releases/latest)
[![Documentation](https://shields.io/badge/-documentation-452859)](https://docs.helix-editor.com/)
[![GitHub contributors](https://img.shields.io/github/contributors/helix-editor/helix)](https://github.com/helix-editor/helix/graphs/contributors)
[![Matrix Space](https://img.shields.io/matrix/helix-community:matrix.org)](https://matrix.to/#/#helix-community:matrix.org)

&lt;/div&gt;

![Screenshot](./screenshot.png)

A [Kakoune](https://github.com/mawww/kakoune) / [Neovim](https://github.com/neovim/neovim) inspired editor, written in Rust.

The editing model is very heavily based on Kakoune; during development I found
myself agreeing with most of Kakoune&#039;s design decisions.

For more information, see the [website](https://helix-editor.com) or
[documentation](https://docs.helix-editor.com/).

All shortcuts/keymaps can be found [in the documentation on the website](https://docs.helix-editor.com/keymap.html).

[Troubleshooting](https://github.com/helix-editor/helix/wiki/Troubleshooting)

# Features

- Vim-like modal editing
- Multiple selections
- Built-in language server support
- Smart, incremental syntax highlighting and code editing via tree-sitter

Although it&#039;s primarily a terminal-based editor, I am interested in exploring
a custom renderer (similar to Emacs) using wgpu or skulpin.

Note: Only certain languages have indentation definitions at the moment. Check
`runtime/queries/&lt;lang&gt;/` for `indents.scm`.

# Installation

[Installation documentation](https://docs.helix-editor.com/install.html).

[![Packaging status](https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1)](https://repology.org/project/helix-editor/versions)

# Contributing

Contributing guidelines can be found [here](./docs/CONTRIBUTING.md).

# Getting help

Your question might already be answered on the [FAQ](https://github.com/helix-editor/helix/wiki/FAQ).

Discuss the project on the community [Matrix Space](https://matrix.to/#/#helix-community:matrix.org) (make sure to join `#helix-editor:matrix.org` if you&#039;re on a client that doesn&#039;t support Matrix Spaces yet).

# Credits

Thanks to [@jakenvac](https://github.com/jakenvac) for designing the logo!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[launchbadge/sqlx]]></title>
            <link>https://github.com/launchbadge/sqlx</link>
            <guid>https://github.com/launchbadge/sqlx</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[🧰 The Rust SQL Toolkit. An async, pure Rust SQL crate featuring compile-time checked queries without a DSL. Supports PostgreSQL, MySQL, and SQLite.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/launchbadge/sqlx">launchbadge/sqlx</a></h1>
            <p>🧰 The Rust SQL Toolkit. An async, pure Rust SQL crate featuring compile-time checked queries without a DSL. Supports PostgreSQL, MySQL, and SQLite.</p>
            <p>Language: Rust</p>
            <p>Stars: 15,705</p>
            <p>Forks: 1,477</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;SQLx&lt;/h1&gt;
&lt;div align=&quot;center&quot;&gt;
 &lt;strong&gt;
   🧰 The Rust SQL Toolkit
 &lt;/strong&gt;
&lt;/div&gt;

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Github Actions --&gt;
  &lt;a href=&quot;https://github.com/launchbadge/sqlx/actions/workflows/sqlx.yml?query=branch%3Amain&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/launchbadge/sqlx/sqlx.yml?branch=main&amp;style=flat-square&quot; alt=&quot;actions status&quot; /&gt;&lt;/a&gt;
  &lt;!-- Version --&gt;
  &lt;a href=&quot;https://crates.io/crates/sqlx&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/sqlx.svg?style=flat-square&quot;
    alt=&quot;Crates.io version&quot; /&gt;&lt;/a&gt;
  &lt;!-- Discord --&gt;
  &lt;a href=&quot;https://discord.gg/uuruzJ7&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/discord/665528275556106240?style=flat-square&quot; alt=&quot;chat&quot; /&gt;&lt;/a&gt;
  &lt;!-- Docs --&gt;
  &lt;a href=&quot;https://docs.rs/sqlx&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square&quot; alt=&quot;docs.rs docs&quot; /&gt;&lt;/a&gt;
  &lt;!-- Downloads --&gt;
  &lt;a href=&quot;https://crates.io/crates/sqlx&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/d/sqlx.svg?style=flat-square&quot; alt=&quot;Download&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h4&gt;
    &lt;a href=&quot;#install&quot;&gt;
      Install
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;#usage&quot;&gt;
      Usage
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://docs.rs/sqlx&quot;&gt;
      Docs
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/launchbadge/sqlx/wiki/Ecosystem&quot;&gt;
      Ecosystem
    &lt;/a&gt;    
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://discord.gg/uuruzJ7&quot;&gt;
      Discord
    &lt;/a&gt;
  &lt;/h4&gt;
&lt;/div&gt;

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;small&gt;Built with ❤️ by &lt;a href=&quot;https://launchbadge.com&quot;&gt;The LaunchBadge team&lt;/a&gt;&lt;/small&gt;
&lt;/div&gt;

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;h5&gt;Have a question? Be sure to &lt;a href=&quot;FAQ.md&quot;&gt;check the FAQ first!&lt;/a&gt;&lt;/h5&gt;
&lt;/div&gt;

&lt;br /&gt;

SQLx is an async, pure Rust&lt;sub&gt;†&lt;/sub&gt; SQL crate featuring compile-time checked queries without a DSL.

-   **Truly Asynchronous**. Built from the ground-up using async/await for maximum concurrency.

-   **Compile-time checked queries** (if you want). See [SQLx is not an ORM](#sqlx-is-not-an-orm).

-   **Database Agnostic**. Support for [PostgreSQL], [MySQL], [MariaDB], [SQLite].
    -   [MSSQL] was supported prior to version 0.7, but has been removed pending a full rewrite of the driver as part of our [SQLx Pro initiative].

-   **Pure Rust**. The Postgres and MySQL/MariaDB drivers are written in pure Rust using **zero** unsafe&lt;sub&gt;††&lt;/sub&gt; code.

-   **Runtime Agnostic**. Works on different runtimes ([`async-std`] / [`tokio`] / [`actix`]) and TLS backends ([`native-tls`], [`rustls`]).

&lt;small&gt;&lt;small&gt;

† The SQLite driver uses the libsqlite3 C library as SQLite is an embedded database (the only way
we could be pure Rust for SQLite is by porting _all_ of SQLite to Rust).

†† SQLx uses `#![forbid(unsafe_code)]` unless the `sqlite` feature is enabled.
The SQLite driver directly invokes the SQLite3 API via `libsqlite3-sys`, which requires `unsafe`.

&lt;/small&gt;&lt;/small&gt;

[postgresql]: http://postgresql.org/
[sqlite]: https://sqlite.org/
[mysql]: https://www.mysql.com/
[mariadb]: https://www.mariadb.org/
[mssql]: https://www.microsoft.com/en-us/sql-server
[SQLx Pro initiative]: https://github.com/launchbadge/sqlx/discussions/1616

---

-   Cross-platform. Being native Rust, SQLx will compile anywhere Rust is supported.

-   Built-in connection pooling with `sqlx::Pool`.

-   Row streaming. Data is read asynchronously from the database and decoded on demand.

-   Automatic statement preparation and caching. When using the high-level query API (`sqlx::query`), statements are
    prepared and cached per connection.

-   Simple (unprepared) query execution including fetching results into the same `Row` types used by
    the high-level API. Supports batch execution and returns results from all statements.

-   Transport Layer Security (TLS) where supported ([MySQL], [MariaDB] and [PostgreSQL]).

-   Asynchronous notifications using `LISTEN` and `NOTIFY` for [PostgreSQL].

-   Nested transactions with support for save points.

-   `Any` database driver for changing the database driver at runtime. An `AnyPool` connects to the driver indicated by the URL scheme.

## Install

SQLx is compatible with the [`async-std`], [`tokio`], and [`actix`] runtimes; and, the [`native-tls`] and [`rustls`] TLS backends. When adding the dependency, you must choose a runtime feature that is `runtime` + `tls`.

[`async-std`]: https://github.com/async-rs/async-std
[`tokio`]: https://github.com/tokio-rs/tokio
[`actix`]: https://github.com/actix/actix-net
[`native-tls`]: https://crates.io/crates/native-tls
[`rustls`]: https://crates.io/crates/rustls

```toml
# Cargo.toml
[dependencies]
# PICK ONE OF THE FOLLOWING:

# tokio (no TLS)
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot; ] }
# tokio + native-tls
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-native-tls&quot; ] }
# tokio + rustls with ring and WebPKI CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-rustls-ring-webpki&quot; ] }
# tokio + rustls with ring and platform&#039;s native CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-rustls-ring-native-roots&quot; ] }
# tokio + rustls with aws-lc-rs
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-rustls-aws-lc-rs&quot; ] }

# async-std (no TLS)
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot; ] }
# async-std + native-tls
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-native-tls&quot; ] }
# async-std + rustls with ring and WebPKI CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-rustls-ring-webpki&quot; ] }
# async-std + rustls with ring and platform&#039;s native CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-rustls-ring-native-roots&quot; ] }
# async-std + rustls with aws-lc-rs
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-rustls-aws-lc-rs&quot; ] }
```

#### Cargo Feature Flags

For backward-compatibility reasons, the runtime and TLS features can either be chosen together as a single feature,
or separately.

For forward compatibility, you should use the separate runtime and TLS features as the combination features may
be removed in the future.

-   `runtime-async-std`: Use the `async-std` runtime without enabling a TLS backend.

-   `runtime-tokio`: Use the `tokio` runtime without enabling a TLS backend.

    - Actix-web is fully compatible with Tokio and so a separate runtime feature is no longer needed.

-   `tls-native-tls`: Use the `native-tls` TLS backend (OpenSSL on *nix, SChannel on Windows, Secure Transport on macOS).

-   `tls-rustls`: Use the `rustls` TLS backend (cross-platform backend, only supports TLS 1.2 and 1.3).

-   `postgres`: Add support for the Postgres database server.

-   `mysql`: Add support for the MySQL/MariaDB database server.

-   `mssql`: Add support for the MSSQL database server.

-   `sqlite`: Add support for the self-contained [SQLite](https://sqlite.org/) database engine with SQLite bundled and statically-linked.

-   `sqlite-unbundled`: The same as above (`sqlite`), but link SQLite from the system instead of the bundled version.
    * Allows updating SQLite independently of SQLx or using forked versions.
    * You must have SQLite installed on the system or provide a path to the library at build time.
       See [the `rusqlite` README](https://github.com/rusqlite/rusqlite?tab=readme-ov-file#notes-on-building-rusqlite-and-libsqlite3-sys) for details.
    * May result in link errors if the SQLite version is too old. Version `3.20.0` or newer is recommended.
    * Can increase build time due to the use of bindgen.

-   `sqlite-preupdate-hook`: enables SQLite&#039;s [preupdate hook](https://sqlite.org/c3ref/preupdate_count.html) API.
    * Exposed as a separate feature because it&#039;s generally not enabled by default.
    * Using this feature with `sqlite-unbundled` may cause linker failures if the system SQLite version does not support it.

-   `any`: Add support for the `Any` database driver, which can proxy to a database driver at runtime.

-   `derive`: Add support for the derive family macros, those are `FromRow`, `Type`, `Encode`, `Decode`.

-   `macros`: Add support for the `query*!` macros, which allows compile-time checked queries.

-   `migrate`: Add support for the migration management and `migrate!` macro, which allow compile-time embedded migrations.

-   `uuid`: Add support for UUID.

-   `chrono`: Add support for date and time types from `chrono`.

-   `time`: Add support for date and time types from `time` crate (alternative to `chrono`, which is preferred by `query!` macro, if both enabled)

-   `bstr`: Add support for `bstr::BString`.

-   `bigdecimal`: Add support for `NUMERIC` using the `bigdecimal` crate.

-   `rust_decimal`: Add support for `NUMERIC` using the `rust_decimal` crate.

-   `ipnet`: Add support for `INET` and `CIDR` (in postgres) using the `ipnet` crate.

-   `ipnetwork`: Add support for `INET` and `CIDR` (in postgres) using the `ipnetwork` crate.

-   `json`: Add support for `JSON` and `JSONB` (in postgres) using the `serde_json` crate.

-   Offline mode is now always enabled. See [sqlx-cli/README.md][readme-offline].

[readme-offline]: sqlx-cli/README.md#enable-building-in-offline-mode-with-query

## SQLx is not an ORM!

SQLx supports **compile-time checked queries**. It does not, however, do this by providing a Rust
API or DSL (domain-specific language) for building queries. Instead, it provides macros that take
regular SQL as input and ensure that it is valid for your database. The way this works is that
SQLx connects to your development DB at compile time to have the database itself verify (and return
some info on) your SQL queries. This has some potentially surprising implications:

- Since SQLx never has to parse the SQL string itself, any syntax that the development DB accepts
  can be used (including things added by database extensions)
- Due to the different amount of information databases let you retrieve about queries, the extent of
  SQL verification you get from the query macros depends on the database

**If you are looking for an (asynchronous) ORM,** you can check out our new [Ecosystem wiki page](https://github.com/launchbadge/sqlx/wiki/Ecosystem#orms)!

[`ormx`]: https://crates.io/crates/ormx
[`SeaORM`]: https://github.com/SeaQL/sea-orm
## Usage

See the `examples/` folder for more in-depth usage.

### Quickstart

```rust
use sqlx::postgres::PgPoolOptions;
// use sqlx::mysql::MySqlPoolOptions;
// etc.

#[async_std::main] // Requires the `attributes` feature of `async-std`
// or #[tokio::main]
// or #[actix_web::main]
async fn main() -&gt; Result&lt;(), sqlx::Error&gt; {
    // Create a connection pool
    //  for MySQL/MariaDB, use MySqlPoolOptions::new()
    //  for SQLite, use SqlitePoolOptions::new()
    //  etc.
    let pool = PgPoolOptions::new()
        .max_connections(5)
        .connect(&quot;postgres://postgres:password@localhost/test&quot;).await?;

    // Make a simple query to return the given parameter (use a question mark `?` instead of `$1` for MySQL/MariaDB)
    let row: (i64,) = sqlx::query_as(&quot;SELECT $1&quot;)
        .bind(150_i64)
        .fetch_one(&amp;pool).await?;

    assert_eq!(row.0, 150);

    Ok(())
}
```


### Connecting

A single connection can be established using any of the database connection types and calling `connect()`.

```rust
use sqlx::Connection;

let conn = SqliteConnection::connect(&quot;sqlite::memory:&quot;).await?;
```

Generally, you will want to instead create a connection pool (`sqlx::Pool`) for the application to
regulate how many server-side connections it&#039;s using.

```rust
let pool = MySqlPool::connect(&quot;mysql://user:pass@host/database&quot;).await?;
```

### Querying

In SQL, queries can be separated into prepared (parameterized) or unprepared (simple). Prepared queries have their
query plan _cached_, use a binary mode of communication (lower bandwidth and faster decoding), and utilize parameters
to avoid SQL injection. Unprepared queries are simple and intended only for use where a prepared statement
will not work, such as various database commands (e.g., `PRAGMA` or `SET` or `BEGIN`).

SQLx supports all operations with both types of queries. In SQLx, a `&amp;str` is treated as an unprepared query,
and a `Query` or `QueryAs` struct is treated as a prepared query.

```rust
// low-level, Executor trait
conn.execute(&quot;BEGIN&quot;).await?; // unprepared, simple query
conn.execute(sqlx::query(&quot;DELETE FROM table&quot;)).await?; // prepared, cached query
```

We should prefer to use the high-level `query` interface whenever possible. To make this easier, there are finalizers
on the type to avoid the need to wrap with an executor.

```rust
sqlx::query(&quot;DELETE FROM table&quot;).execute(&amp;mut conn).await?;
sqlx::query(&quot;DELETE FROM table&quot;).execute(&amp;pool).await?;
```

The `execute` query finalizer returns the number of affected rows, if any, and drops all received results.
In addition, there are `fetch`, `fetch_one`, `fetch_optional`, and `fetch_all` to receive results.

The `Query` type returned from `sqlx::query` will return `Row&lt;&#039;conn&gt;` from the database. Column values can be accessed
by ordinal or by name with `row.get()`. As the `Row` retains an immutable borrow on the connection, only one
`Row` may exist at a time.

The `fetch` query finalizer returns a stream-like type that iterates through the rows in the result sets.

```rust
// provides `try_next`
use futures_util::TryStreamExt;
// provides `try_get`
use sqlx::Row;

let mut rows = sqlx::query(&quot;SELECT * FROM users WHERE email = ?&quot;)
    .bind(email)
    .fetch(&amp;mut conn);

while let Some(row) = rows.try_next().await? {
    // map the row into a user-defined domain type
    let email: &amp;str = row.try_get(&quot;email&quot;)?;
}
```

To assist with mapping the row into a domain type, one of two idioms may be used:

```rust
let mut stream = sqlx::query(&quot;SELECT * FROM users&quot;)
    .map(|row: PgRow| {
        // map the row into a user-defined domain type
    })
    .fetch(&amp;mut conn);
```

```rust
#[derive(sqlx::FromRow)]
struct User { name: String, id: i64 }

let mut stream = sqlx::query_as::&lt;_, User&gt;(&quot;SELECT * FROM users WHERE email = ? OR name = ?&quot;)
    .bind(user_email)
    .bind(user_name)
    .fetch(&amp;mut conn);
```

Instead of a stream of results, we can use `fetch_one` or `fetch_optional` to request one required or optional result
from the database.

### Compile-time verification

We can use the macro, `sqlx::query!` to achieve compile-time syntactic and semantic verification of the SQL, with
an output to an anonymous record type where each SQL column is a Rust field (using raw identifiers where needed).

```rust
let countries = sqlx::query!(
        &quot;
SELECT country, COUNT(*) as count
FROM users
GROUP BY country
WHERE organization = ?
        &quot;,
        organization
    )
    .fetch_all(&amp;pool) // -&gt; Vec&lt;{ country: String, count: i64 }&gt;
    .await?;

// countries[0].country
// countries[0].count
```

Differences from `query()`:

-   The input (or bind) parameters must be given all at once (and they are compile-time validated to be
    the right number and the right type).

-   The output type is an anonymous record. In the above example the type would be similar to:

    ```rust
    { country: String, count: i64 }
    ```

-   The `DATABASE_URL` environment variable must be set at build time to a database which it can prepare
    queries against; the database does not have to contain any data but must be the same
    kind (MySQL, Postgres, etc.) and have the same schema as the database you will be connecting to at runtime.

    For convenience, you can use [a `.env` file][dotenv]&lt;sup&gt;1&lt;/sup&gt; to set DATABASE_URL so that you don&#039;t have to pass it every time:

    ```
    DATABASE_URL=mysql://localhost/my_database
    ```

[dotenv]: https://github.com/dotenv-rs/dotenv#examples

The biggest downside to `query!()` is that the output type cannot be named (due to Rust not
officially supporting anonymous records). To address that, there is a `query_as!()` macro that is
mostly identical except that you can name the output type.

```rust
// no traits are needed
struct Country { country: String, count: i64 }

let countries = sqlx::query_as!(Country,
        &quot;
SELECT country, COUNT(*) as count
FROM users
GROUP BY country
WHERE organization = ?
        &quot;,
        organization
    )
    .fetch_all(&amp;pool) // -&gt; Vec&lt;Country&gt;
    .await?;

// countries[0].country
// countries[0].count
```

To avoid the need of having a development database around to compile the project even when no
modifications (to the database-accessing parts of the code) are done, you can enable &quot;offline mode&quot;
to cache the results of the SQL query analysis using the `sqlx` command-line tool. See
[sqlx-cli/README.md](./sqlx-cli/README.md#enable-building-in-offline-mode-with-query).

Compile-time verified queries do quite a bit of work at compile time. Incremental actions like
`cargo check` and `cargo build` can be significantly faster when using an optimized build by
putting the following in your `Cargo.toml` (More information in the
[Profiles section](https://doc.rust-lang.org/cargo/reference/profiles.html) of The Cargo Book)

```toml
[profile.dev.package.sqlx-macros]
opt-level = 3
```

&lt;sup&gt;1&lt;/sup&gt; The `dotenv` crate itself appears abandoned as of [December 2021](https://github.com/dotenv-rs/dotenv/issues/74)
so we now use the `dotenvy` crate instead. The file format is the same.

## Safety

This crate uses `#![forbid(unsafe_code)]` to ensure everything is implemented in 100% Safe Rust.

If the `sqlite` feature is enabled, this is downgraded to `#![deny(unsafe_code)]` with `#![allow(unsafe_code)]` on the
`sqlx::sqlite` module. There are several places where we interact with the C SQLite API. We try to document each call for the invariants we&#039;re assuming. We absolutely welcome auditing of, and feedback on, our unsafe code usage.

## License

Licensed under either of

-   Apache License, Version 2.0
    ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
-   MIT license
    ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your option.

## Contribution

Unless you explicitly state otherwise, any Contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nexus-xyz/nexus-cli]]></title>
            <link>https://github.com/nexus-xyz/nexus-cli</link>
            <guid>https://github.com/nexus-xyz/nexus-cli</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Command line interface for supplying proofs to the Nexus network.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nexus-xyz/nexus-cli">nexus-xyz/nexus-cli</a></h1>
            <p>Command line interface for supplying proofs to the Nexus network.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,025</p>
            <p>Forks: 575</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>[![Release](https://img.shields.io/github/v/release/nexus-xyz/nexus-cli.svg)](https://github.com/nexus-xyz/nexus-cli/releases)
[![CI](https://github.com/nexus-xyz/nexus-cli/actions/workflows/ci.yml/badge.svg)](https://github.com/nexus-xyz/nexus-cli/actions)
[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](https://github.com/nexus-xyz/nexus-cli/blob/main/LICENSE-APACHE)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/nexus-xyz/nexus-cli/blob/main/LICENSE-MIT)
[![Twitter](https://img.shields.io/twitter/follow/NexusLabs)](https://x.com/NexusLabs)
[![Discord](https://img.shields.io/badge/Discord-Join-7289da.svg?logo=discord&amp;logoColor=white)](https://discord.com/invite/nexus-xyz)

# Nexus CLI

A high-performance command-line interface for contributing proofs to the Nexus network.

&lt;figure&gt;
    &lt;a href=&quot;https://nexus.xyz/&quot;&gt;
        &lt;img src=&quot;assets/images/nexus-network-image.png&quot; alt=&quot;Nexus Network visualization showing a distributed network of interconnected nodes with a &#039;Launch Network&#039; button in the center&quot;&gt;
    &lt;/a&gt;
    &lt;figcaption&gt;
        &lt;strong&gt;Verifiable Computation on a Global Scale&lt;/strong&gt;&lt;br&gt;
        We&#039;re building a global distributed prover network to unite the world&#039;s computers and power a new and better Internet: the Verifiable Internet. Connect to the beta and give it a try today.
    &lt;/figcaption&gt;
&lt;/figure&gt;

## Nexus Network

[Nexus](https://nexus.xyz/) is a global distributed prover network that unites the world&#039;s computers to power a new and
better Internet: the Verifiable Internet.

There have been several testnets so far:

- Testnet 0: [October 8 – 28, 2024](https://blog.nexus.xyz/nexus-launches-worlds-first-open-prover-network/)
- Testnet I: [December 9 – 13, 2024](https://blog.nexus.xyz/the-new-nexus-testnet-is-live/)
- Testnet II: [February 18 – 22, 2025](https://blog.nexus.xyz/testnet-ii-is-open/)
- Devnet: [February 22 - June 20, 2025](https://docs.nexus.xyz/layer-1/testnet/devnet)
- Testnet III: [Ongoing](https://blog.nexus.xyz/live-everywhere/)

---

## Quick Start

### Installation

#### Precompiled Binary (Recommended)

For the simplest and most reliable installation:

```bash
curl https://cli.nexus.xyz/ | sh
```

This downloads the latest binary, prompts for Terms of Use acceptance, and starts interactive mode.

#### Non-Interactive Installation

For automated installations (e.g., in CI):

```bash
curl -sSf https://cli.nexus.xyz/ -o install.sh
chmod +x install.sh
NONINTERACTIVE=1 ./install.sh
```

### Proving

Proving with the CLI is documented [here](https://docs.nexus.xyz/layer-1/testnet/cli-node).

To start with an existing node ID, run:

```bash
nexus-cli start --node-id &lt;your-node-id&gt;
```

Alternatively, you can register your wallet address and create a node ID with the CLI, or at [app.nexus.xyz](https://app.nexus.xyz).

```bash
nexus-cli register-user --wallet-address &lt;your-wallet-address&gt;
nexus-cli register-node --node-id &lt;your-cli-node-id&gt;
nexus-cli start
```

To run the CLI noninteractively, you can also opt to start it in headless mode.

```bash
nexus-cli start --headless
```

#### Quick Reference

The `register-user` and `register-node` commands will save your credentials to `~/.nexus/config.json`. To clear credentials, run:

```bash
nexus-cli logout
```

For troubleshooting or to see available command-line options, run:

```bash
nexus-cli --help
```

### Adaptive Task Difficulty

The Nexus CLI features an **adaptive difficulty system** that automatically adjusts task difficulty based on your node&#039;s performance. This ensures optimal resource utilization while preventing system overload.

#### How It Works

- **Starts at**: `small` difficulty
- **Auto-promotes**: If tasks complete in &lt; 7 minutes

#### When to Override Difficulty

**Lower Difficulty** (e.g. `Small` or `SmallMedium`):
- Resource-constrained systems
- Background processing alongside other apps
- Testing/development environments
- Battery-powered devices

**Higher Difficulty** (e.g. `Large`, `ExtraLarge`, or `ExtraLarge2`):
- High-performance hardware (8+ cores, 16+ GB RAM)
- Dedicated proving machines
- Maximum reward optimization

#### Using Difficulty Override

```bash
# Lower difficulty for resource-constrained systems
nexus-cli start --max-difficulty small
nexus-cli start --max-difficulty small_medium

# Higher difficulty for powerful hardware
nexus-cli start --max-difficulty medium
nexus-cli start --max-difficulty large
nexus-cli start --max-difficulty extra_large
nexus-cli start --max-difficulty extra_large_2
nexus-cli start --max-difficulty extra_large_3
nexus-cli start --max-difficulty extra_large_4
nexus-cli start --max-difficulty extra_large_5

# Case-insensitive (all equivalent)
nexus-cli start --max-difficulty MEDIUM
nexus-cli start --max-difficulty medium
nexus-cli start --max-difficulty Medium
```

#### Difficulty Guidelines

| Difficulty | Use Case |
|------------|----------|
| `small` | Default, starting task |
| `small_medium` | Building reputation |
| `medium` and `large` | Standard desktop/laptop |
| `extra_large` and above | High-performance systems, more points |

&gt; **Tip**: Use `nexus-cli start --help` to see the full auto-promotion details in the CLI help text.

#### Troubleshooting Difficulty Issues

**Tasks taking too long:**

Try a lower difficulty.

```bash
nexus-cli start --max-difficulty small_medium
```

**Want more challenging tasks:**

Request a harder difficulty. It will still take time to build up reputation to get the requested difficulty.

```bash
nexus-cli start --max-difficulty extra_large_2
```

**Unsure about system capabilities:**
- Use the default adaptive system (no `--max-difficulty` needed)
- The system will automatically find the optimal difficulty for your hardware
- Only override if you&#039;re fine-tuning performance

### Docker Installation

For containerized deployments:

1. Install [Docker](https://docs.docker.com/engine/install/) and [Docker Compose](https://docs.docker.com/compose/install/)
2. Update the node ID in `docker-compose.yaml`
3. Build and run:

```bash
docker compose build --no-cache
docker compose up -d
docker compose logs  # Check logs
docker compose down  # Shutdown
```

---

## Terms of Use

Use of the CLI is subject to the [Terms of Use](https://nexus.xyz/terms-of-use).
First-time users running interactively will be prompted to accept these terms.

---

## Node ID

During the CLI&#039;s startup, you&#039;ll be asked for your node ID. To skip prompts in a
non-interactive environment, manually create a `~/.nexus/config.json` in the
following format:

```json
{
   &quot;node_id&quot;: &quot;&lt;YOUR NODE ID&gt;&quot;
}
```

---

## Get Help

- [Network FAQ](https://docs.nexus.xyz/layer-1/testnet/faq)
- [Discord Community](https://discord.gg/nexus-xyz)
- Technical issues? [Open an issue](https://github.com/nexus-xyz/nexus-cli/issues)
- To submit programs to the network for proving, contact
  [growth@nexus.xyz](mailto:growth@nexus.xyz).

---

## Contributing

Interested in contributing to the Nexus Network CLI? Check out our
[Contributor Guide](./CONTRIBUTING.md) for:

- Development setup instructions
- How to report issues and submit pull requests
- Our code of conduct and community guidelines
- Tips for working with the codebase

For most users, we recommend using the precompiled binaries as described above.
The contributor guide is intended for those who want to modify or improve the CLI
itself.

### 🛠  Developer Guide

The following steps may be required in order to set up a development environment for contributing to the project:

#### Linux

```bash
sudo apt update
sudo apt upgrade
sudo apt install build-essential pkg-config libssl-dev git-all
sudo apt install protobuf-compiler
```

#### macOS

```bash
# Install using Homebrew
brew install protobuf

# Verify installation
protoc --version
```

#### Windows

[Install WSL](https://learn.microsoft.com/en-us/windows/wsl/install),
then see Linux instructions above.

```bash
# Install using Chocolatey
choco install protobuf
```

## License

Nexus CLI is distributed under the terms of both the [MIT License](./LICENSE-MIT) and the [Apache License (Version 2.0)](./LICENSE-APACHE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[wezterm/wezterm]]></title>
            <link>https://github.com/wezterm/wezterm</link>
            <guid>https://github.com/wezterm/wezterm</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[A GPU-accelerated cross-platform terminal emulator and multiplexer written by @wez and implemented in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wezterm/wezterm">wezterm/wezterm</a></h1>
            <p>A GPU-accelerated cross-platform terminal emulator and multiplexer written by @wez and implemented in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 22,029</p>
            <p>Forks: 1,000</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># Wez&#039;s Terminal

&lt;img height=&quot;128&quot; alt=&quot;WezTerm Icon&quot; src=&quot;https://raw.githubusercontent.com/wezterm/wezterm/main/assets/icon/wezterm-icon.svg&quot; align=&quot;left&quot;&gt; *A GPU-accelerated cross-platform terminal emulator and multiplexer written by &lt;a href=&quot;https://github.com/wez&quot;&gt;@wez&lt;/a&gt; and implemented in &lt;a href=&quot;https://www.rust-lang.org/&quot;&gt;Rust&lt;/a&gt;*

User facing docs and guide at: https://wezterm.org/

![Screenshot](docs/screenshots/two.png)

*Screenshot of wezterm on macOS, running vim*

## Installation

https://wezterm.org/installation

## Getting help

This is a spare time project, so please bear with me.  There are a couple of channels for support:

* You can use the [GitHub issue tracker](https://github.com/wezterm/wezterm/issues) to see if someone else has a similar issue, or to file a new one.
* Start or join a thread in our [GitHub Discussions](https://github.com/wezterm/wezterm/discussions); if you have general
  questions or want to chat with other wezterm users, you&#039;re welcome here!
* There is a [Matrix room via Element.io](https://app.element.io/#/room/#wezterm:matrix.org)
  for (potentially!) real time discussions.

The GitHub Discussions and Element/Gitter rooms are better suited for questions
than bug reports, but don&#039;t be afraid to use whichever you are most comfortable
using and we&#039;ll work it out.

## Supporting the Project

If you use and like WezTerm, please consider sponsoring it: your support helps
to cover the fees required to maintain the project and to validate the time
spent working on it!

[Read more about sponsoring](https://wezterm.org/sponsor.html).

* [![Sponsor WezTerm](https://img.shields.io/github/sponsors/wez?label=Sponsor%20WezTerm&amp;logo=github&amp;style=for-the-badge)](https://github.com/sponsors/wez)
* [Patreon](https://patreon.com/WezFurlong)
* [Ko-Fi](https://ko-fi.com/wezfurlong)
* [Liberapay](https://liberapay.com/wez)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[sxyazi/yazi]]></title>
            <link>https://github.com/sxyazi/yazi</link>
            <guid>https://github.com/sxyazi/yazi</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[💥 Blazing fast terminal file manager written in Rust, based on async I/O.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sxyazi/yazi">sxyazi/yazi</a></h1>
            <p>💥 Blazing fast terminal file manager written in Rust, based on async I/O.</p>
            <p>Language: Rust</p>
            <p>Stars: 28,581</p>
            <p>Forks: 613</p>
            <p>Stars today: 39 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://go.warp.dev/yazi&quot; target=&quot;_blank&quot;&gt;
		&lt;sup&gt;Special thanks to:&lt;/sup&gt;
		&lt;br&gt;
		&lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://github.com/warpdotdev/brand-assets/blob/main/Github/Sponsor/Warp-Github-LG-02.png&quot;&gt;
		&lt;br&gt;
		&lt;h&gt;Warp, built for coding with multiple AI agents&lt;/b&gt;
		&lt;br&gt;
		&lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt;
	&lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

## Yazi - ⚡️ Blazing Fast Terminal File Manager

Yazi (means &quot;duck&quot;) is a terminal file manager written in Rust, based on non-blocking async I/O. It aims to provide an efficient, user-friendly, and customizable file management experience.

💡 A new article explaining its internal workings: [Why is Yazi Fast?](https://yazi-rs.github.io/blog/why-is-yazi-fast)

- 🚀 **Full Asynchronous Support**: All I/O operations are asynchronous, CPU tasks are spread across multiple threads, making the most of available resources.
- 💪 **Powerful Async Task Scheduling and Management**: Provides real-time progress updates, task cancellation, and internal task priority assignment.
- 🖼️ **Built-in Support for Multiple Image Protocols**: Also integrated with Überzug++ and Chafa, covering almost all terminals.
- 🌟 **Built-in Code Highlighting and Image Decoding**: Combined with the pre-loading mechanism, greatly accelerates image and normal file loading.
- 🔌 **Concurrent Plugin System**: UI plugins (rewriting most of the UI), functional plugins, custom previewer/preloader/spotter/fetcher; Just some pieces of Lua.
- 📡 **Data Distribution Service**: Built on a client-server architecture (no additional server process required), integrated with a Lua-based publish-subscribe model, achieving cross-instance communication and state persistence.
- 📦 **Package Manager**: Install plugins and themes with one command, keeping them up-to-date, or pin them to a specific version.
- 🧰 Integration with ripgrep, fd, fzf, zoxide
- 💫 Vim-like input/pick/confirm/which/notify component, auto-completion for cd paths
- 🏷️ Multi-Tab Support, Cross-directory selection, Scrollable Preview (for videos, PDFs, archives, code, directories, etc.)
- 🔄 Bulk Renaming, Archive Extraction, Visual Mode, File Chooser, [Git Integration](https://github.com/yazi-rs/plugins/tree/main/git.yazi), [Mount Manager](https://github.com/yazi-rs/plugins/tree/main/mount.yazi)
- 🎨 Theme System, Mouse Support, Trash Bin, Custom Layouts, Virtual Filesystem, CSI u, OSC 52
- ... and more!

https://github.com/sxyazi/yazi/assets/17523360/92ff23fa-0cd5-4f04-b387-894c12265cc7

## Project status

Public beta, can be used as a daily driver.

Yazi is currently in heavy development, expect breaking changes.

## Documentation

- Usage: https://yazi-rs.github.io/docs/installation
- Features: https://yazi-rs.github.io/features

## Discussion

- Discord Server (English mainly): https://discord.gg/qfADduSdJu
- Telegram Group (Chinese mainly): https://t.me/yazi_rs

## Image Preview

| Platform                                                                     | Protocol                               | Support                                  |
| ---------------------------------------------------------------------------- | -------------------------------------- | ---------------------------------------- |
| [kitty](https://github.com/kovidgoyal/kitty) (&gt;= 0.28.0)                     | [Kitty unicode placeholders][kgp]      | ✅ Built-in                              |
| [iTerm2](https://iterm2.com)                                                 | [Inline images protocol][iip]          | ✅ Built-in                              |
| [WezTerm](https://github.com/wez/wezterm)                                    | [Inline images protocol][iip]          | ✅ Built-in                              |
| [Konsole](https://invent.kde.org/utilities/konsole)                          | [Kitty old protocol][kgp-old]          | ✅ Built-in                              |
| [foot](https://codeberg.org/dnkl/foot)                                       | [Sixel graphics format][sixel]         | ✅ Built-in                              |
| [Ghostty](https://github.com/ghostty-org/ghostty)                            | [Kitty unicode placeholders][kgp]      | ✅ Built-in                              |
| [Windows Terminal](https://github.com/microsoft/terminal) (&gt;= v1.22.10352.0) | [Sixel graphics format][sixel]         | ✅ Built-in                              |
| [st with Sixel patch](https://github.com/bakkeby/st-flexipatch)              | [Sixel graphics format][sixel]         | ✅ Built-in                              |
| [Warp](https://www.warp.dev) (macOS/Linux only)                              | [Inline images protocol][iip]          | ✅ Built-in                              |
| [Tabby](https://github.com/Eugeny/tabby)                                     | [Inline images protocol][iip]          | ✅ Built-in                              |
| [VSCode](https://github.com/microsoft/vscode)                                | [Inline images protocol][iip]          | ✅ Built-in                              |
| [Rio](https://github.com/raphamorim/rio)                                     | [Inline images protocol][iip]          | ❌ Rio renders images at incorrect sizes |
| [Black Box](https://gitlab.gnome.org/raggesilver/blackbox)                   | [Sixel graphics format][sixel]         | ✅ Built-in                              |
| [Hyper](https://github.com/vercel/hyper)                                     | [Inline images protocol][iip]          | ✅ Built-in                              |
| [Bobcat](https://github.com/ismail-yilmaz/Bobcat)                            | [Inline images protocol][iip]          | ✅ Built-in                              |
| X11 / Wayland                                                                | Window system protocol                 | ☑️ [Überzug++][ueberzug] required        |
| Fallback                                                                     | [ASCII art (Unicode block)][ascii-art] | ☑️ [Chafa][chafa] required               |

See https://yazi-rs.github.io/docs/image-preview for details.

&lt;!-- Protocols --&gt;

[kgp]: https://sw.kovidgoyal.net/kitty/graphics-protocol/#unicode-placeholders
[kgp-old]: https://github.com/sxyazi/yazi/blob/main/yazi-adapter/src/drivers/kgp_old.rs
[iip]: https://iterm2.com/documentation-images.html
[sixel]: https://www.vt100.net/docs/vt3xx-gp/chapter14.html
[ascii-art]: https://en.wikipedia.org/wiki/ASCII_art

&lt;!-- Dependencies --&gt;

[ueberzug]: https://github.com/jstkdng/ueberzugpp
[chafa]: https://hpjansson.org/chafa/

## License

Yazi is MIT-licensed. For more information check the [LICENSE](LICENSE) file.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[abenz1267/walker]]></title>
            <link>https://github.com/abenz1267/walker</link>
            <guid>https://github.com/abenz1267/walker</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[Multi-Purpose Launcher with a lot of features. Highly Customizable and fast.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/abenz1267/walker">abenz1267/walker</a></h1>
            <p>Multi-Purpose Launcher with a lot of features. Highly Customizable and fast.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,525</p>
            <p>Forks: 58</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># Walker - A Modern Application Launcher

A fast, customizable application launcher built with GTK4 and Rust, designed for Linux desktop environments. Walker provides a clean, modern interface for launching applications, running commands, performing calculations, and more.

[![Discord](https://img.shields.io/discord/1402235361463242964?logo=discord)](https://discord.gg/mGQWBQHASt)
[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)

## Features

Walker offers multiple provider types for different use cases:

- **Desktop Applications**: Launch installed GUI applications
- **Calculator**: Perform mathematical calculations with `=` prefix
- **File Browser**: Navigate and open files with `/` prefix
- **Command Runner**: Execute shell commands
- **Websearch**: Search the web with custom-defined engines
- **Clipboard History**: Access clipboard history with `:` prefix
- **Symbol Picker**: Insert special symbols with `.` prefix
- **Provider List**: Switch between providers with `;` prefix
- **Menu Integration**: Create custom menus with elephant and let walker display them
- **Dmenu**: Your good old dmenu ... with seamless menus!
- **Arch Linux Packages**: Search through available packages (official and aur), install or delete a target! List all exlusively installed packages.
- **Todo List**: create simple todo items with basic time tracking, scheduling and notifications

## Installation

### Build from Source

```bash
# Clone the repository
git clone https://github.com/abenz1267/walker.git
cd walker

# Build with Cargo
cargo build --release

# Run Walker
./target/release/walker
```

### Install using Nix

You have two options of installing walker using Nix.

1. Using the package exposed by this flake
   1. Add to your flake `inputs.walker.url = &quot;github:abenz1267/walker&quot;;`
   2. Add `inputs.walker.packages.&lt;system&gt;.default` to `environment.systemPackages` or `home.packages`

2. Using the home-manager module exposed by this flake:
   1. Add to your flake `inputs.walker.url = &quot;github:abenz1267/walker&quot;;`
   2. Add `imports = [inputs.walker.homeManagerModules.default];` into your home-manager config
   3. Configure walker using:

```nix
programs.walker = {
  enable = true;
  runAsService = true;

  # All options from the config.toml can be used here.
  config = {
    placeholders.&quot;default&quot;.input = &quot;Example&quot;;
    providers.prefixes = [
      {provider = &quot;websearch&quot;; prefix = &quot;+&quot;;}
      {provider = &quot;providerlist&quot;; prefix = &quot;_&quot;;}
    ];
    keybinds.quick_activate = [&quot;F1&quot; &quot;F2&quot; &quot;F3&quot;];
  };

  # If this is not set the default styling is used.
  theme.style = &#039;&#039;
    * {
      color: #dcd7ba;
    }
  &#039;&#039;;
};
```

Additionally, there is a binary caches at `https://walker.cachix.org` and `https://walker-git.cachix.org` which you can use with the following:

```nix
nix.settings = {
  substituters = [&quot;https://walker.cachix.org&quot;];
  trusted-public-keys = [&quot;walker.cachix.org-1:fG8q+uAaMqhsMxWjwvk0IMb4mFPFLqHjuvfwQxE4oJM=&quot;];
};
```

```nix
nix.settings = {
  substituters = [&quot;https://walker-git.cachix.org&quot;];
  trusted-public-keys = [&quot;walker-git.cachix.org-1:vmC0ocfPWh0S/vRAQGtChuiZBTAe4wiKDeyyXM0/7pM=&quot;];
};
```

### Dependencies

- GTK4 (version 4.6+)
- gtk4-layer-shell
- Protocol Buffers compiler
- cairo
- poppler-glib
- make sure [elephant](https://github.com/abenz1267/elephant) is running before starting Walker

## Usage

### Basic Usage

**Make sure `elephant` is running and you have providers installed. `elephant-providerlist` and f.e. `elephant-desktopapplications`.**

Launch Walker with:

```bash
walker --gapplication-service
```

To open it, simply call:

```bash
walker
```

or for an ever faster startup

```bash
nc -U /run/user/1000/walker/walker.sock
```

## Keybinds

The following modifier keys are valid: `ctrl`, `alt`, `shift`, `super`.

To get a full list of possible key values, look here: [GDK key-values](https://github.com/gtk-rs/gtk4-rs/blob/0.9/gdk4/sys/src/lib.rs#L302).

F.e. `pub const GDK_KEY_semicolon: c_int = 59;` means that `ctrl semicolon` would be a valid keybind.

## Config

Configuration should be done in `~/.config/walker`.

Check out the [default config](https://raw.githubusercontent.com/abenz1267/walker/refs/heads/master/resources/config.toml).

## Theming

You can customize Walker&#039;s appearance by creating a custom theme. Checkout `resources/themes/default` for the default theme. Themes inherit the default theme by default, so if you just want to change the CSS, you can just create `themes/yours/style.css`.

You can customize rendering of list items for each provider individually, f.e. &quot;item_files.xml&quot; will define the layout for items sourced from the `files` provider.

Please refer to [the GTK4 docs](https://docs.gtk.org/gtk4/) to checkout how to write `*.xml` files for GTK4.

**THE DEFAULT THEME CANNOT BE CHANGED**.

## License

This project is licensed under the GNU General Public License v3.0 - see the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ai-dynamo/dynamo]]></title>
            <link>https://github.com/ai-dynamo/dynamo</link>
            <guid>https://github.com/ai-dynamo/dynamo</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[A Datacenter Scale Distributed Inference Serving Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo</a></h1>
            <p>A Datacenter Scale Distributed Inference Serving Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 5,185</p>
            <p>Forks: 619</p>
            <p>Stars today: 100 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;
![Dynamo banner](./docs/images/frontpage-banner.png)

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)
[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)

| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/762)** | **[Support matrix](https://github.com/ai-dynamo/dynamo/blob/main/docs/support_matrix.md)** | **[Documentation](https://docs.nvidia.com/dynamo/latest/index.html)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Prebuilt containers](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** | **[Blogs](https://developer.nvidia.com/blog/tag/nvidia-dynamo)**

# NVIDIA Dynamo

High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.

## Latest News

* [08/05] Deploy `openai/gpt-oss-120b` with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo [➡️ link](./components/backends/trtllm/gpt-oss.md)

## The Era of Multi-GPU, Multi-Node

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-gpu-vertical.png&quot; alt=&quot;Multi Node Multi-GPU topology&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs—and sometimes many servers—but it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.

Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:

- **Disaggregated prefill &amp; decode inference** – Maximizes GPU throughput and facilitates trade off between throughput and latency.
- **Dynamic GPU scheduling** – Optimizes performance based on fluctuating demand
- **LLM-aware request routing** – Eliminates unnecessary KV cache re-computation
- **Accelerated data transfer** – Reduces inference response time using NIXL.
- **KV cache offloading** – Leverages multiple memory hierarchies for higher system throughput

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-architecture.png&quot; alt=&quot;Dynamo architecture&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

## Framework Support Matrix

| Feature | vLLM | SGLang | TensorRT-LLM |
|---------|----------------------|----------------------------|----------------------------------------|
| [**Disaggregated Serving**](/docs/architecture/disagg_serving.md) | ✅ | ✅ | ✅ |
| [**Conditional Disaggregation**](/docs/architecture/disagg_serving.md#conditional-disaggregation) | 🚧 | 🚧 | 🚧 |
| [**KV-Aware Routing**](/docs/architecture/kv_cache_routing.md) | ✅ | ✅ | ✅ |
| [**Load Based Planner**](/docs/architecture/load_planner.md) | 🚧 | 🚧 | 🚧 |
| [**SLA-Based Planner**](/docs/architecture/sla_planner.md) | ✅ | ✅ | ✅ |
| [**KVBM**](/docs/architecture/kvbm_architecture.md) | ✅ | 🚧 | ✅ |

To learn more about each framework and their capabilities, check out each framework&#039;s README!
- **[vLLM](components/backends/vllm/README.md)**
- **[SGLang](components/backends/sglang/README.md)**
- **[TensorRT-LLM](components/backends/trtllm/README.md)**

Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.

# Installation

The following examples require a few system level packages.
Recommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/support_matrix.md](docs/support_matrix.md)

## 1. Initial setup

The Dynamo team recommends the `uv` Python package manager, although any way works. Install uv:
```
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Install etcd and NATS (required)

To coordinate across a data center, Dynamo relies on etcd and NATS. To run Dynamo locally, these need to be available.

- [etcd](https://etcd.io/) can be run directly as `./etcd`.
- [nats](https://nats.io/) needs jetstream enabled: `nats-server -js`.

To quickly setup etcd &amp; NATS, you can also run:
```
# At the root of the repository:
# Edit deploy/docker-compose.yml to comment out &quot;runtime: nvidia&quot; of the dcgm-exporter service if the nvidia container runtime isn&#039;t deployed or to be used.
docker compose -f deploy/docker-compose.yml up -d
```

## 2. Select an engine

We publish Python wheels specialized for each of our supported engines: vllm, sglang, trtllm, and llama.cpp. The examples that follow use SGLang; continue reading for other engines.

```
uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install &quot;ai-dynamo[sglang]&quot;  #replace with [vllm], [trtllm], etc.
```

## 3. Run Dynamo

### Running an LLM API server

Dynamo provides a simple way to spin up a local set of inference components including:

- **OpenAI Compatible Frontend** – High performance OpenAI compatible http api server written in Rust.
- **Basic and Kv Aware Router** – Route and load balance traffic to a set of workers.
- **Workers** – Set of pre-configured LLM serving engines.

```
# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
python -m dynamo.frontend --http-port 8000 [--tls-cert-path cert.pem] [--tls-key-path key.pem]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
python -m dynamo.sglang.worker --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B --skip-tokenizer-init
```

#### Send a Request

```bash
curl localhost:8000/v1/chat/completions   -H &quot;Content-Type: application/json&quot;   -d &#039;{
    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,
    &quot;messages&quot;: [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello, how are you?&quot;
    }
    ],
    &quot;stream&quot;:false,
    &quot;max_tokens&quot;: 300
  }&#039; | jq
```

Rerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.

### Deploying Dynamo

- Follow the [Quickstart Guide](docs/kubernetes/README.md) to deploy on Kubernetes.
- Check out [Backends](components/backends) to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)
- Run some [Examples](examples) to learn about building components in Dynamo and exploring various integrations.

### Benchmarking Dynamo

Dynamo provides comprehensive benchmarking tools to evaluate and optimize your deployments:

* **[Benchmarking Guide](docs/benchmarks/benchmarking.md)** – Compare deployment topologies (aggregated vs. disaggregated vs. vanilla vLLM) using GenAI-Perf
* **[Pre-Deployment Profiling](docs/benchmarks/pre_deployment_profiling.md)** – Optimize configurations before deployment to meet SLA requirements

# Engines

Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (`python -m dynamo.frontend [--interactive]`).

## vLLM

```
uv pip install ai-dynamo[vllm]
```

Run the backend/worker like this:
```
python -m dynamo.vllm --help
```

vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass `--context-length &lt;value&gt;`.

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

## SGLang

```
# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
```

Run the backend/worker like this:
```
python -m dynamo.sglang.worker --help
```

You can pass any sglang flags directly to this worker, see https://docs.sglang.ai/advanced_features/server_arguments.html . See there to use multiple GPUs.

## TensorRT-LLM

It is recommended to use [NGC PyTorch Container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) for running the TensorRT-LLM engine.

&gt; [!Note]
&gt; Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using.
&gt; For example, if you are using `tensorrt-llm==1.1.0rc5`, use the PyTorch container image version `25.06`.
&gt; To find the correct PyTorch container version for your desired `tensorrt-llm` release, visit the [TensorRT-LLM Dockerfile.multi](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docker/Dockerfile.multi) on GitHub. Switch to the branch that matches your `tensorrt-llm` version, and look for the `BASE_TAG` line to identify the recommended PyTorch container tag.

&gt; [!Important]
&gt; Launch container with the following additional settings `--shm-size=1g --ulimit memlock=-1`

### Install prerequisites
```
# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install &quot;cuda-python&gt;=12,&lt;13&quot;

sudo apt-get -y install libopenmpi-dev
```

&gt; [!Tip]
&gt; You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation [here](https://nvidia.github.io/TensorRT-LLM/installation/linux.html).

### After installing the pre-requisites above, install Dynamo
```
uv pip install ai-dynamo[trtllm]
```

Run the backend/worker like this:
```
python -m dynamo.trtllm --help
```

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

# Developing Locally

## 1. Install libraries

**Ubuntu:**
```
sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
```

**macOS:**
- [Homebrew](https://brew.sh/)
```
# if brew is not installed on your system, install it
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
```
- [Xcode](https://developer.apple.com/xcode/)

```
brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
```
If Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.


## 2. Install Rust

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
```

## 3. Create a Python virtual env:

Follow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don&#039;t have `uv` installed. Once uv is installed, create a virtual environment and activate it.

- Install uv
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

- Create a virtual environment
```bash
uv venv dynamo
source dynamo/bin/activate
```

## 4. Install build tools

```
uv pip install pip maturin
```

[Maturin](https://github.com/PyO3/maturin) is the Rust&lt;-&gt;Python bindings build tool.

## 5. Build the Rust bindings

```
cd lib/bindings/python
maturin develop --uv
```

## 6. Install the wheel

```
cd $PROJECT_ROOT
uv pip install .
# For development, use
export PYTHONPATH=&quot;${PYTHONPATH}:$(pwd)/components/frontend/src:$(pwd)/components/planner/src:$(pwd)/components/backends/vllm/src:$(pwd)/components/backends/sglang/src:$(pwd)/components/backends/trtllm/src:$(pwd)/components/backends/llama_cpp/src:$(pwd)/components/backends/mocker/src&quot;
```

&gt; [!Note]
&gt; Editable (`-e`) does not work because the `dynamo` package is split over multiple directories, one per backend.

You should now be able to run `python -m dynamo.frontend`.

Remember that nats and etcd must be running (see earlier).

Set the environment variable `DYN_LOG` to adjust the logging level; for example, `export DYN_LOG=debug`. It has the same syntax as `RUST_LOG`.

If you use vscode or cursor, we have a .devcontainer folder built on [Microsofts Extension](https://code.visualstudio.com/docs/devcontainers/containers). For instructions see the [ReadMe](.devcontainer/README.md) for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/rust]]></title>
            <link>https://github.com/rust-lang/rust</link>
            <guid>https://github.com/rust-lang/rust</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[Empowering everyone to build reliable and efficient software.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/rust">rust-lang/rust</a></h1>
            <p>Empowering everyone to build reliable and efficient software.</p>
            <p>Language: Rust</p>
            <p>Stars: 106,782</p>
            <p>Forks: 13,784</p>
            <p>Stars today: 40 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-dark.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-light.svg&quot;&gt;
    &lt;img alt=&quot;The Rust Programming Language: A language empowering everyone to build reliable and efficient software&quot;
         src=&quot;https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-light.svg&quot;
         width=&quot;50%&quot;&gt;
  &lt;/picture&gt;

[Website][Rust] | [Getting started] | [Learn] | [Documentation] | [Contributing]
&lt;/div&gt;

This is the main source code repository for [Rust]. It contains the compiler,
standard library, and documentation.

[Rust]: https://www.rust-lang.org/
[Getting Started]: https://www.rust-lang.org/learn/get-started
[Learn]: https://www.rust-lang.org/learn
[Documentation]: https://www.rust-lang.org/learn#learn-use
[Contributing]: CONTRIBUTING.md

## Why Rust?

- **Performance:** Fast and memory-efficient, suitable for critical services, embedded devices, and easily integrated with other languages.

- **Reliability:** Our rich type system and ownership model ensure memory and thread safety, reducing bugs at compile-time.

- **Productivity:** Comprehensive documentation, a compiler committed to providing great diagnostics, and advanced tooling including package manager and build tool ([Cargo]), auto-formatter ([rustfmt]), linter ([Clippy]) and editor support ([rust-analyzer]).

[Cargo]: https://github.com/rust-lang/cargo
[rustfmt]: https://github.com/rust-lang/rustfmt
[Clippy]: https://github.com/rust-lang/rust-clippy
[rust-analyzer]: https://github.com/rust-lang/rust-analyzer

## Quick Start

Read [&quot;Installation&quot;] from [The Book].

[&quot;Installation&quot;]: https://doc.rust-lang.org/book/ch01-01-installation.html
[The Book]: https://doc.rust-lang.org/book/index.html

## Installing from Source

If you really want to install from source (though this is not recommended), see
[INSTALL.md](INSTALL.md).

## Getting Help

See https://www.rust-lang.org/community for a list of chat platforms and forums.

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md).

## License

Rust is primarily distributed under the terms of both the MIT license and the
Apache License (Version 2.0), with portions covered by various BSD-like
licenses.

See [LICENSE-APACHE](LICENSE-APACHE), [LICENSE-MIT](LICENSE-MIT), and
[COPYRIGHT](COPYRIGHT) for details.

## Trademark

[The Rust Foundation][rust-foundation] owns and protects the Rust and Cargo
trademarks and logos (the &quot;Rust Trademarks&quot;).

If you want to use these names or brands, please read the
[Rust language trademark policy][trademark-policy].

Third-party logos may be subject to third-party copyrights and trademarks. See
[Licenses][policies-licenses] for details.

[rust-foundation]: https://rustfoundation.org/
[trademark-policy]: https://rustfoundation.org/policy/rust-trademark-policy/
[policies-licenses]: https://www.rust-lang.org/policies/licenses
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BoundaryML/baml]]></title>
            <link>https://github.com/BoundaryML/baml</link>
            <guid>https://github.com/BoundaryML/baml</guid>
            <pubDate>Mon, 29 Sep 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[The AI framework that adds the engineering to prompt engineering (Python/TS/Ruby/Java/C#/Rust/Go compatible)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BoundaryML/baml">BoundaryML/baml</a></h1>
            <p>The AI framework that adds the engineering to prompt engineering (Python/TS/Ruby/Java/C#/Rust/Go compatible)</p>
            <p>Language: Rust</p>
            <p>Stars: 6,110</p>
            <p>Forks: 285</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://boundaryml.com?utm_source=github&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;fern/assets/baml-lamb-white.png&quot;&gt;
    &lt;img src=&quot;fern/assets/baml-lamb-white.png&quot; height=&quot;64&quot; id=&quot;top&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![BAML Version](https://img.shields.io/pypi/v/baml-py?color=006dad&amp;label=BAML%20Version)](https://pypi.org/project/baml-py/)

## BAML: Basically a Made-up Language
&lt;h4&gt;

[Homepage](https://www.boundaryml.com/) | [Docs](https://docs.boundaryml.com) | [BAML AI Chat](https://www.boundaryml.com/chat) | [Discord](https://discord.gg/BTNBeXGuaS)



&lt;/h4&gt;


&lt;/div&gt;

BAML is a simple prompting language for building reliable **AI workflows and agents**.

BAML makes prompt engineering easy by turning it into _schema engineering_ -- where you mostly focus on the models of your prompt -- to get more reliable outputs. 
You don&#039;t need to write your whole app in BAML, only the prompts! You can wire-up your LLM Functions in any language of your choice! See our quickstarts for [Python](https://docs.boundaryml.com/guide/installation-language/python), [TypeScript](https://docs.boundaryml.com/guide/installation-language/typescript), [Ruby](https://docs.boundaryml.com/guide/installation-language/ruby) and [Go, and more](https://docs.boundaryml.com/guide/installation-language/rest-api-other-languages).

BAML comes with all batteries included -- with full typesafety, streaming, retries, wide model support, even when they don&#039;t support native [tool-calling APIs](#enable-reliable-tool-calling-with-any-model-even-when-they-dont-support-it)

**Try BAML**: [Prompt Fiddle](https://www.promptfiddle.com) • [Interactive App Examples](https://baml-examples.vercel.app/)


## The core BAML principle: LLM Prompts are functions

The fundamental building block in BAML is a function. Every prompt is a function that takes in parameters and returns a type.

```rust
function ChatAgent(message: Message[], tone: &quot;happy&quot; | &quot;sad&quot;) -&gt; string
```

Every function additionally defines which models it uses and what its prompt is.

```rust
function ChatAgent(message: Message[], tone: &quot;happy&quot; | &quot;sad&quot;) -&gt; StopTool | ReplyTool {
    client &quot;openai/gpt-4o-mini&quot;

    prompt #&quot;
        Be a {{ tone }} bot.

        {{ ctx.output_format }}

        {% for m in message %}
        {{ _.role(m.role) }}
        {{ m.content }}
        {% endfor %}
    &quot;#
}

class Message {
    role string
    content string
}

class ReplyTool {
  response string
}

class StopTool {
  action &quot;stop&quot; @description(#&quot;
    when it might be a good time to end the conversation
  &quot;#)
}
```

## BAML Functions can be called from any language
Below we call the ChatAgent function we defined in BAML through Python. BAML&#039;s Rust compiler generates a &quot;baml_client&quot; to access and call them.

```python
from baml_client import b
from baml_client.types import Message, StopTool

messages = [Message(role=&quot;assistant&quot;, content=&quot;How can I help?&quot;)]

while True:
  print(messages[-1].content)
  user_reply = input()
  messages.append(Message(role=&quot;user&quot;, content=user_reply))
  tool = b.ChatAgent(messages, &quot;happy&quot;)
  if isinstance(tool, StopTool):
    print(&quot;Goodbye!&quot;)
    break
  else:
    messages.append(Message(role=&quot;assistant&quot;, content=tool.response))
```
You can write any kind of agent or workflow using chained BAML functions. An agent is a while loop that calls a Chat BAML Function with some state.

And if you need to stream, add a couple more lines:
```python
stream = b.stream.ChatAgent(messages, &quot;happy&quot;)
# partial is a Partial type with all Optional fields
for tool in stream:
    if isinstance(tool, StopTool):
      ...
    
final = stream.get_final_response()
```
And get fully type-safe outputs for each chunk in the stream.

## Test prompts 10x faster, right in your IDE
BAML comes with native tooling for VSCode (jetbrains + neovim coming soon). 

**Visualize full prompt (including any multi-modal assets), and the API request**. BAML gives you full transparency and control of the prompt.

![raw-curl](https://github.com/user-attachments/assets/c0b34db9-80cd-45a7-a356-6b5ab4a9c5b7)

**Using AI is all about iteration speed.**

If testing your pipeline takes 2 minutes, you can only test 10 ideas in 20 minutes.

If you reduce it to 5 seconds, you can test 240 ideas in the same amount of time.
![resume-attempt2-smaller2](https://github.com/user-attachments/assets/6fc6b8a6-ffed-4cfc-80b8-78bc8a3d66a6)

The playground also allows you to run tests in parallel -- for even faster iteration speeds 🚀.

No need to login to websites, and no need to manually define json schemas.

## Enable reliable tool-calling with any model
BAML works even when the models don&#039;t support native tool-calling APIs. We created the SAP (schema-aligned parsing) algorithm to support the flexible outputs LLMs can provide, like markdown within a JSON blob or chain-of-thought prior to answering. [Read more about SAP](https://www.boundaryml.com/blog/schema-aligned-parsing)

With BAML, your structured outputs work in Day-1 of a model release. No need to figure out whether a model supports parallel tool calls, or whether it supports recursive schemas, or `anyOf` or `oneOf` etc.

See it in action with: **[Deepseek-R1](https://www.boundaryml.com/blog/deepseek-r1-function-calling)** and [OpenAI O1](https://www.boundaryml.com/blog/openai-o1).



## Switch from 100s of models in a couple lines
```diff
function Extract() -&gt; Resume {
+  client openai/o3-mini
  prompt #&quot;
    ....
  &quot;#
}
```
[Retry policies](https://docs.boundaryml.com/ref/llm-client-strategies/retry-policy) • [fallbacks](https://docs.boundaryml.com/ref/llm-client-strategies/fallback) • [model rotations](https://docs.boundaryml.com/ref/llm-client-strategies/round-robin). All statically defined.
![Fallback Retry](https://www.boundaryml.com/blog/2025-01-24-ai-agents-need-a-new-syntax/06-fallback-retry.gif)
Want to do pick models at runtime? Check out the [Client Registry](https://docs.boundaryml.com/guide/baml-advanced/llm-client-registry).

We support: [OpenAI](https://docs.boundaryml.com/ref/llm-client-providers/open-ai) • [Anthropic](https://docs.boundaryml.com/ref/llm-client-providers/anthropic) • [Gemini](https://docs.boundaryml.com/ref/llm-client-providers/google-ai-gemini) • [Vertex](https://docs.boundaryml.com/ref/llm-client-providers/google-vertex) • [Bedrock](https://docs.boundaryml.com/ref/llm-client-providers/aws-bedrock) • [Azure OpenAI](https://docs.boundaryml.com/ref/llm-client-providers/open-ai-from-azure) • [Anything OpenAI Compatible](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic) ([Ollama](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-ollama), [OpenRouter](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-open-router), [VLLM](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-v-llm), [LMStudio](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-lm-studio), [TogetherAI](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-together-ai), and more)

## Build beautiful streaming UIs
BAML generates a ton of utilities for NextJS, Python (and any language) to make streaming UIs easy.
![recipe-generator](https://github.com/user-attachments/assets/cf82495b-21fc-40bf-ae98-93eef923d620)

BAML&#039;s streaming interfaces are fully type-safe. Check out the [Streaming Docs](https://docs.boundaryml.com/guide/baml-basics/streaming), and our [React hooks](https://docs.boundaryml.com/guide/framework-integration/react-next-js/quick-start)

## Fully Open-Source, and offline
- 100% open-source (Apache 2)
- 100% private. AGI will not require an internet connection, neither will BAML
    - No network requests beyond model calls you explicitly set
    - Not stored or used for any training data
- BAML files can be saved locally on your machine and checked into Github for easy diffs.
- Built in Rust. So fast, you can&#039;t even tell it&#039;s there.

## BAML&#039;s Design Philosophy

Everything is fair game when making new syntax. If you can code it, it can be yours. This is our design philosophy to help restrict ideas:

- **1:** Avoid invention when possible
    - Yes, prompts need versioning — we have a great versioning tool: git
    - Yes, you need to save prompts — we have a great storage tool: filesystems
- **2:** Any file editor and any terminal should be enough to use it
- **3:** Be fast
- **4:** A first year university student should be able to understand it

## Why a new programming language

We used to write websites like this:

```python
def home():
    return &quot;&lt;button onclick=\&quot;() =&gt; alert(\\\&quot;hello!\\\&quot;)\&quot;&gt;Click&lt;/button&gt;&quot;
```

And now we do this:

```jsx
function Home() {
  return &lt;button onClick={() =&gt; setCount(prev =&gt; prev + 1)}&gt;
          {count} clicks!
         &lt;/button&gt;
}
```

New syntax can be incredible at expressing new ideas. Plus the idea of maintaining hundreds of f-strings for prompts kind of disgusts us 🤮. Strings are bad for maintainable codebases. We prefer structured strings.

The goal of BAML is to give you the expressiveness of English, but the structure of code.

Full [blog post](https://www.boundaryml.com/blog/ai-agents-need-new-syntax) by us.


## Conclusion

As models get better, we&#039;ll continue expecting even more out of them. But what will never change is that we&#039;ll want a way to write maintainable code that uses those models. The current way we all just assemble strings is very reminiscent of the early days PHP/HTML soup in web development. We hope some of the ideas we shared today can make a tiny dent in helping us all shape the way we all code tomorrow.

## FAQ
|   |   |
| - | - |
| Do I need to write my whole app in BAML? | Nope, only the prompts! BAML translates definitions into the language of your choice! [Python](https://docs.boundaryml.com/guide/installation-language/python), [TypeScript](https://docs.boundaryml.com/guide/installation-language/typescript), [Ruby](https://docs.boundaryml.com/guide/installation-language/ruby) and [more](https://docs.boundaryml.com/guide/installation-language/rest-api-other-languages). |
| Is BAML stable? | Yes, many companies use it in production! We ship updates weekly! |
| Why a new language? | [Jump to section](#why-a-new-programming-language) |


## Contributing
Checkout our [guide on getting started](/CONTRIBUTING.md)

## Citation

You can cite the BAML repo as follows:
```bibtex
@software{baml,
  author = {Boundary ML},
  title = {BAML},
  url = {https://github.com/boundaryml/baml},
  year = {2024}
}
```

---

Made with ❤️ by Boundary

HQ in Seattle, WA

P.S. We&#039;re hiring for software engineers that love rust. [Email us](mailto:founders@boundaryml.com) or reach out on [discord](https://discord.gg/ENtBB6kkXH)!

&lt;div align=&quot;left&quot; style=&quot;align-items: left;&quot;&gt;
        &lt;a href=&quot;#top&quot;&gt;
            &lt;img src=&quot;https://img.shields.io/badge/Back%20to%20Top-000000?style=for-the-badge&amp;logo=github&amp;logoColor=white&quot; alt=&quot;Back to Top&quot;&gt;
        &lt;/a&gt;
&lt;/div&gt;

&lt;img src=&quot;https://imgs.xkcd.com/comics/standards.png&quot; alt_text=&quot;hi&quot; /&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>