<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Fri, 13 Feb 2026 00:09:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[EasyTier/EasyTier]]></title>
            <link>https://github.com/EasyTier/EasyTier</link>
            <guid>https://github.com/EasyTier/EasyTier</guid>
            <pubDate>Fri, 13 Feb 2026 00:09:06 GMT</pubDate>
            <description><![CDATA[A simple, decentralized mesh VPN with WireGuard support.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EasyTier/EasyTier">EasyTier/EasyTier</a></h1>
            <p>A simple, decentralized mesh VPN with WireGuard support.</p>
            <p>Language: Rust</p>
            <p>Stars: 9,936</p>
            <p>Forks: 937</p>
            <p>Stars today: 89 stars today</p>
            <h2>README</h2><pre># EasyTier

[![Github release](https://img.shields.io/github/v/tag/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/releases)
[![GitHub](https://img.shields.io/github/license/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/blob/main/LICENSE)
[![GitHub last commit](https://img.shields.io/github/last-commit/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/commits/main)
[![GitHub issues](https://img.shields.io/github/issues/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/issues)
[![GitHub Core Actions](https://github.com/EasyTier/EasyTier/actions/workflows/core.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/core.yml)
[![GitHub GUI Actions](https://github.com/EasyTier/EasyTier/actions/workflows/gui.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/gui.yml)
[![GitHub Test Actions](https://github.com/EasyTier/EasyTier/actions/workflows/test.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/test.yml)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/EasyTier/EasyTier)

[ÁÆÄ‰Ωì‰∏≠Êñá](/README_CN.md) | [English](/README.md)

&gt; ‚ú® A simple, secure, decentralized virtual private network solution powered by Rust and Tokio

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;assets/config-page.png&quot; width=&quot;300&quot; alt=&quot;config page&quot;&gt;
&lt;img src=&quot;assets/running-page.png&quot; width=&quot;300&quot; alt=&quot;running page&quot;&gt;
&lt;/p&gt;

üìö **[Full Documentation](https://easytier.cn/en/)** | üñ•Ô∏è **[Web Console](https://easytier.cn/web)** | üìù **[Download Releases](https://github.com/EasyTier/EasyTier/releases)** | üß© **[Third Party Tools](https://easytier.cn/en/guide/installation_gui.html#third-party-graphical-interfaces)** | ‚ù§Ô∏è **[Sponsor](#sponsor)**

## Features

### Core Features

- üîí **Decentralized**: Nodes are equal and independent, no centralized services required  
- üöÄ **Easy to Use**: Multiple operation methods via web, client, and command line  
- üåç **Cross-Platform**: Supports Win/MacOS/Linux/FreeBSD/Android and X86/ARM/MIPS architectures  
- üîê **Secure**: AES-GCM or WireGuard encryption, prevents man-in-the-middle attacks  

### Advanced Capabilities

- üîå **Efficient NAT Traversal**: Supports UDP and IPv6 traversal, works with NAT4-NAT4 networks  
- üåê **Subnet Proxy**: Nodes can share subnets for other nodes to access  
- üîÑ **Intelligent Routing**: Latency priority and automatic route selection for best network experience  
- ‚ö° **High Performance**: Zero-copy throughout the entire link, supports TCP/UDP/WSS/WG protocols  

### Network Optimization

- üìä **UDP Loss Resistance**: KCP/QUIC proxy optimizes latency and bandwidth in high packet loss environments  
- üîß **Web Management**: Easy configuration and monitoring through web interface  
- üõ†Ô∏è **Zero Config**: Simple deployment with statically linked executables  

## Quick Start

### üì• Installation

Choose the installation method that best suits your needs:

```bash
# 1. Download pre-built binary (Recommended, All platforms supported)
# Visit https://github.com/EasyTier/EasyTier/releases

# 2. Install via cargo (Latest development version)
cargo install --git https://github.com/EasyTier/EasyTier.git easytier

# 3. Install via Docker
# See https://easytier.cn/en/guide/installation.html#installation-methods

# 4. Linux Quick Install
wget -O- https://raw.githubusercontent.com/EasyTier/EasyTier/main/script/install.sh | sudo bash -s install

# 5. MacOS via Homebrew
brew tap brewforge/chinese
brew install --cask easytier-gui

# 6. OpenWrt Luci Web UI
# Visit https://github.com/EasyTier/luci-app-easytier

# 7. (Optional) Install shell completions:
easytier-core --gen-autocomplete fish &gt; ~/.config/fish/completions/easytier-core.fish
easytier-cli gen-autocomplete fish &gt; ~/.config/fish/completions/easytier-cli.fish

```

### üöÄ Basic Usage

#### Quick Networking with Shared Nodes

EasyTier supports quick networking using shared public nodes. When you don&#039;t have a public IP, you can use the free shared nodes provided by the EasyTier community. Nodes will automatically attempt NAT traversal and establish P2P connections. When P2P fails, data will be relayed through shared nodes.

When using shared nodes, each node entering the network needs to provide the same `--network-name` and `--network-secret` parameters as the unique identifier of the network.

Taking two nodes as an example (Please use more complex network name to avoid conflicts):

1. Run on Node A:

```bash
# Run with administrator privileges
sudo easytier-core -d --network-name abc --network-secret abc -p tcp://&lt;SharedNodeIP&gt;:11010
```

2. Run on Node B:

```bash
# Run with administrator privileges
sudo easytier-core -d --network-name abc --network-secret abc -p tcp://&lt;SharedNodeIP&gt;:11010
```

After successful execution, you can check the network status using `easytier-cli`:

```text
| ipv4         | hostname       | cost  | lat_ms | loss_rate | rx_bytes | tx_bytes | tunnel_proto | nat_type | id         | version         |
| ------------ | -------------- | ----- | ------ | --------- | -------- | -------- | ------------ | -------- | ---------- | --------------- |
| 10.126.126.1 | abc-1          | Local | *      | *         | *        | *        | udp          | FullCone | 439804259  | 2.5.0-70e69a38~ |
| 10.126.126.2 | abc-2          | p2p   | 3.452  | 0         | 17.33 kB | 20.42 kB | udp          | FullCone | 390879727  | 2.5.0-70e69a38~ |
|              | PublicServer_a | p2p   | 27.796 | 0.000     | 50.01 kB | 67.46 kB | tcp          | Unknown  | 3771642457 | 2.5.0-70e69a38~ |
```

You can test connectivity between nodes:

```bash
# Test connectivity
ping 10.126.126.1
ping 10.126.126.2
```

Note: If you cannot ping through, it may be that the firewall is blocking incoming traffic. Please turn off the firewall or add allow rules.

To improve availability, you can connect to multiple shared nodes simultaneously:

```bash
# Connect to multiple shared nodes
sudo easytier-core -d --network-name abc --network-secret abc -p tcp://&lt;SharedNodeIP1&gt;:11010 -p udp://&lt;SharedNodeIP2&gt;:11010
```

Once your network is set up successfully, you can easily configure it to start automatically on system boot. Refer to the [One-Click Register Service guide](https://easytier.cn/en/guide/network/oneclick-install-as-service.html) for step-by-step instructions on registering EasyTier as a system service.

#### Decentralized Networking

EasyTier is fundamentally decentralized, with no distinction between server and client. As long as one device can communicate with any node in the virtual network, it can join the virtual network. Here&#039;s how to set up a decentralized network:

1. Start First Node (Node A):

```bash
# Start the first node
sudo easytier-core -i 10.144.144.1
```

After startup, this node will listen on the following ports by default:
- TCP: 11010
- UDP: 11010
- WebSocket: 11011
- WebSocket SSL: 11012
- WireGuard: 11013

2. Connect Second Node (Node B):

```bash
# Connect to the first node using its public IP
sudo easytier-core -i 10.144.144.2 -p udp://FIRST_NODE_PUBLIC_IP:11010
```

3. Verify Connection:

```bash
# Test connectivity
ping 10.144.144.2

# View connected peers
easytier-cli peer

# View routing information
easytier-cli route

# View local node information
easytier-cli node
```

For more nodes to join the network, they can connect to any existing node in the network using the `-p` parameter:

```bash
# Connect to any existing node using its public IP
sudo easytier-core -i 10.144.144.3 -p udp://ANY_EXISTING_NODE_PUBLIC_IP:11010
```

### üîç Advanced Features

#### Subnet Proxy

Assuming the network topology is as follows, Node B wants to share its accessible subnet 10.1.1.0/24 with other nodes:

```mermaid
flowchart LR

subgraph Node A Public IP 22.1.1.1
nodea[EasyTier&lt;br/&gt;10.144.144.1]
end

subgraph Node B
nodeb[EasyTier&lt;br/&gt;10.144.144.2]
end

id1[[10.1.1.0/24]]

nodea &lt;--&gt; nodeb &lt;-.-&gt; id1
```

To share a subnet, add the `-n` parameter when starting EasyTier:

```bash
# Share subnet 10.1.1.0/24 with other nodes
sudo easytier-core -i 10.144.144.2 -n 10.1.1.0/24
```

Subnet proxy information will automatically sync to each node in the virtual network, and each node will automatically configure the corresponding route. You can verify the subnet proxy setup:

1. Check if the routing information has been synchronized (the proxy_cidrs column shows the proxied subnets):

```bash
# View routing information
easytier-cli route
```

![Routing Information](/assets/image-3.png)

2. Test if you can access nodes in the proxied subnet:

```bash
# Test connectivity to proxied subnet
ping 10.1.1.2
```

#### WireGuard Integration

EasyTier can act as a WireGuard server, allowing any device with a WireGuard client (including iOS and Android) to access the EasyTier network. Here&#039;s an example setup:

```mermaid
flowchart LR

ios[[iPhone&lt;br/&gt;WireGuard Installed]]

subgraph Node A Public IP 22.1.1.1
nodea[EasyTier&lt;br/&gt;10.144.144.1]
end

subgraph Node B
nodeb[EasyTier&lt;br/&gt;10.144.144.2]
end

id1[[10.1.1.0/24]]

ios &lt;-.-&gt; nodea &lt;--&gt; nodeb &lt;-.-&gt; id1
```

1. Start EasyTier with WireGuard portal enabled:

```bash
# Listen on 0.0.0.0:11013 and use 10.14.14.0/24 subnet for WireGuard clients
sudo easytier-core -i 10.144.144.1 --vpn-portal wg://0.0.0.0:11013/10.14.14.0/24
```

2. Get WireGuard client configuration:

```bash
# Get WireGuard client configuration
easytier-cli vpn-portal
```

3. In the output configuration:
   - Set `Interface.Address` to an available IP from the WireGuard subnet
   - Set `Peer.Endpoint` to the public IP/domain of your EasyTier node
   - Import the modified configuration into your WireGuard client

#### Self-Hosted Public Shared Node

You can run your own public shared node to help other nodes discover each other. A public shared node is just a regular EasyTier network (with same network name and secret) that other networks can connect to.

To run a public shared node:

```bash
# No need to specify IPv4 address for public shared nodes
sudo easytier-core --network-name mysharednode --network-secret mysharednode
```

## Related Projects

- [ZeroTier](https://www.zerotier.com/): A global virtual network for connecting devices.
- [TailScale](https://tailscale.com/): A VPN solution aimed at simplifying network configuration.

### Contact Us

- üí¨ **[Telegram Group](https://t.me/easytier)**
- üë• **[QQ Group]**
  - No.1 [949700262](https://qm.qq.com/q/wFoTUChqZW)
  - No.2 [837676408](https://qm.qq.com/q/4V33DrfgHe)
  - No.3 [957189589](https://qm.qq.com/q/YNyTQjwlai)

## License

EasyTier is released under the [LGPL-3.0](https://github.com/EasyTier/EasyTier/blob/main/LICENSE).

## Sponsor

CDN acceleration and security protection for this project are sponsored by Tencent EdgeOne.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://edgeone.ai/?from=github&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/edgeone.png&quot; width=&quot;200&quot; alt=&quot;EdgeOne Logo&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

Special thanks to [Langlang Cloud](https://langlangy.cn/?i26c5a5)  and [RainCloud](https://www.rainyun.com/NjM0NzQ1_) for sponsoring our public servers.

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://langlangy.cn/?i26c5a5&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;assets/langlang.png&quot; width=&quot;200&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://langlangy.cn/?i26c5a5&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;assets/raincloud.png&quot; width=&quot;200&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;


If you find EasyTier helpful, please consider sponsoring us. Software development and maintenance require a lot of time and effort, and your sponsorship will help us better maintain and improve EasyTier.

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;assets/wechat.png&quot; width=&quot;200&quot;&gt;
&lt;img src=&quot;assets/alipay.png&quot; width=&quot;200&quot;&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/rust-analyzer]]></title>
            <link>https://github.com/rust-lang/rust-analyzer</link>
            <guid>https://github.com/rust-lang/rust-analyzer</guid>
            <pubDate>Fri, 13 Feb 2026 00:09:05 GMT</pubDate>
            <description><![CDATA[A Rust compiler front-end for IDEs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/rust-analyzer">rust-lang/rust-analyzer</a></h1>
            <p>A Rust compiler front-end for IDEs</p>
            <p>Language: Rust</p>
            <p>Stars: 16,041</p>
            <p>Forks: 1,946</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img
    src=&quot;https://raw.githubusercontent.com/rust-lang/rust-analyzer/master/assets/logo-wide.svg&quot;
    alt=&quot;rust-analyzer logo&quot;&gt;
&lt;/p&gt;

rust-analyzer is a language server that provides IDE functionality for
writing Rust programs. You can use it with any editor that supports
the [Language Server
Protocol](https://microsoft.github.io/language-server-protocol/) (VS
Code, Vim, Emacs, Zed, etc).

rust-analyzer features include go-to-definition, find-all-references,
refactorings and code completion. rust-analyzer also supports
integrated formatting (with rustfmt) and integrated diagnostics (with
rustc and clippy).

Internally, rust-analyzer is structured as a set of libraries for
analyzing Rust code. See
[Architecture](https://rust-analyzer.github.io/book/contributing/architecture.html)
in the manual.

## Quick Start

https://rust-analyzer.github.io/book/installation.html

## Documentation

If you want to **contribute** to rust-analyzer check out the [CONTRIBUTING.md](./CONTRIBUTING.md) or
if you are just curious about how things work under the hood, see the
[Contributing](https://rust-analyzer.github.io/book/contributing) section of the manual.

If you want to **use** rust-analyzer&#039;s language server with your editor of
choice, check [the manual](https://rust-analyzer.github.io/book/).
It also contains some tips &amp; tricks to help you be more productive when using rust-analyzer.

## Security and Privacy

See the [security](https://rust-analyzer.github.io/book/security.html) and
[privacy](https://rust-analyzer.github.io/book/privacy.html) sections of the manual.

## Communication

For usage and troubleshooting requests, please use &quot;IDEs and Editors&quot; category of the Rust forum:

https://users.rust-lang.org/c/ide/14

For questions about development and implementation, join rust-analyzer working group on Zulip:

https://rust-lang.zulipchat.com/#narrow/stream/185405-t-compiler.2Frust-analyzer

## Quick Links

* Website: https://rust-analyzer.github.io/
* Metrics: https://rust-analyzer.github.io/metrics/
* API docs: https://rust-lang.github.io/rust-analyzer/ide/
* Changelog: https://rust-analyzer.github.io/thisweek

## License

rust-analyzer is primarily distributed under the terms of both the MIT
license and the Apache License (Version 2.0).

See [LICENSE-APACHE](LICENSE-APACHE) and [LICENSE-MIT](LICENSE-MIT) for details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[surrealdb/surrealdb]]></title>
            <link>https://github.com/surrealdb/surrealdb</link>
            <guid>https://github.com/surrealdb/surrealdb</guid>
            <pubDate>Fri, 13 Feb 2026 00:09:04 GMT</pubDate>
            <description><![CDATA[A scalable, distributed, collaborative, document-graph database, for the realtime web]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/surrealdb/surrealdb">surrealdb/surrealdb</a></h1>
            <p>A scalable, distributed, collaborative, document-graph database, for the realtime web</p>
            <p>Language: Rust</p>
            <p>Stars: 31,058</p>
            <p>Forks: 1,122</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://surrealdb.com#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;/img/white/hero.png&quot; alt=&quot;SurrealDB Hero&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://surrealdb.com#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;/img/black/hero.png&quot; alt=&quot;SurrealDB Hero&quot;&gt;
&lt;/a&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/surrealdb/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/surrealdb/surrealdb?color=ff00a0&amp;include_prereleases&amp;label=version&amp;sort=semver&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/surrealdb/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/built_with-Rust-dca282.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
	&lt;a href=&quot;https://github.com/surrealdb/surrealdb/actions&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/surrealdb/surrealdb/ci.yml?style=flat-square&amp;branch=main&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/surrealdb/license&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-BSL_1.1-00bfff.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://hub.docker.com/repository/docker/surrealdb/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/surrealdb/surrealdb?label=docker%20pulls&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://crates.io/crates/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/d/surrealdb?color=dca282&amp;label=rust&amp;style=flat-square&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://www.npmjs.com/package/surrealdb.js&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dt/surrealdb.js?color=f7df1e&amp;label=javascript&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
	&lt;a href=&quot;https://pypi.org/project/surrealdb/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pepy/dt/surrealdb?color=426c99&amp;label=python&amp;style=flat-square&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
	&lt;a href=&quot;https://www.nuget.org/packages/SurrealDb.Net&quot;&gt;&lt;img src=&quot;https://img.shields.io/nuget/dt/surrealdb.net?color=4c2dcc&amp;label=.NET&amp;style=flat-square&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
	&lt;a href=&quot;https://packagist.org/packages/surrealdb/surrealdb.php&quot;&gt;&lt;img src=&quot;https://img.shields.io/packagist/dt/surrealdb/surrealdb.php?color=4d588b&amp;label=php&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
	&lt;a href=&quot;https://hub.docker.com/repository/docker/surrealdb/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/surrealdb/surrealdb/total?color=8259dd&amp;label=github%20downloads&amp;style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://surrealdb.com/discord&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/902568124350599239?label=discord&amp;style=flat-square&amp;color=5a66f6&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://x.com/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/x-follow_us-222222.svg?style=flat-square&quot; alt=&quot;X&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://dev.to/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dev-join_us-86f7b7.svg?style=flat-square&quot; alt=&quot;Dev&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/surrealdb/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/linkedin-connect_with_us-0a66c2.svg?style=flat-square&quot; alt=&quot;LinkedIn&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://www.youtube.com/@surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/youtube-subscribe-fc1c1c.svg?style=flat-square&quot; alt=&quot;YouTube&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://surrealdb.com/blog&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/blog.svg&quot; alt=&quot;Blog&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
	&lt;a href=&quot;https://github.com/surrealdb/surrealdb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/github.svg&quot; alt=&quot;Github&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/surrealdb/&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/linkedin.svg&quot; alt=&quot;LinkedIn&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://x.com/surrealdb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/x.svg&quot; alt=&quot;X&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.youtube.com/@surrealdb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/youtube.svg&quot; alt=&quot;YouTube&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://dev.to/surrealdb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/dev.svg&quot; alt=&quot;Dev&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/discord&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/discord.svg&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://stackoverflow.com/questions/tagged/surrealdb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/stack-overflow.svg&quot; alt=&quot;Stack Overflow&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/whatissurreal.svg&quot;&gt;&amp;nbsp;&amp;nbsp;What is SurrealDB?&lt;/h2&gt;

SurrealDB is a multi-model database built in Rust designed to unify multiple data models into a single engine. SurrealDB combines document, graph, relational, time-series, geospatial and key-value data types with powerful search and retrieval functionalities (full-text, vector, hybrid) and real-time and event-driven capabilities, enabling developers to build powerful applications faster and more efficiently. SurrealDB can also be used as a backend-as-a-service given its support for end user authentication. Given that it‚Äôs a single Rust binary, SurrealDB can run embedded (in‚Äêapp), in the browser (via WebAssembly), in the edge, self-hosted as single backend node, or in a distributed cluster in the cloud.

SurrealDB is used for data-intensive systems such as applications requiring multiple data types, data layer for AI agents, knowledge graphs, real-time apps (e.g. recommendation engines, fraud detection systems) and embedded/edge systems. With SurrealDB, you can simplify your database and API infrastructure, reduce development time, and build secure, performant apps quickly and cost-effectively.

**Key features of SurrealDB include:**

- **Reduces development time**: SurrealDB simplifies your database and API stack by removing the need for most server-side components, allowing you to build secure, performant apps faster and cheaper.
- **Real-time collaborative API backend service:** SurrealDB functions as both a database and an API backend service, enabling real-time collaboration.
- **Support for multiple querying languages:** SurrealDB supports SQL querying from client devices, GraphQL, ACID transactions, WebSocket connections, structured and unstructured data, graph querying, full-text and vector indexing, and geospatial querying.
- **Granular access control**: SurrealDB provides row-level permissions-based access control, giving you the ability to manage data access with precision.

View the [features](https://surrealdb.com/features), the latest [releases](https://surrealdb.com/releases), and [documentation](https://surrealdb.com/docs).

&lt;img width=&quot;100%&quot; src=&quot;./img/interface.png&quot; alt=&quot;Surrealist&quot;&gt;

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/contents.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Contents&lt;/h2&gt;

- [Features](#features)
- [Documentation](#documentation)
- [Getting started](#getting-started)
	- [Server side code](#server-side-code)
	- [Client side apps](#client-side-apps)
- [SurrealDB Cloud](#surrealdb-cloud)
- [Installation](#installation)
	- [Install on macOS](#install-on-macos)
	- [Install on Linux](#install-on-linux)
	- [Install on Windows](#install-on-windows)
	- [Run using Docker](#run-using-docker)
- [Quick look](#quick-look)
- [Why SurrealDB](#why-surrealdb)
	- [Database, API, and permissions](#database-api-and-permissions)
	- [Tables, documents, and graph](#tables-documents-and-graph)
	- [Advanced inter-document relations](#advanced-inter-document-relations-and-analysis-no-joins-no-pain)
	- [Simple schema definition](#simple-schema-definition-for-frontend-and-backend-development)
	- [Connect directly from web-browsers](#connect-and-query-directly-from-web-browsers-and-client-devices)
	- [Multiple different query methods](#query-the-database-with-the-tools-you-want)
	- [Realtime live queries and data changes](#realtime-live-queries-and-data-changes-direct-to-application)
	- [Scale effortlessly for high-availability](#scale-effortlessly-to-hundreds-of-nodes-for-high-availability-and-scalability)
	- [Extend your database with JavaScript](#extend-your-database-with-javascript-functions)
	- [Designed to be embedded or in the cloud](#designed-to-be-embedded-or-to-run-distributed-in-the-cloud)
- [Community](#community)
- [Contributing](#contributing)
- [Security](#security)
- [License](#license)

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/features.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Features&lt;/h2&gt;

- [x] Database server, or embedded library
- [x] Multi-row, multi-table ACID transactions
- [x] Single-node, or highly-scalable distributed mode
- [x] Record links and directed typed graph connections
- [x] Store structured and unstructured data
- [x] Incrementally computed views for pre-computed advanced analytics
- [x] Realtime-API layer, and security permissions built in
- [x] Store and model data in any way with tables, documents, and graph
- [x] Simple schema definition for frontend and backend development
- [x] Connect and query directly from web-browsers and client devices
- [x] Use embedded JavaScript functions for custom advanced functionality

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/documentation.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Documentation&lt;/h2&gt;

For guidance on installation, development, deployment, and administration, take a look at the following resources:

- Documentation: https://surrealdb.com/docs
- SurrealDB University: https://surrealdb.com/learn
- Aeon&#039;s Surreal Renaissance (interactive book): https://surrealdb.com/learn/book

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/gettingstarted.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Getting started&lt;/h2&gt;

Getting started with SurrealDB is as easy as starting up the SurrealDB database server, choosing your platform, and integrating its SDK into your code. You can easily get started with your platform of choice by reading one of our tutorials.

**Server side code**

&lt;p&gt;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/rust&quot;&gt;&lt;img width=60 title=&quot;Rust&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/rust.svg&quot; /&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/javascript&quot;&gt;&lt;img width=60 title=&quot;JavaScript&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/javascript.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/sdk/javascript/engines/wasm&quot;&gt;&lt;img width=60 title=&quot;WebAssembly&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/webassembly.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/sdk/javascript/engines/node&quot;&gt;&lt;img width=60 title=&quot;Node.js&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/nodejs.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/javascript&quot;&gt;&lt;img width=60 title=&quot;Deno&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/deno.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
	&lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/python&quot;&gt;&lt;img width=60 title=&quot;Python&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/python.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/golang&quot;&gt;&lt;img width=60 title=&quot;Golang&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/golang.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/dotnet&quot;&gt;&lt;img width=60 title=&quot;.NET&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/dotnet.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/php&quot;&gt;&lt;img width=60 title=&quot;PHP&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/php.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/java&quot;&gt;&lt;img width=60 title=&quot;Java&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/java.svg&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

**Client side apps**

&lt;p&gt;
	&lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/javascript&quot;&gt;&lt;img width=60 title=&quot;JavaScript&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/javascript.svg&quot; /&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/sdk/javascript/engines/wasm&quot;&gt;&lt;img width=60 title=&quot;WebAssembly&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/webassembly.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/javascript&quot;&gt;&lt;img width=60 title=&quot;React&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/reactjs.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/javascript&quot;&gt;&lt;img width=60 title=&quot;Next.js&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/nextjs.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/ember&quot;&gt;&lt;img width=60 title=&quot;Ember.js&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/emberjs.svg&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;/img/cloud.svg?raw=true&quot;&gt;&amp;nbsp;&amp;nbsp;SurrealDB Cloud&lt;/h2&gt;

&lt;a href=&quot;https://surrealdb.com/cloud#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;/img/white/cloud.png&quot; alt=&quot;SurrealDB Cloud&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://surrealdb.com/cloud#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;/img/black/cloud.png&quot; alt=&quot;SurrealDB Cloud&quot;&gt;
&lt;/a&gt;

SurrealDB is available as a [managed cloud service](https://app.surrealdb.com/overview). Forget about infrastructure operations, monitoring, backups or capacity planning. [SurrealDB Cloud](https://surrealdb.com/cloud) allows you to focus on building great products using the power and flexibility of SurrealDB in just a few clicks. Grow from prototype to enterprise-scale. The SurrealDB Cloud scalable architecture allows your database to evolve as your application grows, ensuring you are always ahead of demand. However if you want to deploy SurrealDB yourself, keep reading below.

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/installation.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Installation&lt;/h2&gt;

SurrealDB is designed to be simple to install and simple to run - using just one command from your terminal. In addition to traditional installation, SurrealDB can be installed and run with HomeBrew, Docker, or using any other container orchestration tool such as Docker Compose, Docker Swarm, Rancher, or in Kubernetes.

&lt;h4&gt;&lt;a href=&quot;https://surrealdb.com/install&quot;&gt;&lt;img width=&quot;20&quot; src=&quot;./img/apple.svg&quot;&gt;&lt;/a&gt;&amp;nbsp;Install on macOS&lt;/h4&gt;

The quickest way to get going with SurrealDB on macOS is to use Homebrew. This will install both the command-line tools, and the SurrealDB server as a single executable. If you don&#039;t use Homebrew, follow the instructions for Linux below to install SurrealDB.

```bash
brew install surrealdb/tap/surreal
```

If you want to test a version with the latest features, published every night, install the `nightly` version:

```bash
brew install surrealdb/tap/surreal-nightly
```

&lt;h4&gt;&lt;a href=&quot;https://surrealdb.com/install&quot;&gt;&lt;img width=&quot;20&quot; src=&quot;./img/linux.svg&quot;&gt;&lt;/a&gt;&amp;nbsp;Install on Linux&lt;/h4&gt;

The easiest and preferred way to get going with SurrealDB on Unix operating systems is to install and use the SurrealDB command-line tool. Run the following command in your terminal and follow the on-screen instructions.

```bash
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://install.surrealdb.com | sh
```

If you want to run a beta release, before the next version is released, the `beta` version:

```bash
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://install.surrealdb.com | sh -s -- --beta
```

If you want to test a version with the latest features, published every night, install the `nightly` version:

```bash
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://install.surrealdb.com | sh -s -- --nightly
```

&lt;h4&gt;&lt;a href=&quot;https://surrealdb.com/install&quot;&gt;&lt;img width=&quot;20&quot; src=&quot;./img/windows.svg&quot;&gt;&lt;/a&gt;&amp;nbsp;Install on Windows&lt;/h4&gt;

The easiest and preferred way to get going with SurrealDB on Windows is to install and use the SurrealDB command-line tool. Run the following command in your terminal and follow the on-screen instructions.

```ps1
iwr https://windows.surrealdb.com -useb | iex
```

If you want to test a version with the latest features, published every night, install the `nightly` version:

```ps1
iex &quot;&amp; { $(irm https://windows.surrealdb.com) } -Nightly&quot;
```

&lt;h4&gt;&lt;a href=&quot;https://surrealdb.com/install&quot;&gt;&lt;img width=&quot;20&quot; src=&quot;./img/docker.svg&quot;&gt;&lt;/a&gt;&amp;nbsp;Run using Docker&lt;/h4&gt;

Docker can be used to manage and run SurrealDB database instances without the need to install any command-line tools. The SurrealDB docker container contains the full command-line tools for importing and exporting data from a running server, or for running a server itself.

```bash
docker run --rm --pull always --name surrealdb -p 8000:8000 surrealdb/surrealdb:latest start
```

For just getting started with a development server running in memory, you can pass the container a basic initialization to set the user and password as root and enable logging.

```bash
docker run --rm --pull always --name surrealdb -p 8000:8000 surrealdb/surrealdb:latest start --log info --user root --pass root memory
``` 

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/features.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Quick look&lt;/h2&gt;

With strongly-typed data types, data can be fully modelled right in the database.

```surrealql
UPDATE person SET
    waist = &lt;int&gt; &quot;34&quot;,
    height = &lt;float&gt; 201,
    score = &lt;decimal&gt; 0.3 + 0.3 + 0.3 + 0.1
;
```

Store dynamically computed fields which are calculated when retrieved.

```surrealql
DEFINE FIELD can_drive ON TABLE person COMPUTED time::now() &gt; birthday + 18y;
CREATE person SET birthday = d&quot;2007-06-22&quot;;
;
```

Easily work with unstructured or structured data, in schema-less or schema-full mode.

```surrealql
-- Create a schemafull table
DEFINE TABLE user SCHEMAFULL;

-- Specify fields on the user table
DEFINE FIELD name ON TABLE user TYPE object;
DEFINE FIELD name.first ON TABLE user TYPE string;
DEFINE FIELD name.last ON TABLE user TYPE string;
DEFINE FIELD email ON TABLE user TYPE string ASSERT string::is_email($value);

-- Add a unique index on the email field preventing duplicate values
DEFINE INDEX email ON TABLE user COLUMNS email UNIQUE;

-- Create a new event whenever a user changes their email address
DEFINE EVENT email ON TABLE user WHEN $before.email != $after.email THEN (
    CREATE event SET user = $value, time = time::now(), value = $after.email, action = &#039;email_changed&#039;
);
```

Connect records together with fully directed graph edge connections.

```surrealql
-- Add a graph edge between user:tobie and article:surreal
RELATE user:tobie-&gt;write-&gt;article:surreal
    SET time.written = time::now()
;

-- Add a graph edge between specific users and developers
LET $from = (SELECT users FROM company:surrealdb);
LET $devs = (SELECT * FROM user WHERE tags CONTAINS &#039;developer&#039;);
RELATE $from-&gt;like-&gt;$devs UNIQUE
    SET time.connected = time::now()
;
```

Query data flexibly with advanced expressions and graph queries.

```surrealql
-- Select a nested array, and filter based on an attribute
SELECT emails[WHERE active = true] FROM person;

-- Select all 1st, 2nd, and 3rd level people who this specific person record knows, or likes, as separate outputs
SELECT -&gt;knows-&gt;(? AS f1)-&gt;knows-&gt;(? AS f2)-&gt;(knows, likes AS e3 WHERE influencer = true)-&gt;(? AS f3) FROM person:tobie;

-- Select all person records (and their recipients), who have sent more than 5 emails
SELECT *, -&gt;sent-&gt;email-&gt;to-&gt;person FROM person WHERE count(-&gt;sent-&gt;email) &gt; 5;

-- Select other products purchased by people who purchased this laptop
SELECT &lt;-purchased&lt;-person-&gt;purchased-&gt;product FROM product:laptop;

-- Select products purchased by people in the last 3 weeks who have purchased the same products that we purchased
SELECT -&gt;purchased-&gt;product&lt;-purchased&lt;-person-&gt;(purchased WHERE created_at &gt; time::now() - 3w)-&gt;product FROM person:tobie;
```

Store GeoJSON geographical data types, including points, lines and polygons.

```surrealql
UPDATE city:london SET
    centre = (-0.118092, 51.509865),
    boundary = {
        type: &quot;Polygon&quot;,
        coordinates: [[
            [-0.38314819, 51.37692386], [0.1785278, 51.37692386],
            [0.1785278, 51.61460570], [-0.38314819, 51.61460570],
            [-0.38314819, 51.37692386]
        ]]
    }
;
```

Write custom embedded logic using JavaScript functions.

```surrealql
CREATE film SET
    ratings = [
        { rating: 6, user: user:bt8e39uh1ouhfm8ko8s0 },
        { rating: 8, user: user:bsilfhu88j04rgs0ga70 },
    ],
    featured = function() {
        return this.ratings.filter(r =&gt; {
            return r.rating &gt;= 7;
        }).map(r =&gt; {
            return { ...r, rating: r.rating * 10 };
        });
    }
;
```

Specify granular access 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[conaticus/FileExplorer]]></title>
            <link>https://github.com/conaticus/FileExplorer</link>
            <guid>https://github.com/conaticus/FileExplorer</guid>
            <pubDate>Fri, 13 Feb 2026 00:09:03 GMT</pubDate>
            <description><![CDATA[Fast file explorer written with Tauri and React.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/conaticus/FileExplorer">conaticus/FileExplorer</a></h1>
            <p>Fast file explorer written with Tauri and React.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,155</p>
            <p>Forks: 90</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# üöÄ Fast File Explorer

&lt;img src=&quot;./src-tauri/assets/images/original.png&quot; alt=&quot;Rust Logo&quot; width=&quot;100&quot;/&gt;
  
[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)

**A fast file explorer built with Rust and Tauri**

&lt;img src=&quot;assets/screenshot_ThisPC.png&quot; alt=&quot;Fast Search Feature&quot; width=&quot;1000px&quot;/&gt;

&lt;/div&gt;

## ‚ú® Features

- **üöÄ Blazing Fast Search**: Multiple search algorithms with ~15ms response time vs 3min 45sec for Windows Explorer
- **üîç Advanced Search Engine**: 
  - Fast fuzzy search with ART (Adaptive Radix Tree) implementation
  - LRU caching for optimal performance
  - Multiple search algorithms for different use cases
- **üìÅ Comprehensive File Operations**: Copy, move, delete, rename with robust error handling
- **üåê SFTP Support**: Full remote file system operations including browsing, uploading, and downloading
- **üîê Advanced Permissions**: File and directory permission management
- **üìä File Metadata**: Comprehensive metadata viewing and management
- **üî® File Hashing**: MD5, SHA2, and CRC32 hash generation for file integrity
- **üìÑ File Templates**: Template system for creating new files
- **üëÅÔ∏è File Preview**: Built-in preview system for various file types (spotlight-like)
- **üíæ Volume Operations**: Drive management and volume operations
- **‚öôÔ∏è Customizable Settings**: Extensive configuration options
- **üé® Modern UI**: React-based interface with context menus and responsive design

## üîç Current Status

Cross platform compatibility is given and it supports all common Linux distros, macOS, and Windows
which are supported by Tauri. If there is an interest in contributing feel free to join the
[discord channel](https://discord.com/invite/dnVJQtNXjr) from Connaticus or message me or my team.

## üèóÔ∏è Architecture

This is a Tauri-based application with a **Rust backend** and **React frontend**:

### Backend (Rust)
- **Search Engine**: Multiple algorithms with LRU caching
- **File System Operations**: Local and SFTP file operations
- **Command System**: Modular command handlers for different operations
- **Error Handling**: Centralized error management with standardized codes (401-500)
- **Feature Flags**: Extensive Cargo features for different build configurations

### Frontend (React)
- **Provider Pattern**: Hierarchical context providers for state management
- **Modern UI**: Component-based architecture with custom hooks
- **Responsive Design**: Adaptive layouts for different screen sizes

## Coming Soon

- Real-time file watching with caching service
- Search/caching progress indicators
- Enhanced terminal integration

# üõ†Ô∏è Installation

Our plan is to provide installers for the supported operating systems or common package installers.
Unfortunately we have serious Problems with Tauri and creating installers. There are some installers
for linux under `dist-builds`. In the future there will be ready to go packages for macOS, Linux and
Windows until then please refer to the compilation from source for your computer.

## Installation from source

### Prerequisites for installing from source

- [NodeJS](https://nodejs.org/) (stable version)
- [Rust](https://www.rust-lang.org/) (stable version)
- [Tauri CLI](https://tauri.app/v1/guides/getting-started/prerequisites/) (version &gt;2.4.0)
- [Cargo](https://doc.rust-lang.org/cargo/getting-started/installation.html) (comes with Rust)
- [Vite](https://vitejs.dev/guide/#scaffolding-your-first-vite-project) (comes with Tauri CLI)

Other required dependencies are installed automatically by the Tauri CLI. If they are not please
contact us.

### Install with compiling from source

Note that on macOS you need XCode installed with the build tools.

```bash
# Install Tauri CLI
cargo install tauri-cli # The version should be &gt;2.4.0 if not already installed

# Build for production
cargo tauri build
```

Go into the build directory and run the created binary. The binary is located in
`FileExplorer/src-tauri/target/release/bundle/`. The name of the binary is `file-explorer` or

### üêß Linux

Under Linux the given command generates an `.deb`, `.rpm`, `AppImage` in the
`FileExplorer/src-tauri/target/release/bundle` folder. Select the one which fits your distribution.
Either run the AppImage, Binary or install the `.deb` or `.rpm` package.

#### For the `AppImage`

```bash
#Make sure the image is runnable
chmod +x yourapp-x.y.z.AppImage
#Run the image. After that it should behaving like a native application
./yourapp-x.y.z.AppImage
```

Recommended is to use the binary created in `FileExplorer/src-tauri/target/release/src-tauri`. Give
it executable permissions and then run it from the terminal. You can also put it into your user
binaries folder, e.g. `~/bin`, and add it to your PATH variable.

### üçé macOS

```bash
# Install Tauri CLI
cargo install tauri-cli # The version should be &gt;2.4.0 if not already installed

# Build for production
cargo tauri build
```

Tauri creates an `.dmg` or `.app` bundle under the folder
`FileExplorer/src-tauri/target/release/bundle/macos/`. Recommended is to use the binary created in
`FileExplorer/src-tauri/target/release/src-tauri`. Give it executable permissions and then run it
from the terminal. You can also put it into your user binaries folder, e.g. `~/bin`, and add it to
your PATH variable.

### ü™ü Windows

This generates an installer for your system, which lays in
`FileExplorer/src-tauri/target/release/bundle/msi/`. There should be an `.exe` or `.msi` which is
called `file-explorer`. To install it you need to double click the file and install like any other
application. Then you can completely remove the `FileExplorer` folder.

### Development Setup

```bash
# Install Tauri CLI
cargo install tauri-cli # The version should be &gt;2.4.0

# Build for production
cargo tauri build

# Run the development server
cargo tauri dev
```

### Testing and Development Commands

The project uses feature flags for different configurations:

```bash
# Run all tests including long-running ones
cargo test --features full

# Run with benchmark features
cargo test --features benchmarks

# Enable all logging during tests
cargo test --features log-all
```

Available feature combinations:
- `full` - All features including long tests, benchmarks, and file opening
- `log-search` - Enable search progress and error logging
- `log-index` - Enable indexing progress and error logging

## üì∏ Images

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;assets/screenshot_details.png&quot; width=&quot;700px&quot;/&gt;

&lt;img src=&quot;assets/screenshot_overview.png&quot; width=&quot;700px&quot;/&gt;

&lt;img src=&quot;assets/screenshot_terminal.png&quot; width=&quot;700px&quot;/&gt;

&lt;img src=&quot;assets/screenshot_settings.png&quot; width=&quot;700px&quot;/&gt;
&lt;/div&gt;

## üìÑ History

The Explorer was started as a project from the youtuber
[Connaticus](https://www.youtube.com/@conaticus). He documented parts of his development journey
online in two Videos:
[I Made a FAST File Explorer](https://youtu.be/Z60f2g-COJY?si=PHWogkV1R_wD8dza) and
[How I RUINED My Rust Project](https://youtu.be/4wdAZQROc4A?si=9ksfN2TcxdDI41BD).

Lots of changes were made in the course of the InformatiCup from the year 2025. It is a competition
in Germany. The given task was to contribute to existing open source projects. The team members were
[Marco Brandt](https://github.com/CodeMarco05), [Daniel Schatz](https://github.com/xd1i0),
[Lauritz Wiebusch](https://github.com/wielauritz), [S√∂ren Panten](https://github.com/SPKonig). The
repo can be found under [FileExplorer](https://github.com/CodeMarco05/FileExplorer).

## ‚ö° Performance

This file explorer emphasizes extreme performance with benchmarks showing significant improvements
over native solutions (tested on 170,000 paths):

| Operation   | Fast File Explorer | Windows Explorer |
| ----------- |:------------------:| :--------------: |
| File search |       ~15ms        |   3min 45sec     |

### Technical Implementation
- **Multiple Search Algorithms**: Fast fuzzy search, ART (Adaptive Radix Tree)
- **LRU Caching**: Intelligent caching for search results
- **Rust Backend**: Memory-safe, zero-cost abstractions
- **Modular Architecture**: Command-based system with feature flags

## ‚öôÔ∏è Configuration

The application uses several configuration files:

- `src-tauri/config/settings.json` - Application settings
- `src-tauri/config/meta_data.json` - Metadata configuration  
- `src-tauri/tauri.conf.json` - Tauri application configuration
- `package.json` - Frontend dependencies and scripts

## ü§ù Contributing

Contributions are welcome! Before contributing, please read our
[contributing guidelines](CONTRIBUTING.md).

## üìù License

This project is licensed under the GNU General Public License v3.0 ‚Äì see the LICENSE file for
details.

## üì¨ Contact

Have questions or feedback? Open an issue on our GitHub repository!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[aptos-labs/aptos-core]]></title>
            <link>https://github.com/aptos-labs/aptos-core</link>
            <guid>https://github.com/aptos-labs/aptos-core</guid>
            <pubDate>Fri, 13 Feb 2026 00:09:02 GMT</pubDate>
            <description><![CDATA[Aptos is a layer 1 blockchain built to support the widespread use of blockchain through better technology and user experience.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aptos-labs/aptos-core">aptos-labs/aptos-core</a></h1>
            <p>Aptos is a layer 1 blockchain built to support the widespread use of blockchain through better technology and user experience.</p>
            <p>Language: Rust</p>
            <p>Stars: 6,433</p>
            <p>Forks: 3,884</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://aptos.dev&quot;&gt;
	&lt;img width=&quot;100%&quot; src=&quot;./.assets/aptos_banner.png&quot; alt=&quot;Aptos Banner&quot; /&gt;
&lt;/a&gt;

---

[![License](https://img.shields.io/badge/license-Apache-green.svg)](LICENSE)
[![Lint+Test](https://github.com/aptos-labs/aptos-core/actions/workflows/lint-test.yaml/badge.svg)](https://github.com/aptos-labs/aptos-core/actions/workflows/lint-test.yaml)
[![codecov](https://codecov.io/gh/aptos-labs/aptos-core/branch/main/graph/badge.svg?token=X01RKXSGDE)](https://codecov.io/gh/aptos-labs/aptos-core)
[![Discord chat](https://img.shields.io/discord/945856774056083548?style=flat-square)](https://discord.gg/aptosnetwork)

Aptos is a layer 1 blockchain bringing a paradigm shift to Web3 through better technology and user experience. Built with Move to create a home for developers building next-gen applications.

## Getting Started

* [Aptos Foundation](https://aptosfoundation.org/)
* [Aptos Developer Network](https://aptos.dev)
* [Guide - Integrate with the Aptos Blockchain](https://aptos.dev/guides/system-integrators-guide)
* [Tutorials](https://aptos.dev/tutorials)
* Follow us on [Twitter](https://twitter.com/Aptos).
* Join us on the [Aptos Discord](https://discord.gg/aptosnetwork).

## Contributing

You can learn more about contributing to the Aptos project by reading our [Contribution Guide](https://github.com/aptos-labs/aptos-core/blob/main/CONTRIBUTING.md) and by viewing our [Code of Conduct](https://github.com/aptos-labs/aptos-core/blob/main/CODE_OF_CONDUCT.md).

Aptos Core is licensed under [Innovation-Enabling Source Code License](https://github.com/aptos-labs/aptos-core/blob/main/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Fri, 13 Feb 2026 00:09:01 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 30,380</p>
            <p>Forks: 2,755</p>
            <p>Stars today: 84 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/goose-oss&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;&gt;
     &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.

[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)

# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)
- [Responsible AI-Assisted Coding Guide](https://github.com/block/goose/blob/main/HOWTOAI.md)
- [Governance](https://github.com/block/goose/blob/main/GOVERNANCE.md)
- [Custom Distributions](https://github.com/block/goose/blob/main/CUSTOM_DISTROS.md) - build your own goose distro with preconfigured providers, extensions, and branding

## Need Help?
- [Diagnostics &amp; Reporting](https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting)
- [Known Issues](https://block.github.io/goose/docs/troubleshooting/known-issues)

# a little goose humor ü¶¢

&gt; Why did the developer choose goose as their AI agent?
&gt; 
&gt; Because it always helps them &quot;migrate&quot; their code to production! üöÄ

# goose around with us  
- [Discord](https://discord.gg/goose-oss)
- [YouTube](https://www.youtube.com/@goose-oss)
- [LinkedIn](https://www.linkedin.com/company/goose-oss)
- [Twitter/X](https://x.com/goose_oss)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[matrix-construct/tuwunel]]></title>
            <link>https://github.com/matrix-construct/tuwunel</link>
            <guid>https://github.com/matrix-construct/tuwunel</guid>
            <pubDate>Fri, 13 Feb 2026 00:09:00 GMT</pubDate>
            <description><![CDATA[Official successor to conduwuit]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/matrix-construct/tuwunel">matrix-construct/tuwunel</a></h1>
            <p>Official successor to conduwuit</p>
            <p>Language: Rust</p>
            <p>Stars: 1,346</p>
            <p>Forks: 90</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre># Tuwunel&lt;sup&gt;üíï&lt;/sup&gt;

![GitHub License](https://img.shields.io/github/license/matrix-construct/tuwunel?style=flat%2Dsquare&amp;color=%238A2BE2)
![GitHub Created At](https://img.shields.io/github/created-at/matrix-construct/tuwunel?style=flat%2Dsquare&amp;color=%238A2BE2)
![GitHub Commit Activity](https://img.shields.io/github/commit-activity/m/matrix-construct/tuwunel?style=flat%2Dsquare&amp;link=https%3A%2F%2Fgithub.com%2Fmatrix-construct%2Ftuwunel%2Fpulse%2Fmonthly&amp;color=%238A2BE2)
![Docker Pulls](https://img.shields.io/docker/pulls/jevolk/tuwunel?style=flat%2Dsquare&amp;color=8A2BE2)
![GitHub Repo Stars](https://img.shields.io/github/stars/matrix-construct/tuwunel?style=flat%2Dsquare&amp;link=https%3A%2F%2Fgithub.com%2Fmatrix-construct%2Ftuwunel&amp;color=%238A2BE2)
[![CI/CD](https://github.com/matrix-construct/tuwunel/actions/workflows/main.yml/badge.svg?branch=main&amp;style=flat%2Dsquare)](https://github.com/matrix-construct/tuwunel/actions/workflows/main.yml)

&lt;!-- ANCHOR: catchphrase --&gt;

## High Performance Matrix Homeserver in Rust!

&lt;!-- ANCHOR_END: catchphrase --&gt;

&lt;!-- ANCHOR: body --&gt;

[![Documentation](https://img.shields.io/badge/documentation%2D_?color=%238A2BE2&amp;style=for-the-badge&amp;logo=mdBook&amp;logoColor=FFFFFF)](https://matrix-construct.github.io/tuwunel/)
[![Demo Server](https://img.shields.io/badge/demo%20server%2D_?color=%238A2BE2&amp;style=for-the-badge&amp;logo=Element&amp;logoColor=FFFFFF)](https://try.tuwunel.chat)
[![Support Chat](https://img.shields.io/matrix/tuwunel%3Amatrix.org.svg?color=098A09&amp;style=for-the-badge&amp;label=Support%20Chat&amp;labelColor=8A2BE2&amp;logo=Matrix)](https://matrix.to/#/#tuwunel:grin.hu)

Tuwunel is a featureful [Matrix](https://matrix.org/) homeserver you can use instead of Synapse
with your favorite [client](https://matrix.org/ecosystem/clients/),
[bridge](https://matrix.org/ecosystem/bridges/) or
[bot](https://matrix.org/ecosystem/integrations/). It is written entirely in Rust to be a scalable,
low-cost, enterprise-ready, community-driven alternative, fully implementing the
[Matrix Specification](https://spec.matrix.org/latest/) for all but the most niche uses.

This project is the official successor to [conduwuit](https://github.com/x86pup/conduwuit) after it
reached stability. Tuwunel is now used by many companies with a vested interest in its continued
development by full-time staff. It is primarily sponsored by the government of
Switzerland üá®üá≠ where it is currently deployed for citizens.

### Getting Started

- [GitHub Releases](https://github.com/matrix-construct/tuwunel/releases)
- [Sourcecode](https://github.com/matrix-construct/tuwunel/) `git clone https://github.com/matrix-construct/tuwunel.git`
- [DockerHub](https://hub.docker.com/r/jevolk/tuwunel) or `docker pull jevolk/tuwunel:latest`
- [GHCR](https://github.com/matrix-construct/tuwunel/pkgs/container/tuwunel) or `docker pull ghcr.io/matrix-construct/tuwunel:latest`
- Static binaries available as [releases](https://github.com/matrix-construct/tuwunel/releases) or [build artifacts](https://github.com/matrix-construct/tuwunel/actions?query=branch%3Amain).
- Deb and RPM packages available as [releases](https://github.com/matrix-construct/tuwunel/releases) or [build artifacts](https://github.com/matrix-construct/tuwunel/actions?query=branch%3Amain).
- Arch package available as [tuwunel](https://aur.archlinux.org/packages/tuwunel) or [tuwunel-git](https://aur.archlinux.org/packages/tuwunel-git).
- Nix package available as [`matrix-tuwunel`](https://search.nixos.org/packages?query=matrix-tuwunel) and NixOS module available as [`services.matrix-tuwunel`](https://search.nixos.org/options?query=services.matrix-tuwunel).
- Alpine package available as [tuwunel](https://pkgs.alpinelinux.org/package/edge/testing/x86_64/tuwunel).

**1.** [Configure](https://matrix-construct.github.io/tuwunel/configuration.html) by
copying and editing the `tuwunel-example.toml`. The `server_name` and `database_path` must be
configured. **Most users deploy via docker or a distribution package and should follow the
[appropriate guide](https://matrix-construct.github.io/tuwunel/deploying.html) instead.**
This is just a summary for the impatient. See the full
[documentation](https://matrix-construct.github.io/tuwunel/).

&gt; [!TIP]
&gt; Avoid using a sub-domain for your `server_name`. You can always delegate later with a [`.well-known`](https://github.com/spantaleev/matrix-docker-ansible-deploy/blob/master/docs/configuring-well-known.md)
&gt; file, but you can never change your `server_name`.

**2.** Setup TLS certificates. Most users enjoy the [Caddy](https://caddyserver.com/) reverse-proxy
which automates their certificate renewal. Advanced users can load their own TLS certificates
using the configuration and Tuwunel can be deployed without a reverse proxy. Example
`/etc/caddy/Caddyfile` configuration with [Element](https://github.com/element-hq/element-web/releases)
unzipped to `/var/www/element`:
```
tuwunel.me, tuwunel.me:8448 {
    reverse_proxy localhost:8008
}
web.tuwunel.me {
    root * /var/www/element/
    file_server
}
```
`caddy reload --config /etc/caddy/Caddyfile`

**3.** Start the server, connect your client and register your username. The first registration is
granted server admin.

&gt; [!TIP]
&gt; Configure a secret `registration_token` and set `allow_registration = true`

 ü§ó Did you find this and other documentation helpful? We would love to hear feedback about setting
 up Tuwunel.


### Migrating to Tuwunel

| Can I migrate from | |
|-----------------|-----------|
| conduwuit? | ‚úÖ Yes. This will be supported at a minimum for one year, but likely indefinitely. |
| Synapse? | ‚ùå Not yet, but this is planned and an important issue. Subscribe to [#2](https://github.com/matrix-construct/tuwunel/issues/2). |
| Conduit? | ‚ùå Not right now, but this is planned for the near future. Subscribe to [#41](https://github.com/matrix-construct/tuwunel/issues/41). |
| Any other fork of Conduit? | ‚ùå No. The migration must be explicitly listed in this table. |
&gt; [!CAUTION]
&gt; **Never switch between different forks of Conduit or you will corrupt your database.**
&gt; All derivatives of Conduit share the same linear database version without any awareness of other
&gt; forks. The database will permanently corrupt and we will not be able to help you.

#### Migrating from conduwuit

Migrating from conduwuit to Tuwunel _just works_. In technical parlance it is a &quot;binary swap.&quot;
All you have to do is update to the latest Tuwunel and change the path to the executable from
`conduwuit` to `tuwunel`.

Anything else named &quot;conduwuit&quot; is still recognized, this includes environment variables with prefixes
such as `CONDUWUIT_`. In fact, `CONDUIT_` is still recognized for our legacy users. You may have
noticed that various configs, yamls, services, users, and other items were renamed, but if you
were a conduwuit user we recommend against changing anything at all. This will keep things simple.
If you are not sure please ask. If you found out that something did in fact need to be changed
please open an issue immediately.


### Upgrading &amp; Downgrading Tuwunel

We strive to make moving between versions of Tuwunel safe and easy. Downgrading Tuwunel is always
safe but often prevented by a guard. An error will indicate the downgrade is not possible and a
newer version which does not error must be sought.

#### Branches

The main branch is always _reasonably safe_ to run. We understand the propensity for users to simply clone
the main branch to get up and running, and we&#039;re obliged to ensure it&#039;s always viable. Nevertheless, only
tagged releases are true releases.

#### Container Tracking

&gt; [!IMPORTANT]
&gt; **We strongly advise tracking the `:latest` tag when automatically updating.**

Tracking `:latest` gives us the necessary discretion to keep you on the appropriate stable version.
We discourage tracking the main branch unless frequent restarts are acceptable. Alternatively,
tracking the `:preview` tag provides the latest release-candidate becoming equivalent to `:latest`
after a release. Tracking the `:preview` tag is a worthy alternative to the main branch, with
turbulence limited to release-time.

### Getting Help &amp; Support

If you are opposed to using github, or if private discussion is required such as for security
disclosures, or for any other reason, I would be happy to receive your DM at
[@jason:tuwunel.me](https://matrix.to/#/@jason:tuwunel.me). This will not be bothering me as it would
be my pleasure to help you when possible. As an emergency contact you can send an email to
jasonzemos@gmail.com.

##### Tuwunel Fanclub

We have an unofficial community-run chat which is publicly accessible at
[#tuwunel:matrix.org](https://matrix.to/#/#tuwunel:matrix.org). The members, content, or moderation
decisions of this room are not in any way related or endorsed by this project or its sponsors,
and not all project staff will be present there. There will be at least some presence by staff to
offer assistance so long as the room remains in minimally good standing.


## Tuwunel&lt;sup&gt;üíï&lt;/sup&gt;

Tuwunel&#039;s theme is **empathy** in communication defined by the works of
[Edith Stein](https://plato.stanford.edu/entries/stein/). Empathy is the basis for how we approach
every message and our responsibility to the other in every conversation.

&lt;!-- ANCHOR_END: body --&gt;

&lt;!-- ANCHOR: footer --&gt;

&lt;!-- ANCHOR_END: footer --&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[dani-garcia/vaultwarden]]></title>
            <link>https://github.com/dani-garcia/vaultwarden</link>
            <guid>https://github.com/dani-garcia/vaultwarden</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:59 GMT</pubDate>
            <description><![CDATA[Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dani-garcia/vaultwarden">dani-garcia/vaultwarden</a></h1>
            <p>Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs</p>
            <p>Language: Rust</p>
            <p>Stars: 54,907</p>
            <p>Forks: 2,546</p>
            <p>Stars today: 64 stars today</p>
            <h2>README</h2><pre>![Vaultwarden Logo](./resources/vaultwarden-logo-auto.svg)

An alternative server implementation of the Bitwarden Client API, written in Rust and compatible with [official Bitwarden clients](https://bitwarden.com/download/) [[disclaimer](#disclaimer)], perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.

---

[![GitHub Release](https://img.shields.io/github/release/dani-garcia/vaultwarden.svg?style=for-the-badge&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/releases/latest)
[![ghcr.io Pulls](https://img.shields.io/badge/dynamic/json?style=for-the-badge&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;url=https%3A%2F%2Fipitio.github.io%2Fbackage%2Fdani-garcia%2Fvaultwarden%2Fvaultwarden.json&amp;query=%24.downloads&amp;label=ghcr.io%20pulls&amp;cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden)
[![Docker Pulls](https://img.shields.io/docker/pulls/vaultwarden/server.svg?style=for-the-badge&amp;logo=docker&amp;logoColor=fff&amp;color=005AA4&amp;label=docker.io%20pulls)](https://hub.docker.com/r/vaultwarden/server)
[![Quay.io](https://img.shields.io/badge/quay.io-download-005AA4?style=for-the-badge&amp;logo=redhat&amp;cacheSeconds=14400)](https://quay.io/repository/vaultwarden/server) &lt;br&gt;
[![Contributors](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)
[![Forks](https://img.shields.io/github/forks/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/network/members)
[![Stars](https://img.shields.io/github/stars/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/stargazers)
[![Issues Open](https://img.shields.io/github/issues/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues)
[![Issues Closed](https://img.shields.io/github/issues-closed/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues?q=is%3Aissue+is%3Aclosed)
[![AGPL-3.0 Licensed](https://img.shields.io/github/license/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=vaultwarden&amp;color=944000&amp;cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/blob/main/LICENSE.txt) &lt;br&gt;
[![Dependency Status](https://img.shields.io/badge/dynamic/xml?url=https%3A%2F%2Fdeps.rs%2Frepo%2Fgithub%2Fdani-garcia%2Fvaultwarden%2Fstatus.svg&amp;query=%2F*%5Blocal-name()%3D&#039;svg&#039;%5D%2F*%5Blocal-name()%3D&#039;g&#039;%5D%5B2%5D%2F*%5Blocal-name()%3D&#039;text&#039;%5D%5B4%5D&amp;style=flat-square&amp;logo=rust&amp;label=dependencies&amp;color=005AA4)](https://deps.rs/repo/github/dani-garcia/vaultwarden)
[![GHA Release](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/release.yml?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;label=Release%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/release.yml)
[![GHA Build](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/build.yml?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;label=Build%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/build.yml) &lt;br&gt;
[![Matrix Chat](https://img.shields.io/matrix/vaultwarden:matrix.org.svg?style=flat-square&amp;logo=matrix&amp;logoColor=fff&amp;color=953B00&amp;cacheSeconds=14400)](https://matrix.to/#/#vaultwarden:matrix.org)
[![GitHub Discussions](https://img.shields.io/github/discussions/dani-garcia/vaultwarden?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=953B00&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/discussions)
[![Discourse Discussions](https://img.shields.io/discourse/topics?server=https%3A%2F%2Fvaultwarden.discourse.group%2F&amp;style=flat-square&amp;logo=discourse&amp;color=953B00)](https://vaultwarden.discourse.group/)

&gt; [!IMPORTANT]
&gt; **When using this server, please report any bugs or suggestions directly to us (see [Get in touch](#get-in-touch)), regardless of whatever clients you are using (mobile, desktop, browser...). DO NOT use the official Bitwarden support channels.**

&lt;br&gt;

## Features

A nearly complete implementation of the Bitwarden Client API is provided, including:

 * [Personal Vault](https://bitwarden.com/help/managing-items/)
 * [Send](https://bitwarden.com/help/about-send/)
 * [Attachments](https://bitwarden.com/help/attachments/)
 * [Website icons](https://bitwarden.com/help/website-icons/)
 * [Personal API Key](https://bitwarden.com/help/personal-api-key/)
 * [Organizations](https://bitwarden.com/help/getting-started-organizations/)
   - [Collections](https://bitwarden.com/help/about-collections/),
     [Password Sharing](https://bitwarden.com/help/sharing/),
     [Member Roles](https://bitwarden.com/help/user-types-access-control/),
     [Groups](https://bitwarden.com/help/about-groups/),
     [Event Logs](https://bitwarden.com/help/event-logs/),
     [Admin Password Reset](https://bitwarden.com/help/admin-reset/),
     [Directory Connector](https://bitwarden.com/help/directory-sync/),
     [Policies](https://bitwarden.com/help/policies/)
 * [Multi/Two Factor Authentication](https://bitwarden.com/help/bitwarden-field-guide-two-step-login/)
   - [Authenticator](https://bitwarden.com/help/setup-two-step-login-authenticator/),
     [Email](https://bitwarden.com/help/setup-two-step-login-email/),
     [FIDO2 WebAuthn](https://bitwarden.com/help/setup-two-step-login-fido/),
     [YubiKey](https://bitwarden.com/help/setup-two-step-login-yubikey/),
     [Duo](https://bitwarden.com/help/setup-two-step-login-duo/)
 * [Emergency Access](https://bitwarden.com/help/emergency-access/)
 * [Vaultwarden Admin Backend](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-admin-page)
 * [Modified Web Vault client](https://github.com/dani-garcia/bw_web_builds) (Bundled within our containers)

&lt;br&gt;

## Usage

&gt; [!IMPORTANT]
&gt; The web-vault requires the use a secure context for the [Web Crypto API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API).
&gt; That means it will only work via `http://localhost:8000` (using the port from the example below) or if you [enable HTTPS](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-HTTPS).

The recommended way to install and use Vaultwarden is via our container images which are published to [ghcr.io](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden), [docker.io](https://hub.docker.com/r/vaultwarden/server) and [quay.io](https://quay.io/repository/vaultwarden/server).
See [which container image to use](https://github.com/dani-garcia/vaultwarden/wiki/Which-container-image-to-use) for an explanation of the provided tags.

There are also [community driven packages](https://github.com/dani-garcia/vaultwarden/wiki/Third-party-packages) which can be used, but those might be lagging behind the latest version or might deviate in the way Vaultwarden is configured, as described in our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).

Alternatively, you can also [build Vaultwarden](https://github.com/dani-garcia/vaultwarden/wiki/Building-binary) yourself.

While Vaultwarden is based upon the [Rocket web framework](https://rocket.rs) which has built-in support for TLS our recommendation would be that you setup a reverse proxy (see [proxy examples](https://github.com/dani-garcia/vaultwarden/wiki/Proxy-examples)).

&gt; [!TIP]
&gt;**For more detailed examples on how to install, use and configure Vaultwarden you can check our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).**

### Docker/Podman CLI

Pull the container image and mount a volume from the host for persistent storage.&lt;br&gt;
You can replace `docker` with `podman` if you prefer to use podman.

```shell
docker pull vaultwarden/server:latest
docker run --detach --name vaultwarden \
  --env DOMAIN=&quot;https://vw.domain.tld&quot; \
  --volume /vw-data/:/data/ \
  --restart unless-stopped \
  --publish 127.0.0.1:8000:80 \
  vaultwarden/server:latest
```

This will preserve any persistent data under `/vw-data/`, you can adapt the path to whatever suits you.

### Docker Compose

To use Docker compose you need to create a `compose.yaml` which will hold the configuration to run the Vaultwarden container.

```yaml
services:
  vaultwarden:
    image: vaultwarden/server:latest
    container_name: vaultwarden
    restart: unless-stopped
    environment:
      DOMAIN: &quot;https://vw.domain.tld&quot;
    volumes:
      - ./vw-data/:/data/
    ports:
      - 127.0.0.1:8000:80
```

&lt;br&gt;

## Get in touch

Have a question, suggestion or need help? Join our community on [Matrix](https://matrix.to/#/#vaultwarden:matrix.org), [GitHub Discussions](https://github.com/dani-garcia/vaultwarden/discussions) or [Discourse Forums](https://vaultwarden.discourse.group/).

Encountered a bug or crash? Please search our issue tracker and discussions to see if it&#039;s already been reported. If not, please [start a new discussion](https://github.com/dani-garcia/vaultwarden/discussions) or [create a new issue](https://github.com/dani-garcia/vaultwarden/issues/). Ensure you&#039;re using the latest version of Vaultwarden and there aren&#039;t any similar issues open or closed!

&lt;br&gt;

## Contributors

Thanks for your contribution to the project!

[![Contributors Count](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden?style=for-the-badge&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)&lt;br&gt;
[![Contributors Avatars](https://contributors-img.web.app/image?repo=dani-garcia/vaultwarden)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)

&lt;br&gt;

## Disclaimer

**This project is not associated with [Bitwarden](https://bitwarden.com/) or Bitwarden, Inc.**

However, one of the active maintainers for Vaultwarden is employed by Bitwarden and is allowed to contribute to the project on their own time. These contributions are independent of Bitwarden and are reviewed by other maintainers.

The maintainers work together to set the direction for the project, focusing on serving the self-hosting community, including individuals, families, and small organizations, while ensuring the project&#039;s sustainability.

**Please note:** We cannot be held liable for any data loss that may occur while using Vaultwarden. This includes passwords, attachments, and other information handled by the application. We highly recommend performing regular backups of your files and database. However, should you experience data loss, we encourage you to contact us immediately.

&lt;br&gt;

## Bitwarden_RS

This project was known as Bitwarden_RS and has been renamed to separate itself from the official Bitwarden server in the hopes of avoiding confusion and trademark/branding issues.&lt;br&gt;
Please see [#1642 - v1.21.0 release and project rename to Vaultwarden](https://github.com/dani-garcia/vaultwarden/discussions/1642) for more explanation.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[microsoft/DiskANN]]></title>
            <link>https://github.com/microsoft/DiskANN</link>
            <guid>https://github.com/microsoft/DiskANN</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:58 GMT</pubDate>
            <description><![CDATA[Graph-structured Indices for Scalable, Fast, Fresh and Filtered Approximate Nearest Neighbor Search]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/DiskANN">microsoft/DiskANN</a></h1>
            <p>Graph-structured Indices for Scalable, Fast, Fresh and Filtered Approximate Nearest Neighbor Search</p>
            <p>Language: Rust</p>
            <p>Stars: 1,693</p>
            <p>Forks: 380</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># DiskANN

[![DiskANN Main](https://github.com/microsoft/DiskANN/actions/workflows/push-test.yml/badge.svg?branch=main)](https://github.com/microsoft/DiskANN/actions/workflows/push-test.yml)
[![PyPI version](https://img.shields.io/pypi/v/diskannpy.svg)](https://pypi.org/project/diskannpy/)
[![Downloads shield](https://pepy.tech/badge/diskannpy)](https://pepy.tech/project/diskannpy)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

[![DiskANN Paper](https://img.shields.io/badge/Paper-NeurIPS%3A_DiskANN-blue)](https://papers.nips.cc/paper/9527-rand-nsg-fast-accurate-billion-point-nearest-neighbor-search-on-a-single-node.pdf)
[![DiskANN Paper](https://img.shields.io/badge/Paper-Arxiv%3A_Fresh--DiskANN-blue)](https://arxiv.org/abs/2105.09613)
[![DiskANN Paper](https://img.shields.io/badge/Paper-Filtered--DiskANN-blue)](https://harsha-simhadri.org/pubs/Filtered-DiskANN23.pdf)

&gt; [!IMPORTANT]
&gt; We are currently in the process of updating this repository with a new version of the code written in Rust.

DiskANN is a suite of scalable, accurate and cost-effective approximate nearest neighbor search algorithms for large-scale vector search that support real-time changes and simple filters.
This code is based on ideas from Microsoft&#039;s [DiskANN](https://aka.ms/AboutDiskANN).
The main branch now contains a rearchitected project written in Rust.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

See [guidelines](CONTRIBUTING.md) for contributing to this project.

## Legacy C++ Code

Older C++ code is retained on the `cpp_main` branch, but is not actively developed or maintained.
The legacy C++ code was forked off from [code for NSG](https://github.com/ZJULearning/nsg) algorithm.

If you use the C++ version in your software please cite the following:

```
@misc{diskann-github,
   author = {Simhadri, Harsha Vardhan and Krishnaswamy, Ravishankar and Srinivasa, Gopal and Subramanya, Suhas Jayaram and Antonijevic, Andrija and Pryce, Dax and Kaczynski, David and Williams, Shane and Gollapudi, Siddarth and Sivashankar, Varun and Karia, Neel and Singh, Aditi and Jaiswal, Shikhar and Mahapatro, Neelam and Adams, Philip and Tower, Bryan and Patel, Yash}},
   title = {{DiskANN: Graph-structured Indices for Scalable, Fast, Fresh and Filtered Approximate Nearest Neighbor Search}},
   url = {https://github.com/Microsoft/DiskANN},
   version = {0.6.1},
   year = {2023}
}
```

&gt; [!NOTE]
&gt; Trademarks: This project may contain trademarks or logos for projects, products, or services.
&gt; Authorized use of Microsoft trademarks or logos is subject to and must follow Microsoft‚Äôs Trademark &amp; Brand Guidelines.
&gt; Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
&gt; Any use of third-party trademarks or logos are subject to those third-party‚Äôs policies.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gitbutlerapp/gitbutler]]></title>
            <link>https://github.com/gitbutlerapp/gitbutler</link>
            <guid>https://github.com/gitbutlerapp/gitbutler</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:57 GMT</pubDate>
            <description><![CDATA[The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitbutlerapp/gitbutler">gitbutlerapp/gitbutler</a></h1>
            <p>The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte</p>
            <p>Language: Rust</p>
            <p>Stars: 19,251</p>
            <p>Forks: 834</p>
            <p>Stars today: 72 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  
  &lt;img align=&quot;center&quot; width=&quot;100px&quot; src=&quot;https://gitbutler-docs-images-public.s3.us-east-1.amazonaws.com/md-logo.png&quot; alt=&quot;GitButler logo&quot; /&gt;
  &lt;br /&gt;

  &lt;h1 align=&quot;center&quot;&gt;GitButler&lt;/h1&gt;
  
  &lt;p align=&quot;center&quot;&gt;
   &lt;b&gt;Git, &lt;i&gt;but&lt;/i&gt; better&lt;/b&gt;.
   &lt;br/&gt;
   GitButler is a modern Git-based version control interface with both a GUI and CLI built from the ground up for AI-powered workflows.
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://gitbutler.com&quot;&gt;Website&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://blog.gitbutler.com/&quot;&gt;Blog&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://docs.gitbutler.com/&quot;&gt;Docs&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://gitbutler.com/downloads&quot;&gt;Downloads&lt;/a&gt;
  &lt;/p&gt;

  &lt;br/&gt;

  &lt;img width=&quot;100%&quot; src=&quot;https://gitbutler-docs-images-public.s3.us-east-1.amazonaws.com/app-preview-light.png&quot; alt=&quot;GitButler desktop app preview&quot; /&gt;
  &lt;p align=&quot;center&quot;&gt;&lt;i&gt;Our beautiful GUI&lt;/i&gt;&lt;/p&gt;

  &lt;img width=&quot;100%&quot; src=&quot;https://gitbutler-docs-images-public.s3.us-east-1.amazonaws.com/cli-preview.png&quot; alt=&quot;GitButler CLI preview&quot; /&gt;
  &lt;p align=&quot;center&quot;&gt;&lt;i&gt;Our amazing &lt;code&gt;but&lt;/code&gt; CLI&lt;/i&gt;&lt;/p&gt;

  &lt;br/&gt;

[![TWEET][s1]][l1] [
![BLUESKY][s8]][l8] [![DISCORD][s2]][l2]

[![CI][s0]][l0] [![INSTA][s3]][l3] [![YOUTUBE][s5]][l5] [![DEEPWIKI][s7]][l7]

[s0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml/badge.svg
[l0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml
[s1]: https://img.shields.io/badge/Twitter-black?logo=x&amp;logoColor=white
[l1]: https://twitter.com/intent/follow?screen_name=gitbutler
[s2]: https://img.shields.io/discord/1060193121130000425?label=Discord&amp;color=5865F2
[l2]: https://discord.gg/MmFkmaJ42D
[s3]: https://img.shields.io/badge/Instagram-E4405F?logo=instagram&amp;logoColor=white
[l3]: https://www.instagram.com/gitbutler/
[s5]: https://img.shields.io/youtube/channel/subscribers/UCEwkZIHGqsTGYvX8wgD0LoQ
[l5]: https://www.youtube.com/@gitbutlerapp
[s7]: https://deepwiki.com/badge.svg
[l7]: https://deepwiki.com/gitbutlerapp/gitbutler
[s8]: https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&amp;logoColor=fff
[l8]: https://bsky.app/profile/gitbutler.com

&lt;/div&gt;

&lt;br/&gt;

GitButler is a powerful new Git-based version control system, designed from scratch to be simple, powerful and flexible. It is designed for ease of use and modern agentic workflows.

It features stacked branches, parallel branches, unlimited undo, easy commit mutations, forge integrations and more.

Works instantly in any existing Git repo as a friendlier and more powerful drop-in Git user interface replacement - for you and your agents.

## Main Features

Why use GitButler instead of vanilla Git? What a great question.

- **Stacked Branches** ([gui](https://docs.gitbutler.com/features/branch-management/stacked-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/branching-and-commiting#stacked-branches))
  - Effortlessly create branches stacked on other branches. Amend or edit any commit easily with automatic restacking.
- **Parallel Branches** ([gui](https://docs.gitbutler.com/features/branch-management/virtual-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/branching-and-commiting#parallel-branches))
  - Organize work on multiple branches simultaneously, rather than constantly switching branches.
- **Easy Commit Management** ([gui](https://docs.gitbutler.com/features/branch-management/commits), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/rubbing))
  - Uncommit, reword, amend, move, split and squash commits by dragging and dropping or simple CLI commands. Forget about `rebase -i`, you don&#039;t need it anymore.
- **Undo Timeline** ([gui](https://docs.gitbutler.com/features/timeline), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/operations-log))
  - Logs all operations and changes and allows you to easily undo or revert any operation.
- **First Class Conflicts** ([gui](https://docs.gitbutler.com/overview#conflicting-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/conflict-resolution))
  - Rebases always succeed. Commits can be marked as conflicted and resolved at any time, in any order.
- **Forge Integration** ([gui](https://docs.gitbutler.com/features/forge-integration/github-integration), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/forges))
  - Authenticate to GitHub or GitLab to easily open and update Pull Requests, list branches, get CI statuses and more. No other tools required.
- **AI Tooling** ([gui](https://docs.gitbutler.com/features/ai-integration/ai-overview), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/ai-stuff))
  - Use built-in AI handlers to help create commit messages, branch names, PR descriptions and more.
  - Easily install hooks or skills for all modern agent systems to level up their Git management.

## Tech

The GitButler desktop app is a [Tauri](https://tauri.app/)-based application. Its UI is written in [Svelte](https://svelte.dev/) using [TypeScript](https://www.typescriptlang.org) and its backend is written in [Rust](https://www.rust-lang.org/).

The `but` CLI is the same Rust backend engine with a Rust command line UI.

## Documentation

You can find our end user documentation at: &lt;https://docs.gitbutler.com&gt;

## Bugs and Feature Requests

If you have a bug or feature request, feel free to open an [issue](https://github.com/gitbutlerapp/gitbutler/issues/new),
or [join our Discord server](https://discord.gg/MmFkmaJ42D).

## License

The TLDR is that GitButler is under a [Fair Source](https://fair.io/) software license, meaning that you can use it, view the source, contribute, etc. You just can&#039;t build a competitor with it. It also becomes MIT after 2 years. So, MIT with an expiring non-compete clause.

## Contributing

So you want to help out? Please check out the [CONTRIBUTING.md](CONTRIBUTING.md)
document.

If you want to skip right to getting the code to actually compile, take a look
at the [DEVELOPMENT.md](DEVELOPMENT.md) file.

### Contributors

&lt;a href=&quot;https://github.com/gitbutlerapp/gitbutler/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=gitbutlerapp/gitbutler&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[Polymarket/rs-clob-client]]></title>
            <link>https://github.com/Polymarket/rs-clob-client</link>
            <guid>https://github.com/Polymarket/rs-clob-client</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:56 GMT</pubDate>
            <description><![CDATA[Polymarket Rust CLOB Client]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Polymarket/rs-clob-client">Polymarket/rs-clob-client</a></h1>
            <p>Polymarket Rust CLOB Client</p>
            <p>Language: Rust</p>
            <p>Stars: 504</p>
            <p>Forks: 134</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>![Polymarket](assets/logo.png)

# Polymarket Rust Client

[![Crates.io](https://img.shields.io/crates/v/polymarket-client-sdk.svg)](https://crates.io/crates/polymarket-client-sdk)
[![CI](https://github.com/Polymarket/rs-clob-client/actions/workflows/ci.yml/badge.svg)](https://github.com/Polymarket/rs-clob-client/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/Polymarket/rs-clob-client/graph/badge.svg?token=FW1BYWWFJ2)](https://codecov.io/gh/Polymarket/rs-clob-client)

An ergonomic Rust client for interacting with Polymarket services, primarily the Central Limit Order Book (CLOB).
This crate provides strongly typed request builders, authenticated endpoints, `alloy` support and more.

## Table of Contents

- [Overview](#overview)
- [Getting Started](#getting-started)
- [Feature Flags](#feature-flags)
- [Re-exported Types](#re-exported-types)
- [Examples](#examples)
  - [CLOB Client](#clob-client)
  - [WebSocket Streaming](#websocket-streaming)
  - [Optional APIs](#optional-apis)
- [Additional CLOB Capabilities](#additional-clob-capabilities)
- [Setting Token Allowances](#token-allowances)
- [Minimum Supported Rust Version (MSRV)](#minimum-supported-rust-version-msrv)
- [Contributing](#contributing)
- [About Polymarket](#about-polymarket)

## Overview

- **Typed CLOB requests** (orders, trades, markets, balances, and more)
- **Dual authentication flows**
    - Normal authenticated flow
    - [Builder](https://docs.polymarket.com/developers/builders/builder-intro) authentication flow
- **Type-level state machine**
    - Prevents using authenticated endpoints before authenticating
    - Compile-time enforcement of correct transitions
- **Signer support** via `alloy::signers::Signer`
    - Including remote signers, e.g. AWS KMS
- **Zero-cost abstractions** ‚Äî no dynamic dispatch in hot paths
- **Order builders** for easy construction &amp; signing
- **Full `serde` support**
- **Async-first design** with `reqwest`


## Getting started

Add the crate to your `Cargo.toml`:

```toml
[dependencies]
polymarket-client-sdk = &quot;0.3&quot;
```

or

```bash
cargo add polymarket-client-sdk
```

Then run any of the examples
```bash
cargo run --example unauthenticated
```

## Feature Flags

The crate is modular with optional features for different Polymarket APIs:

| Feature      | Description                                                                                                                                    |
|--------------|------------------------------------------------------------------------------------------------------------------------------------------------|
| `clob`       | Core CLOB client for order placement, market data, and authentication                                                                          |
| `tracing`    | Structured logging via [`tracing`](https://docs.rs/tracing) for HTTP requests, auth flows, and caching                                         |
| `ws`         | WebSocket client for real-time orderbook, price, and user event streaming                                                                      |
| `rtds`       | Real-time data streams for crypto prices (Binance, Chainlink) and comments                                                                     |
| `data`       | Data API client for positions, trades, leaderboards, and analytics                                                                             |
| `gamma`      | Gamma API client for market/event discovery, search, and metadata                                                                              |
| `bridge`     | Bridge API client for cross-chain deposits (EVM, Solana, Bitcoin)                                                                              |
| `rfq`        | RFQ API (within CLOB) for submitting and querying quotes                                                                                       |
| `heartbeats` | Clob feature that automatically sends heartbeat messages to the Polymarket server, if the client disconnects all open orders will be cancelled |
| `ctf`        | CTF API client to perform split/merge/redeem on binary and neg risk markets

Enable features in your `Cargo.toml`:

```toml
[dependencies]
polymarket-client-sdk = { version = &quot;0.3&quot;, features = [&quot;ws&quot;, &quot;data&quot;] }
```

## Re-exported Types

This SDK re-exports commonly used types from external crates so you don&#039;t need to add them to your `Cargo.toml`:

### From `types` module

```rust
use polymarket_client_sdk::types::{
    Address, ChainId, Signature, address,  // from alloy::primitives
    DateTime, NaiveDate, Utc,              // from chrono
    Decimal, dec,                          // from rust_decimal + rust_decimal_macros
};
```

### From `auth` module

```rust
use polymarket_client_sdk::auth::{
    LocalSigner, Signer,          // from alloy::signers (LocalSigner + trait)
    Uuid, ApiKey,                 // from uuid (ApiKey = Uuid)
    SecretString, ExposeSecret,   // from secrecy
    builder::Url,                 // from url (for remote builder config)
};
```

### From `error` module

```rust
use polymarket_client_sdk::error::{
    StatusCode, Method,           // from reqwest (for error inspection)
};
```

This allows you to work with the SDK without managing version compatibility for these common dependencies.

## Examples

See `examples/` for the complete set. Below are hand-picked examples for common use cases.

### CLOB Client

#### Unauthenticated client (read-only)
```rust,ignore
use polymarket_client_sdk::clob::Client;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let client = Client::default();

    let ok = client.ok().await?;
    println!(&quot;Ok: {ok}&quot;);

    Ok(())
}
```

#### Authenticated client

Set `POLYMARKET_PRIVATE_KEY` as an environment variable with your private key.

##### [EOA](https://www.binance.com/en/academy/glossary/externally-owned-account-eoa) wallets
If using MetaMask or hardware wallet, you must first set token allowances. See [Token Allowances](#token-allowances) section below.

```rust,ignore
use std::str::FromStr as _;

use alloy::signers::Signer as _;
use alloy::signers::local::LocalSigner;
use polymarket_client_sdk::{POLYGON, PRIVATE_KEY_VAR};
use polymarket_client_sdk::clob::{Client, Config};

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let private_key = std::env::var(PRIVATE_KEY_VAR).expect(&quot;Need a private key&quot;);
    let signer = LocalSigner::from_str(&amp;private_key)?.with_chain_id(Some(POLYGON));
    let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
        .authentication_builder(&amp;signer)
        .authenticate()
        .await?;

    let ok = client.ok().await?;
    println!(&quot;Ok: {ok}&quot;);

    let api_keys = client.api_keys().await?;
    println!(&quot;API keys: {api_keys:?}&quot;);

    Ok(())
}
```

##### Proxy/Safe wallets
For proxy/Safe wallets, the funder address is **automatically derived** using CREATE2 from your signer&#039;s EOA address:

```rust,ignore
let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
    .authentication_builder(&amp;signer)
    .signature_type(SignatureType::GnosisSafe)  // Funder auto-derived via CREATE2
    .authenticate()
    .await?;
```

The SDK computes the deterministic wallet address that Polymarket deploys for your EOA. This is the same address
shown on polymarket.com when you log in with a browser wallet.

If you need to override the derived address (e.g., for advanced use cases), you can explicitly provide it:

```rust,ignore
let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
    .authentication_builder(&amp;signer)
    .funder(address!(&quot;&lt;your-polymarket-wallet-address&gt;&quot;))
    .signature_type(SignatureType::GnosisSafe)
    .authenticate()
    .await?;
```

You can also derive these addresses manually:

```rust,ignore
use polymarket_client_sdk::{derive_safe_wallet, derive_proxy_wallet, POLYGON};

// For browser wallet users (GnosisSafe)
let safe_address = derive_safe_wallet(signer.address(), POLYGON);

// For Magic/email wallet users (Proxy)
let proxy_address = derive_proxy_wallet(signer.address(), POLYGON);
```

##### Funder Address
The **funder address** is the actual address that holds your funds on Polymarket. When using proxy wallets (email wallets
like Magic or browser extension wallets), the signing key differs from the address holding the funds. The SDK automatically
derives the correct funder address using CREATE2 when you specify `SignatureType::Proxy` or `SignatureType::GnosisSafe`.
You can override this with `.funder(address)` if needed.

##### Signature Types
The **signature_type** parameter tells the system how to verify your signatures:
- `signature_type=0` (default): Standard EOA (Externally Owned Account) signatures - includes MetaMask, hardware wallets,
   and any wallet where you control the private key directly
- `signature_type=1`: Email/Magic wallet signatures (delegated signing)
- `signature_type=2`: Browser wallet proxy signatures (when using a proxy contract, not direct wallet connections)

See [SignatureType](src/clob/types/mod.rs#L182) for more information.

##### Place a market order

```rust,ignore
use std::str::FromStr as _;

use alloy::signers::Signer as _;
use alloy::signers::local::LocalSigner;
use polymarket_client_sdk::{POLYGON, PRIVATE_KEY_VAR};
use polymarket_client_sdk::clob::{Client, Config};
use polymarket_client_sdk::clob::types::{Amount, OrderType, Side};
use polymarket_client_sdk::types::Decimal;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let private_key = std::env::var(PRIVATE_KEY_VAR).expect(&quot;Need a private key&quot;);
    let signer = LocalSigner::from_str(&amp;private_key)?.with_chain_id(Some(POLYGON));
    let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
        .authentication_builder(&amp;signer)
        .authenticate()
        .await?;

    let order = client
        .market_order()
        .token_id(&quot;&lt;token-id&gt;&quot;)
        .amount(Amount::usdc(Decimal::ONE_HUNDRED)?)
        .side(Side::Buy)
        .order_type(OrderType::FOK)
        .build()
        .await?;
    let signed_order = client.sign(&amp;signer, order).await?;
    let response = client.post_order(signed_order).await?;
    println!(&quot;Order response: {:?}&quot;, response);

    Ok(())
}
```

##### Place a limit order

```rust,ignore
use std::str::FromStr as _;

use alloy::signers::Signer as _;
use alloy::signers::local::LocalSigner;
use polymarket_client_sdk::{POLYGON, PRIVATE_KEY_VAR};
use polymarket_client_sdk::clob::{Client, Config};
use polymarket_client_sdk::clob::types::Side;
use polymarket_client_sdk::types::Decimal;
use rust_decimal_macros::dec;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let private_key = std::env::var(PRIVATE_KEY_VAR).expect(&quot;Need a private key&quot;);
    let signer = LocalSigner::from_str(&amp;private_key)?.with_chain_id(Some(POLYGON));
    let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
        .authentication_builder(&amp;signer)
        .authenticate()
        .await?;

    let order = client
        .limit_order()
        .token_id(&quot;&lt;token-id&gt;&quot;)
        .size(Decimal::ONE_HUNDRED)
        .price(dec!(0.1))
        .side(Side::Buy)
        .build()
        .await?;
    let signed_order = client.sign(&amp;signer, order).await?;
    let response = client.post_order(signed_order).await?;
    println!(&quot;Order response: {:?}&quot;, response);

    Ok(())
}
```

#### Builder-authenticated client

For institutional/third-party app integrations with remote signing:
```rust,ignore
use std::str::FromStr as _;

use alloy::signers::Signer as _;
use alloy::signers::local::LocalSigner;
use polymarket_client_sdk::auth::builder::Config as BuilderConfig;
use polymarket_client_sdk::{POLYGON, PRIVATE_KEY_VAR};
use polymarket_client_sdk::clob::{Client, Config};
use polymarket_client_sdk::clob::types::SignatureType;
use polymarket_client_sdk::clob::types::request::TradesRequest;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let private_key = std::env::var(PRIVATE_KEY_VAR).expect(&quot;Need a private key&quot;);
    let signer = LocalSigner::from_str(&amp;private_key)?.with_chain_id(Some(POLYGON));
    let builder_config = BuilderConfig::remote(&quot;http://localhost:3000/sign&quot;, None)?; // Or your signing server

    let client = Client::new(&quot;https://clob.polymarket.com&quot;, Config::default())?
        .authentication_builder(&amp;signer)
        .signature_type(SignatureType::Proxy)  // Funder auto-derived via CREATE2
        .authenticate()
        .await?;

    let client = client.promote_to_builder(builder_config).await?;

    let ok = client.ok().await?;
    println!(&quot;Ok: {ok}&quot;);

    let api_keys = client.api_keys().await?;
    println!(&quot;API keys: {api_keys:?}&quot;);

    let builder_trades = client.builder_trades(&amp;TradesRequest::default(), None).await?;
    println!(&quot;Builder trades: {builder_trades:?}&quot;);

    Ok(())
}
```

### WebSocket Streaming

Real-time orderbook and user event streaming. Requires the `ws` feature.

```toml
polymarket-client-sdk = { version = &quot;0.3&quot;, features = [&quot;ws&quot;] }
```

```rust,ignore
use futures::StreamExt as _;
use polymarket_client_sdk::clob::ws::Client;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let client = Client::default();

    // Subscribe to orderbook updates for specific assets
    let asset_ids = vec![&quot;&lt;asset-id&gt;&quot;.to_owned()];
    let stream = client.subscribe_orderbook(asset_ids)?;
    let mut stream = Box::pin(stream);

    while let Some(book_result) = stream.next().await {
        let book = book_result?;
        println!(&quot;Orderbook update for {}: {} bids, {} asks&quot;,
            book.asset_id, book.bids.len(), book.asks.len());
    }
    Ok(())
}
```

Available streams:
- `subscribe_orderbook()` - Bid/ask levels for assets
- `subscribe_prices()` - Price change events
- `subscribe_midpoints()` - Calculated midpoint prices
- `subscribe_orders()` - User order updates (authenticated)
- `subscribe_trades()` - User trade executions (authenticated)

See [`examples/clob/ws/`](examples/clob/ws/) for more WebSocket examples including authenticated user streams.

### Optional APIs

#### Data API
Trading analytics, positions, and leaderboards. Requires the `data` feature.

```rust,ignore
use polymarket_client_sdk::data::Client;
use polymarket_client_sdk::data::types::request::PositionsRequest;
use polymarket_client_sdk::types::address;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let client = Client::default();
    let user = address!(&quot;0x0000000000000000000000000000000000000000&quot;); // Your address

    let request = PositionsRequest::builder().user(user).limit(10)?.build();
    let positions = client.positions(&amp;request).await?;
    println!(&quot;Open positions: {:?}&quot;, positions);
    Ok(())
}
```

See [`examples/data.rs`](examples/data.rs) for trades, leaderboards, activity, and more.

#### Gamma API
Market and event discovery. Requires the `gamma` feature.

```rust,ignore
use polymarket_client_sdk::gamma::Client;
use polymarket_client_sdk::gamma::types::request::{EventsRequest, SearchRequest};

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let client = Client::default();

    // Find active events
    let request = EventsRequest::builder().active(true).limit(5).build();
    let events = client.events(&amp;request).await?;
    println!(&quot;Found {} events&quot;, events.len());

    // Search for markets
    let search = SearchRequest::builder().q(&quot;bitcoin&quot;).build();
    let results = client.search(&amp;search).await?;
    println!(&quot;Search results: {:?}&quot;, results);
    Ok(())
}
```

See [`examples/gamma.rs`](examples/gamma/client.rs) for tags, series, comments, and sports endpoints.

#### Bridge API
Cross-chain deposits from EVM chains, Solana, and Bitcoin. Requires the `bridge` feature.

```rust,ignore
use polymarket_client_sdk::bridge::Client;
use polymarket_client_sdk::bridge::types::DepositRequest;
use polymarket_client_sdk::types::address;

#[tokio::main]
async fn main() -&gt; anyhow::Result&lt;()&gt; {
    let client = Client::default();

    // Get deposit addresses for your wallet
    let request = DepositRequest::builder()
        .address(address!(&quot;0x0000000000000000000000000000000000000000&quot;)) // Your address
        .build();
    let response = client.deposit(&amp;request).await?;

    println!(&quot;EVM: {}&quot;, response.address.evm);
    println!(&quot;Solana: {}&quot;, response.address.svm);
    println!(&quot;Bitcoin: {}&quot;, response.address.btc);
    Ok(())
}
```

See [`examples/bridge.rs`](examples/bridge.rs) for supported assets and minimum deposits.

## Additional CLOB Capabilities

Beyond basic order placement, the CLOB client supports:

- **Rewards &amp; Earnings** - Query maker rewards, daily earnings, and reward percentages
- **Streaming Pagination** - `stream_data()` for iterating through large result sets
- **Batch Operations** - `post_orders()` and `cancel_orders()` for multiple orders at once
- **Order Scoring** - Check if orders qualify for maker rewards
- **Notifications** - Manage trading notifications
- **Balance Management** - Query and refresh balance/allowance caches
- **Geoblock Detection** - Check if trading is available in your region

See [`examples/clob/authenticated.rs`](examples/clob/authenticated.rs) for comprehensive usage.

## Token Allowances

### Do I need to set allowances?
MetaMask and EOA users must set token allowances.
If you are using a proxy or [Safe](https://help.safe.global/en/articles/40869-what-is-safe)-type wallet, then you do not.

### What are allowances?
Think of allowances as permissions. Before Polymarket can move your funds to execute trades, you need to give the
exchange contracts permission to access your USDC and conditional tokens.

### Quick Setup
You need to approve two types of tokens:
1. **USDC** (for deposits and trading)
2. **Conditional Tokens** (the outcome tokens you trade)

Each needs approval for the exchange contracts to work properly.

### Setting Allowances
Use [examples/approvals.rs](examples/approvals.rs) to approve the right contracts. Run once to approve USDC. Then change
the `TOKEN_TO_APPROVE` and run for each conditional token.

**Pro tip**: You only need to set these once per wallet. After that, you can trade freely.

## Minimum Supported Rust Version (MSRV)

**MSRV: Rust [1.88](https://releases.rs/docs/1.88.0/)**

Older versions *may* compile, but are not supported.

This project aims to maintain compatibility with a Rust version that is at least six months old.

Version updates may occur more frequently than the policy guideline states if external forces require it. For example,
a CVE in a downstream dependency requiring an MSRV bump would be considered an acceptable reason to violate the six-month
guideline.


## Contributing
We encourage contributions from the community. Check out our [contributing guidelines](.github/CONTRIBUTING.md) for
instructions on how to contribute to this SDK.


## About Polymarket
[Polymarket](https://docs.polymarket.com/polymarket-learn/get-started/what-is-polymarket) is the world‚Äôs largest prediction market, allowing you to stay informed and profit from your knowledge by
betting on future events across various topics.
Studies show prediction markets are often more accurate than pundits because they combine news, polls, and expert
opinions into a single value that represents the market‚Äôs view of an event‚Äôs odds. Our markets reflect accurate, unbiased,
and real-time probabilities for the events that matter most to you. Markets seek truth.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[solana-foundation/anchor]]></title>
            <link>https://github.com/solana-foundation/anchor</link>
            <guid>https://github.com/solana-foundation/anchor</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:55 GMT</pubDate>
            <description><![CDATA[‚öì Solana Program Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/solana-foundation/anchor">solana-foundation/anchor</a></h1>
            <p>‚öì Solana Program Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 4,951</p>
            <p>Forks: 1,846</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img height=&quot;170x&quot; src=&quot;https://pbs.twimg.com/media/FVUVaO9XEAAulvK?format=png&amp;name=small&quot; /&gt;

  &lt;h1&gt;Anchor&lt;/h1&gt;

  &lt;p&gt;
    &lt;strong&gt;Solana Program Framework&lt;/strong&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;https://github.com/coral-xyz/anchor/actions&quot;&gt;&lt;img alt=&quot;Build Status&quot; src=&quot;https://github.com/coral-xyz/anchor/actions/workflows/tests.yaml/badge.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://anchor-lang.com&quot;&gt;&lt;img alt=&quot;Tutorials&quot; src=&quot;https://img.shields.io/badge/docs-tutorials-blueviolet&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/NHHGSXAnXk&quot;&gt;&lt;img alt=&quot;Discord Chat&quot; src=&quot;https://img.shields.io/discord/889577356681945098?color=blueviolet&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/github/license/coral-xyz/anchor?color=blueviolet&quot; /&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

[Anchor](https://www.anchor-lang.com/) is a framework providing several convenient developer tools for writing Solana programs (sometimes called &#039;smart contracts&#039;).

- Rust eDSL for writing Solana programs
- [IDL](https://en.wikipedia.org/wiki/Interface_description_language) specification
- TypeScript package for generating clients from IDL
- CLI and workspace management for developing complete applications

Anchor is the most popular framework for Solana programs.

&gt; [!NOTE]
&gt; If you&#039;re familiar with developing in Ethereum&#039;s [Solidity](https://docs.soliditylang.org/en/), [Truffle](https://www.trufflesuite.com/), [web3.js](https://github.com/ethereum/web3.js), then using Anchor will be familiar. Although the DSL syntax and semantics are targeted at Solana, the high level flow of writing RPC request handlers, emitting an IDL, and generating clients from IDL is the same.

## Getting Started

For a quickstart guide and in depth tutorials, see the [Anchor book](https://book.anchor-lang.com) and the [Anchor documentation](https://anchor-lang.com).

To jump straight to examples, go [here](https://github.com/coral-xyz/anchor/tree/master/examples). For the latest Rust and TypeScript API documentation, see [docs.rs](https://docs.rs/anchor-lang) and the [typedoc](https://www.anchor-lang.com/docs/clients/typescript).

## Packages

| Package                 | Description                                              | Version                                                                                                                          | Docs                                                                                                            |
| :---------------------- | :------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------- |
| `anchor-lang`           | Rust primitives for writing programs on Solana           | [![Crates.io](https://img.shields.io/crates/v/anchor-lang?color=blue)](https://crates.io/crates/anchor-lang)                     | [![Docs.rs](https://docs.rs/anchor-lang/badge.svg)](https://docs.rs/anchor-lang)                                |
| `anchor-spl`            | CPI clients for SPL programs on Solana                   | [![crates](https://img.shields.io/crates/v/anchor-spl?color=blue)](https://crates.io/crates/anchor-spl)                          | [![Docs.rs](https://docs.rs/anchor-spl/badge.svg)](https://docs.rs/anchor-spl)                                  |
| `anchor-client`         | Rust client for Anchor programs                          | [![crates](https://img.shields.io/crates/v/anchor-client?color=blue)](https://crates.io/crates/anchor-client)                    | [![Docs.rs](https://docs.rs/anchor-client/badge.svg)](https://docs.rs/anchor-client)                            |
| `@anchor-lang/core`     | TypeScript client for Anchor programs                    | [![npm](https://img.shields.io/npm/v/@anchor-lang/core.svg?color=blue)](https://www.npmjs.com/package/@anchor-lang/core)         | [![Docs](https://img.shields.io/badge/docs-typedoc-blue)](https://coral-xyz.github.io/anchor/ts/index.html)     |
| `@anchor-lang/cli` | CLI to support building and managing an Anchor workspace | [![npm](https://img.shields.io/npm/v/@anchor-lang/cli.svg?color=blue)](https://www.npmjs.com/package/@anchor-lang/core-cli) | [![Docs](https://img.shields.io/badge/docs-typedoc-blue)](https://www.anchor-lang.com/docs/references/cli) |

## Note

- **Anchor is in active development, so all APIs are subject to change.**
- **This code is unaudited. Use at your own risk.**

## Examples

Here&#039;s a counter program, where only the designated `authority`
can increment the count.

```rust
use anchor_lang::prelude::*;

declare_id!(&quot;Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS&quot;);

#[program]
mod counter {
    use super::*;

    pub fn initialize(ctx: Context&lt;Initialize&gt;, start: u64) -&gt; Result&lt;()&gt; {
        let counter = &amp;mut ctx.accounts.counter;
        counter.authority = *ctx.accounts.authority.key;
        counter.count = start;
        Ok(())
    }

    pub fn increment(ctx: Context&lt;Increment&gt;) -&gt; Result&lt;()&gt; {
        let counter = &amp;mut ctx.accounts.counter;
        counter.count += 1;
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Initialize&lt;&#039;info&gt; {
    #[account(init, payer = authority, space = 48)]
    pub counter: Account&lt;&#039;info, Counter&gt;,
    pub authority: Signer&lt;&#039;info&gt;,
    pub system_program: Program&lt;&#039;info, System&gt;,
}

#[derive(Accounts)]
pub struct Increment&lt;&#039;info&gt; {
    #[account(mut, has_one = authority)]
    pub counter: Account&lt;&#039;info, Counter&gt;,
    pub authority: Signer&lt;&#039;info&gt;,
}

#[account]
pub struct Counter {
    pub authority: Pubkey,
    pub count: u64,
}
```

For more, see the [examples](https://github.com/coral-xyz/anchor/tree/master/examples)
and [tests](https://github.com/coral-xyz/anchor/tree/master/tests) directories.

## License

Anchor is licensed under [Apache 2.0](./LICENSE).

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Anchor by you, as defined in the Apache-2.0 license, shall be
licensed as above, without any additional terms or conditions.

## Contribution

Thank you for your interest in contributing to Anchor!
Please see the [CONTRIBUTING.md](./CONTRIBUTING.md) to learn how.

### Thanks ‚ù§Ô∏è

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/coral-xyz/anchor/graphs/contributors&quot;&gt;
    &lt;img src=&quot;https://contrib.rocks/image?repo=coral-xyz/anchor&quot; width=&quot;100%&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[MystenLabs/sui]]></title>
            <link>https://github.com/MystenLabs/sui</link>
            <guid>https://github.com/MystenLabs/sui</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:54 GMT</pubDate>
            <description><![CDATA[Sui, a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the Move programming language]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/MystenLabs/sui">MystenLabs/sui</a></h1>
            <p>Sui, a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the Move programming language</p>
            <p>Language: Rust</p>
            <p>Stars: 7,608</p>
            <p>Forks: 11,717</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/MystenLabs/sui/refs/heads/main/docs/site/static/img/logo.svg&quot; alt=&quot;Logo&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;
&lt;/p&gt;

# Welcome to Sui

[![Github release](https://img.shields.io/github/v/release/MystenLabs/sui.svg?sort=semver)](https://github.com/MystenLabs/sui/releases/latest)
[![License](https://img.shields.io/github/license/MystenLabs/sui)](https://github.com/MystenLabs/sui/blob/main/LICENSE)

[Sui](https://sui.io) is a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the [Move programming language](https://github.com/MystenLabs/awesome-move).

## Sui Highlights

Sui offers the following benefits and capabilities:

 * Unmatched scalability, instant settlement
 * A safe smart contract language accessible to mainstream developers
 * Ability to define rich and composable on-chain assets
 * Better user experience for web3 apps

Sui is the only blockchain today that can scale with the growth of web3 while achieving industry-leading performance, cost, programmability, and usability. Sui demonstrates capacity beyond the transaction processing capabilities of established systems ‚Äì traditional and blockchain alike. Sui is the first internet-scale programmable blockchain platform, a foundational layer for web3.

## Sui Architecture

```mermaid
flowchart LR
    CC(CLI Client) --&gt; ClientService
    RC(Rest Client) --&gt; ClientService
    RPCC(RPC Client) --&gt; ClientService
    ClientService --&gt; AuthorityAggregator
    AuthorityAggregator --&gt; AC1[AuthorityClient] &amp; AC2[AuthorityClient]
    subgraph Authority1
      AS[AuthorityState]
    end
    subgraph Authority2
      AS2[AuthorityState]
    end
    AC1 &lt;==&gt;|Network TCP| Authority1
    AC2 &lt;==&gt;|Network TCP| Authority2
```

## Sui Overview

Sui is a smart contract platform maintained by a permissionless set of authorities that play a role similar to validators or miners in other blockchain systems.

Sui offers scalability and unprecedented low-latency for common use cases. Sui makes the vast majority of transactions processable in parallel, which makes better use of processing resources, and offers the option to increase throughput with more resources. Sui forgoes consensus to instead use simpler and lower-latency primitives for common use cases, such as payment transactions and asset transfers. This is unprecedented in the blockchain world and enables a number of new latency-sensitive distributed applications, ranging from gaming to retail payment at physical points of sale.

Sui is written in [Rust](https://www.rust-lang.org) and supports smart contracts written in the [Move programming language](https://github.com/move-language/move) to define assets that may have an owner. Move programs define operations on these assets including custom rules for their creation, the transfer of these assets to new owners, and operations that mutate assets.

Sui has a native token called SUI, with a fixed supply. The SUI token is used to pay for gas, and is also used as [delegated stake on authorities](https://learn.bybit.com/blockchain/delegated-proof-of-stake-dpos/) within an epoch. The voting power of authorities within this epoch is a function of this delegated stake. Authorities are periodically reconfigured according to the stake delegated to them. In any epoch, the set of authorities is [Byzantine fault tolerant](https://pmg.csail.mit.edu/papers/osdi99.pdf). At the end of the epoch, fees collected through all transactions processed are distributed to authorities according to their contribution to the operation of the system. Authorities can in turn share some of the fees as rewards to users that delegated stakes to them.

Sui is supported by several cutting-edge [peer-reviewed studies](https://github.com/MystenLabs/sui/blob/main/docs/content/concepts/research-papers.mdx) and extensive years of open-source development.

## More About Sui

Use the following links to learn more about Sui and the Sui ecosystem:

 * Learn more about working with Sui in the [Sui Documentation](https://docs.sui.io/).
 * Join the Sui community on [Sui Discord](https://discord.gg/sui).
 * Find out more about the Sui ecosystem on the [Sui Resources](https://sui.io/resources/) page.
 * Review information about Sui governance, [decentralization](https://suifoundation.org/decentralization), and [Developer Grants Program](https://sui.io/grants-hub) on the [Sui Foundation](https://sui.io/about) site.


 ## How to Contribute

 See the [Contributing Guide](CONTRIBUTING.md) for details on how to contribute to Sui.

 ## Code of Conduct

 See the [Code of Conduct](CODE_OF_CONDUCT.MD) for details on our code of conduct.

 ## License

 See the [LICENSE](LICENSE) file for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustdesk/rustdesk]]></title>
            <link>https://github.com/rustdesk/rustdesk</link>
            <guid>https://github.com/rustdesk/rustdesk</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:53 GMT</pubDate>
            <description><![CDATA[An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustdesk/rustdesk">rustdesk/rustdesk</a></h1>
            <p>An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.</p>
            <p>Language: Rust</p>
            <p>Stars: 107,384</p>
            <p>Forks: 15,967</p>
            <p>Stars today: 68 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;res/logo-header.svg&quot; alt=&quot;RustDesk - Your remote desktop&quot;&gt;&lt;br&gt;
  &lt;a href=&quot;#raw-steps-to-build&quot;&gt;Build&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#how-to-build-with-docker&quot;&gt;Docker&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#file-structure&quot;&gt;Structure&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#snapshot&quot;&gt;Snapshot&lt;/a&gt;&lt;br&gt;
  [&lt;a href=&quot;docs/README-UA.md&quot;&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href=&quot;docs/README-CS.md&quot;&gt;ƒçesky&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ZH.md&quot;&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href=&quot;docs/README-HU.md&quot;&gt;Magyar&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ES.md&quot;&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FA.md&quot;&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FR.md&quot;&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DE.md&quot;&gt;Deutsch&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PL.md&quot;&gt;Polski&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ID.md&quot;&gt;Indonesian&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FI.md&quot;&gt;Suomi&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ML.md&quot;&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href=&quot;docs/README-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NL.md&quot;&gt;Nederlands&lt;/a&gt;] | [&lt;a href=&quot;docs/README-IT.md&quot;&gt;Italiano&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PTBR.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href=&quot;docs/README-EO.md&quot;&gt;Esperanto&lt;/a&gt;] | [&lt;a href=&quot;docs/README-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href=&quot;docs/README-AR.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href=&quot;docs/README-VN.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DA.md&quot;&gt;Dansk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-GR.md&quot;&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href=&quot;docs/README-TR.md&quot;&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NO.md&quot;&gt;Norsk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RO.md&quot;&gt;Rom√¢nƒÉ&lt;/a&gt;]&lt;br&gt;
  &lt;b&gt;We need your help to translate this README, &lt;a href=&quot;https://github.com/rustdesk/rustdesk/tree/master/src/lang&quot;&gt;RustDesk UI&lt;/a&gt; and &lt;a href=&quot;https://github.com/rustdesk/doc.rustdesk.com&quot;&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt;
&lt;/p&gt;

&gt; [!Caution]
&gt; **Misuse Disclaimer:** &lt;br&gt;
&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.


Chat with us: [Discord](https://discord.gg/nDceKgxnkV) | [Twitter](https://twitter.com/rustdesk) | [Reddit](https://www.reddit.com/r/rustdesk) | [YouTube](https://www.youtube.com/@rustdesk)

[![RustDesk Server Pro](https://img.shields.io/badge/RustDesk%20Server%20Pro-Advanced%20Features-blue)](https://rustdesk.com/pricing.html)

Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, [set up your own](https://rustdesk.com/server), or [write your own rendezvous/relay server](https://github.com/rustdesk/rustdesk-server-demo).

![image](https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png)

RustDesk welcomes contribution from everyone. See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for help getting started.

[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)

[**BINARY DOWNLOAD**](https://github.com/rustdesk/rustdesk/releases)

[**NIGHTLY BUILD**](https://github.com/rustdesk/rustdesk/releases/tag/nightly)

[&lt;img src=&quot;https://f-droid.org/badge/get-it-on.png&quot;
    alt=&quot;Get it on F-Droid&quot;
    height=&quot;80&quot;&gt;](https://f-droid.org/en/packages/com.carriez.flutter_hbb)
[&lt;img src=&quot;https://flathub.org/api/badge?svg&amp;locale=en&quot;
    alt=&quot;Get it on Flathub&quot;
    height=&quot;80&quot;&gt;](https://flathub.org/apps/com.rustdesk.RustDesk)

## Dependencies

Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our [CI](https://github.com/rustdesk/rustdesk/blob/master/.github/workflows/flutter-build.yml) for building Flutter version.

Please download Sciter dynamic library yourself.

[Windows](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll) |
[Linux](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so) |
[macOS](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib)

## Raw Steps to build

- Prepare your Rust development env and C++ build env

- Install [vcpkg](https://github.com/microsoft/vcpkg), and set `VCPKG_ROOT` env variable correctly

  - Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static
  - Linux/macOS: vcpkg install libvpx libyuv opus aom

- run `cargo run`

## [Build](https://rustdesk.com/docs/en/dev/build/)

## How to Build on Linux

### Ubuntu 18 (Debian 10)

```sh
sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
```

### openSUSE Tumbleweed

```sh
sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
```

### Fedora 28 (CentOS 8)

```sh
sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
```

### Arch (Manjaro)

```sh
sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
```

### Install vcpkg

```sh
git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
```

### Fix libvpx (For Fedora)

```sh
cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i &#039;s/CFLAGS+=-I/CFLAGS+=-fPIC -I/g&#039; Makefile
sed -i &#039;s/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g&#039; Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
```

### Build

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
```

## How to build with Docker

Begin by cloning the repository and building the Docker container:

```sh
git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t &quot;rustdesk-builder&quot; .
```

Then, each time you need to build the application, run the following command:

```sh
docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=&quot;$(id -u)&quot; -e PGID=&quot;$(id -g)&quot; rustdesk-builder
```

Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the `&lt;OPTIONAL-ARGS&gt;` position. For instance, if you wanted to build an optimized release version, you would run the command above followed by `--release`. The resulting executable will be available in the target folder on your system, and can be run with:

```sh
target/debug/rustdesk
```

Or, if you&#039;re running a release executable:

```sh
target/release/rustdesk
```

Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as `install` or `run` are not currently supported via this method as they would install or run the program inside the container instead of the host.

## File Structure

- **[libs/hbb_common](https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common)**: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions
- **[libs/scrap](https://github.com/rustdesk/rustdesk/tree/master/libs/scrap)**: screen capture
- **[libs/enigo](https://github.com/rustdesk/rustdesk/tree/master/libs/enigo)**: platform specific keyboard/mouse control
- **[libs/clipboard](https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard)**: file copy and paste implementation for Windows, Linux, macOS.
- **[src/ui](https://github.com/rustdesk/rustdesk/tree/master/src/ui)**: obsolete Sciter UI (deprecated)
- **[src/server](https://github.com/rustdesk/rustdesk/tree/master/src/server)**: audio/clipboard/input/video services, and network connections
- **[src/client.rs](https://github.com/rustdesk/rustdesk/tree/master/src/client.rs)**: start a peer connection
- **[src/rendezvous_mediator.rs](https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs)**: Communicate with [rustdesk-server](https://github.com/rustdesk/rustdesk-server), wait for remote direct (TCP hole punching) or relayed connection
- **[src/platform](https://github.com/rustdesk/rustdesk/tree/master/src/platform)**: platform specific code
- **[flutter](https://github.com/rustdesk/rustdesk/tree/master/flutter)**: Flutter code for desktop and mobile
- **[flutter/web/js](https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js)**: JavaScript for Flutter web client

## Screenshots

![Connection Manager](https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651)

![Connected to a Windows PC](https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea)

![File Transfer](https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad)

![TCP Tunneling](https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ai-dynamo/dynamo]]></title>
            <link>https://github.com/ai-dynamo/dynamo</link>
            <guid>https://github.com/ai-dynamo/dynamo</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:52 GMT</pubDate>
            <description><![CDATA[A Datacenter Scale Distributed Inference Serving Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo</a></h1>
            <p>A Datacenter Scale Distributed Inference Serving Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 6,094</p>
            <p>Forks: 855</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: Copyright (c) 2024-2026 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

![Dynamo banner](./docs/assets/img/frontpage-banner.png)

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)
[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ) ![Community Contributors](https://img.shields.io/badge/community_contributors-70%2B-brightgreen)

| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/5506)** | **[Support Matrix](https://github.com/ai-dynamo/dynamo/blob/main/docs/pages/reference/support-matrix.md)** | **[Docs](https://docs.nvidia.com/dynamo/)** | **[Recipes](https://github.com/ai-dynamo/dynamo/tree/main/recipes)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Prebuilt Containers](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** | **[Blogs](https://developer.nvidia.com/blog/tag/nvidia-dynamo)**

# NVIDIA Dynamo

High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.

## Why Dynamo

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/assets/img/frontpage-gpu-vertical.png&quot; alt=&quot;Multi Node Multi-GPU topology&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Large language models exceed single-GPU capacity. Tensor parallelism spreads layers across GPUs but creates coordination challenges. Dynamo closes this orchestration gap.

Dynamo is inference engine agnostic (supports TRT-LLM, vLLM, SGLang) and provides:

- **Disaggregated Prefill &amp; Decode** ‚Äì Maximizes GPU throughput with latency/throughput trade-offs
- **Dynamic GPU Scheduling** ‚Äì Optimizes performance based on fluctuating demand
- **LLM-Aware Request Routing** ‚Äì Eliminates unnecessary KV cache re-computation
- **Accelerated Data Transfer** ‚Äì Reduces inference response time using NIXL
- **KV Cache Offloading** ‚Äì Leverages multiple memory hierarchies for higher throughput

Built in Rust for performance and Python for extensibility, Dynamo is fully open-source with an OSS-first development approach.

## Backend Feature Support

| | [SGLang](docs/pages/backends/sglang/README.md) | [TensorRT-LLM](docs/pages/backends/trtllm/README.md) | [vLLM](docs/pages/backends/vllm/README.md) |
|---|:----:|:----------:|:--:|
| **Best For** | High-throughput serving | Maximum performance | Broadest feature coverage |
| [**Disaggregated Serving**](docs/pages/design-docs/disagg-serving.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**KV-Aware Routing**](docs/pages/components/router/README.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**SLA-Based Planner**](docs/pages/components/planner/planner-guide.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**KVBM**](docs/pages/components/kvbm/README.md) | üöß | ‚úÖ | ‚úÖ |
| [**Multimodal**](docs/pages/features/multimodal/README.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**Tool Calling**](docs/pages/agents/tool-calling.md) | ‚úÖ | ‚úÖ | ‚úÖ |

&gt; **[Full Feature Matrix ‚Üí](docs/pages/reference/feature-matrix.md)** ‚Äî Detailed compatibility including LoRA, Request Migration, Speculative Decoding, and feature interactions.

## Dynamo Architecture

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/assets/img/frontpage-architecture.png&quot; alt=&quot;Dynamo architecture&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

&gt; **[Architecture Deep Dive ‚Üí](docs/pages/design-docs/architecture.md)**

## Latest News

- [12/05] [Moonshot AI&#039;s Kimi K2 achieves 10x inference speedup with Dynamo on GB200](https://quantumzeitgeist.com/kimi-k2-nvidia-ai-ai-breakthrough/)
- [12/02] [Mistral AI runs Mistral Large 3 with 10x faster inference using Dynamo](https://www.marktechpost.com/2025/12/02/nvidia-and-mistral-ai-bring-10x-faster-inference-for-the-mistral-3-family-on-gb200-nvl72-gpu-systems/)
- [12/01] [InfoQ: NVIDIA Dynamo simplifies Kubernetes deployment for LLM inference](https://www.infoq.com/news/2025/12/nvidia-dynamo-kubernetes/)

## Get Started

| Path | Use Case | Time | Requirements |
|------|----------|------|--------------|
| [**Local Quick Start**](#local-quick-start) | Test on a single machine | ~5 min | 1 GPU, Ubuntu 24.04 |
| [**Kubernetes Deployment**](#kubernetes-deployment) | Production multi-node clusters | ~30 min | K8s cluster with GPUs |
| [**Building from Source**](#building-from-source) | Contributors and development | ~15 min | Ubuntu, Rust, Python |

Want to help shape the future of distributed LLM inference? See the **[Contributing Guide](CONTRIBUTING.md)**.

# Local Quick Start

The following examples require a few system level packages.
Recommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/pages/reference/support-matrix.md](docs/pages/reference/support-matrix.md)

## Install Dynamo

### Option A: Containers (Recommended)

Containers have all dependencies pre-installed. No setup required.

```bash
# SGLang
docker run --gpus all --network host --rm -it nvcr.io/nvidia/ai-dynamo/sglang-runtime:0.8.1

# TensorRT-LLM
docker run --gpus all --network host --rm -it nvcr.io/nvidia/ai-dynamo/tensorrtllm-runtime:0.8.1

# vLLM
docker run --gpus all --network host --rm -it nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.8.1
```

&gt; **Tip:** To run frontend and worker in the same container, either run processes in background with `&amp;` (see below), or open a second terminal and use `docker exec -it &lt;container_id&gt; bash`.

See [Release Artifacts](docs/pages/reference/release-artifacts.md#container-images) for available versions.

### Option B: Install from PyPI

The Dynamo team recommends the `uv` Python package manager, although any way works.

```bash
# Install uv (recommended Python package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create virtual environment
uv venv venv
source venv/bin/activate
uv pip install pip
```

Install system dependencies and the Dynamo wheel for your chosen backend:

**SGLang**

```bash
sudo apt install python3-dev
uv pip install &quot;ai-dynamo[sglang]&quot;
```

&gt; **Note:** For CUDA 13 (B300/GB300), the container is recommended. See [SGLang install docs](https://docs.sglang.io/get_started/install.html) for details.

**TensorRT-LLM**

```bash
sudo apt install python3-dev
pip install torch==2.9.0 torchvision --index-url https://download.pytorch.org/whl/cu130
pip install --pre --extra-index-url https://pypi.nvidia.com &quot;ai-dynamo[trtllm]&quot;
```

&gt; **Note:** TensorRT-LLM requires `pip` due to a transitive Git URL dependency that `uv` doesn&#039;t resolve. We recommend using the [TensorRT-LLM container](docs/pages/reference/release-artifacts.md#container-images) for broader compatibility.

**vLLM**

```bash
sudo apt install python3-dev libxcb1
uv pip install &quot;ai-dynamo[vllm]&quot;
```

## Run Dynamo

&gt; **Tip (Optional):** Before running Dynamo, verify your system configuration with `python3 deploy/sanity_check.py`

Dynamo provides a simple way to spin up a local set of inference components including:

- **OpenAI Compatible Frontend** ‚Äì High performance OpenAI compatible http api server written in Rust.
- **Basic and Kv Aware Router** ‚Äì Route and load balance traffic to a set of workers.
- **Workers** ‚Äì Set of pre-configured LLM serving engines.

Start the frontend:

&gt; **Tip:** To run in a single terminal (useful in containers), append `&gt; logfile.log 2&gt;&amp;1 &amp;` to run processes in background. Example: `python3 -m dynamo.frontend --store-kv file &gt; dynamo.frontend.log 2&gt;&amp;1 &amp;`

```bash
# Start an OpenAI compatible HTTP server with prompt templating, tokenization, and routing.
# For local dev: --store-kv file avoids etcd (workers and frontend must share a disk)
python3 -m dynamo.frontend --http-port 8000 --store-kv file
```

In another terminal (or same terminal if using background mode), start a worker for your chosen backend:

```bash
# SGLang
python3 -m dynamo.sglang --model-path Qwen/Qwen3-0.6B --store-kv file

# TensorRT-LLM
python3 -m dynamo.trtllm --model-path Qwen/Qwen3-0.6B --store-kv file

# vLLM (note: uses --model, not --model-path)
python3 -m dynamo.vllm --model Qwen/Qwen3-0.6B --store-kv file \
  --kv-events-config &#039;{&quot;enable_kv_cache_events&quot;: false}&#039;
```

&gt; **Note:** For dependency-free local development, disable KV event publishing (avoids NATS):
&gt; - **vLLM:** Add `--kv-events-config &#039;{&quot;enable_kv_cache_events&quot;: false}&#039;`
&gt; - **SGLang:** No flag needed (KV events disabled by default)
&gt; - **TensorRT-LLM:** No flag needed (KV events disabled by default)
&gt;
&gt; **TensorRT-LLM only:** The warning `Cannot connect to ModelExpress server/transport error. Using direct download.` is expected and can be safely ignored.
&gt;
&gt; See [Service Discovery and Messaging](#service-discovery-and-messaging) for details.

#### Send a Request

```bash
curl localhost:8000/v1/chat/completions   -H &quot;Content-Type: application/json&quot;   -d &#039;{
    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,
    &quot;messages&quot;: [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello, how are you?&quot;
    }
    ],
    &quot;stream&quot;:false,
    &quot;max_tokens&quot;: 300
  }&#039; | jq
```

Rerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.

# Kubernetes Deployment

For production deployments on Kubernetes clusters with multiple GPUs.

## Prerequisites

- Kubernetes cluster with GPU nodes
- [Dynamo Platform installed](docs/pages/kubernetes/README.md)
- HuggingFace token for model downloads

## Production Recipes

Pre-built deployment configurations for common models and topologies:

| Model | Framework | Mode | GPUs | Recipe |
|-------|-----------|------|------|--------|
| Llama-3-70B | vLLM | Aggregated | 4x H100 | [View](recipes/llama-3-70b/vllm/) |
| DeepSeek-R1 | SGLang | Disaggregated | 8x H200 | [View](recipes/deepseek-r1/sglang/) |
| Qwen3-32B-FP8 | TensorRT-LLM | Aggregated | 8x GPU | [View](recipes/qwen3-32b-fp8/trtllm/) |

See [recipes/README.md](recipes/README.md) for the full list and deployment instructions.

## Cloud Deployment Guides

- [Amazon EKS](examples/deployments/EKS/)
- [Google GKE](examples/deployments/GKE/)

# Building from Source

For contributors who want to build Dynamo from source rather than installing from PyPI.

## 1. Install Libraries

**Ubuntu:**

```
sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
```

**macOS:**

- [Homebrew](https://brew.sh/)

```
# if brew is not installed on your system, install it
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
```

- [Xcode](https://developer.apple.com/xcode/)

```
brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
```

If Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.

## 2. Install Rust

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
```

## 3. Create a Python Virtual Environment

Follow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don&#039;t have `uv` installed. Once uv is installed, create a virtual environment and activate it.

- Install uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

- Create a virtual environment

```bash
uv venv dynamo
source dynamo/bin/activate
```

## 4. Install Build Tools

```
uv pip install pip maturin
```

[Maturin](https://github.com/PyO3/maturin) is the Rust&lt;-&gt;Python bindings build tool.

## 5. Build the Rust Bindings

```
cd lib/bindings/python
maturin develop --uv
```

## 6. Install GPU Memory Service

The GPU Memory Service is a Python package with a C++ extension. It requires only Python development headers and a C++ compiler (g++).

```bash
cd $PROJECT_ROOT
uv pip install -e lib/gpu_memory_service
```

## 7. Install the Wheel

```
cd $PROJECT_ROOT
uv pip install -e .
```

## 8. Run the Frontend

```bash
python3 -m dynamo.frontend
```

## 9. Configure for Local Development

- Pass `--store-kv file` to avoid external dependencies (see [Service Discovery and Messaging](#service-discovery-and-messaging))
- Set `DYN_LOG` to adjust the logging level (e.g., `export DYN_LOG=debug`). Uses the same syntax as `RUST_LOG`

&gt; **Note:** VSCode and Cursor users can use the `.devcontainer` folder for a pre-configured dev environment. See the [devcontainer README](.devcontainer/README.md) for details.

# Advanced Topics

## Benchmarking

Dynamo provides comprehensive benchmarking tools:

- **[Benchmarking Guide](docs/pages/benchmarks/benchmarking.md)** ‚Äì Compare deployment topologies using AIPerf
- **[SLA-Driven Deployments](docs/pages/components/planner/planner-guide.md)** ‚Äì Optimize deployments to meet SLA requirements

## Frontend OpenAPI Specification

The OpenAI-compatible frontend exposes an OpenAPI 3 spec at `/openapi.json`. To generate without running the server:

```bash
cargo run -p dynamo-llm --bin generate-frontend-openapi
```

This writes to `docs/pages/reference/api/openapi.json`.

## Service Discovery and Messaging

Dynamo uses TCP for inter-component communication. On Kubernetes, native resources ([CRDs + EndpointSlices](docs/pages/kubernetes/service-discovery.md)) handle service discovery. External services are optional for most deployments:

| Deployment | etcd | NATS | Notes |
|------------|------|------|-------|
| **Local Development** | ‚ùå Not required | ‚ùå Not required | Pass `--store-kv file`; vLLM also needs `--kv-events-config &#039;{&quot;enable_kv_cache_events&quot;: false}&#039;` |
| **Kubernetes** | ‚ùå Not required | ‚ùå Not required | K8s-native discovery; TCP request plane |

&gt; **Note:** KV-Aware Routing requires NATS for prefix caching coordination.

For Slurm or other distributed deployments (and KV-aware routing):

- [etcd](https://etcd.io/) can be run directly as `./etcd`.
- [nats](https://nats.io/) needs JetStream enabled: `nats-server -js`.

To quickly setup both: `docker compose -f deploy/docker-compose.yml up -d`

See [SGLang on Slurm](examples/backends/sglang/slurm_jobs/README.md) and [TRT-LLM on Slurm](examples/basics/multinode/trtllm/README.md) for deployment examples.

## More News

- [11/20] [Dell integrates PowerScale with Dynamo&#039;s NIXL for 19x faster TTFT](https://www.dell.com/en-us/dt/corporate/newsroom/announcements/detailpage.press-releases~usa~2025~11~dell-technologies-and-nvidia-advance-enterprise-ai-innovation.htm)
- [11/20] [WEKA partners with NVIDIA on KV cache storage for Dynamo](https://siliconangle.com/2025/11/20/nvidia-weka-kv-cache-solution-ai-inferencing-sc25/)
- [11/13] [Dynamo Office Hours Playlist](https://www.youtube.com/playlist?list=PL5B692fm6--tgryKu94h2Zb7jTFM3Go4X)
- [10/16] [How Baseten achieved 2x faster inference with NVIDIA Dynamo](https://www.baseten.co/blog/how-baseten-achieved-2x-faster-inference-with-nvidia-dynamo/)

&lt;!-- Reference links for Feature Compatibility Matrix --&gt;
[disagg]: docs/pages/design-docs/disagg-serving.md
[kv-routing]: docs/pages/components/router/README.md
[planner]: docs/pages/components/planner/planner-guide.md
[kvbm]: docs/pages/components/kvbm/README.md
[mm]: examples/multimodal/
[migration]: docs/pages/fault-tolerance/request-migration.md
[lora]: examples/backends/vllm/deploy/lora/README.md
[tools]: docs/pages/agents/tool-calling.md
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vortex-data/vortex]]></title>
            <link>https://github.com/vortex-data/vortex</link>
            <guid>https://github.com/vortex-data/vortex</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:51 GMT</pubDate>
            <description><![CDATA[An extensible, state of the art columnar file format. Formerly at @spiraldb, now an Incubation Stage project at LFAI&Data, part of the Linux Foundation.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vortex-data/vortex">vortex-data/vortex</a></h1>
            <p>An extensible, state of the art columnar file format. Formerly at @spiraldb, now an Incubation Stage project at LFAI&Data, part of the Linux Foundation.</p>
            <p>Language: Rust</p>
            <p>Stars: 2,704</p>
            <p>Forks: 132</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># üå™Ô∏è Vortex

[![Build Status](https://github.com/vortex-data/vortex/actions/workflows/ci.yml/badge.svg)](https://github.com/vortex-data/vortex/actions)
[![OpenSSF Best Practices](https://www.bestpractices.dev/projects/10567/badge)](https://www.bestpractices.dev/projects/10567)
[![Documentation](https://docs.rs/vortex/badge.svg)](https://docs.vortex.dev)
[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/vortex-data/vortex)
[![Crates.io](https://img.shields.io/crates/v/vortex.svg)](https://crates.io/crates/vortex)
[![PyPI - Version](https://img.shields.io/pypi/v/vortex-data)](https://pypi.org/project/vortex-data/)
[![Maven - Version](https://img.shields.io/maven-central/v/dev.vortex/vortex-spark)](https://central.sonatype.com/artifact/dev.vortex/vortex-spark)
[![codecov](https://codecov.io/github/vortex-data/vortex/graph/badge.svg)](https://codecov.io/github/vortex-data/vortex)

[Join the community on Slack!](https://vortex.dev/slack) | [Documentation](https://docs.vortex.dev/) | [Performance Benchmarks](https://bench.vortex.dev)

## Overview

Vortex is a next-generation columnar file format and toolkit designed for high-performance data processing.
It is the fastest and most extensible format for building data systems backed by object storage. It provides:

- **Blazing Fast Performance**
  - 100x faster random access reads (vs. modern Apache Parquet)
  - 10-20x faster scans
  - 5x faster writes
  - Similar compression ratios
  - Efficient support for wide tables with zero-copy/zero-parse metadata

- **Extensible Architecture**
  - Modeled after Apache DataFusion&#039;s extensible approach
  - Pluggable encoding system, type system, compression strategy, &amp; layout strategy
  - Zero-copy compatibility with Apache Arrow

- **Open Source, Neutral Governance**
  - A Linux Foundation (LF AI &amp; Data) Project
  - Apache-2.0 Licensed

- **Integrations**
  - Arrow, DataFusion, DuckDB, Spark, Pandas, Polars, &amp; more
  - Apache Iceberg (coming soon)

&gt; üü¢ **Development Status**: Library APIs may change from version to version, but we now consider
&gt; the file format &lt;ins&gt;_stable_&lt;/ins&gt;. From release 0.36.0, all future releases of Vortex should
&gt; maintain backwards compatibility of the file format (i.e., be able to read files written by
&gt; any earlier version &gt;= 0.36.0).

## Key Features

### Core Capabilities

- **Logical Types** - Clean separation between logical schema and physical layout
- **Zero-Copy Arrow Integration** - Seamless conversion to/from Apache Arrow arrays
- **Extensible Encodings** - Pluggable physical layouts with built-in optimizations
- **Cascading Compression** - Support for nested encoding schemes
- **High-Performance Computing** - Optimized compute kernels for encoded data
- **Rich Statistics** - Lazy-loaded summary statistics for optimization

### Technical Architecture

#### Logical vs Physical Design

Vortex strictly separates logical and physical concerns:

- **Logical Layer**: Defines data types and schema
- **Physical Layer**: Handles encoding and storage implementation
- **Built-in Encodings**: Compatible with Apache Arrow&#039;s memory format
- **Extension Encodings**: Optimized compression schemes (RLE, dictionary, etc.)

## Quick Start

### Installation

#### Rust Crate

All features are exported through the main `vortex` crate.

```bash
cargo add vortex
```

#### Python Package

```bash
uv add vortex-data
```

#### Command Line UI (vx)

For browsing the structure of Vortex files, you can use the `vx` command-line tool.

```bash
# Install latest release
cargo install vortex-tui --locked

# Or build from source
cargo install --path vortex-tui --locked

# Usage
vx browse &lt;file&gt;
```

### Development Setup

#### Prerequisites (macOS)

```bash
# Optional but recommended dependencies
brew install flatbuffers protobuf  # For .fbs and .proto files
brew install duckdb               # For benchmarks

# Install Rust toolchain
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
# or
brew install rustup

# Initialize submodules
git submodule update --init --recursive

# Setup dependencies with uv
uv sync --all-packages
```

### Benchmarking

Use `vx-bench` to run benchmarks comparing engines (DataFusion, DuckDB) and formats (Parquet, Vortex):

```bash
# Install the benchmark orchestrator
uv tool install &quot;bench_orchestrator @ ./bench-orchestrator/&quot;

# Run TPC-H benchmarks
vx-bench run tpch --engine datafusion,duckdb --format parquet,vortex

# Compare results
vx-bench compare --run latest
```

See [bench-orchestrator/README.md](bench-orchestrator/README.md) for full documentation.

### Performance Optimization

For optimal performance, we suggest using [MiMalloc](https://github.com/microsoft/mimalloc):

```rust,ignore
#[global_allocator]
static GLOBAL_ALLOC: MiMalloc = MiMalloc;
```

## Project Information

### License

Licensed under the Apache License, Version 2.0.

### Governance

Vortex is an independent open-source project and not controlled by any single company. The Vortex Project is a
sub-project of the Linux Foundation Projects. The governance model is documented in
[CONTRIBUTING.md](CONTRIBUTING.md) and is subject to the terms of
the [Technical Charter](https://vortex.dev/charter.pdf).

### Contributing

Please **do** read [CONTRIBUTING.md](CONTRIBUTING.md) before you contribute.

### Reporting Vulnerabilities

If you discover a security vulnerability, please email &lt;vuln-report@vortex.dev&gt;.

### Trademarks

Copyright ¬© Vortex a Series of LF Projects, LLC.
For terms of use, trademark policy, and other project policies please see &lt;https://lfprojects.org&gt;

## Acknowledgments

The Vortex project benefits enormously from groundbreaking work from the academic &amp; open-source communities.

### Research in Vortex

- [BtrBlocks](https://www.cs.cit.tum.de/fileadmin/w00cfj/dis/papers/btrblocks.pdf) - Efficient columnar compression
- [FastLanes](https://www.vldb.org/pvldb/vol16/p2132-afroozeh.pdf) &amp; [FastLanes on GPU](https://dbdbd2023.ugent.be/abstracts/felius_fastlanes.pdf) - High-performance integer compression
- [FSST](https://www.vldb.org/pvldb/vol13/p2649-boncz.pdf) - Fast random access string compression
- [ALP](https://ir.cwi.nl/pub/33334/33334.pdf) &amp; [G-ALP](https://dl.acm.org/doi/pdf/10.1145/3736227.3736242) - Adaptive lossless floating-point compression
- [Procella](https://dl.acm.org/citation.cfm?id=3360438) - YouTube&#039;s unified data system
- [Anyblob](https://www.durner.dev/app/media/papers/anyblob-vldb23.pdf) - High-performance access to object storage
- [ClickHouse](https://www.vldb.org/pvldb/vol17/p3731-schulze.pdf) - Fast analytics for everyone
- [MonetDB/X100](https://www.cidrdb.org/cidr2005/papers/P19.pdf) - Hyper-Pipelining Query Execution
- [Morsel-Driven Parallelism](https://db.in.tum.de/~leis/papers/morsels.pdf): A NUMA-Aware Query Evaluation Format for the Many-Core Age
- [The FastLanes File Format](https://github.com/cwida/FastLanes/blob/dev/docs/specification.pdf) - Expression Operators

### Vortex in Research

- [Anyblox](https://gienieczko.com/anyblox-paper) - A Framework for Self-Decoding Datasets
- [F3](https://dl.acm.org/doi/pdf/10.1145/3749163) - Open-Source Data File Format for the Future

### Open Source Inspiration

- [Apache Arrow](https://arrow.apache.org)
- [Apache DataFusion](https://github.com/apache/datafusion)
- [parquet2](https://github.com/jorgecarleitao/parquet2) by Jorge Leitao
- [DuckDB](https://github.com/duckdb/duckdb)
- [Velox](https://github.com/facebookincubator/velox) &amp; [Nimble](https://github.com/facebookincubator/nimble)

#### Thanks to all contributors who have shared their knowledge and code with the community! üöÄ
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vectordotdev/vector]]></title>
            <link>https://github.com/vectordotdev/vector</link>
            <guid>https://github.com/vectordotdev/vector</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:50 GMT</pubDate>
            <description><![CDATA[A high-performance observability data pipeline.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vectordotdev/vector">vectordotdev/vector</a></h1>
            <p>A high-performance observability data pipeline.</p>
            <p>Language: Rust</p>
            <p>Stars: 21,321</p>
            <p>Forks: 2,006</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![Nightly](https://github.com/vectordotdev/vector/actions/workflows/nightly.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/nightly.yml)
[![Integration/E2E Test Suite](https://github.com/vectordotdev/vector/actions/workflows/integration.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/integration.yml/badge.svg?event=merge_group)
[![Component Features](https://github.com/vectordotdev/vector/actions/workflows/component_features.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/component_features.yml)

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;website/static/img/diagram.svg&quot; alt=&quot;Vector&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://vector.dev/docs/setup/quickstart/&quot;&gt;Quickstart&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/docs/&quot;&gt;Docs&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/guides/&quot;&gt;Guides&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/components/&quot;&gt;Integrations&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://chat.vector.dev&quot;&gt;Chat&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/releases/latest/download/&quot;&gt;Download&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://rust-doc.vector.dev/&quot;&gt;Rust Crate Docs&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

## What is Vector?

Vector is a high-performance, end-to-end (agent &amp; aggregator) observability data
pipeline that puts you in control of your observability data.
[Collect][docs.sources], [transform][docs.transforms], and [route][docs.sinks]
all your logs and metrics to any vendors you want today and any other
vendors you may want tomorrow. Vector enables dramatic cost reduction, novel
data enrichment, and data security where you need it, not where it is most
convenient for your vendors. Additionally, it is open source and up to 10x
faster than every alternative in the space.

To get started, follow our [**quickstart guide**][docs.quickstart] or [**install
Vector**][docs.installation].

Vector is maintained by Datadog&#039;s [Community Open Source Engineering team](https://opensource.datadoghq.com/about/#the-community-open-source-engineering-team).

### Principles

* **Reliable** - Built in [Rust][urls.rust], Vector&#039;s primary design goal is reliability.
* **End-to-end** - Deploys as an [agent][docs.roles#agent] or [aggregator][docs.roles#aggregator]. Vector is a complete platform.
* **Unified** - [Logs][docs.data-model.log], [metrics][docs.data-model.metric] (beta), and traces (coming soon). One tool for all of your data.

### Use cases

* Reduce total observability costs.
* Transition vendors without disrupting workflows.
* Enhance data quality and improve insights.
* Consolidate agents and eliminate agent fatigue.
* Improve overall observability performance and reliability.

### Community

* Vector is relied on by startups and enterprises like **Atlassian**, **T-Mobile**,
  **Comcast**, **Zendesk**, **Discord**, **Fastly**, **CVS**, **Trivago**,
  **Tuple**, **Douban**, **Visa**, **Mambu**, **Blockfi**, **Claranet**,
  **Instacart**, **Forcepoint**, and [many more][urls.production_users].
* Vector is **downloaded over 100,000 times per day**.
* Vector&#039;s largest user **processes over 500TB daily**.
* Vector has **over 500 contributors** and growing.

## Documentation

All user documentation is available at **[vector.dev/docs](https://vector.dev/docs)**.

Other Resources:

* [**Vector Calendar**][urls.vector_calendar]
* **Policies**:
  * [**Code of Conduct**][urls.vector_code_of_conduct]
  * [**Contributing**][urls.vector_contributing_policy]
  * [**Privacy**][urls.vector_privacy_policy]
  * [**Releases**][urls.vector_releases_policy]
  * [**Versioning**][urls.vector_versioning_policy]
  * [**Security**][urls.vector_security_policy]

## Comparisons

### Performance

The following performance tests demonstrate baseline performance between
common protocols with the exception of the Regex Parsing test.

| Test                                                                                                                   | Vector          | Filebeat | FluentBit       | FluentD   | Logstash  | SplunkUF        | SplunkHF |
| ---------------------------------------------------------------------------------------------------------------------- | --------------- | -------- | --------------- | --------- | --------- | --------------- | -------- |
| [TCP to Blackhole](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance) | _**86mib/s**_   | n/a      | 64.4mib/s       | 27.7mib/s | 40.6mib/s | n/a             | n/a      |
| [File to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance)           | _**76.7mib/s**_ | 7.8mib/s | 35mib/s         | 26.1mib/s | 3.1mib/s  | 40.1mib/s       | 39mib/s  |
| [Regex Parsing](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance)       | 13.2mib/s       | n/a      | _**20.5mib/s**_ | 2.6mib/s  | 4.6mib/s  | n/a             | 7.8mib/s |
| [TCP to HTTP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance)           | _**26.7mib/s**_ | n/a      | 19.6mib/s       | &lt;1mib/s   | 2.7mib/s  | n/a             | n/a      |
| [TCP to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance)             | 69.9mib/s       | 5mib/s   | 67.1mib/s       | 3.9mib/s  | 10mib/s   | _**70.4mib/s**_ | 7.6mib/s |

To learn more about our performance tests, please see the [Vector test harness][urls.vector_test_harness].

### Correctness

The following correctness tests are not exhaustive, but they demonstrate
fundamental differences in quality and attention to detail:

| Test                                                                                                                                 | Vector | Filebeat | FluentBit | FluentD | Logstash | Splunk UF | Splunk HF |
| ------------------------------------------------------------------------------------------------------------------------------------ | ------ | -------- | --------- | ------- | -------- | --------- | --------- |
| [Disk Buffer Persistence](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness) | **‚úì**  | ‚úì        |           |         | ‚ö†        | ‚úì         | ‚úì         |
| [File Rotate (create)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness)         | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |
| [File Rotate (copytruncate)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness) | **‚úì**  |          |           |         |          | ‚úì         | ‚úì         |
| [File Truncation](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness)                   | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |
| [Process (SIGHUP)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness)                         | **‚úì**  |          |           |         | ‚ö†        | ‚úì         | ‚úì         |
| [JSON (wrapped)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness)                     | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |

To learn more about our correctness tests, please see the [Vector test harness][urls.vector_test_harness].

### Features

Vector is an end-to-end, unified, open data platform.

|                     | **Vector** | Beats | Fluentbit | Fluentd | Logstash | Splunk UF | Splunk HF | Telegraf |
| ------------------- | ---------- | ----- | --------- | ------- | -------- | --------- | --------- | -------- |
| **End-to-end**      | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Agent               | **‚úì**      | ‚úì     | ‚úì         |         |          | ‚úì         |           | ‚úì        |
| Aggregator          | **‚úì**      |       |           | ‚úì       | ‚úì        |           | ‚úì         | ‚úì        |
| **Unified**         | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Logs                | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         | ‚úì        |
| Metrics             | **‚úì**      | ‚ö†     | ‚ö†         | ‚ö†       | ‚ö†        | ‚ö†         | ‚ö†         | ‚úì        |
| Traces              | üöß         |       |           |         |          |           |           |          |
| **Open**            | **‚úì**      |       | ‚úì         | ‚úì       |          |           |           | ‚úì        |
| Open-source         | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        |           |           | ‚úì        |
| Vendor-neutral      | **‚úì**      |       | ‚úì         | ‚úì       |          |           |           | ‚úì        |
| **Reliability**     | **‚úì**      |       |           |         |          |           |           |          |
| Memory-safe         | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Delivery guarantees | **‚úì**      |       |           |         |          | ‚úì         | ‚úì         |          |
| Multi-core          | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         | ‚úì        |


‚ö† = Not interoperable, metrics are represented as structured logs

---

&lt;p align=&quot;center&quot;&gt;
  Developed with ‚ù§Ô∏è by &lt;strong&gt;&lt;a href=&quot;https://datadoghq.com&quot;&gt;Datadog&lt;/a&gt;&lt;/strong&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/security/policy&quot;&gt;Security Policy&lt;/a&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/blob/master/PRIVACY.md&quot;&gt;Privacy Policy&lt;/a&gt;
&lt;/p&gt;

[docs.about.concepts]: https://vector.dev/docs/introduction/concepts/
[docs.about.introduction]: https://vector.dev/docs/introduction/
[docs.administration.monitoring]: https://vector.dev/docs/administration/monitoring/
[docs.administration.management]: https://vector.dev/docs/administration/management/
[docs.administration.upgrading]: https://vector.dev/docs/administration/upgrading/
[docs.administration.validating]: https://vector.dev/docs/administration/validating/
[docs.architecture.concurrency-model]: https://vector.dev/docs/architecture/concurrency-model/
[docs.architecture.data-model]: https://vector.dev/docs/architecture/data-model/
[docs.architecture.pipeline-model]: https://vector.dev/docs/architecture/pipeline-model/
[docs.architecture.runtime-model]: https://vector.dev/docs/architecture/runtime-model/
[docs.configuration.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.configuration.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.configuration.tests]: https://vector.dev/docs/reference/configuration/tests/
[docs.configuration.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.configuration.enrichment_tables]: https://vector.dev/docs/reference/configuration/global-options/#enrichment_tables
[docs.data-model.log]: https://vector.dev/docs/architecture/data-model/log/
[docs.data-model.metric]: https://vector.dev/docs/architecture/data-model/metric/
[docs.deployment.roles]: https://vector.dev/docs/setup/deployment/roles/
[docs.deployment.topologies]: https://vector.dev/docs/setup/deployment/topologies/
[docs.deployment]: https://vector.dev/docs/setup/deployment/
[docs.installation.manual]: https://vector.dev/docs/setup/installation/manual/
[docs.installation.operating_systems]: https://vector.dev/docs/setup/installation/operating-systems/
[docs.installation.package_managers]: https://vector.dev/docs/setup/installation/package-managers/
[docs.installation.platforms]: https://vector.dev/docs/setup/installation/platforms/
[docs.installation]: https://vector.dev/docs/setup/installation/
[docs.architecture.adaptive-request-concurrency]: https://vector.dev/docs/architecture/arc/
[docs.platforms.kubernetes]: https://vector.dev/docs/setup/installation/platforms/kubernetes/
[docs.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.reference.api]: https://vector.dev/docs/reference/api/
[docs.reference.cli]: https://vector.dev/docs/reference/cli/
[docs.reference.vrl]: https://vector.dev/docs/reference/vrl/
[docs.roles#agent]: https://vector.dev/docs/setup/deployment/roles/#agent
[docs.roles#aggregator]: https://vector.dev/docs/setup/deployment/roles/#aggregator
[docs.setup.installation]: https://vector.dev/docs/setup/installation/
[docs.setup.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.sinks.aws_cloudwatch_logs]: https://vector.dev/docs/reference/configuration/sinks/aws_cloudwatch_logs/
[docs.sinks.aws_s3]: https://vector.dev/docs/reference/configuration/sinks/aws_s3/
[docs.sinks.clickhouse]: https://vector.dev/docs/reference/configuration/sinks/clickhouse/
[docs.sinks.elasticsearch]: https://vector.dev/docs/reference/configuration/sinks/elasticsearch/
[docs.sinks.gcp_cloud_storage]: https://vector.dev/docs/reference/configuration/sinks/gcp_cloud_storage/
[docs.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.sources.docker_logs]: https://vector.dev/docs/reference/configuration/sources/docker_logs/
[docs.sources.file]: https://vector.dev/docs/reference/configuration/sources/file/
[docs.sources.http]: https://vector.dev/docs/reference/configuration/sources/http/
[docs.sources.journald]: https://vector.dev/docs/reference/configuration/sources/journald/
[docs.sources.kafka]: https://vector.dev/docs/reference/configuration/sources/kafka/
[docs.sources.socket]: https://vector.dev/docs/reference/configuration/sources/socket/
[docs.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.transforms.dedupe]: https://vector.dev/docs/reference/configuration/transforms/dedupe/
[docs.transforms.filter]: https://vector.dev/docs/reference/configuration/transforms/filter/
[docs.transforms.log_to_metric]: https://vector.dev/docs/reference/configuration/transforms/log_to_metric/
[docs.transforms.lua]: https://vector.dev/docs/reference/configuration/transforms/lua/
[docs.transforms.remap]: https://vector.dev/docs/reference/configuration/transforms/remap/
[docs.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.introduction.architecture]: https://vector.dev/docs/architecture/
[docs.introduction.guarantees]: https://vector.dev/docs/introduction/guarantees/
[docs.introduction.architecture]: https://vector.dev/docs/architecture/
[urls.production_users]: https://github.com/vectordotdev/vector/issues/790
[urls.rust]: https://www.rust-lang.org/
[urls.vector_calendar]: https://calendar.vector.dev
[urls.vector_chat]: https://chat.vector.dev
[urls.vector_code_of_conduct]: https://github.com/vectordotdev/vector/blob/master/CODE_OF_CONDUCT.md
[urls.vector_contributing_policy]: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md
[urls.vector_community]: https://vector.dev/community/
[urls.vector_privacy_policy]: https://github.com/vectordotdev/vector/blob/master/PRIVACY.md
[urls.vector_release_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASING.md
[urls.vector_releases]: https://vector.dev/releases/
[urls.vector_releases_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASES.md
[urls.vector_security_policy]: https://github.com/vectordotdev/vector/security/policy
[urls.vector_test_harness]: https://github.com/vectordotdev/vector-test-harness/
[urls.vector_twitter]: https://twitter.com/vectordotdev
[urls.vector_versioning_policy]: https://github.com/vectordotdev/vector/blob/master/VERSIONING.md
[urls.vote_feature]: https://github.com/vectordotdev/vector/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22type%3A+feature%22
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cube-js/cube]]></title>
            <link>https://github.com/cube-js/cube</link>
            <guid>https://github.com/cube-js/cube</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:49 GMT</pubDate>
            <description><![CDATA[üìä Cube Core is open-source semantic layer for AI, BI and embedded analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cube-js/cube">cube-js/cube</a></h1>
            <p>üìä Cube Core is open-source semantic layer for AI, BI and embedded analytics</p>
            <p>Language: Rust</p>
            <p>Stars: 19,492</p>
            <p>Forks: 1,955</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre>![]()
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cube.dev?ref=github-readme&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/cube-js/cube/master/docs/content/cube-core-logo.png&quot; alt=&quot;Cube Core ‚Äî Open-Source Semantic Layer&quot; width=&quot;300px&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;br/&gt;

[Website](https://cube.dev?ref=github-readme) ‚Ä¢ [Docs](https://cube.dev/docs?ref=github-readme) ‚Ä¢ [Examples](https://cube.dev/docs/examples?ref=github-readme) ‚Ä¢ [Blog](https://cube.dev/blog?ref=github-readme) ‚Ä¢ [Slack](https://slack.cube.dev?ref=github-readme) ‚Ä¢ [X](https://twitter.com/the_cube_dev)

[![npm version](https://badge.fury.io/js/%40cubejs-backend%2Fserver.svg)](https://badge.fury.io/js/%40cubejs-backend%2Fserver)
[![GitHub Actions](https://github.com/cube-js/cube/workflows/Build/badge.svg)](https://github.com/cube-js/cube/actions?query=workflow%3ABuild+branch%3Amaster)
[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js.svg?type=shield)](https://app.fossa.io/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js?ref=badge_shield)

__Cube Core is an open-source semantic layer.__ Cube Core can be used to build embedded analytics in your applications, create your own business intelligence tool or provide context about data to AI agents. Cube Core is headless and comes with multiple APIs for embedded analytics and BI: REST, GraphQL, and SQL.

If you are looking for a fully integrated platform, check out [Cube](https://cube.dev), a modern AI-first business intelligence platform. We use Cube Core to power it.

&lt;img
  src=&quot;https://lgo0ecceic.ucarecd.net/418db1f9-7597-4e00-8c10-eba19fcac20f/&quot;
  style=&quot;border: none&quot;
  width=&quot;100%&quot;
/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Learn more about connecting Cube to &lt;a href=&quot;https://cube.dev/docs/config/databases?ref=github-readme&quot; target=&quot;_blank&quot;&gt;data sources&lt;/a&gt; and &lt;a href=&quot;https://cube.dev/docs/config/downstream?ref=github-readme&quot; target=&quot;_blank&quot;&gt;analytics &amp; visualization tools&lt;/a&gt;.&lt;/i&gt;
&lt;/p&gt;

Cube Core was designed to work with all SQL data sources, including cloud data warehouses like Snowflake, Databricks, and BigQuery; query engines like Presto and Amazon Athena; and application databases like Postgres. Cube Core has a built-in relational caching engine to provide sub-second latency and high concurrency for API requests.

## Why Cube Core?

Every business intelligence tool relies on a semantic layer as its core engine‚Äîa critical component that defines metrics, dimensions, and business logic while abstracting the complexity of underlying data sources. However, most semantic layers are proprietary, tightly coupled to specific BI platforms, and cannot be reused across different applications.

Cube Core is an open-source project that aims to create an open, modern semantic layer that can be used to power any analytics applications and AI agents. By decoupling the semantic layer from specific tools and making it accessible through standard APIs, Cube Core enables organizations to define their metrics once and use them everywhere‚Äîfrom BI tools to embedded analytics to AI agents.

## Getting Started üöÄ

You can get started with Cube locally or self-host it with [Docker](https://www.docker.com/).

Once Docker is installed, in a new folder for your project, run the following command:

```bash
docker run -p 4000:4000 \
  -p 15432:15432 \
  -v ${PWD}:/cube/conf \
  -e CUBEJS_DEV_MODE=true \
  cubejs/cube
```

Then, open http://localhost:4000 in your browser to continue setup.

For a step-by-step guide, [see the docs](https://cube.dev/docs/getting-started-docker?ref=github-readme).

### Cube ‚Äî Complete Modern BI Tool from Cube Core Creators

[Cube](https://cube.dev?ref=github-readme) is a complete modern agentic analytics platform built on Cube Core. It provides a fully integrated solution with a user-friendly interface, advanced analytics capabilities, and managed infrastructure.

&lt;a href=&quot;https://cubecloud.dev/auth/signup?ref=github-readme&quot;&gt;&lt;img src=&quot;https://cubedev-blog-images.s3.us-east-2.amazonaws.com/f1f1eac0-0b44-4c47-936e-33b5c06eedf0.png&quot; alt=&quot;Get started now&quot; width=&quot;200px&quot;&gt;&lt;/a&gt;

## Resources

- [Documentation](https://cube.dev/docs?ref=github-readme)
- [Getting Started](https://cube.dev/docs/getting-started?ref=github-readme)
- [Examples &amp; Tutorials](https://cube.dev/docs/examples?ref=github-readme)
- [Architecture](https://cube.dev/docs/product/introduction#four-layers-of-semantic-layer)

## Contributing

There are many ways you can contribute to Cube Core! Here are a few possibilities:

* Star this repo and follow us on [X](https://twitter.com/the_cube_dev).
* Add Cube to your stack on [Stackshare](https://stackshare.io/cube-js).
* Upvote issues with üëç reaction so we know what the demand is for particular issues to prioritize them within the roadmap.
* Create issues every time you feel something is missing or goes wrong.
* Ask questions on [Stack Overflow with cube.js tag](https://stackoverflow.com/questions/tagged/cube.js) if others might have these questions as well.
* Provide pull requests for all open issues and especially for those with [help wanted](https://github.com/cube-js/cube/issues?q=is%3Aissue+is%3Aopen+label%3A&quot;help+wanted&quot;) and [good first issue](https://github.com/cube-js/cube/issues?q=is%3Aissue+is%3Aopen+label%3A&quot;good+first+issue&quot;) labels.

All sorts of contributions are **welcome and extremely helpful** üôå Please refer to [the contribution guide](https://github.com/cube-js/cube/blob/master/CONTRIBUTING.md) for more information.

## License

Cube Client is [MIT licensed](./packages/cubejs-client-core/LICENSE).

Cube Backend is [Apache 2.0 licensed](./packages/cubejs-server/LICENSE).


[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tensorzero/tensorzero]]></title>
            <link>https://github.com/tensorzero/tensorzero</link>
            <guid>https://github.com/tensorzero/tensorzero</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:48 GMT</pubDate>
            <description><![CDATA[TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tensorzero/tensorzero">tensorzero/tensorzero</a></h1>
            <p>TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation.</p>
            <p>Language: Rust</p>
            <p>Stars: 10,951</p>
            <p>Forks: 771</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;p&gt;&lt;picture&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/47d67430-386d-4675-82ad-d4734d3262d9&quot; alt=&quot;TensorZero Logo&quot; width=&quot;128&quot; height=&quot;128&quot;&gt;&lt;/picture&gt;&lt;/p&gt;

# TensorZero

&lt;p&gt;&lt;picture&gt;&lt;img src=&quot;https://www.tensorzero.com/github-trending-badge.svg&quot; alt=&quot;#1 Repository Of The Day&quot;&gt;&lt;/picture&gt;&lt;/p&gt;

**TensorZero is an open-source stack for _industrial-grade LLM applications_:**

- **Gateway:** access every LLM provider through a unified API, built for performance (&lt;1ms p99 latency)
- **Observability:** store inferences and feedback in your database, available programmatically or in the UI
- **Optimization:** collect metrics and human feedback to optimize prompts, models, and inference strategies
- **Evaluation:** benchmark individual inferences or end-to-end workflows using heuristics, LLM judges, etc.
- **Experimentation:** ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.

Take what you need, adopt incrementally, and complement with other tools.

&lt;video src=&quot;https://github.com/user-attachments/assets/04a8466e-27d8-4189-b305-e7cecb6881ee&quot;&gt;&lt;/video&gt;

---

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/&quot; target=&quot;_blank&quot;&gt;Website&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs&quot; target=&quot;_blank&quot;&gt;Docs&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.x.com/tensorzero&quot; target=&quot;_blank&quot;&gt;Twitter&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/slack&quot; target=&quot;_blank&quot;&gt;Slack&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/discord&quot; target=&quot;_blank&quot;&gt;Discord&lt;/a&gt;&lt;/b&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/quickstart&quot; target=&quot;_blank&quot;&gt;Quick Start (5min)&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/deployment&quot; target=&quot;_blank&quot;&gt;Deployment Guide&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/api-reference&quot; target=&quot;_blank&quot;&gt;API Reference&lt;/a&gt;&lt;/b&gt;
  ¬∑
  &lt;b&gt;&lt;a href=&quot;https://www.tensorzero.com/docs/gateway/deployment&quot; target=&quot;_blank&quot;&gt;Configuration Reference&lt;/a&gt;&lt;/b&gt;
&lt;/p&gt;

---

&gt; [!NOTE]
&gt;
&gt; ### **Coming Soon: TensorZero Autopilot**
&gt;
&gt; TensorZero Autopilot is an **automated AI engineer** (powered by the TensorZero Stack) that analyzes LLM observability data, optimizes prompts and models, sets up evals, and runs A/B tests.
&gt; **[Learn more](https://www.tensorzero.com/)** **[Join the waitlist](https://tensorzero.com/autopilot-waitlist)**

## Features

### üåê LLM Gateway

&gt; **Integrate with TensorZero once and access every major LLM provider.**

- [x] **[Call any LLM](https://www.tensorzero.com/docs/gateway/call-any-llm)** (API or self-hosted) through a single unified API
- [x] Infer with **[streaming](https://www.tensorzero.com/docs/gateway/guides/streaming-inference)**, **[tool use](https://www.tensorzero.com/docs/gateway/guides/tool-use)**, **[structured outputs (JSON)](https://www.tensorzero.com/docs/gateway/generate-structured-outputs)**, **[batch](https://www.tensorzero.com/docs/gateway/guides/batch-inference)**, **[embeddings](https://www.tensorzero.com/docs/gateway/generate-embeddings)**, **[multimodal (images, files)](https://www.tensorzero.com/docs/gateway/guides/multimodal-inference)**, **[caching](https://www.tensorzero.com/docs/gateway/guides/inference-caching)**, etc.
- [x] **[Create prompt templates and schemas](https://www.tensorzero.com/docs/gateway/create-a-prompt-template)** to enforce a consistent, typed interface between your application and the LLMs
- [x] Satisfy extreme throughput and latency needs, thanks to ü¶Ä Rust: **[&lt;1ms p99 latency overhead at 10k+ QPS](https://www.tensorzero.com/docs/gateway/benchmarks)**
- [x] Use any programming language: **[integrate via our Python SDK, any OpenAI SDK, or our HTTP API](https://www.tensorzero.com/docs/gateway/clients)**
- [x] **[Ensure high availability](https://www.tensorzero.com/docs/gateway/guides/retries-fallbacks)** with routing, retries, fallbacks, load balancing, granular timeouts, etc.
- [x] **[Enforce custom rate limits](https://www.tensorzero.com/docs/operations/enforce-custom-rate-limits)** with granular scopes (e.g. user-defined tags) to keep usage under control
- [x] **[Set up auth for TensorZero](https://www.tensorzero.com/docs/operations/set-up-auth-for-tensorzero)** to allow clients to access models without sharing provider API keys
- [ ] Soon: spend tracking and budgeting

&lt;br&gt;

**Supported Model Providers:**
**[Anthropic](https://www.tensorzero.com/docs/gateway/guides/providers/anthropic)**,
**[AWS Bedrock](https://www.tensorzero.com/docs/gateway/guides/providers/aws-bedrock)**,
**[AWS SageMaker](https://www.tensorzero.com/docs/gateway/guides/providers/aws-sagemaker)**,
**[Azure](https://www.tensorzero.com/docs/gateway/guides/providers/azure)**,
**[DeepSeek](https://www.tensorzero.com/docs/gateway/guides/providers/deepseek)**,
**[Fireworks](https://www.tensorzero.com/docs/gateway/guides/providers/fireworks)**,
**[GCP Vertex AI Anthropic](https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-anthropic)**,
**[GCP Vertex AI Gemini](https://www.tensorzero.com/docs/gateway/guides/providers/gcp-vertex-ai-gemini)**,
**[Google AI Studio (Gemini API)](https://www.tensorzero.com/docs/gateway/guides/providers/google-ai-studio-gemini)**,
**[Groq](https://www.tensorzero.com/docs/gateway/guides/providers/groq)**,
**[Hyperbolic](https://www.tensorzero.com/docs/gateway/guides/providers/hyperbolic)**,
**[Mistral](https://www.tensorzero.com/docs/gateway/guides/providers/mistral)**,
**[OpenAI](https://www.tensorzero.com/docs/gateway/guides/providers/openai)**,
**[OpenRouter](https://www.tensorzero.com/docs/gateway/guides/providers/openrouter)**,
**[SGLang](https://www.tensorzero.com/docs/gateway/guides/providers/sglang)**,
**[TGI](https://www.tensorzero.com/docs/gateway/guides/providers/tgi)**,
**[Together AI](https://www.tensorzero.com/docs/gateway/guides/providers/together)**,
**[vLLM](https://www.tensorzero.com/docs/gateway/guides/providers/vllm)**, and
**[xAI (Grok)](https://www.tensorzero.com/docs/gateway/guides/providers/xai)**.
Need something else? TensorZero also supports **[any OpenAI-compatible API (e.g. Ollama)](https://www.tensorzero.com/docs/gateway/guides/providers/openai-compatible)**.

&lt;br&gt;

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;Usage: Python &amp;mdash; TensorZero SDK&lt;/b&gt;&lt;/summary&gt;

You can access any provider using the TensorZero Python SDK.

1. `pip install tensorzero`
2. Optional: Set up the TensorZero configuration.
3. Run inference:

```python
from tensorzero import TensorZeroGateway  # or AsyncTensorZeroGateway


with TensorZeroGateway.build_embedded(...) as t0:
    response = t0.inference(
        model_name=&quot;openai::gpt-4o-mini&quot;,
        # Try other providers easily: &quot;anthropic::claude-sonnet-4-5&quot;
        input={
            &quot;messages&quot;: [
                {
                    &quot;role&quot;: &quot;user&quot;,
                    &quot;content&quot;: &quot;Write a haiku about TensorZero.&quot;,
                }
            ]
        },
    )
```

See **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Usage: Python &amp;mdash; OpenAI SDK&lt;/b&gt;&lt;/summary&gt;

You can access any provider using the OpenAI Python SDK with TensorZero.

1. `pip install tensorzero`
2. Optional: Set up the TensorZero configuration.
3. Run inference:

```python
from openai import OpenAI  # or AsyncOpenAI
from tensorzero import patch_openai_client

client = OpenAI()

patch_openai_client(client, ...)

response = client.chat.completions.create(
    model=&quot;tensorzero::model_name::openai::gpt-4o-mini&quot;,
    # Try other providers easily: &quot;tensorzero::model_name::anthropic::claude-sonnet-4-5&quot;
    messages=[
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: &quot;Write a haiku about TensorZero.&quot;,
        }
    ],
)
```

See **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Usage: JavaScript / TypeScript (Node) &amp;mdash; OpenAI SDK&lt;/b&gt;&lt;/summary&gt;

You can access any provider using the OpenAI Node SDK with TensorZero.

1. Deploy `tensorzero/gateway` using Docker.
   **[Detailed instructions ‚Üí](https://www.tensorzero.com/docs/gateway/deployment)**
2. Set up the TensorZero configuration.
3. Run inference:

```ts
import OpenAI from &quot;openai&quot;;

const client = new OpenAI({
  baseURL: &quot;http://localhost:3000/openai/v1&quot;,
});

const response = await client.chat.completions.create({
  model: &quot;tensorzero::model_name::openai::gpt-4o-mini&quot;,
  // Try other providers easily: &quot;tensorzero::model_name::anthropic::claude-sonnet-4-5&quot;
  messages: [
    {
      role: &quot;user&quot;,
      content: &quot;Write a haiku about TensorZero.&quot;,
    },
  ],
});
```

See **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Usage: Other Languages &amp; Platforms &amp;mdash; HTTP API&lt;/b&gt;&lt;/summary&gt;

TensorZero supports virtually any programming language or platform via its HTTP API.

1. Deploy `tensorzero/gateway` using Docker.
   **[Detailed instructions ‚Üí](https://www.tensorzero.com/docs/gateway/deployment)**
2. Optional: Set up the TensorZero configuration.
3. Run inference:

```bash
curl -X POST &quot;http://localhost:3000/inference&quot; \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{
    &quot;model_name&quot;: &quot;openai::gpt-4o-mini&quot;,
    &quot;input&quot;: {
      &quot;messages&quot;: [
        {
          &quot;role&quot;: &quot;user&quot;,
          &quot;content&quot;: &quot;Write a haiku about TensorZero.&quot;
        }
      ]
    }
  }&#039;
```

See **[Quick Start](https://www.tensorzero.com/docs/quickstart)** for more information.

&lt;/details&gt;

### üîç LLM Observability

&gt; **Zoom in to debug individual API calls, or zoom out to monitor metrics across models and prompts over time &amp;mdash; all using the open-source TensorZero UI.**

- [x] Store inferences and **[feedback (metrics, human edits, etc.)](https://www.tensorzero.com/docs/gateway/guides/metrics-feedback)** in your own database
- [x] Dive into individual inferences or high-level aggregate patterns using the TensorZero UI or programmatically
- [x] **[Build datasets](https://www.tensorzero.com/docs/gateway/api-reference/datasets-datapoints)** for optimization, evaluation, and other workflows
- [x] Replay historical inferences with new prompts, models, inference strategies, etc.
- [x] **[Export OpenTelemetry traces (OTLP)](https://www.tensorzero.com/docs/operations/export-opentelemetry-traces)** and **[export Prometheus metrics](https://www.tensorzero.com/docs/observability/export-prometheus-metrics)** to your favorite application observability tools
- [ ] Soon: AI-assisted debugging and root cause analysis; AI-assisted data labeling

&lt;table&gt;
&lt;tr&gt;&lt;/tr&gt; &lt;!-- flip highlight order --&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Observability ¬ª UI&lt;/b&gt;&lt;/td&gt;
&lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Observability ¬ª Programmatic&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;video src=&quot;https://github.com/user-attachments/assets/a23e4c95-18fa-482c-8423-6078fb4cf285&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td width=&quot;50%&quot; align=&quot;left&quot; valign=&quot;middle&quot;&gt;

```python
t0.experimental_list_inferences(
  function_name=&quot;sales_agent&quot;,
  filters=BooleanMetricFilter(
      metric_name=&quot;converted_sale&quot;,
      value=True,
  ),
  # + compound filters
  # + search
  # + pagination
  # ... and more ...
)
```

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

### üìà LLM Optimization

&gt; **Send production metrics and human feedback to easily optimize your prompts, models, and inference strategies &amp;mdash; using the UI or programmatically.**

- [x] Optimize your models with supervised fine-tuning, RLHF, and other techniques
- [x] Optimize your prompts with automated prompt engineering algorithms like **[GEPA](https://www.tensorzero.com/docs/optimization/gepa)** and MIPROv2
- [x] Optimize your **[inference strategy](https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations)** with dynamic in-context learning, best/mixture-of-N sampling, etc.
- [x] Enable a feedback loop for your LLMs: a data &amp; learning flywheel turning production data into smarter, faster, and cheaper models
- [ ] Soon: synthetic data generation

### üìä LLM Evaluation

&gt; **Compare prompts, models, and inference strategies using evaluations powered by heuristics and LLM judges.**

- [x] **[Evaluate individual inferences](https://www.tensorzero.com/docs/evaluations/inference-evaluations/tutorial)** with _inference evaluations_ powered by heuristics or LLM judges (&amp;approx; unit tests for LLMs)
- [x] **[Evaluate end-to-end workflows](https://www.tensorzero.com/docs/evaluations/workflow-evaluations/tutorial)** with _workflow evaluations_ with complete flexibility (&amp;approx; integration tests for LLMs)
- [x] Optimize LLM judges just like any other TensorZero function to align them to human preferences
- [ ] Soon: more built-in evaluators; headless evaluations

&lt;table&gt;
  &lt;tr&gt;&lt;/tr&gt; &lt;!-- flip highlight order --&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Evaluation ¬ª UI&lt;/b&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;b&gt;Evaluation ¬ª CLI&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot; align=&quot;center&quot; valign=&quot;middle&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/f4bf54e3-1b63-46c8-be12-2eaabf615699&quot;&gt;&lt;/td&gt;
    &lt;td width=&quot;50%&quot; align=&quot;left&quot; valign=&quot;middle&quot;&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;docker compose run --rm evaluations \
  --evaluation-name extract_data \
  --dataset-name hard_test_cases \
  --variant-name gpt_4o \
  --concurrency 5&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&quot;language-bash&quot;&gt;Run ID: 01961de9-c8a4-7c60-ab8d-15491a9708e4
Number of datapoints: 100
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 100/100
exact_match: 0.83 ¬± 0.03 (n=100)
semantic_match: 0.98 ¬± 0.01 (n=100)
item_count: 7.15 ¬± 0.39 (n=100)&lt;/code&gt;&lt;/pre&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

### üß™ LLM Experimentation

&gt; **Ship with confidence with built-in A/B testing, routing, fallbacks, retries, etc.**

- [x] **[Run adaptive A/B tests](https://www.tensorzero.com/docs/experimentation/run-adaptive-ab-tests)** to ship with confidence and identify the best prompts and models for your use cases.
- [x] Enforce principled experiments in complex workflows, including support for multi-turn LLM systems, sequential testing, and more.

### &amp; more!

&gt; **Build with an open-source stack well-suited for prototypes but designed from the ground up to support the most complex LLM applications and deployments.**

- [x] Build simple applications or massive deployments with GitOps-friendly orchestration
- [x] **[Extend TensorZero](https://www.tensorzero.com/docs/operations/extend-tensorzero)** with built-in escape hatches, programmatic-first usage, direct database access, and more
- [x] Integrate with third-party tools: specialized observability and evaluations, model providers, agent orchestration frameworks, etc.
- [x] Iterate quickly by experimenting with prompts interactively using the Playground UI

## Frequently Asked Questions

**How is TensorZero different from other LLM frameworks?**

1. TensorZero enables you to optimize complex LLM applications based on production metrics and human feedback.
2. TensorZero supports the needs of industrial-grade LLM applications: low latency, high throughput, type safety, self-hosted, GitOps, customizability, etc.
3. TensorZero unifies the entire LLMOps stack, creating compounding benefits. For example, LLM evaluations can be used for fine-tuning models alongside AI judges.

**Can I use TensorZero with \_\_\_?**

Yes.
Every major programming language is supported.
It plays nicely with the **[OpenAI SDK](https://www.tensorzero.com/docs/gateway/clients/)**, **[OpenTelemetry](https://www.tensorzero.com/docs/operations/export-opentelemetry-traces/)**, and **[every major LLM](https://www.tensorzero.com/docs/integrations/model-providers/)**.

**Is TensorZero production-ready?**

Yes.
TensorZero is used by companies ranging from frontier AI startups to the Fortune 50.

Here&#039;s a case study: **[Automating Code Changelogs at a Large Bank with LLMs](https://www.tensorzero.com/blog/case-study-automating-code-changelogs-at-a-large-bank-with-llms)**

**How much does TensorZero cost?**

TensorZero Stack (LLMOps platform) is 100% self-hosted and open-source.

TensorZero Autopilot (automated AI engineer) is a complementary paid product powered by the TensorZero Stack.

**Who is building TensorZero?**

Our technical team includes a former Rust compiler maintainer, machine learning researchers (Stanford, CMU, Oxford, Columbia) with thousands of citations, and the chief product officer of a decacorn startup. We&#039;re backed by the same investors as leading open-source projects (e.g. ClickHouse, CockroachDB) and AI labs (e.g. OpenAI, Anthropic). See our **[$7.3M seed round announcement](https://www.tensorzero.com/blog/tensorzero-raises-7-3m-seed-round-to-build-an-open-source-stack-for-industrial-grade-llm-applications/)** and **[coverage from VentureBeat](https://venturebeat.com/ai/tensorzero-nabs-7-3m-seed-to-solve-the-messy-world-of-enterprise-llm-development/)**. We&#039;re **[hiring in NYC](https://www.tensorzero.com/jobs)**.

**How do I get started?**

You can adopt TensorZero incrementally. Our **[Quick Start](https://www.tensorzero.com/docs/quickstart)** goes from a vanilla OpenAI wrapper to a production-ready LLM application with observability and fine-tuning in just 5 minutes.

## Demo

&gt; **Watch LLMs get better at data extraction in real-time with TensorZero!**
&gt;
&gt; **[Dynamic in-context learning (DICL)](https://www.tensorzero.com/docs/gateway/guides/inference-time-optimizations#dynamic-in-context-learning-dicl)** is a powerful inference-time optimization available out of the box with TensorZero.
&gt; It enhances LLM performance by automatically incorporating relevant historical examples into the prompt, without the need for model fine-tuning.

https://github.com/user-attachments/assets/4df1022e-886e-48c2-8f79-6af3cdad79cb

## Get Started

**Start building today.**
The **[Quick Start](https://www.tensorzero.com/docs/quickstart)** shows it&#039;s easy to set up an LLM application with TensorZero.

**Questions?**
Ask us on **[Slack](https://www.tensorzero.com/slack)** or **[Discord](https://www.tensorzero.com/discord)**.

**Using TensorZero at work?**
Email us at **[hello@tensorzero.com](mailto:hello@tensorzero.com)** to set up a Slack or Teams channel with your team (free).

## Examples

We are working on a series of **complete runnable examples** illustrating TensorZero&#039;s data &amp; learning flywheel.

&gt; **[Optimizing Data Extraction (NER) with TensorZero](https://github.com/tensorzero/tensorzero/tree/main/examples/data-extraction-ner)**
&gt;
&gt; This example shows how to use TensorZero to optimize a data extraction pipeline.
&gt; We demonstrate techniques like fine-tuning and dynamic in-context learning (DICL).
&gt; In the end, an optimized GPT-4o Mini model outperforms GPT-4o on this task &amp;mdash; at a fraction of the cost and latency &amp;mdash; using a small amount of training data.

&gt; **[Agentic RAG ‚Äî Multi-Hop Question Answering with LLMs](https://github.com/tensorzero/tensorzero/tree/main/examples/rag-retrieval-augmented-generation/simple-agentic-rag/)**
&gt;
&gt; This example shows how to build a multi-hop retrieval agent using TensorZero.
&gt; The agent iteratively searches Wikipedia to gather information, and decides when it has enough context to answer a complex question.

&gt; **[Writing Haikus to Satisfy a Judge with Hidden Preferences](https://github.com/tensorzero/tensorzero/tree/main/examples/haiku-hidden-preferences)**
&gt;
&gt; This example fine-tunes GPT-4o Mini to generate haikus tailored to a specific taste.
&gt; You&#039;ll see TensorZero&#039;s &quot;data flywheel in a box&quot; in action: better variants leads to better data, and better data leads to better variants.
&gt; You&#039;ll see progress by fine-tuning the LLM multiple times.

&gt; **[Image Data Extraction ‚Äî Multimodal (Vision) Fine-tuning](https://github.com/tensorzero/tensorzero/tree/main/examples/multimodal-vision-finetuning)**
&gt;
&gt; This example shows how to fine-tune multimodal models (VLMs) like GPT-4o to improve their performance on vision-language tasks.
&gt; Specifically, we&#039;ll build

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tokio-rs/tracing]]></title>
            <link>https://github.com/tokio-rs/tracing</link>
            <guid>https://github.com/tokio-rs/tracing</guid>
            <pubDate>Fri, 13 Feb 2026 00:08:47 GMT</pubDate>
            <description><![CDATA[Application level tracing for Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tokio-rs/tracing">tokio-rs/tracing</a></h1>
            <p>Application level tracing for Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 6,513</p>
            <p>Forks: 876</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>![Tracing ‚Äî Structured, application-level diagnostics][splash]

[splash]: https://raw.githubusercontent.com/tokio-rs/tracing/main/assets/splash.svg

[![Crates.io][crates-badge]][crates-url]
[![Documentation][docs-badge]][docs-url]
[![Documentation (v0.2.x)][docs-v0.2.x-badge]][docs-v0.2.x-url]
[![MIT licensed][mit-badge]][mit-url]
[![Build Status][actions-badge]][actions-url]
[![Discord chat][discord-badge]][discord-url]

[crates-badge]: https://img.shields.io/crates/v/tracing.svg
[crates-url]: https://crates.io/crates/tracing
[docs-badge]: https://docs.rs/tracing/badge.svg
[docs-url]: https://docs.rs/tracing
[docs-v0.2.x-badge]: https://img.shields.io/badge/docs-v0.2.x-blue
[docs-v0.2.x-url]: https://tracing.rs
[mit-badge]: https://img.shields.io/badge/license-MIT-blue.svg
[mit-url]: LICENSE
[actions-badge]: https://github.com/tokio-rs/tracing/workflows/CI/badge.svg
[actions-url]: https://github.com/tokio-rs/tracing/actions?query=workflow%3ACI
[discord-badge]: https://img.shields.io/discord/500028886025895936?logo=discord&amp;label=discord&amp;logoColor=white
[discord-url]: https://discord.gg/EeF3cQw

[Website](https://tokio.rs) |
[Chat](https://discord.gg/EeF3cQw)

## Overview

`tracing` is a framework for instrumenting Rust programs to collect
structured, event-based diagnostic information. `tracing` is maintained by the
Tokio project, but does _not_ require the `tokio` runtime to be used.

### Branch set-up

- [`main`](https://github.com/tokio-rs/tracing/tree/main) - Default branch, crates.io releases are done from this branch. This was previously the
  `v0.1.x` branch.
- [`v0.2.x`](https://github.com/tokio-rs/tracing/tree/v0.2.x) - Branch containing the as-yet unreleased 0.2 version of `tracing-core`, `tracing`, and
  all the other tracing crates that depend on these versions. This was previously the `master`
  branch.

## Usage

### In Applications

In order to record trace events, executables have to use a `Subscriber`
implementation compatible with `tracing`. A `Subscriber` implements a way of
collecting trace data, such as by logging it to standard output.
[`tracing-subscriber`][tracing-subscriber-docs]&#039;s [`fmt` module][fmt] provides
a subscriber for logging traces with reasonable defaults. Additionally,
`tracing-subscriber` is able to consume messages emitted by `log`-instrumented
libraries and modules.

To use `tracing-subscriber`, add the following to your `Cargo.toml`:

```toml
[dependencies]
tracing = &quot;0.1&quot;
tracing-subscriber = &quot;0.3&quot;
```

Then create and install a `Subscriber`, for example using [`init()`]:

```rust
use tracing::info;
use tracing_subscriber;

fn main() {
    // install global subscriber configured based on RUST_LOG envvar.
    tracing_subscriber::fmt::init();

    let number_of_yaks = 3;
    // this creates a new event, outside of any spans.
    info!(number_of_yaks, &quot;preparing to shave yaks&quot;);

    let number_shaved = yak_shave::shave_all(number_of_yaks);
    info!(
        all_yaks_shaved = number_shaved == number_of_yaks,
        &quot;yak shaving completed.&quot;
    );
}
```

Using `init()` calls [`set_global_default()`] so this subscriber will be used
as the default in all threads for the remainder of the duration of the
program, similar to how loggers work in the `log` crate.

[tracing-subscriber-docs]: https://docs.rs/tracing-subscriber/
[fmt]: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/fmt/index.html
[`set_global_default`]: https://docs.rs/tracing/latest/tracing/subscriber/fn.set_global_default.html


For more control, a subscriber can be built in stages and not set globally,
but instead used to locally override the default subscriber. For example:

```rust
use tracing::{info, Level};
use tracing_subscriber;

fn main() {
    let subscriber = tracing_subscriber::fmt()
        // filter spans/events with level TRACE or higher.
        .with_max_level(Level::TRACE)
        // build but do not install the subscriber.
        .finish();

    tracing::subscriber::with_default(subscriber, || {
        info!(&quot;This will be logged to stdout&quot;);
    });
    info!(&quot;This will _not_ be logged to stdout&quot;);
}
```

Any trace events generated outside the context of a subscriber will not be collected.

This approach allows trace data to be collected by multiple subscribers
within different contexts in the program. Note that the override only applies to the
currently executing thread; other threads will not see the change from with_default.

Once a subscriber has been set, instrumentation points may be added to the
executable using the `tracing` crate&#039;s macros.

[`tracing-subscriber`]: https://docs.rs/tracing-subscriber/
[fmt]: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/fmt/index.html
[`init()`]: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/fmt/fn.init.html
[`set_global_default()`]: https://docs.rs/tracing/latest/tracing/subscriber/fn.set_global_default.html

### In Libraries

Libraries should only rely on the `tracing` crate and use the provided macros
and types to collect whatever information might be useful to downstream consumers.

```rust
use std::{error::Error, io};
use tracing::{debug, error, info, span, warn, Level};

// the `#[tracing::instrument]` attribute creates and enters a span
// every time the instrumented function is called. The span is named after the
// function or method. Parameters passed to the function are recorded as fields.
#[tracing::instrument]
pub fn shave(yak: usize) -&gt; Result&lt;(), Box&lt;dyn Error + &#039;static&gt;&gt; {
    // this creates an event at the DEBUG level with two fields:
    // - `excitement`, with the key &quot;excitement&quot; and the value &quot;yay!&quot;
    // - `message`, with the key &quot;message&quot; and the value &quot;hello! I&#039;m gonna shave a yak.&quot;
    //
    // unlike other fields, `message`&#039;s shorthand initialization is just the string itself.
    debug!(excitement = &quot;yay!&quot;, &quot;hello! I&#039;m gonna shave a yak.&quot;);
    if yak == 3 {
        warn!(&quot;could not locate yak!&quot;);
        // note that this is intended to demonstrate `tracing`&#039;s features, not idiomatic
        // error handling! in a library or application, you should consider returning
        // a dedicated `YakError`. libraries like snafu or thiserror make this easy.
        return Err(io::Error::new(io::ErrorKind::Other, &quot;shaving yak failed!&quot;).into());
    } else {
        debug!(&quot;yak shaved successfully&quot;);
    }
    Ok(())
}

pub fn shave_all(yaks: usize) -&gt; usize {
    // Constructs a new span named &quot;shaving_yaks&quot; at the TRACE level,
    // and a field whose key is &quot;yaks&quot;. This is equivalent to writing:
    //
    // let span = span!(Level::TRACE, &quot;shaving_yaks&quot;, yaks = yaks);
    //
    // local variables (`yaks`) can be used as field values
    // without an assignment, similar to struct initializers.
    let span = span!(Level::TRACE, &quot;shaving_yaks&quot;, yaks);
    let _enter = span.enter();

    info!(&quot;shaving yaks&quot;);

    let mut yaks_shaved = 0;
    for yak in 1..=yaks {
        let res = shave(yak);
        debug!(yak, shaved = res.is_ok());

        if let Err(ref error) = res {
            // Like spans, events can also use the field initialization shorthand.
            // In this instance, `yak` is the field being initialized.
            error!(yak, error = error.as_ref(), &quot;failed to shave yak!&quot;);
        } else {
            yaks_shaved += 1;
        }
        debug!(yaks_shaved);
    }

    yaks_shaved
}
```

```toml
[dependencies]
tracing = &quot;0.1&quot;
```

Note: Libraries should *NOT* install a subscriber by using a method that calls
[`set_global_default()`], as this will cause conflicts when executables try to
set the default later.

### In Asynchronous Code

To trace `async fn`s, the preferred method is using the [`#[instrument]`][instrument] attribute:

```rust
use tracing::{info, instrument};
use tokio::{io::AsyncWriteExt, net::TcpStream};
use std::io;

#[instrument]
async fn write(stream: &amp;mut TcpStream) -&gt; io::Result&lt;usize&gt; {
    let result = stream.write(b&quot;hello world\n&quot;).await;
    info!(&quot;wrote to stream; success={:?}&quot;, result.is_ok());
    result
}
```

Special handling is needed for the general case of code using
[`std::future::Future`][std-future] or blocks with `async`/`await`, as the
following example _will not_ work:

```rust
async {
    let _s = span.enter();
    // ...
}
```

The span guard `_s` will not exit until the future generated by the `async` block is complete.
Since futures and spans can be entered and exited _multiple_ times without them completing,
the span remains entered for as long as the future exists, rather than being entered only when
it is polled, leading to very confusing and incorrect output.
For more details, see [the documentation on closing spans][closing].

This problem can be solved using the [`Future::instrument`] combinator:

```rust
use tracing::Instrument;

let my_future = async {
    // ...
};

my_future
    .instrument(tracing::info_span!(&quot;my_future&quot;))
    .await
```

`Future::instrument` attaches a span to the future, ensuring that the span&#039;s lifetime
is as long as the future&#039;s.

Under the hood, the [`#[instrument]`][instrument] macro performs the same explicit span
attachment that `Future::instrument` does.

[std-future]: https://doc.rust-lang.org/stable/std/future/trait.Future.html
[closing]: https://docs.rs/tracing/latest/tracing/span/index.html#closing-spans
[`Future::instrument`]: https://docs.rs/tracing/latest/tracing/trait.Instrument.html#method.instrument
[instrument]: https://docs.rs/tracing/latest/tracing/attr.instrument.html

## Supported Rust Versions

Tracing is built against the latest stable release. The minimum supported
version is 1.65. The current Tracing version is not guaranteed to build on Rust
versions earlier than the minimum supported version.

Tracing follows the same compiler support policies as the rest of the Tokio
project. The current stable Rust compiler and the three most recent minor
versions before it will always be supported. For example, if the current stable
compiler version is 1.69, the minimum supported version will not be increased
past 1.66, three minor versions prior. Increasing the minimum supported compiler
version is not considered a semver breaking change as long as doing so complies
with this policy.

## Getting Help

First, see if the answer to your question can be found in the API documentation.
If the answer is not there, there is an active community in
the [Tracing Discord channel][chat]. We would be happy to try to answer your
question. Last, if that doesn&#039;t work, try opening an [issue] with the question.

[chat]: https://discord.gg/EeF3cQw
[issue]: https://github.com/tokio-rs/tracing/issues/new

## Contributing

:balloon: Thanks for your help improving the project! We are so happy to have
you! We have a [contributing guide][guide] to help you get involved in the Tracing
project.

[guide]: CONTRIBUTING.md

## Project layout

The [`tracing`] crate contains the primary _instrumentation_ API, used for
instrumenting libraries and applications to emit trace data. The [`tracing-core`]
crate contains the _core_ API primitives on which the rest of `tracing` is
instrumented. Authors of trace subscribers may depend on `tracing-core`, which
guarantees a higher level of stability.

Additionally, this repository contains several compatibility and utility
libraries built on top of `tracing`. Some of these crates are in a pre-release
state, and are less stable than the `tracing` and `tracing-core` crates.

The crates included as part of Tracing are:

* [`tracing-futures`]: Utilities for instrumenting `futures`.
  ([crates.io][fut-crates]|[docs][fut-docs])

* [`tracing-macros`]: Experimental macros for emitting trace events (unstable).

* [`tracing-attributes`]: Procedural macro attributes for automatically
    instrumenting functions. ([crates.io][attr-crates]|[docs][attr-docs])

* [`tracing-log`]: Compatibility with the `log` crate (unstable).

* [`tracing-serde`]: A compatibility layer for serializing trace data with
    `serde` (unstable).

* [`tracing-subscriber`]: Subscriber implementations, and utilities for
  implementing and composing `Subscriber`s.
  ([crates.io][sub-crates]|[docs][sub-docs])

* [`tracing-tower`]: Compatibility with the `tower` ecosystem (unstable).

* [`tracing-appender`]: Utilities for outputting tracing data, including a file appender
   and non-blocking writer. ([crates.io][app-crates]|[docs][app-docs])

* [`tracing-error`]: Provides `SpanTrace`, a type for instrumenting errors with
  tracing spans. ([crates.io][err-crates]|[docs][err-docs])

* [`tracing-flame`]: Provides a layer for generating flame graphs based on
  tracing span entry / exit events. ([crates.io][flame-crates]|[docs][flame-docs])

* [`tracing-journald`]: Provides a layer for recording events to the
  Linux `journald` service, preserving structured data. ([crates.io][jour-crates]|[docs][jour-docs])

[`tracing`]: tracing
[`tracing-core`]: tracing-core
[`tracing-futures`]: tracing-futures
[`tracing-macros`]: tracing-macros
[`tracing-attributes`]: tracing-attributes
[`tracing-log`]: tracing-log
[`tracing-serde`]: tracing-serde
[`tracing-subscriber`]: tracing-subscriber
[`tracing-tower`]: tracing-tower
[`tracing-appender`]: tracing-appender
[`tracing-error`]: tracing-error
[`tracing-flame`]: tracing-flame
[`tracing-journald`]: tracing-journald

[fut-crates]: https://crates.io/crates/tracing-futures
[fut-docs]: https://docs.rs/tracing-futures

[attr-crates]: https://crates.io/crates/tracing-attributes
[attr-docs]: https://docs.rs/tracing-attributes

[sub-crates]: https://crates.io/crates/tracing-subscriber
[sub-docs]: https://docs.rs/tracing-subscriber

[otel-crates]: https://crates.io/crates/tracing-opentelemetry
[otel-docs]: https://docs.rs/tracing-opentelemetry
[OpenTelemetry]: https://opentelemetry.io/

[app-crates]: https://crates.io/crates/tracing-appender
[app-docs]: https://docs.rs/tracing-appender

[err-crates]: https://crates.io/crates/tracing-error
[err-docs]: https://docs.rs/tracing-error

[flame-crates]: https://crates.io/crates/tracing-flame
[flame-docs]: https://docs.rs/tracing-flame

[jour-crates]: https://crates.io/crates/tracing-journald
[jour-docs]: https://docs.rs/tracing-journald

## Related Crates

In addition to this repository, here are also several third-party crates which
are not maintained by the `tokio` project. These include:

- [`tracing-timing`] implements inter-event timing metrics on top of `tracing`.
  It provides a subscriber that records the time elapsed between pairs of
  `tracing` events and generates histograms.
- [`tracing-honeycomb`] Provides a layer that reports traces spanning multiple machines to [honeycomb.io]. Backed by [`tracing-distributed`].
- [`tracing-distributed`] Provides a generic implementation of a layer that reports traces spanning multiple machines to some backend.
- [`tracing-actix-web`] provides `tracing` integration for the `actix-web` web framework.
- [`tracing-actix`] provides `tracing` integration for the `actix` actor
  framework.
- [`axum-insights`] provides `tracing` integration and Application insights export for the `axum` web framework.
- [`tracing-gelf`] implements a subscriber for exporting traces in Graylog
  GELF format.
- [`tracing-coz`] provides integration with the [coz] causal profiler
  (Linux-only).
- [`tracing-bunyan-formatter`] provides a layer implementation that reports events and spans in [bunyan] format, enriched with timing information.
- [`tide-tracing`] provides a [tide] middleware to trace all incoming requests and responses.
- [`color-spantrace`] provides a formatter for rendering span traces in the
  style of `color-backtrace`
- [`color-eyre`] provides customized panic and eyre report handlers for
  `eyre::Report` for capturing span traces and backtraces with new errors and
  pretty printing them.
- [`spandoc`] provides a proc macro for constructing spans from doc comments
  _inside_ of functions.
- [`tracing-wasm`] provides a `Subscriber`/`Layer` implementation that reports
  events and spans via browser `console.log` and [User Timing API (`window.performance`)].
- [`tracing-web`] provides a layer implementation of level-aware logging of events
  to web browsers&#039; `console.*` and span events to the [User Timing API (`window.performance`)].
- [`test-log`] takes care of initializing `tracing` for tests, based on
  environment variables with an `env_logger` compatible syntax.
- [`tracing-unwrap`] provides convenience methods to report failed unwraps on `Result` or `Option` types to a `Subscriber`.
- [`diesel-tracing`] provides integration with [`diesel`] database connections.
- [`tracing-tracy`] provides a way to collect [Tracy] profiles in instrumented
  applications.
- [`tracing-elastic-apm`] provides a layer for reporting traces to [Elastic APM].
- [`tracing-etw`] provides a layer for emitting Windows [ETW] events.
- [`sentry-tracing`] provides a layer for reporting events and traces to [Sentry].
- [`tracing-forest`] provides a subscriber that preserves contextual coherence by
  grouping together logs from the same spans during writing.
- [`tracing-loki`] provides a layer for shipping logs to [Grafana Loki].
- [`tracing-logfmt`] provides a layer that formats events and spans into the logfmt format.
- [`tracing-chrome`] provides a layer that exports trace data that can be viewed in `chrome://tracing`.
- [`reqwest-tracing`] provides a middleware to trace [`reqwest`] HTTP requests.
- [`tracing-cloudwatch`] provides a layer that sends events to AWS CloudWatch Logs.
- [`tracing-subscriber-reload-arcswap`] provides a lock-free alternative to `tracing_subscriber::reload::Layer` using `arc-swap`.
- [`clippy-tracing`] provides a tool to add, remove and check for `tracing::instrument`.

(if you&#039;re the maintainer of a `tracing` ecosystem crate not in this list,
please let us know!)

[`tracing-timing`]: https://crates.io/crates/tracing-timing
[`tracing-honeycomb`]: https://crates.io/crates/tracing-honeycomb
[`tracing-distributed`]: https://crates.io/crates/tracing-distributed
[honeycomb.io]: https://www.honeycomb.io/
[`tracing-actix`]: https://crates.io/crates/tracing-actix
[`tracing-actix-web`]: https://crates.io/crates/tracing-actix-web
[`axum-insights`]: https://crates.io/crates/axum-insights
[`tracing-gelf`]: https://crates.io/crates/tracing-gelf
[`tracing-coz`]: https://crates.io/crates/tracing-coz
[coz]: https://github.com/plasma-umass/coz
[`tracing-bunyan-formatter`]: https://crates.io/crates/tracing-bunyan-formatter
[`tide-tracing`]: https://crates.io/crates/tide-tracing
[tide]: https://crates.io/crates/tide
[bunyan]: https://github.com/trentm/node-bunyan
[`color-spantrace`]: https://docs.rs/color-spantrace
[`color-eyre`]: https://docs.rs/color-eyre
[`spandoc`]: https://docs.rs/spandoc
[`tracing-wasm`]: https://docs.rs/tracing-wasm
[`tracing-web`]: https://crates.io/crates/tracing-web
[`test-log`]: https://crates.io/crates/test-log
[User Timing API (`window.performance`)]: https://developer.mozilla.org/en-US/docs/Web/API/User_Timing_API
[`tracing-unwrap`]: https://docs.rs/tracing-unwrap
[`diesel`]: https://crates.io/crates/diesel
[`diesel-tracing`]: https://crates.io/crates/diesel-tracing
[`tracing-tracy`]: https://crates.io/crates/tracing-tracy
[Tracy]: https://github.com/wolfpld/tracy
[`tracing-elastic-apm`]: https://crates.io/crates/tracing-elastic-apm
[Elastic APM]: https://www.elastic.co/apm
[`tracing-etw`]: https://github.com/microsoft/rust_win_etw/tree/main/win_etw_tracing
[ETW]: https://docs.microsoft.com/en-us/windows/win32/etw/about-event-tracing
[`sentry-tracing`]: https://crates.io/crates/sentry-tracing
[Sentry]: https://sentry.io/welcome/
[`tracing-forest`]: https://crates.io/crates/tracing-forest
[`tracing-loki`]: https://crates.io/crates/tracing-loki
[Grafana Loki]: https://grafana.com/oss/loki/
[`tracing-logfmt`]: https://crates.io/crates/tracing-logfmt
[`tracing-chrome`]: https://crates.io/crates/tracing-chrome
[`reqwest-tracing`]: https://crates.io/crates/reqwest-tracing
[`reqwest`]: https://crates.io/crates/r

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>