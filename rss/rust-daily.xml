<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Sun, 01 Mar 2026 00:06:49 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[clockworklabs/SpacetimeDB]]></title>
            <link>https://github.com/clockworklabs/SpacetimeDB</link>
            <guid>https://github.com/clockworklabs/SpacetimeDB</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:49 GMT</pubDate>
            <description><![CDATA[Development at the speed of light]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/clockworklabs/SpacetimeDB">clockworklabs/SpacetimeDB</a></h1>
            <p>Development at the speed of light</p>
            <p>Language: Rust</p>
            <p>Stars: 21,588</p>
            <p>Forks: 785</p>
            <p>Stars today: 311 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
	&lt;img width=&quot;320&quot; src=&quot;./images/dark/logo.svg&quot; alt=&quot;SpacetimeDB Logo&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
	&lt;img width=&quot;320&quot; src=&quot;./images/light/logo.svg&quot; alt=&quot;SpacetimeDB Logo&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
        &lt;img width=&quot;250&quot; src=&quot;./images/dark/logo-text.svg&quot; alt=&quot;SpacetimeDB&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
        &lt;img width=&quot;250&quot; src=&quot;./images/light/logo-text.svg&quot; alt=&quot;SpacetimeDB&quot;&gt;
    &lt;/a&gt;
    &lt;h3 align=&quot;center&quot;&gt;
        Development at the speed of light.
    &lt;/h3&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/clockworklabs/spacetimedb?color=%23ff00a0&amp;include_prereleases&amp;label=version&amp;sort=semver&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/built_with-Rust-dca282.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
	&lt;a href=&quot;https://github.com/clockworklabs/spacetimedb/actions&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/clockworklabs/spacetimedb/ci.yml?style=flat-square&amp;branch=master&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://status.spacetimedb.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/uptimerobot/ratio/7/m784409192-e472ca350bb615372ededed7?label=cloud%20uptime&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://hub.docker.com/r/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/clockworklabs/spacetimedb?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb/blob/master/LICENSE.txt&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-BSL_1.1-00bfff.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://crates.io/crates/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/d/spacetimedb?color=e45928&amp;label=Rust%20Crate&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.nuget.org/packages/SpacetimeDB.Runtime&quot;&gt;&lt;img src=&quot;https://img.shields.io/nuget/dt/spacetimedb.runtime?color=0b6cff&amp;label=NuGet%20Package&amp;style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://discord.gg/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1037340874172014652?label=discord&amp;style=flat-square&amp;color=5a66f6&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitter.com/spacetime_db&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/twitter-Follow_us-1d9bf0.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://clockworklabs.io/join&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/careers-Join_us-86f7b7.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/clockworklabs/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/linkedin-Connect_with_us-0a66c2.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://discord.gg/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/discord.svg&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitter.com/spacetime_db&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/twitter.svg&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/github.svg&quot; alt=&quot;GitHub&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitch.tv/SpacetimeDB&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/twitch.svg&quot; alt=&quot;Twitch&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://youtube.com/@SpacetimeDB&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/youtube.svg&quot; alt=&quot;YouTube&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/clockwork-labs/&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/linkedin.svg&quot; alt=&quot;LinkedIn&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://stackoverflow.com/questions/tagged/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/stackoverflow.svg&quot; alt=&quot;StackOverflow&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

## What is [SpacetimeDB](https://spacetimedb.com)?

You can think of SpacetimeDB as both a database and server combined into one.

It is a relational database system that lets you upload your application logic directly into the database by way of fancy stored procedures called &quot;modules.&quot;

Instead of deploying a web or game server that sits in between your clients and your database, your clients connect directly to the database and execute your application logic inside the database itself. You can write all of your permission and authorization logic right inside your module just as you would in a normal server.

This means that you can write your entire application in a single language, Rust, and deploy it as a single binary. No more microservices, no more containers, no more Kubernetes, no more Docker, no more VMs, no more DevOps, no more infrastructure, no more ops, no more servers.

&lt;figure&gt;
    &lt;img src=&quot;./images/basic-architecture-diagram.png&quot; alt=&quot;SpacetimeDB Architecture&quot; style=&quot;width:100%&quot;&gt;
    &lt;figcaption align=&quot;center&quot;&gt;
        &lt;p align=&quot;center&quot;&gt;&lt;b&gt;SpacetimeDB application architecture&lt;/b&gt;&lt;br /&gt;&lt;sup&gt;&lt;sub&gt;(elements in white are provided by SpacetimeDB)&lt;/sub&gt;&lt;/sup&gt;&lt;/p&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;

It&#039;s actually similar to the idea of smart contracts, except that SpacetimeDB is a database, has nothing to do with blockchain, and is orders of magnitude faster than any smart contract system.

So fast, in fact, that the entire backend of our MMORPG [BitCraft Online](https://bitcraftonline.com) is just a SpacetimeDB module. We don&#039;t have any other servers or services running, which means that everything in the game, all of the chat messages, items, resources, terrain, and even the locations of the players are stored and processed by the database before being synchronized out to all of the clients in real-time.

SpacetimeDB is optimized for maximum speed and minimum latency rather than batch processing or OLAP workloads. It is designed to be used for real-time applications like games, chat, and collaboration tools.

This speed and latency is achieved by holding all of application state in memory, while persisting the data in a write-ahead-log (WAL) which is used to recover application state.

## Installation

You can run SpacetimeDB as a standalone database server via the `spacetime` CLI tool.
Install instructions for supported platforms are outlined below.
The same install instructions can be found on our website at https://spacetimedb.com/install.

#### Install on macOS

Installing on macOS is as simple as running our install script. After that you can use the spacetime command to manage versions.

```bash
curl -sSf https://install.spacetimedb.com | sh
```

#### Install on Linux

Installing on Linux is as simple as running our install script. After that you can use the spacetime command to manage versions.

```bash
curl -sSf https://install.spacetimedb.com | sh
```

#### Install on Windows

Installing on Windows is as simple as pasting the snippet below into PowerShell. If you would like to use WSL instead, please follow the Linux install instructions.

```ps1
iwr https://windows.spacetimedb.com -useb | iex
```

#### Installing from Source

A quick note on installing from source: we recommend that you don&#039;t install from source unless there is a feature that is available in `master` that hasn&#039;t been released yet, otherwise follow the official installation instructions.

##### MacOS + Linux

Installing on macOS + Linux is pretty straightforward. First we are going to build all of the binaries that we need:

```bash
# Install rustup, you can skip this step if you have cargo and the wasm32-unknown-unknown target already installed.
curl https://sh.rustup.rs -sSf | sh
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
mkdir -p ~/.local/bin
export STDB_VERSION=&quot;$(./target/release/spacetimedb-cli --version | sed -n &#039;s/.*spacetimedb tool version \([0-9.]*\);.*/\1/p&#039;)&quot;
mkdir -p ~/.local/share/spacetime/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/.local/bin/spacetime
cp target/release/spacetimedb-cli ~/.local/share/spacetime/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/.local/share/spacetime/bin/$STDB_VERSION
```

At this stage you&#039;ll need to add ~/.local/bin to your path if you haven&#039;t already.

```
# Please add the following line to your shell configuration and open a new shell session:
export PATH=&quot;$HOME/.local/bin:$PATH&quot;

```

Then finally set your SpacetimeDB version:
```

# Then, in a new shell, set the current version:
spacetime version use $STDB_VERSION

# If STDB_VERSION is not set anymore then you can use the following command to list your versions:
spacetime version list
```

You can verify that the correct version has been installed via `spacetime --version`.

##### Windows

Building on windows is a bit more complicated. You&#039;ll need a slightly different version of perl compared to what comes pre-bundled in most Windows terminals. We recommend [Strawberry Perl](https://strawberryperl.com/). You may also need access to an `openssl` binary which actually comes pre-installed with [Git for Windows](https://git-scm.com/downloads/win). Also, you&#039;ll need to install [rustup](https://rustup.rs/) for Windows.

In a Git for Windows shell you should have something that looks like this:
```
$ which perl
/c/Strawberry/perl/bin/perl
$ which openssl
/mingw64/bin/openssl
$ which cargo 
/c/Users/&lt;user&gt;/.cargo/bin/cargo
```

If that looks correct then you&#039;re ready to proceed!

```powershell
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB

# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
$stdbDir = &quot;$HOME\AppData\Local\SpacetimeDB&quot;
$stdbVersion = &amp; &quot;.\target\release\spacetimedb-cli&quot; --version | Select-String -Pattern &#039;spacetimedb tool version ([0-9.]+);&#039; | ForEach-Object { $_.Matches.Groups[1].Value }
New-Item -ItemType Directory -Path &quot;$stdbDir\bin\$stdbVersion&quot; -Force | Out-Null

# Install the update binary
Copy-Item &quot;target\release\spacetimedb-update.exe&quot; &quot;$stdbDir\spacetime.exe&quot;
Copy-Item &quot;target\release\spacetimedb-cli.exe&quot; &quot;$stdbDir\bin\$stdbVersion\&quot;
Copy-Item &quot;target\release\spacetimedb-standalone.exe&quot; &quot;$stdbDir\bin\$stdbVersion\&quot;

```

Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!

```
%USERPROFILE%\AppData\Local\SpacetimeDB
```

Then finally, open a new shell and use the installed SpacetimeDB version:
```
spacetime version use $stdbVersion

# If stdbVersion is no longer set, list versions using the following command:
spacetime version list
```

You can verify that the correct version has been installed via `spacetime --version`.

If you&#039;re using Git for Windows you can follow these instructions instead:

```bash
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
# Build the CLI binaries - this takes a while on windows so go grab a coffee :)
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
export STDB_VERSION=&quot;$(./target/release/spacetimedb-cli --version | sed -n &#039;s/.*spacetimedb tool version \([0-9.]*\);.*/\1/p&#039;)&quot;
mkdir -p ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/AppData/Local/SpacetimeDB/spacetime
cp target/release/spacetimedb-cli ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!
# %USERPROFILE%\AppData\Local\SpacetimeDB

# Set the current version
spacetime version use $STDB_VERSION
```

You can verify that the correct version has been installed via `spacetime --version`.

#### Running with Docker

If you prefer to run Spacetime in a container, you can use the following command to start a new instance.

```bash
docker run --rm --pull always -p 3000:3000 clockworklabs/spacetime start
```

## Documentation

For more information about SpacetimeDB, getting started guides, game development guides, and reference material please see our [documentation](https://spacetimedb.com/docs).

## Getting Started

We&#039;ve prepared several getting started guides in each of our supported languages to help you get up and running with SpacetimeDB as quickly as possible. You can find them on our [docs page](https://spacetimedb.com/docs).

In summary there are only 4 steps to getting started with SpacetimeDB.

1. Install the `spacetime` CLI tool.
2. Start a SpacetimeDB standalone node with `spacetime start`.
3. Write and upload a module in one of our supported module languages.
4. Connect to the database with one of our client libraries.

You can see a summary of the supported languages below with a link to the getting started guide for each.

## Language Support

You can write SpacetimeDB modules in several popular languages, with more to come in the future!

#### Serverside Libraries

- [Rust](https://spacetimedb.com/docs/modules/rust/quickstart)
- [C#](https://spacetimedb.com/docs/modules/c-sharp/quickstart)

#### Client Libraries

- [Rust](https://spacetimedb.com/docs/sdks/rust/quickstart)
- [C#](https://spacetimedb.com/docs/sdks/c-sharp/quickstart)
- [Typescript](https://spacetimedb.com/docs/sdks/typescript/quickstart)

## License

SpacetimeDB is licensed under the BSL 1.1 license. This is not an open source or free software license, however, it converts to the AGPL v3.0 license with a linking exception after a few years.

Note that the AGPL v3.0 does not typically include a linking exception. We have added a custom linking exception to the AGPL license for SpacetimeDB. Our motivation for choosing a free software license is to ensure that contributions made to SpacetimeDB are propagated back to the community. We are expressly not interested in forcing users of SpacetimeDB to open source their own code if they link with SpacetimeDB, so we needed to include a linking exception.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:48 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 31,528</p>
            <p>Forks: 2,878</p>
            <p>Stars today: 113 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;
    &gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/goose-oss&quot;
    &gt;&lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;
     &gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.

[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)

# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)
- [Responsible AI-Assisted Coding Guide](https://github.com/block/goose/blob/main/HOWTOAI.md)
- [Governance](https://github.com/block/goose/blob/main/GOVERNANCE.md)
- [Custom Distributions](https://github.com/block/goose/blob/main/CUSTOM_DISTROS.md) - build your own goose distro with preconfigured providers, extensions, and branding

## Need Help?
- [Diagnostics &amp; Reporting](https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting)
- [Known Issues](https://block.github.io/goose/docs/troubleshooting/known-issues)

# a little goose humor ü™ø

&gt; Why did the developer choose goose as their AI agent?
&gt; 
&gt; Because it always helps them &quot;migrate&quot; their code to production! üöÄ

# goose around with us  
- [Discord](https://discord.gg/goose-oss)
- [YouTube](https://www.youtube.com/@goose-oss)
- [LinkedIn](https://www.linkedin.com/company/goose-oss)
- [Twitter/X](https://x.com/goose_oss)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustfs/rustfs]]></title>
            <link>https://github.com/rustfs/rustfs</link>
            <guid>https://github.com/rustfs/rustfs</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:47 GMT</pubDate>
            <description><![CDATA[üöÄ2.3x faster than MinIO for 4KB object payloads. RustFS is an open-source, S3-compatible high-performance object storage system supporting migration and coexistence with other S3-compatible platforms such as MinIO and Ceph.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustfs/rustfs">rustfs/rustfs</a></h1>
            <p>üöÄ2.3x faster than MinIO for 4KB object payloads. RustFS is an open-source, S3-compatible high-performance object storage system supporting migration and coexistence with other S3-compatible platforms such as MinIO and Ceph.</p>
            <p>Language: Rust</p>
            <p>Stars: 22,547</p>
            <p>Forks: 949</p>
            <p>Stars today: 84 stars today</p>
            <h2>README</h2><pre>[![RustFS](https://github.com/user-attachments/assets/3ba82e75-2f2d-4415-a4aa-1e4ffe9f22fd)](https://rustfs.com)

&lt;p align=&quot;center&quot;&gt;RustFS is a high-performance, distributed object storage system built in Rust.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/rustfs/rustfs/actions/workflows/ci.yml&quot;&gt;&lt;img alt=&quot;CI&quot; src=&quot;https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/rustfs/rustfs/actions/workflows/docker.yml&quot;&gt;&lt;img alt=&quot;Build and Push Docker Images&quot; src=&quot;https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/m/rustfs/rustfs&quot;/&gt;
  &lt;img alt=&quot;Github Last Commit&quot; src=&quot;https://img.shields.io/github/last-commit/rustfs/rustfs&quot;/&gt;
  &lt;a href=&quot;https://hellogithub.com/repository/rustfs/rustfs&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=b95bcb72bdc340b68f16fdf6790b7d5b&amp;claim_uid=MsbvjYeLDKAH457&amp;theme=small&quot; alt=&quot;FeaturedÔΩúHelloGitHub&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/14181&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14181&quot; alt=&quot;rustfs%2Frustfs | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt; 
&lt;a href=&quot;https://runacap.com/ross-index/q4-2025/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img style=&quot;width: 260px; height: 55px&quot; src=&quot;https://runacap.com/wp-content/uploads/2026/01/ROSS_badge_white_Q4_2025.svg&quot; alt=&quot;ROSS Index - Fastest Growing Open-Source Startups in Q4 2025 | Runa Capital&quot; height=&quot;55&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.rustfs.com/installation/&quot;&gt;Getting Started&lt;/a&gt;
  ¬∑ &lt;a href=&quot;https://docs.rustfs.com/&quot;&gt;Docs&lt;/a&gt;
  ¬∑ &lt;a href=&quot;https://github.com/rustfs/rustfs/issues&quot;&gt;Bug reports&lt;/a&gt;
  ¬∑ &lt;a href=&quot;https://github.com/rustfs/rustfs/discussions&quot;&gt;Discussions&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
English | &lt;a href=&quot;https://github.com/rustfs/rustfs/blob/main/README_ZH.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=de&quot;&gt;Deutsch&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=es&quot;&gt;Espa√±ol&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=fr&quot;&gt;fran√ßais&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=ja&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=ko&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=pt&quot;&gt;Portuguese&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=ru&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;
&lt;/p&gt;

RustFS is a high-performance, distributed object storage system built in Rust‚Äîone of the most loved programming languages worldwide. RustFS combines the simplicity of MinIO with the memory safety and raw performance of Rust. It offers full S3 compatibility, is completely open-source, and is optimized for data lakes, AI, and big data workloads.

Unlike other storage systems, RustFS is released under the permissible Apache 2.0 license, avoiding the restrictions of AGPL. With Rust as its foundation, RustFS delivers superior speed and secure distributed features for next-generation object storage.

## Feature &amp; Status

- **High Performance**: Built with Rust to ensure maximum speed and resource efficiency.
- **Distributed Architecture**: Scalable and fault-tolerant design suitable for large-scale deployments.
- **S3 Compatibility**: Seamless integration with existing S3-compatible applications and tools.
- **OpenStack Keystone Integration**: Native support for OpenStack Keystone authentication with X-Auth-Token headers.
- **Data Lake Support**: Optimized for high-throughput big data and AI workloads.
- **Open Source**: Licensed under Apache 2.0, encouraging unrestricted community contributions and commercial usage.
- **User-Friendly**: Designed with simplicity in mind for easy deployment and management.

| Feature                 | Status       | Feature                  | Status           |
| :---------------------- | :----------- | :----------------------- | :--------------- |
| **S3 Core Features**    | ‚úÖ Available | **Bitrot Protection**    | ‚úÖ Available     |
| **Upload / Download**   | ‚úÖ Available | **Single Node Mode**     | ‚úÖ Available     |
| **Versioning**          | ‚úÖ Available | **Bucket Replication**   | ‚úÖ Available     |
| **Logging**             | ‚úÖ Available | **Lifecycle Management** | üöß Under Testing |
| **Event Notifications** | ‚úÖ Available | **Distributed Mode**     | üöß Under Testing |
| **K8s Helm Charts**     | ‚úÖ Available | **RustFS KMS**           | üöß Under Testing |
| **Keystone Auth**       | ‚úÖ Available | **Multi-Tenancy**        | ‚úÖ Available     |

## RustFS vs MinIO Performance

**Stress Test Environment:**

| Type    | Parameter | Remark                                                   |
| ------- | --------- | -------------------------------------------------------- |
| CPU     | 2 Core    | Intel Xeon (Sapphire Rapids) Platinum 8475B, 2.7/3.2 GHz |
| Memory  | 4GB       |                                                          |
| Network | 15Gbps    |                                                          |
| Drive   | 40GB x 4  | IOPS 3800 / Drive                                        |

&lt;https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a&gt;

### RustFS vs Other Object Storage

| Feature                | RustFS                                                                                                                                                | Other Object Storage                                                                     |
| :--------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------- |
| **Console Experience** | **Powerful Console**&lt;br&gt;Comprehensive management interface.                                                                                           | **Basic / Limited Console**&lt;br&gt;Often overly simple or lacking critical features.         |
| **Language &amp; Safety**  | **Rust-based**&lt;br&gt;Memory safety by design.                                                                                                            | **Go or C-based**&lt;br&gt;Potential for memory GC pauses or leaks.                            |
| **Data Sovereignty**   | **No Telemetry / Full Compliance**&lt;br&gt;Guards against unauthorized cross-border data egress. Compliant with GDPR (EU/UK), CCPA (US), and APPI (Japan). | **Potential Risk**&lt;br&gt;Possible legal exposure and unwanted data telemetry.               |
| **Licensing**          | **Permissive Apache 2.0**&lt;br&gt;Business-friendly, no &quot;poison pill&quot; clauses.                                                                             | **Restrictive AGPL v3**&lt;br&gt;Risk of license traps and intellectual property pollution.    |
| **Compatibility**      | **100% S3 Compatible**&lt;br&gt;Works with any cloud provider or client, anywhere.                                                                          | **Variable Compatibility**&lt;br&gt;May lack support for local cloud vendors or specific APIs. |
| **Edge &amp; IoT**         | **Strong Edge Support**&lt;br&gt;Ideal for secure, innovative edge devices.                                                                                 | **Weak Edge Support**&lt;br&gt;Often too heavy for edge gateways.                              |
| **Risk Profile**       | **Enterprise Risk Mitigation**&lt;br&gt;Clear IP rights and safe for commercial use.                                                                        | **Legal Risks**&lt;br&gt;Intellectual property ambiguity and usage restrictions.               |

## Staying ahead

Star RustFS on GitHub and be instantly notified of new releases.

&lt;img src=&quot;https://github.com/user-attachments/assets/7ee40bb4-3e46-4eac-b0d0-5fbeb85ff8f3&quot; /&gt;

## Quickstart

To get started with RustFS, follow these steps:

### 1. One-click Installation (Option 1)

```bash
curl -O https://rustfs.com/install_rustfs.sh &amp;&amp; bash install_rustfs.sh
```

### 2\. Docker Quick Start (Option 2)

The RustFS container runs as a non-root user `rustfs` (UID `10001`). If you run Docker with `-v` to mount a host directory, please ensure the host directory owner is set to `10001`, otherwise you will encounter permission denied errors.

```bash
 # Create data and logs directories
 mkdir -p data logs

 # Change the owner of these directories
 chown -R 10001:10001 data logs

 # Using latest version
 docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:latest

 # Using specific version
 docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:1.0.0-alpha.76
```

If you use [podman](https://github.com/containers/podman) instead of docker, you can install the RustFS with the below command

```bash
 podman run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:latest
```

You can also use Docker Compose. Using the `docker-compose.yml` file in the root directory:

```bash
docker compose --profile observability up -d
```

Similarly, you can run the command with podman

```bash
podman compose --profile observability up -d
```

**NOTE**: We recommend reviewing the `docker-compose.yaml` file before running. It defines several services including Grafana, Prometheus, and Jaeger, which are helpful for RustFS observability. If you wish to start Redis or Nginx containers, you can specify the corresponding profiles.

### 3\. Build from Source (Option 3) - Advanced Users

For developers who want to build RustFS Docker images from source with multi-architecture support:

```bash
# Build multi-architecture images locally
./docker-buildx.sh --build-arg RELEASE=latest

# Build and push to registry
./docker-buildx.sh --push

# Build specific version
./docker-buildx.sh --release v1.0.0 --push

# Build for custom registry
./docker-buildx.sh --registry your-registry.com --namespace yourname --push
```

The `docker-buildx.sh` script supports:

- **Multi-architecture builds**: `linux/amd64`, `linux/arm64`
- **Automatic version detection**: Uses git tags or commit hashes
- **Registry flexibility**: Supports Docker Hub, GitHub Container Registry, etc.
- **Build optimization**: Includes caching and parallel builds

You can also use Make targets for convenience:

```bash
make docker-buildx                    # Build locally
make docker-buildx-push               # Build and push
make docker-buildx-version VERSION=v1.0.0  # Build specific version
make help-docker                      # Show all Docker-related commands
```

&gt; **Heads-up (macOS cross-compilation)**: macOS keeps the default `ulimit -n` at 256, so `cargo zigbuild` or `./build-rustfs.sh --platform ...` may fail with `ProcessFdQuotaExceeded` when targeting Linux. The build script attempts to raise the limit automatically, but if you still see the warning, run `ulimit -n 4096` (or higher) in your shell before building.

### 4\. Build with Helm Chart (Option 4) - Cloud Native

Follow the instructions in the [Helm Chart README](https://charts.rustfs.com/) to install RustFS on a Kubernetes cluster.

### 5\. Nix Flake (Option 5)

If you have [Nix with flakes enabled](https://nixos.wiki/wiki/Flakes#Enable_flakes):

```bash
# Run directly without installing
nix run github:rustfs/rustfs

# Build the binary
nix build github:rustfs/rustfs
./result/bin/rustfs --help

# Or from a local checkout
nix build
nix run
```

---

### Accessing RustFS

1. **Access the Console**: Open your web browser and navigate to `http://localhost:9001` to access the RustFS console.
    - Default credentials: `rustfsadmin` / `rustfsadmin`
2. **Create a Bucket**: Use the console to create a new bucket for your objects.
3. **Upload Objects**: You can upload files directly through the console or use S3-compatible APIs/clients to interact with your RustFS instance.

**NOTE**: To access the RustFS instance via `https`, please refer to the [TLS Configuration Docs](https://docs.rustfs.com/integration/tls-configured.html).

## Documentation

For detailed documentation, including configuration options, API references, and advanced usage, please visit our [Documentation](https://docs.rustfs.com).

## Getting Help

If you have any questions or need assistance:

- Check the [FAQ](https://github.com/rustfs/rustfs/discussions/categories/q-a) for common issues and solutions.
- Join our [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) to ask questions and share your experiences.
- Open an issue on our [GitHub Issues](https://github.com/rustfs/rustfs/issues) page for bug reports or feature requests.

## Links

- [Documentation](https://docs.rustfs.com) - The manual you should read
- [Changelog](https://github.com/rustfs/rustfs/releases) - What we broke and fixed
- [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) - Where the community lives

## Contact

- **Bugs**: [GitHub Issues](https://github.com/rustfs/rustfs/issues)
- **Business**: [hello@rustfs.com](mailto:hello@rustfs.com)
- **Jobs**: [jobs@rustfs.com](mailto:jobs@rustfs.com)
- **General Discussion**: [GitHub Discussions](https://github.com/rustfs/rustfs/discussions)
- **Contributing**: [CONTRIBUTING.md](CONTRIBUTING.md)

## Contributors

RustFS is a community-driven project, and we appreciate all contributions. Check out the [Contributors](https://github.com/rustfs/rustfs/graphs/contributors) page to see the amazing people who have helped make RustFS better.

&lt;a href=&quot;https://github.com/rustfs/rustfs/graphs/contributors&quot;&gt;
&lt;img src=&quot;https://opencollective.com/rustfs/contributors.svg?width=890&amp;limit=500&amp;button=false&quot; alt=&quot;Contributors&quot; /&gt;
&lt;/a&gt;

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=rustfs/rustfs&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#rustfs/rustfs&amp;type=date&amp;legend=top-left)

## License

[Apache 2.0](https://opensource.org/licenses/Apache-2.0)

**RustFS** is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ruvnet/ruvector]]></title>
            <link>https://github.com/ruvnet/ruvector</link>
            <guid>https://github.com/ruvnet/ruvector</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:46 GMT</pubDate>
            <description><![CDATA[RuVector is a High Performance, Real-Time, Self-Learning, Vector Graph Neural Network, and Database built in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ruvnet/ruvector">ruvnet/ruvector</a></h1>
            <p>RuVector is a High Performance, Real-Time, Self-Learning, Vector Graph Neural Network, and Database built in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 2,092</p>
            <p>Forks: 211</p>
            <p>Stars today: 247 stars today</p>
            <h2>README</h2><pre># RuVector ‚Äî A Self-Learning, Agentic Operating System
[![CES 2026 Innovation Award](https://img.shields.io/badge/üèÖ_CES_2026-Innovation_Award-gold.svg)](https://cognitum.one)
[![GitHub Trending](https://img.shields.io/badge/üî•_GitHub-Trending-orange.svg)](https://github.com/ruvnet/ruvector)

[![Crates.io](https://img.shields.io/crates/v/ruvector-core.svg)](https://crates.io/crates/ruvector-core)
[![npm](https://img.shields.io/npm/v/ruvector.svg)](https://www.npmjs.com/package/ruvector)
[![Downloads](https://img.shields.io/npm/dt/ruvector.svg?label=Downloads)](https://www.npmjs.com/package/ruvector)
[![Monthly Downloads](https://img.shields.io/npm/dm/ruvector.svg?label=Monthly%20Downloads)](https://www.npmjs.com/package/ruvector)
[![ruv.io](https://img.shields.io/badge/ruv.io-website-purple.svg)](https://ruv.io)
[![MIT License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

### **The self-learning, self-optimizing vector database ‚Äî with graph intelligence, local AI, and PostgreSQL built in.**

&gt; Created by [rUv](https://ruv.io) and powering [Cognitum](https://cognitum.one), a üèÖ **CES 2026 Innovation Awards Honoree** ‚Äî the world&#039;s first Agentic Chip designed to be always running for AI agents. Tens of thousands of agents, near-zero power, learns from every signal. [Learn more ‚Üí](https://cognitum.one)


```bash
npx ruvector
```

####  Most vector databases store your data and search it ‚Äî the same way, every time. 

#### **RuVector** is fundamentally different. It watches how you use it and gets smarter: search results improve automatically, the system tunes itself to your workload, and it runs AI models right on your hardware ‚Äî no cloud APIs, no per-query bills, GPUs optional, CPUs preferred. It drops into PostgreSQL, runs in browsers, and ships as a single file. 

Open source. ‚ù§Ô∏è Free forever.

```
User Query ‚Üí [SONA Engine] ‚Üí Model Response ‚Üí User Feedback
                  ‚Üë                                 ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ Learning Signal ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         (&lt; 1ms adaptation)
```

&lt;details&gt;
&lt;summary&gt;üîç RuVector vs Typical Vector Databases (20 differences)&lt;/summary&gt;

| | RuVector | Typical Vector DB |
|---|---|---|
| **Self-Learning &amp; Optimization** | | |
| [Search quality](./crates/ruvector-gnn) | üß† GNN learns from every query ‚Äî results improve over time | Static ‚Äî same results every time |
| [Self-optimizing](./crates/sona) | ‚ö° SONA auto-tunes routing, ranking, and compression to your workload | Manual tuning required |
| [46 attention mechanisms](./crates/ruvector-attention) | üéØ Flash, linear, graph, hyperbolic, [mincut-gated](./crates/ruvector-attn-mincut) (cuts compute 50%) | Basic similarity only |
| [Transfer learning](./crates/ruvector-domain-expansion) | üîÑ Knowledge transfers across domains ‚Äî new tasks bootstrap from past learning | Start from scratch each time |
| **Graph &amp; Relationships** | | |
| [Graph queries](./crates/ruvector-graph) | üîó Full Cypher engine ‚Äî `MATCH (a)-[:KNOWS]-&gt;(b)` like Neo4j | Flat list of results |
| [Graph transformers](./crates/ruvector-graph-transformer) | üî¨ 8 verified modules: physics, bio, manifold, temporal, economic | No graph support |
| [Hyperedges](./crates/ruvector-graph) | üï∏Ô∏è Connect 3+ nodes at once ‚Äî model group relationships natively | Pairwise only |
| **AI &amp; Compute** | | |
| [Local LLMs](./crates/ruvllm) | ü§ñ Run models on your hardware ‚Äî Metal, CUDA, WebGPU, no API costs | Cloud API required (pay per call) |
| [Sublinear solvers](./crates/ruvector-solver) | üìê O(log n) PageRank, spectral methods, sparse linear systems | Not available |
| [Genomics](./examples/dna) | üß¨ Variant calling, protein translation, HNSW k-mer search in 12 ms | Not available |
| [Quantum coherence](./crates/ruqu) | ‚öõÔ∏è Error correction via dynamic min-cut optimization | Not available |
| **Database &amp; Platform** | | |
| [PostgreSQL](./crates/ruvector-postgres) | üêò 230+ SQL functions ‚Äî drop into your existing database, [pgvector replacement](./docs/postgres/) | Separate service to manage |
| [Deploy anywhere](./crates/rvf/README.md) | üåê One file ‚Äî servers, browsers, phones, IoT, bare metal, WASM (58 KB) | Cloud server required |
| [Cognitive containers](./crates/rvf/README.md) | üöÄ Single `.rvf` file boots as a service in 125 ms ‚Äî includes vectors, models, kernel | Configure a cluster |
| [Live updates](./crates/ruvector-core) | ‚ö° Update vectors and graph connections instantly, no downtime | Rebuild index or wait |
| **Operations** | | |
| [Tamper-proof audit](./crates/rvf/rvf-crypto) | üîê Cryptographic witness chain records every operation automatically | Manual logging |
| [Branch your data](./crates/rvf/rvf-cow) | üåø Git-like COW branching ‚Äî 1M vectors, 100 edits = ~2.5 MB branch | Copy everything |
| [Scale out](./crates/ruvector-replication) | üìà Raft consensus, multi-master replication, auto-sharding | Paid tiers, per-vector pricing |
| [Post-quantum crypto](./crates/rvf/rvf-crypto) | üõ°Ô∏è ML-DSA-65 and Ed25519 signatures on every segment | Not available |
| Cost | üí∞ Free forever ‚Äî open source (MIT) | Per-query or per-vector pricing |

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üìã See Full Capabilities (75 features across 10 categories)&lt;/summary&gt;

**Core Vector Database**
| # | Capability | What It Does |
|---|------------|--------------|
| 1 | [**Store vectors**](./crates/ruvector-core) | Embeddings from OpenAI, Cohere, local ONNX with HNSW indexing and SIMD acceleration |
| 2 | [**Query with Cypher**](./crates/ruvector-graph) | Graph queries like Neo4j ‚Äî `MATCH (a)-[:SIMILAR]-&gt;(b)` with hyperedges |
| 3 | [**The index learns**](./crates/ruvector-gnn) | GNN layers make search results improve over time ‚Äî every query teaches the system |
| 4 | [**Hyperbolic HNSW**](./crates/ruvector-hyperbolic-hnsw) | Hierarchy-aware search in Poincare ball space ‚Äî better for trees and taxonomies |
| 5 | [**Compress automatically**](./crates/ruvector-temporal-tensor) | 2-32x memory reduction with adaptive tiered compression and temporal tensor reuse |
| 6 | [**Metadata filtering**](./crates/ruvector-filter) | Filter search results by any field before scanning vectors ‚Äî fast hybrid queries |
| 7 | [**Collections**](./crates/ruvector-collections) | Multi-tenant, schema-managed collections ‚Äî isolate data per customer or project |
| 8 | [**Snapshots**](./crates/ruvector-snapshot) | Point-in-time backups ‚Äî restore your database to any previous state |

**Distributed Systems**
| # | Capability | What It Does |
|---|------------|--------------|
| 9 | [**Raft consensus**](./crates/ruvector-raft) | Leader election and log replication ‚Äî nodes agree on state even when some fail |
| 10 | [**Multi-master replication**](./crates/ruvector-replication) | Vector clocks, conflict resolution, geo-distributed sync across data centers |
| 11 | [**Cluster management**](./crates/ruvector-cluster) | Horizontal scaling with consistent hashing ‚Äî add nodes without rebalancing everything |
| 12 | [**Delta consensus**](./crates/ruvector-delta-consensus) | Track behavioral changes across distributed nodes with CRDTs and causal ordering |
| 13 | **Burst scaling** | 10-50x capacity scaling for traffic spikes ‚Äî absorb load then scale back down |
| 14 | **Auto-sharding** | Automatic data partitioning across nodes based on access patterns |

**AI &amp; Machine Learning**
| # | Capability | What It Does |
|---|------------|--------------|
| 15 | [**Run LLMs locally**](./crates/ruvllm) | Load GGUF models and run inference on your hardware ‚Äî Metal, CUDA, ANE, WebGPU |
| 16 | [**RuvLTRA models**](https://huggingface.co/ruv/ruvltra) | Pre-trained GGUF for routing and embeddings in under 10 ms |
| 17 | [**SONA learning**](./crates/sona) | Self-Optimizing Neural Architecture ‚Äî LoRA fine-tuning + EWC++ memory preservation |
| 18 | [**46 attention mechanisms**](./crates/ruvector-attention) | Flash, linear, graph, hyperbolic, mincut-gated (cuts compute 50%) |
| 19 | [**Semantic routing**](./crates/ruvector-router-core) | Route AI requests to the right model or handler using FastGRNN neural inference |
| 20 | [**Sparse inference**](./crates/ruvector-sparse-inference) | PowerInfer-style engine ‚Äî only activate the neurons you need, 2-10x faster on edge |
| 21 | [**Tiny Dancer**](./crates/ruvector-tiny-dancer-core) | Production-grade agent routing with FastGRNN ‚Äî lightweight alternative to full LLM |
| 22 | [**Domain expansion**](./crates/ruvector-domain-expansion) | Cross-domain transfer learning ‚Äî new tasks bootstrap from past learning automatically |
| 23 | [**Advanced math**](./crates/ruvector-math) | Optimal transport, Sinkhorn distances, KL divergence, spectral clustering |
| 24 | [**Coherence measurement**](./crates/ruvector-coherence) | Measure signal quality and compare attention mechanisms objectively |

**Graph Transformers** ([8 verified modules](./crates/ruvector-graph-transformer))
| # | Capability | What It Does |
|---|------------|--------------|
| 25 | [**Proof-gated mutation**](./crates/ruvector-verified) | Every write to graph state requires a formal proof ‚Äî bugs cannot corrupt data |
| 26 | **Sublinear attention** | O(n log n) via LSH bucketing, PPR sampling, and spectral sparsification |
| 27 | **Physics-informed layers** | Hamiltonian dynamics, gauge equivariant message passing ‚Äî energy conserved by construction |
| 28 | **Biological layers** | Spiking attention, Hebbian/STDP learning, dendritic branching |
| 29 | **Self-organizing layers** | Morphogenetic fields, reaction-diffusion growth ‚Äî graphs that restructure themselves |
| 30 | **Verified training** | Training certificates, delta-apply rollback ‚Äî bad gradient steps auto-reversed |
| 31 | **Manifold geometry** | Product manifolds S^n x H^m x R^k ‚Äî work in curved spaces, not just flat |
| 32 | **Temporal-causal layers** | Causal masking, Granger causality extraction, continuous-time ODE integration |
| 33 | **Economic layers** | Nash equilibrium attention, Shapley attribution ‚Äî fair value assignment in multi-agent graphs |

**Cognitive Containers** ([RVF format](./crates/rvf/README.md))
| # | Capability | What It Does |
|---|------------|--------------|
| 34 | **Self-boot as a microservice** | A single `.rvf` file contains vectors, models, and a Linux kernel ‚Äî boots in 125 ms |
| 35 | **eBPF acceleration** | Hot vectors served in kernel data path via XDP, socket filter, and TC programs |
| 36 | **5.5 KB WASM runtime** | Same `.rvf` file runs queries in a browser tab with zero backend |
| 37 | [**COW branching**](./crates/rvf) | Git-like copy-on-write ‚Äî 1M vectors, 100 edits = ~2.5 MB branch |
| 38 | [**Witness chains**](./crates/rvf/rvf-crypto) | Tamper-evident hash-linked audit trail records every operation automatically |
| 39 | [**Post-quantum signatures**](./crates/rvf/rvf-crypto) | ML-DSA-65 and SLH-DSA-128s alongside Ed25519 ‚Äî future-proof cryptography |
| 40 | **DNA-style lineage** | Track parent/child derivation chains with cryptographic hashes |
| 41 | **25 segment types** | VEC, INDEX, KERNEL, EBPF, WASM, COW_MAP, WITNESS, CRYPTO, and 17 more |

**PostgreSQL Extension** ([230+ SQL functions](./crates/ruvector-postgres))
| # | Capability | What It Does |
|---|------------|--------------|
| 42 | **Drop-in pgvector replacement** | Same SQL interface but with self-learning search ‚Äî no app changes needed |
| 43 | **Sublinear solvers in SQL** | PageRank, conjugate gradient, Laplacian solver ‚Äî O(log n) to O(sqrt(n)) |
| 44 | **Math distances in SQL** | Wasserstein, Sinkhorn, KL divergence, spectral clustering ‚Äî all from SQL |
| 45 | **Topological data analysis** | Persistent homology, Betti numbers, embedding drift detection |
| 46 | **SONA learning in SQL** | Micro-LoRA trajectory learning with EWC++ forgetting prevention |
| 47 | **Extended attention in SQL** | O(n) linear, MoE, hyperbolic, sliding window attention ‚Äî all callable from SQL |

**Specialized Processing**
| # | Capability | What It Does |
|---|------------|--------------|
| 48 | [**SciPix OCR**](./examples/scipix) | Extract LaTeX and MathML from scientific documents and PDFs |
| 49 | [**DAG workflows**](./crates/ruvector-dag) | Self-learning directed acyclic graph execution for multi-step pipelines |
| 50 | [**Cognitum Gate**](./crates/cognitum-gate-kernel) | Cognitive AI gateway with TileZero acceleration for fast routing |
| 51 | [**FPGA transformer**](./crates/ruvector-fpga-transformer) | Hardware-accelerated transformer inference on programmable chips |
| 52 | [**Quantum coherence**](./crates/ruQu) | Error correction via dynamic min-cut optimization for quantum circuits |
| 53 | [**Sublinear solvers**](./crates/ruvector-solver) | 8 algorithms (Neumann, CG, Forward Push, TRUE, BMSSP) ‚Äî O(log n) to O(sqrt(n)) |
| 54 | [**Mincut-gated transformer**](./crates/ruvector-mincut-gated-transformer) | Dynamic attention that prunes irrelevant connections using graph min-cut |
| 55 | [**Nervous system**](./crates/ruvector-nervous-system) | 5-layer bio-inspired adaptive system with spiking networks and BTSP learning |
| 56 | [**Prime Radiant**](./crates/prime-radiant) | Coherence engine using sheaf Laplacian math for AI safety and hallucination detection |

**Genomics &amp; Health** ([rvDNA](./examples/dna))
| # | Capability | What It Does |
|---|------------|--------------|
| 57 | **rvDNA genomic analysis** | Variant calling, protein translation, HNSW k-mer search in 12 ms |
| 58 | **`.rvdna` file format** | AI-native binary with pre-computed vectors, tensors, and embeddings |
| 59 | **Instant diagnostics** | Sickle cell, cancer mutations, drug dosing ‚Äî runs on any device |
| 60 | **Privacy-first WASM** | Browser-based genomics ‚Äî your DNA data never leaves the device |
| 61 | **Biomarker engine** | Composite polygenic risk scoring (20 SNPs, 6 gene-gene interactions, 2 us) |
| 62 | **Streaming biomarkers** | Real-time anomaly detection, CUSUM changepoints, trend analysis (&gt;100k readings/sec) |

**Platform &amp; Integration**
| # | Capability | What It Does |
|---|------------|--------------|
| 63 | **Run anywhere** | Rust, Node.js, browser (WASM), edge ([rvLite](./crates/rvlite)), HTTP server, bare metal |
| 64 | [**MCP server**](./crates/mcp-gate) | Model Context Protocol for AI assistants ‚Äî Claude, GPT, and other agents can use RuVector as a tool |
| 65 | **Cloud deployment** | One-click deploy to [Google Cloud Run](./examples/google-cloud), Kubernetes |
| 66 | [**iOS App Clip**](./examples/app-clip) | Scan a QR code to load an RVF cognitive seed on your phone ‚Äî under 15 MB |
| 67 | [**Prometheus metrics**](./crates/ruvector-metrics) | Built-in monitoring ‚Äî export latency, throughput, and memory stats to Grafana |
| 68 | **90+ Rust crates + npm packages** | Published on [crates.io](https://crates.io/crates/rvf-runtime) and [npm](https://www.npmjs.com/package/@ruvector/rvf) |

**Examples &amp; Applications**
| # | Capability | What It Does |
|---|------------|--------------|
| 69 | [**Neural Trader**](./examples/neural-trader) | Algorithmic trading with Kelly Criterion position sizing and LSTM-Transformer prediction |
| 70 | [**Spiking Neural Network**](./examples/meta-cognition-spiking-neural-network) | Hybrid AI combining spiking networks, SIMD vector ops, and 5 attention types |
| 71 | [**ReFrag Pipeline**](./examples/refrag-pipeline) | Compress-Sense-Expand architecture ‚Äî ~30x RAG latency reduction |
| 72 | [**Edge Network**](./examples/edge-net) | Distributed collective AI ‚Äî share idle compute across devices |
| 73 | [**Vibecast 7Sense**](./examples/vibecast-7sense) | Transform bird calls into navigable geometric space using vector search |
| 74 | [**Ultra-Low Latency Sim**](./examples/ultra-low-latency-sim) | Meta-simulation achieving quadrillion simulations per second on CPU with SIMD |
| 75 | [**Verified Applications**](./examples/verified-applications) | 10 exotic proof-carrying apps: weapons filters, legal forensics, medical diagnostics |

&lt;/details&gt;

### Built by rUv, powered by [Cognitum.one](https://cognitum.one)

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Cognitum Hardware ‚Äî The Agentic Appliance &amp; Chip&lt;/strong&gt;&lt;/summary&gt;

**Cognitum v0 ‚Äî The Agentic Appliance**: Run tens of thousands of always-on agents at no incremental cost beyond the box. Learns in proximity to any signal ‚Äî sensors, networks, machines ‚Äî at near-zero power (~5 uW/inference, &lt;15W total). Sub-millisecond response, 500x cheaper than cloud AI. No cloud bills, no per-agent fees. Like a nervous system, not a brain.

**Cognitum v1 ‚Äî The Agentic Chip**: Same architecture on a single 257-core custom chip. Runs on less than 2W ‚Äî a AA battery. Idle-to-8 GHz burst on demand, 2 TB/s interconnect, built-in encryption per core.

&lt;/details&gt;

### A Complete Agentic AI Operating System

RuVector isn&#039;t a database you add to your stack ‚Äî it&#039;s the entire stack. Self-learning, self-optimizing, and self-deploying. Everything an AI application needs to run, from bare metal hardware up to the application layer, in one package:


**Intelligence**

| | Layer | Replaces | What It Does |
|---|-------|----------|--------------|
| üîÑ | [**Self-Learning**](./crates/sona/README.md) | Manual retraining, MLOps | SONA adapts in &lt;1 ms ‚Äî LoRA fine-tuning + EWC++ memory on every request |
| ‚ö° | [**Self-Optimizing**](./crates/ruvector-gnn/README.md) | Manual tuning, config files | Auto-tunes routing, ranking, compression, and index parameters |
| üéØ | [**Embeddings**](./crates/ruvllm/README.md) | OpenAI API, Cohere, static models | Contrastive training, triplet loss, real-time fine-tuning ‚Äî embeddings improve as you use them |
| ‚úÖ | [**Verified Training**](./crates/ruvector-verified/README.md) | Manual validation | Formal proofs + statistical tests on every training step ‚Äî gradients only apply if invariants pass |

**Data &amp; Search**

| | Layer | Replaces | What It Does |
|---|-------|----------|--------------|
| üîç | [**Search**](./crates/ruvector-core/README.md) | Pinecone, Weaviate, Qdrant | Self-learning HNSW ‚Äî GNN improves results from every query |
| üóÑÔ∏è | [**Storage**](./crates/ruvector-core/README.md) | Separate database + cache | Vector store, graph DB, key-value cache ‚Äî unified engine |
| üêò | [**PostgreSQL**](./crates/ruvector-postgres/README.md) | pgvector, pg_embedding | Drop-in replacement ‚Äî 230+ SQL functions, same interface but search gets smarter over time |
| üîó | [**Graph**](./crates/ruvector-graph/README.md) | Neo4j, Amazon Neptune | Cypher, W3C SPARQL 1.1, hyperedges ‚Äî all built in |

**AI &amp; ML**

| | Layer | Replaces | What It Does |
|---|-------|----------|--------------|
| ü§ñ | [**AI Runtime**](./crates/ruvllm/README.md) | llama.cpp, vLLM, Ollama | ruvllm ‚Äî GGUF models, MicroLoRA (&lt;1 ms), speculative decoding, continuous batching, WASM |
| üß† | [**ML Framework**](./crates/ruvector-attention/README.md) | PyTorch, TensorFlow | 46 attention types, 8 graph transformers, spiking networks, sparse inference, sublinear solvers |
| üî¨ | [**Coherence**](./crates/ruvector-mincut/README.md) | Manual testing, guardrails | Min-cut finds the weakest links in any network ‚Äî detects AI drift, prunes wasted compute (50% reduction), keeps agents in sync |
| üß¨ | [**Domain Models**](./crates/ruvector-domain-expansion/README.md) | Custom ML pipelines | Genomics (DNA variant calling), physics simulation, economic modeling, biological networks |

**Infrastructure**

| | Layer | Replaces | What It Does |
|---|-------|----------|--------------|
| üîß | [**Hardware**](./crates/ruvector-fpga-transformer/README.md) | CUDA toolkit, driver configs | Sparse/spiking CPU (AVX-512, NEON) ‚Äî GPU for bursts (Metal, CUDA, ANE, WebGPU, FPGA) |
| üêß | [**Kernel**](./crates/rvf/README.md) | Linux + Docker + eBPF | `.rvf` file boots its own kernel in 125 ms ‚Äî eBPF accelerates hot paths |
| üåê | [**Coordination**](./crates/ruvector-raft/README.md) | etcd, ZooKeeper, Consul | Raft consensus, multi-master replication, CRDT delta sync, auto-sharding |
| üì¶ | [**Packaging**](./crates/rvf/README.md) | Docker, Kubernetes | One `.rvf` file = your entire service

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lbjlaq/Antigravity-Manager]]></title>
            <link>https://github.com/lbjlaq/Antigravity-Manager</link>
            <guid>https://github.com/lbjlaq/Antigravity-Manager</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:45 GMT</pubDate>
            <description><![CDATA[Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).‰∏ì‰∏öÁöÑ Antigravity Ë¥¶Âè∑ÁÆ°ÁêÜ‰∏éÂàáÊç¢Â∑•ÂÖ∑„ÄÇ‰∏∫ Antigravity Êèê‰æõ‰∏ÄÈîÆÊó†ÁºùË¥¶Âè∑ÂàáÊç¢ÂäüËÉΩ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lbjlaq/Antigravity-Manager">lbjlaq/Antigravity-Manager</a></h1>
            <p>Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).‰∏ì‰∏öÁöÑ Antigravity Ë¥¶Âè∑ÁÆ°ÁêÜ‰∏éÂàáÊç¢Â∑•ÂÖ∑„ÄÇ‰∏∫ Antigravity Êèê‰æõ‰∏ÄÈîÆÊó†ÁºùË¥¶Âè∑ÂàáÊç¢ÂäüËÉΩ„ÄÇ</p>
            <p>Language: Rust</p>
            <p>Stars: 24,798</p>
            <p>Forks: 2,766</p>
            <p>Stars today: 178 stars today</p>
            <h2>README</h2><pre># Antigravity Tools üöÄ
&gt; ‰∏ì‰∏öÁ∫ß AI Ë¥¶Âè∑ÁÆ°ÁêÜ‰∏éÂçèËÆÆ‰ª£ÁêÜÁ≥ªÁªü (v4.1.26)
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;public/icon.png&quot; alt=&quot;Antigravity Logo&quot; width=&quot;120&quot; height=&quot;120&quot; style=&quot;border-radius: 24px; box-shadow: 0 10px 30px rgba(0,0,0,0.15);&quot;&gt;

  &lt;h3&gt;ÊÇ®ÁöÑ‰∏™‰∫∫È´òÊÄßËÉΩ AI Ë∞ÉÂ∫¶ÁΩëÂÖ≥&lt;/h3&gt;
  &lt;p&gt;‰∏ç‰ªÖ‰ªÖÊòØË¥¶Âè∑ÁÆ°ÁêÜÔºåÊõ¥ÊòØÊâìÁ†¥ API Ë∞ÉÁî®Â£ÅÂûíÁöÑÁªàÊûÅËß£ÂÜ≥ÊñπÊ°à„ÄÇ&lt;/p&gt;
  
  &lt;p&gt;
    &lt;a href=&quot;https://github.com/lbjlaq/Antigravity-Manager&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Version-4.1.26-blue?style=flat-square&quot; alt=&quot;Version&quot;&gt;
    &lt;/a&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Tauri-v2-orange?style=flat-square&quot; alt=&quot;Tauri&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Backend-Rust-red?style=flat-square&quot; alt=&quot;Rust&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Frontend-React-61DAFB?style=flat-square&quot; alt=&quot;React&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-CC--BY--NC--SA--4.0-lightgrey?style=flat-square&quot; alt=&quot;License&quot;&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;#-Ê†∏ÂøÉÂäüËÉΩ&quot;&gt;Ê†∏ÂøÉÂäüËÉΩ&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-ÁïåÈù¢ÂØºËßà&quot;&gt;ÁïåÈù¢ÂØºËßà&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-ÊäÄÊúØÊû∂ÊûÑ&quot;&gt;ÊäÄÊúØÊû∂ÊûÑ&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-ÂÆâË£ÖÊåáÂçó&quot;&gt;ÂÆâË£ÖÊåáÂçó&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-Âø´ÈÄüÊé•ÂÖ•&quot;&gt;Âø´ÈÄüÊé•ÂÖ•&lt;/a&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;strong&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/strong&gt; | 
    &lt;a href=&quot;./README_EN.md&quot;&gt;English&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

---

**Antigravity Tools** ÊòØ‰∏Ä‰∏™‰∏ì‰∏∫ÂºÄÂèëËÄÖÂíå AI Áà±Â•ΩËÄÖËÆæËÆ°ÁöÑÂÖ®ÂäüËÉΩÊ°åÈù¢Â∫îÁî®„ÄÇÂÆÉÂ∞ÜÂ§öË¥¶Âè∑ÁÆ°ÁêÜ„ÄÅÂçèËÆÆËΩ¨Êç¢ÂíåÊô∫ËÉΩËØ∑Ê±ÇË∞ÉÂ∫¶ÂÆåÁæéÁªìÂêàÔºå‰∏∫ÊÇ®Êèê‰æõ‰∏Ä‰∏™Á®≥ÂÆö„ÄÅÊûÅÈÄü‰∏îÊàêÊú¨‰ΩéÂªâÁöÑ **Êú¨Âú∞ AI ‰∏≠ËΩ¨Á´ô**„ÄÇ

ÈÄöËøáÊú¨Â∫îÁî®ÔºåÊÇ®ÂèØ‰ª•Â∞ÜÂ∏∏ËßÅÁöÑ Web Á´Ø Session (Google/Anthropic) ËΩ¨Âåñ‰∏∫Ê†áÂáÜÂåñÁöÑ API Êé•Âè£ÔºåÊ∂àÈô§‰∏çÂêåÂéÇÂïÜÈó¥ÁöÑÂçèËÆÆÈ∏øÊ≤ü„ÄÇ

## üíñ ËµûÂä©ÂïÜ (Sponsors)

| ËµûÂä©ÂïÜ (Sponsor) | ÁÆÄ‰ªã (Description) |
| :---: | :--- |
| &lt;img src=&quot;docs/images/packycode_logo.png&quot; width=&quot;200&quot; alt=&quot;PackyCode Logo&quot;&gt; | ÊÑüË∞¢ **PackyCode** ÂØπÊú¨È°πÁõÆÁöÑËµûÂä©ÔºÅPackyCode ÊòØ‰∏ÄÂÆ∂ÂèØÈù†È´òÊïàÁöÑ API ‰∏≠ËΩ¨ÊúçÂä°ÂïÜÔºåÊèê‰æõ Claude Code„ÄÅCodex„ÄÅGemini Á≠âÂ§öÁßçÊúçÂä°ÁöÑ‰∏≠ËΩ¨„ÄÇPackyCode ‰∏∫Êú¨È°πÁõÆÁöÑÁî®Êà∑Êèê‰æõ‰∫ÜÁâπÂà´‰ºòÊÉ†Ôºö‰ΩøÁî®[Ê≠§ÈìæÊé•](https://www.packyapi.com/register?aff=Ctrler)Ê≥®ÂÜåÔºåÂπ∂Âú®ÂÖÖÂÄºÊó∂ËæìÂÖ• **‚ÄúCtrler‚Äù** ‰ºòÊÉ†Á†ÅÂç≥ÂèØ‰∫´Âèó **‰πùÊäò‰ºòÊÉ†**„ÄÇ |
| &lt;img src=&quot;docs/images/AICodeMirror.jpg&quot; width=&quot;200&quot; alt=&quot;AICodeMirror Logo&quot;&gt; | ÊÑüË∞¢ AICodeMirror ËµûÂä©‰∫ÜÊú¨È°πÁõÆÔºÅAICodeMirror Êèê‰æõ Claude Code / Codex / Gemini CLI ÂÆòÊñπÈ´òÁ®≥ÂÆö‰∏≠ËΩ¨ÊúçÂä°ÔºåÊîØÊåÅ‰ºÅ‰∏öÁ∫ßÈ´òÂπ∂Âèë„ÄÅÊûÅÈÄüÂºÄÁ•®„ÄÅ7√ó24 ‰∏ìÂ±ûÊäÄÊúØÊîØÊåÅ„ÄÇ Claude Code / Codex / Gemini ÂÆòÊñπÊ∏†ÈÅì‰ΩéËá≥ 3.8 / 0.2 / 0.9 ÊäòÔºåÂÖÖÂÄºÊõ¥ÊúâÊäò‰∏äÊäòÔºÅAICodeMirror ‰∏∫ Antigravity-Manager ÁöÑÁî®Êà∑Êèê‰æõ‰∫ÜÁâπÂà´Á¶èÂà©ÔºåÈÄöËøá[Ê≠§ÈìæÊé•](https://www.aicodemirror.com/register?invitecode=MV5XUM)Ê≥®ÂÜåÁöÑÁî®Êà∑ÔºåÂèØ‰∫´ÂèóÈ¶ñÂÖÖ8ÊäòÔºå‰ºÅ‰∏öÂÆ¢Êà∑ÊúÄÈ´òÂèØ‰∫´ 7.5 ÊäòÔºÅ |

### ‚òï ÊîØÊåÅÈ°πÁõÆ (Support)

Â¶ÇÊûúÊÇ®ËßâÂæóÊú¨È°πÁõÆÂØπÊÇ®ÊúâÊâÄÂ∏ÆÂä©ÔºåÊ¨¢ËøéÊâìËµè‰ΩúËÄÖÔºÅ

&lt;a href=&quot;https://www.buymeacoffee.com/Ctrler&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://cdn.buymeacoffee.com/buttons/v2/default-green.png&quot; alt=&quot;ËØ∑ÊàëÂñùÊùØÂíñÂï°&quot; style=&quot;height: 60px !important; width: 217px !important;&quot;&gt;&lt;/a&gt;

| ÊîØ‰ªòÂÆù (Alipay) | ÂæÆ‰ø°ÊîØ‰ªò (WeChat) | Buy Me a Coffee |
| :---: | :---: | :---: |
| ![Alipay](./docs/images/donate_alipay.png) | ![WeChat](./docs/images/donate_wechat.png) | ![Coffee](./docs/images/donate_coffee.png) |

## üåü Ê∑±Â∫¶ÂäüËÉΩËß£Êûê (Detailed Features)

### 1. üéõÔ∏è Êô∫ËÉΩË¥¶Âè∑‰ª™Ë°®Áõò (Smart Dashboard)
*   **ÂÖ®Â±ÄÂÆûÊó∂ÁõëÊéß**: ‰∏ÄÁúºÊ¥ûÂØüÊâÄÊúâË¥¶Âè∑ÁöÑÂÅ•Â∫∑Áä∂ÂÜµÔºåÂåÖÊã¨ Gemini Pro„ÄÅGemini Flash„ÄÅClaude ‰ª•Âèä Gemini ÁªòÂõæÁöÑ **Âπ≥ÂùáÂâ©‰ΩôÈÖçÈ¢ù**„ÄÇ
*   **ÊúÄ‰Ω≥Ë¥¶Âè∑Êé®Ëçê (Smart Recommendation)**: Á≥ªÁªü‰ºöÊ†πÊçÆÂΩìÂâçÊâÄÊúâË¥¶Âè∑ÁöÑÈÖçÈ¢ùÂÜó‰ΩôÂ∫¶ÔºåÂÆûÊó∂ÁÆóÊ≥ïÁ≠õÈÄâÂπ∂Êé®Ëçê‚ÄúÊúÄ‰Ω≥Ë¥¶Âè∑‚ÄùÔºåÊîØÊåÅ **‰∏ÄÈîÆÂàáÊç¢**„ÄÇ
*   **Ê¥ªË∑ÉË¥¶Âè∑Âø´ÁÖß**: Áõ¥ËßÇÊòæÁ§∫ÂΩìÂâçÊ¥ªË∑ÉË¥¶Âè∑ÁöÑÂÖ∑‰ΩìÈÖçÈ¢ùÁôæÂàÜÊØîÂèäÊúÄÂêéÂêåÊ≠•Êó∂Èó¥„ÄÇ

### 2. üîê Âº∫Â§ßÁöÑË¥¶Âè∑ÁÆ°ÂÆ∂ (Account Management)
*   **OAuth 2.0 ÊéàÊùÉÔºàËá™Âä®/ÊâãÂä®Ôºâ**: Ê∑ªÂä†Ë¥¶Âè∑Êó∂‰ºöÊèêÂâçÁîüÊàêÂèØÂ§çÂà∂ÁöÑÊéàÊùÉÈìæÊé•ÔºåÊîØÊåÅÂú®‰ªªÊÑèÊµèËßàÂô®ÂÆåÊàêÊéàÊùÉÔºõÂõûË∞ÉÊàêÂäüÂêéÂ∫îÁî®‰ºöËá™Âä®ÂÆåÊàêÂπ∂‰øùÂ≠òÔºàÂøÖË¶ÅÊó∂ÂèØÁÇπÂáª‚ÄúÊàëÂ∑≤ÊéàÊùÉÔºåÁªßÁª≠‚ÄùÊâãÂä®Êî∂Â∞æÔºâ„ÄÇ
*   **Â§öÁª¥Â∫¶ÂØºÂÖ•**: ÊîØÊåÅÂçïÊù° Token ÂΩïÂÖ•„ÄÅJSON ÊâπÈáèÂØºÂÖ•ÔºàÂ¶ÇÊù•Ëá™ÂÖ∂‰ªñÂ∑•ÂÖ∑ÁöÑÂ§á‰ªΩÔºâÔºå‰ª•Âèä‰ªé V1 ÊóßÁâàÊú¨Êï∞ÊçÆÂ∫ìËá™Âä®ÁÉ≠ËøÅÁßª„ÄÇ
*   **ÁΩëÂÖ≥Á∫ßËßÜÂõæ**: ÊîØÊåÅ‚ÄúÂàóË°®‚Äù‰∏é‚ÄúÁΩëÊ†º‚ÄùÂèåËßÜÂõæÂàáÊç¢„ÄÇÊèê‰æõ 403 Â∞ÅÁ¶ÅÊ£ÄÊµãÔºåËá™Âä®Ê†áÊ≥®Âπ∂Ë∑≥ËøáÊùÉÈôêÂºÇÂ∏∏ÁöÑË¥¶Âè∑„ÄÇ

### 3. üîå ÂçèËÆÆËΩ¨Êç¢‰∏é‰∏≠Áªß (API Proxy)
*   **ÂÖ®ÂçèËÆÆÈÄÇÈÖç (Multi-Sink)**:
    *   **OpenAI Ê†ºÂºè**: Êèê‰æõ `/v1/chat/completions` Á´ØÁÇπÔºåÂÖºÂÆπ 99% ÁöÑÁé∞Êúâ AI Â∫îÁî®„ÄÇ
    *   **Anthropic Ê†ºÂºè**: Êèê‰æõÂéüÁîü `/v1/messages` Êé•Âè£ÔºåÊîØÊåÅ **Claude Code CLI** ÁöÑÂÖ®ÂäüËÉΩÔºàÂ¶ÇÊÄùÊÄùÁª¥Èìæ„ÄÅÁ≥ªÁªüÊèêÁ§∫ËØçÔºâ„ÄÇ
    *   **Gemini Ê†ºÂºè**: ÊîØÊåÅ Google ÂÆòÊñπ SDK Áõ¥Êé•Ë∞ÉÁî®„ÄÇ
*   **Êô∫ËÉΩÁä∂ÊÄÅËá™ÊÑà**: ÂΩìËØ∑Ê±ÇÈÅáÂà∞ `429 (Too Many Requests)` Êàñ `401 (Expire)` Êó∂ÔºåÂêéÁ´Ø‰ºöÊØ´ÁßíÁ∫ßËß¶Âèë **Ëá™Âä®ÈáçËØï‰∏éÈùôÈªòËΩÆÊç¢**ÔºåÁ°Æ‰øù‰∏öÂä°‰∏ç‰∏≠Êñ≠„ÄÇ

### 4. üîÄ Ê®°ÂûãË∑ØÁî±‰∏≠ÂøÉ (Model Router)
*   **Á≥ªÂàóÂåñÊò†Â∞Ñ**: ÊÇ®ÂèØ‰ª•Â∞ÜÂ§çÊùÇÁöÑÂéüÂßãÊ®°Âûã ID ÂΩíÁ±ªÂà∞‚ÄúËßÑÊ†ºÂÆ∂Êóè‚ÄùÔºàÂ¶ÇÂ∞ÜÊâÄÊúâ GPT-4 ËØ∑Ê±ÇÁªü‰∏ÄË∑ØÁî±Âà∞ `gemini-3-pro-high`Ôºâ„ÄÇ
*   **‰∏ìÂÆ∂Á∫ßÈáçÂÆöÂêë**: ÊîØÊåÅËá™ÂÆö‰πâÊ≠£ÂàôË°®ËææÂºèÁ∫ßÊ®°ÂûãÊò†Â∞ÑÔºåÁ≤æÂáÜÊéßÂà∂ÊØè‰∏Ä‰∏™ËØ∑Ê±ÇÁöÑËêΩÂú∞Ê®°Âûã„ÄÇ
*   **Êô∫ËÉΩÂàÜÁ∫ßË∑ØÁî± (Tiered Routing)**: [Êñ∞] Á≥ªÁªüÊ†πÊçÆË¥¶Âè∑Á±ªÂûãÔºàUltra/Pro/FreeÔºâÂíåÈÖçÈ¢ùÈáçÁΩÆÈ¢ëÁéáËá™Âä®‰ºòÂÖàÁ∫ßÊéíÂ∫èÔºå‰ºòÂÖàÊ∂àËÄóÈ´òÈÄüÈáçÁΩÆË¥¶Âè∑ÔºåÁ°Æ‰øùÈ´òÈ¢ëË∞ÉÁî®‰∏ãÁöÑÊúçÂä°Á®≥ÂÆöÊÄß„ÄÇ
*   **ÂêéÂè∞‰ªªÂä°ÈùôÈªòÈôçÁ∫ß**: [Êñ∞] Ëá™Âä®ËØÜÂà´ Claude CLI Á≠âÂ∑•ÂÖ∑ÁîüÊàêÁöÑÂêéÂè∞ËØ∑Ê±ÇÔºàÂ¶ÇÊ†áÈ¢òÁîüÊàêÔºâÔºåÊô∫ËÉΩÈáçÂÆöÂêëËá≥ Flash Ê®°ÂûãÔºå‰øùÊä§È´òÁ∫ßÊ®°ÂûãÈÖçÈ¢ù‰∏çË¢´Êµ™Ë¥π„ÄÇ

### 5. üé® Â§öÊ®°ÊÄÅ‰∏é Imagen 3 ÊîØÊåÅ
*   **È´òÁ∫ßÁîªË¥®ÊéßÂà∂**: ÊîØÊåÅÈÄöËøá OpenAI `size` (Â¶Ç `1024x1024`, `16:9`) ÂèÇÊï∞Ëá™Âä®Êò†Â∞ÑÂà∞ Imagen 3 ÁöÑÁõ∏Â∫îËßÑÊ†º„ÄÇ
*   **Ë∂ÖÂº∫ Body ÊîØÊåÅ**: ÂêéÁ´ØÊîØÊåÅÈ´òËææ **100MB** (ÂèØÈÖçÁΩÆ) ÁöÑ PayloadÔºåÂ§ÑÁêÜ 4K È´òÊ∏ÖÂõæËØÜÂà´Áª∞Áª∞Êúâ‰Ωô„ÄÇ

## üì∏ ÁïåÈù¢ÂØºËßà (GUI Overview)

| | |
| :---: | :---: |
| ![‰ª™Ë°®Áõò - ÂÖ®Â±ÄÈÖçÈ¢ùÁõëÊéß‰∏é‰∏ÄÈîÆÂàáÊç¢](docs/images/dashboard-light.png) &lt;br&gt; ‰ª™Ë°®Áõò | ![Ë¥¶Âè∑ÂàóË°® - È´òÂØÜÂ∫¶ÈÖçÈ¢ùÂ±ïÁ§∫‰∏é 403 Êô∫ËÉΩÊ†áÊ≥®](docs/images/accounts-light.png) &lt;br&gt; Ë¥¶Âè∑ÂàóË°® |
| ![ÂÖ≥‰∫éÈ°µÈù¢ - ÂÖ≥‰∫é Antigravity Tools](docs/images/about-dark.png) &lt;br&gt; ÂÖ≥‰∫éÈ°µÈù¢ | ![API Âèç‰ª£ - ÊúçÂä°ÊéßÂà∂](docs/images/v3/proxy-settings.png) &lt;br&gt; API Âèç‰ª£ |
| ![Á≥ªÁªüËÆæÁΩÆ - ÈÄöÁî®ÈÖçÁΩÆ](docs/images/settings-dark.png) &lt;br&gt; Á≥ªÁªüËÆæÁΩÆ | |

### üí° ‰ΩøÁî®Ê°à‰æã (Usage Examples)

| | |
| :---: | :---: |
| ![Claude Code ËÅîÁΩëÊêúÁ¥¢ - ÁªìÊûÑÂåñÊù•Ê∫ê‰∏éÂºïÊñáÊòæÁ§∫](docs/images/usage/claude-code-search.png) &lt;br&gt; Claude Code ËÅîÁΩëÊêúÁ¥¢ | ![Cherry Studio Ê∑±Â∫¶ÈõÜÊàê - ÂéüÁîüÂõûÊòæÊêúÁ¥¢ÂºïÊñá‰∏éÊù•Ê∫êÈìæÊé•](docs/images/usage/cherry-studio-citations.png) &lt;br&gt; Cherry Studio Ê∑±Â∫¶ÈõÜÊàê |
| ![Imagen 3 È´òÁ∫ßÁªòÂõæ - ÂÆåÁæéËøòÂéü Prompt ÊÑèÂ¢É‰∏éÁªÜËäÇ](docs/images/usage/image-gen-nebula.png) &lt;br&gt; Imagen 3 È´òÁ∫ßÁªòÂõæ | ![Kilo Code Êé•ÂÖ• - Â§öË¥¶Âè∑ÊûÅÈÄüËΩÆÊç¢‰∏éÊ®°ÂûãÁ©øÈÄè](docs/images/usage/kilo-code-integration.png) &lt;br&gt; Kilo Code Êé•ÂÖ• |

## üèóÔ∏è ÊäÄÊúØÊû∂ÊûÑ (Architecture)

```mermaid
graph TD
    Client([Â§ñÈÉ®Â∫îÁî®: Claude Code/NextChat]) --&gt;|OpenAI/Anthropic| Gateway[Antigravity Axum Server]
    Gateway --&gt; Middleware[‰∏≠Èó¥‰ª∂: Èâ¥ÊùÉ/ÈôêÊµÅ/Êó•Âøó]
    Middleware --&gt; Router[Model Router: ID Êò†Â∞Ñ]
    Router --&gt; Dispatcher[Ë¥¶Âè∑ÂàÜÂèëÂô®: ËΩÆËØ¢/ÊùÉÈáç]
    Dispatcher --&gt; Mapper[ÂçèËÆÆËΩ¨Êç¢Âô®: Request Mapper]
    Mapper --&gt; Upstream[‰∏äÊ∏∏ËØ∑Ê±Ç: Google/Anthropic API]
    Upstream --&gt; ResponseMapper[ÂìçÂ∫îËΩ¨Êç¢Âô®: Response Mapper]
    ResponseMapper --&gt; Client
```

##  ÂÆâË£ÖÊåáÂçó (Installation)

### ÈÄâÈ°π A: ÁªàÁ´ØÂÆâË£Ö (Êé®Ëçê)

#### Ë∑®Âπ≥Âè∞‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨

Ëá™Âä®Ê£ÄÊµãÊìç‰ΩúÁ≥ªÁªü„ÄÅÊû∂ÊûÑÂíåÂåÖÁÆ°ÁêÜÂô®Ôºå‰∏ÄÊù°ÂëΩ‰ª§ÂÆåÊàê‰∏ãËΩΩ‰∏éÂÆâË£Ö„ÄÇ

**Linux / macOS:**
```bash
curl -fsSL https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/v4.1.26/install.sh | bash
```

**Windows (PowerShell):**
```powershell
irm https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/main/install.ps1 | iex
```

&gt; **ÊîØÊåÅÁöÑÊ†ºÂºè**: Linux (`.deb` / `.rpm` / `.AppImage`) | macOS (`.dmg`) | Windows (NSIS `.exe`)
&gt;
&gt; **È´òÁ∫ßÁî®Ê≥ï**: ÂÆâË£ÖÊåáÂÆöÁâàÊú¨ `curl -fsSL ... | bash -s -- --version 4.1.26`ÔºåÈ¢ÑËßàÊ®°Âºè `curl -fsSL ... | bash -s -- --dry-run`

#### macOS - Homebrew
Â¶ÇÊûúÊÇ®Â∑≤ÂÆâË£Ö [Homebrew](https://brew.sh/)Ôºå‰πüÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÂëΩ‰ª§ÂÆâË£ÖÔºö

```bash
# 1. ËÆ¢ÈòÖÊú¨‰ªìÂ∫ìÁöÑ Tap
brew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager

# 2. ÂÆâË£ÖÂ∫îÁî®
brew install --cask antigravity-tools
```
&gt; **ÊèêÁ§∫**: Â¶ÇÊûúÈÅáÂà∞ÊùÉÈôêÈóÆÈ¢òÔºåÂª∫ËÆÆÊ∑ªÂä† `--no-quarantine` ÂèÇÊï∞„ÄÇ

#### Arch Linux
ÊÇ®ÂèØ‰ª•ÈÄâÊã©ÈÄöËøá‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨Êàñ Homebrew ËøõË°åÂÆâË£ÖÔºö

**ÊñπÂºè 1Ôºö‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨ (Êé®Ëçê)**
```bash
curl -sSL https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/main/deploy/arch/install.sh | bash
```

**ÊñπÂºè 2ÔºöÈÄöËøá Homebrew** (Â¶ÇÊûúÊÇ®Â∑≤ÂÆâË£Ö [Linuxbrew](https://sh.brew.sh/))
```bash
brew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager
brew install --cask antigravity-tools
```

#### ÂÖ∂‰ªñ Linux ÂèëË°åÁâà
ÂÆâË£ÖÂêé‰ºöËá™Âä®Â∞Ü AppImage Ê∑ªÂä†Âà∞‰∫åËøõÂà∂Ë∑ØÂæÑÂπ∂ÈÖçÁΩÆÂèØÊâßË°åÊùÉÈôê„ÄÇ

### ÈÄâÈ°π B: ÊâãÂä®‰∏ãËΩΩ
ÂâçÂæÄ [GitHub Releases](https://github.com/lbjlaq/Antigravity-Manager/releases) ‰∏ãËΩΩÂØπÂ∫îÁ≥ªÁªüÁöÑÂåÖÔºö
*   **macOS**: `.dmg` (ÊîØÊåÅ Apple Silicon &amp; Intel)
*   **Windows**: `.msi` Êàñ ‰æøÊê∫Áâà `.zip`
*   **Linux**: `.deb` Êàñ `AppImage`

### ÈÄâÈ°π C: Docker ÈÉ®ÁΩ≤ (Êé®ËçêÁî®‰∫é NAS/ÊúçÂä°Âô®)
Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®ÂÆπÂô®ÂåñÁéØÂ¢É‰∏≠ËøêË°åÔºåÊàë‰ª¨Êèê‰æõ‰∫ÜÂéüÁîüÁöÑ Docker ÈïúÂÉè„ÄÇËØ•ÈïúÂÉèÂÜÖÁΩÆ‰∫ÜÂØπ v4.0.2 ÂéüÁîü Headless Êû∂ÊûÑÁöÑÊîØÊåÅÔºåÂèØËá™Âä®ÊâòÁÆ°ÂâçÁ´ØÈùôÊÄÅËµÑÊ∫êÔºåÂπ∂ÈÄöËøáÊµèËßàÂô®Áõ¥Êé•ËøõË°åÁÆ°ÁêÜ„ÄÇ

```bash
# ÊñπÂºè 1: Áõ¥Êé•ËøêË°å (Êé®Ëçê)
# - API_KEY: ÂøÖÂ°´„ÄÇÁî®‰∫éÊâÄÊúâÂçèËÆÆÁöÑ AI ËØ∑Ê±ÇÈâ¥ÂÆö„ÄÇ
# - WEB_PASSWORD: ÂèØÈÄâ„ÄÇÁî®‰∫éÁÆ°ÁêÜÂêéÂè∞ÁôªÂΩï„ÄÇËã•‰∏çËÆæÁΩÆÂàôÈªòËÆ§‰ΩøÁî® API_KEY„ÄÇ
docker run -d --name antigravity-manager \
  -p 8045:8045 \
  -e API_KEY=sk-your-api-key \
  -e WEB_PASSWORD=your-login-password \
  -e ABV_MAX_BODY_SIZE=104857600 \
  -v ~/.antigravity_tools:/root/.antigravity_tools \
  lbjlaq/antigravity-manager:latest

# ÂøòËÆ∞ÂØÜÈí•ÔºüÊâßË°å docker logs antigravity-manager Êàñ grep -E &#039;&quot;api_key&quot;|&quot;admin_password&quot;&#039; ~/.antigravity_tools/gui_config.json

#### üîê Èâ¥ÊùÉÈÄªËæëËØ¥Êòé
*   **Âú∫ÊôØ AÔºö‰ªÖËÆæÁΩÆ‰∫Ü `API_KEY`**
    - **Web ÁôªÂΩï**Ôºö‰ΩøÁî® `API_KEY` ËøõÂÖ•ÂêéÂè∞„ÄÇ
    - **API Ë∞ÉÁî®**Ôºö‰ΩøÁî® `API_KEY` ËøõË°å AI ËØ∑Ê±ÇÈâ¥ÊùÉ„ÄÇ
*   **Âú∫ÊôØ BÔºöÂêåÊó∂ËÆæÁΩÆ‰∫Ü `API_KEY` Âíå `WEB_PASSWORD` (Êé®Ëçê)**
    - **Web ÁôªÂΩï**Ôºö**ÂøÖÈ°ª**‰ΩøÁî® `WEB_PASSWORD`Ôºå‰ΩøÁî® API Key Â∞ÜË¢´ÊãíÁªùÔºàÊõ¥ÂÆâÂÖ®Ôºâ„ÄÇ
    - **API Ë∞ÉÁî®**ÔºöÁªü‰∏Ä‰ΩøÁî® `API_KEY`„ÄÇËøôÊ†∑ÊÇ®ÂèØ‰ª•Â∞Ü API Key ÂàÜÂèëÁªôÊàêÂëòÔºåËÄå‰øùÁïôÂØÜÁ†Å‰ªÖ‰æõÁÆ°ÁêÜÂëò‰ΩøÁî®„ÄÇ

#### üÜô ÊóßÁâàÊú¨ÂçáÁ∫ßÊåáÂºï
Â¶ÇÊûúÊÇ®ÊòØ‰ªé v4.0.1 ÂèäÊõ¥Êó©ÁâàÊú¨ÂçáÁ∫ßÔºåÁ≥ªÁªüÈªòËÆ§Êú™ËÆæÁΩÆ `WEB_PASSWORD`„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ã‰ªª‰∏ÄÊñπÂºèËÆæÁΩÆÔºö
1.  **Web UI ÁïåÈù¢ (Êé®Ëçê)**Ôºö‰ΩøÁî®ÂéüÊúâ `API_KEY` ÁôªÂΩïÂêéÔºåÂú® **API Âèç‰ª£ËÆæÁΩÆ** È°µÈù¢ÊâãÂä®ËÆæÁΩÆÂπ∂‰øùÂ≠ò„ÄÇÊñ∞ÂØÜÁ†ÅÂ∞ÜÊåÅ‰πÖÂåñÂ≠òÂÇ®Âú® `gui_config.json` ‰∏≠„ÄÇ
2.  **ÁéØÂ¢ÉÂèòÈáè (Docker)**ÔºöÂú®ÂêØÂä®ÂÆπÂô®Êó∂Â¢ûÂä† `-e WEB_PASSWORD=ÊÇ®ÁöÑÊñ∞ÂØÜÁ†Å`„ÄÇ**Ê≥®ÊÑèÔºöÁéØÂ¢ÉÂèòÈáèÂÖ∑ÊúâÊúÄÈ´ò‰ºòÂÖàÁ∫ßÔºåÂ∞ÜË¶ÜÁõñ UI ‰∏≠ÁöÑ‰ªª‰Ωï‰øÆÊîπ„ÄÇ**
3.  **ÈÖçÁΩÆÊñá‰ª∂ (ÊåÅ‰πÖÂåñ)**ÔºöÁõ¥Êé•‰øÆÊîπ `~/.antigravity_tools/gui_config.json`ÔºåÂú® `proxy` ÂØπË±°‰∏≠‰øÆÊîπÊàñÊ∑ªÂä† `&quot;admin_password&quot;: &quot;ÊÇ®ÁöÑÊñ∞ÂØÜÁ†Å&quot;` Â≠óÊÆµ„ÄÇ
    - *Ê≥®Ôºö`WEB_PASSWORD` ÊòØÁéØÂ¢ÉÂèòÈáèÂêçÔºå`admin_password` ÊòØÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑ JSON ÈîÆÂêç„ÄÇ*

&gt; [!TIP]
&gt; **ÂØÜÁ†Å‰ºòÂÖàÁ∫ßÈÄªËæë (Priority)**:
&gt; - **Á¨¨‰∏Ä‰ºòÂÖàÁ∫ß (ÁéØÂ¢ÉÂèòÈáè)**: `ABV_WEB_PASSWORD` Êàñ `WEB_PASSWORD`„ÄÇÂè™Ë¶ÅËÆæÁΩÆ‰∫ÜÁéØÂ¢ÉÂèòÈáèÔºåÁ≥ªÁªüÂ∞ÜÂßãÁªà‰ΩøÁî®ÂÆÉ„ÄÇ
&gt; - **Á¨¨‰∫å‰ºòÂÖàÁ∫ß (ÈÖçÁΩÆÊñá‰ª∂)**: `gui_config.json` ‰∏≠ÁöÑ `admin_password` Â≠óÊÆµ„ÄÇUI ÁöÑ‚Äú‰øùÂ≠ò‚ÄùÊìç‰Ωú‰ºöÊõ¥Êñ∞Ê≠§ÂÄº„ÄÇ
&gt; - **‰øùÂ∫ïÂõûÈÄÄ (ÂêëÂêéÂÖºÂÆπ)**: Ëã•‰∏äËø∞ÂùáÊú™ËÆæÁΩÆÔºåÂàôÂõûÈÄÄ‰ΩøÁî® `API_KEY` ‰Ωú‰∏∫ÁôªÂΩïÂØÜÁ†Å„ÄÇ

# ÊñπÂºè 2: ‰ΩøÁî® Docker Compose
# 1. ËøõÂÖ•È°πÁõÆÁöÑ docker ÁõÆÂΩï
cd docker
# 2. ÂêØÂä®ÊúçÂä°
docker compose up -d
```
&gt; **ËÆøÈóÆÂú∞ÂùÄ**: `http://localhost:8045` (ÁÆ°ÁêÜÂêéÂè∞) | `http://localhost:8045/v1` (API Base)
&gt; **Á≥ªÁªüË¶ÅÊ±Ç**:
&gt; - **ÂÜÖÂ≠ò**: Âª∫ËÆÆ **1GB** (ÊúÄÂ∞è 256MB)„ÄÇ
&gt; - **ÊåÅ‰πÖÂåñ**: ÈúÄÊåÇËΩΩ `/root/.antigravity_tools` ‰ª•‰øùÂ≠òÊï∞ÊçÆ„ÄÇ
&gt; - **Êû∂ÊûÑ**: ÊîØÊåÅ x86_64 Âíå ARM64„ÄÇ
&gt; **ËØ¶ÊÉÖËßÅ**: [Docker ÈÉ®ÁΩ≤ÊåáÂçó (docker)](./docker/README.md)

---

Copyright ¬© 2024-2026 [lbjlaq](https://github.com/lbjlaq)

### üõ†Ô∏è Â∏∏ËßÅÈóÆÈ¢òÊéíÊü• (Troubleshooting)

#### macOS ÊèêÁ§∫‚ÄúÂ∫îÁî®Â∑≤ÊçüÂùèÔºåÊó†Ê≥ïÊâìÂºÄ‚ÄùÔºü
Áî±‰∫é macOS ÁöÑÂÆâÂÖ®Êú∫Âà∂ÔºåÈùû App Store ‰∏ãËΩΩÁöÑÂ∫îÁî®ÂèØËÉΩ‰ºöËß¶ÂèëÊ≠§ÊèêÁ§∫„ÄÇÊÇ®ÂèØ‰ª•ÊåâÁÖß‰ª•‰∏ãÊ≠•È™§Âø´ÈÄü‰øÆÂ§çÔºö

1.  **ÂëΩ‰ª§Ë°å‰øÆÂ§ç** (Êé®Ëçê):
    ÊâìÂºÄÁªàÁ´ØÔºåÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö
    ```bash
    sudo xattr -rd com.apple.quarantine &quot;/Applications/Antigravity Tools.app&quot;
    ```
2.  **Homebrew ÂÆâË£ÖÊäÄÂ∑ß**:
    Â¶ÇÊûúÊÇ®‰ΩøÁî® brew ÂÆâË£ÖÔºåÂèØ‰ª•Ê∑ªÂä† `--no-quarantine` ÂèÇÊï∞Êù•ËßÑÈÅøÊ≠§ÈóÆÈ¢òÔºö
    ```bash
    brew install --cask --no-quarantine antigravity-tools
    ```

## üîå Âø´ÈÄüÊé•ÂÖ•Á§∫‰æã

### üîê OAuth ÊéàÊùÉÊµÅÁ®ãÔºàÊ∑ªÂä†Ë¥¶Âè∑Ôºâ
1. ÊâìÂºÄ‚ÄúAccounts / Ë¥¶Âè∑‚Äù ‚Üí ‚ÄúÊ∑ªÂä†Ë¥¶Âè∑‚Äù ‚Üí ‚ÄúOAuth‚Äù„ÄÇ
2. ÂºπÁ™ó‰ºöÂú®ÁÇπÂáªÊåâÈíÆÂâçÈ¢ÑÁîüÊàêÊéàÊùÉÈìæÊé•ÔºõÁÇπÂáªÈìæÊé•Âç≥ÂèØÂ§çÂà∂Âà∞Á≥ªÁªüÂâ™Ë¥¥ÊùøÔºåÁÑ∂ÂêéÁî®‰Ω†Â∏åÊúõÁöÑÊµèËßàÂô®ÊâìÂºÄÂπ∂ÂÆåÊàêÊéàÊùÉ„ÄÇ
3. ÊéàÊùÉÂÆåÊàêÂêéÊµèËßàÂô®‰ºöÊâìÂºÄÊú¨Âú∞ÂõûË∞ÉÈ°µÂπ∂ÊòæÁ§∫‚Äú‚úÖ ÊéàÊùÉÊàêÂäü!‚Äù„ÄÇ
4. Â∫îÁî®‰ºöËá™Âä®ÁªßÁª≠ÂÆåÊàêÊéàÊùÉÂπ∂‰øùÂ≠òË¥¶Âè∑ÔºõÂ¶ÇÊú™Ëá™Âä®ÂÆåÊàêÔºåÂèØÁÇπÂáª‚ÄúÊàëÂ∑≤ÊéàÊùÉÔºåÁªßÁª≠‚ÄùÊâãÂä®ÂÆåÊàê„ÄÇ

&gt; ÊèêÁ§∫ÔºöÊéàÊùÉÈìæÊé•ÂåÖÂê´‰∏ÄÊ¨°ÊÄßÂõûË∞ÉÁ´ØÂè£ÔºåËØ∑ÂßãÁªà‰ΩøÁî®ÂºπÁ™óÈáåÁîüÊàêÁöÑÊúÄÊñ∞ÈìæÊé•ÔºõÂ¶ÇÊûúÊéàÊùÉÊó∂Â∫îÁî®Êú™ËøêË°åÊàñÂºπÁ™óÂ∑≤ÂÖ≥Èó≠ÔºåÊµèËßàÂô®ÂèØËÉΩ‰ºöÊèêÁ§∫ `localhost refused connection`„ÄÇ

### Â¶Ç‰ΩïÊé•ÂÖ• Claude Code CLI?
1.  ÂêØÂä® AntigravityÔºåÂπ∂Âú®‚ÄúAPI Âèç‰ª£‚ÄùÈ°µÈù¢ÂºÄÂêØÊúçÂä°„ÄÇ
2.  Âú®ÁªàÁ´ØÊâßË°åÔºö
```bash
export ANTHROPIC_API_KEY=&quot;sk-antigravity&quot;
export ANTHROPIC_BASE_URL=&quot;http://127.0.0.1:8045&quot;
claude
```

### Â¶Ç‰ΩïÊé•ÂÖ• OpenCode?
1.  ËøõÂÖ• **API Âèç‰ª£**È°µÈù¢ ‚Üí **Â§ñÈÉ® Providers** ‚Üí ÁÇπÂáª **OpenCode Sync** Âç°Áâá„ÄÇ
2.  ÁÇπÂáª **Sync** ÊåâÈíÆÔºåÂ∞ÜËá™Âä®ÁîüÊàê `~/.config/opencode/opencode.json` ÈÖçÁΩÆÊñá‰ª∂Ôºö
    - ÂàõÂª∫Áã¨Á´ã provider `antigravity-manager`Ôºà‰∏çË¶ÜÁõñ google/anthropic ÂéüÁîüÈÖçÁΩÆÔºâ
    - ÂèØÈÄâÔºöÂãæÈÄâ **Sync accounts** ÂØºÂá∫ `antigravity-accounts.json`Ôºàplugin-compatible v3 Ê†ºÂºèÔºâÔºå‰æõ OpenCode Êèí‰ª∂Áõ¥Êé•ÂØºÂÖ•
3.  ÁÇπÂáª **Clear Config** ÂèØ‰∏ÄÈîÆÊ∏ÖÈô§ Manager ÈÖçÁΩÆÂπ∂Ê∏ÖÁêÜ legacy ÊÆãÁïôÔºõÁÇπÂáª **Restore** ÂèØ‰ªéÂ§á‰ªΩÊÅ¢Â§ç„ÄÇ
4.  Windows Áî®Êà∑Ë∑ØÂæÑ‰∏∫ `C:\Users\&lt;Áî®Êà∑Âêç&gt;\.config\opencode\`Ôºà‰∏é `~/.config/opencode` ËßÑÂàô‰∏ÄËá¥Ôºâ„ÄÇ

**Âø´ÈÄüÈ™åËØÅÂëΩ‰ª§Ôºö**
```bash
# ÊµãËØï antigravity-manager providerÔºàÊîØÊåÅ --variantÔºâ
opencode run &quot;test&quot; --model antigravity-manager/claude-sonnet-4-5-thinking --variant high

# Ëã•Â∑≤ÂÆâË£Ö opencode-antigravity-auth Êèí‰ª∂ÔºåÈ™åËØÅ google provider ‰ªçÂèØÁã¨Á´ãÂ∑•‰Ωú
opencode run &quot;test&quot; --model google/antigravity-claude-sonnet-4-5-thinking --variant max
```

### Â¶Ç‰ΩïÊé•ÂÖ• Kilo Code?
1.  **ÂçèËÆÆÈÄâÊã©**: Âª∫ËÆÆ‰ºòÂÖà‰ΩøÁî® **Gemini ÂçèËÆÆ**„ÄÇ
2.  **Base URL**: Â°´ÂÜô `http://127.0.0.1:8045`„ÄÇ
3.  **Ê≥®ÊÑè**: 
    - **OpenAI ÂçèËÆÆÈôêÂà∂**: Kilo Code Âú®‰ΩøÁî® OpenAI Ê®°ÂºèÊó∂ÔºåÂÖ∂ËØ∑Ê±ÇË∑ØÂæÑ‰ºöÂè†Âä†‰∫ßÁîü `/v1/chat/completions/responses` ËøôÁßçÈùûÊ†áÂáÜË∑ØÂæÑÔºåÂØºËá¥ Antigravity ËøîÂõû 404„ÄÇÂõ†Ê≠§ËØ∑Âä°ÂøÖÂ°´ÂÖ• Base URL ÂêéÈÄâÊã© Gemini Ê®°Âºè„ÄÇ
    - **Ê®°ÂûãÊò†Â∞Ñ**: Kilo Code ‰∏≠ÁöÑÊ®°ÂûãÂêçÁß∞ÂèØËÉΩ‰∏é Antigravity ÈªòËÆ§ËÆæÁΩÆ‰∏ç‰∏ÄËá¥ÔºåÂ¶ÇÈÅáÂà∞Êó†Ê≥ïËøûÊé•ÔºåËØ∑Âú®‚ÄúÊ®°ÂûãÊò†Â∞Ñ‚ÄùÈ°µÈù¢ËÆæÁΩÆËá™ÂÆö‰πâÊò†Â∞ÑÔºåÂπ∂Êü•Áúã**Êó•ÂøóÊñá‰ª∂**ËøõË°åË∞ÉËØï„ÄÇ

### Â¶Ç‰ΩïÂú® Python ‰∏≠‰ΩøÁî®?
```python
import openai

client = openai.OpenAI(
    api_key=&quot;sk-antigravity&quot;,
    base_url=&quot;http://127.0.0.1:8045/v1&quot;
)

response = client.chat.completions.create(
    model=&quot;gemini-3-flash&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰Ω†Â•ΩÔºåËØ∑Ëá™Êàë‰ªãÁªç&quot;}]
)
print(response.choices[0].message.content)
```

### Â¶Ç‰Ωï‰ΩøÁî®ÂõæÁâáÁîüÊàê (Imagen 3)?

#### ÊñπÂºè‰∏ÄÔºöOpenAI Images API (Êé®Ëçê)
```python
import openai

client = openai.OpenAI(
    api_key=&quot;sk-antigravity&quot;,
    base_url=&quot;http://127.0.0.1:8045/v1&quot;
)

# ÁîüÊàêÂõæÁâá
response = client.images.generate(
    model=&quot;gemini-3-pro-image&quot;,
    prompt=&quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏ÇÔºåËµõÂçöÊúãÂÖãÔºåÈúìËôπÁÅØ&quot;,
    size=&quot;1920x1080&quot;,      # ÊîØÊåÅ‰ªªÊÑè WIDTHxHEIGHT Ê†ºÂºèÔºåËá™Âä®ËÆ°ÁÆóÂÆΩÈ´òÊØî
    quality=&quot;hd&quot;,          # &quot;standard&quot; | &quot;hd&quot; | &quot;medium&quot;
    n=1,
    response_format=&quot;b64_json&quot;
)

# ‰øùÂ≠òÂõæÁâá
import base64
image_data = base64.b64decode(response.data[0].b64_json)
with open(&quot;output.png&quot;, &quot;wb&quot;) as f:
    f.write(image_data)
```

**ÊîØÊåÅÁöÑÂèÇÊï∞**Ôºö
- **`size`**: ‰ªªÊÑè `WIDTHxHEIGHT` Ê†ºÂºèÔºàÂ¶Ç `1280x720`, `1024x1024`, `1920x1080`ÔºâÔºåËá™Âä®ËÆ°ÁÆóÂπ∂Êò†Â∞ÑÂà∞Ê†áÂáÜÂÆΩÈ´òÊØîÔºà21:9, 16:9, 9:16, 4:3, 3:4, 1:1Ôºâ
- **`quality`**: 
  - `&quot;hd&quot;` ‚Üí 4K ÂàÜËæ®ÁéáÔºàÈ´òË¥®ÈáèÔºâ
  - `&quot;medium&quot;` ‚Üí 2K ÂàÜËæ®ÁéáÔºà‰∏≠Á≠âË¥®ÈáèÔºâ
  - `&quot;standard&quot;` ‚Üí ÈªòËÆ§ÂàÜËæ®ÁéáÔºàÊ†áÂáÜË¥®ÈáèÔºâ
- **`n`**: ÁîüÊàêÂõæÁâáÊï∞ÈáèÔºà1-10Ôºâ
- **`response_format`**: `&quot;b64_json&quot;` Êàñ `&quot;url&quot;`ÔºàData URIÔºâ

#### ÊñπÂºè‰∫åÔºöChat API + ÂèÇÊï∞ËÆæÁΩÆ (‚ú® Êñ∞Â¢û)

**ÊâÄÊúâÂçèËÆÆ**ÔºàOpenAI„ÄÅClaudeÔºâÁöÑ Chat API Áé∞Âú®ÈÉΩÊîØÊåÅÁõ¥Êé•‰º†ÈÄí `size` Âíå `quality` ÂèÇÊï∞Ôºö

```python
# OpenAI Chat API
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image&quot;,
    size=&quot;1920x1080&quot;,      # ‚úÖ ÊîØÊåÅ‰ªªÊÑè WIDTHxHEIGHT Ê†ºÂºè
    quality=&quot;hd&quot;,          # ‚úÖ &quot;standard&quot; | &quot;hd&quot; | &quot;medium&quot;
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏Ç&quot;}]
)
```

```bash
# Claude Messages API
curl -X POST http://127.0.0.1:8045/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-antigravity&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gemini-3-pro-image&quot;,
    &quot;size&quot;: &quot;1280x720&quot;,
    &quot;quality&quot;: &quot;hd&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂè™ÂèØÁà±ÁöÑÁå´Âí™&quot;}]
  }&#039;
```

```

**ÂèÇÊï∞‰ºòÂÖàÁ∫ß**: `imageSize` ÂèÇÊï∞ &gt; `quality` ÂèÇÊï∞ &gt; Ê®°ÂûãÂêéÁºÄ

**‚ú® Êñ∞Â¢û `imageSize` ÂèÇÊï∞ÊîØÊåÅ**:

Èô§‰∫Ü `quality` ÂèÇÊï∞Â§ñ,Áé∞Âú®ËøòÊîØÊåÅÁõ¥Êé•‰ΩøÁî® Gemini ÂéüÁîüÁöÑ `imageSize` ÂèÇÊï∞:

```python
# ‰ΩøÁî® imageSize ÂèÇÊï∞(ÊúÄÈ´ò‰ºòÂÖàÁ∫ß)
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image&quot;,
    size=&quot;16:9&quot;,           # ÂÆΩÈ´òÊØî
    imageSize=&quot;4K&quot;,        # ‚ú® Áõ¥Êé•ÊåáÂÆöÂàÜËæ®Áéá: &quot;1K&quot; | &quot;2K&quot; | &quot;4K&quot;
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏Ç&quot;}]
)
```

```bash
# Claude Messages API ‰πüÊîØÊåÅ imageSize
curl -X POST http://127.0.0.1:8045/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-antigravity&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gemini-3-pro-image&quot;,
    &quot;size&quot;: &quot;1280x720&quot;,
    &quot;imageSize&quot;: &quot;4K&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂè™ÂèØÁà±ÁöÑÁå´Âí™&quot;}]
  }&#039;
```

**ÂèÇÊï∞ËØ¥Êòé**:
- **`imageSize`**: Áõ¥Êé•ÊåáÂÆöÂàÜËæ®Áéá (`&quot;1K&quot;` / `&quot;2K&quot;` / `&quot;4K&quot;`)
- **`quality`**: ÈÄöËøáË¥®ÈáèÁ≠âÁ∫ßÊé®Êñ≠ÂàÜËæ®Áéá (`&quot;standard&quot;` ‚Üí 1K, `&quot;medium&quot;` ‚Üí 2K, `&quot;hd&quot;` ‚Üí 4K)
- **‰ºòÂÖàÁ∫ß**: Â¶ÇÊûúÂêåÊó∂ÊåáÂÆö `imageSize` Âíå `quality`,Á≥ªÁªü‰ºö‰ºòÂÖà‰ΩøÁî® `imageSize`


#### ÊñπÂºè‰∏âÔºöChat Êé•Âè£ + Ê®°ÂûãÂêéÁºÄ
```python
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image-16-9-4k&quot;,  # Ê†ºÂºèÔºögemini-3-pro-image-[ÊØî‰æã]-[Ë¥®Èáè]
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏Ç&quot;}]
)
```

**Ê®°ÂûãÂêéÁºÄËØ¥Êòé**Ôºö
- **ÂÆΩÈ´òÊØî**: `-16-9`, `-9-16`, `-4-3`, `-3-4`, `-21-9`, `-1-1`
- **Ë¥®Èáè**: `-4k` (4K), `-2k` (2K), ‰∏çÂä†ÂêéÁºÄÔºàÊ†áÂáÜÔºâ
- **Á§∫‰æã**: `gemini-3-pro-image-16-9-4k` ‚Üí 16:9 ÊØî‰æã + 4K ÂàÜËæ®Áéá

#### ÊñπÂºèÂõõÔºöCherry Studio Á≠âÂÆ¢Êà∑Á´ØËÆæÁΩÆ
Âú®ÊîØÊåÅ OpenAI ÂçèËÆÆÁöÑÂÆ¢Êà∑Á´ØÔºàÂ¶Ç Cherry StudioÔºâ‰∏≠ÔºåÂèØ‰ª•ÈÄöËøá**Ê®°ÂûãËÆæÁΩÆ**È°µÈù¢ÈÖçÁΩÆÂõæÁâáÁîüÊàêÂèÇÊï∞Ôºö

1. **ËøõÂÖ•Ê®°ÂûãËÆæÁΩÆ**ÔºöÈÄâÊã© `gemini-3-pro-image` Ê®°Âûã
2. **ÈÖçÁΩÆÂèÇÊï∞**Ôºö
   - **Size (Â∞∫ÂØ∏)**: ËæìÂÖ•‰ªªÊÑè `WIDTHxHEIGHT` Ê†ºÂºèÔºàÂ¶Ç `1920x1080`, `1024x1024`Ôºâ
   - **Quality (Ë¥®Èáè)**: ÈÄâÊã© `standard` / `hd` / `medium`
   - **Number (Êï∞Èáè)**: ËÆæÁΩÆÁîüÊàêÂõæÁâáÊï∞ÈáèÔºà1-10Ôºâ
3. **ÂèëÈÄÅËØ∑Ê±Ç**ÔºöÁõ¥Êé•Âú®ÂØπËØùÊ°Ü‰∏≠ËæìÂÖ•ÂõæÁâáÊèèËø∞Âç≥ÂèØ

**ÂèÇÊï∞Êò†Â∞ÑËßÑÂàô**Ôºö
- `size: &quot;1920x1080&quot;` ‚Üí Ëá™Âä®ËÆ°ÁÆó‰∏∫ `16:9` ÂÆΩÈ´òÊØî
- `quality: &quot;hd&quot;` ‚Üí Êò†Â∞Ñ‰∏∫ `4K` ÂàÜËæ®Áéá
- `quality: &quot;medium&quot;` ‚Üí Êò†Â∞Ñ‰∏∫ `2K` ÂàÜËæ®Áéá


## üìù ÂºÄÂèëËÄÖ‰∏éÁ§æÂå∫

*   **ÁâàÊú¨ÊºîËøõ (Changelog)**:
    *   **v4.1.26 (2026-02-27)**:
        -   **[ÂäüËÉΩÂ¢ûÂº∫] ‰ºòÂåñÈÖçÈ¢ùÂà∑Êñ∞ÈÄªËæëÔºåÊîØÊåÅÂêåÊ≠•Á¶ÅÁî®Ë¥¶Âè∑**:
            -   **ÈÄªËæëÊîæÂÆΩ**: ‚ÄúÂà∑Êñ∞ÊâÄÊúâ‚ÄùÂíå‚ÄúÊâπÈáèÂà∑Êñ∞‚ÄùÁé∞Âú®‰∏çÂÜçË∑≥ËøáÊ†áËÆ∞‰∏∫ `disabled` Êàñ `proxy_disabled` ÁöÑË¥¶Âè∑„ÄÇ
            -   **Ëá™Âä®ÊÅ¢Â§ç**: ÂÖÅËÆ∏ÈÄöËøáÂà∑Êñ∞Êìç‰ΩúÂ∞ùËØïÈáçÊñ∞ÊøÄÊ¥ªÂõ† Token ËøáÊúüÊàñ‰∏¥Êó∂ÈîôËØØËÄåË¢´Á¶ÅÁî®ÁöÑË¥¶Âè∑ÔºåÊèêÂçá‰∫ÜÂ§öË¥¶Âè∑ÁÆ°ÁêÜÁöÑÁÅµÊ¥ªÊÄß„ÄÇ
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] ‰øÆÂ§ç Windows Á≥ªÁªü‰∏ãÂêéÂè∞‰ªªÂä°ÂØºËá¥ cmd ÈªëÊ°ÜÈó™ÁÉÅÁöÑÈóÆÈ¢ò**:
            -   **ÈùôÈªòÊâßË°å**: ÈÄöËøá‰∏∫ `std::process::Command` Â∞ÅË£ÖÊ≥®ÂÖ• `CREATE_NO_WINDOW` Ê†áÂøóÔºåËß£ÂÜ≥‰∫ÜÂú® Windows Á´ØÂ∫îÁî®Â∫ïÂ±ÇÁªÑ‰ª∂ÔºàÂ¶ÇÁâàÊú¨Êé¢Êµã„ÄÅÈáçÂêØÊõ¥Êñ∞Á≠âÔºâË∞ÉÁî®Á≥ªÁªüÂëΩ‰ª§Êó∂ÂºïÂèëÁöÑÂëΩ‰ª§Ë°åÁ™óÂè£‰∏ÄÈó™ËÄåËøáÁöÑËßÜËßâÂπ≤Êâ∞ÔºåÁ°Æ‰øùÂÖ®ËøáÁ®ãÊó†ËæπÊ°ÜÈùôÈªòÊâßË°å„ÄÇ
    *   **v4.1.25 (2026-02-27)**:
        -   **[Ê†∏ÂøÉÂäüËÉΩ] Âä®ÊÄÅÁîªÂõæÊ®°Âûã‰∏éÊñ∞Êû∂ÊûÑÊîØÊåÅ**:
            -   **Âä®ÊÄÅËß£Êûê**: ÁßªÈô§‰∫ÜÈíàÂØπ `gemini-3-pro-image` ÁöÑÁ°¨ÁºñÁ†ÅÈôêÂà∂„ÄÇÈÄöËøáÊñ∞Â¢ûÁöÑ `clean_image_model_name` Êô∫ËÉΩÊ∏ÖÊ¥óÂêéÁºÄÔºàÂ¶Ç `-4k`, `-16x9`ÔºâÔºåÂÖ®Èù¢ÂÖºÂÆπÂ¶Ç `gemini-3.1-flash-image` Á≠â‰ªªÊÑèÊú™Êù•Êñ∞Â¢ûÁöÑÁîªÂõæÊ®°Âûã„ÄÇ
            -   **ÈÖçÈ¢ùËá™ÈÄÇÂ∫î**: ‰ºòÂåñ‰∫Ü `normalize_to_standard_id`Ôºå‰ΩøÁî® `image` ÂÖ≥ÈîÆËØçÂÆΩÊ≥õÂåπÈÖçÔºåÁ°Æ‰øùÊñ∞Ê®°Âûã‰πüËÉΩÊ≠£Á°ÆËß¶ÂèëÈÖçÈ¢ù‰øùÊä§Êú∫Âà∂„ÄÇ
        -   **[Ê†∏ÂøÉÂäüËÉΩ] ËÅäÂ§©Êé•Âè£ (Chat Completions) ÁîªÂõæÊã¶Êà™ÊîØÊåÅ**:
            -   **Ë∑®ÁïåËûçÂêà**: OpenAI Âíå Claude ÂçèËÆÆÁöÑÂØπËØùÊµÅÁé∞Âú®ËÉΩÊô∫ËÉΩÊé¢ÊµãÁîªÂÉèÁîüÊàêÊÑèÂõæ„ÄÇÂΩì‰ΩøÁî®Â∏¶Êúâ `image` ÁöÑÊ®°ÂûãÂêçÊó∂ÔºåÁ≥ªÁªü‰ºöÂ∞ÜÂ∏∏ËßÑÊñáÊú¨ÁîüÊàêËØ∑Ê±ÇÈùôÈªòËΩ¨ÁßªÁªôÈ´òÁ∫ßÁîªÂõæÂºïÊìé„ÄÇ
            -   **ÊµÅÂºèÂõûÊòæ**: ÁîüÊàêÂÆåÊàêÂêéÔºåÈÄöËøá Markdown Ê†ºÂºèÔºà`![Generated Image](url)`Ôºâ‰ª• SSE ÊµÅÂºèËøîÂõûÂõæÁâáÈìæÊé•ÔºåÂÆåÁæéÈÄÇÈÖçÊâÄÊúâÊîØÊåÅ Markdown ÁöÑËÅäÂ§©ÂÆ¢Êà∑Á´Ø„ÄÇ
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] ÂΩªÂ∫ï‰øÆÂ§çÁîªÂõæÈáçÂÆöÂêë 404 ‰∏éÂèÇÊï∞Á©øÈÄèÂ§±Êïà**:
            -   **404 ÁßªÈô§**: ÁßªÈô§‰∫ÜÂ∫ïÂ±ÇË∞ÉÁî®‰∏≠ÊÆãÁïôÁöÑÊóßÊ®°ÂûãÁ°¨ÁºñÁ†ÅÔºåÊ†πÈô§Âõ†Ê®°Âûã‰ø°ÊÅØ‰∏ç‰∏ÄËá¥ÂØºËá¥ÁöÑ 404 Not Found Â¥©Ê∫ÉÂèäË¥¶Âè∑ÂèóÊçü„ÄÇ
            -   **Á≤æÂáÜÂèÇÊï∞ÁªßÊâø**: ‰øÆÂ§ç‰∫ÜÊú™‰º†ÂèÇÊï∞Êó∂Á≥ªÁªüÂº∫Âà∂Â°ûÂÖ•ÈªòËÆ§ `1024x1024` ÁöÑË°å‰∏∫„ÄÇÁé∞Âú®ÔºåÂ¶ÇÊûúÊ®°ÂûãÂêçÂ∏¶ÊúâÂêéÁºÄÔºàÂ¶Ç `gemini-3-pro-image-16x9-4k`ÔºâÔºåÂêéÂè∞‰ºö‰∏•Ê†º‰ºòÂÖàËß£ÊûêÂêéÁºÄÂàÜËæ®ÁéáËøõË°åÁ©øÈÄèÁªòÂõæ„ÄÇ
    *   **v4.1.24 (2026-02-26)**:
        -   **[ÂäüËÉΩË∞ÉÊï¥] Á¶ÅÁî®Ëá™Âä®È¢ÑÁÉ≠Ë∞ÉÂ∫¶Á®ãÂ∫èÔºå‰øùÁïôÊâãÂä®È¢ÑÁÉ≠**:
            -   **ÂèòÊõ¥ËØ¥Êòé**: ‰∏∫‰∫ÜÂáèÂ∞ë‰∏çÂøÖË¶ÅÁöÑÂêéÂè∞ËµÑÊ∫êÂç†Áî®ÔºåÊú¨ÁâàÊú¨Â∑≤Ê≥®ÈáäÊéâËá™Âä®È¢ÑÁÉ≠ÔºàSmart WarmupÔºâÁöÑÂêéÂè∞Ë∞ÉÂ∫¶ÈÄªËæë„ÄÇ
            -   **ËÆæÁΩÆÈöêËóè**: ËÆæÁΩÆÈ°µÈù¢‰∏≠ÁöÑ‚ÄúÊô∫ËÉΩÈ¢ÑÁÉ≠‚ÄùÈÖçÁΩÆÈ°πÂ∑≤ÈöêËóè„ÄÇ
            -   **ÊâãÂä®‰øùÁïô**: Ë¥¶Âè∑ÁÆ°ÁêÜÈ°µÈù¢ÁöÑÊâãÂä®È¢ÑÁÉ≠ÂäüËÉΩ‰øùÊåÅ‰∏çÂèòÔºå‰ªçÂèØÊ≠£Â∏∏‰ΩøÁî®„ÄÇ
            -   **ÊÅ¢Â§çÊåáÂºï**: Â¶ÇÊûúÊÇ®ÈúÄË¶ÅËá™Âä®È¢ÑÁÉ≠ÂäüËÉΩÔºåÂèØ‰ª•Ëá™Ë°åÊãâÂèñÊú¨È°πÁõÆÊ∫ê‰ª£Á†ÅÔºåÂú® `src-tauri/src/lib.rs` ‰∏≠ÂèñÊ∂à `start_scheduler` ÁöÑÊ≥®ÈáäÂπ∂Ëß£Èô§ `Settings.tsx` ‰∏≠Áõ∏ÂÖ≥ UI ÁöÑÊ≥®ÈáäÂêéÈáçÊñ∞ÁºñËØë‰ΩøÁî®„ÄÇ
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Êô∫ËÉΩÁâàÊú¨ÊåáÁ∫πÈÄâÊã©‰∏éÂêØÂä® Panic ‰øÆÂ§ç (Issue #2123)**:
            -   **ÈóÆÈ¢òÊ†πÊ∫ê**: 1) `constants.rs` ‰∏≠ÁöÑ `KNOWN_STABLE_VERSION` Á°¨ÁºñÁ†Å‰∫Ü‰ΩéÁâàÊú¨Âè∑ÔºåÂΩìÊú¨Âú∞ IDE Ê£ÄÊµãÂ§±Ë¥•Êó∂ÂõûÈÄÄËØ•ÁâàÊú¨‰Ωú‰∏∫ËØ∑Ê±ÇÂ§¥ÔºåÂØºËá¥ Google ÊãíÁªù Gemini 3.1 Pro Ê®°Âûã„ÄÇ2) Êñ∞Â¢ûÁöÑËøúÁ´ØÁâàÊú¨ÁΩëÁªúË∞ÉÁî®Áõ¥Êé•Âú® `LazyLock` ÂàùÂßãÂåñÔºàTokio ÂºÇÊ≠•‰∏ä‰∏ãÊñáÔºâ‰∏≠ÊâßË°åÔºåÂØºËá¥ `Cannot block the current thread` ‰∏•ÈáçÂ¥©Ê∫É„ÄÇ
            -   **‰øÆÂ§çÊñπÊ°à**: 1) ÂºïÂÖ•&quot;Êô∫ËÉΩÊúÄÂ§ßÁâàÊú¨&quot;Á≠ñÁï• `max(Êú¨Âú∞ÁâàÊú¨, ËøúÁ´ØÁâàÊú¨, 4.1.26)`ÔºåÂßãÁªàÂèñÊúÄÈ´òÂÄº„ÄÇ2) Â∞ÜÁΩëÁªúÊé¢ÊµãÈÄªËæëÁßªËá≥Áã¨Á´ã OS Á∫øÁ®ãÂπ∂ÈÖçÂêà `mpsc` ÈÄöÈÅìÔºåÂÆâÂÖ®ÈÅøÂºÄÂºÇÊ≠•ËøêË°åÊó∂ÈôêÂà∂„ÄÇ‰øùËØÅÊó†ËÆ∫Êú¨Âú∞ÁâàÊú¨Êñ∞ÊóßÔºåÊåáÁ∫πÂùá‰∏ç‰Ωé‰∫é‰∏äÊ∏∏Ë¶ÅÊ±ÇÔºå‰∏îÂ∫îÁî®ËÉΩÁ®≥ÂÆöÂêØÂä®„ÄÇ
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Âä®ÊÄÅÊ®°Âûã maxOutputTokens ÈôêÈ¢ùÁ≥ªÁªü (Êõø‰ª£ PR #2119 Á°¨ÁºñÁ†ÅÊñπÊ°à)**:
            -   **ÈóÆÈ¢òÊ†πÊ∫ê**: ÈÉ®ÂàÜÂÆ¢Êà∑Á´ØÂèëÈÄÅÁöÑ `maxOutputTokens` Ë∂ÖËøáÊ®°ÂûãÁâ©ÁêÜ‰∏äÈôêÔºàÂ¶Ç Flash ÈôêÂà∂ 64kÔºâÔºåÂØºËá¥‰∏äÊ∏∏ËøîÂõû 400 ÈîôËØØ„ÄÇ
            -   **‰∏âÂ±ÇÈôêÈ¢ùÊû∂ÊûÑ**:
                -   **Á¨¨‰∏ÄÂ±ÇÔºàÂä®ÊÄÅ‰ºòÂÖàÔºâ**: ÂÆûÊó∂ËØªÂèñË¥¶Âè∑ `quota.models` Êï∞ÊçÆ„ÄÇ
                -   **Á¨¨‰∫åÂ±ÇÔºàÈùôÊÄÅÈªòËÆ§Ë°®Ôºâ**: `model_limits.rs` ÂÜÖÁΩÆÂ∑≤Áü•ÈôêÈ¢ùÔºàÂ¶Ç Flash 65536Ôºâ„ÄÇ
                -   **Á¨¨‰∏âÂ±ÇÔºàÂÖ®Â±ÄÂÖúÂ∫ïÔºâ**: ÈªòËÆ§ 131072„ÄÇ
            -   **ÂÆûÁé∞ÁªÜËäÇ**: Âú® `wrap_request()` ‰∏≠Ê≥®ÂÖ•Ë£ÅÂâ™ÈÄªËæëÔºåÁ°Æ‰øùËØ∑Ê±ÇÂèÇÊï∞ÂêàÊ≥ï„ÄÇ
    *   **v4.1.23 (2026-02-25)**:
        -   **[ÂÆâÂÖ®Â¢ûÂº∫] ‰ºòÂåñ‰∏éÂéüÁîüÂØπÈΩêÂ∫îÁî®Â±Ç‰∏éÂ∫ïÂ±ÇÁâπÂæÅÊåáÁ∫πÔºåÊèêÂçáËØ∑Ê±ÇÁ®≥ÂÆöÊÄß‰∏éÈò≤Êã¶Êà™ËÉΩÂäõ„ÄÇ**
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Â∞Ü v1beta thinkingLevel ËΩ¨Êç¢‰∏∫ v1internal thinkingBudget (PR #2095)**:
            -   **ÈóÆÈ¢òÊ†πÊ∫ê**: OpenClaw„ÄÅCline Á≠âÂÆ¢Êà∑Á´ØÂèëÈÄÅ v1beta Ê†ºÂºèÁöÑ `thinkingLevel` Â≠óÁ¨¶‰∏≤Ôºà`&quot;NONE&quot;` / `&quot;LOW&quot;` / `&quot;MEDIUM&quot;` / `&quot;HIGH&quot;`ÔºâÂà∞ `generationConfig.thinkingConfig`„ÄÇÂΩì AGM ÈÄöËøá Google v1internal API ‰ª£ÁêÜËØ∑Ê±ÇÊó∂ÔºåGoogle ‰ºöÂõ†‰∏∫ v1internal ‰ªÖÊé•ÂèóÊï∞Â≠óÂûã `thinkingBudget` ËÄåÊãíÁªùËØ∑Ê±ÇÔºåËøîÂõû `400 INVALID_ARGUMENT`„ÄÇ
            -   **‰øÆÂ§çÊñπÊ°à**: Âú® `wrap_request()` ÁöÑÁé∞Êúâ budget Â§ÑÁêÜÈÄªËæë‰πãÂâçÔºåÊñ∞Â¢û‰∏Ä‰∏™Êó©ÊúüËΩ¨Êç¢Ê≠•È™§ÔºöÊ£ÄÊµã `thinkingLevel` Â≠óÁ¨¶‰∏≤ÔºåÂ∞ÜÂÖ∂Êò†Â∞Ñ‰∏∫ÂØπÂ∫îÁöÑÊï∞Â≠ó `thinkingBudget`Ôºà`NONE`‚Üí0, `LOW`‚Üí4096, `MEDIUM`‚Üí8192, `HIGH`‚Üí24576ÔºâÔºåÁÑ∂ÂêéÂà†Èô§ `thinkingLevel` Â≠óÊÆµÂπ∂ÂÜôÂÖ• `thinkingBudget`ÔºåÁ°Æ‰øù‰∏ãÊ∏∏ÊâÄÊúâ budget Â§ÑÁêÜÈÄªËæëÔºàÈ¢ÑÁÆóÂ∞ÅÈ°∂„ÄÅ`maxOutputTokens` Ë∞ÉÊï¥„ÄÅËá™ÈÄÇÂ∫îÊ£ÄÊµãÔºâÈÉΩËÉΩÁúãÂà∞Ê≠£Á°ÆÁöÑÊï∞ÂÄºÈ¢ÑÁÆó„ÄÇ
            -   **ÊµãËØï**: Â∑≤È™åËØÅ OpenClaw ÂèëÈÄÅ `thinkingLevel: &quot;LOW&quot;` Âà∞ `gemini-3.1-pro-high`ÔºàGemini ÂéüÁîüÂçèËÆÆÔºâÔºåËØ∑Ê±ÇÁé∞ËøîÂõû `200 OK`Ôºå‰∏çÂÜçÊä• 400 ÈîôËØØ„ÄÇ
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Ë¥¶Âè∑Êï∞ÊçÆÊçüÂùè‰∏éÂêéÂè∞‰ªªÂä°Êó†ÈôêÂæ™ÁéØ‰øÆÂ§ç (PR #2094)**:
            -   **ÈóÆÈ¢òÊ†πÊ∫ê**: ÂΩìÁî®Êà∑Âú®ËÆæÁΩÆ‰∏≠ËæìÂÖ•ËøáÂ§ßÁöÑÂà∑Êñ∞Èó¥ÈöîÂÄºÔºàÂ¶Ç 999999999ÔºâÊó∂Ôºå`interval * 60 * 1000` Ë∂ÖËøá JS ÂºïÊìé 32 ‰ΩçÊúâÁ¨¶Âè∑Êï¥Êï∞‰∏äÈôê `2,147,483,647ms`ÔºåÊµèËßàÂô®‰ºöÂ∞Ü `setInterval` Âª∂ËøüÈùôÈªòÊà™Êñ≠‰∏∫ 1msÔºåÂØºËá¥ÂâçÁ´ØÊØèÁßíËß¶ÂèëÊï∞ÂçÉÊ¨° `refreshAllQuotas`/`syncAccountFromDb` ËØ∑Ê±ÇÔºåËøõËÄåÂºïÂèëÂ§öÁ∫øÁ®ãÂπ∂ÂèëÂÜôÂêå‰∏Ä `[uuid].json` Êñá‰ª∂ÔºåÈÄ†ÊàêÂ≠óËäÇÊµÅ‰∫§Èîô„ÄÅJSON Â∞æÈÉ®ÊÆãÁïôÔºåË¥¶Âè∑Êï∞ÊçÆÊ∞∏‰πÖÊçüÂùè„ÄÇ
            -   **ÂéüÂ≠êÊñá‰ª∂ÂÜôÂÖ• (`account.rs`)**: `save_account` Êîπ‰∏∫ÂÖàÂÜôÂÖ• UUID ÂêéÁºÄÁöÑ‰∏¥Êó∂Êñá‰ª∂ÔºåÂÜçÈÄöËøá `fs::rename`ÔºàPOSIXÔºâ/ `MoveFileExW`ÔºàWindowsÔºâÂéüÂ≠êÊõøÊç¢ÁõÆÊ†áÊñá‰ª∂Ôºå‰∏éÂ∑≤ÊúâÁöÑ `save_account_index` ‰øùÊåÅ‰∏ÄËá¥Ôºå‰ªéÊ†πÊú¨‰∏äÊ∂àÈô§Âπ∂ÂèëÂÜôÂØºËá¥ÁöÑ JSON ÊçüÂùè„ÄÇ
            -   **setInterval Ê∫¢Âá∫‰øùÊä§ (`BackgroundTaskRunner.tsx`)**: ÂØπ `refresh_interval` Âíå `sync_interval` ‰∏§‰∏™ÂÆöÊó∂Âô®ÁöÑÂª∂ËøüÂèÇÊï∞Âä†‰∏ä `Math.min(..., 2147483647)` ‰∏äÁïåÈôêÂà∂ÔºåÈò≤Ê≠¢Ë∂ÖËøá INT32_MAX ÂêéË¢´ÊµèËßàÂô®Êà™Êñ≠‰∏∫ 1ms Êó†ÈôêÂæ™ÁéØ„ÄÇ
            -   **ËæìÂÖ•È™åËØÅ (`Settings.tsx`)**: Â∞Ü `refresh_interval` Âíå `sync_interval` ËæìÂÖ•Ê°ÜÁöÑ `max` Â±ûÊÄß‰ªé `60` Êõ¥Êñ∞‰∏∫ `35791`Ôºà35791 min √ó 60000 &lt; INT32_MAXÔºâÔºåÂπ∂Âú® `onChange` ‰∏≠Ê∑ªÂä† `NaN` fallbackÔºàÈªòËÆ§‰∏∫ 1ÔºâÂèäËåÉÂõ¥Â§πÁ¥ß `[1, 35791]`Ôºå‰ªéÊ∫êÂ§¥ÈòªÊñ≠ÈùûÊ≥ïÂÄºËæìÂÖ•„ÄÇ
        -   **[Ê†∏ÂøÉ‰ºòÂåñ] OAuth Êç¢Á•®‰∏ìÂ±ûÔºöÂâîÈô§ JA3 ÊåáÁ∫π‰∏éÂä®ÊÄÅ User-Agent ‰º™Ë£Ö**:
            -   **Á∫ØÂáÄËØ∑Ê±Ç**: ‰ªÖÈíàÂØπ `exchange_code`ÔºàÈ¶ñÊ¨°ÊéàÊùÉÔºâÂíå `refresh_access_token`ÔºàÈùôÈªòÁª≠ÊúüÔºâÁöÑÊç¢Á•®ËØ∑Ê±ÇÔºåÁßªÈô§‰∫ÜÂ∫ïÂ±ÇÁΩëÁªúÂ∫ìÁöÑ Chrome JA3 ÊåáÁ∫π‰º™Ë£ÖÔºåÊÅ¢Â§çÊ†áÂáÜÁ∫ØÂáÄÁöÑ TLSÁâπÂæÅ„ÄÇ
            -   **Âä®ÊÄÅ UA**: Êç¢Á•®Êó∂Ëá™Âä®ÊèêÂèñÁºñËØëÊó∂ÁâàÊú¨Âè∑ (`CURRENT_VERSION`) ÊûÑÂª∫‰∏ìÂ±ûÁöÑ `User-Agent`ÔºàÂ¶Ç `vscode/1.X.X (Antigravity/4.1.26)`ÔºâÔºå‰ª•ÂåπÈÖçÁ∫ØÂáÄ TLS ÈìæË∑Ø„ÄÇ
        -   **[ÂäüËÉΩÂ¢ûÂº∫] API Âèç‰ª£È°µÈù¢‰∏éËÆæÁΩÆÈ°µÊ®°ÂûãÂàóË°®ÂÖ®Èù¢Êé•ÂÖ•Âä®ÊÄÅÊ®°ÂûãÊï∞ÊçÆ**:
            -   **ÈóÆÈ¢òÊ†πÊ∫ê**: &quot;API Âèç‰ª£ ‚Üí ÊîØÊåÅÊ®°Âûã‰∏éÈõÜÊàê&quot;ÂàóË°®‰∏é&quot;Ê®°ÂûãË∑ØÁî±‰∏≠ÂøÉ&quot;ÁöÑÁõÆÊ†áÊ®°ÂûãÈÄâÊã©‰∏ãÊãâÊ°ÜÔºå‰ª•Âèä&quot;ËÆæÁΩÆ ‚Üí Âõ∫ÂÆöÈÖçÈ¢ùÊ®°Âûã&quot;ÂàóË°®ÔºåÊ≠§ÂâçÂùá‰ªÖ‰ªéÈùôÊÄÅ `MODEL_CONFIG` ËØªÂèñÁ°¨ÁºñÁ†ÅÊ®°Âûã‰ø°ÊÅØÔºåÂØºËá¥Ë¥¶Âè∑ÂÆûÈôÖ‰∏ãÂèëÁöÑÂä®ÊÄÅÊñ∞Ê®°ÂûãÔºàÂ¶Ç `GPT-OSS 120B`„ÄÅ`Gemini 3.1 Pro (High)` Á≠âÔºâÊó†Ê≥ïÂá∫Áé∞Âú®Ëøô‰∫õÂàóË°®‰∏≠„ÄÇ
            -   **‰øÆÂ§çÊñπÊ°à**:
                -   ÈáçÊûÑ `useProxyModels` HookÔºö‰ª•Ë¥¶Âè∑ `quota.models` Âä®ÊÄÅÊï∞ÊçÆ‰∏∫Á¨¨‰∏Ä‰ºòÂÖàÊï∞ÊçÆÊ∫êÔºåËÅöÂêàÊâÄÊúâË¥¶Âè∑ÈáåÊâÄÊúâÊ®°ÂûãÁöÑ `display_name`Ôºà‰∏∫‰∏ªÂ±ïÁ§∫ÂêçÁß∞ÔºâÂíå `name`Ôºà‰∏∫Ê®°Âûã IDÔºâÔºõ`MODEL_CONFIG` ‰ªÖ‰Ωú‰∏∫ÂõæÊ†á/ÂàÜÁªÑÁöÑÊ†∑ÂºèË°•ÂÖÖÔºå‰ª•ÂèäÊó†Ë¥¶Âè∑Êï∞ÊçÆÊó∂ÁöÑÈùôÊÄÅÂÖúÂ∫ï„ÄÇ
                -   Êñ∞Â¢ûËá™Âä®ÊáíÂä†ËΩΩÈÄªËæëÔºö`ApiProxy` È°µÈù¢Êú¨Ë∫´‰∏çË∞ÉÁî® `fetchAccounts`ÔºåÁé∞Âú® Hook ÂÜÖÈÉ®Ê£ÄÊµãÂà∞ store ‰∏∫Á©∫Êó∂Ëá™Âä®Ëß¶ÂèëÔºå‰øùËØÅÂä®ÊÄÅÊ®°ÂûãÂú®‰ªªÊÑèÂØºËà™Ë∑ØÂæÑ‰∏ãÂùáÂèØÊ≠£Â∏∏Â±ïÁ§∫„ÄÇ
                -   ÈáçÊûÑ `PinnedQuotaModels` ÁªÑ‰ª∂ÔºöÈááÁî®ÂêåÁ≠âÁ≠ñÁï•Ôºå‰ªé `useAccountStore` ÊãâÂèñÂÖ®Ë¥¶Âè∑Âä®ÊÄÅÊ®°ÂûãÔºåÂπ∂‰øÆÂ§ç‰∫ÜÂ∑≤Âõ∫ÂÆöÁöÑ &quot;thinking&quot; 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[farion1231/cc-switch]]></title>
            <link>https://github.com/farion1231/cc-switch</link>
            <guid>https://github.com/farion1231/cc-switch</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:44 GMT</pubDate>
            <description><![CDATA[A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/farion1231/cc-switch">farion1231/cc-switch</a></h1>
            <p>A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 21,786</p>
            <p>Forks: 1,342</p>
            <p>Stars today: 501 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# All-in-One Assistant for Claude Code, Codex &amp; Gemini CLI

[![Version](https://img.shields.io/badge/version-3.11.1-blue.svg)](https://github.com/farion1231/cc-switch/releases)
[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)
[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)
[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)

&lt;a href=&quot;https://trendshift.io/repositories/15372&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15372&quot; alt=&quot;farion1231%2Fcc-switch | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

English | [‰∏≠Êñá](README_ZH.md) | [Êó•Êú¨Ë™û](README_JA.md) | [Changelog](CHANGELOG.md)

&lt;/div&gt;

## ‚ù§Ô∏èSponsor

[![MiniMax](assets/partners/banners/minimax-en.jpeg)](https://platform.minimax.io/subscribe/coding-plan?code=ClLhgxr2je&amp;source=link)

MiniMax-M2.5 is a SOTA large language model designed for real-world productivity. Trained in a diverse range of complex real-world digital working environments, M2.5 builds upon the coding expertise of M2.1 to extend into general office work, reaching fluency in generating and operating Word, Excel, and Powerpoint files, context switching between diverse software environments, and working across different agent and human teams. Scoring 80.2% on SWE-Bench Verified, 51.3% on Multi-SWE-Bench, and 76.3% on BrowseComp, M2.5 is also more token efficient than previous generations, having been trained to optimize its actions and output through planning.

[Click](https://platform.minimax.io/subscribe/coding-plan?code=ClLhgxr2je&amp;source=link) to get an exclusive 12% off the MiniMax Coding Plan!

---

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;&lt;img src=&quot;assets/partners/logos/packycode.png&quot; alt=&quot;PackyCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using &lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;this link&lt;/a&gt; and enter the &quot;cc-switch&quot; promo code during first recharge to get 10% off.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/aigocode.png&quot; alt=&quot;AIGoCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses. AIGoCode has prepared a special benefit for CC Switch users: if you register via &lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;this link&lt;/a&gt;, you&#039;ll receive an extra 10% bonus credit on your first top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.aicodemirror.com/register?invitecode=9915W3&quot;&gt;&lt;img src=&quot;assets/partners/logos/aicodemirror.jpg&quot; alt=&quot;AICodeMirror&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AICodeMirror for sponsoring this project! AICodeMirror provides official high-stability relay services for Claude Code / Codex / Gemini CLI, with enterprise-grade concurrency, fast invoicing, and 24/7 dedicated technical support.
Claude Code / Codex / Gemini official channels at 38% / 2% / 9% of original price, with extra discounts on top-ups! AICodeMirror offers special benefits for CC Switch users: register via &lt;a href=&quot;https://www.aicodemirror.com/register?invitecode=9915W3&quot;&gt;this link&lt;/a&gt; to enjoy 20% off your first top-up, and enterprise customers can get up to 25% off!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://cubence.com/signup?code=CCSWITCH&amp;source=ccs&quot;&gt;&lt;img src=&quot;assets/partners/logos/cubence.png&quot; alt=&quot;Cubence&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to Cubence for sponsoring this project! Cubence is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more with flexible billing options including pay-as-you-go and monthly plans. Cubence provides special discounts for CC Switch users: register using &lt;a href=&quot;https://cubence.com/signup?code=CCSWITCH&amp;source=ccs&quot;&gt;this link&lt;/a&gt; and enter the &quot;CCSWITCH&quot; promo code during recharge to get 10% off every top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.dmxapi.cn/register?aff=bUHu&quot;&gt;&lt;img src=&quot;assets/partners/logos/dmx-en.jpg&quot; alt=&quot;DMXAPI&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to DMXAPI for sponsoring this project! DMXAPI provides global large model API services to 200+ enterprise users. One API key for all global models. Features include: instant invoicing, unlimited concurrency, starting from $0.15, 24/7 technical support. GPT/Claude/Gemini all at 32% off, domestic models 20-50% off, Claude Code exclusive models at 66% off! &lt;a href=&quot;https://www.dmxapi.cn/register?aff=bUHu&quot;&gt;Register here&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.right.codes/register?aff=CCSWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/rightcode.jpg&quot; alt=&quot;RightCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thank you to Right Code for sponsoring this project! Right Code reliably provides routing services for models such as Claude Code, Codex, and Gemini. It features a highly cost-effective Codex monthly subscription plan and &lt;strong&gt;supports quota rollovers‚Äîunused quota from one day can be carried over and used the next day.&lt;/strong&gt; Invoices are available upon top-up. Enterprise and team users can receive dedicated one-on-one support. Right Code also offers an exclusive discount for CC Switch users: register via &lt;a href=&quot;https://www.right.codes/register?aff=CCSWITCH&quot;&gt;this link&lt;/a&gt;, and with every top-up you will receive pay-as-you-go credit equivalent to 25% of the amount paid.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://aicoding.sh/i/CCSWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/aicoding.jpg&quot; alt=&quot;AICoding&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AICoding.sh for sponsoring this project! AICoding.sh ‚Äî Global AI Model API Relay Service at Unbeatable Prices! Claude Code at 19% of original price, GPT at just 1%! Trusted by hundreds of enterprises for cost-effective AI services. Supports Claude Code, GPT, Gemini and major domestic models, with enterprise-grade high concurrency, fast invoicing, and 24/7 dedicated technical support. CC Switch users who register via &lt;a href=&quot;https://aicoding.sh/i/CCSWITCH&quot;&gt;this link&lt;/a&gt; get 10% off their first top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://crazyrouter.com/register?aff=OZcm&amp;ref=cc-switch&quot;&gt;&lt;img src=&quot;assets/partners/logos/crazyrouter.jpg&quot; alt=&quot;AICoding&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to Crazyrouter for sponsoring this project! Crazyrouter is a high-performance AI API aggregation platform ‚Äî one API key for 300+ models including Claude Code, Codex, Gemini CLI, and more. All models at 55% of official pricing with auto-failover, smart routing, and unlimited concurrency. Crazyrouter offers an exclusive deal for CC Switch users: register via &lt;a href=&quot;https://crazyrouter.com/register?aff=OZcm&amp;ref=cc-switch&quot;&gt;this link&lt;/a&gt;  to get &lt;strong&gt;$2 free credit&lt;/strong&gt; instantly, plus enter promo code `CCSWITCH` on your first top-up for an extra &lt;strong&gt;30% bonus credit&lt;/strong&gt;! &lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.sssaicode.com/register?ref=DCP0SM&quot;&gt;&lt;img src=&quot;assets/partners/logos/sssaicode.png&quot; alt=&quot;SSSAiCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to SSSAiCode for sponsoring this project! SSSAiCode is a stable and reliable API relay service, dedicated to providing stable, reliable, and affordable Claude and Codex model services, &lt;strong&gt;offering high cost-effective official Claude service at just ¬•0.5/$ equivalent&lt;/strong&gt;, supporting monthly and pay-as-you-go billing plans with same-day fast invoicing. SSSAiCode offers a special deal for CC Switch users: register via &lt;a href=&quot;https://www.sssaicode.com/register?ref=DCP0SM&quot;&gt;this link&lt;/a&gt; to enjoy $10 extra credit on every top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

## Screenshots

|                  Main Interface                   |                  Add Provider                  |
| :-----------------------------------------------: | :--------------------------------------------: |
| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |

## Features

### Current Version: v3.11.1 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.11.1-en.md)

**v3.8.0 Major Update (2025-11-28)**

**Persistence Architecture Upgrade &amp; Brand New UI**

- **SQLite + JSON Dual-layer Architecture**
  - Migrated from JSON file storage to SQLite + JSON dual-layer structure
  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite
  - Device-level data (window state, local paths) stored in JSON
  - Lays the foundation for future cloud sync functionality
  - Schema version management for database migrations

- **Brand New User Interface**
  - Completely redesigned interface layout
  - Unified component styles and smoother animations
  - Optimized visual hierarchy
  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility

- **Japanese Language Support**
  - Added Japanese interface support (now supports Chinese/English/Japanese)

- **Auto Launch on Startup**
  - One-click enable/disable in settings
  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)

- **Skills Recursive Scanning**
  - Support for multi-level directory structures
  - Allow same-named skills from different repositories

- **Critical Bug Fixes**
  - Fixed custom endpoints lost when updating providers
  - Fixed Gemini configuration write issues
  - Fixed Linux WebKitGTK rendering issues

**v3.7.0 Highlights**

**Six Core Features, 18,000+ Lines of New Code**

- **Gemini CLI Integration**
  - Third supported AI CLI (Claude Code / Codex / Gemini)
  - Dual-file configuration support (`.env` + `settings.json`)
  - Complete MCP server management
  - Presets: Google Official (OAuth) / PackyCode / Custom

- **Claude Skills Management System**
  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)
  - One-click install/uninstall to `~/.claude/skills/`
  - Custom repository support + subdirectory scanning
  - Complete lifecycle management (discover/install/update)

- **Prompts Management System**
  - Multi-preset system prompt management (unlimited presets, quick switching)
  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)
  - Markdown editor (CodeMirror 6 + real-time preview)
  - Smart backfill protection, preserves manual modifications

- **MCP v3.7.0 Unified Architecture**
  - Single panel manages MCP servers across three applications
  - New SSE (Server-Sent Events) transport type
  - Smart JSON parser + Codex TOML format auto-correction
  - Unified import/export + bidirectional sync

- **Deep Link Protocol**
  - `ccswitch://` protocol registration (all platforms)
  - One-click import provider configs via shared links
  - Security validation + lifecycle integration

- **Environment Variable Conflict Detection**
  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)
  - Visual conflict indicators + resolution suggestions
  - Override warnings + backup before changes

**Core Capabilities**

- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations
- **AWS Bedrock Support**: Built-in AWS Bedrock provider presets with AKSK and API Key authentication, cross-region inference support (global/us/eu/apac), covering Claude Code and OpenCode
- **Speed Testing**: Measure API endpoint latency with visual quality indicators
- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)
- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)
- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations

**v3.6 Highlights**

- Provider duplication &amp; drag-and-drop sorting
- Multi-endpoint management &amp; custom config directory (cloud sync ready)
- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)
- WSL environment support with auto-sync on directory change
- 100% hooks test coverage &amp; complete architecture refactoring

**System Features**

- System tray with quick switching
- Single instance daemon
- Built-in auto-updater
- Atomic writes with rollback protection

## Download &amp; Installation

### System Requirements

- **Windows**: Windows 10 and above
- **macOS**: macOS 10.15 (Catalina) and above
- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions

### Windows Users

Download the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.

### macOS Users

**Method 1: Install via Homebrew (Recommended)**

```bash
brew tap farion1231/ccswitch
brew install --cask cc-switch
```

Update:

```bash
brew upgrade --cask cc-switch
```

**Method 2: Manual Download**

Download `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.

&gt; **Note**: Since the author doesn&#039;t have an Apple Developer account, you may see an &quot;unidentified developer&quot; warning on first launch. Please close it first, then go to &quot;System Settings&quot; ‚Üí &quot;Privacy &amp; Security&quot; ‚Üí click &quot;Open Anyway&quot;, and you&#039;ll be able to open it normally afterwards.

### Arch Linux Users

**Install via paru (Recommended)**

```bash
paru -S cc-switch-bin
```

### Linux Users

Download the latest Linux build from the [Releases](../../releases) page:

- `CC-Switch-v{version}-Linux.deb` (Debian/Ubuntu)
- `CC-Switch-v{version}-Linux.rpm` (Fedora/RHEL/openSUSE)
- `CC-Switch-v{version}-Linux.AppImage` (Universal)
- `CC-Switch-v{version}-Linux.flatpak` (Flatpak)

Flatpak install &amp; run:

```bash
flatpak install --user ./CC-Switch-v{version}-Linux.flatpak
flatpak run com.ccswitch.desktop
```

## Quick Start

### Basic Usage

1. **Add Provider**: Click &quot;Add Provider&quot; ‚Üí Choose preset or create custom configuration
2. **Switch Provider**:
   - Main UI: Select provider ‚Üí Click &quot;Enable&quot;
   - System Tray: Click provider name directly (instant effect)
3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes
4. **Back to Official**: Select the &quot;Official Login&quot; preset (Claude/Codex) or &quot;Google Official&quot; preset (Gemini), restart the corresponding client, then follow its login/OAuth flow

### MCP Management

- **Location**: Click &quot;MCP&quot; button in top-right corner
- **Add Server**:
  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)
  - Support stdio / http / sse transport types
  - Configure independent MCP servers for different apps
- **Enable/Disable**: Toggle switches to control which servers sync to live config
- **Sync**: Enabled servers auto-sync to each app&#039;s live files
- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files

### Skills Management (v3.7.0 New)

- **Location**: Click &quot;Skills&quot; button in top-right corner
- **Discover Skills**:
  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)
  - Add custom repositories (supports subdirectory scanning)
- **Install Skills**: Click &quot;Install&quot; to one-click install to `~/.claude/skills/`
- **Uninstall Skills**: Click &quot;Uninstall&quot; to safely remove and clean up state
- **Manage Repositories**: Add/remove custom GitHub repositories

### Prompts Management (v3.7.0 New)

- **Location**: Click &quot;Prompts&quot; button in top-right corner
- **Create Presets**:
  - Create unlimited system prompt presets
  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)
- **Switch Presets**: Select preset ‚Üí Click &quot;Activate&quot; to apply immediately
- **Sync Mechanism**:
  - Claude: `~/.claude/CLAUDE.md`
  - Codex: `~/.codex/AGENTS.md`
  - Gemini: `~/.gemini/GEMINI.md`
- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications

### Configuration Files

**Claude Code**

- Live config: `~/.claude/settings.json` (or `claude.json`)
- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`
- MCP servers: `~/.claude.json` ‚Üí `mcpServers`

**Codex**

- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)
- API key field: `OPENAI_API_KEY` in `auth.json`
- MCP servers: `~/.codex/config.toml` ‚Üí `[mcp_servers]` tables

**Gemini**

- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)
- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`
- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.
- MCP servers: `~/.gemini/settings.json` ‚Üí `mcpServers`
- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI

**CC Switch Storage (v3.8.0 New Architecture)**

- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)
- Local settings: `~/.cc-switch/settings.json` (device-level settings)
- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)

### Cloud Sync Setup

1. Go to Settings ‚Üí &quot;Custom Configuration Directory&quot;
2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)
3. Restart app to apply
4. Repeat on other devices to enable cross-device sync

&gt; **Note**: First launch auto-imports existing Claude/Codex configs as default provider.

## Architecture Overview

### Design Principles

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (React + TS)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Components  ‚îÇ  ‚îÇ    Hooks     ‚îÇ  ‚îÇ  TanStack Query  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (UI)      ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Logic) ‚îÇ‚îÄ‚îÄ‚îÇ   (Cache/Sync)   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ Tauri IPC
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Backend (Tauri + Rust)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Commands   ‚îÇ  ‚îÇ   Services   ‚îÇ  ‚îÇ  Models/Config   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ (API Layer) ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Layer) ‚îÇ‚îÄ‚îÄ‚îÇ     (Data)       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Core Design Patterns**

- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)
- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings
- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider
- **Atomic Writes**: Temp file + rename pattern prevents config corruption
- **Concurrency Safe**: Mutex-protected database connection avoids race conditions
- **Layered Architecture**: Clear separation (Commands ‚Üí Services ‚Üí DAO ‚Üí Database)

**Key Components**

- **ProviderService**: Provider CRUD, switching, backfill, sorting
- **McpService**: MCP server management, import/export, live file sync
- **ConfigService**: Config import/export, backup rotation
- **SpeedtestService**: API endpoint latency measurement

**v3.6 Refactoring**

- Backend: 5-phase refactoring (error handling ‚Üí command split ‚Üí tests ‚Üí services ‚Üí concurrency)
- Frontend: 4-stage refactoring (test infra ‚Üí hooks ‚Üí components ‚Üí cleanup)
- Testing: 100% hooks coverage + integration tests (vitest + MSW)

## Development

### Environment Requirements

- Node.js 18+
- pnpm 8+
- Rust 1.85+
- Tauri CLI 2.8+

### 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[risingwavelabs/risingwave]]></title>
            <link>https://github.com/risingwavelabs/risingwave</link>
            <guid>https://github.com/risingwavelabs/risingwave</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:43 GMT</pubDate>
            <description><![CDATA[Event streaming platform for agents, apps, and analytics. Continuously ingest, transform, and serve event data in real time, at scale.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/risingwavelabs/risingwave">risingwavelabs/risingwave</a></h1>
            <p>Event streaming platform for agents, apps, and analytics. Continuously ingest, transform, and serve event data in real time, at scale.</p>
            <p>Language: Rust</p>
            <p>Stars: 8,825</p>
            <p>Forks: 735</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source srcset=&quot;.github/RisingWave-logo-dark.svg&quot; width=&quot;500px&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
    &lt;img src=&quot;.github/RisingWave-logo-light.svg&quot; width=&quot;500px&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;


&lt;div align=&quot;center&quot;&gt;

### üåä Ride the wave of event streaming

&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.risingwave.com/&quot;&gt;Docs&lt;/a&gt; | &lt;a href=&quot;https://docs.risingwave.com/get-started/rw-benchmarks-stream-processing&quot;&gt;Benchmarks&lt;/a&gt; | &lt;a href=&quot;https://docs.risingwave.com/demos/overview&quot;&gt;Demos&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a
    href=&quot;https://github.com/risingwavelabs/risingwave/releases/latest&quot;
    target=&quot;_blank&quot;
  &gt;
    &lt;img alt=&quot;Release&quot; src=&quot;https://img.shields.io/github/v/release/risingwavelabs/risingwave.svg?sort=semver&quot; /&gt;
  &lt;/a&gt;
  &lt;a
    href=&quot;https://go.risingwave.com/slack&quot;
    target=&quot;_blank&quot;
  &gt;
    &lt;img alt=&quot;Slack&quot; src=&quot;https://badgen.net/badge/Slack/Join%20RisingWave/0abd59?icon=slack&quot; /&gt;
  &lt;/a&gt;
  &lt;a
    href=&quot;https://x.com/risingwavelabs&quot;
    target=&quot;_blank&quot;
  &gt;
    &lt;img alt=&quot;X&quot; src=&quot;https://img.shields.io/twitter/follow/risingwavelabs&quot; /&gt;
  &lt;/a&gt;
  &lt;a
    href=&quot;https://www.youtube.com/@risingwave-labs&quot;
    target=&quot;_blank&quot;
  &gt;
    &lt;img alt=&quot;YouTube&quot; src=&quot;https://img.shields.io/youtube/channel/views/UCsHwdyBRxBpmkA5RRd0YNEA&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

RisingWave is an enterprise-grade event streaming platform designed to offer the &lt;i&gt;&lt;b&gt;simplest&lt;/b&gt;&lt;/i&gt; and &lt;i&gt;&lt;b&gt;most cost-effective&lt;/b&gt;&lt;/i&gt; way to &lt;b&gt;ingest&lt;/b&gt;, &lt;b&gt;process&lt;/b&gt;, and &lt;b&gt;manage&lt;/b&gt; real-time event data ‚Äî with built-in support for the [Apache Iceberg‚Ñ¢](https://iceberg.apache.org/) open table format. It provides both a Postgres-compatible [SQL interface](https://docs.risingwave.com/sql/overview) and a DataFrame-style [Python interface](https://docs.risingwave.com/python-sdk/intro).

RisingWave can &lt;b&gt;ingest&lt;/b&gt; millions of events per second, continuously &lt;b&gt;join and analyze&lt;/b&gt; live streams with historical data, &lt;b&gt;serve&lt;/b&gt; ad-hoc queries at low latency, and &lt;b&gt;manage&lt;/b&gt; data reliably in Apache Iceberg‚Ñ¢ tables.

![RisingWave](./docs/dev/src/images/architecture_20250609.jpg)

## Try it out in 60 seconds

Install RisingWave standalone mode:
```shell
curl -L https://risingwave.com/sh | sh
```

To learn about other installation options, such as using a Docker image, see the [quick start guide](https://docs.risingwave.com/get-started/quickstart).

## Unified platform for streaming data

RisingWave delivers a unified streaming data platform that combines **ultra-low-latency stream processing** and **Iceberg-native data management**.

### Low-latency streaming ingestion and processing
RisingWave integrates real-time streaming ingestion, stream processing and low-latency serving in a single system. It continuously ingests data from streaming and batch sources, performs incremental computations across streams and tables with end-to-end freshness under 100 ms. Materialized views can be served directly within RisingWave with 10‚Äì20 ms p99 query latency, or delivered to downstream systems.

### Iceberg lakehouse ingestion, transformation, and management
RisingWave treats Apache Iceberg‚Ñ¢ as a first-class citizen. It directly hosts and manages the Iceberg REST catalog, allowing users to create and operate Iceberg tables through a PostgreSQL-compatible interface. RisingWave supports two write modes: Merge-on-Read (MoR) and Copy-on-Write (CoW), to suit different ingestion and query patterns. It also provides built-in table maintenance capabilities, including compaction, small-file optimization, vacuum, and snapshot cleanup, ensuring efficient and consistent data management without external tools or pipelines.

_Plug: [Nimtable](https://github.com/nimtable/nimtable) is an observability tool developed by RisingWave for easily exploring and managing Iceberg tables._



## Key design decisions

RisingWave is designed to be easier to use and more cost-efficient:

### PostgreSQL compatibility

* **Seamless integration:** Connects via the PostgreSQL wire protocol, working with psql, JDBC, and any Postgres tool.
* **Expressive SQL:** Supports structured, semi-structured, and unstructured data with a familiar SQL dialect.
* **No manual state tuning:** Eliminates complex state management configurations.

### S3 as primary storage

RisingWave stores tables, materialized views, and internal states of stream processing jobs in S3 (or equivalent object storage), providing:
- **High performance:** Optimized for complex queries, including joins and time windowing.
- **Fast recovery:** Restores from system failures within seconds.
- **[Dynamic scaling](https://docs.risingwave.com/deploy/k8s-cluster-scaling):** Instantly adjusts resources to handle workload spikes.

Beyond caching hot data in memory, RisingWave supports [**elastic disk cache**](https://docs.risingwave.com/get-started/disk-cache), a powerful performance optimization that uses local disks or EBS for efficient data caching. This minimizes access to S3, lowering processing latency and cutting S3 access costs.

### Apache Iceberg‚Ñ¢ native support
RisingWave [**natively integrates with Apache Iceberg‚Ñ¢**](https://docs.risingwave.com/iceberg/overview), enabling continuous ingestion of streaming data into Iceberg tables. It can also read directly from Iceberg, perform automatic compaction, and maintain table health over time. Since Iceberg is an open table format, results are accessible by other query engines ‚Äî making storage not only cost-efficient, but interoperable by design.

## In what use cases does RisingWave excel?
RisingWave is particularly effective for the following use cases:

* **Live dashboards**: Achieve sub-second data freshness in live dashboards, ideal for high-stakes scenarios like stock trading, sports betting, and IoT monitoring.
* **Monitoring and alerting**: Develop sophisticated monitoring and alerting systems for critical applications such as fraud and anomaly detection.
* **Real-time data enrichment**: Continuously ingest data from diverse sources, conduct real-time data enrichment, and efficiently deliver the results to downstream systems.
* **Feature engineering**: Transform batch and streaming data into features in your machine learning models using a unified codebase, ensuring seamless integration and consistency.
* **Iceberg-based lakehouses**: Power real-time lakehouse architectures where streaming data is continuously written to Apache Iceberg‚Ñ¢ tables for unified analytics, governance, and long-term retention in open formats.

## Production deployments

[**RisingWave Cloud**](https://cloud.risingwave.com) offers the easiest way to run RisingWave in production.

For **Docker deployment**, please refer to [Docker Compose](https://docs.risingwave.com/deploy/risingwave-docker-compose/).

For **Kubernetes deployment**, please refer to [Kubernetes with Helm](https://docs.risingwave.com/deploy/risingwave-k8s-helm/) or [Kubernetes with Operator](https://docs.risingwave.com/deploy/risingwave-kubernetes/).

## Community

Looking for help, discussions, collaboration opportunities, or a casual afternoon chat with our fellow engineers and community members? Join our [Slack workspace](https://risingwave.com/slack)!

## Notes on telemetry


RisingWave uses [Scarf](https://scarf.sh/) to collect anonymized installation analytics. These analytics help support us understand and improve the distribution of our package. The privacy policy of Scarf is available at [https://about.scarf.sh/privacy-policy](https://about.scarf.sh/privacy-policy).

RisingWave also collects anonymous usage statistics to better understand how the community is using RisingWave. The sole intention of this exercise is to help improve the product. Users may opt out easily at any time. Please refer to the [user documentation](https://docs.risingwave.com/operate/telemetry/) for more details.

## License

RisingWave is distributed under the Apache License (Version 2.0). Please refer to [LICENSE](LICENSE) for more information.

## Contributing

Thanks for your interest in contributing to the project! Please refer to [RisingWave Developer Guide](https://risingwavelabs.github.io/risingwave/) for more information.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cloudflare/quiche]]></title>
            <link>https://github.com/cloudflare/quiche</link>
            <guid>https://github.com/cloudflare/quiche</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:42 GMT</pubDate>
            <description><![CDATA[ü•ß Savoury implementation of the QUIC transport protocol and HTTP/3]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudflare/quiche">cloudflare/quiche</a></h1>
            <p>ü•ß Savoury implementation of the QUIC transport protocol and HTTP/3</p>
            <p>Language: Rust</p>
            <p>Stars: 11,289</p>
            <p>Forks: 942</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>![quiche](quiche.svg)

[![crates.io](https://img.shields.io/crates/v/quiche.svg)](https://crates.io/crates/quiche)
[![docs.rs](https://docs.rs/quiche/badge.svg)](https://docs.rs/quiche)
[![license](https://img.shields.io/github/license/cloudflare/quiche.svg)](https://opensource.org/licenses/BSD-2-Clause)
![build](https://img.shields.io/github/actions/workflow/status/cloudflare/quiche/stable.yml?branch=master)

[quiche] is an implementation of the QUIC transport protocol and HTTP/3 as
specified by the [IETF]. It provides a low level API for processing QUIC packets
and handling connection state. The application is responsible for providing I/O
(e.g. sockets handling) as well as an event loop with support for timers.

For more information on how quiche came about and some insights into its design
you can read a [post] on Cloudflare&#039;s blog that goes into some more detail.

[quiche]: https://docs.quic.tech/quiche/
[ietf]: https://quicwg.org/
[post]: https://blog.cloudflare.com/enjoy-a-slice-of-quic-and-rust/

Who uses quiche?
----------------

### Cloudflare

quiche powers Cloudflare edge network&#039;s [HTTP/3 support][cloudflare-http3]. The
[cloudflare-quic.com](https://cloudflare-quic.com) website can be used for
testing and experimentation.

### Android

Android&#039;s DNS resolver uses quiche to [implement DNS over HTTP/3][android-http3].

### curl

quiche can be [integrated into curl][curl-http3] to provide support for HTTP/3.

[cloudflare-http3]: https://blog.cloudflare.com/http3-the-past-present-and-future/
[android-http3]: https://security.googleblog.com/2022/07/dns-over-http3-in-android.html
[curl-http3]: https://github.com/curl/curl/blob/master/docs/HTTP3.md#quiche-version

Getting Started
---------------

### Command-line apps

Before diving into the quiche API, here are a few examples on how to use the
quiche tools provided as part of the [quiche-apps](apps/) crate. These are not
suitable for production environments; see [disclaimers and
notes](#disclaimers-and-notes).

After cloning the project according to the command mentioned in the [building](#building) section, the client can be run as follows:

```bash
 $ cargo run --bin quiche-client -- https://cloudflare-quic.com/
```

while the server can be run as follows:

```bash
 $ cargo run --bin quiche-server -- --cert apps/src/bin/cert.crt --key apps/src/bin/cert.key
```

(note that the certificate provided is self-signed and should not be used in
production)

Use the `--help` command-line flag to get a more detailed description of each
tool&#039;s options.

### Configuring connections

The first step in establishing a QUIC connection using quiche is creating a
[`Config`] object:

```rust
let mut config = quiche::Config::new(quiche::PROTOCOL_VERSION)?;
config.set_application_protos(&amp;[b&quot;example-proto&quot;]);

// Additional configuration specific to application and use case...
```

The [`Config`] object controls important aspects of the QUIC connection such
as QUIC version, ALPN IDs, flow control, congestion control, idle timeout
and other properties or features.

QUIC is a general-purpose transport protocol and there are several
configuration properties where there is no reasonable default value. For
example, the permitted number of concurrent streams of any particular type
is dependent on the application running over QUIC, and other use-case
specific concerns.

quiche defaults several properties to zero, applications most likely need
to set these to something else to satisfy their needs using the following:

- [`set_initial_max_streams_bidi()`]
- [`set_initial_max_streams_uni()`]
- [`set_initial_max_data()`]
- [`set_initial_max_stream_data_bidi_local()`]
- [`set_initial_max_stream_data_bidi_remote()`]
- [`set_initial_max_stream_data_uni()`]

[`Config`] also holds TLS configuration. This can be changed by mutators on
the an existing object, or by constructing a TLS context manually and
creating a configuration using [`with_boring_ssl_ctx_builder()`].

A configuration object can be shared among multiple connections.

### Connection setup

On the client-side the [`connect()`] utility function can be used to create
a new connection, while [`accept()`] is for servers:

```rust
// Client connection.
let conn = quiche::connect(Some(&amp;server_name), &amp;scid, local, peer, &amp;mut config)?;

// Server connection.
let conn = quiche::accept(&amp;scid, None, local, peer, &amp;mut config)?;
```

### Handling incoming packets

Using the connection&#039;s [`recv()`] method the application can process
incoming packets that belong to that connection from the network:

```rust
let to = socket.local_addr().unwrap();

loop {
    let (read, from) = socket.recv_from(&amp;mut buf).unwrap();

    let recv_info = quiche::RecvInfo { from, to };

    let read = match conn.recv(&amp;mut buf[..read], recv_info) {
        Ok(v) =&gt; v,

        Err(e) =&gt; {
            // An error occurred, handle it.
            break;
        },
    };
}
```

### Generating outgoing packets

Outgoing packet are generated using the connection&#039;s [`send()`] method
instead:

```rust
loop {
    let (write, send_info) = match conn.send(&amp;mut out) {
        Ok(v) =&gt; v,

        Err(quiche::Error::Done) =&gt; {
            // Done writing.
            break;
        },

        Err(e) =&gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;out[..write], &amp;send_info.to).unwrap();
}
```

When packets are sent, the application is responsible for maintaining a
timer to react to time-based connection events. The timer expiration can be
obtained using the connection&#039;s [`timeout()`] method.

```rust
let timeout = conn.timeout();
```

The application is responsible for providing a timer implementation, which
can be specific to the operating system or networking framework used. When
a timer expires, the connection&#039;s [`on_timeout()`] method should be called,
after which additional packets might need to be sent on the network:

```rust
// Timeout expired, handle it.
conn.on_timeout();

// Send more packets as needed after timeout.
loop {
    let (write, send_info) = match conn.send(&amp;mut out) {
        Ok(v) =&gt; v,

        Err(quiche::Error::Done) =&gt; {
            // Done writing.
            break;
        },

        Err(e) =&gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;out[..write], &amp;send_info.to).unwrap();
}
```

#### Pacing

It is recommended that applications [pace] sending of outgoing packets to
avoid creating packet bursts that could cause short-term congestion and
losses in the network.

quiche exposes pacing hints for outgoing packets through the [`at`] field
of the [`SendInfo`] structure that is returned by the [`send()`] method.
This field represents the time when a specific packet should be sent into
the network.

Applications can use these hints by artificially delaying the sending of
packets through platform-specific mechanisms (such as the [`SO_TXTIME`]
socket option on Linux), or custom methods (for example by using user-space
timers).

[pace]: https://datatracker.ietf.org/doc/html/rfc9002#section-7.7
[`SO_TXTIME`]: https://man7.org/linux/man-pages/man8/tc-etf.8.html

### Sending and receiving stream data

After some back and forth, the connection will complete its handshake and
will be ready for sending or receiving application data.

Data can be sent on a stream by using the [`stream_send()`] method:

```rust
if conn.is_established() {
    // Handshake completed, send some data on stream 0.
    conn.stream_send(0, b&quot;hello&quot;, true)?;
}
```

The application can check whether there are any readable streams by using
the connection&#039;s [`readable()`] method, which returns an iterator over all
the streams that have outstanding data to read.

The [`stream_recv()`] method can then be used to retrieve the application
data from the readable stream:

```rust
if conn.is_established() {
    // Iterate over readable streams.
    for stream_id in conn.readable() {
        // Stream is readable, read until there&#039;s no more data.
        while let Ok((read, fin)) = conn.stream_recv(stream_id, &amp;mut buf) {
            println!(&quot;Got {} bytes on stream {}&quot;, read, stream_id);
        }
    }
}
```

### HTTP/3

The quiche [HTTP/3 module] provides a high level API for sending and
receiving HTTP requests and responses on top of the QUIC transport protocol.

[`Config`]: https://docs.quic.tech/quiche/struct.Config.html
[`set_initial_max_streams_bidi()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_bidi
[`set_initial_max_streams_uni()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_uni
[`set_initial_max_data()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_data
[`set_initial_max_stream_data_bidi_local()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_local
[`set_initial_max_stream_data_bidi_remote()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_remote
[`set_initial_max_stream_data_uni()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_uni
[`with_boring_ssl_ctx_builder()`]: https://docs.quic.tech/quiche/struct.Config.html#method.with_boring_ssl_ctx_builder
[`connect()`]: https://docs.quic.tech/quiche/fn.connect.html
[`accept()`]: https://docs.quic.tech/quiche/fn.accept.html
[`recv()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.recv
[`send()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.send
[`timeout()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.timeout
[`on_timeout()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.on_timeout
[`stream_send()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.stream_send
[`readable()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.readable
[`stream_recv()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.stream_recv
[HTTP/3 module]: https://docs.quic.tech/quiche/h3/index.html

Have a look at the [quiche/examples/] directory for more complete examples on
how to use the quiche API, including examples on how to use quiche in C/C++
applications (see below for more information).

[examples/]: quiche/examples/

Calling quiche from C/C++
-------------------------

quiche exposes a [thin C API] on top of the Rust API that can be used to more
easily integrate quiche into C/C++ applications (as well as in other languages
that allow calling C APIs via some form of FFI). The C API follows the same
design of the Rust one, modulo the constraints imposed by the C language itself.

When running ``cargo build``, a static library called ``libquiche.a`` will be
built automatically alongside the Rust one. This is fully stand-alone and can
be linked directly into C/C++ applications.

Note that in order to enable the FFI API, the ``ffi`` feature must be enabled (it
is disabled by default), by passing ``--features ffi`` to ``cargo``.

[thin C API]: https://github.com/cloudflare/quiche/blob/master/quiche/include/quiche.h

Building
--------

quiche requires Rust 1.85 or later to build. The latest stable Rust release can
be installed using [rustup](https://rustup.rs/).

Once the Rust build environment is setup, the quiche source code can be fetched
using git:

```bash
 $ git clone --recursive https://github.com/cloudflare/quiche
```

and then built using cargo:

```bash
 $ cargo build --examples
```

cargo can also be used to run the testsuite:

```bash
 $ cargo test
```

Note that [BoringSSL], which is used to implement QUIC&#039;s cryptographic handshake
based on TLS, needs to be built and linked to quiche. This is done automatically
when building quiche using cargo, but requires the `cmake` command to be
available during the build process. On Windows you also need
[NASM](https://www.nasm.us/). The [official BoringSSL
documentation](https://github.com/google/boringssl/blob/master/BUILDING.md) has
more details.

In alternative you can use your own custom build of BoringSSL by configuring
the BoringSSL directory with the ``QUICHE_BSSL_PATH`` environment variable:

```bash
 $ QUICHE_BSSL_PATH=&quot;/path/to/boringssl&quot; cargo build --examples
```

Alternatively you can use [OpenSSL/quictls]. To enable quiche to use this vendor
the ``openssl`` feature can be added to the ``--feature`` list. Be aware that
``0-RTT`` is not supported if this vendor is used.

[BoringSSL]: https://boringssl.googlesource.com/boringssl/

[OpenSSL/quictls]: https://github.com/quictls/openssl

### Building for Android

Building quiche for Android (NDK version 19 or higher, 21 recommended), can be
done using [cargo-ndk] (v2.0 or later).

First the [Android NDK] needs to be installed, either using Android Studio or
directly, and the `ANDROID_NDK_HOME` environment variable needs to be set to the
NDK installation path, e.g.:

```bash
 $ export ANDROID_NDK_HOME=/usr/local/share/android-ndk
```

Then the Rust toolchain for the Android architectures needed can be installed as
follows:

```bash
 $ rustup target add aarch64-linux-android armv7-linux-androideabi i686-linux-android x86_64-linux-android
```

Note that the minimum API level is 21 for all target architectures.

[cargo-ndk] (v2.0 or later) also needs to be installed:

```bash
 $ cargo install cargo-ndk
```

Finally the quiche library can be built using the following procedure. Note that
the `-t &lt;architecture&gt;` and `-p &lt;NDK version&gt;` options are mandatory.

```bash
 $ cargo ndk -t arm64-v8a -p 21 -- build --features ffi
```

See [build_android_ndk19.sh] for more information.

[Android NDK]: https://developer.android.com/ndk
[cargo-ndk]: https://docs.rs/crate/cargo-ndk
[build_android_ndk19.sh]: https://github.com/cloudflare/quiche/blob/master/tools/android/build_android_ndk19.sh

### Building for iOS

To build quiche for iOS, you need the following:

- Install Xcode command-line tools. You can install them with Xcode or with the
  following command:

```bash
 $ xcode-select --install
```

- Install the Rust toolchain for iOS architectures:

```bash
 $ rustup target add aarch64-apple-ios x86_64-apple-ios
```

- Install `cargo-lipo`:

```bash
 $ cargo install cargo-lipo
```

To build libquiche, run the following command:

```bash
 $ cargo lipo --features ffi
```

or

```bash
 $ cargo lipo --features ffi --release
```

iOS build is tested in Xcode 10.1 and Xcode 11.2.

### Building Docker images

In order to build the Docker images, simply run the following command:

```bash
 $ make docker-build
```

You can find the quiche Docker images on the following Docker Hub repositories:

- [cloudflare/quiche](https://hub.docker.com/repository/docker/cloudflare/quiche)
- [cloudflare/quiche-qns](https://hub.docker.com/repository/docker/cloudflare/quiche-qns)

The `latest` tag will be updated whenever quiche master branch updates.

**cloudflare/quiche**

Provides a server and client installed in /usr/local/bin.

**cloudflare/quiche-qns**

Provides the script to test quiche within the [quic-interop-runner](https://github.com/marten-seemann/quic-interop-runner).

Disclaimers and Notes
---------

‚ö†Ô∏è This repository includes a number of client and server example
applications that are provided to demonstrate simple usage of the quiche library
API. They are not intended to be used in production environments; no
performance, security or reliability guarantees are provided.


Copyright
---------

Copyright (C) 2018-2019, Cloudflare, Inc.

See [COPYING] for the license.

[COPYING]: https://github.com/cloudflare/quiche/tree/master/COPYING
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[openai/codex]]></title>
            <link>https://github.com/openai/codex</link>
            <guid>https://github.com/openai/codex</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:41 GMT</pubDate>
            <description><![CDATA[Lightweight coding agent that runs in your terminal]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/codex">openai/codex</a></h1>
            <p>Lightweight coding agent that runs in your terminal</p>
            <p>Language: Rust</p>
            <p>Stars: 62,413</p>
            <p>Forks: 8,300</p>
            <p>Stars today: 154 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install --cask codex&lt;/code&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer.
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/openai/codex/blob/main/.github/codex-cli-splash.png&quot; alt=&quot;Codex CLI splash&quot; width=&quot;80%&quot; /&gt;
&lt;/p&gt;
&lt;/br&gt;
If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href=&quot;https://developers.openai.com/codex/ide&quot;&gt;install in your IDE.&lt;/a&gt;
&lt;/br&gt;If you want the desktop app experience, run &lt;code&gt;codex app&lt;/code&gt; or visit &lt;a href=&quot;https://chatgpt.com/codex?app-landing-page=true&quot;&gt;the Codex App page&lt;/a&gt;.
&lt;/br&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href=&quot;https://chatgpt.com/codex&quot;&gt;chatgpt.com/codex&lt;/a&gt;.&lt;/p&gt;

---

## Quickstart

### Installing and running Codex CLI

Install globally with your preferred package manager:

```shell
# Install using npm
npm install -g @openai/codex
```

```shell
# Install using Homebrew
brew install --cask codex
```

Then simply run `codex` to get started.

&lt;details&gt;
&lt;summary&gt;You can also go to the &lt;a href=&quot;https://github.com/openai/codex/releases/latest&quot;&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt;

Each GitHub Release contains many executables, but in practice, you likely want one of these:

- macOS
  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`
  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`
- Linux
  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`
  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`

Each archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.

&lt;/details&gt;

### Using Codex with your ChatGPT plan

Run `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what&#039;s included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).

You can also use Codex with an API key, but this requires [additional setup](https://developers.openai.com/codex/auth#sign-in-with-an-api-key).

## Docs

- [**Codex Documentation**](https://developers.openai.com/codex)
- [**Contributing**](./docs/contributing.md)
- [**Installing &amp; building**](./docs/install.md)
- [**Open source fund**](./docs/open-source-fund.md)

This repository is licensed under the [Apache-2.0 License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[longbridge/gpui-component]]></title>
            <link>https://github.com/longbridge/gpui-component</link>
            <guid>https://github.com/longbridge/gpui-component</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:40 GMT</pubDate>
            <description><![CDATA[Rust GUI components for building fantastic cross-platform desktop application by using GPUI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/longbridge/gpui-component">longbridge/gpui-component</a></h1>
            <p>Rust GUI components for building fantastic cross-platform desktop application by using GPUI.</p>
            <p>Language: Rust</p>
            <p>Stars: 10,501</p>
            <p>Forks: 477</p>
            <p>Stars today: 48 stars today</p>
            <h2>README</h2><pre># GPUI Component

[![Build Status](https://github.com/longbridge/gpui-component/actions/workflows/ci.yml/badge.svg)](https://github.com/longbridge/gpui-component/actions/workflows/ci.yml) [![Docs](https://docs.rs/gpui-component/badge.svg)](https://docs.rs/gpui-component/) [![Crates.io](https://img.shields.io/crates/v/gpui-component.svg)](https://crates.io/crates/gpui-component)

UI components for building fantastic desktop applications using [GPUI](https://gpui.rs).

## Features

- **Richness**: 60+ cross-platform desktop UI components.
- **Native**: Inspired by macOS and Windows controls, combined with shadcn/ui design for a modern experience.
- **Ease of Use**: Stateless `RenderOnce` components, simple and user-friendly.
- **Customizable**: Built-in `Theme` and `ThemeColor`, supporting multi-theme and variable-based configurations.
- **Versatile**: Supports sizes like `xs`, `sm`, `md`, and `lg`.
- **Flexible Layout**: Dock layout for panel arrangements, resizing, and freeform (Tiles) layouts.
- **High Performance**: Virtualized Table and List components for smooth large-data rendering.
- **Content Rendering**: Native support for Markdown and simple HTML.
- **Charting**: Built-in charts for visualizing your data.
- **Editor**: High performance code editor (support up to 200K lines) with LSP (diagnostics, completion, hover, etc).
- **Syntax Highlighting**: Syntax highlighting for editor and markdown components using Tree Sitter.

## Showcase

Here is the first application: [Longbridge Pro](https://longbridge.com/desktop), built using GPUI Component.

&lt;img width=&quot;1763&quot; alt=&quot;Image&quot; src=&quot;https://github.com/user-attachments/assets/e1ecb9c3-2dd3-431e-bd97-5a819c30e551&quot; /&gt;

## Usage

```toml
gpui = &quot;0.2.2&quot;
gpui-component = &quot;0.5.1&quot;
```

### Basic Example

```rs
use gpui::*;
use gpui_component::{button::*, *};

pub struct HelloWorld;
impl Render for HelloWorld {
    fn render(&amp;mut self, _: &amp;mut Window, _: &amp;mut Context&lt;Self&gt;) -&gt; impl IntoElement {
        div()
            .v_flex()
            .gap_2()
            .size_full()
            .items_center()
            .justify_center()
            .child(&quot;Hello, World!&quot;)
            .child(
                Button::new(&quot;ok&quot;)
                    .primary()
                    .label(&quot;Let&#039;s Go!&quot;)
                    .on_click(|_, _, _| println!(&quot;Clicked!&quot;)),
            )
    }
}

fn main() {
    let app = Application::new();

    app.run(move |cx| {
        // This must be called before using any GPUI Component features.
        gpui_component::init(cx);

        cx.spawn(async move |cx| {
            cx.open_window(WindowOptions::default(), |window, cx| {
                let view = cx.new(|_| HelloWorld);
                // This first level on the window, should be a Root.
                cx.new(|cx| Root::new(view, window, cx))
            })?;

            Ok::&lt;_, anyhow::Error&gt;(())
        })
        .detach();
    });
}
```

### Icons

GPUI Component has an `Icon` element, but it does not include SVG files by default.

The example uses [Lucide](https://lucide.dev) icons, but you can use any icons you like. Just name the SVG files as defined in [IconName](https://github.com/longbridge/gpui-component/blob/main/crates/ui/src/icon.rs#L86). You can add any icons you need to your project.

## Development

We have a gallery of applications built with GPUI Component.

```bash
cargo run
```

More examples can be found in the `examples` directory. You can run them with `cargo run --example &lt;example_name&gt;`.

Check out [CONTRIBUTING.md](CONTRIBUTING.md) for more details.

## Compare to others

| Features              | GPUI Component                 | [Iced]             | [egui]                | [Qt 6]                                            |
| --------------------- | ------------------------------ | ------------------ | --------------------- | ------------------------------------------------- |
| Language              | Rust                           | Rust               | Rust                  | C++/QML                                           |
| Core Render           | GPUI                           | wgpu               | wgpu                  | QT                                                |
| License               | Apache 2.0                     | MIT                | MIT/Apache 2.0        | [Commercial/LGPL](https://www.qt.io/qt-licensing) |
| Min Binary Size [^1]  | 12MB                           | 11MB               | 5M                    | 20MB [^2]                                         |
| Cross-Platform        | Yes                            | Yes                | Yes                   | Yes                                               |
| Documentation         | Simple                         | Simple             | Simple                | Good                                              |
| Web                   | No                             | Yes                | Yes                   | Yes                                               |
| UI Style              | Modern                         | Basic              | Basic                 | Basic                                             |
| CJK Support           | Yes                            | Yes                | Bad                   | Yes                                               |
| Chart                 | Yes                            | No                 | No                    | Yes                                               |
| Table (Large dataset) | Yes&lt;br&gt;(Virtual Rows, Columns) | No                 | Yes&lt;br&gt;(Virtual Rows) | Yes&lt;br&gt;(Virtual Rows, Columns)                    |
| Table Column Resize   | Yes                            | No                 | Yes                   | Yes                                               |
| Text base             | Rope                           | [COSMIC Text] [^3] | trait TextBuffer [^4] | [QTextDocument]                                   |
| CodeEditor            | Simple                         | Simple             | Simple                | Basic API                                         |
| Dock Layout           | Yes                            | Yes                | Yes                   | Yes                                               |
| Syntax Highlight      | [Tree Sitter]                  | [Syntect]          | [Syntect]             | [QSyntaxHighlighter]                              |
| Markdown Rendering    | Yes                            | Yes                | Basic                 | No                                                |
| Markdown mix HTML     | Yes                            | No                 | No                    | No                                                |
| HTML Rendering        | Basic                          | No                 | No                    | Basic                                             |
| Text Selection        | TextView                       | No                 | Any Label             | Yes                                               |
| Custom Theme          | Yes                            | Yes                | Yes                   | Yes                                               |
| Built Themes          | Yes                            | No                 | No                    | No                                                |
| I18n                  | Yes                            | Yes                | Yes                   | Yes                                               |

&gt; Please submit an issue or PR if any mistakes or outdated are found.

[Iced]: https://github.com/iced-rs/iced
[egui]: https://github.com/emilk/egui
[QT 6]: https://www.qt.io/product/qt6
[Tree Sitter]: https://tree-sitter.github.io/tree-sitter/
[Syntect]: https://github.com/trishume/syntect
[QSyntaxHighlighter]: https://doc.qt.io/qt-6/qsyntaxhighlighter.html
[QTextDocument]: https://doc.qt.io/qt-6/qtextdocument.html
[COSMIC Text]: https://github.com/pop-os/cosmic-text

[^1]: Release builds by use simple hello world example.

[^2]: [Reducing Binary Size of Qt Applications](https://www.qt.io/blog/reducing-binary-size-of-qt-applications-part-3-more-platforms)

[^3]: Iced Editor: &lt;https://github.com/iced-rs/iced/blob/db5a1f6353b9f8520c4f9633d1cdc90242c2afe1/graphics/src/text/editor.rs#L65-L68&gt;

[^4]: egui TextBuffer: &lt;https://github.com/emilk/egui/blob/0a81372cfd3a4deda640acdecbbaf24bf78bb6a2/crates/egui/src/widgets/text_edit/text_buffer.rs#L20&gt;

## License

Apache-2.0

- UI design based on [shadcn/ui](https://ui.shadcn.com).
- Icons from [Lucide](https://lucide.dev).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[mozilla/sccache]]></title>
            <link>https://github.com/mozilla/sccache</link>
            <guid>https://github.com/mozilla/sccache</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:39 GMT</pubDate>
            <description><![CDATA[Sccache is a ccache-like tool. It is used as a compiler wrapper and avoids compilation when possible. Sccache has the capability to utilize caching in remote storage environments, including various cloud storage options, or alternatively, in local storage.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mozilla/sccache">mozilla/sccache</a></h1>
            <p>Sccache is a ccache-like tool. It is used as a compiler wrapper and avoids compilation when possible. Sccache has the capability to utilize caching in remote storage environments, including various cloud storage options, or alternatively, in local storage.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,043</p>
            <p>Forks: 639</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>[![Build Status](https://github.com/mozilla/sccache/workflows/ci/badge.svg)](https://github.com/mozilla/sccache/actions?query=workflow%3Aci)
[![Crates.io](https://img.shields.io/crates/v/sccache.svg)](https://crates.io/crates/sccache)
[![Matrix](https://img.shields.io/matrix/sccache:mozilla.org)](https://chat.mozilla.org/#/room/#sccache:mozilla.org)
![Crates.io](https://img.shields.io/crates/l/sccache)
[![dependency status](https://deps.rs/repo/github/mozilla/sccache/status.svg)](https://deps.rs/repo/github/mozilla/sccache)

[![CodeCov](https://codecov.io/gh/mozilla/sccache/branch/main/graph/badge.svg)](https://codecov.io/gh/mozilla/sccache)


sccache - Shared Compilation Cache
==================================

sccache is a [ccache](https://ccache.dev/)-like compiler caching tool. It is used as a compiler wrapper and avoids compilation when possible, storing cached results either on [local disk](docs/Local.md) or in one of [several cloud storage backends](#storage-options).

sccache includes support for caching the compilation of Assembler, C/C++ code, [Rust](docs/Rust.md), as well as NVIDIA&#039;s CUDA using [nvcc](https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html), and [clang](https://llvm.org/docs/CompileCudaWithLLVM.html), [AMD&#039;s ROCm HIP](https://rocm.docs.amd.com/projects/HIP/en/latest/index.html).

sccache also provides [icecream](https://github.com/icecc/icecream)-style distributed compilation (automatic packaging of local toolchains) for all supported compilers (including Rust). The distributed compilation system includes several security features that icecream lacks such as authentication, transport layer encryption, and sandboxed compiler execution on build servers. See [the distributed quickstart](docs/DistributedQuickstart.md) guide for more information.

sccache is also available as a [GitHub Actions](https://github.com/marketplace/actions/sccache-action) to facilitate the deployment using GitHub Actions cache.

---

Table of Contents (ToC)
=======================

* [Installation](#installation)
* [Usage](#usage)
* [Build Requirements](#build-requirements)
* [Build](#build)
* [Separating caches between invocations](#separating-caches-between-invocations)
* [Overwriting the cache](#overwriting-the-cache)
* [Debugging](#debugging)
* [Interaction with GNU `make` jobserver](#interaction-with-gnu-make-jobserver)
* [Known Caveats](#known-caveats)
* [Storage Options](#storage-options)
  * [Local](docs/Local.md)
  * [S3](docs/S3.md)
  * [R2](docs/S3.md#R2)
  * [Redis](docs/Redis.md)
  * [Memcached](docs/Memcached.md)
  * [Google Cloud Storage](docs/Gcs.md)
  * [Azure](docs/Azure.md)
  * [GitHub Actions](docs/GHA.md)
  * [WebDAV (Ccache/Bazel/Gradle compatible)](docs/Webdav.md)
  * [Alibaba OSS](docs/OSS.md)
  * [Tencent Cloud Object Storage](docs/COS.md)

---

## Installation

There are prebuilt x86-64 binaries available for Windows, Linux (a portable binary compiled against musl), and macOS [on the releases page](https://github.com/mozilla/sccache/releases/latest). Several package managers also include sccache packages, you can install the latest release from source using cargo, or build directly from a source checkout.

### macOS

On macOS sccache can be installed via [Homebrew](https://brew.sh/):

```bash
brew install sccache
```

or via [MacPorts](https://www.macports.org/):

```bash
sudo port install sccache
```

### Windows

On Windows, sccache can be installed via [scoop](https://scoop.sh/):

```
scoop install sccache
```
or `winget`:

```
winget install Mozilla.sccache
```

### Via cargo

If you have a Rust toolchain installed you can install sccache using cargo. **Note that this will compile sccache from source which is fairly resource-intensive. For CI purposes you should use prebuilt binary packages.**


```bash
cargo install sccache --locked
```

### With Nix

Sccache is available in nixpkgs, so if you don&#039;t need the latest version you can use that:

```nix
buildInputs = [ pkgs.sccache ];
```

We also provide a flake with an overlay for getting the latest version:

```nix
{
  inputs = {
    nixpkgs.url = &quot;github:NixOS/nixpkgs/nixos-unstable&quot;;
    sccache = {
      url = &quot;github:mozilla/sccache&quot;;
      inputs.nixpkgs.follows = &quot;nixpkgs&quot;;
    };
  };

  outputs = { self, nixpkgs, sccache, ... }:
    let
      system = &quot;x86_64-linux&quot;;
      pkgs = import nixpkgs {
        inherit system;
        overlays = [ sccache.overlays.default ];
      };
    in {
      devShells.${system}.default = pkgs.mkShell {
        buildInputs = [ pkgs.sccache ];
      };
    };
}
```

Or use it directly from the flake without the overlay:

```bash
nix run github:mozilla/sccache -- --help
nix shell github:mozilla/sccache
```

---

Usage
-----

Running sccache is like running ccache: prefix your compilation commands with it, like so:

```bash
sccache gcc -o foo.o -c foo.c
```

If you want to use sccache for caching Rust builds you can define `build.rustc-wrapper` in the
[cargo configuration file](https://doc.rust-lang.org/cargo/reference/config.html).  For example, you can set it globally
in `$HOME/.cargo/config.toml` by adding:

```toml
[build]
rustc-wrapper = &quot;/path/to/sccache&quot;
```

Note that you need to use cargo 1.40 or newer for this to work.

Alternatively you can use the environment variable `RUSTC_WRAPPER`:

```bash
export RUSTC_WRAPPER=/path/to/sccache
cargo build
```

sccache supports gcc, clang, MSVC, rustc, [NVCC](https://docs.nvidia.com/cuda/cuda-compiler-driver-nvcc/index.html), [NVC++](https://docs.nvidia.com/hpc-sdk//compilers/hpc-compilers-user-guide/index.html), [hipcc](https://rocm.docs.amd.com/projects/HIP/en/latest/index.html), and [Wind River&#039;s diab compiler](https://www.windriver.com/products/development-tools/#diab_compiler). Both gcc and msvc support Response Files, read more about their implementation [here](docs/ResponseFiles.md).

If you don&#039;t [specify otherwise](#storage-options), sccache will use a local disk cache.

sccache works using a client-server model, where the server runs locally on the same machine as the client. The client-server model allows the server to be more efficient by keeping some state in memory. The sccache command will spawn a server process if one is not already running, or you can run `sccache --start-server` to start the background server process without performing any compilation.

By default sccache server will listen on `127.0.0.1:4226`, you can specify environment variable `SCCACHE_SERVER_PORT` to use a different port or `SCCACHE_SERVER_UDS` to listen on unix domain socket. Abstract unix socket is also supported as long as the path is escaped following the [format](https://doc.rust-lang.org/std/ascii/fn.escape_default.html). For example:

```
% env SCCACHE_SERVER_UDS=$HOME/sccache.sock sccache --start-server # unix socket
% env SCCACHE_SERVER_UDS=\\x00sccache.sock sccache --start-server # abstract unix socket
```

You can run `sccache --stop-server` to terminate the server. It will also terminate after (by default) 10 minutes of inactivity.

Running `sccache --show-stats` will print a summary of cache statistics.

Some notes about using `sccache` with [Jenkins](https://jenkins.io) are [here](docs/Jenkins.md).

To use sccache with cmake, provide the following command line arguments to cmake 3.4 or newer:

```
-DCMAKE_C_COMPILER_LAUNCHER=sccache
-DCMAKE_CXX_COMPILER_LAUNCHER=sccache
```

The process for using sccache with MSVC and cmake, depends on which version of cmake you&#039;re using. **For versions of cmake 3.24 and earlier**, to generate PDB files for debugging with MSVC, you can use the [`/Z7` option](https://docs.microsoft.com/en-us/cpp/build/reference/z7-zi-zi-debug-information-format?view=msvc-160). Alternatively, the `/Zi` option together with `/Fd` can work if `/Fd` names a different PDB file name for each object file created. Note that CMake sets `/Zi` by default, so if you use CMake, you can use `/Z7` by adding code like this in your CMakeLists.txt:

```cmake
if(CMAKE_BUILD_TYPE STREQUAL &quot;Debug&quot;)
  string(REPLACE &quot;/Zi&quot; &quot;/Z7&quot; CMAKE_CXX_FLAGS_DEBUG &quot;${CMAKE_CXX_FLAGS_DEBUG}&quot;)
  string(REPLACE &quot;/Zi&quot; &quot;/Z7&quot; CMAKE_C_FLAGS_DEBUG &quot;${CMAKE_C_FLAGS_DEBUG}&quot;)
elseif(CMAKE_BUILD_TYPE STREQUAL &quot;Release&quot;)
  string(REPLACE &quot;/Zi&quot; &quot;/Z7&quot; CMAKE_CXX_FLAGS_RELEASE &quot;${CMAKE_CXX_FLAGS_RELEASE}&quot;)
  string(REPLACE &quot;/Zi&quot; &quot;/Z7&quot; CMAKE_C_FLAGS_RELEASE &quot;${CMAKE_C_FLAGS_RELEASE}&quot;)
elseif(CMAKE_BUILD_TYPE STREQUAL &quot;RelWithDebInfo&quot;)
  string(REPLACE &quot;/Zi&quot; &quot;/Z7&quot; CMAKE_CXX_FLAGS_RELWITHDEBINFO &quot;${CMAKE_CXX_FLAGS_RELWITHDEBINFO}&quot;)
  string(REPLACE &quot;/Zi&quot; &quot;/Z7&quot; CMAKE_C_FLAGS_RELWITHDEBINFO &quot;${CMAKE_C_FLAGS_RELWITHDEBINFO}&quot;)
endif()
```

By default, sccache will fail your build if it fails to successfully communicate with its associated server. To have sccache instead gracefully failover to the local compiler without stopping, set the environment variable `SCCACHE_IGNORE_SERVER_IO_ERROR=1`.

**For versions of cmake 3.25 and later**, to compile with MSVC, you have to use the new `CMAKE_MSVC_DEBUG_INFORMATION_FORMAT` option, meant to configure the `-Z7` flag.  Additionally, you must set the cmake policy number 0141 to the NEW setting:
```cmake
set(CMAKE_MSVC_DEBUG_INFORMATION_FORMAT &quot;$&lt;$&lt;CONFIG:Debug,RelWithDebInfo&gt;:Embedded&gt;&quot;)
cmake_policy(SET CMP0141 NEW)
```

Example configuration where we automatically look for `sccache` in the `PATH`:
```cmake
find_program(SCCACHE sccache REQUIRED)

set(CMAKE_C_COMPILER_LAUNCHER ${SCCACHE})
set(CMAKE_CXX_COMPILER_LAUNCHER ${SCCACHE})
set(CMAKE_MSVC_DEBUG_INFORMATION_FORMAT &quot;$&lt;$&lt;CONFIG:Debug,RelWithDebInfo&gt;:Embedded&gt;&quot;)
cmake_policy(SET CMP0141 NEW)
```

Alternatively, if configuring cmake with MSVC on the command line, assuming that sccache is on the default search path:

```
cmake -DCMAKE_C_COMPILER_LAUNCHER=sccache -DCMAKE_CXX_COMPILER_LAUNCHER=sccache -DCMAKE_MSVC_DEBUG_INFORMATION_FORMAT=Embedded -DCMAKE_POLICY_CMP0141=NEW [...]
```

And you can build code as usual without any additional flags in the command line, which is useful for IDEs.


---

Build Requirements
------------------

sccache is a [Rust](https://www.rust-lang.org/) program. Building it requires `cargo` (and thus`rustc`). sccache currently requires **Rust 1.85.0**. We recommend you install Rust via [Rustup](https://rustup.rs/).

Build
-----

If you are building sccache for non-development purposes make sure you use `cargo build --release` to get optimized binaries:

```bash
cargo build --release [--no-default-features --features=s3|redis|gcs|memcached|azure|gha|webdav|oss|cos]
```

The list of features can be found in the `Cargo.toml` file, `[features]` section.

By default, `sccache` builds with support for all storage backends, but individual backends may be disabled by resetting the list of features and enabling all the other backends. Refer the [Cargo Documentation](http://doc.crates.io/manifest.html#the-features-section) for details on how to select features with Cargo.

### Building portable binaries

When building with the `dist-server` feature, `sccache` will depend on OpenSSL, which can be an annoyance if you want to distribute portable binaries. It is possible to statically link against OpenSSL using the `openssl/vendored` feature.

#### Linux

Build with `cargo` and use `ldd` to check that the resulting binary does not depend on OpenSSL anymore.

#### macOS

Build with `cargo` and use `otool -L` to check that the resulting binary does not depend on OpenSSL anymore.

#### Windows

On Windows, the binary might also depend on a few MSVC CRT DLLs that are not available on older Windows versions.

It is possible to statically link against the CRT using a `.cargo/config.toml` file with the following contents.

```toml
[target.x86_64-pc-windows-msvc]
rustflags = [&quot;-Ctarget-feature=+crt-static&quot;]
```

Build with `cargo` and use `dumpbin /dependents` to check that the resulting binary does not depend on MSVC CRT DLLs anymore.

When statically linking with OpenSSL, you will need Perl available in your `$PATH`.

---

Separating caches between invocations
-------------------------------------

In situations where several different compilation invocations
should not reuse the cached results from each other,
one can set `SCCACHE_C_CUSTOM_CACHE_BUSTER` to a unique value
that&#039;ll be mixed into the hash.
`MACOSX_DEPLOYMENT_TARGET` and `IPHONEOS_DEPLOYMENT_TARGET` variables
already exhibit such reuse-suppression behaviour.
There are currently no such variables for compiling Rust.

---

Overwriting the cache
---------------------

In situations where the cache contains broken build artifacts, it can be necessary to overwrite the contents in the cache. That can be achieved by setting the `SCCACHE_RECACHE` environment variable.

---

Debugging
---------

You can set the `SCCACHE_ERROR_LOG` environment variable to a path and set `SCCACHE_LOG` to get the server process to redirect its logging there (including the output of unhandled panics, since the server sets `RUST_BACKTRACE=1` internally).

    SCCACHE_ERROR_LOG=/tmp/sccache_log.txt SCCACHE_LOG=debug sccache

You can also set these environment variables for your build system, for example

    SCCACHE_ERROR_LOG=/tmp/sccache_log.txt SCCACHE_LOG=debug cmake --build /path/to/cmake/build/directory

Alternatively, if you are compiling locally, you can run the server manually in foreground mode by running `SCCACHE_START_SERVER=1 SCCACHE_NO_DAEMON=1 sccache`, and send logging to stderr by setting the [`SCCACHE_LOG` environment variable](https://docs.rs/env_logger/0.7.1/env_logger/#enabling-logging) for example. This method is not suitable for CI services because you need to compile in another shell at the same time.

    SCCACHE_LOG=debug SCCACHE_START_SERVER=1 SCCACHE_NO_DAEMON=1 sccache

---

Interaction with GNU `make` jobserver
-------------------------------------

sccache provides support for a [GNU make jobserver](https://www.gnu.org/software/make/manual/html_node/Job-Slots.html). When the server is started from a process that provides a jobserver, sccache will use that jobserver and provide it to any processes it spawns. (If you are running sccache from a GNU make recipe, you will need to prefix the command with `+` to get this behavior.) If the sccache server is started without a jobserver present it will create its own with the number of slots equal to the number of available CPU cores.

This is most useful when using sccache for Rust compilation, as rustc supports using a jobserver for parallel codegen, so this ensures that rustc will not overwhelm the system with codegen tasks. Cargo implements its own jobserver ([see the information on `NUM_JOBS` in the cargo documentation](https://doc.rust-lang.org/stable/cargo/reference/environment-variables.html#environment-variables-cargo-sets-for-build-scripts)) for rustc to use, so using sccache for Rust compilation in cargo via `RUSTC_WRAPPER` should do the right thing automatically.

---

Normalizing Paths with `SCCACHE_BASEDIRS`
-----------------------------------------

By default, sccache requires absolute paths to match for cache hits. To enable cache sharing across different build directories, you can set `SCCACHE_BASEDIRS` to strip a base directory from paths before hashing:

```bash
export SCCACHE_BASEDIRS=/home/user/project
```

You can also specify multiple base directories by separating them by `;` on Windows hosts and by `:` on any other operating system. When multiple directories are provided, the longest matching prefix is used:

```bash
export SCCACHE_BASEDIRS=&quot;/home/user/project:/home/user/workspace&quot;
```

Path matching is **case-insensitive** on Windows and **case-sensitive** on other operating systems.

This is similar to ccache&#039;s `CCACHE_BASEDIR` and helps when:
* Building the same project from different directories
* Sharing cache between CI jobs with different checkout paths
* Multiple developers working with different username paths
* Working with multiple project checkouts simultaneously

**Note:** Only absolute paths are supported. Relative paths will prevent server from starting.

You can also configure this in the sccache config file:

```toml
# Single directory
basedirs = [&quot;/home/user/project&quot;]

# Or multiple directories
basedirs = [&quot;/home/user/project&quot;, &quot;/home/user/workspace&quot;]
```

---

Known Caveats
-------------

### General

* By default, absolute paths to files must match to get a cache hit. To work around this, use `SCCACHE_BASEDIRS` (see above) to normalize paths before hashing.

### Rust

* Crates that invoke the system linker cannot be cached. This includes `bin`, `dylib`, `cdylib`, and `proc-macro` crates. You may be able to improve compilation time of large `bin` crates by converting them to a `lib` crate with a thin `bin` wrapper.
* Incrementally compiled crates cannot be cached. By default, in the debug profile Cargo will use incremental compilation for workspace members and path dependencies. [You can disable incremental compilation.](https://doc.rust-lang.org/cargo/reference/profiles.html#incremental)

[More details on Rust caveats](/docs/Rust.md)

### C++20 Modules

sccache has partial support for C++20 named modules when using **Clang**. The following flags are supported:

* `-fmodule-file=&lt;path&gt;` and `-fmodule-file=&lt;name&gt;=&lt;path&gt;` - importing precompiled module interfaces
* `-fmodule-output=&lt;path&gt;` - generating module interface output alongside object files
* `--precompile` - compiling module interface units
* `-fmodules-reduced-bmi` - generating reduced BMI files

The following module-related flags are **not supported** and will bypass the cache:

* `-fmodules` and `-fcxx-modules` - Clang header modules (not C++20 named modules)
* `-fprebuilt-implicit-modules` and `-fprebuilt-module-path` - implicit module discovery

**GCC** and **MSVC** C++20 modules are not yet supported. Compilations using `-fmodules-ts` (GCC) or `/interface`, `/ifcOutput`, etc. (MSVC) will bypass the cache.

### User Agent

* Requests sent to your storage option of choice will have a user agent header indicating the current sccache version, e.g. `sccache/0.8.2`.

Storage Options
---------------

* [Local](docs/Local.md)
* [S3](docs/S3.md)
* [R2](docs/S3.md#R2)
* [Redis](docs/Redis.md)
* [Memcached](docs/Memcached.md)
* [Google Cloud Storage](docs/Gcs.md)
* [Azure](docs/Azure.md)
* [GitHub Actions](docs/GHA.md)
* [WebDAV (Ccache/Bazel/Gradle compatible)](docs/Webdav.md)
* [Alibaba OSS](docs/OSS.md)
* [Tencent Cloud Object Storage](docs/COS.md)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zed-industries/zed]]></title>
            <link>https://github.com/zed-industries/zed</link>
            <guid>https://github.com/zed-industries/zed</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:38 GMT</pubDate>
            <description><![CDATA[Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zed-industries/zed">zed-industries/zed</a></h1>
            <p>Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.</p>
            <p>Language: Rust</p>
            <p>Stars: 76,143</p>
            <p>Forks: 7,120</p>
            <p>Stars today: 59 stars today</p>
            <h2>README</h2><pre># Zed

[![Zed](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/zed-industries/zed/main/assets/badge/v0.json)](https://zed.dev)
[![CI](https://github.com/zed-industries/zed/actions/workflows/run_tests.yml/badge.svg)](https://github.com/zed-industries/zed/actions/workflows/run_tests.yml)

Welcome to Zed, a high-performance, multiplayer code editor from the creators of [Atom](https://github.com/atom/atom) and [Tree-sitter](https://github.com/tree-sitter/tree-sitter).

---

### Installation

On macOS, Linux, and Windows you can [download Zed directly](https://zed.dev/download) or install Zed via your local package manager ([macOS](https://zed.dev/docs/installation#macos)/[Linux](https://zed.dev/docs/linux#installing-via-a-package-manager)/[Windows](https://zed.dev/docs/windows#package-managers)).

Other platforms are not yet available:

- Web ([tracking issue](https://github.com/zed-industries/zed/issues/5396))

### Developing Zed

- [Building Zed for macOS](./docs/src/development/macos.md)
- [Building Zed for Linux](./docs/src/development/linux.md)
- [Building Zed for Windows](./docs/src/development/windows.md)

### Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for ways you can contribute to Zed.

Also... we&#039;re hiring! Check out our [jobs](https://zed.dev/jobs) page for open roles.

### Licensing

License information for third party dependencies must be correctly provided for CI to pass.

We use [`cargo-about`](https://github.com/EmbarkStudios/cargo-about) to automatically comply with open source licenses. If CI is failing, check the following:

- Is it showing a `no license specified` error for a crate you&#039;ve created? If so, add `publish = false` under `[package]` in your crate&#039;s Cargo.toml.
- Is the error `failed to satisfy license requirements` for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license&#039;s requirements. If you&#039;re unsure, ask a lawyer. Once you&#039;ve verified that this system is acceptable add the license&#039;s SPDX identifier to the `accepted` array in `script/licenses/zed-licenses.toml`.
- Is `cargo-about` unable to find the license for a dependency? If so, add a clarification field at the end of `script/licenses/zed-licenses.toml`, as specified in the [cargo-about book](https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration).

## Sponsorship

Zed is developed by **Zed Industries, Inc.**, a for-profit company.

If you‚Äôd like to financially support the project, you can do so via GitHub Sponsors.
Sponsorships go directly to Zed Industries and are used as general company revenue.
There are no perks or entitlements associated with sponsorship.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gitbutlerapp/gitbutler]]></title>
            <link>https://github.com/gitbutlerapp/gitbutler</link>
            <guid>https://github.com/gitbutlerapp/gitbutler</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:37 GMT</pubDate>
            <description><![CDATA[The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitbutlerapp/gitbutler">gitbutlerapp/gitbutler</a></h1>
            <p>The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte</p>
            <p>Language: Rust</p>
            <p>Stars: 19,642</p>
            <p>Forks: 853</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  
  &lt;img align=&quot;center&quot; width=&quot;100px&quot; src=&quot;https://gitbutler-docs-images-public.s3.us-east-1.amazonaws.com/md-logo.png&quot; alt=&quot;GitButler logo&quot; /&gt;
  &lt;br /&gt;

  &lt;h1 align=&quot;center&quot;&gt;GitButler&lt;/h1&gt;
  
  &lt;p align=&quot;center&quot;&gt;
   &lt;b&gt;Git, &lt;i&gt;but&lt;/i&gt; better&lt;/b&gt;.
   &lt;br/&gt;
   GitButler is a modern Git-based version control interface with both a GUI and CLI built from the ground up for AI-powered workflows.
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://gitbutler.com&quot;&gt;Website&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://blog.gitbutler.com/&quot;&gt;Blog&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://docs.gitbutler.com/&quot;&gt;Docs&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://gitbutler.com/downloads&quot;&gt;Downloads&lt;/a&gt;
  &lt;/p&gt;

  &lt;br/&gt;

  &lt;img width=&quot;100%&quot; src=&quot;https://gitbutler-docs-images-public.s3.us-east-1.amazonaws.com/app-preview-light.png&quot; alt=&quot;GitButler desktop app preview&quot; /&gt;
  &lt;p align=&quot;center&quot;&gt;&lt;i&gt;Our beautiful GUI&lt;/i&gt;&lt;/p&gt;

  &lt;img width=&quot;100%&quot; src=&quot;https://gitbutler-docs-images-public.s3.us-east-1.amazonaws.com/cli-preview.png&quot; alt=&quot;GitButler CLI preview&quot; /&gt;
  &lt;p align=&quot;center&quot;&gt;&lt;i&gt;Our amazing &lt;code&gt;but&lt;/code&gt; CLI&lt;/i&gt;&lt;/p&gt;

  &lt;br/&gt;

[![TWEET][s1]][l1] [
![BLUESKY][s8]][l8] [![DISCORD][s2]][l2]

[![CI][s0]][l0] [![INSTA][s3]][l3] [![YOUTUBE][s5]][l5] [![DEEPWIKI][s7]][l7]

[s0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml/badge.svg
[l0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml
[s1]: https://img.shields.io/badge/Twitter-black?logo=x&amp;logoColor=white
[l1]: https://twitter.com/intent/follow?screen_name=gitbutler
[s2]: https://img.shields.io/discord/1060193121130000425?label=Discord&amp;color=5865F2
[l2]: https://discord.gg/MmFkmaJ42D
[s3]: https://img.shields.io/badge/Instagram-E4405F?logo=instagram&amp;logoColor=white
[l3]: https://www.instagram.com/gitbutler/
[s5]: https://img.shields.io/youtube/channel/subscribers/UCEwkZIHGqsTGYvX8wgD0LoQ
[l5]: https://www.youtube.com/@gitbutlerapp
[s7]: https://deepwiki.com/badge.svg
[l7]: https://deepwiki.com/gitbutlerapp/gitbutler
[s8]: https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&amp;logoColor=fff
[l8]: https://bsky.app/profile/gitbutler.com

&lt;/div&gt;

&lt;br/&gt;

GitButler is a powerful new Git-based version control system, designed from scratch to be simple, powerful and flexible. It is designed for ease of use and modern agentic workflows.

It features stacked branches, parallel branches, unlimited undo, easy commit mutations, forge integrations and more.

Works instantly in any existing Git repo as a friendlier and more powerful drop-in Git user interface replacement - for you and your agents.

## Main Features

Why use GitButler instead of vanilla Git? What a great question.

- **Stacked Branches** ([gui](https://docs.gitbutler.com/features/branch-management/stacked-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/branching-and-commiting#stacked-branches))
  - Effortlessly create branches stacked on other branches. Amend or edit any commit easily with automatic restacking.
- **Parallel Branches** ([gui](https://docs.gitbutler.com/features/branch-management/virtual-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/branching-and-commiting#parallel-branches))
  - Organize work on multiple branches simultaneously, rather than constantly switching branches.
- **Easy Commit Management** ([gui](https://docs.gitbutler.com/features/branch-management/commits), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/rubbing))
  - Uncommit, reword, amend, move, split and squash commits by dragging and dropping or simple CLI commands. Forget about `rebase -i`, you don&#039;t need it anymore.
- **Undo Timeline** ([gui](https://docs.gitbutler.com/features/timeline), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/operations-log))
  - Logs all operations and changes and allows you to easily undo or revert any operation.
- **First Class Conflicts** ([gui](https://docs.gitbutler.com/overview#conflicting-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/conflict-resolution))
  - Rebases always succeed. Commits can be marked as conflicted and resolved at any time, in any order.
- **Forge Integration** ([gui](https://docs.gitbutler.com/features/forge-integration/github-integration), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/forges))
  - Authenticate to GitHub or GitLab to easily open and update Pull Requests, list branches, get CI statuses and more. No other tools required.
- **AI Tooling** ([gui](https://docs.gitbutler.com/features/ai-integration/ai-overview), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/ai-stuff))
  - Use built-in AI handlers to help create commit messages, branch names, PR descriptions and more.
  - Easily install hooks or skills for all modern agent systems to level up their Git management.

## Tech

The GitButler desktop app is a [Tauri](https://tauri.app/)-based application. Its UI is written in [Svelte](https://svelte.dev/) using [TypeScript](https://www.typescriptlang.org) and its backend is written in [Rust](https://www.rust-lang.org/).

The `but` CLI is the same Rust backend engine with a Rust command line UI.

## Documentation

You can find our end user documentation at: &lt;https://docs.gitbutler.com&gt;

## Bugs and Feature Requests

If you have a bug or feature request, feel free to open an [issue](https://github.com/gitbutlerapp/gitbutler/issues/new),
or [join our Discord server](https://discord.gg/MmFkmaJ42D).

## License

The TLDR is that GitButler is under a [Fair Source](https://fair.io/) software license, meaning that you can use it, view the source, contribute, etc. You just can&#039;t build a competitor with it. It also becomes MIT after 2 years. So, MIT with an expiring non-compete clause.

## Contributing

So you want to help out? Please check out the [CONTRIBUTING.md](CONTRIBUTING.md)
document.

If you want to skip right to getting the code to actually compile, take a look
at the [DEVELOPMENT.md](DEVELOPMENT.md) file.

### Contributors

&lt;a href=&quot;https://github.com/gitbutlerapp/gitbutler/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=gitbutlerapp/gitbutler&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[EasyTier/EasyTier]]></title>
            <link>https://github.com/EasyTier/EasyTier</link>
            <guid>https://github.com/EasyTier/EasyTier</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:36 GMT</pubDate>
            <description><![CDATA[A simple, decentralized mesh VPN with WireGuard support.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EasyTier/EasyTier">EasyTier/EasyTier</a></h1>
            <p>A simple, decentralized mesh VPN with WireGuard support.</p>
            <p>Language: Rust</p>
            <p>Stars: 10,208</p>
            <p>Forks: 969</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># EasyTier

[![Github release](https://img.shields.io/github/v/tag/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/releases)
[![GitHub](https://img.shields.io/github/license/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/blob/main/LICENSE)
[![GitHub last commit](https://img.shields.io/github/last-commit/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/commits/main)
[![GitHub issues](https://img.shields.io/github/issues/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/issues)
[![GitHub Core Actions](https://github.com/EasyTier/EasyTier/actions/workflows/core.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/core.yml)
[![GitHub GUI Actions](https://github.com/EasyTier/EasyTier/actions/workflows/gui.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/gui.yml)
[![GitHub Test Actions](https://github.com/EasyTier/EasyTier/actions/workflows/test.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/test.yml)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/EasyTier/EasyTier)

[ÁÆÄ‰Ωì‰∏≠Êñá](/README_CN.md) | [English](/README.md)

&gt; ‚ú® A simple, secure, decentralized virtual private network solution powered by Rust and Tokio

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;assets/config-page.png&quot; width=&quot;300&quot; alt=&quot;config page&quot;&gt;
&lt;img src=&quot;assets/running-page.png&quot; width=&quot;300&quot; alt=&quot;running page&quot;&gt;
&lt;/p&gt;

üìö **[Full Documentation](https://easytier.cn/en/)** | üñ•Ô∏è **[Web Console](https://easytier.cn/web)** | üìù **[Download Releases](https://github.com/EasyTier/EasyTier/releases)** | üß© **[Third Party Tools](https://easytier.cn/en/guide/installation_gui.html#third-party-graphical-interfaces)** | ‚ù§Ô∏è **[Sponsor](#sponsor)**

## Features

### Core Features

- üîí **Decentralized**: Nodes are equal and independent, no centralized services required  
- üöÄ **Easy to Use**: Multiple operation methods via web, client, and command line  
- üåç **Cross-Platform**: Supports Win/MacOS/Linux/FreeBSD/Android and X86/ARM/MIPS architectures  
- üîê **Secure**: AES-GCM or WireGuard encryption, prevents man-in-the-middle attacks  

### Advanced Capabilities

- üîå **Efficient NAT Traversal**: Supports UDP and IPv6 traversal, works with NAT4-NAT4 networks  
- üåê **Subnet Proxy**: Nodes can share subnets for other nodes to access  
- üîÑ **Intelligent Routing**: Latency priority and automatic route selection for best network experience  
- ‚ö° **High Performance**: Zero-copy throughout the entire link, supports TCP/UDP/WSS/WG protocols  

### Network Optimization

- üìä **UDP Loss Resistance**: KCP/QUIC proxy optimizes latency and bandwidth in high packet loss environments  
- üîß **Web Management**: Easy configuration and monitoring through web interface  
- üõ†Ô∏è **Zero Config**: Simple deployment with statically linked executables  

## Quick Start

### üì• Installation

Choose the installation method that best suits your needs:

```bash
# 1. Download pre-built binary (Recommended, All platforms supported)
# Visit https://github.com/EasyTier/EasyTier/releases

# 2. Install via cargo (Latest development version)
cargo install --git https://github.com/EasyTier/EasyTier.git easytier

# 3. Install via Docker
# See https://easytier.cn/en/guide/installation.html#installation-methods

# 4. Linux Quick Install
wget -O- https://raw.githubusercontent.com/EasyTier/EasyTier/main/script/install.sh | sudo bash -s install

# 5. MacOS via Homebrew
brew tap brewforge/chinese
brew install --cask easytier-gui

# 6. OpenWrt Luci Web UI
# Visit https://github.com/EasyTier/luci-app-easytier

# 7. (Optional) Install shell completions:
easytier-core --gen-autocomplete fish &gt; ~/.config/fish/completions/easytier-core.fish
easytier-cli gen-autocomplete fish &gt; ~/.config/fish/completions/easytier-cli.fish

```

### üöÄ Basic Usage

#### Quick Networking with Shared Nodes

EasyTier supports quick networking using shared public nodes. When you don&#039;t have a public IP, you can use the free shared nodes provided by the EasyTier community. Nodes will automatically attempt NAT traversal and establish P2P connections. When P2P fails, data will be relayed through shared nodes.

When using shared nodes, each node entering the network needs to provide the same `--network-name` and `--network-secret` parameters as the unique identifier of the network.

Taking two nodes as an example (Please use more complex network name to avoid conflicts):

1. Run on Node A:

```bash
# Run with administrator privileges
sudo easytier-core -d --network-name abc --network-secret abc -p tcp://&lt;SharedNodeIP&gt;:11010
```

2. Run on Node B:

```bash
# Run with administrator privileges
sudo easytier-core -d --network-name abc --network-secret abc -p tcp://&lt;SharedNodeIP&gt;:11010
```

After successful execution, you can check the network status using `easytier-cli`:

```text
| ipv4         | hostname       | cost  | lat_ms | loss_rate | rx_bytes | tx_bytes | tunnel_proto | nat_type | id         | version         |
| ------------ | -------------- | ----- | ------ | --------- | -------- | -------- | ------------ | -------- | ---------- | --------------- |
| 10.126.126.1 | abc-1          | Local | *      | *         | *        | *        | udp          | FullCone | 439804259  | 2.5.0-70e69a38~ |
| 10.126.126.2 | abc-2          | p2p   | 3.452  | 0         | 17.33 kB | 20.42 kB | udp          | FullCone | 390879727  | 2.5.0-70e69a38~ |
|              | PublicServer_a | p2p   | 27.796 | 0.000     | 50.01 kB | 67.46 kB | tcp          | Unknown  | 3771642457 | 2.5.0-70e69a38~ |
```

You can test connectivity between nodes:

```bash
# Test connectivity
ping 10.126.126.1
ping 10.126.126.2
```

Note: If you cannot ping through, it may be that the firewall is blocking incoming traffic. Please turn off the firewall or add allow rules.

To improve availability, you can connect to multiple shared nodes simultaneously:

```bash
# Connect to multiple shared nodes
sudo easytier-core -d --network-name abc --network-secret abc -p tcp://&lt;SharedNodeIP1&gt;:11010 -p udp://&lt;SharedNodeIP2&gt;:11010
```

Once your network is set up successfully, you can easily configure it to start automatically on system boot. Refer to the [One-Click Register Service guide](https://easytier.cn/en/guide/network/oneclick-install-as-service.html) for step-by-step instructions on registering EasyTier as a system service.

#### Decentralized Networking

EasyTier is fundamentally decentralized, with no distinction between server and client. As long as one device can communicate with any node in the virtual network, it can join the virtual network. Here&#039;s how to set up a decentralized network:

1. Start First Node (Node A):

```bash
# Start the first node
sudo easytier-core -i 10.144.144.1
```

After startup, this node will listen on the following ports by default:
- TCP: 11010
- UDP: 11010
- WebSocket: 11011
- WebSocket SSL: 11012
- WireGuard: 11013

2. Connect Second Node (Node B):

```bash
# Connect to the first node using its public IP
sudo easytier-core -i 10.144.144.2 -p udp://FIRST_NODE_PUBLIC_IP:11010
```

3. Verify Connection:

```bash
# Test connectivity
ping 10.144.144.2

# View connected peers
easytier-cli peer

# View routing information
easytier-cli route

# View local node information
easytier-cli node
```

For more nodes to join the network, they can connect to any existing node in the network using the `-p` parameter:

```bash
# Connect to any existing node using its public IP
sudo easytier-core -i 10.144.144.3 -p udp://ANY_EXISTING_NODE_PUBLIC_IP:11010
```

### üîç Advanced Features

#### Subnet Proxy

Assuming the network topology is as follows, Node B wants to share its accessible subnet 10.1.1.0/24 with other nodes:

```mermaid
flowchart LR

subgraph Node A Public IP 22.1.1.1
nodea[EasyTier&lt;br/&gt;10.144.144.1]
end

subgraph Node B
nodeb[EasyTier&lt;br/&gt;10.144.144.2]
end

id1[[10.1.1.0/24]]

nodea &lt;--&gt; nodeb &lt;-.-&gt; id1
```

To share a subnet, add the `-n` parameter when starting EasyTier:

```bash
# Share subnet 10.1.1.0/24 with other nodes
sudo easytier-core -i 10.144.144.2 -n 10.1.1.0/24
```

Subnet proxy information will automatically sync to each node in the virtual network, and each node will automatically configure the corresponding route. You can verify the subnet proxy setup:

1. Check if the routing information has been synchronized (the proxy_cidrs column shows the proxied subnets):

```bash
# View routing information
easytier-cli route
```

![Routing Information](/assets/image-3.png)

2. Test if you can access nodes in the proxied subnet:

```bash
# Test connectivity to proxied subnet
ping 10.1.1.2
```

#### WireGuard Integration

EasyTier can act as a WireGuard server, allowing any device with a WireGuard client (including iOS and Android) to access the EasyTier network. Here&#039;s an example setup:

```mermaid
flowchart LR

ios[[iPhone&lt;br/&gt;WireGuard Installed]]

subgraph Node A Public IP 22.1.1.1
nodea[EasyTier&lt;br/&gt;10.144.144.1]
end

subgraph Node B
nodeb[EasyTier&lt;br/&gt;10.144.144.2]
end

id1[[10.1.1.0/24]]

ios &lt;-.-&gt; nodea &lt;--&gt; nodeb &lt;-.-&gt; id1
```

1. Start EasyTier with WireGuard portal enabled:

```bash
# Listen on 0.0.0.0:11013 and use 10.14.14.0/24 subnet for WireGuard clients
sudo easytier-core -i 10.144.144.1 --vpn-portal wg://0.0.0.0:11013/10.14.14.0/24
```

2. Get WireGuard client configuration:

```bash
# Get WireGuard client configuration
easytier-cli vpn-portal
```

3. In the output configuration:
   - Set `Interface.Address` to an available IP from the WireGuard subnet
   - Set `Peer.Endpoint` to the public IP/domain of your EasyTier node
   - Import the modified configuration into your WireGuard client

#### Self-Hosted Public Shared Node

You can run your own public shared node to help other nodes discover each other. A public shared node is just a regular EasyTier network (with same network name and secret) that other networks can connect to.

To run a public shared node:

```bash
# No need to specify IPv4 address for public shared nodes
sudo easytier-core --network-name mysharednode --network-secret mysharednode
```

## Related Projects

- [ZeroTier](https://www.zerotier.com/): A global virtual network for connecting devices.
- [TailScale](https://tailscale.com/): A VPN solution aimed at simplifying network configuration.

### Contact Us

- üí¨ **[Telegram Group](https://t.me/easytier)**
- üë• **[QQ Group]**
  - No.1 [949700262](https://qm.qq.com/q/wFoTUChqZW)
  - No.2 [837676408](https://qm.qq.com/q/4V33DrfgHe)
  - No.3 [957189589](https://qm.qq.com/q/YNyTQjwlai)

## License

EasyTier is released under the [LGPL-3.0](https://github.com/EasyTier/EasyTier/blob/main/LICENSE).

## Sponsor

CDN acceleration and security protection for this project are sponsored by Tencent EdgeOne.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://edgeone.ai/?from=github&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/edgeone.png&quot; width=&quot;200&quot; alt=&quot;EdgeOne Logo&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

Special thanks to [Langlang Cloud](https://langlangy.cn/?i26c5a5)  and [RainCloud](https://www.rainyun.com/NjM0NzQ1_) for sponsoring our public servers.

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://langlangy.cn/?i26c5a5&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;assets/langlang.png&quot; width=&quot;200&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://langlangy.cn/?i26c5a5&quot; target=&quot;_blank&quot;&gt;
&lt;img src=&quot;assets/raincloud.png&quot; width=&quot;200&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;


If you find EasyTier helpful, please consider sponsoring us. Software development and maintenance require a lot of time and effort, and your sponsorship will help us better maintain and improve EasyTier.

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;assets/wechat.png&quot; width=&quot;200&quot;&gt;
&lt;img src=&quot;assets/alipay.png&quot; width=&quot;200&quot;&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lance-format/lance]]></title>
            <link>https://github.com/lance-format/lance</link>
            <guid>https://github.com/lance-format/lance</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:35 GMT</pubDate>
            <description><![CDATA[Open Lakehouse Format for Multimodal AI. Convert from Parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lance-format/lance">lance-format/lance</a></h1>
            <p>Open Lakehouse Format for Multimodal AI. Convert from Parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..</p>
            <p>Language: Rust</p>
            <p>Stars: 6,117</p>
            <p>Forks: 565</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;

&lt;img width=&quot;257&quot; alt=&quot;Lance Logo&quot; src=&quot;https://user-images.githubusercontent.com/917119/199353423-d3e202f7-0269-411d-8ff2-e747e419e492.png&quot;&gt;

**The Open Lakehouse Format for Multimodal AI**&lt;br/&gt;
**High-performance vector search, full-text search, random access, and feature engineering capabilities for the lakehouse.**&lt;br/&gt;
**Compatible with Pandas, DuckDB, Polars, PyArrow, Ray, Spark, and more integrations on the way.**

&lt;a href=&quot;https://lance.org&quot;&gt;Documentation&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://lance.org/community&quot;&gt;Community&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://discord.gg/lance&quot;&gt;Discord&lt;/a&gt;

[CI]: https://github.com/lance-format/lance/actions/workflows/rust.yml
[CI Badge]: https://github.com/lance-format/lance/actions/workflows/rust.yml/badge.svg
[Docs]: https://lance.org
[Docs Badge]: https://img.shields.io/badge/docs-passing-brightgreen
[crates.io]: https://crates.io/crates/lance
[crates.io badge]: https://img.shields.io/crates/v/lance.svg
[Python versions]: https://pypi.org/project/pylance/
[Python versions badge]: https://img.shields.io/pypi/pyversions/pylance

[![CI Badge]][CI]
[![Docs Badge]][Docs]
[![crates.io badge]][crates.io]
[![Python versions badge]][Python versions]

&lt;/p&gt;
&lt;/div&gt;

&lt;hr /&gt;

Lance is an open lakehouse format for multimodal AI. It contains a file format, table format, and catalog spec that allows you to build a complete lakehouse on top of object storage to power your AI workflows. Lance is perfect for:

1. Building search engines and feature stores with hybrid search capabilities.
2. Large-scale ML training requiring high performance IO and random access.
3. Storing, querying, and managing multimodal data including images, videos, audio, text, and embeddings.

The key features of Lance include:

* **Expressive hybrid search:** Combine vector similarity search, full-text search (BM25), and SQL analytics on the same dataset with accelerated secondary indices.

* **Lightning-fast random access:** 100x faster than Parquet or Iceberg for random access without sacrificing scan performance.

* **Native multimodal data support:** Store images, videos, audio, text, and embeddings in a single unified format with efficient blob encoding and lazy loading.

* **Data evolution:** Efficiently add columns with backfilled values without full table rewrites, perfect for ML feature engineering.

* **Zero-copy versioning:** Automatic versioning with ACID transactions, time travel, tags, and branches‚Äîno extra infrastructure needed.

* **Rich ecosystem integrations:** Apache Arrow, Pandas, Polars, DuckDB, Apache Spark, Ray, Trino, Apache Flink, and open catalogs (Apache Polaris, Unity Catalog, Apache Gravitino).

For more details, see the full [Lance format specification](https://lance.org/format).

&gt; [!TIP]
&gt; Lance is in active development and we welcome contributions. Please see our [contributing guide](https://lance.org/community/contributing/) for more information.

## Quick Start

**Installation**

```shell
pip install pylance
```

To install a preview release:

```shell
pip install --pre --extra-index-url https://pypi.fury.io/lance-format/pylance
```

&gt; [!NOTE]
&gt; For versions prior to 1.0.0-beta.4, you can find them at https://pypi.fury.io/lancedb/pylance

&gt; [!TIP]
&gt; Preview releases are released more often than full releases and contain the
&gt; latest features and bug fixes. They receive the same level of testing as full releases.
&gt; We guarantee they will remain published and available for download for at
&gt; least 6 months. When you want to pin to a specific version, prefer a stable release.

**Converting to Lance**

```python
import lance

import pandas as pd
import pyarrow as pa
import pyarrow.dataset

df = pd.DataFrame({&quot;a&quot;: [5], &quot;b&quot;: [10]})
uri = &quot;/tmp/test.parquet&quot;
tbl = pa.Table.from_pandas(df)
pa.dataset.write_dataset(tbl, uri, format=&#039;parquet&#039;)

parquet = pa.dataset.dataset(uri, format=&#039;parquet&#039;)
lance.write_dataset(parquet, &quot;/tmp/test.lance&quot;)
```

**Reading Lance data**
```python
dataset = lance.dataset(&quot;/tmp/test.lance&quot;)
assert isinstance(dataset, pa.dataset.Dataset)
```

**Pandas**
```python
df = dataset.to_table().to_pandas()
df
```

**DuckDB**
```python
import duckdb

# If this segfaults, make sure you have duckdb v0.7+ installed
duckdb.query(&quot;SELECT * FROM dataset LIMIT 10&quot;).to_df()
```

**Vector search**

Download the sift1m subset

```shell
wget ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz
tar -xzf sift.tar.gz
```

Convert it to Lance

```python
import lance
from lance.vector import vec_to_table
import numpy as np
import struct

nvecs = 1000000
ndims = 128
with open(&quot;sift/sift_base.fvecs&quot;, mode=&quot;rb&quot;) as fobj:
    buf = fobj.read()
    data = np.array(struct.unpack(&quot;&lt;128000000f&quot;, buf[4 : 4 + 4 * nvecs * ndims])).reshape((nvecs, ndims))
    dd = dict(zip(range(nvecs), data))

table = vec_to_table(dd)
uri = &quot;vec_data.lance&quot;
sift1m = lance.write_dataset(table, uri, max_rows_per_group=8192, max_rows_per_file=1024*1024)
```

Build the index

```python
sift1m.create_index(&quot;vector&quot;,
                    index_type=&quot;IVF_PQ&quot;,
                    num_partitions=256,  # IVF
                    num_sub_vectors=16)  # PQ
```

Search the dataset

```python
# Get top 10 similar vectors
import duckdb

dataset = lance.dataset(uri)

# Sample 100 query vectors. If this segfaults, make sure you have duckdb v0.7+ installed
sample = duckdb.query(&quot;SELECT vector FROM dataset USING SAMPLE 100&quot;).to_df()
query_vectors = np.array([np.array(x) for x in sample.vector])

# Get nearest neighbors for all of them
rs = [dataset.to_table(nearest={&quot;column&quot;: &quot;vector&quot;, &quot;k&quot;: 10, &quot;q&quot;: q})
      for q in query_vectors]
```

## Directory structure

| Directory          | Description              |
|--------------------|--------------------------|
| [rust](./rust)     | Core Rust implementation |
| [python](./python) | Python bindings (PyO3)   |
| [java](./java)     | Java bindings (JNI)      |
| [docs](./docs)     | Documentation source     |

## Benchmarks

### Vector search

We used the SIFT dataset to benchmark our results with 1M vectors of 128D

1. For 100 randomly sampled query vectors, we get &lt;1ms average response time (on a 2023 m2 MacBook Air)

![avg_latency.png](docs/src/images/avg_latency.png)

2. ANNs are always a trade-off between recall and performance

![avg_latency.png](docs/src/images/recall_vs_latency.png)

### Vs. parquet

We create a Lance dataset using the Oxford Pet dataset to do some preliminary performance testing of Lance as compared to Parquet and raw image/XMLs. For analytics queries, Lance is 50-100x better than reading the raw metadata. For batched random access, Lance is 100x better than both parquet and raw files.

![](docs/src/images/lance_perf.png)

## Why Lance for AI/ML workflows?

The machine learning development cycle involves multiple stages:

```mermaid
graph LR
    A[Collection] --&gt; B[Exploration];
    B --&gt; C[Analytics];
    C --&gt; D[Feature Engineer];
    D --&gt; E[Training];
    E --&gt; F[Evaluation];
    F --&gt; C;
    E --&gt; G[Deployment];
    G --&gt; H[Monitoring];
    H --&gt; A;
```

Traditional lakehouse formats were designed for SQL analytics and struggle with AI/ML workloads that require:
- **Vector search** for similarity and semantic retrieval
- **Fast random access** for sampling and interactive exploration
- **Multimodal data** storage (images, videos, audio alongside embeddings)
- **Data evolution** for feature engineering without full table rewrites
- **Hybrid search** combining vectors, full-text, and SQL predicates

While existing formats (Parquet, Iceberg, Delta Lake) excel at SQL analytics, they require additional specialized systems for AI capabilities. Lance brings these AI-first features directly into the lakehouse format.

A comparison of different formats across ML development stages:

|                     | Lance | Parquet &amp; ORC | JSON &amp; XML | TFRecord | Database | Warehouse |
|---------------------|-------|---------------|------------|----------|----------|-----------|
| Analytics           | Fast  | Fast          | Slow       | Slow     | Decent   | Fast      |
| Feature Engineering | Fast  | Fast          | Decent     | Slow     | Decent   | Good      |
| Training            | Fast  | Decent        | Slow       | Fast     | N/A      | N/A       |
| Exploration         | Fast  | Slow          | Fast       | Slow     | Fast     | Decent    |
| Infra Support       | Rich  | Rich          | Decent     | Limited  | Rich     | Rich      |

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rolldown/rolldown]]></title>
            <link>https://github.com/rolldown/rolldown</link>
            <guid>https://github.com/rolldown/rolldown</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:34 GMT</pubDate>
            <description><![CDATA[Fast Rust bundler for JavaScript/TypeScript with Rollup-compatible API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rolldown/rolldown">rolldown/rolldown</a></h1>
            <p>Fast Rust bundler for JavaScript/TypeScript with Rollup-compatible API.</p>
            <p>Language: Rust</p>
            <p>Stars: 12,926</p>
            <p>Forks: 701</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://rolldown.rs&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://rolldown.rs/rolldown-light.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://rolldown.rs/rolldown-dark.svg&quot;&gt;
      &lt;img alt=&quot;rolldown logo&quot; src=&quot;https://rolldown.rs/rolldown-dark.svg&quot; height=&quot;60&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![MIT licensed][badge-license]][url-license]
[![NPM version][badge-npm-version]][url-npm]
[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/rolldown/rolldown)
[![Discord chat][badge-discord]][discord-url]
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/rolldown/rolldown)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![NPM Unpacked Size (with version)](https://img.shields.io/npm/unpacked-size/rolldown/latest?label=npm)][url-npm]
[![NPM Unpacked Size darwin-arm64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest?label=darwin-arm64)](https://npmx.dev/package/@rolldown/binding-darwin-arm64)
[![NPM Unpacked Size darwin-x64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-x64/latest?label=darwin-x64)](https://npmx.dev/package/@rolldown/binding-darwin-x64)
[![NPM Unpacked Size linux-x64-gnu](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-linux-x64-gnu/latest?label=linux-x64-gnu)](https://npmx.dev/package/@rolldown/binding-linux-x64-gnu)
[![NPM Unpacked Size win32-x64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest?label=win32-x64)](https://npmx.dev/package/@rolldown/binding-win32-x64-msvc)
[![NPM Unpacked Size wasm32-wasi](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-wasm32-wasi/latest?label=wasm32-wasi)](https://npmx.dev/package/@rolldown/binding-wasm32-wasi)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![pkg.pr.new](https://pkg.pr.new/badge/pkg.pr.new/pkg.pr.new?style=flat&amp;color=000&amp;logoSize=auto)](https://pkg.pr.new/~/rolldown/rolldown)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![rolldown-starter-stackblitz](https://developer.stackblitz.com/img/open_in_stackblitz.svg)](https://stackblitz.com/fork/github/rolldown/rolldown-starter-stackblitz)

&lt;/div&gt;

&gt; üöß **Release Candidate**
&gt;
&gt; Rolldown is currently in RC status. While it can already handle most production use cases, there may still be bugs and rough edges. Most notably, the built-in minification feature is still in alpha status.

# Rolldown

Rolldown is a JavaScript/TypeScript bundler written in Rust intended to serve as the future bundler used in [Vite](https://vitejs.dev/). It provides Rollup-compatible APIs and plugin interface, but will be more similar to esbuild in scope.

For more information, please check out the documentation at [rolldown.rs](https://rolldown.rs/guide/getting-started).

## VoidZero Inc.

Rolldown is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/posts/announcing-voidzero-inc).

If you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!

## Contributing

We would love to have more contributors involved!

To get started, please read our [Contributing Guide](https://rolldown.rs/contribution-guide/).

## Credits

The Rolldown project is heavily inspired by:

- [Rollup](https://github.com/rollup/rollup), created by [Rich Harris](https://github.com/Rich-Harris) and maintained by [Lukas Taegert-Atkinson](https://github.com/lukastaegert).
- [esbuild](https://github.com/evanw/esbuild), created by [Evan Wallace](https://github.com/evanw).

And supported by:

- [napi-rs](https://github.com/napi-rs/napi-rs) for Node.js add-ons in Rust via Node-API.
- [oxc](https://github.com/oxc-project/oxc) for the underlying parser, resolver, and sourcemap support.

## Licenses

This project is licensed under the [MIT License](LICENSE).

This project also partially contains code derived or copied from the following projects:

- [rollup(MIT)](https://github.com/rollup/rollup/blob/680912e2ceb42c8d5e571e01c6ece0e4889aecbb/LICENSE-CORE.md)
- [esbuild(MIT)](https://github.com/evanw/esbuild/blob/0c8a0a901d9a6c7bbff9b4dd347c8a3f65f6c6dd/LICENSE.md)

Licenses of these projects are listed in [THIRD-PARTY-LICENSE](/THIRD-PARTY-LICENSE)

[badge-discord]: https://img.shields.io/discord/1079625926024900739?logo=discord&amp;label=Discord
[discord-url]: https://chat.rolldown.rs
[badge-license]: https://img.shields.io/badge/license-MIT-blue.svg
[url-license]: https://github.com/rolldown/rolldown/blob/main/LICENSE
[badge-npm-version]: https://img.shields.io/npm/v/rolldown/latest?color=brightgreen
[url-npm]: https://npmx.dev/package/rolldown/v/latest

[badge-binary-size-windows]: [https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest]
[badge-binary-size-macos]: [https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest]
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[hank9999/kiro.rs]]></title>
            <link>https://github.com/hank9999/kiro.rs</link>
            <guid>https://github.com/hank9999/kiro.rs</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:33 GMT</pubDate>
            <description><![CDATA[A Kiro Client in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hank9999/kiro.rs">hank9999/kiro.rs</a></h1>
            <p>A Kiro Client in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 685</p>
            <p>Forks: 190</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># kiro-rs

‰∏Ä‰∏™Áî® Rust ÁºñÂÜôÁöÑ Anthropic Claude API ÂÖºÂÆπ‰ª£ÁêÜÊúçÂä°ÔºåÂ∞Ü Anthropic API ËØ∑Ê±ÇËΩ¨Êç¢‰∏∫ Kiro API ËØ∑Ê±Ç„ÄÇ

---

&lt;table&gt;
&lt;tr&gt;
&lt;td&gt;
&lt;b&gt;ÁâπÂà´ÊÑüË∞¢&lt;/b&gt;Ôºö&lt;a href=&quot;https://co.yes.vg/register?ref=hank9999&quot;&gt;YesCode&lt;/a&gt; ‰∏∫Êú¨È°πÁõÆÊèê‰æõ‰∫Ü AI API È¢ùÂ∫¶ËµûÂä©, YesCode ‰Ωú‰∏∫‰∏ÄÂÆ∂‰ΩéË∞ÉÂä°ÂÆûÁöÑ AI API ‰∏≠ËΩ¨ÊúçÂä°ÂïÜ &lt;br&gt;
ÈïøÊúü‰ª•Êù•Êèê‰æõÁ®≥ÂÆöÈ´òÂèØÁî®ÁöÑÊúçÂä°, Â¶ÇÊÇ®ÊúâÊÑè‰ΩìÈ™å, ËØ∑ÁÇπÂáªÈìæÊé•Ê≥®ÂÜå‰ΩìÈ™å ‚Üí &lt;a href=&quot;https://co.yes.vg/register?ref=hank9999&quot;&gt;Á´ãÂç≥ËÆøÈóÆ&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

---

## ÂÖçË¥£Â£∞Êòé

Êú¨È°πÁõÆ‰ªÖ‰æõÁ†îÁ©∂‰ΩøÁî®, Use at your own risk, ‰ΩøÁî®Êú¨È°πÁõÆÊâÄÂØºËá¥ÁöÑ‰ªª‰ΩïÂêéÊûúÁî±‰ΩøÁî®‰∫∫ÊâøÊãÖ, ‰∏éÊú¨È°πÁõÆÊó†ÂÖ≥„ÄÇ
Êú¨È°πÁõÆ‰∏é AWS/KIRO/Anthropic/Claude Á≠âÂÆòÊñπÊó†ÂÖ≥, Êú¨È°πÁõÆ‰∏ç‰ª£Ë°®ÂÆòÊñπÁ´ãÂú∫„ÄÇ

## Ê≥®ÊÑèÔºÅ

Âõ† TLS ÈªòËÆ§‰ªé native-tls ÂàáÊç¢Ëá≥ rustlsÔºå‰Ω†ÂèØËÉΩÈúÄË¶Å‰∏ìÈó®ÂÆâË£ÖËØÅ‰π¶ÂêéÊâçËÉΩÈÖçÁΩÆ HTTP ‰ª£ÁêÜ„ÄÇÂèØÈÄöËøá `config.json` ÁöÑ `tlsBackend` ÂàáÂõû `native-tls`„ÄÇ
Â¶ÇÊûúÈÅáÂà∞ËØ∑Ê±ÇÊä•Èîô, Â∞§ÂÖ∂ÊòØÊó†Ê≥ïÂà∑Êñ∞ token, ÊàñËÄÖÊòØÁõ¥Êé•ËøîÂõû error request, ËØ∑Â∞ùËØïÂàáÊç¢ tls ÂêéÁ´Ø‰∏∫ `native-tls`, ‰∏ÄËà¨Âç≥ÂèØËß£ÂÜ≥„ÄÇ

**Write Failed/‰ºöËØùÂç°Ê≠ª**: Â¶ÇÊûúÈÅáÂà∞ÊåÅÁª≠ÁöÑ Write File / Write Failed Âπ∂ÂØºËá¥‰ºöËØù‰∏çÂèØÁî®ÔºåÂèÇËÄÉ Issue [#22](https://github.com/hank9999/kiro.rs/issues/22) Âíå [#49](https://github.com/hank9999/kiro.rs/issues/49) ÁöÑËØ¥Êòé‰∏é‰∏¥Êó∂Ëß£ÂÜ≥ÊñπÊ°àÔºàÈÄöÂ∏∏‰∏éËæìÂá∫ËøáÈïøË¢´Êà™Êñ≠ÊúâÂÖ≥ÔºåÂèØÂ∞ùËØïË∞É‰ΩéËæìÂá∫Áõ∏ÂÖ≥ token ‰∏äÈôêÔºâ

## ÂäüËÉΩÁâπÊÄß

- **Anthropic API ÂÖºÂÆπ**: ÂÆåÊï¥ÊîØÊåÅ Anthropic Claude API Ê†ºÂºè
- **ÊµÅÂºèÂìçÂ∫î**: ÊîØÊåÅ SSE (Server-Sent Events) ÊµÅÂºèËæìÂá∫
- **Token Ëá™Âä®Âà∑Êñ∞**: Ëá™Âä®ÁÆ°ÁêÜÂíåÂà∑Êñ∞ OAuth Token
- **Â§öÂá≠ÊçÆÊîØÊåÅ**: ÊîØÊåÅÈÖçÁΩÆÂ§ö‰∏™Âá≠ÊçÆÔºåÊåâ‰ºòÂÖàÁ∫ßËá™Âä®ÊïÖÈöúËΩ¨Áßª
- **Ë¥üËΩΩÂùáË°°**: ÊîØÊåÅ `priority`ÔºàÊåâ‰ºòÂÖàÁ∫ßÔºâÂíå `balanced`ÔºàÂùáË°°ÂàÜÈÖçÔºâ‰∏§ÁßçÊ®°Âºè
- **Êô∫ËÉΩÈáçËØï**: ÂçïÂá≠ÊçÆÊúÄÂ§öÈáçËØï 3 Ê¨°ÔºåÂçïËØ∑Ê±ÇÊúÄÂ§öÈáçËØï 9 Ê¨°
- **Âá≠ÊçÆÂõûÂÜô**: Â§öÂá≠ÊçÆÊ†ºÂºè‰∏ãËá™Âä®ÂõûÂÜôÂà∑Êñ∞ÂêéÁöÑ Token
- **Thinking Ê®°Âºè**: ÊîØÊåÅ Claude ÁöÑ extended thinking ÂäüËÉΩ
- **Â∑•ÂÖ∑Ë∞ÉÁî®**: ÂÆåÊï¥ÊîØÊåÅ function calling / tool use
- **WebSearch**: ÂÜÖÁΩÆ WebSearch Â∑•ÂÖ∑ËΩ¨Êç¢ÈÄªËæë
- **Â§öÊ®°ÂûãÊîØÊåÅ**: ÊîØÊåÅ Sonnet„ÄÅOpus„ÄÅHaiku Á≥ªÂàóÊ®°Âûã
- **Admin ÁÆ°ÁêÜ**: ÂèØÈÄâÁöÑ Web ÁÆ°ÁêÜÁïåÈù¢Âíå APIÔºåÊîØÊåÅÂá≠ÊçÆÁÆ°ÁêÜ„ÄÅ‰ΩôÈ¢ùÊü•ËØ¢Á≠â
- **Â§öÁ∫ß Region ÈÖçÁΩÆ**: ÊîØÊåÅÂÖ®Â±ÄÂíåÂá≠ÊçÆÁ∫ßÂà´ÁöÑ Auth Region / API Region ÈÖçÁΩÆ
- **Âá≠ÊçÆÁ∫ß‰ª£ÁêÜ**: ÊîØÊåÅ‰∏∫ÊØè‰∏™Âá≠ÊçÆÂçïÁã¨ÈÖçÁΩÆ HTTP/SOCKS5 ‰ª£ÁêÜÔºå‰ºòÂÖàÁ∫ßÔºöÂá≠ÊçÆ‰ª£ÁêÜ &gt; ÂÖ®Â±Ä‰ª£ÁêÜ &gt; Êó†‰ª£ÁêÜ

---

- [ÂºÄÂßã](#ÂºÄÂßã)
  - [1. ÁºñËØë](#1-ÁºñËØë)
  - [2. ÊúÄÂ∞èÈÖçÁΩÆ](#2-ÊúÄÂ∞èÈÖçÁΩÆ)
  - [3. ÂêØÂä®](#3-ÂêØÂä®)
  - [4. È™åËØÅ](#4-È™åËØÅ)
  - [Docker](#docker)
- [ÈÖçÁΩÆËØ¶Ëß£](#ÈÖçÁΩÆËØ¶Ëß£)
  - [config.json](#configjson)
  - [credentials.json](#credentialsjson)
  - [Region ÈÖçÁΩÆ](#region-ÈÖçÁΩÆ)
  - [‰ª£ÁêÜÈÖçÁΩÆ](#‰ª£ÁêÜÈÖçÁΩÆ)
  - [ËÆ§ËØÅÊñπÂºè](#ËÆ§ËØÅÊñπÂºè)
  - [ÁéØÂ¢ÉÂèòÈáè](#ÁéØÂ¢ÉÂèòÈáè)
- [API Á´ØÁÇπ](#api-Á´ØÁÇπ)
  - [Ê†áÂáÜÁ´ØÁÇπ (/v1)](#Ê†áÂáÜÁ´ØÁÇπ-v1)
  - [Claude Code ÂÖºÂÆπÁ´ØÁÇπ (/cc/v1)](#claude-code-ÂÖºÂÆπÁ´ØÁÇπ-ccv1)
  - [Thinking Ê®°Âºè](#thinking-Ê®°Âºè)
  - [Â∑•ÂÖ∑Ë∞ÉÁî®](#Â∑•ÂÖ∑Ë∞ÉÁî®)
- [Ê®°ÂûãÊò†Â∞Ñ](#Ê®°ÂûãÊò†Â∞Ñ)
- [AdminÔºàÂèØÈÄâÔºâ](#adminÂèØÈÄâ)
- [Ê≥®ÊÑè‰∫ãÈ°π](#Ê≥®ÊÑè‰∫ãÈ°π)
- [È°πÁõÆÁªìÊûÑ](#È°πÁõÆÁªìÊûÑ)
- [ÊäÄÊúØÊ†à](#ÊäÄÊúØÊ†à)
- [License](#license)
- [Ëá¥Ë∞¢](#Ëá¥Ë∞¢)

## ÂºÄÂßã

### 1. ÁºñËØë

&gt; PS: Â¶ÇÊûú‰∏çÊÉ≥ÁºñËæëÂèØ‰ª•Áõ¥Êé•ÂâçÂæÄ Release ‰∏ãËΩΩ‰∫åËøõÂà∂Êñá‰ª∂

&gt; **ÂâçÁΩÆÊ≠•È™§**ÔºöÁºñËØëÂâçÈúÄË¶ÅÂÖàÊûÑÂª∫ÂâçÁ´Ø Admin UIÔºàÁî®‰∫éÂµåÂÖ•Âà∞‰∫åËøõÂà∂‰∏≠ÔºâÔºö
&gt; ```bash
&gt; cd admin-ui &amp;&amp; pnpm install &amp;&amp; pnpm build
&gt; ```

```bash
cargo build --release
```

### 2. ÊúÄÂ∞èÈÖçÁΩÆ

ÂàõÂª∫ `config.json`Ôºö

```json
{
   &quot;host&quot;: &quot;127.0.0.1&quot;,
   &quot;port&quot;: 8990,
   &quot;apiKey&quot;: &quot;sk-kiro-rs-qazWSXedcRFV123456&quot;,
   &quot;region&quot;: &quot;us-east-1&quot;
}
```
&gt; PS: Â¶ÇÊûú‰Ω†ÈúÄË¶Å Web ÁÆ°ÁêÜÈù¢Êùø, ËØ∑Ê≥®ÊÑèÈÖçÁΩÆ `adminApiKey`

ÂàõÂª∫ `credentials.json`Ôºà‰ªé Kiro IDE Á≠â‰∏≠Ëé∑ÂèñÂá≠ËØÅ‰ø°ÊÅØÔºâÔºö
&gt; PS: ÂèØ‰ª•ÂâçÂæÄ Web ÁÆ°ÁêÜÈù¢ÊùøÈÖçÁΩÆË∑≥ËøáÊú¨Ê≠•È™§
&gt; Â¶ÇÊûú‰Ω†ÂØπÂá≠ÊçÆÂú∞ÂüüÊúâÁñëÊÉë, ËØ∑Êü•Áúã [Region ÈÖçÁΩÆ](#region-ÈÖçÁΩÆ)

Social ËÆ§ËØÅÔºö
```json
{
   &quot;refreshToken&quot;: &quot;‰Ω†ÁöÑÂà∑Êñ∞token&quot;,
   &quot;expiresAt&quot;: &quot;2025-12-31T02:32:45.144Z&quot;,
   &quot;authMethod&quot;: &quot;social&quot;
}
```

IdC ËÆ§ËØÅÔºö
```json
{
   &quot;refreshToken&quot;: &quot;‰Ω†ÁöÑÂà∑Êñ∞token&quot;,
   &quot;expiresAt&quot;: &quot;2025-12-31T02:32:45.144Z&quot;,
   &quot;authMethod&quot;: &quot;idc&quot;,
   &quot;clientId&quot;: &quot;‰Ω†ÁöÑclientId&quot;,
   &quot;clientSecret&quot;: &quot;‰Ω†ÁöÑclientSecret&quot;
}
```

### 3. ÂêØÂä®

```bash
./target/release/kiro-rs
```

ÊàñÊåáÂÆöÈÖçÁΩÆÊñá‰ª∂Ë∑ØÂæÑÔºö

```bash
./target/release/kiro-rs -c /path/to/config.json --credentials /path/to/credentials.json
```

### 4. È™åËØÅ

```bash
curl http://127.0.0.1:8990/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-kiro-rs-qazWSXedcRFV123456&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;claude-sonnet-4-20250514&quot;,
    &quot;max_tokens&quot;: 1024,
    &quot;stream&quot;: true,
    &quot;messages&quot;: [
      {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello, Claude!&quot;}
    ]
  }&#039;
```

### Docker

‰πüÂèØ‰ª•ÈÄöËøá Docker ÂêØÂä®Ôºö

```bash
docker-compose up
```

ÈúÄË¶ÅÂ∞Ü `config.json` Âíå `credentials.json` ÊåÇËΩΩÂà∞ÂÆπÂô®‰∏≠ÔºåÂÖ∑‰ΩìÂèÇËßÅ `docker-compose.yml`„ÄÇ

## ÈÖçÁΩÆËØ¶Ëß£

### config.json

| Â≠óÊÆµ | Á±ªÂûã | ÈªòËÆ§ÂÄº | ÊèèËø∞ |
|------|------|--------|------|
| `host` | string | `127.0.0.1` | ÊúçÂä°ÁõëÂê¨Âú∞ÂùÄ |
| `port` | number | `8080` | ÊúçÂä°ÁõëÂê¨Á´ØÂè£ |
| `apiKey` | string | - | Ëá™ÂÆö‰πâ API KeyÔºàÁî®‰∫éÂÆ¢Êà∑Á´ØËÆ§ËØÅÔºåÂøÖÈÖçÔºâ |
| `region` | string | `us-east-1` | AWS Âå∫Âüü |
| `authRegion` | string | - | Auth RegionÔºàÁî®‰∫é Token Âà∑Êñ∞ÔºâÔºåÊú™ÈÖçÁΩÆÊó∂ÂõûÈÄÄÂà∞ region |
| `apiRegion` | string | - | API RegionÔºàÁî®‰∫é API ËØ∑Ê±ÇÔºâÔºåÊú™ÈÖçÁΩÆÊó∂ÂõûÈÄÄÂà∞ region |
| `kiroVersion` | string | `0.9.2` | Kiro ÁâàÊú¨Âè∑ |
| `machineId` | string | - | Ëá™ÂÆö‰πâÊú∫Âô®Á†ÅÔºà64‰ΩçÂçÅÂÖ≠ËøõÂà∂ÔºâÔºå‰∏çÂÆö‰πâÂàôËá™Âä®ÁîüÊàê |
| `systemVersion` | string | ÈöèÊú∫ | Á≥ªÁªüÁâàÊú¨Ê†áËØÜ |
| `nodeVersion` | string | `22.21.1` | Node.js ÁâàÊú¨Ê†áËØÜ |
| `tlsBackend` | string | `rustls` | TLS ÂêéÁ´ØÔºö`rustls` Êàñ `native-tls` |
| `countTokensApiUrl` | string | - | Â§ñÈÉ® count_tokens API Âú∞ÂùÄ |
| `countTokensApiKey` | string | - | Â§ñÈÉ® count_tokens API ÂØÜÈí• |
| `countTokensAuthType` | string | `x-api-key` | Â§ñÈÉ® API ËÆ§ËØÅÁ±ªÂûãÔºö`x-api-key` Êàñ `bearer` |
| `proxyUrl` | string | - | HTTP/SOCKS5 ‰ª£ÁêÜÂú∞ÂùÄ |
| `proxyUsername` | string | - | ‰ª£ÁêÜÁî®Êà∑Âêç |
| `proxyPassword` | string | - | ‰ª£ÁêÜÂØÜÁ†Å |
| `adminApiKey` | string | - | Admin API ÂØÜÈí•ÔºåÈÖçÁΩÆÂêéÂêØÁî®Âá≠ÊçÆÁÆ°ÁêÜ API Âíå Web ÁÆ°ÁêÜÁïåÈù¢ |
| `loadBalancingMode` | string | `priority` | Ë¥üËΩΩÂùáË°°Ê®°ÂºèÔºö`priority`ÔºàÊåâ‰ºòÂÖàÁ∫ßÔºâÊàñ `balanced`ÔºàÂùáË°°ÂàÜÈÖçÔºâ |

ÂÆåÊï¥ÈÖçÁΩÆÁ§∫‰æãÔºö

```json
{
   &quot;host&quot;: &quot;127.0.0.1&quot;,
   &quot;port&quot;: 8990,
   &quot;apiKey&quot;: &quot;sk-kiro-rs-qazWSXedcRFV123456&quot;,
   &quot;region&quot;: &quot;us-east-1&quot;,
   &quot;tlsBackend&quot;: &quot;rustls&quot;,
   &quot;kiroVersion&quot;: &quot;0.9.2&quot;,
   &quot;machineId&quot;: &quot;64‰ΩçÂçÅÂÖ≠ËøõÂà∂Êú∫Âô®Á†Å&quot;,
   &quot;systemVersion&quot;: &quot;darwin#24.6.0&quot;,
   &quot;nodeVersion&quot;: &quot;22.21.1&quot;,
   &quot;authRegion&quot;: &quot;us-east-1&quot;,
   &quot;apiRegion&quot;: &quot;us-east-1&quot;,
   &quot;countTokensApiUrl&quot;: &quot;https://api.example.com/v1/messages/count_tokens&quot;,
   &quot;countTokensApiKey&quot;: &quot;sk-your-count-tokens-api-key&quot;,
   &quot;countTokensAuthType&quot;: &quot;x-api-key&quot;,
   &quot;proxyUrl&quot;: &quot;http://127.0.0.1:7890&quot;,
   &quot;proxyUsername&quot;: &quot;user&quot;,
   &quot;proxyPassword&quot;: &quot;pass&quot;,
   &quot;adminApiKey&quot;: &quot;sk-admin-your-secret-key&quot;,
   &quot;loadBalancingMode&quot;: &quot;priority&quot;
}
```

### credentials.json

ÊîØÊåÅÂçïÂØπË±°Ê†ºÂºèÔºàÂêëÂêéÂÖºÂÆπÔºâÊàñÊï∞ÁªÑÊ†ºÂºèÔºàÂ§öÂá≠ÊçÆÔºâ„ÄÇ

#### Â≠óÊÆµËØ¥Êòé

| Â≠óÊÆµ             | Á±ªÂûã     | ÊèèËø∞                                          |
|----------------|--------|---------------------------------------------|
| `id`           | number | Âá≠ÊçÆÂîØ‰∏Ä IDÔºàÂèØÈÄâÔºå‰ªÖÁî®‰∫é Admin API ÁÆ°ÁêÜÔºõÊâãÂÜôÊñá‰ª∂ÂèØ‰∏çÂ°´Ôºâ        |
| `accessToken`  | string | OAuth ËÆøÈóÆ‰ª§ÁâåÔºàÂèØÈÄâÔºåÂèØËá™Âä®Âà∑Êñ∞Ôºâ                        |
| `refreshToken` | string | OAuth Âà∑Êñ∞‰ª§Áâå                                  |
| `profileArn`   | string | AWS Profile ARNÔºàÂèØÈÄâÔºåÁôªÂΩïÊó∂ËøîÂõûÔºâ                   |
| `expiresAt`    | string | Token ËøáÊúüÊó∂Èó¥ (RFC3339)                        |
| `authMethod`   | string | ËÆ§ËØÅÊñπÂºèÔºö`social` Êàñ `idc`                       |
| `clientId`     | string | IdC ÁôªÂΩïÁöÑÂÆ¢Êà∑Á´Ø IDÔºàIdC ËÆ§ËØÅÂøÖÂ°´Ôºâ                     |
| `clientSecret` | string | IdC ÁôªÂΩïÁöÑÂÆ¢Êà∑Á´ØÂØÜÈí•ÔºàIdC ËÆ§ËØÅÂøÖÂ°´Ôºâ                      |
| `priority`     | number | Âá≠ÊçÆ‰ºòÂÖàÁ∫ßÔºåÊï∞Â≠óË∂äÂ∞èË∂ä‰ºòÂÖàÔºåÈªòËÆ§‰∏∫ 0                         |
| `region`       | string | Âá≠ÊçÆÁ∫ß Auth Region, ÂÖºÂÆπÂ≠óÊÆµ                       |
| `authRegion`   | string | Âá≠ÊçÆÁ∫ß Auth RegionÔºåÁî®‰∫é Token Âà∑Êñ∞, Êú™ÈÖçÁΩÆÊó∂ÂõûÈÄÄÂà∞ region |
| `apiRegion`    | string | Âá≠ÊçÆÁ∫ß API RegionÔºåÁî®‰∫é API ËØ∑Ê±Ç                    |
| `machineId`    | string | Âá≠ÊçÆÁ∫ßÊú∫Âô®Á†ÅÔºà64‰ΩçÂçÅÂÖ≠ËøõÂà∂Ôºâ                             |
| `email`        | string | Áî®Êà∑ÈÇÆÁÆ±ÔºàÂèØÈÄâÔºå‰ªé API Ëé∑ÂèñÔºâ                           |
| `proxyUrl`     | string | Âá≠ÊçÆÁ∫ß‰ª£ÁêÜ URLÔºàÂèØÈÄâÔºåÁâπÊÆäÂÄº `direct` Ë°®Á§∫‰∏ç‰ΩøÁî®‰ª£ÁêÜÔºâ       |
| `proxyUsername`| string | Âá≠ÊçÆÁ∫ß‰ª£ÁêÜÁî®Êà∑ÂêçÔºàÂèØÈÄâÔºâ                                |
| `proxyPassword`| string | Âá≠ÊçÆÁ∫ß‰ª£ÁêÜÂØÜÁ†ÅÔºàÂèØÈÄâÔºâ                                 |

ËØ¥ÊòéÔºö
- IdC / Builder-ID / IAM Âú®Êú¨È°πÁõÆÈáåÂ±û‰∫éÂêå‰∏ÄÁßçÁôªÂΩïÊñπÂºèÔºåÈÖçÁΩÆÊó∂Áªü‰∏Ä‰ΩøÁî® `authMethod: &quot;idc&quot;`
- ‰∏∫ÂÖºÂÆπÊóßÈÖçÁΩÆÔºå`builder-id` / `iam` ‰ªçÂèØË¢´ËØÜÂà´Ôºå‰ΩÜ‰ºöÊåâ `idc` Â§ÑÁêÜ

#### ÂçïÂá≠ÊçÆÊ†ºÂºèÔºàÊóßÊ†ºÂºèÔºåÂêëÂêéÂÖºÂÆπÔºâ

```json
{
   &quot;accessToken&quot;: &quot;ËØ∑Ê±ÇtokenÔºå‰∏ÄËà¨ÊúâÊïàÊúü‰∏ÄÂ∞èÊó∂ÔºåÂèØÈÄâ&quot;,
   &quot;refreshToken&quot;: &quot;Âà∑Êñ∞tokenÔºå‰∏ÄËà¨ÊúâÊïàÊúü7-30Â§©‰∏çÁ≠â&quot;,
   &quot;profileArn&quot;: &quot;arn:aws:codewhisperer:us-east-1:111112222233:profile/QWER1QAZSDFGH&quot;,
   &quot;expiresAt&quot;: &quot;2025-12-31T02:32:45.144Z&quot;,
   &quot;authMethod&quot;: &quot;social&quot;,
   &quot;clientId&quot;: &quot;IdC ÁôªÂΩïÈúÄË¶Å&quot;,
   &quot;clientSecret&quot;: &quot;IdC ÁôªÂΩïÈúÄË¶Å&quot;
}
```

#### Â§öÂá≠ÊçÆÊ†ºÂºèÔºàÊîØÊåÅÊïÖÈöúËΩ¨ÁßªÂíåËá™Âä®ÂõûÂÜôÔºâ

```json
[
   {
      &quot;refreshToken&quot;: &quot;Á¨¨‰∏Ä‰∏™Âá≠ÊçÆÁöÑÂà∑Êñ∞token&quot;,
      &quot;expiresAt&quot;: &quot;2025-12-31T02:32:45.144Z&quot;,
      &quot;authMethod&quot;: &quot;social&quot;,
      &quot;priority&quot;: 0
   },
   {
      &quot;refreshToken&quot;: &quot;Á¨¨‰∫å‰∏™Âá≠ÊçÆÁöÑÂà∑Êñ∞token&quot;,
      &quot;expiresAt&quot;: &quot;2025-12-31T02:32:45.144Z&quot;,
      &quot;authMethod&quot;: &quot;idc&quot;,
      &quot;clientId&quot;: &quot;xxxxxxxxx&quot;,
      &quot;clientSecret&quot;: &quot;xxxxxxxxx&quot;,
      &quot;region&quot;: &quot;us-east-2&quot;,
      &quot;priority&quot;: 1,
      &quot;proxyUrl&quot;: &quot;socks5://proxy.example.com:1080&quot;,
      &quot;proxyUsername&quot;: &quot;user&quot;,
      &quot;proxyPassword&quot;: &quot;pass&quot;
   },
   {
      &quot;refreshToken&quot;: &quot;Á¨¨‰∏â‰∏™Âá≠ÊçÆÔºàÊòæÂºè‰∏çËµ∞‰ª£ÁêÜÔºâ&quot;,
      &quot;expiresAt&quot;: &quot;2025-12-31T02:32:45.144Z&quot;,
      &quot;authMethod&quot;: &quot;social&quot;,
      &quot;priority&quot;: 2,
      &quot;proxyUrl&quot;: &quot;direct&quot;
   }
]
```

Â§öÂá≠ÊçÆÁâπÊÄßÔºö
- Êåâ `priority` Â≠óÊÆµÊéíÂ∫èÔºåÊï∞Â≠óË∂äÂ∞è‰ºòÂÖàÁ∫ßË∂äÈ´òÔºàÈªòËÆ§‰∏∫ 0Ôºâ
- ÂçïÂá≠ÊçÆÊúÄÂ§öÈáçËØï 3 Ê¨°ÔºåÂçïËØ∑Ê±ÇÊúÄÂ§öÈáçËØï 9 Ê¨°
- Ëá™Âä®ÊïÖÈöúËΩ¨ÁßªÂà∞‰∏ã‰∏Ä‰∏™ÂèØÁî®Âá≠ÊçÆ
- Â§öÂá≠ÊçÆÊ†ºÂºè‰∏ã Token Âà∑Êñ∞ÂêéËá™Âä®ÂõûÂÜôÂà∞Ê∫êÊñá‰ª∂

### Region ÈÖçÁΩÆ

ÊîØÊåÅÂ§öÁ∫ß Region ÈÖçÁΩÆÔºåÂàÜÂà´ÊéßÂà∂ Token Âà∑Êñ∞Âíå API ËØ∑Ê±Ç‰ΩøÁî®ÁöÑÂå∫Âüü„ÄÇ

**Auth Region**ÔºàToken Âà∑Êñ∞Ôºâ‰ºòÂÖàÁ∫ßÔºö
`Âá≠ÊçÆ.authRegion` &gt; `Âá≠ÊçÆ.region` &gt; `config.authRegion` &gt; `config.region`

**API Region**ÔºàAPI ËØ∑Ê±ÇÔºâ‰ºòÂÖàÁ∫ßÔºö
`Âá≠ÊçÆ.apiRegion` &gt; `config.apiRegion` &gt; `config.region`

### ‰ª£ÁêÜÈÖçÁΩÆ

ÊîØÊåÅÂÖ®Â±Ä‰ª£ÁêÜÂíåÂá≠ÊçÆÁ∫ß‰ª£ÁêÜÔºåÂá≠ÊçÆÁ∫ß‰ª£ÁêÜ‰ºöË¶ÜÁõñËØ•Âá≠ÊçÆ‰∫ßÁîüÁöÑÊâÄÊúâÂá∫Á´ôËøûÊé•ÔºàAPI ËØ∑Ê±Ç„ÄÅToken Âà∑Êñ∞„ÄÅÈ¢ùÂ∫¶Êü•ËØ¢Ôºâ„ÄÇ

**‰ª£ÁêÜ‰ºòÂÖàÁ∫ß**Ôºö`Âá≠ÊçÆ.proxyUrl` &gt; `config.proxyUrl` &gt; Êó†‰ª£ÁêÜ

| Âá≠ÊçÆ `proxyUrl` ÂÄº | Ë°å‰∏∫ |
|---|---|
| ÂÖ∑‰Ωì URLÔºàÂ¶Ç `http://proxy:8080`„ÄÅ`socks5://proxy:1080`Ôºâ | ‰ΩøÁî®Âá≠ÊçÆÊåáÂÆöÁöÑ‰ª£ÁêÜ |
| `direct` | ÊòæÂºè‰∏ç‰ΩøÁî®‰ª£ÁêÜÔºàÂç≥‰ΩøÂÖ®Â±ÄÈÖçÁΩÆ‰∫Ü‰ª£ÁêÜÔºâ |
| Êú™ÈÖçÁΩÆÔºàÁïôÁ©∫Ôºâ | ÂõûÈÄÄÂà∞ÂÖ®Â±Ä‰ª£ÁêÜÈÖçÁΩÆ |

Âá≠ÊçÆÁ∫ß‰ª£ÁêÜÁ§∫‰æãÔºö

```json
[
   {
      &quot;refreshToken&quot;: &quot;Âá≠ÊçÆAÔºö‰ΩøÁî®Ëá™Â∑±ÁöÑ‰ª£ÁêÜ&quot;,
      &quot;authMethod&quot;: &quot;social&quot;,
      &quot;proxyUrl&quot;: &quot;socks5://proxy-a.example.com:1080&quot;,
      &quot;proxyUsername&quot;: &quot;user_a&quot;,
      &quot;proxyPassword&quot;: &quot;pass_a&quot;
   },
   {
      &quot;refreshToken&quot;: &quot;Âá≠ÊçÆBÔºöÊòæÂºè‰∏çËµ∞‰ª£ÁêÜÔºàÁõ¥ËøûÔºâ&quot;,
      &quot;authMethod&quot;: &quot;social&quot;,
      &quot;proxyUrl&quot;: &quot;direct&quot;
   },
   {
      &quot;refreshToken&quot;: &quot;Âá≠ÊçÆCÔºö‰ΩøÁî®ÂÖ®Â±Ä‰ª£ÁêÜÔºàÊàñÁõ¥ËøûÔºåÂèñÂÜ≥‰∫é config.jsonÔºâ&quot;,
      &quot;authMethod&quot;: &quot;social&quot;
   }
]
```

### ËÆ§ËØÅÊñπÂºè

ÂÆ¢Êà∑Á´ØËØ∑Ê±ÇÊú¨ÊúçÂä°Êó∂ÔºåÊîØÊåÅ‰∏§ÁßçËÆ§ËØÅÊñπÂºèÔºö

1. **x-api-key Header**
   ```
   x-api-key: sk-your-api-key
   ```

2. **Authorization Bearer**
   ```
   Authorization: Bearer sk-your-api-key
   ```

### ÁéØÂ¢ÉÂèòÈáè

ÂèØÈÄöËøáÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆÊó•ÂøóÁ∫ßÂà´Ôºö

```bash
RUST_LOG=debug ./target/release/kiro-rs
```

## API Á´ØÁÇπ

### Ê†áÂáÜÁ´ØÁÇπ (/v1)

| Á´ØÁÇπ | ÊñπÊ≥ï | ÊèèËø∞ |
|------|------|------|
| `/v1/models` | GET | Ëé∑ÂèñÂèØÁî®Ê®°ÂûãÂàóË°® |
| `/v1/messages` | POST | ÂàõÂª∫Ê∂àÊÅØÔºàÂØπËØùÔºâ |
| `/v1/messages/count_tokens` | POST | ‰º∞ÁÆó Token Êï∞Èáè |

### Claude Code ÂÖºÂÆπÁ´ØÁÇπ (/cc/v1)

| Á´ØÁÇπ | ÊñπÊ≥ï | ÊèèËø∞ |
|------|------|------|
| `/cc/v1/messages` | POST | ÂàõÂª∫Ê∂àÊÅØÔºàÁºìÂÜ≤Ê®°ÂºèÔºåÁ°Æ‰øù `input_tokens` ÂáÜÁ°ÆÔºâ |
| `/cc/v1/messages/count_tokens` | POST | ‰º∞ÁÆó Token Êï∞ÈáèÔºà‰∏é `/v1` Áõ∏ÂêåÔºâ |

&gt; **`/cc/v1/messages` ‰∏é `/v1/messages` ÁöÑÂå∫Âà´**Ôºö
&gt; - `/v1/messages`ÔºöÂÆûÊó∂ÊµÅÂºèËøîÂõûÔºå`message_start` ‰∏≠ÁöÑ `input_tokens` ÊòØ‰º∞ÁÆóÂÄº
&gt; - `/cc/v1/messages`ÔºöÁºìÂÜ≤Ê®°ÂºèÔºåÁ≠âÂæÖ‰∏äÊ∏∏ÊµÅÂÆåÊàêÂêéÔºåÁî®‰ªé `contextUsageEvent` ËÆ°ÁÆóÁöÑÂáÜÁ°Æ `input_tokens` Êõ¥Ê≠£ `message_start`ÔºåÁÑ∂Âêé‰∏ÄÊ¨°ÊÄßËøîÂõûÊâÄÊúâ‰∫ã‰ª∂
&gt; - Á≠âÂæÖÊúüÈó¥‰ºöÊØè 25 ÁßíÂèëÈÄÅ `ping` ‰∫ã‰ª∂‰øùÊ¥ª

### Thinking Ê®°Âºè

ÊîØÊåÅ Claude ÁöÑ extended thinking ÂäüËÉΩÔºö

```json
{
  &quot;model&quot;: &quot;claude-sonnet-4-20250514&quot;,
  &quot;max_tokens&quot;: 16000,
  &quot;thinking&quot;: {
    &quot;type&quot;: &quot;enabled&quot;,
    &quot;budget_tokens&quot;: 10000
  },
  &quot;messages&quot;: [...]
}
```

### Â∑•ÂÖ∑Ë∞ÉÁî®

ÂÆåÊï¥ÊîØÊåÅ Anthropic ÁöÑ tool use ÂäüËÉΩÔºö

```json
{
  &quot;model&quot;: &quot;claude-sonnet-4-20250514&quot;,
  &quot;max_tokens&quot;: 1024,
  &quot;tools&quot;: [
    {
      &quot;name&quot;: &quot;get_weather&quot;,
      &quot;description&quot;: &quot;Ëé∑ÂèñÊåáÂÆöÂüéÂ∏ÇÁöÑÂ§©Ê∞î&quot;,
      &quot;input_schema&quot;: {
        &quot;type&quot;: &quot;object&quot;,
        &quot;properties&quot;: {
          &quot;city&quot;: {&quot;type&quot;: &quot;string&quot;}
        },
        &quot;required&quot;: [&quot;city&quot;]
      }
    }
  ],
  &quot;messages&quot;: [...]
}
```

## Ê®°ÂûãÊò†Â∞Ñ

| Anthropic Ê®°Âûã | Kiro Ê®°Âûã |
|----------------|-----------|
| `*sonnet*` | `claude-sonnet-4.5` |
| `*opus*`ÔºàÂê´ 4.5/4-5Ôºâ | `claude-opus-4.5` |
| `*opus*`ÔºàÂÖ∂‰ªñÔºâ | `claude-opus-4.6` |
| `*haiku*` | `claude-haiku-4.5` |

## AdminÔºàÂèØÈÄâÔºâ

ÂΩì `config.json` ÈÖçÁΩÆ‰∫ÜÈùûÁ©∫ `adminApiKey` Êó∂Ôºå‰ºöÂêØÁî®Ôºö

- **Admin APIÔºàËÆ§ËØÅÂêå API KeyÔºâ**
  - `GET /api/admin/credentials` - Ëé∑ÂèñÊâÄÊúâÂá≠ÊçÆÁä∂ÊÄÅ
  - `POST /api/admin/credentials` - Ê∑ªÂä†Êñ∞Âá≠ÊçÆ
  - `DELETE /api/admin/credentials/:id` - Âà†Èô§Âá≠ÊçÆ
  - `POST /api/admin/credentials/:id/disabled` - ËÆæÁΩÆÂá≠ÊçÆÁ¶ÅÁî®Áä∂ÊÄÅ
  - `POST /api/admin/credentials/:id/priority` - ËÆæÁΩÆÂá≠ÊçÆ‰ºòÂÖàÁ∫ß
  - `POST /api/admin/credentials/:id/reset` - ÈáçÁΩÆÂ§±Ë¥•ËÆ°Êï∞
  - `GET /api/admin/credentials/:id/balance` - Ëé∑ÂèñÂá≠ÊçÆ‰ΩôÈ¢ù

- **Admin UI**
  - `GET /admin` - ËÆøÈóÆÁÆ°ÁêÜÈ°µÈù¢ÔºàÈúÄË¶ÅÂú®ÁºñËØëÂâçÊûÑÂª∫ `admin-ui/dist`Ôºâ

## Ê≥®ÊÑè‰∫ãÈ°π

1. **Âá≠ËØÅÂÆâÂÖ®**: ËØ∑Â¶•ÂñÑ‰øùÁÆ° `credentials.json` Êñá‰ª∂Ôºå‰∏çË¶ÅÊèê‰∫§Âà∞ÁâàÊú¨ÊéßÂà∂
2. **Token Âà∑Êñ∞**: ÊúçÂä°‰ºöËá™Âä®Âà∑Êñ∞ËøáÊúüÁöÑ TokenÔºåÊó†ÈúÄÊâãÂä®Âπ≤È¢Ñ
3. **WebSearch Â∑•ÂÖ∑**: ÂΩì `tools` ÂàóË°®‰ªÖÂåÖÂê´‰∏Ä‰∏™ `web_search` Â∑•ÂÖ∑Êó∂Ôºå‰ºöËµ∞ÂÜÖÁΩÆ WebSearch ËΩ¨Êç¢ÈÄªËæë

## È°πÁõÆÁªìÊûÑ

```
kiro-rs/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.rs                 # Á®ãÂ∫èÂÖ•Âè£
‚îÇ   ‚îú‚îÄ‚îÄ http_client.rs          # HTTP ÂÆ¢Êà∑Á´ØÊûÑÂª∫
‚îÇ   ‚îú‚îÄ‚îÄ token.rs                # Token ËÆ°ÁÆóÊ®°Âùó
‚îÇ   ‚îú‚îÄ‚îÄ debug.rs                # Ë∞ÉËØïÂ∑•ÂÖ∑
‚îÇ   ‚îú‚îÄ‚îÄ test.rs                 # ÊµãËØï
‚îÇ   ‚îú‚îÄ‚îÄ model/                  # ÈÖçÁΩÆÂíåÂèÇÊï∞Ê®°Âûã
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.rs           # Â∫îÁî®ÈÖçÁΩÆ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ arg.rs              # ÂëΩ‰ª§Ë°åÂèÇÊï∞
‚îÇ   ‚îú‚îÄ‚îÄ anthropic/              # Anthropic API ÂÖºÂÆπÂ±Ç
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.rs           # Ë∑ØÁî±ÈÖçÁΩÆ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handlers.rs         # ËØ∑Ê±ÇÂ§ÑÁêÜÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware.rs       # ËÆ§ËØÅ‰∏≠Èó¥‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types.rs            # Á±ªÂûãÂÆö‰πâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ converter.rs        # ÂçèËÆÆËΩ¨Êç¢Âô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stream.rs           # ÊµÅÂºèÂìçÂ∫îÂ§ÑÁêÜ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ websearch.rs        # WebSearch Â∑•ÂÖ∑Â§ÑÁêÜ
‚îÇ   ‚îú‚îÄ‚îÄ kiro/                   # Kiro API ÂÆ¢Êà∑Á´Ø
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ provider.rs         # API Êèê‰æõËÄÖ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ token_manager.rs    # Token ÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ machine_id.rs       # ËÆæÂ§áÊåáÁ∫πÁîüÊàê
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model/              # Êï∞ÊçÆÊ®°Âûã
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ credentials.rs  # OAuth Âá≠ËØÅ
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ events/         # ÂìçÂ∫î‰∫ã‰ª∂Á±ªÂûã
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ requests/       # ËØ∑Ê±ÇÁ±ªÂûã
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ common/         # ÂÖ±‰∫´Á±ªÂûã
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ token_refresh.rs # Token Âà∑Êñ∞Ê®°Âûã
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ usage_limits.rs # ‰ΩøÁî®È¢ùÂ∫¶Ê®°Âûã
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ parser/             # AWS Event Stream Ëß£ÊûêÂô®
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ decoder.rs      # ÊµÅÂºèËß£Á†ÅÂô®
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ frame.rs        # Â∏ßËß£Êûê
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ header.rs       # Â§¥ÈÉ®Ëß£Êûê
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ error.rs        # ÈîôËØØÁ±ªÂûã
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ crc.rs          # CRC Ê†°È™å
‚îÇ   ‚îú‚îÄ‚îÄ admin/                  # Admin API Ê®°Âùó
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ router.rs           # Ë∑ØÁî±ÈÖçÁΩÆ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ handlers.rs         # ËØ∑Ê±ÇÂ§ÑÁêÜÂô®
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ service.rs          # ‰∏öÂä°ÈÄªËæëÊúçÂä°
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types.rs            # Á±ªÂûãÂÆö‰πâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ middleware.rs       # ËÆ§ËØÅ‰∏≠Èó¥‰ª∂
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ error.rs            # ÈîôËØØÂ§ÑÁêÜ
‚îÇ   ‚îú‚îÄ‚îÄ admin_ui/               # Admin UI ÈùôÊÄÅÊñá‰ª∂ÂµåÂÖ•
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ router.rs           # ÈùôÊÄÅÊñá‰ª∂Ë∑ØÁî±
‚îÇ   ‚îî‚îÄ‚îÄ common/                 # ÂÖ¨ÂÖ±Ê®°Âùó
‚îÇ       ‚îî‚îÄ‚îÄ auth.rs             # ËÆ§ËØÅÂ∑•ÂÖ∑ÂáΩÊï∞
‚îú‚îÄ‚îÄ admin-ui/                   # Admin UI ÂâçÁ´ØÂ∑•Á®ãÔºàÊûÑÂª∫‰∫ßÁâ©‰ºöÂµåÂÖ•‰∫åËøõÂà∂Ôºâ
‚îú‚îÄ‚îÄ tools/                      # ËæÖÂä©Â∑•ÂÖ∑
‚îú‚îÄ‚îÄ Cargo.toml                  # È°πÁõÆÈÖçÁΩÆ
‚îú‚îÄ‚îÄ config.example.json         # ÈÖçÁΩÆÁ§∫‰æã
‚îú‚îÄ‚îÄ docker-compose.yml          # Docker Compose ÈÖçÁΩÆ
‚îî‚îÄ‚îÄ Dockerfile                  # Docker ÊûÑÂª∫Êñá‰ª∂
```

## ÊäÄÊúØÊ†à

- **Web Ê°ÜÊû∂**: [Axum](https://github.com/tokio-rs/axum) 0.8
- **ÂºÇÊ≠•ËøêË°åÊó∂**: [Tokio](https://tokio.rs/)
- **HTTP ÂÆ¢Êà∑Á´Ø**: [Reqwest](https://github.com/seanmonstar/reqwest)
- **Â∫èÂàóÂåñ**: [Serde](https://serde.rs/)
- **Êó•Âøó**: [tracing](https://github.com/tokio-rs/tracing)
- **ÂëΩ‰ª§Ë°å**: [Clap](https://github.com/clap-rs/clap)

## License

MIT

## Ëá¥Ë∞¢

Êú¨È°πÁõÆÁöÑÂÆûÁé∞Á¶ª‰∏çÂºÄÂâçËæàÁöÑÂä™Âäõ:  
 - [kiro2api](https://github.com/caidaoli/kiro2api)
 - [proxycast](https://github.com/aiclientproxy/proxycast)

Êú¨È°πÁõÆÈÉ®ÂàÜÈÄªËæëÂèÇËÄÉ‰∫Ü‰ª•‰∏äÁöÑÈ°πÁõÆ, ÂÜçÊ¨°Áî±Ë°∑ÁöÑÊÑüË∞¢!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tokio-rs/axum]]></title>
            <link>https://github.com/tokio-rs/axum</link>
            <guid>https://github.com/tokio-rs/axum</guid>
            <pubDate>Sun, 01 Mar 2026 00:06:32 GMT</pubDate>
            <description><![CDATA[HTTP routing and request-handling library for Rust that focuses on ergonomics and modularity]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tokio-rs/axum">tokio-rs/axum</a></h1>
            <p>HTTP routing and request-handling library for Rust that focuses on ergonomics and modularity</p>
            <p>Language: Rust</p>
            <p>Stars: 25,136</p>
            <p>Forks: 1,351</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>axum/README.md</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>