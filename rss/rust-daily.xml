<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Sun, 28 Sep 2025 00:05:46 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[ai-dynamo/dynamo]]></title>
            <link>https://github.com/ai-dynamo/dynamo</link>
            <guid>https://github.com/ai-dynamo/dynamo</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:46 GMT</pubDate>
            <description><![CDATA[A Datacenter Scale Distributed Inference Serving Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo</a></h1>
            <p>A Datacenter Scale Distributed Inference Serving Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 5,132</p>
            <p>Forks: 615</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;
![Dynamo banner](./docs/images/frontpage-banner.png)

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)
[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)

| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/762)** | **[Support matrix](https://github.com/ai-dynamo/dynamo/blob/main/docs/support_matrix.md)** | **[Documentation](https://docs.nvidia.com/dynamo/latest/index.html)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Prebuilt containers](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** | **[Blogs](https://developer.nvidia.com/blog/tag/nvidia-dynamo)**

# NVIDIA Dynamo

High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.

## Latest News

* [08/05] Deploy `openai/gpt-oss-120b` with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo [‚û°Ô∏è link](./components/backends/trtllm/gpt-oss.md)

## The Era of Multi-GPU, Multi-Node

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-gpu-vertical.png&quot; alt=&quot;Multi Node Multi-GPU topology&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs‚Äîand sometimes many servers‚Äîbut it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.

Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:

- **Disaggregated prefill &amp; decode inference** ‚Äì Maximizes GPU throughput and facilitates trade off between throughput and latency.
- **Dynamic GPU scheduling** ‚Äì Optimizes performance based on fluctuating demand
- **LLM-aware request routing** ‚Äì Eliminates unnecessary KV cache re-computation
- **Accelerated data transfer** ‚Äì Reduces inference response time using NIXL.
- **KV cache offloading** ‚Äì Leverages multiple memory hierarchies for higher system throughput

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-architecture.png&quot; alt=&quot;Dynamo architecture&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

## Framework Support Matrix

| Feature | vLLM | SGLang | TensorRT-LLM |
|---------|----------------------|----------------------------|----------------------------------------|
| [**Disaggregated Serving**](/docs/architecture/disagg_serving.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**Conditional Disaggregation**](/docs/architecture/disagg_serving.md#conditional-disaggregation) | üöß | üöß | üöß |
| [**KV-Aware Routing**](/docs/architecture/kv_cache_routing.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**Load Based Planner**](/docs/architecture/load_planner.md) | üöß | üöß | üöß |
| [**SLA-Based Planner**](/docs/architecture/sla_planner.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**KVBM**](/docs/architecture/kvbm_architecture.md) | ‚úÖ | üöß | ‚úÖ |

To learn more about each framework and their capabilities, check out each framework&#039;s README!
- **[vLLM](components/backends/vllm/README.md)**
- **[SGLang](components/backends/sglang/README.md)**
- **[TensorRT-LLM](components/backends/trtllm/README.md)**

Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.

# Installation

The following examples require a few system level packages.
Recommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/support_matrix.md](docs/support_matrix.md)

## 1. Initial setup

The Dynamo team recommends the `uv` Python package manager, although any way works. Install uv:
```
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Install etcd and NATS (required)

To coordinate across a data center, Dynamo relies on etcd and NATS. To run Dynamo locally, these need to be available.

- [etcd](https://etcd.io/) can be run directly as `./etcd`.
- [nats](https://nats.io/) needs jetstream enabled: `nats-server -js`.

To quickly setup etcd &amp; NATS, you can also run:
```
# At the root of the repository:
# Edit deploy/docker-compose.yml to comment out &quot;runtime: nvidia&quot; of the dcgm-exporter service if the nvidia container runtime isn&#039;t deployed or to be used.
docker compose -f deploy/docker-compose.yml up -d
```

## 2. Select an engine

We publish Python wheels specialized for each of our supported engines: vllm, sglang, trtllm, and llama.cpp. The examples that follow use SGLang; continue reading for other engines.

```
uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install &quot;ai-dynamo[sglang]&quot;  #replace with [vllm], [trtllm], etc.
```

## 3. Run Dynamo

### Running an LLM API server

Dynamo provides a simple way to spin up a local set of inference components including:

- **OpenAI Compatible Frontend** ‚Äì High performance OpenAI compatible http api server written in Rust.
- **Basic and Kv Aware Router** ‚Äì Route and load balance traffic to a set of workers.
- **Workers** ‚Äì Set of pre-configured LLM serving engines.

```
# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
python -m dynamo.frontend --http-port 8000 [--tls-cert-path cert.pem] [--tls-key-path key.pem]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
python -m dynamo.sglang.worker --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B --skip-tokenizer-init
```

#### Send a Request

```bash
curl localhost:8000/v1/chat/completions   -H &quot;Content-Type: application/json&quot;   -d &#039;{
    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,
    &quot;messages&quot;: [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello, how are you?&quot;
    }
    ],
    &quot;stream&quot;:false,
    &quot;max_tokens&quot;: 300
  }&#039; | jq
```

Rerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.

### Deploying Dynamo

- Follow the [Quickstart Guide](docs/kubernetes/README.md) to deploy on Kubernetes.
- Check out [Backends](components/backends) to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)
- Run some [Examples](examples) to learn about building components in Dynamo and exploring various integrations.

### Benchmarking Dynamo

Dynamo provides comprehensive benchmarking tools to evaluate and optimize your deployments:

* **[Benchmarking Guide](docs/benchmarks/benchmarking.md)** ‚Äì Compare deployment topologies (aggregated vs. disaggregated vs. vanilla vLLM) using GenAI-Perf
* **[Pre-Deployment Profiling](docs/benchmarks/pre_deployment_profiling.md)** ‚Äì Optimize configurations before deployment to meet SLA requirements

# Engines

Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (`python -m dynamo.frontend [--interactive]`).

## vLLM

```
uv pip install ai-dynamo[vllm]
```

Run the backend/worker like this:
```
python -m dynamo.vllm --help
```

vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass `--context-length &lt;value&gt;`.

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

## SGLang

```
# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
```

Run the backend/worker like this:
```
python -m dynamo.sglang.worker --help
```

You can pass any sglang flags directly to this worker, see https://docs.sglang.ai/advanced_features/server_arguments.html . See there to use multiple GPUs.

## TensorRT-LLM

It is recommended to use [NGC PyTorch Container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) for running the TensorRT-LLM engine.

&gt; [!Note]
&gt; Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using.
&gt; For example, if you are using `tensorrt-llm==1.1.0rc5`, use the PyTorch container image version `25.06`.
&gt; To find the correct PyTorch container version for your desired `tensorrt-llm` release, visit the [TensorRT-LLM Dockerfile.multi](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docker/Dockerfile.multi) on GitHub. Switch to the branch that matches your `tensorrt-llm` version, and look for the `BASE_TAG` line to identify the recommended PyTorch container tag.

&gt; [!Important]
&gt; Launch container with the following additional settings `--shm-size=1g --ulimit memlock=-1`

### Install prerequisites
```
# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install &quot;cuda-python&gt;=12,&lt;13&quot;

sudo apt-get -y install libopenmpi-dev
```

&gt; [!Tip]
&gt; You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation [here](https://nvidia.github.io/TensorRT-LLM/installation/linux.html).

### After installing the pre-requisites above, install Dynamo
```
uv pip install ai-dynamo[trtllm]
```

Run the backend/worker like this:
```
python -m dynamo.trtllm --help
```

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

# Developing Locally

## 1. Install libraries

**Ubuntu:**
```
sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
```

**macOS:**
- [Homebrew](https://brew.sh/)
```
# if brew is not installed on your system, install it
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
```
- [Xcode](https://developer.apple.com/xcode/)

```
brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
```
If Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.


## 2. Install Rust

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
```

## 3. Create a Python virtual env:

Follow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don&#039;t have `uv` installed. Once uv is installed, create a virtual environment and activate it.

- Install uv
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

- Create a virtual environment
```bash
uv venv dynamo
source dynamo/bin/activate
```

## 4. Install build tools

```
uv pip install pip maturin
```

[Maturin](https://github.com/PyO3/maturin) is the Rust&lt;-&gt;Python bindings build tool.

## 5. Build the Rust bindings

```
cd lib/bindings/python
maturin develop --uv
```

## 6. Install the wheel

```
cd $PROJECT_ROOT
uv pip install .
# For development, use
export PYTHONPATH=&quot;${PYTHONPATH}:$(pwd)/components/frontend/src:$(pwd)/components/planner/src:$(pwd)/components/backends/vllm/src:$(pwd)/components/backends/sglang/src:$(pwd)/components/backends/trtllm/src:$(pwd)/components/backends/llama_cpp/src:$(pwd)/components/backends/mocker/src&quot;
```

&gt; [!Note]
&gt; Editable (`-e`) does not work because the `dynamo` package is split over multiple directories, one per backend.

You should now be able to run `python -m dynamo.frontend`.

Remember that nats and etcd must be running (see earlier).

Set the environment variable `DYN_LOG` to adjust the logging level; for example, `export DYN_LOG=debug`. It has the same syntax as `RUST_LOG`.

If you use vscode or cursor, we have a .devcontainer folder built on [Microsofts Extension](https://code.visualstudio.com/docs/devcontainers/containers). For instructions see the [ReadMe](.devcontainer/README.md) for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nexus-xyz/nexus-cli]]></title>
            <link>https://github.com/nexus-xyz/nexus-cli</link>
            <guid>https://github.com/nexus-xyz/nexus-cli</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:45 GMT</pubDate>
            <description><![CDATA[Command line interface for supplying proofs to the Nexus network.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nexus-xyz/nexus-cli">nexus-xyz/nexus-cli</a></h1>
            <p>Command line interface for supplying proofs to the Nexus network.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,017</p>
            <p>Forks: 569</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![Release](https://img.shields.io/github/v/release/nexus-xyz/nexus-cli.svg)](https://github.com/nexus-xyz/nexus-cli/releases)
[![CI](https://github.com/nexus-xyz/nexus-cli/actions/workflows/ci.yml/badge.svg)](https://github.com/nexus-xyz/nexus-cli/actions)
[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](https://github.com/nexus-xyz/nexus-cli/blob/main/LICENSE-APACHE)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/nexus-xyz/nexus-cli/blob/main/LICENSE-MIT)
[![Twitter](https://img.shields.io/twitter/follow/NexusLabs)](https://x.com/NexusLabs)
[![Discord](https://img.shields.io/badge/Discord-Join-7289da.svg?logo=discord&amp;logoColor=white)](https://discord.com/invite/nexus-xyz)

# Nexus CLI

A high-performance command-line interface for contributing proofs to the Nexus network.

&lt;figure&gt;
    &lt;a href=&quot;https://nexus.xyz/&quot;&gt;
        &lt;img src=&quot;assets/images/nexus-network-image.png&quot; alt=&quot;Nexus Network visualization showing a distributed network of interconnected nodes with a &#039;Launch Network&#039; button in the center&quot;&gt;
    &lt;/a&gt;
    &lt;figcaption&gt;
        &lt;strong&gt;Verifiable Computation on a Global Scale&lt;/strong&gt;&lt;br&gt;
        We&#039;re building a global distributed prover network to unite the world&#039;s computers and power a new and better Internet: the Verifiable Internet. Connect to the beta and give it a try today.
    &lt;/figcaption&gt;
&lt;/figure&gt;

## Nexus Network

[Nexus](https://nexus.xyz/) is a global distributed prover network that unites the world&#039;s computers to power a new and
better Internet: the Verifiable Internet.

There have been several testnets so far:

- Testnet 0: [October 8 ‚Äì 28, 2024](https://blog.nexus.xyz/nexus-launches-worlds-first-open-prover-network/)
- Testnet I: [December 9 ‚Äì 13, 2024](https://blog.nexus.xyz/the-new-nexus-testnet-is-live/)
- Testnet II: [February 18 ‚Äì 22, 2025](https://blog.nexus.xyz/testnet-ii-is-open/)
- Devnet: [February 22 - June 20, 2025](https://docs.nexus.xyz/layer-1/testnet/devnet)
- Testnet III: [Ongoing](https://blog.nexus.xyz/live-everywhere/)

---

## Quick Start

### Installation

#### Precompiled Binary (Recommended)

For the simplest and most reliable installation:

```bash
curl https://cli.nexus.xyz/ | sh
```

This downloads the latest binary, prompts for Terms of Use acceptance, and starts interactive mode.

#### Non-Interactive Installation

For automated installations (e.g., in CI):

```bash
curl -sSf https://cli.nexus.xyz/ -o install.sh
chmod +x install.sh
NONINTERACTIVE=1 ./install.sh
```

### Proving

Proving with the CLI is documented [here](https://docs.nexus.xyz/layer-1/testnet/cli-node).

To start with an existing node ID, run:

```bash
nexus-cli start --node-id &lt;your-node-id&gt;
```

Alternatively, you can register your wallet address and create a node ID with the CLI, or at [app.nexus.xyz](https://app.nexus.xyz).

```bash
nexus-cli register-user --wallet-address &lt;your-wallet-address&gt;
nexus-cli register-node --node-id &lt;your-cli-node-id&gt;
nexus-cli start
```

To run the CLI noninteractively, you can also opt to start it in headless mode.

```bash
nexus-cli start --headless
```

#### Quick Reference

The `register-user` and `register-node` commands will save your credentials to `~/.nexus/config.json`. To clear credentials, run:

```bash
nexus-cli logout
```

For troubleshooting or to see available command-line options, run:

```bash
nexus-cli --help
```

### Adaptive Task Difficulty

The Nexus CLI features an **adaptive difficulty system** that automatically adjusts task difficulty based on your node&#039;s performance. This ensures optimal resource utilization while preventing system overload.

#### How It Works

- **Starts at**: `small` difficulty
- **Auto-promotes**: If tasks complete in &lt; 7 minutes

#### When to Override Difficulty

**Lower Difficulty** (e.g. `Small` or `SmallMedium`):
- Resource-constrained systems
- Background processing alongside other apps
- Testing/development environments
- Battery-powered devices

**Higher Difficulty** (e.g. `Large`, `ExtraLarge`, or `ExtraLarge2`):
- High-performance hardware (8+ cores, 16+ GB RAM)
- Dedicated proving machines
- Maximum reward optimization

#### Using Difficulty Override

```bash
# Lower difficulty for resource-constrained systems
nexus-cli start --max-difficulty small
nexus-cli start --max-difficulty small_medium

# Higher difficulty for powerful hardware
nexus-cli start --max-difficulty medium
nexus-cli start --max-difficulty large
nexus-cli start --max-difficulty extra_large
nexus-cli start --max-difficulty extra_large_2
nexus-cli start --max-difficulty extra_large_3
nexus-cli start --max-difficulty extra_large_4
nexus-cli start --max-difficulty extra_large_5

# Case-insensitive (all equivalent)
nexus-cli start --max-difficulty MEDIUM
nexus-cli start --max-difficulty medium
nexus-cli start --max-difficulty Medium
```

#### Difficulty Guidelines

| Difficulty | Use Case |
|------------|----------|
| `small` | Default, starting task |
| `small_medium` | Building reputation |
| `medium` and `large` | Standard desktop/laptop |
| `extra_large` and above | High-performance systems, more points |

&gt; **Tip**: Use `nexus-cli start --help` to see the full auto-promotion details in the CLI help text.

#### Troubleshooting Difficulty Issues

**Tasks taking too long:**

Try a lower difficulty.

```bash
nexus-cli start --max-difficulty small_medium
```

**Want more challenging tasks:**

Request a harder difficulty. It will still take time to build up reputation to get the requested difficulty.

```bash
nexus-cli start --max-difficulty extra_large_2
```

**Unsure about system capabilities:**
- Use the default adaptive system (no `--max-difficulty` needed)
- The system will automatically find the optimal difficulty for your hardware
- Only override if you&#039;re fine-tuning performance

### Docker Installation

For containerized deployments:

1. Install [Docker](https://docs.docker.com/engine/install/) and [Docker Compose](https://docs.docker.com/compose/install/)
2. Update the node ID in `docker-compose.yaml`
3. Build and run:

```bash
docker compose build --no-cache
docker compose up -d
docker compose logs  # Check logs
docker compose down  # Shutdown
```

---

## Terms of Use

Use of the CLI is subject to the [Terms of Use](https://nexus.xyz/terms-of-use).
First-time users running interactively will be prompted to accept these terms.

---

## Node ID

During the CLI&#039;s startup, you&#039;ll be asked for your node ID. To skip prompts in a
non-interactive environment, manually create a `~/.nexus/config.json` in the
following format:

```json
{
   &quot;node_id&quot;: &quot;&lt;YOUR NODE ID&gt;&quot;
}
```

---

## Get Help

- [Network FAQ](https://docs.nexus.xyz/layer-1/testnet/faq)
- [Discord Community](https://discord.gg/nexus-xyz)
- Technical issues? [Open an issue](https://github.com/nexus-xyz/nexus-cli/issues)
- To submit programs to the network for proving, contact
  [growth@nexus.xyz](mailto:growth@nexus.xyz).

---

## Contributing

Interested in contributing to the Nexus Network CLI? Check out our
[Contributor Guide](./CONTRIBUTING.md) for:

- Development setup instructions
- How to report issues and submit pull requests
- Our code of conduct and community guidelines
- Tips for working with the codebase

For most users, we recommend using the precompiled binaries as described above.
The contributor guide is intended for those who want to modify or improve the CLI
itself.

### üõ†  Developer Guide

The following steps may be required in order to set up a development environment for contributing to the project:

#### Linux

```bash
sudo apt update
sudo apt upgrade
sudo apt install build-essential pkg-config libssl-dev git-all
sudo apt install protobuf-compiler
```

#### macOS

```bash
# Install using Homebrew
brew install protobuf

# Verify installation
protoc --version
```

#### Windows

[Install WSL](https://learn.microsoft.com/en-us/windows/wsl/install),
then see Linux instructions above.

```bash
# Install using Chocolatey
choco install protobuf
```

## License

Nexus CLI is distributed under the terms of both the [MIT License](./LICENSE-MIT) and the [Apache License (Version 2.0)](./LICENSE-APACHE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[servo/servo]]></title>
            <link>https://github.com/servo/servo</link>
            <guid>https://github.com/servo/servo</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:44 GMT</pubDate>
            <description><![CDATA[Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/servo/servo">servo/servo</a></h1>
            <p>Servo aims to empower developers with a lightweight, high-performance alternative for embedding web technologies in applications.</p>
            <p>Language: Rust</p>
            <p>Stars: 31,607</p>
            <p>Forks: 3,258</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># The Servo Parallel Browser Engine Project

Servo is a prototype web browser engine written in the
[Rust](https://github.com/rust-lang/rust) language. It is currently developed on
64-bit macOS, 64-bit Linux, 64-bit Windows, 64-bit OpenHarmony, and Android.

Servo welcomes contribution from everyone. Check out:

- The [Servo Book](https://book.servo.org) for documentation
- [servo.org](https://servo.org/) for news and guides

Coordination of Servo development happens:
- Here in the Github Issues
- On the [Servo Zulip](https://servo.zulipchat.com/)
- In video calls advertised in the [Servo Project](https://github.com/servo/project/issues) repo.

## Getting started

For more detailed build instructions, see the Servo book under [Setting up your environment], [Building Servo], [Building for Android] and [Building for OpenHarmony].

[Setting up your environment]: https://book.servo.org/hacking/setting-up-your-environment.html
[Building Servo]: https://book.servo.org/hacking/building-servo.html
[Building for Android]: https://book.servo.org/hacking/building-for-android.html
[Building for OpenHarmony]: https://book.servo.org/hacking/building-for-openharmony.html

### macOS

- Download and install [Xcode](https://developer.apple.com/xcode/) and [`brew`](https://brew.sh/).
- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` 
- Install `rustup`: `curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh`
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `./mach bootstrap`
- Build servoshell: `./mach build`

### Linux

- Install `curl`:
  - Arch: `sudo pacman -S --needed curl`
  - Debian, Ubuntu: `sudo apt install curl`
  - Fedora: `sudo dnf install curl`
  - Gentoo: `sudo emerge net-misc/curl`
- Install `uv`: `curl -LsSf https://astral.sh/uv/install.sh | sh` 
- Install `rustup`: `curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh`
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `./mach bootstrap`
- Build servoshell: `./mach build`

### Windows

- Download [`uv`](https://docs.astral.sh/uv/getting-started/installation/#standalone-installer), [`choco`](https://chocolatey.org/install#individual), and [`rustup`](https://win.rustup.rs/)
  - Be sure to select *Quick install via the Visual Studio Community installer*
- In the Visual Studio Installer, ensure the following components are installed:
  - **Windows 10/11 SDK (anything &gt;= 10.0.19041.0)** (`Microsoft.VisualStudio.Component.Windows{10, 11}SDK.{&gt;=19041}`)
  - **MSVC v143 - VS 2022 C++ x64/x86 build tools (Latest)** (`Microsoft.VisualStudio.Component.VC.Tools.x86.x64`)
  - **C++ ATL for latest v143 build tools (x86 &amp; x64)** (`Microsoft.VisualStudio.Component.VC.ATL`)
  - **C++ MFC for latest v143 build tools (x86 &amp; x64)** (`Microsoft.VisualStudio.Component.VC.ATLMFC`)
- Restart your shell to make sure `cargo` is available
- Install the other dependencies: `.\mach bootstrap`
- Build servoshell: `.\mach build`

### Android

- Ensure that the following environment variables are set:
  - `ANDROID_SDK_ROOT`
  - `ANDROID_NDK_ROOT`: `$ANDROID_SDK_ROOT/ndk/26.2.11394342/`
 `ANDROID_SDK_ROOT` can be any directory (such as `~/android-sdk`).
  All of the Android build dependencies will be installed there.
- Install the latest version of the [Android command-line
  tools](https://developer.android.com/studio#command-tools) to
  `$ANDROID_SDK_ROOT/cmdline-tools/latest`.
- Run the following command to install the necessary components:
  ```shell
  sudo $ANDROID_SDK_ROOT/cmdline-tools/latest/bin/sdkmanager --install \
   &quot;build-tools;34.0.0&quot; \
   &quot;emulator&quot; \
   &quot;ndk;26.2.11394342&quot; \
   &quot;platform-tools&quot; \
   &quot;platforms;android-33&quot; \
   &quot;system-images;android-33;google_apis;x86_64&quot;
  ```
- Follow the instructions above for the platform you are building on

### OpenHarmony

- Follow the instructions above for the platform you are building on to prepare the environment.
- Depending on the target distribution (e.g. `HarmonyOS NEXT` vs pure `OpenHarmony`) the build configuration will differ slightly.
- Ensure that the following environment variables are set
  - `DEVECO_SDK_HOME` (Required when targeting `HarmonyOS NEXT`)
  - `OHOS_BASE_SDK_HOME` (Required when targeting `OpenHarmony`)
  - `OHOS_SDK_NATIVE` (e.g. `${DEVECO_SDK_HOME}/default/openharmony/native` or `${OHOS_BASE_SDK_HOME}/${API_VERSION}/native`)
  - `SERVO_OHOS_SIGNING_CONFIG`: Path to json file containing a valid signing configuration for the demo app.
- Review the detailed instructions at [Building for OpenHarmony].
- The target distribution can be modified by passing `--flavor=&lt;default|harmonyos&gt;` to `mach &lt;build|package|install&gt;`.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[sxyazi/yazi]]></title>
            <link>https://github.com/sxyazi/yazi</link>
            <guid>https://github.com/sxyazi/yazi</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:43 GMT</pubDate>
            <description><![CDATA[üí• Blazing fast terminal file manager written in Rust, based on async I/O.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sxyazi/yazi">sxyazi/yazi</a></h1>
            <p>üí• Blazing fast terminal file manager written in Rust, based on async I/O.</p>
            <p>Language: Rust</p>
            <p>Stars: 28,539</p>
            <p>Forks: 613</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://go.warp.dev/yazi&quot; target=&quot;_blank&quot;&gt;
		&lt;sup&gt;Special thanks to:&lt;/sup&gt;
		&lt;br&gt;
		&lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://github.com/warpdotdev/brand-assets/blob/main/Github/Sponsor/Warp-Github-LG-02.png&quot;&gt;
		&lt;br&gt;
		&lt;h&gt;Warp, built for coding with multiple AI agents&lt;/b&gt;
		&lt;br&gt;
		&lt;sup&gt;Available for macOS, Linux and Windows&lt;/sup&gt;
	&lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

## Yazi - ‚ö°Ô∏è Blazing Fast Terminal File Manager

Yazi (means &quot;duck&quot;) is a terminal file manager written in Rust, based on non-blocking async I/O. It aims to provide an efficient, user-friendly, and customizable file management experience.

üí° A new article explaining its internal workings: [Why is Yazi Fast?](https://yazi-rs.github.io/blog/why-is-yazi-fast)

- üöÄ **Full Asynchronous Support**: All I/O operations are asynchronous, CPU tasks are spread across multiple threads, making the most of available resources.
- üí™ **Powerful Async Task Scheduling and Management**: Provides real-time progress updates, task cancellation, and internal task priority assignment.
- üñºÔ∏è **Built-in Support for Multiple Image Protocols**: Also integrated with √úberzug++ and Chafa, covering almost all terminals.
- üåü **Built-in Code Highlighting and Image Decoding**: Combined with the pre-loading mechanism, greatly accelerates image and normal file loading.
- üîå **Concurrent Plugin System**: UI plugins (rewriting most of the UI), functional plugins, custom previewer/preloader/spotter/fetcher; Just some pieces of Lua.
- üì° **Data Distribution Service**: Built on a client-server architecture (no additional server process required), integrated with a Lua-based publish-subscribe model, achieving cross-instance communication and state persistence.
- üì¶ **Package Manager**: Install plugins and themes with one command, keeping them up-to-date, or pin them to a specific version.
- üß∞ Integration with ripgrep, fd, fzf, zoxide
- üí´ Vim-like input/pick/confirm/which/notify component, auto-completion for cd paths
- üè∑Ô∏è Multi-Tab Support, Cross-directory selection, Scrollable Preview (for videos, PDFs, archives, code, directories, etc.)
- üîÑ Bulk Renaming, Archive Extraction, Visual Mode, File Chooser, [Git Integration](https://github.com/yazi-rs/plugins/tree/main/git.yazi), [Mount Manager](https://github.com/yazi-rs/plugins/tree/main/mount.yazi)
- üé® Theme System, Mouse Support, Trash Bin, Custom Layouts, Virtual Filesystem, CSI u, OSC 52
- ... and more!

https://github.com/sxyazi/yazi/assets/17523360/92ff23fa-0cd5-4f04-b387-894c12265cc7

## Project status

Public beta, can be used as a daily driver.

Yazi is currently in heavy development, expect breaking changes.

## Documentation

- Usage: https://yazi-rs.github.io/docs/installation
- Features: https://yazi-rs.github.io/features

## Discussion

- Discord Server (English mainly): https://discord.gg/qfADduSdJu
- Telegram Group (Chinese mainly): https://t.me/yazi_rs

## Image Preview

| Platform                                                                     | Protocol                               | Support                           |
| ---------------------------------------------------------------------------- | -------------------------------------- | --------------------------------- |
| [kitty](https://github.com/kovidgoyal/kitty) (&gt;= 0.28.0)                     | [Kitty unicode placeholders][kgp]      | ‚úÖ Built-in                       |
| [iTerm2](https://iterm2.com)                                                 | [Inline images protocol][iip]          | ‚úÖ Built-in                       |
| [WezTerm](https://github.com/wez/wezterm)                                    | [Inline images protocol][iip]          | ‚úÖ Built-in                       |
| [Konsole](https://invent.kde.org/utilities/konsole)                          | [Kitty old protocol][kgp-old]          | ‚úÖ Built-in                       |
| [foot](https://codeberg.org/dnkl/foot)                                       | [Sixel graphics format][sixel]         | ‚úÖ Built-in                       |
| [Ghostty](https://github.com/ghostty-org/ghostty)                            | [Kitty unicode placeholders][kgp]      | ‚úÖ Built-in                       |
| [Windows Terminal](https://github.com/microsoft/terminal) (&gt;= v1.22.10352.0) | [Sixel graphics format][sixel]         | ‚úÖ Built-in                       |
| [st with Sixel patch](https://github.com/bakkeby/st-flexipatch)              | [Sixel graphics format][sixel]         | ‚úÖ Built-in                       |
| [Warp](https://www.warp.dev) (macOS/Linux only)                              | [Inline images protocol][iip]          | ‚úÖ Built-in                       |
| [Tabby](https://github.com/Eugeny/tabby)                                     | [Inline images protocol][iip]          | ‚úÖ Built-in                       |
| [VSCode](https://github.com/microsoft/vscode)                                | [Inline images protocol][iip]          | ‚úÖ Built-in                       |
| [Rio](https://github.com/raphamorim/rio)                                     | [Inline images protocol][iip]          | ‚úÖ Built-in                       |
| [Black Box](https://gitlab.gnome.org/raggesilver/blackbox)                   | [Sixel graphics format][sixel]         | ‚úÖ Built-in                       |
| [Hyper](https://github.com/vercel/hyper)                                     | [Inline images protocol][iip]          | ‚úÖ Built-in                       |
| [Bobcat](https://github.com/ismail-yilmaz/Bobcat)                            | [Inline images protocol][iip]          | ‚úÖ Built-in                       |
| X11 / Wayland                                                                | Window system protocol                 | ‚òëÔ∏è [√úberzug++][ueberzug] required |
| Fallback                                                                     | [ASCII art (Unicode block)][ascii-art] | ‚òëÔ∏è [Chafa][chafa] required        |

See https://yazi-rs.github.io/docs/image-preview for details.

&lt;!-- Protocols --&gt;

[kgp]: https://sw.kovidgoyal.net/kitty/graphics-protocol/#unicode-placeholders
[kgp-old]: https://github.com/sxyazi/yazi/blob/main/yazi-adapter/src/drivers/kgp_old.rs
[iip]: https://iterm2.com/documentation-images.html
[sixel]: https://www.vt100.net/docs/vt3xx-gp/chapter14.html
[ascii-art]: https://en.wikipedia.org/wiki/ASCII_art

&lt;!-- Dependencies --&gt;

[ueberzug]: https://github.com/jstkdng/ueberzugpp
[chafa]: https://hpjansson.org/chafa/

## License

Yazi is MIT-licensed. For more information check the [LICENSE](LICENSE) file.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:42 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 19,929</p>
            <p>Forks: 1,760</p>
            <p>Stars today: 40 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/7GaTvbDwga&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;&gt;
     &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

## üéâ Hacktoberfest 2025 üéâ

`goose` is a participating project in Hacktoberfest 2025! We‚Äôre so excited for your contributions, and have created a wide variety of issues so that anyone can contribute. Whether you&#039;re a seasoned developer or a first-time open source contributor, there&#039;s something for everyone.

### To get started:
1. Read the [contributing guide](https://github.com/block/goose/blob/main/CONTRIBUTING.md).
2. Read the [code of conduct](https://github.com/block/.github/blob/main/CODE_OF_CONDUCT.md).
3. Read the [full Responsible AI-Assisted Coding Guide](./ai-assisted-coding-guide.md).
4. Choose a task from this project&#039;s Hacktoberfest issues in our [Project Hub](https://github.com/block/goose/issues/4705) and follow the instructions. Each issue has the üè∑Ô∏è `hacktoberfest` label.

Have questions? Connecting with us in our [Discord community](https://discord.gg/block-opensource) in the `#hacktoberfest` project channel.

---

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.

[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)

# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)


# a little goose humor ü¶¢

&gt; Why did the developer choose goose as their AI agent?
&gt; 
&gt; Because it always helps them &quot;migrate&quot; their code to production! üöÄ

# goose around with us
- [Discord](https://discord.gg/block-opensource)
- [YouTube](https://www.youtube.com/@goose-oss)
- [LinkedIn](https://www.linkedin.com/company/goose-oss)
- [Twitter/X](https://x.com/goose_oss)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cloudflare/quiche]]></title>
            <link>https://github.com/cloudflare/quiche</link>
            <guid>https://github.com/cloudflare/quiche</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:41 GMT</pubDate>
            <description><![CDATA[ü•ß Savoury implementation of the QUIC transport protocol and HTTP/3]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudflare/quiche">cloudflare/quiche</a></h1>
            <p>ü•ß Savoury implementation of the QUIC transport protocol and HTTP/3</p>
            <p>Language: Rust</p>
            <p>Stars: 10,592</p>
            <p>Forks: 863</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>![quiche](quiche.svg)

[![crates.io](https://img.shields.io/crates/v/quiche.svg)](https://crates.io/crates/quiche)
[![docs.rs](https://docs.rs/quiche/badge.svg)](https://docs.rs/quiche)
[![license](https://img.shields.io/github/license/cloudflare/quiche.svg)](https://opensource.org/licenses/BSD-2-Clause)
![build](https://img.shields.io/github/actions/workflow/status/cloudflare/quiche/stable.yml?branch=master)

[quiche] is an implementation of the QUIC transport protocol and HTTP/3 as
specified by the [IETF]. It provides a low level API for processing QUIC packets
and handling connection state. The application is responsible for providing I/O
(e.g. sockets handling) as well as an event loop with support for timers.

For more information on how quiche came about and some insights into its design
you can read a [post] on Cloudflare&#039;s blog that goes into some more detail.

[quiche]: https://docs.quic.tech/quiche/
[ietf]: https://quicwg.org/
[post]: https://blog.cloudflare.com/enjoy-a-slice-of-quic-and-rust/

Who uses quiche?
----------------

### Cloudflare

quiche powers Cloudflare edge network&#039;s [HTTP/3 support][cloudflare-http3]. The
[cloudflare-quic.com](https://cloudflare-quic.com) website can be used for
testing and experimentation.

### Android

Android&#039;s DNS resolver uses quiche to [implement DNS over HTTP/3][android-http3].

### curl

quiche can be [integrated into curl][curl-http3] to provide support for HTTP/3.

[cloudflare-http3]: https://blog.cloudflare.com/http3-the-past-present-and-future/
[android-http3]: https://security.googleblog.com/2022/07/dns-over-http3-in-android.html
[curl-http3]: https://github.com/curl/curl/blob/master/docs/HTTP3.md#quiche-version

Getting Started
---------------

### Command-line apps

Before diving into the quiche API, here are a few examples on how to use the
quiche tools provided as part of the [quiche-apps](apps/) crate.

After cloning the project according to the command mentioned in the [building](#building) section, the client can be run as follows:

```bash
 $ cargo run --bin quiche-client -- https://cloudflare-quic.com/
```

while the server can be run as follows:

```bash
 $ cargo run --bin quiche-server -- --cert apps/src/bin/cert.crt --key apps/src/bin/cert.key
```

(note that the certificate provided is self-signed and should not be used in
production)

Use the `--help` command-line flag to get a more detailed description of each
tool&#039;s options.

### Configuring connections

The first step in establishing a QUIC connection using quiche is creating a
[`Config`] object:

```rust
let mut config = quiche::Config::new(quiche::PROTOCOL_VERSION)?;
config.set_application_protos(&amp;[b&quot;example-proto&quot;]);

// Additional configuration specific to application and use case...
```

The [`Config`] object controls important aspects of the QUIC connection such
as QUIC version, ALPN IDs, flow control, congestion control, idle timeout
and other properties or features.

QUIC is a general-purpose transport protocol and there are several
configuration properties where there is no reasonable default value. For
example, the permitted number of concurrent streams of any particular type
is dependent on the application running over QUIC, and other use-case
specific concerns.

quiche defaults several properties to zero, applications most likely need
to set these to something else to satisfy their needs using the following:

- [`set_initial_max_streams_bidi()`]
- [`set_initial_max_streams_uni()`]
- [`set_initial_max_data()`]
- [`set_initial_max_stream_data_bidi_local()`]
- [`set_initial_max_stream_data_bidi_remote()`]
- [`set_initial_max_stream_data_uni()`]

[`Config`] also holds TLS configuration. This can be changed by mutators on
the an existing object, or by constructing a TLS context manually and
creating a configuration using [`with_boring_ssl_ctx_builder()`].

A configuration object can be shared among multiple connections.

### Connection setup

On the client-side the [`connect()`] utility function can be used to create
a new connection, while [`accept()`] is for servers:

```rust
// Client connection.
let conn = quiche::connect(Some(&amp;server_name), &amp;scid, local, peer, &amp;mut config)?;

// Server connection.
let conn = quiche::accept(&amp;scid, None, local, peer, &amp;mut config)?;
```

### Handling incoming packets

Using the connection&#039;s [`recv()`] method the application can process
incoming packets that belong to that connection from the network:

```rust
let to = socket.local_addr().unwrap();

loop {
    let (read, from) = socket.recv_from(&amp;mut buf).unwrap();

    let recv_info = quiche::RecvInfo { from, to };

    let read = match conn.recv(&amp;mut buf[..read], recv_info) {
        Ok(v) =&gt; v,

        Err(e) =&gt; {
            // An error occurred, handle it.
            break;
        },
    };
}
```

### Generating outgoing packets

Outgoing packet are generated using the connection&#039;s [`send()`] method
instead:

```rust
loop {
    let (write, send_info) = match conn.send(&amp;mut out) {
        Ok(v) =&gt; v,

        Err(quiche::Error::Done) =&gt; {
            // Done writing.
            break;
        },

        Err(e) =&gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;out[..write], &amp;send_info.to).unwrap();
}
```

When packets are sent, the application is responsible for maintaining a
timer to react to time-based connection events. The timer expiration can be
obtained using the connection&#039;s [`timeout()`] method.

```rust
let timeout = conn.timeout();
```

The application is responsible for providing a timer implementation, which
can be specific to the operating system or networking framework used. When
a timer expires, the connection&#039;s [`on_timeout()`] method should be called,
after which additional packets might need to be sent on the network:

```rust
// Timeout expired, handle it.
conn.on_timeout();

// Send more packets as needed after timeout.
loop {
    let (write, send_info) = match conn.send(&amp;mut out) {
        Ok(v) =&gt; v,

        Err(quiche::Error::Done) =&gt; {
            // Done writing.
            break;
        },

        Err(e) =&gt; {
            // An error occurred, handle it.
            break;
        },
    };

    socket.send_to(&amp;out[..write], &amp;send_info.to).unwrap();
}
```

#### Pacing

It is recommended that applications [pace] sending of outgoing packets to
avoid creating packet bursts that could cause short-term congestion and
losses in the network.

quiche exposes pacing hints for outgoing packets through the [`at`] field
of the [`SendInfo`] structure that is returned by the [`send()`] method.
This field represents the time when a specific packet should be sent into
the network.

Applications can use these hints by artificially delaying the sending of
packets through platform-specific mechanisms (such as the [`SO_TXTIME`]
socket option on Linux), or custom methods (for example by using user-space
timers).

[pace]: https://datatracker.ietf.org/doc/html/rfc9002#section-7.7
[`SO_TXTIME`]: https://man7.org/linux/man-pages/man8/tc-etf.8.html

### Sending and receiving stream data

After some back and forth, the connection will complete its handshake and
will be ready for sending or receiving application data.

Data can be sent on a stream by using the [`stream_send()`] method:

```rust
if conn.is_established() {
    // Handshake completed, send some data on stream 0.
    conn.stream_send(0, b&quot;hello&quot;, true)?;
}
```

The application can check whether there are any readable streams by using
the connection&#039;s [`readable()`] method, which returns an iterator over all
the streams that have outstanding data to read.

The [`stream_recv()`] method can then be used to retrieve the application
data from the readable stream:

```rust
if conn.is_established() {
    // Iterate over readable streams.
    for stream_id in conn.readable() {
        // Stream is readable, read until there&#039;s no more data.
        while let Ok((read, fin)) = conn.stream_recv(stream_id, &amp;mut buf) {
            println!(&quot;Got {} bytes on stream {}&quot;, read, stream_id);
        }
    }
}
```

### HTTP/3

The quiche [HTTP/3 module] provides a high level API for sending and
receiving HTTP requests and responses on top of the QUIC transport protocol.

[`Config`]: https://docs.quic.tech/quiche/struct.Config.html
[`set_initial_max_streams_bidi()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_bidi
[`set_initial_max_streams_uni()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_streams_uni
[`set_initial_max_data()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_data
[`set_initial_max_stream_data_bidi_local()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_local
[`set_initial_max_stream_data_bidi_remote()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_bidi_remote
[`set_initial_max_stream_data_uni()`]: https://docs.rs/quiche/latest/quiche/struct.Config.html#method.set_initial_max_stream_data_uni
[`with_boring_ssl_ctx_builder()`]: https://docs.quic.tech/quiche/struct.Config.html#method.with_boring_ssl_ctx_builder
[`connect()`]: https://docs.quic.tech/quiche/fn.connect.html
[`accept()`]: https://docs.quic.tech/quiche/fn.accept.html
[`recv()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.recv
[`send()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.send
[`timeout()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.timeout
[`on_timeout()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.on_timeout
[`stream_send()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.stream_send
[`readable()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.readable
[`stream_recv()`]: https://docs.quic.tech/quiche/struct.Connection.html#method.stream_recv
[HTTP/3 module]: https://docs.quic.tech/quiche/h3/index.html

Have a look at the [quiche/examples/] directory for more complete examples on
how to use the quiche API, including examples on how to use quiche in C/C++
applications (see below for more information).

[examples/]: quiche/examples/

Calling quiche from C/C++
-------------------------

quiche exposes a [thin C API] on top of the Rust API that can be used to more
easily integrate quiche into C/C++ applications (as well as in other languages
that allow calling C APIs via some form of FFI). The C API follows the same
design of the Rust one, modulo the constraints imposed by the C language itself.

When running ``cargo build``, a static library called ``libquiche.a`` will be
built automatically alongside the Rust one. This is fully stand-alone and can
be linked directly into C/C++ applications.

Note that in order to enable the FFI API, the ``ffi`` feature must be enabled (it
is disabled by default), by passing ``--features ffi`` to ``cargo``.

[thin C API]: https://github.com/cloudflare/quiche/blob/master/quiche/include/quiche.h

Building
--------

quiche requires Rust 1.82 or later to build. The latest stable Rust release can
be installed using [rustup](https://rustup.rs/).

Once the Rust build environment is setup, the quiche source code can be fetched
using git:

```bash
 $ git clone --recursive https://github.com/cloudflare/quiche
```

and then built using cargo:

```bash
 $ cargo build --examples
```

cargo can also be used to run the testsuite:

```bash
 $ cargo test
```

Note that [BoringSSL], which is used to implement QUIC&#039;s cryptographic handshake
based on TLS, needs to be built and linked to quiche. This is done automatically
when building quiche using cargo, but requires the `cmake` command to be
available during the build process. On Windows you also need
[NASM](https://www.nasm.us/). The [official BoringSSL
documentation](https://github.com/google/boringssl/blob/master/BUILDING.md) has
more details.

In alternative you can use your own custom build of BoringSSL by configuring
the BoringSSL directory with the ``QUICHE_BSSL_PATH`` environment variable:

```bash
 $ QUICHE_BSSL_PATH=&quot;/path/to/boringssl&quot; cargo build --examples
```

Alternatively you can use [OpenSSL/quictls]. To enable quiche to use this vendor
the ``openssl`` feature can be added to the ``--feature`` list. Be aware that
``0-RTT`` is not supported if this vendor is used.

[BoringSSL]: https://boringssl.googlesource.com/boringssl/

[OpenSSL/quictls]: https://github.com/quictls/openssl

### Building for Android

Building quiche for Android (NDK version 19 or higher, 21 recommended), can be
done using [cargo-ndk] (v2.0 or later).

First the [Android NDK] needs to be installed, either using Android Studio or
directly, and the `ANDROID_NDK_HOME` environment variable needs to be set to the
NDK installation path, e.g.:

```bash
 $ export ANDROID_NDK_HOME=/usr/local/share/android-ndk
```

Then the Rust toolchain for the Android architectures needed can be installed as
follows:

```bash
 $ rustup target add aarch64-linux-android armv7-linux-androideabi i686-linux-android x86_64-linux-android
```

Note that the minimum API level is 21 for all target architectures.

[cargo-ndk] (v2.0 or later) also needs to be installed:

```bash
 $ cargo install cargo-ndk
```

Finally the quiche library can be built using the following procedure. Note that
the `-t &lt;architecture&gt;` and `-p &lt;NDK version&gt;` options are mandatory.

```bash
 $ cargo ndk -t arm64-v8a -p 21 -- build --features ffi
```

See [build_android_ndk19.sh] for more information.

[Android NDK]: https://developer.android.com/ndk
[cargo-ndk]: https://docs.rs/crate/cargo-ndk
[build_android_ndk19.sh]: https://github.com/cloudflare/quiche/blob/master/tools/android/build_android_ndk19.sh

### Building for iOS

To build quiche for iOS, you need the following:

- Install Xcode command-line tools. You can install them with Xcode or with the
  following command:

```bash
 $ xcode-select --install
```

- Install the Rust toolchain for iOS architectures:

```bash
 $ rustup target add aarch64-apple-ios x86_64-apple-ios
```

- Install `cargo-lipo`:

```bash
 $ cargo install cargo-lipo
```

To build libquiche, run the following command:

```bash
 $ cargo lipo --features ffi
```

or

```bash
 $ cargo lipo --features ffi --release
```

iOS build is tested in Xcode 10.1 and Xcode 11.2.

### Building Docker images

In order to build the Docker images, simply run the following command:

```bash
 $ make docker-build
```

You can find the quiche Docker images on the following Docker Hub repositories:

- [cloudflare/quiche](https://hub.docker.com/repository/docker/cloudflare/quiche)
- [cloudflare/quiche-qns](https://hub.docker.com/repository/docker/cloudflare/quiche-qns)

The `latest` tag will be updated whenever quiche master branch updates.

**cloudflare/quiche**

Provides a server and client installed in /usr/local/bin.

**cloudflare/quiche-qns**

Provides the script to test quiche within the [quic-interop-runner](https://github.com/marten-seemann/quic-interop-runner).

Copyright
---------

Copyright (C) 2018-2019, Cloudflare, Inc.

See [COPYING] for the license.

[COPYING]: https://github.com/cloudflare/quiche/tree/master/COPYING
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nautechsystems/nautilus_trader]]></title>
            <link>https://github.com/nautechsystems/nautilus_trader</link>
            <guid>https://github.com/nautechsystems/nautilus_trader</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:40 GMT</pubDate>
            <description><![CDATA[A high-performance algorithmic trading platform and event-driven backtester]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nautechsystems/nautilus_trader">nautechsystems/nautilus_trader</a></h1>
            <p>A high-performance algorithmic trading platform and event-driven backtester</p>
            <p>Language: Rust</p>
            <p>Stars: 15,519</p>
            <p>Forks: 1,721</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png&quot; width=&quot;500&quot;&gt;

[![codecov](https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H)](https://codecov.io/gh/nautechsystems/nautilus_trader)
[![codspeed](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/nautechsystems/nautilus_trader)
![pythons](https://img.shields.io/pypi/pyversions/nautilus_trader)
![pypi-version](https://img.shields.io/pypi/v/nautilus_trader)
![pypi-format](https://img.shields.io/pypi/format/nautilus_trader?color=blue)
[![Downloads](https://pepy.tech/badge/nautilus-trader)](https://pepy.tech/project/nautilus-trader)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/NautilusTrader)

| Branch    | Version                                                                                                                                                                                                                     | Status                                                                                                                                                                                            |
| :-------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `master`  | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html)  | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `nightly` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `develop` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |

| Platform           | Rust   | Python    |
| :----------------- | :----- | :-------- |
| `Linux (x86_64)`   | 1.89.0 | 3.11-3.13 |
| `Linux (ARM64)`    | 1.89.0 | 3.11-3.13 |
| `macOS (ARM64)`    | 1.89.0 | 3.11-3.13 |
| `Windows (x86_64)` | 1.89.0 | 3.11-3.13 |

- **Docs**: &lt;https://nautilustrader.io/docs/&gt;
- **Website**: &lt;https://nautilustrader.io&gt;
- **Support**: [support@nautilustrader.io](mailto:support@nautilustrader.io)

## Introduction

NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform,
providing quantitative traders with the ability to backtest portfolios of automated trading strategies
on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.

The platform is *AI-first*, designed to develop and deploy algorithmic trading strategies within a highly performant
and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest
environment consistent with the production live trading environment.

NautilusTrader&#039;s design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting
and live deployment workloads.

The platform is also universal, and asset-class-agnostic ‚Äî  with any REST API or WebSocket feed able to be integrated via modular
adapters. It supports high-frequency trading across a wide range of asset classes and instrument types
including FX, Equities, Futures, Options, Crypto, DeFi, and Betting, enabling seamless operations across multiple venues simultaneously.

![nautilus-trader](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png &quot;nautilus-trader&quot;)

## Features

- **Fast**: Core is written in Rust with asynchronous networking using [tokio](https://crates.io/crates/tokio).
- **Reliable**: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.
- **Portable**: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.
- **Flexible**: Modular adapters mean any REST API or WebSocket feed can be integrated.
- **Advanced**: Time in force `IOC`, `FOK`, `GTC`, `GTD`, `DAY`, `AT_THE_OPEN`, `AT_THE_CLOSE`, advanced order types and conditional triggers. Execution instructions `post-only`, `reduce-only`, and icebergs. Contingency orders including `OCO`, `OUO`, `OTO`.
- **Customizable**: Add user-defined custom components, or assemble entire systems from scratch leveraging the [cache](https://nautilustrader.io/docs/latest/concepts/cache) and [message bus](https://nautilustrader.io/docs/latest/concepts/message_bus).
- **Backtesting**: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.
- **Live**: Use identical strategy implementations between backtesting and live deployments.
- **Multi-venue**: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.
- **AI Training**: Backtest engine fast enough to be used to train AI trading agents (RL/ES).

![Alt text](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png &quot;nautilus&quot;)

&gt; *nautilus - from ancient Greek &#039;sailor&#039; and naus &#039;ship&#039;.*
&gt;
&gt; *The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral.
&gt; The idea is that this can be translated to the aesthetics of design and architecture.*

## Why NautilusTrader?

- **Highly performant event-driven Python**: Native binary core components.
- **Parity between backtesting and live trading**: Identical strategy code.
- **Reduced operational risk**: Enhanced risk management functionality, logical accuracy, and type safety.
- **Highly extendable**: Message bus, custom components and actors, custom data, custom adapters.

Traditionally, trading strategy research and backtesting might be conducted in Python
using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way
using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot
express the granular time and event dependent complexity of real-time trading, where compiled languages have
proven to be more suitable due to their inherently higher performance, and type safety.

One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform
have all been written entirely in [Rust](https://www.rust-lang.org/) or [Cython](https://cython.org/).
This means we&#039;re using the right tools for the job, where systems programming languages compile performant binaries,
with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.

## Why Python?

Python was originally created decades ago as a simple scripting language with a clean straightforward syntax.
It has since evolved into a fully fledged general purpose object-oriented programming language.
Based on the TIOBE index, Python is currently the most popular programming language in the world.
Not only that, Python has become the *de facto lingua franca* of data science, machine learning, and artificial intelligence.

developer/user communities.
However, Python has performance and typing limitations for large-scale, latency-sensitive systems. Cython addresses many of these issues by introducing static typing into Python&#039;s rich ecosystem of libraries and communities.

## Why Rust?

[Rust](https://www.rust-lang.org/) is a multi-paradigm programming language designed for performance and safety, especially safe
concurrency. Rust is &quot;blazingly fast&quot; and memory-efficient (comparable to C and C++) with no garbage collector.
It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.

Rust‚Äôs rich type system and ownership model guarantees memory-safety and thread-safety deterministically ‚Äî
eliminating many classes of bugs at compile-time.

The project increasingly utilizes Rust for core performance-critical components. Python bindings are implemented via Cython and [PyO3](https://pyo3.rs)‚Äîno Rust toolchain is required at install time.

This project makes the [Soundness Pledge](https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html):

&gt; ‚ÄúThe intent of this project is to be free of soundness bugs.
&gt; The developers will do their best to avoid them, and welcome help in analyzing and fixing them.‚Äù

&gt; [!NOTE]
&gt;
&gt; **MSRV:** NautilusTrader relies heavily on improvements in the Rust language and compiler.
&gt; As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.

## Integrations

NautilusTrader is modularly designed to work with *adapters*, enabling connectivity to trading venues
and data providers by translating their raw APIs into a unified interface and normalized domain model.

The following integrations are currently supported; see [docs/integrations/](https://nautilustrader.io/docs/latest/integrations/) for details:

| Name                                                                         | ID                    | Type                    | Status                                                  | Docs                                        |
| :--------------------------------------------------------------------------- | :-------------------- | :---------------------- | :------------------------------------------------------ | :------------------------------------------ |
| [Betfair](https://betfair.com)                                               | `BETFAIR`             | Sports Betting Exchange | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/betfair.md)       |
| [Binance](https://binance.com)                                               | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/binance.md)       |
| [Binance US](https://binance.us)                                             | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/binance.md)       |
| [Binance Futures](https://www.binance.com/en/futures)                        | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/binance.md)       |
| [BitMEX](https://www.bitmex.com)                                             | `BITMEX`              | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/building-orange) | [Guide](docs/integrations/bitmex.md)        |
| [Bybit](https://www.bybit.com)                                               | `BYBIT`               | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/bybit.md)         |
| [Coinbase International](https://www.coinbase.com/en/international-exchange) | `COINBASE_INTX`       | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/coinbase_intx.md) |
| [Databento](https://databento.com)                                           | `DATABENTO`           | Data Provider           | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/databento.md)     |
| [dYdX](https://dydx.exchange/)                                               | `DYDX`                | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/dydx.md)          |
| [Hyperliquid](https://hyperliquid.xyz)                                       | `HYPERLIQUID`         | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/building-orange) | [Guide](docs/integrations/hyperliquid.md)   |
| [Interactive Brokers](https://www.interactivebrokers.com)                    | `INTERACTIVE_BROKERS` | Brokerage (multi-venue) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/ib.md)            |
| [OKX](https://okx.com)                                                       | `OKX`                 | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/beta-yellow)     | [Guide](docs/integrations/okx.md)           |
| [Polymarket](https://polymarket.com)                                         | `POLYMARKET`          | Prediction Market (DEX) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/polymarket.md)    |
| [Tardis](https://tardis.dev)                                                 | `TARDIS`              | Crypto Data Provider    | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/tardis.md)        |

- **ID**: The default client ID for the integrations adapter clients.
- **Type**: The type of integration (often the venue type).

### Status

- `building`: Under construction and likely not in a usable state.
- `beta`: Completed to a minimally working state and in a beta testing phase.
- `stable`: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).

See the [Integrations](https://nautilustrader.io/docs/latest/integrations/index.html) documentation for further details.

## Versioning and releases

**NautilusTrader is still under active development**. Some features may be incomplete, and while
the API is becoming more stable, breaking changes can occur between releases.
We strive to document these changes in the release notes on a **best-effort basis**.

We aim to follow a **bi-weekly release schedule**, though experimental or larger features may cause delays.

### Branches

We aim to maintain a stable, passing build across all branches.

- `master`: Reflects the source code for the latest released version; recommended for production use.
- `nightly`: Daily snapshots of the `develop` branch for early testing; merged at **14:00 UTC** or on demand.
- `develop`: Active development branch for contributors and feature work.

&gt; [!NOTE]
&gt;
&gt; Our [roadmap](/ROADMAP.md) aims to achieve a **stable API for version 2.x** (likely after the Rust port).
&gt; Once this milestone is reached, we plan to implement a formal deprecation process for any API changes.
&gt; This approach allows us to maintain a rapid development pace for now.

## Precision mode

NautilusTrader supports two precision modes for its core value types (`Price`, `Quantity`, `Money`),
which differ in their internal bit-width and maximum decimal precision.

- **High-precision**: 128-bit integers with up to 16 decimals of precision, and a larger value range.
- **Standard-precision**: 64-bit integers with up to 9 decimals of precision, and a smaller value range.

&gt; [!NOTE]
&gt;
&gt; By default, the official Python wheels **ship** in high-precision (128-bit) mode on Linux and macOS.
&gt; On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support.
&gt; For the Rust crates, the default is standard-precision unless you explicitly enable the `high-precision` feature flag.

See the [Installation Guide](https://nautilustrader.io/docs/latest/getting_started/installation) for further details.

**Rust feature flag**: To enable high-precision mode in Rust, add the `high-precision` feature to your Cargo.toml:

```toml
[dependencies]
nautilus_model = { version = &quot;*&quot;, features = [&quot;high-precision&quot;] }
```

## Installation

We recommend using the latest supported version of Python and installing [nautilus_trader](https://pypi.org/project/nautilus_trader/) inside a virtual environment to isolate dependencies.

**There are two supported ways to install**:

1. Pre-built binary wheel from PyPI *or* the Nautech Systems package index.
2. Build from source.

&gt; [!TIP]
&gt;
&gt; We highly recommend installing using the [uv](https://docs.astral.sh/uv) package manager with a &quot;vanilla&quot; CPython.
&gt;
&gt; Conda and other Python distributions *may* work but aren‚Äôt officially supported.

### From PyPI

To install the latest binary wheel (or sdist package) from PyPI using Python&#039;s pip package manager:

```bash
pip install -U nautilus_trader
```

### From the Nautech Systems package index

The Nautech Systems package index (`packages.nautechsystems.io`) complies with [PEP-503](https://peps.python.org/pep-0503/) and hosts both stable and development binary wheels for `nautilus_trader`.
This enables users to install either the latest stable release or pre-release versions for testing.

#### Stable wheels

Stable wheels correspond to official releases of `nautilus_trader` on PyPI, and use standard versioning.

To install the latest stable release:

```bash
pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple
```

#### Development wheels

Development wheels are published from both the `nightly` and `develop` branches,
allowing users to test features and fixes ahead of stable releases.

**Note**: Wheels from the `develop` branch are only built for the Linux x86_64 platform to save time
and compute resources, while `nightly` wheels support additional platforms as shown below.

| Platform           | Nightly | Develop |
| :----------------- | :------ | :------ |
| `Linux (x86_64)`   | ‚úì       | ‚úì       |
| `Linux (ARM64)`    | ‚úì       | -       |
| `macOS (ARM64)`    | ‚úì       | -       |
| `Windows (x86_64)` | ‚úì       | -       |

This process also helps preserve compute resources and ensures easy access to the exact binaries tested in CI pipelines,
while adhering to [PEP-440](https://peps.python.org/pep-0440/) versioning standards:

- `develop` wheels use the version format `dev{date}+{build_number}` (e.g., `1.208.0.dev20241212+7001`).
- `nightly` wheels use the version format `a{date}` (alpha) (e.g., `1.208.0a20241212`).

&gt; [!WARNING]
&gt;
&gt; We do not recommend using development wheels in production environments, such as live trading controlling real capital.

#### Installation commands

By default, pip will install the latest stable release. Adding the `--pre` flag ensures that pre-release versions, including development wheels, are considered.

To install the latest available pre-release (including development wheels):

```bash
pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple
```

To install a specific development wheel (e.g., `1.208.0a20241212` for December 12, 2024):

```bash
pip install nautilus_trader==1.208.0a20241212 --index-url=https://packages.nautechsystems.io/simple
```

#### Available versions

You can view all available versions of `nautilus_trader` on the [package index](https://packages.nautechsystems.io

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[Lissy93/AdGuardian-Term]]></title>
            <link>https://github.com/Lissy93/AdGuardian-Term</link>
            <guid>https://github.com/Lissy93/AdGuardian-Term</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:39 GMT</pubDate>
            <description><![CDATA[üõ°Ô∏è Terminal-based, real-time traffic monitoring and statistics for your AdGuard Home instance]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Lissy93/AdGuardian-Term">Lissy93/AdGuardian-Term</a></h1>
            <p>üõ°Ô∏è Terminal-based, real-time traffic monitoring and statistics for your AdGuard Home instance</p>
            <p>Language: Rust</p>
            <p>Stars: 1,311</p>
            <p>Forks: 64</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BloopAI/vibe-kanban]]></title>
            <link>https://github.com/BloopAI/vibe-kanban</link>
            <guid>https://github.com/BloopAI/vibe-kanban</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:38 GMT</pubDate>
            <description><![CDATA[Kanban board to manage your AI coding agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BloopAI/vibe-kanban">BloopAI/vibe-kanban</a></h1>
            <p>Kanban board to manage your AI coding agents</p>
            <p>Language: Rust</p>
            <p>Stars: 5,149</p>
            <p>Forks: 488</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vibekanban.com&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;frontend/public/vibe-kanban-logo-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;frontend/public/vibe-kanban-logo.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;frontend/public/vibe-kanban-logo.svg&quot; alt=&quot;Vibe Kanban Logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Get 10X more out of Claude Code, Gemini CLI, Codex, Amp and other coding agents...&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/vibe-kanban&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/vibe-kanban?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/BloopAI/vibe-kanban/blob/main/.github/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/BloopAI/vibe-kanban/.github%2Fworkflows%2Fpublish.yml&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/BloopAI/vibe-kanban&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

![](frontend/public/vibe-kanban-screenshot-overview.png)

## Overview

AI coding agents are increasingly writing the world&#039;s code and human engineers now spend the majority of their time planning, reviewing, and orchestrating tasks. Vibe Kanban streamlines this process, enabling you to:

- Easily switch between different coding agents
- Orchestrate the execution of multiple coding agents in parallel or in sequence
- Quickly review work and start dev servers
- Track the status of tasks that your coding agents are working on
- Centralise configuration of coding agent MCP configs

You can watch a video overview [here](https://youtu.be/TFT3KnZOOAk).

## Installation

Make sure you have authenticated with your favourite coding agent. A full list of supported coding agents can be found in the [docs](https://vibekanban.com/docs). Then in your terminal run:

```bash
npx vibe-kanban
```

## Documentation

Please head to the [website](https://vibekanban.com/docs) for the latest documentation and user guides.

## Support

Please open an issue on this repo if you find any bugs or have any feature requests.

## Contributing

We would prefer that ideas and changes are raised with the core team via GitHub issues, where we can discuss implementation details and alignment with the existing roadmap. Please do not open PRs without first discussing your proposal with the team.

## Development

### Prerequisites

- [Rust](https://rustup.rs/) (latest stable)
- [Node.js](https://nodejs.org/) (&gt;=18)
- [pnpm](https://pnpm.io/) (&gt;=8)

Additional development tools:
```bash
cargo install cargo-watch
cargo install sqlx-cli
```

Install dependencies:
```bash
pnpm i
```

### Running the dev server

```bash
pnpm run dev
```

This will start the backend. A blank DB will be copied from the `dev_assets_seed` folder.

### Building the frontend

To build just the frontend:

```bash
cd frontend
pnpm build
```

### Build from source

1. Run `build-npm-package.sh`
2. In the `npx-cli` folder run `npm pack`
3. You can run your build with `npx [GENERATED FILE].tgz`


### Environment Variables

The following environment variables can be configured at build time or runtime:

| Variable | Type | Default | Description |
|----------|------|---------|-------------|
| `GITHUB_CLIENT_ID` | Build-time | `Ov23li9bxz3kKfPOIsGm` | GitHub OAuth app client ID for authentication |
| `POSTHOG_API_KEY` | Build-time | Empty | PostHog analytics API key (disables analytics if empty) |
| `POSTHOG_API_ENDPOINT` | Build-time | Empty | PostHog analytics endpoint (disables analytics if empty) |
| `BACKEND_PORT` | Runtime | `0` (auto-assign) | Backend server port |
| `FRONTEND_PORT` | Runtime | `3000` | Frontend development server port |
| `HOST` | Runtime | `127.0.0.1` | Backend server host |
| `DISABLE_WORKTREE_ORPHAN_CLEANUP` | Runtime | Not set | Disable git worktree cleanup (for debugging) |

**Build-time variables** must be set when running `pnpm run build`. **Runtime variables** are read when the application starts.

#### Custom GitHub OAuth App (Optional)

By default, Vibe Kanban uses Bloop AI&#039;s GitHub OAuth app for authentication. To use your own GitHub app for self-hosting or custom branding:

1. Create a GitHub OAuth App at [GitHub Developer Settings](https://github.com/settings/developers)
2. Enable &quot;Device Flow&quot; in the app settings
3. Set scopes to include `user:email,repo`
4. Build with your client ID:
   ```bash
   GITHUB_CLIENT_ID=your_client_id_here pnpm run build
   ```
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[aws/amazon-q-developer-cli]]></title>
            <link>https://github.com/aws/amazon-q-developer-cli</link>
            <guid>https://github.com/aws/amazon-q-developer-cli</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:37 GMT</pubDate>
            <description><![CDATA[‚ú® Agentic chat experience in your terminal. Build applications using natural language.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aws/amazon-q-developer-cli">aws/amazon-q-developer-cli</a></h1>
            <p>‚ú® Agentic chat experience in your terminal. Build applications using natural language.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,631</p>
            <p>Forks: 303</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># Amazon Q CLI

## Installation

- **macOS**:
  - **DMG**: [Download now](https://desktop-release.q.us-east-1.amazonaws.com/latest/Amazon%20Q.dmg)
- **Linux**:
  - [Ubuntu/Debian](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-ubuntu)
  - [AppImage](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-appimage)
  - [Alternative Linux builds](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-alternative-linux)

## Contributing

Thank you so much for considering to contribute to Amazon Q.

Before getting started, see our [contributing docs](CONTRIBUTING.md#security-issue-notifications).

### Prerequisites

- MacOS
  - Xcode 13 or later
  - Brew

#### 1. Clone repo

```shell
git clone https://github.com/aws/amazon-q-developer-cli.git
```

#### 2. Install the Rust toolchain using [Rustup](https://rustup.rs):

```shell
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup default stable
rustup toolchain install nightly
cargo install typos-cli
```

#### 3. Develop locally

- To compile and run: `cargo run --bin chat_cli`.
- To run tests: `cargo test`.
- To run lints: `cargo clippy`.
- To format rust files: `cargo +nightly fmt`.
- To run subcommands: `cargo run --bin chat_cli -- {subcommand}`.
  - Login would then be: `cargo run --bin chat_cli -- login`

## Project Layout

- [`chat_cli`](crates/chat-cli/) - the `q` CLI, allows users to interface with Amazon Q Developer from
  the command line
- [`scripts/`](scripts/) - Contains ops and build related scripts
- [`crates/`](crates/) - Contains all rust crates
- [`docs/`](docs/) - Contains technical documentation

## Security

For security related concerns, see [here](SECURITY.md).

## Licensing

This repo is dual licensed under MIT and Apache 2.0 licenses.

Those licenses can be found [here](LICENSE.MIT) and [here](LICENSE.APACHE).

‚ÄúAmazon Web Services‚Äù and all related marks, including logos, graphic designs, and service names, are trademarks or trade dress of AWS in the U.S. and other countries. AWS‚Äôs trademarks and trade dress may not be used in connection with any product or service that is not AWS‚Äôs, in any manner that is likely to cause confusion among customers, or in any manner that disparages or discredits AWS.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[FuelLabs/sway]]></title>
            <link>https://github.com/FuelLabs/sway</link>
            <guid>https://github.com/FuelLabs/sway</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[üå¥ Empowering everyone to build reliable and efficient smart contracts.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/FuelLabs/sway">FuelLabs/sway</a></h1>
            <p>üå¥ Empowering everyone to build reliable and efficient smart contracts.</p>
            <p>Language: Rust</p>
            <p>Stars: 62,138</p>
            <p>Forks: 5,411</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># Sway

[![build](https://github.com/FuelLabs/sway/actions/workflows/ci.yml/badge.svg)](https://github.com/FuelLabs/sway/actions/workflows/ci.yml)
[![crates.io](https://img.shields.io/crates/v/forc?label=latest)](https://crates.io/crates/forc)
[![docs](https://docs.rs/forc/badge.svg)](https://docs.rs/forc/)
[![twitter](https://img.shields.io/twitter/follow/SwayLang)](https://x.com/SwayLang)
[![discord](https://img.shields.io/badge/chat%20on-discord-orange?&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/xfpK4Pe)

Sway is a language developed for the [Fuel](https://docs.fuel.network/docs/intro/what-is-fuel/) blockchain. It is heavily inspired by Rust and aims to bring modern language development and performance to the blockchain ecosystem.

## Documentation

For user documentation, including installing release builds, see the Sway Book: &lt;https://fuellabs.github.io/sway/latest/&gt;.

For Sway Standard library documentation, see: &lt;https://fuellabs.github.io/sway/master/std/&gt;

Also view the technical reference for the Sway programming language: &lt;https://fuellabs.github.io/sway/master/reference/&gt;

## Building from Source

This section is for developing the Sway compiler and toolchain. For developing contracts and using Sway, see the above documentation section.

### Dependencies

Sway is built in Rust. To begin, install the Rust toolchain following instructions at &lt;https://www.rust-lang.org/tools/install&gt;. Then configure your Rust toolchain to use Rust `stable`:

```sh
rustup default stable
```

If not already done, add the Cargo bin directory to your `PATH` by adding the following line to `~/.profile` and restarting the shell session.

```sh
export PATH=&quot;${HOME}/.cargo/bin:${PATH}&quot;
```

### Building Forc

Clone the repository and build the Sway toolchain:

```sh
git clone git@github.com:FuelLabs/sway.git
cd sway
cargo build
```

Confirm the Sway toolchain built successfully:

```sh
cargo run --bin forc -- --help
```

## All other scripts/commands

For all other scripts and commands use https://github.com/casey/just:

```
&gt; just --list
Available recipes:
    [automation]
    update-contract-ids
    update-fuel-dependencies

    [benchmark]
    benchmark
    benchmark-tests
    collect-gas-usage

    [build]
    build-highlightjs
    build-prism
    generate-sway-lib-std

    [ci]
    ci-check
    install-ci-check

    [test]
    test-forc-fmt-check-panic
```

## Contributing to Sway

We welcome contributions to Sway!

Please see the [Contributing To Sway](https://fuellabs.github.io/sway/master/book/reference/contributing_to_sway.html) section of the Sway book for guidelines and instructions to help you get started.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[davidlattimore/wild]]></title>
            <link>https://github.com/davidlattimore/wild</link>
            <guid>https://github.com/davidlattimore/wild</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[A very fast linker for Linux]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/davidlattimore/wild">davidlattimore/wild</a></h1>
            <p>A very fast linker for Linux</p>
            <p>Language: Rust</p>
            <p>Stars: 2,680</p>
            <p>Forks: 67</p>
            <p>Stars today: 68 stars today</p>
            <h2>README</h2><pre># Wild linker

Wild is a linker with the goal of being very fast for iterative development.

The plan is to eventually make it incremental, however that isn&#039;t yet implemented. It is however
already pretty fast even without incremental linking.

## Installation

### From GitHub releases

Download a tarball from the [releases page](https://github.com/davidlattimore/wild/releases). Unpack
it and copy the `wild` binary somewhere on your path.

### Cargo binstall

If you have [cargo-binstall](https://github.com/cargo-bins/cargo-binstall), you can install wild as
follows:

```sh
cargo binstall wild-linker
```

### Build latest release from crates.io

```sh
cargo install --locked wild-linker
```

### Build from git head

To build and install the latest, unreleased code:

```sh
cargo install --locked --bin wild --git https://github.com/davidlattimore/wild.git wild-linker
```

### Nix

See [nix/nix.md](nix/nix.md)

## Using as your default linker

If you&#039;d like to use Wild as your default linker for building Rust code, you can put the following
in `~/.cargo/config.toml`.

```toml
[target.x86_64-unknown-linux-gnu]
linker = &quot;clang&quot;
rustflags = [&quot;-C&quot;, &quot;link-arg=--ld-path=wild&quot;]
```

## Using wild in CI

If you&#039;d like to use Wild as your linker for Rust code in CI, see
[wild-action](https://github.com/davidlattimore/wild-action).

## Q&amp;A

### Why another linker?

Mold is already very fast, however it doesn&#039;t do incremental linking and the author has stated that
they don&#039;t intend to. Wild doesn&#039;t do incremental linking yet, but that is the end-goal. By writing
Wild in Rust, it&#039;s hoped that the complexity of incremental linking will be achievable.

### What&#039;s working?

The following platforms / architectures are currently supported:

* x86-64 on Linux
* ARM64 on Linux
* RISC-V (riscv64gc) on Linux (initial support: [#678](https://github.com/davidlattimore/wild/issues/678))

The following is working with the caveat that there may be bugs:

* Output to statically linked, non-relocatable binaries
* Output to statically linked, position-independent binaries (static-PIE)
* Output to dynamically linked binaries
* Output to shared objects (.so files)
* Rust proc-macros, when linked with Wild work
* Most of the top downloaded crates on crates.io have been tested with Wild and pass their tests
* Debug info
* GNU jobserver support
* Very basic linker script support (section mapping, keeping sections, alignment, defining start /
  stop symbols).

### What isn&#039;t yet supported?

Lots of stuff. Here are some of the larger things that aren&#039;t yet done, roughly sorted by current
priority:

* Incremental linking
* Support for more architectures
* Support for a wider range of linker flags
* More complex linker scripts
* Mac support
* Windows support
* LTO

### How can I verify that Wild was used to link a binary?

Install `readelf`, then run:

```sh
readelf  -p .comment my-executable
```

Look for a line like:

```
Linker: Wild version 0.1.0
```

Or if you don&#039;t want to install readelf, you can probably get away with:

```sh
strings my-executable | grep &#039;Linker:&#039;
```

### Where did the name come from?

It&#039;s somewhat of a tradition for linkers to end with the letters &quot;ld&quot;. e.g. &quot;GNU ld, &quot;gold&quot;, &quot;lld&quot;,
&quot;mold&quot;. Since the end-goal is for the linker to be incremental, an &quot;I&quot; is added. Let&#039;s say the &quot;W&quot;
stands for &quot;Wild&quot;, since recursive acronyms are popular in open-source projects.

## Benchmarks

The goal of Wild is to eventually be very fast via incremental linking. However, we also want to be
as fast as we can be for non-incremental linking and for the initial link when incremental linking
is enabled.

See [BENCHMARKING.md](BENCHMARKING.md) for more details on running benchmarks.

All benchmarks are run with output to a tmpfs.

### Linking clang on x86-64

This benchmark was run on David Lattimore&#039;s laptop (2020 model System76 Lemur pro), which has 4
cores (8 threads) and 42 GB of RAM.

Wild currently doesn&#039;t perform great beyond 8 threads. This is something we&#039;ve been investigating
and hope to improve soon.

First, without debug info:

```
‚ùØ OUT=/home/david/ttt throttle-count hyperfine --warmup 1 -N -n lld-18 &#039;./run-with ld.lld --strip-debug&#039; -n mold-2.36-no-fork &#039;./run-with mold --no-fork --strip-debug&#039; -n wild-0.4.0-no-fork &#039;./run-with wild --no-fork --strip-debug&#039; -n mold-2.36 &#039;./run-with mold --strip-debug&#039; -n wild-0.4.0 &#039;./run-with wild --strip-debug&#039;
temp: +40.0¬∞C
Benchmark 1: lld-18
  Time (mean ¬± œÉ):     514.1 ms ¬±   5.1 ms    [User: 1000.1 ms, System: 451.9 ms]
  Range (min ‚Ä¶ max):   507.1 ms ‚Ä¶ 523.4 ms    10 runs
 
Benchmark 2: mold-2.36-no-fork
  Time (mean ¬± œÉ):     388.5 ms ¬±   5.3 ms    [User: 1986.9 ms, System: 436.2 ms]
  Range (min ‚Ä¶ max):   379.0 ms ‚Ä¶ 396.8 ms    10 runs
 
Benchmark 3: wild-0.4.0-no-fork
  Time (mean ¬± œÉ):     244.4 ms ¬±   3.2 ms    [User: 1087.5 ms, System: 313.0 ms]
  Range (min ‚Ä¶ max):   240.3 ms ‚Ä¶ 251.7 ms    12 runs
 
Benchmark 4: mold-2.36
  Time (mean ¬± œÉ):     365.7 ms ¬±   8.5 ms    [User: 9.4 ms, System: 3.1 ms]
  Range (min ‚Ä¶ max):   358.1 ms ‚Ä¶ 384.9 ms    10 runs
 
Benchmark 5: wild-0.4.0
  Time (mean ¬± œÉ):     220.5 ms ¬±   3.4 ms    [User: 2.6 ms, System: 2.0 ms]
  Range (min ‚Ä¶ max):   214.1 ms ‚Ä¶ 226.1 ms    13 runs
 
Summary
  &#039;wild-0.4.0&#039; ran
    1.11 ¬± 0.02 times faster than &#039;wild-0.4.0-no-fork&#039;
    1.66 ¬± 0.05 times faster than &#039;mold-2.36&#039;
    1.76 ¬± 0.04 times faster than &#039;mold-2.36-no-fork&#039;
    2.33 ¬± 0.04 times faster than &#039;lld-18&#039;
Throttle pkg: 0 core: 0 ms: 0 temp: +59.0¬∞C
```

Note, the user and system CPU times for mold and wild when run with default flags are meaningless,
since these linkers fork by default and hyperfine doesn&#039;t see the CPU usage of the forked
subprocess. For accurate CPU usage, see the no-fork variants. For later benchmarks, we always
include `--no-fork` for these linkers. This makes each of these linkers slower by about 10%.

GNU ld is excluded from the benchmarks because its speed is so totally different to the other
linkers that it makes it hard to compare. But for reference, here is the time for GNU ld for this
benchmark:

```
Benchmark 1: GNU-ld-2.38
  Time (mean ¬± œÉ):      8.414 s ¬±  0.323 s    [User: 7.291 s, System: 1.121 s]
  Range (min ‚Ä¶ max):    7.601 s ‚Ä¶  8.668 s    10 runs
```

Now with debug info:

```
‚ùØ OUT=/home/david/ttt throttle-count hyperfine --warmup 1 -N -n lld-18 &#039;./run-with ld.lld&#039; -n mold-2.36 &#039;./run-with mold --no-fork&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork&#039;
temp: +42.0¬∞C
Benchmark 1: lld-18
  Time (mean ¬± œÉ):     11.350 s ¬±  0.209 s    [User: 70.592 s, System: 6.677 s]
  Range (min ‚Ä¶ max):   11.085 s ‚Ä¶ 11.621 s    10 runs
 
Benchmark 2: mold-2.36
  Time (mean ¬± œÉ):     11.826 s ¬±  0.607 s    [User: 73.569 s, System: 5.435 s]
  Range (min ‚Ä¶ max):   11.130 s ‚Ä¶ 12.721 s    10 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ¬± œÉ):      8.800 s ¬±  0.197 s    [User: 49.397 s, System: 8.273 s]
  Range (min ‚Ä¶ max):    8.588 s ‚Ä¶  9.136 s    10 runs
 
Summary
  &#039;wild-0.4.0&#039; ran
    1.29 ¬± 0.04 times faster than &#039;lld-18&#039;
    1.34 ¬± 0.08 times faster than &#039;mold-2.36&#039;
Throttle pkg: 18454 core: 5916 ms: 328 temp: +77.0¬∞C
```

Note, despite setting my fans to maximum before the start of the benchmark, I did get some thermal
throttling in this run. However, the standard deviations look pretty tight, so I don&#039;t think it
really invalidated the results.

The big takeaway from this benchmark is that debug info can make your link times really slow, so if
you don&#039;t need it, turn it off. If you do need it, try to use split debug info or unpacked debug
info. The situation with debug info is especially bad for C++ codebases like clang, probably due to
header files causing lots of the same information to be repeated.

### Linking rustc-driver.so on x86-64

Without debug info:

```
‚ùØ OUT=/home/david/ttt throttle-count hyperfine --warmup 1 -N -n lld-18 &#039;./run-with ld.lld --strip-debug&#039; -n mold-2.36 &#039;./run-with mold --no-fork --strip-debug&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork --strip-debug&#039;
temp: +47.0¬∞C
Benchmark 1: lld-18
  Time (mean ¬± œÉ):      1.485 s ¬±  0.009 s    [User: 2.247 s, System: 0.771 s]
  Range (min ‚Ä¶ max):    1.471 s ‚Ä¶  1.499 s    10 runs
 
Benchmark 2: mold-2.36
  Time (mean ¬± œÉ):     819.9 ms ¬±   6.6 ms    [User: 3815.0 ms, System: 715.4 ms]
  Range (min ‚Ä¶ max):   810.3 ms ‚Ä¶ 829.3 ms    10 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ¬± œÉ):     476.6 ms ¬±  46.6 ms    [User: 2080.9 ms, System: 514.6 ms]
  Range (min ‚Ä¶ max):   436.7 ms ‚Ä¶ 553.7 ms    10 runs
 
Summary
  &#039;wild-0.4.0&#039; ran
    1.72 ¬± 0.17 times faster than &#039;mold-2.36&#039;
    3.12 ¬± 0.31 times faster than &#039;lld-18&#039;
Throttle pkg: 0 core: 0 ms: 0 temp: +62.0¬∞C
```

With debug info:

```
‚ùØ OUT=/home/david/ttt throttle-count hyperfine --warmup 1 -N -n lld-18 &#039;./run-with ld.lld&#039; -n mold-2.36 &#039;./run-with mold --no-fork&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork&#039;
temp: +47.0¬∞C
Benchmark 1: lld-18
  Time (mean ¬± œÉ):      1.663 s ¬±  0.022 s    [User: 3.244 s, System: 1.024 s]
  Range (min ‚Ä¶ max):    1.633 s ‚Ä¶  1.710 s    10 runs
 
Benchmark 2: mold-2.36
  Time (mean ¬± œÉ):      1.120 s ¬±  0.016 s    [User: 5.126 s, System: 1.005 s]
  Range (min ‚Ä¶ max):    1.101 s ‚Ä¶  1.149 s    10 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ¬± œÉ):     646.3 ms ¬±  10.0 ms    [User: 3016.3 ms, System: 807.9 ms]
  Range (min ‚Ä¶ max):   626.0 ms ‚Ä¶ 657.5 ms    10 runs
 
Summary
  &#039;wild-0.4.0&#039; ran
    1.73 ¬± 0.04 times faster than &#039;mold-2.36&#039;
    2.57 ¬± 0.05 times faster than &#039;lld-18&#039;
Throttle pkg: 0 core: 0 ms: 0 temp: +62.0¬∞C
```

### Linking clang on aarch64 (Raspberry Pi 5)

```
OUT=/run/user/1000/ttt hyperfine --warmup 2 -n lld-19 &#039;./run-with ld.lld-19 --strip-debug&#039; -n mold-2.36 &#039;./run-with mold --no-fork --strip-debug&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork --strip-debug&#039;
Benchmark 1: lld-19
  Time (mean ¬± œÉ):      1.170 s ¬±  0.005 s    [User: 2.046 s, System: 0.233 s]
  Range (min ‚Ä¶ max):    1.165 s ‚Ä¶  1.177 s    10 runs
 
Benchmark 2: mold-2.36
  Time (mean ¬± œÉ):     919.3 ms ¬±   2.7 ms    [User: 3120.7 ms, System: 304.4 ms]
  Range (min ‚Ä¶ max):   915.5 ms ‚Ä¶ 923.7 ms    10 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ¬± œÉ):     423.1 ms ¬±   5.5 ms    [User: 1352.9 ms, System: 147.1 ms]
  Range (min ‚Ä¶ max):   419.1 ms ‚Ä¶ 438.0 ms    10 runs
 
Summary
  wild-0.4.0 ran
    2.17 ¬± 0.03 times faster than mold-2.36
    2.76 ¬± 0.04 times faster than lld-19
```

### Linking wild on aarch64 (Raspberry Pi 5)

Without debug info:

```
OUT=/run/user/1000/ttt hyperfine -N --warmup 2 -n lld-19 &#039;./run-with ld.lld-19 --strip-debug&#039; -n mold-2.36 &#039;./run-with mold --no-fork --strip-debug&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork --strip-debug&#039;
Benchmark 1: lld-19
  Time (mean ¬± œÉ):     225.7 ms ¬±   2.6 ms    [User: 321.5 ms, System: 52.5 ms]
  Range (min ‚Ä¶ max):   222.8 ms ‚Ä¶ 232.7 ms    13 runs
 
Benchmark 2: mold-2.36
  Time (mean ¬± œÉ):     152.2 ms ¬±   0.7 ms    [User: 496.0 ms, System: 46.8 ms]
  Range (min ‚Ä¶ max):   150.5 ms ‚Ä¶ 153.5 ms    19 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ¬± œÉ):      78.3 ms ¬±   0.8 ms    [User: 227.9 ms, System: 30.6 ms]
  Range (min ‚Ä¶ max):    76.9 ms ‚Ä¶  80.3 ms    38 runs
 
Summary
  wild-0.4.0 ran
    1.94 ¬± 0.02 times faster than mold-2.36
    2.88 ¬± 0.04 times faster than lld-19
```

With debug info:

```
OUT=/run/user/1000/ttt hyperfine --warmup 2 -n lld-19 &#039;./run-with ld.lld-19&#039; -n mold-2.36 &#039;./run-with mold --no-fork&#039; -n wild-0.4.0 &#039;./run-with wild --no-fork&#039;
Benchmark 1: lld-19
  Time (mean ¬± œÉ):     325.0 ms ¬±   4.5 ms    [User: 664.0 ms, System: 66.3 ms]
  Range (min ‚Ä¶ max):   319.2 ms ‚Ä¶ 333.7 ms    10 runs
 
Benchmark 2: mold-2.36
  Time (mean ¬± œÉ):     262.3 ms ¬±   2.7 ms    [User: 890.9 ms, System: 75.3 ms]
  Range (min ‚Ä¶ max):   259.1 ms ‚Ä¶ 269.6 ms    11 runs
 
Benchmark 3: wild-0.4.0
  Time (mean ¬± œÉ):     183.2 ms ¬±   3.1 ms    [User: 588.5 ms, System: 64.5 ms]
  Range (min ‚Ä¶ max):   179.8 ms ‚Ä¶ 192.3 ms    16 runs
 
Summary
  wild-0.4.0 ran
    1.43 ¬± 0.03 times faster than mold-2.36
    1.77 ¬± 0.04 times faster than lld-19
```

## Linking Rust code

The following is a `cargo test` command-line that can be used to build and test a crate using Wild.
This has been run successfully on a few popular crates (e.g. ripgrep, serde, tokio, rand, bitflags).
It assumes that the &quot;wild&quot; binary is on your path. It also depends on the Clang compiler being
installed, since GCC doesn&#039;t allow using an arbitrary linker.

```sh
RUSTFLAGS=&quot;-Clinker=clang -Clink-args=--ld-path=wild&quot; cargo test
```

## Contributing

For more information on contributing to `wild` see [CONTRIBUTING.md](CONTRIBUTING.md).

For a high-level overview of Wild&#039;s design, see [DESIGN.md](DESIGN.md).

## Chat server

We have a Zulip server for Wild-related chat. You can join
[here](https://wild.zulipchat.com/join/bbopdeg6howwjpaiyowngyde/).

## Further reading

Many of the posts on [David&#039;s blog](https://davidlattimore.github.io/) are about various aspects of
the Wild linker.

## Sponsorship

If you&#039;d like to [sponsor this work](https://github.com/sponsors/davidlattimore), that would be very
much appreciated. The more sponsorship I get the longer I can continue to work on this project full
time.

## License

Licensed under either of [Apache License, Version 2.0](LICENSE-APACHE) or [MIT license](LICENSE-MIT)
at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in
Wild by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any
additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[paradigmxyz/reth]]></title>
            <link>https://github.com/paradigmxyz/reth</link>
            <guid>https://github.com/paradigmxyz/reth</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol, in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paradigmxyz/reth">paradigmxyz/reth</a></h1>
            <p>Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol, in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 5,012</p>
            <p>Forks: 1,891</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># reth

[![bench status](https://github.com/paradigmxyz/reth/actions/workflows/bench.yml/badge.svg)](https://github.com/paradigmxyz/reth/actions/workflows/bench.yml)
[![CI status](https://github.com/paradigmxyz/reth/workflows/unit/badge.svg)][gh-ci]
[![cargo-lint status](https://github.com/paradigmxyz/reth/actions/workflows/lint.yml/badge.svg)][gh-lint]
[![Telegram Chat][tg-badge]][tg-url]

**Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol**

![](./assets/reth-prod.png)

**[Install](https://paradigmxyz.github.io/reth/installation/installation.html)**
| [User Docs](https://reth.rs)
| [Developer Docs](./docs)
| [Crate Docs](https://reth.rs/docs)

[gh-ci]: https://github.com/paradigmxyz/reth/actions/workflows/unit.yml
[gh-lint]: https://github.com/paradigmxyz/reth/actions/workflows/lint.yml
[tg-badge]: https://img.shields.io/endpoint?color=neon&amp;logo=telegram&amp;label=chat&amp;url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Fparadigm%5Freth

## What is Reth?

Reth (short for Rust Ethereum, [pronunciation](https://twitter.com/kelvinfichter/status/1597653609411268608)) is a new Ethereum full node implementation that is focused on being user-friendly, highly modular, as well as being fast and efficient. Reth is an Execution Layer (EL) and is compatible with all Ethereum Consensus Layer (CL) implementations that support the [Engine API](https://github.com/ethereum/execution-apis/tree/a0d03086564ab1838b462befbc083f873dcf0c0f/src/engine). It is originally built and driven forward by [Paradigm](https://paradigm.xyz/), and is licensed under the Apache and MIT licenses.

## Goals

As a full Ethereum node, Reth allows users to connect to the Ethereum network and interact with the Ethereum blockchain. This includes sending and receiving transactions/logs/traces, as well as accessing and interacting with smart contracts. Building a successful Ethereum node requires creating a high-quality implementation that is both secure and efficient, as well as being easy to use on consumer hardware. It also requires building a strong community of contributors who can help support and improve the software.

More concretely, our goals are:

1. **Modularity**: Every component of Reth is built to be used as a library: well-tested, heavily documented and benchmarked. We envision that developers will import the node&#039;s crates, mix and match, and innovate on top of them. Examples of such usage include but are not limited to spinning up standalone P2P networks, talking directly to a node&#039;s database, or &quot;unbundling&quot; the node into the components you need. To achieve that, we are licensing Reth under the Apache/MIT permissive license. You can learn more about the project&#039;s components [here](./docs/repo/layout.md).
2. **Performance**: Reth aims to be fast, so we use Rust and the [Erigon staged-sync](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) node architecture. We also use our Ethereum libraries (including [Alloy](https://github.com/alloy-rs/alloy/) and [revm](https://github.com/bluealloy/revm/)) which we&#039;ve battle-tested and optimized via [Foundry](https://github.com/foundry-rs/foundry/).
3. **Free for anyone to use any way they want**: Reth is free open source software, built for the community, by the community. By licensing the software under the Apache/MIT license, we want developers to use it without being bound by business licenses, or having to think about the implications of GPL-like licenses.
4. **Client Diversity**: The Ethereum protocol becomes more antifragile when no node implementation dominates. This ensures that if there&#039;s a software bug, the network does not finalize a bad block. By building a new client, we hope to contribute to Ethereum&#039;s antifragility.
5. **Support as many EVM chains as possible**: We aspire that Reth can full-sync not only Ethereum, but also other chains like Optimism, Polygon, BNB Smart Chain, and more. If you&#039;re working on any of these projects, please reach out.
6. **Configurability**: We want to solve for node operators that care about fast historical queries, but also for hobbyists who cannot operate on large hardware. We also want to support teams and individuals who want both sync from genesis and via &quot;fast sync&quot;. We envision that Reth will be configurable enough and provide configurable &quot;profiles&quot; for the tradeoffs that each team faces.

## Status

Reth is production ready, and suitable for usage in mission-critical environments such as staking or high-uptime services. We also actively recommend professional node operators to switch to Reth in production for performance and cost reasons in use cases where high performance with great margins is required such as RPC, MEV, Indexing, Simulations, and P2P activities.

More historical context below:

-   We released 1.0 &quot;production-ready&quot; stable Reth in June 2024.
    -   Reth completed an audit with [Sigma Prime](https://sigmaprime.io/), the developers of [Lighthouse](https://github.com/sigp/lighthouse), the Rust Consensus Layer implementation. Find it [here](./audit/sigma_prime_audit_v2.pdf).
    -   Revm (the EVM used in Reth) underwent an audit with [Guido Vranken](https://twitter.com/guidovranken) (#1 [Ethereum Bug Bounty](https://ethereum.org/en/bug-bounty)). We will publish the results soon.
-   We released multiple iterative beta versions, up to [beta.9](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.9) on Monday June 3, 2024,the last beta release.
-   We released [beta](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) on Monday March 4, 2024, our first breaking change to the database model, providing faster query speed, smaller database footprint, and allowing &quot;history&quot; to be mounted on separate drives.
-   We shipped iterative improvements until the last alpha release on February 28, 2024, [0.1.0-alpha.21](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.21).
-   We [initially announced](https://www.paradigm.xyz/2023/06/reth-alpha) [0.1.0-alpha.1](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.1) on June 20, 2023.

### Database compatibility

We do not have any breaking database changes since beta.1, and we do not plan any in the near future.

Reth [v0.2.0-beta.1](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) includes
a [set of breaking database changes](https://github.com/paradigmxyz/reth/pull/5191) that makes it impossible to use database files produced by earlier versions.

If you had a database produced by alpha versions of Reth, you need to drop it with `reth db drop`
(using the same arguments such as `--config` or `--datadir` that you passed to `reth node`), and resync using the same `reth node` command you&#039;ve used before.

## For Users

See the [Reth documentation](https://paradigmxyz.github.io/reth) for instructions on how to install and run Reth.

## For Developers

### Using reth as a library

You can use individual crates of reth in your project.

The crate docs can be found [here](https://paradigmxyz.github.io/reth/docs).

For a general overview of the crates, see [Project Layout](./docs/repo/layout.md).

### Contributing

If you want to contribute, or follow along with contributor discussion, you can use our [main telegram](https://t.me/paradigm_reth) to chat with us about the development of Reth!

-   Our contributor guidelines can be found in [`CONTRIBUTING.md`](./CONTRIBUTING.md).
-   See our [contributor docs](./docs) for more information on the project. A good starting point is [Project Layout](./docs/repo/layout.md).

### Building and testing

&lt;!--
When updating this, also update:
- Cargo.toml
- .github/workflows/lint.yml
--&gt;

The Minimum Supported Rust Version (MSRV) of this project is [1.88.0](https://blog.rust-lang.org/2025/06/26/Rust-1.88.0/).

See the docs for detailed instructions on how to [build from source](https://paradigmxyz.github.io/reth/installation/source).

To fully test Reth, you will need to have [Geth installed](https://geth.ethereum.org/docs/getting-started/installing-geth), but it is possible to run a subset of tests without Geth.

First, clone the repository:

```sh
git clone https://github.com/paradigmxyz/reth
cd reth
```

Next, run the tests:

```sh
cargo nextest run --workspace

# Run the Ethereum Foundation tests
make ef-tests
```

We highly recommend using [`cargo nextest`](https://nexte.st/) to speed up testing.
Using `cargo test` to run tests may work fine, but this is not tested and does not support more advanced features like retries for spurious failures.

&gt; **Note**
&gt;
&gt; Some tests use random number generators to generate test data. If you want to use a deterministic seed, you can set the `SEED` environment variable.

## Getting Help

If you have any questions, first see if the answer to your question can be found in the [docs][book].

If the answer is not there:

-   Join the [Telegram][tg-url] to get help, or
-   Open a [discussion](https://github.com/paradigmxyz/reth/discussions/new) with your question, or
-   Open an issue with [the bug](https://github.com/paradigmxyz/reth/issues/new?assignees=&amp;labels=C-bug%2CS-needs-triage&amp;projects=&amp;template=bug.yml)

## Security

See [`SECURITY.md`](./SECURITY.md).

## Acknowledgements

Reth is a new implementation of the Ethereum protocol. In the process of developing the node we investigated the design decisions other nodes have made to understand what is done well, what is not, and where we can improve the status quo.

None of this would have been possible without them, so big shoutout to the teams below:

-   [Geth](https://github.com/ethereum/go-ethereum/): We would like to express our heartfelt gratitude to the go-ethereum team for their outstanding contributions to Ethereum over the years. Their tireless efforts and dedication have helped to shape the Ethereum ecosystem and make it the vibrant and innovative community it is today. Thank you for your hard work and commitment to the project.
-   [Erigon](https://github.com/ledgerwatch/erigon) (fka Turbo-Geth): Erigon pioneered the [&quot;Staged Sync&quot; architecture](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) that Reth is using, as well as [introduced MDBX](https://github.com/ledgerwatch/erigon/wiki/Choice-of-storage-engine) as the database of choice. We thank Erigon for pushing the state of the art research on the performance limits of Ethereum nodes.
-   [Akula](https://github.com/akula-bft/akula/): Reth uses forks of the Apache versions of Akula&#039;s [MDBX Bindings](https://github.com/paradigmxyz/reth/pull/132), [FastRLP](https://github.com/paradigmxyz/reth/pull/63) and [ECIES](https://github.com/paradigmxyz/reth/pull/80). Given that these packages were already released under the Apache License, and they implement standardized solutions, we decided not to reimplement them to iterate faster. We thank the Akula team for their contributions to the Rust Ethereum ecosystem and for publishing these packages.

## Warning

The `NippyJar` and `Compact` encoding formats and their implementations are designed for storing and retrieving data internally. They are not hardened to safely read potentially malicious data.

[book]: https://paradigmxyz.github.io/reth/
[tg-url]: https://t.me/paradigm_reth
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[clockworklabs/SpacetimeDB]]></title>
            <link>https://github.com/clockworklabs/SpacetimeDB</link>
            <guid>https://github.com/clockworklabs/SpacetimeDB</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[Multiplayer at the speed of light]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/clockworklabs/SpacetimeDB">clockworklabs/SpacetimeDB</a></h1>
            <p>Multiplayer at the speed of light</p>
            <p>Language: Rust</p>
            <p>Stars: 17,518</p>
            <p>Forks: 605</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
	&lt;img width=&quot;320&quot; src=&quot;./images/dark/logo.svg&quot; alt=&quot;SpacetimeDB Logo&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
	&lt;img width=&quot;320&quot; src=&quot;./images/light/logo.svg&quot; alt=&quot;SpacetimeDB Logo&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
        &lt;img width=&quot;250&quot; src=&quot;./images/dark/logo-text.svg&quot; alt=&quot;SpacetimeDB&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
        &lt;img width=&quot;250&quot; src=&quot;./images/light/logo-text.svg&quot; alt=&quot;SpacetimeDB&quot;&gt;
    &lt;/a&gt;
    &lt;h3 align=&quot;center&quot;&gt;
        Multiplayer at the speed of light.
    &lt;/h3&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/clockworklabs/spacetimedb?color=%23ff00a0&amp;include_prereleases&amp;label=version&amp;sort=semver&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/built_with-Rust-dca282.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
	&lt;a href=&quot;https://github.com/clockworklabs/spacetimedb/actions&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/clockworklabs/spacetimedb/ci.yml?style=flat-square&amp;branch=master&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://status.spacetimedb.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/uptimerobot/ratio/7/m784409192-e472ca350bb615372ededed7?label=cloud%20uptime&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://hub.docker.com/r/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/clockworklabs/spacetimedb?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb/blob/master/LICENSE.txt&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-BSL_1.1-00bfff.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://crates.io/crates/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/d/spacetimedb?color=e45928&amp;label=Rust%20Crate&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.nuget.org/packages/SpacetimeDB.Runtime&quot;&gt;&lt;img src=&quot;https://img.shields.io/nuget/dt/spacetimedb.runtime?color=0b6cff&amp;label=NuGet%20Package&amp;style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://discord.gg/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1037340874172014652?label=discord&amp;style=flat-square&amp;color=5a66f6&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitter.com/spacetime_db&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/twitter-Follow_us-1d9bf0.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://clockworklabs.io/join&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/careers-Join_us-86f7b7.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/clockworklabs/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/linkedin-Connect_with_us-0a66c2.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://discord.gg/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/discord.svg&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitter.com/spacetime_db&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/twitter.svg&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/github.svg&quot; alt=&quot;GitHub&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitch.tv/SpacetimeDB&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/twitch.svg&quot; alt=&quot;Twitch&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://youtube.com/@SpacetimeDB&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/youtube.svg&quot; alt=&quot;YouTube&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/clockwork-labs/&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/linkedin.svg&quot; alt=&quot;LinkedIn&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://stackoverflow.com/questions/tagged/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/stackoverflow.svg&quot; alt=&quot;StackOverflow&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

## What is [SpacetimeDB](https://spacetimedb.com)?

You can think of SpacetimeDB as both a database and server combined into one.

It is a relational database system that lets you upload your application logic directly into the database by way of fancy stored procedures called &quot;modules.&quot;

Instead of deploying a web or game server that sits in between your clients and your database, your clients connect directly to the database and execute your application logic inside the database itself. You can write all of your permission and authorization logic right inside your module just as you would in a normal server.

This means that you can write your entire application in a single language, Rust, and deploy it as a single binary. No more microservices, no more containers, no more Kubernetes, no more Docker, no more VMs, no more DevOps, no more infrastructure, no more ops, no more servers.

&lt;figure&gt;
    &lt;img src=&quot;./images/basic-architecture-diagram.png&quot; alt=&quot;SpacetimeDB Architecture&quot; style=&quot;width:100%&quot;&gt;
    &lt;figcaption align=&quot;center&quot;&gt;
        &lt;p align=&quot;center&quot;&gt;&lt;b&gt;SpacetimeDB application architecture&lt;/b&gt;&lt;br /&gt;&lt;sup&gt;&lt;sub&gt;(elements in white are provided by SpacetimeDB)&lt;/sub&gt;&lt;/sup&gt;&lt;/p&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;

It&#039;s actually similar to the idea of smart contracts, except that SpacetimeDB is a database, has nothing to do with blockchain, and is orders of magnitude faster than any smart contract system.

So fast, in fact, that the entire backend of our MMORPG [BitCraft Online](https://bitcraftonline.com) is just a SpacetimeDB module. We don&#039;t have any other servers or services running, which means that everything in the game, all of the chat messages, items, resources, terrain, and even the locations of the players are stored and processed by the database before being synchronized out to all of the clients in real-time.

SpacetimeDB is optimized for maximum speed and minimum latency rather than batch processing or OLAP workloads. It is designed to be used for real-time applications like games, chat, and collaboration tools.

This speed and latency is achieved by holding all of application state in memory, while persisting the data in a write-ahead-log (WAL) which is used to recover application state.

## Installation

You can run SpacetimeDB as a standalone database server via the `spacetime` CLI tool.
Install instructions for supported platforms are outlined below.
The same install instructions can be found on our website at https://spacetimedb.com/install.

#### Install on macOS

Installing on macOS is as simple as running our install script. After that you can use the spacetime command to manage versions.

```bash
curl -sSf https://install.spacetimedb.com | sh
```

#### Install on Linux

Installing on Linux is as simple as running our install script. After that you can use the spacetime command to manage versions.

```bash
curl -sSf https://install.spacetimedb.com | sh
```

#### Install on Windows

Installing on Windows is as simple as pasting the above snippet into PowerShell. If you would like to use WSL instead, please follow the Linux install instructions.

```ps1
iwr https://windows.spacetimedb.com -useb | iex
```

#### Installing from Source

A quick note on installing from source: we recommend that you don&#039;t install from source unless there is a feature that is available in `master` that hasn&#039;t been released yet, otherwise follow the official installation instructions.

##### MacOS + Linux

Installing on macOS + Linux is pretty straightforward. First we are going to build all of the binaries that we need:

```bash
# Install rustup, you can skip this step if you have cargo and the wasm32-unknown-unknown target already installed.
curl https://sh.rustup.rs -sSf | sh
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
mkdir -p ~/.local/bin
export STDB_VERSION=&quot;$(./target/release/spacetimedb-cli --version | sed -n &#039;s/.*spacetimedb tool version \([0-9.]*\);.*/\1/p&#039;)&quot;
mkdir -p ~/.local/share/spacetime/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/.local/bin/spacetime
cp target/release/spacetimedb-cli ~/.local/share/spacetime/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/.local/share/spacetime/bin/$STDB_VERSION
```

At this stage you&#039;ll need to add ~/.local/bin to your path if you haven&#039;t already.

```
# Please add the following line to your shell configuration and open a new shell session:
export PATH=&quot;$HOME/.local/bin:$PATH&quot;

```

Then finally set your SpacetimeDB version:
```

# Then, in a new shell, set the current version:
spacetime version use $STDB_VERSION

# If STDB_VERSION is not set anymore then you can use the following command to list your versions:
spacetime version list
```

You can verify that the correct version has been installed via `spacetime --version`.

##### Windows

Building on windows is a bit more complicated. You&#039;ll need a slightly different version of perl compared to what comes pre-bundled in most Windows terminals. We recommend [Strawberry Perl](https://strawberryperl.com/). You may also need access to an `openssl` binary which actually comes pre-installed with [Git for Windows](https://git-scm.com/downloads/win). Also, you&#039;ll need to install [rustup](https://rustup.rs/) for Windows.

In a Git for Windows shell you should have something that looks like this:
```
$ which perl
/c/Strawberry/perl/bin/perl
$ which openssl
/mingw64/bin/openssl
$ which cargo 
/c/Users/&lt;user&gt;/.cargo/bin/cargo
```

If that looks correct then you&#039;re ready to proceed!

```powershell
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB

# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
$stdbDir = &quot;$HOME\AppData\Local\SpacetimeDB&quot;
$stdbVersion = &amp; &quot;.\target\release\spacetimedb-cli&quot; --version | Select-String -Pattern &#039;spacetimedb tool version ([0-9.]+);&#039; | ForEach-Object { $_.Matches.Groups[1].Value }
New-Item -ItemType Directory -Path &quot;$stdbDir\bin\$stdbVersion&quot; -Force | Out-Null

# Install the update binary
Copy-Item &quot;target\release\spacetimedb-update.exe&quot; &quot;$stdbDir\spacetime.exe&quot;
Copy-Item &quot;target\release\spacetimedb-cli.exe&quot; &quot;$stdbDir\bin\$stdbVersion\&quot;
Copy-Item &quot;target\release\spacetimedb-standalone.exe&quot; &quot;$stdbDir\bin\$stdbVersion\&quot;

```

Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!

```
%USERPROFILE%\AppData\Local\SpacetimeDB
```

Then finally, open a new shell and use the installed SpacetimeDB version:
```
spacetime version use $stdbVersion

# If stdbVersion is no longer set, list versions using the following command:
spacetime version list
```

You can verify that the correct version has been installed via `spacetime --version`.

If you&#039;re using Git for Windows you can follow these instructions instead:

```bash
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
# Build the CLI binaries - this takes a while on windows so go grab a coffee :)
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
export STDB_VERSION=&quot;$(./target/release/spacetimedb-cli --version | sed -n &#039;s/.*spacetimedb tool version \([0-9.]*\);.*/\1/p&#039;)&quot;
mkdir -p ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/AppData/Local/SpacetimeDB/spacetime
cp target/release/spacetimedb-cli ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!
# %USERPROFILE%\AppData\Local\SpacetimeDB

# Set the current version
spacetime version use $STDB_VERSION
```

You can verify that the correct version has been installed via `spacetime --version`.

#### Running with Docker

If you prefer to run Spacetime in a container, you can use the following command to start a new instance.

```bash
docker run --rm --pull always -p 3000:3000 clockworklabs/spacetime start
```

## Documentation

For more information about SpacetimeDB, getting started guides, game development guides, and reference material please see our [documentation](https://spacetimedb.com/docs).

## Getting Started

We&#039;ve prepared several getting started guides in each of our supported languages to help you get up and running with SpacetimeDB as quickly as possible. You can find them on our [docs page](https://spacetimedb.com/docs).

In summary there are only 4 steps to getting started with SpacetimeDB.

1. Install the `spacetime` CLI tool.
2. Start a SpacetimeDB standalone node with `spacetime start`.
3. Write and upload a module in one of our supported module languages.
4. Connect to the database with one of our client libraries.

You can see a summary of the supported languages below with a link to the getting started guide for each.

## Language Support

You can write SpacetimeDB modules in several popular languages, with more to come in the future!

#### Serverside Libraries

- [Rust](https://spacetimedb.com/docs/modules/rust/quickstart)
- [C#](https://spacetimedb.com/docs/modules/c-sharp/quickstart)

#### Client Libraries

- [Rust](https://spacetimedb.com/docs/sdks/rust/quickstart)
- [C#](https://spacetimedb.com/docs/sdks/c-sharp/quickstart)
- [Typescript](https://spacetimedb.com/docs/sdks/typescript/quickstart)

## License

SpacetimeDB is licensed under the BSL 1.1 license. This is not an open source or free software license, however, it converts to the AGPL v3.0 license with a linking exception after a few years.

Note that the AGPL v3.0 does not typically include a linking exception. We have added a custom linking exception to the AGPL license for SpacetimeDB. Our motivation for choosing a free software license is to ensure that contributions made to SpacetimeDB are propagated back to the community. We are expressly not interested in forcing users of SpacetimeDB to open source their own code if they link with SpacetimeDB, so we needed to include a linking exception.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[aptos-labs/aptos-core]]></title>
            <link>https://github.com/aptos-labs/aptos-core</link>
            <guid>https://github.com/aptos-labs/aptos-core</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[Aptos is a layer 1 blockchain built to support the widespread use of blockchain through better technology and user experience.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aptos-labs/aptos-core">aptos-labs/aptos-core</a></h1>
            <p>Aptos is a layer 1 blockchain built to support the widespread use of blockchain through better technology and user experience.</p>
            <p>Language: Rust</p>
            <p>Stars: 6,366</p>
            <p>Forks: 3,836</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://aptos.dev&quot;&gt;
	&lt;img width=&quot;100%&quot; src=&quot;./.assets/aptos_banner.png&quot; alt=&quot;Aptos Banner&quot; /&gt;
&lt;/a&gt;

---

[![License](https://img.shields.io/badge/license-Apache-green.svg)](LICENSE)
[![Lint+Test](https://github.com/aptos-labs/aptos-core/actions/workflows/lint-test.yaml/badge.svg)](https://github.com/aptos-labs/aptos-core/actions/workflows/lint-test.yaml)
[![codecov](https://codecov.io/gh/aptos-labs/aptos-core/branch/main/graph/badge.svg?token=X01RKXSGDE)](https://codecov.io/gh/aptos-labs/aptos-core)
[![Discord chat](https://img.shields.io/discord/945856774056083548?style=flat-square)](https://discord.gg/aptosnetwork)

Aptos is a layer 1 blockchain bringing a paradigm shift to Web3 through better technology and user experience. Built with Move to create a home for developers building next-gen applications.

## Getting Started

* [Aptos Foundation](https://aptosfoundation.org/)
* [Aptos Developer Network](https://aptos.dev)
* [Guide - Integrate with the Aptos Blockchain](https://aptos.dev/guides/system-integrators-guide)
* [Tutorials](https://aptos.dev/tutorials)
* Follow us on [Twitter](https://twitter.com/Aptos).
* Join us on the [Aptos Discord](https://discord.gg/aptosnetwork).

## Contributing

You can learn more about contributing to the Aptos project by reading our [Contribution Guide](https://github.com/aptos-labs/aptos-core/blob/main/CONTRIBUTING.md) and by viewing our [Code of Conduct](https://github.com/aptos-labs/aptos-core/blob/main/CODE_OF_CONDUCT.md).

Aptos Core is licensed under [Apache 2.0](https://github.com/aptos-labs/aptos-core/blob/main/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zama-ai/fhevm]]></title>
            <link>https://github.com/zama-ai/fhevm</link>
            <guid>https://github.com/zama-ai/fhevm</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zama-ai/fhevm">zama-ai/fhevm</a></h1>
            <p>FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications</p>
            <p>Language: Rust</p>
            <p>Stars: 20,857</p>
            <p>Forks: 899</p>
            <p>Stars today: 151 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/.gitbook/assets/fhevm-header-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/.gitbook/assets/fhevm-header-light.png&quot;&gt;
  &lt;img width=500 alt=&quot;fhevm&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;

&lt;hr/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;fhevm-whitepaper.pdf&quot;&gt; üìÉ Read white paper&lt;/a&gt; |&lt;a href=&quot;https://docs.zama.ai/protocol&quot;&gt; üìí Documentation&lt;/a&gt; | &lt;a href=&quot;https://zama.ai/community&quot;&gt; üíõ Community support&lt;/a&gt; | &lt;a href=&quot;https://github.com/zama-ai/awesome-zama&quot;&gt; üìö FHE resources by Zama&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/zama-ai/fhevm/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/zama-ai/fhevm?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/zama-ai/fhevm/blob/main/LICENSE&quot;&gt;
    &lt;!-- markdown-link-check-disable-next-line --&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-BSD--3--Clause--Clear-%23ffb243?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/zama-ai/bounty-program&quot;&gt;
    &lt;!-- markdown-link-check-disable-next-line --&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Contribute-Zama%20Bounty%20Program-%23ffd208?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://slsa.dev&quot;&gt;&lt;img alt=&quot;SLSA 3&quot; src=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;


## About

### What is FHEVM?

**FHEVM** is the core framework of the *Zama Confidential Blockchain Protocol*. It enables confidential smart contracts on EVM-compatible blockchains by leveraging Fully Homomorphic Encryption (FHE), allowing encrypted data to be processed directly onchain.

FHEVM ensures both confidentiality and composability, with the following guarantees:
- **End-to-end encryption of transactions and state:** Data included in transactions is encrypted and never visible to anyone.
- **Composability and data availability on-chain:** States are updated while remaining encrypted at all times.
- **No impact on existing dApps and state:** Encrypted state co-exists alongside public one, and doesn&#039;t impact existing dApps.
&lt;br&gt;&lt;/br&gt;

### Table of contents

- [About](#about)
  - [What is FHEVM?](#what-is-fhevm)
  - [Project structure](#project-structure)
  - [Main features](#main-features)
  - [Use cases](#use-cases)
- [Resources](#resources)
- [Working with FHEVM](#working-with-fhevm)
  - [Citations](#citations)
  - [Contributing](#contributing)
  - [License](#license)
  - [FAQ](#faq)
- [Support](#support)
  &lt;br&gt;&lt;/br&gt;
### Project structure
The directories of this repository are organized in the following way:

###### FHEVM Contracts

- **`gateway-contracts/`**: Smart contracts managing the gateway between on-chain and off-chain components.

- **`host-contracts/`**: Smart Contracts deployed on the host chain for orchestrating FHE workflows.

###### FHEVM Compute Engines

- **`coprocessor/`**: Rust-based coprocessor implementation for FHE operations.

- **`kms-connector/`**: Interface for integrating with Key Management Services (KMS) to handle encryption keys securely.

###### FHEVM Utilities
- **`charts/`**: Helm charts and deployment configurations for the stack.

- **`golden-container-images/`**: Docker golden images for Node.js and Rust environments used as base images by the stack.

- **`test-suite/`**: Integration with docker-compose and tests covering end-to-end FHEVM stack behavior.



  &lt;br&gt;&lt;/br&gt;
### Main features

- **Privacy by design:** Building decentralized apps with full privacy and confidentiality on Ethereum, leveraging FHE.
- **Solidity integration:** Write FHEVM contracts like any standard Solidity contract using Solidity. Compatible with existing toolchains ‚Äî such as Hardhat and Foundry (*coming soon*).
- **Programmable privacy:**  Define exactly what data is encrypted and write the access control logic directly in your smart contracts.
- **High precision encrypted integers :** Up to 256 bits of precision for integers.
- **Full range of operators:** All typical operators are available: `+`, `-`, `*`, `/`, `&lt;`, `&gt;`, `==`, ternary-if, boolean operations‚Ä¶. Consecutive FHE operations are not limited.
- **Security:** The underlying FHE crypto-scheme of FHEVM is quantum-resistant. Decryption is managed via a key management system (KMS) using multi-party computation (MPC), ensuring security even if some parties are compromised or misbehaving.
- **Symbolic execution of FHE computations:** All FHE operations are executed symbolically on the host chain, significantly reducing execution time. The actual computations on encrypted data are offloaded asynchronously to our coprocessor, allowing for faster, efficient, and scalable processing.

_Learn more about FHEVM features in the [documentation](https://docs.zama.ai/protocol) and in our [whitepaper](https://github.com/zama-ai/fhevm/blob/main/fhevm-whitepaper.pdf)._
&lt;br&gt;&lt;/br&gt;

### Use cases

FHEVM is built for developers to write confidential smart contracts without the need to learn cryptography. Leveraging FHEVM, you can unlock a myriad of new use cases such as DeFi, gaming, and more. For instance:

- **Confidential transfers**: Keep balances and amounts private, without using mixers.
- **Tokenization**: Swap tokens and RWAs on-chain without others seeing the amounts.
- **Blind auctions**: Bid on items without revealing the amount or the winner.
- **On-chain games**: Keep moves, selections, cards, or items hidden until ready to reveal.
- **Confidential voting**: Prevents bribery and blackmailing by keeping votes private.
- **Encrypted DIDs**: Store identities on-chain and generate attestations without ZK.

_Learn more use cases in the [list of examples](https://docs.zama.ai/protocol/examples)._
&lt;br&gt;&lt;/br&gt;


## Resources
- [Documentation](https://docs.zama.ai/protocol) ‚Äî Official documentation of FHEVM.
- [Whitepaper](./fhevm-whitepaper.pdf) ‚Äî Technical overview of FHEVM&#039;s cryptographic design.
- [Examples](https://docs.zama.ai/protocol/examples) ‚Äî Examples of building confidential smart contracts.
- [Awesome Zama ‚Äì FHEVM](https://github.com/zama-ai/awesome-zama?tab=readme-ov-file#fhevm) ‚Äî Curated articles, talks, and ecosystem projects.

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#about&quot; &gt; ‚Üë Back to top &lt;/a&gt;
&lt;/p&gt;

## Working with FHEVM
### Citations

To cite FHEVM or the whitepaper in academic papers, please use the following entries:

```text
@Misc{FHEVM,
title={{FHEVM: A full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications},
author={Zama},
year={2025},
note={\url{https://github.com/zama-ai/fhevm}},
}
```

### Contributing

There are two ways to contribute to FHEVM:

- [Open issues](https://github.com/zama-ai/fhevm/issues/new/choose) to report bugs and typos, or to suggest new ideas
- Request to become an official contributor by emailing hello@zama.ai.

Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do!
&lt;br&gt;&lt;/br&gt;

### License

This software is distributed under the **BSD-3-Clause-Clear** license. Read [this](LICENSE) for more details.

### FAQ

**Is Zama‚Äôs technology free to use?**

&gt; Zama‚Äôs libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama&#039;s open source code, companies must purchase Zama‚Äôs commercial patent license.
&gt;
&gt; Everything we do is open source, and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in [this blog post](https://www.zama.ai/post/open-source).

**What do I need to do if I want to use Zama‚Äôs technology for commercial purposes?**

&gt; To commercially use Zama‚Äôs technology you need to be granted Zama‚Äôs patent license. Please contact us at hello@zama.ai for more information.

**Do you file IP on your technology?**

&gt; Yes, all Zama‚Äôs technologies are patented.

**Can you customize a solution for my specific use case?**

&gt; We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at hello@zama.ai.

## Support

&lt;a target=&quot;_blank&quot; href=&quot;https://community.zama.ai&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/.gitbook/assets/support-banner-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/.gitbook/assets/support-banner-light.png&quot;&gt;
  &lt;img alt=&quot;Support&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;

üåü If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development.

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#about&quot; &gt; ‚Üë Back to top &lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[juspay/hyperswitch]]></title>
            <link>https://github.com/juspay/hyperswitch</link>
            <guid>https://github.com/juspay/hyperswitch</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[An open source payments switch written in Rust to make payments fast, reliable and affordable]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/juspay/hyperswitch">juspay/hyperswitch</a></h1>
            <p>An open source payments switch written in Rust to make payments fast, reliable and affordable</p>
            <p>Language: Rust</p>
            <p>Stars: 34,167</p>
            <p>Forks: 4,211</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/imgs/hyperswitch-logo-dark.svg#gh-dark-mode-only&quot; alt=&quot;Hyperswitch-Logo&quot; width=&quot;40%&quot; /&gt;
  &lt;img src=&quot;./docs/imgs/hyperswitch-logo-light.svg#gh-light-mode-only&quot; alt=&quot;Hyperswitch-Logo&quot; width=&quot;40%&quot; /&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Composable Open-Source Payments Infrastructure&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/juspay/hyperswitch/main/docs/gifs/quickstart.gif&quot; alt=&quot;Quickstart demo&quot; /&gt;
&lt;/p&gt;


&lt;!-- @import &quot;[TOC]&quot; {cmd=&quot;toc&quot; depthFrom=1 depthTo=6 orderedList=false} --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/actions?query=workflow%3ACI+branch%3Amain&quot;&gt;
    &lt;img src=&quot;https://github.com/juspay/hyperswitch/workflows/CI-push/badge.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/juspay/hyperswitch&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Made_in-Rust-orange&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.linkedin.com/company/hyperswitch/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-hyperswitch-blue?logo=linkedin&amp;labelColor=grey&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://x.com/hyperswitchio&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-%40hyperswitchio-white?logo=x&amp;labelColor=grey&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://inviter.co/hyperswitch-slack&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/chat-on_slack-blue?logo=slack&amp;labelColor=grey&amp;color=%233f0e40&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;hr/&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;üìÅ Table of Contents&lt;/strong&gt;&lt;/summary&gt;

- [What Can I Do with Hyperswitch?](#-what-can-i-do-with-hyperswitch)
- [Quickstart (Local Setup)](#-quickstart-local-setup)
- [Cloud Deployment](#cloud-deployment)
- [Hosted Sandbox (No Setup Required)](#hosted-sandbox-no-setup-required)
- [Why Hyperswitch?](#-why-hyperswitch)
- [Architectural Overview](#architectural-overview)
- [Our Vision](#our-vision)
- [Community &amp; Contributions](#community--contributions)
- [Feature Requests &amp; Bugs](#feature-requests--bugs)
- [Versioning](#versioning)
- [License](#copyright-and-license)
- [Team Behind Hyperswitch](#team-behind-hyperswitch)

&lt;/details&gt;

&lt;summary&gt;&lt;h2&gt; What Can I Do with Hyperswitch?&lt;/h2&gt;&lt;/summary&gt;

Hyperswitch offers a modular, open-source payments infrastructure designed for flexibility and control. Apart from our Payment Suite offering, this solution allows businesses to pick and integrate only the modules they need on top of their existing payment stack ‚Äî without unnecessary complexity or vendor lock-in.

Each module is independent and purpose-built to optimize different aspects of payment processing.

&lt;h3&gt; Learn More About The Payment Modules &lt;/h3&gt;
&lt;details&gt;

- **Cost Observability**  
  Advanced observability tools to audit, monitor, and optimize your payment costs. Detect hidden fees, downgrades, and penalties with self-serve dashboards and actionable insights.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/ai-powered-cost-observability)_

- **Revenue Recovery**  
  Combat passive churn with intelligent retry strategies tuned by card bin, region, method, and more. Offers fine-grained control over retry algorithms, penalty budgets, and recovery transparency.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/revenue-recovery)_

- **Vault**  
  A PCI-compliant vault service to store cards, tokens, wallets, and bank credentials. Provides a unified, secure, and reusable store of customer-linked payment methods.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/vault)_

- **Intelligent Routing**  
  Route each transaction to the PSP with the highest predicted auth rate. Reduce retries, avoid downtime, and minimize latency while maximizing first attempt success.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/intelligent-routing)_

- **Reconciliation**  
  Automate 2-way and 3-way reconciliation with backdated support, staggered scheduling, and customizable outputs. Reduces manual ops effort and increases audit confidence.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/reconciliation)_

- **Alternate Payment Methods**  
  Drop-in widgets for PayPal, Apple Pay, Google Pay, Samsung Pay, Pay by Bank, and BNPL providers like Klarna. Maximizes conversions with seamless one-click checkout.  
  _[Read more](https://docs.hyperswitch.io/about-hyperswitch/payments-modules/enable-alternate-payment-method-widgets)_

&lt;/details&gt;

## Quickstart 

&lt;h3&gt; Local Setup via Docker &lt;/h3&gt;

```bash
# One-click local setup

git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch

cd hyperswitch

scripts/setup.sh
```
&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;This script: &lt;/strong&gt;&lt;/summary&gt;

  - Detects Docker/Podman  
  - Offers multiple deployment profiles:
    - **Standard**: App server + Control Center  
    - **Full**: Includes monitoring + schedulers  
    - **Minimal**: Standalone App server  
  - Provides access links when done

  If you need further help, check out our [video tutorial](https://docs.hyperswitch.io/hyperswitch-open-source/overview/unified-local-setup-using-docker).  

  üëâ After setup, [configure a connector](https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/using-hyperswitch-control-center#add-a-payment-processor) and [test a payment](https://docs.hyperswitch.io/hyperswitch-open-source/account-setup/test-a-payment).
&lt;/details&gt;


&lt;h3&gt;Hosted Sandbox (No Setup Required)&lt;/h3&gt;

Hyperswitch offers a fully hosted sandbox environment that requires no setup. You can explore the Control Center, configure payment connectors, and test payments directly from the UI.

   &lt;a href=&quot;https://app.hyperswitch.io&quot;&gt;
     &lt;img src=&quot;https://github.com/juspay/hyperswitch/blob/main/docs/imgs/try-the-sandbox.png?raw=true&quot; height=&quot;35&quot;&gt;
   &lt;/a&gt;


&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt; What you can do in the Hosted Sandbox&lt;/strong&gt;&lt;/summary&gt;

  - Access the full Control Center  
  - Configure payment connectors  
  - View logs, routing rules, and retry strategies  
  - Try payments directly from the UI  
&lt;/details&gt;

&lt;h3&gt;&lt;strong&gt;Cloud Deployment&lt;/strong&gt;&lt;/h3&gt;

You can deploy to AWS, GCP, or Azure using Helm or CDK scripts. Fastest path:

Click to deploy via AWS:

   &lt;a href=&quot;https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=HyperswitchBootstarp&amp;templateURL=https://hyperswitch-synth.s3.eu-central-1.amazonaws.com/hs-starter-config.yaml&quot;&gt;
     &lt;img src=&quot;https://github.com/juspay/hyperswitch/blob/main/docs/imgs/aws_button.png?raw=true&quot; height=&quot;35&quot;&gt;
   &lt;/a&gt;

&lt;details&gt;
  &lt;summary&gt;&lt;strong&gt;Cloud Deployment Instructions&lt;/strong&gt;&lt;/summary&gt;

  1. Click the AWS deployment button above to launch the stack.  
  2. Follow the guided steps in the AWS Console (approx. 30‚Äì45 mins).  

  ‚úÖ This setup provisions Hyperswitch on your cloud account using CloudFormation.  

  üìò For full instructions and Helm-based deployments, check out the  
  &lt;a href=&quot;https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm&quot;&gt;Cloud Install Guide&lt;/a&gt;.
&lt;/details&gt;


&lt;a href=&quot;#architectural-overview&quot;&gt;
  &lt;h2 id=&quot;architectural-overview&quot;&gt;Architectural Overview&lt;/h2&gt;
&lt;/a&gt;
&lt;img src=&quot;./docs/imgs/features.png&quot; /&gt;
&lt;img src=&quot;./docs/imgs/non-functional-features.png&quot; /&gt;
&lt;img src=&quot;./docs/imgs/hyperswitch-architecture-v1.png&quot; /&gt;

## Why Hyperswitch?

Hyperswitch is a commercial open-source payments stack purpose-built for scale, flexibility, and developer experience. Designed with a modular architecture, Hyperswitch lets you pick only the components you need‚Äîwhether it‚Äôs routing, retries, vaulting, or observability‚Äîwithout vendor lock-in or bloated integrations.

Built in Rust for performance and reliability, Hyperswitch supports global payment methods (cards, wallets, BNPL, UPI, Pay by Bank), exposes smart routing and retry logic, and provides a visual workflow builder in the Control Center. Whether you&#039;re integrating a full payment suite or augmenting an existing stack with a single module, Hyperswitch meets you where you are.

&lt;strong&gt;‚ÄúLinux for Payments‚Äù&lt;/strong&gt; ‚Äî Hyperswitch is a well-architected reference for teams who want to own their payments stack.

We believe in:

- &lt;strong&gt; Embracing Payment Diversity:&lt;/strong&gt; Innovation comes from enabling choice‚Äîacross payment methods, processors, and flows.

- &lt;strong&gt; Open Source by Default:&lt;/strong&gt; Transparency drives trust and builds better, reusable software.

- &lt;strong&gt; Community-Driven Development:&lt;/strong&gt; Our roadmap is shaped by real-world use cases and contributors. 

- &lt;strong&gt; Systems-Level Engineering:&lt;/strong&gt; We hold ourselves to a high bar for reliability, security, and performance.

- &lt;strong&gt; Maximizing Value Creation:&lt;/strong&gt; For developers, customers, and partners alike.

- &lt;strong&gt; Community-Driven, Enterprise-Tested:&lt;/strong&gt; Hyperswitch is built in the open with real-world feedback from developers and contributors, and maintained by Juspay, the team powering payment infrastructure for 400+ leading enterprises worldwide.

## Contributing

We welcome contributors from around the world to help build Hyperswitch. Whether you&#039;re fixing bugs, improving documentation, or adding new features, your help is appreciated.

Please read our [contributing guidelines](https://github.com/juspay/hyperswitch/blob/main/docs/CONTRIBUTING.md) to get started.

Join the conversation on [Slack](https://inviter.co/hyperswitch-slack) or explore open issues on [GitHub](https://github.com/juspay/hyperswitch/issues).

&lt;a href=&quot;#feature-requests&quot;&gt;
  &lt;h2 id=&quot;feature-requests&quot;&gt;Feature requests &amp; Bugs&lt;/h2&gt;
&lt;/a&gt;

For new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our [GitHub Discussions](https://github.com/juspay/hyperswitch/discussions)

For reporting a bug, please read the issue guidelines and search for [existing and closed issues](https://github.com/juspay/hyperswitch/issues). If your problem or idea is not addressed yet, please [open a new issue](https://github.com/juspay/hyperswitch/issues/new/choose).

&lt;a href=&quot;#versioning&quot;&gt;
  &lt;h2 id=&quot;versioning&quot;&gt;Versioning&lt;/h2&gt;
&lt;/a&gt;

Check the [CHANGELOG.md](./CHANGELOG.md) file for details.

&lt;a href=&quot;#copyright-and-license&quot;&gt;
  &lt;h2 id=&quot;copyright-and-license&quot;&gt;Copyright and License&lt;/h2&gt;
&lt;/a&gt;

This product is licensed under the [Apache 2.0 License](LICENSE).

&lt;a href=&quot;#team-behind-hyperswitch&quot;&gt;
  &lt;h2 id=&quot;team-behind-hyperswitch&quot;&gt;Team behind Hyperswitch&lt;/h2&gt;
&lt;/a&gt;

The core team of 150+ engineers building Hyperswitch. Keep up the great work! ü•Ç

&lt;a href=&quot;https://github.com/juspay/hyperswitch/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=juspay/hyperswitch&quot; alt=&quot;Contributors&quot;/&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[qdrant/qdrant]]></title>
            <link>https://github.com/qdrant/qdrant</link>
            <guid>https://github.com/qdrant/qdrant</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qdrant/qdrant">qdrant/qdrant</a></h1>
            <p>Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/</p>
            <p>Language: Rust</p>
            <p>Stars: 26,318</p>
            <p>Forks: 1,830</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre>## How to interview using this template

Open ONLY the `shared/` folder within VSCode and in the Extensions Marketplace find `CodeTogether Live`. Install it.

Inside the extension, you&#039;ll have to click on &#039;Host New Session&#039; and then &#039;Start&#039;.

You now have a link in your clipboard, which you should share with the candidate.

Don&#039;t forget to run `npm run vite.dev` inside your editor terminal, since this is not currently possible from the browser editor (link) with the free version of the extension.

The locally running server will display localhost:5173 as well as a the project within the network, which the user can access remotely to see the SPA in action, something like: `10.5.52.144:5173`.

The candidate should be sharing their screen while they read and later approach the challenge!

## React TemplateÔºà‚ö°Ô∏èÔºâ

‚ö°Ô∏è A minimal React Vite starter template.

### Feature

- ‚ö°Ô∏è Fast - Build tools based on vite.
- üëª Small - Based on the smallest runnable build.
- üíÑ Prettier - Integrated Prettier to help you format the code.
- ‚úÖ Safety - Https is enabled by default.
- üòé Reliable - Integrated eslint and commitlint.
- ü§ñ Intelligent - Integrated renovate to help you maintain the dependent version.

### Preview

[![qekup8.png](https://s1.ax1x.com/2022/03/20/qekup8.png)](https://imgtu.com/i/qekup8)

### Getting Started

```bash
npx degit lzm0x219/template-vite-react myapp

cd myapp

git init
```

#### Prerequisites

- `npm` and/or `pnpm` should be installed.
- `git` should be installed (recommended v2.4.11 or higher)

#### Available scripts

##### `npm run vite.dev`

Runs the app in development mode.
Open https://localhost:5173 to view it in the browser.

The page will automatically reload if you make changes to the code.
You will see the build errors and lint warnings in the console.

##### `npm run vite.build`

Builds the app for production to the `dist` folder.
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.

Your app is ready to be deployed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[matter-labs/zksync-era]]></title>
            <link>https://github.com/matter-labs/zksync-era</link>
            <guid>https://github.com/matter-labs/zksync-era</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[zkSync era]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/matter-labs/zksync-era">matter-labs/zksync-era</a></h1>
            <p>zkSync era</p>
            <p>Language: Rust</p>
            <p>Stars: 3,203</p>
            <p>Forks: 2,150</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># ZKsync Era: A ZK Rollup For Scaling Ethereum

[![Logo](eraLogo.png)](https://zksync.io/)

ZKsync Era is a layer 2 rollup that uses zero-knowledge proofs to scale Ethereum without compromising on security or
decentralization. Since it&#039;s EVM compatible (Solidity/Vyper), 99% of Ethereum projects can redeploy without refactoring
or re-auditing a single line of code. ZKsync Era also uses an LLVM-based compiler that will eventually let developers
write smart contracts in C++, Rust and other popular languages.

## Documentation

The most recent documentation can be found here:

- [Core documentation](https://matter-labs.github.io/zksync-era/core/latest/)
- [Prover documentation](https://matter-labs.github.io/zksync-era/prover/latest/)

## Policies

- [Security policy](SECURITY.md)
- [Contribution policy](CONTRIBUTING.md)

## License

ZKsync Era is distributed under the terms of either

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or &lt;http://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/blog/license/mit/&gt;)

at your option.

## Official Links

- [Website](https://zksync.io/)
- [GitHub](https://github.com/matter-labs)
- [ZK Credo](https://github.com/zksync/credo)
- [Twitter](https://twitter.com/zksync)
- [Twitter for Developers](https://twitter.com/zkSyncDevs)
- [Discord](https://join.zksync.dev/)
- [Mirror](https://zksync.mirror.xyz/)
- [Youtube](https://www.youtube.com/@zkSync-era)

## Disclaimer

ZKsync Era has been through lots of testing and audits. Although it is live, it is still in alpha state and will go
through more audits and bug bounty programs. We would love to hear our community&#039;s thoughts and suggestions about it! It
is important to state that forking it now can potentially lead to missing important security updates, critical features,
and performance improvements.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[bluealloy/revm]]></title>
            <link>https://github.com/bluealloy/revm</link>
            <guid>https://github.com/bluealloy/revm</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Rust implementation of the Ethereum Virtual Machine.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bluealloy/revm">bluealloy/revm</a></h1>
            <p>Rust implementation of the Ethereum Virtual Machine.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,999</p>
            <p>Forks: 809</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>### Revm

[![CI](https://github.com/bluealloy/revm/actions/workflows/ci.yml/badge.svg)][gh-ci]
[![License](https://img.shields.io/badge/License-MIT-orange.svg)][mit-license]
[![crates.io](https://img.shields.io/crates/v/revm.svg)](https://crates.io/crates/revm)
[![Chat][tg-badge]][tg-url]

Revm is a highly efficient and stable implementation of the Ethereum Virtual Machine (EVM) written in Rust.

![banner](https://raw.githubusercontent.com/bluealloy/revm/refs/heads/main/assets/logo/revm-banner.png)

[mit-license]: https://opensource.org/license/mit/
[gh-ci]: https://github.com/bluealloy/revm/actions/workflows/ci.yml
[tg-url]: https://t.me/+Ig4WDWOzikA3MzA0
[tg-badge]: https://img.shields.io/badge/chat-telegram-blue

Known for its robustness, it stands as one of the most popular libraries and a critical component of the Ethereum ecosystem. Revm plays a crucial role across various projects, being widely utilized by almost all tooling and block builders. It is integrated into Reth, multiple Layer 2 variants and other clients and serving as a standard for zkVMs.

Revm offers two primary applications: firstly, it functions as an executor where users can set up block info and process mainnet transactions; secondly, it acts as a framework that facilitates the extension and support of different EVM variants such as op-revm.

### How to use:

Here is a straightforward example of using the Execution API: It allows us to create an Ethereum Virtual Machine (EVM) and execute transactions. Additionally, it can be utilized to generate traces with the inspector or more complex example of foundry cheatcodes.

```rust,ignore
let mut evm = Context::mainnet().with_block(block).build_mainnet();
let out = evm.transact(tx);

// or you can use powerful inspection tool to trace it
let mut evm = evm.with_inspector(tracer);
let out = evm.inspect_tx(tx);
```

The EVM Framework API is somewhat complex to use, but this document provides a detailed explanation. It enables users to extend logic, incorporate various context types, and offers built-in support for inspection. For a practical example, you can refer to the [op-revm crate](https://github.com/op-rs/op-revm).

### Users:

As previously noted, there are several groups of projects that utilize this technology:

* **Major block builders**.
* **Clients**: [Reth](https://github.com/paradigmxyz/reth), [Helios](https://github.com/a16z/helios), [Trin](https://github.com/ethereum/trin),..
* **Tooling**: [Foundry](https://github.com/foundry-rs/foundry/), [Hardhat](https://github.com/NomicFoundation/hardhat),..
* **L2s**: [Optimism](https://github.com/bluealloy/revm/tree/main/crates/op-revm), [Coinbase](https://www.base.org/), [Scroll](https://github.com/scroll-tech/revm),..
* **zkVM**: [Risc0](https://github.com/risc0/risc0-ethereum), [Succinct](https://github.com/succinctlabs/rsp),..

The full list of projects that use Revm is available in the [awesome-revm](https://bluealloy.github.io/revm/awesome.html) section of the book.

### How to, dev section

The [book](https://bluealloy.github.io/revm/) and [`Architecture and API`](https://bluealloy.github.io/revm/architecture.html) page is the best starting resource.

Some quick links can be found here. Some point to code documentation or the book. code docs are there to explain usage of a particular part of the code where the book is to get more of an overview of the architecture or how components/projects fit together.

* [How to build and use revm](https://bluealloy.github.io/revm/dev.html)
* [Architecture overview](https://bluealloy.github.io/revm/architecture.html)
* [Structure of the project](https://github.com/bluealloy/revm/tree/main/crates) (list of crates and their versions)
* [How to use Revm Framework](https://github.com/bluealloy/revm/tree/main/examples/my_evm) (MyEvm example)
* [Release procedure and changelogs explanation](https://bluealloy.github.io/revm/release_procedure.html)
* [How to use revme](https://github.com/bluealloy/revm/tree/main/bins/revme) (Revm binary with few commands)
* [How to run Ethereum tests](https://bluealloy.github.io/revm/revme.html#running-eth-tests)
* If there is more need for explanations please open a PR request.

## Supported Rust Versions (MSRV)

Revm always aims to stay up-to-date with the latest stable Rust release.

The Minimum Supported Rust Version (MSRV) may be updated at any time, so we can take advantage of new features and improvements in Rust.

### Community:
For questions please open a github issue or join the public [telegram group](https://t.me/+Ig4WDWOzikA3MzA0)

### Licence
Revm is licensed under MIT Licence.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in these crates by you, shall be licensed as above, without any additional terms or conditions.

If `gmp` feature flag is used, GPL code gets compiled, if enabled please make sure to follow this license.

### Security

For any security questions or findings, please reach out to me directly via email at [dragan0rakita@gmail.com](mailto:dragan0rakita@gmail.com) or contact me on Keybase under the username @draganrakita.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cloudflare/pingora]]></title>
            <link>https://github.com/cloudflare/pingora</link>
            <guid>https://github.com/cloudflare/pingora</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[A library for building fast, reliable and evolvable network services.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloudflare/pingora">cloudflare/pingora</a></h1>
            <p>A library for building fast, reliable and evolvable network services.</p>
            <p>Language: Rust</p>
            <p>Stars: 25,132</p>
            <p>Forks: 1,472</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># Pingora

![Pingora banner image](./docs/assets/pingora_banner.png)

## What is Pingora
Pingora is a Rust framework to [build fast, reliable and programmable networked systems](https://blog.cloudflare.com/pingora-open-source).

Pingora is battle tested as it has been serving more than 40 million Internet requests per second for [more than a few years](https://blog.cloudflare.com/how-we-built-pingora-the-proxy-that-connects-cloudflare-to-the-internet).

## Feature highlights
* Async Rust: fast and reliable
* HTTP 1/2 end to end proxy
* TLS over OpenSSL, BoringSSL or rustls(experimental).
* gRPC and websocket proxying
* Graceful reload
* Customizable load balancing and failover strategies
* Support for a variety of observability tools

## Reasons to use Pingora
* **Security** is your top priority: Pingora is a more memory safe alternative for services that are written in C/C++
* Your service is **performance-sensitive**: Pingora is fast and efficient
* Your service requires extensive **customization**: The APIs Pingora proxy framework provides are highly programmable

# Getting started

See our [quick starting guide](./docs/quick_start.md) to see how easy it is to build a load balancer.

Our [user guide](./docs/user_guide/index.md) covers more topics such as how to configure and run Pingora servers, as well as how to build custom HTTP servers and proxy logic on top of Pingora&#039;s framework.

API docs are also available for all the crates.

# Notable crates in this workspace
* Pingora: the &quot;public facing&quot; crate to build networked systems and proxies
* Pingora-core: this crate defines the protocols, functionalities and basic traits
* Pingora-proxy: the logic and APIs to build HTTP proxies
* Pingora-error: the common error type used across Pingora crates
* Pingora-http: the HTTP header definitions and APIs
* Pingora-openssl &amp; pingora-boringssl: SSL related extensions and APIs
* Pingora-ketama: the [Ketama](https://github.com/RJ/ketama) consistent algorithm
* Pingora-limits: efficient counting algorithms
* Pingora-load-balancing: load balancing algorithm extensions for pingora-proxy
* Pingora-memory-cache: Async in-memory caching with cache lock to prevent cache stampede
* Pingora-timeout: A more efficient async timer system
* TinyUfo: The caching algorithm behind pingora-memory-cache

Note that Pingora proxy integration with caching should be considered experimental, and as such APIs related to caching are currently highly volatile.

# System requirements

## Systems
Linux is our tier 1 environment and main focus.

We will try our best for most code to compile for Unix environments. This is for developers and users to have an easier time developing with Pingora in Unix-like environments like macOS (though some features might be missing)

Windows support is preliminary by community&#039;s best effort only.

Both x86_64 and aarch64 architectures will be supported.

## Rust version

Pingora keeps a rolling MSRV (minimum supported Rust version) policy of 6 months. This means we will accept PRs that upgrade the MSRV as long as the new Rust version used is at least 6 months old.

Our current MSRV is effectively 1.82.

Previously Pingora advertised an MSRV of 1.72. Older Rust versions may still be able to compile via `cargo update` pinning dependencies such as `backtrace@0.3.74`. The advertised MSRV in config files will be officially bumped to 1.82 in an upcoming release.

Building with the optional feature `boringssl` with Boring &gt;= 4.14 requires Rust 1.80.

## Build Requirements

Some of the crates in this repository have dependencies on additional tools and
libraries that must be satisfied in order to build them:

* Make sure that [Clang] is installed on your system (for boringssl)
* Make sure that [Perl 5] is installed on your system (for openssl)

[Clang]:https://clang.llvm.org/
[Perl 5]:https://www.perl.org/

# Contributing
Please see our [contribution guidelines](./.github/CONTRIBUTING.md).

# License
This project is Licensed under [Apache License, Version 2.0](./LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[launchbadge/sqlx]]></title>
            <link>https://github.com/launchbadge/sqlx</link>
            <guid>https://github.com/launchbadge/sqlx</guid>
            <pubDate>Sun, 28 Sep 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[üß∞ The Rust SQL Toolkit. An async, pure Rust SQL crate featuring compile-time checked queries without a DSL. Supports PostgreSQL, MySQL, and SQLite.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/launchbadge/sqlx">launchbadge/sqlx</a></h1>
            <p>üß∞ The Rust SQL Toolkit. An async, pure Rust SQL crate featuring compile-time checked queries without a DSL. Supports PostgreSQL, MySQL, and SQLite.</p>
            <p>Language: Rust</p>
            <p>Stars: 15,705</p>
            <p>Forks: 1,477</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;SQLx&lt;/h1&gt;
&lt;div align=&quot;center&quot;&gt;
 &lt;strong&gt;
   üß∞ The Rust SQL Toolkit
 &lt;/strong&gt;
&lt;/div&gt;

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Github Actions --&gt;
  &lt;a href=&quot;https://github.com/launchbadge/sqlx/actions/workflows/sqlx.yml?query=branch%3Amain&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/launchbadge/sqlx/sqlx.yml?branch=main&amp;style=flat-square&quot; alt=&quot;actions status&quot; /&gt;&lt;/a&gt;
  &lt;!-- Version --&gt;
  &lt;a href=&quot;https://crates.io/crates/sqlx&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/sqlx.svg?style=flat-square&quot;
    alt=&quot;Crates.io version&quot; /&gt;&lt;/a&gt;
  &lt;!-- Discord --&gt;
  &lt;a href=&quot;https://discord.gg/uuruzJ7&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/discord/665528275556106240?style=flat-square&quot; alt=&quot;chat&quot; /&gt;&lt;/a&gt;
  &lt;!-- Docs --&gt;
  &lt;a href=&quot;https://docs.rs/sqlx&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square&quot; alt=&quot;docs.rs docs&quot; /&gt;&lt;/a&gt;
  &lt;!-- Downloads --&gt;
  &lt;a href=&quot;https://crates.io/crates/sqlx&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/d/sqlx.svg?style=flat-square&quot; alt=&quot;Download&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h4&gt;
    &lt;a href=&quot;#install&quot;&gt;
      Install
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;#usage&quot;&gt;
      Usage
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://docs.rs/sqlx&quot;&gt;
      Docs
    &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/launchbadge/sqlx/wiki/Ecosystem&quot;&gt;
      Ecosystem
    &lt;/a&gt;    
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://discord.gg/uuruzJ7&quot;&gt;
      Discord
    &lt;/a&gt;
  &lt;/h4&gt;
&lt;/div&gt;

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;small&gt;Built with ‚ù§Ô∏è by &lt;a href=&quot;https://launchbadge.com&quot;&gt;The LaunchBadge team&lt;/a&gt;&lt;/small&gt;
&lt;/div&gt;

&lt;br /&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;h5&gt;Have a question? Be sure to &lt;a href=&quot;FAQ.md&quot;&gt;check the FAQ first!&lt;/a&gt;&lt;/h5&gt;
&lt;/div&gt;

&lt;br /&gt;

SQLx is an async, pure Rust&lt;sub&gt;‚Ä†&lt;/sub&gt; SQL crate featuring compile-time checked queries without a DSL.

-   **Truly Asynchronous**. Built from the ground-up using async/await for maximum concurrency.

-   **Compile-time checked queries** (if you want). See [SQLx is not an ORM](#sqlx-is-not-an-orm).

-   **Database Agnostic**. Support for [PostgreSQL], [MySQL], [MariaDB], [SQLite].
    -   [MSSQL] was supported prior to version 0.7, but has been removed pending a full rewrite of the driver as part of our [SQLx Pro initiative].

-   **Pure Rust**. The Postgres and MySQL/MariaDB drivers are written in pure Rust using **zero** unsafe&lt;sub&gt;‚Ä†‚Ä†&lt;/sub&gt; code.

-   **Runtime Agnostic**. Works on different runtimes ([`async-std`] / [`tokio`] / [`actix`]) and TLS backends ([`native-tls`], [`rustls`]).

&lt;small&gt;&lt;small&gt;

‚Ä† The SQLite driver uses the libsqlite3 C library as SQLite is an embedded database (the only way
we could be pure Rust for SQLite is by porting _all_ of SQLite to Rust).

‚Ä†‚Ä† SQLx uses `#![forbid(unsafe_code)]` unless the `sqlite` feature is enabled.
The SQLite driver directly invokes the SQLite3 API via `libsqlite3-sys`, which requires `unsafe`.

&lt;/small&gt;&lt;/small&gt;

[postgresql]: http://postgresql.org/
[sqlite]: https://sqlite.org/
[mysql]: https://www.mysql.com/
[mariadb]: https://www.mariadb.org/
[mssql]: https://www.microsoft.com/en-us/sql-server
[SQLx Pro initiative]: https://github.com/launchbadge/sqlx/discussions/1616

---

-   Cross-platform. Being native Rust, SQLx will compile anywhere Rust is supported.

-   Built-in connection pooling with `sqlx::Pool`.

-   Row streaming. Data is read asynchronously from the database and decoded on demand.

-   Automatic statement preparation and caching. When using the high-level query API (`sqlx::query`), statements are
    prepared and cached per connection.

-   Simple (unprepared) query execution including fetching results into the same `Row` types used by
    the high-level API. Supports batch execution and returns results from all statements.

-   Transport Layer Security (TLS) where supported ([MySQL], [MariaDB] and [PostgreSQL]).

-   Asynchronous notifications using `LISTEN` and `NOTIFY` for [PostgreSQL].

-   Nested transactions with support for save points.

-   `Any` database driver for changing the database driver at runtime. An `AnyPool` connects to the driver indicated by the URL scheme.

## Install

SQLx is compatible with the [`async-std`], [`tokio`], and [`actix`] runtimes; and, the [`native-tls`] and [`rustls`] TLS backends. When adding the dependency, you must choose a runtime feature that is `runtime` + `tls`.

[`async-std`]: https://github.com/async-rs/async-std
[`tokio`]: https://github.com/tokio-rs/tokio
[`actix`]: https://github.com/actix/actix-net
[`native-tls`]: https://crates.io/crates/native-tls
[`rustls`]: https://crates.io/crates/rustls

```toml
# Cargo.toml
[dependencies]
# PICK ONE OF THE FOLLOWING:

# tokio (no TLS)
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot; ] }
# tokio + native-tls
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-native-tls&quot; ] }
# tokio + rustls with ring and WebPKI CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-rustls-ring-webpki&quot; ] }
# tokio + rustls with ring and platform&#039;s native CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-rustls-ring-native-roots&quot; ] }
# tokio + rustls with aws-lc-rs
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-tokio&quot;, &quot;tls-rustls-aws-lc-rs&quot; ] }

# async-std (no TLS)
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot; ] }
# async-std + native-tls
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-native-tls&quot; ] }
# async-std + rustls with ring and WebPKI CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-rustls-ring-webpki&quot; ] }
# async-std + rustls with ring and platform&#039;s native CA certificates
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-rustls-ring-native-roots&quot; ] }
# async-std + rustls with aws-lc-rs
sqlx = { version = &quot;0.8&quot;, features = [ &quot;runtime-async-std&quot;, &quot;tls-rustls-aws-lc-rs&quot; ] }
```

#### Cargo Feature Flags

For backward-compatibility reasons, the runtime and TLS features can either be chosen together as a single feature,
or separately.

For forward compatibility, you should use the separate runtime and TLS features as the combination features may
be removed in the future.

-   `runtime-async-std`: Use the `async-std` runtime without enabling a TLS backend.

-   `runtime-tokio`: Use the `tokio` runtime without enabling a TLS backend.

    - Actix-web is fully compatible with Tokio and so a separate runtime feature is no longer needed.

-   `tls-native-tls`: Use the `native-tls` TLS backend (OpenSSL on *nix, SChannel on Windows, Secure Transport on macOS).

-   `tls-rustls`: Use the `rustls` TLS backend (cross-platform backend, only supports TLS 1.2 and 1.3).

-   `postgres`: Add support for the Postgres database server.

-   `mysql`: Add support for the MySQL/MariaDB database server.

-   `mssql`: Add support for the MSSQL database server.

-   `sqlite`: Add support for the self-contained [SQLite](https://sqlite.org/) database engine with SQLite bundled and statically-linked.

-   `sqlite-unbundled`: The same as above (`sqlite`), but link SQLite from the system instead of the bundled version.
    * Allows updating SQLite independently of SQLx or using forked versions.
    * You must have SQLite installed on the system or provide a path to the library at build time.
       See [the `rusqlite` README](https://github.com/rusqlite/rusqlite?tab=readme-ov-file#notes-on-building-rusqlite-and-libsqlite3-sys) for details.
    * May result in link errors if the SQLite version is too old. Version `3.20.0` or newer is recommended.
    * Can increase build time due to the use of bindgen.

-   `sqlite-preupdate-hook`: enables SQLite&#039;s [preupdate hook](https://sqlite.org/c3ref/preupdate_count.html) API.
    * Exposed as a separate feature because it&#039;s generally not enabled by default.
    * Using this feature with `sqlite-unbundled` may cause linker failures if the system SQLite version does not support it.

-   `any`: Add support for the `Any` database driver, which can proxy to a database driver at runtime.

-   `derive`: Add support for the derive family macros, those are `FromRow`, `Type`, `Encode`, `Decode`.

-   `macros`: Add support for the `query*!` macros, which allows compile-time checked queries.

-   `migrate`: Add support for the migration management and `migrate!` macro, which allow compile-time embedded migrations.

-   `uuid`: Add support for UUID.

-   `chrono`: Add support for date and time types from `chrono`.

-   `time`: Add support for date and time types from `time` crate (alternative to `chrono`, which is preferred by `query!` macro, if both enabled)

-   `bstr`: Add support for `bstr::BString`.

-   `bigdecimal`: Add support for `NUMERIC` using the `bigdecimal` crate.

-   `rust_decimal`: Add support for `NUMERIC` using the `rust_decimal` crate.

-   `ipnet`: Add support for `INET` and `CIDR` (in postgres) using the `ipnet` crate.

-   `ipnetwork`: Add support for `INET` and `CIDR` (in postgres) using the `ipnetwork` crate.

-   `json`: Add support for `JSON` and `JSONB` (in postgres) using the `serde_json` crate.

-   Offline mode is now always enabled. See [sqlx-cli/README.md][readme-offline].

[readme-offline]: sqlx-cli/README.md#enable-building-in-offline-mode-with-query

## SQLx is not an ORM!

SQLx supports **compile-time checked queries**. It does not, however, do this by providing a Rust
API or DSL (domain-specific language) for building queries. Instead, it provides macros that take
regular SQL as input and ensure that it is valid for your database. The way this works is that
SQLx connects to your development DB at compile time to have the database itself verify (and return
some info on) your SQL queries. This has some potentially surprising implications:

- Since SQLx never has to parse the SQL string itself, any syntax that the development DB accepts
  can be used (including things added by database extensions)
- Due to the different amount of information databases let you retrieve about queries, the extent of
  SQL verification you get from the query macros depends on the database

**If you are looking for an (asynchronous) ORM,** you can check out our new [Ecosystem wiki page](https://github.com/launchbadge/sqlx/wiki/Ecosystem#orms)!

[`ormx`]: https://crates.io/crates/ormx
[`SeaORM`]: https://github.com/SeaQL/sea-orm
## Usage

See the `examples/` folder for more in-depth usage.

### Quickstart

```rust
use sqlx::postgres::PgPoolOptions;
// use sqlx::mysql::MySqlPoolOptions;
// etc.

#[async_std::main] // Requires the `attributes` feature of `async-std`
// or #[tokio::main]
// or #[actix_web::main]
async fn main() -&gt; Result&lt;(), sqlx::Error&gt; {
    // Create a connection pool
    //  for MySQL/MariaDB, use MySqlPoolOptions::new()
    //  for SQLite, use SqlitePoolOptions::new()
    //  etc.
    let pool = PgPoolOptions::new()
        .max_connections(5)
        .connect(&quot;postgres://postgres:password@localhost/test&quot;).await?;

    // Make a simple query to return the given parameter (use a question mark `?` instead of `$1` for MySQL/MariaDB)
    let row: (i64,) = sqlx::query_as(&quot;SELECT $1&quot;)
        .bind(150_i64)
        .fetch_one(&amp;pool).await?;

    assert_eq!(row.0, 150);

    Ok(())
}
```


### Connecting

A single connection can be established using any of the database connection types and calling `connect()`.

```rust
use sqlx::Connection;

let conn = SqliteConnection::connect(&quot;sqlite::memory:&quot;).await?;
```

Generally, you will want to instead create a connection pool (`sqlx::Pool`) for the application to
regulate how many server-side connections it&#039;s using.

```rust
let pool = MySqlPool::connect(&quot;mysql://user:pass@host/database&quot;).await?;
```

### Querying

In SQL, queries can be separated into prepared (parameterized) or unprepared (simple). Prepared queries have their
query plan _cached_, use a binary mode of communication (lower bandwidth and faster decoding), and utilize parameters
to avoid SQL injection. Unprepared queries are simple and intended only for use where a prepared statement
will not work, such as various database commands (e.g., `PRAGMA` or `SET` or `BEGIN`).

SQLx supports all operations with both types of queries. In SQLx, a `&amp;str` is treated as an unprepared query,
and a `Query` or `QueryAs` struct is treated as a prepared query.

```rust
// low-level, Executor trait
conn.execute(&quot;BEGIN&quot;).await?; // unprepared, simple query
conn.execute(sqlx::query(&quot;DELETE FROM table&quot;)).await?; // prepared, cached query
```

We should prefer to use the high-level `query` interface whenever possible. To make this easier, there are finalizers
on the type to avoid the need to wrap with an executor.

```rust
sqlx::query(&quot;DELETE FROM table&quot;).execute(&amp;mut conn).await?;
sqlx::query(&quot;DELETE FROM table&quot;).execute(&amp;pool).await?;
```

The `execute` query finalizer returns the number of affected rows, if any, and drops all received results.
In addition, there are `fetch`, `fetch_one`, `fetch_optional`, and `fetch_all` to receive results.

The `Query` type returned from `sqlx::query` will return `Row&lt;&#039;conn&gt;` from the database. Column values can be accessed
by ordinal or by name with `row.get()`. As the `Row` retains an immutable borrow on the connection, only one
`Row` may exist at a time.

The `fetch` query finalizer returns a stream-like type that iterates through the rows in the result sets.

```rust
// provides `try_next`
use futures_util::TryStreamExt;
// provides `try_get`
use sqlx::Row;

let mut rows = sqlx::query(&quot;SELECT * FROM users WHERE email = ?&quot;)
    .bind(email)
    .fetch(&amp;mut conn);

while let Some(row) = rows.try_next().await? {
    // map the row into a user-defined domain type
    let email: &amp;str = row.try_get(&quot;email&quot;)?;
}
```

To assist with mapping the row into a domain type, one of two idioms may be used:

```rust
let mut stream = sqlx::query(&quot;SELECT * FROM users&quot;)
    .map(|row: PgRow| {
        // map the row into a user-defined domain type
    })
    .fetch(&amp;mut conn);
```

```rust
#[derive(sqlx::FromRow)]
struct User { name: String, id: i64 }

let mut stream = sqlx::query_as::&lt;_, User&gt;(&quot;SELECT * FROM users WHERE email = ? OR name = ?&quot;)
    .bind(user_email)
    .bind(user_name)
    .fetch(&amp;mut conn);
```

Instead of a stream of results, we can use `fetch_one` or `fetch_optional` to request one required or optional result
from the database.

### Compile-time verification

We can use the macro, `sqlx::query!` to achieve compile-time syntactic and semantic verification of the SQL, with
an output to an anonymous record type where each SQL column is a Rust field (using raw identifiers where needed).

```rust
let countries = sqlx::query!(
        &quot;
SELECT country, COUNT(*) as count
FROM users
GROUP BY country
WHERE organization = ?
        &quot;,
        organization
    )
    .fetch_all(&amp;pool) // -&gt; Vec&lt;{ country: String, count: i64 }&gt;
    .await?;

// countries[0].country
// countries[0].count
```

Differences from `query()`:

-   The input (or bind) parameters must be given all at once (and they are compile-time validated to be
    the right number and the right type).

-   The output type is an anonymous record. In the above example the type would be similar to:

    ```rust
    { country: String, count: i64 }
    ```

-   The `DATABASE_URL` environment variable must be set at build time to a database which it can prepare
    queries against; the database does not have to contain any data but must be the same
    kind (MySQL, Postgres, etc.) and have the same schema as the database you will be connecting to at runtime.

    For convenience, you can use [a `.env` file][dotenv]&lt;sup&gt;1&lt;/sup&gt; to set DATABASE_URL so that you don&#039;t have to pass it every time:

    ```
    DATABASE_URL=mysql://localhost/my_database
    ```

[dotenv]: https://github.com/dotenv-rs/dotenv#examples

The biggest downside to `query!()` is that the output type cannot be named (due to Rust not
officially supporting anonymous records). To address that, there is a `query_as!()` macro that is
mostly identical except that you can name the output type.

```rust
// no traits are needed
struct Country { country: String, count: i64 }

let countries = sqlx::query_as!(Country,
        &quot;
SELECT country, COUNT(*) as count
FROM users
GROUP BY country
WHERE organization = ?
        &quot;,
        organization
    )
    .fetch_all(&amp;pool) // -&gt; Vec&lt;Country&gt;
    .await?;

// countries[0].country
// countries[0].count
```

To avoid the need of having a development database around to compile the project even when no
modifications (to the database-accessing parts of the code) are done, you can enable &quot;offline mode&quot;
to cache the results of the SQL query analysis using the `sqlx` command-line tool. See
[sqlx-cli/README.md](./sqlx-cli/README.md#enable-building-in-offline-mode-with-query).

Compile-time verified queries do quite a bit of work at compile time. Incremental actions like
`cargo check` and `cargo build` can be significantly faster when using an optimized build by
putting the following in your `Cargo.toml` (More information in the
[Profiles section](https://doc.rust-lang.org/cargo/reference/profiles.html) of The Cargo Book)

```toml
[profile.dev.package.sqlx-macros]
opt-level = 3
```

&lt;sup&gt;1&lt;/sup&gt; The `dotenv` crate itself appears abandoned as of [December 2021](https://github.com/dotenv-rs/dotenv/issues/74)
so we now use the `dotenvy` crate instead. The file format is the same.

## Safety

This crate uses `#![forbid(unsafe_code)]` to ensure everything is implemented in 100% Safe Rust.

If the `sqlite` feature is enabled, this is downgraded to `#![deny(unsafe_code)]` with `#![allow(unsafe_code)]` on the
`sqlx::sqlite` module. There are several places where we interact with the C SQLite API. We try to document each call for the invariants we&#039;re assuming. We absolutely welcome auditing of, and feedback on, our unsafe code usage.

## License

Licensed under either of

-   Apache License, Version 2.0
    ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
-   MIT license
    ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your option.

## Contribution

Unless you explicitly state otherwise, any Contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>