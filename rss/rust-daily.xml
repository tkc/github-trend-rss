<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Fri, 11 Apr 2025 00:05:42 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[clockworklabs/SpacetimeDB]]></title>
            <link>https://github.com/clockworklabs/SpacetimeDB</link>
            <guid>https://github.com/clockworklabs/SpacetimeDB</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:42 GMT</pubDate>
            <description><![CDATA[Multiplayer at the speed of light]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/clockworklabs/SpacetimeDB">clockworklabs/SpacetimeDB</a></h1>
            <p>Multiplayer at the speed of light</p>
            <p>Language: Rust</p>
            <p>Stars: 12,812</p>
            <p>Forks: 422</p>
            <p>Stars today: 451 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
	&lt;img width=&quot;320&quot; src=&quot;./images/dark/logo.svg&quot; alt=&quot;SpacetimeDB Logo&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
	&lt;img width=&quot;320&quot; src=&quot;./images/light/logo.svg&quot; alt=&quot;SpacetimeDB Logo&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
        &lt;img width=&quot;250&quot; src=&quot;./images/dark/logo-text.svg&quot; alt=&quot;SpacetimeDB&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
        &lt;img width=&quot;250&quot; src=&quot;./images/light/logo-text.svg&quot; alt=&quot;SpacetimeDB&quot;&gt;
    &lt;/a&gt;
    &lt;h3 align=&quot;center&quot;&gt;
        Multiplayer at the speed of light.
    &lt;/h3&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/clockworklabs/spacetimedb?color=%23ff00a0&amp;include_prereleases&amp;label=version&amp;sort=semver&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/built_with-Rust-dca282.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
	&lt;a href=&quot;https://github.com/clockworklabs/spacetimedb/actions&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/clockworklabs/spacetimedb/ci.yml?style=flat-square&amp;branch=master&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://status.spacetimedb.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/uptimerobot/ratio/7/m784409192-e472ca350bb615372ededed7?label=cloud%20uptime&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://hub.docker.com/r/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/clockworklabs/spacetimedb?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb/blob/master/LICENSE.txt&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-BSL_1.1-00bfff.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://crates.io/crates/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/d/spacetimedb?color=e45928&amp;label=Rust%20Crate&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.nuget.org/packages/SpacetimeDB.Runtime&quot;&gt;&lt;img src=&quot;https://img.shields.io/nuget/dt/spacetimedb.runtime?color=0b6cff&amp;label=NuGet%20Package&amp;style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://discord.gg/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1037340874172014652?label=discord&amp;style=flat-square&amp;color=5a66f6&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitter.com/spacetime_db&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/twitter-Follow_us-1d9bf0.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://clockworklabs.io/join&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/careers-Join_us-86f7b7.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/clockworklabs/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/linkedin-Connect_with_us-0a66c2.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://discord.gg/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/discord.svg&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitter.com/spacetime_db&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/twitter.svg&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/github.svg&quot; alt=&quot;Github&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitch.tv/SpacetimeDB&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/twitch.svg&quot; alt=&quot;Twitch&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://youtube.com/@SpacetimeDB&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/youtube.svg&quot; alt=&quot;YouTube&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/clockwork-labs/&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/linkedin.svg&quot; alt=&quot;LinkedIn&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://stackoverflow.com/questions/tagged/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/stackoverflow.svg&quot; alt=&quot;StackOverflow&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

## What is [SpacetimeDB](https://spacetimedb.com)?

You can think of SpacetimeDB as both a database and server combined into one.

It is a relational database system that lets you upload your application logic directly into the database by way of fancy stored procedures called &quot;modules.&quot;

Instead of deploying a web or game server that sits in between your clients and your database, your clients connect directly to the database and execute your application logic inside the database itself. You can write all of your permission and authorization logic right inside your module just as you would in a normal server.

This means that you can write your entire application in a single language, Rust, and deploy it as a single binary. No more microservices, no more containers, no more Kubernetes, no more Docker, no more VMs, no more DevOps, no more infrastructure, no more ops, no more servers.

&lt;figure&gt;
    &lt;img src=&quot;./images/basic-architecture-diagram.png&quot; alt=&quot;SpacetimeDB Architecture&quot; style=&quot;width:100%&quot;&gt;
    &lt;figcaption align=&quot;center&quot;&gt;
        &lt;p align=&quot;center&quot;&gt;&lt;b&gt;SpacetimeDB application architecture&lt;/b&gt;&lt;br /&gt;&lt;sup&gt;&lt;sub&gt;(elements in white are provided by SpacetimeDB)&lt;/sub&gt;&lt;/sup&gt;&lt;/p&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;

It&#039;s actually similar to the idea of smart contracts, except that SpacetimeDB is a database, has nothing to do with blockchain, and is orders of magnitude faster than any smart contract system.

So fast, in fact, that the entire backend of our MMORPG [BitCraft Online](https://bitcraftonline.com) is just a SpacetimeDB module. We don&#039;t have any other servers or services running, which means that everything in the game, all of the chat messages, items, resources, terrain, and even the locations of the players are stored and processed by the database before being synchronized out to all of the clients in real-time.

SpacetimeDB is optimized for maximum speed and minimum latency rather than batch processing or OLAP workloads. It is designed to be used for real-time applications like games, chat, and collaboration tools.

This speed and latency is achieved by holding all of application state in memory, while persisting the data in a write-ahead-log (WAL) which is used to recover application state.

## Installation

You can run SpacetimeDB as a standalone database server via the `spacetime` CLI tool.
Install instructions for supported platforms are outlined below.
The same install instructions can be found on our website at https://spacetimedb.com/install.

#### Install on macOS

Installing on macOS is as simple as running our install script. After that you can use the spacetime command to manage versions.

```bash
curl -sSf https://install.spacetimedb.com | sh
```

#### Install on Linux

Installing on Linux is as simple as running our install script. After that you can use the spacetime command to manage versions.

```bash
curl -sSf https://install.spacetimedb.com | sh
```

#### Install on Windows

Installing on Windows is as simple as pasting the above snippet into PowerShell. If you would like to use WSL instead, please follow the Linux install instructions.

```ps1
iwr https://windows.spacetimedb.com -useb | iex
```

#### Installing from Source

A quick note on installing from source: we recommend that you don&#039;t install from source unless there is a feature that is available in `master` that hasn&#039;t been released yet, otherwise follow the official installation instructions.

##### MacOS + Linux

Installing on macOS + Linux is pretty straightforward. First we are going to build all of the binaries that we need:

```bash
# Install rustup, you can skip this step if you have cargo and the wasm32-unknown-unknown target already installed.
curl https://sh.rustup.rs -sSf | sh
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
mkdir -p ~/.local/bin
export STDB_VERSION=&quot;$(./target/release/spacetimedb-cli --version | sed -n &#039;s/.*spacetimedb tool version \([0-9.]*\);.*/\1/p&#039;)&quot;
mkdir -p ~/.local/share/spacetime/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/.local/bin/spacetime
cp target/release/spacetimedb-cli ~/.local/share/spacetime/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/.local/share/spacetime/bin/$STDB_VERSION
```

At this stage you&#039;ll need to add ~/.local/bin to your path if you haven&#039;t already.

```
# Please add the following line to your shell configuration and open a new shell session:
export PATH=&quot;$HOME/.local/bin:$PATH&quot;

```

Then finally set your SpacetimeDB version:
```

# Then, in a new shell, set the current version:
spacetime version use $STDB_VERSION

# If STDB_VERSION is not set anymore then you can use the following command to list your versions:
spacetime version list
```

You can verify that the correct version has been installed via `spacetime --version`.

##### Windows

Building on windows is a bit more complicated. You&#039;ll need a slightly different version of perl compared to what comes pre-bundled in most Windows terminals. We recommend [Strawberry Perl](https://strawberryperl.com/). You may also need access to an `openssl` binary which actually comes pre-installed with [Git for Windows](https://git-scm.com/downloads/win). Also, you&#039;ll need to install [rustup](https://rustup.rs/) for Windows.

In a Git for Windows shell you should have something that looks like this:
```
$ which perl
/c/Strawberry/perl/bin/perl
$ which openssl
/mingw64/bin/openssl
$ which cargo 
/c/Users/&lt;user&gt;/.cargo/bin/cargo
```

If that looks correct then you&#039;re ready to proceed!

```powershell
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB

# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
$stdbDir = &quot;$HOME\AppData\Local\SpacetimeDB&quot;
$stdbVersion = &amp; &quot;.\target\release\spacetimedb-cli&quot; --version | Select-String -Pattern &#039;spacetimedb tool version ([0-9.]+);&#039; | ForEach-Object { $_.Matches.Groups[1].Value }
New-Item -ItemType Directory -Path &quot;$stdbDir\bin\$stdbVersion&quot; -Force | Out-Null

# Install the update binary
Copy-Item &quot;target\release\spacetimedb-update.exe&quot; &quot;$stdbDir\spacetime.exe&quot;
Copy-Item &quot;target\release\spacetimedb-cli.exe&quot; &quot;$stdbDir\bin\$stdbVersion\&quot;
Copy-Item &quot;target\release\spacetimedb-standalone.exe&quot; &quot;$stdbDir\bin\$stdbVersion\&quot;

```

Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!

```
%USERPROFILE%\AppData\Local\SpacetimeDB
```

Then finally, open a new shell and use the installed SpacetimeDB version:
```
spacetime version use $stdbVersion

# If stdbVersion is no longer set, list versions using the following command:
spacetime version list
```

You can verify that the correct version has been installed via `spacetime --version`.

If you&#039;re using Git for Windows you can follow these instructions instead:

```bash
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
# Build the CLI binaries - this takes a while on windows so go grab a coffee :)
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
export STDB_VERSION=&quot;$(./target/release/spacetimedb-cli --version | sed -n &#039;s/.*spacetimedb tool version \([0-9.]*\);.*/\1/p&#039;)&quot;
mkdir -p ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/AppData/Local/SpacetimeDB/spacetime
cp target/release/spacetimedb-cli ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!
# %USERPROFILE%\AppData\Local\SpacetimeDB

# Set the current version
spacetime version use $STDB_VERSION
```

You can verify that the correct version has been installed via `spacetime --version`.

#### Running with Docker

If you prefer to run Spacetime in a container, you can use the following command to start a new instance.

```bash
docker run --rm --pull always -p 3000:3000 clockworklabs/spacetime start
```

## Documentation

For more information about SpacetimeDB, getting started guides, game development guides, and reference material please see our [documentation](https://spacetimedb.com/docs).

## Getting Started

We&#039;ve prepared several getting started guides in each of our supported languages to help you get up and running with SpacetimeDB as quickly as possible. You can find them on our [docs page](https://spacetimedb.com/docs).

In summary there are only 4 steps to getting started with SpacetimeDB.

1. Install the `spacetime` CLI tool.
2. Start a SpacetimeDB standalone node with `spacetime start`.
3. Write and upload a module in one of our supported module languages.
4. Connect to the database with one of our client libraries.

You can see a summary of the supported languages below with a link to the getting started guide for each.

## Language Support

You can write SpacetimeDB modules in several popular languages, with more to come in the future!

#### Serverside Libraries

- [Rust](https://spacetimedb.com/docs/modules/rust/quickstart)
- [C#](https://spacetimedb.com/docs/modules/c-sharp/quickstart)

#### Client Libraries

- [Rust](https://spacetimedb.com/docs/sdks/rust/quickstart)
- [C#](https://spacetimedb.com/docs/sdks/c-sharp/quickstart)
- [Typescript](https://spacetimedb.com/docs/sdks/typescript/quickstart)

## License

SpacetimeDB is licensed under the BSL 1.1 license. This is not an open source or free software license, however, it converts to the AGPL v3.0 license with a linking exception after a few years.

Note that the AGPL v3.0 does not typically include a linking exception. We have added a custom linking exception to the AGPL license for SpacetimeDB. Our motivation for choosing a free software license is to ensure that contributions made to SpacetimeDB are propagated back to the community. We are expressly not interested in forcing users of SpacetimeDB to open source their own code if they link with SpacetimeDB, so we needed to include a linking exception.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:41 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 48,902</p>
            <p>Forks: 1,369</p>
            <p>Stars today: 182 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- üöÄ A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`,
  and more.
- ‚ö°Ô∏è [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- üóÇÔ∏è Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- ‚ùáÔ∏è [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- üêç [Installs and manages](#python-versions) Python versions.
- üõ†Ô∏è [Runs and installs](#tools) tools published as Python packages.
- üî© Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a
  familiar CLI.
- üè¢ Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- üíæ Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- ‚è¨ Installable without Rust or Python via `curl` or `pip`.
- üñ•Ô∏è Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Platform support

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

## Versioning policy

See uv&#039;s [versioning policy](https://docs.astral.sh/uv/reference/versioning/) document.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv/blob/main/CONTRIBUTING.md) to get started.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:40 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 11,530</p>
            <p>Forks: 852</p>
            <p>Stars today: 101 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# codename goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/7GaTvbDwga&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;&gt;
     &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation. 


# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)


# Goose Around with Us
- [Discord](https://discord.gg/block-opensource)
- [YouTube](https://www.youtube.com/@blockopensource)
- [LinkedIn](https://www.linkedin.com/company/block-opensource)
- [Twitter/X](https://x.com/blockopensource)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[embassy-rs/embassy]]></title>
            <link>https://github.com/embassy-rs/embassy</link>
            <guid>https://github.com/embassy-rs/embassy</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:39 GMT</pubDate>
            <description><![CDATA[Modern embedded framework, using Rust and async.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/embassy-rs/embassy">embassy-rs/embassy</a></h1>
            <p>Modern embedded framework, using Rust and async.</p>
            <p>Language: Rust</p>
            <p>Stars: 6,579</p>
            <p>Forks: 979</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># Embassy

Embassy is the next-generation framework for embedded applications. Write safe, correct and energy-efficient embedded code faster, using the Rust programming language, its async facilities, and the Embassy libraries.

## &lt;a href=&quot;https://embassy.dev/book/index.html&quot;&gt;Documentation&lt;/a&gt; - &lt;a href=&quot;https://docs.embassy.dev/&quot;&gt;API reference&lt;/a&gt; - &lt;a href=&quot;https://embassy.dev/&quot;&gt;Website&lt;/a&gt; - &lt;a href=&quot;https://matrix.to/#/#embassy-rs:matrix.org&quot;&gt;Chat&lt;/a&gt;
## Rust + async ‚ù§Ô∏è embedded

The Rust programming language is blazingly fast and memory-efficient, with no runtime, garbage collector or OS. It catches a wide variety of bugs at compile time, thanks to its full memory- and thread-safety, and expressive type system. 

Rust&#039;s &lt;a href=&quot;https://rust-lang.github.io/async-book/&quot;&gt;async/await&lt;/a&gt; allows for unprecedentedly easy and efficient multitasking in embedded systems. Tasks get transformed at compile time into state machines that get run cooperatively. It requires no dynamic memory allocation, and runs on a single stack,  so no per-task stack size tuning is required. It obsoletes the need for a traditional RTOS with kernel context switching, and is &lt;a href=&quot;https://tweedegolf.nl/en/blog/65/async-rust-vs-rtos-showdown&quot;&gt;faster and smaller than one!&lt;/a&gt;

## Batteries included

- **Hardware Abstraction Layers** - HALs implement safe, idiomatic Rust APIs to use the hardware capabilities, so raw register manipulation is not needed. The Embassy project maintains HALs for select hardware, but you can still use HALs from other projects with Embassy.
  - &lt;a href=&quot;https://docs.embassy.dev/embassy-stm32/&quot;&gt;embassy-stm32&lt;/a&gt;, for all STM32 microcontroller families.
  - &lt;a href=&quot;https://docs.embassy.dev/embassy-nrf/&quot;&gt;embassy-nrf&lt;/a&gt;, for the Nordic Semiconductor nRF52, nRF53, nRF54 and nRF91 series.
  - &lt;a href=&quot;https://docs.embassy.dev/embassy-rp/&quot;&gt;embassy-rp&lt;/a&gt;, for the Raspberry Pi RP2040 and RP23xx microcontrollers.
  - &lt;a href=&quot;https://docs.embassy.dev/embassy-mspm0/&quot;&gt;embassy-mspm0&lt;/a&gt;, for the Texas Instruments MSPM0 microcontrollers.
  - &lt;a href=&quot;https://github.com/esp-rs&quot;&gt;esp-rs&lt;/a&gt;, for the Espressif Systems ESP32 series of chips.
    - Embassy HAL support for Espressif chips, as well as Async WiFi, Bluetooth and ESP-NOW,  is being developed in the [esp-rs/esp-hal](https://github.com/esp-rs/esp-hal) repository.
  - &lt;a href=&quot;https://github.com/ch32-rs/ch32-hal&quot;&gt;ch32-hal&lt;/a&gt;, for the WCH 32-bit RISC-V(CH32V) series of chips.
  - &lt;a href=&quot;https://github.com/AlexCharlton/mpfs-hal&quot;&gt;mpfs-hal&lt;/a&gt;, for the Microchip PolarFire SoC.
  - &lt;a href=&quot;https://github.com/py32-rs/py32-hal&quot;&gt;py32-hal&lt;/a&gt;, for the Puya Semiconductor PY32 series of microcontrollers.

- **Time that Just Works** - 
No more messing with hardware timers. &lt;a href=&quot;https://docs.embassy.dev/embassy-time&quot;&gt;embassy_time&lt;/a&gt; provides Instant, Duration and Timer types that are globally available and never overflow.

- **Real-time ready** - 
Tasks on the same async executor run cooperatively, but you can create multiple executors with different priorities, so that higher priority tasks preempt lower priority ones. See the &lt;a href=&quot;https://github.com/embassy-rs/embassy/blob/master/examples/nrf52840/src/bin/multiprio.rs&quot;&gt;example&lt;/a&gt;.

- **Low-power ready** - 
Easily build devices with years of battery life. The async executor automatically puts the core to sleep when there&#039;s no work to do. Tasks are woken by interrupts, there is no busy-loop polling while waiting.
 
- **Networking** - 
The &lt;a href=&quot;https://docs.embassy.dev/embassy-net/&quot;&gt;embassy-net&lt;/a&gt; network stack implements extensive networking functionality, including Ethernet, IP, TCP, UDP, ICMP and DHCP. Async drastically simplifies managing timeouts and serving multiple connections concurrently.

- **Bluetooth**
  - The &lt;a href=&quot;https://github.com/embassy-rs/trouble&quot;&gt;trouble&lt;/a&gt; crate provides a Bluetooth Low Energy 4.x and 5.x Host that runs on any microcontroller implementing the &lt;a href=&quot;https://github.com/embassy-rs/bt-hci&quot;&gt;bt-hci&lt;/a&gt; traits (currently `nRF52`, `rp2040`, `rp23xx` and `esp32` and `serial` controllers are supported).
  - The &lt;a href=&quot;https://github.com/embassy-rs/nrf-softdevice&quot;&gt;nrf-softdevice&lt;/a&gt; crate provides Bluetooth Low Energy 4.x and 5.x support for nRF52 microcontrollers.
  - The &lt;a href=&quot;https://github.com/embassy-rs/embassy/tree/main/embassy-stm32-wpan&quot;&gt;embassy-stm32-wpan&lt;/a&gt; crate provides Bluetooth Low Energy 5.x support for stm32wb microcontrollers.

- **LoRa** - The &lt;a href=&quot;https://github.com/lora-rs/lora-rs&quot;&gt;lora-rs&lt;/a&gt; project provides an async LoRa and LoRaWAN stack that works well on Embassy.

- **USB** - 
&lt;a href=&quot;https://docs.embassy.dev/embassy-usb/&quot;&gt;embassy-usb&lt;/a&gt; implements a device-side USB stack. Implementations for common classes such as USB serial (CDC ACM) and USB HID are available, and a rich builder API allows building your own.

- **Bootloader and DFU** - 
&lt;a href=&quot;https://github.com/embassy-rs/embassy/tree/master/embassy-boot&quot;&gt;embassy-boot&lt;/a&gt; is a lightweight bootloader supporting firmware application upgrades in a power-fail-safe way, with trial boots and rollbacks.


## Sneak peek

```rust,ignore
use defmt::info;
use embassy_executor::Spawner;
use embassy_time::{Duration, Timer};
use embassy_nrf::gpio::{AnyPin, Input, Level, Output, OutputDrive, Pin, Pull};
use embassy_nrf::{Peri, Peripherals};

// Declare async tasks
#[embassy_executor::task]
async fn blink(pin: Peri&lt;&#039;static, AnyPin&gt;) {
    let mut led = Output::new(pin, Level::Low, OutputDrive::Standard);

    loop {
        // Timekeeping is globally available, no need to mess with hardware timers.
        led.set_high();
        Timer::after_millis(150).await;
        led.set_low();
        Timer::after_millis(150).await;
    }
}

// Main is itself an async task as well.
#[embassy_executor::main]
async fn main(spawner: Spawner) {
    let p = embassy_nrf::init(Default::default());

    // Spawned tasks run in the background, concurrently.
    spawner.spawn(blink(p.P0_13.into())).unwrap();

    let mut button = Input::new(p.P0_11, Pull::Up);
    loop {
        // Asynchronously wait for GPIO events, allowing other tasks
        // to run, or the core to sleep.
        button.wait_for_low().await;
        info!(&quot;Button pressed!&quot;);
        button.wait_for_high().await;
        info!(&quot;Button released!&quot;);
    }
}
```

## Examples

Examples are found in the `examples/` folder separated by the chip manufacturer they are designed to run on. For example:

*   `examples/nrf52840` run on the `nrf52840-dk` board (PCA10056) but should be easily adaptable to other nRF52 chips and boards.
*   `examples/nrf5340` run on the `nrf5340-dk` board (PCA10095).
*   `examples/stm32xx` for the various STM32 families.
*   `examples/rp` are for the RP2040 chip.
*   `examples/std` are designed to run locally on your PC.

### Running examples

- Install `probe-rs` following the instructions at &lt;https://probe.rs&gt;.
- Change directory to the sample&#039;s base directory. For example:

```bash
cd examples/nrf52840
```

- Ensure `Cargo.toml` sets the right feature for the name of the chip you are programming.
  If this name is incorrect, the example may fail to run or immediately crash
  after being programmed.

- Ensure `.cargo/config.toml` contains the name of the chip you are programming.

- Run the example

For example:

```bash
cargo run --release --bin blinky
```

For more help getting started, see [Getting Started][1] and [Running the Examples][2].

## Developing Embassy with Rust Analyzer based editors

The [Rust Analyzer](https://rust-analyzer.github.io/) is used by [Visual Studio Code](https://code.visualstudio.com/)
and others. Given the multiple targets that Embassy serves, there is no Cargo workspace file. Instead, the Rust Analyzer
must be told of the target project to work with. In the case of Visual Studio Code,
please refer to the `.vscode/settings.json` file&#039;s `rust-analyzer.linkedProjects`setting.

## Minimum supported Rust version (MSRV)

Embassy is guaranteed to compile on stable Rust 1.75 and up. It *might*
compile with older versions but that may change in any new patch release.

## Why the name?

EMBedded ASYnc! :)

## License

Embassy is licensed under either of

- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;http://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;http://opensource.org/licenses/MIT&gt;)

at your option.

## Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall be
dual licensed as above, without any additional terms or conditions.

[1]: https://github.com/embassy-rs/embassy/wiki/Getting-Started
[2]: https://github.com/embassy-rs/embassy/wiki/Running-the-Examples
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[apache/datafusion]]></title>
            <link>https://github.com/apache/datafusion</link>
            <guid>https://github.com/apache/datafusion</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:38 GMT</pubDate>
            <description><![CDATA[Apache DataFusion SQL Query Engine]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/apache/datafusion">apache/datafusion</a></h1>
            <p>Apache DataFusion SQL Query Engine</p>
            <p>Language: Rust</p>
            <p>Stars: 7,006</p>
            <p>Forks: 1,442</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;!---
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  &quot;License&quot;); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing,
  software distributed under the License is distributed on an
  &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  KIND, either express or implied.  See the License for the
  specific language governing permissions and limitations
  under the License.
--&gt;

# Apache DataFusion

[![Crates.io][crates-badge]][crates-url]
[![Apache licensed][license-badge]][license-url]
[![Build Status][actions-badge]][actions-url]
![Commit Activity][commit-activity-badge]
[![Open Issues][open-issues-badge]][open-issues-url]
[![Discord chat][discord-badge]][discord-url]
[![Linkedin][linkedin-badge]][linkedin-url]

[crates-badge]: https://img.shields.io/crates/v/datafusion.svg
[crates-url]: https://crates.io/crates/datafusion
[license-badge]: https://img.shields.io/badge/license-Apache%20v2-blue.svg
[license-url]: https://github.com/apache/datafusion/blob/main/LICENSE.txt
[actions-badge]: https://github.com/apache/datafusion/actions/workflows/rust.yml/badge.svg
[actions-url]: https://github.com/apache/datafusion/actions?query=branch%3Amain
[discord-badge]: https://img.shields.io/badge/Chat-Discord-purple
[discord-url]: https://discord.com/invite/Qw5gKqHxUM
[commit-activity-badge]: https://img.shields.io/github/commit-activity/m/apache/datafusion
[open-issues-badge]: https://img.shields.io/github/issues-raw/apache/datafusion
[open-issues-url]: https://github.com/apache/datafusion/issues
[linkedin-badge]: https://img.shields.io/badge/Follow-Linkedin-blue
[linkedin-url]: https://www.linkedin.com/company/apache-datafusion/

[Website](https://datafusion.apache.org/) |
[API Docs](https://docs.rs/datafusion/latest/datafusion/) |
[Chat](https://discord.com/channels/885562378132000778/885562378132000781)

&lt;a href=&quot;https://datafusion.apache.org/&quot;&gt;
  &lt;img src=&quot;https://github.com/apache/datafusion/raw/HEAD/docs/source/_static/images/2x_bgwhite_original.png&quot; width=&quot;512&quot; alt=&quot;logo&quot;/&gt;
&lt;/a&gt;

DataFusion is an extensible query engine written in [Rust] that
uses [Apache Arrow] as its in-memory format.

This crate provides libraries and binaries for developers building fast and
feature rich database and analytic systems, customized to particular workloads.
See [use cases] for examples. The following related subprojects target end users:

- [DataFusion Python](https://github.com/apache/datafusion-python/) offers a Python interface for SQL and DataFrame
  queries.
- [DataFusion Ray](https://github.com/apache/datafusion-ray/) provides a distributed version of DataFusion that scales
  out on Ray clusters.
- [DataFusion Comet](https://github.com/apache/datafusion-comet/) is an accelerator for Apache Spark based on
  DataFusion.

&quot;Out of the box,&quot;
DataFusion offers [SQL] and [`Dataframe`] APIs, excellent [performance],
built-in support for CSV, Parquet, JSON, and Avro, extensive customization, and
a great community.

DataFusion features a full query planner, a columnar, streaming, multi-threaded,
vectorized execution engine, and partitioned data sources. You can
customize DataFusion at almost all points including additional data sources,
query languages, functions, custom operators and more.
See the [Architecture] section for more details.

[rust]: http://rustlang.org
[apache arrow]: https://arrow.apache.org
[use cases]: https://datafusion.apache.org/user-guide/introduction.html#use-cases
[python bindings]: https://github.com/apache/datafusion-python
[performance]: https://benchmark.clickhouse.com/
[architecture]: https://datafusion.apache.org/contributor-guide/architecture.html

Here are links to some important information

- [Project Site](https://datafusion.apache.org/)
- [Installation](https://datafusion.apache.org/user-guide/cli/installation.html)
- [Rust Getting Started](https://datafusion.apache.org/user-guide/example-usage.html)
- [Rust DataFrame API](https://datafusion.apache.org/user-guide/dataframe.html)
- [Rust API docs](https://docs.rs/datafusion/latest/datafusion)
- [Rust Examples](https://github.com/apache/datafusion/tree/main/datafusion-examples)
- [Python DataFrame API](https://arrow.apache.org/datafusion-python/)
- [Architecture](https://docs.rs/datafusion/latest/datafusion/index.html#architecture)

## What can you do with this crate?

DataFusion is great for building projects such as domain specific query engines, new database platforms and data pipelines, query languages and more.
It lets you start quickly from a fully working engine, and then customize those features specific to your use. [Click Here](https://datafusion.apache.org/user-guide/introduction.html#known-users) to see a list known users.

## Contributing to DataFusion

Please see the [contributor guide] and [communication] pages for more information.

[contributor guide]: https://datafusion.apache.org/contributor-guide
[communication]: https://datafusion.apache.org/contributor-guide/communication.html

## Crate features

This crate has several [features] which can be specified in your `Cargo.toml`.

[features]: https://doc.rust-lang.org/cargo/reference/features.html

Default features:

- `nested_expressions`: functions for working with nested type function such as `array_to_string`
- `compression`: reading files compressed with `xz2`, `bzip2`, `flate2`, and `zstd`
- `crypto_expressions`: cryptographic functions such as `md5` and `sha256`
- `datetime_expressions`: date and time functions such as `to_timestamp`
- `encoding_expressions`: `encode` and `decode` functions
- `parquet`: support for reading the [Apache Parquet] format
- `regex_expressions`: regular expression functions, such as `regexp_match`
- `unicode_expressions`: Include unicode aware functions such as `character_length`
- `unparser`: enables support to reverse LogicalPlans back into SQL
- `recursive_protection`: uses [recursive](https://docs.rs/recursive/latest/recursive/) for stack overflow protection.

Optional features:

- `avro`: support for reading the [Apache Avro] format
- `backtrace`: include backtrace information in error messages
- `pyarrow`: conversions between PyArrow and DataFusion types
- `serde`: enable arrow-schema&#039;s `serde` feature

[apache avro]: https://avro.apache.org/
[apache parquet]: https://parquet.apache.org/

## Rust Version Compatibility Policy

The Rust toolchain releases are tracked at [Rust Versions](https://releases.rs) and follow
[semantic versioning](https://semver.org/). A Rust toolchain release can be identified
by a version string like `1.80.0`, or more generally `major.minor.patch`.

DataFusion&#039;s supports the last 4 stable Rust minor versions released and any such versions released within the last 4 months.

For example, given the releases `1.78.0`, `1.79.0`, `1.80.0`, `1.80.1` and `1.81.0` DataFusion will support 1.78.0, which is 3 minor versions prior to the most minor recent `1.81`.

Note: If a Rust hotfix is released for the current MSRV, the MSRV will be updated to the specific minor version that includes all applicable hotfixes preceding other policies.

DataFusion enforces MSRV policy using a [MSRV CI Check](https://github.com/search?q=repo%3Aapache%2Fdatafusion+rust-version+language%3ATOML+path%3A%2F%5ECargo.toml%2F&amp;type=code)

## DataFusion API Evolution and Deprecation Guidelines

Public methods in Apache DataFusion evolve over time: while we try to maintain a
stable API, we also improve the API over time. As a result, we typically
deprecate methods before removing them, according to the [deprecation guidelines].

[deprecation guidelines]: https://datafusion.apache.org/library-user-guide/api-health.html

## Dependencies and `Cargo.lock`

Following the [guidance] on committing `Cargo.lock` files, this project commits
its `Cargo.lock` file.

CI uses the committed `Cargo.lock` file, and dependencies are updated regularly
using [Dependabot] PRs.

[guidance]: https://blog.rust-lang.org/2023/08/29/committing-lockfiles.html
[dependabot]: https://docs.github.com/en/code-security/dependabot/working-with-dependabot
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[leptos-rs/leptos]]></title>
            <link>https://github.com/leptos-rs/leptos</link>
            <guid>https://github.com/leptos-rs/leptos</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:37 GMT</pubDate>
            <description><![CDATA[Build fast web applications with Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/leptos-rs/leptos">leptos-rs/leptos</a></h1>
            <p>Build fast web applications with Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 18,146</p>
            <p>Forks: 733</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
    &lt;source srcset=&quot;https://raw.githubusercontent.com/leptos-rs/leptos/main/docs/logos/Leptos_logo_pref_dark_RGB.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/leptos-rs/leptos/main/docs/logos/Leptos_logo_RGB.svg&quot; alt=&quot;Leptos Logo&quot;&gt;
&lt;/picture&gt;

[![crates.io](https://img.shields.io/crates/v/leptos.svg)](https://crates.io/crates/leptos)
[![docs.rs](https://docs.rs/leptos/badge.svg)](https://docs.rs/leptos)
![Crates.io MSRV](https://img.shields.io/crates/msrv/leptos)
[![Discord](https://img.shields.io/discord/1031524867910148188?color=%237289DA&amp;label=discord)](https://discord.gg/YdRAhS7eQB)
[![Matrix](https://img.shields.io/badge/Matrix-leptos-grey?logo=matrix&amp;labelColor=white&amp;logoColor=black)](https://matrix.to/#/#leptos:matrix.org)

[Website](https://leptos.dev) | [Book](https://leptos-rs.github.io/leptos/) | [Docs.rs](https://docs.rs/leptos/latest/leptos/) | [Playground](https://codesandbox.io/p/sandbox/leptos-rtfggt?file=%2Fsrc%2Fmain.rs%3A1%2C1) | [Discord](https://discord.gg/YdRAhS7eQB)

You can find a list of useful libraries and example projects at [`awesome-leptos`](https://github.com/leptos-rs/awesome-leptos).

# Leptos

```rust
use leptos::*;

#[component]
pub fn SimpleCounter(initial_value: i32) -&gt; impl IntoView {
    // create a reactive signal with the initial value
    let (value, set_value) = signal(initial_value);

    // create event handlers for our buttons
    // note that `value` and `set_value` are `Copy`, so it&#039;s super easy to move them into closures
    let clear = move |_| set_value(0);
    let decrement = move |_| set_value.update(|value| *value -= 1);
    let increment = move |_| set_value.update(|value| *value += 1);

    // create user interfaces with the declarative `view!` macro
    view! {
        &lt;div&gt;
            &lt;button on:click=clear&gt;Clear&lt;/button&gt;
            &lt;button on:click=decrement&gt;-1&lt;/button&gt;
            // text nodes can be quoted or unquoted
            &lt;span&gt;&quot;Value: &quot; {value} &quot;!&quot;&lt;/span&gt;
            &lt;button on:click=increment&gt;+1&lt;/button&gt;
        &lt;/div&gt;
    }
}

// we also support a builder syntax rather than the JSX-like `view` macro
#[component]
pub fn SimpleCounterWithBuilder(initial_value: i32) -&gt; impl IntoView {
    use leptos::html::*;

    let (value, set_value) = signal(initial_value);
    let clear = move |_| set_value(0);
    let decrement = move |_| set_value.update(|value| *value -= 1);
    let increment = move |_| set_value.update(|value| *value += 1);

    // the `view` macro above expands to this builder syntax
    div().child((
        button().on(ev::click, clear).child(&quot;Clear&quot;),
        button().on(ev::click, decrement).child(&quot;-1&quot;),
        span().child((&quot;Value: &quot;, value, &quot;!&quot;)),
        button().on(ev::click, increment).child(&quot;+1&quot;)
    ))
}

// Easy to use with Trunk (trunkrs.dev) or with a simple wasm-bindgen setup
pub fn main() {
    mount_to_body(|| view! {
        &lt;SimpleCounter initial_value=3 /&gt;
    })
}
```

## About the Framework

Leptos is a full-stack, isomorphic Rust web framework leveraging fine-grained reactivity to build declarative user interfaces.

## What does that mean?

- **Full-stack**: Leptos can be used to build apps that run in the browser (client-side rendering), on the server (server-side rendering), or by rendering HTML on the server and then adding interactivity in the browser (server-side rendering with hydration). This includes support for HTTP streaming of both data ([`Resource`s](https://docs.rs/leptos/latest/leptos/struct.Resource.html)) and HTML (out-of-order or in-order streaming of [`&lt;Suspense/&gt;`](https://docs.rs/leptos/latest/leptos/fn.Suspense.html) components.)
- **Isomorphic**: Leptos provides primitives to write isomorphic [server functions](https://docs.rs/leptos_server/0.2.5/leptos_server/index.html), i.e., functions that can be called with the ‚Äúsame shape‚Äù on the client or server, but only run on the server. This means you can write your server-only logic (database requests, authentication etc.) alongside the client-side components that will consume it, and call server functions as if they were running in the browser, without needing to create and maintain a separate REST or other API.
- **Web**: Leptos is built on the Web platform and Web standards. The [router](https://docs.rs/leptos_router/latest/leptos_router/) is designed to use Web fundamentals (like links and forms) and build on top of them rather than trying to replace them.
- **Framework**: Leptos provides most of what you need to build a modern web app: a reactive system, templating library, and a router that works on both the server and client side.
- **Fine-grained reactivity**: The entire framework is built from reactive primitives. This allows for extremely performant code with minimal overhead: when a reactive signal‚Äôs value changes, it can update a single text node, toggle a single class, or remove an element from the DOM without any other code running. (So, no virtual DOM overhead!)
- **Declarative**: Tell Leptos how you want the page to look, and let the framework tell the browser how to do it.

## Learn more

Here are some resources for learning more about Leptos:

- [Book](https://leptos-rs.github.io/leptos/) (work in progress)
- [Examples](https://github.com/leptos-rs/leptos/tree/main/examples)
- [API Documentation](https://docs.rs/leptos/latest/leptos/)
- [Common Bugs](https://github.com/leptos-rs/leptos/tree/main/docs/COMMON_BUGS.md) (and how to fix them!)

## `nightly` Note

Most of the examples assume you‚Äôre using `nightly` version of Rust and the `nightly` feature of Leptos. To use `nightly` Rust, you can either set your toolchain globally or on per-project basis.

To set `nightly` as a default toolchain for all projects (and add the ability to compile Rust to WebAssembly, if you haven‚Äôt already):

```
rustup toolchain install nightly
rustup default nightly
rustup target add wasm32-unknown-unknown
```

If you&#039;d like to use `nightly` only in your Leptos project however, add [`rust-toolchain.toml`](https://rust-lang.github.io/rustup/overrides.html#the-toolchain-file) file with the following content:

```toml
[toolchain]
channel = &quot;nightly&quot;
targets = [&quot;wasm32-unknown-unknown&quot;]
```

The `nightly` feature enables the function call syntax for accessing and setting signals, as opposed to `.get()` and `.set()`. This leads to a consistent mental model in which accessing a reactive value of any kind (a signal, memo, or derived signal) is always represented as a function call. This is only possible with nightly Rust and the `nightly` feature.

## `cargo-leptos`

[`cargo-leptos`](https://github.com/leptos-rs/cargo-leptos) is a build tool that&#039;s designed to make it easy to build apps that run on both the client and the server, with seamless integration. The best way to get started with a real Leptos project right now is to use `cargo-leptos` and our starter templates for [Actix](https://github.com/leptos-rs/start) or [Axum](https://github.com/leptos-rs/start-axum).

```bash
cargo install cargo-leptos
cargo leptos new --git https://github.com/leptos-rs/start
cd [your project name]
cargo leptos watch
```

Open browser to [http://localhost:3000/](http://localhost:3000/).

## FAQs

### What‚Äôs up with the name?

_Leptos_ (ŒªŒµœÄœÑœåœÇ) is an ancient Greek word meaning ‚Äúthin, light, refined, fine-grained.‚Äù To me, a classicist and not a dog owner, it evokes the lightweight reactive system that powers the framework. I&#039;ve since learned the same word is at the root of the medical term ‚Äúleptospirosis,‚Äù a blood infection that affects humans and animals... My bad. No dogs were harmed in the creation of this framework.

### Is it production ready?

People usually mean one of three things by this question.

1. **Are the APIs stable?** i.e., will I have to rewrite my whole app from Leptos 0.1 to 0.2 to 0.3 to 0.4, or can I write it now and benefit from new features and updates as new versions come?

The APIs are basically settled. We‚Äôre adding new features, but we‚Äôre very happy with where the type system and patterns have landed. I would not expect major breaking changes to your code to adapt to future releases, in terms of architecture.

2. **Are there bugs?**

Yes, I‚Äôm sure there are. You can see from the state of our issue tracker over time that there aren‚Äôt that _many_ bugs and they‚Äôre usually resolved pretty quickly. But for sure, there may be moments where you encounter something that requires a fix at the framework level, which may not be immediately resolved.

3. **Am I a consumer or a contributor?**

This may be the big one: ‚Äúproduction ready‚Äù implies a certain orientation to a library: that you can basically use it, without any special knowledge of its internals or ability to contribute. Everyone has this at some level in their stack: for example I (@gbj) don‚Äôt have the capacity or knowledge to contribute to something like `wasm-bindgen` at this point: I simply rely on it to work.

There are several people in the community using Leptos right now for internal apps at work, who have also become significant contributors. I think this is the right level of production use for now. There may be missing features that you need, and you may end up building them! But for internal apps, if you‚Äôre willing to build and contribute missing pieces along the way, the framework is definitely usable right now.

### Can I use this for native GUI?

Sure! Obviously the `view` macro is for generating DOM nodes but you can use the reactive system to drive any native GUI toolkit that uses the same kind of object-oriented, event-callback-based framework as the DOM pretty easily. The principles are the same:

- Use signals, derived signals, and memos to create your reactive system
- Create GUI widgets
- Use event listeners to update signals
- Create effects to update the UI

The 0.7 update originally set out to create a &quot;generic rendering&quot; approach that would allow us to reuse most of the same view logic to do all of the above. Unfortunately, this has had to be shelved for now due to difficulties encountered by the Rust compiler when building larger-scale applications with the number of generics spread throughout the codebase that this required. It&#039;s an approach I&#039;m looking forward to exploring again in the future; feel free to reach out if you&#039;re interested in this kind of work.

### How is this different from Yew?

Yew is the most-used library for Rust web UI development, but there are several differences between Yew and Leptos, in philosophy, approach, and performance.

- **VDOM vs. fine-grained:** Yew is built on the virtual DOM (VDOM) model: state changes cause components to re-render, generating a new virtual DOM tree. Yew diffs this against the previous VDOM, and applies those patches to the actual DOM. Component functions rerun whenever state changes. Leptos takes an entirely different approach. Components run once, creating (and returning) actual DOM nodes and setting up a reactive system to update those DOM nodes.
- **Performance:** This has huge performance implications: Leptos is simply much faster at both creating and updating the UI than Yew is.
- **Server integration:** Yew was created in an era in which browser-rendered single-page apps (SPAs) were the dominant paradigm. While Leptos supports client-side rendering, it also focuses on integrating with the server side of your application via server functions and multiple modes of serving HTML, including out-of-order streaming.

### How is this different from Dioxus?

Like Leptos, Dioxus is a framework for building UIs using web technologies. However, there are significant differences in approach and features.

- **VDOM vs. fine-grained:** While Dioxus has a performant virtual DOM (VDOM), it still uses coarse-grained/component-scoped reactivity: changing a stateful value reruns the component function and diffs the old UI against the new one. Leptos components use a different mental model, creating (and returning) actual DOM nodes and setting up a reactive system to update those DOM nodes.
- **Web vs. desktop priorities:** Dioxus uses Leptos server functions in its fullstack mode, but does not have the same `&lt;Suspense&gt;`-based support for things like streaming HTML rendering, or share the same focus on holistic web performance. Leptos tends to prioritize holistic web performance (streaming HTML rendering, smaller WASM binary sizes, etc.), whereas Dioxus has an unparalleled experience when building desktop apps, because your application logic runs as a native Rust binary.

### How is this different from Sycamore?

Sycamore and Leptos are both heavily influenced by SolidJS. At this point, Leptos has a larger community and ecosystem and is more actively developed. Other differences:

- **Templating DSLs:** Sycamore uses a custom templating language for its views, while Leptos uses a JSX-like template format.
- **`&#039;static` signals:** One of Leptos‚Äôs main innovations was the creation of `Copy + &#039;static` signals, which have excellent ergonomics. Sycamore is in the process of adopting the same pattern, but this is not yet released.
- **Perseus vs. server functions:** The Perseus metaframework provides an opinionated way to build Sycamore apps that include server functionality. Leptos instead provides primitives like server functions in the core of the framework.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[unionlabs/union]]></title>
            <link>https://github.com/unionlabs/union</link>
            <guid>https://github.com/unionlabs/union</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[The trust-minimized, zero-knowledge bridging protocol, designed for censorship resistance, extremely high security, and usage in decentralized finance.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/unionlabs/union">unionlabs/union</a></h1>
            <p>The trust-minimized, zero-knowledge bridging protocol, designed for censorship resistance, extremely high security, and usage in decentralized finance.</p>
            <p>Language: Rust</p>
            <p>Stars: 53,487</p>
            <p>Forks: 2,691</p>
            <p>Stars today: 207 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./.github/images/union-logo-white.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./.github/images/union-logo-black.svg&quot;&gt;
    &lt;img alt=&quot;Union&quot;
         src=&quot;./.github/images/union-logo-black.svg&quot;
         width=&quot;100%&quot;&gt;
  &lt;/picture&gt;
&lt;/div&gt;

&lt;br/&gt;

&lt;div align=&quot;center&quot;&gt;

[![built with garnix](https://img.shields.io/endpoint.svg?url=https%3A%2F%2Fgarnix.io%2Fapi%2Fbadges%2Funionlabs%2Funion%3Fbranch%3Dmain)](https://garnix.io)
[![Docs](https://img.shields.io/badge/docs-main-blue)][docs]
[![Discord badge]](https://discord.union.build)
[![Twitter handle]][twitter badge]

&lt;/div&gt;

Union is the hyper-efficient zero-knowledge infrastructure layer for general message passing, asset transfers, NFTs, and DeFi. It‚Äôs based on [Consensus Verification] and has no dependencies on trusted third parties, oracles, multi-signatures, or MPC. It implements [IBC] for compatibility with [Cosmos] chains and connects to EVM chains like [Ethereum], [Berachain (beacon-kit)](https://github.com/berachain/beacon-kit), [Arbitrum], and more.

The upgradability of contracts on other chains, connections, token configurations, and evolution of the protocol will all be controlled by decentralized governance, aligning the priorities of Union with its users, validators, and operators.

## Components

| Component                                             | Description                                          | Language(s)           |
| ----------------------------------------------------- | ---------------------------------------------------- | --------------------- |
| [`uniond`](./uniond/README.md)                        | The Union node implementation, using [`CometBLS`]    | [Go]                  |
| [`galoisd`](./galoisd)                                | The zero-knowledge prover implementation             | [Go] [Gnark]          |
| [`voyager`](./voyager)                                | Modular hyper-performant cross-ecosystem relayer     | [Rust]                |
| [`hubble`](./hubble)                                  | Multi-ecosystem, GMP-enabled chain indexer           | [Rust]                |
| [`cosmwasm`](./cosmwasm)                              | [CosmWasm] smart contract stack                      | [Rust]                |
| [`light-clients`](./cosmwasm/ibc-union/lightclient)   | [Light Clients] for various ecosystems               | [Rust]                |
| [`unionvisor`](./unionvisor/README.md)                | Node supervisor intended for production usage        | [Rust]                |
| [`drip`](./drip)                                      | Faucet for [Cosmos] chains: [app.union.build/faucet] | [Rust]                |
| [`evm`](./evm)                                        | [EVM] smart contract stack                           | [Solidity]            |
| [`app`](./app)                                        | [app.union.build]                                    | [TypeScript] [Svelte] |
| [`site`](./site)                                      | [union.build]                                        | [TypeScript] [Astro]  |
| [`TypeScript SDK`](./typescript-sdk)                  | TypeScript SDK for interacting with Union            | [TypeScript]          |

## Quickstart

Install [Nix] to _[reproducibly build](https://en.wikipedia.org/wiki/Reproducible_builds) any component_, and to enter a dev shell with _all dependencies_:

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf -L https://install.determinate.systems/nix | sh -s -- install
```

_(Note that some components can only be built on Linux. If you are using macOS, we recommend using [OrbStack] to easily set up a [NixOS] VM within two minutes. Most Union developers use macOS with [OrbStack], and there is no need to install Nix inside of the [NixOS] VM.)_

You can now _reproducibly_ build any of Union&#039;s components from source:

```sh
nix build .#uniond -L
nix build .#voyager -L
nix build .#app -L

# to see all packages, run:
nix flake show
```

The result of whatever you build will be in `result/`

You can now also enter our dev shell, which has all of the dependencies (`cargo`, `rustc`, `node`, `go`, etc.) you need to work on any component:
_(Don&#039;t worry, this will not affect your system outside of this repo)_

```sh
nix develop
```

Run the following to format the entire repo and check your spelling before each PR:

```sh
nix run .#pre-commit -L
```

Check the `#developers` channel on [Union&#039;s discord](https://discord.union.build) if you need any help with this.

## Docs

The official docs are hosted [here][docs]. Each individual component also has accompanying developer documentation for contributors, which you can find in each `README.md`.

[app.union.build]: https://app.union.build
[app.union.build/faucet]: https://app.union.build/faucet
[arbitrum]: https://github.com/OffchainLabs/arbitrum
[astro]: https://astro.build
[consensus verification]: https://union.build/docs/concepts/consensus-verification/
[cosmos]: https://cosmos.network
[cosmwasm]: https://cosmwasm.com/
[discord badge]: https://img.shields.io/discord/1158939416870522930?logo=discord
[docs]: https://docs.union.build &quot;Official Union Docs&quot;
[ethereum]: https://ethereum.org
[evm]: https://ethereum.org/en/developers/docs/evm/
[gnark]: https://github.com/ConsenSys/gnark
[go]: https://go.dev/
[ibc]: https://github.com/cosmos/ibc &quot;cosmos/ibc&quot;
[light clients]: https://a16zcrypto.com/posts/article/an-introduction-to-light-clients/
[nix]: https://zero-to-nix.com/
[nixos]: https://nixos.org
[orbstack]: https://orbstack.dev/
[rust]: https://www.rust-lang.org/
[solidity]: https://soliditylang.org/
[svelte]: https://svelte.dev
[twitter badge]: https://twitter.com/intent/follow?screen_name=union_build
[twitter handle]: https://img.shields.io/twitter/follow/union_build.svg?style=social&amp;label=Follow
[typescript]: https://www.typescriptlang.org/
[union.build]: https://union.build
[`cometbls`]: https://github.com/unionlabs/cometbls
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vectordotdev/vector]]></title>
            <link>https://github.com/vectordotdev/vector</link>
            <guid>https://github.com/vectordotdev/vector</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[A high-performance observability data pipeline.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vectordotdev/vector">vectordotdev/vector</a></h1>
            <p>A high-performance observability data pipeline.</p>
            <p>Language: Rust</p>
            <p>Stars: 19,139</p>
            <p>Forks: 1,717</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://vector.dev/docs/setup/quickstart/&quot;&gt;Quickstart&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/docs/&quot;&gt;Docs&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/guides/&quot;&gt;Guides&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/components/&quot;&gt;Integrations&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://chat.vector.dev&quot;&gt;Chat&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/releases/latest/download/&quot;&gt;Download&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://rust-doc.vector.dev/&quot;&gt;Rust Crate Docs&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;website/static/img/diagram.svg&quot; alt=&quot;Vector&quot;&gt;
&lt;/p&gt;

## What is Vector?

Vector is a high-performance, end-to-end (agent &amp; aggregator) observability data
pipeline that puts you in control of your observability data.
[Collect][docs.sources], [transform][docs.transforms], and [route][docs.sinks]
all your logs and metrics to any vendors you want today and any other
vendors you may want tomorrow. Vector enables dramatic cost reduction, novel
data enrichment, and data security where you need it, not where it is most
convenient for your vendors. Additionally, it is open source and up to 10x
faster than every alternative in the space.

To get started, follow our [**quickstart guide**][docs.quickstart] or [**install
Vector**][docs.installation].

### Principles

* **Reliable** - Built in [Rust][urls.rust], Vector&#039;s primary design goal is reliability.
* **End-to-end** - Deploys as an [agent][docs.roles#agent] or [aggregator][docs.roles#aggregator]. Vector is a complete platform.
* **Unified** - [Logs][docs.data-model.log], [metrics][docs.data-model.metric] (beta), and traces (coming soon). One tool for all of your data.

### Use cases

* Reduce total observability costs.
* Transition vendors without disrupting workflows.
* Enhance data quality and improve insights.
* Consolidate agents and eliminate agent fatigue.
* Improve overall observability performance and reliability.

### Community

* Vector is relied on by startups and enterprises like **Atlassian**, **T-Mobile**,
  **Comcast**, **Zendesk**, **Discord**, **Fastly**, **CVS**, **Trivago**,
  **Tuple**, **Douban**, **Visa**, **Mambu**, **Blockfi**, **Claranet**,
  **Instacart**, **Forcepoint**, and [many more][urls.production_users].
* Vector is **downloaded over 100,000 times per day**.
* Vector&#039;s largest user **processes over 30TB daily**.
* Vector has **over 100 contributors** and growing.

## [Documentation](https://vector.dev/docs/)

### About

* [**Concepts**][docs.about.concepts]
* [**Under the hood**][docs.about.under-the-hood]
  * [**Architecture**][docs.under-the-hood.architecture] - [data model][docs.architecture.data-model] ([log][docs.data-model.log], [metric][docs.data-model.metric]), [pipeline model][docs.architecture.pipeline-model], [concurrency model][docs.architecture.concurrency-model], [runtime model][docs.architecture.runtime-model]
  * [**Networking**][docs.under-the-hood.networking] - [ARC][docs.networking.adaptive-request-concurrency]
  * [**Guarantees**][docs.under-the-hood.guarantees]

### Setup

* [**Quickstart**][docs.setup.quickstart]
* [**Installation**][docs.setup.installation] - [operating systems][docs.installation.operating_systems], [package managers][docs.installation.package_managers], [platforms][docs.installation.platforms] ([Kubernetes][docs.platforms.kubernetes]), [manual][docs.installation.manual]
* [**Deployment**][docs.deployment] - [roles][docs.deployment.roles], [topologies][docs.deployment.topologies]

### Reference

* **Configuration**
  * [**Sources**][docs.configuration.sources] - [docker_logs][docs.sources.docker_logs], [file][docs.sources.file], [http][docs.sources.http], [journald][docs.sources.journald], [kafka][docs.sources.kafka], [socket][docs.sources.socket], and [many more...][docs.sources]
  * [**Transforms**][docs.configuration.transforms] - [dedupe][docs.transforms.dedupe], [filter][docs.transforms.filter], [log_to_metric][docs.transforms.log_to_metric], [lua][docs.transforms.lua], [remap][docs.transforms.remap],
    and [many more...][docs.transforms]
  * [**Sinks**][docs.configuration.sinks] - [aws_cloudwatch_logs][docs.sinks.aws_cloudwatch_logs], [aws_s3][docs.sinks.aws_s3], [clickhouse][docs.sinks.clickhouse], [elasticsearch][docs.sinks.elasticsearch], [gcp_cloud_storage][docs.sinks.gcp_cloud_storage], and [many more...][docs.sinks]
  * [**Enrichment Tables**][docs.configuration.enrichment_tables]
  * [**Unit tests**][docs.configuration.tests]
* [**Remap Language**][docs.reference.vrl]
* [**API**][docs.reference.api]
* [**CLI**][docs.reference.cli]

### Administration

* [**Management**][docs.administration.management]
* [**Monitoring &amp; observing**][docs.administration.monitoring]
* [**Upgrading**][docs.administration.upgrading]
* [**Validating**][docs.administration.validating]

### Resources

* [**Community**][urls.vector_community] - [chat][urls.vector_chat], [calendar][urls.vector_calendar], [@vectordotdev][urls.vector_twitter]
* [**Releases**][urls.vector_releases]
* **Policies** - [Code of Conduct][urls.vector_code_of_conduct], [Privacy][urls.vector_privacy_policy], [Releases][urls.vector_releases_policy], [Security][urls.vector_security_policy], [Versioning][urls.vector_versioning_policy]

## Comparisons

### Performance

The following performance tests demonstrate baseline performance between
common protocols with the exception of the Regex Parsing test.

| Test                                                                                                                   | Vector          | Filebeat | FluentBit       | FluentD   | Logstash  | SplunkUF        | SplunkHF |
| ---------------------------------------------------------------------------------------------------------------------- | --------------- | -------- | --------------- | --------- | --------- | --------------- | -------- |
| [TCP to Blackhole](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance) | _**86mib/s**_   | n/a      | 64.4mib/s       | 27.7mib/s | 40.6mib/s | n/a             | n/a      |
| [File to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance)           | _**76.7mib/s**_ | 7.8mib/s | 35mib/s         | 26.1mib/s | 3.1mib/s  | 40.1mib/s       | 39mib/s  |
| [Regex Parsing](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance)       | 13.2mib/s       | n/a      | _**20.5mib/s**_ | 2.6mib/s  | 4.6mib/s  | n/a             | 7.8mib/s |
| [TCP to HTTP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance)           | _**26.7mib/s**_ | n/a      | 19.6mib/s       | &lt;1mib/s   | 2.7mib/s  | n/a             | n/a      |
| [TCP to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance)             | 69.9mib/s       | 5mib/s   | 67.1mib/s       | 3.9mib/s  | 10mib/s   | _**70.4mib/s**_ | 7.6mib/s |

To learn more about our performance tests, please see the [Vector test harness][urls.vector_test_harness].

### Correctness

The following correctness tests are not exhaustive, but they demonstrate
fundamental differences in quality and attention to detail:

| Test                                                                                                                                 | Vector | Filebeat | FluentBit | FluentD | Logstash | Splunk UF | Splunk HF |
| ------------------------------------------------------------------------------------------------------------------------------------ | ------ | -------- | --------- | ------- | -------- | --------- | --------- |
| [Disk Buffer Persistence](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness) | **‚úì**  | ‚úì        |           |         | ‚ö†        | ‚úì         | ‚úì         |
| [File Rotate (create)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness)         | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |
| [File Rotate (copytruncate)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness) | **‚úì**  |          |           |         |          | ‚úì         | ‚úì         |
| [File Truncation](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness)                   | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |
| [Process (SIGHUP)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness)                         | **‚úì**  |          |           |         | ‚ö†        | ‚úì         | ‚úì         |
| [JSON (wrapped)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness)                     | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |

To learn more about our correctness tests, please see the [Vector test harness][urls.vector_test_harness].

### Features

Vector is an end-to-end, unified, open data platform.

|                     | **Vector** | Beats | Fluentbit | Fluentd | Logstash | Splunk UF | Splunk HF | Telegraf |
| ------------------- | ---------- | ----- | --------- | ------- | -------- | --------- | --------- | -------- |
| **End-to-end**      | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Agent               | **‚úì**      | ‚úì     | ‚úì         |         |          | ‚úì         |           | ‚úì        |
| Aggregator          | **‚úì**      |       |           | ‚úì       | ‚úì        |           | ‚úì         | ‚úì        |
| **Unified**         | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Logs                | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         | ‚úì        |
| Metrics             | **‚úì**      | ‚ö†     | ‚ö†         | ‚ö†       | ‚ö†        | ‚ö†         | ‚ö†         | ‚úì        |
| Traces              | üöß         |       |           |         |          |           |           |          |
| **Open**            | **‚úì**      |       | ‚úì         | ‚úì       |          |           |           | ‚úì        |
| Open-source         | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        |           |           | ‚úì        |
| Vendor-neutral      | **‚úì**      |       | ‚úì         | ‚úì       |          |           |           | ‚úì        |
| **Reliability**     | **‚úì**      |       |           |         |          |           |           |          |
| Memory-safe         | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Delivery guarantees | **‚úì**      |       |           |         |          | ‚úì         | ‚úì         |          |
| Multi-core          | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         | ‚úì        |


‚ö† = Not interoperable, metrics are represented as structured logs

---

&lt;p align=&quot;center&quot;&gt;
  Developed with ‚ù§Ô∏è by &lt;strong&gt;&lt;a href=&quot;https://datadoghq.com&quot;&gt;Datadog&lt;/a&gt;&lt;/strong&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/security/policy&quot;&gt;Security Policy&lt;/a&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/blob/master/PRIVACY.md&quot;&gt;Privacy Policy&lt;/a&gt;
&lt;/p&gt;

[docs.about.concepts]: https://vector.dev/docs/about/concepts/
[docs.about.under-the-hood]: https://vector.dev/docs/about/under-the-hood/
[docs.administration.monitoring]: https://vector.dev/docs/administration/monitoring/
[docs.administration.management]: https://vector.dev/docs/administration/management/
[docs.administration.upgrading]: https://vector.dev/docs/administration/upgrading/
[docs.administration.validating]: https://vector.dev/docs/administration/validating/
[docs.architecture.concurrency-model]: https://vector.dev/docs/about/under-the-hood/architecture/concurrency-model/
[docs.architecture.data-model]: https://vector.dev/docs/about/under-the-hood/architecture/data-model/
[docs.architecture.pipeline-model]: https://vector.dev/docs/about/under-the-hood/architecture/pipeline-model/
[docs.architecture.runtime-model]: https://vector.dev/docs/about/under-the-hood/architecture/runtime-model/
[docs.configuration.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.configuration.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.configuration.tests]: https://vector.dev/docs/reference/configuration/tests/
[docs.configuration.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.configuration.enrichment_tables]: https://vector.dev/docs/reference/configuration/global-options/#enrichment_tables
[docs.data-model.log]: https://vector.dev/docs/about/under-the-hood/architecture/data-model/log/
[docs.data-model.metric]: https://vector.dev/docs/about/under-the-hood/architecture/data-model/metric/
[docs.deployment.roles]: https://vector.dev/docs/setup/deployment/roles/
[docs.deployment.topologies]: https://vector.dev/docs/setup/deployment/topologies/
[docs.deployment]: https://vector.dev/docs/setup/deployment/
[docs.installation.manual]: https://vector.dev/docs/setup/installation/manual/
[docs.installation.operating_systems]: https://vector.dev/docs/setup/installation/operating-systems/
[docs.installation.package_managers]: https://vector.dev/docs/setup/installation/package-managers/
[docs.installation.platforms]: https://vector.dev/docs/setup/installation/platforms/
[docs.installation]: https://vector.dev/docs/setup/installation/
[docs.networking.adaptive-request-concurrency]: https://vector.dev/docs/about/under-the-hood/networking/arc/
[docs.platforms.kubernetes]: https://vector.dev/docs/setup/installation/platforms/kubernetes/
[docs.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.reference.api]: https://vector.dev/docs/reference/api/
[docs.reference.cli]: https://vector.dev/docs/reference/cli/
[docs.reference.vrl]: https://vector.dev/docs/reference/vrl/
[docs.roles#agent]: https://vector.dev/docs/setup/deployment/roles/#agent
[docs.roles#aggregator]: https://vector.dev/docs/setup/deployment/roles/#aggregator
[docs.setup.installation]: https://vector.dev/docs/setup/installation/
[docs.setup.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.sinks.aws_cloudwatch_logs]: https://vector.dev/docs/reference/configuration/sinks/aws_cloudwatch_logs/
[docs.sinks.aws_s3]: https://vector.dev/docs/reference/configuration/sinks/aws_s3/
[docs.sinks.clickhouse]: https://vector.dev/docs/reference/configuration/sinks/clickhouse/
[docs.sinks.elasticsearch]: https://vector.dev/docs/reference/configuration/sinks/elasticsearch/
[docs.sinks.gcp_cloud_storage]: https://vector.dev/docs/reference/configuration/sinks/gcp_cloud_storage/
[docs.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.sources.docker_logs]: https://vector.dev/docs/reference/configuration/sources/docker_logs/
[docs.sources.file]: https://vector.dev/docs/reference/configuration/sources/file/
[docs.sources.http]: https://vector.dev/docs/reference/configuration/sources/http/
[docs.sources.journald]: https://vector.dev/docs/reference/configuration/sources/journald/
[docs.sources.kafka]: https://vector.dev/docs/reference/configuration/sources/kafka/
[docs.sources.socket]: https://vector.dev/docs/reference/configuration/sources/socket/
[docs.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.transforms.dedupe]: https://vector.dev/docs/reference/configuration/transforms/dedupe/
[docs.transforms.filter]: https://vector.dev/docs/reference/configuration/transforms/filter/
[docs.transforms.log_to_metric]: https://vector.dev/docs/reference/configuration/transforms/log_to_metric/
[docs.transforms.lua]: https://vector.dev/docs/reference/configuration/transforms/lua/
[docs.transforms.remap]: https://vector.dev/docs/reference/configuration/transforms/remap/
[docs.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.under-the-hood.architecture]: https://vector.dev/docs/about/under-the-hood/architecture/
[docs.under-the-hood.guarantees]: https://vector.dev/docs/about/under-the-hood/guarantees/
[docs.under-the-hood.networking]: https://vector.dev/docs/about/under-the-hood/networking/
[urls.production_users]: https://github.com/vectordotdev/vector/issues/790
[urls.rust]: https://www.rust-lang.org/
[urls.vector_calendar]: https://calendar.vector.dev
[urls.vector_chat]: https://chat.vector.dev
[urls.vector_code_of_conduct]: https://github.com/vectordotdev/vector/blob/master/CODE_OF_CONDUCT.md
[urls.vector_community]: https://vector.dev/community/
[urls.vector_privacy_policy]: https://github.com/vectordotdev/vector/blob/master/PRIVACY.md
[urls.vector_release_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASING.md
[urls.vector_releases]: https://vector.dev/releases/
[urls.vector_releases_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASES.md
[urls.vector_security_policy]: https://github.com/vectordotdev/vector/security/policy
[urls.vector_test_harness]: https://github.com/vectordotdev/vector-test-harness/
[urls.vector_twitter]: https://twitter.com/vectordotdev
[urls.vector_versioning_policy]: https://github.com/vectordotdev/vector/blob/master/VERSIONING.md
[urls.vote_feature]: https://github.com/vectordotdev/vector/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22type%3A+feature%22

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[influxdata/influxdb]]></title>
            <link>https://github.com/influxdata/influxdb</link>
            <guid>https://github.com/influxdata/influxdb</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[Scalable datastore for metrics, events, and real-time analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/influxdb">influxdata/influxdb</a></h1>
            <p>Scalable datastore for metrics, events, and real-time analytics</p>
            <p>Language: Rust</p>
            <p>Stars: 29,826</p>
            <p>Forks: 3,596</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
 &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/influxdb-logo.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/influxdb-logo-dark.png&quot;&gt;
    &lt;img src=&quot;assets/influxdb-logo.png&quot; alt=&quot;InfluxDB Logo&quot; width=&quot;600&quot;&gt;
  &lt;/picture&gt;
 &lt;p&gt;
&lt;/div&gt;

InfluxDB Core is a database built to collect, process, transform, and store event and time series data. It is ideal for use cases that require real-time ingest and fast query response times to build user interfaces, monitoring, and automation solutions.

Common use cases include:

- Monitoring sensor data
- Server monitoring
- Application performance monitoring
- Network monitoring
- Financial market and trading analytics
- Behavioral analytics

InfluxDB is optimized for scenarios where near real-time data monitoring is essential and queries 
need to return quickly to support user experiences such as dashboards and interactive user interfaces.

InfluxDB 3 Core‚Äôs feature highlights include:

- Diskless architecture with object storage support (or local disk with no dependencies)
- Fast query response times (under 10ms for last-value queries, or 30ms for distinct metadata)
- Embedded Python VM for plugins and triggers
- Parquet file persistence
- Compatibility with InfluxDB 1.x and 2.x write APIs
- Compatability with InfluxDB 1.x query API (InfluxQL)
- SQL query engine with support for FlightSQL and HTTP query API

## Project Status

InfluxDB 3 Core is in public beta and available for testing and feedback, but is not meant for 
production use. During the beta period we will be adding a couple of security and operational 
features to Enterprise. Otherwise, we will be focused on testing, robustness, performance, and 
operational tooling. Both the product and this documentation are works in progress. New builds get created on 
every merge into main, however we will have weekly beta builds along with a changelog for uses 
that want to move at a slower pace.

All of the APIs outside of the processing engine can be considered stable. They are what we will GA the 3.0 
version with. We will also not be making any changes to file formats that don&#039;t also come with an in-place 
upgrade path. This means that you will be able to keep the data in the database when upgrading beta versions 
and into the GA. We anticpate the general availability of InfluxDB 3 Core in April 2025.

We welcome and encourage your input about your experience with the beta. Join the [InfluxDB3 Discord](https://discord.gg/vZe2w2Ds8B) 
or the public channels below.

See the [InfluxDB 3 beta release announcement here](https://www.influxdata.com/blog/influxdb3-open-source-public-beta/) 
or dig into the [InfluxDB 3 getting started guide here](https://docs.influxdata.com/influxdb3/core/get-started/).

## Learn InfluxDB
[Documentation](https://docs.influxdata.com/) | [Community Forum](https://community.influxdata.com/) | [Community Slack](https://www.influxdata.com/slack/) | [Blog](https://www.influxdata.com/blog/) | [InfluxDB University](https://university.influxdata.com/) | [YouTube](https://www.youtube.com/@influxdata8893)

Try **InfluxDB Cloud** for free and get started fast with no local setup required. Click [here](https://cloud2.influxdata.com/signup) to start building your application on InfluxDB Cloud.


## Installation
We have nightly and versioned Docker images, Debian packages, RPM packages, and tarballs of InfluxDB available on the [InfluxData downloads page](https://portal.influxdata.com/downloads/). We also provide the InfluxDB command line interface (CLI) client as a separate binary available at the same location.

- For v1 installation, use the [main 1.x branch](https://github.com/influxdata/influxdb/tree/master-1.x) or [install InfluxDB OSS directly](https://docs.influxdata.com/influxdb/v1/introduction/install/#installing-influxdb-oss).
- For v2 installation, use the [main 2.x branch](https://github.com/influxdata/influxdb/tree/main-2.x).
- For InfluxDB 3 Core beta see the [InfluxDB 3 Core getting started guide](https://docs.influxdata.com/influxdb3/core/get-started/).

If you are interested in building from source, see the [building from source](https://github.com/influxdata/influxdb/blob/main-2.x/CONTRIBUTING.md#building-from-source) guide for contributors.

To begin using InfluxDB, visit our [Getting Started with InfluxDB](https://docs.influxdata.com/influxdb/v1/introduction/get-started/) documentation.


## License
The open source software we build is licensed under the permissive MIT or Apache 2 licenses at the user&#039;s choosing. We‚Äôve long held the view that our open source code should be truly open and our commercial code should be separate and closed. 


## Interested in joining the team building InfluxDB?
Check out current job openings at [www.influxdata.com/careers](https://www.influxdata.com/careers) today!</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[seanmonstar/reqwest]]></title>
            <link>https://github.com/seanmonstar/reqwest</link>
            <guid>https://github.com/seanmonstar/reqwest</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[An easy and powerful Rust HTTP Client]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/seanmonstar/reqwest">seanmonstar/reqwest</a></h1>
            <p>An easy and powerful Rust HTTP Client</p>
            <p>Language: Rust</p>
            <p>Stars: 10,496</p>
            <p>Forks: 1,213</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># reqwest

[![crates.io](https://img.shields.io/crates/v/reqwest.svg)](https://crates.io/crates/reqwest)
[![Documentation](https://docs.rs/reqwest/badge.svg)](https://docs.rs/reqwest)
[![MIT/Apache-2 licensed](https://img.shields.io/crates/l/reqwest.svg)](./LICENSE-APACHE)
[![CI](https://github.com/seanmonstar/reqwest/workflows/CI/badge.svg)](https://github.com/seanmonstar/reqwest/actions?query=workflow%3ACI)

An ergonomic, batteries-included HTTP Client for Rust.

- Async and blocking `Client`s
- Plain bodies, JSON, urlencoded, multipart
- Customizable redirect policy
- HTTP Proxies
- HTTPS via system-native TLS (or optionally, rustls)
- Cookie Store
- WASM


## Example

This asynchronous example uses [Tokio](https://tokio.rs) and enables some
optional features, so your `Cargo.toml` could look like this:

```toml
[dependencies]
reqwest = { version = &quot;0.12&quot;, features = [&quot;json&quot;] }
tokio = { version = &quot;1&quot;, features = [&quot;full&quot;] }
```

And then the code:

```rust,no_run
use std::collections::HashMap;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let resp = reqwest::get(&quot;https://httpbin.org/ip&quot;)
        .await?
        .json::&lt;HashMap&lt;String, String&gt;&gt;()
        .await?;
    println!(&quot;{resp:#?}&quot;);
    Ok(())
}
```

## Commercial Support

For private advice, support, reviews, access to the maintainer, and the like, reach out for [commercial support][sponsor].

## Requirements

On Linux:

- OpenSSL with headers. See https://docs.rs/openssl for supported versions
  and more details. Alternatively you can enable the `native-tls-vendored`
  feature to compile a copy of OpenSSL. Or, you can use [rustls](https://github.com/rustls/rustls)
  via `rustls-tls` or other `rustls-tls-*` features.

On Windows and macOS:

- Nothing.

By default, Reqwest uses [rust-native-tls](https://github.com/sfackler/rust-native-tls),
which will use the operating system TLS framework if available, meaning Windows
and macOS. On Linux, it will use the available OpenSSL or fail to build if
not found.


## License

Licensed under either of

- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://apache.org/licenses/LICENSE-2.0)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

### Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in the work by you, as defined in the Apache-2.0 license, shall
be dual licensed as above, without any additional terms or conditions.

## Sponsors

Support this project by becoming a [sponsor][].

[sponsor]: https://seanmonstar.com/sponsor
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tikv/tikv]]></title>
            <link>https://github.com/tikv/tikv</link>
            <guid>https://github.com/tikv/tikv</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[Distributed transactional key-value database, originally created to complement TiDB]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tikv/tikv">tikv/tikv</a></h1>
            <p>Distributed transactional key-value database, originally created to complement TiDB</p>
            <p>Language: Rust</p>
            <p>Stars: 15,713</p>
            <p>Forks: 2,175</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;images/tikv-logo.png&quot; alt=&quot;tikv_logo&quot; width=&quot;300&quot;/&gt;

## [Website](https://tikv.org) | [Documentation](https://tikv.org/docs/latest/concepts/overview/) | [Community Chat](https://slack.tidb.io/invite?team=tikv-wg&amp;channel=general)

[![Build Status](https://ci.pingcap.net/buildStatus/icon?job=tikv_ghpr_build_master)](https://ci.pingcap.net/blue/organizations/jenkins/tikv_ghpr_build_master/activity)
[![Coverage Status](https://codecov.io/gh/tikv/tikv/branch/master/graph/badge.svg)](https://codecov.io/gh/tikv/tikv)
[![CII Best Practices](https://bestpractices.coreinfrastructure.org/projects/2574/badge)](https://bestpractices.coreinfrastructure.org/projects/2574)

TiKV is an open-source, distributed, and transactional key-value database. Unlike other traditional NoSQL systems, TiKV not only provides classical key-value APIs, but also transactional APIs with ACID compliance. Built in Rust and powered by Raft, TiKV was originally created by [PingCAP](https://en.pingcap.com) to complement [TiDB](https://github.com/pingcap/tidb), a distributed HTAP database compatible with the MySQL protocol.

The design of TiKV (&#039;Ti&#039; stands for titanium) is inspired by some great distributed systems from Google, such as BigTable, Spanner, and Percolator, and some of the latest achievements in academia in recent years, such as the Raft consensus algorithm.

If you&#039;re interested in contributing to TiKV, or want to build it from source, see [CONTRIBUTING.md](./CONTRIBUTING.md).

![cncf_logo](images/cncf.png#gh-light-mode-only)
![cncf_logo](images/cncf-white.png#gh-dark-mode-only)

TiKV is a graduated project of the [Cloud Native Computing Foundation](https://cncf.io/) (CNCF). If you are an organization that wants to help shape the evolution of technologies that are container-packaged, dynamically-scheduled and microservices-oriented, consider joining the CNCF. For details about who&#039;s involved and how TiKV plays a role, read the CNCF [announcement](https://www.cncf.io/announcements/2020/09/02/cloud-native-computing-foundation-announces-tikv-graduation/).

---

With the implementation of the Raft consensus algorithm in Rust and consensus state stored in RocksDB, TiKV guarantees data consistency. [Placement Driver (PD)](https://github.com/pingcap/pd/), which is introduced to implement auto-sharding, enables automatic data migration. The transaction model is similar to Google&#039;s Percolator with some performance improvements. TiKV also provides snapshot isolation (SI), snapshot isolation with lock (SQL: `SELECT ... FOR UPDATE`), and externally consistent reads and writes in distributed transactions.

TiKV has the following key features:

- **Geo-Replication**

    TiKV uses [Raft](http://raft.github.io/) and the Placement Driver to support Geo-Replication.

- **Horizontal scalability**

    With PD and carefully designed Raft groups, TiKV excels in horizontal scalability and can easily scale to 100+ TBs of data.

- **Consistent distributed transactions**

    Similar to Google&#039;s Spanner, TiKV supports externally-consistent distributed transactions.

- **Coprocessor support**

    Similar to HBase, TiKV implements a coprocessor framework to support distributed computing.

- **Cooperates with [TiDB](https://github.com/pingcap/tidb)**

    Thanks to the internal optimization, TiKV and TiDB can work together to be a compelling database solution with high horizontal scalability, externally-consistent transactions, support for RDBMS, and NoSQL design patterns.

## Governance

See [Governance](https://github.com/tikv/community/blob/master/GOVERNANCE.md).

## Documentation

For instructions on deployment, configuration, and maintenance of TiKV,see TiKV documentation on our [website](https://tikv.org/docs/4.0/tasks/introduction/). For more details on concepts and designs behind TiKV, see [Deep Dive TiKV](https://tikv.org/deep-dive/introduction/).

&gt; **Note:**
&gt;
&gt; We have migrated our documentation from the [TiKV&#039;s wiki page](https://github.com/tikv/tikv/wiki/) to the [official website](https://tikv.org/docs). The original Wiki page is discontinued. If you have any suggestions or issues regarding documentation, offer your feedback [here](https://github.com/tikv/website).

## TiKV adopters

You can view the list of [TiKV Adopters](https://tikv.org/adopters/).

## TiKV software stack

![The TiKV software stack](images/tikv_stack.png)

- **Placement Driver:** PD is the cluster manager of TiKV, which periodically checks replication constraints to balance load and data automatically.
- **Store:** There is a RocksDB within each Store and it stores data into the local disk.
- **Region:** Region is the basic unit of Key-Value data movement. Each Region is replicated to multiple Nodes. These multiple replicas form a Raft group.
- **Node:** A physical node in the cluster. Within each node, there are one or more Stores. Within each Store, there are many Regions.

When a node starts, the metadata of the Node, Store and Region are recorded into PD. The status of each Region and Store is reported to PD regularly.

## Quick start

### Deploy a playground with TiUP

The most quickest to try out TiKV with TiDB is using TiUP, a component manager for TiDB.

You can see [this page](https://docs.pingcap.com/tidb/stable/quick-start-with-tidb#deploy-a-local-test-environment-using-tiup-playground) for a step by step tutorial.

### Deploy a playground with binary

TiKV is able to run separately with PD, which is the minimal deployment required.

1. Download and extract binaries.

```bash
$ export TIKV_VERSION=v7.5.0
$ export GOOS=darwin  # only {darwin, linux} are supported
$ export GOARCH=amd64 # only {amd64, arm64} are supported
$ curl -O  https://tiup-mirrors.pingcap.com/tikv-$TIKV_VERSION-$GOOS-$GOARCH.tar.gz
$ curl -O  https://tiup-mirrors.pingcap.com/pd-$TIKV_VERSION-$GOOS-$GOARCH.tar.gz
$ tar -xzf tikv-$TIKV_VERSION-$GOOS-$GOARCH.tar.gz
$ tar -xzf pd-$TIKV_VERSION-$GOOS-$GOARCH.tar.gz
```

2. Start PD instance.

```bash
$ ./pd-server --name=pd --data-dir=/tmp/pd/data --client-urls=&quot;http://127.0.0.1:2379&quot; --peer-urls=&quot;http://127.0.0.1:2380&quot; --initial-cluster=&quot;pd=http://127.0.0.1:2380&quot; --log-file=/tmp/pd/log/pd.log
```

3. Start TiKV instance.

```bash
$ ./tikv-server --pd-endpoints=&quot;127.0.0.1:2379&quot; --addr=&quot;127.0.0.1:20160&quot; --data-dir=/tmp/tikv/data --log-file=/tmp/tikv/log/tikv.log
```

4. Install TiKV Client(Python) and verify the deployment, required Python 3.5+.

```bash
$ pip3 install -i https://test.pypi.org/simple/ tikv-client
```

```python
from tikv_client import RawClient

client = RawClient.connect(&quot;127.0.0.1:2379&quot;)

client.put(b&#039;foo&#039;, b&#039;bar&#039;)
print(client.get(b&#039;foo&#039;)) # b&#039;bar&#039;

client.put(b&#039;foo&#039;, b&#039;baz&#039;)
print(client.get(b&#039;foo&#039;)) # b&#039;baz&#039;
```

### Deploy a cluster with TiUP

You can see [this manual](./doc/deploy.md) of production-like cluster deployment presented by @c4pt0r.

### Build from source

See [CONTRIBUTING.md](./CONTRIBUTING.md).

## Client drivers

- [Go](https://github.com/tikv/client-go) (The most stable and widely used)
- [Java](https://github.com/tikv/client-java)
- [Rust](https://github.com/tikv/client-rust)
- [C](https://github.com/tikv/client-c)

If you want to try the Go client, see [Go Client](https://tikv.org/docs/4.0/reference/clients/go/).

## Security

### Security audit

A third-party security auditing was performed by Cure53. See the full report [here](./security/Security-Audit.pdf).

### Reporting Security Vulnerabilities

To report a security vulnerability, please send an email to [TiKV-security](mailto:tikv-security@lists.cncf.io) group.

See [Security](SECURITY.md) for the process and policy followed by the TiKV project.

## Communication

Communication within the TiKV community abides by [TiKV Code of Conduct](./CODE_OF_CONDUCT.md). Here is an excerpt:

&gt; In the interest of fostering an open and welcoming environment, we as
contributors and maintainers pledge to making participation in our project and
our community a harassment-free experience for everyone, regardless of age, body
size, disability, ethnicity, sex characteristics, gender identity and expression,
level of experience, education, socio-economic status, nationality, personal
appearance, race, religion, or sexual identity and orientation.

### Social Media

- [Twitter](https://twitter.com/tikvproject)
- [Blog](https://tikv.org/blog/)
- [Reddit](https://www.reddit.com/r/TiKV)
- Post questions or help answer them on [Stack Overflow](https://stackoverflow.com/questions/tagged/tikv)

### Slack

Join the TiKV community on [Slack](https://slack.tidb.io/invite?team=tikv-wg&amp;channel=general) - Sign up and join channels on TiKV topics that interest you.

## License

TiKV is under the Apache 2.0 license. See the [LICENSE](./LICENSE) file for details.

## Acknowledgments

- Thanks [etcd](https://github.com/coreos/etcd) for providing some great open source tools.
- Thanks [RocksDB](https://github.com/facebook/rocksdb) for their powerful storage engines.
- Thanks [rust-clippy](https://github.com/rust-lang/rust-clippy). We do love the great project.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[huggingface/text-embeddings-inference]]></title>
            <link>https://github.com/huggingface/text-embeddings-inference</link>
            <guid>https://github.com/huggingface/text-embeddings-inference</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[A blazing fast inference solution for text embeddings models]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/text-embeddings-inference">huggingface/text-embeddings-inference</a></h1>
            <p>A blazing fast inference solution for text embeddings models</p>
            <p>Language: Rust</p>
            <p>Stars: 3,405</p>
            <p>Forks: 238</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# Text Embeddings Inference

&lt;a href=&quot;https://github.com/huggingface/text-embeddings-inference&quot;&gt;
  &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/huggingface/text-embeddings-inference?style=social&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://huggingface.github.io/text-embeddings-inference&quot;&gt;
  &lt;img alt=&quot;Swagger API documentation&quot; src=&quot;https://img.shields.io/badge/API-Swagger-informational&quot;&gt;
&lt;/a&gt;

A blazing fast inference solution for text embeddings models.

Benchmark for [BAAI/bge-base-en-v1.5](https://huggingface.co/BAAI/bge-base-en-v1.5) on an Nvidia A10 with a sequence
length of 512 tokens:

&lt;p&gt;
  &lt;img src=&quot;assets/bs1-lat.png&quot; width=&quot;400&quot; /&gt;
  &lt;img src=&quot;assets/bs1-tp.png&quot; width=&quot;400&quot; /&gt;
&lt;/p&gt;
&lt;p&gt;
  &lt;img src=&quot;assets/bs32-lat.png&quot; width=&quot;400&quot; /&gt;
  &lt;img src=&quot;assets/bs32-tp.png&quot; width=&quot;400&quot; /&gt;
&lt;/p&gt;

&lt;/div&gt;

## Table of contents

- [Get Started](#get-started)
    - [Supported Models](#supported-models)
    - [Docker](#docker)
    - [Docker Images](#docker-images)
    - [API Documentation](#api-documentation)
    - [Using a private or gated model](#using-a-private-or-gated-model)
    - [Air gapped deployment](#air-gapped-deployment)
    - [Using Re-rankers models](#using-re-rankers-models)
    - [Using Sequence Classification models](#using-sequence-classification-models)
    - [Using SPLADE pooling](#using-splade-pooling)
    - [Distributed Tracing](#distributed-tracing)
    - [gRPC](#grpc)
- [Local Install](#local-install)
- [Docker Build](#docker-build)
    - [Apple M1/M2 Arm](#apple-m1m2-arm64-architectures)
- [Examples](#examples)

Text Embeddings Inference (TEI) is a toolkit for deploying and serving open source text embeddings and sequence
classification models. TEI enables high-performance extraction for the most popular models, including FlagEmbedding,
Ember, GTE and E5. TEI implements many features such as:

* No model graph compilation step
* Metal support for local execution on Macs
* Small docker images and fast boot times. Get ready for true serverless!
* Token based dynamic batching
* Optimized transformers code for inference using [Flash Attention](https://github.com/HazyResearch/flash-attention),
  [Candle](https://github.com/huggingface/candle)
  and [cuBLASLt](https://docs.nvidia.com/cuda/cublas/#using-the-cublaslt-api)
* [Safetensors](https://github.com/huggingface/safetensors) weight loading
* [ONNX](https://github.com/onnx/onnx) weight loading
* Production ready (distributed tracing with Open Telemetry, Prometheus metrics)

## Get Started

### Supported Models

#### Text Embeddings

Text Embeddings Inference currently supports Nomic, BERT, CamemBERT, XLM-RoBERTa models with absolute positions, JinaBERT
model with Alibi positions and Mistral, Alibaba GTE, Qwen2 models with Rope positions, MPNet, and ModernBERT.

Below are some examples of the currently supported models:

| MTEB Rank | Model Size          | Model Type  | Model ID                                                                                         |
|-----------|---------------------|-------------|--------------------------------------------------------------------------------------------------|
| 3         | 7B (Very Expensive) | Qwen2       | [Alibaba-NLP/gte-Qwen2-7B-instruct](https://hf.co/Alibaba-NLP/gte-Qwen2-7B-instruct)             |
| 11        | 1.5B (Expensive)    | Qwen2       | [Alibaba-NLP/gte-Qwen2-1.5B-instruct](https://hf.co/Alibaba-NLP/gte-Qwen2-1.5B-instruct)         |
| 14        | 7B (Very Expensive) | Mistral     | [Salesforce/SFR-Embedding-2_R](https://hf.co/Salesforce/SFR-Embedding-2_R)                       |
| 20        | 0.3B                | Bert        | [WhereIsAI/UAE-Large-V1](https://hf.co/WhereIsAI/UAE-Large-V1)                                   |
| 31        | 0.5B                | XLM-RoBERTa | [Snowflake/snowflake-arctic-embed-l-v2.0](https://hf.co/Snowflake/snowflake-arctic-embed-l-v2.0) |
| 37        | 0.3B                | Alibaba GTE | [Snowflake/snowflake-arctic-embed-m-v2.0](https://hf.co/Snowflake/snowflake-arctic-embed-m-v2.0) |
| 49        | 0.5B                | XLM-RoBERTa | [intfloat/multilingual-e5-large-instruct](https://hf.co/intfloat/multilingual-e5-large-instruct) |
| N/A       | 0.4B                | Alibaba GTE | [Alibaba-NLP/gte-large-en-v1.5](https://hf.co/Alibaba-NLP/gte-large-en-v1.5)                     |
| N/A       | 0.4B                | ModernBERT  | [answerdotai/ModernBERT-large](https://hf.co/answerdotai/ModernBERT-large) |
| N/A       | 0.1B                | NomicBert   | [nomic-ai/nomic-embed-text-v1](https://hf.co/nomic-ai/nomic-embed-text-v1)                       |
| N/A       | 0.1B                | NomicBert   | [nomic-ai/nomic-embed-text-v1.5](https://hf.co/nomic-ai/nomic-embed-text-v1.5)                   |
| N/A       | 0.1B                | JinaBERT    | [jinaai/jina-embeddings-v2-base-en](https://hf.co/jinaai/jina-embeddings-v2-base-en)             |
| N/A       | 0.1B                | JinaBERT    | [jinaai/jina-embeddings-v2-base-code](https://hf.co/jinaai/jina-embeddings-v2-base-code)         |
| N/A       | 0.1B                | MPNet       | [sentence-transformers/all-mpnet-base-v2](https://hf.co/sentence-transformers/all-mpnet-base-v2) |

To explore the list of best performing text embeddings models, visit the
[Massive Text Embedding Benchmark (MTEB) Leaderboard](https://huggingface.co/spaces/mteb/leaderboard).

#### Sequence Classification and Re-Ranking

Text Embeddings Inference currently supports CamemBERT, and XLM-RoBERTa Sequence Classification models with absolute positions.

Below are some examples of the currently supported models:

| Task               | Model Type  | Model ID                                                                                                        |
|--------------------|-------------|-----------------------------------------------------------------------------------------------------------------|
| Re-Ranking         | XLM-RoBERTa | [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large)                                       |
| Re-Ranking         | XLM-RoBERTa | [BAAI/bge-reranker-base](https://huggingface.co/BAAI/bge-reranker-base)                                         |
| Re-Ranking         | GTE         | [Alibaba-NLP/gte-multilingual-reranker-base](https://huggingface.co/Alibaba-NLP/gte-multilingual-reranker-base) |
| Sentiment Analysis | RoBERTa     | [SamLowe/roberta-base-go_emotions](https://huggingface.co/SamLowe/roberta-base-go_emotions)                     |

### Docker

```shell
model=BAAI/bge-large-en-v1.5
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id $model
```

And then you can make requests like

```bash
curl 127.0.0.1:8080/embed \
    -X POST \
    -d &#039;{&quot;inputs&quot;:&quot;What is Deep Learning?&quot;}&#039; \
    -H &#039;Content-Type: application/json&#039;
```

**Note:** To use GPUs, you need to install
the [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html).
NVIDIA drivers on your machine need to be compatible with CUDA version 12.2 or higher.

To see all options to serve your models:

```shell
text-embeddings-router --help
```

```
Usage: text-embeddings-router [OPTIONS]

Options:
      --model-id &lt;MODEL_ID&gt;
          The name of the model to load. Can be a MODEL_ID as listed on &lt;https://hf.co/models&gt; like `thenlper/gte-base`.
          Or it can be a local directory containing the necessary files as saved by `save_pretrained(...)` methods of
          transformers

          [env: MODEL_ID=]
          [default: thenlper/gte-base]

      --revision &lt;REVISION&gt;
          The actual revision of the model if you&#039;re referring to a model on the hub. You can use a specific commit id
          or a branch like `refs/pr/2`

          [env: REVISION=]

      --tokenization-workers &lt;TOKENIZATION_WORKERS&gt;
          Optionally control the number of tokenizer workers used for payload tokenization, validation and truncation.
          Default to the number of CPU cores on the machine

          [env: TOKENIZATION_WORKERS=]

      --dtype &lt;DTYPE&gt;
          The dtype to be forced upon the model

          [env: DTYPE=]
          [possible values: float16, float32]

      --pooling &lt;POOLING&gt;
          Optionally control the pooling method for embedding models.

          If `pooling` is not set, the pooling configuration will be parsed from the model `1_Pooling/config.json` configuration.

          If `pooling` is set, it will override the model pooling configuration

          [env: POOLING=]

          Possible values:
          - cls:        Select the CLS token as embedding
          - mean:       Apply Mean pooling to the model embeddings
          - splade:     Apply SPLADE (Sparse Lexical and Expansion) to the model embeddings. This option is only
          available if the loaded model is a `ForMaskedLM` Transformer model
          - last-token: Select the last token as embedding

      --max-concurrent-requests &lt;MAX_CONCURRENT_REQUESTS&gt;
          The maximum amount of concurrent requests for this particular deployment.
          Having a low limit will refuse clients requests instead of having them wait for too long and is usually good
          to handle backpressure correctly

          [env: MAX_CONCURRENT_REQUESTS=]
          [default: 512]

      --max-batch-tokens &lt;MAX_BATCH_TOKENS&gt;
          **IMPORTANT** This is one critical control to allow maximum usage of the available hardware.

          This represents the total amount of potential tokens within a batch.

          For `max_batch_tokens=1000`, you could fit `10` queries of `total_tokens=100` or a single query of `1000` tokens.

          Overall this number should be the largest possible until the model is compute bound. Since the actual memory
          overhead depends on the model implementation, text-embeddings-inference cannot infer this number automatically.

          [env: MAX_BATCH_TOKENS=]
          [default: 16384]

      --max-batch-requests &lt;MAX_BATCH_REQUESTS&gt;
          Optionally control the maximum number of individual requests in a batch

          [env: MAX_BATCH_REQUESTS=]

      --max-client-batch-size &lt;MAX_CLIENT_BATCH_SIZE&gt;
          Control the maximum number of inputs that a client can send in a single request

          [env: MAX_CLIENT_BATCH_SIZE=]
          [default: 32]

      --auto-truncate
          Automatically truncate inputs that are longer than the maximum supported size

          Unused for gRPC servers

          [env: AUTO_TRUNCATE=]

      --default-prompt-name &lt;DEFAULT_PROMPT_NAME&gt;
          The name of the prompt that should be used by default for encoding. If not set, no prompt will be applied.

          Must be a key in the `sentence-transformers` configuration `prompts` dictionary.

          For example if ``default_prompt_name`` is &quot;query&quot; and the ``prompts`` is {&quot;query&quot;: &quot;query: &quot;, ...}, then the
          sentence &quot;What is the capital of France?&quot; will be encoded as &quot;query: What is the capital of France?&quot; because
          the prompt text will be prepended before any text to encode.

          The argument &#039;--default-prompt-name &lt;DEFAULT_PROMPT_NAME&gt;&#039; cannot be used with &#039;--default-prompt &lt;DEFAULT_PROMPT&gt;`

          [env: DEFAULT_PROMPT_NAME=]

      --default-prompt &lt;DEFAULT_PROMPT&gt;
          The prompt that should be used by default for encoding. If not set, no prompt will be applied.

          For example if ``default_prompt`` is &quot;query: &quot; then the sentence &quot;What is the capital of France?&quot; will be
          encoded as &quot;query: What is the capital of France?&quot; because the prompt text will be prepended before any text
          to encode.

          The argument &#039;--default-prompt &lt;DEFAULT_PROMPT&gt;&#039; cannot be used with &#039;--default-prompt-name &lt;DEFAULT_PROMPT_NAME&gt;`

          [env: DEFAULT_PROMPT=]

      --hf-token &lt;HF_TOKEN&gt;
          Your Hugging Face Hub token

          [env: HF_TOKEN=]

      --hostname &lt;HOSTNAME&gt;
          The IP address to listen on

          [env: HOSTNAME=]
          [default: 0.0.0.0]

      -p, --port &lt;PORT&gt;
          The port to listen on

          [env: PORT=]
          [default: 3000]

      --uds-path &lt;UDS_PATH&gt;
          The name of the unix socket some text-embeddings-inference backends will use as they communicate internally
          with gRPC

          [env: UDS_PATH=]
          [default: /tmp/text-embeddings-inference-server]

      --huggingface-hub-cache &lt;HUGGINGFACE_HUB_CACHE&gt;
          The location of the huggingface hub cache. Used to override the location if you want to provide a mounted disk
          for instance

          [env: HUGGINGFACE_HUB_CACHE=]

      --payload-limit &lt;PAYLOAD_LIMIT&gt;
          Payload size limit in bytes

          Default is 2MB

          [env: PAYLOAD_LIMIT=]
          [default: 2000000]

      --api-key &lt;API_KEY&gt;
          Set an api key for request authorization.

          By default the server responds to every request. With an api key set, the requests must have the Authorization
          header set with the api key as Bearer token.

          [env: API_KEY=]

      --json-output
          Outputs the logs in JSON format (useful for telemetry)

          [env: JSON_OUTPUT=]

      --disable-spans
          Disables the span logging trace

          [env: DISABLE_SPANS=]

      --otlp-endpoint &lt;OTLP_ENDPOINT&gt;
          The grpc endpoint for opentelemetry. Telemetry is sent to this endpoint as OTLP over gRPC. e.g. `http://localhost:4317`

          [env: OTLP_ENDPOINT=]

      --otlp-service-name &lt;OTLP_SERVICE_NAME&gt;
          The service name for opentelemetry. e.g. `text-embeddings-inference.server`

          [env: OTLP_SERVICE_NAME=]
          [default: text-embeddings-inference.server]

      --cors-allow-origin &lt;CORS_ALLOW_ORIGIN&gt;
          Unused for gRPC servers

          [env: CORS_ALLOW_ORIGIN=]
```

### Docker Images

Text Embeddings Inference ships with multiple Docker images that you can use to target a specific backend:

| Architecture                        | Image                                                                   |
|-------------------------------------|-------------------------------------------------------------------------|
| CPU                                 | ghcr.io/huggingface/text-embeddings-inference:cpu-1.7                   |
| Volta                               | NOT SUPPORTED                                                           |
| Turing (T4, RTX 2000 series, ...)   | ghcr.io/huggingface/text-embeddings-inference:turing-1.7 (experimental) |
| Ampere 80 (A100, A30)               | ghcr.io/huggingface/text-embeddings-inference:1.7                       |
| Ampere 86 (A10, A40, ...)           | ghcr.io/huggingface/text-embeddings-inference:86-1.7                    |
| Ada Lovelace (RTX 4000 series, ...) | ghcr.io/huggingface/text-embeddings-inference:89-1.7                    |
| Hopper (H100)                       | ghcr.io/huggingface/text-embeddings-inference:hopper-1.7 (experimental) |

**Warning**: Flash Attention is turned off by default for the Turing image as it suffers from precision issues.
You can turn Flash Attention v1 ON by using the `USE_FLASH_ATTENTION=True` environment variable.

### API documentation

You can consult the OpenAPI documentation of the `text-embeddings-inference` REST API using the `/docs` route.
The Swagger UI is also available
at: [https://huggingface.github.io/text-embeddings-inference](https://huggingface.github.io/text-embeddings-inference).

### Using a private or gated model

You have the option to utilize the `HF_TOKEN` environment variable for configuring the token employed by
`text-embeddings-inference`. This allows you to gain access to protected resources.

For example:

1. Go to https://huggingface.co/settings/tokens
2. Copy your cli READ token
3. Export `HF_TOKEN=&lt;your cli READ token&gt;`

or with Docker:

```shell
model=&lt;your private model&gt;
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run
token=&lt;your cli READ token&gt;

docker run --gpus all -e HF_TOKEN=$token -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id $model
```

### Air gapped deployment

To deploy Text Embeddings Inference in an air-gapped environment, first download the weights and then mount them inside
the container using a volume.

For example:

```shell
# (Optional) create a `models` directory
mkdir models
cd models

# Make sure you have git-lfs installed (https://git-lfs.com)
git lfs install
git clone https://huggingface.co/Alibaba-NLP/gte-base-en-v1.5

# Set the models directory as the volume path
volume=$PWD

# Mount the models directory inside the container with a volume and set the model ID
docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id /data/gte-base-en-v1.5
```

### Using Re-rankers models

`text-embeddings-inference` v0.4.0 added support for CamemBERT, RoBERTa, XLM-RoBERTa, and GTE Sequence Classification models.
Re-rankers models are Sequence Classification cross-encoders models with a single class that scores the similarity
between a query and a text.

See [this blogpost](https://blog.llamaindex.ai/boosting-rag-picking-the-best-embedding-reranker-models-42d079022e83) by
the LlamaIndex team to understand how you can use re-rankers models in your RAG pipeline to improve
downstream performance.

```shell
model=BAAI/bge-reranker-large
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id $model
```

And then you can rank the similarity between a query and a list of texts with:

```bash
curl 127.0.0.1:8080/rerank \
    -X POST \
    -d &#039;{&quot;query&quot;: &quot;What is Deep Learning?&quot;, &quot;texts&quot;: [&quot;Deep Learning is not...&quot;, &quot;Deep learning is...&quot;]}&#039; \
    -H &#039;Content-Type: application/json&#039;
```

### Using Sequence Classification models

You can also use classic Sequence Classification models like `SamLowe/roberta-base-go_emotions`:

```shell
model=SamLowe/roberta-base-go_emotions
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id $model
```

Once you have deployed the model you can use the `predict` endpoint to get the emotions most associated with an input:

```bash
curl 127.0.0.1:8080/predict \
    -X POST \
    -d &#039;{&quot;inputs&quot;:&quot;I like you.&quot;}&#039; \
    -H &#039;Content-Type: application/json&#039;
```

### Using SPLADE pooling

You can choose to activate SPLADE pooling for Bert and Distilbert MaskedLM architectures:

```shell
model=naver/efficient-splade-VI-BT-large-query
volume=$PWD/data # share a volume with the Docker container to avoid downloading weights every run

docker run --gpus all -p 8080:80 -v $volume:/data --pull always ghcr.io/huggingface/text-embeddings-inference:1.7 --model-id $model --pooling splade
```

Once you have deployed the model you can use the `/embed_sparse` endpoint to get the sparse embedding:

```bash
curl 127.0.0.1:8080/embed_sparse \
    -X POST \
    -d &#039;{&quot;inputs&quot;:&quot;I like you.&quot;}&#039; \
    -H &#039;Content-Type: application/json&#039;
```

### Distributed Tracing

`text-embeddings-inference` is instrumented with distributed tracing using OpenTelemetry. You can use this feature
by setting the address to an OTLP collector with the `--otlp-endpoint` argument.

### gRPC

`text-embeddings-inference` offers a gRPC API as an alternative to the default HTTP API for high performance
deployments. The API protobuf definition can be
found [here](https://github.com/huggingface/text-embeddings-infere

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tokio-rs/axum]]></title>
            <link>https://github.com/tokio-rs/axum</link>
            <guid>https://github.com/tokio-rs/axum</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[Ergonomic and modular web framework built with Tokio, Tower, and Hyper]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tokio-rs/axum">tokio-rs/axum</a></h1>
            <p>Ergonomic and modular web framework built with Tokio, Tower, and Hyper</p>
            <p>Language: Rust</p>
            <p>Stars: 21,146</p>
            <p>Forks: 1,147</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>axum/README.md</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[prefix-dev/pixi]]></title>
            <link>https://github.com/prefix-dev/pixi</link>
            <guid>https://github.com/prefix-dev/pixi</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[Package management made easy]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/prefix-dev/pixi">prefix-dev/pixi</a></h1>
            <p>Package management made easy</p>
            <p>Language: Rust</p>
            <p>Stars: 4,191</p>
            <p>Forks: 256</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;h1&gt;
  &lt;a href=&quot;https://github.com/prefix-dev/pixi/&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;https://github.com/prefix-dev/pixi/assets/4995967/a3f9ff01-c9fb-4893-83c0-2a3f924df63e&quot; type=&quot;image/webp&quot;&gt;
      &lt;source srcset=&quot;https://github.com/prefix-dev/pixi/assets/4995967/e42739c4-4cd9-49bb-9d0a-45f8088494b5&quot; type=&quot;image/png&quot;&gt;
      &lt;img src=&quot;https://github.com/prefix-dev/pixi/assets/4995967/e42739c4-4cd9-49bb-9d0a-45f8088494b5&quot; alt=&quot;banner&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;h1 align=&quot;center&quot;&gt;

![License][license-badge]
[![Project Chat][chat-badge]][chat-url]
[![Pixi Badge][pixi-badge]][pixi-url]


[license-badge]: https://img.shields.io/badge/license-BSD--3--Clause-blue?style=flat-square
[chat-badge]: https://img.shields.io/discord/1082332781146800168.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2&amp;style=flat-square
[chat-url]: https://discord.gg/kKV8ZxyzY4
[pixi-badge]:https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/prefix-dev/pixi/main/assets/badge/v0.json&amp;style=flat-square
[pixi-url]: https://pixi.sh

&lt;/h1&gt;

# Pixi: Package Management Made Easy

## Overview

`pixi` is a cross-platform, multi-language package manager and workflow tool built on the foundation of the conda ecosystem. It provides developers with an exceptional experience similar to popular package managers like `cargo` or `yarn`, but for any language.

Developed with ‚ù§Ô∏è at [prefix.dev](https://prefix.dev).
[![Real-time pixi_demo](https://github.com/prefix-dev/pixi/assets/12893423/0fc8f8c8-ac13-4c14-891b-dc613f25475b)](https://asciinema.org/a/636482)

## Highlights

- Supports **multiple languages** including Python, C++, and R using Conda packages. You can find available packages on [prefix.dev](https://prefix.dev).
- Compatible with all major operating systems: Linux, Windows, macOS (including Apple Silicon).
- Always includes an up-to-date **lock file**.
- Provides a clean and simple Cargo-like **command-line interface**.
- Allows you to install tools **per-project** or **system-wide**.
- Entirely written in **Rust** and built on top of the **[rattler](https://github.com/conda/rattler)** library.

## Getting Started

- ‚ö° [Installation](#installation)
- ‚öôÔ∏è [Examples](/examples)
- üìö [Documentation](https://pixi.sh/)
- üòç [Contributing](#contributing)
- üî® [Built using Pixi](#built-using-pixi)
- üöÄ [GitHub Action](https://github.com/prefix-dev/setup-pixi)

## Status

Pixi is ready for production!
We are working hard to keep file-format changes compatible with the previous
versions so that you can rely on Pixi with peace of mind.

Some notable features we envision for upcoming releases are:

- **Build and publish** your project as a Conda package.
- Support for **dependencies from source**.
- More powerful &quot;global installation&quot; of packages towards a deterministic setup of global packages on multiple machines.

## Installation

`pixi` can be installed on macOS, Linux, and Windows. The provided scripts will automatically download the latest version of `pixi`, extract it, and move the `pixi` binary to `~/.pixi/bin`. If this directory does not exist, the script will create it.

### macOS and Linux

To install Pixi on macOS and Linux, open a terminal and run the following command:

```bash
curl -fsSL https://pixi.sh/install.sh | sh
# or with brew
brew install pixi
```

The script will also update your `~/.bashrc` to include `~/.pixi/bin` in your `PATH`, allowing you to invoke the `pixi` command from anywhere.
You might need to restart your terminal or source your shell for the changes to take effect.

Starting with macOS Catalina [zsh is the default login shell and interactive shell](https://support.apple.com/en-us/102360). Therefore, you might want to use `zsh` instead of `bash` in the install command:

```zsh
curl -fsSL https://pixi.sh/install.sh | zsh
```

The script will also update your `~/.zshrc` to include `~/.pixi/bin` in your `PATH`, allowing you to invoke the `pixi` command from anywhere.

### Windows

To install Pixi on Windows, open a PowerShell terminal (you may need to run it as an administrator) and run the following command:

```powershell
powershell -ExecutionPolicy ByPass -c &quot;irm -useb https://pixi.sh/install.ps1 | iex&quot;
```
Changing the [execution policy](https://learn.microsoft.com/en-us/powershell/module/microsoft.powershell.core/about/about_execution_policies?view=powershell-7.4#powershell-execution-policies) allows running a script from the internet.
Check the script you would be running with:
```powershell
powershell -c &quot;irm -useb https://pixi.sh/install.ps1 | more&quot;
```

The script will inform you once the installation is successful and add the `~/.pixi/bin` directory to your `PATH`, which will allow you to run the `pixi` command from any location.
Or with `winget`

```shell
winget install prefix-dev.pixi
```

### Autocompletion

To get autocompletion follow the instructions for your shell.
Afterwards, restart the shell or source the shell config file.

#### Bash (default on most Linux systems)

Add the following to the end of `~/.bashrc`:

```bash
# ~/.bashrc

eval &quot;$(pixi completion --shell bash)&quot;
```
#### Zsh (default on macOS)

Add the following to the end of `~/.zshrc`:


```zsh
# ~/.zshrc

eval &quot;$(pixi completion --shell zsh)&quot;
```

#### PowerShell (pre-installed on all Windows systems)

Add the following to the end of `Microsoft.PowerShell_profile.ps1`.
You can check the location of this file by querying the `$PROFILE` variable in PowerShell.
Typically the path is `~\Documents\PowerShell\Microsoft.PowerShell_profile.ps1` or
`~/.config/powershell/Microsoft.PowerShell_profile.ps1` on -Nix.

```pwsh
(&amp; pixi completion --shell powershell) | Out-String | Invoke-Expression
```

#### Fish

Add the following to the end of `~/.config/fish/config.fish`:

```fish
# ~/.config/fish/config.fish

pixi completion --shell fish | source
```

#### Nushell

Add the following to your Nushell config file (find it by running `$nu.config-path` in Nushell):

```nushell
mkdir $&quot;($nu.data-dir)/vendor/autoload&quot;
pixi completion --shell nushell | save --force $&quot;($nu.data-dir)/vendor/autoload/pixi-completions.nu&quot;
```

#### Elvish

Add the following to the end of `~/.elvish/rc.elv`:

```elv
# ~/.elvish/rc.elv

eval (pixi completion --shell elvish | slurp)
```

### Distro Packages

[![Packaging status](https://repology.org/badge/vertical-allrepos/pixi.svg)](https://repology.org/project/pixi/versions)

#### Arch Linux

You can install `pixi` from the [extra repository](https://archlinux.org/packages/extra/x86_64/pixi/) using [pacman](https://wiki.archlinux.org/title/Pacman):

```shell
pacman -S pixi
```

#### Alpine Linux

`pixi` is available for [Alpine Edge](https://pkgs.alpinelinux.org/packages?name=pixi&amp;branch=edge). It can be installed via [apk](https://wiki.alpinelinux.org/wiki/Alpine_Package_Keeper) after enabling the [testing repository](https://wiki.alpinelinux.org/wiki/Repositories).

```shell
apk add pixi
```

## Build/install from source

`pixi` is 100% written in Rust and therefore it can be installed, built and tested with cargo.
To start using `pixi` from a source build run:

```shell
cargo install --locked --git https://github.com/prefix-dev/pixi.git pixi
```

We don&#039;t publish to `crates.io` anymore, so you need to install it from the repository.
The reason for this is that we depend on some unpublished crates which disallows us to publish to `crates.io`.

or when you want to make changes use:

```shell
cargo build
cargo test
```

If you have any issues building because of the dependency on `rattler` checkout
it&#039;s [compile steps](https://github.com/conda/rattler/tree/main#give-it-a-try)

## Uninstall

To uninstall, the Pixi binary should be removed.
Delete `pixi` from the `$PIXI_DIR` which is default to `~/.pixi/bin/pixi`

So on Linux its:

```shell
rm ~/.pixi/bin/pixi
```

and on Windows:

```shell
$PIXI_BIN = &quot;$Env:LocalAppData\pixi\bin\pixi&quot;; Remove-Item -Path $PIXI_BIN
```

After this command you can still use the tools you installed with `pixi`.
To remove these as well just remove the whole `~/.pixi` directory and remove the directory from your path.

# Usage

The cli looks as follows:

```bash
‚ûú pixi
A package management and workflow tool

Usage: pixi [OPTIONS] &lt;COMMAND&gt;

Commands:
  completion  Generates a completion script for a shell
  init        Creates a new project
  add         Adds a dependency to the project
  run         Runs task in project
  shell       Start a shell in the pixi environment of the project
  global      Global is the main entry point for the part of pixi that executes on the global(system) level
  auth        Login to prefix.dev or anaconda.org servers to access private channels
  install     Install all dependencies
  task        Command management in project
  info        Information about the system and project
  upload      Upload a package to a prefix.dev channel
  search      Search a package, output will list the latest version of package
  project
  help        Print this message or the help of the given subcommand(s)

Options:
  -v, --verbose...     More output per occurrence
  -q, --quiet...       Less output per occurrence
      --color &lt;COLOR&gt;  Whether the log needs to be colored [default: auto] [possible values: always, never, auto]
  -h, --help           Print help
  -V, --version        Print version

```

## Creating a Pixi project

Initialize a new project and navigate to the project directory

```
pixi init myproject
cd myproject
```

Add the dependencies you want to use

```
pixi add cowpy
```

Run the installed package in its environment

```bash
pixi run cowpy &quot;Thanks for using pixi&quot;
```

Activate a shell in the environment

```shell
pixi shell
cowpy &quot;Thanks for using pixi&quot;
exit
```

## Installing a conda package globally

You can also globally install conda packages into their own environment.
This behavior is similar to [`pipx`](https://github.com/pypa/pipx) or [`condax`](https://github.com/mariusvniekerk/condax).

```bash
pixi global install cowpy
```

## Use in GitHub Actions

You can use Pixi in GitHub Actions to install dependencies and run commands.
It supports automatic caching of your environments.

```yml
- uses: prefix-dev/setup-pixi@v0.8.1
- run: pixi exec cowpy &quot;Thanks for using pixi&quot;
```

See the [documentation](https://pixi.sh/latest/advanced/github_actions) for more details.

&lt;a name=&quot;contributing&quot;&gt;&lt;/a&gt;

## Contributing üòç

We would absolutely love for you to contribute to Pixi!
Whether you want to start an issue, fix a bug you encountered, or suggest an
improvement, every contribution is greatly appreciated.

If you&#039;re just getting started with our project or stepping into the Rust
ecosystem for the first time, we&#039;ve got your back!
We recommend beginning with issues labeled as `good first issue`.
These are carefully chosen tasks that provide a smooth entry point into
contributing.These issues are typically more straightforward and are a great way
to get familiar with the project.

Got questions or ideas, or just want to chat? Join our lively conversations on
Discord.
We&#039;re very active and would be happy to welcome you to our
community. [Join our discord server today!][chat-url]

&lt;a name=&quot;pixibuilt&quot;&gt;&lt;/a&gt;

## Built using Pixi

To see what&#039;s being built with `pixi` check out the [Community](/docs/Community.md) page.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zed-industries/zed]]></title>
            <link>https://github.com/zed-industries/zed</link>
            <guid>https://github.com/zed-industries/zed</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zed-industries/zed">zed-industries/zed</a></h1>
            <p>Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.</p>
            <p>Language: Rust</p>
            <p>Stars: 56,862</p>
            <p>Forks: 3,863</p>
            <p>Stars today: 59 stars today</p>
            <h2>README</h2><pre># Zed

[![CI](https://github.com/zed-industries/zed/actions/workflows/ci.yml/badge.svg)](https://github.com/zed-industries/zed/actions/workflows/ci.yml)

Welcome to Zed, a high-performance, multiplayer code editor from the creators of [Atom](https://github.com/atom/atom) and [Tree-sitter](https://github.com/tree-sitter/tree-sitter).

---

### Installation

&lt;a href=&quot;https://repology.org/project/zed-editor/versions&quot;&gt;
    &lt;img src=&quot;https://repology.org/badge/vertical-allrepos/zed-editor.svg?minversion=0.143.5&quot; alt=&quot;Packaging status&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

On macOS and Linux you can [download Zed directly](https://zed.dev/download) or [install Zed via your local package manager](https://zed.dev/docs/linux#installing-via-a-package-manager).

Other platforms are not yet available:

- Windows ([tracking issue](https://github.com/zed-industries/zed/issues/5394))
- Web ([tracking issue](https://github.com/zed-industries/zed/issues/5396))

### Developing Zed

- [Building Zed for macOS](./docs/src/development/macos.md)
- [Building Zed for Linux](./docs/src/development/linux.md)
- [Building Zed for Windows](./docs/src/development/windows.md)
- [Running Collaboration Locally](./docs/src/development/local-collaboration.md)

### Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for ways you can contribute to Zed.

Also... we&#039;re hiring! Check out our [jobs](https://zed.dev/jobs) page for open roles.

### Licensing

License information for third party dependencies must be correctly provided for CI to pass.

We use [`cargo-about`](https://github.com/EmbarkStudios/cargo-about) to automatically comply with open source licenses. If CI is failing, check the following:

- Is it showing a `no license specified` error for a crate you&#039;ve created? If so, add `publish = false` under `[package]` in your crate&#039;s Cargo.toml.
- Is the error `failed to satisfy license requirements` for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license&#039;s requirements. If you&#039;re unsure, ask a lawyer. Once you&#039;ve verified that this system is acceptable add the license&#039;s SPDX identifier to the `accepted` array in `script/licenses/zed-licenses.toml`.
- Is `cargo-about` unable to find the license for a dependency? If so, add a clarification field at the end of `script/licenses/zed-licenses.toml`, as specified in the [cargo-about book](https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[pola-rs/polars]]></title>
            <link>https://github.com/pola-rs/polars</link>
            <guid>https://github.com/pola-rs/polars</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Dataframes powered by a multithreaded, vectorized query engine, written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pola-rs/polars">pola-rs/polars</a></h1>
            <p>Dataframes powered by a multithreaded, vectorized query engine, written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 32,995</p>
            <p>Forks: 2,161</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pola.rs&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/pola-rs/polars-static/master/banner/polars_github_banner.svg&quot; alt=&quot;Polars logo&quot;&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://crates.io/crates/polars&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/polars.svg&quot; alt=&quot;crates.io Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pypi.org/project/polars/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/v/polars.svg&quot; alt=&quot;PyPi Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/nodejs-polars&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/nodejs-polars.svg&quot; alt=&quot;NPM Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://rpolars.r-universe.dev&quot;&gt;
    &lt;img src=&quot;https://rpolars.r-universe.dev/badges/polars&quot; alt=&quot;R-universe Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://doi.org/10.5281/zenodo.7697217&quot;&gt;
    &lt;img src=&quot;https://zenodo.org/badge/DOI/10.5281/zenodo.7697217.svg&quot; alt=&quot;DOI Latest Release&quot;/&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Documentation&lt;/b&gt;:
  &lt;a href=&quot;https://docs.pola.rs/api/python/stable/reference/index.html&quot;&gt;Python&lt;/a&gt;
  -
  &lt;a href=&quot;https://docs.rs/polars/latest/polars/&quot;&gt;Rust&lt;/a&gt;
  -
  &lt;a href=&quot;https://pola-rs.github.io/nodejs-polars/index.html&quot;&gt;Node.js&lt;/a&gt;
  -
  &lt;a href=&quot;https://pola-rs.github.io/r-polars/index.html&quot;&gt;R&lt;/a&gt;
  |
  &lt;b&gt;StackOverflow&lt;/b&gt;:
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/python-polars&quot;&gt;Python&lt;/a&gt;
  -
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/rust-polars&quot;&gt;Rust&lt;/a&gt;
  -
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/nodejs-polars&quot;&gt;Node.js&lt;/a&gt;
  -
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/r-polars&quot;&gt;R&lt;/a&gt;
  |
  &lt;a href=&quot;https://docs.pola.rs/&quot;&gt;User guide&lt;/a&gt;
  |
  &lt;a href=&quot;https://discord.gg/4UfP5cfBE7&quot;&gt;Discord&lt;/a&gt;
&lt;/p&gt;

## Polars: Blazingly fast DataFrames in Rust, Python, Node.js, R, and SQL

Polars is a DataFrame interface on top of an OLAP Query Engine implemented in Rust using
[Apache Arrow Columnar Format](https://arrow.apache.org/docs/format/Columnar.html) as the memory
model.

- Lazy | eager execution
- Multi-threaded
- SIMD
- Query optimization
- Powerful expression API
- Hybrid Streaming (larger-than-RAM datasets)
- Rust | Python | NodeJS | R | ...

To learn more, read the [user guide](https://docs.pola.rs/).

## Python

```python
&gt;&gt;&gt; import polars as pl
&gt;&gt;&gt; df = pl.DataFrame(
...     {
...         &quot;A&quot;: [1, 2, 3, 4, 5],
...         &quot;fruits&quot;: [&quot;banana&quot;, &quot;banana&quot;, &quot;apple&quot;, &quot;apple&quot;, &quot;banana&quot;],
...         &quot;B&quot;: [5, 4, 3, 2, 1],
...         &quot;cars&quot;: [&quot;beetle&quot;, &quot;audi&quot;, &quot;beetle&quot;, &quot;beetle&quot;, &quot;beetle&quot;],
...     }
... )

# embarrassingly parallel execution &amp; very expressive query language
&gt;&gt;&gt; df.sort(&quot;fruits&quot;).select(
...     &quot;fruits&quot;,
...     &quot;cars&quot;,
...     pl.lit(&quot;fruits&quot;).alias(&quot;literal_string_fruits&quot;),
...     pl.col(&quot;B&quot;).filter(pl.col(&quot;cars&quot;) == &quot;beetle&quot;).sum(),
...     pl.col(&quot;A&quot;).filter(pl.col(&quot;B&quot;) &gt; 2).sum().over(&quot;cars&quot;).alias(&quot;sum_A_by_cars&quot;),
...     pl.col(&quot;A&quot;).sum().over(&quot;fruits&quot;).alias(&quot;sum_A_by_fruits&quot;),
...     pl.col(&quot;A&quot;).reverse().over(&quot;fruits&quot;).alias(&quot;rev_A_by_fruits&quot;),
...     pl.col(&quot;A&quot;).sort_by(&quot;B&quot;).over(&quot;fruits&quot;).alias(&quot;sort_A_by_B_by_fruits&quot;),
... )
shape: (5, 8)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ fruits   ‚îÜ cars     ‚îÜ literal_stri ‚îÜ B   ‚îÜ sum_A_by_ca ‚îÜ sum_A_by_fr ‚îÜ rev_A_by_fr ‚îÜ sort_A_by_B ‚îÇ
‚îÇ ---      ‚îÜ ---      ‚îÜ ng_fruits    ‚îÜ --- ‚îÜ rs          ‚îÜ uits        ‚îÜ uits        ‚îÜ _by_fruits  ‚îÇ
‚îÇ str      ‚îÜ str      ‚îÜ ---          ‚îÜ i64 ‚îÜ ---         ‚îÜ ---         ‚îÜ ---         ‚îÜ ---         ‚îÇ
‚îÇ          ‚îÜ          ‚îÜ str          ‚îÜ     ‚îÜ i64         ‚îÜ i64         ‚îÜ i64         ‚îÜ i64         ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ &quot;apple&quot;  ‚îÜ &quot;beetle&quot; ‚îÜ &quot;fruits&quot;     ‚îÜ 11  ‚îÜ 4           ‚îÜ 7           ‚îÜ 4           ‚îÜ 4           ‚îÇ
‚îÇ &quot;apple&quot;  ‚îÜ &quot;beetle&quot; ‚îÜ &quot;fruits&quot;     ‚îÜ 11  ‚îÜ 4           ‚îÜ 7           ‚îÜ 3           ‚îÜ 3           ‚îÇ
‚îÇ &quot;banana&quot; ‚îÜ &quot;beetle&quot; ‚îÜ &quot;fruits&quot;     ‚îÜ 11  ‚îÜ 4           ‚îÜ 8           ‚îÜ 5           ‚îÜ 5           ‚îÇ
‚îÇ &quot;banana&quot; ‚îÜ &quot;audi&quot;   ‚îÜ &quot;fruits&quot;     ‚îÜ 11  ‚îÜ 2           ‚îÜ 8           ‚îÜ 2           ‚îÜ 2           ‚îÇ
‚îÇ &quot;banana&quot; ‚îÜ &quot;beetle&quot; ‚îÜ &quot;fruits&quot;     ‚îÜ 11  ‚îÜ 4           ‚îÜ 8           ‚îÜ 1           ‚îÜ 1           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## SQL

```python
&gt;&gt;&gt; df = pl.scan_csv(&quot;docs/assets/data/iris.csv&quot;)
&gt;&gt;&gt; ## OPTION 1
&gt;&gt;&gt; # run SQL queries on frame-level
&gt;&gt;&gt; df.sql(&quot;&quot;&quot;
...	SELECT species,
...	  AVG(sepal_length) AS avg_sepal_length
...	FROM self
...	GROUP BY species
...	&quot;&quot;&quot;).collect()
shape: (3, 2)
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ species    ‚îÜ avg_sepal_length ‚îÇ
‚îÇ ---        ‚îÜ ---              ‚îÇ
‚îÇ str        ‚îÜ f64              ‚îÇ
‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°
‚îÇ Virginica  ‚îÜ 6.588            ‚îÇ
‚îÇ Versicolor ‚îÜ 5.936            ‚îÇ
‚îÇ Setosa     ‚îÜ 5.006            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
&gt;&gt;&gt; ## OPTION 2
&gt;&gt;&gt; # use pl.sql() to operate on the global context
&gt;&gt;&gt; df2 = pl.LazyFrame({
...    &quot;species&quot;: [&quot;Setosa&quot;, &quot;Versicolor&quot;, &quot;Virginica&quot;],
...    &quot;blooming_season&quot;: [&quot;Spring&quot;, &quot;Summer&quot;, &quot;Fall&quot;]
...})
&gt;&gt;&gt; pl.sql(&quot;&quot;&quot;
... SELECT df.species,
...     AVG(df.sepal_length) AS avg_sepal_length,
...     df2.blooming_season
... FROM df
... LEFT JOIN df2 ON df.species = df2.species
... GROUP BY df.species, df2.blooming_season
... &quot;&quot;&quot;).collect()
```

SQL commands can also be run directly from your terminal using the Polars CLI:

```bash
# run an inline SQL query
&gt; polars -c &quot;SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv(&#039;docs/assets/data/iris.csv&#039;) GROUP BY species;&quot;

# run interactively
&gt; polars
Polars CLI v0.3.0
Type .help for help.

&gt; SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv(&#039;docs/assets/data/iris.csv&#039;) GROUP BY species;
```

Refer to the [Polars CLI repository](https://github.com/pola-rs/polars-cli) for more information.

## Performance üöÄüöÄ

### Blazingly fast

Polars is very fast. In fact, it is one of the best performing solutions available. See the
[PDS-H benchmarks](https://www.pola.rs/benchmarks.html) results.

### Lightweight

Polars is also very lightweight. It comes with zero required dependencies, and this shows in the
import times:

- polars: 70ms
- numpy: 104ms
- pandas: 520ms

### Handles larger-than-RAM data

If you have data that does not fit into memory, Polars&#039; query engine is able to process your query
(or parts of your query) in a streaming fashion. This drastically reduces memory requirements, so
you might be able to process your 250GB dataset on your laptop. Collect with
`collect(engine=&#039;streaming&#039;)` to run the query streaming. (This might be a little slower, but it is
still very fast!)

## Setup

### Python

Install the latest Polars version with:

```sh
pip install polars
```

We also have a conda package (`conda install -c conda-forge polars`), however pip is the preferred
way to install Polars.

Install Polars with all optional dependencies.

```sh
pip install &#039;polars[all]&#039;
```

You can also install a subset of all optional dependencies.

```sh
pip install &#039;polars[numpy,pandas,pyarrow]&#039;
```

See the [User Guide](https://docs.pola.rs/user-guide/installation/#feature-flags) for more details
on optional dependencies

To see the current Polars version and a full list of its optional dependencies, run:

```python
pl.show_versions()
```

Releases happen quite often (weekly / every few days) at the moment, so updating Polars regularly to
get the latest bugfixes / features might not be a bad idea.

### Rust

You can take latest release from `crates.io`, or if you want to use the latest features /
performance improvements point to the `main` branch of this repo.

```toml
polars = { git = &quot;https://github.com/pola-rs/polars&quot;, rev = &quot;&lt;optional git tag&gt;&quot; }
```

Requires Rust version `&gt;=1.80`.

## Contributing

Want to contribute? Read our [contributing guide](https://docs.pola.rs/development/contributing/).

## Python: compile Polars from source

If you want a bleeding edge release or maximal performance you should compile Polars from source.

This can be done by going through the following steps in sequence:

1. Install the latest [Rust compiler](https://www.rust-lang.org/tools/install)
2. Install [maturin](https://maturin.rs/): `pip install maturin`
3. `cd py-polars` and choose one of the following:
   - `make build`, slow binary with debug assertions and symbols, fast compile times
   - `make build-release`, fast binary without debug assertions, minimal debug symbols, long compile
     times
   - `make build-nodebug-release`, same as build-release but without any debug symbols, slightly
     faster to compile
   - `make build-debug-release`, same as build-release but with full debug symbols, slightly slower
     to compile
   - `make build-dist-release`, fastest binary, extreme compile times

By default the binary is compiled with optimizations turned on for a modern CPU. Specify `LTS_CPU=1`
with the command if your CPU is older and does not support e.g. AVX2.

Note that the Rust crate implementing the Python bindings is called `py-polars` to distinguish from
the wrapped Rust crate `polars` itself. However, both the Python package and the Python module are
named `polars`, so you can `pip install polars` and `import polars`.

## Using custom Rust functions in Python

Extending Polars with UDFs compiled in Rust is easy. We expose PyO3 extensions for `DataFrame` and
`Series` data structures. See more in https://github.com/pola-rs/pyo3-polars.

## Going big...

Do you expect more than 2^32 (~4.2 billion) rows? Compile Polars with the `bigidx` feature flag or,
for Python users, install `pip install polars-u64-idx`.

Don&#039;t use this unless you hit the row boundary as the default build of Polars is faster and consumes
less memory.

## Legacy

Do you want Polars to run on an old CPU (e.g. dating from before 2011), or on an `x86-64` build of
Python on Apple Silicon under Rosetta? Install `pip install polars-lts-cpu`. This version of Polars
is compiled without [AVX](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions) target features.

## Sponsors

[&lt;img src=&quot;https://www.jetbrains.com/company/brand/img/jetbrains_logo.png&quot; height=&quot;50&quot; alt=&quot;JetBrains logo&quot; /&gt;](https://www.jetbrains.com)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[DioxusLabs/dioxus]]></title>
            <link>https://github.com/DioxusLabs/dioxus</link>
            <guid>https://github.com/DioxusLabs/dioxus</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[Fullstack app framework for web, desktop, mobile, and more.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DioxusLabs/dioxus">DioxusLabs/dioxus</a></h1>
            <p>Fullstack app framework for web, desktop, mobile, and more.</p>
            <p>Language: Rust</p>
            <p>Stars: 26,466</p>
            <p>Forks: 1,041</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;p&gt;
    &lt;p align=&quot;center&quot; &gt;
      &lt;!-- &lt;img src=&quot;./notes/header-light-updated.svg#gh-light-mode-only&quot; &gt;
      &lt;img src=&quot;./notes/header-dark-updated.svg#gh-dark-mode-only&quot; &gt; --&gt;
      &lt;!-- &lt;a href=&quot;https://dioxuslabs.com&quot;&gt;
          &lt;img src=&quot;./notes/flat-splash.avif&quot;&gt;
      &lt;/a&gt; --&gt;
      &lt;img src=&quot;./notes/splash-header-darkmode.svg#gh-dark-mode-only&quot; style=&quot;width: 80%; height: auto;&quot;&gt;
      &lt;img src=&quot;./notes/splash-header.svg#gh-light-mode-only&quot; style=&quot;width: 80%; height: auto;&quot;&gt;
      &lt;img src=&quot;./notes/image-splash.avif&quot;&gt;
      &lt;br&gt;
    &lt;/p&gt;
&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Crates version --&gt;
  &lt;a href=&quot;https://crates.io/crates/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/dioxus.svg?style=flat-square&quot;
    alt=&quot;Crates.io version&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Downloads --&gt;
  &lt;a href=&quot;https://crates.io/crates/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/d/dioxus.svg?style=flat-square&quot;
      alt=&quot;Download&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- docs --&gt;
  &lt;a href=&quot;https://docs.rs/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square&quot;
      alt=&quot;docs.rs docs&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- CI --&gt;
  &lt;a href=&quot;https://github.com/jkelleyrtp/dioxus/actions&quot;&gt;
    &lt;img src=&quot;https://github.com/dioxuslabs/dioxus/actions/workflows/main.yml/badge.svg&quot;
      alt=&quot;CI status&quot; /&gt;
  &lt;/a&gt;

  &lt;!--Awesome --&gt;
  &lt;a href=&quot;https://dioxuslabs.com/awesome&quot;&gt;
    &lt;img src=&quot;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg&quot; alt=&quot;Awesome Page&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Discord --&gt;
  &lt;a href=&quot;https://discord.gg/XgGxMSkvUM&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/899851952891002890.svg?logo=discord&amp;style=flat-square&quot; alt=&quot;Discord Link&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;
    &lt;a href=&quot;https://dioxuslabs.com&quot;&gt; Website &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/tree/main/examples&quot;&gt; Examples &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://dioxuslabs.com/learn/0.6/guide&quot;&gt; Guide &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/zh-cn/README.md&quot;&gt; ‰∏≠Êñá &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/pt-br/README.md&quot;&gt; PT-BR &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/ja-jp/README.md&quot;&gt; Êó•Êú¨Ë™û &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/tr-tr&quot;&gt; T√ºrk√ße &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/ko-kr&quot;&gt; ÌïúÍµ≠Ïñ¥ &lt;/a&gt;
  &lt;/h3&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://dioxuslabs.com/blog/release-060/&quot;&gt;‚ú® Dioxus 0.6 is released - check it out here! ‚ú®&lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;

Build for web, desktop, and mobile, and more with a single codebase. Zero-config setup, integrated hot-reloading, and signals-based state management. Add backend functionality with Server Functions and bundle with our CLI.

```rust
fn app() -&gt; Element {
    let mut count = use_signal(|| 0);

    rsx! {
        h1 { &quot;High-Five counter: {count}&quot; }
        button { onclick: move |_| count += 1, &quot;Up high!&quot; }
        button { onclick: move |_| count -= 1, &quot;Down low!&quot; }
    }
}
```

## ‚≠êÔ∏è Unique features:

- Cross-platform apps in three lines of code (web, desktop, mobile, server, and more)
- [Ergonomic state management](https://dioxuslabs.com/blog/release-050) combines the best of React, Solid, and Svelte
- Type-safe Routing and server functions to leverage Rust&#039;s powerful compile-time guarantees
- Integrated bundler for deploying to the web, macOS, Linux, and Windows
- And more! [Take a tour of Dioxus](https://dioxuslabs.com/learn/0.6/).

## Instant hot-reloading

With one command, `dx serve` and your app is running. Edit your markup and styles and see the results in real time.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/hotreload-video.webp&quot;&gt;
  &lt;!-- &lt;video src=&quot;https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov&quot; width=&quot;500&quot;&gt;&lt;/video&gt; --&gt;
  &lt;!-- &lt;video src=&quot;https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov&quot; width=&quot;500&quot;&gt;&lt;/video&gt; --&gt;
&lt;/div&gt;


## First-class Android and iOS support

Dioxus is the fastest way to build native mobile apps with Rust. Simply run `dx serve --platform android` and your app is running in an emulator or on device in seconds. Call directly into JNI and Native APIs.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/android_and_ios2.avif&quot; width=&quot;500&quot;&gt;
&lt;/div&gt;

## Bundle for web, desktop, and mobile

Simply run `dx bundle` and your app will be built and bundled with maximization optimizations. On the web, take advantage of [`.avif` generation, `.wasm` compression, minification](https://dioxuslabs.com/learn/0.6/guides/assets), and more. Build WebApps weighing [less than 50kb](https://github.com/ealmloff/tiny-dioxus/) and desktop/mobile apps less than 5mb.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/bundle.gif&quot;&gt;
&lt;/div&gt;


## Fantastic documentation

We&#039;ve put a ton of effort into building clean, readable, and comprehensive documentation. All html elements and listeners are documented with MDN docs, and our Docs runs continuous integration with Dioxus itself to ensure that the docs are always up to date. Check out the [Dioxus website](https://dioxuslabs.com/learn/0.6/) for guides, references, recipes, and more. Fun fact: we use the Dioxus website as a testbed for new Dioxus features - [check it out!](https://github.com/dioxusLabs/docsite)

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/docs.avif&quot;&gt;
&lt;/div&gt;

## Community

Dioxus is a community-driven project, with a very active [Discord](https://discord.gg/XgGxMSkvUM) and [GitHub](https://github.com/DioxusLabs/dioxus/issues) community. We&#039;re always looking for help, and we&#039;re happy to answer questions and help you get started. [Our SDK](https://github.com/DioxusLabs/dioxus-std) is community-run and we even have a [GitHub organization](https://github.com/dioxus-community/) for the best Dioxus crates that receive free upgrades and support.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/dioxus-community.avif&quot;&gt;
&lt;/div&gt;

## Full-time core team

Dioxus has grown from a side project to a small team of fulltime engineers. Thanks to the generous support of FutureWei, Satellite.im, the GitHub Accelerator program, we&#039;re able to work on Dioxus full-time. Our long term goal is for Dioxus to become self-sustaining by providing paid high-quality enterprise tools. If your company is interested in adopting Dioxus and would like to work with us, please reach out!

## Supported Platforms

&lt;div align=&quot;center&quot;&gt;
  &lt;table style=&quot;width:100%&quot;&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Web&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render directly to the DOM using WebAssembly&lt;/li&gt;
          &lt;li&gt;Pre-render with SSR and rehydrate on the client&lt;/li&gt;
          &lt;li&gt;Simple &quot;hello world&quot; at about 50kb, comparable to React&lt;/li&gt;
          &lt;li&gt;Built-in dev server and hot reloading for quick iteration&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Desktop&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render using Webview or - experimentally - with WGPU or &lt;a href=&quot;https://freyaui.dev&quot;&gt;Freya&lt;/a&gt; (Skia) &lt;/li&gt;
          &lt;li&gt;Zero-config setup. Simply `cargo run` or `dx serve` to build your app &lt;/li&gt;
          &lt;li&gt;Full support for native system access without IPC &lt;/li&gt;
          &lt;li&gt;Supports macOS, Linux, and Windows. Portable &lt;3mb binaries &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Mobile&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render using Webview or - experimentally - with WGPU or Skia &lt;/li&gt;
          &lt;li&gt;Build .ipa and .apk files for iOS and Android &lt;/li&gt;
          &lt;li&gt;Call directly into Java and Objective-C with minimal overhead&lt;/li&gt;
          &lt;li&gt;From &quot;hello world&quot; to running on device in seconds&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Server-side Rendering&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Suspense, hydration, and server-side rendering&lt;/li&gt;
          &lt;li&gt;Quickly drop in backend functionality with server functions&lt;/li&gt;
          &lt;li&gt;Extractors, middleware, and routing integrations&lt;/li&gt;
          &lt;li&gt;Static-site generation and incremental regeneration&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## Running the examples

&gt; The examples in the main branch of this repository target the git version of dioxus and the CLI. If you are looking for examples that work with the latest stable release of dioxus, check out the [0.6 branch](https://github.com/DioxusLabs/dioxus/tree/v0.6/examples).

The examples in the top level of this repository can be run with:

```sh
cargo run --example &lt;example&gt;
```

However, we encourage you to download the dioxus-cli. If you are running the git version of dioxus, you can install the matching version of the CLI with:

```sh
cargo install --git https://github.com/DioxusLabs/dioxus dioxus-cli --locked
```

With the CLI, you can also run examples with the web platform. You just need to disable the default desktop feature and enable the web feature with this command:

```sh
dx serve --example &lt;example&gt; --platform web -- --no-default-features
```

## Dioxus vs other frameworks

We love all frameworks and enjoy watching innovation in the Rust ecosystem. In fact, many of our projects are shared with other frameworks. For example, our flex-box library [Taffy](https://github.com/DioxusLabs/taffy) is used by [Bevy](https://bevyengine.org/), [Zed](https://zed.dev/), [Lapce](https://lapce.dev/), [Iced](https://github.com/iced-rs/iced), and many more.

Dioxus places an emphasis on a few key points that make it different from other frameworks:

- **React-like**: we rely on concepts like components, props, and hooks to build UIs, with our state management being closer to Svelte than to SolidJS.
- **HTML and CSS**: we lean completely into HTML and CSS, quirks and all.
- **Renderer-agnostic**: you can swap out the renderer for any platform you want thanks to [our fast VirtualDOM](https://dioxuslabs.com/blog/templates-diffing).
- **Collaborative**: whenever possible, we spin out crates like [Taffy](https://github.com/DioxusLabs/taffy), [manganis](https://github.com/DioxusLabs/manganis), [include_mdbook](https://github.com/DioxusLabs/include_mdbook), and [blitz](http://github.com/dioxusLabs/blitz) so the ecosystem can grow together.

### Dioxus vs Tauri

Tauri is a framework for building desktop mobile apps where your frontend is written in a web-based framework like React, Vue, Svelte, etc. Whenever you need to do native work, you can write Rust functions and call them from your frontend.

- **Natively Rust**: Tauri&#039;s architecture limits your UI to either JavaScript or WebAssembly. With Dioxus, your Rust code is running natively on the user&#039;s machine, letting you do things like spawning threads, accessing the filesystem, without any IPC bridge. This drastically simplifies your app&#039;s architecture and makes it easier to build. You can build a Tauri app with Dioxus-Web as a frontend if you&#039;d like.

- **Different scopes**: Tauri needs to support JavaScript and its complex build tooling, limiting the scope of what you can do with it. Since Dioxus is exclusively focused on Rust, we&#039;re able to provide extra utilities like Server Functions, advanced bundling, and a native renderer.

- **Shared DNA**: While Tauri and Dioxus are separate projects, they do share libraries like Tao and Wry: windowing and webview libraries maintained by the Tauri team.

### Dioxus vs Leptos

Leptos is a library for building fullstack web-apps, similar to SolidJS and SolidStart. The two libraries share similar goals on the web, but have several key differences:

- **Reactivity model**: Leptos uses signals to drive both reactivity and rendering, while Dioxus uses signals just for reactivity. For managing re-renders, Dioxus uses a highly optimized VirtualDOM to support desktop and mobile architectures. Both Dioxus and Leptos are extremely fast.

- **Different scopes**: Dioxus provides renderers for web, desktop, mobile, LiveView, and more. We also maintain community libraries and a cross-platform SDK. Leptos has a tighter focus on the fullstack web with features that Dioxus doesn&#039;t have like islands, `&lt;Form /&gt;` components, and other web-specific utilities.

- **Different DSLs**: Dioxus uses its own custom Rust-like DSL for building UIs while Leptos uses an HTML-like syntax. We chose this to retain compatibility with IDE features like code-folding and syntax highlighting. Generally, Dioxus leans into more &quot;magic&quot; with its DSL including automatic formatting of strings and hot-reloading of simple Rust expressions.

```rust
// dioxus
rsx! {
  div {
    class: &quot;my-class&quot;,
    enabled: true,
    &quot;Hello, {name}&quot;
  }
}

// leptos
view! {
  &lt;div class=&quot;my-class&quot; enabled={true}&gt;
    &quot;Hello &quot;
    {name}
  &lt;/div&gt;
}
```

### Dioxus vs Yew

Yew is a framework for building single-page web apps and initially served as an inspiration for Dioxus. Unfortunately, the architecture of Yew didn&#039;t support the various features we wanted, and thus Dioxus was born.

- **Single-page apps**: Yew is designed exclusively for single-page web apps and is intrinsically tied to the web platform. Dioxus is fullstack and cross-platform, making it suitable for building web, desktop, mobile, and server apps.

- **Developer Tooling**: Dioxus provides a number of utilities like autoformatting, hot-reloading, and a bundler.

- **Ongoing support**: Dioxus is very actively maintained with new features and bug fixes being added on a daily basis.

### Dioxus vs egui

egui is a cross-platform GUI library for Rust powering tools like [Rerun.io](https://www.rerun.io).

- **Immediate vs Retained**: egui is designed to be re-rendered on every frame. This is suitable for games and other interactive applications, but it does not retain style and layout state between frames. Dioxus is a retained UI framework, meaning that the UI is built once and then modified between frames. This enables Dioxus to use native web technologies like HTML and CSS with better battery life and performance.

- **Customizable**: egui brings its own styling and layout solution while Dioxus expects you to use the built-in HTML and CSS. This enables dioxus apps to use any CSS library like Tailwind or Material UI.

- **State management**: egui&#039;s state management is based on a single global state object. Dioxus encourages encapsulation of state by using components and props, making components more reusable.

### Dioxus vs Iced

Iced is a cross-platform GUI library inspired by Elm. Iced renders natively with WGPU and supports the web using DOM nodes.

- **Elm state management**: Iced uses Elm&#039;s state management model, which is based on message passing and reducers. This is simply a different state management model than Dioxus and can be rather verbose at times.

- **Native Feel**: Since Dioxus uses a webview as its renderer, it automatically gets native text input, paste handling, and other native features like accessibility. Iced&#039;s renderer currently doesn&#039;t implement these features, making it feel less native.

- **WGPU**: Dioxus&#039; WGPU renderer is currently quite immature and not yet ready for production use. Iced&#039;s WGPU renderer is much more mature and is being used in production. This enables certain types of apps that need GPU access to be built with Iced that can&#039;t currently be built with Dioxus.

### Dioxus vs Electron

Dioxus and Electron are two entirely different projects with similar goals. Electron makes it possible for developers to build cross-platform desktop apps using web technologies like HTML, CSS, and JavaScript.

- **Lightweight**: Dioxus uses the system&#039;s native WebView - or optionally, a WGPU renderer - to render the UI. This makes a typical Dioxus app about 15mb on macOS in comparison to Electron&#039;s 100mb. Electron also ships an embedded chromium instance which cannot share system resources with the host OS in the same way as Dioxus.

- **Maturity**: Electron is a mature project with a large community and a lot of tooling. Dioxus is still quite young in comparison to Electron. Expect to run into features like deep-linking that require extra work to implement.

## Contributing

- Check out the website [section on contributing](https://dioxuslabs.com/learn/0.6/contributing).
- Report issues on our [issue tracker](https://github.com/dioxuslabs/dioxus/issues).
- [Join](https://discord.gg/XgGxMSkvUM) the discord and ask questions!

&lt;a href=&quot;https://github.com/dioxuslabs/dioxus/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=dioxuslabs/dioxus&amp;max=30&amp;columns=10&quot; /&gt;
&lt;/a&gt;

## License

This project is licensed under either the [MIT license] or the [Apache-2 License].

[apache-2 license]: https://github.com/DioxusLabs/dioxus/blob/master/LICENSE-APACHE
[mit license]: https://github.com/DioxusLabs/dioxus/blob/master/LICENSE-MIT

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Dioxus by you, shall be licensed as MIT or Apache-2, without any additional
terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lancedb/lancedb]]></title>
            <link>https://github.com/lancedb/lancedb</link>
            <guid>https://github.com/lancedb/lancedb</guid>
            <pubDate>Fri, 11 Apr 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[Developer-friendly, embedded retrieval engine for multimodal AI. Search More; Manage Less.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lancedb/lancedb">lancedb/lancedb</a></h1>
            <p>Developer-friendly, embedded retrieval engine for multimodal AI. Search More; Manage Less.</p>
            <p>Language: Rust</p>
            <p>Stars: 6,097</p>
            <p>Forks: 442</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://cloud.lancedb.com&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/92dad0a2-2a37-4ce1-b783-0d1b4f30a00c&quot; alt=&quot;LanceDB Cloud Public Beta&quot; width=&quot;100%&quot; style=&quot;max-width: 100%;&quot;&gt;
&lt;/a&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/ac270358-333e-4bea-a132-acefaa94040e&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/b864d814-0d29-4784-8fd9-807297c758c0&quot;&gt;
  &lt;img alt=&quot;LanceDB Logo&quot; src=&quot;https://github.com/user-attachments/assets/b864d814-0d29-4784-8fd9-807297c758c0&quot; width=300&gt;
&lt;/picture&gt;

**Search More, Manage Less**

&lt;a href=&#039;https://github.com/lancedb/vectordb-recipes/tree/main&#039; target=&quot;_blank&quot;&gt;&lt;img alt=&#039;LanceDB&#039; src=&#039;https://img.shields.io/badge/VectorDB_Recipes-100000?style=for-the-badge&amp;logo=LanceDB&amp;logoColor=white&amp;labelColor=645cfb&amp;color=645cfb&#039;/&gt;&lt;/a&gt;
&lt;a href=&#039;https://lancedb.github.io/lancedb/&#039; target=&quot;_blank&quot;&gt;&lt;img alt=&#039;lancdb&#039; src=&#039;https://img.shields.io/badge/DOCS-100000?style=for-the-badge&amp;logo=lancdb&amp;logoColor=white&amp;labelColor=645cfb&amp;color=645cfb&#039;/&gt;&lt;/a&gt;
[![Blog](https://img.shields.io/badge/Blog-12100E?style=for-the-badge&amp;logoColor=white)](https://blog.lancedb.com/)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.gg/zMM32dvNtd)
[![Twitter](https://img.shields.io/badge/Twitter-%231DA1F2.svg?style=for-the-badge&amp;logo=Twitter&amp;logoColor=white)](https://twitter.com/lancedb)
[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20LanceDB%20Guru-006BFF?style=for-the-badge)](https://gurubase.io/g/lancedb)

&lt;/p&gt;

&lt;img max-width=&quot;750px&quot; alt=&quot;LanceDB Multimodal Search&quot; src=&quot;https://github.com/lancedb/lancedb/assets/917119/09c5afc5-7816-4687-bae4-f2ca194426ec&quot;&gt;

&lt;/p&gt;
&lt;/div&gt;

&lt;hr /&gt;

LanceDB is an open-source database for vector-search built with persistent storage, which greatly simplifies retrieval, filtering and management of embeddings.

The key features of LanceDB include:

* Production-scale vector search with no servers to manage.

* Store, query and filter vectors, metadata and multi-modal data (text, images, videos, point clouds, and more).

* Support for vector similarity search, full-text search and SQL.

* Native Python and Javascript/Typescript support.

* Zero-copy, automatic versioning, manage versions of your data without needing extra infrastructure.

* GPU support in building vector index(*).

* Ecosystem integrations with [LangChain ü¶úÔ∏èüîó](https://python.langchain.com/docs/integrations/vectorstores/lancedb/), [LlamaIndex ü¶ô](https://gpt-index.readthedocs.io/en/latest/examples/vector_stores/LanceDBIndexDemo.html), Apache-Arrow, Pandas, Polars, DuckDB and more on the way.

LanceDB&#039;s core is written in Rust ü¶Ä and is built using &lt;a href=&quot;https://github.com/lancedb/lance&quot;&gt;Lance&lt;/a&gt;, an open-source columnar format designed for performant ML workloads.

## Quick Start

**Javascript**
```shell
npm install @lancedb/lancedb
```

```javascript
import * as lancedb from &quot;@lancedb/lancedb&quot;;

const db = await lancedb.connect(&quot;data/sample-lancedb&quot;);
const table = await db.createTable(&quot;vectors&quot;, [
	{ id: 1, vector: [0.1, 0.2], item: &quot;foo&quot;, price: 10 },
	{ id: 2, vector: [1.1, 1.2], item: &quot;bar&quot;, price: 50 },
], {mode: &#039;overwrite&#039;});


const query = table.vectorSearch([0.1, 0.3]).limit(2);
const results = await query.toArray();

// You can also search for rows by specific criteria without involving a vector search.
const rowsByCriteria = await table.query().where(&quot;price &gt;= 10&quot;).toArray();
```

**Python**
```shell
pip install lancedb
```

```python
import lancedb

uri = &quot;data/sample-lancedb&quot;
db = lancedb.connect(uri)
table = db.create_table(&quot;my_table&quot;,
                         data=[{&quot;vector&quot;: [3.1, 4.1], &quot;item&quot;: &quot;foo&quot;, &quot;price&quot;: 10.0},
                               {&quot;vector&quot;: [5.9, 26.5], &quot;item&quot;: &quot;bar&quot;, &quot;price&quot;: 20.0}])
result = table.search([100, 100]).limit(2).to_pandas()
```

## Blogs, Tutorials &amp; Videos
* üìà &lt;a href=&quot;https://blog.lancedb.com/benchmarking-random-access-in-lance/&quot;&gt;2000x better performance with Lance over Parquet&lt;/a&gt;
* ü§ñ &lt;a href=&quot;https://github.com/lancedb/vectordb-recipes/tree/main/examples/Youtube-Search-QA-Bot&quot;&gt;Build a question and answer bot with LanceDB&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>