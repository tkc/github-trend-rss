<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Thu, 03 Jul 2025 00:05:54 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[GraphiteEditor/Graphite]]></title>
            <link>https://github.com/GraphiteEditor/Graphite</link>
            <guid>https://github.com/GraphiteEditor/Graphite</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:54 GMT</pubDate>
            <description><![CDATA[An open source graphics editor for 2025: comprehensive 2D content creation tool suite for graphic design, digital art, and interactive real-time motion graphics — featuring node-based procedural editing]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GraphiteEditor/Graphite">GraphiteEditor/Graphite</a></h1>
            <p>An open source graphics editor for 2025: comprehensive 2D content creation tool suite for graphic design, digital art, and interactive real-time motion graphics — featuring node-based procedural editing</p>
            <p>Language: Rust</p>
            <p>Stars: 17,738</p>
            <p>Forks: 765</p>
            <p>Stars today: 682 stars today</p>
            <h2>README</h2><pre>

&lt;a href=&quot;https://graphite.rs/&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/9366c148-4405-484f-909a-9a3526eb9209&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/791508ab-bcd5-4e31-a3b9-1187cfd7a2f6&quot;&gt;
&lt;img alt=&quot;Graphite logo&quot; src=&quot;https://github.com/user-attachments/assets/791508ab-bcd5-4e31-a3b9-1187cfd7a2f6&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;

# Your procedural toolbox for 2D content creation

**Graphite is a free, open source vector and raster graphics engine, [available now](https://editor.graphite.rs) in alpha. Get creative with a fully nondestructive editing workflow that combines layer-based compositing with node-based generative design.**

Having begun life as a vector editor, Graphite continues evolving into a generalized, all-in-one graphics toolbox that&#039;s built more like a game engine than a conventional creative app. The editor&#039;s tools wrap its node graph core, providing user-friendly workflows for vector, raster, and beyond. Photo editing, motion graphics, digital painting, desktop publishing, and VFX compositing are additional competencies on the planned [roadmap](https://graphite.rs/features/#roadmap) making Graphite into a highly versatile content creation tool.

Learn more from the [website](https://graphite.rs/), subscribe to the [newsletter](https://graphite.rs/#newsletter), consider [volunteering](https://graphite.rs/volunteer/) or [donating](https://graphite.rs/donate/), and remember to give this repository a ⭐!

&lt;br /&gt;
&lt;a href=&quot;https://discord.graphite.rs/&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/ad185fac-3b48-446d-863c-2bcb0724abee&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/aa23f503-f3bf-444a-9080-8eaa19fa2fa8&quot;&gt;
&lt;img alt=&quot;Discord&quot; src=&quot;https://github.com/user-attachments/assets/aa23f503-f3bf-444a-9080-8eaa19fa2fa8&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://www.reddit.com/r/graphite/&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/d8c05686-2eb9-4ac1-8149-728c12b4e71a&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/6f32329a-4d6f-42d8-9a2f-42977c0b3c05&quot;&gt;
&lt;img alt=&quot;Reddit&quot; src=&quot;https://github.com/user-attachments/assets/6f32329a-4d6f-42d8-9a2f-42977c0b3c05&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://bsky.app/profile/graphiteeditor.bsky.social&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/c736d80c-e9bf-4591-a7e0-a7723057a906&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/3db9b0a1-5ab7-4bff-bfd3-8a4ade7b98bd&quot;&gt;
&lt;img alt=&quot;Bluesky&quot; src=&quot;https://github.com/user-attachments/assets/3db9b0a1-5ab7-4bff-bfd3-8a4ade7b98bd&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://twitter.com/graphiteeditor&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/115f04cc-e3c2-4f90-ac35-eb9edd3ca9be&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/4ed4185d-a622-418c-bbf4-a0419e690ca9&quot;&gt;
&lt;img alt=&quot;Twitter&quot; src=&quot;https://github.com/user-attachments/assets/4ed4185d-a622-418c-bbf4-a0419e690ca9&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://www.youtube.com/@GraphiteEditor&quot;&gt;
&lt;picture&gt;
&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/user-attachments/assets/cbc02fad-5cbc-4715-a8e5-860198e989c7&quot;&gt;
&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/user-attachments/assets/d13b484d-97a8-4d9e-bbe4-c60348b3f676&quot;&gt;
&lt;img alt=&quot;YouTube&quot; src=&quot;https://github.com/user-attachments/assets/d13b484d-97a8-4d9e-bbe4-c60348b3f676&quot; width=&quot;48&quot; height=&quot;48&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;

https://github.com/user-attachments/assets/f4604aea-e8f1-45ce-9218-46ddc666f11d

## Support our mission ❤️

Graphite is 100% community built and funded. Please become a part of keeping the project alive and thriving with a [donation](https://graphite.rs/donate/) if you share a belief in our **mission**:

&gt; Graphite strives to unshackle the creativity of every budding artist and seasoned professional by building the best comprehensive art and design tool that&#039;s accessible to all.
&gt; 
&gt; Mission success will come when Graphite is an industry standard. A cohesive product vision and focus on innovation over imitation is the strategy that will make that possible.

## Screenshots

![Made using nondestructive boolean operations and procedural polka dot patterns](https://github.com/user-attachments/assets/decb7011-18c2-4c68-82af-d1fa5064244a)

![Mandelbrot fractal filled with a noise pattern, procedurally generated and infinitely scalable](https://github.com/user-attachments/assets/9e023997-185b-4f43-a724-797d308d9e7b)

![Design for a magazine spread, a preview of the upcoming focus on desktop publishing](https://github.com/user-attachments/assets/90eca551-5868-4f8d-9016-33958bf96345)

## Contributing/building the code

Are you a graphics programmer or Rust developer? Graphite aims to be one of the most approachable projects for putting your engineering skills to use in the world of open source. See [instructions here](https://graphite.rs/volunteer/guide/) for setting up the project and getting started.

*By submitting code for inclusion in the project, you are agreeing to license your changes under the Apache 2.0 license, and that you have the authority to do so. Some directories may have other licenses, like dual-licensed MIT/Apache 2.0, and code submissions to those directories mean you agree to the applicable license(s).*
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tursodatabase/turso]]></title>
            <link>https://github.com/tursodatabase/turso</link>
            <guid>https://github.com/tursodatabase/turso</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:53 GMT</pubDate>
            <description><![CDATA[Turso Database is a project to build the next evolution of SQLite.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tursodatabase/turso">tursodatabase/turso</a></h1>
            <p>Turso Database is a project to build the next evolution of SQLite.</p>
            <p>Language: Rust</p>
            <p>Stars: 11,398</p>
            <p>Forks: 440</p>
            <p>Stars today: 73 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;turso.png&quot; alt=&quot;Turso Database&quot; width=&quot;800&quot;/&gt;
  &lt;h1 align=&quot;center&quot;&gt;Turso Database&lt;/h1&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Turso Database&lt;/i&gt; is an in-process SQL database, compatible with SQLite.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a title=&quot;Build Status&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/actions/workflows/rust.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/tursodatabase/turso/rust.yml?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;Releases&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/release/tursodatabase/turso?style=flat-square&amp;color=9CF&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;Rust&quot; target=&quot;_blank&quot; href=&quot;https://crates.io/crates/turso&quot;&gt;&lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/crates/v/turso&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;JavaScript&quot; target=&quot;_blank&quot; href=&quot;https://www.npmjs.com/package/@tursodatabase/turso&quot;&gt;&lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/npm/v/@tursodatabase/turso&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;Python&quot; target=&quot;_blank&quot; href=&quot;https://pypi.org/project/pyturso/&quot;&gt;&lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/pypi/v/pyturso&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;MIT&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/blob/main/LICENSE.md&quot;&gt;&lt;img src=&quot;http://img.shields.io/badge/license-MIT-orange.svg?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a title=&quot;GitHub Pull Requests&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/pulls&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues-pr-closed/tursodatabase/turso.svg?style=flat-square&amp;color=FF9966&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;GitHub Commits&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/commits/main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/commit-activity/m/tursodatabase/turso.svg?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a title=&quot;Last Commit&quot; target=&quot;_blank&quot; href=&quot;https://github.com/tursodatabase/turso/commits/main&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/last-commit/tursodatabase/turso.svg?style=flat-square&amp;color=FF9900&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a title=&quot;Developer&#039;s Discord&quot; target=&quot;_blank&quot; href=&quot;https://discord.gg/jgjmyYgHwB&quot;&gt;&lt;img alt=&quot;Chat with the Core Developers on Discord&quot; src=&quot;https://img.shields.io/discord/1258658826257961020?label=Discord&amp;logo=Discord&amp;style=social&amp;label=Core%20Developers&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a title=&quot;Users&#039;s Discord&quot; target=&quot;_blank&quot; href=&quot;https://tur.so/discord&quot;&gt;&lt;img alt=&quot;Chat with other users of Turso (and Turso Cloud) on Discord&quot; src=&quot;https://img.shields.io/discord/933071162680958986?label=Discord&amp;logo=Discord&amp;style=social&amp;label=Users&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

---

## Features and Roadmap

Turso Database is a _work-in-progress_, in-process OLTP database engine library written in Rust that has:

* **SQLite compatibility** [[doc](COMPAT.md)] for SQL dialect, file formats, and the C API
* **Language bindings** for JavaScript/WebAssembly, Rust, Go, Python, and [Java](bindings/java)
* **Asynchronous I/O** support on Linux with `io_uring`
* **OS support** for Linux, macOS, and Windows

In the future, we will be also working on:

* **`BEGIN CONCURRENT`** for improved write throughput.
* **Indexing for vector search**.
* **Improved schema management** including better `ALTER` support and strict column types by default.

## Getting Started

Please see the [Turso Database Manual](docs/manual.md) for more information.

&lt;details&gt;
&lt;summary&gt;💻 Command Line&lt;/summary&gt;
&lt;br&gt;
You can install the latest `turso` release with:

```shell
curl --proto &#039;=https&#039; --tlsv1.2 -LsSf \
  https://github.com/tursodatabase/turso/releases/latest/download/turso_cli-installer.sh | sh
```

Then launch the shell to execute SQL statements:

```console
Turso
Enter &quot;.help&quot; for usage hints.
Connected to a transient in-memory database.
Use &quot;.open FILENAME&quot; to reopen on a persistent database
turso&gt; CREATE TABLE users (id INT PRIMARY KEY, username TEXT);
turso&gt; INSERT INTO users VALUES (1, &#039;alice&#039;);
turso&gt; INSERT INTO users VALUES (2, &#039;bob&#039;);
turso&gt; SELECT * FROM users;
1|alice
2|bob
```

You can also build and run the latest development version with:

```shell
cargo run
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;🦀 Rust&lt;/summary&gt;
&lt;br&gt;

```console
cargo add turso
```

Example usage:

```rust
let db = Builder::new_local(&quot;sqlite.db&quot;).build().await?;
let conn = db.connect()?;

let res = conn.query(&quot;SELECT * FROM users&quot;, ()).await?;
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;✨ JavaScript&lt;/summary&gt;
&lt;br&gt;

```console
npm i @tursodatabase/turso
```

Example usage:

```js
import { Database } from &#039;@tursodatabase/turso&#039;;

const db = new Database(&#039;sqlite.db&#039;);
const stmt = db.prepare(&#039;SELECT * FROM users&#039;);
const users = stmt.all();
console.log(users);
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;🐍 Python&lt;/summary&gt;
&lt;br&gt;

```console
pip install pyturso
```

Example usage:

```python
import turso

con = turso.connect(&quot;sqlite.db&quot;)
cur = con.cursor()
res = cur.execute(&quot;SELECT * FROM users&quot;)
print(res.fetchone())
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;🐹 Go&lt;/summary&gt;
&lt;br&gt;

1. Clone the repository
2. Build the library and set your LD_LIBRARY_PATH to include turso&#039;s target directory
```console
cargo build --package limbo-go
export LD_LIBRARY_PATH=/path/to/limbo/target/debug:$LD_LIBRARY_PATH
```
3. Use the driver

```console
go get github.com/tursodatabase/turso
go install github.com/tursodatabase/turso
```

Example usage:
```go
import (
    &quot;database/sql&quot;
    _ &quot;github.com/tursodatabase/turso&quot;
)

conn, _ = sql.Open(&quot;sqlite3&quot;, &quot;sqlite.db&quot;)
defer conn.Close()

stmt, _ := conn.Prepare(&quot;select * from users&quot;)
defer stmt.Close()

rows, _ = stmt.Query()
for rows.Next() {
    var id int
    var username string
    _ := rows.Scan(&amp;id, &amp;username)
    fmt.Printf(&quot;User: ID: %d, Username: %s\n&quot;, id, username)
}
```
&lt;/details&gt;

&lt;details&gt;

&lt;summary&gt;☕️ Java&lt;/summary&gt;
&lt;br&gt;

We integrated Turso Database into JDBC. For detailed instructions on how to use Turso Database with java, please refer to
the [README.md under bindings/java](bindings/java/README.md).
&lt;/details&gt;

## Contributing

We&#039;d love to have you contribute to Turso Database! Please check out the [contribution guide] to get started.

## FAQ

### Is Turso Database ready for production use?

Turso Database is currently under heavy development and is **not** ready for production use.

### How is Turso Database different from Turso&#039;s libSQL?

Turso Database is a project to build the next evolution of SQLite in Rust, with a strong open contribution focus and features like native async support, vector search, and more. The libSQL project is also an attempt to evolve SQLite in a similar direction, but through a fork rather than a rewrite.

Rewriting SQLite in Rust started as an unassuming experiment, and due to its incredible success, replaces libSQL as our intended direction. At this point, libSQL is production ready, Turso Database is not - although it is evolving rapidly. More details [here](https://turso.tech/blog/we-will-rewrite-sqlite-and-we-are-going-all-in).

## Publications

* Pekka Enberg, Sasu Tarkoma, Jon Crowcroft Ashwin Rao (2024). Serverless Runtime / Database Co-Design With Asynchronous I/O. In _EdgeSys ‘24_. [[PDF]](https://penberg.org/papers/penberg-edgesys24.pdf)
* Pekka Enberg, Sasu Tarkoma, and Ashwin Rao (2023). Towards Database and Serverless Runtime Co-Design. In _CoNEXT-SW ’23_. [[PDF](https://penberg.org/papers/penberg-conext-sw-23.pdf)] [[Slides](https://penberg.org/papers/penberg-conext-sw-23-slides.pdf)]

## License

This project is licensed under the [MIT license].

### Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Turso Database by you, shall be licensed as MIT, without any additional
terms or conditions.

[contribution guide]: https://github.com/tursodatabase/turso/blob/main/CONTRIBUTING.md
[MIT license]: https://github.com/tursodatabase/turso/blob/main/LICENSE.md

## Partners

Thanks to all the partners of Turso!

&lt;a href=&quot;https://blacksmith.sh&quot;&gt;&lt;img src=&quot;assets/blacksmith.svg&quot; width=&quot;400&quot;&gt;&lt;/a&gt;

&lt;a href=&quot;https://antithesis.com/&quot;&gt;&lt;img src=&quot;assets/antithesis.jpg&quot; width=&quot;400&quot;&gt;&lt;/a&gt;

## Contributors

Thanks to all the contributors to Turso Database!

&lt;a href=&quot;https://github.com/tursodatabase/turso/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=tursodatabase/turso&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[EasyTier/EasyTier]]></title>
            <link>https://github.com/EasyTier/EasyTier</link>
            <guid>https://github.com/EasyTier/EasyTier</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:52 GMT</pubDate>
            <description><![CDATA[A simple, decentralized mesh VPN with WireGuard support.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EasyTier/EasyTier">EasyTier/EasyTier</a></h1>
            <p>A simple, decentralized mesh VPN with WireGuard support.</p>
            <p>Language: Rust</p>
            <p>Stars: 5,370</p>
            <p>Forks: 462</p>
            <p>Stars today: 65 stars today</p>
            <h2>README</h2><pre># EasyTier

[![Github release](https://img.shields.io/github/v/tag/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/releases)
[![GitHub](https://img.shields.io/github/license/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/blob/main/LICENSE)
[![GitHub last commit](https://img.shields.io/github/last-commit/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/commits/main)
[![GitHub issues](https://img.shields.io/github/issues/EasyTier/EasyTier)](https://github.com/EasyTier/EasyTier/issues)
[![GitHub Core Actions](https://github.com/EasyTier/EasyTier/actions/workflows/core.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/core.yml)
[![GitHub GUI Actions](https://github.com/EasyTier/EasyTier/actions/workflows/gui.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/gui.yml)
[![GitHub Test Actions](https://github.com/EasyTier/EasyTier/actions/workflows/test.yml/badge.svg)](https://github.com/EasyTier/EasyTier/actions/workflows/test.yml)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/EasyTier/EasyTier)

[简体中文](/README_CN.md) | [English](/README.md)

**Please visit the [EasyTier Official Website](https://easytier.cn/en/) to view the full documentation.**

EasyTier is a simple, safe and decentralized VPN networking solution implemented with the Rust language and Tokio framework.

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;assets/image-5.png&quot; width=&quot;300&quot;&gt;
&lt;img src=&quot;assets/image-4.png&quot; width=&quot;300&quot;&gt;
&lt;/p&gt;

## Features

- **Decentralized**: No need to rely on centralized services, nodes are equal and independent.
- **Safe**: Use WireGuard protocol to encrypt data.
- **High Performance**: Full-link zero-copy, with performance comparable to mainstream networking software.
- **Cross-platform**: Supports MacOS/Linux/Windows/Android, will support IOS in the future. The executable file is statically linked, making deployment simple.
- **Networking without public IP**: Supports networking using shared public nodes, refer to [Configuration Guide](#Networking-without-public-IP)
- **NAT traversal**: Supports UDP-based NAT traversal, able to establish stable connections even in complex network environments.
- **Subnet Proxy (Point-to-Network)**: Nodes can expose accessible network segments as proxies to the VPN subnet, allowing other nodes to access these subnets through the node.
- **Smart Routing**: Selects links based on traffic to reduce latency and increase throughput.
- **TCP Support**: Provides reliable data transmission through concurrent TCP links when UDP is limited, optimizing performance.
- **High Availability**: Supports multi-path and switches to healthy paths when high packet loss or network errors are detected.
- **IPv6 Support**: Supports networking using IPv6.
- **Multiple Protocol Types**: Supports communication between nodes using protocols such as WebSocket and QUIC.
- **Web Management Interface**: Provides a [web-based management](https://easytier.cn/web) interface for easy configuration and monitoring.

## Installation

1. **Download the precompiled binary file**

    Visit the [GitHub Release page](https://github.com/EasyTier/EasyTier/releases) to download the binary file suitable for your operating system. Release includes both command-line programs and GUI programs in the compressed package.

2. **Install via crates.io**

    ```sh
    cargo install easytier
    ```

3. **Install from source code**

    ```sh
    cargo install --git https://github.com/EasyTier/EasyTier.git easytier
    ```

4. **Install by Docker Compose**

    Please visit the [EasyTier Official Website](https://easytier.cn/en/) to view the full documentation.

5. **Install by script (For Linux Only)**

    ```sh
    wget -O /tmp/easytier.sh &quot;https://raw.githubusercontent.com/EasyTier/EasyTier/main/script/install.sh&quot; &amp;&amp; bash /tmp/easytier.sh install
    ```

    The script supports the following commands and options:

    Commands:
    - `install`: Install EasyTier
    - `uninstall`: Uninstall EasyTier
    - `update`: Update EasyTier to the latest version
    - `help`: Show help message

    Options:
    - `--skip-folder-verify`: Skip folder verification during installation
    - `--skip-folder-fix`: Skip automatic folder path fixing
    - `--no-gh-proxy`: Disable GitHub proxy
    - `--gh-proxy`: Set custom GitHub proxy URL (default: https://ghfast.top/)

    Examples:
    ```sh
    # Show help
    bash /tmp/easytier.sh help

    # Install with options
    bash /tmp/easytier.sh install --skip-folder-verify
    bash /tmp/easytier.sh install --no-gh-proxy
    bash /tmp/easytier.sh install --gh-proxy https://your-proxy.com/

    # Update EasyTier
    bash /tmp/easytier.sh update

    # Uninstall EasyTier
    bash /tmp/easytier.sh uninstall
    ```

6. **Install by Homebrew (For MacOS Only)**

    ```sh
    brew tap brewforge/chinese
    brew install --cask easytier-gui
    ```

## Quick Start

&gt; The following text only describes the use of the command-line tool; the GUI program can be configured by referring to the following concepts.

Make sure EasyTier is installed according to the [Installation Guide](#Installation), and both easytier-core and easytier-cli commands are available.

### Two-node Networking

Assuming the network topology of the two nodes is as follows

```mermaid
flowchart LR

subgraph Node A IP 22.1.1.1
nodea[EasyTier\n10.144.144.1]
end

subgraph Node B
nodeb[EasyTier\n10.144.144.2]
end

nodea &lt;-----&gt; nodeb

```

1. Execute on Node A:

    ```sh
    sudo easytier-core --ipv4 10.144.144.1
    ```

    Successful execution of the command will print the following.

    ![alt text](/assets/image-2.png)

2. Execute on Node B

    ```sh
    sudo easytier-core --ipv4 10.144.144.2 --peers udp://22.1.1.1:11010
    ```

3. Test Connectivity

    The two nodes should connect successfully and be able to communicate within the virtual subnet

    ```sh
    ping 10.144.144.2
    ```

    Use easytier-cli to view node information in the subnet

    ```sh
    easytier-cli peer
    ```

    ![alt text](/assets/image.png)

    ```sh
    easytier-cli route
    ```

    ![alt text](/assets/image-1.png)


    ```sh
    easytier-cli node
    ```

    ![alt text](assets/image-10.png)

---

### Multi-node Networking

Based on the two-node networking example just now, if more nodes need to join the virtual network, you can use the following command.

```sh
sudo easytier-core --ipv4 10.144.144.2 --peers udp://22.1.1.1:11010
```

The `--peers` parameter can fill in the listening address of any node already in the virtual network.

---

### Subnet Proxy (Point-to-Network) Configuration

Assuming the network topology is as follows, Node B wants to share its accessible subnet 10.1.1.0/24 with other nodes.

```mermaid
flowchart LR

subgraph Node A IP 22.1.1.1
nodea[EasyTier\n10.144.144.1]
end

subgraph Node B
nodeb[EasyTier\n10.144.144.2]
end

id1[[10.1.1.0/24]]

nodea &lt;--&gt; nodeb &lt;-.-&gt; id1

```

Then the startup parameters for Node B&#039;s easytier are (new -n parameter)

```sh
sudo easytier-core --ipv4 10.144.144.2 -n 10.1.1.0/24
```

Subnet proxy information will automatically sync to each node in the virtual network, and each node will automatically configure the corresponding route. Node A can check whether the subnet proxy is effective through the following command.

1. Check whether the routing information has been synchronized, the proxy_cidrs column shows the proxied subnets.

    ```sh
    easytier-cli route
    ```

   ![alt text](/assets/image-3.png)

2. Test whether Node A can access nodes under the proxied subnet

    ```sh
    ping 10.1.1.2
    ```

---

### Networking without Public IP

EasyTier supports networking using shared public nodes. The currently deployed shared public node is ``tcp://public.easytier.cn:11010``.

When using shared nodes, each node entering the network needs to provide the same ``--network-name`` and ``--network-secret`` parameters as the unique identifier of the network.

Taking two nodes as an example, Node A executes:

```sh
sudo easytier-core -i 10.144.144.1 --network-name abc --network-secret abc -p tcp://public.easytier.cn:11010
```

Node B executes

```sh
sudo easytier-core --ipv4 10.144.144.2 --network-name abc --network-secret abc -p tcp://public.easytier.cn:11010
```

After the command is successfully executed, Node A can access Node B through the virtual IP 10.144.144.2.

### Use EasyTier with WireGuard Client

EasyTier can be used as a WireGuard server to allow any device with WireGuard client installed to access the EasyTier network. For platforms currently unsupported by EasyTier (such as iOS, Android, etc.), this method can be used to connect to the EasyTier network.

Assuming the network topology is as follows:

```mermaid
flowchart LR

ios[[iPhone \n WireGuard Installed]]

subgraph Node A IP 22.1.1.1
nodea[EasyTier\n10.144.144.1]
end

subgraph Node B
nodeb[EasyTier\n10.144.144.2]
end

id1[[10.1.1.0/24]]

ios &lt;-.-&gt; nodea &lt;--&gt; nodeb &lt;-.-&gt; id1
```

To enable an iPhone to access the EasyTier network through Node A, the following configuration can be applied:

Include the --vpn-portal parameter in the easytier-core command on Node A to specify the port that the WireGuard service listens on and the subnet used by the WireGuard network.

```sh
# The following parameters mean: listen on port 0.0.0.0:11013, and use the 10.14.14.0/24 subnet for WireGuard
sudo easytier-core --ipv4 10.144.144.1 --vpn-portal wg://0.0.0.0:11013/10.14.14.0/24
```

After successfully starting easytier-core, use easytier-cli to obtain the WireGuard client configuration.

```sh
$&gt; easytier-cli vpn-portal
portal_name: wireguard

############### client_config_start ###############

[Interface]
PrivateKey = 9VDvlaIC9XHUvRuE06hD2CEDrtGF+0lDthgr9SZfIho=
Address = 10.14.14.0/32 # should assign an ip from this cidr manually

[Peer]
PublicKey = zhrZQg4QdPZs8CajT3r4fmzcNsWpBL9ImQCUsnlXyGM=
AllowedIPs = 10.144.144.0/24,10.14.14.0/24
Endpoint = 0.0.0.0:11013 # should be the public ip(or domain) of the vpn server
PersistentKeepalive = 25

############### client_config_end ###############

connected_clients:
[]
```

Before using the Client Config, you need to modify the Interface Address and Peer Endpoint to the client&#039;s IP and the IP of the EasyTier node, respectively. Import the configuration file into the WireGuard client to access the EasyTier network.

### Self-Hosted Public Server

Every virtual network (with same network name and secret) can act as a public server cluster. Nodes of other network can connect to arbitrary nodes in public server cluster to discover each other without public IP.

Run you own public server cluster is exactly same as running an virtual network, except that you can skip config the ipv4 addr.

You can also join the official public server cluster with following command:

```
sudo easytier-core --network-name easytier --network-secret easytier -p tcp://public.easytier.cn:11010
```


### Configurations

You can use ``easytier-core --help`` to view all configuration items

## Roadmap

- [ ] Support features such TCP hole punching, KCP, FEC etc.
- [ ] Support iOS.

## Community and Contribution

We welcome and encourage community contributions! If you want to get involved, please submit a [GitHub PR](https://github.com/EasyTier/EasyTier/pulls). Detailed contribution guidelines can be found in [CONTRIBUTING.md](https://github.com/EasyTier/EasyTier/blob/main/CONTRIBUTING.md).

## Related Projects and Resources

- [ZeroTier](https://www.zerotier.com/): A global virtual network for connecting devices.
- [TailScale](https://tailscale.com/): A VPN solution aimed at simplifying network configuration.
- [vpncloud](https://github.com/dswd/vpncloud): A P2P Mesh VPN
- [Candy](https://github.com/lanthora/candy): A reliable, low-latency, and anti-censorship virtual private network

## License

EasyTier is released under the [Apache License 2.0](https://github.com/EasyTier/EasyTier/blob/main/LICENSE).

## Contact

- Ask questions or report problems: [GitHub Issues](https://github.com/EasyTier/EasyTier/issues)
- Discussion and exchange: [GitHub Discussions](https://github.com/EasyTier/EasyTier/discussions)
- Telegram：https://t.me/easytier
- QQ Group: 949700262

## Sponsor

&lt;img src=&quot;assets/image-8.png&quot; width=&quot;300&quot;&gt;
&lt;img src=&quot;assets/image-9.png&quot; width=&quot;300&quot;&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lancedb/lance]]></title>
            <link>https://github.com/lancedb/lance</link>
            <guid>https://github.com/lancedb/lance</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:51 GMT</pubDate>
            <description><![CDATA[Modern columnar data format for ML and LLMs implemented in Rust. Convert from parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lancedb/lance">lancedb/lance</a></h1>
            <p>Modern columnar data format for ML and LLMs implemented in Rust. Convert from parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..</p>
            <p>Language: Rust</p>
            <p>Stars: 4,936</p>
            <p>Forks: 369</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;

&lt;img width=&quot;257&quot; alt=&quot;Lance Logo&quot; src=&quot;https://user-images.githubusercontent.com/917119/199353423-d3e202f7-0269-411d-8ff2-e747e419e492.png&quot;&gt;

**Modern columnar data format for ML. Convert from Parquet in 2-lines of code for 100x faster random access, zero-cost schema evolution, rich secondary indices, versioning, and more.&lt;br/&gt;**
**Compatible with Pandas, DuckDB, Polars, Pyarrow, and Ray with more integrations on the way.**

&lt;a href=&quot;https://lancedb.github.io/lance/&quot;&gt;Documentation&lt;/a&gt; •
&lt;a href=&quot;https://blog.lancedb.com/&quot;&gt;Blog&lt;/a&gt; •
&lt;a href=&quot;https://discord.gg/zMM32dvNtd&quot;&gt;Discord&lt;/a&gt; •
&lt;a href=&quot;https://x.com/lancedb&quot;&gt;X&lt;/a&gt;

[CI]: https://github.com/lancedb/lance/actions/workflows/rust.yml
[CI Badge]: https://github.com/lancedb/lance/actions/workflows/rust.yml/badge.svg
[Docs]: https://lancedb.github.io/lance/
[Docs Badge]: https://img.shields.io/badge/docs-passing-brightgreen
[crates.io]: https://crates.io/crates/lance
[crates.io badge]: https://img.shields.io/crates/v/lance.svg
[Python versions]: https://pypi.org/project/pylance/
[Python versions badge]: https://img.shields.io/pypi/pyversions/pylance

[![CI Badge]][CI]
[![Docs Badge]][Docs]
[![crates.io badge]][crates.io]
[![Python versions badge]][Python versions]

&lt;/p&gt;
&lt;/div&gt;

&lt;hr /&gt;

Lance is a modern columnar data format that is optimized for ML workflows and datasets. Lance is perfect for:

1. Building search engines and feature stores.
2. Large-scale ML training requiring high performance IO and shuffles.
3. Storing, querying, and inspecting deeply nested data for robotics or large blobs like images, point clouds, and more.

The key features of Lance include:

* **High-performance random access:** 100x faster than Parquet without sacrificing scan performance.

* **Vector search:** find nearest neighbors in milliseconds and combine OLAP-queries with vector search.

* **Zero-copy, automatic versioning:** manage versions of your data without needing extra infrastructure.

* **Ecosystem integrations:** Apache Arrow, Pandas, Polars, DuckDB, Ray, Spark and more on the way.

&gt; [!TIP]
&gt; Lance is in active development and we welcome contributions. Please see our [contributing guide](docs/contributing.rst) for more information.

## Quick Start

**Installation**

```shell
pip install pylance
```

To install a preview release:

```shell
pip install --pre --extra-index-url https://pypi.fury.io/lancedb/ pylance
```

&gt; [!TIP]
&gt; Preview releases are released more often than full releases and contain the
&gt; latest features and bug fixes. They receive the same level of testing as full releases.
&gt; We guarantee they will remain published and available for download for at
&gt; least 6 months. When you want to pin to a specific version, prefer a stable release.

**Converting to Lance**

```python
import lance

import pandas as pd
import pyarrow as pa
import pyarrow.dataset

df = pd.DataFrame({&quot;a&quot;: [5], &quot;b&quot;: [10]})
uri = &quot;/tmp/test.parquet&quot;
tbl = pa.Table.from_pandas(df)
pa.dataset.write_dataset(tbl, uri, format=&#039;parquet&#039;)

parquet = pa.dataset.dataset(uri, format=&#039;parquet&#039;)
lance.write_dataset(parquet, &quot;/tmp/test.lance&quot;)
```

**Reading Lance data**
```python
dataset = lance.dataset(&quot;/tmp/test.lance&quot;)
assert isinstance(dataset, pa.dataset.Dataset)
```

**Pandas**
```python
df = dataset.to_table().to_pandas()
df
```

**DuckDB**
```python
import duckdb

# If this segfaults, make sure you have duckdb v0.7+ installed
duckdb.query(&quot;SELECT * FROM dataset LIMIT 10&quot;).to_df()
```

**Vector search**

Download the sift1m subset

```shell
wget ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz
tar -xzf sift.tar.gz
```

Convert it to Lance

```python
import lance
from lance.vector import vec_to_table
import numpy as np
import struct

nvecs = 1000000
ndims = 128
with open(&quot;sift/sift_base.fvecs&quot;, mode=&quot;rb&quot;) as fobj:
    buf = fobj.read()
    data = np.array(struct.unpack(&quot;&lt;128000000f&quot;, buf[4 : 4 + 4 * nvecs * ndims])).reshape((nvecs, ndims))
    dd = dict(zip(range(nvecs), data))

table = vec_to_table(dd)
uri = &quot;vec_data.lance&quot;
sift1m = lance.write_dataset(table, uri, max_rows_per_group=8192, max_rows_per_file=1024*1024)
```

Build the index

```python
sift1m.create_index(&quot;vector&quot;,
                    index_type=&quot;IVF_PQ&quot;,
                    num_partitions=256,  # IVF
                    num_sub_vectors=16)  # PQ
```

Search the dataset

```python
# Get top 10 similar vectors
import duckdb

dataset = lance.dataset(uri)

# Sample 100 query vectors. If this segfaults, make sure you have duckdb v0.7+ installed
sample = duckdb.query(&quot;SELECT vector FROM dataset USING SAMPLE 100&quot;).to_df()
query_vectors = np.array([np.array(x) for x in sample.vector])

# Get nearest neighbors for all of them
rs = [dataset.to_table(nearest={&quot;column&quot;: &quot;vector&quot;, &quot;k&quot;: 10, &quot;q&quot;: q})
      for q in query_vectors]
```

## Directory structure

| Directory          | Description              |
|--------------------|--------------------------|
| [rust](./rust)     | Core Rust implementation |
| [python](./python) | Python bindings (PyO3)   |
| [java](./java)     | Java bindings (JNI)      |
| [docs](./docs)     | Documentation source     |

## What makes Lance different

Here we will highlight a few aspects of Lance’s design. For more details, see the full [Lance design document](https://lancedb.github.io/lance/format.html).

**Vector index**: Vector index for similarity search over embedding space.
Support both CPUs (``x86_64`` and ``arm``) and GPU (``Nvidia (cuda)`` and ``Apple Silicon (mps)``).

**Encodings**: To achieve both fast columnar scan and sub-linear point queries, Lance uses custom encodings and layouts.

**Nested fields**: Lance stores each subfield as a separate column to support efficient filters like “find images where detected objects include cats”.

**Versioning**: A Manifest can be used to record snapshots. Currently we support creating new versions automatically via appends, overwrites, and index creation.

**Fast updates** (ROADMAP): Updates will be supported via write-ahead logs.

**Rich secondary indices**: Support `BTree`, `Bitmap`, `Full text search`, `Label list`,
`NGrams`, and more.

## Benchmarks

### Vector search

We used the SIFT dataset to benchmark our results with 1M vectors of 128D

1. For 100 randomly sampled query vectors, we get &lt;1ms average response time (on a 2023 m2 MacBook Air)

![avg_latency.png](docs/avg_latency.png)

2. ANNs are always a trade-off between recall and performance

![avg_latency.png](docs/recall_vs_latency.png)

### Vs. parquet

We create a Lance dataset using the Oxford Pet dataset to do some preliminary performance testing of Lance as compared to Parquet and raw image/XMLs. For analytics queries, Lance is 50-100x better than reading the raw metadata. For batched random access, Lance is 100x better than both parquet and raw files.

![](docs/lance_perf.png)

## Why are you building yet another data format?!

The machine learning development cycle involves the steps:

```mermaid
graph LR
    A[Collection] --&gt; B[Exploration];
    B --&gt; C[Analytics];
    C --&gt; D[Feature Engineer];
    D --&gt; E[Training];
    E --&gt; F[Evaluation];
    F --&gt; C;
    E --&gt; G[Deployment];
    G --&gt; H[Monitoring];
    H --&gt; A;
```

People use different data representations to varying stages for the performance or limited by the tooling available.
Academia mainly uses XML / JSON for annotations and zipped images/sensors data for deep learning, which
is difficult to integrate into data infrastructure and slow to train over cloud storage.
While industry uses data lakes (Parquet-based techniques, i.e., Delta Lake, Iceberg) or data warehouses (AWS Redshift
or Google BigQuery) to collect and analyze data, they have to convert the data into training-friendly formats, such
as [Rikai](https://github.com/eto-ai/rikai)/[Petastorm](https://github.com/uber/petastorm)
or [TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord).
Multiple single-purpose data transforms, as well as syncing copies between cloud storage to local training
instances have become a common practice.

While each of the existing data formats excels at the workload it was originally designed for, we need a new data format
tailored for multistage ML development cycles to reduce and data silos.

A comparison of different data formats in each stage of ML development cycle.

|                     | Lance | Parquet &amp; ORC | JSON &amp; XML | TFRecord | Database | Warehouse |
|---------------------|-------|---------------|------------|----------|----------|-----------|
| Analytics           | Fast  | Fast          | Slow       | Slow     | Decent   | Fast      |
| Feature Engineering | Fast  | Fast          | Decent     | Slow     | Decent   | Good      |
| Training            | Fast  | Decent        | Slow       | Fast     | N/A      | N/A       |
| Exploration         | Fast  | Slow          | Fast       | Slow     | Fast     | Decent    |
| Infra Support       | Rich  | Rich          | Decent     | Limited  | Rich     | Rich      |

## Community Highlights

Lance is currently used in production by:
* [LanceDB](https://github.com/lancedb/lancedb), a serverless, low-latency vector database for ML applications
* [LanceDB Enterprise](https://docs.lancedb.com/enterprise/introduction), hyperscale LanceDB with enterprise SLA.
* Leading multimodal Gen AI companies for training over petabyte-scale multimodal data.
* Self-driving car company for large-scale storage, retrieval and processing of multi-modal data.
* E-commerce company for billion-scale+ vector personalized search.
* and more.

## Presentations, Blogs and Talks

* [Designing a Table Format for ML Workloads](https://blog.lancedb.com/designing-a-table-format-for-ml-workloads/), Feb 2025.
* [Transforming Multimodal Data Management with LanceDB, Ray Summit](https://www.youtube.com/watch?v=xmTFEzAh8ho), Oct 2024.
* [Lance v2: A columnar container format for modern data](https://blog.lancedb.com/lance-v2/), Apr 2024.
* [Lance Deep Dive](https://drive.google.com/file/d/1Orh9rK0Mpj9zN_gnQF1eJJFpAc6lStGm/view?usp=drive_link). July 2023.
* [Lance: A New Columnar Data Format](https://docs.google.com/presentation/d/1a4nAiQAkPDBtOfXFpPg7lbeDAxcNDVKgoUkw3cUs2rE/edit#slide=id.p), [Scipy 2022, Austin, TX](https://www.scipy2022.scipy.org/posters). July, 2022.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[meilisearch/meilisearch]]></title>
            <link>https://github.com/meilisearch/meilisearch</link>
            <guid>https://github.com/meilisearch/meilisearch</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:50 GMT</pubDate>
            <description><![CDATA[A lightning-fast search engine API bringing AI-powered hybrid search to your sites and applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/meilisearch/meilisearch">meilisearch/meilisearch</a></h1>
            <p>A lightning-fast search engine API bringing AI-powered hybrid search to your sites and applications.</p>
            <p>Language: Rust</p>
            <p>Stars: 52,137</p>
            <p>Forks: 2,090</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=logo#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/meilisearch-logo-light.svg?sanitize=true#gh-light-mode-only&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=logo#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/meilisearch-logo-dark.svg?sanitize=true#gh-dark-mode-only&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Website&lt;/a&gt; |
  &lt;a href=&quot;https://roadmap.meilisearch.com/tabs/1-under-consideration&quot;&gt;Roadmap&lt;/a&gt; |
  &lt;a href=&quot;https://www.meilisearch.com/pricing?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Meilisearch Cloud&lt;/a&gt; |
  &lt;a href=&quot;https://blog.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Blog&lt;/a&gt; |
  &lt;a href=&quot;https://www.meilisearch.com/docs?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Documentation&lt;/a&gt; |
  &lt;a href=&quot;https://www.meilisearch.com/docs/faq?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;FAQ&lt;/a&gt; |
  &lt;a href=&quot;https://discord.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Discord&lt;/a&gt;
&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://deps.rs/repo/github/meilisearch/meilisearch&quot;&gt;&lt;img src=&quot;https://deps.rs/repo/github/meilisearch/meilisearch/status.svg&quot; alt=&quot;Dependency status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/meilisearch/meilisearch/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-MIT-informational&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/meilisearch/meilisearch/queue&quot;&gt;&lt;img alt=&quot;Merge Queues enabled&quot; src=&quot;https://img.shields.io/badge/Merge_Queues-enabled-%2357cf60?logo=github&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;⚡ A lightning-fast search engine that fits effortlessly into your apps, websites, and workflow 🔍&lt;/p&gt;

[Meilisearch](https://www.meilisearch.com?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=intro) helps you shape a delightful search experience in a snap, offering features that work out of the box to speed up your workflow.

&lt;p align=&quot;center&quot; name=&quot;demo&quot;&gt;
  &lt;a href=&quot;https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demo-gif#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/demo-light.gif#gh-light-mode-only&quot; alt=&quot;A bright colored application for finding movies screening near the user&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demo-gif#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/demo-dark.gif#gh-dark-mode-only&quot; alt=&quot;A dark colored application for finding movies screening near the user&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## 🖥 Examples

- [**Movies**](https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=organization) — An application to help you find streaming platforms to watch movies using [hybrid search](https://www.meilisearch.com/solutions/hybrid-search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos).
- [**Ecommerce**](https://ecommerce.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) — Ecommerce website using disjunctive [facets](https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos), range and rating filtering, and pagination.
- [**Songs**](https://music.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) — Search through 47 million of songs.
- [**SaaS**](https://saas.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) — Search for contacts, deals, and companies in this [multi-tenant](https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) CRM application.

See the list of all our example apps in our [demos repository](https://github.com/meilisearch/demos).

## ✨ Features
- **Hybrid search:** Combine the best of both [semantic](https://www.meilisearch.com/docs/learn/experimental/vector_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features) &amp; full-text search to get the most relevant results
- **Search-as-you-type:** Find &amp; display results in less than 50 milliseconds to provide an intuitive experience
- **[Typo tolerance](https://www.meilisearch.com/docs/learn/relevancy/typo_tolerance_settings?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** get relevant matches even when queries contain typos and misspellings
- **[Filtering](https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features) and [faceted search](https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** enhance your users&#039; search experience with custom filters and build a faceted search interface in a few lines of code
- **[Sorting](https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** sort results based on price, date, or pretty much anything else your users need
- **[Synonym support](https://www.meilisearch.com/docs/learn/relevancy/synonyms?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** configure synonyms to include more relevant content in your search results
- **[Geosearch](https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** filter and sort documents based on geographic data
- **[Extensive language support](https://www.meilisearch.com/docs/learn/what_is_meilisearch/language?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** search datasets in any language, with optimized support for Chinese, Japanese, Hebrew, and languages using the Latin alphabet
- **[Security management](https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** control which users can access what data with API keys that allow fine-grained permissions handling
- **[Multi-Tenancy](https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** personalize search results for any number of application tenants
- **Highly Customizable:** customize Meilisearch to your specific needs or use our out-of-the-box and hassle-free presets
- **[RESTful API](https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** integrate Meilisearch in your technical stack with our plugins and SDKs
- **AI-ready:** works out of the box with [langchain](https://www.meilisearch.com/with/langchain) and the [model context protocol](https://github.com/meilisearch/meilisearch-mcp)
- **Easy to install, deploy, and maintain**

## 📖 Documentation

You can consult Meilisearch&#039;s documentation at [meilisearch.com/docs](https://www.meilisearch.com/docs/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=docs).

## 🚀 Getting started

For basic instructions on how to set up Meilisearch, add documents to an index, and search for documents, take a look at our [documentation](https://www.meilisearch.com/docs?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=get-started) guide.

## 🌍 Supercharge your Meilisearch experience

Say goodbye to server deployment and manual updates with [Meilisearch Cloud](https://www.meilisearch.com/cloud?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch). Additional features include analytics &amp; monitoring in many regions around the world. No credit card is required.

## 🧰 SDKs &amp; integration tools

Install one of our SDKs in your project for seamless integration between Meilisearch and your favorite language or framework!

Take a look at the complete [Meilisearch integration list](https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=sdks-link).

[![Logos belonging to different languages and frameworks supported by Meilisearch, including React, Ruby on Rails, Go, Rust, and PHP](assets/integrations.png)](https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=sdks-logos)

## ⚙️ Advanced usage

Experienced users will want to keep our [API Reference](https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced) close at hand.

We also offer a wide range of dedicated guides to all Meilisearch features, such as [filtering](https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), [sorting](https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), [geosearch](https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), [API keys](https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), and [tenant tokens](https://www.meilisearch.com/docs/learn/security/tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced).

Finally, for more in-depth information, refer to our articles explaining fundamental Meilisearch concepts such as [documents](https://www.meilisearch.com/docs/learn/core_concepts/documents?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced) and [indexes](https://www.meilisearch.com/docs/learn/core_concepts/indexes?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced).

## 📊 Telemetry

Meilisearch collects **anonymized** user data to help us improve our product. You can [deactivate this](https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=telemetry#how-to-disable-data-collection) whenever you want.

To request deletion of collected data, please write to us at [privacy@meilisearch.com](mailto:privacy@meilisearch.com). Remember to include your `Instance UID` in the message, as this helps us quickly find and delete your data.

If you want to know more about the kind of data we collect and what we use it for, check the [telemetry section](https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=telemetry#how-to-disable-data-collection) of our documentation.

## 📫 Get in touch!

Meilisearch is a search engine created by [Meili](https://www.meilisearch.com/careers), a software development company headquartered in France and with team members all over the world. Want to know more about us? [Check out our blog!](https://blog.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=contact)

🗞 [Subscribe to our newsletter](https://meilisearch.us2.list-manage.com/subscribe?u=27870f7b71c908a8b359599fb&amp;id=79582d828e) if you don&#039;t want to miss any updates! We promise we won&#039;t clutter your mailbox: we only send one edition every two months.

💌 Want to make a suggestion or give feedback? Here are some of the channels where you can reach us:

- For feature requests, please visit our [product repository](https://github.com/meilisearch/product/discussions)
- Found a bug? Open an [issue](https://github.com/meilisearch/meilisearch/issues)!
- Want to be part of our Discord community? [Join us!](https://discord.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=contact)

Thank you for your support!

## 👩‍💻 Contributing

Meilisearch is, and will always be, open-source! If you want to contribute to the project, please look at [our contribution guidelines](CONTRIBUTING.md).

## 📦 Versioning

Meilisearch releases and their associated binaries are available on the project&#039;s [releases page](https://github.com/meilisearch/meilisearch/releases).

The binaries are versioned following [SemVer conventions](https://semver.org/). To know more, read our [versioning policy](https://github.com/meilisearch/engine-team/blob/main/resources/versioning-policy.md).

Differently from the binaries, crates in this repository are not currently available on [crates.io](https://crates.io/) and do not follow [SemVer conventions](https://semver.org).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[wasmerio/wasmer]]></title>
            <link>https://github.com/wasmerio/wasmer</link>
            <guid>https://github.com/wasmerio/wasmer</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:49 GMT</pubDate>
            <description><![CDATA[🚀 Fast, secure, lightweight containers based on WebAssembly]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wasmerio/wasmer">wasmerio/wasmer</a></h1>
            <p>🚀 Fast, secure, lightweight containers based on WebAssembly</p>
            <p>Language: Rust</p>
            <p>Stars: 19,857</p>
            <p>Forks: 889</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://wasmer.io&quot; target=&quot;_blank&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/logo-white.png&quot;  media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;img width=&quot;300&quot; src=&quot;https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/logo.png&quot; alt=&quot;Wasmer logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;

  &lt;p&gt;
     &lt;a href=&quot;https://github.com/wasmerio/wasmer/releases&quot;&gt;
      &lt;img src=&quot;https://shields.io/github/v/tag/wasmerio/wasmer&quot; alt=&quot;Github release&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/wasmerio/wasmer/blob/main/LICENSE&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/github/license/wasmerio/wasmer.svg&quot; alt=&quot;License&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://docs.wasmer.io&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/static/v1?label=Docs&amp;message=docs.wasmer.io&amp;color=blue&quot; alt=&quot;Wasmer Docs&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/rWkMNStrEW&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/discord/1110300506942881873?label=Wasmer&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Wasmer on Discord&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://x.com/wasmerio&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/twitter/follow/wasmerio&quot; alt=&quot;Wasmer on X&quot;&gt;
    &lt;/a&gt;  
  &lt;/p&gt;
&lt;/div&gt;

&lt;br /&gt; 

Wasmer is a _blazing fast_ and _secure_ [**WebAssembly**](https://webassembly.org) runtime that enables incredibly
_lightweight containers_ to run anywhere: from _Desktop_ to the _Cloud_, _Edge_ and your browser.

- **Secure** by default. No file, network, or environment access, unless explicitly enabled.
- **Pluggable**. supports [**WASIX**](https://wasix.org/), [WASI](https://github.com/WebAssembly/WASI) out of the box.
- **Incredibly Fast**. Run WebAssembly at near-native speeds.
- **Embeddable** [anywhere via Wasmer SDKs](https://github.com/wasmerio/wasmer/#wasmer-sdk)

### Install Wasmer

```sh
curl https://get.wasmer.io -sSfL | sh
```

&lt;details&gt;
  &lt;summary&gt;Other installation options (Powershell, Brew, Cargo, ...)&lt;/summary&gt;
  
  _Wasmer can be installed from various package managers. Choose the one that fits best for your environment:_
  
  * Powershell (Windows)
    ```powershell
    iwr https://win.wasmer.io -useb | iex
    ```

- &lt;a href=&quot;https://formulae.brew.sh/formula/wasmer&quot;&gt;Homebrew&lt;/a&gt; (macOS, Linux)

  ```sh
  brew install wasmer
  ```

- &lt;a href=&quot;https://github.com/ScoopInstaller/Main/blob/master/bucket/wasmer.json&quot;&gt;Scoop&lt;/a&gt; (Windows)

  ```sh
  scoop install wasmer
  ```

- &lt;a href=&quot;https://chocolatey.org/packages/wasmer&quot;&gt;Chocolatey&lt;/a&gt; (Windows)

  ```sh
  choco install wasmer
  ```

- &lt;a href=&quot;https://crates.io/crates/cargo-binstall/&quot;&gt;Cargo binstall&lt;/a&gt;

  ```sh
  cargo binstall wasmer-cli
  ```

- &lt;a href=&quot;https://crates.io/crates/wasmer-cli/&quot;&gt;Cargo&lt;/a&gt;

  _Note: All the available
  features are described in the [`wasmer-cli`
  crate docs](https://github.com/wasmerio/wasmer/tree/main/lib/cli/README.md)_

  ```sh
  cargo install wasmer-cli
  ```

&gt; Looking for more installation options? See [the `wasmer-install`
&gt; repository](https://github.com/wasmerio/wasmer-install) to learn
&gt; more!

&lt;/details&gt;

&gt; Note: You can also try Wasmer online in [wasmer.sh](https://wasmer.sh/)

### Quickstart

&gt; [!Tip]  
&gt; As part of our commitment to open source, we want to reward all GitHub users. In addition to the free tier, you can get up to $200 in [Wasmer Edge](https://wasmer.io/products/edge) credits for your open-source contributions - [Claim here](https://github.com/wasmerio/wasmer/discussions/5560).

You can start by running
[Cowsay](https://wasmer.io/syrusakbary/cowsay):

```bash
$ wasmer run cowsay &quot;hello world&quot;
 _____________
&lt; hello world &gt;
 -------------
        \   ^__^
         \  (oo)\_______
            (__)\       )\/\
               ||----w |
                ||     ||
```

&gt; There are many more available packages, such as [`wasmer/python`](https://wasmer.io/wasmer/python) or [`quickjs`](https://wasmer.io/saghul/quickjs). [Create your own package](https://docs.wasmer.io/registry/get-started), or explore packages from the community: https://wasmer.io/explore

#### Here is what you can do next:

- [Run a package](https://docs.wasmer.io/runtime/get-started)
- [Publish a package](https://docs.wasmer.io/registry/get-started)
- [Deploy your website](https://docs.wasmer.io/edge/get-started)
- [Read more about Wasmer](https://wasmer.io/posts)

## Wasmer SDK

You can use the Wasmer runtime **embedded in different
languages** with the Wasmer SDK:

|                  | Language                             | Package                               | Documentation          |
| ---------------- | ------------------------------------ | ------------------------------------- | ---------------------- |
| ![Rust logo]     | [**Rust**][Rust integration]         | [`wasmer` Rust crate]                 | [Learn][rust docs]     |
| ![C logo]        | [**C**][C integration]               | [`wasm.h` header]                     | [Learn][c docs]        |
| ![C++ logo]      | [**C++**][C integration]             | [`wasm.hh` header]                    | [Learn][c docs]        |
| ![C# logo]       | [**C#**][C# integration]             | [`WasmerSharp` NuGet package]         | [Learn][c# docs]       |
| ![D logo]        | [**D**][D integration]               | [`wasmer` Dub package]                | [Learn][d docs]        |
| ![Zig logo]      | [**Zig**][Zig integration]           | [`wasmer` Zig package]                | [Learn][zig docs]      |
| ![Python logo]   | [**Python**][Python integration]     | [`wasmer` PyPI package]               | [Learn][python docs]   |
| ![JS logo]       | [**Javascript**][JS integration]     | [`@wasmerio` NPM packages]            | [Learn][js docs]       |
| ![Go logo]       | [**Go**][Go integration]             | [`wasmer` Go package]                 | [Learn][go docs]       |
| ![PHP logo]      | [**PHP**][PHP integration]           | [`wasm` PECL package]                 | [Learn][php docs]      |
| ![Ruby logo]     | [**Ruby**][Ruby integration]         | [`wasmer` Ruby Gem]                   | [Learn][ruby docs]     |
| ![Java logo]     | [**Java**][Java integration]         | [`wasmer/wasmer-jni` Bintray package] | [Learn][java docs]     |
| ![R logo]        | [**R**][R integration]               | _no published package_                | [Learn][r docs]        |
| ![Postgres logo] | [**Postgres**][Postgres integration] | _no published package_                | [Learn][postgres docs] |
| ![Swift logo]    | [**Swift**][Swift integration]       | _no published package_                |                        |
| ![Dart logo]     | [**Dart**][Dart integration]         | [`wasm` pub package]                  |                        |
| ![Crystal logo]  | [**Crystal**][Crystal integration]   | _no published package_                | [Learn][crystal docs]  |
| ![Lisp logo]     | [**Lisp**][Lisp integration]         | _no published package_                |                        |
| ![Julia logo]    | [**Julia**][Julia integration]       | _no published package_                |                        |
| ![VLang logo]    | [**V**][vlang integration]           | _no published package_                |                        |
| ![Ocaml logo]    | [**OCaml**][OCaml integration]       | [`wasmer` OCaml package]              |                        |

[👋&amp;nbsp;&amp;nbsp;Missing a language?](https://github.com/wasmerio/wasmer/issues/new?assignees=&amp;labels=%F0%9F%8E%89+enhancement&amp;template=---feature-request.md&amp;title=)

[rust logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/rust.svg
[rust integration]: https://github.com/wasmerio/wasmer/tree/main/lib/api
[`wasmer` rust crate]: https://crates.io/crates/wasmer/
[rust docs]: https://docs.rs/wasmer/
[c logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/c.svg
[c integration]: https://github.com/wasmerio/wasmer/tree/main/lib/c-api
[`wasm.h` header]: https://github.com/wasmerio/wasmer/blob/main/lib/c-api/tests/wasm-c-api/include/wasm.h
[c docs]: https://docs.rs/wasmer-c-api/*/wasmer/wasm_c_api/index.html
[c++ logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/cpp.svg
[`wasm.hh` header]: https://github.com/wasmerio/wasmer/blob/main/lib/c-api/tests/wasm-c-api/include/wasm.hh
[c# logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/csharp.svg
[c# integration]: https://github.com/migueldeicaza/WasmerSharp
[`wasmersharp` nuget package]: https://www.nuget.org/packages/WasmerSharp/
[c# docs]: https://migueldeicaza.github.io/WasmerSharp/
[d logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/d.svg
[d integration]: https://github.com/chances/wasmer-d
[`wasmer` Dub package]: https://code.dlang.org/packages/wasmer
[d docs]: https://chances.github.io/wasmer-d
[python logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/python.svg
[python integration]: https://github.com/wasmerio/wasmer-python
[`wasmer` pypi package]: https://pypi.org/project/wasmer/
[python docs]: https://wasmerio.github.io/wasmer-python/api/wasmer
[go logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/go.svg
[go integration]: https://github.com/wasmerio/wasmer-go
[`wasmer` go package]: https://pkg.go.dev/github.com/wasmerio/wasmer-go/wasmer
[go docs]: https://pkg.go.dev/github.com/wasmerio/wasmer-go/wasmer?tab=doc
[php logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/php.svg
[php integration]: https://github.com/wasmerio/wasmer-php
[`wasm` pecl package]: https://pecl.php.net/package/wasm
[php docs]: https://wasmerio.github.io/wasmer-php/
[js logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/js.svg
[js integration]: https://github.com/wasmerio/wasmer-js
[`@wasmerio` npm packages]: https://www.npmjs.com/org/wasmer
[js docs]: https://docs.wasmer.io/sdk/wasmer-js
[ruby logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/ruby.svg
[ruby integration]: https://github.com/wasmerio/wasmer-ruby
[`wasmer` ruby gem]: https://rubygems.org/gems/wasmer
[ruby docs]: https://wasmerio.github.io/wasmer-ruby/wasmer_ruby/index.html
[java logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/java.svg
[java integration]: https://github.com/wasmerio/wasmer-java
[`wasmer/wasmer-jni` bintray package]: https://bintray.com/wasmer/wasmer-jni/wasmer-jni
[java docs]: https://github.com/wasmerio/wasmer-java/#api-of-the-wasmer-library
[elixir logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/elixir.svg
[elixir integration]: https://github.com/tessi/wasmex
[elixir docs]: https://hexdocs.pm/wasmex/api-reference.html
[`wasmex` hex package]: https://hex.pm/packages/wasmex
[r logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/r.svg
[r integration]: https://github.com/dirkschumacher/wasmr
[r docs]: https://github.com/dirkschumacher/wasmr#example
[postgres logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/postgres.svg
[postgres integration]: https://github.com/wasmerio/wasmer-postgres
[postgres docs]: https://github.com/wasmerio/wasmer-postgres#usage--documentation
[swift logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/swift.svg
[swift integration]: https://github.com/AlwaysRightInstitute/SwiftyWasmer
[zig logo]: https://raw.githubusercontent.com/ziglang/logo/master/zig-mark.svg
[zig integration]: https://github.com/Afirium/wasmer-zig-api
[`wasmer` Zig package]: https://github.com/Afirium/wasmer-zig-api/releases/
[zig docs]: https://wasmer-zig-api.crappy.systems/
[dart logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/dart.svg
[dart integration]: https://github.com/dart-lang/wasm
[`wasm` pub package]: https://pub.dev/packages/wasm
[lisp logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/lisp.svg
[lisp integration]: https://github.com/helmutkian/cl-wasm-runtime
[crystal logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/crystal.svg
[crystal integration]: https://github.com/naqvis/wasmer-crystal
[crystal docs]: https://naqvis.github.io/wasmer-crystal/
[julia logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/julia.svg
[julia integration]: https://github.com/Pangoraw/Wasmer.jl
[vlang logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/vlang.svg
[vlang integration]: https://github.com/vlang/wasmer
[OCaml logo]: https://raw.githubusercontent.com/wasmerio/wasmer/master/assets/languages/ocaml.svg
[OCaml integration]: https://github.com/wasmerio/wasmer-ocaml
[`wasmer` OCaml package]: https://opam.ocaml.org/packages/wasmer/

## Develop

We have different guides to help you develop Wasmer:

* [Build Wasmer from Source](./docs/BUILD.md)
* [Testing](./docs/TEST.md)
* [Security advisory](./docs/SECURITY.md)


## Contribute

We appreciate your help! 💜

We recommend reading the following guide on how to contribute into a complex project successfully:
https://mitchellh.com/writing/contributing-to-complex-projects

Check our docs on how to [build Wasmer from
source](./docs/BUILD.md) or [test your changes](https://docs.wasmer.io/developers/testing).

&lt;!-- ## Bounties

For some issues we offer paid bounties. You&#039;ll get paid automatically as soon as your PR solving the issue is merged!

&lt;a href=&quot;https://console.algora.io/org/wasmerio/bounties?status=open&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://console.algora.io/api/og/wasmerio/bounties.png?p=0&amp;status=open&amp;theme=dark&quot;&gt;
    &lt;img alt=&quot;Bounties of wasmerio&quot; src=&quot;https://console.algora.io/api/og/wasmerio/bounties.png?p=0&amp;status=open&amp;theme=light&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt; --&gt;

## Community

Wasmer has an amazing community of developers and contributors. Welcome, please join us! 👋

- [Wasmer Community Discord](https://discord.gg/rWkMNStrEW)
- [Wasmer on Twitter](https://twitter.com/wasmerio)

--------

&gt; _README also in:
&gt; [🇨🇳 中 文 -Chinese](https://github.com/wasmerio/wasmer/blob/main/docs/cn/README.md) •
&gt; [🇩🇪 Deutsch-German](https://github.com/wasmerio/wasmer/blob/main/docs/de/README.md) •
&gt; [🇪🇸 Español-Spanish](https://github.com/wasmerio/wasmer/blob/main/docs/es/README.md) •
&gt; [🇫🇷 Français-French](https://github.com/wasmerio/wasmer/blob/main/docs/fr/README.md) •
&gt; [🇯🇵 日本 語 -Japanese](https://github.com/wasmerio/wasmer/blob/main/docs/ja/README.md) •
&gt; [🇰🇷 한국어 -Korean](https://github.com/wasmerio/wasmer/blob/main/docs/ko/README.md)_.

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[helix-editor/helix]]></title>
            <link>https://github.com/helix-editor/helix</link>
            <guid>https://github.com/helix-editor/helix</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:48 GMT</pubDate>
            <description><![CDATA[A post-modern modal text editor.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/helix-editor/helix">helix-editor/helix</a></h1>
            <p>A post-modern modal text editor.</p>
            <p>Language: Rust</p>
            <p>Stars: 38,318</p>
            <p>Forks: 2,901</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;h1&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;logo_dark.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;logo_light.svg&quot;&gt;
  &lt;img alt=&quot;Helix&quot; height=&quot;128&quot; src=&quot;logo_light.svg&quot;&gt;
&lt;/picture&gt;
&lt;/h1&gt;

[![Build status](https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg)](https://github.com/helix-editor/helix/actions)
[![GitHub Release](https://img.shields.io/github/v/release/helix-editor/helix)](https://github.com/helix-editor/helix/releases/latest)
[![Documentation](https://shields.io/badge/-documentation-452859)](https://docs.helix-editor.com/)
[![GitHub contributors](https://img.shields.io/github/contributors/helix-editor/helix)](https://github.com/helix-editor/helix/graphs/contributors)
[![Matrix Space](https://img.shields.io/matrix/helix-community:matrix.org)](https://matrix.to/#/#helix-community:matrix.org)

&lt;/div&gt;

![Screenshot](./screenshot.png)

A [Kakoune](https://github.com/mawww/kakoune) / [Neovim](https://github.com/neovim/neovim) inspired editor, written in Rust.

The editing model is very heavily based on Kakoune; during development I found
myself agreeing with most of Kakoune&#039;s design decisions.

For more information, see the [website](https://helix-editor.com) or
[documentation](https://docs.helix-editor.com/).

All shortcuts/keymaps can be found [in the documentation on the website](https://docs.helix-editor.com/keymap.html).

[Troubleshooting](https://github.com/helix-editor/helix/wiki/Troubleshooting)

# Features

- Vim-like modal editing
- Multiple selections
- Built-in language server support
- Smart, incremental syntax highlighting and code editing via tree-sitter

Although it&#039;s primarily a terminal-based editor, I am interested in exploring
a custom renderer (similar to Emacs) using wgpu or skulpin.

Note: Only certain languages have indentation definitions at the moment. Check
`runtime/queries/&lt;lang&gt;/` for `indents.scm`.

# Installation

[Installation documentation](https://docs.helix-editor.com/install.html).

[![Packaging status](https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1)](https://repology.org/project/helix-editor/versions)

# Contributing

Contributing guidelines can be found [here](./docs/CONTRIBUTING.md).

# Getting help

Your question might already be answered on the [FAQ](https://github.com/helix-editor/helix/wiki/FAQ).

Discuss the project on the community [Matrix Space](https://matrix.to/#/#helix-community:matrix.org) (make sure to join `#helix-editor:matrix.org` if you&#039;re on a client that doesn&#039;t support Matrix Spaces yet).

# Credits

Thanks to [@jakenvac](https://github.com/jakenvac) for designing the logo!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[GyulyVGC/sniffnet]]></title>
            <link>https://github.com/GyulyVGC/sniffnet</link>
            <guid>https://github.com/GyulyVGC/sniffnet</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:47 GMT</pubDate>
            <description><![CDATA[Comfortably monitor your Internet traffic 🕵️‍♂️]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GyulyVGC/sniffnet">GyulyVGC/sniffnet</a></h1>
            <p>Comfortably monitor your Internet traffic 🕵️‍♂️</p>
            <p>Language: Rust</p>
            <p>Stars: 25,555</p>
            <p>Forks: 810</p>
            <p>Stars today: 132 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;picture&gt;
&lt;img alt=&quot;&quot; title=&quot;Sniffnet&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/header_repository.png&quot; width=&quot;95%&quot;/&gt;
&lt;/picture&gt;

&lt;a href=&quot;#download&quot;&gt;&lt;img alt=&quot;&quot; title=&quot;Download&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/download.svg&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/GyulyVGC/sniffnet/blob/main/ROADMAP.md&quot;&gt;&lt;img alt=&quot;&quot; title=&quot;Roadmap&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/roadmap.svg&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://sniffnet.net&quot;&gt;&lt;img alt=&quot;&quot; title=&quot;Website&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/website.svg&quot;/&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/GyulyVGC/sniffnet/wiki&quot;&gt;&lt;img alt=&quot;&quot; title=&quot;Wiki&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/wiki.svg&quot;/&gt;&lt;/a&gt;

Application to comfortably monitor your Internet traffic.&lt;br&gt;
Cross-platform. Intuitive. Reliable.

Translated in:&lt;br&gt;
🇨🇳 🇩🇪 🇫🇷 🇷🇺 🇵🇹 🇪🇦 🇮🇹 🇵🇱 [+&amp;nbsp;14&amp;nbsp;more&amp;nbsp;languages](https://github.com/GyulyVGC/sniffnet/issues/60)
&lt;/div&gt;

&lt;p&gt;
&lt;picture&gt;
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/hr.png&quot; width=&quot;100%&quot;/&gt;
&lt;/picture&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img alt=&quot;&quot; title=&quot;Overview page&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/overview.png&quot; width=&quot;95%&quot;/&gt;
&lt;img alt=&quot;&quot; title=&quot;Inspect page&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/inspect.png&quot; width=&quot;47%&quot;/&gt;
&lt;img alt=&quot;&quot; title=&quot;Notifications page&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/notifications.png&quot; width=&quot;47%&quot;/&gt;
&lt;img alt=&quot;&quot; title=&quot;Custom theme&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/deep_cosmos.png&quot; width=&quot;47%&quot;/&gt;
&lt;img alt=&quot;&quot; title=&quot;Thumbnail mode&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/pages/thumbnail.png&quot; width=&quot;47%&quot;/&gt;
&lt;/div&gt;

&lt;p&gt;
&lt;picture&gt;
&lt;img alt=&quot;&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/hr.png&quot; width=&quot;100%&quot;/&gt;
&lt;/picture&gt;
&lt;/p&gt;


## _Support Sniffnet&#039;s development_ 💖

&lt;i&gt;Sniffnet is completely free, open-source software which needs lots of effort and time to develop and maintain.&lt;/i&gt;

&lt;i&gt;If you appreciate Sniffnet, [consider sponsoring](https://github.com/sponsors/GyulyVGC):
your support will enable a constant growth with [new features and functionalities](https://github.com/GyulyVGC/sniffnet/blob/main/ROADMAP.md).&lt;br&gt;
Do you want to help the project in an alternative way? You can also head to the [official store](https://grindhouse.dev/collections/sniffnet) and put your hands on some cool merchandise!&lt;/i&gt;

&lt;i&gt;A special mention goes to these awesome organizations and folks who are sponsoring Sniffnet:&lt;/i&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/github&quot; title=&quot;GitHub&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/github?v=4&quot; width=&quot;60px&quot; alt=&quot;GitHub&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://nlnet.nl&quot; title=&quot;NLnet&quot;&gt;&lt;img src=&quot;https://nlnet.nl/logo/logo.svg&quot; width=&quot;60px&quot; alt=&quot;NLnet&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://ipinfo.io&quot; title=&quot;IPinfo&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/ipinfo?v=4&quot; width=&quot;60px&quot; alt=&quot;IPinfo&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/Cthulu201&quot; title=&quot;Cthulu201&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/Cthulu201?v=4&quot; width=&quot;60px&quot; alt=&quot;Cthulu201&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/0x0177b11f&quot; title=&quot;Tiansheng Li&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/0x0177b11f?v=4&quot; width=&quot;60px&quot; alt=&quot;Tiansheng Li&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/ZEROF&quot; title=&quot;ZEROF&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/ZEROF?v=4&quot; width=&quot;60px&quot; alt=&quot;ZEROF&quot;/&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://www.janwalter.org/&quot; title=&quot;Jan Walter&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/wahn?v=4&quot; width=&quot;60px&quot; alt=&quot;Jan Walter&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;


## Download

|                                                                        &lt;a href=&quot;#download&quot;&gt;&lt;img alt=&quot;Windows&quot; title=&quot;Windows&quot; height=&quot;35px&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/windows.svg&quot;/&gt;&lt;/a&gt;                                                                         |                           &lt;a href=&quot;#download&quot;&gt;&lt;img alt=&quot;macOS&quot; title=&quot;macOS&quot; height=&quot;35px&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/macos.svg&quot;/&gt;&lt;/a&gt;                            |                                                                                                                          &lt;a href=&quot;#download&quot;&gt;&lt;img alt=&quot;Linux (.deb)&quot; title=&quot;Linux (.deb)&quot; height=&quot;35px&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/linux_deb.svg&quot;/&gt;&lt;/a&gt;                                                                                                                           |                                                              &lt;a href=&quot;#download&quot;&gt;&lt;img alt=&quot;Linux (.rpm)&quot; title=&quot;Linux (.rpm)&quot; height=&quot;35px&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/linux_rpm.svg&quot;/&gt;&lt;/a&gt;                                                               |
|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|:------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[64&amp;#8209;bit](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_Windows_64-bit.msi)&amp;nbsp;\|&amp;nbsp;[32&amp;#8209;bit](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_Windows_32-bit.msi)&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; | [Intel](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_macOS_Intel.dmg)&amp;nbsp;\|&amp;nbsp;[Apple&amp;nbsp;silicon](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_macOS_AppleSilicon.dmg) | [amd64](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_amd64.deb)&amp;nbsp;\|&amp;nbsp;[arm64](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_arm64.deb)&amp;nbsp;\|&amp;nbsp;[i386](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_i386.deb)&amp;nbsp;\|&amp;nbsp;[armhf](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxDEB_armhf.deb) | &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;[x86_64](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxRPM_x86_64.rpm)&amp;nbsp;\|&amp;nbsp;[aarch64](https://github.com/GyulyVGC/sniffnet/releases/latest/download/Sniffnet_LinuxRPM_aarch64.rpm)&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; |

Links in the table above will download the latest version of Sniffnet directly from [GitHub releases](https://github.com/GyulyVGC/sniffnet/releases). &lt;br&gt;
Not what you&#039;re looking for? Check out [alternative installation methods](https://github.com/GyulyVGC/sniffnet/wiki/Alternative-installation-methods).

&gt; [!NOTE]
&gt;
&gt; Remember to also install the [required dependencies](https://github.com/GyulyVGC/sniffnet/wiki/Required-dependencies) for your operating system.

## Features

- 💻 choose a **network adapter** of your PC to inspect
- 🏷️ select a set of **filters** to apply to the observed traffic
- 📖 view overall **statistics** about your Internet traffic
- 📈 view **real-time charts** about traffic intensity
- 📌 keep an eye on your network even when the application is **minimized**
- 📁 **import** and **export** comprehensive capture reports as **PCAP files**
- 🔎 identify **6000+ upper layer services**, protocols, trojans, and worms
- 🌐 find out **domain name** and **ASN** of the hosts you are exchanging traffic with
- 🏠 identify connections in your **local network**
- 🌍 discover the **geographical location** of remote hosts
- ⭐ save your **favorite** network hosts
- 🕵️‍♂️ search and **inspect** each of your network connections in real time
- 🔉 set custom **notifications** to inform you when defined network events occur
- 🎨 choose the **style** that fits you the most, including custom themes support
- ...and more!

## User manual

Do you want to **learn more**? &lt;br&gt;
Check out the [**Sniffnet Wiki**](https://github.com/GyulyVGC/sniffnet/wiki), a comprehensive manual to help you
thoroughly master the application from a basic setup to the most advanced functionalities. &lt;br&gt;
The Wiki includes step-by-step guides, tips, examples of usage, and answers to frequent questions.

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/GyulyVGC/sniffnet/wiki&quot;&gt;
&lt;img alt=&quot;&quot; title=&quot;Sniffnet Wiki&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/logos/wiki/wikilogo.svg&quot; width=&quot;300px&quot;/&gt;
&lt;/a&gt;
&lt;/p&gt;

## Troubleshooting

&lt;details&gt;

  &lt;summary&gt;See details&lt;/summary&gt;

### Missing dependencies

Most of the errors that may arise are likely due to your system missing dependencies
required to correctly analyze a network adapter. &lt;br&gt;
Check the [required dependencies page](https://github.com/GyulyVGC/sniffnet/wiki/Required-dependencies) 
for instructions on how to proceed depending on your operating system.

### Rendering problems

In some circumstances, especially if you are running on an old architecture or your graphical drivers are not updated,
the `wgpu` default renderer used by [iced](https://github.com/iced-rs/iced)
may manifest bugs (the interface glitches, color gradients are unsupported, or some icons are completely black). &lt;br&gt;
In these cases you can set an environment variable to switch to the `tiny-skia` renderer,
a CPU-only software renderer that should work properly on every environment:

```sh
ICED_BACKEND=tiny-skia
```

### ***In any case, don&#039;t hesitate to [open an issue](https://github.com/GyulyVGC/sniffnet/issues/new/choose), and I will do my best to help you!***

&lt;/details&gt;


## Acknowledgements

- A big shout-out to [all the contributors](https://github.com/GyulyVGC/sniffnet/blob/main/CONTRIBUTORS.md) of Sniffnet!
- The graphical user interface has been realized with [iced](https://github.com/iced-rs/iced), a cross-platform GUI library for Rust focused on simplicity and type-safety
- IP geolocation and ASN data are provided by [MaxMind](https://www.maxmind.com)
- Last but not least, thanks to [every single stargazer](https://github.com/GyulyVGC/sniffnet/stargazers): all forms of support made it possible to keep improving Sniffnet!


## Stay in the loop

Wait... there&#039;s more!&lt;br&gt;Sniffnet is rapidly evolving, and new features are added on a regular basis.&lt;br&gt;
Follow the &lt;a href=&quot;https://sniffnet.net/news&quot;&gt;&lt;b&gt;news&lt;/b&gt;&lt;/a&gt; and Sniffnet socials to never miss an update.

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://bsky.app/profile/sniffnet.net&quot;&gt;&lt;img width=&quot;48&quot; height=&quot;48&quot; alt=&quot;Bluesky&quot; title=&quot;Bluesky&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/bluesky.svg&quot;/&gt;&lt;/a&gt;&amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/sniffnet&quot;&gt;&lt;img width=&quot;48&quot; height=&quot;48&quot; alt=&quot;LinkedIn&quot; title=&quot;LinkedIn&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/linkedin.svg&quot;/&gt;&lt;/a&gt;&amp;nbsp;
    &lt;a href=&quot;https://mastodon.social/@sniffnet&quot;&gt;&lt;img width=&quot;48&quot; height=&quot;48&quot; alt=&quot;Mastodon&quot; title=&quot;Mastodon&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/mastodon.svg&quot;/&gt;&lt;/a&gt;&amp;nbsp;
    &lt;a href=&quot;https://t.me/sniffnet&quot;&gt;&lt;img width=&quot;48&quot; height=&quot;48&quot; alt=&quot;Telegram&quot; title=&quot;Telegram&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/telegram.svg&quot;/&gt;&lt;/a&gt;&amp;nbsp;
    &lt;a href=&quot;https://x.com/sniffnet&quot;&gt;&lt;img width=&quot;48&quot; height=&quot;48&quot; alt=&quot;Twitter / X&quot; title=&quot;Twitter / X&quot; src=&quot;https://raw.githubusercontent.com/GyulyVGC/sniffnet/main/resources/repository/badges/x.svg&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[aws/amazon-q-developer-cli]]></title>
            <link>https://github.com/aws/amazon-q-developer-cli</link>
            <guid>https://github.com/aws/amazon-q-developer-cli</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:46 GMT</pubDate>
            <description><![CDATA[✨ Agentic chat experience in your terminal. Build applications using natural language.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aws/amazon-q-developer-cli">aws/amazon-q-developer-cli</a></h1>
            <p>✨ Agentic chat experience in your terminal. Build applications using natural language.</p>
            <p>Language: Rust</p>
            <p>Stars: 932</p>
            <p>Forks: 163</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html&quot;&gt;
    &lt;picture&gt;
      &lt;img src=&quot;./.github/media/amazon-q-logo.avif&quot; alt=&quot;Amazon Q&quot;
        width=&quot;200px&quot;
      &gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  Amazon Q CLI brings IDE-style autocomplete and agentic capabilities to your terminal.
&lt;/h4&gt;


&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/aws/amazon-q-developer-cli/graphs/commit-activity&quot;&gt;&lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/m/aws/amazon-q-developer-cli&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/aws/amazon-q-developer-cli/issues&quot;&gt;&lt;img alt=&quot;GitHub open issues&quot; src=&quot;https://img.shields.io/github/issues/aws/amazon-q-developer-cli&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;


&lt;div align=&quot;center&quot;&gt;

[![Rust Test](https://github.com/aws/amazon-q-developer-cli/actions/workflows/rust.yml/badge.svg)](https://github.com/aws/amazon-q-developer-cli/actions/workflows/rust.yml)
[![Typos Test](https://github.com/aws/amazon-q-developer-cli/actions/workflows/typos.yml/badge.svg)](https://github.com/aws/amazon-q-developer-cli/actions/workflows/typos.yml)
[![Typescript Test](https://github.com/aws/amazon-q-developer-cli/actions/workflows/typescript.yml/badge.svg)](https://github.com/aws/amazon-q-developer-cli/actions/workflows/typescript.yml)
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html&quot;&gt;
    &lt;picture&gt;
      &lt;img src=&quot;./.github/media/amazon-q-cli-features.jpeg&quot; alt=&quot;Amazon Q CLI Features&quot;
      &gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

## 😍 Features
-   🔮 [**Auto Completion**](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-autocomplete.html): IDE-style completions to hundreds of popular CLIs like `git`, `npm`, `docker`, and `aws`.
-   💬 [**Natural Language Chat**](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-chat.html): Interact with your terminal using natural language to ask questions, debug issues, or explore the codebase.
-   🧠 [**Contextual Awareness**](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-chat.html#command-line-chat-context-integration): Integrates context from your local development environment, so answers are tailored to your specific code and setup.
-   🤖 [**Agentic Execution**](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-autocomplete.html): Let Amazon Q take action: generate code, edit files, automate Git workflows, resolve merge conflicts, and more — with your permission.

## ⚡️ Installation

- **macOS**:
  - **DMG**: [Download now](https://desktop-release.q.us-east-1.amazonaws.com/latest/Amazon%20Q.dmg)
  - **Homebrew**: `brew install amazon-q`
- **Linux**:
  - [Ubuntu/Debian](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-ubuntu)
  - [AppImage](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-appimage)
  - [Alternative Linux builds](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-alternative-linux)
- **Windows**:
  - Follow the discussions for
    [Windows](https://github.com/aws/q-command-line-discussions/discussions/15)
  - Or [use it on Windows with WSL](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-windows)
- **Remote machines**
  - [Autocomplete in SSH](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-autocomplete-ssh.html)


## 🚀 Start Contributing

### Prerequisites

- MacOS
  - Xcode 13 or later
  - Brew

### 1. Clone repo

```shell
git clone https://github.com/aws/amazon-q-developer-cli-autocomplete.git
```

### 2. Setup
Hassle-free setup:
```shell
npm run setup
```

Or if you&#039;d like to DIY:

&lt;details&gt;
&lt;summary&gt;Manual Setup&lt;/summary&gt;
&lt;div&gt;

### 1. Install platform dependencies

For Debian/Ubuntu:

```shell
sudo apt update
sudo apt install build-essential pkg-config jq dpkg curl wget cmake clang libssl-dev libgtk-3-dev libayatana-appindicator3-dev librsvg2-dev libdbus-1-dev libwebkit2gtk-4.1-dev libjavascriptcoregtk-4.1-dev valac libibus-1.0-dev libglib2.0-dev sqlite3 libxdo-dev protobuf-compiler
```
### 2. Install Rust toolchain using [Rustup](https://rustup.rs):

```shell
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup default stable
```

For pre-commit hooks, the following commands are required:

```shell
rustup toolchain install nightly
cargo install typos-cli
```

For MacOS development make sure the right targets are installed:

```shell
rustup target add x86_64-apple-darwin
rustup target add aarch64-apple-darwin
```

### 3. Setup Python and Node using [`mise`](https://mise.jdx.dev)

Add mise integrations to your shell:

For zsh:
```shell
echo &#039;eval &quot;$(mise activate zsh)&quot;&#039; &gt;&gt; &quot;${ZDOTDIR-$HOME}/.zshrc&quot;
```

For bash:
```shell
echo &#039;eval &quot;$(mise activate bash)&quot;&#039; &gt;&gt; ~/.bashrc
```

For fish:
```shell
echo &#039;mise activate fish | source&#039; &gt;&gt; ~/.config/fish/config.fish
```

Install the Python and Node toolchains using:

```shell
mise trust
mise install
```

### 4. Setup precommit hooks

Run `pnpm` in root directory to add pre-commit hooks:

```shell
pnpm install --ignore-scripts
```

&lt;/div&gt;
&lt;/details&gt;


### 3. Start Local Development
To compile and view changes made to `q chat`:
```shell
cargo run --bin chat_cli
```

&gt; If you are working on other q commands, just append `-- &lt;command name&gt;`. For example, to run `q login`, you can run `cargo run --bin chat_cli -- login`

To run tests for the Q CLI crate:
```shell
cargo test -p chat_cli
```

To format Rust files:
```shell
cargo +nightly fmt
```

To run clippy:
```shell
cargo clippy --locked --workspace --color always -- -D warnings
```



### 💡 Quick Tip for Onboarding

Use Q CLI to help you onboard Q CLI! 

Start a `q chat` session:

```shell
q chat
```

Once inside `q chat`, you can supply project context by adding the [`codebase-summary.md`](codebase-summary.md) file:

```shell
/context add codebase-summary.md
```

This enables Q to answer onboarding questions like:

- “What does this crate do?”

- “Where is X implemented?”

- “How do these components interact?”

Great for speeding up your ramp-up and navigating the repo more effectively.




## 🏗️ Project Layout

Several projects live here:

- [`autocomplete`](packages/autocomplete/) - The autocomplete react app
- [`dashboard`](packages/dashboard-app/) - The dashboard react app
- [`figterm`](crates/figterm/) - figterm, our headless terminal/pseudoterminal that
  intercepts the user’s terminal edit buffer.
- [`q_cli`](crates/q_cli/) - the `q` CLI, allows users to interface with Amazon Q Developer from
  the command line
- [`fig_desktop`](crates/fig_desktop/) - the Rust desktop app, uses
  [`tao`](https://docs.rs/tao/latest/tao/)/[`wry`](https://docs.rs/wry/latest/wry/)
  for windowing/webviews
- [`fig_input_method`](crates/fig_input_method/) - The input method used to get cursor
  position on macOS
- [`vscode`](extensions/vscode/) - Contains the VSCode plugin needed
  for the Amazon Q Developer for command line to work in VSCode
- [`jetbrains`](extensions/jetbrains/) - Contains the VSCode plugin
  needed for the Amazon Q Developer for command line to work in Jetbrains IDEs

Other folder to be aware of

- [`build-scripts/`](build-scripts/) - Contains all python scripts to build,
  sign, and test the project on macOS and Linux
- [`crates/`](crates/) - Contains all internal rust crates
- [`packages/`](packages/) - Contains all internal npm packages
- [`proto/`](proto/) -
  [protocol buffer](https://developers.google.com/protocol-buffers/) message
  specification for inter-process communication
- [`tests/`](tests/) - Contain integration tests for the projects

Below is a high level architecture of how the different components of the app and
their IPC:

![architecture](docs/assets/architecture.svg)




## 🛡️ Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## 📜 Licensing

This repo is dual licensed under MIT and Apache 2.0 licenses.

“Amazon Web Services” and all related marks, including logos, graphic designs, and service names, are trademarks or trade dress of AWS in the U.S. and other countries. AWS’s trademarks and trade dress may not be used in connection with any product or service that is not AWS’s, in any manner that is likely to cause confusion among customers, or in any manner that disparages or discredits AWS.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[openobserve/openobserve]]></title>
            <link>https://github.com/openobserve/openobserve</link>
            <guid>https://github.com/openobserve/openobserve</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:45 GMT</pubDate>
            <description><![CDATA[🚀 10x easier, 🚀 140x lower storage cost, 🚀 high performance, 🚀 petabyte scale - Elasticsearch/Splunk/Datadog alternative for 🚀 (logs, metrics, traces, RUM, Error tracking, Session replay).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openobserve/openobserve">openobserve/openobserve</a></h1>
            <p>🚀 10x easier, 🚀 140x lower storage cost, 🚀 high performance, 🚀 petabyte scale - Elasticsearch/Splunk/Datadog alternative for 🚀 (logs, metrics, traces, RUM, Error tracking, Session replay).</p>
            <p>Language: Rust</p>
            <p>Stars: 15,698</p>
            <p>Forks: 595</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://openobserve.ai&quot;&gt;&lt;img src=&quot;https://openobserve.ai/img/logo/logo_horizontal.svg&quot; alt=&quot;OpenObserve&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;em&gt;🚀 10x easier, 🚀 140x lower storage cost, 🚀 high performance, 🚀 petabyte scale - Elasticsearch/Splunk/Datadog alternative for 🚀 (logs, metrics, traces).&lt;/em&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/openobserve/openobserve&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/last-commit/openobserve/openobserve&quot; alt=&quot;Last Commit&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/openobserve/openobserve/stargazers&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/openobserve/openobserve&quot; alt=&quot;GitHub Stars&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/openobserve/openobserve/issues&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/issues/openobserve/openobserve&quot; alt=&quot;GitHub Issues&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/openobserve/openobserve/graphs/contributors&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/contributors/openobserve/openobserve&quot; alt=&quot;Contributors&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/openobserve/openobserve/releases&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/openobserve/openobserve&quot; alt=&quot;GitHub Release&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;

OpenObserve (O2 for short) is a cloud-native observability platform built specifically for logs, metrics, traces, analytics, RUM (Real User Monitoring - Performance, Errors, Session Replay) designed to work at petabyte scale.

It is straightforward and easy to operate, in contrast to Elasticsearch, which requires understanding and tuning numerous settings. Get OpenObserve up and running in under 2 minutes.

OpenObserve serves as a seamless replacement for Elasticsearch for users who ingest data using APIs and perform searches. OpenObserve comes with its own user interface, eliminating the need for separate installation.

You can reduce your log storage costs by ~140x compared to Elasticsearch by using OpenObserve. Below, we present the results from pushing logs from our production Kubernetes cluster to both Elasticsearch and OpenObserve using Fluent Bit.

![OpenObserve Vs Elasticsearch](./screenshots/zo_vs_es.png)

## 🎥 Introduction Video

[![OpenObserve Introduction](./screenshots/o2_intro.webp)](https://www.youtube.com/watch?v=4VwuC1tpRP4)

## 🌟 Features:

- **Logs, Metrics, Traces**: Comprehensive support for various data types.
- **OpenTelemetry Support**: Full compatibility with OTLP for logs, metrics, and traces.
- **Real User Monitoring (RUM)**: Includes performance tracking, error logging, and session replay.
- **Dashboards, Reports, Alerts**: Features over 18 different chart types for comprehensive data visualization for on-the-fly analysis and reporting along with alerting.
- **Pipelines**: Enrich, redact, reduce, normalize data on the fly. Stream processing for logs to metrics and more.
- **Advanced Embedded GUI**: Intuitive and user-friendly interface.
- **SQL and PromQL Support**: Query logs and traces with SQL, and metrics with SQL and PromQL.
- **Single Binary or HA Installation**: Install using a single binary for small deployments or in HA mode for large deployments.
- **Versatile Storage Options**: Supports local disk, S3, MinIO, GCS, Azure Blob Storage.
- **High Availability and Clustering**: Ensures reliable and scalable performance.
- **Dynamic Schema**: Adapts to your data structure seamlessly.
- **Built-in Authentication**: Secure and ready to use.
- **Ease of Operation**: Designed for simplicity and efficiency.
- **Seamless Upgrades**: Hassle-free updates.
- **Multilingual UI**: Supports 11 languages, including English, Spanish, German, French, Chinese, and more.

For a full list of features, check the [documentation](https://openobserve.ai/docs/#project-status-features-and-roadmap).

## ⚡️ Quick start

### 🐳 Docker:
```bash
docker run -d \
      --name openobserve \
      -v $PWD/data:/data \
      -p 5080:5080 \
      -e ZO_ROOT_USER_EMAIL=&quot;root@example.com&quot; \
      -e ZO_ROOT_USER_PASSWORD=&quot;Complexpass#123&quot; \
      public.ecr.aws/zinclabs/openobserve:latest
```

### 🐙 Docker Compose:
```yaml
services:
  openobserve:
    image: public.ecr.aws/zinclabs/openobserve:latest
    restart: unless-stopped
    environment:
      ZO_ROOT_USER_EMAIL: &quot;root@example.com&quot;
      ZO_ROOT_USER_PASSWORD: &quot;Complexpass#123&quot;
    ports:
      - &quot;5080:5080&quot;
    volumes:
      - data:/data
volumes:
  data:
```

For other ways to quickly install OpenObserve or use OpenObserve cloud, check [quickstart documentation](https://openobserve.ai/docs/quickstart).

For installing OpenObserve in HA mode, check [HA deployment documentation](https://openobserve.ai/docs/ha_deployment/).

&lt;!-- ## Enterprise Vs Open source Vs Cloud edition

OpenObserve is available in three different editions:


| Feature | Open Source (Self hosted) | Enterprise (Self hosted) | Cloud |
| --- | --- | --- | --- | 
| Logs | ✅ | ✅ | ✅ |
| Metrics | ✅ | ✅ | ✅ |
| Traces | ✅ | ✅ | ✅ |
| RUM | ✅ | ✅ | ✅ |
| Alerts | ✅ | ✅ | ✅ |
| Dashboards | ✅ | ✅ | ✅ |
| Reports | ✅ | ✅ | ✅ |
| VRL functions | ✅ | ✅ | ✅ |
| Pipelines | ✅ | ✅ | ✅ |
| High Availability | ✅ | ✅ | ✅ |
| Multitenancy (Organizations) | ✅ | ✅ | ✅ |
| Dynamic schema and schema evolution | ✅ | ✅ | ✅ |
| Advanced multilingual GUI | ✅ | ✅ | ✅ |
| Single Sign On | ❌ | ✅ | ✅ |
| Role Based Access Control (RBAC) | ❌ | ✅ | ✅ |
| Federated search / Super cluster | ❌ | ✅ | ❌ |
| Query management | ❌ | ✅ | ❌ |
| Workload management (QoS) | ❌ | ✅ | ❌ |
| Audit trail | ❌ | ✅ | ❌ |
| Ability to influence roadmap | ❌ | ✅ | ✅ on enterprise plan |
| License | AGPL | Enterprise | Cloud |
| Support | Community | Enterprise | Cloud |
| Cost | Free | If self hosted, free for up to 200 GB/Day data ingested &lt;br&gt; Paid thereafter  | Free 200 GB/Month data ingested &lt;br&gt; Paid thereafter | --&gt;


## 📷 Screenshots

### Home

![Home](./screenshots/zo_home.png)

### Logs

![Logs](./screenshots/logs.png)

### Traces (OpenTelemetry)

Trace details page
![Traces using OpenTelemetry](./screenshots/traces.png)

Golden metrics based on traces
![Traces golden metrics](./screenshots/traces-overall.png)

### Visualizations and Dashboards

![Dashboard](./screenshots/dashboard.png)
![Dashboard](./screenshots/dashboard2.png)
![Create panel](./screenshots/create-panel.png)
![Map](./screenshots/map.png)

### Front end monitoring

Performance analytics
![Performance](./screenshots/performance.png)

Session replay
![Session replay](./screenshots/session-replay.png)

Error tracking
![Error tracking](./screenshots/error-tracking.png)


### Alerts

![Alerts](./screenshots/alerts.png)


### Streams

![Streams](./screenshots/streams.png)

### Ingestion

![Ingestion](./screenshots/ingestion1.png)

### Pipeline

Pipeline
![Pipeline](./screenshots/pipeline.png)

Function
![Function](./screenshots/function.png)


### IAM

SSO (Single Sign On)
![SSO](./screenshots/sso.png)

RBAC (Role Based Access Control)
![RBAC](./screenshots/iam_rbac.png)


### SBOM

Software Bill of Materials for OpenObserve

#### Rust

SBOM can be found [here](./openobserve.cdx.xml). You can analyze it using [dependency track](https://dependencytrack.org/).

In order to generate the SBOM, you can use the following commands:

Install cargo-cyclonedx:

````bash
cargo install cargo-cyclonedx
````

Generate the SBOM:
```bash
cargo-cyclonedx cyclonedx
```

#### JavaScript

SBOM can be found [here](./web/sbom.json ). You can analyze it using [dependency track](https://dependencytrack.org/).

In order to generate the SBOM, you can use the following commands:

Install cyclonedx-npm:

````bash
npm install --global @cyclonedx/cyclonedx-npm
````

Generate the SBOM:
```bash
cd web
cyclonedx-npm &gt; sbom.json         
```


## ⚖️ License

OpenObserve is licensed under the AGPL-3.0 license. For more details, see the [LICENSE](https://github.com/openobserve/openobserve/blob/main/LICENSE).

## 🌍 Community

### 🔗 Join OpenObserve community on Slack

[![Slack](./screenshots/slack.png)](https://short.openobserve.ai/community)

Easiest way to get support is to join the [Slack channel](https://short.openobserve.ai/community).

### 📱 Join OpenObserve community on WeChat

&lt;img src=&quot;./screenshots/wechat_qr.jpg&quot; width=&quot;300&quot;&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vectordotdev/vector]]></title>
            <link>https://github.com/vectordotdev/vector</link>
            <guid>https://github.com/vectordotdev/vector</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:44 GMT</pubDate>
            <description><![CDATA[A high-performance observability data pipeline.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vectordotdev/vector">vectordotdev/vector</a></h1>
            <p>A high-performance observability data pipeline.</p>
            <p>Language: Rust</p>
            <p>Stars: 19,845</p>
            <p>Forks: 1,781</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://vector.dev/docs/setup/quickstart/&quot;&gt;Quickstart&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/docs/&quot;&gt;Docs&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/guides/&quot;&gt;Guides&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/components/&quot;&gt;Integrations&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://chat.vector.dev&quot;&gt;Chat&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/releases/latest/download/&quot;&gt;Download&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://rust-doc.vector.dev/&quot;&gt;Rust Crate Docs&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;website/static/img/diagram.svg&quot; alt=&quot;Vector&quot;&gt;
&lt;/p&gt;

## What is Vector?

Vector is a high-performance, end-to-end (agent &amp; aggregator) observability data
pipeline that puts you in control of your observability data.
[Collect][docs.sources], [transform][docs.transforms], and [route][docs.sinks]
all your logs and metrics to any vendors you want today and any other
vendors you may want tomorrow. Vector enables dramatic cost reduction, novel
data enrichment, and data security where you need it, not where it is most
convenient for your vendors. Additionally, it is open source and up to 10x
faster than every alternative in the space.

To get started, follow our [**quickstart guide**][docs.quickstart] or [**install
Vector**][docs.installation].

Vector is maintained by the Datadog&#039;s [Community Open Source Engineering team](https://opensource.datadoghq.com/about/#the-community-open-source-engineering-team).

### Principles

* **Reliable** - Built in [Rust][urls.rust], Vector&#039;s primary design goal is reliability.
* **End-to-end** - Deploys as an [agent][docs.roles#agent] or [aggregator][docs.roles#aggregator]. Vector is a complete platform.
* **Unified** - [Logs][docs.data-model.log], [metrics][docs.data-model.metric] (beta), and traces (coming soon). One tool for all of your data.

### Use cases

* Reduce total observability costs.
* Transition vendors without disrupting workflows.
* Enhance data quality and improve insights.
* Consolidate agents and eliminate agent fatigue.
* Improve overall observability performance and reliability.

### Community

* Vector is relied on by startups and enterprises like **Atlassian**, **T-Mobile**,
  **Comcast**, **Zendesk**, **Discord**, **Fastly**, **CVS**, **Trivago**,
  **Tuple**, **Douban**, **Visa**, **Mambu**, **Blockfi**, **Claranet**,
  **Instacart**, **Forcepoint**, and [many more][urls.production_users].
* Vector is **downloaded over 100,000 times per day**.
* Vector&#039;s largest user **processes over 500TB daily**.
* Vector has **over 500 contributors** and growing.

## Documentation

All user documentation is available at **[vector.dev/docs](https://vector.dev/docs)**.

Other Resources:

* [**Vector Calendar**][urls.vector_calendar]
* **Policies**:
  * [**Code of Conduct**][urls.vector_code_of_conduct]
  * [**Contributing**][urls.vector_contributing_policy]
  * [**Privacy**][urls.vector_privacy_policy]
  * [**Releases**][urls.vector_releases_policy]
  * [**Versioning**][urls.vector_versioning_policy]
  * [**Security**][urls.vector_security_policy]

## Comparisons

### Performance

The following performance tests demonstrate baseline performance between
common protocols with the exception of the Regex Parsing test.

| Test                                                                                                                   | Vector          | Filebeat | FluentBit       | FluentD   | Logstash  | SplunkUF        | SplunkHF |
| ---------------------------------------------------------------------------------------------------------------------- | --------------- | -------- | --------------- | --------- | --------- | --------------- | -------- |
| [TCP to Blackhole](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance) | _**86mib/s**_   | n/a      | 64.4mib/s       | 27.7mib/s | 40.6mib/s | n/a             | n/a      |
| [File to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance)           | _**76.7mib/s**_ | 7.8mib/s | 35mib/s         | 26.1mib/s | 3.1mib/s  | 40.1mib/s       | 39mib/s  |
| [Regex Parsing](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance)       | 13.2mib/s       | n/a      | _**20.5mib/s**_ | 2.6mib/s  | 4.6mib/s  | n/a             | 7.8mib/s |
| [TCP to HTTP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance)           | _**26.7mib/s**_ | n/a      | 19.6mib/s       | &lt;1mib/s   | 2.7mib/s  | n/a             | n/a      |
| [TCP to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance)             | 69.9mib/s       | 5mib/s   | 67.1mib/s       | 3.9mib/s  | 10mib/s   | _**70.4mib/s**_ | 7.6mib/s |

To learn more about our performance tests, please see the [Vector test harness][urls.vector_test_harness].

### Correctness

The following correctness tests are not exhaustive, but they demonstrate
fundamental differences in quality and attention to detail:

| Test                                                                                                                                 | Vector | Filebeat | FluentBit | FluentD | Logstash | Splunk UF | Splunk HF |
| ------------------------------------------------------------------------------------------------------------------------------------ | ------ | -------- | --------- | ------- | -------- | --------- | --------- |
| [Disk Buffer Persistence](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness) | **✓**  | ✓        |           |         | ⚠        | ✓         | ✓         |
| [File Rotate (create)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness)         | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |
| [File Rotate (copytruncate)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness) | **✓**  |          |           |         |          | ✓         | ✓         |
| [File Truncation](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness)                   | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |
| [Process (SIGHUP)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness)                         | **✓**  |          |           |         | ⚠        | ✓         | ✓         |
| [JSON (wrapped)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness)                     | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |

To learn more about our correctness tests, please see the [Vector test harness][urls.vector_test_harness].

### Features

Vector is an end-to-end, unified, open data platform.

|                     | **Vector** | Beats | Fluentbit | Fluentd | Logstash | Splunk UF | Splunk HF | Telegraf |
| ------------------- | ---------- | ----- | --------- | ------- | -------- | --------- | --------- | -------- |
| **End-to-end**      | **✓**      |       |           |         |          |           |           | ✓        |
| Agent               | **✓**      | ✓     | ✓         |         |          | ✓         |           | ✓        |
| Aggregator          | **✓**      |       |           | ✓       | ✓        |           | ✓         | ✓        |
| **Unified**         | **✓**      |       |           |         |          |           |           | ✓        |
| Logs                | **✓**      | ✓     | ✓         | ✓       | ✓        | ✓         | ✓         | ✓        |
| Metrics             | **✓**      | ⚠     | ⚠         | ⚠       | ⚠        | ⚠         | ⚠         | ✓        |
| Traces              | 🚧         |       |           |         |          |           |           |          |
| **Open**            | **✓**      |       | ✓         | ✓       |          |           |           | ✓        |
| Open-source         | **✓**      | ✓     | ✓         | ✓       | ✓        |           |           | ✓        |
| Vendor-neutral      | **✓**      |       | ✓         | ✓       |          |           |           | ✓        |
| **Reliability**     | **✓**      |       |           |         |          |           |           |          |
| Memory-safe         | **✓**      |       |           |         |          |           |           | ✓        |
| Delivery guarantees | **✓**      |       |           |         |          | ✓         | ✓         |          |
| Multi-core          | **✓**      | ✓     | ✓         | ✓       | ✓        | ✓         | ✓         | ✓        |


⚠ = Not interoperable, metrics are represented as structured logs

---

&lt;p align=&quot;center&quot;&gt;
  Developed with ❤️ by &lt;strong&gt;&lt;a href=&quot;https://datadoghq.com&quot;&gt;Datadog&lt;/a&gt;&lt;/strong&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/security/policy&quot;&gt;Security Policy&lt;/a&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/blob/master/PRIVACY.md&quot;&gt;Privacy Policy&lt;/a&gt;
&lt;/p&gt;

[docs.about.concepts]: https://vector.dev/docs/introduction/concepts/
[docs.about.introduction]: https://vector.dev/docs/introduction/
[docs.administration.monitoring]: https://vector.dev/docs/administration/monitoring/
[docs.administration.management]: https://vector.dev/docs/administration/management/
[docs.administration.upgrading]: https://vector.dev/docs/administration/upgrading/
[docs.administration.validating]: https://vector.dev/docs/administration/validating/
[docs.architecture.concurrency-model]: https://vector.dev/docs/architecture/concurrency-model/
[docs.architecture.data-model]: https://vector.dev/docs/architecture/data-model/
[docs.architecture.pipeline-model]: https://vector.dev/docs/architecture/pipeline-model/
[docs.architecture.runtime-model]: https://vector.dev/docs/architecture/runtime-model/
[docs.configuration.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.configuration.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.configuration.tests]: https://vector.dev/docs/reference/configuration/tests/
[docs.configuration.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.configuration.enrichment_tables]: https://vector.dev/docs/reference/configuration/global-options/#enrichment_tables
[docs.data-model.log]: https://vector.dev/docs/architecture/data-model/log/
[docs.data-model.metric]: https://vector.dev/docs/architecture/data-model/metric/
[docs.deployment.roles]: https://vector.dev/docs/setup/deployment/roles/
[docs.deployment.topologies]: https://vector.dev/docs/setup/deployment/topologies/
[docs.deployment]: https://vector.dev/docs/setup/deployment/
[docs.installation.manual]: https://vector.dev/docs/setup/installation/manual/
[docs.installation.operating_systems]: https://vector.dev/docs/setup/installation/operating-systems/
[docs.installation.package_managers]: https://vector.dev/docs/setup/installation/package-managers/
[docs.installation.platforms]: https://vector.dev/docs/setup/installation/platforms/
[docs.installation]: https://vector.dev/docs/setup/installation/
[docs.architecture.adaptive-request-concurrency]: https://vector.dev/docs/architecture/arc/
[docs.platforms.kubernetes]: https://vector.dev/docs/setup/installation/platforms/kubernetes/
[docs.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.reference.api]: https://vector.dev/docs/reference/api/
[docs.reference.cli]: https://vector.dev/docs/reference/cli/
[docs.reference.vrl]: https://vector.dev/docs/reference/vrl/
[docs.roles#agent]: https://vector.dev/docs/setup/deployment/roles/#agent
[docs.roles#aggregator]: https://vector.dev/docs/setup/deployment/roles/#aggregator
[docs.setup.installation]: https://vector.dev/docs/setup/installation/
[docs.setup.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.sinks.aws_cloudwatch_logs]: https://vector.dev/docs/reference/configuration/sinks/aws_cloudwatch_logs/
[docs.sinks.aws_s3]: https://vector.dev/docs/reference/configuration/sinks/aws_s3/
[docs.sinks.clickhouse]: https://vector.dev/docs/reference/configuration/sinks/clickhouse/
[docs.sinks.elasticsearch]: https://vector.dev/docs/reference/configuration/sinks/elasticsearch/
[docs.sinks.gcp_cloud_storage]: https://vector.dev/docs/reference/configuration/sinks/gcp_cloud_storage/
[docs.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.sources.docker_logs]: https://vector.dev/docs/reference/configuration/sources/docker_logs/
[docs.sources.file]: https://vector.dev/docs/reference/configuration/sources/file/
[docs.sources.http]: https://vector.dev/docs/reference/configuration/sources/http/
[docs.sources.journald]: https://vector.dev/docs/reference/configuration/sources/journald/
[docs.sources.kafka]: https://vector.dev/docs/reference/configuration/sources/kafka/
[docs.sources.socket]: https://vector.dev/docs/reference/configuration/sources/socket/
[docs.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.transforms.dedupe]: https://vector.dev/docs/reference/configuration/transforms/dedupe/
[docs.transforms.filter]: https://vector.dev/docs/reference/configuration/transforms/filter/
[docs.transforms.log_to_metric]: https://vector.dev/docs/reference/configuration/transforms/log_to_metric/
[docs.transforms.lua]: https://vector.dev/docs/reference/configuration/transforms/lua/
[docs.transforms.remap]: https://vector.dev/docs/reference/configuration/transforms/remap/
[docs.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.introduction.architecture]: https://vector.dev/docs/architecture/
[docs.introduction.guarantees]: https://vector.dev/docs/introduction/guarantees/
[docs.introduction.architecture]: https://vector.dev/docs/architecture/
[urls.production_users]: https://github.com/vectordotdev/vector/issues/790
[urls.rust]: https://www.rust-lang.org/
[urls.vector_calendar]: https://calendar.vector.dev
[urls.vector_chat]: https://chat.vector.dev
[urls.vector_code_of_conduct]: https://github.com/vectordotdev/vector/blob/master/CODE_OF_CONDUCT.md
[urls.vector_contributing_policy]: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md
[urls.vector_community]: https://vector.dev/community/
[urls.vector_privacy_policy]: https://github.com/vectordotdev/vector/blob/master/PRIVACY.md
[urls.vector_release_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASING.md
[urls.vector_releases]: https://vector.dev/releases/
[urls.vector_releases_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASES.md
[urls.vector_security_policy]: https://github.com/vectordotdev/vector/security/policy
[urls.vector_test_harness]: https://github.com/vectordotdev/vector-test-harness/
[urls.vector_twitter]: https://twitter.com/vectordotdev
[urls.vector_versioning_policy]: https://github.com/vectordotdev/vector/blob/master/VERSIONING.md
[urls.vote_feature]: https://github.com/vectordotdev/vector/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22type%3A+feature%22
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cocoindex-io/cocoindex]]></title>
            <link>https://github.com/cocoindex-io/cocoindex</link>
            <guid>https://github.com/cocoindex-io/cocoindex</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:43 GMT</pubDate>
            <description><![CDATA[Data transformation framework for AI. Ultra performant, with incremental processing.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cocoindex-io/cocoindex">cocoindex-io/cocoindex</a></h1>
            <p>Data transformation framework for AI. Ultra performant, with incremental processing.</p>
            <p>Language: Rust</p>
            <p>Stars: 2,050</p>
            <p>Forks: 139</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/github.svg&quot; alt=&quot;CocoIndex&quot;&gt;
&lt;/p&gt;

&lt;h2 align=&quot;center&quot;&gt;Extract, Transform, Index Data. Easy and Fresh. 🌴&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;

[![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex)
[![Documentation](https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;logoColor=00B9FF)](https://cocoindex.io/docs/getting_started/quickstart)
[![License](https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white)](https://opensource.org/licenses/Apache-2.0)
[![PyPI version](https://img.shields.io/pypi/v/cocoindex?color=5B5BD6)](https://pypi.org/project/cocoindex/)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex)

[![CI](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml)
[![release](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml)
[![Discord](https://img.shields.io/discord/1314801574169673738?logo=discord&amp;color=5B5BD6&amp;logoColor=white)](https://discord.com/invite/zpA9S2DR7s)
&lt;/div&gt;

**CocoIndex** is an ultra performant data transformation framework, with its core engine written in Rust. The problem it tries to solve is to make it easy to prepare fresh data for AI - either creating embedding, building knowledge graphs, or performing other data transformations - and take real-time data pipelines beyond traditional SQL.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/cocoindex-features.png&quot; alt=&quot;CocoIndex Features&quot; width=&quot;500&quot;&gt;
&lt;/p&gt;

The philosophy is to have the framework handle the source updates, and having developers only worry about defining a series of data transformation, inspired by spreadsheet.

## Dataflow programming
Unlike a workflow orchestration framework where data is usually opaque, in CocoIndex, data and data operations are first class citizens. CocoIndex follows the idea of [Dataflow](https://en.wikipedia.org/wiki/Dataflow_programming) programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.

**Particularly**, users don&#039;t explicitly mutate data by creating, updating and deleting. Rather, they define something like - for a set of source data, this is the transformation or formula. The framework takes care of the data operations such as when to create, update, or delete.

```python
# import
data[&#039;content&#039;] = flow_builder.add_source(...)

# transform
data[&#039;out&#039;] = data[&#039;content&#039;]
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
```

## Data Freshness
As a data framework, CocoIndex takes it to the next level on data freshness. **Incremental processing** is one of the core values provided by CocoIndex.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6&quot; alt=&quot;Incremental Processing&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

The frameworks takes care of
- Change data capture.
- Figure out what exactly needs to be updated, and only updating that without having to recompute everything.

This makes it fast to reflect any source updates to the target store. If you have concerns with surfacing stale data to AI agents and are spending lots of efforts working on infra piece to optimize the latency, the framework actually handles it for you.


## Quick Start:
If you&#039;re new to CocoIndex, we recommend checking out
- 📖 [Documentation](https://cocoindex.io/docs)
- ⚡  [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart)
- 🎬 [Quick Start Video Tutorial](https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT)

### Setup

1. Install CocoIndex Python library

```bash
pip install -U cocoindex
```

2. [Install Postgres](https://cocoindex.io/docs/getting_started/installation#-install-postgres) if you don&#039;t have one. CocoIndex uses it for incremental processing.


### Define data flow

Follow [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart) to define your first indexing flow. An example flow looks like:

```python
@cocoindex.flow_def(name=&quot;TextEmbedding&quot;)
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope[&quot;documents&quot;] = flow_builder.add_source(cocoindex.sources.LocalFile(path=&quot;markdown_files&quot;))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope[&quot;documents&quot;].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc[&quot;chunks&quot;] = doc[&quot;content&quot;].transform(
            cocoindex.functions.SplitRecursively(),
            language=&quot;markdown&quot;, chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc[&quot;chunks&quot;].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk[&quot;embedding&quot;] = chunk[&quot;text&quot;].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model=&quot;sentence-transformers/all-MiniLM-L6-v2&quot;))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc[&quot;filename&quot;], location=chunk[&quot;location&quot;],
                                   text=chunk[&quot;text&quot;], embedding=chunk[&quot;embedding&quot;])

    # Export collected data to a vector index.
    doc_embeddings.export(
        &quot;doc_embeddings&quot;,
        cocoindex.targets.Postgres(),
        primary_key_fields=[&quot;filename&quot;, &quot;location&quot;],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name=&quot;embedding&quot;,
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
```

It defines an index flow like this:

&lt;img width=&quot;363&quot; alt=&quot;Data Flow&quot; src=&quot;https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463&quot; /&gt;


## 🚀 Examples and demo

| Example | Description |
|---------|-------------|
| [Text Embedding](examples/text_embedding) | Index text documents with embeddings for semantic search |
| [Code Embedding](examples/code_embedding) | Index code embeddings for semantic search |
| [PDF Embedding](examples/pdf_embedding) | Parse PDF and index text embeddings for semantic search |
| [Manuals LLM Extraction](examples/manuals_llm_extraction) | Extract structured information from a manual using LLM |
| [Amazon S3 Embedding](examples/amazon_s3_embedding) | Index text documents from Amazon S3 |
| [Google Drive Text Embedding](examples/gdrive_text_embedding) | Index text documents from Google Drive |
| [Docs to Knowledge Graph](examples/docs_to_knowledge_graph) | Extract relationships from Markdown documents and build a knowledge graph |
| [Embeddings to Qdrant](examples/text_embedding_qdrant) | Index documents in a Qdrant collection for semantic search |
| [FastAPI Server with Docker](examples/fastapi_server_docker) | Run the semantic search server in a Dockerized FastAPI setup |
| [Product Recommendation](examples/product_recommendation) | Build real-time product recommendations with LLM and graph database|
| [Image Search with Vision API](examples/image_search) | Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend|

More coming and stay tuned 👀!

## 📖 Documentation
For detailed documentation, visit [CocoIndex Documentation](https://cocoindex.io/docs), including a [Quickstart guide](https://cocoindex.io/docs/getting_started/quickstart).

## 🤝 Contributing
We love contributions from our community ❤️. For details on contributing or running the project for development, check out our [contributing guide](https://cocoindex.io/docs/about/contributing).

## 👥 Community
Welcome with a huge coconut hug 🥥⋆｡˚🤗. We are super excited for community contributions of all kinds - whether it&#039;s code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.

Join our community here:

- 🌟 [Star us on GitHub](https://github.com/cocoindex-io/cocoindex)
- 👋 [Join our Discord community](https://discord.com/invite/zpA9S2DR7s)
- ▶️ [Subscribe to our YouTube channel](https://www.youtube.com/@cocoindex-io)
- 📜 [Read our blog posts](https://cocoindex.io/blogs/)

## Support us:
We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ⭐ at GitHub repo [![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex) to stay tuned and help us grow.

## License
CocoIndex is Apache 2.0 licensed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[influxdata/influxdb]]></title>
            <link>https://github.com/influxdata/influxdb</link>
            <guid>https://github.com/influxdata/influxdb</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:42 GMT</pubDate>
            <description><![CDATA[Scalable datastore for metrics, events, and real-time analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/influxdb">influxdata/influxdb</a></h1>
            <p>Scalable datastore for metrics, events, and real-time analytics</p>
            <p>Language: Rust</p>
            <p>Stars: 30,255</p>
            <p>Forks: 3,620</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
 &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/influxdb-logo.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/influxdb-logo-dark.png&quot;&gt;
    &lt;img src=&quot;assets/influxdb-logo.png&quot; alt=&quot;InfluxDB Logo&quot; width=&quot;600&quot;&gt;
  &lt;/picture&gt;
 &lt;p&gt;
&lt;/div&gt;

InfluxDB Core is a database built to collect, process, transform, and store event and time series data. It is ideal for use cases that require real-time ingest and fast query response times to build user interfaces, monitoring, and automation solutions.

Common use cases include:

- Monitoring sensor data
- Server monitoring
- Application performance monitoring
- Network monitoring
- Financial market and trading analytics
- Behavioral analytics

InfluxDB is optimized for scenarios where near real-time data monitoring is essential and queries 
need to return quickly to support user experiences such as dashboards and interactive user interfaces.

InfluxDB 3 Core’s feature highlights include:

- Diskless architecture with object storage support (or local disk with no dependencies)
- Fast query response times (under 10ms for last-value queries, or 30ms for distinct metadata)
- Embedded Python VM for plugins and triggers
- Parquet file persistence
- Compatibility with InfluxDB 1.x and 2.x write APIs
- Compatability with InfluxDB 1.x query API (InfluxQL)
- SQL query engine with support for FlightSQL and HTTP query API

## Project Status

InfluxDB 3 Core is GA as of April 15, 2025! We plan to have monthly point releases for the following six months, with patch releases as needed. We will move to a quarterly cadence after that for 3-4 releases, after which we&#039;ll reevaluate our release schedule.

Join the [InfluxDB3 Discord](https://discord.gg/vZe2w2Ds8B) 
or the public channels below to share your feedback, feature requests, and bug reports.

See the [InfluxDB 3 Core &amp; Enterprise GA release announcement here](https://www.influxdata.com/blog/influxdb-3-oss-ga/) 
or dig into the [InfluxDB 3 getting started guide here](https://docs.influxdata.com/influxdb3/core/get-started/).

## Learn InfluxDB
[Documentation](https://docs.influxdata.com/) | [Community Forum](https://community.influxdata.com/) | [Community Slack](https://www.influxdata.com/slack/) | [Blog](https://www.influxdata.com/blog/) | [InfluxDB University](https://university.influxdata.com/) | [YouTube](https://www.youtube.com/@influxdata8893)

Try **InfluxDB Cloud** for free and get started fast with no local setup required. Click [here](https://cloud2.influxdata.com/signup) to start building your application on InfluxDB Cloud.


## Installation
We have nightly and versioned Docker images, Debian packages, RPM packages, and tarballs of InfluxDB available on the [InfluxData downloads page](https://portal.influxdata.com/downloads/). We also provide the InfluxDB command line interface (CLI) client as a separate binary available at the same location.

- For v1 installation, use the [main 1.x branch](https://github.com/influxdata/influxdb/tree/master-1.x) or [install InfluxDB OSS directly](https://docs.influxdata.com/influxdb/v1/introduction/install/#installing-influxdb-oss).
- For v2 installation, use the [main 2.x branch](https://github.com/influxdata/influxdb/tree/main-2.x).
- For InfluxDB 3 Core see the [InfluxDB 3 Core getting started guide](https://docs.influxdata.com/influxdb3/core/get-started/).
- For InfluxDB 3 Enterprise see the [InfluxDB 3 Enterprise getting started guide](https://docs.influxdata.com/influxdb3/enterprise/get-started/).

If you are interested in building from source, see the [building from source](CONTRIBUTING.md#building-from-source) guide for contributors.

To begin using InfluxDB, visit our [Getting Started with InfluxDB](https://docs.influxdata.com/influxdb/v1/introduction/get-started/) documentation.


## License
The open source software we build is licensed under the permissive MIT or Apache 2 licenses at the user&#039;s choosing. We’ve long held the view that our open source code should be truly open and our commercial code should be separate and closed. 


## Interested in joining the team building InfluxDB?
Check out current job openings at [www.influxdata.com/careers](https://www.influxdata.com/careers) today!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rolldown/rolldown]]></title>
            <link>https://github.com/rolldown/rolldown</link>
            <guid>https://github.com/rolldown/rolldown</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:41 GMT</pubDate>
            <description><![CDATA[Fast Rust bundler for JavaScript/TypeScript with Rollup-compatible API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rolldown/rolldown">rolldown/rolldown</a></h1>
            <p>Fast Rust bundler for JavaScript/TypeScript with Rollup-compatible API.</p>
            <p>Language: Rust</p>
            <p>Stars: 11,524</p>
            <p>Forks: 617</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://rolldown.rs&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
    &lt;img width=&quot;180&quot; src=&quot;https://rolldown.rs/rolldown-round.svg&quot; alt=&quot;Rolldown logo&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![MIT licensed][badge-license]][url-license]
[![NPM version][badge-npm-version]][url-npm]
[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/rolldown/rolldown)
[![Discord chat][badge-discord]][discord-url]

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![NPM Unpacked Size (with version)](https://img.shields.io/npm/unpacked-size/rolldown/latest?label=npm)][url-npm]
[![NPM Unpacked Size darwin-arm64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest?label=darwin-arm64)](https://www.npmjs.com/package/@rolldown/binding-darwin-arm64)
[![NPM Unpacked Size darwin-x64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-x64/latest?label=darwin-x64)](https://www.npmjs.com/package/@rolldown/binding-darwin-x64)
[![NPM Unpacked Size linux-x64-gnu](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-linux-x64-gnu/latest?label=linux-x64-gnu)](https://www.npmjs.com/package/@rolldown/binding-linux-x64-gnu)
[![NPM Unpacked Size win32-x64](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest?label=win32-x64)](https://www.npmjs.com/package/@rolldown/binding-win32-x64-msvc)
[![NPM Unpacked Size wasm32-wasi](https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-wasm32-wasi/latest?label=wasm32-wasi)](https://www.npmjs.com/package/@rolldown/binding-wasm32-wasi)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![pkg.pr.new](https://pkg.pr.new/badge/pkg.pr.new/pkg.pr.new?style=flat&amp;color=000&amp;logoSize=auto)](https://pkg.pr.new/~/rolldown/rolldown)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![rolldown-starter-stackblitz](https://developer.stackblitz.com/img/open_in_stackblitz.svg)](https://stackblitz.com/fork/github/rolldown/rolldown-starter-stackblitz)

&lt;/div&gt;

&gt; 🚧 **Beta Software**
&gt;
&gt; Rolldown is currently in beta status. While it can already handle most production use cases, there may still be bugs and rough edges. Most notably, the built-in minification feature is still in alpha status.

# Rolldown

Rolldown is a JavaScript/TypeScript bundler written in Rust intended to serve as the future bundler used in [Vite](https://vitejs.dev/). It provides Rollup-compatible APIs and plugin interface, but will be more similar to esbuild in scope.

For more information, please check out the documentation at [rolldown.rs](https://rolldown.rs/about).

## VoidZero Inc.

Rolldown is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/posts/announcing-voidzero-inc).

If you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!

## Contributing

We would love to have more contributors involved!

To get started, please read our [Contributing Guide](https://rolldown.rs/contrib-guide/).

## Credits

The Rolldown project is heavily inspired by:

- [Rollup](https://github.com/rollup/rollup), created by [Rich Harris](https://github.com/Rich-Harris) and maintained by [Lukas Taegert-Atkinson](https://github.com/lukastaegert).
- [esbuild](https://github.com/evanw/esbuild), created by [Evan Wallace](https://github.com/evanw).

And supported by:

- [napi-rs](https://github.com/napi-rs/napi-rs) for Node.js add-ons in Rust via Node-API.
- [oxc](https://github.com/oxc-project/oxc) for the underlying parser, resolver, and sourcemap support.

## Licenses

This project is licensed under the [MIT License](LICENSE).

This project also partially contains code derived or copied from the following projects:

- [rollup(MIT)](https://github.com/rollup/rollup/blob/680912e2ceb42c8d5e571e01c6ece0e4889aecbb/LICENSE-CORE.md)
- [esbuild(MIT)](https://github.com/evanw/esbuild/blob/0c8a0a901d9a6c7bbff9b4dd347c8a3f65f6c6dd/LICENSE.md)

Licenses of these projects are listed in [THIRD-PARTY-LICENSE](/THIRD-PARTY-LICENSE)

[badge-discord]: https://img.shields.io/discord/1079625926024900739?logo=discord&amp;label=Discord
[discord-url]: https://chat.rolldown.rs
[badge-license]: https://img.shields.io/badge/license-MIT-blue.svg
[url-license]: https://github.com/rolldown/rolldown/blob/main/LICENSE
[badge-npm-version]: https://img.shields.io/npm/v/rolldown/latest?color=brightgreen
[url-npm]: https://www.npmjs.com/package/rolldown/v/latest
[badge-binary-size-windows]: [https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-win32-x64-msvc/latest]
[badge-binary-size-macos]: [https://img.shields.io/npm/unpacked-size/%40rolldown%2Fbinding-darwin-arm64/latest]
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[katanemo/archgw]]></title>
            <link>https://github.com/katanemo/archgw</link>
            <guid>https://github.com/katanemo/archgw</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:40 GMT</pubDate>
            <description><![CDATA[The AI-native proxy server for agents. Arch handles the pesky low-level work in building agents like clariyfing vague user input, routing prompts to the right agents and unifying access to any LLM - all without locking you into a framework.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/katanemo/archgw">katanemo/archgw</a></h1>
            <p>The AI-native proxy server for agents. Arch handles the pesky low-level work in building agents like clariyfing vague user input, routing prompts to the right agents and unifying access to any LLM - all without locking you into a framework.</p>
            <p>Language: Rust</p>
            <p>Stars: 2,998</p>
            <p>Forks: 166</p>
            <p>Stars today: 65 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/source/_static/img/arch-logo.png&quot; alt=&quot;Arch Logo&quot; width=&quot;75%&quot; heigh=auto&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;


_The AI-native proxy server and the universal data plane for AI agents._&lt;br&gt;&lt;br&gt;
Arch handles the *pesky low-level work* in building AI agents like clarifying vague user inputs, routing prompts to the right agents, calling tools for simple tasks, and unifying access to large language models (LLMs) - all without locking you into a framework. Move faster by focusing on the high-level logic of your agents.


[Quickstart](#Quickstart) •
[Demos](#Demos) •
[Build agentic apps with Arch](#Build-AI-Agent-with-Arch-Gateway) •
[Route LLMs](#Use-Arch-as-a-LLM-Router) •
[Documentation](https://docs.archgw.com) •
[Contact](#Contact)

[![pre-commit](https://github.com/katanemo/arch/actions/workflows/pre-commit.yml/badge.svg)](https://github.com/katanemo/arch/actions/workflows/pre-commit.yml)
[![rust tests (prompt and llm gateway)](https://github.com/katanemo/arch/actions/workflows/rust_tests.yml/badge.svg)](https://github.com/katanemo/arch/actions/workflows/rust_tests.yml)
[![e2e tests](https://github.com/katanemo/arch/actions/workflows/e2e_tests.yml/badge.svg)](https://github.com/katanemo/arch/actions/workflows/e2e_tests.yml)
[![Build and Deploy Documentation](https://github.com/katanemo/arch/actions/workflows/static.yml/badge.svg)](https://github.com/katanemo/arch/actions/workflows/static.yml)


&lt;/div&gt;

# Overview
&lt;a href=&quot;https://www.producthunt.com/posts/arch-3?embed=true&amp;utm_source=badge-top-post-badge&amp;utm_medium=badge&amp;utm_souce=badge-arch&amp;#0045;3&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=565761&amp;theme=dark&amp;period=daily&amp;t=1742359429995&quot; alt=&quot;Arch - Build&amp;#0032;fast&amp;#0044;&amp;#0032;hyper&amp;#0045;personalized&amp;#0032;agents&amp;#0032;with&amp;#0032;intelligent&amp;#0032;infra | Product Hunt&quot; style=&quot;width: 188px; height: 41px;&quot; width=&quot;188&quot; height=&quot;41&quot; /&gt;&lt;/a&gt;

AI demos are easy to build. But past the thrill of a quick hack, you are left building, maintaining and scaling low-level plumbing code for agents that slows down AI innovation. For example:

- You want to build specialized agents, but get stuck building **routing and handoff** code.
- You want use new LLMs, but struggle to **quickly and safely add LLMs** without writing integration code.
- You&#039;re bogged down with prompt engineering work to **clarify user intent and validate inputs**.
- You&#039;re wasting cycles choosing and integrating code for **observability** instead of it happening transparently.

With Arch, you can move faster by focusing on higher-level objectives in a language and framework agnostic way. **Arch** was built by the contributors of [Envoy Proxy](https://www.envoyproxy.io/) with the belief that:

&gt;Prompts are nuanced and opaque user requests, which require the same capabilities as traditional HTTP requests including secure handling, intelligent routing, robust observability, and integration with backend (API) systems to improve speed and accuracy for common agentic scenarios  – all outside core application logic.*

**Core Features**:

  - `🚦 Routing to Agents`. Engineered with purpose-built [LLMs](https://huggingface.co/collections/katanemo/arch-function-66f209a693ea8df14317ad68) for fast (&lt;100ms) agent routing and hand-off scenarios
  - `🔗 Routing to LLMs`: Unify access and routing to any LLM, including dynamic routing via [preference policies](#Preference-based-Routing).
  - `⛨ Guardrails`: Centrally configure and prevent harmful outcomes and ensure safe user interactions
  - `⚡ Tools Use`: For common agentic scenarios let Arch instantly clarify and convert prompts to tools/API calls
  - `🕵 Observability`: W3C compatible request tracing and LLM metrics that instantly plugin with popular tools
  - `🧱 Built on Envoy`: Arch runs alongside app servers as a containerized process, and builds on top of [Envoy&#039;s](https://envoyproxy.io) proven HTTP management and scalability features to handle ingress and egress traffic related to prompts and LLMs.

**High-Level Sequence Diagram**:
![alt text](docs/source/_static/img/arch_network_diagram_high_level.png)

**Jump to our [docs](https://docs.archgw.com)** to learn how you can use Arch to improve the speed, security and personalization of your GenAI apps.

&gt; [!IMPORTANT]
&gt; Today, the function calling LLM (Arch-Function) designed for the agentic and RAG scenarios is hosted free of charge in the US-central region. To offer consistent latencies and throughput, and to manage our expenses, we will enable access to the hosted version via developers keys soon, and give you the option to run that LLM locally. For more details see this issue [#258](https://github.com/katanemo/archgw/issues/258)

## Contact
To get in touch with us, please join our [discord server](https://discord.gg/pGZf2gcwEc). We will be monitoring that actively and offering support there.

## Demos
* [Sample App: Weather Forecast Agent](demos/samples_python/weather_forecast/README.md) - A sample agentic weather forecasting app that highlights core function calling capabilities of Arch.
* [Sample App: Network Operator Agent](demos/samples_python/network_switch_operator_agent/README.md) - A simple network device switch operator agent that can retrive device statistics and reboot them.
* [User Case: Connecting to SaaS APIs](demos/use_cases/spotify_bearer_auth) - Connect 3rd party SaaS APIs to your agentic chat experience.

## Quickstart

Follow this quickstart guide to use arch gateway to build a simple AI agent. Laster in the section we will see how you can Arch Gateway to manage access keys, provide unified access to upstream LLMs and to provide e2e observability.

### Prerequisites

Before you begin, ensure you have the following:

1. [Docker System](https://docs.docker.com/get-started/get-docker/) (v24)
2. [Docker compose](https://docs.docker.com/compose/install/) (v2.29)
3. [Python](https://www.python.org/downloads/) (v3.12)

Arch&#039;s CLI allows you to manage and interact with the Arch gateway efficiently. To install the CLI, simply run the following command:

&gt; [!TIP]
&gt; We recommend that developers create a new Python virtual environment to isolate dependencies before installing Arch. This ensures that archgw and its dependencies do not interfere with other packages on your system.

```console
$ python -m venv venv
$ source venv/bin/activate   # On Windows, use: venv\Scripts\activate
$ pip install archgw==0.3.2
```

### Build Agentic Apps with Arch Gateway

In following quickstart we will show you how easy it is to build AI agent with Arch gateway. We will build a currency exchange agent using following simple steps. For this demo we will use `https://api.frankfurter.dev/` to fetch latest price for currencies and assume USD as base currency.

#### Step 1. Create arch config file

Create `arch_config.yaml` file with following content,

```yaml
version: v0.1.0

listeners:
  ingress_traffic:
    address: 0.0.0.0
    port: 10000
    message_format: openai
    timeout: 30s

llm_providers:
  - name: gpt-4o
    access_key: $OPENAI_API_KEY
    provider: openai
    model: gpt-4o

system_prompt: |
  You are a helpful assistant.

prompt_guards:
  input_guards:
    jailbreak:
      on_exception:
        message: Looks like you&#039;re curious about my abilities, but I can only provide assistance for currency exchange.

prompt_targets:
  - name: currency_exchange
    description: Get currency exchange rate from USD to other currencies
    parameters:
      - name: currency_symbol
        description: the currency that needs conversion
        required: true
        type: str
        in_path: true
    endpoint:
      name: frankfurther_api
      path: /v1/latest?base=USD&amp;symbols={currency_symbol}
    system_prompt: |
      You are a helpful assistant. Show me the currency symbol you want to convert from USD.

  - name: get_supported_currencies
    description: Get list of supported currencies for conversion
    endpoint:
      name: frankfurther_api
      path: /v1/currencies

endpoints:
  frankfurther_api:
    endpoint: api.frankfurter.dev:443
    protocol: https
```

#### Step 2. Start arch gateway with currency conversion config

```sh

$ archgw up arch_config.yaml
2024-12-05 16:56:27,979 - cli.main - INFO - Starting archgw cli version: 0.1.5
...
2024-12-05 16:56:28,485 - cli.utils - INFO - Schema validation successful!
2024-12-05 16:56:28,485 - cli.main - INFO - Starting arch model server and arch gateway
...
2024-12-05 16:56:51,647 - cli.core - INFO - Container is healthy!

```

Once the gateway is up you can start interacting with at port 10000 using openai chat completion API.

Some of the sample queries you can ask could be `what is currency rate for gbp?` or `show me list of currencies for conversion`.

#### Step 3. Interacting with gateway using curl command

Here is a sample curl command you can use to interact,

```bash
$ curl --header &#039;Content-Type: application/json&#039; \
  --data &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;,&quot;content&quot;: &quot;what is exchange rate for gbp&quot;}], &quot;model&quot;: &quot;none&quot;}&#039; \
  http://localhost:10000/v1/chat/completions | jq &quot;.choices[0].message.content&quot;

&quot;As of the date provided in your context, December 5, 2024, the exchange rate for GBP (British Pound) from USD (United States Dollar) is 0.78558. This means that 1 USD is equivalent to 0.78558 GBP.&quot;

```

And to get list of supported currencies,

```bash
$ curl --header &#039;Content-Type: application/json&#039; \
  --data &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;,&quot;content&quot;: &quot;show me list of currencies that are supported for conversion&quot;}], &quot;model&quot;: &quot;none&quot;}&#039; \
  http://localhost:10000/v1/chat/completions | jq &quot;.choices[0].message.content&quot;

&quot;Here is a list of the currencies that are supported for conversion from USD, along with their symbols:\n\n1. AUD - Australian Dollar\n2. BGN - Bulgarian Lev\n3. BRL - Brazilian Real\n4. CAD - Canadian Dollar\n5. CHF - Swiss Franc\n6. CNY - Chinese Renminbi Yuan\n7. CZK - Czech Koruna\n8. DKK - Danish Krone\n9. EUR - Euro\n10. GBP - British Pound\n11. HKD - Hong Kong Dollar\n12. HUF - Hungarian Forint\n13. IDR - Indonesian Rupiah\n14. ILS - Israeli New Sheqel\n15. INR - Indian Rupee\n16. ISK - Icelandic Króna\n17. JPY - Japanese Yen\n18. KRW - South Korean Won\n19. MXN - Mexican Peso\n20. MYR - Malaysian Ringgit\n21. NOK - Norwegian Krone\n22. NZD - New Zealand Dollar\n23. PHP - Philippine Peso\n24. PLN - Polish Złoty\n25. RON - Romanian Leu\n26. SEK - Swedish Krona\n27. SGD - Singapore Dollar\n28. THB - Thai Baht\n29. TRY - Turkish Lira\n30. USD - United States Dollar\n31. ZAR - South African Rand\n\nIf you want to convert USD to any of these currencies, you can select the one you are interested in.&quot;

```

### Use Arch as a LLM Router
Arch supports two primary routing strategies for LLMs: model-based routing and preference-based routing.

#### Model-based Routing
Model-based routing allows you to configure static model names for routing. This is useful when you always want to use a specific model for certain tasks, or manually swap between models. Below an example configuration for model-based routing, and you can follow our [usage guide](demos/use_cases/README.md) on how to get working.

```yaml
version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - name: gpt-4o
    access_key: $OPENAI_API_KEY
    provider: openai
    model: gpt-4o
    default: true

  - name: mistral-3b
    access_key: $MISTRAL_API_KEY
    provider: openai
    model: mistral-3b-latest
```

#### Preference-based Routing
Preference-based routing is designed for more dynamic and intelligent selection of models. Instead of static model names, you write plain-language routing policies that describe the type of task or preference — for example:

```yaml
version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - name: code_generation
    access_key: $OPENAI_API_KEY
    provider_interface: openai
    model: gpt-4.1
    usage: generating new code snippets, functions, or boilerplate based on user prompts or requirements

  - name: code_understanding
    provider_interface: openai
    access_key: $OPENAI_API_KEY
    model: gpt-4o-mini
    usage: understand and explain existing code snippets, functions, or libraries
```

Arch uses a lightweight 1.5B autoregressive model to map prompts (and conversation context) to these policies. This approach adapts to intent drift, supports multi-turn conversations, and avoids the brittleness of embedding-based classifiers or manual if/else chains. No retraining is required when adding new models or updating policies — routing is governed entirely by human-readable rules. You can learn more about the design, benchmarks, and methodology behind preference-based routing in our paper:

&lt;div align=&quot;left&quot;&gt;
  &lt;a href=&quot;https://arxiv.org/abs/2506.16655&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;docs/source/_static/img/arch_router_paper_preview.png&quot; alt=&quot;Arch Router Paper Preview&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

## [Observability](https://docs.archgw.com/guides/observability/observability.html)
Arch is designed to support best-in class observability by supporting open standards. Please read our [docs](https://docs.archgw.com/guides/observability/observability.html) on observability for more details on tracing, metrics, and logs. The screenshot below is from our integration with Signoz (among others)

![alt text](docs/source/_static/img/tracing.png)

## Debugging

When debugging issues / errors application logs and access logs provide key information to give you more context on whats going on with the system. Arch gateway runs in info log level and following is a typical output you could see in a typical interaction between developer and arch gateway,

```
$ archgw up --service archgw --foreground
...
[2025-03-26 18:32:01.350][26][info] prompt_gateway: on_http_request_body: sending request to model server
[2025-03-26 18:32:01.851][26][info] prompt_gateway: on_http_call_response: model server response received
[2025-03-26 18:32:01.852][26][info] prompt_gateway: on_http_call_response: dispatching api call to developer endpoint: weather_forecast_service, path: /weather, method: POST
[2025-03-26 18:32:01.882][26][info] prompt_gateway: on_http_call_response: developer api call response received: status code: 200
[2025-03-26 18:32:01.882][26][info] prompt_gateway: on_http_call_response: sending request to upstream llm
[2025-03-26 18:32:01.883][26][info] llm_gateway: on_http_request_body: provider: gpt-4o-mini, model requested: None, model selected: gpt-4o-mini
[2025-03-26 18:32:02.818][26][info] llm_gateway: on_http_response_body: time to first token: 1468ms
[2025-03-26 18:32:04.532][26][info] llm_gateway: on_http_response_body: request latency: 3183ms
...
```

Log level can be changed to debug to get more details. To enable debug logs edit (supervisord.conf)[arch/supervisord.conf], change the log level `--component-log-level wasm:info` to `--component-log-level wasm:debug`. And after that you need to rebuild docker image and restart the arch gateway using following set of commands,

```
# make sure you are at the root of the repo
$ archgw build
# go to your service that has arch_config.yaml file and issue following command,
$ archgw up --service archgw --foreground
```

## Contribution
We would love feedback on our [Roadmap](https://github.com/orgs/katanemo/projects/1) and we welcome contributions to **Arch**!
Whether you&#039;re fixing bugs, adding new features, improving documentation, or creating tutorials, your help is much appreciated.
Please visit our [Contribution Guide](CONTRIBUTING.md) for more details
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[apache/arrow-rs]]></title>
            <link>https://github.com/apache/arrow-rs</link>
            <guid>https://github.com/apache/arrow-rs</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:39 GMT</pubDate>
            <description><![CDATA[Official Rust implementation of Apache Arrow]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/apache/arrow-rs">apache/arrow-rs</a></h1>
            <p>Official Rust implementation of Apache Arrow</p>
            <p>Language: Rust</p>
            <p>Stars: 3,002</p>
            <p>Forks: 962</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;!---
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  &quot;License&quot;); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing,
  software distributed under the License is distributed on an
  &quot;AS IS&quot; BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  KIND, either express or implied.  See the License for the
  specific language governing permissions and limitations
  under the License.
--&gt;

# Native Rust implementation of Apache Arrow and Apache Parquet

Welcome to the [Rust][rust] implementation of [Apache Arrow], the popular in-memory columnar format.

This repository contains the following crates:

| Crate              | Description                                                                  | Latest API Docs                                  | README                            |
| ------------------ | ---------------------------------------------------------------------------- | ------------------------------------------------ | --------------------------------- |
| [`arrow`]          | Core functionality (memory layout, arrays, low level computations)           | [docs.rs](https://docs.rs/arrow/latest)          | [(README)][arrow-readme]          |
| [`arrow-flight`]   | Support for Arrow-Flight IPC protocol                                        | [docs.rs](https://docs.rs/arrow-flight/latest)   | [(README)][flight-readme]         |
| [`parquet`]        | Support for Parquet columnar file format                                     | [docs.rs](https://docs.rs/parquet/latest)        | [(README)][parquet-readme]        |
| [`parquet_derive`] | A crate for deriving RecordWriter/RecordReader for arbitrary, simple structs | [docs.rs](https://docs.rs/parquet-derive/latest) | [(README)][parquet-derive-readme] |

The current development version the API documentation in this repo can be found [here](https://arrow.apache.org/rust).

Note: previously the [`object_store`] crate was also part of this repository,
but it has been moved to the [arrow-rs-object-store repository]

[apache arrow]: https://arrow.apache.org/
[`arrow`]: https://crates.io/crates/arrow
[`parquet`]: https://crates.io/crates/parquet
[`parquet_derive`]: https://crates.io/crates/parquet-derive
[`arrow-flight`]: https://crates.io/crates/arrow-flight
[arrow-rs-object-store repository]: https://github.com/apache/arrow-rs-object-store

## Release Versioning and Schedule

The Arrow Rust project releases approximately monthly and follows [Semantic
Versioning].

Due to available maintainer and testing bandwidth, [`arrow`] crates ([`arrow`],
[`arrow-flight`], etc.) are released on the same schedule with the same versions
as the [`parquet`] and [`parquet-derive`] crates.

This crate releases every month. We release new major versions (with potentially
breaking API changes) at most once a quarter, and release incremental minor
versions in the intervening months. See [ticket #5368] for more details.

To keep our maintenance burden down, we do regularly scheduled releases (major
and minor) from the `main` branch. How we handle PRs with breaking API changes
is described in the [contributing] guide.

[contributing]: CONTRIBUTING.md#breaking-changes

Planned Release Schedule

| Approximate Date | Version    | Notes                                   |
| ---------------- | ---------- | --------------------------------------- |
| July 2025        | [`56.0.0`] | Major, potentially breaking API changes |
| August 2025      | [`56.1.0`] | Minor, NO breaking API changes          |
| September 2025   | [`56.2.0`] | Minor, NO breaking API changes          |
| October 2025     | [`57.0.0`] | Major, potentially breaking API changes |

[`56.0.0`]: https://github.com/apache/arrow-rs/issues/7395
[`56.1.0`]: https://github.com/apache/arrow-rs/issues/7837
[`56.2.0`]: https://github.com/apache/arrow-rs/issues/7836
[`57.0.0`]: https://github.com/apache/arrow-rs/issues/7835
[ticket #5368]: https://github.com/apache/arrow-rs/issues/5368
[semantic versioning]: https://semver.org/

### Rust Version Compatibility Policy

arrow-rs, parquet and object_store are built and tested with stable Rust, and will keep a rolling MSRV (minimum supported Rust version) that can only be updated in major releases on a need by basis (e.g. project dependencies bump their MSRV or a particular Rust feature is useful for us etc.). The new MSRV if selected will be at least 6 months old. The minor releases are guaranteed to have the same MSRV.

Note: If a Rust hotfix is released for the current MSRV, the MSRV will be updated to the specific minor version that includes all applicable hotfixes preceding other policies.

E.g.

in Apr 2025 we will release version 55.0.0 which might have a version bump. But the Rust version selected in this case will be at most version 1.81.

### Guidelines for `panic` vs `Result`

In general, use panics for bad states that are unreachable, unrecoverable or harmful.
For those caused by invalid user input, however, we prefer to report that invalidity
gracefully as an error result instead of panicking. In general, invalid input should result
in an `Error` as soon as possible. It _is_ ok for code paths after validation to assume
validation has already occurred and panic if not. See [ticket #6737] for more nuances.

[ticket #6737]: https://github.com/apache/arrow-rs/issues/6737

### Deprecation Guidelines

Minor releases may deprecate, but not remove APIs. Deprecating APIs allows
downstream Rust programs to still compile, but generate compiler warnings. This
gives downstream crates time to migrate prior to API removal.

To deprecate an API:

- Mark the API as deprecated using `#[deprecated]` and specify the exact arrow-rs version in which it was deprecated
- Concisely describe the preferred API to help the user transition

The deprecated version is the next version which will be released (please
consult the list above). To mark the API as deprecated, use the
`#[deprecated(since = &quot;...&quot;, note = &quot;...&quot;)]` attribute.

Foe example

```rust
#[deprecated(since = &quot;51.0.0&quot;, note = &quot;Use `date_part` instead&quot;)]
```

In general, deprecated APIs will remain in the codebase for at least two major releases after
they were deprecated (typically between 6 - 9 months later). For example, an API
deprecated in `51.3.0` can be removed in `54.0.0` (or later). Deprecated APIs
may be removed earlier or later than these guidelines at the discretion of the
maintainers.

## Related Projects

There are several related crates in different repositories

| Crate               | Description                                                  | Documentation                      |
| ------------------- | ------------------------------------------------------------ | ---------------------------------- |
| [`object_store`]    | Object Storage (aws, azure, gcp, local, in-memory) interface | [(README)](object_store-readme)    |
| [`datafusion`]      | In-memory query engine with SQL support                      | [(README)][datafusion-readme]      |
| [`ballista`]        | Distributed query execution                                  | [(README)][ballista-readme]        |
| [`parquet_opendal`] | Use [`opendal`] for [`parquet`] Arrow IO                     | [(README)][parquet_opendal-readme] |

[`datafusion`]: https://crates.io/crates/datafusion
[`ballista`]: https://crates.io/crates/ballista
[`parquet_opendal`]: https://crates.io/crates/parquet_opendal
[parquet_opendal-readme]: https://github.com/apache/opendal/blob/main/integrations/parquet/README.md
[object_store-readme]: https://github.com/apache/arrow-rs-object-store/blob/main/README.md

Collectively, these crates support a wider array of functionality for analytic computations in Rust.

For example, you can write SQL queries or a `DataFrame` (using the
[`datafusion`] crate) to read a parquet file (using the [`parquet`] crate),
evaluate it in-memory using Arrow&#039;s columnar format (using the [`arrow`] crate),
and send to another process (using the [`arrow-flight`] crate).

Generally speaking, the [`arrow`] crate offers functionality for using Arrow
arrays, and [`datafusion`] offers most operations typically found in SQL,
including `join`s and window functions.

You can find more details about each crate in their respective READMEs.

## Arrow Rust Community

The `dev@arrow.apache.org` mailing list serves as the core communication channel for the Arrow community. Instructions for signing up and links to the archives can be found on the [Arrow Community](https://arrow.apache.org/community/) page. All major announcements and communications happen there.

The Rust Arrow community also uses the official [ASF Slack](https://s.apache.org/slack-invite) for informal discussions and coordination. This is
a great place to meet other contributors and get guidance on where to contribute. Join us in the `#arrow-rust` channel and feel free to ask for an invite via:

1. the `dev@arrow.apache.org` mailing list
2. the [GitHub Discussions][discussions]
3. the [Discord channel](https://discord.gg/YAb2TdazKQ)

The Rust implementation uses [GitHub issues][issues] as the system of record for new features and bug fixes and
this plays a critical role in the release process.

For design discussions we generally use GitHub issues.

There is more information in the [contributing] guide.

[rust]: https://www.rust-lang.org/
[`object_store`]: https://crates.io/crates/object-store
[arrow-readme]: arrow/README.md
[contributing]: CONTRIBUTING.md
[parquet-readme]: parquet/README.md
[flight-readme]: arrow-flight/README.md
[datafusion-readme]: https://github.com/apache/datafusion/blob/main/README.md
[ballista-readme]: https://github.com/apache/datafusion-ballista/blob/main/README.md
[parquet-derive-readme]: parquet_derive/README.md
[issues]: https://github.com/apache/arrow-rs/issues
[discussions]: https://github.com/apache/arrow-rs/discussions
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:38 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 15,411</p>
            <p>Forks: 1,276</p>
            <p>Stars today: 104 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# codename goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/7GaTvbDwga&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;&gt;
     &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.

# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)


# Goose Around with Us
- [Discord](https://discord.gg/block-opensource)
- [YouTube](https://www.youtube.com/@blockopensource)
- [LinkedIn](https://www.linkedin.com/company/block-opensource)
- [Twitter/X](https://x.com/blockopensource)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:37 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 60,070</p>
            <p>Forks: 1,713</p>
            <p>Stars today: 131 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- 🚀 A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`,
  and more.
- ⚡️ [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- 🗂️ Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- ❇️ [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- 🐍 [Installs and manages](#python-versions) Python versions.
- 🛠️ [Runs and installs](#tools) tools published as Python packages.
- 🔩 Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a
  familiar CLI.
- 🏢 Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- 💾 Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- ⏬ Installable without Rust or Python via `curl` or `pip`.
- 🖥️ Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows — and experience a 10-100x speedup — with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Platform support

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

## Versioning policy

See uv&#039;s [versioning policy](https://docs.astral.sh/uv/reference/versioning/) document.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv/blob/main/CONTRIBUTING.md) to get started.

## FAQ

#### How do you pronounce uv?

It&#039;s pronounced as &quot;you - vee&quot; ([`/juː viː/`](https://en.wikipedia.org/wiki/Help:IPA/English#Key))

#### How should I stylize uv?

Just &quot;uv&quot;, please. See the [style guide](./STYLE.md#styling-uv) for details.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ai-dynamo/dynamo]]></title>
            <link>https://github.com/ai-dynamo/dynamo</link>
            <guid>https://github.com/ai-dynamo/dynamo</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[A Datacenter Scale Distributed Inference Serving Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo</a></h1>
            <p>A Datacenter Scale Distributed Inference Serving Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 4,401</p>
            <p>Forks: 462</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;
![Dynamo banner](./docs/images/frontpage-banner.png)

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)
[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)

| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/762)** | **[Documentation](https://docs.nvidia.com/dynamo/latest/index.html)** | **[Examples](https://github.com/ai-dynamo/examples)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** |

### The Era of Multi-Node, Multi-GPU

![GPU Evolution](./docs/images/frontpage-gpu-evolution.png)


Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs—and sometimes many servers—but it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.

![Multi Node Multi-GPU topology](./docs/images/frontpage-gpu-vertical.png)



### Introducing NVIDIA Dynamo

NVIDIA Dynamo is a high-throughput low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments. Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:

![Dynamo architecture](./docs/images/frontpage-architecture.png)

- **Disaggregated prefill &amp; decode inference** – Maximizes GPU throughput and facilitates trade off between throughput and latency.
- **Dynamic GPU scheduling** – Optimizes performance based on fluctuating demand
- **LLM-aware request routing** – Eliminates unnecessary KV cache re-computation
- **Accelerated data transfer** – Reduces inference response time using NIXL.
- **KV cache offloading** – Leverages multiple memory hierarchies for higher system throughput

Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.



### Installation

The following examples require a few system level packages.
Recommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/support_matrix.md](docs/support_matrix.md)

```
apt-get update
DEBIAN_FRONTEND=noninteractive apt-get install -yq python3-dev python3-pip python3-venv libucx0
python3 -m venv venv
source venv/bin/activate

pip install &quot;ai-dynamo[all]&quot;
```
&gt; [!NOTE]
&gt; To ensure compatibility, please refer to the examples in the release branch or tag that matches the version you installed.

### Building the Dynamo Base Image

Although not needed for local development, deploying your Dynamo pipelines to Kubernetes will require you to build and push a Dynamo base image to your container registry. You can use any container registry of your choice, such as:
- Docker Hub (docker.io)
- NVIDIA NGC Container Registry (nvcr.io)
- Any private registry

Here&#039;s how to build it:

```bash
./container/build.sh
docker tag dynamo:latest-vllm &lt;your-registry&gt;/dynamo-base:latest-vllm
docker login &lt;your-registry&gt;
docker push &lt;your-registry&gt;/dynamo-base:latest-vllm
```

Notes about builds for specific frameworks:
- For specific details on the `--framework vllm` build, see [here](examples/llm/README.md).
- For specific details on the `--framework tensorrtllm` build, see [here](examples/tensorrt_llm/README.md).

Note about AWS environments:
- If deploying Dynamo in AWS, make sure to build the container with EFA support using the `--make-efa` flag.

After building, you can use this image by setting the `DYNAMO_IMAGE` environment variable to point to your built image:
```bash
export DYNAMO_IMAGE=&lt;your-registry&gt;/dynamo-base:latest-vllm
```

&gt; [!NOTE]
&gt; We are working on leaner base images that can be built using the targets in the top-level Earthfile.

### Running and Interacting with an LLM Locally

To run a model and interact with it locally you can call `dynamo
run` with a hugging face model. `dynamo run` supports several backends
including: `mistralrs`, `sglang`, `vllm`, and `tensorrtllm`.

#### Example Command

```
dynamo run out=vllm deepseek-ai/DeepSeek-R1-Distill-Llama-8B
```

```
? User › Hello, how are you?
✔ User · Hello, how are you?
Okay, so I&#039;m trying to figure out how to respond to the user&#039;s greeting. They said, &quot;Hello, how are you?&quot; and then followed it with &quot;Hello! I&#039;m just a program, but thanks for asking.&quot; Hmm, I need to come up with a suitable reply. ...
```

### LLM Serving

Dynamo provides a simple way to spin up a local set of inference
components including:

- **OpenAI Compatible Frontend** – High performance OpenAI compatible http api server written in Rust.
- **Basic and Kv Aware Router** – Route and load balance traffic to a set of workers.
- **Workers** – Set of pre-configured LLM serving engines.

To run a minimal configuration you can use a pre-configured
example.

#### Start Dynamo Distributed Runtime Services

First start the Dynamo Distributed Runtime services:

```bash
docker compose -f deploy/metrics/docker-compose.yml up -d
```
#### Start Dynamo LLM Serving Components

Next serve a minimal configuration with an http server, basic
round-robin router, and a single worker.

```bash
cd examples/llm
dynamo serve graphs.agg:Frontend -f configs/agg.yaml
```

#### Send a Request

```bash
curl localhost:8000/v1/chat/completions   -H &quot;Content-Type: application/json&quot;   -d &#039;{
    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,
    &quot;messages&quot;: [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello, how are you?&quot;
    }
    ],
    &quot;stream&quot;:false,
    &quot;max_tokens&quot;: 300
  }&#039; | jq
```

### Local Development

If you use vscode or cursor, we have a .devcontainer folder built on [Microsofts Extension](https://code.visualstudio.com/docs/devcontainers/containers). For instructions see the [ReadMe](.devcontainer/README.md) for more details.

Otherwise, to develop locally, we recommend working inside of the container

```bash
./container/build.sh
./container/run.sh -it --mount-workspace

cargo build --release
mkdir -p /workspace/deploy/sdk/src/dynamo/sdk/cli/bin
cp /workspace/target/release/http /workspace/deploy/sdk/src/dynamo/sdk/cli/bin
cp /workspace/target/release/llmctl /workspace/deploy/sdk/src/dynamo/sdk/cli/bin
cp /workspace/target/release/dynamo-run /workspace/deploy/sdk/src/dynamo/sdk/cli/bin

uv pip install -e .
export PYTHONPATH=$PYTHONPATH:/workspace/deploy/sdk/src:/workspace/components/planner/src
```


#### Conda Environment

Alternately, you can use a conda environment

```bash
conda activate &lt;ENV_NAME&gt;

pip install nixl # Or install https://github.com/ai-dynamo/nixl from source

cargo build --release

# To install ai-dynamo-runtime from source
cd lib/bindings/python
pip install .

cd ../../../
pip install &quot;.[all]&quot;

# To test
docker compose -f deploy/metrics/docker-compose.yml up -d
cd examples/llm
dynamo serve graphs.agg:Frontend -f configs/agg.yaml
```
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[emmett-framework/granian]]></title>
            <link>https://github.com/emmett-framework/granian</link>
            <guid>https://github.com/emmett-framework/granian</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[A Rust HTTP server for Python applications]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/emmett-framework/granian">emmett-framework/granian</a></h1>
            <p>A Rust HTTP server for Python applications</p>
            <p>Language: Rust</p>
            <p>Stars: 3,685</p>
            <p>Forks: 105</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;550&quot; src=&quot;https://emmett.sh/static/img/granian-logo-xb-fw.png&quot; alt=&quot;granian&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;em&gt;The Rust HTTP server for Python&lt;/em&gt;
&lt;/p&gt;

---

Granian is a Rust HTTP server for Python applications built on top of [Hyper](https://github.com/hyperium/hyper) and [Tokio](https://github.com/tokio-rs/tokio).

## Rationale

The main reasons behind Granian design are:

- Have a single, correct HTTP implementation, supporting versions 1, 2 (and eventually 3)
- Provide a single package for several platforms
- Avoid the usual Gunicorn + uvicorn + http-tools dependency composition on unix systems
- Provide stable [performance](https://github.com/emmett-framework/granian/blob/master/benchmarks/vs.md) when compared to existing alternatives

Adopting Granian would thus be a good choice when:

- wanting a modern, single dependency to serve both ASGI and WSGI applications
- looking for the most performant way to serve your Python application under HTTP/2
- you need great concurrency capabilities, especially with websockets
- you care about performance more than everything else

On the other hand, Granian won&#039;t be the ideal option if:

- you want a *pure Python* solution
- you need advanced debugging features
- your application relies on `trio` or `gevent`
- you&#039;re looking for ASGI extensions [not (yet) implemented](https://github.com/emmett-framework/granian/issues/93) like trailers

## Features

- Supports ASGI/3, [RSGI](https://github.com/emmett-framework/granian/blob/master/docs/spec/RSGI.md) and WSGI interface applications
- HTTP/1 and HTTP/2 protocols
- HTTPS and mTLS
- Websockets
- Direct static files serving
- ASGI [pathsend](https://asgi.readthedocs.io/en/latest/extensions.html#path-send) extension

## Quickstart

You can install Granian using pip:

    $ pip install granian

### ASGI

Create an application in your `main.py`:

```python
async def app(scope, receive, send):
    assert scope[&#039;type&#039;] == &#039;http&#039;

    await send({
        &#039;type&#039;: &#039;http.response.start&#039;,
        &#039;status&#039;: 200,
        &#039;headers&#039;: [
            [b&#039;content-type&#039;, b&#039;text/plain&#039;],
        ],
    })
    await send({
        &#039;type&#039;: &#039;http.response.body&#039;,
        &#039;body&#039;: b&#039;Hello, world!&#039;,
    })
```

and serve it using Granian CLI:

    $ granian --interface asgi main:app

### RSGI

Create an application your `main.py`:

```python
async def app(scope, proto):
    assert scope.proto == &#039;http&#039;

    proto.response_str(
        status=200,
        headers=[
            (&#039;content-type&#039;, &#039;text/plain&#039;)
        ],
        body=&quot;Hello, world!&quot;
    )
```

and serve it using Granian CLI:

    $ granian --interface rsgi main:app

### WSGI

Create an application your `main.py`:

```python
def app(environ, start_response):
    start_response(&#039;200 OK&#039;, [(&#039;content-type&#039;, &#039;text/plain&#039;)])
    return [b&quot;Hello, world!&quot;]
```

and serve it using Granian CLI:

    $ granian --interface wsgi main:app

## Extra dependecies

Mind that Granian also provides several extra dependencies you might be interested into, in particular:

- dotenv (allows to load environment files)
- pname (allows to customize processes&#039; names)
- reload (adds reload on changes functionality)
- [rloop](https://pypi.org/project/rloop/)
- [uvloop](https://pypi.org/project/uvloop/)

You can combine the above extras to suit your needs, eg:

    $ pip install granian[pname,uvloop]

For further information, check the options below.

## Options

You can check all the options provided by Granian with the `--help` command:

```
$ granian --help
Usage: granian [OPTIONS] APP

  APP  Application target to serve.  [required]

Options:
  --host TEXT                     Host address to bind to  [env var:
                                  GRANIAN_HOST; default: (127.0.0.1)]
  --port INTEGER                  Port to bind to.  [env var: GRANIAN_PORT;
                                  default: 8000]
  --interface [asgi|asginl|rsgi|wsgi]
                                  Application interface type  [env var:
                                  GRANIAN_INTERFACE; default: (rsgi)]
  --http [auto|1|2]               HTTP version  [env var: GRANIAN_HTTP;
                                  default: (auto)]
  --ws / --no-ws                  Enable websockets handling  [env var:
                                  GRANIAN_WEBSOCKETS; default: (enabled)]
  --workers INTEGER RANGE         Number of worker processes  [env var:
                                  GRANIAN_WORKERS; default: 1; x&gt;=1]
  --blocking-threads INTEGER RANGE
                                  Number of blocking threads (per worker)
                                  [env var: GRANIAN_BLOCKING_THREADS; x&gt;=1]
  --blocking-threads-idle-timeout INTEGER RANGE
                                  The maximum amount of time in seconds an
                                  idle blocking thread will be kept alive
                                  [env var:
                                  GRANIAN_BLOCKING_THREADS_IDLE_TIMEOUT;
                                  default: 30; 10&lt;=x&lt;=600]
  --runtime-threads INTEGER RANGE
                                  Number of runtime threads (per worker)  [env
                                  var: GRANIAN_RUNTIME_THREADS; default: 1;
                                  x&gt;=1]
  --runtime-blocking-threads INTEGER RANGE
                                  Number of runtime I/O blocking threads (per
                                  worker)  [env var:
                                  GRANIAN_RUNTIME_BLOCKING_THREADS; x&gt;=1]
  --runtime-mode [mt|st]          Runtime mode to use (single/multi threaded)
                                  [env var: GRANIAN_RUNTIME_MODE; default:
                                  (st)]
  --loop [auto|asyncio|rloop|uvloop]
                                  Event loop implementation  [env var:
                                  GRANIAN_LOOP; default: (auto)]
  --task-impl [asyncio|rust]      Async task implementation to use  [env var:
                                  GRANIAN_TASK_IMPL; default: (asyncio)]
  --backlog INTEGER RANGE         Maximum number of connections to hold in
                                  backlog (globally)  [env var:
                                  GRANIAN_BACKLOG; default: 1024; x&gt;=128]
  --backpressure INTEGER RANGE    Maximum number of requests to process
                                  concurrently (per worker)  [env var:
                                  GRANIAN_BACKPRESSURE; default:
                                  (backlog/workers); x&gt;=1]
  --http1-buffer-size INTEGER RANGE
                                  Sets the maximum buffer size for HTTP/1
                                  connections  [env var:
                                  GRANIAN_HTTP1_BUFFER_SIZE; default: 417792;
                                  x&gt;=8192]
  --http1-header-read-timeout INTEGER RANGE
                                  Sets a timeout (in milliseconds) to read
                                  headers  [env var:
                                  GRANIAN_HTTP1_HEADER_READ_TIMEOUT; default:
                                  30000; 1&lt;=x&lt;=60000]
  --http1-keep-alive / --no-http1-keep-alive
                                  Enables or disables HTTP/1 keep-alive  [env
                                  var: GRANIAN_HTTP1_KEEP_ALIVE; default:
                                  (enabled)]
  --http1-pipeline-flush / --no-http1-pipeline-flush
                                  Aggregates HTTP/1 flushes to better support
                                  pipelined responses (experimental)  [env
                                  var: GRANIAN_HTTP1_PIPELINE_FLUSH; default:
                                  (disabled)]
  --http2-adaptive-window / --no-http2-adaptive-window
                                  Sets whether to use an adaptive flow control
                                  for HTTP2  [env var:
                                  GRANIAN_HTTP2_ADAPTIVE_WINDOW; default:
                                  (disabled)]
  --http2-initial-connection-window-size INTEGER RANGE
                                  Sets the max connection-level flow control
                                  for HTTP2  [env var: GRANIAN_HTTP2_INITIAL_C
                                  ONNECTION_WINDOW_SIZE; default: 1048576;
                                  x&gt;=1024]
  --http2-initial-stream-window-size INTEGER RANGE
                                  Sets the `SETTINGS_INITIAL_WINDOW_SIZE`
                                  option for HTTP2 stream-level flow control
                                  [env var:
                                  GRANIAN_HTTP2_INITIAL_STREAM_WINDOW_SIZE;
                                  default: 1048576; x&gt;=1024]
  --http2-keep-alive-interval INTEGER RANGE
                                  Sets an interval (in milliseconds) for HTTP2
                                  Ping frames should be sent to keep a
                                  connection alive  [env var:
                                  GRANIAN_HTTP2_KEEP_ALIVE_INTERVAL;
                                  1&lt;=x&lt;=60000]
  --http2-keep-alive-timeout INTEGER RANGE
                                  Sets a timeout (in seconds) for receiving an
                                  acknowledgement of the HTTP2 keep-alive ping
                                  [env var: GRANIAN_HTTP2_KEEP_ALIVE_TIMEOUT;
                                  default: 20; x&gt;=1]
  --http2-max-concurrent-streams INTEGER RANGE
                                  Sets the SETTINGS_MAX_CONCURRENT_STREAMS
                                  option for HTTP2 connections  [env var:
                                  GRANIAN_HTTP2_MAX_CONCURRENT_STREAMS;
                                  default: 200; x&gt;=10]
  --http2-max-frame-size INTEGER RANGE
                                  Sets the maximum frame size to use for HTTP2
                                  [env var: GRANIAN_HTTP2_MAX_FRAME_SIZE;
                                  default: 16384; x&gt;=1024]
  --http2-max-headers-size INTEGER RANGE
                                  Sets the max size of received header frames
                                  [env var: GRANIAN_HTTP2_MAX_HEADERS_SIZE;
                                  default: 16777216; x&gt;=1]
  --http2-max-send-buffer-size INTEGER RANGE
                                  Set the maximum write buffer size for each
                                  HTTP/2 stream  [env var:
                                  GRANIAN_HTTP2_MAX_SEND_BUFFER_SIZE; default:
                                  409600; x&gt;=1024]
  --log / --no-log                Enable logging  [env var:
                                  GRANIAN_LOG_ENABLED; default: (enabled)]
  --log-level [critical|error|warning|warn|info|debug|notset]
                                  Log level  [env var: GRANIAN_LOG_LEVEL;
                                  default: (info)]
  --log-config FILE               Logging configuration file (json)  [env var:
                                  GRANIAN_LOG_CONFIG]
  --access-log / --no-access-log  Enable access log  [env var:
                                  GRANIAN_LOG_ACCESS_ENABLED; default:
                                  (disabled)]
  --access-log-fmt TEXT           Access log format  [env var:
                                  GRANIAN_LOG_ACCESS_FMT]
  --ssl-certificate FILE          SSL certificate file  [env var:
                                  GRANIAN_SSL_CERTIFICATE]
  --ssl-keyfile FILE              SSL key file  [env var: GRANIAN_SSL_KEYFILE]
  --ssl-keyfile-password TEXT     SSL key password  [env var:
                                  GRANIAN_SSL_KEYFILE_PASSWORD]
  --ssl-ca FILE                   Root SSL cerificate file for client
                                  verification  [env var: GRANIAN_SSL_CA]
  --ssl-crl FILE                  SSL CRL file(s)  [env var: GRANIAN_SSL_CRL]
  --ssl-client-verify / --no-ssl-client-verify
                                  Verify clients SSL certificates  [env var:
                                  GRANIAN_SSL_CLIENT_VERIFY; default:
                                  (disabled)]
  --url-path-prefix TEXT          URL path prefix the app is mounted on  [env
                                  var: GRANIAN_URL_PATH_PREFIX]
  --respawn-failed-workers / --no-respawn-failed-workers
                                  Enable workers respawn on unexpected exit
                                  [env var: GRANIAN_RESPAWN_FAILED_WORKERS;
                                  default: (disabled)]
  --respawn-interval FLOAT        The number of seconds to sleep between
                                  workers respawn  [env var:
                                  GRANIAN_RESPAWN_INTERVAL; default: 3.5]
  --workers-lifetime INTEGER RANGE
                                  The maximum amount of time in seconds a
                                  worker will be kept alive before respawn
                                  [env var: GRANIAN_WORKERS_LIFETIME; x&gt;=60]
  --workers-kill-timeout INTEGER RANGE
                                  The amount of time in seconds to wait for
                                  killing workers that refused to gracefully
                                  stop  [env var:
                                  GRANIAN_WORKERS_KILL_TIMEOUT; default:
                                  (disabled); 1&lt;=x&lt;=1800]
  --factory / --no-factory        Treat target as a factory function, that
                                  should be invoked to build the actual target
                                  [env var: GRANIAN_FACTORY; default:
                                  (disabled)]
  --working-dir DIRECTORY         Set the working directory  [env var:
                                  GRANIAN_WORKING_DIR]
  --env-files FILE                Environment file(s) to load (requires
                                  granian[dotenv] extra)  [env var:
                                  GRANIAN_ENV_FILES]
  --static-path-route TEXT        Route for static file serving  [env var:
                                  GRANIAN_STATIC_PATH_ROUTE; default:
                                  (/static)]
  --static-path-mount DIRECTORY   Path to mount for static file serving  [env
                                  var: GRANIAN_STATIC_PATH_MOUNT]
  --static-path-expires INTEGER RANGE
                                  Cache headers expiration (in seconds) for
                                  static file serving  [env var:
                                  GRANIAN_STATIC_PATH_EXPIRES; default: 86400;
                                  x&gt;=60]
  --reload / --no-reload          Enable auto reload on application&#039;s files
                                  changes (requires granian[reload] extra)
                                  [env var: GRANIAN_RELOAD; default:
                                  (disabled)]
  --reload-paths PATH             Paths to watch for changes  [env var:
                                  GRANIAN_RELOAD_PATHS; default: (Working
                                  directory)]
  --reload-ignore-dirs TEXT       Names of directories to ignore changes for.
                                  Extends the default list of directories to
                                  ignore in watchfiles&#039; default filter  [env
                                  var: GRANIAN_RELOAD_IGNORE_DIRS]
  --reload-ignore-patterns TEXT   File/directory name patterns (regex) to
                                  ignore changes for. Extends the default list
                                  of patterns to ignore in watchfiles&#039; default
                                  filter  [env var:
                                  GRANIAN_RELOAD_IGNORE_PATTERNS]
  --reload-ignore-paths PATH      Absolute paths to ignore changes for  [env
                                  var: GRANIAN_RELOAD_IGNORE_PATHS]
  --reload-tick INTEGER RANGE     The tick frequency (in milliseconds) the
                                  reloader watch for changes  [env var:
                                  GRANIAN_RELOAD_TICK; default: 50;
                                  50&lt;=x&lt;=5000]
  --reload-ignore-worker-failure / --no-reload-ignore-worker-failure
                                  Ignore worker failures when auto reload is
                                  enabled  [env var:
                                  GRANIAN_RELOAD_IGNORE_WORKER_FAILURE;
                                  default: (disabled)]
  --process-name TEXT             Set a custom name for processes (requires
                                  granian[pname] extra)  [env var:
                                  GRANIAN_PROCESS_NAME]
  --pid-file FILE                 A path to write the PID file to  [env var:
                                  GRANIAN_PID_FILE]
  --version                       Show the version and exit.
  --help                          Show this message and exit.
```

### Logging

Despite being a Rust project, Granian is a good Python citizen and uses the standard library&#039;s [`logging`](https://docs.python.org/3/library/logging.html) module to produce logs. This means you can freely configure your logging level and format using the [standard idioms](https://docs.python.org/3/howto/logging.html) you probably familiar with.

As many other web servers, Granian uses two different loggers, specifically:

- the `_granian` logger for runtime messages
- the `granian.access` logger for access logs

### Access log format

The access log format can be configured by specifying the atoms (see below) to include in a specific format. By default Granian will use `[%(time)s] %(addr)s - &quot;%(method)s %(path)s %(protocol)s&quot; %(status)d %(dt_ms).3f` as the format.

#### Access log atoms

The following atoms are available for use:

| identifier | description |
| --- | --- |
| addr | Client remote address |
| time | Datetime of the request | 
| dt_ms | Request duration in ms |
| status | HTTP response status |
| path | Request path (without query string) |
| query\_string | Request query string |
| method | Request HTTP method |
| scheme | Request scheme |
| protocol | HTTP protocol version |

### Workers and threads

Granian offers different options to configure the number of workers and threads to be run, in particular:

- **workers**: the total number of processes holding a dedicated Python interpreter that will run the application
- **blocking threads**: the number of threads per worker interacting with the Python interpreter
- **runtime threads**: the number of Rust threads per worker that will perform network I/O
- **runtime blocking threads**: the number of Rust threads per worker involved in blocking operations. The main role of these threads is dealing with blocking I/O – like file system operations.

In general, Granian will try its best to automatically pick proper values for the threading configuration, leaving to you the responsibility to choose the number of workers you need.    
There is no *golden rule* here, as these numbers will vastly depend both on your application behavior and the deployment target, but we can list some suggestions:
- matching the amount of CPU cores for the workers is generally the best starting point; on containerized environments like docker or k8s is best to have 1 worker per container though and scale your containers using the relevant orchestrator;
- the default number of runtime threads and runtime blocking threads is fine for the vast majority of applications out there; you might want to increase the first for applications dealing with several concurrently opened websockets, and lowering the second only if you serve the same few files to a lot of connections;

In regards of blocking threads, the option is irrelevant on asynchronous protocols, as all the interop will happen with the AsyncIO event loop which will also be the one holding the GIL for the vast majority of the time, and thus the value is fixed to a single thread; on synchronous protocols like WSGI instead, it will be the maximum amount of threads interacting – 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[paradedb/paradedb]]></title>
            <link>https://github.com/paradedb/paradedb</link>
            <guid>https://github.com/paradedb/paradedb</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[ParadeDB is a modern Elasticsearch alternative built on Postgres. Built for real-time, update-heavy workloads.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paradedb/paradedb">paradedb/paradedb</a></h1>
            <p>ParadeDB is a modern Elasticsearch alternative built on Postgres. Built for real-time, update-heavy workloads.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,240</p>
            <p>Forks: 248</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://paradedb.com&quot;&gt;&lt;img src=&quot;docs/logo/readme.svg&quot; alt=&quot;ParadeDB&quot;&gt;&lt;/a&gt;
&lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Postgres for Search and Analytics&lt;/b&gt; &lt;br /&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://paradedb.com&quot;&gt;Website&lt;/a&gt; &amp;bull;
  &lt;a href=&quot;https://docs.paradedb.com&quot;&gt;Docs&lt;/a&gt; &amp;bull;
  &lt;a href=&quot;https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw&quot;&gt;Community&lt;/a&gt; &amp;bull;
  &lt;a href=&quot;https://paradedb.com/blog/&quot;&gt;Blog&lt;/a&gt; &amp;bull;
  &lt;a href=&quot;https://docs.paradedb.com/changelog/&quot;&gt;Changelog&lt;/a&gt;
&lt;/h3&gt;

---

[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/paradedb)](https://artifacthub.io/packages/search?repo=paradedb)
[![Docker Pulls](https://img.shields.io/docker/pulls/paradedb/paradedb)](https://hub.docker.com/r/paradedb/paradedb)
[![License](https://img.shields.io/github/license/paradedb/paradedb?color=blue)](https://github.com/paradedb/paradedb?tab=AGPL-3.0-1-ov-file#readme)
[![Slack URL](https://img.shields.io/badge/Join%20Slack-purple?logo=slack&amp;link=https%3A%2F%2Fjoin.slack.com%2Ft%2Fparadedbcommunity%2Fshared_invite%2Fzt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw)](https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw)
[![X URL](https://img.shields.io/twitter/url?url=https%3A%2F%2Ftwitter.com%2Fparadedb&amp;label=Follow%20%40paradedb)](https://x.com/paradedb)

[ParadeDB](https://paradedb.com) is a modern Elasticsearch alternative built on Postgres. Built for real-time, update-heavy workloads.

## Roadmap

- [x] Search
  - [x] Full-text search with BM25 with [pg_search](https://github.com/paradedb/paradedb/tree/dev/pg_search#overview)
  - [x] Dense and sparse vector search with [pgvector](https://github.com/pgvector/pgvector#pgvector)
  - [ ] Distributed search
- [ ] Analytics
  - [x] Faceted search over Postgres data with [pg_search](https://github.com/paradedb/paradedb/tree/dev/pg_search#overview)
  - [ ] Column-oriented Postgres table access method

For a detailed roadmap, see the [ParadeDB Roadmap for 2025](https://github.com/orgs/paradedb/discussions/2041).

## Get Started

To get started, please visit our [documentation](https://docs.paradedb.com).

## Deploying ParadeDB

ParadeDB and its extensions can be deployed in one of two ways:

- Docker image based on [Postgres](https://hub.docker.com/_/postgres) ([see deployment instructions](https://docs.paradedb.com/deploy/aws))
- Kubernetes Helm chart based on [CloudNativePG](https://artifacthub.io/packages/helm/cloudnative-pg/cloudnative-pg) ([see deployment instructions](https://docs.paradedb.com/deploy/helm))

For more information, including enterprise features and support, please [contact us by email](mailto:sales@paradedb.com).

### Extensions

You can find prebuilt binaries for the ParadeDB Postgres extensions on Debian 11, 12, Ubuntu 22.04 and 24.04, Red Hat Enterprise Linux 8 and 9, and macOS 14 (Sonoma) and 15 (Sequoia) for Postgres 14+ in the [GitHub Releases](https://github.com/paradedb/paradedb/releases/latest).

ParadeDB supports all versions supported by the PostgreSQL Global Development Group, which includes PostgreSQL 14+, and you can compile the extensions for other versions of Postgres by following the instructions in the respective extension&#039;s README.

### Docker Image

To quickly get a ParadeDB instance up and running, simply pull and run the latest Docker image:

```bash
docker run --name paradedb -e POSTGRES_PASSWORD=password paradedb/paradedb
```

This will start a ParadeDB instance with default user `postgres` and password `password`. You can then connect to the database using `psql`:

```bash
docker exec -it paradedb psql -U postgres
```

To install ParadeDB locally or on-premise, we recommend using our `docker-compose.yml` file. Alternatively, you can pass the appropriate environment variables to the `docker run` command, replacing the &lt;&gt; with your desired values:

```bash
docker run \
  --name paradedb \
  -e POSTGRES_USER=&lt;user&gt; \
  -e POSTGRES_PASSWORD=&lt;password&gt; \
  -e POSTGRES_DB=&lt;dbname&gt; \
  -v paradedb_data:/var/lib/postgresql/data/ \
  -p 5432:5432 \
  -d \
  paradedb/paradedb:latest
```

This will start a ParadeDB instance with non-root user `&lt;user&gt;` and password `&lt;password&gt;`. The `-v` flag enables your ParadeDB data to persist across restarts in a Docker volume named `paradedb_data`.

You can then connect to the database using `psql`:

```bash
docker exec -it paradedb psql -U &lt;user&gt; -d &lt;dbname&gt; -p 5432 -W
```

### Helm Chart

ParadeDB is also available for Kubernetes via our Helm chart. You can find our Helm chart in the [ParadeDB Helm Chart GitHub repository](https://github.com/paradedb/charts) or download it directly from [Artifact Hub](https://artifacthub.io/packages/helm/paradedb/paradedb).

### ParadeDB Cloud

At the moment, ParadeDB is not available as a managed cloud service. If you are interested in a ParadeDB Cloud service, please let us know by joining our [waitlist](https://form.typeform.com/to/jHkLmIzx).

## Support

If you&#039;re missing a feature or have found a bug, please open a
[GitHub Issue](https://github.com/paradedb/paradedb/issues/new/choose).

To get community support, you can:

- Post a question in the [ParadeDB Slack Community](https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw)
- Ask for help on our [GitHub Discussions](https://github.com/paradedb/paradedb/discussions)

If you need commercial support, please [contact the ParadeDB team](mailto:sales@paradedb.com).

## Contributing

We welcome community contributions, big or small, and are here to guide you along
the way. To get started contributing, check our [first timer issues](https://github.com/paradedb/paradedb/labels/good%20first%20issue)
or message us in the [ParadeDB Community Slack](https://join.slack.com/t/paradedbcommunity/shared_invite/zt-32abtyjg4-yoYoi~RPh9MSW8tDbl0BQw). Once you contribute, ping us in Slack and we&#039;ll send you some ParadeDB swag!

For more information on how to contribute, please see our
[Contributing Guide](/CONTRIBUTING.md).

This project is released with a [Contributor Code of Conduct](/CODE_OF_CONDUCT.md).
By participating in this project, you agree to follow its terms.

Thank you for helping us make ParadeDB better for everyone :heart:.

## License

ParadeDB is licensed under the [GNU Affero General Public License v3.0](LICENSE) and as commercial software. For commercial licensing, please contact us at [sales@paradedb.com](mailto:sales@paradedb.com).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[google/comprehensive-rust]]></title>
            <link>https://github.com/google/comprehensive-rust</link>
            <guid>https://github.com/google/comprehensive-rust</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[This is the Rust course used by the Android team at Google. It provides you the material to quickly teach Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google/comprehensive-rust">google/comprehensive-rust</a></h1>
            <p>This is the Rust course used by the Android team at Google. It provides you the material to quickly teach Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 30,305</p>
            <p>Forks: 1,809</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre># Comprehensive Rust 🦀

[![Build workflow](https://img.shields.io/github/actions/workflow/status/google/comprehensive-rust/build.yml?style=flat-square)](https://github.com/google/comprehensive-rust/actions/workflows/build.yml?query=branch%3Amain)
[![GitHub contributors](https://img.shields.io/github/contributors/google/comprehensive-rust?style=flat-square)](https://github.com/google/comprehensive-rust/graphs/contributors)
[![GitHub stars](https://img.shields.io/github/stars/google/comprehensive-rust?style=flat-square)](https://github.com/google/comprehensive-rust/stargazers)

This repository has the source code for Comprehensive Rust 🦀, a multi-day Rust
course developed by the Android team. The course covers all aspects of Rust,
from basic syntax to generics and error handling. It also includes deep dives on
[Android], [Chromium], [bare-metal], and [concurrency].

[Android]: https://google.github.io/comprehensive-rust/android.html
[Chromium]: https://google.github.io/comprehensive-rust/chromium.html
[bare-metal]: https://google.github.io/comprehensive-rust/bare-metal.html
[concurrency]: https://google.github.io/comprehensive-rust/concurrency.html

Read the course at **https://google.github.io/comprehensive-rust/**.

## Course Format and Target Audience

The course is used internally at Google when teaching Rust to experienced
software engineers. They typically have a background in C++ or Java.

The course is taught in a classroom setting and we hope it will be useful for
others who want to teach Rust to their team. The course will be less useful for
self-study since you miss out on the discussions happening in the classroom. You
don&#039;t see the questions and answers and you don&#039;t see the compiler errors we
trigger when going through the code samples. We hope to improve on this via
[speaker notes](https://github.com/google/comprehensive-rust/issues/53) and by
[publishing videos](https://github.com/google/comprehensive-rust/issues/52).

## Press

Articles and blog posts from around the web which cover Comprehensive Rust:

- 2023-09-08:
  _[Teaching Rust in 5 days](https://mo8it.com/blog/teaching-rust/)_.
  Comprehensive Rust was used as a base for a 5-day university class on Rust.
- 2023-09-21:
  _[Scaling Rust Adoption Through Training](https://security.googleblog.com/2023/09/scaling-rust-adoption-through-training.html)_.
  We published a blog post with details on the development of the course.
- 2023-10-02:
  _[In Search of Rust Developers, Companies Turn to In-House Training](https://www.darkreading.com/application-security/google-microsoft-take-refuge-in-rust-languages-better-security)_.
  About how Microsoft, Google, and others are training people in Rust.
- 2024-10-18:
  _[Rust Training at Scale | Rust Global @ RustConf 2024](https://youtu.be/7h5KyMqt2-Q?si=4M99HdWWxMaqN8Zr)_.
  What Google learnt from teaching Comprehensive Rust for more than two years.

## Setup

The course is built using a few tools:

- [mdbook](https://github.com/rust-lang/mdBook)
- [mdbook-svgbob](https://github.com/boozook/mdbook-svgbob)
- [mdbook-i18n-helpers and i18n-report](https://github.com/google/mdbook-i18n-helpers)
- [mdbook-exerciser](mdbook-exerciser/)
- [mdbook-course](mdbook-course/)
- [mdbook-linkcheck2](https://github.com/marxin/mdbook-linkcheck2)

First install Rust by following the instructions on https://rustup.rs/. Then
clone this repository:

```shell
git clone https://github.com/google/comprehensive-rust/
cd comprehensive-rust
```

Then install these tools with:

```shell
cargo xtask install-tools
```

## Commands

Here is a summary of the various commands you can run in the project.

| Command                     | Description                                                                                                                                                                                                                                                                                                                                                                                                   |
| --------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `cargo xtask install-tools` | Install all the tools the project depends on.                                                                                                                                                                                                                                                                                                                                                                 |
| `cargo xtask serve`         | Start a web server with the course. You&#039;ll find the content on http://localhost:3000.                                                                                                                                                                                                                                                                                                                         |
| `cargo xtask rust-tests`    | Test the included Rust snippets.                                                                                                                                                                                                                                                                                                                                                                              |
| `cargo xtask web-tests`     | Run the web driver tests in the tests directory.                                                                                                                                                                                                                                                                                                                                                              |
| `cargo xtask build`         | Create a static version of the course in the `book/` directory. Note that you have to separately build and zip exercises and add them to book/html. To build any of the translated versions of the course, run MDBOOK_BOOK__LANGUAGE=xx mdbook build -d book/xx where xx is the ISO 639 language code (e.g. da for the Danish translation). [TRANSLATIONS.md](TRANSLATIONS.md) contains further instructions. |

&gt; **Note** On Windows, you need to enable symlinks
&gt; (`git config --global core.symlinks true`) and Developer Mode.

## Contributing

We would like to receive your contributions. Please see
[CONTRIBUTING.md](CONTRIBUTING.md) for details.

## Contact

For questions or comments, please contact
[Martin Geisler](mailto:mgeisler@google.com) or start a
[discussion on GitHub](https://github.com/google/comprehensive-rust/discussions).
We would love to hear from you.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[clap-rs/clap]]></title>
            <link>https://github.com/clap-rs/clap</link>
            <guid>https://github.com/clap-rs/clap</guid>
            <pubDate>Thu, 03 Jul 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[A full featured, fast Command Line Argument Parser for Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/clap-rs/clap">clap-rs/clap</a></h1>
            <p>A full featured, fast Command Line Argument Parser for Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 15,233</p>
            <p>Forks: 1,112</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># clap

&gt; **Command Line Argument Parser for Rust**

[![Crates.io](https://img.shields.io/crates/v/clap?style=flat-square)](https://crates.io/crates/clap)
[![Crates.io](https://img.shields.io/crates/d/clap?style=flat-square)](https://crates.io/crates/clap)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square)](LICENSE-APACHE)
[![License](https://img.shields.io/badge/license-MIT-blue?style=flat-square)](LICENSE-MIT)
[![Build Status](https://img.shields.io/github/actions/workflow/status/clap-rs/clap/ci.yml?branch=master&amp;style=flat-square)](https://github.com/clap-rs/clap/actions/workflows/ci.yml?query=branch%3Amaster)
[![Coverage Status](https://img.shields.io/coveralls/github/clap-rs/clap/master?style=flat-square)](https://coveralls.io/github/clap-rs/clap?branch=master)
[![Contributors](https://img.shields.io/github/contributors/clap-rs/clap?style=flat-square)](https://github.com/clap-rs/clap/graphs/contributors)

Dual-licensed under [Apache 2.0](LICENSE-APACHE) or [MIT](LICENSE-MIT).

## About

Create your command-line parser, with all of the bells and whistles, declaratively or procedurally.

For more details, see:
- [docs.rs](https://docs.rs/clap/latest/clap/)
- [examples](examples/)

## Sponsors

&lt;!-- omit in TOC --&gt;
### Gold

[![](https://opencollective.com/clap/tiers/gold.svg?avatarHeight=36&amp;width=600)](https://opencollective.com/clap)

&lt;!-- omit in TOC --&gt;
### Silver

[![](https://opencollective.com/clap/tiers/silver.svg?avatarHeight=36&amp;width=600)](https://opencollective.com/clap)

&lt;!-- omit in TOC --&gt;
### Bronze

[![](https://opencollective.com/clap/tiers/bronze.svg?avatarHeight=36&amp;width=600)](https://opencollective.com/clap)

&lt;!-- omit in TOC --&gt;
### Backer

[![](https://opencollective.com/clap/tiers/backer.svg?avatarHeight=36&amp;width=600)](https://opencollective.com/clap)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>