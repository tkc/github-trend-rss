<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Sat, 23 Aug 2025 00:05:16 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[zama-ai/fhevm]]></title>
            <link>https://github.com/zama-ai/fhevm</link>
            <guid>https://github.com/zama-ai/fhevm</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zama-ai/fhevm">zama-ai/fhevm</a></h1>
            <p>FHEVM, a full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications</p>
            <p>Language: Rust</p>
            <p>Stars: 16,439</p>
            <p>Forks: 647</p>
            <p>Stars today: 55 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/.gitbook/assets/fhevm-header-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/.gitbook/assets/fhevm-header-light.png&quot;&gt;
  &lt;img width=500 alt=&quot;fhevm&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;

&lt;hr/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;fhevm-whitepaper.pdf&quot;&gt; 📃 Read white paper&lt;/a&gt; |&lt;a href=&quot;https://docs.zama.ai/protocol&quot;&gt; 📒 Documentation&lt;/a&gt; | &lt;a href=&quot;https://zama.ai/community&quot;&gt; 💛 Community support&lt;/a&gt; | &lt;a href=&quot;https://github.com/zama-ai/awesome-zama&quot;&gt; 📚 FHE resources by Zama&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/zama-ai/fhevm/releases&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/v/release/zama-ai/fhevm?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/zama-ai/fhevm/blob/main/LICENSE&quot;&gt;
    &lt;!-- markdown-link-check-disable-next-line --&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-BSD--3--Clause--Clear-%23ffb243?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/zama-ai/bounty-program&quot;&gt;
    &lt;!-- markdown-link-check-disable-next-line --&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Contribute-Zama%20Bounty%20Program-%23ffd208?style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://slsa.dev&quot;&gt;&lt;img alt=&quot;SLSA 3&quot; src=&quot;https://slsa.dev/images/gh-badge-level3.svg&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;


## About

### What is FHEVM?

**FHEVM** is the core framework of the *Zama Confidential Blockchain Protocol*. It enables confidential smart contracts on EVM-compatible blockchains by leveraging Fully Homomorphic Encryption (FHE), allowing encrypted data to be processed directly onchain.

FHEVM ensures both confidentiality and composability, with the following guarantees:
- **End-to-end encryption of transactions and state:** Data included in transactions is encrypted and never visible to anyone.
- **Composability and data availability on-chain:** States are updated while remaining encrypted at all times.
- **No impact on existing dApps and state:** Encrypted state co-exists alongside public one, and doesn&#039;t impact existing dApps.
&lt;br&gt;&lt;/br&gt;

### Table of contents

- [About](#about)
  - [What is FHEVM?](#what-is-fhevm)
  - [Project structure](#project-structure)
  - [Main features](#main-features)
  - [Use cases](#use-cases)
- [Resources](#resources)
- [Working with FHEVM](#working-with-fhevm)
  - [Citations](#citations)
  - [Contributing](#contributing)
  - [License](#license)
  - [FAQ](#faq)
- [Support](#support)
  &lt;br&gt;&lt;/br&gt;
### Project structure
The directories of this repository are organized in the following way:

###### FHEVM Contracts

- **`gateway-contracts/`**: Smart contracts managing the gateway between on-chain and off-chain components.

- **`host-contracts/`**: Smart Contracts deployed on the host chain for orchestrating FHE workflows.

###### FHEVM Compute Engines

- **`coprocessor/`**: Rust-based coprocessor implementation for FHE operations.

- **`kms-connector/`**: Interface for integrating with Key Management Services (KMS) to handle encryption keys securely.

###### FHEVM Utilities
- **`charts/`**: Helm charts and deployment configurations for the stack.

- **`golden-container-images/`**: Docker golden images for Node.js and Rust environments used as base images by the stack.

- **`test-suite/`**: Integration with docker-compose and tests covering end-to-end FHEVM stack behavior.



  &lt;br&gt;&lt;/br&gt;
### Main features

- **Privacy by design:** Building decentralized apps with full privacy and confidentiality on Ethereum, leveraging FHE.
- **Solidity integration:** Write FHEVM contracts like any standard Solidity contract using Solidity. Compatible with existing toolchains — such as Hardhat and Foundry (*coming soon*).
- **Programmable privacy:**  Define exactly what data is encrypted and write the access control logic directly in your smart contracts.
- **High precision encrypted integers :** Up to 256 bits of precision for integers.
- **Full range of operators:** All typical operators are available: `+`, `-`, `*`, `/`, `&lt;`, `&gt;`, `==`, ternary-if, boolean operations…. Consecutive FHE operations are not limited.
- **Security:** The underlying FHE crypto-scheme of FHEVM is quantum-resistant. Decryption is managed via a key management system (KMS) using multi-party computation (MPC), ensuring security even if some parties are compromised or misbehaving.
- **Symbolic execution of FHE computations:** All FHE operations are executed symbolically on the host chain, significantly reducing execution time. The actual computations on encrypted data are offloaded asynchronously to our coprocessor, allowing for faster, efficient, and scalable processing.

_Learn more about FHEVM features in the [documentation](https://docs.zama.ai/protocol) and in our [whitepaper](https://github.com/zama-ai/fhevm/blob/main/fhevm-whitepaper.pdf)._
&lt;br&gt;&lt;/br&gt;

### Use cases

FHEVM is built for developers to write confidential smart contracts without the need to learn cryptography. Leveraging FHEVM, you can unlock a myriad of new use cases such as DeFi, gaming, and more. For instance:

- **Confidential transfers**: Keep balances and amounts private, without using mixers.
- **Tokenization**: Swap tokens and RWAs on-chain without others seeing the amounts.
- **Blind auctions**: Bid on items without revealing the amount or the winner.
- **On-chain games**: Keep moves, selections, cards, or items hidden until ready to reveal.
- **Confidential voting**: Prevents bribery and blackmailing by keeping votes private.
- **Encrypted DIDs**: Store identities on-chain and generate attestations without ZK.

_Learn more use cases in the [list of examples](https://docs.zama.ai/protocol/examples)._
&lt;br&gt;&lt;/br&gt;


## Resources
- [Documentation](https://docs.zama.ai/protocol) — Official documentation of FHEVM.
- [Whitepaper](./fhevm-whitepaper.pdf) — Technical overview of FHEVM&#039;s cryptographic design.
- [Examples](https://docs.zama.ai/protocol/examples) — Examples of building confidential smart contracts.
- [Awesome Zama – FHEVM](https://github.com/zama-ai/awesome-zama?tab=readme-ov-file#fhevm) — Curated articles, talks, and ecosystem projects.

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#about&quot; &gt; ↑ Back to top &lt;/a&gt;
&lt;/p&gt;

## Working with FHEVM
### Citations

To cite FHEVM or the whitepaper in academic papers, please use the following entries:

```text
@Misc{FHEVM,
title={{FHEVM: A full-stack framework for integrating Fully Homomorphic Encryption (FHE) with blockchain applications},
author={Zama},
year={2025},
note={\url{https://github.com/zama-ai/fhevm}},
}
```

### Contributing

There are two ways to contribute to FHEVM:

- [Open issues](https://github.com/zama-ai/fhevm/issues/new/choose) to report bugs and typos, or to suggest new ideas
- Request to become an official contributor by emailing hello@zama.ai.

Becoming an approved contributor involves signing our Contributor License Agreement (CLA). Only approved contributors can send pull requests, so please make sure to get in touch before you do!
&lt;br&gt;&lt;/br&gt;

### License

This software is distributed under the **BSD-3-Clause-Clear** license. Read [this](LICENSE) for more details.

### FAQ

**Is Zama’s technology free to use?**

&gt; Zama’s libraries are free to use under the BSD 3-Clause Clear license only for development, research, prototyping, and experimentation purposes. However, for any commercial use of Zama&#039;s open source code, companies must purchase Zama’s commercial patent license.
&gt;
&gt; Everything we do is open source, and we are very transparent on what it means for our users, you can read more about how we monetize our open source products at Zama in [this blog post](https://www.zama.ai/post/open-source).

**What do I need to do if I want to use Zama’s technology for commercial purposes?**

&gt; To commercially use Zama’s technology you need to be granted Zama’s patent license. Please contact us at hello@zama.ai for more information.

**Do you file IP on your technology?**

&gt; Yes, all Zama’s technologies are patented.

**Can you customize a solution for my specific use case?**

&gt; We are open to collaborating and advancing the FHE space with our partners. If you have specific needs, please email us at hello@zama.ai.

## Support

&lt;a target=&quot;_blank&quot; href=&quot;https://community.zama.ai&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/.gitbook/assets/support-banner-dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/.gitbook/assets/support-banner-light.png&quot;&gt;
  &lt;img alt=&quot;Support&quot;&gt;
&lt;/picture&gt;
&lt;/a&gt;

🌟 If you find this project helpful or interesting, please consider giving it a star on GitHub! Your support helps to grow the community and motivates further development.

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#about&quot; &gt; ↑ Back to top &lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gorules/zen]]></title>
            <link>https://github.com/gorules/zen</link>
            <guid>https://github.com/gorules/zen</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Open-source Business Rules Engine for your Rust, NodeJS, Python, Go, Kotlin (JVM) and Java applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gorules/zen">gorules/zen</a></h1>
            <p>Open-source Business Rules Engine for your Rust, NodeJS, Python, Go, Kotlin (JVM) and Java applications.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,321</p>
            <p>Forks: 135</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

# Business Rules Engine

ZEN Engine is a cross-platform, Open-Source Business Rules Engine (BRE). It is written in **Rust** and provides native
bindings for **NodeJS**, **Python** and **Go**. ZEN Engine allows to load and
execute [JSON Decision Model (JDM)](https://docs.gorules.io/reference/json-decision-model-jdm) from JSON files.

&lt;img width=&quot;800&quot; alt=&quot;Open-Source Rules Engine&quot; src=&quot;https://gorules.io/images/jdm-editor.gif&quot;&gt;

An open-source React editor is available on our [JDM Editor](https://github.com/gorules/jdm-editor) repo.

## Usage

ZEN Engine is built as embeddable BRE for your **Rust**, **NodeJS**, **Python** or **Go** applications.
It parses JDM from JSON content. It is up to you to obtain the JSON content, e.g. from file system, database or service
call.

### Supported Platforms

List of platforms where Zen Engine is natively available:

* **NodeJS** - [GitHub](https://github.com/gorules/zen/blob/master/bindings/nodejs/README.md) | [Documentation](https://gorules.io/docs/developers/bre/engines/nodejs) | [npmjs](https://www.npmjs.com/package/@gorules/zen-engine)
* **Python** - [GitHub](https://github.com/gorules/zen/blob/master/bindings/python/README.md) | [Documentation](https://gorules.io/docs/developers/bre/engines/python) | [pypi](https://pypi.org/project/zen-engine/)
* **Go** - [GitHub](https://github.com/gorules/zen-go) | [Documentation](https://gorules.io/docs/developers/bre/engines/go)
* **Rust (Core)** - [GitHub](https://github.com/gorules/zen) | [Documentation](https://gorules.io/docs/developers/bre/engines/rust) | [crates.io](https://crates.io/crates/zen-engine)

For a complete **Business Rules Management Systems (BRMS)** solution:

* [Self-hosted BRMS](https://gorules.io)
* [GoRules Cloud BRMS](https://gorules.io/signin/verify-email)

### Rust

```toml
[dependencies]
zen-engine = &quot;0&quot;
```

```rust
use serde_json::json;
use zen_engine::DecisionEngine;
use zen_engine::model::DecisionContent;

async fn evaluate() {
    let decision_content: DecisionContent = serde_json::from_str(include_str!(&quot;jdm_graph.json&quot;)).unwrap();
    let engine = DecisionEngine::default();
    let decision = engine.create_decision(decision_content.into());

    let result = decision.evaluate(&amp;json!({ &quot;input&quot;: 12 })).await;
}
```

For more advanced use cases visit [Rust Docs](https://gorules.io/docs/developers/bre/engines/rust).

## JSON Decision Model (JDM)

GoRules JDM (JSON Decision Model) is a modeling framework designed to streamline the representation and implementation
of decision models.

#### Understanding GoRules JDM

At its core, GoRules JDM revolves around the concept of decision models as interconnected graphs stored in JSON format.
These graphs capture the intricate relationships between various decision points, conditions, and outcomes in a GoRules
Zen-Engine.

Graphs are made by linking nodes with edges, which act like pathways for moving information from one node to another,
usually from the left to the right.

The Input node serves as an entry for all data relevant to the context, while the Output nodes produce the result of
decision-making process. The progression of data follows a path from the Input Node to the Output Node, traversing all
interconnected nodes in between. As the data flows through this network, it undergoes evaluation at each node, and
connections determine where the data is passed along the graph.

To see JDM Graph in action you can use [Free Online Editor](https://editor.gorules.io) with built in Simulator.

There are 5 main node types in addition to a graph Input Node (Request) and Output Node (Response):

* Decision Table Node
* Switch Node
* Function Node
* Expression Node
* Decision Node

### Decision Table Node

#### Overview

Tables provide a structured representation of decision-making processes, allowing developers and business users to
express complex rules in a clear and concise manner.

&lt;img width=&quot;960&quot; alt=&quot;Decision Table&quot; src=&quot;https://gorules.io/images/decision-table.png&quot;&gt;

#### Structure

At the core of the Decision Table is its schema, defining the structure with inputs and outputs. Inputs encompass
business-friendly expressions using the ZEN Expression Language, accommodating a range of conditions such as equality,
numeric comparisons, boolean values, date time functions, array functions and more. The schema&#039;s outputs dictate the
form of results generated by the Decision Table.
Inputs and outputs are expressed through a user-friendly interface, often resembling a spreadsheet. This facilitates
easy modification and addition of rules, enabling business users to contribute to decision logic without delving into
intricate code.

#### Evaluation Process

Decision Tables are evaluated row by row, from top to bottom, adhering to a specified hit policy.
Single row is evaluated via Inputs columns, from left to right. Each input column represents `AND` operator. If cell is
empty that column is evaluated **truthfully**, independently of the value.

If a single cell within a row fails (due to error, or otherwise), the row is skipped.

**HitPolicy**

The hit policy determines the outcome calculation based on matching rules.

The result of the evaluation is:

* **an object** if the hit policy of the decision table is `first` and a rule matched. The structure is defined by the
  output fields. Qualified field names with a dot (.) inside lead to nested objects.
* **`null`/`undefined`** if no rule matched in `first` hit policy
* **an array of objects** if the hit policy of the decision table is `collect` (one array item for each matching rule)
  or empty array if no rules match

#### Inputs

In the assessment of rules or rows, input columns embody the `AND` operator. The values typically consist of (qualified)
names, such as `customer.country` or `customer.age`.

There are two types of evaluation of inputs, `Unary` and `Expression`.

**Unary Evaluation**

Unary evaluation is usually used when we would like to compare single fields from incoming context separately, for
example `customer.country` and `cart.total` . It is activated when a column has `field` defined in its schema.

***Example***

For the input:

```json
{
  &quot;customer&quot;: {
    &quot;country&quot;: &quot;US&quot;
  },
  &quot;cart&quot;: {
    &quot;total&quot;: 1500
  }
}
```

&lt;img width=&quot;960&quot; alt=&quot;Decision Table Unary Test&quot; src=&quot;https://gorules.io/images/decision-table.png&quot;&gt;

This evaluation translates to

```
IF customer.country == &#039;US&#039; AND cart.total &gt; 1000 THEN {&quot;fees&quot;: {&quot;percent&quot;: 2}}
ELSE IF customer.country == &#039;US&#039; THEN {&quot;fees&quot;: {&quot;flat&quot;: 30}}
ELSE IF customer.country == &#039;CA&#039; OR customer.country == &#039;MX&#039; THEN {&quot;fees&quot;: {&quot;flat&quot;: 50}}
ELSE {&quot;fees&quot;: {&quot;flat&quot;: 150}}
```

List shows basic example of the unary tests in the Input Fields:

| Input entry | Input Expression                               |
|-------------|------------------------------------------------|
| &quot;A&quot;         | the field equals &quot;A&quot;                           |
| &quot;A&quot;, &quot;B&quot;    | the field is either &quot;A&quot; or &quot;B&quot;                 |
| 36          | the numeric value equals 36                    |
| &lt; 36        | a value less than 36                           |
| &gt; 36        | a value greater than 36                        |
| [20..39]    | a value between 20 and 39 (inclusive)          |
| 20,39       | a value either 20 or 39                        |
| &lt;20, &gt;39    | a value either less than 20 or greater than 39 |
| true        | the boolean value true                         |
| false       | the boolean value false                        |
|             | any value, even null/undefined                 |
| null        | the value null or undefined                    |

Note: For the full list please
visit [ZEN Expression Language](https://gorules.io/docs/rules-engine/expression-language/).

**Expression Evaluation**

Expression evaluation is used when we would like to create more complex evaluation logic inside single cell. It allows
us to compare multiple fields from the incoming context inside same cell.

It can be used by providing an empty `Selector (field)` inside column configuration.

***Example***

For the input:

```json
{
  &quot;transaction&quot;: {
    &quot;country&quot;: &quot;US&quot;,
    &quot;createdAt&quot;: &quot;2023-11-20T19:00:25Z&quot;,
    &quot;amount&quot;: 10000
  }
}
```

&lt;img width=&quot;960&quot; alt=&quot;Decision Table Expression&quot; src=&quot;https://gorules.io/images/decision-table-expression.png&quot;&gt;

```
IF time(transaction.createdAt) &gt; time(&quot;17:00:00&quot;) AND transaction.amount &gt; 1000 THEN {&quot;status&quot;: &quot;reject&quot;}
ELSE {&quot;status&quot;: &quot;approve&quot;}
```

Note: For the full list please
visit [ZEN Expression Language](https://gorules.io/docs/rules-engine/expression-language/).

**Outputs**

Output columns serve as the blueprint for the data that the decision table will generate when the conditions are met
during evaluation.

When a row in the decision table satisfies its specified conditions, the output columns determine the nature and
structure of the information that will be returned. Each output column represents a distinct field, and the collective
set of these fields forms the output or result associated with the validated row. This mechanism allows decision tables
to precisely define and control the data output.

***Example***

&lt;img width=&quot;860&quot; alt=&quot;Decision Table Output&quot; src=&quot;https://gorules.io/images/decision-table-output.png&quot;&gt;

And the result would be:

```json
{
  &quot;flatProperty&quot;: &quot;A&quot;,
  &quot;output&quot;: {
    &quot;nested&quot;: {
      &quot;property&quot;: &quot;B&quot;
    },
    &quot;property&quot;: 36
  }
}
```

### Switch Node (NEW)

The Switch node in GoRules JDM introduces a dynamic branching mechanism to decision models, enabling the graph to
diverge based on conditions.

Conditions are written in a Zen Expression Language.

By incorporating the Switch node, decision models become more flexible and context-aware. This capability is
particularly valuable in scenarios where diverse decision logic is required based on varying inputs. The Switch node
efficiently manages branching within the graph, enhancing the overall complexity and realism of decision models in
GoRules JDM, making it a pivotal component for crafting intelligent and adaptive systems.

The Switch node preserves the incoming data without modification; it forwards the entire context to the output branch(
es).

&lt;img width=&quot;960&quot; alt=&quot;Switch / Branching&quot; src=&quot;https://gorules.io/images/decision-graph.png&quot;&gt;

#### HitPolicy

There are two HitPolicy options for the switch node, `first` and `collect`.

In the context of a first hit policy, the graph branches to the initial matching condition, analogous to the behavior
observed in a table. Conversely, under a collect hit policy, the graph extends to all branches where conditions hold
true, allowing branching to multiple paths.

Note: If there are multiple edges from the same condition, there is no guaranteed order of execution.

*Available from:*

* Python 0.16.0
* NodeJS 0.13.0
* Rust 0.16.0
* Go 0.1.0

### Functions Node

Function nodes are JavaScript snippets that allow for quick and easy parsing, re-mapping or otherwise modifying the data
using JavaScript. Inputs of the node are provided as function&#039;s arguments. Functions are executed on top of QuickJS
Engine that is bundled into the ZEN Engine.

Function timeout is set to a 50ms.

```js
const handler = (input, {dayjs, Big}) =&gt; {
    return {
        ...input,
        someField: &#039;hello&#039;
    };
};
```

There are two built in libraries:

* [dayjs](https://www.npmjs.com/package/dayjs) - for Date Manipulation
* [big.js](https://www.npmjs.com/package/big.js) - for arbitrary-precision decimal arithmetic.

### Expression Node

The Expression node serves as a tool for transforming input objects into alternative objects using the Zen Expression
Language. When specifying the output properties, each property requires a separate row. These rows are defined by two
fields:

- Key - qualified name of the output property
- Value - value expressed through the Zen Expression Language

Note: Any errors within the Expression node will bring the graph to a halt.

&lt;img width=&quot;960&quot; alt=&quot;Decision Table&quot; src=&quot;https://gorules.io/images/expression.png&quot;&gt;

### Decision Node

The &quot;Decision&quot; node is designed to extend the capabilities of decision models. Its function is to invoke and reuse other
decision models during execution.

By incorporating the &quot;Decision&quot; node, developers can modularize decision logic, promoting reusability and
maintainability in complex systems.

## Support matrix

| Arch            | Rust               | NodeJS             | Python             | Go                 |
|:----------------|:-------------------|:-------------------|:-------------------|:-------------------|
| linux-x64-gnu   | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |
| linux-arm64-gnu | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |
| darwin-x64      | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |
| darwin-arm64    | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |
| win32-x64-msvc  | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: | :heavy_check_mark: |
| linux-x64-musl  | :x:                | :heavy_check_mark: | :x:                | :x:                |
| linux-arm64-musl| :x:                | :heavy_check_mark: | :x:                | :x:                |

## Contribution

JDM standard is growing and we need to keep tight control over its development and roadmap as there are number of
companies that are using GoRules Zen-Engine and GoRules BRMS.
For this reason we can&#039;t accept any code contributions at this moment, apart from help with documentation and additional
tests.

## License

[MIT License]()
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[0xPlaygrounds/rig]]></title>
            <link>https://github.com/0xPlaygrounds/rig</link>
            <guid>https://github.com/0xPlaygrounds/rig</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[⚙️🦀 Build modular and scalable LLM Applications in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/0xPlaygrounds/rig">0xPlaygrounds/rig</a></h1>
            <p>⚙️🦀 Build modular and scalable LLM Applications in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 4,240</p>
            <p>Forks: 455</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;img/rig-playgrounds-dark.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;img/rig-playgrounds-light.svg&quot;&gt;
    &lt;img src=&quot;img/rig-playgrounds-light.svg&quot; style=&quot;width: 40%; height: 40%;&quot; alt=&quot;Rig logo&quot;&gt;
&lt;/picture&gt;
&lt;br&gt;
&lt;a href=&quot;https://docs.rig.rs&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/📖 docs-rig.rs-dca282.svg&quot; /&gt;&lt;/a&gt; &amp;nbsp;
&lt;a href=&quot;https://docs.rs/rig-core/latest/rig/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-API Reference-dca282.svg&quot; /&gt;&lt;/a&gt; &amp;nbsp;
&lt;a href=&quot;https://crates.io/crates/rig-core&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/v/rig-core.svg?color=dca282&quot; /&gt;&lt;/a&gt;
&amp;nbsp;
&lt;a href=&quot;https://crates.io/crates/rig-core&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/d/rig-core.svg?color=dca282&quot; /&gt;&lt;/a&gt;
&lt;/br&gt;
&lt;a href=&quot;https://discord.gg/playgrounds&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/511303648119226382?color=%236d82cc&amp;label=Discord&amp;logo=discord&amp;logoColor=white&quot; /&gt;&lt;/a&gt;
&amp;nbsp;
&lt;a href=&quot;https://github.com/0xPlaygrounds/rig&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/0xPlaygrounds/rig?style=social&quot; alt=&quot;stars - rig&quot; /&gt;&lt;/a&gt;
&lt;br&gt;
&lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/built_with-Rust-dca282.svg?logo=rust&quot; /&gt;&lt;/a&gt;
&amp;nbsp;
&lt;a href=&quot;https://twitter.com/Playgrounds0x&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/Playgrounds0x&quot;&gt;&lt;/a&gt; &amp;nbsp

&lt;br&gt;
&lt;/p&gt;
&amp;nbsp;


&lt;div align=&quot;center&quot;&gt;

[📑 Docs](https://docs.rig.rs)
&lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
[🌐 Website](https://rig.rs)
&lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
[🤝 Contribute](https://github.com/0xPlaygrounds/rig/issues/new)
&lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
[✍🏽 Blogs](https://docs.rig.rs/guides)

&lt;/div&gt;

✨ If you would like to help spread the word about Rig, please consider starring the repo!

&gt; [!WARNING]
&gt; Here be dragons! As we plan to ship a torrent of features in the following months, future updates **will** contain **breaking changes**. With Rig evolving, we&#039;ll annotate changes and highlight migration paths as we encounter them.

## Table of contents

- [Table of contents](#table-of-contents)
- [What is Rig?](#what-is-rig)
- [High-level features](#high-level-features)
- [Who&#039;s using Rig in production?](#who-is-using-rig-in-production)
- [Get Started](#get-started)
  - [Simple example:](#simple-example)
- [Integrations](#integrations)

## What is Rig?
Rig is a Rust library for building scalable, modular, and ergonomic **LLM-powered** applications.

More information about this crate can be found in the [official](https://docs.rig.rs) &amp; [crate](https://docs.rs/rig-core/latest/rig/) (API Reference) documentations.

## High-level features
- Full support for LLM completion and embedding workflows
- Simple but powerful common abstractions over LLM providers (e.g. OpenAI, Cohere) and vector stores (e.g. MongoDB, SQlite, in-memory)
- Integrate LLMs in your app with minimal boilerplate

## Who is using Rig in production?
Below is a non-exhaustive list of companies and people who are using Rig in production:
- [Dria Compute Node](https://github.com/firstbatchxyz/dkn-compute-node) - a node that serves computation results within the Dria Knowledge Network
- [The MCP Rust SDK](https://github.com/modelcontextprotocol/rust-sdk ) - the official Model Context Protocol Rust SDK. Has an example for usage with Rig.
- [Probe](https://github.com/buger/probe) - an AI-friendly, fully local semantic code search tool.
- [NINE](https://github.com/NethermindEth/nine) - Neural Interconnected Nodes Engine, by [Nethermind.](https://www.nethermind.io/)
- [rig-onchain-kit](https://github.com/0xPlaygrounds/rig-onchain-kit) - the Rig Onchain Kit. Intended to make interactions between Solana/EVM and Rig much easier to implement.
- [Linera Protocol](https://github.com/linera-io/linera-protocol) - Decentralized blockchain infrastructure designed for highly scalable, secure, low-latency Web3 applications.
- [Listen](https://github.com/piotrostr/listen) - A framework aiming to become the go-to framework for AI portfolio management agents. Powers [the Listen app.](https://app.listen-rs.com/)

Are you also using Rig in production? [Open an issue](https://www.github.com/0xPlaygrounds/rig/issues) to have your name added!

## Get Started
```bash
cargo add rig-core
```

### Simple example:
```rust
use rig::{completion::Prompt, providers::openai};

#[tokio::main]
async fn main() {
    // Create OpenAI client and model
    // This requires the `OPENAI_API_KEY` environment variable to be set.
    let openai_client = openai::Client::from_env();

    let gpt4 = openai_client.agent(&quot;gpt-4&quot;).build();

    // Prompt the model and print its response
    let response = gpt4
        .prompt(&quot;Who are you?&quot;)
        .await
        .expect(&quot;Failed to prompt GPT-4&quot;);

    println!(&quot;GPT-4: {response}&quot;);
}
```
Note using `#[tokio::main]` requires you enable tokio&#039;s `macros` and `rt-multi-thread` features
or just `full` to enable all features (`cargo add tokio --features macros,rt-multi-thread`).

You can find more examples each crate&#039;s `examples` (ie. [`rig-core/examples`](./rig-core/examples)) directory. More detailed use cases walkthroughs are regularly published on our [Dev.to Blog](https://dev.to/0thtachi) and added to Rig&#039;s official documentation [(docs.rig.rs)](http://docs.rig.rs).

## Supported Integrations

Vector stores are available as separate companion-crates:
- MongoDB: [`rig-mongodb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-mongodb)
- LanceDB: [`rig-lancedb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-lancedb)
- Neo4j: [`rig-neo4j`](https://github.com/0xPlaygrounds/rig/tree/main/rig-neo4j)
- Qdrant: [`rig-qdrant`](https://github.com/0xPlaygrounds/rig/tree/main/rig-qdrant)
- SQLite: [`rig-sqlite`](https://github.com/0xPlaygrounds/rig/tree/main/rig-sqlite)
- SurrealDB: [`rig-surrealdb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-surrealdb)
- Milvus: [`rig-milvus`](https://github.com/0xPlaygrounds/rig/tree/main/rig-milvus)
- ScyllaDB: [`rig-scylladb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-scylladb)
- AWS S3Vectors: [`rig-s3vectors`](https://github.com/0xPlaygrounds/rig/tree/main/rig-s3vectors)

The following providers are available as separate companion-crates:
- Fastembed: [`rig-fastembed`](https://github.com/0xPlaygrounds/rig/tree/main/rig-fastembed)
- Eternal AI: [`rig-eternalai`](https://github.com/0xPlaygrounds/rig/tree/main/rig-eternalai)


&lt;p align=&quot;center&quot;&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img src=&quot;img/built-by-playgrounds.svg&quot; alt=&quot;Build by Playgrounds&quot; width=&quot;30%&quot;&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[jj-vcs/jj]]></title>
            <link>https://github.com/jj-vcs/jj</link>
            <guid>https://github.com/jj-vcs/jj</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[A Git-compatible VCS that is both simple and powerful]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jj-vcs/jj">jj-vcs/jj</a></h1>
            <p>A Git-compatible VCS that is both simple and powerful</p>
            <p>Language: Rust</p>
            <p>Stars: 19,113</p>
            <p>Forks: 661</p>
            <p>Stars today: 141 stars today</p>
            <h2>README</h2><pre>&lt;div class=&quot;title-block&quot; style=&quot;text-align: center;&quot; align=&quot;center&quot;&gt;

# Jujutsu—a version control system

&lt;p&gt;&lt;img title=&quot;jj logo&quot; src=&quot;docs/images/jj-logo.svg&quot; width=&quot;320&quot; height=&quot;320&quot;&gt;&lt;/p&gt;

[![Release](https://img.shields.io/github/v/release/martinvonz/jj)](https://github.com/jj-vcs/jj/releases)
[![Release date](https://img.shields.io/github/release-date/martinvonz/jj)](https://github.com/jj-vcs/jj/releases)
&lt;br/&gt;
[![License](https://img.shields.io/github/license/martinvonz/jj)](https://github.com/jj-vcs/jj/blob/main/LICENSE)
[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN)
[![IRC](https://img.shields.io/badge/irc-%23jujutsu-blue.svg)](https://web.libera.chat/?channel=#jujutsu)

**[Homepage] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Installation] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Getting Started] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Development Roadmap] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Contributing](#contributing)**

[Homepage]: https://jj-vcs.github.io/jj
[Installation]: https://jj-vcs.github.io/jj/latest/install-and-setup
[Getting Started]: https://jj-vcs.github.io/jj/latest/tutorial
[Development Roadmap]: https://jj-vcs.github.io/jj/latest/roadmap

&lt;/div&gt;

## Introduction

Jujutsu is a powerful [version control system](https://en.wikipedia.org/wiki/Version_control)
for software projects. You use it to get a copy of your code, track changes
to the code, and finally publish those changes for others to see and use.
It is designed from the ground up to be easy to use—whether you&#039;re new or
experienced, working on brand new projects alone, or large scale software
projects with large histories and teams.

Jujutsu is unlike most other systems, because internally it abstracts the user
interface and version control algorithms from the *storage systems* used to
serve your content. This allows it to serve as a VCS with many possible physical
backends, that may have their own data or networking models—like [Mercurial] or
[Breezy], or hybrid systems like Google&#039;s cloud-based design, [Piper/CitC].

[Mercurial]: https://www.mercurial-scm.org/
[Breezy]: https://www.breezy-vcs.org/
[Piper/CitC]: https://youtu.be/W71BTkUbdqE?t=645

Today, we use Git repositories as a storage layer to serve and track content,
making it **compatible with many of your favorite Git-based tools, right now!**
All core developers use Jujutsu to develop Jujutsu, right here on GitHub. But it
should hopefully work with your favorite Git forges, too.

We combine many distinct design choices and concepts from other version control
systems into a single tool. Some of those sources of inspiration include:

- **Git**: We make an effort to [be fast][perf]—with a snappy UX, efficient
  algorithms, correct data structures, and good-old-fashioned attention to
  detail. The default storage backend uses Git repositories for &quot;physical
  storage&quot;, for wide interoperability and ease of onboarding.

- **Mercurial &amp; Sapling**: There are many Mercurial-inspired features, such as
  the [revset] language to select commits. There is [no explicit index][no-index]
  or staging area. Branches are &quot;anonymous&quot; like Mercurial, so you don&#039;t need
  to make up a name for each small change. Primitives for rewriting history are
  powerful and simple. Formatting output is done with a robust template language
  that can be configured by the user.

- **Darcs**: Jujutsu keeps track of conflicts as [first-class
  objects][conflicts] in its model; they are first-class in the same way commits
  are, while alternatives like Git simply think of conflicts as textual diffs.
  While not as rigorous as systems like Darcs (which is based on a formalized
  theory of patches, as opposed to snapshots), the effect is that many forms of
  conflict resolution can be performed and propagated automatically.

[perf]: https://github.com/jj-vcs/jj/discussions/49
[revset]: https://jj-vcs.github.io/jj/latest/revsets/
[no-index]: https://jj-vcs.github.io/jj/latest/git-comparison/#the-index
[conflicts]: https://jj-vcs.github.io/jj/latest/conflicts/

And it adds several innovative, useful features of its own:

- **Working-copy-as-a-commit**: Changes to files are [recorded automatically][wcc]
  as normal commits, and amended on every subsequent change. This &quot;snapshot&quot;
  design simplifies the user-facing data model (commits are the only visible
  object), simplifies internal algorithms, and completely subsumes features like
  Git&#039;s stashes or the index/staging-area.

- **Operation log &amp; undo**: Jujutsu records every operation that is performed on the
  repository, from commits, to pulls, to pushes. This makes debugging problems like
  &quot;what just happened?&quot; or &quot;how did I end up here?&quot; easier, *especially* when
  you&#039;re helping your coworker answer those questions about their repository!
  And because everything is recorded, you can undo that mistake you just made
  with ease. Version control has finally entered [the 1960s][undo-history]!

- **Automatic rebase and conflict resolution**: When you modify a commit, every
  descendent is automatically rebased on top of the freshly-modified one. This
  makes &quot;patch-based&quot; workflows a breeze. If you resolve a conflict in a commit,
  the _resolution_ of that conflict is also propagated through descendants as
  well. In effect, this is a completely transparent version of `git rebase
  --update-refs` combined with `git rerere`, supported by design.

&gt; [!WARNING]
&gt; The following features are available for use, but experimental; they may have
&gt; bugs, backwards incompatible storage changes, and user-interface changes!

- **Safe, concurrent replication**: Have you ever wanted to store your version
  controlled repositories inside a Dropbox folder? Or continuously backup
  repositories to S3? No? Well, now you can!

  The fundamental problem with using filesystems like Dropbox and backup tools
  like `rsync` on your typical Git/Mercurial repositories is that they rely
  on *local filesystem operations* being atomic, serialized, and non-concurrent
  with respect to other reads and writes—which is _not_ true when operating on
  distributed file systems, or when operations like concurrent file copies (for
  backup) happen while lock files are being held.

  Jujutsu is instead designed to be [safe under concurrent scenarios][conc-safety];
  simply using rsync or Dropbox and then using that resulting repository
  should never result in a repository in a *corrupt state*. The worst that
  _should_ happen is that it will expose conflicts between the local and remote
  state, leaving you to resolve them.

[wcc]: https://jj-vcs.github.io/jj/latest/working-copy/
[undo-history]: https://en.wikipedia.org/wiki/Undo#History
[conc-safety]: https://jj-vcs.github.io/jj/latest/technical/concurrency/

The command-line tool is called `jj` for now because it&#039;s easy to type and easy
to replace (rare in English). The project is called &quot;Jujutsu&quot; because it matches
&quot;jj&quot;.

Jujutsu is relatively young, with lots of work to still be done. If you have any
questions, or want to talk about future plans, please join us on Discord
[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN),
start a [GitHub Discussion](https://github.com/jj-vcs/jj/discussions), or
send an IRC message to [`#jujutsu` on Libera
Chat](https://web.libera.chat/?channel=#jujutsu). The developers monitor all of
these channels[^bridge].

[^bridge]: To be more precise, the `#jujutsu` Libera IRC channel is bridged to
one of the channels on jj&#039;s Discord. Some of the developers stay on Discord and
use the bridge to follow IRC.

### News and Updates 📣

- **December 2024**: The `jj` Repository has moved to the `jj-vcs` GitHub
  organisation.
- **November 2024**: Version 0.24 is released which adds `jj file annotate`,
  which is equivalent to `git blame` or `hg annotate`.
- **September 2024**: Martin gave a [presentation about Jujutsu][merge-vid-2024] at
  Git Merge 2024.
- **Feb 2024**: Version 0.14 is released, which deprecates [&quot;jj checkout&quot; and &quot;jj merge&quot;](CHANGELOG.md#0140---2024-02-07),
  as well as `jj init --git`, which is now just called `jj git init`.
- **Oct 2023**: Version 0.10.0 is released! Now includes a bundled merge and
  diff editor for all platforms, &quot;immutable revsets&quot; to avoid accidentally
  `edit`-ing the wrong revisions, and lots of polish.
- **Jan 2023**: Martin gave a presentation about Google&#039;s plans for Jujutsu at
  Git Merge 2022!
  See the [slides][merge-slides] or the [recording][merge-talk].

### Related Media

- **Mar 2024**: Chris Krycho started [a YouTube series about Jujutsu][krycho-yt].
- **Feb 2024**: Chris Krycho published an article about Jujutsu called [jj init][krycho]
  and Steve Klabnik followed up with the [Jujutsu Tutorial][klabnik].
- **Jan 2024**: Jujutsu was featured in an LWN.net article called
  [Jujutsu: a new, Git-compatible version control system][lwn].
- **Jan 2023**: Martin&#039;s Talk about Jujutsu at Git Merge 2022, [video][merge-talk]
  and the associated [slides][merge-slides].

The wiki also contains a more extensive list of [media references][wiki-media].

[krycho-yt]: https://www.youtube.com/playlist?list=PLelyiwKWHHAq01Pvmpf6x7J0y-yQpmtxp
[krycho]: https://v5.chriskrycho.com/essays/jj-init/
[klabnik]: https://steveklabnik.github.io/jujutsu-tutorial/
[lwn]: https://lwn.net/Articles/958468/
[merge-talk]: https://www.youtube.com/watch?v=bx_LGilOuE4
[merge-slides]: https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view
[merge-vid-2024]: https://www.youtube.com/watch?v=LV0JzI8IcCY
[wiki-media]: https://github.com/jj-vcs/jj/wiki/Media

## Getting started

&gt; [!IMPORTANT]
&gt; Jujutsu is an **experimental version control system**. While Git compatibility
&gt; is stable, and most developers use it daily for all their needs, there may
&gt; still be work-in-progress features, suboptimal UX, and workflow gaps that make
&gt; it unusable for your particular use.

Follow the [installation
instructions](https://jj-vcs.github.io/jj/latest/install-and-setup) to
obtain and configure `jj`.

The best way to get started is probably to go through [the
tutorial](https://jj-vcs.github.io/jj/latest/tutorial). Also see the [Git
comparison](https://jj-vcs.github.io/jj/latest/git-comparison), which
includes a table of `jj` vs. `git` commands.

As you become more familiar with Jujutsu, the following resources may be helpful:

- The [FAQ](https://jj-vcs.github.io/jj/latest/FAQ).
- The [Glossary](https://jj-vcs.github.io/jj/latest/glossary).
- The `jj help` command (e.g. `jj help rebase`).
- The `jj help -k &lt;keyword&gt;` command (e.g. `jj help -k config`). Use `jj help --help`
  to see what keywords are available.

If you are using a **prerelease** version of `jj`, you would want to consult
[the docs for the prerelease (main branch)
version](https://jj-vcs.github.io/jj/prerelease/). You can also get there
from the docs for the latest release by using the website&#039;s version switcher. The version switcher is visible in
the header of the website when you scroll to the top of any page.

## Features

### Compatible with Git

Jujutsu is designed so that the underlying data and storage model is abstract.
Today, only the Git backend is production-ready. The Git backend uses the
[gitoxide](https://github.com/Byron/gitoxide) Rust library.

[backends]: https://jj-vcs.github.io/jj/latest/glossary#backend

The Git backend is fully featured and maintained, and allows you to use Jujutsu
with any Git remote. The commits you create will look like regular Git commits.
You can fetch branches from a regular Git remote and push branches to the
remote. You can always switch back to Git.

Here is how you can explore a GitHub repository with `jj`.

&lt;img src=&quot;demos/git_compat.png&quot; /&gt;

You can even have a [&quot;co-located&quot; local
repository](https://jj-vcs.github.io/jj/latest/git-compatibility#co-located-jujutsugit-repos)
where you can use both `jj` and `git` commands interchangeably.

### The working copy is automatically committed

Jujutsu uses a real commit to represent the working copy. Checking out a commit
results a new working-copy commit on top of the target commit. Almost all
commands automatically amend the working-copy commit.

The working-copy being a commit means that commands never fail because the
working copy is dirty (no &quot;error: Your local changes to the following
files...&quot;), and there is no need for `git stash`. Also, because the working copy
is a commit, commands work the same way on the working-copy commit as on any
other commit, so you can set the commit message before you&#039;re done with the
changes.

&lt;img src=&quot;demos/working_copy.png&quot; /&gt;

### The repo is the source of truth

With Jujutsu, the working copy plays a smaller role than with Git. Commands
snapshot the working copy before they start, then they update the repo, and then
the working copy is updated (if the working-copy commit was modified). Almost
all commands (even checkout!) operate on the commits in the repo, leaving the
common functionality of snapshotting and updating of the working copy to
centralized code. For example, `jj restore` (similar to `git restore`) can
restore from any commit and into any commit, and `jj describe` can set the
commit message of any commit (defaults to the working-copy commit).

### Entire repo is under version control

All operations you perform in the repo are recorded, along with a snapshot of
the repo state after the operation. This means that you can easily revert to an
earlier repo state, or to simply undo a particular operation (which does not
necessarily have to be the most recent operation).

&lt;img src=&quot;demos/operation_log.png&quot; /&gt;

### Conflicts can be recorded in commits

If an operation results in
[conflicts](https://jj-vcs.github.io/jj/latest/glossary#conflict),
information about those conflicts will be recorded in the commit(s). The
operation will succeed. You can then resolve the conflicts later. One
consequence of this design is that there&#039;s no need to continue interrupted
operations. Instead, you get a single workflow for resolving conflicts,
regardless of which command caused them. This design also lets Jujutsu rebase
merge commits correctly (unlike both Git and Mercurial).

Basic conflict resolution:

&lt;img src=&quot;demos/resolve_conflicts.png&quot; /&gt;

Juggling conflicts:

&lt;img src=&quot;demos/juggle_conflicts.png&quot; /&gt;

### Automatic rebase

Whenever you modify a commit, any descendants of the old commit will be rebased
onto the new commit. Thanks to the conflict design described above, that can be
done even if there are conflicts. Bookmarks pointing to rebased commits will be
updated. So will the working copy if it points to a rebased commit.

### Comprehensive support for rewriting history

Besides the usual rebase command, there&#039;s `jj describe` for editing the
description (commit message) of an arbitrary commit. There&#039;s also `jj diffedit`,
which lets you edit the changes in a commit without checking it out. To split
a commit into two, use `jj split`. You can even move part of the changes in a
commit to any other commit using `jj squash -i --from X --into Y`.

## Status

The tool is fairly feature-complete, but some important features like support
for Git submodules are not yet completed. There
are also several performance bugs. It&#039;s likely that workflows and setups
different from what the core developers use are not well supported, e.g. there
is no native support for email-based workflows.

Today, all core developers use `jj` to work on `jj`. I (Martin von Zweigbergk)
have almost exclusively used `jj` to develop the project itself since early
January 2021. I haven&#039;t had to re-clone from source (I don&#039;t think I&#039;ve even had
to restore from backup).

There *will* be changes to workflows and backward-incompatible changes to the
on-disk formats before version 1.0.0. For any format changes, we&#039;ll try to
implement transparent upgrades (as we&#039;ve done with recent changes), or provide
upgrade commands or scripts if requested.

## Related work

There are several tools trying to solve similar problems as Jujutsu. See
[related work](https://jj-vcs.github.io/jj/latest/related-work) for details.

## Contributing

We welcome outside contributions, and there&#039;s plenty of things to do, so
don&#039;t be shy. Please ask if you want a pointer on something you can help with,
and hopefully we can all figure something out.

We do have [a few policies and
suggestions](https://jj-vcs.github.io/jj/prerelease/contributing/)
for contributors. The broad TL;DR:

- Bug reports are very welcome!
- Every commit that lands in the `main` branch is code reviewed.
- Please behave yourself, and obey the Community Guidelines.
- There **is** a mandatory CLA you must agree to. Importantly, it **does not**
  transfer copyright ownership to Google or anyone else; it simply gives us the
  right to safely redistribute and use your changes.

### Mandatory Google Disclaimer

I (Martin von Zweigbergk, &lt;martinvonz@google.com&gt;) started Jujutsu as a hobby
project in late 2019, and it has evolved into my full-time project at Google,
with several other Googlers (now) assisting development in various capacities.
That said, **this is not a Google product**.

## License

Jujutsu is available as Open Source Software, under the Apache 2.0 license. See
[`LICENSE`](./LICENSE) for details about copyright and redistribution.

The `jj` logo was contributed by J. Jennings and is licensed under a Creative
Commons License, see [`docs/images/LICENSE`](docs/images/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/rustlings]]></title>
            <link>https://github.com/rust-lang/rustlings</link>
            <guid>https://github.com/rust-lang/rustlings</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[🦀 Small exercises to get you used to reading and writing Rust code!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/rustlings">rust-lang/rustlings</a></h1>
            <p>🦀 Small exercises to get you used to reading and writing Rust code!</p>
            <p>Language: Rust</p>
            <p>Stars: 59,707</p>
            <p>Forks: 10,857</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre># [Rustlings](https://rustlings.rust-lang.org) 🦀

Small exercises to get you used to reading and writing [Rust](https://www.rust-lang.org) code - _Recommended in parallel to reading [the official Rust book](https://doc.rust-lang.org/book) 📚️_

Visit the **website** for a demo, info about setup and more:

## ➡️ [rustlings.rust-lang.org](https://rustlings.rust-lang.org) ⬅️
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zed-industries/zed]]></title>
            <link>https://github.com/zed-industries/zed</link>
            <guid>https://github.com/zed-industries/zed</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[Code at the speed of thought – Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zed-industries/zed">zed-industries/zed</a></h1>
            <p>Code at the speed of thought – Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.</p>
            <p>Language: Rust</p>
            <p>Stars: 64,246</p>
            <p>Forks: 4,991</p>
            <p>Stars today: 65 stars today</p>
            <h2>README</h2><pre># Zed

[![Zed](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/zed-industries/zed/main/assets/badge/v0.json)](https://zed.dev)
[![CI](https://github.com/zed-industries/zed/actions/workflows/ci.yml/badge.svg)](https://github.com/zed-industries/zed/actions/workflows/ci.yml)

Welcome to Zed, a high-performance, multiplayer code editor from the creators of [Atom](https://github.com/atom/atom) and [Tree-sitter](https://github.com/tree-sitter/tree-sitter).

---

### Installation

On macOS and Linux you can [download Zed directly](https://zed.dev/download) or [install Zed via your local package manager](https://zed.dev/docs/linux#installing-via-a-package-manager).

Other platforms are not yet available:

- Windows ([tracking issue](https://github.com/zed-industries/zed/issues/5394))
- Web ([tracking issue](https://github.com/zed-industries/zed/issues/5396))

### Developing Zed

- [Building Zed for macOS](./docs/src/development/macos.md)
- [Building Zed for Linux](./docs/src/development/linux.md)
- [Building Zed for Windows](./docs/src/development/windows.md)
- [Running Collaboration Locally](./docs/src/development/local-collaboration.md)

### Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for ways you can contribute to Zed.

Also... we&#039;re hiring! Check out our [jobs](https://zed.dev/jobs) page for open roles.

### Licensing

License information for third party dependencies must be correctly provided for CI to pass.

We use [`cargo-about`](https://github.com/EmbarkStudios/cargo-about) to automatically comply with open source licenses. If CI is failing, check the following:

- Is it showing a `no license specified` error for a crate you&#039;ve created? If so, add `publish = false` under `[package]` in your crate&#039;s Cargo.toml.
- Is the error `failed to satisfy license requirements` for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license&#039;s requirements. If you&#039;re unsure, ask a lawyer. Once you&#039;ve verified that this system is acceptable add the license&#039;s SPDX identifier to the `accepted` array in `script/licenses/zed-licenses.toml`.
- Is `cargo-about` unable to find the license for a dependency? If so, add a clarification field at the end of `script/licenses/zed-licenses.toml`, as specified in the [cargo-about book](https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[eythaann/Seelen-UI]]></title>
            <link>https://github.com/eythaann/Seelen-UI</link>
            <guid>https://github.com/eythaann/Seelen-UI</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[The Fully Customizable Desktop Environment for Windows 10/11.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eythaann/Seelen-UI">eythaann/Seelen-UI</a></h1>
            <p>The Fully Customizable Desktop Environment for Windows 10/11.</p>
            <p>Language: Rust</p>
            <p>Stars: 10,298</p>
            <p>Forks: 316</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[aws/amazon-q-developer-cli]]></title>
            <link>https://github.com/aws/amazon-q-developer-cli</link>
            <guid>https://github.com/aws/amazon-q-developer-cli</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[✨ Agentic chat experience in your terminal. Build applications using natural language.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aws/amazon-q-developer-cli">aws/amazon-q-developer-cli</a></h1>
            <p>✨ Agentic chat experience in your terminal. Build applications using natural language.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,474</p>
            <p>Forks: 258</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># Amazon Q CLI

## Installation

- **macOS**:
  - **DMG**: [Download now](https://desktop-release.q.us-east-1.amazonaws.com/latest/Amazon%20Q.dmg)
- **Linux**:
  - [Ubuntu/Debian](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-ubuntu)
  - [AppImage](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-appimage)
  - [Alternative Linux builds](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html#command-line-installing-alternative-linux)

## Contributing

Thank you so much for considering to contribute to Amazon Q.

Before getting started, see our [contributing docs](CONTRIBUTING.md#security-issue-notifications).

### Prerequisites

- MacOS
  - Xcode 13 or later
  - Brew

#### 1. Clone repo

```shell
git clone https://github.com/aws/amazon-q-developer-cli.git
```

#### 2. Install the Rust toolchain using [Rustup](https://rustup.rs):

```shell
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup default stable
rustup toolchain install nightly
cargo install typos-cli
```

#### 3. Develop locally

- To compile and run: `cargo run --bin chat_cli`.
- To run tests: `cargo test`.
- To run lints: `cargo clippy`.
- To format rust files: `cargo +nightly fmt`.
- To run subcommands: `cargo run --bin chat_cli -- {subcommand}`.
  - Login would then be: `cargo run --bin chat_cli -- login`

## Project Layout

- [`chat_cli`](crates/chat_cli/) - the `q` CLI, allows users to interface with Amazon Q Developer from
  the command line
- [`scripts/`](scripts/) - Contains ops and build related scripts
- [`crates/`](crates/) - Contains all rust crates
- [`docs/`](docs/) - Contains technical documentation

## Security

For security related concerns, see [here](SECURITY.md).

## Licensing

This repo is dual licensed under MIT and Apache 2.0 licenses.

Those licenses can be found [here](LICENSE.MIT) and [here](LICENSE.APACHE).

“Amazon Web Services” and all related marks, including logos, graphic designs, and service names, are trademarks or trade dress of AWS in the U.S. and other countries. AWS’s trademarks and trade dress may not be used in connection with any product or service that is not AWS’s, in any manner that is likely to cause confusion among customers, or in any manner that disparages or discredits AWS.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[eclipse-zenoh/zenoh]]></title>
            <link>https://github.com/eclipse-zenoh/zenoh</link>
            <guid>https://github.com/eclipse-zenoh/zenoh</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[zenoh unifies data in motion, data in-use, data at rest and computations. It carefully blends traditional pub/sub with geo-distributed storages, queries and computations, while retaining a level of time and space efficiency that is well beyond any of the mainstream stacks.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eclipse-zenoh/zenoh">eclipse-zenoh/zenoh</a></h1>
            <p>zenoh unifies data in motion, data in-use, data at rest and computations. It carefully blends traditional pub/sub with geo-distributed storages, queries and computations, while retaining a level of time and space efficiency that is well beyond any of the mainstream stacks.</p>
            <p>Language: Rust</p>
            <p>Stars: 2,032</p>
            <p>Forks: 207</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://raw.githubusercontent.com/eclipse-zenoh/zenoh/master/zenoh-dragon.png&quot; height=&quot;150&quot;&gt;

[![CI](https://github.com/eclipse-zenoh/zenoh/actions/workflows/ci.yml/badge.svg?branch=main)](https://github.com/eclipse-zenoh/zenoh/actions?query=workflow%3ACI+branch%3Amain++)
[![Documentation Status](https://readthedocs.org/projects/zenoh-rust/badge/?version=latest)](https://zenoh-rust.readthedocs.io/en/latest/?badge=latest)
[![codecov](https://codecov.io/github/eclipse-zenoh/zenoh/branch/main/graph/badge.svg?token=F8T4C8WPZD)](https://codecov.io/github/eclipse-zenoh/zenoh)
[![Discussion](https://img.shields.io/badge/discussion-on%20github-blue)](https://github.com/eclipse-zenoh/roadmap/discussions)
[![Discord](https://img.shields.io/badge/chat-on%20discord-blue)](https://discord.gg/2GJ958VuHs)
[![License](https://img.shields.io/badge/License-EPL%202.0-blue)](https://choosealicense.com/licenses/epl-2.0/)
[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)

# Eclipse Zenoh

The Eclipse Zenoh: Zero Overhead Pub/sub, Store/Query and Compute.

Zenoh (pronounce _/zeno/_) unifies data in motion, data at rest and computations. It carefully blends traditional pub/sub with geo-distributed storages, queries and computations, while retaining a level of time and space efficiency that is well beyond any of the mainstream stacks.

Check the website [zenoh.io](http://zenoh.io) and the [roadmap](https://github.com/eclipse-zenoh/roadmap) for more detailed information.

-------------------------------

## Getting Started

Zenoh is extremely easy to learn, the best place to master the fundamentals is our [getting started guide](https://zenoh.io/docs/getting-started/first-app/).

-------------------------------

## How to install it

To install the latest release of the Zenoh router (`zenohd`) and its default plugins (REST API plugin and Storages Manager plugin) you can do as follows:

### Manual installation (all platforms)

All release packages can be downloaded from [https://download.eclipse.org/zenoh/zenoh/latest/](https://download.eclipse.org/zenoh/zenoh/latest/).

Each subdirectory has the name of the Rust target. See the platforms each target corresponds to on [https://doc.rust-lang.org/stable/rustc/platform-support.html](https://doc.rust-lang.org/stable/rustc/platform-support.html).

Choose your platform and download the `.zip` file.
Unzip it where you want, and run the extracted `zenohd` binary.

### Linux Debian

Add Eclipse Zenoh private repository to the sources list, and install the `zenoh` package:

```bash
curl -L https://download.eclipse.org/zenoh/debian-repo/zenoh-public-key | sudo gpg --dearmor --yes --output /etc/apt/keyrings/zenoh-public-key.gpg
echo &quot;deb [signed-by=/etc/apt/keyrings/zenoh-public-key.gpg] https://download.eclipse.org/zenoh/debian-repo/ /&quot; | sudo tee /etc/apt/sources.list.d/zenoh.list &gt; /dev/null
sudo apt update
sudo apt install zenoh
```

Then you can start run `zenohd`.

### MacOS

Tap our brew package repository and install the `zenoh` formula:

```bash
brew tap eclipse-zenoh/homebrew-zenoh
brew install zenoh
```

Then you can start run `zenohd`.

-------------------------------

## Rust API

* [Docs.rs for Zenoh](https://docs.rs/zenoh/latest/zenoh/)

-------------------------------

## How to build it

Install [Cargo and Rust](https://doc.rust-lang.org/cargo/getting-started/installation.html). Zenoh can be successfully compiled with Rust stable (&gt;= 1.75.0), so no special configuration is required from your side. If you already have the Rust toolchain installed, make sure it is up-to-date with:

```bash
rustup update
```

To build Zenoh, just type the following command after having followed the previous instructions:

```bash
cargo build --release --all-targets
```

Building all targets may cause an out-of-memory error if memory is limited. Reducing the number of parallel build jobs can help, though it may increase build time. You can fine-tune the job count to balance performance and resource usage.

```bash
cargo build --release --all-targets --jobs=1
```

Zenoh&#039;s router is built as `target/release/zenohd`. All the examples are built into the `target/release/examples` directory. They can all work in peer-to-peer, or interconnected via the zenoh router.

-------------------------------

## Quick tests of your build

### Peer-to-peer tests

* **pub/sub**
  * run: `./target/release/examples/z_sub`
  * in another shell run: `./target/release/examples/z_put`
  * the subscriber should receive the publication.

* **get/queryable**
  * run: `./target/release/examples/z_queryable`
  * in another shell run: `./target/release/examples/z_get`
  * the queryable should display the log in its listener, and the get should receive the queryable result.

### Routed tests

&gt; [!NOTE]
&gt; **Windows users**: to properly execute the commands below in PowerShell you need to escape `&quot;` characters as `\&quot;`.

* **put / store / get**
  * run the Zenoh router with a memory storage:

    ```sh
    ./target/release/zenohd --cfg=&#039;plugins/storage_manager/storages/demo:{key_expr:&quot;demo/example/**&quot;,volume:&quot;memory&quot;}&#039;
    ```

  * in another shell run:
  
    ```sh
    ./target/release/examples/z_put`
    ```

  * then run

    ```sh
    ./target/release/examples/z_get
    ```

  * the get should receive the stored publication.

* **REST API using `curl` tool**
  * run the Zenoh router with a memory storage:

    ```sh
    ./target/release/zenohd --cfg=&#039;plugins/storage_manager/storages/demo:{key_expr:&quot;demo/example/**&quot;,volume:&quot;memory&quot;}&#039;
    ```

  * in another shell, do a publication via the REST API:

    ```sh
    curl -X PUT -d &#039;&quot;Hello World!&quot;&#039; http://localhost:8000/demo/example/test
    ```

  * get it back via the REST API:

    ```sh
    curl http://localhost:8000/demo/example/test
    ```

* **router admin space via the REST API**
  * run the Zenoh router with permission to perform config changes via the admin space, and with a memory storage:

    ```sh
    ./target/release/zenohd --rest-http-port=8000 --adminspace-permissions=rw --cfg=&#039;plugins/storage_manager/storages/demo:{key_expr:&quot;demo/example/**&quot;,volume:&quot;memory&quot;}&#039;
    ```

  * in another shell, get info of the zenoh router via the zenoh admin space (you may use `jq` for pretty json formatting):

    ```sh
    curl -s http://localhost:8000/@/local/router | jq
    ```

  * get the volumes of the router (only memory by default):

    ```sh
    curl -s &#039;http://localhost:8000/@/local/router/**/volumes/*&#039; | jq
    ```

  * get the storages of the local router (the memory storage configured at startup on &#039;/demo/example/**&#039; should be present):

    ```sh
    curl -s &#039;http://localhost:8000/@/local/router/**/storages/*&#039; | jq
    ```

  * add another memory storage on `/demo/mystore/**`:

    ```sh
    curl -X PUT -H &#039;content-type:application/json&#039; -d &#039;{&quot;key_expr&quot;:&quot;demo/mystore/**&quot;,&quot;volume&quot;:&quot;memory&quot;}&#039; http://localhost:8000/@/local/router/config/plugins/storage_manager/storages/mystore
    ```

  * check it has been created:
  
    ```sh
    curl -s &#039;http://localhost:8000/@/local/router/**/storages/*&#039; | jq
    ```

### Configuration options

A Zenoh configuration file can be provided via CLI to all Zenoh examples and the Zenoh router.

* `-c, --config &lt;FILE&gt;`: a [JSON5](https://json5.org) configuration file. [DEFAULT_CONFIG.json5](DEFAULT_CONFIG.json5) shows the schema of this file and the available options.

See other examples of Zenoh usage in [examples/](examples)

&gt; [!NOTE]
&gt; **Zenoh Runtime Configuration**: Starting from version 0.11.0-rc, Zenoh allows for configuring the number of worker threads and other advanced options of the runtime. For guidance on utilizing it, please refer to the [doc](https://docs.rs/zenoh-runtime/latest/zenoh_runtime/enum.ZRuntime.html).

-------------------------------

## Zenoh router command line arguments

`zenohd` accepts the following arguments:

* `--adminspace-permissions &lt;[r|w|rw|none]&gt;`: Configure the read and/or write permissions on the admin space. Default is read only.
* `-c, --config &lt;FILE&gt;`: a [JSON5](https://json5.org) configuration file. [DEFAULT_CONFIG.json5](DEFAULT_CONFIG.json5) shows the schema of this file. All properties of this configuration are optional, so you may not need such a large configuration for your use-case.
* `--cfg &lt;KEY&gt;:&lt;VALUE&gt;`: allows you to change specific parts of the configuration right after it has been constructed. VALUE must be a valid JSON5 value, and key must be a path through the configuration file, where each element is separated by a `/`. When inserting in parts of the config that are arrays, you may use indexes, or may use `+` to indicate that you want to append your value to the array. `--cfg` passed values will always override any previously existing value for their key in the configuration.
* `-l, --listen &lt;ENDPOINT&gt;...`: An endpoint on which this router will listen for incoming sessions.
  Repeat this option to open several listeners. By default, `tcp/[::]:7447` is used. The following endpoints are currently supported:
  * TCP: `tcp/&lt;host_name_or_IPv4_or_IPv6&gt;:&lt;port&gt;`
  * UDP: `udp/&lt;host_name_or_IPv4_or_IPv6&gt;:&lt;port&gt;`
  * [TCP+TLS](https://zenoh.io/docs/manual/tls/): `tls/&lt;host_name&gt;:&lt;port&gt;`
  * [QUIC](https://zenoh.io/docs/manual/quic/): `quic/&lt;host_name&gt;:&lt;port&gt;`
* `-e, --connect &lt;ENDPOINT&gt;...`: An endpoint this router will try to connect to. Repeat this option to connect to several peers or routers.
* `--no-multicast-scouting`: By default zenohd replies to multicast scouting messages for being discovered by peers and clients.
  This option disables this feature.
* `-i, --id &lt;hex_string&gt;`: The identifier (as an hexadecimal string - e.g.: A0B23...) that zenohd must use.
   **WARNING**: this identifier must be unique in the system! If not set, a random unsigned 128bit integer will be used.
* `--no-timestamp`: By default zenohd adds a HLC-generated Timestamp to each routed Data if there isn&#039;t already one.
  This option disables this feature.
* `-P, --plugin [&lt;PLUGIN_NAME&gt; | &lt;PLUGIN_NAME&gt;:&lt;LIBRARY_PATH&gt;]...`: A [plugin](https://zenoh.io/docs/manual/plugins/) that must be loaded. Accepted values:
  * a plugin name; zenohd will search for a library named `libzenoh_plugin_&lt;name&gt;.so` on Unix, `libzenoh_plugin_&lt;PLUGIN_NAME&gt;.dylib` on MacOS or `zenoh_plugin_&lt;PLUGIN_NAME&gt;.dll` on Windows.
  * `&quot;&lt;PLUGIN_NAME&gt;:&lt;LIBRARY_PATH&gt;&quot;`; the plugin will be loaded from library file at `&lt;LIBRARY_PATH&gt;`.

  Repeat this option to load several plugins.
* `--plugin-search-dir &lt;DIRECTORY&gt;...`: A directory where to search for [plugins](https://zenoh.io/docs/manual/plugins/) libraries to load.
  Repeat this option to specify several search directories&#039;. By default, the plugins libraries will be searched in:
  `&#039;/usr/local/lib:/usr/lib:~/.zenoh/lib:.&#039;`
* `--rest-http-port &lt;rest-http-port&gt;`: Configures the [REST plugin](https://zenoh.io/docs/manual/plugin-http/)&#039;s HTTP port. Accepted values:
  * a port number
  * a string with format `&lt;local_ip&gt;:&lt;port_number&gt;` (to bind the HTTP server to a specific interface)
  * `&quot;None&quot;` to deactivate the REST plugin

  If not specified, the REST plugin will be active on any interface (`[::]`) and port `8000`.

-------------------------------

## Plugins

&gt; [!WARNING]
&gt; As Rust doesn&#039;t have a stable ABI, the plugins should be
built with the exact same Rust version as `zenohd`, and using for `zenoh` dependency the same version (or commit number) as `zenohd` with the same
set of features. A plugin compiled with different Rust version or with different set of `zenoh` crate features will be rejected when `zenohd` attempts to load it. Otherwise, incompatibilities in memory mapping of structures shared between `zenohd` and the library could lead to a `&quot;SIGSEGV&quot;` crash.

By default the Zenoh router is delivered or built with 2 plugins. These may be configured through a configuration file, or through individual changes to the configuration via the `--cfg` CLI option or via zenoh puts on individual parts of the configuration.

**[REST plugin](https://zenoh.io/docs/manual/plugin-http/)** (exposing a REST API):
This plugin converts GET and PUT REST requests into Zenoh gets and puts respectively.

Note that to activate the REST plugin on `zenohd` the CLI argument should be passed: `--rest-http-port=8000` (or any other port of your choice).

**[Storages plugin](https://zenoh.io/docs/manual/plugin-storage-manager/)** (managing [backends and storages](https://zenoh.io/docs/manual/plugin-storage-manager/#backends-and-volumes))
This plugin allows you to easily define storages. These will store key-value pairs they subscribed to, and send the most recent ones when queried. Check out [DEFAULT_CONFIG.json5](DEFAULT_CONFIG.json5) for info on how to configure them.

-------------------------------

## Troubleshooting

In case of troubles, please first check on [this page](https://zenoh.io/docs/getting-started/troubleshooting/) if the trouble and cause are already known.
Otherwise, you can ask a question on the [zenoh Discord server](https://discord.gg/vSDSpqnbkm), or [create an issue](https://github.com/eclipse-zenoh/zenoh/issues).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[delta-io/delta-rs]]></title>
            <link>https://github.com/delta-io/delta-rs</link>
            <guid>https://github.com/delta-io/delta-rs</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[A native Rust library for Delta Lake, with bindings into Python]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/delta-io/delta-rs">delta-io/delta-rs</a></h1>
            <p>A native Rust library for Delta Lake, with bindings into Python</p>
            <p>Language: Rust</p>
            <p>Stars: 2,913</p>
            <p>Forks: 511</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://delta.io/&quot;&gt;
    &lt;img src=&quot;https://github.com/delta-io/delta-rs/blob/main/docs\delta-rust-no-whitespace.svg?raw=true&quot; alt=&quot;delta-rs logo&quot; height=&quot;200&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  A native Rust library for Delta Lake, with bindings to Python
  &lt;br&gt;
  &lt;a href=&quot;https://delta-io.github.io/delta-rs/&quot;&gt;Python docs&lt;/a&gt;
  ·
  &lt;a href=&quot;https://docs.rs/deltalake/latest/deltalake/&quot;&gt;Rust docs&lt;/a&gt;
  ·
  &lt;a href=&quot;https://github.com/delta-io/delta-rs/issues/new?template=bug_report.md&quot;&gt;Report a bug&lt;/a&gt;
  ·
  &lt;a href=&quot;https://github.com/delta-io/delta-rs/issues/new?template=feature_request.md&quot;&gt;Request a feature&lt;/a&gt;
  ·
  &lt;a href=&quot;https://github.com/delta-io/delta-rs/issues/1128&quot;&gt;Roadmap&lt;/a&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://pypi.python.org/pypi/deltalake&quot;&gt;
    &lt;img alt=&quot;Deltalake&quot; src=&quot;https://img.shields.io/pypi/l/deltalake.svg?style=flat-square&amp;color=00ADD4&amp;logo=apache&quot;&gt;
  &lt;/a&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://github.com/delta-io/delta-rs&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/delta-io/delta-rs?logo=github&amp;color=F75101&quot;&gt;
  &lt;/a&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://crates.io/crates/deltalake&quot; style=&quot;background:none&quot;&gt;
    &lt;img alt=&quot;Crate&quot; src=&quot;https://img.shields.io/crates/v/deltalake.svg?style=flat-square&amp;color=00ADD4&amp;logo=rust&quot; &gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pypi.python.org/pypi/deltalake&quot;&gt;
    &lt;img alt=&quot;Deltalake&quot; src=&quot;https://img.shields.io/pypi/v/deltalake.svg?style=flat-square&amp;color=F75101&amp;logo=pypi&quot; &gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pypi.python.org/pypi/deltalake&quot;&gt;
    &lt;img alt=&quot;Deltalake&quot; src=&quot;https://img.shields.io/pypi/pyversions/deltalake.svg?style=flat-square&amp;color=00ADD4&amp;logo=python&quot;&gt;
  &lt;/a&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://go.delta.io/slack&quot;&gt;
    &lt;img alt=&quot;#delta-rs in the Delta Lake Slack workspace&quot; src=&quot;https://img.shields.io/badge/slack-delta-blue.svg?logo=slack&amp;style=flat-square&amp;color=F75101&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
Delta Lake is an open-source storage format that runs on top of existing data lakes. Delta Lake is compatible with processing engines like Apache Spark and provides benefits such as ACID transaction guarantees, schema enforcement, and scalable data handling.

The Delta Lake project aims to unlock the power of the Deltalake for as many users and projects as possible
by providing native low-level APIs aimed at developers and integrators, as well as a high-level operations
API that lets you query, inspect, and operate your Delta Lake with ease.

| Source                  | Downloads                         | Installation Command    | Docs            |
| ----------------------- | --------------------------------- | ----------------------- | --------------- |
| **[PyPi][pypi]**        | [![Downloads][pypi-dl]][pypi]     | `pip install deltalake` | [Docs][py-docs] |
| **[Crates.io][crates]** | [![Downloads][crates-dl]][crates] | `cargo add deltalake`   | [Docs][rs-docs] |

[pypi]: https://pypi.org/project/deltalake/
[pypi-dl]: https://img.shields.io/pypi/dm/deltalake?style=flat-square&amp;color=00ADD4
[py-docs]: https://delta-io.github.io/delta-rs/
[rs-docs]: https://docs.rs/deltalake/latest/deltalake/
[crates]: https://crates.io/crates/deltalake
[crates-dl]: https://img.shields.io/crates/d/deltalake?color=F75101

## Table of contents

- [Table of contents](#table-of-contents)
- [Quick Start](#quick-start)
- [Get Involved](#get-involved)
- [Integrations](#integrations)
- [Features](#features)
  - [Cloud Integrations](#cloud-integrations)
  - [Supported Operations](#supported-operations)
  - [Protocol Support Level](#protocol-support-level)

## Quick Start

The `deltalake` library aims to adopt patterns from other libraries in data processing,
so getting started should look familiar.

```py3
from deltalake import DeltaTable, write_deltalake
import pandas as pd

# write some data into a delta table
df = pd.DataFrame({&quot;id&quot;: [1, 2], &quot;value&quot;: [&quot;foo&quot;, &quot;boo&quot;]})
write_deltalake(&quot;./data/delta&quot;, df)

# Load data from the delta table
dt = DeltaTable(&quot;./data/delta&quot;)
df2 = dt.to_pandas()

assert df.equals(df2)
```

The same table can also be loaded using the core Rust crate:

```rs
use deltalake::{open_table, DeltaTableError};

#[tokio::main]
async fn main() -&gt; Result&lt;(), DeltaTableError&gt; {
    // open the table written in python
    let table = open_table(&quot;./data/delta&quot;).await?;

    // show all active files in the table
    let files: Vec&lt;_&gt; = table.get_file_uris()?.collect();
    println!(&quot;{files:?}&quot;);

    Ok(())
}
```

You can also try Delta Lake docker at [DockerHub](https://go.delta.io/dockerhub) | [Docker Repo](https://go.delta.io/docker)

## Get Involved

We encourage you to reach out, and are [committed](https://github.com/delta-io/delta-rs/blob/main/CODE_OF_CONDUCT.md)
to provide a welcoming community.

- [Join us in our Slack workspace](https://go.delta.io/slack)
- [Report an issue](https://github.com/delta-io/delta-rs/issues/new?template=bug_report.md)
- Looking to contribute? See our [good first issues](https://github.com/delta-io/delta-rs/contribute).

## Integrations

Libraries and frameworks that interoperate with delta-rs - in alphabetical order.

- [AWS SDK for Pandas](https://github.com/aws/aws-sdk-pandas)
- [ballista][ballista]
- [datafusion][datafusion]
- [Daft](https://www.getdaft.io/)
- [Dask](https://github.com/dask-contrib/dask-deltatable)
- [datahub](https://datahubproject.io/)
- [DuckDB](https://duckdb.org/)
- [polars](https://www.pola.rs/)
- [Ray](https://github.com/delta-incubator/deltaray)

## Features

The following section outlines some core features like supported [storage backends](#cloud-integrations)
and [operations](#supported-operations) that can be performed against tables. The state of implementation
of features outlined in the Delta [protocol][protocol] is also [tracked](#protocol-support-level).

### Cloud Integrations

| Storage              |  Rust   | Python  | Comment                                                          |
| -------------------- | :-----: | :-----: | ---------------------------------------------------------------- |
| Local                | ![done] | ![done] |                                                                  |
| S3 - AWS             | ![done] | ![done] |                                                                  |
| S3 - MinIO           | ![done] | ![done] |                                                                  |
| S3 - R2              | ![done] | ![done] |                                                                  |
| Azure Blob           | ![done] | ![done] |                                                                  |
| Azure ADLS Gen2      | ![done] | ![done] |                                                                  |
| Microsoft OneLake    | ![done] | ![done] |                                                                  |
| Google Cloud Storage | ![done] | ![done] |                                                                  |
| HDFS                 | ![done] | ![done] |                                                                  |
| LakeFS               | ![done] | ![done] |   Python: Rust engine writer only supported                      |

### Supported Operations

| Operation             |  Rust   | Python  | Description                                 |
| --------------------- | :-----: | :-----: | ------------------------------------------- |
| Create                | ![done] | ![done] | Create a new table                          |
| Read                  | ![done] | ![done] | Read data from a table                      |
| Vacuum                | ![done] | ![done] | Remove unused files and log entries         |
| Delete - predicates   | ![done] | ![done] | Delete data based on a predicate            |
| Optimize - compaction | ![done] | ![done] | Harmonize the size of data file             |
| Optimize - Z-order    | ![done] | ![done] | Place similar data into the same file       |
| Merge                 | ![done] | ![done] | Merge a target Delta table with source data |
| Update                | ![done] | ![done] | Update values from a table                  |
| Add Column            | ![done] | ![done] | Add new columns or nested fields            |
| Add Feature           | ![done] | ![done] | Enable delta table features                 |
| Add Constraints       | ![done] | ![done] | Set delta constraints, to verify data on write |
| Drop Constraints      | ![done] | ![done] | Removes delta constraints                   |
| Set Table Properties  | ![done] | ![done] | Set delta table properties                  |
| Convert to Delta      | ![done] | ![done] | Convert parquet table to delta table        |
| FS check              | ![done] | ![done] | Remove corrupted files from table           |
| Restore               | ![done] | ![done] | Restores table to previous version state    |

### Protocol Support Level

| Writer Version | Requirement                                   |              Status               |
| -------------- | --------------------------------------------- | :-------------------------------: |
| Version 2      | Append Only Tables                            |              ![done]              |
| Version 2      | Column Invariants                             |              ![done]              |
| Version 3      | Enforce `delta.checkpoint.writeStatsAsJson`   |              ![done]              |
| Version 3      | Enforce `delta.checkpoint.writeStatsAsStruct` |              ![done]              |
| Version 3      | CHECK constraints                             | [![done]][check-constraints]      |
| Version 4      | Change Data Feed                              |              ![done]              |
| Version 4      | Generated Columns                             |              ![done]              |
| Version 5      | Column Mapping                                |                                   |
| Version 6      | Identity Columns                              |                                   |
| Version 7      | Table Features                                |              ![done]              |

| Reader Version | Requirement                         |   Status   |
| -------------- | ----------------------------------- |   ------   |
| Version 2      | Column Mapping                      |            |
| Version 3      | Table Features (requires reader V7) |  ![done]   |

[datafusion]: https://github.com/apache/datafusion
[ballista]: https://github.com/apache/arrow-ballista
[polars]: https://github.com/pola-rs/polars
[open]: https://cdn.jsdelivr.net/gh/Readme-Workflows/Readme-Icons@main/icons/octicons/IssueNeutral.svg
[semi-done]: https://cdn.jsdelivr.net/gh/Readme-Workflows/Readme-Icons@main/icons/octicons/ApprovedChangesGrey.svg
[done]: https://cdn.jsdelivr.net/gh/Readme-Workflows/Readme-Icons@main/icons/octicons/ApprovedChanges.svg
[roadmap]: https://github.com/delta-io/delta-rs/issues/1128
[writer-rs]: https://github.com/delta-io/delta-rs/issues/851
[check-constraints]: https://github.com/delta-io/delta-rs/issues/1881
[onelake-rs]: https://github.com/delta-io/delta-rs/issues/1418
[protocol]: https://github.com/delta-io/delta/blob/master/PROTOCOL.md
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cube-js/cube]]></title>
            <link>https://github.com/cube-js/cube</link>
            <guid>https://github.com/cube-js/cube</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[📊 Cube’s universal semantic layer platform is the next evolution of OLAP technology for AI, BI, spreadsheets, and embedded analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cube-js/cube">cube-js/cube</a></h1>
            <p>📊 Cube’s universal semantic layer platform is the next evolution of OLAP technology for AI, BI, spreadsheets, and embedded analytics</p>
            <p>Language: Rust</p>
            <p>Stars: 18,822</p>
            <p>Forks: 1,880</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cube.dev?ref=github-readme&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/cube-js/cube/master/docs/content/cube-logo-with-bg.png&quot; alt=&quot;Cube — Semantic Layer for Data Applications&quot; width=&quot;300px&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;br/&gt;

[Website](https://cube.dev?ref=github-readme) • [Getting Started](https://cube.dev/docs/getting-started?ref=github-readme) • [Docs](https://cube.dev/docs?ref=github-readme) • [Examples](https://cube.dev/docs/examples?ref=github-readme) • [Blog](https://cube.dev/blog?ref=github-readme) • [Slack](https://slack.cube.dev?ref=github-readme) • [X](https://twitter.com/the_cube_dev)

[![npm version](https://badge.fury.io/js/%40cubejs-backend%2Fserver.svg)](https://badge.fury.io/js/%40cubejs-backend%2Fserver)
[![GitHub Actions](https://github.com/cube-js/cube/workflows/Build/badge.svg)](https://github.com/cube-js/cube/actions?query=workflow%3ABuild+branch%3Amaster)
[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js.svg?type=shield)](https://app.fossa.io/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js?ref=badge_shield)

__Cube is the universal semantic layer for modern data applications.__ Born in the cloud era, Cube represents the next evolution of OLAP technology, helping data engineers and application developers access data from modern data stores, organize it into consistent definitions, and deliver it to every application.

&lt;img
  src=&quot;https://ucarecdn.com/8d945f29-e9eb-4e7f-9e9e-29ae7074e195/&quot;
  style=&quot;border: none&quot;
  width=&quot;100%&quot;
/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Learn more about connecting Cube to &lt;a href=&quot;https://cube.dev/docs/config/databases?ref=github-readme&quot; target=&quot;_blank&quot;&gt;data sources&lt;/a&gt; and &lt;a href=&quot;https://cube.dev/docs/config/downstream?ref=github-readme&quot; target=&quot;_blank&quot;&gt;analytics &amp; visualization tools&lt;/a&gt;.&lt;/i&gt;
&lt;/p&gt;

Cube was designed to work with all SQL-enabled data sources, including cloud data warehouses like Snowflake or Google BigQuery, query engines like Presto or Amazon Athena, and application databases like Postgres. Cube has a built-in relational caching engine to provide sub-second latency and high concurrency for API requests.

For more details, see the [introduction](https://cube.dev/docs/cubejs-introduction?ref=github-readme) page in our documentation.

## Why Cube?

As data infrastructure evolved from traditional relational databases to cloud data platforms, OLAP capabilities that once lived in specialized servers like SQL Server Analysis Services and Oracle Essbase were left behind. Today&#039;s organizations face several challenges:

1. __Analytics Modeling and Multidimensionality.__ Modern cloud data platforms excel at processing large volumes of data but lack native support for multidimensional analysis and modeling. Cube brings OLAP-style analytics to these platforms, enabling consistent metric definitions and multidimensional analysis.

2. __Performance Optimization.__ While cloud data warehouses have improved query performance through column-oriented storage and distributed processing, they still struggle with complex analytical workloads. Cube provides intelligent caching and pre-aggregation strategies that dramatically improve query response times.

3. __Access Control and Governance.__ Securing and governing access to data across all consuming applications remains critical. Cube offers robust access control to ensure consistent security across your entire data ecosystem.

4. __API Flexibility.__ Legacy OLAP tools were limited in how they exposed data. Cube provides modern REST, GraphQL, and SQL APIs along with support for traditional MDX and DAX interfaces, making it a truly universal semantic layer.

Cube is the missing OLAP engine for the cloud data platform era that provides the necessary infrastructure and features to implement efficient data modeling, access control, and performance optimizations without duplicating analytics modeling, data, or security permissions across different tools.

![](https://raw.githubusercontent.com/cube-js/cube.js/master/docs/content/old-was-vs-cubejs-way.png)

## Getting Started 🚀

### Cube Cloud

[Cube Cloud](https://cube.dev/cloud?ref=github-readme) is the fastest way to get started with Cube. It provides managed infrastructure as well as an instant and free access for development projects and proofs of concept.

&lt;a href=&quot;https://cubecloud.dev/auth/signup?ref=github-readme&quot;&gt;&lt;img src=&quot;https://cubedev-blog-images.s3.us-east-2.amazonaws.com/f1f1eac0-0b44-4c47-936e-33b5c06eedf0.png&quot; alt=&quot;Get started now&quot; width=&quot;200px&quot;&gt;&lt;/a&gt;

For a step-by-step guide on Cube Cloud, [see the docs](https://cube.dev/docs/getting-started/cloud/overview?ref=github-readme).

### Docker

Alternatively, you can get started with Cube locally or self-host it with [Docker](https://www.docker.com/).

Once Docker is installed, in a new folder for your project, run the following command:

```bash
docker run -p 4000:4000 \
  -p 15432:15432 \
  -v ${PWD}:/cube/conf \
  -e CUBEJS_DEV_MODE=true \
  cubejs/cube
```

Then, open http://localhost:4000 in your browser to continue setup.

For a step-by-step guide on Docker, [see the docs](https://cube.dev/docs/getting-started-docker?ref=github-readme).

## Resources

- [Documentation](https://cube.dev/docs?ref=github-readme)
- [Getting Started](https://cube.dev/docs/getting-started?ref=github-readme)
- [Examples &amp; Tutorials](https://cube.dev/docs/examples?ref=github-readme)
- [Architecture](https://cube.dev/docs/product/introduction#four-layers-of-semantic-layer)

## Contributing

There are many ways you can contribute to Cube! Here are a few possibilities:

* Star this repo and follow us on [X](https://twitter.com/the_cube_dev).
* Add Cube to your stack on [Stackshare](https://stackshare.io/cube-js).
* Upvote issues with 👍 reaction so we know what&#039;s the demand for particular issue to prioritize it within road map.
* Create issues every time you feel something is missing or goes wrong.
* Ask questions on [Stack Overflow with cube.js tag](https://stackoverflow.com/questions/tagged/cube.js) if others can have these questions as well.
* Provide pull requests for all open issues and especially for those with [help wanted](https://github.com/cube-js/cube/issues?q=is%3Aissue+is%3Aopen+label%3A&quot;help+wanted&quot;) and [good first issue](https://github.com/cube-js/cube/issues?q=is%3Aissue+is%3Aopen+label%3A&quot;good+first+issue&quot;) labels.

All sort of contributions are **welcome and extremely helpful** 🙌 Please refer to [the contribution guide](https://github.com/cube-js/cube/blob/master/CONTRIBUTING.md) for more information.

## License

Cube Client is [MIT licensed](./packages/cubejs-client-core/LICENSE).

Cube Backend is [Apache 2.0 licensed](./packages/cubejs-server/LICENSE).


[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[signalapp/libsignal]]></title>
            <link>https://github.com/signalapp/libsignal</link>
            <guid>https://github.com/signalapp/libsignal</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[Home to the Signal Protocol as well as other cryptographic primitives which make Signal possible.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/signalapp/libsignal">signalapp/libsignal</a></h1>
            <p>Home to the Signal Protocol as well as other cryptographic primitives which make Signal possible.</p>
            <p>Language: Rust</p>
            <p>Stars: 4,672</p>
            <p>Forks: 565</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># Overview

libsignal contains platform-agnostic APIs used by the official Signal clients and servers, exposed
as a Java, Swift, or TypeScript library. The underlying implementations are written in Rust:

- libsignal-protocol: Implements the Signal protocol, including the [Double Ratchet algorithm][]. A
  replacement for [libsignal-protocol-java][] and [libsignal-metadata-java][].
- signal-crypto: Cryptographic primitives such as AES-GCM. We use [RustCrypto][]&#039;s where we can
  but sometimes have differing needs.
- device-transfer: Support logic for Signal&#039;s device-to-device transfer feature.
- attest: Functionality for remote attestation of [SGX enclaves][] and server-side [HSMs][].
- zkgroup: Functionality for [zero-knowledge groups][] and related features available in Signal.
- zkcredential: An abstraction for the sort of zero-knowledge credentials used by zkgroup, based on the paper &quot;[The Signal Private Group System][]&quot; by Chase, Perrin, and Zaverucha.
- poksho: Utilities for implementing zero-knowledge proofs (such as those used by zkgroup); stands for &quot;proof-of-knowledge, stateful-hash-object&quot;.
- account-keys: Functionality for consistently using [PINs][] as passwords in Signal&#039;s Secure Value Recovery system, as well as other account-wide key operations.
- usernames: Functionality for username generation, hashing, and proofs.
- media: Utilities for manipulating media.

This repository is used by the Signal client apps ([Android][], [iOS][], and [Desktop][]) as well as
server-side. Use outside of Signal is unsupported. In particular, the products of this repository
are the Java, Swift, and TypeScript libraries that wrap the underlying Rust implementations. All
APIs and implementations are subject to change without notice, as are the JNI, C, and Node add-on
&quot;bridge&quot; layers. However, backwards-incompatible changes to the Java, Swift, TypeScript, and
non-bridge Rust APIs will be reflected in the version number on a best-effort basis, including
increases to the minimum supported tools versions.

[Double Ratchet algorithm]: https://signal.org/docs/
[libsignal-protocol-java]: https://github.com/signalapp/libsignal-protocol-java
[libsignal-metadata-java]: https://github.com/signalapp/libsignal-metadata-java
[RustCrypto]: https://github.com/RustCrypto
[Noise protocol]: http://noiseprotocol.org/
[SGX enclaves]: https://www.intel.com/content/www/us/en/architecture-and-technology/software-guard-extensions.html
[HSMs]: https://en.wikipedia.org/wiki/Hardware_security_module
[zero-knowledge groups]: https://signal.org/blog/signal-private-group-system/
[The Signal Private Group System]: https://eprint.iacr.org/2019/1416.pdf
[PINs]: https://signal.org/blog/signal-pins/
[Android]: https://github.com/signalapp/Signal-Android
[iOS]: https://github.com/signalapp/Signal-iOS
[Desktop]: https://github.com/signalapp/Signal-Desktop


# Building

### Toolchain Installation

To build anything in this repository you must have [Rust](https://rust-lang.org) installed,
as well as Clang, libclang, [CMake](https://cmake.org), Make, protoc, and git.

#### Linux/Debian

On a Debian-like system, you can get these extra dependencies through `apt`:

```shell
$ apt-get install clang libclang-dev cmake make protobuf-compiler git
```

#### macOS

On macOS, we have a best-effort maintained script to set up the Rust toolchain you can run by:

```shell
$ bin/mac_setup.sh
```

## Rust

### First Build and Test

The build currently uses a specific version of the Rust nightly compiler, which
will be downloaded automatically by cargo. To build and test the basic protocol
libraries:

```shell
$ cargo build
...
$ cargo test
...
```

### Additional Rust Tools

The basic tools above should get you set up for most libsignal Rust development. 

Eventually, you may find that you need some additional Rust tools like `cbindgen` to modify the bridges to the 
client libraries or `taplo` for code formatting. 

You should always install any Rust tools you need that may affect the build from cargo rather than from your system
package manager (e.g. `apt` or `brew`). Package managers sometimes contain outdated versions of these tools that can break
the build with incompatibility issues (especially cbindgen).

To install the main Rust extra dependencies matching the versions we use, you can run the following commands: 

```shell
$ cargo +stable install cbindgen cargo-fuzz
$ cargo +stable install --version &quot;$(cat ../acknowledgments/cargo-about-version)&quot; --locked cargo-about
$ cargo +stable install --version &quot;$(cat ../.taplo-cli-version)&quot; --locked taplo-cli
```

## Java/Android

### Toolchain Setup / Configuration

To build for Android you must install several additional packages including a JDK,
the Android NDK/SDK, and add the Android targets to the Rust compiler, using

```rustup target add armv7-linux-androideabi aarch64-linux-android i686-linux-android x86_64-linux-android```

Our officially supported JDK version for Android builds is JDK 17, so be sure to install e.g. OpenJDK 17, and then point JAVA_HOME to it.

You can easily do this on macOS via:

```shell
export JAVA_HOME=$(/usr/libexec/java_home -v 17)
```

On Linux, the way you do this varies by distribution. For Debian based distributions like Ubuntu, you can use:

```shell
sudo update-alternatives --config java
```

We also check-in a `.tools_version` file for use with runtime version managers.

### Building and Testing

To build the Java/Android ``jar`` and ``aar``, and run the tests:

```shell
$ cd java
$ ./gradlew test
$ ./gradlew build # if you need AAR outputs
```

You can pass `-P debugLevelLogs` to Gradle to build without filtering out debug- and verbose-level
logs from Rust, and `-P jniTypeTagging` to enable additional checks in the Rust JNI bridging code.

Alternately, a build system using Docker is available:

```shell
$ cd java
$ make
```

When exposing new APIs to Java, you will need to run `rust/bridge/jni/bin/gen_java_decl.py` in
addition to rebuilding. This requires installing the `cbindgen` Rust tool, as detailed above. 

### Maven Central

Signal publishes Java packages on [Maven Central](https://central.sonatype.org) for its own use,
under the names org.signal:libsignal-server, org.signal:libsignal-client, and
org.signal:libsignal-android. libsignal-client and libsignal-server contain native libraries for
Debian-flavored x86_64 Linux as well as Windows (x86_64) and macOS (x86_64 and arm64).
libsignal-android contains native libraries for armeabi-v7a, arm64-v8a, x86, and x86_64 Android.

When building for Android you need *both* libsignal-android and libsignal-client, but the Windows
and macOS libraries in libsignal-client won&#039;t automatically be excluded from your final app. You can
explicitly exclude them using `packagingOptions`:

```
android {
  // ...
  packagingOptions {
    resources {
      excludes += setOf(&quot;libsignal_jni*.dylib&quot;, &quot;signal_jni*.dll&quot;)
    }
  }
  // ...
}
```

You can additionally exclude `libsignal_jni_testing.so` if you do not plan to use any of the APIs
intended for client testing.


## Swift

To learn about the Swift build process see [``swift/README.md``](swift/)


## Node

You&#039;ll need Node installed to build. If you have [nvm][], you can run `nvm use` to select an
appropriate version automatically.

We use `npm` as our package manager, and `node-gyp` to control building the Rust library.

```shell
$ cd node
$ nvm use
$ npm install
$ npx node-gyp rebuild  # clean-&gt;configure-&gt;build
$ npm run tsc
$ npm run test
```

When testing changes locally, you can use `npm run build` to do an incremental rebuild of the Rust library. Alternately, `npm run build-with-debug-level-logs` will rebuild without filtering out debug- and verbose-level logs.

When exposing new APIs to Node, you will need to run `rust/bridge/node/bin/gen_ts_decl.py` in
addition to rebuilding.

[nvm]: https://github.com/nvm-sh/nvm

### NPM

Signal publishes the NPM package `@signalapp/libsignal-client` for its own use, including native
libraries for Windows, macOS, and Debian-flavored Linux. Both x64 and arm64 builds are included for
all three platforms, but the arm64 builds for Windows and Linux are considered experimental, since
there are no official builds of Signal for those architectures.


# Contributions

Signal does accept external contributions to this project. However unless the change is
simple and easily understood, for example fixing a bug or portability issue, adding a new
test, or improving performance, first open an issue to discuss your intended change as not
all changes can be accepted.

Contributions that will not be used directly by one of Signal&#039;s official client apps may still be
considered, but only if they do not pose an undue maintenance burden or conflict with the goals of
the project.

Signing a [CLA (Contributor License Agreement)](https://signal.org/cla/) is required for all contributions.

## Code Formatting and Acknowledgments

You can run the styler on the entire project by running:

```shell
just format-all
```

You can run more extensive tests as well as linters and clippy by running:

```shell
just check-pre-commit
```

When making a PR that adjusts dependencies, you&#039;ll need to regenerate our acknowledgments files. See [``acknowledgments/README.md``](acknowledgments/).

# Legal things
## Cryptography Notice

This distribution includes cryptographic software. The country in which you currently reside may have restrictions on
the import, possession, use, and/or re-export to another country, of encryption software.  BEFORE using any encryption
software, please check your country&#039;s laws, regulations and policies concerning the import, possession, or use, and
re-export of encryption software, to see if this is permitted.  See &lt;http://www.wassenaar.org/&gt; for more information.

The U.S. Government Department of Commerce, Bureau of Industry and Security (BIS), has classified this software as
Export Commodity Control Number (ECCN) 5D002.C.1, which includes information security software using or performing
cryptographic functions with asymmetric algorithms.  The form and manner of this distribution makes it eligible for
export under the License Exception ENC Technology Software Unrestricted (TSU) exception (see the BIS Export
Administration Regulations, Section 740.13) for both object code and source code.

## License

Copyright 2020-2024 Signal Messenger, LLC

Licensed under the GNU AGPLv3: https://www.gnu.org/licenses/agpl-3.0.html
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[DioxusLabs/dioxus]]></title>
            <link>https://github.com/DioxusLabs/dioxus</link>
            <guid>https://github.com/DioxusLabs/dioxus</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[Fullstack app framework for web, desktop, and mobile.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/DioxusLabs/dioxus">DioxusLabs/dioxus</a></h1>
            <p>Fullstack app framework for web, desktop, and mobile.</p>
            <p>Language: Rust</p>
            <p>Stars: 30,165</p>
            <p>Forks: 1,260</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre>&lt;p&gt;
    &lt;p align=&quot;center&quot; &gt;
      &lt;!-- &lt;img src=&quot;./notes/header-light-updated.svg#gh-light-mode-only&quot; &gt;
      &lt;img src=&quot;./notes/header-dark-updated.svg#gh-dark-mode-only&quot; &gt; --&gt;
      &lt;!-- &lt;a href=&quot;https://dioxuslabs.com&quot;&gt;
          &lt;img src=&quot;./notes/flat-splash.avif&quot;&gt;
      &lt;/a&gt; --&gt;
      &lt;img src=&quot;./notes/splash-header-darkmode.svg#gh-dark-mode-only&quot; style=&quot;width: 80%; height: auto;&quot;&gt;
      &lt;img src=&quot;./notes/splash-header.svg#gh-light-mode-only&quot; style=&quot;width: 80%; height: auto;&quot;&gt;
      &lt;img src=&quot;./notes/image-splash.avif&quot;&gt;
      &lt;br&gt;
    &lt;/p&gt;
&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Crates version --&gt;
  &lt;a href=&quot;https://crates.io/crates/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/dioxus.svg?style=flat-square&quot;
    alt=&quot;Crates.io version&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Downloads --&gt;
  &lt;a href=&quot;https://crates.io/crates/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/d/dioxus.svg?style=flat-square&quot;
      alt=&quot;Download&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- docs --&gt;
  &lt;a href=&quot;https://docs.rs/dioxus&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square&quot;
      alt=&quot;docs.rs docs&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- CI --&gt;
  &lt;a href=&quot;https://github.com/jkelleyrtp/dioxus/actions&quot;&gt;
    &lt;img src=&quot;https://github.com/dioxuslabs/dioxus/actions/workflows/main.yml/badge.svg&quot;
      alt=&quot;CI status&quot; /&gt;
  &lt;/a&gt;

  &lt;!--Awesome --&gt;
  &lt;a href=&quot;https://dioxuslabs.com/awesome&quot;&gt;
    &lt;img src=&quot;https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg&quot; alt=&quot;Awesome Page&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Discord --&gt;
  &lt;a href=&quot;https://discord.gg/XgGxMSkvUM&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/899851952891002890.svg?logo=discord&amp;style=flat-square&quot; alt=&quot;Discord Link&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;
    &lt;a href=&quot;https://dioxuslabs.com&quot;&gt; Website &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/tree/main/examples&quot;&gt; Examples &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://dioxuslabs.com/learn/0.6/guide&quot;&gt; Guide &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/zh-cn/README.md&quot;&gt; 中文 &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/pt-br/README.md&quot;&gt; PT-BR &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/ja-jp/README.md&quot;&gt; 日本語 &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/tr-tr&quot;&gt; Türkçe &lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/blob/main/translations/ko-kr&quot;&gt; 한국어 &lt;/a&gt;
  &lt;/h3&gt;
&lt;/div&gt;
&lt;br&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/DioxusLabs/dioxus/releases/tag/v0.7.0-alpha.0&quot;&gt;✨ Dioxus 0.7 is in alpha - test it out! ✨&lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;

Build for web, desktop, and mobile, and more with a single codebase. Zero-config setup, integrated hot-reloading, and signals-based state management. Add backend functionality with Server Functions and bundle with our CLI.

```rust
fn app() -&gt; Element {
    let mut count = use_signal(|| 0);

    rsx! {
        h1 { &quot;High-Five counter: {count}&quot; }
        button { onclick: move |_| count += 1, &quot;Up high!&quot; }
        button { onclick: move |_| count -= 1, &quot;Down low!&quot; }
    }
}
```

## ⭐️ Unique features:

- Cross-platform apps in three lines of code (web, desktop, mobile, server, and more)
- [Ergonomic state management](https://dioxuslabs.com/blog/release-050) combines the best of React, Solid, and Svelte
- Built-in featureful, type-safe, fullstack web framework
- Integrated bundler for deploying to the web, macOS, Linux, and Windows
- Subsecond Rust hot-patching and asset hot-reloading
- And more! [Take a tour of Dioxus](https://dioxuslabs.com/learn/0.6/).

## Instant hot-reloading

With one command, `dx serve` and your app is running. Edit your markup, styles, and see changes in milliseconds. Use our experimental `dx serve --hotpatch` to update Rust code in real time.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/hotreload-video.webp&quot;&gt;
  &lt;!-- &lt;video src=&quot;https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov&quot; width=&quot;500&quot;&gt;&lt;/video&gt; --&gt;
  &lt;!-- &lt;video src=&quot;https://private-user-images.githubusercontent.com/10237910/386919031-6da371d5-3340-46da-84ff-628216851ba6.mov&quot; width=&quot;500&quot;&gt;&lt;/video&gt; --&gt;
&lt;/div&gt;

## Build Beautiful Apps

Dioxus apps are styled with HTML and CSS. Use the built-in TailwindCSS support or load your favorite CSS library. Easily call into native code (objective-c, JNI, Web-Sys) for a perfect native touch.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/ebou2.avif&quot;&gt;
&lt;/div&gt;


## Experimental Native Renderer

Render using web-sys, webview, server-side-rendering, liveview, or even with our experimental WGPU-based renderer. Embed Dioxus in Bevy, WGPU, or even run on embedded Linux!

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/native-blitz-wgpu.webp&quot;&gt;
&lt;/div&gt;


## First-party primitive components

Get started quickly with a complete set of primitives modeled after shadcn/ui and Radix-Primitives.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/primitive-components.avif&quot;&gt;
&lt;/div&gt;

## First-class Android and iOS support

Dioxus is the fastest way to build native mobile apps with Rust. Simply run `dx serve --platform android` and your app is running in an emulator or on device in seconds. Call directly into JNI and Native APIs.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/android_and_ios2.avif&quot; width=&quot;500&quot;&gt;
&lt;/div&gt;


## Productive, typesafe, fullstack web framework

Directly call your backend from your frontend with our built-in type-safe RPC using [`server_fn`](http://crates.io/crates/server_fn). Supports streaming, suspense, bundle splitting, websockets, and more.

```rust
fn app() -&gt; Element {
  let mut fortune = use_signal(|| &quot;Fetch a fortune!&quot;);
  rsx! {
    h1 { &quot;{fortune}&quot; }
    button {
      onclick: move |_| async move {
        fortune.set(fetch_fortune().await.unwrap());
      }
    }
  }
}

#[server]
async fn fetch_fortune() -&gt; ServerFnResult&lt;String&gt; {
  &quot;Dioxus is super productive!&quot;.to_string()
}
```

## Bundle for web, desktop, and mobile

Simply run `dx bundle` and your app will be built and bundled with maximization optimizations. On the web, take advantage of [`.avif` generation, `.wasm` compression, minification](https://dioxuslabs.com/learn/0.6/guides/assets), and more. Build WebApps weighing [less than 50kb](https://github.com/ealmloff/tiny-dioxus/) and desktop/mobile apps less than 5mb.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/bundle.gif&quot;&gt;
&lt;/div&gt;


## Fantastic documentation

We&#039;ve put a ton of effort into building clean, readable, and comprehensive documentation. All html elements and listeners are documented with MDN docs, and our Docs runs continuous integration with Dioxus itself to ensure that the docs are always up to date. Check out the [Dioxus website](https://dioxuslabs.com/learn/0.6/) for guides, references, recipes, and more. Fun fact: we use the Dioxus website as a testbed for new Dioxus features - [check it out!](https://github.com/dioxusLabs/docsite)

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/docs.avif&quot;&gt;
&lt;/div&gt;


## Modular and Customizable

Build your own renderer, or use a community renderer like [Freya](http://freyaui.dev). Use our modular components like RSX, VirtualDom, Blitz, Taffy, and Subsecond.


&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/DioxusLabs/screenshots/refs/heads/main/blitz/freya-todo-example.webp&quot;&gt;
&lt;/div&gt;

## Community

Dioxus is a community-driven project, with a very active [Discord](https://discord.gg/XgGxMSkvUM) and [GitHub](https://github.com/DioxusLabs/dioxus/issues) community. We&#039;re always looking for help, and we&#039;re happy to answer questions and help you get started. [Our SDK](https://github.com/DioxusLabs/dioxus-std) is community-run and we even have a [GitHub organization](https://github.com/dioxus-community/) for the best Dioxus crates that receive free upgrades and support.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;./notes/dioxus-community.avif&quot;&gt;
&lt;/div&gt;

## Full-time core team

Dioxus has grown from a side project to a small team of fulltime engineers. Thanks to the generous support of FutureWei, Satellite.im, the GitHub Accelerator program, we&#039;re able to work on Dioxus full-time. Our long term goal is for Dioxus to become self-sustaining by providing paid high-quality enterprise tools. If your company is interested in adopting Dioxus and would like to work with us, please reach out!

## Supported Platforms

&lt;div align=&quot;center&quot;&gt;
  &lt;table style=&quot;width:100%&quot;&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Web&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render directly to the DOM using WebAssembly&lt;/li&gt;
          &lt;li&gt;Pre-render with SSR and rehydrate on the client&lt;/li&gt;
          &lt;li&gt;Simple &quot;hello world&quot; at about 50kb, comparable to React&lt;/li&gt;
          &lt;li&gt;Built-in dev server and hot reloading for quick iteration&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Desktop&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render using Webview or - experimentally - with WGPU or &lt;a href=&quot;https://freyaui.dev&quot;&gt;Freya&lt;/a&gt; (Skia) &lt;/li&gt;
          &lt;li&gt;Zero-config setup. Simply `cargo run` or `dx serve` to build your app &lt;/li&gt;
          &lt;li&gt;Full support for native system access without IPC &lt;/li&gt;
          &lt;li&gt;Supports macOS, Linux, and Windows. Portable &lt;3mb binaries &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Mobile&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Render using Webview or - experimentally - with WGPU or Skia &lt;/li&gt;
          &lt;li&gt;Build .ipa and .apk files for iOS and Android &lt;/li&gt;
          &lt;li&gt;Call directly into Java and Objective-C with minimal overhead&lt;/li&gt;
          &lt;li&gt;From &quot;hello world&quot; to running on device in seconds&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;
      &lt;b&gt;Server-side Rendering&lt;/b&gt;
      &lt;/td&gt;
      &lt;td&gt;
        &lt;ul&gt;
          &lt;li&gt;Suspense, hydration, and server-side rendering&lt;/li&gt;
          &lt;li&gt;Quickly drop in backend functionality with server functions&lt;/li&gt;
          &lt;li&gt;Extractors, middleware, and routing integrations&lt;/li&gt;
          &lt;li&gt;Static-site generation and incremental regeneration&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

## Running the examples

&gt; The examples in the main branch of this repository target the git version of dioxus and the CLI. If you are looking for examples that work with the latest stable release of dioxus, check out the [0.6 branch](https://github.com/DioxusLabs/dioxus/tree/v0.6/examples).

The examples in the top level of this repository can be run with:

```sh
cargo run --example &lt;example&gt;
```

However, we encourage you to download the dioxus-cli to test out features like hot-reloading. To install the most recent binary CLI, you can use cargo binstall.

```sh
cargo binstall dioxus-cli@0.7.0-rc.0 --force
```

If this CLI is out-of-date, you can install it directly from git

```sh
cargo install --git https://github.com/DioxusLabs/dioxus dioxus-cli --locked
```

With the CLI, you can also run examples with the web platform. You will need to disable the default desktop feature and enable the web feature with this command:

```sh
dx serve --example &lt;example&gt; --platform web -- --no-default-features
```

## Contributing

- Check out the website [section on contributing](https://dioxuslabs.com/learn/0.6/contributing).
- Report issues on our [issue tracker](https://github.com/dioxuslabs/dioxus/issues).
- [Join](https://discord.gg/XgGxMSkvUM) the discord and ask questions!

&lt;a href=&quot;https://github.com/dioxuslabs/dioxus/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=dioxuslabs/dioxus&amp;max=30&amp;columns=10&quot; /&gt;
&lt;/a&gt;

## License

This project is licensed under either the [MIT license] or the [Apache-2 License].

[apache-2 license]: https://github.com/DioxusLabs/dioxus/blob/master/LICENSE-APACHE
[mit license]: https://github.com/DioxusLabs/dioxus/blob/master/LICENSE-MIT

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Dioxus by you, shall be licensed as MIT or Apache-2, without any additional
terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 65,554</p>
            <p>Forks: 1,916</p>
            <p>Stars today: 99 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- 🚀 A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`,
  and more.
- ⚡️ [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- 🗂️ Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- ❇️ [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- 🐍 [Installs and manages](#python-versions) Python versions.
- 🛠️ [Runs and installs](#tools) tools published as Python packages.
- 🔩 Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a
  familiar CLI.
- 🏢 Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- 💾 Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- ⏬ Installable without Rust or Python via `curl` or `pip`.
- 🖥️ Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows — and experience a 10-100x speedup — with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Platform support

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

## Versioning policy

See uv&#039;s [versioning policy](https://docs.astral.sh/uv/reference/versioning/) document.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv/blob/main/CONTRIBUTING.md) to get started.

## FAQ

#### How do you pronounce uv?

It&#039;s pronounced as &quot;you - vee&quot; ([`/juː viː/`](https://en.wikipedia.org/wiki/Help:IPA/English#Key))

#### How should I stylize uv?

Just &quot;uv&quot;, please. See the [style guide](./STYLE.md#styling-uv) for details.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[pola-rs/polars]]></title>
            <link>https://github.com/pola-rs/polars</link>
            <guid>https://github.com/pola-rs/polars</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[Dataframes powered by a multithreaded, vectorized query engine, written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pola-rs/polars">pola-rs/polars</a></h1>
            <p>Dataframes powered by a multithreaded, vectorized query engine, written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 35,004</p>
            <p>Forks: 2,362</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pola.rs&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/pola-rs/polars-static/master/banner/polars_github_banner.svg&quot; alt=&quot;Polars logo&quot;&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://crates.io/crates/polars&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/polars.svg&quot; alt=&quot;crates.io Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pypi.org/project/polars/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/v/polars.svg&quot; alt=&quot;PyPi Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/nodejs-polars&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/nodejs-polars.svg&quot; alt=&quot;NPM Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://community.r-multiverse.org/polars&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fcommunity.r-multiverse.org%2Fapi%2Fpackages%2Fpolars&amp;query=%24.Version&amp;label=r-multiverse&quot; alt=&quot;R-multiverse Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://doi.org/10.5281/zenodo.7697217&quot;&gt;
    &lt;img src=&quot;https://zenodo.org/badge/DOI/10.5281/zenodo.7697217.svg&quot; alt=&quot;DOI Latest Release&quot;/&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Documentation&lt;/b&gt;:
  &lt;a href=&quot;https://docs.pola.rs/api/python/stable/reference/index.html&quot;&gt;Python&lt;/a&gt;
  -
  &lt;a href=&quot;https://docs.rs/polars/latest/polars/&quot;&gt;Rust&lt;/a&gt;
  -
  &lt;a href=&quot;https://pola-rs.github.io/nodejs-polars/index.html&quot;&gt;Node.js&lt;/a&gt;
  -
  &lt;a href=&quot;https://pola-rs.github.io/r-polars/index.html&quot;&gt;R&lt;/a&gt;
  |
  &lt;b&gt;StackOverflow&lt;/b&gt;:
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/python-polars&quot;&gt;Python&lt;/a&gt;
  -
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/rust-polars&quot;&gt;Rust&lt;/a&gt;
  -
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/nodejs-polars&quot;&gt;Node.js&lt;/a&gt;
  -
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/r-polars&quot;&gt;R&lt;/a&gt;
  |
  &lt;a href=&quot;https://docs.pola.rs/&quot;&gt;User guide&lt;/a&gt;
  |
  &lt;a href=&quot;https://discord.gg/4UfP5cfBE7&quot;&gt;Discord&lt;/a&gt;
&lt;/p&gt;

## Polars: Blazingly fast DataFrames in Rust, Python, Node.js, R, and SQL

Polars is a DataFrame interface on top of an OLAP Query Engine implemented in Rust using
[Apache Arrow Columnar Format](https://arrow.apache.org/docs/format/Columnar.html) as the memory
model.

- Lazy | eager execution
- Multi-threaded
- SIMD
- Query optimization
- Powerful expression API
- Hybrid Streaming (larger-than-RAM datasets)
- Rust | Python | NodeJS | R | ...

To learn more, read the [user guide](https://docs.pola.rs/).

## Python

```python
&gt;&gt;&gt; import polars as pl
&gt;&gt;&gt; df = pl.DataFrame(
...     {
...         &quot;A&quot;: [1, 2, 3, 4, 5],
...         &quot;fruits&quot;: [&quot;banana&quot;, &quot;banana&quot;, &quot;apple&quot;, &quot;apple&quot;, &quot;banana&quot;],
...         &quot;B&quot;: [5, 4, 3, 2, 1],
...         &quot;cars&quot;: [&quot;beetle&quot;, &quot;audi&quot;, &quot;beetle&quot;, &quot;beetle&quot;, &quot;beetle&quot;],
...     }
... )

# embarrassingly parallel execution &amp; very expressive query language
&gt;&gt;&gt; df.sort(&quot;fruits&quot;).select(
...     &quot;fruits&quot;,
...     &quot;cars&quot;,
...     pl.lit(&quot;fruits&quot;).alias(&quot;literal_string_fruits&quot;),
...     pl.col(&quot;B&quot;).filter(pl.col(&quot;cars&quot;) == &quot;beetle&quot;).sum(),
...     pl.col(&quot;A&quot;).filter(pl.col(&quot;B&quot;) &gt; 2).sum().over(&quot;cars&quot;).alias(&quot;sum_A_by_cars&quot;),
...     pl.col(&quot;A&quot;).sum().over(&quot;fruits&quot;).alias(&quot;sum_A_by_fruits&quot;),
...     pl.col(&quot;A&quot;).reverse().over(&quot;fruits&quot;).alias(&quot;rev_A_by_fruits&quot;),
...     pl.col(&quot;A&quot;).sort_by(&quot;B&quot;).over(&quot;fruits&quot;).alias(&quot;sort_A_by_B_by_fruits&quot;),
... )
shape: (5, 8)
┌──────────┬──────────┬──────────────┬─────┬─────────────┬─────────────┬─────────────┬─────────────┐
│ fruits   ┆ cars     ┆ literal_stri ┆ B   ┆ sum_A_by_ca ┆ sum_A_by_fr ┆ rev_A_by_fr ┆ sort_A_by_B │
│ ---      ┆ ---      ┆ ng_fruits    ┆ --- ┆ rs          ┆ uits        ┆ uits        ┆ _by_fruits  │
│ str      ┆ str      ┆ ---          ┆ i64 ┆ ---         ┆ ---         ┆ ---         ┆ ---         │
│          ┆          ┆ str          ┆     ┆ i64         ┆ i64         ┆ i64         ┆ i64         │
╞══════════╪══════════╪══════════════╪═════╪═════════════╪═════════════╪═════════════╪═════════════╡
│ &quot;apple&quot;  ┆ &quot;beetle&quot; ┆ &quot;fruits&quot;     ┆ 11  ┆ 4           ┆ 7           ┆ 4           ┆ 4           │
│ &quot;apple&quot;  ┆ &quot;beetle&quot; ┆ &quot;fruits&quot;     ┆ 11  ┆ 4           ┆ 7           ┆ 3           ┆ 3           │
│ &quot;banana&quot; ┆ &quot;beetle&quot; ┆ &quot;fruits&quot;     ┆ 11  ┆ 4           ┆ 8           ┆ 5           ┆ 5           │
│ &quot;banana&quot; ┆ &quot;audi&quot;   ┆ &quot;fruits&quot;     ┆ 11  ┆ 2           ┆ 8           ┆ 2           ┆ 2           │
│ &quot;banana&quot; ┆ &quot;beetle&quot; ┆ &quot;fruits&quot;     ┆ 11  ┆ 4           ┆ 8           ┆ 1           ┆ 1           │
└──────────┴──────────┴──────────────┴─────┴─────────────┴─────────────┴─────────────┴─────────────┘
```

## SQL

```python
&gt;&gt;&gt; df = pl.scan_csv(&quot;docs/assets/data/iris.csv&quot;)
&gt;&gt;&gt; ## OPTION 1
&gt;&gt;&gt; # run SQL queries on frame-level
&gt;&gt;&gt; df.sql(&quot;&quot;&quot;
...	SELECT species,
...	  AVG(sepal_length) AS avg_sepal_length
...	FROM self
...	GROUP BY species
...	&quot;&quot;&quot;).collect()
shape: (3, 2)
┌────────────┬──────────────────┐
│ species    ┆ avg_sepal_length │
│ ---        ┆ ---              │
│ str        ┆ f64              │
╞════════════╪══════════════════╡
│ Virginica  ┆ 6.588            │
│ Versicolor ┆ 5.936            │
│ Setosa     ┆ 5.006            │
└────────────┴──────────────────┘
&gt;&gt;&gt; ## OPTION 2
&gt;&gt;&gt; # use pl.sql() to operate on the global context
&gt;&gt;&gt; df2 = pl.LazyFrame({
...    &quot;species&quot;: [&quot;Setosa&quot;, &quot;Versicolor&quot;, &quot;Virginica&quot;],
...    &quot;blooming_season&quot;: [&quot;Spring&quot;, &quot;Summer&quot;, &quot;Fall&quot;]
...})
&gt;&gt;&gt; pl.sql(&quot;&quot;&quot;
... SELECT df.species,
...     AVG(df.sepal_length) AS avg_sepal_length,
...     df2.blooming_season
... FROM df
... LEFT JOIN df2 ON df.species = df2.species
... GROUP BY df.species, df2.blooming_season
... &quot;&quot;&quot;).collect()
```

SQL commands can also be run directly from your terminal using the Polars CLI:

```bash
# run an inline SQL query
&gt; polars -c &quot;SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv(&#039;docs/assets/data/iris.csv&#039;) GROUP BY species;&quot;

# run interactively
&gt; polars
Polars CLI v0.3.0
Type .help for help.

&gt; SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv(&#039;docs/assets/data/iris.csv&#039;) GROUP BY species;
```

Refer to the [Polars CLI repository](https://github.com/pola-rs/polars-cli) for more information.

## Performance 🚀🚀

### Blazingly fast

Polars is very fast. In fact, it is one of the best performing solutions available. See the
[PDS-H benchmarks](https://www.pola.rs/benchmarks.html) results.

### Lightweight

Polars is also very lightweight. It comes with zero required dependencies, and this shows in the
import times:

- polars: 70ms
- numpy: 104ms
- pandas: 520ms

### Handles larger-than-RAM data

If you have data that does not fit into memory, Polars&#039; query engine is able to process your query
(or parts of your query) in a streaming fashion. This drastically reduces memory requirements, so
you might be able to process your 250GB dataset on your laptop. Collect with
`collect(engine=&#039;streaming&#039;)` to run the query streaming. (This might be a little slower, but it is
still very fast!)

## Setup

### Python

Install the latest Polars version with:

```sh
pip install polars
```

We also have a conda package (`conda install -c conda-forge polars`), however pip is the preferred
way to install Polars.

Install Polars with all optional dependencies.

```sh
pip install &#039;polars[all]&#039;
```

You can also install a subset of all optional dependencies.

```sh
pip install &#039;polars[numpy,pandas,pyarrow]&#039;
```

See the [User Guide](https://docs.pola.rs/user-guide/installation/#feature-flags) for more details
on optional dependencies

To see the current Polars version and a full list of its optional dependencies, run:

```python
pl.show_versions()
```

Releases happen quite often (weekly / every few days) at the moment, so updating Polars regularly to
get the latest bugfixes / features might not be a bad idea.

### Rust

You can take latest release from `crates.io`, or if you want to use the latest features /
performance improvements point to the `main` branch of this repo.

```toml
polars = { git = &quot;https://github.com/pola-rs/polars&quot;, rev = &quot;&lt;optional git tag&gt;&quot; }
```

Requires Rust version `&gt;=1.80`.

## Contributing

Want to contribute? Read our [contributing guide](https://docs.pola.rs/development/contributing/).

## Python: compile Polars from source

If you want a bleeding edge release or maximal performance you should compile Polars from source.

This can be done by going through the following steps in sequence:

1. Install the latest [Rust compiler](https://www.rust-lang.org/tools/install)
2. Install [maturin](https://maturin.rs/): `pip install maturin`
3. `cd py-polars` and choose one of the following:
   - `make build`, slow binary with debug assertions and symbols, fast compile times
   - `make build-release`, fast binary without debug assertions, minimal debug symbols, long compile
     times
   - `make build-nodebug-release`, same as build-release but without any debug symbols, slightly
     faster to compile
   - `make build-debug-release`, same as build-release but with full debug symbols, slightly slower
     to compile
   - `make build-dist-release`, fastest binary, extreme compile times

By default the binary is compiled with optimizations turned on for a modern CPU. Specify `LTS_CPU=1`
with the command if your CPU is older and does not support e.g. AVX2.

Note that the Rust crate implementing the Python bindings is called `py-polars` to distinguish from
the wrapped Rust crate `polars` itself. However, both the Python package and the Python module are
named `polars`, so you can `pip install polars` and `import polars`.

## Using custom Rust functions in Python

Extending Polars with UDFs compiled in Rust is easy. We expose PyO3 extensions for `DataFrame` and
`Series` data structures. See more in https://github.com/pola-rs/polars/tree/main/pyo3-polars.

## Going big...

Do you expect more than 2^32 (~4.2 billion) rows? Compile Polars with the `bigidx` feature flag or,
for Python users, install `pip install polars-u64-idx`.

Don&#039;t use this unless you hit the row boundary as the default build of Polars is faster and consumes
less memory.

## Legacy

Do you want Polars to run on an old CPU (e.g. dating from before 2011), or on an `x86-64` build of
Python on Apple Silicon under Rosetta? Install `pip install polars-lts-cpu`. This version of Polars
is compiled without [AVX](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions) target features.

## Sponsors

[&lt;img src=&quot;https://www.jetbrains.com/company/brand/img/jetbrains_logo.png&quot; height=&quot;50&quot; alt=&quot;JetBrains logo&quot; /&gt;](https://www.jetbrains.com)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ai-dynamo/dynamo]]></title>
            <link>https://github.com/ai-dynamo/dynamo</link>
            <guid>https://github.com/ai-dynamo/dynamo</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[A Datacenter Scale Distributed Inference Serving Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo</a></h1>
            <p>A Datacenter Scale Distributed Inference Serving Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 4,791</p>
            <p>Forks: 550</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;
![Dynamo banner](./docs/images/frontpage-banner.png)

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)
[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)

| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/762)** | **[Documentation](https://docs.nvidia.com/dynamo/latest/index.html)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** |

# NVIDIA Dynamo

High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.

## Latest News

* [08/05] Deploy `openai/gpt-oss-120b` with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo [➡️ link](./components/backends/trtllm/gpt-oss.md)

## The Era of Multi-GPU, Multi-Node

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-gpu-vertical.png&quot; alt=&quot;Multi Node Multi-GPU topology&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs—and sometimes many servers—but it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.

Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:

- **Disaggregated prefill &amp; decode inference** – Maximizes GPU throughput and facilitates trade off between throughput and latency.
- **Dynamic GPU scheduling** – Optimizes performance based on fluctuating demand
- **LLM-aware request routing** – Eliminates unnecessary KV cache re-computation
- **Accelerated data transfer** – Reduces inference response time using NIXL.
- **KV cache offloading** – Leverages multiple memory hierarchies for higher system throughput

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-architecture.png&quot; alt=&quot;Dynamo architecture&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

## Framework Support Matrix

| Feature | vLLM | SGLang | TensorRT-LLM |
|---------|----------------------|----------------------------|----------------------------------------|
| [**Disaggregated Serving**](/docs/architecture/disagg_serving.md) | ✅ | ✅ | ✅ |
| [**Conditional Disaggregation**](/docs/architecture/disagg_serving.md#conditional-disaggregation) | 🚧 | 🚧 | 🚧 |
| [**KV-Aware Routing**](/docs/architecture/kv_cache_routing.md) | ✅ | ✅ | ✅ |
| [**Load Based Planner**](/docs/architecture/load_planner.md) | 🚧 | 🚧 | 🚧 |
| [**SLA-Based Planner**](/docs/architecture/sla_planner.md) | ✅ | ✅ | 🚧 |
| [**KVBM**](/docs/architecture/kvbm_architecture.md) | 🚧 | 🚧 | 🚧 |

To learn more about each framework and their capabilities, check out each framework&#039;s README!
- **[vLLM](components/backends/vllm/README.md)**
- **[SGLang](components/backends/sglang/README.md)**
- **[TensorRT-LLM](components/backends/trtllm/README.md)**

Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.

# Installation

The following examples require a few system level packages.
Recommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/support_matrix.md](docs/support_matrix.md)

## 1. Initial setup

The Dynamo team recommends the `uv` Python package manager, although any way works. Install uv:
```
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Install etcd and NATS (required)

To coordinate across a data center, Dynamo relies on etcd and NATS. To run Dynamo locally, these need to be available.

- [etcd](https://etcd.io/) can be run directly as `./etcd`.
- [nats](https://nats.io/) needs jetstream enabled: `nats-server -js`.

To quickly setup etcd &amp; NATS, you can also run:
```
# At the root of the repository:
docker compose -f deploy/docker-compose.yml up -d
```

## 2. Select an engine

We publish Python wheels specialized for each of our supported engines: vllm, sglang, trtllm, and llama.cpp. The examples that follow use SGLang; continue reading for other engines.

```
uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install &quot;ai-dynamo[sglang]&quot;  #replace with [vllm], [trtllm], etc.
```

## 3. Run Dynamo

### Running an LLM API server

Dynamo provides a simple way to spin up a local set of inference components including:

- **OpenAI Compatible Frontend** – High performance OpenAI compatible http api server written in Rust.
- **Basic and Kv Aware Router** – Route and load balance traffic to a set of workers.
- **Workers** – Set of pre-configured LLM serving engines.

```
# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
python -m dynamo.frontend --http-port 8080 [--tls-cert-path cert.pem] [--tls-key-path key.pem]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
python -m dynamo.sglang.worker --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B --skip-tokenizer-init
```

#### Send a Request

```bash
curl localhost:8080/v1/chat/completions   -H &quot;Content-Type: application/json&quot;   -d &#039;{
    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,
    &quot;messages&quot;: [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello, how are you?&quot;
    }
    ],
    &quot;stream&quot;:false,
    &quot;max_tokens&quot;: 300
  }&#039; | jq
```

Rerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.

### Deploying Dynamo

- Follow the [Quickstart Guide](docs/guides/dynamo_deploy/README.md) to deploy on Kubernetes.
- Check out [Backends](components/backends) to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)
- Run some [Examples](examples) to learn about building components in Dynamo and exploring various integrations.

# Engines

Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (`python -m dynamo.frontend [--interactive]`).

## vLLM

```
uv pip install ai-dynamo[vllm]
```

Run the backend/worker like this:
```
python -m dynamo.vllm --help
```

vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass `--context-length &lt;value&gt;`.

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

## SGLang

```
# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
```

Run the backend/worker like this:
```
python -m dynamo.sglang.worker --help
```

You can pass any sglang flags directly to this worker, see https://docs.sglang.ai/advanced_features/server_arguments.html . See there to use multiple GPUs.

## TensorRT-LLM

It is recommended to use [NGC PyTorch Container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) for running the TensorRT-LLM engine.

&gt; [!Note]
&gt; Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using.
&gt; For example, if you are using `tensorrt-llm==1.0.0rc6`, use the PyTorch container image version `25.06`.
&gt; To find the correct PyTorch container version for your desired `tensorrt-llm` release, visit the [TensorRT-LLM Dockerfile.multi](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docker/Dockerfile.multi) on GitHub. Switch to the branch that matches your `tensorrt-llm` version, and look for the `BASE_TAG` line to identify the recommended PyTorch container tag.

&gt; [!Important]
&gt; Launch container with the following additional settings `--shm-size=1g --ulimit memlock=-1`

### Install prerequisites
```
# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install &quot;cuda-python&gt;=12,&lt;13&quot;

sudo apt-get -y install libopenmpi-dev
```

&gt; [!Tip]
&gt; You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation [here](https://nvidia.github.io/TensorRT-LLM/installation/linux.html).

### After installing the pre-requisites above, install Dynamo
```
uv pip install ai-dynamo[trtllm]
```

Run the backend/worker like this:
```
python -m dynamo.trtllm --help
```

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

# Developing Locally

## 1. Install libraries

**Ubuntu:**
```
sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
```

**macOS:**
- [Homebrew](https://brew.sh/)
```
# if brew is not installed on your system, install it
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
```
- [Xcode](https://developer.apple.com/xcode/)

```
brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
```
If Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.


## 2. Install Rust

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
```

## 3. Create a Python virtual env:

Follow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don&#039;t have `uv` installed. Once uv is installed, create a virtual environment and activate it.

- Install uv
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

- Create a virtual environment
```bash
uv venv dynamo
source dynamo/bin/activate
```

## 4. Install build tools

```
uv pip install pip maturin
```

[Maturin](https://github.com/PyO3/maturin) is the Rust&lt;-&gt;Python bindings build tool.

## 5. Build the Rust bindings

```
cd lib/bindings/python
maturin develop --uv
```

## 6. Install the wheel

```
cd $PROJECT_ROOT
uv pip install .
# For development, use
export PYTHONPATH=&quot;${PYTHONPATH}:$(pwd)/components/frontend/src:$(pwd)/components/planner/src:$(pwd)/components/backends/vllm/src:$(pwd)/components/backends/sglang/src:$(pwd)/components/backends/trtllm/src:$(pwd)/components/backends/llama_cpp/src:$(pwd)/components/backends/mocker/src&quot;
```

&gt; [!Note]
&gt; Editable (`-e`) does not work because the `dynamo` package is split over multiple directories, one per backend.

You should now be able to run `python -m dynamo.frontend`.

Remember that nats and etcd must be running (see earlier).

Set the environment variable `DYN_LOG` to adjust the logging level; for example, `export DYN_LOG=debug`. It has the same syntax as `RUST_LOG`.

If you use vscode or cursor, we have a .devcontainer folder built on [Microsofts Extension](https://code.visualstudio.com/docs/devcontainers/containers). For instructions see the [ReadMe](.devcontainer/README.md) for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[linera-io/linera-protocol]]></title>
            <link>https://github.com/linera-io/linera-protocol</link>
            <guid>https://github.com/linera-io/linera-protocol</guid>
            <pubDate>Sat, 23 Aug 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[Main repository for the Linera protocol]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/linera-io/linera-protocol">linera-io/linera-protocol</a></h1>
            <p>Main repository for the Linera protocol</p>
            <p>Language: Rust</p>
            <p>Stars: 28,216</p>
            <p>Forks: 1,875</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/linera-io/linera-protocol/assets/1105398/fe08c941-93af-4114-bb83-bcc0eaec95f9&quot; width=&quot;250&quot; height=&quot;85&quot; /&gt;

[![License](https://img.shields.io/github/license/linera-io/linera-protocol)](LICENSE)
[![Build Status for Docker](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml)
[![Build Status for Rust](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml)
[![Build Status for Documentation](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml)
[![Twitter](https://img.shields.io/twitter/follow/linera_io)](https://x.com/linera_io)
[![Discord](https://img.shields.io/discord/984941796272521226)](https://discord.com/invite/linera)

&lt;!-- [![Build Status for Kubernetes](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml) --&gt;

[Linera](https://linera.io) is a decentralized blockchain infrastructure designed for highly scalable,
secure, low-latency Web3 applications.

## Documentation

Visit our [developer page](https://linera.dev) and read our
[whitepaper](https://linera.io/whitepaper) to learn more about the Linera protocol.

## Repository Structure

The main crates and directories of this repository can be summarized as follows: (listed
from low to high levels in the dependency graph)

* [`linera-base`](https://linera-io.github.io/linera-protocol/linera_base/index.html) Base
  definitions, including cryptography.

* [`linera-version`](https://linera-io.github.io/linera-protocol/linera_version/index.html)
  A library to manage version info in binaries and services.

* [`linera-views`](https://linera-io.github.io/linera-protocol/linera_views/index.html) A
  library mapping complex data structures onto a key-value store. The corresponding
  procedural macros are implemented in `linera-views-derive`.

* [`linera-execution`](https://linera-io.github.io/linera-protocol/linera_execution/index.html)
  Persistent data and the corresponding logic for runtime and execution of Linera
  applications.

* [`linera-chain`](https://linera-io.github.io/linera-protocol/linera_chain/index.html)
  Persistent data and the corresponding logic for chains of blocks, certificates, and
  cross-chain messaging.

* [`linera-storage`](https://linera-io.github.io/linera-protocol/linera_storage/index.html)
  Defines the storage abstractions for the protocol on top of `linera-chain`.

* [`linera-core`](https://linera-io.github.io/linera-protocol/linera_core/index.html) The
  core Linera protocol, including client and server logic, node synchronization, etc.

* [`linera-rpc`](https://linera-io.github.io/linera-protocol/linera_rpc/index.html)
  Defines the data-type for RPC messages (currently all client &amp;#x2194; proxy &amp;#x2194;
  chain &amp;#x2194; chain interactions), and track the corresponding data schemas.

* [`linera-client`](https://linera-io.github.io/linera-protocol/linera_client/index.html)
  Library for writing Linera clients.  Used for the command-line
  client and the node service in `linera-service`, as well as the Web
  client in [`linera-web`](https://github.com/linera-io/linera-web/).

* [`linera-service`](https://linera-io.github.io/linera-protocol/linera_service/index.html)
  Executable for clients (aka CLI wallets), proxy (aka validator frontend) and servers.

* [`linera-sdk`](https://linera-io.github.io/linera-protocol/linera_sdk/index.html) The
  library to develop Linera applications written in Rust for the Wasm virtual machine. The
  corresponding procedural macros are implemented in `linera-sdk-derive`.

* [`examples`](./examples) Examples of Linera applications written in Rust.

## Prerequisites

See [`INSTALL.md`](./INSTALL.md) for software requirements to develop in this repo.

## Quickstart with the Linera CLI tool

The following commands set up a local test network and run some transfers between the
microchains owned by a single wallet.

```bash
# Make sure to compile the Linera binaries and add them in the $PATH.
# cargo build -p linera-storage-service -p linera-service --bins
export PATH=&quot;$PWD/target/debug:$PATH&quot;

# Import the optional helper function `linera_spawn`.
source /dev/stdin &lt;&lt;&lt;&quot;$(linera net helper 2&gt;/dev/null)&quot;

# Run a local test network with the default parameters and a number of microchains
# owned by the default wallet. This also defines `LINERA_TMP_DIR`.
linera_spawn \
linera net up --with-faucet --faucet-port 8080

# Remember the URL of the faucet.
FAUCET_URL=http://localhost:8080

# If you&#039;re using a testnet, start here and run this instead:
#   LINERA_TMP_DIR=$(mktemp -d)
#   FAUCET_URL=https://faucet.testnet-XXX.linera.net  # for some value XXX

# Set the path of the future wallet.
export LINERA_WALLET=&quot;$LINERA_TMP_DIR/wallet.json&quot;
export LINERA_KEYSTORE=&quot;$LINERA_TMP_DIR/keystore.json&quot;
export LINERA_STORAGE=&quot;rocksdb:$LINERA_TMP_DIR/client.db&quot;

# Initialize a new user wallet.
linera wallet init --faucet $FAUCET_URL

# Request chains.
INFO1=($(linera wallet request-chain --faucet $FAUCET_URL))
INFO2=($(linera wallet request-chain --faucet $FAUCET_URL))
CHAIN1=&quot;${INFO1[0]}&quot;
ACCOUNT1=&quot;${INFO1[1]}&quot;
CHAIN2=&quot;${INFO2[0]}&quot;
ACCOUNT2=&quot;${INFO2[1]}&quot;

# Show the different chains tracked by the wallet.
linera wallet show

# Query the chain balance of some of the chains.
linera query-balance &quot;$CHAIN1&quot;
linera query-balance &quot;$CHAIN2&quot;

# Transfer 10 units then 5 back.
linera transfer 10 --from &quot;$CHAIN1&quot; --to &quot;$CHAIN2&quot;
linera transfer 5 --from &quot;$CHAIN2&quot; --to &quot;$CHAIN1&quot;

# Query balances again.
linera query-balance &quot;$CHAIN1&quot;
linera query-balance &quot;$CHAIN2&quot;

# Now let&#039;s fund the user balances.
linera transfer 5 --from &quot;$CHAIN1&quot; --to &quot;$CHAIN1:$ACCOUNT1&quot;
linera transfer 2 --from &quot;$CHAIN1:$ACCOUNT1&quot; --to &quot;$CHAIN2:$ACCOUNT2&quot;

# Query user balances again.
linera query-balance &quot;$CHAIN1:$ACCOUNT1&quot;
linera query-balance &quot;$CHAIN2:$ACCOUNT2&quot;
```

More complex examples may be found in our [developer manual](https://linera.dev) as well
as the [example applications](./examples) in this repository.

## Contributing

We welcome contributions from the community! If you&#039;d like to contribute to the Linera protocol:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m &#039;Add some amazing feature&#039;`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

For detailed guidelines, see our [contribution guide](./CONTRIBUTING.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[katanemo/archgw]]></title>
            <link>https://github.com/katanemo/archgw</link>
            <guid>https://github.com/katanemo/archgw</guid>
            <pubDate>Sat, 23 Aug 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[The smart edge and AI gateway for agents. Arch is a high-performance proxy server that handles the low-level work in building agents: like applying guardrails, routing prompts to the right agent, and unifying access to LLMs, etc. Natively designed to process prompts, it's framework-agnostic and helps you build agents faster.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/katanemo/archgw">katanemo/archgw</a></h1>
            <p>The smart edge and AI gateway for agents. Arch is a high-performance proxy server that handles the low-level work in building agents: like applying guardrails, routing prompts to the right agent, and unifying access to LLMs, etc. Natively designed to process prompts, it's framework-agnostic and helps you build agents faster.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,543</p>
            <p>Forks: 198</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/source/_static/img/arch-logo.png&quot; alt=&quot;Arch Logo&quot; width=&quot;75%&quot; heigh=auto&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;


_Arch is a smart proxy server designed as a modular edge and AI gateway for agents._&lt;br&gt;&lt;br&gt;
 Arch handles the *pesky low-level work* in building agentic apps — like applying guardrails, clarifying vague user input, routing prompts to the right agent, and unifying access to any LLM. It’s a language and framework friendly infrastructure layer designed to help you build and ship agentic apps faster.


[Quickstart](#Quickstart) •
[Demos](#Demos) •
[Route LLMs](#Use-Arch-as-a-LLM-Router) •
[Build agentic apps with Arch](#Build-Agentic-Apps-with-Arch) •
[Documentation](https://docs.archgw.com) •
[Contact](#Contact)

[![pre-commit](https://github.com/katanemo/arch/actions/workflows/pre-commit.yml/badge.svg)](https://github.com/katanemo/arch/actions/workflows/pre-commit.yml)
[![rust tests (prompt and llm gateway)](https://github.com/katanemo/arch/actions/workflows/rust_tests.yml/badge.svg)](https://github.com/katanemo/arch/actions/workflows/rust_tests.yml)
[![e2e tests](https://github.com/katanemo/arch/actions/workflows/e2e_tests.yml/badge.svg)](https://github.com/katanemo/arch/actions/workflows/e2e_tests.yml)
[![Build and Deploy Documentation](https://github.com/katanemo/arch/actions/workflows/static.yml/badge.svg)](https://github.com/katanemo/arch/actions/workflows/static.yml)


&lt;/div&gt;

# Overview
&lt;a href=&quot;https://www.producthunt.com/posts/arch-3?embed=true&amp;utm_source=badge-top-post-badge&amp;utm_medium=badge&amp;utm_souce=badge-arch&amp;#0045;3&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=565761&amp;theme=dark&amp;period=daily&amp;t=1742359429995&quot; alt=&quot;Arch - Build&amp;#0032;fast&amp;#0044;&amp;#0032;hyper&amp;#0045;personalized&amp;#0032;agents&amp;#0032;with&amp;#0032;intelligent&amp;#0032;infra | Product Hunt&quot; style=&quot;width: 188px; height: 41px;&quot; width=&quot;188&quot; height=&quot;41&quot; /&gt;&lt;/a&gt;

AI demos are easy to hack. But once you move past a prototype, you’re stuck building and maintaining low-level plumbing code that slows down real innovation. For example:

- **Routing &amp; orchestration.** Frameworks handle routing and handoffs in tightly coupled ways, so if you want to plug in your own router, planner, or policy engine, you’re stuck with a heavy refactor or brittle overrides.
- **Model integration churn.** Frameworks wire LLM integrations directly into code abstractions, making it hard to add or swap models without touching application code — meaning you’ll have to do codewide search/replace every time you want to experiment with a new model or version.
- **Observability &amp; governance.** Logging, tracing, and guardrails are baked in as tightly coupled features, so bringing in best-of-breed solutions is painful and often requires digging through the guts of a framework.
- **Prompt engineering overhead**. Input validation, clarifying vague user input, and coercing outputs into the right schema all pile up, turning what should be design work into low-level plumbing work.
- **Brittle upgrades**. Every change (new model, new guardrail, new trace format) means patching and redeploying application servers. Contrast that with bouncing a central proxy—one upgrade, instantly consistent everywhere.

With Arch, you can move faster by focusing on higher-level objectives in a language and framework agnostic way. **Arch** was built by the contributors of [Envoy Proxy](https://www.envoyproxy.io/) with the belief that:

&gt;Prompts are nuanced and opaque user requests, which require the same capabilities as traditional HTTP requests including secure handling, intelligent routing, robust observability, and integration with backend (API) systems to improve speed and accuracy for common agentic scenarios  – all outside core application logic.*

**Core Features**:

  - `🚦 Route to Agents`: Engineered with purpose-built [LLMs](https://huggingface.co/collections/katanemo/arch-function-66f209a693ea8df14317ad68) for fast (&lt;100ms) agent routing and hand-off
  - `🔗 Route to LLMs`: Unify access to LLMs with support for [dynamic routing](#Preference-based-Routing). Model aliases [coming soon](https://github.com/katanemo/archgw/issues/557)
  - `⛨ Guardrails`: Centrally configure and prevent harmful outcomes and ensure safe user interactions
  - `⚡ Tools Use`: For common agentic scenarios let Arch instantly clarify and convert prompts to tools/API calls
  - `🕵 Observability`: W3C compatible request tracing and LLM metrics that instantly plugin with popular tools
  - `🧱 Built on Envoy`: Arch runs alongside app servers as a containerized process, and builds on top of [Envoy&#039;s](https://envoyproxy.io) proven HTTP management and scalability features to handle ingress and egress traffic related to prompts and LLMs.

**High-Level Sequence Diagram**:
![alt text](docs/source/_static/img/arch_network_diagram_high_level.png)

**Jump to our [docs](https://docs.archgw.com)** to learn how you can use Arch to improve the speed, security and personalization of your GenAI apps.

&gt; [!IMPORTANT]
&gt; Today, the function calling LLM (Arch-Function) designed for the agentic and RAG scenarios is hosted free of charge in the US-central region. To offer consistent latencies and throughput, and to manage our expenses, we will enable access to the hosted version via developers keys soon, and give you the option to run that LLM locally. For more details see this issue [#258](https://github.com/katanemo/archgw/issues/258)

## Contact
To get in touch with us, please join our [discord server](https://discord.gg/pGZf2gcwEc). We will be monitoring that actively and offering support there.

## Demos
* [Sample App: Weather Forecast Agent](demos/samples_python/weather_forecast/README.md) - A sample agentic weather forecasting app that highlights core function calling capabilities of Arch.
* [Sample App: Network Operator Agent](demos/samples_python/network_switch_operator_agent/README.md) - A simple network device switch operator agent that can retrive device statistics and reboot them.
* [User Case: Connecting to SaaS APIs](demos/use_cases/spotify_bearer_auth) - Connect 3rd party SaaS APIs to your agentic chat experience.

## Quickstart

Follow this quickstart guide to use Arch as a router for local or hosted LLMs, including dynamic routing. Later in the section we will see how you can Arch to build highly capable agentic applications, and to provide e2e observability.

### Prerequisites

Before you begin, ensure you have the following:

1. [Docker System](https://docs.docker.com/get-started/get-docker/) (v24)
2. [Docker compose](https://docs.docker.com/compose/install/) (v2.29)
3. [Python](https://www.python.org/downloads/) (v3.13)

Arch&#039;s CLI allows you to manage and interact with the Arch gateway efficiently. To install the CLI, simply run the following command:

&gt; [!TIP]
&gt; We recommend that developers create a new Python virtual environment to isolate dependencies before installing Arch. This ensures that archgw and its dependencies do not interfere with other packages on your system.

```console
$ python3.12 -m venv venv
$ source venv/bin/activate   # On Windows, use: venv\Scripts\activate
$ pip install archgw==0.3.10
```

### Use Arch as a LLM Router
Arch supports two primary routing strategies for LLMs: model-based routing and preference-based routing.

#### Model-based Routing
Model-based routing allows you to configure static model names for routing. This is useful when you always want to use a specific model for certain tasks, or manually swap between models. Below an example configuration for model-based routing, and you can follow our [usage guide](demos/use_cases/README.md) on how to get working.

```yaml
version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - access_key: $OPENAI_API_KEY
    model: openai/gpt-4o
    default: true

  - access_key: $MISTRAL_API_KEY
    model: mistral/mistral-3b-latest
```

#### Preference-based Routing
Preference-based routing is designed for more dynamic and intelligent selection of models. Instead of static model names, you write plain-language routing policies that describe the type of task or preference — for example:

```yaml
version: v0.1.0

listeners:
  egress_traffic:
    address: 0.0.0.0
    port: 12000
    message_format: openai
    timeout: 30s

llm_providers:
  - model: openai/gpt-4.1
    access_key: $OPENAI_API_KEY
    default: true
    routing_preferences:
      - name: code generation
        description: generating new code snippets, functions, or boilerplate based on user prompts or requirements

  - model: openai/gpt-4o-mini
    access_key: $OPENAI_API_KEY
    routing_preferences:
      - name: code understanding
        description: understand and explain existing code snippets, functions, or libraries
```

Arch uses a lightweight 1.5B autoregressive model to map prompts (and conversation context) to these policies. This approach adapts to intent drift, supports multi-turn conversations, and avoids the brittleness of embedding-based classifiers or manual if/else chains. No retraining is required when adding new models or updating policies — routing is governed entirely by human-readable rules. You can learn more about the design, benchmarks, and methodology behind preference-based routing in our paper:

&lt;div align=&quot;left&quot;&gt;
  &lt;a href=&quot;https://arxiv.org/abs/2506.16655&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;docs/source/_static/img/arch_router_paper_preview.png&quot; alt=&quot;Arch Router Paper Preview&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

### Build Agentic Apps with Arch

In following quickstart we will show you how easy it is to build AI agent with Arch gateway. We will build a currency exchange agent using following simple steps. For this demo we will use `https://api.frankfurter.dev/` to fetch latest price for currencies and assume USD as base currency.

#### Step 1. Create arch config file

Create `arch_config.yaml` file with following content,

```yaml
version: v0.1.0

listeners:
  ingress_traffic:
    address: 0.0.0.0
    port: 10000
    message_format: openai
    timeout: 30s

llm_providers:
  - access_key: $OPENAI_API_KEY
    model: openai/gpt-4o

system_prompt: |
  You are a helpful assistant.

prompt_guards:
  input_guards:
    jailbreak:
      on_exception:
        message: Looks like you&#039;re curious about my abilities, but I can only provide assistance for currency exchange.

prompt_targets:
  - name: currency_exchange
    description: Get currency exchange rate from USD to other currencies
    parameters:
      - name: currency_symbol
        description: the currency that needs conversion
        required: true
        type: str
        in_path: true
    endpoint:
      name: frankfurther_api
      path: /v1/latest?base=USD&amp;symbols={currency_symbol}
    system_prompt: |
      You are a helpful assistant. Show me the currency symbol you want to convert from USD.

  - name: get_supported_currencies
    description: Get list of supported currencies for conversion
    endpoint:
      name: frankfurther_api
      path: /v1/currencies

endpoints:
  frankfurther_api:
    endpoint: api.frankfurter.dev:443
    protocol: https
```

#### Step 2. Start arch gateway with currency conversion config

```sh

$ archgw up arch_config.yaml
2024-12-05 16:56:27,979 - cli.main - INFO - Starting archgw cli version: 0.3.10
2024-12-05 16:56:28,485 - cli.utils - INFO - Schema validation successful!
2024-12-05 16:56:28,485 - cli.main - INFO - Starting arch model server and arch gateway
2024-12-05 16:56:51,647 - cli.core - INFO - Container is healthy!
```

Once the gateway is up you can start interacting with at port 10000 using openai chat completion API.

Some of the sample queries you can ask could be `what is currency rate for gbp?` or `show me list of currencies for conversion`.

#### Step 3. Interacting with gateway using curl command

Here is a sample curl command you can use to interact,

```bash
$ curl --header &#039;Content-Type: application/json&#039; \
  --data &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;,&quot;content&quot;: &quot;what is exchange rate for gbp&quot;}], &quot;model&quot;: &quot;none&quot;}&#039; \
  http://localhost:10000/v1/chat/completions | jq &quot;.choices[0].message.content&quot;

&quot;As of the date provided in your context, December 5, 2024, the exchange rate for GBP (British Pound) from USD (United States Dollar) is 0.78558. This means that 1 USD is equivalent to 0.78558 GBP.&quot;

```

And to get list of supported currencies,

```bash
$ curl --header &#039;Content-Type: application/json&#039; \
  --data &#039;{&quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;,&quot;content&quot;: &quot;show me list of currencies that are supported for conversion&quot;}], &quot;model&quot;: &quot;none&quot;}&#039; \
  http://localhost:10000/v1/chat/completions | jq &quot;.choices[0].message.content&quot;

&quot;Here is a list of the currencies that are supported for conversion from USD, along with their symbols:\n\n1. AUD - Australian Dollar\n2. BGN - Bulgarian Lev\n3. BRL - Brazilian Real\n4. CAD - Canadian Dollar\n5. CHF - Swiss Franc\n6. CNY - Chinese Renminbi Yuan\n7. CZK - Czech Koruna\n8. DKK - Danish Krone\n9. EUR - Euro\n10. GBP - British Pound\n11. HKD - Hong Kong Dollar\n12. HUF - Hungarian Forint\n13. IDR - Indonesian Rupiah\n14. ILS - Israeli New Sheqel\n15. INR - Indian Rupee\n16. ISK - Icelandic Króna\n17. JPY - Japanese Yen\n18. KRW - South Korean Won\n19. MXN - Mexican Peso\n20. MYR - Malaysian Ringgit\n21. NOK - Norwegian Krone\n22. NZD - New Zealand Dollar\n23. PHP - Philippine Peso\n24. PLN - Polish Złoty\n25. RON - Romanian Leu\n26. SEK - Swedish Krona\n27. SGD - Singapore Dollar\n28. THB - Thai Baht\n29. TRY - Turkish Lira\n30. USD - United States Dollar\n31. ZAR - South African Rand\n\nIf you want to convert USD to any of these currencies, you can select the one you are interested in.&quot;

```

## [Observability](https://docs.archgw.com/guides/observability/observability.html)
Arch is designed to support best-in class observability by supporting open standards. Please read our [docs](https://docs.archgw.com/guides/observability/observability.html) on observability for more details on tracing, metrics, and logs. The screenshot below is from our integration with Signoz (among others)

![alt text](docs/source/_static/img/tracing.png)

## Debugging

When debugging issues / errors application logs and access logs provide key information to give you more context on whats going on with the system. Arch gateway runs in info log level and following is a typical output you could see in a typical interaction between developer and arch gateway,

```
$ archgw up --service archgw --foreground
...
[2025-03-26 18:32:01.350][26][info] prompt_gateway: on_http_request_body: sending request to model server
[2025-03-26 18:32:01.851][26][info] prompt_gateway: on_http_call_response: model server response received
[2025-03-26 18:32:01.852][26][info] prompt_gateway: on_http_call_response: dispatching api call to developer endpoint: weather_forecast_service, path: /weather, method: POST
[2025-03-26 18:32:01.882][26][info] prompt_gateway: on_http_call_response: developer api call response received: status code: 200
[2025-03-26 18:32:01.882][26][info] prompt_gateway: on_http_call_response: sending request to upstream llm
[2025-03-26 18:32:01.883][26][info] llm_gateway: on_http_request_body: provider: gpt-4o-mini, model requested: None, model selected: gpt-4o-mini
[2025-03-26 18:32:02.818][26][info] llm_gateway: on_http_response_body: time to first token: 1468ms
[2025-03-26 18:32:04.532][26][info] llm_gateway: on_http_response_body: request latency: 3183ms
...
```

Log level can be changed to debug to get more details. To enable debug logs edit (supervisord.conf)[arch/supervisord.conf], change the log level `--component-log-level wasm:info` to `--component-log-level wasm:debug`. And after that you need to rebuild docker image and restart the arch gateway using following set of commands,

```
# make sure you are at the root of the repo
$ archgw build
# go to your service that has arch_config.yaml file and issue following command,
$ archgw up --service archgw --foreground
```

## Contribution
We would love feedback on our [Roadmap](https://github.com/orgs/katanemo/projects/1) and we welcome contributions to **Arch**!
Whether you&#039;re fixing bugs, adding new features, improving documentation, or creating tutorials, your help is much appreciated.
Please visit our [Contribution Guide](CONTRIBUTING.md) for more details
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[modelcontextprotocol/rust-sdk]]></title>
            <link>https://github.com/modelcontextprotocol/rust-sdk</link>
            <guid>https://github.com/modelcontextprotocol/rust-sdk</guid>
            <pubDate>Sat, 23 Aug 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[The official Rust SDK for the Model Context Protocol]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/modelcontextprotocol/rust-sdk">modelcontextprotocol/rust-sdk</a></h1>
            <p>The official Rust SDK for the Model Context Protocol</p>
            <p>Language: Rust</p>
            <p>Stars: 2,066</p>
            <p>Forks: 309</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;div align = &quot;right&quot;&gt;
&lt;a href=&quot;docs/readme/README.zh-cn.md&quot;&gt;简体中文(待更新)&lt;/a&gt;
&lt;/div&gt;

# RMCP
[![Crates.io Version](https://img.shields.io/crates/v/rmcp)](https://crates.io/crates/rmcp)
&lt;!-- ![Release status](https://github.com/modelcontextprotocol/rust-sdk/actions/workflows/release.yml/badge.svg) --&gt;
&lt;!-- [![docs.rs](todo)](todo) --&gt;
![Coverage](docs/coverage.svg)

An official Rust Model Context Protocol SDK implementation with tokio async runtime.

This repository contains the following crates:

- [rmcp](crates/rmcp): The core crate providing the RMCP protocol implementation (If you want to get more information, please visit [rmcp](crates/rmcp/README.md))
- [rmcp-macros](crates/rmcp-macros): A procedural macro crate for generating RMCP tool implementations (If you want to get more information, please visit [rmcp-macros](crates/rmcp-macros/README.md))

## Usage

### Import the crate

```toml
rmcp = { version = &quot;0.2.0&quot;, features = [&quot;server&quot;] }
## or dev channel
rmcp = { git = &quot;https://github.com/modelcontextprotocol/rust-sdk&quot;, branch = &quot;main&quot; }
```
### Third Dependencies
Basic dependencies:
- [tokio required](https://github.com/tokio-rs/tokio)
- [serde required](https://github.com/serde-rs/serde)



### Build a Client
&lt;details&gt;
&lt;summary&gt;Start a client&lt;/summary&gt;

```rust, ignore
use rmcp::{ServiceExt, transport::{TokioChildProcess, ConfigureCommandExt}};
use tokio::process::Command;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let client = ().serve(TokioChildProcess::new(Command::new(&quot;npx&quot;).configure(|cmd| {
        cmd.arg(&quot;-y&quot;).arg(&quot;@modelcontextprotocol/server-everything&quot;);
    }))?).await?;
    Ok(())
}
```
&lt;/details&gt;

### Build a Server

&lt;details&gt;
&lt;summary&gt;Build a transport&lt;/summary&gt;

```rust, ignore
use tokio::io::{stdin, stdout};
let transport = (stdin(), stdout());
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Build a service&lt;/summary&gt;

You can easily build a service by using [`ServerHandler`](crates/rmcp/src/handler/server.rs) or [`ClientHandler`](crates/rmcp/src/handler/client.rs).

```rust, ignore
let service = common::counter::Counter::new();
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Start the server&lt;/summary&gt;

```rust, ignore
// this call will finish the initialization process
let server = service.serve(transport).await?;
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Interact with the server&lt;/summary&gt;

Once the server is initialized, you can send requests or notifications:

```rust, ignore
// request
let roots = server.list_roots().await?;

// or send notification
server.notify_cancelled(...).await?;
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Waiting for service shutdown&lt;/summary&gt;

```rust, ignore
let quit_reason = server.waiting().await?;
// or cancel it
let quit_reason = server.cancel().await?;
```
&lt;/details&gt;


## Examples

See [examples](examples/README.md)

## OAuth Support

See [oauth_support](docs/OAUTH_SUPPORT.md) for details.

## Related Resources

- [MCP Specification](https://spec.modelcontextprotocol.io/specification/2024-11-05/)
- [Schema](https://github.com/modelcontextprotocol/specification/blob/main/schema/2024-11-05/schema.ts)

## Related Projects
- [rustfs-mcp](https://github.com/rustfs/rustfs/tree/main/crates/mcp) - High-performance MCP server providing S3-compatible object storage operations for AI/LLM integration
- [containerd-mcp-server](https://github.com/jokemanfire/mcp-containerd) - A containerd-based MCP server implementation

## Development

### Tips for Contributors

See [docs/CONTRIBUTE.MD](docs/CONTRIBUTE.MD) to get some tips for contributing.

### Using Dev Container

If you want to use dev container, see [docs/DEVCONTAINER.md](docs/DEVCONTAINER.md) for instructions on using Dev Container for development.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[chroma-core/chroma]]></title>
            <link>https://github.com/chroma-core/chroma</link>
            <guid>https://github.com/chroma-core/chroma</guid>
            <pubDate>Sat, 23 Aug 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[Open-source search and retrieval database for AI applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/chroma-core/chroma">chroma-core/chroma</a></h1>
            <p>Open-source search and retrieval database for AI applications.</p>
            <p>Language: Rust</p>
            <p>Stars: 21,969</p>
            <p>Forks: 1,728</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trychroma.com&quot;&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/891664/227103090-6624bf7d-9524-4e05-9d2c-c28d5d451481.png&quot; alt=&quot;Chroma logo&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;b&gt;Chroma - the open-source embedding database&lt;/b&gt;. &lt;br /&gt;
    The fastest way to build Python or JavaScript LLM apps with memory!
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.gg/MMeYNTmh3x&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/discord/1073293645303795742?cacheSeconds=3600&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt; |
  &lt;a href=&quot;https://github.com/chroma-core/chroma/blob/master/LICENSE&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot; alt=&quot;License&quot;&gt;
  &lt;/a&gt; |
  &lt;a href=&quot;https://docs.trychroma.com/&quot; target=&quot;_blank&quot;&gt;
      Docs
  &lt;/a&gt; |
  &lt;a href=&quot;https://www.trychroma.com/&quot; target=&quot;_blank&quot;&gt;
      Homepage
  &lt;/a&gt;
&lt;/p&gt;

```bash
pip install chromadb # python client
# for javascript, npm install chromadb!
# for client-server mode, chroma run --path /chroma_db_path
```

## Chroma Cloud

Our hosted service, Chroma Cloud, powers serverless vector and full-text search. It&#039;s extremely fast, cost-effective, scalable and painless. Create a DB and try it out in under 30 seconds with $5 of free credits.

[Get started with Chroma Cloud](https://trychroma.com/signup)

## API

The core API is only 4 functions (run our [💡 Google Colab](https://colab.research.google.com/drive/1QEzFyqnoFxq7LUGyP1vzR4iLt9PpCDXv?usp=sharing)):

```python
import chromadb
# setup Chroma in-memory, for easy prototyping. Can add persistence easily!
client = chromadb.Client()

# Create collection. get_collection, get_or_create_collection, delete_collection also available!
collection = client.create_collection(&quot;all-my-documents&quot;)

# Add docs to the collection. Can also update and delete. Row-based API coming soon!
collection.add(
    documents=[&quot;This is document1&quot;, &quot;This is document2&quot;], # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well
    metadatas=[{&quot;source&quot;: &quot;notion&quot;}, {&quot;source&quot;: &quot;google-docs&quot;}], # filter on these!
    ids=[&quot;doc1&quot;, &quot;doc2&quot;], # unique for each doc
)

# Query/search 2 most similar results. You can also .get by id
results = collection.query(
    query_texts=[&quot;This is a query document&quot;],
    n_results=2,
    # where={&quot;metadata_field&quot;: &quot;is_equal_to_this&quot;}, # optional filter
    # where_document={&quot;$contains&quot;:&quot;search_string&quot;}  # optional filter
)
```

Learn about all features on our [Docs](https://docs.trychroma.com)

## Features
- __Simple__: Fully-typed, fully-tested, fully-documented == happiness
- __Integrations__: [`🦜️🔗 LangChain`](https://blog.langchain.dev/langchain-chroma/) (python and js), [`🦙 LlamaIndex`](https://twitter.com/atroyn/status/1628557389762007040) and more soon
- __Dev, Test, Prod__: the same API that runs in your python notebook, scales to your cluster
- __Feature-rich__: Queries, filtering, regex and more
- __Free &amp; Open Source__: Apache 2.0 Licensed

## Use case: ChatGPT for ______

For example, the `&quot;Chat your data&quot;` use case:
1. Add documents to your database. You can pass in your own embeddings, embedding function, or let Chroma embed them for you.
2. Query relevant documents with natural language.
3. Compose documents into the context window of an LLM like `GPT4` for additional summarization or analysis.

## Embeddings?

What are embeddings?

- [Read the guide from OpenAI](https://platform.openai.com/docs/guides/embeddings/what-are-embeddings)
- __Literal__: Embedding something turns it from image/text/audio into a list of numbers. 🖼️ or 📄 =&gt; `[1.2, 2.1, ....]`. This process makes documents &quot;understandable&quot; to a machine learning model.
- __By analogy__: An embedding represents the essence of a document. This enables documents and queries with the same essence to be &quot;near&quot; each other and therefore easy to find.
- __Technical__: An embedding is the latent-space position of a document at a layer of a deep neural network. For models trained specifically to embed data, this is the last layer.
- __A small example__: If you search your photos for &quot;famous bridge in San Francisco&quot;. By embedding this query and comparing it to the embeddings of your photos and their metadata - it should return photos of the Golden Gate Bridge.

Embeddings databases (also known as **vector databases**) store embeddings and allow you to search by nearest neighbors rather than by substrings like a traditional database. By default, Chroma uses [Sentence Transformers](https://docs.trychroma.com/guides/embeddings#default:-all-minilm-l6-v2) to embed for you but you can also use OpenAI embeddings, Cohere (multilingual) embeddings, or your own.

## Get involved

Chroma is a rapidly developing project. We welcome PR contributors and ideas for how to improve the project.
- [Join the conversation on Discord](https://discord.gg/MMeYNTmh3x) - `#contributing` channel
- [Review the 🛣️ Roadmap and contribute your ideas](https://docs.trychroma.com/roadmap)
- [Grab an issue and open a PR](https://github.com/chroma-core/chroma/issues) - [`Good first issue tag`](https://github.com/chroma-core/chroma/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)
- [Read our contributing guide](https://docs.trychroma.com/contributing)

**Release Cadence**
We currently release new tagged versions of the `pypi` and `npm` packages on Mondays. Hotfixes go out at any time during the week.

## License

[Apache 2.0](./LICENSE)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>