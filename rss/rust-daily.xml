<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Thu, 18 Sep 2025 00:05:20 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[category-labs/monad-bft]]></title>
            <link>https://github.com/category-labs/monad-bft</link>
            <guid>https://github.com/category-labs/monad-bft</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:20 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/category-labs/monad-bft">category-labs/monad-bft</a></h1>
            <p></p>
            <p>Language: Rust</p>
            <p>Stars: 353</p>
            <p>Forks: 103</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># Monad BFT

![Nightly Tests][tests-badge]

## Overview

This repository contains implementation for the Monad consensus client and JsonRpc server. Monad consensus collects transactions and produces blocks which are written to a ledger filestream. These blocks are consumed by Monad execution, which then updates the state of the blockchain. The [triedb](monad-triedb/README.md) is a database which stores block information and the blockchain state.

## Getting Started

```sh
git submodule update --init --recursive
```

### Using Docker

The most straightforward way to start a consensus client + an execution client + a JsonRpc server. Run the following:
1. `cd docker/single-node`
2. `nets/run.sh`

### Using Cargo

To run a Monad consensus client, follow instructions [here](monad-node/README.md).
 
To run a JsonRpc server, follow instructions [here](monad-rpc/README.md).

## Architecture

```mermaid
sequenceDiagram
autonumber
    participant D as Driver
    box Purple Executor
    participant S as impl Stream
    participant E as impl Executor
    end
    participant State
    participant PersistenceLogger
    loop
    D -&gt;&gt;+ S: CALL next()
    Note over S: blocks until event ready
    S --&gt;&gt;- D: RETURN Event
    D -&gt;&gt; PersistenceLogger: CALL push(Event)
    D -&gt;&gt;+ State: CALL update(Event)
    Note over State: mutate state
    State --&gt;&gt;- D: RETURN Vec&lt;Command&gt;
    D -&gt;&gt; E: CALL exec(Vec&lt;Command&gt;)
    Note over E: apply side effects
    end
```

[tests-badge]: https://github.com/monad-crypto/monad-bft/actions/workflows/randomized.yml/badge.svg?branch=master
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[openai/codex]]></title>
            <link>https://github.com/openai/codex</link>
            <guid>https://github.com/openai/codex</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Lightweight coding agent that runs in your terminal]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/codex">openai/codex</a></h1>
            <p>Lightweight coding agent that runs in your terminal</p>
            <p>Language: Rust</p>
            <p>Stars: 42,069</p>
            <p>Forks: 4,895</p>
            <p>Stars today: 487 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;OpenAI Codex CLI&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install codex&lt;/code&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer.
&lt;/br&gt;
&lt;/br&gt;If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href=&quot;https://developers.openai.com/codex/ide&quot;&gt;install in your IDE&lt;/a&gt;
&lt;/br&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href=&quot;https://chatgpt.com/codex&quot;&gt;chatgpt.com/codex&lt;/a&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./.github/codex-cli-splash.png&quot; alt=&quot;Codex CLI splash&quot; width=&quot;80%&quot; /&gt;
  &lt;/p&gt;

---

## Quickstart

### Installing and running Codex CLI

Install globally with your preferred package manager. If you use npm:

```shell
npm install -g @openai/codex
```

Alternatively, if you use Homebrew:

```shell
brew install codex
```

Then simply run `codex` to get started:

```shell
codex
```

&lt;details&gt;
&lt;summary&gt;You can also go to the &lt;a href=&quot;https://github.com/openai/codex/releases/latest&quot;&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt;

Each GitHub Release contains many executables, but in practice, you likely want one of these:

- macOS
  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`
  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`
- Linux
  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`
  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`

Each archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.

&lt;/details&gt;

### Using Codex with your ChatGPT plan

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./.github/codex-cli-login.png&quot; alt=&quot;Codex CLI login&quot; width=&quot;80%&quot; /&gt;
  &lt;/p&gt;

Run `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what&#039;s included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).

You can also use Codex with an API key, but this requires [additional setup](./docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key). If you previously used an API key for usage-based billing, see the [migration steps](./docs/authentication.md#migrating-from-usage-based-billing-api-key). If you&#039;re having trouble with login, please comment on [this issue](https://github.com/openai/codex/issues/1243).

### Model Context Protocol (MCP)

Codex CLI supports [MCP servers](./docs/advanced.md#model-context-protocol-mcp). Enable by adding an `mcp_servers` section to your `~/.codex/config.toml`.


### Configuration

Codex CLI supports a rich set of configuration options, with preferences stored in `~/.codex/config.toml`. For full configuration options, see [Configuration](./docs/config.md).

---

### Docs &amp; FAQ

- [**Getting started**](./docs/getting-started.md)
  - [CLI usage](./docs/getting-started.md#cli-usage)
  - [Running with a prompt as input](./docs/getting-started.md#running-with-a-prompt-as-input)
  - [Example prompts](./docs/getting-started.md#example-prompts)
  - [Memory with AGENTS.md](./docs/getting-started.md#memory-with-agentsmd)
  - [Configuration](./docs/config.md)
- [**Sandbox &amp; approvals**](./docs/sandbox.md)
- [**Authentication**](./docs/authentication.md)
  - [Auth methods](./docs/authentication.md#forcing-a-specific-auth-method-advanced)
  - [Login on a &quot;Headless&quot; machine](./docs/authentication.md#connecting-on-a-headless-machine)
- [**Advanced**](./docs/advanced.md)
  - [Non-interactive / CI mode](./docs/advanced.md#non-interactive--ci-mode)
  - [Tracing / verbose logging](./docs/advanced.md#tracing--verbose-logging)
  - [Model Context Protocol (MCP)](./docs/advanced.md#model-context-protocol-mcp)
- [**Zero data retention (ZDR)**](./docs/zdr.md)
- [**Contributing**](./docs/contributing.md)
- [**Install &amp; build**](./docs/install.md)
  - [System Requirements](./docs/install.md#system-requirements)
  - [DotSlash](./docs/install.md#dotslash)
  - [Build from source](./docs/install.md#build-from-source)
- [**FAQ**](./docs/faq.md)
- [**Open source fund**](./docs/open-source-fund.md)

---

## License

This repository is licensed under the [Apache-2.0 License](LICENSE).

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[erebe/wstunnel]]></title>
            <link>https://github.com/erebe/wstunnel</link>
            <guid>https://github.com/erebe/wstunnel</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[Tunnel all your traffic over Websocket or HTTP2 - Bypass firewalls/DPI - Static binary available]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/erebe/wstunnel">erebe/wstunnel</a></h1>
            <p>Tunnel all your traffic over Websocket or HTTP2 - Bypass firewalls/DPI - Static binary available</p>
            <p>Language: Rust</p>
            <p>Stars: 5,503</p>
            <p>Forks: 453</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/erebe/wstunnel/raw/main/docs/logo_wstunnel.png&quot; alt=&quot;wstunnel logo&quot; height=&quot;400&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;https://ko-fi.com/P5P4QCHMO&quot;&gt;&lt;img src=&quot;https://ko-fi.com/img/githubbutton_sm.svg&quot;/&gt;&lt;/a&gt;
  &lt;br/&gt;
&lt;/p&gt;

## Summary

* [Description](#description)
* [Demo server](#demo)
* [Command line](#cmd)
* [Examples](#examples)
* [Release](#release)
* [Note](#note)
* [Benchmark](#bench)
* [How to build](#build)

## Description &lt;a name=&quot;description&quot;&gt;&lt;/a&gt;

Most of the time when you are using a public network, you are behind some kind of firewall or proxy. One of their
purpose is to constrain you to only use certain kind of protocols and consult only a subset of the web. Nowadays, the
most widespread protocol is http and is de facto allowed by third party equipment.

Wstunnel uses the websocket protocol which is compatible with http in order to bypass firewalls and proxies. Wstunnel
allows you to tunnel whatever traffic you want and access whatever resources/site you need.

My inspiration came from [this project](https://www.npmjs.com/package/wstunnel) but as I don&#039;t want to install npm and
nodejs to use this tool, I remade it in ~~Haskell~~ Rust and improved it.

**What to expect:**

* Easy to use
* Good error messages and debug information
* Static forward (reverse) tunneling (TCP, UDP, Unix socket, Stdio)
* Dynamic (reverse) tunneling (Socks5 proxy, HTTP proxy and Transparent Proxy)
* Support for using http proxy (when behind one) as gateway
* Support of proxy protocol
* Support for tls/https server with certificates auto-reload (with embedded self-signed certificate, or your own)
* Support of mTLS with certificates auto-reload - [documentation here](https://github.com/erebe/wstunnel/blob/main/docs/using_mtls.md)
* Support IPv6
* Support for Websocket and HTTP2 as transport protocol (websocket is more performant)
* **Standalone binaries** (so just cp it where you want) [here](https://github.com/erebe/wstunnel/releases)

## Sponsors &lt;a name=&quot;sponsors&quot;&gt;&lt;/a&gt;

Part of Wstunnel development has been sponsored by
&lt;p align=&quot;center&quot;&gt;
   &lt;a href=&quot;https://serviceplanet.nl&quot;&gt;
    &lt;img width=&quot;200&quot; height=&quot;100&quot; src=&quot;https://github.com/erebe/wstunnel/raw/main/docs/logo_serviceplanet.png&quot; alt=&quot;service planet logo&quot;/&gt;
   &lt;/a&gt;&lt;/p&gt;

## Note &lt;a name=&quot;note&quot;&gt;&lt;/a&gt;

v7.0.0 is a complete rewrite of wstunnel in Rust and is not compatible with previous version.
Previous code in Haskell can be found on branch https://github.com/erebe/wstunnel/tree/haskell

What to expect from previous version:

* More throughput and less jitter due to Haskell GC. Most of you will not care, as it was performant enough already. But
  you can now saturate a gigabit ethernet card with a single connection
* Command line is more homogeneous/has better UX. All tunnel can be specified multiple times
* Tunnel protocol tries to look like normal traffic, to avoid being flagged
* Support of reverse tunneling
* New bug, it is a rewrite (╯&#039;□&#039;)╯︵ ┻━┻ ¯\\_(ツ)_/¯
* Mainly for me to ease the maintenance of the project. I don&#039;t do a lot of haskell nowadays and it was harder for me to
  keep maintening the project over time, as I get lost in touch of the Haskell ecosystem and new release.
* Armv7 build (aka raspberry pi), as new version of GHC (Haskell compiler) dropped its support


## Demo server &lt;a name=&quot;demo&quot;&gt;&lt;/a&gt;

If you just want to try out that you can bypass your proxy/firewall.
You can give it a try with wstunnel demo server.

```bash
# In a terminal start wstunnel client
# You can set as tls-sni-override whatever domain you want. The tunnel is the only one that is going to be allowed. 
wstunnel client -L &#039;tcp://4443:localhost:444?proxy_protocol&#039; -P demo --tls-sni-override=google.fr wss://49.13.58.9

# on another terminal, run curl and it should return you this greetings
curl -k https://localhost:4443
&gt; Memento mori !
```


## Command line &lt;a name=&quot;cmd&quot;&gt;&lt;/a&gt;

```
Usage: wstunnel client [OPTIONS] &lt;ws[s]|http[s]://wstunnel.server.com[:port]&gt;

Arguments:
  &lt;ws[s]|http[s]://wstunnel.server.com[:port]&gt;
          Address of the wstunnel server
          You can either use websocket or http2 as transport protocol. Use websocket if you are unsure.
          Example: For websocket with TLS wss://wstunnel.example.com or without ws://wstunnel.example.com
                   For http2 with TLS https://wstunnel.example.com or without http://wstunnel.example.com
          
          *WARNING* HTTP2 as transport protocol is harder to make it works because:
            - If you are behind a (reverse) proxy/CDN they are going to buffer the whole request before forwarding it to the server
              Obviously, this is not going to work for tunneling traffic
            - if you have wstunnel behind a reverse proxy, most of them (i.e: nginx) are going to turn http2 request into http1
              This is not going to work, because http1 does not support streaming naturally
          The only way to make it works with http2 is to have wstunnel directly exposed to the internet without any reverse proxy in front of it

Options:
  -L, --local-to-remote &lt;{tcp,udp,socks5,stdio,unix}://[BIND:]PORT:HOST:PORT&gt;
          Listen on local and forwards traffic from remote. Can be specified multiple times
          examples:
          &#039;tcp://1212:google.com:443&#039;      =&gt;       listen locally on tcp on port 1212 and forward to google.com on port 443
          &#039;tcp://2:n.lan:4?proxy_protocol&#039; =&gt;       listen locally on tcp on port 2 and forward to n.lan on port 4
                                                    Send a proxy protocol header v2 when establishing connection to n.lan
          
          &#039;udp://1212:1.1.1.1:53&#039;          =&gt;       listen locally on udp on port 1212 and forward to cloudflare dns 1.1.1.1 on port 53
          &#039;udp://1212:1.1.1.1:53?timeout_sec=10&#039;    timeout_sec on udp force close the tunnel after 10sec. Set it to 0 to disable the timeout [default: 30]
          
          &#039;socks5://[::1]:1212&#039;            =&gt;       listen locally with socks5 on port 1212 and forward dynamically requested tunnel
          &#039;socks5://[::1]:1212?login=admin&amp;password=admin&#039; =&gt; listen locally with socks5 on port 1212 and only accept connection with login=admin and password=admin
          
          &#039;http://[::1]:1212&#039;              =&gt;       start a http proxy on port 1212 and forward dynamically requested tunnel
          &#039;http://[::1]:1212?login=admin&amp;password=admin&#039; =&gt; start a http proxy on port 1212 and only accept connection with login=admin and password=admin

          &#039;tproxy+tcp://[::1]:1212&#039;        =&gt;       listen locally on tcp on port 1212 as a *transparent proxy* and forward dynamically requested tunnel
          &#039;tproxy+udp://[::1]:1212?timeout_sec=10&#039;  listen locally on udp on port 1212 as a *transparent proxy* and forward dynamically requested tunnel
                                                    linux only and requires sudo/CAP_NET_ADMIN
          
          &#039;stdio://google.com:443&#039;         =&gt;       listen for data from stdio, mainly for `ssh -o ProxyCommand=&quot;wstunnel client --log-lvl=off -L stdio://%h:%p ws://localhost:8080&quot; my-server`
          
          &#039;unix:///tmp/wstunnel.sock:g.com:443&#039; =&gt;  listen for data from unix socket of path /tmp/wstunnel.sock and forward to g.com:443

  -R, --remote-to-local &lt;{tcp,udp,socks5,unix}://[BIND:]PORT:HOST:PORT&gt;
          Listen on remote and forwards traffic from local. Can be specified multiple times. Only tcp is supported
          examples:
          &#039;tcp://1212:google.com:443&#039;      =&gt;     listen on server for incoming tcp cnx on port 1212 and forward to google.com on port 443 from local machine
          &#039;udp://1212:1.1.1.1:53&#039;          =&gt;     listen on server for incoming udp on port 1212 and forward to cloudflare dns 1.1.1.1 on port 53 from local machine
          &#039;socks5://[::1]:1212&#039;            =&gt;     listen on server for incoming socks5 request on port 1212 and forward dynamically request from local machine
          &#039;http://[::1]:1212&#039;              =&gt;     listen on server for incoming http proxy request on port 1212 and forward dynamically request from local machine (login/password is supported)
          &#039;unix://wstunnel.sock:g.com:443&#039; =&gt;     listen on server for incoming data from unix socket of path wstunnel.sock and forward to g.com:443 from local machine

      --no-color &lt;NO_COLOR&gt;
          Disable color output in logs
          
          [env: NO_COLOR=]

      --socket-so-mark &lt;INT&gt;
          (linux only) Mark network packet with SO_MARK sockoption with the specified value.
          You need to use {root, sudo, capabilities} to run wstunnel when using this option

  -c, --connection-min-idle &lt;INT&gt;
          Client will maintain a pool of open connection to the server, in order to speed up the connection process.
          This option set the maximum number of connection that will be kept open.
          This is useful if you plan to create/destroy a lot of tunnel (i.e: with socks5 to navigate with a browser)
          It will avoid the latency of doing tcp + tls handshake with the server
          
          [default: 0]

      --nb-worker-threads &lt;INT&gt;
          *WARNING* The flag does nothing, you need to set the env variable *WARNING*
          Control the number of threads that will be used.
          By default, it is equal the number of cpus
          
          [env: TOKIO_WORKER_THREADS=]

      --log-lvl &lt;LOG_LEVEL&gt;
          Control the log verbosity. i.e: TRACE, DEBUG, INFO, WARN, ERROR, OFF
          for more details: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html#example-syntax
          
          [env: RUST_LOG=]
          [default: INFO]

      --tls-sni-override &lt;DOMAIN_NAME&gt;
          Domain name that will be used as SNI during TLS handshake
          Warning: If you are behind a CDN (i.e: Cloudflare) you must set this domain also in the http HOST header.
                   or it will be flagged as fishy and your request rejected

      --tls-sni-disable
          Disable sending SNI during TLS handshake
          Warning: Most reverse proxies rely on it

      --tls-ech-enable
          Enable ECH (encrypted sni) during TLS handshake to wstunnel server.
          Warning: Ech DNS config is not refreshed over time. It is retrieved only once at startup of the program

      --tls-verify-certificate
          Enable TLS certificate verification.
          Disabled by default. The client will happily connect to any server with self-signed certificate.

  -p, --http-proxy &lt;USER:PASS@HOST:PORT&gt;
          If set, will use this http proxy to connect to the server
          
          [env: HTTP_PROXY=]

      --http-proxy-login &lt;LOGIN&gt;
          If set, will use this login to connect to the http proxy. Override the one from --http-proxy
          
          [env: WSTUNNEL_HTTP_PROXY_LOGIN=]

      --http-proxy-password &lt;PASSWORD&gt;
          If set, will use this password to connect to the http proxy. Override the one from --http-proxy
          
          [env: WSTUNNEL_HTTP_PROXY_PASSWORD=]

  -P, --http-upgrade-path-prefix &lt;HTTP_UPGRADE_PATH_PREFIX&gt;
          Use a specific prefix that will show up in the http path during the upgrade request.
          Useful if you need to route requests server side but don&#039;t have vhosts
          
          [env: WSTUNNEL_HTTP_UPGRADE_PATH_PREFIX=]
          [default: v1]

      --http-upgrade-credentials &lt;USER[:PASS]&gt;
          Pass authorization header with basic auth credentials during the upgrade request.
          If you need more customization, you can use the http_headers option.

      --websocket-ping-frequency-sec &lt;seconds&gt;
          Frequency at which the client will send websocket ping to the server.
          
          [default: 30]

      --websocket-mask-frame
          Enable the masking of websocket frames. Default is false
          Enable this option only if you use unsecure (non TLS) websocket server, and you see some issues. Otherwise, it is just overhead.

  -H, --http-headers &lt;HEADER_NAME: HEADER_VALUE&gt;
          Send custom headers in the upgrade request
          Can be specified multiple time

      --http-headers-file &lt;FILE_PATH&gt;
          Send custom headers in the upgrade request reading them from a file.
          It overrides http_headers specified from command line.
          File is read everytime and file format must contain lines with `HEADER_NAME: HEADER_VALUE`

      --tls-certificate &lt;FILE_PATH&gt;
          [Optional] Certificate (pem) to present to the server when connecting over TLS (HTTPS).
          Used when the server requires clients to authenticate themselves with a certificate (i.e. mTLS).
          The certificate will be automatically reloaded if it changes

      --tls-private-key &lt;FILE_PATH&gt;
          [Optional] The private key for the corresponding certificate used with mTLS.
          The certificate will be automatically reloaded if it changes

      --dns-resolver &lt;DNS_RESOLVER&gt;
          Dns resolver to use to lookup ips of domain name. Can be specified multiple time
          Example:
           dns://1.1.1.1 for using udp
           dns+https://1.1.1.1?sni=cloudflare-dns.com for using dns over HTTPS
           dns+tls://8.8.8.8?sni=dns.google for using dns over TLS
          For Dns over HTTPS/TLS if an HTTP proxy is configured, it will be used also
          To use libc resolver, use
          system://0.0.0.0

          **WARN** On windows you may want to specify explicitly the DNS resolver to avoid excessive DNS queries
```

```
SERVER
Usage: wstunnel server [OPTIONS] &lt;ws[s]://0.0.0.0[:port]&gt;

Arguments:
  &lt;ws[s]://0.0.0.0[:port]&gt;
          Address of the wstunnel server to bind to
          Example: With TLS wss://0.0.0.0:8080 or without ws://[::]:8080
          
          The server is capable of detecting by itself if the request is websocket or http2. So you don&#039;t need to specify it.

Options:
      --socket-so-mark &lt;INT&gt;
          (linux only) Mark network packet with SO_MARK sockoption with the specified value.
          You need to use {root, sudo, capabilities} to run wstunnel when using this option

      --websocket-ping-frequency-sec &lt;seconds&gt;
          Frequency at which the server will send websocket ping to client.

      --no-color &lt;NO_COLOR&gt;
          Disable color output in logs
          
          [env: NO_COLOR=]

      --websocket-mask-frame
          Enable the masking of websocket frames. Default is false
          Enable this option only if you use unsecure (non TLS) websocket server, and you see some issues. Otherwise, it is just overhead.

      --nb-worker-threads &lt;INT&gt;
          *WARNING* The flag does nothing, you need to set the env variable *WARNING*
          Control the number of threads that will be used.
          By default, it is equal the number of cpus
          
          [env: TOKIO_WORKER_THREADS=]

      --restrict-to &lt;DEST:PORT&gt;
          Server will only accept connection from the specified tunnel information.
          Can be specified multiple time
          Example: --restrict-to &quot;google.com:443&quot; --restrict-to &quot;localhost:22&quot;

      --dns-resolver &lt;DNS_RESOLVER&gt;
          Dns resolver to use to lookup ips of domain name
          This option is not going to work if you use transparent proxy
          Can be specified multiple time
          Example:
           dns://1.1.1.1 for using udp
           dns+https://1.1.1.1?sni=loudflare-dns.com for using dns over HTTPS
           dns+tls://8.8.8.8?sni=dns.google for using dns over TLS
          To use libc resolver, use
          system://0.0.0.0

      --log-lvl &lt;LOG_LEVEL&gt;
          Control the log verbosity. i.e: TRACE, DEBUG, INFO, WARN, ERROR, OFF
          for more details: https://docs.rs/tracing-subscriber/latest/tracing_subscriber/filter/struct.EnvFilter.html#example-syntax
          
          [env: RUST_LOG=]
          [default: INFO]

  -r, --restrict-http-upgrade-path-prefix &lt;RESTRICT_HTTP_UPGRADE_PATH_PREFIX&gt;
          Server will only accept connection from if this specific path prefix is used during websocket upgrade.
          Useful if you specify in the client a custom path prefix, and you want the server to only allow this one.
          The path prefix act as a secret to authenticate clients
          Disabled by default. Accept all path prefix. Can be specified multiple time
          
          [env: WSTUNNEL_RESTRICT_HTTP_UPGRADE_PATH_PREFIX=]

      --restrict-config &lt;RESTRICT_CONFIG&gt;
          Path to the location of the restriction yaml config file.
          Restriction file is automatically reloaded if it changes

      --tls-certificate &lt;FILE_PATH&gt;
          [Optional] Use custom certificate (pem) instead of the default embedded self-signed certificate.
          The certificate will be automatically reloaded if it changes

      --tls-private-key &lt;FILE_PATH&gt;
          [Optional] Use a custom tls key (pem, ec, rsa) that the server will use instead of the default embedded one
          The private key will be automatically reloaded if it changes

      --tls-client-ca-certs &lt;FILE_PATH&gt;
          [Optional] Enables mTLS (client authentication with certificate). Argument must be PEM file
          containing one or more certificates of CA&#039;s of which the certificate of clients needs to be signed with.
          The ca will be automatically reloaded if it changes
          
    -p, --http-proxy &lt;USER:PASS@HOST:PORT&gt;
          If set, will use this http proxy to connect to the client

          [env: HTTP_PROXY=]

      --http-proxy-login &lt;LOGIN&gt;
          If set, will use this login to connect to the http proxy. Override the one from --http-proxy

          [env: WSTUNNEL_HTTP_PROXY_LOGIN=]

      --http-proxy-password &lt;PASSWORD&gt;
          If set, will use this password to connect to the http proxy. Override the one from --http-proxy

          [env: WSTUNNEL_HTTP_PROXY_PASSWORD=]
```

## Release &lt;a name=&quot;release&quot;&gt;&lt;/a&gt;

Static binaries are available in [release section](https://github.com/erebe/wstunnel/releases)

docker image are available at https://github.com/erebe/wstunnel/pkgs/container/wstunnel

```bash
docker pull ghcr.io/erebe/wstunnel:latest
```

## Examples &lt;a name=&quot;examples&quot;&gt;&lt;/a&gt;

* [Understand command line syntax](#syntax)
* [Simplest one with socks5 - Good for browsing internet](#simple)
* [Proxy SSH](#ssh)
* [Bypass a corporate proxy](#corporate)
* [Proxy Wireguard traffic](#wireguard)
* [Android](#android)
* [Proxy easily any traffic with transparent proxy (linux only)](#tproxy)
* [Reverse tunneling](#reverse)
* [How to secure access of your wstunnel server](#secure)
* [Use HTTP2 instead of websocket for transport protocol](#http2)
* [Maximize your stealthiness/Make your traffic discrete](#stealth)

### Understand command line syntax &lt;a name=&quot;syntax&quot;&gt;&lt;/a&gt;

Wstunnel command line mimic ssh tunnel syntax.
You can take reference to [this article](https://iximiuz.com/en/posts/ssh-tunnels/), or this diagram to understand
&lt;img src=&quot;https://iximiuz.com/ssh-tunnels/ssh-tunnels.png&quot;&gt;

---

### Simplest one &lt;a name=&quot;simple&quot;&gt;&lt;/a&gt;

On your remote host, start the wstunnel&#039;s server by typing this command in your terminal

```bash
wstunnel server wss://[::]:8080
```

This will create a websocket server listening on any interface on port 8080.
On the client side use this command to forward traffic through the websocket tunnel

```bash
wstunnel client -L socks5://127.0.0.1:8888 --connection-min-idle 5 wss://myRemoteHost:8080
```

This command will create a socks5 server listening on port 8888 of the loopback interface and will forward traffic
dynamically.
`connection-min-idle 10` is going an optimization to create a pool of 10 connection connected to the server, to speed-up
the establishement of new tunnels.

With firefox you can setup a proxy using this tunnel, by setting in networking preferences 127.0.0.1:8888 and selecting
socks5 proxy.
Be sure to check the option `Proxy DNS when using SOCKS v5` fo

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zed-industries/zed]]></title>
            <link>https://github.com/zed-industries/zed</link>
            <guid>https://github.com/zed-industries/zed</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Code at the speed of thought – Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zed-industries/zed">zed-industries/zed</a></h1>
            <p>Code at the speed of thought – Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.</p>
            <p>Language: Rust</p>
            <p>Stars: 65,868</p>
            <p>Forks: 5,304</p>
            <p>Stars today: 104 stars today</p>
            <h2>README</h2><pre># Zed

[![Zed](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/zed-industries/zed/main/assets/badge/v0.json)](https://zed.dev)
[![CI](https://github.com/zed-industries/zed/actions/workflows/ci.yml/badge.svg)](https://github.com/zed-industries/zed/actions/workflows/ci.yml)

Welcome to Zed, a high-performance, multiplayer code editor from the creators of [Atom](https://github.com/atom/atom) and [Tree-sitter](https://github.com/tree-sitter/tree-sitter).

---

### Installation

On macOS and Linux you can [download Zed directly](https://zed.dev/download) or [install Zed via your local package manager](https://zed.dev/docs/linux#installing-via-a-package-manager).

Other platforms are not yet available:

- Windows ([tracking issue](https://github.com/zed-industries/zed/issues/5394))
- Web ([tracking issue](https://github.com/zed-industries/zed/issues/5396))

### Developing Zed

- [Building Zed for macOS](./docs/src/development/macos.md)
- [Building Zed for Linux](./docs/src/development/linux.md)
- [Building Zed for Windows](./docs/src/development/windows.md)
- [Running Collaboration Locally](./docs/src/development/local-collaboration.md)

### Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for ways you can contribute to Zed.

Also... we&#039;re hiring! Check out our [jobs](https://zed.dev/jobs) page for open roles.

### Licensing

License information for third party dependencies must be correctly provided for CI to pass.

We use [`cargo-about`](https://github.com/EmbarkStudios/cargo-about) to automatically comply with open source licenses. If CI is failing, check the following:

- Is it showing a `no license specified` error for a crate you&#039;ve created? If so, add `publish = false` under `[package]` in your crate&#039;s Cargo.toml.
- Is the error `failed to satisfy license requirements` for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license&#039;s requirements. If you&#039;re unsure, ask a lawyer. Once you&#039;ve verified that this system is acceptable add the license&#039;s SPDX identifier to the `accepted` array in `script/licenses/zed-licenses.toml`.
- Is `cargo-about` unable to find the license for a dependency? If so, add a clarification field at the end of `script/licenses/zed-licenses.toml`, as specified in the [cargo-about book](https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ArthurBrussee/brush]]></title>
            <link>https://github.com/ArthurBrussee/brush</link>
            <guid>https://github.com/ArthurBrussee/brush</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[3D Reconstruction for all]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ArthurBrussee/brush">ArthurBrussee/brush</a></h1>
            <p>3D Reconstruction for all</p>
            <p>Language: Rust</p>
            <p>Stars: 2,559</p>
            <p>Forks: 113</p>
            <p>Stars today: 224 stars today</p>
            <h2>README</h2><pre># Brush

&lt;video src=https://github.com/user-attachments/assets/5756967a-846c-44cf-bde9-3ca4c86f1a4d&gt;A video showing various Brush features and scenes&lt;/video&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;
    Massive thanks to &lt;a href=&quot;https://www.youtube.com/@gradeeterna&quot;&gt;@GradeEterna&lt;/a&gt; for the beautiful scenes
  &lt;/i&gt;
&lt;/p&gt;

Brush is a 3D reconstruction engine using [Gaussian splatting](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/). It works on a wide range of systems: **macOS/windows/linux**, **AMD/Nvidia/Intel** cards, **Android**, and in a **browser**. To achieve this, it uses WebGPU compatible tech and the [Burn](https://github.com/tracel-ai/burn) machine learning framework.

Machine learning for real time rendering has tons of potential, but most ML tools don&#039;t work well with it: Rendering requires realtime interactivity, usually involve dynamic shapes &amp; computations, don&#039;t run on most platforms, and it can be cumbersome to ship apps with large CUDA deps. Brush on the other hand produces simple dependency free binaries, runs on nearly all devices, without any setup.

[**Try the web demo** &lt;img src=&quot;https://cdn-icons-png.flaticon.com/256/888/888846.png&quot; alt=&quot;chrome logo&quot; width=&quot;24&quot;/&gt;
](https://arthurbrussee.github.io/brush-demo)
_NOTE: Only works on Chrome and Edge. Firefox and Safari are hopefully supported soon)_

[![](https://dcbadge.limes.pink/api/server/https://discord.gg/TbxJST2BbC)](https://discord.gg/TbxJST2BbC)

# Features

## Training

Brush takes in COLMAP data or datasets in the Nerfstudio format. Training is fully supported natively, on mobile, and in a browser. While training you can interact with the scene and see the training dynamics live, and compare the current rendering to input views as the training progresses.

It also supports masking images:
- Images with transparency. This will force the final splat to match the transparency of the input.
- A folder of images called &#039;masks&#039;. This ignores parts of the image that are masked out.

## Viewer
Brush also works well as a splat viewer, including on the web. It can load .ply &amp; .compressed.ply files. You can stream in data from a URL (for a web app, simply append `?url=`).

Brush also can load .zip of splat files to display them as an animation, or a special ply that includes delta frames (see [cat-4D](https://cat-4d.github.io/) and [Cap4D](https://felixtaubner.github.io/cap4d/)!).

## CLI
Brush can be used as a CLI. Run `brush --help` to get an overview. Every CLI command can work with `--with-viewer` which also opens the UI, for easy debugging.

## Rerun

https://github.com/user-attachments/assets/f679fec0-935d-4dd2-87e1-c301db9cdc2c

While training, additional data can be visualized with the excellent [rerun](https://rerun.io/). To install rerun on your machine, please follow their [instructions](https://rerun.io/docs/getting-started/installing-viewer). Open the ./brush_blueprint.rbl in the viewer for best results.

## Building Brush
First install rust 1.88+. You can run tests with `cargo test --all`. Brush uses the wonderful [rerun](https://rerun.io/) for additional visualizations while training, run `cargo install rerun-cli` if you want to use it.

### Windows/macOS/Linux
Simply `cargo run` or `cargo run --release` from the workspace root. Brush can also be used as a CLI, run `cargo run --release -- --help` to use the CLI directly from source. See the notes about the CLI in the features section.

### Web
Brush can be compiled to WASM. Run `npm run dev` to start the demo website using Next.js, see the brush_nextjs directory.

Brush uses [`wasm-pack`](https://rustwasm.github.io/wasm-bindgen/introduction.html) to build the WASM bundle. You can also use it without a bundler, see [wasm-pack&#039;s documentation](hhttps://rustwasm.github.io/wasm-bindgen/examples/without-a-bundler.html).

WebGPU is still an upcoming standard, and as such, only Chrome 134+ on Windows and macOS is currently supported.

### Android

As a one time setup, make sure you have the Android SDK &amp; NDK installed.
- Check if ANDROID_NDK_HOME and ANDROID_HOME are set
- Add the Android target to rust `rustup target add aarch64-linux-android`
- Install cargo-ndk to manage building a lib `cargo install cargo-ndk`

Each time you change the rust code, run
- `cargo ndk -t arm64-v8a -o crates/brush-app/app/src/main/jniLibs/ build`
- Nb:  Nb, for best performance, build in release mode. This is separate
  from the Android Studio app build configuration.
- `cargo ndk -t arm64-v8a -o crates/brush-app/app/src/main/jniLibs/  build --release`

You can now either run the project from Android Studio (Android Studio does NOT build the rust code), or run it from the command line:
```
./gradlew build
./gradlew installDebug
adb shell am start -n com.splats.app/.MainActivity
```

You can also open this folder as a project in Android Studio and run things from there. Nb: Running in Android Studio does _not_ rebuild the rust code automatically.

## Benchmarks

Rendering and training are generally faster than gsplat. You can run benchmarks of some of the kernels using `cargo bench`.

# Acknowledgements

[**gSplat**](https://github.com/nerfstudio-project/gsplat), for their reference version of the kernels

**Peter Hedman, George Kopanas &amp; Bernhard Kerbl**, for the many discussions &amp; pointers.

**The Burn team**, for help &amp; improvements to Burn along the way

**Raph Levien**, for the [original version](https://github.com/googlefonts/compute-shader-101/pull/31) of the GPU radix sort.

**GradeEterna**, for feedback and their scenes.

# Disclaimer

This is *not* an official Google product. This repository is a forked public version of [the google-research repository](https://github.com/google-research/google-research/tree/master/brush_splat)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[swc-project/swc]]></title>
            <link>https://github.com/swc-project/swc</link>
            <guid>https://github.com/swc-project/swc</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Rust-based platform for the Web]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/swc-project/swc">swc-project/swc</a></h1>
            <p>Rust-based platform for the Web</p>
            <p>Language: Rust</p>
            <p>Stars: 32,718</p>
            <p>Forks: 1,346</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://swc.rs/&quot;&gt;
    &lt;img alt=&quot;swc&quot; src=&quot;https://raw.githubusercontent.com/swc-project/logo/master/swc.png&quot; width=&quot;546&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  Make the web (development) faster.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@swc/core&quot;&gt;
    &lt;img alt=&quot;downloads (@swc/core)&quot; src=&quot;https://img.shields.io/npm/dm/@swc/core?label=downloads%20%28%40swc%2Fcore%29&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/@swc/counter?activeTab=dependents&quot;&gt;
    &lt;img alt=&quot;downloads (3rd party)&quot; src=&quot;https://img.shields.io/npm/dm/@swc/counter?label=downloads%20%283rd%20party%29&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://crates.io/crates/swc_ecma_parser&quot;&gt;
    &lt;img alt=&quot;undefined&quot; src=&quot;https://img.shields.io/crates/d/swc_ecma_parser.svg?label=crates.io%20downloads&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/swc-project/swc/releases/latest&quot;&gt;
    &lt;img alt=&quot;GitHub release (latest SemVer)&quot; src=&quot;https://img.shields.io/github/v/release/swc-project/swc&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;GitHub code size in bytes&quot; src=&quot;https://img.shields.io/github/languages/code-size/swc-project/swc&quot;&gt;
  &lt;a href=&quot;https://github.com/swc-project/swc/blob/main/package.json#L22&quot;&gt;
    &lt;img alt=&quot;node-current (scoped)&quot; src=&quot;https://img.shields.io/node/v/@swc/core&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.com/invite/GnHbXTdZz6&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/889779439272075314&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

SWC (stands for `Speedy Web Compiler`) is a super-fast TypeScript / JavaScript compiler written in Rust. It&#039;s a library for Rust and JavaScript at the same time. If you are using SWC from Rust, see [rustdoc](https://rustdoc.swc.rs/swc/) and for most users, your entry point for using the library will be [parser](https://rustdoc.swc.rs/swc_ecma_parser/).

Also, SWC tries to ensure that

&gt; If you select the latest version of each crates, it will work

for rust users.

MSRV of crates is currently `1.73`.

To update all SWC crates you use, you can run `curl https://raw.githubusercontent.com/swc-project/swc/main/scripts/update-all-swc-crates.sh | bash -s`. This script will update all dependencies to the latest version and run `cargo build` to ensure that everything works.
Note that you need

-   `jq`
-   `cargo upgrade`

command to run the script.

Supported Node Versions:

-   Node v10+ for usage
-   Node v20+ for development

---

If you are using SWC from JavaScript, please refer to [docs on the website](https://swc.rs/docs/installation/).

# Documentation

Check out the documentation [in the website](https://swc.rs/docs/installation/).

# Features

Please see [comparison with babel](https://swc.rs/docs/migrating-from-babel).

# Performance

Please see [benchmark results](https://swc.rs/docs/benchmark-transform) on the website.

# Supporting development

&lt;h2 align=&quot;center&quot;&gt;Supporting swc&lt;/h2&gt;

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=swc-project/swc&amp;type=Timeline)](https://www.star-history.com/#swc-project/swc&amp;Timeline)

## Powered by

[![JetBrains logo.](https://resources.jetbrains.com/storage/products/company/brand/logos/jetbrains.svg)](https://jb.gg/OpenSourceSupport)

## Sponsors

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opencollective.com/swc&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/swc-project/swc-sponsor-images/main/sponsors.svg&quot; alt=&quot;Sponsors&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

SWC is a community-driven project, and is maintained by a group of [volunteers](https://swc.rs/docs/team). If you&#039;d like to help support the future of the project, please consider:

-   Giving developer time on the project. (Message us on [Discord](https://discord.gg/GnHbXTdZz6) (preferred) or [Github discussions](https://github.com/swc-project/swc/discussions) for guidance!)
-   Giving funds by becoming a sponsor (see https://opencollective.com/swc)!

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md). You may also find the architecture
documentation useful ([ARCHITECTURE.md](ARCHITECTURE.md)).

## License

SWC is primarily distributed under the terms of the Apache License (Version 2.0).

See [LICENSE](LICENSE) for details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[meilisearch/meilisearch]]></title>
            <link>https://github.com/meilisearch/meilisearch</link>
            <guid>https://github.com/meilisearch/meilisearch</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[A lightning-fast search engine API bringing AI-powered hybrid search to your sites and applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/meilisearch/meilisearch">meilisearch/meilisearch</a></h1>
            <p>A lightning-fast search engine API bringing AI-powered hybrid search to your sites and applications.</p>
            <p>Language: Rust</p>
            <p>Stars: 53,232</p>
            <p>Forks: 2,168</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=logo#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/meilisearch-logo-light.svg?sanitize=true#gh-light-mode-only&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=logo#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/meilisearch-logo-dark.svg?sanitize=true#gh-dark-mode-only&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Website&lt;/a&gt; |
  &lt;a href=&quot;https://roadmap.meilisearch.com/tabs/1-under-consideration&quot;&gt;Roadmap&lt;/a&gt; |
  &lt;a href=&quot;https://www.meilisearch.com/pricing?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Meilisearch Cloud&lt;/a&gt; |
  &lt;a href=&quot;https://blog.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Blog&lt;/a&gt; |
  &lt;a href=&quot;https://www.meilisearch.com/docs?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Documentation&lt;/a&gt; |
  &lt;a href=&quot;https://www.meilisearch.com/docs/faq?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;FAQ&lt;/a&gt; |
  &lt;a href=&quot;https://discord.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Discord&lt;/a&gt;
&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://deps.rs/repo/github/meilisearch/meilisearch&quot;&gt;&lt;img src=&quot;https://deps.rs/repo/github/meilisearch/meilisearch/status.svg&quot; alt=&quot;Dependency status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/meilisearch/meilisearch/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-MIT-informational&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/meilisearch/meilisearch/queue&quot;&gt;&lt;img alt=&quot;Merge Queues enabled&quot; src=&quot;https://img.shields.io/badge/Merge_Queues-enabled-%2357cf60?logo=github&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;⚡ A lightning-fast search engine that fits effortlessly into your apps, websites, and workflow 🔍&lt;/p&gt;

[Meilisearch](https://www.meilisearch.com?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=intro) helps you shape a delightful search experience in a snap, offering features that work out of the box to speed up your workflow.

&lt;p align=&quot;center&quot; name=&quot;demo&quot;&gt;
  &lt;a href=&quot;https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demo-gif#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/demo-light.gif#gh-light-mode-only&quot; alt=&quot;A bright colored application for finding movies screening near the user&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demo-gif#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/demo-dark.gif#gh-dark-mode-only&quot; alt=&quot;A dark colored application for finding movies screening near the user&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## 🖥 Examples

- [**Movies**](https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=organization) — An application to help you find streaming platforms to watch movies using [hybrid search](https://www.meilisearch.com/solutions/hybrid-search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos).
- [**Ecommerce**](https://ecommerce.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) — Ecommerce website using disjunctive [facets](https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos), range and rating filtering, and pagination.
- [**Songs**](https://music.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) — Search through 47 million of songs.
- [**SaaS**](https://saas.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) — Search for contacts, deals, and companies in this [multi-tenant](https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) CRM application.

See the list of all our example apps in our [demos repository](https://github.com/meilisearch/demos).

## ✨ Features
- **Hybrid search:** Combine the best of both [semantic](https://www.meilisearch.com/docs/learn/experimental/vector_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features) &amp; full-text search to get the most relevant results
- **Search-as-you-type:** Find &amp; display results in less than 50 milliseconds to provide an intuitive experience
- **[Typo tolerance](https://www.meilisearch.com/docs/learn/relevancy/typo_tolerance_settings?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** get relevant matches even when queries contain typos and misspellings
- **[Filtering](https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features) and [faceted search](https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** enhance your users&#039; search experience with custom filters and build a faceted search interface in a few lines of code
- **[Sorting](https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** sort results based on price, date, or pretty much anything else your users need
- **[Synonym support](https://www.meilisearch.com/docs/learn/relevancy/synonyms?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** configure synonyms to include more relevant content in your search results
- **[Geosearch](https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** filter and sort documents based on geographic data
- **[Extensive language support](https://www.meilisearch.com/docs/learn/what_is_meilisearch/language?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** search datasets in any language, with optimized support for Chinese, Japanese, Hebrew, and languages using the Latin alphabet
- **[Security management](https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** control which users can access what data with API keys that allow fine-grained permissions handling
- **[Multi-Tenancy](https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** personalize search results for any number of application tenants
- **Highly Customizable:** customize Meilisearch to your specific needs or use our out-of-the-box and hassle-free presets
- **[RESTful API](https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** integrate Meilisearch in your technical stack with our plugins and SDKs
- **AI-ready:** works out of the box with [langchain](https://www.meilisearch.com/with/langchain) and the [model context protocol](https://github.com/meilisearch/meilisearch-mcp)
- **Easy to install, deploy, and maintain**

## 📖 Documentation

You can consult Meilisearch&#039;s documentation at [meilisearch.com/docs](https://www.meilisearch.com/docs/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=docs).

## 🚀 Getting started

For basic instructions on how to set up Meilisearch, add documents to an index, and search for documents, take a look at our [documentation](https://www.meilisearch.com/docs?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=get-started) guide.

## 🌍 Supercharge your Meilisearch experience

Say goodbye to server deployment and manual updates with [Meilisearch Cloud](https://www.meilisearch.com/cloud?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch). Additional features include analytics &amp; monitoring in many regions around the world. No credit card is required.

## 🧰 SDKs &amp; integration tools

Install one of our SDKs in your project for seamless integration between Meilisearch and your favorite language or framework!

Take a look at the complete [Meilisearch integration list](https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=sdks-link).

[![Logos belonging to different languages and frameworks supported by Meilisearch, including React, Ruby on Rails, Go, Rust, and PHP](assets/integrations.png)](https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=sdks-logos)

## ⚙️ Advanced usage

Experienced users will want to keep our [API Reference](https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced) close at hand.

We also offer a wide range of dedicated guides to all Meilisearch features, such as [filtering](https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), [sorting](https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), [geosearch](https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), [API keys](https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), and [tenant tokens](https://www.meilisearch.com/docs/learn/security/tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced).

Finally, for more in-depth information, refer to our articles explaining fundamental Meilisearch concepts such as [documents](https://www.meilisearch.com/docs/learn/core_concepts/documents?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced) and [indexes](https://www.meilisearch.com/docs/learn/core_concepts/indexes?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced).

## 🧾 Editions &amp; Licensing

Meilisearch is available in two editions:

### 🧪 Community Edition (CE)

- Fully open source under the [MIT license](./LICENSE)
- Core search engine with fast and relevant full-text, semantic or hybrid search
- Free to use for anyone, including commercial usage

### 🏢 Enterprise Edition (EE)

- Includes advanced features such as:
  - Sharding
- Governed by a [commercial license](./LICENSE-EE) or the [Business Source License 1.1](https://mariadb.com/bsl11)
- Not allowed in production without a commercial agreement with Meilisearch.
  - You may use, modify, and distribute the Licensed Work for non-production purposes only, such as testing, development, or evaluation.

Want access to Enterprise features? → Contact us at [sales@meilisearch.com](maito:sales@meilisearch.com).

## 📊 Telemetry

Meilisearch collects **anonymized** user data to help us improve our product. You can [deactivate this](https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=telemetry#how-to-disable-data-collection) whenever you want.

To request deletion of collected data, please write to us at [privacy@meilisearch.com](mailto:privacy@meilisearch.com). Remember to include your `Instance UID` in the message, as this helps us quickly find and delete your data.

If you want to know more about the kind of data we collect and what we use it for, check the [telemetry section](https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=telemetry#how-to-disable-data-collection) of our documentation.

## 📫 Get in touch!

Meilisearch is a search engine created by [Meili](https://www.meilisearch.com/careers), a software development company headquartered in France and with team members all over the world. Want to know more about us? [Check out our blog!](https://blog.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=contact)

🗞 [Subscribe to our newsletter](https://meilisearch.us2.list-manage.com/subscribe?u=27870f7b71c908a8b359599fb&amp;id=79582d828e) if you don&#039;t want to miss any updates! We promise we won&#039;t clutter your mailbox: we only send one edition every two months.

💌 Want to make a suggestion or give feedback? Here are some of the channels where you can reach us:

- For feature requests, please visit our [product repository](https://github.com/meilisearch/product/discussions)
- Found a bug? Open an [issue](https://github.com/meilisearch/meilisearch/issues)!
- Want to be part of our Discord community? [Join us!](https://discord.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=contact)

Thank you for your support!

## 👩‍💻 Contributing

Meilisearch is, and will always be, open-source! If you want to contribute to the project, please look at [our contribution guidelines](CONTRIBUTING.md).

## 📦 Versioning

Meilisearch releases and their associated binaries are available on the project&#039;s [releases page](https://github.com/meilisearch/meilisearch/releases).

The binaries are versioned following [SemVer conventions](https://semver.org/). To know more, read our [versioning policy](./documentation/versioning-policy.md).

Differently from the binaries, crates in this repository are not currently available on [crates.io](https://crates.io/) and do not follow [SemVer conventions](https://semver.org).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 67,766</p>
            <p>Forks: 2,018</p>
            <p>Stars today: 89 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- 🚀 A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`,
  and more.
- ⚡️ [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- 🗂️ Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- ❇️ [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- 🐍 [Installs and manages](#python-versions) Python versions.
- 🛠️ [Runs and installs](#tools) tools published as Python packages.
- 🔩 Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a
  familiar CLI.
- 🏢 Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- 💾 Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- ⏬ Installable without Rust or Python via `curl` or `pip`.
- 🖥️ Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows — and experience a 10-100x speedup — with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Platform support

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

## Versioning policy

See uv&#039;s [versioning policy](https://docs.astral.sh/uv/reference/versioning/) document.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv/blob/main/CONTRIBUTING.md) to get started.

## FAQ

#### How do you pronounce uv?

It&#039;s pronounced as &quot;you - vee&quot; ([`/juː viː/`](https://en.wikipedia.org/wiki/Help:IPA/English#Key))

#### How should I stylize uv?

Just &quot;uv&quot;, please. See the [style guide](./STYLE.md#styling-uv) for details.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cloud-hypervisor/cloud-hypervisor]]></title>
            <link>https://github.com/cloud-hypervisor/cloud-hypervisor</link>
            <guid>https://github.com/cloud-hypervisor/cloud-hypervisor</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[A Virtual Machine Monitor for modern Cloud workloads. Features include CPU, memory and device hotplug, support for running Windows and Linux guests, device offload with vhost-user and a minimal compact footprint. Written in Rust with a strong focus on security.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cloud-hypervisor/cloud-hypervisor">cloud-hypervisor/cloud-hypervisor</a></h1>
            <p>A Virtual Machine Monitor for modern Cloud workloads. Features include CPU, memory and device hotplug, support for running Windows and Linux guests, device offload with vhost-user and a minimal compact footprint. Written in Rust with a strong focus on security.</p>
            <p>Language: Rust</p>
            <p>Stars: 4,801</p>
            <p>Forks: 520</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>- [1. What is Cloud Hypervisor?](#1-what-is-cloud-hypervisor)
  - [Objectives](#objectives)
    - [High Level](#high-level)
    - [Architectures](#architectures)
    - [Guest OS](#guest-os)
- [2. Getting Started](#2-getting-started)
  - [Host OS](#host-os)
  - [Use Pre-built Binaries](#use-pre-built-binaries)
  - [Packages](#packages)
  - [Building from Source](#building-from-source)
  - [Booting Linux](#booting-linux)
    - [Firmware Booting](#firmware-booting)
    - [Custom Kernel and Disk Image](#custom-kernel-and-disk-image)
      - [Building your Kernel](#building-your-kernel)
      - [Disk image](#disk-image)
      - [Booting the guest VM](#booting-the-guest-vm)
- [3. Status](#3-status)
  - [Hot Plug](#hot-plug)
  - [Device Model](#device-model)
  - [Roadmap](#roadmap)
- [4. Relationship with _Rust VMM_ Project](#4-relationship-with-rust-vmm-project)
  - [Differences with Firecracker and crosvm](#differences-with-firecracker-and-crosvm)
- [5. Community](#5-community)
  - [Contribute](#contribute)
  - [Slack](#slack)
  - [Mailing list](#mailing-list)
  - [Security issues](#security-issues)

# 1. What is Cloud Hypervisor?

Cloud Hypervisor is an open source Virtual Machine Monitor (VMM) that runs on
top of the [KVM](https://www.kernel.org/doc/Documentation/virtual/kvm/api.txt)
hypervisor and the Microsoft Hypervisor (MSHV).

The project focuses on running modern, _Cloud Workloads_, on specific, common,
hardware architectures. In this case _Cloud Workloads_ refers to those that are
run by customers inside a Cloud Service Provider. This means modern operating
systems with most I/O handled by
paravirtualised devices (e.g. _virtio_), no requirement for legacy devices, and
64-bit CPUs.

Cloud Hypervisor is implemented in [Rust](https://www.rust-lang.org/) and is
based on the [Rust VMM](https://github.com/rust-vmm) crates.

## Objectives

### High Level

- Runs on KVM or MSHV
- Minimal emulation
- Low latency
- Low memory footprint
- Low complexity
- High performance
- Small attack surface
- 64-bit support only
- CPU, memory, PCI hotplug
- Machine to machine migration

### Architectures

Cloud Hypervisor supports the `x86-64`, `AArch64` and `riscv64`
architectures, with functionality varying across these platforms. The
functionality differences between `x86-64` and `AArch64` are documented
in [#1125](https://github.com/cloud-hypervisor/cloud-hypervisor/issues/1125).
The `riscv64` architecture support is experimental and offers limited
functionality. For more details and instructions, please refer to [riscv
documentation](docs/riscv.md).

### Guest OS

Cloud Hypervisor supports `64-bit Linux` and Windows 10/Windows Server 2019.

# 2. Getting Started

The following sections describe how to build and run Cloud Hypervisor.

## Prerequisites for AArch64

- AArch64 servers (recommended) or development boards equipped with the GICv3
  interrupt controller.

## Host OS

For required KVM functionality and adequate performance the recommended host
kernel version is 5.13. The majority of the CI currently tests with kernel
version 5.15.

## Use Pre-built Binaries

The recommended approach to getting started with Cloud Hypervisor is by using a
pre-built binary. Binaries are available for the [latest
release](https://github.com/cloud-hypervisor/cloud-hypervisor/releases/latest).
Use `cloud-hypervisor-static` for `x86-64` or `cloud-hypervisor-static-aarch64`
for `AArch64` platform.

## Packages

For convenience, packages are also available targeting some popular Linux
distributions. This is thanks to the [Open Build
Service](https://build.opensuse.org). The [OBS
README](https://github.com/cloud-hypervisor/obs-packaging) explains how to
enable the repository in a supported Linux distribution and install Cloud Hypervisor
and accompanying packages. Please report any packaging issues in the
[obs-packaging](https://github.com/cloud-hypervisor/obs-packaging) repository.

## Building from Source

Please see the [instructions for building from source](docs/building.md) if you
do not wish to use the pre-built binaries.

## Booting Linux

Cloud Hypervisor supports direct kernel boot (the x86-64 kernel requires the kernel
built with PVH support or a bzImage) or booting via a firmware (either [Rust Hypervisor
Firmware](https://github.com/cloud-hypervisor/rust-hypervisor-firmware) or an
edk2 UEFI firmware called `CLOUDHV` / `CLOUDHV_EFI`.)

Binary builds of the firmware files are available for the latest release of
[Rust Hypervisor
Firmware](https://github.com/cloud-hypervisor/rust-hypervisor-firmware/releases/latest)
and [our edk2
repository](https://github.com/cloud-hypervisor/edk2/releases/latest)

The choice of firmware depends on your guest OS choice; some experimentation
may be required.

### Firmware Booting

Cloud Hypervisor supports booting disk images containing all needed components
to run cloud workloads, a.k.a. cloud images.

The following sample commands will download an Ubuntu Cloud image, converting
it into a format that Cloud Hypervisor can use and a firmware to boot the image
with.

```shell
$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img
$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-amd64.img focal-server-cloudimg-amd64.raw
$ wget https://github.com/cloud-hypervisor/rust-hypervisor-firmware/releases/download/0.4.2/hypervisor-fw
```

The Ubuntu cloud images do not ship with a default password so it necessary to
use a `cloud-init` disk image to customise the image on the first boot. A basic
`cloud-init` image is generated by this [script](scripts/create-cloud-init.sh).
This seeds the image with a default username/password of `cloud/cloud123`. It
is only necessary to add this disk image on the first boot. Script also assigns
default IP address using `test_data/cloud-init/ubuntu/local/network-config` details
with `--net &quot;mac=12:34:56:78:90:ab,tap=&quot;` option. Then the matching mac address
interface will be enabled as per `network-config` details.

```shell
$ sudo setcap cap_net_admin+ep ./cloud-hypervisor
$ ./create-cloud-init.sh
$ ./cloud-hypervisor \
	--firmware ./hypervisor-fw \
	--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \
	--cpus boot=4 \
	--memory size=1024M \
	--net &quot;tap=,mac=,ip=,mask=&quot;
```

If access to the firmware messages or interaction with the boot loader (e.g.
GRUB) is required then it necessary to switch to the serial console instead of
`virtio-console`.

```shell
$ ./cloud-hypervisor \
	--kernel ./hypervisor-fw \
	--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \
	--cpus boot=4 \
	--memory size=1024M \
	--net &quot;tap=,mac=,ip=,mask=&quot; \
	--serial tty \
	--console off
```

## Booting: `--firmware` vs `--kernel`

The following scenarios are supported by Cloud Hypervisor to bootstrap a VM, i.e.,
to load a payload/bootitem(s):

- Provide firmware
- Provide kernel \[+ cmdline\]\ [+ initrd\]

Please note that our Cloud Hypervisor firmware (`hypervisor-fw`) has a Xen PVH
boot entry, therefore it can also be booted via the `--kernel` parameter, as 
seen in some examples.

### Custom Kernel and Disk Image

#### Building your Kernel

Cloud Hypervisor also supports direct kernel boot. For x86-64, a `vmlinux` ELF kernel (compiled with PVH support) or a regular bzImage are supported. In order to support development there is a custom branch; however provided the required options are enabled any recent kernel will suffice.

To build the kernel:

```shell
# Clone the Cloud Hypervisor Linux branch
$ git clone --depth 1 https://github.com/cloud-hypervisor/linux.git -b ch-6.12.8 linux-cloud-hypervisor
$ pushd linux-cloud-hypervisor
$ make ch_defconfig
# Do native build of the x86-64 kernel
$ KCFLAGS=&quot;-Wa,-mx86-used-note=no&quot; make bzImage -j `nproc`
# Do native build of the AArch64 kernel
$ make -j `nproc`
$ popd
```

For x86-64, the `vmlinux` kernel image will then be located at
`linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin`.
For AArch64, the `Image` kernel image will then be located at
`linux-cloud-hypervisor/arch/arm64/boot/Image`.

#### Disk image

For the disk image the same Ubuntu image as before can be used. This contains
an `ext4` root filesystem.

```shell
$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-amd64.img # x86-64
$ wget https://cloud-images.ubuntu.com/focal/current/focal-server-cloudimg-arm64.img # AArch64
$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-amd64.img focal-server-cloudimg-amd64.raw # x86-64
$ qemu-img convert -p -f qcow2 -O raw focal-server-cloudimg-arm64.img focal-server-cloudimg-arm64.raw # AArch64
```

#### Booting the guest VM

These sample commands boot the disk image using the custom kernel whilst also
supplying the desired kernel command line.

- x86-64

```shell
$ sudo setcap cap_net_admin+ep ./cloud-hypervisor
$ ./create-cloud-init.sh
$ ./cloud-hypervisor \
	--kernel ./linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin \
	--disk path=focal-server-cloudimg-amd64.raw path=/tmp/ubuntu-cloudinit.img \
	--cmdline &quot;console=hvc0 root=/dev/vda1 rw&quot; \
	--cpus boot=4 \
	--memory size=1024M \
	--net &quot;tap=,mac=,ip=,mask=&quot;
```

- AArch64

```shell
$ sudo setcap cap_net_admin+ep ./cloud-hypervisor
$ ./create-cloud-init.sh
$ ./cloud-hypervisor \
	--kernel ./linux-cloud-hypervisor/arch/arm64/boot/Image \
	--disk path=focal-server-cloudimg-arm64.raw path=/tmp/ubuntu-cloudinit.img \
	--cmdline &quot;console=hvc0 root=/dev/vda1 rw&quot; \
	--cpus boot=4 \
	--memory size=1024M \
	--net &quot;tap=,mac=,ip=,mask=&quot;
```

If earlier kernel messages are required the serial console should be used instead of `virtio-console`.

- x86-64

```shell
$ ./cloud-hypervisor \
	--kernel ./linux-cloud-hypervisor/arch/x86/boot/compressed/vmlinux.bin \
	--console off \
	--serial tty \
	--disk path=focal-server-cloudimg-amd64.raw \
	--cmdline &quot;console=ttyS0 root=/dev/vda1 rw&quot; \
	--cpus boot=4 \
	--memory size=1024M \
	--net &quot;tap=,mac=,ip=,mask=&quot;
```

- AArch64

```shell
$ ./cloud-hypervisor \
	--kernel ./linux-cloud-hypervisor/arch/arm64/boot/Image \
	--console off \
	--serial tty \
	--disk path=focal-server-cloudimg-arm64.raw \
	--cmdline &quot;console=ttyAMA0 root=/dev/vda1 rw&quot; \
	--cpus boot=4 \
	--memory size=1024M \
	--net &quot;tap=,mac=,ip=,mask=&quot;
```

# 3. Status

Cloud Hypervisor is under active development. The following stability
guarantees are currently made:

* The API (including command line options) will not be removed or changed in a
  breaking way without a minimum of 2 major releases notice. Where possible
  warnings will be given about the use of deprecated functionality and the
  deprecations will be documented in the release notes.

* Point releases will be made between individual releases where there are
  substantial bug fixes or security issues that need to be fixed. These point
  releases will only include bug fixes.

Currently the following items are **not** guaranteed across updates:

* Snapshot/restore is not supported across different versions
* Live migration is not supported across different versions
* The following features are considered experimental and may change
  substantially between releases: TDX, vfio-user, vDPA.

Further details can be found in the [release documentation](docs/releases.md).

As of 2023-01-03, the following cloud images are supported:

- [Ubuntu Focal](https://cloud-images.ubuntu.com/focal/current/) (focal-server-cloudimg-{amd64,arm64}.img)
- [Ubuntu Jammy](https://cloud-images.ubuntu.com/jammy/current/) (jammy-server-cloudimg-{amd64,arm64}.img)
- [Ubuntu Noble](https://cloud-images.ubuntu.com/noble/current/) (noble-server-cloudimg-{amd64,arm64}.img)
- [Fedora 36](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/) ([Fedora-Cloud-Base-36-1.5.x86_64.raw.xz](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/x86_64/images/) / [Fedora-Cloud-Base-36-1.5.aarch64.raw.xz](https://archives.fedoraproject.org/pub/archive/fedora/linux/releases/36/Cloud/aarch64/images/))

Direct kernel boot to userspace should work with a rootfs from most
distributions although you may need to enable exotic filesystem types in the
reference kernel configuration (e.g. XFS or btrfs.)

## Hot Plug

Cloud Hypervisor supports hotplug of CPUs, passthrough devices (VFIO),
`virtio-{net,block,pmem,fs,vsock}` and memory resizing. This
[document](docs/hotplug.md) details how to add devices to a running VM.

## Device Model

Details of the device model can be found in this
[documentation](docs/device_model.md).

## Roadmap

The project roadmap is tracked through a [GitHub
project](https://github.com/orgs/cloud-hypervisor/projects/6).

# 4. Relationship with _Rust VMM_ Project

In order to satisfy the design goal of having a high-performance,
security-focused hypervisor the decision was made to use the
[Rust](https://www.rust-lang.org/) programming language. The language&#039;s strong
focus on memory and thread safety makes it an ideal candidate for implementing
VMMs.

Instead of implementing the VMM components from scratch, Cloud Hypervisor is
importing the [Rust VMM](https://github.com/rust-vmm) crates, and sharing code
and architecture together with other VMMs like e.g. Amazon&#039;s
[Firecracker](https://firecracker-microvm.github.io/) and Google&#039;s
[crosvm](https://chromium.googlesource.com/chromiumos/platform/crosvm/).

Cloud Hypervisor embraces the _Rust VMM_ project&#039;s goals, which is to be able
to share and re-use as many virtualization crates as possible.

## Differences with Firecracker and crosvm

A large part of the Cloud Hypervisor code is based on either the Firecracker or
the crosvm project&#039;s implementations. Both of these are VMMs written in Rust
with a focus on safety and security, like Cloud Hypervisor.

The goal of the Cloud Hypervisor project differs from the aforementioned
projects in that it aims to be a general purpose VMM for _Cloud Workloads_ and
not limited to container/serverless or client workloads.

The Cloud Hypervisor community thanks the communities of both the Firecracker
and crosvm projects for their excellent work.

# 5. Community

The Cloud Hypervisor project follows the governance, and community guidelines
described in the [Community](https://github.com/cloud-hypervisor/community)
repository.

## Contribute

The project strongly believes in building a global, diverse and collaborative
community around the Cloud Hypervisor project. Anyone who is interested in
[contributing](CONTRIBUTING.md) to the project is welcome to participate.

Contributing to a open source project like Cloud Hypervisor covers a lot more
than just sending code. Testing, documentation, pull request
reviews, bug reports, feature requests, project improvement suggestions, etc,
are all equal and welcome means of contribution. See the
[CONTRIBUTING](CONTRIBUTING.md) document for more details.

## Slack

Get an [invite to our Slack channel](https://join.slack.com/t/cloud-hypervisor/shared_invite/enQtNjY3MTE3MDkwNDQ4LWQ1MTA1ZDVmODkwMWQ1MTRhYzk4ZGNlN2UwNTI3ZmFlODU0OTcwOWZjMTkwZDExYWE3YjFmNzgzY2FmNDAyMjI),
 [join us on Slack](https://cloud-hypervisor.slack.com/), and [participate in our community activities](https://cloud-hypervisor.slack.com/archives/C04R5DUQVBN).

## Mailing list

Please report bugs using the [GitHub issue
tracker](https://github.com/cloud-hypervisor/cloud-hypervisor/issues) but for
broader community discussions you may use our [mailing
list](https://lists.cloudhypervisor.org/g/dev/).

## Security issues

Please contact the maintainers listed in the MAINTAINERS.md file with security issues.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[firecracker-microvm/firecracker]]></title>
            <link>https://github.com/firecracker-microvm/firecracker</link>
            <guid>https://github.com/firecracker-microvm/firecracker</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[Secure and fast microVMs for serverless computing.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/firecracker-microvm/firecracker">firecracker-microvm/firecracker</a></h1>
            <p>Secure and fast microVMs for serverless computing.</p>
            <p>Language: Rust</p>
            <p>Stars: 30,463</p>
            <p>Forks: 2,078</p>
            <p>Stars today: 24 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/fc_logo_full_transparent-bg_white-fg.png&quot;&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/images/fc_logo_full_transparent-bg.png&quot;&gt;
   &lt;img alt=&quot;Firecracker Logo Title&quot; width=&quot;750&quot; src=&quot;docs/images/fc_logo_full_transparent-bg.png&quot;&gt;
&lt;/picture&gt;

Our mission is to enable secure, multi-tenant, minimal-overhead execution of
container and function workloads.

Read more about the Firecracker Charter [here](CHARTER.md).

## What is Firecracker?

Firecracker is an open source virtualization technology that is purpose-built
for creating and managing secure, multi-tenant container and function-based
services that provide serverless operational models. Firecracker runs workloads
in lightweight virtual machines, called microVMs, which combine the security and
isolation properties provided by hardware virtualization technology with the
speed and flexibility of containers.

## Overview

The main component of Firecracker is a virtual machine monitor (VMM) that uses
the Linux Kernel Virtual Machine (KVM) to create and run microVMs. Firecracker
has a minimalist design. It excludes unnecessary devices and guest-facing
functionality to reduce the memory footprint and attack surface area of each
microVM. This improves security, decreases the startup time, and increases
hardware utilization. Firecracker has also been integrated in container
runtimes, for example
[Kata Containers](https://github.com/kata-containers/kata-containers) and
[Flintlock](https://github.com/liquidmetal-dev/flintlock).

Firecracker was developed at Amazon Web Services to accelerate the speed and
efficiency of services like [AWS Lambda](https://aws.amazon.com/lambda/) and
[AWS Fargate](https://aws.amazon.com/fargate/). Firecracker is open sourced
under [Apache version 2.0](LICENSE).

To read more about Firecracker, check out
[firecracker-microvm.io](https://firecracker-microvm.github.io).

## Getting Started

To get started with Firecracker, download the latest
[release](https://github.com/firecracker-microvm/firecracker/releases) binaries
or build it from source.

You can build Firecracker on any Unix/Linux system that has Docker running (we
use a development container) and `bash` installed, as follows:

```bash
git clone https://github.com/firecracker-microvm/firecracker
cd firecracker
tools/devtool build
toolchain=&quot;$(uname -m)-unknown-linux-musl&quot;
```

The Firecracker binary will be placed at
`build/cargo_target/${toolchain}/debug/firecracker`. For more information on
building, testing, and running Firecracker, go to the
[quickstart guide](docs/getting-started.md).

The overall security of Firecracker microVMs, including the ability to meet the
criteria for safe multi-tenant computing, depends on a well configured Linux
host operating system. A configuration that we believe meets this bar is
included in [the production host setup document](docs/prod-host-setup.md).

## Contributing

Firecracker is already running production workloads within AWS, but it&#039;s still
Day 1 on the journey guided by our [mission](CHARTER.md). There&#039;s a lot more to
build and we welcome all contributions.

To contribute to Firecracker, check out the development setup section in the
[getting started guide](docs/getting-started.md) and then the Firecracker
[contribution guidelines](CONTRIBUTING.md).

## Releases

New Firecracker versions are released via the GitHub repository
[releases](https://github.com/firecracker-microvm/firecracker/releases) page,
typically every two or three months. A history of changes is recorded in our
[changelog](CHANGELOG.md).

The Firecracker release policy is detailed [here](docs/RELEASE_POLICY.md).

## Design

Firecracker&#039;s overall architecture is described in
[the design document](docs/design.md).

## Features &amp; Capabilities

Firecracker consists of a single micro Virtual Machine Manager process that
exposes an API endpoint to the host once started. The API is
[specified in OpenAPI format](src/firecracker/swagger/firecracker.yaml). Read
more about it in the [API docs](docs/api_requests).

The **API endpoint** can be used to:

- Configure the microvm by:
  - Setting the number of vCPUs (the default is 1).
  - Setting the memory size (the default is 128 MiB).
  - Configuring a [CPU template](docs/cpu_templates/cpu-templates.md).
- Add one or more network interfaces to the microVM.
- Add one or more read-write or read-only disks to the microVM, each represented
  by a file-backed block device.
- Trigger a block device re-scan while the guest is running. This enables the
  guest OS to pick up size changes to the block device&#039;s backing file.
- Change the backing file for a block device, before or after the guest boots.
- Configure rate limiters for virtio devices which can limit the bandwidth,
  operations per second, or both.
- Configure the logging and metric system.
- `[BETA]` Configure the data tree of the guest-facing metadata service. The
  service is only available to the guest if this resource is configured.
- Add a [vsock socket](docs/vsock.md) to the microVM.
- Add a [entropy device](docs/entropy.md) to the microVM.
- Start the microVM using a given kernel image, root file system, and boot
  arguments.
- [x86_64 only] Stop the microVM.

**Built-in Capabilities**:

- Demand fault paging and CPU oversubscription enabled by default.
- Advanced, thread-specific seccomp filters for enhanced security.
- [Jailer](docs/jailer.md) process for starting Firecracker in production
  scenarios; applies a cgroup/namespace isolation barrier and then drops
  privileges.

## Tested platforms

We test all combinations of:

| Instance                               | Host OS &amp; Kernel | Guest Rootfs | Guest Kernel |
| :------------------------------------- | :--------------- | :----------- | :----------- |
| m5n.metal (Intel Cascade Lake)         | al2 linux_5.10   | ubuntu 24.04 | linux_5.10   |
| m6i.metal (Intel Ice Lake)             | al2023 linux_6.1 |              | linux_6.1    |
| m7i.metal-24xl (Intel Sapphire Rapids) |                  |              |              |
| m7i.metal-48xl (Intel Sapphire Rapids) |                  |              |              |
| m6a.metal (AMD Milan)                  |                  |              |              |
| m7a.metal-48xl (AMD Genoa)             |                  |              |              |
| m6g.metal (Graviton 2)                 |                  |              |              |
| m7g.metal (Graviton 3)                 |                  |              |              |
| m8g.metal-24xl (Graviton 4)            |                  |              |              |
| m8g.metal-48xl (Graviton 4)            |                  |              |              |

## Known issues and Limitations

- The `pl031` RTC device on aarch64 does not support interrupts, so guest
  programs which use an RTC alarm (e.g. `hwclock`) will not work.

## Performance

Firecracker&#039;s performance characteristics are listed as part of the
[specification documentation](SPECIFICATION.md). All specifications are a part
of our commitment to supporting container and function workloads in serverless
operational models, and are therefore enforced via continuous integration
testing.

## Policy for Security Disclosures

The security of Firecracker is our top priority. If you suspect you have
uncovered a vulnerability, contact us privately, as outlined in our
[security policy document](SECURITY.md); we will immediately prioritize your
disclosure.

## FAQ &amp; Contact

Frequently asked questions are collected in our [FAQ doc](FAQ.md).

You can get in touch with the Firecracker community in the following ways:

- Security-related issues, see our [security policy document](SECURITY.md).
- Chat with us on our
  [Slack workspace](https://join.slack.com/t/firecracker-microvm/shared_invite/zt-2tc0mfxpc-tU~HYAYSzLDl5XGGJU3YIg)
  _Note: most of the maintainers are on a European time zone._
- Open a GitHub issue in this repository.
- Email the maintainers at
  [firecracker-maintainers@amazon.com](mailto:firecracker-maintainers@amazon.com).

When communicating within the Firecracker community, please mind our
[code of conduct](CODE_OF_CONDUCT.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BoundaryML/baml]]></title>
            <link>https://github.com/BoundaryML/baml</link>
            <guid>https://github.com/BoundaryML/baml</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:10 GMT</pubDate>
            <description><![CDATA[The AI framework that adds the engineering to prompt engineering (Python/TS/Ruby/Java/C#/Rust/Go compatible)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BoundaryML/baml">BoundaryML/baml</a></h1>
            <p>The AI framework that adds the engineering to prompt engineering (Python/TS/Ruby/Java/C#/Rust/Go compatible)</p>
            <p>Language: Rust</p>
            <p>Stars: 5,850</p>
            <p>Forks: 273</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://boundaryml.com?utm_source=github&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;fern/assets/baml-lamb-white.png&quot;&gt;
    &lt;img src=&quot;fern/assets/baml-lamb-white.png&quot; height=&quot;64&quot; id=&quot;top&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![BAML Version](https://img.shields.io/pypi/v/baml-py?color=006dad&amp;label=BAML%20Version)](https://pypi.org/project/baml-py/)

## BAML: Basically a Made-up Language
&lt;h4&gt;

[Homepage](https://www.boundaryml.com/) | [Docs](https://docs.boundaryml.com) | [BAML AI Chat](https://www.boundaryml.com/chat) | [Discord](https://discord.gg/BTNBeXGuaS)



&lt;/h4&gt;


&lt;/div&gt;

BAML is a simple prompting language for building reliable **AI workflows and agents**.

BAML makes prompt engineering easy by turning it into _schema engineering_ -- where you mostly focus on the models of your prompt -- to get more reliable outputs. 
You don&#039;t need to write your whole app in BAML, only the prompts! You can wire-up your LLM Functions in any language of your choice! See our quickstarts for [Python](https://docs.boundaryml.com/guide/installation-language/python), [TypeScript](https://docs.boundaryml.com/guide/installation-language/typescript), [Ruby](https://docs.boundaryml.com/guide/installation-language/ruby) and [Go, and more](https://docs.boundaryml.com/guide/installation-language/rest-api-other-languages).

BAML comes with all batteries included -- with full typesafety, streaming, retries, wide model support, even when they don&#039;t support native [tool-calling APIs](#enable-reliable-tool-calling-with-any-model-even-when-they-dont-support-it)

**Try BAML**: [Prompt Fiddle](https://www.promptfiddle.com) • [Interactive App Examples](https://baml-examples.vercel.app/)


## The core BAML principle: LLM Prompts are functions

The fundamental building block in BAML is a function. Every prompt is a function that takes in parameters and returns a type.

```rust
function ChatAgent(message: Message[], tone: &quot;happy&quot; | &quot;sad&quot;) -&gt; string
```

Every function additionally defines which models it uses and what its prompt is.

```rust
function ChatAgent(message: Message[], tone: &quot;happy&quot; | &quot;sad&quot;) -&gt; StopTool | ReplyTool {
    client &quot;openai/gpt-4o-mini&quot;

    prompt #&quot;
        Be a {{ tone }} bot.

        {{ ctx.output_format }}

        {% for m in message %}
        {{ _.role(m.role) }}
        {{ m.content }}
        {% endfor %}
    &quot;#
}

class Message {
    role string
    content string
}

class ReplyTool {
  response string
}

class StopTool {
  action &quot;stop&quot; @description(#&quot;
    when it might be a good time to end the conversation
  &quot;#)
}
```

## BAML Functions can be called from any language
Below we call the ChatAgent function we defined in BAML through Python. BAML&#039;s Rust compiler generates a &quot;baml_client&quot; to access and call them.

```python
from baml_client import b
from baml_client.types import Message, StopTool

messages = [Message(role=&quot;assistant&quot;, content=&quot;How can I help?&quot;)]

while True:
  print(messages[-1].content)
  user_reply = input()
  messages.append(Message(role=&quot;user&quot;, content=user_reply))
  tool = b.ChatAgent(messages, &quot;happy&quot;)
  if isinstance(tool, StopTool):
    print(&quot;Goodbye!&quot;)
    break
  else:
    messages.append(Message(role=&quot;assistant&quot;, content=tool.response))
```
You can write any kind of agent or workflow using chained BAML functions. An agent is a while loop that calls a Chat BAML Function with some state.

And if you need to stream, add a couple more lines:
```python
stream = b.stream.ChatAgent(messages, &quot;happy&quot;)
# partial is a Partial type with all Optional fields
for tool in stream:
    if isinstance(tool, StopTool):
      ...
    
final = stream.get_final_response()
```
And get fully type-safe outputs for each chunk in the stream.

## Test prompts 10x faster, right in your IDE
BAML comes with native tooling for VSCode (jetbrains + neovim coming soon). 

**Visualize full prompt (including any multi-modal assets), and the API request**. BAML gives you full transparency and control of the prompt.

![raw-curl](https://github.com/user-attachments/assets/c0b34db9-80cd-45a7-a356-6b5ab4a9c5b7)

**Using AI is all about iteration speed.**

If testing your pipeline takes 2 minutes, you can only test 10 ideas in 20 minutes.

If you reduce it to 5 seconds, you can test 240 ideas in the same amount of time.
![resume-attempt2-smaller2](https://github.com/user-attachments/assets/6fc6b8a6-ffed-4cfc-80b8-78bc8a3d66a6)

The playground also allows you to run tests in parallel -- for even faster iteration speeds 🚀.

No need to login to websites, and no need to manually define json schemas.

## Enable reliable tool-calling with any model
BAML works even when the models don&#039;t support native tool-calling APIs. We created the SAP (schema-aligned parsing) algorithm to support the flexible outputs LLMs can provide, like markdown within a JSON blob or chain-of-thought prior to answering. [Read more about SAP](https://www.boundaryml.com/blog/schema-aligned-parsing)

With BAML, your structured outputs work in Day-1 of a model release. No need to figure out whether a model supports parallel tool calls, or whether it supports recursive schemas, or `anyOf` or `oneOf` etc.

See it in action with: **[Deepseek-R1](https://www.boundaryml.com/blog/deepseek-r1-function-calling)** and [OpenAI O1](https://www.boundaryml.com/blog/openai-o1).



## Switch from 100s of models in a couple lines
```diff
function Extract() -&gt; Resume {
+  client openai/o3-mini
  prompt #&quot;
    ....
  &quot;#
}
```
[Retry policies](https://docs.boundaryml.com/ref/llm-client-strategies/retry-policy) • [fallbacks](https://docs.boundaryml.com/ref/llm-client-strategies/fallback) • [model rotations](https://docs.boundaryml.com/ref/llm-client-strategies/round-robin). All statically defined.
![Fallback Retry](https://www.boundaryml.com/blog/2025-01-24-ai-agents-need-a-new-syntax/06-fallback-retry.gif)
Want to do pick models at runtime? Check out the [Client Registry](https://docs.boundaryml.com/guide/baml-advanced/llm-client-registry).

We support: [OpenAI](https://docs.boundaryml.com/ref/llm-client-providers/open-ai) • [Anthropic](https://docs.boundaryml.com/ref/llm-client-providers/anthropic) • [Gemini](https://docs.boundaryml.com/ref/llm-client-providers/google-ai-gemini) • [Vertex](https://docs.boundaryml.com/ref/llm-client-providers/google-vertex) • [Bedrock](https://docs.boundaryml.com/ref/llm-client-providers/aws-bedrock) • [Azure OpenAI](https://docs.boundaryml.com/ref/llm-client-providers/open-ai-from-azure) • [Anything OpenAI Compatible](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic) ([Ollama](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-ollama), [OpenRouter](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-open-router), [VLLM](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-v-llm), [LMStudio](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-lm-studio), [TogetherAI](https://docs.boundaryml.com/ref/llm-client-providers/openai-generic-together-ai), and more)

## Build beautiful streaming UIs
BAML generates a ton of utilities for NextJS, Python (and any language) to make streaming UIs easy.
![recipe-generator](https://github.com/user-attachments/assets/cf82495b-21fc-40bf-ae98-93eef923d620)

BAML&#039;s streaming interfaces are fully type-safe. Check out the [Streaming Docs](https://docs.boundaryml.com/guide/baml-basics/streaming), and our [React hooks](https://docs.boundaryml.com/guide/framework-integration/react-next-js/quick-start)

## Fully Open-Source, and offline
- 100% open-source (Apache 2)
- 100% private. AGI will not require an internet connection, neither will BAML
    - No network requests beyond model calls you explicitly set
    - Not stored or used for any training data
- BAML files can be saved locally on your machine and checked into Github for easy diffs.
- Built in Rust. So fast, you can&#039;t even tell it&#039;s there.

## BAML&#039;s Design Philosophy

Everything is fair game when making new syntax. If you can code it, it can be yours. This is our design philosophy to help restrict ideas:

- **1:** Avoid invention when possible
    - Yes, prompts need versioning — we have a great versioning tool: git
    - Yes, you need to save prompts — we have a great storage tool: filesystems
- **2:** Any file editor and any terminal should be enough to use it
- **3:** Be fast
- **4:** A first year university student should be able to understand it

## Why a new programming language

We used to write websites like this:

```python
def home():
    return &quot;&lt;button onclick=\&quot;() =&gt; alert(\\\&quot;hello!\\\&quot;)\&quot;&gt;Click&lt;/button&gt;&quot;
```

And now we do this:

```jsx
function Home() {
  return &lt;button onClick={() =&gt; setCount(prev =&gt; prev + 1)}&gt;
          {count} clicks!
         &lt;/button&gt;
}
```

New syntax can be incredible at expressing new ideas. Plus the idea of maintaining hundreds of f-strings for prompts kind of disgusts us 🤮. Strings are bad for maintainable codebases. We prefer structured strings.

The goal of BAML is to give you the expressiveness of English, but the structure of code.

Full [blog post](https://www.boundaryml.com/blog/ai-agents-need-new-syntax) by us.


## Conclusion

As models get better, we&#039;ll continue expecting even more out of them. But what will never change is that we&#039;ll want a way to write maintainable code that uses those models. The current way we all just assemble strings is very reminiscent of the early days PHP/HTML soup in web development. We hope some of the ideas we shared today can make a tiny dent in helping us all shape the way we all code tomorrow.

## FAQ
|   |   |
| - | - |
| Do I need to write my whole app in BAML? | Nope, only the prompts! BAML translates definitions into the language of your choice! [Python](https://docs.boundaryml.com/guide/installation-language/python), [TypeScript](https://docs.boundaryml.com/guide/installation-language/typescript), [Ruby](https://docs.boundaryml.com/guide/installation-language/ruby) and [more](https://docs.boundaryml.com/guide/installation-language/rest-api-other-languages). |
| Is BAML stable? | Yes, many companies use it in production! We ship updates weekly! |
| Why a new language? | [Jump to section](#why-a-new-programming-language) |


## Contributing
Checkout our [guide on getting started](/CONTRIBUTING.md)

## Citation

You can cite the BAML repo as follows:
```bibtex
@software{baml,
  author = {Boundary ML},
  title = {BAML},
  url = {https://github.com/boundaryml/baml},
  year = {2024}
}
```

---

Made with ❤️ by Boundary

HQ in Seattle, WA

P.S. We&#039;re hiring for software engineers that love rust. [Email us](mailto:founders@boundaryml.com) or reach out on [discord](https://discord.gg/ENtBB6kkXH)!

&lt;div align=&quot;left&quot; style=&quot;align-items: left;&quot;&gt;
        &lt;a href=&quot;#top&quot;&gt;
            &lt;img src=&quot;https://img.shields.io/badge/Back%20to%20Top-000000?style=for-the-badge&amp;logo=github&amp;logoColor=white&quot; alt=&quot;Back to Top&quot;&gt;
        &lt;/a&gt;
&lt;/div&gt;

&lt;img src=&quot;https://imgs.xkcd.com/comics/standards.png&quot; alt_text=&quot;hi&quot; /&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[linera-io/linera-protocol]]></title>
            <link>https://github.com/linera-io/linera-protocol</link>
            <guid>https://github.com/linera-io/linera-protocol</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[Main repository for the Linera protocol]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/linera-io/linera-protocol">linera-io/linera-protocol</a></h1>
            <p>Main repository for the Linera protocol</p>
            <p>Language: Rust</p>
            <p>Stars: 28,528</p>
            <p>Forks: 1,918</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/linera-io/linera-protocol/assets/1105398/fe08c941-93af-4114-bb83-bcc0eaec95f9&quot; width=&quot;250&quot; height=&quot;85&quot; /&gt;

[![License](https://img.shields.io/github/license/linera-io/linera-protocol)](LICENSE)
[![Build Status for Docker](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml)
[![Build Status for Rust](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml)
[![Build Status for Documentation](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml)
[![Twitter](https://img.shields.io/twitter/follow/linera_io)](https://x.com/linera_io)
[![Discord](https://img.shields.io/discord/984941796272521226)](https://discord.com/invite/linera)

&lt;!-- [![Build Status for Kubernetes](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml) --&gt;

[Linera](https://linera.io) is a decentralized blockchain infrastructure designed for highly scalable,
secure, low-latency Web3 applications.

## Documentation

Visit our [developer page](https://linera.dev) and read our
[whitepaper](https://linera.io/whitepaper) to learn more about the Linera protocol.

## Repository Structure

The main crates and directories of this repository can be summarized as follows: (listed
from low to high levels in the dependency graph)

* [`linera-base`](https://linera-io.github.io/linera-protocol/linera_base/index.html) Base
  definitions, including cryptography.

* [`linera-version`](https://linera-io.github.io/linera-protocol/linera_version/index.html)
  A library to manage version info in binaries and services.

* [`linera-views`](https://linera-io.github.io/linera-protocol/linera_views/index.html) A
  library mapping complex data structures onto a key-value store. The corresponding
  procedural macros are implemented in `linera-views-derive`.

* [`linera-execution`](https://linera-io.github.io/linera-protocol/linera_execution/index.html)
  Persistent data and the corresponding logic for runtime and execution of Linera
  applications.

* [`linera-chain`](https://linera-io.github.io/linera-protocol/linera_chain/index.html)
  Persistent data and the corresponding logic for chains of blocks, certificates, and
  cross-chain messaging.

* [`linera-storage`](https://linera-io.github.io/linera-protocol/linera_storage/index.html)
  Defines the storage abstractions for the protocol on top of `linera-chain`.

* [`linera-core`](https://linera-io.github.io/linera-protocol/linera_core/index.html) The
  core Linera protocol, including client and server logic, node synchronization, etc.

* [`linera-rpc`](https://linera-io.github.io/linera-protocol/linera_rpc/index.html)
  Defines the data-type for RPC messages (currently all client &amp;#x2194; proxy &amp;#x2194;
  chain &amp;#x2194; chain interactions), and track the corresponding data schemas.

* [`linera-client`](https://linera-io.github.io/linera-protocol/linera_client/index.html)
  Library for writing Linera clients.  Used for the command-line
  client and the node service in `linera-service`, as well as the Web
  client in [`linera-web`](https://github.com/linera-io/linera-web/).

* [`linera-service`](https://linera-io.github.io/linera-protocol/linera_service/index.html)
  Executable for clients (aka CLI wallets), proxy (aka validator frontend) and servers.

* [`linera-sdk`](https://linera-io.github.io/linera-protocol/linera_sdk/index.html) The
  library to develop Linera applications written in Rust for the Wasm virtual machine. The
  corresponding procedural macros are implemented in `linera-sdk-derive`.

* [`examples`](./examples) Examples of Linera applications written in Rust.

## Prerequisites

See [`INSTALL.md`](./INSTALL.md) for software requirements to develop in this repo.

## Quickstart with the Linera CLI tool

The following commands set up a local test network and run some transfers between the
microchains owned by a single wallet.

```bash
# Make sure to compile the Linera binaries and add them in the $PATH.
# cargo build -p linera-storage-service -p linera-service --bins
export PATH=&quot;$PWD/target/debug:$PATH&quot;

# Import the optional helper function `linera_spawn`.
source /dev/stdin &lt;&lt;&lt;&quot;$(linera net helper 2&gt;/dev/null)&quot;

# Run a local test network with the default parameters and a number of microchains
# owned by the default wallet. This also defines `LINERA_TMP_DIR`.
linera_spawn \
linera net up --with-faucet --faucet-port 8080

# Remember the URL of the faucet.
FAUCET_URL=http://localhost:8080

# If you&#039;re using a testnet, start here and run this instead:
#   LINERA_TMP_DIR=$(mktemp -d)
#   FAUCET_URL=https://faucet.testnet-XXX.linera.net  # for some value XXX

# Set the path of the future wallet.
export LINERA_WALLET=&quot;$LINERA_TMP_DIR/wallet.json&quot;
export LINERA_KEYSTORE=&quot;$LINERA_TMP_DIR/keystore.json&quot;
export LINERA_STORAGE=&quot;rocksdb:$LINERA_TMP_DIR/client.db&quot;

# Initialize a new user wallet.
linera wallet init --faucet $FAUCET_URL

# Request chains.
INFO1=($(linera wallet request-chain --faucet $FAUCET_URL))
INFO2=($(linera wallet request-chain --faucet $FAUCET_URL))
CHAIN1=&quot;${INFO1[0]}&quot;
ACCOUNT1=&quot;${INFO1[1]}&quot;
CHAIN2=&quot;${INFO2[0]}&quot;
ACCOUNT2=&quot;${INFO2[1]}&quot;

# Show the different chains tracked by the wallet.
linera wallet show

# Query the chain balance of some of the chains.
linera query-balance &quot;$CHAIN1&quot;
linera query-balance &quot;$CHAIN2&quot;

# Transfer 10 units then 5 back.
linera transfer 10 --from &quot;$CHAIN1&quot; --to &quot;$CHAIN2&quot;
linera transfer 5 --from &quot;$CHAIN2&quot; --to &quot;$CHAIN1&quot;

# Query balances again.
linera query-balance &quot;$CHAIN1&quot;
linera query-balance &quot;$CHAIN2&quot;

# Now let&#039;s fund the user balances.
linera transfer 5 --from &quot;$CHAIN1&quot; --to &quot;$CHAIN1:$ACCOUNT1&quot;
linera transfer 2 --from &quot;$CHAIN1:$ACCOUNT1&quot; --to &quot;$CHAIN2:$ACCOUNT2&quot;

# Query user balances again.
linera query-balance &quot;$CHAIN1:$ACCOUNT1&quot;
linera query-balance &quot;$CHAIN2:$ACCOUNT2&quot;
```

More complex examples may be found in our [developer manual](https://linera.dev) as well
as the [example applications](./examples) in this repository.

## Contributing

We welcome contributions from the community! If you&#039;d like to contribute to the Linera protocol:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m &#039;Add some amazing feature&#039;`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

For detailed guidelines, see our [contribution guide](./CONTRIBUTING.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[kata-containers/kata-containers]]></title>
            <link>https://github.com/kata-containers/kata-containers</link>
            <guid>https://github.com/kata-containers/kata-containers</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kata-containers/kata-containers">kata-containers/kata-containers</a></h1>
            <p>Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/</p>
            <p>Language: Rust</p>
            <p>Stars: 6,727</p>
            <p>Forks: 1,169</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/6e4619c416ff4bd19e1c087f27a43eea/www-images-prod/openstack-logo/kata/SVG/kata-1.svg&quot; width=&quot;900&quot;&gt;

[![CI | Publish Kata Containers payload](https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml/badge.svg)](https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml) [![Kata Containers Nightly CI](https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml/badge.svg)](https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/kata-containers/kata-containers/badge)](https://scorecard.dev/viewer/?uri=github.com/kata-containers/kata-containers)

# Kata Containers

Welcome to Kata Containers!

This repository is the home of the Kata Containers code for the 2.0 and newer
releases.

If you want to learn about Kata Containers, visit the main
[Kata Containers website](https://katacontainers.io).

## Introduction

Kata Containers is an open source project and community working to build a
standard implementation of lightweight Virtual Machines (VMs) that feel and
perform like containers, but provide the workload isolation and security
advantages of VMs.

## License

The code is licensed under the Apache 2.0 license.
See [the license file](LICENSE) for further details.

## Platform support

Kata Containers currently runs on 64-bit systems supporting the following
technologies:

| Architecture | Virtualization technology |
|-|-|
| `x86_64`, `amd64` | [Intel](https://www.intel.com) VT-x, AMD SVM |
| `aarch64` (&quot;`arm64`&quot;)| [ARM](https://www.arm.com) Hyp |
| `ppc64le` | [IBM](https://www.ibm.com) Power |
| `s390x` | [IBM](https://www.ibm.com) Z &amp; LinuxONE SIE |

### Hardware requirements

The [Kata Containers runtime](src/runtime) provides a command to
determine if your host system is capable of running and creating a
Kata Container:

```bash
$ kata-runtime check
```

&gt; **Notes:**
&gt;
&gt; - This command runs a number of checks including connecting to the
&gt;   network to determine if a newer release of Kata Containers is
&gt;   available on GitHub. If you do not wish this to check to run, add
&gt;   the `--no-network-checks` option.
&gt;
&gt; - By default, only a brief success / failure message is printed.
&gt;   If more details are needed, the `--verbose` flag can be used to display the
&gt;   list of all the checks performed.
&gt;
&gt; - If the command is run as the `root` user additional checks are
&gt;   run (including checking if another incompatible hypervisor is running).
&gt;   When running as `root`, network checks are automatically disabled.

## Getting started

See the [installation documentation](docs/install).

## Documentation

See the [official documentation](docs) including:

- [Installation guides](docs/install)
- [Developer guide](docs/Developer-Guide.md)
- [Design documents](docs/design)
  - [Architecture overview](docs/design/architecture)
  - [Architecture 3.0 overview](docs/design/architecture_3.0/)

## Configuration

Kata Containers uses a single
[configuration file](src/runtime/README.md#configuration)
which contains a number of sections for various parts of the Kata
Containers system including the [runtime](src/runtime), the
[agent](src/agent) and the [hypervisor](#hypervisors).

## Hypervisors

See the [hypervisors document](docs/hypervisors.md) and the
[Hypervisor specific configuration details](src/runtime/README.md#hypervisor-specific-configuration).

## Community

To learn more about the project, its community and governance, see the
[community repository](https://github.com/kata-containers/community). This is
the first place to go if you wish to contribute to the project.

## Getting help

See the [community](#community) section for ways to contact us.

### Raising issues

Please raise an issue
[in this repository](https://github.com/kata-containers/kata-containers/issues).

&gt; **Note:**
&gt; If you are reporting a security issue, please follow the [vulnerability reporting process](https://github.com/kata-containers/community#vulnerability-handling)

## Developers

See the [developer guide](docs/Developer-Guide.md).

### Components

### Main components

The table below lists the core parts of the project:

| Component | Type | Description |
|-|-|-|
| [runtime](src/runtime) | core | Main component run by a container manager and providing a containerd shimv2 runtime implementation. |
| [runtime-rs](src/runtime-rs) | core | The Rust version runtime. |
| [agent](src/agent) | core | Management process running inside the virtual machine / POD that sets up the container environment. |
| [`dragonball`](src/dragonball) | core | An optional built-in VMM brings out-of-the-box Kata Containers experience with optimizations on container workloads |
| [documentation](docs) | documentation | Documentation common to all components (such as design and install documentation). |
| [tests](tests) | tests | Excludes unit tests which live with the main code. |

### Additional components

The table below lists the remaining parts of the project:

| Component | Type | Description |
|-|-|-|
| [packaging](tools/packaging) | infrastructure | Scripts and metadata for producing packaged binaries&lt;br/&gt;(components, hypervisors, kernel and rootfs). |
| [kernel](https://www.kernel.org) | kernel | Linux kernel used by the hypervisor to boot the guest image. Patches are stored [here](tools/packaging/kernel). |
| [osbuilder](tools/osbuilder) | infrastructure | Tool to create &quot;mini O/S&quot; rootfs and initrd images and kernel for the hypervisor. |
| [kata-debug](tools/packaging/kata-debug/README.md) | infrastructure | Utility tool to gather Kata Containers debug information from Kubernetes clusters. |
| [`agent-ctl`](src/tools/agent-ctl) | utility | Tool that provides low-level access for testing the agent. |
| [`kata-ctl`](src/tools/kata-ctl) | utility | Tool that provides advanced commands and debug facilities. |
| [`trace-forwarder`](src/tools/trace-forwarder) | utility | Agent tracing helper. |
| [`runk`](src/tools/runk) | utility | Standard OCI container runtime based on the agent. |
| [`ci`](.github/workflows) | CI | Continuous Integration configuration files and scripts. |
| [`ocp-ci`](ci/openshift-ci/README.md) | CI | Continuous Integration configuration for the OpenShift pipelines. |
| [`katacontainers.io`](https://github.com/kata-containers/www.katacontainers.io) | Source for the [`katacontainers.io`](https://www.katacontainers.io) site. |
| [`Webhook`](tools/testing/kata-webhook/README.md) | utility | Example of a simple admission controller webhook to annotate pods with the Kata runtime class |

### Packaging and releases

Kata Containers is now
[available natively for most distributions](docs/install/README.md#packaged-installation-methods).

## General tests

See the [tests documentation](tests/README.md).

## Metrics tests

See the [metrics documentation](tests/metrics/README.md).

## Glossary of Terms

See the [glossary of terms](https://github.com/kata-containers/kata-containers/wiki/Glossary) related to Kata Containers.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[influxdata/influxdb]]></title>
            <link>https://github.com/influxdata/influxdb</link>
            <guid>https://github.com/influxdata/influxdb</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[Scalable datastore for metrics, events, and real-time analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/influxdata/influxdb">influxdata/influxdb</a></h1>
            <p>Scalable datastore for metrics, events, and real-time analytics</p>
            <p>Language: Rust</p>
            <p>Stars: 30,636</p>
            <p>Forks: 3,642</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
 &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/influxdb-logo.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/influxdb-logo-dark.png&quot;&gt;
    &lt;img src=&quot;assets/influxdb-logo.png&quot; alt=&quot;InfluxDB Logo&quot; width=&quot;600&quot;&gt;
  &lt;/picture&gt;
 &lt;p&gt;
&lt;/div&gt;

InfluxDB Core is a database built to collect, process, transform, and store event and time series data. It is ideal for use cases that require real-time ingest and fast query response times to build user interfaces, monitoring, and automation solutions.

Common use cases include:

- Monitoring sensor data
- Server monitoring
- Application performance monitoring
- Network monitoring
- Financial market and trading analytics
- Behavioral analytics

InfluxDB is optimized for scenarios where near real-time data monitoring is essential and queries 
need to return quickly to support user experiences such as dashboards and interactive user interfaces.

InfluxDB 3 Core’s feature highlights include:

- Diskless architecture with object storage support (or local disk with no dependencies)
- Fast query response times (under 10ms for last-value queries, or 30ms for distinct metadata)
- Embedded Python VM for plugins and triggers
- Parquet file persistence
- Compatibility with InfluxDB 1.x and 2.x write APIs
- Compatability with InfluxDB 1.x query API (InfluxQL)
- SQL query engine with support for FlightSQL and HTTP query API

## Project Status

InfluxDB 3 Core is GA as of April 15, 2025! We plan to have monthly point releases for the following six months, with patch releases as needed. We will move to a quarterly cadence after that for 3-4 releases, after which we&#039;ll reevaluate our release schedule.

Join the [InfluxDB3 Discord](https://discord.gg/vZe2w2Ds8B) 
or the public channels below to share your feedback, feature requests, and bug reports.

See the [InfluxDB 3 Core &amp; Enterprise GA release announcement here](https://www.influxdata.com/blog/influxdb-3-oss-ga/) 
or dig into the [InfluxDB 3 getting started guide here](https://docs.influxdata.com/influxdb3/core/get-started/).

## Learn InfluxDB
[Documentation](https://docs.influxdata.com/) | [Community Forum](https://community.influxdata.com/) | [Community Slack](https://www.influxdata.com/slack/) | [Blog](https://www.influxdata.com/blog/) | [InfluxDB University](https://university.influxdata.com/) | [YouTube](https://www.youtube.com/@influxdata8893)

Try **InfluxDB Cloud** for free and get started fast with no local setup required. Click [here](https://cloud2.influxdata.com/signup) to start building your application on InfluxDB Cloud.


## Installation
We have nightly and versioned Docker images, Debian packages, RPM packages, and tarballs of InfluxDB available on the [InfluxData downloads page](https://portal.influxdata.com/downloads/). We also provide the InfluxDB command line interface (CLI) client as a separate binary available at the same location.

- For v1 installation, use the [main 1.x branch](https://github.com/influxdata/influxdb/tree/master-1.x) or [install InfluxDB OSS directly](https://docs.influxdata.com/influxdb/v1/introduction/install/#installing-influxdb-oss).
- For v2 installation, use the [main 2.x branch](https://github.com/influxdata/influxdb/tree/main-2.x).
- For InfluxDB 3 Core see the [InfluxDB 3 Core getting started guide](https://docs.influxdata.com/influxdb3/core/get-started/).
- For InfluxDB 3 Enterprise see the [InfluxDB 3 Enterprise getting started guide](https://docs.influxdata.com/influxdb3/enterprise/get-started/).

If you are interested in building from source, see the [building from source](CONTRIBUTING.md#building-from-source) guide for contributors.

To begin using InfluxDB, visit our [Getting Started with InfluxDB](https://docs.influxdata.com/influxdb/v1/introduction/get-started/) documentation.


## License
The open source software we build is licensed under the permissive MIT or Apache 2 licenses at the user&#039;s choosing. We’ve long held the view that our open source code should be truly open and our commercial code should be separate and closed. 


## Interested in joining the team building InfluxDB?
Check out current job openings at [www.influxdata.com/careers](https://www.influxdata.com/careers) today!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[restatedev/restate]]></title>
            <link>https://github.com/restatedev/restate</link>
            <guid>https://github.com/restatedev/restate</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[Restate is the platform for building resilient applications that tolerate all infrastructure faults w/o the need for a PhD.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/restatedev/restate">restatedev/restate</a></h1>
            <p>Restate is the platform for building resilient applications that tolerate all infrastructure faults w/o the need for a PhD.</p>
            <p>Language: Rust</p>
            <p>Stars: 2,919</p>
            <p>Forks: 103</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>[![Documentation](https://img.shields.io/badge/doc-reference-blue)](https://docs.restate.dev)
[![Examples](https://img.shields.io/badge/view-examples-blue)](https://github.com/restatedev/examples)
[![Discord](https://img.shields.io/discord/1128210118216007792?logo=discord)](https://discord.gg/skW3AZ6uGd)
[![Slack](https://img.shields.io/badge/Slack-4A154B?logo=slack&amp;logoColor=fff)](https://join.slack.com/t/restatecommunity/shared_invite/zt-2v9gl005c-WBpr167o5XJZI1l7HWKImA)
[![Twitter](https://img.shields.io/twitter/follow/restatedev.svg?style=social&amp;label=Follow)](https://x.com/intent/follow?screen_name=restatedev)

# Restate - Building resilient applications made easy!

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://restate.dev/blog/announcing-restate-1.0-restate-cloud-and-our-seed-funding-round/title_figure_hudf3f5cd4c2c091de8198c7c4b273b831_2636815_6620x0_resize_q75_h2_box_3.webp&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://restate.dev/blog/announcing-restate-1.0-restate-cloud-and-our-seed-funding-round/title_figure_hudf3f5cd4c2c091de8198c7c4b273b831_2636815_6620x0_resize_q75_h2_box_3.webp&quot;&gt;
    &lt;img alt=&quot;Restate overview&quot; src=&quot;https://restate.dev/blog/announcing-restate-1.0-restate-cloud-and-our-seed-funding-round/title_figure_hudf3f5cd4c2c091de8198c7c4b273b831_2636815_6620x0_resize_q75_h2_box_3.webp&quot; width=&quot;100%&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

[Restate](https://restate.dev) is the simplest way to build resilient applications.

Restate provides a distributed durable version of your everyday building blocks, letting you build a wide range of use cases:

* [Durable AI Agents](https://github.com/restatedev/ai-examples)
* [Workflows-as-Code](https://docs.restate.dev/use-cases/workflows)
* [Microservice Orchestration](https://docs.restate.dev/use-cases/microservice-orchestration)
* [Event Processing](https://docs.restate.dev/use-cases/event-processing)
* [Async Tasks](https://docs.restate.dev/use-cases/async-tasks)
* [Agents, Stateful Actors, state machines, and much more](https://github.com/restatedev/examples)

## Get started with Restate

1. 🏎 [Follow the Quickstart](https://docs.restate.dev/get_started/quickstart) to get Restate up and running within 2 minutes!
1. 💡 [The Tour of Restate](https://docs.restate.dev/get_started/tour) walks you through the most important features of Restate.

## SDKs

Restate supports the following SDKs:

* [Typescript](https://github.com/restatedev/sdk-typescript)
* [Java and Kotlin](https://github.com/restatedev/sdk-java)
* [Python](https://github.com/restatedev/sdk-python)
* [Go](https://github.com/restatedev/sdk-go)
* [Rust](https://github.com/restatedev/sdk-rust)

## Install

We offer pre-built binaries of the CLI and the server for MacOS and Linux.

Have a look at the [Quickstart](https://docs.restate.dev/get_started/quickstart) or [installation instructions in the docs](https://docs.restate.dev/develop/local_dev). 

### Install the server

Install via Homebrew:
```bash
brew install restatedev/tap/restate-server
```

Run via npx:
```bash
npx @restatedev/restate-server
```

Run via docker:
```bash
docker run --rm -p 8080:8080 -p 9070:9070 -p 9071:9071 \
    --add-host=host.docker.internal:host-gateway docker.restate.dev/restatedev/restate:latest
```

### Install the CLI

Install via Homebrew:
```bash
brew install restatedev/tap/restate
```

Install via npm:
```bash
npm install --global @restatedev/restate
```

Run via npx:
```bash
npx @restatedev/restate
```

You can also download the binaries from the [release page](https://github.com/restatedev/restate/releases) or our [download page](https://restate.dev/get-restate/).

## Community

* 🤗️ Join our online community on [Discord](https://discord.gg/skW3AZ6uGd) or [Slack](https://join.slack.com/t/restatecommunity/shared_invite/zt-2v9gl005c-WBpr167o5XJZI1l7HWKImA) for help, sharing feedback and talking to the community.
* 📖 [Check out our documentation](https://docs.restate.dev) to get started quickly!
* 📣 [Follow us on Twitter](https://twitter.com/restatedev) for staying up to date.
* 🙋 [Create a GitHub issue](https://github.com/restatedev/restate/issues) for requesting a new feature or reporting a problem.
* 🏠 [Visit our GitHub org](https://github.com/restatedev) for exploring other repositories.

## Core primitives

The basic primitives Restate offers to simplify application development are the following:

* **Reliable Execution**: Restate guarantees code runs to completion. Failures result in retries that use the [Durable Execution mechanism](https://docs.restate.dev/concepts/durable_execution) to recover partial progress and prevent re-executing completed steps.
* **Reliable Communication**: Services communicate with exactly-once semantics: whether it&#039;s [request-response, one-way messages, or scheduled tasks](https://docs.restate.dev/concepts/invocations). Restate reliably delivers messages and uses Durable Execution to ensure no losses or duplicates can happen.
* **Durable Promises and Timers**: Register Promises/Futures and timers in Restate to make them resilient to failures (e.g. sleep, webhooks, timers). Restate can recover them across failures, processes, and time.
* **Consistent State**: Implement [stateful entities](https://docs.restate.dev/concepts/services) with isolated K/V state per entity. Restate persists the K/V state updates together with the execution progress to ensure consistent state. Restate attaches the K/V state to the request on invocation, and writes it back upon completion. This is particularly efficient for FaaS deployments (stateful serverless, yay!).
* **Suspending User Code**: long-running code suspends when awaiting on a Promise/Future and resumes when that promise is resolved. This is particularly useful in combination with serverless deployments.
* **Observability &amp; Introspection**: Restate includes a UI and CLI to inspect the [state of your application](https://docs.restate.dev/operate/introspection) across services and invocations. Restate automatically generates Open Telemetry traces for the interactions between handlers.

## Contributing

We’re excited if you join the Restate community and start contributing!
Whether it is feature requests, bug reports, ideas &amp; feedback or PRs, we appreciate any and all contributions.
We know that your time is precious and, therefore, deeply value any effort to contribute!

Check out our [development guidelines](/docs/dev/development-guidelines.md) and [tips for local development](/docs/dev/local-development.md) to get started.

## Versions

Restate follows [Semantic Versioning](https://semver.org/).

You can safely upgrade from a Restate `x.y` to `x.(y+1)` release without performing any manual data migration, as Restate performs an automatic data migration for you.

For SDK compatibility, refer to the supported version matrix in the respective READMEs:

* [Restate Java/Kotlin SDK](https://github.com/restatedev/sdk-java#versions)
* [Restate TypeScript SDK](https://github.com/restatedev/sdk-typescript#versions)
* [Restate Go SDK](https://github.com/restatedev/sdk-go#versions)
* [Restate Python SDK](https://github.com/restatedev/sdk-python#versions)
* [Restate Rust SDK](https://github.com/restatedev/sdk-rust#versions)

### Building Restate locally

In order to build Restate locally [follow the build instructions](https://github.com/restatedev/restate/blob/main/docs/dev/local-development.md#building-restate).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vercel/turborepo]]></title>
            <link>https://github.com/vercel/turborepo</link>
            <guid>https://github.com/vercel/turborepo</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[Build system optimized for JavaScript and TypeScript, written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vercel/turborepo">vercel/turborepo</a></h1>
            <p>Build system optimized for JavaScript and TypeScript, written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 28,682</p>
            <p>Forks: 2,093</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://turborepo.com&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://user-images.githubusercontent.com/4060187/196936123-f6e1db90-784d-4174-b774-92502b718836.png&quot;&gt;
      &lt;img src=&quot;https://user-images.githubusercontent.com/4060187/196936104-5797972c-ab10-4834-bd61-0d1e5f442c9c.png&quot; height=&quot;128&quot;&gt;
    &lt;/picture&gt;
    &lt;h1 align=&quot;center&quot;&gt;Turborepo&lt;/h1&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Vercel logo&quot; href=&quot;https://vercel.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&amp;logo=Vercel&amp;labelColor=000&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;NPM version&quot; href=&quot;https://www.npmjs.com/package/turbo&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/npm/v/turbo.svg?style=for-the-badge&amp;labelColor=000000&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;License&quot; href=&quot;https://github.com/vercel/turborepo/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/npm/l/turbo.svg?style=for-the-badge&amp;labelColor=000000&amp;color=&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;Join the community on GitHub&quot; href=&quot;https://github.com/vercel/turborepo/discussions&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&amp;logo=turborepo&amp;labelColor=000000&amp;logoWidth=20&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Turborepo is a high-performance build system for JavaScript and TypeScript codebases, written in Rust.

## Getting Started

Visit https://turborepo.com to get started with Turborepo.

## Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for more information.

## Community

The Turborepo community can be found on [GitHub Discussions](https://github.com/vercel/turborepo/discussions), where you can ask questions, voice ideas, and share your projects.

To chat with other community members, you can join [Vercel Community&#039;s `#turborepo` tag](https://vercel.community/tag/turborepo).

Our [Code of Conduct](https://github.com/vercel/turborepo/blob/main/CODE_OF_CONDUCT.md) applies to all Turborepo community channels.

## Who is using Turborepo?

Turborepo is used by the world&#039;s leading companies. Check out the [Turborepo Showcase](https://turborepo.com/showcase) to learn more.

## Updates

Follow [@turborepo](https://x.com/turborepo) on X for project updates.

## Authors

**Turborepo**

- Jared Palmer ([@jaredpalmer](https://x.com/jaredpalmer))

## Security

If you believe you have found a security vulnerability in Turborepo, we encourage you to responsibly disclose this and not open a public issue. We will investigate all legitimate reports. Email `security@vercel.com` to disclose any security vulnerabilities.

https://vercel.com/security
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ai-dynamo/dynamo]]></title>
            <link>https://github.com/ai-dynamo/dynamo</link>
            <guid>https://github.com/ai-dynamo/dynamo</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[A Datacenter Scale Distributed Inference Serving Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo</a></h1>
            <p>A Datacenter Scale Distributed Inference Serving Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 5,001</p>
            <p>Forks: 599</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;
![Dynamo banner](./docs/images/frontpage-banner.png)

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)
[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)

| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/762)** | **[Support matrix](https://github.com/ai-dynamo/dynamo/blob/main/docs/support_matrix.md)** | **[Documentation](https://docs.nvidia.com/dynamo/latest/index.html)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Prebuilt containers](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** | **[Blogs](https://developer.nvidia.com/blog/tag/nvidia-dynamo)**

# NVIDIA Dynamo

High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.

## Latest News

* [08/05] Deploy `openai/gpt-oss-120b` with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo [➡️ link](./components/backends/trtllm/gpt-oss.md)

## The Era of Multi-GPU, Multi-Node

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-gpu-vertical.png&quot; alt=&quot;Multi Node Multi-GPU topology&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs—and sometimes many servers—but it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.

Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:

- **Disaggregated prefill &amp; decode inference** – Maximizes GPU throughput and facilitates trade off between throughput and latency.
- **Dynamic GPU scheduling** – Optimizes performance based on fluctuating demand
- **LLM-aware request routing** – Eliminates unnecessary KV cache re-computation
- **Accelerated data transfer** – Reduces inference response time using NIXL.
- **KV cache offloading** – Leverages multiple memory hierarchies for higher system throughput

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-architecture.png&quot; alt=&quot;Dynamo architecture&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

## Framework Support Matrix

| Feature | vLLM | SGLang | TensorRT-LLM |
|---------|----------------------|----------------------------|----------------------------------------|
| [**Disaggregated Serving**](/docs/architecture/disagg_serving.md) | ✅ | ✅ | ✅ |
| [**Conditional Disaggregation**](/docs/architecture/disagg_serving.md#conditional-disaggregation) | 🚧 | 🚧 | 🚧 |
| [**KV-Aware Routing**](/docs/architecture/kv_cache_routing.md) | ✅ | ✅ | ✅ |
| [**Load Based Planner**](/docs/architecture/load_planner.md) | 🚧 | 🚧 | 🚧 |
| [**SLA-Based Planner**](/docs/architecture/sla_planner.md) | ✅ | ✅ | ✅ |
| [**KVBM**](/docs/architecture/kvbm_architecture.md) | ✅ | 🚧 | ✅ |

To learn more about each framework and their capabilities, check out each framework&#039;s README!
- **[vLLM](components/backends/vllm/README.md)**
- **[SGLang](components/backends/sglang/README.md)**
- **[TensorRT-LLM](components/backends/trtllm/README.md)**

Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.

# Installation

The following examples require a few system level packages.
Recommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/support_matrix.md](docs/support_matrix.md)

## 1. Initial setup

The Dynamo team recommends the `uv` Python package manager, although any way works. Install uv:
```
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Install etcd and NATS (required)

To coordinate across a data center, Dynamo relies on etcd and NATS. To run Dynamo locally, these need to be available.

- [etcd](https://etcd.io/) can be run directly as `./etcd`.
- [nats](https://nats.io/) needs jetstream enabled: `nats-server -js`.

To quickly setup etcd &amp; NATS, you can also run:
```
# At the root of the repository:
docker compose -f deploy/docker-compose.yml up -d
```

## 2. Select an engine

We publish Python wheels specialized for each of our supported engines: vllm, sglang, trtllm, and llama.cpp. The examples that follow use SGLang; continue reading for other engines.

```
uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install &quot;ai-dynamo[sglang]&quot;  #replace with [vllm], [trtllm], etc.
```

## 3. Run Dynamo

### Running an LLM API server

Dynamo provides a simple way to spin up a local set of inference components including:

- **OpenAI Compatible Frontend** – High performance OpenAI compatible http api server written in Rust.
- **Basic and Kv Aware Router** – Route and load balance traffic to a set of workers.
- **Workers** – Set of pre-configured LLM serving engines.

```
# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
python -m dynamo.frontend --http-port 8000 [--tls-cert-path cert.pem] [--tls-key-path key.pem]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
python -m dynamo.sglang.worker --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B --skip-tokenizer-init
```

#### Send a Request

```bash
curl localhost:8000/v1/chat/completions   -H &quot;Content-Type: application/json&quot;   -d &#039;{
    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,
    &quot;messages&quot;: [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello, how are you?&quot;
    }
    ],
    &quot;stream&quot;:false,
    &quot;max_tokens&quot;: 300
  }&#039; | jq
```

Rerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.

### Deploying Dynamo

- Follow the [Quickstart Guide](docs/guides/dynamo_deploy/README.md) to deploy on Kubernetes.
- Check out [Backends](components/backends) to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)
- Run some [Examples](examples) to learn about building components in Dynamo and exploring various integrations.

### Benchmarking Dynamo

Dynamo provides comprehensive benchmarking tools to evaluate and optimize your deployments:

* **[Benchmarking Guide](docs/benchmarks/benchmarking.md)** – Compare deployment topologies (aggregated vs. disaggregated vs. vanilla vLLM) using GenAI-Perf
* **[Pre-Deployment Profiling](docs/benchmarks/pre_deployment_profiling.md)** – Optimize configurations before deployment to meet SLA requirements

# Engines

Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (`python -m dynamo.frontend [--interactive]`).

## vLLM

```
uv pip install ai-dynamo[vllm]
```

Run the backend/worker like this:
```
python -m dynamo.vllm --help
```

vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass `--context-length &lt;value&gt;`.

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

## SGLang

```
# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
```

Run the backend/worker like this:
```
python -m dynamo.sglang.worker --help
```

You can pass any sglang flags directly to this worker, see https://docs.sglang.ai/advanced_features/server_arguments.html . See there to use multiple GPUs.

## TensorRT-LLM

It is recommended to use [NGC PyTorch Container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) for running the TensorRT-LLM engine.

&gt; [!Note]
&gt; Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using.
&gt; For example, if you are using `tensorrt-llm==1.1.0rc3`, use the PyTorch container image version `25.06`.
&gt; To find the correct PyTorch container version for your desired `tensorrt-llm` release, visit the [TensorRT-LLM Dockerfile.multi](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docker/Dockerfile.multi) on GitHub. Switch to the branch that matches your `tensorrt-llm` version, and look for the `BASE_TAG` line to identify the recommended PyTorch container tag.

&gt; [!Important]
&gt; Launch container with the following additional settings `--shm-size=1g --ulimit memlock=-1`

### Install prerequisites
```
# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install &quot;cuda-python&gt;=12,&lt;13&quot;

sudo apt-get -y install libopenmpi-dev
```

&gt; [!Tip]
&gt; You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation [here](https://nvidia.github.io/TensorRT-LLM/installation/linux.html).

### After installing the pre-requisites above, install Dynamo
```
uv pip install ai-dynamo[trtllm]
```

Run the backend/worker like this:
```
python -m dynamo.trtllm --help
```

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

# Developing Locally

## 1. Install libraries

**Ubuntu:**
```
sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
```

**macOS:**
- [Homebrew](https://brew.sh/)
```
# if brew is not installed on your system, install it
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
```
- [Xcode](https://developer.apple.com/xcode/)

```
brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
```
If Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.


## 2. Install Rust

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
```

## 3. Create a Python virtual env:

Follow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don&#039;t have `uv` installed. Once uv is installed, create a virtual environment and activate it.

- Install uv
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

- Create a virtual environment
```bash
uv venv dynamo
source dynamo/bin/activate
```

## 4. Install build tools

```
uv pip install pip maturin
```

[Maturin](https://github.com/PyO3/maturin) is the Rust&lt;-&gt;Python bindings build tool.

## 5. Build the Rust bindings

```
cd lib/bindings/python
maturin develop --uv
```

## 6. Install the wheel

```
cd $PROJECT_ROOT
uv pip install .
# For development, use
export PYTHONPATH=&quot;${PYTHONPATH}:$(pwd)/components/frontend/src:$(pwd)/components/planner/src:$(pwd)/components/backends/vllm/src:$(pwd)/components/backends/sglang/src:$(pwd)/components/backends/trtllm/src:$(pwd)/components/backends/llama_cpp/src:$(pwd)/components/backends/mocker/src&quot;
```

&gt; [!Note]
&gt; Editable (`-e`) does not work because the `dynamo` package is split over multiple directories, one per backend.

You should now be able to run `python -m dynamo.frontend`.

Remember that nats and etcd must be running (see earlier).

Set the environment variable `DYN_LOG` to adjust the logging level; for example, `export DYN_LOG=debug`. It has the same syntax as `RUST_LOG`.

If you use vscode or cursor, we have a .devcontainer folder built on [Microsofts Extension](https://code.visualstudio.com/docs/devcontainers/containers). For instructions see the [ReadMe](.devcontainer/README.md) for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[denoland/deno]]></title>
            <link>https://github.com/denoland/deno</link>
            <guid>https://github.com/denoland/deno</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[A modern runtime for JavaScript and TypeScript.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/denoland/deno">denoland/deno</a></h1>
            <p>A modern runtime for JavaScript and TypeScript.</p>
            <p>Language: Rust</p>
            <p>Stars: 104,235</p>
            <p>Forks: 5,710</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># Deno

[![](https://img.shields.io/crates/v/deno.svg)](https://crates.io/crates/deno)
[![Twitter badge][]][Twitter link] [![Bluesky badge][]][Bluesky link]
[![Discord badge][]][Discord link] [![YouTube badge][]][YouTube link]

&lt;img align=&quot;right&quot; src=&quot;https://deno.land/logo.svg&quot; height=&quot;150px&quot; alt=&quot;the deno mascot dinosaur standing in the rain&quot;&gt;

[Deno](https://deno.com)
([/ˈdiːnoʊ/](https://ipa-reader.com/?text=%CB%88di%CB%90no%CA%8A), pronounced
`dee-no`) is a JavaScript, TypeScript, and WebAssembly runtime with secure
defaults and a great developer experience. It&#039;s built on [V8](https://v8.dev/),
[Rust](https://www.rust-lang.org/), and [Tokio](https://tokio.rs/).

Learn more about the Deno runtime
[in the documentation](https://docs.deno.com/runtime/manual).

## Installation

Install the Deno runtime on your system using one of the commands below. Note
that there are a number of ways to install Deno - a comprehensive list of
installation options can be found
[here](https://docs.deno.com/runtime/manual/getting_started/installation).

Shell (Mac, Linux):

```sh
curl -fsSL https://deno.land/install.sh | sh
```

PowerShell (Windows):

```powershell
irm https://deno.land/install.ps1 | iex
```

[Homebrew](https://formulae.brew.sh/formula/deno) (Mac):

```sh
brew install deno
```

[Chocolatey](https://chocolatey.org/packages/deno) (Windows):

```powershell
choco install deno
```

[WinGet](https://winstall.app/apps/DenoLand.Deno) (Windows):

```powershell
winget install --id=DenoLand.Deno
```

### Build and install from source

Complete instructions for building Deno from source can be found
[here](https://github.com/denoland/deno/blob/main/.github/CONTRIBUTING.md#building-from-source).

## Your first Deno program

Deno can be used for many different applications, but is most commonly used to
build web servers. Create a file called `server.ts` and include the following
TypeScript code:

```ts
Deno.serve((_req: Request) =&gt; {
  return new Response(&quot;Hello, world!&quot;);
});
```

Run your server with the following command:

```sh
deno run --allow-net server.ts
```

This should start a local web server on
[http://localhost:8000](http://localhost:8000).

Learn more about writing and running Deno programs
[in the docs](https://docs.deno.com/runtime/manual).

## Additional resources

- **[Deno Docs](https://docs.deno.com)**: official guides and reference docs for
  the Deno runtime, [Deno Deploy](https://deno.com/deploy), and beyond.
- **[Deno Standard Library](https://jsr.io/@std)**: officially supported common
  utilities for Deno programs.
- **[JSR](https://jsr.io/)**: The open-source package registry for modern
  JavaScript and TypeScript
- **[Developer Blog](https://deno.com/blog)**: Product updates, tutorials, and
  more from the Deno team.

## Contributing

We appreciate your help! To contribute, please read our
[contributing instructions](.github/CONTRIBUTING.md).

[Build status - Cirrus]: https://github.com/denoland/deno/workflows/ci/badge.svg?branch=main&amp;event=push
[Build status]: https://github.com/denoland/deno/actions
[Twitter badge]: https://img.shields.io/twitter/follow/deno_land.svg?style=social&amp;label=Follow
[Twitter link]: https://twitter.com/intent/follow?screen_name=deno_land
[Bluesky badge]: https://img.shields.io/badge/Follow-whitesmoke?logo=bluesky
[Bluesky link]: https://bsky.app/profile/deno.land
[YouTube badge]: https://img.shields.io/youtube/channel/subscribers/UCqC2G2M-rg4fzg1esKFLFIw?style=social
[YouTube link]: https://www.youtube.com/@deno_land
[Discord badge]: https://img.shields.io/discord/684898665143206084?logo=discord&amp;style=social
[Discord link]: https://discord.gg/deno
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[mtkennerly/ludusavi]]></title>
            <link>https://github.com/mtkennerly/ludusavi</link>
            <guid>https://github.com/mtkennerly/ludusavi</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[Backup tool for PC game saves]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mtkennerly/ludusavi">mtkennerly/ludusavi</a></h1>
            <p>Backup tool for PC game saves</p>
            <p>Language: Rust</p>
            <p>Stars: 4,239</p>
            <p>Forks: 93</p>
            <p>Stars today: 116 stars today</p>
            <h2>README</h2><pre># ![Logo](assets/icon.svg) Ludusavi
Ludusavi is a tool for backing up your PC video game save data,
written in [Rust](https://www.rust-lang.org).
It is cross-platform and supports multiple game stores.

## Features
* Ability to back up data from more than 19,000 games plus your own custom entries.
* Backup and restore for Steam, GOG, Epic, Heroic, Lutris, and other game libraries.
* Both a graphical interface and command line interface for scripting.
  Tab completion is available for Bash, Fish, Zsh, PowerShell, and Elvish.
* Support for:
  * Saves that are stored as files and in the Windows registry.
  * Proton saves with Steam.
  * Steam screenshots.
* Available as a [Playnite](https://playnite.link) extension:
  https://github.com/mtkennerly/ludusavi-playnite
* Works on the Steam Deck.

This tool uses the [Ludusavi Manifest](https://github.com/mtkennerly/ludusavi-manifest)
for info on what to back up for each game.
The data is primarily sourced from [PCGamingWiki](https://www.pcgamingwiki.com/wiki/Home),
so please contribute any new or fixed data back to the wiki itself,
and your improvements will be incorporated into Ludusavi&#039;s data as well.

If you&#039;d like to help translate Ludusavi into other languages,
[check out the Crowdin project](https://crowdin.com/project/ludusavi).

## Demo
&lt;!-- These anchors are kept for compatibility with old section headers. --&gt;
&lt;a name=&quot;gui&quot;&gt;&lt;/a&gt;

&gt; ![GUI demo of previewing a backup](docs/demo-gui.gif)

## Installation
&lt;!-- These anchors are kept for compatibility with old section headers. --&gt;
&lt;a name=&quot;requirements&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;methods&quot;&gt;&lt;/a&gt;

Download the executable for Windows, Linux, or Mac from the
[releases page](https://github.com/mtkennerly/ludusavi/releases).
It&#039;s portable, so you can simply download it and put it anywhere on your system.

If you prefer, Ludusavi is also available via
[Winget, Scoop, Flatpak, and Cargo](docs/help/installation.md).

Note:

* Windows users may see a popup that says
  &quot;Windows protected your PC&quot;,
  because Windows does not recognize the program&#039;s publisher.
  Click &quot;more info&quot; and then &quot;run anyway&quot; to start the program.
* Mac users may see a popup that says
  &quot;Ludusavi can&#039;t be opened because it is from an unidentified developer&quot;.
  To allow Ludusavi to run, please refer to [this article](https://support.apple.com/en-us/102445),
  specifically the section on `If you want to open an app [...] from an unidentified developer`.

## Usage
&lt;!-- These anchors are kept for compatibility with old section headers. --&gt;
&lt;a name=&quot;backup-exclusions&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;backup-retention&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;backup-structure&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;backup-validation&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;cli-api&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;cloud-backup&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;command-line&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;configuration&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;configuration-file&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;custom-games&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;duplicates&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;environment-variables&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;filter&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;game-launch-wrapping&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;logging&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;redirects&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;roots&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;selective-scanning&quot;&gt;&lt;/a&gt;
&lt;a name=&quot;troubleshooting&quot;&gt;&lt;/a&gt;

Detailed help documentation is available for several topics.

### General
* [Backup automation](/docs/help/backup-automation.md)
* [Backup exclusions](/docs/help/backup-exclusions.md)
* [Backup retention](/docs/help/backup-retention.md)
* [Backup validation](/docs/help/backup-validation.md)
* [Cloud backup](/docs/help/cloud-backup.md)
* [Custom games](/docs/help/custom-games.md)
* [Duplicates](/docs/help/duplicates.md)
* [Filter](/docs/help/filter.md)
* [Game launch wrapping](/docs/help/game-launch-wrapping.md)
* [Redirects](/docs/help/redirects.md)
* [Roots](/docs/help/roots.md)
* [Selective scanning](/docs/help/selective-scanning.md)

### Interfaces
* [Application folder](/docs/help/application-folder.md)
* [Backup structure](/docs/help/backup-structure.md)
* [Command line](/docs/help/command-line.md)
* [Configuration file](/docs/help/configuration-file.md)
* [Environment variables](/docs/help/environment-variables.md)
* [Logging](/docs/help/logging.md)

### Other
* [Troubleshooting](/docs/help/troubleshooting.md)
* [What if my saves aren&#039;t found?](/docs/help/missing-saves.md)

## Community

The community has created some additional resources you may find useful.
Please note that this is not an exhaustive list
and that these projects are not officially affiliated with Ludusavi itself:

* Secondary manifests:
  * https://github.com/BloodShed-Oni/ludusavi-extra-manifests
  * https://github.com/hblamo/ludusavi-emudeck-manifest
  * https://github.com/hvmzx/ludusavi-manifests
    * This has an example of using a scheduled GitHub workflow
      to generate a manifest that adds more paths to the primary manifest&#039;s entries.
* Plugins for Decky Loader on Steam Deck:
  * https://github.com/GedasFX/decky-ludusavi
* Plugins for VS Code:
  * https://marketplace.visualstudio.com/items?itemName=claui.ludusavi
* Tools:
  * https://github.com/jose-l-martins/GSM-to-Ludusavi-converter

## Comparison with other tools
There are other excellent backup tools available, but not a singular
cross-platform and cross-store solution:

* [GameSave Manager](https://www.gamesave-manager.com) (as of v3.1.512.0):
  * Only supports Windows.
  * Much slower than Ludusavi. On the same hardware and with default settings,
    an initial scan of the whole system takes 2 minutes in GSM versus 10 seconds in Ludusavi.
    Performing a backup immediately after that scan takes 4 minutes 16 seconds in GSM versus 4.5 seconds in Ludusavi.
    In this test, GSM found 257 games with 2.84 GB, and Ludusavi found 297 games with 2.95 GiB.
  * Closed source, so the community cannot contribute improvements.
  * Interface can be slow or unresponsive.
    For example, when clicking &quot;select all / de-select all&quot;, each checkbox has to individually toggle itself.
    With 257 games, this means you end up having to wait around 42 seconds.
  * Minimal command line interface.
  * Can create symlinks for games and game data.
    Ludusavi does not support this.
* [Game Backup Monitor](https://mikemaximus.github.io/gbm-web) (as of v1.2.2):
  * Does not support Mac.
  * Database only covers 577 games (as of 2022-11-16), although it can also import
    the Ludusavi manifest starting in 1.3.1.
  * No command line interface.
  * Can automatically back up saves for a game after you play it.
    Ludusavi can only do that in conjunction with a launcher like Playnite.
* [Gaming Backup Multitool for Linux](https://supremesonicbrazil.gitlab.io/gbml-web) (as of v1.4.0.0):
  * Only supports Linux and Steam.
  * Database is not actively updated. As of 2022-11-16, the last update was 2018-06-05.
  * No command line interface.

## Development
Please refer to [CONTRIBUTING.md](./CONTRIBUTING.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[asciinema/asciinema]]></title>
            <link>https://github.com/asciinema/asciinema</link>
            <guid>https://github.com/asciinema/asciinema</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[Terminal session recorder, streamer and player 📹]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/asciinema/asciinema">asciinema/asciinema</a></h1>
            <p>Terminal session recorder, streamer and player 📹</p>
            <p>Language: Rust</p>
            <p>Stars: 15,914</p>
            <p>Forks: 970</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre># asciinema

[![Build Status](https://github.com/asciinema/asciinema/actions/workflows/ci.yml/badge.svg)](https://github.com/asciinema/asciinema/actions/workflows/asciinema.yml)
[![license](http://img.shields.io/badge/license-GNU-blue.svg)](https://raw.githubusercontent.com/asciinema/asciinema/master/LICENSE)

__asciinema__ (aka asciinema CLI or asciinema recorder) is a command-line tool
for recording and live streaming terminal sessions.

Unlike typical _screen_ recording software, which records visual output of a
screen into a heavyweight video files (`.mp4`, `.mov`), asciinema CLI runs
_inside a terminal_, capturing terminal session output into a lightweight
recording files in the
[asciicast](https://docs.asciinema.org/manual/asciicast/v3/) format (`.cast`),
or streaming it live to viewers in real-time.

The recordings can be replayed in a terminal, embedded on a web page with the
[asciinema player](https://docs.asciinema.org/manual/player/), or published to
an [asciinema server](https://docs.asciinema.org/manual/server/), such as
[asciinema.org](https://asciinema.org), for further sharing. Live streams allow
viewers to watch terminal sessions as they happen.

asciinema runs on GNU/Linux, macOS and FreeBSD.

[![asciinema CLI
demo](https://asciinema.org/a/85R4jTtjKVRIYXTcKCNq0vzYH.svg)](https://asciinema.org/a/85R4jTtjKVRIYXTcKCNq0vzYH?autoplay=1)

Notable features:

- recording and replaying of sessions inside a terminal,
- local and remote [live
  streaming](https://docs.asciinema.org/manual/cli/quick-start/#stream-a-terminal-session)
  of terminal sessions to multiple viewers in real-time,
- [lightweight recording
  format](https://docs.asciinema.org/manual/asciicast/v3/), which is highly
  compressible (down to 15% of the original size e.g. with `zstd` or `gzip`),
- integration with [asciinema
  server](https://docs.asciinema.org/manual/server/), e.g.
  [asciinema.org](https://asciinema.org), for easy recording hosting and live
  streaming.

To record a session run this command in your shell:

```sh
asciinema rec demo.cast
```

To stream a session via built-in HTTP server run:

```sh
asciinema stream -l
```

To stream a session via a relay (asciinema server) run:

```sh
asciinema stream -r
```

Check out the [Getting started
guide](https://docs.asciinema.org/getting-started/) for installation and usage
overview.

## Building

Building asciinema from source requires the [Rust](https://www.rust-lang.org/)
compiler (1.75 or later), and the [Cargo package
manager](https://doc.rust-lang.org/cargo/). If they are not available via your
system package manager then use [rustup](https://rustup.rs/).

To download the source code, build the asciinema binary, and install it in
`$HOME/.cargo/bin` in one go run:

```sh
cargo install --locked --git https://github.com/asciinema/asciinema
```

Then, ensure `$HOME/.cargo/bin` is in your shell&#039;s `$PATH`.

Alternatively, you can manually download the source code and build the asciinema
binary with:

```sh
git clone https://github.com/asciinema/asciinema
cd asciinema
cargo build --release
```

This produces the binary at `target/release/asciinema`. You can just copy the
binary to a directory in your `$PATH`.

To generate man pages and shell completion files, set `ASCIINEMA_GEN_DIR` to the
path where these artifacts should be stored. For example:

```sh
ASCIINEMA_GEN_DIR=/foo cargo build --release
```

The above command will build the binary and place the man pages in `/foo/man/`,
and the shell completion files in the `/foo/completion/` directory.

&gt; [!NOTE]
&gt; Windows is currently not supported. See [#467](https://github.com/orgs/asciinema/discussions/278).

## Development

All development happens on `develop` branch. This branch contains the current
generation (3.x) of the asciinema CLI, written in Rust.

The previous generation (2.x), written in Python, can be found in the `python`
branch.

If you wish to propose non-trivial code changes, please first reach out to the
team via [forum](https://discourse.asciinema.org/),
[Matrix](https://matrix.to/#/#asciinema:matrix.org) or
[IRC](https://web.libera.chat/#asciinema).

## Donations

Sustainability of asciinema development relies on donations and sponsorships.

If you like the project then consider becoming a
[supporter](https://docs.asciinema.org/donations/#individuals) or a [corporate
sponsor](https://docs.asciinema.org/donations/#corporate-sponsorship).

asciinema is sponsored by:

- [Brightbox](https://www.brightbox.com/)
- [DataDog](https://datadoghq.com/)

## Consulting

If you&#039;re interested in integration or customization of asciinema to suit your
needs, check [asciinema consulting
services](https://docs.asciinema.org/consulting/).

## License

© 2011 Marcin Kulik.

All code is licensed under the GPL, v3 or later. See [LICENSE](./LICENSE) file
for details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/ruff]]></title>
            <link>https://github.com/astral-sh/ruff</link>
            <guid>https://github.com/astral-sh/ruff</guid>
            <pubDate>Thu, 18 Sep 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[An extremely fast Python linter and code formatter, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/ruff">astral-sh/ruff</a></h1>
            <p>An extremely fast Python linter and code formatter, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 42,496</p>
            <p>Forks: 1,535</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;!-- Begin section: Overview --&gt;

# Ruff

[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![image](https://img.shields.io/pypi/v/ruff.svg)](https://pypi.python.org/pypi/ruff)
[![image](https://img.shields.io/pypi/l/ruff.svg)](https://github.com/astral-sh/ruff/blob/main/LICENSE)
[![image](https://img.shields.io/pypi/pyversions/ruff.svg)](https://pypi.python.org/pypi/ruff)
[![Actions status](https://github.com/astral-sh/ruff/workflows/CI/badge.svg)](https://github.com/astral-sh/ruff/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.com/invite/astral-sh)

[**Docs**](https://docs.astral.sh/ruff/) | [**Playground**](https://play.ruff.rs/)

An extremely fast Python linter and code formatter, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://user-images.githubusercontent.com/1309177/232603514-c95e9b0f-6b31-43de-9a80-9e844173fd6a.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://user-images.githubusercontent.com/1309177/232603516-4fb4892d-585c-4b20-b810-3db9161831e4.svg&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://user-images.githubusercontent.com/1309177/232603516-4fb4892d-585c-4b20-b810-3db9161831e4.svg&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Linting the CPython codebase from scratch.&lt;/i&gt;
&lt;/p&gt;

- ⚡️ 10-100x faster than existing linters (like Flake8) and formatters (like Black)
- 🐍 Installable via `pip`
- 🛠️ `pyproject.toml` support
- 🤝 Python 3.13 compatibility
- ⚖️ Drop-in parity with [Flake8](https://docs.astral.sh/ruff/faq/#how-does-ruffs-linter-compare-to-flake8), isort, and [Black](https://docs.astral.sh/ruff/faq/#how-does-ruffs-formatter-compare-to-black)
- 📦 Built-in caching, to avoid re-analyzing unchanged files
- 🔧 Fix support, for automatic error correction (e.g., automatically remove unused imports)
- 📏 Over [800 built-in rules](https://docs.astral.sh/ruff/rules/), with native re-implementations
    of popular Flake8 plugins, like flake8-bugbear
- ⌨️ First-party [editor integrations](https://docs.astral.sh/ruff/editors) for [VS Code](https://github.com/astral-sh/ruff-vscode) and [more](https://docs.astral.sh/ruff/editors/setup)
- 🌎 Monorepo-friendly, with [hierarchical and cascading configuration](https://docs.astral.sh/ruff/configuration/#config-file-discovery)

Ruff aims to be orders of magnitude faster than alternative tools while integrating more
functionality behind a single, common interface.

Ruff can be used to replace [Flake8](https://pypi.org/project/flake8/) (plus dozens of plugins),
[Black](https://github.com/psf/black), [isort](https://pypi.org/project/isort/),
[pydocstyle](https://pypi.org/project/pydocstyle/), [pyupgrade](https://pypi.org/project/pyupgrade/),
[autoflake](https://pypi.org/project/autoflake/), and more, all while executing tens or hundreds of
times faster than any individual tool.

Ruff is extremely actively developed and used in major open-source projects like:

- [Apache Airflow](https://github.com/apache/airflow)
- [Apache Superset](https://github.com/apache/superset)
- [FastAPI](https://github.com/tiangolo/fastapi)
- [Hugging Face](https://github.com/huggingface/transformers)
- [Pandas](https://github.com/pandas-dev/pandas)
- [SciPy](https://github.com/scipy/scipy)

...and [many more](#whos-using-ruff).

Ruff is backed by [Astral](https://astral.sh). Read the [launch post](https://astral.sh/blog/announcing-astral-the-company-behind-ruff),
or the original [project announcement](https://notes.crmarsh.com/python-tooling-could-be-much-much-faster).

## Testimonials

[**Sebastián Ramírez**](https://twitter.com/tiangolo/status/1591912354882764802), creator
of [FastAPI](https://github.com/tiangolo/fastapi):

&gt; Ruff is so fast that sometimes I add an intentional bug in the code just to confirm it&#039;s actually
&gt; running and checking the code.

[**Nick Schrock**](https://twitter.com/schrockn/status/1612615862904827904), founder of [Elementl](https://www.elementl.com/),
co-creator of [GraphQL](https://graphql.org/):

&gt; Why is Ruff a gamechanger? Primarily because it is nearly 1000x faster. Literally. Not a typo. On
&gt; our largest module (dagster itself, 250k LOC) pylint takes about 2.5 minutes, parallelized across 4
&gt; cores on my M1. Running ruff against our _entire_ codebase takes .4 seconds.

[**Bryan Van de Ven**](https://github.com/bokeh/bokeh/pull/12605), co-creator
of [Bokeh](https://github.com/bokeh/bokeh/), original author
of [Conda](https://docs.conda.io/en/latest/):

&gt; Ruff is ~150-200x faster than flake8 on my machine, scanning the whole repo takes ~0.2s instead of
&gt; ~20s. This is an enormous quality of life improvement for local dev. It&#039;s fast enough that I added
&gt; it as an actual commit hook, which is terrific.

[**Timothy Crosley**](https://twitter.com/timothycrosley/status/1606420868514877440),
creator of [isort](https://github.com/PyCQA/isort):

&gt; Just switched my first project to Ruff. Only one downside so far: it&#039;s so fast I couldn&#039;t believe
&gt; it was working till I intentionally introduced some errors.

[**Tim Abbott**](https://github.com/astral-sh/ruff/issues/465#issuecomment-1317400028), lead
developer of [Zulip](https://github.com/zulip/zulip):

&gt; This is just ridiculously fast... `ruff` is amazing.

&lt;!-- End section: Overview --&gt;

## Table of Contents

For more, see the [documentation](https://docs.astral.sh/ruff/).

1. [Getting Started](#getting-started)
1. [Configuration](#configuration)
1. [Rules](#rules)
1. [Contributing](#contributing)
1. [Support](#support)
1. [Acknowledgements](#acknowledgements)
1. [Who&#039;s Using Ruff?](#whos-using-ruff)
1. [License](#license)

## Getting Started&lt;a id=&quot;getting-started&quot;&gt;&lt;/a&gt;

For more, see the [documentation](https://docs.astral.sh/ruff/).

### Installation

Ruff is available as [`ruff`](https://pypi.org/project/ruff/) on PyPI.

Invoke Ruff directly with [`uvx`](https://docs.astral.sh/uv/):

```shell
uvx ruff check   # Lint all files in the current directory.
uvx ruff format  # Format all files in the current directory.
```

Or install Ruff with `uv` (recommended), `pip`, or `pipx`:

```shell
# With uv.
uv tool install ruff@latest  # Install Ruff globally.
uv add --dev ruff            # Or add Ruff to your project.

# With pip.
pip install ruff

# With pipx.
pipx install ruff
```

Starting with version `0.5.0`, Ruff can be installed with our standalone installers:

```shell
# On macOS and Linux.
curl -LsSf https://astral.sh/ruff/install.sh | sh

# On Windows.
powershell -c &quot;irm https://astral.sh/ruff/install.ps1 | iex&quot;

# For a specific version.
curl -LsSf https://astral.sh/ruff/0.13.0/install.sh | sh
powershell -c &quot;irm https://astral.sh/ruff/0.13.0/install.ps1 | iex&quot;
```

You can also install Ruff via [Homebrew](https://formulae.brew.sh/formula/ruff), [Conda](https://anaconda.org/conda-forge/ruff),
and with [a variety of other package managers](https://docs.astral.sh/ruff/installation/).

### Usage

To run Ruff as a linter, try any of the following:

```shell
ruff check                          # Lint all files in the current directory (and any subdirectories).
ruff check path/to/code/            # Lint all files in `/path/to/code` (and any subdirectories).
ruff check path/to/code/*.py        # Lint all `.py` files in `/path/to/code`.
ruff check path/to/code/to/file.py  # Lint `file.py`.
ruff check @arguments.txt           # Lint using an input file, treating its contents as newline-delimited command-line arguments.
```

Or, to run Ruff as a formatter:

```shell
ruff format                          # Format all files in the current directory (and any subdirectories).
ruff format path/to/code/            # Format all files in `/path/to/code` (and any subdirectories).
ruff format path/to/code/*.py        # Format all `.py` files in `/path/to/code`.
ruff format path/to/code/to/file.py  # Format `file.py`.
ruff format @arguments.txt           # Format using an input file, treating its contents as newline-delimited command-line arguments.
```

Ruff can also be used as a [pre-commit](https://pre-commit.com/) hook via [`ruff-pre-commit`](https://github.com/astral-sh/ruff-pre-commit):

```yaml
- repo: https://github.com/astral-sh/ruff-pre-commit
  # Ruff version.
  rev: v0.13.0
  hooks:
    # Run the linter.
    - id: ruff-check
      args: [ --fix ]
    # Run the formatter.
    - id: ruff-format
```

Ruff can also be used as a [VS Code extension](https://github.com/astral-sh/ruff-vscode) or with [various other editors](https://docs.astral.sh/ruff/editors/setup).

Ruff can also be used as a [GitHub Action](https://github.com/features/actions) via
[`ruff-action`](https://github.com/astral-sh/ruff-action):

```yaml
name: Ruff
on: [ push, pull_request ]
jobs:
  ruff:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/ruff-action@v3
```

### Configuration&lt;a id=&quot;configuration&quot;&gt;&lt;/a&gt;

Ruff can be configured through a `pyproject.toml`, `ruff.toml`, or `.ruff.toml` file (see:
[_Configuration_](https://docs.astral.sh/ruff/configuration/), or [_Settings_](https://docs.astral.sh/ruff/settings/)
for a complete list of all configuration options).

If left unspecified, Ruff&#039;s default configuration is equivalent to the following `ruff.toml` file:

```toml
# Exclude a variety of commonly ignored directories.
exclude = [
    &quot;.bzr&quot;,
    &quot;.direnv&quot;,
    &quot;.eggs&quot;,
    &quot;.git&quot;,
    &quot;.git-rewrite&quot;,
    &quot;.hg&quot;,
    &quot;.ipynb_checkpoints&quot;,
    &quot;.mypy_cache&quot;,
    &quot;.nox&quot;,
    &quot;.pants.d&quot;,
    &quot;.pyenv&quot;,
    &quot;.pytest_cache&quot;,
    &quot;.pytype&quot;,
    &quot;.ruff_cache&quot;,
    &quot;.svn&quot;,
    &quot;.tox&quot;,
    &quot;.venv&quot;,
    &quot;.vscode&quot;,
    &quot;__pypackages__&quot;,
    &quot;_build&quot;,
    &quot;buck-out&quot;,
    &quot;build&quot;,
    &quot;dist&quot;,
    &quot;node_modules&quot;,
    &quot;site-packages&quot;,
    &quot;venv&quot;,
]

# Same as Black.
line-length = 88
indent-width = 4

# Assume Python 3.9
target-version = &quot;py39&quot;

[lint]
# Enable Pyflakes (`F`) and a subset of the pycodestyle (`E`) codes by default.
select = [&quot;E4&quot;, &quot;E7&quot;, &quot;E9&quot;, &quot;F&quot;]
ignore = []

# Allow fix for all enabled rules (when `--fix`) is provided.
fixable = [&quot;ALL&quot;]
unfixable = []

# Allow unused variables when underscore-prefixed.
dummy-variable-rgx = &quot;^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$&quot;

[format]
# Like Black, use double quotes for strings.
quote-style = &quot;double&quot;

# Like Black, indent with spaces, rather than tabs.
indent-style = &quot;space&quot;

# Like Black, respect magic trailing commas.
skip-magic-trailing-comma = false

# Like Black, automatically detect the appropriate line ending.
line-ending = &quot;auto&quot;
```

Note that, in a `pyproject.toml`, each section header should be prefixed with `tool.ruff`. For
example, `[lint]` should be replaced with `[tool.ruff.lint]`.

Some configuration options can be provided via dedicated command-line arguments, such as those
related to rule enablement and disablement, file discovery, and logging level:

```shell
ruff check --select F401 --select F403 --quiet
```

The remaining configuration options can be provided through a catch-all `--config` argument:

```shell
ruff check --config &quot;lint.per-file-ignores = {&#039;some_file.py&#039; = [&#039;F841&#039;]}&quot;
```

To opt in to the latest lint rules, formatter style changes, interface updates, and more, enable
[preview mode](https://docs.astral.sh/ruff/rules/) by setting `preview = true` in your configuration
file or passing `--preview` on the command line. Preview mode enables a collection of unstable
features that may change prior to stabilization.

See `ruff help` for more on Ruff&#039;s top-level commands, or `ruff help check` and `ruff help format`
for more on the linting and formatting commands, respectively.

## Rules&lt;a id=&quot;rules&quot;&gt;&lt;/a&gt;

&lt;!-- Begin section: Rules --&gt;

**Ruff supports over 800 lint rules**, many of which are inspired by popular tools like Flake8,
isort, pyupgrade, and others. Regardless of the rule&#039;s origin, Ruff re-implements every rule in
Rust as a first-party feature.

By default, Ruff enables Flake8&#039;s `F` rules, along with a subset of the `E` rules, omitting any
stylistic rules that overlap with the use of a formatter, like `ruff format` or
[Black](https://github.com/psf/black).

If you&#039;re just getting started with Ruff, **the default rule set is a great place to start**: it
catches a wide variety of common errors (like unused imports) with zero configuration.

&lt;!-- End section: Rules --&gt;

Beyond the defaults, Ruff re-implements some of the most popular Flake8 plugins and related code
quality tools, including:

- [autoflake](https://pypi.org/project/autoflake/)
- [eradicate](https://pypi.org/project/eradicate/)
- [flake8-2020](https://pypi.org/project/flake8-2020/)
- [flake8-annotations](https://pypi.org/project/flake8-annotations/)
- [flake8-async](https://pypi.org/project/flake8-async)
- [flake8-bandit](https://pypi.org/project/flake8-bandit/) ([#1646](https://github.com/astral-sh/ruff/issues/1646))
- [flake8-blind-except](https://pypi.org/project/flake8-blind-except/)
- [flake8-boolean-trap](https://pypi.org/project/flake8-boolean-trap/)
- [flake8-bugbear](https://pypi.org/project/flake8-bugbear/)
- [flake8-builtins](https://pypi.org/project/flake8-builtins/)
- [flake8-commas](https://pypi.org/project/flake8-commas/)
- [flake8-comprehensions](https://pypi.org/project/flake8-comprehensions/)
- [flake8-copyright](https://pypi.org/project/flake8-copyright/)
- [flake8-datetimez](https://pypi.org/project/flake8-datetimez/)
- [flake8-debugger](https://pypi.org/project/flake8-debugger/)
- [flake8-django](https://pypi.org/project/flake8-django/)
- [flake8-docstrings](https://pypi.org/project/flake8-docstrings/)
- [flake8-eradicate](https://pypi.org/project/flake8-eradicate/)
- [flake8-errmsg](https://pypi.org/project/flake8-errmsg/)
- [flake8-executable](https://pypi.org/project/flake8-executable/)
- [flake8-future-annotations](https://pypi.org/project/flake8-future-annotations/)
- [flake8-gettext](https://pypi.org/project/flake8-gettext/)
- [flake8-implicit-str-concat](https://pypi.org/project/flake8-implicit-str-concat/)
- [flake8-import-conventions](https://github.com/joaopalmeiro/flake8-import-conventions)
- [flake8-logging](https://pypi.org/project/flake8-logging/)
- [flake8-logging-format](https://pypi.org/project/flake8-logging-format/)
- [flake8-no-pep420](https://pypi.org/project/flake8-no-pep420)
- [flake8-pie](https://pypi.org/project/flake8-pie/)
- [flake8-print](https://pypi.org/project/flake8-print/)
- [flake8-pyi](https://pypi.org/project/flake8-pyi/)
- [flake8-pytest-style](https://pypi.org/project/flake8-pytest-style/)
- [flake8-quotes](https://pypi.org/project/flake8-quotes/)
- [flake8-raise](https://pypi.org/project/flake8-raise/)
- [flake8-return](https://pypi.org/project/flake8-return/)
- [flake8-self](https://pypi.org/project/flake8-self/)
- [flake8-simplify](https://pypi.org/project/flake8-simplify/)
- [flake8-slots](https://pypi.org/project/flake8-slots/)
- [flake8-super](https://pypi.org/project/flake8-super/)
- [flake8-tidy-imports](https://pypi.org/project/flake8-tidy-imports/)
- [flake8-todos](https://pypi.org/project/flake8-todos/)
- [flake8-type-checking](https://pypi.org/project/flake8-type-checking/)
- [flake8-use-pathlib](https://pypi.org/project/flake8-use-pathlib/)
- [flynt](https://pypi.org/project/flynt/) ([#2102](https://github.com/astral-sh/ruff/issues/2102))
- [isort](https://pypi.org/project/isort/)
- [mccabe](https://pypi.org/project/mccabe/)
- [pandas-vet](https://pypi.org/project/pandas-vet/)
- [pep8-naming](https://pypi.org/project/pep8-naming/)
- [pydocstyle](https://pypi.org/project/pydocstyle/)
- [pygrep-hooks](https://github.com/pre-commit/pygrep-hooks)
- [pylint-airflow](https://pypi.org/project/pylint-airflow/)
- [pyupgrade](https://pypi.org/project/pyupgrade/)
- [tryceratops](https://pypi.org/project/tryceratops/)
- [yesqa](https://pypi.org/project/yesqa/)

For a complete enumeration of the supported rules, see [_Rules_](https://docs.astral.sh/ruff/rules/).

## Contributing&lt;a id=&quot;contributing&quot;&gt;&lt;/a&gt;

Contributions are welcome and highly appreciated. To get started, check out the
[**contributing guidelines**](https://docs.astral.sh/ruff/contributing/).

You can also join us on [**Discord**](https://discord.com/invite/astral-sh).

## Support&lt;a id=&quot;support&quot;&gt;&lt;/a&gt;

Having trouble? Check out the existing issues on [**GitHub**](https://github.com/astral-sh/ruff/issues),
or feel free to [**open a new one**](https://github.com/astral-sh/ruff/issues/new).

You can also ask for help on [**Discord**](https://discord.com/invite/astral-sh).

## Acknowledgements&lt;a id=&quot;acknowledgements&quot;&gt;&lt;/a&gt;

Ruff&#039;s linter draws on both the APIs and implementation details of many other
tools in the Python ecosystem, especially [Flake8](https://github.com/PyCQA/flake8), [Pyflakes](https://github.com/PyCQA/pyflakes),
[pycodestyle](https://github.com/PyCQA/pycodestyle), [pydocstyle](https://github.com/PyCQA/pydocstyle),
[pyupgrade](https://github.com/asottile/pyupgrade), and [isort](https://github.com/PyCQA/isort).

In some cases, Ruff includes a &quot;direct&quot; Rust port of the corresponding tool.
We&#039;re grateful to the maintainers of these tools for their work, and for all
the value they&#039;ve provided to the Python community.

Ruff&#039;s formatter is built on a fork of Rome&#039;s [`rome_formatter`](https://github.com/rome/tools/tree/main/crates/rome_formatter),
and again draws on both API and implementation details from [Rome](https://github.com/rome/tools),
[Prettier](https://github.com/prettier/prettier), and [Black](https://github.com/psf/black).

Ruff&#039;s import resolver is based on the import resolution algorithm from [Pyright](https://github.com/microsoft/pyright).

Ruff is also influenced by a number of tools outside the Python ecosystem, like
[Clippy](https://github.com/rust-lang/rust-clippy) and [ESLint](https://github.com/eslint/eslint).

Ruff is the beneficiary of a large number of [contributors](https://github.com/astral-sh/ruff/graphs/contributors).

Ruff is released under the MIT license.

## Who&#039;s Using Ruff?&lt;a id=&quot;whos-using-ruff&quot;&gt;&lt;/a&gt;

Ruff is used by a number of major open-source projects and companies, including:

- [Albumentations](https://github.com/albumentations-team/AlbumentationsX)
- Amazon ([AWS SAM](https://github.com/aws/serverless-application-model))
- [Anki](https://apps.ankiweb.net/)
- Anthropic ([Python SDK](https://github.com/anthropics/anthropic-sdk-python))
- [Apache Airflow](https://github.com/apache/airflow)
- AstraZeneca ([Magnus](https://github.com/AstraZeneca/magnus-core))
- [Babel](https://github.com/python-babel/babel)
- Benchling ([Refac](https://github.com/benchling/refac))
- [Bokeh](https://github.com/bokeh/bokeh)
- Capital One ([datacompy](https://github.com/capitalone/datacompy))
- CrowdCent ([NumerBlox](https://github.com/crowdcent/numerblox)) &lt;!-- typos: ignore --&gt;
- [Cryptography (PyCA)](https://github.com/pyca/cryptography)
- CERN ([Indico](https://getindico.io/))
- [DVC](https://github.com/iterative/dvc)
- [Dagger](https://github.com/dagger/dagger)
- [Dagster](https://github.com/dagster-io/dagster)
- Databricks ([MLflow](https://github.com/mlflow/mlflow))
- [Dify](https://github.com/langgenius/dify)
- [FastAPI](https://github.com/tiangolo/fastapi)
- [Godot](https://github.com/godotengine/godot)
- [Gradio](https://github.com/gradio-app/gradio)
- [Great Expectations](https://github.com/great-expectations/great_expectations)
- [HTTPX](https://github.com/encode/httpx)
- [Hatch](https://github.com/pypa/hatch)
- [Home Assistant](https://github.com/home-assistant/core)
- Hugging Face ([Transformers](https://github.com/huggingface/transformers),
    [Datasets](https://github.com/huggingface/datasets),
    [Diffusers](https://github.com/huggingface/diffusers))
- IBM ([Qiskit](https://github.com/Qiskit/qiskit))
- ING Bank ([popmon](https://github.com/ing-bank/popmon), [probatus](https://github.com/ing-bank/probatus))
- [I

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>