<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Sun, 13 Jul 2025 00:06:19 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[MystenLabs/sui]]></title>
            <link>https://github.com/MystenLabs/sui</link>
            <guid>https://github.com/MystenLabs/sui</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:19 GMT</pubDate>
            <description><![CDATA[Sui, a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the Move programming language]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/MystenLabs/sui">MystenLabs/sui</a></h1>
            <p>Sui, a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the Move programming language</p>
            <p>Language: Rust</p>
            <p>Stars: 7,171</p>
            <p>Forks: 11,543</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/MystenLabs/sui/refs/heads/main/docs/site/static/img/logo.svg&quot; alt=&quot;Logo&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;
&lt;/p&gt;

# Welcome to Sui

[![Github release](https://img.shields.io/github/v/tag/MystenLabs/sui.svg?sort=semver)](https://github.com/MystenLabs/sui/releases/latest)
[![License](https://img.shields.io/github/license/MystenLabs/sui)](https://github.com/MystenLabs/sui/blob/main/LICENSE)

[Sui](https://sui.io) is a next-generation smart contract platform with high throughput, low latency, and an asset-oriented programming model powered by the [Move programming language](https://github.com/MystenLabs/awesome-move).

## Sui Highlights

Sui offers the following benefits and capabilities:

 * Unmatched scalability, instant settlement
 * A safe smart contract language accessible to mainstream developers
 * Ability to define rich and composable on-chain assets
 * Better user experience for web3 apps

Sui is the only blockchain today that can scale with the growth of web3 while achieving industry-leading performance, cost, programmability, and usability. As Sui approaches Mainnet launch, it will demonstrate capacity beyond the transaction processing capabilities of established systems ‚Äì traditional and blockchain alike. Sui is the first internet-scale programmable blockchain platform, a foundational layer for web3.

## Sui Architecture

```mermaid
flowchart LR
    CC(CLI Client) --&gt; ClientService
    RC(Rest Client) --&gt; ClientService
    RPCC(RPC Client) --&gt; ClientService
    ClientService --&gt; AuthorityAggregator
    AuthorityAggregator --&gt; AC1[AuthorityClient] &amp; AC2[AuthorityClient]
    subgraph Authority1
      AS[AuthorityState]
    end
    subgraph Authority2
      AS2[AuthorityState]
    end
    AC1 &lt;==&gt;|Network TCP| Authority1
    AC2 &lt;==&gt;|Network TCP| Authority2
```

## Sui Overview

Sui is a smart contract platform maintained by a permissionless set of authorities that play a role similar to validators or miners in other blockchain systems.

Sui offers scalability and unprecedented low-latency for common use cases. Sui makes the vast majority of transactions processable in parallel, which makes better use of processing resources, and offers the option to increase throughput with more resources. Sui forgoes consensus to instead use simpler and lower-latency primitives for common use cases, such as payment transactions and asset transfers. This is unprecedented in the blockchain world and enables a number of new latency-sensitive distributed applications, ranging from gaming to retail payment at physical points of sale.

Sui is written in [Rust](https://www.rust-lang.org) and supports smart contracts written in the [Move programming language](https://github.com/move-language/move) to define assets that may have an owner. Move programs define operations on these assets including custom rules for their creation, the transfer of these assets to new owners, and operations that mutate assets.

Sui has a native token called SUI, with a fixed supply. The SUI token is used to pay for gas, and is also used as [delegated stake on authorities](https://learn.bybit.com/blockchain/delegated-proof-of-stake-dpos/) within an epoch. The voting power of authorities within this epoch is a function of this delegated stake. Authorities are periodically reconfigured according to the stake delegated to them. In any epoch, the set of authorities is [Byzantine fault tolerant](https://pmg.csail.mit.edu/papers/osdi99.pdf). At the end of the epoch, fees collected through all transactions processed are distributed to authorities according to their contribution to the operation of the system. Authorities can in turn share some of the fees as rewards to users that delegated stakes to them.

Sui is supported by several cutting-edge [peer-reviewed studies](https://github.com/MystenLabs/sui/blob/main/docs/content/concepts/research-papers.mdx) and extensive years of open-source development.

## More About Sui

Use the following links to learn more about Sui and the Sui ecosystem:

 * Learn more about working with Sui in the [Sui Documentation](https://docs.sui.io/).
 * Join the Sui community on [Sui Discord](https://discord.gg/sui).
 * Find out more about the Sui ecosystem on the [Sui Resources](https://sui.io/resources/) page.
 * Review information about Sui governance, [decentralization](https://suifoundation.org/decentralization), and [Developer Grants Program](https://sui.io/grants-hub) on the [Sui Foundation](https://sui.io/about) site.


 ## How to Contribute

 See the [Contributing Guide](CONTRIBUTING.md) for details on how to contribute to Sui.

 ## Code of Conduct

 See the [Code of Conduct](CODE_OF_CONDUCT.MD) for details on our code of conduct.

 ## License

 See the [LICENSE](LICENSE) file for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:18 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 16,045</p>
            <p>Forks: 1,363</p>
            <p>Stars today: 164 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# codename goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/7GaTvbDwga&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;&gt;
     &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.

# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)


# Goose Around with Us
- [Discord](https://discord.gg/block-opensource)
- [YouTube](https://www.youtube.com/@blockopensource)
- [LinkedIn](https://www.linkedin.com/company/block-opensource)
- [Twitter/X](https://x.com/blockopensource)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[emilk/egui]]></title>
            <link>https://github.com/emilk/egui</link>
            <guid>https://github.com/emilk/egui</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:17 GMT</pubDate>
            <description><![CDATA[egui: an easy-to-use immediate mode GUI in Rust that runs on both web and native]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/emilk/egui">emilk/egui</a></h1>
            <p>egui: an easy-to-use immediate mode GUI in Rust that runs on both web and native</p>
            <p>Language: Rust</p>
            <p>Stars: 25,744</p>
            <p>Forks: 1,781</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre># üñå egui: an easy-to-use GUI in pure Rust

[&lt;img alt=&quot;github&quot; src=&quot;https://img.shields.io/badge/github-emilk/egui-8da0cb?logo=github&quot; height=&quot;20&quot;&gt;](https://github.com/emilk/egui)
[![Latest version](https://img.shields.io/crates/v/egui.svg)](https://crates.io/crates/egui)
[![Documentation](https://docs.rs/egui/badge.svg)](https://docs.rs/egui)
[![unsafe forbidden](https://img.shields.io/badge/unsafe-forbidden-success.svg)](https://github.com/rust-secure-code/safety-dance/)
[![Build Status](https://github.com/emilk/egui/workflows/Rust/badge.svg)](https://github.com/emilk/egui/actions/workflows/rust.yml)
[![MIT](https://img.shields.io/badge/license-MIT-blue.svg)](https://github.com/emilk/egui/blob/main/LICENSE-MIT)
[![Apache](https://img.shields.io/badge/license-Apache-blue.svg)](https://github.com/emilk/egui/blob/main/LICENSE-APACHE)
[![Discord](https://img.shields.io/discord/900275882684477440?label=egui%20discord)](https://discord.gg/JFcEma9bJq)


&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.rerun.io/&quot;&gt;&lt;img src=&quot;https://github.com/user-attachments/assets/78e79463-4357-461b-bbd1-31aa5ef5e1a2&quot; width=&quot;250&quot;&gt;&lt;/a&gt;

egui development is sponsored by [Rerun](https://www.rerun.io/), a startup building&lt;br&gt;
an SDK for visualizing streams of multimodal data.
&lt;/div&gt;

---

üëâ [Click to run the web demo](https://www.egui.rs/#demo) üëà

egui (pronounced &quot;e-gooey&quot;) is a simple, fast, and highly portable immediate mode GUI library for Rust. egui runs on the web, natively, and [in your favorite game engine](#integrations).

egui aims to be the easiest-to-use Rust GUI library, and the simplest way to make a web app in Rust.

egui can be used anywhere you can draw textured triangles, which means you can easily integrate it into your game engine of choice.

[`eframe`](https://github.com/emilk/egui/tree/main/crates/eframe) is the official egui framework, which supports writing apps for Web, Linux, Mac, Windows, and Android.


## Example

``` rust
ui.heading(&quot;My egui Application&quot;);
ui.horizontal(|ui| {
    ui.label(&quot;Your name: &quot;);
    ui.text_edit_singleline(&amp;mut name);
});
ui.add(egui::Slider::new(&amp;mut age, 0..=120).text(&quot;age&quot;));
if ui.button(&quot;Increment&quot;).clicked() {
    age += 1;
}
ui.label(format!(&quot;Hello &#039;{name}&#039;, age {age}&quot;));
ui.image(egui::include_image!(&quot;ferris.png&quot;));
```

&lt;img alt=&quot;Dark mode&quot; src=&quot;https://github.com/user-attachments/assets/3b446d29-99d8-4c82-86bb-4d8ef0516017&quot;&gt; &amp;nbsp; &amp;nbsp; &lt;img alt=&quot;Light mode&quot; src=&quot;https://github.com/user-attachments/assets/a5e7da93-89a8-4ba0-86b8-0fa2228a4f62&quot; height=&quot;278&quot;&gt;

## Sections:

* [Example](#example)
* [Quick start](#quick-start)
* [Demo](#demo)
* [Goals](#goals)
* [State / features](#state)
* [Dependencies](#dependencies)
* [Who is egui for?](#who-is-egui-for)
* [Integrations](#integrations)
* [Why immediate mode](#why-immediate-mode)
* [FAQ](#faq)
* [Other](#other)
* [Credits](#credits)

([egui ÁöÑ‰∏≠ÊñáÁøªËØëÊñáÊ°£ / chinese translation](https://github.com/Re-Ch-Love/egui-doc-cn/blob/main/README_zh-hans.md))


## Quick start

There are simple examples in [the `examples/` folder](https://github.com/emilk/egui/blob/main/examples/). If you want to write a web app, then go to &lt;https://github.com/emilk/eframe_template/&gt; and follow the instructions. The official docs are at &lt;https://docs.rs/egui&gt;. For inspiration and more examples, check out the [the egui web demo](https://www.egui.rs/#demo) and follow the links in it to its source code.

If you want to integrate egui into an existing engine, go to the [Integrations](#integrations) section.

If you have questions, use [GitHub Discussions](https://github.com/emilk/egui/discussions). There is also [an egui discord server](https://discord.gg/JFcEma9bJq). If you want to contribute to egui, please read the [Contributing Guidelines](https://github.com/emilk/egui/blob/main/CONTRIBUTING.md).

## Demo

[Click to run egui web demo](https://www.egui.rs/#demo) (works in any browser with Wasm and WebGL support). Uses [`eframe`](https://github.com/emilk/egui/tree/main/crates/eframe).

To test the demo app locally, run `cargo run --release -p egui_demo_app`.

The native backend is [`egui_glow`](https://github.com/emilk/egui/tree/main/crates/egui_glow) (using [`glow`](https://crates.io/crates/glow)) and should work out-of-the-box on Mac and Windows, but on Linux you need to first run:

`sudo apt-get install -y libclang-dev libgtk-3-dev libxcb-render0-dev libxcb-shape0-dev libxcb-xfixes0-dev libxkbcommon-dev libssl-dev`

On Fedora Rawhide you need to run:

`dnf install clang clang-devel clang-tools-extra libxkbcommon-devel pkg-config openssl-devel libxcb-devel gtk3-devel atk fontconfig-devel`

**NOTE**: This is just for the demo app - egui itself is completely platform agnostic!

## Goals

* The easiest to use GUI library
* Responsive: target 60 Hz in debug build
* Friendly: difficult to make mistakes, and shouldn&#039;t panic
* Portable: the same code works on the web and as a native app
* Easy to integrate into any environment
* A simple 2D graphics API for custom painting ([`epaint`](https://docs.rs/epaint)).
* Pure immediate mode: no callbacks
* Extensible: [easy to write your own widgets for egui](https://github.com/emilk/egui/blob/main/crates/egui_demo_lib/src/demo/toggle_switch.rs)
* Modular: You should be able to use small parts of egui and combine them in new ways
* Safe: there is no `unsafe` code in egui
* Minimal dependencies

egui is *not* a framework. egui is a library you call into, not an environment you program for.

**NOTE**: egui does not claim to have reached all these goals yet! egui is still work in progress.

### Non-goals

* Become the most powerful GUI library
* Native looking interface

## State

egui is in active development. It works well for what it does, but it lacks many features and the interfaces are still in flux. New releases will have breaking changes.

Still, egui can be used to create professional looking applications, like [the Rerun Viewer](https://app.rerun.io/).

### Features

* Widgets: label, text button, hyperlink, checkbox, radio button, slider, draggable value, text editing, color picker, spinner
* Images
* Layouts: horizontal, vertical, columns, automatic wrapping
* Text editing: multiline, copy/paste, undo, emoji supports
* Windows: move, resize, name, minimize and close. Automatically sized and positioned.
* Regions: resizing, vertical scrolling, collapsing headers (sections), panels
* Rendering: Anti-aliased rendering of lines, circles, text and convex polygons.
* Tooltips on hover
* Accessibility via [AccessKit](https://accesskit.dev/)
* Label text selection
* And more!

Check out the [3rd party egui crates wiki](https://github.com/emilk/egui/wiki/3rd-party-egui-crates) for even more
widgets and features, maintained by the community.

&lt;img src=&quot;https://github.com/user-attachments/assets/13e73b76-e456-42bd-8ec9-220802834268&quot; width=&quot;50%&quot;&gt;

Light Theme:

&lt;img src=&quot;https://github.com/user-attachments/assets/2e38972c-a444-4894-b32f-47a2719cf369&quot; width=&quot;50%&quot;&gt;

## Dependencies
`egui` has a minimal set of default dependencies:

* [`ab_glyph`](https://crates.io/crates/ab_glyph)
* [`ahash`](https://crates.io/crates/ahash)
* [`bitflags`](https://crates.io/crates/bitflags)
* [`nohash-hasher`](https://crates.io/crates/nohash-hasher)
* [`parking_lot`](https://crates.io/crates/parking_lot)

Heavier dependencies are kept out of `egui`, even as opt-in.
All code in `egui` is Wasm-friendly (even outside a browser).

To load images into `egui` you can use the official [`egui_extras`](https://github.com/emilk/egui/tree/main/crates/egui_extras) crate.

[`eframe`](https://github.com/emilk/egui/tree/main/crates/eframe) on the other hand has a lot of dependencies, including [`winit`](https://crates.io/crates/winit), [`image`](https://crates.io/crates/image), graphics crates, clipboard crates, etc,

## Who is egui for?

egui aims to be the best choice when you want a simple way to create a GUI, or you want to add a GUI to a game engine.

If you are not using Rust, egui is not for you. If you want a GUI that looks native, egui is not for you. If you want something that doesn&#039;t break when you upgrade it, egui isn&#039;t for you (yet).

But if you are writing something interactive in Rust that needs a simple GUI, egui may be for you.


## Integrations

egui is built to be easy to integrate into any existing game engine or platform you are working on.
egui itself doesn&#039;t know or care on what OS it is running or how to render things to the screen - that is the job of the egui integration.

An integration needs to do the following each frame:

* **Input**: Gather input (mouse, touches, keyboard, screen size, etc) and give it to egui
* Call into the application GUI code
* **Output**: Handle egui output (cursor changes, paste, texture allocations, ‚Ä¶)
* **Painting**: Render the triangle mesh egui produces (see [OpenGL example](https://github.com/emilk/egui/blob/main/crates/egui_glow/src/painter.rs))

### Official integrations

These are the official egui integrations:

* [`eframe`](https://github.com/emilk/egui/tree/main/crates/eframe) for compiling the same app to web/wasm and desktop/native. Uses `egui-winit` and `egui_glow` or `egui-wgpu`
* [`egui_glow`](https://github.com/emilk/egui/tree/main/crates/egui_glow) for rendering egui with [glow](https://github.com/grovesNL/glow) on native and web, and for making native apps
* [`egui-wgpu`](https://github.com/emilk/egui/tree/main/crates/egui-wgpu) for [wgpu](https://crates.io/crates/wgpu) (WebGPU API)
* [`egui-winit`](https://github.com/emilk/egui/tree/main/crates/egui-winit) for integrating with [winit](https://github.com/rust-windowing/winit)

### 3rd party integrations

Check the wiki to find [3rd party integrations](https://github.com/emilk/egui/wiki/3rd-party-integrations)
and [egui crates](https://github.com/emilk/egui/wiki/3rd-party-egui-crates).

### Writing your own egui integration
Missing an integration for the thing you&#039;re working on? Create one, it&#039;s easy!
See &lt;https://docs.rs/egui/latest/egui/#integrating-with-egui&gt;.


## Why immediate mode

`egui` is an [immediate mode GUI library](https://en.wikipedia.org/wiki/Immediate_mode_GUI), as opposed to a *retained mode* GUI library. The difference between retained mode and immediate mode is best illustrated with the example of a button: In a retained GUI you create a button, add it to some UI and install some on-click handler (callback). The button is retained in the UI, and to change the text on it you need to store some sort of reference to it. By contrast, in immediate mode you show the button and interact with it immediately, and you do so every frame (e.g. 60 times per second). This means there is no need for any on-click handler, nor to store any reference to it. In `egui` this looks like this: `if ui.button(&quot;Save file&quot;).clicked() { save(file); }`.

A more detailed description of immediate mode can be found [in the `egui` docs](https://docs.rs/egui/latest/egui/#understanding-immediate-mode).

There are advantages and disadvantages to both systems.

The short of it is this: immediate mode GUI libraries are easier to use, but less powerful.

### Advantages of immediate mode
#### Usability
The main advantage of immediate mode is that the application code becomes vastly simpler:

* You never need to have any on-click handlers and callbacks that disrupts your code flow.
* You don&#039;t have to worry about a lingering callback calling something that is gone.
* Your GUI code can easily live in a simple function (no need for an object just for the UI).
* You don&#039;t have to worry about app state and GUI state being out-of-sync (i.e. the GUI showing something outdated), because the GUI isn&#039;t storing any state - it is showing the latest state *immediately*.

In other words, a whole lot of code, complexity and bugs are gone, and you can focus your time on something more interesting than writing GUI code.

### Disadvantages of immediate mode

#### Layout
The main disadvantage of immediate mode is it makes layout more difficult. Say you want to show a small dialog window in the center of the screen. To position the window correctly the GUI library must first know the size of it. To know the size of the window the GUI library must first layout the contents of the window. In retained mode this is easy: the GUI library does the window layout, positions the window, then checks for interaction (&quot;was the OK button clicked?&quot;).

In immediate mode you run into a paradox: to know the size of the window, we must do the layout, but the layout code also checks for interaction (&quot;was the OK button clicked?&quot;) and so it needs to know the window position *before* showing the window contents. This means we must decide where to show the window *before* we know its size!

This is a fundamental shortcoming of immediate mode GUIs, and any attempt to resolve it comes with its own downsides.

One workaround is to store the size and use it the next frame. This produces a frame-delay for the correct layout, producing occasional flickering the first frame something shows up. `egui` does this for some things such as windows and grid layouts.

The &quot;first-frame jitter&quot; can be covered up with an extra _pass_, which egui supports via `Context::request_discard`.
The downside of this is the added CPU cost of a second pass, so egui only does this in very rare circumstances (the majority of frames are single-pass).

For &quot;atomic&quot; widgets (e.g. a button) `egui` knows the size before showing it, so centering buttons, labels etc is possible in `egui` without any special workarounds.

See [this issue](https://github.com/emilk/egui/issues/4378) for more.

#### CPU usage
Since an immediate mode GUI does a full layout each frame, the layout code needs to be quick. If you have a very complex GUI this can tax the CPU. In particular, having a very large UI in a scroll area (with very long scrollback) can be slow, as the content needs to be laid out each frame.

If you design the GUI with this in mind and refrain from huge scroll areas (or only lay out the part that is in view) then the performance hit is generally pretty small. For most cases you can expect `egui` to take up 1-2 ms per frame, but `egui` still has a lot of room for optimization (it&#039;s not something I&#039;ve focused on yet). `egui` only repaints when there is interaction (e.g. mouse movement) or an animation, so if your app is idle, no CPU is wasted.

If your GUI is highly interactive, then immediate mode may actually be more performant compared to retained mode. Go to any web page and resize the browser window, and you&#039;ll notice that the browser is very slow to do the layout and eats a lot of CPU doing it. Resize a window in `egui` by contrast, and you&#039;ll get smooth 60 FPS at no extra CPU cost.


#### IDs
There are some GUI state that you want the GUI library to retain, even in an immediate mode library such as `egui`. This includes position and sizes of windows and how far the user has scrolled in some UI. In these cases you need to provide `egui` with a seed of a unique identifier (unique within the parent UI). For instance: by default `egui` uses the window titles as unique IDs to store window positions. If you want two windows with the same name (or one window with a dynamic name) you must provide some other ID source to `egui` (some unique integer or string).

`egui` also needs to track which widget is being interacted with (e.g. which slider is being dragged). `egui` uses unique IDs for this as well, but in this case the IDs are automatically generated, so there is no need for the user to worry about it. In particular, having two buttons with the same name is no problem (this is in contrast with [`Dear ImGui`](https://github.com/ocornut/imgui)).

Overall, ID handling is a rare inconvenience, and not a big disadvantage.


## FAQ

Also see [GitHub Discussions](https://github.com/emilk/egui/discussions/categories/q-a).

### Can I use `egui` with non-latin characters?
Yes! But you need to install your own font (`.ttf` or `.otf`) using [`Context::set_fonts`](https://docs.rs/egui/latest/egui/struct.Context.html#method.set_fonts).

### Can I customize the look of egui?
Yes! You can customize the colors, spacing, fonts and sizes of everything using `Context::set_style`.

This is not yet as powerful as say CSS, [but this is going to improve](https://github.com/emilk/egui/issues/3284).

Here is an example (from https://github.com/a-liashenko/TinyPomodoro):

&lt;img src=&quot;https://github.com/user-attachments/assets/e6107237-2547-41d6-996b-9a20ae0345ab&quot; width=&quot;50%&quot;&gt;

### How do I use egui with `async`?
If you call `.await` in your GUI code, the UI will freeze, which is very bad UX. Instead, keep the GUI thread non-blocking and communicate with any concurrent tasks (`async` tasks or other threads) with something like:
* Channels (e.g. [`std::sync::mpsc::channel`](https://doc.rust-lang.org/std/sync/mpsc/fn.channel.html)). Make sure to use [`try_recv`](https://doc.rust-lang.org/std/sync/mpsc/struct.Receiver.html#method.try_recv) so you don&#039;t block the gui thread!
* `Arc&lt;Mutex&lt;Value&gt;&gt;` (background thread sets a value; GUI thread reads it)
* [`poll_promise::Promise`](https://docs.rs/poll-promise)
* [`eventuals::Eventual`](https://docs.rs/eventuals/latest/eventuals/struct.Eventual.html)
* [`tokio::sync::watch::channel`](https://docs.rs/tokio/latest/tokio/sync/watch/fn.channel.html)

### How do I create a file dialog?

The async version of [rfd](https://docs.rs/rfd/latest/rfd/) supports both native and Wasm. See example app here https://github.com/woelper/egui_pick_file which also has a demo available via [gitub pages](https://woelper.github.io/egui_pick_file/).

### What about accessibility, such as screen readers?
egui includes optional support for [AccessKit](https://accesskit.dev/), which currently implements the native accessibility APIs on Windows and macOS. This feature is enabled by default in eframe. For platforms that AccessKit doesn&#039;t yet support, including web, there is an experimental built-in screen reader; in [the web demo](https://www.egui.rs/#demo) you can enable it in the &quot;Backend&quot; tab.

The original discussion of accessibility in egui is at &lt;https://github.com/emilk/egui/issues/167&gt;. Now that AccessKit support is merged, providing a strong foundation for future accessibility work, please open new issues on specific accessibility problems.

### What is the difference between [egui](https://docs.rs/egui) and [eframe](https://github.com/emilk/egui/tree/main/crates/eframe)?

`egui` is a 2D user interface library for laying out and interacting with buttons, sliders, etc.
`egui` has no idea if it is running on the web or natively, and does not know how to collect input or show things on screen.
That is the job of *the integration* or *backend*.

It is common to use `egui` from a game engine (using e.g. [`bevy_egui`](https://docs.rs/bevy_egui)),
but you can also use `egui` stand-alone using `eframe`. `eframe` has integration for web and native, and handles input and rendering.
The _frame_ in `eframe` stands both for the frame in which your egui app resides and also for &quot;framework&quot; (`eframe` is a framework, `egui` is a library).

### How do I render 3D stuff in an egui area?
There are multiple ways to combine egui with 3D. The simplest way is to use a 3D library and have egui sit on top of the 3D view. See for instance [`bevy_egui`](https://github.com/mvlabat/bevy_egui) or [`three-d`](https://github.com/asny/three-d).

If you want to embed 3D into an egui view there are two options:

#### `Shape::Callback`
Example:
* &lt;https://github.com/emilk/egui/blob/main/examples/custom_3d_glow/src/main.rs&gt;

`Shape::Callback` will call your code when egui gets painted, to show anything using whatever the background rendering context is. When using [`eframe`](https://github.com/emilk/egui/tree/main/crates/eframe) this will be [`glow`](https://github.com/grovesNL/glow). Other integrations will give you other rendering contexts, if they support `Shape::Callback` at all.

#### Re

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zed-industries/zed]]></title>
            <link>https://github.com/zed-industries/zed</link>
            <guid>https://github.com/zed-industries/zed</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:16 GMT</pubDate>
            <description><![CDATA[Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zed-industries/zed">zed-industries/zed</a></h1>
            <p>Code at the speed of thought ‚Äì Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.</p>
            <p>Language: Rust</p>
            <p>Stars: 62,400</p>
            <p>Forks: 4,684</p>
            <p>Stars today: 50 stars today</p>
            <h2>README</h2><pre># Zed

[![CI](https://github.com/zed-industries/zed/actions/workflows/ci.yml/badge.svg)](https://github.com/zed-industries/zed/actions/workflows/ci.yml)

Welcome to Zed, a high-performance, multiplayer code editor from the creators of [Atom](https://github.com/atom/atom) and [Tree-sitter](https://github.com/tree-sitter/tree-sitter).

---

### Installation

On macOS and Linux you can [download Zed directly](https://zed.dev/download) or [install Zed via your local package manager](https://zed.dev/docs/linux#installing-via-a-package-manager).

Other platforms are not yet available:

- Windows ([tracking issue](https://github.com/zed-industries/zed/issues/5394))
- Web ([tracking issue](https://github.com/zed-industries/zed/issues/5396))

### Developing Zed

- [Building Zed for macOS](./docs/src/development/macos.md)
- [Building Zed for Linux](./docs/src/development/linux.md)
- [Building Zed for Windows](./docs/src/development/windows.md)
- [Running Collaboration Locally](./docs/src/development/local-collaboration.md)

### Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for ways you can contribute to Zed.

Also... we&#039;re hiring! Check out our [jobs](https://zed.dev/jobs) page for open roles.

### Licensing

License information for third party dependencies must be correctly provided for CI to pass.

We use [`cargo-about`](https://github.com/EmbarkStudios/cargo-about) to automatically comply with open source licenses. If CI is failing, check the following:

- Is it showing a `no license specified` error for a crate you&#039;ve created? If so, add `publish = false` under `[package]` in your crate&#039;s Cargo.toml.
- Is the error `failed to satisfy license requirements` for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license&#039;s requirements. If you&#039;re unsure, ask a lawyer. Once you&#039;ve verified that this system is acceptable add the license&#039;s SPDX identifier to the `accepted` array in `script/licenses/zed-licenses.toml`.
- Is `cargo-about` unable to find the license for a dependency? If so, add a clarification field at the end of `script/licenses/zed-licenses.toml`, as specified in the [cargo-about book](https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[qdrant/qdrant]]></title>
            <link>https://github.com/qdrant/qdrant</link>
            <guid>https://github.com/qdrant/qdrant</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:15 GMT</pubDate>
            <description><![CDATA[Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qdrant/qdrant">qdrant/qdrant</a></h1>
            <p>Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/</p>
            <p>Language: Rust</p>
            <p>Stars: 24,639</p>
            <p>Forks: 1,695</p>
            <p>Stars today: 31 stars today</p>
            <h2>README</h2><pre>## How to interview using this template

Open ONLY the `shared/` folder within VSCode and in the Extensions Marketplace find `CodeTogether Live`. Install it.

Inside the extension, you&#039;ll have to click on &#039;Host New Session&#039; and then &#039;Start&#039;.

You now have a link in your clipboard, which you should share with the candidate.

Don&#039;t forget to run `npm run vite.dev` inside your editor terminal, since this is not currently possible from the browser editor (link) with the free version of the extension.

The locally running server will display localhost:5173 as well as a the project within the network, which the user can access remotely to see the SPA in action, something like: `10.5.52.144:5173`.

The candidate should be sharing their screen while they read and later approach the challenge!

## React TemplateÔºà‚ö°Ô∏èÔºâ

‚ö°Ô∏è A minimal React Vite starter template.

### Feature

- ‚ö°Ô∏è Fast - Build tools based on vite.
- üëª Small - Based on the smallest runnable build.
- üíÑ Prettier - Integrated Prettier to help you format the code.
- ‚úÖ Safety - Https is enabled by default.
- üòé Reliable - Integrated eslint and commitlint.
- ü§ñ Intelligent - Integrated renovate to help you maintain the dependent version.

### Preview

[![qekup8.png](https://s1.ax1x.com/2022/03/20/qekup8.png)](https://imgtu.com/i/qekup8)

### Getting Started

```bash
npx degit lzm0x219/template-vite-react myapp

cd myapp

git init
```

#### Prerequisites

- `npm` and/or `pnpm` should be installed.
- `git` should be installed (recommended v2.4.11 or higher)

#### Available scripts

##### `npm run vite.dev`

Runs the app in development mode.
Open https://localhost:5173 to view it in the browser.

The page will automatically reload if you make changes to the code.
You will see the build errors and lint warnings in the console.

##### `npm run vite.build`

Builds the app for production to the `dist` folder.
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.

Your app is ready to be deployed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[sxyazi/yazi]]></title>
            <link>https://github.com/sxyazi/yazi</link>
            <guid>https://github.com/sxyazi/yazi</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:14 GMT</pubDate>
            <description><![CDATA[üí• Blazing fast terminal file manager written in Rust, based on async I/O.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sxyazi/yazi">sxyazi/yazi</a></h1>
            <p>üí• Blazing fast terminal file manager written in Rust, based on async I/O.</p>
            <p>Language: Rust</p>
            <p>Stars: 26,581</p>
            <p>Forks: 568</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;sup&gt;Special thanks to:&lt;/sup&gt;
  &lt;br&gt;&lt;br&gt;
  &lt;a href=&quot;https://www.warp.dev/?utm_source=github&amp;utm_medium=referral&amp;utm_campaign=yazi&quot; target=&quot;_blank&quot;&gt;
    &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;300&quot; src=&quot;https://github.com/user-attachments/assets/c7f141e7-9751-407d-bb0e-d6f2c487b34f&quot;&gt;
    &lt;br&gt;
    &lt;b&gt;Warp, the intelligent terminal&lt;/b&gt;
    &lt;br&gt;
    &lt;sup&gt;Yazi&#039;s AI-powered terminal of choice!&lt;br&gt;Available for macOS, Linux and Windows&lt;/sup&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

## Yazi - ‚ö°Ô∏è Blazing Fast Terminal File Manager

Yazi (means &quot;duck&quot;) is a terminal file manager written in Rust, based on non-blocking async I/O. It aims to provide an efficient, user-friendly, and customizable file management experience.

üí° A new article explaining its internal workings: [Why is Yazi Fast?](https://yazi-rs.github.io/blog/why-is-yazi-fast)

- üöÄ **Full Asynchronous Support**: All I/O operations are asynchronous, CPU tasks are spread across multiple threads, making the most of available resources.
- üí™ **Powerful Async Task Scheduling and Management**: Provides real-time progress updates, task cancellation, and internal task priority assignment.
- üñºÔ∏è **Built-in Support for Multiple Image Protocols**: Also integrated with √úberzug++ and Chafa, covering almost all terminals.
- üåü **Built-in Code Highlighting and Image Decoding**: Combined with the pre-loading mechanism, greatly accelerates image and normal file loading.
- üîå **Concurrent Plugin System**: UI plugins (rewriting most of the UI), functional plugins, custom previewer/preloader/spotter/fetcher; Just some pieces of Lua.
- üì° **Data Distribution Service**: Built on a client-server architecture (no additional server process required), integrated with a Lua-based publish-subscribe model, achieving cross-instance communication and state persistence.
- üì¶ **Package Manager**: Install plugins and themes with one command, keeping them up-to-date, or pin them to a specific version.
- üß∞ Integration with ripgrep, fd, fzf, zoxide
- üí´ Vim-like input/pick/confirm/which/notify component, auto-completion for cd paths
- üè∑Ô∏è Multi-Tab Support, Cross-directory selection, Scrollable Preview (for videos, PDFs, archives, code, directories, etc.)
- üîÑ Bulk Renaming, Archive Extraction, Visual Mode, File Chooser, [Git Integration](https://github.com/yazi-rs/plugins/tree/main/git.yazi), [Mount Manager](https://github.com/yazi-rs/plugins/tree/main/mount.yazi)
- üé® Theme System, Mouse Support, Trash Bin, Custom Layouts, CSI u, OSC 52
- ... and more!

https://github.com/sxyazi/yazi/assets/17523360/92ff23fa-0cd5-4f04-b387-894c12265cc7

## Project status

Public beta, can be used as a daily driver.

Yazi is currently in heavy development, expect breaking changes.

## Documentation

- Usage: https://yazi-rs.github.io/docs/installation
- Features: https://yazi-rs.github.io/features

## Discussion

- Discord Server (English mainly): https://discord.gg/qfADduSdJu
- Telegram Group (Chinese mainly): https://t.me/yazi_rs

## Image Preview

| Platform                                                                     | Protocol                               | Support                                               |
| ---------------------------------------------------------------------------- | -------------------------------------- | ----------------------------------------------------- |
| [kitty](https://github.com/kovidgoyal/kitty) (&gt;= 0.28.0)                     | [Kitty unicode placeholders][kgp]      | ‚úÖ Built-in                                           |
| [iTerm2](https://iterm2.com)                                                 | [Inline images protocol][iip]          | ‚úÖ Built-in                                           |
| [WezTerm](https://github.com/wez/wezterm)                                    | [Inline images protocol][iip]          | ‚úÖ Built-in                                           |
| [Konsole](https://invent.kde.org/utilities/konsole)                          | [Kitty old protocol][kgp-old]          | ‚úÖ Built-in                                           |
| [foot](https://codeberg.org/dnkl/foot)                                       | [Sixel graphics format][sixel]         | ‚úÖ Built-in                                           |
| [Ghostty](https://github.com/ghostty-org/ghostty)                            | [Kitty unicode placeholders][kgp]      | ‚úÖ Built-in                                           |
| [Windows Terminal](https://github.com/microsoft/terminal) (&gt;= v1.22.10352.0) | [Sixel graphics format][sixel]         | ‚úÖ Built-in                                           |
| [st with Sixel patch](https://github.com/bakkeby/st-flexipatch)              | [Sixel graphics format][sixel]         | ‚úÖ Built-in                                           |
| [Warp](https://www.warp.dev) (macOS/Linux only)                              | [Inline images protocol][iip]          | ‚úÖ Built-in                                           |
| [Tabby](https://github.com/Eugeny/tabby)                                     | [Inline images protocol][iip]          | ‚úÖ Built-in                                           |
| [VSCode](https://github.com/microsoft/vscode)                                | [Inline images protocol][iip]          | ‚úÖ Built-in                                           |
| [Rio](https://github.com/raphamorim/rio)                                     | [Inline images protocol][iip]          | ‚ùå Rio doesn&#039;t correctly clear images [#709][rio-bug] |
| [Black Box](https://gitlab.gnome.org/raggesilver/blackbox)                   | [Sixel graphics format][sixel]         | ‚úÖ Built-in                                           |
| [Hyper](https://github.com/vercel/hyper)                                     | [Inline images protocol][iip]          | ‚úÖ Built-in                                           |
| [Bobcat](https://github.com/ismail-yilmaz/Bobcat)                            | [Inline images protocol][iip]          | ‚úÖ Built-in                                           |
| X11 / Wayland                                                                | Window system protocol                 | ‚òëÔ∏è [√úberzug++][ueberzug] required                     |
| Fallback                                                                     | [ASCII art (Unicode block)][ascii-art] | ‚òëÔ∏è [Chafa][chafa] required                            |

See https://yazi-rs.github.io/docs/image-preview for details.

&lt;!-- Protocols --&gt;

[kgp]: https://sw.kovidgoyal.net/kitty/graphics-protocol/#unicode-placeholders
[kgp-old]: https://github.com/sxyazi/yazi/blob/main/yazi-adapter/src/drivers/kgp_old.rs
[iip]: https://iterm2.com/documentation-images.html
[sixel]: https://www.vt100.net/docs/vt3xx-gp/chapter14.html
[ascii-art]: https://en.wikipedia.org/wiki/ASCII_art

&lt;!-- Dependencies --&gt;

[ueberzug]: https://github.com/jstkdng/ueberzugpp
[chafa]: https://hpjansson.org/chafa/

&lt;!-- Rio bug --&gt;

[rio-bug]: https://github.com/raphamorim/rio/issues/709

## License

Yazi is MIT-licensed. For more information check the [LICENSE](LICENSE) file.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[Automattic/harper]]></title>
            <link>https://github.com/Automattic/harper</link>
            <guid>https://github.com/Automattic/harper</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:13 GMT</pubDate>
            <description><![CDATA[Offline, privacy-first grammar checker. Fast, open-source, Rust-powered]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Automattic/harper">Automattic/harper</a></h1>
            <p>Offline, privacy-first grammar checker. Fast, open-source, Rust-powered</p>
            <p>Language: Rust</p>
            <p>Stars: 6,925</p>
            <p>Forks: 166</p>
            <p>Stars today: 173 stars today</p>
            <h2>README</h2><pre>&lt;div id=&quot;header&quot; align=&quot;center&quot;&gt;
    &lt;img src=&quot;logo.svg&quot; width=&quot;400px&quot; /&gt;
    &lt;h1&gt;Harper&lt;/h1&gt;
&lt;/div&gt;

[![Harper Binaries](https://github.com/automattic/harper/actions/workflows/build_harper_binaries.yml/badge.svg)](https://github.com/automattic/harper/actions/workflows/build_harper_binaries.yml)
[![Website](https://github.com/automattic/harper/actions/workflows/build_web.yml/badge.svg)](https://github.com/automattic/harper/actions/workflows/build_web.yml)
[![Precommit](https://github.com/automattic/harper/actions/workflows/precommit.yml/badge.svg)](https://github.com/automattic/harper/actions/workflows/precommit.yml)
[![Crates.io](https://img.shields.io/crates/v/harper-ls)](https://crates.io/crates/harper-ls)
![NPM Version](https://img.shields.io/npm/v/harper.js)

Harper is an English grammar checker designed to be _just right._
I created it after years of dealing with the shortcomings of the competition.

Grammarly was too expensive and too overbearing.
Its suggestions lacked context, and were often just plain _wrong_.
Not to mention: it&#039;s a privacy nightmare.
Everything you write with Grammarly is sent to their servers.
Their privacy policy claims they don&#039;t sell the data, but that doesn&#039;t mean they don&#039;t use it to train large language models and god knows what else.
Not only that, but the round-trip-time of the network request makes revising your work all the more tedious.

LanguageTool is great, if you have gigabytes of RAM to spare and are willing to download the ~16GB n-gram dataset.
Besides the memory requirements, I found LanguageTool too slow: it would take several seconds to lint even a moderate-size document.

That&#039;s why I created Harper: it is the grammar checker that fits my needs.
Not only does it take milliseconds to lint a document, take less than 1/50th of LanguageTool&#039;s memory footprint,
but it is also completely private.

Harper is even small enough to load via [WebAssembly.](https://writewithharper.com)

## Language Support

Harper currently only supports English, but the core is extensible to support other languages, so we welcome contributions that allow for other language support.

## Performance Issues

We consider long lint times bugs.
If you encounter any significant performance issues, please create an issue on the topic.

If you find a fix to any performance issue, we would appreciate the contribution.
Just please make sure to read [our contribution guidelines first.](https://github.com/automattic/harper/blob/master/CONTRIBUTING.md)

## Links

- [Frequently Asked Questions](https://writewithharper.com/docs/faq)
- [Obsidian Documentation](https://writewithharper.com/docs/integrations/obsidian)
- [`harper-ls` Documentation](https://writewithharper.com/docs/integrations/language-server)
- Supported Editors&#039; Documentation
  - [Visual Studio Code](https://writewithharper.com/docs/integrations/visual-studio-code)
  - [Neovim](https://writewithharper.com/docs/integrations/neovim)
  - [Helix](https://writewithharper.com/docs/integrations/helix)
  - [Emacs](https://writewithharper.com/docs/integrations/emacs)
  - [Zed](https://writewithharper.com/docs/integrations/zed)
- [`harper.js` Documentation](https://writewithharper.com/docs/harperjs/introduction)
- [Official Discord Server](https://discord.com/invite/JBqcAaKrzQ)

## Huge Thanks

This project would not be possible without the hard work from those who [contribute](https://writewithharper.com/docs/contributors/introduction).

&lt;a href=&quot;https://github.com/automattic/harper/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=automattic/harper&quot; /&gt;
&lt;/a&gt;

Harper&#039;s logo was designed by [Lukas Werner](https://lukaswerner.com/).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[bee-san/RustScan]]></title>
            <link>https://github.com/bee-san/RustScan</link>
            <guid>https://github.com/bee-san/RustScan</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:12 GMT</pubDate>
            <description><![CDATA[ü§ñ The Modern Port Scanner ü§ñ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bee-san/RustScan">bee-san/RustScan</a></h1>
            <p>ü§ñ The Modern Port Scanner ü§ñ</p>
            <p>Language: Rust</p>
            <p>Stars: 16,865</p>
            <p>Forks: 1,141</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

‚û°Ô∏è [Discord][discord] | [Installation Guide][toc-install] | [Usage Guide][usage-guide] ‚¨ÖÔ∏è

&lt;img src=&quot;pictures/rustscan.png&quot; height=400px width=400px&gt;

&lt;!--&lt;u&gt;**The Modern Port Scanner.**&lt;/u&gt;--&gt;
**Fast, smart, effective.**

![Arch Linux package][badge-1] ![Built with Rust][badge-2] ![GitHub All Releases][badge-3] ![Crates.io][badge-4] ![Discord][badge-5] ![Actions][badge-6]

&lt;/div&gt;

# ü§î What is this?

![fast][speed-1]

The Modern Port Scanner. **Find ports quickly (3 seconds at its fastest)**. Run scripts through our scripting engine (Python, Lua, Shell supported).

# üõ†Ô∏è Installation

You can install RustScan&#039;s binary from our [releases page](https://github.com/RustScan/RustScan/releases).

We would prefer you to install with a package manager so it is tested and works for your system.

RustScan is in many repositories already. Install it with whatever tools you wish:

[![Packaging status](https://repology.org/badge/vertical-allrepos/rustscan.svg)](https://repology.org/project/rustscan/versions)

RustScan only officially supports Cargo installations, if you want to use that please install Rust and then `cargo install rustscan`

Example installations include:

MacOS:

```
  brew install rustscan
```

Arch:

```
  yay rustscan
```

# ‚ú® Features

- Scans all 65k ports in **3 seconds**.
- Full scripting engine support. Automatically pipe results into Nmap, or use our scripts (or write your own) to do whatever you want.
- Adaptive learning. RustScan improves the more you use it. No bloated machine learning here, just basic maths.
- The usuals you would expect. IPv6, CIDR, file input and more.
- Automatically pipes ports into Nmap.

## ‚ÄºÔ∏è Important Links

|         &lt;!--Installation Guide--&gt;          |          &lt;!--Documentation--&gt;          |       &lt;!--Discord--&gt;        |
| :----------------------------------------: | :------------------------------------: | :-------------------------: |
| :book: [Installation Guide][links-table-1] | :books: [Documentation][links-table-2] | :parrot: [Discord][discord] |

## üôã Table of Contents

- üìñ [Installation Guide][toc-install]
- üêã [Docker Usage][toc-docker-usage]
- ü¶ú [Discord][discord]
- ü§∏ [Usage][usage-1]

# üî≠ Why RustScan?

RustScan is a modern take on the port scanner. Sleek &amp; fast. All while providing extensive extendability to you.

Not to mention RustScan uses Adaptive Learning to improve itself over time, making it the best port scanner for **you**.

## üßã Speed

![fast][speed-1]

Speed is guaranteed via RustScan. However, if you want to run a slow scan due to stealth, that is possible too.

Firstly, let&#039;s talk code.

We have tests that check to see if RustScan is significantly slower than the previous version. If it is, the continuous integration fails, and we can&#039;t commit code to master unless we make it faster.

[HyperFine][speed-2] is used to monitor RustScan&#039;s performance over time to answer the question, &quot;Are we getting faster? Are we getting slower?&quot;.

Every pull request is reviewed by **one** person, but more often than not, **two** people review it. We test it manually and ensure the code doesn&#039;t negatively affect performance.

[Read more here][speed-3].

## ‚öôÔ∏è Extensible

![scripts][extensible-1]

### _RustScan piping results into the custom Python script_

RustScan has a new scripting engine that allows anyone to write scripts in most languages. Python, Lua, and Shell are all supported.

Want to take your found ports and pipe them into Nmap for further analysis? That&#039;s possible. Want to run `smb-enum` if SMB is found open? Possible.

The possibilities are endless -- and you can write scripts in whatever language you feel comfortable with.

[Read more here][extensible-2].

## üåä Adaptive

![adaptive][adaptive-1]

### _RustScan automatically fine-tunes itself to match the host OS_

RustScan has a cool set of features called &quot;Adaptive Learning&quot;. These features &quot;learn&quot; about the environment you are scanning and how _you_ use RustScan to **improve itself over time**.

We use this umbrella term for any feature that fits this criterion. The list constantly changes, so [check out our wiki for more information][adaptive-learning].

## üë©‚Äçü¶Ø Accessible

![fast][accessible-1]

RustScan is one of the first penetration testing tools that aims to be entirely accessible.

[Most penetration testing tools are not accessible][accessible-2], which negatively affects the whole industry.

RustScan has continuous integration testing that aims to ensure it is accessible, and we are constantly working on ways to improve our accessibility and ensure _everyone_ can use RustScan.

# ü§∏ Usage

We have 2 usage guides. [Basic Usage][usage-1] and [Things you may want to do][usage-2].

We also have documentation about our config file [here][config-file-here].

# üé™ Community

[Contributing][community-1] Read this to learn how.

## Contributors ‚ú®

&lt;!-- ALL-CONTRIBUTORS-BADGE:START - Do not remove or modify this section --&gt;

[![All Contributors](https://img.shields.io/badge/all_contributors-26-orange.svg?style=flat-square)](#contributors-)

&lt;!-- ALL-CONTRIBUTORS-BADGE:END --&gt;

Thanks goes to these wonderful people ([emoji key](https://allcontributors.org/docs/en/emoji-key)):

&lt;!-- ALL-CONTRIBUTORS-LIST:START - Do not remove or modify this section --&gt;
&lt;!-- prettier-ignore-start --&gt;
&lt;!-- markdownlint-disable --&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://skerritt.blog&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/10378052?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bee&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#infra-beeskerritt&quot; title=&quot;Infrastructure (Hosting, Build-Tools, etc)&quot;&gt;üöá&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=beeskerritt&quot; title=&quot;Tests&quot;&gt;‚ö†Ô∏è&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=beesan&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;#design-beeskerritt&quot; title=&quot;Design&quot;&gt;üé®&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://sakiir.ovh&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/9950578?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;SakiiR&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=SakiiR&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/issues?q=author%3ASakiiR&quot; title=&quot;Bug reports&quot;&gt;üêõ&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/smackhack&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/48143394?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;smackhack&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#ideas-smackhack&quot; title=&quot;Ideas, Planning, &amp; Feedback&quot;&gt;ü§î&lt;/a&gt; &lt;a href=&quot;#example-smackhack&quot; title=&quot;Examples&quot;&gt;üí°&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;http://bernardoamc.github.io/&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/428984?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Bernardo Araujo&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=bernardoamc&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/issues?q=author%3Abernardoamc&quot; title=&quot;Bug reports&quot;&gt;üêõ&lt;/a&gt; &lt;a href=&quot;#design-bernardoamc&quot; title=&quot;Design&quot;&gt;üé®&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/Isona&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/11759523?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Izzy Whistlecroft&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/issues?q=author%3AIsona&quot; title=&quot;Bug reports&quot;&gt;üêõ&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://imlonghao.com&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/4951333?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;imlonghao&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/issues?q=author%3Aimlonghao&quot; title=&quot;Bug reports&quot;&gt;üêõ&lt;/a&gt; &lt;a href=&quot;#maintenance-imlonghao&quot; title=&quot;Maintenance&quot;&gt;üöß&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/royharoush&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/8113056?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;royharoush&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#ideas-royharoush&quot; title=&quot;Ideas, Planning, &amp; Feedback&quot;&gt;ü§î&lt;/a&gt; &lt;a href=&quot;#design-royharoush&quot; title=&quot;Design&quot;&gt;üé®&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/Atul9&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/3390330?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Atul Bhosale&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=Atul9&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://tgotwig.dev&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/30773779?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Thomas Gotwig&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#platform-TGotwig&quot; title=&quot;Packaging/porting to new platform&quot;&gt;üì¶&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/remigourdon&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/2874133?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;R√©mi Gourdon&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=remigourdon&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=remigourdon&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://cmnatic.co.uk&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/4163116?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Ben (CMNatic)&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=cmnatic&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=cmnatic&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt; &lt;a href=&quot;#design-cmnatic&quot; title=&quot;Design&quot;&gt;üé®&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/Ferryistaken&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/47927670?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Alessandro Ferrari&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#content-Ferryistaken&quot; title=&quot;Content&quot;&gt;üñã&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/Phenomite&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/8285537?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Phenomite&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#content-Phenomite&quot; title=&quot;Content&quot;&gt;üñã&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://supersandro.de/&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/7258858?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sandro&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#content-SuperSandro2000&quot; title=&quot;Content&quot;&gt;üñã&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/issues?q=author%3ASuperSandro2000&quot; title=&quot;Bug reports&quot;&gt;üêõ&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=SuperSandro2000&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://swag.lgbt&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/25358963?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Cass&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#platform-caass&quot; title=&quot;Packaging/porting to new platform&quot;&gt;üì¶&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=caass&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/issues?q=author%3Acaass&quot; title=&quot;Bug reports&quot;&gt;üêõ&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/niklasmohrin&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/47574893?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Niklas Mohrin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=niklasmohrin&quot; title=&quot;Documentation&quot;&gt;üìñ&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=niklasmohrin&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/issues?q=author%3Aniklasmohrin&quot; title=&quot;Bug reports&quot;&gt;üêõ&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://liberapay.com/Artem4/&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/5614476?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Artem Polishchuk&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#platform-tim77&quot; title=&quot;Packaging/porting to new platform&quot;&gt;üì¶&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/buermarc&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/44375277?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;buermarc&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=buermarc&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/bergabman&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/44554109?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;bergabman&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=bergabman&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/issues?q=author%3Abergabman&quot; title=&quot;Bug reports&quot;&gt;üêõ&lt;/a&gt; &lt;a href=&quot;#design-bergabman&quot; title=&quot;Design&quot;&gt;üé®&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/dmitris&quot;&gt;&lt;img src=&quot;https://avatars0.githubusercontent.com/u/31205?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Dmitry Savintsev&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=dmitris&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/bofh69&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/1444315?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Sebastian Andersson&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=bofh69&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/mattcorbin&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/6537765?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Matt Corbin&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=mattcorbin&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;http://rootsploit.com&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/67270834?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;RootSploit&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;#blog-rootsploit&quot; title=&quot;Blogposts&quot;&gt;üìù&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/eiffel-fl&quot;&gt;&lt;img src=&quot;https://avatars2.githubusercontent.com/u/12171754?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;eiffel-fl&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=eiffel-fl&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/u5surf&quot;&gt;&lt;img src=&quot;https://avatars1.githubusercontent.com/u/14180225?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Y.Horie&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=u5surf&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/okrplay&quot;&gt;&lt;img src=&quot;https://avatars3.githubusercontent.com/u/32576280?v=4&quot; width=&quot;100px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;Oskar&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;br /&gt;&lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=okrplay&quot; title=&quot;Code&quot;&gt;üíª&lt;/a&gt; &lt;a href=&quot;https://github.com/RustScan/RustScan/commits?author=okrplay&quot; title=&quot;Tests&quot;&gt;‚ö†Ô∏è&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;!-- markdownlint-enable --&gt;
&lt;!-- prettier-ignore-end --&gt;

&lt;!-- ALL-CONTRIBUTORS-LIST:END --&gt;

This project follows the [all-contributors](https://github.com/all-contributors/all-contributors) specification. Contributions of any kind welcome!

&lt;!--Links--&gt;

[Docker]: https://hub.docker.com/r/cmnatic/rustscan &quot;This is the recommended distribution of rustscan&quot;
[kali]: https://github.com/RustScan/RustScan/wiki/Installation-Guide#%EF%B8%8F-debian--kali &quot;Read the install guide&quot;
[Kali/Debian]: https://github.com/RustScan/RustScan/releases &quot;Kali Debian&quot;
[Arch-Linux]: https://archlinux.org/packages/extra/x86_64/rustscan/ &quot;Arch Linux installation of Rustscan&quot;
[Homebrew]: https://formulae.brew.sh/formula/rustscan &quot;Homebrew install of Rustscan&quot;
[usage-1]: https://github.com/RustScan/RustScan/wiki/Usage &quot;Basic Usage of Rustscan&quot;
[usage-0]: https://github.com/RustScan/RustScan/wiki/Installation-Guide#docker-whale &quot;Use Docker Rustscan&quot;
[config-file-here]: https://github.com/RustScan/RustScan/wiki/Config-File &quot;RustScan Configuration File&quot;
[usage-2]: https://github.com/RustScan/RustScan/wiki/Things-you-may-want-to-do-with-RustScan-but-don&#039;t-understand-how &quot;Things you may want to do with rustscan but don&#039;t know how&quot;
[community-1]: https://github.com/RustScan/RustScan/wiki/Contributing &quot;Learn how to contribute&quot;
[distributions-1]: https://software.opensuse.org/package/rustscan?search_term=rustscan &quot;Open Suse rustscan distribution&quot;
[distributions-2]: https://copr.fedorainfracloud.org/coprs/atim/rustscan/ &quot;Rustscan in Fedora&quot;
[repology-1]: https://repology.org/project/rustscan/versions &quot;Packaging Status&quot;
[install-1]: https://github.com/RustScan/RustScan/wiki/Installation-Guide &quot;Installation guide&quot;
[accessible-2]: https://bees.substack.com/p/making-hacking-accessible &quot;Making Hacking Accessible&quot;
[extensible-2]: https://github.com/RustScan/RustScan/wiki/RustScan-Scripting-Engine &quot;Scripting Engine&quot;
[speed-2]: https://github.com/sharkdp/hyperfine &quot;Hyperfine&quot;
[speed-3]: https://github.com/RustScan/RustScan/wiki/Increasing-Speed-&amp;-Accuracy &quot;Increasing Speed &amp; Accuracy&quot;
[toc-community]: https://github.com/RustScan/RustScan#-community &quot;Community&quot;
[links-table-1]: https://github.com/RustScan/RustScan#-full-installation-guide &quot;Full installation guide&quot;
[links-table-2]: https://github.com/bee-san/RustScan/wiki &quot;Rustscan&quot;
[discord]: http://discord.skerritt.blog &quot;Discord blog&quot;
[toc-install]: https://github.com/RustScan/RustScan/wiki/Installation-Guide &quot;Installation Guide Wiki&quot;
[toc-docker-usage]: https://github.com/RustScan/RustScan/wiki/Installation-Guide#docker- &quot;Docker Installation Guide Wiki&quot;
[usage-guide]: https://github.com/RustScan/RustScan#-usage
[adaptive-learning]: https://github.com/RustScan/RustScan/wiki/Adaptive-Learning &quot;Adaptive Learning&quot;

&lt;!--Pictures--&gt;

[DockerPic]: https://github.com/RustScan/RustScan/blob/master/pictures/docker.png?raw=true &quot;Docker install&quot;
[Kali1]: https://github.com/RustScan/RustScan/blob/master/pictures/kali.png?raw=true &quot;Kali Picture&quot;
[Arch]: https://github.com/RustScan/RustScan/blob/master/pictures/arch.png?raw=true &quot;Arch Linux&quot;
[Apple]: https://raw.githubusercontent.com/RustScan/RustScan/master/pictures/apple.png?size &quot;Apple&quot;
[rustscan-svg]: https://repology.org/badge/vertical-allrepos/rustscan.svg &quot;Picture of rustscan repology&quot;
[accessible-1]: pictures/accessible.gif &quot;Fast&quot;
[adaptive-1]: pictures/adaptive.gif &quot;Adaptive&quot;
[extensible-1]: pictures/scripts.gif &quot;Scripts&quot;
[speed-1]: pictures/fast.gif &quot;Speed&quot;
[badge-1]: https://img.shields.io/archlinux/v/extra/x86_64/rustscan?style=plastic&amp;logo=archlinux&amp;link=https%3A%2F%2Farchlinux.org%2Fpackages%2Fextra%2Fx86_64%2Frustscan%2F
[badge-2]: https://img.shields.io/badge/Built%20with-Rust-Purple
[badge-3]: https://img.shields.io/github/downloads/rustscan/rustscan/total?label=GitHub%20Downloads
[badge-4]: https://img.shields.io/crates/d/rustscan?label=Cargo%20Downloads
[badge-5]: https://img.shields.io/discord/754001738184392704
[badge-6]: https://github.com/RustScan/RustScan/actions/workflows/build.yml/badge.svg?branch=master
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustdesk/rustdesk]]></title>
            <link>https://github.com/rustdesk/rustdesk</link>
            <guid>https://github.com/rustdesk/rustdesk</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:11 GMT</pubDate>
            <description><![CDATA[An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustdesk/rustdesk">rustdesk/rustdesk</a></h1>
            <p>An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.</p>
            <p>Language: Rust</p>
            <p>Stars: 92,641</p>
            <p>Forks: 13,473</p>
            <p>Stars today: 110 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;res/logo-header.svg&quot; alt=&quot;RustDesk - Your remote desktop&quot;&gt;&lt;br&gt;
  &lt;a href=&quot;#raw-steps-to-build&quot;&gt;Build&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#how-to-build-with-docker&quot;&gt;Docker&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#file-structure&quot;&gt;Structure&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#snapshot&quot;&gt;Snapshot&lt;/a&gt;&lt;br&gt;
  [&lt;a href=&quot;docs/README-UA.md&quot;&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href=&quot;docs/README-CS.md&quot;&gt;ƒçesky&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ZH.md&quot;&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href=&quot;docs/README-HU.md&quot;&gt;Magyar&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ES.md&quot;&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FA.md&quot;&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FR.md&quot;&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DE.md&quot;&gt;Deutsch&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PL.md&quot;&gt;Polski&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ID.md&quot;&gt;Indonesian&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FI.md&quot;&gt;Suomi&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ML.md&quot;&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href=&quot;docs/README-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NL.md&quot;&gt;Nederlands&lt;/a&gt;] | [&lt;a href=&quot;docs/README-IT.md&quot;&gt;Italiano&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PTBR.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href=&quot;docs/README-EO.md&quot;&gt;Esperanto&lt;/a&gt;] | [&lt;a href=&quot;docs/README-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href=&quot;docs/README-AR.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href=&quot;docs/README-VN.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DA.md&quot;&gt;Dansk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-GR.md&quot;&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href=&quot;docs/README-TR.md&quot;&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NO.md&quot;&gt;Norsk&lt;/a&gt;]&lt;br&gt;
  &lt;b&gt;We need your help to translate this README, &lt;a href=&quot;https://github.com/rustdesk/rustdesk/tree/master/src/lang&quot;&gt;RustDesk UI&lt;/a&gt; and &lt;a href=&quot;https://github.com/rustdesk/doc.rustdesk.com&quot;&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt;
&lt;/p&gt;

&gt; [!Caution]
&gt; **Misuse Disclaimer:** &lt;br&gt;
&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.


Chat with us: [Discord](https://discord.gg/nDceKgxnkV) | [Twitter](https://twitter.com/rustdesk) | [Reddit](https://www.reddit.com/r/rustdesk) | [YouTube](https://www.youtube.com/@rustdesk)

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/I2I04VU09)

Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, [set up your own](https://rustdesk.com/server), or [write your own rendezvous/relay server](https://github.com/rustdesk/rustdesk-server-demo).

![image](https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png)

RustDesk welcomes contribution from everyone. See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for help getting started.

[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)

[**BINARY DOWNLOAD**](https://github.com/rustdesk/rustdesk/releases)

[**NIGHTLY BUILD**](https://github.com/rustdesk/rustdesk/releases/tag/nightly)

[&lt;img src=&quot;https://f-droid.org/badge/get-it-on.png&quot;
    alt=&quot;Get it on F-Droid&quot;
    height=&quot;80&quot;&gt;](https://f-droid.org/en/packages/com.carriez.flutter_hbb)
[&lt;img src=&quot;https://flathub.org/api/badge?svg&amp;locale=en&quot;
    alt=&quot;Get it on Flathub&quot;
    height=&quot;80&quot;&gt;](https://flathub.org/apps/com.rustdesk.RustDesk)

## Dependencies

Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our [CI](https://github.com/rustdesk/rustdesk/blob/master/.github/workflows/flutter-build.yml) for building Flutter version.

Please download Sciter dynamic library yourself.

[Windows](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll) |
[Linux](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so) |
[macOS](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib)

## Raw Steps to build

- Prepare your Rust development env and C++ build env

- Install [vcpkg](https://github.com/microsoft/vcpkg), and set `VCPKG_ROOT` env variable correctly

  - Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static
  - Linux/macOS: vcpkg install libvpx libyuv opus aom

- run `cargo run`

## [Build](https://rustdesk.com/docs/en/dev/build/)

## How to Build on Linux

### Ubuntu 18 (Debian 10)

```sh
sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
```

### openSUSE Tumbleweed

```sh
sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
```

### Fedora 28 (CentOS 8)

```sh
sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
```

### Arch (Manjaro)

```sh
sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
```

### Install vcpkg

```sh
git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
```

### Fix libvpx (For Fedora)

```sh
cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i &#039;s/CFLAGS+=-I/CFLAGS+=-fPIC -I/g&#039; Makefile
sed -i &#039;s/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g&#039; Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
```

### Build

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
```

## How to build with Docker

Begin by cloning the repository and building the Docker container:

```sh
git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t &quot;rustdesk-builder&quot; .
```

Then, each time you need to build the application, run the following command:

```sh
docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=&quot;$(id -u)&quot; -e PGID=&quot;$(id -g)&quot; rustdesk-builder
```

Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the `&lt;OPTIONAL-ARGS&gt;` position. For instance, if you wanted to build an optimized release version, you would run the command above followed by `--release`. The resulting executable will be available in the target folder on your system, and can be run with:

```sh
target/debug/rustdesk
```

Or, if you&#039;re running a release executable:

```sh
target/release/rustdesk
```

Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as `install` or `run` are not currently supported via this method as they would install or run the program inside the container instead of the host.

## File Structure

- **[libs/hbb_common](https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common)**: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions
- **[libs/scrap](https://github.com/rustdesk/rustdesk/tree/master/libs/scrap)**: screen capture
- **[libs/enigo](https://github.com/rustdesk/rustdesk/tree/master/libs/enigo)**: platform specific keyboard/mouse control
- **[libs/clipboard](https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard)**: file copy and paste implementation for Windows, Linux, macOS.
- **[src/ui](https://github.com/rustdesk/rustdesk/tree/master/src/ui)**: obsolete Sciter UI (deprecated)
- **[src/server](https://github.com/rustdesk/rustdesk/tree/master/src/server)**: audio/clipboard/input/video services, and network connections
- **[src/client.rs](https://github.com/rustdesk/rustdesk/tree/master/src/client.rs)**: start a peer connection
- **[src/rendezvous_mediator.rs](https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs)**: Communicate with [rustdesk-server](https://github.com/rustdesk/rustdesk-server), wait for remote direct (TCP hole punching) or relayed connection
- **[src/platform](https://github.com/rustdesk/rustdesk/tree/master/src/platform)**: platform specific code
- **[flutter](https://github.com/rustdesk/rustdesk/tree/master/flutter)**: Flutter code for desktop and mobile
- **[flutter/web/js](https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js)**: JavaScript for Flutter web client

## Screenshots

![Connection Manager](https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651)

![Connected to a Windows PC](https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea)

![File Transfer](https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad)

![TCP Tunneling](https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[huggingface/candle]]></title>
            <link>https://github.com/huggingface/candle</link>
            <guid>https://github.com/huggingface/candle</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:10 GMT</pubDate>
            <description><![CDATA[Minimalist ML framework for Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/candle">huggingface/candle</a></h1>
            <p>Minimalist ML framework for Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 17,600</p>
            <p>Forks: 1,145</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># candle
[![discord server](https://dcbadge.vercel.app/api/server/hugging-face-879548962464493619)](https://discord.gg/hugging-face-879548962464493619)
[![Latest version](https://img.shields.io/crates/v/candle-core.svg)](https://crates.io/crates/candle-core)
[![Documentation](https://docs.rs/candle-core/badge.svg)](https://docs.rs/candle-core)
[![License](https://img.shields.io/github/license/base-org/node?color=blue)](https://github.com/huggingface/candle/blob/main/LICENSE-MIT)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square)](https://github.com/huggingface/candle/blob/main/LICENSE-APACHE)

Candle is a minimalist ML framework for Rust with a focus on performance (including GPU support) 
and ease of use. Try our online demos: 
[whisper](https://huggingface.co/spaces/lmz/candle-whisper),
[LLaMA2](https://huggingface.co/spaces/lmz/candle-llama2),
[T5](https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm),
[yolo](https://huggingface.co/spaces/lmz/candle-yolo),
[Segment
Anything](https://huggingface.co/spaces/radames/candle-segment-anything-wasm).

## Get started

Make sure that you have [`candle-core`](https://github.com/huggingface/candle/tree/main/candle-core) correctly installed as described in [**Installation**](https://huggingface.github.io/candle/guide/installation.html).

Let&#039;s see how to run a simple matrix multiplication.
Write the following to your `myapp/src/main.rs` file:
```rust
use candle_core::{Device, Tensor};

fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let device = Device::Cpu;

    let a = Tensor::randn(0f32, 1., (2, 3), &amp;device)?;
    let b = Tensor::randn(0f32, 1., (3, 4), &amp;device)?;

    let c = a.matmul(&amp;b)?;
    println!(&quot;{c}&quot;);
    Ok(())
}
```

`cargo run` should display a tensor of shape `Tensor[[2, 4], f32]`.


Having installed `candle` with Cuda support, simply define the `device` to be on GPU:

```diff
- let device = Device::Cpu;
+ let device = Device::new_cuda(0)?;
```

For more advanced examples, please have a look at the following section.

## Check out our examples

These online demos run entirely in your browser:
- [yolo](https://huggingface.co/spaces/lmz/candle-yolo): pose estimation and
  object recognition.
- [whisper](https://huggingface.co/spaces/lmz/candle-whisper): speech recognition.
- [LLaMA2](https://huggingface.co/spaces/lmz/candle-llama2): text generation.
- [T5](https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm): text generation.
- [Phi-1.5, and Phi-2](https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm): text generation.
- [Segment Anything Model](https://huggingface.co/spaces/radames/candle-segment-anything-wasm): Image segmentation.
- [BLIP](https://huggingface.co/spaces/radames/Candle-BLIP-Image-Captioning): image captioning.

We also provide some command line based examples using state of the art models:

- [LLaMA v1, v2, and v3](./candle-examples/examples/llama/): general LLM, includes
  the SOLAR-10.7B variant.
- [Falcon](./candle-examples/examples/falcon/): general LLM.
- [Codegeex4](./candle-examples/examples/codegeex4-9b/): Code completion, code interpreter, web search, function calling, repository-level
- [GLM4](./candle-examples/examples/glm4/): Open Multilingual Multimodal Chat LMs by THUDM
- [Gemma v1 and v2](./candle-examples/examples/gemma/): 2b and 7b+/9b general LLMs from Google Deepmind.
- [RecurrentGemma](./candle-examples/examples/recurrent-gemma/): 2b and 7b
  Griffin based models from Google that mix attention with a RNN like state.
- [Phi-1, Phi-1.5, Phi-2, and Phi-3](./candle-examples/examples/phi/): 1.3b,
  2.7b, and 3.8b general LLMs with performance on par with 7b models.
- [StableLM-3B-4E1T](./candle-examples/examples/stable-lm/): a 3b general LLM
  pre-trained on 1T tokens of English and code datasets. Also supports
  StableLM-2, a 1.6b LLM trained on 2T tokens, as well as the code variants.
- [Mamba](./candle-examples/examples/mamba/): an inference only
  implementation of the Mamba state space model.
- [Mistral7b-v0.1](./candle-examples/examples/mistral/): a 7b general LLM with
  better performance than all publicly available 13b models as of 2023-09-28.
- [Mixtral8x7b-v0.1](./candle-examples/examples/mixtral/): a sparse mixture of
  experts 8x7b general LLM with better performance than a Llama 2 70B model with
  much faster inference.
- [StarCoder](./candle-examples/examples/bigcode/) and
  [StarCoder2](./candle-examples/examples/starcoder2/): LLM specialized to code generation.
- [Qwen1.5](./candle-examples/examples/qwen/): Bilingual (English/Chinese) LLMs.
- [RWKV v5 and v6](./candle-examples/examples/rwkv/): An RNN with transformer level LLM
  performance.
- [Replit-code-v1.5](./candle-examples/examples/replit-code/): a 3.3b LLM specialized for code completion.
- [Yi-6B / Yi-34B](./candle-examples/examples/yi/): two bilingual
  (English/Chinese) general LLMs with 6b and 34b parameters.
- [Quantized LLaMA](./candle-examples/examples/quantized/): quantized version of
  the LLaMA model using the same quantization techniques as
  [llama.cpp](https://github.com/ggerganov/llama.cpp).

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/quantized/assets/aoc.gif&quot; width=&quot;600&quot;&gt;
  
- [Stable Diffusion](./candle-examples/examples/stable-diffusion/): text to
  image generative model, support for the 1.5, 2.1, SDXL 1.0 and Turbo versions.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/stable-diffusion/assets/stable-diffusion-xl.jpg&quot; width=&quot;200&quot;&gt;

- [Wuerstchen](./candle-examples/examples/wuerstchen/): another text to
  image generative model.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/wuerstchen/assets/cat.jpg&quot; width=&quot;200&quot;&gt;

- [yolo-v3](./candle-examples/examples/yolo-v3/) and
  [yolo-v8](./candle-examples/examples/yolo-v8/): object detection and pose
  estimation models.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.od.jpg&quot; width=&quot;200&quot;&gt;&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.pose.jpg&quot; width=&quot;200&quot;&gt;
- [segment-anything](./candle-examples/examples/segment-anything/): image
  segmentation model with prompt.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/segment-anything/assets/sam_merged.jpg&quot; width=&quot;200&quot;&gt;

- [SegFormer](./candle-examples/examples/segformer/): transformer based semantic segmentation model.
- [Whisper](./candle-examples/examples/whisper/): speech recognition model.
- [EnCodec](./candle-examples/examples/encodec/): high-quality audio compression
  model using residual vector quantization.
- [MetaVoice](./candle-examples/examples/metavoice/): foundational model for
  text-to-speech.
- [Parler-TTS](./candle-examples/examples/parler-tts/): large text-to-speech
  model.
- [T5](./candle-examples/examples/t5), [Bert](./candle-examples/examples/bert/),
  [JinaBert](./candle-examples/examples/jina-bert/) : useful for sentence embeddings.
- [DINOv2](./candle-examples/examples/dinov2/): computer vision model trained
  using self-supervision (can be used for imagenet classification, depth
  evaluation, segmentation).
- [VGG](./candle-examples/examples/vgg/),
  [RepVGG](./candle-examples/examples/repvgg): computer vision models.
- [BLIP](./candle-examples/examples/blip/): image to text model, can be used to
  generate captions for an image.
- [CLIP](./candle-examples/examples/clip/): multi-model vision and language
  model.
- [TrOCR](./candle-examples/examples/trocr/): a transformer OCR model, with
  dedicated submodels for hand-writing and printed recognition.
- [Marian-MT](./candle-examples/examples/marian-mt/): neural machine translation
  model, generates the translated text from the input text.
- [Moondream](./candle-examples/examples/moondream/): tiny computer-vision model 
  that can answer real-world questions about images.

Run them using commands like:
```
cargo run --example quantized --release
```

In order to use **CUDA** add `--features cuda` to the example command line. If
you have cuDNN installed, use `--features cudnn` for even more speedups.

There are also some wasm examples for whisper and
[llama2.c](https://github.com/karpathy/llama2.c). You can either build them with
`trunk` or try them online:
[whisper](https://huggingface.co/spaces/lmz/candle-whisper),
[llama2](https://huggingface.co/spaces/lmz/candle-llama2),
[T5](https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm),
[Phi-1.5, and Phi-2](https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm),
[Segment Anything Model](https://huggingface.co/spaces/radames/candle-segment-anything-wasm).

For LLaMA2, run the following command to retrieve the weight files and start a
test server:
```bash
cd candle-wasm-examples/llama2-c
wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/model.bin
wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/tokenizer.json
trunk serve --release --port 8081
```
And then head over to
[http://localhost:8081/](http://localhost:8081/).

&lt;!--- ANCHOR: useful_libraries ---&gt;

## Useful External Resources
- [`candle-tutorial`](https://github.com/ToluClassics/candle-tutorial): A
  very detailed tutorial showing how to convert a PyTorch model to Candle.
- [`candle-lora`](https://github.com/EricLBuehler/candle-lora): Efficient and
  ergonomic LoRA implementation for Candle. `candle-lora` has      
  out-of-the-box LoRA support for many models from Candle, which can be found
  [here](https://github.com/EricLBuehler/candle-lora/tree/master/candle-lora-transformers/examples).
- [`optimisers`](https://github.com/KGrewal1/optimisers): A collection of optimisers
  including SGD with momentum, AdaGrad, AdaDelta, AdaMax, NAdam, RAdam, and RMSprop.
- [`candle-vllm`](https://github.com/EricLBuehler/candle-vllm): Efficient platform for inference and
  serving local LLMs including an OpenAI compatible API server.
- [`candle-ext`](https://github.com/mokeyish/candle-ext): An extension library to Candle that provides PyTorch functions not currently available in Candle.
- [`candle-coursera-ml`](https://github.com/vishpat/candle-coursera-ml): Implementation of ML algorithms from Coursera&#039;s [Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction) course.
- [`kalosm`](https://github.com/floneum/floneum/tree/master/interfaces/kalosm): A multi-modal meta-framework in Rust for interfacing with local pre-trained models with support for controlled generation, custom samplers, in-memory vector databases, audio transcription, and more.
- [`candle-sampling`](https://github.com/EricLBuehler/candle-sampling): Sampling techniques for Candle.
- [`gpt-from-scratch-rs`](https://github.com/jeroenvlek/gpt-from-scratch-rs): A port of Andrej Karpathy&#039;s _Let&#039;s build GPT_ tutorial on YouTube showcasing the Candle API on a toy problem.
- [`candle-einops`](https://github.com/tomsanbear/candle-einops): A pure rust implementation of the python [einops](https://github.com/arogozhnikov/einops) library.
- [`atoma-infer`](https://github.com/atoma-network/atoma-infer): A Rust library for fast inference at scale, leveraging FlashAttention2 for efficient attention computation, PagedAttention for efficient KV-cache memory management, and multi-GPU support. It is OpenAI api compatible.
- [`llms-from-scratch-rs`](https://github.com/nerdai/llms-from-scratch-rs): A comprehensive Rust translation of the code from Sebastian Raschka&#039;s Build an LLM from Scratch book.

If you have an addition to this list, please submit a pull request.

&lt;!--- ANCHOR_END: useful_libraries ---&gt;

&lt;!--- ANCHOR: features ---&gt;

## Features

- Simple syntax, looks and feels like PyTorch.
    - Model training.
    - Embed user-defined ops/kernels, such as [flash-attention v2](https://github.com/huggingface/candle/blob/89ba005962495f2bfbda286e185e9c3c7f5300a3/candle-flash-attn/src/lib.rs#L152).
- Backends.
    - Optimized CPU backend with optional MKL support for x86 and Accelerate for macs.
    - CUDA backend for efficiently running on GPUs, multiple GPU distribution via NCCL.
    - WASM support, run your models in a browser.
- Included models.
    - Language Models.
        - LLaMA v1, v2, and v3 with variants such as SOLAR-10.7B.
        - Falcon.
        - StarCoder, StarCoder2.
        - Phi 1, 1.5, 2, and 3.
        - Mamba, Minimal Mamba
        - Gemma v1 2b and 7b+, v2 2b and 9b.
        - Mistral 7b v0.1.
        - Mixtral 8x7b v0.1.
        - StableLM-3B-4E1T, StableLM-2-1.6B, Stable-Code-3B.
        - Replit-code-v1.5-3B.
        - Bert.
        - Yi-6B and Yi-34B.
        - Qwen1.5, Qwen1.5 MoE.
        - RWKV v5 and v6.
    - Quantized LLMs.
        - Llama 7b, 13b, 70b, as well as the chat and code variants.
        - Mistral 7b, and 7b instruct.
        - Mixtral 8x7b.
        - Zephyr 7b a and b (Mistral-7b based).
        - OpenChat 3.5 (Mistral-7b based).
    - Text to text.
        - T5 and its variants: FlanT5, UL2, MADLAD400 (translation), CoEdit (Grammar correction).
        - Marian MT (Machine Translation).
    - Text to image.
        - Stable Diffusion v1.5, v2.1, XL v1.0.
        - Wurstchen v2.
    - Image to text.
        - BLIP.
        - TrOCR.
    - Audio.
        - Whisper, multi-lingual speech-to-text.
        - EnCodec, audio compression model.
        - MetaVoice-1B, text-to-speech model.
        - Parler-TTS, text-to-speech model.
    - Computer Vision Models.
        - DINOv2, ConvMixer, EfficientNet, ResNet, ViT, VGG, RepVGG, ConvNeXT,
          ConvNeXTv2, MobileOne, EfficientVit (MSRA), MobileNetv4, Hiera, FastViT.
        - yolo-v3, yolo-v8.
        - Segment-Anything Model (SAM).
        - SegFormer.
- File formats: load models from safetensors, npz, ggml, or PyTorch files.
- Serverless (on CPU), small and fast deployments.
- Quantization support using the llama.cpp quantized types.

&lt;!--- ANCHOR_END: features ---&gt;

## How to use

&lt;!--- ANCHOR: cheatsheet ---&gt;
Cheatsheet:

|            | Using PyTorch                            | Using Candle                                                     |
|------------|------------------------------------------|------------------------------------------------------------------|
| Creation   | `torch.Tensor([[1, 2], [3, 4]])`         | `Tensor::new(&amp;[[1f32, 2.], [3., 4.]], &amp;Device::Cpu)?`           |
| Creation   | `torch.zeros((2, 2))`                    | `Tensor::zeros((2, 2), DType::F32, &amp;Device::Cpu)?`               |
| Indexing   | `tensor[:, :4]`                          | `tensor.i((.., ..4))?`                                           |
| Operations | `tensor.view((2, 2))`                    | `tensor.reshape((2, 2))?`                                        |
| Operations | `a.matmul(b)`                            | `a.matmul(&amp;b)?`                                                  |
| Arithmetic | `a + b`                                  | `&amp;a + &amp;b`                                                        |
| Device     | `tensor.to(device=&quot;cuda&quot;)`               | `tensor.to_device(&amp;Device::new_cuda(0)?)?`                            |
| Dtype      | `tensor.to(dtype=torch.float16)`         | `tensor.to_dtype(&amp;DType::F16)?`                                  |
| Saving     | `torch.save({&quot;A&quot;: A}, &quot;model.bin&quot;)`      | `candle::safetensors::save(&amp;HashMap::from([(&quot;A&quot;, A)]), &quot;model.safetensors&quot;)?` |
| Loading    | `weights = torch.load(&quot;model.bin&quot;)`      | `candle::safetensors::load(&quot;model.safetensors&quot;, &amp;device)`        |

&lt;!--- ANCHOR_END: cheatsheet ---&gt;


## Structure

- [candle-core](./candle-core): Core ops, devices, and `Tensor` struct definition
- [candle-nn](./candle-nn/): Tools to build real models
- [candle-examples](./candle-examples/): Examples of using the library in realistic settings
- [candle-kernels](./candle-kernels/): CUDA custom kernels
- [candle-datasets](./candle-datasets/): Datasets and data loaders.
- [candle-transformers](./candle-transformers): transformers-related utilities.
- [candle-flash-attn](./candle-flash-attn): Flash attention v2 layer.
- [candle-onnx](./candle-onnx/): ONNX model evaluation.

## FAQ

### Why should I use Candle?

&lt;!--- ANCHOR: goals ---&gt;

Candle&#039;s core goal is to *make serverless inference possible*. Full machine learning frameworks like PyTorch
are very large, which makes creating instances on a cluster slow. Candle allows deployment of lightweight
binaries.

Secondly, Candle lets you *remove Python* from production workloads. Python overhead can seriously hurt performance,
and the [GIL](https://www.backblaze.com/blog/the-python-gil-past-present-and-future/) is a notorious source of headaches.

Finally, Rust is cool! A lot of the HF ecosystem already has Rust crates, like [safetensors](https://github.com/huggingface/safetensors) and [tokenizers](https://github.com/huggingface/tokenizers).

&lt;!--- ANCHOR_END: goals ---&gt;

### Other ML frameworks

- [dfdx](https://github.com/coreylowman/dfdx) is a formidable crate, with shapes being included
  in types. This prevents a lot of headaches by getting the compiler to complain about shape mismatches right off the bat.
  However, we found that some features still require nightly, and writing code can be a bit daunting for non rust experts.

  We&#039;re leveraging and contributing to other core crates for the runtime so hopefully both crates can benefit from each
  other.

- [burn](https://github.com/burn-rs/burn) is a general crate that can leverage multiple backends so you can choose the best
  engine for your workload.

- [tch-rs](https://github.com/LaurentMazare/tch-rs.git) Bindings to the torch library in Rust. Extremely versatile, but they 
  bring in the entire torch library into the runtime. The main contributor of `tch-rs` is also involved in the development
  of `candle`.

### Common Errors

#### Missing symbols when compiling with the mkl feature.

If you get some missing symbols when compiling binaries/tests using the mkl
or accelerate features, e.g. for mkl you get:
```
  = note: /usr/bin/ld: (....o): in function `blas::sgemm&#039;:
          .../blas-0.22.0/src/lib.rs:1944: undefined reference to `sgemm_&#039; collect2: error: ld returned 1 exit status

  = note: some `extern` functions couldn&#039;t be found; some native libraries may need to be installed or have their path specified
  = note: use the `-l` flag to specify native libraries to link
  = note: use the `cargo:rustc-link-lib` directive to specify the native libraries to link with Cargo
```
or for accelerate:
```
Undefined symbols for architecture arm64:
            &quot;_dgemm_&quot;, referenced from:
                candle_core::accelerate::dgemm::h1b71a038552bcabe in libcandle_core...
            &quot;_sgemm_&quot;, referenced from:
                candle_core::accelerate::sgemm::h2cf21c592cba3c47 in libcandle_core...
          ld: symbol(s) not found for architecture arm64
```

This is likely due to a missing linker flag that was needed to enable the mkl library. You
can try adding the following for mkl at the top of your binary:
```rust
extern crate intel_mkl_src;
```
or for accelerate:
```rust
extern crate accelerate_src;
```

#### Cannot run the LLaMA examples: access to source requires login credentials

```
Error: request error: https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/tokenizer.json: status code 401
```

This is likely because you&#039;re not permissioned for the LLaMA-v2 model. To fix
this, you have to register on the huggingface-hub, accept the [LLaMA-v2 model
conditions](https://huggingface.co/meta-llama/Llama-2-7b-hf), and set up your
authentication token. See issue
[#350](https://github.com/huggingface/candle/issues/350) for more details.

#### Missing cute/cutlass headers when compiling flash-attn

```
  In file included from kernels/flash_fwd_launch_template.h:11:0,
                   from kernels/flash_fwd_hdim224_fp16_sm80.cu:5:
  kernels/flash_fwd_kernel.h:8:10: fatal error: cute

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[neondatabase/neon]]></title>
            <link>https://github.com/neondatabase/neon</link>
            <guid>https://github.com/neondatabase/neon</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:09 GMT</pubDate>
            <description><![CDATA[Neon: Serverless Postgres. We separated storage and compute to offer autoscaling, code-like database branching, and scale to zero.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/neondatabase/neon">neondatabase/neon</a></h1>
            <p>Neon: Serverless Postgres. We separated storage and compute to offer autoscaling, code-like database branching, and scale to zero.</p>
            <p>Language: Rust</p>
            <p>Stars: 19,050</p>
            <p>Forks: 717</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>[![Neon](https://github.com/neondatabase/neon/assets/11527560/f15a17f0-836e-40c5-b35d-030606a6b660)](https://neon.tech)



# Neon

Neon is a serverless open-source alternative to AWS Aurora Postgres. It separates storage and compute and substitutes the PostgreSQL storage layer by redistributing data across a cluster of nodes.

## Quick start
Try the [Neon Free Tier](https://neon.tech/github) to create a serverless Postgres instance. Then connect to it with your preferred Postgres client (psql, dbeaver, etc) or use the online [SQL Editor](https://neon.tech/docs/get-started-with-neon/query-with-neon-sql-editor/). See [Connect from any application](https://neon.tech/docs/connect/connect-from-any-app/) for connection instructions.

Alternatively, compile and run the project [locally](#running-local-installation).

## Architecture overview

A Neon installation consists of compute nodes and the Neon storage engine. Compute nodes are stateless PostgreSQL nodes backed by the Neon storage engine.

The Neon storage engine consists of two major components:
- Pageserver: Scalable storage backend for the compute nodes.
- Safekeepers: The safekeepers form a redundant WAL service that received WAL from the compute node, and stores it durably until it has been processed by the pageserver and uploaded to cloud storage.

See developer documentation in [SUMMARY.md](/docs/SUMMARY.md) for more information.

## Running a local development environment

Neon can be run on a workstation for small experiments and to test code changes, by
following these instructions.

#### Installing dependencies on Linux
1. Install build dependencies and other applicable packages

* On Ubuntu or Debian, this set of packages should be sufficient to build the code:
```bash
apt install build-essential libtool libreadline-dev zlib1g-dev flex bison libseccomp-dev \
libssl-dev clang pkg-config libpq-dev cmake postgresql-client protobuf-compiler \
libprotobuf-dev libcurl4-openssl-dev openssl python3-poetry lsof libicu-dev
```
* On Fedora, these packages are needed:
```bash
dnf install flex bison readline-devel zlib-devel openssl-devel \
  libseccomp-devel perl clang cmake postgresql postgresql-contrib protobuf-compiler \
  protobuf-devel libcurl-devel openssl poetry lsof libicu-devel libpq-devel python3-devel \
  libffi-devel
```
* On Arch based systems, these packages are needed:
```bash
pacman -S base-devel readline zlib libseccomp openssl clang \
postgresql-libs cmake postgresql protobuf curl lsof
```

Building Neon requires 3.15+ version of `protoc` (protobuf-compiler). If your distribution provides an older version, you can install a newer version from [here](https://github.com/protocolbuffers/protobuf/releases).

2. [Install Rust](https://www.rust-lang.org/tools/install)
```
# recommended approach from https://www.rust-lang.org/tools/install
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

#### Installing dependencies on macOS (12.3.1)
1. Install XCode and dependencies
```
xcode-select --install
brew install protobuf openssl flex bison icu4c pkg-config m4

# add openssl to PATH, required for ed25519 keys generation in neon_local
echo &#039;export PATH=&quot;$(brew --prefix openssl)/bin:$PATH&quot;&#039; &gt;&gt; ~/.zshrc
```

If you get errors about missing `m4` you may have to install it manually:
```
brew install m4
brew link --force m4
```

2. [Install Rust](https://www.rust-lang.org/tools/install)
```
# recommended approach from https://www.rust-lang.org/tools/install
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

3. Install PostgreSQL Client
```
# from https://stackoverflow.com/questions/44654216/correct-way-to-install-psql-without-full-postgres-on-macos
brew install libpq
brew link --force libpq
```

#### Rustc version

The project uses [rust toolchain file](./rust-toolchain.toml) to define the version it&#039;s built with in CI for testing and local builds.

This file is automatically picked up by [`rustup`](https://rust-lang.github.io/rustup/overrides.html#the-toolchain-file) that installs (if absent) and uses the toolchain version pinned in the file.

rustup users who want to build with another toolchain can use the [`rustup override`](https://rust-lang.github.io/rustup/overrides.html#directory-overrides) command to set a specific toolchain for the project&#039;s directory.

non-rustup users most probably are not getting the same toolchain automatically from the file, so are responsible to manually verify that their toolchain matches the version in the file.
Newer rustc versions most probably will work fine, yet older ones might not be supported due to some new features used by the project or the crates.

#### Building on Linux

1. Build neon and patched postgres
```
# Note: The path to the neon sources can not contain a space.

git clone --recursive https://github.com/neondatabase/neon.git
cd neon

# The preferred and default is to make a debug build. This will create a
# demonstrably slower build than a release build. For a release build,
# use &quot;BUILD_TYPE=release make -j`nproc` -s&quot;
# Remove -s for the verbose build log

make -j`nproc` -s
```

#### Building on OSX

1. Build neon and patched postgres
```
# Note: The path to the neon sources can not contain a space.

git clone --recursive https://github.com/neondatabase/neon.git
cd neon

# The preferred and default is to make a debug build. This will create a
# demonstrably slower build than a release build. For a release build,
# use &quot;BUILD_TYPE=release make -j`sysctl -n hw.logicalcpu` -s&quot;
# Remove -s for the verbose build log

make -j`sysctl -n hw.logicalcpu` -s
```

#### Dependency installation notes
To run the `psql` client, install the `postgresql-client` package or modify `PATH` and `LD_LIBRARY_PATH` to include `pg_install/bin` and `pg_install/lib`, respectively.

To run the integration tests or Python scripts (not required to use the code), install
Python (3.11 or higher), and install the python3 packages using `./scripts/pysync` (requires [poetry&gt;=1.8](https://python-poetry.org/)) in the project directory.


#### Running neon database
1. Start pageserver and postgres on top of it (should be called from repo root):
```sh
# Create repository in .neon with proper paths to binaries and data
# Later that would be responsibility of a package install script
&gt; cargo neon init
Initializing pageserver node 1 at &#039;127.0.0.1:64000&#039; in &quot;.neon&quot;

# start pageserver, safekeeper, and broker for their intercommunication
&gt; cargo neon start
Starting neon broker at 127.0.0.1:50051.
storage_broker started, pid: 2918372
Starting pageserver node 1 at &#039;127.0.0.1:64000&#039; in &quot;.neon&quot;.
pageserver started, pid: 2918386
Starting safekeeper at &#039;127.0.0.1:5454&#039; in &#039;.neon/safekeepers/sk1&#039;.
safekeeper 1 started, pid: 2918437

# create initial tenant and use it as a default for every future neon_local invocation
&gt; cargo neon tenant create --set-default
tenant 9ef87a5bf0d92544f6fafeeb3239695c successfully created on the pageserver
Created an initial timeline &#039;de200bd42b49cc1814412c7e592dd6e9&#039; at Lsn 0/16B5A50 for tenant: 9ef87a5bf0d92544f6fafeeb3239695c
Setting tenant 9ef87a5bf0d92544f6fafeeb3239695c as a default one

# create postgres compute node
&gt; cargo neon endpoint create main

# start postgres compute node
&gt; cargo neon endpoint start main
Starting new endpoint main (PostgreSQL v14) on timeline de200bd42b49cc1814412c7e592dd6e9 ...
Starting postgres at &#039;postgresql://cloud_admin@127.0.0.1:55432/postgres&#039;

# check list of running postgres instances
&gt; cargo neon endpoint list
 ENDPOINT  ADDRESS          TIMELINE                          BRANCH NAME  LSN        STATUS
 main      127.0.0.1:55432  de200bd42b49cc1814412c7e592dd6e9  main         0/16B5BA8  running
```

2. Now, it is possible to connect to postgres and run some queries:
```text
&gt; psql -p 55432 -h 127.0.0.1 -U cloud_admin postgres
postgres=# CREATE TABLE t(key int primary key, value text);
CREATE TABLE
postgres=# insert into t values(1,1);
INSERT 0 1
postgres=# select * from t;
 key | value
-----+-------
   1 | 1
(1 row)
```

3. And create branches and run postgres on them:
```sh
# create branch named migration_check
&gt; cargo neon timeline branch --branch-name migration_check
Created timeline &#039;b3b863fa45fa9e57e615f9f2d944e601&#039; at Lsn 0/16F9A00 for tenant: 9ef87a5bf0d92544f6fafeeb3239695c. Ancestor timeline: &#039;main&#039;

# check branches tree
&gt; cargo neon timeline list
(L) main [de200bd42b49cc1814412c7e592dd6e9]
(L) ‚îó‚îÅ @0/16F9A00: migration_check [b3b863fa45fa9e57e615f9f2d944e601]

# create postgres on that branch
&gt; cargo neon endpoint create migration_check --branch-name migration_check

# start postgres on that branch
&gt; cargo neon endpoint start migration_check
Starting new endpoint migration_check (PostgreSQL v14) on timeline b3b863fa45fa9e57e615f9f2d944e601 ...
Starting postgres at &#039;postgresql://cloud_admin@127.0.0.1:55434/postgres&#039;

# check the new list of running postgres instances
&gt; cargo neon endpoint list
 ENDPOINT         ADDRESS          TIMELINE                          BRANCH NAME      LSN        STATUS
 main             127.0.0.1:55432  de200bd42b49cc1814412c7e592dd6e9  main             0/16F9A38  running
 migration_check  127.0.0.1:55434  b3b863fa45fa9e57e615f9f2d944e601  migration_check  0/16F9A70  running

# this new postgres instance will have all the data from &#039;main&#039; postgres,
# but all modifications would not affect data in original postgres
&gt; psql -p 55434 -h 127.0.0.1 -U cloud_admin postgres
postgres=# select * from t;
 key | value
-----+-------
   1 | 1
(1 row)

postgres=# insert into t values(2,2);
INSERT 0 1

# check that the new change doesn&#039;t affect the &#039;main&#039; postgres
&gt; psql -p 55432 -h 127.0.0.1 -U cloud_admin postgres
postgres=# select * from t;
 key | value
-----+-------
   1 | 1
(1 row)
```

4. If you want to run tests afterwards (see below), you must stop all the running pageserver, safekeeper, and postgres instances
   you have just started. You can terminate them all with one command:
```sh
&gt; cargo neon stop
```

More advanced usages can be found at [Local Development Control Plane (`neon_local`))](./control_plane/README.md).

#### Handling build failures

If you encounter errors during setting up the initial tenant, it&#039;s best to stop everything (`cargo neon stop`) and remove the `.neon` directory. Then fix the problems, and start the setup again.

## Running tests

### Rust unit tests

We are using [`cargo-nextest`](https://nexte.st/) to run the tests in Github Workflows.
Some crates do not support running plain `cargo test` anymore, prefer `cargo nextest run` instead.
You can install `cargo-nextest` with `cargo install cargo-nextest`.

### Integration tests

Ensure your dependencies are installed as described [here](https://github.com/neondatabase/neon#dependency-installation-notes).

```sh
git clone --recursive https://github.com/neondatabase/neon.git

CARGO_BUILD_FLAGS=&quot;--features=testing&quot; make

./scripts/pytest
```

By default, this runs both debug and release modes, and all supported postgres versions. When
testing locally, it is convenient to run just one set of permutations, like this:

```sh
DEFAULT_PG_VERSION=17 BUILD_TYPE=release ./scripts/pytest
```

## Flamegraphs

You may find yourself in need of flamegraphs for software in this repository.
You can use [`flamegraph-rs`](https://github.com/flamegraph-rs/flamegraph) or the original [`flamegraph.pl`](https://github.com/brendangregg/FlameGraph). Your choice!

&gt;[!IMPORTANT]
&gt; If you&#039;re using `lld` or `mold`, you need the `--no-rosegment` linker argument.
&gt; It&#039;s a [general thing with Rust / lld / mold](https://crbug.com/919499#c16), not specific to this repository.
&gt; See [this PR for further instructions](https://github.com/neondatabase/neon/pull/6764).

## Cleanup

For cleaning up the source tree from build artifacts, run `make clean` in the source directory.

For removing every artifact from build and configure steps, run `make distclean`, and also consider removing the cargo binaries in the `target` directory, as well as the database in the `.neon` directory. Note that removing the `.neon` directory will remove your database, with all data in it. You have been warned!

## Documentation

[docs](/docs) Contains a top-level overview of all available markdown documentation.

- [sourcetree.md](/docs/sourcetree.md) contains overview of source tree layout.

To view your `rustdoc` documentation in a browser, try running `cargo doc --no-deps --open`

See also README files in some source directories, and `rustdoc` style documentation comments.

Other resources:

- [SELECT &#039;Hello, World&#039;](https://neon.tech/blog/hello-world/): Blog post by Nikita Shamgunov on the high level architecture
- [Architecture decisions in Neon](https://neon.tech/blog/architecture-decisions-in-neon/): Blog post by Heikki Linnakangas
- [Neon: Serverless PostgreSQL!](https://www.youtube.com/watch?v=rES0yzeERns): Presentation on storage system by Heikki Linnakangas in the CMU Database Group seminar series

### Postgres-specific terms

Due to Neon&#039;s very close relation with PostgreSQL internals, numerous specific terms are used.
The same applies to certain spelling: i.e. we use MB to denote 1024 * 1024 bytes, while MiB would be technically more correct, it&#039;s inconsistent with what PostgreSQL code and its documentation use.

To get more familiar with this aspect, refer to:

- [Neon glossary](/docs/glossary.md)
- [PostgreSQL glossary](https://www.postgresql.org/docs/14/glossary.html)
- Other PostgreSQL documentation and sources (Neon fork sources can be found [here](https://github.com/neondatabase/postgres))

## Join the development

- Read [CONTRIBUTING.md](/CONTRIBUTING.md) to learn about project code style and practices.
- To get familiar with a source tree layout, use [sourcetree.md](/docs/sourcetree.md).
- To learn more about PostgreSQL internals, check http://www.interdb.jp/pg/index.html
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[solana-labs/solana]]></title>
            <link>https://github.com/solana-labs/solana</link>
            <guid>https://github.com/solana-labs/solana</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:08 GMT</pubDate>
            <description><![CDATA[Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/solana-labs/solana">solana-labs/solana</a></h1>
            <p>Web-Scale Blockchain for fast, secure, scalable, decentralized apps and marketplaces.</p>
            <p>Language: Rust</p>
            <p>Stars: 14,234</p>
            <p>Forks: 4,990</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre># PLEASE READ: This repo is now a public archive

This repo still exists in archived form, feel free to fork any reference
implementations it still contains.

See Agave, the Solana validator implementation from Anza: https://github.com/anza-xyz/agave

---

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://solana.com&quot;&gt;
    &lt;img alt=&quot;Solana&quot; src=&quot;https://i.imgur.com/IKyzQ6T.png&quot; width=&quot;250&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

[![Solana crate](https://img.shields.io/crates/v/solana-core.svg)](https://crates.io/crates/solana-core)
[![Solana documentation](https://docs.rs/solana-core/badge.svg)](https://docs.rs/solana-core)
[![Build status](https://badge.buildkite.com/8cc350de251d61483db98bdfc895b9ea0ac8ffa4a32ee850ed.svg?branch=master)](https://buildkite.com/solana-labs/solana/builds?branch=master)
[![codecov](https://codecov.io/gh/solana-labs/solana/branch/master/graph/badge.svg)](https://codecov.io/gh/solana-labs/solana)

# Building

## **1. Install rustc, cargo and rustfmt.**

```bash
$ curl https://sh.rustup.rs -sSf | sh
$ source $HOME/.cargo/env
$ rustup component add rustfmt
```

When building the master branch, please make sure you are using the latest stable rust version by running:

```bash
$ rustup update
```

When building a specific release branch, you should check the rust version in `ci/rust-version.sh` and if necessary, install that version by running:

```bash
$ rustup install VERSION
```

Note that if this is not the latest rust version on your machine, cargo commands may require an [override](https://rust-lang.github.io/rustup/overrides.html) in order to use the correct version.

On Linux systems you may need to install libssl-dev, pkg-config, zlib1g-dev, protobuf etc.

On Ubuntu:

```bash
$ sudo apt-get update
$ sudo apt-get install libssl-dev libudev-dev pkg-config zlib1g-dev llvm clang cmake make libprotobuf-dev protobuf-compiler
```

On Fedora:

```bash
$ sudo dnf install openssl-devel systemd-devel pkg-config zlib-devel llvm clang cmake make protobuf-devel protobuf-compiler perl-core
```

## **2. Download the source code.**

```bash
$ git clone https://github.com/solana-labs/solana.git
$ cd solana
```

## **3. Build.**

```bash
$ ./cargo build
```

# Testing

**Run the test suite:**

```bash
$ ./cargo test
```

### Starting a local testnet

Start your own testnet locally, instructions are in the [online docs](https://docs.solanalabs.com/clusters/benchmark).

### Accessing the remote development cluster

- `devnet` - stable public cluster for development accessible via
  devnet.solana.com. Runs 24/7. Learn more about the [public clusters](https://docs.solanalabs.com/clusters)

# Benchmarking

First, install the nightly build of rustc. `cargo bench` requires the use of the
unstable features only available in the nightly build.

```bash
$ rustup install nightly
```

Run the benchmarks:

```bash
$ cargo +nightly bench
```

# Release Process

The release process for this project is described [here](RELEASE.md).

# Code coverage

To generate code coverage statistics:

```bash
$ scripts/coverage.sh
$ open target/cov/lcov-local/index.html
```

Why coverage? While most see coverage as a code quality metric, we see it primarily as a developer
productivity metric. When a developer makes a change to the codebase, presumably it&#039;s a _solution_ to
some problem. Our unit-test suite is how we encode the set of _problems_ the codebase solves. Running
the test suite should indicate that your change didn&#039;t _infringe_ on anyone else&#039;s solutions. Adding a
test _protects_ your solution from future changes. Say you don&#039;t understand why a line of code exists,
try deleting it and running the unit-tests. The nearest test failure should tell you what problem
was solved by that code. If no test fails, go ahead and submit a Pull Request that asks, &quot;what
problem is solved by this code?&quot; On the other hand, if a test does fail and you can think of a
better way to solve the same problem, a Pull Request with your solution would most certainly be
welcome! Likewise, if rewriting a test can better communicate what code it&#039;s protecting, please
send us that patch!

# Disclaimer

All claims, content, designs, algorithms, estimates, roadmaps,
specifications, and performance measurements described in this project
are done with the Solana Labs, Inc. (‚ÄúSL‚Äù) good faith efforts. It is up to
the reader to check and validate their accuracy and truthfulness.
Furthermore, nothing in this project constitutes a solicitation for
investment.

Any content produced by SL or developer resources that SL provides are
for educational and inspirational purposes only. SL does not encourage,
induce or sanction the deployment, integration or use of any such
applications (including the code comprising the Solana blockchain
protocol) in violation of applicable laws or regulations and hereby
prohibits any such deployment, integration or use. This includes the use of
any such applications by the reader (a) in violation of export control
or sanctions laws of the United States or any other applicable
jurisdiction, (b) if the reader is located in or ordinarily resident in
a country or territory subject to comprehensive sanctions administered
by the U.S. Office of Foreign Assets Control (OFAC), or (c) if the
reader is or is working on behalf of a Specially Designated National
(SDN) or a person subject to similar blocking or denied party
prohibitions.

The reader should be aware that U.S. export control and sanctions laws prohibit
U.S. persons (and other persons that are subject to such laws) from transacting
with persons in certain countries and territories or that are on the SDN list.
Accordingly, there is a risk to individuals that other persons using any of the
code contained in this repo, or a derivation thereof, may be sanctioned persons
and that transactions with such persons would be a violation of U.S. export
controls and sanctions law.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[EricLBuehler/mistral.rs]]></title>
            <link>https://github.com/EricLBuehler/mistral.rs</link>
            <guid>https://github.com/EricLBuehler/mistral.rs</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:07 GMT</pubDate>
            <description><![CDATA[Blazingly fast LLM inference.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EricLBuehler/mistral.rs">EricLBuehler/mistral.rs</a></h1>
            <p>Blazingly fast LLM inference.</p>
            <p>Language: Rust</p>
            <p>Stars: 5,880</p>
            <p>Forks: 431</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;top&quot;&gt;&lt;/a&gt;
&lt;h1 align=&quot;center&quot;&gt;
  mistral.rs
&lt;/h1&gt;

&lt;h3 align=&quot;center&quot;&gt;
Blazingly fast LLM inference.
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
| &lt;a href=&quot;https://ericlbuehler.github.io/mistral.rs/mistralrs/&quot;&gt;&lt;b&gt;Rust Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://github.com/EricLBuehler/mistral.rs/blob/master/mistralrs-pyo3/API.md&quot;&gt;&lt;b&gt;Python Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://discord.gg/SZrecqK8qw&quot;&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://matrix.to/#/#mistral.rs:matrix.org&quot;&gt;&lt;b&gt;Matrix&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/EricLBuehler/mistral.rs/stargazers&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/EricLBuehler/mistral.rs?style=social&amp;label=Star&quot; alt=&quot;GitHub stars&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

**Mistral.rs is a cross-platform, highly-multimodal inference engine that brings you:**
- All-in-one multimodal workflow: text‚Üîtext, text+vision‚Üîtext, text+vision+audio‚Üîtext, text‚Üíspeech, text‚Üíimage
- APIs: Rust, Python, OpenAI HTTP server, MCP server
- üîó **MCP Client**: Connect to external tools and services automatically (file systems, web search, databases, APIs)
- Performance: ISQ, PagedAttention, FlashAttention

Please submit requests for new models [here](https://github.com/EricLBuehler/mistral.rs/issues/156).

## Get started fast üöÄ

1) [Install](#installation-and-build)

2) [Get models](#getting-models)

3) Deploy with our easy to use APIs
    - [Python](examples/python)
    - [Rust](mistralrs/examples)
    - [OpenAI-compatible HTTP server](README.md#openai-http-server)
    - [Interactive mode](README.md#interactive-mode)
    - üîó [**MCP Client**](examples/MCP_QUICK_START.md) - Connect to external tools automatically

4) Try the **web chat app** for local in-browser conversation (text, vision, and speech support):
    - Quickstart [here](mistralrs-web-chat/README.md)
    - Run the server and visit [http://localhost:8080](http://localhost:8080) by default.

&lt;br&gt;

&lt;!-- Web Chat App --&gt;
&lt;details open&gt;
  &lt;summary&gt;üñ•Ô∏è &lt;strong&gt;Web Chat App&lt;/strong&gt;&lt;/summary&gt;
  &lt;br&gt;
  &lt;img src=&quot;./res/chat.gif&quot; alt=&quot;Web Chat UI Demo&quot; /&gt;
  &lt;br&gt;
  Try our modern in-browser chat with text, vision, and speech support (TTS generation).
&lt;/details&gt;

&lt;!-- Interactive Mode --&gt;
&lt;details&gt;
  &lt;summary&gt;üíª &lt;strong&gt;Terminal Interactive Mode&lt;/strong&gt;&lt;/summary&gt;
  &lt;br&gt;
  &lt;img src=&quot;./res/demo.gif&quot; alt=&quot;Terminal Interactive Mode&quot; /&gt;
  &lt;br&gt;
  Prefer the terminal? Use interactive mode for a classic CLI experience.
&lt;/details&gt;

&lt;br&gt;

## Quick examples

*After following installation instructions*

- üíéü™Üüíéü™Üüíé Run the **Gemma 3n** family (E2B, E4B) with **vision**, **audio**, and **MatFormer** support: [documentation](docs/GEMMA3N.md)  
  &lt;details&gt;
    &lt;summary&gt;Show commands&lt;/summary&gt;

    **Normal use, run the full model (E4B or E2B):**
    ```bash
    ./mistralrs-server -i --isq 8 run -m google/gemma-3n-E4B-it
    ```

    **Use [MatFormer](docs/GEMMA3N.md#using-matformer-with-gemma-3n) to get a balanced smaller model:**
    ```bash
    ./mistralrs-server -i --isq 8 run -m google/gemma-3n-E4B-it \
      --matformer-config-path matformer_configs/gemma3n.csv \
      --matformer-slice-name &quot;Config for E2.49B (block-level)&quot;
    ```
  &lt;/details&gt;
  

- ü§óü§óü§ó Run the **SmolLM 3** long-context hybrid-reasoning model with full tool-calling support: [documentation](docs/SMOLLM3.md)  
  &lt;details&gt;
    &lt;summary&gt;Show command&lt;/summary&gt;

    **Default, easiest:**
    ```bash
    ./mistralrs-server -i --isq 8 run -m HuggingFaceTB/SmolLM3-3B
    ```

    **UQFF prequantized:**
    ```bash
    ./mistralrs-server -i run -m EricB/SmolLM3-3B-UQFF -f smollm33b-q4k-0.uqff
    ```
  &lt;/details&gt;

- üîä Run the **Dia 1.6b** model for highly-realistic dialogue generation: [documentation](docs/DIA.md)  
  &lt;details&gt;
    &lt;summary&gt;Show command&lt;/summary&gt;

    ```bash
    ./mistralrs-server -i speech -m nari-labs/Dia-1.6B -a dia
    ```
  &lt;/details&gt;

- ü¶ô Run the **Llama 3.\* and Llama 4** models with long context &amp; vision support: [docs (llama 3.2)](docs/VLLAMA.md), [docs (llama 4)](docs/LLAMA4.md)  
  &lt;details&gt;
    &lt;summary&gt;Show commands&lt;/summary&gt;

    **Llama 4:**

    ```bash
    ./mistralrs-server -i --isq 4 run -m meta-llama/Llama-4-Scout-17B-16E-Instruct
    ```

    **Llama 3.1/3.2/3.3:**

    ```
    ./mistralrs-server -i --isq 8 run -m meta-llama/Llama-3.2-3B-Instruct
    ```

    **Llama 3.2 vision:**

    ```
    ./mistralrs-server -i --isq 8 run -m meta-llama/Llama-3.2-11B-Vision-Instruct
    ```

  &lt;/details&gt;

- üíéüíéüíé Run the **Gemma 3** family (1b, 4b, 12b, 27b) with 128k context &amp; vision support: [documentation](docs/GEMMA3.md)  
  &lt;details&gt;
    &lt;summary&gt;Show command&lt;/summary&gt;

    ```bash
    ./mistralrs-server -i --isq 8 run -m google/gemma-3-4b-it
    ```
  &lt;/details&gt;

- üå≤üì∑ Run the **FLUX.1** diffusion model: [documentation](docs/FLUX.md)  
  &lt;details&gt;
    &lt;summary&gt;Show command&lt;/summary&gt;

    ```bash
    ./mistralrs-server -i diffusion -m black-forest-labs/FLUX.1-schnell -a flux
    ```
  &lt;/details&gt;

- üß† Run the **Qwen 3** hybrid-reasoning model with full tool-calling support: [documentation](docs/QWEN3.md)  
  &lt;details&gt;
    &lt;summary&gt;Show command&lt;/summary&gt;

    ```bash
    ./mistralrs-server -i --isq 8 run -m Qwen/Qwen3-8B
    ```
  &lt;/details&gt;

- üîó **MCP Client** - Connect to external tools and services automatically: [**Quick Start Guide**](examples/MCP_QUICK_START.md)  
  &lt;details&gt;
    &lt;summary&gt;Show examples&lt;/summary&gt;

    **1. Create config file (`mcp-config.json`):**
    ```json
    {
      &quot;servers&quot;: [{
        &quot;name&quot;: &quot;Filesystem Tools&quot;,
        &quot;source&quot;: {
          &quot;type&quot;: &quot;Process&quot;,
          &quot;command&quot;: &quot;npx&quot;,
          &quot;args&quot;: [&quot;@modelcontextprotocol/server-filesystem&quot;, &quot;/tmp&quot;, &quot;-y&quot;]
        }
      }],
      &quot;auto_register_tools&quot;: true
    }
    ```

    **2. Start server with tools:**
    ```bash
    ./mistralrs-server --mcp-config mcp-config.json --port 1234 run -m Qwen/Qwen3-4B
    ```
    
    **3. Tools work automatically:**
    ```bash
    curl -X POST http://localhost:1234/v1/chat/completions \
      -d &#039;{&quot;model&quot;:&quot;Qwen/Qwen3-4B&quot;,&quot;messages&quot;:[{&quot;role&quot;:&quot;user&quot;,&quot;content&quot;:&quot;List files in /tmp and create hello.txt&quot;}]}&#039;
    ```

    **Python API:**
    ```python
    mcp_config = mistralrs.McpClientConfigPy(
        servers=[mistralrs.McpServerConfigPy(
            name=&quot;Filesystem&quot;,
            source=mistralrs.McpServerSourcePy.Process(
                command=&quot;npx&quot;, 
                args=[&quot;@modelcontextprotocol/server-filesystem&quot;, &quot;/tmp&quot;, &quot;-y&quot;]
            )
        )],
        auto_register_tools=True
    )
    
    runner = mistralrs.Runner(
        which=mistralrs.Which.Plain(model_id=&quot;Qwen/Qwen3-4B&quot;),
        mcp_client_config=mcp_config
    )
    # Tools automatically available!
    ```

    **Rust API:**
    ```rust
    let model = TextModelBuilder::new(&quot;Qwen/Qwen3-4B&quot;)
        .with_mcp_client(mcp_config) // Tools automatically available!
        .build().await?;
    ```
  &lt;/details&gt;

## Description

[mistral.rs](https://github.com/EricLBuehler/mistral.rs) is a blazing-fast, cross-platform LLM inference engine with support for text, vision, image generation, and speech.

**Key Benefits:**

1. **Ease of Use**
   - [OpenAI-compatible HTTP server](docs/HTTP.md)
   - [Rust API](https://ericlbuehler.github.io/mistral.rs/mistralrs/) &amp; [Python API](mistralrs-pyo3/API.md)
   - [Automatic device mapping](docs/DEVICE_MAPPING.md) (multi-GPU, CPU)
   - [Chat templates](docs/CHAT_TOK.md) &amp; tokenizer auto-detection
   - [MCP server](docs/MCP/server.md) for structured, realtime tool calls
   - ‚≠ê [MCP client](examples/MCP_QUICK_START.md) to connect to external tools and services automatically

2. **Performance**
   - CPU acceleration (MKL, AVX, NEON, Accelerate)
   - GPU acceleration (CUDA with [FlashAttention](docs/FLASH_ATTENTION.md) &amp; cuDNN, Metal)
   - Automatic [tensor parallelism](docs/DISTRIBUTED/DISTRIBUTED.md) for splitting models across multiple devices
     - CUDA-specialized [NCCL](docs/DISTRIBUTED/NCCL.md)
     - Heterogeneous, flexible [Ring backend](docs/DISTRIBUTED/RING.md)

3. **Quantization**
   - [In-place quantization (ISQ)](docs/ISQ.md) of Hugging Face models
   - [GGML &amp; GGUF support](docs/QUANTS.md): 2‚Äì8 bit
   - [GPTQ](docs/QUANTS.md), [AWQ](scripts/convert_awq_marlin.py), [AFQ](docs/QUANTS.md), [HQQ](docs/QUANTS.md), [FP8](docs/QUANTS.md), [BNB](https://github.com/TimDettmers/bitsandbytes) (int8/fp4/nf4)
   - ‚≠ê Auto-select the fastest quant method
   - [KV cache quantization](docs/PAGED_ATTENTION.md#kv-cache-quantization)

4. **Flexibility**
   - [LoRA](docs/ADAPTER_MODELS.md) &amp; [X-LoRA](docs/ADAPTER_MODELS.md) adapters with weight merging
   - [AnyMoE](docs/ANYMOE.md): create MoE models on any base model
   - [Sampling &amp; penalty options](docs/SAMPLING.md)
   - Prompt chunking for large inputs
   - Integrated [tool calling](docs/TOOL_CALLING.md) with customizable Python/Rust native tool and search callbacks

5. **Advanced Features**
   - High-throughput with [PagedAttention](docs/PAGED_ATTENTION.md) &amp; FlashAttention V2/V3
   - Prefix caching (including multimodal)
   - Customizable quantization with [topology](docs/TOPOLOGY.md) &amp; [UQFF format](docs/UQFF.md)
   - Speculative decoding across models
   - ‚≠ê Agentic [web search integration](docs/WEB_SEARCH.md)

## APIs and Integrations

### Rust Crate

Rust multithreaded/async API for easy integration into any application.

- [Docs](https://ericlbuehler.github.io/mistral.rs/mistralrs/)
- [Examples](mistralrs/examples/) including [MCP client integration](mistralrs/examples/mcp_client)
- To use: add `mistralrs = { git = &quot;https://github.com/EricLBuehler/mistral.rs.git&quot; }` to your Cargo.toml
- **MCP Client**: Connect to external tools automatically - [Quick Start](examples/MCP_QUICK_START.md)

### Python API

Python API for mistral.rs.

- [Installation including PyPI](mistralrs-pyo3/_README.md)
- [Docs](mistralrs-pyo3/API.md)
- [Examples](examples/python) including [MCP client usage](examples/python/mcp_client.py)
- [Cookbook](examples/python/cookbook.ipynb)
- **MCP Client**: Full MCP integration - [Quick Start](examples/MCP_QUICK_START.md)

### HTTP Server

OpenAI API compatible API server

- [API Docs](docs/HTTP.md)
- [Launching the server or use the CLI](README.md#using-the-cli)
- [Example](examples/server/chat.py)
- [Use or extend the server in other axum projects](https://ericlbuehler.github.io/mistral.rs/mistralrs_server_core/)
- **MCP Client**: Configure via `--mcp-config` flag for automatic tool integration - [Quick Start](examples/MCP_QUICK_START.md)

### MCP Protocol

Serve the same models over the open [MCP](docs/mcp/server.md) (Model Context Protocol) in parallel to the HTTP API:

```bash
./mistralrs-server --mcp-port 4321 plain -m Qwen/Qwen3-4B
```

See the [docs](docs/mcp/server.md) for feature flags, examples and limitations.


### Llama Index integration

- Docs: https://docs.llamaindex.ai/en/stable/examples/llm/mistral_rs/

---

## Supported accelerators

| Accelerator              | Feature Flag  | Additional Flags       |
|--------------------------|---------------|------------------------|
| NVIDIA GPUs (CUDA)       | `cuda`        | `flash-attn`, `flash-attn-v3`, `cudnn`  |
| Apple Silicon GPU (Metal)| `metal`       |                        |
| CPU (Intel)              | `mkl`         |                        |
| CPU (Apple Accelerate)   | `accelerate`  |                        |
| Generic CPU (ARM/AVX)    | _none_        | ARM NEON / AVX enabled by default |

To enable one or more features, pass them to Cargo. For example:

```bash
cargo build --release --features &quot;cuda flash-attn cudnn&quot;
```

&gt; **Note for Linux users:** The `metal` feature is macOS-only and should not be used on Linux. Use `--features &quot;cuda flash-attn cudnn&quot;` for NVIDIA GPUs or `--features mkl` for Intel CPUs instead of `--all-features`.

## Installation and Build

&gt; Note: You can use our [Docker containers here](https://github.com/EricLBuehler/mistral.rs/pkgs/container/mistral.rs).
&gt; Learn more about running Docker containers: https://docs.docker.com/engine/reference/run/

- Install the [Python package here](mistralrs-pyo3/_README.md).
- The Python package has [wheels on PyPi](mistralrs-pyo3/_README.md#installation-from-pypi)!

1) Install required packages:
    - `OpenSSL` (*Example on Ubuntu:* `sudo apt install libssl-dev`)
    - &lt;b&gt;*Linux only:*&lt;/b&gt; `pkg-config` (*Example on Ubuntu:* `sudo apt install pkg-config`)

2) Install Rust: https://rustup.rs/

    *Example on Ubuntu:*
    ```bash
    curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
    source $HOME/.cargo/env
    ```

3) &lt;b&gt;*Optional:*&lt;/b&gt; Set HF token correctly (skip if already set or your model is not gated, or if you want to use the `token_source` parameters in Python or the command line.)
    - Note: you can install `huggingface-cli` as documented [here](https://huggingface.co/docs/huggingface_hub/en/installation). 
    ```bash
    huggingface-cli login
    ```

4) Download the code:
    ```bash
    git clone https://github.com/EricLBuehler/mistral.rs.git
    cd mistral.rs
    ```

5) Build or install `mistralrs-server`:
    - Build the `mistralrs-server` binary, which can be found at `target/release/mistralrs-server`.
        ```bash
        cargo build --release --features &lt;specify feature(s) here&gt;
        ```
    - Install with `cargo install` for easy command line usage

        Pass the same values to `--features` as you would for `cargo build`
        ```bash
        cargo install --path mistralrs-server --features &lt;specify feature(s) here&gt;
        ```

6) (*If you used `cargo build`*) The build process will output a binary `mistralrs-server` at `./target/release/mistralrs-server`. We can switch to that directory so that the binary can be accessed as `./mistralrs-server` with the following command:

    *Example on Ubuntu:*
    ```
    cd target/release
    ```

7) Use our APIs and integrations: 
    
    [APIs and integrations list](#apis-and-integrations)

## Getting models
&lt;details&gt;
&lt;summary&gt;Show: How to get models (Hub, local, GGUF, adapters, etc.)&lt;/summary&gt;

### Getting models from Hugging Face Hub
- **Default:** Downloads from Hugging Face Hub.
- For gated models, you can optionally set token source:
    - CLI: `./mistralrs-server --token-source env:HF_TOKEN ...`
    - Python: See [examples/python/token_source.py](examples/python/token_source.py)
    - If no token is found, tries `~/.cache/huggingface/token` or runs with no token.

### Loading models from local files
- Pass a path to a downloaded model from Hugging Face hub:
    - Example:  
      ```
      ./mistralrs-server -i run -m path/to/model
      ```

### Running GGUF models
- Minimal example:
  ```
  ./mistralrs-server gguf -m author/model-repo -f model-quant.gguf
  ```
- Specify tokenizer (if needed):
  ```
  ./mistralrs-server gguf -m author/model-repo -f file.gguf -t author/official-tokenizer
  ```
  (Or use the built-in GGUF tokenizer.)

### Adapters, X-LoRA, LoRA, Chat Templates
- Use the correct subcommand (`x-lora-*`, `lora-*`), pass model, adapter, or quant file as needed.
- See [docs/ADAPTER_MODELS.md](docs/ADAPTER_MODELS.md) for details.
- For chat templates: usually auto-detected, override with `--chat-template &lt;file&gt;`.  
  See [docs/CHAT_TOK.md](docs/CHAT_TOK.md).

### More model CLI examples
- See [Run with the CLI](#run-with-the-cli) below or [full documentation](docs/README.md).

&lt;/details&gt;

## Using the CLI

Mistral.rs uses subcommands to control the model type. Please run `./mistralrs-server --help` to see the subcommands which categorize the models by kind.

&gt; **üö® Important:** The `run` subcommand (alias for `plain`/`vision-plain`) only auto-detects and runs **text** and **vision** models. It does **not** support **diffusion** or **speech** models. 
&gt; To run a diffusion model (e.g. FLUX series), use the `diffusion` subcommand:
&gt; ```bash
&gt; mistralrs-server -i diffusion -m &lt;model-id&gt; [options]
&gt; ```
&gt; To run a speech model (e.g. Dia), use the `speech` subcommand:
&gt; ```bash
&gt; mistralrs-server -i speech -m &lt;model-id&gt; [options]
&gt; ```
&gt; If you attempt to use `run` with diffusion or speech models, model loading will fail.

### Interactive mode

**Llama 3.2 3B running on an M3 Max with 8-bit ISQ:**

&lt;img src=&quot;./res/demo.gif&quot; alt=&quot;Interactive demo&quot; /&gt;

You can launch interactive mode, a simple chat application running in the terminal, by passing `-i`:

```bash
./mistralrs-server -i plain -m meta-llama/Llama-3.2-3B-Instruct
```

Vision models work seamlessly:

```bash
./mistralrs-server -i vision-plain -m lamm-mit/Cephalo-Llama-3.2-11B-Vision-Instruct-128k
```

Diffusion models can be run too (quantization and adapters are not yet supported):

```bash
./mistralrs-server -i diffusion -m black-forest-labs/FLUX.1-schnell -a flux
```

And you can run speech generation in your terminal!

```bash
./mistralrs-server -i speech -m nari-labs/Dia-1.6B -a dia
```

### OpenAI HTTP server

You can launch an HTTP server by replacing `-i` with `--port &lt;port&gt;`. For instance:

```bash
./mistralrs-server --port 1234 run -m microsoft/Phi-3.5-MoE-instruct
```

You can find documentation about the server itself [here](docs/HTTP.md).

### Multi-model support

Serve multiple models simultaneously from a single server instance. Perfect for comparing models, A/B testing, or serving different models for different use cases.

```bash
./mistralrs-server --port 1234 multi-model --config example-multi-model-config.json --default-model-id meta-llama/Llama-3.2-3B-Instruct
```

Select models in your requests using the `model` parameter:
```bash
curl http://localhost:1234/v1/chat/completions \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{&quot;model&quot;: &quot;meta-llama/Llama-3.2-3B-Instruct&quot;, &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]}&#039;
```

üìñ **[Complete multi-model documentation ‚Üí](docs/multi_model/README.md)**

### Structured selection with a `.toml` file

We provide a method to select models with a `.toml` file. The keys are the same as the command line, with `no_kv_cache` and `tokenizer_json` being &quot;global&quot; keys.

Example:
```bash
./mistralrs-server --port 1234 toml -f toml-selectors/gguf.toml
```

### Architecture for plain models

&gt; Note: for plain models, you can specify the data type to load and run in. This must be one of `f32`, `f16`, `bf16` or `auto` to choose based on the device. This is specified in the `--dype`/`-d` parameter after the model architecture (`plain`). For quantized models (gguf/ggml), you may specify data type of `f32` or `bf16` (`f16` is not recommended due to its lower precision in quantized inference).

If you do not specify the architecture, an attempt will be made to use the model&#039;s config. If this fails, please raise an issue.

&lt;details&gt;
  &lt;summary&gt;Show plain architectures&lt;/summary&gt;

- `mistral`
- `gemma`
- `mixtral`
- `llama`
- `phi2`
- `phi3`
- `phi3.5moe`
- `qwen2`
- `gemma2`
- `glm4`
- `starcoder2`
- `deepseekv2`
- `deepseekv3`
- `qwen3`
- `qwen3moe`
- `smollm3`

&lt;/details&gt;

### Architecture for vision models

&gt; Note: for vision models, you can specify the data type to load and run in. This must be one of `f32`, `f16`, `bf16` or `auto` to choose based on the device. This is specified in the `--dype`/`-d` parameter after the model architecture (`vision-plain`).

&lt;details&gt;
  &lt;summary&gt;Show vision architectures&lt;/summary&gt;

- `phi3v`
- `idefics2`
- `llava_next`
- `llava`
- `vllama`
- `qwen2vl`
- `idefics3`
- `minicpmo`
- `phi4mm`
- `qwen2_5vl`
- `gemma3`
- `mistral3`
- `llama4`
- `gemma3n`

&lt;/details&gt;

### Supported GGUF architectures

&lt;details&gt;
  &lt;summary&gt;Show supported GGUF architectures&lt;/summary&gt;

**Plain:**
- llama
- phi2
- phi3
- starcoder2
- qwen2
- qwen3

**With adapters:**
- llama
- phi3

&lt;/details&gt;

---

Please submit more benchmarks via raising an issue!

## Supported models

&lt;details&gt;
&lt;summary&gt;Show quantization support&lt;/summary&gt;

**Quantization support**
|Model|GGUF|GGML|ISQ|
|--|--|--|--|
|Mistral|‚úÖ| |‚úÖ|
|Gemma| | |‚úÖ|
|Llama|‚úÖ|‚úÖ|‚úÖ|
|Mixtral|‚úÖ| |‚úÖ|
|Phi 2|‚úÖ| |‚úÖ|
|Phi 3|‚úÖ| |‚úÖ|
|Phi 3.5 MoE| | |‚úÖ|
|Qwen 2.5| | |‚úÖ|
|Phi 3 Vision| | |‚úÖ|
|Idefics 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nexus-xyz/nexus-cli]]></title>
            <link>https://github.com/nexus-xyz/nexus-cli</link>
            <guid>https://github.com/nexus-xyz/nexus-cli</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:06 GMT</pubDate>
            <description><![CDATA[Command line interface for supplying proofs to the Nexus network.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nexus-xyz/nexus-cli">nexus-xyz/nexus-cli</a></h1>
            <p>Command line interface for supplying proofs to the Nexus network.</p>
            <p>Language: Rust</p>
            <p>Stars: 858</p>
            <p>Forks: 420</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>[![Release](https://img.shields.io/github/v/release/nexus-xyz/nexus-cli.svg)](https://github.com/nexus-xyz/nexus-cli/releases)
[![CI](https://github.com/nexus-xyz/nexus-cli/actions/workflows/ci.yml/badge.svg)](https://github.com/nexus-xyz/nexus-cli/actions)
[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](https://github.com/nexus-xyz/nexus-cli/blob/main/LICENSE-APACHE)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](https://github.com/nexus-xyz/nexus-cli/blob/main/LICENSE-MIT)
[![Twitter](https://img.shields.io/twitter/follow/NexusLabs)](https://x.com/NexusLabs)
[![Discord](https://img.shields.io/badge/Discord-Join-7289da.svg?logo=discord&amp;logoColor=white)](https://discord.com/invite/nexus-xyz)

# Nexus CLI

A high-performance command-line interface for contributing proofs to the Nexus network.

&lt;figure&gt;
    &lt;a href=&quot;https://beta.nexus.xyz/&quot;&gt;
        &lt;img src=&quot;assets/images/nexus-network-image.png&quot; alt=&quot;Nexus Network visualization showing a distributed network of interconnected nodes with a &#039;Launch Network&#039; button in the center&quot;&gt;
    &lt;/a&gt;
    &lt;figcaption&gt;
        &lt;strong&gt;Verifiable Computation on a Global Scale&lt;/strong&gt;&lt;br&gt;
        We&#039;re building a global distributed prover network to unite the world&#039;s computers and power a new and better Internet: the Verifiable Internet. Connect to the beta and give it a try today.
    &lt;/figcaption&gt;
&lt;/figure&gt;

## Nexus Network

[Nexus](https://nexus.xyz/) is a global distributed prover network that unites the world&#039;s computers to power a new and
better Internet: the Verifiable Internet.

There have been several testnets so far:

- Testnet 0: [October 8 ‚Äì 28, 2024](https://blog.nexus.xyz/nexus-launches-worlds-first-open-prover-network/)
- Testnet I: [December 9 ‚Äì 13, 2024](https://blog.nexus.xyz/the-new-nexus-testnet-is-live/)
- Testnet II: [February 18 ‚Äì 22, 2025](https://blog.nexus.xyz/testnet-ii-is-open/)
- Devnet: February 22 - June 20 2025
- Testnet III: [Ongoing](https://blog.nexus.xyz/live-everywhere/)

---

## Quick Start

### Installation

#### Precompiled Binary (Recommended)

For the simplest and most reliable installation:

```bash
curl https://cli.nexus.xyz/ | sh
```

This will:
1. Download and install the latest precompiled binary for your platform.
2. Prompt you to accept the Terms of Use.
3. Start the CLI in interactive mode.

The exact installation script is viewable [here](./public/install.sh).

#### Non-Interactive Installation

For automated installations (e.g., in CI):

```bash
curl -sSf https://cli.nexus.xyz/ -o install.sh
chmod +x install.sh
NONINTERACTIVE=1 ./install.sh
```

### Proving

Proving with the CLI is documented [here](https://docs.nexus.xyz/layer-1/testnet/cli-node).

To start with an existing node ID, run:

```bash
nexus-cli start --node-id &lt;your-node-id&gt;
```

Alternatively, you can register your wallet address and create a node ID with the CLI, or at [app.nexus.xyz](https://app.nexus.xyz).

```bash
nexus-cli register-user --wallet-address &lt;your-wallet-address&gt;
nexus-cli register-node
nexus-cli start
```

The `register-user` and `register-node` commands will save your credentials to `~/.nexus/config.json`. To clear credentials, run:

```bash
nexus-cli logout
```

For troubleshooting or to see available command line options, run:

```bash
nexus-cli --help
```

### Use Docker
Make sure docker and docker compose have been installed on you machine. check documentation here:
- [Install Docker](https://docs.docker.com/engine/install/)
- [Install Docker Compose](https://docs.docker.com/compose/install/)

Then, modify the node id in the `docker-compose.yaml` file, run:

```bash
docker compose build --no-cache
docker compose up -d
```

Check log

```bash
docker compose logs
```

If you want to shut down, run:

```bash
docker compose down
```

---

## Terms of Use

Use of the CLI is subject to the [Terms of Use](https://nexus.xyz/terms-of-use).
First-time users running interactively will be prompted to accept these terms.

---

## Node ID

During the CLI&#039;s startup, you&#039;ll be asked for your node ID. To skip prompts in a
non-interactive environment, manually create a `~/.nexus/config.json` in the
following format:

```json
{
   &quot;node_id&quot;: &quot;&lt;YOUR NODE ID&gt;&quot;
}
```

---

## Current Limitations

- To submit programs to the network for proving, contact
  [growth@nexus.xyz](mailto:growth@nexus.xyz).

---

## Get Help

- [Network FAQ](https://docs.nexus.xyz/layer-1/network-devnet/faq)
- [Discord Community](https://discord.gg/nexus-xyz)
- Technical issues? [Open an issue](https://github.com/nexus-xyz/nexus-cli/issues)

---

## Contributing

Interested in contributing to the Nexus Network CLI? Check out our
[Contributor Guide](./CONTRIBUTING.md) for:

- Development setup instructions
- How to report issues and submit pull requests
- Our code of conduct and community guidelines
- Tips for working with the codebase

For most users, we recommend using the precompiled binaries as described above.
The contributor guide is intended for those who want to modify or improve the CLI
itself.

### üõ†  Developer Guide

The following steps may be required in order to setup a development environment for contributing to the project:

#### Linux

```bash
sudo apt update
sudo apt upgrade
sudo apt install build-essential pkg-config libssl-dev git-all
sudo apt install protobuf-compiler
```

#### macOS

```bash
# Install using Homebrew
brew install protobuf

# Verify installation
protoc --version
```

#### Windows

[Install WSL](https://learn.microsoft.com/en-us/windows/wsl/install),
then see Linux instructions above.

```bash
# Install using Chocolatey
choco install protobuf
```

### Building ProtoBuf files

To build the ProtoBuf files, run the following command in the `clients/cli` directory:

```bash
cargo build --features build_proto
```

### Creating a Release

To create a release, update the package version in `Cargo.toml`, then create and push a new (annotated) tag, e.g.:

```bash
git tag -a v0.1.2 -m &quot;Release v0.1.2&quot;
git push origin v0.1.2
```

This will trigger the GitHub Actions release workflow that compiles binaries and pushes the Docker image, in
addition to creating release.

**WARNING**: Creating a release through the GitHub UI creates a new release but does **NOT** trigger
the workflow. This leads to a release without a Docker image or binaries, which breaks the installation script.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lapce/lapce]]></title>
            <link>https://github.com/lapce/lapce</link>
            <guid>https://github.com/lapce/lapce</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:05 GMT</pubDate>
            <description><![CDATA[Lightning-fast and Powerful Code Editor written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lapce/lapce">lapce/lapce</a></h1>
            <p>Lightning-fast and Powerful Code Editor written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 36,635</p>
            <p>Forks: 1,147</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://lapce.dev&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;extra/images/logo.png&quot; width=200 height=200/&gt;&lt;br&gt;
  Lapce
  &lt;/a&gt;
&lt;/h1&gt;

&lt;h4 align=&quot;center&quot;&gt;Lightning-fast And Powerful Code Editor&lt;/h4&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/lapce/lapce/actions/workflows/ci.yml&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://github.com/lapce/lapce/actions/workflows/ci.yml/badge.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/n8tGJ6Rn6D&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/946858761413328946?logo=discord&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://docs.lapce.dev&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/static/v1?label=Docs&amp;message=docs.lapce.dev&amp;color=blue&quot; alt=&quot;Lapce Docs&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://wiki.mutable.ai/lapce/lapce&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/static/v1?label=Code Wiki&amp;message=Mutable.ai&amp;color=blue&quot; alt=&quot;Mutable.ai Auto Wiki&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;br/&gt;


Lapce (IPA: /l√¶ps/) is written in pure Rust, with a UI in [Floem](https://github.com/lapce/floem). It is designed with [Rope Science](https://xi-editor.io/docs/rope_science_00.html) from the [Xi-Editor](https://github.com/xi-editor/xi-editor), enabling lightning-fast computation, and leverages [wgpu](https://github.com/gfx-rs/wgpu) for rendering. More information about the features of Lapce can be found on the [main website](https://lapce.dev) and user documentation can be found on [GitBook](https://docs.lapce.dev/).

![](https://github.com/lapce/lapce/blob/master/extra/images/screenshot.png?raw=true)

## Features

* Built-in LSP ([Language Server Protocol](https://microsoft.github.io/language-server-protocol/)) support to give you intelligent code features such as: completion, diagnostics and code actions
* Modal editing support as first class citizen (Vim-like, and toggleable)
* Built-in remote development support inspired by [VSCode Remote Development](https://code.visualstudio.com/docs/remote/remote-overview). Enjoy the benefits of a &quot;local&quot; experience, and seamlessly gain the full power of a remote system. We also have [Lapdev](https://lap.dev/) which can help manage your remote dev environments. 
* Plugins can be written in programming languages that can compile to the [WASI](https://wasi.dev/) format (C, Rust, [AssemblyScript](https://www.assemblyscript.org/))
* Built-in terminal, so you can execute commands in your workspace, without leaving Lapce.

## Installation

You can find pre-built releases for Windows, Linux and macOS [here](https://github.com/lapce/lapce/releases), or [installing with a package manager](docs/installing-with-package-manager.md).
If you&#039;d like to compile from source, you can find the [guide](docs/building-from-source.md).

## Contributing

&lt;a href=&quot;https://ws.lap.dev/#https://github.com/lapce/lapce&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://lap.dev/images/open-in-lapdev.svg?version=8&quot; alt=&quot;Open in Lapdev&quot;&gt;
&lt;/a&gt;

[Lapdev](https://lap.dev/), developed by the Lapce team, is a cloud dev env service similar to GitHub Codespaces. By clicking the button above, you&#039;ll be taken to a fully set up Lapce dev env where you can browse the code and start developing. All dependencies are pre-installed, so you can get straight to code.

Guidelines for contributing to Lapce can be found in [`CONTRIBUTING.md`](CONTRIBUTING.md).

## Feedback &amp; Contact

The most popular place for Lapce developers and users is on the [Discord server](https://discord.gg/n8tGJ6Rn6D).

Or, join the discussion on [Reddit](https://www.reddit.com/r/lapce/) where we are just getting started.

There is also a [Matrix Space](https://matrix.to/#/#lapce-editor:matrix.org), which is linked to the content from the Discord server.

## License

Lapce is released under the Apache License Version 2, which is an open source license. You may contribute to this project, or use the code as you please as long as you adhere to its conditions. You can find a copy of the license text here: [`LICENSE`](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[dani-garcia/vaultwarden]]></title>
            <link>https://github.com/dani-garcia/vaultwarden</link>
            <guid>https://github.com/dani-garcia/vaultwarden</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:04 GMT</pubDate>
            <description><![CDATA[Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dani-garcia/vaultwarden">dani-garcia/vaultwarden</a></h1>
            <p>Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs</p>
            <p>Language: Rust</p>
            <p>Stars: 46,695</p>
            <p>Forks: 2,203</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>![Vaultwarden Logo](./resources/vaultwarden-logo-auto.svg)

An alternative server implementation of the Bitwarden Client API, written in Rust and compatible with [official Bitwarden clients](https://bitwarden.com/download/) [[disclaimer](#disclaimer)], perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.

---

[![GitHub Release](https://img.shields.io/github/release/dani-garcia/vaultwarden.svg?style=for-the-badge&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/releases/latest)
[![ghcr.io Pulls](https://img.shields.io/badge/dynamic/json?style=for-the-badge&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;url=https%3A%2F%2Fipitio.github.io%2Fbackage%2Fdani-garcia%2Fvaultwarden%2Fvaultwarden.json&amp;query=%24.downloads&amp;label=ghcr.io%20pulls&amp;cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden)
[![Docker Pulls](https://img.shields.io/docker/pulls/vaultwarden/server.svg?style=for-the-badge&amp;logo=docker&amp;logoColor=fff&amp;color=005AA4&amp;label=docker.io%20pulls)](https://hub.docker.com/r/vaultwarden/server)
[![Quay.io](https://img.shields.io/badge/quay.io-download-005AA4?style=for-the-badge&amp;logo=redhat&amp;cacheSeconds=14400)](https://quay.io/repository/vaultwarden/server) &lt;br&gt;
[![Contributors](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)
[![Forks](https://img.shields.io/github/forks/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/network/members)
[![Stars](https://img.shields.io/github/stars/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/stargazers)
[![Issues Open](https://img.shields.io/github/issues/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues)
[![Issues Closed](https://img.shields.io/github/issues-closed/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues?q=is%3Aissue+is%3Aclosed)
[![AGPL-3.0 Licensed](https://img.shields.io/github/license/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=vaultwarden&amp;color=944000&amp;cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/blob/main/LICENSE.txt) &lt;br&gt;
[![Dependency Status](https://img.shields.io/badge/dynamic/xml?url=https%3A%2F%2Fdeps.rs%2Frepo%2Fgithub%2Fdani-garcia%2Fvaultwarden%2Fstatus.svg&amp;query=%2F*%5Blocal-name()%3D&#039;svg&#039;%5D%2F*%5Blocal-name()%3D&#039;g&#039;%5D%5B2%5D%2F*%5Blocal-name()%3D&#039;text&#039;%5D%5B4%5D&amp;style=flat-square&amp;logo=rust&amp;label=dependencies&amp;color=005AA4)](https://deps.rs/repo/github/dani-garcia/vaultwarden)
[![GHA Release](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/release.yml?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;label=Release%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/release.yml)
[![GHA Build](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/build.yml?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;label=Build%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/build.yml) &lt;br&gt;
[![Matrix Chat](https://img.shields.io/matrix/vaultwarden:matrix.org.svg?style=flat-square&amp;logo=matrix&amp;logoColor=fff&amp;color=953B00&amp;cacheSeconds=14400)](https://matrix.to/#/#vaultwarden:matrix.org)
[![GitHub Discussions](https://img.shields.io/github/discussions/dani-garcia/vaultwarden?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=953B00&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/discussions)
[![Discourse Discussions](https://img.shields.io/discourse/topics?server=https%3A%2F%2Fvaultwarden.discourse.group%2F&amp;style=flat-square&amp;logo=discourse&amp;color=953B00)](https://vaultwarden.discourse.group/)

&gt; [!IMPORTANT]
&gt; **When using this server, please report any bugs or suggestions directly to us (see [Get in touch](#get-in-touch)), regardless of whatever clients you are using (mobile, desktop, browser...). DO NOT use the official Bitwarden support channels.**

&lt;br&gt;

## Features

A nearly complete implementation of the Bitwarden Client API is provided, including:

 * [Personal Vault](https://bitwarden.com/help/managing-items/)
 * [Send](https://bitwarden.com/help/about-send/)
 * [Attachments](https://bitwarden.com/help/attachments/)
 * [Website icons](https://bitwarden.com/help/website-icons/)
 * [Personal API Key](https://bitwarden.com/help/personal-api-key/)
 * [Organizations](https://bitwarden.com/help/getting-started-organizations/)
   - [Collections](https://bitwarden.com/help/about-collections/),
     [Password Sharing](https://bitwarden.com/help/sharing/),
     [Member Roles](https://bitwarden.com/help/user-types-access-control/),
     [Groups](https://bitwarden.com/help/about-groups/),
     [Event Logs](https://bitwarden.com/help/event-logs/),
     [Admin Password Reset](https://bitwarden.com/help/admin-reset/),
     [Directory Connector](https://bitwarden.com/help/directory-sync/),
     [Policies](https://bitwarden.com/help/policies/)
 * [Multi/Two Factor Authentication](https://bitwarden.com/help/bitwarden-field-guide-two-step-login/)
   - [Authenticator](https://bitwarden.com/help/setup-two-step-login-authenticator/),
     [Email](https://bitwarden.com/help/setup-two-step-login-email/),
     [FIDO2 WebAuthn](https://bitwarden.com/help/setup-two-step-login-fido/),
     [YubiKey](https://bitwarden.com/help/setup-two-step-login-yubikey/),
     [Duo](https://bitwarden.com/help/setup-two-step-login-duo/)
 * [Emergency Access](https://bitwarden.com/help/emergency-access/)
 * [Vaultwarden Admin Backend](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-admin-page)
 * [Modified Web Vault client](https://github.com/dani-garcia/bw_web_builds) (Bundled within our containers)

&lt;br&gt;

## Usage

&gt; [!IMPORTANT]
&gt; The web-vault requires the use a secure context for the [Web Crypto API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API).
&gt; That means it will only work via `http://localhost:8000` (using the port from the example below) or if you [enable HTTPS](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-HTTPS).

The recommended way to install and use Vaultwarden is via our container images which are published to [ghcr.io](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden), [docker.io](https://hub.docker.com/r/vaultwarden/server) and [quay.io](https://quay.io/repository/vaultwarden/server).
See [which container image to use](https://github.com/dani-garcia/vaultwarden/wiki/Which-container-image-to-use) for an explanation of the provided tags.

There are also [community driven packages](https://github.com/dani-garcia/vaultwarden/wiki/Third-party-packages) which can be used, but those might be lagging behind the latest version or might deviate in the way Vaultwarden is configured, as described in our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).

Alternatively, you can also [build Vaultwarden](https://github.com/dani-garcia/vaultwarden/wiki/Building-binary) yourself.

While Vaultwarden is based upon the [Rocket web framework](https://rocket.rs) which has built-in support for TLS our recommendation would be that you setup a reverse proxy (see [proxy examples](https://github.com/dani-garcia/vaultwarden/wiki/Proxy-examples)).

&gt; [!TIP]
&gt;**For more detailed examples on how to install, use and configure Vaultwarden you can check our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).**

### Docker/Podman CLI

Pull the container image and mount a volume from the host for persistent storage.&lt;br&gt;
You can replace `docker` with `podman` if you prefer to use podman.

```shell
docker pull vaultwarden/server:latest
docker run --detach --name vaultwarden \
  --env DOMAIN=&quot;https://vw.domain.tld&quot; \
  --volume /vw-data/:/data/ \
  --restart unless-stopped \
  --publish 127.0.0.1:8000:80 \
  vaultwarden/server:latest
```

This will preserve any persistent data under `/vw-data/`, you can adapt the path to whatever suits you.

### Docker Compose

To use Docker compose you need to create a `compose.yaml` which will hold the configuration to run the Vaultwarden container.

```yaml
services:
  vaultwarden:
    image: vaultwarden/server:latest
    container_name: vaultwarden
    restart: unless-stopped
    environment:
      DOMAIN: &quot;https://vw.domain.tld&quot;
    volumes:
      - ./vw-data/:/data/
    ports:
      - 127.0.0.1:8000:80
```

&lt;br&gt;

## Get in touch

Have a question, suggestion or need help? Join our community on [Matrix](https://matrix.to/#/#vaultwarden:matrix.org), [GitHub Discussions](https://github.com/dani-garcia/vaultwarden/discussions) or [Discourse Forums](https://vaultwarden.discourse.group/).

Encountered a bug or crash? Please search our issue tracker and discussions to see if it&#039;s already been reported. If not, please [start a new discussion](https://github.com/dani-garcia/vaultwarden/discussions) or [create a new issue](https://github.com/dani-garcia/vaultwarden/issues/). Ensure you&#039;re using the latest version of Vaultwarden and there aren&#039;t any similar issues open or closed!

&lt;br&gt;

## Contributors

Thanks for your contribution to the project!

[![Contributors Count](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden?style=for-the-badge&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)&lt;br&gt;
[![Contributors Avatars](https://contributors-img.web.app/image?repo=dani-garcia/vaultwarden)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)

&lt;br&gt;

## Disclaimer

**This project is not associated with [Bitwarden](https://bitwarden.com/) or Bitwarden, Inc.**

However, one of the active maintainers for Vaultwarden is employed by Bitwarden and is allowed to contribute to the project on their own time. These contributions are independent of Bitwarden and are reviewed by other maintainers.

The maintainers work together to set the direction for the project, focusing on serving the self-hosting community, including individuals, families, and small organizations, while ensuring the project&#039;s sustainability.

**Please note:** We cannot be held liable for any data loss that may occur while using Vaultwarden. This includes passwords, attachments, and other information handled by the application. We highly recommend performing regular backups of your files and database. However, should you experience data loss, we encourage you to contact us immediately.

&lt;br&gt;

## Bitwarden_RS

This project was known as Bitwarden_RS and has been renamed to separate itself from the official Bitwarden server in the hopes of avoiding confusion and trademark/branding issues.&lt;br&gt;
Please see [#1642 - v1.21.0 release and project rename to Vaultwarden](https://github.com/dani-garcia/vaultwarden/discussions/1642) for more explanation.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[jj-vcs/jj]]></title>
            <link>https://github.com/jj-vcs/jj</link>
            <guid>https://github.com/jj-vcs/jj</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:03 GMT</pubDate>
            <description><![CDATA[A Git-compatible VCS that is both simple and powerful]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jj-vcs/jj">jj-vcs/jj</a></h1>
            <p>A Git-compatible VCS that is both simple and powerful</p>
            <p>Language: Rust</p>
            <p>Stars: 17,369</p>
            <p>Forks: 579</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>&lt;div class=&quot;title-block&quot; style=&quot;text-align: center;&quot; align=&quot;center&quot;&gt;

# Jujutsu‚Äîa version control system

&lt;p&gt;&lt;img title=&quot;jj logo&quot; src=&quot;docs/images/jj-logo.svg&quot; width=&quot;320&quot; height=&quot;320&quot;&gt;&lt;/p&gt;

[![Release](https://img.shields.io/github/v/release/martinvonz/jj)](https://github.com/jj-vcs/jj/releases)
[![Release date](https://img.shields.io/github/release-date/martinvonz/jj)](https://github.com/jj-vcs/jj/releases)
&lt;br/&gt;
[![License](https://img.shields.io/github/license/martinvonz/jj)](https://github.com/jj-vcs/jj/blob/main/LICENSE)
[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN)
[![IRC](https://img.shields.io/badge/irc-%23jujutsu-blue.svg)](https://web.libera.chat/?channel=#jujutsu)

**[Homepage] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Installation] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Getting Started] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Development Roadmap] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Contributing](#contributing)**

[Homepage]: https://jj-vcs.github.io/jj
[Installation]: https://jj-vcs.github.io/jj/latest/install-and-setup
[Getting Started]: https://jj-vcs.github.io/jj/latest/tutorial
[Development Roadmap]: https://jj-vcs.github.io/jj/latest/roadmap

&lt;/div&gt;

## Introduction

Jujutsu is a powerful [version control system](https://en.wikipedia.org/wiki/Version_control)
for software projects. You use it to get a copy of your code, track changes
to the code, and finally publish those changes for others to see and use.
It is designed from the ground up to be easy to use‚Äîwhether you&#039;re new or
experienced, working on brand new projects alone, or large scale software
projects with large histories and teams.

Jujutsu is unlike most other systems, because internally it abstracts the user
interface and version control algorithms from the *storage systems* used to
serve your content. This allows it to serve as a VCS with many possible physical
backends, that may have their own data or networking models‚Äîlike [Mercurial] or
[Breezy], or hybrid systems like Google&#039;s cloud-based design, [Piper/CitC].

[Mercurial]: https://www.mercurial-scm.org/
[Breezy]: https://www.breezy-vcs.org/
[Piper/CitC]: https://youtu.be/W71BTkUbdqE?t=645

Today, we use Git repositories as a storage layer to serve and track content,
making it **compatible with many of your favorite Git-based tools, right now!**
All core developers use Jujutsu to develop Jujutsu, right here on GitHub. But it
should hopefully work with your favorite Git forges, too.

We combine many distinct design choices and concepts from other version control
systems into a single tool. Some of those sources of inspiration include:

- **Git**: We make an effort to [be fast][perf]‚Äîwith a snappy UX, efficient
  algorithms, correct data structures, and good-old-fashioned attention to
  detail. The default storage backend uses Git repositories for &quot;physical
  storage&quot;, for wide interoperability and ease of onboarding.

- **Mercurial &amp; Sapling**: There are many Mercurial-inspired features, such as
  the [revset] language to select commits. There is [no explicit index][no-index]
  or staging area. Branches are &quot;anonymous&quot; like Mercurial, so you don&#039;t need
  to make up a name for each small change. Primitives for rewriting history are
  powerful and simple. Formatting output is done with a robust template language
  that can be configured by the user.

- **Darcs**: Jujutsu keeps track of conflicts as [first-class
  objects][conflicts] in its model; they are first-class in the same way commits
  are, while alternatives like Git simply think of conflicts as textual diffs.
  While not as rigorous as systems like Darcs (which is based on a formalized
  theory of patches, as opposed to snapshots), the effect is that many forms of
  conflict resolution can be performed and propagated automatically.

[perf]: https://github.com/jj-vcs/jj/discussions/49
[revset]: https://jj-vcs.github.io/jj/latest/revsets/
[no-index]: https://jj-vcs.github.io/jj/latest/git-comparison/#the-index
[conflicts]: https://jj-vcs.github.io/jj/latest/conflicts/

And it adds several innovative, useful features of its own:

- **Working-copy-as-a-commit**: Changes to files are [recorded automatically][wcc]
  as normal commits, and amended on every subsequent change. This &quot;snapshot&quot;
  design simplifies the user-facing data model (commits are the only visible
  object), simplifies internal algorithms, and completely subsumes features like
  Git&#039;s stashes or the index/staging-area.

- **Operation log &amp; undo**: Jujutsu records every operation that is performed on the
  repository, from commits, to pulls, to pushes. This makes debugging problems like
  &quot;what just happened?&quot; or &quot;how did I end up here?&quot; easier, *especially* when
  you&#039;re helping your coworker answer those questions about their repository!
  And because everything is recorded, you can undo that mistake you just made
  with ease. Version control has finally entered [the 1960s][undo-history]!

- **Automatic rebase and conflict resolution**: When you modify a commit, every
  descendent is automatically rebased on top of the freshly-modified one. This
  makes &quot;patch-based&quot; workflows a breeze. If you resolve a conflict in a commit,
  the _resolution_ of that conflict is also propagated through descendants as
  well. In effect, this is a completely transparent version of `git rebase
  --update-refs` combined with `git rerere`, supported by design.

&gt; [!WARNING]
&gt; The following features are available for use, but experimental; they may have
&gt; bugs, backwards incompatible storage changes, and user-interface changes!

- **Safe, concurrent replication**: Have you ever wanted to store your version
  controlled repositories inside a Dropbox folder? Or continuously backup
  repositories to S3? No? Well, now you can!

  The fundamental problem with using filesystems like Dropbox and backup tools
  like `rsync` on your typical Git/Mercurial repositories is that they rely
  on *local filesystem operations* being atomic, serialized, and non-concurrent
  with respect to other reads and writes‚Äîwhich is _not_ true when operating on
  distributed file systems, or when operations like concurrent file copies (for
  backup) happen while lock files are being held.

  Jujutsu is instead designed to be [safe under concurrent scenarios][conc-safety];
  simply using rsync or Dropbox and then using that resulting repository
  should never result in a repository in a *corrupt state*. The worst that
  _should_ happen is that it will expose conflicts between the local and remote
  state, leaving you to resolve them.

[wcc]: https://jj-vcs.github.io/jj/latest/working-copy/
[undo-history]: https://en.wikipedia.org/wiki/Undo#History
[conc-safety]: https://jj-vcs.github.io/jj/latest/technical/concurrency/

The command-line tool is called `jj` for now because it&#039;s easy to type and easy
to replace (rare in English). The project is called &quot;Jujutsu&quot; because it matches
&quot;jj&quot;.

Jujutsu is relatively young, with lots of work to still be done. If you have any
questions, or want to talk about future plans, please join us on Discord
[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN),
start a [GitHub Discussion](https://github.com/jj-vcs/jj/discussions), or
send an IRC message to [`#jujutsu` on Libera
Chat](https://web.libera.chat/?channel=#jujutsu). The developers monitor all of
these channels[^bridge].

[^bridge]: To be more precise, the `#jujutsu` Libera IRC channel is bridged to
one of the channels on jj&#039;s Discord. Some of the developers stay on Discord and
use the bridge to follow IRC.

### News and Updates üì£

- **December 2024**: The `jj` Repository has moved to the `jj-vcs` GitHub
  organisation.
- **November 2024**: Version 0.24 is released which adds `jj file annotate`,
  which is equivalent to `git blame` or `hg annotate`.
- **September 2024**: Martin gave a [presentation about Jujutsu][merge-vid-2024] at
  Git Merge 2024.
- **Feb 2024**: Version 0.14 is released, which deprecates [&quot;jj checkout&quot; and &quot;jj merge&quot;](CHANGELOG.md#0140---2024-02-07),
  as well as `jj init --git`, which is now just called `jj git init`.
- **Oct 2023**: Version 0.10.0 is released! Now includes a bundled merge and
  diff editor for all platforms, &quot;immutable revsets&quot; to avoid accidentally
  `edit`-ing the wrong revisions, and lots of polish.
- **Jan 2023**: Martin gave a presentation about Google&#039;s plans for Jujutsu at
  Git Merge 2022!
  See the [slides][merge-slides] or the [recording][merge-talk].

### Related Media

- **Mar 2024**: Chris Krycho started [a YouTube series about Jujutsu][krycho-yt].
- **Feb 2024**: Chris Krycho published an article about Jujutsu called [jj init][krycho]
  and Steve Klabnik followed up with the [Jujutsu Tutorial][klabnik].
- **Jan 2024**: Jujutsu was featured in an LWN.net article called
  [Jujutsu: a new, Git-compatible version control system][lwn].
- **Jan 2023**: Martin&#039;s Talk about Jujutsu at Git Merge 2022, [video][merge-talk]
  and the associated [slides][merge-slides].

The wiki also contains a more extensive list of [media references][wiki-media].

[krycho-yt]: https://www.youtube.com/playlist?list=PLelyiwKWHHAq01Pvmpf6x7J0y-yQpmtxp
[krycho]: https://v5.chriskrycho.com/essays/jj-init/
[klabnik]: https://steveklabnik.github.io/jujutsu-tutorial/
[lwn]: https://lwn.net/Articles/958468/
[merge-talk]: https://www.youtube.com/watch?v=bx_LGilOuE4
[merge-slides]: https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view
[merge-vid-2024]: https://www.youtube.com/watch?v=LV0JzI8IcCY
[wiki-media]: https://github.com/jj-vcs/jj/wiki/Media

## Getting started

&gt; [!IMPORTANT]
&gt; Jujutsu is an **experimental version control system**. While Git compatibility
&gt; is stable, and most developers use it daily for all their needs, there may
&gt; still be work-in-progress features, suboptimal UX, and workflow gaps that make
&gt; it unusable for your particular use.

Follow the [installation
instructions](https://jj-vcs.github.io/jj/latest/install-and-setup) to
obtain and configure `jj`.

The best way to get started is probably to go through [the
tutorial](https://jj-vcs.github.io/jj/latest/tutorial). Also see the [Git
comparison](https://jj-vcs.github.io/jj/latest/git-comparison), which
includes a table of `jj` vs. `git` commands.

As you become more familiar with Jujutsu, the following resources may be helpful:

- The [FAQ](https://jj-vcs.github.io/jj/latest/FAQ).
- The [Glossary](https://jj-vcs.github.io/jj/latest/glossary).
- The `jj help` command (e.g. `jj help rebase`).
- The `jj help -k &lt;keyword&gt;` command (e.g. `jj help -k config`). Use `jj help --help`
  to see what keywords are available.

If you are using a **prerelease** version of `jj`, you would want to consult
[the docs for the prerelease (main branch)
version](https://jj-vcs.github.io/jj/prerelease/). You can also get there
from the docs for the latest release by using the website&#039;s version switcher. The version switcher is visible in
the header of the website when you scroll to the top of any page.

## Features

### Compatible with Git

Jujutsu is designed so that the underlying data and storage model is abstract.
Today, only the Git backend is production-ready. The Git backend uses the
[gitoxide](https://github.com/Byron/gitoxide) Rust library.

[backends]: https://jj-vcs.github.io/jj/latest/glossary#backend

The Git backend is fully featured and maintained, and allows you to use Jujutsu
with any Git remote. The commits you create will look like regular Git commits.
You can fetch branches from a regular Git remote and push branches to the
remote. You can always switch back to Git.

Here is how you can explore a GitHub repository with `jj`.

&lt;img src=&quot;demos/git_compat.png&quot; /&gt;

You can even have a [&quot;co-located&quot; local
repository](https://jj-vcs.github.io/jj/latest/git-compatibility#co-located-jujutsugit-repos)
where you can use both `jj` and `git` commands interchangeably.

### The working copy is automatically committed

Jujutsu uses a real commit to represent the working copy. Checking out a commit
results a new working-copy commit on top of the target commit. Almost all
commands automatically amend the working-copy commit.

The working-copy being a commit means that commands never fail because the
working copy is dirty (no &quot;error: Your local changes to the following
files...&quot;), and there is no need for `git stash`. Also, because the working copy
is a commit, commands work the same way on the working-copy commit as on any
other commit, so you can set the commit message before you&#039;re done with the
changes.

&lt;img src=&quot;demos/working_copy.png&quot; /&gt;

### The repo is the source of truth

With Jujutsu, the working copy plays a smaller role than with Git. Commands
snapshot the working copy before they start, then they update the repo, and then
the working copy is updated (if the working-copy commit was modified). Almost
all commands (even checkout!) operate on the commits in the repo, leaving the
common functionality of snapshotting and updating of the working copy to
centralized code. For example, `jj restore` (similar to `git restore`) can
restore from any commit and into any commit, and `jj describe` can set the
commit message of any commit (defaults to the working-copy commit).

### Entire repo is under version control

All operations you perform in the repo are recorded, along with a snapshot of
the repo state after the operation. This means that you can easily revert to an
earlier repo state, or to simply undo a particular operation (which does not
necessarily have to be the most recent operation).

&lt;img src=&quot;demos/operation_log.png&quot; /&gt;

### Conflicts can be recorded in commits

If an operation results in
[conflicts](https://jj-vcs.github.io/jj/latest/glossary#conflict),
information about those conflicts will be recorded in the commit(s). The
operation will succeed. You can then resolve the conflicts later. One
consequence of this design is that there&#039;s no need to continue interrupted
operations. Instead, you get a single workflow for resolving conflicts,
regardless of which command caused them. This design also lets Jujutsu rebase
merge commits correctly (unlike both Git and Mercurial).

Basic conflict resolution:

&lt;img src=&quot;demos/resolve_conflicts.png&quot; /&gt;

Juggling conflicts:

&lt;img src=&quot;demos/juggle_conflicts.png&quot; /&gt;

### Automatic rebase

Whenever you modify a commit, any descendants of the old commit will be rebased
onto the new commit. Thanks to the conflict design described above, that can be
done even if there are conflicts. Bookmarks pointing to rebased commits will be
updated. So will the working copy if it points to a rebased commit.

### Comprehensive support for rewriting history

Besides the usual rebase command, there&#039;s `jj describe` for editing the
description (commit message) of an arbitrary commit. There&#039;s also `jj diffedit`,
which lets you edit the changes in a commit without checking it out. To split
a commit into two, use `jj split`. You can even move part of the changes in a
commit to any other commit using `jj squash -i --from X --into Y`.

## Status

The tool is fairly feature-complete, but some important features like support
for Git submodules are not yet completed. There
are also several performance bugs. It&#039;s likely that workflows and setups
different from what the core developers use are not well supported, e.g. there
is no native support for email-based workflows.

Today, all core developers use `jj` to work on `jj`. I (Martin von Zweigbergk)
have almost exclusively used `jj` to develop the project itself since early
January 2021. I haven&#039;t had to re-clone from source (I don&#039;t think I&#039;ve even had
to restore from backup).

There *will* be changes to workflows and backward-incompatible changes to the
on-disk formats before version 1.0.0. Even the binary&#039;s name may change (i.e.
away from `jj`). For any format changes, we&#039;ll try to implement transparent
upgrades (as we&#039;ve done with recent changes), or provide upgrade commands or
scripts if requested.

## Related work

There are several tools trying to solve similar problems as Jujutsu. See
[related work](https://jj-vcs.github.io/jj/latest/related-work) for details.

## Contributing

We welcome outside contributions, and there&#039;s plenty of things to do, so
don&#039;t be shy. Please ask if you want a pointer on something you can help with,
and hopefully we can all figure something out.

We do have [a few policies and
suggestions](https://jj-vcs.github.io/jj/prerelease/contributing/)
for contributors. The broad TL;DR:

- Bug reports are very welcome!
- Every commit that lands in the `main` branch is code reviewed.
- Please behave yourself, and obey the Community Guidelines.
- There **is** a mandatory CLA you must agree to. Importantly, it **does not**
  transfer copyright ownership to Google or anyone else; it simply gives us the
  right to safely redistribute and use your changes.

### Mandatory Google Disclaimer

I (Martin von Zweigbergk, &lt;martinvonz@google.com&gt;) started Jujutsu as a hobby
project in late 2019, and it has evolved into my full-time project at Google,
with several other Googlers (now) assisting development in various capacities.
That said, **this is not a Google product**.

## License

Jujutsu is available as Open Source Software, under the Apache 2.0 license. See
[`LICENSE`](./LICENSE) for details about copyright and redistribution.

The `jj` logo was contributed by J. Jennings and is licensed under a Creative
Commons License, see [`docs/images/LICENSE`](docs/images/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:02 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 61,170</p>
            <p>Forks: 1,753</p>
            <p>Stars today: 89 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- üöÄ A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`,
  and more.
- ‚ö°Ô∏è [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- üóÇÔ∏è Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- ‚ùáÔ∏è [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- üêç [Installs and manages](#python-versions) Python versions.
- üõ†Ô∏è [Runs and installs](#tools) tools published as Python packages.
- üî© Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a
  familiar CLI.
- üè¢ Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- üíæ Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- ‚è¨ Installable without Rust or Python via `curl` or `pip`.
- üñ•Ô∏è Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Platform support

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

## Versioning policy

See uv&#039;s [versioning policy](https://docs.astral.sh/uv/reference/versioning/) document.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv/blob/main/CONTRIBUTING.md) to get started.

## FAQ

#### How do you pronounce uv?

It&#039;s pronounced as &quot;you - vee&quot; ([`/juÀê viÀê/`](https://en.wikipedia.org/wiki/Help:IPA/English#Key))

#### How should I stylize uv?

Just &quot;uv&quot;, please. See the [style guide](./STYLE.md#styling-uv) for details.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[Xerxes-2/clewdr]]></title>
            <link>https://github.com/Xerxes-2/clewdr</link>
            <guid>https://github.com/Xerxes-2/clewdr</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:01 GMT</pubDate>
            <description><![CDATA[High Performance LLM Reverse Proxy]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Xerxes-2/clewdr">Xerxes-2/clewdr</a></h1>
            <p>High Performance LLM Reverse Proxy</p>
            <p>Language: Rust</p>
            <p>Stars: 321</p>
            <p>Forks: 57</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># Clewd&lt;span style=&quot;color:#CE422B&quot;&gt;R&lt;/span&gt;

[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/Xerxes-2/clewdr)
[![GitHub Release](https://img.shields.io/github/v/release/Xerxes-2/clewdr?style=flat-square)](https://github.com/Xerxes-2/clewdr/releases/latest)

[English](./README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](./README_zh.md)

## High-Performance LLM Proxy

Specifically built for Claude (Claude.ai) and Gemini (Google AI Studio, Google Vertex AI)

## Core Advantages

### Full-Featured Frontend

- Integrated React frontend providing a complete functional experience

### Efficient Architecture

- Occupies one-tenth the resources compared to script language implementations, with ten times the performance, easily handling thousands of requests per second
- Event-driven design, decoupled logic, supports hot reloading and multiple configuration methods
- High-performance response caching supported by Moka technology
- Multi-threaded asynchronous processing based on Tokio and Axum
- Fingerprint-level Chrome simulation Rquest HTTP client

### Intelligent Cookie Management

- Automatic classification and management of account status
- Fine-grained polling mechanism to maximize resource utilization

### Full Platform Compatibility

- Rust static compilation, single binary deployment, no environment dependencies needed
- Native support for macOS/Android and other platforms
- Extremely low memory usage (only single-digit MB)
- No need for virtual machines or complex dependencies

### Enhanced Features

- Built-in proxy server support (no TUN required)
- Concurrent cache request handling
- Gemini additional support:
  - Google AI Studio and Google Vertex AI
  - OpenAI compatible mode / Gemini format
  - Painless HTTP Keep-Alive support
- Claude additional support:
  - OpenAI compatible mode / Claude format
  - Extend Thinking
  - Stop sequences implemented on the proxy side
  - Image attachment uploads
  - Web search
  - Claude Max

## Quick Start

1. Download the program package for your platform ([Latest Version](https://github.com/Xerxes-2/clewdr/releases/latest))
2. The password will be automatically generated on the first run. Access the default frontend address &lt;http://127.0.0.1:8484&gt;, and log in using the Web Admin Password displayed in the console.
   - If you need to change the password, you can set a new one in the frontend interface.
   - If you forget the password, you can delete the `clewdr.toml` file to regenerate it.
   - Note: If deploying with Docker, the password will be generated and displayed in the logs when the container starts.
3. Configure the proxy address and other parameters in the frontend interface, add Cookies and Keys.
4. Third-party application configuration:
    1. ClewdR will print the access addresses for each API in the console when it starts.
    2. Choose the API format you want (Claude or Gemini or OpenAI compatible).
    3. Set the corresponding proxy address in applications like SillyTavern, and fill in the API Password displayed in the console as the proxy password.
5. Enjoy the high-performance LLM proxy service!

## Community Resources

**Github Aggregated Wiki**: &lt;https://github.com/Xerxes-2/clewdr/wiki&gt;

## Acknowledgements

- [Clewd Modified Version](https://github.com/teralomaniac/clewd) - A modified version of the original Clewd, providing many inspirations and foundational features.
- [Clove](https://github.com/mirrorange/clove) - Provides the support logic for Claude Code.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[afnanenayet/diffsitter]]></title>
            <link>https://github.com/afnanenayet/diffsitter</link>
            <guid>https://github.com/afnanenayet/diffsitter</guid>
            <pubDate>Sun, 13 Jul 2025 00:06:00 GMT</pubDate>
            <description><![CDATA[A tree-sitter based AST difftool to get meaningful semantic diffs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/afnanenayet/diffsitter">afnanenayet/diffsitter</a></h1>
            <p>A tree-sitter based AST difftool to get meaningful semantic diffs</p>
            <p>Language: Rust</p>
            <p>Stars: 2,094</p>
            <p>Forks: 39</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre># diffsitter

[![CI](https://github.com/afnanenayet/diffsitter/actions/workflows/CI.yml/badge.svg)](https://github.com/afnanenayet/diffsitter/actions/workflows/CI.yml)
[![CD](https://github.com/afnanenayet/diffsitter/actions/workflows/CD.yml/badge.svg)](https://github.com/afnanenayet/diffsitter/actions/workflows/CD.yml)
[![codecov](https://codecov.io/gh/afnanenayet/diffsitter/branch/main/graph/badge.svg?token=GBTJGXEXOS)](https://codecov.io/gh/afnanenayet/diffsitter)
[![crates version](https://img.shields.io/crates/v/diffsitter)](https://crates.io/crates/diffsitter)
[![GitHub release (latest by date)](https://img.shields.io/github/v/release/afnanenayet/diffsitter)](https://github.com/afnanenayet/diffsitter/releases/latest)
![downloads](https://img.shields.io/crates/d/diffsitter)
[![license](https://img.shields.io/github/license/afnanenayet/diffsitter)](./LICENSE)

[![asciicast](https://asciinema.org/a/joEIfP8XoxUhZKXEqUD8CEP7j.svg)](https://asciinema.org/a/joEIfP8XoxUhZKXEqUD8CEP7j)

## Disclaimer

`diffsitter` is very much a work in progress and nowhere close to production
ready (yet). Contributions are always welcome!

## Summary

`diffsitter` creates semantically meaningful diffs that ignore formatting
differences like spacing. It does so by computing a diff on the AST (abstract
syntax tree) of a file rather than computing the diff on the text contents of
the file.

`diffsitter` uses the parsers from the
[tree-sitter](https://tree-sitter.github.io/tree-sitter) project to parse
source code. As such, the languages supported by this tool are restricted to the
languages supported by tree-sitter.

`diffsitter` supports the following languages:

* Bash
* C#
* C++
* CSS
* Go
* Java
* OCaml
* PHP
* Python
* Ruby
* Rust
* Typescript/TSX
* HCL

## Examples

Take the following files:

[`a.rs`](test_data/short/rust/a.rs)

```rust
fn main() {
    let x = 1;
}

fn add_one {
}
```

[`b.rs`](test_data/short/rust/b.rs)

```rust
fn



main

()

{
}

fn addition() {
}

fn add_two() {
}
```

The standard output from `diff` will get you:

```text
1,2c1,12
&lt; fn main() {
&lt;     let x = 1;
---
&gt; fn
&gt;
&gt;
&gt;
&gt; main
&gt;
&gt; ()
&gt;
&gt; {
&gt; }
&gt;
&gt; fn addition() {
5c15
&lt; fn add_one {
---
&gt; fn add_two() {
```

You can see that it picks up the formatting differences for the `main`
function, even though they aren&#039;t semantically different.

Check out the output from `diffsitter`:

```
test_data/short/rust/a.rs -&gt; test_data/short/rust/b.rs
======================================================

9:
--
+ }

11:
---
+ fn addition() {

1:
--
-     let x = 1;

14:
---
+ fn add_two() {

4:
--
- fn add_one {
```

*Note: the numbers correspond to line numbers from the original files.*

You can also filter which tree sitter nodes are considered in the diff through
the config file.

Since it uses the AST to calculate the difference, it knows that the formatting
differences in `main` between the two files isn&#039;t a meaningful difference, so
it doesn&#039;t show up in the diff.

`diffsitter` has some nice (terminal aware) formatting too:

![screenshot of rust diff](assets/rust_example.png)

It also has extensive logging if you want to debug or see timing information:

![screenshot of rust diff with logs](assets/rust_example_logs.png)

### Node filtering

You can filter the nodes that are considered in the diff by setting
`include_nodes` or `exclude_nodes` in the config file. `exclude_nodes` always
takes precedence over `include_nodes`, and the type of a node is the `kind`
of a tree-sitter node. The `kind` directly corresponds to whatever is reported
by the tree-sitter API, so this example may occasionally go out of date.

This feature currently only applies to leaf nodes, but we could exclude nodes
recursively if there&#039;s demand for it.

```json5
&quot;input-processing&quot;: {
    // You can exclude different tree sitter node types - this rule takes precedence over `include_kinds`.
    &quot;exclude_kinds&quot;: [&quot;string_content&quot;],
    // You can specifically allow only certain tree sitter node types
    &quot;include_kinds&quot;: [&quot;method_definition&quot;],
}
```

## Installation

&lt;a href=&quot;https://repology.org/project/diffsitter/versions&quot;&gt;
  &lt;img src=&quot;https://repology.org/badge/vertical-allrepos/diffsitter.svg&quot; alt=&quot;Packaging status&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

### Published binaries

This project uses Github actions to build and publish binaries for each tagged
release. You can download binaries from there if your platform is listed. We
publish [nightly releases](https://github.com/afnanenayet/diffsitter/releases/tag/nightly)
as well as tagged [stable releases](https://github.com/afnanenayet/diffsitter/releases/latest).

### Cargo

You can build from source with `cargo` using the following command:

```sh
cargo install diffsitter --bin diffsitter
```

If you want to generate completion files and other assets you can install the
`diffsitter_completions` binary with the following command:

```sh
cargo install diffsitter --bin diffsitter_completions
```

### Homebrew

You can use my tap to install diffsitter:

```sh
brew tap afnanenayet/tap
brew install diffsitter
# brew install afnanenayet/tap/diffsitter
```

### Arch Linux (AUR)

@samhh has packaged diffsitter for arch on the AUR. Use your favorite AUR
helper to install [`diffsitter-bin`](https://aur.archlinux.org/packages/diffsitter-bin/).

### Alpine Linux

Install package [diffsitter](https://pkgs.alpinelinux.org/packages?name=diffsitter) from the Alpine Linux repositories (on v3.16+ or Edge):

```sh
apk add diffsitter
```

Tree-sitter grammars are packaged separately (search for [tree-sitter-\*](https://pkgs.alpinelinux.org/packages?name=tree-sitter-*&amp;arch=x86_64)).
You can install individual packages you need or the virtual package `tree-sitter-grammars` to install all of them.

### Building with Docker

We also provide a Docker image that builds diffsitter using the standard Rust
base image. It separates the compilation stage from the run stage, so you can
build it and run with the following command (assuming you have Docker installed
on your system):

```sh
docker build -t diffsitter .
docker run -it --rm --name diffsitter-interactive diffsitter
```

## Usage

For detailed help you can run `diffsitter --help` (`diffsitter -h` provides
brief help messages).

You can configure file associations and formatting options for `diffsitter`
using a config file. If a config is not supplied, the app will use the default
config, which you can see with `diffsitter dump-default-config`. It will
look for a config at `${XDG_HOME:-$HOME}/.config/diffsitter/config.json5` on
macOS and Linux, and the standard directory for Windows. You can also refer to
the [sample config](/assets/sample_config.json5).

You can override the default config path by using the `--config` flag or set
the `DIFFSITTER_CONFIG` environment variable.

*Note: the tests for this crate check to make sure the provided sample config
is a valid config.*

### Git integration

To see the changes to the current git repo in diffsitter, you can add
the following to your repo&#039;s `.git/config` and run `git difftool`.

```
[diff]
        tool = diffsitter

[difftool]
        prompt = false

[difftool &quot;diffsitter&quot;]
        cmd = diffsitter &quot;$LOCAL&quot; &quot;$REMOTE&quot;
```

### Shell Completion

You can generate shell completion scripts using the binary using the
`gen-completion` subcommand. This will print the shell completion script for a
given shell to `STDOUT`.

You should use the help text for the most up to date usage information, but
general usage would look like this:

```sh
diffsitter gen-completion bash &gt; completion.bash
```

We currently support the following shells (via `clap_complete`):

* Bash
* Zsh
* Fish
* Elvish
* Powershell

## Dependencies

`diffsitter` is usually compiled as a static binary, so the `tree-sitter`
grammars/libraries are baked into the binary as static libraries. There is an
option to build with support for dynamic libraries which will look for shared
library files in the user&#039;s default library path. This will search for
library files of the form `libtree-sitter-{lang}.{ext}`, where `lang` is the
language that the user is trying to diff and `ext` is the platform-specific
extension for shared library files (`.so`, `.dylib`, etc). The user can
override the dynamic library file for each language in the config as such:

```json5
{
    &quot;grammar&quot;: {
        // You can specify the dynamic library names for each language
        &quot;dylib-overrides&quot;: {
            // with a filename
            &quot;rust&quot;: &quot;libtree-sitter-rust.so&quot;,
            // with an absolute path
            &quot;c&quot;: &quot;/usr/lib/libtree-sitter-c.so&quot;,
            // with a relative path
            &quot;cpp&quot;: &quot;../libtree-sitter-c.so&quot;,
        },
    }
}
```

*The above excerpt was taken from the
[sample config](/assets/sample_config.json5).*

## Questions, Bugs, and Support

If you notice any bugs, have any issues, want to see a new feature, or just
have a question, feel free to open an
[issue](https://github.com/afnanenayet/diffsitter/issues) or create a
[discussion post](https://github.com/afnanenayet/diffsitter/discussions).

If you file an issue, it would be preferable that you include a minimal example
and/or post the log output of `diffsitter` (which you can do by adding the
`-d/--debug` flag).

## Contributing

See [CONTRIBUTING.md](docs/CONTRIBUTING.md).

## Similar Projects

* [difftastic](https://github.com/Wilfred/difftastic)
* [locust](https://github.com/bugout-dev/locust)
* [gumtree](https://github.com/GumTreeDiff/gumtree)
* [diffr](https://github.com/mookid/diffr)
* [delta](https://github.com/dandavison/delta)
* [Semantic Diff Tool](https://www.sdt.dev)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gfx-rs/wgpu]]></title>
            <link>https://github.com/gfx-rs/wgpu</link>
            <guid>https://github.com/gfx-rs/wgpu</guid>
            <pubDate>Sun, 13 Jul 2025 00:05:59 GMT</pubDate>
            <description><![CDATA[A cross-platform, safe, pure-Rust graphics API.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gfx-rs/wgpu">gfx-rs/wgpu</a></h1>
            <p>A cross-platform, safe, pure-Rust graphics API.</p>
            <p>Language: Rust</p>
            <p>Stars: 14,581</p>
            <p>Forks: 1,096</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># wgpu
&lt;img align=&quot;right&quot; width=&quot;20%&quot; src=&quot;logo.png&quot;&gt;

[![Matrix Space](https://img.shields.io/static/v1?label=Space&amp;message=%23Wgpu&amp;color=blue&amp;logo=matrix)](https://matrix.to/#/#Wgpu:matrix.org)
[![Dev Matrix](https://img.shields.io/static/v1?label=devs&amp;message=%23wgpu&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu:matrix.org)
[![User Matrix](https://img.shields.io/static/v1?label=users&amp;message=%23wgpu-users&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu-users:matrix.org)
[![Build Status](https://img.shields.io/github/actions/workflow/status/gfx-rs/wgpu/ci.yml?branch=trunk&amp;logo=github&amp;label=CI)](https://github.com/gfx-rs/wgpu/actions)
[![codecov.io](https://img.shields.io/codecov/c/github/gfx-rs/wgpu?logo=codecov&amp;logoColor=fff&amp;label=codecov&amp;token=84qJTesmeS)](https://codecov.io/gh/gfx-rs/wgpu)

`wgpu` is a cross-platform, safe, pure-rust graphics API. It runs natively on Vulkan, Metal, D3D12, and OpenGL; and on top of WebGL2 and WebGPU on wasm.

The API is based on the [WebGPU standard][webgpu]. It serves as the core of the WebGPU integration in Firefox, Servo, and Deno.

[webgpu]: https://gpuweb.github.io/gpuweb/

## Quick Links

| Docs                  | Examples                  | Changelog               |
|:---------------------:|:-------------------------:|:-----------------------:|
| [v26][rel-docs]       | [v26][rel-examples]       | [v26][rel-change]       |
| [`trunk`][trunk-docs] | [`trunk`][trunk-examples] | [`trunk`][trunk-change] |

Contributors are welcome! See [CONTRIBUTING.md][contrib] for more information.

[rel-docs]: https://docs.rs/wgpu/
[rel-examples]: https://github.com/gfx-rs/wgpu/tree/v26/examples#readme
[rel-change]: https://github.com/gfx-rs/wgpu/releases
[trunk-docs]: https://wgpu.rs/doc/wgpu/
[trunk-examples]: https://github.com/gfx-rs/wgpu/tree/trunk/examples#readme
[trunk-change]: https://github.com/gfx-rs/wgpu/blob/trunk/CHANGELOG.md#unreleased
[contrib]: CONTRIBUTING.md

## Repo Overview

The repository hosts the following libraries:

- [![Crates.io](https://img.shields.io/crates/v/wgpu.svg?label=wgpu)](https://crates.io/crates/wgpu) [![docs.rs](https://docs.rs/wgpu/badge.svg)](https://docs.rs/wgpu/) - User facing Rust API.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-core.svg?label=wgpu-core)](https://crates.io/crates/wgpu-core) [![docs.rs](https://docs.rs/wgpu-core/badge.svg)](https://docs.rs/wgpu-core/) - Internal safe implementation.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-hal.svg?label=wgpu-hal)](https://crates.io/crates/wgpu-hal) [![docs.rs](https://docs.rs/wgpu-hal/badge.svg)](https://docs.rs/wgpu-hal/) - Internal unsafe GPU API abstraction layer.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-types.svg?label=wgpu-types)](https://crates.io/crates/wgpu-types) [![docs.rs](https://docs.rs/wgpu-types/badge.svg)](https://docs.rs/wgpu-types/) - Rust types shared between all crates.
- [![Crates.io](https://img.shields.io/crates/v/naga.svg?label=naga)](https://crates.io/crates/naga) [![docs.rs](https://docs.rs/naga/badge.svg)](https://docs.rs/naga/) - Stand-alone shader translation library.
- [![Crates.io](https://img.shields.io/crates/v/deno_webgpu.svg?label=deno_webgpu)](https://crates.io/crates/deno_webgpu) - WebGPU implementation for the Deno JavaScript/TypeScript runtime

The following binaries:

- [![Crates.io](https://img.shields.io/crates/v/naga-cli.svg?label=naga-cli)](https://crates.io/crates/naga-cli) - Tool for translating shaders between different languages using `naga`.
- [![Crates.io](https://img.shields.io/crates/v/wgpu-info.svg?label=wgpu-info)](https://crates.io/crates/wgpu-info) - Tool for getting information on GPUs in the system.
- `cts_runner` - WebGPU Conformance Test Suite runner using `deno_webgpu`.
- `player` - standalone application for replaying the API traces.

For an overview of all the components in the gfx-rs ecosystem, see [the big picture](./docs/big-picture.png).

## Getting Started

### Play with our Examples

Go to &lt;https://wgpu.rs/examples/&gt; to play with our examples in your browser. Requires a browser supporting WebGPU for the WebGPU examples.

### Rust

Rust examples can be found at [examples](examples). You can run the examples natively with `cargo run --bin wgpu-examples &lt;example&gt;`.

If you are new to wgpu and graphics programming, we recommend starting with https://sotrh.github.io/learn-wgpu/.

To run the examples in a browser, run `cargo xtask run-wasm`.
Then open `http://localhost:8000` in your browser, and you can choose an example to run.
Naturally, in order to display any of the WebGPU based examples, you need to make sure your browser supports it.

### C/C++

To use wgpu in C/C++, you need [wgpu-native](https://github.com/gfx-rs/wgpu-native).

If you are looking for a wgpu C++ tutorial, look at the following:

- https://eliemichel.github.io/LearnWebGPU/

### Others

If you want to use wgpu in other languages, there are many bindings to wgpu-native from languages such as Python, D, Julia, Kotlin, and more. See [the list](https://github.com/gfx-rs/wgpu-native#bindings).

## Community

We have the Matrix space [![Matrix Space](https://img.shields.io/static/v1?label=Space&amp;message=%23Wgpu&amp;color=blue&amp;logo=matrix)](https://matrix.to/#/#Wgpu:matrix.org) with a few different rooms that form the wgpu community:

- [![Wgpu Matrix](https://img.shields.io/static/v1?label=wgpu-devs&amp;message=%23wgpu&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu:matrix.org) - discussion of the wgpu&#039;s development.
- [![Naga Matrix](https://img.shields.io/static/v1?label=naga-devs&amp;message=%23naga&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#naga:matrix.org) - discussion of the naga&#039;s development.
- [![User Matrix](https://img.shields.io/static/v1?label=wgpu-users&amp;message=%23wgpu-users&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu-users:matrix.org) - discussion of using the library and the surrounding ecosystem.
- [![Random Matrix](https://img.shields.io/static/v1?label=random&amp;message=%23wgpu-random&amp;color=blueviolet&amp;logo=matrix)](https://matrix.to/#/#wgpu-random:matrix.org) - discussion of everything else.

## Wiki

We have a [wiki](https://github.com/gfx-rs/wgpu/wiki) that serves as a knowledge base.

## Extension Specifications

While the core of wgpu is based on the WebGPU standard, we also support extensions that allow for features that the standard does not have yet.
For high-level documentation on how to use these extensions, see the individual specifications:

üß™EXPERIMENTALüß™ APIs are subject to change and may allow undefined behavior if used incorrectly.

- üß™EXPERIMENTALüß™ [Ray Tracing](./docs/api-specs/ray_tracing.md).
- üß™EXPERIMENTALüß™ [Mesh Shading](./docs/api-specs/mesh_shading.md).

## Supported Platforms

| API    | Windows            | Linux/Android      | macOS/iOS          | Web (wasm)         |
| ------ | ------------------ | ------------------ | ------------------ | ------------------ |
| Vulkan |         ‚úÖ         |         ‚úÖ         |         üåã         |                    |
| Metal  |                    |                    |         ‚úÖ         |                    |
| DX12   |         ‚úÖ         |                    |                    |                    |
| OpenGL |    üÜó (GL 3.3+)    |  üÜó (GL ES 3.0+)   |         üìê         |    üÜó (WebGL2)     |
| WebGPU |                    |                    |                    |         ‚úÖ         |

‚úÖ = First Class Support  
üÜó = Downlevel/Best Effort Support  
üìê = Requires the [ANGLE](#angle) translation layer (GL ES 3.0 only)  
üåã = Requires the [MoltenVK](https://vulkan.lunarg.com/sdk/home#mac) translation layer  
üõ†Ô∏è = Unsupported, though open to contributions

### Shader Support

wgpu supports shaders in [WGSL](https://gpuweb.github.io/gpuweb/wgsl/), SPIR-V, and GLSL.
Both [HLSL](https://github.com/Microsoft/DirectXShaderCompiler) and [GLSL](https://github.com/KhronosGroup/glslang)
have compilers to target SPIR-V. All of these shader languages can be used with any backend as we handle all of the conversions. Additionally, support for these shader inputs is not going away.

While WebGPU does not support any shading language other than WGSL, we will automatically convert your
non-WGSL shaders if you&#039;re running on WebGPU.

WGSL is always supported by default, but GLSL and SPIR-V need features enabled to compile in support.

Note that the WGSL specification is still under development,
so the [draft specification][wgsl spec] does not exactly describe what `wgpu` supports.
See [below](#tracking-the-webgpu-and-wgsl-draft-specifications) for details.

To enable SPIR-V shaders, enable the `spirv` feature of wgpu.
To enable GLSL shaders, enable the `glsl` feature of wgpu.

### Angle

[Angle](http://angleproject.org) is a translation layer from GLES to other backends developed by Google.
We support running our GLES3 backend over it in order to reach platforms DX11 support, which aren&#039;t accessible otherwise.
In order to run with Angle, the &quot;angle&quot; feature has to be enabled, and Angle libraries placed in a location visible to the application.
These binaries can be downloaded from [gfbuild-angle](https://github.com/DileSoft/gfbuild-angle) artifacts, [manual compilation](https://github.com/google/angle/blob/main/doc/DevSetup.md) may be required on Macs with Apple silicon.

On Windows, you generally need to copy them into the working directory, in the same directory as the executable, or somewhere in your path.
On Linux, you can point to them using `LD_LIBRARY_PATH` environment.

### MSRV policy

Due to complex dependants, we have two MSRV policies:

- `naga`, `wgpu-core`, `wgpu-hal`, and `wgpu-types`&#039;s MSRV is **1.76**.
- The rest of the workspace has an MSRV of **1.84**.

It is enforced on CI (in &quot;/.github/workflows/ci.yml&quot;) with the `CORE_MSRV` and `REPO_MSRV` variables.
This version can only be upgraded in breaking releases, though we release a breaking version every three months.

The `naga`, `wgpu-core`, `wgpu-hal`, and `wgpu-types` crates should never
require an MSRV ahead of Firefox&#039;s MSRV for nightly builds, as
determined by the value of `MINIMUM_RUST_VERSION` in
[`python/mozboot/mozboot/util.py`][util].

[util]: https://searchfox.org/mozilla-central/source/python/mozboot/mozboot/util.py

## Environment Variables

All testing and example infrastructure share the same set of environment variables that determine which Backend/GPU it will run on.

- `WGPU_ADAPTER_NAME` with a substring of the name of the adapter you want to use (ex. `1080` will match `NVIDIA GeForce 1080ti`).
- `WGPU_BACKEND` with a comma-separated list of the backends you want to use (`vulkan`, `metal`, `dx12`, or `gl`).
- `WGPU_POWER_PREF` with the power preference to choose when a specific adapter name isn&#039;t specified (`high`, `low` or `none`)
- `WGPU_DX12_COMPILER` with the DX12 shader compiler you wish to use (`dxc`, `static-dxc`, or `fxc`). Note that `dxc` requires `dxcompiler.dll` (min v1.8.2502) to be in the working directory, and `static-dxc` requires the `static-dxc` crate feature to be enabled. Otherwise, it will fall back to `fxc`.
- `WGPU_GLES_MINOR_VERSION` with the minor OpenGL ES 3 version number to request (`0`, `1`, `2` or `automatic`).
- `WGPU_ALLOW_UNDERLYING_NONCOMPLIANT_ADAPTER` with a boolean whether non-compliant drivers are enumerated (`0` for false, `1` for true).

When running the CTS, use the variables `DENO_WEBGPU_ADAPTER_NAME`, `DENO_WEBGPU_BACKEND`, `DENO_WEBGPU_POWER_PREFERENCE`.

## Testing

We have multiple methods of testing, each of which tests different qualities about wgpu. We automatically run our tests on CI. The current state of CI testing:

| Platform/Backend | Tests              | Notes                 |
| ---------------- | ------------------ | --------------------- |
| Windows/DX12     | :heavy_check_mark: | using WARP            |
| Windows/OpenGL   | :heavy_check_mark: | using llvmpipe        |
| MacOS/Metal      | :heavy_check_mark: | using hardware runner |
| Linux/Vulkan     | :heavy_check_mark: | using lavapipe        |
| Linux/OpenGL ES  | :heavy_check_mark: | using llvmpipe        |
| Chrome/WebGL     | :heavy_check_mark: | using swiftshader     |
| Chrome/WebGPU    | :x:                | not set up            |

### Core Test Infrastructure

We use a tool called [`cargo nextest`](https://github.com/nextest-rs/nextest) to run our tests.
To install it, run `cargo install cargo-nextest`.

To run the test suite:

```
cargo xtask test
```

To run the test suite on WebGL (currently incomplete):

```
cd wgpu
wasm-pack test --headless --chrome --no-default-features --features webgl --workspace
```

This will automatically run the tests using a packaged browser. Remove `--headless` to run the tests with whatever browser you wish at `http://localhost:8000`.

If you are a user and want a way to help contribute to wgpu, we always need more help writing test cases.

### WebGPU Conformance Test Suite

WebGPU includes a Conformance Test Suite to validate that implementations are
working correctly. We run cases from the CTS against wgpu using
[Deno](https://deno.com/). A [default list of enabled
tests](./cts_runner/test.lst) is automatically run on pull requests in CI.

To run the default set of CTS tests locally, run:

```
cargo xtask cts
```

You can also specify a test selector on the command line:

```
cargo xtask cts &#039;webgpu:api,operation,command_buffer,basic:*&#039;
```

Or supply your own test list in a file:

```
cargo xtask cts -f your_tests.lst
```

To find the full list of tests, go to the
[web version of the CTS](https://gpuweb.github.io/cts/standalone/?runnow=0&amp;worker=0&amp;debug=0&amp;q=webgpu:*).

The version of the CTS used by `cargo xtask cts` is specified in
[`cts_runner/revision.txt`](./cts_runner/revision.txt).

## Tracking the WebGPU and WGSL draft specifications

The `wgpu` crate is meant to be an idiomatic Rust translation of the [WebGPU API][webgpu spec].
That specification, along with its shading language, [WGSL][wgsl spec],
are both still in the &quot;Working Draft&quot; phase,
and while the general outlines are stable,
details change frequently.
Until the specification is stabilized, the `wgpu` crate and the version of WGSL it implements
will likely differ from what is specified,
as the implementation catches up.

Exactly which WGSL features `wgpu` supports depends on how you are using it:

- When running as native code, `wgpu` uses the [Naga][naga] crate
  to translate WGSL code into the shading language of your platform&#039;s native GPU API.
  Naga has [a milestone][naga wgsl milestone]
  for catching up to the WGSL specification,
  but in general, there is no up-to-date summary
  of the differences between Naga and the WGSL spec.

- When running in a web browser (by compilation to WebAssembly)
  without the `&quot;webgl&quot;` feature enabled,
  `wgpu` relies on the browser&#039;s own WebGPU implementation.
  WGSL shaders are simply passed through to the browser,
  so that determines which WGSL features you can use.

- When running in a web browser with `wgpu`&#039;s `&quot;webgl&quot;` feature enabled,
  `wgpu` uses Naga to translate WGSL programs into GLSL.
  This uses the same version of Naga as if you were running `wgpu` as native code.

[webgpu spec]: https://www.w3.org/TR/webgpu/
[wgsl spec]: https://gpuweb.github.io/gpuweb/wgsl/
[naga]: https://github.com/gfx-rs/naga/
[naga wgsl milestone]: https://github.com/gfx-rs/naga/milestone/4

## Coordinate Systems

wgpu uses the coordinate systems of D3D and Metal:

| Render                                              | Texture                                               |
| --------------------------------------------------- | ----------------------------------------------------- |
| ![render_coordinates](./docs/render_coordinates.png) | ![texture_coordinates](./docs/texture_coordinates.png) |
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>