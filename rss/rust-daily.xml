<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Thu, 26 Feb 2026 00:08:06 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[ruvnet/ruvector]]></title>
            <link>https://github.com/ruvnet/ruvector</link>
            <guid>https://github.com/ruvnet/ruvector</guid>
            <pubDate>Thu, 26 Feb 2026 00:08:06 GMT</pubDate>
            <description><![CDATA[RuVector is a High Performance, Real-Time, Self-Learning, Vector Graph Neural Network, and Database built in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ruvnet/ruvector">ruvnet/ruvector</a></h1>
            <p>RuVector is a High Performance, Real-Time, Self-Learning, Vector Graph Neural Network, and Database built in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,159</p>
            <p>Forks: 150</p>
            <p>Stars today: 437 stars today</p>
            <h2>README</h2><pre># RuVector

[![Crates.io](https://img.shields.io/crates/v/ruvector-core.svg)](https://crates.io/crates/ruvector-core)
[![npm](https://img.shields.io/npm/v/ruvector.svg)](https://www.npmjs.com/package/ruvector)
[![npm Downloads](https://img.shields.io/npm/dt/ruvector.svg?label=total)](https://www.npmjs.com/package/ruvector)
[![npm Downloads](https://img.shields.io/npm/dm/ruvector.svg?label=monthly)](https://www.npmjs.com/package/ruvector)
[![HuggingFace](https://img.shields.io/badge/ü§ó-RuvLTRA_Models-yellow.svg)](https://huggingface.co/ruv/ruvltra)
[![ruv.io](https://img.shields.io/badge/ruv.io-website-purple.svg)](https://ruv.io)
[![MIT License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

**The vector database that gets smarter the more you use it ‚Äî and now ships as a cognitive container.**

```bash
npx ruvector
```

Most vector databases are static ‚Äî they store embeddings and search them. That&#039;s it. RuVector is different: it learns from every query, runs LLMs locally, scales horizontally, boots as a Linux microservice from a single file, and costs nothing to operate.

| | Pinecone/Weaviate | RuVector |
|---|---|---|
| üß† **Search improves over time** | ‚ùå | ‚úÖ The more you search, the better results get |
| ü§ñ **Run LLMs locally** | ‚ùå | ‚úÖ Run AI models on your own machine for free |
| üîó **Graph queries** | ‚ùå | ‚úÖ Ask questions about relationships between data |
| üìö **Self-learning** | ‚ùå | ‚úÖ System watches what works and gets smarter |
| üöÄ **Self-booting microservice** | ‚ùå | ‚úÖ [One file boots into a running service](./crates/rvf/README.md) in 125 ms |
| ‚ö° **Real-time graph updates** | ‚ùå Must rebuild | ‚úÖ Update connections instantly, no downtime |
| üì¶ **Single-file deployment** | ‚ùå Server required | ‚úÖ One file ‚Äî copy it anywhere and it just works |
| üîê **Tamper-proof audit trail** | ‚ùå | ‚úÖ Every operation is cryptographically recorded |
| üåê **Works offline** | ‚ùå | ‚úÖ Runs in browsers, phones, IoT, and bare metal |
| üí∞ **Cost** | Per-query pricing | ‚úÖ Free forever ‚Äî open source (MIT) |
| üìà **Scales horizontally** | üí∞ Paid tiers | ‚úÖ Add nodes freely, no per-vector fees |
| üåø **Git-like branching** | ‚ùå | ‚úÖ Branch your data like code ‚Äî only changes are copied |
| ‚ö° **Sublinear Solvers** | ‚ùå | ‚úÖ O(log n) sparse linear systems, PageRank, spectral methods |
| üî¨ **Proof-Gated Graph Transformers** | ‚ùå | ‚úÖ 8 verified modules: physics, bio, manifold, temporal, economic |

**One package. Everything included:** vector search, graph queries, GNN learning, [proof-gated graph transformers](./crates/ruvector-graph-transformer) (8 verified modules ‚Äî physics, biological, manifold, temporal, economic), distributed clustering, local LLMs, 46 attention mechanisms, cognitive containers ([RVF](./crates/rvf/README.md) ‚Äî self-booting `.rvf` files with eBPF, witness chains, and COW branching), and WASM support.

&lt;details&gt;
&lt;summary&gt;üìã See Full Capabilities (53 features)&lt;/summary&gt;

**Core Vector Database**
| # | Capability | What It Does |
|---|------------|--------------|
| 1 | **Store vectors** | Embeddings from OpenAI, Cohere, local ONNX with HNSW indexing |
| 2 | **Query with Cypher** | Graph queries like Neo4j (`MATCH (a)-[:SIMILAR]-&gt;(b)`) |
| 3 | **The index learns** | GNN layers make search results improve over time |
| 4 | **Hyperbolic HNSW** | Hierarchical data in hyperbolic space for better tree structures |
| 5 | **Compress automatically** | 2-32x memory reduction with adaptive tiered compression |

**Distributed Systems**
| # | Capability | What It Does |
|---|------------|--------------|
| 6 | **Raft consensus** | Leader election, log replication, fault-tolerant coordination |
| 7 | **Multi-master replication** | Vector clocks, conflict resolution, geo-distributed sync |
| 8 | **Burst scaling** | 10-50x capacity scaling for traffic spikes |
| 9 | **Auto-sharding** | Automatic data partitioning across nodes |

**AI &amp; Machine Learning**
| # | Capability | What It Does |
|---|------------|--------------|
| 10 | **Run LLMs locally** | ruvllm with GGUF, Metal/CUDA/ANE acceleration |
| 11 | **RuvLTRA models** | Pre-trained GGUF for routing &amp; embeddings (&lt;10ms) ‚Üí [HuggingFace](https://huggingface.co/ruv/ruvltra) |
| 12 | **SONA learning** | Self-Optimizing Neural Architecture with LoRA, EWC++ |
| 13 | **46 attention mechanisms** | Flash, linear, graph, hyperbolic, mincut-gated (50% compute) |
| 14 | **Spiking neural networks** | Event-driven neuromorphic computing |
| 15 | **Mincut-gated transformer** | Dynamic attention via graph min-cut optimization |
| 16 | **Route AI requests** | Semantic routing + FastGRNN for LLM optimization |
| 17 | **Sublinear Solvers in SQL** | PageRank, CG, Laplacian solver ‚Äî O(log n) to O(‚àön) via PostgreSQL |
| 18 | **Math Distances in SQL** | Wasserstein, Sinkhorn OT, KL divergence, spectral clustering |
| 19 | **Topological Data Analysis** | Persistent homology, Betti numbers, embedding drift detection |
| 20 | **Sona Learning in SQL** | Micro-LoRA trajectory learning with EWC++ forgetting prevention |
| 21 | **Domain Expansion** | Cross-domain transfer learning with contextual bandits |
| 22 | **Extended Attention** | O(n) linear, MoE, hyperbolic, sliding window attention in SQL |
| 52 | **Proof-Gated Graph Transformers** | 8 verified modules: every graph mutation requires a formal proof |
| 53 | **Verified Training** | Training with certificates, delta-apply rollback, fail-closed invariants |

**Cognitive Containers ([RVF](./crates/rvf/README.md))**
| # | Capability | What It Does |
|---|------------|--------------|
| 23 | **Self-boot as a microservice** | A `.rvf` file contains a real Linux kernel ‚Äî drop it on a VM and it boots in 125 ms |
| 24 | **eBPF acceleration** | Hot vectors served in kernel data path via XDP, socket filter, and TC programs |
| 25 | **5.5 KB WASM runtime** | Same file runs queries in a browser tab with zero backend |
| 26 | **COW branching** | Git-like copy-on-write ‚Äî 1M-vector parent, 100 edits = ~2.5 MB child |
| 27 | **Witness chains** | Tamper-evident hash-linked audit trail for every operation |
| 28 | **Post-quantum signatures** | ML-DSA-65 and SLH-DSA-128s alongside Ed25519 |
| 29 | **DNA-style lineage** | Track parent/child derivation chains with cryptographic hashes |
| 30 | **24 segment types** | VEC, INDEX, KERNEL, EBPF, WASM, COW_MAP, WITNESS, CRYPTO, and 16 more |

**Specialized Processing**
| # | Capability | What It Does |
|---|------------|--------------|
| 31 | **SciPix OCR** | LaTeX/MathML extraction from scientific documents |
| 32 | **DAG workflows** | Self-learning directed acyclic graph execution |
| 33 | **Cognitum Gate** | Cognitive AI gateway with TileZero acceleration |
| 34 | **FPGA transformer** | Hardware-accelerated transformer inference |
| 35 | **Quantum coherence** | ruQu for quantum error correction via dynamic min-cut |
| 36 | **Sublinear Solvers** | 8 algorithms: Neumann, CG, Forward Push, TRUE, BMSSP ‚Äî O(log n) to O(‚àön) |

**Genomics &amp; Health**
| # | Capability | What It Does |
|---|------------|--------------|
| 37 | **rvDNA genomic analysis** | Variant calling, protein translation, HNSW k-mer search in 12 ms |
| 38 | **`.rvdna` file format** | AI-native binary with pre-computed vectors, tensors, and embeddings |
| 39 | **Instant diagnostics** | Sickle cell, cancer mutations, drug dosing ‚Äî runs on any device |
| 40 | **Privacy-first WASM** | Browser-based genomics, data never leaves the device |
| 41 | **Health biomarker engine** | Composite polygenic risk scoring (20 SNPs, 6 gene-gene interactions, 2 us) |
| 42 | **Streaming biomarkers** | Real-time anomaly detection, CUSUM changepoints, trend analysis (&gt;100k readings/sec) |

**Platform &amp; Integration**
| # | Capability | What It Does |
|---|------------|--------------|
| 43 | **Run anywhere** | Node.js, browser (WASM), edge (rvLite), HTTP server, Rust, bare metal |
| 44 | **Drop into Postgres** | pgvector-compatible extension with SIMD acceleration |
| 45 | **MCP integration** | Model Context Protocol server for AI assistant tools |
| 46 | **Cloud deployment** | One-click deploy to Cloud Run, Kubernetes |
| 47 | **13 Rust crates + 4 npm packages** | [RVF SDK](./crates/rvf/README.md) published on [crates.io](https://crates.io/crates/rvf-runtime) and [npm](https://www.npmjs.com/package/@ruvector/rvf) |

**Self-Learning &amp; Adaptation**
| # | Capability | What It Does |
|---|------------|--------------|
| 48 | **Self-learning hooks** | Q-learning, neural patterns, HNSW memory |
| 49 | **ReasoningBank** | Trajectory learning with verdict judgment |
| 50 | **Economy system** | Tokenomics, CRDT-based distributed state |
| 51 | **Agentic synthesis** | Multi-agent workflow composition |

&lt;/details&gt;

*Think of it as: **Pinecone + Neo4j + PyTorch + llama.cpp + postgres + etcd + Docker** ‚Äî in one Rust package.*

*The [RVF cognitive container](./crates/rvf/README.md) is the Docker part: a single `.rvf` file that stores vectors, ships models, boots as a Linux microservice in 125 ms, accelerates queries via eBPF, branches like Git at cluster granularity, and proves every operation through a cryptographic witness chain ‚Äî all without external dependencies.*

---

### Ecosystem: AI Agent Orchestration

RuVector powers two major AI orchestration platforms:

| Platform | Purpose | Install |
|----------|---------|---------|
| [**Claude-Flow**](https://github.com/ruvnet/claude-flow) | Enterprise multi-agent orchestration for Claude Code | `npx @claude-flow/cli@latest` |
| [**Agentic-Flow**](https://github.com/ruvnet/agentic-flow) | Standalone AI agent framework (any LLM provider) | `npx agentic-flow@latest` |

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Claude-Flow v3&lt;/strong&gt; ‚Äî Turn Claude Code into a collaborative AI team&lt;/summary&gt;

**54+ specialized agents** working together on complex software engineering tasks:

```bash
# Install
npx @claude-flow/cli@latest init --wizard

# Spawn a swarm
npx @claude-flow/cli@latest swarm init --topology hierarchical --max-agents 8
```

**Key Features:**
- **SONA Learning**: Sub-50ms adaptive routing, learns optimal patterns over time
- **Queen-led Swarms**: Byzantine fault-tolerant consensus with 5 protocols (Raft, Gossip, CRDT)
- **HNSW Memory**: 150x-12,500x faster pattern retrieval via RuVector
- **175+ MCP Tools**: Native Model Context Protocol integration
- **Cost Optimization**: 3-tier routing extends Claude Code quota by 2.5x
- **Security**: AIDefence threat detection (&lt;10ms), prompt injection blocking

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Agentic-Flow v2&lt;/strong&gt; ‚Äî Production AI agents for any cloud&lt;/summary&gt;

**66 self-learning agents** with Claude Agent SDK, deployable to any cloud:

```bash
# Install
npx agentic-flow@latest

# Or with npm
npm install agentic-flow
```

**Key Features:**
- **SONA Architecture**: &lt;1ms adaptive learning, +55% quality improvement
- **Flash Attention**: 2.49x JS speedup, 7.47x with NAPI bindings
- **213 MCP Tools**: Swarm management, memory, GitHub integration
- **Agent Booster**: 352x faster code editing for simple transforms
- **Multi-Provider**: Claude, GPT, Gemini, Cohere, local models with failover
- **Graph Reasoning**: GNN query refinement with +12.4% recall improvement

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;rvDNA&lt;/strong&gt; ‚Äî AI-native genomic diagnostics, instant and available to everyone&lt;/summary&gt;

**Using AI to make the world a healthier place.** rvDNA puts genomic diagnostics on any device ‚Äî a phone, a laptop, a browser tab ‚Äî in 12 milliseconds. No cloud, no GPU, no subscription. Private by default.

```bash
cargo add rvdna              # Rust
npm install @ruvector/rvdna  # JavaScript / TypeScript
```

| What It Does | How |
|---|---|
| Find mutations (sickle cell, cancer) | Bayesian variant calling, 155 ns/SNP |
| Translate DNA to protein | Full codon table + GNN contact graphs |
| Predict biological age | Horvath clock, 353 CpG sites |
| Recommend drug doses | CYP2D6 star alleles + CPIC guidelines |
| Score health risks | 20 SNPs, 6 gene-gene interactions, composite risk scoring in 2 us |
| Stream biomarker data | Real-time anomaly detection, CUSUM changepoints, &gt;100k readings/sec |
| Search genomes by similarity | HNSW k-mer vectors, O(log N) |
| Store pre-computed AI features | `.rvdna` binary format ‚Äî open and instant |

- **Rust crate**: [crates.io/crates/rvdna](https://crates.io/crates/rvdna)
- **npm package**: [@ruvector/rvdna](https://www.npmjs.com/package/@ruvector/rvdna) (NAPI-RS native + JS fallback)
- **Source**: [examples/dna](./examples/dna)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;RVF Cognitive Containers&lt;/strong&gt; ‚Äî One file that stores, boots, and proves everything&lt;/summary&gt;

**[RVF (RuVector Format)](./crates/rvf/README.md)** is a universal binary substrate that merges database, model, graph engine, kernel, and attestation into a single deployable file. A `.rvf` file can store vector embeddings, carry LoRA adapter deltas, embed GNN graph state, include a bootable Linux microkernel, run queries in a 5.5 KB WASM runtime, and prove every operation through a cryptographic witness chain ‚Äî all in one file that runs anywhere from a browser to bare metal.

This is not a database format. It is an **executable knowledge unit**.

```bash
cargo install rvf-cli                          # CLI tool
cargo add rvf-runtime                          # Rust library
npm install @ruvector/rvf                      # TypeScript SDK
npx @ruvector/rvf-mcp-server --transport stdio # MCP server for AI agents
```

| What It Does | How |
|---|---|
| Self-boot as a microservice | Real Linux kernel in the file, boots in 125 ms on QEMU/KVM |
| Hardware-speed lookups | eBPF programs (XDP, TC, socket filter) bypass userspace entirely |
| Run in any browser | 5.5 KB WASM runtime, zero backend |
| Git-like branching | COW at cluster granularity ‚Äî 1M vectors, 100 edits = ~2.5 MB child |
| Tamper-evident audit | Hash-linked witness chain for every insert, query, and deletion |
| Post-quantum signatures | ML-DSA-65 and Ed25519 signing on every segment |
| DNA-style lineage | Parent/child derivation chains with cryptographic verification |
| 24 segment types | VEC, INDEX, KERNEL, EBPF, WASM, COW_MAP, WITNESS, CRYPTO, and 16 more |

**Rust crates** (13): [`rvf-types`](https://crates.io/crates/rvf-types) `rvf-wire` `rvf-manifest` `rvf-quant` `rvf-index` `rvf-crypto` [`rvf-runtime`](https://crates.io/crates/rvf-runtime) `rvf-kernel` `rvf-ebpf` `rvf-launch` `rvf-server` `rvf-import` [`rvf-cli`](https://crates.io/crates/rvf-cli)

**npm packages** (4): [`@ruvector/rvf`](https://www.npmjs.com/package/@ruvector/rvf) [`@ruvector/rvf-node`](https://www.npmjs.com/package/@ruvector/rvf-node) [`@ruvector/rvf-wasm`](https://www.npmjs.com/package/@ruvector/rvf-wasm) [`@ruvector/rvf-mcp-server`](https://www.npmjs.com/package/@ruvector/rvf-mcp-server)

- **Security Hardened RVF** ([`examples/security_hardened.rvf`](./examples/security_hardened.rvf)) ‚Äî 2.1 MB sealed artifact with 22 verified capabilities: TEE attestation (SGX/SEV-SNP/TDX/ARM CCA), AIDefence (injection/jailbreak/PII/exfil), hardened Linux microkernel, eBPF firewall, Ed25519 signing, 6-role RBAC, Coherence Gate, 30-entry witness chain, Paranoid policy, COW branching, audited k-NN. See [ADR-042](./docs/adr/ADR-042-Security-RVF-AIDefence-TEE.md).
- **Full documentation**: [crates/rvf/README.md](./crates/rvf/README.md)
- **ADR-030**: [Cognitive Container Architecture](./docs/adr/ADR-030-rvf-cognitive-container.md)
- **ADR-031**: [COW Branching &amp; Real Containers](./docs/adr/ADR-031-rvcow-branching-and-real-cognitive-containers.md)
- **ADR-042**: [Security RVF ‚Äî AIDefence + TEE](./docs/adr/ADR-042-Security-RVF-AIDefence-TEE.md)
- **46 runnable examples**: [examples/rvf/examples/](./examples/rvf/examples/)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Sublinear-Time Solver&lt;/strong&gt; ‚Äî O(log n) sparse linear systems for graph analytics and AI&lt;/summary&gt;

**[ruvector-solver](./crates/ruvector-solver/README.md)** provides 8 iterative algorithms for sparse linear systems, achieving O(log n) to O(‚àön) complexity ‚Äî orders of magnitude faster than dense O(n¬≥) solvers. Powers Prime Radiant coherence, GNN message passing, spectral methods, and PageRank computation.

```bash
cargo add ruvector-solver --features all-algorithms
```

| Algorithm | Complexity | Best For |
|-----------|-----------|----------|
| **Neumann Series** | O(k ¬∑ nnz) | Diagonally dominant, fast convergence |
| **Conjugate Gradient** | O(‚àöŒ∫ ¬∑ log(1/Œµ) ¬∑ nnz) | Gold-standard SPD solver |
| **Forward Push** | O(1/Œµ) | Single-source PageRank |
| **Backward Push** | O(1/Œµ) | Reverse relevance computation |
| **Hybrid Random Walk** | O(‚àön/Œµ) | Pairwise relevance, Monte Carlo |
| **TRUE** | O(log n) amortized | Large-scale Laplacian systems |
| **BMSSP** | O(nnz ¬∑ log n) | Multigrid hierarchical solve |
| **Auto Router** | Automatic | Selects optimal algorithm |

**Key optimizations**: AVX2 SIMD SpMV, fused residual kernels, bounds-check elimination, arena allocator

**Supporting crates**:
- [`ruvector-attn-mincut`](./crates/ruvector-attn-mincut/README.md) ‚Äî Min-cut gating as alternative to softmax attention
- [`ruvector-coherence`](./crates/ruvector-coherence/README.md) ‚Äî Coherence measurement for attention comparison
- [`ruvector-profiler`](./crates/ruvector-profiler/README.md) ‚Äî Memory, power, and latency benchmarking

- **177 tests** | 5 Criterion benchmarks | WASM + NAPI bindings
- **ADR documentation**: [docs/research/sublinear-time-solver/](./docs/research/sublinear-time-solver/)

&lt;/details&gt;

---

## How the GNN Works

Traditional vector search:
```
Query ‚Üí HNSW Index ‚Üí Top K Results
```

RuVector with GNN:
```
Query ‚Üí HNSW Index ‚Üí GNN Layer ‚Üí Enhanced Results
                ‚Üë                      ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ learns from ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

The GNN layer:
1. Takes your query and its nearest neighbors
2. Applies multi-head attention to weigh which neighbors matter
3. Updates representations based on graph structure
4. Returns better-ranked results

Over time, frequently-accessed paths get reinforced, making common queries faster and more accurate.


## Quick Start

### One-Line Install

```bash
# Interactive installer - lists all packages
npx ruvector install

# Or install directly
npm install ruvector
npx ruvector

# Self-learning hooks for Claude Code
npx @ruvector/cli hooks init
npx @ruvector/cli hooks install

# LLM runtime (SONA learning, HNSW memory)
npm install @ruvector/ruvllm
```

### Node.js / Browser

```bash
# Install
npm install ruvector

# Or try instantly
npx ruvector
```


&lt;details&gt;
&lt;summary&gt;üìä Comparison with Other Vector Databases&lt;/summary&gt;

| Feature | RuVector | Pinecone | Qdrant | Milvus | ChromaDB |
|---------|----------|----------|--------|--------|----------|
| **Latency (p50)** | **61¬µs** | ~2ms | ~1ms | ~5ms | ~50ms |
| **Memory (1M vec)** | 200MB* | 2GB | 1.5GB | 1GB | 3GB |
| **Graph Queries** | ‚úÖ Cypher | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **SPARQL/RDF** | ‚úÖ W3C 1.1 | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Hyperedges** | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Dynamic Min-Cut** | ‚úÖ n^0.12 | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Sublinear Solvers** | ‚úÖ 8 algorithms | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **O(log n) Graph Solve** | ‚úÖ TRUE+BMSSP | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Self-Learning (GNN)** | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Runtime Adaptation (SONA)** | ‚úÖ LoRA+EWC++ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **AI Agent Routing** | ‚úÖ Tiny Dancer | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Attention Mechanisms** | ‚úÖ 40 types | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Coherence Gate** | ‚úÖ Prime-Radiant | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Hyperbolic Embeddings** | ‚úÖ Poincar√©+Lorentz | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Local Embeddings** | ‚úÖ 8+ models | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **PostgreSQL Extension** | ‚úÖ 77+ functions | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **SIMD Optimization** | ‚úÖ AVX-512/NEON | Partial | ‚úÖ | ‚úÖ | ‚ùå |
| **Metadata Filtering** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| **Sparse Vectors** | ‚úÖ BM25/TF-IDF | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |
| **Raft Consensus** | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå | ‚ùå |
| **Multi-Master Replication** | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ | ‚ùå |
| **Auto-Sharding** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |
| **Auto-Compression** | ‚úÖ 2-32x | ‚ùå | ‚ùå | ‚úÖ | ‚ùå |
| **Sna

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[katanemo/plano]]></title>
            <link>https://github.com/katanemo/plano</link>
            <guid>https://github.com/katanemo/plano</guid>
            <pubDate>Thu, 26 Feb 2026 00:08:05 GMT</pubDate>
            <description><![CDATA[Delivery infrastructure for agentic apps - Plano is an AI-native proxy and data plane that offloads plumbing work, so you stay focused on your agent's core logic (via any AI framework).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/katanemo/plano">katanemo/plano</a></h1>
            <p>Delivery infrastructure for agentic apps - Plano is an AI-native proxy and data plane that offloads plumbing work, so you stay focused on your agent's core logic (via any AI framework).</p>
            <p>Language: Rust</p>
            <p>Stars: 5,547</p>
            <p>Forks: 329</p>
            <p>Stars today: 205 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/source/_static/img/PlanoTagline.svg&quot; alt=&quot;Plano Logo&quot; width=&quot;75%&quot; height=auto&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;

 _The AI-native proxy server and data plane for agentic apps._&lt;br&gt;&lt;br&gt;
 Plano pulls out the rote plumbing work and decouples you from brittle framework abstractions, centralizing what shouldn‚Äôt be bespoke in every codebase - like agent routing and orchestration, rich agentic signals and traces for continuous improvement, guardrail filters for safety and moderation, and smart LLM routing APIs for model agility. Use any language or AI framework, and deliver agents faster to production.


[Quickstart Guide](https://docs.planoai.dev/get_started/quickstart.html) ‚Ä¢
[Build Agentic Apps with Plano](#Build-Agentic-Apps-with-Plano) ‚Ä¢
[Documentation](https://docs.planoai.dev) ‚Ä¢
[Contact](#Contact)

[![CI](https://github.com/katanemo/plano/actions/workflows/ci.yml/badge.svg)](https://github.com/katanemo/plano/actions/workflows/ci.yml)
[![Docker Image](https://github.com/katanemo/plano/actions/workflows/docker-push-main.yml/badge.svg)](https://github.com/katanemo/plano/actions/workflows/docker-push-main.yml)
[![Build and Deploy Documentation](https://github.com/katanemo/plano/actions/workflows/static.yml/badge.svg)](https://github.com/katanemo/plano/actions/workflows/static.yml)

Star ‚≠êÔ∏è the repo if you found Plano useful ‚Äî new releases and updates land here first.
&lt;/div&gt;

# Overview
Building agentic demos is easy. Shipping agentic applications safely, reliably, and repeatably to production is hard. After the thrill of a quick hack, you end up building the ‚Äúhidden middleware‚Äù to reach production: routing logic to reach the right agent, guardrail hooks for safety and moderation, evaluation and observability glue for continuous learning, and model/provider quirks scattered across frameworks and application code.

Plano solves this by moving core delivery concerns into a unified, out-of-process dataplane.

- **üö¶ Orchestration:** Low-latency orchestration between agents; add new agents without modifying app code.
- **üîó Model Agility:** Route [by model name, alias (semantic names) or automatically via preferences](#use-plano-as-a-llm-router).
- **üïµ Agentic Signals&amp;trade;:** Zero-code capture of [Signals](https://docs.planoai.dev/concepts/signals.html) plus OTEL traces/metrics across every agent.
- **üõ°Ô∏è Moderation &amp; Memory Hooks:** Build jailbreak protection, add moderation policies and memory consistently via [Filter Chains](https://docs.planoai.dev/concepts/filter_chain.html).

Plano pulls rote plumbing out of your framework so you can stay focused on what matters most: the core product logic of your agentic applications. Plano is backed by [industry-leading LLM research](https://planoai.dev/research) and built on [Envoy](https://envoyproxy.io) by its core contributors, who built critical infrastructure at scale for modern worklaods.

**High-Level Network Sequence Diagram**:
![high-level network plano arcitecture for Plano](docs/source/_static/img/plano_network_diagram_high_level.png)

**Jump to our [docs](https://docs.planoai.dev)** to learn how you can use Plano to improve the speed, safety and obervability of your agentic applications.

&gt; [!IMPORTANT]
&gt; Plano and the Arch family of LLMs (like Plano-Orchestrator-4B, Arch-Router, etc) are hosted free of charge in the US-central region to give you a great first-run developer experience of Plano. To scale and run in production, you can either run these LLMs locally or contact us on [Discord](https://discord.gg/pGZf2gcwEc) for API keys.

---

## Build Agentic Apps with Plano

Plano handles **orchestration, model management, and observability** as modular building blocks - letting you configure only what you need (edge proxying for agentic orchestration and guardrails, or LLM routing from your services, or both together) to fit cleanly into existing architectures. Below is a simple multi-agent travel agent built with Plano that showcases all three core capabilities

&gt; üìÅ **Full working code:** See [`demos/agent_orchestration/travel_agents/`](demos/agent_orchestration/travel_agents/) for complete weather and flight agents you can run locally.



### 1. Define Your Agents in YAML

```yaml
# config.yaml
version: v0.3.0

# What you declare: Agent URLs and natural language descriptions
# What you don&#039;t write: Intent classifiers, routing logic, model fallbacks, provider adapters, or tracing instrumentation

agents:
  - id: weather_agent
    url: http://localhost:10510
  - id: flight_agent
    url: http://localhost:10520

model_providers:
  - model: openai/gpt-4o
    access_key: $OPENAI_API_KEY
    default: true
  - model: anthropic/claude-3-5-sonnet
    access_key: $ANTHROPIC_API_KEY

listeners:
  - type: agent
    name: travel_assistant
    port: 8001
    router: plano_orchestrator_v1  # Powered by our 4B-parameter routing model. You can change this to different models
    agents:
      - id: weather_agent
        description: |
          Gets real-time weather and forecasts for any city worldwide.
          Handles: &quot;What&#039;s the weather in Paris?&quot;, &quot;Will it rain in Tokyo?&quot;

      - id: flight_agent
        description: |
          Searches flights between airports with live status and schedules.
          Handles: &quot;Flights from NYC to LA&quot;, &quot;Show me flights to Seattle&quot;

tracing:
  random_sampling: 100  # Auto-capture traces for evaluation
```

### 2. Write Simple Agent Code

Your agents are just HTTP servers that implement the OpenAI-compatible chat completions endpoint. Use any language or framework:

```python
# weather_agent.py
from fastapi import FastAPI, Request
from fastapi.responses import StreamingResponse
from openai import AsyncOpenAI

app = FastAPI()

# Point to Plano&#039;s LLM gateway - it handles model routing for you
llm = AsyncOpenAI(base_url=&quot;http://localhost:12001/v1&quot;, api_key=&quot;EMPTY&quot;)

@app.post(&quot;/v1/chat/completions&quot;)
async def chat(request: Request):
    body = await request.json()
    messages = body.get(&quot;messages&quot;, [])
    days = 7

    # Your agent logic: fetch data, call APIs, run tools
    # See demos/agent_orchestration/travel_agents/ for the full implementation
    weather_data = await get_weather_data(request, messages, days)

    # Stream the response back through Plano
    async def generate():
        stream = await llm.chat.completions.create(
            model=&quot;openai/gpt-4o&quot;,
            messages=[{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: f&quot;Weather: {weather_data}&quot;}, *messages],
            stream=True
        )
        async for chunk in stream:
            yield f&quot;data: {chunk.model_dump_json()}\n\n&quot;

    return StreamingResponse(generate(), media_type=&quot;text/event-stream&quot;)
```

### 3. Start Plano &amp; Query Your Agents

**Prerequisites:** Follow the [prerequisites guide](https://docs.planoai.dev/get_started/quickstart.html#prerequisites) to install Plano and set up your environment.

```bash
# Start Plano
planoai up config.yaml
...

# Query - Plano intelligently routes to both agents in a single conversation
curl http://localhost:8001/v1/chat/completions \
  -H &quot;Content-Type: application/json&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gpt-4o&quot;,
    &quot;messages&quot;: [
      {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;I want to travel from NYC to Paris next week. What is the weather like there, and can you find me some flights?&quot;}
    ]
  }&#039;
# ‚Üí Plano routes to weather_agent for Paris weather ‚úì
# ‚Üí Then routes to flight_agent for NYC ‚Üí Paris flights ‚úì
# ‚Üí Returns a complete travel plan with both weather info and flight options
```

### 4. Get Observability and Model Agility for Free

Every request is traced end-to-end with OpenTelemetry - no instrumentation code needed.

![Atomatic Tracing](docs/source/_static/img/demo_tracing.png)

### What You Didn&#039;t Have to Build

| Infrastructure Concern | Without Plano | With Plano |
|---------|---------------|------------|
| **Agent Orchestration** | Write intent classifier + routing logic | Declare agent descriptions in YAML |
| **Model Management** | Handle each provider&#039;s API quirks | Unified LLM APIs with state management |
| **Rich Tracing** | Instrument every service with OTEL | Automatic end-to-end traces and logs |
| **Learning Signals** | Build pipeline to capture/export spans | Zero-code agentic signals |
| **Adding Agents** | Update routing code, test, redeploy | Add to config, restart |

**Why it&#039;s efficient:** Plano uses purpose-built, lightweight LLMs (like our 4B-parameter orchestrator) instead of heavyweight frameworks or GPT-4 for routing - giving you production-grade routing at a fraction of the cost and latency.

---

## Contact
To get in touch with us, please join our [discord server](https://discord.gg/pGZf2gcwEc). We actively monitor that and offer support there.

## Getting Started

Ready to try Plano? Check out our comprehensive documentation:

- **[Quickstart Guide](https://docs.planoai.dev/get_started/quickstart.html)** - Get up and running in minutes
- **[LLM Routing](https://docs.planoai.dev/guides/llm_router.html)** - Route by model name, alias, or intelligent preferences
- **[Agent Orchestration](https://docs.planoai.dev/guides/orchestration.html)** - Build multi-agent workflows
- **[Filter Chains](https://docs.planoai.dev/concepts/filter_chain.html)** - Add guardrails, moderation, and memory hooks
- **[Prompt Targets](https://docs.planoai.dev/concepts/prompt_target.html)** - Turn prompts into deterministic API calls
- **[Observability](https://docs.planoai.dev/guides/observability/observability.html)** - Traces, metrics, and logs

## Contribution
We would love feedback on our [Roadmap](https://github.com/orgs/katanemo/projects/1) and we welcome contributions to **Plano**! Whether you&#039;re fixing bugs, adding new features, improving documentation, or creating tutorials, your help is much appreciated. Please visit our [Contribution Guide](CONTRIBUTING.md) for more details

Star ‚≠êÔ∏è the repo if you found Plano useful ‚Äî new releases and updates land here first.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[bytecodealliance/wasmtime]]></title>
            <link>https://github.com/bytecodealliance/wasmtime</link>
            <guid>https://github.com/bytecodealliance/wasmtime</guid>
            <pubDate>Thu, 26 Feb 2026 00:08:04 GMT</pubDate>
            <description><![CDATA[A lightweight WebAssembly runtime that is fast, secure, and standards-compliant]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bytecodealliance/wasmtime">bytecodealliance/wasmtime</a></h1>
            <p>A lightweight WebAssembly runtime that is fast, secure, and standards-compliant</p>
            <p>Language: Rust</p>
            <p>Stars: 17,636</p>
            <p>Forks: 1,625</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;h1&gt;&lt;code&gt;wasmtime&lt;/code&gt;&lt;/h1&gt;

  &lt;p&gt;
    &lt;strong&gt;A standalone runtime for
    &lt;a href=&quot;https://webassembly.org/&quot;&gt;WebAssembly&lt;/a&gt;&lt;/strong&gt;
  &lt;/p&gt;

  &lt;strong&gt;A &lt;a href=&quot;https://bytecodealliance.org/&quot;&gt;Bytecode Alliance&lt;/a&gt; project&lt;/strong&gt;

  &lt;p&gt;
    &lt;a href=&quot;https://github.com/bytecodealliance/wasmtime/actions?query=workflow%3ACI&quot;&gt;&lt;img src=&quot;https://github.com/bytecodealliance/wasmtime/workflows/CI/badge.svg&quot; alt=&quot;build status&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://bytecodealliance.zulipchat.com/#narrow/stream/217126-wasmtime&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/zulip-join_chat-brightgreen.svg&quot; alt=&quot;zulip chat&quot; /&gt;&lt;/a&gt;
    &lt;img src=&quot;https://img.shields.io/badge/rustc-stable+-green.svg&quot; alt=&quot;supported rustc stable&quot; /&gt;
    &lt;a href=&quot;https://docs.rs/wasmtime&quot;&gt;&lt;img src=&quot;https://docs.rs/wasmtime/badge.svg&quot; alt=&quot;Documentation Status&quot; /&gt;&lt;/a&gt;
  &lt;/p&gt;

  &lt;h3&gt;
    &lt;a href=&quot;https://bytecodealliance.github.io/wasmtime/&quot;&gt;Guide&lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://bytecodealliance.github.io/wasmtime/contributing.html&quot;&gt;Contributing&lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://wasmtime.dev/&quot;&gt;Website&lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;https://bytecodealliance.zulipchat.com/#narrow/stream/217126-wasmtime&quot;&gt;Chat&lt;/a&gt;
  &lt;/h3&gt;
&lt;/div&gt;

## Installation

The Wasmtime CLI can be installed on Linux and macOS (locally) with a small install
script:

```console
curl https://wasmtime.dev/install.sh -sSf | bash
```
This script installs into `$WASMTIME_HOME` (defaults to `$HOME/.wasmtime`), and executable is placed in `$WASMTIME_HOME/bin`.

After running the install script above, follow the on-screen instructions.

Windows or otherwise interested users can download installers and
binaries directly from the [GitHub
Releases](https://github.com/bytecodealliance/wasmtime/releases) page.

For additional installation options, refer to the [online book CLI installation page](https://docs.wasmtime.dev/cli-install.html).

Documentation on Wasmtime&#039;s currently supported versions can be found [in the
online book
documentation](https://docs.wasmtime.dev/stability-release.html#current-versions).

## Example

If you&#039;ve got the [Rust compiler
installed](https://www.rust-lang.org/tools/install) then you can take some Rust
source code:

```rust
fn main() {
    println!(&quot;Hello, world!&quot;);
}
```

and compile it into a WebAssembly component with:

```console
rustup target add wasm32-wasip2
rustc hello.rs --target wasm32-wasip2
```

Once compiled, you can run your component:

```console
wasmtime hello.wasm
```

You should see the following output:

```text
Hello, world!
```

(Note: make sure you installed Rust using the [`rustup`][rustup] method in the official
instructions above, and do not have a copy of the Rust toolchain installed on
your system in some other way as well (e.g. the system package manager). Otherwise, the `rustup target add...`
command may not install the target for the correct copy of Rust.)

[rustup]: https://rustup.rs

## Features

* **Fast**. Wasmtime is built on the optimizing [Cranelift] code generator to
  quickly generate high-quality machine code either at runtime or
  ahead-of-time. Wasmtime is optimized for efficient instantiation, low-overhead
  calls between the embedder and wasm, and scalability of concurrent instances.

* **[Secure]**. Wasmtime&#039;s development is strongly focused on correctness and
  security. Building on top of Rust&#039;s runtime safety guarantees, each Wasmtime
  feature goes through careful review and consideration via an [RFC
  process]. Once features are designed and implemented, they undergo 24/7
  fuzzing donated by [Google&#039;s OSS Fuzz]. As features stabilize they become part
  of a [release][release policy], and when things go wrong we have a
  well-defined [security policy] in place to quickly mitigate and patch any
  issues. We follow best practices for defense-in-depth and integrate
  protections and mitigations for issues like Spectre. Finally, we&#039;re working to
  push the state-of-the-art by collaborating with academic researchers to
  formally verify critical parts of Wasmtime and Cranelift.

* **[Configurable]**. Wasmtime uses sensible defaults, but can also be
  configured to provide more fine-grained control over things like CPU and
  memory consumption. Whether you want to run Wasmtime in a tiny environment or
  on massive servers with many concurrent instances, we&#039;ve got you covered.

* **[WASI]**. Wasmtime supports a rich set of APIs for interacting with the host
  environment through the [WASI standard](https://wasi.dev).

* **[Standards Compliant]**. Wasmtime passes the [official WebAssembly test
  suite](https://github.com/WebAssembly/testsuite), implements the [official C
  API of wasm](https://github.com/WebAssembly/wasm-c-api), and implements
  [future proposals to WebAssembly](https://github.com/WebAssembly/proposals) as
  well. Wasmtime developers are intimately engaged with the WebAssembly
  standards process all along the way too.

[Wasmtime]: https://github.com/bytecodealliance/wasmtime
[Cranelift]: https://cranelift.dev/
[Google&#039;s OSS Fuzz]: https://google.github.io/oss-fuzz/
[security policy]: https://bytecodealliance.org/security
[RFC process]: https://github.com/bytecodealliance/rfcs
[release policy]: https://docs.wasmtime.dev/stability-release.html
[Secure]: https://docs.wasmtime.dev/security.html
[Configurable]: https://docs.rs/wasmtime/latest/wasmtime/struct.Config.html
[WASI]: https://docs.rs/wasmtime-wasi/latest/wasmtime_wasi/
[Standards Compliant]: https://docs.wasmtime.dev/stability-tiers.html

## Language Support

You can use Wasmtime from a variety of different languages through embeddings of
the implementation.

Languages supported by the Bytecode Alliance:

* **[Rust]** - the [`wasmtime` crate]
* **[C]** - the [`wasm.h`, `wasi.h`, and `wasmtime.h` headers][c-headers], [CMake](crates/c-api/CMakeLists.txt)
* **C++** - the [`wasmtime.hh` header][c-headers]
* **[Python]** - the [`wasmtime` PyPI package]
* **[.NET]** - the [`Wasmtime` NuGet package]
* **[Go]** - the [`wasmtime-go` repository]
* **[Ruby]** - the [`wasmtime` gem]

Languages supported by the community:

* **[Elixir]** - the [`wasmex` hex package]
* **Perl** - the [`Wasm` Perl package&#039;s `Wasm::Wasmtime`]

[Rust]: https://bytecodealliance.github.io/wasmtime/lang-rust.html
[C]: https://bytecodealliance.github.io/wasmtime/lang-c.html
[`wasmtime` crate]: https://crates.io/crates/wasmtime
[c-headers]: https://bytecodealliance.github.io/wasmtime/c-api/
[Python]: https://bytecodealliance.github.io/wasmtime/lang-python.html
[`wasmtime` PyPI package]: https://pypi.org/project/wasmtime/
[.NET]: https://bytecodealliance.github.io/wasmtime/lang-dotnet.html
[`Wasmtime` NuGet package]: https://www.nuget.org/packages/Wasmtime
[Go]: https://bytecodealliance.github.io/wasmtime/lang-go.html
[`wasmtime-go` repository]: https://pkg.go.dev/github.com/bytecodealliance/wasmtime-go
[Ruby]: https://bytecodealliance.github.io/wasmtime/lang-ruby.html
[`wasmtime` gem]: https://rubygems.org/gems/wasmtime
[Elixir]: https://docs.wasmtime.dev/lang-elixir.html
[`wasmex` hex package]: https://hex.pm/packages/wasmex
[`Wasm` Perl package&#039;s `Wasm::Wasmtime`]: https://metacpan.org/pod/Wasm::Wasmtime

## Documentation

[üìö Read the Wasmtime guide here! üìö][guide]

The [wasmtime guide][guide] is the best starting point to learn about what
Wasmtime can do for you or help answer your questions about Wasmtime. If you&#039;re
curious in contributing to Wasmtime, [it can also help you do
that][contributing]!

[contributing]: https://bytecodealliance.github.io/wasmtime/contributing.html
[guide]: https://bytecodealliance.github.io/wasmtime

---

It&#039;s Wasmtime.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustdesk/rustdesk]]></title>
            <link>https://github.com/rustdesk/rustdesk</link>
            <guid>https://github.com/rustdesk/rustdesk</guid>
            <pubDate>Thu, 26 Feb 2026 00:08:03 GMT</pubDate>
            <description><![CDATA[An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustdesk/rustdesk">rustdesk/rustdesk</a></h1>
            <p>An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.</p>
            <p>Language: Rust</p>
            <p>Stars: 108,127</p>
            <p>Forks: 16,091</p>
            <p>Stars today: 92 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;res/logo-header.svg&quot; alt=&quot;RustDesk - Your remote desktop&quot;&gt;&lt;br&gt;
  &lt;a href=&quot;#raw-steps-to-build&quot;&gt;Build&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#how-to-build-with-docker&quot;&gt;Docker&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#file-structure&quot;&gt;Structure&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#snapshot&quot;&gt;Snapshot&lt;/a&gt;&lt;br&gt;
  [&lt;a href=&quot;docs/README-UA.md&quot;&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href=&quot;docs/README-CS.md&quot;&gt;ƒçesky&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ZH.md&quot;&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href=&quot;docs/README-HU.md&quot;&gt;Magyar&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ES.md&quot;&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FA.md&quot;&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FR.md&quot;&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DE.md&quot;&gt;Deutsch&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PL.md&quot;&gt;Polski&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ID.md&quot;&gt;Indonesian&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FI.md&quot;&gt;Suomi&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ML.md&quot;&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href=&quot;docs/README-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NL.md&quot;&gt;Nederlands&lt;/a&gt;] | [&lt;a href=&quot;docs/README-IT.md&quot;&gt;Italiano&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PTBR.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href=&quot;docs/README-EO.md&quot;&gt;Esperanto&lt;/a&gt;] | [&lt;a href=&quot;docs/README-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href=&quot;docs/README-AR.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href=&quot;docs/README-VN.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DA.md&quot;&gt;Dansk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-GR.md&quot;&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href=&quot;docs/README-TR.md&quot;&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NO.md&quot;&gt;Norsk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RO.md&quot;&gt;Rom√¢nƒÉ&lt;/a&gt;]&lt;br&gt;
  &lt;b&gt;We need your help to translate this README, &lt;a href=&quot;https://github.com/rustdesk/rustdesk/tree/master/src/lang&quot;&gt;RustDesk UI&lt;/a&gt; and &lt;a href=&quot;https://github.com/rustdesk/doc.rustdesk.com&quot;&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt;
&lt;/p&gt;

&gt; [!Caution]
&gt; **Misuse Disclaimer:** &lt;br&gt;
&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.


Chat with us: [Discord](https://discord.gg/nDceKgxnkV) | [Twitter](https://twitter.com/rustdesk) | [Reddit](https://www.reddit.com/r/rustdesk) | [YouTube](https://www.youtube.com/@rustdesk)

[![RustDesk Server Pro](https://img.shields.io/badge/RustDesk%20Server%20Pro-Advanced%20Features-blue)](https://rustdesk.com/pricing.html)

Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, [set up your own](https://rustdesk.com/server), or [write your own rendezvous/relay server](https://github.com/rustdesk/rustdesk-server-demo).

![image](https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png)

RustDesk welcomes contribution from everyone. See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for help getting started.

[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)

[**BINARY DOWNLOAD**](https://github.com/rustdesk/rustdesk/releases)

[**NIGHTLY BUILD**](https://github.com/rustdesk/rustdesk/releases/tag/nightly)

[&lt;img src=&quot;https://f-droid.org/badge/get-it-on.png&quot;
    alt=&quot;Get it on F-Droid&quot;
    height=&quot;80&quot;&gt;](https://f-droid.org/en/packages/com.carriez.flutter_hbb)
[&lt;img src=&quot;https://flathub.org/api/badge?svg&amp;locale=en&quot;
    alt=&quot;Get it on Flathub&quot;
    height=&quot;80&quot;&gt;](https://flathub.org/apps/com.rustdesk.RustDesk)

## Dependencies

Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our [CI](https://github.com/rustdesk/rustdesk/blob/master/.github/workflows/flutter-build.yml) for building Flutter version.

Please download Sciter dynamic library yourself.

[Windows](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll) |
[Linux](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so) |
[macOS](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib)

## Raw Steps to build

- Prepare your Rust development env and C++ build env

- Install [vcpkg](https://github.com/microsoft/vcpkg), and set `VCPKG_ROOT` env variable correctly

  - Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static
  - Linux/macOS: vcpkg install libvpx libyuv opus aom

- run `cargo run`

## [Build](https://rustdesk.com/docs/en/dev/build/)

## How to Build on Linux

### Ubuntu 18 (Debian 10)

```sh
sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
```

### openSUSE Tumbleweed

```sh
sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
```

### Fedora 28 (CentOS 8)

```sh
sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
```

### Arch (Manjaro)

```sh
sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
```

### Install vcpkg

```sh
git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
```

### Fix libvpx (For Fedora)

```sh
cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i &#039;s/CFLAGS+=-I/CFLAGS+=-fPIC -I/g&#039; Makefile
sed -i &#039;s/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g&#039; Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
```

### Build

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
```

## How to build with Docker

Begin by cloning the repository and building the Docker container:

```sh
git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t &quot;rustdesk-builder&quot; .
```

Then, each time you need to build the application, run the following command:

```sh
docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=&quot;$(id -u)&quot; -e PGID=&quot;$(id -g)&quot; rustdesk-builder
```

Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the `&lt;OPTIONAL-ARGS&gt;` position. For instance, if you wanted to build an optimized release version, you would run the command above followed by `--release`. The resulting executable will be available in the target folder on your system, and can be run with:

```sh
target/debug/rustdesk
```

Or, if you&#039;re running a release executable:

```sh
target/release/rustdesk
```

Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as `install` or `run` are not currently supported via this method as they would install or run the program inside the container instead of the host.

## File Structure

- **[libs/hbb_common](https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common)**: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions
- **[libs/scrap](https://github.com/rustdesk/rustdesk/tree/master/libs/scrap)**: screen capture
- **[libs/enigo](https://github.com/rustdesk/rustdesk/tree/master/libs/enigo)**: platform specific keyboard/mouse control
- **[libs/clipboard](https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard)**: file copy and paste implementation for Windows, Linux, macOS.
- **[src/ui](https://github.com/rustdesk/rustdesk/tree/master/src/ui)**: obsolete Sciter UI (deprecated)
- **[src/server](https://github.com/rustdesk/rustdesk/tree/master/src/server)**: audio/clipboard/input/video services, and network connections
- **[src/client.rs](https://github.com/rustdesk/rustdesk/tree/master/src/client.rs)**: start a peer connection
- **[src/rendezvous_mediator.rs](https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs)**: Communicate with [rustdesk-server](https://github.com/rustdesk/rustdesk-server), wait for remote direct (TCP hole punching) or relayed connection
- **[src/platform](https://github.com/rustdesk/rustdesk/tree/master/src/platform)**: platform specific code
- **[flutter](https://github.com/rustdesk/rustdesk/tree/master/flutter)**: Flutter code for desktop and mobile
- **[flutter/web/js](https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js)**: JavaScript for Flutter web client

## Screenshots

![Connection Manager](https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651)

![Connected to a Windows PC](https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea)

![File Transfer](https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad)

![TCP Tunneling](https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[storytold/artcraft]]></title>
            <link>https://github.com/storytold/artcraft</link>
            <guid>https://github.com/storytold/artcraft</guid>
            <pubDate>Thu, 26 Feb 2026 00:08:02 GMT</pubDate>
            <description><![CDATA[ArtCraft is an intentional crafting engine for artists, designers, and filmmakers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/storytold/artcraft">storytold/artcraft</a></h1>
            <p>ArtCraft is an intentional crafting engine for artists, designers, and filmmakers</p>
            <p>Language: Rust</p>
            <p>Stars: 918</p>
            <p>Forks: 73</p>
            <p>Stars today: 47 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;video src=&quot;https://github.com/user-attachments/assets/b4e24c27-d87d-4fd1-8599-dc0d0b8af48d&quot; width=&quot;100%&quot; autoplay=&quot;true&quot; loop controls&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;The IDE for artists.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.gg/artcraft&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1359579021108842617?style=for-the-badge&amp;label=discord&amp;color=ffffff&amp;logo=discord&amp;logoColor=ffffff&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.youtube.com/@OfficialArtCraftStudios&quot;&gt;&lt;img alt=&quot;YouTube&quot; src=&quot;https://img.shields.io/youtube/channel/subscribers/UCdjY4VG0ntoGwFsKZO4sVWA?style=for-the-badge&amp;logo=YouTube&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/intent/follow?screen_name=get_artcraft&quot;&gt;&lt;img alt=&quot;X&quot; src=&quot;https://img.shields.io/twitter/follow/get_artcraft?style=for-the-badge&amp;label=follow&amp;logo=x&amp;logoColor=ffffff&amp;color=ffffff&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.linkedin.com/company/artcraft-ai&quot;&gt;&lt;img alt=&quot;LinkedIn&quot; src=&quot;https://img.shields.io/badge/linkedin--0A66C2?style=for-the-badge&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

---

ArtCraft
========
ArtCraft is the IDE for interactive AI image and video creation.
We turn prompting into *crafting*, so your ideas become a form of tangible expression and computing.
This is Adobe Photoshop for everyone, and we&#039;re giving away the source code!

## Show, Don&#039;t Tell: Advanced Crafting Features

Text-to-image is great, but artists *need control*. It&#039;s important to know what your image will look like before you generate it, and it&#039;s vitally important to achieve consistency and repeatability.

| Feature                           | Demo + Explanation                                                                                                                                                                                                                                                      
|-----------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Image to Location**             | ![Video](https://github.com/user-attachments/assets/21f103e3-cc19-4882-a630-9caa1b76ae31) Placing virtual actors into physical environments establishes single-location consistency. You can film multiple shots within a room without having things disappear.         |
| **3D Image Compositing**          | ![Video](https://github.com/user-attachments/assets/f93a616f-571d-474e-bcc0-53736de7303d) Use images (backdrops, foreground elements, props, etc.) in scenes with depth and blend them naturally together. Just a couple of images usually leads to great compositions. |
| **2D Image Compositing**          | ![Video](https://github.com/user-attachments/assets/d6f99391-e496-4c62-9e37-29734ba5f899) Use images, background removal, layers, and simple drawing tools to precisely compose a scene.                                                                                |
| **Image to 3D Mesh**              | ![Video](https://github.com/user-attachments/assets/600a405c-e360-48c1-9b42-6e657ae6243b) It&#039;s almost impossible to lay out complicated objects or block complicated scenes; turning images into 3D helps position elements exactingly and intentionally.               |
| **Character Posing**              | ![Video](https://github.com/user-attachments/assets/52a8e983-7c8f-42d2-be8b-25296ab9ed57) You can dynamically pose your characters to achieve the precise character, scene, and camera blocking before calling &quot;action&quot;.                                                |
| **Scene Blocking w/ Kit Bashing** | ![Video](https://github.com/user-attachments/assets/eef025ac-0346-4a46-a023-d48e23629eb5) Use 3D asset kits to precisely block out your scene: get the correct angles, object positions, and rich depth layering you can&#039;t with text prompting.                         |
| **Character Identity Transfer**   | ![Video](https://github.com/user-attachments/assets/629119ee-8c76-4a83-9827-8c6c995a3ec1) Use mannequins as simple 3D ControlNets for posing any character.                                                                                                             |
| **Background Removal**            | ![Video](https://github.com/user-attachments/assets/90c65057-5531-404f-83af-b34e66e24ec1) Remove backgrounds from images to make them useful in 2D or 3D compositing. They can be props, layers, or backdrops.                                                          |
| **Mixed Asset Crafting**          | ![Video](https://raw.githubusercontent.com/storytold/github-media/main/ship-editing.gif) You can use image cutouts, worlds, and simple 3D meshes all together to precisely and intentionally lay out your scenes.                                                       |
| **Scene Blocking**                | (preview coming soon)                                                                                                                                                                                                                                                   |
| **Canvas Editing**                | (preview coming soon)                                                                                                                                                                                                                                                   |
| **Scene Relighting**              | (preview coming soon)                                                                                                                                                                                                                                                   |

Note: all of the above videos were generated for free with Grok Video; the cost to build this README was negligible.

## Quick and Easy Prompting
We haven&#039;t abandoned text-to-asset generation for quick prototyping and ideation. We support every popular workflow in a first class fashion.

| Feature               | Demo + Explanation                                                                                                                                    
|-----------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Text to Image**     | ![Video](https://github.com/user-attachments/assets/9cc289cd-faf4-4eaf-aed2-21134cce127c) Text prompt over a dozen different image models.            |
| **Image Editing**     | ![Video](https://github.com/user-attachments/assets/a06fa6ad-936c-42d0-8767-48fdbb8ff141) Edit with Nano Banana Pro and GPT Image 1.5.                |
| **Image Editing**     | ![Video](https://github.com/user-attachments/assets/f036e08a-f3a6-417a-98ee-ec7f04b2b5ff) Use inpainting, drawing, masking, etc. to edit images.      |
| **Image to Video**    | ![Video](https://github.com/user-attachments/assets/2bc6c592-511e-4fba-b40f-03c96699b7f7) Image to video with lots of different options and controls. |
| **Image Inpainting**  | (preview coming soon)                                                                                                                                 |
| **Image Ingredients** | (preview coming soon)                                                                                                                                 |

## Models and Providers Supported within Artcraft

| Provider   | Features                                                                                                                                                                |
|------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Artcraft   | Nano Banana, Nano Banana Pro, GPT-Image-1 / 1.5, Seedance 2 / Seedream 4 / 4.5, Flux 1.1 / Kontext, Veo 2 / 3 / 3.1, Kling 1.6 / 2.1 / 2.5 / 2.6, Seedance, Sora 2 / Pro, Hunyuan 3d 2 / 3 |
| Grok       | Grok Imagine, Grok Video                                                                                                                                                |
| Midjourney | Image Gen (all versions)                                                                                                                                                |
| Sora       | Sora 1, Sora 2, GPT-Image-1                                                                                                                                             |
| WorldLabs  | Marble (Gaussian Splat World Generation)                                                                                                                                |

We&#039;re going to be adding the following providers soon: Kling (via Kling website accounts), Google (via API keys), 
Runway (via website account), Luma (via website account).

We&#039;re potentially interested in adding other aggregators for those who already have subscriptions and credits at 
those providers, for example: OpenArt, FreePik, etc.

## Downloads

- [Visit our website for the stable Windows and MacOS releases](https://getartcraft.com/)
- Or you can grab a [more recent Windows and MacOS build directly](https://github.com/storytold/artcraft/releases)
- Linux requires building from source for now

## Documentation

- [developer documentation](./_docs)
- [tools, scripts, misc](./script)
- [license](./LICENSE.md)
- [roadmap](./ROADMAP.md)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[clockworklabs/SpacetimeDB]]></title>
            <link>https://github.com/clockworklabs/SpacetimeDB</link>
            <guid>https://github.com/clockworklabs/SpacetimeDB</guid>
            <pubDate>Thu, 26 Feb 2026 00:08:01 GMT</pubDate>
            <description><![CDATA[Development at the speed of light]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/clockworklabs/SpacetimeDB">clockworklabs/SpacetimeDB</a></h1>
            <p>Development at the speed of light</p>
            <p>Language: Rust</p>
            <p>Stars: 20,399</p>
            <p>Forks: 719</p>
            <p>Stars today: 974 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
	&lt;img width=&quot;320&quot; src=&quot;./images/dark/logo.svg&quot; alt=&quot;SpacetimeDB Logo&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
	&lt;img width=&quot;320&quot; src=&quot;./images/light/logo.svg&quot; alt=&quot;SpacetimeDB Logo&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
        &lt;img width=&quot;250&quot; src=&quot;./images/dark/logo-text.svg&quot; alt=&quot;SpacetimeDB&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://spacetimedb.com#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
        &lt;img width=&quot;250&quot; src=&quot;./images/light/logo-text.svg&quot; alt=&quot;SpacetimeDB&quot;&gt;
    &lt;/a&gt;
    &lt;h3 align=&quot;center&quot;&gt;
        Development at the speed of light.
    &lt;/h3&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/clockworklabs/spacetimedb?color=%23ff00a0&amp;include_prereleases&amp;label=version&amp;sort=semver&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/built_with-Rust-dca282.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
	&lt;a href=&quot;https://github.com/clockworklabs/spacetimedb/actions&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/clockworklabs/spacetimedb/ci.yml?style=flat-square&amp;branch=master&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://status.spacetimedb.com&quot;&gt;&lt;img src=&quot;https://img.shields.io/uptimerobot/ratio/7/m784409192-e472ca350bb615372ededed7?label=cloud%20uptime&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://hub.docker.com/r/clockworklabs/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/clockworklabs/spacetimedb?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb/blob/master/LICENSE.txt&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-BSL_1.1-00bfff.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://crates.io/crates/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/d/spacetimedb?color=e45928&amp;label=Rust%20Crate&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.nuget.org/packages/SpacetimeDB.Runtime&quot;&gt;&lt;img src=&quot;https://img.shields.io/nuget/dt/spacetimedb.runtime?color=0b6cff&amp;label=NuGet%20Package&amp;style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://discord.gg/spacetimedb&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1037340874172014652?label=discord&amp;style=flat-square&amp;color=5a66f6&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitter.com/spacetime_db&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/twitter-Follow_us-1d9bf0.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://clockworklabs.io/join&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/careers-Join_us-86f7b7.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/clockworklabs/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/linkedin-Connect_with_us-0a66c2.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://discord.gg/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/discord.svg&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitter.com/spacetime_db&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/twitter.svg&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/clockworklabs/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/github.svg&quot; alt=&quot;GitHub&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://twitch.tv/SpacetimeDB&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/twitch.svg&quot; alt=&quot;Twitch&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://youtube.com/@SpacetimeDB&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/youtube.svg&quot; alt=&quot;YouTube&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/clockwork-labs/&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/linkedin.svg&quot; alt=&quot;LinkedIn&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://stackoverflow.com/questions/tagged/spacetimedb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./images/social/stackoverflow.svg&quot; alt=&quot;StackOverflow&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

## What is [SpacetimeDB](https://spacetimedb.com)?

You can think of SpacetimeDB as both a database and server combined into one.

It is a relational database system that lets you upload your application logic directly into the database by way of fancy stored procedures called &quot;modules.&quot;

Instead of deploying a web or game server that sits in between your clients and your database, your clients connect directly to the database and execute your application logic inside the database itself. You can write all of your permission and authorization logic right inside your module just as you would in a normal server.

This means that you can write your entire application in a single language, Rust, and deploy it as a single binary. No more microservices, no more containers, no more Kubernetes, no more Docker, no more VMs, no more DevOps, no more infrastructure, no more ops, no more servers.

&lt;figure&gt;
    &lt;img src=&quot;./images/basic-architecture-diagram.png&quot; alt=&quot;SpacetimeDB Architecture&quot; style=&quot;width:100%&quot;&gt;
    &lt;figcaption align=&quot;center&quot;&gt;
        &lt;p align=&quot;center&quot;&gt;&lt;b&gt;SpacetimeDB application architecture&lt;/b&gt;&lt;br /&gt;&lt;sup&gt;&lt;sub&gt;(elements in white are provided by SpacetimeDB)&lt;/sub&gt;&lt;/sup&gt;&lt;/p&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;

It&#039;s actually similar to the idea of smart contracts, except that SpacetimeDB is a database, has nothing to do with blockchain, and is orders of magnitude faster than any smart contract system.

So fast, in fact, that the entire backend of our MMORPG [BitCraft Online](https://bitcraftonline.com) is just a SpacetimeDB module. We don&#039;t have any other servers or services running, which means that everything in the game, all of the chat messages, items, resources, terrain, and even the locations of the players are stored and processed by the database before being synchronized out to all of the clients in real-time.

SpacetimeDB is optimized for maximum speed and minimum latency rather than batch processing or OLAP workloads. It is designed to be used for real-time applications like games, chat, and collaboration tools.

This speed and latency is achieved by holding all of application state in memory, while persisting the data in a write-ahead-log (WAL) which is used to recover application state.

## Installation

You can run SpacetimeDB as a standalone database server via the `spacetime` CLI tool.
Install instructions for supported platforms are outlined below.
The same install instructions can be found on our website at https://spacetimedb.com/install.

#### Install on macOS

Installing on macOS is as simple as running our install script. After that you can use the spacetime command to manage versions.

```bash
curl -sSf https://install.spacetimedb.com | sh
```

#### Install on Linux

Installing on Linux is as simple as running our install script. After that you can use the spacetime command to manage versions.

```bash
curl -sSf https://install.spacetimedb.com | sh
```

#### Install on Windows

Installing on Windows is as simple as pasting the snippet below into PowerShell. If you would like to use WSL instead, please follow the Linux install instructions.

```ps1
iwr https://windows.spacetimedb.com -useb | iex
```

#### Installing from Source

A quick note on installing from source: we recommend that you don&#039;t install from source unless there is a feature that is available in `master` that hasn&#039;t been released yet, otherwise follow the official installation instructions.

##### MacOS + Linux

Installing on macOS + Linux is pretty straightforward. First we are going to build all of the binaries that we need:

```bash
# Install rustup, you can skip this step if you have cargo and the wasm32-unknown-unknown target already installed.
curl https://sh.rustup.rs -sSf | sh
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
mkdir -p ~/.local/bin
export STDB_VERSION=&quot;$(./target/release/spacetimedb-cli --version | sed -n &#039;s/.*spacetimedb tool version \([0-9.]*\);.*/\1/p&#039;)&quot;
mkdir -p ~/.local/share/spacetime/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/.local/bin/spacetime
cp target/release/spacetimedb-cli ~/.local/share/spacetime/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/.local/share/spacetime/bin/$STDB_VERSION
```

At this stage you&#039;ll need to add ~/.local/bin to your path if you haven&#039;t already.

```
# Please add the following line to your shell configuration and open a new shell session:
export PATH=&quot;$HOME/.local/bin:$PATH&quot;

```

Then finally set your SpacetimeDB version:
```

# Then, in a new shell, set the current version:
spacetime version use $STDB_VERSION

# If STDB_VERSION is not set anymore then you can use the following command to list your versions:
spacetime version list
```

You can verify that the correct version has been installed via `spacetime --version`.

##### Windows

Building on windows is a bit more complicated. You&#039;ll need a slightly different version of perl compared to what comes pre-bundled in most Windows terminals. We recommend [Strawberry Perl](https://strawberryperl.com/). You may also need access to an `openssl` binary which actually comes pre-installed with [Git for Windows](https://git-scm.com/downloads/win). Also, you&#039;ll need to install [rustup](https://rustup.rs/) for Windows.

In a Git for Windows shell you should have something that looks like this:
```
$ which perl
/c/Strawberry/perl/bin/perl
$ which openssl
/mingw64/bin/openssl
$ which cargo 
/c/Users/&lt;user&gt;/.cargo/bin/cargo
```

If that looks correct then you&#039;re ready to proceed!

```powershell
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB

# Build and install the CLI
cd SpacetimeDB
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
$stdbDir = &quot;$HOME\AppData\Local\SpacetimeDB&quot;
$stdbVersion = &amp; &quot;.\target\release\spacetimedb-cli&quot; --version | Select-String -Pattern &#039;spacetimedb tool version ([0-9.]+);&#039; | ForEach-Object { $_.Matches.Groups[1].Value }
New-Item -ItemType Directory -Path &quot;$stdbDir\bin\$stdbVersion&quot; -Force | Out-Null

# Install the update binary
Copy-Item &quot;target\release\spacetimedb-update.exe&quot; &quot;$stdbDir\spacetime.exe&quot;
Copy-Item &quot;target\release\spacetimedb-cli.exe&quot; &quot;$stdbDir\bin\$stdbVersion\&quot;
Copy-Item &quot;target\release\spacetimedb-standalone.exe&quot; &quot;$stdbDir\bin\$stdbVersion\&quot;

```

Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!

```
%USERPROFILE%\AppData\Local\SpacetimeDB
```

Then finally, open a new shell and use the installed SpacetimeDB version:
```
spacetime version use $stdbVersion

# If stdbVersion is no longer set, list versions using the following command:
spacetime version list
```

You can verify that the correct version has been installed via `spacetime --version`.

If you&#039;re using Git for Windows you can follow these instructions instead:

```bash
# Clone SpacetimeDB
git clone https://github.com/clockworklabs/SpacetimeDB
# Build and install the CLI
cd SpacetimeDB
# Build the CLI binaries - this takes a while on windows so go grab a coffee :)
cargo build --locked --release -p spacetimedb-standalone -p spacetimedb-update -p spacetimedb-cli

# Create directories
export STDB_VERSION=&quot;$(./target/release/spacetimedb-cli --version | sed -n &#039;s/.*spacetimedb tool version \([0-9.]*\);.*/\1/p&#039;)&quot;
mkdir -p ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Install the update binary
cp target/release/spacetimedb-update ~/AppData/Local/SpacetimeDB/spacetime
cp target/release/spacetimedb-cli ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION
cp target/release/spacetimedb-standalone ~/AppData/Local/SpacetimeDB/bin/$STDB_VERSION

# Now add the directory we just created to your path. We recommend adding it to the system path because then it will be available to all of your applications (including Unity3D). After you do this, restart your shell!
# %USERPROFILE%\AppData\Local\SpacetimeDB

# Set the current version
spacetime version use $STDB_VERSION
```

You can verify that the correct version has been installed via `spacetime --version`.

#### Running with Docker

If you prefer to run Spacetime in a container, you can use the following command to start a new instance.

```bash
docker run --rm --pull always -p 3000:3000 clockworklabs/spacetime start
```

## Documentation

For more information about SpacetimeDB, getting started guides, game development guides, and reference material please see our [documentation](https://spacetimedb.com/docs).

## Getting Started

We&#039;ve prepared several getting started guides in each of our supported languages to help you get up and running with SpacetimeDB as quickly as possible. You can find them on our [docs page](https://spacetimedb.com/docs).

In summary there are only 4 steps to getting started with SpacetimeDB.

1. Install the `spacetime` CLI tool.
2. Start a SpacetimeDB standalone node with `spacetime start`.
3. Write and upload a module in one of our supported module languages.
4. Connect to the database with one of our client libraries.

You can see a summary of the supported languages below with a link to the getting started guide for each.

## Language Support

You can write SpacetimeDB modules in several popular languages, with more to come in the future!

#### Serverside Libraries

- [Rust](https://spacetimedb.com/docs/modules/rust/quickstart)
- [C#](https://spacetimedb.com/docs/modules/c-sharp/quickstart)

#### Client Libraries

- [Rust](https://spacetimedb.com/docs/sdks/rust/quickstart)
- [C#](https://spacetimedb.com/docs/sdks/c-sharp/quickstart)
- [Typescript](https://spacetimedb.com/docs/sdks/typescript/quickstart)

## License

SpacetimeDB is licensed under the BSL 1.1 license. This is not an open source or free software license, however, it converts to the AGPL v3.0 license with a linking exception after a few years.

Note that the AGPL v3.0 does not typically include a linking exception. We have added a custom linking exception to the AGPL license for SpacetimeDB. Our motivation for choosing a free software license is to ensure that contributions made to SpacetimeDB are propagated back to the community. We are expressly not interested in forcing users of SpacetimeDB to open source their own code if they link with SpacetimeDB, so we needed to include a linking exception.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[farion1231/cc-switch]]></title>
            <link>https://github.com/farion1231/cc-switch</link>
            <guid>https://github.com/farion1231/cc-switch</guid>
            <pubDate>Thu, 26 Feb 2026 00:08:00 GMT</pubDate>
            <description><![CDATA[A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/farion1231/cc-switch">farion1231/cc-switch</a></h1>
            <p>A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.</p>
            <p>Language: TypeScript</p>
            <p>Stars: 20,108</p>
            <p>Forks: 1,254</p>
            <p>Stars today: 341 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# All-in-One Assistant for Claude Code, Codex &amp; Gemini CLI

[![Version](https://img.shields.io/badge/version-3.10.2-blue.svg)](https://github.com/farion1231/cc-switch/releases)
[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)
[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)
[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)

&lt;a href=&quot;https://trendshift.io/repositories/15372&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15372&quot; alt=&quot;farion1231%2Fcc-switch | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

English | [‰∏≠Êñá](README_ZH.md) | [Êó•Êú¨Ë™û](README_JA.md) | [Changelog](CHANGELOG.md)

&lt;/div&gt;

## ‚ù§Ô∏èSponsor

[![MiniMax](assets/partners/banners/minimax-en.jpeg)](https://platform.minimax.io/subscribe/coding-plan?code=ClLhgxr2je&amp;source=link)

MiniMax-M2.5 is a SOTA large language model designed for real-world productivity. Trained in a diverse range of complex real-world digital working environments, M2.5 builds upon the coding expertise of M2.1 to extend into general office work, reaching fluency in generating and operating Word, Excel, and Powerpoint files, context switching between diverse software environments, and working across different agent and human teams. Scoring 80.2% on SWE-Bench Verified, 51.3% on Multi-SWE-Bench, and 76.3% on BrowseComp, M2.5 is also more token efficient than previous generations, having been trained to optimize its actions and output through planning.

[Click](https://platform.minimax.io/subscribe/coding-plan?code=ClLhgxr2je&amp;source=link) to get an exclusive 12% off the MiniMax Coding Plan!

---

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;&lt;img src=&quot;assets/partners/logos/packycode.png&quot; alt=&quot;PackyCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using &lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;this link&lt;/a&gt; and enter the &quot;cc-switch&quot; promo code during first recharge to get 10% off.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/aigocode.png&quot; alt=&quot;AIGoCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses. AIGoCode has prepared a special benefit for CC Switch users: if you register via &lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;this link&lt;/a&gt;, you&#039;ll receive an extra 10% bonus credit on your first top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.aicodemirror.com/register?invitecode=9915W3&quot;&gt;&lt;img src=&quot;assets/partners/logos/aicodemirror.jpg&quot; alt=&quot;AICodeMirror&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AICodeMirror for sponsoring this project! AICodeMirror provides official high-stability relay services for Claude Code / Codex / Gemini CLI, with enterprise-grade concurrency, fast invoicing, and 24/7 dedicated technical support.
Claude Code / Codex / Gemini official channels at 38% / 2% / 9% of original price, with extra discounts on top-ups! AICodeMirror offers special benefits for CC Switch users: register via &lt;a href=&quot;https://www.aicodemirror.com/register?invitecode=9915W3&quot;&gt;this link&lt;/a&gt; to enjoy 20% off your first top-up, and enterprise customers can get up to 25% off!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://cubence.com/signup?code=CCSWITCH&amp;source=ccs&quot;&gt;&lt;img src=&quot;assets/partners/logos/cubence.png&quot; alt=&quot;Cubence&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to Cubence for sponsoring this project! Cubence is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more with flexible billing options including pay-as-you-go and monthly plans. Cubence provides special discounts for CC Switch users: register using &lt;a href=&quot;https://cubence.com/signup?code=CCSWITCH&amp;source=ccs&quot;&gt;this link&lt;/a&gt; and enter the &quot;CCSWITCH&quot; promo code during recharge to get 10% off every top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.dmxapi.cn/register?aff=bUHu&quot;&gt;&lt;img src=&quot;assets/partners/logos/dmx-en.jpg&quot; alt=&quot;DMXAPI&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to DMXAPI for sponsoring this project! DMXAPI provides global large model API services to 200+ enterprise users. One API key for all global models. Features include: instant invoicing, unlimited concurrency, starting from $0.15, 24/7 technical support. GPT/Claude/Gemini all at 32% off, domestic models 20-50% off, Claude Code exclusive models at 66% off! &lt;a href=&quot;https://www.dmxapi.cn/register?aff=bUHu&quot;&gt;Register here&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.right.codes/register?aff=CCSWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/rightcode.jpg&quot; alt=&quot;RightCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thank you to Right Code for sponsoring this project! Right Code reliably provides routing services for models such as Claude Code, Codex, and Gemini. It features a highly cost-effective Codex monthly subscription plan and &lt;strong&gt;supports quota rollovers‚Äîunused quota from one day can be carried over and used the next day.&lt;/strong&gt; Invoices are available upon top-up. Enterprise and team users can receive dedicated one-on-one support. Right Code also offers an exclusive discount for CC Switch users: register via &lt;a href=&quot;https://www.right.codes/register?aff=CCSWITCH&quot;&gt;this link&lt;/a&gt;, and with every top-up you will receive pay-as-you-go credit equivalent to 25% of the amount paid.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://aicoding.sh/i/CCSWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/aicoding.jpg&quot; alt=&quot;AICoding&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AICoding.sh for sponsoring this project! AICoding.sh ‚Äî Global AI Model API Relay Service at Unbeatable Prices! Claude Code at 19% of original price, GPT at just 1%! Trusted by hundreds of enterprises for cost-effective AI services. Supports Claude Code, GPT, Gemini and major domestic models, with enterprise-grade high concurrency, fast invoicing, and 24/7 dedicated technical support. CC Switch users who register via &lt;a href=&quot;https://aicoding.sh/i/CCSWITCH&quot;&gt;this link&lt;/a&gt; get 10% off their first top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://crazyrouter.com/register?aff=OZcm&amp;ref=cc-switch&quot;&gt;&lt;img src=&quot;assets/partners/logos/crazyrouter.jpg&quot; alt=&quot;AICoding&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to Crazyrouter for sponsoring this project! Crazyrouter is a high-performance AI API aggregation platform ‚Äî one API key for 300+ models including Claude Code, Codex, Gemini CLI, and more. All models at 55% of official pricing with auto-failover, smart routing, and unlimited concurrency. Crazyrouter offers an exclusive deal for CC Switch users: register via &lt;a href=&quot;https://crazyrouter.com/register?aff=OZcm&amp;ref=cc-switch&quot;&gt;this link&lt;/a&gt;  to get &lt;strong&gt;$2 free credit&lt;/strong&gt; instantly, plus enter promo code `CCSWITCH` on your first top-up for an extra &lt;strong&gt;30% bonus credit&lt;/strong&gt;! &lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.sssaicode.com/register?ref=DCP0SM&quot;&gt;&lt;img src=&quot;assets/partners/logos/sssaicode.png&quot; alt=&quot;SSSAiCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to SSSAiCode for sponsoring this project! SSSAiCode is a stable and reliable API relay service, dedicated to providing stable, reliable, and affordable Claude and Codex model services, &lt;strong&gt;offering high cost-effective official Claude service at just ¬•0.5/$ equivalent&lt;/strong&gt;, supporting monthly and pay-as-you-go billing plans with same-day fast invoicing. SSSAiCode offers a special deal for CC Switch users: register via &lt;a href=&quot;https://www.sssaicode.com/register?ref=DCP0SM&quot;&gt;this link&lt;/a&gt; to enjoy $10 extra credit on every top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

## Screenshots

|                  Main Interface                   |                  Add Provider                  |
| :-----------------------------------------------: | :--------------------------------------------: |
| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |

## Features

### Current Version: v3.10.2 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.9.0-en.md)

**v3.8.0 Major Update (2025-11-28)**

**Persistence Architecture Upgrade &amp; Brand New UI**

- **SQLite + JSON Dual-layer Architecture**
  - Migrated from JSON file storage to SQLite + JSON dual-layer structure
  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite
  - Device-level data (window state, local paths) stored in JSON
  - Lays the foundation for future cloud sync functionality
  - Schema version management for database migrations

- **Brand New User Interface**
  - Completely redesigned interface layout
  - Unified component styles and smoother animations
  - Optimized visual hierarchy
  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility

- **Japanese Language Support**
  - Added Japanese interface support (now supports Chinese/English/Japanese)

- **Auto Launch on Startup**
  - One-click enable/disable in settings
  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)

- **Skills Recursive Scanning**
  - Support for multi-level directory structures
  - Allow same-named skills from different repositories

- **Critical Bug Fixes**
  - Fixed custom endpoints lost when updating providers
  - Fixed Gemini configuration write issues
  - Fixed Linux WebKitGTK rendering issues

**v3.7.0 Highlights**

**Six Core Features, 18,000+ Lines of New Code**

- **Gemini CLI Integration**
  - Third supported AI CLI (Claude Code / Codex / Gemini)
  - Dual-file configuration support (`.env` + `settings.json`)
  - Complete MCP server management
  - Presets: Google Official (OAuth) / PackyCode / Custom

- **Claude Skills Management System**
  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)
  - One-click install/uninstall to `~/.claude/skills/`
  - Custom repository support + subdirectory scanning
  - Complete lifecycle management (discover/install/update)

- **Prompts Management System**
  - Multi-preset system prompt management (unlimited presets, quick switching)
  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)
  - Markdown editor (CodeMirror 6 + real-time preview)
  - Smart backfill protection, preserves manual modifications

- **MCP v3.7.0 Unified Architecture**
  - Single panel manages MCP servers across three applications
  - New SSE (Server-Sent Events) transport type
  - Smart JSON parser + Codex TOML format auto-correction
  - Unified import/export + bidirectional sync

- **Deep Link Protocol**
  - `ccswitch://` protocol registration (all platforms)
  - One-click import provider configs via shared links
  - Security validation + lifecycle integration

- **Environment Variable Conflict Detection**
  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)
  - Visual conflict indicators + resolution suggestions
  - Override warnings + backup before changes

**Core Capabilities**

- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations
- **AWS Bedrock Support**: Built-in AWS Bedrock provider presets with AKSK and API Key authentication, cross-region inference support (global/us/eu/apac), covering Claude Code and OpenCode
- **Speed Testing**: Measure API endpoint latency with visual quality indicators
- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)
- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)
- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations

**v3.6 Highlights**

- Provider duplication &amp; drag-and-drop sorting
- Multi-endpoint management &amp; custom config directory (cloud sync ready)
- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)
- WSL environment support with auto-sync on directory change
- 100% hooks test coverage &amp; complete architecture refactoring

**System Features**

- System tray with quick switching
- Single instance daemon
- Built-in auto-updater
- Atomic writes with rollback protection

## Download &amp; Installation

### System Requirements

- **Windows**: Windows 10 and above
- **macOS**: macOS 10.15 (Catalina) and above
- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions

### Windows Users

Download the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.

### macOS Users

**Method 1: Install via Homebrew (Recommended)**

```bash
brew tap farion1231/ccswitch
brew install --cask cc-switch
```

Update:

```bash
brew upgrade --cask cc-switch
```

**Method 2: Manual Download**

Download `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.

&gt; **Note**: Since the author doesn&#039;t have an Apple Developer account, you may see an &quot;unidentified developer&quot; warning on first launch. Please close it first, then go to &quot;System Settings&quot; ‚Üí &quot;Privacy &amp; Security&quot; ‚Üí click &quot;Open Anyway&quot;, and you&#039;ll be able to open it normally afterwards.

### Arch Linux Users

**Install via paru (Recommended)**

```bash
paru -S cc-switch-bin
```

### Linux Users

Download the latest Linux build from the [Releases](../../releases) page:

- `CC-Switch-v{version}-Linux.deb` (Debian/Ubuntu)
- `CC-Switch-v{version}-Linux.rpm` (Fedora/RHEL/openSUSE)
- `CC-Switch-v{version}-Linux.AppImage` (Universal)
- `CC-Switch-v{version}-Linux.flatpak` (Flatpak)

Flatpak install &amp; run:

```bash
flatpak install --user ./CC-Switch-v{version}-Linux.flatpak
flatpak run com.ccswitch.desktop
```

## Quick Start

### Basic Usage

1. **Add Provider**: Click &quot;Add Provider&quot; ‚Üí Choose preset or create custom configuration
2. **Switch Provider**:
   - Main UI: Select provider ‚Üí Click &quot;Enable&quot;
   - System Tray: Click provider name directly (instant effect)
3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes
4. **Back to Official**: Select the &quot;Official Login&quot; preset (Claude/Codex) or &quot;Google Official&quot; preset (Gemini), restart the corresponding client, then follow its login/OAuth flow

### MCP Management

- **Location**: Click &quot;MCP&quot; button in top-right corner
- **Add Server**:
  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)
  - Support stdio / http / sse transport types
  - Configure independent MCP servers for different apps
- **Enable/Disable**: Toggle switches to control which servers sync to live config
- **Sync**: Enabled servers auto-sync to each app&#039;s live files
- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files

### Skills Management (v3.7.0 New)

- **Location**: Click &quot;Skills&quot; button in top-right corner
- **Discover Skills**:
  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)
  - Add custom repositories (supports subdirectory scanning)
- **Install Skills**: Click &quot;Install&quot; to one-click install to `~/.claude/skills/`
- **Uninstall Skills**: Click &quot;Uninstall&quot; to safely remove and clean up state
- **Manage Repositories**: Add/remove custom GitHub repositories

### Prompts Management (v3.7.0 New)

- **Location**: Click &quot;Prompts&quot; button in top-right corner
- **Create Presets**:
  - Create unlimited system prompt presets
  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)
- **Switch Presets**: Select preset ‚Üí Click &quot;Activate&quot; to apply immediately
- **Sync Mechanism**:
  - Claude: `~/.claude/CLAUDE.md`
  - Codex: `~/.codex/AGENTS.md`
  - Gemini: `~/.gemini/GEMINI.md`
- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications

### Configuration Files

**Claude Code**

- Live config: `~/.claude/settings.json` (or `claude.json`)
- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`
- MCP servers: `~/.claude.json` ‚Üí `mcpServers`

**Codex**

- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)
- API key field: `OPENAI_API_KEY` in `auth.json`
- MCP servers: `~/.codex/config.toml` ‚Üí `[mcp_servers]` tables

**Gemini**

- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)
- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`
- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.
- MCP servers: `~/.gemini/settings.json` ‚Üí `mcpServers`
- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI

**CC Switch Storage (v3.8.0 New Architecture)**

- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)
- Local settings: `~/.cc-switch/settings.json` (device-level settings)
- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)

### Cloud Sync Setup

1. Go to Settings ‚Üí &quot;Custom Configuration Directory&quot;
2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)
3. Restart app to apply
4. Repeat on other devices to enable cross-device sync

&gt; **Note**: First launch auto-imports existing Claude/Codex configs as default provider.

## Architecture Overview

### Design Principles

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (React + TS)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Components  ‚îÇ  ‚îÇ    Hooks     ‚îÇ  ‚îÇ  TanStack Query  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (UI)      ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Logic) ‚îÇ‚îÄ‚îÄ‚îÇ   (Cache/Sync)   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ Tauri IPC
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Backend (Tauri + Rust)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Commands   ‚îÇ  ‚îÇ   Services   ‚îÇ  ‚îÇ  Models/Config   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ (API Layer) ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Layer) ‚îÇ‚îÄ‚îÄ‚îÇ     (Data)       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Core Design Patterns**

- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)
- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings
- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider
- **Atomic Writes**: Temp file + rename pattern prevents config corruption
- **Concurrency Safe**: Mutex-protected database connection avoids race conditions
- **Layered Architecture**: Clear separation (Commands ‚Üí Services ‚Üí DAO ‚Üí Database)

**Key Components**

- **ProviderService**: Provider CRUD, switching, backfill, sorting
- **McpService**: MCP server management, import/export, live file sync
- **ConfigService**: Config import/export, backup rotation
- **SpeedtestService**: API endpoint latency measurement

**v3.6 Refactoring**

- Backend: 5-phase refactoring (error handling ‚Üí command split ‚Üí tests ‚Üí services ‚Üí concurrency)
- Frontend: 4-stage refactoring (test infra ‚Üí hooks ‚Üí components ‚Üí cleanup)
- Testing: 100% hooks coverage + integration tests (vitest + MSW)

## Development

### Environment Requirements

- Node.js 18+
- pnpm 8+
- Rust 1.85+
- Tauri CLI 2.8+

### D

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>TypeScript</category>
        </item>
        <item>
            <title><![CDATA[pgdogdev/pgdog]]></title>
            <link>https://github.com/pgdogdev/pgdog</link>
            <guid>https://github.com/pgdogdev/pgdog</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:59 GMT</pubDate>
            <description><![CDATA[PostgreSQL connection pooler, load balancer and database sharder.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pgdogdev/pgdog">pgdogdev/pgdog</a></h1>
            <p>PostgreSQL connection pooler, load balancer and database sharder.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,970</p>
            <p>Forks: 142</p>
            <p>Stars today: 75 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;/.github/logo2-white.png&quot; height=&quot;128&quot; width=&quot;auto&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;/.github/logo2_wide.png&quot; height=&quot;128&quot; width=&quot;auto&quot;&gt;
      &lt;img alt=&quot;Fallback image description&quot; src=&quot;/.github/logo2-white.png&quot; height=&quot;128&quot; width=&quot;auto&quot;&gt;
    &lt;/picture&gt;
&lt;/p&gt;

[![CI](https://github.com/levkk/pgdog/actions/workflows/ci.yml/badge.svg)](https://github.com/levkk/pgdog/actions/workflows/ci.yml)

PgDog is a proxy for scaling PostgreSQL. It supports connection pooling, load balancing queries and sharding entire databases. Written in Rust, PgDog is fast, secure and can manage thousands of connections on commodity hardware.

## Documentation

&amp;#128216; PgDog documentation can be **[found here](https://docs.pgdog.dev/)**. Any questions? Chat with us on **[Discord](https://discord.com/invite/CcBZkjSJdd)**.

## Quick start

### Kubernetes

Helm chart is **[here](https://github.com/pgdogdev/helm)**. To install it, run:

```bash
helm repo add pgdogdev https://helm.pgdog.dev
helm install pgdog pgdogdev/pgdog
```

### AWS

If you&#039;re using AWS RDS, you can deploy PgDog using one of two supported methods:

1. [Helm chart](https://github.com/pgdogdev/helm) with [EKS](https://aws.amazon.com/eks/), or a self-hosted Kubernetes cluster
2. [Terraform module](https://github.com/pgdogdev/pgdog-ecs-terraform) to deploy PgDog on [ECS](https://aws.amazon.com/ecs/)

### Try in Docker

You can try PgDog quickly using Docker. Install [Docker Compose](https://docs.docker.com/compose/) and run:

```
docker-compose up
```

Once started, you can connect to PgDog with psql or any other PostgreSQL client:

```
PGPASSWORD=postgres psql -h 127.0.0.1 -p 6432 -U postgres
```

The demo comes with 3 shards and 2 sharded tables:

```sql
INSERT INTO users (id, email) VALUES (1, &#039;admin@acme.com&#039;);
INSERT INTO payments (id, user_id, amount) VALUES (1, 1, 100.0);

SELECT * FROM users WHERE id = 1;
SELECT * FROM payments WHERE user_id = 1;
```

## Features

&amp;#128216; **[Configuration](https://docs.pgdog.dev/configuration/)**

All PgDog features are configurable and can be turned on and off. PgDog requires 2 configuration files to operate:

1. `pgdog.toml`: hosts, sharding configuration, and other settings
2. `users.toml`: usernames and passwords

### Example

Most options have reasonable defaults, so a basic configuration for a single user
and database running on the same machine is pretty short:

**`pgdog.toml`**

```toml
[general]
port = 6432
default_pool_size = 10

[[databases]]
name = &quot;pgdog&quot;
host = &quot;127.0.0.1&quot;
```

**`users.toml`**

```toml
[[users]]
name = &quot;alice&quot;
database = &quot;pgdog&quot;
password = &quot;hunter2&quot;
```

If a database in `pgdog.toml` doesn&#039;t have a user in `users.toml`, the connection pool for that database will not be created and users won&#039;t be able to connect.

If you&#039;d like to try it out locally, create the database and user like so:

```sql
CREATE DATABASE pgdog;
CREATE USER pgdog PASSWORD &#039;pgdog&#039; LOGIN;
```

### Transaction pooling

&amp;#128216; **[Transactions](https://docs.pgdog.dev/features/transaction-mode)**

Like PgBouncer, PgDog supports transaction (and session) pooling, allowing
thousands of clients to use just a few PostgreSQL server connections.

Unlike PgBouncer, PgDog can parse and handle `SET` statements and startup options, ensuring session state is set correctly when sharing server connections between clients with different parameters.

PgDog also has more advanced connection recovery options, like automatic abandoned transaction rollbacks and connection re-synchronization to avoid churning server connections during an application crash.

### Load balancer

&amp;#128216; **[Load balancer](https://docs.pgdog.dev/features/load-balancer/)**

PgDog is an application layer (OSI Level 7) load balancer for PostgreSQL. It understands the Postgres protocol, can proxy multiple replicas (and primary) and distributes transactions evenly between databases. The load balancer supports 3 strategies: round robin, random and least active connections.


**Example**

The load balancer is enabled automatically when a database has more than one host:

```toml
[[databases]]
name = &quot;prod&quot;
host = &quot;10.0.0.1&quot;
role = &quot;primary&quot;

[[databases]]
name = &quot;prod&quot;
host = &quot;10.0.0.2&quot;
role = &quot;replica&quot;
```

#### Health checks

&amp;#128216; **[Healthchecks](https://docs.pgdog.dev/features/load-balancer/healthchecks/)**


PgDog maintains a real-time list of healthy hosts. When a database fails a health check, it&#039;s removed from the active rotation and queries are re-routed to other replicas. This works like an HTTP load balancer, except it&#039;s for your database.

Health checks maximize database availability and protect against bad network connections, temporary hardware failures or misconfiguration.


#### Single endpoint

&amp;#128216; **[Single endpoint](https://docs.pgdog.dev/features/load-balancer/#single-endpoint)**


PgDog uses [`pg_query`](https://github.com/pganalyze/pg_query.rs), which includes the PostgreSQL native parser. By parsing queries, PgDog can detect writes (e.g. `INSERT`, `UPDATE`, `CREATE TABLE`, etc.) and send them to the primary, leaving the replicas to serve reads (`SELECT`). This allows applications to connect to the same PgDog deployment for both reads and writes.


##### Transactions

&amp;#128216; **[Load balancer &amp; transactions](https://docs.pgdog.dev/features/load-balancer/transactions/)**


Transactions can execute multiple statements, so in a primary &amp; replica configuration, PgDog routes them to the primary. Clients can indicate a transaction is read-only, in which case PgDog will send it to a replica:

```sql
BEGIN READ ONLY;
-- This goes to a replica.
SELECT * FROM users LIMIT 1;
COMMIT;
```


#### Failover

&amp;#128216; **[Failover](https://docs.pgdog.dev/features/load-balancer/replication-failover/)**


PgDog monitors Postgres replication state and can automatically redirect writes to a different database if a replica is promoted. This doesn&#039;t replace tools like Patroni that actually orchestrate failovers. You can use PgDog alongside Patroni (or AWS RDS or other managed Postgres host), to gracefully failover live traffic.


**Example**

To enable failover, set all database `role` attributes to `auto` and enable replication monitoring (`lsn_check_delay` setting):

```toml
[general]
lsn_check_delay = 0

[[databases]]
name = &quot;prod&quot;
host = &quot;10.0.0.1&quot;
role = &quot;auto&quot;

[[databases]]
name = &quot;prod&quot;
host = &quot;10.0.0.2&quot;
role = &quot;auto&quot;
```

### Sharding

&amp;#128216; **[Sharding](https://docs.pgdog.dev/features/sharding/)**

PgDog is able to manage databases with multiple shards. By using the PostgreSQL parser, PgDog extracts sharding keys and determines the best routing strategy for each query.

For cross-shard queries, PgDog assembles and transforms results in memory, sending all rows to the client as if they are coming from a single database.

**Example**

Configuring multiple hosts for the same database with different shard numbers (`shard` setting) enables sharding:

```toml
[[databases]]
name = &quot;prod&quot;
host = &quot;10.0.0.1&quot;
shard = 0

[[databases]]
name = &quot;prod&quot;
host = &quot;10.0.0.2&quot;
shard = 1
```

Note: read below for how to configure query routing. At least one sharded table is required for sharding to work as expected.

#### Sharding functions

&amp;#128216; **[Sharding functions](https://docs.pgdog.dev/features/sharding/sharding-functions/)**

PgDog has two main sharding algorithms:

1. PostgreSQL partition functions (`HASH`, `LIST`, `RANGE`)
2. Using schemas

##### Partition-based sharding

Partition-based sharding functions are taken directly from Postgres source code. This choice intentionally allows to shard data both with PgDog and with Postgres [foreign tables](https://www.postgresql.org/docs/current/sql-createforeigntable.html) and [`postgres_fdw`](https://www.postgresql.org/docs/current/postgres-fdw.html).

**Examples**

The `PARTITION BY HASH` algorithm is used by default when configuring sharded tables:

```toml
[[sharded_tables]]
database = &quot;prod&quot;
column = &quot;user_id&quot;
```

List-based sharding (same as `PARTITION BY LIST` in Postgres) can be configured as follows:

```toml
# Sharded table definition still required.
[[sharded_tables]]
database = &quot;prod&quot;
column = &quot;user_id&quot;

# Value-specific shard mappings.
[[sharded_mapping]]
database = &quot;prod&quot;
column = &quot;user_id&quot;
values = [1, 2, 3, 4]
shard = 0

[[sharded_mapping]]
database = &quot;prod&quot;
column = &quot;user_id&quot;
values = [5, 6, 7, 8]
shard = 1
```

For range-based sharding, replace the `values` setting with a range, for example:

```toml
start = 0 # include
end = 5 # exclusive
```

##### Schema-based sharding

&amp;#128216; **[Schema-based sharding](https://docs.pgdog.dev/configuration/pgdog.toml/sharded_schemas/)**

Schema-based sharding works on the basis of PostgreSQL schemas. Tables under the same schema are placed on the same shard and all queries that refer to those tables are routed to that shard automatically.

**Example**

Configuring sharded schemas uses a different configuration from sharded tables:

```toml
[[sharded_schemas]]
database = &quot;prod&quot;
name = &quot;customer_a&quot;
shard = 0

[[sharded_schemas]]
database = &quot;prod&quot;
name = &quot;customer_b&quot;
shard = 1
```

Queries that refer tables in schema `customer_a` will be sent to shard 0. For example, a query that refers to a table by its fully-qualified name will be sent to one shard only:

```sql
INSERT INTO customer_a.orders (id, user_id, amount)
VALUES ($1, $2, $3);
```

Alternatively, the schema name can be specified in the `search_path` session variable:

```sql
SET search_path TO public, customer_a;
-- All subsequent queries will be sent to shard 0.
SELECT * FROM orders LIMIT 1;
```

You can also set the `search_path` for the duration of a single transaction, using `SET LOCAL`, ensuring only that transaction is sent to the desired shard:

```sql
-- The entire transaction will be sent to shard 1.
BEGIN;
SET LOCAL search_path TO public, customer_b;
SELECT * FROM orders LIMIT 1;
COMMIT;
```

#### Direct-to-shard queries

&amp;#128216; **[Direct-to-shard queries](https://docs.pgdog.dev/features/sharding/query-routing/)**


Queries that contain a sharding key are sent to one database only. This is the best case scenario for sharded databases, since the load is uniformly distributed across the cluster.

**Example**:

```sql
-- user_id is the sharding key.
SELECT * FROM users WHERE user_id = $1;
```

#### Cross-shard queries

- &amp;#128216; **[Cross-shard queries](https://docs.pgdog.dev/features/sharding/cross-shard-queries/)**
- &amp;#128216; **[SELECT](https://docs.pgdog.dev/features/sharding/cross-shard-queries/select/)**
- &amp;#128216; **[INSERT](https://docs.pgdog.dev/features/sharding/cross-shard-queries/insert/)**
- &amp;#128216; **[UPDATE and DELETE](https://docs.pgdog.dev/features/sharding/cross-shard-queries/update/)**
- &amp;#128216; **[DDL](https://docs.pgdog.dev/features/sharding/cross-shard-queries/ddl/)**

Queries with multiple sharding keys or without one are sent to all databases and results are post-processed and assembled in memory. PgDog then sends the final result to the client.

Currently, support for certain SQL features in cross-shard queries is limited. However, the list of supported ones keeps growing:

| Feature | Supported | Notes |
|-|-|-|
| Aggregates | Partial | `count`, `min`, `max`, `stddev`, `variance`, `sum`, `avg` are supported. |
| `ORDER BY` | Partial | Column in `ORDER BY` clause must be present in the result set. |
| `GROUP BY` | Partial | Same as `ORDER BY`, referenced columns must be present in result set. |
| Multi-tuple `INSERT` | Supported | PgDog generates one statement per tuple and executes them automatically. |
| Sharding key `UPDATE` | Supported | PgDog generates a `SELECT`, `INSERT` and `DELETE` statements and execute them automatically. |
| Subqueries | No | The same subquery is executed on all shards. |
| CTEs | No | The same CTE is executed on all shards. |


#### Using `COPY`

&amp;#128216; **[Copy](https://docs.pgdog.dev/features/sharding/cross-shard-queries/copy/)**

PgDog has a text, CSV &amp; binary parser and can split rows sent via `COPY` command between all shards automatically. This allows clients to ingest data into sharded PostgreSQL without preprocessing

**Example**

```sql
COPY orders (id, user_id, amount) FROM STDIN CSV HEADER;
```

Columns must be specified in the `COPY` statement, so PgDog can infer the sharding key automatically, but are optional in the data file.


#### Consistency (two-phase commit)

&amp;#128216; **[Two-phase commit](https://docs.pgdog.dev/features/sharding/2pc/)**

To make sure cross-shard writes are atomic, PgDog supports Postgres&#039; [two-phase transactions](https://www.postgresql.org/docs/current/two-phase.html). When enabled, PgDog handles `COMMIT` statements sent by clients by executing the 2pc exchange on their behalf:

```sql
PREPARE TRANSACTION &#039;__pgdog_unique_id&#039;;
COMMIT PREPARED &#039;__pgdog_unique_id&#039;;
```

In case the client disconnects or Postgres crashes, PgDog will automatically rollback the transaction if it&#039;s in phase I and commit it if it&#039;s in phase II.

#### Unique identifiers

&amp;#128216; **[Unique IDs](https://docs.pgdog.dev/features/sharding/unique-ids/)**

While applications can use `UUID` (v4 and now v7) to generate unique primary keys, PgDog supports creating unique `BIGINT` identifiers, without using a sequence:

```sql
SELECT pgdog.unique_id();
```

This uses a timestamp-based algorithm, can produce millions of unique numbers per second and doesn&#039;t require an expensive cross-shard index to guarantee uniqueness.

#### Shard key updates

PgDog supports changing the sharding key for a row online. Under the hood, it will execute 3 statements to make it happen:

1. `SELECT` to get the entire row from its original shard
2. `INSERT` to write the new, changed row to the new shard
3. `DELETE` to remove it from the old shard

This happens automatically, and the client can retrieve the new row as normal:

```sql
UPDATE orders SET user_id = 5 WHERE user_id = 1 RETURNING *;
-- This will return the new row
```

Note: Only one row can be updated at a time and if a query attempts to update multiple, PgDog will abort the transaction.

To enable shard key updates, add this to `pgdog.toml`:

```toml
[rewrite]
enabled = true
shard_key = &quot;rewrite&quot; # options: ignore (possible data loss), error (block shard key update)
```

#### Multi-tuple inserts

PgDog can handle multi-tuple `INSERT` queries by sending each tuple to the right shard, e.g.:

```sql
INSERT INTO payments
    (id, user_id, amount) -- user_id is the sharding key
VALUES
(pgdog.unique_id(), 1, 25.00), -- Tuples go to different shards
(pgdog.unique_id(), 5, 55.0); -- Each tuple gets a unique primary key because unique ID function is invoked twice
```

This happens automatically, if enabled:

```toml
[rewrite]
enabled = true
split_inserts = &quot;rewrite&quot; # other options: ignore, error
```

#### Re-sharding

- &amp;#128216; **[Re-sharding](https://docs.pgdog.dev/features/sharding/resharding/)**
- &amp;#128216; **[Schema sync](https://docs.pgdog.dev/features/sharding/resharding/schema/)**
- &amp;#128216; **[Data sync](https://docs.pgdog.dev/features/sharding/resharding/hash/)**

PgDog understands the PostgreSQL logical replication protocol and can orchestrate data splits between databases, in the background and without downtime. This allows to shard existing databases and add more shards to existing clusters in production, without impacting database operations.

The re-sharding process is done in 5 steps:

1. Create new empty cluster with the desired number of shards
2. Configure it in `pgdog.toml` and run `schema-sync` command to copy table schemas to the new databases
3. Run `data-sync` command to copy and re-shard table data with logical replication (tables are copied in parallel)
4. While keeping previous command running (it streams row updates in real-time), run `schema-sync --data-sync-complete` to create secondary indexes on the new databases (much faster to do this after data is copied)
5. Cutover traffic to new cluster with `MAINTENANCE ON`, `RELOAD`, `MAINTENANCE OFF` command sequence

Cutover can be done atomically with multiple PgDog containers because `RELOAD` doesn&#039;t resume traffic, `MAINTENANCE OFF` does, so the config is the same in all containers before queries are resumed. No complex synchronization tooling like etcd or  Zookeeper is required.

### Monitoring

&amp;#128216; **[Metrics](https://docs.pgdog.dev/features/metrics/)**

PgDog exposes both the standard PgBouncer-style admin database and an OpenMetrics endpoint. The admin database isn&#039;t 100% compatible,
so we recommend you use OpenMetrics for monitoring. Example Datadog configuration and dashboard are [included](examples/datadog).


## Running PgDog locally

Install the latest version of the Rust compiler from [rust-lang.org](https://rust-lang.org).
Clone this repository and build the project in release mode:

```bash
cargo build --release
```

It&#039;s important to use the release profile if you&#039;re deploying to production or want to run
performance benchmarks.

#### Try sharding

Sharded database clusters are set in the config. For example, to set up a 2 shard cluster, you can:

**`pgdog.toml`**

```toml
[[databases]]
name = &quot;pgdog_sharded&quot;
host = &quot;127.0.0.1&quot;
database_name = &quot;shard_0&quot;
shard = 0

[[databases]]
name = &quot;pgdog_sharded&quot;
host = &quot;127.0.0.1&quot;
database_name = &quot;shard_1&quot;
shard = 1

[[sharded_tables]]
database = &quot;pgdog_sharded&quot;
column = &quot;user_id&quot;
```

Don&#039;t forget to configure a user:

**`users.toml`**

```toml
[[users]]
database = &quot;pgdog_sharded&quot;
name = &quot;pgdog&quot;
password = &quot;pgdog&quot;
```

And finally, to make it work locally, create the required databases:

```sql
CREATE DATABASE shard_0;
CREATE DATABASE shard_1;

GRANT ALL ON DATABASE shard_0 TO pgdog;
GRANT ALL ON DATABASE shard_1 TO pgdog;
```

### Start PgDog

Running PgDog can be done with Cargo:

```bash
cargo run --release
```

#### Command-line options

PgDog supports several command-line options:

- `-c, --config &lt;CONFIG&gt;`: Path to the configuration file (default: `&quot;pgdog.toml&quot;`)
- `-u, --users &lt;USERS&gt;`: Path to the users.toml file (default: `&quot;users.toml&quot;`)
- `-d, --database_url &lt;DATABASE_URL&gt;`: Connection URL(s). Can be specified multiple times to add multiple database connections. When provided, these URLs override database configurations from the config file.

Example using database URLs directly:

```bash
cargo run --release -- -d postgres://user:pass@localhost:5432/db1 -d postgres://user:pass@localhost:5433/db2
```

You can connect to PgDog with `psql` or any other PostgreSQL client:

```bash
psql postgres://pgdog:pgdog@127.0.0.1:6432/pgdog
```

## &amp;#128678; Status &amp;#128678;

PgDog is used in production and at scale. Most features are stable, while some are experimental. Check [documentation](https://docs.pgdog.dev/features/) for more details. New sharding features are added almost weekly.

## Performance

&amp;#128216; **[Architecture &amp; benchmarks](https://docs.pgdog.dev/architecture/)**

PgDog is heavily optimized for performance. We use Rust, [Tokio](https://tokio.rs/), [bytes crate](https://docs.rs/bytes/latest/bytes/) to avoid unnecessary memory allocations, and profile for performance regressions on a regular basis.

## License

PgDog is free and open source software, licensed under the AGPL v3. While often misunderstood, this license is very permissive
and allows the following without any additional requirements from you or your organization:

* Internal use
* Private modifications for internal use without sharing any source code

You can freely use PgDog to power your PostgreSQL databases without having to
share any source code, including proprietary work product or any PgDog modifications you make.

AGPL was written specifically for organizations that offer PgDog _as a public service_ (e.g. database cloud providers) and require
those organizations to share any modifications they make to PgDog, including new features and bug fixes.

## Contributions

Pl

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lance-format/lance]]></title>
            <link>https://github.com/lance-format/lance</link>
            <guid>https://github.com/lance-format/lance</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:58 GMT</pubDate>
            <description><![CDATA[Open Lakehouse Format for Multimodal AI. Convert from Parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lance-format/lance">lance-format/lance</a></h1>
            <p>Open Lakehouse Format for Multimodal AI. Convert from Parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..</p>
            <p>Language: Rust</p>
            <p>Stars: 6,087</p>
            <p>Forks: 562</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;

&lt;img width=&quot;257&quot; alt=&quot;Lance Logo&quot; src=&quot;https://user-images.githubusercontent.com/917119/199353423-d3e202f7-0269-411d-8ff2-e747e419e492.png&quot;&gt;

**The Open Lakehouse Format for Multimodal AI**&lt;br/&gt;
**High-performance vector search, full-text search, random access, and feature engineering capabilities for the lakehouse.**&lt;br/&gt;
**Compatible with Pandas, DuckDB, Polars, PyArrow, Ray, Spark, and more integrations on the way.**

&lt;a href=&quot;https://lance.org&quot;&gt;Documentation&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://lance.org/community&quot;&gt;Community&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://discord.gg/lance&quot;&gt;Discord&lt;/a&gt;

[CI]: https://github.com/lance-format/lance/actions/workflows/rust.yml
[CI Badge]: https://github.com/lance-format/lance/actions/workflows/rust.yml/badge.svg
[Docs]: https://lance.org
[Docs Badge]: https://img.shields.io/badge/docs-passing-brightgreen
[crates.io]: https://crates.io/crates/lance
[crates.io badge]: https://img.shields.io/crates/v/lance.svg
[Python versions]: https://pypi.org/project/pylance/
[Python versions badge]: https://img.shields.io/pypi/pyversions/pylance

[![CI Badge]][CI]
[![Docs Badge]][Docs]
[![crates.io badge]][crates.io]
[![Python versions badge]][Python versions]

&lt;/p&gt;
&lt;/div&gt;

&lt;hr /&gt;

Lance is an open lakehouse format for multimodal AI. It contains a file format, table format, and catalog spec that allows you to build a complete lakehouse on top of object storage to power your AI workflows. Lance is perfect for:

1. Building search engines and feature stores with hybrid search capabilities.
2. Large-scale ML training requiring high performance IO and random access.
3. Storing, querying, and managing multimodal data including images, videos, audio, text, and embeddings.

The key features of Lance include:

* **Expressive hybrid search:** Combine vector similarity search, full-text search (BM25), and SQL analytics on the same dataset with accelerated secondary indices.

* **Lightning-fast random access:** 100x faster than Parquet or Iceberg for random access without sacrificing scan performance.

* **Native multimodal data support:** Store images, videos, audio, text, and embeddings in a single unified format with efficient blob encoding and lazy loading.

* **Data evolution:** Efficiently add columns with backfilled values without full table rewrites, perfect for ML feature engineering.

* **Zero-copy versioning:** Automatic versioning with ACID transactions, time travel, tags, and branches‚Äîno extra infrastructure needed.

* **Rich ecosystem integrations:** Apache Arrow, Pandas, Polars, DuckDB, Apache Spark, Ray, Trino, Apache Flink, and open catalogs (Apache Polaris, Unity Catalog, Apache Gravitino).

For more details, see the full [Lance format specification](https://lance.org/format).

&gt; [!TIP]
&gt; Lance is in active development and we welcome contributions. Please see our [contributing guide](https://lance.org/community/contributing/) for more information.

## Quick Start

**Installation**

```shell
pip install pylance
```

To install a preview release:

```shell
pip install --pre --extra-index-url https://pypi.fury.io/lance-format/pylance
```

&gt; [!NOTE]
&gt; For versions prior to 1.0.0-beta.4, you can find them at https://pypi.fury.io/lancedb/pylance

&gt; [!TIP]
&gt; Preview releases are released more often than full releases and contain the
&gt; latest features and bug fixes. They receive the same level of testing as full releases.
&gt; We guarantee they will remain published and available for download for at
&gt; least 6 months. When you want to pin to a specific version, prefer a stable release.

**Converting to Lance**

```python
import lance

import pandas as pd
import pyarrow as pa
import pyarrow.dataset

df = pd.DataFrame({&quot;a&quot;: [5], &quot;b&quot;: [10]})
uri = &quot;/tmp/test.parquet&quot;
tbl = pa.Table.from_pandas(df)
pa.dataset.write_dataset(tbl, uri, format=&#039;parquet&#039;)

parquet = pa.dataset.dataset(uri, format=&#039;parquet&#039;)
lance.write_dataset(parquet, &quot;/tmp/test.lance&quot;)
```

**Reading Lance data**
```python
dataset = lance.dataset(&quot;/tmp/test.lance&quot;)
assert isinstance(dataset, pa.dataset.Dataset)
```

**Pandas**
```python
df = dataset.to_table().to_pandas()
df
```

**DuckDB**
```python
import duckdb

# If this segfaults, make sure you have duckdb v0.7+ installed
duckdb.query(&quot;SELECT * FROM dataset LIMIT 10&quot;).to_df()
```

**Vector search**

Download the sift1m subset

```shell
wget ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz
tar -xzf sift.tar.gz
```

Convert it to Lance

```python
import lance
from lance.vector import vec_to_table
import numpy as np
import struct

nvecs = 1000000
ndims = 128
with open(&quot;sift/sift_base.fvecs&quot;, mode=&quot;rb&quot;) as fobj:
    buf = fobj.read()
    data = np.array(struct.unpack(&quot;&lt;128000000f&quot;, buf[4 : 4 + 4 * nvecs * ndims])).reshape((nvecs, ndims))
    dd = dict(zip(range(nvecs), data))

table = vec_to_table(dd)
uri = &quot;vec_data.lance&quot;
sift1m = lance.write_dataset(table, uri, max_rows_per_group=8192, max_rows_per_file=1024*1024)
```

Build the index

```python
sift1m.create_index(&quot;vector&quot;,
                    index_type=&quot;IVF_PQ&quot;,
                    num_partitions=256,  # IVF
                    num_sub_vectors=16)  # PQ
```

Search the dataset

```python
# Get top 10 similar vectors
import duckdb

dataset = lance.dataset(uri)

# Sample 100 query vectors. If this segfaults, make sure you have duckdb v0.7+ installed
sample = duckdb.query(&quot;SELECT vector FROM dataset USING SAMPLE 100&quot;).to_df()
query_vectors = np.array([np.array(x) for x in sample.vector])

# Get nearest neighbors for all of them
rs = [dataset.to_table(nearest={&quot;column&quot;: &quot;vector&quot;, &quot;k&quot;: 10, &quot;q&quot;: q})
      for q in query_vectors]
```

## Directory structure

| Directory          | Description              |
|--------------------|--------------------------|
| [rust](./rust)     | Core Rust implementation |
| [python](./python) | Python bindings (PyO3)   |
| [java](./java)     | Java bindings (JNI)      |
| [docs](./docs)     | Documentation source     |

## Benchmarks

### Vector search

We used the SIFT dataset to benchmark our results with 1M vectors of 128D

1. For 100 randomly sampled query vectors, we get &lt;1ms average response time (on a 2023 m2 MacBook Air)

![avg_latency.png](docs/src/images/avg_latency.png)

2. ANNs are always a trade-off between recall and performance

![avg_latency.png](docs/src/images/recall_vs_latency.png)

### Vs. parquet

We create a Lance dataset using the Oxford Pet dataset to do some preliminary performance testing of Lance as compared to Parquet and raw image/XMLs. For analytics queries, Lance is 50-100x better than reading the raw metadata. For batched random access, Lance is 100x better than both parquet and raw files.

![](docs/src/images/lance_perf.png)

## Why Lance for AI/ML workflows?

The machine learning development cycle involves multiple stages:

```mermaid
graph LR
    A[Collection] --&gt; B[Exploration];
    B --&gt; C[Analytics];
    C --&gt; D[Feature Engineer];
    D --&gt; E[Training];
    E --&gt; F[Evaluation];
    F --&gt; C;
    E --&gt; G[Deployment];
    G --&gt; H[Monitoring];
    H --&gt; A;
```

Traditional lakehouse formats were designed for SQL analytics and struggle with AI/ML workloads that require:
- **Vector search** for similarity and semantic retrieval
- **Fast random access** for sampling and interactive exploration
- **Multimodal data** storage (images, videos, audio alongside embeddings)
- **Data evolution** for feature engineering without full table rewrites
- **Hybrid search** combining vectors, full-text, and SQL predicates

While existing formats (Parquet, Iceberg, Delta Lake) excel at SQL analytics, they require additional specialized systems for AI capabilities. Lance brings these AI-first features directly into the lakehouse format.

A comparison of different formats across ML development stages:

|                     | Lance | Parquet &amp; ORC | JSON &amp; XML | TFRecord | Database | Warehouse |
|---------------------|-------|---------------|------------|----------|----------|-----------|
| Analytics           | Fast  | Fast          | Slow       | Slow     | Decent   | Fast      |
| Feature Engineering | Fast  | Fast          | Decent     | Slow     | Decent   | Good      |
| Training            | Fast  | Decent        | Slow       | Fast     | N/A      | N/A       |
| Exploration         | Fast  | Slow          | Fast       | Slow     | Fast     | Decent    |
| Infra Support       | Rich  | Rich          | Decent     | Limited  | Rich     | Rich      |

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lbjlaq/Antigravity-Manager]]></title>
            <link>https://github.com/lbjlaq/Antigravity-Manager</link>
            <guid>https://github.com/lbjlaq/Antigravity-Manager</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:57 GMT</pubDate>
            <description><![CDATA[Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).‰∏ì‰∏öÁöÑ Antigravity Ë¥¶Âè∑ÁÆ°ÁêÜ‰∏éÂàáÊç¢Â∑•ÂÖ∑„ÄÇ‰∏∫ Antigravity Êèê‰æõ‰∏ÄÈîÆÊó†ÁºùË¥¶Âè∑ÂàáÊç¢ÂäüËÉΩ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lbjlaq/Antigravity-Manager">lbjlaq/Antigravity-Manager</a></h1>
            <p>Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).‰∏ì‰∏öÁöÑ Antigravity Ë¥¶Âè∑ÁÆ°ÁêÜ‰∏éÂàáÊç¢Â∑•ÂÖ∑„ÄÇ‰∏∫ Antigravity Êèê‰æõ‰∏ÄÈîÆÊó†ÁºùË¥¶Âè∑ÂàáÊç¢ÂäüËÉΩ„ÄÇ</p>
            <p>Language: Rust</p>
            <p>Stars: 24,294</p>
            <p>Forks: 2,722</p>
            <p>Stars today: 134 stars today</p>
            <h2>README</h2><pre># Antigravity Tools üöÄ
&gt; ‰∏ì‰∏öÁ∫ß AI Ë¥¶Âè∑ÁÆ°ÁêÜ‰∏éÂçèËÆÆ‰ª£ÁêÜÁ≥ªÁªü (v4.1.23)
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;public/icon.png&quot; alt=&quot;Antigravity Logo&quot; width=&quot;120&quot; height=&quot;120&quot; style=&quot;border-radius: 24px; box-shadow: 0 10px 30px rgba(0,0,0,0.15);&quot;&gt;

  &lt;h3&gt;ÊÇ®ÁöÑ‰∏™‰∫∫È´òÊÄßËÉΩ AI Ë∞ÉÂ∫¶ÁΩëÂÖ≥&lt;/h3&gt;
  &lt;p&gt;‰∏ç‰ªÖ‰ªÖÊòØË¥¶Âè∑ÁÆ°ÁêÜÔºåÊõ¥ÊòØÊâìÁ†¥ API Ë∞ÉÁî®Â£ÅÂûíÁöÑÁªàÊûÅËß£ÂÜ≥ÊñπÊ°à„ÄÇ&lt;/p&gt;
  
  &lt;p&gt;
    &lt;a href=&quot;https://github.com/lbjlaq/Antigravity-Manager&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Version-4.1.23-blue?style=flat-square&quot; alt=&quot;Version&quot;&gt;
    &lt;/a&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Tauri-v2-orange?style=flat-square&quot; alt=&quot;Tauri&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Backend-Rust-red?style=flat-square&quot; alt=&quot;Rust&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Frontend-React-61DAFB?style=flat-square&quot; alt=&quot;React&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-CC--BY--NC--SA--4.0-lightgrey?style=flat-square&quot; alt=&quot;License&quot;&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;#-Ê†∏ÂøÉÂäüËÉΩ&quot;&gt;Ê†∏ÂøÉÂäüËÉΩ&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-ÁïåÈù¢ÂØºËßà&quot;&gt;ÁïåÈù¢ÂØºËßà&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-ÊäÄÊúØÊû∂ÊûÑ&quot;&gt;ÊäÄÊúØÊû∂ÊûÑ&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-ÂÆâË£ÖÊåáÂçó&quot;&gt;ÂÆâË£ÖÊåáÂçó&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-Âø´ÈÄüÊé•ÂÖ•&quot;&gt;Âø´ÈÄüÊé•ÂÖ•&lt;/a&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;strong&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/strong&gt; | 
    &lt;a href=&quot;./README_EN.md&quot;&gt;English&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

---

**Antigravity Tools** ÊòØ‰∏Ä‰∏™‰∏ì‰∏∫ÂºÄÂèëËÄÖÂíå AI Áà±Â•ΩËÄÖËÆæËÆ°ÁöÑÂÖ®ÂäüËÉΩÊ°åÈù¢Â∫îÁî®„ÄÇÂÆÉÂ∞ÜÂ§öË¥¶Âè∑ÁÆ°ÁêÜ„ÄÅÂçèËÆÆËΩ¨Êç¢ÂíåÊô∫ËÉΩËØ∑Ê±ÇË∞ÉÂ∫¶ÂÆåÁæéÁªìÂêàÔºå‰∏∫ÊÇ®Êèê‰æõ‰∏Ä‰∏™Á®≥ÂÆö„ÄÅÊûÅÈÄü‰∏îÊàêÊú¨‰ΩéÂªâÁöÑ **Êú¨Âú∞ AI ‰∏≠ËΩ¨Á´ô**„ÄÇ

ÈÄöËøáÊú¨Â∫îÁî®ÔºåÊÇ®ÂèØ‰ª•Â∞ÜÂ∏∏ËßÅÁöÑ Web Á´Ø Session (Google/Anthropic) ËΩ¨Âåñ‰∏∫Ê†áÂáÜÂåñÁöÑ API Êé•Âè£ÔºåÊ∂àÈô§‰∏çÂêåÂéÇÂïÜÈó¥ÁöÑÂçèËÆÆÈ∏øÊ≤ü„ÄÇ

## üíñ ËµûÂä©ÂïÜ (Sponsors)

| ËµûÂä©ÂïÜ (Sponsor) | ÁÆÄ‰ªã (Description) |
| :---: | :--- |
| &lt;img src=&quot;docs/images/packycode_logo.png&quot; width=&quot;200&quot; alt=&quot;PackyCode Logo&quot;&gt; | ÊÑüË∞¢ **PackyCode** ÂØπÊú¨È°πÁõÆÁöÑËµûÂä©ÔºÅPackyCode ÊòØ‰∏ÄÂÆ∂ÂèØÈù†È´òÊïàÁöÑ API ‰∏≠ËΩ¨ÊúçÂä°ÂïÜÔºåÊèê‰æõ Claude Code„ÄÅCodex„ÄÅGemini Á≠âÂ§öÁßçÊúçÂä°ÁöÑ‰∏≠ËΩ¨„ÄÇPackyCode ‰∏∫Êú¨È°πÁõÆÁöÑÁî®Êà∑Êèê‰æõ‰∫ÜÁâπÂà´‰ºòÊÉ†Ôºö‰ΩøÁî®[Ê≠§ÈìæÊé•](https://www.packyapi.com/register?aff=Ctrler)Ê≥®ÂÜåÔºåÂπ∂Âú®ÂÖÖÂÄºÊó∂ËæìÂÖ• **‚ÄúCtrler‚Äù** ‰ºòÊÉ†Á†ÅÂç≥ÂèØ‰∫´Âèó **‰πùÊäò‰ºòÊÉ†**„ÄÇ |
| &lt;img src=&quot;docs/images/AICodeMirror.jpg&quot; width=&quot;200&quot; alt=&quot;AICodeMirror Logo&quot;&gt; | ÊÑüË∞¢ AICodeMirror ËµûÂä©‰∫ÜÊú¨È°πÁõÆÔºÅAICodeMirror Êèê‰æõ Claude Code / Codex / Gemini CLI ÂÆòÊñπÈ´òÁ®≥ÂÆö‰∏≠ËΩ¨ÊúçÂä°ÔºåÊîØÊåÅ‰ºÅ‰∏öÁ∫ßÈ´òÂπ∂Âèë„ÄÅÊûÅÈÄüÂºÄÁ•®„ÄÅ7√ó24 ‰∏ìÂ±ûÊäÄÊúØÊîØÊåÅ„ÄÇ Claude Code / Codex / Gemini ÂÆòÊñπÊ∏†ÈÅì‰ΩéËá≥ 3.8 / 0.2 / 0.9 ÊäòÔºåÂÖÖÂÄºÊõ¥ÊúâÊäò‰∏äÊäòÔºÅAICodeMirror ‰∏∫ Antigravity-Manager ÁöÑÁî®Êà∑Êèê‰æõ‰∫ÜÁâπÂà´Á¶èÂà©ÔºåÈÄöËøá[Ê≠§ÈìæÊé•](https://www.aicodemirror.com/register?invitecode=MV5XUM)Ê≥®ÂÜåÁöÑÁî®Êà∑ÔºåÂèØ‰∫´ÂèóÈ¶ñÂÖÖ8ÊäòÔºå‰ºÅ‰∏öÂÆ¢Êà∑ÊúÄÈ´òÂèØ‰∫´ 7.5 ÊäòÔºÅ |

### ‚òï ÊîØÊåÅÈ°πÁõÆ (Support)

Â¶ÇÊûúÊÇ®ËßâÂæóÊú¨È°πÁõÆÂØπÊÇ®ÊúâÊâÄÂ∏ÆÂä©ÔºåÊ¨¢ËøéÊâìËµè‰ΩúËÄÖÔºÅ

&lt;a href=&quot;https://www.buymeacoffee.com/Ctrler&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://cdn.buymeacoffee.com/buttons/v2/default-green.png&quot; alt=&quot;ËØ∑ÊàëÂñùÊùØÂíñÂï°&quot; style=&quot;height: 60px !important; width: 217px !important;&quot;&gt;&lt;/a&gt;

| ÊîØ‰ªòÂÆù (Alipay) | ÂæÆ‰ø°ÊîØ‰ªò (WeChat) | Buy Me a Coffee |
| :---: | :---: | :---: |
| ![Alipay](./docs/images/donate_alipay.png) | ![WeChat](./docs/images/donate_wechat.png) | ![Coffee](./docs/images/donate_coffee.png) |

## üåü Ê∑±Â∫¶ÂäüËÉΩËß£Êûê (Detailed Features)

### 1. üéõÔ∏è Êô∫ËÉΩË¥¶Âè∑‰ª™Ë°®Áõò (Smart Dashboard)
*   **ÂÖ®Â±ÄÂÆûÊó∂ÁõëÊéß**: ‰∏ÄÁúºÊ¥ûÂØüÊâÄÊúâË¥¶Âè∑ÁöÑÂÅ•Â∫∑Áä∂ÂÜµÔºåÂåÖÊã¨ Gemini Pro„ÄÅGemini Flash„ÄÅClaude ‰ª•Âèä Gemini ÁªòÂõæÁöÑ **Âπ≥ÂùáÂâ©‰ΩôÈÖçÈ¢ù**„ÄÇ
*   **ÊúÄ‰Ω≥Ë¥¶Âè∑Êé®Ëçê (Smart Recommendation)**: Á≥ªÁªü‰ºöÊ†πÊçÆÂΩìÂâçÊâÄÊúâË¥¶Âè∑ÁöÑÈÖçÈ¢ùÂÜó‰ΩôÂ∫¶ÔºåÂÆûÊó∂ÁÆóÊ≥ïÁ≠õÈÄâÂπ∂Êé®Ëçê‚ÄúÊúÄ‰Ω≥Ë¥¶Âè∑‚ÄùÔºåÊîØÊåÅ **‰∏ÄÈîÆÂàáÊç¢**„ÄÇ
*   **Ê¥ªË∑ÉË¥¶Âè∑Âø´ÁÖß**: Áõ¥ËßÇÊòæÁ§∫ÂΩìÂâçÊ¥ªË∑ÉË¥¶Âè∑ÁöÑÂÖ∑‰ΩìÈÖçÈ¢ùÁôæÂàÜÊØîÂèäÊúÄÂêéÂêåÊ≠•Êó∂Èó¥„ÄÇ

### 2. üîê Âº∫Â§ßÁöÑË¥¶Âè∑ÁÆ°ÂÆ∂ (Account Management)
*   **OAuth 2.0 ÊéàÊùÉÔºàËá™Âä®/ÊâãÂä®Ôºâ**: Ê∑ªÂä†Ë¥¶Âè∑Êó∂‰ºöÊèêÂâçÁîüÊàêÂèØÂ§çÂà∂ÁöÑÊéàÊùÉÈìæÊé•ÔºåÊîØÊåÅÂú®‰ªªÊÑèÊµèËßàÂô®ÂÆåÊàêÊéàÊùÉÔºõÂõûË∞ÉÊàêÂäüÂêéÂ∫îÁî®‰ºöËá™Âä®ÂÆåÊàêÂπ∂‰øùÂ≠òÔºàÂøÖË¶ÅÊó∂ÂèØÁÇπÂáª‚ÄúÊàëÂ∑≤ÊéàÊùÉÔºåÁªßÁª≠‚ÄùÊâãÂä®Êî∂Â∞æÔºâ„ÄÇ
*   **Â§öÁª¥Â∫¶ÂØºÂÖ•**: ÊîØÊåÅÂçïÊù° Token ÂΩïÂÖ•„ÄÅJSON ÊâπÈáèÂØºÂÖ•ÔºàÂ¶ÇÊù•Ëá™ÂÖ∂‰ªñÂ∑•ÂÖ∑ÁöÑÂ§á‰ªΩÔºâÔºå‰ª•Âèä‰ªé V1 ÊóßÁâàÊú¨Êï∞ÊçÆÂ∫ìËá™Âä®ÁÉ≠ËøÅÁßª„ÄÇ
*   **ÁΩëÂÖ≥Á∫ßËßÜÂõæ**: ÊîØÊåÅ‚ÄúÂàóË°®‚Äù‰∏é‚ÄúÁΩëÊ†º‚ÄùÂèåËßÜÂõæÂàáÊç¢„ÄÇÊèê‰æõ 403 Â∞ÅÁ¶ÅÊ£ÄÊµãÔºåËá™Âä®Ê†áÊ≥®Âπ∂Ë∑≥ËøáÊùÉÈôêÂºÇÂ∏∏ÁöÑË¥¶Âè∑„ÄÇ

### 3. üîå ÂçèËÆÆËΩ¨Êç¢‰∏é‰∏≠Áªß (API Proxy)
*   **ÂÖ®ÂçèËÆÆÈÄÇÈÖç (Multi-Sink)**:
    *   **OpenAI Ê†ºÂºè**: Êèê‰æõ `/v1/chat/completions` Á´ØÁÇπÔºåÂÖºÂÆπ 99% ÁöÑÁé∞Êúâ AI Â∫îÁî®„ÄÇ
    *   **Anthropic Ê†ºÂºè**: Êèê‰æõÂéüÁîü `/v1/messages` Êé•Âè£ÔºåÊîØÊåÅ **Claude Code CLI** ÁöÑÂÖ®ÂäüËÉΩÔºàÂ¶ÇÊÄùÊÄùÁª¥Èìæ„ÄÅÁ≥ªÁªüÊèêÁ§∫ËØçÔºâ„ÄÇ
    *   **Gemini Ê†ºÂºè**: ÊîØÊåÅ Google ÂÆòÊñπ SDK Áõ¥Êé•Ë∞ÉÁî®„ÄÇ
*   **Êô∫ËÉΩÁä∂ÊÄÅËá™ÊÑà**: ÂΩìËØ∑Ê±ÇÈÅáÂà∞ `429 (Too Many Requests)` Êàñ `401 (Expire)` Êó∂ÔºåÂêéÁ´Ø‰ºöÊØ´ÁßíÁ∫ßËß¶Âèë **Ëá™Âä®ÈáçËØï‰∏éÈùôÈªòËΩÆÊç¢**ÔºåÁ°Æ‰øù‰∏öÂä°‰∏ç‰∏≠Êñ≠„ÄÇ

### 4. üîÄ Ê®°ÂûãË∑ØÁî±‰∏≠ÂøÉ (Model Router)
*   **Á≥ªÂàóÂåñÊò†Â∞Ñ**: ÊÇ®ÂèØ‰ª•Â∞ÜÂ§çÊùÇÁöÑÂéüÂßãÊ®°Âûã ID ÂΩíÁ±ªÂà∞‚ÄúËßÑÊ†ºÂÆ∂Êóè‚ÄùÔºàÂ¶ÇÂ∞ÜÊâÄÊúâ GPT-4 ËØ∑Ê±ÇÁªü‰∏ÄË∑ØÁî±Âà∞ `gemini-3-pro-high`Ôºâ„ÄÇ
*   **‰∏ìÂÆ∂Á∫ßÈáçÂÆöÂêë**: ÊîØÊåÅËá™ÂÆö‰πâÊ≠£ÂàôË°®ËææÂºèÁ∫ßÊ®°ÂûãÊò†Â∞ÑÔºåÁ≤æÂáÜÊéßÂà∂ÊØè‰∏Ä‰∏™ËØ∑Ê±ÇÁöÑËêΩÂú∞Ê®°Âûã„ÄÇ
*   **Êô∫ËÉΩÂàÜÁ∫ßË∑ØÁî± (Tiered Routing)**: [Êñ∞] Á≥ªÁªüÊ†πÊçÆË¥¶Âè∑Á±ªÂûãÔºàUltra/Pro/FreeÔºâÂíåÈÖçÈ¢ùÈáçÁΩÆÈ¢ëÁéáËá™Âä®‰ºòÂÖàÁ∫ßÊéíÂ∫èÔºå‰ºòÂÖàÊ∂àËÄóÈ´òÈÄüÈáçÁΩÆË¥¶Âè∑ÔºåÁ°Æ‰øùÈ´òÈ¢ëË∞ÉÁî®‰∏ãÁöÑÊúçÂä°Á®≥ÂÆöÊÄß„ÄÇ
*   **ÂêéÂè∞‰ªªÂä°ÈùôÈªòÈôçÁ∫ß**: [Êñ∞] Ëá™Âä®ËØÜÂà´ Claude CLI Á≠âÂ∑•ÂÖ∑ÁîüÊàêÁöÑÂêéÂè∞ËØ∑Ê±ÇÔºàÂ¶ÇÊ†áÈ¢òÁîüÊàêÔºâÔºåÊô∫ËÉΩÈáçÂÆöÂêëËá≥ Flash Ê®°ÂûãÔºå‰øùÊä§È´òÁ∫ßÊ®°ÂûãÈÖçÈ¢ù‰∏çË¢´Êµ™Ë¥π„ÄÇ

### 5. üé® Â§öÊ®°ÊÄÅ‰∏é Imagen 3 ÊîØÊåÅ
*   **È´òÁ∫ßÁîªË¥®ÊéßÂà∂**: ÊîØÊåÅÈÄöËøá OpenAI `size` (Â¶Ç `1024x1024`, `16:9`) ÂèÇÊï∞Ëá™Âä®Êò†Â∞ÑÂà∞ Imagen 3 ÁöÑÁõ∏Â∫îËßÑÊ†º„ÄÇ
*   **Ë∂ÖÂº∫ Body ÊîØÊåÅ**: ÂêéÁ´ØÊîØÊåÅÈ´òËææ **100MB** (ÂèØÈÖçÁΩÆ) ÁöÑ PayloadÔºåÂ§ÑÁêÜ 4K È´òÊ∏ÖÂõæËØÜÂà´Áª∞Áª∞Êúâ‰Ωô„ÄÇ

## üì∏ ÁïåÈù¢ÂØºËßà (GUI Overview)

| | |
| :---: | :---: |
| ![‰ª™Ë°®Áõò - ÂÖ®Â±ÄÈÖçÈ¢ùÁõëÊéß‰∏é‰∏ÄÈîÆÂàáÊç¢](docs/images/dashboard-light.png) &lt;br&gt; ‰ª™Ë°®Áõò | ![Ë¥¶Âè∑ÂàóË°® - È´òÂØÜÂ∫¶ÈÖçÈ¢ùÂ±ïÁ§∫‰∏é 403 Êô∫ËÉΩÊ†áÊ≥®](docs/images/accounts-light.png) &lt;br&gt; Ë¥¶Âè∑ÂàóË°® |
| ![ÂÖ≥‰∫éÈ°µÈù¢ - ÂÖ≥‰∫é Antigravity Tools](docs/images/about-dark.png) &lt;br&gt; ÂÖ≥‰∫éÈ°µÈù¢ | ![API Âèç‰ª£ - ÊúçÂä°ÊéßÂà∂](docs/images/v3/proxy-settings.png) &lt;br&gt; API Âèç‰ª£ |
| ![Á≥ªÁªüËÆæÁΩÆ - ÈÄöÁî®ÈÖçÁΩÆ](docs/images/settings-dark.png) &lt;br&gt; Á≥ªÁªüËÆæÁΩÆ | |

### üí° ‰ΩøÁî®Ê°à‰æã (Usage Examples)

| | |
| :---: | :---: |
| ![Claude Code ËÅîÁΩëÊêúÁ¥¢ - ÁªìÊûÑÂåñÊù•Ê∫ê‰∏éÂºïÊñáÊòæÁ§∫](docs/images/usage/claude-code-search.png) &lt;br&gt; Claude Code ËÅîÁΩëÊêúÁ¥¢ | ![Cherry Studio Ê∑±Â∫¶ÈõÜÊàê - ÂéüÁîüÂõûÊòæÊêúÁ¥¢ÂºïÊñá‰∏éÊù•Ê∫êÈìæÊé•](docs/images/usage/cherry-studio-citations.png) &lt;br&gt; Cherry Studio Ê∑±Â∫¶ÈõÜÊàê |
| ![Imagen 3 È´òÁ∫ßÁªòÂõæ - ÂÆåÁæéËøòÂéü Prompt ÊÑèÂ¢É‰∏éÁªÜËäÇ](docs/images/usage/image-gen-nebula.png) &lt;br&gt; Imagen 3 È´òÁ∫ßÁªòÂõæ | ![Kilo Code Êé•ÂÖ• - Â§öË¥¶Âè∑ÊûÅÈÄüËΩÆÊç¢‰∏éÊ®°ÂûãÁ©øÈÄè](docs/images/usage/kilo-code-integration.png) &lt;br&gt; Kilo Code Êé•ÂÖ• |

## üèóÔ∏è ÊäÄÊúØÊû∂ÊûÑ (Architecture)

```mermaid
graph TD
    Client([Â§ñÈÉ®Â∫îÁî®: Claude Code/NextChat]) --&gt;|OpenAI/Anthropic| Gateway[Antigravity Axum Server]
    Gateway --&gt; Middleware[‰∏≠Èó¥‰ª∂: Èâ¥ÊùÉ/ÈôêÊµÅ/Êó•Âøó]
    Middleware --&gt; Router[Model Router: ID Êò†Â∞Ñ]
    Router --&gt; Dispatcher[Ë¥¶Âè∑ÂàÜÂèëÂô®: ËΩÆËØ¢/ÊùÉÈáç]
    Dispatcher --&gt; Mapper[ÂçèËÆÆËΩ¨Êç¢Âô®: Request Mapper]
    Mapper --&gt; Upstream[‰∏äÊ∏∏ËØ∑Ê±Ç: Google/Anthropic API]
    Upstream --&gt; ResponseMapper[ÂìçÂ∫îËΩ¨Êç¢Âô®: Response Mapper]
    ResponseMapper --&gt; Client
```

##  ÂÆâË£ÖÊåáÂçó (Installation)

### ÈÄâÈ°π A: ÁªàÁ´ØÂÆâË£Ö (Êé®Ëçê)

#### Ë∑®Âπ≥Âè∞‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨

Ëá™Âä®Ê£ÄÊµãÊìç‰ΩúÁ≥ªÁªü„ÄÅÊû∂ÊûÑÂíåÂåÖÁÆ°ÁêÜÂô®Ôºå‰∏ÄÊù°ÂëΩ‰ª§ÂÆåÊàê‰∏ãËΩΩ‰∏éÂÆâË£Ö„ÄÇ

**Linux / macOS:**
```bash
curl -fsSL https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/v4.1.23/install.sh | bash
```

**Windows (PowerShell):**
```powershell
irm https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/main/install.ps1 | iex
```

&gt; **ÊîØÊåÅÁöÑÊ†ºÂºè**: Linux (`.deb` / `.rpm` / `.AppImage`) | macOS (`.dmg`) | Windows (NSIS `.exe`)
&gt;
&gt; **È´òÁ∫ßÁî®Ê≥ï**: ÂÆâË£ÖÊåáÂÆöÁâàÊú¨ `curl -fsSL ... | bash -s -- --version 4.1.23`ÔºåÈ¢ÑËßàÊ®°Âºè `curl -fsSL ... | bash -s -- --dry-run`

#### macOS - Homebrew
Â¶ÇÊûúÊÇ®Â∑≤ÂÆâË£Ö [Homebrew](https://brew.sh/)Ôºå‰πüÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÂëΩ‰ª§ÂÆâË£ÖÔºö

```bash
# 1. ËÆ¢ÈòÖÊú¨‰ªìÂ∫ìÁöÑ Tap
brew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager

# 2. ÂÆâË£ÖÂ∫îÁî®
brew install --cask antigravity-tools
```
&gt; **ÊèêÁ§∫**: Â¶ÇÊûúÈÅáÂà∞ÊùÉÈôêÈóÆÈ¢òÔºåÂª∫ËÆÆÊ∑ªÂä† `--no-quarantine` ÂèÇÊï∞„ÄÇ

#### Arch Linux
ÊÇ®ÂèØ‰ª•ÈÄâÊã©ÈÄöËøá‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨Êàñ Homebrew ËøõË°åÂÆâË£ÖÔºö

**ÊñπÂºè 1Ôºö‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨ (Êé®Ëçê)**
```bash
curl -sSL https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/main/deploy/arch/install.sh | bash
```

**ÊñπÂºè 2ÔºöÈÄöËøá Homebrew** (Â¶ÇÊûúÊÇ®Â∑≤ÂÆâË£Ö [Linuxbrew](https://sh.brew.sh/))
```bash
brew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager
brew install --cask antigravity-tools
```

#### ÂÖ∂‰ªñ Linux ÂèëË°åÁâà
ÂÆâË£ÖÂêé‰ºöËá™Âä®Â∞Ü AppImage Ê∑ªÂä†Âà∞‰∫åËøõÂà∂Ë∑ØÂæÑÂπ∂ÈÖçÁΩÆÂèØÊâßË°åÊùÉÈôê„ÄÇ

### ÈÄâÈ°π B: ÊâãÂä®‰∏ãËΩΩ
ÂâçÂæÄ [GitHub Releases](https://github.com/lbjlaq/Antigravity-Manager/releases) ‰∏ãËΩΩÂØπÂ∫îÁ≥ªÁªüÁöÑÂåÖÔºö
*   **macOS**: `.dmg` (ÊîØÊåÅ Apple Silicon &amp; Intel)
*   **Windows**: `.msi` Êàñ ‰æøÊê∫Áâà `.zip`
*   **Linux**: `.deb` Êàñ `AppImage`

### ÈÄâÈ°π C: Docker ÈÉ®ÁΩ≤ (Êé®ËçêÁî®‰∫é NAS/ÊúçÂä°Âô®)
Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®ÂÆπÂô®ÂåñÁéØÂ¢É‰∏≠ËøêË°åÔºåÊàë‰ª¨Êèê‰æõ‰∫ÜÂéüÁîüÁöÑ Docker ÈïúÂÉè„ÄÇËØ•ÈïúÂÉèÂÜÖÁΩÆ‰∫ÜÂØπ v4.0.2 ÂéüÁîü Headless Êû∂ÊûÑÁöÑÊîØÊåÅÔºåÂèØËá™Âä®ÊâòÁÆ°ÂâçÁ´ØÈùôÊÄÅËµÑÊ∫êÔºåÂπ∂ÈÄöËøáÊµèËßàÂô®Áõ¥Êé•ËøõË°åÁÆ°ÁêÜ„ÄÇ

```bash
# ÊñπÂºè 1: Áõ¥Êé•ËøêË°å (Êé®Ëçê)
# - API_KEY: ÂøÖÂ°´„ÄÇÁî®‰∫éÊâÄÊúâÂçèËÆÆÁöÑ AI ËØ∑Ê±ÇÈâ¥ÂÆö„ÄÇ
# - WEB_PASSWORD: ÂèØÈÄâ„ÄÇÁî®‰∫éÁÆ°ÁêÜÂêéÂè∞ÁôªÂΩï„ÄÇËã•‰∏çËÆæÁΩÆÂàôÈªòËÆ§‰ΩøÁî® API_KEY„ÄÇ
docker run -d --name antigravity-manager \
  -p 8045:8045 \
  -e API_KEY=sk-your-api-key \
  -e WEB_PASSWORD=your-login-password \
  -e ABV_MAX_BODY_SIZE=104857600 \
  -v ~/.antigravity_tools:/root/.antigravity_tools \
  lbjlaq/antigravity-manager:latest

# ÂøòËÆ∞ÂØÜÈí•ÔºüÊâßË°å docker logs antigravity-manager Êàñ grep -E &#039;&quot;api_key&quot;|&quot;admin_password&quot;&#039; ~/.antigravity_tools/gui_config.json

#### üîê Èâ¥ÊùÉÈÄªËæëËØ¥Êòé
*   **Âú∫ÊôØ AÔºö‰ªÖËÆæÁΩÆ‰∫Ü `API_KEY`**
    - **Web ÁôªÂΩï**Ôºö‰ΩøÁî® `API_KEY` ËøõÂÖ•ÂêéÂè∞„ÄÇ
    - **API Ë∞ÉÁî®**Ôºö‰ΩøÁî® `API_KEY` ËøõË°å AI ËØ∑Ê±ÇÈâ¥ÊùÉ„ÄÇ
*   **Âú∫ÊôØ BÔºöÂêåÊó∂ËÆæÁΩÆ‰∫Ü `API_KEY` Âíå `WEB_PASSWORD` (Êé®Ëçê)**
    - **Web ÁôªÂΩï**Ôºö**ÂøÖÈ°ª**‰ΩøÁî® `WEB_PASSWORD`Ôºå‰ΩøÁî® API Key Â∞ÜË¢´ÊãíÁªùÔºàÊõ¥ÂÆâÂÖ®Ôºâ„ÄÇ
    - **API Ë∞ÉÁî®**ÔºöÁªü‰∏Ä‰ΩøÁî® `API_KEY`„ÄÇËøôÊ†∑ÊÇ®ÂèØ‰ª•Â∞Ü API Key ÂàÜÂèëÁªôÊàêÂëòÔºåËÄå‰øùÁïôÂØÜÁ†Å‰ªÖ‰æõÁÆ°ÁêÜÂëò‰ΩøÁî®„ÄÇ

#### üÜô ÊóßÁâàÊú¨ÂçáÁ∫ßÊåáÂºï
Â¶ÇÊûúÊÇ®ÊòØ‰ªé v4.0.1 ÂèäÊõ¥Êó©ÁâàÊú¨ÂçáÁ∫ßÔºåÁ≥ªÁªüÈªòËÆ§Êú™ËÆæÁΩÆ `WEB_PASSWORD`„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ã‰ªª‰∏ÄÊñπÂºèËÆæÁΩÆÔºö
1.  **Web UI ÁïåÈù¢ (Êé®Ëçê)**Ôºö‰ΩøÁî®ÂéüÊúâ `API_KEY` ÁôªÂΩïÂêéÔºåÂú® **API Âèç‰ª£ËÆæÁΩÆ** È°µÈù¢ÊâãÂä®ËÆæÁΩÆÂπ∂‰øùÂ≠ò„ÄÇÊñ∞ÂØÜÁ†ÅÂ∞ÜÊåÅ‰πÖÂåñÂ≠òÂÇ®Âú® `gui_config.json` ‰∏≠„ÄÇ
2.  **ÁéØÂ¢ÉÂèòÈáè (Docker)**ÔºöÂú®ÂêØÂä®ÂÆπÂô®Êó∂Â¢ûÂä† `-e WEB_PASSWORD=ÊÇ®ÁöÑÊñ∞ÂØÜÁ†Å`„ÄÇ**Ê≥®ÊÑèÔºöÁéØÂ¢ÉÂèòÈáèÂÖ∑ÊúâÊúÄÈ´ò‰ºòÂÖàÁ∫ßÔºåÂ∞ÜË¶ÜÁõñ UI ‰∏≠ÁöÑ‰ªª‰Ωï‰øÆÊîπ„ÄÇ**
3.  **ÈÖçÁΩÆÊñá‰ª∂ (ÊåÅ‰πÖÂåñ)**ÔºöÁõ¥Êé•‰øÆÊîπ `~/.antigravity_tools/gui_config.json`ÔºåÂú® `proxy` ÂØπË±°‰∏≠‰øÆÊîπÊàñÊ∑ªÂä† `&quot;admin_password&quot;: &quot;ÊÇ®ÁöÑÊñ∞ÂØÜÁ†Å&quot;` Â≠óÊÆµ„ÄÇ
    - *Ê≥®Ôºö`WEB_PASSWORD` ÊòØÁéØÂ¢ÉÂèòÈáèÂêçÔºå`admin_password` ÊòØÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑ JSON ÈîÆÂêç„ÄÇ*

&gt; [!TIP]
&gt; **ÂØÜÁ†Å‰ºòÂÖàÁ∫ßÈÄªËæë (Priority)**:
&gt; - **Á¨¨‰∏Ä‰ºòÂÖàÁ∫ß (ÁéØÂ¢ÉÂèòÈáè)**: `ABV_WEB_PASSWORD` Êàñ `WEB_PASSWORD`„ÄÇÂè™Ë¶ÅËÆæÁΩÆ‰∫ÜÁéØÂ¢ÉÂèòÈáèÔºåÁ≥ªÁªüÂ∞ÜÂßãÁªà‰ΩøÁî®ÂÆÉ„ÄÇ
&gt; - **Á¨¨‰∫å‰ºòÂÖàÁ∫ß (ÈÖçÁΩÆÊñá‰ª∂)**: `gui_config.json` ‰∏≠ÁöÑ `admin_password` Â≠óÊÆµ„ÄÇUI ÁöÑ‚Äú‰øùÂ≠ò‚ÄùÊìç‰Ωú‰ºöÊõ¥Êñ∞Ê≠§ÂÄº„ÄÇ
&gt; - **‰øùÂ∫ïÂõûÈÄÄ (ÂêëÂêéÂÖºÂÆπ)**: Ëã•‰∏äËø∞ÂùáÊú™ËÆæÁΩÆÔºåÂàôÂõûÈÄÄ‰ΩøÁî® `API_KEY` ‰Ωú‰∏∫ÁôªÂΩïÂØÜÁ†Å„ÄÇ

# ÊñπÂºè 2: ‰ΩøÁî® Docker Compose
# 1. ËøõÂÖ•È°πÁõÆÁöÑ docker ÁõÆÂΩï
cd docker
# 2. ÂêØÂä®ÊúçÂä°
docker compose up -d
```
&gt; **ËÆøÈóÆÂú∞ÂùÄ**: `http://localhost:8045` (ÁÆ°ÁêÜÂêéÂè∞) | `http://localhost:8045/v1` (API Base)
&gt; **Á≥ªÁªüË¶ÅÊ±Ç**:
&gt; - **ÂÜÖÂ≠ò**: Âª∫ËÆÆ **1GB** (ÊúÄÂ∞è 256MB)„ÄÇ
&gt; - **ÊåÅ‰πÖÂåñ**: ÈúÄÊåÇËΩΩ `/root/.antigravity_tools` ‰ª•‰øùÂ≠òÊï∞ÊçÆ„ÄÇ
&gt; - **Êû∂ÊûÑ**: ÊîØÊåÅ x86_64 Âíå ARM64„ÄÇ
&gt; **ËØ¶ÊÉÖËßÅ**: [Docker ÈÉ®ÁΩ≤ÊåáÂçó (docker)](./docker/README.md)

---

Copyright ¬© 2024-2026 [lbjlaq](https://github.com/lbjlaq)

### üõ†Ô∏è Â∏∏ËßÅÈóÆÈ¢òÊéíÊü• (Troubleshooting)

#### macOS ÊèêÁ§∫‚ÄúÂ∫îÁî®Â∑≤ÊçüÂùèÔºåÊó†Ê≥ïÊâìÂºÄ‚ÄùÔºü
Áî±‰∫é macOS ÁöÑÂÆâÂÖ®Êú∫Âà∂ÔºåÈùû App Store ‰∏ãËΩΩÁöÑÂ∫îÁî®ÂèØËÉΩ‰ºöËß¶ÂèëÊ≠§ÊèêÁ§∫„ÄÇÊÇ®ÂèØ‰ª•ÊåâÁÖß‰ª•‰∏ãÊ≠•È™§Âø´ÈÄü‰øÆÂ§çÔºö

1.  **ÂëΩ‰ª§Ë°å‰øÆÂ§ç** (Êé®Ëçê):
    ÊâìÂºÄÁªàÁ´ØÔºåÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö
    ```bash
    sudo xattr -rd com.apple.quarantine &quot;/Applications/Antigravity Tools.app&quot;
    ```
2.  **Homebrew ÂÆâË£ÖÊäÄÂ∑ß**:
    Â¶ÇÊûúÊÇ®‰ΩøÁî® brew ÂÆâË£ÖÔºåÂèØ‰ª•Ê∑ªÂä† `--no-quarantine` ÂèÇÊï∞Êù•ËßÑÈÅøÊ≠§ÈóÆÈ¢òÔºö
    ```bash
    brew install --cask --no-quarantine antigravity-tools
    ```

## üîå Âø´ÈÄüÊé•ÂÖ•Á§∫‰æã

### üîê OAuth ÊéàÊùÉÊµÅÁ®ãÔºàÊ∑ªÂä†Ë¥¶Âè∑Ôºâ
1. ÊâìÂºÄ‚ÄúAccounts / Ë¥¶Âè∑‚Äù ‚Üí ‚ÄúÊ∑ªÂä†Ë¥¶Âè∑‚Äù ‚Üí ‚ÄúOAuth‚Äù„ÄÇ
2. ÂºπÁ™ó‰ºöÂú®ÁÇπÂáªÊåâÈíÆÂâçÈ¢ÑÁîüÊàêÊéàÊùÉÈìæÊé•ÔºõÁÇπÂáªÈìæÊé•Âç≥ÂèØÂ§çÂà∂Âà∞Á≥ªÁªüÂâ™Ë¥¥ÊùøÔºåÁÑ∂ÂêéÁî®‰Ω†Â∏åÊúõÁöÑÊµèËßàÂô®ÊâìÂºÄÂπ∂ÂÆåÊàêÊéàÊùÉ„ÄÇ
3. ÊéàÊùÉÂÆåÊàêÂêéÊµèËßàÂô®‰ºöÊâìÂºÄÊú¨Âú∞ÂõûË∞ÉÈ°µÂπ∂ÊòæÁ§∫‚Äú‚úÖ ÊéàÊùÉÊàêÂäü!‚Äù„ÄÇ
4. Â∫îÁî®‰ºöËá™Âä®ÁªßÁª≠ÂÆåÊàêÊéàÊùÉÂπ∂‰øùÂ≠òË¥¶Âè∑ÔºõÂ¶ÇÊú™Ëá™Âä®ÂÆåÊàêÔºåÂèØÁÇπÂáª‚ÄúÊàëÂ∑≤ÊéàÊùÉÔºåÁªßÁª≠‚ÄùÊâãÂä®ÂÆåÊàê„ÄÇ

&gt; ÊèêÁ§∫ÔºöÊéàÊùÉÈìæÊé•ÂåÖÂê´‰∏ÄÊ¨°ÊÄßÂõûË∞ÉÁ´ØÂè£ÔºåËØ∑ÂßãÁªà‰ΩøÁî®ÂºπÁ™óÈáåÁîüÊàêÁöÑÊúÄÊñ∞ÈìæÊé•ÔºõÂ¶ÇÊûúÊéàÊùÉÊó∂Â∫îÁî®Êú™ËøêË°åÊàñÂºπÁ™óÂ∑≤ÂÖ≥Èó≠ÔºåÊµèËßàÂô®ÂèØËÉΩ‰ºöÊèêÁ§∫ `localhost refused connection`„ÄÇ

### Â¶Ç‰ΩïÊé•ÂÖ• Claude Code CLI?
1.  ÂêØÂä® AntigravityÔºåÂπ∂Âú®‚ÄúAPI Âèç‰ª£‚ÄùÈ°µÈù¢ÂºÄÂêØÊúçÂä°„ÄÇ
2.  Âú®ÁªàÁ´ØÊâßË°åÔºö
```bash
export ANTHROPIC_API_KEY=&quot;sk-antigravity&quot;
export ANTHROPIC_BASE_URL=&quot;http://127.0.0.1:8045&quot;
claude
```

### Â¶Ç‰ΩïÊé•ÂÖ• OpenCode?
1.  ËøõÂÖ• **API Âèç‰ª£**È°µÈù¢ ‚Üí **Â§ñÈÉ® Providers** ‚Üí ÁÇπÂáª **OpenCode Sync** Âç°Áâá„ÄÇ
2.  ÁÇπÂáª **Sync** ÊåâÈíÆÔºåÂ∞ÜËá™Âä®ÁîüÊàê `~/.config/opencode/opencode.json` ÈÖçÁΩÆÊñá‰ª∂Ôºö
    - ÂàõÂª∫Áã¨Á´ã provider `antigravity-manager`Ôºà‰∏çË¶ÜÁõñ google/anthropic ÂéüÁîüÈÖçÁΩÆÔºâ
    - ÂèØÈÄâÔºöÂãæÈÄâ **Sync accounts** ÂØºÂá∫ `antigravity-accounts.json`Ôºàplugin-compatible v3 Ê†ºÂºèÔºâÔºå‰æõ OpenCode Êèí‰ª∂Áõ¥Êé•ÂØºÂÖ•
3.  ÁÇπÂáª **Clear Config** ÂèØ‰∏ÄÈîÆÊ∏ÖÈô§ Manager ÈÖçÁΩÆÂπ∂Ê∏ÖÁêÜ legacy ÊÆãÁïôÔºõÁÇπÂáª **Restore** ÂèØ‰ªéÂ§á‰ªΩÊÅ¢Â§ç„ÄÇ
4.  Windows Áî®Êà∑Ë∑ØÂæÑ‰∏∫ `C:\Users\&lt;Áî®Êà∑Âêç&gt;\.config\opencode\`Ôºà‰∏é `~/.config/opencode` ËßÑÂàô‰∏ÄËá¥Ôºâ„ÄÇ

**Âø´ÈÄüÈ™åËØÅÂëΩ‰ª§Ôºö**
```bash
# ÊµãËØï antigravity-manager providerÔºàÊîØÊåÅ --variantÔºâ
opencode run &quot;test&quot; --model antigravity-manager/claude-sonnet-4-5-thinking --variant high

# Ëã•Â∑≤ÂÆâË£Ö opencode-antigravity-auth Êèí‰ª∂ÔºåÈ™åËØÅ google provider ‰ªçÂèØÁã¨Á´ãÂ∑•‰Ωú
opencode run &quot;test&quot; --model google/antigravity-claude-sonnet-4-5-thinking --variant max
```

### Â¶Ç‰ΩïÊé•ÂÖ• Kilo Code?
1.  **ÂçèËÆÆÈÄâÊã©**: Âª∫ËÆÆ‰ºòÂÖà‰ΩøÁî® **Gemini ÂçèËÆÆ**„ÄÇ
2.  **Base URL**: Â°´ÂÜô `http://127.0.0.1:8045`„ÄÇ
3.  **Ê≥®ÊÑè**: 
    - **OpenAI ÂçèËÆÆÈôêÂà∂**: Kilo Code Âú®‰ΩøÁî® OpenAI Ê®°ÂºèÊó∂ÔºåÂÖ∂ËØ∑Ê±ÇË∑ØÂæÑ‰ºöÂè†Âä†‰∫ßÁîü `/v1/chat/completions/responses` ËøôÁßçÈùûÊ†áÂáÜË∑ØÂæÑÔºåÂØºËá¥ Antigravity ËøîÂõû 404„ÄÇÂõ†Ê≠§ËØ∑Âä°ÂøÖÂ°´ÂÖ• Base URL ÂêéÈÄâÊã© Gemini Ê®°Âºè„ÄÇ
    - **Ê®°ÂûãÊò†Â∞Ñ**: Kilo Code ‰∏≠ÁöÑÊ®°ÂûãÂêçÁß∞ÂèØËÉΩ‰∏é Antigravity ÈªòËÆ§ËÆæÁΩÆ‰∏ç‰∏ÄËá¥ÔºåÂ¶ÇÈÅáÂà∞Êó†Ê≥ïËøûÊé•ÔºåËØ∑Âú®‚ÄúÊ®°ÂûãÊò†Â∞Ñ‚ÄùÈ°µÈù¢ËÆæÁΩÆËá™ÂÆö‰πâÊò†Â∞ÑÔºåÂπ∂Êü•Áúã**Êó•ÂøóÊñá‰ª∂**ËøõË°åË∞ÉËØï„ÄÇ

### Â¶Ç‰ΩïÂú® Python ‰∏≠‰ΩøÁî®?
```python
import openai

client = openai.OpenAI(
    api_key=&quot;sk-antigravity&quot;,
    base_url=&quot;http://127.0.0.1:8045/v1&quot;
)

response = client.chat.completions.create(
    model=&quot;gemini-3-flash&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰Ω†Â•ΩÔºåËØ∑Ëá™Êàë‰ªãÁªç&quot;}]
)
print(response.choices[0].message.content)
```

### Â¶Ç‰Ωï‰ΩøÁî®ÂõæÁâáÁîüÊàê (Imagen 3)?

#### ÊñπÂºè‰∏ÄÔºöOpenAI Images API (Êé®Ëçê)
```python
import openai

client = openai.OpenAI(
    api_key=&quot;sk-antigravity&quot;,
    base_url=&quot;http://127.0.0.1:8045/v1&quot;
)

# ÁîüÊàêÂõæÁâá
response = client.images.generate(
    model=&quot;gemini-3-pro-image&quot;,
    prompt=&quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏ÇÔºåËµõÂçöÊúãÂÖãÔºåÈúìËôπÁÅØ&quot;,
    size=&quot;1920x1080&quot;,      # ÊîØÊåÅ‰ªªÊÑè WIDTHxHEIGHT Ê†ºÂºèÔºåËá™Âä®ËÆ°ÁÆóÂÆΩÈ´òÊØî
    quality=&quot;hd&quot;,          # &quot;standard&quot; | &quot;hd&quot; | &quot;medium&quot;
    n=1,
    response_format=&quot;b64_json&quot;
)

# ‰øùÂ≠òÂõæÁâá
import base64
image_data = base64.b64decode(response.data[0].b64_json)
with open(&quot;output.png&quot;, &quot;wb&quot;) as f:
    f.write(image_data)
```

**ÊîØÊåÅÁöÑÂèÇÊï∞**Ôºö
- **`size`**: ‰ªªÊÑè `WIDTHxHEIGHT` Ê†ºÂºèÔºàÂ¶Ç `1280x720`, `1024x1024`, `1920x1080`ÔºâÔºåËá™Âä®ËÆ°ÁÆóÂπ∂Êò†Â∞ÑÂà∞Ê†áÂáÜÂÆΩÈ´òÊØîÔºà21:9, 16:9, 9:16, 4:3, 3:4, 1:1Ôºâ
- **`quality`**: 
  - `&quot;hd&quot;` ‚Üí 4K ÂàÜËæ®ÁéáÔºàÈ´òË¥®ÈáèÔºâ
  - `&quot;medium&quot;` ‚Üí 2K ÂàÜËæ®ÁéáÔºà‰∏≠Á≠âË¥®ÈáèÔºâ
  - `&quot;standard&quot;` ‚Üí ÈªòËÆ§ÂàÜËæ®ÁéáÔºàÊ†áÂáÜË¥®ÈáèÔºâ
- **`n`**: ÁîüÊàêÂõæÁâáÊï∞ÈáèÔºà1-10Ôºâ
- **`response_format`**: `&quot;b64_json&quot;` Êàñ `&quot;url&quot;`ÔºàData URIÔºâ

#### ÊñπÂºè‰∫åÔºöChat API + ÂèÇÊï∞ËÆæÁΩÆ (‚ú® Êñ∞Â¢û)

**ÊâÄÊúâÂçèËÆÆ**ÔºàOpenAI„ÄÅClaudeÔºâÁöÑ Chat API Áé∞Âú®ÈÉΩÊîØÊåÅÁõ¥Êé•‰º†ÈÄí `size` Âíå `quality` ÂèÇÊï∞Ôºö

```python
# OpenAI Chat API
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image&quot;,
    size=&quot;1920x1080&quot;,      # ‚úÖ ÊîØÊåÅ‰ªªÊÑè WIDTHxHEIGHT Ê†ºÂºè
    quality=&quot;hd&quot;,          # ‚úÖ &quot;standard&quot; | &quot;hd&quot; | &quot;medium&quot;
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏Ç&quot;}]
)
```

```bash
# Claude Messages API
curl -X POST http://127.0.0.1:8045/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-antigravity&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gemini-3-pro-image&quot;,
    &quot;size&quot;: &quot;1280x720&quot;,
    &quot;quality&quot;: &quot;hd&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂè™ÂèØÁà±ÁöÑÁå´Âí™&quot;}]
  }&#039;
```

```

**ÂèÇÊï∞‰ºòÂÖàÁ∫ß**: `imageSize` ÂèÇÊï∞ &gt; `quality` ÂèÇÊï∞ &gt; Ê®°ÂûãÂêéÁºÄ

**‚ú® Êñ∞Â¢û `imageSize` ÂèÇÊï∞ÊîØÊåÅ**:

Èô§‰∫Ü `quality` ÂèÇÊï∞Â§ñ,Áé∞Âú®ËøòÊîØÊåÅÁõ¥Êé•‰ΩøÁî® Gemini ÂéüÁîüÁöÑ `imageSize` ÂèÇÊï∞:

```python
# ‰ΩøÁî® imageSize ÂèÇÊï∞(ÊúÄÈ´ò‰ºòÂÖàÁ∫ß)
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image&quot;,
    size=&quot;16:9&quot;,           # ÂÆΩÈ´òÊØî
    imageSize=&quot;4K&quot;,        # ‚ú® Áõ¥Êé•ÊåáÂÆöÂàÜËæ®Áéá: &quot;1K&quot; | &quot;2K&quot; | &quot;4K&quot;
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏Ç&quot;}]
)
```

```bash
# Claude Messages API ‰πüÊîØÊåÅ imageSize
curl -X POST http://127.0.0.1:8045/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-antigravity&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gemini-3-pro-image&quot;,
    &quot;size&quot;: &quot;1280x720&quot;,
    &quot;imageSize&quot;: &quot;4K&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂè™ÂèØÁà±ÁöÑÁå´Âí™&quot;}]
  }&#039;
```

**ÂèÇÊï∞ËØ¥Êòé**:
- **`imageSize`**: Áõ¥Êé•ÊåáÂÆöÂàÜËæ®Áéá (`&quot;1K&quot;` / `&quot;2K&quot;` / `&quot;4K&quot;`)
- **`quality`**: ÈÄöËøáË¥®ÈáèÁ≠âÁ∫ßÊé®Êñ≠ÂàÜËæ®Áéá (`&quot;standard&quot;` ‚Üí 1K, `&quot;medium&quot;` ‚Üí 2K, `&quot;hd&quot;` ‚Üí 4K)
- **‰ºòÂÖàÁ∫ß**: Â¶ÇÊûúÂêåÊó∂ÊåáÂÆö `imageSize` Âíå `quality`,Á≥ªÁªü‰ºö‰ºòÂÖà‰ΩøÁî® `imageSize`


#### ÊñπÂºè‰∏âÔºöChat Êé•Âè£ + Ê®°ÂûãÂêéÁºÄ
```python
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image-16-9-4k&quot;,  # Ê†ºÂºèÔºögemini-3-pro-image-[ÊØî‰æã]-[Ë¥®Èáè]
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏Ç&quot;}]
)
```

**Ê®°ÂûãÂêéÁºÄËØ¥Êòé**Ôºö
- **ÂÆΩÈ´òÊØî**: `-16-9`, `-9-16`, `-4-3`, `-3-4`, `-21-9`, `-1-1`
- **Ë¥®Èáè**: `-4k` (4K), `-2k` (2K), ‰∏çÂä†ÂêéÁºÄÔºàÊ†áÂáÜÔºâ
- **Á§∫‰æã**: `gemini-3-pro-image-16-9-4k` ‚Üí 16:9 ÊØî‰æã + 4K ÂàÜËæ®Áéá

#### ÊñπÂºèÂõõÔºöCherry Studio Á≠âÂÆ¢Êà∑Á´ØËÆæÁΩÆ
Âú®ÊîØÊåÅ OpenAI ÂçèËÆÆÁöÑÂÆ¢Êà∑Á´ØÔºàÂ¶Ç Cherry StudioÔºâ‰∏≠ÔºåÂèØ‰ª•ÈÄöËøá**Ê®°ÂûãËÆæÁΩÆ**È°µÈù¢ÈÖçÁΩÆÂõæÁâáÁîüÊàêÂèÇÊï∞Ôºö

1. **ËøõÂÖ•Ê®°ÂûãËÆæÁΩÆ**ÔºöÈÄâÊã© `gemini-3-pro-image` Ê®°Âûã
2. **ÈÖçÁΩÆÂèÇÊï∞**Ôºö
   - **Size (Â∞∫ÂØ∏)**: ËæìÂÖ•‰ªªÊÑè `WIDTHxHEIGHT` Ê†ºÂºèÔºàÂ¶Ç `1920x1080`, `1024x1024`Ôºâ
   - **Quality (Ë¥®Èáè)**: ÈÄâÊã© `standard` / `hd` / `medium`
   - **Number (Êï∞Èáè)**: ËÆæÁΩÆÁîüÊàêÂõæÁâáÊï∞ÈáèÔºà1-10Ôºâ
3. **ÂèëÈÄÅËØ∑Ê±Ç**ÔºöÁõ¥Êé•Âú®ÂØπËØùÊ°Ü‰∏≠ËæìÂÖ•ÂõæÁâáÊèèËø∞Âç≥ÂèØ

**ÂèÇÊï∞Êò†Â∞ÑËßÑÂàô**Ôºö
- `size: &quot;1920x1080&quot;` ‚Üí Ëá™Âä®ËÆ°ÁÆó‰∏∫ `16:9` ÂÆΩÈ´òÊØî
- `quality: &quot;hd&quot;` ‚Üí Êò†Â∞Ñ‰∏∫ `4K` ÂàÜËæ®Áéá
- `quality: &quot;medium&quot;` ‚Üí Êò†Â∞Ñ‰∏∫ `2K` ÂàÜËæ®Áéá


## üìù ÂºÄÂèëËÄÖ‰∏éÁ§æÂå∫

*   **ÁâàÊú¨ÊºîËøõ (Changelog)**:
    *   **v4.1.23 (2026-02-25)**:
        -   **[ÂÆâÂÖ®Â¢ûÂº∫] ‰ºòÂåñ‰∏éÂéüÁîüÂØπÈΩêÂ∫îÁî®Â±Ç‰∏éÂ∫ïÂ±ÇÁâπÂæÅÊåáÁ∫πÔºåÊèêÂçáËØ∑Ê±ÇÁ®≥ÂÆöÊÄß‰∏éÈò≤Êã¶Êà™ËÉΩÂäõ„ÄÇ**
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Â∞Ü v1beta thinkingLevel ËΩ¨Êç¢‰∏∫ v1internal thinkingBudget (PR #2095)**:
            -   **ÈóÆÈ¢òÊ†πÊ∫ê**: OpenClaw„ÄÅCline Á≠âÂÆ¢Êà∑Á´ØÂèëÈÄÅ v1beta Ê†ºÂºèÁöÑ `thinkingLevel` Â≠óÁ¨¶‰∏≤Ôºà`&quot;NONE&quot;` / `&quot;LOW&quot;` / `&quot;MEDIUM&quot;` / `&quot;HIGH&quot;`ÔºâÂà∞ `generationConfig.thinkingConfig`„ÄÇÂΩì AGM ÈÄöËøá Google v1internal API ‰ª£ÁêÜËØ∑Ê±ÇÊó∂ÔºåGoogle ‰ºöÂõ†‰∏∫ v1internal ‰ªÖÊé•ÂèóÊï∞Â≠óÂûã `thinkingBudget` ËÄåÊãíÁªùËØ∑Ê±ÇÔºåËøîÂõû `400 INVALID_ARGUMENT`„ÄÇ
            -   **‰øÆÂ§çÊñπÊ°à**: Âú® `wrap_request()` ÁöÑÁé∞Êúâ budget Â§ÑÁêÜÈÄªËæë‰πãÂâçÔºåÊñ∞Â¢û‰∏Ä‰∏™Êó©ÊúüËΩ¨Êç¢Ê≠•È™§ÔºöÊ£ÄÊµã `thinkingLevel` Â≠óÁ¨¶‰∏≤ÔºåÂ∞ÜÂÖ∂Êò†Â∞Ñ‰∏∫ÂØπÂ∫îÁöÑÊï∞Â≠ó `thinkingBudget`Ôºà`NONE`‚Üí0, `LOW`‚Üí4096, `MEDIUM`‚Üí8192, `HIGH`‚Üí24576ÔºâÔºåÁÑ∂ÂêéÂà†Èô§ `thinkingLevel` Â≠óÊÆµÂπ∂ÂÜôÂÖ• `thinkingBudget`ÔºåÁ°Æ‰øù‰∏ãÊ∏∏ÊâÄÊúâ budget Â§ÑÁêÜÈÄªËæëÔºàÈ¢ÑÁÆóÂ∞ÅÈ°∂„ÄÅ`maxOutputTokens` Ë∞ÉÊï¥„ÄÅËá™ÈÄÇÂ∫îÊ£ÄÊµãÔºâÈÉΩËÉΩÁúãÂà∞Ê≠£Á°ÆÁöÑÊï∞ÂÄºÈ¢ÑÁÆó„ÄÇ
            -   **ÊµãËØï**: Â∑≤È™åËØÅ OpenClaw ÂèëÈÄÅ `thinkingLevel: &quot;LOW&quot;` Âà∞ `gemini-3.1-pro-high`ÔºàGemini ÂéüÁîüÂçèËÆÆÔºâÔºåËØ∑Ê±ÇÁé∞ËøîÂõû `200 OK`Ôºå‰∏çÂÜçÊä• 400 ÈîôËØØ„ÄÇ
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Ë¥¶Âè∑Êï∞ÊçÆÊçüÂùè‰∏éÂêéÂè∞‰ªªÂä°Êó†ÈôêÂæ™ÁéØ‰øÆÂ§ç (PR #2094)**:
            -   **ÈóÆÈ¢òÊ†πÊ∫ê**: ÂΩìÁî®Êà∑Âú®ËÆæÁΩÆ‰∏≠ËæìÂÖ•ËøáÂ§ßÁöÑÂà∑Êñ∞Èó¥ÈöîÂÄºÔºàÂ¶Ç 999999999ÔºâÊó∂Ôºå`interval * 60 * 1000` Ë∂ÖËøá JS ÂºïÊìé 32 ‰ΩçÊúâÁ¨¶Âè∑Êï¥Êï∞‰∏äÈôê `2,147,483,647ms`ÔºåÊµèËßàÂô®‰ºöÂ∞Ü `setInterval` Âª∂ËøüÈùôÈªòÊà™Êñ≠‰∏∫ 1msÔºåÂØºËá¥ÂâçÁ´ØÊØèÁßíËß¶ÂèëÊï∞ÂçÉÊ¨° `refreshAllQuotas`/`syncAccountFromDb` ËØ∑Ê±ÇÔºåËøõËÄåÂºïÂèëÂ§öÁ∫øÁ®ãÂπ∂ÂèëÂÜôÂêå‰∏Ä `[uuid].json` Êñá‰ª∂ÔºåÈÄ†ÊàêÂ≠óËäÇÊµÅ‰∫§Èîô„ÄÅJSON Â∞æÈÉ®ÊÆãÁïôÔºåË¥¶Âè∑Êï∞ÊçÆÊ∞∏‰πÖÊçüÂùè„ÄÇ
            -   **ÂéüÂ≠êÊñá‰ª∂ÂÜôÂÖ• (`account.rs`)**: `save_account` Êîπ‰∏∫ÂÖàÂÜôÂÖ• UUID ÂêéÁºÄÁöÑ‰∏¥Êó∂Êñá‰ª∂ÔºåÂÜçÈÄöËøá `fs::rename`ÔºàPOSIXÔºâ/ `MoveFileExW`ÔºàWindowsÔºâÂéüÂ≠êÊõøÊç¢ÁõÆÊ†áÊñá‰ª∂Ôºå‰∏éÂ∑≤ÊúâÁöÑ `save_account_index` ‰øùÊåÅ‰∏ÄËá¥Ôºå‰ªéÊ†πÊú¨‰∏äÊ∂àÈô§Âπ∂ÂèëÂÜôÂØºËá¥ÁöÑ JSON ÊçüÂùè„ÄÇ
            -   **setInterval Ê∫¢Âá∫‰øùÊä§ (`BackgroundTaskRunner.tsx`)**: ÂØπ `refresh_interval` Âíå `sync_interval` ‰∏§‰∏™ÂÆöÊó∂Âô®ÁöÑÂª∂ËøüÂèÇÊï∞Âä†‰∏ä `Math.min(..., 2147483647)` ‰∏äÁïåÈôêÂà∂ÔºåÈò≤Ê≠¢Ë∂ÖËøá INT32_MAX ÂêéË¢´ÊµèËßàÂô®Êà™Êñ≠‰∏∫ 1ms Êó†ÈôêÂæ™ÁéØ„ÄÇ
            -   **ËæìÂÖ•È™åËØÅ (`Settings.tsx`)**: Â∞Ü `refresh_interval` Âíå `sync_interval` ËæìÂÖ•Ê°ÜÁöÑ `max` Â±ûÊÄß‰ªé `60` Êõ¥Êñ∞‰∏∫ `35791`Ôºà35791 min √ó 60000 &lt; INT32_MAXÔºâÔºåÂπ∂Âú® `onChange` ‰∏≠Ê∑ªÂä† `NaN` fallbackÔºàÈªòËÆ§‰∏∫ 1ÔºâÂèäËåÉÂõ¥Â§πÁ¥ß `[1, 35791]`Ôºå‰ªéÊ∫êÂ§¥ÈòªÊñ≠ÈùûÊ≥ïÂÄºËæìÂÖ•„ÄÇ
        -   **[Ê†∏ÂøÉ‰ºòÂåñ] OAuth Êç¢Á•®‰∏ìÂ±ûÔºöÂâîÈô§ JA3 ÊåáÁ∫π‰∏éÂä®ÊÄÅ User-Agent ‰º™Ë£Ö**:
            -   **Á∫ØÂáÄËØ∑Ê±Ç**: ‰ªÖÈíàÂØπ `exchange_code`ÔºàÈ¶ñÊ¨°ÊéàÊùÉÔºâÂíå `refresh_access_token`ÔºàÈùôÈªòÁª≠ÊúüÔºâÁöÑÊç¢Á•®ËØ∑Ê±ÇÔºåÁßªÈô§‰∫ÜÂ∫ïÂ±ÇÁΩëÁªúÂ∫ìÁöÑ Chrome JA3 ÊåáÁ∫π‰º™Ë£ÖÔºåÊÅ¢Â§çÊ†áÂáÜÁ∫ØÂáÄÁöÑ TLSÁâπÂæÅ„ÄÇ
            -   **Âä®ÊÄÅ UA**: Êç¢Á•®Êó∂Ëá™Âä®ÊèêÂèñÁºñËØëÊó∂ÁâàÊú¨Âè∑ (`CURRENT_VERSION`) ÊûÑÂª∫‰∏ìÂ±ûÁöÑ `User-Agent`ÔºàÂ¶Ç `vscode/1.X.X (Antigravity/4.1.23)`ÔºâÔºå‰ª•ÂåπÈÖçÁ∫ØÂáÄ TLS ÈìæË∑Ø„ÄÇ
        -   **[ÂäüËÉΩÂ¢ûÂº∫] API Âèç‰ª£È°µÈù¢‰∏éËÆæÁΩÆÈ°µÊ®°ÂûãÂàóË°®ÂÖ®Èù¢Êé•ÂÖ•Âä®ÊÄÅÊ®°ÂûãÊï∞ÊçÆ**:
            -   **ÈóÆÈ¢òÊ†πÊ∫ê**: &quot;API Âèç‰ª£ ‚Üí ÊîØÊåÅÊ®°Âûã‰∏éÈõÜÊàê&quot;ÂàóË°®‰∏é&quot;Ê®°ÂûãË∑ØÁî±‰∏≠ÂøÉ&quot;ÁöÑÁõÆÊ†áÊ®°ÂûãÈÄâÊã©‰∏ãÊãâÊ°ÜÔºå‰ª•Âèä&quot;ËÆæÁΩÆ ‚Üí Âõ∫ÂÆöÈÖçÈ¢ùÊ®°Âûã&quot;ÂàóË°®ÔºåÊ≠§ÂâçÂùá‰ªÖ‰ªéÈùôÊÄÅ `MODEL_CONFIG` ËØªÂèñÁ°¨ÁºñÁ†ÅÊ®°Âûã‰ø°ÊÅØÔºåÂØºËá¥Ë¥¶Âè∑ÂÆûÈôÖ‰∏ãÂèëÁöÑÂä®ÊÄÅÊñ∞Ê®°ÂûãÔºàÂ¶Ç `GPT-OSS 120B`„ÄÅ`Gemini 3.1 Pro (High)` Á≠âÔºâÊó†Ê≥ïÂá∫Áé∞Âú®Ëøô‰∫õÂàóË°®‰∏≠„ÄÇ
            -   **‰øÆÂ§çÊñπÊ°à**:
                -   ÈáçÊûÑ `useProxyModels` HookÔºö‰ª•Ë¥¶Âè∑ `quota.models` Âä®ÊÄÅÊï∞ÊçÆ‰∏∫Á¨¨‰∏Ä‰ºòÂÖàÊï∞ÊçÆÊ∫êÔºåËÅöÂêàÊâÄÊúâË¥¶Âè∑ÈáåÊâÄÊúâÊ®°ÂûãÁöÑ `display_name`Ôºà‰∏∫‰∏ªÂ±ïÁ§∫ÂêçÁß∞ÔºâÂíå `name`Ôºà‰∏∫Ê®°Âûã IDÔºâÔºõ`MODEL_CONFIG` ‰ªÖ‰Ωú‰∏∫ÂõæÊ†á/ÂàÜÁªÑÁöÑÊ†∑ÂºèË°•ÂÖÖÔºå‰ª•ÂèäÊó†Ë¥¶Âè∑Êï∞ÊçÆÊó∂ÁöÑÈùôÊÄÅÂÖúÂ∫ï„ÄÇ
                -   Êñ∞Â¢ûËá™Âä®ÊáíÂä†ËΩΩÈÄªËæëÔºö`ApiProxy` È°µÈù¢Êú¨Ë∫´‰∏çË∞ÉÁî® `fetchAccounts`ÔºåÁé∞Âú® Hook ÂÜÖÈÉ®Ê£ÄÊµãÂà∞ store ‰∏∫Á©∫Êó∂Ëá™Âä®Ëß¶ÂèëÔºå‰øùËØÅÂä®ÊÄÅÊ®°ÂûãÂú®‰ªªÊÑèÂØºËà™Ë∑ØÂæÑ‰∏ãÂùáÂèØÊ≠£Â∏∏Â±ïÁ§∫„ÄÇ
                -   ÈáçÊûÑ `PinnedQuotaModels` ÁªÑ‰ª∂ÔºöÈááÁî®ÂêåÁ≠âÁ≠ñÁï•Ôºå‰ªé `useAccountStore` ÊãâÂèñÂÖ®Ë¥¶Âè∑Âä®ÊÄÅÊ®°ÂûãÔºåÂπ∂‰øÆÂ§ç‰∫ÜÂ∑≤Âõ∫ÂÆöÁöÑ &quot;thinking&quot; Á±ªÂûãÊ®°ÂûãÊòæÁ§∫&quot;Êú™Áü•&quot;ÁöÑÈóÆÈ¢òÔºåÊîπ‰∏∫‰ºòÂÖàÂ±ïÁ§∫ÂÖ∂ÁúüÂÆû `display_name`„ÄÇ
            -   **ÂéªÈáç‰ºòÂåñ**: ÊâÄÊúâÂàóË°®ÂùáÂü∫‰∫éÊ®°ÂûãÂéüÂßã `name`ÔºàÂ∞èÂÜôÔºâÂéªÈáçÔºåÂπ∂È¢ùÂ§ñËøáÊª§Êéâ `-thinking` ÂêéÁºÄÁöÑ MODEL_CONFIG ÈùôÊÄÅÂà´ÂêçÊù°ÁõÆÔºàËøôÁ±ªÂèò‰ΩìÂ∑≤Áî±Ë¥¶Âè∑Êï∞ÊçÆ‰∏≠ÁöÑ `supports_thinking` Ê†áËÆ∞Ë¶ÜÁõñÔºâ„ÄÇ
    *   **v4.1.22 (2026-02-21)**:
        -   **[ÈáçË¶ÅÊèêÈÜí] 2api È£éÊéßÈ£éÈô©ÊèêÁ§∫**:
            -   Áî±‰∫éËøëÊúüÁöÑË∞∑Ê≠åÈ£éÊéßÂéüÂõ†Ôºå‰ΩøÁî® 2api ÂäüËÉΩ‰ºöÂØºËá¥Ë¥¶Âè∑Ë¢´È£éÊéßÁöÑÊ¶ÇÁéáÊòæËëóÂ¢ûÂä†„ÄÇ
            -   **Âº∫ÁÉàÂª∫ËÆÆ**: ‰∏∫‰∫ÜÁ°Æ‰øùÊÇ®ÁöÑË¥¶Âè∑ÂÆâÂÖ®‰∏éË∞ÉÁî®Á®≥ÂÆöÊÄßÔºåÂª∫ËÆÆÂáèÂ∞ëÊàñÂÅúÊ≠¢‰ΩøÁî® 2api ÂäüËÉΩ„ÄÇÁõÆÂâçÊõ¥ÂéüÁîü„ÄÅÊõ¥Á®≥ÂÆöÁöÑ **gRPC (`application/grpc`)** Êàñ **gRPC-Web (`application/grpc-web`)** ÂçèËÆÆ‰ª£ÁêÜÊîØÊåÅ‰ªçÂú®ÁßØÊûÅÊµãËØï‰∏≠ÔºåÂ¶ÇÊûúÊÇ®ÊúâÁõ∏ÂÖ≥ÁöÑÊµãËØïÁªèÈ™åÊàñÊÉ≥Ê≥ïÔºåÈùûÂ∏∏Ê¨¢ËøéËÅîÁ≥ªËÆ®ËÆ∫Ôºå‰πüÊ¨¢ËøéÊÇ®Âª∫Á´ãÊñ∞ÂàÜÊîØ‰∏ÄËµ∑Êé¢Á¥¢ÔºÅ
            -   &lt;details&gt;&lt;summary&gt;üì∏ ÁÇπÂáªÊü•Áúã gRPC ÂÆûÊó∂ËΩ¨Êç¢ OpenAI ËßÑËåÉÊµãËØïÊºîÁ§∫&lt;/summary&gt;&lt;img src=&quot;docs/images/usage/grpc-test.png&quot; alt=&quot;gRPC Test&quot; width=&quot;600&quot;&gt;&lt;/details&gt;
        -   **[Ê†∏ÂøÉ‰ºòÂåñ] Claude Sonnet 4.5 ËøÅÁßªËá≥ 4.6 (PR #2014)**:
            -   **Ê®°ÂûãÂçáÁ∫ß**: ÂºïÂÖ• `claude-sonnet-4-6` Âèä `claude-sonnet-4-6-thinking` ‰Ωú‰∏∫‰∏ªÊé®Ê®°Âûã„ÄÇ
            -   **Âπ≥ÊªëËøáÊ∏°**: Ëá™Âä®Â∞Ü legacy Ê®°Âûã `claude-sonnet-4-5` ÈáçÂÆöÂêëËá≥ `4.6`„ÄÇ
            -   **ÂÖ®Â±ÄÈÄÇÈÖç**: Êõ¥Êñ∞‰∫ÜÂÖ®ÈÉ® 12 ÁßçËØ≠Ë®ÄÁöÑÊú¨Âú∞ÂåñÊñá‰ª∂„ÄÅUI Ê†áÁ≠æÔºàSonnet 4.6, Sonnet 4.6 TK, Opus 4.6 TKÔºâ‰ª•ÂèäÈ¢ÑËÆæË∑ØÁî±„ÄÇ
        -   **[Ê†∏ÂøÉ‰ºòÂåñ] Gemini Pro Ê®°ÂûãÂêçÁß∞ËøÅÁßª (PR #2063)**: Â∞Ü `gemini-pro-high/low` ËøÅÁßªËá≥ `gemini-3.1-pro`ÔºåÁ°Æ‰øù‰∏é Google ÊúÄÊñ∞ API ÂëΩÂêçÂØπÈΩê„ÄÇ
        -   **[ÈáçÂ§ßÊû∂ÊûÑ] ÂõΩÈôÖÂåñ (i18n) ‰∏éÁªìÊûÑÂåñÊ®°ÂûãÈÖçÁΩÆÈõÜÊàê (PR #2040)**:
            -   **Êû∂ÊûÑÈáçÊûÑ**: ÂºïÂÖ•‰∫ÜÂÖ®Êñ∞ÁöÑ i18n ÁøªËØëÊ°ÜÊû∂ÔºåÂ∞ÜÁ°¨ÁºñÁ†ÅÁöÑÊ®°ÂûãÂ±ïÁ§∫ÈÄªËæëËß£ËÄ¶Ëá≥ÁªìÊûÑÂåñ `MODEL_CONFIG`„ÄÇ
            -   **ÈÄªËæëÈÄÇÈÖç**: Âú®Ë¥¶Âè∑Ë°®Ê†º„ÄÅËØ¶ÊÉÖÂºπÁ™óÂíåËÆæÁΩÆÈ°µÈù¢‰∏≠ÈõÜÊàê‰∫ÜÂü∫‰∫é i18n Ê†áÁ≠æÁöÑÂä®ÊÄÅÂéªÈáçÊú∫Âà∂Ôºå‰øÆÂ§ç‰∫Ü Gemini 3.1 Pro È¢ùÂ∫¶ÈáçÂ§çÊòæÁ§∫ÁöÑ UI ÈóÆÈ¢ò„ÄÇ
            -   **Â§öËØ≠Ë®ÄÊèêÂçá**: ‰ºòÂåñÂπ∂‰øÆÊ≠£‰∫ÜÊâÄÊúâ 12 ÁßçËØ≠Ë®ÄÁöÑÁâàÊú¨ÊèèËø∞ÔºåÂ∞Ü `Claude 4.5` ÊèèËø∞ÂÖ®Èù¢ÂçáÁ∫ß‰∏∫Ê≠£ÂºèÁâà `4.6`ÔºåÂπ∂Â∞Ü `G3` ÊèèËø∞Áªü‰∏Ä‰∏∫ `G3.1`„ÄÇ
            -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Claude Opus 4.6 ÊÄùËÄÉÊ®°Âºè 400 Êä•Èîô (Claude ÂçèËÆÆ)**:
            -   **ÂèÇÊï∞‰∏ìÈ°πÂØπÈΩê**: ‰øÆÂ§ç‰∫Ü `claude-opus-4-6-thinking` Âú® Claude ÂçèËÆÆ‰∏ãËøîÂõû `400 INVALID_ARGUMENT` ÁöÑÈóÆÈ¢ò„ÄÇÈÄöËøáÂº∫Âà∂ÂØπÈΩê `thinkingBudget` (24576) ‰∏é `maxOutputTokens` (57344)ÔºåÂπ∂ÂâîÈô§Âú®ËØ•Ê®°Âºè‰∏ã‰∏çÂÖºÂÆπÁöÑ `stopSequences`ÔºåÁ°Æ‰øùÂÖ∂ËØ∑Ê±ÇÂèÇÊï∞‰∏é 100% ÊàêÂäüÁöÑ OpenAI ÂçèËÆÆÂÆåÂÖ®‰∏ÄËá¥ÔºåÊèêÂçá‰∫ÜÂØπ Claude ÂéüÁîüÂçèËÆÆÂÆ¢Êà∑Á´ØÁöÑÂÖºÂÆπÊÄß„ÄÇ
    *   **v4.1.21 (2026-02-17)**:
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Cherry Studio / Claude ÂçèËÆÆÂÖºÂÆπÊÄß (Fix Issue #2007)**:
            -   **maxOutputTokens ÈôêÂà∂**: ‰øÆÂ§ç‰∫Ü Cherry Studio Á≠âÂÆ¢Êà∑Á´ØÂèëÈÄÅË∂ÖÂ§ß `maxOutputTokens` (128k) ÂØºËá¥ Google API ËøîÂõû `400 INVALID_ARGUMENT` ÁöÑÈóÆÈ¢ò„ÄÇÁé∞Âú®Ëá™Âä®Â∞Ü Claude ÂçèËÆÆÁöÑËæìÂá∫‰∏äÈôêÈôêÂà∂‰∏∫ **65536**ÔºåÁ°Æ‰øùËØ∑Ê±ÇÂßãÁªàÂú® Gemini ÂÖÅËÆ∏ÁöÑËåÉÂõ¥ÂÜÖ„ÄÇ
            -   **Adaptive ÊÄùËÄÉÊ®°ÂºèÂØπÈΩê**: ÈíàÂØπ Gemini Ê®°Âûã‰ºòÂåñ‰∫Ü Claude ÂçèËÆÆÁöÑ `thinking: { type: &quot;adaptive&quot; }` Ë°å‰∏∫„ÄÇÁé∞Âú®Ëá™Âä®Êò†Â∞Ñ‰∏∫ **24576** ÁöÑÂõ∫ÂÆöÊÄùËÄÉÈ¢ÑÁÆó (‰∏é OpenAI ÂçèËÆÆ‰∏ÄËá¥)ÔºåËß£ÂÜ≥‰∫Ü Gemini Vertex AI ÂØπ `thinkingBudget: -1` ÁöÑ‰∏çÂÖºÂÆπÈóÆÈ¢òÔºåÊòæËëóÊèêÂçá‰∫Ü Cherry Studio ÁöÑÊÄùËÄÉÊ®°ÂºèÁ®≥ÂÆöÊÄß„ÄÇ
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Áîü‰∫ßÁéØÂ¢ÉËá™ÂÆö‰πâÂçèËÆÆÊîØÊåÅ (PR #2005)**:
            -   **ÂçèËÆÆ‰øÆÂ§ç**: ÈªòËÆ§ÂêØÁî® `custom-protocol` ÁâπÊÄßÔºå‰øÆÂ§ç‰∫ÜÁîü‰∫ßÁéØÂ¢É‰∏ãËá™ÂÆö‰πâÂçèËÆÆ (Â¶Ç `tauri://`) Âä†ËΩΩÂ§±Ë¥•ÁöÑÈóÆÈ¢òÔºåÁ°Æ‰øùÊú¨Âú∞ËµÑÊ∫êÂíåÁâπÊÆäÂçèËÆÆËØ∑Ê±ÇÁöÑÁ®≥ÂÆöÊÄß„ÄÇ
        -   **[Ê†∏ÂøÉ‰ºòÂåñ] ÊâòÁõòÂõæÊ†á‰∏éÁ™óÂè£ÁîüÂëΩÂë®ÊúüÁÆ°ÁêÜ**:
            -   **Êô∫ËÉΩÊâòÁõò**: ÂºïÂÖ• `AppRuntimeFlags` Áä∂ÊÄÅÁÆ°ÁêÜÔºåÂÆûÁé∞‰∫ÜÁ™óÂè£ÂÖ≥Èó≠Ë°å‰∏∫‰∏éÊâòÁõòÁä∂ÊÄÅÁöÑËÅîÂä®„ÄÇ
            -   **Ë°å‰∏∫‰ºòÂåñ**: ÂΩìÊâòÁõòÂêØÁî®Êó∂ÔºåÂÖ≥Èó≠Á™óÂè£Â∞ÜËá™Âä®ÈöêËóèËÄåÈùûÈÄÄÂá∫Â∫î

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[oxc-project/oxc]]></title>
            <link>https://github.com/oxc-project/oxc</link>
            <guid>https://github.com/oxc-project/oxc</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:56 GMT</pubDate>
            <description><![CDATA[‚öì A collection of high-performance JavaScript tools.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oxc-project/oxc">oxc-project/oxc</a></h1>
            <p>‚öì A collection of high-performance JavaScript tools.</p>
            <p>Language: Rust</p>
            <p>Stars: 19,382</p>
            <p>Forks: 848</p>
            <p>Stars today: 85 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://oxc.rs&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://oxc.rs/oxc-light.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://oxc.rs/oxc-dark.svg&quot;&gt;
      &lt;img alt=&quot;Oxc logo&quot; src=&quot;https://oxc.rs/oxc-dark.svg&quot; height=&quot;60&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![MIT licensed][license-badge]][license-url]
[![Build Status][ci-badge]][ci-url]
[![Code Coverage][code-coverage-badge]][code-coverage-url]
[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/oxc-project/oxc)
[![Sponsors][sponsors-badge]][sponsors-url]

[![Discord chat][discord-badge]][discord-url]
[![Playground][playground-badge]][playground-url]
[![Website][website-badge]][website-url]

&lt;/div&gt;

## ‚öì Oxc

_/o ä …õks siÀê/_

The Oxidation Compiler is a collection of high-performance tools for JavaScript and TypeScript written in Rust.

Oxc is part of [VoidZero](https://voidzero.dev/)&#039;s vision for a unified, high-performance toolchain for JavaScript. It powers [Rolldown](https://rolldown.rs) ([Vite]&#039;s future bundler) and enables the next generation of ultra-fast development tools that work seamlessly together.

For more information, check out our website at [oxc.rs](https://oxc.rs).

&lt;sub&gt;\* Oxidation is the chemical process that creates rust&lt;/sub&gt;

## üèóÔ∏è Design Principles

- **Performance**: Through rigorous performance engineering.
- **Correctness**: Through conformance testing to standards and similar projects.
- **Developer Experience**: Clear APIs, comprehensive documentation, and sensible configuration.
- **Modular composability**: Use individual components independently or compose them into complete toolchains.

Read more about our [architecture](https://oxc.rs/docs/learn/architecture/parser.html) and [performance philosophy](https://oxc.rs/docs/learn/performance).

## üì¶ Tools &amp; Packages

| Tool        | npm                                                     | crates.io                                                   |
| ----------- | ------------------------------------------------------- | ----------------------------------------------------------- |
| Linter      | [oxlint](https://npmx.dev/package/oxlint)               | -                                                           |
| Formatter   | [oxfmt](https://npmx.dev/package/oxfmt)                 | -                                                           |
| Parser      | [oxc-parser](https://npmx.dev/package/oxc-parser)       | [oxc_parser](https://crates.io/crates/oxc_parser)           |
| Transformer | [oxc-transform](https://npmx.dev/package/oxc-transform) | [oxc_transformer](https://crates.io/crates/oxc_transformer) |
| Minifier    | [oxc-minify](https://npmx.dev/package/oxc-minify)       | [oxc_minifier](https://crates.io/crates/oxc_minifier)       |
| Resolver    | [oxc-resolver](https://npmx.dev/package/oxc-resolver)   | [oxc_resolver](https://crates.io/crates/oxc_resolver)       |

See [documentation](https://oxc.rs/) for detailed usage guides for each tool.

## ‚ö°Ô∏è Quick Start

### Linter

The production-ready linter catches mistakes for you with sensible defaults and optional configuration:

```bash
npx oxlint@latest
```

To give you an idea of its capabilities, here is an example from the [vscode] repository, which finishes linting 4800+ files in 0.7 seconds:

&lt;p float=&quot;left&quot; align=&quot;left&quot;&gt;
  &lt;img src=&quot;https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/linter-screenshot.png&quot; width=&quot;60%&quot;&gt;
&lt;/p&gt;

‚Üí [oxlint documentation](https://oxc.rs/docs/guide/usage/linter/cli.html)

### Formatter

Fast, opinionated code formatter compatible with [Prettier]:

```bash
npx oxfmt@latest
```

‚Üí [Formatter documentation](https://oxc.rs/docs/guide/usage/formatter)

### Parser (Node.js)

The fastest JavaScript/TypeScript parser written in Rust:

```bash
npm install oxc-parser
```

```js
import { parseSync } from &quot;oxc-parser&quot;;
const result = parseSync(&quot;const x = 1;&quot;);
```

‚Üí [Parser documentation](https://oxc.rs/docs/guide/usage/parser)

### Transformer (Node.js)

TypeScript, React, and modern JavaScript transformation:

```bash
npm install oxc-transform
```

```js
import { transform } from &quot;oxc-transform&quot;;
const result = transform(&quot;source.tsx&quot;, code, { typescript: true });
```

‚Üí [Transformer documentation](https://oxc.rs/docs/guide/usage/transformer)

### Minifier (Node.js)

High-performance JavaScript minifier:

```bash
npm install oxc-minify
```

```js
import { minify } from &quot;oxc-minify&quot;;
const result = minify(code, { mangle: true });
```

‚Üí [Minifier documentation](https://oxc.rs/docs/guide/usage/minifier)

### Rust

Individual crates are published for building your own JavaScript tools:

```toml
[dependencies]
oxc = &quot;0.x&quot;
```

‚Üí [Rust documentation](https://docs.rs/oxc)

## VoidZero Inc.

Oxc is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/blog).

If you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!

## üôã Who&#039;s using Oxc?

[Rolldown] and [Nuxt] use Oxc for parsing. [Rolldown] also uses Oxc for transformation and minification. [Nova], [swc-node], and [knip] use [oxc_resolver][docs-resolver-url] for module resolution. [Preact], [Shopify], [ByteDance], and [Shopee] use oxlint for linting.

[See more projects using Oxc ‚Üí](https://oxc.rs/docs/guide/projects.html)

## ‚úçÔ∏è Contribute

Check out some of the [good first issues](https://github.com/oxc-project/oxc/contribute) or ask us on [Discord][discord-url].

See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidance, or read the complete [contributing guide on our website ‚Üí](https://oxc.rs/docs/contribute/introduction.html)

If you are unable to contribute by code, you can still participate by:

- Add a [GitHub Star](https://github.com/oxc-project/oxc/stargazers) to the project
- Join us on [Discord][discord-url]
- [Follow me on X](https://x.com/boshen_c) and post about this project

## ü§ù Credits

This project was incubated with the assistance of these exceptional mentors and their projects:

- [Biome][biome] - [@ematipico](https://github.com/ematipico)
- [Ruff][ruff] - [@charliermarsh](https://github.com/charliermarsh), [@MichaReiser](https://github.com/MichaReiser)
- [quick-lint-js](https://github.com/quick-lint/quick-lint-js) - [@strager](https://github.com/strager)
- [elm-review](https://package.elm-lang.org/packages/jfmengels/elm-review/latest) - [@jfmengels](https://github.com/jfmengels)

Special thanks go to:

- [@domonji](https://github.com/domonji) for bootstrapping this project together and also completing the TypeScript parser
- [@tongtong-lu](https://github.com/tongtong-lu) and [@guan-wy](https://github.com/guan-wy) for designing the [project logo](https://github.com/oxc-project/oxc-assets)

## ‚ù§ Who&#039;s [Sponsoring Oxc](https://github.com/sponsors/Boshen)?

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/sponsors/Boshen&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/Boshen/sponsors/main/sponsors.svg&quot; alt=&quot;My sponsors&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## üìñ License

Oxc is free and open-source software licensed under the [MIT License](./LICENSE).

Oxc ports or copies code from other open source projects, their licenses are listed in [**Third-party library licenses**](./THIRD-PARTY-LICENSE).

[discord-badge]: https://img.shields.io/discord/1079625926024900739?logo=discord&amp;label=Discord
[discord-url]: https://discord.gg/9uXCAwqQZW
[license-badge]: https://img.shields.io/badge/license-MIT-blue.svg
[license-url]: https://github.com/oxc-project/oxc/blob/main/LICENSE
[ci-badge]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml/badge.svg?event=push&amp;branch=main
[ci-url]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml?query=event%3Apush+branch%3Amain
[code-coverage-badge]: https://codecov.io/gh/oxc-project/oxc/graph/badge.svg?token=FVHEH0BQLJ
[code-coverage-url]: https://codecov.io/gh/oxc-project/oxc
[sponsors-badge]: https://img.shields.io/github/sponsors/Boshen
[sponsors-url]: https://github.com/sponsors/Boshen
[playground-badge]: https://img.shields.io/badge/Playground-blue?color=9BE4E0
[playground-url]: https://playground.oxc.rs/
[website-badge]: https://img.shields.io/badge/Website-blue
[website-url]: https://oxc.rs
[docs-resolver-url]: https://docs.rs/oxc_resolver
[biome]: https://biomejs.dev/
[ruff]: https://beta.ruff.rs
[vscode]: https://github.com/microsoft/vscode
[rolldown]: https://rolldown.rs
[vite]: https://vitejs.dev/
[nuxt]: https://nuxt.com/
[nova]: https://trynova.dev/
[swc-node]: https://github.com/swc-project/swc-node
[knip]: https://github.com/webpro/knip
[preact]: https://preactjs.com/
[shopify]: https://shopify.com/
[bytedance]: https://www.bytedance.com/
[shopee]: https://shopee.com/
[prettier]: https://prettier.io/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gitbutlerapp/gitbutler]]></title>
            <link>https://github.com/gitbutlerapp/gitbutler</link>
            <guid>https://github.com/gitbutlerapp/gitbutler</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:55 GMT</pubDate>
            <description><![CDATA[The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitbutlerapp/gitbutler">gitbutlerapp/gitbutler</a></h1>
            <p>The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte</p>
            <p>Language: Rust</p>
            <p>Stars: 19,571</p>
            <p>Forks: 849</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  
  &lt;img align=&quot;center&quot; width=&quot;100px&quot; src=&quot;https://gitbutler-docs-images-public.s3.us-east-1.amazonaws.com/md-logo.png&quot; alt=&quot;GitButler logo&quot; /&gt;
  &lt;br /&gt;

  &lt;h1 align=&quot;center&quot;&gt;GitButler&lt;/h1&gt;
  
  &lt;p align=&quot;center&quot;&gt;
   &lt;b&gt;Git, &lt;i&gt;but&lt;/i&gt; better&lt;/b&gt;.
   &lt;br/&gt;
   GitButler is a modern Git-based version control interface with both a GUI and CLI built from the ground up for AI-powered workflows.
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://gitbutler.com&quot;&gt;Website&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://blog.gitbutler.com/&quot;&gt;Blog&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://docs.gitbutler.com/&quot;&gt;Docs&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;‚Ä¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://gitbutler.com/downloads&quot;&gt;Downloads&lt;/a&gt;
  &lt;/p&gt;

  &lt;br/&gt;

  &lt;img width=&quot;100%&quot; src=&quot;https://gitbutler-docs-images-public.s3.us-east-1.amazonaws.com/app-preview-light.png&quot; alt=&quot;GitButler desktop app preview&quot; /&gt;
  &lt;p align=&quot;center&quot;&gt;&lt;i&gt;Our beautiful GUI&lt;/i&gt;&lt;/p&gt;

  &lt;img width=&quot;100%&quot; src=&quot;https://gitbutler-docs-images-public.s3.us-east-1.amazonaws.com/cli-preview.png&quot; alt=&quot;GitButler CLI preview&quot; /&gt;
  &lt;p align=&quot;center&quot;&gt;&lt;i&gt;Our amazing &lt;code&gt;but&lt;/code&gt; CLI&lt;/i&gt;&lt;/p&gt;

  &lt;br/&gt;

[![TWEET][s1]][l1] [
![BLUESKY][s8]][l8] [![DISCORD][s2]][l2]

[![CI][s0]][l0] [![INSTA][s3]][l3] [![YOUTUBE][s5]][l5] [![DEEPWIKI][s7]][l7]

[s0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml/badge.svg
[l0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml
[s1]: https://img.shields.io/badge/Twitter-black?logo=x&amp;logoColor=white
[l1]: https://twitter.com/intent/follow?screen_name=gitbutler
[s2]: https://img.shields.io/discord/1060193121130000425?label=Discord&amp;color=5865F2
[l2]: https://discord.gg/MmFkmaJ42D
[s3]: https://img.shields.io/badge/Instagram-E4405F?logo=instagram&amp;logoColor=white
[l3]: https://www.instagram.com/gitbutler/
[s5]: https://img.shields.io/youtube/channel/subscribers/UCEwkZIHGqsTGYvX8wgD0LoQ
[l5]: https://www.youtube.com/@gitbutlerapp
[s7]: https://deepwiki.com/badge.svg
[l7]: https://deepwiki.com/gitbutlerapp/gitbutler
[s8]: https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&amp;logoColor=fff
[l8]: https://bsky.app/profile/gitbutler.com

&lt;/div&gt;

&lt;br/&gt;

GitButler is a powerful new Git-based version control system, designed from scratch to be simple, powerful and flexible. It is designed for ease of use and modern agentic workflows.

It features stacked branches, parallel branches, unlimited undo, easy commit mutations, forge integrations and more.

Works instantly in any existing Git repo as a friendlier and more powerful drop-in Git user interface replacement - for you and your agents.

## Main Features

Why use GitButler instead of vanilla Git? What a great question.

- **Stacked Branches** ([gui](https://docs.gitbutler.com/features/branch-management/stacked-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/branching-and-commiting#stacked-branches))
  - Effortlessly create branches stacked on other branches. Amend or edit any commit easily with automatic restacking.
- **Parallel Branches** ([gui](https://docs.gitbutler.com/features/branch-management/virtual-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/branching-and-commiting#parallel-branches))
  - Organize work on multiple branches simultaneously, rather than constantly switching branches.
- **Easy Commit Management** ([gui](https://docs.gitbutler.com/features/branch-management/commits), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/rubbing))
  - Uncommit, reword, amend, move, split and squash commits by dragging and dropping or simple CLI commands. Forget about `rebase -i`, you don&#039;t need it anymore.
- **Undo Timeline** ([gui](https://docs.gitbutler.com/features/timeline), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/operations-log))
  - Logs all operations and changes and allows you to easily undo or revert any operation.
- **First Class Conflicts** ([gui](https://docs.gitbutler.com/overview#conflicting-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/conflict-resolution))
  - Rebases always succeed. Commits can be marked as conflicted and resolved at any time, in any order.
- **Forge Integration** ([gui](https://docs.gitbutler.com/features/forge-integration/github-integration), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/forges))
  - Authenticate to GitHub or GitLab to easily open and update Pull Requests, list branches, get CI statuses and more. No other tools required.
- **AI Tooling** ([gui](https://docs.gitbutler.com/features/ai-integration/ai-overview), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/ai-stuff))
  - Use built-in AI handlers to help create commit messages, branch names, PR descriptions and more.
  - Easily install hooks or skills for all modern agent systems to level up their Git management.

## Tech

The GitButler desktop app is a [Tauri](https://tauri.app/)-based application. Its UI is written in [Svelte](https://svelte.dev/) using [TypeScript](https://www.typescriptlang.org) and its backend is written in [Rust](https://www.rust-lang.org/).

The `but` CLI is the same Rust backend engine with a Rust command line UI.

## Documentation

You can find our end user documentation at: &lt;https://docs.gitbutler.com&gt;

## Bugs and Feature Requests

If you have a bug or feature request, feel free to open an [issue](https://github.com/gitbutlerapp/gitbutler/issues/new),
or [join our Discord server](https://discord.gg/MmFkmaJ42D).

## License

The TLDR is that GitButler is under a [Fair Source](https://fair.io/) software license, meaning that you can use it, view the source, contribute, etc. You just can&#039;t build a competitor with it. It also becomes MIT after 2 years. So, MIT with an expiring non-compete clause.

## Contributing

So you want to help out? Please check out the [CONTRIBUTING.md](CONTRIBUTING.md)
document.

If you want to skip right to getting the code to actually compile, take a look
at the [DEVELOPMENT.md](DEVELOPMENT.md) file.

### Contributors

&lt;a href=&quot;https://github.com/gitbutlerapp/gitbutler/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=gitbutlerapp/gitbutler&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cocoindex-io/cocoindex]]></title>
            <link>https://github.com/cocoindex-io/cocoindex</link>
            <guid>https://github.com/cocoindex-io/cocoindex</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:54 GMT</pubDate>
            <description><![CDATA[Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cocoindex-io/cocoindex">cocoindex-io/cocoindex</a></h1>
            <p>Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!</p>
            <p>Language: Rust</p>
            <p>Stars: 6,224</p>
            <p>Forks: 455</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/github.svg&quot; alt=&quot;CocoIndex&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Data transformation for AI&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;

[![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex)
[![Documentation](https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;logoColor=00B9FF)](https://cocoindex.io/docs/getting_started/quickstart)
[![License](https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white)](https://opensource.org/licenses/Apache-2.0)
[![PyPI version](https://img.shields.io/pypi/v/cocoindex?color=5B5BD6)](https://pypi.org/project/cocoindex/)
&lt;!--[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex) --&gt;
[![PyPI Downloads](https://static.pepy.tech/badge/cocoindex/month)](https://pepy.tech/projects/cocoindex)
[![CI](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml)
[![release](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml)
[![Link Check](https://github.com/cocoindex-io/cocoindex/actions/workflows/links.yml/badge.svg)](https://github.com/cocoindex-io/cocoindex/actions/workflows/links.yml)
[![prek](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/j178/prek/master/docs/assets/badge-v0.json)](https://github.com/j178/prek)
[![Discord](https://img.shields.io/discord/1314801574169673738?logo=discord&amp;color=5B5BD6&amp;logoColor=white)](https://discord.com/invite/zpA9S2DR7s)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/13939&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13939&quot; alt=&quot;cocoindex-io%2Fcocoindex | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box.  Exceptional developer velocity. Production-ready at day 0.

‚≠ê Drop a star to help us grow!

&lt;div align=&quot;center&quot;&gt;

&lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
[Deutsch](https://readme-i18n.com/cocoindex-io/cocoindex?lang=de) |
[English](https://readme-i18n.com/cocoindex-io/cocoindex?lang=en) |
[Espa√±ol](https://readme-i18n.com/cocoindex-io/cocoindex?lang=es) |
[fran√ßais](https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr) |
[Êó•Êú¨Ë™û](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja) |
[ÌïúÍµ≠Ïñ¥](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko) |
[Portugu√™s](https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt) |
[–†—É—Å—Å–∫–∏–π](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru) |
[‰∏≠Êñá](https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh)

&lt;/div&gt;

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/transformation.svg&quot; alt=&quot;CocoIndex Transformation&quot;&gt;
&lt;/p&gt;

&lt;/br&gt;

CocoIndex makes it effortless to transform data with AI, and keep source data and target in sync. Whether you‚Äôre building a vector index, creating knowledge graphs for context engineering or performing any custom data transformations ‚Äî goes beyond SQL.

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;CocoIndex Features&quot; src=&quot;https://cocoindex.io/images/venn2.svg&quot; /&gt;
&lt;/p&gt;

&lt;/br&gt;

## Exceptional velocity

Just declare transformation in dataflow with ~100 lines of python

```python
# import
data[&#039;content&#039;] = flow_builder.add_source(...)

# transform
data[&#039;out&#039;] = data[&#039;content&#039;]
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
```

CocoIndex follows the idea of [Dataflow](https://en.wikipedia.org/wiki/Dataflow_programming) programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.

**Particularly**, developers don&#039;t explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.

## Plug-and-Play Building Blocks

Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components - as easy as assembling building blocks.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/components.svg&quot; alt=&quot;CocoIndex Features&quot;&gt;
&lt;/p&gt;

## Data Freshness

CocoIndex keep source data and target in sync effortlessly.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6&quot; alt=&quot;Incremental Processing&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

It has out-of-box support for incremental indexing:

- minimal recomputation on source or logic change.
- (re-)processing necessary portions; reuse cache when possible

## Quick Start

If you&#039;re new to CocoIndex, we recommend checking out

- üìñ [Documentation](https://cocoindex.io/docs)
- ‚ö°  [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart)
- üé¨ [Quick Start Video Tutorial](https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT)

### Setup

1. Install CocoIndex Python library

```sh
pip install -U cocoindex
```

2. [Install Postgres](https://cocoindex.io/docs/getting_started/installation#-install-postgres) if you don&#039;t have one. CocoIndex uses it for incremental processing.

3. (Optional) Install Claude Code skill for enhanced development experience. Run these commands in [Claude Code](https://claude.com/claude-code):

```
/plugin marketplace add cocoindex-io/cocoindex-claude
/plugin install cocoindex-skills@cocoindex
```

## Define data flow

Follow [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart) to define your first indexing flow. An example flow looks like:

```python
@cocoindex.flow_def(name=&quot;TextEmbedding&quot;)
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope[&quot;documents&quot;] = flow_builder.add_source(cocoindex.sources.LocalFile(path=&quot;markdown_files&quot;))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope[&quot;documents&quot;].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc[&quot;chunks&quot;] = doc[&quot;content&quot;].transform(
            cocoindex.functions.SplitRecursively(),
            language=&quot;markdown&quot;, chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc[&quot;chunks&quot;].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk[&quot;embedding&quot;] = chunk[&quot;text&quot;].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model=&quot;sentence-transformers/all-MiniLM-L6-v2&quot;))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc[&quot;filename&quot;], location=chunk[&quot;location&quot;],
                                   text=chunk[&quot;text&quot;], embedding=chunk[&quot;embedding&quot;])

    # Export collected data to a vector index.
    doc_embeddings.export(
        &quot;doc_embeddings&quot;,
        cocoindex.targets.Postgres(),
        primary_key_fields=[&quot;filename&quot;, &quot;location&quot;],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name=&quot;embedding&quot;,
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
```

It defines an index flow like this:

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;400&quot; alt=&quot;Data Flow&quot; src=&quot;https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463&quot; /&gt;
&lt;/p&gt;

## üöÄ Examples and demo

| Example | Description |
|---------|-------------|
| [Text Embedding](examples/text_embedding) | Index text documents with embeddings for semantic search |
| [Code Embedding](examples/code_embedding) | Index code embeddings for semantic search |
| [PDF Embedding](examples/pdf_embedding) | Parse PDF and index text embeddings for semantic search |
| [PDF Elements Embedding](examples/pdf_elements_embedding) | Extract text and images from PDFs; embed text with SentenceTransformers and images with CLIP; store in Qdrant for multimodal search |
| [Manuals LLM Extraction](examples/manuals_llm_extraction) | Extract structured information from a manual using LLM |
| [Amazon S3 Embedding](examples/amazon_s3_embedding) | Index text documents from Amazon S3 |
| [Azure Blob Storage Embedding](examples/azure_blob_embedding) | Index text documents from Azure Blob Storage |
| [Google Drive Text Embedding](examples/gdrive_text_embedding) | Index text documents from Google Drive |
| [Meeting Notes to Knowledge Graph](examples/meeting_notes_graph) | Extract structured meeting info from Google Drive and build a knowledge graph |
| [Docs to Knowledge Graph](examples/docs_to_knowledge_graph) | Extract relationships from Markdown documents and build a knowledge graph |
| [Embeddings to Qdrant](examples/text_embedding_qdrant) | Index documents in a Qdrant collection for semantic search |
| [Embeddings to LanceDB](examples/text_embedding_lancedb) | Index documents in a LanceDB collection for semantic search |
| [FastAPI Server with Docker](examples/fastapi_server_docker) | Run the semantic search server in a Dockerized FastAPI setup |
| [Product Recommendation](examples/product_recommendation) | Build real-time product recommendations with LLM and graph database|
| [Image Search with Vision API](examples/image_search) | Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend|
| [Face Recognition](examples/face_recognition) | Recognize faces in images and build embedding index |
| [Paper Metadata](examples/paper_metadata) | Index papers in PDF files, and build metadata tables for each paper |
| [Multi Format Indexing](examples/multi_format_indexing) | Build visual document index from PDFs and images with ColPali for semantic search |
| [Custom Source HackerNews](examples/custom_source_hn) | Index HackerNews threads and comments, using *CocoIndex Custom Source* |
| [Custom Output Files](examples/custom_output_files) | Convert markdown files to HTML files and save them to a local directory, using *CocoIndex Custom Targets* |
| [Patient intake form extraction](examples/patient_intake_extraction) | Use LLM to extract structured data from patient intake forms with different formats |
| [HackerNews Trending Topics](examples/hn_trending_topics) | Extract trending topics from HackerNews threads and comments, using *CocoIndex Custom Source* and LLM |
| [Patient Intake Form Extraction with BAML](examples/patient_intake_extraction_baml) | Extract structured data from patient intake forms using BAML |
| [Patient Intake Form Extraction with DSPy](examples/patient_intake_extraction_dspy) | Extract structured data from patient intake forms using DSPy |

More coming and stay tuned üëÄ!

## üìñ Documentation

For detailed documentation, visit [CocoIndex Documentation](https://cocoindex.io/docs), including a [Quickstart guide](https://cocoindex.io/docs/getting_started/quickstart).

## ü§ù Contributing

We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our [contributing guide](https://cocoindex.io/docs/about/contributing).

## üë• Community

Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it&#039;s code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.

Join our community here:

- üåü [Star us on GitHub](https://github.com/cocoindex-io/cocoindex)
- üëã [Join our Discord community](https://discord.com/invite/zpA9S2DR7s)
- ‚ñ∂Ô∏è [Subscribe to our YouTube channel](https://www.youtube.com/@cocoindex-io)
- üìú [Read our blog posts](https://cocoindex.io/blogs/)

## Support us

We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo [![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex) to stay tuned and help us grow.

## License

CocoIndex is Apache 2.0 licensed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[dani-garcia/vaultwarden]]></title>
            <link>https://github.com/dani-garcia/vaultwarden</link>
            <guid>https://github.com/dani-garcia/vaultwarden</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:53 GMT</pubDate>
            <description><![CDATA[Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dani-garcia/vaultwarden">dani-garcia/vaultwarden</a></h1>
            <p>Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs</p>
            <p>Language: Rust</p>
            <p>Stars: 55,796</p>
            <p>Forks: 2,574</p>
            <p>Stars today: 309 stars today</p>
            <h2>README</h2><pre>![Vaultwarden Logo](./resources/vaultwarden-logo-auto.svg)

An alternative server implementation of the Bitwarden Client API, written in Rust and compatible with [official Bitwarden clients](https://bitwarden.com/download/) [[disclaimer](#disclaimer)], perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.

---

[![GitHub Release](https://img.shields.io/github/release/dani-garcia/vaultwarden.svg?style=for-the-badge&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/releases/latest)
[![ghcr.io Pulls](https://img.shields.io/badge/dynamic/json?style=for-the-badge&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;url=https%3A%2F%2Fipitio.github.io%2Fbackage%2Fdani-garcia%2Fvaultwarden%2Fvaultwarden.json&amp;query=%24.downloads&amp;label=ghcr.io%20pulls&amp;cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden)
[![Docker Pulls](https://img.shields.io/docker/pulls/vaultwarden/server.svg?style=for-the-badge&amp;logo=docker&amp;logoColor=fff&amp;color=005AA4&amp;label=docker.io%20pulls)](https://hub.docker.com/r/vaultwarden/server)
[![Quay.io](https://img.shields.io/badge/quay.io-download-005AA4?style=for-the-badge&amp;logo=redhat&amp;cacheSeconds=14400)](https://quay.io/repository/vaultwarden/server) &lt;br&gt;
[![Contributors](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)
[![Forks](https://img.shields.io/github/forks/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/network/members)
[![Stars](https://img.shields.io/github/stars/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/stargazers)
[![Issues Open](https://img.shields.io/github/issues/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues)
[![Issues Closed](https://img.shields.io/github/issues-closed/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues?q=is%3Aissue+is%3Aclosed)
[![AGPL-3.0 Licensed](https://img.shields.io/github/license/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=vaultwarden&amp;color=944000&amp;cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/blob/main/LICENSE.txt) &lt;br&gt;
[![Dependency Status](https://img.shields.io/badge/dynamic/xml?url=https%3A%2F%2Fdeps.rs%2Frepo%2Fgithub%2Fdani-garcia%2Fvaultwarden%2Fstatus.svg&amp;query=%2F*%5Blocal-name()%3D&#039;svg&#039;%5D%2F*%5Blocal-name()%3D&#039;g&#039;%5D%5B2%5D%2F*%5Blocal-name()%3D&#039;text&#039;%5D%5B4%5D&amp;style=flat-square&amp;logo=rust&amp;label=dependencies&amp;color=005AA4)](https://deps.rs/repo/github/dani-garcia/vaultwarden)
[![GHA Release](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/release.yml?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;label=Release%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/release.yml)
[![GHA Build](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/build.yml?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;label=Build%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/build.yml) &lt;br&gt;
[![Matrix Chat](https://img.shields.io/matrix/vaultwarden:matrix.org.svg?style=flat-square&amp;logo=matrix&amp;logoColor=fff&amp;color=953B00&amp;cacheSeconds=14400)](https://matrix.to/#/#vaultwarden:matrix.org)
[![GitHub Discussions](https://img.shields.io/github/discussions/dani-garcia/vaultwarden?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=953B00&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/discussions)
[![Discourse Discussions](https://img.shields.io/discourse/topics?server=https%3A%2F%2Fvaultwarden.discourse.group%2F&amp;style=flat-square&amp;logo=discourse&amp;color=953B00)](https://vaultwarden.discourse.group/)

&gt; [!IMPORTANT]
&gt; **When using this server, please report any bugs or suggestions directly to us (see [Get in touch](#get-in-touch)), regardless of whatever clients you are using (mobile, desktop, browser...). DO NOT use the official Bitwarden support channels.**

&lt;br&gt;

## Features

A nearly complete implementation of the Bitwarden Client API is provided, including:

 * [Personal Vault](https://bitwarden.com/help/managing-items/)
 * [Send](https://bitwarden.com/help/about-send/)
 * [Attachments](https://bitwarden.com/help/attachments/)
 * [Website icons](https://bitwarden.com/help/website-icons/)
 * [Personal API Key](https://bitwarden.com/help/personal-api-key/)
 * [Organizations](https://bitwarden.com/help/getting-started-organizations/)
   - [Collections](https://bitwarden.com/help/about-collections/),
     [Password Sharing](https://bitwarden.com/help/sharing/),
     [Member Roles](https://bitwarden.com/help/user-types-access-control/),
     [Groups](https://bitwarden.com/help/about-groups/),
     [Event Logs](https://bitwarden.com/help/event-logs/),
     [Admin Password Reset](https://bitwarden.com/help/admin-reset/),
     [Directory Connector](https://bitwarden.com/help/directory-sync/),
     [Policies](https://bitwarden.com/help/policies/)
 * [Multi/Two Factor Authentication](https://bitwarden.com/help/bitwarden-field-guide-two-step-login/)
   - [Authenticator](https://bitwarden.com/help/setup-two-step-login-authenticator/),
     [Email](https://bitwarden.com/help/setup-two-step-login-email/),
     [FIDO2 WebAuthn](https://bitwarden.com/help/setup-two-step-login-fido/),
     [YubiKey](https://bitwarden.com/help/setup-two-step-login-yubikey/),
     [Duo](https://bitwarden.com/help/setup-two-step-login-duo/)
 * [Emergency Access](https://bitwarden.com/help/emergency-access/)
 * [Vaultwarden Admin Backend](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-admin-page)
 * [Modified Web Vault client](https://github.com/dani-garcia/bw_web_builds) (Bundled within our containers)

&lt;br&gt;

## Usage

&gt; [!IMPORTANT]
&gt; The web-vault requires the use a secure context for the [Web Crypto API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API).
&gt; That means it will only work via `http://localhost:8000` (using the port from the example below) or if you [enable HTTPS](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-HTTPS).

The recommended way to install and use Vaultwarden is via our container images which are published to [ghcr.io](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden), [docker.io](https://hub.docker.com/r/vaultwarden/server) and [quay.io](https://quay.io/repository/vaultwarden/server).
See [which container image to use](https://github.com/dani-garcia/vaultwarden/wiki/Which-container-image-to-use) for an explanation of the provided tags.

There are also [community driven packages](https://github.com/dani-garcia/vaultwarden/wiki/Third-party-packages) which can be used, but those might be lagging behind the latest version or might deviate in the way Vaultwarden is configured, as described in our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).

Alternatively, you can also [build Vaultwarden](https://github.com/dani-garcia/vaultwarden/wiki/Building-binary) yourself.

While Vaultwarden is based upon the [Rocket web framework](https://rocket.rs) which has built-in support for TLS our recommendation would be that you setup a reverse proxy (see [proxy examples](https://github.com/dani-garcia/vaultwarden/wiki/Proxy-examples)).

&gt; [!TIP]
&gt;**For more detailed examples on how to install, use and configure Vaultwarden you can check our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).**

### Docker/Podman CLI

Pull the container image and mount a volume from the host for persistent storage.&lt;br&gt;
You can replace `docker` with `podman` if you prefer to use podman.

```shell
docker pull vaultwarden/server:latest
docker run --detach --name vaultwarden \
  --env DOMAIN=&quot;https://vw.domain.tld&quot; \
  --volume /vw-data/:/data/ \
  --restart unless-stopped \
  --publish 127.0.0.1:8000:80 \
  vaultwarden/server:latest
```

This will preserve any persistent data under `/vw-data/`, you can adapt the path to whatever suits you.

### Docker Compose

To use Docker compose you need to create a `compose.yaml` which will hold the configuration to run the Vaultwarden container.

```yaml
services:
  vaultwarden:
    image: vaultwarden/server:latest
    container_name: vaultwarden
    restart: unless-stopped
    environment:
      DOMAIN: &quot;https://vw.domain.tld&quot;
    volumes:
      - ./vw-data/:/data/
    ports:
      - 127.0.0.1:8000:80
```

&lt;br&gt;

## Get in touch

Have a question, suggestion or need help? Join our community on [Matrix](https://matrix.to/#/#vaultwarden:matrix.org), [GitHub Discussions](https://github.com/dani-garcia/vaultwarden/discussions) or [Discourse Forums](https://vaultwarden.discourse.group/).

Encountered a bug or crash? Please search our issue tracker and discussions to see if it&#039;s already been reported. If not, please [start a new discussion](https://github.com/dani-garcia/vaultwarden/discussions) or [create a new issue](https://github.com/dani-garcia/vaultwarden/issues/). Ensure you&#039;re using the latest version of Vaultwarden and there aren&#039;t any similar issues open or closed!

&lt;br&gt;

## Contributors

Thanks for your contribution to the project!

[![Contributors Count](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden?style=for-the-badge&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)&lt;br&gt;
[![Contributors Avatars](https://contributors-img.web.app/image?repo=dani-garcia/vaultwarden)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)

&lt;br&gt;

## Disclaimer

**This project is not associated with [Bitwarden](https://bitwarden.com/) or Bitwarden, Inc.**

However, one of the active maintainers for Vaultwarden is employed by Bitwarden and is allowed to contribute to the project on their own time. These contributions are independent of Bitwarden and are reviewed by other maintainers.

The maintainers work together to set the direction for the project, focusing on serving the self-hosting community, including individuals, families, and small organizations, while ensuring the project&#039;s sustainability.

**Please note:** We cannot be held liable for any data loss that may occur while using Vaultwarden. This includes passwords, attachments, and other information handled by the application. We highly recommend performing regular backups of your files and database. However, should you experience data loss, we encourage you to contact us immediately.

&lt;br&gt;

## Bitwarden_RS

This project was known as Bitwarden_RS and has been renamed to separate itself from the official Bitwarden server in the hopes of avoiding confusion and trademark/branding issues.&lt;br&gt;
Please see [#1642 - v1.21.0 release and project rename to Vaultwarden](https://github.com/dani-garcia/vaultwarden/discussions/1642) for more explanation.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vectordotdev/vector]]></title>
            <link>https://github.com/vectordotdev/vector</link>
            <guid>https://github.com/vectordotdev/vector</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:52 GMT</pubDate>
            <description><![CDATA[A high-performance observability data pipeline.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vectordotdev/vector">vectordotdev/vector</a></h1>
            <p>A high-performance observability data pipeline.</p>
            <p>Language: Rust</p>
            <p>Stars: 21,387</p>
            <p>Forks: 2,015</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>[![Nightly](https://github.com/vectordotdev/vector/actions/workflows/nightly.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/nightly.yml)
[![Integration/E2E Test Suite](https://github.com/vectordotdev/vector/actions/workflows/integration.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/integration.yml/badge.svg?event=merge_group)
[![Component Features](https://github.com/vectordotdev/vector/actions/workflows/component_features.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/component_features.yml)

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;website/static/img/diagram.svg&quot; alt=&quot;Vector&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://vector.dev/docs/setup/quickstart/&quot;&gt;Quickstart&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/docs/&quot;&gt;Docs&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/guides/&quot;&gt;Guides&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/components/&quot;&gt;Integrations&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://chat.vector.dev&quot;&gt;Chat&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/releases/latest/download/&quot;&gt;Download&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://rust-doc.vector.dev/&quot;&gt;Rust Crate Docs&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

## What is Vector?

Vector is a high-performance, end-to-end (agent &amp; aggregator) observability data
pipeline that puts you in control of your observability data.
[Collect][docs.sources], [transform][docs.transforms], and [route][docs.sinks]
all your logs and metrics to any vendors you want today and any other
vendors you may want tomorrow. Vector enables dramatic cost reduction, novel
data enrichment, and data security where you need it, not where it is most
convenient for your vendors. Additionally, it is open source and up to 10x
faster than every alternative in the space.

To get started, follow our [**quickstart guide**][docs.quickstart] or [**install
Vector**][docs.installation].

Vector is maintained by Datadog&#039;s [Community Open Source Engineering team](https://opensource.datadoghq.com/about/#the-community-open-source-engineering-team).

### Principles

* **Reliable** - Built in [Rust][urls.rust], Vector&#039;s primary design goal is reliability.
* **End-to-end** - Deploys as an [agent][docs.roles#agent] or [aggregator][docs.roles#aggregator]. Vector is a complete platform.
* **Unified** - [Logs][docs.data-model.log], [metrics][docs.data-model.metric] (beta), and traces (coming soon). One tool for all of your data.

### Use cases

* Reduce total observability costs.
* Transition vendors without disrupting workflows.
* Enhance data quality and improve insights.
* Consolidate agents and eliminate agent fatigue.
* Improve overall observability performance and reliability.

### Community

* Vector is relied on by startups and enterprises like **Atlassian**, **T-Mobile**,
  **Comcast**, **Zendesk**, **Discord**, **Fastly**, **CVS**, **Trivago**,
  **Tuple**, **Douban**, **Visa**, **Mambu**, **Blockfi**, **Claranet**,
  **Instacart**, **Forcepoint**, and [many more][urls.production_users].
* Vector is **downloaded over 100,000 times per day**.
* Vector&#039;s largest user **processes over 500TB daily**.
* Vector has **over 500 contributors** and growing.

## Documentation

All user documentation is available at **[vector.dev/docs](https://vector.dev/docs)**.

Other Resources:

* [**Vector Calendar**][urls.vector_calendar]
* **Policies**:
  * [**Code of Conduct**][urls.vector_code_of_conduct]
  * [**Contributing**][urls.vector_contributing_policy]
  * [**Privacy**][urls.vector_privacy_policy]
  * [**Releases**][urls.vector_releases_policy]
  * [**Versioning**][urls.vector_versioning_policy]
  * [**Security**][urls.vector_security_policy]

## Comparisons

### Performance

The following performance tests demonstrate baseline performance between
common protocols with the exception of the Regex Parsing test.

| Test                                                                                                                   | Vector          | Filebeat | FluentBit       | FluentD   | Logstash  | SplunkUF        | SplunkHF |
| ---------------------------------------------------------------------------------------------------------------------- | --------------- | -------- | --------------- | --------- | --------- | --------------- | -------- |
| [TCP to Blackhole](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance) | _**86mib/s**_   | n/a      | 64.4mib/s       | 27.7mib/s | 40.6mib/s | n/a             | n/a      |
| [File to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance)           | _**76.7mib/s**_ | 7.8mib/s | 35mib/s         | 26.1mib/s | 3.1mib/s  | 40.1mib/s       | 39mib/s  |
| [Regex Parsing](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance)       | 13.2mib/s       | n/a      | _**20.5mib/s**_ | 2.6mib/s  | 4.6mib/s  | n/a             | 7.8mib/s |
| [TCP to HTTP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance)           | _**26.7mib/s**_ | n/a      | 19.6mib/s       | &lt;1mib/s   | 2.7mib/s  | n/a             | n/a      |
| [TCP to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance)             | 69.9mib/s       | 5mib/s   | 67.1mib/s       | 3.9mib/s  | 10mib/s   | _**70.4mib/s**_ | 7.6mib/s |

To learn more about our performance tests, please see the [Vector test harness][urls.vector_test_harness].

### Correctness

The following correctness tests are not exhaustive, but they demonstrate
fundamental differences in quality and attention to detail:

| Test                                                                                                                                 | Vector | Filebeat | FluentBit | FluentD | Logstash | Splunk UF | Splunk HF |
| ------------------------------------------------------------------------------------------------------------------------------------ | ------ | -------- | --------- | ------- | -------- | --------- | --------- |
| [Disk Buffer Persistence](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness) | **‚úì**  | ‚úì        |           |         | ‚ö†        | ‚úì         | ‚úì         |
| [File Rotate (create)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness)         | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |
| [File Rotate (copytruncate)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness) | **‚úì**  |          |           |         |          | ‚úì         | ‚úì         |
| [File Truncation](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness)                   | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |
| [Process (SIGHUP)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness)                         | **‚úì**  |          |           |         | ‚ö†        | ‚úì         | ‚úì         |
| [JSON (wrapped)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness)                     | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |

To learn more about our correctness tests, please see the [Vector test harness][urls.vector_test_harness].

### Features

Vector is an end-to-end, unified, open data platform.

|                     | **Vector** | Beats | Fluentbit | Fluentd | Logstash | Splunk UF | Splunk HF | Telegraf |
| ------------------- | ---------- | ----- | --------- | ------- | -------- | --------- | --------- | -------- |
| **End-to-end**      | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Agent               | **‚úì**      | ‚úì     | ‚úì         |         |          | ‚úì         |           | ‚úì        |
| Aggregator          | **‚úì**      |       |           | ‚úì       | ‚úì        |           | ‚úì         | ‚úì        |
| **Unified**         | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Logs                | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         | ‚úì        |
| Metrics             | **‚úì**      | ‚ö†     | ‚ö†         | ‚ö†       | ‚ö†        | ‚ö†         | ‚ö†         | ‚úì        |
| Traces              | üöß         |       |           |         |          |           |           |          |
| **Open**            | **‚úì**      |       | ‚úì         | ‚úì       |          |           |           | ‚úì        |
| Open-source         | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        |           |           | ‚úì        |
| Vendor-neutral      | **‚úì**      |       | ‚úì         | ‚úì       |          |           |           | ‚úì        |
| **Reliability**     | **‚úì**      |       |           |         |          |           |           |          |
| Memory-safe         | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Delivery guarantees | **‚úì**      |       |           |         |          | ‚úì         | ‚úì         |          |
| Multi-core          | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         | ‚úì        |


‚ö† = Not interoperable, metrics are represented as structured logs

---

&lt;p align=&quot;center&quot;&gt;
  Developed with ‚ù§Ô∏è by &lt;strong&gt;&lt;a href=&quot;https://datadoghq.com&quot;&gt;Datadog&lt;/a&gt;&lt;/strong&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/security/policy&quot;&gt;Security Policy&lt;/a&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/blob/master/PRIVACY.md&quot;&gt;Privacy Policy&lt;/a&gt;
&lt;/p&gt;

[docs.about.concepts]: https://vector.dev/docs/introduction/concepts/
[docs.about.introduction]: https://vector.dev/docs/introduction/
[docs.administration.monitoring]: https://vector.dev/docs/administration/monitoring/
[docs.administration.management]: https://vector.dev/docs/administration/management/
[docs.administration.upgrading]: https://vector.dev/docs/administration/upgrading/
[docs.administration.validating]: https://vector.dev/docs/administration/validating/
[docs.architecture.concurrency-model]: https://vector.dev/docs/architecture/concurrency-model/
[docs.architecture.data-model]: https://vector.dev/docs/architecture/data-model/
[docs.architecture.pipeline-model]: https://vector.dev/docs/architecture/pipeline-model/
[docs.architecture.runtime-model]: https://vector.dev/docs/architecture/runtime-model/
[docs.configuration.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.configuration.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.configuration.tests]: https://vector.dev/docs/reference/configuration/tests/
[docs.configuration.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.configuration.enrichment_tables]: https://vector.dev/docs/reference/configuration/global-options/#enrichment_tables
[docs.data-model.log]: https://vector.dev/docs/architecture/data-model/log/
[docs.data-model.metric]: https://vector.dev/docs/architecture/data-model/metric/
[docs.deployment.roles]: https://vector.dev/docs/setup/deployment/roles/
[docs.deployment.topologies]: https://vector.dev/docs/setup/deployment/topologies/
[docs.deployment]: https://vector.dev/docs/setup/deployment/
[docs.installation.manual]: https://vector.dev/docs/setup/installation/manual/
[docs.installation.operating_systems]: https://vector.dev/docs/setup/installation/operating-systems/
[docs.installation.package_managers]: https://vector.dev/docs/setup/installation/package-managers/
[docs.installation.platforms]: https://vector.dev/docs/setup/installation/platforms/
[docs.installation]: https://vector.dev/docs/setup/installation/
[docs.architecture.adaptive-request-concurrency]: https://vector.dev/docs/architecture/arc/
[docs.platforms.kubernetes]: https://vector.dev/docs/setup/installation/platforms/kubernetes/
[docs.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.reference.api]: https://vector.dev/docs/reference/api/
[docs.reference.cli]: https://vector.dev/docs/reference/cli/
[docs.reference.vrl]: https://vector.dev/docs/reference/vrl/
[docs.roles#agent]: https://vector.dev/docs/setup/deployment/roles/#agent
[docs.roles#aggregator]: https://vector.dev/docs/setup/deployment/roles/#aggregator
[docs.setup.installation]: https://vector.dev/docs/setup/installation/
[docs.setup.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.sinks.aws_cloudwatch_logs]: https://vector.dev/docs/reference/configuration/sinks/aws_cloudwatch_logs/
[docs.sinks.aws_s3]: https://vector.dev/docs/reference/configuration/sinks/aws_s3/
[docs.sinks.clickhouse]: https://vector.dev/docs/reference/configuration/sinks/clickhouse/
[docs.sinks.elasticsearch]: https://vector.dev/docs/reference/configuration/sinks/elasticsearch/
[docs.sinks.gcp_cloud_storage]: https://vector.dev/docs/reference/configuration/sinks/gcp_cloud_storage/
[docs.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.sources.docker_logs]: https://vector.dev/docs/reference/configuration/sources/docker_logs/
[docs.sources.file]: https://vector.dev/docs/reference/configuration/sources/file/
[docs.sources.http]: https://vector.dev/docs/reference/configuration/sources/http/
[docs.sources.journald]: https://vector.dev/docs/reference/configuration/sources/journald/
[docs.sources.kafka]: https://vector.dev/docs/reference/configuration/sources/kafka/
[docs.sources.socket]: https://vector.dev/docs/reference/configuration/sources/socket/
[docs.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.transforms.dedupe]: https://vector.dev/docs/reference/configuration/transforms/dedupe/
[docs.transforms.filter]: https://vector.dev/docs/reference/configuration/transforms/filter/
[docs.transforms.log_to_metric]: https://vector.dev/docs/reference/configuration/transforms/log_to_metric/
[docs.transforms.lua]: https://vector.dev/docs/reference/configuration/transforms/lua/
[docs.transforms.remap]: https://vector.dev/docs/reference/configuration/transforms/remap/
[docs.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.introduction.architecture]: https://vector.dev/docs/architecture/
[docs.introduction.guarantees]: https://vector.dev/docs/introduction/guarantees/
[docs.introduction.architecture]: https://vector.dev/docs/architecture/
[urls.production_users]: https://github.com/vectordotdev/vector/issues/790
[urls.rust]: https://www.rust-lang.org/
[urls.vector_calendar]: https://calendar.vector.dev
[urls.vector_chat]: https://chat.vector.dev
[urls.vector_code_of_conduct]: https://github.com/vectordotdev/vector/blob/master/CODE_OF_CONDUCT.md
[urls.vector_contributing_policy]: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md
[urls.vector_community]: https://vector.dev/community/
[urls.vector_privacy_policy]: https://github.com/vectordotdev/vector/blob/master/PRIVACY.md
[urls.vector_release_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASING.md
[urls.vector_releases]: https://vector.dev/releases/
[urls.vector_releases_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASES.md
[urls.vector_security_policy]: https://github.com/vectordotdev/vector/security/policy
[urls.vector_test_harness]: https://github.com/vectordotdev/vector-test-harness/
[urls.vector_twitter]: https://twitter.com/vectordotdev
[urls.vector_versioning_policy]: https://github.com/vectordotdev/vector/blob/master/VERSIONING.md
[urls.vote_feature]: https://github.com/vectordotdev/vector/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22type%3A+feature%22
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[claration/Impactor]]></title>
            <link>https://github.com/claration/Impactor</link>
            <guid>https://github.com/claration/Impactor</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:51 GMT</pubDate>
            <description><![CDATA[WIP feature rich iOS/tvOS sideloading application written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/claration/Impactor">claration/Impactor</a></h1>
            <p>WIP feature rich iOS/tvOS sideloading application written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,345</p>
            <p>Forks: 64</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/user-attachments/assets/18f2eff4-546f-4365-98eb-afb19b13dc13&quot; width=&quot;25&quot; height=&quot;25&quot; /&gt; Impactor

[![GitHub Release](https://img.shields.io/github/v/release/claration/Impactor?include_prereleases)](https://github.com/claration/Impactor/releases)
[![GitHub Downloads (all assets, all releases)](https://img.shields.io/github/downloads/claration/Impactor/total)](https://github.com/claration/Impactor/releases)
[![GitHub License](https://img.shields.io/github/license/claration/Impactor?color=%23C96FAD)](https://github.com/claration/Impactor/blob/main/LICENSE)
[![Sponsor Me](https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=%23fe8e86)](https://github.com/sponsors/claration)

Open-source, cross-platform, and feature rich iOS sideloading application. Supporting macOS, Linux[^1], and Windows[^2].

[^1]: On Linux, usbmuxd must be installed on your system. Don&#039;t worry though, it comes with most popular distributions by default already! However, due to some distributions [udev](https://man7.org/linux/man-pages/man7/udev.7.html) rules `usbmuxd` may stop running after no devices are connected causing Impactor to not detect the device after plugging it in. You can mitigate this by plugging your phone first then restarting the app. \
\
Auto-refresh will not work the same as it would on other platforms like macOS/Windows, due to `usbmuxd` lacking WiFi connectivity so it will attempt to do it automatically only when a device is plugged in, we are looking for a proper solution though.\
\
Some distributions (like Bazzite) may need you to run `sudo update-crypto-policies` so `usbmuxd` ends up detecting the device again.

[^2]: On Windows, [iTunes](https://support.apple.com/en-us/106372) must be downloaded so Impactor is able to use the drivers for interacting with Apple devices.

![Demo of app](demo.png)

### Features

- User friendly and clean UI.
- Supports installing [SideStore](https://github.com/SideStore/SideStore) and [LiveContainer](https://github.com/LiveContainer/LiveContainer) properly.
- Supports Linux.
- Sign and sideload applications on iOS 9.0+ &amp; Mac with your Apple ID.
  - Installing with [AppSync](https://github.com/akemin-dayo/AppSync) is supported.
  - Installing with ipatool gotten ipa&#039;s is supported.
    - Automatically disables updates from the App Store.
- Simple customization options for the app.
- Tweak support for advanced users, using [ElleKit](https://github.com/tealbathingsuit/ellekit) for injection.
  - Supports injecting `.deb` and `.dylib` files.
  - Supports adding `.framework`, `.bundle`, and `.appex` directories.
  - Supports replacing Cydia Substrate with ElleKit for 26.0 compatibility.
- Generates P12 for SideStore/AltStore to use, similar to Altserver.
- Automatically populate pairing files for apps like SideStore, Antrag, and Protokolle.
- Comes with simple device utilities for retrusting/placing pairing file.
- Export P12 for use with LiveContainer.
- Almost *proper* entitlement handling and can register app plugins.
  - Able to request entitlements like `increased-memory-limit`, for emulators like MelonX or UTM.

## Download

Visit [releases](https://github.com/khcrysalis/PlumeImpactor/releases) and get the latest version for your computer.

###### *This is also available on flatpak &amp; homebrew.*

**Linux:**

&lt;a href=&quot;https://flathub.org/en/apps/dev.khcrysalis.PlumeImpactor&quot;&gt;
  &lt;img src=&quot;https://dl.flathub.org/assets/badges/flathub-badge-en.svg&quot; width=&quot;200px&quot;&gt;
&lt;/a&gt;

**macOS:**

```sh
brew install --cask impactor
```

## How it works

How it works is that we try to replicate what [Xcode](https://developer.apple.com/xcode/) would do but in our own application, by using your Apple Account (which serves the purpose of being a &quot;Developer&quot;) so we can request certificates, provisioning profiles, and register your device from Apple themselves. 

Apple here is the provider of these and how we&#039;ll even be able to get apps on your phone. Unfortunately, without paying for their developer program you are limited to 7-days and a limited amount of apps/components you can register.

The very first thing we do when trying to sideload an app, is register your idevice to their servers, then try to create a certificate. These last 365 days, we also store the key locally so you would need to copy these keys over to other machines, if you don&#039;t, Impactor will try to make a new one.

After that, we try to register your app that you&#039;re trying to sideload, and try to provision it with proper entitlements gathered from the binary. Once we do, we have to download the neccessary files when signing, that being the certificate and provisioning profile that we just created.

Lastly, we do all of the necessary modifications we need to the app you&#039;re trying to sideload, can range between tweaks, name changing, etc. Though most importantly, we need to *sign* the app using [apple-codesign-rs](https://github.com/indygreg/apple-platform-rs) so we can **install it** with [idevice](https://github.com/jkcoxson/idevice)!

That&#039;s the entire gist of how this works! Of course its very short and brief, however feel free to look how it works since its open source :D

### Pairing File

Impactor also allows the user to generate a pairing file for applications to talk directly to the device remotely. This pairing file is device specific and will become invalid if you ever re-trust/update/reset.

Supported apps for pairing file:
- [`SideStore`](https://github.com/SideStore/SideStore): Uses your Apple ID to install iOS apps.
- [`Feather`](https://github.com/khcrysalis/Feather): Uses raw certificates to install iOS apps.
- [`SparseBox`](https://github.com/khanhduytran0/SparseBox): Device customizer.
- [`LiveContainer + SideStore`](https://github.com/LiveContainer/LiveContainer) Uses your Apple ID to install iOS apps.
- [`Antrag`](https://github.com/khcrysalis/Antrag): List currently installed iOS apps.
- [`Protokolle`](https://github.com/khcrysalis/Protokolle): View logs from system processes.
- [`StikDebug`](https://github.com/StephenDev0/StikDebug): Enable JIT for iOS apps.
- [`EnsWilde`](https://github.com/YangJiiii/EnsWilde): Device customizer.
- [`ByeTunes`](https://github.com/EduAlexxis/ByeTunes): Import mp3 files to the Music App.

You can retrieve this file by either sideloading the supported app of your choice, or going to the `Utilities` page when a device is connected and press install for the supported app. Head over to the [downloads](https://github.com/khcrysalis/PlumeImpactor/releases).

## Sponsors

| Thanks to all my [sponsors](https://github.com/sponsors/khcrysalis)!! |
|:-:|
| &lt;img src=&quot;https://raw.githubusercontent.com/khcrysalis/github-sponsor-graph/main/graph.png&quot;&gt; |
| _**&quot;samara is cute&quot; - Vendicated**_ |

## Star History

&lt;a href=&quot;https://star-history.com/#khcrysalis/plumeimpactor&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=khcrysalis/plumeimpactor&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=khcrysalis/plumeimpactor&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=khcrysalis/plumeimpactor&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## Acknowledgements

- [SAMSAM](https://github.com/khcrysalis) ‚Äì The maker.
- [Paige](https://github.com/paigely) ‚Äì Icon &amp; flatpak distribution.
- [SideStore](https://github.com/SideStore/apple-private-apis) ‚Äì Grandslam auth &amp; Omnisette.
- [gms.py](https://gist.github.com/JJTech0130/049716196f5f1751b8944d93e73d3452) ‚Äì Grandslam auth API references.
- [isideload](https://github.com/nab138/isideload) - Code for properly grabbing Xcode token.
- [Sideloader](https://github.com/Dadoum/Sideloader) ‚Äì Apple Developer API references.
- [PyDunk](https://github.com/nythepegasus/PyDunk) ‚Äì `v1` Apple Developer API references.
- [idevice](https://github.com/jkcoxson/idevice) ‚Äì Used for communication with `installd`, specifically for sideloading the apps to your devices.
- [apple-codesign-rs](https://github.com/indygreg/apple-platform-rs) ‚Äì Codesign alternative, modified and extended upon to work for Impactor.

&lt;a href=&quot;https://github.com/iced-rs/iced&quot;&gt;
  &lt;img src=&quot;https://gist.githubusercontent.com/hecrj/ad7ecd38f6e47ff3688a38c79fd108f0/raw/74384875ecbad02ae2a926425e9bcafd0695bade/color.svg&quot; width=&quot;130px&quot;&gt;
&lt;/a&gt;

## License

Project is licensed under the MIT license. You can see the full details of the license [here](https://github.com/khcrysalis/PlumeImpactor/blob/main/LICENSE). Some components may be licensed under different licenses, see their respective directories for details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BloopAI/vibe-kanban]]></title>
            <link>https://github.com/BloopAI/vibe-kanban</link>
            <guid>https://github.com/BloopAI/vibe-kanban</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:50 GMT</pubDate>
            <description><![CDATA[Get 10X more out of Claude Code, Codex or any coding agent]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BloopAI/vibe-kanban">BloopAI/vibe-kanban</a></h1>
            <p>Get 10X more out of Claude Code, Codex or any coding agent</p>
            <p>Language: Rust</p>
            <p>Stars: 21,888</p>
            <p>Forks: 2,095</p>
            <p>Stars today: 114 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vibekanban.com&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;packages/local-web/public/vibe-kanban-logo-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;packages/local-web/public/vibe-kanban-logo.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;packages/local-web/public/vibe-kanban-logo.svg&quot; alt=&quot;Vibe Kanban Logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Get 10X more out of Claude Code, Gemini CLI, Codex, Amp and other coding agents...&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/vibe-kanban&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/vibe-kanban?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/BloopAI/vibe-kanban/blob/main/.github/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/BloopAI/vibe-kanban/.github%2Fworkflows%2Fpublish.yml&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/BloopAI/vibe-kanban&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://jobs.polymer.co/vibe-kanban?source=github&quot;&gt;&lt;strong&gt;We&#039;re hiring!&lt;/strong&gt;&lt;/a&gt;
&lt;/h1&gt;

![](packages/local-web/public/vibe-kanban-screenshot-overview.png)

## Overview

AI coding agents are increasingly writing the world&#039;s code and human engineers now spend the majority of their time planning, reviewing, and orchestrating tasks. Vibe Kanban streamlines this process, enabling you to:

- Easily switch between different coding agents
- Orchestrate the execution of multiple coding agents in parallel or in sequence
- Quickly review work and start dev servers
- Track the status of tasks that your coding agents are working on
- Centralise configuration of coding agent MCP configs
- Open projects remotely via SSH when running Vibe Kanban on a remote server

You can watch a video overview [here](https://youtu.be/TFT3KnZOOAk).

## Installation

Make sure you have authenticated with your favourite coding agent. A full list of supported coding agents can be found in the [docs](https://vibekanban.com/docs). Then in your terminal run:

```bash
npx vibe-kanban
```

## Documentation

Please head to the [website](https://vibekanban.com/docs) for the latest documentation and user guides.

## Self-Hosting

Want to host your own Vibe Kanban Cloud instance? See our [self-hosting guide](https://vibekanban.com/docs/self-hosting).
  
## Support

We use [GitHub Discussions](https://github.com/BloopAI/vibe-kanban/discussions) for feature requests. Please open a discussion to create a feature request. For bugs please open an issue on this repo.

## Contributing

We would prefer that ideas and changes are first raised with the core team via [GitHub Discussions](https://github.com/BloopAI/vibe-kanban/discussions) or [Discord](https://discord.gg/AC4nwVtJM3), where we can discuss implementation details and alignment with the existing roadmap. Please do not open PRs without first discussing your proposal with the team.

## Development

### Prerequisites

- [Rust](https://rustup.rs/) (latest stable)
- [Node.js](https://nodejs.org/) (&gt;=20)
- [pnpm](https://pnpm.io/) (&gt;=8)

Additional development tools:
```bash
cargo install cargo-watch
cargo install sqlx-cli
```

Install dependencies:
```bash
pnpm i
```

### Running the dev server

```bash
pnpm run dev
```

This will start the backend and web app. A blank DB will be copied from the `dev_assets_seed` folder.

### Building the web app

To build just the web app:

```bash
cd packages/local-web
pnpm run build
```

### Build from source (macOS)

1. Run `./local-build.sh`
2. Test with `cd npx-cli &amp;&amp; node bin/cli.js`

### Environment Variables

The following environment variables can be configured at build time or runtime:

| Variable | Type | Default | Description |
|----------|------|---------|-------------|
| `POSTHOG_API_KEY` | Build-time | Empty | PostHog analytics API key (disables analytics if empty) |
| `POSTHOG_API_ENDPOINT` | Build-time | Empty | PostHog analytics endpoint (disables analytics if empty) |
| `PORT` | Runtime | Auto-assign | **Production**: Server port. **Dev**: Frontend port (backend uses PORT+1) |
| `BACKEND_PORT` | Runtime | `0` (auto-assign) | Backend server port (dev mode only, overrides PORT+1) |
| `FRONTEND_PORT` | Runtime | `3000` | Frontend dev server port (dev mode only, overrides PORT) |
| `HOST` | Runtime | `127.0.0.1` | Backend server host |
| `MCP_HOST` | Runtime | Value of `HOST` | MCP server connection host (use `127.0.0.1` when `HOST=0.0.0.0` on Windows) |
| `MCP_PORT` | Runtime | Value of `BACKEND_PORT` | MCP server connection port |
| `DISABLE_WORKTREE_CLEANUP` | Runtime | Not set | Disable all git worktree cleanup including orphan and expired workspace cleanup (for debugging) |
| `VK_ALLOWED_ORIGINS` | Runtime | Not set | Comma-separated list of origins that are allowed to make backend API requests (e.g., `https://my-vibekanban-frontend.com`) |

**Build-time variables** must be set when running `pnpm run build`. **Runtime variables** are read when the application starts.

#### Self-Hosting with a Reverse Proxy or Custom Domain

When running Vibe Kanban behind a reverse proxy (e.g., nginx, Caddy, Traefik) or on a custom domain, you must set the `VK_ALLOWED_ORIGINS` environment variable. Without this, the browser&#039;s Origin header won&#039;t match the backend&#039;s expected host, and API requests will be rejected with a 403 Forbidden error.

Set it to the full origin URL(s) where your frontend is accessible:

```bash
# Single origin
VK_ALLOWED_ORIGINS=https://vk.example.com

# Multiple origins (comma-separated)
VK_ALLOWED_ORIGINS=https://vk.example.com,https://vk-staging.example.com
```

### Remote Deployment

When running Vibe Kanban on a remote server (e.g., via systemctl, Docker, or cloud hosting), you can configure your editor to open projects via SSH:

1. **Access via tunnel**: Use Cloudflare Tunnel, ngrok, or similar to expose the web UI
2. **Configure remote SSH** in Settings ‚Üí Editor Integration:
   - Set **Remote SSH Host** to your server hostname or IP
   - Set **Remote SSH User** to your SSH username (optional)
3. **Prerequisites**:
   - SSH access from your local machine to the remote server
   - SSH keys configured (passwordless authentication)
   - VSCode Remote-SSH extension

When configured, the &quot;Open in VSCode&quot; buttons will generate URLs like `vscode://vscode-remote/ssh-remote+user@host/path` that open your local editor and connect to the remote server.

See the [documentation](https://vibekanban.com/docs/configuration-customisation/global-settings#remote-ssh-configuration) for detailed setup instructions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:49 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 31,214</p>
            <p>Forks: 2,838</p>
            <p>Stars today: 99 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;
    &gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/goose-oss&quot;
    &gt;&lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;
     &gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.

[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)

# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)
- [Responsible AI-Assisted Coding Guide](https://github.com/block/goose/blob/main/HOWTOAI.md)
- [Governance](https://github.com/block/goose/blob/main/GOVERNANCE.md)
- [Custom Distributions](https://github.com/block/goose/blob/main/CUSTOM_DISTROS.md) - build your own goose distro with preconfigured providers, extensions, and branding

## Need Help?
- [Diagnostics &amp; Reporting](https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting)
- [Known Issues](https://block.github.io/goose/docs/troubleshooting/known-issues)

# a little goose humor ü¶¢

&gt; Why did the developer choose goose as their AI agent?
&gt; 
&gt; Because it always helps them &quot;migrate&quot; their code to production! üöÄ

# goose around with us  
- [Discord](https://discord.gg/goose-oss)
- [YouTube](https://www.youtube.com/@goose-oss)
- [LinkedIn](https://www.linkedin.com/company/goose-oss)
- [Twitter/X](https://x.com/goose_oss)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tempoxyz/tempo]]></title>
            <link>https://github.com/tempoxyz/tempo</link>
            <guid>https://github.com/tempoxyz/tempo</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:48 GMT</pubDate>
            <description><![CDATA[the blockchain for payments]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tempoxyz/tempo">tempoxyz/tempo</a></h1>
            <p>the blockchain for payments</p>
            <p>Language: Rust</p>
            <p>Stars: 796</p>
            <p>Forks: 219</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;br&gt;
&lt;br&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://tempo.xyz&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/tempoxyz/.github/refs/heads/main/assets/combomark-dark.svg&quot;&gt;
      &lt;img alt=&quot;tempo combomark&quot; src=&quot;https://raw.githubusercontent.com/tempoxyz/.github/refs/heads/main/assets/combomark-bright.svg&quot; width=&quot;auto&quot; height=&quot;120&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;
&lt;br&gt;

# Tempo

The blockchain for payments at scale.

[Tempo](https://docs.tempo.xyz/) is a blockchain designed specifically for stablecoin payments. Its architecture focuses on high throughput, low cost, and features that financial institutions, payment service providers, and fintech platforms expect from modern payment infrastructure.

You can get started today by integrating with the [Tempo testnet](https://docs.tempo.xyz/quickstart/integrate-tempo), [building on Tempo](https://docs.tempo.xyz/guide/use-accounts), [running a Tempo node](https://docs.tempo.xyz/guide/node), reading the [Tempo protocol specs](https://docs.tempo.xyz/protocol) or by [building with Tempo SDKs](https://docs.tempo.xyz/sdk).

## What makes Tempo different

- [TIP‚Äë20 token standard](https://docs.tempo.xyz/protocol/tip20/overview) (enshrined ERC‚Äë20 extensions)

  - Predictable payment throughput via dedicated payment lanes reserved for TIP‚Äë20 transfers (eliminates noisy‚Äëneighbor contention).
  - Native reconciliation with on‚Äëtransfer memos and commitment patterns (hash/locator) for off‚Äëchain PII and large data.
  - Built‚Äëin compliance through [TIP‚Äë403 Policy Registry](https://docs.tempo.xyz/protocol/tip403/overview): single policy shared across multiple tokens, updated once and enforced everywhere.

- Low, predictable fees in [stablecoins](https://docs.tempo.xyz/learn/stablecoins)

  - Users pay gas directly in USD-stablecoins at launch; the [Fee AMM](https://docs.tempo.xyz/protocol/fees/fee-amm#fee-amm-overview) automatically converts to the validator‚Äôs preferred stablecoin.
  - TIP‚Äë20 transfers target sub‚Äëmillidollar costs (&lt;$0.001).

- [Tempo Transactions](https://docs.tempo.xyz/guide/tempo-transaction) (native ‚Äúsmart accounts‚Äù)

  - Batched payments: atomic multi‚Äëoperation payouts (payroll, settlements, refunds).
  - Fee sponsorship: apps can pay users&#039; gas to streamline onboarding and flows.
  - Scheduled payments: protocol‚Äëlevel time windows for recurring and timed disbursements.
  - Modern authentication: passkeys via WebAuthn/P256 (biometric sign‚Äëin, secure enclave, cross‚Äëdevice sync).

- Performance and finality

  - Built on the [Reth SDK](https://github.com/paradigmxyz/reth), the most performant and flexible EVM (Ethereum Virtual Machine) execution client.
  - Simplex Consensus (via [Commonware](https://commonware.xyz/)): fast, sub‚Äësecond finality in normal conditions; graceful degradation under adverse networks.

- Coming soon

  - On‚Äëchain FX and non‚ÄëUSD stablecoin support for direct on‚Äëchain liquidity; pay fees in more currencies.
  - Native private token standard: opt‚Äëin privacy for balances/transfers coexisting with issuer compliance and auditability.

## What makes Tempo familiar

- Fully compatible with the Ethereum Virtual Machine (EVM), targeting the Osaka hardfork.
- Deploy and interact with smart contracts using the same tools, languages, and frameworks used on Ethereum, such as Solidity, Foundry, and Hardhat.
- All Ethereum JSON-RPC methods work out of the box.

While the execution environment mirrors Ethereum&#039;s, Tempo introduces some differences optimized for payments, described [here](https://docs.tempo.xyz/quickstart/evm-compatibility).

## Getting Started

### As a user

You can connect to Tempo&#039;s public testnet using the following details:

| Property           | Value                              |
| ------------------ | ---------------------------------- |
| **Network Name**   | Tempo Testnet (Moderato)           |
| **Currency**       | `USD`                              |
| **Chain ID**       | `42431`                            |
| **HTTP URL**       | `https://rpc.moderato.tempo.xyz`   |
| **WebSocket URL**  | `wss://rpc.moderato.tempo.xyz`     |
| **Block Explorer** | `https://explore.tempo.xyz`        |

Next, grab some stablecoins to test with from Tempo&#039;s [Faucet](https://docs.tempo.xyz/quickstart/faucet#faucet).

Alternatively, use [`cast`](https://github.com/tempoxyz/tempo-foundry):

```bash
cast rpc tempo_fundAddress &lt;ADDRESS&gt; --rpc-url https://rpc.moderato.tempo.xyz
```

### As an operator

We provide three different installation paths: installing a pre-built binary, building from source or using our provided Docker image.

- [Pre-built Binary](https://docs.tempo.xyz/guide/node/installation#pre-built-binary)
- [Build from Source](https://docs.tempo.xyz/guide/node/installation#build-from-source)
- [Docker](https://docs.tempo.xyz/guide/node/installation#docker)

See the [Tempo documentation](https://docs.tempo.xyz/guide/node) for instructions on how to install and run Tempo.

### As a developer

Tempo has several SDKs to help you get started building on Tempo:

- [TypeScript](https://docs.tempo.xyz/sdk/typescript)
- [Rust](https://docs.tempo.xyz/sdk/rust)
- [Go](https://docs.tempo.xyz/sdk/go)
- [Foundry](https://docs.tempo.xyz/sdk/foundry)

Want to contribute?

First, clone the repository:

```
git clone https://github.com/tempoxyz/tempo
cd tempo
```

Next, install [`just`](https://github.com/casey/just?tab=readme-ov-file#packages).

Install the dependencies:

```bash
just
```

Build Tempo:

```bash
just build-all
```

Run the tests:

```bash
cargo nextest run
```

Start a `localnet`:

```bash
just localnet
```

## Contributing

Our contributor guidelines can be found in [`CONTRIBUTING.md`](https://github.com/tempoxyz/tempo?tab=contributing-ov-file).

## Security

See [`SECURITY.md`](https://github.com/tempoxyz/tempo?tab=security-ov-file). Note: Tempo is still undergoing audit and does not have an active bug bounty. Submissions will not be eligible for a bounty until audits have concluded.

## License

Licensed under either of [Apache License](./LICENSE-APACHE), Version
2.0 or [MIT License](./LICENSE-MIT) at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in these crates by you, as defined in the Apache-2.0 license,
shall be dual licensed as above, without any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>