<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Wed, 25 Feb 2026 00:09:17 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[ruvnet/ruvector]]></title>
            <link>https://github.com/ruvnet/ruvector</link>
            <guid>https://github.com/ruvnet/ruvector</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:17 GMT</pubDate>
            <description><![CDATA[RuVector is a high performance vector and graph database built in Rust for AI, agentic systems, and real time analytics. It combines HNSW search, dynamic minimum cut coherence, graph intelligence, and self learning memory into one unified engine for scalable, low latency reasoning and structured retrieval.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ruvnet/ruvector">ruvnet/ruvector</a></h1>
            <p>RuVector is a high performance vector and graph database built in Rust for AI, agentic systems, and real time analytics. It combines HNSW search, dynamic minimum cut coherence, graph intelligence, and self learning memory into one unified engine for scalable, low latency reasoning and structured retrieval.</p>
            <p>Language: Rust</p>
            <p>Stars: 707</p>
            <p>Forks: 124</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre># RuVector

[![Crates.io](https://img.shields.io/crates/v/ruvector-core.svg)](https://crates.io/crates/ruvector-core)
[![npm](https://img.shields.io/npm/v/ruvector.svg)](https://www.npmjs.com/package/ruvector)
[![npm Downloads](https://img.shields.io/npm/dt/ruvector.svg?label=total)](https://www.npmjs.com/package/ruvector)
[![npm Downloads](https://img.shields.io/npm/dm/ruvector.svg?label=monthly)](https://www.npmjs.com/package/ruvector)
[![HuggingFace](https://img.shields.io/badge/ü§ó-RuvLTRA_Models-yellow.svg)](https://huggingface.co/ruv/ruvltra)
[![ruv.io](https://img.shields.io/badge/ruv.io-website-purple.svg)](https://ruv.io)
[![MIT License](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

**The vector database that gets smarter the more you use it ‚Äî and now ships as a cognitive container.**

```bash
npx ruvector
```

Most vector databases are static ‚Äî they store embeddings and search them. That&#039;s it. RuVector is different: it learns from every query, runs LLMs locally, scales horizontally, boots as a Linux microservice from a single file, and costs nothing to operate.

| | Pinecone/Weaviate | RuVector |
|---|---|---|
| üß† **Search improves over time** | ‚ùå | ‚úÖ The more you search, the better results get |
| ü§ñ **Run LLMs locally** | ‚ùå | ‚úÖ Run AI models on your own machine for free |
| üîó **Graph queries** | ‚ùå | ‚úÖ Ask questions about relationships between data |
| üìö **Self-learning** | ‚ùå | ‚úÖ System watches what works and gets smarter |
| üöÄ **Self-booting microservice** | ‚ùå | ‚úÖ [One file boots into a running service](./crates/rvf/README.md) in 125 ms |
| ‚ö° **Real-time graph updates** | ‚ùå Must rebuild | ‚úÖ Update connections instantly, no downtime |
| üì¶ **Single-file deployment** | ‚ùå Server required | ‚úÖ One file ‚Äî copy it anywhere and it just works |
| üîê **Tamper-proof audit trail** | ‚ùå | ‚úÖ Every operation is cryptographically recorded |
| üåê **Works offline** | ‚ùå | ‚úÖ Runs in browsers, phones, IoT, and bare metal |
| üí∞ **Cost** | Per-query pricing | ‚úÖ Free forever ‚Äî open source (MIT) |
| üìà **Scales horizontally** | üí∞ Paid tiers | ‚úÖ Add nodes freely, no per-vector fees |
| üåø **Git-like branching** | ‚ùå | ‚úÖ Branch your data like code ‚Äî only changes are copied |
| ‚ö° **Sublinear Solvers** | ‚ùå | ‚úÖ O(log n) sparse linear systems, PageRank, spectral methods |

**One package. Everything included:** vector search, graph queries, GNN learning, distributed clustering, local LLMs, 46 attention mechanisms, cognitive containers ([RVF](./crates/rvf/README.md) ‚Äî self-booting `.rvf` files with eBPF, witness chains, and COW branching), and WASM support.

&lt;details&gt;
&lt;summary&gt;üìã See Full Capabilities (51 features)&lt;/summary&gt;

**Core Vector Database**
| # | Capability | What It Does |
|---|------------|--------------|
| 1 | **Store vectors** | Embeddings from OpenAI, Cohere, local ONNX with HNSW indexing |
| 2 | **Query with Cypher** | Graph queries like Neo4j (`MATCH (a)-[:SIMILAR]-&gt;(b)`) |
| 3 | **The index learns** | GNN layers make search results improve over time |
| 4 | **Hyperbolic HNSW** | Hierarchical data in hyperbolic space for better tree structures |
| 5 | **Compress automatically** | 2-32x memory reduction with adaptive tiered compression |

**Distributed Systems**
| # | Capability | What It Does |
|---|------------|--------------|
| 6 | **Raft consensus** | Leader election, log replication, fault-tolerant coordination |
| 7 | **Multi-master replication** | Vector clocks, conflict resolution, geo-distributed sync |
| 8 | **Burst scaling** | 10-50x capacity scaling for traffic spikes |
| 9 | **Auto-sharding** | Automatic data partitioning across nodes |

**AI &amp; Machine Learning**
| # | Capability | What It Does |
|---|------------|--------------|
| 10 | **Run LLMs locally** | ruvllm with GGUF, Metal/CUDA/ANE acceleration |
| 11 | **RuvLTRA models** | Pre-trained GGUF for routing &amp; embeddings (&lt;10ms) ‚Üí [HuggingFace](https://huggingface.co/ruv/ruvltra) |
| 12 | **SONA learning** | Self-Optimizing Neural Architecture with LoRA, EWC++ |
| 13 | **46 attention mechanisms** | Flash, linear, graph, hyperbolic, mincut-gated (50% compute) |
| 14 | **Spiking neural networks** | Event-driven neuromorphic computing |
| 15 | **Mincut-gated transformer** | Dynamic attention via graph min-cut optimization |
| 16 | **Route AI requests** | Semantic routing + FastGRNN for LLM optimization |
| 17 | **Sublinear Solvers in SQL** | PageRank, CG, Laplacian solver ‚Äî O(log n) to O(‚àön) via PostgreSQL |
| 18 | **Math Distances in SQL** | Wasserstein, Sinkhorn OT, KL divergence, spectral clustering |
| 19 | **Topological Data Analysis** | Persistent homology, Betti numbers, embedding drift detection |
| 20 | **Sona Learning in SQL** | Micro-LoRA trajectory learning with EWC++ forgetting prevention |
| 21 | **Domain Expansion** | Cross-domain transfer learning with contextual bandits |
| 22 | **Extended Attention** | O(n) linear, MoE, hyperbolic, sliding window attention in SQL |

**Cognitive Containers ([RVF](./crates/rvf/README.md))**
| # | Capability | What It Does |
|---|------------|--------------|
| 23 | **Self-boot as a microservice** | A `.rvf` file contains a real Linux kernel ‚Äî drop it on a VM and it boots in 125 ms |
| 24 | **eBPF acceleration** | Hot vectors served in kernel data path via XDP, socket filter, and TC programs |
| 25 | **5.5 KB WASM runtime** | Same file runs queries in a browser tab with zero backend |
| 26 | **COW branching** | Git-like copy-on-write ‚Äî 1M-vector parent, 100 edits = ~2.5 MB child |
| 27 | **Witness chains** | Tamper-evident hash-linked audit trail for every operation |
| 28 | **Post-quantum signatures** | ML-DSA-65 and SLH-DSA-128s alongside Ed25519 |
| 29 | **DNA-style lineage** | Track parent/child derivation chains with cryptographic hashes |
| 30 | **24 segment types** | VEC, INDEX, KERNEL, EBPF, WASM, COW_MAP, WITNESS, CRYPTO, and 16 more |

**Specialized Processing**
| # | Capability | What It Does |
|---|------------|--------------|
| 31 | **SciPix OCR** | LaTeX/MathML extraction from scientific documents |
| 32 | **DAG workflows** | Self-learning directed acyclic graph execution |
| 33 | **Cognitum Gate** | Cognitive AI gateway with TileZero acceleration |
| 34 | **FPGA transformer** | Hardware-accelerated transformer inference |
| 35 | **Quantum coherence** | ruQu for quantum error correction via dynamic min-cut |
| 36 | **Sublinear Solvers** | 8 algorithms: Neumann, CG, Forward Push, TRUE, BMSSP ‚Äî O(log n) to O(‚àön) |

**Genomics &amp; Health**
| # | Capability | What It Does |
|---|------------|--------------|
| 37 | **rvDNA genomic analysis** | Variant calling, protein translation, HNSW k-mer search in 12 ms |
| 38 | **`.rvdna` file format** | AI-native binary with pre-computed vectors, tensors, and embeddings |
| 39 | **Instant diagnostics** | Sickle cell, cancer mutations, drug dosing ‚Äî runs on any device |
| 40 | **Privacy-first WASM** | Browser-based genomics, data never leaves the device |
| 41 | **Health biomarker engine** | Composite polygenic risk scoring (20 SNPs, 6 gene-gene interactions, 2 us) |
| 42 | **Streaming biomarkers** | Real-time anomaly detection, CUSUM changepoints, trend analysis (&gt;100k readings/sec) |

**Platform &amp; Integration**
| # | Capability | What It Does |
|---|------------|--------------|
| 43 | **Run anywhere** | Node.js, browser (WASM), edge (rvLite), HTTP server, Rust, bare metal |
| 44 | **Drop into Postgres** | pgvector-compatible extension with SIMD acceleration |
| 45 | **MCP integration** | Model Context Protocol server for AI assistant tools |
| 46 | **Cloud deployment** | One-click deploy to Cloud Run, Kubernetes |
| 47 | **13 Rust crates + 4 npm packages** | [RVF SDK](./crates/rvf/README.md) published on [crates.io](https://crates.io/crates/rvf-runtime) and [npm](https://www.npmjs.com/package/@ruvector/rvf) |

**Self-Learning &amp; Adaptation**
| # | Capability | What It Does |
|---|------------|--------------|
| 48 | **Self-learning hooks** | Q-learning, neural patterns, HNSW memory |
| 49 | **ReasoningBank** | Trajectory learning with verdict judgment |
| 50 | **Economy system** | Tokenomics, CRDT-based distributed state |
| 51 | **Agentic synthesis** | Multi-agent workflow composition |

&lt;/details&gt;

*Think of it as: **Pinecone + Neo4j + PyTorch + llama.cpp + postgres + etcd + Docker** ‚Äî in one Rust package.*

*The [RVF cognitive container](./crates/rvf/README.md) is the Docker part: a single `.rvf` file that stores vectors, ships models, boots as a Linux microservice in 125 ms, accelerates queries via eBPF, branches like Git at cluster granularity, and proves every operation through a cryptographic witness chain ‚Äî all without external dependencies.*

---

### Ecosystem: AI Agent Orchestration

RuVector powers two major AI orchestration platforms:

| Platform | Purpose | Install |
|----------|---------|---------|
| [**Claude-Flow**](https://github.com/ruvnet/claude-flow) | Enterprise multi-agent orchestration for Claude Code | `npx @claude-flow/cli@latest` |
| [**Agentic-Flow**](https://github.com/ruvnet/agentic-flow) | Standalone AI agent framework (any LLM provider) | `npx agentic-flow@latest` |

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Claude-Flow v3&lt;/strong&gt; ‚Äî Turn Claude Code into a collaborative AI team&lt;/summary&gt;

**54+ specialized agents** working together on complex software engineering tasks:

```bash
# Install
npx @claude-flow/cli@latest init --wizard

# Spawn a swarm
npx @claude-flow/cli@latest swarm init --topology hierarchical --max-agents 8
```

**Key Features:**
- **SONA Learning**: Sub-50ms adaptive routing, learns optimal patterns over time
- **Queen-led Swarms**: Byzantine fault-tolerant consensus with 5 protocols (Raft, Gossip, CRDT)
- **HNSW Memory**: 150x-12,500x faster pattern retrieval via RuVector
- **175+ MCP Tools**: Native Model Context Protocol integration
- **Cost Optimization**: 3-tier routing extends Claude Code quota by 2.5x
- **Security**: AIDefence threat detection (&lt;10ms), prompt injection blocking

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Agentic-Flow v2&lt;/strong&gt; ‚Äî Production AI agents for any cloud&lt;/summary&gt;

**66 self-learning agents** with Claude Agent SDK, deployable to any cloud:

```bash
# Install
npx agentic-flow@latest

# Or with npm
npm install agentic-flow
```

**Key Features:**
- **SONA Architecture**: &lt;1ms adaptive learning, +55% quality improvement
- **Flash Attention**: 2.49x JS speedup, 7.47x with NAPI bindings
- **213 MCP Tools**: Swarm management, memory, GitHub integration
- **Agent Booster**: 352x faster code editing for simple transforms
- **Multi-Provider**: Claude, GPT, Gemini, Cohere, local models with failover
- **Graph Reasoning**: GNN query refinement with +12.4% recall improvement

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;rvDNA&lt;/strong&gt; ‚Äî AI-native genomic diagnostics, instant and available to everyone&lt;/summary&gt;

**Using AI to make the world a healthier place.** rvDNA puts genomic diagnostics on any device ‚Äî a phone, a laptop, a browser tab ‚Äî in 12 milliseconds. No cloud, no GPU, no subscription. Private by default.

```bash
cargo add rvdna              # Rust
npm install @ruvector/rvdna  # JavaScript / TypeScript
```

| What It Does | How |
|---|---|
| Find mutations (sickle cell, cancer) | Bayesian variant calling, 155 ns/SNP |
| Translate DNA to protein | Full codon table + GNN contact graphs |
| Predict biological age | Horvath clock, 353 CpG sites |
| Recommend drug doses | CYP2D6 star alleles + CPIC guidelines |
| Score health risks | 20 SNPs, 6 gene-gene interactions, composite risk scoring in 2 us |
| Stream biomarker data | Real-time anomaly detection, CUSUM changepoints, &gt;100k readings/sec |
| Search genomes by similarity | HNSW k-mer vectors, O(log N) |
| Store pre-computed AI features | `.rvdna` binary format ‚Äî open and instant |

- **Rust crate**: [crates.io/crates/rvdna](https://crates.io/crates/rvdna)
- **npm package**: [@ruvector/rvdna](https://www.npmjs.com/package/@ruvector/rvdna) (NAPI-RS native + JS fallback)
- **Source**: [examples/dna](./examples/dna)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;RVF Cognitive Containers&lt;/strong&gt; ‚Äî One file that stores, boots, and proves everything&lt;/summary&gt;

**[RVF (RuVector Format)](./crates/rvf/README.md)** is a universal binary substrate that merges database, model, graph engine, kernel, and attestation into a single deployable file. A `.rvf` file can store vector embeddings, carry LoRA adapter deltas, embed GNN graph state, include a bootable Linux microkernel, run queries in a 5.5 KB WASM runtime, and prove every operation through a cryptographic witness chain ‚Äî all in one file that runs anywhere from a browser to bare metal.

This is not a database format. It is an **executable knowledge unit**.

```bash
cargo install rvf-cli                          # CLI tool
cargo add rvf-runtime                          # Rust library
npm install @ruvector/rvf                      # TypeScript SDK
npx @ruvector/rvf-mcp-server --transport stdio # MCP server for AI agents
```

| What It Does | How |
|---|---|
| Self-boot as a microservice | Real Linux kernel in the file, boots in 125 ms on QEMU/KVM |
| Hardware-speed lookups | eBPF programs (XDP, TC, socket filter) bypass userspace entirely |
| Run in any browser | 5.5 KB WASM runtime, zero backend |
| Git-like branching | COW at cluster granularity ‚Äî 1M vectors, 100 edits = ~2.5 MB child |
| Tamper-evident audit | Hash-linked witness chain for every insert, query, and deletion |
| Post-quantum signatures | ML-DSA-65 and Ed25519 signing on every segment |
| DNA-style lineage | Parent/child derivation chains with cryptographic verification |
| 24 segment types | VEC, INDEX, KERNEL, EBPF, WASM, COW_MAP, WITNESS, CRYPTO, and 16 more |

**Rust crates** (13): [`rvf-types`](https://crates.io/crates/rvf-types) `rvf-wire` `rvf-manifest` `rvf-quant` `rvf-index` `rvf-crypto` [`rvf-runtime`](https://crates.io/crates/rvf-runtime) `rvf-kernel` `rvf-ebpf` `rvf-launch` `rvf-server` `rvf-import` [`rvf-cli`](https://crates.io/crates/rvf-cli)

**npm packages** (4): [`@ruvector/rvf`](https://www.npmjs.com/package/@ruvector/rvf) [`@ruvector/rvf-node`](https://www.npmjs.com/package/@ruvector/rvf-node) [`@ruvector/rvf-wasm`](https://www.npmjs.com/package/@ruvector/rvf-wasm) [`@ruvector/rvf-mcp-server`](https://www.npmjs.com/package/@ruvector/rvf-mcp-server)

- **Security Hardened RVF** ([`examples/security_hardened.rvf`](./examples/security_hardened.rvf)) ‚Äî 2.1 MB sealed artifact with 22 verified capabilities: TEE attestation (SGX/SEV-SNP/TDX/ARM CCA), AIDefence (injection/jailbreak/PII/exfil), hardened Linux microkernel, eBPF firewall, Ed25519 signing, 6-role RBAC, Coherence Gate, 30-entry witness chain, Paranoid policy, COW branching, audited k-NN. See [ADR-042](./docs/adr/ADR-042-Security-RVF-AIDefence-TEE.md).
- **Full documentation**: [crates/rvf/README.md](./crates/rvf/README.md)
- **ADR-030**: [Cognitive Container Architecture](./docs/adr/ADR-030-rvf-cognitive-container.md)
- **ADR-031**: [COW Branching &amp; Real Containers](./docs/adr/ADR-031-rvcow-branching-and-real-cognitive-containers.md)
- **ADR-042**: [Security RVF ‚Äî AIDefence + TEE](./docs/adr/ADR-042-Security-RVF-AIDefence-TEE.md)
- **46 runnable examples**: [examples/rvf/examples/](./examples/rvf/examples/)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Sublinear-Time Solver&lt;/strong&gt; ‚Äî O(log n) sparse linear systems for graph analytics and AI&lt;/summary&gt;

**[ruvector-solver](./crates/ruvector-solver/README.md)** provides 8 iterative algorithms for sparse linear systems, achieving O(log n) to O(‚àön) complexity ‚Äî orders of magnitude faster than dense O(n¬≥) solvers. Powers Prime Radiant coherence, GNN message passing, spectral methods, and PageRank computation.

```bash
cargo add ruvector-solver --features all-algorithms
```

| Algorithm | Complexity | Best For |
|-----------|-----------|----------|
| **Neumann Series** | O(k ¬∑ nnz) | Diagonally dominant, fast convergence |
| **Conjugate Gradient** | O(‚àöŒ∫ ¬∑ log(1/Œµ) ¬∑ nnz) | Gold-standard SPD solver |
| **Forward Push** | O(1/Œµ) | Single-source PageRank |
| **Backward Push** | O(1/Œµ) | Reverse relevance computation |
| **Hybrid Random Walk** | O(‚àön/Œµ) | Pairwise relevance, Monte Carlo |
| **TRUE** | O(log n) amortized | Large-scale Laplacian systems |
| **BMSSP** | O(nnz ¬∑ log n) | Multigrid hierarchical solve |
| **Auto Router** | Automatic | Selects optimal algorithm |

**Key optimizations**: AVX2 SIMD SpMV, fused residual kernels, bounds-check elimination, arena allocator

**Supporting crates**:
- [`ruvector-attn-mincut`](./crates/ruvector-attn-mincut/README.md) ‚Äî Min-cut gating as alternative to softmax attention
- [`ruvector-coherence`](./crates/ruvector-coherence/README.md) ‚Äî Coherence measurement for attention comparison
- [`ruvector-profiler`](./crates/ruvector-profiler/README.md) ‚Äî Memory, power, and latency benchmarking

- **177 tests** | 5 Criterion benchmarks | WASM + NAPI bindings
- **ADR documentation**: [docs/research/sublinear-time-solver/](./docs/research/sublinear-time-solver/)

&lt;/details&gt;

---

## How the GNN Works

Traditional vector search:
```
Query ‚Üí HNSW Index ‚Üí Top K Results
```

RuVector with GNN:
```
Query ‚Üí HNSW Index ‚Üí GNN Layer ‚Üí Enhanced Results
                ‚Üë                      ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ learns from ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

The GNN layer:
1. Takes your query and its nearest neighbors
2. Applies multi-head attention to weigh which neighbors matter
3. Updates representations based on graph structure
4. Returns better-ranked results

Over time, frequently-accessed paths get reinforced, making common queries faster and more accurate.


## Quick Start

### One-Line Install

```bash
# Interactive installer - lists all packages
npx ruvector install

# Or install directly
npm install ruvector
npx ruvector

# Self-learning hooks for Claude Code
npx @ruvector/cli hooks init
npx @ruvector/cli hooks install

# LLM runtime (SONA learning, HNSW memory)
npm install @ruvector/ruvllm
```

### Node.js / Browser

```bash
# Install
npm install ruvector

# Or try instantly
npx ruvector
```


&lt;details&gt;
&lt;summary&gt;üìä Comparison with Other Vector Databases&lt;/summary&gt;

| Feature | RuVector | Pinecone | Qdrant | Milvus | ChromaDB |
|---------|----------|----------|--------|--------|----------|
| **Latency (p50)** | **61¬µs** | ~2ms | ~1ms | ~5ms | ~50ms |
| **Memory (1M vec)** | 200MB* | 2GB | 1.5GB | 1GB | 3GB |
| **Graph Queries** | ‚úÖ Cypher | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **SPARQL/RDF** | ‚úÖ W3C 1.1 | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Hyperedges** | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Dynamic Min-Cut** | ‚úÖ n^0.12 | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Sublinear Solvers** | ‚úÖ 8 algorithms | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **O(log n) Graph Solve** | ‚úÖ TRUE+BMSSP | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Self-Learning (GNN)** | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Runtime Adaptation (SONA)** | ‚úÖ LoRA+EWC++ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **AI Agent Routing** | ‚úÖ Tiny Dancer | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Attention Mechanisms** | ‚úÖ 40 types | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Coherence Gate** | ‚úÖ Prime-Radiant | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Hyperbolic Embeddings** | ‚úÖ Poincar√©+Lorentz | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Local Embeddings** | ‚úÖ 8+ models | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **PostgreSQL Extension** | ‚úÖ 77+ functions | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **SIMD Optimization** | ‚úÖ AVX-512/NEON | Partial | ‚úÖ | ‚úÖ | ‚ùå |
| **Metadata Filtering** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |
| **Sparse Vectors** | ‚úÖ BM25/TF-IDF | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |
| **Raft Consensus** | ‚úÖ | ‚ùå | ‚úÖ | ‚ùå | ‚ùå |
| **Multi-Master Replication** | ‚úÖ | ‚ùå | ‚ùå | ‚úÖ | ‚ùå |
| **Auto-Sharding** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |
| **Auto-Compression** | ‚úÖ 2-32x | ‚ùå | ‚ùå | ‚úÖ | ‚ùå |
| **Snapshots/Backups** | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå |
| **Browser/WASM** | ‚úÖ WebGPU | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Standalone Edge DB** | ‚úÖ rvLite | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **LLM Runtime** | ‚úÖ ruvllm | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Pre-trained Models** | ‚úÖ RuvLTRA (HF) | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **MCP Server** | ‚úÖ mcp-gate | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Self-Learning Hooks** | ‚úÖ Q-learning+Neural+HNSW | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **Quantum Coherence** | ‚úÖ ruQu | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| **MinCut-Gated Attention** | ‚úÖ 50% compute | ‚ùå | ‚ùå | ‚ùå

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[oxc-project/oxc]]></title>
            <link>https://github.com/oxc-project/oxc</link>
            <guid>https://github.com/oxc-project/oxc</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:16 GMT</pubDate>
            <description><![CDATA[‚öì A collection of high-performance JavaScript tools.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oxc-project/oxc">oxc-project/oxc</a></h1>
            <p>‚öì A collection of high-performance JavaScript tools.</p>
            <p>Language: Rust</p>
            <p>Stars: 19,310</p>
            <p>Forks: 846</p>
            <p>Stars today: 55 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://oxc.rs&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://oxc.rs/oxc-light.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://oxc.rs/oxc-dark.svg&quot;&gt;
      &lt;img alt=&quot;Oxc logo&quot; src=&quot;https://oxc.rs/oxc-dark.svg&quot; height=&quot;60&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![MIT licensed][license-badge]][license-url]
[![Build Status][ci-badge]][ci-url]
[![Code Coverage][code-coverage-badge]][code-coverage-url]
[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/oxc-project/oxc)
[![Sponsors][sponsors-badge]][sponsors-url]

[![Discord chat][discord-badge]][discord-url]
[![Playground][playground-badge]][playground-url]
[![Website][website-badge]][website-url]

&lt;/div&gt;

## ‚öì Oxc

_/o ä …õks siÀê/_

The Oxidation Compiler is a collection of high-performance tools for JavaScript and TypeScript written in Rust.

Oxc is part of [VoidZero](https://voidzero.dev/)&#039;s vision for a unified, high-performance toolchain for JavaScript. It powers [Rolldown](https://rolldown.rs) ([Vite]&#039;s future bundler) and enables the next generation of ultra-fast development tools that work seamlessly together.

For more information, check out our website at [oxc.rs](https://oxc.rs).

&lt;sub&gt;\* Oxidation is the chemical process that creates rust&lt;/sub&gt;

## üèóÔ∏è Design Principles

- **Performance**: Through rigorous performance engineering.
- **Correctness**: Through conformance testing to standards and similar projects.
- **Developer Experience**: Clear APIs, comprehensive documentation, and sensible configuration.
- **Modular composability**: Use individual components independently or compose them into complete toolchains.

Read more about our [architecture](https://oxc.rs/docs/learn/architecture/parser.html) and [performance philosophy](https://oxc.rs/docs/learn/performance).

## üì¶ Tools &amp; Packages

| Tool        | npm                                                     | crates.io                                                   |
| ----------- | ------------------------------------------------------- | ----------------------------------------------------------- |
| Linter      | [oxlint](https://npmx.dev/package/oxlint)               | -                                                           |
| Formatter   | [oxfmt](https://npmx.dev/package/oxfmt)                 | -                                                           |
| Parser      | [oxc-parser](https://npmx.dev/package/oxc-parser)       | [oxc_parser](https://crates.io/crates/oxc_parser)           |
| Transformer | [oxc-transform](https://npmx.dev/package/oxc-transform) | [oxc_transformer](https://crates.io/crates/oxc_transformer) |
| Minifier    | [oxc-minify](https://npmx.dev/package/oxc-minify)       | [oxc_minifier](https://crates.io/crates/oxc_minifier)       |
| Resolver    | [oxc-resolver](https://npmx.dev/package/oxc-resolver)   | [oxc_resolver](https://crates.io/crates/oxc_resolver)       |

See [documentation](https://oxc.rs/) for detailed usage guides for each tool.

## ‚ö°Ô∏è Quick Start

### Linter

The production-ready linter catches mistakes for you with sensible defaults and optional configuration:

```bash
npx oxlint@latest
```

To give you an idea of its capabilities, here is an example from the [vscode] repository, which finishes linting 4800+ files in 0.7 seconds:

&lt;p float=&quot;left&quot; align=&quot;left&quot;&gt;
  &lt;img src=&quot;https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/linter-screenshot.png&quot; width=&quot;60%&quot;&gt;
&lt;/p&gt;

‚Üí [oxlint documentation](https://oxc.rs/docs/guide/usage/linter/cli.html)

### Formatter

Fast, opinionated code formatter compatible with [Prettier]:

```bash
npx oxfmt@latest
```

‚Üí [Formatter documentation](https://oxc.rs/docs/guide/usage/formatter)

### Parser (Node.js)

The fastest JavaScript/TypeScript parser written in Rust:

```bash
npm install oxc-parser
```

```js
import { parseSync } from &quot;oxc-parser&quot;;
const result = parseSync(&quot;const x = 1;&quot;);
```

‚Üí [Parser documentation](https://oxc.rs/docs/guide/usage/parser)

### Transformer (Node.js)

TypeScript, React, and modern JavaScript transformation:

```bash
npm install oxc-transform
```

```js
import { transform } from &quot;oxc-transform&quot;;
const result = transform(&quot;source.tsx&quot;, code, { typescript: true });
```

‚Üí [Transformer documentation](https://oxc.rs/docs/guide/usage/transformer)

### Minifier (Node.js)

High-performance JavaScript minifier:

```bash
npm install oxc-minify
```

```js
import { minify } from &quot;oxc-minify&quot;;
const result = minify(code, { mangle: true });
```

‚Üí [Minifier documentation](https://oxc.rs/docs/guide/usage/minifier)

### Rust

Individual crates are published for building your own JavaScript tools:

```toml
[dependencies]
oxc = &quot;0.x&quot;
```

‚Üí [Rust documentation](https://docs.rs/oxc)

## VoidZero Inc.

Oxc is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/blog).

If you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!

## üôã Who&#039;s using Oxc?

[Rolldown] and [Nuxt] use Oxc for parsing. [Rolldown] also uses Oxc for transformation and minification. [Nova], [swc-node], and [knip] use [oxc_resolver][docs-resolver-url] for module resolution. [Preact], [Shopify], [ByteDance], and [Shopee] use oxlint for linting.

[See more projects using Oxc ‚Üí](https://oxc.rs/docs/guide/projects.html)

## ‚úçÔ∏è Contribute

Check out some of the [good first issues](https://github.com/oxc-project/oxc/contribute) or ask us on [Discord][discord-url].

See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidance, or read the complete [contributing guide on our website ‚Üí](https://oxc.rs/docs/contribute/introduction.html)

If you are unable to contribute by code, you can still participate by:

- Add a [GitHub Star](https://github.com/oxc-project/oxc/stargazers) to the project
- Join us on [Discord][discord-url]
- [Follow me on X](https://x.com/boshen_c) and post about this project

## ü§ù Credits

This project was incubated with the assistance of these exceptional mentors and their projects:

- [Biome][biome] - [@ematipico](https://github.com/ematipico)
- [Ruff][ruff] - [@charliermarsh](https://github.com/charliermarsh), [@MichaReiser](https://github.com/MichaReiser)
- [quick-lint-js](https://github.com/quick-lint/quick-lint-js) - [@strager](https://github.com/strager)
- [elm-review](https://package.elm-lang.org/packages/jfmengels/elm-review/latest) - [@jfmengels](https://github.com/jfmengels)

Special thanks go to:

- [@domonji](https://github.com/domonji) for bootstrapping this project together and also completing the TypeScript parser
- [@tongtong-lu](https://github.com/tongtong-lu) and [@guan-wy](https://github.com/guan-wy) for designing the [project logo](https://github.com/oxc-project/oxc-assets)

## ‚ù§ Who&#039;s [Sponsoring Oxc](https://github.com/sponsors/Boshen)?

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/sponsors/Boshen&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/Boshen/sponsors/main/sponsors.svg&quot; alt=&quot;My sponsors&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## üìñ License

Oxc is free and open-source software licensed under the [MIT License](./LICENSE).

Oxc ports or copies code from other open source projects, their licenses are listed in [**Third-party library licenses**](./THIRD-PARTY-LICENSE).

[discord-badge]: https://img.shields.io/discord/1079625926024900739?logo=discord&amp;label=Discord
[discord-url]: https://discord.gg/9uXCAwqQZW
[license-badge]: https://img.shields.io/badge/license-MIT-blue.svg
[license-url]: https://github.com/oxc-project/oxc/blob/main/LICENSE
[ci-badge]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml/badge.svg?event=push&amp;branch=main
[ci-url]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml?query=event%3Apush+branch%3Amain
[code-coverage-badge]: https://codecov.io/gh/oxc-project/oxc/graph/badge.svg?token=FVHEH0BQLJ
[code-coverage-url]: https://codecov.io/gh/oxc-project/oxc
[sponsors-badge]: https://img.shields.io/github/sponsors/Boshen
[sponsors-url]: https://github.com/sponsors/Boshen
[playground-badge]: https://img.shields.io/badge/Playground-blue?color=9BE4E0
[playground-url]: https://playground.oxc.rs/
[website-badge]: https://img.shields.io/badge/Website-blue
[website-url]: https://oxc.rs
[docs-resolver-url]: https://docs.rs/oxc_resolver
[biome]: https://biomejs.dev/
[ruff]: https://beta.ruff.rs
[vscode]: https://github.com/microsoft/vscode
[rolldown]: https://rolldown.rs
[vite]: https://vitejs.dev/
[nuxt]: https://nuxt.com/
[nova]: https://trynova.dev/
[swc-node]: https://github.com/swc-project/swc-node
[knip]: https://github.com/webpro/knip
[preact]: https://preactjs.com/
[shopify]: https://shopify.com/
[bytedance]: https://www.bytedance.com/
[shopee]: https://shopee.com/
[prettier]: https://prettier.io/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[storytold/artcraft]]></title>
            <link>https://github.com/storytold/artcraft</link>
            <guid>https://github.com/storytold/artcraft</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:15 GMT</pubDate>
            <description><![CDATA[ArtCraft is an intentional crafting engine for artists, designers, and filmmakers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/storytold/artcraft">storytold/artcraft</a></h1>
            <p>ArtCraft is an intentional crafting engine for artists, designers, and filmmakers</p>
            <p>Language: Rust</p>
            <p>Stars: 883</p>
            <p>Forks: 70</p>
            <p>Stars today: 64 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;video src=&quot;https://github.com/user-attachments/assets/b4e24c27-d87d-4fd1-8599-dc0d0b8af48d&quot; width=&quot;100%&quot; autoplay=&quot;true&quot; loop controls&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;The IDE for artists.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.gg/artcraft&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1359579021108842617?style=for-the-badge&amp;label=discord&amp;color=ffffff&amp;logo=discord&amp;logoColor=ffffff&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.youtube.com/@OfficialArtCraftStudios&quot;&gt;&lt;img alt=&quot;YouTube&quot; src=&quot;https://img.shields.io/youtube/channel/subscribers/UCdjY4VG0ntoGwFsKZO4sVWA?style=for-the-badge&amp;logo=YouTube&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/intent/follow?screen_name=get_artcraft&quot;&gt;&lt;img alt=&quot;X&quot; src=&quot;https://img.shields.io/twitter/follow/get_artcraft?style=for-the-badge&amp;label=follow&amp;logo=x&amp;logoColor=ffffff&amp;color=ffffff&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://www.linkedin.com/company/artcraft-ai&quot;&gt;&lt;img alt=&quot;LinkedIn&quot; src=&quot;https://img.shields.io/badge/linkedin--0A66C2?style=for-the-badge&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

---

ArtCraft
========
ArtCraft is the IDE for interactive AI image and video creation.
We turn prompting into *crafting*, so your ideas become a form of tangible expression and computing.
This is Adobe Photoshop for everyone, and we&#039;re giving away the source code!

## Show, Don&#039;t Tell: Advanced Crafting Features

Text-to-image is great, but artists *need control*. It&#039;s important to know what your image will look like before you generate it, and it&#039;s vitally important to achieve consistency and repeatability.

| Feature                           | Demo + Explanation                                                                                                                                                                                                                                                      
|-----------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Image to Location**             | ![Video](https://github.com/user-attachments/assets/21f103e3-cc19-4882-a630-9caa1b76ae31) Placing virtual actors into physical environments establishes single-location consistency. You can film multiple shots within a room without having things disappear.         |
| **3D Image Compositing**          | ![Video](https://github.com/user-attachments/assets/f93a616f-571d-474e-bcc0-53736de7303d) Use images (backdrops, foreground elements, props, etc.) in scenes with depth and blend them naturally together. Just a couple of images usually leads to great compositions. |
| **2D Image Compositing**          | ![Video](https://github.com/user-attachments/assets/d6f99391-e496-4c62-9e37-29734ba5f899) Use images, background removal, layers, and simple drawing tools to precisely compose a scene.                                                                                |
| **Image to 3D Mesh**              | ![Video](https://github.com/user-attachments/assets/600a405c-e360-48c1-9b42-6e657ae6243b) It&#039;s almost impossible to lay out complicated objects or block complicated scenes; turning images into 3D helps position elements exactingly and intentionally.               |
| **Character Posing**              | ![Video](https://github.com/user-attachments/assets/52a8e983-7c8f-42d2-be8b-25296ab9ed57) You can dynamically pose your characters to achieve the precise character, scene, and camera blocking before calling &quot;action&quot;.                                                |
| **Scene Blocking w/ Kit Bashing** | ![Video](https://github.com/user-attachments/assets/eef025ac-0346-4a46-a023-d48e23629eb5) Use 3D asset kits to precisely block out your scene: get the correct angles, object positions, and rich depth layering you can&#039;t with text prompting.                         |
| **Character Identity Transfer**   | ![Video](https://github.com/user-attachments/assets/629119ee-8c76-4a83-9827-8c6c995a3ec1) Use mannequins as simple 3D ControlNets for posing any character.                                                                                                             |
| **Background Removal**            | ![Video](https://github.com/user-attachments/assets/90c65057-5531-404f-83af-b34e66e24ec1) Remove backgrounds from images to make them useful in 2D or 3D compositing. They can be props, layers, or backdrops.                                                          |
| **Mixed Asset Crafting**          | ![Video](https://raw.githubusercontent.com/storytold/github-media/main/ship-editing.gif) You can use image cutouts, worlds, and simple 3D meshes all together to precisely and intentionally lay out your scenes.                                                       |
| **Scene Blocking**                | (preview coming soon)                                                                                                                                                                                                                                                   |
| **Canvas Editing**                | (preview coming soon)                                                                                                                                                                                                                                                   |
| **Scene Relighting**              | (preview coming soon)                                                                                                                                                                                                                                                   |

Note: all of the above videos were generated for free with Grok Video; the cost to build this README was negligible.

## Quick and Easy Prompting
We haven&#039;t abandoned text-to-asset generation for quick prototyping and ideation. We support every popular workflow in a first class fashion.

| Feature               | Demo + Explanation                                                                                                                                    
|-----------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Text to Image**     | ![Video](https://github.com/user-attachments/assets/9cc289cd-faf4-4eaf-aed2-21134cce127c) Text prompt over a dozen different image models.            |
| **Image Editing**     | ![Video](https://github.com/user-attachments/assets/a06fa6ad-936c-42d0-8767-48fdbb8ff141) Edit with Nano Banana Pro and GPT Image 1.5.                |
| **Image Editing**     | ![Video](https://github.com/user-attachments/assets/f036e08a-f3a6-417a-98ee-ec7f04b2b5ff) Use inpainting, drawing, masking, etc. to edit images.      |
| **Image to Video**    | ![Video](https://github.com/user-attachments/assets/2bc6c592-511e-4fba-b40f-03c96699b7f7) Image to video with lots of different options and controls. |
| **Image Inpainting**  | (preview coming soon)                                                                                                                                 |
| **Image Ingredients** | (preview coming soon)                                                                                                                                 |

## Models and Providers Supported within Artcraft

| Provider   | Features                                                                                                                                                                |
|------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Artcraft   | Nano Banana, Nano Banana Pro, GPT-Image-1 / 1.5, Seedance 2 / Seedream 4 / 4.5, Flux 1.1 / Kontext, Veo 2 / 3 / 3.1, Kling 1.6 / 2.1 / 2.5 / 2.6, Seedance, Sora 2 / Pro, Hunyuan 3d 2 / 3 |
| Grok       | Grok Imagine, Grok Video                                                                                                                                                |
| Midjourney | Image Gen (all versions)                                                                                                                                                |
| Sora       | Sora 1, Sora 2, GPT-Image-1                                                                                                                                             |
| WorldLabs  | Marble (Gaussian Splat World Generation)                                                                                                                                |

We&#039;re going to be adding the following providers soon: Kling (via Kling website accounts), Google (via API keys), 
Runway (via website account), Luma (via website account).

We&#039;re potentially interested in adding other aggregators for those who already have subscriptions and credits at 
those providers, for example: OpenArt, FreePik, etc.

## Downloads

- [Visit our website for the stable Windows and MacOS releases](https://getartcraft.com/)
- Or you can grab a [more recent Windows and MacOS build directly](https://github.com/storytold/artcraft/releases)
- Linux requires building from source for now

## Documentation

- [developer documentation](./_docs)
- [tools, scripts, misc](./script)
- [license](./LICENSE.md)
- [roadmap](./ROADMAP.md)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[linera-io/linera-protocol]]></title>
            <link>https://github.com/linera-io/linera-protocol</link>
            <guid>https://github.com/linera-io/linera-protocol</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:14 GMT</pubDate>
            <description><![CDATA[Main repository for the Linera protocol]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/linera-io/linera-protocol">linera-io/linera-protocol</a></h1>
            <p>Main repository for the Linera protocol</p>
            <p>Language: Rust</p>
            <p>Stars: 32,141</p>
            <p>Forks: 2,301</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/linera-io/linera-protocol/assets/1105398/fe08c941-93af-4114-bb83-bcc0eaec95f9&quot; width=&quot;250&quot; height=&quot;85&quot; /&gt;

[![License](https://img.shields.io/github/license/linera-io/linera-protocol)](LICENSE)
[![Build Status for Docker](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml)
[![Build Status for Rust](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml)
[![Build Status for Documentation](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml)
[![Twitter](https://img.shields.io/twitter/follow/linera_io)](https://x.com/linera_io)
[![Discord](https://img.shields.io/discord/984941796272521226)](https://discord.com/invite/linera)

&lt;!-- [![Build Status for Kubernetes](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml) --&gt;

[Linera](https://linera.io) is a decentralized blockchain infrastructure designed for highly scalable,
secure, low-latency Web3 applications.

## Documentation

Visit our [developer page](https://linera.dev) and read our
[whitepaper](https://linera.io/whitepaper) to learn more about the Linera protocol.

## Repository Structure

The main crates and directories of this repository can be summarized as follows: (listed
from low to high levels in the dependency graph)

* [`linera-base`](https://linera-io.github.io/linera-protocol/linera_base/index.html) Base
  definitions, including cryptography.

* [`linera-version`](https://linera-io.github.io/linera-protocol/linera_version/index.html)
  A library to manage version info in binaries and services.

* [`linera-views`](https://linera-io.github.io/linera-protocol/linera_views/index.html) A
  library mapping complex data structures onto a key-value store. The corresponding
  procedural macros are implemented in `linera-views-derive`.

* [`linera-execution`](https://linera-io.github.io/linera-protocol/linera_execution/index.html)
  Persistent data and the corresponding logic for runtime and execution of Linera
  applications.

* [`linera-chain`](https://linera-io.github.io/linera-protocol/linera_chain/index.html)
  Persistent data and the corresponding logic for chains of blocks, certificates, and
  cross-chain messaging.

* [`linera-storage`](https://linera-io.github.io/linera-protocol/linera_storage/index.html)
  Defines the storage abstractions for the protocol on top of `linera-chain`.

* [`linera-core`](https://linera-io.github.io/linera-protocol/linera_core/index.html) The
  core Linera protocol, including client and server logic, node synchronization, etc.

* [`linera-rpc`](https://linera-io.github.io/linera-protocol/linera_rpc/index.html)
  Defines the data-type for RPC messages (currently all client &amp;#x2194; proxy &amp;#x2194;
  chain &amp;#x2194; chain interactions), and track the corresponding data schemas.

* [`linera-client`](https://linera-io.github.io/linera-protocol/linera_client/index.html)
  Library for writing Linera clients.  Used for the command-line
  client and the node service in `linera-service`, as well as the Web
  client in [`linera-web`](https://github.com/linera-io/linera-web/).

* [`linera-service`](https://linera-io.github.io/linera-protocol/linera_service/index.html)
  Executable for clients (aka CLI wallets), proxy (aka validator frontend) and servers.

* [`linera-sdk`](https://linera-io.github.io/linera-protocol/linera_sdk/index.html) The
  library to develop Linera applications written in Rust for the Wasm virtual machine. The
  corresponding procedural macros are implemented in `linera-sdk-derive`.

* [`examples`](./examples) Examples of Linera applications written in Rust.

## Prerequisites

See [`INSTALL.md`](./INSTALL.md) for software requirements to develop in this repo.

## Quickstart with the Linera CLI tool

The following commands set up a local test network and run some transfers between the
microchains owned by a single wallet.

```bash
# Make sure to compile the Linera binaries and add them in the $PATH.
# cargo build -p linera-storage-service -p linera-service --bins
export PATH=&quot;$PWD/target/debug:$PATH&quot;

# Import the optional helper function `linera_spawn`.
source /dev/stdin &lt;&lt;&lt;&quot;$(linera net helper 2&gt;/dev/null)&quot;

# Run a local test network with the default parameters and a number of microchains
# owned by the default wallet. This also defines `LINERA_TMP_DIR`.
linera_spawn \
linera net up --with-faucet --faucet-port 8080

# Remember the URL of the faucet.
FAUCET_URL=http://localhost:8080

# If you&#039;re using a testnet, start here and run this instead:
#   LINERA_TMP_DIR=$(mktemp -d)
#   FAUCET_URL=https://faucet.testnet-XXX.linera.net  # for some value XXX
```

Enable logs for user applications:

```bash
export LINERA_APPLICATION_LOGS=true
```

Set the path of the future wallet:

```bash
export LINERA_WALLET=&quot;$LINERA_TMP_DIR/wallet.json&quot;
export LINERA_KEYSTORE=&quot;$LINERA_TMP_DIR/keystore.json&quot;
export LINERA_STORAGE=&quot;rocksdb:$LINERA_TMP_DIR/client.db&quot;

# Initialize a new user wallet.
linera wallet init --faucet $FAUCET_URL

# Request chains.
INFO1=($(linera wallet request-chain --faucet $FAUCET_URL))
INFO2=($(linera wallet request-chain --faucet $FAUCET_URL))
CHAIN1=&quot;${INFO1[0]}&quot;
ACCOUNT1=&quot;${INFO1[1]}&quot;
CHAIN2=&quot;${INFO2[0]}&quot;
ACCOUNT2=&quot;${INFO2[1]}&quot;

# Show the different chains tracked by the wallet.
linera wallet show

# Query the chain balance of some of the chains.
linera query-balance &quot;$CHAIN1&quot;
linera query-balance &quot;$CHAIN2&quot;

# Transfer 10 units then 5 back.
linera transfer 10 --from &quot;$CHAIN1&quot; --to &quot;$CHAIN2&quot;
linera transfer 5 --from &quot;$CHAIN2&quot; --to &quot;$CHAIN1&quot;

# Query balances again.
linera query-balance &quot;$CHAIN1&quot;
linera query-balance &quot;$CHAIN2&quot;

# Now let&#039;s fund the user balances.
linera transfer 5 --from &quot;$CHAIN1&quot; --to &quot;$ACCOUNT1@$CHAIN1&quot;
linera transfer 2 --from &quot;$ACCOUNT1@$CHAIN1&quot; --to &quot;$ACCOUNT2@$CHAIN2&quot;

# Query user balances again.
linera query-balance &quot;$ACCOUNT1@$CHAIN1&quot;
linera query-balance &quot;$ACCOUNT2@$CHAIN2&quot;
```

More complex examples may be found in our [developer manual](https://linera.dev) as well
as the [example applications](./examples) in this repository.

## Contributing

We welcome contributions from the community! If you&#039;d like to contribute to the Linera protocol:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m &#039;Add some amazing feature&#039;`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

For detailed guidelines, see our [contribution guide](./CONTRIBUTING.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[claration/Impactor]]></title>
            <link>https://github.com/claration/Impactor</link>
            <guid>https://github.com/claration/Impactor</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:13 GMT</pubDate>
            <description><![CDATA[WIP feature rich iOS/tvOS sideloading application written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/claration/Impactor">claration/Impactor</a></h1>
            <p>WIP feature rich iOS/tvOS sideloading application written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,314</p>
            <p>Forks: 63</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/user-attachments/assets/18f2eff4-546f-4365-98eb-afb19b13dc13&quot; width=&quot;25&quot; height=&quot;25&quot; /&gt; Impactor

[![GitHub Release](https://img.shields.io/github/v/release/claration/Impactor?include_prereleases)](https://github.com/claration/Impactor/releases)
[![GitHub Downloads (all assets, all releases)](https://img.shields.io/github/downloads/claration/Impactor/total)](https://github.com/claration/Impactor/releases)
[![GitHub License](https://img.shields.io/github/license/claration/Impactor?color=%23C96FAD)](https://github.com/claration/Impactor/blob/main/LICENSE)
[![Sponsor Me](https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;color=%23fe8e86)](https://github.com/sponsors/claration)

Open-source, cross-platform, and feature rich iOS sideloading application. Supporting macOS, Linux[^1], and Windows[^2].

[^1]: On Linux, usbmuxd must be installed on your system. Don&#039;t worry though, it comes with most popular distributions by default already! However, due to some distributions [udev](https://man7.org/linux/man-pages/man7/udev.7.html) rules `usbmuxd` may stop running after no devices are connected causing Impactor to not detect the device after plugging it in. You can mitigate this by plugging your phone first then restarting the app. \
\
Auto-refresh will not work the same as it would on other platforms like macOS/Windows, due to `usbmuxd` lacking WiFi connectivity so it will attempt to do it automatically only when a device is plugged in, we are looking for a proper solution though.\
\
Some distributions (like Bazzite) may need you to run `sudo update-crypto-policies` so `usbmuxd` ends up detecting the device again.

[^2]: On Windows, [iTunes](https://support.apple.com/en-us/106372) must be downloaded so Impactor is able to use the drivers for interacting with Apple devices.

![Demo of app](demo.png)

### Features

- User friendly and clean UI.
- Supports installing [SideStore](https://github.com/SideStore/SideStore) and [LiveContainer](https://github.com/LiveContainer/LiveContainer) properly.
- Supports Linux.
- Sign and sideload applications on iOS 9.0+ &amp; Mac with your Apple ID.
  - Installing with [AppSync](https://github.com/akemin-dayo/AppSync) is supported.
  - Installing with ipatool gotten ipa&#039;s is supported.
    - Automatically disables updates from the App Store.
- Simple customization options for the app.
- Tweak support for advanced users, using [ElleKit](https://github.com/tealbathingsuit/ellekit) for injection.
  - Supports injecting `.deb` and `.dylib` files.
  - Supports adding `.framework`, `.bundle`, and `.appex` directories.
  - Supports replacing Cydia Substrate with ElleKit for 26.0 compatibility.
- Generates P12 for SideStore/AltStore to use, similar to Altserver.
- Automatically populate pairing files for apps like SideStore, Antrag, and Protokolle.
- Comes with simple device utilities for retrusting/placing pairing file.
- Export P12 for use with LiveContainer.
- Almost *proper* entitlement handling and can register app plugins.
  - Able to request entitlements like `increased-memory-limit`, for emulators like MelonX or UTM.

## Download

Visit [releases](https://github.com/khcrysalis/PlumeImpactor/releases) and get the latest version for your computer.

###### *This is also available on flatpak &amp; homebrew.*

**Linux:**

&lt;a href=&quot;https://flathub.org/en/apps/dev.khcrysalis.PlumeImpactor&quot;&gt;
  &lt;img src=&quot;https://dl.flathub.org/assets/badges/flathub-badge-en.svg&quot; width=&quot;200px&quot;&gt;
&lt;/a&gt;

**macOS:**

```sh
brew install --cask impactor
```

## How it works

How it works is that we try to replicate what [Xcode](https://developer.apple.com/xcode/) would do but in our own application, by using your Apple Account (which serves the purpose of being a &quot;Developer&quot;) so we can request certificates, provisioning profiles, and register your device from Apple themselves. 

Apple here is the provider of these and how we&#039;ll even be able to get apps on your phone. Unfortunately, without paying for their developer program you are limited to 7-days and a limited amount of apps/components you can register.

The very first thing we do when trying to sideload an app, is register your idevice to their servers, then try to create a certificate. These last 365 days, we also store the key locally so you would need to copy these keys over to other machines, if you don&#039;t, Impactor will try to make a new one.

After that, we try to register your app that you&#039;re trying to sideload, and try to provision it with proper entitlements gathered from the binary. Once we do, we have to download the neccessary files when signing, that being the certificate and provisioning profile that we just created.

Lastly, we do all of the necessary modifications we need to the app you&#039;re trying to sideload, can range between tweaks, name changing, etc. Though most importantly, we need to *sign* the app using [apple-codesign-rs](https://github.com/indygreg/apple-platform-rs) so we can **install it** with [idevice](https://github.com/jkcoxson/idevice)!

That&#039;s the entire gist of how this works! Of course its very short and brief, however feel free to look how it works since its open source :D

### Pairing File

Impactor also allows the user to generate a pairing file for applications to talk directly to the device remotely. This pairing file is device specific and will become invalid if you ever re-trust/update/reset.

Supported apps for pairing file:
- [`SideStore`](https://github.com/SideStore/SideStore): Uses your Apple ID to install iOS apps.
- [`Feather`](https://github.com/khcrysalis/Feather): Uses raw certificates to install iOS apps.
- [`SparseBox`](https://github.com/khanhduytran0/SparseBox): Device customizer.
- [`LiveContainer + SideStore`](https://github.com/LiveContainer/LiveContainer) Uses your Apple ID to install iOS apps.
- [`Antrag`](https://github.com/khcrysalis/Antrag): List currently installed iOS apps.
- [`Protokolle`](https://github.com/khcrysalis/Protokolle): View logs from system processes.
- [`StikDebug`](https://github.com/StephenDev0/StikDebug): Enable JIT for iOS apps.
- [`EnsWilde`](https://github.com/YangJiiii/EnsWilde): Device customizer.
- [`ByeTunes`](https://github.com/EduAlexxis/ByeTunes): Import mp3 files to the Music App.

You can retrieve this file by either sideloading the supported app of your choice, or going to the `Utilities` page when a device is connected and press install for the supported app. Head over to the [downloads](https://github.com/khcrysalis/PlumeImpactor/releases).

## Sponsors

| Thanks to all my [sponsors](https://github.com/sponsors/khcrysalis)!! |
|:-:|
| &lt;img src=&quot;https://raw.githubusercontent.com/khcrysalis/github-sponsor-graph/main/graph.png&quot;&gt; |
| _**&quot;samara is cute&quot; - Vendicated**_ |

## Star History

&lt;a href=&quot;https://star-history.com/#khcrysalis/plumeimpactor&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=khcrysalis/plumeimpactor&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=khcrysalis/plumeimpactor&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=khcrysalis/plumeimpactor&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## Acknowledgements

- [SAMSAM](https://github.com/khcrysalis) ‚Äì The maker.
- [Paige](https://github.com/paigely) ‚Äì Icon &amp; flatpak distribution.
- [SideStore](https://github.com/SideStore/apple-private-apis) ‚Äì Grandslam auth &amp; Omnisette.
- [gms.py](https://gist.github.com/JJTech0130/049716196f5f1751b8944d93e73d3452) ‚Äì Grandslam auth API references.
- [isideload](https://github.com/nab138/isideload) - Code for properly grabbing Xcode token.
- [Sideloader](https://github.com/Dadoum/Sideloader) ‚Äì Apple Developer API references.
- [PyDunk](https://github.com/nythepegasus/PyDunk) ‚Äì `v1` Apple Developer API references.
- [idevice](https://github.com/jkcoxson/idevice) ‚Äì Used for communication with `installd`, specifically for sideloading the apps to your devices.
- [apple-codesign-rs](https://github.com/indygreg/apple-platform-rs) ‚Äì Codesign alternative, modified and extended upon to work for Impactor.

&lt;a href=&quot;https://github.com/iced-rs/iced&quot;&gt;
  &lt;img src=&quot;https://gist.githubusercontent.com/hecrj/ad7ecd38f6e47ff3688a38c79fd108f0/raw/74384875ecbad02ae2a926425e9bcafd0695bade/color.svg&quot; width=&quot;130px&quot;&gt;
&lt;/a&gt;

## License

Project is licensed under the MIT license. You can see the full details of the license [here](https://github.com/khcrysalis/PlumeImpactor/blob/main/LICENSE). Some components may be licensed under different licenses, see their respective directories for details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:12 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 79,746</p>
            <p>Forks: 2,597</p>
            <p>Stars today: 79 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`, and
  more.
- [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- [Installs and manages](#python-versions) Python versions.
- [Runs and installs](#tools) tools published as Python packages.
- Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a familiar
  CLI.
- Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- Installable without Rust or Python via `curl` or `pip`.
- Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff) and [ty](https://github.com/astral-sh/ty).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.12 3.13 3.14
Installed 3 versions in 972ms
 + cpython-3.12.12-macos-aarch64-none (python3.12)
 + cpython-3.13.9-macos-aarch64-none (python3.13)
 + cpython-3.14.0-macos-aarch64-none (python3.14)

```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv?tab=contributing-ov-file#contributing) to get
started.

## FAQ

#### How do you pronounce uv?

It&#039;s pronounced as &quot;you - vee&quot; ([`/juÀê viÀê/`](https://en.wikipedia.org/wiki/Help:IPA/English#Key))

#### How should I stylize uv?

Just &quot;uv&quot;, please. See the [style guide](./STYLE.md#styling-uv) for details.

#### What platforms does uv support?

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

#### Is uv ready for production?

Yes, uv is stable and widely used in production. See uv&#039;s
[versioning policy](https://docs.astral.sh/uv/reference/versioning/) document for details.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lbjlaq/Antigravity-Manager]]></title>
            <link>https://github.com/lbjlaq/Antigravity-Manager</link>
            <guid>https://github.com/lbjlaq/Antigravity-Manager</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:11 GMT</pubDate>
            <description><![CDATA[Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).‰∏ì‰∏öÁöÑ Antigravity Ë¥¶Âè∑ÁÆ°ÁêÜ‰∏éÂàáÊç¢Â∑•ÂÖ∑„ÄÇ‰∏∫ Antigravity Êèê‰æõ‰∏ÄÈîÆÊó†ÁºùË¥¶Âè∑ÂàáÊç¢ÂäüËÉΩ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lbjlaq/Antigravity-Manager">lbjlaq/Antigravity-Manager</a></h1>
            <p>Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).‰∏ì‰∏öÁöÑ Antigravity Ë¥¶Âè∑ÁÆ°ÁêÜ‰∏éÂàáÊç¢Â∑•ÂÖ∑„ÄÇ‰∏∫ Antigravity Êèê‰æõ‰∏ÄÈîÆÊó†ÁºùË¥¶Âè∑ÂàáÊç¢ÂäüËÉΩ„ÄÇ</p>
            <p>Language: Rust</p>
            <p>Stars: 24,170</p>
            <p>Forks: 2,712</p>
            <p>Stars today: 149 stars today</p>
            <h2>README</h2><pre># Antigravity Tools üöÄ
&gt; ‰∏ì‰∏öÁ∫ß AI Ë¥¶Âè∑ÁÆ°ÁêÜ‰∏éÂçèËÆÆ‰ª£ÁêÜÁ≥ªÁªü (v4.1.22)
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;public/icon.png&quot; alt=&quot;Antigravity Logo&quot; width=&quot;120&quot; height=&quot;120&quot; style=&quot;border-radius: 24px; box-shadow: 0 10px 30px rgba(0,0,0,0.15);&quot;&gt;

  &lt;h3&gt;ÊÇ®ÁöÑ‰∏™‰∫∫È´òÊÄßËÉΩ AI Ë∞ÉÂ∫¶ÁΩëÂÖ≥&lt;/h3&gt;
  &lt;p&gt;‰∏ç‰ªÖ‰ªÖÊòØË¥¶Âè∑ÁÆ°ÁêÜÔºåÊõ¥ÊòØÊâìÁ†¥ API Ë∞ÉÁî®Â£ÅÂûíÁöÑÁªàÊûÅËß£ÂÜ≥ÊñπÊ°à„ÄÇ&lt;/p&gt;
  
  &lt;p&gt;
    &lt;a href=&quot;https://github.com/lbjlaq/Antigravity-Manager&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Version-4.1.22-blue?style=flat-square&quot; alt=&quot;Version&quot;&gt;
    &lt;/a&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Tauri-v2-orange?style=flat-square&quot; alt=&quot;Tauri&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Backend-Rust-red?style=flat-square&quot; alt=&quot;Rust&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Frontend-React-61DAFB?style=flat-square&quot; alt=&quot;React&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-CC--BY--NC--SA--4.0-lightgrey?style=flat-square&quot; alt=&quot;License&quot;&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;#-Ê†∏ÂøÉÂäüËÉΩ&quot;&gt;Ê†∏ÂøÉÂäüËÉΩ&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-ÁïåÈù¢ÂØºËßà&quot;&gt;ÁïåÈù¢ÂØºËßà&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-ÊäÄÊúØÊû∂ÊûÑ&quot;&gt;ÊäÄÊúØÊû∂ÊûÑ&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-ÂÆâË£ÖÊåáÂçó&quot;&gt;ÂÆâË£ÖÊåáÂçó&lt;/a&gt; ‚Ä¢ 
    &lt;a href=&quot;#-Âø´ÈÄüÊé•ÂÖ•&quot;&gt;Âø´ÈÄüÊé•ÂÖ•&lt;/a&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;strong&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/strong&gt; | 
    &lt;a href=&quot;./README_EN.md&quot;&gt;English&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

---

**Antigravity Tools** ÊòØ‰∏Ä‰∏™‰∏ì‰∏∫ÂºÄÂèëËÄÖÂíå AI Áà±Â•ΩËÄÖËÆæËÆ°ÁöÑÂÖ®ÂäüËÉΩÊ°åÈù¢Â∫îÁî®„ÄÇÂÆÉÂ∞ÜÂ§öË¥¶Âè∑ÁÆ°ÁêÜ„ÄÅÂçèËÆÆËΩ¨Êç¢ÂíåÊô∫ËÉΩËØ∑Ê±ÇË∞ÉÂ∫¶ÂÆåÁæéÁªìÂêàÔºå‰∏∫ÊÇ®Êèê‰æõ‰∏Ä‰∏™Á®≥ÂÆö„ÄÅÊûÅÈÄü‰∏îÊàêÊú¨‰ΩéÂªâÁöÑ **Êú¨Âú∞ AI ‰∏≠ËΩ¨Á´ô**„ÄÇ

ÈÄöËøáÊú¨Â∫îÁî®ÔºåÊÇ®ÂèØ‰ª•Â∞ÜÂ∏∏ËßÅÁöÑ Web Á´Ø Session (Google/Anthropic) ËΩ¨Âåñ‰∏∫Ê†áÂáÜÂåñÁöÑ API Êé•Âè£ÔºåÊ∂àÈô§‰∏çÂêåÂéÇÂïÜÈó¥ÁöÑÂçèËÆÆÈ∏øÊ≤ü„ÄÇ

## üíñ ËµûÂä©ÂïÜ (Sponsors)

| ËµûÂä©ÂïÜ (Sponsor) | ÁÆÄ‰ªã (Description) |
| :---: | :--- |
| &lt;img src=&quot;docs/images/packycode_logo.png&quot; width=&quot;200&quot; alt=&quot;PackyCode Logo&quot;&gt; | ÊÑüË∞¢ **PackyCode** ÂØπÊú¨È°πÁõÆÁöÑËµûÂä©ÔºÅPackyCode ÊòØ‰∏ÄÂÆ∂ÂèØÈù†È´òÊïàÁöÑ API ‰∏≠ËΩ¨ÊúçÂä°ÂïÜÔºåÊèê‰æõ Claude Code„ÄÅCodex„ÄÅGemini Á≠âÂ§öÁßçÊúçÂä°ÁöÑ‰∏≠ËΩ¨„ÄÇPackyCode ‰∏∫Êú¨È°πÁõÆÁöÑÁî®Êà∑Êèê‰æõ‰∫ÜÁâπÂà´‰ºòÊÉ†Ôºö‰ΩøÁî®[Ê≠§ÈìæÊé•](https://www.packyapi.com/register?aff=Ctrler)Ê≥®ÂÜåÔºåÂπ∂Âú®ÂÖÖÂÄºÊó∂ËæìÂÖ• **‚ÄúCtrler‚Äù** ‰ºòÊÉ†Á†ÅÂç≥ÂèØ‰∫´Âèó **‰πùÊäò‰ºòÊÉ†**„ÄÇ |
| &lt;img src=&quot;docs/images/AICodeMirror.jpg&quot; width=&quot;200&quot; alt=&quot;AICodeMirror Logo&quot;&gt; | ÊÑüË∞¢ AICodeMirror ËµûÂä©‰∫ÜÊú¨È°πÁõÆÔºÅAICodeMirror Êèê‰æõ Claude Code / Codex / Gemini CLI ÂÆòÊñπÈ´òÁ®≥ÂÆö‰∏≠ËΩ¨ÊúçÂä°ÔºåÊîØÊåÅ‰ºÅ‰∏öÁ∫ßÈ´òÂπ∂Âèë„ÄÅÊûÅÈÄüÂºÄÁ•®„ÄÅ7√ó24 ‰∏ìÂ±ûÊäÄÊúØÊîØÊåÅ„ÄÇ Claude Code / Codex / Gemini ÂÆòÊñπÊ∏†ÈÅì‰ΩéËá≥ 3.8 / 0.2 / 0.9 ÊäòÔºåÂÖÖÂÄºÊõ¥ÊúâÊäò‰∏äÊäòÔºÅAICodeMirror ‰∏∫ Antigravity-Manager ÁöÑÁî®Êà∑Êèê‰æõ‰∫ÜÁâπÂà´Á¶èÂà©ÔºåÈÄöËøá[Ê≠§ÈìæÊé•](https://www.aicodemirror.com/register?invitecode=MV5XUM)Ê≥®ÂÜåÁöÑÁî®Êà∑ÔºåÂèØ‰∫´ÂèóÈ¶ñÂÖÖ8ÊäòÔºå‰ºÅ‰∏öÂÆ¢Êà∑ÊúÄÈ´òÂèØ‰∫´ 7.5 ÊäòÔºÅ |

### ‚òï ÊîØÊåÅÈ°πÁõÆ (Support)

Â¶ÇÊûúÊÇ®ËßâÂæóÊú¨È°πÁõÆÂØπÊÇ®ÊúâÊâÄÂ∏ÆÂä©ÔºåÊ¨¢ËøéÊâìËµè‰ΩúËÄÖÔºÅ

&lt;a href=&quot;https://www.buymeacoffee.com/Ctrler&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://cdn.buymeacoffee.com/buttons/v2/default-green.png&quot; alt=&quot;ËØ∑ÊàëÂñùÊùØÂíñÂï°&quot; style=&quot;height: 60px !important; width: 217px !important;&quot;&gt;&lt;/a&gt;

| ÊîØ‰ªòÂÆù (Alipay) | ÂæÆ‰ø°ÊîØ‰ªò (WeChat) | Buy Me a Coffee |
| :---: | :---: | :---: |
| ![Alipay](./docs/images/donate_alipay.png) | ![WeChat](./docs/images/donate_wechat.png) | ![Coffee](./docs/images/donate_coffee.png) |

## üåü Ê∑±Â∫¶ÂäüËÉΩËß£Êûê (Detailed Features)

### 1. üéõÔ∏è Êô∫ËÉΩË¥¶Âè∑‰ª™Ë°®Áõò (Smart Dashboard)
*   **ÂÖ®Â±ÄÂÆûÊó∂ÁõëÊéß**: ‰∏ÄÁúºÊ¥ûÂØüÊâÄÊúâË¥¶Âè∑ÁöÑÂÅ•Â∫∑Áä∂ÂÜµÔºåÂåÖÊã¨ Gemini Pro„ÄÅGemini Flash„ÄÅClaude ‰ª•Âèä Gemini ÁªòÂõæÁöÑ **Âπ≥ÂùáÂâ©‰ΩôÈÖçÈ¢ù**„ÄÇ
*   **ÊúÄ‰Ω≥Ë¥¶Âè∑Êé®Ëçê (Smart Recommendation)**: Á≥ªÁªü‰ºöÊ†πÊçÆÂΩìÂâçÊâÄÊúâË¥¶Âè∑ÁöÑÈÖçÈ¢ùÂÜó‰ΩôÂ∫¶ÔºåÂÆûÊó∂ÁÆóÊ≥ïÁ≠õÈÄâÂπ∂Êé®Ëçê‚ÄúÊúÄ‰Ω≥Ë¥¶Âè∑‚ÄùÔºåÊîØÊåÅ **‰∏ÄÈîÆÂàáÊç¢**„ÄÇ
*   **Ê¥ªË∑ÉË¥¶Âè∑Âø´ÁÖß**: Áõ¥ËßÇÊòæÁ§∫ÂΩìÂâçÊ¥ªË∑ÉË¥¶Âè∑ÁöÑÂÖ∑‰ΩìÈÖçÈ¢ùÁôæÂàÜÊØîÂèäÊúÄÂêéÂêåÊ≠•Êó∂Èó¥„ÄÇ

### 2. üîê Âº∫Â§ßÁöÑË¥¶Âè∑ÁÆ°ÂÆ∂ (Account Management)
*   **OAuth 2.0 ÊéàÊùÉÔºàËá™Âä®/ÊâãÂä®Ôºâ**: Ê∑ªÂä†Ë¥¶Âè∑Êó∂‰ºöÊèêÂâçÁîüÊàêÂèØÂ§çÂà∂ÁöÑÊéàÊùÉÈìæÊé•ÔºåÊîØÊåÅÂú®‰ªªÊÑèÊµèËßàÂô®ÂÆåÊàêÊéàÊùÉÔºõÂõûË∞ÉÊàêÂäüÂêéÂ∫îÁî®‰ºöËá™Âä®ÂÆåÊàêÂπ∂‰øùÂ≠òÔºàÂøÖË¶ÅÊó∂ÂèØÁÇπÂáª‚ÄúÊàëÂ∑≤ÊéàÊùÉÔºåÁªßÁª≠‚ÄùÊâãÂä®Êî∂Â∞æÔºâ„ÄÇ
*   **Â§öÁª¥Â∫¶ÂØºÂÖ•**: ÊîØÊåÅÂçïÊù° Token ÂΩïÂÖ•„ÄÅJSON ÊâπÈáèÂØºÂÖ•ÔºàÂ¶ÇÊù•Ëá™ÂÖ∂‰ªñÂ∑•ÂÖ∑ÁöÑÂ§á‰ªΩÔºâÔºå‰ª•Âèä‰ªé V1 ÊóßÁâàÊú¨Êï∞ÊçÆÂ∫ìËá™Âä®ÁÉ≠ËøÅÁßª„ÄÇ
*   **ÁΩëÂÖ≥Á∫ßËßÜÂõæ**: ÊîØÊåÅ‚ÄúÂàóË°®‚Äù‰∏é‚ÄúÁΩëÊ†º‚ÄùÂèåËßÜÂõæÂàáÊç¢„ÄÇÊèê‰æõ 403 Â∞ÅÁ¶ÅÊ£ÄÊµãÔºåËá™Âä®Ê†áÊ≥®Âπ∂Ë∑≥ËøáÊùÉÈôêÂºÇÂ∏∏ÁöÑË¥¶Âè∑„ÄÇ

### 3. üîå ÂçèËÆÆËΩ¨Êç¢‰∏é‰∏≠Áªß (API Proxy)
*   **ÂÖ®ÂçèËÆÆÈÄÇÈÖç (Multi-Sink)**:
    *   **OpenAI Ê†ºÂºè**: Êèê‰æõ `/v1/chat/completions` Á´ØÁÇπÔºåÂÖºÂÆπ 99% ÁöÑÁé∞Êúâ AI Â∫îÁî®„ÄÇ
    *   **Anthropic Ê†ºÂºè**: Êèê‰æõÂéüÁîü `/v1/messages` Êé•Âè£ÔºåÊîØÊåÅ **Claude Code CLI** ÁöÑÂÖ®ÂäüËÉΩÔºàÂ¶ÇÊÄùÊÄùÁª¥Èìæ„ÄÅÁ≥ªÁªüÊèêÁ§∫ËØçÔºâ„ÄÇ
    *   **Gemini Ê†ºÂºè**: ÊîØÊåÅ Google ÂÆòÊñπ SDK Áõ¥Êé•Ë∞ÉÁî®„ÄÇ
*   **Êô∫ËÉΩÁä∂ÊÄÅËá™ÊÑà**: ÂΩìËØ∑Ê±ÇÈÅáÂà∞ `429 (Too Many Requests)` Êàñ `401 (Expire)` Êó∂ÔºåÂêéÁ´Ø‰ºöÊØ´ÁßíÁ∫ßËß¶Âèë **Ëá™Âä®ÈáçËØï‰∏éÈùôÈªòËΩÆÊç¢**ÔºåÁ°Æ‰øù‰∏öÂä°‰∏ç‰∏≠Êñ≠„ÄÇ

### 4. üîÄ Ê®°ÂûãË∑ØÁî±‰∏≠ÂøÉ (Model Router)
*   **Á≥ªÂàóÂåñÊò†Â∞Ñ**: ÊÇ®ÂèØ‰ª•Â∞ÜÂ§çÊùÇÁöÑÂéüÂßãÊ®°Âûã ID ÂΩíÁ±ªÂà∞‚ÄúËßÑÊ†ºÂÆ∂Êóè‚ÄùÔºàÂ¶ÇÂ∞ÜÊâÄÊúâ GPT-4 ËØ∑Ê±ÇÁªü‰∏ÄË∑ØÁî±Âà∞ `gemini-3-pro-high`Ôºâ„ÄÇ
*   **‰∏ìÂÆ∂Á∫ßÈáçÂÆöÂêë**: ÊîØÊåÅËá™ÂÆö‰πâÊ≠£ÂàôË°®ËææÂºèÁ∫ßÊ®°ÂûãÊò†Â∞ÑÔºåÁ≤æÂáÜÊéßÂà∂ÊØè‰∏Ä‰∏™ËØ∑Ê±ÇÁöÑËêΩÂú∞Ê®°Âûã„ÄÇ
*   **Êô∫ËÉΩÂàÜÁ∫ßË∑ØÁî± (Tiered Routing)**: [Êñ∞] Á≥ªÁªüÊ†πÊçÆË¥¶Âè∑Á±ªÂûãÔºàUltra/Pro/FreeÔºâÂíåÈÖçÈ¢ùÈáçÁΩÆÈ¢ëÁéáËá™Âä®‰ºòÂÖàÁ∫ßÊéíÂ∫èÔºå‰ºòÂÖàÊ∂àËÄóÈ´òÈÄüÈáçÁΩÆË¥¶Âè∑ÔºåÁ°Æ‰øùÈ´òÈ¢ëË∞ÉÁî®‰∏ãÁöÑÊúçÂä°Á®≥ÂÆöÊÄß„ÄÇ
*   **ÂêéÂè∞‰ªªÂä°ÈùôÈªòÈôçÁ∫ß**: [Êñ∞] Ëá™Âä®ËØÜÂà´ Claude CLI Á≠âÂ∑•ÂÖ∑ÁîüÊàêÁöÑÂêéÂè∞ËØ∑Ê±ÇÔºàÂ¶ÇÊ†áÈ¢òÁîüÊàêÔºâÔºåÊô∫ËÉΩÈáçÂÆöÂêëËá≥ Flash Ê®°ÂûãÔºå‰øùÊä§È´òÁ∫ßÊ®°ÂûãÈÖçÈ¢ù‰∏çË¢´Êµ™Ë¥π„ÄÇ

### 5. üé® Â§öÊ®°ÊÄÅ‰∏é Imagen 3 ÊîØÊåÅ
*   **È´òÁ∫ßÁîªË¥®ÊéßÂà∂**: ÊîØÊåÅÈÄöËøá OpenAI `size` (Â¶Ç `1024x1024`, `16:9`) ÂèÇÊï∞Ëá™Âä®Êò†Â∞ÑÂà∞ Imagen 3 ÁöÑÁõ∏Â∫îËßÑÊ†º„ÄÇ
*   **Ë∂ÖÂº∫ Body ÊîØÊåÅ**: ÂêéÁ´ØÊîØÊåÅÈ´òËææ **100MB** (ÂèØÈÖçÁΩÆ) ÁöÑ PayloadÔºåÂ§ÑÁêÜ 4K È´òÊ∏ÖÂõæËØÜÂà´Áª∞Áª∞Êúâ‰Ωô„ÄÇ

## üì∏ ÁïåÈù¢ÂØºËßà (GUI Overview)

| | |
| :---: | :---: |
| ![‰ª™Ë°®Áõò - ÂÖ®Â±ÄÈÖçÈ¢ùÁõëÊéß‰∏é‰∏ÄÈîÆÂàáÊç¢](docs/images/dashboard-light.png) &lt;br&gt; ‰ª™Ë°®Áõò | ![Ë¥¶Âè∑ÂàóË°® - È´òÂØÜÂ∫¶ÈÖçÈ¢ùÂ±ïÁ§∫‰∏é 403 Êô∫ËÉΩÊ†áÊ≥®](docs/images/accounts-light.png) &lt;br&gt; Ë¥¶Âè∑ÂàóË°® |
| ![ÂÖ≥‰∫éÈ°µÈù¢ - ÂÖ≥‰∫é Antigravity Tools](docs/images/about-dark.png) &lt;br&gt; ÂÖ≥‰∫éÈ°µÈù¢ | ![API Âèç‰ª£ - ÊúçÂä°ÊéßÂà∂](docs/images/v3/proxy-settings.png) &lt;br&gt; API Âèç‰ª£ |
| ![Á≥ªÁªüËÆæÁΩÆ - ÈÄöÁî®ÈÖçÁΩÆ](docs/images/settings-dark.png) &lt;br&gt; Á≥ªÁªüËÆæÁΩÆ | |

### üí° ‰ΩøÁî®Ê°à‰æã (Usage Examples)

| | |
| :---: | :---: |
| ![Claude Code ËÅîÁΩëÊêúÁ¥¢ - ÁªìÊûÑÂåñÊù•Ê∫ê‰∏éÂºïÊñáÊòæÁ§∫](docs/images/usage/claude-code-search.png) &lt;br&gt; Claude Code ËÅîÁΩëÊêúÁ¥¢ | ![Cherry Studio Ê∑±Â∫¶ÈõÜÊàê - ÂéüÁîüÂõûÊòæÊêúÁ¥¢ÂºïÊñá‰∏éÊù•Ê∫êÈìæÊé•](docs/images/usage/cherry-studio-citations.png) &lt;br&gt; Cherry Studio Ê∑±Â∫¶ÈõÜÊàê |
| ![Imagen 3 È´òÁ∫ßÁªòÂõæ - ÂÆåÁæéËøòÂéü Prompt ÊÑèÂ¢É‰∏éÁªÜËäÇ](docs/images/usage/image-gen-nebula.png) &lt;br&gt; Imagen 3 È´òÁ∫ßÁªòÂõæ | ![Kilo Code Êé•ÂÖ• - Â§öË¥¶Âè∑ÊûÅÈÄüËΩÆÊç¢‰∏éÊ®°ÂûãÁ©øÈÄè](docs/images/usage/kilo-code-integration.png) &lt;br&gt; Kilo Code Êé•ÂÖ• |

## üèóÔ∏è ÊäÄÊúØÊû∂ÊûÑ (Architecture)

```mermaid
graph TD
    Client([Â§ñÈÉ®Â∫îÁî®: Claude Code/NextChat]) --&gt;|OpenAI/Anthropic| Gateway[Antigravity Axum Server]
    Gateway --&gt; Middleware[‰∏≠Èó¥‰ª∂: Èâ¥ÊùÉ/ÈôêÊµÅ/Êó•Âøó]
    Middleware --&gt; Router[Model Router: ID Êò†Â∞Ñ]
    Router --&gt; Dispatcher[Ë¥¶Âè∑ÂàÜÂèëÂô®: ËΩÆËØ¢/ÊùÉÈáç]
    Dispatcher --&gt; Mapper[ÂçèËÆÆËΩ¨Êç¢Âô®: Request Mapper]
    Mapper --&gt; Upstream[‰∏äÊ∏∏ËØ∑Ê±Ç: Google/Anthropic API]
    Upstream --&gt; ResponseMapper[ÂìçÂ∫îËΩ¨Êç¢Âô®: Response Mapper]
    ResponseMapper --&gt; Client
```

##  ÂÆâË£ÖÊåáÂçó (Installation)

### ÈÄâÈ°π A: ÁªàÁ´ØÂÆâË£Ö (Êé®Ëçê)

#### Ë∑®Âπ≥Âè∞‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨

Ëá™Âä®Ê£ÄÊµãÊìç‰ΩúÁ≥ªÁªü„ÄÅÊû∂ÊûÑÂíåÂåÖÁÆ°ÁêÜÂô®Ôºå‰∏ÄÊù°ÂëΩ‰ª§ÂÆåÊàê‰∏ãËΩΩ‰∏éÂÆâË£Ö„ÄÇ

**Linux / macOS:**
```bash
curl -fsSL https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/v4.1.22/install.sh | bash
```

**Windows (PowerShell):**
```powershell
irm https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/main/install.ps1 | iex
```

&gt; **ÊîØÊåÅÁöÑÊ†ºÂºè**: Linux (`.deb` / `.rpm` / `.AppImage`) | macOS (`.dmg`) | Windows (NSIS `.exe`)
&gt;
&gt; **È´òÁ∫ßÁî®Ê≥ï**: ÂÆâË£ÖÊåáÂÆöÁâàÊú¨ `curl -fsSL ... | bash -s -- --version 4.1.22`ÔºåÈ¢ÑËßàÊ®°Âºè `curl -fsSL ... | bash -s -- --dry-run`

#### macOS - Homebrew
Â¶ÇÊûúÊÇ®Â∑≤ÂÆâË£Ö [Homebrew](https://brew.sh/)Ôºå‰πüÂèØ‰ª•ÈÄöËøá‰ª•‰∏ãÂëΩ‰ª§ÂÆâË£ÖÔºö

```bash
# 1. ËÆ¢ÈòÖÊú¨‰ªìÂ∫ìÁöÑ Tap
brew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager

# 2. ÂÆâË£ÖÂ∫îÁî®
brew install --cask antigravity-tools
```
&gt; **ÊèêÁ§∫**: Â¶ÇÊûúÈÅáÂà∞ÊùÉÈôêÈóÆÈ¢òÔºåÂª∫ËÆÆÊ∑ªÂä† `--no-quarantine` ÂèÇÊï∞„ÄÇ

#### Arch Linux
ÊÇ®ÂèØ‰ª•ÈÄâÊã©ÈÄöËøá‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨Êàñ Homebrew ËøõË°åÂÆâË£ÖÔºö

**ÊñπÂºè 1Ôºö‰∏ÄÈîÆÂÆâË£ÖËÑöÊú¨ (Êé®Ëçê)**
```bash
curl -sSL https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/main/deploy/arch/install.sh | bash
```

**ÊñπÂºè 2ÔºöÈÄöËøá Homebrew** (Â¶ÇÊûúÊÇ®Â∑≤ÂÆâË£Ö [Linuxbrew](https://sh.brew.sh/))
```bash
brew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager
brew install --cask antigravity-tools
```

#### ÂÖ∂‰ªñ Linux ÂèëË°åÁâà
ÂÆâË£ÖÂêé‰ºöËá™Âä®Â∞Ü AppImage Ê∑ªÂä†Âà∞‰∫åËøõÂà∂Ë∑ØÂæÑÂπ∂ÈÖçÁΩÆÂèØÊâßË°åÊùÉÈôê„ÄÇ

### ÈÄâÈ°π B: ÊâãÂä®‰∏ãËΩΩ
ÂâçÂæÄ [GitHub Releases](https://github.com/lbjlaq/Antigravity-Manager/releases) ‰∏ãËΩΩÂØπÂ∫îÁ≥ªÁªüÁöÑÂåÖÔºö
*   **macOS**: `.dmg` (ÊîØÊåÅ Apple Silicon &amp; Intel)
*   **Windows**: `.msi` Êàñ ‰æøÊê∫Áâà `.zip`
*   **Linux**: `.deb` Êàñ `AppImage`

### ÈÄâÈ°π C: Docker ÈÉ®ÁΩ≤ (Êé®ËçêÁî®‰∫é NAS/ÊúçÂä°Âô®)
Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®ÂÆπÂô®ÂåñÁéØÂ¢É‰∏≠ËøêË°åÔºåÊàë‰ª¨Êèê‰æõ‰∫ÜÂéüÁîüÁöÑ Docker ÈïúÂÉè„ÄÇËØ•ÈïúÂÉèÂÜÖÁΩÆ‰∫ÜÂØπ v4.0.2 ÂéüÁîü Headless Êû∂ÊûÑÁöÑÊîØÊåÅÔºåÂèØËá™Âä®ÊâòÁÆ°ÂâçÁ´ØÈùôÊÄÅËµÑÊ∫êÔºåÂπ∂ÈÄöËøáÊµèËßàÂô®Áõ¥Êé•ËøõË°åÁÆ°ÁêÜ„ÄÇ

```bash
# ÊñπÂºè 1: Áõ¥Êé•ËøêË°å (Êé®Ëçê)
# - API_KEY: ÂøÖÂ°´„ÄÇÁî®‰∫éÊâÄÊúâÂçèËÆÆÁöÑ AI ËØ∑Ê±ÇÈâ¥ÂÆö„ÄÇ
# - WEB_PASSWORD: ÂèØÈÄâ„ÄÇÁî®‰∫éÁÆ°ÁêÜÂêéÂè∞ÁôªÂΩï„ÄÇËã•‰∏çËÆæÁΩÆÂàôÈªòËÆ§‰ΩøÁî® API_KEY„ÄÇ
docker run -d --name antigravity-manager \
  -p 8045:8045 \
  -e API_KEY=sk-your-api-key \
  -e WEB_PASSWORD=your-login-password \
  -e ABV_MAX_BODY_SIZE=104857600 \
  -v ~/.antigravity_tools:/root/.antigravity_tools \
  lbjlaq/antigravity-manager:latest

# ÂøòËÆ∞ÂØÜÈí•ÔºüÊâßË°å docker logs antigravity-manager Êàñ grep -E &#039;&quot;api_key&quot;|&quot;admin_password&quot;&#039; ~/.antigravity_tools/gui_config.json

#### üîê Èâ¥ÊùÉÈÄªËæëËØ¥Êòé
*   **Âú∫ÊôØ AÔºö‰ªÖËÆæÁΩÆ‰∫Ü `API_KEY`**
    - **Web ÁôªÂΩï**Ôºö‰ΩøÁî® `API_KEY` ËøõÂÖ•ÂêéÂè∞„ÄÇ
    - **API Ë∞ÉÁî®**Ôºö‰ΩøÁî® `API_KEY` ËøõË°å AI ËØ∑Ê±ÇÈâ¥ÊùÉ„ÄÇ
*   **Âú∫ÊôØ BÔºöÂêåÊó∂ËÆæÁΩÆ‰∫Ü `API_KEY` Âíå `WEB_PASSWORD` (Êé®Ëçê)**
    - **Web ÁôªÂΩï**Ôºö**ÂøÖÈ°ª**‰ΩøÁî® `WEB_PASSWORD`Ôºå‰ΩøÁî® API Key Â∞ÜË¢´ÊãíÁªùÔºàÊõ¥ÂÆâÂÖ®Ôºâ„ÄÇ
    - **API Ë∞ÉÁî®**ÔºöÁªü‰∏Ä‰ΩøÁî® `API_KEY`„ÄÇËøôÊ†∑ÊÇ®ÂèØ‰ª•Â∞Ü API Key ÂàÜÂèëÁªôÊàêÂëòÔºåËÄå‰øùÁïôÂØÜÁ†Å‰ªÖ‰æõÁÆ°ÁêÜÂëò‰ΩøÁî®„ÄÇ

#### üÜô ÊóßÁâàÊú¨ÂçáÁ∫ßÊåáÂºï
Â¶ÇÊûúÊÇ®ÊòØ‰ªé v4.0.1 ÂèäÊõ¥Êó©ÁâàÊú¨ÂçáÁ∫ßÔºåÁ≥ªÁªüÈªòËÆ§Êú™ËÆæÁΩÆ `WEB_PASSWORD`„ÄÇÊÇ®ÂèØ‰ª•ÈÄöËøá‰ª•‰∏ã‰ªª‰∏ÄÊñπÂºèËÆæÁΩÆÔºö
1.  **Web UI ÁïåÈù¢ (Êé®Ëçê)**Ôºö‰ΩøÁî®ÂéüÊúâ `API_KEY` ÁôªÂΩïÂêéÔºåÂú® **API Âèç‰ª£ËÆæÁΩÆ** È°µÈù¢ÊâãÂä®ËÆæÁΩÆÂπ∂‰øùÂ≠ò„ÄÇÊñ∞ÂØÜÁ†ÅÂ∞ÜÊåÅ‰πÖÂåñÂ≠òÂÇ®Âú® `gui_config.json` ‰∏≠„ÄÇ
2.  **ÁéØÂ¢ÉÂèòÈáè (Docker)**ÔºöÂú®ÂêØÂä®ÂÆπÂô®Êó∂Â¢ûÂä† `-e WEB_PASSWORD=ÊÇ®ÁöÑÊñ∞ÂØÜÁ†Å`„ÄÇ**Ê≥®ÊÑèÔºöÁéØÂ¢ÉÂèòÈáèÂÖ∑ÊúâÊúÄÈ´ò‰ºòÂÖàÁ∫ßÔºåÂ∞ÜË¶ÜÁõñ UI ‰∏≠ÁöÑ‰ªª‰Ωï‰øÆÊîπ„ÄÇ**
3.  **ÈÖçÁΩÆÊñá‰ª∂ (ÊåÅ‰πÖÂåñ)**ÔºöÁõ¥Êé•‰øÆÊîπ `~/.antigravity_tools/gui_config.json`ÔºåÂú® `proxy` ÂØπË±°‰∏≠‰øÆÊîπÊàñÊ∑ªÂä† `&quot;admin_password&quot;: &quot;ÊÇ®ÁöÑÊñ∞ÂØÜÁ†Å&quot;` Â≠óÊÆµ„ÄÇ
    - *Ê≥®Ôºö`WEB_PASSWORD` ÊòØÁéØÂ¢ÉÂèòÈáèÂêçÔºå`admin_password` ÊòØÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑ JSON ÈîÆÂêç„ÄÇ*

&gt; [!TIP]
&gt; **ÂØÜÁ†Å‰ºòÂÖàÁ∫ßÈÄªËæë (Priority)**:
&gt; - **Á¨¨‰∏Ä‰ºòÂÖàÁ∫ß (ÁéØÂ¢ÉÂèòÈáè)**: `ABV_WEB_PASSWORD` Êàñ `WEB_PASSWORD`„ÄÇÂè™Ë¶ÅËÆæÁΩÆ‰∫ÜÁéØÂ¢ÉÂèòÈáèÔºåÁ≥ªÁªüÂ∞ÜÂßãÁªà‰ΩøÁî®ÂÆÉ„ÄÇ
&gt; - **Á¨¨‰∫å‰ºòÂÖàÁ∫ß (ÈÖçÁΩÆÊñá‰ª∂)**: `gui_config.json` ‰∏≠ÁöÑ `admin_password` Â≠óÊÆµ„ÄÇUI ÁöÑ‚Äú‰øùÂ≠ò‚ÄùÊìç‰Ωú‰ºöÊõ¥Êñ∞Ê≠§ÂÄº„ÄÇ
&gt; - **‰øùÂ∫ïÂõûÈÄÄ (ÂêëÂêéÂÖºÂÆπ)**: Ëã•‰∏äËø∞ÂùáÊú™ËÆæÁΩÆÔºåÂàôÂõûÈÄÄ‰ΩøÁî® `API_KEY` ‰Ωú‰∏∫ÁôªÂΩïÂØÜÁ†Å„ÄÇ

# ÊñπÂºè 2: ‰ΩøÁî® Docker Compose
# 1. ËøõÂÖ•È°πÁõÆÁöÑ docker ÁõÆÂΩï
cd docker
# 2. ÂêØÂä®ÊúçÂä°
docker compose up -d
```
&gt; **ËÆøÈóÆÂú∞ÂùÄ**: `http://localhost:8045` (ÁÆ°ÁêÜÂêéÂè∞) | `http://localhost:8045/v1` (API Base)
&gt; **Á≥ªÁªüË¶ÅÊ±Ç**:
&gt; - **ÂÜÖÂ≠ò**: Âª∫ËÆÆ **1GB** (ÊúÄÂ∞è 256MB)„ÄÇ
&gt; - **ÊåÅ‰πÖÂåñ**: ÈúÄÊåÇËΩΩ `/root/.antigravity_tools` ‰ª•‰øùÂ≠òÊï∞ÊçÆ„ÄÇ
&gt; - **Êû∂ÊûÑ**: ÊîØÊåÅ x86_64 Âíå ARM64„ÄÇ
&gt; **ËØ¶ÊÉÖËßÅ**: [Docker ÈÉ®ÁΩ≤ÊåáÂçó (docker)](./docker/README.md)

---

Copyright ¬© 2024-2026 [lbjlaq](https://github.com/lbjlaq)

### üõ†Ô∏è Â∏∏ËßÅÈóÆÈ¢òÊéíÊü• (Troubleshooting)

#### macOS ÊèêÁ§∫‚ÄúÂ∫îÁî®Â∑≤ÊçüÂùèÔºåÊó†Ê≥ïÊâìÂºÄ‚ÄùÔºü
Áî±‰∫é macOS ÁöÑÂÆâÂÖ®Êú∫Âà∂ÔºåÈùû App Store ‰∏ãËΩΩÁöÑÂ∫îÁî®ÂèØËÉΩ‰ºöËß¶ÂèëÊ≠§ÊèêÁ§∫„ÄÇÊÇ®ÂèØ‰ª•ÊåâÁÖß‰ª•‰∏ãÊ≠•È™§Âø´ÈÄü‰øÆÂ§çÔºö

1.  **ÂëΩ‰ª§Ë°å‰øÆÂ§ç** (Êé®Ëçê):
    ÊâìÂºÄÁªàÁ´ØÔºåÊâßË°å‰ª•‰∏ãÂëΩ‰ª§Ôºö
    ```bash
    sudo xattr -rd com.apple.quarantine &quot;/Applications/Antigravity Tools.app&quot;
    ```
2.  **Homebrew ÂÆâË£ÖÊäÄÂ∑ß**:
    Â¶ÇÊûúÊÇ®‰ΩøÁî® brew ÂÆâË£ÖÔºåÂèØ‰ª•Ê∑ªÂä† `--no-quarantine` ÂèÇÊï∞Êù•ËßÑÈÅøÊ≠§ÈóÆÈ¢òÔºö
    ```bash
    brew install --cask --no-quarantine antigravity-tools
    ```

## üîå Âø´ÈÄüÊé•ÂÖ•Á§∫‰æã

### üîê OAuth ÊéàÊùÉÊµÅÁ®ãÔºàÊ∑ªÂä†Ë¥¶Âè∑Ôºâ
1. ÊâìÂºÄ‚ÄúAccounts / Ë¥¶Âè∑‚Äù ‚Üí ‚ÄúÊ∑ªÂä†Ë¥¶Âè∑‚Äù ‚Üí ‚ÄúOAuth‚Äù„ÄÇ
2. ÂºπÁ™ó‰ºöÂú®ÁÇπÂáªÊåâÈíÆÂâçÈ¢ÑÁîüÊàêÊéàÊùÉÈìæÊé•ÔºõÁÇπÂáªÈìæÊé•Âç≥ÂèØÂ§çÂà∂Âà∞Á≥ªÁªüÂâ™Ë¥¥ÊùøÔºåÁÑ∂ÂêéÁî®‰Ω†Â∏åÊúõÁöÑÊµèËßàÂô®ÊâìÂºÄÂπ∂ÂÆåÊàêÊéàÊùÉ„ÄÇ
3. ÊéàÊùÉÂÆåÊàêÂêéÊµèËßàÂô®‰ºöÊâìÂºÄÊú¨Âú∞ÂõûË∞ÉÈ°µÂπ∂ÊòæÁ§∫‚Äú‚úÖ ÊéàÊùÉÊàêÂäü!‚Äù„ÄÇ
4. Â∫îÁî®‰ºöËá™Âä®ÁªßÁª≠ÂÆåÊàêÊéàÊùÉÂπ∂‰øùÂ≠òË¥¶Âè∑ÔºõÂ¶ÇÊú™Ëá™Âä®ÂÆåÊàêÔºåÂèØÁÇπÂáª‚ÄúÊàëÂ∑≤ÊéàÊùÉÔºåÁªßÁª≠‚ÄùÊâãÂä®ÂÆåÊàê„ÄÇ

&gt; ÊèêÁ§∫ÔºöÊéàÊùÉÈìæÊé•ÂåÖÂê´‰∏ÄÊ¨°ÊÄßÂõûË∞ÉÁ´ØÂè£ÔºåËØ∑ÂßãÁªà‰ΩøÁî®ÂºπÁ™óÈáåÁîüÊàêÁöÑÊúÄÊñ∞ÈìæÊé•ÔºõÂ¶ÇÊûúÊéàÊùÉÊó∂Â∫îÁî®Êú™ËøêË°åÊàñÂºπÁ™óÂ∑≤ÂÖ≥Èó≠ÔºåÊµèËßàÂô®ÂèØËÉΩ‰ºöÊèêÁ§∫ `localhost refused connection`„ÄÇ

### Â¶Ç‰ΩïÊé•ÂÖ• Claude Code CLI?
1.  ÂêØÂä® AntigravityÔºåÂπ∂Âú®‚ÄúAPI Âèç‰ª£‚ÄùÈ°µÈù¢ÂºÄÂêØÊúçÂä°„ÄÇ
2.  Âú®ÁªàÁ´ØÊâßË°åÔºö
```bash
export ANTHROPIC_API_KEY=&quot;sk-antigravity&quot;
export ANTHROPIC_BASE_URL=&quot;http://127.0.0.1:8045&quot;
claude
```

### Â¶Ç‰ΩïÊé•ÂÖ• OpenCode?
1.  ËøõÂÖ• **API Âèç‰ª£**È°µÈù¢ ‚Üí **Â§ñÈÉ® Providers** ‚Üí ÁÇπÂáª **OpenCode Sync** Âç°Áâá„ÄÇ
2.  ÁÇπÂáª **Sync** ÊåâÈíÆÔºåÂ∞ÜËá™Âä®ÁîüÊàê `~/.config/opencode/opencode.json` ÈÖçÁΩÆÊñá‰ª∂Ôºö
    - ÂàõÂª∫Áã¨Á´ã provider `antigravity-manager`Ôºà‰∏çË¶ÜÁõñ google/anthropic ÂéüÁîüÈÖçÁΩÆÔºâ
    - ÂèØÈÄâÔºöÂãæÈÄâ **Sync accounts** ÂØºÂá∫ `antigravity-accounts.json`Ôºàplugin-compatible v3 Ê†ºÂºèÔºâÔºå‰æõ OpenCode Êèí‰ª∂Áõ¥Êé•ÂØºÂÖ•
3.  ÁÇπÂáª **Clear Config** ÂèØ‰∏ÄÈîÆÊ∏ÖÈô§ Manager ÈÖçÁΩÆÂπ∂Ê∏ÖÁêÜ legacy ÊÆãÁïôÔºõÁÇπÂáª **Restore** ÂèØ‰ªéÂ§á‰ªΩÊÅ¢Â§ç„ÄÇ
4.  Windows Áî®Êà∑Ë∑ØÂæÑ‰∏∫ `C:\Users\&lt;Áî®Êà∑Âêç&gt;\.config\opencode\`Ôºà‰∏é `~/.config/opencode` ËßÑÂàô‰∏ÄËá¥Ôºâ„ÄÇ

**Âø´ÈÄüÈ™åËØÅÂëΩ‰ª§Ôºö**
```bash
# ÊµãËØï antigravity-manager providerÔºàÊîØÊåÅ --variantÔºâ
opencode run &quot;test&quot; --model antigravity-manager/claude-sonnet-4-5-thinking --variant high

# Ëã•Â∑≤ÂÆâË£Ö opencode-antigravity-auth Êèí‰ª∂ÔºåÈ™åËØÅ google provider ‰ªçÂèØÁã¨Á´ãÂ∑•‰Ωú
opencode run &quot;test&quot; --model google/antigravity-claude-sonnet-4-5-thinking --variant max
```

### Â¶Ç‰ΩïÊé•ÂÖ• Kilo Code?
1.  **ÂçèËÆÆÈÄâÊã©**: Âª∫ËÆÆ‰ºòÂÖà‰ΩøÁî® **Gemini ÂçèËÆÆ**„ÄÇ
2.  **Base URL**: Â°´ÂÜô `http://127.0.0.1:8045`„ÄÇ
3.  **Ê≥®ÊÑè**: 
    - **OpenAI ÂçèËÆÆÈôêÂà∂**: Kilo Code Âú®‰ΩøÁî® OpenAI Ê®°ÂºèÊó∂ÔºåÂÖ∂ËØ∑Ê±ÇË∑ØÂæÑ‰ºöÂè†Âä†‰∫ßÁîü `/v1/chat/completions/responses` ËøôÁßçÈùûÊ†áÂáÜË∑ØÂæÑÔºåÂØºËá¥ Antigravity ËøîÂõû 404„ÄÇÂõ†Ê≠§ËØ∑Âä°ÂøÖÂ°´ÂÖ• Base URL ÂêéÈÄâÊã© Gemini Ê®°Âºè„ÄÇ
    - **Ê®°ÂûãÊò†Â∞Ñ**: Kilo Code ‰∏≠ÁöÑÊ®°ÂûãÂêçÁß∞ÂèØËÉΩ‰∏é Antigravity ÈªòËÆ§ËÆæÁΩÆ‰∏ç‰∏ÄËá¥ÔºåÂ¶ÇÈÅáÂà∞Êó†Ê≥ïËøûÊé•ÔºåËØ∑Âú®‚ÄúÊ®°ÂûãÊò†Â∞Ñ‚ÄùÈ°µÈù¢ËÆæÁΩÆËá™ÂÆö‰πâÊò†Â∞ÑÔºåÂπ∂Êü•Áúã**Êó•ÂøóÊñá‰ª∂**ËøõË°åË∞ÉËØï„ÄÇ

### Â¶Ç‰ΩïÂú® Python ‰∏≠‰ΩøÁî®?
```python
import openai

client = openai.OpenAI(
    api_key=&quot;sk-antigravity&quot;,
    base_url=&quot;http://127.0.0.1:8045/v1&quot;
)

response = client.chat.completions.create(
    model=&quot;gemini-3-flash&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰Ω†Â•ΩÔºåËØ∑Ëá™Êàë‰ªãÁªç&quot;}]
)
print(response.choices[0].message.content)
```

### Â¶Ç‰Ωï‰ΩøÁî®ÂõæÁâáÁîüÊàê (Imagen 3)?

#### ÊñπÂºè‰∏ÄÔºöOpenAI Images API (Êé®Ëçê)
```python
import openai

client = openai.OpenAI(
    api_key=&quot;sk-antigravity&quot;,
    base_url=&quot;http://127.0.0.1:8045/v1&quot;
)

# ÁîüÊàêÂõæÁâá
response = client.images.generate(
    model=&quot;gemini-3-pro-image&quot;,
    prompt=&quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏ÇÔºåËµõÂçöÊúãÂÖãÔºåÈúìËôπÁÅØ&quot;,
    size=&quot;1920x1080&quot;,      # ÊîØÊåÅ‰ªªÊÑè WIDTHxHEIGHT Ê†ºÂºèÔºåËá™Âä®ËÆ°ÁÆóÂÆΩÈ´òÊØî
    quality=&quot;hd&quot;,          # &quot;standard&quot; | &quot;hd&quot; | &quot;medium&quot;
    n=1,
    response_format=&quot;b64_json&quot;
)

# ‰øùÂ≠òÂõæÁâá
import base64
image_data = base64.b64decode(response.data[0].b64_json)
with open(&quot;output.png&quot;, &quot;wb&quot;) as f:
    f.write(image_data)
```

**ÊîØÊåÅÁöÑÂèÇÊï∞**Ôºö
- **`size`**: ‰ªªÊÑè `WIDTHxHEIGHT` Ê†ºÂºèÔºàÂ¶Ç `1280x720`, `1024x1024`, `1920x1080`ÔºâÔºåËá™Âä®ËÆ°ÁÆóÂπ∂Êò†Â∞ÑÂà∞Ê†áÂáÜÂÆΩÈ´òÊØîÔºà21:9, 16:9, 9:16, 4:3, 3:4, 1:1Ôºâ
- **`quality`**: 
  - `&quot;hd&quot;` ‚Üí 4K ÂàÜËæ®ÁéáÔºàÈ´òË¥®ÈáèÔºâ
  - `&quot;medium&quot;` ‚Üí 2K ÂàÜËæ®ÁéáÔºà‰∏≠Á≠âË¥®ÈáèÔºâ
  - `&quot;standard&quot;` ‚Üí ÈªòËÆ§ÂàÜËæ®ÁéáÔºàÊ†áÂáÜË¥®ÈáèÔºâ
- **`n`**: ÁîüÊàêÂõæÁâáÊï∞ÈáèÔºà1-10Ôºâ
- **`response_format`**: `&quot;b64_json&quot;` Êàñ `&quot;url&quot;`ÔºàData URIÔºâ

#### ÊñπÂºè‰∫åÔºöChat API + ÂèÇÊï∞ËÆæÁΩÆ (‚ú® Êñ∞Â¢û)

**ÊâÄÊúâÂçèËÆÆ**ÔºàOpenAI„ÄÅClaudeÔºâÁöÑ Chat API Áé∞Âú®ÈÉΩÊîØÊåÅÁõ¥Êé•‰º†ÈÄí `size` Âíå `quality` ÂèÇÊï∞Ôºö

```python
# OpenAI Chat API
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image&quot;,
    size=&quot;1920x1080&quot;,      # ‚úÖ ÊîØÊåÅ‰ªªÊÑè WIDTHxHEIGHT Ê†ºÂºè
    quality=&quot;hd&quot;,          # ‚úÖ &quot;standard&quot; | &quot;hd&quot; | &quot;medium&quot;
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏Ç&quot;}]
)
```

```bash
# Claude Messages API
curl -X POST http://127.0.0.1:8045/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-antigravity&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gemini-3-pro-image&quot;,
    &quot;size&quot;: &quot;1280x720&quot;,
    &quot;quality&quot;: &quot;hd&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂè™ÂèØÁà±ÁöÑÁå´Âí™&quot;}]
  }&#039;
```

```

**ÂèÇÊï∞‰ºòÂÖàÁ∫ß**: `imageSize` ÂèÇÊï∞ &gt; `quality` ÂèÇÊï∞ &gt; Ê®°ÂûãÂêéÁºÄ

**‚ú® Êñ∞Â¢û `imageSize` ÂèÇÊï∞ÊîØÊåÅ**:

Èô§‰∫Ü `quality` ÂèÇÊï∞Â§ñ,Áé∞Âú®ËøòÊîØÊåÅÁõ¥Êé•‰ΩøÁî® Gemini ÂéüÁîüÁöÑ `imageSize` ÂèÇÊï∞:

```python
# ‰ΩøÁî® imageSize ÂèÇÊï∞(ÊúÄÈ´ò‰ºòÂÖàÁ∫ß)
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image&quot;,
    size=&quot;16:9&quot;,           # ÂÆΩÈ´òÊØî
    imageSize=&quot;4K&quot;,        # ‚ú® Áõ¥Êé•ÊåáÂÆöÂàÜËæ®Áéá: &quot;1K&quot; | &quot;2K&quot; | &quot;4K&quot;
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏Ç&quot;}]
)
```

```bash
# Claude Messages API ‰πüÊîØÊåÅ imageSize
curl -X POST http://127.0.0.1:8045/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-antigravity&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gemini-3-pro-image&quot;,
    &quot;size&quot;: &quot;1280x720&quot;,
    &quot;imageSize&quot;: &quot;4K&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂè™ÂèØÁà±ÁöÑÁå´Âí™&quot;}]
  }&#039;
```

**ÂèÇÊï∞ËØ¥Êòé**:
- **`imageSize`**: Áõ¥Êé•ÊåáÂÆöÂàÜËæ®Áéá (`&quot;1K&quot;` / `&quot;2K&quot;` / `&quot;4K&quot;`)
- **`quality`**: ÈÄöËøáË¥®ÈáèÁ≠âÁ∫ßÊé®Êñ≠ÂàÜËæ®Áéá (`&quot;standard&quot;` ‚Üí 1K, `&quot;medium&quot;` ‚Üí 2K, `&quot;hd&quot;` ‚Üí 4K)
- **‰ºòÂÖàÁ∫ß**: Â¶ÇÊûúÂêåÊó∂ÊåáÂÆö `imageSize` Âíå `quality`,Á≥ªÁªü‰ºö‰ºòÂÖà‰ΩøÁî® `imageSize`


#### ÊñπÂºè‰∏âÔºöChat Êé•Âè£ + Ê®°ÂûãÂêéÁºÄ
```python
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image-16-9-4k&quot;,  # Ê†ºÂºèÔºögemini-3-pro-image-[ÊØî‰æã]-[Ë¥®Èáè]
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰∏ÄÂ∫ßÊú™Êù•‰∏ª‰πâÈ£éÊ†ºÁöÑÂüéÂ∏Ç&quot;}]
)
```

**Ê®°ÂûãÂêéÁºÄËØ¥Êòé**Ôºö
- **ÂÆΩÈ´òÊØî**: `-16-9`, `-9-16`, `-4-3`, `-3-4`, `-21-9`, `-1-1`
- **Ë¥®Èáè**: `-4k` (4K), `-2k` (2K), ‰∏çÂä†ÂêéÁºÄÔºàÊ†áÂáÜÔºâ
- **Á§∫‰æã**: `gemini-3-pro-image-16-9-4k` ‚Üí 16:9 ÊØî‰æã + 4K ÂàÜËæ®Áéá

#### ÊñπÂºèÂõõÔºöCherry Studio Á≠âÂÆ¢Êà∑Á´ØËÆæÁΩÆ
Âú®ÊîØÊåÅ OpenAI ÂçèËÆÆÁöÑÂÆ¢Êà∑Á´ØÔºàÂ¶Ç Cherry StudioÔºâ‰∏≠ÔºåÂèØ‰ª•ÈÄöËøá**Ê®°ÂûãËÆæÁΩÆ**È°µÈù¢ÈÖçÁΩÆÂõæÁâáÁîüÊàêÂèÇÊï∞Ôºö

1. **ËøõÂÖ•Ê®°ÂûãËÆæÁΩÆ**ÔºöÈÄâÊã© `gemini-3-pro-image` Ê®°Âûã
2. **ÈÖçÁΩÆÂèÇÊï∞**Ôºö
   - **Size (Â∞∫ÂØ∏)**: ËæìÂÖ•‰ªªÊÑè `WIDTHxHEIGHT` Ê†ºÂºèÔºàÂ¶Ç `1920x1080`, `1024x1024`Ôºâ
   - **Quality (Ë¥®Èáè)**: ÈÄâÊã© `standard` / `hd` / `medium`
   - **Number (Êï∞Èáè)**: ËÆæÁΩÆÁîüÊàêÂõæÁâáÊï∞ÈáèÔºà1-10Ôºâ
3. **ÂèëÈÄÅËØ∑Ê±Ç**ÔºöÁõ¥Êé•Âú®ÂØπËØùÊ°Ü‰∏≠ËæìÂÖ•ÂõæÁâáÊèèËø∞Âç≥ÂèØ

**ÂèÇÊï∞Êò†Â∞ÑËßÑÂàô**Ôºö
- `size: &quot;1920x1080&quot;` ‚Üí Ëá™Âä®ËÆ°ÁÆó‰∏∫ `16:9` ÂÆΩÈ´òÊØî
- `quality: &quot;hd&quot;` ‚Üí Êò†Â∞Ñ‰∏∫ `4K` ÂàÜËæ®Áéá
- `quality: &quot;medium&quot;` ‚Üí Êò†Â∞Ñ‰∏∫ `2K` ÂàÜËæ®Áéá


## üìù ÂºÄÂèëËÄÖ‰∏éÁ§æÂå∫

*   **ÁâàÊú¨ÊºîËøõ (Changelog)**:
    *   **v4.1.22 (2026-02-21)**:
        -   **[ÈáçË¶ÅÊèêÈÜí] 2api È£éÊéßÈ£éÈô©ÊèêÁ§∫**:
            -   Áî±‰∫éËøëÊúüÁöÑË∞∑Ê≠åÈ£éÊéßÂéüÂõ†Ôºå‰ΩøÁî® 2api ÂäüËÉΩ‰ºöÂØºËá¥Ë¥¶Âè∑Ë¢´È£éÊéßÁöÑÊ¶ÇÁéáÊòæËëóÂ¢ûÂä†„ÄÇ
            -   **Âº∫ÁÉàÂª∫ËÆÆ**: ‰∏∫‰∫ÜÁ°Æ‰øùÊÇ®ÁöÑË¥¶Âè∑ÂÆâÂÖ®‰∏éË∞ÉÁî®Á®≥ÂÆöÊÄßÔºåÂª∫ËÆÆÂáèÂ∞ëÊàñÂÅúÊ≠¢‰ΩøÁî® 2api ÂäüËÉΩ„ÄÇÁõÆÂâçÊõ¥ÂéüÁîü„ÄÅÊõ¥Á®≥ÂÆöÁöÑ **gRPC (`application/grpc`)** Êàñ **gRPC-Web (`application/grpc-web`)** ÂçèËÆÆ‰ª£ÁêÜÊîØÊåÅ‰ªçÂú®ÁßØÊûÅÊµãËØï‰∏≠ÔºåÂ¶ÇÊûúÊÇ®ÊúâÁõ∏ÂÖ≥ÁöÑÊµãËØïÁªèÈ™åÊàñÊÉ≥Ê≥ïÔºåÈùûÂ∏∏Ê¨¢ËøéËÅîÁ≥ªËÆ®ËÆ∫Ôºå‰πüÊ¨¢ËøéÊÇ®Âª∫Á´ãÊñ∞ÂàÜÊîØ‰∏ÄËµ∑Êé¢Á¥¢ÔºÅ
            -   &lt;details&gt;&lt;summary&gt;üì∏ ÁÇπÂáªÊü•Áúã gRPC ÂÆûÊó∂ËΩ¨Êç¢ OpenAI ËßÑËåÉÊµãËØïÊºîÁ§∫&lt;/summary&gt;&lt;img src=&quot;docs/images/usage/grpc-test.png&quot; alt=&quot;gRPC Test&quot; width=&quot;600&quot;&gt;&lt;/details&gt;
        -   **[Ê†∏ÂøÉ‰ºòÂåñ] Claude Sonnet 4.5 ËøÅÁßªËá≥ 4.6 (PR #2014)**:
            -   **Ê®°ÂûãÂçáÁ∫ß**: ÂºïÂÖ• `claude-sonnet-4-6` Âèä `claude-sonnet-4-6-thinking` ‰Ωú‰∏∫‰∏ªÊé®Ê®°Âûã„ÄÇ
            -   **Âπ≥ÊªëËøáÊ∏°**: Ëá™Âä®Â∞Ü legacy Ê®°Âûã `claude-sonnet-4-5` ÈáçÂÆöÂêëËá≥ `4.6`„ÄÇ
            -   **ÂÖ®Â±ÄÈÄÇÈÖç**: Êõ¥Êñ∞‰∫ÜÂÖ®ÈÉ® 12 ÁßçËØ≠Ë®ÄÁöÑÊú¨Âú∞ÂåñÊñá‰ª∂„ÄÅUI Ê†áÁ≠æÔºàSonnet 4.6, Sonnet 4.6 TK, Opus 4.6 TKÔºâ‰ª•ÂèäÈ¢ÑËÆæË∑ØÁî±„ÄÇ
        -   **[Ê†∏ÂøÉ‰ºòÂåñ] Gemini Pro Ê®°ÂûãÂêçÁß∞ËøÅÁßª (PR #2063)**: Â∞Ü `gemini-pro-high/low` ËøÅÁßªËá≥ `gemini-3.1-pro`ÔºåÁ°Æ‰øù‰∏é Google ÊúÄÊñ∞ API ÂëΩÂêçÂØπÈΩê„ÄÇ
        -   **[ÈáçÂ§ßÊû∂ÊûÑ] ÂõΩÈôÖÂåñ (i18n) ‰∏éÁªìÊûÑÂåñÊ®°ÂûãÈÖçÁΩÆÈõÜÊàê (PR #2040)**:
            -   **Êû∂ÊûÑÈáçÊûÑ**: ÂºïÂÖ•‰∫ÜÂÖ®Êñ∞ÁöÑ i18n ÁøªËØëÊ°ÜÊû∂ÔºåÂ∞ÜÁ°¨ÁºñÁ†ÅÁöÑÊ®°ÂûãÂ±ïÁ§∫ÈÄªËæëËß£ËÄ¶Ëá≥ÁªìÊûÑÂåñ `MODEL_CONFIG`„ÄÇ
            -   **ÈÄªËæëÈÄÇÈÖç**: Âú®Ë¥¶Âè∑Ë°®Ê†º„ÄÅËØ¶ÊÉÖÂºπÁ™óÂíåËÆæÁΩÆÈ°µÈù¢‰∏≠ÈõÜÊàê‰∫ÜÂü∫‰∫é i18n Ê†áÁ≠æÁöÑÂä®ÊÄÅÂéªÈáçÊú∫Âà∂Ôºå‰øÆÂ§ç‰∫Ü Gemini 3.1 Pro È¢ùÂ∫¶ÈáçÂ§çÊòæÁ§∫ÁöÑ UI ÈóÆÈ¢ò„ÄÇ
            -   **Â§öËØ≠Ë®ÄÊèêÂçá**: ‰ºòÂåñÂπ∂‰øÆÊ≠£‰∫ÜÊâÄÊúâ 12 ÁßçËØ≠Ë®ÄÁöÑÁâàÊú¨ÊèèËø∞ÔºåÂ∞Ü `Claude 4.5` ÊèèËø∞ÂÖ®Èù¢ÂçáÁ∫ß‰∏∫Ê≠£ÂºèÁâà `4.6`ÔºåÂπ∂Â∞Ü `G3` ÊèèËø∞Áªü‰∏Ä‰∏∫ `G3.1`„ÄÇ
            -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Claude Opus 4.6 ÊÄùËÄÉÊ®°Âºè 400 Êä•Èîô (Claude ÂçèËÆÆ)**:
            -   **ÂèÇÊï∞‰∏ìÈ°πÂØπÈΩê**: ‰øÆÂ§ç‰∫Ü `claude-opus-4-6-thinking` Âú® Claude ÂçèËÆÆ‰∏ãËøîÂõû `400 INVALID_ARGUMENT` ÁöÑÈóÆÈ¢ò„ÄÇÈÄöËøáÂº∫Âà∂ÂØπÈΩê `thinkingBudget` (24576) ‰∏é `maxOutputTokens` (57344)ÔºåÂπ∂ÂâîÈô§Âú®ËØ•Ê®°Âºè‰∏ã‰∏çÂÖºÂÆπÁöÑ `stopSequences`ÔºåÁ°Æ‰øùÂÖ∂ËØ∑Ê±ÇÂèÇÊï∞‰∏é 100% ÊàêÂäüÁöÑ OpenAI ÂçèËÆÆÂÆåÂÖ®‰∏ÄËá¥ÔºåÊèêÂçá‰∫ÜÂØπ Claude ÂéüÁîüÂçèËÆÆÂÆ¢Êà∑Á´ØÁöÑÂÖºÂÆπÊÄß„ÄÇ
    *   **v4.1.21 (2026-02-17)**:
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Cherry Studio / Claude ÂçèËÆÆÂÖºÂÆπÊÄß (Fix Issue #2007)**:
            -   **maxOutputTokens ÈôêÂà∂**: ‰øÆÂ§ç‰∫Ü Cherry Studio Á≠âÂÆ¢Êà∑Á´ØÂèëÈÄÅË∂ÖÂ§ß `maxOutputTokens` (128k) ÂØºËá¥ Google API ËøîÂõû `400 INVALID_ARGUMENT` ÁöÑÈóÆÈ¢ò„ÄÇÁé∞Âú®Ëá™Âä®Â∞Ü Claude ÂçèËÆÆÁöÑËæìÂá∫‰∏äÈôêÈôêÂà∂‰∏∫ **65536**ÔºåÁ°Æ‰øùËØ∑Ê±ÇÂßãÁªàÂú® Gemini ÂÖÅËÆ∏ÁöÑËåÉÂõ¥ÂÜÖ„ÄÇ
            -   **Adaptive ÊÄùËÄÉÊ®°ÂºèÂØπÈΩê**: ÈíàÂØπ Gemini Ê®°Âûã‰ºòÂåñ‰∫Ü Claude ÂçèËÆÆÁöÑ `thinking: { type: &quot;adaptive&quot; }` Ë°å‰∏∫„ÄÇÁé∞Âú®Ëá™Âä®Êò†Â∞Ñ‰∏∫ **24576** ÁöÑÂõ∫ÂÆöÊÄùËÄÉÈ¢ÑÁÆó (‰∏é OpenAI ÂçèËÆÆ‰∏ÄËá¥)ÔºåËß£ÂÜ≥‰∫Ü Gemini Vertex AI ÂØπ `thinkingBudget: -1` ÁöÑ‰∏çÂÖºÂÆπÈóÆÈ¢òÔºåÊòæËëóÊèêÂçá‰∫Ü Cherry Studio ÁöÑÊÄùËÄÉÊ®°ÂºèÁ®≥ÂÆöÊÄß„ÄÇ
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Áîü‰∫ßÁéØÂ¢ÉËá™ÂÆö‰πâÂçèËÆÆÊîØÊåÅ (PR #2005)**:
            -   **ÂçèËÆÆ‰øÆÂ§ç**: ÈªòËÆ§ÂêØÁî® `custom-protocol` ÁâπÊÄßÔºå‰øÆÂ§ç‰∫ÜÁîü‰∫ßÁéØÂ¢É‰∏ãËá™ÂÆö‰πâÂçèËÆÆ (Â¶Ç `tauri://`) Âä†ËΩΩÂ§±Ë¥•ÁöÑÈóÆÈ¢òÔºåÁ°Æ‰øùÊú¨Âú∞ËµÑÊ∫êÂíåÁâπÊÆäÂçèËÆÆËØ∑Ê±ÇÁöÑÁ®≥ÂÆöÊÄß„ÄÇ
        -   **[Ê†∏ÂøÉ‰ºòÂåñ] ÊâòÁõòÂõæÊ†á‰∏éÁ™óÂè£ÁîüÂëΩÂë®ÊúüÁÆ°ÁêÜ**:
            -   **Êô∫ËÉΩÊâòÁõò**: ÂºïÂÖ• `AppRuntimeFlags` Áä∂ÊÄÅÁÆ°ÁêÜÔºåÂÆûÁé∞‰∫ÜÁ™óÂè£ÂÖ≥Èó≠Ë°å‰∏∫‰∏éÊâòÁõòÁä∂ÊÄÅÁöÑËÅîÂä®„ÄÇ
            -   **Ë°å‰∏∫‰ºòÂåñ**: ÂΩìÊâòÁõòÂêØÁî®Êó∂ÔºåÂÖ≥Èó≠Á™óÂè£Â∞ÜËá™Âä®ÈöêËóèËÄåÈùûÈÄÄÂá∫Â∫îÁî®ÔºõÂΩìÊâòÁõòÁ¶ÅÁî®Êó∂ÔºåÂÖ≥Èó≠Á™óÂè£Â∞ÜÊ≠£Â∏∏ÈÄÄÂá∫ÔºåÊèê‰æõ‰∫ÜÊõ¥Á¨¶ÂêàÁõ¥ËßâÁöÑÊ°åÈù¢‰ΩìÈ™å„ÄÇ
        -   **[Ê†∏ÂøÉÂ¢ûÂº∫] Linux ÁâàÊú¨Ê£ÄÊµã‰∏é HTTP ÂÆ¢Êà∑Á´ØÈ≤ÅÊ£íÊÄß**:
            -   **ÁâàÊú¨Ëß£Êûê**: Â¢ûÂº∫‰∫Ü Linux Âπ≥Âè∞ÁöÑÁâàÊú¨Âè∑ÊèêÂèñÈÄªËæë (`extract_semver`)ÔºåËÉΩ‰ªéÂ§çÊùÇÁöÑÂëΩ‰ª§Ë°åËæìÂá∫‰∏≠ÂáÜÁ°ÆËØÜÂà´ÁâàÊú¨ÔºåÊèêÂçá‰∫ÜËá™Âä®Êõ¥Êñ∞ÂíåÁéØÂ¢ÉÊ£ÄÊµãÁöÑÂáÜÁ°ÆÊÄß„ÄÇ
            -   **ÂÆ¢Êà∑Á´ØÈôçÁ∫ß**: ‰∏∫ HTTP ÂÆ¢Êà∑Á´ØÊûÑÂª∫ËøáÁ®ãÂ¢ûÂä†‰∫ÜËá™Âä®ÈôçÁ∫ßÊú∫Âà∂„ÄÇÂΩì‰ª£ÁêÜÈÖçÁΩÆÂØºËá¥ÊûÑÂª∫Â§±Ë¥•Êó∂ÔºåÁ≥ªÁªü‰ºöËá™Âä®ÂõûÈÄÄÂà∞Êó†‰ª£ÁêÜÊ®°ÂºèÊàñÈªòËÆ§ÈÖçÁΩÆÔºåÈò≤Ê≠¢Âõ†ÁΩëÁªúÈÖçÁΩÆÈîôËØØÂØºËá¥Â∫îÁî®ÂÆåÂÖ®‰∏çÂèØÁî®„ÄÇ
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] Cherry Studio ËÅîÁΩëÊêúÁ¥¢Á©∫ÂìçÂ∫î‰øÆÂ§ç (/v1/responses)**:
            -   **SSE ‰∫ã‰ª∂Ë°•ÂÖ®**: ÈáçÂÜô‰∫Ü `create_codex_sse_stream`ÔºåË°•ÂÖ®‰∫Ü OpenAI Responses API ËßÑËåÉË¶ÅÊ±ÇÁöÑÂÆåÊï¥ SSE ‰∫ã‰ª∂ÁîüÂëΩÂë®ÊúüÔºà`response.output_item.added`„ÄÅ`content_part.added/done`„ÄÅ`output_item.done`„ÄÅ`response.completed`ÔºâÔºåËß£ÂÜ≥‰∫Ü Cherry Studio Âõ†‰∫ã‰ª∂Áº∫Â§±ÂØºËá¥Êó†Ê≥ïÁªÑË£ÖÂìçÂ∫îÂÜÖÂÆπÁöÑÈóÆÈ¢ò„ÄÇ
            -   **ËÅîÁΩëÊêúÁ¥¢Ê≥®ÂÖ•‰øÆÂ§ç**: ËøáÊª§‰∫Ü Cherry Studio ÂèëÈÄÅÁöÑ `builtin_web_search` Â∑•ÂÖ∑Â£∞ÊòéÔºåÈò≤Ê≠¢ÂÖ∂‰∏é `inject_google_search_tool` ÂÜ≤Á™ÅÔºåÁ°Æ‰øù Google Search Â∑•ÂÖ∑Ë¢´Ê≠£Á°ÆÊ≥®ÂÖ•„ÄÇ
            -   **ÊêúÁ¥¢ÂºïÊñáÂõûÊòæ**: ‰∏∫ Codex ÊµÅÂºèÂìçÂ∫îÊ∑ªÂä†‰∫Ü `groundingMetadata` Ëß£ÊûêÔºåÊîØÊåÅÂú®ËÅîÁΩëÊêúÁ¥¢ÁªìÊûú‰∏≠ÂõûÊòæÊêúÁ¥¢Êü•ËØ¢ÂíåÊù•Ê∫êÂºïÊñá„ÄÇ
        -   **[‰ºòÂåñ] Claude ÂçèËÆÆËÅîÁΩë‰∏éÊÄùËÄÉÁ®≥ÂÆöÊÄß (PR #2007)**:
            -   **ÁßªÈô§ËÅîÁΩëÈôçÁ∫ß**: ÁßªÈô§‰∫Ü Claude ÂçèËÆÆ‰∏≠ÈíàÂØπËÅîÁΩëÊêúÁ¥¢ÁöÑÊøÄËøõÊ®°ÂûãÈôçÁ∫ßÈÄªËæëÔºåÈÅøÂÖç‰∏çÂøÖË¶ÅÁöÑÊ®°ÂûãÂõûÈÄÄ„ÄÇ
            -   **ÁßªÈô§ÊÄùËÄÉÂéÜÂè≤ÈôçÁ∫ß**: ÁßªÈô§‰∫Ü `should_disable_thinking_due_to_history` Ê£ÄÊü•Ôºå‰∏çÂÜçÂõ†ÂéÜÂè≤Ê∂àÊÅØÊ†ºÂºèÈóÆÈ¢òÊ∞∏‰πÖÁ¶ÅÁî®ÊÄùËÄÉÊ®°ÂºèÔºåÊîπ‰∏∫‰æùËµñ `thinking_recovery` Êú∫Âà∂Ëá™Âä®‰øÆÂ§ç„ÄÇ
        -   **UI ‰ºòÂåñ (Fix #2008)**: ÊîπËøõ‰∫ÜÂÜ∑Âç¥Êó∂Èó¥ÁöÑÊòæÁ§∫È¢úËâ≤ (‰ΩøÁî®ËìùËâ≤)ÔºåÊèêÈ´ò‰∫ÜÂú®Â∞èÂ≠ó‰Ωì‰∏ãÁöÑÂèØËØªÊÄß„ÄÇ
    *   **v4.1.20 (2026-02-16)**:
        *   **[‚ú® Êñ∞Êò•Á•ùÁ¶è] Á•ùÂ§ßÂÆ∂È©¨Âπ¥‰∏ÄÈ©¨ÂΩìÂÖàÔºå‰∏á‰∫ãÂ¶ÇÊÑèÔºÅCode ËøêÊòåÈöÜÔºå‰∏äÁ∫øÊó† BugÔºÅüßß**
        *   **[Critical]** ‰øÆÂ§ç‰∫Ü Claude Opus/Haiku Á≠âÊ®°ÂûãÂú® Antigravity API ‰∏äÁöÑ `400 INVALID_ARGUMENT` ÈîôËØØÔºàÈÄöËøáÊÅ¢Â§ç v4.1.16 ÁöÑÊ†∏ÂøÉÂçèËÆÆÊ†ºÂºèÔºâ„ÄÇ
        *   Â¢ûÂº∫‰∫ÜÊµÅÂºèÂìçÂ∫îÁöÑÂÅ•Â£ÆÊÄßÔºå‰ºòÂåñ‰∫ÜÂØπÂøÉË∑≥ÂåÖÂíåÈùû‰ªéÈõ∂ÂºÄÂßãÁöÑ Thinking Block ÁöÑÂ§ÑÁêÜ„ÄÇ
        *   **[Ê†∏ÂøÉ‰øÆÂ§ç] ‰øÆÂ§çÂõæÂÉèÁîüÊàêÈÖçÈ¢ùÂêåÊ≠•ÈóÆÈ¢ò (Issue #1995)**Ôºö
            *   **ÊîæÂÆΩÊ®°ÂûãËøáÊª§**Ôºö‰ºòÂåñ‰∫ÜÈÖçÈ¢ùÊäìÂèñÈÄªËæëÔºåÂ¢ûÂä†‰∫ÜÂØπ `image` / `imagen` ÂÖ≥ÈîÆÂ≠óÁöÑÊîØÊåÅÔºåÁ°Æ‰øùÂõæÂÉèÊ®°ÂûãÁöÑÈÖçÈ¢ù‰ø°ÊÅØËÉΩÊ≠£Â∏∏ÂêåÊ≠•„ÄÇ
            *   **Âç≥Êó∂Âà∑Êñ∞Êú∫Âà∂**ÔºöÂú®ÂõæÂÉèÁîüÊàêÊàêÂäüÂêéÁ´ãÂç≥ÂºÇÊ≠•Ëß¶ÂèëÂÖ®Â±ÄÈÖçÈ¢ùÂà∑Êñ∞ÔºåÂÆûÁé∞‰∫Ü UI ‰æßÂâ©‰ΩôÈÖçÈ¢ùÁöÑÂÆûÊó∂ÂèçÈ¶à„ÄÇ
        *   **[Ê†∏ÂøÉ‰øÆÂ§ç] ‰øÆÂ§ç OpenAI ÊµÅÂºèÊî∂ÈõÜÂô®Â∑•ÂÖ∑Ë∞ÉÁî®ÂêàÂπ∂ Bug (PR #1994)**Ôºö
            *   **ID ÂÜ≤Á™ÅÊ†°È™å**ÔºöÂú®ËÅöÂêàÊµÅÂºèÁâáÊÆµÊó∂ÂºïÂÖ• ID Ê†°È™åÔºåÈò≤Ê≠¢Â§ö‰∏™Â∑•ÂÖ∑Ë∞ÉÁî®Âõ†Á¥¢ÂºïÈáçÂè†ËÄåÂØºËá¥ÂèÇÊï∞Ë¢´ÈîôËØØÊãºÊé•„ÄÇ
            *   **Á¥¢ÂºïÁ®≥ÂÆöÊÄß‰ºòÂåñ**Ôºö‰ºòÂåñ‰∫ÜÊµÅÂºèËæìÂá∫‰∏≠ÁöÑÁ¥¢ÂºïÂàÜÈÖçÈÄªËæëÔºåÁ°Æ‰øùÂ§öËΩÆÊï∞ÊçÆ‰º†Ëæì‰∏ãÂ∑•ÂÖ∑Ë∞ÉÁî®Á¥¢ÂºïÂßãÁªàÂçïÂêëÈÄíÂ¢û„ÄÇ
        *   **[Ê†∏ÂøÉ‰ºòÂåñ] ÊûÅËá¥ÊãüÁúüËØ∑Ê±Ç‰º™Ë£Ö (Request Identity Camouflage)**:
            *   **Âä®ÊÄÅÁâàÊú¨‰º™Ë£Ö**: ÂÆûÁé∞‰∫ÜÊô∫ËÉΩÁâàÊú¨Êé¢ÊµãÊú∫Âà∂„ÄÇAntigravity Áé∞Âú®‰ºöËá™Âä®ËØªÂèñÊú¨Âú∞ÂÆâË£ÖÁöÑÁúüÂÆûÁâàÊú¨Âè∑ÊûÑÂª∫ User-AgentÔºåÂΩªÂ∫ïÂëäÂà´‰∫ÜÁ°¨ÁºñÁ†ÅÁöÑ &quot;1.0.0&quot; Êó∂‰ª£„ÄÇ
            *   **Docker ÁéØÂ¢ÉÂÖúÂ∫ï**: ÈíàÂØπÊó†Â§¥Ê®°ÂºèÔºàDocker/Linux ServerÔºâÔºåÂÜÖÁΩÆ‰∫Ü‚ÄúÂ∑≤Áü•Á®≥ÂÆöÁâà‚ÄùÊåáÁ∫πÂ∫ì„ÄÇÂΩìÊó†Ê≥ïÊ£ÄÊµãÂà∞Êú¨Âú∞ÂÆ¢Êà∑Á´ØÊó∂ÔºåËá™Âä®‰º™Ë£Ö‰∏∫ÊúÄÊñ∞Á®≥ÂÆöÁâàÂÆ¢Êà∑Á´ØÔºàÂ¶Ç v1.16.5ÔºâÔºåÁ°Æ‰øùÊúçÂä°Á´ØÁúãÂà∞ÁöÑÊ∞∏ËøúÊòØÂêàÊ≥ïÁöÑÂÆòÊñπÂÆ¢Êà∑Á´Ø„ÄÇ
            *   **ÂÖ®Áª¥Â∫¶ Header Ê≥®ÂÖ•**: Ë°•ÂÖ®‰∫Ü `X-Client-Name`, `X-Client-Version`, `X-Machine-Id`, `X-VSCode-SessionId` Á≠âÂÖ≥ÈîÆÊåáÁ∫πÂ§¥ÔºåÂÆûÁé∞‰∫Ü‰ªéÁΩëÁªúÂ±ÇÂà∞Â∫îÁî®Â±ÇÁöÑÂÉèÁ¥†Á∫ß‰º™Ë£ÖÔºåËøõ‰∏ÄÊ≠•Èôç‰Ωé‰∫Ü 403 È£éÊéßÊ¶ÇÁéá„ÄÇ
        *   **[Ê†∏ÂøÉÂäüËÉΩ] ÂêéÂè∞Ëá™Âä®Âà∑Êñ∞ÂºÄÂÖ≥‰∏éËÆæÁΩÆÁÉ≠‰øùÂ≠ò**:
            *   **Áã¨Á´ãÂºÄÂÖ≥**: Âú®ËÆæÁΩÆÈ°µÈù¢Êñ∞Â¢û‰∫Ü‚ÄúÂêéÂè∞Ëá™Âä®Âà∑Êñ∞‚ÄùÁöÑÁã¨Á´ãÂºÄÂÖ≥ÔºåÂÖÅËÆ∏Áî®Êà∑Êõ¥Á≤æÁªÜÂú∞ÊéßÂà∂ÂêéÂè∞‰ªªÂä°„ÄÇ
            *   **ÈÖçÁΩÆÁÉ≠‰øùÂ≠ò**: ÂÆûÁé∞‰∫ÜËÆæÁΩÆÈ°πÔºàËá™Âä®Âà∑Êñ∞„ÄÅÊô∫ËÉΩÈ¢ÑÁÉ≠„ÄÅÈÖçÈ¢ù‰øùÊä§ÔºâÁöÑÁÉ≠‰øùÂ≠òÊú∫Âà∂ÔºåÊó†ÈúÄÊâãÂä®ÁÇπÂáª‰øùÂ≠òÊåâÈíÆÂç≥ÂèØÂÆûÊó∂ÁîüÊïà„ÄÇ
        *   **[ÈÄªËæë‰ºòÂåñ] Êô∫ËÉΩÈ¢ÑÁÉ≠‰∏éÈÖçÈ¢ù‰øùÊä§Ëß£ËÄ¶**:
            *   **Ëß£Èô§ÈîÅÂÆö**: ÂΩªÂ∫ïÁßªÈô§‰∫Ü‚ÄúÈ¢ùÂ∫¶‰øùÊä§‚ÄùÂØπ‚ÄúÊô∫ËÉΩÈ¢ÑÁÉ≠‚ÄùÁöÑÂº∫Âà∂ÁªëÂÆö„ÄÇÁé∞Âú®ÂºÄÂêØÈ¢ùÂ∫¶‰øùÊä§‰ªÖ‰ºöÂº∫Âà∂ÂºÄÂêØ‚ÄúÂêéÂè∞Ëá™Âä®Âà∑Êñ∞‚ÄùÔºàÁî®‰∫éÊ£ÄÊµãÈÖçÈ¢ùÔºâÔºåËÄå‰∏ç‰ºöÂº∫Âà∂ÂêØÂä®È¢ÑÁÉ≠ËØ∑Ê±Ç„ÄÇ
            *   **[ÈáçË¶ÅÂª∫ËÆÆ]**: Âª∫ËÆÆÁî®Êà∑Âú®ÂΩìÂâçÁâàÊú¨ÊöÇÊó∂ÂÖ≥Èó≠‚ÄúÈ¢ùÂ∫¶‰øùÊä§‚ÄùÂíå‚ÄúÂêéÂè∞Ëá™Âä®Âà∑Êñ∞‚ÄùÂäüËÉΩÔºå‰ª•ÈÅøÂÖçÂõ†È¢ëÁπÅËØ∑Ê±ÇÂØºËá¥ÁöÑÊΩúÂú®ÈóÆÈ¢ò„ÄÇ
    *   **v4.1.19 (2026-02-15)**:
        -   **[Ê†∏ÂøÉ‰øÆÂ§ç] ‰øÆÂ§ç Claude Code CLI Â∑•ÂÖ∑Ë∞ÉÁî®Á©∫ÊñáÊú¨ÂùóÈîôËØØ (Fix #1974)**:
            -   **Â≠óÊÆµÁº∫Â§±‰øÆÂ§ç**: ‰øÆÂ§ç‰∫Ü Claude Code CLI Âú®Â∑•ÂÖ∑Ë∞ÉÁî®ËøáÁ®ã‰∏≠ÔºåÂõ†ÂèëÈÄÅÁ©∫ÊñáÊú¨Âùó (`text: &quot;&quot;`) ÂØºËá¥‰∏äÊ∏∏ API Êä•Èîô `Field required` ÁöÑÈóÆÈ¢ò„ÄÇ
            -   **Á©∫ÂÄºËøáÊª§**: Âú®ÂçèËÆÆËΩ¨Êç¢Â±ÇÂ¢ûÂä†‰∫ÜÂØπÊó†ÊïàÁ©∫ÊñáÊú¨ÂùóÁöÑËá™Âä®ËøáÊª§‰∏éÊ∏ÖÁêÜ

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustdesk/rustdesk]]></title>
            <link>https://github.com/rustdesk/rustdesk</link>
            <guid>https://github.com/rustdesk/rustdesk</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:10 GMT</pubDate>
            <description><![CDATA[An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustdesk/rustdesk">rustdesk/rustdesk</a></h1>
            <p>An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.</p>
            <p>Language: Rust</p>
            <p>Stars: 108,060</p>
            <p>Forks: 16,080</p>
            <p>Stars today: 79 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;res/logo-header.svg&quot; alt=&quot;RustDesk - Your remote desktop&quot;&gt;&lt;br&gt;
  &lt;a href=&quot;#raw-steps-to-build&quot;&gt;Build&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#how-to-build-with-docker&quot;&gt;Docker&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#file-structure&quot;&gt;Structure&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#snapshot&quot;&gt;Snapshot&lt;/a&gt;&lt;br&gt;
  [&lt;a href=&quot;docs/README-UA.md&quot;&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href=&quot;docs/README-CS.md&quot;&gt;ƒçesky&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ZH.md&quot;&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href=&quot;docs/README-HU.md&quot;&gt;Magyar&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ES.md&quot;&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FA.md&quot;&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FR.md&quot;&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DE.md&quot;&gt;Deutsch&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PL.md&quot;&gt;Polski&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ID.md&quot;&gt;Indonesian&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FI.md&quot;&gt;Suomi&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ML.md&quot;&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href=&quot;docs/README-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NL.md&quot;&gt;Nederlands&lt;/a&gt;] | [&lt;a href=&quot;docs/README-IT.md&quot;&gt;Italiano&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PTBR.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href=&quot;docs/README-EO.md&quot;&gt;Esperanto&lt;/a&gt;] | [&lt;a href=&quot;docs/README-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href=&quot;docs/README-AR.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href=&quot;docs/README-VN.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DA.md&quot;&gt;Dansk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-GR.md&quot;&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href=&quot;docs/README-TR.md&quot;&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NO.md&quot;&gt;Norsk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RO.md&quot;&gt;Rom√¢nƒÉ&lt;/a&gt;]&lt;br&gt;
  &lt;b&gt;We need your help to translate this README, &lt;a href=&quot;https://github.com/rustdesk/rustdesk/tree/master/src/lang&quot;&gt;RustDesk UI&lt;/a&gt; and &lt;a href=&quot;https://github.com/rustdesk/doc.rustdesk.com&quot;&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt;
&lt;/p&gt;

&gt; [!Caution]
&gt; **Misuse Disclaimer:** &lt;br&gt;
&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.


Chat with us: [Discord](https://discord.gg/nDceKgxnkV) | [Twitter](https://twitter.com/rustdesk) | [Reddit](https://www.reddit.com/r/rustdesk) | [YouTube](https://www.youtube.com/@rustdesk)

[![RustDesk Server Pro](https://img.shields.io/badge/RustDesk%20Server%20Pro-Advanced%20Features-blue)](https://rustdesk.com/pricing.html)

Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, [set up your own](https://rustdesk.com/server), or [write your own rendezvous/relay server](https://github.com/rustdesk/rustdesk-server-demo).

![image](https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png)

RustDesk welcomes contribution from everyone. See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for help getting started.

[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)

[**BINARY DOWNLOAD**](https://github.com/rustdesk/rustdesk/releases)

[**NIGHTLY BUILD**](https://github.com/rustdesk/rustdesk/releases/tag/nightly)

[&lt;img src=&quot;https://f-droid.org/badge/get-it-on.png&quot;
    alt=&quot;Get it on F-Droid&quot;
    height=&quot;80&quot;&gt;](https://f-droid.org/en/packages/com.carriez.flutter_hbb)
[&lt;img src=&quot;https://flathub.org/api/badge?svg&amp;locale=en&quot;
    alt=&quot;Get it on Flathub&quot;
    height=&quot;80&quot;&gt;](https://flathub.org/apps/com.rustdesk.RustDesk)

## Dependencies

Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our [CI](https://github.com/rustdesk/rustdesk/blob/master/.github/workflows/flutter-build.yml) for building Flutter version.

Please download Sciter dynamic library yourself.

[Windows](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll) |
[Linux](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so) |
[macOS](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib)

## Raw Steps to build

- Prepare your Rust development env and C++ build env

- Install [vcpkg](https://github.com/microsoft/vcpkg), and set `VCPKG_ROOT` env variable correctly

  - Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static
  - Linux/macOS: vcpkg install libvpx libyuv opus aom

- run `cargo run`

## [Build](https://rustdesk.com/docs/en/dev/build/)

## How to Build on Linux

### Ubuntu 18 (Debian 10)

```sh
sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
```

### openSUSE Tumbleweed

```sh
sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
```

### Fedora 28 (CentOS 8)

```sh
sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
```

### Arch (Manjaro)

```sh
sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
```

### Install vcpkg

```sh
git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
```

### Fix libvpx (For Fedora)

```sh
cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i &#039;s/CFLAGS+=-I/CFLAGS+=-fPIC -I/g&#039; Makefile
sed -i &#039;s/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g&#039; Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
```

### Build

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
```

## How to build with Docker

Begin by cloning the repository and building the Docker container:

```sh
git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t &quot;rustdesk-builder&quot; .
```

Then, each time you need to build the application, run the following command:

```sh
docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=&quot;$(id -u)&quot; -e PGID=&quot;$(id -g)&quot; rustdesk-builder
```

Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the `&lt;OPTIONAL-ARGS&gt;` position. For instance, if you wanted to build an optimized release version, you would run the command above followed by `--release`. The resulting executable will be available in the target folder on your system, and can be run with:

```sh
target/debug/rustdesk
```

Or, if you&#039;re running a release executable:

```sh
target/release/rustdesk
```

Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as `install` or `run` are not currently supported via this method as they would install or run the program inside the container instead of the host.

## File Structure

- **[libs/hbb_common](https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common)**: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions
- **[libs/scrap](https://github.com/rustdesk/rustdesk/tree/master/libs/scrap)**: screen capture
- **[libs/enigo](https://github.com/rustdesk/rustdesk/tree/master/libs/enigo)**: platform specific keyboard/mouse control
- **[libs/clipboard](https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard)**: file copy and paste implementation for Windows, Linux, macOS.
- **[src/ui](https://github.com/rustdesk/rustdesk/tree/master/src/ui)**: obsolete Sciter UI (deprecated)
- **[src/server](https://github.com/rustdesk/rustdesk/tree/master/src/server)**: audio/clipboard/input/video services, and network connections
- **[src/client.rs](https://github.com/rustdesk/rustdesk/tree/master/src/client.rs)**: start a peer connection
- **[src/rendezvous_mediator.rs](https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs)**: Communicate with [rustdesk-server](https://github.com/rustdesk/rustdesk-server), wait for remote direct (TCP hole punching) or relayed connection
- **[src/platform](https://github.com/rustdesk/rustdesk/tree/master/src/platform)**: platform specific code
- **[flutter](https://github.com/rustdesk/rustdesk/tree/master/flutter)**: Flutter code for desktop and mobile
- **[flutter/web/js](https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js)**: JavaScript for Flutter web client

## Screenshots

![Connection Manager](https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651)

![Connected to a Windows PC](https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea)

![File Transfer](https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad)

![TCP Tunneling](https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[paritytech/polkadot-sdk]]></title>
            <link>https://github.com/paritytech/polkadot-sdk</link>
            <guid>https://github.com/paritytech/polkadot-sdk</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:09 GMT</pubDate>
            <description><![CDATA[The Parity Polkadot Blockchain SDK]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paritytech/polkadot-sdk">paritytech/polkadot-sdk</a></h1>
            <p>The Parity Polkadot Blockchain SDK</p>
            <p>Language: Rust</p>
            <p>Stars: 2,692</p>
            <p>Forks: 1,137</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![SDK Logo](./docs/images/Polkadot_Logo_Horizontal_Pink_White.png#gh-dark-mode-only)
![SDK Logo](./docs/images/Polkadot_Logo_Horizontal_Pink_Black.png#gh-light-mode-only)

# Polkadot SDK

![GitHub stars](https://img.shields.io/github/stars/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub
forks](https://img.shields.io/github/forks/paritytech/polkadot-sdk)

&lt;!-- markdownlint-disable-next-line MD013 --&gt;
[![StackExchange](https://img.shields.io/badge/StackExchange-Community%20&amp;%20Support-222222?logo=stackexchange)](https://substrate.stackexchange.com/)&amp;nbsp;&amp;nbsp;![GitHub contributors](https://img.shields.io/github/contributors/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub commit activity](https://img.shields.io/github/commit-activity/m/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub last commit](https://img.shields.io/github/last-commit/paritytech/polkadot-sdk)

&gt; The Polkadot SDK repository provides all the components needed to start building on the
&gt; [Polkadot](https://polkadot.com/) network, a multi-chain blockchain platform that enables
&gt; different blockchains to interoperate and share information in a secure and scalable way.

&lt;/div&gt;

## ‚ö° Quickstart
If you want to get an example node running quickly you can execute the following getting started script:

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/scripts/getting-started.sh | bash
```

## üë©üèΩ‚Äçüíª Building

In order to build this project you need to install some dependencies, follow the instructions in [this guide](https://docs.polkadot.com/develop/parachains/install-polkadot-sdk).

### üéØ Build targets

When building full runtimes, the WASM builder takes care of all required configuration.  
For individual crates, however, there are a few caveats when targeting `no_std`.

#### WASM
Set `RUSTFLAGS=&quot;--cfg substrate_runtime&quot;` when building for WASM. See the
[WASM build](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/substrate/index.html#wasm-build)
in the Polkadot SDK Documentation.

#### PolkaVM
PolkaVM builds require some `riscv32` or `riscv64` target architecture.  
See the CI example: [RiscV-build](https://github.com/paritytech/polkadot-sdk/blob/6de451a105ca0a5feb675a215d4e8de5207febf6/.github/workflows/build-misc.yml#L55).

## üìö Documentation

* [Polkadot Documentation Portal](https://docs.polkadot.com)
* [ü¶Ä rust-docs](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/index.html): Where we keep track of
the API docs of our Rust crates. Includes:
  * [Introduction](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/index.html)
	to each component of the Polkadot SDK: Substrate, FRAME, Cumulus, and XCM
  * [Guides](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/guides/index.html),
	namely how to build your first FRAME pallet
  * [Templates](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/templates/index.html)
    for starting a new project.
  * [External Resources](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/external_resources/index.html)
* Have a question? You can ask in the Polkadot SDK Developers Chat.
Messages from either of these channels are bridged to the other, so you can use whichever one you like.
  * [Telegram](https://t.me/substratedevs)
  * [Matrix](https://matrix.to/#/#substratedevs:matrix.org)
  * [Discord](https://discord.com/channels/722223075629727774/997505821955076196)
  * [Polkadot and Substrate StackExchange](https://substrate.stackexchange.com/)

## üöÄ Releases

&lt;!-- markdownlint-disable-next-line MD013 --&gt;
![Current Stable Release](https://raw.githubusercontent.com/paritytech/release-registry/main/badges/polkadot-sdk-latest.svg)&amp;nbsp;&amp;nbsp;![Next Stable Release](https://raw.githubusercontent.com/paritytech/release-registry/main/badges/polkadot-sdk-next.svg)

The Polkadot SDK is released every three months as a `Polkadot stableYYMM` release. Each stable release is supported for
one year with patches. See the next upcoming versions in the [Release
Registry](https://github.com/paritytech/release-registry/) and more docs in [RELEASE.md](./docs/RELEASE.md).

You can use [`psvm`](https://github.com/paritytech/psvm) to update all dependencies to a specific
version without needing to manually select the correct version for each crate.

## üõ†Ô∏è Tooling

[Polkadot SDK Version Manager](https://github.com/paritytech/psvm):
A simple tool to manage and update the Polkadot SDK dependencies in any Cargo.toml file.
It will automatically update the Polkadot SDK dependencies to their correct crates.io version.

## üîê Security

The security policy and procedures can be found in
[docs/contributor/SECURITY.md](./docs/contributor/SECURITY.md).

## ü§ç Contributing &amp; Code of Conduct

Ensure you follow our [contribution guidelines](./docs/contributor/CONTRIBUTING.md). In every
interaction and contribution, this project adheres to the [Contributor Covenant Code of
Conduct](./docs/contributor/CODE_OF_CONDUCT.md).

### üëæ Ready to Contribute?

Take a look at the issues labeled with [`mentor`](https://github.com/paritytech/polkadot-sdk/labels/C1-mentor)
(or alternatively [this](https://mentor.tasty.limo/) page, created by one of the maintainers) label to get started!
We always recognize valuable contributions by proposing an on-chain tip to the Polkadot network as a token of our
appreciation.

## Polkadot Fellowship

Development in this repo usually goes hand in hand with the `fellowship` organization. In short,
this repository provides all the SDK pieces needed to build both Polkadot and its parachains. But,
the actual Polkadot runtime lives in the `fellowship/runtimes` repository. Read more about the
fellowship, this separation, the RFC process
[here](https://polkadot-fellows.github.io/dashboard/).

## History

This repository is the amalgamation of 3 separate repositories that used to make up Polkadot SDK,
namely Substrate, Polkadot and Cumulus. Read more about the merge and its history
[here](https://polkadot-public.notion.site/Polkadot-SDK-FAQ-fbc4cecc2c46443fb37b9eeec2f0d85f).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[kitao/pyxel]]></title>
            <link>https://github.com/kitao/pyxel</link>
            <guid>https://github.com/kitao/pyxel</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:08 GMT</pubDate>
            <description><![CDATA[A retro game engine for Python]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kitao/pyxel">kitao/pyxel</a></h1>
            <p>A retro game engine for Python</p>
            <p>Language: Rust</p>
            <p>Stars: 17,146</p>
            <p>Forks: 911</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;docs/images/pyxel_logo_152x64.png&quot;&gt;

[![Downloads](https://static.pepy.tech/personalized-badge/pyxel?period=total&amp;units=international_system&amp;left_color=grey&amp;right_color=blue&amp;left_text=PyPI%20downloads)](https://pypi.org/project/pyxel/)
[![GitHub Repo stars](https://img.shields.io/github/stars/kitao/pyxel?style=social)](https://github.com/kitao/pyxel)
[![GitHub forks](https://img.shields.io/github/forks/kitao/pyxel?style=social)](https://github.com/kitao/pyxel)
[![GitHub Sponsors](https://img.shields.io/github/sponsors/kitao?label=Sponsor%20me&amp;logo=github%20sponsors&amp;style=social)](https://github.com/sponsors/kitao)

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/H2H27VDKD)

[ [English](README.md) | [‰∏≠Êñá](docs/README.cn.md) | [Deutsch](docs/README.de.md) | [Espa√±ol](docs/README.es.md) | [Fran√ßais](docs/README.fr.md) | [Italiano](docs/README.it.md) | [Êó•Êú¨Ë™û](docs/README.ja.md) | [ÌïúÍµ≠Ïñ¥](docs/README.ko.md) | [Portugu√™s](docs/README.pt.md) | [–†—É—Å—Å–∫–∏–π](docs/README.ru.md) | [T√ºrk√ße](docs/README.tr.md) | [–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](docs/README.uk.md) ]

**Pyxel** (/Ààp…™ks…ôl/) is a retro game engine for Python.

With simple specifications inspired by retro gaming consoles, such as displaying only 16 colors and supporting 4 sound channels, you can easily enjoy making pixel-art-style games.

[&lt;img src=&quot;docs/images/pyxel_thanks.png&quot; width=&quot;460&quot;&gt;](https://github.com/kitao/pyxel/wiki/Pyxel-User-Examples) [&lt;img src=&quot;docs/images/pyxel_book.png&quot; width=&quot;180&quot;&gt;](https://gihyo.jp/book/2025/978-4-297-14657-3)

The development of Pyxel is driven by user feedback. Please give Pyxel a star on GitHub!

&lt;p&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/examples/10-platformer.html&quot;&gt;
&lt;img src=&quot;docs/images/10_platformer.gif&quot; width=&quot;290&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/apps/30sec-of-daylight.html&quot;&gt;
&lt;img src=&quot;docs/images/30sec_of_daylight.gif&quot; width=&quot;350&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/examples/02-jump-game.html&quot;&gt;
&lt;img src=&quot;docs/images/02_jump_game.gif&quot; width=&quot;330&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/apps/megaball.html&quot;&gt;
&lt;img src=&quot;docs/images/megaball.gif&quot; width=&quot;310&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/tools/image-editor.html&quot;&gt;
&lt;img src=&quot;docs/images/image_tilemap_editor.gif&quot; width=&quot;320&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/tools/sound-editor.html&quot;&gt;
&lt;img src=&quot;docs/images/sound_music_editor.gif&quot; width=&quot;320&quot;&gt;
&lt;/a&gt;
&lt;/p&gt;

Pyxel&#039;s specifications and APIs are inspired by [PICO-8](https://www.lexaloffle.com/pico-8.php) and [TIC-80](https://tic80.com/).

Pyxel is open source under the [MIT License](LICENSE) and free to use. Let&#039;s start making retro games with Pyxel!

## Specifications

- Runs on Windows, Mac, Linux, and Web
- Programming in Python
- Customizable screen size
- 16-color palette
- 3 256x256 image banks
- 8 256x256 tilemaps
- 4 channels with 64 definable sounds
- 8 music tracks composed of sounds
- Keyboard, mouse, and gamepad inputs
- Image and sound editing tools
- User-extensible colors, sound channels, and banks

### Color Palette

&lt;img src=&quot;docs/images/05_color_palette.png&quot;&gt;

&lt;img src=&quot;docs/images/pyxel_palette.png&quot;&gt;

## How to Install

### Windows

After installing [Python 3](https://www.python.org/) (version 3.8 or higher), run the following command:

```sh
pip install -U pyxel
```

When installing Python using the official installer, make sure to check the `Add Python 3.x to PATH` option to enable the `pyxel` command.

### Mac

After installing [Homebrew](https://brew.sh/), run the following commands:

```sh
brew install pipx
pipx ensurepath
pipx install pyxel
```

To upgrade Pyxel after installation, run `pipx upgrade pyxel`.

### Linux

After installing [Python 3](https://www.python.org/) (version 3.8 or higher), run the following command:

```sh
pip install -U pyxel
```

If the previous command fails, consider building Pyxel from source by following the instructions in the [Makefile](Makefile).

### Web

The web version of Pyxel works on PCs, smartphones, and tablets with a compatible browser, without installing Python or Pyxel.

The easiest way to use it is through the online IDE [Pyxel Code Maker](https://kitao.github.io/pyxel/wasm/code-maker/).

For other usage patterns, such as embedding Pyxel apps on your own site, please refer to [this page](docs/pyxel-web-en.md).

### Try Examples

After installing Pyxel, you can copy the examples to the current directory with the following command:

```sh
pyxel copy_examples
```

The examples can be viewed and run in the browser from [this page](https://kitao.github.io/pyxel/wasm/examples/).

Locally, the examples can be executed with the following commands:

```sh
# Run example in examples directory
cd pyxel_examples
pyxel run 01_hello_pyxel.py

# Run app in examples/apps directory
cd apps
pyxel play 30sec_of_daylight.pyxapp
```

## How to Use

### Create Application

In your Python script, import Pyxel, set the window size with `init`, and start the application with `run`.

```python
import pyxel

pyxel.init(160, 120)

def update():
    if pyxel.btnp(pyxel.KEY_Q):
        pyxel.quit()

def draw():
    pyxel.cls(0)
    pyxel.rect(10, 10, 20, 20, 11)

pyxel.run(update, draw)
```

The arguments of the `run` function are the `update` function, which processes frame updates, and the `draw` function, which handles screen drawing.

In an actual application, it is recommended to wrap Pyxel code in a class, as shown below:

```python
import pyxel

class App:
    def __init__(self):
        pyxel.init(160, 120)
        self.x = 0
        pyxel.run(self.update, self.draw)

    def update(self):
        self.x = (self.x + 1) % pyxel.width

    def draw(self):
        pyxel.cls(0)
        pyxel.rect(self.x, 0, 8, 8, 9)

App()
```

For creating simple graphics without animation, you can use the `show` function to simplify your code.

```python
import pyxel

pyxel.init(120, 120)
pyxel.cls(1)
pyxel.circb(60, 60, 40, 7)
pyxel.show()
```

### Run Application

A created script can be executed using the `python` command:

```sh
python PYTHON_SCRIPT_FILE
```

It can also be run with the `pyxel run` command:

```sh
pyxel run PYTHON_SCRIPT_FILE
```

Additionally, the `pyxel watch` command monitors changes in a specified directory and automatically re-runs the program when changes are detected:

```sh
pyxel watch WATCH_DIR PYTHON_SCRIPT_FILE
```

Stop directory monitoring by pressing `Ctrl(Command)+C`.

### Special Key Controls

The following special key actions are available while a Pyxel application is running:

- `Esc`&lt;br&gt;
  Quit the application
- `Alt(Option)+R` or `A+B+X+Y+BACK` on gamepad&lt;br&gt;
  Reset the application
- `Alt(Option)+1`&lt;br&gt;
  Save the screenshot to the desktop
- `Alt(Option)+2`&lt;br&gt;
  Reset the recording start time of the screen capture video
- `Alt(Option)+3`&lt;br&gt;
  Save a screen capture video to the desktop (up to 10 seconds)
- `Alt(Option)+8` or `A+B+X+Y+DL` on gamepad&lt;br&gt;
  Toggle screen scaling between maximum and integer
- `Alt(Option)+9` or `A+B+X+Y+DR` on gamepad&lt;br&gt;
  Switch between screen modes (Crisp/Smooth/Retro)
- `Alt(Option)+0` or `A+B+X+Y+DU` on gamepad&lt;br&gt;
  Toggle the performance monitor (FPS/`update` time/`draw` time)
- `Alt(Option)+Enter` or `A+B+X+Y+DD` on gamepad&lt;br&gt;
  Toggle fullscreen
- `Shift+Alt(Option)+1/2/3`&lt;br&gt;
  Save image bank 0, 1, or 2 to the desktop
- `Shift+Alt(Option)+0`&lt;br&gt;
  Save the current color palette to the desktop

### How to Create Resources

Pyxel Editor creates images and sounds used in a Pyxel application.

You can start Pyxel Editor with the following command:

```sh
pyxel edit PYXEL_RESOURCE_FILE
```

If the specified Pyxel resource file (.pyxres) exists, it will be loaded. If it does not exist, a new file with the specified name will be created. If the resource file is omitted, a new file named `my_resource.pyxres` will be created.

After starting Pyxel Editor, you can switch to another resource file by dragging and dropping it onto the editor.

The created resource file can be loaded using the `load` function.

Pyxel Editor has the following editing modes.

**Image Editor**

The mode for editing images in each **image bank**.

&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/tools/image-editor.html&quot;&gt;
&lt;img src=&quot;docs/images/image_editor.gif&quot;&gt;
&lt;/a&gt;

You can drag and drop an image file (PNG/GIF/JPEG) into the image editor to load the image into the currently selected image bank.

**Tilemap Editor**

The mode for editing **tilemaps** that arrange images from the image banks in a tile pattern.

&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/tools/tilemap-editor.html&quot;&gt;
&lt;img src=&quot;docs/images/tilemap_editor.gif&quot;&gt;
&lt;/a&gt;

Drag and drop a TMX file (Tiled Map File) onto the tilemap editor to load its layer 0 into the currently selected tilemap.

**Sound Editor**

The mode for editing **sounds** used for melodies and sound effects.

&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/tools/sound-editor.html&quot;&gt;
&lt;img src=&quot;docs/images/sound_editor.gif&quot;&gt;
&lt;/a&gt;

**Music Editor**

The mode for editing **music tracks** in which the sounds are arranged in order of playback.

&lt;a href=&quot;https://kitao.github.io/pyxel/wasm/examples/tools/music-editor.html&quot;&gt;
&lt;img src=&quot;docs/images/music_editor.gif&quot;&gt;
&lt;/a&gt;

### Other Resource Creation Methods

Pyxel images and tilemaps can also be created using the following methods:

- Create images or tilemaps from lists of strings with the `Image.set` or `Tilemap.set` functions
- Load palette-ready image files (PNG/GIF/JPEG) with the `Image.load` function

Pyxel sounds and music can also be created using the following method:

- Create them from strings with the `Sound.set` or `Music.set` functions

Refer to the API reference for the usage of these functions.

### How to Distribute Applications

Pyxel supports a cross-platform distribution format called a Pyxel application file.

Create a Pyxel application file (.pyxapp) with the `pyxel package` command:

```sh
pyxel package APP_DIR STARTUP_SCRIPT_FILE
```

If you need to include resources or additional modules, place them in the application directory.

Metadata can be displayed at runtime by specifying it in the following format within the startup script. Fields other than `title` and `author` are optional.

```python
# title: Pyxel Platformer
# author: Takashi Kitao
# desc: A Pyxel platformer example
# site: https://github.com/kitao/pyxel
# license: MIT
# version: 1.0
```

The created application file can be run using the `pyxel play` command:

```sh
pyxel play PYXEL_APP_FILE
```

A Pyxel application file can also be converted to an executable or an HTML file using the `pyxel app2exe` or `pyxel app2html` commands.

## API Reference

### System

- `width`, `height`&lt;br&gt;
  The width and height of the screen

- `frame_count`&lt;br&gt;
  The number of elapsed frames

- `init(width, height, [title], [fps], [quit_key], [display_scale], [capture_scale], [capture_sec])`&lt;br&gt;
  Initialize the Pyxel application with the screen size (`width`, `height`). The following options can be specified: the window title with `title`, the frame rate with `fps`, the key to quit the application with `quit_key`, the display scale with `display_scale`, the screen capture scale with `capture_scale`, and the maximum recording time of the screen capture video with `capture_sec`.&lt;br&gt;
  Example: `pyxel.init(160, 120, title=&quot;My Pyxel App&quot;, fps=60, quit_key=pyxel.KEY_NONE, capture_scale=3, capture_sec=0)`

- `run(update, draw)`&lt;br&gt;
  Start the Pyxel application and call the `update` function for frame update and the `draw` function for drawing.

- `show()`&lt;br&gt;
  Show the screen and wait until the `Esc` key is pressed.

- `flip()`&lt;br&gt;
  Refresh the screen by one frame. The application exits when the `Esc` key is pressed. This function is not available in the web version.

- `quit()`&lt;br&gt;
  Quit the Pyxel application.

- `reset()`&lt;br&gt;
  Reset the Pyxel application. Environment variables are preserved after reset.

### Resource

- `load(filename, [exclude_images], [exclude_tilemaps], [exclude_sounds], [exclude_musics])`&lt;br&gt;
  Load the resource file (.pyxres). If an option is set to `True`, the corresponding resource will be excluded from loading. If a palette file (.pyxpal) with the same name exists in the same location as the resource file, the palette display colors will also be updated. The palette file contains hexadecimal entries for the display colors (e.g. `1100ff`), separated by newlines. The palette file can also be used to change the colors displayed in Pyxel Editor.

- `user_data_dir(vendor_name, app_name)`&lt;br&gt;
  Return the user data directory created based on `vendor_name` and `app_name`. If the directory does not exist, it will be created automatically. It is used to store high scores, game progress, and similar data.&lt;br&gt;
  Example: `print(pyxel.user_data_dir(&quot;Takashi Kitao&quot;, &quot;Pyxel Shooter&quot;))`

### Input

- `mouse_x`, `mouse_y`&lt;br&gt;
  The current position of the mouse cursor

- `mouse_wheel`&lt;br&gt;
  The current value of the mouse wheel

- `btn(key)`&lt;br&gt;
  Return `True` if the `key` is pressed, otherwise return `False`. ([Key definition list](python/pyxel/__init__.pyi))

- `btnp(key, [hold], [repeat])`&lt;br&gt;
  Return `True` if the `key` is pressed in that frame, otherwise return `False`. If `hold` and `repeat` are specified, after the `key` has been held down for `hold` frames or more, `True` is returned every `repeat` frames.

- `btnr(key)`&lt;br&gt;
  Return `True` if the `key` is released in that frame, otherwise return `False`.

- `mouse(visible)`&lt;br&gt;
  Show the mouse cursor if `visible` is `True`, and hide it if `visible` is `False`. The cursor&#039;s position continues to update even when it is hidden.

### Graphics

- `colors`&lt;br&gt;
  List of the palette display colors. The display color is specified by a 24-bit numerical value. It can be manipulated like a Python list to add, remove, or bulk-replace colors.&lt;br&gt;
  Example: `old_colors = list(pyxel.colors); pyxel.colors[:] = [0x111111, 0x222222, 0x333333]; pyxel.colors[15] = 0x112233`

- `images`&lt;br&gt;
  List of the image banks (instances of the Image class) (0-2)&lt;br&gt;
  Example: `pyxel.images[0].load(0, 0, &quot;title.png&quot;)`

- `tilemaps`&lt;br&gt;
  List of the tilemaps (instances of the Tilemap class) (0-7)

- `clip(x, y, w, h)`&lt;br&gt;
  Set the drawing area of the screen from (`x`, `y`) with a width of `w` and a height of `h`. Call `clip()` to reset the drawing area to full screen.

- `camera(x, y)`&lt;br&gt;
  Change the upper-left corner coordinates of the screen to (`x`, `y`). Call `camera()` to reset the upper-left corner coordinates to (`0`, `0`).

- `pal(col1, col2)`&lt;br&gt;
  Replace color `col1` with `col2` when drawing. Call `pal()` to reset to the initial palette.

- `dither(alpha)`&lt;br&gt;
  Apply dithering (pseudo-transparency) when drawing. Set `alpha` in the range `0.0`-`1.0`, where `0.0` is transparent and `1.0` is opaque.

- `cls(col)`&lt;br&gt;
  Clear screen with color `col`.

- `pget(x, y)`&lt;br&gt;
  Get the color of the pixel at (`x`, `y`).

- `pset(x, y, col)`&lt;br&gt;
  Draw a pixel of color `col` at (`x`, `y`).

- `line(x1, y1, x2, y2, col)`&lt;br&gt;
  Draw a line of color `col` from (`x1`, `y1`) to (`x2`, `y2`).

- `rect(x, y, w, h, col)`&lt;br&gt;
  Draw a rectangle of width `w`, height `h` and color `col` from (`x`, `y`).

- `rectb(x, y, w, h, col)`&lt;br&gt;
  Draw the outline of a rectangle of width `w`, height `h` and color `col` from (`x`, `y`).

- `circ(x, y, r, col)`&lt;br&gt;
  Draw a circle of radius `r` and color `col` at (`x`, `y`).

- `circb(x, y, r, col)`&lt;br&gt;
  Draw the outline of a circle of radius `r` and color `col` at (`x`, `y`).

- `elli(x, y, w, h, col)`&lt;br&gt;
  Draw an ellipse of width `w`, height `h` and color `col` from (`x`, `y`).

- `ellib(x, y, w, h, col)`&lt;br&gt;
  Draw the outline of an ellipse of width `w`, height `h` and color `col` from (`x`, `y`).

- `tri(x1, y1, x2, y2, x3, y3, col)`&lt;br&gt;
  Draw a triangle with vertices (`x1`, `y1`), (`x2`, `y2`), (`x3`, `y3`) and color `col`.

- `trib(x1, y1, x2, y2, x3, y3, col)`&lt;br&gt;
  Draw the outline of a triangle with vertices (`x1`, `y1`), (`x2`, `y2`), (`x3`, `y3`) and color `col`.

- `fill(x, y, col)`&lt;br&gt;
  Fill the area connected with the same color as (`x`, `y`) with color `col`.

- `blt(x, y, img, u, v, w, h, [colkey], [rotate], [scale])`&lt;br&gt;
  Copy the region of size (`w`, `h`) from (`u`, `v`) of the image bank `img`(0-2) to (`x`, `y`). If a negative value is assigned to `w` and/or `h`, the region will be flipped horizontally and/or vertically. If `colkey` is specified, it will be treated as a transparent color. If `rotate`(in degrees), `scale`(1.0 = 100%), or both are specified, the corresponding transformations will be applied.

&lt;img src=&quot;docs/images/blt_figure.png&quot;&gt;

- `bltm(x, y, tm, u, v, w, h, [colkey], [rotate], [scale])`&lt;br&gt;
  Copy the region of size (`w`, `h`) from (`u`, `v`) of the tilemap `tm`(0-7) to (`x`, `y`). If a negative value is assigned to `w` and/or `h`, the region will be flipped horizontally and/or vertically. If `colkey` is specified, it will be treated as a transparent color. If `rotate`(in degrees), `scale`(1.0 = 100%), or both are specified, the corresponding transformations will be applied. The size of a tile is 8x8 pixels and is stored in a tilemap as a tuple of `(image_tx, image_ty)`.

&lt;img src=&quot;docs/images/bltm_figure.png&quot;&gt;

- `text(x, y, s, col)`&lt;br&gt;
  Draw a string `s` in color `col` at (`x`, `y`).

### Audio

- `sounds`&lt;br&gt;
  List of the sounds (instances of the Sound class) (0-63)&lt;br&gt;
  Example: `pyxel.sounds[0].speed = 60`

- `musics`&lt;br&gt;
  List of music tracks (instances of the Music class) (0-7)

- `play(ch, snd, [sec], [loop], [resume])`&lt;br&gt;
  Play the sound `snd`(0-63) on channel `ch`(0-3). `snd` can be a sound number, a list of sound numbers, or an MML string. The playback start position can be specified in seconds with `sec`. If `loop` is set to `True`, the sound will loop. To resume the previous sound after playback ends, set `resume` to `True`.

- `playm(msc, [sec], [loop])`&lt;br&gt;
  Play the music `msc`(0-7). The playback start position can be specified in seconds with `sec`. If `loop` is set to `True`, the music will loop.

- `stop([ch])`&lt;br&gt;
  Stop playback of the specified channel `ch`(0-3). Call `stop()` to stop all channels.

- `play_pos(ch)`&lt;br&gt;
  Get the sound playback position of channel `ch`(0-3) as a tuple of `(sound_no, sec)`. Return `None` when playback has stopped.

- `gen_bgm(preset, instr, [seed], [play])`&lt;br&gt;
  Generate a BGM MML list using an algorithm based on [8bit BGM generator](https://github.com/shiromofufactory/8bit-bgm-generator). `preset` is the preset number (0-7), `instr` is the instrumentation number (0-3): `0`=melody+reverb+bass, `1`=melody+bass+drums, `2`=melody+sub+bass, `3`=melody+sub+bass+drums. If `seed` is not specified, the result is random. If `play` is set to `True`, the generated MML is played.

### Math

- `ceil(x)`&lt;br&gt;
  Return the smallest integer that is greater than or equal to `x`.

- `floor(x)`&lt;br&gt;
  Return the largest integer that is less than or equal to `x`.

- `clamp(x, lower, upper)`&lt;br&gt;
  Return `x` clamped between `lower` as the minimum value and `upper` as the maximum value.

- `sgn(x)`&lt;br&gt;
  Return `1` when `x` is positive, `0` when it is `0`, and `-1` when it is negative.

- `sqrt(x)`&lt;br&gt;
  Return the square root of `x`.

- `sin(deg)`&lt;br&gt;
  Return the sine of `deg` degrees.

- `cos(deg)`&lt;br&gt;
  Return the cosine of `deg` degrees.

- `atan2(y, x)`&lt;br&gt;
  Return the arctangent of `y`/`x` in degrees.

- `rseed(seed)`&lt;br&gt;
  Set the seed of the random number generator.

- `rndi(a, b)`&lt;br&gt;
  Return a random integer greater than or equal to `a` and less than or equal to `b`.

- `rndf(a, b)`&lt;br&gt;
  Return a random floating-point number greater than or equal to `a` and less than or equal to `b`.

- `nseed(seed)`&lt;br&gt;
  Set the seed of Perlin noise.

- `noise(x, [y], [z])`&lt;br&gt;
  Return the Perlin noise value for the specified coordinates.

### Image Class

- `width`, `height`&lt;br&gt;
  The width and height of the imag

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lance-format/lance]]></title>
            <link>https://github.com/lance-format/lance</link>
            <guid>https://github.com/lance-format/lance</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:07 GMT</pubDate>
            <description><![CDATA[Open Lakehouse Format for Multimodal AI. Convert from Parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lance-format/lance">lance-format/lance</a></h1>
            <p>Open Lakehouse Format for Multimodal AI. Convert from Parquet in 2 lines of code for 100x faster random access, vector index, and data versioning. Compatible with Pandas, DuckDB, Polars, Pyarrow, and PyTorch with more integrations coming..</p>
            <p>Language: Rust</p>
            <p>Stars: 6,078</p>
            <p>Forks: 558</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;p align=&quot;center&quot;&gt;

&lt;img width=&quot;257&quot; alt=&quot;Lance Logo&quot; src=&quot;https://user-images.githubusercontent.com/917119/199353423-d3e202f7-0269-411d-8ff2-e747e419e492.png&quot;&gt;

**The Open Lakehouse Format for Multimodal AI**&lt;br/&gt;
**High-performance vector search, full-text search, random access, and feature engineering capabilities for the lakehouse.**&lt;br/&gt;
**Compatible with Pandas, DuckDB, Polars, PyArrow, Ray, Spark, and more integrations on the way.**

&lt;a href=&quot;https://lance.org&quot;&gt;Documentation&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://lance.org/community&quot;&gt;Community&lt;/a&gt; ‚Ä¢
&lt;a href=&quot;https://discord.gg/lance&quot;&gt;Discord&lt;/a&gt;

[CI]: https://github.com/lance-format/lance/actions/workflows/rust.yml
[CI Badge]: https://github.com/lance-format/lance/actions/workflows/rust.yml/badge.svg
[Docs]: https://lance.org
[Docs Badge]: https://img.shields.io/badge/docs-passing-brightgreen
[crates.io]: https://crates.io/crates/lance
[crates.io badge]: https://img.shields.io/crates/v/lance.svg
[Python versions]: https://pypi.org/project/pylance/
[Python versions badge]: https://img.shields.io/pypi/pyversions/pylance

[![CI Badge]][CI]
[![Docs Badge]][Docs]
[![crates.io badge]][crates.io]
[![Python versions badge]][Python versions]

&lt;/p&gt;
&lt;/div&gt;

&lt;hr /&gt;

Lance is an open lakehouse format for multimodal AI. It contains a file format, table format, and catalog spec that allows you to build a complete lakehouse on top of object storage to power your AI workflows. Lance is perfect for:

1. Building search engines and feature stores with hybrid search capabilities.
2. Large-scale ML training requiring high performance IO and random access.
3. Storing, querying, and managing multimodal data including images, videos, audio, text, and embeddings.

The key features of Lance include:

* **Expressive hybrid search:** Combine vector similarity search, full-text search (BM25), and SQL analytics on the same dataset with accelerated secondary indices.

* **Lightning-fast random access:** 100x faster than Parquet or Iceberg for random access without sacrificing scan performance.

* **Native multimodal data support:** Store images, videos, audio, text, and embeddings in a single unified format with efficient blob encoding and lazy loading.

* **Data evolution:** Efficiently add columns with backfilled values without full table rewrites, perfect for ML feature engineering.

* **Zero-copy versioning:** Automatic versioning with ACID transactions, time travel, tags, and branches‚Äîno extra infrastructure needed.

* **Rich ecosystem integrations:** Apache Arrow, Pandas, Polars, DuckDB, Apache Spark, Ray, Trino, Apache Flink, and open catalogs (Apache Polaris, Unity Catalog, Apache Gravitino).

For more details, see the full [Lance format specification](https://lance.org/format).

&gt; [!TIP]
&gt; Lance is in active development and we welcome contributions. Please see our [contributing guide](https://lance.org/community/contributing/) for more information.

## Quick Start

**Installation**

```shell
pip install pylance
```

To install a preview release:

```shell
pip install --pre --extra-index-url https://pypi.fury.io/lance-format/pylance
```

&gt; [!NOTE]
&gt; For versions prior to 1.0.0-beta.4, you can find them at https://pypi.fury.io/lancedb/pylance

&gt; [!TIP]
&gt; Preview releases are released more often than full releases and contain the
&gt; latest features and bug fixes. They receive the same level of testing as full releases.
&gt; We guarantee they will remain published and available for download for at
&gt; least 6 months. When you want to pin to a specific version, prefer a stable release.

**Converting to Lance**

```python
import lance

import pandas as pd
import pyarrow as pa
import pyarrow.dataset

df = pd.DataFrame({&quot;a&quot;: [5], &quot;b&quot;: [10]})
uri = &quot;/tmp/test.parquet&quot;
tbl = pa.Table.from_pandas(df)
pa.dataset.write_dataset(tbl, uri, format=&#039;parquet&#039;)

parquet = pa.dataset.dataset(uri, format=&#039;parquet&#039;)
lance.write_dataset(parquet, &quot;/tmp/test.lance&quot;)
```

**Reading Lance data**
```python
dataset = lance.dataset(&quot;/tmp/test.lance&quot;)
assert isinstance(dataset, pa.dataset.Dataset)
```

**Pandas**
```python
df = dataset.to_table().to_pandas()
df
```

**DuckDB**
```python
import duckdb

# If this segfaults, make sure you have duckdb v0.7+ installed
duckdb.query(&quot;SELECT * FROM dataset LIMIT 10&quot;).to_df()
```

**Vector search**

Download the sift1m subset

```shell
wget ftp://ftp.irisa.fr/local/texmex/corpus/sift.tar.gz
tar -xzf sift.tar.gz
```

Convert it to Lance

```python
import lance
from lance.vector import vec_to_table
import numpy as np
import struct

nvecs = 1000000
ndims = 128
with open(&quot;sift/sift_base.fvecs&quot;, mode=&quot;rb&quot;) as fobj:
    buf = fobj.read()
    data = np.array(struct.unpack(&quot;&lt;128000000f&quot;, buf[4 : 4 + 4 * nvecs * ndims])).reshape((nvecs, ndims))
    dd = dict(zip(range(nvecs), data))

table = vec_to_table(dd)
uri = &quot;vec_data.lance&quot;
sift1m = lance.write_dataset(table, uri, max_rows_per_group=8192, max_rows_per_file=1024*1024)
```

Build the index

```python
sift1m.create_index(&quot;vector&quot;,
                    index_type=&quot;IVF_PQ&quot;,
                    num_partitions=256,  # IVF
                    num_sub_vectors=16)  # PQ
```

Search the dataset

```python
# Get top 10 similar vectors
import duckdb

dataset = lance.dataset(uri)

# Sample 100 query vectors. If this segfaults, make sure you have duckdb v0.7+ installed
sample = duckdb.query(&quot;SELECT vector FROM dataset USING SAMPLE 100&quot;).to_df()
query_vectors = np.array([np.array(x) for x in sample.vector])

# Get nearest neighbors for all of them
rs = [dataset.to_table(nearest={&quot;column&quot;: &quot;vector&quot;, &quot;k&quot;: 10, &quot;q&quot;: q})
      for q in query_vectors]
```

## Directory structure

| Directory          | Description              |
|--------------------|--------------------------|
| [rust](./rust)     | Core Rust implementation |
| [python](./python) | Python bindings (PyO3)   |
| [java](./java)     | Java bindings (JNI)      |
| [docs](./docs)     | Documentation source     |

## Benchmarks

### Vector search

We used the SIFT dataset to benchmark our results with 1M vectors of 128D

1. For 100 randomly sampled query vectors, we get &lt;1ms average response time (on a 2023 m2 MacBook Air)

![avg_latency.png](docs/src/images/avg_latency.png)

2. ANNs are always a trade-off between recall and performance

![avg_latency.png](docs/src/images/recall_vs_latency.png)

### Vs. parquet

We create a Lance dataset using the Oxford Pet dataset to do some preliminary performance testing of Lance as compared to Parquet and raw image/XMLs. For analytics queries, Lance is 50-100x better than reading the raw metadata. For batched random access, Lance is 100x better than both parquet and raw files.

![](docs/src/images/lance_perf.png)

## Why Lance for AI/ML workflows?

The machine learning development cycle involves multiple stages:

```mermaid
graph LR
    A[Collection] --&gt; B[Exploration];
    B --&gt; C[Analytics];
    C --&gt; D[Feature Engineer];
    D --&gt; E[Training];
    E --&gt; F[Evaluation];
    F --&gt; C;
    E --&gt; G[Deployment];
    G --&gt; H[Monitoring];
    H --&gt; A;
```

Traditional lakehouse formats were designed for SQL analytics and struggle with AI/ML workloads that require:
- **Vector search** for similarity and semantic retrieval
- **Fast random access** for sampling and interactive exploration
- **Multimodal data** storage (images, videos, audio alongside embeddings)
- **Data evolution** for feature engineering without full table rewrites
- **Hybrid search** combining vectors, full-text, and SQL predicates

While existing formats (Parquet, Iceberg, Delta Lake) excel at SQL analytics, they require additional specialized systems for AI capabilities. Lance brings these AI-first features directly into the lakehouse format.

A comparison of different formats across ML development stages:

|                     | Lance | Parquet &amp; ORC | JSON &amp; XML | TFRecord | Database | Warehouse |
|---------------------|-------|---------------|------------|----------|----------|-----------|
| Analytics           | Fast  | Fast          | Slow       | Slow     | Decent   | Fast      |
| Feature Engineering | Fast  | Fast          | Decent     | Slow     | Decent   | Good      |
| Training            | Fast  | Decent        | Slow       | Fast     | N/A      | N/A       |
| Exploration         | Fast  | Slow          | Fast       | Slow     | Fast     | Decent    |
| Infra Support       | Rich  | Rich          | Decent     | Limited  | Rich     | Rich      |

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[farion1231/cc-switch]]></title>
            <link>https://github.com/farion1231/cc-switch</link>
            <guid>https://github.com/farion1231/cc-switch</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:06 GMT</pubDate>
            <description><![CDATA[A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/farion1231/cc-switch">farion1231/cc-switch</a></h1>
            <p>A cross-platform desktop All-in-One assistant tool for Claude Code, Codex, OpenCode & Gemini CLI.</p>
            <p>Language: Rust</p>
            <p>Stars: 19,760</p>
            <p>Forks: 1,232</p>
            <p>Stars today: 325 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# All-in-One Assistant for Claude Code, Codex &amp; Gemini CLI

[![Version](https://img.shields.io/badge/version-3.10.2-blue.svg)](https://github.com/farion1231/cc-switch/releases)
[![Platform](https://img.shields.io/badge/platform-Windows%20%7C%20macOS%20%7C%20Linux-lightgrey.svg)](https://github.com/farion1231/cc-switch/releases)
[![Built with Tauri](https://img.shields.io/badge/built%20with-Tauri%202-orange.svg)](https://tauri.app/)
[![Downloads](https://img.shields.io/endpoint?url=https://api.pinstudios.net/api/badges/downloads/farion1231/cc-switch/total)](https://github.com/farion1231/cc-switch/releases/latest)

&lt;a href=&quot;https://trendshift.io/repositories/15372&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15372&quot; alt=&quot;farion1231%2Fcc-switch | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

English | [‰∏≠Êñá](README_ZH.md) | [Êó•Êú¨Ë™û](README_JA.md) | [Changelog](CHANGELOG.md)

&lt;/div&gt;

## ‚ù§Ô∏èSponsor

[![MiniMax](assets/partners/banners/minimax-en.jpeg)](https://platform.minimax.io/subscribe/coding-plan?code=ClLhgxr2je&amp;source=link)

MiniMax-M2.5 is a SOTA large language model designed for real-world productivity. Trained in a diverse range of complex real-world digital working environments, M2.5 builds upon the coding expertise of M2.1 to extend into general office work, reaching fluency in generating and operating Word, Excel, and Powerpoint files, context switching between diverse software environments, and working across different agent and human teams. Scoring 80.2% on SWE-Bench Verified, 51.3% on Multi-SWE-Bench, and 76.3% on BrowseComp, M2.5 is also more token efficient than previous generations, having been trained to optimize its actions and output through planning.

[Click](https://platform.minimax.io/subscribe/coding-plan?code=ClLhgxr2je&amp;source=link) to get an exclusive 12% off the MiniMax Coding Plan!

---

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;&lt;img src=&quot;assets/partners/logos/packycode.png&quot; alt=&quot;PackyCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to PackyCode for sponsoring this project! PackyCode is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more. PackyCode provides special discounts for our software users: register using &lt;a href=&quot;https://www.packyapi.com/register?aff=cc-switch&quot;&gt;this link&lt;/a&gt; and enter the &quot;cc-switch&quot; promo code during first recharge to get 10% off.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/aigocode.png&quot; alt=&quot;AIGoCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AIGoCode for sponsoring this project! AIGoCode is an all-in-one platform that integrates Claude Code, Codex, and the latest Gemini models, providing you with stable, efficient, and highly cost-effective AI coding services. The platform offers flexible subscription plans, zero risk of account suspension, direct access with no VPN required, and lightning-fast responses. AIGoCode has prepared a special benefit for CC Switch users: if you register via &lt;a href=&quot;https://aigocode.com/invite/CC-SWITCH&quot;&gt;this link&lt;/a&gt;, you&#039;ll receive an extra 10% bonus credit on your first top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.aicodemirror.com/register?invitecode=9915W3&quot;&gt;&lt;img src=&quot;assets/partners/logos/aicodemirror.jpg&quot; alt=&quot;AICodeMirror&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AICodeMirror for sponsoring this project! AICodeMirror provides official high-stability relay services for Claude Code / Codex / Gemini CLI, with enterprise-grade concurrency, fast invoicing, and 24/7 dedicated technical support.
Claude Code / Codex / Gemini official channels at 38% / 2% / 9% of original price, with extra discounts on top-ups! AICodeMirror offers special benefits for CC Switch users: register via &lt;a href=&quot;https://www.aicodemirror.com/register?invitecode=9915W3&quot;&gt;this link&lt;/a&gt; to enjoy 20% off your first top-up, and enterprise customers can get up to 25% off!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://cubence.com/signup?code=CCSWITCH&amp;source=ccs&quot;&gt;&lt;img src=&quot;assets/partners/logos/cubence.png&quot; alt=&quot;Cubence&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to Cubence for sponsoring this project! Cubence is a reliable and efficient API relay service provider, offering relay services for Claude Code, Codex, Gemini, and more with flexible billing options including pay-as-you-go and monthly plans. Cubence provides special discounts for CC Switch users: register using &lt;a href=&quot;https://cubence.com/signup?code=CCSWITCH&amp;source=ccs&quot;&gt;this link&lt;/a&gt; and enter the &quot;CCSWITCH&quot; promo code during recharge to get 10% off every top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.dmxapi.cn/register?aff=bUHu&quot;&gt;&lt;img src=&quot;assets/partners/logos/dmx-en.jpg&quot; alt=&quot;DMXAPI&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to DMXAPI for sponsoring this project! DMXAPI provides global large model API services to 200+ enterprise users. One API key for all global models. Features include: instant invoicing, unlimited concurrency, starting from $0.15, 24/7 technical support. GPT/Claude/Gemini all at 32% off, domestic models 20-50% off, Claude Code exclusive models at 66% off! &lt;a href=&quot;https://www.dmxapi.cn/register?aff=bUHu&quot;&gt;Register here&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.right.codes/register?aff=CCSWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/rightcode.jpg&quot; alt=&quot;RightCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thank you to Right Code for sponsoring this project! Right Code reliably provides routing services for models such as Claude Code, Codex, and Gemini. It features a highly cost-effective Codex monthly subscription plan and &lt;strong&gt;supports quota rollovers‚Äîunused quota from one day can be carried over and used the next day.&lt;/strong&gt; Invoices are available upon top-up. Enterprise and team users can receive dedicated one-on-one support. Right Code also offers an exclusive discount for CC Switch users: register via &lt;a href=&quot;https://www.right.codes/register?aff=CCSWITCH&quot;&gt;this link&lt;/a&gt;, and with every top-up you will receive pay-as-you-go credit equivalent to 25% of the amount paid.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://aicoding.sh/i/CCSWITCH&quot;&gt;&lt;img src=&quot;assets/partners/logos/aicoding.jpg&quot; alt=&quot;AICoding&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to AICoding.sh for sponsoring this project! AICoding.sh ‚Äî Global AI Model API Relay Service at Unbeatable Prices! Claude Code at 19% of original price, GPT at just 1%! Trusted by hundreds of enterprises for cost-effective AI services. Supports Claude Code, GPT, Gemini and major domestic models, with enterprise-grade high concurrency, fast invoicing, and 24/7 dedicated technical support. CC Switch users who register via &lt;a href=&quot;https://aicoding.sh/i/CCSWITCH&quot;&gt;this link&lt;/a&gt; get 10% off their first top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://crazyrouter.com/register?aff=OZcm&amp;ref=cc-switch&quot;&gt;&lt;img src=&quot;assets/partners/logos/crazyrouter.jpg&quot; alt=&quot;AICoding&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to Crazyrouter for sponsoring this project! Crazyrouter is a high-performance AI API aggregation platform ‚Äî one API key for 300+ models including Claude Code, Codex, Gemini CLI, and more. All models at 55% of official pricing with auto-failover, smart routing, and unlimited concurrency. Crazyrouter offers an exclusive deal for CC Switch users: register via &lt;a href=&quot;https://crazyrouter.com/register?aff=OZcm&amp;ref=cc-switch&quot;&gt;this link&lt;/a&gt;  to get &lt;strong&gt;$2 free credit&lt;/strong&gt; instantly, plus enter promo code `CCSWITCH` on your first top-up for an extra &lt;strong&gt;30% bonus credit&lt;/strong&gt;! &lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;180&quot;&gt;&lt;a href=&quot;https://www.sssaicode.com/register?ref=DCP0SM&quot;&gt;&lt;img src=&quot;assets/partners/logos/sssaicode.png&quot; alt=&quot;SSSAiCode&quot; width=&quot;150&quot;&gt;&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;Thanks to SSSAiCode for sponsoring this project! SSSAiCode is a stable and reliable API relay service, dedicated to providing stable, reliable, and affordable Claude and Codex model services, &lt;strong&gt;offering high cost-effective official Claude service at just ¬•0.5/$ equivalent&lt;/strong&gt;, supporting monthly and pay-as-you-go billing plans with same-day fast invoicing. SSSAiCode offers a special deal for CC Switch users: register via &lt;a href=&quot;https://www.sssaicode.com/register?ref=DCP0SM&quot;&gt;this link&lt;/a&gt; to enjoy $10 extra credit on every top-up!&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

## Screenshots

|                  Main Interface                   |                  Add Provider                  |
| :-----------------------------------------------: | :--------------------------------------------: |
| ![Main Interface](assets/screenshots/main-en.png) | ![Add Provider](assets/screenshots/add-en.png) |

## Features

### Current Version: v3.10.2 | [Full Changelog](CHANGELOG.md) | [Release Notes](docs/release-note-v3.9.0-en.md)

**v3.8.0 Major Update (2025-11-28)**

**Persistence Architecture Upgrade &amp; Brand New UI**

- **SQLite + JSON Dual-layer Architecture**
  - Migrated from JSON file storage to SQLite + JSON dual-layer structure
  - Syncable data (providers, MCP, Prompts, Skills) stored in SQLite
  - Device-level data (window state, local paths) stored in JSON
  - Lays the foundation for future cloud sync functionality
  - Schema version management for database migrations

- **Brand New User Interface**
  - Completely redesigned interface layout
  - Unified component styles and smoother animations
  - Optimized visual hierarchy
  - Tailwind CSS downgraded from v4 to v3.4 for better browser compatibility

- **Japanese Language Support**
  - Added Japanese interface support (now supports Chinese/English/Japanese)

- **Auto Launch on Startup**
  - One-click enable/disable in settings
  - Platform-native APIs (Registry/LaunchAgent/XDG autostart)

- **Skills Recursive Scanning**
  - Support for multi-level directory structures
  - Allow same-named skills from different repositories

- **Critical Bug Fixes**
  - Fixed custom endpoints lost when updating providers
  - Fixed Gemini configuration write issues
  - Fixed Linux WebKitGTK rendering issues

**v3.7.0 Highlights**

**Six Core Features, 18,000+ Lines of New Code**

- **Gemini CLI Integration**
  - Third supported AI CLI (Claude Code / Codex / Gemini)
  - Dual-file configuration support (`.env` + `settings.json`)
  - Complete MCP server management
  - Presets: Google Official (OAuth) / PackyCode / Custom

- **Claude Skills Management System**
  - Auto-scan skills from GitHub repositories (3 pre-configured curated repos)
  - One-click install/uninstall to `~/.claude/skills/`
  - Custom repository support + subdirectory scanning
  - Complete lifecycle management (discover/install/update)

- **Prompts Management System**
  - Multi-preset system prompt management (unlimited presets, quick switching)
  - Cross-app support (Claude: `CLAUDE.md` / Codex: `AGENTS.md` / Gemini: `GEMINI.md`)
  - Markdown editor (CodeMirror 6 + real-time preview)
  - Smart backfill protection, preserves manual modifications

- **MCP v3.7.0 Unified Architecture**
  - Single panel manages MCP servers across three applications
  - New SSE (Server-Sent Events) transport type
  - Smart JSON parser + Codex TOML format auto-correction
  - Unified import/export + bidirectional sync

- **Deep Link Protocol**
  - `ccswitch://` protocol registration (all platforms)
  - One-click import provider configs via shared links
  - Security validation + lifecycle integration

- **Environment Variable Conflict Detection**
  - Auto-detect cross-app configuration conflicts (Claude/Codex/Gemini/MCP)
  - Visual conflict indicators + resolution suggestions
  - Override warnings + backup before changes

**Core Capabilities**

- **Provider Management**: One-click switching between Claude Code, Codex, and Gemini API configurations
- **AWS Bedrock Support**: Built-in AWS Bedrock provider presets with AKSK and API Key authentication, cross-region inference support (global/us/eu/apac), covering Claude Code and OpenCode
- **Speed Testing**: Measure API endpoint latency with visual quality indicators
- **Import/Export**: Backup and restore configs with auto-rotation (keep 10 most recent)
- **i18n Support**: Complete Chinese/English localization (UI, errors, tray)
- **Claude Plugin Sync**: One-click apply/restore Claude plugin configurations

**v3.6 Highlights**

- Provider duplication &amp; drag-and-drop sorting
- Multi-endpoint management &amp; custom config directory (cloud sync ready)
- Granular model configuration (4-tier: Haiku/Sonnet/Opus/Custom)
- WSL environment support with auto-sync on directory change
- 100% hooks test coverage &amp; complete architecture refactoring

**System Features**

- System tray with quick switching
- Single instance daemon
- Built-in auto-updater
- Atomic writes with rollback protection

## Download &amp; Installation

### System Requirements

- **Windows**: Windows 10 and above
- **macOS**: macOS 10.15 (Catalina) and above
- **Linux**: Ubuntu 22.04+ / Debian 11+ / Fedora 34+ and other mainstream distributions

### Windows Users

Download the latest `CC-Switch-v{version}-Windows.msi` installer or `CC-Switch-v{version}-Windows-Portable.zip` portable version from the [Releases](../../releases) page.

### macOS Users

**Method 1: Install via Homebrew (Recommended)**

```bash
brew tap farion1231/ccswitch
brew install --cask cc-switch
```

Update:

```bash
brew upgrade --cask cc-switch
```

**Method 2: Manual Download**

Download `CC-Switch-v{version}-macOS.zip` from the [Releases](../../releases) page and extract to use.

&gt; **Note**: Since the author doesn&#039;t have an Apple Developer account, you may see an &quot;unidentified developer&quot; warning on first launch. Please close it first, then go to &quot;System Settings&quot; ‚Üí &quot;Privacy &amp; Security&quot; ‚Üí click &quot;Open Anyway&quot;, and you&#039;ll be able to open it normally afterwards.

### Arch Linux Users

**Install via paru (Recommended)**

```bash
paru -S cc-switch-bin
```

### Linux Users

Download the latest Linux build from the [Releases](../../releases) page:

- `CC-Switch-v{version}-Linux.deb` (Debian/Ubuntu)
- `CC-Switch-v{version}-Linux.rpm` (Fedora/RHEL/openSUSE)
- `CC-Switch-v{version}-Linux.AppImage` (Universal)
- `CC-Switch-v{version}-Linux.flatpak` (Flatpak)

Flatpak install &amp; run:

```bash
flatpak install --user ./CC-Switch-v{version}-Linux.flatpak
flatpak run com.ccswitch.desktop
```

## Quick Start

### Basic Usage

1. **Add Provider**: Click &quot;Add Provider&quot; ‚Üí Choose preset or create custom configuration
2. **Switch Provider**:
   - Main UI: Select provider ‚Üí Click &quot;Enable&quot;
   - System Tray: Click provider name directly (instant effect)
3. **Takes Effect**: Restart your terminal or Claude Code / Codex / Gemini clients to apply changes
4. **Back to Official**: Select the &quot;Official Login&quot; preset (Claude/Codex) or &quot;Google Official&quot; preset (Gemini), restart the corresponding client, then follow its login/OAuth flow

### MCP Management

- **Location**: Click &quot;MCP&quot; button in top-right corner
- **Add Server**:
  - Use built-in templates (mcp-fetch, mcp-filesystem, etc.)
  - Support stdio / http / sse transport types
  - Configure independent MCP servers for different apps
- **Enable/Disable**: Toggle switches to control which servers sync to live config
- **Sync**: Enabled servers auto-sync to each app&#039;s live files
- **Import/Export**: Import existing MCP servers from Claude/Codex/Gemini config files

### Skills Management (v3.7.0 New)

- **Location**: Click &quot;Skills&quot; button in top-right corner
- **Discover Skills**:
  - Auto-scan pre-configured GitHub repositories (Anthropic official, ComposioHQ, community, etc.)
  - Add custom repositories (supports subdirectory scanning)
- **Install Skills**: Click &quot;Install&quot; to one-click install to `~/.claude/skills/`
- **Uninstall Skills**: Click &quot;Uninstall&quot; to safely remove and clean up state
- **Manage Repositories**: Add/remove custom GitHub repositories

### Prompts Management (v3.7.0 New)

- **Location**: Click &quot;Prompts&quot; button in top-right corner
- **Create Presets**:
  - Create unlimited system prompt presets
  - Use Markdown editor to write prompts (syntax highlighting + real-time preview)
- **Switch Presets**: Select preset ‚Üí Click &quot;Activate&quot; to apply immediately
- **Sync Mechanism**:
  - Claude: `~/.claude/CLAUDE.md`
  - Codex: `~/.codex/AGENTS.md`
  - Gemini: `~/.gemini/GEMINI.md`
- **Protection Mechanism**: Auto-save current prompt content before switching, preserves manual modifications

### Configuration Files

**Claude Code**

- Live config: `~/.claude/settings.json` (or `claude.json`)
- API key field: `env.ANTHROPIC_AUTH_TOKEN` or `env.ANTHROPIC_API_KEY`
- MCP servers: `~/.claude.json` ‚Üí `mcpServers`

**Codex**

- Live config: `~/.codex/auth.json` (required) + `config.toml` (optional)
- API key field: `OPENAI_API_KEY` in `auth.json`
- MCP servers: `~/.codex/config.toml` ‚Üí `[mcp_servers]` tables

**Gemini**

- Live config: `~/.gemini/.env` (API key) + `~/.gemini/settings.json` (auth mode)
- API key field: `GEMINI_API_KEY` or `GOOGLE_GEMINI_API_KEY` in `.env`
- Environment variables: Support `GOOGLE_GEMINI_BASE_URL`, `GEMINI_MODEL`, etc.
- MCP servers: `~/.gemini/settings.json` ‚Üí `mcpServers`
- Tray quick switch: Each provider switch rewrites `~/.gemini/.env`, no need to restart Gemini CLI

**CC Switch Storage (v3.8.0 New Architecture)**

- Database (SSOT): `~/.cc-switch/cc-switch.db` (SQLite, stores providers, MCP, Prompts, Skills)
- Local settings: `~/.cc-switch/settings.json` (device-level settings)
- Backups: `~/.cc-switch/backups/` (auto-rotate, keep 10)

### Cloud Sync Setup

1. Go to Settings ‚Üí &quot;Custom Configuration Directory&quot;
2. Choose your cloud sync folder (Dropbox, OneDrive, iCloud, etc.)
3. Restart app to apply
4. Repeat on other devices to enable cross-device sync

&gt; **Note**: First launch auto-imports existing Claude/Codex configs as default provider.

## Architecture Overview

### Design Principles

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Frontend (React + TS)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ Components  ‚îÇ  ‚îÇ    Hooks     ‚îÇ  ‚îÇ  TanStack Query  ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ   (UI)      ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Logic) ‚îÇ‚îÄ‚îÄ‚îÇ   (Cache/Sync)   ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ Tauri IPC
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  Backend (Tauri + Rust)                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îÇ
‚îÇ  ‚îÇ  Commands   ‚îÇ  ‚îÇ   Services   ‚îÇ  ‚îÇ  Models/Config   ‚îÇ    ‚îÇ
‚îÇ  ‚îÇ (API Layer) ‚îÇ‚îÄ‚îÄ‚îÇ (Bus. Layer) ‚îÇ‚îÄ‚îÄ‚îÇ     (Data)       ‚îÇ    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Core Design Patterns**

- **SSOT** (Single Source of Truth): All data stored in `~/.cc-switch/cc-switch.db` (SQLite)
- **Dual-layer Storage**: SQLite for syncable data, JSON for device-level settings
- **Dual-way Sync**: Write to live files on switch, backfill from live when editing active provider
- **Atomic Writes**: Temp file + rename pattern prevents config corruption
- **Concurrency Safe**: Mutex-protected database connection avoids race conditions
- **Layered Architecture**: Clear separation (Commands ‚Üí Services ‚Üí DAO ‚Üí Database)

**Key Components**

- **ProviderService**: Provider CRUD, switching, backfill, sorting
- **McpService**: MCP server management, import/export, live file sync
- **ConfigService**: Config import/export, backup rotation
- **SpeedtestService**: API endpoint latency measurement

**v3.6 Refactoring**

- Backend: 5-phase refactoring (error handling ‚Üí command split ‚Üí tests ‚Üí services ‚Üí concurrency)
- Frontend: 4-stage refactoring (test infra ‚Üí hooks ‚Üí components ‚Üí cleanup)
- Testing: 100% hooks coverage + integration tests (vitest + MSW)

## Development

### Environment Requirements

- Node.js 18+
- pnpm 8+
- Rust 1.85+
- Tauri CLI 2.8+

### D

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[paradigmxyz/reth]]></title>
            <link>https://github.com/paradigmxyz/reth</link>
            <guid>https://github.com/paradigmxyz/reth</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:05 GMT</pubDate>
            <description><![CDATA[Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol, in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paradigmxyz/reth">paradigmxyz/reth</a></h1>
            <p>Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol, in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 5,432</p>
            <p>Forks: 2,306</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># reth

[![bench status](https://github.com/paradigmxyz/reth/actions/workflows/bench.yml/badge.svg)](https://github.com/paradigmxyz/reth/actions/workflows/bench.yml)
[![CI status](https://github.com/paradigmxyz/reth/workflows/unit/badge.svg)][gh-ci]
[![cargo-lint status](https://github.com/paradigmxyz/reth/actions/workflows/lint.yml/badge.svg)][gh-lint]
[![Telegram Chat][tg-badge]][tg-url]

**Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol**

![](./assets/reth-prod.png)

**[Install](https://paradigmxyz.github.io/reth/installation/installation.html)**
| [User Docs](https://reth.rs)
| [Developer Docs](./docs)
| [Crate Docs](https://reth.rs/docs)

[gh-ci]: https://github.com/paradigmxyz/reth/actions/workflows/unit.yml
[gh-lint]: https://github.com/paradigmxyz/reth/actions/workflows/lint.yml
[tg-badge]: https://img.shields.io/endpoint?color=neon&amp;logo=telegram&amp;label=chat&amp;url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Fparadigm%5Freth

&gt; **Note: OP-Reth has moved**
&gt;
&gt; The Optimism (op-reth) crates have been moved to [ethereum-optimism/optimism](https://github.com/ethereum-optimism/optimism).
&gt; Git contribution history has been preserved. If you are looking for op-reth, please see the new repository.

## What is Reth?

Reth (short for Rust Ethereum, [pronunciation](https://x.com/kelvinfichter/status/1597653609411268608)) is a new Ethereum full node implementation that is focused on being user-friendly, highly modular, as well as being fast and efficient. Reth is an Execution Layer (EL) and is compatible with all Ethereum Consensus Layer (CL) implementations that support the [Engine API](https://github.com/ethereum/execution-apis/tree/a0d03086564ab1838b462befbc083f873dcf0c0f/src/engine). It is originally built and driven forward by [Paradigm](https://paradigm.xyz/), and is licensed under the Apache and MIT licenses.

## Goals

As a full Ethereum node, Reth allows users to connect to the Ethereum network and interact with the Ethereum blockchain. This includes sending and receiving transactions/logs/traces, as well as accessing and interacting with smart contracts. Building a successful Ethereum node requires creating a high-quality implementation that is both secure and efficient, as well as being easy to use on consumer hardware. It also requires building a strong community of contributors who can help support and improve the software.

More concretely, our goals are:

1. **Modularity**: Every component of Reth is built to be used as a library: well-tested, heavily documented and benchmarked. We envision that developers will import the node&#039;s crates, mix and match, and innovate on top of them. Examples of such usage include but are not limited to spinning up standalone P2P networks, talking directly to a node&#039;s database, or &quot;unbundling&quot; the node into the components you need. To achieve that, we are licensing Reth under the Apache/MIT permissive license. You can learn more about the project&#039;s components [here](./docs/repo/layout.md).
2. **Performance**: Reth aims to be fast, so we use Rust and the [Erigon staged-sync](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) node architecture. We also use our Ethereum libraries (including [Alloy](https://github.com/alloy-rs/alloy/) and [revm](https://github.com/bluealloy/revm/)) which we&#039;ve battle-tested and optimized via [Foundry](https://github.com/foundry-rs/foundry/).
3. **Free for anyone to use any way they want**: Reth is free open source software, built for the community, by the community. By licensing the software under the Apache/MIT license, we want developers to use it without being bound by business licenses, or having to think about the implications of GPL-like licenses.
4. **Client Diversity**: The Ethereum protocol becomes more antifragile when no node implementation dominates. This ensures that if there&#039;s a software bug, the network does not finalize a bad block. By building a new client, we hope to contribute to Ethereum&#039;s antifragility.
5. **Support as many EVM chains as possible**: We aspire that Reth can full-sync not only Ethereum, but also other chains like Optimism, Polygon, BNB Smart Chain, and more. If you&#039;re working on any of these projects, please reach out. Note: OP-Reth has moved to [ethereum-optimism/optimism](https://github.com/ethereum-optimism/optimism).
6. **Configurability**: We want to solve for node operators that care about fast historical queries, but also for hobbyists who cannot operate on large hardware. We also want to support teams and individuals who want both sync from genesis and via &quot;fast sync&quot;. We envision that Reth will be configurable enough and provide configurable &quot;profiles&quot; for the tradeoffs that each team faces.

## Status

Reth is production ready, and suitable for usage in mission-critical environments such as staking or high-uptime services. We also actively recommend professional node operators to switch to Reth in production for performance and cost reasons in use cases where high performance with great margins is required such as RPC, MEV, Indexing, Simulations, and P2P activities.

More historical context below:

- We released 1.0 &quot;production-ready&quot; stable Reth in June 2024.
  - Reth completed an audit with [Sigma Prime](https://sigmaprime.io/), the developers of [Lighthouse](https://github.com/sigp/lighthouse), the Rust Consensus Layer implementation. Find it [here](./audit/sigma_prime_audit_v2.pdf).
  - Revm (the EVM used in Reth) underwent an audit with [Guido Vranken](https://x.com/guidovranken) (#1 [Ethereum Bug Bounty](https://ethereum.org/en/bug-bounty)). We will publish the results soon.
- We released multiple iterative beta versions, up to [beta.9](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.9) on Monday June 3, 2024, the last beta release.
- We released [beta](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) on Monday March 4, 2024, our first breaking change to the database model, providing faster query speed, smaller database footprint, and allowing &quot;history&quot; to be mounted on separate drives.
- We shipped iterative improvements until the last alpha release on February 28, 2024, [0.1.0-alpha.21](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.21).
- We [initially announced](https://www.paradigm.xyz/2023/06/reth-alpha) [0.1.0-alpha.1](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.1) on June 20, 2023.

### Database compatibility

We do not have any breaking database changes since beta.1, and we do not plan any in the near future.

Reth [v0.2.0-beta.1](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) includes
a [set of breaking database changes](https://github.com/paradigmxyz/reth/pull/5191) that makes it impossible to use database files produced by earlier versions.

If you had a database produced by alpha versions of Reth, you need to drop it with `reth db drop`
(using the same arguments such as `--config` or `--datadir` that you passed to `reth node`), and resync using the same `reth node` command you&#039;ve used before.

## For Users

See the [Reth documentation](https://reth.rs/) for instructions on how to install and run Reth.

## For Developers

### Using reth as a library

You can use individual crates of reth in your project.

The crate docs can be found [here](https://reth.rs/docs/).

For a general overview of the crates, see [Project Layout](./docs/repo/layout.md).

### Contributing

If you want to contribute, or follow along with contributor discussion, you can use our [main telegram](https://t.me/paradigm_reth) to chat with us about the development of Reth!

- Our contributor guidelines can be found in [`CONTRIBUTING.md`](./CONTRIBUTING.md).
- See our [contributor docs](./docs) for more information on the project. A good starting point is [Project Layout](./docs/repo/layout.md).

### Building and testing

&lt;!--
When updating this, also update:
- Cargo.toml
- .github/workflows/lint.yml
--&gt;

The Minimum Supported Rust Version (MSRV) of this project is [1.93.0](https://blog.rust-lang.org/2026/01/22/Rust-1.93.0/).

See the docs for detailed instructions on how to [build from source](https://reth.rs/installation/source/).

To fully test Reth, you will need to have [Geth installed](https://geth.ethereum.org/docs/getting-started/installing-geth), but it is possible to run a subset of tests without Geth.

First, clone the repository:

```sh
git clone https://github.com/paradigmxyz/reth
cd reth
```

Next, run the tests:

```sh
cargo nextest run --workspace

# Run the Ethereum Foundation tests
make ef-tests
```

We highly recommend using [`cargo nextest`](https://nexte.st/) to speed up testing.
Using `cargo test` to run tests may work fine, but this is not tested and does not support more advanced features like retries for spurious failures.

&gt; **Note**
&gt;
&gt; Some tests use random number generators to generate test data. If you want to use a deterministic seed, you can set the `SEED` environment variable.

## Getting Help

If you have any questions, first see if the answer to your question can be found in the [docs][book].

If the answer is not there:

- Join the [Telegram][tg-url] to get help, or
- Open a [discussion](https://github.com/paradigmxyz/reth/discussions/new) with your question, or
- Open an issue with [the bug](https://github.com/paradigmxyz/reth/issues/new?assignees=&amp;labels=C-bug%2CS-needs-triage&amp;projects=&amp;template=bug.yml)

## Security

See [`SECURITY.md`](./SECURITY.md).

## Acknowledgements

Reth is a new implementation of the Ethereum protocol. In the process of developing the node we investigated the design decisions other nodes have made to understand what is done well, what is not, and where we can improve the status quo.

None of this would have been possible without them, so big shoutout to the teams below:

- [Geth](https://github.com/ethereum/go-ethereum/): We would like to express our heartfelt gratitude to the go-ethereum team for their outstanding contributions to Ethereum over the years. Their tireless efforts and dedication have helped to shape the Ethereum ecosystem and make it the vibrant and innovative community it is today. Thank you for your hard work and commitment to the project.
- [Erigon](https://github.com/ledgerwatch/erigon) (fka Turbo-Geth): Erigon pioneered the [&quot;Staged Sync&quot; architecture](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) that Reth is using, as well as [introduced MDBX](https://github.com/ledgerwatch/erigon/wiki/Choice-of-storage-engine) as the database of choice. We thank Erigon for pushing the state of the art research on the performance limits of Ethereum nodes.
- [Akula](https://github.com/akula-bft/akula/): Reth uses forks of the Apache versions of Akula&#039;s [MDBX Bindings](https://github.com/paradigmxyz/reth/pull/132), [FastRLP](https://github.com/paradigmxyz/reth/pull/63) and [ECIES](https://github.com/paradigmxyz/reth/pull/80). Given that these packages were already released under the Apache License, and they implement standardized solutions, we decided not to reimplement them to iterate faster. We thank the Akula team for their contributions to the Rust Ethereum ecosystem and for publishing these packages.

## Warning

The `NippyJar` and `Compact` encoding formats and their implementations are designed for storing and retrieving data internally. They are not hardened to safely read potentially malicious data.

[book]: https://reth.rs/
[tg-url]: https://t.me/paradigm_reth
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cube-js/cube]]></title>
            <link>https://github.com/cube-js/cube</link>
            <guid>https://github.com/cube-js/cube</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:04 GMT</pubDate>
            <description><![CDATA[üìä Cube Core is open-source semantic layer for AI, BI and embedded analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cube-js/cube">cube-js/cube</a></h1>
            <p>üìä Cube Core is open-source semantic layer for AI, BI and embedded analytics</p>
            <p>Language: Rust</p>
            <p>Stars: 19,536</p>
            <p>Forks: 1,962</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>![]()
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cube.dev?ref=github-readme&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/cube-js/cube/master/docs/content/cube-core-logo.png&quot; alt=&quot;Cube Core ‚Äî Open-Source Semantic Layer&quot; width=&quot;300px&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;br/&gt;

[Website](https://cube.dev?ref=github-readme) ‚Ä¢ [Docs](https://cube.dev/docs?ref=github-readme) ‚Ä¢ [Examples](https://cube.dev/docs/examples?ref=github-readme) ‚Ä¢ [Blog](https://cube.dev/blog?ref=github-readme) ‚Ä¢ [Slack](https://slack.cube.dev?ref=github-readme) ‚Ä¢ [X](https://twitter.com/the_cube_dev)

[![npm version](https://badge.fury.io/js/%40cubejs-backend%2Fserver.svg)](https://badge.fury.io/js/%40cubejs-backend%2Fserver)
[![GitHub Actions](https://github.com/cube-js/cube/workflows/Build/badge.svg)](https://github.com/cube-js/cube/actions?query=workflow%3ABuild+branch%3Amaster)
[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js.svg?type=shield)](https://app.fossa.io/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js?ref=badge_shield)

__Cube Core is an open-source semantic layer.__ Cube Core can be used to build embedded analytics in your applications, create your own business intelligence tool or provide context about data to AI agents. Cube Core is headless and comes with multiple APIs for embedded analytics and BI: REST, GraphQL, and SQL.

If you are looking for a fully integrated platform, check out [Cube](https://cube.dev), a modern AI-first business intelligence platform. We use Cube Core to power it.

&lt;img
  src=&quot;https://lgo0ecceic.ucarecd.net/418db1f9-7597-4e00-8c10-eba19fcac20f/&quot;
  style=&quot;border: none&quot;
  width=&quot;100%&quot;
/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Learn more about connecting Cube to &lt;a href=&quot;https://cube.dev/docs/config/databases?ref=github-readme&quot; target=&quot;_blank&quot;&gt;data sources&lt;/a&gt; and &lt;a href=&quot;https://cube.dev/docs/config/downstream?ref=github-readme&quot; target=&quot;_blank&quot;&gt;analytics &amp; visualization tools&lt;/a&gt;.&lt;/i&gt;
&lt;/p&gt;

Cube Core was designed to work with all SQL data sources, including cloud data warehouses like Snowflake, Databricks, and BigQuery; query engines like Presto and Amazon Athena; and application databases like Postgres. Cube Core has a built-in relational caching engine to provide sub-second latency and high concurrency for API requests.

## Why Cube Core?

Every business intelligence tool relies on a semantic layer as its core engine‚Äîa critical component that defines metrics, dimensions, and business logic while abstracting the complexity of underlying data sources. However, most semantic layers are proprietary, tightly coupled to specific BI platforms, and cannot be reused across different applications.

Cube Core is an open-source project that aims to create an open, modern semantic layer that can be used to power any analytics applications and AI agents. By decoupling the semantic layer from specific tools and making it accessible through standard APIs, Cube Core enables organizations to define their metrics once and use them everywhere‚Äîfrom BI tools to embedded analytics to AI agents.

## Getting Started üöÄ

You can get started with Cube locally or self-host it with [Docker](https://www.docker.com/).

Once Docker is installed, in a new folder for your project, run the following command:

```bash
docker run -p 4000:4000 \
  -p 15432:15432 \
  -v ${PWD}:/cube/conf \
  -e CUBEJS_DEV_MODE=true \
  cubejs/cube
```

Then, open http://localhost:4000 in your browser to continue setup.

For a step-by-step guide, [see the docs](https://cube.dev/docs/getting-started-docker?ref=github-readme).

### Cube ‚Äî Complete Modern BI Tool from Cube Core Creators

[Cube](https://cube.dev?ref=github-readme) is a complete modern agentic analytics platform built on Cube Core. It provides a fully integrated solution with a user-friendly interface, advanced analytics capabilities, and managed infrastructure.

&lt;a href=&quot;https://cubecloud.dev/auth/signup?ref=github-readme&quot;&gt;&lt;img src=&quot;https://cubedev-blog-images.s3.us-east-2.amazonaws.com/f1f1eac0-0b44-4c47-936e-33b5c06eedf0.png&quot; alt=&quot;Get started now&quot; width=&quot;200px&quot;&gt;&lt;/a&gt;

## Resources

- [Documentation](https://cube.dev/docs?ref=github-readme)
- [Getting Started](https://cube.dev/docs/getting-started?ref=github-readme)
- [Examples &amp; Tutorials](https://cube.dev/docs/examples?ref=github-readme)
- [Architecture](https://cube.dev/docs/product/introduction#four-layers-of-semantic-layer)

## Contributing

There are many ways you can contribute to Cube Core! Here are a few possibilities:

* Star this repo and follow us on [X](https://twitter.com/the_cube_dev).
* Add Cube to your stack on [Stackshare](https://stackshare.io/cube-js).
* Upvote issues with üëç reaction so we know what the demand is for particular issues to prioritize them within the roadmap.
* Create issues every time you feel something is missing or goes wrong.
* Ask questions on [Stack Overflow with cube.js tag](https://stackoverflow.com/questions/tagged/cube.js) if others might have these questions as well.
* Provide pull requests for all open issues and especially for those with [help wanted](https://github.com/cube-js/cube/issues?q=is%3Aissue+is%3Aopen+label%3A&quot;help+wanted&quot;) and [good first issue](https://github.com/cube-js/cube/issues?q=is%3Aissue+is%3Aopen+label%3A&quot;good+first+issue&quot;) labels.

All sorts of contributions are **welcome and extremely helpful** üôå Please refer to [the contribution guide](https://github.com/cube-js/cube/blob/master/CONTRIBUTING.md) for more information.

## License

Cube Client is [MIT licensed](./packages/cubejs-client-core/LICENSE).

Cube Backend is [Apache 2.0 licensed](./packages/cubejs-server/LICENSE).


[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fcube-js%2Fcube.js?ref=badge_large)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ai-dynamo/dynamo]]></title>
            <link>https://github.com/ai-dynamo/dynamo</link>
            <guid>https://github.com/ai-dynamo/dynamo</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:03 GMT</pubDate>
            <description><![CDATA[A Datacenter Scale Distributed Inference Serving Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo</a></h1>
            <p>A Datacenter Scale Distributed Inference Serving Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 6,127</p>
            <p>Forks: 876</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: Copyright (c) 2024-2026 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

![Dynamo banner](./docs/assets/img/frontpage-banner.png)

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)
[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ) ![Community Contributors](https://img.shields.io/badge/community_contributors-70%2B-brightgreen)

| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/5506)** | **[Support Matrix](https://github.com/ai-dynamo/dynamo/blob/main/docs/pages/reference/support-matrix.md)** | **[Docs](https://docs.nvidia.com/dynamo/)** | **[Recipes](https://github.com/ai-dynamo/dynamo/tree/main/recipes)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Prebuilt Containers](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** | **[Blogs](https://developer.nvidia.com/blog/tag/nvidia-dynamo)**

# NVIDIA Dynamo

High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.

## Why Dynamo

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/assets/img/frontpage-gpu-vertical.png&quot; alt=&quot;Multi Node Multi-GPU topology&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Large language models exceed single-GPU capacity. Tensor parallelism spreads layers across GPUs but creates coordination challenges. Dynamo closes this orchestration gap.

Dynamo is inference engine agnostic (supports TRT-LLM, vLLM, SGLang) and provides:

- **Disaggregated Prefill &amp; Decode** ‚Äì Maximizes GPU throughput with latency/throughput trade-offs
- **Dynamic GPU Scheduling** ‚Äì Optimizes performance based on fluctuating demand
- **LLM-Aware Request Routing** ‚Äì Eliminates unnecessary KV cache re-computation
- **Accelerated Data Transfer** ‚Äì Reduces inference response time using NIXL
- **KV Cache Offloading** ‚Äì Leverages multiple memory hierarchies for higher throughput

Built in Rust for performance and Python for extensibility, Dynamo is fully open-source with an OSS-first development approach.

## Backend Feature Support

| | [SGLang](docs/pages/backends/sglang/README.md) | [TensorRT-LLM](docs/pages/backends/trtllm/README.md) | [vLLM](docs/pages/backends/vllm/README.md) |
|---|:----:|:----------:|:--:|
| **Best For** | High-throughput serving | Maximum performance | Broadest feature coverage |
| [**Disaggregated Serving**](docs/pages/design-docs/disagg-serving.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**KV-Aware Routing**](docs/pages/components/router/README.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**SLA-Based Planner**](docs/pages/components/planner/planner-guide.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**KVBM**](docs/pages/components/kvbm/README.md) | üöß | ‚úÖ | ‚úÖ |
| [**Multimodal**](docs/pages/features/multimodal/README.md) | ‚úÖ | ‚úÖ | ‚úÖ |
| [**Tool Calling**](docs/pages/agents/tool-calling.md) | ‚úÖ | ‚úÖ | ‚úÖ |

&gt; **[Full Feature Matrix ‚Üí](docs/pages/reference/feature-matrix.md)** ‚Äî Detailed compatibility including LoRA, Request Migration, Speculative Decoding, and feature interactions.

## Dynamo Architecture

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/assets/img/frontpage-architecture.png&quot; alt=&quot;Dynamo architecture&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

&gt; **[Architecture Deep Dive ‚Üí](docs/pages/design-docs/architecture.md)**

## Latest News

- [12/05] [Moonshot AI&#039;s Kimi K2 achieves 10x inference speedup with Dynamo on GB200](https://quantumzeitgeist.com/kimi-k2-nvidia-ai-ai-breakthrough/)
- [12/02] [Mistral AI runs Mistral Large 3 with 10x faster inference using Dynamo](https://www.marktechpost.com/2025/12/02/nvidia-and-mistral-ai-bring-10x-faster-inference-for-the-mistral-3-family-on-gb200-nvl72-gpu-systems/)
- [12/01] [InfoQ: NVIDIA Dynamo simplifies Kubernetes deployment for LLM inference](https://www.infoq.com/news/2025/12/nvidia-dynamo-kubernetes/)

## Get Started

| Path | Use Case | Time | Requirements |
|------|----------|------|--------------|
| [**Local Quick Start**](#local-quick-start) | Test on a single machine | ~5 min | 1 GPU, Ubuntu 24.04 |
| [**Kubernetes Deployment**](#kubernetes-deployment) | Production multi-node clusters | ~30 min | K8s cluster with GPUs |
| [**Building from Source**](#building-from-source) | Contributors and development | ~15 min | Ubuntu, Rust, Python |

Want to help shape the future of distributed LLM inference? See the **[Contributing Guide](CONTRIBUTING.md)**.

# Local Quick Start

The following examples require a few system level packages.
Recommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/pages/reference/support-matrix.md](docs/pages/reference/support-matrix.md)

## Install Dynamo

### Option A: Containers (Recommended)

Containers have all dependencies pre-installed. No setup required.

```bash
# SGLang
docker run --gpus all --network host --rm -it nvcr.io/nvidia/ai-dynamo/sglang-runtime:0.8.1

# TensorRT-LLM
docker run --gpus all --network host --rm -it nvcr.io/nvidia/ai-dynamo/tensorrtllm-runtime:0.8.1

# vLLM
docker run --gpus all --network host --rm -it nvcr.io/nvidia/ai-dynamo/vllm-runtime:0.8.1
```

&gt; **Tip:** To run frontend and worker in the same container, either run processes in background with `&amp;` (see below), or open a second terminal and use `docker exec -it &lt;container_id&gt; bash`.

See [Release Artifacts](docs/pages/reference/release-artifacts.md#container-images) for available versions.

### Option B: Install from PyPI

The Dynamo team recommends the `uv` Python package manager, although any way works.

```bash
# Install uv (recommended Python package manager)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Create virtual environment
uv venv venv
source venv/bin/activate
uv pip install pip
```

Install system dependencies and the Dynamo wheel for your chosen backend:

**SGLang**

```bash
sudo apt install python3-dev
uv pip install &quot;ai-dynamo[sglang]&quot;
```

&gt; **Note:** For CUDA 13 (B300/GB300), the container is recommended. See [SGLang install docs](https://docs.sglang.io/get_started/install.html) for details.

**TensorRT-LLM**

```bash
sudo apt install python3-dev
pip install torch==2.9.0 torchvision --index-url https://download.pytorch.org/whl/cu130
pip install --pre --extra-index-url https://pypi.nvidia.com &quot;ai-dynamo[trtllm]&quot;
```

&gt; **Note:** TensorRT-LLM requires `pip` due to a transitive Git URL dependency that `uv` doesn&#039;t resolve. We recommend using the [TensorRT-LLM container](docs/pages/reference/release-artifacts.md#container-images) for broader compatibility.

**vLLM**

```bash
sudo apt install python3-dev libxcb1
uv pip install &quot;ai-dynamo[vllm]&quot;
```

## Run Dynamo

&gt; **Tip (Optional):** Before running Dynamo, verify your system configuration with `python3 deploy/sanity_check.py`

Dynamo provides a simple way to spin up a local set of inference components including:

- **OpenAI Compatible Frontend** ‚Äì High performance OpenAI compatible http api server written in Rust.
- **Basic and Kv Aware Router** ‚Äì Route and load balance traffic to a set of workers.
- **Workers** ‚Äì Set of pre-configured LLM serving engines.

Start the frontend:

&gt; **Tip:** To run in a single terminal (useful in containers), append `&gt; logfile.log 2&gt;&amp;1 &amp;` to run processes in background. Example: `python3 -m dynamo.frontend --discovery-backend file &gt; dynamo.frontend.log 2&gt;&amp;1 &amp;`

```bash
# Start an OpenAI compatible HTTP server with prompt templating, tokenization, and routing.
# For local dev: --discovery-backend file avoids etcd (workers and frontend must share a disk)
python3 -m dynamo.frontend --http-port 8000 --discovery-backend file
```

In another terminal (or same terminal if using background mode), start a worker for your chosen backend:

```bash
# SGLang
python3 -m dynamo.sglang --model-path Qwen/Qwen3-0.6B --discovery-backend file

# TensorRT-LLM
python3 -m dynamo.trtllm --model-path Qwen/Qwen3-0.6B --discovery-backend file

# vLLM (note: uses --model, not --model-path)
python3 -m dynamo.vllm --model Qwen/Qwen3-0.6B --discovery-backend file \
  --kv-events-config &#039;{&quot;enable_kv_cache_events&quot;: false}&#039;
```

&gt; **Note:** For dependency-free local development, disable KV event publishing (avoids NATS):
&gt; - **vLLM:** Add `--kv-events-config &#039;{&quot;enable_kv_cache_events&quot;: false}&#039;`
&gt; - **SGLang:** No flag needed (KV events disabled by default)
&gt; - **TensorRT-LLM:** No flag needed (KV events disabled by default)
&gt;
&gt; **TensorRT-LLM only:** The warning `Cannot connect to ModelExpress server/transport error. Using direct download.` is expected and can be safely ignored.
&gt;
&gt; See [Service Discovery and Messaging](#service-discovery-and-messaging) for details.

&gt; **Deprecation notice:** vLLM automatically enables KV event publishing when prefix caching is active. In a future release, this will change ‚Äî KV events will be disabled by default for all backends. Start using `--kv-events-config` explicitly to prepare.

#### Send a Request

```bash
curl localhost:8000/v1/chat/completions   -H &quot;Content-Type: application/json&quot;   -d &#039;{
    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,
    &quot;messages&quot;: [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello, how are you?&quot;
    }
    ],
    &quot;stream&quot;:false,
    &quot;max_tokens&quot;: 300
  }&#039; | jq
```

Rerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.

# Kubernetes Deployment

For production deployments on Kubernetes clusters with multiple GPUs.

## Prerequisites

- Kubernetes cluster with GPU nodes
- [Dynamo Platform installed](docs/pages/kubernetes/README.md)
- HuggingFace token for model downloads

## Production Recipes

Pre-built deployment configurations for common models and topologies:

| Model | Framework | Mode | GPUs | Recipe |
|-------|-----------|------|------|--------|
| Llama-3-70B | vLLM | Aggregated | 4x H100 | [View](recipes/llama-3-70b/vllm/) |
| DeepSeek-R1 | SGLang | Disaggregated | 8x H200 | [View](recipes/deepseek-r1/sglang/) |
| Qwen3-32B-FP8 | TensorRT-LLM | Aggregated | 8x GPU | [View](recipes/qwen3-32b-fp8/trtllm/) |

See [recipes/README.md](recipes/README.md) for the full list and deployment instructions.

## Cloud Deployment Guides

- [Amazon EKS](examples/deployments/EKS/)
- [Google GKE](examples/deployments/GKE/)

# Building from Source

For contributors who want to build Dynamo from source rather than installing from PyPI.

## 1. Install Libraries

**Ubuntu:**

```
sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
```

**macOS:**

- [Homebrew](https://brew.sh/)

```
# if brew is not installed on your system, install it
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
```

- [Xcode](https://developer.apple.com/xcode/)

```
brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
```

If Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.

## 2. Install Rust

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
```

## 3. Create a Python Virtual Environment

Follow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don&#039;t have `uv` installed. Once uv is installed, create a virtual environment and activate it.

- Install uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

- Create a virtual environment

```bash
uv venv dynamo
source dynamo/bin/activate
```

## 4. Install Build Tools

```
uv pip install pip maturin
```

[Maturin](https://github.com/PyO3/maturin) is the Rust&lt;-&gt;Python bindings build tool.

## 5. Build the Rust Bindings

```
cd lib/bindings/python
maturin develop --uv
```

## 6. Install GPU Memory Service

The GPU Memory Service is a Python package with a C++ extension. It requires only Python development headers and a C++ compiler (g++).

```bash
cd $PROJECT_ROOT
uv pip install -e lib/gpu_memory_service
```

## 7. Install the Wheel

```
cd $PROJECT_ROOT
uv pip install -e .
```

## 8. Run the Frontend

```bash
python3 -m dynamo.frontend
```

## 9. Configure for Local Development

- Pass `--discovery-backend file` to avoid external dependencies (see [Service Discovery and Messaging](#service-discovery-and-messaging))
- Set `DYN_LOG` to adjust the logging level (e.g., `export DYN_LOG=debug`). Uses the same syntax as `RUST_LOG`

&gt; **Note:** VSCode and Cursor users can use the `.devcontainer` folder for a pre-configured dev environment. See the [devcontainer README](.devcontainer/README.md) for details.

# Advanced Topics

## Benchmarking

Dynamo provides comprehensive benchmarking tools:

- **[Benchmarking Guide](docs/pages/benchmarks/benchmarking.md)** ‚Äì Compare deployment topologies using AIPerf
- **[SLA-Driven Deployments](docs/pages/components/planner/planner-guide.md)** ‚Äì Optimize deployments to meet SLA requirements

## Frontend OpenAPI Specification

The OpenAI-compatible frontend exposes an OpenAPI 3 spec at `/openapi.json`. To generate without running the server:

```bash
cargo run -p dynamo-llm --bin generate-frontend-openapi
```

This writes to `docs/pages/reference/api/openapi.json`.

## Service Discovery and Messaging

Dynamo uses TCP for inter-component communication. On Kubernetes, native resources ([CRDs + EndpointSlices](docs/pages/kubernetes/service-discovery.md)) handle service discovery. External services are optional for most deployments:

| Deployment | etcd | NATS | Notes |
|------------|------|------|-------|
| **Local Development** | ‚ùå Not required | ‚ùå Not required | Pass `--discovery-backend file`; vLLM also needs `--kv-events-config &#039;{&quot;enable_kv_cache_events&quot;: false}&#039;` |
| **Kubernetes** | ‚ùå Not required | ‚ùå Not required | K8s-native discovery; TCP request plane |

&gt; **Note:** KV-Aware Routing requires NATS for prefix caching coordination.

For Slurm or other distributed deployments (and KV-aware routing):

- [etcd](https://etcd.io/) can be run directly as `./etcd`.
- [nats](https://nats.io/) needs JetStream enabled: `nats-server -js`.

To quickly setup both: `docker compose -f deploy/docker-compose.yml up -d`

See [TRT-LLM on Slurm](examples/basics/multinode/trtllm/README.md) for deployment examples.

## More News

- [11/20] [Dell integrates PowerScale with Dynamo&#039;s NIXL for 19x faster TTFT](https://www.dell.com/en-us/dt/corporate/newsroom/announcements/detailpage.press-releases~usa~2025~11~dell-technologies-and-nvidia-advance-enterprise-ai-innovation.htm)
- [11/20] [WEKA partners with NVIDIA on KV cache storage for Dynamo](https://siliconangle.com/2025/11/20/nvidia-weka-kv-cache-solution-ai-inferencing-sc25/)
- [11/13] [Dynamo Office Hours Playlist](https://www.youtube.com/playlist?list=PL5B692fm6--tgryKu94h2Zb7jTFM3Go4X)
- [10/16] [How Baseten achieved 2x faster inference with NVIDIA Dynamo](https://www.baseten.co/blog/how-baseten-achieved-2x-faster-inference-with-nvidia-dynamo/)

&lt;!-- Reference links for Feature Compatibility Matrix --&gt;
[disagg]: docs/pages/design-docs/disagg-serving.md
[kv-routing]: docs/pages/components/router/README.md
[planner]: docs/pages/components/planner/planner-guide.md
[kvbm]: docs/pages/components/kvbm/README.md
[mm]: examples/multimodal/
[migration]: docs/pages/fault-tolerance/request-migration.md
[lora]: examples/backends/vllm/deploy/lora/README.md
[tools]: docs/pages/agents/tool-calling.md
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[erikjuhani/basalt]]></title>
            <link>https://github.com/erikjuhani/basalt</link>
            <guid>https://github.com/erikjuhani/basalt</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:02 GMT</pubDate>
            <description><![CDATA[TUI Application to manage Obsidian notes directly from the terminal]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/erikjuhani/basalt">erikjuhani/basalt</a></h1>
            <p>TUI Application to manage Obsidian notes directly from the terminal</p>
            <p>Language: Rust</p>
            <p>Stars: 1,019</p>
            <p>Forks: 26</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre>&lt;img align=&quot;left&quot; width=&quot;125px&quot; src=&quot;https://raw.githubusercontent.com/erikjuhani/basalt/refs/heads/main/assets/basalt.png?raw=true&quot;&gt;&lt;h3&gt;Basalt&amp;nbsp;&amp;nbsp;&lt;/h3&gt;
&lt;p&gt;TUI Application to manage Obsidian notes&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;hr&gt;

TUI Application to manage Obsidian vaults and notes directly from the terminal ‚ú®.

![Demo](https://raw.githubusercontent.com/erikjuhani/basalt/refs/heads/main/assets/basalt_demo.gif)

Basalt is a cross-platform TUI (Terminal User Interface) for managing Obsidian vaults and notes. It runs on Windows, macOS, and Linux. Basalt is not a replacement for Obsidian. Instead, it provides a minimalist terminal interface with a [WYSIWYG](https://en.wikipedia.org/wiki/WYSIWYG) experience.

## Installation

Install Basalt using [Cargo](https://doc.rust-lang.org/cargo/getting-started/installation.html):

```sh
cargo install basalt-tui
```

Or download a pre-compiled binary from the [latest release](https://github.com/erikjuhani/basalt/releases/latest), extract it, and move the `basalt` binary to a location in your `PATH`.

## Configuration

Basalt can be customized using a TOML configuration file. The file does not exist by default ‚Äî create it manually when you want to override the defaults.

**macOS and Linux:**

- `$HOME/.basalt.toml`
- `$XDG_CONFIG_HOME/basalt/config.toml`

**Windows:**

- `%USERPROFILE%\.basalt.toml`
- `%APPDATA%\basalt\config.toml`

If configuration files exist in multiple locations, only the first one found is used. The home directory configuration takes precedence.

&gt; [!WARNING]
&gt;
&gt; This behavior may change in future versions to merge all found configurations instead.

See the [full configuration reference](docs/Configuration/Configuration.md) for key mappings, custom commands, and defaults.

## Documentation

- [Getting started](docs/Getting%20started/Installation.md)
- [User interface](docs/User%20interface/User%20interface.md)
- [Configuration](docs/Configuration/Configuration.md)
- [Editing and Formatting](docs/Editing%20and%20Formatting.md)
- [Files and Folders](docs/Files%20and%20Folders.md)
- [Known Limitations](docs/Known%20Limitations.md)

## Contributing

Contributions are welcome, primarily for bug fixes. Feature work is considered on a case-by-case basis ‚Äî please open an issue first to discuss.

See [CONTRIBUTING.md](CONTRIBUTING.md) for development setup, code style, and contribution guidelines.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[kata-containers/kata-containers]]></title>
            <link>https://github.com/kata-containers/kata-containers</link>
            <guid>https://github.com/kata-containers/kata-containers</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:01 GMT</pubDate>
            <description><![CDATA[Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kata-containers/kata-containers">kata-containers/kata-containers</a></h1>
            <p>Kata Containers is an open source project and community working to build a standard implementation of lightweight Virtual Machines (VMs) that feel and perform like containers, but provide the workload isolation and security advantages of VMs. https://katacontainers.io/</p>
            <p>Language: Rust</p>
            <p>Stars: 7,509</p>
            <p>Forks: 1,269</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://object-storage-ca-ymq-1.vexxhost.net/swift/v1/6e4619c416ff4bd19e1c087f27a43eea/www-images-prod/openstack-logo/kata/SVG/kata-1.svg&quot; width=&quot;900&quot;&gt;

[![CI | Publish Kata Containers payload](https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml/badge.svg)](https://github.com/kata-containers/kata-containers/actions/workflows/payload-after-push.yaml) [![Kata Containers Nightly CI](https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml/badge.svg)](https://github.com/kata-containers/kata-containers/actions/workflows/ci-nightly.yaml)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/kata-containers/kata-containers/badge)](https://scorecard.dev/viewer/?uri=github.com/kata-containers/kata-containers)

# Kata Containers

Welcome to Kata Containers!

This repository is the home of the Kata Containers code for the 2.0 and newer
releases.

If you want to learn about Kata Containers, visit the main
[Kata Containers website](https://katacontainers.io).

## Introduction

Kata Containers is an open source project and community working to build a
standard implementation of lightweight Virtual Machines (VMs) that feel and
perform like containers, but provide the workload isolation and security
advantages of VMs.

## License

The code is licensed under the Apache 2.0 license.
See [the license file](LICENSE) for further details.

## Platform support

Kata Containers currently runs on 64-bit systems supporting the following
technologies:

| Architecture | Virtualization technology |
|-|-|
| `x86_64`, `amd64` | [Intel](https://www.intel.com) VT-x, AMD SVM |
| `aarch64` (&quot;`arm64`&quot;)| [ARM](https://www.arm.com) Hyp |
| `ppc64le` | [IBM](https://www.ibm.com) Power |
| `s390x` | [IBM](https://www.ibm.com) Z &amp; LinuxONE SIE |

### Hardware requirements

The [Kata Containers runtime](src/runtime) provides a command to
determine if your host system is capable of running and creating a
Kata Container:

```bash
$ kata-runtime check
```

&gt; **Notes:**
&gt;
&gt; - This command runs a number of checks including connecting to the
&gt;   network to determine if a newer release of Kata Containers is
&gt;   available on GitHub. If you do not wish this to check to run, add
&gt;   the `--no-network-checks` option.
&gt;
&gt; - By default, only a brief success / failure message is printed.
&gt;   If more details are needed, the `--verbose` flag can be used to display the
&gt;   list of all the checks performed.
&gt;
&gt; - If the command is run as the `root` user additional checks are
&gt;   run (including checking if another incompatible hypervisor is running).
&gt;   When running as `root`, network checks are automatically disabled.

## Getting started

See the [installation documentation](docs/install).

## Documentation

See the [official documentation](docs) including:

- [Installation guides](docs/install)
- [Developer guide](docs/Developer-Guide.md)
- [Design documents](docs/design)
  - [Architecture overview](docs/design/architecture)
  - [Architecture 3.0 overview](docs/design/architecture_3.0/)

## Configuration

Kata Containers uses a single
[configuration file](src/runtime/README.md#configuration)
which contains a number of sections for various parts of the Kata
Containers system including the [runtime](src/runtime), the
[agent](src/agent) and the [hypervisor](#hypervisors).

## Hypervisors

See the [hypervisors document](docs/hypervisors.md) and the
[Hypervisor specific configuration details](src/runtime/README.md#hypervisor-specific-configuration).

## Community

To learn more about the project, its community and governance, see the
[community repository](https://github.com/kata-containers/community). This is
the first place to go if you wish to contribute to the project.

## Getting help

See the [community](#community) section for ways to contact us.

### Raising issues

Please raise an issue
[in this repository](https://github.com/kata-containers/kata-containers/issues).

&gt; **Note:**
&gt; If you are reporting a security issue, please follow the [vulnerability reporting process](https://github.com/kata-containers/community#vulnerability-handling)

## Developers

See the [developer guide](docs/Developer-Guide.md).

### Components

### Main components

The table below lists the core parts of the project:

| Component | Type | Description |
|-|-|-|
| [runtime](src/runtime) | core | Main component run by a container manager and providing a containerd shimv2 runtime implementation. |
| [runtime-rs](src/runtime-rs) | core | The Rust version runtime. |
| [agent](src/agent) | core | Management process running inside the virtual machine / POD that sets up the container environment. |
| [`dragonball`](src/dragonball) | core | An optional built-in VMM brings out-of-the-box Kata Containers experience with optimizations on container workloads |
| [documentation](docs) | documentation | Documentation common to all components (such as design and install documentation). |
| [tests](tests) | tests | Excludes unit tests which live with the main code. |

### Additional components

The table below lists the remaining parts of the project:

| Component | Type | Description |
|-|-|-|
| [packaging](tools/packaging) | infrastructure | Scripts and metadata for producing packaged binaries&lt;br/&gt;(components, hypervisors, kernel and rootfs). |
| [kernel](https://www.kernel.org) | kernel | Linux kernel used by the hypervisor to boot the guest image. Patches are stored [here](tools/packaging/kernel). |
| [osbuilder](tools/osbuilder) | infrastructure | Tool to create &quot;mini O/S&quot; rootfs and initrd images and kernel for the hypervisor. |
| [kata-debug](tools/packaging/kata-debug/README.md) | infrastructure | Utility tool to gather Kata Containers debug information from Kubernetes clusters. |
| [`agent-ctl`](src/tools/agent-ctl) | utility | Tool that provides low-level access for testing the agent. |
| [`kata-ctl`](src/tools/kata-ctl) | utility | Tool that provides advanced commands and debug facilities. |
| [`trace-forwarder`](src/tools/trace-forwarder) | utility | Agent tracing helper. |
| [`ci`](.github/workflows) | CI | Continuous Integration configuration files and scripts. |
| [`ocp-ci`](ci/openshift-ci/README.md) | CI | Continuous Integration configuration for the OpenShift pipelines. |
| [`katacontainers.io`](https://github.com/kata-containers/www.katacontainers.io) | Source for the [`katacontainers.io`](https://www.katacontainers.io) site. |
| [`Webhook`](tools/testing/kata-webhook/README.md) | utility | Example of a simple admission controller webhook to annotate pods with the Kata runtime class |

### Packaging and releases

Kata Containers is now
[available natively for most distributions](docs/install/README.md#packaged-installation-methods).

## General tests

See the [tests documentation](tests/README.md).

## Metrics tests

See the [metrics documentation](tests/metrics/README.md).

## Glossary of Terms

See the [glossary of terms](https://github.com/kata-containers/kata-containers/wiki/Glossary) related to Kata Containers.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cocoindex-io/cocoindex]]></title>
            <link>https://github.com/cocoindex-io/cocoindex</link>
            <guid>https://github.com/cocoindex-io/cocoindex</guid>
            <pubDate>Wed, 25 Feb 2026 00:09:00 GMT</pubDate>
            <description><![CDATA[Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cocoindex-io/cocoindex">cocoindex-io/cocoindex</a></h1>
            <p>Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!</p>
            <p>Language: Rust</p>
            <p>Stars: 6,210</p>
            <p>Forks: 455</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/github.svg&quot; alt=&quot;CocoIndex&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Data transformation for AI&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;

[![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex)
[![Documentation](https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;logoColor=00B9FF)](https://cocoindex.io/docs/getting_started/quickstart)
[![License](https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white)](https://opensource.org/licenses/Apache-2.0)
[![PyPI version](https://img.shields.io/pypi/v/cocoindex?color=5B5BD6)](https://pypi.org/project/cocoindex/)
&lt;!--[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex) --&gt;
[![PyPI Downloads](https://static.pepy.tech/badge/cocoindex/month)](https://pepy.tech/projects/cocoindex)
[![CI](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml)
[![release](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml)
[![Link Check](https://github.com/cocoindex-io/cocoindex/actions/workflows/links.yml/badge.svg)](https://github.com/cocoindex-io/cocoindex/actions/workflows/links.yml)
[![prek](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/j178/prek/master/docs/assets/badge-v0.json)](https://github.com/j178/prek)
[![Discord](https://img.shields.io/discord/1314801574169673738?logo=discord&amp;color=5B5BD6&amp;logoColor=white)](https://discord.com/invite/zpA9S2DR7s)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/13939&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13939&quot; alt=&quot;cocoindex-io%2Fcocoindex | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box.  Exceptional developer velocity. Production-ready at day 0.

‚≠ê Drop a star to help us grow!

&lt;div align=&quot;center&quot;&gt;

&lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
[Deutsch](https://readme-i18n.com/cocoindex-io/cocoindex?lang=de) |
[English](https://readme-i18n.com/cocoindex-io/cocoindex?lang=en) |
[Espa√±ol](https://readme-i18n.com/cocoindex-io/cocoindex?lang=es) |
[fran√ßais](https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr) |
[Êó•Êú¨Ë™û](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja) |
[ÌïúÍµ≠Ïñ¥](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko) |
[Portugu√™s](https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt) |
[–†—É—Å—Å–∫–∏–π](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru) |
[‰∏≠Êñá](https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh)

&lt;/div&gt;

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/transformation.svg&quot; alt=&quot;CocoIndex Transformation&quot;&gt;
&lt;/p&gt;

&lt;/br&gt;

CocoIndex makes it effortless to transform data with AI, and keep source data and target in sync. Whether you‚Äôre building a vector index, creating knowledge graphs for context engineering or performing any custom data transformations ‚Äî goes beyond SQL.

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;CocoIndex Features&quot; src=&quot;https://cocoindex.io/images/venn2.svg&quot; /&gt;
&lt;/p&gt;

&lt;/br&gt;

## Exceptional velocity

Just declare transformation in dataflow with ~100 lines of python

```python
# import
data[&#039;content&#039;] = flow_builder.add_source(...)

# transform
data[&#039;out&#039;] = data[&#039;content&#039;]
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
```

CocoIndex follows the idea of [Dataflow](https://en.wikipedia.org/wiki/Dataflow_programming) programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.

**Particularly**, developers don&#039;t explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.

## Plug-and-Play Building Blocks

Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components - as easy as assembling building blocks.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/components.svg&quot; alt=&quot;CocoIndex Features&quot;&gt;
&lt;/p&gt;

## Data Freshness

CocoIndex keep source data and target in sync effortlessly.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6&quot; alt=&quot;Incremental Processing&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

It has out-of-box support for incremental indexing:

- minimal recomputation on source or logic change.
- (re-)processing necessary portions; reuse cache when possible

## Quick Start

If you&#039;re new to CocoIndex, we recommend checking out

- üìñ [Documentation](https://cocoindex.io/docs)
- ‚ö°  [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart)
- üé¨ [Quick Start Video Tutorial](https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT)

### Setup

1. Install CocoIndex Python library

```sh
pip install -U cocoindex
```

2. [Install Postgres](https://cocoindex.io/docs/getting_started/installation#-install-postgres) if you don&#039;t have one. CocoIndex uses it for incremental processing.

3. (Optional) Install Claude Code skill for enhanced development experience. Run these commands in [Claude Code](https://claude.com/claude-code):

```
/plugin marketplace add cocoindex-io/cocoindex-claude
/plugin install cocoindex-skills@cocoindex
```

## Define data flow

Follow [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart) to define your first indexing flow. An example flow looks like:

```python
@cocoindex.flow_def(name=&quot;TextEmbedding&quot;)
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope[&quot;documents&quot;] = flow_builder.add_source(cocoindex.sources.LocalFile(path=&quot;markdown_files&quot;))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope[&quot;documents&quot;].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc[&quot;chunks&quot;] = doc[&quot;content&quot;].transform(
            cocoindex.functions.SplitRecursively(),
            language=&quot;markdown&quot;, chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc[&quot;chunks&quot;].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk[&quot;embedding&quot;] = chunk[&quot;text&quot;].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model=&quot;sentence-transformers/all-MiniLM-L6-v2&quot;))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc[&quot;filename&quot;], location=chunk[&quot;location&quot;],
                                   text=chunk[&quot;text&quot;], embedding=chunk[&quot;embedding&quot;])

    # Export collected data to a vector index.
    doc_embeddings.export(
        &quot;doc_embeddings&quot;,
        cocoindex.targets.Postgres(),
        primary_key_fields=[&quot;filename&quot;, &quot;location&quot;],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name=&quot;embedding&quot;,
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
```

It defines an index flow like this:

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;400&quot; alt=&quot;Data Flow&quot; src=&quot;https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463&quot; /&gt;
&lt;/p&gt;

## üöÄ Examples and demo

| Example | Description |
|---------|-------------|
| [Text Embedding](examples/text_embedding) | Index text documents with embeddings for semantic search |
| [Code Embedding](examples/code_embedding) | Index code embeddings for semantic search |
| [PDF Embedding](examples/pdf_embedding) | Parse PDF and index text embeddings for semantic search |
| [PDF Elements Embedding](examples/pdf_elements_embedding) | Extract text and images from PDFs; embed text with SentenceTransformers and images with CLIP; store in Qdrant for multimodal search |
| [Manuals LLM Extraction](examples/manuals_llm_extraction) | Extract structured information from a manual using LLM |
| [Amazon S3 Embedding](examples/amazon_s3_embedding) | Index text documents from Amazon S3 |
| [Azure Blob Storage Embedding](examples/azure_blob_embedding) | Index text documents from Azure Blob Storage |
| [Google Drive Text Embedding](examples/gdrive_text_embedding) | Index text documents from Google Drive |
| [Meeting Notes to Knowledge Graph](examples/meeting_notes_graph) | Extract structured meeting info from Google Drive and build a knowledge graph |
| [Docs to Knowledge Graph](examples/docs_to_knowledge_graph) | Extract relationships from Markdown documents and build a knowledge graph |
| [Embeddings to Qdrant](examples/text_embedding_qdrant) | Index documents in a Qdrant collection for semantic search |
| [Embeddings to LanceDB](examples/text_embedding_lancedb) | Index documents in a LanceDB collection for semantic search |
| [FastAPI Server with Docker](examples/fastapi_server_docker) | Run the semantic search server in a Dockerized FastAPI setup |
| [Product Recommendation](examples/product_recommendation) | Build real-time product recommendations with LLM and graph database|
| [Image Search with Vision API](examples/image_search) | Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend|
| [Face Recognition](examples/face_recognition) | Recognize faces in images and build embedding index |
| [Paper Metadata](examples/paper_metadata) | Index papers in PDF files, and build metadata tables for each paper |
| [Multi Format Indexing](examples/multi_format_indexing) | Build visual document index from PDFs and images with ColPali for semantic search |
| [Custom Source HackerNews](examples/custom_source_hn) | Index HackerNews threads and comments, using *CocoIndex Custom Source* |
| [Custom Output Files](examples/custom_output_files) | Convert markdown files to HTML files and save them to a local directory, using *CocoIndex Custom Targets* |
| [Patient intake form extraction](examples/patient_intake_extraction) | Use LLM to extract structured data from patient intake forms with different formats |
| [HackerNews Trending Topics](examples/hn_trending_topics) | Extract trending topics from HackerNews threads and comments, using *CocoIndex Custom Source* and LLM |
| [Patient Intake Form Extraction with BAML](examples/patient_intake_extraction_baml) | Extract structured data from patient intake forms using BAML |
| [Patient Intake Form Extraction with DSPy](examples/patient_intake_extraction_dspy) | Extract structured data from patient intake forms using DSPy |

More coming and stay tuned üëÄ!

## üìñ Documentation

For detailed documentation, visit [CocoIndex Documentation](https://cocoindex.io/docs), including a [Quickstart guide](https://cocoindex.io/docs/getting_started/quickstart).

## ü§ù Contributing

We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our [contributing guide](https://cocoindex.io/docs/about/contributing).

## üë• Community

Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it&#039;s code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.

Join our community here:

- üåü [Star us on GitHub](https://github.com/cocoindex-io/cocoindex)
- üëã [Join our Discord community](https://discord.com/invite/zpA9S2DR7s)
- ‚ñ∂Ô∏è [Subscribe to our YouTube channel](https://www.youtube.com/@cocoindex-io)
- üìú [Read our blog posts](https://cocoindex.io/blogs/)

## Support us

We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo [![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex) to stay tuned and help us grow.

## License

CocoIndex is Apache 2.0 licensed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[stalwartlabs/stalwart]]></title>
            <link>https://github.com/stalwartlabs/stalwart</link>
            <guid>https://github.com/stalwartlabs/stalwart</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:59 GMT</pubDate>
            <description><![CDATA[All-in-one Mail & Collaboration server. Secure, scalable and fluent in every protocol (IMAP, JMAP, SMTP, CalDAV, CardDAV, WebDAV).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/stalwartlabs/stalwart">stalwartlabs/stalwart</a></h1>
            <p>All-in-one Mail & Collaboration server. Secure, scalable and fluent in every protocol (IMAP, JMAP, SMTP, CalDAV, CardDAV, WebDAV).</p>
            <p>Language: Rust</p>
            <p>Stars: 11,677</p>
            <p>Forks: 647</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://stalw.art&quot;&gt;
    &lt;img src=&quot;./img/logo-red.svg&quot; height=&quot;150&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  Secure, scalable mail &amp; collaboration server with comprehensive protocol support üõ°Ô∏è &lt;br/&gt;(IMAP, JMAP, SMTP, CalDAV, CardDAV, WebDAV)
&lt;/h3&gt;

&lt;br&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/stalwartlabs/stalwart/actions/workflows/ci.yml&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/stalwartlabs/stalwart/ci.yml?style=flat-square&quot; alt=&quot;continuous integration&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.gnu.org/licenses/agpl-3.0&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-AGPL_v3-blue.svg?label=license&amp;style=flat-square&quot; alt=&quot;License: AGPL v3&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://stalw.art/docs/install/get-started&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/read_the-docs-red?style=flat-square&quot; alt=&quot;Documentation&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mastodon.social/@stalwartlabs&quot;&gt;&lt;img src=&quot;https://img.shields.io/mastodon/follow/109929667531941122?style=flat-square&amp;logo=mastodon&amp;color=%236364ff&amp;label=Follow%20on%20Mastodon&quot; alt=&quot;Mastodon&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://twitter.com/stalwartlabs&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/stalwartlabs?style=flat-square&amp;logo=x&amp;label=Follow%20on%20Twitter&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.com/servers/stalwart-923615863037390889&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/923615863037390889?label=Join%20Discord&amp;logo=discord&amp;style=flat-square&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
  &amp;nbsp;
  &lt;a href=&quot;https://www.reddit.com/r/stalwartlabs/&quot;&gt;&lt;img src=&quot;https://img.shields.io/reddit/subreddit-subscribers/stalwartlabs?label=Join%20%2Fr%2Fstalwartlabs&amp;logo=reddit&amp;style=flat-square&quot; alt=&quot;Reddit&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

## Features

**Stalwart** is an open-source mail &amp; collaboration server with JMAP, IMAP4, POP3, SMTP, CalDAV, CardDAV and WebDAV support and a wide range of modern features. It is written in Rust and designed to be secure, fast, robust and scalable.

Key features:

- **Email** server with complete protocol support:
  - JMAP: 
    * [JMAP for Mail](https://datatracker.ietf.org/doc/html/rfc8621) server.
    * [JMAP for Sieve Scripts](https://www.ietf.org/archive/id/draft-ietf-jmap-sieve-22.html).
    * [WebSocket](https://datatracker.ietf.org/doc/html/rfc8887), [Blob Management](https://www.rfc-editor.org/rfc/rfc9404.html) and [Quotas](https://www.rfc-editor.org/rfc/rfc9425.html) extensions.
  - IMAP:
    * [IMAP4rev2](https://datatracker.ietf.org/doc/html/rfc9051) and [IMAP4rev1](https://datatracker.ietf.org/doc/html/rfc3501) server.
    * [ManageSieve](https://datatracker.ietf.org/doc/html/rfc5804) server.
    * Numerous [extensions](https://stalw.art/docs/development/rfcs#imap4-and-extensions) supported.
  - POP3:
    - [POP3](https://datatracker.ietf.org/doc/html/rfc1939) server.
    - [STLS](https://datatracker.ietf.org/doc/html/rfc2595) and [SASL](https://datatracker.ietf.org/doc/html/rfc5034) support as well as other [extensions](https://datatracker.ietf.org/doc/html/rfc2449).
  - SMTP:
    * SMTP server with built-in [DMARC](https://datatracker.ietf.org/doc/html/rfc7489), [DKIM](https://datatracker.ietf.org/doc/html/rfc6376), [SPF](https://datatracker.ietf.org/doc/html/rfc7208) and [ARC](https://datatracker.ietf.org/doc/html/rfc8617) support for message authentication.
    * Strong transport security through [DANE](https://datatracker.ietf.org/doc/html/rfc6698), [MTA-STS](https://datatracker.ietf.org/doc/html/rfc8461) and [SMTP TLS](https://datatracker.ietf.org/doc/html/rfc8460) reporting.
    * Inbound throttling and filtering with granular configuration rules, sieve scripting, MTA hooks and milter integration.
    * Distributed virtual queues with delayed delivery, priority delivery, quotas, routing rules and throttling support.
    * Envelope rewriting and message modification.
- **Collaboration** server:
  - Calendaring and scheduling:
    - [CalDAV](https://datatracker.ietf.org/doc/html/rfc4791) and [CalDAV Scheduling](https://datatracker.ietf.org/doc/html/rfc6638) support.
    - [JMAP for Calendars](https://datatracker.ietf.org/doc/html/draft-ietf-jmap-calendars-24) support.
  - Contact management:
    - [CardDAV](https://datatracker.ietf.org/doc/html/rfc6352) support.
    - [JMAP for Contacts](https://datatracker.ietf.org/doc/html/rfc9610) support.
  - File storage:
    - [WebDAV](https://datatracker.ietf.org/doc/html/rfc4918) support.
    - [JMAP for File Storage](https://datatracker.ietf.org/doc/html/draft-ietf-jmap-filenode-03) support.
  - Sharing with fine-grained access controls:
    - [WebDAV ACL](https://datatracker.ietf.org/doc/html/rfc3744) support.
    - [JMAP Sharing](https://datatracker.ietf.org/doc/html/rfc9670) support.
- **Spam** and **Phishing** built-in filter:
  - Comprehensive set of filtering **rules** on par with popular solutions.
  - LLM-driven spam filtering and message analysis.
  - Statistical **spam classifier** with collaborative filtering, automatic training capabilities and address book integration.
  - DNS Blocklists (**DNSBLs**) checking of IP addresses, domains, and hashes.
  - Collaborative digest-based spam filtering with **Pyzor**.
  - **Phishing** protection against homographic URL attacks, sender spoofing and other techniques.
  - Trusted **reply** tracking to recognize and prioritize genuine e-mail replies.
  - Sender **reputation** monitoring by IP address, ASN, domain and email address.
  - **Greylisting** to temporarily defer unknown senders.
  - **Spam traps** to set up decoy email addresses that catch and analyze spam.
- **Flexible**:
  - Pluggable storage backends with **RocksDB**, **FoundationDB**, **PostgreSQL**, **mySQL**, **SQLite**, **S3-Compatible**, **Azure** and **Redis** support.
  - Full-text search available in 17 languages using the built-in search engine or via **Meilisearch**, **ElasticSearch**, **OpenSearch**, **PostgreSQL** or **mySQL** backends.
  - Sieve scripting language with support for all [registered extensions](https://www.iana.org/assignments/sieve-extensions/sieve-extensions.xhtml).
  - Email aliases, mailing lists, subaddressing and catch-all addresses support.
  - Automatic account configuration and discovery with [autoconfig](https://www.ietf.org/id/draft-bucksch-autoconfig-02.html) and [autodiscover](https://learn.microsoft.com/en-us/exchange/architecture/client-access/autodiscover?view=exchserver-2019). 
  - Multi-tenancy support with domain and tenant isolation.
  - Disk quotas per user and tenant.
- **Secure and robust**:
  - Encryption at rest with **S/MIME** or **OpenPGP**.
  - Automatic TLS certificate provisioning with [ACME](https://datatracker.ietf.org/doc/html/rfc8555) using `TLS-ALPN-01`, `DNS-01` or `HTTP-01` challenges.
  - Automated blocking of IP addresses that attack, abuse or scan the server for exploits.
  - Rate limiting.
  - Security audited (read the [report](https://stalw.art/blog/security-audit)).
  - Memory safe (thanks to Rust).
- **Scalable and fault-tolerant**:
  - Designed to handle growth seamlessly, from small setups to large-scale deployments of thousands of nodes.
  - Built with **fault tolerance** and **high availability** in mind, recovers from hardware or software failures with minimal operational impact. 
  - Peer-to-peer cluster coordination or with **Kafka**, **Redpanda**, **NATS** or **Redis**.
  - **Kubernetes**, **Apache Mesos** and **Docker Swarm** support for automated scaling and container orchestration.
  - Read replicas, sharded blob storage and in-memory data stores for high performance and low latency.
- **Authentication and Authorization**:
  - **OpenID Connect** authentication.
  - OAuth 2.0 authorization with [authorization code](https://www.rfc-editor.org/rfc/rfc8628) and [device authorization](https://www.rfc-editor.org/rfc/rfc8628) flows.
  - **LDAP**, **OIDC**, **SQL** or built-in authentication backend support.
  - Two-factor authentication with Time-based One-Time Passwords (`2FA-TOTP`) 
  - Application passwords (App Passwords).
  - Roles and permissions.
  - Access Control Lists (ACLs).
- **Observability**:
  - Logging and tracing with **OpenTelemetry**, journald, log files and console support.
  - Metrics with **OpenTelemetry** and **Prometheus** integration.
  - Webhooks for event-driven automation.
  - Alerts with email and webhook notifications.
  - Live tracing and metrics.
- **Web-based administration**:
  - Dashboard with real-time statistics and monitoring.
  - Account, domain, group and mailing list management.
  - SMTP queue management for messages and outbound DMARC and TLS reports.
  - Report visualization interface for received DMARC, TLS-RPT and Failure (ARF) reports.
  - Configuration of every aspect of the mail server.
  - Log viewer with search and filtering capabilities.
  - Self-service portal for password reset and encryption-at-rest key management.

## Screenshots

&lt;img src=&quot;./img/screencast-setup.gif&quot;&gt;

## Presentation

**Want a deeper dive?** Need to explain to your boss why Stalwart is the perfect fit? Whether you&#039;re evaluating options, making a case to your team, or simply curious about how it all works under the hood, these slides walk you through the key features, architecture, and benefits of Stalwart. Browse the [slides](https://stalw.art/slides) to see what makes it stand out.

## Get Started

Install Stalwart on your server by following the instructions for your platform:

- [Linux / MacOS](https://stalw.art/docs/install/platform/linux)
- [Windows](https://stalw.art/docs/install/platform/windows)
- [Docker](https://stalw.art/docs/install/platform/docker)

All documentation is available at [stalw.art/docs](https://stalw.art/docs/install/get-started).

## Support

If you are having problems running Stalwart, you found a bug or just have a question, do not hesitate to reach us on [GitHub Discussions](https://github.com/stalwartlabs/stalwart/discussions), [Reddit](https://www.reddit.com/r/stalwartlabs) or [Discord](https://discord.com/servers/stalwart-923615863037390889).
Additionally you may purchase an [Enterprise License](https://stalw.art/enterprise) to obtain priority support from Stalwart Labs LLC.

## Roadmap

Stalwart has reached an exciting point in its journey, it‚Äôs now **feature complete**. All the core functionality and open standard email and collaboration protocols that we set out to support are in place. In other words, Stalwart already does everything you‚Äôd expect from a modern, standards-compliant mail and collaboration platform.

The next major milestone is all about refinement: finalizing the database schema and focusing on performance optimizations to ensure everything runs as efficiently and reliably as possible. Once that‚Äôs done, we‚Äôll be ready to roll out version **1.0**.

Of course, development doesn‚Äôt stop there. The community has contributed hundreds of great ideas for improvements and new features, everything from subtle usability tweaks to entirely new integrations. You can see the full list of proposals over on our [GitHub issues](https://github.com/stalwartlabs/stalwart/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3Aenhancement). If there‚Äôs something you‚Äôd like to see prioritized, just give it a thumbs up as we plan to implement enhancements based on the community‚Äôs votes.

## Sponsorship

Your support is crucial in helping us continue to improve the project, add new features, and maintain the highest level of quality. By [becoming a sponsor](https://opencollective.com/stalwart), you help fund the development and future of Stalwart. As a thank-you, sponsors who contribute $5 per month or more will automatically receive a [Enterprise edition](https://stalw.art/enterprise/) license. And, sponsors who contribute $30 per month or more, also have access to [Premium Support](https://stalw.art/support) from Stalwart Labs.

## Funding

Part of the development of this project was funded through:

- [NGI0 Entrust Fund](https://nlnet.nl/entrust), a fund established by [NLnet](https://nlnet.nl/) with financial support from the European Commission&#039;s [Next Generation Internet](https://ngi.eu/) programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 101069594.
- [NGI Zero Core](https://nlnet.nl/NGI0/), a fund established by [NLnet](https://nlnet.nl/) with financial support from the European Commission&#039;s programme, under the aegis of DG Communications Networks, Content and Technology under grant agreement No 101092990.

If you find the project useful you can help by [becoming a sponsor](https://opencollective.com/stalwart). Thank you!

## License

This project is dual-licensed under the **GNU Affero General Public License v3.0** (AGPL-3.0; as published by the Free Software Foundation) and the **Stalwart Enterprise License v1 (SELv1)**:

- The [GNU Affero General Public License v3.0](./LICENSES/AGPL-3.0-only.txt) is a free software license that ensures your freedom to use, modify, and distribute the software, with the condition that any modified versions of the software must also be distributed under the same license. 
- The [Stalwart Enterprise License v1 (SELv1)](./LICENSES/LicenseRef-SEL.txt) is a proprietary license designed for commercial use. It offers additional features and greater flexibility for businesses that do not wish to comply with the AGPL-3.0 license requirements. 

Each file in this project contains a license notice at the top, indicating the applicable license(s). The license notice follows the [REUSE guidelines](https://reuse.software/) to ensure clarity and consistency. The full text of each license is available in the [LICENSES](./LICENSES/) directory.

## Copyright

Copyright (C) 2020, Stalwart Labs LLC
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[memvid/memvid]]></title>
            <link>https://github.com/memvid/memvid</link>
            <guid>https://github.com/memvid/memvid</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:58 GMT</pubDate>
            <description><![CDATA[Memory layer for AI Agents. Replace complex RAG pipelines with a serverless, single-file memory layer. Give your agents instant retrieval and long-term memory.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/memvid/memvid">memvid/memvid</a></h1>
            <p>Memory layer for AI Agents. Replace complex RAG pipelines with a serverless, single-file memory layer. Give your agents instant retrieval and long-term memory.</p>
            <p>Language: Rust</p>
            <p>Stars: 13,215</p>
            <p>Forks: 1,107</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre>&lt;!-- HEADER:START --&gt;
&lt;img width=&quot;2000&quot; height=&quot;524&quot; alt=&quot;Social Cover (9)&quot;
     src=&quot;https://github.com/user-attachments/assets/cf66f045-c8be-494b-b696-b8d7e4fb709c&quot; /&gt;
&lt;!-- HEADER:END --&gt;

&lt;div style=&quot;height: 16px;&quot;&gt;&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/17293&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/17293&quot; alt=&quot;memvid%2Fmemvid | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;!-- BADGES:END --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;Memvid is a single-file memory layer for AI agents with instant retrieval and long-term memory.&lt;/strong&gt;&lt;br/&gt;
  Persistent, versioned, and portable memory, without databases.
&lt;/p&gt;

&lt;!-- NAV:START --&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.memvid.com&quot;&gt;Website&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://sandbox.memvid.com&quot;&gt;Try Sandbox&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://docs.memvid.com&quot;&gt;Docs&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://github.com/memvid/memvid/discussions&quot;&gt;Discussions&lt;/a&gt;
&lt;/p&gt;
&lt;!-- NAV:END --&gt;

&lt;!-- BADGES:START --&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://crates.io/crates/memvid-core&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/v/memvid-core?style=flat-square&amp;logo=rust&quot; alt=&quot;Crates.io&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://docs.rs/memvid-core&quot;&gt;&lt;img src=&quot;https://img.shields.io/docsrs/memvid-core?style=flat-square&amp;logo=docs.rs&quot; alt=&quot;docs.rs&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/memvid/memvid/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square&quot; alt=&quot;License&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/memvid/memvid/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/memvid/memvid?style=flat-square&amp;logo=github&quot; alt=&quot;Stars&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/memvid/memvid/network/members&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/memvid/memvid?style=flat-square&amp;logo=github&quot; alt=&quot;Forks&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/memvid/memvid/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/memvid/memvid?style=flat-square&amp;logo=github&quot; alt=&quot;Issues&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/2mynS7fcK7&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/1442910055233224745?style=flat-square&amp;logo=discord&amp;label=discord&quot; alt=&quot;Discord&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;




## Benchmark Highlights

**üöÄ Higher accuracy than any other memory system :** +35% SOTA on LoCoMo, best-in-class long-horizon conversational recall &amp; reasoning

**üß† Superior multi-hop &amp; temporal reasoning:**  +76% multi-hop, +56% temporal vs. the industry average

**‚ö° Ultra-low latency at scale** 0.025ms P50 and 0.075ms P99, with 1,372√ó higher throughput than standard

**üî¨ Fully reproducible benchmarks:** LoCoMo (10 √ó ~26K-token conversations), open-source eval, LLM-as-Judge


## What is Memvid?

Memvid is a portable AI memory system that packages your data, embeddings, search structure, and metadata into a single file.

Instead of running complex RAG pipelines or server-based vector databases, Memvid enables fast retrieval directly from the file.

The result is a model-agnostic, infrastructure-free memory layer that gives AI agents persistent, long-term memory they can carry anywhere.

    
## What are Smart Frames?

Memvid draws inspiration from video encoding, not to store video, but to **organize AI memory as an append-only, ultra-efficient sequence of Smart Frames.**

A Smart Frame is an immutable unit that stores content along with timestamps, checksums and basic metadata.
Frames are grouped in a way that allows efficient compression, indexing, and parallel reads.

This frame-based design enables:

-   Append-only writes without modifying or corrupting existing data
-   Queries over past memory states
-   Timeline-style inspection of how knowledge evolves
-   Crash safety through committed, immutable frames
-   Efficient compression using techniques adapted from video encoding

The result is a single file that behaves like a rewindable memory timeline for AI systems.


## Core Concepts

-   **Living Memory Engine**
    Continuously append, branch, and evolve memory across sessions.

-   **Capsule Context (`.mv2`)**
    Self-contained, shareable memory capsules with rules and expiry.

-   **Time-Travel Debugging**
    Rewind, replay, or branch any memory state.

-   **Smart Recall**
    Sub-5ms local memory access with predictive caching.

-   **Codec Intelligence**
    Auto-selects and upgrades compression over time.


## Use Cases

Memvid is a portable, serverless memory layer that gives AI agents persistent memory and fast recall. Because it&#039;s model-agnostic, multi-modal, and works fully offline, developers are using Memvid across a wide range of real-world applications.

-   Long-Running AI Agents
-   Enterprise Knowledge Bases
-   Offline-First AI Systems
-   Codebase Understanding
-   Customer Support Agents
-   Workflow Automation
-   Sales and Marketing Copilots
-   Personal Knowledge Assistants
-   Medical, Legal, and Financial Agents
-   Auditable and Debuggable AI Workflows
-   Custom Applications


## SDKs &amp; CLI

Use Memvid in your preferred language:

| Package         | Install                     | Links                                                                                                               |
| --------------- | --------------------------- | ------------------------------------------------------------------------------------------------------------------- |
| **CLI**         | `npm install -g memvid-cli` | [![npm](https://img.shields.io/npm/v/memvid-cli?style=flat-square)](https://www.npmjs.com/package/memvid-cli)       |
| **Node.js SDK** | `npm install @memvid/sdk`   | [![npm](https://img.shields.io/npm/v/@memvid/sdk?style=flat-square)](https://www.npmjs.com/package/@memvid/sdk)     |
| **Python SDK**  | `pip install memvid-sdk`    | [![PyPI](https://img.shields.io/pypi/v/memvid-sdk?style=flat-square)](https://pypi.org/project/memvid-sdk/)         |
| **Rust**        | `cargo add memvid-core`     | [![Crates.io](https://img.shields.io/crates/v/memvid-core?style=flat-square)](https://crates.io/crates/memvid-core) |

---

## Installation (Rust)

### Requirements

-   **Rust 1.85.0+** ‚Äî Install from [rustup.rs](https://rustup.rs)

### Add to Your Project

```toml
[dependencies]
memvid-core = &quot;2.0&quot;
```

### Feature Flags

| Feature             | Description                                                      |
| ------------------- | ---------------------------------------------------------------- |
| `lex`               | Full-text search with BM25 ranking (Tantivy)                     |
| `pdf_extract`       | Pure Rust PDF text extraction                                    |
| `vec`               | Vector similarity search (HNSW + local text embeddings via ONNX) |
| `clip`              | CLIP visual embeddings for image search                          |
| `whisper`           | Audio transcription with Whisper                                 |
| `api_embed`         | Cloud API embeddings (OpenAI)                                    |
| `temporal_track`    | Natural language date parsing (&quot;last Tuesday&quot;)                   |
| `parallel_segments` | Multi-threaded ingestion                                         |
| `encryption`        | Password-based encryption capsules (.mv2e)                       |
| `symspell_cleanup`  | Robust PDF text repair (fixes &quot;emp lo yee&quot; -&gt; &quot;employee&quot;)        |

Enable features as needed:

```toml
[dependencies]
memvid-core = { version = &quot;2.0&quot;, features = [&quot;lex&quot;, &quot;vec&quot;, &quot;temporal_track&quot;] }
```


## Quick Start

```rust
use memvid_core::{Memvid, PutOptions, SearchRequest};

fn main() -&gt; memvid_core::Result&lt;()&gt; {
    // Create a new memory file
    let mut mem = Memvid::create(&quot;knowledge.mv2&quot;)?;

    // Add documents with metadata
    let opts = PutOptions::builder()
        .title(&quot;Meeting Notes&quot;)
        .uri(&quot;mv2://meetings/2024-01-15&quot;)
        .tag(&quot;project&quot;, &quot;alpha&quot;)
        .build();
    mem.put_bytes_with_options(b&quot;Q4 planning discussion...&quot;, opts)?;
    mem.commit()?;

    // Search
    let response = mem.search(SearchRequest {
        query: &quot;planning&quot;.into(),
        top_k: 10,
        snippet_chars: 200,
        ..Default::default()
    })?;

    for hit in response.hits {
        println!(&quot;{}: {}&quot;, hit.title.unwrap_or_default(), hit.text);
    }

    Ok(())
}
```

---

## Build

Clone the repository:

```bash
git clone https://github.com/memvid/memvid.git
cd memvid
```

Build in debug mode:

```bash
cargo build
```

Build in release mode (optimized):

```bash
cargo build --release
```

Build with specific features:

```bash
cargo build --release --features &quot;lex,vec,temporal_track&quot;
```

---

## Run Tests

Run all tests:

```bash
cargo test
```

Run tests with output:

```bash
cargo test -- --nocapture
```

Run a specific test:

```bash
cargo test test_name
```

Run integration tests only:

```bash
cargo test --test lifecycle
cargo test --test search
cargo test --test mutation
```

---

## Examples

The `examples/` directory contains working examples:

### Basic Usage

Demonstrates create, put, search, and timeline operations:

```bash
cargo run --example basic_usage
```

### PDF Ingestion

Ingest and search PDF documents (uses the &quot;Attention Is All You Need&quot; paper):

```bash
cargo run --example pdf_ingestion
```

### CLIP Visual Search

Image search using CLIP embeddings (requires `clip` feature):

```bash
cargo run --example clip_visual_search --features clip
```

### Whisper Transcription

Audio transcription (requires `whisper` feature):

```bash
cargo run --example test_whisper --features whisper -- /path/to/audio.mp3
```

**Available Models:**

| Model                 | Size   | Speed   | Use Case                            |
| --------------------- | ------ | ------- | ----------------------------------- |
| `whisper-small-en`    | 244 MB | Slowest | Best accuracy (default)             |
| `whisper-tiny-en`     | 75 MB  | Fast    | Balanced                            |
| `whisper-tiny-en-q8k` | 19 MB  | Fastest | Quick testing, resource-constrained |

**Model Selection:**

```bash
# Default (FP32 small, highest accuracy)
cargo run --example test_whisper --features whisper -- audio.mp3

# Quantized tiny (75% smaller, faster)
MEMVID_WHISPER_MODEL=whisper-tiny-en-q8k cargo run --example test_whisper --features whisper -- audio.mp3
```

**Programmatic Configuration:**

```rust
use memvid_core::{WhisperConfig, WhisperTranscriber};

// Default FP32 small model
let config = WhisperConfig::default();

// Quantized tiny model (faster, smaller)
let config = WhisperConfig::with_quantization();

// Specific model
let config = WhisperConfig::with_model(&quot;whisper-tiny-en-q8k&quot;);

let transcriber = WhisperTranscriber::new(&amp;config)?;
let result = transcriber.transcribe_file(&quot;audio.mp3&quot;)?;
println!(&quot;{}&quot;, result.text);
```


## Text Embedding Models

The `vec` feature includes local text embedding support using ONNX models. Before using local text embeddings, you need to download the model files manually.

### Quick Start: BGE-small (Recommended)

Download the default BGE-small model (384 dimensions, fast and efficient):

```bash
mkdir -p ~/.cache/memvid/text-models

# Download ONNX model
curl -L &#039;https://huggingface.co/BAAI/bge-small-en-v1.5/resolve/main/onnx/model.onnx&#039; \
  -o ~/.cache/memvid/text-models/bge-small-en-v1.5.onnx

# Download tokenizer
curl -L &#039;https://huggingface.co/BAAI/bge-small-en-v1.5/resolve/main/tokenizer.json&#039; \
  -o ~/.cache/memvid/text-models/bge-small-en-v1.5_tokenizer.json
```

### Available Models

| Model                   | Dimensions | Size   | Best For        |
| ----------------------- | ---------- | ------ | --------------- |
| `bge-small-en-v1.5`     | 384        | ~120MB | Default, fast   |
| `bge-base-en-v1.5`      | 768        | ~420MB | Better quality  |
| `nomic-embed-text-v1.5` | 768        | ~530MB | Versatile tasks |
| `gte-large`             | 1024       | ~1.3GB | Highest quality |

### Other Models

**BGE-base** (768 dimensions):
```bash
curl -L &#039;https://huggingface.co/BAAI/bge-base-en-v1.5/resolve/main/onnx/model.onnx&#039; \
  -o ~/.cache/memvid/text-models/bge-base-en-v1.5.onnx
curl -L &#039;https://huggingface.co/BAAI/bge-base-en-v1.5/resolve/main/tokenizer.json&#039; \
  -o ~/.cache/memvid/text-models/bge-base-en-v1.5_tokenizer.json
```

**Nomic** (768 dimensions):
```bash
curl -L &#039;https://huggingface.co/nomic-ai/nomic-embed-text-v1.5/resolve/main/onnx/model.onnx&#039; \
  -o ~/.cache/memvid/text-models/nomic-embed-text-v1.5.onnx
curl -L &#039;https://huggingface.co/nomic-ai/nomic-embed-text-v1.5/resolve/main/tokenizer.json&#039; \
  -o ~/.cache/memvid/text-models/nomic-embed-text-v1.5_tokenizer.json
```

**GTE-large** (1024 dimensions):
```bash
curl -L &#039;https://huggingface.co/thenlper/gte-large/resolve/main/onnx/model.onnx&#039; \
  -o ~/.cache/memvid/text-models/gte-large.onnx
curl -L &#039;https://huggingface.co/thenlper/gte-large/resolve/main/tokenizer.json&#039; \
  -o ~/.cache/memvid/text-models/gte-large_tokenizer.json
```

### Usage in Code

```rust
use memvid_core::text_embed::{LocalTextEmbedder, TextEmbedConfig};
use memvid_core::types::embedding::EmbeddingProvider;

// Use default model (BGE-small)
let config = TextEmbedConfig::default();
let embedder = LocalTextEmbedder::new(config)?;

let embedding = embedder.embed_text(&quot;hello world&quot;)?;
assert_eq!(embedding.len(), 384);

// Use different model
let config = TextEmbedConfig::bge_base();
let embedder = LocalTextEmbedder::new(config)?;
```

See `examples/text_embedding.rs` for a complete example with similarity computation and search ranking.

### Model Consistency

To prevent accidental model mixing (e.g., querying a BGE-small index with OpenAI embeddings), you can explicitly bind your Memvid instance to a specific model name:

```rust
// Bind the index to a specific model.
// If the index was previously created with a different model, this will return an error.
mem.set_vec_model(&quot;bge-small-en-v1.5&quot;)?;
```

This binding is persistent. Once set, future attempts to use a different model name will fail fast with a `ModelMismatch` error.



## API Embeddings (OpenAI)

The `api_embed` feature enables cloud-based embedding generation using OpenAI&#039;s API.

### Setup

Set your OpenAI API key:

```bash
export OPENAI_API_KEY=&quot;sk-...&quot;
```

### Usage

```rust
use memvid_core::api_embed::{OpenAIConfig, OpenAIEmbedder};
use memvid_core::types::embedding::EmbeddingProvider;

// Use default model (text-embedding-3-small)
let config = OpenAIConfig::default();
let embedder = OpenAIEmbedder::new(config)?;

let embedding = embedder.embed_text(&quot;hello world&quot;)?;
assert_eq!(embedding.len(), 1536);

// Use higher quality model
let config = OpenAIConfig::large();  // text-embedding-3-large (3072 dims)
let embedder = OpenAIEmbedder::new(config)?;
```

### Available Models

| Model                    | Dimensions | Best For                   |
| ------------------------ | ---------- | -------------------------- |
| `text-embedding-3-small` | 1536       | Default, fastest, cheapest |
| `text-embedding-3-large` | 3072       | Highest quality            |
| `text-embedding-ada-002` | 1536       | Legacy model               |

See `examples/openai_embedding.rs` for a complete example.



## File Format

Everything lives in a single `.mv2` file:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Header (4KB)               ‚îÇ  Magic, version, capacity
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Embedded WAL (1-64MB)      ‚îÇ  Crash recovery
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Data Segments              ‚îÇ  Compressed frames
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Lex Index                  ‚îÇ  Tantivy full-text
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Vec Index                  ‚îÇ  HNSW vectors
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Time Index                 ‚îÇ  Chronological ordering
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ TOC (Footer)               ‚îÇ  Segment offsets
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

No `.wal`, `.lock`, `.shm`, or sidecar files. Ever.

See [MV2_SPEC.md](MV2_SPEC.md) for the complete file format specification.



## Support

Have questions or feedback?
Email: contact@memvid.com

**Drop a ‚≠ê to show support**

---

&gt; **Memvid v1 (QR-based memory) is deprecated**
&gt;
&gt; If you are referencing QR codes, you are using outdated information.
&gt;
&gt; See: https://docs.memvid.com/memvid-v1-deprecation

---

## License

Apache License 2.0 ‚Äî see the [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[eza-community/eza]]></title>
            <link>https://github.com/eza-community/eza</link>
            <guid>https://github.com/eza-community/eza</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:57 GMT</pubDate>
            <description><![CDATA[A modern alternative to ls]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eza-community/eza">eza-community/eza</a></h1>
            <p>A modern alternative to ls</p>
            <p>Language: Rust</p>
            <p>Stars: 20,137</p>
            <p>Forks: 398</p>
            <p>Stars today: 39 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: 2023-2024 Christina S√∏rensen
SPDX-FileContributor: Christina S√∏rensen

SPDX-License-Identifier: EUPL-1.2
--&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;
   &lt;sup&gt;Special thanks to:&lt;/sup&gt;
   &lt;br&gt;
   &lt;br&gt;
   &lt;a href=&quot;https://www.warp.dev/eza&quot;&gt;
      &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://github.com/user-attachments/assets/ab8dd143-b0fd-4904-bdc5-dd7ecac94eae&quot;&gt;
   &lt;/a&gt;

### [Warp, the AI terminal for developers](https://www.warp.dev/eza)
[Available for MacOS, Linux, &amp; Windows](https://www.warp.dev/eza)&lt;br&gt;

&lt;/div&gt;
    
# eza

A modern replacement for ls.

&lt;a href=&quot;https://matrix.to/#/#eza-community:gitter.im&quot;&gt;&lt;img alt=&quot;Gitter&quot; src=&quot;https://img.shields.io/gitter/room/eza-community/eza?logo=element&amp;link=https%3A%2F%2Fapp.gitter.im%2F%23%2Froom%2F%23eza%3Agitter.im&amp;link=Gitter%20matrix%20room%20for%20Eza&quot; width=200&gt;&lt;/a&gt;

[![Built with Nix](https://img.shields.io/badge/Built_With-Nix-5277C3.svg?logo=nixos&amp;labelColor=73C3D5)](https://nixos.org)
[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.1-4baaaa.svg)](CODE_OF_CONDUCT.md)

[![Unit tests](https://github.com/eza-community/eza/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/eza-community/eza/actions/workflows/unit-tests.yml)
[![Crates.io](https://img.shields.io/crates/v/eza?link=https%3A%2F%2Fcrates.io%2Fcrates%2Feza)](https://crates.io/crates/eza)
![Crates.io](https://img.shields.io/crates/l/eza?link=https%3A%2F%2Fgithub.com%2Feza-community%2Feza%2Fblob%2Fmain%2FLICENCE)

&lt;/div&gt;

![eza demo gif](docs/images/screenshots.png)

---

**eza** is a modern alternative for the venerable file-listing command-line program `ls` that ships with Unix and Linux operating systems, giving it more features and better defaults.
It uses colours to distinguish file types and metadata.
It knows about symlinks, extended attributes, and Git.
And it‚Äôs **small**, **fast**, and just **one single binary**.

By deliberately making some decisions differently, eza attempts to be a more featureful, more user-friendly version of `ls`.

---

**eza** features not in exa (non-exhaustive):

- Fixes [‚ÄúThe Grid Bug‚Äù](https://github.com/eza-community/eza/issues/66#issuecomment-1656758327) introduced in exa 2021.
- Hyperlink support.
- Mount point details.
- Selinux context output.
- Git repo status output.
- Human readable relative dates.
- Several security fixes.
- Support for `bright` terminal colours.
- Many smaller bug fixes/changes!
- Configuration `theme.yml` file for customization of colors and icons.

...and like, so much more that it became exhausting to update this all the time.
Like seriously, we have a lot of good stuff.

---

&lt;a id=&quot;try-it&quot;&gt;
&lt;h1&gt;Try it!&lt;/h1&gt;
&lt;/a&gt;

### Nix ‚ùÑÔ∏è

If you already have Nix setup with flake support, you can try out eza with the `nix run` command:

    nix run github:eza-community/eza

Nix will build eza and run it.

If you want to pass arguments this way, use e.g. `nix run github:eza-community/eza -- -ol`.

# Installation

eza is available for Windows, macOS and Linux. Platform and distribution
specific installation instructions can be found in [INSTALL.md](INSTALL.md).

[![Packaging status](https://repology.org/badge/vertical-allrepos/eza.svg?columns=3)](https://repology.org/project/eza/versions)

---

&lt;a id=&quot;options&quot;&gt;
&lt;h1&gt;Command-line options&lt;/h1&gt;
&lt;/a&gt;

eza‚Äôs options are almost, but not quite, entirely unlike `ls`‚Äôs. Quick overview:

## Display options

&lt;details&gt;
&lt;summary&gt;Click to expand&lt;/summary&gt;

- **-1**, **--oneline**: display one entry per line
- **-G**, **--grid**: display entries as a grid (default)
- **-l**, **--long**: display extended details and attributes
- **-R**, **--recurse**: recurse into directories
- **-T**, **--tree**: recurse into directories as a tree
- **-x**, **--across**: sort the grid across, rather than downwards
- **-F**, **--classify=(when)**: display type indicator by file names (always, auto, never)
- **--colo[u]r=(when)**: when to use terminal colours (always, auto, never)
- **--colo[u]r-scale=(field)**: highlight levels of `field` distinctly(all, age, size)
- **--color-scale-mode=(mode)**: use gradient or fixed colors in --color-scale. valid options are `fixed` or `gradient`
- **--icons=(when)**: when to display icons (always, auto, never)
- **--hyperlink**: display entries as hyperlinks
- **--absolute=(mode)**: display entries with their absolute path (on, follow, off)
- **-w**, **--width=(columns)**: set screen width in columns

&lt;/details&gt;

## Filtering options

&lt;details&gt;
&lt;summary&gt;Click to expand&lt;/summary&gt;

- **-a**, **--all**: show hidden and &#039;dot&#039; files
- **-d**, **--treat-dirs-as-files**: list directories like regular files
- **-L**, **--level=(depth)**: limit the depth of recursion
- **-r**, **--reverse**: reverse the sort order
- **-s**, **--sort=(field)**: which field to sort by
- **--group-directories-first**: list directories before other files
- **--group-directories-last**: list directories after other files
- **-D**, **--only-dirs**: list only directories
- **-f**, **--only-files**: list only files
- **--no-symlinks**: don&#039;t show symbolic links
- **--show-symlinks**: explicitly show links (with `--only-dirs`, `--only-files`, to show symlinks that match the filter)
- **--git-ignore**: ignore files mentioned in `.gitignore`
- **-I**, **--ignore-glob=(globs)**: glob patterns (pipe-separated) of files to ignore

Pass the `--all` option twice to also show the `.` and `..` directories.

&lt;/details&gt;

## Long view options

&lt;details&gt;
&lt;summary&gt;Click to expand&lt;/summary&gt;

These options are available when running with `--long` (`-l`):

- **-b**, **--binary**: list file sizes with binary prefixes
- **-B**, **--bytes**: list file sizes in bytes, without any prefixes
- **-g**, **--group**: list each file‚Äôs group
- **--smart-group**: only show group if it has a different name from owner
- **-h**, **--header**: add a header row to each column
- **-H**, **--links**: list each file‚Äôs number of hard links
- **-i**, **--inode**: list each file‚Äôs inode number
- **-m**, **--modified**: use the modified timestamp field
- **-M**, **--mounts**: Show mount details (Linux and MacOS only).
- **-S**, **--blocksize**: show size of allocated file system blocks
- **-t**, **--time=(field)**: which timestamp field to use
- **-u**, **--accessed**: use the accessed timestamp field
- **-U**, **--created**: use the created timestamp field
- **-X**, **--dereference**: dereference symlinks for file information
- **-Z**, **--context**: list each file‚Äôs security context
- **-@**, **--extended**: list each file‚Äôs extended attributes and sizes
- **--changed**: use the changed timestamp field
- **--git**: list each file‚Äôs Git status, if tracked or ignored
- **--git-repos**: list each directory‚Äôs Git status, if tracked
- **--git-repos-no-status**: list whether a directory is a Git repository, but not its status (faster)
- **--no-git**: suppress Git status (always overrides `--git`, `--git-repos`, `--git-repos-no-status`)
- **--time-style**: how to format timestamps. valid timestamp styles are ‚Äò`default`‚Äô, ‚Äò`iso`‚Äô, ‚Äò`long-iso`‚Äô, ‚Äò`full-iso`‚Äô, ‚Äò`relative`‚Äô, or a custom style ‚Äò`+&lt;FORMAT&gt;`‚Äô (E.g., ‚Äò`+%Y-%m-%d %H:%M`‚Äô =&gt; ‚Äò`2023-09-30 13:00`‚Äô. For more specifications on the format string, see the _`eza(1)` manual page_ and [chrono documentation](https://docs.rs/chrono/latest/chrono/format/strftime/index.html).).
- **--total-size**: show recursive directory size
- **--no-permissions**: suppress the permissions field
- **-o**, **--octal-permissions**: list each file&#039;s permission in octal format
- **--no-filesize**: suppress the filesize field
- **--no-user**: suppress the user field
- **--no-time**: suppress the time field
- **--stdin**: read file names from stdin

Some of the options accept parameters:

- Valid **--colo\[u\]r** options are **always**, **automatic** (or **auto** for short), and **never**.
- Valid sort fields are **accessed**, **changed**, **created**, **extension**, **Extension**, **inode**, **modified**, **name**, **Name**, **size**, **type**, and **none**. Fields starting with a capital letter sort uppercase before lowercase. The modified field has the aliases **date**, **time**, and **newest**, while its reverse has the aliases **age** and **oldest**.
- Valid time fields are **modified**, **changed**, **accessed**, and **created**.
- Valid time styles are **default**, **iso**, **long-iso**, **full-iso**, and **relative**.



See the `man` pages for further documentation of usage. They are available
- online [in the repo](https://github.com/eza-community/eza/tree/main/man)
- in your terminal via `man eza`, as of version [`[0.18.13] - 2024-04-25`](https://github.com/eza-community/eza/blob/main/CHANGELOG.md#01813---2024-04-25)
&lt;/details&gt;


## Custom Themes
&lt;details&gt;
&lt;summary&gt;Click to expand&lt;/summary&gt;

**Eza** has recently added support for a `theme.yml` file, where you can specify all of the existing theme-ing options
available for the `LS_COLORS` and `EXA_COLORS` environment variables, as well as the option to specify different icons
for different file types and extensions. Any existing environment variables set will continue to work and will take
precedence for backwards compatibility.

#### **New** Pre-made themes
Check out the themes available in the official [eza-themes](https://github.com/eza-community/eza-themes) repository, or contribute your own.

An example theme file is available in `docs/theme.yml`, and needs to either be placed in a directory specified by the 
environment variable `EZA_CONFIG_DIR`, or will looked for by default in `$XDG_CONFIG_HOME/eza`.

Full details are available on the [man page](https://github.com/eza-community/eza/tree/main/man/eza_colors-explanation.5.md) and an example theme file is included [here](https://github.com/eza-community/eza/tree/main/docs/theme.yml)

&lt;/details&gt;


# Hacking on eza

If you wanna contribute to eza, firstly, you&#039;re expected to follow our 
[code of conduct](https://github.com/eza-community/eza/blob/main/CODE_OF_CONDUCT.md). 
After having understood the code of conduct, you can have a look at our
[CONTRIBUTING.md](https://github.com/eza-community/eza/blob/main/CONTRIBUTING.md) 
for more info about actual hacking.

[![Star History Chart](https://api.star-history.com/svg?repos=eza-community/eza&amp;type=Date)](https://star-history.com/#eza-community/eza&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>