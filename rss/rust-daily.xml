<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Thu, 12 Feb 2026 00:07:28 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[gitbutlerapp/gitbutler]]></title>
            <link>https://github.com/gitbutlerapp/gitbutler</link>
            <guid>https://github.com/gitbutlerapp/gitbutler</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:28 GMT</pubDate>
            <description><![CDATA[The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitbutlerapp/gitbutler">gitbutlerapp/gitbutler</a></h1>
            <p>The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte</p>
            <p>Language: Rust</p>
            <p>Stars: 19,198</p>
            <p>Forks: 830</p>
            <p>Stars today: 401 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img align=&quot;center&quot; width=&quot;100%&quot; src=&quot;./readme-preview.webp&quot; /&gt;

  &lt;p align=&quot;center&quot;&gt;&lt;i&gt;Our beautiful GUI&lt;/i&gt;&lt;/p&gt;

  &lt;br /&gt;

&lt;img align=&quot;center&quot; width=&quot;100%&quot; src=&quot;https://gitbutler-docs-images-public.s3.us-east-1.amazonaws.com/CleanShot%202026-02-08%20at%2012.46.35%402x.png&quot; 
/&gt;

  &lt;p align=&quot;center&quot;&gt;&lt;i&gt;Our amazing &lt;code&gt;but&lt;/code&gt; CLI&lt;/i&gt;&lt;/p&gt;
  &lt;br /&gt;
  &lt;br /&gt;

  &lt;p align=&quot;center&quot; &gt;
  &lt;b&gt;Git, &lt;i&gt;but&lt;/i&gt; better&lt;/b&gt;. GitButler is a modern Git-based version control interface with both a GUI and CLI built from the ground up for AI-powered workflows.
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://gitbutler.com&quot;&gt;Website&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;â€¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://blog.gitbutler.com/&quot;&gt;Blog&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;â€¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://docs.gitbutler.com/&quot;&gt;Docs&lt;/a&gt;
    &lt;span&gt;&amp;nbsp;&amp;nbsp;â€¢&amp;nbsp;&amp;nbsp;&lt;/span&gt;
    &lt;a href=&quot;https://gitbutler.com/downloads&quot;&gt;Downloads&lt;/a&gt;
  &lt;/p&gt;

[![TWEET][s1]][l1] [
![BLUESKY][s8]][l8 ] [![DISCORD][s2]][l2]

[![CI][s0]][l0] [![INSTA][s3]][l3] [![YOUTUBE][s5]][l5] [![DEEPWIKI][s7]][l7]

[s0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml/badge.svg
[l0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml
[s1]: https://img.shields.io/badge/Twitter-black?logo=x&amp;logoColor=white
[l1]: https://twitter.com/intent/follow?screen_name=gitbutler
[s2]: https://img.shields.io/discord/1060193121130000425?label=Discord&amp;color=5865F2
[l2]: https://discord.gg/MmFkmaJ42D
[s3]: https://img.shields.io/badge/Instagram-E4405F?logo=instagram&amp;logoColor=white
[l3]: https://www.instagram.com/gitbutler/
[s5]: https://img.shields.io/youtube/channel/subscribers/UCEwkZIHGqsTGYvX8wgD0LoQ
[l5]: https://www.youtube.com/@gitbutlerapp
[s7]: https://deepwiki.com/badge.svg
[l7]: https://deepwiki.com/gitbutlerapp/gitbutler
[s8]: https://img.shields.io/badge/Bluesky-0285FF?logo=bluesky&amp;logoColor=fff
[l8]: https://bsky.app/profile/gitbutler.com

&lt;/div&gt;

&lt;br/&gt;

GitButler is a powerful new Git-based version control system, designed from scratch to be simple, powerful and flexible. It is designed for ease of use and modern agentic workflows.

It features stacked branches, parallel branches, unlimited undo, easy commit mutations, forge integrations and more.

Works instantly in any existing Git repo as a friendlier and more powerful drop-in Git user interface replacement - for you and your agents.

## Main Features

Why use GitButler instead of vanilla Git? What a great question.

- **Stacked Branches** ([gui](https://docs.gitbutler.com/features/branch-management/stacked-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/branching-and-commiting#stacked-branches))
  - Effortlessly create branches stacked on other branches. Amend or edit any commit easily with automatic restacking.
- **Parallel Branches** ([gui](https://docs.gitbutler.com/features/branch-management/virtual-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/branching-and-commiting#parallel-branches))
  - Organize work on multiple branches simultaneously, rather than constantly switching branches.
- **Easy Commit Management** ([gui](https://docs.gitbutler.com/features/branch-management/commits), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/rubbing))
  - Uncommit, reword, amend, move, split and squash commits by dragging and dropping or simple CLI commands. Forget about `rebase -i`, you don&#039;t need it anymore.
- **Undo Timeline** ([gui](https://docs.gitbutler.com/features/timeline), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/operations-log))
  - Logs all operations and changes and allows you to easily undo or revert any operation.
- **First Class Conflicts** ([gui](https://docs.gitbutler.com/overview#conflicting-branches), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/conflict-resolution))
  - Rebases always succeed. Commits can be marked as conflicted and resolved at any time, in any order.
- **Forge Integration** ([gui](https://docs.gitbutler.com/features/forge-integration/github-integration), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/forges))
  - Authenticate to GitHub or GitLab to easily open and update Pull Requests, list branches, get CI statuses and more. No other tools required.
- **AI Tooling** ([gui](https://docs.gitbutler.com/features/ai-integration/ai-overview), [cli](https://docs.gitbutler.com/cli-guides/cli-tutorial/ai-stuff))
  - Use built-in AI handlers to help create commit messages, branch names, PR descriptions and more.
  - Easily install hooks or skills for all modern agent systems to level up their Git management.

## Tech

The GitButler desktop app is a [Tauri](https://tauri.app/)-based application. Its UI is written in [Svelte](https://svelte.dev/) using [TypeScript](https://www.typescriptlang.org) and its backend is written in [Rust](https://www.rust-lang.org/).

The `but` CLI is the same Rust backend engine with a Rust command line UI.

## Documentation

You can find our end user documentation at: &lt;https://docs.gitbutler.com&gt;

## Bugs and Feature Requests

If you have a bug or feature request, feel free to open an [issue](https://github.com/gitbutlerapp/gitbutler/issues/new),
or [join our Discord server](https://discord.gg/MmFkmaJ42D).

## License

The TLDR is that GitButler is under a [Fair Source](https://fair.io/) software license, meaning that you can use it, view the source, contribute, etc. You just can&#039;t build a competitor with it. It also becomes MIT after 2 years. So, MIT with an expiring non-compete clause.

## Contributing

So you want to help out? Please check out the [CONTRIBUTING.md](CONTRIBUTING.md)
document.

If you want to skip right to getting the code to actually compile, take a look
at the [DEVELOPMENT.md](DEVELOPMENT.md) file.

### Contributors

&lt;a href=&quot;https://github.com/gitbutlerapp/gitbutler/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=gitbutlerapp/gitbutler&quot; /&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[matrix-construct/tuwunel]]></title>
            <link>https://github.com/matrix-construct/tuwunel</link>
            <guid>https://github.com/matrix-construct/tuwunel</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:27 GMT</pubDate>
            <description><![CDATA[Official successor to conduwuit]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/matrix-construct/tuwunel">matrix-construct/tuwunel</a></h1>
            <p>Official successor to conduwuit</p>
            <p>Language: Rust</p>
            <p>Stars: 1,328</p>
            <p>Forks: 90</p>
            <p>Stars today: 50 stars today</p>
            <h2>README</h2><pre># Tuwunel&lt;sup&gt;ğŸ’•&lt;/sup&gt;

![GitHub License](https://img.shields.io/github/license/matrix-construct/tuwunel?style=flat%2Dsquare&amp;color=%238A2BE2)
![GitHub Created At](https://img.shields.io/github/created-at/matrix-construct/tuwunel?style=flat%2Dsquare&amp;color=%238A2BE2)
![GitHub Commit Activity](https://img.shields.io/github/commit-activity/m/matrix-construct/tuwunel?style=flat%2Dsquare&amp;link=https%3A%2F%2Fgithub.com%2Fmatrix-construct%2Ftuwunel%2Fpulse%2Fmonthly&amp;color=%238A2BE2)
![Docker Pulls](https://img.shields.io/docker/pulls/jevolk/tuwunel?style=flat%2Dsquare&amp;color=8A2BE2)
![GitHub Repo Stars](https://img.shields.io/github/stars/matrix-construct/tuwunel?style=flat%2Dsquare&amp;link=https%3A%2F%2Fgithub.com%2Fmatrix-construct%2Ftuwunel&amp;color=%238A2BE2)
[![CI/CD](https://github.com/matrix-construct/tuwunel/actions/workflows/main.yml/badge.svg?branch=main&amp;style=flat%2Dsquare)](https://github.com/matrix-construct/tuwunel/actions/workflows/main.yml)

&lt;!-- ANCHOR: catchphrase --&gt;

## High Performance Matrix Homeserver in Rust!

&lt;!-- ANCHOR_END: catchphrase --&gt;

&lt;!-- ANCHOR: body --&gt;

[![Documentation](https://img.shields.io/badge/documentation%2D_?color=%238A2BE2&amp;style=for-the-badge&amp;logo=mdBook&amp;logoColor=FFFFFF)](https://matrix-construct.github.io/tuwunel/)
[![Demo Server](https://img.shields.io/badge/demo%20server%2D_?color=%238A2BE2&amp;style=for-the-badge&amp;logo=Element&amp;logoColor=FFFFFF)](https://try.tuwunel.chat)
[![Support Chat](https://img.shields.io/matrix/tuwunel%3Amatrix.org.svg?color=098A09&amp;style=for-the-badge&amp;label=Support%20Chat&amp;labelColor=8A2BE2&amp;logo=Matrix)](https://matrix.to/#/#tuwunel:grin.hu)

Tuwunel is a featureful [Matrix](https://matrix.org/) homeserver you can use instead of Synapse
with your favorite [client](https://matrix.org/ecosystem/clients/),
[bridge](https://matrix.org/ecosystem/bridges/) or
[bot](https://matrix.org/ecosystem/integrations/). It is written entirely in Rust to be a scalable,
low-cost, enterprise-ready, community-driven alternative, fully implementing the
[Matrix Specification](https://spec.matrix.org/latest/) for all but the most niche uses.

This project is the official successor to [conduwuit](https://github.com/x86pup/conduwuit) after it
reached stability. Tuwunel is now used by many companies with a vested interest in its continued
development by full-time staff. It is primarily sponsored by the government of
Switzerland ğŸ‡¨ğŸ‡­ where it is currently deployed for citizens.

### Getting Started

- [GitHub Releases](https://github.com/matrix-construct/tuwunel/releases)
- [Sourcecode](https://github.com/matrix-construct/tuwunel/) `git clone https://github.com/matrix-construct/tuwunel.git`
- [DockerHub](https://hub.docker.com/r/jevolk/tuwunel) or `docker pull jevolk/tuwunel:latest`
- [GHCR](https://github.com/matrix-construct/tuwunel/pkgs/container/tuwunel) or `docker pull ghcr.io/matrix-construct/tuwunel:latest`
- Static binaries available as [releases](https://github.com/matrix-construct/tuwunel/releases) or [build artifacts](https://github.com/matrix-construct/tuwunel/actions?query=branch%3Amain).
- Deb and RPM packages available as [releases](https://github.com/matrix-construct/tuwunel/releases) or [build artifacts](https://github.com/matrix-construct/tuwunel/actions?query=branch%3Amain).
- Arch package available as [tuwunel](https://aur.archlinux.org/packages/tuwunel) or [tuwunel-git](https://aur.archlinux.org/packages/tuwunel-git).
- Nix package available as [`matrix-tuwunel`](https://search.nixos.org/packages?query=matrix-tuwunel) and NixOS module available as [`services.matrix-tuwunel`](https://search.nixos.org/options?query=services.matrix-tuwunel).
- Alpine package available as [tuwunel](https://pkgs.alpinelinux.org/package/edge/testing/x86_64/tuwunel).

**1.** [Configure](https://matrix-construct.github.io/tuwunel/configuration.html) by
copying and editing the `tuwunel-example.toml`. The `server_name` and `database_path` must be
configured. **Most users deploy via docker or a distribution package and should follow the
[appropriate guide](https://matrix-construct.github.io/tuwunel/deploying.html) instead.**
This is just a summary for the impatient. See the full
[documentation](https://matrix-construct.github.io/tuwunel/).

&gt; [!TIP]
&gt; Avoid using a sub-domain for your `server_name`. You can always delegate later with a [`.well-known`](https://github.com/spantaleev/matrix-docker-ansible-deploy/blob/master/docs/configuring-well-known.md)
&gt; file, but you can never change your `server_name`.

**2.** Setup TLS certificates. Most users enjoy the [Caddy](https://caddyserver.com/) reverse-proxy
which automates their certificate renewal. Advanced users can load their own TLS certificates
using the configuration and Tuwunel can be deployed without a reverse proxy. Example
`/etc/caddy/Caddyfile` configuration with [Element](https://github.com/element-hq/element-web/releases)
unzipped to `/var/www/element`:
```
tuwunel.me, tuwunel.me:8448 {
    reverse_proxy localhost:8008
}
web.tuwunel.me {
    root * /var/www/element/
    file_server
}
```
`caddy reload --config /etc/caddy/Caddyfile`

**3.** Start the server, connect your client and register your username. The first registration is
granted server admin.

&gt; [!TIP]
&gt; Configure a secret `registration_token` and set `allow_registration = true`

 ğŸ¤— Did you find this and other documentation helpful? We would love to hear feedback about setting
 up Tuwunel.


### Migrating to Tuwunel

| Can I migrate from | |
|-----------------|-----------|
| conduwuit? | âœ… Yes. This will be supported at a minimum for one year, but likely indefinitely. |
| Synapse? | âŒ Not yet, but this is planned and an important issue. Subscribe to [#2](https://github.com/matrix-construct/tuwunel/issues/2). |
| Conduit? | âŒ Not right now, but this is planned for the near future. Subscribe to [#41](https://github.com/matrix-construct/tuwunel/issues/41). |
| Any other fork of Conduit? | âŒ No. The migration must be explicitly listed in this table. |
&gt; [!CAUTION]
&gt; **Never switch between different forks of Conduit or you will corrupt your database.**
&gt; All derivatives of Conduit share the same linear database version without any awareness of other
&gt; forks. The database will permanently corrupt and we will not be able to help you.

#### Migrating from conduwuit

Migrating from conduwuit to Tuwunel _just works_. In technical parlance it is a &quot;binary swap.&quot;
All you have to do is update to the latest Tuwunel and change the path to the executable from
`conduwuit` to `tuwunel`.

Anything else named &quot;conduwuit&quot; is still recognized, this includes environment variables with prefixes
such as `CONDUWUIT_`. In fact, `CONDUIT_` is still recognized for our legacy users. You may have
noticed that various configs, yamls, services, users, and other items were renamed, but if you
were a conduwuit user we recommend against changing anything at all. This will keep things simple.
If you are not sure please ask. If you found out that something did in fact need to be changed
please open an issue immediately.


### Upgrading &amp; Downgrading Tuwunel

We strive to make moving between versions of Tuwunel safe and easy. Downgrading Tuwunel is always
safe but often prevented by a guard. An error will indicate the downgrade is not possible and a
newer version which does not error must be sought.

#### Branches

The main branch is always _reasonably safe_ to run. We understand the propensity for users to simply clone
the main branch to get up and running, and we&#039;re obliged to ensure it&#039;s always viable. Nevertheless, only
tagged releases are true releases.

#### Container Tracking

&gt; [!IMPORTANT]
&gt; **We strongly advise tracking the `:latest` tag when automatically updating.**

Tracking `:latest` gives us the necessary discretion to keep you on the appropriate stable version.
We discourage tracking the main branch unless frequent restarts are acceptable. Alternatively,
tracking the `:preview` tag provides the latest release-candidate becoming equivalent to `:latest`
after a release. Tracking the `:preview` tag is a worthy alternative to the main branch, with
turbulence limited to release-time.

### Getting Help &amp; Support

If you are opposed to using github, or if private discussion is required such as for security
disclosures, or for any other reason, I would be happy to receive your DM at
[@jason:tuwunel.me](https://matrix.to/#/@jason:tuwunel.me). This will not be bothering me as it would
be my pleasure to help you when possible. As an emergency contact you can send an email to
jasonzemos@gmail.com.

##### Tuwunel Fanclub

We have an unofficial community-run chat which is publicly accessible at
[#tuwunel:matrix.org](https://matrix.to/#/#tuwunel:matrix.org). The members, content, or moderation
decisions of this room are not in any way related or endorsed by this project or its sponsors,
and not all project staff will be present there. There will be at least some presence by staff to
offer assistance so long as the room remains in minimally good standing.


## Tuwunel&lt;sup&gt;ğŸ’•&lt;/sup&gt;

Tuwunel&#039;s theme is **empathy** in communication defined by the works of
[Edith Stein](https://plato.stanford.edu/entries/stein/). Empathy is the basis for how we approach
every message and our responsibility to the other in every conversation.

&lt;!-- ANCHOR_END: body --&gt;

&lt;!-- ANCHOR: footer --&gt;

&lt;!-- ANCHOR_END: footer --&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[EricLBuehler/mistral.rs]]></title>
            <link>https://github.com/EricLBuehler/mistral.rs</link>
            <guid>https://github.com/EricLBuehler/mistral.rs</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:26 GMT</pubDate>
            <description><![CDATA[Fast, flexible LLM inference]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EricLBuehler/mistral.rs">EricLBuehler/mistral.rs</a></h1>
            <p>Fast, flexible LLM inference</p>
            <p>Language: Rust</p>
            <p>Stars: 6,563</p>
            <p>Forks: 527</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;top&quot;&gt;&lt;/a&gt;
&lt;!--
&lt;h1 align=&quot;center&quot;&gt;
  mistral.rs
&lt;/h1&gt;
--&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/res/banner.png&quot; alt=&quot;mistral.rs&quot; width=&quot;100%&quot; style=&quot;max-width: 800px;&quot;&gt;
&lt;/div&gt;

&lt;h3 align=&quot;center&quot;&gt;
Fast, flexible LLM inference.
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
  | &lt;a href=&quot;https://ericlbuehler.github.io/mistral.rs/&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://crates.io/crates/mistralrs&quot;&gt;&lt;b&gt;Rust SDK&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://ericlbuehler.github.io/mistral.rs/PYTHON_SDK.html&quot;&gt;&lt;b&gt;Python SDK&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://discord.gg/SZrecqK8qw&quot;&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/EricLBuehler/mistral.rs/stargazers&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/stars/EricLBuehler/mistral.rs?style=social&amp;label=Star&quot; alt=&quot;GitHub stars&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## Why mistral.rs?

- **Any HuggingFace model, zero config**: Just `mistralrs run -m user/model`. Auto-detects architecture, quantization, chat template.
- **True multimodality**: Vision, audio, speech generation, image generation, embeddings.
- **Not another model registry**: Use HuggingFace models directly. No converting, no uploading to a separate service.
- **Full quantization control**: Choose the precise quantization you want to use, or make your own UQFF with `mistralrs quantize`.
- **Built-in web UI**: `mistralrs serve --ui` gives you a web interface instantly.
- **Hardware-aware**: `mistralrs tune` benchmarks your system and picks optimal quantization + device mapping.
- **Flexible SDKs**: Python package and Rust crate to build your projects.

## Quick Start

### Install

**Linux/macOS:**
```bash
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/install.sh | sh
```

**Windows (PowerShell):**
```powershell
irm https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/install.ps1 | iex
```

[Manual installation &amp; other platforms](docs/INSTALLATION.md)

### Run Your First Model

```bash
# Interactive chat
mistralrs run -m Qwen/Qwen3-4B

# Or start a server with web UI
mistralrs serve --ui -m google/gemma-3-4b-it
```

Then visit `http://localhost:1234/ui` for the web chat interface.

### The `mistralrs` CLI

The CLI is designed to be **zero-config**: just point it at a model and go.

- **Auto-detection**: Automatically detects model architecture, quantization format, and chat template
- **All-in-one**: Single binary for chat, server, benchmarks, and web UI (`run`, `serve`, `bench`)
- **Hardware tuning**: Run `mistralrs tune` to automatically benchmark and configure optimal settings for your hardware
- **Format-agnostic**: Works with Hugging Face models, GGUF files, and [UQFF quantizations](docs/UQFF.md) seamlessly

```bash
# Auto-tune for your hardware and emit a config file
mistralrs tune -m Qwen/Qwen3-4B --emit-config config.toml

# Run using the generated config
mistralrs from-config -f config.toml

# Diagnose system issues (CUDA, Metal, HuggingFace connectivity)
mistralrs doctor
```

[Full CLI documentation](docs/CLI.md)

&lt;details open&gt;
  &lt;summary&gt;&lt;b&gt;Web Chat Demo&lt;/b&gt;&lt;/summary&gt;
  &lt;br&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/EricLBuehler/mistral.rs/master/res/chat.gif&quot; alt=&quot;Web Chat UI Demo&quot; /&gt;
&lt;/details&gt;

## What Makes It Fast

**Performance**
- Continuous batching support by default on all devices.
- CUDA with [FlashAttention](docs/FLASH_ATTENTION.md) V2/V3, Metal, [multi-GPU tensor parallelism](docs/DISTRIBUTED/DISTRIBUTED.md)
- [PagedAttention](docs/PAGED_ATTENTION.md) for high throughput continuous batching on CUDA or Apple Silicon, prefix caching (including multimodal)

**Quantization** ([full docs](docs/QUANTS.md))
- [In-situ quantization (ISQ)](docs/ISQ.md) of any Hugging Face model
- GGUF (2-8 bit), GPTQ, AWQ, HQQ, FP8, BNB support
- â­ [Per-layer topology](docs/TOPOLOGY.md): Fine-tune quantization per layer for optimal quality/speed
- â­ Auto-select fastest quant method for your hardware

**Flexibility**
- [LoRA &amp; X-LoRA](docs/ADAPTER_MODELS.md) with weight merging
- [AnyMoE](docs/ANYMOE.md): Create mixture-of-experts on any base model
- [Multiple models](docs/multi_model/README.md): Load/unload at runtime

**Agentic Features**
- Integrated [tool calling](docs/TOOL_CALLING.md) with Python/Rust callbacks
- â­ [Web search integration](docs/WEB_SEARCH.md)
- â­ [MCP client](docs/MCP/README.md): Connect to external tools automatically

[Full feature documentation](docs/README.md)

## Supported Models

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Text Models&lt;/b&gt;&lt;/summary&gt;

- Granite 4.0
- SmolLM 3
- DeepSeek V3
- GPT-OSS
- DeepSeek V2
- Qwen 3 MoE
- Phi 3.5 MoE
- Qwen 3
- GLM 4
- GLM-4.7-Flash
- GLM-4.7 (MoE)
- Gemma 2
- Qwen 2
- Starcoder 2
- Phi 3
- Mixtral
- Phi 2
- Gemma
- Llama
- Mistral
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Vision Models&lt;/b&gt;&lt;/summary&gt;

- Qwen 3-VL
- Gemma 3n
- Llama 4
- Gemma 3
- Mistral 3
- Phi 4 multimodal
- Qwen 2.5-VL
- MiniCPM-O
- Llama 3.2 Vision
- Qwen 2-VL
- Idefics 3
- Idefics 2
- LLaVA Next
- LLaVA
- Phi 3V
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Speech Models&lt;/b&gt;&lt;/summary&gt;

- Dia
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Image Generation Models&lt;/b&gt;&lt;/summary&gt;

- FLUX
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Embedding Models&lt;/b&gt;&lt;/summary&gt;

- Embedding Gemma
- Qwen 3 Embedding
&lt;/details&gt;

[Request a new model](https://github.com/EricLBuehler/mistral.rs/issues/156) | [Full compatibility tables](docs/SUPPORTED_MODELS.md)

## Python SDK

```bash
pip install mistralrs  # or mistralrs-cuda, mistralrs-metal, mistralrs-mkl, mistralrs-accelerate
```

```python
from mistralrs import Runner, Which, ChatCompletionRequest

runner = Runner(
    which=Which.Plain(model_id=&quot;Qwen/Qwen3-4B&quot;),
    in_situ_quant=&quot;4&quot;,
)

res = runner.send_chat_completion_request(
    ChatCompletionRequest(
        model=&quot;default&quot;,
        messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}],
        max_tokens=256,
    )
)
print(res.choices[0].message.content)
```

[Python SDK](https://ericlbuehler.github.io/mistral.rs/PYTHON_SDK.html) | [Installation](https://ericlbuehler.github.io/mistral.rs/PYTHON_INSTALLATION.html) | [Examples](examples/python) | [Cookbook](examples/python/cookbook.ipynb)

## Rust SDK

```bash
cargo add mistralrs
```

```rust
use anyhow::Result;
use mistralrs::{IsqType, TextMessageRole, TextMessages, VisionModelBuilder};

#[tokio::main]
async fn main() -&gt; Result&lt;()&gt; {
    let model = VisionModelBuilder::new(&quot;google/gemma-3-4b-it&quot;)
        .with_isq(IsqType::Q4K)
        .with_logging()
        .build()
        .await?;

    let messages = TextMessages::new().add_message(
        TextMessageRole::User,
        &quot;Hello!&quot;,
    );

    let response = model.send_chat_request(messages).await?;

    println!(&quot;{:?}&quot;, response.choices[0].message.content);

    Ok(())
}
```

[Rust SDK](https://crates.io/crates/mistralrs) | [Examples](mistralrs/examples)

## Docker

For quick containerized deployment:

```bash
docker pull ghcr.io/ericlbuehler/mistral.rs:latest
docker run --gpus all -p 1234:1234 ghcr.io/ericlbuehler/mistral.rs:latest \
  serve -m Qwen/Qwen3-4B
```

[Docker images](https://github.com/EricLBuehler/mistral.rs/pkgs/container/mistral.rs)

&gt; For production use, we recommend installing the CLI directly for maximum flexibility.

## Documentation

For complete documentation, see the **[Documentation](https://ericlbuehler.github.io/mistral.rs/)**.

**Quick Links:**
- [CLI Reference](docs/CLI.md) - All commands and options
- [HTTP API](docs/HTTP.md) - OpenAI-compatible endpoints
- [Quantization](docs/QUANTS.md) - ISQ, GGUF, GPTQ, and more
- [Device Mapping](docs/DEVICE_MAPPING.md) - Multi-GPU and CPU offloading
- [MCP Integration](docs/MCP/README.md) - MCP integration documentation
- [Troubleshooting](docs/TROUBLESHOOTING.md) - Common issues and solutions
- [Configuration](docs/CONFIGURATION.md) - Environment variables for configuration

## Contributing

Contributions welcome! Please [open an issue](https://github.com/EricLBuehler/mistral.rs/issues) to discuss new features or report bugs. If you want to add a new model, please contact us via an issue and we can coordinate.

## Credits

This project would not be possible without the excellent work at [Candle](https://github.com/huggingface/candle). Thank you to all [contributors](https://github.com/EricLBuehler/mistral.rs/graphs/contributors)!

mistral.rs is not affiliated with Mistral AI.

&lt;p align=&quot;right&quot;&gt;
  &lt;a href=&quot;#top&quot;&gt;Back to Top&lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lbjlaq/Antigravity-Manager]]></title>
            <link>https://github.com/lbjlaq/Antigravity-Manager</link>
            <guid>https://github.com/lbjlaq/Antigravity-Manager</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:25 GMT</pubDate>
            <description><![CDATA[Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).ä¸“ä¸šçš„ Antigravity è´¦å·ç®¡ç†ä¸åˆ‡æ¢å·¥å…·ã€‚ä¸º Antigravity æä¾›ä¸€é”®æ— ç¼è´¦å·åˆ‡æ¢åŠŸèƒ½ã€‚]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lbjlaq/Antigravity-Manager">lbjlaq/Antigravity-Manager</a></h1>
            <p>Professional Antigravity Account Manager & Switcher. One-click seamless account switching for Antigravity Tools. Built with Tauri v2 + React (Rust).ä¸“ä¸šçš„ Antigravity è´¦å·ç®¡ç†ä¸åˆ‡æ¢å·¥å…·ã€‚ä¸º Antigravity æä¾›ä¸€é”®æ— ç¼è´¦å·åˆ‡æ¢åŠŸèƒ½ã€‚</p>
            <p>Language: Rust</p>
            <p>Stars: 22,929</p>
            <p>Forks: 2,600</p>
            <p>Stars today: 296 stars today</p>
            <h2>README</h2><pre># Antigravity Tools ğŸš€
&gt; ä¸“ä¸šçº§ AI è´¦å·ç®¡ç†ä¸åè®®ä»£ç†ç³»ç»Ÿ (v4.1.15)
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;public/icon.png&quot; alt=&quot;Antigravity Logo&quot; width=&quot;120&quot; height=&quot;120&quot; style=&quot;border-radius: 24px; box-shadow: 0 10px 30px rgba(0,0,0,0.15);&quot;&gt;

  &lt;h3&gt;æ‚¨çš„ä¸ªäººé«˜æ€§èƒ½ AI è°ƒåº¦ç½‘å…³&lt;/h3&gt;
  &lt;p&gt;ä¸ä»…ä»…æ˜¯è´¦å·ç®¡ç†ï¼Œæ›´æ˜¯æ‰“ç ´ API è°ƒç”¨å£å’çš„ç»ˆæè§£å†³æ–¹æ¡ˆã€‚&lt;/p&gt;
  
  &lt;p&gt;
    &lt;a href=&quot;https://github.com/lbjlaq/Antigravity-Manager&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Version-4.1.15-blue?style=flat-square&quot; alt=&quot;Version&quot;&gt;
    &lt;/a&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Tauri-v2-orange?style=flat-square&quot; alt=&quot;Tauri&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Backend-Rust-red?style=flat-square&quot; alt=&quot;Rust&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Frontend-React-61DAFB?style=flat-square&quot; alt=&quot;React&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-CC--BY--NC--SA--4.0-lightgrey?style=flat-square&quot; alt=&quot;License&quot;&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;#-æ ¸å¿ƒåŠŸèƒ½&quot;&gt;æ ¸å¿ƒåŠŸèƒ½&lt;/a&gt; â€¢ 
    &lt;a href=&quot;#-ç•Œé¢å¯¼è§ˆ&quot;&gt;ç•Œé¢å¯¼è§ˆ&lt;/a&gt; â€¢ 
    &lt;a href=&quot;#-æŠ€æœ¯æ¶æ„&quot;&gt;æŠ€æœ¯æ¶æ„&lt;/a&gt; â€¢ 
    &lt;a href=&quot;#-å®‰è£…æŒ‡å—&quot;&gt;å®‰è£…æŒ‡å—&lt;/a&gt; â€¢ 
    &lt;a href=&quot;#-å¿«é€Ÿæ¥å…¥&quot;&gt;å¿«é€Ÿæ¥å…¥&lt;/a&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;strong&gt;ç®€ä½“ä¸­æ–‡&lt;/strong&gt; | 
    &lt;a href=&quot;./README_EN.md&quot;&gt;English&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

---

**Antigravity Tools** æ˜¯ä¸€ä¸ªä¸“ä¸ºå¼€å‘è€…å’Œ AI çˆ±å¥½è€…è®¾è®¡çš„å…¨åŠŸèƒ½æ¡Œé¢åº”ç”¨ã€‚å®ƒå°†å¤šè´¦å·ç®¡ç†ã€åè®®è½¬æ¢å’Œæ™ºèƒ½è¯·æ±‚è°ƒåº¦å®Œç¾ç»“åˆï¼Œä¸ºæ‚¨æä¾›ä¸€ä¸ªç¨³å®šã€æé€Ÿä¸”æˆæœ¬ä½å»‰çš„ **æœ¬åœ° AI ä¸­è½¬ç«™**ã€‚

é€šè¿‡æœ¬åº”ç”¨ï¼Œæ‚¨å¯ä»¥å°†å¸¸è§çš„ Web ç«¯ Session (Google/Anthropic) è½¬åŒ–ä¸ºæ ‡å‡†åŒ–çš„ API æ¥å£ï¼Œæ¶ˆé™¤ä¸åŒå‚å•†é—´çš„åè®®é¸¿æ²Ÿã€‚

## ğŸ’– èµåŠ©å•† (Sponsors)

| èµåŠ©å•† (Sponsor) | ç®€ä»‹ (Description) |
| :---: | :--- |
| &lt;img src=&quot;docs/images/packycode_logo.png&quot; width=&quot;200&quot; alt=&quot;PackyCode Logo&quot;&gt; | æ„Ÿè°¢ **PackyCode** å¯¹æœ¬é¡¹ç›®çš„èµåŠ©ï¼PackyCode æ˜¯ä¸€å®¶å¯é é«˜æ•ˆçš„ API ä¸­è½¬æœåŠ¡å•†ï¼Œæä¾› Claude Codeã€Codexã€Gemini ç­‰å¤šç§æœåŠ¡çš„ä¸­è½¬ã€‚PackyCode ä¸ºæœ¬é¡¹ç›®çš„ç”¨æˆ·æä¾›äº†ç‰¹åˆ«ä¼˜æƒ ï¼šä½¿ç”¨[æ­¤é“¾æ¥](https://www.packyapi.com/register?aff=Ctrler)æ³¨å†Œï¼Œå¹¶åœ¨å……å€¼æ—¶è¾“å…¥ **â€œCtrlerâ€** ä¼˜æƒ ç å³å¯äº«å— **ä¹æŠ˜ä¼˜æƒ **ã€‚ |
| &lt;img src=&quot;docs/images/AICodeMirror.jpg&quot; width=&quot;200&quot; alt=&quot;AICodeMirror Logo&quot;&gt; | æ„Ÿè°¢ AICodeMirror èµåŠ©äº†æœ¬é¡¹ç›®ï¼AICodeMirror æä¾› Claude Code / Codex / Gemini CLI å®˜æ–¹é«˜ç¨³å®šä¸­è½¬æœåŠ¡ï¼Œæ”¯æŒä¼ä¸šçº§é«˜å¹¶å‘ã€æé€Ÿå¼€ç¥¨ã€7Ã—24 ä¸“å±æŠ€æœ¯æ”¯æŒã€‚ Claude Code / Codex / Gemini å®˜æ–¹æ¸ é“ä½è‡³ 3.8 / 0.2 / 0.9 æŠ˜ï¼Œå……å€¼æ›´æœ‰æŠ˜ä¸ŠæŠ˜ï¼AICodeMirror ä¸º Antigravity-Manager çš„ç”¨æˆ·æä¾›äº†ç‰¹åˆ«ç¦åˆ©ï¼Œé€šè¿‡[æ­¤é“¾æ¥](https://www.aicodemirror.com/register?invitecode=MV5XUM)æ³¨å†Œçš„ç”¨æˆ·ï¼Œå¯äº«å—é¦–å……8æŠ˜ï¼Œä¼ä¸šå®¢æˆ·æœ€é«˜å¯äº« 7.5 æŠ˜ï¼ |

### â˜• æ”¯æŒé¡¹ç›® (Support)

å¦‚æœæ‚¨è§‰å¾—æœ¬é¡¹ç›®å¯¹æ‚¨æœ‰æ‰€å¸®åŠ©ï¼Œæ¬¢è¿æ‰“èµä½œè€…ï¼

&lt;a href=&quot;https://www.buymeacoffee.com/Ctrler&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://cdn.buymeacoffee.com/buttons/v2/default-green.png&quot; alt=&quot;è¯·æˆ‘å–æ¯å’–å•¡&quot; style=&quot;height: 60px !important; width: 217px !important;&quot;&gt;&lt;/a&gt;

| æ”¯ä»˜å® (Alipay) | å¾®ä¿¡æ”¯ä»˜ (WeChat) | Buy Me a Coffee |
| :---: | :---: | :---: |
| ![Alipay](./docs/images/donate_alipay.png) | ![WeChat](./docs/images/donate_wechat.png) | ![Coffee](./docs/images/donate_coffee.png) |

## ğŸŒŸ æ·±åº¦åŠŸèƒ½è§£æ (Detailed Features)

### 1. ğŸ›ï¸ æ™ºèƒ½è´¦å·ä»ªè¡¨ç›˜ (Smart Dashboard)
*   **å…¨å±€å®æ—¶ç›‘æ§**: ä¸€çœ¼æ´å¯Ÿæ‰€æœ‰è´¦å·çš„å¥åº·çŠ¶å†µï¼ŒåŒ…æ‹¬ Gemini Proã€Gemini Flashã€Claude ä»¥åŠ Gemini ç»˜å›¾çš„ **å¹³å‡å‰©ä½™é…é¢**ã€‚
*   **æœ€ä½³è´¦å·æ¨è (Smart Recommendation)**: ç³»ç»Ÿä¼šæ ¹æ®å½“å‰æ‰€æœ‰è´¦å·çš„é…é¢å†—ä½™åº¦ï¼Œå®æ—¶ç®—æ³•ç­›é€‰å¹¶æ¨èâ€œæœ€ä½³è´¦å·â€ï¼Œæ”¯æŒ **ä¸€é”®åˆ‡æ¢**ã€‚
*   **æ´»è·ƒè´¦å·å¿«ç…§**: ç›´è§‚æ˜¾ç¤ºå½“å‰æ´»è·ƒè´¦å·çš„å…·ä½“é…é¢ç™¾åˆ†æ¯”åŠæœ€ååŒæ­¥æ—¶é—´ã€‚

### 2. ğŸ” å¼ºå¤§çš„è´¦å·ç®¡å®¶ (Account Management)
*   **OAuth 2.0 æˆæƒï¼ˆè‡ªåŠ¨/æ‰‹åŠ¨ï¼‰**: æ·»åŠ è´¦å·æ—¶ä¼šæå‰ç”Ÿæˆå¯å¤åˆ¶çš„æˆæƒé“¾æ¥ï¼Œæ”¯æŒåœ¨ä»»æ„æµè§ˆå™¨å®Œæˆæˆæƒï¼›å›è°ƒæˆåŠŸååº”ç”¨ä¼šè‡ªåŠ¨å®Œæˆå¹¶ä¿å­˜ï¼ˆå¿…è¦æ—¶å¯ç‚¹å‡»â€œæˆ‘å·²æˆæƒï¼Œç»§ç»­â€æ‰‹åŠ¨æ”¶å°¾ï¼‰ã€‚
*   **å¤šç»´åº¦å¯¼å…¥**: æ”¯æŒå•æ¡ Token å½•å…¥ã€JSON æ‰¹é‡å¯¼å…¥ï¼ˆå¦‚æ¥è‡ªå…¶ä»–å·¥å…·çš„å¤‡ä»½ï¼‰ï¼Œä»¥åŠä» V1 æ—§ç‰ˆæœ¬æ•°æ®åº“è‡ªåŠ¨çƒ­è¿ç§»ã€‚
*   **ç½‘å…³çº§è§†å›¾**: æ”¯æŒâ€œåˆ—è¡¨â€ä¸â€œç½‘æ ¼â€åŒè§†å›¾åˆ‡æ¢ã€‚æä¾› 403 å°ç¦æ£€æµ‹ï¼Œè‡ªåŠ¨æ ‡æ³¨å¹¶è·³è¿‡æƒé™å¼‚å¸¸çš„è´¦å·ã€‚

### 3. ğŸ”Œ åè®®è½¬æ¢ä¸ä¸­ç»§ (API Proxy)
*   **å…¨åè®®é€‚é… (Multi-Sink)**:
    *   **OpenAI æ ¼å¼**: æä¾› `/v1/chat/completions` ç«¯ç‚¹ï¼Œå…¼å®¹ 99% çš„ç°æœ‰ AI åº”ç”¨ã€‚
    *   **Anthropic æ ¼å¼**: æä¾›åŸç”Ÿ `/v1/messages` æ¥å£ï¼Œæ”¯æŒ **Claude Code CLI** çš„å…¨åŠŸèƒ½ï¼ˆå¦‚æ€æ€ç»´é“¾ã€ç³»ç»Ÿæç¤ºè¯ï¼‰ã€‚
    *   **Gemini æ ¼å¼**: æ”¯æŒ Google å®˜æ–¹ SDK ç›´æ¥è°ƒç”¨ã€‚
*   **æ™ºèƒ½çŠ¶æ€è‡ªæ„ˆ**: å½“è¯·æ±‚é‡åˆ° `429 (Too Many Requests)` æˆ– `401 (Expire)` æ—¶ï¼Œåç«¯ä¼šæ¯«ç§’çº§è§¦å‘ **è‡ªåŠ¨é‡è¯•ä¸é™é»˜è½®æ¢**ï¼Œç¡®ä¿ä¸šåŠ¡ä¸ä¸­æ–­ã€‚

### 4. ğŸ”€ æ¨¡å‹è·¯ç”±ä¸­å¿ƒ (Model Router)
*   **ç³»åˆ—åŒ–æ˜ å°„**: æ‚¨å¯ä»¥å°†å¤æ‚çš„åŸå§‹æ¨¡å‹ ID å½’ç±»åˆ°â€œè§„æ ¼å®¶æ—â€ï¼ˆå¦‚å°†æ‰€æœ‰ GPT-4 è¯·æ±‚ç»Ÿä¸€è·¯ç”±åˆ° `gemini-3-pro-high`ï¼‰ã€‚
*   **ä¸“å®¶çº§é‡å®šå‘**: æ”¯æŒè‡ªå®šä¹‰æ­£åˆ™è¡¨è¾¾å¼çº§æ¨¡å‹æ˜ å°„ï¼Œç²¾å‡†æ§åˆ¶æ¯ä¸€ä¸ªè¯·æ±‚çš„è½åœ°æ¨¡å‹ã€‚
*   **æ™ºèƒ½åˆ†çº§è·¯ç”± (Tiered Routing)**: [æ–°] ç³»ç»Ÿæ ¹æ®è´¦å·ç±»å‹ï¼ˆUltra/Pro/Freeï¼‰å’Œé…é¢é‡ç½®é¢‘ç‡è‡ªåŠ¨ä¼˜å…ˆçº§æ’åºï¼Œä¼˜å…ˆæ¶ˆè€—é«˜é€Ÿé‡ç½®è´¦å·ï¼Œç¡®ä¿é«˜é¢‘è°ƒç”¨ä¸‹çš„æœåŠ¡ç¨³å®šæ€§ã€‚
*   **åå°ä»»åŠ¡é™é»˜é™çº§**: [æ–°] è‡ªåŠ¨è¯†åˆ« Claude CLI ç­‰å·¥å…·ç”Ÿæˆçš„åå°è¯·æ±‚ï¼ˆå¦‚æ ‡é¢˜ç”Ÿæˆï¼‰ï¼Œæ™ºèƒ½é‡å®šå‘è‡³ Flash æ¨¡å‹ï¼Œä¿æŠ¤é«˜çº§æ¨¡å‹é…é¢ä¸è¢«æµªè´¹ã€‚

### 5. ğŸ¨ å¤šæ¨¡æ€ä¸ Imagen 3 æ”¯æŒ
*   **é«˜çº§ç”»è´¨æ§åˆ¶**: æ”¯æŒé€šè¿‡ OpenAI `size` (å¦‚ `1024x1024`, `16:9`) å‚æ•°è‡ªåŠ¨æ˜ å°„åˆ° Imagen 3 çš„ç›¸åº”è§„æ ¼ã€‚
*   **è¶…å¼º Body æ”¯æŒ**: åç«¯æ”¯æŒé«˜è¾¾ **100MB** (å¯é…ç½®) çš„ Payloadï¼Œå¤„ç† 4K é«˜æ¸…å›¾è¯†åˆ«ç»°ç»°æœ‰ä½™ã€‚

## ğŸ“¸ ç•Œé¢å¯¼è§ˆ (GUI Overview)

| | |
| :---: | :---: |
| ![ä»ªè¡¨ç›˜ - å…¨å±€é…é¢ç›‘æ§ä¸ä¸€é”®åˆ‡æ¢](docs/images/dashboard-light.png) &lt;br&gt; ä»ªè¡¨ç›˜ | ![è´¦å·åˆ—è¡¨ - é«˜å¯†åº¦é…é¢å±•ç¤ºä¸ 403 æ™ºèƒ½æ ‡æ³¨](docs/images/accounts-light.png) &lt;br&gt; è´¦å·åˆ—è¡¨ |
| ![å…³äºé¡µé¢ - å…³äº Antigravity Tools](docs/images/about-dark.png) &lt;br&gt; å…³äºé¡µé¢ | ![API åä»£ - æœåŠ¡æ§åˆ¶](docs/images/v3/proxy-settings.png) &lt;br&gt; API åä»£ |
| ![ç³»ç»Ÿè®¾ç½® - é€šç”¨é…ç½®](docs/images/settings-dark.png) &lt;br&gt; ç³»ç»Ÿè®¾ç½® | |

### ğŸ’¡ ä½¿ç”¨æ¡ˆä¾‹ (Usage Examples)

| | |
| :---: | :---: |
| ![Claude Code è”ç½‘æœç´¢ - ç»“æ„åŒ–æ¥æºä¸å¼•æ–‡æ˜¾ç¤º](docs/images/usage/claude-code-search.png) &lt;br&gt; Claude Code è”ç½‘æœç´¢ | ![Cherry Studio æ·±åº¦é›†æˆ - åŸç”Ÿå›æ˜¾æœç´¢å¼•æ–‡ä¸æ¥æºé“¾æ¥](docs/images/usage/cherry-studio-citations.png) &lt;br&gt; Cherry Studio æ·±åº¦é›†æˆ |
| ![Imagen 3 é«˜çº§ç»˜å›¾ - å®Œç¾è¿˜åŸ Prompt æ„å¢ƒä¸ç»†èŠ‚](docs/images/usage/image-gen-nebula.png) &lt;br&gt; Imagen 3 é«˜çº§ç»˜å›¾ | ![Kilo Code æ¥å…¥ - å¤šè´¦å·æé€Ÿè½®æ¢ä¸æ¨¡å‹ç©¿é€](docs/images/usage/kilo-code-integration.png) &lt;br&gt; Kilo Code æ¥å…¥ |

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„ (Architecture)

```mermaid
graph TD
    Client([å¤–éƒ¨åº”ç”¨: Claude Code/NextChat]) --&gt;|OpenAI/Anthropic| Gateway[Antigravity Axum Server]
    Gateway --&gt; Middleware[ä¸­é—´ä»¶: é‰´æƒ/é™æµ/æ—¥å¿—]
    Middleware --&gt; Router[Model Router: ID æ˜ å°„]
    Router --&gt; Dispatcher[è´¦å·åˆ†å‘å™¨: è½®è¯¢/æƒé‡]
    Dispatcher --&gt; Mapper[åè®®è½¬æ¢å™¨: Request Mapper]
    Mapper --&gt; Upstream[ä¸Šæ¸¸è¯·æ±‚: Google/Anthropic API]
    Upstream --&gt; ResponseMapper[å“åº”è½¬æ¢å™¨: Response Mapper]
    ResponseMapper --&gt; Client
```

##  å®‰è£…æŒ‡å— (Installation)

### é€‰é¡¹ A: ç»ˆç«¯å®‰è£… (macOS &amp; Linux æ¨è)

#### macOS 
å¦‚æœæ‚¨å·²å®‰è£… [Homebrew](https://brew.sh/)ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤å¿«é€Ÿå®‰è£…ï¼š

```bash
# 1. è®¢é˜…æœ¬ä»“åº“çš„ Tap
brew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager

# 2. å®‰è£…åº”ç”¨
brew install --cask antigravity-tools
```
&gt; **æç¤º**: å¦‚æœé‡åˆ°æƒé™é—®é¢˜ï¼Œå»ºè®®æ·»åŠ  `--no-quarantine` å‚æ•°ã€‚

#### Arch Linux
æ‚¨å¯ä»¥é€‰æ‹©é€šè¿‡ä¸€é”®å®‰è£…è„šæœ¬æˆ– Homebrew è¿›è¡Œå®‰è£…ï¼š

**æ–¹å¼ 1ï¼šä¸€é”®å®‰è£…è„šæœ¬ (æ¨è)**
```bash
curl -sSL https://raw.githubusercontent.com/lbjlaq/Antigravity-Manager/main/deploy/arch/install.sh | bash
```

**æ–¹å¼ 2ï¼šé€šè¿‡ Homebrew** (å¦‚æœæ‚¨å·²å®‰è£… [Linuxbrew](https://sh.brew.sh/))
```bash
brew tap lbjlaq/antigravity-manager https://github.com/lbjlaq/Antigravity-Manager
brew install --cask antigravity-tools
```

#### å…¶ä»– Linux å‘è¡Œç‰ˆ
å®‰è£…åä¼šè‡ªåŠ¨å°† AppImage æ·»åŠ åˆ°äºŒè¿›åˆ¶è·¯å¾„å¹¶é…ç½®å¯æ‰§è¡Œæƒé™ã€‚

### é€‰é¡¹ B: æ‰‹åŠ¨ä¸‹è½½
å‰å¾€ [GitHub Releases](https://github.com/lbjlaq/Antigravity-Manager/releases) ä¸‹è½½å¯¹åº”ç³»ç»Ÿçš„åŒ…ï¼š
*   **macOS**: `.dmg` (æ”¯æŒ Apple Silicon &amp; Intel)
*   **Windows**: `.msi` æˆ– ä¾¿æºç‰ˆ `.zip`
*   **Linux**: `.deb` æˆ– `AppImage`

### é€‰é¡¹ C: Docker éƒ¨ç½² (æ¨èç”¨äº NAS/æœåŠ¡å™¨)
å¦‚æœæ‚¨å¸Œæœ›åœ¨å®¹å™¨åŒ–ç¯å¢ƒä¸­è¿è¡Œï¼Œæˆ‘ä»¬æä¾›äº†åŸç”Ÿçš„ Docker é•œåƒã€‚è¯¥é•œåƒå†…ç½®äº†å¯¹ v4.0.2 åŸç”Ÿ Headless æ¶æ„çš„æ”¯æŒï¼Œå¯è‡ªåŠ¨æ‰˜ç®¡å‰ç«¯é™æ€èµ„æºï¼Œå¹¶é€šè¿‡æµè§ˆå™¨ç›´æ¥è¿›è¡Œç®¡ç†ã€‚

```bash
# æ–¹å¼ 1: ç›´æ¥è¿è¡Œ (æ¨è)
# - API_KEY: å¿…å¡«ã€‚ç”¨äºæ‰€æœ‰åè®®çš„ AI è¯·æ±‚é‰´å®šã€‚
# - WEB_PASSWORD: å¯é€‰ã€‚ç”¨äºç®¡ç†åå°ç™»å½•ã€‚è‹¥ä¸è®¾ç½®åˆ™é»˜è®¤ä½¿ç”¨ API_KEYã€‚
docker run -d --name antigravity-manager \
  -p 8045:8045 \
  -e API_KEY=sk-your-api-key \
  -e WEB_PASSWORD=your-login-password \
  -e ABV_MAX_BODY_SIZE=104857600 \
  -v ~/.antigravity_tools:/root/.antigravity_tools \
  lbjlaq/antigravity-manager:latest

# å¿˜è®°å¯†é’¥ï¼Ÿæ‰§è¡Œ docker logs antigravity-manager æˆ– grep -E &#039;&quot;api_key&quot;|&quot;admin_password&quot;&#039; ~/.antigravity_tools/gui_config.json

#### ğŸ” é‰´æƒé€»è¾‘è¯´æ˜
*   **åœºæ™¯ Aï¼šä»…è®¾ç½®äº† `API_KEY`**
    - **Web ç™»å½•**ï¼šä½¿ç”¨ `API_KEY` è¿›å…¥åå°ã€‚
    - **API è°ƒç”¨**ï¼šä½¿ç”¨ `API_KEY` è¿›è¡Œ AI è¯·æ±‚é‰´æƒã€‚
*   **åœºæ™¯ Bï¼šåŒæ—¶è®¾ç½®äº† `API_KEY` å’Œ `WEB_PASSWORD` (æ¨è)**
    - **Web ç™»å½•**ï¼š**å¿…é¡»**ä½¿ç”¨ `WEB_PASSWORD`ï¼Œä½¿ç”¨ API Key å°†è¢«æ‹’ç»ï¼ˆæ›´å®‰å…¨ï¼‰ã€‚
    - **API è°ƒç”¨**ï¼šç»Ÿä¸€ä½¿ç”¨ `API_KEY`ã€‚è¿™æ ·æ‚¨å¯ä»¥å°† API Key åˆ†å‘ç»™æˆå‘˜ï¼Œè€Œä¿ç•™å¯†ç ä»…ä¾›ç®¡ç†å‘˜ä½¿ç”¨ã€‚

#### ğŸ†™ æ—§ç‰ˆæœ¬å‡çº§æŒ‡å¼•
å¦‚æœæ‚¨æ˜¯ä» v4.0.1 åŠæ›´æ—©ç‰ˆæœ¬å‡çº§ï¼Œç³»ç»Ÿé»˜è®¤æœªè®¾ç½® `WEB_PASSWORD`ã€‚æ‚¨å¯ä»¥é€šè¿‡ä»¥ä¸‹ä»»ä¸€æ–¹å¼è®¾ç½®ï¼š
1.  **Web UI ç•Œé¢ (æ¨è)**ï¼šä½¿ç”¨åŸæœ‰ `API_KEY` ç™»å½•åï¼Œåœ¨ **API åä»£è®¾ç½®** é¡µé¢æ‰‹åŠ¨è®¾ç½®å¹¶ä¿å­˜ã€‚æ–°å¯†ç å°†æŒä¹…åŒ–å­˜å‚¨åœ¨ `gui_config.json` ä¸­ã€‚
2.  **ç¯å¢ƒå˜é‡ (Docker)**ï¼šåœ¨å¯åŠ¨å®¹å™¨æ—¶å¢åŠ  `-e WEB_PASSWORD=æ‚¨çš„æ–°å¯†ç `ã€‚**æ³¨æ„ï¼šç¯å¢ƒå˜é‡å…·æœ‰æœ€é«˜ä¼˜å…ˆçº§ï¼Œå°†è¦†ç›– UI ä¸­çš„ä»»ä½•ä¿®æ”¹ã€‚**
3.  **é…ç½®æ–‡ä»¶ (æŒä¹…åŒ–)**ï¼šç›´æ¥ä¿®æ”¹ `~/.antigravity_tools/gui_config.json`ï¼Œåœ¨ `proxy` å¯¹è±¡ä¸­ä¿®æ”¹æˆ–æ·»åŠ  `&quot;admin_password&quot;: &quot;æ‚¨çš„æ–°å¯†ç &quot;` å­—æ®µã€‚
    - *æ³¨ï¼š`WEB_PASSWORD` æ˜¯ç¯å¢ƒå˜é‡åï¼Œ`admin_password` æ˜¯é…ç½®æ–‡ä»¶ä¸­çš„ JSON é”®åã€‚*

&gt; [!TIP]
&gt; **å¯†ç ä¼˜å…ˆçº§é€»è¾‘ (Priority)**:
&gt; - **ç¬¬ä¸€ä¼˜å…ˆçº§ (ç¯å¢ƒå˜é‡)**: `ABV_WEB_PASSWORD` æˆ– `WEB_PASSWORD`ã€‚åªè¦è®¾ç½®äº†ç¯å¢ƒå˜é‡ï¼Œç³»ç»Ÿå°†å§‹ç»ˆä½¿ç”¨å®ƒã€‚
&gt; - **ç¬¬äºŒä¼˜å…ˆçº§ (é…ç½®æ–‡ä»¶)**: `gui_config.json` ä¸­çš„ `admin_password` å­—æ®µã€‚UI çš„â€œä¿å­˜â€æ“ä½œä¼šæ›´æ–°æ­¤å€¼ã€‚
&gt; - **ä¿åº•å›é€€ (å‘åå…¼å®¹)**: è‹¥ä¸Šè¿°å‡æœªè®¾ç½®ï¼Œåˆ™å›é€€ä½¿ç”¨ `API_KEY` ä½œä¸ºç™»å½•å¯†ç ã€‚

# æ–¹å¼ 2: ä½¿ç”¨ Docker Compose
# 1. è¿›å…¥é¡¹ç›®çš„ docker ç›®å½•
cd docker
# 2. å¯åŠ¨æœåŠ¡
docker compose up -d
```
&gt; **è®¿é—®åœ°å€**: `http://localhost:8045` (ç®¡ç†åå°) | `http://localhost:8045/v1` (API Base)
&gt; **ç³»ç»Ÿè¦æ±‚**:
&gt; - **å†…å­˜**: å»ºè®® **1GB** (æœ€å° 256MB)ã€‚
&gt; - **æŒä¹…åŒ–**: éœ€æŒ‚è½½ `/root/.antigravity_tools` ä»¥ä¿å­˜æ•°æ®ã€‚
&gt; - **æ¶æ„**: æ”¯æŒ x86_64 å’Œ ARM64ã€‚
&gt; **è¯¦æƒ…è§**: [Docker éƒ¨ç½²æŒ‡å— (docker)](./docker/README.md)

---

Copyright Â© 2024-2026 [lbjlaq](https://github.com/lbjlaq)

### ğŸ› ï¸ å¸¸è§é—®é¢˜æ’æŸ¥ (Troubleshooting)

#### macOS æç¤ºâ€œåº”ç”¨å·²æŸåï¼Œæ— æ³•æ‰“å¼€â€ï¼Ÿ
ç”±äº macOS çš„å®‰å…¨æœºåˆ¶ï¼Œé App Store ä¸‹è½½çš„åº”ç”¨å¯èƒ½ä¼šè§¦å‘æ­¤æç¤ºã€‚æ‚¨å¯ä»¥æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤å¿«é€Ÿä¿®å¤ï¼š

1.  **å‘½ä»¤è¡Œä¿®å¤** (æ¨è):
    æ‰“å¼€ç»ˆç«¯ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
    ```bash
    sudo xattr -rd com.apple.quarantine &quot;/Applications/Antigravity Tools.app&quot;
    ```
2.  **Homebrew å®‰è£…æŠ€å·§**:
    å¦‚æœæ‚¨ä½¿ç”¨ brew å®‰è£…ï¼Œå¯ä»¥æ·»åŠ  `--no-quarantine` å‚æ•°æ¥è§„é¿æ­¤é—®é¢˜ï¼š
    ```bash
    brew install --cask --no-quarantine antigravity-tools
    ```

## ğŸ”Œ å¿«é€Ÿæ¥å…¥ç¤ºä¾‹

### ğŸ” OAuth æˆæƒæµç¨‹ï¼ˆæ·»åŠ è´¦å·ï¼‰
1. æ‰“å¼€â€œAccounts / è´¦å·â€ â†’ â€œæ·»åŠ è´¦å·â€ â†’ â€œOAuthâ€ã€‚
2. å¼¹çª—ä¼šåœ¨ç‚¹å‡»æŒ‰é’®å‰é¢„ç”Ÿæˆæˆæƒé“¾æ¥ï¼›ç‚¹å‡»é“¾æ¥å³å¯å¤åˆ¶åˆ°ç³»ç»Ÿå‰ªè´´æ¿ï¼Œç„¶åç”¨ä½ å¸Œæœ›çš„æµè§ˆå™¨æ‰“å¼€å¹¶å®Œæˆæˆæƒã€‚
3. æˆæƒå®Œæˆåæµè§ˆå™¨ä¼šæ‰“å¼€æœ¬åœ°å›è°ƒé¡µå¹¶æ˜¾ç¤ºâ€œâœ… æˆæƒæˆåŠŸ!â€ã€‚
4. åº”ç”¨ä¼šè‡ªåŠ¨ç»§ç»­å®Œæˆæˆæƒå¹¶ä¿å­˜è´¦å·ï¼›å¦‚æœªè‡ªåŠ¨å®Œæˆï¼Œå¯ç‚¹å‡»â€œæˆ‘å·²æˆæƒï¼Œç»§ç»­â€æ‰‹åŠ¨å®Œæˆã€‚

&gt; æç¤ºï¼šæˆæƒé“¾æ¥åŒ…å«ä¸€æ¬¡æ€§å›è°ƒç«¯å£ï¼Œè¯·å§‹ç»ˆä½¿ç”¨å¼¹çª—é‡Œç”Ÿæˆçš„æœ€æ–°é“¾æ¥ï¼›å¦‚æœæˆæƒæ—¶åº”ç”¨æœªè¿è¡Œæˆ–å¼¹çª—å·²å…³é—­ï¼Œæµè§ˆå™¨å¯èƒ½ä¼šæç¤º `localhost refused connection`ã€‚

### å¦‚ä½•æ¥å…¥ Claude Code CLI?
1.  å¯åŠ¨ Antigravityï¼Œå¹¶åœ¨â€œAPI åä»£â€é¡µé¢å¼€å¯æœåŠ¡ã€‚
2.  åœ¨ç»ˆç«¯æ‰§è¡Œï¼š
```bash
export ANTHROPIC_API_KEY=&quot;sk-antigravity&quot;
export ANTHROPIC_BASE_URL=&quot;http://127.0.0.1:8045&quot;
claude
```

### å¦‚ä½•æ¥å…¥ OpenCode?
1.  è¿›å…¥ **API åä»£**é¡µé¢ â†’ **å¤–éƒ¨ Providers** â†’ ç‚¹å‡» **OpenCode Sync** å¡ç‰‡ã€‚
2.  ç‚¹å‡» **Sync** æŒ‰é’®ï¼Œå°†è‡ªåŠ¨ç”Ÿæˆ `~/.config/opencode/opencode.json` é…ç½®æ–‡ä»¶ï¼š
    - åˆ›å»ºç‹¬ç«‹ provider `antigravity-manager`ï¼ˆä¸è¦†ç›– google/anthropic åŸç”Ÿé…ç½®ï¼‰
    - å¯é€‰ï¼šå‹¾é€‰ **Sync accounts** å¯¼å‡º `antigravity-accounts.json`ï¼ˆplugin-compatible v3 æ ¼å¼ï¼‰ï¼Œä¾› OpenCode æ’ä»¶ç›´æ¥å¯¼å…¥
3.  ç‚¹å‡» **Clear Config** å¯ä¸€é”®æ¸…é™¤ Manager é…ç½®å¹¶æ¸…ç† legacy æ®‹ç•™ï¼›ç‚¹å‡» **Restore** å¯ä»å¤‡ä»½æ¢å¤ã€‚
4.  Windows ç”¨æˆ·è·¯å¾„ä¸º `C:\Users\&lt;ç”¨æˆ·å&gt;\.config\opencode\`ï¼ˆä¸ `~/.config/opencode` è§„åˆ™ä¸€è‡´ï¼‰ã€‚

**å¿«é€ŸéªŒè¯å‘½ä»¤ï¼š**
```bash
# æµ‹è¯• antigravity-manager providerï¼ˆæ”¯æŒ --variantï¼‰
opencode run &quot;test&quot; --model antigravity-manager/claude-sonnet-4-5-thinking --variant high

# è‹¥å·²å®‰è£… opencode-antigravity-auth æ’ä»¶ï¼ŒéªŒè¯ google provider ä»å¯ç‹¬ç«‹å·¥ä½œ
opencode run &quot;test&quot; --model google/antigravity-claude-sonnet-4-5-thinking --variant max
```

### å¦‚ä½•æ¥å…¥ Kilo Code?
1.  **åè®®é€‰æ‹©**: å»ºè®®ä¼˜å…ˆä½¿ç”¨ **Gemini åè®®**ã€‚
2.  **Base URL**: å¡«å†™ `http://127.0.0.1:8045`ã€‚
3.  **æ³¨æ„**: 
    - **OpenAI åè®®é™åˆ¶**: Kilo Code åœ¨ä½¿ç”¨ OpenAI æ¨¡å¼æ—¶ï¼Œå…¶è¯·æ±‚è·¯å¾„ä¼šå åŠ äº§ç”Ÿ `/v1/chat/completions/responses` è¿™ç§éæ ‡å‡†è·¯å¾„ï¼Œå¯¼è‡´ Antigravity è¿”å› 404ã€‚å› æ­¤è¯·åŠ¡å¿…å¡«å…¥ Base URL åé€‰æ‹© Gemini æ¨¡å¼ã€‚
    - **æ¨¡å‹æ˜ å°„**: Kilo Code ä¸­çš„æ¨¡å‹åç§°å¯èƒ½ä¸ Antigravity é»˜è®¤è®¾ç½®ä¸ä¸€è‡´ï¼Œå¦‚é‡åˆ°æ— æ³•è¿æ¥ï¼Œè¯·åœ¨â€œæ¨¡å‹æ˜ å°„â€é¡µé¢è®¾ç½®è‡ªå®šä¹‰æ˜ å°„ï¼Œå¹¶æŸ¥çœ‹**æ—¥å¿—æ–‡ä»¶**è¿›è¡Œè°ƒè¯•ã€‚

### å¦‚ä½•åœ¨ Python ä¸­ä½¿ç”¨?
```python
import openai

client = openai.OpenAI(
    api_key=&quot;sk-antigravity&quot;,
    base_url=&quot;http://127.0.0.1:8045/v1&quot;
)

response = client.chat.completions.create(
    model=&quot;gemini-3-flash&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä½ å¥½ï¼Œè¯·è‡ªæˆ‘ä»‹ç»&quot;}]
)
print(response.choices[0].message.content)
```

### å¦‚ä½•ä½¿ç”¨å›¾ç‰‡ç”Ÿæˆ (Imagen 3)?

#### æ–¹å¼ä¸€ï¼šOpenAI Images API (æ¨è)
```python
import openai

client = openai.OpenAI(
    api_key=&quot;sk-antigravity&quot;,
    base_url=&quot;http://127.0.0.1:8045/v1&quot;
)

# ç”Ÿæˆå›¾ç‰‡
response = client.images.generate(
    model=&quot;gemini-3-pro-image&quot;,
    prompt=&quot;ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚ï¼Œèµ›åšæœ‹å…‹ï¼Œéœ“è™¹ç¯&quot;,
    size=&quot;1920x1080&quot;,      # æ”¯æŒä»»æ„ WIDTHxHEIGHT æ ¼å¼ï¼Œè‡ªåŠ¨è®¡ç®—å®½é«˜æ¯”
    quality=&quot;hd&quot;,          # &quot;standard&quot; | &quot;hd&quot; | &quot;medium&quot;
    n=1,
    response_format=&quot;b64_json&quot;
)

# ä¿å­˜å›¾ç‰‡
import base64
image_data = base64.b64decode(response.data[0].b64_json)
with open(&quot;output.png&quot;, &quot;wb&quot;) as f:
    f.write(image_data)
```

**æ”¯æŒçš„å‚æ•°**ï¼š
- **`size`**: ä»»æ„ `WIDTHxHEIGHT` æ ¼å¼ï¼ˆå¦‚ `1280x720`, `1024x1024`, `1920x1080`ï¼‰ï¼Œè‡ªåŠ¨è®¡ç®—å¹¶æ˜ å°„åˆ°æ ‡å‡†å®½é«˜æ¯”ï¼ˆ21:9, 16:9, 9:16, 4:3, 3:4, 1:1ï¼‰
- **`quality`**: 
  - `&quot;hd&quot;` â†’ 4K åˆ†è¾¨ç‡ï¼ˆé«˜è´¨é‡ï¼‰
  - `&quot;medium&quot;` â†’ 2K åˆ†è¾¨ç‡ï¼ˆä¸­ç­‰è´¨é‡ï¼‰
  - `&quot;standard&quot;` â†’ é»˜è®¤åˆ†è¾¨ç‡ï¼ˆæ ‡å‡†è´¨é‡ï¼‰
- **`n`**: ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-10ï¼‰
- **`response_format`**: `&quot;b64_json&quot;` æˆ– `&quot;url&quot;`ï¼ˆData URIï¼‰

#### æ–¹å¼äºŒï¼šChat API + å‚æ•°è®¾ç½® (âœ¨ æ–°å¢)

**æ‰€æœ‰åè®®**ï¼ˆOpenAIã€Claudeï¼‰çš„ Chat API ç°åœ¨éƒ½æ”¯æŒç›´æ¥ä¼ é€’ `size` å’Œ `quality` å‚æ•°ï¼š

```python
# OpenAI Chat API
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image&quot;,
    size=&quot;1920x1080&quot;,      # âœ… æ”¯æŒä»»æ„ WIDTHxHEIGHT æ ¼å¼
    quality=&quot;hd&quot;,          # âœ… &quot;standard&quot; | &quot;hd&quot; | &quot;medium&quot;
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚&quot;}]
)
```

```bash
# Claude Messages API
curl -X POST http://127.0.0.1:8045/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-antigravity&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gemini-3-pro-image&quot;,
    &quot;size&quot;: &quot;1280x720&quot;,
    &quot;quality&quot;: &quot;hd&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸€åªå¯çˆ±çš„çŒ«å’ª&quot;}]
  }&#039;
```

```

**å‚æ•°ä¼˜å…ˆçº§**: `imageSize` å‚æ•° &gt; `quality` å‚æ•° &gt; æ¨¡å‹åç¼€

**âœ¨ æ–°å¢ `imageSize` å‚æ•°æ”¯æŒ**:

é™¤äº† `quality` å‚æ•°å¤–,ç°åœ¨è¿˜æ”¯æŒç›´æ¥ä½¿ç”¨ Gemini åŸç”Ÿçš„ `imageSize` å‚æ•°:

```python
# ä½¿ç”¨ imageSize å‚æ•°(æœ€é«˜ä¼˜å…ˆçº§)
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image&quot;,
    size=&quot;16:9&quot;,           # å®½é«˜æ¯”
    imageSize=&quot;4K&quot;,        # âœ¨ ç›´æ¥æŒ‡å®šåˆ†è¾¨ç‡: &quot;1K&quot; | &quot;2K&quot; | &quot;4K&quot;
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚&quot;}]
)
```

```bash
# Claude Messages API ä¹Ÿæ”¯æŒ imageSize
curl -X POST http://127.0.0.1:8045/v1/messages \
  -H &quot;Content-Type: application/json&quot; \
  -H &quot;x-api-key: sk-antigravity&quot; \
  -d &#039;{
    &quot;model&quot;: &quot;gemini-3-pro-image&quot;,
    &quot;size&quot;: &quot;1280x720&quot;,
    &quot;imageSize&quot;: &quot;4K&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸€åªå¯çˆ±çš„çŒ«å’ª&quot;}]
  }&#039;
```

**å‚æ•°è¯´æ˜**:
- **`imageSize`**: ç›´æ¥æŒ‡å®šåˆ†è¾¨ç‡ (`&quot;1K&quot;` / `&quot;2K&quot;` / `&quot;4K&quot;`)
- **`quality`**: é€šè¿‡è´¨é‡ç­‰çº§æ¨æ–­åˆ†è¾¨ç‡ (`&quot;standard&quot;` â†’ 1K, `&quot;medium&quot;` â†’ 2K, `&quot;hd&quot;` â†’ 4K)
- **ä¼˜å…ˆçº§**: å¦‚æœåŒæ—¶æŒ‡å®š `imageSize` å’Œ `quality`,ç³»ç»Ÿä¼šä¼˜å…ˆä½¿ç”¨ `imageSize`


#### æ–¹å¼ä¸‰ï¼šChat æ¥å£ + æ¨¡å‹åç¼€
```python
response = client.chat.completions.create(
    model=&quot;gemini-3-pro-image-16-9-4k&quot;,  # æ ¼å¼ï¼šgemini-3-pro-image-[æ¯”ä¾‹]-[è´¨é‡]
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ä¸€åº§æœªæ¥ä¸»ä¹‰é£æ ¼çš„åŸå¸‚&quot;}]
)
```

**æ¨¡å‹åç¼€è¯´æ˜**ï¼š
- **å®½é«˜æ¯”**: `-16-9`, `-9-16`, `-4-3`, `-3-4`, `-21-9`, `-1-1`
- **è´¨é‡**: `-4k` (4K), `-2k` (2K), ä¸åŠ åç¼€ï¼ˆæ ‡å‡†ï¼‰
- **ç¤ºä¾‹**: `gemini-3-pro-image-16-9-4k` â†’ 16:9 æ¯”ä¾‹ + 4K åˆ†è¾¨ç‡

#### æ–¹å¼å››ï¼šCherry Studio ç­‰å®¢æˆ·ç«¯è®¾ç½®
åœ¨æ”¯æŒ OpenAI åè®®çš„å®¢æˆ·ç«¯ï¼ˆå¦‚ Cherry Studioï¼‰ä¸­ï¼Œå¯ä»¥é€šè¿‡**æ¨¡å‹è®¾ç½®**é¡µé¢é…ç½®å›¾ç‰‡ç”Ÿæˆå‚æ•°ï¼š

1. **è¿›å…¥æ¨¡å‹è®¾ç½®**ï¼šé€‰æ‹© `gemini-3-pro-image` æ¨¡å‹
2. **é…ç½®å‚æ•°**ï¼š
   - **Size (å°ºå¯¸)**: è¾“å…¥ä»»æ„ `WIDTHxHEIGHT` æ ¼å¼ï¼ˆå¦‚ `1920x1080`, `1024x1024`ï¼‰
   - **Quality (è´¨é‡)**: é€‰æ‹© `standard` / `hd` / `medium`
   - **Number (æ•°é‡)**: è®¾ç½®ç”Ÿæˆå›¾ç‰‡æ•°é‡ï¼ˆ1-10ï¼‰
3. **å‘é€è¯·æ±‚**ï¼šç›´æ¥åœ¨å¯¹è¯æ¡†ä¸­è¾“å…¥å›¾ç‰‡æè¿°å³å¯

**å‚æ•°æ˜ å°„è§„åˆ™**ï¼š
- `size: &quot;1920x1080&quot;` â†’ è‡ªåŠ¨è®¡ç®—ä¸º `16:9` å®½é«˜æ¯”
- `quality: &quot;hd&quot;` â†’ æ˜ å°„ä¸º `4K` åˆ†è¾¨ç‡
- `quality: &quot;medium&quot;` â†’ æ˜ å°„ä¸º `2K` åˆ†è¾¨ç‡


## ğŸ“ å¼€å‘è€…ä¸ç¤¾åŒº

*   **ç‰ˆæœ¬æ¼”è¿› (Changelog)**:
    *   **v4.1.15 (2026-02-11)**:
        -   **[æ ¸å¿ƒåŠŸèƒ½] å¼€å¯ macOS ä¸ Windows åŸç”Ÿè‡ªåŠ¨æ›´æ–°æ”¯æŒ (PR #1850)**:
            -   **ç«¯åˆ°ç«¯è‡ªåŠ¨æ›´æ–°**: å¯ç”¨äº† Tauri çš„åŸç”Ÿæ›´æ–°æ’ä»¶ï¼Œæ”¯æŒåœ¨åº”ç”¨å†…ç›´æ¥æ£€æµ‹ã€ä¸‹è½½å¹¶å®‰è£…æ›´æ–°ã€‚
            -   **å‘å¸ƒå·¥ä½œæµä¿®å¤**: å½»åº•ä¿®å¤äº† Release å·¥ä½œæµä¸­ç”Ÿæˆæ›´æ–°å…ƒæ•°æ® (`updater.json`) çš„é€»è¾‘ã€‚ç°åœ¨ç³»ç»Ÿä¼šè‡ªåŠ¨æ ¹æ® `.sig` ç­¾åæ–‡ä»¶æ„å»ºå®Œæ•´çš„æ›´æ–°ç´¢å¼•ï¼Œæ”¯æŒ darwin-aarch64, darwin-x86_64 ä»¥åŠ windows-x86_64 æ¶æ„ã€‚
            -   **ä½“éªŒæ‰“é€š**: é…åˆå‰ç«¯å·²æœ‰çš„æ›´æ–°æé†’ç»„ä»¶ï¼Œå®ç°äº†ä»å‘å¸ƒåˆ°å®‰è£…çš„å…¨è‡ªåŠ¨åŒ–é—­ç¯ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] è§£å†³åˆ‡æ¢è´¦å·æ—¶ç”±äºç©º Project ID å¯¼è‡´çš„ 400 é”™è¯¯ (PR #1852)**:
            -   **ç©ºå€¼è¿‡æ»¤**: åœ¨ Proxy å±‚å¢åŠ äº†å¯¹ `project_id` çš„ç©ºå­—ç¬¦ä¸²è¿‡æ»¤é€»è¾‘ã€‚
            -   **è‡ªåŠ¨çº é”™**: å½“æ£€æµ‹åˆ°è´¦å·æ•°æ®ä¸­çš„ `project_id` ä¸ºç©ºæ—¶ï¼Œç°åœ¨ä¼šè§¦å‘è‡ªåŠ¨é‡æ–°è·å–æµç¨‹ï¼Œæœ‰æ•ˆè§£å†³äº† Issue #1846 å’Œ #1851 ä¸­æåˆ°çš„ &quot;Invalid project resource name projects/&quot; é”™è¯¯ã€‚
        -   **[æ•…éšœæ’æŸ¥] é’ˆå¯¹ HTTP 404 &quot;Resource projects/... not found&quot; çš„è§£å†³å»ºè®® (Issue #1858)**:
            -   **éªŒè¯é¡¹ç›® ID**: ç™»å½• [Google Cloud Console](https://console.cloud.google.com/)ï¼Œåœ¨é¡¹ç›®é€‰æ‹©å™¨ä¸­æœç´¢æŠ¥é”™æåˆ°çš„ IDï¼ˆå¦‚ `bold-spark-xxx`ï¼‰ã€‚è‹¥é¡¹ç›®ä¸å­˜åœ¨ï¼Œè¯·åˆ›å»ºæ–°é¡¹ç›®å¹¶å¯ç”¨æ‰€éœ€çš„ Vertex AI APIã€‚
            -   **é‡ç½®è´¦æˆ·ä¼šè¯**: å°è¯•åœ¨ Antigravity åº”ç”¨ä¸­â€œåˆ é™¤è´¦æˆ·â€å¹¶â€œé‡æ–°æ·»åŠ â€ï¼Œä»¥æ¸…é™¤æ—§çš„ä¼šè¯æ®‹ç•™ã€‚
            -   **CLI è¾…åŠ©éªŒè¯**: å»ºè®®ä½¿ç”¨ Gemini CLI (`gcloud auth login`) é‡æ–°è¿›è¡Œèº«ä»½éªŒè¯ï¼Œå¹¶ç¡®ä¿ `gcloud config set project` æŒ‡å‘äº†æ­£ç¡®çš„æœ‰æ•ˆé¡¹ç›®ã€‚
        -   **[æ•…éšœæ’æŸ¥] é’ˆå¯¹ HTTP 403 &quot;Forbidden&quot; é”™è¯¯çš„è§£å†³å»ºè®® (Issue #1834)**:
            -   **æ£€æŸ¥éªŒè¯é“¾æ¥**: è¯·æ£€æŸ¥ API å“åº”ä¸­æ˜¯å¦åŒ…å«æç¤º &quot;To continue, verify your account at...&quot; çš„é“¾æ¥ã€‚è‹¥æœ‰ï¼Œè¯·ç‚¹å‡»è¯¥é“¾æ¥å¹¶æŒ‰ç…§ Google æç¤ºå®ŒæˆéªŒè¯ã€‚
            -   **ç¡®è®¤è®¡åˆ’èµ„æ ¼**: è®¿é—® [FAQ é¡µé¢](https://antigravity.google/docs/faq#why-am-i-ineligible-for-a-google-one-ai-plan) ç¡®è®¤æ‚¨çš„è´¦å·æ˜¯å¦ç¬¦åˆ Google One AI è®¡åˆ’æˆ– Gemini Code Assist çš„ä½¿ç”¨è¦æ±‚ã€‚
            -   **è‡ªåŠ¨æ¢å¤**: éƒ¨åˆ† 403 é”™è¯¯ï¼ˆå¦‚è§¦å‘é£é™©æ§åˆ¶æˆ–é…é¢è°ƒæ•´ï¼‰å¯èƒ½ä¼šåœ¨ç­‰å¾…ä¸€æ®µæ—¶é—´åè‡ªåŠ¨æ¢å¤æ­£å¸¸ã€‚
    *   **v4.1.15 (2026-02-11)**:
        -   **[æ ¸å¿ƒä¿®å¤] Cloudflared å…¬ç½‘è®¿é—®è®¾ç½®æŒä¹…åŒ– (Issue #1805)**:
            -   **è®¾ç½®è®°å¿†**: ä¿®å¤äº† Cloudflared (CF Tunnel) çš„ Tokenã€éš§é“æ¨¡å¼åŠ HTTP/2 è®¾ç½®åœ¨åº”ç”¨é‡å¯åä¸¢å¤±çš„é—®é¢˜ã€‚
            -   **çƒ­æ›´æ–°åŒæ­¥**: å®ç°äº†è®¾ç½®çš„å®æ—¶æŒä¹…åŒ–ã€‚ç°åœ¨åˆ‡æ¢éš§é“æ¨¡å¼ã€ä¿®æ”¹ Token (å¤±ç„¦åŒæ­¥) æˆ–åˆ‡æ¢ HTTP/2 é€‰é¡¹æ—¶ï¼Œé…ç½®éƒ½ä¼šç«‹å³ä¿å­˜ï¼Œç¡®ä¿é‡å¯åæ¢å¤å¦‚åˆã€‚
        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ Warmup è¿‡ç¨‹ä¸­çš„ 403 ç¦ç”¨æ ‡è®° (PR #1803)**:
            -   **ç¦ç”¨è¯†åˆ«**: ä¿®å¤äº†è´¦å·åœ¨ Warmup (é¢„çƒ­) è¿‡ç¨‹ä¸­è¿”å› 403 é”™è¯¯æ—¶æœªè¢«æ ‡è®°ä¸º `is_forbidden` çš„é—®é¢˜ã€‚
            -   **è‡ªåŠ¨è·³è¿‡**: ç°åœ¨ Warmup è¿‡ç¨‹ä¸­æ£€æµ‹åˆ° 403 å°†ç«‹å³æ ‡è®°å¹¶æŒä¹…åŒ–è´¦å·ç¦ç”¨çŠ¶æ€ï¼Œå¹¶åœ¨åç»­çš„è°ƒåº¦ã€é¢„çƒ­å’Œé…é¢æ£€æŸ¥ä¸­è‡ªåŠ¨è·³è¿‡è¯¥è´¦å·ï¼Œé¿å…æ— æ•ˆè¯·æ±‚ã€‚
        -   **[UI ä¼˜åŒ–] è¿·ä½ è§†å›¾ (Mini View) çŠ¶æ€æ˜¾ç¤ºä¸äº¤äº’å¢å¼º (PR #1816)**:
            -   **çŠ¶æ€æŒ‡ç¤ºç‚¹**: åœ¨è¿·ä½ è§†å›¾åº•éƒ¨æ–°å¢äº†è¯·æ±‚çŠ¶æ€åœ†ç‚¹ã€‚æˆåŠŸ (200-399) æ˜¾ç¤ºä¸ºç»¿è‰²ï¼Œå¤±è´¥æ˜¾ç¤ºä¸ºçº¢è‰²ï¼Œç›´è§‚åé¦ˆæœ€è¿‘ä¸€æ¬¡è¯·æ±‚ç»“æœã€‚
            -   **æ¨¡å‹åç§°å›é€€**: ä¼˜åŒ–äº†æ¨¡å‹åç§°æ˜¾ç¤ºé€»è¾‘ã€‚å½“ `mapped_model` ä¸ºç©ºæ—¶ï¼Œè‡ªåŠ¨å›é€€æ˜¾ç¤ºåŸå§‹æ¨¡å‹ ID è€Œé &quot;Unknown&quot;ï¼Œæå‡ä¿¡æ¯é€æ˜åº¦ã€‚
            -   **åˆ·æ–°åŠ¨ç”»ä¼˜åŒ–**: æ”¹è¿›äº†åˆ·æ–°æŒ‰é’®çš„åŠ¨ç”»æ•ˆæœï¼Œä½¿æ—‹è½¬åŠ¨ç”»ä»…ä½œç”¨äº `RefreshCw` å›¾æ ‡æœ¬èº«ï¼Œäº¤äº’æ›´åŠ ç»†è…»ã€‚
        -   **[æ ¸å¿ƒåŠŸèƒ½] Claude 4.6 Adaptive Thinking æ¨¡å¼æ”¯æŒ**:
            -   **Dynamic Effort**: å…¨é¢æ”¯æŒ `effort` å‚æ•° (low/medium/high)ï¼Œå…è®¸ç”¨æˆ·åŠ¨æ€è°ƒæ•´æ¨¡å‹çš„æ€è€ƒæ·±åº¦ä¸é¢„ç®—ã€‚
            -   **Token é™åˆ¶è‡ªé€‚åº”**: ä¿®å¤äº† Adaptive æ¨¡å¼ä¸‹ `maxOutputTokens` æœªèƒ½æ­£ç¡®æ„ŸçŸ¥ Budget å¯¼è‡´è¢«æˆªæ–­çš„é—®é¢˜ï¼Œç¡®ä¿é•¿æ€ç»´é“¾ä¸è¢«è…°æ–©ã€‚
        -   **[æ–‡æ¡£æ›´æ–°] æ–°å¢ Adaptive æ¨¡å¼æµ‹è¯•ç”¨ä¾‹**:
            -   æä¾›äº† `docs/adaptive_mode_test_examples.md`ï¼Œæ¶µç›–å¤šè½®å¯¹è¯ã€å¤æ‚ä»»åŠ¡åœºæ™¯åŠ Budget æ¨¡å¼åˆ‡æ¢çš„å®Œæ•´éªŒè¯æŒ‡å—ã€‚
        -   **[æ ¸å¿ƒåŠŸèƒ½] å›¾ç‰‡ç”Ÿæˆ imageSize å‚æ•°æ”¯æŒ**:
            -   **ç›´æ¥å‚æ•°æ”¯æŒ**: æ–°å¢å¯¹ Gemini åŸç”Ÿ `imageSize` å‚æ•°çš„ç›´æ¥æ”¯æŒ,å¯åœ¨æ‰€æœ‰åè®®(OpenAI/Claude/Gemini)ä¸­ä½¿ç”¨ã€‚
            -   **å‚æ•°ä¼˜å…ˆçº§**: å®ç°äº†æ¸…æ™°çš„å‚æ•°ä¼˜å…ˆçº§é€»è¾‘:`imageSize` å‚æ•° &gt; `quality` å‚æ•°æ¨æ–­ &gt; æ¨¡å‹åç¼€æ¨æ–­ã€‚
            -   **å…¨åè®®å…¼å®¹**: OpenAI Chat APIã€Claude Messages API å’Œ Gemini åŸç”Ÿåè®®å‡æ”¯æŒé€šè¿‡ `imageSize` å­—æ®µç›´æ¥æŒ‡å®šåˆ†è¾¨ç‡(&quot;1K&quot;/&quot;2K&quot;/&quot;4K&quot;)ã€‚
            -   **å‘åå…¼å®¹**: å®Œå…¨å…¼å®¹ç°æœ‰çš„ `quality` å‚æ•°å’Œæ¨¡å‹åç¼€æ–¹å¼,ä¸å½±å“ç°æœ‰ä»£ç ã€‚
        -   **[æ ¸å¿ƒåŠŸèƒ½] Opencode æä¾›å•†éš”ç¦»ä¸æ¸…ç†å·¥ä½œæµ (PR #1820)**:
            -   **éš”ç¦»åŒæ­¥é€»è¾‘**: å®ç° Opencode æä¾›å•†çš„ç‹¬ç«‹åŒæ­¥æœºåˆ¶,é˜²æ­¢çŠ¶æ€æ±¡æŸ“,ç¡®ä¿æ•°æ®çº¯å‡€ã€‚
            -   **æ¸…ç†å·¥ä½œæµ**: æ–°å¢èµ„æºæ¸…ç†å·¥ä½œæµ,ä¼˜åŒ–èµ„æºç®¡ç†,æå‡ç³»ç»Ÿè¿è¡Œæ•ˆç‡ã€‚
            -   **ç¨³å®šæ€§å¢å¼º**: å¢å¼ºäº†åŒæ­¥è¿‡ç¨‹çš„ç¨³å®šæ€§å’Œå¯é æ€§ã€‚
    *   **v4.1.15 (2026-02-11)**:
        -   **[æ ¸å¿ƒåŠŸèƒ½] Homebrew Cask å®‰è£…æ£€æµ‹ä¸æ”¯æŒ (PR #1673)**:
            -   **åº”ç”¨å‡çº§**: æ–°å¢äº†å¯¹ Homebrew Cask å®‰è£…çš„æ£€æµ‹é€»è¾‘ã€‚å¦‚æœåº”ç”¨æ˜¯é€šè¿‡ Cask å®‰è£…çš„ï¼Œç°åœ¨å¯ä»¥ç›´æ¥åœ¨åº”ç”¨å†…è§¦å‘ `brew upgrade --cask` æµç¨‹ï¼Œå®ç°æ— ç¼å‡çº§ä½“éªŒã€‚
        -   **[æ ¸å¿ƒä¿®å¤] Gemini å›¾åƒç”Ÿæˆé…é¢ä¿æŠ¤ (PR #1764)**:
            -   **ä¿æŠ¤ç”Ÿæ•ˆ**: ä¿®å¤äº†é…é¢ä¿æŠ¤æœºåˆ¶å¯èƒ½ä¼šé”™è¯¯ç»Ÿè®¡æ–‡æœ¬è¯·æ±‚çš„é—®é¢˜ï¼Œå¹¶ç¡®ä¿åœ¨ç»˜å›¾é…é¢è€—å°½æ—¶èƒ½æ­£ç¡®æ‹¦æˆª `gemini-3-pro-image` çš„è¯·æ±‚ã€‚
        -   **[UI ä¼˜åŒ–] ä¿®å¤å¯¼èˆªæ è¾¹ç•Œä¸æ˜¾ç¤ºé—®é¢˜ (PR #1636)**:
            -   **è¾¹ç•Œä¿®å¤**: ä¿®å¤äº†å¯¼èˆªæ å³ä¾§èœå•åœ¨ç‰¹å®šçª—å£å®½åº¦ä¸‹å¯èƒ½è¶…å‡ºè¾¹ç•Œæˆ–æ˜¾ç¤ºä¸å…¨çš„é—®é¢˜ã€‚
            -   **å…¼å®¹æ€§**: æ­¤æ¬¡åˆå¹¶ä¿ç•™äº†ä¸»åˆ†æ”¯ä¸Šçš„ Mini View ç­‰æ–°ç‰¹æ€§ï¼Œåªåº”ç”¨äº†å¿…è¦çš„æ ·å¼ä¿®æ­£ã€‚
        -   **[UI ä¼˜åŒ–] ä¿®å¤è‹±æ–‡æ¨¡å¼ä¸‹çš„å¸ƒå±€æº¢å‡ºä¸æ°´å¹³æ»šåŠ¨ (Issue #1783)**:
            -   **å…¨å±€é™åˆ¶**: åœ¨å…¨å±€æ ·å¼ä¸­å°é”äº†æ°´å¹³è½´æº¢å‡ºï¼Œæœç»äº†å› æ–‡å­—è¿‡é•¿å¯¼è‡´çš„é¡µé¢æ¨ªå‘æŠ–åŠ¨ã€‚
            -   **å“åº”å¼å¢å¼º**: ä¼˜åŒ–äº†å¯¼èˆªæ æ–­ç‚¹ï¼Œå°†æ–‡å­—èƒ¶å›Šçš„æ˜¾ç¤ºé˜ˆå€¼æé«˜è‡³ 1120pxï¼Œç¡®ä¿é•¿è‹±æ–‡æ ‡ç­¾åœ¨çª„çª—å£ä¸‹è‡ªåŠ¨åˆ‡æ¢ä¸ºå›¾æ ‡æ¨¡å¼ï¼Œä¿æŒå¸ƒå±€æ•´æ´ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤å¤„ç†å¤æ‚ JSON Schema æ—¶å¯èƒ½å‘ç”Ÿçš„æ ˆæº¢å‡ºé—®é¢˜ (Issue #1781)**:
            -   **å®‰å…¨åŠ å›º**: ä¸º `flatten_refs` ç­‰æ·±åº¦é€’å½’é€»è¾‘å¼•å…¥äº† `MAX_RECURSION_DEPTH` (10) é™åˆ¶ï¼Œæœ‰æ•ˆé˜²æ­¢äº†ç”±å¾ªç¯å¼•ç”¨æˆ–è¿‡æ·±åµŒå¥—å¯¼è‡´çš„ç¨‹åºå´©æºƒã€‚
        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤æµå¼è¾“å‡ºä¸‹å¤šä¸ªå·¥å…·è°ƒç”¨è¢«é”™è¯¯æ‹¼æ¥çš„é—®é¢˜ (Issue #1786)**:
            -   **ç´¢å¼•æ ¡æ­£**: ä¿®æ­£äº† `create_openai_sse_stream` ä¸­ `tool_calls` çš„ç´¢å¼•åˆ†é…é€»è¾‘ï¼Œç¡®ä¿åŒä¸€ä¸ª chunk ä¸­çš„å¤šä¸ªå·¥å…·è°ƒç”¨æ‹¥æœ‰ç‹¬ç«‹ä¸”è¿ç»­çš„ `index`ï¼Œé¿å…äº†å‚æ•°è¢«é”™è¯¯æ‹¼æ¥å¯¼è‡´è§£æå¤±è´¥çš„ç°è±¡ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ Claude Thinking æ¨¡å‹å¤šè½®å¯¹è¯æ—¶çš„ç­¾åé”™è¯¯ (Issue #1790)**:
            -   **ç­¾åæ³¨å…¥ä¸é™çº§**: åœ¨ OpenAI åè®®è½¬æ¢å±‚ä¸­å¢åŠ äº†å¯¹å†å²æ¶ˆæ¯æ€è€ƒå—ç­¾åçš„è‡ªåŠ¨æ³¨å…¥é€»è¾‘ã€‚å½“æ— æ³•è·å–æœ‰æ•ˆç­¾åæ—¶ï¼Œè‡ªåŠ¨å°†å…¶é™çº§ä¸ºæ™®é€šæ–‡æœ¬å—ï¼Œä»è€Œè§£å†³äº† Claude-opus-thinking ç­‰æ¨¡å‹åœ¨å¤šè½®å¯¹è¯ä¸­å› ç­¾åç¼ºå¤±å¯¼è‡´çš„ HTTP 400 é”™è¯¯ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ Google Cloud é¡¹ç›® ID è·å–å¤±è´¥å¯¼è‡´çš„ 503 é”™è¯¯ (Issue #1794)**:
            -   **å¢åŠ å…œåº•**: ä¿®å¤äº†ç”±äºè´¦å·æƒé™å¯¼è‡´æ— æ³•è·å–å®˜æ–¹é¡¹ç›® ID æ—¶ä¼šè·³è¿‡è¯¥è´¦å·çš„ Bugã€‚ç°åœ¨ç³»ç»Ÿä¼šè‡ªåŠ¨å›é€€åˆ°ç»éªŒè¯ç¨³å®šçš„é€šç”¨ Project ID (`bamboo-precept-lgxtn`)ï¼Œç¡®ä¿ API è¯·æ±‚çš„è¿ç»­æ€§ã€‚
        -   **[i18n] å®Œå–„ Settings ä¸ ApiProxy å›½é™…åŒ–æ”¯æŒ (PR #1789)**:
            -   **é‡æ„**: å°† `Settings.tsx` å’Œ `ApiProxy.tsx` ä¸­ç¡¬ç¼–ç çš„ä¸­æ–‡å­—ç¬¦ä¸²æ›¿æ¢ä¸º `t()` å›½é™…åŒ–è°ƒç”¨ã€‚
            -   **ç¿»è¯‘è¡¥å…¨**: åŒæ­¥æ›´æ–°äº†éŸ©è¯­ã€ç¼…ç”¸è¯­ã€è‘¡è„ç‰™è¯­ã€ä¿„è¯­ã€åœŸè€³å…¶è¯­ã€è¶Šå—è¯­ã€ç¹ä½“ä¸­æ–‡å’Œç®€ä½“ä¸­æ–‡çš„æœ¬åœ°åŒ–è¯æ¡ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] ä¿®å¤ IP ç™½åå•åˆ é™¤å¤±è´¥é—®é¢˜ (Issue #1797)**:
            -   **å‚æ•°è§„èŒƒåŒ–**: ä¿®å¤äº†ç”±äºå‰ç«¯ä¸åç«¯å‚æ•°å‘½åé£æ ¼ (snake_case vs camelCase) ä¸ä¸€è‡´å¯¼è‡´æ— æ³•åˆ é™¤ç™½åå• IP çš„é—®é¢˜ã€‚åŒæ—¶ç»Ÿä¸€äº†é»‘åå•ç®¡ç†ä¸ IP è®¿é—®æ—¥å¿—çš„ç›¸å…³å‚æ•°ï¼Œç¡®ä¿å…¨ç³»ç»Ÿå‚æ•°ä¼ é€’çš„ä¸€è‡´æ€§ã€‚
    *   **v4.1.12 (2026-02-10)**:
        -   **[æ ¸å¿ƒåŠŸèƒ½] OpenCode CLI æ·±åº¦é›†æˆ (PR #1739)**:
            -   **è‡ªåŠ¨æ¢æµ‹**: æ–°å¢äº†å¯¹ OpenCode CLI çš„è‡ªåŠ¨æ£€æµ‹ä¸ç¯å¢ƒå˜é‡é…ç½®åŒæ­¥æ”¯æŒã€‚
            -   **ä¸€é”®åŒæ­¥**: æ”¯æŒé€šè¿‡â€œå¤–éƒ¨ Providersâ€å¡ç‰‡å°† Antigravity çš„é…ç½®æ— ç¼æ³¨å…¥åˆ° OpenCode CLI ç¯å¢ƒï¼Œå®ç°é›¶é…ç½®æ¥å…¥ã€‚
        -   **[æ ¸å¿ƒä¿®å¤] Claude Opus æ€è€ƒé¢„ç®—è‡ªåŠ¨æ³¨å…¥ (PR #1747)**:
            -   **é¢„ç®—ä¿®æ­£**: ä¿®å¤äº† Opus æ¨¡å‹åœ¨è‡ªåŠ¨å¯ç”¨æ€è€ƒæ¨¡å¼æ—¶ï¼Œæœªèƒ½æ­£ç¡®æ³¨å…¥é»˜è®¤æ€è€ƒé¢„ç®— (Thinking Budget) çš„é—®é¢˜ï¼Œé˜²æ­¢å› é¢„ç®—ç¼ºå¤±å¯¼è‡´çš„ä¸Šæ¸¸é”™è¯¯ã€‚
        -   **[æ ¸å¿ƒä¼˜åŒ–] Claude Opus 4.6 Thinking å…¨é¢å‡çº§ (Issue #1741, #1742, #1743)**:
            -  

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[freenet/freenet-core]]></title>
            <link>https://github.com/freenet/freenet-core</link>
            <guid>https://github.com/freenet/freenet-core</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:24 GMT</pubDate>
            <description><![CDATA[Declare your digital independence]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/freenet/freenet-core">freenet/freenet-core</a></h1>
            <p>Declare your digital independence</p>
            <p>Language: Rust</p>
            <p>Stars: 2,645</p>
            <p>Forks: 124</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Github Actions --&gt;
  &lt;a href=&quot;https://github.com/freenet/freenet-core/actions/workflows/ci.yml&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/freenet/freenet-core/ci.yml?branch=main&amp;label=tests&amp;style=flat-square&quot; alt=&quot;continuous integration status&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://crates.io/crates/freenet&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/freenet.svg?style=flat-square&quot;
    alt=&quot;Crates.io version&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://matrix.to/#/#freenet:matrix.org&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/matrix/freenet:matrix.org?label=matrix&amp;logo=matrix&amp;style=flat-square&quot; alt=&quot;matrix&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://docs.rs/freenet&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/docs-latest-blue.svg?style=flat-square&amp;label=api%20docs&quot;
      alt=&quot;docs.rs docs&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

This is the freenet-core repository. To learn more about Freenet please visit our website 
at [freenet.org](https://freenet.org/).

# Decentralize Everything

Freenet is the internet as it should beâ€”fully decentralized, designed to put you back in control. Imagine a global shared 
computer where you can communicate and collaborate freely, without reliance on big tech. Freenet lets you regain your 
digital independence.

Freenet is a peer-to-peer network that transforms usersâ€™ computers into a resilient, distributed platform on which anyone 
can build decentralized services. Every peer contributes to a fault-tolerant collective, ensuring services are always 
available and robust.

Todayâ€™s web is a series of siloed services, but every system built on Freenet is fully interoperable by default. Freenet 
apps can be built with popular web frameworks, accessed through any browser just like the web.

## Build Instructions

Before installing anything you need to run the following in the repository,
or the commands will fail:

```bash
$ git submodule update --init --recursive
```

To install the Freenet core:

```bash
$ cargo install --path crates/core
```

Or for the fdev utility:

```bash
$ cargo install --path crates/fdev
```
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[eythaann/Seelen-UI]]></title>
            <link>https://github.com/eythaann/Seelen-UI</link>
            <guid>https://github.com/eythaann/Seelen-UI</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:23 GMT</pubDate>
            <description><![CDATA[The Fully Customizable Desktop Environment for Windows 10/11.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/eythaann/Seelen-UI">eythaann/Seelen-UI</a></h1>
            <p>The Fully Customizable Desktop Environment for Windows 10/11.</p>
            <p>Language: Rust</p>
            <p>Stars: 15,875</p>
            <p>Forks: 483</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img src=&quot;documentation/images/logo.svg&quot; width=&quot;44&quot; align=&quot;top&quot; alt=&quot;Seelen UI Logo&quot; /&gt;
  Seelen UI
&lt;/h1&gt;

&lt;h2 align=&quot;center&quot;&gt;
  Fully Customizable Desktop Environment for Windows
  &lt;br/&gt;
  Available in 70+ Languages
&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;

[![Contributors](https://img.shields.io/github/contributors/eythaann/seelen-ui.svg)](https://github.com/eythaann/seelen-ui/graphs/contributors)
[![Last Commit](https://img.shields.io/github/last-commit/eythaann/seelen-ui.svg)](https://github.com/eythaann/seelen-ui/commits/main)
[![Version](https://img.shields.io/github/v/release/eythaann/seelen-ui.svg)](https://github.com/eythaann/seelen-ui/releases)
[![Downloads](https://img.shields.io/github/downloads/eythaann/seelen-ui/total.svg)](https://github.com/eythaann/seelen-ui/releases)

&lt;/div&gt;

&lt;img src=&quot;./documentation/images/preview.png&quot; width=&quot;100%&quot; alt=&quot;Screenshot of Seelen UI desktop showing a customized desktop environment&quot;&gt;

&lt;table align=&quot;center&quot;&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot; width=&quot;33%&quot;&gt;
      &lt;a
        href=&quot;https://apps.microsoft.com/detail/Seelen%20UI/9p67c2d4t9fb?mode=full&quot;
        target=&quot;_blank&quot;
        rel=&quot;noopener noreferrer&quot;
        aria-label=&quot;Download Seelen UI from Microsoft Store&quot;&gt;
        &lt;img src=&quot;https://get.microsoft.com/images/en-us%20dark.svg&quot; width=&quot;100%&quot; alt=&quot;Download Seelen UI from Microsoft Store&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; width=&quot;33%&quot;&gt;
      &lt;a
        href=&quot;https://discord.gg/ABfASx5ZAJ&quot;
        target=&quot;_blank&quot;
        rel=&quot;noopener noreferrer&quot;
        aria-label=&quot;Join the Seelen UI Discord community&quot;&gt;
        &lt;img src=&quot;./documentation/images/discord-alt.png&quot; width=&quot;100%&quot; alt=&quot;Join the Seelen UI Discord community&quot;&gt;
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot; width=&quot;33%&quot;&gt;
      &lt;a
        href=&#039;https://www.digitalocean.com/?refcode=955c7335abf5&amp;utm_campaign=Referral_Invite&amp;utm_medium=Referral_Program&amp;utm_source=badge&#039;
        target=&#039;_blank&#039;
        rel=&quot;noopener noreferrer&quot;
        aria-label=&quot;DigitalOcean Referral Badge&quot;
      &gt;
        &lt;img src=&#039;https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg&#039; width=&quot;100%&quot; alt=&#039;DigitalOcean Referral Badge&#039; /&gt;
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Overview

[Seelen UI](https://seelen.io/apps/seelen-ui) is a tool designed to enhance your Windows desktop experience with a focus
on customization and productivity. It integrates smoothly into your system, providing a range of features that allow you
to personalize your desktop and optimize your workflow.

- **Be Creative**: Seelen UI lets you tailor your desktop to fit your style and needs. You can adjust menus, widgets,
  icons, and other elements to create a personalized and visually appealing desktop environment.

  ![Seelen UI Custom Theme](./documentation/images/theme_preview.png)

&lt;br/&gt;

- **Enhance Your Productivity**: Seelen UI helps you organize your desktop efficiently. With a Tiling Windows Manager,
  windows automatically arrange themselves to support multitasking, making your work more streamlined.

  ![Seelen UI Tiling Window Manager](./documentation/images/twm_preview.png)

&lt;br/&gt;

- **Enjoy your music**: With an integrated media module that&#039;s compatible with most music players, Seelen UI allows you
  to enjoy your music seamlessly. You can pause, resume, and skip tracks at any time without the need to open additional
  windows.

  ![Seelen UI Media Module](./documentation/images/media_module_preview.png)

&lt;br/&gt;

- **Be faster!**: With an app launcher inspired by Rofi, Seelen UI provides a simple and intuitive way to quickly access
  your applications and execute commands.

  ![Seelen UI App Launcher](./documentation/images/app_launcher_preview.png)

&lt;br/&gt;

- **User-Friendly Configuration**: Seelen UI offers an intuitive interface for easy customization. Adjust settings such
  as themes, taskbar layouts, icons, etc. With just a few clicks.

  ![Seelen UI Settings](./documentation/images/settings_preview.png)

&lt;br/&gt;

## Installation

&gt; [!CAUTION]
&gt; Seelen UI requires the WebView runtime to be installed. On Windows 11, it comes pre-installed with the system.
&gt; However, on Windows 10, the WebView runtime is included with the `setup.exe` installer. Additionally, Microsoft Edge
&gt; is necessary to function correctly. Some users may have modified their system and removed Edge, so please ensure both
&gt; Edge and the WebView runtime are installed on your system.

&gt; [!NOTE]
&gt; On fresh installations of Windows, the app might show a white or dark screen. You only need to update your Windows
&gt; through Windows Update and restart your PC.

You can choose from different installation options based on your preference:

### Microsoft Store &lt;em&gt;(recommended)&lt;/em&gt;

Download the latest version from the [Store](https://www.microsoft.com/store/productId/9P67C2D4T9FB?ocid=pdpshare) page.
This is the recommended option because you will receive updates and a secure version of the program.

_**Note**_: It may take around 1 to 3 business days for changes to be reflected in the Microsoft Store, as updates are
approved by real people in the store.

### Winget

Install the latest version using:

```pwsh
winget install --id Seelen.SeelenUI
```

This option also uses the signed `.msix` package and ensures you have the latest secure version. Similar to the
Microsoft Store, it may take around 1 to 3 business days for changes to be reflected in Winget, as updates are approved
by real people in the `winget-pkg` project.

### .msix Installer

Download the `.msix` installer from the [Releases](https://github.com/eythaann/seelen-ui/releases) page. This package is
signed, ensuring a secure installation. This is the same option as the Microsoft Store but is a portable installer.

### .exe Installer

Download the latest version from the [Releases](https://github.com/eythaann/seelen-ui/releases) page and run the
`setup.exe` installer. This option is less recommended as the installer is not signed, which may cause it to be flagged
as a potential threat by some antivirus programs. The `setup.exe` is updated more quickly than the Microsoft Store or
Winget versions and also it receives notifications updates on new release.

## Usage

Once installed or extracted, simply open the program. The easy-to-use and intuitive GUI will guide you through the
configuration process. Customize your desktop environment effortlessly.

## Upcoming Features

Iâ€™m excited to share some upcoming features for Seelen UI! Hereâ€™s a glimpse of whatâ€™s planned for the future:

### ~~App Launcher~~ âœ…

Iâ€™m planning to develop an app launcher inspired by [Rofi](https://github.com/davatorium/rofi) on Linux. This feature
will provide a sleek and highly customizable way to quickly access your applications.

![App Launcher Preview](https://raw.githubusercontent.com/adi1090x/files/master/rofi/previews/colorful/main.gif) _Image
courtesy of [rofi-themes](https://github.com/dctxmei/rofi-themes)_

### Customizable Popup Widgets

I aim to introduce a set of fully customizable popup widgets, similar to the features available in
[EWW](https://github.com/elkowar/eww). These widgets will be highly configurable and adaptable to your needs, providing
an enhanced and interactive way to manage your desktop environment.

![Customizable Widgets Preview](https://raw.githubusercontent.com/adi1090x/widgets/main/previews/dashboard.png) _Image
courtesy of [adi1090x](https://github.com/adi1090x/widgets)_

### Custom Alt + Tab (Task Switching)

An upgraded Alt + Tab system for task switching is on the horizon. This will offer a more visually appealing and
functional experience, allowing for smoother transitions between open applications and windows.

### Custom Virtual Desktops Viewer and Animations

Iâ€™m also working on a custom virtual desktops viewer and dynamic animations to improve navigation between different
workspaces. This will provide a more intuitive and immersive multitasking experience.

Stay tuned for more updates as I develop these features. I appreciate your support and enthusiasm!

Happy customizing!

The Seelen UI Team

## Contributing

We welcome contributions!

- Read the [Contribution Guidelines](CONTRIBUTING) to get started with terms.

## License

See the [LICENSE](LICENSE) file for details.

## Contact

For inquiries and support, please contact me on [Discord](https://discord.gg/ABfASx5ZAJ).

## Sponsors

We&#039;re grateful for the support of our sponsors who help make Seelen UI possible.

|                                                                                                         Sponsor                                                                                                          | Description                                                                                                  |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------------------------------- |
| [![DigitalOcean](https://web-platforms.sfo2.cdn.digitaloceanspaces.com/WWW/Badge%201.svg)](https://www.digitalocean.com/?refcode=955c7335abf5&amp;utm_campaign=Referral_Invite&amp;utm_medium=Referral_Program&amp;utm_source=badge) | **DigitalOcean** provides cloud infrastructure services that power our development and testing environments. |
|                                                                [![SignPath](https://avatars.githubusercontent.com/u/34448643?s=60)](https://signpath.io/)                                                                | **SignPath** provides free code signing certificates, ensuring secure and trusted releases for our users.    |

## See you later

```
                 .      .&amp;     _,x&amp;&quot;``
                  &amp; .   &amp;&#039;  ;.&amp;&amp;&#039;
            &amp;.  . &amp;.&amp;     .0&amp;&amp;&amp;;&amp;&quot;&quot;`
       .    &#039;&amp;  &amp;.&amp;&amp;&amp;  .&amp;&amp;&amp;&amp;&amp;&#039;
     .&amp;         ;&amp;&amp;&amp; &amp;&amp;&amp;&amp;&amp;&#039;
    &amp;&amp;          &amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;     &amp;&amp;&amp;
   0&amp;    .     &amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&quot;&quot;
  &amp;&amp;   .0     &amp;&amp;&amp;&amp;&amp;&amp;&amp;
 0&amp;&amp; .&amp;&#039;     &amp;&amp;&amp;&amp;&amp;&amp;
:&amp;&amp;&amp;&amp;&amp;    . &amp;&amp;&amp;&amp;&amp; 
0&amp;&amp;&amp;&amp;    &amp; &amp;&amp;&amp;&amp;&amp;
&amp;&amp;&amp;&amp;&#039;   &amp;&amp;&amp;&amp;&amp;&amp;&amp;               .&amp;&amp;&amp;x&amp;
&amp;&amp;&amp;&amp;   :&amp;&amp;&amp;&amp;&amp;0.&amp;&#039;        , .&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;;.
&amp;&amp;&amp;&amp;.  &amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;        .&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&#039;               .
0&amp;&amp;&amp;&amp;  &amp;&amp;&amp;&amp;&amp;&amp;&amp;       ,&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;                &amp;
:&amp;&amp;&amp;&amp;; &amp;&amp;&amp;&amp;&amp;0       ,;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;             ;  .0
 0&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;0     ,;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;             &amp;  &amp;;
  0&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;0   :&#039;,;&quot;.&amp;&amp;&amp;&amp;&amp;&amp;&quot;.&amp;             &amp;&amp; &amp;0
   0&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;0  &#039;,;&#039;,&amp;&amp;&amp;&amp;&amp;&quot; ,&amp;&#039;             &amp;&amp;&amp;&amp;0
    0&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;0 ,x&amp;&amp;&amp;&amp;&quot; .&amp;&amp;&amp;              &amp;&amp;&amp;&amp;0
      0&amp;&amp;&amp;&amp;&amp;&amp; .&amp;&amp;&amp;&amp;&quot;&#039;&#039;&#039;&quot;&amp;&amp;&quot;&amp;&amp;            &amp;&amp;&amp;&amp;&amp;0
       0&amp;&amp; .&amp;&amp;;``       `&amp;: :&amp;         &amp;&amp;&amp;&amp;&amp;&amp;0
          &amp;&quot;&#039; &amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;   &amp;&quot;&amp; &amp;&quot;&amp;   &amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;0
            0&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;0
               0&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;0         Seelen
                    0&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;0
```

---

ğŸ“Œ **Official Website**: [https://seelen.io](https://seelen.io)

Seelen Inc Â© 2026 - All rights reserved
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[a2x/cs2-dumper]]></title>
            <link>https://github.com/a2x/cs2-dumper</link>
            <guid>https://github.com/a2x/cs2-dumper</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:22 GMT</pubDate>
            <description><![CDATA[Counter-Strike: 2 Offset Dumper]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/a2x/cs2-dumper">a2x/cs2-dumper</a></h1>
            <p>Counter-Strike: 2 Offset Dumper</p>
            <p>Language: Rust</p>
            <p>Stars: 1,744</p>
            <p>Forks: 257</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># cs2-dumper

An external offset/interface dumper for Counter-Strike 2, with support for both Windows &amp; Linux. Powered
by [memflow](https://github.com/memflow/memflow).

The native Linux version is available in the [linux](https://github.com/a2x/cs2-dumper/tree/linux) branch (currently
outdated).

For a work-in-progress offline version, check out the [cs2-analyzer](https://github.com/a2x/cs2-analyzer) repository or
view its included web demo [here](https://a2x.github.io/cs2-analyzer).

## Getting Started

You can download the latest release from [Releases](https://github.com/a2x/cs2-dumper/releases) or compile it yourself.
Note that compiling it yourself requires your Rust compiler version to be at least 1.74.0 or newer.

## Usage

1. Ensure the game is running (Being in the main menu should suffice).
2. Run the `cs2-dumper` executable.

_Note:_ If you run the executable without specifying an optional memflow connector name, it will automatically use the
[memflow-native](https://github.com/memflow/memflow-native) OS layer to read the memory of the game process. If you
wish to use an existing memflow connector instead, such as **pcileech** or **kvm**, you can pass the `connector` and
optional `connector-args` arguments to the program. These connectors can be installed and managed using
the [memflowup](https://github.com/memflow/memflowup) tool.

E.g (for pcileech). `cs2-dumper -c pcileech -a :device=FPGA -vv`

Certain connectors, such as the [kvm](https://github.com/memflow/memflow-kvm) connector on Linux or
the [pcileech](https://github.com/memflow/memflow-pcileech) / [winio](https://github.com/a2x/memflow-winio)
connectors on Windows, require elevated privileges to work. So either run the `cs2-dumper` executable with `sudo` on
Linux or as an administrator on Windows.

### Available Arguments

- `-c, --connector &lt;connector&gt;`: The name of the memflow connector to use.
- `-a, --connector-args &lt;connector-args&gt;`: Additional arguments to pass to the memflow connector.
- `-f, --file-types &lt;file-types&gt;`: The types of files to generate. Default: `cs`, `hpp`,  `json`, `rs`.
- `-i, --indent-size &lt;indent-size&gt;`: The number of spaces to use per indentation level. Default: `4`.
- `-o, --output &lt;output&gt;`: The output directory to write the generated files to. Default: `output`.
- `-p, --process-name &lt;process-name&gt;`: The name of the game process. Default: `cs2.exe`.
- `-v...`: Increase logging verbosity. Can be specified multiple times.
- `-h, --help`: Print help.
- `-V, --version`: Print version.

## Running Tests

To run the few basic provided tests, use the following command: `cargo test -- --nocapture`.

## License

Licensed under the MIT license ([LICENSE](./LICENSE)).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[oxc-project/oxc]]></title>
            <link>https://github.com/oxc-project/oxc</link>
            <guid>https://github.com/oxc-project/oxc</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:21 GMT</pubDate>
            <description><![CDATA[âš“ A collection of high-performance JavaScript tools.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oxc-project/oxc">oxc-project/oxc</a></h1>
            <p>âš“ A collection of high-performance JavaScript tools.</p>
            <p>Language: Rust</p>
            <p>Stars: 18,934</p>
            <p>Forks: 821</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://oxc.rs&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://oxc.rs/oxc-light.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://oxc.rs/oxc-dark.svg&quot;&gt;
      &lt;img alt=&quot;Oxc logo&quot; src=&quot;https://oxc.rs/oxc-dark.svg&quot; height=&quot;60&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
  &lt;br&gt;
  &lt;br&gt;
  &lt;br&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![MIT licensed][license-badge]][license-url]
[![Build Status][ci-badge]][ci-url]
[![Code Coverage][code-coverage-badge]][code-coverage-url]
[![CodSpeed Badge](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/oxc-project/oxc)
[![Sponsors][sponsors-badge]][sponsors-url]

[![Discord chat][discord-badge]][discord-url]
[![Playground][playground-badge]][playground-url]
[![Website][website-badge]][website-url]

&lt;/div&gt;

## âš“ Oxc

_/oÊŠ É›ks siË/_

The Oxidation Compiler is a collection of high-performance tools for JavaScript and TypeScript written in Rust.

Oxc is part of [VoidZero](https://voidzero.dev/)&#039;s vision for a unified, high-performance toolchain for JavaScript. It powers [Rolldown](https://rolldown.rs) ([Vite]&#039;s future bundler) and enables the next generation of ultra-fast development tools that work seamlessly together.

For more information, check out our website at [oxc.rs](https://oxc.rs).

&lt;sub&gt;\* Oxidation is the chemical process that creates rust&lt;/sub&gt;

## ğŸ—ï¸ Design Principles

- **Performance**: Through rigorous performance engineering.
- **Correctness**: Through conformance testing to standards and similar projects.
- **Developer Experience**: Clear APIs, comprehensive documentation, and sensible configuration.
- **Modular composability**: Use individual components independently or compose them into complete toolchains.

Read more about our [architecture](https://oxc.rs/docs/learn/architecture/parser.html) and [performance philosophy](https://oxc.rs/docs/learn/performance).

## ğŸ“¦ Tools &amp; Packages

| Tool        | npm                                                          | crates.io                                                   |
| ----------- | ------------------------------------------------------------ | ----------------------------------------------------------- |
| Linter      | [oxlint](https://www.npmjs.com/package/oxlint)               | -                                                           |
| Formatter   | [oxfmt](https://www.npmjs.com/package/oxfmt)                 | -                                                           |
| Parser      | [oxc-parser](https://www.npmjs.com/package/oxc-parser)       | [oxc_parser](https://crates.io/crates/oxc_parser)           |
| Transformer | [oxc-transform](https://www.npmjs.com/package/oxc-transform) | [oxc_transformer](https://crates.io/crates/oxc_transformer) |
| Minifier    | [oxc-minify](https://www.npmjs.com/package/oxc-minify)       | [oxc_minifier](https://crates.io/crates/oxc_minifier)       |
| Resolver    | [oxc-resolver](https://www.npmjs.com/package/oxc-resolver)   | [oxc_resolver](https://crates.io/crates/oxc_resolver)       |

See [documentation](https://oxc.rs/) for detailed usage guides for each tool.

## âš¡ï¸ Quick Start

### Linter

The production-ready linter catches mistakes for you with sensible defaults and optional configuration:

```bash
npx oxlint@latest
```

To give you an idea of its capabilities, here is an example from the [vscode] repository, which finishes linting 4800+ files in 0.7 seconds:

&lt;p float=&quot;left&quot; align=&quot;left&quot;&gt;
  &lt;img src=&quot;https://cdn.jsdelivr.net/gh/oxc-project/oxc-assets/linter-screenshot.png&quot; width=&quot;60%&quot;&gt;
&lt;/p&gt;

â†’ [oxlint documentation](https://oxc.rs/docs/guide/usage/linter/cli.html)

### Formatter

Fast, opinionated code formatter compatible with [Prettier]:

```bash
npx oxfmt@latest
```

â†’ [Formatter documentation](https://oxc.rs/docs/guide/usage/formatter)

### Parser (Node.js)

The fastest JavaScript/TypeScript parser written in Rust:

```bash
npm install oxc-parser
```

```js
import { parseSync } from &quot;oxc-parser&quot;;
const result = parseSync(&quot;const x = 1;&quot;);
```

â†’ [Parser documentation](https://oxc.rs/docs/guide/usage/parser)

### Transformer (Node.js)

TypeScript, React, and modern JavaScript transformation:

```bash
npm install oxc-transform
```

```js
import { transform } from &quot;oxc-transform&quot;;
const result = transform(&quot;source.tsx&quot;, code, { typescript: true });
```

â†’ [Transformer documentation](https://oxc.rs/docs/guide/usage/transformer)

### Minifier (Node.js)

High-performance JavaScript minifier:

```bash
npm install oxc-minify
```

```js
import { minify } from &quot;oxc-minify&quot;;
const result = minify(code, { mangle: true });
```

â†’ [Minifier documentation](https://oxc.rs/docs/guide/usage/minifier)

### Rust

Individual crates are published for building your own JavaScript tools:

```toml
[dependencies]
oxc = &quot;0.x&quot;
```

â†’ [Rust documentation](https://docs.rs/oxc)

## VoidZero Inc.

Oxc is a project of [VoidZero](https://voidzero.dev/), see our announcement [Announcing VoidZero - Next Generation Toolchain for JavaScript](https://voidzero.dev/blog).

If you have requirements for JavaScript tools at scale, please [get in touch](https://forms.gle/WQgjyzYJpwurpxWKA)!

## ğŸ™‹ Who&#039;s using Oxc?

[Rolldown] and [Nuxt] use Oxc for parsing. [Rolldown] also uses Oxc for transformation and minification. [Nova], [swc-node], and [knip] use [oxc_resolver][docs-resolver-url] for module resolution. [Preact], [Shopify], [ByteDance], and [Shopee] use oxlint for linting.

[See more projects using Oxc â†’](https://oxc.rs/docs/guide/projects.html)

## âœï¸ Contribute

Check out some of the [good first issues](https://github.com/oxc-project/oxc/contribute) or ask us on [Discord][discord-url].

See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidance, or read the complete [contributing guide on our website â†’](https://oxc.rs/docs/contribute/introduction.html)

If you are unable to contribute by code, you can still participate by:

- Add a [GitHub Star](https://github.com/oxc-project/oxc/stargazers) to the project
- Join us on [Discord][discord-url]
- [Follow me on X](https://x.com/boshen_c) and post about this project

## ğŸ¤ Credits

This project was incubated with the assistance of these exceptional mentors and their projects:

- [Biome][biome] - [@ematipico](https://github.com/ematipico)
- [Ruff][ruff] - [@charliermarsh](https://github.com/charliermarsh), [@MichaReiser](https://github.com/MichaReiser)
- [quick-lint-js](https://github.com/quick-lint/quick-lint-js) - [@strager](https://github.com/strager)
- [elm-review](https://package.elm-lang.org/packages/jfmengels/elm-review/latest) - [@jfmengels](https://github.com/jfmengels)

Special thanks go to:

- [@domonji](https://github.com/domonji) for bootstrapping this project together and also completing the TypeScript parser
- [@tongtong-lu](https://github.com/tongtong-lu) and [@guan-wy](https://github.com/guan-wy) for designing the [project logo](https://github.com/oxc-project/oxc-assets)

## â¤ Who&#039;s [Sponsoring Oxc](https://github.com/sponsors/Boshen)?

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/sponsors/Boshen&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/Boshen/sponsors/main/sponsors.svg&quot; alt=&quot;My sponsors&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## ğŸ“– License

Oxc is free and open-source software licensed under the [MIT License](./LICENSE).

Oxc ports or copies code from other open source projects, their licenses are listed in [**Third-party library licenses**](./THIRD-PARTY-LICENSE).

[discord-badge]: https://img.shields.io/discord/1079625926024900739?logo=discord&amp;label=Discord
[discord-url]: https://discord.gg/9uXCAwqQZW
[license-badge]: https://img.shields.io/badge/license-MIT-blue.svg
[license-url]: https://github.com/oxc-project/oxc/blob/main/LICENSE
[ci-badge]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml/badge.svg?event=push&amp;branch=main
[ci-url]: https://github.com/oxc-project/oxc/actions/workflows/ci.yml?query=event%3Apush+branch%3Amain
[code-coverage-badge]: https://codecov.io/gh/oxc-project/oxc/graph/badge.svg?token=FVHEH0BQLJ
[code-coverage-url]: https://codecov.io/gh/oxc-project/oxc
[sponsors-badge]: https://img.shields.io/github/sponsors/Boshen
[sponsors-url]: https://github.com/sponsors/Boshen
[playground-badge]: https://img.shields.io/badge/Playground-blue?color=9BE4E0
[playground-url]: https://playground.oxc.rs/
[website-badge]: https://img.shields.io/badge/Website-blue
[website-url]: https://oxc.rs
[docs-resolver-url]: https://docs.rs/oxc_resolver
[biome]: https://biomejs.dev/
[ruff]: https://beta.ruff.rs
[vscode]: https://github.com/microsoft/vscode
[rolldown]: https://rolldown.rs
[vite]: https://vitejs.dev/
[nuxt]: https://nuxt.com/
[nova]: https://trynova.dev/
[swc-node]: https://github.com/swc-project/swc-node
[knip]: https://github.com/webpro/knip
[preact]: https://preactjs.com/
[shopify]: https://shopify.com/
[bytedance]: https://www.bytedance.com/
[shopee]: https://shopee.com/
[prettier]: https://prettier.io/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tracel-ai/burn]]></title>
            <link>https://github.com/tracel-ai/burn</link>
            <guid>https://github.com/tracel-ai/burn</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:20 GMT</pubDate>
            <description><![CDATA[Burn is a next generation tensor library and Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tracel-ai/burn">tracel-ai/burn</a></h1>
            <p>Burn is a next generation tensor library and Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.</p>
            <p>Language: Rust</p>
            <p>Stars: 14,337</p>
            <p>Forks: 816</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp&quot; width=&quot;350px&quot;/&gt;

[![Discord](https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;&amp;logo=discord)](https://discord.gg/uPEBbYYDB6)
[![Current Crates.io Version](https://img.shields.io/crates/v/burn.svg)](https://crates.io/crates/burn)
[![Minimum Supported Rust Version](https://img.shields.io/crates/msrv/burn)](https://crates.io/crates/burn)
[![Documentation](https://img.shields.io/badge/docs-latest-blue)](https://burn.dev/docs/burn)
[![Test Status](https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg)](https://github.com/tracel-ai/burn/actions/workflows/test.yml)
[![license](https://shields.io/badge/license-MIT%2FApache--2.0-blue)](#license)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/tracel-ai/burn)

[&lt;img src=&quot;https://www.runblaze.dev/ci-blaze-powered.png&quot; width=&quot;125px&quot;/&gt;](https://www.runblaze.dev)

---

**Burn is a next generation Tensor Library and Deep Learning Framework that doesn&#039;t compromise on
&lt;br /&gt; flexibility, efficiency and portability.**

&lt;br/&gt;
&lt;/div&gt;

&lt;div align=&quot;left&quot;&gt;

Burn is both a tensor library and a deep learning framework optimized for numerical computing, model
inference and model training. Burn leverages Rust to perform optimizations normally only available
in static-graph frameworks, offering optimal speed without impacting flexibility.

## Backend

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png&quot; height=&quot;96px&quot;/&gt;

Burn strives to be as fast as possible on as many hardwares as possible, with robust
implementations. We believe this flexibility is crucial for modern needs where you may train your
models in the cloud, then deploy on customer hardwares, which vary from user to user.

&lt;/div&gt;

### Supported Backends

Most backends support all operating systems, so we don&#039;t mention them in the tables below.

**GPU Backends:**

|         | CUDA | ROCm | Metal | Vulkan | WebGPU | LibTorch |
| ------- | ---- | ---- | ----- | ------ | ------ | -------- |
| Nvidia  | â˜‘ï¸   | -    | -     | â˜‘ï¸     | â˜‘ï¸     | â˜‘ï¸       |
| AMD     | -    | â˜‘ï¸   | -     | â˜‘ï¸     | â˜‘ï¸     | â˜‘ï¸       |
| Apple   | -    | -    | â˜‘ï¸    | -      | â˜‘ï¸     | â˜‘ï¸       |
| Intel   | -    | -    | -     | â˜‘ï¸     | â˜‘ï¸     | -        |
| Qualcom | -    | -    | -     | â˜‘ï¸     | â˜‘ï¸     | -        |
| Wasm    | -    | -    | -     | -      | â˜‘ï¸     | -        |

**CPU Backends:**

|        | Cpu (CubeCL) | NdArray | LibTorch |
| ------ | ------------ | ------- | -------- |
| X86    | â˜‘ï¸           | â˜‘ï¸      | â˜‘ï¸       |
| Arm    | â˜‘ï¸           | â˜‘ï¸      | â˜‘ï¸       |
| Wasm   | -            | â˜‘ï¸      | -        |
| no-std | -            | â˜‘ï¸      | -        |

&lt;br /&gt;

Compared to other frameworks, Burn has a very different approach to supporting many backends. By
design, most code is generic over the Backend trait, which allows us to build Burn with swappable
backends. This makes composing backend possible, augmenting them with additional functionalities
such as autodifferentiation and automatic kernel fusion.

&lt;details&gt;
&lt;summary&gt;
Autodiff: Backend decorator that brings backpropagation to any backend ğŸ”„
&lt;/summary&gt;
&lt;br /&gt;

Contrary to the aforementioned backends, Autodiff is actually a backend _decorator_. This means that
it cannot exist by itself; it must encapsulate another backend.

The simple act of wrapping a base backend with Autodiff transparently equips it with
autodifferentiation support, making it possible to call backward on your model.

```rust
use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&lt;Wgpu&gt;;

    let device = Default::default();

    let x: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default, &amp;device);
    let y: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default, &amp;device).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;grads).unwrap();
    println!(&quot;{y_grad}&quot;);
}
```

Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend
that does not support autodiff (for inference), as this method is only offered by an Autodiff
backend.

See the [Autodiff Backend README](./crates/burn-autodiff/README.md) for more details.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Fusion: Backend decorator that brings kernel fusion to all first-party backends
&lt;/summary&gt;
&lt;br /&gt;

This backend decorator enhances a backend with kernel fusion, provided that the inner backend
supports it. Note that you can compose this backend with other backend decorators such as Autodiff.
All first-party accelerated backends (like WGPU and CUDA) use Fusion by default (`burn/fusion`
feature flag), so you typically don&#039;t need to apply it manually.

```rust
#[cfg(not(feature = &quot;fusion&quot;))]
pub type Cuda&lt;F = f32, I = i32&gt; = CubeBackend&lt;CudaRuntime, F, I, u8&gt;;

#[cfg(feature = &quot;fusion&quot;)]
pub type Cuda&lt;F = f32, I = i32&gt; = burn_fusion::Fusion&lt;CubeBackend&lt;CudaRuntime, F, I, u8&gt;&gt;;
```

Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory
bound operations, which will work gracefully with the fusion backend to make your code run even
faster during training, see [this issue](https://github.com/tracel-ai/burn/issues/936).

See the [Fusion Backend README](./crates/burn-fusion/README.md) for more details.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Router (Beta): Backend decorator that composes multiple backends into a single one
&lt;/summary&gt;
&lt;br /&gt;

That backend simplifies hardware operability, if for instance you want to execute some operations on
the CPU and other operations on the GPU.

```rust
use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&lt;(Wgpu, NdArray)&gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;device_0);
    let tensor_cpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;device_1);
}

```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations
&lt;/summary&gt;
&lt;br /&gt;

That backend has two parts, one client and one server. The client sends tensor operations over the
network to a remote compute backend. You can use any first-party backend as server in a single line
of code:

```rust
fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&lt;burn::backend::Cuda&gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&lt;RemoteDevice&gt;;

    let device = RemoteDevice::new(&quot;ws://localhost:3000&quot;);
    let tensor_gpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], Distribution::Default, &amp;device);
}

```

&lt;/details&gt;

&lt;br /&gt;

## Training &amp; Inference

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png&quot; height=&quot;96px&quot;/&gt;

The whole deep learning workflow is made easy with Burn, as you can monitor your training progress
with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU
clusters.

Burn was built from the ground up with training and inference in mind. It&#039;s also worth noting how
Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to
deployment, eliminating the need for code changes.

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;br /&gt;

&lt;a href=&quot;https://www.youtube.com/watch?v=N9RM5CQbNQc&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png&quot; alt=&quot;Burn Train TUI&quot; width=&quot;75%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;br /&gt;

**Click on the following sections to expand ğŸ‘‡**

&lt;details&gt;
&lt;summary&gt;
Training Dashboard ğŸ“ˆ
&lt;/summary&gt;
&lt;br /&gt;

As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on
the [Ratatui](https://github.com/ratatui-org/ratatui) crate allows users to follow their training
with ease without having to connect to any external application.

You can visualize your training and validation metrics updating in real-time and analyze the
lifelong progression or recent history of any registered metrics using only the arrow keys. Break
from the training loop without crashing, allowing potential checkpoints to be fully written or
important pieces of code to complete without interruption ğŸ›¡

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
ONNX Support ğŸ«
&lt;/summary&gt;
&lt;br /&gt;

Burn supports importing ONNX (Open Neural Network Exchange) models through the
[burn-onnx](https://github.com/tracel-ai/burn-onnx) crate, allowing you to easily port models from
TensorFlow or PyTorch to Burn. The ONNX model is converted into Rust code that uses Burn&#039;s native
APIs, enabling the imported model to run on any Burn backend (CPU, GPU, WebAssembly) and benefit
from all of Burn&#039;s optimizations like automatic kernel fusion.

Our ONNX support is further described in
[this section of the Burn Book ğŸ”¥](https://burn.dev/books/burn/onnx-import.html).

&gt; **Note**: This crate is in active development and currently supports a
&gt; [limited set of ONNX operators](https://github.com/tracel-ai/burn-onnx/blob/main/SUPPORTED-ONNX-OPS.md).

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Importing PyTorch or Safetensors Models ğŸšš
&lt;/summary&gt;
&lt;br /&gt;

You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models.
This makes it easy to reuse existing models while benefiting from Burn&#039;s performance and deployment
features.

Learn more in the [Saving &amp; Loading Models](https://burn.dev/books/burn/saving-and-loading.html)
section of the Burn Book.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Inference in the Browser ğŸŒ
&lt;/summary&gt;
&lt;br /&gt;

Several of our backends can run in WebAssembly environments: NdArray for CPU execution,
and WGPU for GPU acceleration via WebGPU. This means that you can run inference directly within a
browser. We provide several examples of this:

- [MNIST](./examples/mnist-inference-web) where you can draw digits and a small convnet tries to
  find which one it is! 2ï¸âƒ£ 7ï¸âƒ£ ğŸ˜°
- [Image Classification](./examples/image-classification-web) where you can upload images and
  classify them! ğŸŒ„

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Embedded: &lt;i&gt;no_std&lt;/i&gt; support âš™ï¸
&lt;/summary&gt;
&lt;br /&gt;

Burn&#039;s core components support [no_std](https://docs.rust-embedded.org/book/intro/no-std.html). This
means it can run in bare metal environment such as embedded devices without an operating system.

&gt; As of now, only the NdArray backend can be used in a _no_std_ environment.

&lt;/details&gt;

&lt;br /&gt;

### Benchmarks

To evaluate performance across different backends and track improvements over time, we provide a
dedicated benchmarking suite.

Run and compare benchmarks using [burn-bench](https://github.com/tracel-ai/burn-bench).

&gt; âš ï¸ **Warning** When using one of the `wgpu` backends, you may encounter compilation errors related
&gt; to recursive type evaluation. This is due to complex type nesting within the `wgpu` dependency
&gt; chain. To resolve this issue, add the following line at the top of your `main.rs` or `lib.rs`
&gt; file:
&gt;
&gt; ```rust
&gt; #![recursion_limit = &quot;256&quot;]
&gt; ```
&gt;
&gt; The default recursion limit (128) is often just below the required depth (typically 130-150) due
&gt; to deeply nested associated types and trait bounds.

## Getting Started

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png&quot; height=&quot;96px&quot;/&gt;

Just heard of Burn? You are at the right place! Just continue reading this section and we hope you
can get on board really quickly.

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;
The Burn Book ğŸ”¥
&lt;/summary&gt;
&lt;br /&gt;

To begin working effectively with Burn, it is crucial to understand its key components and
philosophy. This is why we highly recommend new users to read the first sections of
[The Burn Book ğŸ”¥](https://burn.dev/books/burn/). It provides detailed examples and explanations
covering every facet of the framework, including building blocks like tensors, modules, and
optimizers, all the way to advanced usage, like coding your own GPU kernels.

&gt; The project is constantly evolving, and we try as much as possible to keep the book up to date
&gt; with new additions. However, we might miss some details sometimes, so if you see something weird,
&gt; let us know! We also gladly accept Pull Requests ğŸ˜„

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Examples ğŸ™
&lt;/summary&gt;
&lt;br /&gt;

Let&#039;s start with a code snippet that shows how intuitive the framework is to use! In the following,
we declare a neural network module with some parameters along with its forward pass.

```rust
use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&lt;B: Backend&gt; {
    linear_inner: nn::Linear&lt;B&gt;,
    linear_outer: nn::Linear&lt;B&gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&lt;B: Backend&gt; PositionWiseFeedForward&lt;B&gt; {
    pub fn forward&lt;const D: usize&gt;(&amp;self, input: Tensor&lt;B, D&gt;) -&gt; Tensor&lt;B, D&gt; {
        let x = self.linear_inner.forward(input);
        let x = self.gelu.forward(x);
        let x = self.dropout.forward(x);

        self.linear_outer.forward(x)
    }
}
```

We have a somewhat large amount of [examples](./examples) in the repository that shows how to use
the framework in different scenarios.

Following [the book](https://burn.dev/books/burn/):

- [Basic Workflow](./examples/guide) : Creates a custom CNN `Module` to train on the MNIST dataset
  and use for inference.
- [Custom Training Loop](./examples/custom-training-loop) : Implements a basic training loop instead
  of using the `Learner`.
- [Custom WGPU Kernel](./examples/custom-wgpu-kernel) : Learn how to create your own custom
  operation with the WGPU backend.

Additional examples:

- [Custom CSV Dataset](./examples/custom-csv-dataset) : Implements a dataset to parse CSV data for a
  regression task.
- [Regression](./examples/simple-regression) : Trains a simple MLP on the California Housing dataset
  to predict the median house value for a district.
- [Custom Image Dataset](./examples/custom-image-dataset) : Trains a simple CNN on custom image
  dataset following a simple folder structure.
- [Custom Renderer](./examples/custom-renderer) : Implements a custom renderer to display the
  [`Learner`](./building-blocks/learner.md) progress.
- [Image Classification Web](./examples/image-classification-web) : Image classification web browser
  demo using Burn, WGPU and WebAssembly.
- [MNIST Inference on Web](./examples/mnist-inference-web) : An interactive MNIST inference demo in
  the browser. The demo is available [online](https://burn.dev/demo/).
- [MNIST Training](./examples/mnist) : Demonstrates how to train a custom `Module` (MLP) with the
  `Learner` configured to log metrics and keep training checkpoints.
- [Named Tensor](./examples/named-tensor) : Performs operations with the experimental `NamedTensor`
  feature.
- [PyTorch Import Inference](./examples/import-model-weights) : Imports a PyTorch model pre-trained
  on MNIST to perform inference on a sample image with Burn.
- [Text Classification](./examples/text-classification) : Trains a text classification transformer
  model on the AG News or DbPedia dataset. The trained model can then be used to classify a text
  sample.
- [Text Generation](./examples/text-generation) : Trains a text generation transformer model on the
  DbPedia dataset.
- [Wasserstein GAN MNIST](./examples/wgan) : Trains a WGAN model to generate new handwritten digits
  based on MNIST.

For more practical insights, you can clone the repository and run any of them directly on your
computer!

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Pre-trained Models ğŸ¤–
&lt;/summary&gt;
&lt;br /&gt;

We keep an updated and curated list of models and examples built with Burn, see the
[tracel-ai/models repository](https://github.com/tracel-ai/models) for more details.

Don&#039;t see the model you want? Don&#039;t hesitate to open an issue, and we may prioritize it. Built a
model using Burn and want to share it? You can also open a Pull Request and add your model under the
community section!

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Why use Rust for Deep Learning? ğŸ¦€
&lt;/summary&gt;
&lt;br /&gt;

Deep Learning is a special form of software where you need very high level abstractions as well as
extremely fast execution time. Rust is the perfect candidate for that use case since it provides
zero-cost abstractions to easily create neural network modules, and fine-grained control over memory
to optimize every detail.

It&#039;s important that a framework be easy to use at a high level so that its users can focus on
innovating in the AI field. However, since running models relies so heavily on computations,
performance can&#039;t be neglected.

To this day, the mainstream solution to this problem has been to offer APIs in Python, but rely on
bindings to low-level languages such as C/C++. This reduces portability, increases complexity and
creates frictions between researchers and engineers. We feel like Rust&#039;s approach to abstractions
makes it versatile enough to tackle this two languages dichotomy.

Rust also comes with the Cargo package manager, which makes it incredibly easy to build, test, and
deploy from any environment, which is usually a pain in Python.

Although Rust has the reputation of being a difficult language at first, we strongly believe it
leads to more reliable, bug-free solutions built faster (after some practice ğŸ˜…)!

&lt;/details&gt;

&lt;br /&gt;

&gt; **Deprecation Note**&lt;br /&gt;Since `0.14.0`, the internal structure for tensor data has changed. The
&gt; previous `Data` struct was deprecated and officially removed since `0.17.0` in favor of the new
&gt; `TensorData` struct, which allows for more flexibility by storing the underlying data as bytes and
&gt; keeping the data type as a field. If you are using `Data` in your code, make sure to switch to
&gt; `TensorData`.

&lt;!-- &gt;
&gt; In the event that you are trying to load a model record saved in a previous version, make sure to
&gt; enable the `record-backward-compat` feature using a previous version of burn (&lt;=0.16.0). Otherwise,
&gt; the record won&#039;t be deserialized correctly and you will get an error message (which will also point
&gt; you to the backward compatible feature flag). The backward compatibility was maintained for
&gt; deserialization (loading), so as soon as you have saved the record again it will be saved according
&gt; to the new structure and you will be able to upgrade to this version. Please note that binary formats
&gt; are not backward compatible. Thus, you will need to load your record in a previous version and save it
&gt; to another of the self-describing record formats before using a compatible version (as described) with the
&gt; `record-backward-compat` feature flag. --&gt;

&lt;details id=&quot;deprecation&quot;&gt;
&lt;summary&gt;
Loading Model Records From Previous Versions âš ï¸
&lt;/summary&gt;
&lt;br /&gt;

In the event that you are trying to load a model record saved in a version older than `0.14.0`, make
sure to use a compatible version (`0.14`, `0.15` or `0.16`) with the `record-backward-compat`
feature flag.

```
features = [..., &quot;record-backward-compat&quot;]
```

Otherwise, the record won&#039;t be deserialized correctly and you will get an error message. This error
will also point you to the backward compatible feature flag.

The backward compatibility was maintained for deserialization when loading records. Therefore, as
soon as you have saved the record again it will be saved according to the new structure and you can
upgrade back to the cu

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:19 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 30,323</p>
            <p>Forks: 2,748</p>
            <p>Stars today: 88 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/goose-oss&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;&gt;
     &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and supports multi-model configuration to optimize performance and cost, seamlessly integrates with MCP servers, and is available as both a desktop app as well as CLI - making it the ultimate AI assistant for developers who want to move faster and focus on innovation.

[![Watch the video](https://github.com/user-attachments/assets/ddc71240-3928-41b5-8210-626dfb28af7a)](https://youtu.be/D-DpDunrbpo)

# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)
- [Responsible AI-Assisted Coding Guide](https://github.com/block/goose/blob/main/HOWTOAI.md)
- [Governance](https://github.com/block/goose/blob/main/GOVERNANCE.md)

## Need Help?
- [Diagnostics &amp; Reporting](https://block.github.io/goose/docs/troubleshooting/diagnostics-and-reporting)
- [Known Issues](https://block.github.io/goose/docs/troubleshooting/known-issues)

# a little goose humor ğŸ¦¢

&gt; Why did the developer choose goose as their AI agent?
&gt; 
&gt; Because it always helps them &quot;migrate&quot; their code to production! ğŸš€

# goose around with us  
- [Discord](https://discord.gg/goose-oss)
- [YouTube](https://www.youtube.com/@goose-oss)
- [LinkedIn](https://www.linkedin.com/company/goose-oss)
- [Twitter/X](https://x.com/goose_oss)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[Zackriya-Solutions/meeting-minutes]]></title>
            <link>https://github.com/Zackriya-Solutions/meeting-minutes</link>
            <guid>https://github.com/Zackriya-Solutions/meeting-minutes</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:18 GMT</pubDate>
            <description><![CDATA[Privacy first, AI meeting assistant with 4x faster Parakeet/Whisper live transcription, speaker diarization, and Ollama summarization built on Rust. 100% local processing. no cloud required. Meetily (Meetly Ai - https://meetily.ai) is the #1 Self-hosted, Open-source Ai meeting note taker for macOS & Windows.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Zackriya-Solutions/meeting-minutes">Zackriya-Solutions/meeting-minutes</a></h1>
            <p>Privacy first, AI meeting assistant with 4x faster Parakeet/Whisper live transcription, speaker diarization, and Ollama summarization built on Rust. 100% local processing. no cloud required. Meetily (Meetly Ai - https://meetily.ai) is the #1 Self-hosted, Open-source Ai meeting note taker for macOS & Windows.</p>
            <p>Language: Rust</p>
            <p>Stars: 9,781</p>
            <p>Forks: 872</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; style=&quot;border-bottom: none&quot;&gt;
    &lt;h1&gt;
        &lt;img src=&quot;docs/Meetily-6.png&quot; style=&quot;border-radius: 10px;&quot; /&gt;
        &lt;br&gt;
        Privacy-First AI Meeting Assistant
    &lt;/h1&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/13272&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13272&quot; alt=&quot;Zackriya-Solutions%2Fmeeting-minutes | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
    &lt;br&gt;
    &lt;br&gt;
    &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Pre_Release-Link-brightgreen&quot; alt=&quot;Pre-Release&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases&quot;&gt;&lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/zackriya-solutions/meeting-minutes?style=flat&quot;&gt;
&lt;/a&gt;
 &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases&quot;&gt; &lt;img alt=&quot;GitHub Downloads (all assets, all releases)&quot; src=&quot;https://img.shields.io/github/downloads/zackriya-solutions/meeting-minutes/total?style=plastic&quot;&gt; &lt;/a&gt;
    &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Supported_OS-macOS,_Windows-white&quot; alt=&quot;Supported OS&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases&quot;&gt;&lt;img alt=&quot;GitHub Tag&quot; src=&quot;https://img.shields.io/github/v/tag/zackriya-solutions/meeting-minutes?include_prereleases&amp;color=yellow&quot;&gt;
&lt;/a&gt;
    &lt;br&gt;
    &lt;h3&gt;
    &lt;br&gt;
    Open Source â€¢ Privacy-First â€¢ Enterprise-Ready
    &lt;/h3&gt;
    &lt;p align=&quot;center&quot;&gt;
    Get latest &lt;a href=&quot;https://www.zackriya.com/meetily-subscribe/&quot;&gt;&lt;b&gt;Product updates&lt;/b&gt;&lt;/a&gt; &lt;br&gt;&lt;br&gt;
    &lt;a href=&quot;https://meetily.ai&quot;&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; â€¢
    &lt;a href=&quot;https://www.linkedin.com/company/106363062/&quot;&gt;&lt;b&gt;LinkedIn&lt;/b&gt;&lt;/a&gt; â€¢
    &lt;a href=&quot;https://discord.gg/crRymMQBFH&quot;&gt;&lt;b&gt;Meetily Discord&lt;/b&gt;&lt;/a&gt; â€¢
    &lt;a href=&quot;https://discord.com/invite/vCFJvN4BwJ&quot;&gt;&lt;b&gt;Privacy-First AI&lt;/b&gt;&lt;/a&gt; â€¢
    &lt;a href=&quot;https://www.reddit.com/r/meetily/&quot;&gt;&lt;b&gt;Reddit&lt;/b&gt;&lt;/a&gt;
&lt;/p&gt;
    &lt;p align=&quot;center&quot;&gt;

A privacy-first AI meeting assistant that captures, transcribes, and summarizes meetings entirely on your infrastructure. Built by expert AI engineers passionate about data sovereignty and open source solutions. Perfect for enterprises that need advanced meeting intelligence without compromising on privacy, compliance, or control.

&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/meetily_demo.gif&quot; width=&quot;650&quot; alt=&quot;Meetily Demo&quot; /&gt;
    &lt;br&gt;
    &lt;a href=&quot;https://youtu.be/6FnhSC_eSz8&quot;&gt;View full Demo Video&lt;/a&gt;
&lt;/p&gt;

&lt;/div&gt;

---

&gt; **ğŸ‰ New: Meetily PRO Available** - Looking for enhanced accuracy and advanced features? Check out our professional-grade solution with custom summary templates, advanced exports (PDF, DOCX), auto-meeting detection, built-in GDPR compliance, and many more. **This Community Edition remains forever free &amp; open source**. [Learn more about PRO â†’](https://meetily.ai/pro/)

---

&lt;details&gt;
&lt;summary&gt;Table of Contents&lt;/summary&gt;

- [Introduction](#introduction)
- [Why Meetily?](#why-meetily)
- [Features](#features)
- [Installation](#installation)
- [Key Features in Action](#key-features-in-action)
- [System Architecture](#system-architecture)
- [For Developers](#for-developers)
- [Meetily PRO](#meetily-pro)
- [Contributing](#contributing)
- [License](#license)

&lt;/details&gt;

## Introduction

Meetily is a privacy-first AI meeting assistant that runs entirely on your local machine. It captures your meetings, transcribes them in real-time, and generates summaries, all without sending any data to the cloud. This makes it the perfect solution for professionals and enterprises who need to maintain complete control over their sensitive information.

## Why Meetily?

While there are many meeting transcription tools available, this solution stands out by offering:

- **Privacy First:** All processing happens locally on your device.
- **Cost-Effective:** Uses open-source AI models instead of expensive APIs.
- **Flexible:** Works offline and supports multiple meeting platforms.
- **Customizable:** Self-host and modify for your specific needs.

&lt;details&gt;
&lt;summary&gt;The Privacy Problem&lt;/summary&gt;

Meeting AI tools create significant privacy and compliance risks across all sectors:

- **$4.4M average cost per data breach** (IBM 2024)
- **â‚¬5.88 billion in GDPR fines** issued by 2025
- **400+ unlawful recording cases** filed in California this year

Whether you&#039;re a defense consultant, enterprise executive, legal professional, or healthcare provider, your sensitive discussions shouldn&#039;t live on servers you don&#039;t control. Cloud meeting tools promise convenience but deliver privacy nightmares with unclear data storage practices and potential unauthorized access.

**Meetily solves this:** Complete data sovereignty on your infrastructure, zero vendor lock-in, and full control over your sensitive conversations.

&lt;/details&gt;

## Features

- **Local First:** All processing is done on your machine. No data ever leaves your computer.
- **Real-time Transcription:** Get a live transcript of your meeting as it happens.
- **AI-Powered Summaries:** Generate summaries of your meetings using powerful language models.
- **Multi-Platform:** Works on macOS, Windows, and Linux.
- **Open Source:** Meetily is open source and free to use.
- **Flexible AI Provider Support:** Choose from Ollama (local), Claude, Groq, OpenRouter, or use your own OpenAI-compatible endpoint.

## Installation

### ğŸªŸ **Windows**

1. Download the latest `x64-setup.exe` from [Releases](https://github.com/Zackriya-Solutions/meeting-minutes/releases/latest)
2. Run the installer

### ğŸ **macOS**

1. Download `meetily_0.2.1_aarch64.dmg` from [Releases](https://github.com/Zackriya-Solutions/meeting-minutes/releases/latest)
2. Open the downloaded `.dmg` file
3. Drag **Meetily** to your Applications folder
4. Open **Meetily** from Applications folder

### ğŸ§ **Linux**

Build from source following our detailed guides:

- [Building on Linux](docs/building_in_linux.md)
- [General Build Instructions](docs/BUILDING.md)

**Quick start:**

```bash
git clone https://github.com/Zackriya-Solutions/meeting-minutes
cd meeting-minutes/frontend
pnpm install
./build-gpu.sh
```

## Key Features in Action

### ğŸ¯ Local Transcription

Transcribe meetings entirely on your device using **Whisper** or **Parakeet** models. No cloud required.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/home.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Meetily Demo&quot; /&gt;
&lt;/p&gt;

### ğŸ¤– AI-Powered Summaries

Generate meeting summaries with your choice of AI provider. **Ollama** (local) is recommended, with support for Claude, Groq, OpenRouter, and OpenAI.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/summary.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Summary generation&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/editor1.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Editor Summary generation&quot; /&gt;
&lt;/p&gt;

### ğŸ”’ Privacy-First Design

All data stays on your machine. Transcription models, recordings, and transcripts are stored locally.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/settings.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Local Transcription and storage&quot; /&gt;
&lt;/p&gt;

### ğŸŒ Custom OpenAI Endpoint Support

Use your own OpenAI-compatible endpoint for AI summaries. Perfect for organizations with custom AI infrastructure or preferred providers.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/custom.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Custom OpenAI Endpoint Configuration&quot; /&gt;
&lt;/p&gt;

### ğŸ™ï¸ Professional Audio Mixing

Capture microphone and system audio simultaneously with intelligent ducking and clipping prevention.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/audio.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Device selection&quot; /&gt;
&lt;/p&gt;

### âš¡ GPU Acceleration

Built-in support for hardware acceleration across platforms:

- **macOS**: Apple Silicon (Metal) + CoreML
- **Windows/Linux**: NVIDIA (CUDA), AMD/Intel (Vulkan)

Automatically enabled at build time - no configuration needed.

## System Architecture

Meetily is a single, self-contained application built with [Tauri](https://tauri.app/). It uses a Rust-based backend to handle all the core logic, and a Next.js frontend for the user interface.

For more details, see the [Architecture documentation](docs/architecture.md).

## For Developers

If you want to contribute to Meetily or build it from source, you&#039;ll need to have Rust and Node.js installed. For detailed build instructions, please see the [Building from Source guide](docs/BUILDING.md).

## Meetily Pro

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/pv2.1.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Upcoming version&quot; /&gt;
&lt;/p&gt;

**Meetily PRO** is a professional-grade solution with enhanced accuracy and advanced features for serious users and teams. Built on a different codebase with superior transcription models and enterprise-ready capabilities.

### Key Advantages Over Community Edition:

- **Enhanced Accuracy**: Superior transcription models for professional-grade accuracy
- **Custom Summary Templates**: Tailor summaries to your specific workflow and needs
- **Advanced Export Options**: PDF, DOCX, and Markdown exports with formatting
- **Auto-detect and Join Meetings**: Automatic meeting detection and joining
- **Speaker Identification**: Distinguish between speakers automatically *(Coming Soon)*
- **Chat with Meetings**: AI-powered meeting insights and queries *(Coming Soon)*
- **Calendar Integration**: Seamless integration with your calendar *(Coming Soon)*
- **Self-Hosted Deployment**: Deploy on your own infrastructure for teams
- **GDPR Compliance Built-In**: Privacy by design architecture with complete audit trails
- **Priority Support**: Dedicated support for PRO users

### Who is PRO for?

- **Professionals** who need the highest accuracy for critical meetings
- **Teams and organizations** (2-100 users) requiring self-hosted deployment
- **Power users** who need advanced export formats and custom workflows
- **Compliance-focused organizations** requiring GDPR readiness

&gt; **Note:** Meetily Community Edition remains **free &amp; open source forever** with local transcription, AI summaries, and core features. PRO is a separate professional solution for users who need enhanced accuracy and advanced capabilities.

For organizations needing 100+ users or managed compliance solutions, explore [Meetily Enterprise](https://meetily.ai/enterprise/).

**Learn more about pricing and features:** [https://meetily.ai/pro/](https://meetily.ai/pro/)

## Contributing

We welcome contributions from the community! If you have any questions or suggestions, please open an issue or submit a pull request. Please follow the established project structure and guidelines. For more details, refer to the [CONTRIBUTING.md](CONTRIBUTING.md) file.

Thanks for all the contributions. Our community is what makes this project possible.

## License

MIT License - Feel free to use this project for your own purposes.

## Acknowledgments

- We borrowed some code from [Whisper.cpp](https://github.com/ggerganov/whisper.cpp).
- We borrowed some code from [Screenpipe](https://github.com/mediar-ai/screenpipe).
- We borrowed some code from [transcribe-rs](https://crates.io/crates/transcribe-rs).
- Thanks to **NVIDIA** for developing the **Parakeet** model.
- Thanks to [istupakov](https://huggingface.co/istupakov/parakeet-tdt-0.6b-v3-onnx) for providing the **ONNX conversion** of the Parakeet model.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Zackriya-Solutions/meeting-minutes&amp;type=Date)](https://star-history.com/#Zackriya-Solutions/meeting-minutes&amp;Date)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[typst/typst]]></title>
            <link>https://github.com/typst/typst</link>
            <guid>https://github.com/typst/typst</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:17 GMT</pubDate>
            <description><![CDATA[A markup-based typesetting system that is powerful and easy to learn.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/typst/typst">typst/typst</a></h1>
            <p>A markup-based typesetting system that is powerful and easy to learn.</p>
            <p>Language: Rust</p>
            <p>Stars: 51,230</p>
            <p>Forks: 1,455</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Typst&quot; src=&quot;https://user-images.githubusercontent.com/17899797/226108480-722b770e-6313-40d7-84f2-26bebb55a281.png&quot;&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://typst.app/docs/&quot;&gt;
    &lt;img alt=&quot;Documentation&quot; src=&quot;https://img.shields.io/website?down_message=offline&amp;label=docs&amp;up_color=007aff&amp;up_message=online&amp;url=https%3A%2F%2Ftypst.app%2Fdocs&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://typst.app/&quot;&gt;
    &lt;img alt=&quot;Typst App&quot; src=&quot;https://img.shields.io/website?down_message=offline&amp;label=typst.app&amp;up_color=239dad&amp;up_message=online&amp;url=https%3A%2F%2Ftypst.app&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/2uDybryKPe&quot;&gt;
    &lt;img alt=&quot;Discord Server&quot; src=&quot;https://img.shields.io/discord/1054443721975922748?color=5865F2&amp;label=discord&amp;labelColor=555&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/typst/typst/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;Apache-2 License&quot; src=&quot;https://img.shields.io/badge/license-Apache%202-brightgreen&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://typst.app/jobs/&quot;&gt;
    &lt;img alt=&quot;Jobs at Typst&quot; src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ftypst.app%2Fassets%2Fdata%2Fshields.json&amp;query=%24.jobs.text&amp;label=jobs&amp;color=%23A561FF&amp;cacheSeconds=1800&quot;
  &gt;&lt;/a&gt;
&lt;/p&gt;

Typst is a new markup-based typesetting system that is designed to be as powerful
as LaTeX while being much easier to learn and use. Typst has:

- Built-in markup for the most common formatting tasks
- Flexible functions for everything else
- A tightly integrated scripting system
- Math typesetting, bibliography management, and more
- Fast compile times thanks to incremental compilation
- Friendly error messages in case something goes wrong

This repository contains the Typst compiler and its CLI, which is everything you
need to compile Typst documents locally. For the best writing experience,
consider signing up to our [collaborative online editor][app] for free.

## Example
A [gentle introduction][tutorial] to Typst is available in our documentation.
However, if you want to see the power of Typst encapsulated in one image, here
it is:
&lt;p align=&quot;center&quot;&gt;
 &lt;img alt=&quot;Example&quot; width=&quot;900&quot; src=&quot;https://user-images.githubusercontent.com/17899797/228031796-ced0e452-fcee-4ae9-92da-b9287764ff25.png&quot;&gt;
&lt;/p&gt;


Let&#039;s dissect what&#039;s going on:

- We use _set rules_ to configure element properties like the size of pages or
  the numbering of headings. By setting the page height to `auto`, it scales to
  fit the content. Set rules accommodate the most common configurations. If you
  need full control, you can also use [show rules][show] to completely redefine
  the appearance of an element.

- We insert a heading with the `= Heading` syntax. One equals sign creates a top
  level heading, two create a subheading and so on. Typst has more lightweight
  markup like this; see the [syntax] reference for a full list.

- [Mathematical equations][math] are enclosed in dollar signs. By adding extra
  spaces around the contents of an equation, we can put it into a separate block.
  Multi-letter identifiers are interpreted as Typst definitions and functions
  unless put into quotes. This way, we don&#039;t need backslashes for things like
  `floor` and `sqrt`. And `phi.alt` applies the `alt` modifier to the `phi` to
  select a particular symbol variant.

- Now, we get to some [scripting]. To input code into a Typst document, we can
  write a hash followed by an expression. We define two variables and a
  recursive function to compute the n-th fibonacci number. Then, we display the
  results in a center-aligned table. The table function takes its cells
  row-by-row. Therefore, we first pass the formulas `$F_1$` to `$F_8$` and then
  the computed fibonacci numbers. We apply the spreading operator (`..`) to both
  because they are arrays and we want to pass the arrays&#039; items as individual
  arguments.

&lt;details&gt;
  &lt;summary&gt;Text version of the code example.&lt;/summary&gt;

  ```typst
  #set page(width: 10cm, height: auto)
  #set heading(numbering: &quot;1.&quot;)

  = Fibonacci sequence
  The Fibonacci sequence is defined through the
  recurrence relation $F_n = F_(n-1) + F_(n-2)$.
  It can also be expressed in _closed form:_

  $ F_n = round(1 / sqrt(5) phi.alt^n), quad
    phi.alt = (1 + sqrt(5)) / 2 $

  #let count = 8
  #let nums = range(1, count + 1)
  #let fib(n) = (
    if n &lt;= 2 { 1 }
    else { fib(n - 1) + fib(n - 2) }
  )

  The first #count numbers of the sequence are:

  #align(center, table(
    columns: count,
    ..nums.map(n =&gt; $F_#n$),
    ..nums.map(n =&gt; str(fib(n))),
  ))
  ```
&lt;/details&gt;

## Installation
Typst&#039;s CLI is available from different sources:

- You can get sources and pre-built binaries for the latest release of Typst
  from the [releases page][releases]. Download the archive for your platform and
  place it in a directory that is in your `PATH`. To stay up to date with future
  releases, you can simply run `typst update`.

- You can install Typst through different package managers. Note that the
  versions in the package managers might lag behind the latest release.
  - Linux:
      - View [Typst on Repology][repology]
      - View [Typst&#039;s Snap][snap]
  - macOS: `brew install typst`
  - Windows: `winget install --id Typst.Typst`

- If you have a [Rust][rust] toolchain installed, you can install
  - the latest released Typst version with
    `cargo install --locked typst-cli`
  - a development version with
    `cargo install --git https://github.com/typst/typst --locked typst-cli`

- Nix users can
  - use the `typst` package with `nix-shell -p typst`
  - build and run the [Typst flake](https://github.com/typst/typst-flake) with
    `nix run github:typst/typst-flake -- --version`.

- Docker users can run a prebuilt image with
  `docker run ghcr.io/typst/typst:latest --help`.

## Usage
Once you have installed Typst, you can use it like this:
```sh
# Creates `file.pdf` in working directory.
typst compile file.typ

# Creates a PDF file at the desired path.
typst compile path/to/source.typ path/to/output.pdf
```

You can also watch source files and automatically recompile on changes. This is
faster than compiling from scratch each time because Typst has incremental
compilation.
```sh
# Watches source files and recompiles on changes.
typst watch file.typ
```

Typst further allows you to add custom font paths for your project and list all
of the fonts it discovered:
```sh
# Adds additional directories to search for fonts.
typst compile --font-path path/to/fonts file.typ

# Lists all of the discovered fonts in the system and the given directory.
typst fonts --font-path path/to/fonts

# Or via environment variable (Linux syntax).
TYPST_FONT_PATHS=path/to/fonts typst fonts
```

For other CLI subcommands and options, see below:
```sh
# Prints available subcommands and options.
typst help

# Prints detailed usage of a subcommand.
typst help watch
```

If you prefer an integrated IDE-like experience with autocompletion and instant 
preview, you can also check out our [free web app][app]. Alternatively, there is 
a community-created language server called 
[Tinymist](https://myriad-dreamin.github.io/tinymist/) which is integrated into 
various editor extensions.

## Community
The main places where the community gathers are our [Forum][forum] and our
[Discord server][discord]. The Forum is a great place to ask questions, help
others, and share cool things you created with Typst. The Discord server is more
suitable for quicker questions, discussions about contributing, or just to chat.
We&#039;d be happy to see you there!

[Typst Universe][universe] is where the community shares templates and packages.
If you want to share your own creations, you can submit them to our
[package repository][packages].

If you had a bad experience in our community, please [reach out to us][contact].

## Contributing
We love to see contributions from the community. If you experience bugs, feel
free to open an issue. If you would like to implement a new feature or bug fix,
please follow the steps outlined in the [contribution guide][contributing].

To build Typst yourself, first ensure that you have the
[latest stable Rust][rust] installed. Then, clone this repository and build the
CLI with the following commands:

```sh
git clone https://github.com/typst/typst
cd typst
cargo build --release
```

The optimized binary will be stored in `target/release/`.

Another good way to contribute is by [sharing packages][packages] with the
community.

## Pronunciation and Spelling
IPA: /taÉªpst/. &quot;Ty&quot; like in **Ty**pesetting and &quot;pst&quot; like in Hi**pst**er. When
writing about Typst, capitalize its name as a proper noun, with a capital &quot;T&quot;.

## Design Principles
All of Typst has been designed with three key goals in mind: Power,
simplicity, and performance. We think it&#039;s time for a system that matches the
power of LaTeX, is easy to learn and use, all while being fast enough to realize
instant preview. To achieve these goals, we follow three core design principles:

- **Simplicity through Consistency:**
  If you know how to do one thing in Typst, you should be able to transfer that
  knowledge to other things. If there are multiple ways to do the same thing,
  one of them should be at a different level of abstraction than the other. E.g.
  it&#039;s okay that `= Introduction` and `#heading[Introduction]` do the same thing
  because the former is just syntax sugar for the latter.

- **Power through Composability:**
  There are two ways to make something flexible: Have a knob for everything or
  have a few knobs that you can combine in many ways. Typst is designed with the
  second way in mind. We provide systems that you can compose in ways we&#039;ve
  never even thought of. TeX is also in the second category, but it&#039;s a bit
  low-level and therefore people use LaTeX instead. But there, we don&#039;t really
  have that much composability. Instead, there&#039;s a package for everything
  (`\usepackage{knob}`).

- **Performance through Incrementality:**
  All Typst language features must accommodate for incremental compilation.
  Luckily we have [`comemo`], a system for incremental compilation which does
  most of the hard work in the background.

## Acknowledgements

We&#039;d like to thank everyone who is supporting Typst&#039;s development, be it via
[GitHub sponsors] or elsewhere. In particular, special thanks[^1] go to:

- [Posit](https://posit.co/blog/posit-and-typst/) for financing a full-time
  compiler engineer
- [NLnet](https://nlnet.nl/) for supporting work on Typst via multiple grants
  through the [NGI Zero Core](https://nlnet.nl/core) fund:
  - Work on [HTML export](https://nlnet.nl/project/Typst-HTML/)
  - Work on [PDF accessibility](https://nlnet.nl/project/Typst-Accessibility/)
- [Science &amp; Startups](https://www.science-startups.berlin/) for having financed
  Typst development from January through June 2023 via the Berlin Startup
  Scholarship
- [Zerodha](https://zerodha.tech/blog/1-5-million-pdfs-in-25-minutes/) for their
  generous one-time sponsorship

[^1]: This list only includes contributions for our open-source work that exceed
    or are expected to exceed â‚¬10K.

[docs]: https://typst.app/docs/
[app]: https://typst.app/
[discord]: https://discord.gg/2uDybryKPe
[forum]: https://forum.typst.app/
[universe]: https://typst.app/universe/
[tutorial]: https://typst.app/docs/tutorial/
[show]: https://typst.app/docs/reference/styling/#show-rules
[math]: https://typst.app/docs/reference/math/
[syntax]: https://typst.app/docs/reference/syntax/
[scripting]: https://typst.app/docs/reference/scripting/
[rust]: https://rustup.rs/
[releases]: https://github.com/typst/typst/releases/
[repology]: https://repology.org/project/typst/versions
[contact]: https://typst.app/contact
[architecture]: https://github.com/typst/typst/blob/main/docs/dev/architecture.md
[contributing]: https://github.com/typst/typst/blob/main/CONTRIBUTING.md
[packages]: https://github.com/typst/packages/
[`comemo`]: https://github.com/typst/comemo/
[snap]: https://snapcraft.io/typst
[GitHub sponsors]: https://github.com/sponsors/typst/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[quickwit-oss/quickwit]]></title>
            <link>https://github.com/quickwit-oss/quickwit</link>
            <guid>https://github.com/quickwit-oss/quickwit</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:16 GMT</pubDate>
            <description><![CDATA[Cloud-native search engine for observability. An open-source alternative to Datadog, Elasticsearch, Loki, and Tempo.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/quickwit-oss/quickwit">quickwit-oss/quickwit</a></h1>
            <p>Cloud-native search engine for observability. An open-source alternative to Datadog, Elasticsearch, Loki, and Tempo.</p>
            <p>Language: Rust</p>
            <p>Stars: 10,884</p>
            <p>Forks: 517</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>[![CI](https://github.com/quickwit-oss/quickwit/actions/workflows/ci.yml/badge.svg)](https://github.com/quickwit-oss/quickwit/actions?query=workflow%3ACI+branch%3Amain)
[![codecov](https://codecov.io/gh/quickwit-oss/quickwit/branch/main/graph/badge.svg?token=06SRGAV5SS)](https://codecov.io/gh/quickwit-oss/quickwit)
[![OpenSSF Scorecard](https://api.scorecard.dev/projects/github.com/quickwit-oss/quickwit/badge)](https://scorecard.dev/viewer/?uri=github.com/quickwit-oss/quickwit)
[![Contributor Covenant](https://img.shields.io/badge/Contributor%20Covenant-2.0-4baaaa.svg)](CODE_OF_CONDUCT.md)
[![License: Apache 2.0](https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square)](LICENSE)
[![Twitter Follow](https://img.shields.io/twitter/follow/Quickwit_Inc?color=%231DA1F2&amp;logo=Twitter&amp;style=plastic)](https://twitter.com/Quickwit_Inc)
[![Discord](https://img.shields.io/discord/908281611840282624?logo=Discord&amp;logoColor=%23FFFFFF&amp;style=plastic)](https://discord.quickwit.io)
&lt;br/&gt;

&lt;br/&gt;
&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;docs/assets/images/logo_horizontal.svg#gh-light-mode-only&quot; alt=&quot;Quickwit Cloud-Native Search Engine&quot; height=&quot;40&quot;&gt;
  &lt;img src=&quot;docs/assets/images/quickwit-dark-theme-logo.png#gh-dark-mode-only&quot; alt=&quot;Quickwit Cloud-Native Search Engine&quot; height=&quot;40&quot;&gt;
&lt;/p&gt;

&lt;h2 align=&quot;center&quot;&gt;
Cloud-native search engine for observability (logs, traces, and soon metrics!). An open-source alternative to Datadog, Elasticsearch,  Loki, and Tempo.
&lt;/h2&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://quickwit.io/docs/get-started/quickstart&quot;&gt;Quickstart&lt;/a&gt; |
  &lt;a href=&quot;https://quickwit.io/docs/&quot;&gt;Docs&lt;/a&gt; |
  &lt;a href=&quot;https://quickwit.io/tutorials&quot;&gt;Tutorials&lt;/a&gt; |
  &lt;a href=&quot;https://discord.quickwit.io&quot;&gt;Chat&lt;/a&gt; |
  &lt;a href=&quot;https://quickwit.io/docs/get-started/installation&quot;&gt;Download&lt;/a&gt;
&lt;/h4&gt;
&lt;br/&gt;

&lt;b&gt;We just released Quickwit 0.8! Read the [blog post](https://quickwit.io/blog/quickwit-0.8) to learn about the latest powerful features!&lt;/b&gt;

### **Quickwit is the fastest search engine on cloud storage. It&#039;s the perfect fit for observability use cases**

- [Log management](https://quickwit.io/docs/log-management/overview)
- [Distributed tracing](https://quickwit.io/docs/distributed-tracing/overview)
- Metrics support is on the roadmap

### ğŸš€ Quickstart

- [Search and analytics on Stack Overflow dataset](https://quickwit.io/docs/get-started/quickstart)
- [Trace analytics with Grafana](https://quickwit.io/docs/get-started/tutorials/trace-analytics-with-grafana)
- [Distributed tracing with Jaeger](https://quickwit.io/docs/get-started/tutorials/tutorial-jaeger)

&lt;br/&gt;

&lt;video src=&quot;https://github.com/quickwit-oss/quickwit/assets/653704/020b94b9-deeb-4376-9a3a-b82e1168094c&quot; controls=&quot;controls&quot; style=&quot;max-width: 1200px;&quot;&gt;
&lt;/video&gt;

&lt;br/&gt;

# ğŸ’¡ Features

- Full-text search and aggregation queries
- Elasticsearch-compatible API, use Quickwit with any Elasticsearch or OpenSearch client
- [Jaeger-native](https://quickwit.io/docs/distributed-tracing/plug-quickwit-to-jaeger)
- OTEL-native for [logs](https://quickwit.io/docs/log-management/overview) and [traces](https://quickwit.io/docs/distributed-tracing/overview)
- [Schemaless](https://quickwit.io/docs/guides/schemaless) or strict schema indexing
- Schemaless analytics
- Sub-second search on cloud storage (Amazon S3, Azure Blob Storage, Google Cloud Storage, â€¦)
- Decoupled compute and storage, stateless indexers &amp; searchers
- [Grafana data source](https://github.com/quickwit-oss/quickwit-datasource)
- Kubernetes ready - See our [helm-chart](https://quickwit.io/docs/deployment/kubernetes/helm)
- RESTful API

## Enterprise ready

- Multiple [data sources](https://quickwit.io/docs/ingest-data/) Kafka / Kinesis / Pulsar native
- Multi-tenancy: indexing with many indexes and partitioning
- Retention policies
- Delete tasks (for GDPR use cases)
- Distributed and highly available* engine that scales out in seconds (*HA indexing only with Kafka)

# ğŸ“‘ Architecture overview

![Quickwit Distributed Tracing](./docs/assets/images/quickwit-overview-light.svg#gh-light-mode-only)![Quickwit Distributed Tracing](./docs/assets/images/quickwit-overview-dark.svg#gh-dark-mode-only)

- [Architecture overview]([https://quickwit.io/docs/distributed-tracing/overview](https://quickwit.io/docs/overview/architecture))
- [Log management](https://quickwit.io/docs/log-management/overview)
- [Distributed traces](https://quickwit.io/docs/distributed-tracing/overview)


# ğŸ“• Documentation

- [Installation](https://quickwit.io/docs/get-started/installation)
- [Log management with Quickwit](https://quickwit.io/docs/log-management/overview)
- [Distributed Tracing with Quickwit](https://quickwit.io/docs/distributed-tracing/overview)
- [Ingest data](https://quickwit.io/docs/ingest-data/)
- [REST API](https://quickwit.io/docs/reference/rest-api)

# ğŸ“š Resources

- [Blog posts](https://quickwit.io/blog/)
- [Youtube channel](https://www.youtube.com/@quickwit8103)
- [Discord](https://discord.quickwit.io)

# ğŸ”® Roadmap

- Quickwit 0.9 (July 2024)
  - Indexing and search performance improvements
  - Index configuration updates (retention policy, indexing and search settings)
  - Concatenated field

- Quickwit 0.10 (October 2024)
  - Schema (doc mapping) updates
  - Native distributed ingestion
  - Index templates

# ğŸ™‹ FAQ

### How can I switch from Elasticsearch or OpenSearch to Quickwit?

Quickwit supports a large subset of Elasticsearch/OpenSearch API.

For instance, it has an ES-compatible ingest API to make it easier to migrate your log shippers (Vector, Fluent Bit, Syslog, ...) to Quickwit.

On the search side, the most popular Elasticsearch endpoints, query DSL, and even aggregations are supported.

The list of available endpoints and queries is available [here](https://quickwit.io/docs/reference/es_compatible_api), while the list of supported aggregations is available [here](https://quickwit.io/docs/reference/aggregation).

Let us know if part of the API you are using is missing!

If the client you are using is refusing to connect to Quickwit due to missing headers, you can use the `extra_headers` option in the [node configuration](https://quickwit.io/docs/configuration/node-config#rest-configuration) to impersonate any compatible version of Elasticsearch or OpenSearch.

### How is Quickwit different from traditional search engines like Elasticsearch or Solr?

The core difference and advantage of Quickwit is its architecture built from the ground to search on cloud storage. We optimized IO paths, revamped the index data structures and made search stateless and sub-second on cloud storage.

### How does Quickwit compare to Elastic in terms of cost?

We estimate that Quickwit can be up to 10x cheaper on average than Elastic. To understand how, check out our [blog post](https://quickwit.io/blog/commoncrawl/) about searching the web on AWS S3.

### What license does Quickwit use?

Quickwit is open-source under the Apache License, Version 2.0 - Apache-2.0.

### Is it possible to set up Quickwit for a High Availability (HA)?

HA is available for search, for indexing it&#039;s available only with a Kafka source.

# ğŸ¤ Contribute and spread the word

We are always thrilled to receive contributions: code, documentation, issues, or feedback. Here&#039;s how you can help us build the future of log management:

- Start by checking out the [GitHub issues labeled &quot;Good first issue&quot;](https://github.com/quickwit-oss/quickwit/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22). These are a great place for newcomers to contribute.
- Read our [Contributor Covenant Code of Conduct](./CODE_OF_CONDUCT.md) to understand our community standards.
- [Create a fork of Quickwit](https://github.com/quickwit-oss/quickwit/fork) to have your own copy of the repository where you can make changes.
- To understand how to contribute, read our [contributing guide](./CONTRIBUTING.md).
- Set up your development environment following our [development setup guide](./CONTRIBUTING.md#development).
- Once you&#039;ve made your changes and tested them, you can contribute by [submitting a pull request](./CONTRIBUTING.md#submitting-a-pr).

âœ¨ After your contributions are accepted, don&#039;t forget to claim your swag by emailing us at hello@quickwit.io. Thank you for contributing!

# ğŸ’¬ Join Our Community

We welcome everyone to our community! Whether you&#039;re contributing code or just saying hello, we&#039;d love to hear from you. Here&#039;s how you can connect with us:

- Join the conversation on [Discord](https://discord.quickwit.io).
- Follow us on [Twitter](https://twitter.com/Quickwit_Inc).
- Check out our [website](https://quickwit.io/) and [blog](https://quickwit.io/blog) for the latest updates.
- Watch our [YouTube](https://www.youtube.com/channel/UCvZVuRm2FiDq1_ul0mY85wA) channel for video content.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[qdrant/qdrant]]></title>
            <link>https://github.com/qdrant/qdrant</link>
            <guid>https://github.com/qdrant/qdrant</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:15 GMT</pubDate>
            <description><![CDATA[Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qdrant/qdrant">qdrant/qdrant</a></h1>
            <p>Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/</p>
            <p>Language: Rust</p>
            <p>Stars: 28,741</p>
            <p>Forks: 2,031</p>
            <p>Stars today: 30 stars today</p>
            <h2>README</h2><pre>## How to interview using this template

Open ONLY the `shared/` folder within VSCode and in the Extensions Marketplace find `CodeTogether Live`. Install it.

Inside the extension, you&#039;ll have to click on &#039;Host New Session&#039; and then &#039;Start&#039;.

You now have a link in your clipboard, which you should share with the candidate.

Don&#039;t forget to run `npm run vite.dev` inside your editor terminal, since this is not currently possible from the browser editor (link) with the free version of the extension.

The locally running server will display localhost:5173 as well as a the project within the network, which the user can access remotely to see the SPA in action, something like: `10.5.52.144:5173`.

The candidate should be sharing their screen while they read and later approach the challenge!

## React Templateï¼ˆâš¡ï¸ï¼‰

âš¡ï¸ A minimal React Vite starter template.

### Feature

- âš¡ï¸ Fast - Build tools based on vite.
- ğŸ‘» Small - Based on the smallest runnable build.
- ğŸ’„ Prettier - Integrated Prettier to help you format the code.
- âœ… Safety - Https is enabled by default.
- ğŸ˜ Reliable - Integrated eslint and commitlint.
- ğŸ¤– Intelligent - Integrated renovate to help you maintain the dependent version.

### Preview

[![qekup8.png](https://s1.ax1x.com/2022/03/20/qekup8.png)](https://imgtu.com/i/qekup8)

### Getting Started

```bash
npx degit lzm0x219/template-vite-react myapp

cd myapp

git init
```

#### Prerequisites

- `npm` and/or `pnpm` should be installed.
- `git` should be installed (recommended v2.4.11 or higher)

#### Available scripts

##### `npm run vite.dev`

Runs the app in development mode.
Open https://localhost:5173 to view it in the browser.

The page will automatically reload if you make changes to the code.
You will see the build errors and lint warnings in the console.

##### `npm run vite.build`

Builds the app for production to the `dist` folder.
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.

Your app is ready to be deployed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[dani-garcia/vaultwarden]]></title>
            <link>https://github.com/dani-garcia/vaultwarden</link>
            <guid>https://github.com/dani-garcia/vaultwarden</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:14 GMT</pubDate>
            <description><![CDATA[Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dani-garcia/vaultwarden">dani-garcia/vaultwarden</a></h1>
            <p>Unofficial Bitwarden compatible server written in Rust, formerly known as bitwarden_rs</p>
            <p>Language: Rust</p>
            <p>Stars: 54,855</p>
            <p>Forks: 2,543</p>
            <p>Stars today: 67 stars today</p>
            <h2>README</h2><pre>![Vaultwarden Logo](./resources/vaultwarden-logo-auto.svg)

An alternative server implementation of the Bitwarden Client API, written in Rust and compatible with [official Bitwarden clients](https://bitwarden.com/download/) [[disclaimer](#disclaimer)], perfect for self-hosted deployment where running the official resource-heavy service might not be ideal.

---

[![GitHub Release](https://img.shields.io/github/release/dani-garcia/vaultwarden.svg?style=for-the-badge&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/releases/latest)
[![ghcr.io Pulls](https://img.shields.io/badge/dynamic/json?style=for-the-badge&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;url=https%3A%2F%2Fipitio.github.io%2Fbackage%2Fdani-garcia%2Fvaultwarden%2Fvaultwarden.json&amp;query=%24.downloads&amp;label=ghcr.io%20pulls&amp;cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden)
[![Docker Pulls](https://img.shields.io/docker/pulls/vaultwarden/server.svg?style=for-the-badge&amp;logo=docker&amp;logoColor=fff&amp;color=005AA4&amp;label=docker.io%20pulls)](https://hub.docker.com/r/vaultwarden/server)
[![Quay.io](https://img.shields.io/badge/quay.io-download-005AA4?style=for-the-badge&amp;logo=redhat&amp;cacheSeconds=14400)](https://quay.io/repository/vaultwarden/server) &lt;br&gt;
[![Contributors](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)
[![Forks](https://img.shields.io/github/forks/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/network/members)
[![Stars](https://img.shields.io/github/stars/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/stargazers)
[![Issues Open](https://img.shields.io/github/issues/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues)
[![Issues Closed](https://img.shields.io/github/issues-closed/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=005AA4&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/issues?q=is%3Aissue+is%3Aclosed)
[![AGPL-3.0 Licensed](https://img.shields.io/github/license/dani-garcia/vaultwarden.svg?style=flat-square&amp;logo=vaultwarden&amp;color=944000&amp;cacheSeconds=14400)](https://github.com/dani-garcia/vaultwarden/blob/main/LICENSE.txt) &lt;br&gt;
[![Dependency Status](https://img.shields.io/badge/dynamic/xml?url=https%3A%2F%2Fdeps.rs%2Frepo%2Fgithub%2Fdani-garcia%2Fvaultwarden%2Fstatus.svg&amp;query=%2F*%5Blocal-name()%3D&#039;svg&#039;%5D%2F*%5Blocal-name()%3D&#039;g&#039;%5D%5B2%5D%2F*%5Blocal-name()%3D&#039;text&#039;%5D%5B4%5D&amp;style=flat-square&amp;logo=rust&amp;label=dependencies&amp;color=005AA4)](https://deps.rs/repo/github/dani-garcia/vaultwarden)
[![GHA Release](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/release.yml?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;label=Release%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/release.yml)
[![GHA Build](https://img.shields.io/github/actions/workflow/status/dani-garcia/vaultwarden/build.yml?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;label=Build%20Workflow)](https://github.com/dani-garcia/vaultwarden/actions/workflows/build.yml) &lt;br&gt;
[![Matrix Chat](https://img.shields.io/matrix/vaultwarden:matrix.org.svg?style=flat-square&amp;logo=matrix&amp;logoColor=fff&amp;color=953B00&amp;cacheSeconds=14400)](https://matrix.to/#/#vaultwarden:matrix.org)
[![GitHub Discussions](https://img.shields.io/github/discussions/dani-garcia/vaultwarden?style=flat-square&amp;logo=github&amp;logoColor=fff&amp;color=953B00&amp;cacheSeconds=300)](https://github.com/dani-garcia/vaultwarden/discussions)
[![Discourse Discussions](https://img.shields.io/discourse/topics?server=https%3A%2F%2Fvaultwarden.discourse.group%2F&amp;style=flat-square&amp;logo=discourse&amp;color=953B00)](https://vaultwarden.discourse.group/)

&gt; [!IMPORTANT]
&gt; **When using this server, please report any bugs or suggestions directly to us (see [Get in touch](#get-in-touch)), regardless of whatever clients you are using (mobile, desktop, browser...). DO NOT use the official Bitwarden support channels.**

&lt;br&gt;

## Features

A nearly complete implementation of the Bitwarden Client API is provided, including:

 * [Personal Vault](https://bitwarden.com/help/managing-items/)
 * [Send](https://bitwarden.com/help/about-send/)
 * [Attachments](https://bitwarden.com/help/attachments/)
 * [Website icons](https://bitwarden.com/help/website-icons/)
 * [Personal API Key](https://bitwarden.com/help/personal-api-key/)
 * [Organizations](https://bitwarden.com/help/getting-started-organizations/)
   - [Collections](https://bitwarden.com/help/about-collections/),
     [Password Sharing](https://bitwarden.com/help/sharing/),
     [Member Roles](https://bitwarden.com/help/user-types-access-control/),
     [Groups](https://bitwarden.com/help/about-groups/),
     [Event Logs](https://bitwarden.com/help/event-logs/),
     [Admin Password Reset](https://bitwarden.com/help/admin-reset/),
     [Directory Connector](https://bitwarden.com/help/directory-sync/),
     [Policies](https://bitwarden.com/help/policies/)
 * [Multi/Two Factor Authentication](https://bitwarden.com/help/bitwarden-field-guide-two-step-login/)
   - [Authenticator](https://bitwarden.com/help/setup-two-step-login-authenticator/),
     [Email](https://bitwarden.com/help/setup-two-step-login-email/),
     [FIDO2 WebAuthn](https://bitwarden.com/help/setup-two-step-login-fido/),
     [YubiKey](https://bitwarden.com/help/setup-two-step-login-yubikey/),
     [Duo](https://bitwarden.com/help/setup-two-step-login-duo/)
 * [Emergency Access](https://bitwarden.com/help/emergency-access/)
 * [Vaultwarden Admin Backend](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-admin-page)
 * [Modified Web Vault client](https://github.com/dani-garcia/bw_web_builds) (Bundled within our containers)

&lt;br&gt;

## Usage

&gt; [!IMPORTANT]
&gt; The web-vault requires the use a secure context for the [Web Crypto API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Crypto_API).
&gt; That means it will only work via `http://localhost:8000` (using the port from the example below) or if you [enable HTTPS](https://github.com/dani-garcia/vaultwarden/wiki/Enabling-HTTPS).

The recommended way to install and use Vaultwarden is via our container images which are published to [ghcr.io](https://github.com/dani-garcia/vaultwarden/pkgs/container/vaultwarden), [docker.io](https://hub.docker.com/r/vaultwarden/server) and [quay.io](https://quay.io/repository/vaultwarden/server).
See [which container image to use](https://github.com/dani-garcia/vaultwarden/wiki/Which-container-image-to-use) for an explanation of the provided tags.

There are also [community driven packages](https://github.com/dani-garcia/vaultwarden/wiki/Third-party-packages) which can be used, but those might be lagging behind the latest version or might deviate in the way Vaultwarden is configured, as described in our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).

Alternatively, you can also [build Vaultwarden](https://github.com/dani-garcia/vaultwarden/wiki/Building-binary) yourself.

While Vaultwarden is based upon the [Rocket web framework](https://rocket.rs) which has built-in support for TLS our recommendation would be that you setup a reverse proxy (see [proxy examples](https://github.com/dani-garcia/vaultwarden/wiki/Proxy-examples)).

&gt; [!TIP]
&gt;**For more detailed examples on how to install, use and configure Vaultwarden you can check our [Wiki](https://github.com/dani-garcia/vaultwarden/wiki).**

### Docker/Podman CLI

Pull the container image and mount a volume from the host for persistent storage.&lt;br&gt;
You can replace `docker` with `podman` if you prefer to use podman.

```shell
docker pull vaultwarden/server:latest
docker run --detach --name vaultwarden \
  --env DOMAIN=&quot;https://vw.domain.tld&quot; \
  --volume /vw-data/:/data/ \
  --restart unless-stopped \
  --publish 127.0.0.1:8000:80 \
  vaultwarden/server:latest
```

This will preserve any persistent data under `/vw-data/`, you can adapt the path to whatever suits you.

### Docker Compose

To use Docker compose you need to create a `compose.yaml` which will hold the configuration to run the Vaultwarden container.

```yaml
services:
  vaultwarden:
    image: vaultwarden/server:latest
    container_name: vaultwarden
    restart: unless-stopped
    environment:
      DOMAIN: &quot;https://vw.domain.tld&quot;
    volumes:
      - ./vw-data/:/data/
    ports:
      - 127.0.0.1:8000:80
```

&lt;br&gt;

## Get in touch

Have a question, suggestion or need help? Join our community on [Matrix](https://matrix.to/#/#vaultwarden:matrix.org), [GitHub Discussions](https://github.com/dani-garcia/vaultwarden/discussions) or [Discourse Forums](https://vaultwarden.discourse.group/).

Encountered a bug or crash? Please search our issue tracker and discussions to see if it&#039;s already been reported. If not, please [start a new discussion](https://github.com/dani-garcia/vaultwarden/discussions) or [create a new issue](https://github.com/dani-garcia/vaultwarden/issues/). Ensure you&#039;re using the latest version of Vaultwarden and there aren&#039;t any similar issues open or closed!

&lt;br&gt;

## Contributors

Thanks for your contribution to the project!

[![Contributors Count](https://img.shields.io/github/contributors-anon/dani-garcia/vaultwarden?style=for-the-badge&amp;logo=vaultwarden&amp;color=005AA4)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)&lt;br&gt;
[![Contributors Avatars](https://contributors-img.web.app/image?repo=dani-garcia/vaultwarden)](https://github.com/dani-garcia/vaultwarden/graphs/contributors)

&lt;br&gt;

## Disclaimer

**This project is not associated with [Bitwarden](https://bitwarden.com/) or Bitwarden, Inc.**

However, one of the active maintainers for Vaultwarden is employed by Bitwarden and is allowed to contribute to the project on their own time. These contributions are independent of Bitwarden and are reviewed by other maintainers.

The maintainers work together to set the direction for the project, focusing on serving the self-hosting community, including individuals, families, and small organizations, while ensuring the project&#039;s sustainability.

**Please note:** We cannot be held liable for any data loss that may occur while using Vaultwarden. This includes passwords, attachments, and other information handled by the application. We highly recommend performing regular backups of your files and database. However, should you experience data loss, we encourage you to contact us immediately.

&lt;br&gt;

## Bitwarden_RS

This project was known as Bitwarden_RS and has been renamed to separate itself from the official Bitwarden server in the hopes of avoiding confusion and trademark/branding issues.&lt;br&gt;
Please see [#1642 - v1.21.0 release and project rename to Vaultwarden](https://github.com/dani-garcia/vaultwarden/discussions/1642) for more explanation.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[max-sixty/worktrunk]]></title>
            <link>https://github.com/max-sixty/worktrunk</link>
            <guid>https://github.com/max-sixty/worktrunk</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:13 GMT</pubDate>
            <description><![CDATA[Worktrunk is a CLI for Git worktree management, designed for parallel AI agent workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/max-sixty/worktrunk">max-sixty/worktrunk</a></h1>
            <p>Worktrunk is a CLI for Git worktree management, designed for parallel AI agent workflows</p>
            <p>Language: Rust</p>
            <p>Stars: 1,974</p>
            <p>Forks: 73</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable MD033 --&gt;

&lt;h1&gt;&lt;img src=&quot;docs/static/logo.png&quot; alt=&quot;Worktrunk logo&quot; width=&quot;50&quot; align=&quot;absmiddle&quot;&gt;&amp;nbsp;&amp;nbsp;Worktrunk&lt;/h1&gt;

[![Docs](https://img.shields.io/badge/docs-worktrunk.dev-blue?style=for-the-badge&amp;logo=gitbook)](https://worktrunk.dev)
[![Crates.io](https://img.shields.io/crates/v/worktrunk?style=for-the-badge&amp;logo=rust)](https://crates.io/crates/worktrunk)
[![License: MIT](https://img.shields.io/badge/license-MIT-blue?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![CI](https://img.shields.io/github/actions/workflow/status/max-sixty/worktrunk/ci.yaml?event=push&amp;branch=main&amp;style=for-the-badge&amp;logo=github)](https://github.com/max-sixty/worktrunk/actions?query=branch%3Amain+workflow%3Aci)
[![Codecov](https://img.shields.io/codecov/c/github/max-sixty/worktrunk?style=for-the-badge&amp;logo=codecov)](https://codecov.io/gh/max-sixty/worktrunk)
[![Stars](https://img.shields.io/github/stars/max-sixty/worktrunk?style=for-the-badge&amp;logo=github)](https://github.com/max-sixty/worktrunk/stargazers)

&gt; **February 2026**: Worktrunk was [released](https://x.com/max_sixty/status/2006077845391724739?s=20) over the holidays, and lots of folks seem to be using it. It&#039;s built with love (there&#039;s no slop!). If social proof is helpful: I also created [PRQL](https://github.com/PRQL/prql) (10k stars) and am a maintainer of [Xarray](https://github.com/pydata/xarray) (4k stars), [Insta](https://github.com/mitsuhiko/insta), &amp; [Numbagg](https://github.com/numbagg/numbagg). Please let me know any frictions at all; I&#039;m intensely focused on making Worktrunk excellent, and the biggest gap is understanding how others experience using it.

Worktrunk is a CLI for git worktree management, designed for running AI agents in parallel.

Worktrunk&#039;s three core commands make worktrees as easy as branches. Plus, Worktrunk has a bunch of quality-of-life features to simplify working with many parallel changes, including hooks to automate local workflows.

Scaling agents becomes trivial. A quick demo:

![Worktrunk Demo](https://cdn.jsdelivr.net/gh/max-sixty/worktrunk-assets@main/assets/docs/light/wt-core.gif)

&gt; ### ğŸ“š Full documentation at [worktrunk.dev](https://worktrunk.dev) ğŸ“š

&lt;!-- âš ï¸ AUTO-GENERATED from docs/content/worktrunk.md#context-git-worktrees..worktrunk-makes-git-worktrees-as-easy-as-branches â€” edit source to update --&gt;

## Context: git worktrees

AI agents like Claude Code and Codex can handle longer tasks without
supervision, such that it&#039;s possible to manage 5-10+ in parallel. Git&#039;s native
worktree feature give each agent its own working directory, so they don&#039;t step
on each other&#039;s changes.

But the git worktree UX is clunky. Even a task as small as starting a new
worktree requires typing the branch name three times: `git worktree add -b feat
../repo.feat`, then `cd ../repo.feat`.

## Worktrunk makes git worktrees as easy as branches

Worktrees are addressed by branch name; paths are computed from a configurable template.

&gt; Start with the core commands

**Core commands:**

&lt;table class=&quot;cmd-compare&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Task&lt;/th&gt;
      &lt;th&gt;Worktrunk&lt;/th&gt;
      &lt;th&gt;Plain git&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Switch worktrees&lt;/td&gt;
      &lt;td&gt;&lt;pre&gt;wt switch feat&lt;/pre&gt;&lt;/td&gt;
      &lt;td&gt;&lt;pre&gt;cd ../repo.feat&lt;/pre&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Create + start Claude&lt;/td&gt;
      &lt;td&gt;&lt;pre&gt;wt switch -c -x claude feat&lt;/pre&gt;&lt;/td&gt;
      &lt;td&gt;&lt;pre&gt;git worktree add -b feat ../repo.feat &amp;&amp; \
cd ../repo.feat &amp;&amp; \
claude&lt;/pre&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Clean up&lt;/td&gt;
      &lt;td&gt;&lt;pre&gt;wt remove&lt;/pre&gt;&lt;/td&gt;
      &lt;td&gt;&lt;pre&gt;cd ../repo &amp;&amp; \
git worktree remove ../repo.feat &amp;&amp; \
git branch -d feat&lt;/pre&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;List with status&lt;/td&gt;
      &lt;td&gt;&lt;pre&gt;wt list&lt;/pre&gt;&lt;/td&gt;
      &lt;td&gt;&lt;pre&gt;git worktree list&lt;/pre&gt; (paths only)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

**Workflow automation:**

&gt; Expand into the more advanced commands as needed

- **[Hooks](https://worktrunk.dev/hook/)** â€” run commands on create, pre-merge, post-merge, etc
- **[LLM commit messages](https://worktrunk.dev/llm-commits/)** â€” generate commit messages from diffs
- **[Merge workflow](https://worktrunk.dev/merge/)** â€” squash, rebase, merge, clean up in one command
- ...and **[lots more](#next-steps)**

A demo with some advanced features:

![Worktrunk omnibus demo: multiple Claude agents in Zellij tabs with hooks, LLM commits, and merge workflow](https://raw.githubusercontent.com/max-sixty/worktrunk-assets/main/assets/docs/light/wt-zellij-omnibus.gif)

&lt;!-- END AUTO-GENERATED --&gt;

&lt;!-- âš ï¸ AUTO-GENERATED from docs/content/worktrunk.md#install..further-reading â€” edit source to update --&gt;

## Install

**Homebrew (macOS &amp; Linux):**

```bash
brew install worktrunk &amp;&amp; wt config shell install
```

Shell integration allows commands to change directories.

**Cargo:**

```bash
cargo install worktrunk &amp;&amp; wt config shell install
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Windows&lt;/strong&gt;&lt;/summary&gt;

On Windows, `wt` defaults to Windows Terminal&#039;s command. Winget additionally installs Worktrunk as `git-wt` to avoid the conflict:

```bash
winget install max-sixty.worktrunk
git-wt config shell install
```

Alternatively, disable Windows Terminal&#039;s alias (Settings â†’ Privacy &amp; security â†’ For developers â†’ App Execution Aliases â†’ disable &quot;Windows Terminal&quot;) to use `wt` directly.

&lt;/details&gt;

**Arch Linux:**

```bash
paru worktrunk-bin &amp;&amp; wt config shell install
```

## Quick start

Create a worktree for a new feature:

```console
$ wt switch --create feature-auth
âœ“ Created branch feature-auth from main and worktree @ repo.feature-auth

```

This creates a new branch and worktree, then switches to it. Do your work, then check all worktrees with [`wt list`](https://worktrunk.dev/list/):

```console
$ wt list
  Branch        Status        HEADÂ±    mainâ†•  Remoteâ‡…  Commit    Age   Message
@ feature-auth  +   â€“      +53                         0e631add  1d    Initial commit
^ main              ^â‡¡                         â‡¡1      0e631add  1d    Initial commit

â—‹ Showing 2 worktrees, 1 with changes, 1 column hidden

```

The `@` marks the current worktree. `+` means uncommitted changes, `â†•` means unpushed commits.

When done, either:

**PR workflow** â€” commit, push, open a PR, merge via GitHub/GitLab, then clean up:

```bash
wt step commit                    # commit staged changes
gh pr create                      # or glab mr create
wt remove                         # after PR is merged
```

**Local merge** â€” squash, rebase onto main, fast-forward merge, clean up:

```console
$ wt merge main
â— Generating commit message and committing changes... (2 files, +53, no squashing needed)
  Add authentication module
âœ“ Committed changes @ a1b2c3d
â— Merging 1 commit to main @ a1b2c3d (no rebase needed)
  * a1b2c3d Add authentication module
   auth.rs | 51 +++++++++++++++++++++++++++++++++++++++++++++++++++
   lib.rs  |  2 ++
   2 files changed, 53 insertions(+)
âœ“ Merged to main (1 commit, 2 files, +53)
â— Removing feature-auth worktree &amp; branch in background (same commit as main, _)
â—‹ Switched to worktree for main @ repo

```

For parallel agents, create multiple worktrees and launch an agent in each:

```bash
wt switch -x claude -c feature-a -- &#039;Add user authentication&#039;
wt switch -x claude -c feature-b -- &#039;Fix the pagination bug&#039;
wt switch -x claude -c feature-c -- &#039;Write tests for the API&#039;
```

The `-x` flag runs a command after switching; arguments after `--` are passed to it. Configure [post-start hooks](https://worktrunk.dev/hook/) to automate setup (install deps, start dev servers).

## Next steps

- Learn the core commands: [`wt switch`](https://worktrunk.dev/switch/), [`wt list`](https://worktrunk.dev/list/), [`wt merge`](https://worktrunk.dev/merge/), [`wt remove`](https://worktrunk.dev/remove/)
- Set up [project hooks](https://worktrunk.dev/hook/) for automated setup
- Explore [LLM commit messages](https://worktrunk.dev/llm-commits/), [interactive
  picker](https://worktrunk.dev/switch/#interactive-picker), [Claude Code integration](https://worktrunk.dev/claude-code/), [CI
  status &amp; PR links](https://worktrunk.dev/list/#ci-status)
- Run `wt --help` or `wt &lt;command&gt; --help` for quick CLI reference

## Further reading

- [Claude Code: Best practices for agentic coding](https://www.anthropic.com/engineering/claude-code-best-practices) â€” Anthropic&#039;s official guide, including the worktree pattern
- [Shipping faster with Claude Code and Git Worktrees](https://incident.io/blog/shipping-faster-with-claude-code-and-git-worktrees) â€” incident.io&#039;s workflow for parallel agents
- [Git worktree pattern discussion](https://github.com/anthropics/claude-code/issues/1052) â€” Community discussion in the Claude Code repo
- [git-worktree documentation](https://git-scm.com/docs/git-worktree) â€” Official git reference

&lt;!-- END AUTO-GENERATED --&gt;

## Contributing

- â­ Star the repo
- Tell a friend about Worktrunk
- [Open an issue](https://github.com/max-sixty/worktrunk/issues/new?title=&amp;body=%23%23%20Description%0A%0A%3C!--%20Describe%20the%20bug%20or%20feature%20request%20--%3E%0A%0A%23%23%20Context%0A%0A%3C!--%20Any%20relevant%20context%3A%20your%20workflow%2C%20what%20you%20were%20trying%20to%20do%2C%20etc.%20--%3E) â€” feedback, feature requests, even a small friction or imperfect user message, or [a worktree pain not yet solved](https://github.com/max-sixty/worktrunk/issues/new?title=Worktree%20friction%3A%20&amp;body=%23%23%20The%20friction%0A%0A%3C!--%20What%20worktree-related%20task%20is%20still%20painful%3F%20--%3E%0A%0A%23%23%20Current%20workaround%0A%0A%3C!--%20How%20do%20you%20handle%20this%20today%3F%20--%3E%0A%0A%23%23%20Ideal%20solution%0A%0A%3C!--%20What%20would%20make%20this%20easier%3F%20--%3E)
- Share: [X](https://twitter.com/intent/tweet?text=Worktrunk%20%E2%80%94%20CLI%20for%20git%20worktree%20management&amp;url=https%3A%2F%2Fworktrunk.dev) Â· [Reddit](https://www.reddit.com/submit?url=https%3A%2F%2Fworktrunk.dev&amp;title=Worktrunk%20%E2%80%94%20CLI%20for%20git%20worktree%20management) Â· [LinkedIn](https://www.linkedin.com/sharing/share-offsite/?url=https%3A%2F%2Fworktrunk.dev)

&gt; ### ğŸ“š Full documentation at [worktrunk.dev](https://worktrunk.dev) ğŸ“š

### Star history

&lt;a href=&quot;https://star-history.com/#max-sixty/worktrunk&amp;Date&quot;&gt;
  &lt;img src=&quot;https://api.star-history.com/svg?repos=max-sixty/worktrunk&amp;type=Date&quot; width=&quot;500&quot; alt=&quot;Star History Chart&quot;&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[huggingface/candle]]></title>
            <link>https://github.com/huggingface/candle</link>
            <guid>https://github.com/huggingface/candle</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:12 GMT</pubDate>
            <description><![CDATA[Minimalist ML framework for Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/candle">huggingface/candle</a></h1>
            <p>Minimalist ML framework for Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 19,360</p>
            <p>Forks: 1,420</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre># candle
[![discord server](https://dcbadge.limes.pink/api/server/hugging-face-879548962464493619)](https://discord.gg/hugging-face-879548962464493619)
[![Latest version](https://img.shields.io/crates/v/candle-core.svg)](https://crates.io/crates/candle-core)
[![Documentation](https://docs.rs/candle-core/badge.svg)](https://docs.rs/candle-core)
[![License](https://img.shields.io/github/license/base-org/node?color=blue)](https://github.com/huggingface/candle/blob/main/LICENSE-MIT)
[![License](https://img.shields.io/badge/license-Apache%202.0-blue?style=flat-square)](https://github.com/huggingface/candle/blob/main/LICENSE-APACHE)

Candle is a minimalist ML framework for Rust with a focus on performance (including GPU support) 
and ease of use. Try our online demos: 
[whisper](https://huggingface.co/spaces/lmz/candle-whisper),
[LLaMA2](https://huggingface.co/spaces/lmz/candle-llama2),
[T5](https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm),
[yolo](https://huggingface.co/spaces/lmz/candle-yolo),
[Segment
Anything](https://huggingface.co/spaces/radames/candle-segment-anything-wasm).

## Get started

Make sure that you have [`candle-core`](https://github.com/huggingface/candle/tree/main/candle-core) correctly installed as described in [**Installation**](https://huggingface.github.io/candle/guide/installation.html).

Let&#039;s see how to run a simple matrix multiplication.
Write the following to your `myapp/src/main.rs` file:
```rust
use candle_core::{Device, Tensor};

fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let device = Device::Cpu;

    let a = Tensor::randn(0f32, 1., (2, 3), &amp;device)?;
    let b = Tensor::randn(0f32, 1., (3, 4), &amp;device)?;

    let c = a.matmul(&amp;b)?;
    println!(&quot;{c}&quot;);
    Ok(())
}
```

`cargo run` should display a tensor of shape `Tensor[[2, 4], f32]`.


Having installed `candle` with Cuda support, simply define the `device` to be on GPU:

```diff
- let device = Device::Cpu;
+ let device = Device::new_cuda(0)?;
```

For more advanced examples, please have a look at the following section.

## Check out our examples

These online demos run entirely in your browser:
- [yolo](https://huggingface.co/spaces/lmz/candle-yolo): pose estimation and
  object recognition.
- [whisper](https://huggingface.co/spaces/lmz/candle-whisper): speech recognition.
- [LLaMA2](https://huggingface.co/spaces/lmz/candle-llama2): text generation.
- [T5](https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm): text generation.
- [Phi-1.5, and Phi-2](https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm): text generation.
- [Segment Anything Model](https://huggingface.co/spaces/radames/candle-segment-anything-wasm): Image segmentation.
- [BLIP](https://huggingface.co/spaces/radames/Candle-BLIP-Image-Captioning): image captioning.

We also provide some command line based examples using state of the art models:

- [LLaMA v1, v2, and v3](./candle-examples/examples/llama/): general LLM, includes
  the SOLAR-10.7B variant.
- [Falcon](./candle-examples/examples/falcon/): general LLM.
- [Codegeex4](./candle-examples/examples/codegeex4-9b/): Code completion, code interpreter, web search, function calling, repository-level
- [GLM4](./candle-examples/examples/glm4/): Open Multilingual Multimodal Chat LMs by THUDM
- [Gemma v1 and v2](./candle-examples/examples/gemma/): 2b and 7b+/9b general LLMs from Google Deepmind.
- [RecurrentGemma](./candle-examples/examples/recurrent-gemma/): 2b and 7b
  Griffin based models from Google that mix attention with a RNN like state.
- [Phi-1, Phi-1.5, Phi-2, and Phi-3](./candle-examples/examples/phi/): 1.3b,
  2.7b, and 3.8b general LLMs with performance on par with 7b models.
- [StableLM-3B-4E1T](./candle-examples/examples/stable-lm/): a 3b general LLM
  pre-trained on 1T tokens of English and code datasets. Also supports
  StableLM-2, a 1.6b LLM trained on 2T tokens, as well as the code variants.
- [Mamba](./candle-examples/examples/mamba/): an inference only
  implementation of the Mamba state space model.
- [Mistral7b-v0.1](./candle-examples/examples/mistral/): a 7b general LLM with
  better performance than all publicly available 13b models as of 2023-09-28.
- [Mixtral8x7b-v0.1](./candle-examples/examples/mixtral/): a sparse mixture of
  experts 8x7b general LLM with better performance than a Llama 2 70B model with
  much faster inference.
- [StarCoder](./candle-examples/examples/bigcode/) and
  [StarCoder2](./candle-examples/examples/starcoder2/): LLM specialized to code generation.
- [Qwen1.5](./candle-examples/examples/qwen/): Bilingual (English/Chinese) LLMs.
- [RWKV v5 and v6](./candle-examples/examples/rwkv/): An RNN with transformer level LLM
  performance.
- [Replit-code-v1.5](./candle-examples/examples/replit-code/): a 3.3b LLM specialized for code completion.
- [Yi-6B / Yi-34B](./candle-examples/examples/yi/): two bilingual
  (English/Chinese) general LLMs with 6b and 34b parameters.
- [Quantized LLaMA](./candle-examples/examples/quantized/): quantized version of
  the LLaMA model using the same quantization techniques as
  [llama.cpp](https://github.com/ggerganov/llama.cpp).
- [Quantized Qwen3 MoE](./candle-examples/examples/quantized-qwen3-moe/): support gguf quantized models of Qwen3 MoE models.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/quantized/assets/aoc.gif&quot; width=&quot;600&quot;&gt;
  
- [Stable Diffusion](./candle-examples/examples/stable-diffusion/): text to
  image generative model, support for the 1.5, 2.1, SDXL 1.0 and Turbo versions.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/stable-diffusion/assets/stable-diffusion-xl.jpg&quot; width=&quot;200&quot;&gt;

- [Wuerstchen](./candle-examples/examples/wuerstchen/): another text to
  image generative model.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/wuerstchen/assets/cat.jpg&quot; width=&quot;200&quot;&gt;

- [yolo-v3](./candle-examples/examples/yolo-v3/) and
  [yolo-v8](./candle-examples/examples/yolo-v8/): object detection and pose
  estimation models.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.od.jpg&quot; width=&quot;200&quot;&gt;&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/yolo-v8/assets/bike.pose.jpg&quot; width=&quot;200&quot;&gt;
- [segment-anything](./candle-examples/examples/segment-anything/): image
  segmentation model with prompt.

&lt;img src=&quot;https://github.com/huggingface/candle/raw/main/candle-examples/examples/segment-anything/assets/sam_merged.jpg&quot; width=&quot;200&quot;&gt;

- [SegFormer](./candle-examples/examples/segformer/): transformer based semantic segmentation model.
- [Whisper](./candle-examples/examples/whisper/): speech recognition model.
- [EnCodec](./candle-examples/examples/encodec/): high-quality audio compression
  model using residual vector quantization.
- [MetaVoice](./candle-examples/examples/metavoice/): foundational model for
  text-to-speech.
- [Parler-TTS](./candle-examples/examples/parler-tts/): large text-to-speech
  model.
- [T5](./candle-examples/examples/t5), [Bert](./candle-examples/examples/bert/),
  [JinaBert](./candle-examples/examples/jina-bert/) : useful for sentence embeddings.
- [DINOv2](./candle-examples/examples/dinov2/): computer vision model trained
  using self-supervision (can be used for imagenet classification, depth
  evaluation, segmentation).
- [VGG](./candle-examples/examples/vgg/),
  [RepVGG](./candle-examples/examples/repvgg): computer vision models.
- [BLIP](./candle-examples/examples/blip/): image to text model, can be used to
  generate captions for an image.
- [CLIP](./candle-examples/examples/clip/): multi-model vision and language
  model.
- [TrOCR](./candle-examples/examples/trocr/): a transformer OCR model, with
  dedicated submodels for hand-writing and printed recognition.
- [Marian-MT](./candle-examples/examples/marian-mt/): neural machine translation
  model, generates the translated text from the input text.
- [Moondream](./candle-examples/examples/moondream/): tiny computer-vision model 
  that can answer real-world questions about images.

Run them using commands like:
```
cargo run --example quantized --release
```

In order to use **CUDA** add `--features cuda` to the example command line. If
you have cuDNN installed, use `--features cudnn` for even more speedups.

There are also some wasm examples for whisper and
[llama2.c](https://github.com/karpathy/llama2.c). You can either build them with
`trunk` or try them online:
[whisper](https://huggingface.co/spaces/lmz/candle-whisper),
[llama2](https://huggingface.co/spaces/lmz/candle-llama2),
[T5](https://huggingface.co/spaces/radames/Candle-T5-Generation-Wasm),
[Phi-1.5, and Phi-2](https://huggingface.co/spaces/radames/Candle-Phi-1.5-Wasm),
[Segment Anything Model](https://huggingface.co/spaces/radames/candle-segment-anything-wasm).

For LLaMA2, run the following command to retrieve the weight files and start a
test server:
```bash
cd candle-wasm-examples/llama2-c
wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/model.bin
wget https://huggingface.co/spaces/lmz/candle-llama2/resolve/main/tokenizer.json
trunk serve --release --port 8081
```
And then head over to
[http://localhost:8081/](http://localhost:8081/).

&lt;!--- ANCHOR: useful_libraries ---&gt;

## Useful External Resources
- [`candle-tutorial`](https://github.com/ToluClassics/candle-tutorial): A
  very detailed tutorial showing how to convert a PyTorch model to Candle.
- [`candle-lora`](https://github.com/EricLBuehler/candle-lora): Efficient and
  ergonomic LoRA implementation for Candle. `candle-lora` has      
  out-of-the-box LoRA support for many models from Candle, which can be found
  [here](https://github.com/EricLBuehler/candle-lora/tree/master/candle-lora-transformers/examples).
- [`candle-video`](https://github.com/FerrisMind/candle-video): Rust library for text-to-video generation (LTX-Video and related models) built on Candle, focused on fast, Python-free inference.
- [`optimisers`](https://github.com/KGrewal1/optimisers): A collection of optimisers
  including SGD with momentum, AdaGrad, AdaDelta, AdaMax, NAdam, RAdam, and RMSprop.
- [`candle-vllm`](https://github.com/EricLBuehler/candle-vllm): Efficient platform for inference and
  serving local LLMs including an OpenAI compatible API server.
- [`candle-ext`](https://github.com/mokeyish/candle-ext): An extension library to Candle that provides PyTorch functions not currently available in Candle.
- [`candle-coursera-ml`](https://github.com/vishpat/candle-coursera-ml): Implementation of ML algorithms from Coursera&#039;s [Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction) course.
- [`kalosm`](https://github.com/floneum/floneum/tree/master/interfaces/kalosm): A multi-modal meta-framework in Rust for interfacing with local pre-trained models with support for controlled generation, custom samplers, in-memory vector databases, audio transcription, and more.
- [`candle-sampling`](https://github.com/EricLBuehler/candle-sampling): Sampling techniques for Candle.
- [`gpt-from-scratch-rs`](https://github.com/jeroenvlek/gpt-from-scratch-rs): A port of Andrej Karpathy&#039;s _Let&#039;s build GPT_ tutorial on YouTube showcasing the Candle API on a toy problem.
- [`candle-einops`](https://github.com/tomsanbear/candle-einops): A pure rust implementation of the python [einops](https://github.com/arogozhnikov/einops) library.
- [`atoma-infer`](https://github.com/atoma-network/atoma-infer): A Rust library for fast inference at scale, leveraging FlashAttention2 for efficient attention computation, PagedAttention for efficient KV-cache memory management, and multi-GPU support. It is OpenAI api compatible.
- [`llms-from-scratch-rs`](https://github.com/nerdai/llms-from-scratch-rs): A comprehensive Rust translation of the code from Sebastian Raschka&#039;s Build an LLM from Scratch book.
- [`vllm.rs`](https://github.com/guoqingbao/vllm.rs): A minimalist vLLM implementation in Rust based on Candle.

If you have an addition to this list, please submit a pull request.

&lt;!--- ANCHOR_END: useful_libraries ---&gt;

&lt;!--- ANCHOR: features ---&gt;

## Features

- Simple syntax, looks and feels like PyTorch.
    - Model training.
    - Embed user-defined ops/kernels, such as [flash-attention v2](https://github.com/huggingface/candle/blob/89ba005962495f2bfbda286e185e9c3c7f5300a3/candle-flash-attn/src/lib.rs#L152).
- Backends.
    - Optimized CPU backend with optional MKL support for x86 and Accelerate for macs.
    - CUDA backend for efficiently running on GPUs, multiple GPU distribution via NCCL.
    - WASM support, run your models in a browser.
- Included models.
    - Language Models.
        - LLaMA v1, v2, and v3 with variants such as SOLAR-10.7B.
        - Falcon.
        - StarCoder, StarCoder2.
        - Phi 1, 1.5, 2, and 3.
        - Mamba, Minimal Mamba
        - Gemma v1 2b and 7b+, v2 2b and 9b.
        - Mistral 7b v0.1.
        - Mixtral 8x7b v0.1.
        - StableLM-3B-4E1T, StableLM-2-1.6B, Stable-Code-3B.
        - Replit-code-v1.5-3B.
        - Bert.
        - Yi-6B and Yi-34B.
        - Qwen1.5, Qwen1.5 MoE, Qwen3 MoE.
        - RWKV v5 and v6.
    - Quantized LLMs.
        - Llama 7b, 13b, 70b, as well as the chat and code variants.
        - Mistral 7b, and 7b instruct.
        - Mixtral 8x7b.
        - Zephyr 7b a and b (Mistral-7b based).
        - OpenChat 3.5 (Mistral-7b based).
        - Qwen3 MoE (16B-A3B, 32B-A3B)
    - Text to text.
        - T5 and its variants: FlanT5, UL2, MADLAD400 (translation), CoEdit (Grammar correction).
        - Marian MT (Machine Translation).
    - Text to image.
        - Stable Diffusion v1.5, v2.1, XL v1.0.
        - Wurstchen v2.
    - Image to text.
        - BLIP.
        - TrOCR.
    - Audio.
        - Whisper, multi-lingual speech-to-text.
        - EnCodec, audio compression model.
        - MetaVoice-1B, text-to-speech model.
        - Parler-TTS, text-to-speech model.
    - Computer Vision Models.
        - DINOv2, ConvMixer, EfficientNet, ResNet, ViT, VGG, RepVGG, ConvNeXT,
          ConvNeXTv2, MobileOne, EfficientVit (MSRA), MobileNetv4, Hiera, FastViT.
        - yolo-v3, yolo-v8.
        - Segment-Anything Model (SAM).
        - SegFormer.
- File formats: load models from safetensors, npz, ggml, or PyTorch files.
- Serverless (on CPU), small and fast deployments.
- Quantization support using the llama.cpp quantized types.

&lt;!--- ANCHOR_END: features ---&gt;

## How to use

&lt;!--- ANCHOR: cheatsheet ---&gt;
Cheatsheet:

|            | Using PyTorch                            | Using Candle                                                     |
|------------|------------------------------------------|------------------------------------------------------------------|
| Creation   | `torch.Tensor([[1, 2], [3, 4]])`         | `Tensor::new(&amp;[[1f32, 2.], [3., 4.]], &amp;Device::Cpu)?`           |
| Creation   | `torch.zeros((2, 2))`                    | `Tensor::zeros((2, 2), DType::F32, &amp;Device::Cpu)?`               |
| Indexing   | `tensor[:, :4]`                          | `tensor.i((.., ..4))?`                                           |
| Operations | `tensor.view((2, 2))`                    | `tensor.reshape((2, 2))?`                                        |
| Operations | `a.matmul(b)`                            | `a.matmul(&amp;b)?`                                                  |
| Arithmetic | `a + b`                                  | `&amp;a + &amp;b`                                                        |
| Device     | `tensor.to(device=&quot;cuda&quot;)`               | `tensor.to_device(&amp;Device::new_cuda(0)?)?`                            |
| Dtype      | `tensor.to(dtype=torch.float16)`         | `tensor.to_dtype(&amp;DType::F16)?`                                  |
| Saving     | `torch.save({&quot;A&quot;: A}, &quot;model.bin&quot;)`      | `candle::safetensors::save(&amp;HashMap::from([(&quot;A&quot;, A)]), &quot;model.safetensors&quot;)?` |
| Loading    | `weights = torch.load(&quot;model.bin&quot;)`      | `candle::safetensors::load(&quot;model.safetensors&quot;, &amp;device)`        |

&lt;!--- ANCHOR_END: cheatsheet ---&gt;


## Structure

- [candle-core](./candle-core): Core ops, devices, and `Tensor` struct definition
- [candle-nn](./candle-nn/): Tools to build real models
- [candle-examples](./candle-examples/): Examples of using the library in realistic settings
- [candle-kernels](./candle-kernels/): CUDA custom kernels
- [candle-datasets](./candle-datasets/): Datasets and data loaders.
- [candle-transformers](./candle-transformers): transformers-related utilities.
- [candle-flash-attn](./candle-flash-attn): Flash attention v2 layer.
- [candle-onnx](./candle-onnx/): ONNX model evaluation.

## FAQ

### Why should I use Candle?

&lt;!--- ANCHOR: goals ---&gt;

Candle&#039;s core goal is to *make serverless inference possible*. Full machine learning frameworks like PyTorch
are very large, which makes creating instances on a cluster slow. Candle allows deployment of lightweight
binaries.

Secondly, Candle lets you *remove Python* from production workloads. Python overhead can seriously hurt performance,
and the [GIL](https://www.backblaze.com/blog/the-python-gil-past-present-and-future/) is a notorious source of headaches.

Finally, Rust is cool! A lot of the HF ecosystem already has Rust crates, like [safetensors](https://github.com/huggingface/safetensors) and [tokenizers](https://github.com/huggingface/tokenizers).

&lt;!--- ANCHOR_END: goals ---&gt;

### Other ML frameworks

- [dfdx](https://github.com/coreylowman/dfdx) is a formidable crate, with shapes being included
  in types. This prevents a lot of headaches by getting the compiler to complain about shape mismatches right off the bat.
  However, we found that some features still require nightly, and writing code can be a bit daunting for non rust experts.

  We&#039;re leveraging and contributing to other core crates for the runtime so hopefully both crates can benefit from each
  other.

- [burn](https://github.com/burn-rs/burn) is a general crate that can leverage multiple backends so you can choose the best
  engine for your workload.

- [tch-rs](https://github.com/LaurentMazare/tch-rs.git) Bindings to the torch library in Rust. Extremely versatile, but they 
  bring in the entire torch library into the runtime. The main contributor of `tch-rs` is also involved in the development
  of `candle`.

### Common Errors

#### Missing symbols when compiling with the mkl feature.

If you get some missing symbols when compiling binaries/tests using the mkl
or accelerate features, e.g. for mkl you get:
```
  = note: /usr/bin/ld: (....o): in function `blas::sgemm&#039;:
          .../blas-0.22.0/src/lib.rs:1944: undefined reference to `sgemm_&#039; collect2: error: ld returned 1 exit status

  = note: some `extern` functions couldn&#039;t be found; some native libraries may need to be installed or have their path specified
  = note: use the `-l` flag to specify native libraries to link
  = note: use the `cargo:rustc-link-lib` directive to specify the native libraries to link with Cargo
```
or for accelerate:
```
Undefined symbols for architecture arm64:
            &quot;_dgemm_&quot;, referenced from:
                candle_core::accelerate::dgemm::h1b71a038552bcabe in libcandle_core...
            &quot;_sgemm_&quot;, referenced from:
                candle_core::accelerate::sgemm::h2cf21c592cba3c47 in libcandle_core...
          ld: symbol(s) not found for architecture arm64
```

This is likely due to a missing linker flag that was needed to enable the mkl library. You
can try adding the following for mkl at the top of your binary:
```rust
extern crate intel_mkl_src;
```
or for accelerate:
```rust
extern crate accelerate_src;
```

#### Cannot run the LLaMA examples: access to source requires login credentials

```
Error: request error: https://huggingface.co/meta-llama/Llama-2-7b-hf/resolve/main/tokenizer.json: status code 401
```

This is likely because you&#039;re not permissioned for the LLaMA-v2 model. To fix
this, you have to register on th

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustdesk/rustdesk]]></title>
            <link>https://github.com/rustdesk/rustdesk</link>
            <guid>https://github.com/rustdesk/rustdesk</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:11 GMT</pubDate>
            <description><![CDATA[An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustdesk/rustdesk">rustdesk/rustdesk</a></h1>
            <p>An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.</p>
            <p>Language: Rust</p>
            <p>Stars: 107,321</p>
            <p>Forks: 15,952</p>
            <p>Stars today: 87 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;res/logo-header.svg&quot; alt=&quot;RustDesk - Your remote desktop&quot;&gt;&lt;br&gt;
  &lt;a href=&quot;#raw-steps-to-build&quot;&gt;Build&lt;/a&gt; â€¢
  &lt;a href=&quot;#how-to-build-with-docker&quot;&gt;Docker&lt;/a&gt; â€¢
  &lt;a href=&quot;#file-structure&quot;&gt;Structure&lt;/a&gt; â€¢
  &lt;a href=&quot;#snapshot&quot;&gt;Snapshot&lt;/a&gt;&lt;br&gt;
  [&lt;a href=&quot;docs/README-UA.md&quot;&gt;Ğ£ĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ°&lt;/a&gt;] | [&lt;a href=&quot;docs/README-CS.md&quot;&gt;Äesky&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ZH.md&quot;&gt;ä¸­æ–‡&lt;/a&gt;] | [&lt;a href=&quot;docs/README-HU.md&quot;&gt;Magyar&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ES.md&quot;&gt;EspaÃ±ol&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FA.md&quot;&gt;ÙØ§Ø±Ø³ÛŒ&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FR.md&quot;&gt;FranÃ§ais&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DE.md&quot;&gt;Deutsch&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PL.md&quot;&gt;Polski&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ID.md&quot;&gt;Indonesian&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FI.md&quot;&gt;Suomi&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ML.md&quot;&gt;à´®à´²à´¯à´¾à´³à´‚&lt;/a&gt;] | [&lt;a href=&quot;docs/README-JP.md&quot;&gt;æ—¥æœ¬èª&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NL.md&quot;&gt;Nederlands&lt;/a&gt;] | [&lt;a href=&quot;docs/README-IT.md&quot;&gt;Italiano&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RU.md&quot;&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PTBR.md&quot;&gt;PortuguÃªs (Brasil)&lt;/a&gt;] | [&lt;a href=&quot;docs/README-EO.md&quot;&gt;Esperanto&lt;/a&gt;] | [&lt;a href=&quot;docs/README-KR.md&quot;&gt;í•œêµ­ì–´&lt;/a&gt;] | [&lt;a href=&quot;docs/README-AR.md&quot;&gt;Ø§Ù„Ø¹Ø±Ø¨ÙŠ&lt;/a&gt;] | [&lt;a href=&quot;docs/README-VN.md&quot;&gt;Tiáº¿ng Viá»‡t&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DA.md&quot;&gt;Dansk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-GR.md&quot;&gt;Î•Î»Î»Î·Î½Î¹ÎºÎ¬&lt;/a&gt;] | [&lt;a href=&quot;docs/README-TR.md&quot;&gt;TÃ¼rkÃ§e&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NO.md&quot;&gt;Norsk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RO.md&quot;&gt;RomÃ¢nÄƒ&lt;/a&gt;]&lt;br&gt;
  &lt;b&gt;We need your help to translate this README, &lt;a href=&quot;https://github.com/rustdesk/rustdesk/tree/master/src/lang&quot;&gt;RustDesk UI&lt;/a&gt; and &lt;a href=&quot;https://github.com/rustdesk/doc.rustdesk.com&quot;&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt;
&lt;/p&gt;

&gt; [!Caution]
&gt; **Misuse Disclaimer:** &lt;br&gt;
&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.


Chat with us: [Discord](https://discord.gg/nDceKgxnkV) | [Twitter](https://twitter.com/rustdesk) | [Reddit](https://www.reddit.com/r/rustdesk) | [YouTube](https://www.youtube.com/@rustdesk)

[![RustDesk Server Pro](https://img.shields.io/badge/RustDesk%20Server%20Pro-Advanced%20Features-blue)](https://rustdesk.com/pricing.html)

Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, [set up your own](https://rustdesk.com/server), or [write your own rendezvous/relay server](https://github.com/rustdesk/rustdesk-server-demo).

![image](https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png)

RustDesk welcomes contribution from everyone. See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for help getting started.

[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)

[**BINARY DOWNLOAD**](https://github.com/rustdesk/rustdesk/releases)

[**NIGHTLY BUILD**](https://github.com/rustdesk/rustdesk/releases/tag/nightly)

[&lt;img src=&quot;https://f-droid.org/badge/get-it-on.png&quot;
    alt=&quot;Get it on F-Droid&quot;
    height=&quot;80&quot;&gt;](https://f-droid.org/en/packages/com.carriez.flutter_hbb)
[&lt;img src=&quot;https://flathub.org/api/badge?svg&amp;locale=en&quot;
    alt=&quot;Get it on Flathub&quot;
    height=&quot;80&quot;&gt;](https://flathub.org/apps/com.rustdesk.RustDesk)

## Dependencies

Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our [CI](https://github.com/rustdesk/rustdesk/blob/master/.github/workflows/flutter-build.yml) for building Flutter version.

Please download Sciter dynamic library yourself.

[Windows](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll) |
[Linux](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so) |
[macOS](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib)

## Raw Steps to build

- Prepare your Rust development env and C++ build env

- Install [vcpkg](https://github.com/microsoft/vcpkg), and set `VCPKG_ROOT` env variable correctly

  - Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static
  - Linux/macOS: vcpkg install libvpx libyuv opus aom

- run `cargo run`

## [Build](https://rustdesk.com/docs/en/dev/build/)

## How to Build on Linux

### Ubuntu 18 (Debian 10)

```sh
sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
```

### openSUSE Tumbleweed

```sh
sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
```

### Fedora 28 (CentOS 8)

```sh
sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
```

### Arch (Manjaro)

```sh
sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
```

### Install vcpkg

```sh
git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
```

### Fix libvpx (For Fedora)

```sh
cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i &#039;s/CFLAGS+=-I/CFLAGS+=-fPIC -I/g&#039; Makefile
sed -i &#039;s/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g&#039; Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
```

### Build

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
```

## How to build with Docker

Begin by cloning the repository and building the Docker container:

```sh
git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t &quot;rustdesk-builder&quot; .
```

Then, each time you need to build the application, run the following command:

```sh
docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=&quot;$(id -u)&quot; -e PGID=&quot;$(id -g)&quot; rustdesk-builder
```

Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the `&lt;OPTIONAL-ARGS&gt;` position. For instance, if you wanted to build an optimized release version, you would run the command above followed by `--release`. The resulting executable will be available in the target folder on your system, and can be run with:

```sh
target/debug/rustdesk
```

Or, if you&#039;re running a release executable:

```sh
target/release/rustdesk
```

Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as `install` or `run` are not currently supported via this method as they would install or run the program inside the container instead of the host.

## File Structure

- **[libs/hbb_common](https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common)**: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions
- **[libs/scrap](https://github.com/rustdesk/rustdesk/tree/master/libs/scrap)**: screen capture
- **[libs/enigo](https://github.com/rustdesk/rustdesk/tree/master/libs/enigo)**: platform specific keyboard/mouse control
- **[libs/clipboard](https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard)**: file copy and paste implementation for Windows, Linux, macOS.
- **[src/ui](https://github.com/rustdesk/rustdesk/tree/master/src/ui)**: obsolete Sciter UI (deprecated)
- **[src/server](https://github.com/rustdesk/rustdesk/tree/master/src/server)**: audio/clipboard/input/video services, and network connections
- **[src/client.rs](https://github.com/rustdesk/rustdesk/tree/master/src/client.rs)**: start a peer connection
- **[src/rendezvous_mediator.rs](https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs)**: Communicate with [rustdesk-server](https://github.com/rustdesk/rustdesk-server), wait for remote direct (TCP hole punching) or relayed connection
- **[src/platform](https://github.com/rustdesk/rustdesk/tree/master/src/platform)**: platform specific code
- **[flutter](https://github.com/rustdesk/rustdesk/tree/master/flutter)**: Flutter code for desktop and mobile
- **[flutter/web/js](https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js)**: JavaScript for Flutter web client

## Screenshots

![Connection Manager](https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651)

![Connected to a Windows PC](https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea)

![File Transfer](https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad)

![TCP Tunneling](https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[esp-rs/esp-hal]]></title>
            <link>https://github.com/esp-rs/esp-hal</link>
            <guid>https://github.com/esp-rs/esp-hal</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:10 GMT</pubDate>
            <description><![CDATA[no_std Hardware Abstraction Layers for ESP32 microcontrollers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/esp-rs/esp-hal">esp-rs/esp-hal</a></h1>
            <p>no_std Hardware Abstraction Layers for ESP32 microcontrollers</p>
            <p>Language: Rust</p>
            <p>Stars: 1,731</p>
            <p>Forks: 397</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./resources/esp-rs.svg&quot; alt=&quot;esp-rs logo&quot; width=&quot;100px&quot; /&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;esp-hal&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/esp-rs/esp-hal/ci.yml?labelColor=1C2C2E&amp;label=CI&amp;logo=github&amp;style=flat-square&quot; alt=&quot;GitHub Actions Workflow Status&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/esp-rs/esp-hal/hil.yml?labelColor=1C2C2E&amp;label=HIL&amp;logo=github&amp;style=flat-square&amp;event=merge_group&quot; alt=&quot;GitHub Actions Workflow Status&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/badge/license-MIT%2FApache--2.0-blue?labelColor=1C2C2E&amp;style=flat-square&quot; alt=&quot;MIT/Apache-2.0 licensed&quot; /&gt;
  &lt;a href=&quot;https://matrix.to/#/#esp-rs:matrix.org&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/matrix/esp-rs:matrix.org?labelColor=1C2C2E&amp;label=join%20matrix&amp;color=BEC5C9&amp;logo=matrix&amp;style=flat-square&quot; alt=&quot;Matrix&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

Bare-metal (`no_std`) hardware abstraction layer for Espressif devices. Currently supports the following devices:

- ESP32 Series: _ESP32_
- ESP32-C Series: _ESP32-C2, ESP32-C3, ESP32-C6_
- ESP32-H Series: _ESP32-H2_
- ESP32-S Series: _ESP32-S2, ESP32-S3_

Additionally provides support for programming the low-power RISC-V cores found on the _ESP32-C6_, _ESP32-S2_, and _ESP32-S3_ via the [esp-lp-hal] package.

For additional information regarding any of the crates in this repository, please refer to the relevant crate&#039;s `README.md` file. If you have any questions, comments, or concerns, please [open an issue], or join us on [Matrix].

If you are currently using (or considering using) `esp-hal` in a production environment and have any feedback or require support, please feel free to contact us at &lt;rust.support@espressif.com&gt;.

&gt; [!NOTE]
&gt;
&gt; This repository includes crates that are at various stages of maturity and stability. While many functionalities have already been implemented and are usable for most tasks, certain advanced or less common features may still be under development. Each crate may offer different levels of functionality and guarantees.

[esp-lp-hal]: https://github.com/esp-rs/esp-hal/tree/main/esp-lp-hal
[esp-idf-svc]: https://github.com/esp-rs/esp-idf-svc
[open an issue]: https://github.com/esp-rs/esp-hal/issues/new
[matrix]: https://matrix.to/#/#esp-rs:matrix.org

## Getting Started

For information relating to the development of Rust applications on ESP devices, please first read [The Rust on ESP Book].

For information about the HAL and how to use it in your own projects, please refer to the [documentation].

When browsing the examples, we recommend viewing the tag for the `esp-hal` release you are using to ensure compatibility, e.g. [esp-hal-v1.0.0], as the `main` branch is used for development and APIs may have changed in the meantime.

[The Rust on ESP Book]: https://docs.espressif.com/projects/rust/book/
[documentation]: https://docs.espressif.com/projects/rust/
[esp-hal-v1.0.0]: https://github.com/esp-rs/esp-hal/tree/esp-hal-v1.0.0/examples

## Resources

- [The Rust Programming Language](https://doc.rust-lang.org/book/)
- [The Embedded Rust Book](https://docs.rust-embedded.org/book/index.html)
- [The Embedonomicon](https://docs.rust-embedded.org/embedonomicon/)
- [The Rust on ESP Book](https://docs.espressif.com/projects/rust/esp-hal/latest/)
- [Embedded Rust (no_std) on Espressif](https://docs.espressif.com/projects/rust/no_std-training/)

## Support policy

All active development will occur on `main`.

We will only backport fixes to the _latest_ minor release in a major version. For example, this means we will apply patches (bug fixes) to `1.1.x` until `1.2.0` is released, at which point all patches are only backported to the `1.2.x` series of releases.

If you are a user of `unstable` APIs, we will never push breaking changes in a patch release. However, `unstable` changes _will_ make there way into minor releases. This means that as an `unstable` user updating from `1.1.x` to `1.2.x` _may_ introduce breaking changes. If you depend on `unstable`, we recommend defining your esp-hal dependency as follows:

```toml
esp-hal = { version = &quot;~1.1&quot; }
```

Using the [`~` operator](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html#tilde-requirements) will prevent cargo auto updating to minor versions, allowing you to use `cargo update` without the possiblity of breaking your project.

## AI Contribution Policy

We follow the same policy as the official Rust Embedded working group, please review [the policy](https://github.com/rust-embedded/wg/blob/HEAD/CODE_OF_CONDUCT.md#ai-tool-use-policy) before contributing with AI tools.

## Contributing

We have a number of living documents to aid contributing to the project, please give these a read before modifying code:

- [DEVELOPER-GUIDELINES](https://github.com/esp-rs/esp-hal/blob/main/documentation/DEVELOPER-GUIDELINES.md)
- [CONTRIBUTING-GUIDE](https://github.com/esp-rs/esp-hal/blob/main/documentation/CONTRIBUTING.md)

## License

All packages within this repository are licensed under either of:

- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your option.

### Contribution notice

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in
the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without
any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[bevyengine/bevy]]></title>
            <link>https://github.com/bevyengine/bevy</link>
            <guid>https://github.com/bevyengine/bevy</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:09 GMT</pubDate>
            <description><![CDATA[A refreshingly simple data-driven game engine built in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/bevyengine/bevy">bevyengine/bevy</a></h1>
            <p>A refreshingly simple data-driven game engine built in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 44,595</p>
            <p>Forks: 4,378</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre># [![Bevy](https://bevy.org/assets/bevy_logo_light_dark_and_dimmed.svg)](https://bevy.org)

[![License](https://img.shields.io/badge/license-MIT%2FApache-blue.svg)](https://github.com/bevyengine/bevy#license)
[![Crates.io](https://img.shields.io/crates/v/bevy.svg)](https://crates.io/crates/bevy)
[![Downloads](https://img.shields.io/crates/d/bevy.svg)](https://crates.io/crates/bevy)
[![Docs](https://docs.rs/bevy/badge.svg)](https://docs.rs/bevy/latest/bevy/)
[![CI](https://github.com/bevyengine/bevy/workflows/CI/badge.svg)](https://github.com/bevyengine/bevy/actions)
[![Discord](https://img.shields.io/discord/691052431525675048.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/bevy)

## What is Bevy?

Bevy is a refreshingly simple data-driven game engine built in Rust. It is free and open-source forever!

## WARNING

Bevy is still in the early stages of development. Important features are missing. Documentation is sparse. A new version of Bevy containing breaking changes to the API is released [approximately once every 3 months](https://bevy.org/news/bevy-0-6/#the-train-release-schedule). We provide [migration guides](https://bevy.org/learn/migration-guides/), but we can&#039;t guarantee migrations will always be easy. Use only if you are willing to work in this environment.

**MSRV:** Bevy relies heavily on improvements in the Rust language and compiler.
As a result, the Minimum Supported Rust Version (MSRV) is generally close to &quot;the latest stable release&quot; of Rust.

## Design Goals

* **Capable**: Offer a complete 2D and 3D feature set
* **Simple**: Easy for newbies to pick up, but infinitely flexible for power users
* **Data Focused**: Data-oriented architecture using the Entity Component System paradigm
* **Modular**: Use only what you need. Replace what you don&#039;t like
* **Fast**: App logic should run quickly, and when possible, in parallel
* **Productive**: Changes should compile quickly ... waiting isn&#039;t fun

## About

* **[Features](https://bevy.org):** A quick overview of Bevy&#039;s features.
* **[News](https://bevy.org/news/)**: A development blog that covers our progress, plans and shiny new features.

## Docs

* **[Quick Start Guide](https://bevy.org/learn/quick-start/introduction):** Bevy&#039;s official Quick Start Guide. The best place to start learning Bevy.
* **[Bevy Rust API Docs](https://docs.rs/bevy):** Bevy&#039;s Rust API docs, which are automatically generated from the doc comments in this repo.
* **[Official Examples](https://github.com/bevyengine/bevy/tree/latest/examples):** Bevy&#039;s dedicated, runnable examples, which are great for digging into specific concepts.
* **[Community-Made Learning Resources](https://bevy.org/assets/#learning)**: More tutorials, documentation, and examples made by the Bevy community.

## Community

Before contributing or participating in discussions with the community, you should familiarize yourself with our [**Code of Conduct**](./CODE_OF_CONDUCT.md).

* **[Discord](https://discord.gg/bevy):** Bevy&#039;s official discord server.
* **[Reddit](https://reddit.com/r/bevy):** Bevy&#039;s official subreddit.
* **[GitHub Discussions](https://github.com/bevyengine/bevy/discussions):** The best place for questions about Bevy, answered right here!
* **[Bevy Assets](https://bevy.org/assets/):** A collection of awesome Bevy projects, tools, plugins and learning materials.

### Contributing

If you&#039;d like to help build Bevy, check out the **[Contributor&#039;s Guide](https://bevy.org/learn/contribute/introduction)**.
For simple problems, feel free to [open an issue](https://github.com/bevyengine/bevy/issues) or
[PR](https://github.com/bevyengine/bevy/pulls) and tackle it yourself!

For more complex architecture decisions and experimental mad science, please open an [RFC](https://github.com/bevyengine/rfcs) (Request For Comments) so we can brainstorm together effectively!

## Getting Started

We recommend checking out the [Quick Start Guide](https://bevy.org/learn/quick-start/introduction) for a brief introduction.

Follow the [Setup guide](https://bevy.org/learn/quick-start/getting-started/setup) to ensure your development environment is set up correctly.
Once set up, you can quickly try out the [examples](https://github.com/bevyengine/bevy/tree/latest/examples) by cloning this repo and running the following commands:

```sh
# Switch to the correct version (latest release, default is main development branch)
git checkout latest
# Runs the &quot;breakout&quot; example
cargo run --example breakout
```

To draw a window with standard functionality enabled, use:

```rust
use bevy::prelude::*;

fn main() {
    App::new()
        .add_plugins(DefaultPlugins)
        .run();
}
```

### Fast Compiles

Bevy can be built just fine using default configuration on stable Rust. However for really fast iterative compiles, you should enable the &quot;fast compiles&quot; setup by [following the instructions here](https://bevy.org/learn/quick-start/getting-started/setup).

## [Bevy Cargo Features][cargo_features]

This [list][cargo_features] outlines the different cargo features supported by Bevy. These allow you to customize the Bevy feature set for your use-case.

[cargo_features]: docs/cargo_features.md

## Thanks

Bevy is the result of the hard work of many people. A huge thanks to all Bevy contributors, the many open source projects that have come before us, the [Rust gamedev ecosystem](https://arewegameyet.rs/), and the many libraries we build on.

A huge thanks to Bevy&#039;s [generous sponsors](https://bevy.org). Bevy will always be free and open source, but it isn&#039;t free to make. Please consider [sponsoring our work](https://bevy.org/donate/) if you like what we&#039;re building.

&lt;!-- This next line need to stay exactly as is. It is required for BrowserStack sponsorship. --&gt;
This project is tested with BrowserStack.

## License

Bevy is free, open source and permissively licensed!
Except where noted (below and/or in individual files), all code in this repository is dual-licensed under either:

* MIT License ([LICENSE-MIT](LICENSE-MIT) or [http://opensource.org/licenses/MIT](http://opensource.org/licenses/MIT))
* Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or [http://www.apache.org/licenses/LICENSE-2.0](http://www.apache.org/licenses/LICENSE-2.0))

at your option.
This means you can select the license you prefer!
This dual-licensing approach is the de-facto standard in the Rust ecosystem and there are [very good reasons](https://github.com/bevyengine/bevy/issues/2373) to include both.

Some of the engine&#039;s code carries additional copyright notices and license terms due to their external origins.
These are generally BSD-like, but exact details vary by crate:
If the README of a crate contains a &#039;License&#039; header (or similar), the additional copyright notices and license terms applicable to that crate will be listed.
The above licensing requirement still applies to contributions to those crates, and sections of those crates will carry those license terms.
The [license](https://doc.rust-lang.org/cargo/reference/manifest.html#the-license-and-license-file-fields) field of each crate will also reflect this.

The [assets](assets) included in this repository (for our [examples](./examples/README.md)) typically fall under different open licenses.
These will not be included in your game (unless copied in by you), and they are not distributed in the published bevy crates.
See [CREDITS.md](CREDITS.md) for the details of the licenses of those files.

### Your contributions

Unless you explicitly state otherwise,
any contribution intentionally submitted for inclusion in the work by you,
as defined in the Apache-2.0 license,
shall be dual licensed as above,
without any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[surrealdb/surrealdb]]></title>
            <link>https://github.com/surrealdb/surrealdb</link>
            <guid>https://github.com/surrealdb/surrealdb</guid>
            <pubDate>Thu, 12 Feb 2026 00:07:08 GMT</pubDate>
            <description><![CDATA[A scalable, distributed, collaborative, document-graph database, for the realtime web]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/surrealdb/surrealdb">surrealdb/surrealdb</a></h1>
            <p>A scalable, distributed, collaborative, document-graph database, for the realtime web</p>
            <p>Language: Rust</p>
            <p>Stars: 31,045</p>
            <p>Forks: 1,124</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://surrealdb.com#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;/img/white/hero.png&quot; alt=&quot;SurrealDB Hero&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://surrealdb.com#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;/img/black/hero.png&quot; alt=&quot;SurrealDB Hero&quot;&gt;
&lt;/a&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/surrealdb/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/surrealdb/surrealdb?color=ff00a0&amp;include_prereleases&amp;label=version&amp;sort=semver&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/surrealdb/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/built_with-Rust-dca282.svg?style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
	&lt;a href=&quot;https://github.com/surrealdb/surrealdb/actions&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/surrealdb/surrealdb/ci.yml?style=flat-square&amp;branch=main&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://github.com/surrealdb/license&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-BSL_1.1-00bfff.svg?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://hub.docker.com/repository/docker/surrealdb/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/docker/pulls/surrealdb/surrealdb?label=docker%20pulls&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://crates.io/crates/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/d/surrealdb?color=dca282&amp;label=rust&amp;style=flat-square&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://www.npmjs.com/package/surrealdb.js&quot;&gt;&lt;img src=&quot;https://img.shields.io/npm/dt/surrealdb.js?color=f7df1e&amp;label=javascript&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
	&lt;a href=&quot;https://pypi.org/project/surrealdb/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pepy/dt/surrealdb?color=426c99&amp;label=python&amp;style=flat-square&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
	&lt;a href=&quot;https://www.nuget.org/packages/SurrealDb.Net&quot;&gt;&lt;img src=&quot;https://img.shields.io/nuget/dt/surrealdb.net?color=4c2dcc&amp;label=.NET&amp;style=flat-square&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
	&lt;a href=&quot;https://packagist.org/packages/surrealdb/surrealdb.php&quot;&gt;&lt;img src=&quot;https://img.shields.io/packagist/dt/surrealdb/surrealdb.php?color=4d588b&amp;label=php&amp;style=flat-square&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
	&lt;a href=&quot;https://hub.docker.com/repository/docker/surrealdb/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/surrealdb/surrealdb/total?color=8259dd&amp;label=github%20downloads&amp;style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://surrealdb.com/discord&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/902568124350599239?label=discord&amp;style=flat-square&amp;color=5a66f6&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://x.com/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/x-follow_us-222222.svg?style=flat-square&quot; alt=&quot;X&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://dev.to/surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/dev-join_us-86f7b7.svg?style=flat-square&quot; alt=&quot;Dev&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/surrealdb/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/linkedin-connect_with_us-0a66c2.svg?style=flat-square&quot; alt=&quot;LinkedIn&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://www.youtube.com/@surrealdb&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/youtube-subscribe-fc1c1c.svg?style=flat-square&quot; alt=&quot;YouTube&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
	&lt;a href=&quot;https://surrealdb.com/blog&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/blog.svg&quot; alt=&quot;Blog&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
	&lt;a href=&quot;https://github.com/surrealdb/surrealdb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/github.svg&quot; alt=&quot;Github&quot;&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://www.linkedin.com/company/surrealdb/&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/linkedin.svg&quot; alt=&quot;LinkedIn&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://x.com/surrealdb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/x.svg&quot; alt=&quot;X&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://www.youtube.com/@surrealdb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/youtube.svg&quot; alt=&quot;YouTube&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://dev.to/surrealdb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/dev.svg&quot; alt=&quot;Dev&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/discord&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/discord.svg&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://stackoverflow.com/questions/tagged/surrealdb&quot;&gt;&lt;img height=&quot;25&quot; src=&quot;./img/social/stack-overflow.svg&quot; alt=&quot;Stack Overflow&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/whatissurreal.svg&quot;&gt;&amp;nbsp;&amp;nbsp;What is SurrealDB?&lt;/h2&gt;

SurrealDB is a multi-model database built in Rust designed to unify multiple data models into a single engine. SurrealDB combines document, graph, relational, time-series, geospatial and key-value data types with powerful search and retrieval functionalities (full-text, vector, hybrid) and real-time and event-driven capabilities, enabling developers to build powerful applications faster and more efficiently. SurrealDB can also be used as a backend-as-a-service given its support for end user authentication. Given that itâ€™s a single Rust binary, SurrealDB can run embedded (inâ€app), in the browser (via WebAssembly), in the edge, self-hosted as single backend node, or in a distributed cluster in the cloud.

SurrealDB is used for data-intensive systems such as applications requiring multiple data types, data layer for AI agents, knowledge graphs, real-time apps (e.g. recommendation engines, fraud detection systems) and embedded/edge systems. With SurrealDB, you can simplify your database and API infrastructure, reduce development time, and build secure, performant apps quickly and cost-effectively.

**Key features of SurrealDB include:**

- **Reduces development time**: SurrealDB simplifies your database and API stack by removing the need for most server-side components, allowing you to build secure, performant apps faster and cheaper.
- **Real-time collaborative API backend service:** SurrealDB functions as both a database and an API backend service, enabling real-time collaboration.
- **Support for multiple querying languages:** SurrealDB supports SQL querying from client devices, GraphQL, ACID transactions, WebSocket connections, structured and unstructured data, graph querying, full-text and vector indexing, and geospatial querying.
- **Granular access control**: SurrealDB provides row-level permissions-based access control, giving you the ability to manage data access with precision.

View the [features](https://surrealdb.com/features), the latest [releases](https://surrealdb.com/releases), and [documentation](https://surrealdb.com/docs).

&lt;img width=&quot;100%&quot; src=&quot;./img/interface.png&quot; alt=&quot;Surrealist&quot;&gt;

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/contents.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Contents&lt;/h2&gt;

- [Features](#features)
- [Documentation](#documentation)
- [Getting started](#getting-started)
	- [Server side code](#server-side-code)
	- [Client side apps](#client-side-apps)
- [SurrealDB Cloud](#surrealdb-cloud)
- [Installation](#installation)
	- [Install on macOS](#install-on-macos)
	- [Install on Linux](#install-on-linux)
	- [Install on Windows](#install-on-windows)
	- [Run using Docker](#run-using-docker)
- [Quick look](#quick-look)
- [Why SurrealDB](#why-surrealdb)
	- [Database, API, and permissions](#database-api-and-permissions)
	- [Tables, documents, and graph](#tables-documents-and-graph)
	- [Advanced inter-document relations](#advanced-inter-document-relations-and-analysis-no-joins-no-pain)
	- [Simple schema definition](#simple-schema-definition-for-frontend-and-backend-development)
	- [Connect directly from web-browsers](#connect-and-query-directly-from-web-browsers-and-client-devices)
	- [Multiple different query methods](#query-the-database-with-the-tools-you-want)
	- [Realtime live queries and data changes](#realtime-live-queries-and-data-changes-direct-to-application)
	- [Scale effortlessly for high-availability](#scale-effortlessly-to-hundreds-of-nodes-for-high-availability-and-scalability)
	- [Extend your database with JavaScript](#extend-your-database-with-javascript-functions)
	- [Designed to be embedded or in the cloud](#designed-to-be-embedded-or-to-run-distributed-in-the-cloud)
- [Community](#community)
- [Contributing](#contributing)
- [Security](#security)
- [License](#license)

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/features.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Features&lt;/h2&gt;

- [x] Database server, or embedded library
- [x] Multi-row, multi-table ACID transactions
- [x] Single-node, or highly-scalable distributed mode
- [x] Record links and directed typed graph connections
- [x] Store structured and unstructured data
- [x] Incrementally computed views for pre-computed advanced analytics
- [x] Realtime-API layer, and security permissions built in
- [x] Store and model data in any way with tables, documents, and graph
- [x] Simple schema definition for frontend and backend development
- [x] Connect and query directly from web-browsers and client devices
- [x] Use embedded JavaScript functions for custom advanced functionality

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/documentation.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Documentation&lt;/h2&gt;

For guidance on installation, development, deployment, and administration, take a look at the following resources:

- Documentation: https://surrealdb.com/docs
- SurrealDB University: https://surrealdb.com/learn
- Aeon&#039;s Surreal Renaissance (interactive book): https://surrealdb.com/learn/book

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/gettingstarted.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Getting started&lt;/h2&gt;

Getting started with SurrealDB is as easy as starting up the SurrealDB database server, choosing your platform, and integrating its SDK into your code. You can easily get started with your platform of choice by reading one of our tutorials.

**Server side code**

&lt;p&gt;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/rust&quot;&gt;&lt;img width=60 title=&quot;Rust&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/rust.svg&quot; /&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/javascript&quot;&gt;&lt;img width=60 title=&quot;JavaScript&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/javascript.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/sdk/javascript/engines/wasm&quot;&gt;&lt;img width=60 title=&quot;WebAssembly&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/webassembly.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/sdk/javascript/engines/node&quot;&gt;&lt;img width=60 title=&quot;Node.js&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/nodejs.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/javascript&quot;&gt;&lt;img width=60 title=&quot;Deno&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/deno.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
	&lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/python&quot;&gt;&lt;img width=60 title=&quot;Python&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/python.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/golang&quot;&gt;&lt;img width=60 title=&quot;Golang&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/golang.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/dotnet&quot;&gt;&lt;img width=60 title=&quot;.NET&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/dotnet.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/php&quot;&gt;&lt;img width=60 title=&quot;PHP&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/php.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/java&quot;&gt;&lt;img width=60 title=&quot;Java&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/java.svg&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

**Client side apps**

&lt;p&gt;
	&lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/javascript&quot;&gt;&lt;img width=60 title=&quot;JavaScript&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/javascript.svg&quot; /&gt;&lt;/a&gt;
    &amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/sdk/javascript/engines/wasm&quot;&gt;&lt;img width=60 title=&quot;WebAssembly&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/webassembly.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/javascript&quot;&gt;&lt;img width=60 title=&quot;React&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/reactjs.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/javascript&quot;&gt;&lt;img width=60 title=&quot;Next.js&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/nextjs.svg&quot; /&gt;&lt;/a&gt;
	&amp;nbsp;
    &lt;a href=&quot;https://surrealdb.com/docs/integration/sdks/ember&quot;&gt;&lt;img width=60 title=&quot;Ember.js&quot; src=&quot;https://raw.githubusercontent.com/surrealdb/icons/main/emberjs.svg&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;/img/cloud.svg?raw=true&quot;&gt;&amp;nbsp;&amp;nbsp;SurrealDB Cloud&lt;/h2&gt;

&lt;a href=&quot;https://surrealdb.com/cloud#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;/img/white/cloud.png&quot; alt=&quot;SurrealDB Cloud&quot;&gt;
&lt;/a&gt;
&lt;a href=&quot;https://surrealdb.com/cloud#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img width=&quot;100%&quot; src=&quot;/img/black/cloud.png&quot; alt=&quot;SurrealDB Cloud&quot;&gt;
&lt;/a&gt;

SurrealDB is available as a [managed cloud service](https://app.surrealdb.com/overview). Forget about infrastructure operations, monitoring, backups or capacity planning. [SurrealDB Cloud](https://surrealdb.com/cloud) allows you to focus on building great products using the power and flexibility of SurrealDB in just a few clicks. Grow from prototype to enterprise-scale. The SurrealDB Cloud scalable architecture allows your database to evolve as your application grows, ensuring you are always ahead of demand. However if you want to deploy SurrealDB yourself, keep reading below.

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/installation.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Installation&lt;/h2&gt;

SurrealDB is designed to be simple to install and simple to run - using just one command from your terminal. In addition to traditional installation, SurrealDB can be installed and run with HomeBrew, Docker, or using any other container orchestration tool such as Docker Compose, Docker Swarm, Rancher, or in Kubernetes.

&lt;h4&gt;&lt;a href=&quot;https://surrealdb.com/install&quot;&gt;&lt;img width=&quot;20&quot; src=&quot;./img/apple.svg&quot;&gt;&lt;/a&gt;&amp;nbsp;Install on macOS&lt;/h4&gt;

The quickest way to get going with SurrealDB on macOS is to use Homebrew. This will install both the command-line tools, and the SurrealDB server as a single executable. If you don&#039;t use Homebrew, follow the instructions for Linux below to install SurrealDB.

```bash
brew install surrealdb/tap/surreal
```

If you want to test a version with the latest features, published every night, install the `nightly` version:

```bash
brew install surrealdb/tap/surreal-nightly
```

&lt;h4&gt;&lt;a href=&quot;https://surrealdb.com/install&quot;&gt;&lt;img width=&quot;20&quot; src=&quot;./img/linux.svg&quot;&gt;&lt;/a&gt;&amp;nbsp;Install on Linux&lt;/h4&gt;

The easiest and preferred way to get going with SurrealDB on Unix operating systems is to install and use the SurrealDB command-line tool. Run the following command in your terminal and follow the on-screen instructions.

```bash
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://install.surrealdb.com | sh
```

If you want to run a beta release, before the next version is released, the `beta` version:

```bash
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://install.surrealdb.com | sh -s -- --beta
```

If you want to test a version with the latest features, published every night, install the `nightly` version:

```bash
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://install.surrealdb.com | sh -s -- --nightly
```

&lt;h4&gt;&lt;a href=&quot;https://surrealdb.com/install&quot;&gt;&lt;img width=&quot;20&quot; src=&quot;./img/windows.svg&quot;&gt;&lt;/a&gt;&amp;nbsp;Install on Windows&lt;/h4&gt;

The easiest and preferred way to get going with SurrealDB on Windows is to install and use the SurrealDB command-line tool. Run the following command in your terminal and follow the on-screen instructions.

```ps1
iwr https://windows.surrealdb.com -useb | iex
```

If you want to test a version with the latest features, published every night, install the `nightly` version:

```ps1
iex &quot;&amp; { $(irm https://windows.surrealdb.com) } -Nightly&quot;
```

&lt;h4&gt;&lt;a href=&quot;https://surrealdb.com/install&quot;&gt;&lt;img width=&quot;20&quot; src=&quot;./img/docker.svg&quot;&gt;&lt;/a&gt;&amp;nbsp;Run using Docker&lt;/h4&gt;

Docker can be used to manage and run SurrealDB database instances without the need to install any command-line tools. The SurrealDB docker container contains the full command-line tools for importing and exporting data from a running server, or for running a server itself.

```bash
docker run --rm --pull always --name surrealdb -p 8000:8000 surrealdb/surrealdb:latest start
```

For just getting started with a development server running in memory, you can pass the container a basic initialization to set the user and password as root and enable logging.

```bash
docker run --rm --pull always --name surrealdb -p 8000:8000 surrealdb/surrealdb:latest start --log info --user root --pass root memory
``` 

&lt;h2&gt;&lt;img height=&quot;20&quot; src=&quot;./img/features.svg&quot;&gt;&amp;nbsp;&amp;nbsp;Quick look&lt;/h2&gt;

With strongly-typed data types, data can be fully modelled right in the database.

```surrealql
UPDATE person SET
    waist = &lt;int&gt; &quot;34&quot;,
    height = &lt;float&gt; 201,
    score = &lt;decimal&gt; 0.3 + 0.3 + 0.3 + 0.1
;
```

Store dynamically computed fields which are calculated when retrieved.

```surrealql
DEFINE FIELD can_drive ON TABLE person COMPUTED time::now() &gt; birthday + 18y;
CREATE person SET birthday = d&quot;2007-06-22&quot;;
;
```

Easily work with unstructured or structured data, in schema-less or schema-full mode.

```surrealql
-- Create a schemafull table
DEFINE TABLE user SCHEMAFULL;

-- Specify fields on the user table
DEFINE FIELD name ON TABLE user TYPE object;
DEFINE FIELD name.first ON TABLE user TYPE string;
DEFINE FIELD name.last ON TABLE user TYPE string;
DEFINE FIELD email ON TABLE user TYPE string ASSERT string::is_email($value);

-- Add a unique index on the email field preventing duplicate values
DEFINE INDEX email ON TABLE user COLUMNS email UNIQUE;

-- Create a new event whenever a user changes their email address
DEFINE EVENT email ON TABLE user WHEN $before.email != $after.email THEN (
    CREATE event SET user = $value, time = time::now(), value = $after.email, action = &#039;email_changed&#039;
);
```

Connect records together with fully directed graph edge connections.

```surrealql
-- Add a graph edge between user:tobie and article:surreal
RELATE user:tobie-&gt;write-&gt;article:surreal
    SET time.written = time::now()
;

-- Add a graph edge between specific users and developers
LET $from = (SELECT users FROM company:surrealdb);
LET $devs = (SELECT * FROM user WHERE tags CONTAINS &#039;developer&#039;);
RELATE $from-&gt;like-&gt;$devs UNIQUE
    SET time.connected = time::now()
;
```

Query data flexibly with advanced expressions and graph queries.

```surrealql
-- Select a nested array, and filter based on an attribute
SELECT emails[WHERE active = true] FROM person;

-- Select all 1st, 2nd, and 3rd level people who this specific person record knows, or likes, as separate outputs
SELECT -&gt;knows-&gt;(? AS f1)-&gt;knows-&gt;(? AS f2)-&gt;(knows, likes AS e3 WHERE influencer = true)-&gt;(? AS f3) FROM person:tobie;

-- Select all person records (and their recipients), who have sent more than 5 emails
SELECT *, -&gt;sent-&gt;email-&gt;to-&gt;person FROM person WHERE count(-&gt;sent-&gt;email) &gt; 5;

-- Select other products purchased by people who purchased this laptop
SELECT &lt;-purchased&lt;-person-&gt;purchased-&gt;product FROM product:laptop;

-- Select products purchased by people in the last 3 weeks who have purchased the same products that we purchased
SELECT -&gt;purchased-&gt;product&lt;-purchased&lt;-person-&gt;(purchased WHERE created_at &gt; time::now() - 3w)-&gt;product FROM person:tobie;
```

Store GeoJSON geographical data types, including points, lines and polygons.

```surrealql
UPDATE city:london SET
    centre = (-0.118092, 51.509865),
    boundary = {
        type: &quot;Polygon&quot;,
        coordinates: [[
            [-0.38314819, 51.37692386], [0.1785278, 51.37692386],
            [0.1785278, 51.61460570], [-0.38314819, 51.61460570],
            [-0.38314819, 51.37692386]
        ]]
    }
;
```

Write custom embedded logic using JavaScript functions.

```surrealql
CREATE film SET
    ratings = [
        { rating: 6, user: user:bt8e39uh1ouhfm8ko8s0 },
        { rating: 8, user: user:bsilfhu88j04rgs0ga70 },
    ],
    featured = function() {
        return this.ratings.filter(r =&gt; {
            return r.rating &gt;= 7;
        }).map(r =&gt; {
            return { ...r, rating: r.rating * 10 };
        });
    }
;
```

Specify granular access 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>