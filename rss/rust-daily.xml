<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Thu, 06 Nov 2025 00:05:31 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[cocoindex-io/cocoindex]]></title>
            <link>https://github.com/cocoindex-io/cocoindex</link>
            <guid>https://github.com/cocoindex-io/cocoindex</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cocoindex-io/cocoindex">cocoindex-io/cocoindex</a></h1>
            <p>Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!</p>
            <p>Language: Rust</p>
            <p>Stars: 3,166</p>
            <p>Forks: 254</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/github.svg&quot; alt=&quot;CocoIndex&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Data transformation for AI&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;

[![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex)
[![Documentation](https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;logoColor=00B9FF)](https://cocoindex.io/docs/getting_started/quickstart)
[![License](https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white)](https://opensource.org/licenses/Apache-2.0)
[![PyPI version](https://img.shields.io/pypi/v/cocoindex?color=5B5BD6)](https://pypi.org/project/cocoindex/)
&lt;!--[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex) --&gt;
[![PyPI Downloads](https://static.pepy.tech/badge/cocoindex/month)](https://pepy.tech/projects/cocoindex)
[![CI](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml)
[![release](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml)
[![Discord](https://img.shields.io/discord/1314801574169673738?logo=discord&amp;color=5B5BD6&amp;logoColor=white)](https://discord.com/invite/zpA9S2DR7s)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/13939&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13939&quot; alt=&quot;cocoindex-io%2Fcocoindex | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box.  Exceptional developer velocity. Production-ready at day 0.

‚≠ê Drop a star to help us grow!

&lt;div align=&quot;center&quot;&gt;

&lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
[Deutsch](https://readme-i18n.com/cocoindex-io/cocoindex?lang=de) |
[English](https://readme-i18n.com/cocoindex-io/cocoindex?lang=en) |
[Espa√±ol](https://readme-i18n.com/cocoindex-io/cocoindex?lang=es) |
[fran√ßais](https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr) |
[Êó•Êú¨Ë™û](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja) |
[ÌïúÍµ≠Ïñ¥](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko) |
[Portugu√™s](https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt) |
[–†—É—Å—Å–∫–∏–π](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru) |
[‰∏≠Êñá](https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh)

&lt;/div&gt;

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/transformation.svg&quot; alt=&quot;CocoIndex Transformation&quot;&gt;
&lt;/p&gt;

&lt;/br&gt;

CocoIndex makes it effortless to transform data with AI, and keep source data and target in sync. Whether you‚Äôre building a vector index for RAG, creating knowledge graphs, or performing any custom data transformations ‚Äî goes beyond SQL.

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;CocoIndex Features&quot; src=&quot;https://cocoindex.io/images/venn2.svg&quot; /&gt;
&lt;/p&gt;

&lt;/br&gt;

## Exceptional velocity

Just declare transformation in dataflow with ~100 lines of python

```python
# import
data[&#039;content&#039;] = flow_builder.add_source(...)

# transform
data[&#039;out&#039;] = data[&#039;content&#039;]
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
```

CocoIndex follows the idea of [Dataflow](https://en.wikipedia.org/wiki/Dataflow_programming) programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.

**Particularly**, developers don&#039;t explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.

## Plug-and-Play Building Blocks

Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components - as easy as assembling building blocks.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/components.svg&quot; alt=&quot;CocoIndex Features&quot;&gt;
&lt;/p&gt;

## Data Freshness

CocoIndex keep source data and target in sync effortlessly.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6&quot; alt=&quot;Incremental Processing&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

It has out-of-box support for incremental indexing:

- minimal recomputation on source or logic change.
- (re-)processing necessary portions; reuse cache when possible

## Quick Start

If you&#039;re new to CocoIndex, we recommend checking out

- üìñ [Documentation](https://cocoindex.io/docs)
- ‚ö°  [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart)
- üé¨ [Quick Start Video Tutorial](https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT)

### Setup

1. Install CocoIndex Python library

```bash
pip install -U cocoindex
```

2. [Install Postgres](https://cocoindex.io/docs/getting_started/installation#-install-postgres) if you don&#039;t have one. CocoIndex uses it for incremental processing.

3. (Optional) Install Claude Code skill for enhanced development experience. Run these commands in [Claude Code](https://claude.com/claude-code):

```
/plugin marketplace add cocoindex-io/cocoindex-claude
/plugin install cocoindex-skills@cocoindex
```

## Define data flow

Follow [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart) to define your first indexing flow. An example flow looks like:

```python
@cocoindex.flow_def(name=&quot;TextEmbedding&quot;)
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope[&quot;documents&quot;] = flow_builder.add_source(cocoindex.sources.LocalFile(path=&quot;markdown_files&quot;))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope[&quot;documents&quot;].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc[&quot;chunks&quot;] = doc[&quot;content&quot;].transform(
            cocoindex.functions.SplitRecursively(),
            language=&quot;markdown&quot;, chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc[&quot;chunks&quot;].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk[&quot;embedding&quot;] = chunk[&quot;text&quot;].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model=&quot;sentence-transformers/all-MiniLM-L6-v2&quot;))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc[&quot;filename&quot;], location=chunk[&quot;location&quot;],
                                   text=chunk[&quot;text&quot;], embedding=chunk[&quot;embedding&quot;])

    # Export collected data to a vector index.
    doc_embeddings.export(
        &quot;doc_embeddings&quot;,
        cocoindex.targets.Postgres(),
        primary_key_fields=[&quot;filename&quot;, &quot;location&quot;],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name=&quot;embedding&quot;,
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
```

It defines an index flow like this:

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;400&quot; alt=&quot;Data Flow&quot; src=&quot;https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463&quot; /&gt;
&lt;/p&gt;

## üöÄ Examples and demo

| Example | Description |
|---------|-------------|
| [Text Embedding](examples/text_embedding) | Index text documents with embeddings for semantic search |
| [Code Embedding](examples/code_embedding) | Index code embeddings for semantic search |
| [PDF Embedding](examples/pdf_embedding) | Parse PDF and index text embeddings for semantic search |
| [PDF Elements Embedding](examples/pdf_elements_embedding) | Extract text and images from PDFs; embed text with SentenceTransformers and images with CLIP; store in Qdrant for multimodal search |
| [Manuals LLM Extraction](examples/manuals_llm_extraction) | Extract structured information from a manual using LLM |
| [Amazon S3 Embedding](examples/amazon_s3_embedding) | Index text documents from Amazon S3 |
| [Azure Blob Storage Embedding](examples/azure_blob_embedding) | Index text documents from Azure Blob Storage |
| [Google Drive Text Embedding](examples/gdrive_text_embedding) | Index text documents from Google Drive |
| [Docs to Knowledge Graph](examples/docs_to_knowledge_graph) | Extract relationships from Markdown documents and build a knowledge graph |
| [Embeddings to Qdrant](examples/text_embedding_qdrant) | Index documents in a Qdrant collection for semantic search |
| [Embeddings to LanceDB](examples/text_embedding_lancedb) | Index documents in a LanceDB collection for semantic search |
| [FastAPI Server with Docker](examples/fastapi_server_docker) | Run the semantic search server in a Dockerized FastAPI setup |
| [Product Recommendation](examples/product_recommendation) | Build real-time product recommendations with LLM and graph database|
| [Image Search with Vision API](examples/image_search) | Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend|
| [Face Recognition](examples/face_recognition) | Recognize faces in images and build embedding index |
| [Paper Metadata](examples/paper_metadata) | Index papers in PDF files, and build metadata tables for each paper |
| [Multi Format Indexing](examples/multi_format_indexing) | Build visual document index from PDFs and images with ColPali for semantic search |
| [Custom Source HackerNews](examples/custom_source_hn) | Index HackerNews threads and comments, using *CocoIndex Custom Source* |
| [Custom Output Files](examples/custom_output_files) | Convert markdown files to HTML files and save them to a local directory, using *CocoIndex Custom Targets* |
| [Patient intake form extraction](examples/patient_intake_extraction) | Use LLM to extract structured data from patient intake forms with different formats |
| [HackerNews Trending Topics](examples/hn_trending_topics) | Extract trending topics from HackerNews threads and comments, using *CocoIndex Custom Source* and LLM |
| [Patient Intake Form Extraction with BAML](examples/patient_intake_extraction_baml) | Extract structured data from patient intake forms using BAML |

More coming and stay tuned üëÄ!

## üìñ Documentation

For detailed documentation, visit [CocoIndex Documentation](https://cocoindex.io/docs), including a [Quickstart guide](https://cocoindex.io/docs/getting_started/quickstart).

## ü§ù Contributing

We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our [contributing guide](https://cocoindex.io/docs/about/contributing).

## üë• Community

Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it&#039;s code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.

Join our community here:

- üåü [Star us on GitHub](https://github.com/cocoindex-io/cocoindex)
- üëã [Join our Discord community](https://discord.com/invite/zpA9S2DR7s)
- ‚ñ∂Ô∏è [Subscribe to our YouTube channel](https://www.youtube.com/@cocoindex-io)
- üìú [Read our blog posts](https://cocoindex.io/blogs/)

## Support us

We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo [![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex) to stay tuned and help us grow.

## License

CocoIndex is Apache 2.0 licensed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vercel/turborepo]]></title>
            <link>https://github.com/vercel/turborepo</link>
            <guid>https://github.com/vercel/turborepo</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[Build system optimized for JavaScript¬†and TypeScript, written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vercel/turborepo">vercel/turborepo</a></h1>
            <p>Build system optimized for JavaScript¬†and TypeScript, written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 29,021</p>
            <p>Forks: 2,125</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://turborepo.com&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://user-images.githubusercontent.com/4060187/196936123-f6e1db90-784d-4174-b774-92502b718836.png&quot;&gt;
      &lt;img src=&quot;https://user-images.githubusercontent.com/4060187/196936104-5797972c-ab10-4834-bd61-0d1e5f442c9c.png&quot; height=&quot;128&quot;&gt;
    &lt;/picture&gt;
    &lt;h1 align=&quot;center&quot;&gt;Turborepo&lt;/h1&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Vercel logo&quot; href=&quot;https://vercel.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&amp;logo=Vercel&amp;labelColor=000&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;NPM version&quot; href=&quot;https://www.npmjs.com/package/turbo&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/npm/v/turbo.svg?style=for-the-badge&amp;labelColor=000000&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;License&quot; href=&quot;https://github.com/vercel/turborepo/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/npm/l/turbo.svg?style=for-the-badge&amp;labelColor=000000&amp;color=&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;Join the community on GitHub&quot; href=&quot;https://github.com/vercel/turborepo/discussions&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&amp;logo=turborepo&amp;labelColor=000000&amp;logoWidth=20&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Turborepo is a high-performance build system for JavaScript and TypeScript codebases, written in Rust.

## Getting Started

Visit https://turborepo.com to get started with Turborepo.

## Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for more information.

## Community

The Turborepo community can be found on [GitHub Discussions](https://github.com/vercel/turborepo/discussions), where you can ask questions, voice ideas, and share your projects.

To chat with other community members, you can join [Vercel Community&#039;s `#turborepo` tag](https://vercel.community/tag/turborepo).

Our [Code of Conduct](https://github.com/vercel/turborepo/blob/main/CODE_OF_CONDUCT.md) applies to all Turborepo community channels.

## Who is using Turborepo?

Turborepo is used by the world&#039;s leading companies. Check out the [Turborepo Showcase](https://turborepo.com/showcase) to learn more.

## Updates

Follow [@turborepo](https://x.com/turborepo) on X for project updates.

## Authors

**Turborepo**

- Jared Palmer ([@jaredpalmer](https://x.com/jaredpalmer))

## Security

If you believe you have found a security vulnerability in Turborepo, we encourage you to responsibly disclose this and not open a public issue. We will investigate all legitimate reports. Email `security@vercel.com` to disclose any security vulnerabilities.

https://vercel.com/security
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[pola-rs/polars]]></title>
            <link>https://github.com/pola-rs/polars</link>
            <guid>https://github.com/pola-rs/polars</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[Extremely fast Query Engine for DataFrames, written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pola-rs/polars">pola-rs/polars</a></h1>
            <p>Extremely fast Query Engine for DataFrames, written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 35,947</p>
            <p>Forks: 2,456</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pola.rs&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/pola-rs/polars-static/master/banner/polars_github_banner.svg&quot; alt=&quot;Polars logo&quot;&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://crates.io/crates/polars&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/polars.svg&quot; alt=&quot;crates.io Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pypi.org/project/polars/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/v/polars.svg&quot; alt=&quot;PyPi Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/nodejs-polars&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/nodejs-polars.svg&quot; alt=&quot;NPM Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://community.r-multiverse.org/polars&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fcommunity.r-multiverse.org%2Fapi%2Fpackages%2Fpolars&amp;query=%24.Version&amp;label=r-multiverse&quot; alt=&quot;R-multiverse Latest Release&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://doi.org/10.5281/zenodo.7697217&quot;&gt;
    &lt;img src=&quot;https://zenodo.org/badge/DOI/10.5281/zenodo.7697217.svg&quot; alt=&quot;DOI Latest Release&quot;/&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Documentation&lt;/b&gt;:
  &lt;a href=&quot;https://docs.pola.rs/api/python/stable/reference/index.html&quot;&gt;Python&lt;/a&gt;
  -
  &lt;a href=&quot;https://docs.rs/polars/latest/polars/&quot;&gt;Rust&lt;/a&gt;
  -
  &lt;a href=&quot;https://pola-rs.github.io/nodejs-polars/index.html&quot;&gt;Node.js&lt;/a&gt;
  -
  &lt;a href=&quot;https://pola-rs.github.io/r-polars/index.html&quot;&gt;R&lt;/a&gt;
  |
  &lt;b&gt;StackOverflow&lt;/b&gt;:
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/python-polars&quot;&gt;Python&lt;/a&gt;
  -
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/rust-polars&quot;&gt;Rust&lt;/a&gt;
  -
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/nodejs-polars&quot;&gt;Node.js&lt;/a&gt;
  -
  &lt;a href=&quot;https://stackoverflow.com/questions/tagged/r-polars&quot;&gt;R&lt;/a&gt;
  |
  &lt;a href=&quot;https://docs.pola.rs/&quot;&gt;User guide&lt;/a&gt;
  |
  &lt;a href=&quot;https://discord.gg/4UfP5cfBE7&quot;&gt;Discord&lt;/a&gt;
&lt;/p&gt;

## Polars: Extremely fast Query Engine for DataFrames, written in Rust

Polars is an analytical query engine written for DataFrames. It is designed to be fast, easy to use
and expressive. Key features are:

- Lazy | Eager execution
- Streaming (larger-than-RAM datasets)
- Query optimization
- Multi-threaded
- Written in Rust
- SIMD
- Powerful expression API
- Front end in Python | Rust | NodeJS | R | SQL
- [Apache Arrow Columnar Format](https://arrow.apache.org/docs/format/Columnar.html)

To learn more, read the [user guide](https://docs.pola.rs/).

## Performance üöÄüöÄ

### Blazingly fast

Polars is very fast. In fact, it is one of the best performing solutions available. See the
[PDS-H benchmarks](https://www.pola.rs/benchmarks.html) results.

### Lightweight

Polars is also very lightweight. It comes with zero required dependencies, and this shows in the
import times:

- polars: 70ms
- numpy: 104ms
- pandas: 520ms

### Handles larger-than-RAM data

If you have data that does not fit into memory, Polars&#039; query engine is able to process your query
(or parts of your query) in a streaming fashion. This drastically reduces memory requirements, so
you might be able to process your 250GB dataset on your laptop. Collect with
`collect(engine=&#039;streaming&#039;)` to run the query streaming.

## Setup

### Python

Install the latest Polars version with:

```sh
pip install polars
```

See the [User Guide](https://docs.pola.rs/user-guide/installation/#feature-flags) for more details
on optional dependencies

To see the current Polars version and a full list of its optional dependencies, run:

```python
pl.show_versions()
```

## Contributing

Want to contribute? Read our [contributing guide](https://docs.pola.rs/development/contributing/).

## Managed/Distributed Polars

Do you want a managed solution or scale out to distributed clusters? Consider our
[offering](https://cloud.pola.rs/) and help the project!

## Python: compile Polars from source

If you want a bleeding edge release or maximal performance you should compile Polars from source.

This can be done by going through the following steps in sequence:

1. Install the latest [Rust compiler](https://www.rust-lang.org/tools/install)
2. Install [maturin](https://maturin.rs/): `pip install maturin`
3. `cd py-polars` and choose one of the following:
   - `make build`, slow binary with debug assertions and symbols, fast compile times
   - `make build-release`, fast binary without debug assertions, minimal debug symbols, long compile
     times
   - `make build-nodebug-release`, same as build-release but without any debug symbols, slightly
     faster to compile
   - `make build-debug-release`, same as build-release but with full debug symbols, slightly slower
     to compile
   - `make build-dist-release`, fastest binary, extreme compile times

By default the binary is compiled with optimizations turned on for a modern CPU. Specify `LTS_CPU=1`
with the command if your CPU is older and does not support e.g. AVX2.

Note that the Rust crate implementing the Python bindings is called `py-polars` to distinguish from
the wrapped Rust crate `polars` itself. However, both the Python package and the Python module are
named `polars`, so you can `pip install polars` and `import polars`.

## Using custom Rust functions in Python

Extending Polars with UDFs compiled in Rust is easy. We expose PyO3 extensions for `DataFrame` and
`Series` data structures. See more in https://github.com/pola-rs/polars/tree/main/pyo3-polars.

## Going big...

Do you expect more than 2^32 (~4.2 billion) rows? Compile Polars with the `bigidx` feature flag or,
for Python users, install `pip install polars[rt64]`.

Don&#039;t use this unless you hit the row boundary as the default build of Polars is faster and consumes
less memory.

## Legacy

Do you want Polars to run on an old CPU (e.g. dating from before 2011), or on an `x86-64` build of
Python on Apple Silicon under Rosetta? Install `pip install polars[rtcompat]`. This version of
Polars is compiled without [AVX](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions) target
features.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[asterinas/asterinas]]></title>
            <link>https://github.com/asterinas/asterinas</link>
            <guid>https://github.com/asterinas/asterinas</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Asterinas is a secure, fast, and general-purpose OS kernel, written in Rust and providing Linux-compatible ABI.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/asterinas/asterinas">asterinas/asterinas</a></h1>
            <p>Asterinas is a secure, fast, and general-purpose OS kernel, written in Rust and providing Linux-compatible ABI.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,786</p>
            <p>Forks: 242</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;book/src/images/logo_en.svg&quot; alt=&quot;asterinas-logo&quot; width=&quot;620&quot;&gt;&lt;br&gt;
    A secure, fast, and general-purpose OS kernel written in Rust and compatible with Linux&lt;br/&gt;
    &lt;a href=&quot;https://github.com/asterinas/asterinas/actions/workflows/test_x86.yml&quot;&gt;&lt;img src=&quot;https://github.com/asterinas/asterinas/actions/workflows/test_x86.yml/badge.svg?event=push&quot; alt=&quot;Test x86-64&quot; style=&quot;max-width: 100%;&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/asterinas/asterinas/actions/workflows/test_riscv.yml&quot;&gt;&lt;img src=&quot;https://github.com/asterinas/asterinas/actions/workflows/test_riscv.yml/badge.svg?event=push&quot; alt=&quot;Test riscv64&quot; style=&quot;max-width: 100%;&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/asterinas/asterinas/actions/workflows/test_loongarch.yml&quot;&gt;&lt;img src=&quot;https://github.com/asterinas/asterinas/actions/workflows/test_loongarch.yml/badge.svg?event=push&quot; alt=&quot;Test loongarch64&quot; style=&quot;max-width: 100%;&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/asterinas/asterinas/actions/workflows/test_x86_tdx.yml&quot;&gt;&lt;img src=&quot;https://github.com/asterinas/asterinas/actions/workflows/test_x86_tdx.yml/badge.svg&quot; alt=&quot;Test Intel TDX&quot; style=&quot;max-width: 100%;&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://asterinas.github.io/benchmark/x86-64/&quot;&gt;&lt;img src=&quot;https://github.com/asterinas/asterinas/actions/workflows/benchmark_x86.yml/badge.svg&quot; alt=&quot;Benchmark x86-64&quot; style=&quot;max-width: 100%;&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://asterinas.github.io/benchmark/tdx/&quot;&gt;&lt;img src=&quot;https://github.com/asterinas/asterinas/actions/workflows/benchmark_x86_tdx.yml/badge.svg&quot; alt=&quot;Benchmark Intel TDX&quot; style=&quot;max-width: 100%;&quot;&gt;&lt;/a&gt;
    &lt;br/&gt;
&lt;/p&gt;

English | [‰∏≠ÊñáÁâà](README_CN.md) | [Êó•Êú¨Ë™û](README_JP.md)

**News:**
* 2025-10-17: **ICSE 2026** accepted yet another paper about Asterinas: _RusyFuzz: Unhandled Exception Guided Fuzzing for Rust OS Kernel_.
* 2025-10-14: [*CortenMM: Efficient Memory Management with Strong Correctness Guarantees*](https://dl.acm.org/doi/10.1145/3731569.3764836) received the **Best Paper Award** at **SOSP 2025**.
* 2025-07-23: **SOSP 2025** accepted another Asterinas paper: [*CortenMM: Efficient Memory Management with Strong Correctness Guarantees*](https://dl.acm.org/doi/10.1145/3731569.3764836).
* 2025-06-18: **USENIX _;login:_ magazine** published [*Asterinas: A Rust-Based Framekernel to Reimagine Linux in the 2020s*](https://www.usenix.org/publications/loginonline/asterinas-rust-based-framekernel-reimagine-linux-2020s).
* 2025-04-30: **USENIX ATC 2025** accepted two Asterinas papers:
    1. [*Asterinas: A Linux ABI-Compatible, Rust-Based Framekernel OS with a Small and Sound TCB*](https://www.usenix.org/conference/atc25/presentation/peng-yuke);
    2. [*Converos: Practical Model Checking for Verifying Rust OS Kernel Concurrency*](https://www.usenix.org/conference/atc25/presentation/tang).

Congratulations to the Asterinas communityüéâüéâüéâ

## Introducing Asterinas

Asterinas is a _secure_, _fast_, and _general-purpose_ OS kernel
that provides _Linux-compatible_ ABI.
It can serve as a seamless replacement for Linux
while enhancing _memory safety_ and _developer friendliness_.

* Asterinas prioritizes memory safety
by employing Rust as its sole programming language
and limiting the use of _unsafe Rust_
to a clearly defined and minimal Trusted Computing Base (TCB).
This innovative approach,
known as [the framekernel architecture](https://asterinas.github.io/book/kernel/the-framekernel-architecture.html),
establishes Asterinas as a more secure and dependable kernel option.

* Asterinas surpasses Linux in terms of developer friendliness.
It empowers kernel developers to
(1) utilize the more productive Rust programming language,
(2) leverage a purpose-built toolkit called [OSDK](https://asterinas.github.io/book/osdk/guide/index.html) to streamline their workflows,
and (3) choose between releasing their kernel modules as open source
or keeping them proprietary,
thanks to the flexibility offered by [MPL](#License).

While the journey towards a production-grade OS kernel is challenging,
we are steadfastly progressing towards this goal.
Over the course of 2024,
we significantly enhanced Asterinas&#039;s maturity,
as detailed in [our end-year report](https://asterinas.github.io/2025/01/20/asterinas-in-2024.html).
In 2025, our primary goal is to make Asterinas production-ready on x86-64 virtual machines
and attract real users!

## Getting Started

Get yourself an x86-64 Linux machine with Docker installed.
Follow the three simple steps below to get Asterinas up and running.

1. Download the latest source code.

```bash
git clone https://github.com/asterinas/asterinas
```

2. Run a Docker container as the development environment.

```bash
docker run -it --privileged --network=host --device=/dev/kvm -v $(pwd)/asterinas:/root/asterinas asterinas/asterinas:0.16.1-20250922
```

3. Inside the container, go to the project folder to build and run Asterinas.

```bash
make build
make run
```

If everything goes well, Asterinas is now up and running inside a VM.

## The Book

See [The Asterinas Book](https://asterinas.github.io/book/) to learn more about the project.

## License

Asterinas&#039;s source code and documentation primarily use the
[Mozilla Public License (MPL), Version 2.0](https://github.com/asterinas/asterinas/blob/main/LICENSE-MPL).
Select components are under more permissive licenses,
detailed [here](https://github.com/asterinas/asterinas/blob/main/.licenserc.yaml). For the rationales behind the choice of MPL, see [here](https://asterinas.github.io/book/index.html#licensing).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[openai/codex]]></title>
            <link>https://github.com/openai/codex</link>
            <guid>https://github.com/openai/codex</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Lightweight coding agent that runs in your terminal]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/codex">openai/codex</a></h1>
            <p>Lightweight coding agent that runs in your terminal</p>
            <p>Language: Rust</p>
            <p>Stars: 49,845</p>
            <p>Forks: 6,157</p>
            <p>Stars today: 104 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install --cask codex&lt;/code&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer.
&lt;/br&gt;
&lt;/br&gt;If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href=&quot;https://developers.openai.com/codex/ide&quot;&gt;install in your IDE&lt;/a&gt;
&lt;/br&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href=&quot;https://chatgpt.com/codex&quot;&gt;chatgpt.com/codex&lt;/a&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./.github/codex-cli-splash.png&quot; alt=&quot;Codex CLI splash&quot; width=&quot;80%&quot; /&gt;
  &lt;/p&gt;

---

## Quickstart

### Installing and running Codex CLI

Install globally with your preferred package manager. If you use npm:

```shell
npm install -g @openai/codex
```

Alternatively, if you use Homebrew:

```shell
brew install --cask codex
```

Then simply run `codex` to get started:

```shell
codex
```

If you&#039;re running into upgrade issues with Homebrew, see the [FAQ entry on brew upgrade codex](./docs/faq.md#brew-upgrade-codex-isnt-upgrading-me).

&lt;details&gt;
&lt;summary&gt;You can also go to the &lt;a href=&quot;https://github.com/openai/codex/releases/latest&quot;&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt;

Each GitHub Release contains many executables, but in practice, you likely want one of these:

- macOS
  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`
  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`
- Linux
  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`
  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`

Each archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.

&lt;/details&gt;

### Using Codex with your ChatGPT plan

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./.github/codex-cli-login.png&quot; alt=&quot;Codex CLI login&quot; width=&quot;80%&quot; /&gt;
  &lt;/p&gt;

Run `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what&#039;s included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).

You can also use Codex with an API key, but this requires [additional setup](./docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key). If you previously used an API key for usage-based billing, see the [migration steps](./docs/authentication.md#migrating-from-usage-based-billing-api-key). If you&#039;re having trouble with login, please comment on [this issue](https://github.com/openai/codex/issues/1243).

### Model Context Protocol (MCP)

Codex can access MCP servers. To configure them, refer to the [config docs](./docs/config.md#mcp_servers).

### Configuration

Codex CLI supports a rich set of configuration options, with preferences stored in `~/.codex/config.toml`. For full configuration options, see [Configuration](./docs/config.md).

---

### Docs &amp; FAQ

- [**Getting started**](./docs/getting-started.md)
  - [CLI usage](./docs/getting-started.md#cli-usage)
  - [Slash Commands](./docs/slash_commands.md)
  - [Running with a prompt as input](./docs/getting-started.md#running-with-a-prompt-as-input)
  - [Example prompts](./docs/getting-started.md#example-prompts)
  - [Custom prompts](./docs/prompts.md)
  - [Memory with AGENTS.md](./docs/getting-started.md#memory-with-agentsmd)
- [**Configuration**](./docs/config.md)
  - [Example config](./docs/example-config.md)
- [**Sandbox &amp; approvals**](./docs/sandbox.md)
- [**Authentication**](./docs/authentication.md)
  - [Auth methods](./docs/authentication.md#forcing-a-specific-auth-method-advanced)
  - [Login on a &quot;Headless&quot; machine](./docs/authentication.md#connecting-on-a-headless-machine)
- **Automating Codex**
  - [GitHub Action](https://github.com/openai/codex-action)
  - [TypeScript SDK](./sdk/typescript/README.md)
  - [Non-interactive mode (`codex exec`)](./docs/exec.md)
- [**Advanced**](./docs/advanced.md)
  - [Tracing / verbose logging](./docs/advanced.md#tracing--verbose-logging)
  - [Model Context Protocol (MCP)](./docs/advanced.md#model-context-protocol-mcp)
- [**Zero data retention (ZDR)**](./docs/zdr.md)
- [**Contributing**](./docs/contributing.md)
- [**Install &amp; build**](./docs/install.md)
  - [System Requirements](./docs/install.md#system-requirements)
  - [DotSlash](./docs/install.md#dotslash)
  - [Build from source](./docs/install.md#build-from-source)
- [**FAQ**](./docs/faq.md)
- [**Open source fund**](./docs/open-source-fund.md)

---

## License

This repository is licensed under the [Apache-2.0 License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/rust]]></title>
            <link>https://github.com/rust-lang/rust</link>
            <guid>https://github.com/rust-lang/rust</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[Empowering everyone to build reliable and efficient software.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/rust">rust-lang/rust</a></h1>
            <p>Empowering everyone to build reliable and efficient software.</p>
            <p>Language: Rust</p>
            <p>Stars: 107,658</p>
            <p>Forks: 13,941</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-dark.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-light.svg&quot;&gt;
    &lt;img alt=&quot;The Rust Programming Language: A language empowering everyone to build reliable and efficient software&quot;
         src=&quot;https://raw.githubusercontent.com/rust-lang/www.rust-lang.org/master/static/images/rust-social-wide-light.svg&quot;
         width=&quot;50%&quot;&gt;
  &lt;/picture&gt;

[Website][Rust] | [Getting started] | [Learn] | [Documentation] | [Contributing]
&lt;/div&gt;

This is the main source code repository for [Rust]. It contains the compiler,
standard library, and documentation.

[Rust]: https://www.rust-lang.org/
[Getting Started]: https://www.rust-lang.org/learn/get-started
[Learn]: https://www.rust-lang.org/learn
[Documentation]: https://www.rust-lang.org/learn#learn-use
[Contributing]: CONTRIBUTING.md

## Why Rust?

- **Performance:** Fast and memory-efficient, suitable for critical services, embedded devices, and easily integrated with other languages.

- **Reliability:** Our rich type system and ownership model ensure memory and thread safety, reducing bugs at compile-time.

- **Productivity:** Comprehensive documentation, a compiler committed to providing great diagnostics, and advanced tooling including package manager and build tool ([Cargo]), auto-formatter ([rustfmt]), linter ([Clippy]) and editor support ([rust-analyzer]).

[Cargo]: https://github.com/rust-lang/cargo
[rustfmt]: https://github.com/rust-lang/rustfmt
[Clippy]: https://github.com/rust-lang/rust-clippy
[rust-analyzer]: https://github.com/rust-lang/rust-analyzer

## Quick Start

Read [&quot;Installation&quot;] from [The Book].

[&quot;Installation&quot;]: https://doc.rust-lang.org/book/ch01-01-installation.html
[The Book]: https://doc.rust-lang.org/book/index.html

## Installing from Source

If you really want to install from source (though this is not recommended), see
[INSTALL.md](INSTALL.md).

## Getting Help

See https://www.rust-lang.org/community for a list of chat platforms and forums.

## Contributing

See [CONTRIBUTING.md](CONTRIBUTING.md).

## License

Rust is primarily distributed under the terms of both the MIT license and the
Apache License (Version 2.0), with portions covered by various BSD-like
licenses.

See [LICENSE-APACHE](LICENSE-APACHE), [LICENSE-MIT](LICENSE-MIT), and
[COPYRIGHT](COPYRIGHT) for details.

## Trademark

[The Rust Foundation][rust-foundation] owns and protects the Rust and Cargo
trademarks and logos (the &quot;Rust Trademarks&quot;).

If you want to use these names or brands, please read the
[Rust language trademark policy][trademark-policy].

Third-party logos may be subject to third-party copyrights and trademarks. See
[Licenses][policies-licenses] for details.

[rust-foundation]: https://rustfoundation.org/
[trademark-policy]: https://rustfoundation.org/policy/rust-trademark-policy/
[policies-licenses]: https://www.rust-lang.org/policies/licenses
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rustdesk/rustdesk]]></title>
            <link>https://github.com/rustdesk/rustdesk</link>
            <guid>https://github.com/rustdesk/rustdesk</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustdesk/rustdesk">rustdesk/rustdesk</a></h1>
            <p>An open-source remote desktop application designed for self-hosting, as an alternative to TeamViewer.</p>
            <p>Language: Rust</p>
            <p>Stars: 101,949</p>
            <p>Forks: 14,942</p>
            <p>Stars today: 60 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;res/logo-header.svg&quot; alt=&quot;RustDesk - Your remote desktop&quot;&gt;&lt;br&gt;
  &lt;a href=&quot;#raw-steps-to-build&quot;&gt;Build&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#how-to-build-with-docker&quot;&gt;Docker&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#file-structure&quot;&gt;Structure&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;#snapshot&quot;&gt;Snapshot&lt;/a&gt;&lt;br&gt;
  [&lt;a href=&quot;docs/README-UA.md&quot;&gt;–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞&lt;/a&gt;] | [&lt;a href=&quot;docs/README-CS.md&quot;&gt;ƒçesky&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ZH.md&quot;&gt;‰∏≠Êñá&lt;/a&gt;] | [&lt;a href=&quot;docs/README-HU.md&quot;&gt;Magyar&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ES.md&quot;&gt;Espa√±ol&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FA.md&quot;&gt;ŸÅÿßÿ±ÿ≥€å&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FR.md&quot;&gt;Fran√ßais&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DE.md&quot;&gt;Deutsch&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PL.md&quot;&gt;Polski&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ID.md&quot;&gt;Indonesian&lt;/a&gt;] | [&lt;a href=&quot;docs/README-FI.md&quot;&gt;Suomi&lt;/a&gt;] | [&lt;a href=&quot;docs/README-ML.md&quot;&gt;‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç&lt;/a&gt;] | [&lt;a href=&quot;docs/README-JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NL.md&quot;&gt;Nederlands&lt;/a&gt;] | [&lt;a href=&quot;docs/README-IT.md&quot;&gt;Italiano&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;] | [&lt;a href=&quot;docs/README-PTBR.md&quot;&gt;Portugu√™s (Brasil)&lt;/a&gt;] | [&lt;a href=&quot;docs/README-EO.md&quot;&gt;Esperanto&lt;/a&gt;] | [&lt;a href=&quot;docs/README-KR.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;] | [&lt;a href=&quot;docs/README-AR.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®Ÿä&lt;/a&gt;] | [&lt;a href=&quot;docs/README-VN.md&quot;&gt;Ti·∫øng Vi·ªát&lt;/a&gt;] | [&lt;a href=&quot;docs/README-DA.md&quot;&gt;Dansk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-GR.md&quot;&gt;ŒïŒªŒªŒ∑ŒΩŒπŒ∫Œ¨&lt;/a&gt;] | [&lt;a href=&quot;docs/README-TR.md&quot;&gt;T√ºrk√ße&lt;/a&gt;] | [&lt;a href=&quot;docs/README-NO.md&quot;&gt;Norsk&lt;/a&gt;] | [&lt;a href=&quot;docs/README-RO.md&quot;&gt;Rom√¢nƒÉ&lt;/a&gt;]&lt;br&gt;
  &lt;b&gt;We need your help to translate this README, &lt;a href=&quot;https://github.com/rustdesk/rustdesk/tree/master/src/lang&quot;&gt;RustDesk UI&lt;/a&gt; and &lt;a href=&quot;https://github.com/rustdesk/doc.rustdesk.com&quot;&gt;RustDesk Doc&lt;/a&gt; to your native language&lt;/b&gt;
&lt;/p&gt;

&gt; [!Caution]
&gt; **Misuse Disclaimer:** &lt;br&gt;
&gt; The developers of RustDesk do not condone or support any unethical or illegal use of this software. Misuse, such as unauthorized access, control or invasion of privacy, is strictly against our guidelines. The authors are not responsible for any misuse of the application.


Chat with us: [Discord](https://discord.gg/nDceKgxnkV) | [Twitter](https://twitter.com/rustdesk) | [Reddit](https://www.reddit.com/r/rustdesk) | [YouTube](https://www.youtube.com/@rustdesk)

[![RustDesk Server Pro](https://img.shields.io/badge/RustDesk%20Server%20Pro-Advanced%20Features-blue)](https://rustdesk.com/pricing.html)

Yet another remote desktop solution, written in Rust. Works out of the box with no configuration required. You have full control of your data, with no concerns about security. You can use our rendezvous/relay server, [set up your own](https://rustdesk.com/server), or [write your own rendezvous/relay server](https://github.com/rustdesk/rustdesk-server-demo).

![image](https://user-images.githubusercontent.com/71636191/171661982-430285f0-2e12-4b1d-9957-4a58e375304d.png)

RustDesk welcomes contribution from everyone. See [CONTRIBUTING.md](docs/CONTRIBUTING.md) for help getting started.

[**FAQ**](https://github.com/rustdesk/rustdesk/wiki/FAQ)

[**BINARY DOWNLOAD**](https://github.com/rustdesk/rustdesk/releases)

[**NIGHTLY BUILD**](https://github.com/rustdesk/rustdesk/releases/tag/nightly)

[&lt;img src=&quot;https://f-droid.org/badge/get-it-on.png&quot;
    alt=&quot;Get it on F-Droid&quot;
    height=&quot;80&quot;&gt;](https://f-droid.org/en/packages/com.carriez.flutter_hbb)
[&lt;img src=&quot;https://flathub.org/api/badge?svg&amp;locale=en&quot;
    alt=&quot;Get it on Flathub&quot;
    height=&quot;80&quot;&gt;](https://flathub.org/apps/com.rustdesk.RustDesk)

## Dependencies

Desktop versions use Flutter or Sciter (deprecated) for GUI, this tutorial is for Sciter only, since it is easier and more friendly to start. Check out our [CI](https://github.com/rustdesk/rustdesk/blob/master/.github/workflows/flutter-build.yml) for building Flutter version.

Please download Sciter dynamic library yourself.

[Windows](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.win/x64/sciter.dll) |
[Linux](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so) |
[macOS](https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.osx/libsciter.dylib)

## Raw Steps to build

- Prepare your Rust development env and C++ build env

- Install [vcpkg](https://github.com/microsoft/vcpkg), and set `VCPKG_ROOT` env variable correctly

  - Windows: vcpkg install libvpx:x64-windows-static libyuv:x64-windows-static opus:x64-windows-static aom:x64-windows-static
  - Linux/macOS: vcpkg install libvpx libyuv opus aom

- run `cargo run`

## [Build](https://rustdesk.com/docs/en/dev/build/)

## How to Build on Linux

### Ubuntu 18 (Debian 10)

```sh
sudo apt install -y zip g++ gcc git curl wget nasm yasm libgtk-3-dev clang libxcb-randr0-dev libxdo-dev \
        libxfixes-dev libxcb-shape0-dev libxcb-xfixes0-dev libasound2-dev libpulse-dev cmake make \
        libclang-dev ninja-build libgstreamer1.0-dev libgstreamer-plugins-base1.0-dev libpam0g-dev
```

### openSUSE Tumbleweed

```sh
sudo zypper install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libXfixes-devel cmake alsa-lib-devel gstreamer-devel gstreamer-plugins-base-devel xdotool-devel pam-devel
```

### Fedora 28 (CentOS 8)

```sh
sudo yum -y install gcc-c++ git curl wget nasm yasm gcc gtk3-devel clang libxcb-devel libxdo-devel libXfixes-devel pulseaudio-libs-devel cmake alsa-lib-devel gstreamer1-devel gstreamer1-plugins-base-devel pam-devel
```

### Arch (Manjaro)

```sh
sudo pacman -Syu --needed unzip git cmake gcc curl wget yasm nasm zip make pkg-config clang gtk3 xdotool libxcb libxfixes alsa-lib pipewire
```

### Install vcpkg

```sh
git clone https://github.com/microsoft/vcpkg
cd vcpkg
git checkout 2023.04.15
cd ..
vcpkg/bootstrap-vcpkg.sh
export VCPKG_ROOT=$HOME/vcpkg
vcpkg/vcpkg install libvpx libyuv opus aom
```

### Fix libvpx (For Fedora)

```sh
cd vcpkg/buildtrees/libvpx/src
cd *
./configure
sed -i &#039;s/CFLAGS+=-I/CFLAGS+=-fPIC -I/g&#039; Makefile
sed -i &#039;s/CXXFLAGS+=-I/CXXFLAGS+=-fPIC -I/g&#039; Makefile
make
cp libvpx.a $HOME/vcpkg/installed/x64-linux/lib/
cd
```

### Build

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
git clone --recurse-submodules https://github.com/rustdesk/rustdesk
cd rustdesk
mkdir -p target/debug
wget https://raw.githubusercontent.com/c-smile/sciter-sdk/master/bin.lnx/x64/libsciter-gtk.so
mv libsciter-gtk.so target/debug
VCPKG_ROOT=$HOME/vcpkg cargo run
```

## How to build with Docker

Begin by cloning the repository and building the Docker container:

```sh
git clone https://github.com/rustdesk/rustdesk
cd rustdesk
git submodule update --init --recursive
docker build -t &quot;rustdesk-builder&quot; .
```

Then, each time you need to build the application, run the following command:

```sh
docker run --rm -it -v $PWD:/home/user/rustdesk -v rustdesk-git-cache:/home/user/.cargo/git -v rustdesk-registry-cache:/home/user/.cargo/registry -e PUID=&quot;$(id -u)&quot; -e PGID=&quot;$(id -g)&quot; rustdesk-builder
```

Note that the first build may take longer before dependencies are cached, subsequent builds will be faster. Additionally, if you need to specify different arguments to the build command, you may do so at the end of the command in the `&lt;OPTIONAL-ARGS&gt;` position. For instance, if you wanted to build an optimized release version, you would run the command above followed by `--release`. The resulting executable will be available in the target folder on your system, and can be run with:

```sh
target/debug/rustdesk
```

Or, if you&#039;re running a release executable:

```sh
target/release/rustdesk
```

Please ensure that you run these commands from the root of the RustDesk repository, or the application may not find the required resources. Also note that other cargo subcommands such as `install` or `run` are not currently supported via this method as they would install or run the program inside the container instead of the host.

## File Structure

- **[libs/hbb_common](https://github.com/rustdesk/rustdesk/tree/master/libs/hbb_common)**: video codec, config, tcp/udp wrapper, protobuf, fs functions for file transfer, and some other utility functions
- **[libs/scrap](https://github.com/rustdesk/rustdesk/tree/master/libs/scrap)**: screen capture
- **[libs/enigo](https://github.com/rustdesk/rustdesk/tree/master/libs/enigo)**: platform specific keyboard/mouse control
- **[libs/clipboard](https://github.com/rustdesk/rustdesk/tree/master/libs/clipboard)**: file copy and paste implementation for Windows, Linux, macOS.
- **[src/ui](https://github.com/rustdesk/rustdesk/tree/master/src/ui)**: obsolete Sciter UI (deprecated)
- **[src/server](https://github.com/rustdesk/rustdesk/tree/master/src/server)**: audio/clipboard/input/video services, and network connections
- **[src/client.rs](https://github.com/rustdesk/rustdesk/tree/master/src/client.rs)**: start a peer connection
- **[src/rendezvous_mediator.rs](https://github.com/rustdesk/rustdesk/tree/master/src/rendezvous_mediator.rs)**: Communicate with [rustdesk-server](https://github.com/rustdesk/rustdesk-server), wait for remote direct (TCP hole punching) or relayed connection
- **[src/platform](https://github.com/rustdesk/rustdesk/tree/master/src/platform)**: platform specific code
- **[flutter](https://github.com/rustdesk/rustdesk/tree/master/flutter)**: Flutter code for desktop and mobile
- **[flutter/web/js](https://github.com/rustdesk/rustdesk/tree/master/flutter/web/v1/js)**: JavaScript for Flutter web client

## Screenshots

![Connection Manager](https://github.com/rustdesk/rustdesk/assets/28412477/db82d4e7-c4bc-4823-8e6f-6af7eadf7651)

![Connected to a Windows PC](https://github.com/rustdesk/rustdesk/assets/28412477/9baa91e9-3362-4d06-aa1a-7518edcbd7ea)

![File Transfer](https://github.com/rustdesk/rustdesk/assets/28412477/39511ad3-aa9a-4f8c-8947-1cce286a46ad)

![TCP Tunneling](https://github.com/rustdesk/rustdesk/assets/28412477/78e8708f-e87e-4570-8373-1360033ea6c5)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tracel-ai/burn]]></title>
            <link>https://github.com/tracel-ai/burn</link>
            <guid>https://github.com/tracel-ai/burn</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[Burn is a next generation tensor library and Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tracel-ai/burn">tracel-ai/burn</a></h1>
            <p>Burn is a next generation tensor library and Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.</p>
            <p>Language: Rust</p>
            <p>Stars: 13,334</p>
            <p>Forks: 731</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp&quot; width=&quot;350px&quot;/&gt;

[![Discord](https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;&amp;logo=discord)](https://discord.gg/uPEBbYYDB6)
[![Current Crates.io Version](https://img.shields.io/crates/v/burn.svg)](https://crates.io/crates/burn)
[![Minimum Supported Rust Version](https://img.shields.io/crates/msrv/burn)](https://crates.io/crates/burn)
[![Documentation](https://img.shields.io/badge/docs-latest-blue)](https://burn.dev/docs/burn)
[![Test Status](https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg)](https://github.com/tracel-ai/burn/actions/workflows/test.yml)
[![license](https://shields.io/badge/license-MIT%2FApache--2.0-blue)](#license)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/tracel-ai/burn)

[&lt;img src=&quot;https://www.runblaze.dev/ci-blaze-powered.png&quot; width=&quot;125px&quot;/&gt;](https://www.runblaze.dev)

---

**Burn is a next generation Tensor Library and Deep Learning Framework that doesn&#039;t compromise on
&lt;br /&gt; flexibility, efficiency and portability.**

&lt;br/&gt;
&lt;/div&gt;

&lt;div align=&quot;left&quot;&gt;

Burn is both a tensor library and a deep learning framework optimized for numerical computing, model
inference and model training. Burn leverages Rust to perform optimizations normally only available
in static-graph frameworks, offering optimal speed without impacting flexibility.

## Backend

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png&quot; height=&quot;96px&quot;/&gt;

Burn strives to be as fast as possible on as many hardwares as possible, with robust
implementations. We believe this flexibility is crucial for modern needs where you may train your
models in the cloud, then deploy on customer hardwares, which vary from user to user.

&lt;/div&gt;

### Supported Backends

Most backends support all operating systems, so we don&#039;t mention them in the tables below.

**GPU Backends:**

|         | CUDA | ROCm | Metal | Vulkan | WebGPU | Candle | LibTorch |
| ------- | ---- | ---- | ----- | ------ | ------ | ------ | -------- |
| Nvidia  | ‚òëÔ∏è   | -    | -     | ‚òëÔ∏è     | ‚òëÔ∏è     | ‚òëÔ∏è     | ‚òëÔ∏è       |
| AMD     | -    | ‚òëÔ∏è   | -     | ‚òëÔ∏è     | ‚òëÔ∏è     | -      | ‚òëÔ∏è       |
| Apple   | -    | -    | ‚òëÔ∏è    | -      | ‚òëÔ∏è     | -      | ‚òëÔ∏è       |
| Intel   | -    | -    | -     | ‚òëÔ∏è     | ‚òëÔ∏è     | -      | -        |
| Qualcom | -    | -    | -     | ‚òëÔ∏è     | ‚òëÔ∏è     | -      | -        |
| Wasm    | -    | -    | -     | -      | ‚òëÔ∏è     | -      | -        |

**CPU Backends:**

|        | Cpu (CubeCL) | NdArray | Candle | LibTorch |
| ------ | ------------ | ------- | ------ | -------- |
| X86    | ‚òëÔ∏è           | ‚òëÔ∏è      | ‚òëÔ∏è     | ‚òëÔ∏è       |
| Arm    | ‚òëÔ∏è           | ‚òëÔ∏è      | ‚òëÔ∏è     | ‚òëÔ∏è       |
| Wasm   | -            | ‚òëÔ∏è      | ‚òëÔ∏è     | -        |
| no-std | -            | ‚òëÔ∏è      | -      | -        |

&lt;br /&gt;

Compared to other frameworks, Burn has a very different approach to supporting many backends. By
design, most code is generic over the Backend trait, which allows us to build Burn with swappable
backends. This makes composing backend possible, augmenting them with additional functionalities
such as autodifferentiation and automatic kernel fusion.

&lt;details&gt;
&lt;summary&gt;
Autodiff: Backend decorator that brings backpropagation to any backend üîÑ
&lt;/summary&gt;
&lt;br /&gt;

Contrary to the aforementioned backends, Autodiff is actually a backend _decorator_. This means that
it cannot exist by itself; it must encapsulate another backend.

The simple act of wrapping a base backend with Autodiff transparently equips it with
autodifferentiation support, making it possible to call backward on your model.

```rust
use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&lt;Wgpu&gt;;

    let device = Default::default();

    let x: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default, &amp;device);
    let y: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default, &amp;device).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;grads).unwrap();
    println!(&quot;{y_grad}&quot;);
}
```

Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend
that does not support autodiff (for inference), as this method is only offered by an Autodiff
backend.

See the [Autodiff Backend README](./crates/burn-autodiff/README.md) for more details.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Fusion: Backend decorator that brings kernel fusion to all first-party backends
&lt;/summary&gt;
&lt;br /&gt;

This backend decorator enhances a backend with kernel fusion, provided that the inner backend
supports it. Note that you can compose this backend with other backend decorators such as Autodiff.
All first-party accelerated backends (like WGPU and CUDA) use Fusion by default (`burn/fusion`
feature flag), so you typically don&#039;t need to apply it manually.

```rust
#[cfg(not(feature = &quot;fusion&quot;))]
pub type Cuda&lt;F = f32, I = i32&gt; = CubeBackend&lt;CudaRuntime, F, I, u8&gt;;

#[cfg(feature = &quot;fusion&quot;)]
pub type Cuda&lt;F = f32, I = i32&gt; = burn_fusion::Fusion&lt;CubeBackend&lt;CudaRuntime, F, I, u8&gt;&gt;;
```

Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory
bound operations, which will work gracefully with the fusion backend to make your code run even
faster during training, see [this issue](https://github.com/tracel-ai/burn/issues/936).

See the [Fusion Backend README](./crates/burn-fusion/README.md) for more details.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Router (Beta): Backend decorator that composes multiple backends into a single one
&lt;/summary&gt;
&lt;br /&gt;

That backend simplifies hardware operability, if for instance you want to execute some operations on
the CPU and other operations on the GPU.

```rust
use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&lt;(Wgpu, NdArray)&gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;device_0);
    let tensor_cpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;device_1);
}

```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations
&lt;/summary&gt;
&lt;br /&gt;

That backend has two parts, one client and one server. The client sends tensor operations over the
network to a remote compute backend. You can use any first-party backend as server in a single line
of code:

```rust
fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&lt;burn::backend::Cuda&gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&lt;RemoteDevice&gt;;

    let device = RemoteDevice::new(&quot;ws://localhost:3000&quot;);
    let tensor_gpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], Distribution::Default, &amp;device);
}

```

&lt;/details&gt;

&lt;br /&gt;

## Training &amp; Inference

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png&quot; height=&quot;96px&quot;/&gt;

The whole deep learning workflow is made easy with Burn, as you can monitor your training progress
with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU
clusters.

Burn was built from the ground up with training and inference in mind. It&#039;s also worth noting how
Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to
deployment, eliminating the need for code changes.

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;br /&gt;

&lt;a href=&quot;https://www.youtube.com/watch?v=N9RM5CQbNQc&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png&quot; alt=&quot;Burn Train TUI&quot; width=&quot;75%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;br /&gt;

**Click on the following sections to expand üëá**

&lt;details&gt;
&lt;summary&gt;
Training Dashboard üìà
&lt;/summary&gt;
&lt;br /&gt;

As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on
the [Ratatui](https://github.com/ratatui-org/ratatui) crate allows users to follow their training
with ease without having to connect to any external application.

You can visualize your training and validation metrics updating in real-time and analyze the
lifelong progression or recent history of any registered metrics using only the arrow keys. Break
from the training loop without crashing, allowing potential checkpoints to be fully written or
important pieces of code to complete without interruption üõ°

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
ONNX Support üê´
&lt;/summary&gt;
&lt;br /&gt;

Burn supports importing ONNX (Open Neural Network Exchange) models, allowing you to easily port
models from TensorFlow or PyTorch to Burn. The ONNX model is converted into Rust code that uses
Burn&#039;s native APIs, enabling the imported model to run on any Burn backend (CPU, GPU, WebAssembly)
and benefit from all of Burn&#039;s optimizations like automatic kernel fusion.

Our ONNX support is further described in
[this section of the Burn Book üî•](https://burn.dev/books/burn/import/onnx-model.html).

&gt; **Note**: This crate is in active development and currently supports a
&gt; [limited set of ONNX operators](./crates/burn-import/SUPPORTED-ONNX-OPS.md).

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Importing PyTorch or Safetensors Models üöö
&lt;/summary&gt;
&lt;br /&gt;

You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models.
This makes it easy to reuse existing models while benefiting from Burn&#039;s performance and deployment
features.

Learn more:

- [Import pre-trained PyTorch models into Burn](https://burn.dev/books/burn/import/pytorch-model.html)
- [Load models from Safetensors format](https://burn.dev/books/burn/import/safetensors-model.html)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Inference in the Browser üåê
&lt;/summary&gt;
&lt;br /&gt;

Several of our backends can run in WebAssembly environments: Candle and NdArray for CPU execution,
and WGPU for GPU acceleration via WebGPU. This means that you can run inference directly within a
browser. We provide several examples of this:

- [MNIST](./examples/mnist-inference-web) where you can draw digits and a small convnet tries to
  find which one it is! 2Ô∏è‚É£ 7Ô∏è‚É£ üò∞
- [Image Classification](./examples/image-classification-web) where you can upload images and
  classify them! üåÑ

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Embedded: &lt;i&gt;no_std&lt;/i&gt; support ‚öôÔ∏è
&lt;/summary&gt;
&lt;br /&gt;

Burn&#039;s core components support [no_std](https://docs.rust-embedded.org/book/intro/no-std.html). This
means it can run in bare metal environment such as embedded devices without an operating system.

&gt; As of now, only the NdArray backend can be used in a _no_std_ environment.

&lt;/details&gt;

&lt;br /&gt;

### Benchmarks

To evaluate performance across different backends and track improvements over time, we provide a
dedicated benchmarking suite.

Run and compare benchmarks using [burn-bench](https://github.com/tracel-ai/burn-bench).

&gt; ‚ö†Ô∏è **Warning** When using one of the `wgpu` backends, you may encounter compilation errors related
&gt; to recursive type evaluation. This is due to complex type nesting within the `wgpu` dependency
&gt; chain. To resolve this issue, add the following line at the top of your `main.rs` or `lib.rs`
&gt; file:
&gt;
&gt; ```rust
&gt; #![recursion_limit = &quot;256&quot;]
&gt; ```
&gt;
&gt; The default recursion limit (128) is often just below the required depth (typically 130-150) due
&gt; to deeply nested associated types and trait bounds.

## Getting Started

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png&quot; height=&quot;96px&quot;/&gt;

Just heard of Burn? You are at the right place! Just continue reading this section and we hope you
can get on board really quickly.

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;
The Burn Book üî•
&lt;/summary&gt;
&lt;br /&gt;

To begin working effectively with Burn, it is crucial to understand its key components and
philosophy. This is why we highly recommend new users to read the first sections of
[The Burn Book üî•](https://burn.dev/books/burn/). It provides detailed examples and explanations
covering every facet of the framework, including building blocks like tensors, modules, and
optimizers, all the way to advanced usage, like coding your own GPU kernels.

&gt; The project is constantly evolving, and we try as much as possible to keep the book up to date
&gt; with new additions. However, we might miss some details sometimes, so if you see something weird,
&gt; let us know! We also gladly accept Pull Requests üòÑ

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Examples üôè
&lt;/summary&gt;
&lt;br /&gt;

Let&#039;s start with a code snippet that shows how intuitive the framework is to use! In the following,
we declare a neural network module with some parameters along with its forward pass.

```rust
use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&lt;B: Backend&gt; {
    linear_inner: nn::Linear&lt;B&gt;,
    linear_outer: nn::Linear&lt;B&gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&lt;B: Backend&gt; PositionWiseFeedForward&lt;B&gt; {
    pub fn forward&lt;const D: usize&gt;(&amp;self, input: Tensor&lt;B, D&gt;) -&gt; Tensor&lt;B, D&gt; {
        let x = self.linear_inner.forward(input);
        let x = self.gelu.forward(x);
        let x = self.dropout.forward(x);

        self.linear_outer.forward(x)
    }
}
```

We have a somewhat large amount of [examples](./examples) in the repository that shows how to use
the framework in different scenarios.

Following [the book](https://burn.dev/books/burn/):

- [Basic Workflow](./examples/guide) : Creates a custom CNN `Module` to train on the MNIST dataset
  and use for inference.
- [Custom Training Loop](./examples/custom-training-loop) : Implements a basic training loop instead
  of using the `Learner`.
- [Custom WGPU Kernel](./examples/custom-wgpu-kernel) : Learn how to create your own custom
  operation with the WGPU backend.

Additional examples:

- [Custom CSV Dataset](./examples/custom-csv-dataset) : Implements a dataset to parse CSV data for a
  regression task.
- [Regression](./examples/simple-regression) : Trains a simple MLP on the California Housing dataset
  to predict the median house value for a district.
- [Custom Image Dataset](./examples/custom-image-dataset) : Trains a simple CNN on custom image
  dataset following a simple folder structure.
- [Custom Renderer](./examples/custom-renderer) : Implements a custom renderer to display the
  [`Learner`](./building-blocks/learner.md) progress.
- [Image Classification Web](./examples/image-classification-web) : Image classification web browser
  demo using Burn, WGPU and WebAssembly.
- [MNIST Inference on Web](./examples/mnist-inference-web) : An interactive MNIST inference demo in
  the browser. The demo is available [online](https://burn.dev/demo/).
- [MNIST Training](./examples/mnist) : Demonstrates how to train a custom `Module` (MLP) with the
  `Learner` configured to log metrics and keep training checkpoints.
- [Named Tensor](./examples/named-tensor) : Performs operations with the experimental `NamedTensor`
  feature.
- [ONNX Import Inference](./examples/onnx-inference) : Imports an ONNX model pre-trained on MNIST to
  perform inference on a sample image with Burn.
- [PyTorch Import Inference](./examples/import-model-weights) : Imports a PyTorch model pre-trained
  on MNIST to perform inference on a sample image with Burn.
- [Text Classification](./examples/text-classification) : Trains a text classification transformer
  model on the AG News or DbPedia dataset. The trained model can then be used to classify a text
  sample.
- [Text Generation](./examples/text-generation) : Trains a text generation transformer model on the
  DbPedia dataset.
- [Wasserstein GAN MNIST](./examples/wgan) : Trains a WGAN model to generate new handwritten digits
  based on MNIST.

For more practical insights, you can clone the repository and run any of them directly on your
computer!

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Pre-trained Models ü§ñ
&lt;/summary&gt;
&lt;br /&gt;

We keep an updated and curated list of models and examples built with Burn, see the
[tracel-ai/models repository](https://github.com/tracel-ai/models) for more details.

Don&#039;t see the model you want? Don&#039;t hesitate to open an issue, and we may prioritize it. Built a
model using Burn and want to share it? You can also open a Pull Request and add your model under the
community section!

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Why use Rust for Deep Learning? ü¶Ä
&lt;/summary&gt;
&lt;br /&gt;

Deep Learning is a special form of software where you need very high level abstractions as well as
extremely fast execution time. Rust is the perfect candidate for that use case since it provides
zero-cost abstractions to easily create neural network modules, and fine-grained control over memory
to optimize every detail.

It&#039;s important that a framework be easy to use at a high level so that its users can focus on
innovating in the AI field. However, since running models relies so heavily on computations,
performance can&#039;t be neglected.

To this day, the mainstream solution to this problem has been to offer APIs in Python, but rely on
bindings to low-level languages such as C/C++. This reduces portability, increases complexity and
creates frictions between researchers and engineers. We feel like Rust&#039;s approach to abstractions
makes it versatile enough to tackle this two languages dichotomy.

Rust also comes with the Cargo package manager, which makes it incredibly easy to build, test, and
deploy from any environment, which is usually a pain in Python.

Although Rust has the reputation of being a difficult language at first, we strongly believe it
leads to more reliable, bug-free solutions built faster (after some practice üòÖ)!

&lt;/details&gt;

&lt;br /&gt;

&gt; **Deprecation Note**&lt;br /&gt;Since `0.14.0`, the internal structure for tensor data has changed. The
&gt; previous `Data` struct was deprecated and officially removed since `0.17.0` in favor of the new
&gt; `TensorData` struct, which allows for more flexibility by storing the underlying data as bytes and
&gt; keeping the data type as a field. If you are using `Data` in your code, make sure to switch to
&gt; `TensorData`.

&lt;!-- &gt;
&gt; In the event that you are trying to load a model record saved in a previous version, make sure to
&gt; enable the `record-backward-compat` feature using a previous version of burn (&lt;=0.16.0). Otherwise,
&gt; the record won&#039;t be deserialized correctly and you will get an error message (which will also point
&gt; you to the backward compatible feature flag). The backward compatibility was maintained for
&gt; deserialization (loading), so as soon as you have saved the record again it will be saved according
&gt; to the new structure and you will be able to upgrade to this version. Please note that binary formats
&gt; are not backward compatible. Thus, you will need to load your record in a previous version and save it
&gt; to another of the self-describing record formats before using a compatible version (as described) with the
&gt; `record-backward-compat` feature flag. --&gt;

&lt;details id=&quot;deprecation&quot;&gt;
&lt;summary&gt;
Loading Model Records From Previous Versions ‚ö†Ô∏è
&lt;/summary&gt;
&lt;br /&gt;

In the event that you are trying to load a model record saved in a version older than `0.14.0`, make
sure to use a compatible version (`0.14`, `0.15` or `0.16`) with the `record-backward-compat`
feature flag.

```
features = [..., &quot;record-backward-compat&quot;]
```

Otherwise, the record won&#039;t be deserialized correctly and you will get an error message. This e

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[qdrant/qdrant]]></title>
            <link>https://github.com/qdrant/qdrant</link>
            <guid>https://github.com/qdrant/qdrant</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qdrant/qdrant">qdrant/qdrant</a></h1>
            <p>Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/</p>
            <p>Language: Rust</p>
            <p>Stars: 26,943</p>
            <p>Forks: 1,882</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>## How to interview using this template

Open ONLY the `shared/` folder within VSCode and in the Extensions Marketplace find `CodeTogether Live`. Install it.

Inside the extension, you&#039;ll have to click on &#039;Host New Session&#039; and then &#039;Start&#039;.

You now have a link in your clipboard, which you should share with the candidate.

Don&#039;t forget to run `npm run vite.dev` inside your editor terminal, since this is not currently possible from the browser editor (link) with the free version of the extension.

The locally running server will display localhost:5173 as well as a the project within the network, which the user can access remotely to see the SPA in action, something like: `10.5.52.144:5173`.

The candidate should be sharing their screen while they read and later approach the challenge!

## React TemplateÔºà‚ö°Ô∏èÔºâ

‚ö°Ô∏è A minimal React Vite starter template.

### Feature

- ‚ö°Ô∏è Fast - Build tools based on vite.
- üëª Small - Based on the smallest runnable build.
- üíÑ Prettier - Integrated Prettier to help you format the code.
- ‚úÖ Safety - Https is enabled by default.
- üòé Reliable - Integrated eslint and commitlint.
- ü§ñ Intelligent - Integrated renovate to help you maintain the dependent version.

### Preview

[![qekup8.png](https://s1.ax1x.com/2022/03/20/qekup8.png)](https://imgtu.com/i/qekup8)

### Getting Started

```bash
npx degit lzm0x219/template-vite-react myapp

cd myapp

git init
```

#### Prerequisites

- `npm` and/or `pnpm` should be installed.
- `git` should be installed (recommended v2.4.11 or higher)

#### Available scripts

##### `npm run vite.dev`

Runs the app in development mode.
Open https://localhost:5173 to view it in the browser.

The page will automatically reload if you make changes to the code.
You will see the build errors and lint warnings in the console.

##### `npm run vite.build`

Builds the app for production to the `dist` folder.
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.

Your app is ready to be deployed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[libp2p/rust-libp2p]]></title>
            <link>https://github.com/libp2p/rust-libp2p</link>
            <guid>https://github.com/libp2p/rust-libp2p</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[The Rust Implementation of the libp2p networking stack.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/libp2p/rust-libp2p">libp2p/rust-libp2p</a></h1>
            <p>The Rust Implementation of the libp2p networking stack.</p>
            <p>Language: Rust</p>
            <p>Stars: 5,258</p>
            <p>Forks: 1,139</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># Central repository for work on libp2p

&lt;a href=&quot;http://libp2p.io/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/project-libp2p-yellow.svg?style=flat-square&quot; /&gt;&lt;/a&gt;
[![dependency status](https://deps.rs/repo/github/libp2p/rust-libp2p/status.svg?style=flat-square)](https://deps.rs/repo/github/libp2p/rust-libp2p)
[![Crates.io](https://img.shields.io/crates/v/libp2p.svg)](https://crates.io/crates/libp2p)
[![docs.rs](https://img.shields.io/badge/api-rustdoc-blue.svg)](https://docs.rs/libp2p)
[![docs.rs master](https://img.shields.io/badge/docs-master-blueviolet)](https://libp2p.github.io/rust-libp2p/libp2p/)

This repository is the central place for Rust development of the [libp2p](https://libp2p.io) spec.

## Getting started

- **Main documentation** can be found on https://docs.rs/libp2p.

- The **[examples](examples)** folder contains small binaries showcasing the
  many protocols in this repository.

- For **security related issues** please [file a private security vulnerability
  report](https://github.com/libp2p/rust-libp2p/security/advisories/new) . Please do not file a
  public issue on GitHub.

- To **report bugs, suggest improvements or request new features** please open a
  GitHub issue on this repository.

- For **rust-libp2p specific questions** please use the GitHub _Discussions_
  forum https://github.com/libp2p/rust-libp2p/discussions.

- For **discussions and questions related to multiple libp2p implementations**
  please use the libp2p _Discourse_ forum https://discuss.libp2p.io.

- For synchronous discussions join the [open rust-libp2p maintainer
  calls](https://github.com/libp2p/rust-libp2p/discussions?discussions_q=open+maintainers+call+)
  or the [biweekly libp2p community calls](https://discuss.libp2p.io/t/libp2p-community-calls/1157).

## Repository Structure

The main components of this repository are structured as follows:

  * `core/`: The implementation of `libp2p-core` with its `Transport` and
    `StreamMuxer` API on which almost all other crates depend.

  * `transports/`: Implementations of transport protocols (e.g. TCP) and protocol upgrades
    (e.g. for authenticated encryption, compression, ...) based on the `libp2p-core` `Transport`
    API.

  * `muxers/`: Implementations of the `StreamMuxer` interface of `libp2p-core`,
    e.g. (sub)stream multiplexing protocols on top of (typically TCP) connections.
    Multiplexing protocols are (mandatory) `Transport` upgrades.

  * `swarm/`: The implementation of `libp2p-swarm` building on `libp2p-core`
    with the central interfaces `NetworkBehaviour` and `ConnectionHandler` used
    to implement application protocols (see `protocols/`).

  * `protocols/`: Implementations of application protocols based on the
    `libp2p-swarm` APIs.

  * `misc/`: Utility libraries.

  * `libp2p/examples/`: Worked examples of built-in application protocols (see `protocols/`)
    with common `Transport` configurations.

## Community Guidelines

The libp2p project operates under the [IPFS Code of
Conduct](https://github.com/ipfs/community/blob/master/code-of-conduct.md).

&gt; tl;dr
&gt;
&gt; - Be respectful.
&gt; - We&#039;re here to help: abuse@ipfs.io
&gt; - Abusive behavior is never tolerated.
&gt; - Violations of this code may result in swift and permanent expulsion from the
&gt;   IPFS [and libp2p] community.
&gt; - &quot;Too long, didn&#039;t read&quot; is not a valid excuse for not knowing what is in
&gt;   this document.

## Maintainers

(In alphabetical order.)

- Jo√£o Oliveira ([@jxs](https://github.com/jxs))

## Notable users

(open a pull request if you want your project to be added here)

- [COMIT](https://github.com/comit-network/xmr-btc-swap) - Bitcoin‚ÄìMonero Cross-chain Atomic Swap.
- [Forest](https://github.com/ChainSafe/forest) - An implementation of Filecoin written in Rust.
- [fuel-core](https://github.com/FuelLabs/fuel-core) - A Rust implementation of the Fuel protocol.
- [HotShot](https://github.com/EspressoSystems/HotShot) - Decentralized sequencer in Rust developed by [Espresso Systems](https://www.espressosys.com/).
- [ipfs-embed](https://github.com/ipfs-rust/ipfs-embed) - A small embeddable ipfs implementation used and maintained by [Actyx](https://www.actyx.com).
- [Homestar](https://github.com/ipvm-wg/homestar) - An InterPlanetary Virtual Machine (IPVM) implementation used and maintained by Fission.
- [beetle](https://github.com/n0-computer/beetle) - Next-generation implementation of IPFS for Cloud &amp; Mobile platforms.
- [Lighthouse](https://github.com/sigp/lighthouse) - Ethereum consensus client in Rust.
- [Locutus](https://github.com/freenet/locutus) - Global, observable, decentralized key-value store.
- [OpenMina](https://github.com/openmina/openmina) - In-browser Mina Rust implementation.
- [qaul ŸÇŸàŸÑ](https://github.com/qaul/qaul.net) - Internet Independent Wireless Mesh Communication App
- [rust-ipfs](https://github.com/rs-ipfs/rust-ipfs) - IPFS implementation in Rust.
- [Safe Network](https://github.com/maidsafe/safe_network) - Safe Network implementation in Rust.
- [SQD Network](https://github.com/subsquid/sqd-network) - A decentralized storage for Web3 data.
- [Starcoin](https://github.com/starcoinorg/starcoin) - A smart contract blockchain network that scales by layering.
- [Subspace](https://github.com/subspace/subspace) - Subspace Network reference implementation
- [Substrate](https://github.com/paritytech/substrate) - Framework for blockchain innovation,
used by [Polkadot](https://www.parity.io/technologies/polkadot/).
- [Swarm NL](https://github.com/algorealmInc/SwarmNL) - A library that makes it easy to configure the networking requirements for any distributed application.
- [Taple](https://github.com/opencanarias/taple-core) - Sustainable DLT for asset and process traceability by [OpenCanarias](https://www.opencanarias.com/en/).
- [Ceylon](https://github.com/ceylonai/ceylon) - A Multi-Agent System (MAS) Development Framework.
- [Fungi](https://github.com/enbop/fungi) - A platform built for seamless multi-device integration.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[modelcontextprotocol/rust-sdk]]></title>
            <link>https://github.com/modelcontextprotocol/rust-sdk</link>
            <guid>https://github.com/modelcontextprotocol/rust-sdk</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[The official Rust SDK for the Model Context Protocol]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/modelcontextprotocol/rust-sdk">modelcontextprotocol/rust-sdk</a></h1>
            <p>The official Rust SDK for the Model Context Protocol</p>
            <p>Language: Rust</p>
            <p>Stars: 2,520</p>
            <p>Forks: 395</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;div align = &quot;right&quot;&gt;
&lt;a href=&quot;docs/readme/README.zh-cn.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá(ÂæÖÊõ¥Êñ∞)&lt;/a&gt;
&lt;/div&gt;

# RMCP
[![Crates.io Version](https://img.shields.io/crates/v/rmcp)](https://crates.io/crates/rmcp)
&lt;!-- ![Release status](https://github.com/modelcontextprotocol/rust-sdk/actions/workflows/release.yml/badge.svg) --&gt;
&lt;!-- [![docs.rs](todo)](todo) --&gt;
![Coverage](docs/coverage.svg)

An official Rust Model Context Protocol SDK implementation with tokio async runtime.

This repository contains the following crates:

- [rmcp](crates/rmcp): The core crate providing the RMCP protocol implementation (If you want to get more information, please visit [rmcp](crates/rmcp/README.md))
- [rmcp-macros](crates/rmcp-macros): A procedural macro crate for generating RMCP tool implementations (If you want to get more information, please visit [rmcp-macros](crates/rmcp-macros/README.md))

## Usage

### Import the crate

```toml
rmcp = { version = &quot;0.8.0&quot;, features = [&quot;server&quot;] }
## or dev channel
rmcp = { git = &quot;https://github.com/modelcontextprotocol/rust-sdk&quot;, branch = &quot;main&quot; }
```
### Third Dependencies
Basic dependencies:
- [tokio required](https://github.com/tokio-rs/tokio)
- [serde required](https://github.com/serde-rs/serde)



### Build a Client
&lt;details&gt;
&lt;summary&gt;Start a client&lt;/summary&gt;

```rust, ignore
use rmcp::{ServiceExt, transport::{TokioChildProcess, ConfigureCommandExt}};
use tokio::process::Command;

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let client = ().serve(TokioChildProcess::new(Command::new(&quot;npx&quot;).configure(|cmd| {
        cmd.arg(&quot;-y&quot;).arg(&quot;@modelcontextprotocol/server-everything&quot;);
    }))?).await?;
    Ok(())
}
```
&lt;/details&gt;

### Build a Server

&lt;details&gt;
&lt;summary&gt;Build a transport&lt;/summary&gt;

```rust, ignore
use tokio::io::{stdin, stdout};
let transport = (stdin(), stdout());
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Build a service&lt;/summary&gt;

You can easily build a service by using [`ServerHandler`](crates/rmcp/src/handler/server.rs) or [`ClientHandler`](crates/rmcp/src/handler/client.rs).

```rust, ignore
let service = common::counter::Counter::new();
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Start the server&lt;/summary&gt;

```rust, ignore
// this call will finish the initialization process
let server = service.serve(transport).await?;
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Interact with the server&lt;/summary&gt;

Once the server is initialized, you can send requests or notifications:

```rust, ignore
// request
let roots = server.list_roots().await?;

// or send notification
server.notify_cancelled(...).await?;
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Waiting for service shutdown&lt;/summary&gt;

```rust, ignore
let quit_reason = server.waiting().await?;
// or cancel it
let quit_reason = server.cancel().await?;
```
&lt;/details&gt;


## Examples

See [examples](examples/README.md)

## OAuth Support

See [oauth_support](docs/OAUTH_SUPPORT.md) for details.

## Related Resources

- [MCP Specification](https://spec.modelcontextprotocol.io/specification/2024-11-05/)
- [Schema](https://github.com/modelcontextprotocol/specification/blob/main/schema/2024-11-05/schema.ts)

## Related Projects

### Extending `rmcp`

- [rmcp-actix-web](https://gitlab.com/lx-industries/rmcp-actix-web) - An `actix_web` backend for `rmcp`
- [rmcp-openapi](https://gitlab.com/lx-industries/rmcp-openapi) - Transform OpenAPI definition endpoints into MCP tools

### Built with `rmcp`

- [rustfs-mcp](https://github.com/rustfs/rustfs/tree/main/crates/mcp) - High-performance MCP server providing S3-compatible object storage operations for AI/LLM integration
- [containerd-mcp-server](https://github.com/jokemanfire/mcp-containerd) - A containerd-based MCP server implementation
- [rmcp-openapi-server](https://gitlab.com/lx-industries/rmcp-openapi/-/tree/main/crates/rmcp-openapi-server) - High-performance MCP server that exposes OpenAPI definition endpoints as MCP tools
- [nvim-mcp](https://github.com/linw1995/nvim-mcp) - A MCP server to interact with Neovim
- [terminator](https://github.com/mediar-ai/terminator) - AI-powered desktop automation MCP server with cross-platform support and &gt;95% success rate
- [stakpak-agent](https://github.com/stakpak/agent) - Security-hardened terminal agent for DevOps with MCP over mTLS, streaming, secret tokenization, and async task management


## Development

### Tips for Contributors

See [docs/CONTRIBUTE.MD](docs/CONTRIBUTE.MD) to get some tips for contributing.

### Using Dev Container

If you want to use dev container, see [docs/DEVCONTAINER.md](docs/DEVCONTAINER.md) for instructions on using Dev Container for development.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[meilisearch/meilisearch]]></title>
            <link>https://github.com/meilisearch/meilisearch</link>
            <guid>https://github.com/meilisearch/meilisearch</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[A lightning-fast search engine API bringing AI-powered hybrid search to your sites and applications.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/meilisearch/meilisearch">meilisearch/meilisearch</a></h1>
            <p>A lightning-fast search engine API bringing AI-powered hybrid search to your sites and applications.</p>
            <p>Language: Rust</p>
            <p>Stars: 54,368</p>
            <p>Forks: 2,248</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=logo#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/meilisearch-logo-light.svg?sanitize=true#gh-light-mode-only&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=logo#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/meilisearch-logo-dark.svg?sanitize=true#gh-dark-mode-only&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Website&lt;/a&gt; |
  &lt;a href=&quot;https://roadmap.meilisearch.com/tabs/1-under-consideration&quot;&gt;Roadmap&lt;/a&gt; |
  &lt;a href=&quot;https://www.meilisearch.com/pricing?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Meilisearch Cloud&lt;/a&gt; |
  &lt;a href=&quot;https://blog.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Blog&lt;/a&gt; |
  &lt;a href=&quot;https://www.meilisearch.com/docs?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Documentation&lt;/a&gt; |
  &lt;a href=&quot;https://www.meilisearch.com/docs/faq?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;FAQ&lt;/a&gt; |
  &lt;a href=&quot;https://discord.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=nav&quot;&gt;Discord&lt;/a&gt;
&lt;/h4&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://deps.rs/repo/github/meilisearch/meilisearch&quot;&gt;&lt;img src=&quot;https://deps.rs/repo/github/meilisearch/meilisearch/status.svg&quot; alt=&quot;Dependency status&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/meilisearch/meilisearch/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/license-MIT-informational&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/meilisearch/meilisearch/queue&quot;&gt;&lt;img alt=&quot;Merge Queues enabled&quot; src=&quot;https://img.shields.io/badge/Merge_Queues-enabled-%2357cf60?logo=github&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;‚ö° A lightning-fast search engine that fits effortlessly into your apps, websites, and workflow üîç&lt;/p&gt;

[Meilisearch](https://www.meilisearch.com?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=intro) helps you shape a delightful search experience in a snap, offering features that work out of the box to speed up your workflow.

&lt;p align=&quot;center&quot; name=&quot;demo&quot;&gt;
  &lt;a href=&quot;https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demo-gif#gh-light-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/demo-light.gif#gh-light-mode-only&quot; alt=&quot;A bright colored application for finding movies screening near the user&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demo-gif#gh-dark-mode-only&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;assets/demo-dark.gif#gh-dark-mode-only&quot; alt=&quot;A dark colored application for finding movies screening near the user&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## üñ• Examples

- [**Movies**](https://where2watch.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=organization) ‚Äî An application to help you find streaming platforms to watch movies using [hybrid search](https://www.meilisearch.com/solutions/hybrid-search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos).
- [**Flickr**](https://flickr.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=organization) ‚Äî Search and explore one hundred million Flickr images with semantic search.
- [**Ecommerce**](https://ecommerce.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) ‚Äî Ecommerce website using disjunctive [facets](https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos), range and rating filtering, and pagination.
- [**Songs**](https://music.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) ‚Äî Search through 47 million of songs.
- [**SaaS**](https://saas.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) ‚Äî Search for contacts, deals, and companies in this [multi-tenant](https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=demos) CRM application.

See the list of all our example apps in our [demos repository](https://github.com/meilisearch/demos).

## ‚ú® Features
- **Hybrid search:** Combine the best of both [semantic](https://www.meilisearch.com/docs/learn/experimental/vector_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features) &amp; full-text search to get the most relevant results
- **Search-as-you-type:** Find &amp; display results in less than 50 milliseconds to provide an intuitive experience
- **[Typo tolerance](https://www.meilisearch.com/docs/learn/relevancy/typo_tolerance_settings?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** get relevant matches even when queries contain typos and misspellings
- **[Filtering](https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features) and [faceted search](https://www.meilisearch.com/docs/learn/fine_tuning_results/faceted_search?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** enhance your users&#039; search experience with custom filters and build a faceted search interface in a few lines of code
- **[Sorting](https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** sort results based on price, date, or pretty much anything else your users need
- **[Synonym support](https://www.meilisearch.com/docs/learn/relevancy/synonyms?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** configure synonyms to include more relevant content in your search results
- **[Geosearch](https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** filter and sort documents based on geographic data
- **[Extensive language support](https://www.meilisearch.com/docs/learn/what_is_meilisearch/language?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** search datasets in any language, with optimized support for Chinese, Japanese, Hebrew, and languages using the Latin alphabet
- **[Security management](https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** control which users can access what data with API keys that allow fine-grained permissions handling
- **[Multi-Tenancy](https://www.meilisearch.com/docs/learn/security/multitenancy_tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** personalize search results for any number of application tenants
- **Highly Customizable:** customize Meilisearch to your specific needs or use our out-of-the-box and hassle-free presets
- **[RESTful API](https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=features):** integrate Meilisearch in your technical stack with our plugins and SDKs
- **AI-ready:** works out of the box with [langchain](https://www.meilisearch.com/with/langchain) and the [model context protocol](https://github.com/meilisearch/meilisearch-mcp)
- **Easy to install, deploy, and maintain**

## üìñ Documentation

You can consult Meilisearch&#039;s documentation at [meilisearch.com/docs](https://www.meilisearch.com/docs/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=docs).

## üöÄ Getting started

For basic instructions on how to set up Meilisearch, add documents to an index, and search for documents, take a look at our [documentation](https://www.meilisearch.com/docs?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=get-started) guide.

## üåç Supercharge your Meilisearch experience

Say goodbye to server deployment and manual updates with [Meilisearch Cloud](https://www.meilisearch.com/cloud?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch). Additional features include analytics &amp; monitoring in many regions around the world. No credit card is required.

## üß∞ SDKs &amp; integration tools

Install one of our SDKs in your project for seamless integration between Meilisearch and your favorite language or framework!

Take a look at the complete [Meilisearch integration list](https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=sdks-link).

[![Logos belonging to different languages and frameworks supported by Meilisearch, including React, Ruby on Rails, Go, Rust, and PHP](assets/integrations.png)](https://www.meilisearch.com/docs/learn/what_is_meilisearch/sdks?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=sdks-logos)

## ‚öôÔ∏è Advanced usage

Experienced users will want to keep our [API Reference](https://www.meilisearch.com/docs/reference/api/overview?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced) close at hand.

We also offer a wide range of dedicated guides to all Meilisearch features, such as [filtering](https://www.meilisearch.com/docs/learn/fine_tuning_results/filtering?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), [sorting](https://www.meilisearch.com/docs/learn/fine_tuning_results/sorting?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), [geosearch](https://www.meilisearch.com/docs/learn/fine_tuning_results/geosearch?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), [API keys](https://www.meilisearch.com/docs/learn/security/master_api_keys?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced), and [tenant tokens](https://www.meilisearch.com/docs/learn/security/tenant_tokens?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced).

Finally, for more in-depth information, refer to our articles explaining fundamental Meilisearch concepts such as [documents](https://www.meilisearch.com/docs/learn/core_concepts/documents?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced) and [indexes](https://www.meilisearch.com/docs/learn/core_concepts/indexes?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=advanced).

## üßæ Editions &amp; Licensing

Meilisearch is available in two editions:

### üß™ Community Edition (CE)

- Fully open source under the [MIT license](./LICENSE)
- Core search engine with fast and relevant full-text, semantic or hybrid search
- Free to use for anyone, including commercial usage

### üè¢ Enterprise Edition (EE)

- Includes advanced features such as:
  - Sharding
- Governed by a [commercial license](./LICENSE-EE) or the [Business Source License 1.1](https://mariadb.com/bsl11)
- Not allowed in production without a commercial agreement with Meilisearch.
  - You may use, modify, and distribute the Licensed Work for non-production purposes only, such as testing, development, or evaluation.

Want access to Enterprise features? ‚Üí Contact us at [sales@meilisearch.com](maito:sales@meilisearch.com).

## üìä Telemetry

Meilisearch collects **anonymized** user data to help us improve our product. You can [deactivate this](https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=telemetry#how-to-disable-data-collection) whenever you want.

To request deletion of collected data, please write to us at [privacy@meilisearch.com](mailto:privacy@meilisearch.com). Remember to include your `Instance UID` in the message, as this helps us quickly find and delete your data.

If you want to know more about the kind of data we collect and what we use it for, check the [telemetry section](https://www.meilisearch.com/docs/learn/what_is_meilisearch/telemetry?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=telemetry#how-to-disable-data-collection) of our documentation.

## üì´ Get in touch!

Meilisearch is a search engine created by [Meili](https://www.meilisearch.com/careers), a software development company headquartered in France and with team members all over the world. Want to know more about us? [Check out our blog!](https://blog.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=contact)

üóû [Subscribe to our newsletter](https://share-eu1.hsforms.com/1LN5N0x_GQgq7ss7tXmSykwfg3aq) if you don&#039;t want to miss any updates! We promise we won&#039;t clutter your mailbox: we only send one edition every two months.

üíå Want to make a suggestion or give feedback? Here are some of the channels where you can reach us:

- For feature requests, please visit our [product repository](https://github.com/meilisearch/product/discussions)
- Found a bug? Open an [issue](https://github.com/meilisearch/meilisearch/issues)!
- Want to be part of our Discord community? [Join us!](https://discord.meilisearch.com/?utm_campaign=oss&amp;utm_source=github&amp;utm_medium=meilisearch&amp;utm_content=contact)

Thank you for your support!

## üë©‚Äçüíª Contributing

Meilisearch is, and will always be, open-source! If you want to contribute to the project, please look at [our contribution guidelines](CONTRIBUTING.md).

## üì¶ Versioning

Meilisearch releases and their associated binaries are available on the project&#039;s [releases page](https://github.com/meilisearch/meilisearch/releases).

The binaries are versioned following [SemVer conventions](https://semver.org/). To know more, read our [versioning policy](./documentation/versioning-policy.md).

Differently from the binaries, crates in this repository are not currently available on [crates.io](https://crates.io/) and do not follow [SemVer conventions](https://semver.org).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[supabase/etl]]></title>
            <link>https://github.com/supabase/etl</link>
            <guid>https://github.com/supabase/etl</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Stream your Postgres data anywhere in real-time. Simple Rust building blocks for change data capture (CDC) pipelines.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/supabase/etl">supabase/etl</a></h1>
            <p>Stream your Postgres data anywhere in real-time. Simple Rust building blocks for change data capture (CDC) pipelines.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,415</p>
            <p>Forks: 79</p>
            <p>Stars today: 90 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://supabase.com&quot;&gt;
    &lt;picture&gt;
      &lt;img alt=&quot;ETL by Supabase&quot; width=&quot;100%&quot; src=&quot;docs/assets/etl-logo-extended.png&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;

  &lt;h1 align=&quot;center&quot;&gt;ETL&lt;/h1&gt;

  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/supabase/etl/actions/workflows/ci.yml&quot;&gt;
      &lt;img alt=&quot;CI&quot; src=&quot;https://github.com/supabase/etl/actions/workflows/ci.yml/badge.svg?branch=main&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://coveralls.io/github/supabase/etl?branch=main&quot;&gt;
      &lt;img alt=&quot;Coverage Status&quot; src=&quot;https://coveralls.io/repos/github/supabase/etl/badge.svg?branch=main&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/supabase/etl/actions/workflows/docs.yml&quot;&gt;
      &lt;img alt=&quot;Docs&quot; src=&quot;https://github.com/supabase/etl/actions/workflows/docs.yml/badge.svg?branch=main&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/supabase/etl/actions/workflows/docker-build.yml&quot;&gt;
      &lt;img alt=&quot;Docker Build&quot; src=&quot;https://github.com/supabase/etl/actions/workflows/docker-build.yml/badge.svg?branch=main&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/supabase/etl/actions/workflows/audit.yml&quot;&gt;
      &lt;img alt=&quot;Security Audit&quot; src=&quot;https://github.com/supabase/etl/actions/workflows/audit.yml/badge.svg?branch=main&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;LICENSE&quot;&gt;
      &lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
    &lt;/a&gt;
    &lt;br /&gt;
    Build real-time Postgres replication applications in Rust
    &lt;br /&gt;
    &lt;a href=&quot;https://supabase.github.io/etl&quot;&gt;&lt;strong&gt;Documentation&lt;/strong&gt;&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/supabase/etl/tree/main/etl-examples&quot;&gt;&lt;strong&gt;Examples&lt;/strong&gt;&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/supabase/etl/issues&quot;&gt;&lt;strong&gt;Issues&lt;/strong&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;/p&gt;

ETL is a Rust framework by [Supabase](https://supabase.com) for building high‚Äëperformance, real‚Äëtime data replication apps on Postgres. It sits on top of Postgres [logical replication](https://www.postgresql.org/docs/current/protocol-logical-replication.html) and gives you a clean, Rust‚Äënative API for streaming changes to your own destinations.

## Highlights

- **Real‚Äëtime replication**: stream changes in real time to your own destinations.
- **High performance**: configurable batching and parallelism to maximize throughput.
- **Fault-tolerant**: robust error handling and retry logic built-in.
- **Extensible**: implement your own custom destinations and state/schema stores.
- **Rust native**: typed and ergonomic Rust API.

## Requirements

**PostgreSQL Version:** ETL officially supports and tests against **PostgreSQL 14, 15, 16, and 17**.

- **PostgreSQL 15+** is recommended for access to advanced publication features including:
  - Column-level filtering
  - Row-level filtering with `WHERE` clauses
  - `FOR ALL TABLES IN SCHEMA` syntax

For detailed configuration instructions, see the [Configure Postgres documentation](https://supabase.github.io/etl/how-to/configure-postgres/).

## Get Started

Install via Git while we prepare for a crates.io release:

```toml
[dependencies]
etl = { git = &quot;https://github.com/supabase/etl&quot; }
```

Quick example using the in‚Äëmemory destination:

```rust
use etl::{
    config::{BatchConfig, PgConnectionConfig, PipelineConfig, TlsConfig},
    destination::memory::MemoryDestination,
    pipeline::Pipeline,
    store::both::memory::MemoryStore,
};

#[tokio::main]
async fn main() -&gt; Result&lt;(), Box&lt;dyn std::error::Error&gt;&gt; {
    let pg = PgConnectionConfig {
        host: &quot;localhost&quot;.into(),
        port: 5432,
        name: &quot;mydb&quot;.into(),
        username: &quot;postgres&quot;.into(),
        password: Some(&quot;password&quot;.into()),
        tls: TlsConfig { enabled: false, trusted_root_certs: String::new() },
    };

    let store = MemoryStore::new();
    let destination = MemoryDestination::new();

    let config = PipelineConfig {
        id: 1,
        publication_name: &quot;my_publication&quot;.into(),
        pg_connection: pg,
        batch: BatchConfig { max_size: 1000, max_fill_ms: 5000 },
        table_error_retry_delay_ms: 10_000,
        table_error_retry_max_attempts: 5,
        max_table_sync_workers: 4,
    };

    let mut pipeline = Pipeline::new(config, store, destination);
    pipeline.start().await?;
    // pipeline.wait().await?; // Optional: block until completion

    Ok(())
}
```

For tutorials and deeper guidance, see the [Documentation](https://supabase.github.io/etl) or jump into the [examples](etl-examples/README.md).

## Destinations

ETL is designed to be extensible. You can implement your own destinations to send data to any destination you like, however it comes with a few built in destinations:

- BigQuery

Out-of-the-box destinations are available in the `etl-destinations` crate:

```toml
[dependencies]
etl = { git = &quot;https://github.com/supabase/etl&quot; }
etl-destinations = { git = &quot;https://github.com/supabase/etl&quot;, features = [&quot;bigquery&quot;] }
```

## License

Apache‚Äë2.0. See `LICENSE` for details.

---

&lt;p align=&quot;center&quot;&gt;
  Made with ‚ù§Ô∏è by the &lt;a href=&quot;https://supabase.com&quot;&gt;Supabase&lt;/a&gt; team
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[crate-ci/typos]]></title>
            <link>https://github.com/crate-ci/typos</link>
            <guid>https://github.com/crate-ci/typos</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[Source code spell checker]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/crate-ci/typos">crate-ci/typos</a></h1>
            <p>Source code spell checker</p>
            <p>Language: Rust</p>
            <p>Stars: 3,565</p>
            <p>Forks: 147</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># typos

&gt; **Source code spell checker**

Finds and corrects spelling mistakes among source code:
- Fast enough to run on monorepos
- Low false positives so you can run on PRs

![Screenshot](./docs/screenshot.png)


[![Downloads](https://img.shields.io/github/downloads/crate-ci/typos/total.svg)](https://github.com/crate-ci/typos/releases)
[![codecov](https://codecov.io/gh/crate-ci/typos/branch/master/graph/badge.svg)](https://codecov.io/gh/crate-ci/typos)
[![Documentation](https://img.shields.io/badge/docs-master-blue.svg)][Documentation]
![License](https://img.shields.io/crates/l/typos.svg)
[![Crates Status](https://img.shields.io/crates/v/typos.svg)][Crates.io]

Dual-licensed under [MIT](LICENSE-MIT) or [Apache 2.0](LICENSE-APACHE)

## Documentation

- [Installation](#install)
- [Getting Started](#getting-started)
  - [False Positives](#false-positives)
  - [Integrations](#integrations)
    - [GitHub Action](docs/github-action.md)
    - [pre-commit](docs/pre-commit.md)
    - [Custom](#custom)
  - [Debugging](#debugging)
- [Reference](docs/reference.md)
- [FAQ](#faq)
- [Comparison with other spell checkers](docs/comparison.md)
- [Projects using typos](https://github.com/crate-ci/typos/wiki)
- [Benchmarks](benchsuite/runs)
- [Design](docs/design.md)
- [Contribute](CONTRIBUTING.md)
- [CHANGELOG](CHANGELOG.md)

## Install

[Download](https://github.com/crate-ci/typos/releases) a pre-built binary
(installable via [gh-install](https://github.com/crate-ci/gh-install)).

Or use rust to install:
```console
$ cargo install typos-cli --locked
```

Or use [Homebrew](https://brew.sh/) to install:
```console
$ brew install typos-cli
```

Or use [Conda](https://conda.io/) to install:
```console
$ conda install typos
```

Or use [Pacman](https://wiki.archlinux.org/title/pacman) to install:
```console
$ sudo pacman -S typos
```

## Getting Started

Most commonly, you&#039;ll either want to see what typos are available with
```console
$ typos
```

Or have them fixed
```console
$ typos --write-changes
$ typos -w
```
If there is any ambiguity (multiple possible corrections), `typos` will just report it to the user and move on.

### False Positives

Sometimes, what looks like a typo is intentional, like with people&#039;s names, acronyms, or localized content.

To mark a word or an identifier (grouping of words) as valid, add it to your [`_typos.toml`](docs/reference.md) by declaring itself as the valid spelling:
```toml
[default]
extend-ignore-identifiers-re = [
    # *sigh* this just isn&#039;t worth the cost of fixing
    &quot;AttributeID.*Supress.*&quot;,
]

[default.extend-identifiers]
# *sigh* this just isn&#039;t worth the cost of fixing
AttributeIDSupressMenu = &quot;AttributeIDSupressMenu&quot;

[default.extend-words]
# Don&#039;t correct the surname &quot;Teh&quot;
teh = &quot;teh&quot;
```
For more ways to ignore or extend the dictionary with examples, see the [config reference](docs/reference.md).

For cases like localized content, you can disable spell checking of file contents while still checking the file name:
```toml
[type.po]
extend-glob = [&quot;*.po&quot;]
check-file = false
```
(run `typos --type-list` to see configured file types)

If you need some more flexibility, you can completely exclude some files from consideration:
```toml
[files]
extend-exclude = [&quot;localized/*.po&quot;]
```

### Integrations

- [GitHub Actions](docs/github-action.md)
- [pre-commit](docs/pre-commit.md)
- [üêäPutout Processor](https://github.com/putoutjs/putout-processor-typos)
- [Visual Studio Code](https://github.com/tekumara/typos-vscode)
- [typos-lsp (Language Server Protocol server)](https://github.com/tekumara/typos-vscode)

#### Custom

`typos` provides several building blocks for custom native integrations
- `-` reads from `stdin`, `--write-changes` will be written to `stdout`
- `--diff` to provide a diff
- `--format json` to get jsonlines with exit code 0 on no errors, code 2 on typos, anything else is an error.

Examples:
```console
$ # Read file from stdin, write corrected version to stdout
$ typos - --write-changes
$ # Creates a diff of what would change
$ typos dir/file --diff
$ # Fully programmatic control
$ typos dir/file --format json
```

### Debugging

You can see what the effective config looks like by running
```console
$ typos --dump-config -
```

You can then see how typos is processing your project with
```console
$ typos --files
$ typos --identifiers
$ typos --words
```

If you need to dig in more, you can enable debug logging with `-v`

## FAQ

### Why was ... not corrected?

**Does the file show up in `typos --files`?**
If not, check your config with `typos --dump-config -`.
The `[files]` table controls how we walk files.
If you are using `files.extend-exclude`,
are you running into [#593](https://github.com/crate-ci/typos/issues/593)?
If you are using `files.ignore-vcs = true`,
is the file in your `.gitignore` but git tracks it anyways?
Prefer allowing the file explicitly (see [#909](https://github.com/crate-ci/typos/issues/909)).

**Does the identifier show up in `typos --identifiers` or the word show up in `typos --words`?**
If not, it might be subject to one of typos&#039; heuristics for
detecting non-words (like hashes) or
unambiguous words (like words after a `\` escape).

If it is showing up, likely `typos` doesn&#039;t know about it yet.

`typos` maintains a list of known typo corrections to keep the false positive
count low so it can safely run unassisted.

This is in contrast to most spell checking UIs people use where there is a
known list of valid words.  In this case, the spell checker tries to guess your
intent by finding the closest-looking word.  It then has a gauge for when a
word isn&#039;t close enough and assumes you know best.  The user has the
opportunity to verify these corrections and explicitly allow or reject them.

For more on the trade offs of these approaches, see [Design](docs/design.md).

- To correct it locally, see also our [False Positives documentation](#false-positives).
- To contribute your correction, see [Contribute](CONTRIBUTING.md)

[Crates.io]: https://crates.io/crates/typos-cli
[Documentation]: https://docs.rs/typos
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gopher64/gopher64]]></title>
            <link>https://github.com/gopher64/gopher64</link>
            <guid>https://github.com/gopher64/gopher64</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[Highly compatible N64 emulator]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gopher64/gopher64">gopher64/gopher64</a></h1>
            <p>Highly compatible N64 emulator</p>
            <p>Language: Rust</p>
            <p>Stars: 621</p>
            <p>Forks: 11</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre># gopher64
## download

Windows: https://github.com/gopher64/gopher64/releases/latest/download/gopher64-windows-x86_64.exe

Linux: https://flathub.org/apps/io.github.gopher64.gopher64

## wiki

https://github.com/gopher64/gopher64/wiki

## discord

https://discord.gg/9RGXq8W8JQ

## controls

Keys are mapped according to [these defaults](https://github.com/gopher64/gopher64/wiki/Default-Keyboard-Setup). Xbox-style controllers also have a [default mapping applied](https://github.com/gopher64/gopher64/wiki/Default-Gamepad-Setup).

## netplay

Gopher64 supports netplay (online play with others) via cloud hosted servers. You can also run the server (https://github.com/gopher64/gopher64-netplay-server) yourself on a LAN.

## portable mode

If you would like to keep all the game data in the same folder as the executable, you just need to create a file called &quot;portable.txt&quot; in the same directory as the executable.

## flatpak

If you want to run the flatpak from the command line, you need to add the `--filesystem=host:ro` option, for example:

```
flatpak run --filesystem=host:ro io.github.gopher64.gopher64 /path/to/rom.z64
```

## building and usage

1. Linux only: install the SDL3 dependencies: https://wiki.libsdl.org/SDL3/README-linux#build-dependencies
2. Install rust: https://www.rust-lang.org/tools/install
3. `git clone --recursive https://github.com/gopher64/gopher64.git`
4. `cd gopher64`
5. `cargo build --release`
6. `./target/release/gopher64 /path/to/rom.z64`

## contributing

I am very open to contributions! Please contact me via a GitHub issue or Discord (loganmc10) before doing substantial work on a PR.

## license

Gopher64 is licensed under the GPLv3 license. Many portions of gopher64 have been adapted from mupen64plus and/or ares. The license for mupen64plus can be found here: https://github.com/mupen64plus/mupen64plus-core/blob/master/LICENSES. The license for ares can be found here: https://github.com/ares-emulator/ares/blob/master/LICENSE.

## privacy and code signing policy

Free code signing for the Windows release is provided by [SignPath.io](https://about.signpath.io), certificate by [SignPath Foundation](https://signpath.org).

During online netplay sessions, the server logs your IP address and basic session information (game title and session name) for operational purposes. No additional personal data is collected or stored.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[timescale/pgvectorscale]]></title>
            <link>https://github.com/timescale/pgvectorscale</link>
            <guid>https://github.com/timescale/pgvectorscale</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[A complement to pgvector for high performance, cost efficient vector search on large workloads.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/timescale/pgvectorscale">timescale/pgvectorscale</a></h1>
            <p>A complement to pgvector for high performance, cost efficient vector search on large workloads.</p>
            <p>Language: Rust</p>
            <p>Stars: 2,377</p>
            <p>Forks: 110</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;p&gt;&lt;/p&gt;
&lt;div align=center&gt;

# pgvectorscale

&lt;h3&gt;pgvectorscale builds on pgvector with higher performance embedding search and cost-efficient storage for AI applications. &lt;/h3&gt;

[![Discord](https://img.shields.io/badge/Join_us_on_Discord-black?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.gg/KRdHVXAmkp)
[![Try Timescale for free](https://img.shields.io/badge/Try_Timescale_for_free-black?style=for-the-badge&amp;logo=timescale&amp;logoColor=white)](https://tsdb.co/gh-pgvector-signup)
&lt;/div&gt;

pgvectorscale complements [pgvector][pgvector], the open-source vector data extension for PostgreSQL, and introduces the following key innovations for pgvector data:
- A new index type called StreamingDiskANN, inspired by the [DiskANN](https://github.com/microsoft/DiskANN) algorithm, based on research from Microsoft.
- Statistical Binary Quantization: developed by Timescale researchers, This compression method improves on standard Binary Quantization.
- Label-based filtered vector search: based on Microsoft&#039;s Filtered DiskANN research, this allows you to combine vector similarity search with label filtering for more precise and efficient results.

On a benchmark dataset of 50 million Cohere embeddings with 768 dimensions
each, PostgreSQL with `pgvector` and `pgvectorscale` achieves **28x lower p95
latency** and **16x higher query throughput** compared to Pinecone&#039;s storage
optimized (s1) index for approximate nearest neighbor queries at 99% recall,
all at 75% less cost when self-hosted on AWS EC2.

&lt;div align=center&gt;

![Benchmarks](https://assets.timescale.com/docs/images/benchmark-comparison-pgvectorscale-pinecone.png)

&lt;/div&gt;

To learn more about the performance impact of pgvectorscale, and details about benchmark methodology and results, see the [pgvector vs Pinecone comparison blog post](http://www.timescale.com/blog/pgvector-vs-pinecone).

In contrast to pgvector, which is written in C, pgvectorscale is developed in [Rust][rust-language] using the [PGRX framework](https://github.com/pgcentralfoundation/pgrx),
offering the PostgreSQL community a new avenue for contributing to vector support.

**Application developers or DBAs** can use pgvectorscale with their PostgreSQL databases.
   * [Install pgvectorscale](#installation)
   * [Get started using pgvectorscale](#get-started-with-pgvectorscale)

If you **want to contribute** to this extension, see how to [build pgvectorscale from source in a developer environment](./DEVELOPMENT.md) and our [testing guide](./TESTING.md).

For production vector workloads, get **private beta access to vector-optimized databases** with pgvector and pgvectorscale on Timescale. [Sign up here for priority access](https://timescale.typeform.com/to/H7lQ10eQ).

## Installation

The fastest ways to run PostgreSQL with pgvectorscale are:

* [Using a pre-built Docker container](#using-a-pre-built-docker-container)
* [Installing from source](#installing-from-source)
* [Enable pgvectorscale in a Timescale Cloud service](#enable-pgai-in-a-timescale-cloud-service)

### Using a pre-built Docker container

1.  [Run the TimescaleDB Docker image](https://docs.timescale.com/self-hosted/latest/install/installation-docker/).

1. Connect to your database:
   ```bash
   psql -d &quot;postgres://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;database-name&gt;&quot;
   ```

1. Create the pgvectorscale extension:

    ```sql
    CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;
    ```

   The `CASCADE` automatically installs `pgvector`.

### Installing from source

You can install pgvectorscale from source and install it in an existing PostgreSQL server

&gt; [!WARNING]
&gt; Building pgvectorscale on macOS X86 (Intel) machines is currently not
&gt; supported due to an [open issue][macos-x86-issue]. As alternatives, you can:
&gt;
&gt; - Use an ARM-based Mac.
&gt; - Build using Linux.
&gt; - Use our pre-built Docker containers.
&gt;
&gt; We welcome community contributions to resolve this limitation. If you&#039;re
&gt; interested in helping, please check the issue for details.

1. Compile and install the extension

    ```bash
    # install rust
    curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh

    # download pgvectorscale
    cd /tmp
    git clone --branch &lt;version&gt; https://github.com/timescale/pgvectorscale
    cd pgvectorscale/pgvectorscale
    # install cargo-pgrx with the same version as pgrx
    cargo install --locked cargo-pgrx --version $(cargo metadata --format-version 1 | jq -r &#039;.packages[] | select(.name == &quot;pgrx&quot;) | .version&#039;)
    cargo pgrx init --pg18 pg_config
    # build and install pgvectorscale
    cargo pgrx install --release
    ```

    You can also take a look at our [documentation for extension developers](./DEVELOPMENT.md) for more complete instructions.

1. Connect to your database:
   ```bash
   psql -d &quot;postgres://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;database-name&gt;&quot;
   ```

1. Ensure the pgvector extension is available:

   ```sql
   SELECT * FROM pg_available_extensions WHERE name = &#039;vector&#039;;
   ```

   If pgvector is not available, install it using the [pgvector installation
   instructions][pgvector-install].


1. Create the pgvectorscale extension:

    ```sql
    CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;
    ```

   The `CASCADE` automatically installs `pgvector`.

### Enable pgvectorscale in a Timescale Cloud service

Note: the instructions below are for Timescale&#039;s standard compute instance. For production vector workloads, we&#039;re offering **private beta access to vector-optimized databases** with pgvector and pgvectorscale on Timescale. [Sign up here for priority access](https://timescale.typeform.com/to/H7lQ10eQ).

To enable pgvectorscale:

1. Create a new [Timescale Service](https://console.cloud.timescale.com/signup?utm_campaign=vectorlaunch).

   If you want to use an existing service, pgvectorscale is added as an available extension on the first maintenance window
   after the pgvectorscale release date.

1. Connect to your Timescale service:
   ```bash
   psql -d &quot;postgres://&lt;username&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;database-name&gt;&quot;
   ```

1. Create the pgvectorscale extension:

    ```postgresql
    CREATE EXTENSION IF NOT EXISTS vectorscale CASCADE;
    ```

   The `CASCADE` automatically installs `pgvector`.


## Get started with pgvectorscale


1. Create a table with an embedding column. For example:

    ```postgresql
    CREATE TABLE IF NOT EXISTS document_embedding  (
        id BIGINT PRIMARY KEY GENERATED BY DEFAULT AS IDENTITY,
        metadata JSONB,
        contents TEXT,
        embedding VECTOR(1536)
    )
    ```

1. Populate the table.

   For more information, see the [pgvector instructions](https://github.com/pgvector/pgvector/blob/master/README.md#storing) and [list of clients](https://github.com/pgvector/pgvector/blob/master/README.md#languages).
1. Create a StreamingDiskANN index on the embedding column:
    ```postgresql
    CREATE INDEX document_embedding_idx ON document_embedding
    USING diskann (embedding vector_cosine_ops);
    ```
1. Find the 10 closest embeddings using the index.

    ```postgresql
    SELECT *
    FROM document_embedding
    ORDER BY embedding &lt;=&gt; $1
    LIMIT 10;
    ```

    Note: pgvectorscale currently supports: cosine distance (`&lt;=&gt;`) queries, for indices created with `vector_cosine_ops`; L2 distance (`&lt;-&gt;`) queries, for indices created with `vector_l2_ops`; and inner product (`&lt;#&gt;`) queries, for indices created with `vector_ip_ops`.  This is the same syntax used by `pgvector`.  If you would like additional distance types,
    [create an issue](https://github.com/timescale/pgvectorscale/issues).  (Note: inner product indices are not compatible with plain storage.)

## Filtered Vector Search

pgvectorscale supports combining vector similarity search with metadata filtering. There are two basic kinds of filtering, which can be combined in a single query:

1. **Label-based filtering with the diskann index**: This provides optimized performance for filtering by labels.
2. **Arbitrary WHERE clause filtering**: This uses post-filtering after the vector search.

The label-based filtering implementation is based on the [Filtered DiskANN](https://dl.acm.org/doi/10.1145/3543507.3583552) approach developed by Microsoft researchers, which enables efficient filtered vector search while maintaining high recall.

The post-filtering implementation, while slower, is streaming and correct, ensuring accurate results without requiring the entire result set to be loaded into memory.

### Label-based Filtering with diskann

For optimal performance with label filtering, you must specify the label column directly in the index creation:

1. Create a table with an embedding column and a labels array:

    ```postgresql
    CREATE TABLE documents (
        id SERIAL PRIMARY KEY,
        embedding VECTOR(1536),
        labels SMALLINT[],  -- Array of category labels
        status TEXT,
        created_at TIMESTAMPTZ
    );
    ```

2. Create a StreamingDiskANN index on the embedding column, including the labels column:

    ```postgresql
    CREATE INDEX ON documents USING diskann (embedding vector_cosine_ops, labels);
    ```

&gt; **Note**: Label values must be within the PostgreSQL `smallint` range (-32768 to 32767). Using `smallint[]` for labels ensures that PostgreSQL&#039;s type system will automatically enforce these bounds.
&gt; 
&gt; pgvectorscale includes an implementation of the `&amp;&amp;` overlap operator for `smallint[]` arrays, which is used for efficient label-based filtering.

3. Perform label-filtered vector searches using the `&amp;&amp;` operator (array overlap):

    ```postgresql
    -- Find similar documents with specific labels
    SELECT * FROM documents
    WHERE labels &amp;&amp; ARRAY[1, 3]  -- Documents with label 1 OR 3
    ORDER BY embedding &lt;=&gt; &#039;[...]&#039;
    LIMIT 10;
    ```

    The index directly supports this type of filtering, providing significantly lower latency results compared to post-filtering.

#### Giving Semantic Meaning to Labels

While the labels must be stored as integers in the array for the index to work efficiently, you can give them semantic meaning by relating them to a separate labels table:

1. Create a labels table with meaningful descriptions:

    ```postgresql
    CREATE TABLE label_definitions (
        id INTEGER PRIMARY KEY,
        name TEXT,
        description TEXT,
        attributes JSONB  -- Can store additional metadata about the label
    );

    -- Insert some label definitions
    INSERT INTO label_definitions (id, name, description, attributes) VALUES
    (1, &#039;science&#039;, &#039;Scientific content&#039;, &#039;{&quot;domain&quot;: &quot;academic&quot;, &quot;confidence&quot;: 0.95}&#039;),
    (2, &#039;technology&#039;, &#039;Technology-related content&#039;, &#039;{&quot;domain&quot;: &quot;technical&quot;, &quot;confidence&quot;: 0.92}&#039;),
    (3, &#039;business&#039;, &#039;Business and finance content&#039;, &#039;{&quot;domain&quot;: &quot;commercial&quot;, &quot;confidence&quot;: 0.88}&#039;);
    ```

2. When inserting documents, use the appropriate label IDs:

    ```postgresql
    -- Insert a document with science and technology labels
    INSERT INTO documents (embedding, labels)
    VALUES (&#039;[...]&#039;, ARRAY[1, 2]);
    ```

3. When querying, you can join with the labels table to work with meaningful names:

    ```postgresql
    -- Find similar science documents and include label information
    SELECT d.*, array_agg(l.name) as label_names
    FROM documents d
    JOIN label_definitions l ON l.id = ANY(d.labels)
    WHERE d.labels &amp;&amp; ARRAY[1]  -- Science label
    GROUP BY d.id, d.embedding, d.labels, d.status, d.created_at
    ORDER BY d.embedding &lt;=&gt; &#039;[...]&#039;
    LIMIT 10;
    ```

4. You can also convert between label names and IDs when filtering:

    ```postgresql
    -- Find documents with specific label names
    SELECT d.*
    FROM documents d
    WHERE d.labels &amp;&amp; (
        SELECT array_agg(id)
        FROM label_definitions
        WHERE name IN (&#039;science&#039;, &#039;business&#039;)
    )
    ORDER BY d.embedding &lt;=&gt; &#039;[...]&#039;
    LIMIT 10;
    ```

This approach gives you the performance benefits of integer-based label filtering while still allowing you to work with semantically meaningful labels in your application.

### Arbitrary WHERE Clause Filtering

You can also use any PostgreSQL WHERE clause with vector search, but these conditions will be applied as post-filtering:

```postgresql
-- Find similar documents with specific status and date range
SELECT * FROM documents
WHERE status = &#039;active&#039; AND created_at &gt; &#039;2024-01-01&#039;
ORDER BY embedding &lt;=&gt; &#039;[...]&#039;
LIMIT 10;
```

For these arbitrary conditions, the vector search happens first, and then the WHERE conditions are applied to the results. For best performance with frequently used filters, consider using the label-based approach described above.

## Tuning

The StreamingDiskANN index comes with **smart defaults** but also the ability to customize its behavior. There are two types of parameters: index build-time parameters that are specified when an index is created and query-time parameters that can be tuned when querying an index.

We suggest setting the index build-time paramers for major changes to index operations while query-time parameters can be used to tune the accuracy/performance tradeoff for individual queries.

 We expect most people to tune the query-time parameters (if any) and leave the index build time parameters set to default.

### StreamingDiskANN index build-time parameters

The StreamingDiskANN index build process can be memory-intensive. You may need to increase the `maintenance_work_mem` parameter to improve build performance. For example:

```sql
SET maintenance_work_mem = &#039;2GB&#039;;
```

This parameter controls the maximum amount of memory to be used by maintenance operations, including index builds. The default value is typically 64MB, which may be too low for building StreamingDiskANN indexes on large datasets.

These parameters can be set when an index is created.

| Parameter name   | Description                                                                                                                                                    | Default value |
|------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|
| `storage_layout` | `memory_optimized` which uses SBQ to compress vector data or `plain` which stores data uncompressed | memory_optimized
| `num_neighbors`    | Sets the maximum number of neighbors per node. Higher values increase accuracy but make the graph traversal slower.                                           | 50            |
| `search_list_size` | This is the S parameter used in the greedy search algorithm used during construction. Higher values improve graph quality at the cost of slower index builds. | 100           |
| `max_alpha`        | Is the alpha parameter in the algorithm. Higher values improve graph quality at the cost of slower index builds.                                              | 1.2           |
| `num_dimensions` | The number of dimensions to index. By default, all dimensions are indexed. But you can also index less dimensions to make use of [Matryoshka embeddings](https://huggingface.co/blog/matryoshka) | 0 (all dimensions)
| `num_bits_per_dimension` | Number of bits used to encode each dimension when using SBQ | 2 for less than 900 dimensions, 1 otherwise

An example of how to set the `num_neighbors` parameter is:

```sql
CREATE INDEX document_embedding_idx ON document_embedding
USING diskann (embedding) WITH(num_neighbors=50);
```

An example of creating an index with label-based filtering:

```sql
CREATE INDEX document_embedding_idx ON document_embedding
USING diskann (embedding vector_cosine_ops, labels);
```

#### Parallel Index Build Parameters

pgvectorscale supports parallel index building to improve performance on large datasets. These parameters control parallel build behavior:

| Parameter name   | Description                                                                                                                                                    | Default value |
|------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|
| `diskann.parallel_flush_interval` | The fraction of total vectors (0.0-1.0) processed before flushing neighbor cache in parallel builds | 0.1 |
| `diskann.parallel_initial_start_nodes_count` | The number of initial start nodes to process before starting parallel workers | 1024 |
| `diskann.min_vectors_for_parallel_build` | Minimum number of vectors required to enable parallel building | 65536 |
| `diskann.force_parallel_workers` | Force a specific number of parallel workers for index builds (-1 for automatic) | -1 |

Parallel building is automatically enabled when:
- The feature is compiled in (enabled by default)
- The table has no labels (label-based filtering not yet supported in parallel)
- Using SBQ compression storage layout
- The number of vectors meets the `min_vectors_for_parallel_build` threshold

You can set these parameters using `SET` before creating an index:

```sql
-- Enable parallel building for smaller datasets
SET diskann.min_vectors_for_parallel_build = 10000;

-- Use 4 parallel workers regardless of PostgreSQL&#039;s automatic determination
SET diskann.force_parallel_workers = 4;

-- Adjust cache flushing frequency for memory usage (flush after processing 5% of vectors)
SET diskann.parallel_flush_interval = 0.05;

CREATE INDEX ON my_table USING diskann (embedding vector_cosine_ops);
```

#### StreamingDiskANN query-time parameters

You can also set two parameters to control the accuracy vs. query speed trade-off at query time. We suggest adjusting `diskann.query_rescore` to fine-tune accuracy.

| Parameter name   | Description                                                                                                                                                    | Default value |
|------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|
| `diskann.query_search_list_size` | The number of additional candidates considered during the graph search. | 100
| `diskann.query_rescore` | The number of elements rescored (0 to disable rescoring) | 50


You can set the value by using `SET` before executing a query. For example:

```sql
SET diskann.query_rescore = 400;
```

Note the [SET command](https://www.postgresql.org/docs/current/sql-set.html) applies to the entire session (database connection) from the point of execution. You can use a transaction-local variant using `LOCAL` which will
be reset after the end of the transaction:

```sql
BEGIN;
SET LOCAL diskann.query_search_list_size= 10;
SELECT * FROM document_embedding ORDER BY embedding &lt;=&gt; $1 LIMIT 10
COMMIT;
```

## Null Value Handling

* Null vectors are not indexed
* Null labels are treated as empty arrays
* Null values in label arrays are ignored

## ORDER BY vector distance

pgvectorscale&#039;s diskann index uses relaxed ordering which allows results to be
slightly out of order by distance. This is analogous to using
[`iterative scan with relaxed ordering`][pgvector-iterative-index-scan] with
pgvector&#039;s ivfflat or hnsw indexes.

If you need strict ordering you can use a [materialized CTE][materialized-cte]:

```sql
WITH relaxed_results AS MATERIALIZED (
    SELECT id, embedding &lt;=&gt; &#039;[1,2,3]&#039; AS distance
    FROM items
    WHERE category_id = 123
    ORDER BY distance
    LIMIT 5
) SELECT * FROM relaxed_results ORDER BY distance;
```

## Index on an UNLOGGED table

Creating an index on an UNLOGGED table is currently not supported.
Trying will yield the error:

```
ERROR:  ambuildempty: not yet implemented
```

## Get involved

pgvectorscale is still at an early stage. Now is a great time to help shape the
direction of this project; we are currently deciding priori

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tensorchord/VectorChord]]></title>
            <link>https://github.com/tensorchord/VectorChord</link>
            <guid>https://github.com/tensorchord/VectorChord</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Scalable, fast, and disk-friendly vector search in Postgres, the successor of pgvecto.rs.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tensorchord/VectorChord">tensorchord/VectorChord</a></h1>
            <p>Scalable, fast, and disk-friendly vector search in Postgres, the successor of pgvecto.rs.</p>
            <p>Language: Rust</p>
            <p>Stars: 1,269</p>
            <p>Forks: 42</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;h1 align=center&gt;VectorChord&lt;/h1&gt;
&lt;h4 align=center&gt;Effortlessly host 100 million 768-dimensional vectors (250GB+) on an AWS i4i.xlarge instance ($250/month), featuring 4 vCPUs and 32GB of RAM with VectorChord.&lt;/h4&gt;
&lt;/div&gt;

&lt;div align=center&gt;


[Official Site][official-site-link] ¬∑ [Blog][blog-link] ¬∑ [Docs][docs-link] ¬∑ [Feedback][github-issues-link] ¬∑ [Contact Us][email-link]


[![][github-release-shield]][github-release-link]
[![][docker-release-shield]][docker-release-link]
[![][docker-pulls-shield]][docker-pulls-link]
[![][ghcr-release-shield]][ghcr-release-link]
[![][github-downloads-shield]][github-downloads-link]
[![][discord-shield]][discord-link]
[![][X-shield]][X-link]
[![][cloud-shield]][cloud-link]
[![][deepwiki-shield]][deepwiki-link]
[![][license-1-shield]][license-1-link]
[![][license-2-shield]][license-2-link]
&lt;/div&gt;


&gt; [!NOTE]
&gt; VectorChord serves as the successor to [pgvecto.rs](https://github.com/tensorchord/pgvecto.rs) [![][previous-docker-pulls-shield]][previous-docker-pulls-link] with better stability and performance. If you are interested in this new solution, you may find the [migration guide](https://docs.vectorchord.ai/vectorchord/admin/migration.html) helpful.

VectorChord (vchord) is a PostgreSQL extension designed for scalable, high-performance, and disk-efficient vector similarity search.

With VectorChord, you can store 400,000 vectors for just $1, enabling significant savings: 6x more vectors compared to Pinecone&#039;s optimized storage and 26x more than pgvector/pgvecto.rs for the same price[^1].

![][image-compare]

## Features

VectorChord introduces remarkable enhancements over pgvecto.rs and pgvector:

**‚ö° Enhanced Performance**: Delivering optimized operations with up to 5x faster queries, 16x higher insert throughput, and 16x quicker[^1] index building compared to pgvector&#039;s HNSW implementation.

[^1]: Based on [MyScale Benchmark](https://myscale.github.io/benchmark/) with 768-dimensional vectors and 95% recall. Please checkout our [blog post](https://blog.vectorchord.ai/vectorchord-store-400k-vectors-for-1-in-postgresql) for more details.

**üí∞ Affordable Vector Search**: Query 100M 768-dimensional vectors using just 32GB of memory, achieving 35ms P50 latency with top10 recall@95%, helping you keep infrastructure costs down while maintaining high search quality.

**üîå Seamless Integration**: Fully compatible with pgvector data types and syntax while providing optimal defaults out of the box - no manual parameter tuning needed. Just drop in VectorChord for enhanced performance.

**üîß Accelerated Index Build**: Leverage IVF to build indexes externally (e.g., on GPU) for faster KMeans clustering, combined with RaBitQ[^2] compression to efficiently store vectors while maintaining search quality through autonomous reranking.

[^2]: Gao, Jianyang, and Cheng Long. &quot;RaBitQ: Quantizing High-Dimensional Vectors with a Theoretical Error Bound for Approximate Nearest Neighbor Search.&quot; Proceedings of the ACM on Management of Data 2.3 (2024): 1-27.

**üìè Long Vector Support**: Store and search vectors up to 60,000[^3] dimensions, enabling the use of the best high-dimensional models like text-embedding-3-large with ease.

[^3]: There is a [limitation](https://github.com/pgvector/pgvector#vector-type) at pgvector of 16,000 dimensions now. If you really have a large dimension(`16,000&lt;dim&lt;60,000`), consider changing [VECTOR_MAX_DIM](https://github.com/pgvector/pgvector/blob/fef635c9e5512597621e5669dce845c744170822/src/vector.h#L4) and compile pgvector yourself.

**üåê Scale As You Want**: Based on horizontal expansion, the query of 5M / 100M 768-dimensional vectors can be easily scaled to 10000+ QPS with top10 recall@90% at a competitive cost[^4]

[^4]: Please check our [blog post](https://blog.vectorchord.ai/vector-search-at-10000-qps-in-postgresql-with-vectorchord)  for more details, the PostgreSQL scalability is powered by [CloudNative-PG](https://github.com/cloudnative-pg/cloudnative-pg).

**üè≠ Production Proven**: Deployed in mission-critical environments, VectorChord ‚Äã‚Äãreliably handles 3B+ vectors‚Äã‚Äã in production with consistent performance. Please check out [3B vectors in PostgreSQL to Protect the Earth](https://blog.vectorchord.ai/3-billion-vectors-in-postgresql-to-protect-the-earth).

## Quick Start

For new users, we recommend using the Docker image to get started quickly. If you do not prefer Docker, please read [installation guide](https://docs.vectorchord.ai/vectorchord/getting-started/installation.html) for other installation methods.

```bash
docker run \
  --name vectorchord-demo \
  -e POSTGRES_PASSWORD=mysecretpassword \
  -p 5432:5432 \
  -d ghcr.io/tensorchord/vchord-postgres:pg18-v0.5.3
```
&gt; [!NOTE]
&gt; In addition to the base image with the VectorChord extension, we provide an all-in-one image, `tensorchord/vchord-suite:pg17-latest`. This comprehensive image includes all official TensorChord extensions, including `VectorChord`, `VectorChord-bm25` and `pg_tokenizer.rs` . Developers should select an image tag that is compatible with their extension&#039;s version, as indicated in [the support matrix](https://github.com/tensorchord/VectorChord-images?tab=readme-ov-file#support-matrix).

Then you can connect to the database using the `psql` command line tool. The default username is `postgres`, and the default password is `mysecretpassword`.

```bash
psql -h localhost -p 5432 -U postgres
```

Now you can play with VectorChord!

VectorChord depends on pgvector, including the vector representation. Since you can use them directly, your application can be easily migrated without pain!

```sql
CREATE EXTENSION IF NOT EXISTS vchord CASCADE;
```

Similar to pgvector, you can create a table with vector column and insert some rows to it.

```sql
CREATE TABLE items (id bigserial PRIMARY KEY, embedding vector(3));
INSERT INTO items (embedding) SELECT ARRAY[random(), random(), random()]::real[] FROM generate_series(1, 1000);
```

With VectorChord, you can create `vchordrq` indexes.

```SQL
CREATE INDEX ON items USING vchordrq (embedding vector_l2_ops);
```

And then perform a vector search using `SELECT ... ORDER BY ... LIMIT ...`.

```SQL
SELECT * FROM items ORDER BY embedding &lt;-&gt; &#039;[3,1,2]&#039; LIMIT 5;
```

For more usage, please read:

- [Indexing](https://docs.vectorchord.ai/vectorchord/usage/indexing.html)
- [Multi-Vector Retrieval](https://docs.vectorchord.ai/vectorchord/usage/indexing-with-maxsim-operators.html)
- [Graph Index](https://docs.vectorchord.ai/vectorchord/usage/graph-index.html)
- [Similarity Filter](https://docs.vectorchord.ai/vectorchord/usage/range-query.html)
- [PostgreSQL Tuning](https://docs.vectorchord.ai/vectorchord/usage/performance-tuning.html)
- [Monitoring](https://docs.vectorchord.ai/vectorchord/usage/monitoring.html)
- [Measure Recall](https://docs.vectorchord.ai/vectorchord/usage/measure-recall.html)
- [Prewarm](https://docs.vectorchord.ai/vectorchord/usage/prewarm.html)
- [Prefilter](https://docs.vectorchord.ai/vectorchord/usage/prefilter.html)
- [Prefetch](https://docs.vectorchord.ai/vectorchord/usage/prefetch.html)
- [Rerank In Table](https://docs.vectorchord.ai/vectorchord/usage/rerank-in-table.html)
- [External Build](https://docs.vectorchord.ai/vectorchord/usage/external-index-precomputation.html)

## License

This software is licensed under a dual license model:

1. **GNU Affero General Public License v3 (AGPLv3)**: You may use, modify, and distribute this software under the terms of the AGPLv3.

2. **Elastic License v2 (ELv2)**: You may also use, modify, and distribute this software under the Elastic License v2, which has specific restrictions.

You may choose either license based on your needs. We welcome any commercial collaboration or support, so please email us &lt;vectorchord-inquiry@tensorchord.ai&gt; with any questions or requests regarding the licenses.

[image-compare]: https://github.com/user-attachments/assets/2d985f1e-7093-4c3a-8bf3-9f0b92c0e7e7
[license-1-link]: https://github.com/tensorchord/VectorChord#license
[license-1-shield]: https://img.shields.io/badge/License-AGPLv3-green?logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0IiBoZWlnaHQ9IjI0IiBmaWxsPSIjZmZmZmZmIj48cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xMi43NSAyLjc1YS43NS43NSAwIDAwLTEuNSAwVjQuNUg5LjI3NmExLjc1IDEuNzUgMCAwMC0uOTg1LjMwM0w2LjU5NiA1Ljk1N0EuMjUuMjUgMCAwMTYuNDU1IDZIMi4zNTNhLjc1Ljc1IDAgMTAwIDEuNUgzLjkzTC41NjMgMTUuMThhLjc2Mi43NjIgMCAwMC4yMS44OGMuMDguMDY0LjE2MS4xMjUuMzA5LjIyMS4xODYuMTIxLjQ1Mi4yNzguNzkyLjQzMy42OC4zMTEgMS42NjIuNjIgMi44NzYuNjJhNi45MTkgNi45MTkgMCAwMDIuODc2LS42MmMuMzQtLjE1NS42MDYtLjMxMi43OTItLjQzMy4xNS0uMDk3LjIzLS4xNTguMzEtLjIyM2EuNzUuNzUgMCAwMC4yMDktLjg3OEw1LjU2OSA3LjVoLjg4NmMuMzUxIDAgLjY5NC0uMTA2Ljk4NC0uMzAzbDEuNjk2LTEuMTU0QS4yNS4yNSAwIDAxOS4yNzUgNmgxLjk3NXYxNC41SDYuNzYzYS43NS43NSAwIDAwMCAxLjVoMTAuNDc0YS43NS43NSAwIDAwMC0xLjVIMTIuNzVWNmgxLjk3NGMuMDUgMCAuMS4wMTUuMTQuMDQzbDEuNjk3IDEuMTU0Yy4yOS4xOTcuNjMzLjMwMy45ODQuMzAzaC44ODZsLTMuMzY4IDcuNjhhLjc1Ljc1IDAgMDAuMjMuODk2Yy4wMTIuMDA5IDAgMCAuMDAyIDBhMy4xNTQgMy4xNTQgMCAwMC4zMS4yMDZjLjE4NS4xMTIuNDUuMjU2Ljc5LjRhNy4zNDMgNy4zNDMgMCAwMDIuODU1LjU2OCA3LjM0MyA3LjM0MyAwIDAwMi44NTYtLjU2OWMuMzM4LS4xNDMuNjA0LS4yODcuNzktLjM5OWEzLjUgMy41IDAgMDAuMzEtLjIwNi43NS43NSAwIDAwLjIzLS44OTZMMjAuMDcgNy41aDEuNTc4YS43NS43NSAwIDAwMC0xLjVoLTQuMTAyYS4yNS4yNSAwIDAxLS4xNC0uMDQzbC0xLjY5Ny0xLjE1NGExLjc1IDEuNzUgMCAwMC0uOTg0LS4zMDNIMTIuNzVWMi43NXpNMi4xOTMgMTUuMTk4YTUuNDE4IDUuNDE4IDAgMDAyLjU1Ny42MzUgNS40MTggNS40MTggMCAwMDIuNTU3LS42MzVMNC43NSA5LjM2OGwtMi41NTcgNS44M3ptMTQuNTEtLjAyNGMuMDgyLjA0LjE3NC4wODMuMjc1LjEyNi41My4yMjMgMS4zMDUuNDUgMi4yNzIuNDVhNS44NDYgNS44NDYgMCAwMDIuNTQ3LS41NzZMMTkuMjUgOS4zNjdsLTIuNTQ3IDUuODA3eiI+PC9wYXRoPjwvc3ZnPgo=
[license-2-link]: https://github.com/tensorchord/VectorChord#license
[license-2-shield]: https://img.shields.io/badge/License-ELv2-green?logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCAyNCAyNCIgd2lkdGg9IjI0IiBoZWlnaHQ9IjI0IiBmaWxsPSIjZmZmZmZmIj48cGF0aCBmaWxsLXJ1bGU9ImV2ZW5vZGQiIGQ9Ik0xMi43NSAyLjc1YS43NS43NSAwIDAwLTEuNSAwVjQuNUg5LjI3NmExLjc1IDEuNzUgMCAwMC0uOTg1LjMwM0w2LjU5NiA1Ljk1N0EuMjUuMjUgMCAwMTYuNDU1IDZIMi4zNTNhLjc1Ljc1IDAgMTAwIDEuNUgzLjkzTC41NjMgMTUuMThhLjc2Mi43NjIgMCAwMC4yMS44OGMuMDguMDY0LjE2MS4xMjUuMzA5LjIyMS4xODYuMTIxLjQ1Mi4yNzguNzkyLjQzMy42OC4zMTEgMS42NjIuNjIgMi44NzYuNjJhNi45MTkgNi45MTkgMCAwMDIuODc2LS42MmMuMzQtLjE1NS42MDYtLjMxMi43OTItLjQzMy4xNS0uMDk3LjIzLS4xNTguMzEtLjIyM2EuNzUuNzUgMCAwMC4yMDktLjg3OEw1LjU2OSA3LjVoLjg4NmMuMzUxIDAgLjY5NC0uMTA2Ljk4NC0uMzAzbDEuNjk2LTEuMTU0QS4yNS4yNSAwIDAxOS4yNzUgNmgxLjk3NXYxNC41SDYuNzYzYS43NS43NSAwIDAwMCAxLjVoMTAuNDc0YS43NS43NSAwIDAwMC0xLjVIMTIuNzVWNmgxLjk3NGMuMDUgMCAuMS4wMTUuMTQuMDQzbDEuNjk3IDEuMTU0Yy4yOS4xOTcuNjMzLjMwMy45ODQuMzAzaC44ODZsLTMuMzY4IDcuNjhhLjc1Ljc1IDAgMDAuMjMuODk2Yy4wMTIuMDA5IDAgMCAuMDAyIDBhMy4xNTQgMy4xNTQgMCAwMC4zMS4yMDZjLjE4NS4xMTIuNDUuMjU2Ljc5LjRhNy4zNDMgNy4zNDMgMCAwMDIuODU1LjU2OCA3LjM0MyA3LjM0MyAwIDAwMi44NTYtLjU2OWMuMzM4LS4xNDMuNjA0LS4yODcuNzktLjM5OWEzLjUgMy41IDAgMDAuMzEtLjIwNi43NS43NSAwIDAwLjIzLS44OTZMMjAuMDcgNy41aDEuNTc4YS43NS43NSAwIDAwMC0xLjVoLTQuMTAyYS4yNS4yNSAwIDAxLS4xNC0uMDQzbC0xLjY5Ny0xLjE1NGExLjc1IDEuNzUgMCAwMC0uOTg0LS4zMDNIMTIuNzVWMi43NXpNMi4xOTMgMTUuMTk4YTUuNDE4IDUuNDE4IDAgMDAyLjU1Ny42MzUgNS40MTggNS40MTggMCAwMDIuNTU3LS42MzVMNC43NSA5LjM2OGwtMi41NTcgNS44M3ptMTQuNTEtLjAyNGMuMDgyLjA0LjE3NC4wODMuMjc1LjEyNi41My4yMjMgMS4zMDUuNDUgMi4yNzIuNDVhNS44NDYgNS44NDYgMCAwMDIuNTQ3LS41NzZMMTkuMjUgOS4zNjdsLTIuNTQ3IDUuODA3eiI+PC9wYXRoPjwvc3ZnPgo=

[docker-release-link]: https://hub.docker.com/r/tensorchord/vchord-postgres
[docker-release-shield]: https://img.shields.io/docker/v/tensorchord/vchord-postgres?color=369eff&amp;label=docker&amp;labelColor=black&amp;logo=docker&amp;logoColor=white&amp;style=flat
[github-release-link]: https://github.com/tensorchord/VectorChord/releases
[github-release-shield]: https://img.shields.io/github/v/release/tensorchord/VectorChord?color=369eff&amp;labelColor=black&amp;logo=github&amp;style=flat
[ghcr-release-link]: https://github.com/orgs/tensorchord/packages/container/package/vchord-postgres
&lt;!-- GHCR badge is not supported by shields.io yet, use docker badge instead --&gt;
[ghcr-release-shield]: https://img.shields.io/docker/v/tensorchord/vchord-postgres?color=369eff&amp;label=GHCR&amp;labelColor=black&amp;logo=github&amp;logoColor=white&amp;style=flat
[docker-pulls-link]: https://hub.docker.com/r/tensorchord/vchord-postgres
[docker-pulls-shield]: https://img.shields.io/docker/pulls/tensorchord/vchord-postgres?color=45cc11&amp;labelColor=black&amp;style=flat&amp;sort=semver
[previous-docker-pulls-link]: https://hub.docker.com/r/tensorchord/pgvecto-rs
[previous-docker-pulls-shield]: https://img.shields.io/docker/pulls/tensorchord/pgvecto-rs?color=45cc11&amp;labelColor=black&amp;style=flat&amp;sort=semver
[github-downloads-link]: https://github.com/tensorchord/VectorChord/releases
[github-downloads-shield]: https://img.shields.io/github/downloads/tensorchord/VectorChord/total?color=45cc11&amp;labelColor=black&amp;style=flat&amp;sort=semver
[discord-link]: https://discord.gg/KqswhpVgdU
[discord-shield]: https://img.shields.io/discord/974584200327991326?&amp;logoColor=white&amp;color=5865F2&amp;style=flat&amp;logo=discord&amp;cacheSeconds=60
[X-link]: https://x.com/TensorChord
[X-shield]: https://img.shields.io/badge/follow-%40tensorchord-1DA1F2?logo=x&amp;style=flat&amp;logoColor=white&amp;color=1da1f2
[cloud-link]: https://cloud.vectorchord.ai/
[cloud-shield]: https://img.shields.io/badge/VectorChord_Cloud-Try_For_Free-F2B263.svg?labelColor=DAFDBA&amp;logo=data:image/svg%2bxml;base64,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
[deepwiki-link]: https://deepwiki.com/tensorchord/VectorChord
[deepwiki-shield]: https://deepwiki.com/badge.svg
[blog-link]: https://blog.vectorchord.ai/
[official-site-link]: https://vectorchord.ai/
[github-issues-link]: https://github.com/tensorchord/VectorChord/issues
[email-link]: mailto:support@tensorchord.ai
[docs-link]: https://docs.vectorchord.ai/vectorchord/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lusingander/serie]]></title>
            <link>https://github.com/lusingander/serie</link>
            <guid>https://github.com/lusingander/serie</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[A rich git commit graph in your terminal, like magic üìö]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lusingander/serie">lusingander/serie</a></h1>
            <p>A rich git commit graph in your terminal, like magic üìö</p>
            <p>Language: Rust</p>
            <p>Stars: 1,225</p>
            <p>Forks: 26</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre># Serie

[![Crate Status](https://img.shields.io/crates/v/serie.svg)](https://crates.io/crates/serie)
[![Built With Ratatui](https://img.shields.io/badge/Built_With-Ratatui-000?logo=ratatui&amp;logoColor=fff&amp;labelColor=000&amp;color=fff)](https://ratatui.rs)

A rich git commit graph in your terminal, like magic üìö

&lt;img src=&quot;./img/demo.gif&quot;&gt;

(This demo shows [Ratatui](https://github.com/ratatui/ratatui) repository!)

## About

Serie (`/z√©Àêri…ô/`) is a TUI application that uses the terminal emulators&#039; image display protocol to render commit graphs like `git log --graph --all`.

### Why?

While some users prefer to use Git via CLI, they often rely on a GUI or feature-rich TUI to view commit logs. Others may find `git log --graph` sufficient.

Personally, I found the output from `git log --graph` difficult to read, even with additional options. Learning complex tools just to view logs seemed cumbersome.

### Goals

- Provide a rich `git log --graph` experience in the terminal.
- Offer commit graph-centric browsing of Git repositories.

### Non-Goals

- Implement a fully-featured Git client.
- Create a TUI application with a complex UI.
- Works in any terminal environment.

## Requirements

- Git
- Supported terminal emulator
  - Refer to [Compatibility](#compatibility) for details.

## Installation

### [Cargo](https://crates.io/crates/serie)

```
$ cargo install --locked serie
```

### [Arch Linux](https://archlinux.org/packages/extra/x86_64/serie/)

```
$ pacman -S serie
```

### [Homebrew](https://formulae.brew.sh/formula/serie)

```
$ brew install serie
```

or from [tap](https://github.com/lusingander/homebrew-tap/blob/master/serie.rb):

```
$ brew install lusingander/tap/serie
```

### [NetBSD](https://pkgsrc.se/devel/serie)

```
$ pkgin install serie
```

### Downloading binary

You can download pre-compiled binaries from [releases](https://github.com/lusingander/serie/releases).

### Build from source

If you want to check the latest development version, build from source:

```
$ git clone https://github.com/lusingander/serie.git
$ cd serie
$ cargo build --release # Unless it&#039;s a release build, it&#039;s very slow.
$ ./target/release/serie
```

## Usage

### Basic

Run `serie` in the directory where your git repository exists.

```
$ cd &lt;your git repository&gt;
$ serie
```

### Options

```
Serie - A rich git commit graph in your terminal, like magic üìö

Usage: serie [OPTIONS]

Options:
  -p, --protocol &lt;TYPE&gt;     Image protocol to render graph [default: auto] [possible values: auto, iterm, kitty]
  -o, --order &lt;TYPE&gt;        Commit ordering algorithm [default: chrono] [possible values: chrono, topo]
  -g, --graph-width &lt;TYPE&gt;  Commit graph image cell width [default: auto] [possible values: auto, double, single]
      --preload             Preload all graph images
  -h, --help                Print help
  -V, --version             Print version
```

#### -p, --protocol \&lt;TYPE\&gt;

A protocol type for rendering images of commit graphs.

By default `auto` will guess the best supported protocol for the current terminal (if listed in [Supported terminals](#supported-terminals)).

#### -o, --order \&lt;TYPE\&gt;

`--order chrono` will order commits by commit date if possible.

`--order topo` will order commits on the same branch consecutively if possible.

&lt;details&gt;
&lt;summary&gt;Screenshots&lt;/summary&gt;

&lt;img src=&quot;./img/order-chrono.png&quot; width=400&gt;

`--order chrono`

&lt;img src=&quot;./img/order-topo.png&quot; width=400&gt;

`--order topo`

&lt;/details&gt;

#### -g, --graph-width \&lt;TYPE\&gt;

The character width that a graph image unit cell occupies.

If not specified or `auto` is specified, `double` will be used automatically if there is enough width to display it, `single` otherwise.

&lt;details&gt;
&lt;summary&gt;Screenshots&lt;/summary&gt;

&lt;img src=&quot;./img/graph-width-double.png&quot; width=300&gt;

`--graph-width double`

&lt;img src=&quot;./img/graph-width-single.png&quot; width=300&gt;

`--graph-width single`

&lt;/details&gt;

#### --preload

By default, graph images are generated and loaded lazily as needed.

If `--preload` is specified, all graph images will be generated and loaded at startup. This can result in smoother scrolling, as the images are already available, and might reduce memory usage. However, this may lead to slower startup times, especially for large repositories.

### Keybindings

You can see the keybindings by pressing the `?` key.

The default key bindings can be overridden. Please refer to [default-keybind.toml](./assets/default-keybind.toml) and add it to [config file](#config).

&lt;details&gt;
&lt;summary&gt;List of all default keybindings&lt;/summary&gt;

#### Common

| Key                            | Description | Corresponding keybind |
| ------------------------------ | ----------- | --------------------- |
| &lt;kbd&gt;Ctrl-c&lt;/kbd&gt; &lt;kbd&gt;q&lt;/kbd&gt; | Quit app    | `force_quit` `quit`   |
| &lt;kbd&gt;?&lt;/kbd&gt;                   | Open help   | `help_toggle`         |

#### Commit List

| Key                                  | Description                                        | Corresponding keybind                        |
| ------------------------------------ | -------------------------------------------------- | -------------------------------------------- |
| &lt;kbd&gt;Down/Up&lt;/kbd&gt; &lt;kbd&gt;j/k&lt;/kbd&gt;    | Move down/up                                       | `navigate_down` `navigate_up`                |
| &lt;kbd&gt;Alt-Down&lt;/kbd&gt; &lt;kbd&gt;Alt-j&lt;/kbd&gt; | Move to parent commit                              | `go_to_parent`                               |
| &lt;kbd&gt;g/G&lt;/kbd&gt;                       | Go to top/bottom                                   | `go_to_top` `go_to_bottom`                   |
| &lt;kbd&gt;Ctrl-f/b&lt;/kbd&gt;                  | Scroll page down/up                                | `page_down` `page_up`                        |
| &lt;kbd&gt;Ctrl-d/u&lt;/kbd&gt;                  | Scroll half page down/up                           | `half_page_down` `half_page_up`              |
| &lt;kbd&gt;Ctrl-e/y&lt;/kbd&gt;                  | Scroll down/up                                     | `scroll_down` `scroll_up`                    |
| &lt;kbd&gt;H/M/L&lt;/kbd&gt;                     | Select top/middle/bottom of the screen             | `select_top` `select_middle` `select_bottom` |
| &lt;kbd&gt;Enter&lt;/kbd&gt;                     | Show commit details&lt;br&gt;Apply search (if searching) | `confirm`                                    |
| &lt;kbd&gt;Tab&lt;/kbd&gt;                       | Open refs list                                     | `ref_list_toggle`                            |
| &lt;kbd&gt;/&lt;/kbd&gt;                         | Start search                                       | `search`                                     |
| &lt;kbd&gt;Esc&lt;/kbd&gt;                       | Cancel search                                      | `cancel`                                     |
| &lt;kbd&gt;n/N&lt;/kbd&gt;                       | Go to next/previous search match                   | `go_to_next` `go_to_previous`                |
| &lt;kbd&gt;Ctrl-g&lt;/kbd&gt;                    | Toggle ignore case (if searching)                  | `ignore_case_toggle`                         |
| &lt;kbd&gt;Ctrl-x&lt;/kbd&gt;                    | Toggle fuzzy match (if searching)                  | `fuzzy_toggle`                               |
| &lt;kbd&gt;c/C&lt;/kbd&gt;                       | Copy commit short/full hash                        | `short_copy` `full_copy`                     |
| &lt;kbd&gt;d&lt;/kbd&gt;                         | Toggle custom user command view                    | `user_command_view_toggle_1`                 |

#### Commit Detail

| Key                                 | Description                     | Corresponding keybind           |
| ----------------------------------- | ------------------------------- | ------------------------------- |
| &lt;kbd&gt;Esc&lt;/kbd&gt; &lt;kbd&gt;Backspace&lt;/kbd&gt; | Close commit details            | `close` `cancel`                |
| &lt;kbd&gt;Down/Up&lt;/kbd&gt; &lt;kbd&gt;j/k&lt;/kbd&gt;   | Scroll down/up                  | `navigate_down` `navigate_up`   |
| &lt;kbd&gt;Ctrl-f/b&lt;/kbd&gt;                 | Scroll page down/up             | `page_down` `page_up`           |
| &lt;kbd&gt;Ctrl-d/u&lt;/kbd&gt;                 | Scroll half page down/up        | `half_page_down` `half_page_up` |
| &lt;kbd&gt;g/G&lt;/kbd&gt;                      | Go to top/bottom                | `go_to_top` `go_to_bottom`      |
| &lt;kbd&gt;c/C&lt;/kbd&gt;                      | Copy commit short/full hash     | `short_copy` `full_copy`        |
| &lt;kbd&gt;d&lt;/kbd&gt;                        | Toggle custom user command view | `user_command_view_toggle_1`    |

#### Refs List

| Key                                                | Description      | Corresponding keybind              |
| -------------------------------------------------- | ---------------- | ---------------------------------- |
| &lt;kbd&gt;Esc&lt;/kbd&gt; &lt;kbd&gt;Backspace&lt;/kbd&gt; &lt;kbd&gt;Tab&lt;/kbd&gt; | Close refs list  | `close` `cancel` `ref_list_toggle` |
| &lt;kbd&gt;Down/Up&lt;/kbd&gt; &lt;kbd&gt;j/k&lt;/kbd&gt;                  | Move down/up     | `navigate_down` `navigate_up`      |
| &lt;kbd&gt;g/G&lt;/kbd&gt;                                     | Go to top/bottom | `go_to_top` `go_to_bottom`         |
| &lt;kbd&gt;Right/Left&lt;/kbd&gt; &lt;kbd&gt;l/h&lt;/kbd&gt;               | Open/Close node  | `navigate_right` `navigate_left`   |
| &lt;kbd&gt;c&lt;/kbd&gt;                                       | Copy ref name    | `short_copy`                       |

#### User Command

| Key                                              | Description              | Corresponding keybind           |
| ------------------------------------------------ | ------------------------ | ------------------------------- |
| &lt;kbd&gt;Esc&lt;/kbd&gt; &lt;kbd&gt;Backspace&lt;/kbd&gt; &lt;kbd&gt;?&lt;/kbd&gt; | Close user command       | `close` `cancel` `help_toggle`  |
| &lt;kbd&gt;Down/Up&lt;/kbd&gt; &lt;kbd&gt;j/k&lt;/kbd&gt;                | Scroll down/up           | `navigate_down` `navigate_up`   |
| &lt;kbd&gt;Ctrl-f/b&lt;/kbd&gt;                              | Scroll page down/up      | `page_down` `page_up`           |
| &lt;kbd&gt;Ctrl-d/u&lt;/kbd&gt;                              | Scroll half page down/up | `half_page_down` `half_page_up` |
| &lt;kbd&gt;g/G&lt;/kbd&gt;                                   | Go to top/bottom         | `go_to_top` `go_to_bottom`      |

#### Help

| Key                                              | Description              | Corresponding keybind           |
| ------------------------------------------------ | ------------------------ | ------------------------------- |
| &lt;kbd&gt;Esc&lt;/kbd&gt; &lt;kbd&gt;Backspace&lt;/kbd&gt; &lt;kbd&gt;?&lt;/kbd&gt; | Close help               | `close` `cancel` `help_toggle`  |
| &lt;kbd&gt;Down/Up&lt;/kbd&gt; &lt;kbd&gt;j/k&lt;/kbd&gt;                | Scroll down/up           | `navigate_down` `navigate_up`   |
| &lt;kbd&gt;Ctrl-f/b&lt;/kbd&gt;                              | Scroll page down/up      | `page_down` `page_up`           |
| &lt;kbd&gt;Ctrl-d/u&lt;/kbd&gt;                              | Scroll half page down/up | `half_page_down` `half_page_up` |
| &lt;kbd&gt;g/G&lt;/kbd&gt;                                   | Go to top/bottom         | `go_to_top` `go_to_bottom`      |

&lt;/details&gt;

### Config

Config files are loaded in the following order of priority:

- `$SERIE_CONFIG_FILE`
  - If `$SERIE_CONFIG_FILE` is set but the file does not exist, an error occurs.
- `$XDG_CONFIG_HOME/serie/config.toml`
  - If `$XDG_CONFIG_HOME` is not set, `~/.config/` will be used instead.

If the config file does not exist, the default values will be used for all items.
If the config file exists but some items are not set, the default values will be used for those unset items.

&lt;details&gt;
&lt;summary&gt;Config file details&lt;/summary&gt;

#### Config file format

The values set in this example are the default values.

```toml
[core.option]
# The protocol type for rendering images of commit graphs.
# The value specified in the command line argument takes precedence.
# type: enum (possible values: &quot;auto&quot;, &quot;iterm&quot;, &quot;kitty&quot;)
protocol = &quot;auto&quot;
# The commit ordering algorithm.
# The value specified in the command line argument takes precedence.
# type: enum (possible values: &quot;chrono&quot;, &quot;topo&quot;)
order = &quot;chrono&quot;
# The character width that a graph image unit cell occupies.
# The value specified in the command line argument takes precedence.
# type: enum (possible values: &quot;auto&quot;, &quot;double&quot;, &quot;single&quot;)
graph_width = &quot;auto&quot;

[core.search]
# Whether to enable ignore case by default.
# type: boolean
ignore_case = false
# Whether to enable fuzzy matching by default.
# type: boolean
fuzzy = false

[core.user_command]
# The command definition for generating the content displayed in the user command view.
# Multiple commands can be specified in the format commands_{n}.
# For details about user command, see the separate User command section.
# type: object
commands_1 = { name = &quot;git diff&quot;, commands = [&quot;git&quot;, &quot;--no-pager&quot;, &quot;diff&quot;, &quot;--color=always&quot;, &quot;{{first_parent_hash}}&quot;, &quot;{{target_hash}}&quot;]}
# The number of spaces to replace tabs in the user command output.
# type: u16
tab_width = 4

[ui.common]
# The type of a cursor to display in the input.
# If `cursor_type = &quot;Native&quot;` is set, the terminal native cursor is used.
# If `cursor_type = { &quot;Virtual&quot; = &quot;|&quot; }` is set, a virtual cursor with the specified string will be used.
# type: enum
cursor_type = &quot;Native&quot;

[ui.list]
# The minimum width of a subject in the commit list.
# type: u16
subject_min_width = 20
# The date format of a author date in the commit list.
# The format must be specified in strftime format.
# https://docs.rs/chrono/latest/chrono/format/strftime/index.html
# type: string
date_format = &quot;%Y-%m-%d&quot;
# The width of a author date in the commit list.
# type: u16
date_width = 10
# Whether to show a author date in the commit list in local timezone.
# type: boolean
date_local = true
# The width of a author name in the commit list.
# type: u16
name_width = 20

[ui.detail]
# The height of a commit detail area.
# type: u16
height = 20
# The date format of a author/committer date in the commit detail.
# The format must be specified in strftime format.
# https://docs.rs/chrono/latest/chrono/format/strftime/index.html
# type: string
date_format = &quot;%Y-%m-%d %H:%M:%S %z&quot;
# Whether to show a author/committer date in the commit list in local timezone.
# type: boolean
date_local = true

[ui.user_command]
# The height of a user command area.
# type: u16
height = 20

[ui.refs]
# The width of a refs list area.
# type: u16
width = 26

[graph.color]
# Colors should be specified in the format #RRGGBB or #RRGGBBAA.

# Array of colors used for the commit graph.
# type: array of strings
branches = [
  &quot;#E06C76&quot;,
  &quot;#98C379&quot;,
  &quot;#E5C07B&quot;,
  &quot;#61AFEF&quot;,
  &quot;#C678DD&quot;,
  &quot;#56B6C2&quot;,
]
# Color of the edge surrounding the commit circles in the graph.
# type: string
edge = &quot;#00000000&quot;
# Background color of the commit graph.
# type: string
background = &quot;#00000000&quot;

[color]
# The colors of each element of the application.
# Note: Graph colors are specified with [graph.color].
#
# Colors should be specified in one of the following formats:
# - ANSI color name
#   - &quot;red&quot;, &quot;bright-blue&quot;, &quot;light-red&quot;, &quot;reset&quot;, ...
# - 8-bit color (256-color) index values
#   - &quot;34&quot;, &quot;128&quot;, &quot;255&quot;, ...
# - 24-bit true color hex codes
#   - &quot;#abcdef&quot;, ...
# type: string
fg = &quot;reset&quot;
bg = &quot;reset&quot;
list_selected_fg = &quot;white&quot;
list_selected_bg = &quot;dark-gray&quot;
list_ref_paren_fg = &quot;yellow&quot;
list_ref_branch_fg = &quot;green&quot;
list_ref_remote_branch_fg = &quot;red&quot;
list_ref_tag_fg = &quot;yellow&quot;
list_ref_stash_fg = &quot;magenta&quot;
list_head_fg = &quot;cyan&quot;
list_subject_fg = &quot;reset&quot;
list_name_fg = &quot;cyan&quot;
list_hash_fg = &quot;yellow&quot;
list_date_fg = &quot;magenta&quot;
list_match_fg = &quot;black&quot;
list_match_bg = &quot;yellow&quot;
detail_email_fg = &quot;blue&quot;
detail_ref_branch_fg = &quot;green&quot;
detail_ref_remote_branch_fg = &quot;red&quot;
detail_ref_tag_fg = &quot;yellow&quot;
detail_file_change_add_fg = &quot;green&quot;
detail_file_change_modify_fg = &quot;yellow&quot;
detail_file_change_delete_fg = &quot;red&quot;
detail_file_change_move_fg = &quot;magenta&quot;
ref_selected_fg = &quot;white&quot;
ref_selected_bg = &quot;dark-gray&quot;
help_block_title_fg = &quot;green&quot;
help_key_fg = &quot;yellow&quot;
virtual_cursor_fg = &quot;reset&quot;
status_input_fg = &quot;reset&quot;
status_input_transient_fg = &quot;dark-gray&quot;
status_info_fg = &quot;cyan&quot;
status_success_fg = &quot;green&quot;
status_warn_fg = &quot;yellow&quot;
status_error_fg = &quot;red&quot;
divider_fg = &quot;dark-gray&quot;

[keybind]
# See ./assets/default-keybind.toml for a specific example configuration.
# ...
```

&lt;/details&gt;

### User command

The User command view allows you to display the output (stdout) of your custom external commands.
This allows you to do things like view commit diffs using your favorite tools.

To define a user command, you need to configure the following two settings:
- Keybinding definition. Specify the key to display each user command.
  - Config: `keybind.user_command_view_toggle_{n}`
- Command definition. Specify the actual command you want to execute.
  - Config: `core.user_command.commands_{n}`

&lt;details&gt;
&lt;summary&gt;Configuration example&lt;/summary&gt;

```toml
[keybind]
user_command_view_toggle_1 = [&quot;d&quot;]
user_command_view_toggle_2 = [&quot;shift-d&quot;]

[core.user_command]
commands_1 = { &quot;name&quot; = &quot;git diff&quot;, commands = [&quot;git&quot;, &quot;--no-pager&quot;, &quot;diff&quot;, &quot;--color=always&quot;, &quot;{{first_parent_hash}}&quot;, &quot;{{target_hash}}&quot;] }
commands_2 = { &quot;name&quot; = &quot;xxx&quot;, commands = [&quot;xxx&quot;, &quot;{{first_parent_hash}}&quot;, &quot;{{target_hash}}&quot;, &quot;--width&quot;, &quot;{{area_width}}&quot;, &quot;--height&quot;, &quot;{{area_height}}&quot;] }
```

&lt;/details&gt;

#### Variables

The following variables can be used in command definitions.
They will be replaced with their respective values command is executed.

- `{{target_hash}}`
  - The hash of the selected commit.
  - example: `b0ce4cb9c798576af9b4accc9f26ddce5e72063d`
- `{{first_parent_hash}}`
  - The hash of the first parent of the selected commit.
  - example: `c103d9744df8ebf100773a11345f011152ec5581`
- `{{area_width}}`
  - Width of the user command display area (number of cells).
  - example: `80`
- `{{area_height}}`
  - Height of the user command display area (number of cells).
  - example: `30`

## Compatibility

### Supported terminals

These image protocols are supported:

- [Inline Images Protocol (iTerm2)](https://iterm2.com/documentation-images.html)
- [Terminal graphics protocol (kitty)](https://sw.kovidgoyal.net/kitty/graphics-protocol/)

The terminals on which each has been confirmed to work are listed below.

#### Inline Images Protocol

| Terminal emulator                                                                   | Note                                                                                                                                         |
| ----------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------- |
| [iTerm2](https://iterm2.com)                                                        | But slower than other terminals                                                                                                              |
| [WezTerm](https://wezfurlong.org/wezterm/)                                          |                                                                                                                                              |
| [VSCode integrated terminal](https://code.visualstudio.com/docs/terminal/basics) \* | Requires the [`terminal.integrated.enableImages` setting](https://code.visualstudio.com/docs/terminal/advanced#_image-support) to be enabled |

\*Not only the VSCode integrated terminal, but any terminal emulator using [xterm.js](https://xtermjs.org) may basically work in the same way as long as [image display feature is enabled](https://github.com/xtermjs/xterm.js/tree/master/addons/addon-image).

#### Terminal graphics protocol

| Terminal emulator                         | Note |
| ----------------------------------------- | ---- |
| [kitty](https://sw.kovidgoyal.net/kitty/) |      |
| [Ghostty](https://ghostty.org)            |      |

### Unsupported environments

- Sixel graphics is not supported.
- Terminal multiplexers (screen, tmux, Zellij, etc.) are not supported.

## Contributing

To get started with contributing, please review [CONTRIBUTING.md](CONTRIBUTING.md).

Contributions that do not follow these guidelines may not be accepted.

## Scree

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[dfinity/ic]]></title>
            <link>https://github.com/dfinity/ic</link>
            <guid>https://github.com/dfinity/ic</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[Internet Computer blockchain source: the client/replica software run by nodes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dfinity/ic">dfinity/ic</a></h1>
            <p>Internet Computer blockchain source: the client/replica software run by nodes</p>
            <p>Language: Rust</p>
            <p>Stars: 1,691</p>
            <p>Forks: 366</p>
            <p>Stars today: 0 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[facebook/pyrefly]]></title>
            <link>https://github.com/facebook/pyrefly</link>
            <guid>https://github.com/facebook/pyrefly</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[A fast type checker and language server for Python]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/facebook/pyrefly">facebook/pyrefly</a></h1>
            <p>A fast type checker and language server for Python</p>
            <p>Language: Rust</p>
            <p>Stars: 4,220</p>
            <p>Forks: 176</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># Pyrefly: A fast type checker and language server for Python with powerful IDE features

[![pyrefly](https://img.shields.io/endpoint?url=https://pyrefly.org/badge.json)](https://github.com/facebook/pyrefly)
[![PyPI](https://img.shields.io/pypi/v/pyrefly.svg?color=blue)](https://pypi.python.org/pypi/pyrefly)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/Cf7mFQtW7W)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

Pyrefly is a type checker and language server for Python, which provides
lightning-fast type checking along with IDE features such as code navigation,
semantic highlighting, and code completion. It is available as a
[command-line tool](https://pyrefly.org/en/docs/installation/) and a
[VSCode extension](https://marketplace.visualstudio.com/items?itemName=meta.pyrefly).

See the [Pyrefly website](https://pyrefly.org) for full documentation and how to
add Pyrefly to your editor of choice.

Currently under active development with known issues. Please open an issue if
you find bugs.

### Getting Started

- Try out pyrefly in your browser: [Sandbox](https://pyrefly.org/sandbox/)
- Get the command-line tool: `pip install pyrefly`
- Get the VSCode extension:
  [Link](https://marketplace.visualstudio.com/items?itemName=meta.pyrefly)

### Key Features:

- Type Inference: Pyrefly infers types in most locations, apart from function
  parameters. It can infer types of variables and return types.
- Flow Types: Pyrefly can understand your program&#039;s control flow to refine
  static types.
- Incrementality: Pyrefly aims for large-scale incrementality at the module
  level, with optimized checking and parallelism.

## Getting Involved

If you have questions or would like to report a bug, please
[create an issue](https://github.com/facebook/pyrefly/issues).

See our
[contributing guide](https://github.com/facebook/pyrefly/blob/main/CONTRIBUTING.md)
for information on how to contribute to Pyrefly.

Join our [Discord](https://discord.com/invite/Cf7mFQtW7W) to chat about Pyrefly
and types. This is also where we hold biweekly office hours.

## Choices

There are a number of choices when writing a Python type checker. We are taking
inspiration from [Pyre1](https://pyre-check.org/),
[Pyright](https://github.com/microsoft/pyright) and
[MyPy](https://mypy.readthedocs.io/en/stable/). Some notable choices:

- We infer types in most locations, apart from parameters to functions. We do
  infer types of variables and return types. As an example,
  `def foo(x): return True` would result in something equivalent to had you
  written `def foo(x: Any) -&gt; bool: ...`.
- We attempt to infer the type of `[]` to however it is used first, then fix it
  after. For example `xs = []; xs.append(1); xs.append(&quot;&quot;)` will infer that
  `xs: List[int]` and then error on the final statement.
- We use flow types which refine static types, e.g. `x: int = 4` will both know
  that `x` has type `int`, but also that the immediately next usage of `x` will
  be aware the type is `Literal[4]`.
- We aim for large-scale incrementality (at the module level) and optimized
  checking with parallelism, aiming to use the advantages of Rust to keep the
  code a bit simpler.
- We expect large strongly connected components of modules, and do not attempt
  to take advantage of a DAG-shape in the source code.

## Code layout

Pyrefly is split into a number of crates (mostly under `crates/`):

- `pyrefly_util` are general purpose utilities, which have nothing to do with
  Python or type checking. Examples include IO wrappers, locking, command line
  helpers etc.
- `pyrefly_derive` are proc-macros for deriving traits such as `TypeEq` and
  `Visit`.
- `pyrefly_python` are Python utilities with no type-checking aspects, such as
  modelling modules or `sys.info`.
- `pyrefly_bundled` are the third-party
  [typeshed stubs](https://github.com/python/typeshed).
- `pyrefly_config` defines the Pyrefly configuration, along with support for
  reading Mypy/Pyright configuration.
- `pyrefly_types` defines the Pyrefly type along with operations on it.
- `pyrefly_wasm` defines the sandbox code that compiles to WASM.
- `pyrefly` itself is the type checker and everything else.

## Design

There are many nuances of design that change on a regular basis. But the basic
substrate on which the checker is built involves three steps:

1. Figure out what each module exports. That requires solving all `import *`
   statements transitively.
2. For each module in isolation, convert it to bindings, dealing with all
   statements and scope information (both static and flow).
3. Solve those bindings, which may require the solutions of bindings in other
   modules.

If we encounter unknowable information (e.g. recursion) we use `Type::Var` to
insert placeholders which are filled in later.

For each module, we solve the steps sequentially and completely. In particular,
we do not try and solve a specific identifier first (like
[Roslyn](https://github.com/dotnet/roslyn) or
[TypeScript](https://www.typescriptlang.org/)), and do not use fine-grained
incrementality (like [Rust Analyzer](https://github.com/rust-lang/rust-analyzer)
using [Salsa](https://github.com/salsa-rs/salsa)). Instead, we aim for raw
performance and a simpler module-centric design - there&#039;s no need to solve a
single binding in isolation if solving all bindings in a module is fast enough.

### Example of bindings

Given the program:

```python
1: x: int = 4
2: print(x)
```

We might produce the bindings:

- `define int@0` = `from builtins import int`
- `define x@1` = `4: int@0`
- `use x@2` = `x@1`
- `anon @2` = `print(x@2)`
- `export x` = `x@2`

Of note:

- The keys are things like `define` (the definition of something), `use` (a
  usage of a thing) and `anon` (a statement we need to type check, but don&#039;t
  care about the result of).
- In many cases the value of a key refers to other keys.
- Some keys are imported from other modules, via `export` keys and `import`
  values.
- In order to disambiguate identifiers we use the textual position at which they
  occur (in the example we&#039;ve used `@line`, but in reality it&#039;s the byte offset
  in the file).

### Example of `Var`

Given the program:

```python
1: x = 1
2: while test():
3:     x = x
4: print(x)
```

We end up with the bindings:

- `x@1` = `1`
- `x@3` = `phi(x@1, x@3)`
- `x@4` = `phi(x@1, x@3)`

The expression `phi` is the join point of the two values, e.g. `phi(int, str)`
would be `int | str`. We skip the distinction between `define` and `use`, since
it is not necessary for this example.

When solving `x@3` we encounter recursion. Operationally:

- We start solving `x@3`.
- That requires us to solve `x@1`.
- We solve `x@1` to be `Literal[1]`
- We start solving `x@3`. But we are currently solving `x@3`, so we invent a
  fresh `Var` (let&#039;s call it `?1`) and return that.
- We conclude that `x@3` must be `Literal[1] | ?1`.
- Since `?1` was introduced by `x@3` we record that `?1 = Literal[1] | ?1`. We
  can take the upper reachable bound of that and conclude that
  `?1 = Literal[1]`.
- We simplify `x@3` to just `Literal[1]`.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/rust-clippy]]></title>
            <link>https://github.com/rust-lang/rust-clippy</link>
            <guid>https://github.com/rust-lang/rust-clippy</guid>
            <pubDate>Thu, 06 Nov 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[A bunch of lints to catch common mistakes and improve your Rust code. Book: https://doc.rust-lang.org/clippy/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/rust-clippy">rust-lang/rust-clippy</a></h1>
            <p>A bunch of lints to catch common mistakes and improve your Rust code. Book: https://doc.rust-lang.org/clippy/</p>
            <p>Language: Rust</p>
            <p>Stars: 12,596</p>
            <p>Forks: 1,804</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre># Clippy

[![License: MIT OR Apache-2.0](https://img.shields.io/crates/l/clippy.svg)](#license)

A collection of lints to catch common mistakes and improve your [Rust](https://github.com/rust-lang/rust) code.

[There are over 750 lints included in this crate!](https://rust-lang.github.io/rust-clippy/master/index.html)

Lints are divided into categories, each with a default [lint level](https://doc.rust-lang.org/rustc/lints/levels.html).
You can choose how much Clippy is supposed to ~~annoy~~ help you by changing the lint level by category.

| Category              | Description                                                                         | Default level |
|-----------------------|-------------------------------------------------------------------------------------|---------------|
| `clippy::all`         | all lints that are on by default (correctness, suspicious, style, complexity, perf) | **warn/deny** |
| `clippy::correctness` | code that is outright wrong or useless                                              | **deny**      |
| `clippy::suspicious`  | code that is most likely wrong or useless                                           | **warn**      |
| `clippy::style`       | code that should be written in a more idiomatic way                                 | **warn**      |
| `clippy::complexity`  | code that does something simple but in a complex way                                | **warn**      |
| `clippy::perf`        | code that can be written to run faster                                              | **warn**      |
| `clippy::pedantic`    | lints which are rather strict or have occasional false positives                    | allow         |
| `clippy::restriction` | lints which prevent the use of language and library features[^restrict]             | allow         |
| `clippy::nursery`     | new lints that are still under development                                          | allow         |
| `clippy::cargo`       | lints for the cargo manifest                                                        | allow         |

More to come, please [file an issue](https://github.com/rust-lang/rust-clippy/issues) if you have ideas!

The `restriction` category should, *emphatically*, not be enabled as a whole. The contained
lints may lint against perfectly reasonable code, may not have an alternative suggestion,
and may contradict any other lints (including other categories). Lints should be considered
on a case-by-case basis before enabling.

[^restrict]: Some use cases for `restriction` lints include:
    - Strict coding styles (e.g. [`clippy::else_if_without_else`]).
    - Additional restrictions on CI (e.g. [`clippy::todo`]).
    - Preventing panicking in certain functions (e.g. [`clippy::unwrap_used`]).
    - Running a lint only on a subset of code (e.g. `#[forbid(clippy::float_arithmetic)]` on a module).

[`clippy::else_if_without_else`]: https://rust-lang.github.io/rust-clippy/master/index.html#else_if_without_else
[`clippy::todo`]: https://rust-lang.github.io/rust-clippy/master/index.html#todo
[`clippy::unwrap_used`]: https://rust-lang.github.io/rust-clippy/master/index.html#unwrap_used

---

Table of contents:

* [Usage instructions](#usage)
* [Configuration](#configuration)
* [Contributing](#contributing)
* [License](#license)

## Usage

Below are instructions on how to use Clippy as a cargo subcommand,
in projects that do not use cargo, or in Travis CI.

### As a cargo subcommand (`cargo clippy`)

One way to use Clippy is by installing Clippy through rustup as a cargo
subcommand.

#### Step 1: Install Rustup

You can install [Rustup](https://rustup.rs/) on supported platforms. This will help
us install Clippy and its dependencies.

If you already have Rustup installed, update to ensure you have the latest
Rustup and compiler:

```terminal
rustup update
```

#### Step 2: Install Clippy

Once you have rustup and the latest stable release (at least Rust 1.29) installed, run the following command:

```terminal
rustup component add clippy
```

If it says that it can&#039;t find the `clippy` component, please run `rustup self update`.

#### Step 3: Run Clippy

Now you can run Clippy by invoking the following command:

```terminal
cargo clippy
```

#### Automatically applying Clippy suggestions

Clippy can automatically apply some lint suggestions, just like the compiler. Note that `--fix` implies
`--all-targets`, so it can fix as much code as it can.

```terminal
cargo clippy --fix
```

#### Workspaces

All the usual workspace options should work with Clippy. For example the following command
will run Clippy on the `example` crate:

```terminal
cargo clippy -p example
```

As with `cargo check`, this includes dependencies that are members of the workspace, like path dependencies.
If you want to run Clippy **only** on the given crate, use the `--no-deps` option like this:

```terminal
cargo clippy -p example -- --no-deps
```

### Using `clippy-driver`

Clippy can also be used in projects that do not use cargo. To do so, run `clippy-driver`
with the same arguments you use for `rustc`. For example:

```terminal
clippy-driver --edition 2018 -Cpanic=abort foo.rs
```

Note that `clippy-driver` is designed for running Clippy only and should not be used as a general
replacement for `rustc`. `clippy-driver` may produce artifacts that are not optimized as expected,
for example.

### Travis CI

You can add Clippy to Travis CI in the same way you use it locally:

```yaml
language: rust
rust:
  - stable
  - beta
before_script:
  - rustup component add clippy
script:
  - cargo clippy
  # if you want the build job to fail when encountering warnings, use
  - cargo clippy -- -D warnings
  # in order to also check tests and non-default crate features, use
  - cargo clippy --all-targets --all-features -- -D warnings
  - cargo test
  # etc.
```

Note that adding `-D warnings` will cause your build to fail if **any** warnings are found in your code.
That includes warnings found by rustc (e.g. `dead_code`, etc.). If you want to avoid this and only cause
an error for Clippy warnings, use `#![deny(clippy::all)]` in your code or `-D clippy::all` on the command
line. (You can swap `clippy::all` with the specific lint category you are targeting.)

## Configuration

### Allowing/denying lints

You can add options to your code to `allow`/`warn`/`deny` Clippy lints:

* the whole set of `Warn` lints using the `clippy` lint group (`#![deny(clippy::all)]`).
  Note that `rustc` has additional [lint groups](https://doc.rust-lang.org/rustc/lints/groups.html).

* all lints using both the `clippy` and `clippy::pedantic` lint groups (`#![deny(clippy::all)]`,
  `#![deny(clippy::pedantic)]`). Note that `clippy::pedantic` contains some very aggressive
  lints prone to false positives.

* only some lints (`#![deny(clippy::single_match, clippy::box_vec)]`, etc.)

* `allow`/`warn`/`deny` can be limited to a single function or module using `#[allow(...)]`, etc.

Note: `allow` means to suppress the lint for your code. With `warn` the lint
will only emit a warning, while with `deny` the lint will emit an error, when
triggering for your code. An error causes Clippy to exit with an error code, so
is useful in scripts like CI/CD.

If you do not want to include your lint levels in your code, you can globally
enable/disable lints by passing extra flags to Clippy during the run:

To allow `lint_name`, run

```terminal
cargo clippy -- -A clippy::lint_name
```

And to warn on `lint_name`, run

```terminal
cargo clippy -- -W clippy::lint_name
```

This also works with lint groups. For example, you
can run Clippy with warnings for all lints enabled:

```terminal
cargo clippy -- -W clippy::pedantic
```

If you care only about a single lint, you can allow all others and then explicitly warn on
the lint(s) you are interested in:

```terminal
cargo clippy -- -A clippy::all -W clippy::useless_format -W clippy::...
```

### Configure the behavior of some lints

Some lints can be configured in a TOML file named `clippy.toml` or `.clippy.toml`. It contains a basic `variable =
value` mapping e.g.

```toml
avoid-breaking-exported-api = false
disallowed-names = [&quot;toto&quot;, &quot;tata&quot;, &quot;titi&quot;]
```

The [table of configurations](https://doc.rust-lang.org/nightly/clippy/lint_configuration.html)
contains all config values, their default, and a list of lints they affect.
Each [configurable lint](https://rust-lang.github.io/rust-clippy/master/index.html#Configuration)
, also contains information about these values.

For configurations that are a list type with default values such as
[disallowed-names](https://rust-lang.github.io/rust-clippy/master/index.html#disallowed_names),
you can use the unique value `&quot;..&quot;` to extend the default values instead of replacing them.

```toml
# default of disallowed-names is [&quot;foo&quot;, &quot;baz&quot;, &quot;quux&quot;]
disallowed-names = [&quot;bar&quot;, &quot;..&quot;] # -&gt; [&quot;bar&quot;, &quot;foo&quot;, &quot;baz&quot;, &quot;quux&quot;]
```

&gt; **Note**
&gt;
&gt; `clippy.toml` or `.clippy.toml` cannot be used to allow/deny lints.

To deactivate the ‚Äúfor further information visit *lint-link*‚Äù message you can
define the `CLIPPY_DISABLE_DOCS_LINKS` environment variable.

### Specifying the minimum supported Rust version

Projects that intend to support old versions of Rust can disable lints pertaining to newer features by
specifying the minimum supported Rust version (MSRV) in the Clippy configuration file.

```toml
msrv = &quot;1.30.0&quot;
```

Alternatively, the [`rust-version` field](https://doc.rust-lang.org/cargo/reference/manifest.html#the-rust-version-field)
in the `Cargo.toml` can be used.

```toml
# Cargo.toml
rust-version = &quot;1.30&quot;
```

The MSRV can also be specified as an attribute, like below.

```rust,ignore
#![feature(custom_inner_attributes)]
#![clippy::msrv = &quot;1.30.0&quot;]

fn main() {
  ...
}
```

You can also omit the patch version when specifying the MSRV, so `msrv = 1.30`
is equivalent to `msrv = 1.30.0`.

Note: `custom_inner_attributes` is an unstable feature, so it has to be enabled explicitly.

Lints that recognize this configuration option can be found [here](https://rust-lang.github.io/rust-clippy/master/index.html#msrv)

## Contributing

If you want to contribute to Clippy, you can find more information in [CONTRIBUTING.md](https://github.com/rust-lang/rust-clippy/blob/master/CONTRIBUTING.md).

## License

&lt;!-- REUSE-IgnoreStart --&gt;

Copyright 2014-2025 The Rust Project Developers

Licensed under the Apache License, Version 2.0 &lt;LICENSE-APACHE or
[https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)&gt; or the MIT license
&lt;LICENSE-MIT or [https://opensource.org/licenses/MIT](https://opensource.org/licenses/MIT)&gt;, at your
option. Files in the project may not be
copied, modified, or distributed except according to those terms.

&lt;!-- REUSE-IgnoreEnd --&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>