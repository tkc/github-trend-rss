<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Sun, 20 Jul 2025 00:06:19 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:19 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 61,935</p>
            <p>Forks: 1,779</p>
            <p>Stars today: 99 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- üöÄ A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`,
  and more.
- ‚ö°Ô∏è [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- üóÇÔ∏è Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- ‚ùáÔ∏è [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- üêç [Installs and manages](#python-versions) Python versions.
- üõ†Ô∏è [Runs and installs](#tools) tools published as Python packages.
- üî© Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a
  familiar CLI.
- üè¢ Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- üíæ Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- ‚è¨ Installable without Rust or Python via `curl` or `pip`.
- üñ•Ô∏è Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows ‚Äî and experience a 10-100x speedup ‚Äî with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Platform support

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

## Versioning policy

See uv&#039;s [versioning policy](https://docs.astral.sh/uv/reference/versioning/) document.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv/blob/main/CONTRIBUTING.md) to get started.

## FAQ

#### How do you pronounce uv?

It&#039;s pronounced as &quot;you - vee&quot; ([`/juÀê viÀê/`](https://en.wikipedia.org/wiki/Help:IPA/English#Key))

#### How should I stylize uv?

Just &quot;uv&quot;, please. See the [style guide](./STYLE.md#styling-uv) for details.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[helix-editor/helix]]></title>
            <link>https://github.com/helix-editor/helix</link>
            <guid>https://github.com/helix-editor/helix</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:18 GMT</pubDate>
            <description><![CDATA[A post-modern modal text editor.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/helix-editor/helix">helix-editor/helix</a></h1>
            <p>A post-modern modal text editor.</p>
            <p>Language: Rust</p>
            <p>Stars: 38,864</p>
            <p>Forks: 2,941</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;h1&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;logo_dark.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;logo_light.svg&quot;&gt;
  &lt;img alt=&quot;Helix&quot; height=&quot;128&quot; src=&quot;logo_light.svg&quot;&gt;
&lt;/picture&gt;
&lt;/h1&gt;

[![Build status](https://github.com/helix-editor/helix/actions/workflows/build.yml/badge.svg)](https://github.com/helix-editor/helix/actions)
[![GitHub Release](https://img.shields.io/github/v/release/helix-editor/helix)](https://github.com/helix-editor/helix/releases/latest)
[![Documentation](https://shields.io/badge/-documentation-452859)](https://docs.helix-editor.com/)
[![GitHub contributors](https://img.shields.io/github/contributors/helix-editor/helix)](https://github.com/helix-editor/helix/graphs/contributors)
[![Matrix Space](https://img.shields.io/matrix/helix-community:matrix.org)](https://matrix.to/#/#helix-community:matrix.org)

&lt;/div&gt;

![Screenshot](./screenshot.png)

A [Kakoune](https://github.com/mawww/kakoune) / [Neovim](https://github.com/neovim/neovim) inspired editor, written in Rust.

The editing model is very heavily based on Kakoune; during development I found
myself agreeing with most of Kakoune&#039;s design decisions.

For more information, see the [website](https://helix-editor.com) or
[documentation](https://docs.helix-editor.com/).

All shortcuts/keymaps can be found [in the documentation on the website](https://docs.helix-editor.com/keymap.html).

[Troubleshooting](https://github.com/helix-editor/helix/wiki/Troubleshooting)

# Features

- Vim-like modal editing
- Multiple selections
- Built-in language server support
- Smart, incremental syntax highlighting and code editing via tree-sitter

Although it&#039;s primarily a terminal-based editor, I am interested in exploring
a custom renderer (similar to Emacs) using wgpu or skulpin.

Note: Only certain languages have indentation definitions at the moment. Check
`runtime/queries/&lt;lang&gt;/` for `indents.scm`.

# Installation

[Installation documentation](https://docs.helix-editor.com/install.html).

[![Packaging status](https://repology.org/badge/vertical-allrepos/helix-editor.svg?exclude_unsupported=1)](https://repology.org/project/helix-editor/versions)

# Contributing

Contributing guidelines can be found [here](./docs/CONTRIBUTING.md).

# Getting help

Your question might already be answered on the [FAQ](https://github.com/helix-editor/helix/wiki/FAQ).

Discuss the project on the community [Matrix Space](https://matrix.to/#/#helix-community:matrix.org) (make sure to join `#helix-editor:matrix.org` if you&#039;re on a client that doesn&#039;t support Matrix Spaces yet).

# Credits

Thanks to [@jakenvac](https://github.com/jakenvac) for designing the logo!
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[antinomyhq/forge]]></title>
            <link>https://github.com/antinomyhq/forge</link>
            <guid>https://github.com/antinomyhq/forge</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:17 GMT</pubDate>
            <description><![CDATA[AI enabled pair programmer for Claude, GPT, O Series, Grok, Deepseek, Gemini and 300+ models]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/antinomyhq/forge">antinomyhq/forge</a></h1>
            <p>AI enabled pair programmer for Claude, GPT, O Series, Grok, Deepseek, Gemini and 300+ models</p>
            <p>Language: Rust</p>
            <p>Stars: 3,789</p>
            <p>Forks: 1,187</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;‚öíÔ∏è Forge: AI-Enhanced Terminal Development Environment&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;A comprehensive coding agent that integrates AI capabilities with your development environment&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;code&gt;npx forgecode@latest&lt;/code&gt;&lt;/p&gt;

[![CI Status](https://img.shields.io/github/actions/workflow/status/antinomyhq/forge/ci.yml?style=for-the-badge)](https://github.com/antinomyhq/forge/actions)
[![GitHub Release](https://img.shields.io/github/v/release/antinomyhq/forge?style=for-the-badge)](https://github.com/antinomyhq/forge/releases)
[![Discord](https://img.shields.io/discord/1044859667798568962?style=for-the-badge&amp;cacheSeconds=120&amp;logo=discord)](https://discord.gg/kRZBPpkgwq)
[![CLA assistant](https://cla-assistant.io/readme/badge/antinomyhq/forge?style=for-the-badge)](https://cla-assistant.io/antinomyhq/forge)

![Code-Forge Demo](https://assets.antinomy.ai/images/forge_demo_2x.gif)

---

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Table&amp;nbsp;of&amp;nbsp;Contents&lt;/strong&gt;&lt;/summary&gt;

- [Quickstart](#quickstart)
- [Usage Examples](#usage-examples)
- [Why Forge?](#why-forge)
- [Command-Line Options](#command-line-options)
- [Advanced Configuration](#advanced-configuration)
  - [Provider Configuration](#provider-configuration)
  - [forge.yaml Configuration Options](#forgeyaml-configuration-options)
  - [MCP Configuration](#mcp-configuration)
  - [Example Use Cases](#example-use-cases)
  - [Usage in Multi-Agent Workflows](#usage-in-multi-agent-workflows)
- [Documentation](#documentation)
- [Community](#community)
- [Support Us](#support-us)

&lt;/details&gt;

---

## Quickstart

Run Forge in interactive mode via npx

```bash
npx forgecode@latest
```

Connect through the Forge app and complete the OAuth process.
This will open your browser to app.forgecode.dev where you can sign up or sign in with Google/GitHub.

That&#039;s it! Forge is now ready to assist you with your development tasks.

## Usage Examples

Forge can be used in different ways depending on your needs. Here are some common usage patterns:

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Code Understanding&lt;/strong&gt;&lt;/summary&gt;

```
&gt; Can you explain how the authentication system works in this codebase?
```

Forge will analyze your project&#039;s structure, identify authentication-related files, and provide a detailed explanation of the authentication flow, including the relationships between different components.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Implementing New Features&lt;/strong&gt;&lt;/summary&gt;

```
&gt; I need to add a dark mode toggle to our React application. How should I approach this?
```

Forge will suggest the best approach based on your current codebase, explain the steps needed, and even scaffold the necessary components and styles for you.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Debugging Assistance&lt;/strong&gt;&lt;/summary&gt;

```
&gt; I&#039;m getting this error: &quot;TypeError: Cannot read property &#039;map&#039; of undefined&quot;. What might be causing it?
```

Forge will analyze the error, suggest potential causes based on your code, and propose different solutions to fix the issue.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Code Reviews&lt;/strong&gt;&lt;/summary&gt;

```
&gt; Please review the code in src/components/UserProfile.js and suggest improvements
```

Forge will analyze the code, identify potential issues, and suggest improvements for readability, performance, security, and maintainability.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Learning New Technologies&lt;/strong&gt;&lt;/summary&gt;

```
&gt; I want to integrate GraphQL into this Express application. Can you explain how to get started?
```

Forge will provide a tailored tutorial on integrating GraphQL with Express, using your specific project structure as context.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Database Schema Design&lt;/strong&gt;&lt;/summary&gt;

```
&gt; I need to design a database schema for a blog with users, posts, comments, and categories
```

Forge will suggest an appropriate schema design, including tables/collections, relationships, indexes, and constraints based on your project&#039;s existing database technology.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Refactoring Legacy Code&lt;/strong&gt;&lt;/summary&gt;

```
&gt; Help me refactor this class-based component to use React Hooks
```

Forge can help modernize your codebase by walking you through refactoring steps and implementing them with your approval.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Git Operations&lt;/strong&gt;&lt;/summary&gt;

```
&gt; I need to merge branch &#039;feature/user-profile&#039; into main but there are conflicts
```

Forge can guide you through resolving git conflicts, explaining the differences and suggesting the best way to reconcile them.

&lt;/details&gt;

## Why Forge?

Forge is designed for developers who want to enhance their workflow with AI assistance while maintaining full control over their development environment.

- **Zero configuration** - Just add your API key and you&#039;re ready to go
- **Seamless integration** - Works right in your terminal, where you already work
- **Multi-provider support** - Use OpenAI, Anthropic, or other LLM providers
- **Secure by design** - Your code stays on your machine
- **Open-source** - Transparent, extensible, and community-driven

Forge helps you code faster, solve complex problems, and learn new technologies without leaving your terminal.

## Command-Line Options

Here&#039;s a quick reference of Forge&#039;s command-line options:

| Option                          | Description                                                |
| ------------------------------- | ---------------------------------------------------------- |
| `-p, --prompt &lt;PROMPT&gt;`         | Direct prompt to process without entering interactive mode |
| `-c, --command &lt;COMMAND&gt;`       | Path to a file containing initial commands to execute      |
| `-w, --workflow &lt;WORKFLOW&gt;`     | Path to a file containing the workflow to execute          |
| `-e, --event &lt;EVENT&gt;`           | Dispatch an event to the workflow                          |
| `--conversation &lt;CONVERSATION&gt;` | Path to a file containing the conversation to execute      |
| `-r, --restricted`              | Enable restricted shell mode for enhanced security         |
| `--verbose`                     | Enable verbose output mode                                 |
| `-h, --help`                    | Print help information                                     |
| `-V, --version`                 | Print version                                              |

## Advanced Configuration

### Provider Configuration

Forge supports multiple AI providers. Below are setup instructions for each supported provider:

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;forgecode.dev (Recommended)&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
FORGE_KEY=ForgeKey
```

To use Forgecode&#039;s provider with Forge:

1. Visit [https://app.forgecode.dev/](https://app.forgecode.dev/)
2. Login with your existing credentials or create a new account
3. Once logged in, your account will automatically enable the Forge Provider

_No changes in `forge.yaml` required_

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;OpenRouter&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
OPENROUTER_API_KEY=&lt;your_openrouter_api_key&gt;
```

_No changes in `forge.yaml` required_

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Requesty&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
REQUESTY_API_KEY=&lt;your_requesty_api_key&gt;
```

_No changes in `forge.yaml` required_

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;x-ai&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
XAI_API_KEY=&lt;your_xai_api_key&gt;
```

switch the model using `/model` command in the Forge CLI.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;OpenAI&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
OPENAI_API_KEY=&lt;your_openai_api_key&gt;
```

```yaml
# forge.yaml
model: o3-mini-high
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Anthropic&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
ANTHROPIC_API_KEY=&lt;your_anthropic_api_key&gt;
```

```yaml
# forge.yaml
model: claude-3.7-sonnet
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Google Vertex AI&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
PROJECT_ID=&lt;your_project_id&gt;
LOCATION=&lt;your_location&gt;
OPENAI_API_KEY=&lt;vertex_ai_key&gt;
OPENAI_URL=https://${LOCATION}-aiplatform.googleapis.com/v1beta1/projects/${PROJECT_ID}/locations/${LOCATION}/endpoints/openapi
```

```yaml
# forge.yaml
model: publishers/anthropic/models/claude-3-7-sonnet
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;OpenAI-Compatible Providers&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
OPENAI_API_KEY=&lt;your_provider_api_key&gt;
OPENAI_URL=&lt;your_provider_url&gt;
```

```yaml
# forge.yaml
model: &lt;provider-specific-model&gt;
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Groq&lt;/strong&gt;&lt;/summary&gt;

```bash
# .env
OPENAI_API_KEY=&lt;your_groq_api_key&gt;
OPENAI_URL=https://api.groq.com/openai/v1
```

```yaml
# forge.yaml
model: deepseek-r1-distill-llama-70b
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Amazon Bedrock&lt;/strong&gt;&lt;/summary&gt;

To use Amazon Bedrock models with Forge, you&#039;ll need to first set up the [Bedrock Access Gateway](https://github.com/aws-samples/bedrock-access-gateway):

1. **Set up Bedrock Access Gateway**:

   - Follow the deployment steps in the [Bedrock Access Gateway repo](https://github.com/aws-samples/bedrock-access-gateway)
   - Create your own API key in Secrets Manager
   - Deploy the CloudFormation stack
   - Note your API Base URL from the CloudFormation outputs

2. **Create these files in your project directory**:

   ```bash
   # .env
   OPENAI_API_KEY=&lt;your_bedrock_gateway_api_key&gt;
   OPENAI_URL=&lt;your_bedrock_gateway_base_url&gt;
   ```

   ```yaml
   # forge.yaml
   model: anthropic.claude-3-opus
   ```

   &lt;/details&gt;

### forge.yaml Configuration Options

The `forge.yaml` file supports several advanced configuration options that let you customize Forge&#039;s behavior.

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Custom Rules&lt;/strong&gt;&lt;/summary&gt;

Add your own guidelines that all agents should follow when generating responses.

```yaml
# forge.yaml
custom_rules: |
  1. Always add comprehensive error handling to any code you write.
  2. Include unit tests for all new functions.
  3. Follow our team&#039;s naming convention: camelCase for variables, PascalCase for classes.
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Commands&lt;/strong&gt;&lt;/summary&gt;

Define custom commands as shortcuts for repetitive prompts:

```yaml
# forge.yaml
commands:
  - name: &#039;refactor&#039;
    description: &#039;Refactor selected code&#039;
    prompt: &#039;Please refactor this code to improve readability and performance&#039;
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Model&lt;/strong&gt;&lt;/summary&gt;

Specify the default AI model to use for all agents in the workflow.

```yaml
# forge.yaml
model: &#039;claude-3.7-sonnet&#039;
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Max Walker Depth&lt;/strong&gt;&lt;/summary&gt;

Control how deeply Forge traverses your project directory structure when gathering context.

```yaml
# forge.yaml
max_walker_depth: 3 # Limit directory traversal to 3 levels deep
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Temperature&lt;/strong&gt;&lt;/summary&gt;

Adjust the creativity and randomness in AI responses. Lower values (0.0-0.3) produce more focused, deterministic outputs, while higher values (0.7-2.0) generate more diverse and creative results.

```yaml
# forge.yaml
temperature: 0.7 # Balanced creativity and focus
```

&lt;/details&gt;
&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Tool Max Failure Limit&lt;/strong&gt;&lt;/summary&gt;

Control how many times a tool can fail before Forge forces completion to prevent infinite retry loops. This helps avoid situations where an agent gets stuck repeatedly trying the same failing operation.

```yaml
# forge.yaml
tool_max_failure_limit: 3 # Allow up to 3 failures per tool before forcing completion
```

Set to a higher value if you want more retry attempts, or lower if you want faster failure detection.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Max Requests Per Turn&lt;/strong&gt;&lt;/summary&gt;

Limit the maximum number of requests an agent can make in a single conversation turn. This prevents runaway conversations and helps control API usage and costs.

```yaml
# forge.yaml
max_requests_per_turn: 50 # Allow up to 50 requests per turn
```

When this limit is reached, Forge will:
- Ask you if you wish to continue
- If you respond with &#039;Yes&#039;, it will continue the conversation
- If you respond with &#039;No&#039;, it will end the conversation

&lt;/details&gt;

---

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Model Context Protocol (MCP)&lt;/strong&gt;&lt;/summary&gt;

The MCP feature allows AI agents to communicate with external tools and services. This implementation follows Anthropic&#039;s [Model Context Protocol](https://docs.anthropic.com/en/docs/claude-code/tutorials#set-up-model-context-protocol-mcp) design.

### MCP Configuration

Configure MCP servers using the CLI:

```bash
# List all MCP servers
forge mcp list

# Add a new server
forge mcp add

# Add a server using JSON format
forge mcp add-json

# Get server details
forge mcp get

# Remove a server
forge mcp remove
```

Or manually create a `.mcp.json` file with the following structure:

```json
{
	&quot;mcpServers&quot;: {
		&quot;server_name&quot;: {
			&quot;command&quot;: &quot;command_to_execute&quot;,
			&quot;args&quot;: [&quot;arg1&quot;, &quot;arg2&quot;],
			&quot;env&quot;: { &quot;ENV_VAR&quot;: &quot;value&quot; }
		},
		&quot;another_server&quot;: {
			&quot;url&quot;: &quot;http://localhost:3000/events&quot;
		}
	}
}
```

MCP configurations are read from two locations (in order of precedence):

1. Local configuration (project-specific)
2. User configuration (user-specific)

### Example Use Cases

MCP can be used for various integrations:

- Web browser automation
- External API interactions
- Tool integration
- Custom service connections

### Usage in Multi-Agent Workflows

MCP tools can be used as part of multi-agent workflows, allowing specialized agents to interact with external systems as part of a collaborative problem-solving approach.

&lt;/details&gt;

---

## Documentation

For comprehensive documentation on all features and capabilities, please visit the [documentation site](https://github.com/antinomyhq/forge/tree/main/docs).

---

## Community

Join our vibrant Discord community to connect with other Forge users and contributors, get help with your projects, share ideas, and provide feedback!

[![Discord](https://img.shields.io/discord/1044859667798568962?style=for-the-badge&amp;cacheSeconds=120&amp;logo=discord)](https://discord.gg/kRZBPpkgwq)

---

## Support Us

Your support drives Forge&#039;s continued evolution! By starring our GitHub repository, you:

- Help others discover this powerful tool üîç
- Motivate our development team üí™
- Enable us to prioritize new features üõ†Ô∏è
- Strengthen our open-source community üå±
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[tracel-ai/burn]]></title>
            <link>https://github.com/tracel-ai/burn</link>
            <guid>https://github.com/tracel-ai/burn</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:16 GMT</pubDate>
            <description><![CDATA[Burn is a next generation Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tracel-ai/burn">tracel-ai/burn</a></h1>
            <p>Burn is a next generation Deep Learning Framework that doesn't compromise on flexibility, efficiency and portability.</p>
            <p>Language: Rust</p>
            <p>Stars: 11,681</p>
            <p>Forks: 623</p>
            <p>Stars today: 52 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/logo-burn-neutral.webp&quot; width=&quot;350px&quot;/&gt;

[![Discord](https://img.shields.io/discord/1038839012602941528.svg?color=7289da&amp;&amp;logo=discord)](https://discord.gg/uPEBbYYDB6)
[![Current Crates.io Version](https://img.shields.io/crates/v/burn.svg)](https://crates.io/crates/burn)
[![Minimum Supported Rust Version](https://img.shields.io/crates/msrv/burn)](https://crates.io/crates/burn)
[![Documentation](https://img.shields.io/badge/docs-latest-blue)](https://burn.dev/docs/burn)
[![Test Status](https://github.com/tracel-ai/burn/actions/workflows/test.yml/badge.svg)](https://github.com/tracel-ai/burn/actions/workflows/test.yml)
[![license](https://shields.io/badge/license-MIT%2FApache--2.0-blue)](#license)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/tracel-ai/burn)

[&lt;img src=&quot;https://www.runblaze.dev/ci-blaze-powered.png&quot; width=&quot;125px&quot;/&gt;](https://www.runblaze.dev)

---

**Burn is a next generation Deep Learning Framework that doesn&#039;t compromise on &lt;br /&gt;
flexibility, efficiency and portability.**

&lt;br/&gt;
&lt;/div&gt;

&lt;div align=&quot;left&quot;&gt;

## Performance

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-blazingly-fast.png&quot; height=&quot;96px&quot;/&gt;

Because we believe the goal of a deep learning framework is to convert computation into useful
intelligence, we have made performance a core pillar of Burn. We strive to achieve top efficiency by
leveraging multiple optimization techniques described below.

**Click on each section for more details** üëá

&lt;/div&gt;

&lt;br /&gt;

&lt;details&gt;
&lt;summary&gt;
Automatic kernel fusion üí•
&lt;/summary&gt;
&lt;br /&gt;

Using Burn means having your models optimized on any backend. When possible, we provide a way to
automatically and dynamically create custom kernels that minimize data relocation between different
memory spaces, extremely useful when moving memory is the bottleneck.

As an example, you could write your own GELU activation function with the high level tensor api (see
Rust code snippet below).

```rust
fn gelu_custom&lt;B: Backend, const D: usize&gt;(x: Tensor&lt;B, D&gt;) -&gt; Tensor&lt;B, D&gt; {
    let x = x.clone() * ((x / SQRT_2).erf() + 1);
    x / 2
}
```

Then, at runtime, a custom low-level kernel will be automatically created for your specific
implementation and will rival a handcrafted GPU implementation. The kernel consists of about 60
lines of WGSL [WebGPU Shading Language](&quot;https://www.w3.org/TR/WGSL/https://www.w3.org/TR/WGSL/&quot;),
an extremely verbose lower level shader language you probably don&#039;t want to program your deep
learning models in!

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Asynchronous execution ‚ù§Ô∏è‚Äçüî•
&lt;/summary&gt;
&lt;br /&gt;

For [first-party backends](#backends), an asynchronous execution style
is used, which allows to perform various optimizations, such as the previously mentioned automatic
kernel fusion.

Asynchronous execution also ensures that the normal execution of the framework does not block the
model computations, which implies that the framework overhead won&#039;t impact the speed of execution
significantly. Conversely, the intense computations in the model do not interfere with the
responsiveness of the framework. For more information about our asynchronous backends, see
[this blog post](https://burn.dev/blog/creating-high-performance-asynchronous-backends-with-burn-compute).

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Thread-safe building blocks ü¶û
&lt;/summary&gt;
&lt;br /&gt;

Burn emphasizes thread safety by leveraging the
[ownership system of Rust](https://doc.rust-lang.org/book/ch04-00-understanding-ownership.html).
With Burn, each module is the owner of its weights. It is therefore possible to send a module to
another thread for computing the gradients, then send the gradients to the main thread that can
aggregate them, and _voil√†_, you get multi-device training.

This is a very different approach from what PyTorch does, where backpropagation actually mutates the
_grad_ attribute of each tensor parameter. This is not a thread-safe operation and therefore
requires lower level synchronization primitives, see
[distributed training](https://pytorch.org/docs/stable/distributed.html) for reference. Note that
this is still very fast, but not compatible across different backends and quite hard to implement.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Intelligent memory management ü¶Ä
&lt;/summary&gt;
&lt;br /&gt;

One of the main roles of a deep learning framework is to reduce the amount of memory necessary to
run models. The naive way of handling memory is that each tensor has its own memory space, which is
allocated when the tensor is created then deallocated as the tensor gets out of scope. However,
allocating and deallocating data is very costly, so a memory pool is often required to achieve good
throughput. Burn offers an infrastructure that allows for easily creating and selecting memory
management strategies for backends. For more details on memory management in Burn, see
[this blog post](https://burn.dev/blog/creating-high-performance-asynchronous-backends-with-burn-compute).

Another very important memory optimization of Burn is that we keep track of when a tensor can be
mutated in-place just by using the ownership system well. Even though it is a rather small memory
optimization on its own, it adds up considerably when training or running inference with larger
models and contributes to reduce the memory usage even more. For more information, see
[this blog post about tensor handling](https://burn.dev/blog/burn-rusty-approach-to-tensor-handling).

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Automatic kernel selection üéØ
&lt;/summary&gt;
&lt;br /&gt;

A good deep learning framework should ensure that models run smoothly on all hardware. However, not
all hardware share the same behavior in terms of execution speed. For instance, a matrix
multiplication kernel can be launched with many different parameters, which are highly sensitive to
the size of the matrices and the hardware. Using the wrong configuration could reduce the speed of
execution by a large factor (10 times or even more in extreme cases), so choosing the right kernels
becomes a priority.

With our home-made backends, we run benchmarks automatically and choose the best configuration for
the current hardware and matrix sizes with a reasonable caching strategy.

This adds a small overhead by increasing the warmup execution time, but stabilizes quickly after a
few forward and backward passes, saving lots of time in the long run. Note that this feature isn&#039;t
mandatory, and can be disabled when cold starts are a priority over optimized throughput.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Hardware specific features üî•
&lt;/summary&gt;
&lt;br /&gt;

It is no secret that deep learning is mostly relying on matrix multiplication as its core operation,
since this is how fully-connected neural networks are modeled.

More and more, hardware manufacturers optimize their chips specifically for matrix multiplication
workloads. For instance, Nvidia has its _Tensor Cores_ and today most cellphones have AI specialized
chips. As of this moment, we support Tensor Cores with our LibTorch, Candle, CUDA, Metal and WGPU/SPIR-V
backends, but not other accelerators yet. We hope
[this issue](https://github.com/gpuweb/gpuweb/issues/4195) gets resolved at some point to bring
support to our WGPU backend.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Custom Backend Extension üéí
&lt;/summary&gt;
&lt;br /&gt;

Burn aims to be the most flexible deep learning framework. While it&#039;s crucial to maintain
compatibility with a wide variety of backends, Burn also provides the ability to extend the
functionalities of a backend implementation to suit your personal modeling requirements.

This versatility is advantageous in numerous ways, such as supporting custom operations like flash
attention or manually writing your own kernel for a specific backend to enhance performance. See
[this section](https://burn.dev/books/burn/advanced/backend-extension/index.html) in the Burn Book üî•
for more details.

&lt;/details&gt;

&lt;br /&gt;

## Backend

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/backend-chip.png&quot; height=&quot;96px&quot;/&gt;

Burn strives to be as fast as possible on as many hardwares as possible, with robust implementations.
We believe this flexibility is crucial for modern needs where you may train your models in the cloud,
then deploy on customer hardwares, which vary from user to user.

&lt;/div&gt;

&lt;br /&gt;

**Supported Backends**

| Backend  | Devices                      | Class       |
| -------- | ---------------------------- | ----------- |
| CUDA     | NVIDIA GPUs                  | First-Party |
| ROCm     | AMD GPUs                     | First-Party |
| Metal    | Apple GPUs                   | First-Party |
| Vulkan   | Most GPUs on Linux &amp; Windows | First-Party |
| Wgpu     | Most GPUs                    | First-Party |
| NdArray  | Most CPUs                    | Third-Party |
| LibTorch | Most GPUs &amp; CPUs             | Third-Party |
| Candle   | Nvidia, Apple GPUs &amp; CPUs    | Third-Party |

&lt;br /&gt;

Compared to other frameworks, Burn has a very different approach to supporting many backends. By
design, most code is generic over the Backend trait, which allows us to build Burn with swappable
backends. This makes composing backend possible, augmenting them with additional functionalities
such as autodifferentiation and automatic kernel fusion.

&lt;details&gt;
&lt;summary&gt;
Autodiff: Backend decorator that brings backpropagation to any backend üîÑ
&lt;/summary&gt;
&lt;br /&gt;

Contrary to the aforementioned backends, Autodiff is actually a backend _decorator_. This means that
it cannot exist by itself; it must encapsulate another backend.

The simple act of wrapping a base backend with Autodiff transparently equips it with
autodifferentiation support, making it possible to call backward on your model.

```rust
use burn::backend::{Autodiff, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&lt;Wgpu&gt;;

    let x: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default);
    let y: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;grads).unwrap();
    println!(&quot;{y_grad}&quot;);
}
```

Of note, it is impossible to make the mistake of calling backward on a model that runs on a backend
that does not support autodiff (for inference), as this method is only offered by an Autodiff
backend.

See the [Autodiff Backend README](./crates/burn-autodiff/README.md) for more details.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Fusion: Backend decorator that brings kernel fusion to all first-party backends
&lt;/summary&gt;
&lt;br /&gt;

This backend decorator enhances a backend with kernel fusion, provided that the inner backend
supports it. Note that you can compose this backend with other backend decorators such as Autodiff.
For now, only the WGPU and CUDA backends have support for fused kernels.

```rust
use burn::backend::{Autodiff, Fusion, Wgpu};
use burn::tensor::{Distribution, Tensor};

fn main() {
    type Backend = Autodiff&lt;Fusion&lt;Wgpu&gt;&gt;;

    let x: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default);
    let y: Tensor&lt;Backend, 2&gt; = Tensor::random([32, 32], Distribution::Default).require_grad();

    let tmp = x.clone() + y.clone();
    let tmp = tmp.matmul(x);
    let tmp = tmp.exp();

    let grads = tmp.backward();
    let y_grad = y.grad(&amp;grads).unwrap();
    println!(&quot;{y_grad}&quot;);
}

```

Of note, we plan to implement automatic gradient checkpointing based on compute bound and memory
bound operations, which will work gracefully with the fusion backend to make your code run even
faster during training, see [this issue](https://github.com/tracel-ai/burn/issues/936).

See the [Fusion Backend README](./crates/burn-fusion/README.md) for more details.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Router (Beta): Backend decorator that composes multiple backends into a single one
&lt;/summary&gt;
&lt;br /&gt;

That backend simplifies hardware operability, if for instance you want to execute some operations on the CPU and other operations on the GPU.

```rust
use burn::tensor::{Distribution, Tensor};
use burn::backend::{
    NdArray, Router, Wgpu, ndarray::NdArrayDevice, router::duo::MultiDevice, wgpu::WgpuDevice,
};

fn main() {
    type Backend = Router&lt;(Wgpu, NdArray)&gt;;

    let device_0 = MultiDevice::B1(WgpuDevice::DiscreteGpu(0));
    let device_1 = MultiDevice::B2(NdArrayDevice::Cpu);

    let tensor_gpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;device_0);
    let tensor_cpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], burn::tensor::Distribution::Default, &amp;device_1);
}

```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Remote (Beta): Backend decorator for remote backend execution, useful for distributed computations
&lt;/summary&gt;
&lt;br /&gt;

That backend has two parts, one client and one server.
The client sends tensor operations over the network to a remote compute backend.
You can use any first-party backend as server in a single line of code:

```rust
fn main_server() {
    // Start a server on port 3000.
    burn::server::start::&lt;burn::backend::Cuda&gt;(Default::default(), 3000);
}

fn main_client() {
    // Create a client that communicate with the server on port 3000.
    use burn::backend::{Autodiff, RemoteBackend};

    type Backend = Autodiff&lt;RemoteDevice&gt;;

    let device = RemoteDevice::new(&quot;ws://localhost:3000&quot;);
    let tensor_gpu =
        Tensor::&lt;Backend, 2&gt;::random([3, 3], Distribution::Default, &amp;device);
}

```

&lt;/details&gt;

&lt;br /&gt;

## Training &amp; Inference

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-wall.png&quot; height=&quot;96px&quot;/&gt;

The whole deep learning workflow is made easy with Burn, as you can monitor your training progress
with an ergonomic dashboard, and run inference everywhere from embedded devices to large GPU
clusters.

Burn was built from the ground up with training and inference in mind. It&#039;s also worth noting how
Burn, in comparison to frameworks like PyTorch, simplifies the transition from training to
deployment, eliminating the need for code changes.

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;br /&gt;

&lt;a href=&quot;https://www.youtube.com/watch?v=N9RM5CQbNQc&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/burn-train-tui.png&quot; alt=&quot;Burn Train TUI&quot; width=&quot;75%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

&lt;br /&gt;

**Click on the following sections to expand üëá**

&lt;details&gt;
&lt;summary&gt;
Training Dashboard üìà
&lt;/summary&gt;
&lt;br /&gt;

As you can see in the previous video (click on the picture!), a new terminal UI dashboard based on
the [Ratatui](https://github.com/ratatui-org/ratatui) crate allows users to follow their training
with ease without having to connect to any external application.

You can visualize your training and validation metrics updating in real-time and analyze the
lifelong progression or recent history of any registered metrics using only the arrow keys. Break
from the training loop without crashing, allowing potential checkpoints to be fully written or
important pieces of code to complete without interruption üõ°

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
ONNX Support üê´
&lt;/summary&gt;
&lt;br /&gt;

ONNX (Open Neural Network Exchange) is an open-standard format that exports both the architecture
and the weights of a deep learning model.

Burn supports the importation of models that follow the ONNX standard so you can easily port a model
you have written in another framework like TensorFlow or PyTorch to Burn to benefit from all the
advantages our framework offers.

Our ONNX support is further described in
[this section of the Burn Book üî•](https://burn.dev/books/burn/import/onnx-model.html).

&gt; **Note**: This crate is in active development and currently supports a
&gt; [limited set of ONNX operators](./crates/burn-import/SUPPORTED-ONNX-OPS.md).

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Importing PyTorch or Safetensors Models üöö
&lt;/summary&gt;
&lt;br /&gt;

You can load weights from PyTorch or Safetensors formats directly into your Burn-defined models. This makes it easy to reuse existing models while benefiting from Burn&#039;s performance and deployment features.

Learn more:

- [Import pre-trained PyTorch models into Burn](https://burn.dev/books/burn/import/pytorch-model.html)
- [Load models from Safetensors format](https://burn.dev/books/burn/import/safetensors-model.html)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Inference in the Browser üåê
&lt;/summary&gt;
&lt;br /&gt;

Several of our backends can compile to Web Assembly: Candle and NdArray for CPU, and WGPU for GPU.
This means that you can run inference directly within a browser. We provide several examples of
this:

- [MNIST](./examples/mnist-inference-web) where you can draw digits and a small convnet tries to
  find which one it is! 2Ô∏è‚É£ 7Ô∏è‚É£ üò∞
- [Image Classification](./examples/image-classification-web) where you can upload images and
  classify them! üåÑ

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Embedded: &lt;i&gt;no_std&lt;/i&gt; support ‚öôÔ∏è
&lt;/summary&gt;
&lt;br /&gt;

Burn&#039;s core components support [no_std](https://docs.rust-embedded.org/book/intro/no-std.html). This
means it can run in bare metal environment such as embedded devices without an operating system.

&gt; As of now, only the NdArray backend can be used in a _no_std_ environment.

&lt;/details&gt;

&lt;br /&gt;

### Benchmarks

To evaluate performance across different backends and track improvements over time, we provide a
dedicated benchmarking suite.

Run and compare benchmarks using [burn-bench](https://github.com/tracel-ai/burn-bench).

&gt; ‚ö†Ô∏è **Warning**
&gt; When using one of the `wgpu` backends, you may encounter compilation errors related to recursive type evaluation. This is due to complex type nesting within the `wgpu` dependency chain.
&gt; To resolve this issue, add the following line at the top of your `main.rs` or `lib.rs` file:
&gt;
&gt; ```rust
&gt; #![recursion_limit = &quot;256&quot;]
&gt; ```
&gt;
&gt; The default recursion limit (128) is often just below the required depth (typically 130-150) due to deeply nested associated types and trait bounds.

## Getting Started

&lt;div align=&quot;left&quot;&gt;
&lt;img align=&quot;right&quot; src=&quot;https://raw.githubusercontent.com/tracel-ai/burn/main/assets/ember-walking.png&quot; height=&quot;96px&quot;/&gt;

Just heard of Burn? You are at the right place! Just continue reading this section and we hope you
can get on board really quickly.

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;
The Burn Book üî•
&lt;/summary&gt;
&lt;br /&gt;

To begin working effectively with Burn, it is crucial to understand its key components and
philosophy. This is why we highly recommend new users to read the first sections of
[The Burn Book üî•](https://burn.dev/books/burn/). It provides detailed examples and explanations
covering every facet of the framework, including building blocks like tensors, modules, and
optimizers, all the way to advanced usage, like coding your own GPU kernels.

&gt; The project is constantly evolving, and we try as much as possible to keep the book up to date
&gt; with new additions. However, we might miss some details sometimes, so if you see something weird,
&gt; let us know! We also gladly accept Pull Requests üòÑ

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;
Examples üôè
&lt;/summary&gt;
&lt;br /&gt;

Let&#039;s start with a code snippet that shows how intuitive the framework is to use! In the following,
we declare a neural network module with some parameters along with its forward pass.

```rust
use burn::nn;
use burn::module::Module;
use burn::tensor::backend::Backend;

#[derive(Module, Debug)]
pub struct PositionWiseFeedForward&lt;B: Backend&gt; {
    linear_inner: nn::Linear&lt;B&gt;,
    linear_outer: nn::Linear&lt;B&gt;,
    dropout: nn::Dropout,
    gelu: nn::Gelu,
}

impl&lt;B: Backend&gt; PositionWiseFeedForward&lt;B&gt; {
    pub fn forward&lt;const D: usize&gt;(&amp;self, input: Tensor&lt;B, D&gt;) -&gt; Tensor&lt;B, D&gt; {
        let x = self.linear_inner.forward(input);
        let x = self.gelu.forward(x);
        l

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rerun-io/rerun]]></title>
            <link>https://github.com/rerun-io/rerun</link>
            <guid>https://github.com/rerun-io/rerun</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:15 GMT</pubDate>
            <description><![CDATA[Visualize streams of multimodal data. Free, fast, easy to use, and simple to integrate. Built in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rerun-io/rerun">rerun-io/rerun</a></h1>
            <p>Visualize streams of multimodal data. Free, fast, easy to use, and simple to integrate. Built in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 8,888</p>
            <p>Forks: 490</p>
            <p>Stars today: 11 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.rerun.io/&quot;&gt;
    &lt;img alt=&quot;banner&quot; src=&quot;https://user-images.githubusercontent.com/1148717/218142418-1d320929-6b7a-486e-8277-fbeef2432529.png&quot;&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pypi.org/project/rerun-sdk/&quot;&gt;                        &lt;img alt=&quot;PyPi&quot;           src=&quot;https://img.shields.io/pypi/v/rerun-sdk.svg&quot;&gt;                              &lt;/a&gt;
  &lt;a href=&quot;https://crates.io/crates/rerun&quot;&gt;                             &lt;img alt=&quot;crates.io&quot;      src=&quot;https://img.shields.io/crates/v/rerun.svg&quot;&gt;                                &lt;/a&gt;
  &lt;a href=&quot;https://github.com/rerun-io/rerun/blob/main/LICENSE-MIT&quot;&gt;    &lt;img alt=&quot;MIT&quot;            src=&quot;https://img.shields.io/badge/license-MIT-blue.svg&quot;&gt;                        &lt;/a&gt;
  &lt;a href=&quot;https://github.com/rerun-io/rerun/blob/main/LICENSE-APACHE&quot;&gt; &lt;img alt=&quot;Apache&quot;         src=&quot;https://img.shields.io/badge/license-Apache-blue.svg&quot;&gt;                     &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/Gcm8BbTaAj&quot;&gt;                              &lt;img alt=&quot;Rerun Discord&quot;  src=&quot;https://img.shields.io/discord/1062300748202921994?label=Rerun%20Discord&quot;&gt; &lt;/a&gt;
&lt;/h1&gt;

# Time-aware multimodal data stack and visualizations
Rerun is building the multimodal data stack to model, ingest, store, query and view robotics-style data.
It&#039;s used in areas like robotics, spatial and embodied AI, generative media, industrial processing, simulation, security, and health.

Rerun is easy to use!
Use the Rerun SDK (available for C++, Python and Rust) to log data like images, tensors, point clouds, and text.
Logs are streamed to the Rerun Viewer for live visualization or to file for later use.
You can also query the logged data through [our dataframe API](https://rerun.io/docs/howto/dataframe-api).

[Get started](#getting-started) in minutes ‚Äì no account needed.

* [Run the Rerun Viewer in your browser](https://www.rerun.io/viewer)
* [Read about what Rerun is and who it is for](https://www.rerun.io/docs/getting-started/what-is-rerun)

### A short taste
```py
import rerun as rr  # pip install rerun-sdk

rr.init(&quot;rerun_example_app&quot;)

rr.spawn()  # Spawn a child process with a viewer and connect
# rr.save(&quot;recording.rrd&quot;)  # Stream all logs to disk
# rr.connect_grpc()  # Connect to a remote viewer

# Associate subsequent data with 42 on the ‚Äúframe‚Äù timeline
rr.set_time(&quot;frame&quot;, sequence=42)

# Log colored 3D points to the entity at `path/to/points`
rr.log(&quot;path/to/points&quot;, rr.Points3D(positions, colors=colors))
‚Ä¶
```

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/full.png&quot; alt=&quot;&quot;&gt;
    &lt;source media=&quot;(max-width: 480px)&quot; srcset=&quot;https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/480w.png&quot;&gt;
    &lt;source media=&quot;(max-width: 768px)&quot; srcset=&quot;https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/768w.png&quot;&gt;
    &lt;source media=&quot;(max-width: 1024px)&quot; srcset=&quot;https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/1024w.png&quot;&gt;
    &lt;source media=&quot;(max-width: 1200px)&quot; srcset=&quot;https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/1200w.png&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

## Getting started
* [**C++**](https://www.rerun.io/docs/getting-started/quick-start/cpp)
* [**Python**](https://www.rerun.io/docs/getting-started/quick-start/python): `pip install rerun-sdk` or on [`conda`](https://github.com/conda-forge/rerun-sdk-feedstock)
* [**Rust**](https://www.rerun.io/docs/getting-started/quick-start/rust): `cargo add rerun`

### Installing the Rerun Viewer binary
To stream log data over the network or load our `.rrd` data files you also need the `rerun` binary.
It can be installed with `pip install rerun-sdk` or with `cargo install rerun-cli --locked --features nasm` (see note below).
Note that only the Python SDK comes bundled with the Viewer whereas C++ &amp; Rust always rely on a separate install.

**Note**: the `nasm` Cargo feature requires the [`nasm`](https://github.com/netwide-assembler/nasm) CLI to be installed and available in your path.
Alternatively, you may skip enabling this feature, but this may result in inferior video decoding performance.

You should now be able to run `rerun --help` in any terminal.


### Documentation
- üìö [High-level docs](http://rerun.io/docs)
- ‚èÉ [Loggable Types](https://www.rerun.io/docs/reference/types)
- ‚öôÔ∏è [Examples](http://rerun.io/examples)
- üìñ [Code snippets](./docs/snippets/INDEX.md)
- üåä [C++ API docs](https://ref.rerun.io/docs/cpp)
- üêç [Python API docs](https://ref.rerun.io/docs/python)
- ü¶Ä [Rust API docs](https://docs.rs/rerun/)
- ‚ÅâÔ∏è [Troubleshooting](https://www.rerun.io/docs/getting-started/troubleshooting)


## Status
We are in active development.
There are many features we want to add, and the API is still evolving.
_Expect breaking changes!_

Some shortcomings:
* [The viewer slows down when there are too many entities](https://github.com/rerun-io/rerun/issues/7115)
* [We don&#039;t support transparency yet](https://github.com/rerun-io/rerun/issues/1611)
* The data you want to visualize must fit in RAM
  - See &lt;https://www.rerun.io/docs/howto/limit-ram&gt; for how to bound memory use.
  - We plan on having a disk-based data store some time in the future.
* [Multi-million point clouds can be slow](https://github.com/rerun-io/rerun/issues/1136)


## What is Rerun for?

Rerun is built to help you understand and improve complex processes that include rich multimodal data, like 2D, 3D, text, time series, tensors, etc.
It is used in many industries, including robotics, simulation, computer vision,
or anything that involves a lot of sensors or other signals that evolve over time.

### Example use case
Say you&#039;re building a vacuum cleaning robot and it keeps running into walls. Why is it doing that? You need some tool to debug it, but a normal debugger isn&#039;t gonna be helpful. Similarly, just logging text won&#039;t be very helpful either. The robot may log &quot;Going through doorway&quot; but that won&#039;t explain why it thinks the wall is a door.

What you need is a visual and temporal debugger, that can log all the different representations of the world the robots holds in its little head, such as:

* RGB camera feed
* depth images
* lidar scan
* segmentation image (how the robot interprets what it sees)
* its 3D map of the apartment
* all the objects the robot has detected (or thinks it has detected), as 3D shapes in the 3D map
* its confidence in its prediction
* etc

You also want to see how all these streams of data evolve over time so you can go back and pinpoint exactly what went wrong, when and why.

Maybe it turns out that a glare from the sun hit one of the sensors in the wrong way, confusing the segmentation network leading to bad object detection. Or maybe it was a bug in the lidar scanning code. Or maybe the robot thought it was somewhere else in the apartment, because its odometry was broken. Or it could be one of a thousand other things. Rerun will help you find out!

But seeing the world from the point of the view of the robot is not just for debugging - it will also give you ideas on how to improve the algorithms, new test cases to set up, or datasets to collect. It will also let you explain the brains of the robot to your colleagues, boss, and customers. And so on. Seeing is believing, and an image is worth a thousand words, and multimodal temporal logging is worth a thousand images :)

While seeing and understanding your data is core to making progress in robotics, there is one more thing:
You can also use the data you collected for visualization to create new datasets for training and evaluating the models and algorithms that run on your robot.
Rerun provides query APIs to make it easy to extract clean datasets from your recording for exactly that purpose.

Of course, Rerun is useful for much more than just robots. Any time you have any form of sensors, or 2D or 3D state evolving over time, Rerun is a great tool.


## Business model
Rerun uses an open-core model. Everything in this repository will stay open source and free (both as in beer and as in freedom).

We are also building a commercial data platform.
Right now that is only available for a few select design partners.
[Click here if you&#039;re interested](https://rerun.io/pricing).

The Rerun open source project targets the needs of individual developers.
The commercial product targets the needs specific to teams that build and run computer vision and robotics products.

## How to cite Rerun

When using Rerun in your research, please cite it to acknowledge its contribution to your work. This can be done by
including a reference to Rerun in the software or methods section of your paper.

Suggested citation format:

```bibtex
@software{RerunSDK,
  title = {Rerun: A Visualization SDK for Multimodal Data},
  author = {{Rerun Development Team}},
  url = {https://www.rerun.io},
  version = {insert version number},
  date = {insert date of usage},
  year = {2024},
  publisher = {{Rerun Technologies AB}},
  address = {Online},
  note = {Available from https://www.rerun.io/ and https://github.com/rerun-io/rerun}
}
```

Please replace &quot;insert version number&quot; with the version of Rerun you used and &quot;insert date of usage&quot; with the date(s)
you used the tool in your research.
This citation format helps ensure that Rerun&#039;s development team receives appropriate credit for their work and
facilitates the tool&#039;s discovery by other researchers.

# Development
* [`ARCHITECTURE.md`](ARCHITECTURE.md)
* [`CODE_OF_CONDUCT.md`](CODE_OF_CONDUCT.md)
* [`CODE_STYLE.md`](CODE_STYLE.md)
* [`CONTRIBUTING.md`](CONTRIBUTING.md)
* [`BUILD.md`](BUILD.md)
* [`rerun_py/README.md`](rerun_py/README.md) - instructions for Python SDK
* [`rerun_cpp/README.md`](rerun_cpp/README.md) - instructions for C++ SDK


## Installing a pre-release Python SDK

1. Download the correct `.whl` from [GitHub Releases](https://github.com/rerun-io/rerun/releases)
2. Run `pip install rerun_sdk&lt;‚Ä¶&gt;.whl` (replace `&lt;‚Ä¶&gt;` with the actual filename)
3. Test it: `rerun --version`
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[neondatabase/neon]]></title>
            <link>https://github.com/neondatabase/neon</link>
            <guid>https://github.com/neondatabase/neon</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:14 GMT</pubDate>
            <description><![CDATA[Neon: Serverless Postgres. We separated storage and compute to offer autoscaling, code-like database branching, and scale to zero.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/neondatabase/neon">neondatabase/neon</a></h1>
            <p>Neon: Serverless Postgres. We separated storage and compute to offer autoscaling, code-like database branching, and scale to zero.</p>
            <p>Language: Rust</p>
            <p>Stars: 19,139</p>
            <p>Forks: 719</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>[![Neon](https://github.com/neondatabase/neon/assets/11527560/f15a17f0-836e-40c5-b35d-030606a6b660)](https://neon.tech)



# Neon

Neon is a serverless open-source alternative to AWS Aurora Postgres. It separates storage and compute and substitutes the PostgreSQL storage layer by redistributing data across a cluster of nodes.

## Quick start
Try the [Neon Free Tier](https://neon.tech/github) to create a serverless Postgres instance. Then connect to it with your preferred Postgres client (psql, dbeaver, etc) or use the online [SQL Editor](https://neon.tech/docs/get-started-with-neon/query-with-neon-sql-editor/). See [Connect from any application](https://neon.tech/docs/connect/connect-from-any-app/) for connection instructions.

Alternatively, compile and run the project [locally](#running-local-installation).

## Architecture overview

A Neon installation consists of compute nodes and the Neon storage engine. Compute nodes are stateless PostgreSQL nodes backed by the Neon storage engine.

The Neon storage engine consists of two major components:
- Pageserver: Scalable storage backend for the compute nodes.
- Safekeepers: The safekeepers form a redundant WAL service that received WAL from the compute node, and stores it durably until it has been processed by the pageserver and uploaded to cloud storage.

See developer documentation in [SUMMARY.md](/docs/SUMMARY.md) for more information.

## Running a local development environment

Neon can be run on a workstation for small experiments and to test code changes, by
following these instructions.

#### Installing dependencies on Linux
1. Install build dependencies and other applicable packages

* On Ubuntu or Debian, this set of packages should be sufficient to build the code:
```bash
apt install build-essential libtool libreadline-dev zlib1g-dev flex bison libseccomp-dev \
libssl-dev clang pkg-config libpq-dev cmake postgresql-client protobuf-compiler \
libprotobuf-dev libcurl4-openssl-dev openssl python3-poetry lsof libicu-dev
```
* On Fedora, these packages are needed:
```bash
dnf install flex bison readline-devel zlib-devel openssl-devel \
  libseccomp-devel perl clang cmake postgresql postgresql-contrib protobuf-compiler \
  protobuf-devel libcurl-devel openssl poetry lsof libicu-devel libpq-devel python3-devel \
  libffi-devel
```
* On Arch based systems, these packages are needed:
```bash
pacman -S base-devel readline zlib libseccomp openssl clang \
postgresql-libs cmake postgresql protobuf curl lsof
```

Building Neon requires 3.15+ version of `protoc` (protobuf-compiler). If your distribution provides an older version, you can install a newer version from [here](https://github.com/protocolbuffers/protobuf/releases).

2. [Install Rust](https://www.rust-lang.org/tools/install)
```
# recommended approach from https://www.rust-lang.org/tools/install
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

#### Installing dependencies on macOS (12.3.1)
1. Install XCode and dependencies
```
xcode-select --install
brew install protobuf openssl flex bison icu4c pkg-config m4

# add openssl to PATH, required for ed25519 keys generation in neon_local
echo &#039;export PATH=&quot;$(brew --prefix openssl)/bin:$PATH&quot;&#039; &gt;&gt; ~/.zshrc
```

If you get errors about missing `m4` you may have to install it manually:
```
brew install m4
brew link --force m4
```

2. [Install Rust](https://www.rust-lang.org/tools/install)
```
# recommended approach from https://www.rust-lang.org/tools/install
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
```

3. Install PostgreSQL Client
```
# from https://stackoverflow.com/questions/44654216/correct-way-to-install-psql-without-full-postgres-on-macos
brew install libpq
brew link --force libpq
```

#### Rustc version

The project uses [rust toolchain file](./rust-toolchain.toml) to define the version it&#039;s built with in CI for testing and local builds.

This file is automatically picked up by [`rustup`](https://rust-lang.github.io/rustup/overrides.html#the-toolchain-file) that installs (if absent) and uses the toolchain version pinned in the file.

rustup users who want to build with another toolchain can use the [`rustup override`](https://rust-lang.github.io/rustup/overrides.html#directory-overrides) command to set a specific toolchain for the project&#039;s directory.

non-rustup users most probably are not getting the same toolchain automatically from the file, so are responsible to manually verify that their toolchain matches the version in the file.
Newer rustc versions most probably will work fine, yet older ones might not be supported due to some new features used by the project or the crates.

#### Building on Linux

1. Build neon and patched postgres
```
# Note: The path to the neon sources can not contain a space.

git clone --recursive https://github.com/neondatabase/neon.git
cd neon

# The preferred and default is to make a debug build. This will create a
# demonstrably slower build than a release build. For a release build,
# use &quot;BUILD_TYPE=release make -j`nproc` -s&quot;
# Remove -s for the verbose build log

make -j`nproc` -s
```

#### Building on OSX

1. Build neon and patched postgres
```
# Note: The path to the neon sources can not contain a space.

git clone --recursive https://github.com/neondatabase/neon.git
cd neon

# The preferred and default is to make a debug build. This will create a
# demonstrably slower build than a release build. For a release build,
# use &quot;BUILD_TYPE=release make -j`sysctl -n hw.logicalcpu` -s&quot;
# Remove -s for the verbose build log

make -j`sysctl -n hw.logicalcpu` -s
```

#### Dependency installation notes
To run the `psql` client, install the `postgresql-client` package or modify `PATH` and `LD_LIBRARY_PATH` to include `pg_install/bin` and `pg_install/lib`, respectively.

To run the integration tests or Python scripts (not required to use the code), install
Python (3.11 or higher), and install the python3 packages using `./scripts/pysync` (requires [poetry&gt;=1.8](https://python-poetry.org/)) in the project directory.


#### Running neon database
1. Start pageserver and postgres on top of it (should be called from repo root):
```sh
# Create repository in .neon with proper paths to binaries and data
# Later that would be responsibility of a package install script
&gt; cargo neon init
Initializing pageserver node 1 at &#039;127.0.0.1:64000&#039; in &quot;.neon&quot;

# start pageserver, safekeeper, and broker for their intercommunication
&gt; cargo neon start
Starting neon broker at 127.0.0.1:50051.
storage_broker started, pid: 2918372
Starting pageserver node 1 at &#039;127.0.0.1:64000&#039; in &quot;.neon&quot;.
pageserver started, pid: 2918386
Starting safekeeper at &#039;127.0.0.1:5454&#039; in &#039;.neon/safekeepers/sk1&#039;.
safekeeper 1 started, pid: 2918437

# create initial tenant and use it as a default for every future neon_local invocation
&gt; cargo neon tenant create --set-default
tenant 9ef87a5bf0d92544f6fafeeb3239695c successfully created on the pageserver
Created an initial timeline &#039;de200bd42b49cc1814412c7e592dd6e9&#039; at Lsn 0/16B5A50 for tenant: 9ef87a5bf0d92544f6fafeeb3239695c
Setting tenant 9ef87a5bf0d92544f6fafeeb3239695c as a default one

# create postgres compute node
&gt; cargo neon endpoint create main

# start postgres compute node
&gt; cargo neon endpoint start main
Starting new endpoint main (PostgreSQL v14) on timeline de200bd42b49cc1814412c7e592dd6e9 ...
Starting postgres at &#039;postgresql://cloud_admin@127.0.0.1:55432/postgres&#039;

# check list of running postgres instances
&gt; cargo neon endpoint list
 ENDPOINT  ADDRESS          TIMELINE                          BRANCH NAME  LSN        STATUS
 main      127.0.0.1:55432  de200bd42b49cc1814412c7e592dd6e9  main         0/16B5BA8  running
```

2. Now, it is possible to connect to postgres and run some queries:
```text
&gt; psql -p 55432 -h 127.0.0.1 -U cloud_admin postgres
postgres=# CREATE TABLE t(key int primary key, value text);
CREATE TABLE
postgres=# insert into t values(1,1);
INSERT 0 1
postgres=# select * from t;
 key | value
-----+-------
   1 | 1
(1 row)
```

3. And create branches and run postgres on them:
```sh
# create branch named migration_check
&gt; cargo neon timeline branch --branch-name migration_check
Created timeline &#039;b3b863fa45fa9e57e615f9f2d944e601&#039; at Lsn 0/16F9A00 for tenant: 9ef87a5bf0d92544f6fafeeb3239695c. Ancestor timeline: &#039;main&#039;

# check branches tree
&gt; cargo neon timeline list
(L) main [de200bd42b49cc1814412c7e592dd6e9]
(L) ‚îó‚îÅ @0/16F9A00: migration_check [b3b863fa45fa9e57e615f9f2d944e601]

# create postgres on that branch
&gt; cargo neon endpoint create migration_check --branch-name migration_check

# start postgres on that branch
&gt; cargo neon endpoint start migration_check
Starting new endpoint migration_check (PostgreSQL v14) on timeline b3b863fa45fa9e57e615f9f2d944e601 ...
Starting postgres at &#039;postgresql://cloud_admin@127.0.0.1:55434/postgres&#039;

# check the new list of running postgres instances
&gt; cargo neon endpoint list
 ENDPOINT         ADDRESS          TIMELINE                          BRANCH NAME      LSN        STATUS
 main             127.0.0.1:55432  de200bd42b49cc1814412c7e592dd6e9  main             0/16F9A38  running
 migration_check  127.0.0.1:55434  b3b863fa45fa9e57e615f9f2d944e601  migration_check  0/16F9A70  running

# this new postgres instance will have all the data from &#039;main&#039; postgres,
# but all modifications would not affect data in original postgres
&gt; psql -p 55434 -h 127.0.0.1 -U cloud_admin postgres
postgres=# select * from t;
 key | value
-----+-------
   1 | 1
(1 row)

postgres=# insert into t values(2,2);
INSERT 0 1

# check that the new change doesn&#039;t affect the &#039;main&#039; postgres
&gt; psql -p 55432 -h 127.0.0.1 -U cloud_admin postgres
postgres=# select * from t;
 key | value
-----+-------
   1 | 1
(1 row)
```

4. If you want to run tests afterwards (see below), you must stop all the running pageserver, safekeeper, and postgres instances
   you have just started. You can terminate them all with one command:
```sh
&gt; cargo neon stop
```

More advanced usages can be found at [Local Development Control Plane (`neon_local`))](./control_plane/README.md).

#### Handling build failures

If you encounter errors during setting up the initial tenant, it&#039;s best to stop everything (`cargo neon stop`) and remove the `.neon` directory. Then fix the problems, and start the setup again.

## Running tests

### Rust unit tests

We are using [`cargo-nextest`](https://nexte.st/) to run the tests in Github Workflows.
Some crates do not support running plain `cargo test` anymore, prefer `cargo nextest run` instead.
You can install `cargo-nextest` with `cargo install cargo-nextest`.

### Integration tests

Ensure your dependencies are installed as described [here](https://github.com/neondatabase/neon#dependency-installation-notes).

```sh
git clone --recursive https://github.com/neondatabase/neon.git

CARGO_BUILD_FLAGS=&quot;--features=testing&quot; make

./scripts/pytest
```

By default, this runs both debug and release modes, and all supported postgres versions. When
testing locally, it is convenient to run just one set of permutations, like this:

```sh
DEFAULT_PG_VERSION=17 BUILD_TYPE=release ./scripts/pytest
```

## Flamegraphs

You may find yourself in need of flamegraphs for software in this repository.
You can use [`flamegraph-rs`](https://github.com/flamegraph-rs/flamegraph) or the original [`flamegraph.pl`](https://github.com/brendangregg/FlameGraph). Your choice!

&gt;[!IMPORTANT]
&gt; If you&#039;re using `lld` or `mold`, you need the `--no-rosegment` linker argument.
&gt; It&#039;s a [general thing with Rust / lld / mold](https://crbug.com/919499#c16), not specific to this repository.
&gt; See [this PR for further instructions](https://github.com/neondatabase/neon/pull/6764).

## Cleanup

For cleaning up the source tree from build artifacts, run `make clean` in the source directory.

For removing every artifact from build and configure steps, run `make distclean`, and also consider removing the cargo binaries in the `target` directory, as well as the database in the `.neon` directory. Note that removing the `.neon` directory will remove your database, with all data in it. You have been warned!

## Documentation

[docs](/docs) Contains a top-level overview of all available markdown documentation.

- [sourcetree.md](/docs/sourcetree.md) contains overview of source tree layout.

To view your `rustdoc` documentation in a browser, try running `cargo doc --no-deps --open`

See also README files in some source directories, and `rustdoc` style documentation comments.

Other resources:

- [SELECT &#039;Hello, World&#039;](https://neon.tech/blog/hello-world/): Blog post by Nikita Shamgunov on the high level architecture
- [Architecture decisions in Neon](https://neon.tech/blog/architecture-decisions-in-neon/): Blog post by Heikki Linnakangas
- [Neon: Serverless PostgreSQL!](https://www.youtube.com/watch?v=rES0yzeERns): Presentation on storage system by Heikki Linnakangas in the CMU Database Group seminar series

### Postgres-specific terms

Due to Neon&#039;s very close relation with PostgreSQL internals, numerous specific terms are used.
The same applies to certain spelling: i.e. we use MB to denote 1024 * 1024 bytes, while MiB would be technically more correct, it&#039;s inconsistent with what PostgreSQL code and its documentation use.

To get more familiar with this aspect, refer to:

- [Neon glossary](/docs/glossary.md)
- [PostgreSQL glossary](https://www.postgresql.org/docs/14/glossary.html)
- Other PostgreSQL documentation and sources (Neon fork sources can be found [here](https://github.com/neondatabase/postgres))

## Join the development

- Read [CONTRIBUTING.md](/CONTRIBUTING.md) to learn about project code style and practices.
- To get familiar with a source tree layout, use [sourcetree.md](/docs/sourcetree.md).
- To learn more about PostgreSQL internals, check http://www.interdb.jp/pg/index.html
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[databendlabs/databend]]></title>
            <link>https://github.com/databendlabs/databend</link>
            <guid>https://github.com/databendlabs/databend</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:13 GMT</pubDate>
            <description><![CDATA[ùóóùóÆùòÅùóÆ, ùóîùóªùóÆùóπùòÜùòÅùó∂ùó∞ùòÄ & ùóîùóú. Modern alternative to Snowflake. Cost-effective and simple for massive-scale analytics. https://databend.com]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/databendlabs/databend">databendlabs/databend</a></h1>
            <p>ùóóùóÆùòÅùóÆ, ùóîùóªùóÆùóπùòÜùòÅùó∂ùó∞ùòÄ & ùóîùóú. Modern alternative to Snowflake. Cost-effective and simple for massive-scale analytics. https://databend.com</p>
            <p>Language: Rust</p>
            <p>Stars: 8,646</p>
            <p>Forks: 795</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;Databend: The Next-Gen Cloud [Data+AI] Analytics&lt;/h1&gt;
&lt;h2 align=&quot;center&quot;&gt;The open-source, on-premise alternative to Snowflake&lt;/h2&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.databend.com/guides/cloud&quot;&gt;Databend Serverless Cloud (beta)&lt;/a&gt;  |
  &lt;a href=&quot;https://docs.databend.com/&quot;&gt;Documentation&lt;/a&gt;  |
  &lt;a href=&quot;https://benchmark.clickhouse.com/&quot;&gt;Benchmarking&lt;/a&gt;  |
  &lt;a href=&quot;https://github.com/databendlabs/databend/issues/11868&quot;&gt;Roadmap (v1.3)&lt;/a&gt;

&lt;/h4&gt;

&lt;div&gt;
&lt;a href=&quot;https://link.databend.com/join-slack&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/slack-databend-0abd59?logo=slack&quot; alt=&quot;slack&quot; /&gt;
&lt;/a&gt;

&lt;a href=&quot;https://link.databend.com/join-feishu&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/feishu-databend-0abd59&quot; alt=&quot;feishu&quot; /&gt;
&lt;/a&gt;

&lt;br&gt;

&lt;a href=&quot;https://github.com/databendlabs/databend/actions/workflows/release.yml&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/datafuselabs/databend/release.yml?branch=main&quot; alt=&quot;CI Status&quot; /&gt;
&lt;/a&gt;

&lt;img src=&quot;https://img.shields.io/badge/Platform-Linux%2C%20macOS%2C%20ARM-green.svg?style=flat&quot; alt=&quot;Linux Platform&quot; /&gt;

&lt;a href=&quot;https://gurubase.io/g/databend&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20Databend%20Guru-006BFF&quot; alt=&quot;Gurubase&quot; /&gt;
&lt;/a&gt;

&lt;/div&gt;
&lt;/div&gt;

&lt;img src=&quot;https://github.com/databendlabs/databend/assets/172204/9997d8bc-6462-4dbd-90e3-527cf50a709c&quot; alt=&quot;databend&quot; /&gt;

## üêã Introduction

**Databend**, built in Rust, is an open-source cloud data warehouse that serves as a cost-effective [alternative to Snowflake](https://github.com/databendlabs/databend/issues/13059). With its focus on fast query execution and data ingestion, it&#039;s designed for complex analysis of the world&#039;s largest datasets.

**Production-Proven Scale:**
- ü§ù **Enterprise Adoption**: Trusted by over **50 organizations** processing more than **100 million queries daily**
- üóÑÔ∏è **Massive Scale**: Successfully managing over **800 petabytes** of analytical data

## ‚ö° Performance

&lt;div align=&quot;center&quot;&gt;

[TPC-H Benchmark: Databend Cloud vs. Snowflake](https://docs.databend.com/guides/benchmark/tpch)

&lt;/div&gt;

![Databend vs. Snowflake](https://github.com/databendlabs/wizard/assets/172204/d796acf0-0a66-4b1d-8754-cd2cd1de04c7)

&lt;div align=&quot;center&quot;&gt;

[Data Ingestion Benchmark: Databend Cloud vs. Snowflake](https://docs.databend.com/guides/benchmark/data-ingest)

&lt;/div&gt;

![Databend vs. Snowflake](https://github.com/databendlabs/databend/assets/172204/c61d7a40-f6fe-4fb9-83e8-06ea9599aeb4)


## üöÄ Why Databend

- **Full Control**: Deploy on **cloud** or **on-prem** to suit your needs.

- **Blazing-Fast Performance**: Built with **Rust** for high-speed query execution. üëâ [ClickBench](https://databend.com/blog/clickbench-databend-top)

- **Cost-Effective**: Scalable architecture that boosts **performance** and reduces **costs**. üëâ [TPC-H](https://docs.databend.com/guides/benchmark/tpch)

- **AI-Enhanced Analytics**: Leverage built-in **[AI Functions](https://docs.databend.com/guides/ai-functions/)** for smarter data insights.

- **Simplified ETL**: Direct **data ingestion** without the need for external ETL tools. üëâ [Data Loading](https://docs.databend.com/guides/load-data/)

- **Real-Time Data Updates**: Keep your analytics **up-to-date** with real-time incremental data updates. üëâ [Stream](https://docs.databend.com/guides/load-data/continuous-data-pipelines/stream)

- **Advanced Indexing**: Boost query performance with **[Virtual Column](https://docs.databend.com/guides/performance/virtual-column)**, **[Aggregating Index](https://docs.databend.com/guides/performance/aggregating-index)**, and **[Full-Text Index](https://docs.databend.com/guides/performance/fulltext-index)**.

- **ACID Compliance + Version Control**: Ensure reliable **transactions** with full ACID compliance and Git-like versioning.

- **Schema Flexibility**: Effortlessly handle **semi-structured data** with the flexible **[VARIANT](https://docs.databend.com/sql/sql-reference/data-types/variant)** data type.

- **Community-Driven Growth**: **Open-source** and continuously evolving with contributions from a global community.



## üìê Architecture

![Databend Architecture](https://github.com/databendlabs/databend/assets/172204/68b1adc6-0ec1-41d4-9e1d-37b80ce0e5ef)

## üöÄ Try Databend

### 1. Databend Serverless Cloud

The fastest way to try Databend, [Databend Cloud](https://databend.com)

### 2. Install Databend from Docker

Prepare the image (once) from Docker Hub (this will download about 170 MB data):

```shell
docker pull datafuselabs/databend
```

To run Databend quickly:

```shell
docker run --net=host  datafuselabs/databend
```

## üöÄ Getting Started

&lt;details&gt;
&lt;summary&gt;Connecting to Databend&lt;/summary&gt;

- [Connecting to Databend with BendSQL](https://docs.databend.com/guides/sql-clients/bendsql)
- [Connecting to Databend with JDBC](https://docs.databend.com/guides/sql-clients/jdbc)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Data Import and Export&lt;/summary&gt;

- [How to load Parquet file into a table](https://docs.databend.com/guides/load-data/load-semistructured/load-parquet)
- [How to export a table to Parquet file](https://docs.databend.com/guides/unload-data/unload-parquet)
- [How to load CSV file into a table](https://docs.databend.com/guides/load-data/load-semistructured/load-csv)
- [How to export a table to CSV file](https://docs.databend.com/guides/unload-data/unload-csv)
- [How to load TSV file into a table](https://docs.databend.com/guides/load-data/load-semistructured/load-tsv)
- [How to export a table to TSV file](https://docs.databend.com/guides/unload-data/unload-tsv)
- [How to load NDJSON file into a table](https://docs.databend.com/guides/load-data/load-semistructured/load-ndjson)
- [How to export a table to NDJSON file](https://docs.databend.com/guides/unload-data/unload-ndjson)
- [How to load ORC file into a table](https://docs.databend.com/guides/load-data/load-semistructured/load-orc)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Loading Data From Other Databases&lt;/summary&gt;

- [How to Sync Full and Incremental MySQL Changes into Databend](https://docs.databend.com/guides/load-data/load-db/debezium)
- [How to Sync Full and Incremental PostgreSQL Changes into Databend](https://docs.databend.com/guides/load-data/load-db/flink-cdc)
- [How to Sync Full and Incremental Oracle Changes into Databend](https://docs.databend.com/guides/load-data/load-db/flink-cdc)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Querying Semi-structured Data&lt;/summary&gt;

- [How to query directly on Parquet file](https://docs.databend.com/guides/load-data/transform/querying-parquet)
- [How to query directly on CSV file](https://docs.databend.com/guides/load-data/transform/querying-csv)
- [How to query directly on TSV file](https://docs.databend.com/guides/load-data/transform/querying-tsv)
- [How to query directly on NDJSON file](https://docs.databend.com/guides/load-data/transform/querying-ndjson)
- [How to query directly on ORC file](https://docs.databend.com/guides/load-data/transform/querying-orc)
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Visualize Tools with Databend&lt;/summary&gt;

- [Deepnote](https://docs.databend.com/guides/visualize/deepnote)
- [Grafana](https://docs.databend.com/guides/visualize/grafana)
- [Jupyter Notebook](https://docs.databend.com/guides/visualize/jupyter)
- [Metabase](https://docs.databend.com/guides/visualize/metabase)
- [MindsDB](https://docs.databend.com/guides/visualize/mindsdb)
- [Redash](https://docs.databend.com/guides/visualize/redash)
- [Superset](https://docs.databend.com/guides/visualize/superset)
- [Tableau](https://docs.databend.com/guides/visualize/tableau)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Managing Users&lt;/summary&gt;

- [How to Create a User](https://docs.databend.com/sql/sql-commands/ddl/user/user-create-user)
- [How to Grant Privileges to a User](https://docs.databend.com/sql/sql-commands/ddl/user/grant#granting-privileges)
- [How to Revoke Privileges from a User](https://docs.databend.com/sql/sql-commands/ddl/user/revoke#revoking-privileges)
- [How to Create a Role](https://docs.databend.com/sql/sql-commands/ddl/user/user-create-role)
- [How to Grant Privileges to a Role](https://docs.databend.com/sql/sql-commands/ddl/user/grant#granting-role)
- [How to Grant Role to a User](https://docs.databend.com/sql/sql-commands/ddl/user/grant)
- [How to Revoke the Role of a User](https://docs.databend.com/sql/sql-commands/ddl/user/revoke#revoking-role)
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Managing Databases&lt;/summary&gt;

- [How to Create a Database](https://docs.databend.com/sql/sql-commands/ddl/database/ddl-create-database)
- [How to Drop a Database](https://docs.databend.com/sql/sql-commands/ddl/database/ddl-drop-database)
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Managing Tables&lt;/summary&gt;

- [How to Create a Table](https://docs.databend.com/sql/sql-commands/ddl/table/ddl-create-table)
- [How to Drop a Table](https://docs.databend.com/sql/sql-commands/ddl/table/ddl-drop-table)
- [How to Rename a Table](https://docs.databend.com/sql/sql-commands/ddl/table/ddl-rename-table)
- [How to Truncate a Table](https://docs.databend.com/sql/sql-commands/ddl/table/ddl-truncate-table)
- [How to Flash Back a Table](https://docs.databend.com/sql/sql-commands/ddl/table/flashback-table)
- [How to Add/Drop Table Column](https://docs.databend.com/sql/sql-commands/ddl/table/alter-table-column)
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Managing Data&lt;/summary&gt;

- [COPY-INTO](https://docs.databend.com/sql/sql-commands/dml/dml-copy-into-table)
- [INSERT](https://docs.databend.com/sql/sql-commands/dml/dml-insert)
- [DELETE](https://docs.databend.com/sql/sql-commands/dml/dml-delete-from)
- [UPDATE](https://docs.databend.com/sql/sql-commands/dml/dml-update)
- [REPLACE](https://docs.databend.com/sql/sql-commands/dml/dml-replace)
- [MERGE-INTO](https://docs.databend.com/sql/sql-commands/dml/dml-merge)
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Managing Views&lt;/summary&gt;

- [How to Create a View](https://docs.databend.com/sql/sql-commands/ddl/view/ddl-create-view)
- [How to Drop a View](https://docs.databend.com/sql/sql-commands/ddl/view/ddl-drop-view)
- [How to Alter a View](https://docs.databend.com/sql/sql-commands/ddl/view/ddl-alter-view)
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;AI Functions&lt;/summary&gt;

- [Generating SQL with AI](https://docs.databend.com/sql/sql-functions/ai-functions/ai-to-sql)
- [Creating Embedding Vectors](https://docs.databend.com/sql/sql-functions/ai-functions/ai-embedding-vector)
- [Text Completion with AI](https://docs.databend.com/sql/sql-functions/ai-functions/ai-text-completion)
- [Vector Distance](https://docs.databend.com/sql/sql-functions/vector-distance-functions/)
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Data Management&lt;/summary&gt;

- [Data Lifecycle in Databend](https://docs.databend.com/guides/data-management/data-lifecycle)
- [Data Recovery in Databend](https://docs.databend.com/guides/data-management/data-recovery)
- [Data Protection in Databend](https://docs.databend.com/guides/data-management/data-protection)
- [Data Purge in Databend](https://docs.databend.com/guides/data-management/data-recycle)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Accessing Data Lake&lt;/summary&gt;

- [Apache Hive](https://docs.databend.com/guides/access-data-lake/hive)
- [Apache Iceberg](https://docs.databend.com/guides/access-data-lake/iceberg/)
- [Delta Lake](https://docs.databend.com/guides/access-data-lake/delta)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Security&lt;/summary&gt;

- [Access Control](https://docs.databend.com/guides/security/access-control)
- [Masking Policy](https://docs.databend.com/guides/security/masking-policy)
- [Network Policy](https://docs.databend.com/guides/security/network-policy)
- [Password Policy](https://docs.databend.com/guides/security/password-policy)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Performance&lt;/summary&gt;

- [Review Clickbench](https://databend.com/blog/clickbench-databend-top)
- [TPC-H Benchmark: Databend Cloud vs. Snowflake](https://docs.databend.com/guides/benchmark/tpch)
- [Databend vs. Snowflake: Data Ingestion Benchmark](https://docs.databend.com/guides/benchmark/data-ingest)

&lt;/details&gt;

## ü§ù Contributing

Databend thrives on community contributions! Whether it&#039;s through ideas, code, or documentation, every effort helps in enhancing our project. As a token of our appreciation, once your code is merged, your name will be eternally preserved in the **system.contributors** table.

Here are some resources to help you get started:

- [Building Databend From Source](https://docs.databend.com/developer/community/contributor/building-from-source)
- [The First Good Pull Request](https://docs.databend.com/developer/community/contributor/good-pr)

## üë• Community

For guidance on using Databend, we recommend starting with the official documentation. If you need further assistance, explore the following community channels:

- [Slack](https://link.databend.com/join-slack) (For live discussion with the Community)
- [GitHub](https://github.com/databendlabs/databend) (Feature/Bug reports, Contributions)
- [Twitter](https://twitter.com/DatabendLabs/) (Get the news fast)
- [I&#039;m feeling lucky](https://link.databend.com/i-m-feeling-lucky) (Pick up a good first issue now!)

## üõ£Ô∏è Roadmap

Stay updated with Databend&#039;s development journey. Here are our roadmap milestones:

- [Roadmap 2025](https://github.com/databendlabs/databend/issues/14167)

## üìú License

Databend is released under a combination of two licenses: the [Apache License 2.0](licenses/Apache-2.0.txt) and the [Elastic License 2.0](licenses/Elastic.txt).

When contributing to Databend, you can find the relevant license header in each file.

For more information, see the [LICENSE](LICENSE) file and [Licensing FAQs](https://docs.databend.com/guides/products/dee/license).

## üôè Acknowledgement

- **Inspiration**: Databend&#039;s design draws inspiration from industry leaders [ClickHouse](https://github.com/clickhouse/clickhouse) and [Snowflake](https://docs.snowflake.com/en/user-guide/intro-key-concepts.html#snowflake-architecture).

- **Computing Model**: Our computing foundation is built upon apache arrow.

- **Documentation Hosting**: The [Databend documentation website](https://docs.databend.com) proudly runs on [Vercel](https://vercel.com/?utm_source=databend&amp;utm_campaign=oss).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[get-convex/convex-backend]]></title>
            <link>https://github.com/get-convex/convex-backend</link>
            <guid>https://github.com/get-convex/convex-backend</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:12 GMT</pubDate>
            <description><![CDATA[The open-source reactive database for app developers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/get-convex/convex-backend">get-convex/convex-backend</a></h1>
            <p>The open-source reactive database for app developers</p>
            <p>Language: Rust</p>
            <p>Stars: 5,815</p>
            <p>Forks: 303</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://static.convex.dev/logo/convex-logo-light.svg&quot; width=&quot;600&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://static.convex.dev/logo/convex-logo.svg&quot; width=&quot;600&quot;&gt;
  &lt;img alt=&quot;Convex logo&quot; src=&quot;https://static.convex.dev/logo/convex-logo.svg&quot; width=&quot;600&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;

[Convex](https://convex.dev) is the open-source reactive database designed to
make life easy for web app developers, whether human or LLM. Fetch data and
perform business logic with strong consistency by writing pure TypeScript.

Convex provides a database, a place to write your server functions, and client
libraries. It makes it easy to build and scale dynamic live-updating apps.
[Read the docs to learn more](https://docs.convex.dev/understanding/).

Development of the Convex backend is led by the Convex team. We
[welcome bug fixes](./CONTRIBUTING.md) and
[love receiving feedback](https://discord.gg/convex). We keep this repository
synced with any internal development work within a handful of days.

## Getting Started

Visit our [documentation](https://docs.convex.dev/) to learn more about Convex
and follow our getting started guides.

The easiest way to build with Convex is through our
[cloud platform](https://www.convex.dev/plans), which includes a generous free
tier and lets you focus on building your application without worrying about
infrastructure. Many small applications and side-projects can operate entirely
on the free tier with zero cost and zero maintenance.

## Self Hosting

The self-hosted product includes most features of the cloud product, including
the dashboard and CLI. Self-hosted Convex works well with a variety of tools
including Neon, Fly.io, Vercel, Netlify, RDS, Sqlite, Postgres, and more.

You can either use Docker (recommended) or a prebuilt binary to self host
Convex. Check out our [self-hosting guide](./self-hosted/README.md) for detailed
instructions. Community support for self-hosting is available in the
`#self-hosted` channel on [Discord](https://discord.gg/convex).

## Community &amp; Support

- Join our [Discord community](https://discord.gg/convex) for help and
  discussions.
- Report issues when building and using the open source Convex backend through
  [GitHub Issues](https://github.com/get-convex/convex-backend/issues)

## Building from source

See [BUILD.md](./BUILD.md).

## Disclaimers

- If you choose to self-host, we recommend following the self-hosting guide. If
  you are instead building from source, make sure to change your instance secret
  and admin key from the defaults in the repo.
- Convex is battle tested most thoroughly on Linux and Mac. On Windows, it has
  less experience. If you run into issues, please message us on
  [Discord](https://convex.dev/community) in the `#self-hosted` channel.
- Convex self-hosted builds contain a beacon to help Convex improve the product.
  The information is minimal and anonymous and helpful to Convex, but if you
  really want to disable it, you can set the `--disable-beacon` flag on the
  backend binary. The beacon&#039;s messages print in the log and only include
  - A random identifier for your deployment (not used elsewhere)
  - Migration version of your database
  - Git rev of the backend
  - Uptime of the backend

## Repository layout

- `crates/` contains Rust code

  - Main binary
    - `local_backend/` is an application server on top of the `Runtime`. This is
      the serving edge for the Convex cloud.

- `npm-packages/` contains both our public and internal TypeScript packages.
  - Internal packages
    - `udf-runtime/` sets up the user-defined functions JS environment for
      queries and mutations
    - `udf-tests/` is a collection of functions used in testing the isolate
      layer
    - `system-udfs/` contains functions used by the Convex system e.g. the CLI
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[linera-io/linera-protocol]]></title>
            <link>https://github.com/linera-io/linera-protocol</link>
            <guid>https://github.com/linera-io/linera-protocol</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:11 GMT</pubDate>
            <description><![CDATA[Main repository for the Linera protocol]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/linera-io/linera-protocol">linera-io/linera-protocol</a></h1>
            <p>Main repository for the Linera protocol</p>
            <p>Language: Rust</p>
            <p>Stars: 27,821</p>
            <p>Forks: 1,838</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/linera-io/linera-protocol/assets/1105398/fe08c941-93af-4114-bb83-bcc0eaec95f9&quot; width=&quot;250&quot; height=&quot;85&quot; /&gt;

[![License](https://img.shields.io/github/license/linera-io/linera-protocol)](LICENSE)
[![Build Status for Docker](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/docker-compose.yml)
[![Build Status for Rust](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/rust.yml)
[![Build Status for Documentation](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/documentation.yml)
[![Twitter](https://img.shields.io/twitter/follow/linera_io)](https://x.com/linera_io)
[![Discord](https://img.shields.io/discord/984941796272521226)](https://discord.com/invite/linera)

&lt;!-- [![Build Status for Kubernetes](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml/badge.svg)](https://github.com/linera-io/linera-protocol/actions/workflows/kubernetes.yml) --&gt;

[Linera](https://linera.io) is a decentralized blockchain infrastructure designed for highly scalable,
secure, low-latency Web3 applications.

## Documentation

Visit our [developer page](https://linera.dev) and read our
[whitepaper](https://linera.io/whitepaper) to learn more about the Linera protocol.

## Repository Structure

The main crates and directories of this repository can be summarized as follows: (listed
from low to high levels in the dependency graph)

* [`linera-base`](https://linera-io.github.io/linera-protocol/linera_base/index.html) Base
  definitions, including cryptography.

* [`linera-version`](https://linera-io.github.io/linera-protocol/linera_version/index.html)
  A library to manage version info in binaries and services.

* [`linera-views`](https://linera-io.github.io/linera-protocol/linera_views/index.html) A
  library mapping complex data structures onto a key-value store. The corresponding
  procedural macros are implemented in `linera-views-derive`.

* [`linera-execution`](https://linera-io.github.io/linera-protocol/linera_execution/index.html)
  Persistent data and the corresponding logic for runtime and execution of Linera
  applications.

* [`linera-chain`](https://linera-io.github.io/linera-protocol/linera_chain/index.html)
  Persistent data and the corresponding logic for chains of blocks, certificates, and
  cross-chain messaging.

* [`linera-storage`](https://linera-io.github.io/linera-protocol/linera_storage/index.html)
  Defines the storage abstractions for the protocol on top of `linera-chain`.

* [`linera-core`](https://linera-io.github.io/linera-protocol/linera_core/index.html) The
  core Linera protocol, including client and server logic, node synchronization, etc.

* [`linera-rpc`](https://linera-io.github.io/linera-protocol/linera_rpc/index.html)
  Defines the data-type for RPC messages (currently all client &amp;#x2194; proxy &amp;#x2194;
  chain &amp;#x2194; chain interactions), and track the corresponding data schemas.

* [`linera-client`](https://linera-io.github.io/linera-protocol/linera_client/index.html)
  Library for writing Linera clients.  Used for the command-line
  client and the node service in `linera-service`, as well as the Web
  client in [`linera-web`](https://github.com/linera-io/linera-web/).

* [`linera-service`](https://linera-io.github.io/linera-protocol/linera_service/index.html)
  Executable for clients (aka CLI wallets), proxy (aka validator frontend) and servers.

* [`linera-sdk`](https://linera-io.github.io/linera-protocol/linera_sdk/index.html) The
  library to develop Linera applications written in Rust for the Wasm virtual machine. The
  corresponding procedural macros are implemented in `linera-sdk-derive`.

* [`examples`](./examples) Examples of Linera applications written in Rust.

## Prerequisites

See [`INSTALL.md`](./INSTALL.md) for software requirements to develop in this repo.

## Quickstart with the Linera CLI tool

The following commands set up a local test network and run some transfers between the
microchains owned by a single wallet.

```bash
# Make sure to compile the Linera binaries and add them in the $PATH.
# cargo build -p linera-storage-service -p linera-service --bins
export PATH=&quot;$PWD/target/debug:$PATH&quot;

# Import the optional helper function `linera_spawn`.
source /dev/stdin &lt;&lt;&lt;&quot;$(linera net helper 2&gt;/dev/null)&quot;

# Run a local test network with the default parameters and a number of microchains
# owned by the default wallet. This also defines `LINERA_TMP_DIR`.
linera_spawn \
linera net up --with-faucet --faucet-port 8080

# Remember the URL of the faucet.
FAUCET_URL=http://localhost:8080

# If you&#039;re using a testnet, start here and run this instead:
#   LINERA_TMP_DIR=$(mktemp -d)
#   FAUCET_URL=https://faucet.testnet-XXX.linera.net  # for some value XXX

# Set the path of the future wallet.
export LINERA_WALLET=&quot;$LINERA_TMP_DIR/wallet.json&quot;
export LINERA_KEYSTORE=&quot;$LINERA_TMP_DIR/keystore.json&quot;
export LINERA_STORAGE=&quot;rocksdb:$LINERA_TMP_DIR/client.db&quot;

# Initialize a new user wallet.
linera wallet init --faucet $FAUCET_URL

# Request chains.
INFO1=($(linera wallet request-chain --faucet $FAUCET_URL))
INFO2=($(linera wallet request-chain --faucet $FAUCET_URL))
CHAIN1=&quot;${INFO1[0]}&quot;
ACCOUNT1=&quot;${INFO1[1]}&quot;
CHAIN2=&quot;${INFO2[0]}&quot;
ACCOUNT2=&quot;${INFO2[1]}&quot;

# Show the different chains tracked by the wallet.
linera wallet show

# Query the chain balance of some of the chains.
linera query-balance &quot;$CHAIN1&quot;
linera query-balance &quot;$CHAIN2&quot;

# Transfer 10 units then 5 back.
linera transfer 10 --from &quot;$CHAIN1&quot; --to &quot;$CHAIN2&quot;
linera transfer 5 --from &quot;$CHAIN2&quot; --to &quot;$CHAIN1&quot;

# Query balances again.
linera query-balance &quot;$CHAIN1&quot;
linera query-balance &quot;$CHAIN2&quot;

# Now let&#039;s fund the user balances.
linera transfer 5 --from &quot;$CHAIN1&quot; --to &quot;$CHAIN1:$ACCOUNT1&quot;
linera transfer 2 --from &quot;$CHAIN1:$ACCOUNT1&quot; --to &quot;$CHAIN2:$ACCOUNT2&quot;

# Query user balances again.
linera query-balance &quot;$CHAIN1:$ACCOUNT1&quot;
linera query-balance &quot;$CHAIN2:$ACCOUNT2&quot;
```

More complex examples may be found in our [developer manual](https://linera.dev) as well
as the [example applications](./examples) in this repository.

## Contributing

We welcome contributions from the community! If you&#039;d like to contribute to the Linera protocol:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m &#039;Add some amazing feature&#039;`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

For detailed guidelines, see our [contribution guide](./CONTRIBUTING.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[qdrant/qdrant]]></title>
            <link>https://github.com/qdrant/qdrant</link>
            <guid>https://github.com/qdrant/qdrant</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:10 GMT</pubDate>
            <description><![CDATA[Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qdrant/qdrant">qdrant/qdrant</a></h1>
            <p>Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine for the next generation of AI. Also available in the cloud https://cloud.qdrant.io/</p>
            <p>Language: Rust</p>
            <p>Stars: 24,789</p>
            <p>Forks: 1,705</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>## How to interview using this template

Open ONLY the `shared/` folder within VSCode and in the Extensions Marketplace find `CodeTogether Live`. Install it.

Inside the extension, you&#039;ll have to click on &#039;Host New Session&#039; and then &#039;Start&#039;.

You now have a link in your clipboard, which you should share with the candidate.

Don&#039;t forget to run `npm run vite.dev` inside your editor terminal, since this is not currently possible from the browser editor (link) with the free version of the extension.

The locally running server will display localhost:5173 as well as a the project within the network, which the user can access remotely to see the SPA in action, something like: `10.5.52.144:5173`.

The candidate should be sharing their screen while they read and later approach the challenge!

## React TemplateÔºà‚ö°Ô∏èÔºâ

‚ö°Ô∏è A minimal React Vite starter template.

### Feature

- ‚ö°Ô∏è Fast - Build tools based on vite.
- üëª Small - Based on the smallest runnable build.
- üíÑ Prettier - Integrated Prettier to help you format the code.
- ‚úÖ Safety - Https is enabled by default.
- üòé Reliable - Integrated eslint and commitlint.
- ü§ñ Intelligent - Integrated renovate to help you maintain the dependent version.

### Preview

[![qekup8.png](https://s1.ax1x.com/2022/03/20/qekup8.png)](https://imgtu.com/i/qekup8)

### Getting Started

```bash
npx degit lzm0x219/template-vite-react myapp

cd myapp

git init
```

#### Prerequisites

- `npm` and/or `pnpm` should be installed.
- `git` should be installed (recommended v2.4.11 or higher)

#### Available scripts

##### `npm run vite.dev`

Runs the app in development mode.
Open https://localhost:5173 to view it in the browser.

The page will automatically reload if you make changes to the code.
You will see the build errors and lint warnings in the console.

##### `npm run vite.build`

Builds the app for production to the `dist` folder.
It correctly bundles React in production mode and optimizes the build for the best performance.

The build is minified and the filenames include the hashes.

Your app is ready to be deployed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[YaLTeR/niri]]></title>
            <link>https://github.com/YaLTeR/niri</link>
            <guid>https://github.com/YaLTeR/niri</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:09 GMT</pubDate>
            <description><![CDATA[A scrollable-tiling Wayland compositor.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/YaLTeR/niri">YaLTeR/niri</a></h1>
            <p>A scrollable-tiling Wayland compositor.</p>
            <p>Language: Rust</p>
            <p>Stars: 9,766</p>
            <p>Forks: 352</p>
            <p>Stars today: 36 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;niri&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;A scrollable-tiling Wayland compositor.&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://matrix.to/#/#niri:matrix.org&quot;&gt;&lt;img alt=&quot;Matrix&quot; src=&quot;https://img.shields.io/badge/matrix-%23niri-blue?logo=matrix&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;GitHub License&quot; src=&quot;https://img.shields.io/github/license/YaLTeR/niri&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/releases&quot;&gt;&lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/YaLTeR/niri?logo=github&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/YaLTeR/niri/wiki/Getting-Started&quot;&gt;Getting Started&lt;/a&gt; | &lt;a href=&quot;https://github.com/YaLTeR/niri/wiki/Configuration:-Introduction&quot;&gt;Configuration&lt;/a&gt; | &lt;a href=&quot;https://github.com/YaLTeR/niri/discussions/325&quot;&gt;Setup&amp;nbsp;Showcase&lt;/a&gt;
&lt;/p&gt;

![niri with a few windows open](https://github.com/user-attachments/assets/535e6530-2f44-4b84-a883-1240a3eee6e9)

## About

Windows are arranged in columns on an infinite strip going to the right.
Opening a new window never causes existing windows to resize.

Every monitor has its own separate window strip.
Windows can never &quot;overflow&quot; onto an adjacent monitor.

Workspaces are dynamic and arranged vertically.
Every monitor has an independent set of workspaces, and there&#039;s always one empty workspace present all the way down.

The workspace arrangement is preserved across disconnecting and connecting monitors where it makes sense.
When a monitor disconnects, its workspaces will move to another monitor, but upon reconnection they will move back to the original monitor.

## Features

- Built from the ground up for scrollable tiling
- [Dynamic workspaces](https://github.com/YaLTeR/niri/wiki/Workspaces) like in GNOME
- An [Overview](https://github.com/user-attachments/assets/379a5d1f-acdb-4c11-b36c-e85fd91f0995) that zooms out workspaces and windows
- Built-in screenshot UI
- Monitor and window screencasting through xdg-desktop-portal-gnome
    - You can [block out](https://github.com/YaLTeR/niri/wiki/Configuration:-Window-Rules#block-out-from) sensitive windows from screencasts
    - [Dynamic cast target](https://github.com/YaLTeR/niri/wiki/Screencasting#dynamic-screencast-target) that can change what it shows on the go
- [Touchpad](https://github.com/YaLTeR/niri/assets/1794388/946a910e-9bec-4cd1-a923-4a9421707515) and [mouse](https://github.com/YaLTeR/niri/assets/1794388/8464e65d-4bf2-44fa-8c8e-5883355bd000) gestures
- Group windows into [tabs](https://github.com/YaLTeR/niri/wiki/Tabs)
- Configurable layout: gaps, borders, struts, window sizes
- [Gradient borders](https://github.com/YaLTeR/niri/wiki/Configuration:-Layout#gradients) with Oklab and Oklch support
- [Animations](https://github.com/YaLTeR/niri/assets/1794388/ce178da2-af9e-4c51-876f-8709c241d95e) with support for [custom shaders](https://github.com/YaLTeR/niri/assets/1794388/27a238d6-0a22-4692-b794-30dc7a626fad)
- Live-reloading config

## Video Demo

https://github.com/YaLTeR/niri/assets/1794388/bce834b0-f205-434e-a027-b373495f9729

Also check out this video from Brodie Robertson that showcases a lot of the niri functionality: [Niri Is My New Favorite Wayland Compositor](https://youtu.be/DeYx2exm04M)

## Status

Niri is stable for day-to-day use and does most things expected of a Wayland compositor.
Many people are daily-driving niri, and are happy to help in our [Matrix channel].

Give it a try!
Follow the instructions on the [Getting Started](https://github.com/YaLTeR/niri/wiki/Getting-Started) wiki page.
Have your [waybar]s and [fuzzel]s ready: niri is not a complete desktop environment.

Here are some points you may have questions about:

- **Multi-monitor**: yes, a core part of the design from the very start. Mixed DPI works.
- **Fractional scaling**: yes, plus all niri UI stays pixel-perfect.
- **NVIDIA**: seems to work fine.
- **Floating windows**: yes, starting from niri 25.01.
- **Input devices**: niri supports tablets, touchpads, and touchscreens.
You can map the tablet to a specific monitor, or use [OpenTabletDriver].
We have touchpad gestures, but no touchscreen gestures yet.
- **Wlr protocols**: yes, we have most of the important ones like layer-shell, gamma-control, screencopy.
You can check on [wayland.app](https://wayland.app) at the bottom of each protocol&#039;s page.
- **Performance**: while I run niri on beefy machines, I try to stay conscious of performance.
I&#039;ve seen someone use it fine on an Eee¬†PC¬†900 from¬†2008, of all things.
- **Xwayland**: no built-in support, but xwayland-satellite is [easy to set up](https://github.com/YaLTeR/niri/wiki/Xwayland#using-xwayland-satellite) and works very well.
    - Steam and games, including Proton: work perfectly through xwayland-satellite.
    - JetBrains IDEs, Ghidra: work well through xwayland-satellite.
    - Discord and other Electron apps: work well through xwayland-satellite.
    - Chromium and VSCode: work perfectly natively on Wayland with the right flags.
    - X11 apps that want to position windows or bars at specific screen coordinates: won&#039;t work well; you can run them in a nested compositor like [labwc](https://github.com/YaLTeR/niri/wiki/Xwayland#using-the-labwc-wayland-compositor) or [rootful Xwayland](https://github.com/YaLTeR/niri/wiki/Xwayland#directly-running-xwayland-in-rootful-mode).
    - Display scaling (integer or fractional) keeps X11 apps crisp, but you need the latest xwayland-satellite.
    For games, you can run them in [gamescope] at native resolution, even with display scaling.

## Media

[niri: Making a Wayland compositor in Rust](https://youtu.be/Kmz8ODolnDg?list=PLRdS-n5seLRqrmWDQY4KDqtRMfIwU0U3T) ¬∑ *December 2024*

My talk from the 2024 Moscow RustCon about niri, and how I do randomized property testing and profiling, and measure input latency.
The talk is in Russian, but I prepared full English subtitles that you can find in YouTube&#039;s subtitle language selector.

[An interview with Ivan, the developer behind Niri](https://www.trommelspeicher.de/podcast/special_the_developer_behind_niri) ¬∑ *June 2025*

An interview by a German tech podcast Das Triumvirat (in English).
We talk about niri development and history, and my experience building and maintaining niri.

[A tour of the niri scrolling-tiling Wayland compositor](https://lwn.net/Articles/1025866/) ¬∑ *July 2025*

An LWN article with a nice overview and introduction to niri.

## Contributing

If you&#039;d like to help with niri, there are plenty of both coding- and non-coding-related ways to do so.
See [CONTRIBUTING.md](https://github.com/YaLTeR/niri/blob/main/CONTRIBUTING.md) for an overview.

## Inspiration

Niri is heavily inspired by [PaperWM] which implements scrollable tiling on top of GNOME Shell.

One of the reasons that prompted me to try writing my own compositor is being able to properly separate the monitors.
Being a GNOME Shell extension, PaperWM has to work against Shell&#039;s global window coordinate space to prevent windows from overflowing.

## Tile Scrollably Elsewhere

Here are some other projects which implement a similar workflow:

- [PaperWM]: scrollable tiling on top of GNOME Shell.
- [karousel]: scrollable tiling on top of KDE.
- [scroll](https://github.com/dawsers/scroll) and [papersway]: scrollable tiling on top of sway/i3.
- [hyprscrolling] and [hyprslidr]: scrollable tiling on top of Hyprland.
- [PaperWM.spoon]: scrollable tiling on top of macOS.

## Contact

We have a Matrix chat, feel free to join and ask a question: https://matrix.to/#/#niri:matrix.org

[PaperWM]: https://github.com/paperwm/PaperWM
[waybar]: https://github.com/Alexays/Waybar
[fuzzel]: https://codeberg.org/dnkl/fuzzel
[karousel]: https://github.com/peterfajdiga/karousel
[papersway]: https://spwhitton.name/tech/code/papersway/
[hyprscrolling]: https://github.com/hyprwm/hyprland-plugins/tree/main/hyprscrolling
[hyprslidr]: https://gitlab.com/magus/hyprslidr
[PaperWM.spoon]: https://github.com/mogenson/PaperWM.spoon
[Matrix channel]: https://matrix.to/#/#niri:matrix.org
[OpenTabletDriver]: https://opentabletdriver.net/
[gamescope]: https://github.com/ValveSoftware/gamescope
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[facebook/pyrefly]]></title>
            <link>https://github.com/facebook/pyrefly</link>
            <guid>https://github.com/facebook/pyrefly</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:08 GMT</pubDate>
            <description><![CDATA[A fast type checker and IDE for Python]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/facebook/pyrefly">facebook/pyrefly</a></h1>
            <p>A fast type checker and IDE for Python</p>
            <p>Language: Rust</p>
            <p>Stars: 3,301</p>
            <p>Forks: 127</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

# Pyrefly: A fast type checker and IDE for Python

Currently under active development with known issues. Please open an issue if
you find bugs.

Pyrefly is a fast type checker for Python. It&#039;s designed to replace the existing
Pyre type checker at Meta by the end of 2025. This README describes basic usage.
See the [Pyrefly website](https://pyrefly.org) for full documentation and a tool
for checking code.

### Getting Started

Pyrefly aims to increase development velocity with IDE features and by checking
your Python code.

- Try out pyrefly in your browser: [Sandbox](https://pyrefly.org/sandbox/)
- Get the command-line tool: `pip install pyrefly`
- Get the VSCode extension:
  [Link](https://marketplace.visualstudio.com/items?itemName=meta.pyrefly)

### Key Features:

- Type Inference: Pyrefly infers types in most locations, apart from function
  parameters. It can infer types of variables and return types.
- Flow Types: Pyrefly can understand your program&#039;s control flow to refine
  static types.
- Incrementality: Pyrefly aims for large-scale incrementality at the module
  level, with optimized checking and parallelism.

## Getting Involved

If you have questions or would like to report a bug, please
[create an issue](https://github.com/facebook/pyrefly/issues).

See our
[contributing guide](https://github.com/facebook/pyrefly/blob/main/CONTRIBUTING.md)
for information on how to contribute to Pyrefly.

## Choices

There are a number of choices when writing a Python type checker. We are taking
inspiration from [Pyre1](https://pyre-check.org/),
[Pyright](https://github.com/microsoft/pyright) and
[MyPy](https://mypy.readthedocs.io/en/stable/). Some notable choices:

- We infer types in most locations, apart from parameters to functions. We do
  infer types of variables and return types. As an example,
  `def foo(x): return True` would result in something equivalent to had you
  written `def foo(x: Any) -&gt; bool: ...`.
- We attempt to infer the type of `[]` to however it is used first, then fix it
  after. For example `xs = []; xs.append(1); xs.append(&quot;&quot;)` will infer that
  `xs: List[int]` and then error on the final statement.
- We use flow types which refine static types, e.g. `x: int = 4` will both know
  that `x` has type `int`, but also that the immediately next usage of `x` will
  be aware the type is `Literal[4]`.
- We aim for large-scale incrementality (at the module level) and optimized
  checking with parallelism, aiming to use the advantages of Rust to keep the
  code a bit simpler.
- We expect large strongly connected components of modules, and do not attempt
  to take advantage of a DAG-shape in the source code.

## Design

There are many nuances of design that change on a regular basis. But the basic
substrate on which the checker is built involves three steps:

1. Figure out what each module exports. That requires solving all `import *`
   statements transitively.
2. For each module in isolation, convert it to bindings, dealing with all
   statements and scope information (both static and flow).
3. Solve those bindings, which may require the solutions of bindings in other
   modules.

If we encounter unknowable information (e.g. recursion) we use `Type::Var` to
insert placeholders which are filled in later.

For each module, we solve the steps sequentially and completely. In particular,
we do not try and solve a specific identifier first (like
[Roslyn](https://github.com/dotnet/roslyn) or
[TypeScript](https://www.typescriptlang.org/)), and do not use fine-grained
incrementality (like [Rust Analyzer](https://github.com/rust-lang/rust-analyzer)
using [Salsa](https://github.com/salsa-rs/salsa)). Instead, we aim for raw
performance and a simpler module-centric design - there&#039;s no need to solve a
single binding in isolation if solving all bindings in a module is fast enough.

### Example of bindings

Given the program:

```python
1: x: int = 4
2: print(x)
```

We might produce the bindings:

- `define int@0` = `from builtins import int`
- `define x@1` = `4: int@0`
- `use x@2` = `x@1`
- `anon @2` = `print(x@2)`
- `export x` = `x@2`

Of note:

- The keys are things like `define` (the definition of something), `use` (a
  usage of a thing) and `anon` (a statement we need to type check, but don&#039;t
  care about the result of).
- In many cases the value of a key refers to other keys.
- Some keys are imported from other modules, via `export` keys and `import`
  values.
- In order to disambiguate identifiers we use the textual position at which they
  occur (in the example we&#039;ve used `@line`, but in reality it&#039;s the byte offset
  in the file).

### Example of `Var`

Given the program:

```python
1: x = 1
2: while test():
3:     x = x
4: print(x)
```

We end up with the bindings:

- `x@1` = `1`
- `x@3` = `phi(x@1, x@3)`
- `x@4` = `phi(x@1, x@3)`

The expression `phi` is the join point of the two values, e.g. `phi(int, str)`
would be `int | str`. We skip the distinction between `define` and `use`, since
it is not necessary for this example.

When solving `x@3` we encounter recursion. Operationally:

- We start solving `x@3`.
- That requires us to solve `x@1`.
- We solve `x@1` to be `Literal[1]`
- We start solving `x@3`. But we are currently solving `x@3`, so we invent a
  fresh `Var` (let&#039;s call it `?1`) and return that.
- We conclude that `x@3` must be `Literal[1] | ?1`.
- Since `?1` was introduced by `x@3` we record that `?1 = Literal[1] | ?1`. We
  can take the upper reachable bound of that and conclude that
  `?1 = Literal[1]`.
- We simplify `x@3` to just `Literal[1]`.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[louis-e/arnis]]></title>
            <link>https://github.com/louis-e/arnis</link>
            <guid>https://github.com/louis-e/arnis</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:07 GMT</pubDate>
            <description><![CDATA[Generate any location from the real world in Minecraft Java Edition with a high level of detail.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/louis-e/arnis">louis-e/arnis</a></h1>
            <p>Generate any location from the real world in Minecraft Java Edition with a high level of detail.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,495</p>
            <p>Forks: 497</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img width=&quot;456&quot; height=&quot;125&quot; src=&quot;https://github.com/louis-e/arnis/blob/main/gui-src/images/logo.png?raw=true&quot;&gt;
&lt;/p&gt;

# Arnis [![CI Build Status](https://github.com/louis-e/arnis/actions/workflows/ci-build.yml/badge.svg)](https://github.com/louis-e/arnis/actions) [&lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/louis-e/arnis&quot; /&gt;](https://github.com/louis-e/arnis/releases) [&lt;img alt=&quot;GitHub Downloads (all assets, all releases&quot; src=&quot;https://img.shields.io/github/downloads/louis-e/arnis/total&quot; /&gt;](https://github.com/louis-e/arnis/releases)

Arnis creates complex and accurate Minecraft Java Edition worlds that reflect real-world geography and architecture using OpenStreetMap.

###### ‚ö†Ô∏è This Github page is the official project website. Do not download Arnis from any other website.

## :desktop_computer: Example
![Minecraft Preview](https://github.com/louis-e/arnis/blob/main/gitassets/mc.gif?raw=true)

Arnis is designed to handle large-scale data and generate rich, immersive environments that bring real-world cities, landmarks, and natural features into Minecraft. Whether you&#039;re looking to replicate your hometown, explore urban environments, or simply build something unique and realistic, Arnis generates your vision.

## :keyboard: Usage
&lt;img width=&quot;60%&quot; src=&quot;https://github.com/louis-e/arnis/blob/main/gitassets/gui.png?raw=true&quot;&gt;&lt;br&gt;
Download the [latest release](https://github.com/louis-e/arnis/releases/) or [compile](#trophy-open-source) the project on your own.
 
Choose your area using the rectangle tool and select your Minecraft world - then simply click on &#039;Start Generation&#039;!

&gt; The world will always be generated starting from the Minecraft coordinates 0 0 0 (/tp 0 0 0). This is the top left of your selected area.
Minecraft version 1.16.5 and below is currently not supported, but we are working on it! For the best results, use Minecraft version 1.21.4 or above.
If you choose to select an own world, be aware that Arnis will overwrite certain areas.

[[Arch Linux AUR package](https://aur.archlinux.org/packages/arnis)]

## üìö Documentation

Full documentation is available in the [GitHub Wiki](https://github.com/louis-e/arnis/wiki/), covering topics such as technical explanations, FAQs, contribution guidelines and roadmaps.

## :trophy: Open Source
#### Key objectives of this project
- **Modularity**: Ensure that all components (e.g., data fetching, processing, and world generation) are cleanly separated into distinct modules for better maintainability and scalability.
- **Performance Optimization**: We aim to keep a good performance and speed of the world generation process.
- **Comprehensive Documentation**: Detailed in-code documentation for a clear structure and logic.
- **User-Friendly Experience**: Focus on making the project easy to use for end users.
- **Cross-Platform Support**: We want this project to run smoothly on Windows, macOS, and Linux.

#### How to contribute
This project is open source and welcomes contributions from everyone! Whether you&#039;re interested in fixing bugs, improving performance, adding new features, or enhancing documentation, your input is valuable. Simply fork the repository, make your changes, and submit a pull request. Please respect the above mentioned key objectives. Contributions of all levels are appreciated, and your efforts help improve this tool for everyone.

Build and run it using: ```cargo run --release --no-default-features -- --path=&quot;C:/YOUR_PATH/.minecraft/saves/worldname&quot; --bbox=&quot;min_lng,min_lat,max_lng,max_lat&quot;```&lt;br&gt;
For the GUI: ```cargo run --release```&lt;br&gt;

&gt; You can use the parameter --debug to get a more detailed output of the processed values, which can be helpful for debugging and development.

After your pull request was merged, I will take care of regularly creating update releases which will include your changes.

## :star: Star History

&lt;a href=&quot;https://star-history.com/#louis-e/arnis&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=louis-e/arnis&amp;Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=louis-e/arnis&amp;Date&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=louis-e/arnis&amp;Date&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

## :copyright: License Information
Copyright (c) 2022-2025 Louis Erbkamm (louis-e)

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.[^3]

Download Arnis only from the official source (https://github.com/louis-e/arnis/). Every other website providing a download and claiming to be affiliated with the project is unofficial and may be malicious.

The logo was made by @nxfx21.


[^1]: https://en.wikipedia.org/wiki/OpenStreetMap

[^2]: https://en.wikipedia.org/wiki/Arnis,_Germany

[^3]: https://github.com/louis-e/arnis/blob/main/LICENSE
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nautechsystems/nautilus_trader]]></title>
            <link>https://github.com/nautechsystems/nautilus_trader</link>
            <guid>https://github.com/nautechsystems/nautilus_trader</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:06 GMT</pubDate>
            <description><![CDATA[A high-performance algorithmic trading platform and event-driven backtester]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nautechsystems/nautilus_trader">nautechsystems/nautilus_trader</a></h1>
            <p>A high-performance algorithmic trading platform and event-driven backtester</p>
            <p>Language: Rust</p>
            <p>Stars: 9,811</p>
            <p>Forks: 1,196</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png&quot; width=&quot;500&quot;&gt;

[![codecov](https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H)](https://codecov.io/gh/nautechsystems/nautilus_trader)
[![codspeed](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/nautechsystems/nautilus_trader)
![pythons](https://img.shields.io/pypi/pyversions/nautilus_trader)
![pypi-version](https://img.shields.io/pypi/v/nautilus_trader)
![pypi-format](https://img.shields.io/pypi/format/nautilus_trader?color=blue)
[![Downloads](https://pepy.tech/badge/nautilus-trader)](https://pepy.tech/project/nautilus-trader)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/NautilusTrader)

| Branch    | Version                                                                                                                                                                                                                     | Status                                                                                                                                                                                            |
| :-------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `master`  | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html)  | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `nightly` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `develop` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |

| Platform           | Rust   | Python     |
| :----------------- | :----- | :--------- |
| `Linux (x86_64)`   | 1.88.0 | 3.11-3.13  |
| `Linux (ARM64)`    | 1.88.0 | 3.11-3.13  |
| `macOS (ARM64)`    | 1.88.0 | 3.11-3.13  |
| `Windows (x86_64)` | 1.88.0 | 3.11-3.13* |

\* Windows builds are currently pinned to CPython 3.13.2, see [installation guide](https://github.com/nautechsystems/nautilus_trader/blob/develop/docs/getting_started/installation.md).

- **Docs**: &lt;https://nautilustrader.io/docs/&gt;
- **Website**: &lt;https://nautilustrader.io&gt;
- **Support**: [support@nautilustrader.io](mailto:support@nautilustrader.io)

## Introduction

NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform,
providing quantitative traders with the ability to backtest portfolios of automated trading strategies
on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.

The platform is *AI-first*, designed to develop and deploy algorithmic trading strategies within a highly performant
and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest
environment consistent with the production live trading environment.

NautilusTrader&#039;s design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting
and live deployment workloads.

The platform is also universal, and asset-class-agnostic ‚Äî  with any REST API or WebSocket feed able to be integrated via modular
adapters. It supports high-frequency trading across a wide range of asset classes and instrument types
including FX, Equities, Futures, Options, Crypto and Betting, enabling seamless operations across multiple venues simultaneously.

![nautilus-trader](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png &quot;nautilus-trader&quot;)

## Features

- **Fast**: Core is written in Rust with asynchronous networking using [tokio](https://crates.io/crates/tokio).
- **Reliable**: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.
- **Portable**: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.
- **Flexible**: Modular adapters mean any REST API or WebSocket feed can be integrated.
- **Advanced**: Time in force `IOC`, `FOK`, `GTC`, `GTD`, `DAY`, `AT_THE_OPEN`, `AT_THE_CLOSE`, advanced order types and conditional triggers. Execution instructions `post-only`, `reduce-only`, and icebergs. Contingency orders including `OCO`, `OUO`, `OTO`.
- **Customizable**: Add user-defined custom components, or assemble entire systems from scratch leveraging the [cache](https://nautilustrader.io/docs/latest/concepts/cache) and [message bus](https://nautilustrader.io/docs/latest/concepts/message_bus).
- **Backtesting**: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.
- **Live**: Use identical strategy implementations between backtesting and live deployments.
- **Multi-venue**: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.
- **AI Training**: Backtest engine fast enough to be used to train AI trading agents (RL/ES).

![Alt text](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png &quot;nautilus&quot;)

&gt; *nautilus - from ancient Greek &#039;sailor&#039; and naus &#039;ship&#039;.*
&gt;
&gt; *The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral.
&gt; The idea is that this can be translated to the aesthetics of design and architecture.*

## Why NautilusTrader?

- **Highly performant event-driven Python**: Native binary core components.
- **Parity between backtesting and live trading**: Identical strategy code.
- **Reduced operational risk**: Enhanced risk management functionality, logical accuracy, and type safety.
- **Highly extendable**: Message bus, custom components and actors, custom data, custom adapters.

Traditionally, trading strategy research and backtesting might be conducted in Python
using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way
using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot
express the granular time and event dependent complexity of real-time trading, where compiled languages have
proven to be more suitable due to their inherently higher performance, and type safety.

One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform
have all been written entirely in [Rust](https://www.rust-lang.org/) or [Cython](https://cython.org/).
This means we&#039;re using the right tools for the job, where systems programming languages compile performant binaries,
with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.

## Why Python?

Python was originally created decades ago as a simple scripting language with a clean straightforward syntax.
It has since evolved into a fully fledged general purpose object-oriented programming language.
Based on the TIOBE index, Python is currently the most popular programming language in the world.
Not only that, Python has become the *de facto lingua franca* of data science, machine learning, and artificial intelligence.

developer/user communities.
However, Python has performance and typing limitations for large-scale, latency-sensitive systems. Cython addresses many of these issues by introducing static typing into Python&#039;s rich ecosystem of libraries and communities.

## Why Rust?

[Rust](https://www.rust-lang.org/) is a multi-paradigm programming language designed for performance and safety, especially safe
concurrency. Rust is &quot;blazingly fast&quot; and memory-efficient (comparable to C and C++) with no garbage collector.
It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.

Rust‚Äôs rich type system and ownership model guarantees memory-safety and thread-safety deterministically ‚Äî
eliminating many classes of bugs at compile-time.

The project increasingly utilizes Rust for core performance-critical components. Python bindings are implemented via Cython and [PyO3](https://pyo3.rs)‚Äîno Rust toolchain is required at install time.

This project makes the [Soundness Pledge](https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html):

&gt; ‚ÄúThe intent of this project is to be free of soundness bugs.
&gt; The developers will do their best to avoid them, and welcome help in analyzing and fixing them.‚Äù

&gt; [!NOTE]
&gt;
&gt; **MSRV:** NautilusTrader relies heavily on improvements in the Rust language and compiler.
&gt; As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.

## Integrations

NautilusTrader is modularly designed to work with *adapters*, enabling connectivity to trading venues
and data providers by translating their raw APIs into a unified interface and normalized domain model.

The following integrations are currently supported; see [docs/integrations/](https://nautilustrader.io/docs/latest/integrations/) for details:

| Name                                                                         | ID                    | Type                    | Status                                                  | Docs                                        |
| :--------------------------------------------------------------------------- | :-------------------- | :---------------------- | :------------------------------------------------------ | :------------------------------------------ |
| [Betfair](https://betfair.com)                                               | `BETFAIR`             | Sports Betting Exchange | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/betfair.md)       |
| [Binance](https://binance.com)                                               | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/binance.md)       |
| [Binance US](https://binance.us)                                             | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/binance.md)       |
| [Binance Futures](https://www.binance.com/en/futures)                        | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/binance.md)       |
| [Bybit](https://www.bybit.com)                                               | `BYBIT`               | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/bybit.md)         |
| [Coinbase International](https://www.coinbase.com/en/international-exchange) | `COINBASE_INTX`       | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/coinbase_intx.md) |
| [Databento](https://databento.com)                                           | `DATABENTO`           | Data Provider           | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/databento.md)     |
| [dYdX](https://dydx.exchange/)                                               | `DYDX`                | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/dydx.md)          |
| [Interactive Brokers](https://www.interactivebrokers.com)                    | `INTERACTIVE_BROKERS` | Brokerage (multi-venue) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/ib.md)            |
| [OKX](https://okx.com)                                                       | `OKX`                 | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/building-orange) | [Guide](docs/integrations/okx.md)           |
| [Polymarket](https://polymarket.com)                                         | `POLYMARKET`          | Prediction Market (DEX) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/polymarket.md)    |
| [Tardis](https://tardis.dev)                                                 | `TARDIS`              | Crypto Data Provider    | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/tardis.md)        |

- **ID**: The default client ID for the integrations adapter clients.
- **Type**: The type of integration (often the venue type).

### Status

- `building`: Under construction and likely not in a usable state.
- `beta`: Completed to a minimally working state and in a beta testing phase.
- `stable`: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).

See the [Integrations](https://nautilustrader.io/docs/latest/integrations/index.html) documentation for further details.

## Versioning and releases

**NautilusTrader is still under active development**. Some features may be incomplete, and while
the API is becoming more stable, breaking changes can occur between releases.
We strive to document these changes in the release notes on a **best-effort basis**.

We aim to follow a **bi-weekly release schedule**, though experimental or larger features may cause delays.

### Branches

We aim to maintain a stable, passing build across all branches.

- `master`: Reflects the source code for the latest released version; recommended for production use.
- `nightly`: Daily snapshots of the `develop` branch for early testing; merged at **14:00 UTC** or on demand.
- `develop`: Active development branch for contributors and feature work.

&gt; [!NOTE]
&gt;
&gt; Our [roadmap](/ROADMAP.md) aims to achieve a **stable API for version 2.x** (likely after the Rust port).
&gt; Once this milestone is reached, we plan to implement a formal deprecation process for any API changes.
&gt; This approach allows us to maintain a rapid development pace for now.

## Precision mode

NautilusTrader supports two precision modes for its core value types (`Price`, `Quantity`, `Money`),
which differ in their internal bit-width and maximum decimal precision.

- **High-precision**: 128-bit integers with up to 16 decimals of precision, and a larger value range.
- **Standard-precision**: 64-bit integers with up to 9 decimals of precision, and a smaller value range.

&gt; [!NOTE]
&gt;
&gt; By default, the official Python wheels **ship** in high-precision (128-bit) mode on Linux and macOS.
&gt; On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support.
&gt; For the Rust crates, the default is standard-precision unless you explicitly enable the `high-precision` feature flag.

See the [Installation Guide](https://nautilustrader.io/docs/latest/getting_started/installation) for further details.

**Rust feature flag**: To enable high-precision mode in Rust, add the `high-precision` feature to your Cargo.toml:

```toml
[dependencies]
nautilus_model = { version = &quot;*&quot;, features = [&quot;high-precision&quot;] }
```

## Installation

We recommend using the latest supported version of Python and installing [nautilus_trader](https://pypi.org/project/nautilus_trader/) inside a virtual environment to isolate dependencies.

**There are two supported ways to install**:

1. Pre-built binary wheel from PyPI *or* the Nautech Systems package index.
2. Build from source.

&gt; [!TIP]
&gt;
&gt; We highly recommend installing using the [uv](https://docs.astral.sh/uv) package manager with a &quot;vanilla&quot; CPython.
&gt;
&gt; Conda and other Python distributions *may* work but aren‚Äôt officially supported.

### From PyPI

To install the latest binary wheel (or sdist package) from PyPI using Python&#039;s pip package manager:

```bash
pip install -U nautilus_trader
```

### From the Nautech Systems package index

The Nautech Systems package index (`packages.nautechsystems.io`) is [PEP-503](https://peps.python.org/pep-0503/) compliant and hosts both stable and development binary wheels for `nautilus_trader`.
This enables users to install either the latest stable release or pre-release versions for testing.

#### Stable wheels

Stable wheels correspond to official releases of `nautilus_trader` on PyPI, and use standard versioning.

To install the latest stable release:

```bash
pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple
```

#### Development wheels

Development wheels are published from both the `nightly` and `develop` branches,
allowing users to test features and fixes ahead of stable releases.

**Note**: Wheels from the `develop` branch are only built for the Linux x86_64 platform to save time
and compute resources, while `nightly` wheels support additional platforms as shown below.

| Platform           | Nightly | Develop |
| :----------------- | :------ | :------ |
| `Linux (x86_64)`   | ‚úì       | ‚úì       |
| `Linux (ARM64)`    | ‚úì       | -       |
| `macOS (ARM64)`    | ‚úì       | -       |
| `Windows (x86_64)` | ‚úì       | -       |

This process also helps preserve compute resources and ensures easy access to the exact binaries tested in CI pipelines,
while adhering to [PEP-440](https://peps.python.org/pep-0440/) versioning standards:

- `develop` wheels use the version format `dev{date}+{build_number}` (e.g., `1.208.0.dev20241212+7001`).
- `nightly` wheels use the version format `a{date}` (alpha) (e.g., `1.208.0a20241212`).

&gt; [!WARNING]
&gt;
&gt; We don&#039;t recommend using development wheels in production environments, such as live trading controlling real capital.

#### Installation commands

By default, pip installs the latest stable release. Adding the `--pre` flag ensures that pre-release versions, including development wheels, are considered.

To install the latest available pre-release (including development wheels):

```bash
pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple
```

To install a specific development wheel (e.g., `1.208.0a20241212` for December 12, 2024):

```bash
pip install nautilus_trader==1.208.0a20241212 --index-url=https://packages.nautechsystems.io/simple
```

#### Available versions

You can view all available versions of `nautilus_trader` on the [package index](https://packages.nautechsystems.io/simple/nautilus-trader/index.html).

To programmatically fetch and list available versions:

```bash
curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP &#039;(?&lt;=&lt;a href=&quot;)[^&quot;]+(?=&quot;)&#039; | awk -F&#039;#&#039; &#039;{print $1}&#039; | sort
```

#### Branch updates

- `develop` bran

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[solana-foundation/anchor]]></title>
            <link>https://github.com/solana-foundation/anchor</link>
            <guid>https://github.com/solana-foundation/anchor</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:05 GMT</pubDate>
            <description><![CDATA[‚öì Solana Sealevel Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/solana-foundation/anchor">solana-foundation/anchor</a></h1>
            <p>‚öì Solana Sealevel Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 4,440</p>
            <p>Forks: 1,595</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img height=&quot;170x&quot; src=&quot;https://pbs.twimg.com/media/FVUVaO9XEAAulvK?format=png&amp;name=small&quot; /&gt;

  &lt;h1&gt;Anchor&lt;/h1&gt;

  &lt;p&gt;
    &lt;strong&gt;Solana Program Framework&lt;/strong&gt;
  &lt;/p&gt;

  &lt;p&gt;
    &lt;a href=&quot;https://github.com/coral-xyz/anchor/actions&quot;&gt;&lt;img alt=&quot;Build Status&quot; src=&quot;https://github.com/coral-xyz/anchor/actions/workflows/tests.yaml/badge.svg&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://anchor-lang.com&quot;&gt;&lt;img alt=&quot;Tutorials&quot; src=&quot;https://img.shields.io/badge/docs-tutorials-blueviolet&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/NHHGSXAnXk&quot;&gt;&lt;img alt=&quot;Discord Chat&quot; src=&quot;https://img.shields.io/discord/889577356681945098?color=blueviolet&quot; /&gt;&lt;/a&gt;
    &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/github/license/coral-xyz/anchor?color=blueviolet&quot; /&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

[Anchor](https://www.anchor-lang.com/) is a framework providing several convenient developer tools for writing Solana programs (sometimes called &#039;smart contracts&#039;).

- Rust eDSL for writing Solana programs
- [IDL](https://en.wikipedia.org/wiki/Interface_description_language) specification
- TypeScript package for generating clients from IDL
- CLI and workspace management for developing complete applications

Anchor is the most popular framework for Solana programs.

&gt; [!NOTE]
&gt; If you&#039;re familiar with developing in Ethereum&#039;s [Solidity](https://docs.soliditylang.org/en/), [Truffle](https://www.trufflesuite.com/), [web3.js](https://github.com/ethereum/web3.js), then using Anchor be familiar. Although the DSL syntax and semantics are targeted at Solana, the high level flow of writing RPC request handlers, emitting an IDL, and generating clients from IDL is the same.

## Getting Started

For a quickstart guide and in depth tutorials, see the [Anchor book](https://book.anchor-lang.com) and the [Anchor documentation](https://anchor-lang.com).

To jump straight to examples, go [here](https://github.com/coral-xyz/anchor/tree/master/examples). For the latest Rust and TypeScript API documentation, see [docs.rs](https://docs.rs/anchor-lang) and the [typedoc](https://www.anchor-lang.com/docs/clients/typescript).

## Packages

| Package                 | Description                                              | Version                                                                                                                          | Docs                                                                                                            |
| :---------------------- | :------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------- |
| `anchor-lang`           | Rust primitives for writing programs on Solana           | [![Crates.io](https://img.shields.io/crates/v/anchor-lang?color=blue)](https://crates.io/crates/anchor-lang)                     | [![Docs.rs](https://docs.rs/anchor-lang/badge.svg)](https://docs.rs/anchor-lang)                                |
| `anchor-spl`            | CPI clients for SPL programs on Solana                   | [![crates](https://img.shields.io/crates/v/anchor-spl?color=blue)](https://crates.io/crates/anchor-spl)                          | [![Docs.rs](https://docs.rs/anchor-spl/badge.svg)](https://docs.rs/anchor-spl)                                  |
| `anchor-client`         | Rust client for Anchor programs                          | [![crates](https://img.shields.io/crates/v/anchor-client?color=blue)](https://crates.io/crates/anchor-client)                    | [![Docs.rs](https://docs.rs/anchor-client/badge.svg)](https://docs.rs/anchor-client)                            |
| `@coral-xyz/anchor`     | TypeScript client for Anchor programs                    | [![npm](https://img.shields.io/npm/v/@coral-xyz/anchor.svg?color=blue)](https://www.npmjs.com/package/@coral-xyz/anchor)         | [![Docs](https://img.shields.io/badge/docs-typedoc-blue)](https://coral-xyz.github.io/anchor/ts/index.html)     |
| `@coral-xyz/anchor-cli` | CLI to support building and managing an Anchor workspace | [![npm](https://img.shields.io/npm/v/@coral-xyz/anchor-cli.svg?color=blue)](https://www.npmjs.com/package/@coral-xyz/anchor-cli) | [![Docs](https://img.shields.io/badge/docs-typedoc-blue)](https://coral-xyz.github.io/anchor/cli/commands.html) |

## Note

- **Anchor is in active development, so all APIs are subject to change.**
- **This code is unaudited. Use at your own risk.**

## Examples

Here&#039;s a counter program, where only the designated `authority`
can increment the count.

```rust
use anchor_lang::prelude::*;

declare_id!(&quot;Fg6PaFpoGXkYsidMpWTK6W2BeZ7FEfcYkg476zPFsLnS&quot;);

#[program]
mod counter {
    use super::*;

    pub fn initialize(ctx: Context&lt;Initialize&gt;, start: u64) -&gt; Result&lt;()&gt; {
        let counter = &amp;mut ctx.accounts.counter;
        counter.authority = *ctx.accounts.authority.key;
        counter.count = start;
        Ok(())
    }

    pub fn increment(ctx: Context&lt;Increment&gt;) -&gt; Result&lt;()&gt; {
        let counter = &amp;mut ctx.accounts.counter;
        counter.count += 1;
        Ok(())
    }
}

#[derive(Accounts)]
pub struct Initialize&lt;&#039;info&gt; {
    #[account(init, payer = authority, space = 48)]
    pub counter: Account&lt;&#039;info, Counter&gt;,
    pub authority: Signer&lt;&#039;info&gt;,
    pub system_program: Program&lt;&#039;info, System&gt;,
}

#[derive(Accounts)]
pub struct Increment&lt;&#039;info&gt; {
    #[account(mut, has_one = authority)]
    pub counter: Account&lt;&#039;info, Counter&gt;,
    pub authority: Signer&lt;&#039;info&gt;,
}

#[account]
pub struct Counter {
    pub authority: Pubkey,
    pub count: u64,
}
```

For more, see the [examples](https://github.com/coral-xyz/anchor/tree/master/examples)
and [tests](https://github.com/coral-xyz/anchor/tree/master/tests) directories.

## License

Anchor is licensed under [Apache 2.0](./LICENSE).

Unless you explicitly state otherwise, any contribution intentionally submitted
for inclusion in Anchor by you, as defined in the Apache-2.0 license, shall be
licensed as above, without any additional terms or conditions.

## Contribution

Thank you for your interest in contributing to Anchor!
Please see the [CONTRIBUTING.md](./CONTRIBUTING.md) to learn how.

### Thanks ‚ù§Ô∏è

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/coral-xyz/anchor/graphs/contributors&quot;&gt;
    &lt;img src=&quot;https://contrib.rocks/image?repo=coral-xyz/anchor&quot; width=&quot;100%&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[paritytech/polkadot-sdk]]></title>
            <link>https://github.com/paritytech/polkadot-sdk</link>
            <guid>https://github.com/paritytech/polkadot-sdk</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:04 GMT</pubDate>
            <description><![CDATA[The Parity Polkadot Blockchain SDK]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paritytech/polkadot-sdk">paritytech/polkadot-sdk</a></h1>
            <p>The Parity Polkadot Blockchain SDK</p>
            <p>Language: Rust</p>
            <p>Stars: 2,339</p>
            <p>Forks: 979</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![SDK Logo](./docs/images/Polkadot_Logo_Horizontal_Pink_White.png#gh-dark-mode-only)
![SDK Logo](./docs/images/Polkadot_Logo_Horizontal_Pink_Black.png#gh-light-mode-only)

# Polkadot SDK

![GitHub stars](https://img.shields.io/github/stars/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub
forks](https://img.shields.io/github/forks/paritytech/polkadot-sdk)

&lt;!-- markdownlint-disable-next-line MD013 --&gt;
[![StackExchange](https://img.shields.io/badge/StackExchange-Community%20&amp;%20Support-222222?logo=stackexchange)](https://substrate.stackexchange.com/)&amp;nbsp;&amp;nbsp;![GitHub contributors](https://img.shields.io/github/contributors/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub commit activity](https://img.shields.io/github/commit-activity/m/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub last commit](https://img.shields.io/github/last-commit/paritytech/polkadot-sdk)

&gt; The Polkadot SDK repository provides all the components needed to start building on the
&gt; [Polkadot](https://polkadot.com/) network, a multi-chain blockchain platform that enables
&gt; different blockchains to interoperate and share information in a secure and scalable way.

&lt;/div&gt;

## ‚ö° Quickstart
If you want to get an example node running quickly you can execute the following getting started script:

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/scripts/getting-started.sh | bash
```

## üë©üèΩ‚Äçüíª Building

In order to build this project you need to install some dependencies, follow the instructions in [this guide](https://docs.polkadot.com/develop/parachains/install-polkadot-sdk).

## üìö Documentation

* [Polkadot Documentation Portal](https://docs.polkadot.com)
* [ü¶Ä rust-docs](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/index.html): Where we keep track of
the API docs of our Rust crates. Includes:
  * [Introduction](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/index.html)
	to each component of the Polkadot SDK: Substrate, FRAME, Cumulus, and XCM
  * [Guides](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/guides/index.html),
	namely how to build your first FRAME pallet
  * [Templates](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/templates/index.html)
    for starting a new project.
  * [External Resources](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/external_resources/index.html)
* Have a question? You can ask in the Polkadot SDK Developers Chat.
Messages from either of these channels are bridged to the other, so you can use whichever one you like.
  * [Telegram](https://t.me/substratedevs)
  * [Matrix](https://matrix.to/#/#substratedevs:matrix.org)
  * [Discord](https://discord.com/channels/722223075629727774/997505821955076196)
  * [Polkadot and Substrate StackExchange](https://substrate.stackexchange.com/)

## üöÄ Releases

&lt;!-- markdownlint-disable-next-line MD013 --&gt;
![Current Stable Release](https://raw.githubusercontent.com/paritytech/release-registry/main/badges/polkadot-sdk-latest.svg)&amp;nbsp;&amp;nbsp;![Next Stable Release](https://raw.githubusercontent.com/paritytech/release-registry/main/badges/polkadot-sdk-next.svg)

The Polkadot SDK is released every three months as a `Polkadot stableYYMM` release. Each stable release is supported for
one year with patches. See the next upcoming versions in the [Release
Registry](https://github.com/paritytech/release-registry/) and more docs in [RELEASE.md](./docs/RELEASE.md).

You can use [`psvm`](https://github.com/paritytech/psvm) to update all dependencies to a specific
version without needing to manually select the correct version for each crate.

## üõ†Ô∏è Tooling

[Polkadot SDK Version Manager](https://github.com/paritytech/psvm):
A simple tool to manage and update the Polkadot SDK dependencies in any Cargo.toml file.
It will automatically update the Polkadot SDK dependencies to their correct crates.io version.

## üîê Security

The security policy and procedures can be found in
[docs/contributor/SECURITY.md](./docs/contributor/SECURITY.md).

## ü§ç Contributing &amp; Code of Conduct

Ensure you follow our [contribution guidelines](./docs/contributor/CONTRIBUTING.md). In every
interaction and contribution, this project adheres to the [Contributor Covenant Code of
Conduct](./docs/contributor/CODE_OF_CONDUCT.md).

### üëæ Ready to Contribute?

Take a look at the issues labeled with [`mentor`](https://github.com/paritytech/polkadot-sdk/labels/C1-mentor)
(or alternatively [this](https://mentor.tasty.limo/) page, created by one of the maintainers) label to get started!
We always recognize valuable contributions by proposing an on-chain tip to the Polkadot network as a token of our
appreciation.

## Polkadot Fellowship

Development in this repo usually goes hand in hand with the `fellowship` organization. In short,
this repository provides all the SDK pieces needed to build both Polkadot and its parachains. But,
the actual Polkadot runtime lives in the `fellowship/runtimes` repository. Read more about the
fellowship, this separation, the RFC process
[here](https://polkadot-fellows.github.io/dashboard/).

## History

This repository is the amalgamation of 3 separate repositories that used to make up Polkadot SDK,
namely Substrate, Polkadot and Cumulus. Read more about the merge and its history
[here](https://polkadot-public.notion.site/Polkadot-SDK-FAQ-fbc4cecc2c46443fb37b9eeec2f0d85f).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[risingwavelabs/risingwave]]></title>
            <link>https://github.com/risingwavelabs/risingwave</link>
            <guid>https://github.com/risingwavelabs/risingwave</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:03 GMT</pubDate>
            <description><![CDATA[Stream processing and management platform.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/risingwavelabs/risingwave">risingwavelabs/risingwave</a></h1>
            <p>Stream processing and management platform.</p>
            <p>Language: Rust</p>
            <p>Stars: 8,137</p>
            <p>Forks: 661</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source srcset=&quot;.github/RisingWave-logo-dark.svg&quot; width=&quot;500px&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
    &lt;img src=&quot;.github/RisingWave-logo-light.svg&quot; width=&quot;500px&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;


&lt;div align=&quot;center&quot;&gt;

### üåä Ride the Wave of Streaming Data.

&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.risingwave.com/&quot;&gt;Docs&lt;/a&gt; | &lt;a href=&quot;https://docs.risingwave.com/get-started/rw-benchmarks-stream-processing&quot;&gt;Benchmarks&lt;/a&gt; | &lt;a href=&quot;https://docs.risingwave.com/demos/overview&quot;&gt;Demos&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a
    href=&quot;https://github.com/risingwavelabs/risingwave/releases/latest&quot;
    target=&quot;_blank&quot;
  &gt;
    &lt;img alt=&quot;Release&quot; src=&quot;https://img.shields.io/github/v/release/risingwavelabs/risingwave.svg?sort=semver&quot; /&gt;
  &lt;/a&gt;
  &lt;a
    href=&quot;https://go.risingwave.com/slack&quot;
    target=&quot;_blank&quot;
  &gt;
    &lt;img alt=&quot;Slack&quot; src=&quot;https://badgen.net/badge/Slack/Join%20RisingWave/0abd59?icon=slack&quot; /&gt;
  &lt;/a&gt;
  &lt;a
    href=&quot;https://x.com/risingwavelabs&quot;
    target=&quot;_blank&quot;
  &gt;
    &lt;img alt=&quot;X&quot; src=&quot;https://img.shields.io/twitter/follow/risingwavelabs&quot; /&gt;
  &lt;/a&gt;
  &lt;a
    href=&quot;https://www.youtube.com/@risingwave-labs&quot;
    target=&quot;_blank&quot;
  &gt;
    &lt;img alt=&quot;YouTube&quot; src=&quot;https://img.shields.io/youtube/channel/views/UCsHwdyBRxBpmkA5RRd0YNEA&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

RisingWave is a stream processing and management platform designed to offer the &lt;i&gt;&lt;b&gt;simplest&lt;/b&gt;&lt;/i&gt; and &lt;i&gt;&lt;b&gt;most cost-effective&lt;/b&gt;&lt;/i&gt; way to &lt;b&gt;process&lt;/b&gt;, &lt;b&gt;analyze&lt;/b&gt;, and &lt;b&gt;manage&lt;/b&gt; real-time event data ‚Äî with built-in support for the [Apache Iceberg‚Ñ¢](https://iceberg.apache.org/) open table format. It provides both a Postgres-compatible [SQL interface](https://docs.risingwave.com/sql/overview) and a DataFrame-style [Python interface](https://docs.risingwave.com/python-sdk/intro).

RisingWave can &lt;b&gt;ingest&lt;/b&gt; millions of events per second, continuously &lt;b&gt;join and analyze&lt;/b&gt; live streams with historical data, &lt;b&gt;serve&lt;/b&gt; ad-hoc queries at low latency, and &lt;b&gt;persist&lt;/b&gt; fresh, consistent results to Apache Iceberg‚Ñ¢ or any other downstream system.

![RisingWave](./docs/dev/src/images/architecture_20250609.jpg)

## Try it out in 60 seconds

Install RisingWave standalone mode:
```shell
curl -L https://risingwave.com/sh | sh
```

To learn about other installation options, such as using a Docker image, see [Quick Start](https://docs.risingwave.com/docs/current/get-started/).

## Stream, Store, and Query ‚Äî All in One

RisingWave delivers a full **end-to-end streaming data platform** ‚Äî combining real-time processing with built-in storage and open-format persistence.

It supports:

* **Ingestion:** Ingest millions of events per second from streaming and batch sources.
* **Stream processing:** Perform real-time incremental processing to join and analyze live data with historical tables.
* **Delivery:** Deliver fresh, consistent results to data lakes (e.g., Apache Iceberg‚Ñ¢) or any destination.

What sets RisingWave apart is its integrated storage engine:

* **Online serving:** Row-based storage optimized for point and range queries with single-digit millisecond latency.
* **Offline persistence:** Built-in Apache Iceberg‚Ñ¢ integration for low-cost, durable storage with open access for external query engines.

With RisingWave, real-time data isn‚Äôt just processed ‚Äî it‚Äôs stored, queried, and shared across your entire stack.

## Key design decisions

RisingWave is designed to be easier to use and more cost-efficient:

### PostgreSQL compatibility

* **Seamless integration:** Connects via the PostgreSQL wire protocol, working with psql, JDBC, and any Postgres tool.
* **Expressive SQL:** Supports structured, semi-structured, and unstructured data with a familiar SQL dialect.
* **No manual state tuning:** Eliminates complex state management configurations.

### S3 as primary storage

RisingWave stores tables, materialized views, and internal states of stream processing jobs in S3 (or equivalent object storage), providing:
- **High performance:** Optimized for complex queries, including joins and time windowing.
- **Fast recovery:** Restores from system failures within seconds.
- **[Dynamic scaling](https://docs.risingwave.com/deploy/k8s-cluster-scaling):** Instantly adjusts resources to handle workload spikes.

### Elastic disk cache

Beyond caching hot data in memory, RisingWave supports [**elastic disk cache**](https://docs.risingwave.com/get-started/disk-cache), a powerful performance optimization that uses local disks or EBS for efficient data caching. This minimizes access to S3, lowering processing latency and cutting S3 access costs.

### Apache Iceberg‚Ñ¢ native support
RisingWave [**natively integrates with Apache Iceberg‚Ñ¢**](https://docs.risingwave.com/iceberg/overview), enabling continuous ingestion of streaming data into Iceberg tables. It can also read directly from Iceberg, perform automatic compaction, and maintain table health over time. Since Iceberg is an open table format, results are accessible by other query engines ‚Äî making storage not only cost-efficient, but interoperable by design.

## In what use cases does RisingWave excel?
RisingWave is particularly effective for the following use cases:

* **Streaming analytics**: Achieve sub-second data freshness in live dashboards, ideal for high-stakes scenarios like stock trading, sports betting, and IoT monitoring.
* **Event-driven applications**: Develop sophisticated monitoring and alerting systems for critical applications such as fraud and anomaly detection.
* **Real-time data enrichment**: Continuously ingest data from diverse sources, conduct real-time data enrichment, and efficiently deliver the results to downstream systems.
* **Feature engineering**: Transform batch and streaming data into features in your machine learning models using a unified codebase, ensuring seamless integration and consistency.

## Production deployments

[**RisingWave Cloud**](https://cloud.risingwave.com) offers the easiest way to run RisingWave in production.

For **Docker deployment**, please refer to [Docker Compose](https://docs.risingwave.com/docs/current/risingwave-docker-compose/).

For **Kubernetes deployment**, please refer to [Kubernetes with Helm](https://docs.risingwave.com/docs/current/risingwave-k8s-helm/) or [Kubernetes with Operator](https://docs.risingwave.com/docs/current/risingwave-kubernetes/).

## Community

Looking for help, discussions, collaboration opportunities, or a casual afternoon chat with our fellow engineers and community members? Join our [Slack workspace](https://risingwave.com/slack)!

## Notes on telemetry


RisingWave uses [Scarf](https://scarf.sh/) to collect anonymized installation analytics. These analytics help support us understand and improve the distribution of our package. The privacy policy of Scarf is available at [https://about.scarf.sh/privacy-policy](https://about.scarf.sh/privacy-policy).

RisingWave also collects anonymous usage statistics to better understand how the community is using RisingWave. The sole intention of this exercise is to help improve the product. Users may opt out easily at any time. Please refer to the [user documentation](https://docs.risingwave.com/docs/current/telemetry/) for more details.

## License

RisingWave is distributed under the Apache License (Version 2.0). Please refer to [LICENSE](LICENSE) for more information.

## Contributing

Thanks for your interest in contributing to the project! Please refer to [RisingWave Developer Guide](https://risingwavelabs.github.io/risingwave/) for more information.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[szabodanika/microbin]]></title>
            <link>https://github.com/szabodanika/microbin</link>
            <guid>https://github.com/szabodanika/microbin</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:02 GMT</pubDate>
            <description><![CDATA[A secure, configurable file-sharing and URL shortening web app written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/szabodanika/microbin">szabodanika/microbin</a></h1>
            <p>A secure, configurable file-sharing and URL shortening web app written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,644</p>
            <p>Forks: 227</p>
            <p>Stars today: 132 stars today</p>
            <h2>README</h2><pre>
![Screenshot](.github/index.png)

# MicroBin

![Build](https://github.com/szabodanika/microbin/actions/workflows/rust.yml/badge.svg)
[![crates.io](https://img.shields.io/crates/v/microbin.svg)](https://crates.io/crates/microbin)
[![Docker Image](https://github.com/szabodanika/microbin/actions/workflows/release.yml/badge.svg)](https://hub.docker.com/r/danielszabo99/microbin)
[![Docker Pulls](https://img.shields.io/docker/pulls/danielszabo99/microbin?label=Docker%20pulls)](https://img.shields.io/docker/pulls/danielszabo99/microbin?label=Docker%20pulls)

MicroBin is a super tiny, feature-rich, configurable, self-contained and self-hosted paste bin web application. It is very easy to set up and use, and will only require a few megabytes of memory and disk storage. It takes only a couple minutes to set it up, why not give it a try now?

### Check out the Public Test Server at [pub.microbin.eu](https://pub.microbin.eu)!

### Or host MicroBin yourself

Run our quick docker setup script ([DockerHub](https://hub.docker.com/r/danielszabo99/microbin)):
```bash
bash &lt;(curl -s https://microbin.eu/docker.sh)
```

Or install it manually from [Cargo](https://crates.io/crates/microbin):

```bash
cargo install microbin;
curl -L -O https://raw.githubusercontent.com/szabodanika/microbin/master/.env;
source .env;
microbin
```

On our website [microbin.eu](https://microbin.eu), you will find the following:

- [Screenshots](https://microbin.eu/screenshots/)
- [Guide and Documentation](https://microbin.eu/docs/intro)
- [Donations and Sponsorships](https://microbin.eu/sponsorship)
- [Roadmap](https://microbin.eu/roadmap)

## Features

- Entirely self-contained executable, MicroBin is a single file!
- Server-side and client-side encryption
- File uploads (e.g. `server.com/file/pig-dog-cat`)
- Raw text serving (e.g. `server.com/raw/pig-dog-cat`)
- QR code support
- URL shortening and redirection
- Animal names instead of random numbers for upload identifiers (64 animals)
- SQLite and JSON database support
- Private and public, editable and uneditable, automatically and never expiring uploads
- Automatic dark mode and custom styling support with very little CSS and only vanilla JS (see [`water.css`](https://github.com/kognise/water.css))
- And much more!

## What is an upload?

In MicroBin, an upload can be:

- A text that you want to paste from one machine to another, e.g. some code,
- A file that you want to share, e.g. a video that is too large for Discord, a zip with a code project in it or an image,
- A URL redirection.

## When is MicroBin useful?

You can use MicroBin:

- To send long texts to other people,
- To send large files to other people,
- To share secrets or sensitive documents securely,
- As a URL shortener/redirect service,
- To serve content on the web, eg . configuration files for testing, images, or any other file content using the Raw functionality,
- To move files between your desktop and a server you access from the console,
- As a &quot;postbox&quot; service where people can upload their files or texts, but they cannot see or remove what others sent you,
- Or even to take quick notes.

...and many other things, why not get creative?

MicroBin and MicroBin.eu are available under the [BSD 3-Clause License](LICENSE).

¬© D√°niel Szab√≥ 2022-2024
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rust-lang/rustlings]]></title>
            <link>https://github.com/rust-lang/rustlings</link>
            <guid>https://github.com/rust-lang/rustlings</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:01 GMT</pubDate>
            <description><![CDATA[ü¶Ä Small exercises to get you used to reading and writing Rust code!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rust-lang/rustlings">rust-lang/rustlings</a></h1>
            <p>ü¶Ä Small exercises to get you used to reading and writing Rust code!</p>
            <p>Language: Rust</p>
            <p>Stars: 59,285</p>
            <p>Forks: 10,731</p>
            <p>Stars today: 19 stars today</p>
            <h2>README</h2><pre># [Rustlings](https://rustlings.rust-lang.org) ü¶Ä

Small exercises to get you used to reading and writing [Rust](https://www.rust-lang.org) code - _Recommended in parallel to reading [the official Rust book](https://doc.rust-lang.org/book) üìöÔ∏è_

Visit the **website** for a demo, info about setup and more:

## ‚û°Ô∏è [rustlings.rust-lang.org](https://rustlings.rust-lang.org) ‚¨ÖÔ∏è
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[fujiapple852/trippy]]></title>
            <link>https://github.com/fujiapple852/trippy</link>
            <guid>https://github.com/fujiapple852/trippy</guid>
            <pubDate>Sun, 20 Jul 2025 00:06:00 GMT</pubDate>
            <description><![CDATA[A network diagnostic tool]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/fujiapple852/trippy">fujiapple852/trippy</a></h1>
            <p>A network diagnostic tool</p>
            <p>Language: Rust</p>
            <p>Stars: 4,950</p>
            <p>Forks: 128</p>
            <p>Stars today: 12 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/fujiapple852/trippy/master/docs/src/assets/Trippy-Vertical-DarkMode.svg#gh-dark-mode-only&quot; width=&quot;300&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/fujiapple852/trippy/master/docs/src/assets/Trippy-Vertical.svg#gh-light-mode-only&quot; width=&quot;300&quot;&gt;&lt;br&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://github.com/fujiapple852/trippy/actions/workflows/ci.yml&quot;&gt;
    &lt;img src=&quot;https://github.com/fujiapple852/trippy/actions/workflows/ci.yml/badge.svg?branch=master&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://crates.io/crates/trippy/0.13.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/crates/v/trippy.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://repology.org/project/trippy/versions&quot;&gt;
    &lt;img src=&quot;https://repology.org/badge/tiny-repos/trippy.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://trippy.zulipchat.com&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/zulip-join_chat-brightgreen.svg&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://matrix.to/#/#trippy-dev:matrix.org&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/matrix/trippy-dev:matrix.org-blue&quot;&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;br&gt;
  Trippy combines the functionality of traceroute and ping and is designed to assist with the analysis of networking
issues.
&lt;/p&gt;

&lt;img src=&quot;https://raw.githubusercontent.com/fujiapple852/trippy/master/assets/0.12.0/demo.gif&quot; alt=&quot;trippy&quot;/&gt;

## Quick Start

See the [getting started](https://trippy.rs/start/getting-started) guide.

### Install

Trippy runs on Linux, BSD, macOS, and Windows. It can be installed from most package managers, precompiled binaries, or
source.

For example, to install Trippy from `cargo`:

```shell
cargo install trippy --locked
```

&lt;details&gt;

&lt;summary&gt;All package managers&lt;/summary&gt;

### Cargo

[![Crates.io](https://img.shields.io/crates/v/trippy)](https://crates.io/crates/trippy/0.13.0)

```shell
cargo install trippy --locked
```

### APT (Debian)

[![Debian 13 package](https://repology.org/badge/version-for-repo/debian_13/trippy.svg)](https://tracker.debian.org/pkg/trippy)

```shell
apt install trippy
```

&gt; ‚ìò Note:
&gt;
&gt; Only available for Debian 13 (`trixie`) and later.

### PPA (Ubuntu)

[![Ubuntu PPA](https://img.shields.io/badge/Ubuntu%20PPA-0.13.0-brightgreen)](https://launchpad.net/~fujiapple/+archive/ubuntu/trippy/+packages)

```shell
add-apt-repository ppa:fujiapple/trippy
apt update &amp;&amp; apt install trippy
```

&gt; ‚ìò Note:
&gt;
&gt; Only available for Ubuntu 24.04 (`Noble`) and 22.04 (`Jammy`).

### Snap (Linux)

[![trippy](https://snapcraft.io/trippy/badge.svg)](https://snapcraft.io/trippy)

```shell
snap install trippy
```

### Homebrew (macOS)

[![Homebrew package](https://repology.org/badge/version-for-repo/homebrew/trippy.svg)](https://formulae.brew.sh/formula/trippy)

```shell
brew install trippy
```

### WinGet (Windows)

[![winget package](https://img.shields.io/badge/WinGet-0.13.0-brightgreen)](https://github.com/microsoft/winget-pkgs/tree/master/manifests/f/FujiApple/Trippy/0.13.0)

```shell
winget install trippy
```

### Scoop (Windows)

[![Scoop package](https://img.shields.io/scoop/v/trippy?style=flat&amp;labelColor=5c5c5c&amp;color=%234dc71f)](https://github.com/ScoopInstaller/Main/blob/master/bucket/trippy.json)

```shell
scoop install trippy
```

### Chocolatey (Windows)

[![Chocolatey package](https://repology.org/badge/version-for-repo/chocolatey/trippy.svg)](https://community.chocolatey.org/packages/trippy)

```shell
choco install trippy
```

### NetBSD

[![pkgsrc current package](https://repology.org/badge/version-for-repo/pkgsrc_current/trippy.svg)](https://pkgsrc.se/net/trippy)

```shell
pkgin install trippy
```

### FreeBSD

[![FreeBSD port](https://repology.org/badge/version-for-repo/freebsd/trippy.svg)](https://www.freshports.org/net/trippy/)

```shell
pkg install trippy
```

### OpenBSD

[![OpenBSD port](https://repology.org/badge/version-for-repo/openbsd/trippy.svg)](https://openports.pl/path/net/trippy)

```shell
pkg_add trippy
```

### Arch Linux

[![Arch package](https://repology.org/badge/version-for-repo/arch/trippy.svg)](https://archlinux.org/packages/extra/x86_64/trippy)

```shell
pacman -S trippy
```

### Gentoo Linux

[![Gentoo package](https://repology.org/badge/version-for-repo/gentoo/trippy.svg)](https://packages.gentoo.org/packages/net-analyzer/trippy)

```shell
emerge -av net-analyzer/trippy
```

### Void Linux

[![Void Linux x86_64 package](https://repology.org/badge/version-for-repo/void_x86_64/trippy.svg)](https://github.com/void-linux/void-packages/tree/master/srcpkgs/trippy)

```shell
xbps-install -S trippy
```

### ALT Sisyphus

[![ALT Sisyphus package](https://repology.org/badge/version-for-repo/altsisyphus/trippy.svg)](https://packages.altlinux.org/en/sisyphus/srpms/trippy/)

```shell
apt-get install trippy
```

### Chimera Linux

[![Chimera Linux package](https://repology.org/badge/version-for-repo/chimera/trippy.svg)](https://github.com/chimera-linux/cports/tree/master/user/trippy)

```shell
apk add trippy
```

### Nix

[![nixpkgs unstable package](https://repology.org/badge/version-for-repo/nix_unstable/trippy.svg)](https://github.com/NixOS/nixpkgs/blob/master/pkgs/by-name/tr/trippy/package.nix)

```shell
nix-env -iA trippy
```

### Docker

[![Docker Image Version (latest by date)](https://img.shields.io/docker/v/fujiapple/trippy)](https://hub.docker.com/r/fujiapple/trippy/)

```shell
docker run -it fujiapple/trippy
```

### All Repositories

[![Packaging status](https://repology.org/badge/vertical-allrepos/trippy.svg)](https://repology.org/project/trippy/versions)

&lt;/details&gt;

See the [installation](https://trippy.rs/start/installation) guide for details of how to install Trippy on your system.

### Run

To run a basic trace to `example.com` with default settings, use the following command:

```shell
sudo trip example.com
```

See the [usage examples](https://trippy.rs/guides/usage) and [CLI reference](https://trippy.rs/reference/cli) for
details of how to use Trippy. To use Trippy without elevated privileges, see
the [privileges](https://trippy.rs/guides/privileges) guide.

## Documentation

Full documentation is available at [trippy.rs](https://trippy.rs).

&lt;details&gt;

&lt;summary&gt;documentation links&lt;/summary&gt;

## Getting Started

See the [Getting Started](https://trippy.rs/start/getting-started/) guide.

## Features

See the [Features](https://trippy.rs/start/features/) list.

## Distributions

See the [Distributions](https://trippy.rs/start/installation/) list.

## Privileges

See the [Privileges](https://trippy.rs/guides/privileges/) guide.

## Usage Examples

See the [Usage Examples](https://trippy.rs/guides/usage/).

## Command Reference

See the [Command Reference](https://trippy.rs/reference/cli/).

## Theme Reference

See the [Theme Reference](https://trippy.rs/reference/theme/).

## Column Reference

See the [Column Reference](https://trippy.rs/reference/column/).

## Configuration Reference

See the [Configuration Reference](https://trippy.rs/reference/configuration/).

## Locale Reference

See the [Locale Reference](https://trippy.rs/reference/locale/).

## Versions

See the [Version Reference](https://trippy.rs/reference/version/).

## Frequently Asked Questions

### Why does Trippy show &quot;Awaiting data...&quot;?

See the [Awaiting Data](https://trippy.rs/guides/faq/) guide.

&lt;a name=&quot;windows-defender&quot;&gt;&lt;/a&gt;

### How do I allow incoming ICMP traffic in the Windows Defender firewall?

See the [Windows Defender Firewall](https://trippy.rs/guides/windows_firewall/) guide.

### What are the recommended settings for Trippy?

See the [Recommended Tracing Settings](https://trippy.rs/guides/recommendation/) guide.

&lt;/details&gt;

## Acknowledgements

Trippy is made possible by [ratatui](https://github.com/ratatui-org/ratatui) (
formerly [tui-rs](https://github.com/fdehau/tui-rs)),
[crossterm](https://github.com/crossterm-rs/crossterm) as well
as [several](https://github.com/fujiapple852/trippy/blob/master/Cargo.toml) foundational Rust libraries.

Trippy draws heavily from [mtr](https://github.com/traviscross/mtr) and also incorporates ideas
from both [libparistraceroute](https://github.com/libparistraceroute/libparistraceroute)
&amp; [Dublin Traceroute](https://github.com/insomniacslk/dublin-traceroute).

The Trippy networking code is inspired by [pnet](https://github.com/libpnet/libpnet) and some elements of that codebase
are incorporated in Trippy.

The [AS][autonomous_system] data is retrieved from
the [IP to ASN Mapping Service](https://team-cymru.com/community-services/ip-asn-mapping/#dns) provided
by [Team Cymru](https://team-cymru.com).

The [trippy.cli.rs](https://trippy.cli.rs) CNAME hosting is provided by [cli.rs](https://cli.rs).

The Trippy chat room is sponsored by [Zulip](https://zulip.com).

Trippy logo designed by [Harun Ocaksiz Design](https://www.instagram.com/harunocaksiz).

## License

This project is distributed under the terms of the Apache License (Version 2.0).

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in time by you, as defined
in the Apache-2.0 license, shall be licensed as above, without any additional terms or conditions.

See [LICENSE](LICENSE) for details.

Copyright 2022 [Trippy Contributors](https://github.com/fujiapple852/trippy/graphs/contributors)

[autonomous_system]: https://en.wikipedia.org/wiki/Autonomous_system_(Internet)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[dandavison/delta]]></title>
            <link>https://github.com/dandavison/delta</link>
            <guid>https://github.com/dandavison/delta</guid>
            <pubDate>Sun, 20 Jul 2025 00:05:59 GMT</pubDate>
            <description><![CDATA[A syntax-highlighting pager for git, diff, grep, and blame output]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dandavison/delta">dandavison/delta</a></h1>
            <p>A syntax-highlighting pager for git, diff, grep, and blame output</p>
            <p>Language: Rust</p>
            <p>Stars: 26,867</p>
            <p>Forks: 422</p>
            <p>Stars today: 52 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img width=400px src=&quot;https://user-images.githubusercontent.com/52205/147996902-9829bd3f-cd33-466e-833e-49a6f3ebd623.png&quot; alt=&quot;image&quot; /&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/dandavison/delta/actions&quot;&gt;
    &lt;img src=&quot;https://github.com/dandavison/delta/workflows/Continuous%20Integration/badge.svg&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://coveralls.io/github/dandavison/delta?branch=main&quot;&gt;
    &lt;img src=&quot;https://coveralls.io/repos/github/dandavison/delta/badge.svg?branch=main&quot; alt=&quot;Coverage Status&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://gitter.im/dandavison-delta/community?utm_source=badge&amp;amp;utm_medium=badge&amp;amp;utm_campaign=pr-badge&quot;&gt;
    &lt;img src=&quot;https://badges.gitter.im/dandavison-delta/community.svg&quot; alt=&quot;Gitter&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## Get Started

[Install it](https://dandavison.github.io/delta/installation.html) (the package is called &quot;git-delta&quot; in most package managers, but the executable is just `delta`) and add this to your `~/.gitconfig`:

```gitconfig
[core]
    pager = delta

[interactive]
    diffFilter = delta --color-only

[delta]
    navigate = true  # use n and N to move between diff sections
    dark = true      # or light = true, or omit for auto-detection

[merge]
    conflictstyle = zdiff3
```

Or run:

```sh
git config --global core.pager delta
git config --global interactive.diffFilter &#039;delta --color-only&#039;
git config --global delta.navigate true
git config --global merge.conflictStyle zdiff3
```

Delta has many features and is very customizable; please see `delta -h` (short help) or `delta --help` (full manual), or the [online user manual](https://dandavison.github.io/delta/).

## Features

- Language syntax highlighting with the same syntax-highlighting themes as [bat](https://github.com/sharkdp/bat#readme)
- Word-level diff highlighting using a Levenshtein edit inference algorithm
- Side-by-side view with line-wrapping
- Line numbering
- `n` and `N` keybindings to move between files in large diffs, and between diffs in `log -p` views (`--navigate`)
- Improved merge conflict display
- Improved `git blame` display (syntax highlighting; `--hyperlinks` formats commits as links to hosting provider etc. Supported hosting providers are: GitHub, GitLab, SourceHut, Codeberg)
- Syntax-highlights grep output from `rg`, `git grep`, `grep`, etc
- Support for Git&#039;s `--color-moved` feature.
- Code can be copied directly from the diff (`-/+` markers are removed by default).
- `diff-highlight` and `diff-so-fancy` emulation modes
- Commit hashes can be formatted as terminal [hyperlinks](https://gist.github.com/egmontkob/eb114294efbcd5adb1944c9f3cb5feda) to the hosting provider page (`--hyperlinks`).
  File paths can also be formatted as hyperlinks for opening in your OS.
- Stylable box/line decorations to draw attention to commit, file and hunk header sections.
- Style strings (foreground color, background color, font attributes) are supported for &gt;20 stylable elements, using the same color/style language as git
- Handles traditional unified diff output in addition to git output
- Automatic detection of light/dark terminal background

## A syntax-highlighting pager for git, diff, and grep output

Code evolves, and we all spend time studying diffs. Delta aims to make this both efficient and enjoyable: it allows you to make extensive changes to the layout and styling of diffs, as well as allowing you to stay arbitrarily close to the default git/diff output.

&lt;table align=&quot;center&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;
      &lt;img width=400px src=&quot;https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png&quot; alt=&quot;image&quot; /&gt;
      &lt;br&gt;
      &lt;p align=&quot;center&quot;&gt;&lt;sub&gt;delta with &lt;code&gt;line-numbers&lt;/code&gt; activated&lt;/sub&gt;&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;table align=&quot;center&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;
      &lt;img width=800px src=&quot;https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png&quot; alt=&quot;image&quot; /&gt;
      &lt;br&gt;
      &lt;p align=&quot;center&quot;&gt;&lt;sub&gt;delta with &lt;code&gt;side-by-side&lt;/code&gt; and &lt;code&gt;line-numbers&lt;/code&gt; activated&lt;/sub&gt;&lt;/p&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

Here&#039;s what `git show` can look like with git configured to use delta:

&lt;br&gt;

&lt;table align=&quot;center&quot;&gt;
  &lt;tr&gt;
    &lt;td&gt;
      &lt;img width=500px style=&quot;border: 1px solid black&quot;
           src=&quot;https://user-images.githubusercontent.com/52205/81058545-a5725f80-8e9c-11ea-912e-d21954586a44.png&quot;
           alt=&quot;image&quot; /&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;img width=500px style=&quot;border: 1px solid black&quot;
           src=&quot;https://user-images.githubusercontent.com/52205/81058911-6abcf700-8e9d-11ea-93be-e212824ec03d.png&quot;
           alt=&quot;image&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;
      &quot;Dracula&quot; theme
    &lt;/td&gt;
    &lt;td&gt;
      &quot;GitHub&quot; theme
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;br&gt;
&lt;br&gt;

### Syntax-highlighting themes

**All the syntax-highlighting color themes that are available with [bat](https://github.com/sharkdp/bat/) are available with delta:**

&lt;br&gt;
&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;
      &lt;img width=400px style=&quot;border: 1px solid black&quot;
           src=&quot;https://user-images.githubusercontent.com/52205/149431273-e3ad049d-771e-4186-869d-0e57967958a6.png&quot;
           alt=&quot;image&quot; /&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;img width=400px style=&quot;border: 1px solid black&quot;
           src=&quot;https://user-images.githubusercontent.com/52205/149431419-48836001-2afc-4fd0-97ad-561a69b71db7.png&quot;
           alt=&quot;image&quot; /&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;
      &lt;code&gt;delta --show-syntax-themes --dark&lt;/code&gt;
    &lt;/td&gt;
    &lt;td&gt;
      &lt;code&gt;delta --show-syntax-themes --light&lt;/code&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

&lt;br&gt;

### Side-by-side view

[[User manual](https://dandavison.github.io/delta/side-by-side-view.html)]

```gitconfig
[delta]
    side-by-side = true
```

By default, side-by-side view has line-numbers activated, and has syntax highlighting in both the left and right panels: [[config](#side-by-side-view-1)]

&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;img width=800px src=&quot;https://user-images.githubusercontent.com/52205/87230973-412eb900-c381-11ea-8aec-cc200290bd1b.png&quot; alt=&quot;image&quot; /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

Side-by-side view wraps long lines automatically:

&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;img width=600px src=&quot;https://user-images.githubusercontent.com/52205/139064537-f8479504-16d3-429a-b4f6-d0122438adaa.png&quot; alt=&quot;image&quot; /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

### Line numbers

[[User manual](https://dandavison.github.io/delta/line-numbers.html)]

```gitconfig
[delta]
    line-numbers = true
```

&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;img width=400px src=&quot;https://user-images.githubusercontent.com/52205/86275526-76792100-bba1-11ea-9e78-6be9baa80b29.png&quot; alt=&quot;image&quot; /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

### Merge conflicts

[[User manual](https://dandavison.github.io/delta/merge-conflicts.html)]

&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;img width=500px src=&quot;https://user-images.githubusercontent.com/52205/144783121-bb549100-69d8-41b8-ac62-1704f1f7b43e.png&quot; alt=&quot;image&quot; /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

### Git blame

[[User manual](https://dandavison.github.io/delta/git-blame.html)]

&lt;table&gt;&lt;tr&gt;&lt;td&gt;&lt;img width=600px src=&quot;https://user-images.githubusercontent.com/52205/141891376-1fdb87dc-1d9c-4ad6-9d72-eeb19a8aeb0b.png&quot; alt=&quot;image&quot; /&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

### Ripgrep, git grep

[[User manual](https://dandavison.github.io/delta/grep.html)]

&lt;table&gt;&lt;tr&gt;&lt;td&gt;
&lt;img width=&quot;600px&quot; alt=&quot;image&quot; src=&quot;https://github.com/dandavison/open-in-editor/assets/52205/d203d380-5acb-4296-aeb9-e38c73d6c27f&quot;&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

### Installation and usage

Please see the [user manual](https://dandavison.github.io/delta/) and `delta --help`.

### Maintainers

- [@dandavison](https://github.com/dandavison)
- [@th1000s](https://github.com/th1000s)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[unionlabs/union]]></title>
            <link>https://github.com/unionlabs/union</link>
            <guid>https://github.com/unionlabs/union</guid>
            <pubDate>Sun, 20 Jul 2025 00:05:58 GMT</pubDate>
            <description><![CDATA[The trust-minimized, zero-knowledge bridging protocol, designed for censorship resistance, extremely high security, and usage in decentralized finance.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/unionlabs/union">unionlabs/union</a></h1>
            <p>The trust-minimized, zero-knowledge bridging protocol, designed for censorship resistance, extremely high security, and usage in decentralized finance.</p>
            <p>Language: Rust</p>
            <p>Stars: 73,069</p>
            <p>Forks: 3,585</p>
            <p>Stars today: 374 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./.github/images/union-logo-white.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;./.github/images/union-logo-black.svg&quot;&gt;
    &lt;img alt=&quot;Union&quot;
         src=&quot;./.github/images/union-logo-black.svg&quot;
         width=&quot;100%&quot;&gt;
  &lt;/picture&gt;
&lt;/div&gt;

&lt;br/&gt;

&lt;div align=&quot;center&quot;&gt;

[![built with garnix](https://img.shields.io/endpoint.svg?url=https%3A%2F%2Fgarnix.io%2Fapi%2Fbadges%2Funionlabs%2Funion%3Fbranch%3Dmain)](https://garnix.io)
[![Docs](https://img.shields.io/badge/docs-main-blue)][docs]
[![Discord badge]](https://discord.union.build)
[![Twitter handle]][twitter badge]

&lt;/div&gt;

Union is the hyper-efficient zero-knowledge infrastructure layer for general message passing, asset transfers, NFTs, and DeFi. Its based on [Consensus Verification] and has no dependencies on trusted third parties, oracles, multi-signatures or MPC. It implements [IBC] for compatibility with [Cosmos] chains and connects to EVM chains like [Ethereum], [Berachain (beacon-kit)](https://github.com/berachain/beacon-kit), [Arbitrum], and more.

The upgradability of contracts on other chains, connections, token configurations, and evolution of the protocol will all be controlled by decentralized governance, aligning the priorities of Union with its users, validators, and operators.

## Components

| Component                                             | Description                                          | Language(s)           |
| ----------------------------------------------------- | ---------------------------------------------------- | --------------------- |
| [`uniond`](./uniond/README.md)                        | The Union node implementation, using [`CometBLS`]    | [Go]                  |
| [`galoisd`](./galoisd)                                | The zero-knowledge prover implementation             | [Go] [Gnark]          |
| [`voyager`](./voyager)                                | Modular hyper-performant cross-ecosystem relayer     | [Rust]                |
| [`hubble`](./hubble)                                  | Multi-ecosystem, GMP-enabled chain indexer           | [Rust]                |
| [`cosmwasm`](./cosmwasm)                              | [CosmWasm] smart contract stack                      | [Rust]                |
| [`light-clients`](./cosmwasm/ibc-union/lightclient)   | [Light Clients] for various ecosystems               | [Rust]                |
| [`unionvisor`](./unionvisor/README.md)                | Node supervisor intended for production usage        | [Rust]                |
| [`drip`](./drip)                                      | Faucet for [Cosmos] chains: [app.union.build/faucet] | [Rust]                |
| [`evm`](./evm)                                        | [EVM] smart contract stack                           | [Solidity]            |
| [`app`](./app2)                                       | [app.union.build]                                    | [TypeScript] [Svelte] |
| [`site`](./site)                                      | [union.build]                                        | [TypeScript] [Astro]  |
| [`TypeScript SDK`](./ts-sdk)                  | TypeScript SDK for interacting with Union            | [TypeScript]          |

## Quickstart

Install [Nix] to _[reproducibly build](https://en.wikipedia.org/wiki/Reproducible_builds) any component_, and to enter a dev shell with _all dependencies_:

```sh
curl --proto &#039;=https&#039; --tlsv1.2 -sSf -L https://install.determinate.systems/nix | sh -s -- install
```

_(Note that some components can only be built on Linux. If you are using macOS, we recommend using [OrbStack] to easily set up a [NixOS] VM within two minutes. Most Union developers use macOS with [OrbStack], and there is no need to install Nix inside of the [NixOS] VM.)_

You can now _reproducibly_ build any of Union&#039;s components from source:

```sh
nix build .#uniond -L
nix build .#voyager -L
nix build .#app -L

# to see all packages, run:
nix flake show
```

The result of whatever you build will be in `result/`

You can now also enter our dev shell, which has all of the dependencies (`cargo`, `rustc`, `node`, `go`, etc.) you need to work on any component:
_(Don&#039;t worry, this will not affect your system outside of this repo)_

```sh
nix develop
```

Run the following to format the entire repo and check your spelling before each PR:

```sh
nix run .#pre-commit -L
```

Check the `#developers` channel on [Union&#039;s discord](https://discord.union.build) if you need any help with this.

## Docs

The official docs are hosted [here][docs]. Each individual component also has accompanying developer documentation for contributors, which you can find in each `README.md`.

[app.union.build]: https://app.union.build
[app.union.build/faucet]: https://app.union.build/faucet
[arbitrum]: https://github.com/OffchainLabs/arbitrum
[astro]: https://astro.build
[consensus verification]: https://union.build/docs/concepts/consensus-verification/
[cosmos]: https://cosmos.network
[cosmwasm]: https://cosmwasm.com/
[discord badge]: https://img.shields.io/discord/1158939416870522930?logo=discord
[docs]: https://docs.union.build &quot;Official Union Docs&quot;
[ethereum]: https://ethereum.org
[evm]: https://ethereum.org/en/developers/docs/evm/
[gnark]: https://github.com/ConsenSys/gnark
[go]: https://go.dev/
[ibc]: https://github.com/cosmos/ibc &quot;cosmos/ibc&quot;
[light clients]: https://a16zcrypto.com/posts/article/an-introduction-to-light-clients/
[nix]: https://zero-to-nix.com/
[nixos]: https://nixos.org
[orbstack]: https://orbstack.dev/
[rust]: https://www.rust-lang.org/
[solidity]: https://soliditylang.org/
[svelte]: https://svelte.dev
[twitter badge]: https://twitter.com/intent/follow?screen_name=union_build
[twitter handle]: https://img.shields.io/twitter/follow/union_build.svg?style=social&amp;label=Follow
[typescript]: https://www.typescriptlang.org/
[union.build]: https://union.build
[`cometbls`]: https://github.com/unionlabs/cometbls
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>