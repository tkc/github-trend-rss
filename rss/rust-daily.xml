<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Fri, 21 Mar 2025 00:05:30 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[block/goose]]></title>
            <link>https://github.com/block/goose</link>
            <guid>https://github.com/block/goose</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/block/goose">block/goose</a></h1>
            <p>an open source, extensible AI agent that goes beyond code suggestions - install, execute, edit, and test with any LLM</p>
            <p>Language: Rust</p>
            <p>Stars: 10,607</p>
            <p>Forks: 752</p>
            <p>Stars today: 73 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

# codename goose

_a local, extensible, open source AI agent that automates engineering tasks_

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/7GaTvbDwga&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/1287729918100246654?logo=discord&amp;logoColor=white&amp;label=Join+Us&amp;color=blueviolet&quot; alt=&quot;Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/block/goose/actions/workflows/ci.yml&quot;&gt;
     &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/block/goose/ci.yml?branch=main&quot; alt=&quot;CI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;/div&gt;

goose is your on-machine AI agent, capable of automating complex development tasks from start to finish. More than just code suggestions, goose can build entire projects from scratch, write and execute code, debug failures, orchestrate workflows, and interact with external APIs - _autonomously_.

Whether you&#039;re prototyping an idea, refining existing code, or managing intricate engineering pipelines, goose adapts to your workflow and executes tasks with precision.

Designed for maximum flexibility, goose works with any LLM and seamlessly integrates with MCP-enabled APIs, making it the ultimate AI-powered assistant for developers who want to move faster and focus on innovation. 


# Quick Links
- [Quickstart](https://block.github.io/goose/docs/quickstart)
- [Installation](https://block.github.io/goose/docs/getting-started/installation)
- [Tutorials](https://block.github.io/goose/docs/category/tutorials)
- [Documentation](https://block.github.io/goose/docs/category/getting-started)


# Goose Around with Us
- [Discord](https://discord.gg/block-opensource)
- [YouTube](https://www.youtube.com/@blockopensource)
- [LinkedIn](https://www.linkedin.com/company/block-opensource)
- [Twitter/X](https://x.com/blockopensource)
- [Bluesky](https://bsky.app/profile/opensource.block.xyz)
- [Nostr](https://njump.me/opensource@block.xyz)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[sharkdp/fd]]></title>
            <link>https://github.com/sharkdp/fd</link>
            <guid>https://github.com/sharkdp/fd</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[A simple, fast and user-friendly alternative to 'find']]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sharkdp/fd">sharkdp/fd</a></h1>
            <p>A simple, fast and user-friendly alternative to 'find'</p>
            <p>Language: Rust</p>
            <p>Stars: 36,720</p>
            <p>Forks: 857</p>
            <p>Stars today: 647 stars today</p>
            <h2>README</h2><pre># fd

[![CICD](https://github.com/sharkdp/fd/actions/workflows/CICD.yml/badge.svg)](https://github.com/sharkdp/fd/actions/workflows/CICD.yml)
[![Version info](https://img.shields.io/crates/v/fd-find.svg)](https://crates.io/crates/fd-find)
[[中文](https://github.com/cha0ran/fd-zh)]
[[한국어](https://github.com/spearkkk/fd-kor)]

`fd` is a program to find entries in your filesystem.
It is a simple, fast and user-friendly alternative to [`find`](https://www.gnu.org/software/findutils/).
While it does not aim to support all of `find`&#039;s powerful functionality, it provides sensible
(opinionated) defaults for a majority of use cases.

[Installation](#installation) • [How to use](#how-to-use) • [Troubleshooting](#troubleshooting)

## Features

* Intuitive syntax: `fd PATTERN` instead of `find -iname &#039;*PATTERN*&#039;`.
* Regular expression (default) and glob-based patterns.
* [Very fast](#benchmark) due to parallelized directory traversal.
* Uses colors to highlight different file types (same as `ls`).
* Supports [parallel command execution](#command-execution)
* Smart case: the search is case-insensitive by default. It switches to
  case-sensitive if the pattern contains an uppercase
  character[\*](http://vimdoc.sourceforge.net/htmldoc/options.html#&#039;smartcase&#039;).
* Ignores hidden directories and files, by default.
* Ignores patterns from your `.gitignore`, by default.
* The command name is *50%* shorter[\*](https://github.com/ggreer/the_silver_searcher) than
  `find` :-).

## Demo

![Demo](doc/screencast.svg)

## How to use

First, to get an overview of all available command line options, you can either run
[`fd -h`](#command-line-options) for a concise help message or `fd --help` for a more detailed
version.

### Simple search

*fd* is designed to find entries in your filesystem. The most basic search you can perform is to
run *fd* with a single argument: the search pattern. For example, assume that you want to find an
old script of yours (the name included `netflix`):
``` bash
&gt; fd netfl
Software/python/imdb-ratings/netflix-details.py
```
If called with just a single argument like this, *fd* searches the current directory recursively
for any entries that *contain* the pattern `netfl`.

### Regular expression search

The search pattern is treated as a regular expression. Here, we search for entries that start
with `x` and end with `rc`:
``` bash
&gt; cd /etc
&gt; fd &#039;^x.*rc$&#039;
X11/xinit/xinitrc
X11/xinit/xserverrc
```

The regular expression syntax used by `fd` is [documented here](https://docs.rs/regex/latest/regex/#syntax).

### Specifying the root directory

If we want to search a specific directory, it can be given as a second argument to *fd*:
``` bash
&gt; fd passwd /etc
/etc/default/passwd
/etc/pam.d/passwd
/etc/passwd
```

### List all files, recursively

*fd* can be called with no arguments. This is very useful to get a quick overview of all entries
in the current directory, recursively (similar to `ls -R`):
``` bash
&gt; cd fd/tests
&gt; fd
testenv
testenv/mod.rs
tests.rs
```

If you want to use this functionality to list all files in a given directory, you have to use
a catch-all pattern such as `.` or `^`:
``` bash
&gt; fd . fd/tests/
testenv
testenv/mod.rs
tests.rs
```

### Searching for a particular file extension

Often, we are interested in all files of a particular type. This can be done with the `-e` (or
`--extension`) option. Here, we search for all Markdown files in the fd repository:
``` bash
&gt; cd fd
&gt; fd -e md
CONTRIBUTING.md
README.md
```

The `-e` option can be used in combination with a search pattern:
``` bash
&gt; fd -e rs mod
src/fshelper/mod.rs
src/lscolors/mod.rs
tests/testenv/mod.rs
```

### Searching for a particular file name

 To find files with exactly the provided search pattern, use the `-g` (or `--glob`) option:
``` bash
&gt; fd -g libc.so /usr
/usr/lib32/libc.so
/usr/lib/libc.so
```

### Hidden and ignored files
By default, *fd* does not search hidden directories and does not show hidden files in the
search results. To disable this behavior, we can use the `-H` (or `--hidden`) option:
``` bash
&gt; fd pre-commit
&gt; fd -H pre-commit
.git/hooks/pre-commit.sample
```

If we work in a directory that is a Git repository (or includes Git repositories), *fd* does not
search folders (and does not show files) that match one of the `.gitignore` patterns. To disable
this behavior, we can use the `-I` (or `--no-ignore`) option:
``` bash
&gt; fd num_cpu
&gt; fd -I num_cpu
target/debug/deps/libnum_cpus-f5ce7ef99006aa05.rlib
```

To really search *all* files and directories, simply combine the hidden and ignore features to show
everything (`-HI`) or use `-u`/`--unrestricted`.

### Matching the full path
By default, *fd* only matches the filename of each file. However, using the `--full-path` or `-p` option,
you can match against the full path.

```bash
&gt; fd -p -g &#039;**/.git/config&#039;
&gt; fd -p &#039;.*/lesson-\d+/[a-z]+.(jpg|png)&#039;
```

### Command execution

Instead of just showing the search results, you often want to *do something* with them. `fd`
provides two ways to execute external commands for each of your search results:

* The `-x`/`--exec` option runs an external command *for each of the search results* (in parallel).
* The `-X`/`--exec-batch` option launches the external command once, with *all search results as arguments*.

#### Examples

Recursively find all zip archives and unpack them:
``` bash
fd -e zip -x unzip
```
If there are two such files, `file1.zip` and `backup/file2.zip`, this would execute
`unzip file1.zip` and `unzip backup/file2.zip`. The two `unzip` processes run in parallel
(if the files are found fast enough).

Find all `*.h` and `*.cpp` files and auto-format them inplace with `clang-format -i`:
``` bash
fd -e h -e cpp -x clang-format -i
```
Note how the `-i` option to `clang-format` can be passed as a separate argument. This is why
we put the `-x` option last.

Find all `test_*.py` files and open them in your favorite editor:
``` bash
fd -g &#039;test_*.py&#039; -X vim
```
Note that we use capital `-X` here to open a single `vim` instance. If there are two such files,
`test_basic.py` and `lib/test_advanced.py`, this will run `vim test_basic.py lib/test_advanced.py`.

To see details like file permissions, owners, file sizes etc., you can tell `fd` to show them
by running `ls` for each result:
``` bash
fd … -X ls -lhd --color=always
```
This pattern is so useful that `fd` provides a shortcut. You can use the `-l`/`--list-details`
option to execute `ls` in this way: `fd … -l`.

The `-X` option is also useful when combining `fd` with [ripgrep](https://github.com/BurntSushi/ripgrep/) (`rg`) in order to search within a certain class of files, like all C++ source files:
```bash
fd -e cpp -e cxx -e h -e hpp -X rg &#039;std::cout&#039;
```

Convert all `*.jpg` files to `*.png` files:
``` bash
fd -e jpg -x convert {} {.}.png
```
Here, `{}` is a placeholder for the search result. `{.}` is the same, without the file extension.
See below for more details on the placeholder syntax.

The terminal output of commands run from parallel threads using `-x` will not be interlaced or garbled,
so `fd -x` can be used to rudimentarily parallelize a task run over many files.
An example of this is calculating the checksum of each individual file within a directory.
```
fd -tf -x md5sum &gt; file_checksums.txt
```

#### Placeholder syntax

The `-x` and `-X` options take a *command template* as a series of arguments (instead of a single string).
If you want to add additional options to `fd` after the command template, you can terminate it with a `\;`.

The syntax for generating commands is similar to that of [GNU Parallel](https://www.gnu.org/software/parallel/):

- `{}`: A placeholder token that will be replaced with the path of the search result
  (`documents/images/party.jpg`).
- `{.}`: Like `{}`, but without the file extension (`documents/images/party`).
- `{/}`: A placeholder that will be replaced by the basename of the search result (`party.jpg`).
- `{//}`: The parent of the discovered path (`documents/images`).
- `{/.}`: The basename, with the extension removed (`party`).

If you do not include a placeholder, *fd* automatically adds a `{}` at the end.

#### Parallel vs. serial execution

For `-x`/`--exec`, you can control the number of parallel jobs by using the `-j`/`--threads` option.
Use `--threads=1` for serial execution.

### Excluding specific files or directories

Sometimes we want to ignore search results from a specific subdirectory. For example, we might
want to search all hidden files and directories (`-H`) but exclude all matches from `.git`
directories. We can use the `-E` (or `--exclude`) option for this. It takes an arbitrary glob
pattern as an argument:
``` bash
&gt; fd -H -E .git …
```

We can also use this to skip mounted directories:
``` bash
&gt; fd -E /mnt/external-drive …
```

.. or to skip certain file types:
``` bash
&gt; fd -E &#039;*.bak&#039; …
```

To make exclude-patterns like these permanent, you can create a `.fdignore` file. They work like
`.gitignore` files, but are specific to `fd`. For example:
``` bash
&gt; cat ~/.fdignore
/mnt/external-drive
*.bak
```

&gt; [!NOTE]
&gt; `fd` also supports `.ignore` files that are used by other programs such as `rg` or `ag`.

If you want `fd` to ignore these patterns globally, you can put them in `fd`&#039;s global ignore file.
This is usually located in `~/.config/fd/ignore` in macOS or Linux, and `%APPDATA%\fd\ignore` in
Windows.

You may wish to include `.git/` in your `fd/ignore` file so that `.git` directories, and their contents
are not included in output if you use the `--hidden` option.

### Deleting files

You can use `fd` to remove all files and directories that are matched by your search pattern.
If you only want to remove files, you can use the `--exec-batch`/`-X` option to call `rm`. For
example, to recursively remove all `.DS_Store` files, run:
``` bash
&gt; fd -H &#039;^\.DS_Store$&#039; -tf -X rm
```
If you are unsure, always call `fd` without `-X rm` first. Alternatively, use `rm`s &quot;interactive&quot;
option:
``` bash
&gt; fd -H &#039;^\.DS_Store$&#039; -tf -X rm -i
```

If you also want to remove a certain class of directories, you can use the same technique. You will
have to use `rm`s `--recursive`/`-r` flag to remove directories.

&gt; [!NOTE]
&gt; There are scenarios where using `fd … -X rm -r` can cause race conditions: if you have a
path like `…/foo/bar/foo/…` and want to remove all directories named `foo`, you can end up in a
situation where the outer `foo` directory is removed first, leading to (harmless) *&quot;&#039;foo/bar/foo&#039;:
No such file or directory&quot;* errors in the `rm` call.

### Command-line options

This is the output of `fd -h`. To see the full set of command-line options, use `fd --help` which
also includes a much more detailed help text.

```
Usage: fd [OPTIONS] [pattern] [path]...

Arguments:
  [pattern]  the search pattern (a regular expression, unless &#039;--glob&#039; is used; optional)
  [path]...  the root directories for the filesystem search (optional)

Options:
  -H, --hidden                     Search hidden files and directories
  -I, --no-ignore                  Do not respect .(git|fd)ignore files
  -s, --case-sensitive             Case-sensitive search (default: smart case)
  -i, --ignore-case                Case-insensitive search (default: smart case)
  -g, --glob                       Glob-based search (default: regular expression)
  -a, --absolute-path              Show absolute instead of relative paths
  -l, --list-details               Use a long listing format with file metadata
  -L, --follow                     Follow symbolic links
  -p, --full-path                  Search full abs. path (default: filename only)
  -d, --max-depth &lt;depth&gt;          Set maximum search depth (default: none)
  -E, --exclude &lt;pattern&gt;          Exclude entries that match the given glob pattern
  -t, --type &lt;filetype&gt;            Filter by type: file (f), directory (d/dir), symlink (l),
                                   executable (x), empty (e), socket (s), pipe (p), char-device
                                   (c), block-device (b)
  -e, --extension &lt;ext&gt;            Filter by file extension
  -S, --size &lt;size&gt;                Limit results based on the size of files
      --changed-within &lt;date|dur&gt;  Filter by file modification time (newer than)
      --changed-before &lt;date|dur&gt;  Filter by file modification time (older than)
  -o, --owner &lt;user:group&gt;         Filter by owning user and/or group
      --format &lt;fmt&gt;               Print results according to template
  -x, --exec &lt;cmd&gt;...              Execute a command for each search result
  -X, --exec-batch &lt;cmd&gt;...        Execute a command with all search results at once
  -c, --color &lt;when&gt;               When to use colors [default: auto] [possible values: auto,
                                   always, never]
      --hyperlink[=&lt;when&gt;]         Add hyperlinks to output paths [default: never] [possible
                                   values: auto, always, never]
  -h, --help                       Print help (see more with &#039;--help&#039;)
  -V, --version                    Print version
```

## Benchmark

Let&#039;s search my home folder for files that end in `[0-9].jpg`. It contains ~750.000
subdirectories and about a 4 million files. For averaging and statistical analysis, I&#039;m using
[hyperfine](https://github.com/sharkdp/hyperfine). The following benchmarks are performed
with a &quot;warm&quot;/pre-filled disk-cache (results for a &quot;cold&quot; disk-cache show the same trends).

Let&#039;s start with `find`:
```
Benchmark 1: find ~ -iregex &#039;.*[0-9]\.jpg$&#039;
  Time (mean ± σ):     19.922 s ±  0.109 s
  Range (min … max):   19.765 s … 20.065 s
```

`find` is much faster if it does not need to perform a regular-expression search:
```
Benchmark 2: find ~ -iname &#039;*[0-9].jpg&#039;
  Time (mean ± σ):     11.226 s ±  0.104 s
  Range (min … max):   11.119 s … 11.466 s
```

Now let&#039;s try the same for `fd`. Note that `fd` performs a regular expression
search by default. The options `-u`/`--unrestricted` option is needed here for
a fair comparison. Otherwise `fd` does not have to traverse hidden folders and
ignored paths (see below):
```
Benchmark 3: fd -u &#039;[0-9]\.jpg$&#039; ~
  Time (mean ± σ):     854.8 ms ±  10.0 ms
  Range (min … max):   839.2 ms … 868.9 ms
```
For this particular example, `fd` is approximately **23 times faster** than `find -iregex`
and about **13 times faster** than `find -iname`. By the way, both tools found the exact
same 546 files :smile:.

**Note**: This is *one particular* benchmark on *one particular* machine. While we have
performed a lot of different tests (and found consistent results), things might
be different for you! We encourage everyone to try it out on their own. See
[this repository](https://github.com/sharkdp/fd-benchmarks) for all necessary scripts.

Concerning *fd*&#039;s speed, a lot of credit goes to the `regex` and `ignore` crates that are
also used in [ripgrep](https://github.com/BurntSushi/ripgrep) (check it out!).

## Troubleshooting

### `fd` does not find my file!

Remember that `fd` ignores hidden directories and files by default. It also ignores patterns
from `.gitignore` files. If you want to make sure to find absolutely every possible file, always
use the options `-u`/`--unrestricted` option (or `-HI` to enable hidden and ignored files):
``` bash
&gt; fd -u …
```

Also remember that by default, `fd` only searches based on the filename and
doesn&#039;t compare the pattern to the full path. If you want to search based on the
full path (similar to the `-path` option of `find`) you need to use the `--full-path`
(or `-p`) option.

### Colorized output

`fd` can colorize files by extension, just like `ls`. In order for this to work, the environment
variable [`LS_COLORS`](https://linux.die.net/man/5/dir_colors) has to be set. Typically, the value
of this variable is set by the `dircolors` command which provides a convenient configuration format
to define colors for different file formats.
On most distributions, `LS_COLORS` should be set already. If you are on Windows or if you are looking
for alternative, more complete (or more colorful) variants, see [here](https://github.com/sharkdp/vivid),
[here](https://github.com/seebi/dircolors-solarized) or
[here](https://github.com/trapd00r/LS_COLORS).

`fd` also honors the [`NO_COLOR`](https://no-color.org/) environment variable.

### `fd` doesn&#039;t seem to interpret my regex pattern correctly

A lot of special regex characters (like `[]`, `^`, `$`, ..) are also special characters in your
shell. If in doubt, always make sure to put single quotes around the regex pattern:

``` bash
&gt; fd &#039;^[A-Z][0-9]+$&#039;
```

If your pattern starts with a dash, you have to add `--` to signal the end of command line
options. Otherwise, the pattern will be interpreted as a command-line option. Alternatively,
use a character class with a single hyphen character:

``` bash
&gt; fd -- &#039;-pattern&#039;
&gt; fd &#039;[-]pattern&#039;
```

### &quot;Command not found&quot; for `alias`es or shell functions

Shell `alias`es and shell functions can not be used for command execution via `fd -x` or
`fd -X`. In `zsh`, you can make the alias global via `alias -g myalias=&quot;…&quot;`. In `bash`,
you can use `export -f my_function` to make available to child processes. You would still
need to call `fd -x bash -c &#039;my_function &quot;$1&quot;&#039; bash`. For other use cases or shells, use
a (temporary) shell script.

## Integration with other programs

### Using fd with `fzf`

You can use *fd* to generate input for the command-line fuzzy finder [fzf](https://github.com/junegunn/fzf):
``` bash
export FZF_DEFAULT_COMMAND=&#039;fd --type file&#039;
export FZF_CTRL_T_COMMAND=&quot;$FZF_DEFAULT_COMMAND&quot;
```

Then, you can type `vim &lt;Ctrl-T&gt;` on your terminal to open fzf and search through the fd-results.

Alternatively, you might like to follow symbolic links and include hidden files (but exclude `.git` folders):
``` bash
export FZF_DEFAULT_COMMAND=&#039;fd --type file --follow --hidden --exclude .git&#039;
```

You can even use fd&#039;s colored output inside fzf by setting:
``` bash
export FZF_DEFAULT_COMMAND=&quot;fd --type file --color=always&quot;
export FZF_DEFAULT_OPTS=&quot;--ansi&quot;
```

For more details, see the [Tips section](https://github.com/junegunn/fzf#tips) of the fzf README.

### Using fd with `rofi`

[*rofi*](https://github.com/davatorium/rofi) is a graphical launch menu application that is able to create menus by reading from *stdin*. Piping `fd` output into `rofi`s `-dmenu` mode creates fuzzy-searchable lists of files and directories.

#### Example

Create a case-insensitive searchable multi-select list of *PDF* files under your `$HOME` directory and open the selection with your configured PDF viewer. To list all file types, drop the `-e pdf` argument.

``` bash
fd --type f -e pdf . $HOME | rofi -keep-right -dmenu -i -p FILES -multi-select | xargs -I {} xdg-open {}
```

To modify the list that is presented by rofi, add arguments to the `fd` command. To modify the search behaviour of rofi, add arguments to the `rofi` command.

### Using fd with `emacs`

The emacs package [find-file-in-project](https://github.com/technomancy/find-file-in-project) can
use *fd* to find files.

After installing `find-file-in-project`, add the line `(setq ffip-use-rust-fd t)` to your
`~/.emacs` or `~/.emacs.d/init.el` file.

In emacs, run `M-x find-file-in-project-by-selected` to find matching files. Alternatively, run
`M-x find-file-in-project` to list all available files in the project.

### Printing the output as a tree

To format the output of `fd` as a file-tree you can use the `tree` command with
`--fromfile`:
```bash
❯ fd | tree --fromfile
```

This can be more useful than running `tree` by itself because `tree` does not
ignore any files by default, nor does it support as rich a set of options as
`fd` does to control what to print:
```bash
❯ fd --extension rs | tree --fromfile
.
├── build.rs
└── src
    ├── app.rs
    └── error.rs
```

On bash and similar you can simply create an alias:
```bash
❯ alias as-tree=&#039;tree --fromfile&#039;
```

### Using fd with `xargs` or `parallel`

Note that `fd` has a builtin feature

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zellij-org/zellij]]></title>
            <link>https://github.com/zellij-org/zellij</link>
            <guid>https://github.com/zellij-org/zellij</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[A terminal workspace with batteries included]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zellij-org/zellij">zellij-org/zellij</a></h1>
            <p>A terminal workspace with batteries included</p>
            <p>Language: Rust</p>
            <p>Stars: 23,561</p>
            <p>Forks: 709</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;br&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/zellij-org/zellij/main/assets/logo.png&quot; alt=&quot;logo&quot; width=&quot;200&quot;&gt;
  &lt;br&gt;
  Zellij
  &lt;br&gt;
  &lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.gg/CrUAFH3&quot;&gt;&lt;img alt=&quot;Discord Chat&quot; src=&quot;https://img.shields.io/discord/771367133715628073?color=5865F2&amp;label=discord&amp;style=flat-square&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://matrix.to/#/#zellij_general:matrix.org&quot;&gt;&lt;img alt=&quot;Matrix Chat&quot; src=&quot;https://img.shields.io/matrix/zellij_general:matrix.org?color=1d7e64&amp;label=matrix%20chat&amp;style=flat-square&amp;logo=matrix&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://zellij.dev/documentation/&quot;&gt;&lt;img alt=&quot;Zellij documentation&quot; src=&quot;https://img.shields.io/badge/zellij-documentation-fc0060?style=flat-square&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/zellij-org/zellij/main/assets/demo.gif&quot; alt=&quot;demo&quot;&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  [&lt;a href=&quot;https://zellij.dev/documentation/installation&quot;&gt;Installation&lt;/a&gt;]
  [&lt;a href=&quot;https://zellij.dev/screencasts/&quot;&gt;Screencasts &amp; Tutorials&lt;/a&gt;]
  [&lt;a href=&quot;https://zellij.dev/documentation/configuration&quot;&gt;Configuration&lt;/a&gt;]
  [&lt;a href=&quot;https://zellij.dev/documentation/layouts&quot;&gt;Layouts&lt;/a&gt;]
  [&lt;a href=&quot;https://zellij.dev/documentation/faq&quot;&gt;FAQ&lt;/a&gt;]
&lt;/h4&gt;

# What is this?

[Zellij](#origin-of-the-name) is a workspace aimed at developers, ops-oriented people and anyone who loves the terminal. Similar programs are sometimes called &quot;Terminal Multiplexers&quot;.

Zellij is designed around the philosophy that one must not sacrifice simplicity for power, taking pride in its great experience out of the box as well as the advanced features it places at its users&#039; fingertips.

Zellij is geared toward beginner and power users alike - allowing deep customizability, personal automation through [layouts](https://zellij.dev/documentation/layouts.html), true multiplayer collaboration, unique UX features such as floating and stacked panes, and a [plugin system](https://zellij.dev/documentation/plugins.html) allowing one to create plugins in any language that compiles to WebAssembly.

You can get started by [installing](https://zellij.dev/documentation/installation.html) Zellij and checking out the [Screencasts &amp; Tutorials](https://zellij.dev/screencasts/).

For more details about our future plans, read about upcoming features in our [roadmap](#roadmap).

## How do I install it?

The easiest way to install Zellij is through a [package for your OS](./docs/THIRD_PARTY_INSTALL.md).

If one is not available for your OS, you could download a prebuilt binary from the [latest release](https://github.com/zellij-org/zellij/releases/latest) and place it in your `$PATH`. If you&#039;d like, we could [automatically choose one for you](#try-zellij-without-installing).

You can also install (compile) with `cargo`:

```
cargo install --locked zellij
```

#### Try Zellij without installing

bash/zsh:
```bash
bash &lt;(curl -L https://zellij.dev/launch)
```
fish/xonsh:
```bash
bash -c &#039;bash &lt;(curl -L https://zellij.dev/launch)&#039;
```

#### Installing from `main`
Installing Zellij from the `main` branch is not recommended. This branch represents pre-release code, is constantly being worked on and may contain broken or unusable features. In addition, using it may corrupt the cache for future versions, forcing users to clear it before they can use the officially released version.

That being said - no-one will stop you from using it (and bug reports involving new features are greatly appreciated), but please consider using the latest release instead as detailed at the top of this section.

## How do I start a development environment?

* Clone the project
* In the project folder, for debug builds run: `cargo xtask run`
* To run all tests: `cargo xtask test`

For more build commands, see [CONTRIBUTING.md](CONTRIBUTING.md).

## Configuration
For configuring Zellij, please see the [Configuration Documentation](https://zellij.dev/documentation/configuration.html).

## About issues in this repository
Issues in this repository, whether open or closed, do not necessarily indicate a problem or a bug in the software. They only indicate that the reporter wanted to communicate their experiences or thoughts to the maintainers. The Zellij maintainers do their best to go over and reply to all issue reports, but unfortunately cannot promise these will always be dealt with or even read. Your understanding is appreciated.

## Roadmap
Presented here is the project roadmap, divided into three main sections.

These are issues that are either being actively worked on or are planned for the near future.

***If you&#039;ll click on the image, you&#039;ll be led to an SVG version of it on the website where you can directly click on every issue***

[![roadmap](https://github.com/zellij-org/zellij/assets/795598/9c5b573b-20f5-41c6-908b-6b21c5fd456e)](https://zellij.dev/roadmap)

## Origin of the Name
[From Wikipedia, the free encyclopedia](https://en.wikipedia.org/wiki/Zellij)

Zellij (Arabic: الزليج, romanized: zillīj; also spelled zillij or zellige) is a style of mosaic tilework made from individually hand-chiseled tile pieces. The pieces were typically of different colours and fitted together to form various patterns on the basis of tessellations, most notably elaborate Islamic geometric motifs such as radiating star patterns composed of various polygons. This form of Islamic art is one of the main characteristics of architecture in the western Islamic world. It is found in the architecture of Morocco, the architecture of Algeria, early Islamic sites in Tunisia, and in the historic monuments of al-Andalus (in the Iberian Peninsula).

## License

MIT

## Sponsored by
&lt;a href=&quot;https://terminaltrove.com/&quot;&gt;&lt;img src=&quot;https://avatars.githubusercontent.com/u/121595180?s=200&amp;v=4&quot; width=&quot;80px&quot;&gt;&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[0xPlaygrounds/rig]]></title>
            <link>https://github.com/0xPlaygrounds/rig</link>
            <guid>https://github.com/0xPlaygrounds/rig</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[⚙️🦀 Build portable, modular & lightweight Fullstack Agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/0xPlaygrounds/rig">0xPlaygrounds/rig</a></h1>
            <p>⚙️🦀 Build portable, modular & lightweight Fullstack Agents</p>
            <p>Language: Rust</p>
            <p>Stars: 3,262</p>
            <p>Forks: 329</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
&lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;img/rig-playgrounds-dark.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;img/rig-playgrounds-light.svg&quot;&gt;
    &lt;img src=&quot;img/rig-playgrounds-light.svg&quot; style=&quot;width: 40%; height: 40%;&quot; alt=&quot;Rig logo&quot;&gt;
&lt;/picture&gt;
&lt;br&gt;
&lt;a href=&quot;https://docs.rig.rs&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/📖 docs-rig.rs-dca282.svg&quot; /&gt;&lt;/a&gt; &amp;nbsp;
&lt;a href=&quot;https://docs.rs/rig-core/latest/rig/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-API Reference-dca282.svg&quot; /&gt;&lt;/a&gt; &amp;nbsp;
&lt;a href=&quot;https://crates.io/crates/rig-core&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/v/rig-core.svg?color=dca282&quot; /&gt;&lt;/a&gt;
&amp;nbsp;
&lt;a href=&quot;https://crates.io/crates/rig-core&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/d/rig-core.svg?color=dca282&quot; /&gt;&lt;/a&gt;
&lt;/br&gt;
&lt;a href=&quot;https://discord.gg/playgrounds&quot;&gt;&lt;img src=&quot;https://img.shields.io/discord/511303648119226382?color=%236d82cc&amp;label=Discord&amp;logo=discord&amp;logoColor=white&quot; /&gt;&lt;/a&gt;
&amp;nbsp;
&lt;a href=&quot;https://github.com/0xPlaygrounds/rig&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/0xPlaygrounds/rig?style=social&quot; alt=&quot;stars - rig&quot; /&gt;&lt;/a&gt;
&lt;br&gt;
&lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/built_with-Rust-dca282.svg?logo=rust&quot; /&gt;&lt;/a&gt;
&amp;nbsp;
&lt;a href=&quot;https://twitter.com/Playgrounds0x&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/Playgrounds0x&quot;&gt;&lt;/a&gt; &amp;nbsp

&lt;br&gt;
&lt;/p&gt;
&amp;nbsp;


&lt;div align=&quot;center&quot;&gt;

[📑 Docs](https://docs.rig.rs)
&lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
[🌐 Website](https://rig.rs)
&lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
[🤝 Contribute](https://github.com/0xPlaygrounds/rig/issues/new)
&lt;span&gt;&amp;nbsp;&amp;nbsp;•&amp;nbsp;&amp;nbsp;&lt;/span&gt;
[✍🏽 Blogs](https://docs.rig.rs/guides)

&lt;/div&gt;

✨ If you would like to help spread the word about Rig, please consider starring the repo!

&gt; [!WARNING]
&gt; Here be dragons! As we plan to ship a torrent of features in the following months, future updates **will** contain **breaking changes**. With Rig evolving, we&#039;ll annotate changes and highlight migration paths as we encounter them.


## What is Rig?
Rig is a Rust library for building scalable, modular, and ergonomic **LLM-powered** applications.

More information about this crate can be found in the [official](https://docs.rig.rs) &amp; [crate](https://docs.rs/rig-core/latest/rig/) (API Reference) documentations.

Help us improve Rig by contributing to our [Feedback form](https://bit.ly/Rig-Feeback-Form).

## Table of contents

- [What is Rig?](#what-is-rig)
- [Table of contents](#table-of-contents)
- [High-level features](#high-level-features)
- [Get Started](#get-started)
  - [Simple example:](#simple-example)
- [Integrations](#integrations)

## High-level features
- Full support for LLM completion and embedding workflows
- Simple but powerful common abstractions over LLM providers (e.g. OpenAI, Cohere) and vector stores (e.g. MongoDB, SQlite, in-memory)
- Integrate LLMs in your app with minimal boilerplate



## Get Started
```bash
cargo add rig-core
```

### Simple example:
```rust
use rig::{completion::Prompt, providers::openai};

#[tokio::main]
async fn main() {
    // Create OpenAI client and model
    // This requires the `OPENAI_API_KEY` environment variable to be set.
    let openai_client = openai::Client::from_env();

    let gpt4 = openai_client.agent(&quot;gpt-4&quot;).build();

    // Prompt the model and print its response
    let response = gpt4
        .prompt(&quot;Who are you?&quot;)
        .await
        .expect(&quot;Failed to prompt GPT-4&quot;);

    println!(&quot;GPT-4: {response}&quot;);
}
```
Note using `#[tokio::main]` requires you enable tokio&#039;s `macros` and `rt-multi-thread` features
or just `full` to enable all features (`cargo add tokio --features macros,rt-multi-thread`).

You can find more examples each crate&#039;s `examples` (ie. [`rig-core/examples`](./rig-core/examples)) directory. More detailed use cases walkthroughs are regularly published on our [Dev.to Blog](https://dev.to/0thtachi) and added to Rig&#039;s official documentation [(docs.rig.rs)](http://docs.rig.rs).

## Supported Integrations

| Model Providers |                                                                                                                                                                                                                                                                                                               Vector Stores                                                                                                                                                                                                                                                                                                               |
|:--------------:|:-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| &lt;br&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/ChatGPT_logo.svg/1024px-ChatGPT_logo.svg.png&quot; alt=&quot;ChatGPT logo&quot; width=&quot;50em&quot;&gt; &lt;picture&gt;&lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://www.fahimai.com/wp-content/uploads/2024/06/Untitled-design-7.png&quot;&gt;&lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Claude_AI_logo.svg/1024px-Claude_AI_logo.svg.png&quot;&gt;&lt;img src=&quot;https://www.fahimai.com/wp-content/uploads/2024/06/Untitled-design-7.png&quot; alt=&quot;Claude Anthropic logo&quot; width=&quot;50em&quot;&gt;&lt;/picture&gt; &lt;br&gt; &lt;img src=&quot;https://cdn.sanity.io/images/rjtqmwfu/production/0adbf394439f4cd0ab8b5b3b6fe1da10c8099024-201x200.svg&quot; alt=&quot;Cohere logo&quot; width=&quot;50em&quot;&gt; &lt;img src=&quot;https://logospng.org/download/google-gemini/google-gemini-1024.png&quot; style=&quot;background-color: white; border-radius: 10px; padding: 5px 5px ; width: 3em;&quot; alt=&quot;Gemini logo&quot;&gt; &lt;br&gt; &lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/5/57/XAI-Logo.svg/512px-XAI-Logo.svg.png?20240912222841&quot; style=&quot;background-color: white; border-radius: 10px; padding: 5px 5px ; width: 3em;&quot; alt=&quot;xAI logo&quot;&gt; &lt;img src=&quot;https://github.com/user-attachments/assets/4763ae96-ddc9-4f69-ab38-23592e6c4ead&quot; style=&quot;background-color: white; border-radius: 10px; padding: 5px 0px ; width: 4em;&quot; alt=&quot;perplexity logo&quot;&gt;| &lt;br&gt;&lt;img src=&quot;https://cdn.prod.website-files.com/6640cd28f51f13175e577c05/664e00a400e23f104ed2b6cd_3b3dd6e8-8a73-5879-84a9-a42d5b910c74.svg&quot; alt=&quot;Mongo DB logo&quot; width=&quot;50em&quot;&gt; &lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/e/e5/Neo4j-logo_color.png&quot; alt=&quot;Neo4j logo&quot; style=&quot;background-color: white; border-radius: 1em; padding: 1em 1em ; width: 4em;&quot;&gt;&lt;br&gt;&lt;br&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/844/1*Jp6VwF0OcdeyRyW0Ln0RMQ@2x.png&quot; width=&quot;100em&quot; alt=&quot;Lance DB logo&quot;&gt; &lt;br&gt; &lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/SQLite370.svg/440px-SQLite370.svg.png&quot; style=&quot;width: 6em&quot;&gt; |


Vector stores are available as separate companion-crates:
- MongoDB vector store: [`rig-mongodb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-mongodb)
- LanceDB vector store: [`rig-lancedb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-lancedb)
- Neo4j vector store: [`rig-neo4j`](https://github.com/0xPlaygrounds/rig/tree/main/rig-neo4j)
- Qdrant vector store: [`rig-qdrant`](https://github.com/0xPlaygrounds/rig/tree/main/rig-qdrant)
- SQLite vector store: [`rig-sqlite`](https://github.com/0xPlaygrounds/rig/tree/main/rig-sqlite)
- SurrealDB vector store: [`rig-surrealdb`](https://github.com/0xPlaygrounds/rig/tree/main/rig-surrealdb)

The following providers are available as separate companion-crates:
- Fastembed: [`rig-fastembed`](https://github.com/0xPlaygrounds/rig/tree/main/rig-fastembed)


&lt;p align=&quot;center&quot;&gt;
&lt;br&gt;
&lt;br&gt;
&lt;img src=&quot;img/built-by-playgrounds.svg&quot; alt=&quot;Build by Playgrounds&quot; width=&quot;30%&quot;&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[Rust-GPU/Rust-CUDA]]></title>
            <link>https://github.com/Rust-GPU/Rust-CUDA</link>
            <guid>https://github.com/Rust-GPU/Rust-CUDA</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[Ecosystem of libraries and tools for writing and executing fast GPU code fully in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Rust-GPU/Rust-CUDA">Rust-GPU/Rust-CUDA</a></h1>
            <p>Ecosystem of libraries and tools for writing and executing fast GPU code fully in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,833</p>
            <p>Forks: 157</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;h1&gt;The Rust CUDA Project&lt;/h1&gt;

  &lt;p&gt;
    &lt;strong&gt;An ecosystem of libraries and tools for writing and executing extremely fast GPU code fully in 
    &lt;a href=&quot;https://www.rust-lang.org/&quot;&gt;Rust&lt;/a&gt;&lt;/strong&gt;
  &lt;/p&gt;

  &lt;h3&gt;
    &lt;a href=&quot;https://rust-gpu.github.io/Rust-CUDA/guide/index.html&quot;&gt;Guide&lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;guide/src/guide/getting_started.md&quot;&gt;Getting Started&lt;/a&gt;
    &lt;span&gt; | &lt;/span&gt;
    &lt;a href=&quot;guide/src/features.md&quot;&gt;Features&lt;/a&gt;
  &lt;/h3&gt;
&lt;strong&gt;⚠️ The project is still in early development, expect bugs, safety issues, and things that don&#039;t work ⚠️&lt;/strong&gt; 
&lt;/div&gt;

&lt;br/&gt;

&gt; [!IMPORTANT]
&gt; This project is no longer dormant and is [being
&gt; rebooted](https://rust-gpu.github.io/blog/2025/01/27/rust-cuda-reboot).
&gt; Please contribute!

## Goal

The Rust CUDA Project is a project aimed at making Rust a tier-1 language for extremely fast GPU computing
using the CUDA Toolkit. It provides tools for compiling Rust to extremely fast PTX code as well as libraries
for using existing CUDA libraries with it.

## Background

Historically, general purpose high performance GPU computing has been done using the CUDA toolkit. The CUDA toolkit primarily
provides a way to use Fortran/C/C++ code for GPU computing in tandem with CPU code with a single source. It also provides
many libraries, tools, forums, and documentation to supplement the single-source CPU/GPU code.

CUDA is exclusively an NVIDIA-only toolkit. Many tools have been proposed for cross-platform GPU computing such as
OpenCL, Vulkan Computing, and HIP. However, CUDA remains the most used toolkit for such tasks by far. This is why it is
imperative to make Rust a viable option for use with the CUDA toolkit.

However, CUDA with Rust has been a historically very rocky road. The only viable option until now has been to use the LLVM PTX
backend, however, the LLVM PTX backend does not always work and would generate invalid PTX for many common Rust operations, and
in recent years it has been shown time and time again that a specialized solution is needed for Rust on the GPU with the advent
of projects such as rust-gpu (for Rust -&gt; SPIR-V).

Our hope is that with this project we can push the Rust GPU computing industry forward and make Rust an excellent language
for such tasks. Rust offers plenty of benefits such as `__restrict__` performance benefits for every kernel, An excellent module/crate system,
delimiting of unsafe areas of CPU/GPU code with `unsafe`, high level wrappers to low level CUDA libraries, etc.

## Structure

The scope of the Rust CUDA Project is quite broad, it spans the entirety of the CUDA ecosystem, with libraries and tools to make it
usable using Rust. Therefore, the project contains many crates for all corners of the CUDA ecosystem.

The current line-up of libraries is the following:

- `rustc_codegen_nvvm` Which is a rustc backend that targets NVVM IR (a subset of LLVM IR) for the [libnvvm](https://docs.nvidia.com/cuda/nvvm-ir-spec/index.html) library.
  - Generates highly optimized PTX code which can be loaded by the CUDA Driver API to execute on the GPU.
  - For the near future it will be CUDA-only, but it may be used to target amdgpu in the future.
- `cuda_std` for GPU-side functions and utilities, such as thread index queries, memory allocation, warp intrinsics, etc.
  - _Not_ a low level library, provides many utility functions to make it easier to write cleaner and more reliable GPU kernels.
  - Closely tied to `rustc_codegen_nvvm` which exposes GPU features through it internally.
- [`cudnn`](https://github.com/Rust-GPU/Rust-CUDA/tree/master/crates/cudnn) for a collection of GPU-accelerated primitives for deep neural networks.
- `cust` for CPU-side CUDA features such as launching GPU kernels, GPU memory allocation, device queries, etc.
  - High level with features such as RAII and Rust Results that make it easier and cleaner to manage the interface to the GPU.
  - A high level wrapper for the CUDA Driver API, the lower level version of the more common CUDA Runtime API used from C++.
  - Provides much more fine grained control over things like kernel concurrency and module loading than the C++ Runtime API.
- `gpu_rand` for GPU-friendly random number generation, currently only implements xoroshiro RNGs from `rand_xoshiro`.
- `optix` for CPU-side hardware raytracing and denoising using the CUDA OptiX library.

In addition to many &quot;glue&quot; crates for things such as high level wrappers for certain smaller CUDA libraries.

## Related Projects

Other projects related to using Rust on the GPU:

- 2016: [glassful](https://github.com/kmcallister/glassful) Subset of Rust that compiles to GLSL.
- 2017: [inspirv-rust](https://github.com/msiglreith/inspirv-rust) Experimental Rust MIR -&gt; SPIR-V Compiler.
- 2018: [nvptx](https://github.com/japaric-archived/nvptx) Rust to PTX compiler using the `nvptx` target for rustc (using the LLVM PTX backend).
- 2020: [accel](https://github.com/termoshtt/accel) Higher-level library that relied on the same mechanism that `nvptx` does.
- 2020: [rlsl](https://github.com/MaikKlein/rlsl) Experimental Rust -&gt; SPIR-V compiler (predecessor to rust-gpu)
- 2020: [rust-gpu](https://github.com/Rust-GPU/rust-gpu) `rustc` compiler backend to compile Rust to SPIR-V for use in shaders, similar mechanism as our project.

## Usage
```bash
## setup your environment like:
### export OPTIX_ROOT=/opt/NVIDIA-OptiX-SDK-9.0.0-linux64-x86_64
### export OPTIX_ROOT_DIR=/opt/NVIDIA-OptiX-SDK-9.0.0-linux64-x86_64

## build proj
cargo build
```

## License

Licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your discretion.

### Contribution

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[juspay/hyperswitch]]></title>
            <link>https://github.com/juspay/hyperswitch</link>
            <guid>https://github.com/juspay/hyperswitch</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[An open source payments switch written in Rust to make payments fast, reliable and affordable]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/juspay/hyperswitch">juspay/hyperswitch</a></h1>
            <p>An open source payments switch written in Rust to make payments fast, reliable and affordable</p>
            <p>Language: Rust</p>
            <p>Stars: 14,041</p>
            <p>Forks: 1,463</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/imgs/hyperswitch-logo-dark.svg#gh-dark-mode-only&quot; alt=&quot;Hyperswitch-Logo&quot; width=&quot;40%&quot; /&gt;
  &lt;img src=&quot;./docs/imgs/hyperswitch-logo-light.svg#gh-light-mode-only&quot; alt=&quot;Hyperswitch-Logo&quot; width=&quot;40%&quot; /&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Open-Source Payments Orchestration&lt;/h1&gt;

&lt;div align=&quot;center&quot; &gt;
Single API to access the payments ecosystem and its features
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/actions?query=workflow%3ACI+branch%3Amain&quot;&gt;
    &lt;img src=&quot;https://github.com/juspay/hyperswitch/workflows/CI-push/badge.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/license/juspay/hyperswitch&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/juspay/hyperswitch/blob/main/LICENSE&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Made_in-Rust-orange&quot; /&gt;
  &lt;/a&gt;
  &lt;!-- Uncomment when we reach &gt;50% coverage --&gt;
  &lt;!-- &lt;a href=&quot;https://codecov.io/github/juspay/hyperswitch&quot; &gt;
    &lt;img src=&quot;https://codecov.io/github/juspay/hyperswitch/graph/badge.svg&quot;/&gt;
  &lt;/a&gt; --&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.linkedin.com/company/hyperswitch/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-hyperswitch-blue?logo=linkedin&amp;labelColor=grey&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://x.com/hyperswitchio&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/follow-%40hyperswitchio-white?logo=x&amp;labelColor=grey&quot;/&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://join.slack.com/t/hyperswitch-io/shared_invite/zt-2jqxmpsbm-WXUENx022HjNEy~Ark7Orw&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/chat-on_slack-blue?logo=slack&amp;labelColor=grey&amp;color=%233f0e40&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;hr&gt;

## Table of Contents

1. [Introduction](#introduction)
2. [Architectural Overview](#architectural-overview) 
3. [Try Hyperswitch](#try-hyperswitch)  
4. [Support, Feature requests &amp; Bugs](#support-feature-requests)  
5. [Our Vision](#our-vision)  
6. [Versioning](#versioning)  
7. [Copyright and License](#copyright-and-license)

&lt;a href=&quot;#introduction&quot;&gt;
  &lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;
&lt;/a&gt;
Juspay, founded in 2012, is a global leader in payment orchestration and checkout solutions, trusted by 400+ leading enterprises and brands worldwide. Hyperswitch is Juspay&#039;s new generation of composable, commercial open-source payments platform for merchant and brands. It is an enterprise-grade, transparent and modular payments platform designed to provide digital businesses access to the best payments infrastructure.

Here are the key components of Hyperswitch that deliver the whole solution:

* [Hyperswitch Backend](https://github.com/juspay/hyperswitch): Hyperswitch backend enables seamless payment processing with comprehensive support for various payment flows - authorization, authentication, void and capture workflows along with robust management of post-payment processes like refunds and chargeback handling. Additionally, Hyperswitch supports non-payment use cases by enabling connections with external FRM or authentication providers as part of the payment flow. The backend optimizes payment routing with customizable workflows, including success rate-based routing, rule-based routing, volume distribution, fallback handling, and intelligent retry mechanisms for failed payments based on specific error codes.

* [SDK (Frontend)](https://github.com/juspay/hyperswitch-web): The SDK, available for web, [Android, and iOS](https://github.com/juspay/hyperswitch-client-core), unifies the payment experience across various methods such as cards, wallets, BNPL, bank transfers, and more, while supporting the diverse payment flows of underlying PSPs. When paired with the locker, it surfaces the user&#039;s saved payment methods.    

* [Control Center](https://github.com/juspay/hyperswitch-control-center): The Control Center enables users to manage the entire payments stack without any coding. It allows the creation of workflows for routing, payment retries, and defining conditions to invoke 3DS, fraud risk management (FRM), and surcharge modules. The Control Center provides access to transaction, refund, and chargeback operations across all integrated PSPs, transaction-level logs for initial debugging, and detailed analytics and insights into payment performance.

Read more at [Hyperswitch docs](https://docs.hyperswitch.io/).

&lt;a href=&quot;#architectural-overview&quot;&gt;
  &lt;h2 id=&quot;architectural-overview&quot;&gt;Architectural Overview&lt;/h2&gt;
&lt;/a&gt;
&lt;img src=&quot;./docs/imgs/features.png&quot; /&gt;
&lt;img src=&quot;./docs/imgs/non-functional-features.png&quot; /&gt;

&lt;img src=&quot;./docs/imgs/hyperswitch-architecture-v1.png&quot; /&gt;

&lt;a href=&quot;#try-hyperswitch&quot;&gt;
  &lt;h2 id=&quot;try-hyperswitch&quot;&gt;Try Hyperswitch&lt;/h2&gt;
&lt;/a&gt;

### 1. Local Setup

You can run Hyperswitch on your system using Docker compose after cloning this repository. 

```shell
git clone --depth 1 --branch latest https://github.com/juspay/hyperswitch
cd hyperswitch
docker compose up -d
```

Check out the [local setup guide][local-setup-guide] for a more details on setting up the entire stack or component wise. This takes 15-mins and gives the following output 
```shell
[+] Running 2/2
✔ hyperswitch-control-center Pulled 2.9s
✔ hyperswitch-server Pulled 3.0s
[+] Running 6/0

✔ Container hyperswitch-pg-1 Created 0.0s
✔ Container hyperswitch-redis-standalone-1 Created 0.0s
✔ Container hyperswitch-migration_runner-1 Created 0.0s
✔ Container hyperswitch-hyperswitch-server-1 Created 0.0s
✔ Container hyperswitch-hyperswitch-web-1 Created 0.0s
✔ Container hyperswitch-hyperswitch-control-center-1 Created 0.0s

Attaching to hyperswitch-control-center-1, hyperswitch-server-1, hyperswitch-web-1, migration_runner-1, pg-1, redis-standalone-1
```

### 2. Deployment on cloud

The fastest and easiest way to try Hyperswitch on AWS is via our CDK scripts

1. Click on the following button for a quick standalone deployment on AWS, suitable for prototyping.
   No code or setup is required in your system and the deployment is covered within the AWS free-tier setup.

   &lt;a href=&quot;https://console.aws.amazon.com/cloudformation/home?region=us-east-1#/stacks/new?stackName=HyperswitchBootstarp&amp;templateURL=https://hyperswitch-synth.s3.eu-central-1.amazonaws.com/hs-starter-config.yaml&quot;&gt;&lt;img src=&quot;https://github.com/juspay/hyperswitch/blob/main/docs/imgs/aws_button.png?raw=true&quot; height=&quot;35&quot;&gt;&lt;/a&gt;

2. Sign-in to your AWS console.

3. Follow the instructions provided on the console to successfully deploy Hyperswitch. This takes 30-45mins and gives the following output 

| Service| Host|
|----------------------------------------------|----------------------------------------------|
| App server running on                        | `http://hyperswitch-&lt;host-id.region&gt;.elb.amazonaws.com` |
| HyperloaderJS Hosted at                      | `http://&lt;cloudfront.host-id&gt;/0.103.1/v0/HyperLoader.js` |
| Control center server running on             | `http://hyperswitch-control-center-&lt;host-id.region&gt;.elb.amazonaws.com`, Login with Email: `test@gmail.com` |
| Hyperswitch Demo Store running on            | `http://hyperswitch-sdk-demo-&lt;host-id.region&gt;.elb.amazonaws.com` |
| Logs server running on                       | `http://hyperswitch-logs-&lt;host-id.region&gt;.elb.amazonaws.com`, Login with username: `admin`, password: `admin` |

We support deployment on GCP and Azure via Helm charts which takes 30-45mins. You can read more at [Hyperswitch docs](https://docs.hyperswitch.io/hyperswitch-open-source/deploy-on-kubernetes-using-helm). 

### 3. Hosted Sandbox

You can experience the product by signing up for our [hosted sandbox](https://app.hyperswitch.io/). The signup process accepts any email ID and provides access to the entire Control Center. You can set up connectors, define workflows for routing and retries, and even try payments from the dashboard.

[docs-link-for-enterprise]: https://docs.hyperswitch.io/hyperswitch-cloud/quickstart
[docs-link-for-developers]: https://docs.hyperswitch.io/hyperswitch-open-source/overview
[contributing-guidelines]: docs/CONTRIBUTING.md
[dashboard-link]: https://app.hyperswitch.io/
[website-link]: https://hyperswitch.io/
[learning-resources]: https://docs.hyperswitch.io/learn-more/payment-flows
[local-setup-guide]: /docs/try_local_system.md
[docker-compose-scheduler-monitoring]: /docs/try_local_system.md#running-additional-services


&lt;a href=&quot;support-feature-requests&quot;&gt;
  &lt;h2 id=&quot;support-feature-requests&quot;&gt;Support, Feature requests &amp; Bugs&lt;/h2&gt;
&lt;/a&gt;

For any support, join the conversation in [Slack](https://join.slack.com/t/hyperswitch-io/shared_invite/zt-2jqxmpsbm-WXUENx022HjNEy~Ark7Orw)

For new product features, enhancements, roadmap discussions, or to share queries and ideas, visit our [GitHub Discussions](https://github.com/juspay/hyperswitch/discussions)

For reporting a bug, please read the issue guidelines and search for [existing and closed issues]. If your problem or idea is not addressed yet, please [open a new issue].

[existing and closed issues]: https://github.com/juspay/hyperswitch/issues
[open a new issue]: https://github.com/juspay/hyperswitch/issues/new/choose

&lt;a href=&quot;our-vision&quot;&gt;
  &lt;h2 id=&quot;our-vision&quot;&gt;Our Vision&lt;/h2&gt;
&lt;/a&gt;

&gt; Linux for Payments

Payments are evolving rapidly worldwide, with hundreds of processors, fraud detection systems, authentication modules, and new payment methods and flows emerging. Businesses building or managing their own payment stacks often face similar challenges, struggle with comparable issues, and find it hard to innovate at the desired pace.

Hyperswitch serves as a well-architected designed reference platform, built on best-in-class design principles, empowering businesses to own and customize their payment stack. It provides a reusable core payments stack that can be tailored to specific requirements while relying on the Hyperswitch team for enhancements, support, and continuous innovation.

### Our Values

1. Embrace Payments Diversity: It will drive innovation in the ecosystem in
   multiple ways.
2. Make it Open Source: Increases trust; Improves the quality and reusability of
   software.
3. Be community driven: It enables participatory design and development.
4. Build it like Systems Software: This sets a high bar for Reliability,
   Security and Performance SLAs.
5. Maximise Value Creation: For developers, customers &amp; partners.

This project is being created and maintained by [Juspay](https://juspay.io)

&lt;a href=&quot;#versioning&quot;&gt;
  &lt;h2 id=&quot;versioning&quot;&gt;Versioning&lt;/h2&gt;
&lt;/a&gt;

Check the [CHANGELOG.md](./CHANGELOG.md) file for details.

&lt;a href=&quot;#copyright-and-license&quot;&gt;
  &lt;h2 id=&quot;copyright-and-license&quot;&gt;Copyright and License&lt;/h2&gt;
&lt;/a&gt;

This product is licensed under the [Apache 2.0 License](LICENSE).


&lt;a href=&quot;team-behind-hyperswitch&quot;&gt;
  &lt;h2 id=&quot;team-behind-hyperswitch&quot;&gt;Team behind Hyperswitch&lt;/h2&gt;
&lt;/a&gt;

The core team of 150+ engineers building Hyperswitch. Keep up the great work! 🥂

&lt;a href=&quot;https://github.com/juspay/hyperswitch/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=juspay/hyperswitch&quot; alt=&quot;Contributors&quot;/&gt;
&lt;/a&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[sharkdp/bat]]></title>
            <link>https://github.com/sharkdp/bat</link>
            <guid>https://github.com/sharkdp/bat</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[A cat(1) clone with wings.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sharkdp/bat">sharkdp/bat</a></h1>
            <p>A cat(1) clone with wings.</p>
            <p>Language: Rust</p>
            <p>Stars: 51,786</p>
            <p>Forks: 1,284</p>
            <p>Stars today: 100 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;doc/logo-header.svg&quot; alt=&quot;bat - a cat clone with wings&quot;&gt;&lt;br&gt;
  &lt;a href=&quot;https://github.com/sharkdp/bat/actions?query=workflow%3ACICD&quot;&gt;&lt;img src=&quot;https://github.com/sharkdp/bat/workflows/CICD/badge.svg&quot; alt=&quot;Build Status&quot;&gt;&lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/crates/l/bat.svg&quot; alt=&quot;license&quot;&gt;
  &lt;a href=&quot;https://crates.io/crates/bat&quot;&gt;&lt;img src=&quot;https://img.shields.io/crates/v/bat.svg?colorB=319e8c&quot; alt=&quot;Version info&quot;&gt;&lt;/a&gt;&lt;br&gt;
  A &lt;i&gt;cat(1)&lt;/i&gt; clone with syntax highlighting and Git integration.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#syntax-highlighting&quot;&gt;Key Features&lt;/a&gt; •
  &lt;a href=&quot;#how-to-use&quot;&gt;How To Use&lt;/a&gt; •
  &lt;a href=&quot;#installation&quot;&gt;Installation&lt;/a&gt; •
  &lt;a href=&quot;#customization&quot;&gt;Customization&lt;/a&gt; •
  &lt;a href=&quot;#project-goals-and-alternatives&quot;&gt;Project goals, alternatives&lt;/a&gt;&lt;br&gt;
  [English]
  [&lt;a href=&quot;doc/README-zh.md&quot;&gt;中文&lt;/a&gt;]
  [&lt;a href=&quot;doc/README-ja.md&quot;&gt;日本語&lt;/a&gt;]
  [&lt;a href=&quot;doc/README-ko.md&quot;&gt;한국어&lt;/a&gt;]
  [&lt;a href=&quot;doc/README-ru.md&quot;&gt;Русский&lt;/a&gt;]
&lt;/p&gt;

### Sponsors

A special *thank you* goes to our biggest &lt;a href=&quot;doc/sponsors.md&quot;&gt;sponsor&lt;/a&gt;:&lt;br&gt;

&lt;a href=&quot;https://www.warp.dev/bat&quot;&gt;
  &lt;img src=&quot;doc/sponsors/warp-logo.png&quot; width=&quot;200&quot; alt=&quot;Warp&quot;&gt;
  &lt;br&gt;
  &lt;strong&gt;Warp, the intelligent terminal&lt;/strong&gt;
  &lt;br&gt;
  &lt;sub&gt;Available on MacOS, Linux, Windows&lt;/sub&gt;
&lt;/a&gt;

### Syntax highlighting

`bat` supports syntax highlighting for a large number of programming and markup
languages:

![Syntax highlighting example](https://imgur.com/rGsdnDe.png)

### Git integration

`bat` communicates with `git` to show modifications with respect to the index
(see left side bar):

![Git integration example](https://i.imgur.com/2lSW4RE.png)

### Show non-printable characters

You can use the `-A`/`--show-all` option to show and highlight non-printable
characters:

![Non-printable character example](https://i.imgur.com/WndGp9H.png)

### Automatic paging

By default, `bat` pipes its own output to a pager (e.g. `less`) if the output is too large for one screen.
If you would rather `bat` work like `cat` all the time (never page output), you can set `--paging=never` as an option, either on the command line or in your configuration file.
If you intend to alias `cat` to `bat` in your shell configuration, you can use `alias cat=&#039;bat --paging=never&#039;` to preserve the default behavior.

#### File concatenation

Even with a pager set, you can still use `bat` to concatenate files :wink:.
Whenever `bat` detects a non-interactive terminal (i.e. when you pipe into another process or into a file), `bat` will act as a drop-in replacement for `cat` and fall back to printing the plain file contents, regardless of the `--pager` option&#039;s value.

## How to use

Display a single file on the terminal

```bash
&gt; bat README.md
```

Display multiple files at once

```bash
&gt; bat src/*.rs
```

Read from stdin, determine the syntax automatically (note, highlighting will
only work if the syntax can be determined from the first line of the file,
usually through a shebang such as `#!/bin/sh`)

```bash
&gt; curl -s https://sh.rustup.rs | bat
```

Read from stdin, specify the language explicitly

```bash
&gt; yaml2json .travis.yml | json_pp | bat -l json
```

Show and highlight non-printable characters:
```bash
&gt; bat -A /etc/hosts
```

Use it as a `cat` replacement:

```bash
bat &gt; note.md  # quickly create a new file

bat header.md content.md footer.md &gt; document.md

bat -n main.rs  # show line numbers (only)

bat f - g  # output &#039;f&#039;, then stdin, then &#039;g&#039;.
```

### Integration with other tools

#### `fzf`

You can use `bat` as a previewer for [`fzf`](https://github.com/junegunn/fzf). To do this,
use `bat`s `--color=always` option to force colorized output. You can also use `--line-range`
option to restrict the load times for long files:

```bash
fzf --preview &quot;bat --color=always --style=numbers --line-range=:500 {}&quot;
```

For more information, see [`fzf`&#039;s `README`](https://github.com/junegunn/fzf#preview-window).

#### `find` or `fd`

You can use the `-exec` option of `find` to preview all search results with `bat`:

```bash
find … -exec bat {} +
```

If you happen to use [`fd`](https://github.com/sharkdp/fd), you can use the `-X`/`--exec-batch` option to do the same:

```bash
fd … -X bat
```

#### `ripgrep`

With [`batgrep`](https://github.com/eth-p/bat-extras/blob/master/doc/batgrep.md), `bat` can be used as the printer for [`ripgrep`](https://github.com/BurntSushi/ripgrep) search results.

```bash
batgrep needle src/
```

#### `tail -f`

`bat` can be combined with `tail -f` to continuously monitor a given file with syntax highlighting.

```bash
tail -f /var/log/pacman.log | bat --paging=never -l log
```

Note that we have to switch off paging in order for this to work. We have also specified the syntax
explicitly (`-l log`), as it can not be auto-detected in this case.

#### `git`

You can combine `bat` with `git show` to view an older version of a given file with proper syntax
highlighting:

```bash
git show v0.6.0:src/main.rs | bat -l rs
```

#### `git diff`

You can combine `bat` with `git diff` to view lines around code changes with proper syntax
highlighting:
```bash
batdiff() {
    git diff --name-only --relative --diff-filter=d | xargs bat --diff
}
```
If you prefer to use this as a separate tool, check out `batdiff` in [`bat-extras`](https://github.com/eth-p/bat-extras).

If you are looking for more support for git and diff operations, check out [`delta`](https://github.com/dandavison/delta).

#### `xclip`

The line numbers and Git modification markers in the output of `bat` can make it hard to copy
the contents of a file. To prevent this, you can call `bat` with the `-p`/`--plain` option or
simply pipe the output into `xclip`:
```bash
bat main.cpp | xclip
```
`bat` will detect that the output is being redirected and print the plain file contents.

#### `man`

`bat` can be used as a colorizing pager for `man`, by setting the
`MANPAGER` environment variable:

```bash
export MANPAGER=&quot;sh -c &#039;sed -u -e \&quot;s/\\x1B\[[0-9;]*m//g; s/.\\x08//g\&quot; | bat -p -lman&#039;&quot;
man 2 select
```
(replace `bat` with `batcat` if you are on Debian or Ubuntu)

If you prefer to have this bundled in a new command, you can also use [`batman`](https://github.com/eth-p/bat-extras/blob/master/doc/batman.md).

&gt; [!WARNING]  
&gt; This will [not work](https://github.com/sharkdp/bat/issues/1145) out of the box with Mandoc&#039;s `man` implementation.
&gt;
&gt; Please either use `batman`, or convert the shell script to a [shebang executable](https://en.wikipedia.org/wiki/Shebang_(Unix)) and point `MANPAGER` to that.

Note that the [Manpage syntax](assets/syntaxes/02_Extra/Manpage.sublime-syntax) is developed in this repository and still needs some work.

#### `prettier` / `shfmt` / `rustfmt`

The [`prettybat`](https://github.com/eth-p/bat-extras/blob/master/doc/prettybat.md) script is a wrapper that will format code and print it with `bat`.

#### `Warp`

&lt;a href=&quot;https://app.warp.dev/drive/folder/-Bat-Warp-Pack-lxhe7HrEwgwpG17mvrFSz1&quot;&gt;
  &lt;img src=&quot;doc/sponsors/warp-pack-header.png&quot; alt=&quot;Warp&quot;&gt;
&lt;/a&gt;

#### Highlighting `--help` messages

You can use `bat` to colorize help text: `$ cp --help | bat -plhelp`

You can also use a wrapper around this:

```bash
# in your .bashrc/.zshrc/*rc
alias bathelp=&#039;bat --plain --language=help&#039;
help() {
    &quot;$@&quot; --help 2&gt;&amp;1 | bathelp
}
```

Then you can do `$ help cp` or `$ help git commit`.

When you are using `zsh`, you can also use global aliases to override `-h` and `--help` entirely:

```bash
alias -g -- -h=&#039;-h 2&gt;&amp;1 | bat --language=help --style=plain&#039;
alias -g -- --help=&#039;--help 2&gt;&amp;1 | bat --language=help --style=plain&#039;
```

This way, you can keep on using `cp --help`, but get colorized help pages.

Be aware that in some cases, `-h` may not be a shorthand of `--help` (for example with `ls`).

Please report any issues with the help syntax in [this repository](https://github.com/victor-gp/cmd-help-sublime-syntax).


## Installation

[![Packaging status](https://repology.org/badge/vertical-allrepos/bat-cat.svg?columns=3&amp;exclude_unsupported=1)](https://repology.org/project/bat-cat/versions)

### On Ubuntu (using `apt`)
*... and other Debian-based Linux distributions.*

`bat` is available on [Ubuntu since 20.04 (&quot;Focal&quot;)](https://packages.ubuntu.com/search?keywords=bat&amp;exact=1) and [Debian since August 2021 (Debian 11 - &quot;Bullseye&quot;)](https://packages.debian.org/bullseye/bat).

If your Ubuntu/Debian installation is new enough you can simply run:

```bash
sudo apt install bat
```

**Important**: If you install `bat` this way, please note that the executable may be installed as `batcat` instead of `bat` (due to [a name
clash with another package](https://github.com/sharkdp/bat/issues/982)). You can set up a `bat -&gt; batcat` symlink or alias to prevent any issues that may come up because of this and to be consistent with other distributions:
``` bash
mkdir -p ~/.local/bin
ln -s /usr/bin/batcat ~/.local/bin/bat
```

### On Ubuntu (using most recent `.deb` packages)
*... and other Debian-based Linux distributions.*

If the package has not yet been promoted to your Ubuntu/Debian installation, or you want
the most recent release of `bat`, download the latest `.deb` package from the
[release page](https://github.com/sharkdp/bat/releases) and install it via:

```bash
sudo dpkg -i bat_0.18.3_amd64.deb  # adapt version number and architecture
```

### On Alpine Linux

You can install [the `bat` package](https://pkgs.alpinelinux.org/packages?name=bat)
from the official sources, provided you have the appropriate repository enabled:

```bash
apk add bat
```

### On Arch Linux

You can install [the `bat` package](https://www.archlinux.org/packages/extra/x86_64/bat/)
from the official sources:

```bash
pacman -S bat
```

### On Fedora

You can install [the `bat` package](https://koji.fedoraproject.org/koji/packageinfo?packageID=27506) from the official [Fedora Modular](https://docs.fedoraproject.org/en-US/modularity/using-modules/) repository.

```bash
dnf install bat
```

### On Funtoo Linux

You can install [the `bat` package](https://github.com/funtoo/dev-kit/tree/1.4-release/sys-apps/bat) from dev-kit.

```bash
emerge sys-apps/bat
```

### On Gentoo Linux

You can install [the `bat` package](https://packages.gentoo.org/packages/sys-apps/bat)
from the official sources:

```bash
emerge sys-apps/bat
```

### On Void Linux

You can install `bat` via xbps-install:
```bash
xbps-install -S bat
```

### On Termux

You can install `bat` via pkg:
```bash
pkg install bat
```

### On FreeBSD

You can install a precompiled [`bat` package](https://www.freshports.org/textproc/bat) with pkg:

```bash
pkg install bat
```

or build it on your own from the FreeBSD ports:

```bash
cd /usr/ports/textproc/bat
make install
```

### On OpenBSD

You can install `bat` package using [`pkg_add(1)`](https://man.openbsd.org/pkg_add.1):

```bash
pkg_add bat
```

### Via nix

You can install `bat` using the [nix package manager](https://nixos.org/nix):

```bash
nix-env -i bat
```

### Via flox

You can install `bat` using [Flox](https://flox.dev)

```bash
flox install bat
```

### On openSUSE

You can install `bat` with zypper:

```bash
zypper install bat
```

### Via snap package

There is currently no recommended snap package available.
Existing packages may be available, but are not officially supported and may contain [issues](https://github.com/sharkdp/bat/issues/1519).

### On macOS (or Linux) via Homebrew

You can install `bat` with [Homebrew](https://formulae.brew.sh/formula/bat):

```bash
brew install bat
```

### On macOS via MacPorts

Or install `bat` with [MacPorts](https://ports.macports.org/port/bat/summary):

```bash
port install bat
```

### On Windows

There are a few options to install `bat` on Windows. Once you have installed `bat`,
take a look at the [&quot;Using `bat` on Windows&quot;](#using-bat-on-windows) section.

#### Prerequisites

You will need to install the [Visual C++ Redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) package.

#### With WinGet

You can install `bat` via [WinGet](https://learn.microsoft.com/en-us/windows/package-manager/winget):

```bash
winget install sharkdp.bat
```

#### With Chocolatey

You can install `bat` via [Chocolatey](https://chocolatey.org/packages/Bat):
```bash
choco install bat
```

#### With Scoop

You can install `bat` via [scoop](https://scoop.sh/):
```bash
scoop install bat
```

#### From prebuilt binaries:

You can download prebuilt binaries from the [Release page](https://github.com/sharkdp/bat/releases),

You will need to install the [Visual C++ Redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) package.

### From binaries

Check out the [Release page](https://github.com/sharkdp/bat/releases) for
prebuilt versions of `bat` for many different architectures. Statically-linked
binaries are also available: look for archives with `musl` in the file name.

### From source

If you want to build `bat` from source, you need Rust 1.74.0 or
higher. You can then use `cargo` to build everything:

```bash
cargo install --locked bat
```

Note that additional files like the man page or shell completion
files can not be installed in this way. They will be generated by `cargo` and should be available in the cargo target folder (under `build`).

Shell completions are also available by running:
```bash
bat --completion &lt;shell&gt;
# see --help for supported shells
```

## Customization

### Highlighting theme

Use `bat --list-themes` to get a list of all available themes for syntax
highlighting. To select the `TwoDark` theme, call `bat` with the
`--theme=TwoDark` option or set the `BAT_THEME` environment variable to
`TwoDark`. Use `export BAT_THEME=&quot;TwoDark&quot;` in your shell&#039;s startup file to
make the change permanent. Alternatively, use `bat`s
[configuration file](https://github.com/sharkdp/bat#configuration-file).

If you want to preview the different themes on a custom file, you can use
the following command (you need [`fzf`](https://github.com/junegunn/fzf) for this):
```bash
bat --list-themes | fzf --preview=&quot;bat --theme={} --color=always /path/to/file&quot;
```

`bat` automatically picks a fitting theme depending on your terminal&#039;s background color.
You can use the `--theme-dark` / `--theme-light` options or the `BAT_THEME_DARK` / `BAT_THEME_LIGHT` environment variables
to customize the themes used. This is especially useful if you frequently switch between dark and light mode.

You can also use a custom theme by following the
[&#039;Adding new themes&#039; section below](https://github.com/sharkdp/bat#adding-new-themes).

### 8-bit themes

`bat` has three themes that always use [8-bit colors](https://en.wikipedia.org/wiki/ANSI_escape_code#Colors),
even when truecolor support is available:

- `ansi` looks decent on any terminal. It uses 3-bit colors: black, red, green,
  yellow, blue, magenta, cyan, and white.
- `base16` is designed for [base16](https://github.com/chriskempson/base16) terminal themes. It uses
  4-bit colors (3-bit colors plus bright variants) in accordance with the
  [base16 styling guidelines](https://github.com/chriskempson/base16/blob/master/styling.md).
- `base16-256` is designed for [base16-shell](https://github.com/chriskempson/base16-shell).
  It replaces certain bright colors with 8-bit colors from 16 to 21. **Do not** use this simply
  because you have a 256-color terminal but are not using base16-shell.

Although these themes are more restricted, they have three advantages over truecolor themes. They:

- Enjoy maximum compatibility. Some terminal utilities do not support more than 3-bit colors.
- Adapt to terminal theme changes. Even for already printed output.
- Visually harmonize better with other terminal software.

### Output style

You can use the `--style` option to control the appearance of `bat`s output.
You can use `--style=numbers,changes`, for example, to show only Git changes
and line numbers but no grid and no file header. Set the `BAT_STYLE` environment
variable to make these changes permanent or use `bat`s
[configuration file](https://github.com/sharkdp/bat#configuration-file).

&gt;[!tip]
&gt; If you specify a default style in `bat`&#039;s config file, you can change which components
&gt; are displayed during a single run of `bat` using the `--style` command-line argument.
&gt; By prefixing a component with `+` or `-`, it can be added or removed from the current style.
&gt;
&gt; For example, if your config contains `--style=full,-snip`, you can run bat with
&gt; `--style=-grid,+snip` to remove the grid and add back the `snip` component.
&gt; Or, if you want to override the styles completely, you use `--style=numbers` to
&gt; only show the line numbers.

### Adding new syntaxes / language definitions

Should you find that a particular syntax is not available within `bat`, you can follow these
instructions to easily add new syntaxes to your current `bat` installation.

`bat` uses the excellent [`syntect`](https://github.com/trishume/syntect/)
library for syntax highlighting. `syntect` can read any
[Sublime Text `.sublime-syntax` file](https://www.sublimetext.com/docs/3/syntax.html)
and theme.

A good resource for finding Sublime Syntax packages is [Package Control](https://packagecontrol.io/). Once you found a
syntax:

1. Create a folder with syntax definition files:

   ```bash
   mkdir -p &quot;$(bat --config-dir)/syntaxes&quot;
   cd &quot;$(bat --config-dir)/syntaxes&quot;

   # Put new &#039;.sublime-syntax&#039; language definition files
   # in this folder (or its subdirectories), for example:
   git clone https://github.com/tellnobody1/sublime-purescript-syntax
   ```

2. Now use the following command to parse these files into a binary cache:

   ```bash
   bat cache --build
   ```

3. Finally, use `bat --list-languages` to check if the new languages are available.

   If you ever want to go back to the default settings, call:

   ```bash
   bat cache --clear
   ```

4. If you think that a specific syntax should be included in `bat` by default, please
   consider opening a &quot;syntax request&quot; ticket after reading the policies and
   instructions [here](doc/assets.md): [Open Syntax Request](https://github.com/sharkdp/bat/issues/new?labels=syntax-request&amp;template=syntax_request.md).

### Adding new themes

This works very similar to how we add new syntax definitions.

First, create a folder with the new syntax highlighting themes:
```bash
mkdir -p &quot;$(bat --config-dir)/themes&quot;
cd &quot;$(bat --config-dir)/themes&quot;

# Download a theme in &#039;.tmTheme&#039; format, for example:
git clone https://github.com/greggb/sublime-snazzy

# Update the binary cache
bat cache --build
```

Finally, use `bat --list-themes` to check if the new themes are available.

### Adding or changing file type associations

You can add new (or change existing) file name patterns using the `--map-syntax`
command line option. The option takes an argument of the form `pattern:syntax` where
`pattern` is a glob pattern that is matched against the file name and
the absolute file path. The `syntax` part is the full name of a supported language
(use `bat --list-languages` for an overview).

**Note:** You probably want to use this option as [an entry in `bat`&#039;s configuration file](#configuration-file)
for persistence instead of passing it on the command line as a one-off. Generally
you&#039;d just use `-l` if you want to manually specify a language for a file.

Example: To use &quot;INI&quot; syntax highlighting for all files with a `.conf` file extension, use
```bash
--map-syntax=&#039;*.conf:INI&#039;
```

Example: To open all files called `.ignore` (exact match) with the &quot;Git Ignore&quot; syntax, use:
```bash
--map-syntax=&#039;.ignore:Git Ignore&#039;
```

Example: To open all `.conf` files in subfolders of `/etc/apache2` with the &quot;Apache Conf&quot;
syntax, use (this mapping is already built in):
```bash
--map-syntax=&#039;/etc/apache2/**/*.conf:Apache Conf&#039;
```

### Using a different pager

`bat` uses the pager that is specified in the `PAGER` environment variable. If this variable is not

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[EricLBuehler/mistral.rs]]></title>
            <link>https://github.com/EricLBuehler/mistral.rs</link>
            <guid>https://github.com/EricLBuehler/mistral.rs</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[Blazingly fast LLM inference.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EricLBuehler/mistral.rs">EricLBuehler/mistral.rs</a></h1>
            <p>Blazingly fast LLM inference.</p>
            <p>Language: Rust</p>
            <p>Stars: 5,260</p>
            <p>Forks: 377</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;top&quot;&gt;&lt;/a&gt;
&lt;h1 align=&quot;center&quot;&gt;
  mistral.rs
&lt;/h1&gt;

&lt;h3 align=&quot;center&quot;&gt;
Blazingly fast LLM inference.
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
| &lt;a href=&quot;https://ericlbuehler.github.io/mistral.rs/mistralrs/&quot;&gt;&lt;b&gt;Rust Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://github.com/EricLBuehler/mistral.rs/blob/master/mistralrs-pyo3/API.md&quot;&gt;&lt;b&gt;Python Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://discord.gg/SZrecqK8qw&quot;&gt;&lt;b&gt;Discord&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://matrix.to/#/#mistral.rs:matrix.org&quot;&gt;&lt;b&gt;Matrix&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

Please submit requests for new models [here](https://github.com/EricLBuehler/mistral.rs/issues/156).

## Get started fast 🚀

1) [Install](#installation-and-build)

2) [Get models](#getting-models)

3) Deploy with our easy to use APIs
    - [Python](examples/python)
    - [Rust](mistralrs/examples)
    - [OpenAI compatible HTTP server](docs/HTTP.md)

## Quick examples

*After following installation instructions*

- Check out UQFF for prequantized models of various methods!
    - Models can be found [here](https://huggingface.co/collections/EricB/uqff-670e4a49d56ecdd3f7f0fd4c).

- 💎💎💎 Run the **Gemma 3** Model with 128k context length and vision support: [documentation](docs/GEMMA3.md)

    ```
    ./mistralrs-server -i vision-plain -m google/gemma-3-4b-it -a gemma3
    ```

- 🐋🐋🐋 Run the Deepseek R1/V3 model: [documentation](docs/DEEPSEEKV3.md)

    ```
    ./mistralrs-server -i --isq Q4K plain -m deepseek-ai/DeepSeek-R1
    ```

- 🐋🐋🐋 Run the Deepseek R1 [distillations](https://huggingface.co/collections/deepseek-ai/deepseek-r1-678e1e131c0169c0bc89728d) out of the box

    ```
    ./mistralrs-server -i --isq Q4K plain -m deepseek-ai/DeepSeek-R1-Distill-Llama-8B
    ./mistralrs-server -i --isq Q4K plain -m deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B
    ./mistralrs-server -i --isq Q4K plain -m deepseek-ai/DeepSeek-R1-Distill-Qwen-32B
    ```

- 🦙📷 Run the **Llama 3.2 Vision** Model: [documentation and guide here](docs/VLLAMA.md)

    &lt;img src=&quot;https://www.nhmagazine.com/content/uploads/2019/05/mtwashingtonFranconia-2-19-18-108-Edit-Edit.jpg&quot; alt=&quot;Mount Washington&quot; width = &quot;400&quot; height = &quot;267&quot;&gt;
    &lt;h6&gt;&lt;a href = &quot;https://www.nhmagazine.com/mount-washington/&quot;&gt;Credit&lt;/a&gt;&lt;/h6&gt;

    ```
    ./mistralrs-server -i vision-plain -m lamm-mit/Cephalo-Llama-3.2-11B-Vision-Instruct-128k -a vllama
    ```

- φ⁴ 📷 Run the **Phi 4 Multimodal** model: [documentation and guide here](docs/PHI4MM.md)

    ```
    ./mistralrs-server -i vision-plain -m microsoft/Phi-4-multimodal-instruct -a phi4mm
    ```

- φ⁴ Run the new **Phi 4/Phi 4 Mini** models with 128K context window

    ```
    ./mistralrs-server -i plain -m microsoft/Phi-4-mini-instruct -a phi3
    ```

- 🧮 Enhance ISQ by collecting an imatrix from calibration data: [documentation](docs/IMATRIX.md)

    ```
    ./mistralrs-server -i --isq Q4K plain -m meta-llama/Llama-3.2-3B-Instruct --calibration-file calibration_data/calibration_datav3_small.txt
    ```

- 🌲📷 Run the FLUX.1 diffusion model: [documentation and guide here](docs/FLUX.md)

    &lt;img src=&quot;https://github.com/user-attachments/assets/82bf5009-e3e9-402b-acf9-c48a52c7721b&quot; width = &quot;400&quot; height = &quot;267&quot;&gt;

    ```
    ./mistralrs-server --port 1234 diffusion-plain -m black-forest-labs/FLUX.1-schnell -a flux
    ```

- Other models: [see a support matrix](#support-matrix) and [how to run them](#run-with-the-cli)

Mistral.rs supports several model categories:
- Text to Text
- Text+Image to Text: Vision (see [the docs](docs/VISION_MODELS.md))
- Text to Image: Image Generation (see [the docs](docs/IMAGEGEN_MODELS.md))

## Description
**Easy**:
- Lightweight OpenAI API compatible HTTP server
- Python API
- Grammar support with JSON Schema, Regex, Lark, and Guidance via [LLGuidance library](https://github.com/microsoft/llguidance)
- [ISQ](docs/ISQ.md) (In situ quantization): run `.safetensors` models directly from 🤗 Hugging Face by quantizing in-place
    - Enhance performance with an [imatrix](docs/IMATRIX.md)!
- Automatic [device mapping](docs/DEVICE_MAPPING.md) to easily load and run models across multiple GPUs and CPU.

**Fast**:
- Apple silicon support: ARM NEON, Accelerate, Metal
- Accelerated CPU inference with MKL, AVX support
- CUDA support with FlashAttention and cuDNN.
- Automatic tensor-parallelism support with NCCL: [distributed documentation](docs/DISTRIBUTED.md)

**Quantization**:
- [Details](docs/QUANTS.md)
- GGML: 2-bit, 3-bit, 4-bit, 5-bit, 6-bit and 8-bit, with imatrix support
- GPTQ: 2-bit, 3-bit, 4-bit and 8-bit, with [Marlin](https://github.com/IST-DASLab/marlin) kernel support in 4-bit and 8-bit.
- HQQ: 4-bit and 8 bit, with ISQ support
- FP8
- BNB: bitsandbytes int8, fp4, nf4 support

**Powerful**:
- LoRA support with weight merging
- First X-LoRA inference platform with first class support
- [AnyMoE](docs/ANYMOE.md): Build a memory-efficient MoE model from anything, in seconds
- Various [sampling and penalty](docs/SAMPLING.mds) methods
- Tool calling: [docs](docs/TOOL_CALLING.md)
- Prompt chunking: process large prompts in a more manageable way

**Advanced features**:
- [PagedAttention](docs/PAGED_ATTENTION.md) and continuous batching (CUDA and Metal support)
- [FlashAttention](docs/FLASH_ATTENTION.md) V2/V3
- Prefix caching
- [Topology](docs/TOPOLOGY.md): Configure ISQ and device mapping easily
- [UQFF](docs/UQFF.md): Quantized file format for easy mixing of quants, [collection here](https://huggingface.co/collections/EricB/uqff-670e4a49d56ecdd3f7f0fd4c).
- Speculative Decoding: Mix supported models as the draft model or the target model
- Dynamic LoRA adapter activation with adapter preloading: [examples and docs](docs/ADAPTER_MODELS.md#adapter-model-dynamic-adapter-activation)

**Documentation for mistral.rs can be found [here](docs/README.md).**

This is a demo of interactive mode with streaming running Phi 3 128k mini with quantization via ISQ to Q4K.

&lt;!-- Mistral GGUF demo, old API --&gt;
&lt;!-- https://github.com/EricLBuehler/mistral.rs/assets/65165915/3396abcd-8d44-4bf7-95e6-aa532db09415 --&gt;

https://github.com/EricLBuehler/mistral.rs/assets/65165915/09d9a30f-1e22-4b9a-9006-4ec6ebc6473c

## Architecture Support matrix

&gt; Note: See [supported models](#supported-models) for more information

|Model|Supports quantization|Supports adapters|Supports device mapping|Supported by AnyMoE|
|--|--|--|--|--|
|Mistral v0.1/v0.2/v0.3|✅|✅|✅|✅|
|Gemma|✅|✅|✅|✅|
|Llama 3.1/3.2|✅|✅|✅|✅|
|Mixtral|✅|✅|✅| |
|Phi 2|✅|✅|✅|✅|
|Phi 3|✅|✅|✅|✅|
|Phi 3.5 MoE|✅| |✅| |
|Qwen 2.5|✅| |✅|✅|
|Phi 3 Vision|✅| |✅|✅|
|Idefics 2|✅| |✅|✅|
|Gemma 2|✅|✅|✅|✅|
|Starcoder 2|✅|✅|✅|✅|
|LLaVa Next|✅| |✅|✅|
|LLaVa|✅| |✅|✅|
|Llama 3.2 Vision|✅| |✅| |
|Qwen2-VL|✅| |✅| |
|Idefics 3|✅| |✅|✅|
|DeepseekV2|✅| |✅| |
|DeepseekV3|✅| |✅| |
|MinCPM-O 2.6|✅| |✅| |
|Phi 4 Multimodal|✅| |✅| |
|Qwen2.5-VL|✅| |✅| |
|Gemma 3|✅| |✅|✅|

## APIs and Integrations

### Rust Crate

Rust multithreaded/async API for easy integration into any application.

- [Docs](https://ericlbuehler.github.io/mistral.rs/mistralrs/)
- [Examples](mistralrs/examples/)
- To install: Add `mistralrs = { git = &quot;https://github.com/EricLBuehler/mistral.rs.git&quot; }`

### Python API

Python API for mistral.rs.

- [Installation including PyPI](mistralrs-pyo3/_README.md)
- [Docs](mistralrs-pyo3/API.md)
- [Examples](examples/python)
- [Cookbook](examples/python/cookbook.ipynb)


### HTTP Server

OpenAI API compatible API server

- [API Docs](docs/HTTP.md).
- [Running](README.md#run-with-the-cli)
- [Example](examples/server/chat.py)


### Llama Index integration (Python)

- Docs: https://docs.llamaindex.ai/en/stable/examples/llm/mistral_rs/

---

## Supported accelerators
- CUDA:
  - Compile with the `cuda` feature: `--features cuda`
  - FlashAttention support: compile with the `flash-attn` feature
  - cuDNN support: compile with the`cudnn` feature: `--features cudnn`
- Metal:
  - Compile with the `metal` feature: `--features metal`
- CPU:
  - Intel MKL: compile with the `mkl` feature: `--features mkl`
  - Apple Accelerate: compile with the `accelerate` feature: `--features accelerate`
  - ARM NEON and AVX are used automatically

Enabling features is done by passing `--features ...` to the build system. When using `cargo run` or `maturin develop`, pass the `--features` flag before the `--` separating build flags from runtime flags.

- To enable a single feature like `metal`: `cargo build --release --features metal`.
- To enable multiple features, specify them in quotes: `cargo build --release --features &quot;cuda flash-attn cudnn&quot;`.

## Installation and Build

&gt; Note: You can use our [Docker containers here](https://github.com/EricLBuehler/mistral.rs/pkgs/container/mistral.rs).
&gt; Learn more about running Docker containers: https://docs.docker.com/engine/reference/run/

- Install the [Python package here](mistralrs-pyo3/_README.md).
- The Python package has [wheels on PyPi](mistralrs-pyo3/_README.md#installation-from-pypi)!

1) Install required packages:
    - `OpenSSL` (*Example on Ubuntu:* `sudo apt install libssl-dev`)
    - &lt;b&gt;*Linux only:*&lt;/b&gt; `pkg-config` (*Example on Ubuntu:* `sudo apt install pkg-config`)

2) Install Rust: https://rustup.rs/

    *Example on Ubuntu:*
    ```bash
    curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
    source $HOME/.cargo/env
    ```

3) &lt;b&gt;*Optional:*&lt;/b&gt; Set HF token correctly (skip if already set or your model is not gated, or if you want to use the `token_source` parameters in Python or the command line.)
    - Note: you can install `huggingface-cli` as documented [here](https://huggingface.co/docs/huggingface_hub/en/installation). 
    ```bash
    huggingface-cli login
    ```

4) Download the code:
    ```bash
    git clone https://github.com/EricLBuehler/mistral.rs.git
    cd mistral.rs
    ```

5) Build or install:
    - Base build command
        ```bash
        cargo build --release
        ```
    - Build with CUDA support
        ```bash
        cargo build --release --features cuda
        ```
    - Build with CUDA and Flash Attention V2 support
        ```bash
        cargo build --release --features &quot;cuda flash-attn&quot;
        ```
    - Build with Metal support
        ```bash
        cargo build --release --features metal
        ```
    - Build with Accelerate support
        ```bash
        cargo build --release --features accelerate
        ```
    - Build with MKL support
        ```bash
        cargo build --release --features mkl
        ```
    - Install with `cargo install` for easy command line usage

        Pass the same values to `--features` as you would for `cargo build`
        ```bash
        cargo install --path mistralrs-server --features cuda
        ```
6) The build process will output a binary `mistralrs-server` at `./target/release/mistralrs-server`. We can switch to that directory so that the binary can be accessed as `./mistralrs-server` with the following command:

    *Example on Ubuntu:*
    ```
    cd target/release
    ```

7) Use our APIs and integrations: 
    
    [APIs and integrations list](#apis-and-integrations)

## Getting models

There are 2 ways to get models with mistral.rs:
- From Hugging Face Hub (easiest)
- From local files
    - Running a GGUF model
    - Specify local paths

### Getting models from Hugging Face Hub

Mistral.rs can automatically download models from HF Hub. To access gated models, you should provide a token source. They may be one of:
- `literal:&lt;value&gt;`: Load from a specified literal
- `env:&lt;value&gt;`: Load from a specified environment variable
- `path:&lt;value&gt;`: Load from a specified file
- `cache`: **default**: Load from the HF token at ~/.cache/huggingface/token or equivalent.
- `none`: Use no HF token

This is passed in the following ways:
- Command line:
```bash
./mistralrs-server --token-source none -i plain -m microsoft/Phi-3-mini-128k-instruct -a phi3
```
- Python:

[Here](examples/python/token_source.py) is an example of setting the token source.

If token cannot be loaded, no token will be used (i.e. effectively using `none`).

### Loading models from local files:

You can also instruct mistral.rs to load models fully locally by modifying the `*_model_id` arguments or options:
```bash
./mistralrs-server --port 1234 plain -m . -a mistral
```

Throughout mistral.rs, any model ID argument or option may be a local path and should contain the following files for each model ID option:
- `--model-id` (server) or `model_id` (python/rust) or `--tok-model-id` (server) or `tok_model_id` (python/rust): 
  - `config.json`
  - `tokenizer_config.json`
  - `tokenizer.json` (if not specified separately)
  - `.safetensors`/`.bin`/`.pth`/`.pt` files (defaults to `.safetensors`)
  - `preprocessor_config.json` (required for vision models).
  - `processor_config.json` (optional for vision models).
- `--quantized-model-id` (server) or `quantized_model_id` (python/rust):
  - Specified `.gguf` or `.ggml` file.
- `--x-lora-model-id` (server) or `xlora_model_id` (python/rust):
  - `xlora_classifier.safetensors`
  - `xlora_config.json`
  - Adapters `.safetensors` and `adapter_config.json` files in their respective directories
- `--adapters-model-id` (server) or `adapters_model_id` (python/rust):
  - Adapters `.safetensors` and `adapter_config.json` files in their respective directories

### Running GGUF models

To run GGUF models, the only mandatory arguments are the quantized model ID and the quantized filename. The quantized model ID can be a HF model ID.

You must also specify either `-i` for interactive mode or `--port` to launch a server, just like when [running a non-GGUF model with the CLI](#run-with-the-cli)

GGUF models contain a tokenizer. However, mistral.rs allows you to run the model with a tokenizer from a specified model, typically the official one. This means there are two options:
1) [With a specified tokenizer](#with-a-specified-tokenizer)
1) [With the builtin tokenizer](#with-the-builtin-tokenizer)

#### With a specified tokenizer

Running with a tokenizer model ID enables you to specify the model ID to source the tokenizer from:

```bash
./mistralrs-server gguf -m bartowski/Phi-3.5-mini-instruct-GGUF -f Phi-3.5-mini-instruct-Q4_K_M.gguf -t microsoft/Phi-3.5-mini-instruct
```

If the specified tokenizer model ID contains a `tokenizer.json`, then it will be used over the GGUF tokenizer.

#### With the builtin tokenizer

Using the builtin tokenizer:

```bash
./mistralrs-server gguf -m bartowski/Phi-3.5-mini-instruct-GGUF -f Phi-3.5-mini-instruct-Q4_K_M.gguf
```

(or using a local file):

```bash
./mistralrs-server gguf -m path/to/files -f Phi-3.5-mini-instruct-Q4_K_M.gguf
```

There are a few more ways to configure:

**Chat template:**

The chat template can be automatically detected and loaded from the GGUF file if no other chat template source is specified including the tokenizer model ID.

If that does not work, you can either [provide a tokenizer](#with-a-specified-tokenizer) (recommended), or specify a custom chat template.

```bash
./mistralrs-server --chat-template &lt;chat_template&gt; gguf -m . -f Phi-3.5-mini-instruct-Q4_K_M.gguf
```

**Tokenizer**

The following tokenizer model types are currently supported. If you would like one to be added, please raise an issue. Otherwise,
please consider using the method demonstrated in examples below, where the tokenizer is sourced from Hugging Face.

**Supported GGUF tokenizer types**
- `llama` (sentencepiece)
- `gpt2` (BPE)

## Run with the CLI

Mistral.rs uses subcommands to control the model type. Please run `./mistralrs-server --help` to see the subcommands which categorize the models by kind.

### Architecture for plain models

&gt; Note: for plain models, you can specify the data type to load and run in. This must be one of `f32`, `f16`, `bf16` or `auto` to choose based on the device. This is specified in the `--dype`/`-d` parameter after the model architecture (`plain`). For quantized models (gguf/ggml), you may specify data type of `f32` or `bf16` (`f16` is not recommended due to its lower precision in quantized inference).

If you do not specify the architecture, an attempt will be made to use the model&#039;s config. If this fails, please raise an issue.

- `mistral`
- `gemma`
- `mixtral`
- `llama`
- `phi2`
- `phi3`
- `phi3.5moe`
- `qwen2`
- `gemma2`
- `starcoder2`
- `deepseekv2`
- `deepseekv3`

### Architecture for vision models

&gt; Note: for vision models, you can specify the data type to load and run in. This must be one of `f32`, `f16`, `bf16` or `auto` to choose based on the device. This is specified in the `--dype`/`-d` parameter after the model architecture (`vision-plain`).

- `phi3v`
- `idefics2`
- `llava_next`
- `llava`
- `vllama`
- `qwen2vl`
- `idefics3`
- `minicpmo`
- `phi4mm`
- `qwen2_5vl`
- `gemma3`

### Supported GGUF architectures

**Plain:**

- `llama`
- `phi2`
- `phi3`
- `starcoder2`
- `qwen2`

**With adapters:**

- `llama`
- `phi3`

### Interactive mode

You can launch interactive mode, a simple chat application running in the terminal, by passing `-i`:

```bash
./mistralrs-server -i plain -m microsoft/Phi-3-mini-128k-instruct -a phi3
```

Vision models work too:

```bash
./mistralrs-server -i vision-plain -m lamm-mit/Cephalo-Llama-3.2-11B-Vision-Instruct-128k -a vllama
```

And even diffusion models:

```bash
./mistralrs-server -i diffusion-plain -m black-forest-labs/FLUX.1-schnell -a flux
```

On Apple Silicon (`Metal`), run with throughput log, settings of paged attention (maximum usage of 4GB for kv cache) and dtype (bf16 for kv cache and attention)

```bash
cargo build --release --features metal
./target/release/mistralrs-server -i --throughput --paged-attn --pa-gpu-mem 4096 gguf --dtype bf16 -m /Users/Downloads/ -f Phi-3.5-mini-instruct-Q4_K_M.gguf
```

### OpenAI HTTP server

You can an HTTP server

```bash
./mistralrs-server --port 1234 plain -m microsoft/Phi-3.5-MoE-instruct -a phi3.5moe
```

### Structured selection with a `.toml` file

We provide a method to select models with a `.toml` file. The keys are the same as the command line, with `no_kv_cache` and `tokenizer_json` being &quot;global&quot; keys.

Example:
```bash
./mistralrs-server --port 1234 toml -f toml-selectors/gguf.toml
```

---

## Benchmarks
|Device|Mistral.rs Completion T/s|Llama.cpp Completion T/s|Model|Quant|
|-|-|-|-|-|
|A10 GPU, CUDA|86|83|[mistral-7b](TheBloke/Mistral-7B-Instruct-v0.1-GGUF)|4_K_M|
|Intel Xeon 8358 CPU, AVX|11|23|[mistral-7b](TheBloke/Mistral-7B-Instruct-v0.1-GGUF)|4_K_M|
|Raspberry Pi 5 (8GB), Neon|2|3|[mistral-7b](TheBloke/Mistral-7B-Instruct-v0.1-GGUF)|2_K|
|A100 GPU, CUDA|131|134|[mistral-7b](TheBloke/Mistral-7B-Instruct-v0.1-GGUF)|4_K_M|
|RTX 6000 GPU, CUDA|103|96|[mistral-7b](TheBloke/Mistral-7B-Instruct-v0.1-GGUF)|4_K_M|

&gt; Note: All CUDA tests for mistral.rs conducted with PagedAttention enabled, block size = 32

Please submit more benchmarks via raising an issue!

## Supported models

**Quantization support**
|Model|GGUF|GGML|ISQ|
|--|--|--|--|
|Mistral|✅| |✅|
|Gemma| | |✅|
|Llama|✅|✅|✅|
|Mixtral|✅| |✅|
|Phi 2|✅| |✅|
|Phi 3|✅| |✅|
|Phi 3.5 MoE| | |✅|
|Qwen 2.5| | |✅|
|Phi 3 Vision| | |✅|
|Idefics 2| | |✅|
|Gemma 2| | |✅|
|Starcoder 2| |✅|✅|
|LLaVa Next| | |✅|
|LLaVa| | |✅|
|Llama 3.2 Vision| | |✅|
|Qwen2-VL| | |✅|
|Idefics 3| | |✅|
|Deepseek V2| | |✅|
|Deepseek V3| | |✅|
|MiniCPM-O 2.6| | |✅|
|Qwen2.5-VL| | |✅|
|Gemma 3| | |✅|

**Device mapping support**
|Model category|Supported|
|--|--|
|Plain|✅|
|GGUF|✅|
|GGML| |
|Vision Plain|✅|

**X-LoRA and LoRA support**
|Model|X-LoRA|X-LoRA+GGUF|X-LoRA+GGML|
|--|--|--|--|
|Mistral|✅|✅| |
|Gemma|✅| | |
|Llama|✅|✅|✅|
|Mixtral|✅|✅| |
|Phi 2|✅| | |
|Phi 3|✅|✅| |
|Phi 3.5 MoE| | | |
|Qwen 2.5| | | |
|Phi 3 Vision| | | |
|Idefics 2| | | |
|Gemma 2|✅| | |
|Starcoder 2|✅| | |
|LLaVa Next| | | |
|LLaVa| | | |
|Qwen2-VL| | | |
|Idefics 3| | | |
|Deepseek V2| | | |
|Deepseek V3| | | |
|MiniCPM-O 2.6| | | |
|Qwen2.5-VL| | | |
|Gemma 3| | | |

**AnyMoE support**
|Model|AnyMoE|
|--|--|
|Mistral 7B|✅|
|Gemma|✅|
|Llama|✅|
|Mixtral| |
|Phi 2|✅|
|Phi 3|✅|
|Phi 3.5 MoE| |
|Qwen 2.5|✅|
|Phi 3 Vision| 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vectordotdev/vector]]></title>
            <link>https://github.com/vectordotdev/vector</link>
            <guid>https://github.com/vectordotdev/vector</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:22 GMT</pubDate>
            <description><![CDATA[A high-performance observability data pipeline.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vectordotdev/vector">vectordotdev/vector</a></h1>
            <p>A high-performance observability data pipeline.</p>
            <p>Language: Rust</p>
            <p>Stars: 18,995</p>
            <p>Forks: 1,687</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://vector.dev/docs/setup/quickstart/&quot;&gt;Quickstart&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/docs/&quot;&gt;Docs&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/guides/&quot;&gt;Guides&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/components/&quot;&gt;Integrations&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://chat.vector.dev&quot;&gt;Chat&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/releases/latest/download/&quot;&gt;Download&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://rust-doc.vector.dev/&quot;&gt;Rust Crate Docs&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;website/static/img/diagram.svg&quot; alt=&quot;Vector&quot;&gt;
&lt;/p&gt;

## What is Vector?

Vector is a high-performance, end-to-end (agent &amp; aggregator) observability data
pipeline that puts you in control of your observability data.
[Collect][docs.sources], [transform][docs.transforms], and [route][docs.sinks]
all your logs and metrics to any vendors you want today and any other
vendors you may want tomorrow. Vector enables dramatic cost reduction, novel
data enrichment, and data security where you need it, not where it is most
convenient for your vendors. Additionally, it is open source and up to 10x
faster than every alternative in the space.

To get started, follow our [**quickstart guide**][docs.quickstart] or [**install
Vector**][docs.installation].

### Principles

* **Reliable** - Built in [Rust][urls.rust], Vector&#039;s primary design goal is reliability.
* **End-to-end** - Deploys as an [agent][docs.roles#agent] or [aggregator][docs.roles#aggregator]. Vector is a complete platform.
* **Unified** - [Logs][docs.data-model.log], [metrics][docs.data-model.metric] (beta), and traces (coming soon). One tool for all of your data.

### Use cases

* Reduce total observability costs.
* Transition vendors without disrupting workflows.
* Enhance data quality and improve insights.
* Consolidate agents and eliminate agent fatigue.
* Improve overall observability performance and reliability.

### Community

* Vector is relied on by startups and enterprises like **Atlassian**, **T-Mobile**,
  **Comcast**, **Zendesk**, **Discord**, **Fastly**, **CVS**, **Trivago**,
  **Tuple**, **Douban**, **Visa**, **Mambu**, **Blockfi**, **Claranet**,
  **Instacart**, **Forcepoint**, and [many more][urls.production_users].
* Vector is **downloaded over 100,000 times per day**.
* Vector&#039;s largest user **processes over 30TB daily**.
* Vector has **over 100 contributors** and growing.

## [Documentation](https://vector.dev/docs/)

### About

* [**Concepts**][docs.about.concepts]
* [**Under the hood**][docs.about.under-the-hood]
  * [**Architecture**][docs.under-the-hood.architecture] - [data model][docs.architecture.data-model] ([log][docs.data-model.log], [metric][docs.data-model.metric]), [pipeline model][docs.architecture.pipeline-model], [concurrency model][docs.architecture.concurrency-model], [runtime model][docs.architecture.runtime-model]
  * [**Networking**][docs.under-the-hood.networking] - [ARC][docs.networking.adaptive-request-concurrency]
  * [**Guarantees**][docs.under-the-hood.guarantees]

### Setup

* [**Quickstart**][docs.setup.quickstart]
* [**Installation**][docs.setup.installation] - [operating systems][docs.installation.operating_systems], [package managers][docs.installation.package_managers], [platforms][docs.installation.platforms] ([Kubernetes][docs.platforms.kubernetes]), [manual][docs.installation.manual]
* [**Deployment**][docs.deployment] - [roles][docs.deployment.roles], [topologies][docs.deployment.topologies]

### Reference

* **Configuration**
  * [**Sources**][docs.configuration.sources] - [docker_logs][docs.sources.docker_logs], [file][docs.sources.file], [http][docs.sources.http], [journald][docs.sources.journald], [kafka][docs.sources.kafka], [socket][docs.sources.socket], and [many more...][docs.sources]
  * [**Transforms**][docs.configuration.transforms] - [dedupe][docs.transforms.dedupe], [filter][docs.transforms.filter], [log_to_metric][docs.transforms.log_to_metric], [lua][docs.transforms.lua], [remap][docs.transforms.remap],
    and [many more...][docs.transforms]
  * [**Sinks**][docs.configuration.sinks] - [aws_cloudwatch_logs][docs.sinks.aws_cloudwatch_logs], [aws_s3][docs.sinks.aws_s3], [clickhouse][docs.sinks.clickhouse], [elasticsearch][docs.sinks.elasticsearch], [gcp_cloud_storage][docs.sinks.gcp_cloud_storage], and [many more...][docs.sinks]
  * [**Enrichment Tables**][docs.configuration.enrichment_tables]
  * [**Unit tests**][docs.configuration.tests]
* [**Remap Language**][docs.reference.vrl]
* [**API**][docs.reference.api]
* [**CLI**][docs.reference.cli]

### Administration

* [**Management**][docs.administration.management]
* [**Monitoring &amp; observing**][docs.administration.monitoring]
* [**Upgrading**][docs.administration.upgrading]
* [**Validating**][docs.administration.validating]

### Resources

* [**Community**][urls.vector_community] - [chat][urls.vector_chat], [calendar][urls.vector_calendar], [@vectordotdev][urls.vector_twitter]
* [**Releases**][urls.vector_releases]
* **Policies** - [Code of Conduct][urls.vector_code_of_conduct], [Privacy][urls.vector_privacy_policy], [Releases][urls.vector_releases_policy], [Security][urls.vector_security_policy], [Versioning][urls.vector_versioning_policy]

## Comparisons

### Performance

The following performance tests demonstrate baseline performance between
common protocols with the exception of the Regex Parsing test.

| Test                                                                                                                   | Vector          | Filebeat | FluentBit       | FluentD   | Logstash  | SplunkUF        | SplunkHF |
| ---------------------------------------------------------------------------------------------------------------------- | --------------- | -------- | --------------- | --------- | --------- | --------------- | -------- |
| [TCP to Blackhole](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance) | _**86mib/s**_   | n/a      | 64.4mib/s       | 27.7mib/s | 40.6mib/s | n/a             | n/a      |
| [File to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance)           | _**76.7mib/s**_ | 7.8mib/s | 35mib/s         | 26.1mib/s | 3.1mib/s  | 40.1mib/s       | 39mib/s  |
| [Regex Parsing](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance)       | 13.2mib/s       | n/a      | _**20.5mib/s**_ | 2.6mib/s  | 4.6mib/s  | n/a             | 7.8mib/s |
| [TCP to HTTP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance)           | _**26.7mib/s**_ | n/a      | 19.6mib/s       | &lt;1mib/s   | 2.7mib/s  | n/a             | n/a      |
| [TCP to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance)             | 69.9mib/s       | 5mib/s   | 67.1mib/s       | 3.9mib/s  | 10mib/s   | _**70.4mib/s**_ | 7.6mib/s |

To learn more about our performance tests, please see the [Vector test harness][urls.vector_test_harness].

### Correctness

The following correctness tests are not exhaustive, but they demonstrate
fundamental differences in quality and attention to detail:

| Test                                                                                                                                 | Vector | Filebeat | FluentBit | FluentD | Logstash | Splunk UF | Splunk HF |
| ------------------------------------------------------------------------------------------------------------------------------------ | ------ | -------- | --------- | ------- | -------- | --------- | --------- |
| [Disk Buffer Persistence](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness) | **✓**  | ✓        |           |         | ⚠        | ✓         | ✓         |
| [File Rotate (create)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness)         | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |
| [File Rotate (copytruncate)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness) | **✓**  |          |           |         |          | ✓         | ✓         |
| [File Truncation](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness)                   | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |
| [Process (SIGHUP)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness)                         | **✓**  |          |           |         | ⚠        | ✓         | ✓         |
| [JSON (wrapped)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness)                     | **✓**  | ✓        | ✓         | ✓       | ✓        | ✓         | ✓         |

To learn more about our correctness tests, please see the [Vector test harness][urls.vector_test_harness].

### Features

Vector is an end-to-end, unified, open data platform.

|                     | **Vector** | Beats | Fluentbit | Fluentd | Logstash | Splunk UF | Splunk HF | Telegraf |
| ------------------- | ---------- | ----- | --------- | ------- | -------- | --------- | --------- | -------- |
| **End-to-end**      | **✓**      |       |           |         |          |           |           | ✓        |
| Agent               | **✓**      | ✓     | ✓         |         |          | ✓         |           | ✓        |
| Aggregator          | **✓**      |       |           | ✓       | ✓        |           | ✓         | ✓        |
| **Unified**         | **✓**      |       |           |         |          |           |           | ✓        |
| Logs                | **✓**      | ✓     | ✓         | ✓       | ✓        | ✓         | ✓         | ✓        |
| Metrics             | **✓**      | ⚠     | ⚠         | ⚠       | ⚠        | ⚠         | ⚠         | ✓        |
| Traces              | 🚧         |       |           |         |          |           |           |          |
| **Open**            | **✓**      |       | ✓         | ✓       |          |           |           | ✓        |
| Open-source         | **✓**      | ✓     | ✓         | ✓       | ✓        |           |           | ✓        |
| Vendor-neutral      | **✓**      |       | ✓         | ✓       |          |           |           | ✓        |
| **Reliability**     | **✓**      |       |           |         |          |           |           |          |
| Memory-safe         | **✓**      |       |           |         |          |           |           | ✓        |
| Delivery guarantees | **✓**      |       |           |         |          | ✓         | ✓         |          |
| Multi-core          | **✓**      | ✓     | ✓         | ✓       | ✓        | ✓         | ✓         | ✓        |


⚠ = Not interoperable, metrics are represented as structured logs

---

&lt;p align=&quot;center&quot;&gt;
  Developed with ❤️ by &lt;strong&gt;&lt;a href=&quot;https://datadoghq.com&quot;&gt;Datadog&lt;/a&gt;&lt;/strong&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/security/policy&quot;&gt;Security Policy&lt;/a&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/blob/master/PRIVACY.md&quot;&gt;Privacy Policy&lt;/a&gt;
&lt;/p&gt;

[docs.about.concepts]: https://vector.dev/docs/about/concepts/
[docs.about.under-the-hood]: https://vector.dev/docs/about/under-the-hood/
[docs.administration.monitoring]: https://vector.dev/docs/administration/monitoring/
[docs.administration.management]: https://vector.dev/docs/administration/management/
[docs.administration.upgrading]: https://vector.dev/docs/administration/upgrading/
[docs.administration.validating]: https://vector.dev/docs/administration/validating/
[docs.architecture.concurrency-model]: https://vector.dev/docs/about/under-the-hood/architecture/concurrency-model/
[docs.architecture.data-model]: https://vector.dev/docs/about/under-the-hood/architecture/data-model/
[docs.architecture.pipeline-model]: https://vector.dev/docs/about/under-the-hood/architecture/pipeline-model/
[docs.architecture.runtime-model]: https://vector.dev/docs/about/under-the-hood/architecture/runtime-model/
[docs.configuration.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.configuration.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.configuration.tests]: https://vector.dev/docs/reference/configuration/tests/
[docs.configuration.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.configuration.enrichment_tables]: https://vector.dev/docs/reference/configuration/global-options/#enrichment_tables
[docs.data-model.log]: https://vector.dev/docs/about/under-the-hood/architecture/data-model/log/
[docs.data-model.metric]: https://vector.dev/docs/about/under-the-hood/architecture/data-model/metric/
[docs.deployment.roles]: https://vector.dev/docs/setup/deployment/roles/
[docs.deployment.topologies]: https://vector.dev/docs/setup/deployment/topologies/
[docs.deployment]: https://vector.dev/docs/setup/deployment/
[docs.installation.manual]: https://vector.dev/docs/setup/installation/manual/
[docs.installation.operating_systems]: https://vector.dev/docs/setup/installation/operating-systems/
[docs.installation.package_managers]: https://vector.dev/docs/setup/installation/package-managers/
[docs.installation.platforms]: https://vector.dev/docs/setup/installation/platforms/
[docs.installation]: https://vector.dev/docs/setup/installation/
[docs.networking.adaptive-request-concurrency]: https://vector.dev/docs/about/under-the-hood/networking/arc/
[docs.platforms.kubernetes]: https://vector.dev/docs/setup/installation/platforms/kubernetes/
[docs.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.reference.api]: https://vector.dev/docs/reference/api/
[docs.reference.cli]: https://vector.dev/docs/reference/cli/
[docs.reference.vrl]: https://vector.dev/docs/reference/vrl/
[docs.roles#agent]: https://vector.dev/docs/setup/deployment/roles/#agent
[docs.roles#aggregator]: https://vector.dev/docs/setup/deployment/roles/#aggregator
[docs.setup.installation]: https://vector.dev/docs/setup/installation/
[docs.setup.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.sinks.aws_cloudwatch_logs]: https://vector.dev/docs/reference/configuration/sinks/aws_cloudwatch_logs/
[docs.sinks.aws_s3]: https://vector.dev/docs/reference/configuration/sinks/aws_s3/
[docs.sinks.clickhouse]: https://vector.dev/docs/reference/configuration/sinks/clickhouse/
[docs.sinks.elasticsearch]: https://vector.dev/docs/reference/configuration/sinks/elasticsearch/
[docs.sinks.gcp_cloud_storage]: https://vector.dev/docs/reference/configuration/sinks/gcp_cloud_storage/
[docs.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.sources.docker_logs]: https://vector.dev/docs/reference/configuration/sources/docker_logs/
[docs.sources.file]: https://vector.dev/docs/reference/configuration/sources/file/
[docs.sources.http]: https://vector.dev/docs/reference/configuration/sources/http/
[docs.sources.journald]: https://vector.dev/docs/reference/configuration/sources/journald/
[docs.sources.kafka]: https://vector.dev/docs/reference/configuration/sources/kafka/
[docs.sources.socket]: https://vector.dev/docs/reference/configuration/sources/socket/
[docs.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.transforms.dedupe]: https://vector.dev/docs/reference/configuration/transforms/dedupe/
[docs.transforms.filter]: https://vector.dev/docs/reference/configuration/transforms/filter/
[docs.transforms.log_to_metric]: https://vector.dev/docs/reference/configuration/transforms/log_to_metric/
[docs.transforms.lua]: https://vector.dev/docs/reference/configuration/transforms/lua/
[docs.transforms.remap]: https://vector.dev/docs/reference/configuration/transforms/remap/
[docs.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.under-the-hood.architecture]: https://vector.dev/docs/about/under-the-hood/architecture/
[docs.under-the-hood.guarantees]: https://vector.dev/docs/about/under-the-hood/guarantees/
[docs.under-the-hood.networking]: https://vector.dev/docs/about/under-the-hood/networking/
[urls.production_users]: https://github.com/vectordotdev/vector/issues/790
[urls.rust]: https://www.rust-lang.org/
[urls.vector_calendar]: https://calendar.vector.dev
[urls.vector_chat]: https://chat.vector.dev
[urls.vector_code_of_conduct]: https://github.com/vectordotdev/vector/blob/master/CODE_OF_CONDUCT.md
[urls.vector_community]: https://vector.dev/community/
[urls.vector_privacy_policy]: https://github.com/vectordotdev/vector/blob/master/PRIVACY.md
[urls.vector_release_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASING.md
[urls.vector_releases]: https://vector.dev/releases/
[urls.vector_releases_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASES.md
[urls.vector_security_policy]: https://github.com/vectordotdev/vector/security/policy
[urls.vector_test_harness]: https://github.com/vectordotdev/vector-test-harness/
[urls.vector_twitter]: https://twitter.com/vectordotdev
[urls.vector_versioning_policy]: https://github.com/vectordotdev/vector/blob/master/VERSIONING.md
[urls.vote_feature]: https://github.com/vectordotdev/vector/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22type%3A+feature%22

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[paradigmxyz/reth]]></title>
            <link>https://github.com/paradigmxyz/reth</link>
            <guid>https://github.com/paradigmxyz/reth</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:21 GMT</pubDate>
            <description><![CDATA[Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol, in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paradigmxyz/reth">paradigmxyz/reth</a></h1>
            <p>Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol, in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 4,472</p>
            <p>Forks: 1,492</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># reth

[![CI status](https://github.com/paradigmxyz/reth/workflows/unit/badge.svg)][gh-ci]
[![cargo-deny status](https://github.com/paradigmxyz/reth/workflows/deny/badge.svg)][gh-deny]
[![Telegram Chat][tg-badge]][tg-url]

**Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol**

![](./assets/reth-prod.png)

**[Install](https://paradigmxyz.github.io/reth/installation/installation.html)**
| [User Book](https://reth.rs)
| [Developer Docs](./docs)
| [Crate Docs](https://reth.rs/docs)

[gh-ci]: https://github.com/paradigmxyz/reth/actions/workflows/unit.yml
[gh-deny]: https://github.com/paradigmxyz/reth/actions/workflows/lint.yml
[tg-badge]: https://img.shields.io/endpoint?color=neon&amp;logo=telegram&amp;label=chat&amp;url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Fparadigm%5Freth

## What is Reth?

Reth (short for Rust Ethereum, [pronunciation](https://twitter.com/kelvinfichter/status/1597653609411268608)) is a new Ethereum full node implementation that is focused on being user-friendly, highly modular, as well as being fast and efficient. Reth is an Execution Layer (EL) and is compatible with all Ethereum Consensus Layer (CL) implementations that support the [Engine API](https://github.com/ethereum/execution-apis/tree/a0d03086564ab1838b462befbc083f873dcf0c0f/src/engine). It is originally built and driven forward by [Paradigm](https://paradigm.xyz/), and is licensed under the Apache and MIT licenses.

## Goals

As a full Ethereum node, Reth allows users to connect to the Ethereum network and interact with the Ethereum blockchain. This includes sending and receiving transactions/logs/traces, as well as accessing and interacting with smart contracts. Building a successful Ethereum node requires creating a high-quality implementation that is both secure and efficient, as well as being easy to use on consumer hardware. It also requires building a strong community of contributors who can help support and improve the software.

More concretely, our goals are:

1. **Modularity**: Every component of Reth is built to be used as a library: well-tested, heavily documented and benchmarked. We envision that developers will import the node&#039;s crates, mix and match, and innovate on top of them. Examples of such usage include but are not limited to spinning up standalone P2P networks, talking directly to a node&#039;s database, or &quot;unbundling&quot; the node into the components you need. To achieve that, we are licensing Reth under the Apache/MIT permissive license. You can learn more about the project&#039;s components [here](./docs/repo/layout.md).
2. **Performance**: Reth aims to be fast, so we used Rust and the [Erigon staged-sync](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) node architecture. We also use our Ethereum libraries (including [Alloy](https://github.com/alloy-rs/alloy/) and [revm](https://github.com/bluealloy/revm/)) which we’ve battle-tested and optimized via [Foundry](https://github.com/foundry-rs/foundry/).
3. **Free for anyone to use any way they want**: Reth is free open source software, built for the community, by the community. By licensing the software under the Apache/MIT license, we want developers to use it without being bound by business licenses, or having to think about the implications of GPL-like licenses.
4. **Client Diversity**: The Ethereum protocol becomes more antifragile when no node implementation dominates. This ensures that if there&#039;s a software bug, the network does not finalize a bad block. By building a new client, we hope to contribute to Ethereum&#039;s antifragility.
5. **Support as many EVM chains as possible**: We aspire that Reth can full-sync not only Ethereum, but also other chains like Optimism, Polygon, BNB Smart Chain, and more. If you&#039;re working on any of these projects, please reach out.
6. **Configurability**: We want to solve for node operators that care about fast historical queries, but also for hobbyists who cannot operate on large hardware. We also want to support teams and individuals who want both sync from genesis and via &quot;fast sync&quot;. We envision that Reth will be configurable enough and provide configurable &quot;profiles&quot; for the tradeoffs that each team faces.

## Status

Reth is production ready, and suitable for usage in mission-critical environments such as staking or high-uptime services. We also actively recommend professional node operators to switch to Reth in production for performance and cost reasons in use cases where high performance with great margins is required such as RPC, MEV, Indexing, Simulations, and P2P activities.

More historical context below:
* We released 1.0 &quot;production-ready&quot; stable Reth in June 2024.
    * Reth completed an audit with [Sigma Prime](https://sigmaprime.io/), the developers of [Lighthouse](https://github.com/sigp/lighthouse), the Rust Consensus Layer implementation. Find it [here](./audit/sigma_prime_audit_v2.pdf).
    * Revm (the EVM used in Reth) underwent an audit with [Guido Vranken](https://twitter.com/guidovranken) (#1 [Ethereum Bug Bounty](https://ethereum.org/en/bug-bounty)). We will publish the results soon.
* We released multiple iterative beta versions, up to [beta.9](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.9) on Monday June 3rd 2024 the last beta release.
* We released [beta](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) on Monday March 4th 2024, our first breaking change to the database model, providing faster query speed, smaller database footprint, and allowing &quot;history&quot; to be mounted on separate drives.
* We shipped iterative improvements until the last alpha release on February 28th 2024, [0.1.0-alpha.21](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.21).
* We [initially announced](https://www.paradigm.xyz/2023/06/reth-alpha) [0.1.0-alpha.1](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.1) in June 20th 2023.

### Database compatibility

We do not have any breaking database changes since beta.1, and do not plan any in the near future.

Reth [v0.2.0-beta.1](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) includes
a [set of breaking database changes](https://github.com/paradigmxyz/reth/pull/5191) that makes it impossible to use database files produced by earlier versions.

If you had a database produced by alpha versions of Reth, you need to drop it with `reth db drop`
(using the same arguments such as `--config` or `--datadir` that you passed to `reth node`), and resync using the same `reth node` command you&#039;ve used before.

## For Users

See the [Reth Book](https://paradigmxyz.github.io/reth) for instructions on how to install and run Reth.

## For Developers

### Using reth as a library

You can use individual crates of reth in your project.

The crate docs can be found [here](https://paradigmxyz.github.io/reth/docs).

For a general overview of the crates, see [Project Layout](./docs/repo/layout.md).

### Contributing

If you want to contribute, or follow along with contributor discussion, you can use our [main telegram](https://t.me/paradigm_reth) to chat with us about the development of Reth!

- Our contributor guidelines can be found in [`CONTRIBUTING.md`](./CONTRIBUTING.md).
- See our [contributor docs](./docs) for more information on the project. A good starting point is [Project Layout](./docs/repo/layout.md).

### Building and testing

&lt;!--
When updating this, also update:
- clippy.toml
- Cargo.toml
- .github/workflows/lint.yml
--&gt;

The Minimum Supported Rust Version (MSRV) of this project is [1.85.0](https://blog.rust-lang.org/2025/02/20/Rust-1.85.0.html).

See the book for detailed instructions on how to [build from source](https://paradigmxyz.github.io/reth/installation/source.html).

To fully test Reth, you will need to have [Geth installed](https://geth.ethereum.org/docs/getting-started/installing-geth), but it is possible to run a subset of tests without Geth.

First, clone the repository:

```sh
git clone https://github.com/paradigmxyz/reth
cd reth
```

Next, run the tests:

```sh
# Without Geth
cargo test --workspace

# With Geth
cargo test --workspace --features geth-tests

# With Ethereum Foundation tests
#
# Note: Requires cloning https://github.com/ethereum/tests
#
#   cd testing/ef-tests &amp;&amp; git clone https://github.com/ethereum/tests ethereum-tests
cargo test -p ef-tests --features ef-tests
```

We recommend using [`cargo nextest`](https://nexte.st/) to speed up testing. With nextest installed, simply substitute `cargo test` with `cargo nextest run`.

&gt; **Note**
&gt;
&gt; Some tests use random number generators to generate test data. If you want to use a deterministic seed, you can set the `SEED` environment variable.

## Getting Help

If you have any questions, first see if the answer to your question can be found in the [book][book].

If the answer is not there:

- Join the [Telegram][tg-url] to get help, or
- Open a [discussion](https://github.com/paradigmxyz/reth/discussions/new) with your question, or
- Open an issue with [the bug](https://github.com/paradigmxyz/reth/issues/new?assignees=&amp;labels=C-bug%2CS-needs-triage&amp;projects=&amp;template=bug.yml)

## Security

See [`SECURITY.md`](./SECURITY.md).

## Acknowledgements

Reth is a new implementation of the Ethereum protocol. In the process of developing the node we investigated the design decisions other nodes have made to understand what is done well, what is not, and where we can improve the status quo.

None of this would have been possible without them, so big shoutout to the teams below:

- [Geth](https://github.com/ethereum/go-ethereum/): We would like to express our heartfelt gratitude to the go-ethereum team for their outstanding contributions to Ethereum over the years. Their tireless efforts and dedication have helped to shape the Ethereum ecosystem and make it the vibrant and innovative community it is today. Thank you for your hard work and commitment to the project.
- [Erigon](https://github.com/ledgerwatch/erigon) (fka Turbo-Geth): Erigon pioneered the [&quot;Staged Sync&quot; architecture](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) that Reth is using, as well as [introduced MDBX](https://github.com/ledgerwatch/erigon/wiki/Choice-of-storage-engine) as the database of choice. We thank Erigon for pushing the state of the art research on the performance limits of Ethereum nodes.
- [Akula](https://github.com/akula-bft/akula/): Reth uses forks of the Apache versions of Akula&#039;s [MDBX Bindings](https://github.com/paradigmxyz/reth/pull/132), [FastRLP](https://github.com/paradigmxyz/reth/pull/63) and [ECIES](https://github.com/paradigmxyz/reth/pull/80) . Given that these packages were already released under the Apache License, and they implement standardized solutions, we decided not to reimplement them to iterate faster. We thank the Akula team for their contributions to the Rust Ethereum ecosystem and for publishing these packages.

## Warning

The `NippyJar` and `Compact` encoding formats and their implementations are designed for storing and retrieving data internally. They are not hardened to safely read potentially malicious data.

[book]: https://paradigmxyz.github.io/reth/
[tg-url]: https://t.me/paradigm_reth
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[zed-industries/zed]]></title>
            <link>https://github.com/zed-industries/zed</link>
            <guid>https://github.com/zed-industries/zed</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:20 GMT</pubDate>
            <description><![CDATA[Code at the speed of thought – Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zed-industries/zed">zed-industries/zed</a></h1>
            <p>Code at the speed of thought – Zed is a high-performance, multiplayer code editor from the creators of Atom and Tree-sitter.</p>
            <p>Language: Rust</p>
            <p>Stars: 55,887</p>
            <p>Forks: 3,746</p>
            <p>Stars today: 64 stars today</p>
            <h2>README</h2><pre># Zed

[![CI](https://github.com/zed-industries/zed/actions/workflows/ci.yml/badge.svg)](https://github.com/zed-industries/zed/actions/workflows/ci.yml)

Welcome to Zed, a high-performance, multiplayer code editor from the creators of [Atom](https://github.com/atom/atom) and [Tree-sitter](https://github.com/tree-sitter/tree-sitter).

---

### Installation

&lt;a href=&quot;https://repology.org/project/zed-editor/versions&quot;&gt;
    &lt;img src=&quot;https://repology.org/badge/vertical-allrepos/zed-editor.svg?minversion=0.143.5&quot; alt=&quot;Packaging status&quot; align=&quot;right&quot;&gt;
&lt;/a&gt;

On macOS and Linux you can [download Zed directly](https://zed.dev/download) or [install Zed via your local package manager](https://zed.dev/docs/linux#installing-via-a-package-manager).

Other platforms are not yet available:

- Windows ([tracking issue](https://github.com/zed-industries/zed/issues/5394))
- Web ([tracking issue](https://github.com/zed-industries/zed/issues/5396))

### Developing Zed

- [Building Zed for macOS](./docs/src/development/macos.md)
- [Building Zed for Linux](./docs/src/development/linux.md)
- [Building Zed for Windows](./docs/src/development/windows.md)
- [Running Collaboration Locally](./docs/src/development/local-collaboration.md)

### Contributing

See [CONTRIBUTING.md](./CONTRIBUTING.md) for ways you can contribute to Zed.

Also... we&#039;re hiring! Check out our [jobs](https://zed.dev/jobs) page for open roles.

### Licensing

License information for third party dependencies must be correctly provided for CI to pass.

We use [`cargo-about`](https://github.com/EmbarkStudios/cargo-about) to automatically comply with open source licenses. If CI is failing, check the following:

- Is it showing a `no license specified` error for a crate you&#039;ve created? If so, add `publish = false` under `[package]` in your crate&#039;s Cargo.toml.
- Is the error `failed to satisfy license requirements` for a dependency? If so, first determine what license the project has and whether this system is sufficient to comply with this license&#039;s requirements. If you&#039;re unsure, ask a lawyer. Once you&#039;ve verified that this system is acceptable add the license&#039;s SPDX identifier to the `accepted` array in `script/licenses/zed-licenses.toml`.
- Is `cargo-about` unable to find the license for a dependency? If so, add a clarification field at the end of `script/licenses/zed-licenses.toml`, as specified in the [cargo-about book](https://embarkstudios.github.io/cargo-about/cli/generate/config.html#crate-configuration).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[rerun-io/rerun]]></title>
            <link>https://github.com/rerun-io/rerun</link>
            <guid>https://github.com/rerun-io/rerun</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:19 GMT</pubDate>
            <description><![CDATA[Visualize streams of multimodal data. Free, fast, easy to use, and simple to integrate. Built in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rerun-io/rerun">rerun-io/rerun</a></h1>
            <p>Visualize streams of multimodal data. Free, fast, easy to use, and simple to integrate. Built in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 7,957</p>
            <p>Forks: 416</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.rerun.io/&quot;&gt;
    &lt;img alt=&quot;banner&quot; src=&quot;https://user-images.githubusercontent.com/1148717/218142418-1d320929-6b7a-486e-8277-fbeef2432529.png&quot;&gt;
  &lt;/a&gt;
&lt;/h1&gt;

&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pypi.org/project/rerun-sdk/&quot;&gt;                        &lt;img alt=&quot;PyPi&quot;           src=&quot;https://img.shields.io/pypi/v/rerun-sdk.svg&quot;&gt;                              &lt;/a&gt;
  &lt;a href=&quot;https://crates.io/crates/rerun&quot;&gt;                             &lt;img alt=&quot;crates.io&quot;      src=&quot;https://img.shields.io/crates/v/rerun.svg&quot;&gt;                                &lt;/a&gt;
  &lt;a href=&quot;https://github.com/rerun-io/rerun/blob/main/LICENSE-MIT&quot;&gt;    &lt;img alt=&quot;MIT&quot;            src=&quot;https://img.shields.io/badge/license-MIT-blue.svg&quot;&gt;                        &lt;/a&gt;
  &lt;a href=&quot;https://github.com/rerun-io/rerun/blob/main/LICENSE-APACHE&quot;&gt; &lt;img alt=&quot;Apache&quot;         src=&quot;https://img.shields.io/badge/license-Apache-blue.svg&quot;&gt;                     &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/Gcm8BbTaAj&quot;&gt;                              &lt;img alt=&quot;Rerun Discord&quot;  src=&quot;https://img.shields.io/discord/1062300748202921994?label=Rerun%20Discord&quot;&gt; &lt;/a&gt;
&lt;/h1&gt;

# Time-aware multimodal data stack and visualizations
Rerun is building the multimodal data stack to model, ingest, store, query and view robotics-style data.
It&#039;s used in areas like robotics, spatial and embodied AI, generative media, industrial processing, simulation, security, and health.

Rerun is easy to use!
Use the Rerun SDK (available for C++, Python and Rust) to log data like images, tensors, point clouds, and text.
Logs are streamed to the Rerun Viewer for live visualization or to file for later use.
You can also query the logged data through [our dataframe API](https://rerun.io/docs/howto/dataframe-api).

[Get started](#getting-started) in minutes – no account needed.

* [Run the Rerun Viewer in your browser](https://www.rerun.io/viewer)
* [Read about what Rerun is and who it is for](https://www.rerun.io/docs/getting-started/what-is-rerun)

### A short taste
```py
import rerun as rr  # pip install rerun-sdk

rr.init(&quot;rerun_example_app&quot;)

rr.connect()  # Connect to a remote viewer
# rr.spawn()  # Spawn a child process with a viewer and connect
# rr.save(&quot;recording.rrd&quot;)  # Stream all logs to disk

# Associate subsequent data with 42 on the “frame” timeline
rr.set_time(&quot;frame&quot;, sequence=42)

# Log colored 3D points to the entity at `path/to/points`
rr.log(&quot;path/to/points&quot;, rr.Points3D(positions, colors=colors))
…
```

&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;img src=&quot;https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/full.png&quot; alt=&quot;&quot;&gt;
    &lt;source media=&quot;(max-width: 480px)&quot; srcset=&quot;https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/480w.png&quot;&gt;
    &lt;source media=&quot;(max-width: 768px)&quot; srcset=&quot;https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/768w.png&quot;&gt;
    &lt;source media=&quot;(max-width: 1024px)&quot; srcset=&quot;https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/1024w.png&quot;&gt;
    &lt;source media=&quot;(max-width: 1200px)&quot; srcset=&quot;https://static.rerun.io/opf_screenshot/bee51040cba93c0bae62ef6c57fa703704012a41/1200w.png&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

## Getting started
* [**C++**](https://www.rerun.io/docs/getting-started/quick-start/cpp)
* [**Python**](https://www.rerun.io/docs/getting-started/quick-start/python): `pip install rerun-sdk` or on [`conda`](https://github.com/conda-forge/rerun-sdk-feedstock)
* [**Rust**](https://www.rerun.io/docs/getting-started/quick-start/rust): `cargo add rerun`

### Installing the Rerun Viewer binary
To stream log data over the network or load our `.rrd` data files you also need the `rerun` binary.
It can be installed with `pip install rerun-sdk` or with `cargo install rerun-cli --locked --features nasm` (see note below).
Note that only the Python SDK comes bundled with the Viewer whereas C++ &amp; Rust always rely on a separate install.

**Note**: the `nasm` Cargo feature requires the [`nasm`](https://www.nasm.us) CLI to be installed and available in your path.
Alternatively, you may skip enabling this feature, but this may result in inferior video decoding performance.

You should now be able to run `rerun --help` in any terminal.


### Documentation
- 📚 [High-level docs](http://rerun.io/docs)
- ⏃ [Loggable Types](https://www.rerun.io/docs/reference/types)
- ⚙️ [Examples](http://rerun.io/examples)
- 📖 [Code snippets](./docs/snippets/INDEX.md)
- 🌊 [C++ API docs](https://ref.rerun.io/docs/cpp)
- 🐍 [Python API docs](https://ref.rerun.io/docs/python)
- 🦀 [Rust API docs](https://docs.rs/rerun/)
- ⁉️ [Troubleshooting](https://www.rerun.io/docs/getting-started/troubleshooting)


## Status
We are in active development.
There are many features we want to add, and the API is still evolving.
_Expect breaking changes!_

Some shortcomings:
* [Multi-million point clouds are slow](https://github.com/rerun-io/rerun/issues/1136)
* [The viewer slows down when there are too many entities](https://github.com/rerun-io/rerun/issues/7115)
* The data you want to visualize must fit in RAM
  - See &lt;https://www.rerun.io/docs/howto/limit-ram&gt; for how to bound memory use.
  - We plan on having a disk-based data store some time in the future.


## What is Rerun for?

Rerun is built to help you understand and improve complex processes that include rich multimodal data, like 2D, 3D, text, time series, tensors, etc.
It is used in many industries, including robotics, simulation, computer vision,
or anything that involves a lot of sensors or other signals that evolve over time.

### Example use case
Say you&#039;re building a vacuum cleaning robot and it keeps running into walls. Why is it doing that? You need some tool to debug it, but a normal debugger isn&#039;t gonna be helpful. Similarly, just logging text won&#039;t be very helpful either. The robot may log &quot;Going through doorway&quot; but that won&#039;t explain why it thinks the wall is a door.

What you need is a visual and temporal debugger, that can log all the different representations of the world the robots holds in its little head, such as:

* RGB camera feed
* depth images
* lidar scan
* segmentation image (how the robot interprets what it sees)
* its 3D map of the apartment
* all the objects the robot has detected (or thinks it has detected), as 3D shapes in the 3D map
* its confidence in its prediction
* etc

You also want to see how all these streams of data evolve over time so you can go back and pinpoint exactly what went wrong, when and why.

Maybe it turns out that a glare from the sun hit one of the sensors in the wrong way, confusing the segmentation network leading to bad object detection. Or maybe it was a bug in the lidar scanning code. Or maybe the robot thought it was somewhere else in the apartment, because its odometry was broken. Or it could be one of a thousand other things. Rerun will help you find out!

But seeing the world from the point of the view of the robot is not just for debugging - it will also give you ideas on how to improve the algorithms, new test cases to set up, or datasets to collect. It will also let you explain the brains of the robot to your colleagues, boss, and customers. And so on. Seeing is believing, and an image is worth a thousand words, and multimodal temporal logging is worth a thousand images :)

While seeing and understanding your data is core to making progress in robotics, there is one more thing:
You can also use the data you collected for visualization to create new datasets for training and evaluating the models and algorithms that run on your robot.
Rerun provides query APIs to make it easy to extract clean datasets from your recording for exactly that purpose.

Of course, Rerun is useful for much more than just robots. Any time you have any form of sensors, or 2D or 3D state evolving over time, Rerun is a great tool.


## Business model
Rerun uses an open-core model. Everything in this repository will stay open source and free (both as in beer and as in freedom).

We are also building a commercial data platform.
Right now that is only available for a few select design partners.
[Click here if you&#039;re interested](https://rerun.io/pricing).

The Rerun open source project targets the needs of individual developers.
The commercial product targets the needs specific to teams that build and run computer vision and robotics products.

## How to cite Rerun

When using Rerun in your research, please cite it to acknowledge its contribution to your work. This can be done by
including a reference to Rerun in the software or methods section of your paper.

Suggested citation format:

```bibtex
@software{RerunSDK,
  title = {Rerun: A Visualization SDK for Multimodal Data},
  author = {{Rerun Development Team}},
  url = {https://www.rerun.io},
  version = {insert version number},
  date = {insert date of usage},
  year = {2024},
  publisher = {{Rerun Technologies AB}},
  address = {Online},
  note = {Available from https://www.rerun.io/ and https://github.com/rerun-io/rerun}
}
```

Please replace &quot;insert version number&quot; with the version of Rerun you used and &quot;insert date of usage&quot; with the date(s)
you used the tool in your research.
This citation format helps ensure that Rerun&#039;s development team receives appropriate credit for their work and
facilitates the tool&#039;s discovery by other researchers.

# Development
* [`ARCHITECTURE.md`](ARCHITECTURE.md)
* [`CODE_OF_CONDUCT.md`](CODE_OF_CONDUCT.md)
* [`CODE_STYLE.md`](CODE_STYLE.md)
* [`CONTRIBUTING.md`](CONTRIBUTING.md)
* [`BUILD.md`](BUILD.md)
* [`rerun_py/README.md`](rerun_py/README.md) - instructions for Python SDK
* [`rerun_cpp/README.md`](rerun_cpp/README.md) - instructions for C++ SDK


## Installing a pre-release Python SDK

1. Download the correct `.whl` from [GitHub Releases](https://github.com/rerun-io/rerun/releases)
2. Run `pip install rerun_sdk&lt;…&gt;.whl` (replace `&lt;…&gt;` with the actual filename)
3. Test it: `rerun --version`
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[gitbutlerapp/gitbutler]]></title>
            <link>https://github.com/gitbutlerapp/gitbutler</link>
            <guid>https://github.com/gitbutlerapp/gitbutler</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:18 GMT</pubDate>
            <description><![CDATA[The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/gitbutlerapp/gitbutler">gitbutlerapp/gitbutler</a></h1>
            <p>The GitButler version control client, backed by Git, powered by Tauri/Rust/Svelte</p>
            <p>Language: Rust</p>
            <p>Stars: 14,707</p>
            <p>Forks: 581</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
   &lt;img align=&quot;center&quot; width=&quot;128px&quot; src=&quot;crates/gitbutler-tauri/icons/128x128@2x.png&quot; /&gt;
	&lt;h1 align=&quot;center&quot;&gt;&lt;b&gt;GitButler&lt;/b&gt;&lt;/h1&gt;
	&lt;p align=&quot;center&quot;&gt;
		Git branch management tool, built from the ground up for modern workflows
    &lt;br /&gt;
    &lt;a href=&quot;https://gitbutler.com&quot;&gt;&lt;strong&gt;gitbutler.com »&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;b&gt;Download for &lt;/b&gt;
    macOS (&lt;a href=&quot;https://app.gitbutler.com/downloads/release/darwin/aarch64/dmg&quot;&gt;Apple Silicon&lt;/a&gt; |
      &lt;a href=&quot;https://app.gitbutler.com/downloads/release/darwin/x86_64/dmg&quot;&gt;Intel&lt;/a&gt;) ·
		Linux (&lt;a href=&quot;https://app.gitbutler.com/downloads/release/linux/x86_64/gz&quot;&gt;AppImage&lt;/a&gt; |
       &lt;a href=&quot;https://app.gitbutler.com/downloads/release/linux/x86_64/deb&quot;&gt;deb&lt;/a&gt;)
      ·
		Windows (&lt;a href=&quot;https://app.gitbutler.com/downloads/release/windows/x86_64/msi&quot;&gt;msi&lt;/a&gt;)
    &lt;br /&gt;
    &lt;br /&gt;
    (Unstable Nightly releases can be found &lt;a href=&quot;https://app.gitbutler.com/downloads&quot;&gt;here&lt;/a&gt;)
  &lt;/p&gt;
&lt;/div&gt;

&lt;br/&gt;

![gitbutler_client](https://github.com/gitbutlerapp/gitbutler/assets/16262535/0d180bfd-7a3c-4a66-a923-30534c5a8197)

[![CI][s0]][l0] [![BADGE][s6]][l6] [![TWEET][s1]][l1] [![DISCORD][s2]][l2] [![INSTA][s3]][l3] [![YOUTUBE][s5]][l5]

[s0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml/badge.svg
[l0]: https://github.com/gitbutlerapp/gitbutler/actions/workflows/push.yaml
[s1]: https://img.shields.io/badge/Twitter-black?logo=x&amp;logoColor=white
[l1]: https://twitter.com/intent/follow?screen_name=gitbutler
[s2]: https://img.shields.io/discord/1060193121130000425?label=Discord&amp;color=5865F2
[l2]: https://discord.gg/MmFkmaJ42D
[s3]: https://img.shields.io/badge/Instagram-E4405F?logo=instagram&amp;logoColor=white
[l3]: https://www.instagram.com/gitbutler/
[s5]: https://img.shields.io/youtube/channel/subscribers/UCEwkZIHGqsTGYvX8wgD0LoQ
[l5]: https://www.youtube.com/@gitbutlerapp
[s6]: https://img.shields.io/badge/GitButler-%23B9F4F2?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMzkiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCAzOSAyOCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTI1LjIxNDUgMTIuMTk5N0wyLjg3MTA3IDEuMzg5MTJDMS41NDI5NSAwLjc0NjUzMiAwIDEuNzE0MDYgMCAzLjE4OTQ3VjI0LjgxMDVDMCAyNi4yODU5IDEuNTQyOTUgMjcuMjUzNSAyLjg3MTA3IDI2LjYxMDlMMjUuMjE0NSAxNS44MDAzQzI2LjcxOTcgMTUuMDcyMSAyNi43MTk3IDEyLjkyNzkgMjUuMjE0NSAxMi4xOTk3WiIgZmlsbD0iYmxhY2siLz4KPHBhdGggZD0iTTEzLjc4NTUgMTIuMTk5N0wzNi4xMjg5IDEuMzg5MTJDMzcuNDU3MSAwLjc0NjUzMiAzOSAxLjcxNDA2IDM5IDMuMTg5NDdWMjQuODEwNUMzOSAyNi4yODU5IDM3LjQ1NzEgMjcuMjUzNSAzNi4xMjg5IDI2LjYxMDlMMTMuNzg1NSAxNS44MDAzQzEyLjI4MDMgMTUuMDcyMSAxMi4yODAzIDEyLjkyNzkgMTMuNzg1NSAxMi4xOTk3WiIgZmlsbD0idXJsKCNwYWludDBfcmFkaWFsXzMxMF8xMjkpIi8%2BCjxkZWZzPgo8cmFkaWFsR3JhZGllbnQgaWQ9InBhaW50MF9yYWRpYWxfMzEwXzEyOSIgY3g9IjAiIGN5PSIwIiByPSIxIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIgZ3JhZGllbnRUcmFuc2Zvcm09InRyYW5zbGF0ZSgxNi41NzAxIDE0KSBzY2FsZSgxOS44NjQxIDE5LjgzODMpIj4KPHN0b3Agb2Zmc2V0PSIwLjMwMTA1NiIgc3RvcC1vcGFjaXR5PSIwIi8%2BCjxzdG9wIG9mZnNldD0iMSIvPgo8L3JhZGlhbEdyYWRpZW50Pgo8L2RlZnM%2BCjwvc3ZnPgo%3D
[l6]: https://gitbutler.com/

![Alt](https://repobeats.axiom.co/api/embed/fb23382bcf57c609832661874d3019a43555d6ae.svg &#039;Repobeats analytics for GitButler&#039;)

GitButler is a git client that lets you work on multiple branches at the same time.
It allows you to quickly organize file changes into separate branches while still having them applied to your working directory.
You can then push branches individually to your remote, or directly create pull requests.

In a nutshell, it&#039;s a more flexible version of `git add -p` and `git rebase -i`, allowing you to efficiently multitask across branches.

## How Does It Work?

GitButler keeps track of uncommitted changes in a layer on top of Git. Changes to files or parts of files can be grouped into what we call virtual branches. Whenever you are happy with the contents of a virtual branch, you can push it to a remote. GitButler makes sure that the state of other virtual branches is kept separate.

## How Do GB&#039;s Virtual Branches Differ From Git Branches?

The branches that we know and love in Git are separate universes, and switching between them is a full context switch. GitButler allows you to work with multiple branches in parallel in the same working directory. This effectively means having the content of multiple branches available at the same time.

GitButler is aware of changes before they are committed. This allows it to keep a record of which virtual branch each individual diff belongs to. Effectively, this means that you can separate out individual branches with their content at any time to push them to a remote or to unapply them from your working directory.

And finally, while in Git it is preferable that you create your desired branch ahead of time, using GitButler you can move changes between virtual branches at any point during development.

## Why GitButler?

We love Git. Our own [@schacon](https://github.com/schacon) has even published the [Pro Git](https://git-scm.com/book/en/v2) book. At the same time, Git&#039;s user interface hasn&#039;t been fundamentally changed for 15 years. While it was written for Linux kernel devs sending patches to each other over mailing lists, most developers today have different workflows and needs.

Instead of trying to fit the semantics of the Git CLI into a graphical interface, we are starting with the developer workflow and mapping it back to Git.

## Tech

GitButler is a [Tauri](https://tauri.app/)-based application. Its UI is written in [Svelte](https://svelte.dev/) using [TypeScript](https://www.typescriptlang.org) and its backend is written in [Rust](https://www.rust-lang.org/).

## Main Features

- **Virtual Branches**
  - Organize work on multiple branches simultaneously, rather than constantly switching branches
  - Automatically create new branches when needed
- **Easy Commit Management**
  - Undo, Amend and Squash commits by dragging and dropping
- **Undo Timeline**
  - Logs all operations and changes and allows you to easily undo or revert any operation
- **GitHub Integration**
  - Authenticate to GitHub to open Pull Requests, list branches and statuses and more
- **Easy SSH Key Management**
  - GitButler can generate an SSH key to upload to GitHub automatically
- **AI Tooling**
  - Automatically write commit messages based on your work in progress
  - Automatically create descriptive branch names
- **Commit Signing**
  - Easy commit signing with GPG or SSH

## Example Uses

### Fixing a Bug While Working on a Feature

&gt; Say that while developing a feature, you encounter a bug that you wish to fix. It&#039;s often desirable that you ship the fix as a separate contribution (Pull request).

Using Git you can stash your changes and switch to another branch, where you can commit, and push your fix.

_With GitButler_ you simply assign your fix to a separate virtual branch, which you can individually push (or directly create a PR). An additional benefit is that you can retain the fix in your working directory while waiting for CI and/or code review.

### Trying Someone Else&#039;s Branch Together With My Work in Progress

&gt; Say you want to test a branch from someone else for the purpose of code review.

Using Git trying out someone else&#039;s branch is a full context switch away from your own work.
_With GitButler_ you can apply and unapply (add / remove) any remote branch directly into your working directory.

## Documentation

You can find our end user documentation at: https://docs.gitbutler.com

## Bugs and Feature Requests

If you have a bug or feature request, feel free to open an [issue](https://github.com/gitbutlerapp/gitbutler/issues/new),
or [join our Discord server](https://discord.gg/MmFkmaJ42D).

## AI Commit Message Generation

Commit message generation is an opt-in feature. You can enable it while adding your repository for the first time or later in the project settings.

Currently, GitButler uses OpenAI&#039;s API for diff summarization, which means that if enabled, code diffs would be sent to OpenAI&#039;s servers.

Our goal is to make this feature more modular such that in the future you can modify the prompt as well as plug a different LLM endpoints (including local ones).

## Contributing

So you want to help out? Please check out the [CONTRIBUTING.md](CONTRIBUTING.md)
document.

If you want to skip right to getting the code to actually compile, take a look
at the [DEVELOPMENT.md](DEVELOPMENT.md) file.

Want to show your support? Add a GitButler badge to your project&#039;s README:

```md
[![GitButler](https://img.shields.io/badge/GitButler-%23B9F4F2?logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMzkiIGhlaWdodD0iMjgiIHZpZXdCb3g9IjAgMCAzOSAyOCIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTI1LjIxNDUgMTIuMTk5N0wyLjg3MTA3IDEuMzg5MTJDMS41NDI5NSAwLjc0NjUzMiAwIDEuNzE0MDYgMCAzLjE4OTQ3VjI0LjgxMDVDMCAyNi4yODU5IDEuNTQyOTUgMjcuMjUzNSAyLjg3MTA3IDI2LjYxMDlMMjUuMjE0NSAxNS44MDAzQzI2LjcxOTcgMTUuMDcyMSAyNi43MTk3IDEyLjkyNzkgMjUuMjE0NSAxMi4xOTk3WiIgZmlsbD0iYmxhY2siLz4KPHBhdGggZD0iTTEzLjc4NTUgMTIuMTk5N0wzNi4xMjg5IDEuMzg5MTJDMzcuNDU3MSAwLjc0NjUzMiAzOSAxLjcxNDA2IDM5IDMuMTg5NDdWMjQuODEwNUMzOSAyNi4yODU5IDM3LjQ1NzEgMjcuMjUzNSAzNi4xMjg5IDI2LjYxMDlMMTMuNzg1NSAxNS44MDAzQzEyLjI4MDMgMTUuMDcyMSAxMi4yODAzIDEyLjkyNzkgMTMuNzg1NSAxMi4xOTk3WiIgZmlsbD0idXJsKCNwYWludDBfcmFkaWFsXzMxMF8xMjkpIi8%2BCjxkZWZzPgo8cmFkaWFsR3JhZGllbnQgaWQ9InBhaW50MF9yYWRpYWxfMzEwXzEyOSIgY3g9IjAiIGN5PSIwIiByPSIxIiBncmFkaWVudFVuaXRzPSJ1c2VyU3BhY2VPblVzZSIgZ3JhZGllbnRUcmFuc2Zvcm09InRyYW5zbGF0ZSgxNi41NzAxIDE0KSBzY2FsZSgxOS44NjQxIDE5LjgzODMpIj4KPHN0b3Agb2Zmc2V0PSIwLjMwMTA1NiIgc3RvcC1vcGFjaXR5PSIwIi8%2BCjxzdG9wIG9mZnNldD0iMSIvPgo8L3JhZGlhbEdyYWRpZW50Pgo8L2RlZnM%2BCjwvc3ZnPgo%3D)](https://gitbutler.com/)
```

[![BADGE][s6]][l6]
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[sharkdp/hyperfine]]></title>
            <link>https://github.com/sharkdp/hyperfine</link>
            <guid>https://github.com/sharkdp/hyperfine</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:17 GMT</pubDate>
            <description><![CDATA[A command-line benchmarking tool]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sharkdp/hyperfine">sharkdp/hyperfine</a></h1>
            <p>A command-line benchmarking tool</p>
            <p>Language: Rust</p>
            <p>Stars: 24,511</p>
            <p>Forks: 389</p>
            <p>Stars today: 96 stars today</p>
            <h2>README</h2><pre># hyperfine
[![CICD](https://github.com/sharkdp/hyperfine/actions/workflows/CICD.yml/badge.svg)](https://github.com/sharkdp/hyperfine/actions/workflows/CICD.yml)
[![Version info](https://img.shields.io/crates/v/hyperfine.svg)](https://crates.io/crates/hyperfine)
[中文](https://github.com/chinanf-boy/hyperfine-zh)

A command-line benchmarking tool.

**Demo**: Benchmarking [`fd`](https://github.com/sharkdp/fd) and
[`find`](https://www.gnu.org/software/findutils/):

![hyperfine](https://i.imgur.com/z19OYxE.gif)

### Sponsors

A special *thank you* goes to our biggest &lt;a href=&quot;doc/sponsors.md&quot;&gt;sponsor&lt;/a&gt;:&lt;br&gt;

&lt;a href=&quot;https://www.warp.dev/hyperfine&quot;&gt;
  &lt;img src=&quot;doc/sponsors/warp-logo.png&quot; width=&quot;200&quot; alt=&quot;Warp&quot;&gt;
  &lt;br&gt;
  &lt;strong&gt;Warp, the intelligent terminal&lt;/strong&gt;
  &lt;br&gt;
  &lt;sub&gt;Available on MacOS, Linux, Windows&lt;/sub&gt;
&lt;/a&gt;

## Features

* Statistical analysis across multiple runs.
* Support for arbitrary shell commands.
* Constant feedback about the benchmark progress and current estimates.
* Warmup runs can be executed before the actual benchmark.
* Cache-clearing commands can be set up before each timing run.
* Statistical outlier detection to detect interference from other programs and caching effects.
* Export results to various formats: CSV, JSON, Markdown, AsciiDoc.
* Parameterized benchmarks (e.g. vary the number of threads).
* Cross-platform

## Usage

### Basic benchmarks

To run a benchmark, you can simply call `hyperfine &lt;command&gt;...`. The argument(s) can be any
shell command. For example:
```sh
hyperfine &#039;sleep 0.3&#039;
```

Hyperfine will automatically determine the number of runs to perform for each command. By default,
it will perform *at least* 10 benchmarking runs and measure for at least 3 seconds. To change this,
you can use the `-r`/`--runs` option:
```sh
hyperfine --runs 5 &#039;sleep 0.3&#039;
```

If you want to compare the runtimes of different programs, you can pass multiple commands:
```sh
hyperfine &#039;hexdump file&#039; &#039;xxd file&#039;
```

### Warmup runs and preparation commands

For programs that perform a lot of disk I/O, the benchmarking results can be heavily influenced
by disk caches and whether they are cold or warm.

If you want to run the benchmark on a warm cache, you can use the `-w`/`--warmup` option to
perform a certain number of program executions before the actual benchmark:
```sh
hyperfine --warmup 3 &#039;grep -R TODO *&#039;
```

Conversely, if you want to run the benchmark for a cold cache, you can use the `-p`/`--prepare`
option to run a special command before *each* timing run. For example, to clear harddisk caches
on Linux, you can run
```sh
sync; echo 3 | sudo tee /proc/sys/vm/drop_caches
```
To use this specific command with hyperfine, call `sudo -v` to temporarily gain sudo permissions
and then call:
```sh
hyperfine --prepare &#039;sync; echo 3 | sudo tee /proc/sys/vm/drop_caches&#039; &#039;grep -R TODO *&#039;
```

### Parameterized benchmarks

If you want to run a series of benchmarks where a single parameter is varied (say, the number of
threads), you can use the `-P`/`--parameter-scan` option and call:
```sh
hyperfine --prepare &#039;make clean&#039; --parameter-scan num_threads 1 12 &#039;make -j {num_threads}&#039;
```
This also works with decimal numbers. The `-D`/`--parameter-step-size` option can be used
to control the step size:
```sh
hyperfine --parameter-scan delay 0.3 0.7 -D 0.2 &#039;sleep {delay}&#039;
```
This runs `sleep 0.3`, `sleep 0.5` and `sleep 0.7`.

For non-numeric parameters, you can also supply a list of values with the `-L`/`--parameter-list`
option:
```
hyperfine -L compiler gcc,clang &#039;{compiler} -O2 main.cpp&#039;
```

### Intermediate shell

By default, commands are executed using a predefined shell (`/bin/sh` on Unix, `cmd.exe` on Windows).
If you want to use a different shell, you can use the `-S, --shell &lt;SHELL&gt;` option:
```sh
hyperfine --shell zsh &#039;for i in {1..10000}; do echo test; done&#039;
```

Note that hyperfine always *corrects for the shell spawning time*. To do this, it performs a calibration
procedure where it runs the shell with an empty command (multiple times), to measure the startup time
of the shell. It will then subtract this time from the total to show the actual time used by the command
in question.

If you want to run a benchmark *without an intermediate shell*, you can use the `-N` or `--shell=none`
option. This is helpful for very fast commands (&lt; 5 ms) where the shell startup overhead correction would
produce a significant amount of noise. Note that you cannot use shell syntax like `*` or `~` in this case.
```
hyperfine -N &#039;grep TODO /home/user&#039;
```


### Shell functions and aliases

If you are using bash, you can export shell functions to directly benchmark them with hyperfine:

```bash
my_function() { sleep 1; }
export -f my_function
hyperfine --shell=bash my_function
```

Otherwise, inline them into or source them from the benchmarked program:

```sh
hyperfine &#039;my_function() { sleep 1; }; my_function&#039;

echo &#039;alias my_alias=&quot;sleep 1&quot;&#039; &gt; /tmp/my_alias.sh
hyperfine &#039;. /tmp/my_alias.sh; my_alias&#039;
```

### Exporting results

Hyperfine has multiple options for exporting benchmark results to CSV, JSON, Markdown and other
formats (see `--help` text for details).

#### Markdown

You can use the `--export-markdown &lt;file&gt;` option to create tables like the following:

| Command | Mean [s] | Min [s] | Max [s] | Relative |
|:---|---:|---:|---:|---:|
| `find . -iregex &#039;.*[0-9]\.jpg$&#039;` | 2.275 ± 0.046 | 2.243 | 2.397 | 9.79 ± 0.22 |
| `find . -iname &#039;*[0-9].jpg&#039;` | 1.427 ± 0.026 | 1.405 | 1.468 | 6.14 ± 0.13 |
| `fd -HI &#039;.*[0-9]\.jpg$&#039;` | 0.232 ± 0.002 | 0.230 | 0.236 | 1.00 |

#### JSON

The JSON output is useful if you want to analyze the benchmark results in more detail. The
[`scripts/`](https://github.com/sharkdp/hyperfine/tree/master/scripts) folder includes a lot
of helpful Python programs to further analyze benchmark results and create helpful
visualizations, like a histogram of runtimes or a whisker plot to compare
multiple benchmarks:

| ![](doc/histogram.png) | ![](doc/whisker.png) |
|---:|---:|


### Detailed benchmark flowchart

The following chart explains the execution order of various timing runs when using options
like `--warmup`, `--prepare &lt;cmd&gt;`, `--setup &lt;cmd&gt;` or `--cleanup &lt;cmd&gt;`:

![](doc/execution-order.png)

## Installation

[![Packaging status](https://repology.org/badge/vertical-allrepos/hyperfine.svg?columns=3&amp;exclude_unsupported=1)](https://repology.org/project/hyperfine/versions)

### On Ubuntu

Download the appropriate `.deb` package from the [Release page](https://github.com/sharkdp/hyperfine/releases)
and install it via `dpkg`:
```
wget https://github.com/sharkdp/hyperfine/releases/download/v1.19.0/hyperfine_1.19.0_amd64.deb
sudo dpkg -i hyperfine_1.19.0_amd64.deb
```

### On Fedora

On Fedora, hyperfine can be installed from the official repositories:

```sh
dnf install hyperfine
```

### On Alpine Linux

On Alpine Linux, hyperfine can be installed [from the official repositories](https://pkgs.alpinelinux.org/packages?name=hyperfine):
```
apk add hyperfine
```

### On Arch Linux

On Arch Linux, hyperfine can be installed [from the official repositories](https://archlinux.org/packages/extra/x86_64/hyperfine/):
```
pacman -S hyperfine
```

### On Debian Linux

On Debian Linux, hyperfine can be installed [from the testing repositories](https://packages.debian.org/testing/main/hyperfine):
```
apt install hyperfine
```

### On Exherbo Linux

On Exherbo Linux, hyperfine can be installed [from the rust repositories](https://gitlab.exherbo.org/exherbo/rust/-/tree/master/packages/sys-apps/hyperfine):
```
cave resolve -x repository/rust
cave resolve -x hyperfine
```

### On Funtoo Linux

On Funtoo Linux, hyperfine can be installed [from core-kit](https://github.com/funtoo/core-kit/tree/1.4-release/app-benchmarks/hyperfine):
```
emerge app-benchmarks/hyperfine
```

### On NixOS

On NixOS, hyperfine can be installed [from the official repositories](https://nixos.org/nixos/packages.html?query=hyperfine):
```
nix-env -i hyperfine
```

### On Flox

On Flox, hyperfine can be installed as follows.
```
flox install hyperfine
```
Hyperfine&#039;s version in Flox follows that of Nix.

### On openSUSE

On openSUSE, hyperfine can be installed [from the official repositories](https://software.opensuse.org/package/hyperfine):
```
zypper install hyperfine
```

### On Void Linux

Hyperfine can be installed via xbps

```
xbps-install -S hyperfine
```

### On macOS

Hyperfine can be installed via [Homebrew](https://brew.sh):
```
brew install hyperfine
```

Or you can install using [MacPorts](https://www.macports.org):
```
sudo port selfupdate
sudo port install hyperfine
```

### On FreeBSD

Hyperfine can be installed via pkg:
```
pkg install hyperfine
```

### On OpenBSD

```
doas pkg_add hyperfine
```

### On Windows

Hyperfine can be installed via [Chocolatey](https://community.chocolatey.org/packages/hyperfine), [Scoop](https://scoop.sh/#/apps?q=hyperfine&amp;s=0&amp;d=1&amp;o=true&amp;id=8f7c10f75ecf5f9e42a862c615257328e2f70f61), or [Winget](https://github.com/microsoft/winget-pkgs/tree/master/manifests/s/sharkdp/hyperfine):
```
choco install hyperfine
```
```
scoop install hyperfine
```
```
winget install hyperfine
```

### With conda

Hyperfine can be installed via [`conda`](https://conda.io/en/latest/) from the [`conda-forge`](https://anaconda.org/conda-forge/hyperfine) channel:
```
conda install -c conda-forge hyperfine
```

### With cargo (Linux, macOS, Windows)

Hyperfine can be installed from source via [cargo](https://doc.rust-lang.org/cargo/):
```
cargo install --locked hyperfine
```

Make sure that you use Rust 1.76 or newer.

### From binaries (Linux, macOS, Windows)

Download the corresponding archive from the [Release page](https://github.com/sharkdp/hyperfine/releases).

## Alternative tools

Hyperfine is inspired by [bench](https://github.com/Gabriella439/bench).

## Integration with other tools

[Chronologer](https://github.com/dandavison/chronologer) is a tool that uses `hyperfine` to
visualize changes in benchmark timings across your Git history.

[Bencher](https://github.com/bencherdev/bencher) is a continuous benchmarking tool that supports `hyperfine` to
track benchmarks and catch performance regressions in CI.

Drop hyperfine JSON outputs onto the [Venz](https://try.venz.dev) chart to visualize the results,
and manage hyperfine configurations.

Make sure to check out the [`scripts` folder](https://github.com/sharkdp/hyperfine/tree/master/scripts)
in this repository for a set of tools to work with `hyperfine` benchmark results.

## Origin of the name

The name *hyperfine* was chosen in reference to the hyperfine levels of caesium 133 which play a crucial role in the
[definition of our base unit of time](https://en.wikipedia.org/wiki/Second#History_of_definition)
— the second.

## Citing hyperfine

Thank you for considering to cite hyperfine in your research work. Please see the information
in the sidebar on how to properly cite hyperfine.

## License

`hyperfine` is dual-licensed under the terms of the MIT License and the Apache License 2.0.

See the [LICENSE-APACHE](LICENSE-APACHE) and [LICENSE-MIT](LICENSE-MIT) files for details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nushell/nushell]]></title>
            <link>https://github.com/nushell/nushell</link>
            <guid>https://github.com/nushell/nushell</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:16 GMT</pubDate>
            <description><![CDATA[A new type of shell]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nushell/nushell">nushell/nushell</a></h1>
            <p>A new type of shell</p>
            <p>Language: Rust</p>
            <p>Stars: 34,390</p>
            <p>Forks: 1,776</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre># Nushell &lt;!-- omit in toc --&gt;
[![Crates.io](https://img.shields.io/crates/v/nu.svg)](https://crates.io/crates/nu)
[![Build Status](https://img.shields.io/github/actions/workflow/status/nushell/nushell/ci.yml?branch=main)](https://github.com/nushell/nushell/actions)
[![Nightly Build](https://github.com/nushell/nushell/actions/workflows/nightly-build.yml/badge.svg)](https://github.com/nushell/nushell/actions/workflows/nightly-build.yml)
[![Discord](https://img.shields.io/discord/601130461678272522.svg?logo=discord)](https://discord.gg/NtAbbGn)
[![The Changelog #363](https://img.shields.io/badge/The%20Changelog-%23363-61c192.svg)](https://changelog.com/podcast/363)
[![GitHub commit activity](https://img.shields.io/github/commit-activity/m/nushell/nushell)](https://github.com/nushell/nushell/graphs/commit-activity)
[![GitHub contributors](https://img.shields.io/github/contributors/nushell/nushell)](https://github.com/nushell/nushell/graphs/contributors)

A new type of shell.

![Example of nushell](assets/nushell-autocomplete6.gif &quot;Example of nushell&quot;)

## Table of Contents &lt;!-- omit in toc --&gt;

- [Status](#status)
- [Learning About Nu](#learning-about-nu)
- [Installation](#installation)
- [Configuration](#configuration)
- [Philosophy](#philosophy)
  - [Pipelines](#pipelines)
  - [Opening files](#opening-files)
  - [Plugins](#plugins)
- [Goals](#goals)
- [Officially Supported By](#officially-supported-by)
- [Contributing](#contributing)
- [License](#license)

## Status

This project has reached a minimum-viable-product level of quality. Many people use it as their daily driver, but it may be unstable for some commands. Nu&#039;s design is subject to change as it matures.

## Learning About Nu

The [Nushell book](https://www.nushell.sh/book/) is the primary source of Nushell documentation. You can find [a full list of Nu commands in the book](https://www.nushell.sh/commands/), and we have many examples of using Nu in our [cookbook](https://www.nushell.sh/cookbook/).

We&#039;re also active on [Discord](https://discord.gg/NtAbbGn); come and chat with us!

## Installation

To quickly install Nu:

```bash
# Linux and macOS
brew install nushell
# Windows
winget install nushell
```

To use `Nu` in GitHub Action, check [setup-nu](https://github.com/marketplace/actions/setup-nu) for more detail.

Detailed installation instructions can be found in the [installation chapter of the book](https://www.nushell.sh/book/installation.html). Nu is available via many package managers:

[![Packaging status](https://repology.org/badge/vertical-allrepos/nushell.svg?columns=3)](https://repology.org/project/nushell/versions)

For details about which platforms the Nushell team actively supports, see [our platform support policy](devdocs/PLATFORM_SUPPORT.md).

## Configuration

The default configurations can be found at [sample_config](crates/nu-utils/src/default_files)
which are the configuration files one gets when they startup Nushell for the first time.

It sets all of the default configuration to run Nushell.  From here one can
then customize this file for their specific needs.

To see where *config.nu* is located on your system simply type this command.

```rust
$nu.config-path
```

Please see our [book](https://www.nushell.sh) for all of the Nushell documentation.


## Philosophy

Nu draws inspiration from projects like PowerShell, functional programming languages, and modern CLI tools.
Rather than thinking of files and data as raw streams of text, Nu looks at each input as something with structure.
For example, when you list the contents of a directory what you get back is a table of rows, where each row represents an item in that directory.
These values can be piped through a series of steps, in a series of commands called a &#039;pipeline&#039;.

### Pipelines

In Unix, it&#039;s common to pipe between commands to split up a sophisticated command over multiple steps.
Nu takes this a step further and builds heavily on the idea of _pipelines_.
As in the Unix philosophy, Nu allows commands to output to stdout and read from stdin.
Additionally, commands can output structured data (you can think of this as a third kind of stream).
Commands that work in the pipeline fit into one of three categories:

-   Commands that produce a stream (e.g., `ls`)
-   Commands that filter a stream (e.g., `where type == &quot;dir&quot;`)
-   Commands that consume the output of the pipeline (e.g., `table`)

Commands are separated by the pipe symbol (`|`) to denote a pipeline flowing left to right.

```shell
ls | where type == &quot;dir&quot; | table
# =&gt; ╭────┬──────────┬──────┬─────────┬───────────────╮
# =&gt; │ #  │   name   │ type │  size   │   modified    │
# =&gt; ├────┼──────────┼──────┼─────────┼───────────────┤
# =&gt; │  0 │ .cargo   │ dir  │     0 B │ 9 minutes ago │
# =&gt; │  1 │ assets   │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  2 │ crates   │ dir  │ 4.0 KiB │ 2 weeks ago   │
# =&gt; │  3 │ docker   │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  4 │ docs     │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  5 │ images   │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  6 │ pkg_mgrs │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  7 │ samples  │ dir  │     0 B │ 2 weeks ago   │
# =&gt; │  8 │ src      │ dir  │ 4.0 KiB │ 2 weeks ago   │
# =&gt; │  9 │ target   │ dir  │     0 B │ a day ago     │
# =&gt; │ 10 │ tests    │ dir  │ 4.0 KiB │ 2 weeks ago   │
# =&gt; │ 11 │ wix      │ dir  │     0 B │ 2 weeks ago   │
# =&gt; ╰────┴──────────┴──────┴─────────┴───────────────╯
```

Because most of the time you&#039;ll want to see the output of a pipeline, `table` is assumed.
We could have also written the above:

```shell
ls | where type == &quot;dir&quot;
```

Being able to use the same commands and compose them differently is an important philosophy in Nu.
For example, we could use the built-in `ps` command to get a list of the running processes, using the same `where` as above.

```shell
ps | where cpu &gt; 0
# =&gt; ╭───┬───────┬───────────┬───────┬───────────┬───────────╮
# =&gt; │ # │  pid  │   name    │  cpu  │    mem    │  virtual  │
# =&gt; ├───┼───────┼───────────┼───────┼───────────┼───────────┤
# =&gt; │ 0 │  2240 │ Slack.exe │ 16.40 │ 178.3 MiB │ 232.6 MiB │
# =&gt; │ 1 │ 16948 │ Slack.exe │ 16.32 │ 205.0 MiB │ 197.9 MiB │
# =&gt; │ 2 │ 17700 │ nu.exe    │  3.77 │  26.1 MiB │   8.8 MiB │
# =&gt; ╰───┴───────┴───────────┴───────┴───────────┴───────────╯
```

### Opening files

Nu can load file and URL contents as raw text or structured data (if it recognizes the format).
For example, you can load a .toml file as structured data and explore it:

```shell
open Cargo.toml
# =&gt; ╭──────────────────┬────────────────────╮
# =&gt; │ bin              │ [table 1 row]      │
# =&gt; │ dependencies     │ {record 25 fields} │
# =&gt; │ dev-dependencies │ {record 8 fields}  │
# =&gt; │ features         │ {record 10 fields} │
# =&gt; │ package          │ {record 13 fields} │
# =&gt; │ patch            │ {record 1 field}   │
# =&gt; │ profile          │ {record 3 fields}  │
# =&gt; │ target           │ {record 3 fields}  │
# =&gt; │ workspace        │ {record 1 field}   │
# =&gt; ╰──────────────────┴────────────────────╯
```

We can pipe this into a command that gets the contents of one of the columns:

```shell
open Cargo.toml | get package
# =&gt; ╭───────────────┬────────────────────────────────────╮
# =&gt; │ authors       │ [list 1 item]                      │
# =&gt; │ default-run   │ nu                                 │
# =&gt; │ description   │ A new type of shell                │
# =&gt; │ documentation │ https://www.nushell.sh/book/       │
# =&gt; │ edition       │ 2018                               │
# =&gt; │ exclude       │ [list 1 item]                      │
# =&gt; │ homepage      │ https://www.nushell.sh             │
# =&gt; │ license       │ MIT                                │
# =&gt; │ metadata      │ {record 1 field}                   │
# =&gt; │ name          │ nu                                 │
# =&gt; │ repository    │ https://github.com/nushell/nushell │
# =&gt; │ rust-version  │ 1.60                               │
# =&gt; │ version       │ 0.72.0                             │
# =&gt; ╰───────────────┴────────────────────────────────────╯
```

And if needed we can drill down further:

```shell
open Cargo.toml | get package.version
# =&gt; 0.72.0
```

### Plugins

Nu supports plugins that offer additional functionality to the shell and follow the same structured data model that built-in commands use. There are a few examples in the `crates/nu_plugins_*` directories.

Plugins are binaries that are available in your path and follow a `nu_plugin_*` naming convention.
These binaries interact with nu via a simple JSON-RPC protocol where the command identifies itself and passes along its configuration, making it available for use.
If the plugin is a filter, data streams to it one element at a time, and it can stream data back in return via stdin/stdout.
If the plugin is a sink, it is given the full vector of final data and is given free reign over stdin/stdout to use as it pleases.

The [awesome-nu repo](https://github.com/nushell/awesome-nu#plugins) lists a variety of nu-plugins while the [showcase repo](https://github.com/nushell/showcase) *shows* off informative blog posts that have been written about Nushell along with videos that highlight technical
topics that have been presented.

## Goals

Nu adheres closely to a set of goals that make up its design philosophy. As features are added, they are checked against these goals.

-   First and foremost, Nu is cross-platform. Commands and techniques should work across platforms and Nu has [first-class support for Windows, macOS, and Linux](devdocs/PLATFORM_SUPPORT.md).

-   Nu ensures compatibility with existing platform-specific executables.

-   Nu&#039;s workflow and tools should have the usability expected of modern software in 2022 (and beyond).

-   Nu views data as either structured or unstructured. It is a structured shell like PowerShell.

-   Finally, Nu views data functionally. Rather than using mutation, pipelines act as a means to load, change, and save data without mutable state.

## Officially Supported By

Please submit an issue or PR to be added to this list.

-   [zoxide](https://github.com/ajeetdsouza/zoxide)
-   [starship](https://github.com/starship/starship)
-   [oh-my-posh](https://ohmyposh.dev)
-   [Couchbase Shell](https://couchbase.sh)
-   [virtualenv](https://github.com/pypa/virtualenv)
-   [atuin](https://github.com/ellie/atuin)
-   [clap](https://github.com/clap-rs/clap/tree/master/clap_complete_nushell)
-   [Dorothy](http://github.com/bevry/dorothy)
-   [Direnv](https://github.com/direnv/direnv/blob/master/docs/hook.md#nushell)
-   [x-cmd](https://x-cmd.com/mod/nu)

## Contributing

See [Contributing](CONTRIBUTING.md) for details. Thanks to all the people who already contributed!

&lt;a href=&quot;https://github.com/nushell/nushell/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contributors-img.web.app/image?repo=nushell/nushell&amp;max=750&amp;columns=20&quot; /&gt;
&lt;/a&gt;

## License

The project is made available under the MIT license. See the `LICENSE` file for more information.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[aws/amazon-q-developer-cli]]></title>
            <link>https://github.com/aws/amazon-q-developer-cli</link>
            <guid>https://github.com/aws/amazon-q-developer-cli</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:15 GMT</pubDate>
            <description><![CDATA[Add autocomplete and AI to your existing terminal on macOS & Linux]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aws/amazon-q-developer-cli">aws/amazon-q-developer-cli</a></h1>
            <p>Add autocomplete and AI to your existing terminal on macOS & Linux</p>
            <p>Language: Rust</p>
            <p>Stars: 155</p>
            <p>Forks: 28</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># Amazon Q Developer for command line Monorepo

The **`amazon-q-developer-cli`** monorepo houses most of the core code for the Amazon Q Developer desktop
app and CLI.

## Installation

To install Amazon Q Developer for command line see the AWS public documentation [here](https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-installing.html).

## Overview

Several projects live here:

- [`autocomplete`](packages/autocomplete/) - The autocomplete react app
- [`dashboard`](packages/dashboard/) - The dashboard react app
- [`figterm`](crates/figterm/) - figterm, our headless terminal/pseudoterminal that
  intercepts the user’s terminal edit buffer.
- [`q_cli`](crates/q_cli/) - the `q` CLI, allows users to interface with Amazon Q Developer from
  the command line
- [`fig_desktop`](crates/fig_desktop/) - the Rust desktop app, uses
  [`tao`](https://docs.rs/tao/latest/tao/)/[`wry`](https://docs.rs/wry/latest/wry/)
  for windowing/webviews
- [`fig_input_method`](crates/fig_input_method/) - The input method used to get cursor
  position on macOS
- [`vscode`](extensions/vscode/) - Contains the VSCode plugin needed
  for the Amazon Q Developer for command line to work in VSCode
- [`jetbrains`](extensions/jetbrains/) - Contains the VSCode plugin
  needed for the Amazon Q Developer for command line to work in Jetbrains IDEs

Other folder to be aware of

- [`build-scripts/`](build-scripts/) - Contains all python scripts to build,
  sign, and test the project on macOS and Linux
- [`crates/`](crates/) - Contains all internal rust crates
- [`packages/`](packages/) - Contains all internal npm packages
- [`proto/`](proto/) -
  [protocol buffer](https://developers.google.com/protocol-buffers/) message
  specification for inter-process communication
- [`tests/`](tests/) - Contain integration tests for the projects

Below is a high level architecture of how the different components of the app and
their IPC:

![architecture](docs/assets/architecture.svg)

## Setup

### Prerequisites

- MacOS
  - Xcode 13 or later
  - Brew

### 1. Clone repo

```bash
git clone https://github.com/aws/amazon-q-for-command-line.git
```

### 2. Install platform dependencies

This is all the dep

For Debian/Ubuntu:

```bash
sudo apt update
sudo apt install build-essential pkg-config jq dpkg curl wget cmake clang libssl-dev libgtk-3-dev libayatana-appindicator3-dev librsvg2-dev libdbus-1-dev libwebkit2gtk-4.1-dev libjavascriptcoregtk-4.1-dev valac libibus-1.0-dev libglib2.0-dev sqlite3 libxdo-dev protobuf-compiler
```

For Arch:

```bash
sudo pacman -Syu
sudo pacman -S --needed webkit2gtk base-devel curl wget openssl appmenu-gtk-module gtk3 libappindicator-gtk3 librsvg libvips cmake jq pkgconf
```

For Fedora:

```bash
sudo dnf check-update
sudo dnf install webkit2gtk3-devel.x86_64 openssl-devel curl wget libappindicator-gtk3 librsvg2-devel jq
sudo dnf group install &quot;C Development Tools and Libraries&quot;
```

For MacOS:

```shell
xcode-select --install
brew install mise pnpm protobuf zsh bash fish shellcheck jq
```

### 2. Install Rust toolchain using [Rustup](https://rustup.rs):

```shell
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
rustup default stable
# for pre-commit hooks the two following commands are required
rustup toolchain install nightly
cargo install typos-cli
```

For MacOS development make sure the right targets are installed:

```bash
rustup target add x86_64-apple-darwin
rustup target add aarch64-apple-darwin
```

### 3. Setup Python and Node using [`mise`](https://mise.jdx.dev)

Add mise integrations to your shell shell

```shell
# zsh
echo &#039;eval &quot;$(mise activate zsh)&quot;&#039; &gt;&gt; &quot;${ZDOTDIR-$HOME}/.zshrc&quot;

# bash
echo &#039;eval &quot;$(mise activate bash)&quot;&#039; &gt;&gt; ~/.bashrc

# fish
echo &#039;mise activate fish | source&#039; &gt;&gt; ~/.config/fish/config.fish
```

Install the Python and Node toolchains using:

```shell
mise trust
mise install
```

### 4. Setup precommit hooks

```shell
# Run `pnpm` in root directory to add pre-commit hooks
pnpm install --ignore-scripts &amp;&amp; pnpm husky install
```

## Security

See [CONTRIBUTING](CONTRIBUTING.md#security-issue-notifications) for more information.

## Licensing

This repo is dual licensed under MIT and Apache 2.0 licenses.

“Amazon Web Services” and all related marks, including logos, graphic designs, and service names, are trademarks or trade dress of AWS in the U.S. and other countries. AWS’s trademarks and trade dress may not be used in connection with any product or service that is not AWS’s, in any manner that is likely to cause confusion among customers, or in any manner that disparages or discredits AWS.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[astral-sh/uv]]></title>
            <link>https://github.com/astral-sh/uv</link>
            <guid>https://github.com/astral-sh/uv</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:14 GMT</pubDate>
            <description><![CDATA[An extremely fast Python package and project manager, written in Rust.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/astral-sh/uv">astral-sh/uv</a></h1>
            <p>An extremely fast Python package and project manager, written in Rust.</p>
            <p>Language: Rust</p>
            <p>Stars: 45,288</p>
            <p>Forks: 1,274</p>
            <p>Stars today: 199 stars today</p>
            <h2>README</h2><pre># uv

[![uv](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/uv/main/assets/badge/v0.json)](https://github.com/astral-sh/uv)
[![image](https://img.shields.io/pypi/v/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/l/uv.svg)](https://pypi.python.org/pypi/uv)
[![image](https://img.shields.io/pypi/pyversions/uv.svg)](https://pypi.python.org/pypi/uv)
[![Actions status](https://github.com/astral-sh/uv/actions/workflows/ci.yml/badge.svg)](https://github.com/astral-sh/uv/actions)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/astral-sh)

An extremely fast Python package and project manager, written in Rust.

&lt;p align=&quot;center&quot;&gt;
  &lt;picture align=&quot;center&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/03aa9163-1c79-4a87-a31d-7a9311ed9310&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
    &lt;img alt=&quot;Shows a bar chart with benchmark results.&quot; src=&quot;https://github.com/astral-sh/uv/assets/1309177/629e59c0-9c6e-4013-9ad4-adb2bcf5080d&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;i&gt;Installing &lt;a href=&quot;https://trio.readthedocs.io/&quot;&gt;Trio&lt;/a&gt;&#039;s dependencies with a warm cache.&lt;/i&gt;
&lt;/p&gt;

## Highlights

- 🚀 A single tool to replace `pip`, `pip-tools`, `pipx`, `poetry`, `pyenv`, `twine`, `virtualenv`,
  and more.
- ⚡️ [10-100x faster](https://github.com/astral-sh/uv/blob/main/BENCHMARKS.md) than `pip`.
- 🗂️ Provides [comprehensive project management](#projects), with a
  [universal lockfile](https://docs.astral.sh/uv/concepts/projects/layout#the-lockfile).
- ❇️ [Runs scripts](#scripts), with support for
  [inline dependency metadata](https://docs.astral.sh/uv/guides/scripts#declaring-script-dependencies).
- 🐍 [Installs and manages](#python-versions) Python versions.
- 🛠️ [Runs and installs](#tools) tools published as Python packages.
- 🔩 Includes a [pip-compatible interface](#the-pip-interface) for a performance boost with a
  familiar CLI.
- 🏢 Supports Cargo-style [workspaces](https://docs.astral.sh/uv/concepts/projects/workspaces) for
  scalable projects.
- 💾 Disk-space efficient, with a [global cache](https://docs.astral.sh/uv/concepts/cache) for
  dependency deduplication.
- ⏬ Installable without Rust or Python via `curl` or `pip`.
- 🖥️ Supports macOS, Linux, and Windows.

uv is backed by [Astral](https://astral.sh), the creators of
[Ruff](https://github.com/astral-sh/ruff).

## Installation

Install uv with our standalone installers:

```bash
# On macOS and Linux.
curl -LsSf https://astral.sh/uv/install.sh | sh
```

```bash
# On Windows.
powershell -ExecutionPolicy ByPass -c &quot;irm https://astral.sh/uv/install.ps1 | iex&quot;
```

Or, from [PyPI](https://pypi.org/project/uv/):

```bash
# With pip.
pip install uv
```

```bash
# Or pipx.
pipx install uv
```

If installed via the standalone installer, uv can update itself to the latest version:

```bash
uv self update
```

See the [installation documentation](https://docs.astral.sh/uv/getting-started/installation/) for
details and alternative installation methods.

## Documentation

uv&#039;s documentation is available at [docs.astral.sh/uv](https://docs.astral.sh/uv).

Additionally, the command line reference documentation can be viewed with `uv help`.

## Features

### Projects

uv manages project dependencies and environments, with support for lockfiles, workspaces, and more,
similar to `rye` or `poetry`:

```console
$ uv init example
Initialized project `example` at `/home/user/example`

$ cd example

$ uv add ruff
Creating virtual environment at: .venv
Resolved 2 packages in 170ms
   Built example @ file:///home/user/example
Prepared 2 packages in 627ms
Installed 2 packages in 1ms
 + example==0.1.0 (from file:///home/user/example)
 + ruff==0.5.0

$ uv run ruff check
All checks passed!

$ uv lock
Resolved 2 packages in 0.33ms

$ uv sync
Resolved 2 packages in 0.70ms
Audited 1 package in 0.02ms
```

See the [project documentation](https://docs.astral.sh/uv/guides/projects/) to get started.

uv also supports building and publishing projects, even if they&#039;re not managed with uv. See the
[publish guide](https://docs.astral.sh/uv/guides/publish/) to learn more.

### Scripts

uv manages dependencies and environments for single-file scripts.

Create a new script and add inline metadata declaring its dependencies:

```console
$ echo &#039;import requests; print(requests.get(&quot;https://astral.sh&quot;))&#039; &gt; example.py

$ uv add --script example.py requests
Updated `example.py`
```

Then, run the script in an isolated virtual environment:

```console
$ uv run example.py
Reading inline script metadata from: example.py
Installed 5 packages in 12ms
&lt;Response [200]&gt;
```

See the [scripts documentation](https://docs.astral.sh/uv/guides/scripts/) to get started.

### Tools

uv executes and installs command-line tools provided by Python packages, similar to `pipx`.

Run a tool in an ephemeral environment using `uvx` (an alias for `uv tool run`):

```console
$ uvx pycowsay &#039;hello world!&#039;
Resolved 1 package in 167ms
Installed 1 package in 9ms
 + pycowsay==0.0.0.2
  &quot;&quot;&quot;

  ------------
&lt; hello world! &gt;
  ------------
   \   ^__^
    \  (oo)\_______
       (__)\       )\/\
           ||----w |
           ||     ||
```

Install a tool with `uv tool install`:

```console
$ uv tool install ruff
Resolved 1 package in 6ms
Installed 1 package in 2ms
 + ruff==0.5.0
Installed 1 executable: ruff

$ ruff --version
ruff 0.5.0
```

See the [tools documentation](https://docs.astral.sh/uv/guides/tools/) to get started.

### Python versions

uv installs Python and allows quickly switching between versions.

Install multiple Python versions:

```console
$ uv python install 3.10 3.11 3.12
Searching for Python versions matching: Python 3.10
Searching for Python versions matching: Python 3.11
Searching for Python versions matching: Python 3.12
Installed 3 versions in 3.42s
 + cpython-3.10.14-macos-aarch64-none
 + cpython-3.11.9-macos-aarch64-none
 + cpython-3.12.4-macos-aarch64-none
```

Download Python versions as needed:

```console
$ uv venv --python 3.12.0
Using Python 3.12.0
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate

$ uv run --python pypy@3.8 -- python --version
Python 3.8.16 (a9dbdca6fc3286b0addd2240f11d97d8e8de187a, Dec 29 2022, 11:45:30)
[PyPy 7.3.11 with GCC Apple LLVM 13.1.6 (clang-1316.0.21.2.5)] on darwin
Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.
&gt;&gt;&gt;&gt;
```

Use a specific Python version in the current directory:

```console
$ uv python pin 3.11
Pinned `.python-version` to `3.11`
```

See the [Python installation documentation](https://docs.astral.sh/uv/guides/install-python/) to get
started.

### The pip interface

uv provides a drop-in replacement for common `pip`, `pip-tools`, and `virtualenv` commands.

uv extends their interfaces with advanced features, such as dependency version overrides,
platform-independent resolutions, reproducible resolutions, alternative resolution strategies, and
more.

Migrate to uv without changing your existing workflows — and experience a 10-100x speedup — with the
`uv pip` interface.

Compile requirements into a platform-independent requirements file:

```console
$ uv pip compile docs/requirements.in \
   --universal \
   --output-file docs/requirements.txt
Resolved 43 packages in 12ms
```

Create a virtual environment:

```console
$ uv venv
Using Python 3.12.3
Creating virtual environment at: .venv
Activate with: source .venv/bin/activate
```

Install the locked requirements:

```console
$ uv pip sync docs/requirements.txt
Resolved 43 packages in 11ms
Installed 43 packages in 208ms
 + babel==2.15.0
 + black==24.4.2
 + certifi==2024.7.4
 ...
```

See the [pip interface documentation](https://docs.astral.sh/uv/pip/index/) to get started.

## Platform support

See uv&#039;s [platform support](https://docs.astral.sh/uv/reference/platforms/) document.

## Versioning policy

See uv&#039;s [versioning policy](https://docs.astral.sh/uv/reference/versioning/) document.

## Contributing

We are passionate about supporting contributors of all levels of experience and would love to see
you get involved in the project. See the
[contributing guide](https://github.com/astral-sh/uv/blob/main/CONTRIBUTING.md) to get started.

## Acknowledgements

uv&#039;s dependency resolver uses [PubGrub](https://github.com/pubgrub-rs/pubgrub) under the hood. We&#039;re
grateful to the PubGrub maintainers, especially [Jacob Finkelman](https://github.com/Eh2406), for
their support.

uv&#039;s Git implementation is based on [Cargo](https://github.com/rust-lang/cargo).

Some of uv&#039;s optimizations are inspired by the great work we&#039;ve seen in [pnpm](https://pnpm.io/),
[Orogene](https://github.com/orogene/orogene), and [Bun](https://github.com/oven-sh/bun). We&#039;ve also
learned a lot from Nathaniel J. Smith&#039;s [Posy](https://github.com/njsmith/posy) and adapted its
[trampoline](https://github.com/njsmith/posy/tree/main/src/trampolines/windows-trampolines/posy-trampoline)
for Windows support.

## License

uv is licensed under either of

- Apache License, Version 2.0, ([LICENSE-APACHE](LICENSE-APACHE) or
  &lt;https://www.apache.org/licenses/LICENSE-2.0&gt;)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;https://opensource.org/licenses/MIT&gt;)

at your option.

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in uv
by you, as defined in the Apache-2.0 license, shall be dually licensed as above, without any
additional terms or conditions.

&lt;div align=&quot;center&quot;&gt;
  &lt;a target=&quot;_blank&quot; href=&quot;https://astral.sh&quot; style=&quot;background:none&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/astral-sh/uv/main/assets/svg/Astral.svg&quot; alt=&quot;Made by Astral&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[paradedb/paradedb]]></title>
            <link>https://github.com/paradedb/paradedb</link>
            <guid>https://github.com/paradedb/paradedb</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:13 GMT</pubDate>
            <description><![CDATA[Postgres for Search and Analytics]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paradedb/paradedb">paradedb/paradedb</a></h1>
            <p>Postgres for Search and Analytics</p>
            <p>Language: Rust</p>
            <p>Stars: 6,872</p>
            <p>Forks: 227</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://paradedb.com&quot;&gt;&lt;img src=&quot;docs/logo/readme.svg&quot; alt=&quot;ParadeDB&quot;&gt;&lt;/a&gt;
&lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;b&gt;Postgres for Search and Analytics&lt;/b&gt; &lt;br /&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://paradedb.com&quot;&gt;Website&lt;/a&gt; &amp;bull;
  &lt;a href=&quot;https://docs.paradedb.com&quot;&gt;Docs&lt;/a&gt; &amp;bull;
  &lt;a href=&quot;https://join.slack.com/t/paradedbcommunity/shared_invite/zt-2lkzdsetw-OiIgbyFeiibd1DG~6wFgTQ&quot;&gt;Community&lt;/a&gt; &amp;bull;
  &lt;a href=&quot;https://paradedb.com/blog/&quot;&gt;Blog&lt;/a&gt; &amp;bull;
  &lt;a href=&quot;https://docs.paradedb.com/changelog/&quot;&gt;Changelog&lt;/a&gt;
&lt;/h3&gt;

---

[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/paradedb)](https://artifacthub.io/packages/search?repo=paradedb)
[![Docker Pulls](https://img.shields.io/docker/pulls/paradedb/paradedb)](https://hub.docker.com/r/paradedb/paradedb)
[![License](https://img.shields.io/github/license/paradedb/paradedb?color=blue)](https://github.com/paradedb/paradedb?tab=AGPL-3.0-1-ov-file#readme)
[![Slack URL](https://img.shields.io/badge/Join%20Slack-purple?logo=slack&amp;link=https%3A%2F%2Fjoin.slack.com%2Ft%2Fparadedbcommunity%2Fshared_invite%2Fzt-2lkzdsetw-OiIgbyFeiibd1DG~6wFgTQ)](https://join.slack.com/t/paradedbcommunity/shared_invite/zt-2lkzdsetw-OiIgbyFeiibd1DG~6wFgTQ)
[![X URL](https://img.shields.io/twitter/url?url=https%3A%2F%2Ftwitter.com%2Fparadedb&amp;label=Follow%20%40paradedb)](https://x.com/paradedb)

[ParadeDB](https://paradedb.com) is an Elasticsearch alternative built on Postgres. We&#039;re modernizing the features of Elasticsearch&#039;s product suite, starting with real-time search and analytics.

## Roadmap

- [x] Search
  - [x] Full-text search with BM25 with [pg_search](https://github.com/paradedb/paradedb/tree/dev/pg_search#overview)
  - [x] Dense and sparse vector search with [pgvector](https://github.com/pgvector/pgvector#pgvector)
  - [ ] Distributed search
- [ ] Analytics
  - [x] Fast analytics over data lakes (i.e. S3) and table formats (i.e. Iceberg) with [pg_analytics](https://github.com/paradedb/pg_analytics)
  - [ ] Column-oriented Postgres table access method

For a detailed roadmap, see the [ParadeDB Roadmap for 2025](https://github.com/orgs/paradedb/discussions/2041).

## Get Started

To get started, please visit our [documentation](https://docs.paradedb.com).

## Deploying ParadeDB

ParadeDB and its extensions can be deployed in one of two ways:

- Docker image based on [Postgres](https://hub.docker.com/_/postgres) ([see deployment instructions](https://docs.paradedb.com/deploy/aws))
- Kubernetes Helm chart based on [CloudNativePG](https://artifacthub.io/packages/helm/cloudnative-pg/cloudnative-pg) ([see deployment instructions](https://docs.paradedb.com/deploy/helm))

For more information, including enterprise features and support, please [contact us by email](mailto:sales@paradedb.com).

### Extensions

You can find prebuilt binaries for the ParadeDB Postgres extensions on Debian 11, 12, Ubuntu 22.04 and 24.04, Red Hat Enterprise Linux 8 and 9, and macOS 14 (Sonoma) and 15 (Sequoia) for Postgres 14+ in the [GitHub Releases](https://github.com/paradedb/paradedb/releases/latest).

ParadeDB supports all versions supported by the PostgreSQL Global Development Group, which includes PostgreSQL 13+, and you can compile the extensions for other versions of Postgres by following the instructions in the respective extension&#039;s README.

### Docker Image

To quickly get a ParadeDB instance up and running, simply pull and run the latest Docker image:

```bash
docker run --name paradedb -e POSTGRES_PASSWORD=password paradedb/paradedb
```

This will start a ParadeDB instance with default user `postgres` and password `password`. You can then connect to the database using `psql`:

```bash
docker exec -it paradedb psql -U postgres
```

To install ParadeDB locally or on-premise, we recommend using our `docker-compose.yml` file. Alternatively, you can pass the appropriate environment variables to the `docker run` command, replacing the &lt;&gt; with your desired values:

```bash
docker run \
  --name paradedb \
  -e POSTGRES_USER=&lt;user&gt; \
  -e POSTGRES_PASSWORD=&lt;password&gt; \
  -e POSTGRES_DB=&lt;dbname&gt; \
  -v paradedb_data:/var/lib/postgresql/data/ \
  -p 5432:5432 \
  -d \
  paradedb/paradedb:latest
```

This will start a ParadeDB instance with non-root user `&lt;user&gt;` and password `&lt;password&gt;`. The `-v` flag enables your ParadeDB data to persist across restarts in a Docker volume named `paradedb_data`.

You can then connect to the database using `psql`:

```bash
docker exec -it paradedb psql -U &lt;user&gt; -d &lt;dbname&gt; -p 5432 -W
```

ParadeDB collects anonymous telemetry to help us understand how many people are using the project. You can opt out of telemetry using configuration variables within Postgres:

```sql
ALTER SYSTEM SET paradedb.pg_search_telemetry TO &#039;off&#039;;
```

### Helm Chart

ParadeDB is also available for Kubernetes via our Helm chart. You can find our Helm chart in the [ParadeDB Helm Chart GitHub repository](https://github.com/paradedb/charts) or download it directly from [Artifact Hub](https://artifacthub.io/packages/helm/paradedb/paradedb).

### ParadeDB Cloud

At the moment, ParadeDB is not available as a managed cloud service. If you are interested in a ParadeDB Cloud service, please let us know by joining our [waitlist](https://form.typeform.com/to/jHkLmIzx).

## Support

If you&#039;re missing a feature or have found a bug, please open a
[GitHub Issue](https://github.com/paradedb/paradedb/issues/new/choose).

To get community support, you can:

- Post a question in the [ParadeDB Slack Community](https://join.slack.com/t/paradedbcommunity/shared_invite/zt-2lkzdsetw-OiIgbyFeiibd1DG~6wFgTQ)
- Ask for help on our [GitHub Discussions](https://github.com/paradedb/paradedb/discussions)

If you need commercial support, please [contact the ParadeDB team](mailto:sales@paradedb.com).

## Contributing

We welcome community contributions, big or small, and are here to guide you along
the way. To get started contributing, check our [first timer issues](https://github.com/paradedb/paradedb/labels/good%20first%20issue)
or message us in the [ParadeDB Community Slack](https://join.slack.com/t/paradedbcommunity/shared_invite/zt-2lkzdsetw-OiIgbyFeiibd1DG~6wFgTQ). Once you contribute, ping us in Slack and we&#039;ll send you some ParadeDB swag!

For more information on how to contribute, please see our
[Contributing Guide](/CONTRIBUTING.md).

This project is released with a [Contributor Code of Conduct](/CODE_OF_CONDUCT.md).
By participating in this project, you agree to follow its terms.

Thank you for helping us make ParadeDB better for everyone :heart:.

## License

ParadeDB is licensed under the [GNU Affero General Public License v3.0](LICENSE) and as commercial software. For commercial licensing, please contact us at [sales@paradedb.com](mailto:sales@paradedb.com).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[dfinity/ic]]></title>
            <link>https://github.com/dfinity/ic</link>
            <guid>https://github.com/dfinity/ic</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:12 GMT</pubDate>
            <description><![CDATA[Internet Computer blockchain source: the client/replica software run by nodes]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/dfinity/ic">dfinity/ic</a></h1>
            <p>Internet Computer blockchain source: the client/replica software run by nodes</p>
            <p>Language: Rust</p>
            <p>Stars: 1,623</p>
            <p>Forks: 339</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[emmett-framework/granian]]></title>
            <link>https://github.com/emmett-framework/granian</link>
            <guid>https://github.com/emmett-framework/granian</guid>
            <pubDate>Fri, 21 Mar 2025 00:05:11 GMT</pubDate>
            <description><![CDATA[A Rust HTTP server for Python applications]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/emmett-framework/granian">emmett-framework/granian</a></h1>
            <p>A Rust HTTP server for Python applications</p>
            <p>Language: Rust</p>
            <p>Stars: 3,263</p>
            <p>Forks: 93</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># Granian

A Rust HTTP server for Python applications built on top of the [Hyper crate](https://github.com/hyperium/hyper).

## Rationale

The main reasons behind Granian design are:

- Have a single, correct HTTP implementation, supporting versions 1, 2 (and eventually 3)
- Provide a single package for several platforms
- Avoid the usual Gunicorn + uvicorn + http-tools dependency composition on unix systems
- Provide stable [performance](https://github.com/emmett-framework/granian/blob/master/benchmarks/README.md) when compared to existing alternatives

## Features

- Supports ASGI/3, [RSGI](https://github.com/emmett-framework/granian/blob/master/docs/spec/RSGI.md) and WSGI interface applications
- Implements HTTP/1 and HTTP/2 protocols
- Supports HTTPS
- Supports Websockets

## Quickstart

You can install Granian using pip:

    $ pip install granian

### ASGI

Create an application in your `main.py`:

```python
async def app(scope, receive, send):
    assert scope[&#039;type&#039;] == &#039;http&#039;

    await send({
        &#039;type&#039;: &#039;http.response.start&#039;,
        &#039;status&#039;: 200,
        &#039;headers&#039;: [
            [b&#039;content-type&#039;, b&#039;text/plain&#039;],
        ],
    })
    await send({
        &#039;type&#039;: &#039;http.response.body&#039;,
        &#039;body&#039;: b&#039;Hello, world!&#039;,
    })
```

and serve it using Granian CLI:

    $ granian --interface asgi main:app

### RSGI

Create an application your `main.py`:

```python
async def app(scope, proto):
    assert scope.proto == &#039;http&#039;

    proto.response_str(
        status=200,
        headers=[
            (&#039;content-type&#039;, &#039;text/plain&#039;)
        ],
        body=&quot;Hello, world!&quot;
    )
```

and serve it using Granian CLI:

    $ granian --interface rsgi main:app

### WSGI

Create an application your `main.py`:

```python
def app(environ, start_response):
    start_response(&#039;200 OK&#039;, [(&#039;content-type&#039;, &#039;text/plain&#039;)])
    return [b&quot;Hello, world!&quot;]
```

and serve it using Granian CLI:

    $ granian --interface wsgi main:app

## Options

You can check all the options provided by Granian with the `--help` command:

```
$ granian --help
Usage: granian [OPTIONS] APP

  APP  Application target to serve.  [required]

Options:
  --host TEXT                     Host address to bind to  [env var:
                                  GRANIAN_HOST; default: (127.0.0.1)]
  --port INTEGER                  Port to bind to.  [env var: GRANIAN_PORT;
                                  default: 8000]
  --interface [asgi|asginl|rsgi|wsgi]
                                  Application interface type  [env var:
                                  GRANIAN_INTERFACE; default: (rsgi)]
  --http [auto|1|2]               HTTP version  [env var: GRANIAN_HTTP;
                                  default: (auto)]
  --ws / --no-ws                  Enable websockets handling  [env var:
                                  GRANIAN_WEBSOCKETS; default: (enabled)]
  --workers INTEGER RANGE         Number of worker processes  [env var:
                                  GRANIAN_WORKERS; default: 1; x&gt;=1]
  --blocking-threads INTEGER RANGE
                                  Number of blocking threads (per worker)
                                  [env var: GRANIAN_BLOCKING_THREADS; x&gt;=1]
  --blocking-threads-idle-timeout INTEGER RANGE
                                  The maximum amount of time in seconds an
                                  idle blocking thread will be kept alive
                                  [env var:
                                  GRANIAN_BLOCKING_THREADS_IDLE_TIMEOUT;
                                  default: 30; 10&lt;=x&lt;=600]
  --runtime-threads INTEGER RANGE
                                  Number of runtime threads (per worker)  [env
                                  var: GRANIAN_RUNTIME_THREADS; default: 1;
                                  x&gt;=1]
  --runtime-blocking-threads INTEGER RANGE
                                  Number of runtime I/O blocking threads (per
                                  worker)  [env var:
                                  GRANIAN_RUNTIME_BLOCKING_THREADS; x&gt;=1]
  --runtime-mode [mt|st]          Runtime mode to use (single/multi threaded)
                                  [env var: GRANIAN_RUNTIME_MODE; default:
                                  (st)]
  --loop [auto|asyncio|rloop|uvloop]
                                  Event loop implementation  [env var:
                                  GRANIAN_LOOP; default: (auto)]
  --task-impl [asyncio|rust]      Async task implementation to use  [env var:
                                  GRANIAN_TASK_IMPL; default: (asyncio)]
  --backlog INTEGER RANGE         Maximum number of connections to hold in
                                  backlog (globally)  [env var:
                                  GRANIAN_BACKLOG; default: 1024; x&gt;=128]
  --backpressure INTEGER RANGE    Maximum number of requests to process
                                  concurrently (per worker)  [env var:
                                  GRANIAN_BACKPRESSURE; default:
                                  (backlog/workers); x&gt;=1]
  --http1-buffer-size INTEGER RANGE
                                  Sets the maximum buffer size for HTTP/1
                                  connections  [env var:
                                  GRANIAN_HTTP1_BUFFER_SIZE; default: 417792;
                                  x&gt;=8192]
  --http1-header-read-timeout INTEGER RANGE
                                  Sets a timeout (in milliseconds) to read
                                  headers  [env var:
                                  GRANIAN_HTTP1_HEADER_READ_TIMEOUT; default:
                                  30000; 1&lt;=x&lt;=60000]
  --http1-keep-alive / --no-http1-keep-alive
                                  Enables or disables HTTP/1 keep-alive  [env
                                  var: GRANIAN_HTTP1_KEEP_ALIVE; default:
                                  (enabled)]
  --http1-pipeline-flush / --no-http1-pipeline-flush
                                  Aggregates HTTP/1 flushes to better support
                                  pipelined responses (experimental)  [env
                                  var: GRANIAN_HTTP1_PIPELINE_FLUSH; default:
                                  (disabled)]
  --http2-adaptive-window / --no-http2-adaptive-window
                                  Sets whether to use an adaptive flow control
                                  for HTTP2  [env var:
                                  GRANIAN_HTTP2_ADAPTIVE_WINDOW; default:
                                  (disabled)]
  --http2-initial-connection-window-size INTEGER RANGE
                                  Sets the max connection-level flow control
                                  for HTTP2  [env var: GRANIAN_HTTP2_INITIAL_C
                                  ONNECTION_WINDOW_SIZE; default: 1048576;
                                  x&gt;=1024]
  --http2-initial-stream-window-size INTEGER RANGE
                                  Sets the `SETTINGS_INITIAL_WINDOW_SIZE`
                                  option for HTTP2 stream-level flow control
                                  [env var:
                                  GRANIAN_HTTP2_INITIAL_STREAM_WINDOW_SIZE;
                                  default: 1048576; x&gt;=1024]
  --http2-keep-alive-interval INTEGER RANGE
                                  Sets an interval (in milliseconds) for HTTP2
                                  Ping frames should be sent to keep a
                                  connection alive  [env var:
                                  GRANIAN_HTTP2_KEEP_ALIVE_INTERVAL;
                                  1&lt;=x&lt;=60000]
  --http2-keep-alive-timeout INTEGER RANGE
                                  Sets a timeout (in seconds) for receiving an
                                  acknowledgement of the HTTP2 keep-alive ping
                                  [env var: GRANIAN_HTTP2_KEEP_ALIVE_TIMEOUT;
                                  default: 20; x&gt;=1]
  --http2-max-concurrent-streams INTEGER RANGE
                                  Sets the SETTINGS_MAX_CONCURRENT_STREAMS
                                  option for HTTP2 connections  [env var:
                                  GRANIAN_HTTP2_MAX_CONCURRENT_STREAMS;
                                  default: 200; x&gt;=10]
  --http2-max-frame-size INTEGER RANGE
                                  Sets the maximum frame size to use for HTTP2
                                  [env var: GRANIAN_HTTP2_MAX_FRAME_SIZE;
                                  default: 16384; x&gt;=1024]
  --http2-max-headers-size INTEGER RANGE
                                  Sets the max size of received header frames
                                  [env var: GRANIAN_HTTP2_MAX_HEADERS_SIZE;
                                  default: 16777216; x&gt;=1]
  --http2-max-send-buffer-size INTEGER RANGE
                                  Set the maximum write buffer size for each
                                  HTTP/2 stream  [env var:
                                  GRANIAN_HTTP2_MAX_SEND_BUFFER_SIZE; default:
                                  409600; x&gt;=1024]
  --log / --no-log                Enable logging  [env var:
                                  GRANIAN_LOG_ENABLED; default: (enabled)]
  --log-level [critical|error|warning|warn|info|debug|notset]
                                  Log level  [env var: GRANIAN_LOG_LEVEL;
                                  default: (info)]
  --log-config FILE               Logging configuration file (json)  [env var:
                                  GRANIAN_LOG_CONFIG]
  --access-log / --no-access-log  Enable access log  [env var:
                                  GRANIAN_LOG_ACCESS_ENABLED; default:
                                  (disabled)]
  --access-log-fmt TEXT           Access log format  [env var:
                                  GRANIAN_LOG_ACCESS_FMT]
  --ssl-certificate FILE          SSL certificate file  [env var:
                                  GRANIAN_SSL_CERTIFICATE]
  --ssl-keyfile FILE              SSL key file  [env var: GRANIAN_SSL_KEYFILE]
  --ssl-keyfile-password TEXT     SSL key password  [env var:
                                  GRANIAN_SSL_KEYFILE_PASSWORD]
  --url-path-prefix TEXT          URL path prefix the app is mounted on  [env
                                  var: GRANIAN_URL_PATH_PREFIX]
  --respawn-failed-workers / --no-respawn-failed-workers
                                  Enable workers respawn on unexpected exit
                                  [env var: GRANIAN_RESPAWN_FAILED_WORKERS;
                                  default: (disabled)]
  --respawn-interval FLOAT        The number of seconds to sleep between
                                  workers respawn  [env var:
                                  GRANIAN_RESPAWN_INTERVAL; default: 3.5]
  --workers-lifetime INTEGER RANGE
                                  The maximum amount of time in seconds a
                                  worker will be kept alive before respawn
                                  [env var: GRANIAN_WORKERS_LIFETIME; x&gt;=60]
  --workers-kill-timeout INTEGER RANGE
                                  The amount of time in seconds to wait for
                                  killing workers that refused to gracefully
                                  stop  [env var:
                                  GRANIAN_WORKERS_KILL_TIMEOUT; default:
                                  (disabled); 1&lt;=x&lt;=1800]
  --factory / --no-factory        Treat target as a factory function, that
                                  should be invoked to build the actual target
                                  [env var: GRANIAN_FACTORY; default:
                                  (disabled)]
  --reload / --no-reload          Enable auto reload on application&#039;s files
                                  changes (requires granian[reload] extra)
                                  [env var: GRANIAN_RELOAD; default:
                                  (disabled)]
  --reload-paths PATH             Paths to watch for changes  [env var:
                                  GRANIAN_RELOAD_PATHS; default: (Working
                                  directory)]
  --reload-ignore-dirs TEXT       Names of directories to ignore changes for.
                                  Extends the default list of directories to
                                  ignore in watchfiles&#039; default filter  [env
                                  var: GRANIAN_RELOAD_IGNORE_DIRS]
  --reload-ignore-patterns TEXT   File/directory name patterns (regex) to
                                  ignore changes for. Extends the default list
                                  of patterns to ignore in watchfiles&#039; default
                                  filter  [env var:
                                  GRANIAN_RELOAD_IGNORE_PATTERNS]
  --reload-ignore-paths PATH      Absolute paths to ignore changes for  [env
                                  var: GRANIAN_RELOAD_IGNORE_PATHS]
  --process-name TEXT             Set a custom name for processes (requires
                                  granian[pname] extra)  [env var:
                                  GRANIAN_PROCESS_NAME]
  --pid-file FILE                 A path to write the PID file to  [env var:
                                  GRANIAN_PID_FILE]
  --version                       Show the version and exit.
  --help                          Show this message and exit.
```

### Logging

Despite being a Rust project, Granian is a good Python citizen and uses the standard library&#039;s [`logging`](https://docs.python.org/3/library/logging.html) module to produce logs. This means you can freely configure your logging level and format using the [standard idioms](https://docs.python.org/3/howto/logging.html) you probably familiar with.

As many other web servers, Granian uses two different loggers, specifically:

- the `_granian` logger for runtime messages
- the `granian.access` logger for access logs

### Access log format

The access log format can be configured by specifying the atoms (see below) to include in a specific format. By default Granian will use `[%(time)s] %(addr)s - &quot;%(method)s %(path)s %(protocol)s&quot; %(status)d %(dt_ms).3f` as the format.

#### Access log atoms

The following atoms are available for use:

| identifier | description |
| --- | --- |
| addr | Client remote address |
| time | Datetime of the request | 
| dt_ms | Request duration in ms |
| status | HTTP response status |
| path | Request path (without query string) |
| query\_string | Request query string |
| method | Request HTTP method |
| scheme | Request scheme |
| protocol | HTTP protocol version |

### Workers and threads

Granian offers different options to configure the number of workers and threads to be run, in particular:

- **workers**: the total number of processes holding a dedicated Python interpreter that will run the application
- **blocking threads**: the number of threads per worker interacting with the Python interpreter
- **runtime threads**: the number of Rust threads per worker that will perform network I/O
- **runtime blocking threads**: the number of Rust threads per worker involved in blocking operations. The main role of these threads is dealing with blocking I/O – like file system operations.

In general, Granian will try its best to automatically pick proper values for the threading configuration, leaving to you the responsibility to choose the number of workers you need.    
There is no *golden rule* here, as these numbers will vastly depend both on your application behavior and the deployment target, but we can list some suggestions:
- matching the amount of CPU cores for the workers is generally the best starting point; on containerized environments like docker or k8s is best to have 1 worker per container though and scale your containers using the relevant orchestrator;
- the default number of runtime threads and runtime blocking threads is fine for the vast majority of applications out there; you might want to increase the first for applications dealing with several concurrently opened websockets, and lowering the second only if you serve the same few files to a lot of connections;

In regards of blocking threads, the option is irrelevant on asynchronous protocols, as all the interop will happen with the AsyncIO event loop which will also be the one holding the GIL for the vast majority of the time, and thus the value is fixed to a single thread; on synchronous protocols like WSGI instead, it will be the maximum amount of threads interacting – and thus trying to acquire the GIL – with your application code. All those threads will be spawned on-demand depending on the amount of concurrency, and they&#039;ll be shutdown after the amount of inactivity time specified with the relevant setting.    
In general, and unless you have a very specific use-case to do so (for example, if your application have an average millisecond response, a very limited amount of blocking threads usually delivers better throughput) you should avoid to tune this threadpool size and configure a backpressure value that suits your needs instead. In that regards, please check the next section.

Also, you should generally avoid to configure workers and threads based on numbers suggested for other servers, as Granian architecture is quite different from projects like Gunicorn or Uvicorn.

### Backpressure

Since Granian runs a separated Rust runtime aside of your application that will handle I/O and &quot;send work&quot; to the Python interpreter, a mechanism to avoid pushing more work that what the Python interpreter can actually do is provided: backpressure.

Backpressure in Granian operates at the single worker&#039;s connections accept loop, practically interrupting the loop in case too many requests are waiting to be processed down the line. You can think of it as _a secondary backlog_, handled by Granian itself in addition to the network stack one provided by the OS kernel (and configured with apposite parameter).

While on asynchronous protocols, the default value for the backpressure should work fine for the vast majority of applications, as _work_ will be handled and suspended by the AsyncIO event loop, on synchronous protocols there&#039;s no way to predict the amount of interrupts (and thus GIL releases) your application would do on a single request, and thus you should configure a value that makes sense in your environment. For example, if your WSGI application never does I/O within a request-reponse flow, then you can&#039;t really go beyond serial, and thus any backpressure value above 2 wouldn&#039;t probably make any difference, as all the requests will just be waiting to acquire the GIL in order to be processed. On the other hand, if your application makes external network requests within the standard request-response flow, a large backpressure can help, as during the time spent on those code paths you can still process other requests. Another example would be if your application communicate with a database, and you have a limited amount of connections that can be opened to that database: in this case setting the backpressure to that value would definitely be the best option.

In general, think of backpressure as the maximum amount of concurrency you want to handle (per worker) in your application, after which Granian will halt and wait before pushing more work.

### Runtime mode

Granian offers two different runtime threading paradigms, due to the fact the runtime can be multi-threaded – in opposition to what happens in Python event-loop which can only run as a single thread.

Given you specify N threads with the relevant option, in **st** mode Granian will spawn N single-threaded Rust runtimes, while in **mt** mode Granian will spawn a single multi-threaded runtime with N threads.

Benchmarks suggests **st** mode to be more efficient with a small amount of processes, while **mt** mode seems to scale more efficiently where you have a large number of CPUs. Real performance will though depend on specific applica

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>