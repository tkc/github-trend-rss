<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for rust - Rust Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for rust.</description>
        <lastBuildDate>Sat, 06 Dec 2025 00:05:45 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[rustfs/rustfs]]></title>
            <link>https://github.com/rustfs/rustfs</link>
            <guid>https://github.com/rustfs/rustfs</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:45 GMT</pubDate>
            <description><![CDATA[üöÄ2.3x faster than MinIO for 4KB object payloads. RustFS is an open-source, S3-compatible high-performance object storage system supporting migration and coexistence with other S3-compatible platforms such as MinIO and Ceph.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rustfs/rustfs">rustfs/rustfs</a></h1>
            <p>üöÄ2.3x faster than MinIO for 4KB object payloads. RustFS is an open-source, S3-compatible high-performance object storage system supporting migration and coexistence with other S3-compatible platforms such as MinIO and Ceph.</p>
            <p>Language: Rust</p>
            <p>Stars: 14,380</p>
            <p>Forks: 630</p>
            <p>Stars today: 657 stars today</p>
            <h2>README</h2><pre>[![RustFS](https://rustfs.com/images/rustfs-github.png)](https://rustfs.com)

&lt;p align=&quot;center&quot;&gt;RustFS is a high-performance, distributed object storage system built in Rust.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/rustfs/rustfs/actions/workflows/ci.yml&quot;&gt;&lt;img alt=&quot;CI&quot; src=&quot;https://github.com/rustfs/rustfs/actions/workflows/ci.yml/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/rustfs/rustfs/actions/workflows/docker.yml&quot;&gt;&lt;img alt=&quot;Build and Push Docker Images&quot; src=&quot;https://github.com/rustfs/rustfs/actions/workflows/docker.yml/badge.svg&quot; /&gt;&lt;/a&gt;
  &lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/m/rustfs/rustfs&quot;/&gt;
  &lt;img alt=&quot;Github Last Commit&quot; src=&quot;https://img.shields.io/github/last-commit/rustfs/rustfs&quot;/&gt;
  &lt;a href=&quot;https://hellogithub.com/repository/rustfs/rustfs&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=b95bcb72bdc340b68f16fdf6790b7d5b&amp;claim_uid=MsbvjYeLDKAH457&amp;theme=small&quot; alt=&quot;FeaturedÔΩúHelloGitHub&quot; /&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.rustfs.com/installation/&quot;&gt;Getting Started&lt;/a&gt;
  ¬∑ &lt;a href=&quot;https://docs.rustfs.com/&quot;&gt;Docs&lt;/a&gt;
  ¬∑ &lt;a href=&quot;https://github.com/rustfs/rustfs/issues&quot;&gt;Bug reports&lt;/a&gt;
  ¬∑ &lt;a href=&quot;https://github.com/rustfs/rustfs/discussions&quot;&gt;Discussions&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
English | &lt;a href=&quot;https://github.com/rustfs/rustfs/blob/main/README_ZH.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=de&quot;&gt;Deutsch&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=es&quot;&gt;Espa√±ol&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=fr&quot;&gt;fran√ßais&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=ja&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=ko&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=pt&quot;&gt;Portuguese&lt;/a&gt; |
  &lt;a href=&quot;https://readme-i18n.com/rustfs/rustfs?lang=ru&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;
&lt;/p&gt;

RustFS is a high-performance, distributed object storage system built in Rust‚Äîone of the most loved programming languages worldwide. RustFS combines the simplicity of MinIO with the memory safety and raw performance of Rust. It offers full S3 compatibility, is completely open-source, and is optimized for data lakes, AI, and big data workloads.

Unlike other storage systems, RustFS is released under the permissible Apache 2.0 license, avoiding the restrictions of AGPL. With Rust as its foundation, RustFS delivers superior speed and secure distributed features for next-generation object storage.

## Feature &amp; Status

- **High Performance**: Built with Rust to ensure maximum speed and resource efficiency.
- **Distributed Architecture**: Scalable and fault-tolerant design suitable for large-scale deployments.
- **S3 Compatibility**: Seamless integration with existing S3-compatible applications and tools.
- **Data Lake Support**: Optimized for high-throughput big data and AI workloads.
- **Open Source**: Licensed under Apache 2.0, encouraging unrestricted community contributions and commercial usage.
- **User-Friendly**: Designed with simplicity in mind for easy deployment and management.

| Feature | Status | Feature | Status |
| :--- | :--- | :--- | :--- |
| **S3 Core Features** | ‚úÖ Available | **Bitrot Protection** | ‚úÖ Available |
| **Upload / Download** | ‚úÖ Available | **Single Node Mode** | ‚úÖ Available |
| **Versioning** | ‚úÖ Available |  **Bucket Replication** | ‚ö†Ô∏è Partial Support |
| **Logging** | ‚úÖ Available |  **Lifecycle Management** | üöß Under Testing |
| **Event Notifications** | ‚úÖ Available |  **Distributed Mode** | üöß Under Testing |
| **K8s Helm Charts** | ‚úÖ Available |  **OPA (Open Policy Agent)** | üöß Under Testing |




## RustFS vs MinIO Performance

**Stress Test Environment:**

| Type    | Parameter | Remark                                                   |
|---------|-----------|----------------------------------------------------------|
| CPU     | 2 Core    | Intel Xeon (Sapphire Rapids) Platinum 8475B, 2.7/3.2 GHz |
| Memory  | 4GB       |                                                          |
| Network | 15Gbps    |                                                          |
| Drive   | 40GB x 4  | IOPS 3800 / Drive                                        |

&lt;https://github.com/user-attachments/assets/2e4979b5-260c-4f2c-ac12-c87fd558072a&gt;

### RustFS vs Other Object Storage

| Feature | RustFS | Other Object Storage |
| :--- | :--- | :--- |
| **Console Experience** | **Powerful Console**&lt;br&gt;Comprehensive management interface. | **Basic / Limited Console**&lt;br&gt;Often overly simple or lacking critical features. |
| **Language &amp; Safety** | **Rust-based**&lt;br&gt;Memory safety by design. | **Go or C-based**&lt;br&gt;Potential for memory GC pauses or leaks. |
| **Data Sovereignty** | **No Telemetry / Full Compliance**&lt;br&gt;Guards against unauthorized cross-border data egress. Compliant with GDPR (EU/UK), CCPA (US), and APPI (Japan). | **Potential Risk**&lt;br&gt;Possible legal exposure and unwanted data telemetry. |
| **Licensing** | **Permissive Apache 2.0**&lt;br&gt;Business-friendly, no &quot;poison pill&quot; clauses. | **Restrictive AGPL v3**&lt;br&gt;Risk of license traps and intellectual property pollution. |
| **Compatibility** | **100% S3 Compatible**&lt;br&gt;Works with any cloud provider or client, anywhere. | **Variable Compatibility**&lt;br&gt;May lack support for local cloud vendors or specific APIs. |
| **Edge &amp; IoT** | **Strong Edge Support**&lt;br&gt;Ideal for secure, innovative edge devices. | **Weak Edge Support**&lt;br&gt;Often too heavy for edge gateways. |
| **Risk Profile** | **Enterprise Risk Mitigation**&lt;br&gt;Clear IP rights and safe for commercial use. | **Legal Risks**&lt;br&gt;Intellectual property ambiguity and usage restrictions. |

## Quickstart

To get started with RustFS, follow these steps:

### 1. One-click Installation (Option 1)

  ```bash
  curl -O https://rustfs.com/install_rustfs.sh &amp;&amp; bash install_rustfs.sh
````

### 2\. Docker Quick Start (Option 2)

The RustFS container runs as a non-root user `rustfs` (UID `10001`). If you run Docker with `-v` to mount a host directory, please ensure the host directory owner is set to `10001`, otherwise you will encounter permission denied errors.

```bash
 # Create data and logs directories
 mkdir -p data logs

 # Change the owner of these directories
 chown -R 10001:10001 data logs

 # Using latest version
 docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:latest

 # Using specific version
 docker run -d -p 9000:9000 -p 9001:9001 -v $(pwd)/data:/data -v $(pwd)/logs:/logs rustfs/rustfs:1.0.0.alpha.68
```

You can also use Docker Compose. Using the `docker-compose.yml` file in the root directory:

```bash
docker compose --profile observability up -d
```

**NOTE**: We recommend reviewing the `docker-compose.yaml` file before running. It defines several services including Grafana, Prometheus, and Jaeger, which are helpful for RustFS observability. If you wish to start Redis or Nginx containers, you can specify the corresponding profiles.

### 3\. Build from Source (Option 3) - Advanced Users

For developers who want to build RustFS Docker images from source with multi-architecture support:

```bash
# Build multi-architecture images locally
./docker-buildx.sh --build-arg RELEASE=latest

# Build and push to registry
./docker-buildx.sh --push

# Build specific version
./docker-buildx.sh --release v1.0.0 --push

# Build for custom registry
./docker-buildx.sh --registry your-registry.com --namespace yourname --push
```

The `docker-buildx.sh` script supports:
\- **Multi-architecture builds**: `linux/amd64`, `linux/arm64`
\- **Automatic version detection**: Uses git tags or commit hashes
\- **Registry flexibility**: Supports Docker Hub, GitHub Container Registry, etc.
\- **Build optimization**: Includes caching and parallel builds

You can also use Make targets for convenience:

```bash
make docker-buildx                    # Build locally
make docker-buildx-push               # Build and push
make docker-buildx-version VERSION=v1.0.0  # Build specific version
make help-docker                      # Show all Docker-related commands
```

&gt; **Heads-up (macOS cross-compilation)**: macOS keeps the default `ulimit -n` at 256, so `cargo zigbuild` or `./build-rustfs.sh --platform ...` may fail with `ProcessFdQuotaExceeded` when targeting Linux. The build script attempts to raise the limit automatically, but if you still see the warning, run `ulimit -n 4096` (or higher) in your shell before building.

### 4\. Build with Helm Chart (Option 4) - Cloud Native

Follow the instructions in the [Helm Chart README](https://charts.rustfs.com/) to install RustFS on a Kubernetes cluster.

-----

### Accessing RustFS

5.  **Access the Console**: Open your web browser and navigate to `http://localhost:9000` to access the RustFS console.
      * Default credentials: `rustfsadmin` / `rustfsadmin`
6.  **Create a Bucket**: Use the console to create a new bucket for your objects.
7.  **Upload Objects**: You can upload files directly through the console or use S3-compatible APIs/clients to interact with your RustFS instance.

**NOTE**: To access the RustFS instance via `https`, please refer to the [TLS Configuration Docs](https://docs.rustfs.com/integration/tls-configured.html).

## Documentation

For detailed documentation, including configuration options, API references, and advanced usage, please visit our [Documentation](https://docs.rustfs.com).

## Getting Help

If you have any questions or need assistance:

  - Check the [FAQ](https://github.com/rustfs/rustfs/discussions/categories/q-a) for common issues and solutions.
  - Join our [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) to ask questions and share your experiences.
  - Open an issue on our [GitHub Issues](https://github.com/rustfs/rustfs/issues) page for bug reports or feature requests.

## Links

  - [Documentation](https://docs.rustfs.com) - The manual you should read
  - [Changelog](https://github.com/rustfs/rustfs/releases) - What we broke and fixed
  - [GitHub Discussions](https://github.com/rustfs/rustfs/discussions) - Where the community lives

## Contact

  - **Bugs**: [GitHub Issues](https://github.com/rustfs/rustfs/issues)
  - **Business**: [hello@rustfs.com](mailto:hello@rustfs.com)
  - **Jobs**: [jobs@rustfs.com](mailto:jobs@rustfs.com)
  - **General Discussion**: [GitHub Discussions](https://github.com/rustfs/rustfs/discussions)
  - **Contributing**: [CONTRIBUTING.md](CONTRIBUTING.md)

## Contributors

RustFS is a community-driven project, and we appreciate all contributions. Check out the [Contributors](https://github.com/rustfs/rustfs/graphs/contributors) page to see the amazing people who have helped make RustFS better.

&lt;a href=&quot;https://github.com/rustfs/rustfs/graphs/contributors&quot;&gt;
&lt;img src=&quot;https://opencollective.com/rustfs/contributors.svg?width=890&amp;limit=500&amp;button=false&quot; alt=&quot;Contributors&quot; /&gt;
&lt;/a&gt;

## Github Trending Top

üöÄ RustFS is beloved by open-source enthusiasts and enterprise users worldwide, often appearing on the GitHub Trending top charts.

&lt;a href=&quot;https://trendshift.io/repositories/14181&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/rustfs/rustfs/refs/heads/main/docs/rustfs-trending.jpg&quot; alt=&quot;rustfs%2Frustfs | Trendshift&quot; /&gt;&lt;/a&gt;

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=rustfs/rustfs&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#rustfs/rustfs&amp;type=date&amp;legend=top-left)

## License

[Apache 2.0](https://opensource.org/licenses/Apache-2.0)

**RustFS** is a trademark of RustFS, Inc. All other trademarks are the property of their respective owners.

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[sinelaw/fresh]]></title>
            <link>https://github.com/sinelaw/fresh</link>
            <guid>https://github.com/sinelaw/fresh</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:44 GMT</pubDate>
            <description><![CDATA[Text editor for your terminal: easy, powerful and fast]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sinelaw/fresh">sinelaw/fresh</a></h1>
            <p>Text editor for your terminal: easy, powerful and fast</p>
            <p>Language: Rust</p>
            <p>Stars: 538</p>
            <p>Forks: 14</p>
            <p>Stars today: 167 stars today</p>
            <h2>README</h2><pre># Fresh

[Visit the official Fresh website](https://sinelaw.github.io/fresh/)

**[üì¶ Installation Instructions](#installation)**

A terminal-based text editor.

## Discovery &amp; Ease of Use

Fresh is designed for discovery. It features native UIs, a full Menu system, and a powerful Command Palette. With full mouse support, transitioning from graphical editors is seamless.

## Modern Extensibility

Extend Fresh easily using modern tools. Plugins are written in TypeScript and run securely in a sandboxed Deno environment, providing access to a modern JavaScript ecosystem without compromising stability.

## Zero-Latency Performance

Fresh is engineered for speed. It delivers a near zero-latency experience, with text appearing instantly. The editor is designed to be light and fast, reliably opening and editing huge files up to multi-gigabyte sizes without slowdown.

## Comprehensive Feature Set

- **File Management**: open/save/new/close, file explorer, tabs, auto-revert, git file finder
- **Editing**: undo/redo, multi-cursor, block selection, smart indent, comments, clipboard
- **Search &amp; Replace**: incremental search, find in selection, query replace, git grep
- **Navigation**: go to line/bracket, word movement, position history, bookmarks, error navigation
- **Views &amp; Layout**: split panes, line numbers, line wrap, backgrounds, markdown preview
- **Language Server (LSP)**: go to definition, references, hover, code actions, rename, diagnostics, autocompletion
- **Productivity**: command palette, menu bar, keyboard macros, git log, diagnostics panel
- **Plugins &amp; Extensibility**: TypeScript plugins, color highlighter, TODO highlighter, merge conflicts, path complete, keymaps

![Fresh Screenshot](docs/screenshot1.png)
![Fresh Screenshot](docs/screenshot2.png)
![Fresh Screenshot](docs/screenshot3.png)

## Installation

| Platform | Method |
|----------|--------|
| macOS | [Homebrew](#macos-homebrew) |
| Arch Linux | [AUR](#arch-linux-aur) |
| Debian/Ubuntu | [.deb](#debianubuntu-deb) |
| Fedora/RHEL | [.rpm](#fedorarhelopensuse-rpm) |
| All platforms | [Pre-built binaries](#pre-built-binaries) |
| npm | [npm / npx](#npm) |
| Rust users | [crates.io](#from-cratesio) |
| Developers | [From source](#from-source) |

### macOS (Homebrew)

```bash
brew tap sinelaw/fresh
brew install fresh-editor
```

### Arch Linux ([AUR](https://aur.archlinux.org/packages/fresh-editor))

```bash
yay -S fresh-editor
```

### Debian/Ubuntu (.deb)

Download the `.deb` file from the [releases page](https://github.com/sinelaw/fresh/releases) and install:

```bash
sudo dpkg -i fresh-editor_*.deb
```

### Fedora/RHEL/openSUSE (.rpm)

Download the `.rpm` file from the [releases page](https://github.com/sinelaw/fresh/releases) and install:

```bash
sudo rpm -i fresh-editor-*.rpm
```

### Pre-built binaries

Download the latest release for your platform from the [releases page](https://github.com/sinelaw/fresh/releases).

### npm

```bash
npm install -g @fresh-editor/fresh-editor
```

Or try it without installing:

```bash
npx @fresh-editor/fresh-editor
```

### From crates.io

```bash
cargo install fresh-editor
```

### From source

```bash
git clone https://github.com/sinelaw/fresh.git
cd fresh
cargo build --release
./target/release/fresh [file]
```

## Documentation

- [User Guide](docs/USER_GUIDE.md)
- [Plugin Development](docs/PLUGIN_DEVELOPMENT.md)
- [Architecture](docs/ARCHITECTURE.md)

## License

Copyright (c) Noam Lewis

This project is licensed under the GNU General Public License v2.0 (GPL-2.0).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[openai/codex]]></title>
            <link>https://github.com/openai/codex</link>
            <guid>https://github.com/openai/codex</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:43 GMT</pubDate>
            <description><![CDATA[Lightweight coding agent that runs in your terminal]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/codex">openai/codex</a></h1>
            <p>Lightweight coding agent that runs in your terminal</p>
            <p>Language: Rust</p>
            <p>Stars: 52,003</p>
            <p>Forks: 6,596</p>
            <p>Stars today: 241 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;&lt;code&gt;npm i -g @openai/codex&lt;/code&gt;&lt;br /&gt;or &lt;code&gt;brew install --cask codex&lt;/code&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;strong&gt;Codex CLI&lt;/strong&gt; is a coding agent from OpenAI that runs locally on your computer.
&lt;/br&gt;
&lt;/br&gt;If you want Codex in your code editor (VS Code, Cursor, Windsurf), &lt;a href=&quot;https://developers.openai.com/codex/ide&quot;&gt;install in your IDE&lt;/a&gt;
&lt;/br&gt;If you are looking for the &lt;em&gt;cloud-based agent&lt;/em&gt; from OpenAI, &lt;strong&gt;Codex Web&lt;/strong&gt;, go to &lt;a href=&quot;https://chatgpt.com/codex&quot;&gt;chatgpt.com/codex&lt;/a&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./.github/codex-cli-splash.png&quot; alt=&quot;Codex CLI splash&quot; width=&quot;80%&quot; /&gt;
  &lt;/p&gt;

---

## Quickstart

### Installing and running Codex CLI

Install globally with your preferred package manager. If you use npm:

```shell
npm install -g @openai/codex
```

Alternatively, if you use Homebrew:

```shell
brew install --cask codex
```

Then simply run `codex` to get started:

```shell
codex
```

If you&#039;re running into upgrade issues with Homebrew, see the [FAQ entry on brew upgrade codex](./docs/faq.md#brew-upgrade-codex-isnt-upgrading-me).

&lt;details&gt;
&lt;summary&gt;You can also go to the &lt;a href=&quot;https://github.com/openai/codex/releases/latest&quot;&gt;latest GitHub Release&lt;/a&gt; and download the appropriate binary for your platform.&lt;/summary&gt;

Each GitHub Release contains many executables, but in practice, you likely want one of these:

- macOS
  - Apple Silicon/arm64: `codex-aarch64-apple-darwin.tar.gz`
  - x86_64 (older Mac hardware): `codex-x86_64-apple-darwin.tar.gz`
- Linux
  - x86_64: `codex-x86_64-unknown-linux-musl.tar.gz`
  - arm64: `codex-aarch64-unknown-linux-musl.tar.gz`

Each archive contains a single entry with the platform baked into the name (e.g., `codex-x86_64-unknown-linux-musl`), so you likely want to rename it to `codex` after extracting it.

&lt;/details&gt;

### Using Codex with your ChatGPT plan

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./.github/codex-cli-login.png&quot; alt=&quot;Codex CLI login&quot; width=&quot;80%&quot; /&gt;
  &lt;/p&gt;

Run `codex` and select **Sign in with ChatGPT**. We recommend signing into your ChatGPT account to use Codex as part of your Plus, Pro, Team, Edu, or Enterprise plan. [Learn more about what&#039;s included in your ChatGPT plan](https://help.openai.com/en/articles/11369540-codex-in-chatgpt).

You can also use Codex with an API key, but this requires [additional setup](./docs/authentication.md#usage-based-billing-alternative-use-an-openai-api-key). If you previously used an API key for usage-based billing, see the [migration steps](./docs/authentication.md#migrating-from-usage-based-billing-api-key). If you&#039;re having trouble with login, please comment on [this issue](https://github.com/openai/codex/issues/1243).

### Model Context Protocol (MCP)

Codex can access MCP servers. To configure them, refer to the [config docs](./docs/config.md#mcp_servers).

### Configuration

Codex CLI supports a rich set of configuration options, with preferences stored in `~/.codex/config.toml`. For full configuration options, see [Configuration](./docs/config.md).

### Execpolicy

See the [Execpolicy quickstart](./docs/execpolicy.md) to set up rules that govern what commands Codex can execute.

### Docs &amp; FAQ

- [**Getting started**](./docs/getting-started.md)
  - [CLI usage](./docs/getting-started.md#cli-usage)
  - [Slash Commands](./docs/slash_commands.md)
  - [Running with a prompt as input](./docs/getting-started.md#running-with-a-prompt-as-input)
  - [Example prompts](./docs/getting-started.md#example-prompts)
  - [Custom prompts](./docs/prompts.md)
  - [Memory with AGENTS.md](./docs/getting-started.md#memory-with-agentsmd)
- [**Configuration**](./docs/config.md)
  - [Example config](./docs/example-config.md)
- [**Sandbox &amp; approvals**](./docs/sandbox.md)
- [**Execpolicy quickstart**](./docs/execpolicy.md)
- [**Authentication**](./docs/authentication.md)
  - [Auth methods](./docs/authentication.md#forcing-a-specific-auth-method-advanced)
  - [Login on a &quot;Headless&quot; machine](./docs/authentication.md#connecting-on-a-headless-machine)
- **Automating Codex**
  - [GitHub Action](https://github.com/openai/codex-action)
  - [TypeScript SDK](./sdk/typescript/README.md)
  - [Non-interactive mode (`codex exec`)](./docs/exec.md)
- [**Advanced**](./docs/advanced.md)
  - [Tracing / verbose logging](./docs/advanced.md#tracing--verbose-logging)
  - [Model Context Protocol (MCP)](./docs/advanced.md#model-context-protocol-mcp)
- [**Zero data retention (ZDR)**](./docs/zdr.md)
- [**Contributing**](./docs/contributing.md)
- [**Install &amp; build**](./docs/install.md)
  - [System Requirements](./docs/install.md#system-requirements)
  - [DotSlash](./docs/install.md#dotslash)
  - [Build from source](./docs/install.md#build-from-source)
- [**FAQ**](./docs/faq.md)
- [**Open source fund**](./docs/open-source-fund.md)

---

## License

This repository is licensed under the [Apache-2.0 License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[jj-vcs/jj]]></title>
            <link>https://github.com/jj-vcs/jj</link>
            <guid>https://github.com/jj-vcs/jj</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:42 GMT</pubDate>
            <description><![CDATA[A Git-compatible VCS that is both simple and powerful]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jj-vcs/jj">jj-vcs/jj</a></h1>
            <p>A Git-compatible VCS that is both simple and powerful</p>
            <p>Language: Rust</p>
            <p>Stars: 22,795</p>
            <p>Forks: 829</p>
            <p>Stars today: 31 stars today</p>
            <h2>README</h2><pre>&lt;div class=&quot;title-block&quot; style=&quot;text-align: center;&quot; align=&quot;center&quot;&gt;

# Jujutsu‚Äîa version control system

&lt;p&gt;&lt;img title=&quot;jj logo&quot; src=&quot;docs/images/jj-logo.svg&quot; width=&quot;320&quot; height=&quot;320&quot;&gt;&lt;/p&gt;

[![Release](https://img.shields.io/github/v/release/martinvonz/jj)](https://github.com/jj-vcs/jj/releases)
[![Release date](https://img.shields.io/github/release-date/martinvonz/jj)](https://github.com/jj-vcs/jj/releases)
&lt;br/&gt;
[![License](https://img.shields.io/github/license/martinvonz/jj)](https://github.com/jj-vcs/jj/blob/main/LICENSE)
[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN)
[![IRC](https://img.shields.io/badge/irc-%23jujutsu-blue.svg)](https://web.libera.chat/?channel=#jujutsu)

**[Homepage] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Installation] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Getting Started] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Development Roadmap] &amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;**
**[Contributing](#contributing)**

[Homepage]: https://www.jj-vcs.dev
[Installation]: https://docs.jj-vcs.dev/latest/install-and-setup
[Getting Started]: https://docs.jj-vcs.dev/latest/tutorial
[Development Roadmap]: https://docs.jj-vcs.dev/latest/roadmap

&lt;/div&gt;

## Introduction

Jujutsu is a powerful [version control system](https://en.wikipedia.org/wiki/Version_control)
for software projects. You use it to get a copy of your code, track changes
to the code, and finally publish those changes for others to see and use.
It is designed from the ground up to be easy to use‚Äîwhether you&#039;re new or
experienced, working on brand new projects alone, or large scale software
projects with large histories and teams.

Jujutsu is unlike most other systems, because internally it abstracts the user
interface and version control algorithms from the *storage systems* used to
serve your content. This allows it to serve as a VCS with many possible physical
backends, that may have their own data or networking models‚Äîlike [Mercurial] or
[Breezy], or hybrid systems like Google&#039;s cloud-based design, [Piper/CitC].

[Mercurial]: https://www.mercurial-scm.org/
[Breezy]: https://www.breezy-vcs.org/
[Piper/CitC]: https://youtu.be/W71BTkUbdqE?t=645

Today, we use Git repositories as a storage layer to serve and track content,
making it **compatible with many of your favorite Git-based tools, right now!**
All core developers use Jujutsu to develop Jujutsu, right here on GitHub. But it
should hopefully work with your favorite Git forges, too.

We combine many distinct design choices and concepts from other version control
systems into a single tool. Some of those sources of inspiration include:

- **Git**: We make an effort to [be fast][perf]‚Äîwith a snappy UX, efficient
  algorithms, correct data structures, and good-old-fashioned attention to
  detail. The default storage backend uses Git repositories for &quot;physical
  storage&quot;, for wide interoperability and ease of onboarding.

- **Mercurial &amp; Sapling**: There are many Mercurial-inspired features, such as
  the [revset] language to select commits. There is [no explicit index][no-index]
  or staging area. Branches are &quot;anonymous&quot; like Mercurial, so you don&#039;t need
  to make up a name for each small change. Primitives for rewriting history are
  powerful and simple. Formatting output is done with a robust template language
  that can be configured by the user.

- **Darcs**: Jujutsu keeps track of conflicts as [first-class
  objects][conflicts] in its model; they are first-class in the same way commits
  are, while alternatives like Git simply think of conflicts as textual diffs.
  While not as rigorous as systems like Darcs (which is based on a formalized
  theory of patches, as opposed to snapshots), the effect is that many forms of
  conflict resolution can be performed and propagated automatically.

[perf]: https://github.com/jj-vcs/jj/discussions/49
[revset]: https://docs.jj-vcs.dev/latest/revsets/
[no-index]: https://docs.jj-vcs.dev/latest/git-comparison/#the-index
[conflicts]: https://docs.jj-vcs.dev/latest/conflicts/

And it adds several innovative, useful features of its own:

- **Working-copy-as-a-commit**: Changes to files are [recorded automatically][wcc]
  as normal commits, and amended on every subsequent change. This &quot;snapshot&quot;
  design simplifies the user-facing data model (commits are the only visible
  object), simplifies internal algorithms, and completely subsumes features like
  Git&#039;s stashes or the index/staging-area.

- **Operation log &amp; undo**: Jujutsu records every operation that is performed on the
  repository, from commits, to pulls, to pushes. This makes debugging problems like
  &quot;what just happened?&quot; or &quot;how did I end up here?&quot; easier, *especially* when
  you&#039;re helping your coworker answer those questions about their repository!
  And because everything is recorded, you can undo that mistake you just made
  with ease. Version control has finally entered [the 1960s][undo-history]!

- **Automatic rebase and conflict resolution**: When you modify a commit, every
  descendent is automatically rebased on top of the freshly-modified one. This
  makes &quot;patch-based&quot; workflows a breeze. If you resolve a conflict in a commit,
  the _resolution_ of that conflict is also propagated through descendants as
  well. In effect, this is a completely transparent version of `git rebase
  --update-refs` combined with `git rerere`, supported by design.

&gt; [!WARNING]
&gt; The following features are available for use, but experimental; they may have
&gt; bugs, backwards incompatible storage changes, and user-interface changes!

- **Safe, concurrent replication**: Have you ever wanted to store your version
  controlled repositories inside a Dropbox folder? Or continuously backup
  repositories to S3? No? Well, now you can!

  The fundamental problem with using filesystems like Dropbox and backup tools
  like `rsync` on your typical Git/Mercurial repositories is that they rely
  on *local filesystem operations* being atomic, serialized, and non-concurrent
  with respect to other reads and writes‚Äîwhich is _not_ true when operating on
  distributed file systems, or when operations like concurrent file copies (for
  backup) happen while lock files are being held.

  Jujutsu is instead designed to be [safe under concurrent scenarios][conc-safety];
  simply using rsync or Dropbox and then using that resulting repository
  should never result in a repository in a *corrupt state*. The worst that
  _should_ happen is that it will expose conflicts between the local and remote
  state, leaving you to resolve them.

[wcc]: https://docs.jj-vcs.dev/latest/working-copy/
[undo-history]: https://en.wikipedia.org/wiki/Undo#History
[conc-safety]: https://docs.jj-vcs.dev/latest/technical/concurrency/

The command-line tool is called `jj` for now because it&#039;s easy to type and easy
to replace (rare in English). The project is called &quot;Jujutsu&quot; because it matches
&quot;jj&quot;.

Jujutsu is relatively young, with lots of work to still be done. If you have any
questions, or want to talk about future plans, please join us on Discord
[![Discord](https://img.shields.io/discord/968932220549103686.svg?label=&amp;logo=discord&amp;logoColor=ffffff&amp;color=7389D8&amp;labelColor=6A7EC2)](https://discord.gg/dkmfj3aGQN),
start a [GitHub Discussion](https://github.com/jj-vcs/jj/discussions), or
send an IRC message to [`#jujutsu` on Libera
Chat](https://web.libera.chat/?channel=#jujutsu). The developers monitor all of
these channels[^bridge].

[^bridge]: To be more precise, the `#jujutsu` Libera IRC channel is bridged to
one of the channels on jj&#039;s Discord. Some of the developers stay on Discord and
use the bridge to follow IRC.

### News and Updates üì£

- **December 2024**: The `jj` Repository has moved to the `jj-vcs` GitHub
  organization.
- **November 2024**: Version 0.24 is released which adds `jj file annotate`,
  which is equivalent to `git blame` or `hg annotate`.
- **September 2024**: Martin gave a [presentation about Jujutsu][merge-vid-2024] at
  Git Merge 2024.
- **Feb 2024**: Version 0.14 is released, which deprecates [&quot;jj checkout&quot; and &quot;jj merge&quot;](CHANGELOG.md#0140---2024-02-07),
  as well as `jj init --git`, which is now just called `jj git init`.
- **Oct 2023**: Version 0.10.0 is released! Now includes a bundled merge and
  diff editor for all platforms, &quot;immutable revsets&quot; to avoid accidentally
  `edit`-ing the wrong revisions, and lots of polish.
- **Jan 2023**: Martin gave a presentation about Google&#039;s plans for Jujutsu at
  Git Merge 2022!
  See the [slides][merge-slides] or the [recording][merge-talk].

### Related Media

- **Mar 2024**: Chris Krycho started [a YouTube series about Jujutsu][krycho-yt].
- **Feb 2024**: Chris Krycho published an article about Jujutsu called [jj init][krycho]
  and Steve Klabnik followed up with the [Jujutsu Tutorial][klabnik].
- **Jan 2024**: Jujutsu was featured in an LWN.net article called
  [Jujutsu: a new, Git-compatible version control system][lwn].
- **Jan 2023**: Martin&#039;s Talk about Jujutsu at Git Merge 2022, [video][merge-talk]
  and the associated [slides][merge-slides].

The wiki also contains a more extensive list of [media references][wiki-media].

[krycho-yt]: https://www.youtube.com/playlist?list=PLelyiwKWHHAq01Pvmpf6x7J0y-yQpmtxp
[krycho]: https://v5.chriskrycho.com/essays/jj-init/
[klabnik]: https://steveklabnik.github.io/jujutsu-tutorial/
[lwn]: https://lwn.net/Articles/958468/
[merge-talk]: https://www.youtube.com/watch?v=bx_LGilOuE4
[merge-slides]: https://docs.google.com/presentation/d/1F8j9_UOOSGUN9MvHxPZX_L4bQ9NMcYOp1isn17kTC_M/view
[merge-vid-2024]: https://www.youtube.com/watch?v=LV0JzI8IcCY
[wiki-media]: https://github.com/jj-vcs/jj/wiki/Media

## Getting started

&gt; [!IMPORTANT]
&gt; Jujutsu is an **experimental version control system**. While Git compatibility
&gt; is stable, and most developers use it daily for all their needs, there may
&gt; still be work-in-progress features, suboptimal UX, and workflow gaps that make
&gt; it unusable for your particular use.

Follow the [installation
instructions](https://docs.jj-vcs.dev/latest/install-and-setup) to
obtain and configure `jj`.

The best way to get started is probably to go through [the
tutorial](https://docs.jj-vcs.dev/latest/tutorial). Also see the [Git
comparison](https://docs.jj-vcs.dev/latest/git-comparison), which
includes a table of `jj` vs. `git` commands.

As you become more familiar with Jujutsu, the following resources may be helpful:

- The [FAQ](https://docs.jj-vcs.dev/latest/FAQ).
- The [Glossary](https://docs.jj-vcs.dev/latest/glossary).
- The `jj help` command (e.g. `jj help rebase`).
- The `jj help -k &lt;keyword&gt;` command (e.g. `jj help -k config`). Use `jj help --help`
  to see what keywords are available.

If you are using a **prerelease** version of `jj`, you would want to consult
[the docs for the prerelease (main branch)
version](https://docs.jj-vcs.dev/prerelease/). You can also get there
from the docs for the latest release by using the website&#039;s version switcher. The version switcher is visible in
the header of the website when you scroll to the top of any page.

## Features

### Compatible with Git

Jujutsu is designed so that the underlying data and storage model is abstract.
Today, only the Git backend is production-ready. The Git backend uses the
[gitoxide](https://github.com/Byron/gitoxide) Rust library.

[backends]: https://docs.jj-vcs.dev/latest/glossary#backend

The Git backend is fully featured and maintained, and allows you to use Jujutsu
with any Git remote. The commits you create will look like regular Git commits.
You can fetch branches from a regular Git remote and push branches to the
remote. You can always switch back to Git.

Here is how you can explore a GitHub repository with `jj`.

&lt;img src=&quot;demos/git_compat.png&quot; /&gt;

You can even have a [colocated local
workspace](https://docs.jj-vcs.dev/latest/git-compatibility#colocated-jujutsugit-repos)
where you can use both `jj` and `git` commands interchangeably.

### The working copy is automatically committed

Jujutsu uses a real commit to represent the working copy. Checking out a commit
results in a new working-copy commit on top of the target commit. Almost all
commands automatically amend the working-copy commit.

The working-copy being a commit means that commands never fail because the
working copy is dirty (no &quot;error: Your local changes to the following
files...&quot;), and there is no need for `git stash`. Also, because the working copy
is a commit, commands work the same way on the working-copy commit as on any
other commit, so you can set the commit message before you&#039;re done with the
changes.

&lt;img src=&quot;demos/working_copy.png&quot; /&gt;

### The repo is the source of truth

With Jujutsu, the working copy plays a smaller role than with Git. Commands
snapshot the working copy before they start, then they update the repo, and then
the working copy is updated (if the working-copy commit was modified). Almost
all commands (even checkout!) operate on the commits in the repo, leaving the
common functionality of snapshotting and updating of the working copy to
centralized code. For example, `jj restore` (similar to `git restore`) can
restore from any commit and into any commit, and `jj describe` can set the
commit message of any commit (defaults to the working-copy commit).

### Entire repo is under version control

All operations you perform in the repo are recorded, along with a snapshot of
the repo state after the operation. This means that you can easily restore to
an earlier repo state, simply undo your operations one-by-one or even _revert_ a
particular operation which does not have to be the most recent one.

&lt;img src=&quot;demos/operation_log.png&quot; /&gt;

### Conflicts can be recorded in commits

If an operation results in
[conflicts](https://docs.jj-vcs.dev/latest/glossary#conflict),
information about those conflicts will be recorded in the commit(s). The
operation will succeed. You can then resolve the conflicts later. One
consequence of this design is that there&#039;s no need to continue interrupted
operations. Instead, you get a single workflow for resolving conflicts,
regardless of which command caused them. This design also lets Jujutsu rebase
merge commits correctly (unlike both Git and Mercurial).

Basic conflict resolution:

&lt;img src=&quot;demos/resolve_conflicts.png&quot; /&gt;

Juggling conflicts:

&lt;img src=&quot;demos/juggle_conflicts.png&quot; /&gt;

### Automatic rebase

Whenever you modify a commit, any descendants of the old commit will be rebased
onto the new commit. Thanks to the conflict design described above, that can be
done even if there are conflicts. Bookmarks pointing to rebased commits will be
updated. So will the working copy if it points to a rebased commit.

### Comprehensive support for rewriting history

Besides the usual rebase command, there&#039;s `jj describe` for editing the
description (commit message) of an arbitrary commit. There&#039;s also `jj diffedit`,
which lets you edit the changes in a commit without checking it out. To split
a commit into two, use `jj split`. You can even move part of the changes in a
commit to any other commit using `jj squash -i --from X --into Y`.

## Status

The tool is fairly feature-complete, but some important features like support
for Git submodules are not yet completed. There
are also several performance bugs. It&#039;s likely that workflows and setups
different from what the core developers use are not well supported, e.g. there
is no native support for email-based workflows.

Today, all core developers use `jj` to work on `jj`. I (Martin von Zweigbergk)
have almost exclusively used `jj` to develop the project itself since early
January 2021. I haven&#039;t had to re-clone from source (I don&#039;t think I&#039;ve even had
to restore from backup).

There *will* be changes to workflows and backward-incompatible changes to the
on-disk formats before version 1.0.0. For any format changes, we&#039;ll try to
implement transparent upgrades (as we&#039;ve done with recent changes), or provide
upgrade commands or scripts if requested.

## Related work

There are several tools trying to solve similar problems as Jujutsu. See
[related work](https://docs.jj-vcs.dev/latest/related-work) for details.

## Contributing

We welcome outside contributions, and there&#039;s plenty of things to do, so
don&#039;t be shy. Please ask if you want a pointer on something you can help with,
and hopefully we can all figure something out.

We do have [a few policies and
suggestions](https://docs.jj-vcs.dev/prerelease/contributing/)
for contributors. The broad TL;DR:

- Bug reports are very welcome!
- Every commit that lands in the `main` branch is code reviewed.
- Please behave yourself, and obey the Community Guidelines.
- There **is** a mandatory CLA you must agree to. Importantly, it **does not**
  transfer copyright ownership to Google or anyone else; it simply gives us the
  right to safely redistribute and use your changes.

### Mandatory Google Disclaimer

I (Martin von Zweigbergk, &lt;martinvonz@google.com&gt;) started Jujutsu as a hobby
project in late 2019, and it has evolved into my full-time project at Google,
with several other Googlers (now) assisting development in various capacities.
That said, **this is not a Google product**.

## License

Jujutsu is available as Open Source Software, under the Apache 2.0 license. See
[`LICENSE`](./LICENSE) for details about copyright and redistribution.

The `jj` logo was contributed by J. Jennings and is licensed under a Creative
Commons License, see [`docs/images/LICENSE`](docs/images/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[BloopAI/vibe-kanban]]></title>
            <link>https://github.com/BloopAI/vibe-kanban</link>
            <guid>https://github.com/BloopAI/vibe-kanban</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:41 GMT</pubDate>
            <description><![CDATA[Kanban board to manage your AI coding agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BloopAI/vibe-kanban">BloopAI/vibe-kanban</a></h1>
            <p>Kanban board to manage your AI coding agents</p>
            <p>Language: Rust</p>
            <p>Stars: 6,197</p>
            <p>Forks: 630</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vibekanban.com&quot;&gt;
    &lt;picture&gt;
      &lt;source srcset=&quot;frontend/public/vibe-kanban-logo-dark.svg&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
      &lt;source srcset=&quot;frontend/public/vibe-kanban-logo.svg&quot; media=&quot;(prefers-color-scheme: light)&quot;&gt;
      &lt;img src=&quot;frontend/public/vibe-kanban-logo.svg&quot; alt=&quot;Vibe Kanban Logo&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;Get 10X more out of Claude Code, Gemini CLI, Codex, Amp and other coding agents...&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/vibe-kanban&quot;&gt;&lt;img alt=&quot;npm&quot; src=&quot;https://img.shields.io/npm/v/vibe-kanban?style=flat-square&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/BloopAI/vibe-kanban/blob/main/.github/workflows/publish.yml&quot;&gt;&lt;img alt=&quot;Build status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/BloopAI/vibe-kanban/.github%2Fworkflows%2Fpublish.yml&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://deepwiki.com/BloopAI/vibe-kanban&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://jobs.polymer.co/vibe-kanban?source=github&quot;&gt;&lt;strong&gt;We&#039;re hiring!&lt;/strong&gt;&lt;/a&gt;
&lt;/h1&gt;

![](frontend/public/vibe-kanban-screenshot-overview.png)

## Overview

AI coding agents are increasingly writing the world&#039;s code and human engineers now spend the majority of their time planning, reviewing, and orchestrating tasks. Vibe Kanban streamlines this process, enabling you to:

- Easily switch between different coding agents
- Orchestrate the execution of multiple coding agents in parallel or in sequence
- Quickly review work and start dev servers
- Track the status of tasks that your coding agents are working on
- Centralise configuration of coding agent MCP configs
- Open projects remotely via SSH when running Vibe Kanban on a remote server

You can watch a video overview [here](https://youtu.be/TFT3KnZOOAk).

## Installation

Make sure you have authenticated with your favourite coding agent. A full list of supported coding agents can be found in the [docs](https://vibekanban.com/docs). Then in your terminal run:

```bash
npx vibe-kanban
```

## Documentation

Please head to the [website](https://vibekanban.com/docs) for the latest documentation and user guides.

## Support

We use [GitHub Discussions](https://github.com/BloopAI/vibe-kanban/discussions) for feature requests. Please open a discussion to create a feature request. For bugs please open an issue on this repo.

## Contributing

We would prefer that ideas and changes are first raised with the core team via [GitHub Discussions](https://github.com/BloopAI/vibe-kanban/discussions) or [Discord](https://discord.gg/AC4nwVtJM3), where we can discuss implementation details and alignment with the existing roadmap. Please do not open PRs without first discussing your proposal with the team.

## Development

### Prerequisites

- [Rust](https://rustup.rs/) (latest stable)
- [Node.js](https://nodejs.org/) (&gt;=18)
- [pnpm](https://pnpm.io/) (&gt;=8)

Additional development tools:
```bash
cargo install cargo-watch
cargo install sqlx-cli
```

Install dependencies:
```bash
pnpm i
```

### Running the dev server

```bash
pnpm run dev
```

This will start the backend. A blank DB will be copied from the `dev_assets_seed` folder.

### Building the frontend

To build just the frontend:

```bash
cd frontend
pnpm build
```

### Build from source

1. Run `build-npm-package.sh`
2. In the `npx-cli` folder run `npm pack`
3. You can run your build with `npx [GENERATED FILE].tgz`


### Environment Variables

The following environment variables can be configured at build time or runtime:

| Variable | Type | Default | Description |
|----------|------|---------|-------------|
| `POSTHOG_API_KEY` | Build-time | Empty | PostHog analytics API key (disables analytics if empty) |
| `POSTHOG_API_ENDPOINT` | Build-time | Empty | PostHog analytics endpoint (disables analytics if empty) |
| `BACKEND_PORT` | Runtime | `0` (auto-assign) | Backend server port |
| `FRONTEND_PORT` | Runtime | `3000` | Frontend development server port |
| `HOST` | Runtime | `127.0.0.1` | Backend server host |
| `DISABLE_WORKTREE_ORPHAN_CLEANUP` | Runtime | Not set | Disable git worktree cleanup (for debugging) |

**Build-time variables** must be set when running `pnpm run build`. **Runtime variables** are read when the application starts.

### Remote Deployment

When running Vibe Kanban on a remote server (e.g., via systemctl, Docker, or cloud hosting), you can configure your editor to open projects via SSH:

1. **Access via tunnel**: Use Cloudflare Tunnel, ngrok, or similar to expose the web UI
2. **Configure remote SSH** in Settings ‚Üí Editor Integration:
   - Set **Remote SSH Host** to your server hostname or IP
   - Set **Remote SSH User** to your SSH username (optional)
3. **Prerequisites**:
   - SSH access from your local machine to the remote server
   - SSH keys configured (passwordless authentication)
   - VSCode Remote-SSH extension

When configured, the &quot;Open in VSCode&quot; buttons will generate URLs like `vscode://vscode-remote/ssh-remote+user@host/path` that open your local editor and connect to the remote server.

See the [documentation](https://vibekanban.com/docs/configuration-customisation/global-settings#remote-ssh-configuration) for detailed setup instructions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[facebook/pyrefly]]></title>
            <link>https://github.com/facebook/pyrefly</link>
            <guid>https://github.com/facebook/pyrefly</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:40 GMT</pubDate>
            <description><![CDATA[A fast type checker and language server for Python]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/facebook/pyrefly">facebook/pyrefly</a></h1>
            <p>A fast type checker and language server for Python</p>
            <p>Language: Rust</p>
            <p>Stars: 4,926</p>
            <p>Forks: 213</p>
            <p>Stars today: 26 stars today</p>
            <h2>README</h2><pre># Pyrefly: A fast type checker and language server for Python with powerful IDE features

[![pyrefly](https://img.shields.io/endpoint?url=https://pyrefly.org/badge.json)](https://github.com/facebook/pyrefly)
[![PyPI](https://img.shields.io/pypi/v/pyrefly.svg?color=blue)](https://pypi.python.org/pypi/pyrefly)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/Cf7mFQtW7W)
[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)

Pyrefly is a type checker and language server for Python, which provides
lightning-fast type checking along with IDE features such as code navigation,
semantic highlighting, and code completion. It is available as a
[command-line tool](https://pyrefly.org/en/docs/installation/) and a
[VSCode extension](https://marketplace.visualstudio.com/items?itemName=meta.pyrefly).

See the [Pyrefly website](https://pyrefly.org) for full documentation and how to
add Pyrefly to your editor of choice.

Currently under active development with known issues. Please open an issue if
you find bugs.

### Getting Started

- Try out pyrefly in your browser: [Sandbox](https://pyrefly.org/sandbox/)
- Get the command-line tool: `pip install pyrefly`
- Get the VSCode extension:
  [Link](https://marketplace.visualstudio.com/items?itemName=meta.pyrefly)

### Key Features:

- Type Inference: Pyrefly infers types in most locations, apart from function
  parameters. It can infer types of variables and return types.
- Flow Types: Pyrefly can understand your program&#039;s control flow to refine
  static types.
- Incrementality: Pyrefly aims for large-scale incrementality at the module
  level, with optimized checking and parallelism.

## Getting Involved

If you have questions or would like to report a bug, please
[create an issue](https://github.com/facebook/pyrefly/issues).

See our
[contributing guide](https://github.com/facebook/pyrefly/blob/main/CONTRIBUTING.md)
for information on how to contribute to Pyrefly.

Join our [Discord](https://discord.com/invite/Cf7mFQtW7W) to chat about Pyrefly
and types. This is also where we hold biweekly office hours.

## Choices

There are a number of choices when writing a Python type checker. We are taking
inspiration from [Pyre1](https://pyre-check.org/),
[Pyright](https://github.com/microsoft/pyright) and
[MyPy](https://mypy.readthedocs.io/en/stable/). Some notable choices:

- We infer types in most locations, apart from parameters to functions. We do
  infer types of variables and return types. As an example,
  `def foo(x): return True` would result in something equivalent to had you
  written `def foo(x: Any) -&gt; bool: ...`.
- We attempt to infer the type of `[]` to however it is used first, then fix it
  after. For example `xs = []; xs.append(1); xs.append(&quot;&quot;)` will infer that
  `xs: List[int]` and then error on the final statement.
- We use flow types which refine static types, e.g. `x: int = 4` will both know
  that `x` has type `int`, but also that the immediately next usage of `x` will
  be aware the type is `Literal[4]`.
- We aim for large-scale incrementality (at the module level) and optimized
  checking with parallelism, aiming to use the advantages of Rust to keep the
  code a bit simpler.
- We expect large strongly connected components of modules, and do not attempt
  to take advantage of a DAG-shape in the source code.

## Code layout

Pyrefly is split into a number of crates (mostly under `crates/`):

- `pyrefly_util` are general purpose utilities, which have nothing to do with
  Python or type checking. Examples include IO wrappers, locking, command line
  helpers etc.
- `pyrefly_derive` are proc-macros for deriving traits such as `TypeEq` and
  `Visit`.
- `pyrefly_python` are Python utilities with no type-checking aspects, such as
  modelling modules or `sys.info`.
- `pyrefly_bundled` are the third-party
  [typeshed stubs](https://github.com/python/typeshed).
- `pyrefly_config` defines the Pyrefly configuration, along with support for
  reading Mypy/Pyright configuration.
- `pyrefly_types` defines the Pyrefly type along with operations on it.
- `pyrefly_wasm` defines the sandbox code that compiles to WASM.
- `pyrefly` itself is the type checker and everything else.

## Design

There are many nuances of design that change on a regular basis. But the basic
substrate on which the checker is built involves three steps:

1. Figure out what each module exports. That requires solving all `import *`
   statements transitively.
2. For each module in isolation, convert it to bindings, dealing with all
   statements and scope information (both static and flow).
3. Solve those bindings, which may require the solutions of bindings in other
   modules.

If we encounter unknowable information (e.g. recursion) we use `Type::Var` to
insert placeholders which are filled in later.

For each module, we solve the steps sequentially and completely. In particular,
we do not try and solve a specific identifier first (like
[Roslyn](https://github.com/dotnet/roslyn) or
[TypeScript](https://www.typescriptlang.org/)), and do not use fine-grained
incrementality (like [Rust Analyzer](https://github.com/rust-lang/rust-analyzer)
using [Salsa](https://github.com/salsa-rs/salsa)). Instead, we aim for raw
performance and a simpler module-centric design - there&#039;s no need to solve a
single binding in isolation if solving all bindings in a module is fast enough.

### Example of bindings

Given the program:

```python
1: x: int = 4
2: print(x)
```

We might produce the bindings:

- `define int@0` = `from builtins import int`
- `define x@1` = `4: int@0`
- `use x@2` = `x@1`
- `anon @2` = `print(x@2)`
- `export x` = `x@2`

Of note:

- The keys are things like `define` (the definition of something), `use` (a
  usage of a thing) and `anon` (a statement we need to type check, but don&#039;t
  care about the result of).
- In many cases the value of a key refers to other keys.
- Some keys are imported from other modules, via `export` keys and `import`
  values.
- In order to disambiguate identifiers we use the textual position at which they
  occur (in the example we&#039;ve used `@line`, but in reality it&#039;s the byte offset
  in the file).

### Example of `Var`

Given the program:

```python
1: x = 1
2: while test():
3:     x = x
4: print(x)
```

We end up with the bindings:

- `x@1` = `1`
- `x@3` = `phi(x@1, x@3)`
- `x@4` = `phi(x@1, x@3)`

The expression `phi` is the join point of the two values, e.g. `phi(int, str)`
would be `int | str`. We skip the distinction between `define` and `use`, since
it is not necessary for this example.

When solving `x@3` we encounter recursion. Operationally:

- We start solving `x@3`.
- That requires us to solve `x@1`.
- We solve `x@1` to be `Literal[1]`
- We start solving `x@3`. But we are currently solving `x@3`, so we invent a
  fresh `Var` (let&#039;s call it `?1`) and return that.
- We conclude that `x@3` must be `Literal[1] | ?1`.
- Since `?1` was introduced by `x@3` we record that `?1 = Literal[1] | ?1`. We
  can take the upper reachable bound of that and conclude that
  `?1 = Literal[1]`.
- We simplify `x@3` to just `Literal[1]`.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[firecracker-microvm/firecracker]]></title>
            <link>https://github.com/firecracker-microvm/firecracker</link>
            <guid>https://github.com/firecracker-microvm/firecracker</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:39 GMT</pubDate>
            <description><![CDATA[Secure and fast microVMs for serverless computing.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/firecracker-microvm/firecracker">firecracker-microvm/firecracker</a></h1>
            <p>Secure and fast microVMs for serverless computing.</p>
            <p>Language: Rust</p>
            <p>Stars: 31,279</p>
            <p>Forks: 2,154</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;docs/images/fc_logo_full_transparent-bg_white-fg.png&quot;&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;docs/images/fc_logo_full_transparent-bg.png&quot;&gt;
   &lt;img alt=&quot;Firecracker Logo Title&quot; width=&quot;750&quot; src=&quot;docs/images/fc_logo_full_transparent-bg.png&quot;&gt;
&lt;/picture&gt;

Our mission is to enable secure, multi-tenant, minimal-overhead execution of
container and function workloads.

Read more about the Firecracker Charter [here](CHARTER.md).

## What is Firecracker?

Firecracker is an open source virtualization technology that is purpose-built
for creating and managing secure, multi-tenant container and function-based
services that provide serverless operational models. Firecracker runs workloads
in lightweight virtual machines, called microVMs, which combine the security and
isolation properties provided by hardware virtualization technology with the
speed and flexibility of containers.

## Overview

The main component of Firecracker is a virtual machine monitor (VMM) that uses
the Linux Kernel Virtual Machine (KVM) to create and run microVMs. Firecracker
has a minimalist design. It excludes unnecessary devices and guest-facing
functionality to reduce the memory footprint and attack surface area of each
microVM. This improves security, decreases the startup time, and increases
hardware utilization. Firecracker has also been integrated in container
runtimes, for example
[Kata Containers](https://github.com/kata-containers/kata-containers) and
[Flintlock](https://github.com/liquidmetal-dev/flintlock).

Firecracker was developed at Amazon Web Services to accelerate the speed and
efficiency of services like [AWS Lambda](https://aws.amazon.com/lambda/) and
[AWS Fargate](https://aws.amazon.com/fargate/). Firecracker is open sourced
under [Apache version 2.0](LICENSE).

To read more about Firecracker, check out
[firecracker-microvm.io](https://firecracker-microvm.github.io).

## Getting Started

To get started with Firecracker, download the latest
[release](https://github.com/firecracker-microvm/firecracker/releases) binaries
or build it from source.

You can build Firecracker on any Unix/Linux system that has Docker running (we
use a development container) and `bash` installed, as follows:

```bash
git clone https://github.com/firecracker-microvm/firecracker
cd firecracker
tools/devtool build
toolchain=&quot;$(uname -m)-unknown-linux-musl&quot;
```

The Firecracker binary will be placed at
`build/cargo_target/${toolchain}/debug/firecracker`. For more information on
building, testing, and running Firecracker, go to the
[quickstart guide](docs/getting-started.md).

The overall security of Firecracker microVMs, including the ability to meet the
criteria for safe multi-tenant computing, depends on a well configured Linux
host operating system. A configuration that we believe meets this bar is
included in [the production host setup document](docs/prod-host-setup.md).

## Contributing

Firecracker is already running production workloads within AWS, but it&#039;s still
Day 1 on the journey guided by our [mission](CHARTER.md). There&#039;s a lot more to
build and we welcome all contributions.

To contribute to Firecracker, check out the development setup section in the
[getting started guide](docs/getting-started.md) and then the Firecracker
[contribution guidelines](CONTRIBUTING.md).

## Releases

New Firecracker versions are released via the GitHub repository
[releases](https://github.com/firecracker-microvm/firecracker/releases) page,
typically every two or three months. A history of changes is recorded in our
[changelog](CHANGELOG.md).

The Firecracker release policy is detailed [here](docs/RELEASE_POLICY.md).

## Design

Firecracker&#039;s overall architecture is described in
[the design document](docs/design.md).

## Features &amp; Capabilities

Firecracker consists of a single micro Virtual Machine Manager process that
exposes an API endpoint to the host once started. The API is
[specified in OpenAPI format](src/firecracker/swagger/firecracker.yaml). Read
more about it in the [API docs](docs/api_requests).

The **API endpoint** can be used to:

- Configure the microvm by:
  - Setting the number of vCPUs (the default is 1).
  - Setting the memory size (the default is 128 MiB).
  - Configuring a [CPU template](docs/cpu_templates/cpu-templates.md).
- Add one or more network interfaces to the microVM.
- Add one or more read-write or read-only disks to the microVM, each represented
  by a file-backed block device.
- Trigger a block device re-scan while the guest is running. This enables the
  guest OS to pick up size changes to the block device&#039;s backing file.
- Change the backing file for a block device, before or after the guest boots.
- Configure rate limiters for virtio devices which can limit the bandwidth,
  operations per second, or both.
- Configure the logging and metric system.
- `[BETA]` Configure the data tree of the guest-facing metadata service. The
  service is only available to the guest if this resource is configured.
- Add a [vsock socket](docs/vsock.md) to the microVM.
- Add a [entropy device](docs/entropy.md) to the microVM.
- Add a [pmem device](docs/pmem.md) to the microVM.
- Configure and manage [memory hotplugging](docs/memory-hotplug.md).
- Start the microVM using a given kernel image, root file system, and boot
  arguments.
- [x86_64 only] Stop the microVM.

**Built-in Capabilities**:

- Demand fault paging and CPU oversubscription enabled by default.
- Advanced, thread-specific seccomp filters for enhanced security.
- [Jailer](docs/jailer.md) process for starting Firecracker in production
  scenarios; applies a cgroup/namespace isolation barrier and then drops
  privileges.

## Tested platforms

We test all combinations of:

| Instance                               | Host OS &amp; Kernel | Guest Rootfs | Guest Kernel |
| :------------------------------------- | :--------------- | :----------- | :----------- |
| m5n.metal (Intel Cascade Lake)         | al2 linux_5.10   | ubuntu 24.04 | linux_5.10   |
| m6i.metal (Intel Ice Lake)             | al2023 linux_6.1 |              | linux_6.1    |
| m7i.metal-24xl (Intel Sapphire Rapids) |                  |              |              |
| m7i.metal-48xl (Intel Sapphire Rapids) |                  |              |              |
| m6a.metal (AMD Milan)                  |                  |              |              |
| m7a.metal-48xl (AMD Genoa)             |                  |              |              |
| m6g.metal (Graviton 2)                 |                  |              |              |
| m7g.metal (Graviton 3)                 |                  |              |              |
| m8g.metal-24xl (Graviton 4)            |                  |              |              |
| m8g.metal-48xl (Graviton 4)            |                  |              |              |

## Known issues and Limitations

- The `pl031` RTC device on aarch64 does not support interrupts, so guest
  programs which use an RTC alarm (e.g. `hwclock`) will not work.

## Performance

Firecracker&#039;s performance characteristics are listed as part of the
[specification documentation](SPECIFICATION.md). All specifications are a part
of our commitment to supporting container and function workloads in serverless
operational models, and are therefore enforced via continuous integration
testing.

## Policy for Security Disclosures

The security of Firecracker is our top priority. If you suspect you have
uncovered a vulnerability, contact us privately, as outlined in our
[security policy document](SECURITY.md); we will immediately prioritize your
disclosure.

## FAQ &amp; Contact

Frequently asked questions are collected in our [FAQ doc](FAQ.md).

You can get in touch with the Firecracker community in the following ways:

- Security-related issues, see our [security policy document](SECURITY.md).
- Chat with us on our
  [Slack workspace](https://join.slack.com/t/firecracker-microvm/shared_invite/zt-2tc0mfxpc-tU~HYAYSzLDl5XGGJU3YIg)
  _Note: most of the maintainers are on a European time zone._
- Open a GitHub issue in this repository.
- Email the maintainers at
  [firecracker-maintainers@amazon.com](mailto:firecracker-maintainers@amazon.com).

When communicating within the Firecracker community, please mind our
[code of conduct](CODE_OF_CONDUCT.md).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[ai-dynamo/dynamo]]></title>
            <link>https://github.com/ai-dynamo/dynamo</link>
            <guid>https://github.com/ai-dynamo/dynamo</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:38 GMT</pubDate>
            <description><![CDATA[A Datacenter Scale Distributed Inference Serving Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ai-dynamo/dynamo">ai-dynamo/dynamo</a></h1>
            <p>A Datacenter Scale Distributed Inference Serving Framework</p>
            <p>Language: Rust</p>
            <p>Stars: 5,609</p>
            <p>Forks: 725</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;!--
SPDX-FileCopyrightText: Copyright (c) 2024-2025 NVIDIA CORPORATION &amp; AFFILIATES. All rights reserved.
SPDX-License-Identifier: Apache-2.0

Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
--&gt;

![Dynamo banner](./docs/images/frontpage-banner.png)

[![License](https://img.shields.io/badge/License-Apache_2.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![GitHub Release](https://img.shields.io/github/v/release/ai-dynamo/dynamo)](https://github.com/ai-dynamo/dynamo/releases/latest)
[![Discord](https://dcbadge.limes.pink/api/server/D92uqZRjCZ?style=flat)](https://discord.gg/D92uqZRjCZ)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/ai-dynamo/dynamo)

| **[Roadmap](https://github.com/ai-dynamo/dynamo/issues/2486)** | **[Support matrix](https://github.com/ai-dynamo/dynamo/blob/main/docs/reference/support-matrix.md)** | **[Docs](https://docs.nvidia.com/dynamo/latest/index.html)** | **[Recipes](https://github.com/ai-dynamo/dynamo/tree/main/recipes)** | **[Examples](https://github.com/ai-dynamo/dynamo/tree/main/examples)** | **[Prebuilt containers](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/ai-dynamo/collections/ai-dynamo)** | **[Design Proposals](https://github.com/ai-dynamo/enhancements)** | **[Blogs](https://developer.nvidia.com/blog/tag/nvidia-dynamo)**

# NVIDIA Dynamo

High-throughput, low-latency inference framework designed for serving generative AI and reasoning models in multi-node distributed environments.

## Framework Support Matrix

| Feature                                                                                           | [vLLM](docs/backends/vllm/README.md) | [SGLang](docs/backends/sglang/README.md) | [TensorRT-LLM](docs/backends/trtllm/README.md) |
| ------------------------------------------------------------------------------------------------- | ---- | ------ | ------------ |
| [**Disaggregated Serving**](/docs/design_docs/disagg_serving.md)                                 | ‚úÖ   | ‚úÖ     | ‚úÖ           |
| [**KV-Aware Routing**](/docs/router/kv_cache_routing.md)                                    | ‚úÖ   | ‚úÖ     | ‚úÖ           |
| [**SLA-Based Planner**](docs/planner/sla_planner.md)                                        | ‚úÖ   | ‚úÖ     | ‚úÖ           |
| [**KVBM**](docs/kvbm/kvbm_architecture.md)                                               | ‚úÖ   | üöß     | ‚úÖ           |

## Latest News

- [11/13] [Dynamo Office Hours Playlist](https://www.youtube.com/playlist?list=PL5B692fm6--tgryKu94h2Zb7jTFM3Go4X)
- [10/16] [How Baseten achieved 2x faster inference with NVIDIA Dynamo](https://www.baseten.co/blog/how-baseten-achieved-2x-faster-inference-with-nvidia-dynamo/#qwen3-coder-benchmarks-with-kv-routing)
- [10/13] [NVIDIA Blackwell Leads on New SemiAnalysis InferenceMax Benchmarks](https://developer.nvidia.com/blog/nvidia-blackwell-leads-on-new-semianalysis-inferencemax-benchmarks/)
- [09/09] [Dynamo + NVIDIA Blackwell Ultra Sets New MLPerf Inference Benchmark Record](https://blogs.nvidia.com/blog/mlperf-inference-blackwell-ultra/)
- [08/05] Deploy `openai/gpt-oss-120b` with disaggregated serving on NVIDIA Blackwell GPUs using Dynamo [‚û°Ô∏è link](./docs/backends/trtllm/gpt-oss.md)

## The Era of Multi-GPU, Multi-Node

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-gpu-vertical.png&quot; alt=&quot;Multi Node Multi-GPU topology&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Large language models are quickly outgrowing the memory and compute budget of any single GPU. Tensor-parallelism solves the capacity problem by spreading each layer across many GPUs‚Äîand sometimes many servers‚Äîbut it creates a new one: how do you coordinate those shards, route requests, and share KV cache fast enough to feel like one accelerator? This orchestration gap is exactly what NVIDIA Dynamo is built to close.

Dynamo is designed to be inference engine agnostic (supports TRT-LLM, vLLM, SGLang or others) and captures LLM-specific capabilities such as:

- **Disaggregated prefill &amp; decode inference** ‚Äì Maximizes GPU throughput and facilitates trade off between throughput and latency.
- **Dynamic GPU scheduling** ‚Äì Optimizes performance based on fluctuating demand
- **LLM-aware request routing** ‚Äì Eliminates unnecessary KV cache re-computation
- **Accelerated data transfer** ‚Äì Reduces inference response time using NIXL.
- **KV cache offloading** ‚Äì Leverages multiple memory hierarchies for higher system throughput

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./docs/images/frontpage-architecture.png&quot; alt=&quot;Dynamo architecture&quot; width=&quot;600&quot; /&gt;
&lt;/p&gt;

Built in Rust for performance and in Python for extensibility, Dynamo is fully open-source and driven by a transparent, OSS (Open Source Software) first development approach.

# Installation

The following examples require a few system level packages.
Recommended to use Ubuntu 24.04 with a x86_64 CPU. See [docs/reference/support-matrix.md](docs/reference/support-matrix.md)

## 1. Initial setup

The Dynamo team recommends the `uv` Python package manager, although any way works. Install uv:

```
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### Install Python development headers

Backend engines require Python development headers for JIT compilation. Install them with:

```bash
sudo apt install python3-dev
```

### Install etcd (optional) and NATS (required)

To coordinate across a data center, Dynamo relies on etcd and NATS. These will be used in production. To run Dynamo locally etcd is optional.

- [etcd](https://etcd.io/) can be run directly as `./etcd`.
- [nats](https://nats.io/) needs jetstream enabled: `nats-server -js`.

To quickly setup etcd &amp; NATS, you can also run:

```bash
# At the root of the repository:
docker compose -f deploy/docker-compose.yml up -d
```

To run locally without etcd, pass `--store-kv file` to both the frontend and workers. The directory used for key-value data can be configured via the `DYN_FILE_KV` environment variable (example: `export DYN_FILE_KV=/data/kv/dynamo`). Defaults to `$TMPDIR/dynamo_store_kv`.


## 2. Select an engine

We publish Python wheels specialized for each of our supported engines: vllm, sglang, and trtllm. The examples that follow use SGLang; continue reading for other engines.

```
uv venv venv
source venv/bin/activate
uv pip install pip

# Choose one
uv pip install &quot;ai-dynamo[sglang]&quot;  #replace with [vllm], [trtllm], etc.
```

## 3. Run Dynamo

### Sanity check (optional)

Before trying out Dynamo, you can verify your system configuration and dependencies:

```bash
./deploy/sanity_check.py
```

This is a quick check for system resources, development tools, LLM frameworks, and Dynamo components.

### Running an LLM API server

Dynamo provides a simple way to spin up a local set of inference components including:

- **OpenAI Compatible Frontend** ‚Äì High performance OpenAI compatible http api server written in Rust.
- **Basic and Kv Aware Router** ‚Äì Route and load balance traffic to a set of workers.
- **Workers** ‚Äì Set of pre-configured LLM serving engines.

```
# Start an OpenAI compatible HTTP server, a pre-processor (prompt templating and tokenization) and a router.
# Pass the TLS certificate and key paths to use HTTPS instead of HTTP.
# Pass --store-kv to use the filesystem instead of etcd. The workers and frontend must share a disk.
python -m dynamo.frontend --http-port 8000 [--tls-cert-path cert.pem] [--tls-key-path key.pem] [--store-kv file]

# Start the SGLang engine, connecting to NATS and etcd to receive requests. You can run several of these,
# both for the same model and for multiple models. The frontend node will discover them.
# Pass --store-kv to use the filesystem instead of etcd. The workers and frontend must share a disk.
python -m dynamo.sglang --model deepseek-ai/DeepSeek-R1-Distill-Llama-8B [--store-kv file]
```

#### Send a Request

```bash
curl localhost:8000/v1/chat/completions   -H &quot;Content-Type: application/json&quot;   -d &#039;{
    &quot;model&quot;: &quot;deepseek-ai/DeepSeek-R1-Distill-Llama-8B&quot;,
    &quot;messages&quot;: [
    {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;Hello, how are you?&quot;
    }
    ],
    &quot;stream&quot;:false,
    &quot;max_tokens&quot;: 300
  }&#039; | jq
```

Rerun with `curl -N` and change `stream` in the request to `true` to get the responses as soon as the engine issues them.

### Deploying Dynamo

- Follow the [Quickstart Guide](docs/kubernetes/README.md) to deploy on Kubernetes.
- Check out [Backends](examples/backends) to deploy various workflow configurations (e.g. SGLang with router, vLLM with disaggregated serving, etc.)
- Run some [Examples](examples) to learn about building components in Dynamo and exploring various integrations.

### Benchmarking Dynamo

Dynamo provides comprehensive benchmarking tools to evaluate and optimize your deployments:

- **[Benchmarking Guide](docs/benchmarks/benchmarking.md)** ‚Äì Compare deployment topologies (aggregated vs. disaggregated vs. vanilla vLLM) using AIPerf
- **[SLA-Driven Dynamo Deployments](docs/planner/sla_planner_quickstart.md)** ‚Äì Optimize your deployment to meet SLA requirements

# Engines

Dynamo is designed to be inference engine agnostic. To use any engine with Dynamo, NATS and etcd need to be installed, along with a Dynamo frontend (`python -m dynamo.frontend [--interactive]`).

## vLLM

```
uv pip install ai-dynamo[vllm]
```

Run the backend/worker like this:

```
python -m dynamo.vllm --help
```

vLLM attempts to allocate enough KV cache for the full context length at startup. If that does not fit in your available memory pass `--context-length &lt;value&gt;`.

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

## SGLang

```
# Install libnuma
apt install -y libnuma-dev

uv pip install ai-dynamo[sglang]
```

Run the backend/worker like this:

```
python -m dynamo.sglang --help
```

You can pass any sglang flags directly to this worker, see https://docs.sglang.ai/advanced_features/server_arguments.html . See there to use multiple GPUs.

## TensorRT-LLM

It is recommended to use [NGC PyTorch Container](https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch) for running the TensorRT-LLM engine.

&gt; [!Note]
&gt; Ensure that you select a PyTorch container image version that matches the version of TensorRT-LLM you are using.
&gt; For example, if you are using `tensorrt-llm==1.1.0rc5`, use the PyTorch container image version `25.06`.
&gt; To find the correct PyTorch container version for your desired `tensorrt-llm` release, visit the [TensorRT-LLM Dockerfile.multi](https://github.com/NVIDIA/TensorRT-LLM/blob/main/docker/Dockerfile.multi) on GitHub. Switch to the branch that matches your `tensorrt-llm` version, and look for the `BASE_TAG` line to identify the recommended PyTorch container tag.

&gt; [!Important]
&gt; Launch container with the following additional settings `--shm-size=1g --ulimit memlock=-1`

### Install prerequisites

```
# Optional step: Only required for Blackwell and Grace Hopper
uv pip install torch==2.7.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128

# Required until the trtllm version is bumped to include this pinned dependency itself
uv pip install &quot;cuda-python&gt;=12,&lt;13&quot;

sudo apt-get -y install libopenmpi-dev
```

&gt; [!Tip]
&gt; You can learn more about these prequisites and known issues with TensorRT-LLM pip based installation [here](https://nvidia.github.io/TensorRT-LLM/installation/linux.html).

### After installing the pre-requisites above, install Dynamo

```
uv pip install ai-dynamo[trtllm]
```

Run the backend/worker like this:

```
python -m dynamo.trtllm --help
```

To specify which GPUs to use set environment variable `CUDA_VISIBLE_DEVICES`.

# Developing Locally

## 1. Install libraries

**Ubuntu:**

```
sudo apt install -y build-essential libhwloc-dev libudev-dev pkg-config libclang-dev protobuf-compiler python3-dev cmake
```

**macOS:**

- [Homebrew](https://brew.sh/)

```
# if brew is not installed on your system, install it
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;
```

- [Xcode](https://developer.apple.com/xcode/)

```
brew install cmake protobuf

## Check that Metal is accessible
xcrun -sdk macosx metal
```

If Metal is accessible, you should see an error like `metal: error: no input files`, which confirms it is installed correctly.

## 2. Install Rust

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://sh.rustup.rs | sh
source $HOME/.cargo/env
```

## 3. Create a Python virtual env:

Follow the instructions in [uv installation](https://docs.astral.sh/uv/#installation) guide to install uv if you don&#039;t have `uv` installed. Once uv is installed, create a virtual environment and activate it.

- Install uv

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

- Create a virtual environment

```bash
uv venv dynamo
source dynamo/bin/activate
```

## 4. Install build tools

```
uv pip install pip maturin
```

[Maturin](https://github.com/PyO3/maturin) is the Rust&lt;-&gt;Python bindings build tool.

## 5. Build the Rust bindings

```
cd lib/bindings/python
maturin develop --uv
```

## 6. Install the wheel

```
cd $PROJECT_ROOT
uv pip install -e .
```

You should now be able to run `python -m dynamo.frontend`.

Remember that nats and etcd must typically be running (see earlier).

Set the environment variable `DYN_LOG` to adjust the logging level; for example, `export DYN_LOG=debug`. It has the same syntax as `RUST_LOG`.

If you use vscode or cursor, we have a .devcontainer folder built on [Microsofts Extension](https://code.visualstudio.com/docs/devcontainers/containers). For instructions see the [ReadMe](.devcontainer/README.md) for more details.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[lapce/lapce]]></title>
            <link>https://github.com/lapce/lapce</link>
            <guid>https://github.com/lapce/lapce</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:37 GMT</pubDate>
            <description><![CDATA[Lightning-fast and Powerful Code Editor written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lapce/lapce">lapce/lapce</a></h1>
            <p>Lightning-fast and Powerful Code Editor written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 37,693</p>
            <p>Forks: 1,207</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://lapce.dev&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;extra/images/logo.png&quot; width=200 height=200/&gt;&lt;br&gt;
  Lapce
  &lt;/a&gt;
&lt;/h1&gt;

&lt;h4 align=&quot;center&quot;&gt;Lightning-fast And Powerful Code Editor&lt;/h4&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/lapce/lapce/actions/workflows/ci.yml&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://github.com/lapce/lapce/actions/workflows/ci.yml/badge.svg&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/n8tGJ6Rn6D&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/946858761413328946?logo=discord&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://docs.lapce.dev&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/static/v1?label=Docs&amp;message=docs.lapce.dev&amp;color=blue&quot; alt=&quot;Lapce Docs&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://wiki.mutable.ai/lapce/lapce&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/static/v1?label=Code Wiki&amp;message=Mutable.ai&amp;color=blue&quot; alt=&quot;Mutable.ai Auto Wiki&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;br/&gt;


Lapce (IPA: /l√¶ps/) is written in pure Rust, with a UI in [Floem](https://github.com/lapce/floem). It is designed with [Rope Science](https://xi-editor.io/docs/rope_science_00.html) from the [Xi-Editor](https://github.com/xi-editor/xi-editor), enabling lightning-fast computation, and leverages [wgpu](https://github.com/gfx-rs/wgpu) for rendering. More information about the features of Lapce can be found on the [main website](https://lapce.dev) and user documentation can be found on [GitBook](https://docs.lapce.dev/).

![](https://github.com/lapce/lapce/blob/master/extra/images/screenshot.png?raw=true)

## Features

* Built-in LSP ([Language Server Protocol](https://microsoft.github.io/language-server-protocol/)) support to give you intelligent code features such as: completion, diagnostics and code actions
* Modal editing support as first class citizen (Vim-like, and toggleable)
* Built-in remote development support inspired by [VSCode Remote Development](https://code.visualstudio.com/docs/remote/remote-overview). Enjoy the benefits of a &quot;local&quot; experience, and seamlessly gain the full power of a remote system. We also have [Lapdev](https://lap.dev/) which can help manage your remote dev environments. 
* Plugins can be written in programming languages that can compile to the [WASI](https://wasi.dev/) format (C, Rust, [AssemblyScript](https://www.assemblyscript.org/))
* Built-in terminal, so you can execute commands in your workspace, without leaving Lapce.

## Installation

You can find pre-built releases for Windows, Linux and macOS [here](https://github.com/lapce/lapce/releases), or [installing with a package manager](docs/installing-with-package-manager.md).
If you&#039;d like to compile from source, you can find the [guide](docs/building-from-source.md).

## Contributing

&lt;a href=&quot;https://ws.lap.dev/#https://github.com/lapce/lapce&quot; target=&quot;_blank&quot;&gt;
      &lt;img src=&quot;https://lap.dev/images/open-in-lapdev.svg?version=8&quot; alt=&quot;Open in Lapdev&quot;&gt;
&lt;/a&gt;

[Lapdev](https://lap.dev/), developed by the Lapce team, is a cloud dev env service similar to GitHub Codespaces. By clicking the button above, you&#039;ll be taken to a fully set up Lapce dev env where you can browse the code and start developing. All dependencies are pre-installed, so you can get straight to code.

Guidelines for contributing to Lapce can be found in [`CONTRIBUTING.md`](CONTRIBUTING.md).

## Feedback &amp; Contact

The most popular place for Lapce developers and users is on the [Discord server](https://discord.gg/n8tGJ6Rn6D).

Or, join the discussion on [Reddit](https://www.reddit.com/r/lapce/) where we are just getting started.

There is also a [Matrix Space](https://matrix.to/#/#lapce-editor:matrix.org), which is linked to the content from the Discord server.

## License

Lapce is released under the Apache License Version 2, which is an open source license. You may contribute to this project, or use the code as you please as long as you adhere to its conditions. You can find a copy of the license text here: [`LICENSE`](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[paritytech/polkadot-sdk]]></title>
            <link>https://github.com/paritytech/polkadot-sdk</link>
            <guid>https://github.com/paritytech/polkadot-sdk</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:36 GMT</pubDate>
            <description><![CDATA[The Parity Polkadot Blockchain SDK]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paritytech/polkadot-sdk">paritytech/polkadot-sdk</a></h1>
            <p>The Parity Polkadot Blockchain SDK</p>
            <p>Language: Rust</p>
            <p>Stars: 2,562</p>
            <p>Forks: 1,087</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![SDK Logo](./docs/images/Polkadot_Logo_Horizontal_Pink_White.png#gh-dark-mode-only)
![SDK Logo](./docs/images/Polkadot_Logo_Horizontal_Pink_Black.png#gh-light-mode-only)

# Polkadot SDK

![GitHub stars](https://img.shields.io/github/stars/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub
forks](https://img.shields.io/github/forks/paritytech/polkadot-sdk)

&lt;!-- markdownlint-disable-next-line MD013 --&gt;
[![StackExchange](https://img.shields.io/badge/StackExchange-Community%20&amp;%20Support-222222?logo=stackexchange)](https://substrate.stackexchange.com/)&amp;nbsp;&amp;nbsp;![GitHub contributors](https://img.shields.io/github/contributors/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub commit activity](https://img.shields.io/github/commit-activity/m/paritytech/polkadot-sdk)&amp;nbsp;&amp;nbsp;![GitHub last commit](https://img.shields.io/github/last-commit/paritytech/polkadot-sdk)

&gt; The Polkadot SDK repository provides all the components needed to start building on the
&gt; [Polkadot](https://polkadot.com/) network, a multi-chain blockchain platform that enables
&gt; different blockchains to interoperate and share information in a secure and scalable way.

&lt;/div&gt;

## ‚ö° Quickstart
If you want to get an example node running quickly you can execute the following getting started script:

```
curl --proto &#039;=https&#039; --tlsv1.2 -sSf https://raw.githubusercontent.com/paritytech/polkadot-sdk/master/scripts/getting-started.sh | bash
```

## üë©üèΩ‚Äçüíª Building

In order to build this project you need to install some dependencies, follow the instructions in [this guide](https://docs.polkadot.com/develop/parachains/install-polkadot-sdk).

### üéØ Build targets

When building full runtimes, the WASM builder takes care of all required configuration.  
For individual crates, however, there are a few caveats when targeting `no_std`.

#### WASM
Set `RUSTFLAGS=&quot;--cfg substrate_runtime&quot;` when building for WASM. See the
[WASM build](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/substrate/index.html#wasm-build)
in the Polkadot SDK Documentation.

#### PolkaVM
PolkaVM builds require some `riscv32` or `riscv64` target architecture.  
See the CI example: [RiscV-build](https://github.com/paritytech/polkadot-sdk/blob/6de451a105ca0a5feb675a215d4e8de5207febf6/.github/workflows/build-misc.yml#L55).

## üìö Documentation

* [Polkadot Documentation Portal](https://docs.polkadot.com)
* [ü¶Ä rust-docs](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/index.html): Where we keep track of
the API docs of our Rust crates. Includes:
  * [Introduction](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/index.html)
	to each component of the Polkadot SDK: Substrate, FRAME, Cumulus, and XCM
  * [Guides](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/guides/index.html),
	namely how to build your first FRAME pallet
  * [Templates](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/polkadot_sdk/templates/index.html)
    for starting a new project.
  * [External Resources](https://paritytech.github.io/polkadot-sdk/master/polkadot_sdk_docs/external_resources/index.html)
* Have a question? You can ask in the Polkadot SDK Developers Chat.
Messages from either of these channels are bridged to the other, so you can use whichever one you like.
  * [Telegram](https://t.me/substratedevs)
  * [Matrix](https://matrix.to/#/#substratedevs:matrix.org)
  * [Discord](https://discord.com/channels/722223075629727774/997505821955076196)
  * [Polkadot and Substrate StackExchange](https://substrate.stackexchange.com/)

## üöÄ Releases

&lt;!-- markdownlint-disable-next-line MD013 --&gt;
![Current Stable Release](https://raw.githubusercontent.com/paritytech/release-registry/main/badges/polkadot-sdk-latest.svg)&amp;nbsp;&amp;nbsp;![Next Stable Release](https://raw.githubusercontent.com/paritytech/release-registry/main/badges/polkadot-sdk-next.svg)

The Polkadot SDK is released every three months as a `Polkadot stableYYMM` release. Each stable release is supported for
one year with patches. See the next upcoming versions in the [Release
Registry](https://github.com/paritytech/release-registry/) and more docs in [RELEASE.md](./docs/RELEASE.md).

You can use [`psvm`](https://github.com/paritytech/psvm) to update all dependencies to a specific
version without needing to manually select the correct version for each crate.

## üõ†Ô∏è Tooling

[Polkadot SDK Version Manager](https://github.com/paritytech/psvm):
A simple tool to manage and update the Polkadot SDK dependencies in any Cargo.toml file.
It will automatically update the Polkadot SDK dependencies to their correct crates.io version.

## üîê Security

The security policy and procedures can be found in
[docs/contributor/SECURITY.md](./docs/contributor/SECURITY.md).

## ü§ç Contributing &amp; Code of Conduct

Ensure you follow our [contribution guidelines](./docs/contributor/CONTRIBUTING.md). In every
interaction and contribution, this project adheres to the [Contributor Covenant Code of
Conduct](./docs/contributor/CODE_OF_CONDUCT.md).

### üëæ Ready to Contribute?

Take a look at the issues labeled with [`mentor`](https://github.com/paritytech/polkadot-sdk/labels/C1-mentor)
(or alternatively [this](https://mentor.tasty.limo/) page, created by one of the maintainers) label to get started!
We always recognize valuable contributions by proposing an on-chain tip to the Polkadot network as a token of our
appreciation.

## Polkadot Fellowship

Development in this repo usually goes hand in hand with the `fellowship` organization. In short,
this repository provides all the SDK pieces needed to build both Polkadot and its parachains. But,
the actual Polkadot runtime lives in the `fellowship/runtimes` repository. Read more about the
fellowship, this separation, the RFC process
[here](https://polkadot-fellows.github.io/dashboard/).

## History

This repository is the amalgamation of 3 separate repositories that used to make up Polkadot SDK,
namely Substrate, Polkadot and Cumulus. Read more about the merge and its history
[here](https://polkadot-public.notion.site/Polkadot-SDK-FAQ-fbc4cecc2c46443fb37b9eeec2f0d85f).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[Zackriya-Solutions/meeting-minutes]]></title>
            <link>https://github.com/Zackriya-Solutions/meeting-minutes</link>
            <guid>https://github.com/Zackriya-Solutions/meeting-minutes</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:35 GMT</pubDate>
            <description><![CDATA[Open-source Rust based AI meeting assistant with 4x faster Parakeet/Whisper live transcription, speaker diarization, and Ollama summarization. 100% local processing. no cloud required. Meetily (Meetly Ai - https://meetily.ai) is the #1 Self-hosted Ai meeting note taker for macOS & Windows.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Zackriya-Solutions/meeting-minutes">Zackriya-Solutions/meeting-minutes</a></h1>
            <p>Open-source Rust based AI meeting assistant with 4x faster Parakeet/Whisper live transcription, speaker diarization, and Ollama summarization. 100% local processing. no cloud required. Meetily (Meetly Ai - https://meetily.ai) is the #1 Self-hosted Ai meeting note taker for macOS & Windows.</p>
            <p>Language: Rust</p>
            <p>Stars: 8,582</p>
            <p>Forks: 694</p>
            <p>Stars today: 45 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; style=&quot;border-bottom: none&quot;&gt;
    &lt;h1&gt;
        &lt;img src=&quot;docs/Meetily-6.png&quot; style=&quot;border-radius: 10px;&quot; /&gt;
        &lt;br&gt;
        Privacy-First AI Meeting Assistant
    &lt;/h1&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/13272&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13272&quot; alt=&quot;Zackriya-Solutions%2Fmeeting-minutes | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
    &lt;br&gt;
    &lt;br&gt;
    &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Pre_Release-Link-brightgreen&quot; alt=&quot;Pre-Release&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases&quot;&gt;&lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/zackriya-solutions/meeting-minutes?style=flat&quot;&gt;
&lt;/a&gt;
 &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases&quot;&gt; &lt;img alt=&quot;GitHub Downloads (all assets, all releases)&quot; src=&quot;https://img.shields.io/github/downloads/zackriya-solutions/meeting-minutes/total?style=plastic&quot;&gt; &lt;/a&gt;
    &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-MIT-blue&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Supported_OS-macOS,_Windows-white&quot; alt=&quot;Supported OS&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/Zackriya-Solutions/meeting-minutes/releases&quot;&gt;&lt;img alt=&quot;GitHub Tag&quot; src=&quot;https://img.shields.io/github/v/tag/zackriya-solutions/meeting-minutes?include_prereleases&amp;color=yellow&quot;&gt;
&lt;/a&gt;
    &lt;br&gt;
    &lt;h3&gt;
    &lt;br&gt;
    Open Source ‚Ä¢ Privacy-First ‚Ä¢ Enterprise-Ready
    &lt;/h3&gt;
    &lt;p align=&quot;center&quot;&gt;
    Get latest &lt;a href=&quot;https://www.zackriya.com/meetily-subscribe/&quot;&gt;&lt;b&gt;Product updates&lt;/b&gt;&lt;/a&gt; &lt;br&gt;&lt;br&gt;
    &lt;a href=&quot;https://meetily.zackriya.com&quot;&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://www.linkedin.com/company/106363062/&quot;&gt;&lt;b&gt;LinkedIn&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://discord.gg/crRymMQBFH&quot;&gt;&lt;b&gt;Meetily Discord&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://discord.com/invite/vCFJvN4BwJ&quot;&gt;&lt;b&gt;Privacy-First AI&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://www.reddit.com/r/meetily/&quot;&gt;&lt;b&gt;Reddit&lt;/b&gt;&lt;/a&gt;
&lt;/p&gt;
    &lt;p align=&quot;center&quot;&gt;

 A privacy-first AI meeting assistant that captures, transcribes, and summarizes meetings entirely on your infrastructure. Built by expert AI engineers passionate about data sovereignty and open source solutions. Perfect for enterprises that need advanced meeting intelligence without compromising on privacy, compliance, or control.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/meetily_demo.gif&quot; width=&quot;650&quot; alt=&quot;Meetily Demo&quot; /&gt;
    &lt;br&gt;
    &lt;a href=&quot;https://youtu.be/6FnhSC_eSz8&quot;&gt;View full Demo Video&lt;/a&gt;
&lt;/p&gt;

&lt;/div&gt;

&lt;details&gt;
&lt;summary&gt;Table of Contents&lt;/summary&gt;

- [Introduction](#introduction)
- [Why Meetily?](#why-meetily)
- [Features](#features)
- [Installation](#installation)
- [Key Features in Action](#key-features-in-action)
- [System Architecture](#system-architecture)
- [For Developers](#for-developers)
- [Enterprise Solutions](#enterprise-solutions)
- [Contributing](#contributing)
- [License](#license)

&lt;/details&gt;

## Introduction

Meetily is a privacy-first AI meeting assistant that runs entirely on your local machine. It captures your meetings, transcribes them in real-time, and generates summaries, all without sending any data to the cloud. This makes it the perfect solution for professionals and enterprises who need to maintain complete control over their sensitive information.

## Why Meetily?

While there are many meeting transcription tools available, this solution stands out by offering:

- **Privacy First:** All processing happens locally on your device.
- **Cost-Effective:** Uses open-source AI models instead of expensive APIs.
- **Flexible:** Works offline and supports multiple meeting platforms.
- **Customizable:** Self-host and modify for your specific needs.

&lt;details&gt;
&lt;summary&gt;The Privacy Problem&lt;/summary&gt;

Meeting AI tools create significant privacy and compliance risks across all sectors:

- **$4.4M average cost per data breach** (IBM 2024)
- **‚Ç¨5.88 billion in GDPR fines** issued by 2025
- **400+ unlawful recording cases** filed in California this year

Whether you&#039;re a defense consultant, enterprise executive, legal professional, or healthcare provider, your sensitive discussions shouldn&#039;t live on servers you don&#039;t control. Cloud meeting tools promise convenience but deliver privacy nightmares with unclear data storage practices and potential unauthorized access.

**Meetily solves this:** Complete data sovereignty on your infrastructure, zero vendor lock-in, and full control over your sensitive conversations.

&lt;/details&gt;

## Features

- **Local First:** All processing is done on your machine. No data ever leaves your computer.
- **Real-time Transcription:** Get a live transcript of your meeting as it happens.
- **AI-Powered Summaries:** Generate summaries of your meetings using powerful language models.
- **Multi-Platform:** Works on macOS, Windows, and Linux.
- **Open Source:** Meetily is open source and free to use.

## Installation

### ü™ü **Windows**

1. Download the latest `x64-setup.exe` from [Releases](https://github.com/Zackriya-Solutions/meeting-minutes/releases/latest)
2. Right-click the downloaded file ‚Üí **Properties** ‚Üí Check **Unblock** ‚Üí Click **OK**
3. Run the installer (if Windows shows a security warning: Click **More info** ‚Üí **Run anyway**)

### üçé **macOS**

### üçé **macOS** (M Series chips)

1. [meetily_0.1.1_aarch64.dmg](https://github.com/Zackriya-Solutions/meeting-minutes/releases/download/0.1.1/meetily_0.1.1_aarch64.dmg)
2. Install the .dmg
3. Then open **meetily.app** from Applications folder.

&gt; **‚ö†Ô∏è Data Migration:** The application will ask whether to import your old database through a popup window on first launch.

### üêß **Linux**

Build from source following our detailed guides:

- [Building on Linux](docs/building_in_linux.md)
- [General Build Instructions](docs/BUILDING.md)

**Quick start:**

```bash
git clone https://github.com/Zackriya-Solutions/meeting-minutes
cd meeting-minutes/frontend
pnpm install
pnpm run tauri:build
```

## Key Features in Action

### üéØ Local Transcription

Transcribe meetings entirely on your device using **Whisper** or **Parakeet** models. No cloud required.
&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/home.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Meetily Demo&quot; /&gt;
&lt;/p&gt;

### ü§ñ AI-Powered Summaries

Generate meeting summaries with your choice of AI provider. **Ollama** (local) is recommended, with support for Claude, Groq, OpenRouter, and OpenAI.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/summary.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Summary generation&quot; /&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/editor1.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Editor Summary generation&quot; /&gt;
&lt;/p&gt;

### üîí Privacy-First Design

All data stays on your machine. Transcription models, recordings, and transcripts are stored locally.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/settings.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Local Transcription and storage&quot; /&gt;
&lt;/p&gt;

### üéôÔ∏è Professional Audio Mixing

Capture microphone and system audio simultaneously with intelligent ducking and clipping prevention.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;docs/audio.png&quot; width=&quot;650&quot; style=&quot;border-radius: 10px;&quot; alt=&quot;Device selection&quot; /&gt;
&lt;/p&gt;

### ‚ö° GPU Acceleration

Built-in support for hardware acceleration across platforms:

- **macOS**: Apple Silicon (Metal) + CoreML
- **Windows/Linux**: NVIDIA (CUDA), AMD/Intel (Vulkan)

Automatically enabled at build time - no configuration needed.

## System Architecture

Meetily is a single, self-contained application built with [Tauri](https://tauri.app/). It uses a Rust-based backend to handle all the core logic, and a Next.js frontend for the user interface.

For more details, see the [Architecture documentation](docs/architecture.md).

## For Developers

If you want to contribute to Meetily or build it from source, you&#039;ll need to have Rust and Node.js installed. For detailed build instructions, please see the [Building from Source guide](docs/BUILDING.md).

## Enterprise Solutions

**Meetily Enterprise** is available for on-premise deployment, giving organizations complete control over their meeting intelligence infrastructure. This enterprise version includes:

- **100% On-Premise Deployment**: Your data never leaves your infrastructure
- **Centralized Management**: Support for 100+ users with administrative controls
- **Zero Vendor Lock-in**: Open source MIT license ensures complete ownership
- **Compliance Ready**: Meet GDPR, SOX, HIPAA, and industry-specific requirements
- **Custom Integration**: APIs and webhooks for enterprise systems

For enterprise solutions: [https://meetily.zackriya.com](https://meetily.zackriya.com)

## Contributing

We welcome contributions from the community! If you have any questions or suggestions, please open an issue or submit a pull request. Please follow the established project structure and guidelines. For more details, refer to the [CONTRIBUTING.md](CONTRIBUTING.md) file.

## License

MIT License - Feel free to use this project for your own purposes.

## Contributions

Thanks for all the contributions. Our community is what makes this project possible. Below is the list of contributors:

&lt;a href=&quot;https://github.com/zackriya-solutions/meeting-minutes/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=zackriya-solutions/meeting-minutes&quot; /&gt;
&lt;/a&gt;

We welcome contributions from the community! If you have any questions or suggestions, please open an issue or submit a pull request. Please follow the established project structure and guidelines. For more details, refer to the [CONTRIBUTING](CONTRIBUTING.md) file.

## Acknowledgments

- We borrowed some code from [Whisper.cpp](https://github.com/ggerganov/whisper.cpp).
- We borrowed some code from [Screenpipe](https://github.com/mediar-ai/screenpipe).
- We borrowed some code from [transcribe-rs](https://crates.io/crates/transcribe-rs).
- Thanks to **NVIDIA** for developing the **Parakeet** model.
- Thanks to [istupakov](https://huggingface.co/istupakov/parakeet-tdt-0.6b-v3-onnx) for providing the **ONNX conversion** of the Parakeet model.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Zackriya-Solutions/meeting-minutes&amp;type=Date)](https://star-history.com/#Zackriya-Solutions/meeting-minutes&amp;Date)

</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[nautechsystems/nautilus_trader]]></title>
            <link>https://github.com/nautechsystems/nautilus_trader</link>
            <guid>https://github.com/nautechsystems/nautilus_trader</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:34 GMT</pubDate>
            <description><![CDATA[A high-performance algorithmic trading platform and event-driven backtester]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/nautechsystems/nautilus_trader">nautechsystems/nautilus_trader</a></h1>
            <p>A high-performance algorithmic trading platform and event-driven backtester</p>
            <p>Language: Rust</p>
            <p>Stars: 16,557</p>
            <p>Forks: 1,945</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># &lt;img src=&quot;https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader-logo.png&quot; width=&quot;500&quot;&gt;

[![codecov](https://codecov.io/gh/nautechsystems/nautilus_trader/branch/master/graph/badge.svg?token=DXO9QQI40H)](https://codecov.io/gh/nautechsystems/nautilus_trader)
[![codspeed](https://img.shields.io/endpoint?url=https://codspeed.io/badge.json)](https://codspeed.io/nautechsystems/nautilus_trader)
![pythons](https://img.shields.io/pypi/pyversions/nautilus_trader)
![pypi-version](https://img.shields.io/pypi/v/nautilus_trader)
![pypi-format](https://img.shields.io/pypi/format/nautilus_trader?color=blue)
[![Downloads](https://pepy.tech/badge/nautilus-trader)](https://pepy.tech/project/nautilus-trader)
[![Discord](https://img.shields.io/badge/Discord-%235865F2.svg?logo=discord&amp;logoColor=white)](https://discord.gg/NautilusTrader)

| Branch    | Version                                                                                                                                                                                                                     | Status                                                                                                                                                                                            |
| :-------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `master`  | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fmaster%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html)  | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `nightly` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fnightly%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=nightly)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |
| `develop` | [![version](https://img.shields.io/endpoint?url=https%3A%2F%2Fraw.githubusercontent.com%2Fnautechsystems%2Fnautilus_trader%2Fdevelop%2Fversion.json)](https://packages.nautechsystems.io/simple/nautilus-trader/index.html) | [![build](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml/badge.svg?branch=develop)](https://github.com/nautechsystems/nautilus_trader/actions/workflows/build.yml) |

| Platform           | Rust   | Python    |
| :----------------- | :----- | :-------- |
| `Linux (x86_64)`   | 1.90.0 | 3.11-3.13 |
| `Linux (ARM64)`    | 1.90.0 | 3.11-3.13 |
| `macOS (ARM64)`    | 1.90.0 | 3.11-3.13 |
| `Windows (x86_64)` | 1.90.0 | 3.11-3.13 |

- **Docs**: &lt;https://nautilustrader.io/docs/&gt;
- **Website**: &lt;https://nautilustrader.io&gt;
- **Support**: [support@nautilustrader.io](mailto:support@nautilustrader.io)

## Introduction

NautilusTrader is an open-source, high-performance, production-grade algorithmic trading platform,
providing quantitative traders with the ability to backtest portfolios of automated trading strategies
on historical data with an event-driven engine, and also deploy those same strategies live, with no code changes.

The platform is *AI-first*, designed to develop and deploy algorithmic trading strategies within a highly performant
and robust Python-native environment. This helps to address the parity challenge of keeping the Python research/backtest
environment consistent with the production live trading environment.

NautilusTrader&#039;s design, architecture, and implementation philosophy prioritizes software correctness and safety at the
highest level, with the aim of supporting Python-native, mission-critical, trading system backtesting
and live deployment workloads.

The platform is also universal, and asset-class-agnostic ‚Äî with any REST API or WebSocket feed able to be integrated via modular
adapters. It supports high-frequency trading across a wide range of asset classes and instrument types
including FX, Equities, Futures, Options, Crypto, DeFi, and Betting ‚Äî enabling seamless operations across multiple venues simultaneously.

![nautilus-trader](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-trader.png &quot;nautilus-trader&quot;)

## Features

- **Fast**: Core is written in Rust with asynchronous networking using [tokio](https://crates.io/crates/tokio).
- **Reliable**: Rust-powered type- and thread-safety, with optional Redis-backed state persistence.
- **Portable**: OS independent, runs on Linux, macOS, and Windows. Deploy using Docker.
- **Flexible**: Modular adapters mean any REST API or WebSocket feed can be integrated.
- **Advanced**: Time in force `IOC`, `FOK`, `GTC`, `GTD`, `DAY`, `AT_THE_OPEN`, `AT_THE_CLOSE`, advanced order types and conditional triggers. Execution instructions `post-only`, `reduce-only`, and icebergs. Contingency orders including `OCO`, `OUO`, `OTO`.
- **Customizable**: Add user-defined custom components, or assemble entire systems from scratch leveraging the [cache](https://nautilustrader.io/docs/latest/concepts/cache) and [message bus](https://nautilustrader.io/docs/latest/concepts/message_bus).
- **Backtesting**: Run with multiple venues, instruments and strategies simultaneously using historical quote tick, trade tick, bar, order book and custom data with nanosecond resolution.
- **Live**: Use identical strategy implementations between backtesting and live deployments.
- **Multi-venue**: Multiple venue capabilities facilitate market-making and statistical arbitrage strategies.
- **AI Training**: Backtest engine fast enough to be used to train AI trading agents (RL/ES).

![Alt text](https://github.com/nautechsystems/nautilus_trader/raw/develop/assets/nautilus-art.png &quot;nautilus&quot;)

&gt; *nautilus - from ancient Greek &#039;sailor&#039; and naus &#039;ship&#039;.*
&gt;
&gt; *The nautilus shell consists of modular chambers with a growth factor which approximates a logarithmic spiral.
&gt; The idea is that this can be translated to the aesthetics of design and architecture.*

## Why NautilusTrader?

- **Highly performant event-driven Python**: Native binary core components.
- **Parity between backtesting and live trading**: Identical strategy code.
- **Reduced operational risk**: Enhanced risk management functionality, logical accuracy, and type safety.
- **Highly extendable**: Message bus, custom components and actors, custom data, custom adapters.

Traditionally, trading strategy research and backtesting might be conducted in Python
using vectorized methods, with the strategy then needing to be reimplemented in a more event-driven way
using C++, C#, Java or other statically typed language(s). The reasoning here is that vectorized backtesting code cannot
express the granular time and event dependent complexity of real-time trading, where compiled languages have
proven to be more suitable due to their inherently higher performance, and type safety.

One of the key advantages of NautilusTrader here, is that this reimplementation step is now circumvented - as the critical core components of the platform
have all been written entirely in [Rust](https://www.rust-lang.org/) or [Cython](https://cython.org/).
This means we&#039;re using the right tools for the job, where systems programming languages compile performant binaries,
with CPython C extension modules then able to offer a Python-native environment, suitable for professional quantitative traders and trading firms.

## Why Python?

Python was originally created decades ago as a simple scripting language with a clean straightforward syntax.
It has since evolved into a fully fledged general purpose object-oriented programming language.
Based on the TIOBE index, Python is currently the most popular programming language in the world.
Not only that, Python has become the *de facto lingua franca* of data science, machine learning, and artificial intelligence.

## Why Rust?

[Rust](https://www.rust-lang.org/) is a multi-paradigm programming language designed for performance and safety, especially safe
concurrency. Rust is &quot;blazingly fast&quot; and memory-efficient (comparable to C and C++) with no garbage collector.
It can power mission-critical systems, run on embedded devices, and easily integrates with other languages.

Rust‚Äôs rich type system and ownership model guarantees memory-safety and thread-safety deterministically ‚Äî
eliminating many classes of bugs at compile-time.

The project increasingly utilizes Rust for core performance-critical components. Python bindings are implemented via Cython and [PyO3](https://pyo3.rs)‚Äîno Rust toolchain is required at install time.

This project makes the [Soundness Pledge](https://raphlinus.github.io/rust/2020/01/18/soundness-pledge.html):

&gt; ‚ÄúThe intent of this project is to be free of soundness bugs.
&gt; The developers will do their best to avoid them, and welcome help in analyzing and fixing them.‚Äù

&gt; [!NOTE]
&gt;
&gt; **MSRV:** NautilusTrader relies heavily on improvements in the Rust language and compiler.
&gt; As a result, the Minimum Supported Rust Version (MSRV) is generally equal to the latest stable release of Rust.

## Integrations

NautilusTrader is modularly designed to work with *adapters*, enabling connectivity to trading venues
and data providers by translating their raw APIs into a unified interface and normalized domain model.

The following integrations are currently supported; see [docs/integrations/](https://nautilustrader.io/docs/latest/integrations/) for details:

| Name                                                                         | ID                    | Type                    | Status                                                  | Docs                                        |
| :--------------------------------------------------------------------------- | :-------------------- | :---------------------- | :------------------------------------------------------ | :------------------------------------------ |
| [Betfair](https://betfair.com)                                               | `BETFAIR`             | Sports Betting Exchange | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/betfair.md)       |
| [Binance](https://binance.com)                                               | `BINANCE`             | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/binance.md)       |
| [BitMEX](https://www.bitmex.com)                                             | `BITMEX`              | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/bitmex.md)        |
| [Bybit](https://www.bybit.com)                                               | `BYBIT`               | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/bybit.md)         |
| [Coinbase International](https://www.coinbase.com/en/international-exchange) | `COINBASE_INTX`       | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/coinbase_intx.md) |
| [Databento](https://databento.com)                                           | `DATABENTO`           | Data Provider           | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/databento.md)     |
| [dYdX](https://dydx.exchange/)                                               | `DYDX`                | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/dydx.md)          |
| [Hyperliquid](https://hyperliquid.xyz)                                       | `HYPERLIQUID`         | Crypto Exchange (DEX)   | ![status](https://img.shields.io/badge/building-orange) | [Guide](docs/integrations/hyperliquid.md)   |
| [Interactive Brokers](https://www.interactivebrokers.com)                    | `INTERACTIVE_BROKERS` | Brokerage (multi-venue) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/ib.md)            |
| [OKX](https://okx.com)                                                       | `OKX`                 | Crypto Exchange (CEX)   | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/okx.md)           |
| [Polymarket](https://polymarket.com)                                         | `POLYMARKET`          | Prediction Market (DEX) | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/polymarket.md)    |
| [Tardis](https://tardis.dev)                                                 | `TARDIS`              | Crypto Data Provider    | ![status](https://img.shields.io/badge/stable-green)    | [Guide](docs/integrations/tardis.md)        |

- **ID**: The default client ID for the integrations adapter clients.
- **Type**: The type of integration (often the venue type).

### Status

- `building`: Under construction and likely not in a usable state.
- `beta`: Completed to a minimally working state and in a beta testing phase.
- `stable`: Stabilized feature set and API, the integration has been tested by both developers and users to a reasonable level (some bugs may still remain).

See the [Integrations](https://nautilustrader.io/docs/latest/integrations/index.html) documentation for further details.

## Versioning and releases

&gt; [!WARNING]
&gt;
&gt; **NautilusTrader is still under active development**. Some features may be incomplete, and while
&gt; the API is becoming more stable, breaking changes can occur between releases.
&gt; We strive to document these changes in the release notes on a **best-effort basis**.

We aim to follow a **bi-weekly release schedule**, though experimental or larger features may cause delays.

### Branches

We aim to maintain a stable, passing build across all branches.

- `master`: Reflects the source code for the latest released version; recommended for production use.
- `nightly`: Daily snapshots of the `develop` branch for early testing; merged at **14:00 UTC** and as required.
- `develop`: Active development branch for contributors and feature work.

&gt; [!NOTE]
&gt;
&gt; Our [roadmap](/ROADMAP.md) aims to achieve a **stable API for version 2.x** (likely after the Rust port).
&gt; Once this milestone is reached, we plan to implement a formal deprecation process for any API changes.
&gt; This approach allows us to maintain a rapid development pace for now.

## Precision mode

NautilusTrader supports two precision modes for its core value types (`Price`, `Quantity`, `Money`),
which differ in their internal bit-width and maximum decimal precision.

- **High-precision**: 128-bit integers with up to 16 decimals of precision, and a larger value range.
- **Standard-precision**: 64-bit integers with up to 9 decimals of precision, and a smaller value range.

&gt; [!NOTE]
&gt;
&gt; By default, the official Python wheels ship in high-precision (128-bit) mode on Linux and macOS.
&gt; On Windows, only standard-precision (64-bit) is available due to the lack of native 128-bit integer support.
&gt; For the Rust crates, the default is standard-precision unless you explicitly enable the `high-precision` feature flag.

See the [Installation Guide](https://nautilustrader.io/docs/latest/getting_started/installation) for further details.

**Rust feature flag**: To enable high-precision mode in Rust, add the `high-precision` feature to your Cargo.toml:

```toml
[dependencies]
nautilus_model = { version = &quot;*&quot;, features = [&quot;high-precision&quot;] }
```

## Installation

We recommend using the latest supported version of Python and installing [nautilus_trader](https://pypi.org/project/nautilus_trader/) inside a virtual environment to isolate dependencies.

**There are two supported ways to install**:

1. Pre-built binary wheel from PyPI *or* the Nautech Systems package index.
2. Build from source.

&gt; [!TIP]
&gt;
&gt; We highly recommend installing using the [uv](https://docs.astral.sh/uv) package manager with a &quot;vanilla&quot; CPython.
&gt;
&gt; Conda and other Python distributions *may* work but aren‚Äôt officially supported.

### From PyPI

To install the latest binary wheel (or sdist package) from PyPI using Python&#039;s pip package manager:

```bash
pip install -U nautilus_trader
```

### From the Nautech Systems package index

The Nautech Systems package index (`packages.nautechsystems.io`) complies with [PEP-503](https://peps.python.org/pep-0503/) and hosts both stable and development binary wheels for `nautilus_trader`.
This enables users to install either the latest stable release or pre-release versions for testing.

#### Stable wheels

Stable wheels correspond to official releases of `nautilus_trader` on PyPI, and use standard versioning.

To install the latest stable release:

```bash
pip install -U nautilus_trader --index-url=https://packages.nautechsystems.io/simple
```

&gt; [!TIP]
&gt;
&gt; Use `--extra-index-url` instead of `--index-url` if you want pip to fall back to PyPI automatically:

#### Development wheels

Development wheels are published from both the `nightly` and `develop` branches,
allowing users to test features and fixes ahead of stable releases.

This process also helps preserve compute resources and provides easy access to the exact binaries tested in CI pipelines,
while adhering to [PEP-440](https://peps.python.org/pep-0440/) versioning standards:

- `develop` wheels use the version format `dev{date}+{build_number}` (e.g., `1.208.0.dev20241212+7001`).
- `nightly` wheels use the version format `a{date}` (alpha) (e.g., `1.208.0a20241212`).

| Platform           | Nightly | Develop |
| :----------------- | :------ | :------ |
| `Linux (x86_64)`   | ‚úì       | ‚úì       |
| `Linux (ARM64)`    | ‚úì       | -       |
| `macOS (ARM64)`    | ‚úì       | ‚úì       |
| `Windows (x86_64)` | ‚úì       | ‚úì       |

**Note**: Development wheels from the `develop` branch publish for every supported platform except Linux ARM64.
Skipping that target keeps CI feedback fast while avoiding unnecessary build resource usage.

&gt; [!WARNING]
&gt;
&gt; We do not recommend using development wheels in production environments, such as live trading controlling real capital.

#### Installation commands

By default, pip will install the latest stable release. Adding the `--pre` flag ensures that pre-release versions, including development wheels, are considered.

To install the latest available pre-release (including development wheels):

```bash
pip install -U nautilus_trader --pre --index-url=https://packages.nautechsystems.io/simple
```

To install a specific development wheel (e.g., `1.221.0a20250912` for September 12, 2025):

```bash
pip install nautilus_trader==1.221.0a20250912 --index-url=https://packages.nautechsystems.io/simple
```

#### Available versions

You can view all available versions of `nautilus_trader` on the [package index](https://packages.nautechsystems.io/simple/nautilus-trader/index.html).

To programmatically fetch and list available versions:

```bash
curl -s https://packages.nautechsystems.io/simple/nautilus-trader/index.html | grep -oP &#039;(?&lt;=&lt;a href=&quot;)[^&quot;]+(?=&quot;)&#039; | awk -F&#039;#&#039; &#039;{print $1}&#039; | sort
```

&gt; [!NOTE]
&gt;
&gt; On Linux, confirm your glibc version with `ldd --version` and ensure it reports **2.35** or newer before installing binary wheels.

#### Branch updates

- `develop` branch wheels (`.dev`): Build and publish continuously with every merged commit.
- `nightly` branch wheels (`a`): Build and publish daily whe

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vercel/turborepo]]></title>
            <link>https://github.com/vercel/turborepo</link>
            <guid>https://github.com/vercel/turborepo</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:33 GMT</pubDate>
            <description><![CDATA[Build system optimized for JavaScript¬†and TypeScript, written in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vercel/turborepo">vercel/turborepo</a></h1>
            <p>Build system optimized for JavaScript¬†and TypeScript, written in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 29,208</p>
            <p>Forks: 2,181</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://turborepo.com&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://user-images.githubusercontent.com/4060187/196936123-f6e1db90-784d-4174-b774-92502b718836.png&quot;&gt;
      &lt;img src=&quot;https://user-images.githubusercontent.com/4060187/196936104-5797972c-ab10-4834-bd61-0d1e5f442c9c.png&quot; height=&quot;128&quot;&gt;
    &lt;/picture&gt;
    &lt;h1 align=&quot;center&quot;&gt;Turborepo&lt;/h1&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a aria-label=&quot;Vercel logo&quot; href=&quot;https://vercel.com/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/MADE%20BY%20Vercel-000000.svg?style=for-the-badge&amp;logo=Vercel&amp;labelColor=000&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;NPM version&quot; href=&quot;https://www.npmjs.com/package/turbo&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/npm/v/turbo.svg?style=for-the-badge&amp;labelColor=000000&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;License&quot; href=&quot;https://github.com/vercel/turborepo/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/npm/l/turbo.svg?style=for-the-badge&amp;labelColor=000000&amp;color=&quot;&gt;&lt;/a&gt;
  &lt;a aria-label=&quot;Join the community on GitHub&quot; href=&quot;https://github.com/vercel/turborepo/discussions&quot;&gt;&lt;img alt=&quot;&quot; src=&quot;https://img.shields.io/badge/Join%20the%20community-blueviolet.svg?style=for-the-badge&amp;logo=turborepo&amp;labelColor=000000&amp;logoWidth=20&amp;logoColor=white&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

Turborepo is a high-performance build system for JavaScript and TypeScript codebases, written in Rust.

## Getting Started

Visit https://turborepo.com to get started with Turborepo.

## Contributing

See [CONTRIBUTING.md](https://github.com/vercel/turborepo/blob/main/CONTRIBUTING.md) for more information.

## Community

The Turborepo community can be found on [GitHub Discussions](https://github.com/vercel/turborepo/discussions), where you can ask questions, voice ideas, and share your projects.

To chat with other community members, you can join [Vercel Community&#039;s `#turborepo` tag](https://vercel.community/tag/turborepo).

Our [Code of Conduct](https://github.com/vercel/turborepo/blob/main/CODE_OF_CONDUCT.md) applies to all Turborepo community channels.

## Who is using Turborepo?

Turborepo is used by the world&#039;s leading companies. Check out the [Turborepo Showcase](https://turborepo.com/showcase) to learn more.

## Updates

Follow [@turborepo](https://x.com/turborepo) on X for project updates.

## Security

If you believe you have found a security vulnerability in Turborepo, we encourage you to responsibly disclose this and not open a public issue. We will investigate all legitimate reports. Email `security@vercel.com` to disclose any security vulnerabilities.

https://vercel.com/security
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[shadowsocks/shadowsocks-rust]]></title>
            <link>https://github.com/shadowsocks/shadowsocks-rust</link>
            <guid>https://github.com/shadowsocks/shadowsocks-rust</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:32 GMT</pubDate>
            <description><![CDATA[A Rust port of shadowsocks]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/shadowsocks/shadowsocks-rust">shadowsocks/shadowsocks-rust</a></h1>
            <p>A Rust port of shadowsocks</p>
            <p>Language: Rust</p>
            <p>Stars: 10,065</p>
            <p>Forks: 1,361</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre># shadowsocks

[![License](https://img.shields.io/github/license/zonyitoo/shadowsocks-rust.svg)](https://github.com/zonyitoo/shadowsocks-rust)
[![Build &amp; Test](https://github.com/shadowsocks/shadowsocks-rust/actions/workflows/build-and-test.yml/badge.svg)](https://github.com/shadowsocks/shadowsocks-rust/actions/workflows/build-and-test.yml)
[![Build MSRV](https://github.com/shadowsocks/shadowsocks-rust/actions/workflows/build-msrv.yml/badge.svg)](https://github.com/shadowsocks/shadowsocks-rust/actions/workflows/build-msrv.yml)
[![Build Releases](https://github.com/shadowsocks/shadowsocks-rust/actions/workflows/build-release.yml/badge.svg?event=push)](https://github.com/shadowsocks/shadowsocks-rust/actions/workflows/build-release.yml)
[![Build Nightly Releases](https://github.com/shadowsocks/shadowsocks-rust/actions/workflows/build-nightly-release.yml/badge.svg)](https://github.com/shadowsocks/shadowsocks-rust/actions/workflows/build-nightly-release.yml)
[![Gurubase](https://img.shields.io/badge/Gurubase-Ask%20shadowsocks%20Guru-006BFF)](https://gurubase.io/g/shadowsocks)

[![crates.io](https://img.shields.io/crates/v/shadowsocks-rust.svg)](https://crates.io/crates/shadowsocks-rust)
[![Release](https://img.shields.io/github/release/shadowsocks/shadowsocks-rust.svg)](https://github.com/shadowsocks/shadowsocks-rust/releases)
[![shadowsocks-rust](https://img.shields.io/archlinux/v/extra/x86_64/shadowsocks-rust)](https://archlinux.org/packages/extra/x86_64/shadowsocks-rust/)
[![aur shadowsocks-rust-git](https://img.shields.io/aur/version/shadowsocks-rust-git)](https://aur.archlinux.org/packages/shadowsocks-rust-git)
[![NixOS](https://img.shields.io/badge/NixOS-shadowsocks--rust-blue?logo=nixos)](https://github.com/NixOS/nixpkgs/tree/master/pkgs/tools/networking/shadowsocks-rust)
[![snap shadowsocks-rust](https://snapcraft.io/shadowsocks-rust/badge.svg)](https://snapcraft.io/shadowsocks-rust)
[![homebrew shadowsocks-rust](https://img.shields.io/homebrew/v/shadowsocks-rust)](https://formulae.brew.sh/formula/shadowsocks-rust#default)
[![MacPorts shadowsocks-rust](https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Fports.macports.org%2Fapi%2Fv1%2Fports%2Fshadowsocks-rust%2F&amp;query=%24.version&amp;label=macports)](https://ports.macports.org/port/shadowsocks-rust/)

This is a port of [shadowsocks](https://github.com/shadowsocks/shadowsocks).

shadowsocks is a fast tunnel proxy that helps you bypass firewalls.

| Library                                                                 | Description                                                                                                                                                                                                                                                 |
| ----------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| [**shadowsocks**](https://crates.io/crates/shadowsocks)                 | [![crates.io](https://img.shields.io/crates/v/shadowsocks.svg)](https://crates.io/crates/shadowsocks) [![docs.rs](https://img.shields.io/docsrs/shadowsocks)](https://docs.rs/shadowsocks) shadowsocks core protocol                                        |
| [**shadowsocks-service**](https://crates.io/crates/shadowsocks-service) | [![crates.io](https://img.shields.io/crates/v/shadowsocks-service.svg)](https://crates.io/crates/shadowsocks-service) [![docs.rs](https://img.shields.io/docsrs/shadowsocks-service)](https://docs.rs/shadowsocks-service) Services for serving shadowsocks |
| [**shadowsocks-rust**](https://crates.io/crates/shadowsocks-rust)       | [![crates.io](https://img.shields.io/crates/v/shadowsocks-rust.svg)](https://crates.io/crates/shadowsocks-rust) Binaries running common shadowsocks services                                                                                                |

Related Projects:

- [spyophobia/shadowsocks-gtk-rs](https://github.com/spyophobia/shadowsocks-gtk-rs) A GUI on Linux for `sslocal` using GTK, [discussion](https://github.com/shadowsocks/shadowsocks-rust/issues/664)
- [honwen/openwrt-shadowsocks-rust](https://github.com/honwen/openwrt-shadowsocks-rust) OpenWRT solution for `sslocal`, [discussion](https://github.com/honwen/openwrt-shadowsocks-rust)
- [cg31/shadowsocks-windows-gui-rust](https://github.com/cg31/shadowsocks-windows-gui-rust) Windows GUI client, [discussion](https://github.com/shadowsocks/shadowsocks-rust/issues/375)

## Build &amp; Install

### Optional Features

- `hickory-dns` - Uses [`hickory-resolver`](https://crates.io/crates/hickory-resolver) as DNS resolver instead of `tokio`&#039;s builtin.

- `local-http` - Allow using HTTP protocol for `sslocal`

  - `local-http-native-tls` - Support HTTPS with [`native-tls`](https://crates.io/crates/native-tls)

  - `local-http-rustls` - Support HTTPS with [`rustls`](https://crates.io/crates/rustls)

- `local-tunnel` - Allow using tunnel protocol for `sslocal`

- `local-socks4` - Allow using SOCKS4/4a protocol for `sslocal`

- `local-redir` - Allow using redir (transparent proxy) protocol for `sslocal`

- `local-dns` - Allow using dns protocol for `sslocal`, serves as a DNS server proxying queries to local or remote DNS servers by ACL rules

- `local-fake-dns` - FakeDNS, allocating an IP address for each individual Query from a specific IP pool

- `local-tun` - [TUN](https://en.wikipedia.org/wiki/TUN/TAP) interface support for `sslocal`

- `local-online-config` - [SIP008](https://shadowsocks.org/doc/sip008.html) Online Configuration Delivery

- `stream-cipher` - Enable deprecated stream ciphers. WARN: stream ciphers are UNSAFE!

- `aead-cipher-extra` - Enable non-standard AEAD ciphers

- `aead-cipher-2022` - Enable AEAD-2022 ciphers ([SIP022](https://github.com/shadowsocks/shadowsocks-org/issues/196))

- `aead-cipher-2022-extra` - Enable AEAD-2022 extra ciphers (non-standard ciphers)

#### Memory Allocators

This project uses system (libc) memory allocator (Rust&#039;s default). But it also allows you to use other famous allocators by features:

- `jemalloc` - Uses [jemalloc](http://jemalloc.net/) as global memory allocator
- `mimalloc` - Uses [mi-malloc](https://microsoft.github.io/mimalloc/) as global memory allocator
- `tcmalloc` - Uses [TCMalloc](https://google.github.io/tcmalloc/overview.html) as global memory allocator. It tries to link system-wide tcmalloc by default, use vendored from source with `tcmalloc-vendored`.
- `snmalloc` - Uses [snmalloc](https://github.com/microsoft/snmalloc) as global memory allocator
- `rpmalloc` - Uses [rpmalloc](https://github.com/mjansson/rpmalloc) as global memory allocator

### **crates.io**

Install from [crates.io](https://crates.io/crates/shadowsocks-rust):

```bash
# Install from crates.io
cargo install shadowsocks-rust
```

then you can find `sslocal` and `ssserver` in `$CARGO_HOME/bin`.

### **Install using Homebrew**

For macOS and Linux, you can install it using [Homebrew](https://brew.sh/):

```bash
brew install shadowsocks-rust
```

### **Install using snap**

```bash
# Install from snapstore
snap install shadowsocks-rust

# List services
snap services shadowsocks-rust

# Enable and start shadowsocks-rust.sslocal-daemon snap service
snap start --enable shadowsocks-rust.sslocal-daemon

# Show generated systemd service status
systemctl status snap.shadowsocks-rust.sslocal-daemon.service

# Override generated systemd service (configure startup options)
systemctl edit snap.shadowsocks-rust.sslocal-daemon.service

## NOTE: you can pass args to sslocal:
##  [Service]
##  ExecStart=
##  ExecStart=/usr/bin/snap run shadowsocks-rust.sslocal-daemon -b &quot;127.0.0.1:1080&quot; --server-url &quot;ss://....&quot;

# Restart generated systemd service to apply changes
systemctl restart snap.shadowsocks-rust.sslocal-daemon.service

# ... and show service status
systemctl status snap.shadowsocks-rust.sslocal-daemon.service
```

Default configuration file path probably is `/var/snap/shadowsocks-rust/common/etc/shadowsocks-rust/config.json`.

### **Download release**

Download static-linked build [here](https://github.com/shadowsocks/shadowsocks-rust/releases).

- Most of them are built with [cross](https://github.com/cross-rs/cross). Build environment details could be found in its README, such as glibc&#039;s version.
- `x86_64-apple-darwin`, `aarch64-apple-darwin` are built in github&#039;s `macos-latest` image. Information could be found in [here](https://docs.github.com/en/actions/using-github-hosted-runners/using-github-hosted-runners/about-github-hosted-runners).
- `x86_64-pc-windows-msvc` is built in github&#039;s `windows-latest` image. Information could be found in [here](https://docs.github.com/en/actions/using-github-hosted-runners/using-github-hosted-runners/about-github-hosted-runners).

### **Docker**

This project provided Docker images for the `linux/i386` and `linux/amd64` and `linux/arm64/v8` architectures.

&gt; :warning: **Docker containers do not have access to IPv6 by default**: Make sure to disable IPv6 Route in the client or [enable IPv6 access to docker containers](https://docs.docker.com/config/daemon/ipv6/#use-ipv6-for-the-default-bridge-network).

#### Pull from GitHub Container Registry

Docker will pull the image of the appropriate architecture from our [GitHub Packages](https://github.com/orgs/shadowsocks/packages?repo_name=shadowsocks-rust).

```bash
docker pull ghcr.io/shadowsocks/sslocal-rust:latest
docker pull ghcr.io/shadowsocks/ssserver-rust:latest
```

#### Build on the local machineÔºàOptionalÔºâ

If you want to build the Docker image yourself, you need to use the [BuildX](https://docs.docker.com/buildx/working-with-buildx/).

```bash
docker buildx build -t shadowsocks/ssserver-rust:latest -t shadowsocks/ssserver-rust:v1.15.2 --target ssserver .
docker buildx build -t shadowsocks/sslocal-rust:latest -t shadowsocks/sslocal-rust:v1.15.2 --target sslocal .
```

#### Run the container

You need to mount the configuration file into the container and create an external port map for the container to connect to it.

```bash
docker run --name sslocal-rust \
  --restart always \
  -p 1080:1080/tcp \
  -v /path/to/config.json:/etc/shadowsocks-rust/config.json \
  -dit ghcr.io/shadowsocks/sslocal-rust:latest

docker run --name ssserver-rust \
  --restart always \
  -p 8388:8388/tcp \
  -p 8388:8388/udp \
  -v /path/to/config.json:/etc/shadowsocks-rust/config.json \
  -dit ghcr.io/shadowsocks/ssserver-rust:latest
```

### **Deploy to Kubernetes**

This project provided yaml manifests for deploying to Kubernetes.

You can leverage k8s Service to expose traffic outside, like LoadBalancer or NodePort which gains more fine-grained compared with fixed host or port.

For a more interesting use case, you can use a Ingress(Istio, nginx, etc.) which routes the matched traffic to shadowsocks along with the real web service.

#### Using `kubectl`

`kubectl apply -f https://github.com/shadowsocks/shadowsocks-rust/raw/master/k8s/shadowsocks-rust.yaml`

You can change the config via editing the ConfigMap named `shadowsocks-rust`.

For more fine-grained control, use `helm`.

#### Using `helm`

`helm install my-release k8s/chart -f my-values.yaml`

Below is the common default values you can change:

```yaml
# This is the shadowsocks config which will be mount to /etc/shadowocks-rust.
# You can put arbitrary yaml here, and it will be translated to json before mounting.
servers:
- server: &quot;::&quot;
  server_port: 8388
  service_port: 80 # the k8s service port, default to server_port
  password: mypassword
  method: aes-256-gcm
  fast_open: true
  mode: tcp_and_udp
  # plugin: v2ray-plugin
  # plugin_opts: server;tls;host=github.com

# Whether to download v2ray and xray plugin.
downloadPlugins: false

# Name of the ConfigMap with config.json configuration for shadowsocks-rust.
configMapName: &quot;&quot;

service:
  # Change to LoadBalancer if you are behind a cloud provider like aws, gce, or tke.
  type: ClusterIP

# Bind shadowsocks port port to host, i.e., we can use host:port to access shawdowsocks server.
hostPort: false

replicaCount: 1

image:
  repository: ghcr.io/shadowsocks/ssserver-rust
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: &quot;latest&quot;
```

### **Build from source**

Use cargo to build. NOTE: **RAM &gt;= 2GiB**

```bash
cargo build --release
```

Then `sslocal` and `ssserver` will appear in `./target/(debug|release)/`, it works similarly as the two binaries in the official ShadowSocks&#039; implementation.

```bash
make install TARGET=release
```

Then `sslocal`, `ssserver`, `ssmanager` and `ssurl` will be installed to `/usr/local/bin` (variable PREFIX).

For Windows users, if you have encountered any problem in building, check and discuss in [#102](https://github.com/shadowsocks/shadowsocks-rust/issues/102).

### **target-cpu optimization**

If you are building for your current CPU platform (for example, build and run on your personal computer), it is recommended to set `target-cpu=native` feature to let `rustc` generate and optimize code for the CPU running the compiler.

```bash
export RUSTFLAGS=&quot;-C target-cpu=native&quot;
```

### **Build standalone binaries**

Requirements:

- Docker

```bash
./build/build-release
```

Then `sslocal`, `ssserver`, `ssmanager`, `ssservice` and `ssurl` will be packaged in

- `./build/shadowsocks-${VERSION}-stable.x86_64-unknown-linux-musl.tar.xz`
- `./build/shadowsocks-${VERSION}-stable.x86_64-pc-windows-gnu.zip`

Read `Cargo.toml` for more details.

For Linux with low GLIBC versions, set `CROSS_CONFIG` to CentOS based image:

```bash
export CROSS_CONFIG=Cross-centos.toml
```

## Getting Started

Generate a safe and secured password for a specific encryption method (`aes-128-gcm` in the example) with:

```bash
ssservice genkey -m &quot;aes-128-gcm&quot;
```

Create a ShadowSocks&#039; configuration file. Example

```jsonc
{
    &quot;server&quot;: &quot;my_server_ip&quot;,
    &quot;server_port&quot;: 8388,
    &quot;password&quot;: &quot;rwQc8qPXVsRpGx3uW+Y3Lj4Y42yF9Bs0xg1pmx8/+bo=&quot;,
    &quot;method&quot;: &quot;aes-256-gcm&quot;,
    // ONLY FOR `sslocal`
    // Delete these lines if you are running `ssserver` or `ssmanager`
    &quot;local_address&quot;: &quot;127.0.0.1&quot;,
    &quot;local_port&quot;: 1080
}
```

Detailed explanation of the configuration file could be found in [shadowsocks&#039; documentation](https://github.com/shadowsocks/shadowsocks/wiki). (Link to original project, not maintained anymore !)

&gt; :warning: For snap installations, configuration file is most probably located in `/var/snap/shadowsocks-rust/common/etc/shadowsocks-rust/config.json` (see &lt;https://github.com/shadowsocks/shadowsocks-rust/issues/621&gt; / &lt;https://github.com/shadowsocks/shadowsocks-rust/issues/1146&gt;)

In shadowsocks-rust, we also have an extended configuration file format, which is able to define more than one server. You can also disable individual servers.

```jsonc
{
    &quot;servers&quot;: [
        {
            &quot;server&quot;: &quot;127.0.0.1&quot;,
            &quot;server_port&quot;: 8388,
            &quot;password&quot;: &quot;rwQc8qPXVsRpGx3uW+Y3Lj4Y42yF9Bs0xg1pmx8/+bo=&quot;,
            &quot;method&quot;: &quot;aes-256-gcm&quot;,
            &quot;timeout&quot;: 7200
        },
        {
            &quot;server&quot;: &quot;127.0.0.1&quot;,
            &quot;server_port&quot;: 8389,
            &quot;password&quot;: &quot;/dliNXn5V4jg6vBW4MnC1I8Jljg9x7vSihmk6UZpRBM=&quot;,
            &quot;method&quot;: &quot;chacha20-ietf-poly1305&quot;
        },
        {
            &quot;disabled&quot;: true,
            &quot;server&quot;: &quot;eg.disable.me&quot;,
            &quot;server_port&quot;: 8390,
            &quot;password&quot;: &quot;mGvbWWay8ueP9IHnV5F1uWGN2BRToiVCAWJmWOTLU24=&quot;,
            &quot;method&quot;: &quot;chacha20-ietf-poly1305&quot;
        }
    ],
    // ONLY FOR `sslocal`
    // Delete these lines if you are running `ssserver` or `ssmanager`
    &quot;local_port&quot;: 1080,
    &quot;local_address&quot;: &quot;127.0.0.1&quot;
}
```

`sslocal` automatically selects the best server with the lowest latency and the highest availability.

Start Shadowsocks client and server with:

```bash
sslocal -c config.json
ssserver -c config.json
```

If you Build it with Cargo:

```bash
cargo run --bin sslocal -- -c config.json
cargo run --bin ssserver -- -c config.json
```

List all available arguments with `-h`.

## Usage

Start local client with configuration file

```bash
# Read local client configuration from file
sslocal -c /path/to/shadowsocks.json
```

### Socks5 Local client

```bash
# Pass all parameters via command line
sslocal -b &quot;127.0.0.1:1080&quot; -s &quot;[::1]:8388&quot; -m &quot;aes-256-gcm&quot; -k &quot;hello-kitty&quot; --plugin &quot;v2ray-plugin&quot; --plugin-opts &quot;server;tls;host=github.com&quot;

# Pass server with SIP002 URL
sslocal -b &quot;127.0.0.1:1080&quot; --server-url &quot;ss://YWVzLTI1Ni1nY206cGFzc3dvcmQ@127.0.0.1:8388/?plugin=v2ray-plugin%3Bserver%3Btls%3Bhost%3Dgithub.com&quot;
```

### HTTP Local client

```bash
sslocal -b &quot;127.0.0.1:3128&quot; --protocol http -s &quot;[::1]:8388&quot; -m &quot;aes-256-gcm&quot; -k &quot;hello-kitty&quot;
```

All parameters are the same as Socks5 client, except `--protocol http`.

### Tunnel Local client

```bash
# Set 127.0.0.1:8080 as the target for forwarding to
sslocal --protocol tunnel -b &quot;127.0.0.1:3128&quot; -f &quot;127.0.0.1:8080&quot; -s &quot;[::1]:8388&quot; -m &quot;aes-256-gcm&quot; -k &quot;hello-kitty&quot;
```

- `--protocol tunnel` enables local client Tunnel mode
- `-f &quot;127.0.0.1:8080` sets the tunnel target address

### Transparent Proxy Local client

**NOTE**: It currently only supports

- Linux (with `iptables` targets `REDIRECT` and `TPROXY`)
- BSDs (with `pf`), such as OS X 10.10+, FreeBSD, ...

```bash
sslocal -b &quot;127.0.0.1:60080&quot; --protocol redir -s &quot;[::1]:8388&quot; -m &quot;aes-256-gcm&quot; -k &quot;hello-kitty&quot; --tcp-redir &quot;redirect&quot; --udp-redir &quot;tproxy&quot;
```

Redirects connections with `iptables` configurations to the port that `sslocal` is listening on.

- `--protocol redir` enables local client Redir mode
- (optional) `--tcp-redir` sets TCP mode to `REDIRECT` (Linux)
- (optional) `--udp-redir` sets UDP mode to `TPROXY` (Linux)

### Tun interface client

**NOTE**: It currently only supports

- Linux, Android
- macOS, iOS
- Windows

#### Linux

Create a Tun interface with name `tun0`

```bash
ip tuntap add mode tun tun0
ifconfig tun0 inet 10.255.0.1 netmask 255.255.255.0 up
```

Start `sslocal` with `--protocol tun` and binds to `tun0`

```bash
sslocal --protocol tun -s &quot;[::1]:8388&quot; -m &quot;aes-256-gcm&quot; -k &quot;hello-kitty&quot; --outbound-bind-interface lo0 --tun-interface-name tun0
```

#### macOS

```bash
sslocal --protocol tun -s &quot;[::1]:8388&quot; -m &quot;aes-256-gcm&quot; -k &quot;hello-kitty&quot; --outbound-bind-interface lo0 --tun-interface-address 10.255.0.1/24
```

It will create a Tun interface with address `10.255.0.1` and netmask `255.255.255.0`.

#### Windows

Download `wintun.dll` from [Wintun](https://www.wintun.net/), and place it in the folder with shadowsocks&#039; runnable binaries, or in the system PATH.

```powershell
sslocal --protocol tun -s &quot;[::1]:8388&quot; -m &quot;aes-256-gcm&quot; -k &quot;hello-kitty&quot; --outbound-bind-interface &quot;Ethernet 0&quot; --tun-interface-name &quot;shadowsocks&quot;
```

### Local client for Windows Service

Compile it by enabling `--features &quot;winservice&quot;` (not included in the default build):

```bash
cargo build --release --bin &quot;sswinservice&quot; --features &quot;winservice&quot;
```

Install it as a Windows Service (PowerShell):

```powershell
New-Service -Name &quot;shadowsocks-local-service&quot; `
            -DisplayName &quot;Shadowsocks Local Service&quot; `
            -BinaryPathName &quot;&lt;Path\to&gt;\sswinservice.exe local -c &lt;Path\to&gt;\local_config.json&quot;
```

There are other ways to install `sswinservice` as a Windows Service, for example, the `sc` command.

As you may have noticed that the `-BinaryPathName` contains not only just the `sswinservice.exe`, but `local -c local_config.json`. These command line parameters will be used as the default parameter when the Windows Service starts. You can also start the service with customized parameters.

Learn more from [Microsoft&#039;s Document](https://learn.microsoft.com/en-us/dotnet/framework/windows-services/introduction-to-windows-service-applications

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[cocoindex-io/cocoindex]]></title>
            <link>https://github.com/cocoindex-io/cocoindex</link>
            <guid>https://github.com/cocoindex-io/cocoindex</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:31 GMT</pubDate>
            <description><![CDATA[Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/cocoindex-io/cocoindex">cocoindex-io/cocoindex</a></h1>
            <p>Data transformation framework for AI. Ultra performant, with incremental processing. üåü Star if you like it!</p>
            <p>Language: Rust</p>
            <p>Stars: 3,531</p>
            <p>Forks: 284</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/github.svg&quot; alt=&quot;CocoIndex&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;Data transformation for AI&lt;/h1&gt;

&lt;div align=&quot;center&quot;&gt;

[![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex)
[![Documentation](https://img.shields.io/badge/Documentation-394e79?logo=readthedocs&amp;logoColor=00B9FF)](https://cocoindex.io/docs/getting_started/quickstart)
[![License](https://img.shields.io/badge/license-Apache%202.0-5B5BD6?logoColor=white)](https://opensource.org/licenses/Apache-2.0)
[![PyPI version](https://img.shields.io/pypi/v/cocoindex?color=5B5BD6)](https://pypi.org/project/cocoindex/)
&lt;!--[![PyPI - Downloads](https://img.shields.io/pypi/dm/cocoindex)](https://pypistats.org/packages/cocoindex) --&gt;
[![PyPI Downloads](https://static.pepy.tech/badge/cocoindex/month)](https://pepy.tech/projects/cocoindex)
[![CI](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/CI.yml)
[![release](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml/badge.svg?event=push&amp;color=5B5BD6)](https://github.com/cocoindex-io/cocoindex/actions/workflows/release.yml)
[![Discord](https://img.shields.io/discord/1314801574169673738?logo=discord&amp;color=5B5BD6&amp;logoColor=white)](https://discord.com/invite/zpA9S2DR7s)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/13939&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13939&quot; alt=&quot;cocoindex-io%2Fcocoindex | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

Ultra performant data transformation framework for AI, with core engine written in Rust. Support incremental processing and data lineage out-of-box.  Exceptional developer velocity. Production-ready at day 0.

‚≠ê Drop a star to help us grow!

&lt;div align=&quot;center&quot;&gt;

&lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
[Deutsch](https://readme-i18n.com/cocoindex-io/cocoindex?lang=de) |
[English](https://readme-i18n.com/cocoindex-io/cocoindex?lang=en) |
[Espa√±ol](https://readme-i18n.com/cocoindex-io/cocoindex?lang=es) |
[fran√ßais](https://readme-i18n.com/cocoindex-io/cocoindex?lang=fr) |
[Êó•Êú¨Ë™û](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ja) |
[ÌïúÍµ≠Ïñ¥](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ko) |
[Portugu√™s](https://readme-i18n.com/cocoindex-io/cocoindex?lang=pt) |
[–†—É—Å—Å–∫–∏–π](https://readme-i18n.com/cocoindex-io/cocoindex?lang=ru) |
[‰∏≠Êñá](https://readme-i18n.com/cocoindex-io/cocoindex?lang=zh)

&lt;/div&gt;

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/transformation.svg&quot; alt=&quot;CocoIndex Transformation&quot;&gt;
&lt;/p&gt;

&lt;/br&gt;

CocoIndex makes it effortless to transform data with AI, and keep source data and target in sync. Whether you‚Äôre building a vector index, creating knowledge graphs for context engineering or performing any custom data transformations ‚Äî goes beyond SQL.

&lt;/br&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img alt=&quot;CocoIndex Features&quot; src=&quot;https://cocoindex.io/images/venn2.svg&quot; /&gt;
&lt;/p&gt;

&lt;/br&gt;

## Exceptional velocity

Just declare transformation in dataflow with ~100 lines of python

```python
# import
data[&#039;content&#039;] = flow_builder.add_source(...)

# transform
data[&#039;out&#039;] = data[&#039;content&#039;]
    .transform(...)
    .transform(...)

# collect data
collector.collect(...)

# export to db, vector db, graph db ...
collector.export(...)
```

CocoIndex follows the idea of [Dataflow](https://en.wikipedia.org/wiki/Dataflow_programming) programming model. Each transformation creates a new field solely based on input fields, without hidden states and value mutation. All data before/after each transformation is observable, with lineage out of the box.

**Particularly**, developers don&#039;t explicitly mutate data by creating, updating and deleting. They just need to define transformation/formula for a set of source data.

## Plug-and-Play Building Blocks

Native builtins for different source, targets and transformations. Standardize interface, make it 1-line code switch between different components - as easy as assembling building blocks.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://cocoindex.io/images/components.svg&quot; alt=&quot;CocoIndex Features&quot;&gt;
&lt;/p&gt;

## Data Freshness

CocoIndex keep source data and target in sync effortlessly.

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/f4eb29b3-84ee-4fa0-a1e2-80eedeeabde6&quot; alt=&quot;Incremental Processing&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

It has out-of-box support for incremental indexing:

- minimal recomputation on source or logic change.
- (re-)processing necessary portions; reuse cache when possible

## Quick Start

If you&#039;re new to CocoIndex, we recommend checking out

- üìñ [Documentation](https://cocoindex.io/docs)
- ‚ö°  [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart)
- üé¨ [Quick Start Video Tutorial](https://youtu.be/gv5R8nOXsWU?si=9ioeKYkMEnYevTXT)

### Setup

1. Install CocoIndex Python library

```sh
pip install -U cocoindex
```

2. [Install Postgres](https://cocoindex.io/docs/getting_started/installation#-install-postgres) if you don&#039;t have one. CocoIndex uses it for incremental processing.

3. (Optional) Install Claude Code skill for enhanced development experience. Run these commands in [Claude Code](https://claude.com/claude-code):

```
/plugin marketplace add cocoindex-io/cocoindex-claude
/plugin install cocoindex-skills@cocoindex
```

## Define data flow

Follow [Quick Start Guide](https://cocoindex.io/docs/getting_started/quickstart) to define your first indexing flow. An example flow looks like:

```python
@cocoindex.flow_def(name=&quot;TextEmbedding&quot;)
def text_embedding_flow(flow_builder: cocoindex.FlowBuilder, data_scope: cocoindex.DataScope):
    # Add a data source to read files from a directory
    data_scope[&quot;documents&quot;] = flow_builder.add_source(cocoindex.sources.LocalFile(path=&quot;markdown_files&quot;))

    # Add a collector for data to be exported to the vector index
    doc_embeddings = data_scope.add_collector()

    # Transform data of each document
    with data_scope[&quot;documents&quot;].row() as doc:
        # Split the document into chunks, put into `chunks` field
        doc[&quot;chunks&quot;] = doc[&quot;content&quot;].transform(
            cocoindex.functions.SplitRecursively(),
            language=&quot;markdown&quot;, chunk_size=2000, chunk_overlap=500)

        # Transform data of each chunk
        with doc[&quot;chunks&quot;].row() as chunk:
            # Embed the chunk, put into `embedding` field
            chunk[&quot;embedding&quot;] = chunk[&quot;text&quot;].transform(
                cocoindex.functions.SentenceTransformerEmbed(
                    model=&quot;sentence-transformers/all-MiniLM-L6-v2&quot;))

            # Collect the chunk into the collector.
            doc_embeddings.collect(filename=doc[&quot;filename&quot;], location=chunk[&quot;location&quot;],
                                   text=chunk[&quot;text&quot;], embedding=chunk[&quot;embedding&quot;])

    # Export collected data to a vector index.
    doc_embeddings.export(
        &quot;doc_embeddings&quot;,
        cocoindex.targets.Postgres(),
        primary_key_fields=[&quot;filename&quot;, &quot;location&quot;],
        vector_indexes=[
            cocoindex.VectorIndexDef(
                field_name=&quot;embedding&quot;,
                metric=cocoindex.VectorSimilarityMetric.COSINE_SIMILARITY)])
```

It defines an index flow like this:

&lt;p align=&quot;center&quot;&gt;
    &lt;img width=&quot;400&quot; alt=&quot;Data Flow&quot; src=&quot;https://github.com/user-attachments/assets/2ea7be6d-3d94-42b1-b2bd-22515577e463&quot; /&gt;
&lt;/p&gt;

## üöÄ Examples and demo

| Example | Description |
|---------|-------------|
| [Text Embedding](examples/text_embedding) | Index text documents with embeddings for semantic search |
| [Code Embedding](examples/code_embedding) | Index code embeddings for semantic search |
| [PDF Embedding](examples/pdf_embedding) | Parse PDF and index text embeddings for semantic search |
| [PDF Elements Embedding](examples/pdf_elements_embedding) | Extract text and images from PDFs; embed text with SentenceTransformers and images with CLIP; store in Qdrant for multimodal search |
| [Manuals LLM Extraction](examples/manuals_llm_extraction) | Extract structured information from a manual using LLM |
| [Amazon S3 Embedding](examples/amazon_s3_embedding) | Index text documents from Amazon S3 |
| [Azure Blob Storage Embedding](examples/azure_blob_embedding) | Index text documents from Azure Blob Storage |
| [Google Drive Text Embedding](examples/gdrive_text_embedding) | Index text documents from Google Drive |
| [Meeting Notes to Knowledge Graph](examples/meeting_notes_graph) | Extract structured meeting info from Google Drive and build a knowledge graph |
| [Docs to Knowledge Graph](examples/docs_to_knowledge_graph) | Extract relationships from Markdown documents and build a knowledge graph |
| [Embeddings to Qdrant](examples/text_embedding_qdrant) | Index documents in a Qdrant collection for semantic search |
| [Embeddings to LanceDB](examples/text_embedding_lancedb) | Index documents in a LanceDB collection for semantic search |
| [FastAPI Server with Docker](examples/fastapi_server_docker) | Run the semantic search server in a Dockerized FastAPI setup |
| [Product Recommendation](examples/product_recommendation) | Build real-time product recommendations with LLM and graph database|
| [Image Search with Vision API](examples/image_search) | Generates detailed captions for images using a vision model, embeds them, enables live-updating semantic search via FastAPI and served on a React frontend|
| [Face Recognition](examples/face_recognition) | Recognize faces in images and build embedding index |
| [Paper Metadata](examples/paper_metadata) | Index papers in PDF files, and build metadata tables for each paper |
| [Multi Format Indexing](examples/multi_format_indexing) | Build visual document index from PDFs and images with ColPali for semantic search |
| [Custom Source HackerNews](examples/custom_source_hn) | Index HackerNews threads and comments, using *CocoIndex Custom Source* |
| [Custom Output Files](examples/custom_output_files) | Convert markdown files to HTML files and save them to a local directory, using *CocoIndex Custom Targets* |
| [Patient intake form extraction](examples/patient_intake_extraction) | Use LLM to extract structured data from patient intake forms with different formats |
| [HackerNews Trending Topics](examples/hn_trending_topics) | Extract trending topics from HackerNews threads and comments, using *CocoIndex Custom Source* and LLM |
| [Patient Intake Form Extraction with BAML](examples/patient_intake_extraction_baml) | Extract structured data from patient intake forms using BAML |
| [Patient Intake Form Extraction with DSPy](examples/patient_intake_extraction_dspy) | Extract structured data from patient intake forms using DSPy |

More coming and stay tuned üëÄ!

## üìñ Documentation

For detailed documentation, visit [CocoIndex Documentation](https://cocoindex.io/docs), including a [Quickstart guide](https://cocoindex.io/docs/getting_started/quickstart).

## ü§ù Contributing

We love contributions from our community ‚ù§Ô∏è. For details on contributing or running the project for development, check out our [contributing guide](https://cocoindex.io/docs/about/contributing).

## üë• Community

Welcome with a huge coconut hug ü••‚ãÜÔΩ°Àöü§ó. We are super excited for community contributions of all kinds - whether it&#039;s code improvements, documentation updates, issue reports, feature requests, and discussions in our Discord.

Join our community here:

- üåü [Star us on GitHub](https://github.com/cocoindex-io/cocoindex)
- üëã [Join our Discord community](https://discord.com/invite/zpA9S2DR7s)
- ‚ñ∂Ô∏è [Subscribe to our YouTube channel](https://www.youtube.com/@cocoindex-io)
- üìú [Read our blog posts](https://cocoindex.io/blogs/)

## Support us

We are constantly improving, and more features and examples are coming soon. If you love this project, please drop us a star ‚≠ê at GitHub repo [![GitHub](https://img.shields.io/github/stars/cocoindex-io/cocoindex?color=5B5BD6)](https://github.com/cocoindex-io/cocoindex) to stay tuned and help us grow.

## License

CocoIndex is Apache 2.0 licensed.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[sigp/lighthouse]]></title>
            <link>https://github.com/sigp/lighthouse</link>
            <guid>https://github.com/sigp/lighthouse</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:30 GMT</pubDate>
            <description><![CDATA[Ethereum consensus client in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sigp/lighthouse">sigp/lighthouse</a></h1>
            <p>Ethereum consensus client in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 3,355</p>
            <p>Forks: 939</p>
            <p>Stars today: 1 star today</p>
            <h2>README</h2><pre># Lighthouse: Ethereum consensus client

An open-source Ethereum consensus client, written in Rust and maintained by Sigma Prime.

[![Book Status]][Book Link] [![Chat Badge]][Chat Link]

[Chat Badge]: https://img.shields.io/badge/chat-discord-%237289da
[Chat Link]: https://discord.gg/cyAszAh
[Book Status]:https://img.shields.io/badge/user--docs-unstable-informational
[Book Link]: https://lighthouse-book.sigmaprime.io
[stable]: https://github.com/sigp/lighthouse/tree/stable
[unstable]: https://github.com/sigp/lighthouse/tree/unstable
[blog]: https://lighthouse-blog.sigmaprime.io

[Documentation](https://lighthouse-book.sigmaprime.io)

![Banner](https://i.postimg.cc/hjdTGKPd/photo-2020-10-23-09-52-16.jpg)

## Overview

Lighthouse is:

- Ready for use on Ethereum consensus mainnet.
- Fully open-source, licensed under Apache 2.0.
- Security-focused. Fuzzing techniques have been continuously applied and several external security reviews have been performed.
- Built in [Rust](https://www.rust-lang.org), a modern language providing unique safety guarantees and
	excellent performance (comparable to C++).
- Funded by various organisations, including Sigma Prime, the
	Ethereum Foundation, Consensys, the Decentralization Foundation and private individuals.
- Actively involved in the specification and security analysis of the
	Ethereum proof-of-stake consensus specification.

## Staking Deposit Contract

The Lighthouse team acknowledges
[`0x00000000219ab540356cBB839Cbe05303d7705Fa`](https://etherscan.io/address/0x00000000219ab540356cbb839cbe05303d7705fa)
as the canonical staking deposit contract address.

## Documentation

The [Lighthouse Book](https://lighthouse-book.sigmaprime.io) contains information for users and
developers.

The Lighthouse team maintains a blog at [https://blog.sigmaprime.io/tag/lighthouse][blog] which contains periodic
progress updates, roadmap insights and interesting findings.

## Branches

Lighthouse maintains two permanent branches:

- [`stable`][stable]: Always points to the latest stable release.
  - This is ideal for most users.
- [`unstable`][unstable]: Used for development, contains the latest PRs.
  - Developers should base their PRs on this branch.

## Contributing

Lighthouse welcomes contributors.

If you are looking to contribute, please head to the
[Contributing](https://lighthouse-book.sigmaprime.io/contributing.html) section
of the Lighthouse book.

## Contact

The best place for discussion is the [Lighthouse Discord
server](https://discord.gg/cyAszAh).

Sign up to the [Lighthouse Development Updates](https://eepurl.com/dh9Lvb) mailing list for email
notifications about releases, network status and other important information.

Encrypt sensitive messages using our [PGP
key](https://keybase.io/sigp/pgp_keys.asc?fingerprint=15e66d941f697e28f49381f426416dc3f30674b0).

## Donations

Lighthouse is an open-source project and a public good. Funding public goods is
hard and we&#039;re grateful for the donations we receive from the community via:

- [Gitcoin Grants](https://gitcoin.co/grants/25/lighthouse-ethereum-20-client).
- Ethereum address: `0x25c4a76E7d118705e7Ea2e9b7d8C59930d8aCD3b` (donation.sigmaprime.eth).
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[vectordotdev/vector]]></title>
            <link>https://github.com/vectordotdev/vector</link>
            <guid>https://github.com/vectordotdev/vector</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:29 GMT</pubDate>
            <description><![CDATA[A high-performance observability data pipeline.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vectordotdev/vector">vectordotdev/vector</a></h1>
            <p>A high-performance observability data pipeline.</p>
            <p>Language: Rust</p>
            <p>Stars: 20,861</p>
            <p>Forks: 1,933</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>[![Nightly](https://github.com/vectordotdev/vector/actions/workflows/nightly.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/nightly.yml)
[![E2E Test Suite](https://github.com/vectordotdev/vector/actions/workflows/e2e.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/e2e.yml)
[![Component Features](https://github.com/vectordotdev/vector/actions/workflows/component_features.yml/badge.svg)](https://github.com/vectordotdev/vector/actions/workflows/component_features.yml)

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;website/static/img/diagram.svg&quot; alt=&quot;Vector&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;
    &lt;a href=&quot;https://vector.dev/docs/setup/quickstart/&quot;&gt;Quickstart&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/docs/&quot;&gt;Docs&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/guides/&quot;&gt;Guides&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/components/&quot;&gt;Integrations&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://chat.vector.dev&quot;&gt;Chat&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://vector.dev/releases/latest/download/&quot;&gt;Download&lt;/a&gt;&amp;nbsp;&amp;nbsp;&amp;bull;&amp;nbsp;&amp;nbsp;
    &lt;a href=&quot;https://rust-doc.vector.dev/&quot;&gt;Rust Crate Docs&lt;/a&gt;
  &lt;/strong&gt;
&lt;/p&gt;

## What is Vector?

Vector is a high-performance, end-to-end (agent &amp; aggregator) observability data
pipeline that puts you in control of your observability data.
[Collect][docs.sources], [transform][docs.transforms], and [route][docs.sinks]
all your logs and metrics to any vendors you want today and any other
vendors you may want tomorrow. Vector enables dramatic cost reduction, novel
data enrichment, and data security where you need it, not where it is most
convenient for your vendors. Additionally, it is open source and up to 10x
faster than every alternative in the space.

To get started, follow our [**quickstart guide**][docs.quickstart] or [**install
Vector**][docs.installation].

Vector is maintained by Datadog&#039;s [Community Open Source Engineering team](https://opensource.datadoghq.com/about/#the-community-open-source-engineering-team).

### Principles

* **Reliable** - Built in [Rust][urls.rust], Vector&#039;s primary design goal is reliability.
* **End-to-end** - Deploys as an [agent][docs.roles#agent] or [aggregator][docs.roles#aggregator]. Vector is a complete platform.
* **Unified** - [Logs][docs.data-model.log], [metrics][docs.data-model.metric] (beta), and traces (coming soon). One tool for all of your data.

### Use cases

* Reduce total observability costs.
* Transition vendors without disrupting workflows.
* Enhance data quality and improve insights.
* Consolidate agents and eliminate agent fatigue.
* Improve overall observability performance and reliability.

### Community

* Vector is relied on by startups and enterprises like **Atlassian**, **T-Mobile**,
  **Comcast**, **Zendesk**, **Discord**, **Fastly**, **CVS**, **Trivago**,
  **Tuple**, **Douban**, **Visa**, **Mambu**, **Blockfi**, **Claranet**,
  **Instacart**, **Forcepoint**, and [many more][urls.production_users].
* Vector is **downloaded over 100,000 times per day**.
* Vector&#039;s largest user **processes over 500TB daily**.
* Vector has **over 500 contributors** and growing.

## Documentation

All user documentation is available at **[vector.dev/docs](https://vector.dev/docs)**.

Other Resources:

* [**Vector Calendar**][urls.vector_calendar]
* **Policies**:
  * [**Code of Conduct**][urls.vector_code_of_conduct]
  * [**Contributing**][urls.vector_contributing_policy]
  * [**Privacy**][urls.vector_privacy_policy]
  * [**Releases**][urls.vector_releases_policy]
  * [**Versioning**][urls.vector_versioning_policy]
  * [**Security**][urls.vector_security_policy]

## Comparisons

### Performance

The following performance tests demonstrate baseline performance between
common protocols with the exception of the Regex Parsing test.

| Test                                                                                                                   | Vector          | Filebeat | FluentBit       | FluentD   | Logstash  | SplunkUF        | SplunkHF |
| ---------------------------------------------------------------------------------------------------------------------- | --------------- | -------- | --------------- | --------- | --------- | --------------- | -------- |
| [TCP to Blackhole](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_blackhole_performance) | _**86mib/s**_   | n/a      | 64.4mib/s       | 27.7mib/s | 40.6mib/s | n/a             | n/a      |
| [File to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_to_tcp_performance)           | _**76.7mib/s**_ | 7.8mib/s | 35mib/s         | 26.1mib/s | 3.1mib/s  | 40.1mib/s       | 39mib/s  |
| [Regex Parsing](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/regex_parsing_performance)       | 13.2mib/s       | n/a      | _**20.5mib/s**_ | 2.6mib/s  | 4.6mib/s  | n/a             | 7.8mib/s |
| [TCP to HTTP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_http_performance)           | _**26.7mib/s**_ | n/a      | 19.6mib/s       | &lt;1mib/s   | 2.7mib/s  | n/a             | n/a      |
| [TCP to TCP](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/tcp_to_tcp_performance)             | 69.9mib/s       | 5mib/s   | 67.1mib/s       | 3.9mib/s  | 10mib/s   | _**70.4mib/s**_ | 7.6mib/s |

To learn more about our performance tests, please see the [Vector test harness][urls.vector_test_harness].

### Correctness

The following correctness tests are not exhaustive, but they demonstrate
fundamental differences in quality and attention to detail:

| Test                                                                                                                                 | Vector | Filebeat | FluentBit | FluentD | Logstash | Splunk UF | Splunk HF |
| ------------------------------------------------------------------------------------------------------------------------------------ | ------ | -------- | --------- | ------- | -------- | --------- | --------- |
| [Disk Buffer Persistence](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/disk_buffer_persistence_correctness) | **‚úì**  | ‚úì        |           |         | ‚ö†        | ‚úì         | ‚úì         |
| [File Rotate (create)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_create_correctness)         | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |
| [File Rotate (copytruncate)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_rotate_truncate_correctness) | **‚úì**  |          |           |         |          | ‚úì         | ‚úì         |
| [File Truncation](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/file_truncate_correctness)                   | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |
| [Process (SIGHUP)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/sighup_correctness)                         | **‚úì**  |          |           |         | ‚ö†        | ‚úì         | ‚úì         |
| [JSON (wrapped)](https://github.com/vectordotdev/vector-test-harness/tree/master/cases/wrapped_json_correctness)                     | **‚úì**  | ‚úì        | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         |

To learn more about our correctness tests, please see the [Vector test harness][urls.vector_test_harness].

### Features

Vector is an end-to-end, unified, open data platform.

|                     | **Vector** | Beats | Fluentbit | Fluentd | Logstash | Splunk UF | Splunk HF | Telegraf |
| ------------------- | ---------- | ----- | --------- | ------- | -------- | --------- | --------- | -------- |
| **End-to-end**      | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Agent               | **‚úì**      | ‚úì     | ‚úì         |         |          | ‚úì         |           | ‚úì        |
| Aggregator          | **‚úì**      |       |           | ‚úì       | ‚úì        |           | ‚úì         | ‚úì        |
| **Unified**         | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Logs                | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         | ‚úì        |
| Metrics             | **‚úì**      | ‚ö†     | ‚ö†         | ‚ö†       | ‚ö†        | ‚ö†         | ‚ö†         | ‚úì        |
| Traces              | üöß         |       |           |         |          |           |           |          |
| **Open**            | **‚úì**      |       | ‚úì         | ‚úì       |          |           |           | ‚úì        |
| Open-source         | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        |           |           | ‚úì        |
| Vendor-neutral      | **‚úì**      |       | ‚úì         | ‚úì       |          |           |           | ‚úì        |
| **Reliability**     | **‚úì**      |       |           |         |          |           |           |          |
| Memory-safe         | **‚úì**      |       |           |         |          |           |           | ‚úì        |
| Delivery guarantees | **‚úì**      |       |           |         |          | ‚úì         | ‚úì         |          |
| Multi-core          | **‚úì**      | ‚úì     | ‚úì         | ‚úì       | ‚úì        | ‚úì         | ‚úì         | ‚úì        |


‚ö† = Not interoperable, metrics are represented as structured logs

---

&lt;p align=&quot;center&quot;&gt;
  Developed with ‚ù§Ô∏è by &lt;strong&gt;&lt;a href=&quot;https://datadoghq.com&quot;&gt;Datadog&lt;/a&gt;&lt;/strong&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/security/policy&quot;&gt;Security Policy&lt;/a&gt; - &lt;a href=&quot;https://github.com/vectordotdev/vector/blob/master/PRIVACY.md&quot;&gt;Privacy Policy&lt;/a&gt;
&lt;/p&gt;

[docs.about.concepts]: https://vector.dev/docs/introduction/concepts/
[docs.about.introduction]: https://vector.dev/docs/introduction/
[docs.administration.monitoring]: https://vector.dev/docs/administration/monitoring/
[docs.administration.management]: https://vector.dev/docs/administration/management/
[docs.administration.upgrading]: https://vector.dev/docs/administration/upgrading/
[docs.administration.validating]: https://vector.dev/docs/administration/validating/
[docs.architecture.concurrency-model]: https://vector.dev/docs/architecture/concurrency-model/
[docs.architecture.data-model]: https://vector.dev/docs/architecture/data-model/
[docs.architecture.pipeline-model]: https://vector.dev/docs/architecture/pipeline-model/
[docs.architecture.runtime-model]: https://vector.dev/docs/architecture/runtime-model/
[docs.configuration.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.configuration.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.configuration.tests]: https://vector.dev/docs/reference/configuration/tests/
[docs.configuration.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.configuration.enrichment_tables]: https://vector.dev/docs/reference/configuration/global-options/#enrichment_tables
[docs.data-model.log]: https://vector.dev/docs/architecture/data-model/log/
[docs.data-model.metric]: https://vector.dev/docs/architecture/data-model/metric/
[docs.deployment.roles]: https://vector.dev/docs/setup/deployment/roles/
[docs.deployment.topologies]: https://vector.dev/docs/setup/deployment/topologies/
[docs.deployment]: https://vector.dev/docs/setup/deployment/
[docs.installation.manual]: https://vector.dev/docs/setup/installation/manual/
[docs.installation.operating_systems]: https://vector.dev/docs/setup/installation/operating-systems/
[docs.installation.package_managers]: https://vector.dev/docs/setup/installation/package-managers/
[docs.installation.platforms]: https://vector.dev/docs/setup/installation/platforms/
[docs.installation]: https://vector.dev/docs/setup/installation/
[docs.architecture.adaptive-request-concurrency]: https://vector.dev/docs/architecture/arc/
[docs.platforms.kubernetes]: https://vector.dev/docs/setup/installation/platforms/kubernetes/
[docs.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.reference.api]: https://vector.dev/docs/reference/api/
[docs.reference.cli]: https://vector.dev/docs/reference/cli/
[docs.reference.vrl]: https://vector.dev/docs/reference/vrl/
[docs.roles#agent]: https://vector.dev/docs/setup/deployment/roles/#agent
[docs.roles#aggregator]: https://vector.dev/docs/setup/deployment/roles/#aggregator
[docs.setup.installation]: https://vector.dev/docs/setup/installation/
[docs.setup.quickstart]: https://vector.dev/docs/setup/quickstart/
[docs.sinks.aws_cloudwatch_logs]: https://vector.dev/docs/reference/configuration/sinks/aws_cloudwatch_logs/
[docs.sinks.aws_s3]: https://vector.dev/docs/reference/configuration/sinks/aws_s3/
[docs.sinks.clickhouse]: https://vector.dev/docs/reference/configuration/sinks/clickhouse/
[docs.sinks.elasticsearch]: https://vector.dev/docs/reference/configuration/sinks/elasticsearch/
[docs.sinks.gcp_cloud_storage]: https://vector.dev/docs/reference/configuration/sinks/gcp_cloud_storage/
[docs.sinks]: https://vector.dev/docs/reference/configuration/sinks/
[docs.sources.docker_logs]: https://vector.dev/docs/reference/configuration/sources/docker_logs/
[docs.sources.file]: https://vector.dev/docs/reference/configuration/sources/file/
[docs.sources.http]: https://vector.dev/docs/reference/configuration/sources/http/
[docs.sources.journald]: https://vector.dev/docs/reference/configuration/sources/journald/
[docs.sources.kafka]: https://vector.dev/docs/reference/configuration/sources/kafka/
[docs.sources.socket]: https://vector.dev/docs/reference/configuration/sources/socket/
[docs.sources]: https://vector.dev/docs/reference/configuration/sources/
[docs.transforms.dedupe]: https://vector.dev/docs/reference/configuration/transforms/dedupe/
[docs.transforms.filter]: https://vector.dev/docs/reference/configuration/transforms/filter/
[docs.transforms.log_to_metric]: https://vector.dev/docs/reference/configuration/transforms/log_to_metric/
[docs.transforms.lua]: https://vector.dev/docs/reference/configuration/transforms/lua/
[docs.transforms.remap]: https://vector.dev/docs/reference/configuration/transforms/remap/
[docs.transforms]: https://vector.dev/docs/reference/configuration/transforms/
[docs.introduction.architecture]: https://vector.dev/docs/architecture/
[docs.introduction.guarantees]: https://vector.dev/docs/introduction/guarantees/
[docs.introduction.architecture]: https://vector.dev/docs/architecture/
[urls.production_users]: https://github.com/vectordotdev/vector/issues/790
[urls.rust]: https://www.rust-lang.org/
[urls.vector_calendar]: https://calendar.vector.dev
[urls.vector_chat]: https://chat.vector.dev
[urls.vector_code_of_conduct]: https://github.com/vectordotdev/vector/blob/master/CODE_OF_CONDUCT.md
[urls.vector_contributing_policy]: https://github.com/vectordotdev/vector/blob/master/CONTRIBUTING.md
[urls.vector_community]: https://vector.dev/community/
[urls.vector_privacy_policy]: https://github.com/vectordotdev/vector/blob/master/PRIVACY.md
[urls.vector_release_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASING.md
[urls.vector_releases]: https://vector.dev/releases/
[urls.vector_releases_policy]: https://github.com/vectordotdev/vector/blob/master/RELEASES.md
[urls.vector_security_policy]: https://github.com/vectordotdev/vector/security/policy
[urls.vector_test_harness]: https://github.com/vectordotdev/vector-test-harness/
[urls.vector_twitter]: https://twitter.com/vectordotdev
[urls.vector_versioning_policy]: https://github.com/vectordotdev/vector/blob/master/VERSIONING.md
[urls.vote_feature]: https://github.com/vectordotdev/vector/issues?q=is%3Aissue+is%3Aopen+sort%3Areactions-%2B1-desc+label%3A%22type%3A+feature%22
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[paradigmxyz/reth]]></title>
            <link>https://github.com/paradigmxyz/reth</link>
            <guid>https://github.com/paradigmxyz/reth</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:28 GMT</pubDate>
            <description><![CDATA[Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol, in Rust]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/paradigmxyz/reth">paradigmxyz/reth</a></h1>
            <p>Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol, in Rust</p>
            <p>Language: Rust</p>
            <p>Stars: 5,197</p>
            <p>Forks: 2,171</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre># reth

[![bench status](https://github.com/paradigmxyz/reth/actions/workflows/bench.yml/badge.svg)](https://github.com/paradigmxyz/reth/actions/workflows/bench.yml)
[![CI status](https://github.com/paradigmxyz/reth/workflows/unit/badge.svg)][gh-ci]
[![cargo-lint status](https://github.com/paradigmxyz/reth/actions/workflows/lint.yml/badge.svg)][gh-lint]
[![Telegram Chat][tg-badge]][tg-url]

**Modular, contributor-friendly and blazing-fast implementation of the Ethereum protocol**

![](./assets/reth-prod.png)

**[Install](https://paradigmxyz.github.io/reth/installation/installation.html)**
| [User Docs](https://reth.rs)
| [Developer Docs](./docs)
| [Crate Docs](https://reth.rs/docs)

[gh-ci]: https://github.com/paradigmxyz/reth/actions/workflows/unit.yml
[gh-lint]: https://github.com/paradigmxyz/reth/actions/workflows/lint.yml
[tg-badge]: https://img.shields.io/endpoint?color=neon&amp;logo=telegram&amp;label=chat&amp;url=https%3A%2F%2Ftg.sumanjay.workers.dev%2Fparadigm%5Freth

## What is Reth?

Reth (short for Rust Ethereum, [pronunciation](https://x.com/kelvinfichter/status/1597653609411268608)) is a new Ethereum full node implementation that is focused on being user-friendly, highly modular, as well as being fast and efficient. Reth is an Execution Layer (EL) and is compatible with all Ethereum Consensus Layer (CL) implementations that support the [Engine API](https://github.com/ethereum/execution-apis/tree/a0d03086564ab1838b462befbc083f873dcf0c0f/src/engine). It is originally built and driven forward by [Paradigm](https://paradigm.xyz/), and is licensed under the Apache and MIT licenses.

## Goals

As a full Ethereum node, Reth allows users to connect to the Ethereum network and interact with the Ethereum blockchain. This includes sending and receiving transactions/logs/traces, as well as accessing and interacting with smart contracts. Building a successful Ethereum node requires creating a high-quality implementation that is both secure and efficient, as well as being easy to use on consumer hardware. It also requires building a strong community of contributors who can help support and improve the software.

More concretely, our goals are:

1. **Modularity**: Every component of Reth is built to be used as a library: well-tested, heavily documented and benchmarked. We envision that developers will import the node&#039;s crates, mix and match, and innovate on top of them. Examples of such usage include but are not limited to spinning up standalone P2P networks, talking directly to a node&#039;s database, or &quot;unbundling&quot; the node into the components you need. To achieve that, we are licensing Reth under the Apache/MIT permissive license. You can learn more about the project&#039;s components [here](./docs/repo/layout.md).
2. **Performance**: Reth aims to be fast, so we use Rust and the [Erigon staged-sync](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) node architecture. We also use our Ethereum libraries (including [Alloy](https://github.com/alloy-rs/alloy/) and [revm](https://github.com/bluealloy/revm/)) which we&#039;ve battle-tested and optimized via [Foundry](https://github.com/foundry-rs/foundry/).
3. **Free for anyone to use any way they want**: Reth is free open source software, built for the community, by the community. By licensing the software under the Apache/MIT license, we want developers to use it without being bound by business licenses, or having to think about the implications of GPL-like licenses.
4. **Client Diversity**: The Ethereum protocol becomes more antifragile when no node implementation dominates. This ensures that if there&#039;s a software bug, the network does not finalize a bad block. By building a new client, we hope to contribute to Ethereum&#039;s antifragility.
5. **Support as many EVM chains as possible**: We aspire that Reth can full-sync not only Ethereum, but also other chains like Optimism, Polygon, BNB Smart Chain, and more. If you&#039;re working on any of these projects, please reach out.
6. **Configurability**: We want to solve for node operators that care about fast historical queries, but also for hobbyists who cannot operate on large hardware. We also want to support teams and individuals who want both sync from genesis and via &quot;fast sync&quot;. We envision that Reth will be configurable enough and provide configurable &quot;profiles&quot; for the tradeoffs that each team faces.

## Status

Reth is production ready, and suitable for usage in mission-critical environments such as staking or high-uptime services. We also actively recommend professional node operators to switch to Reth in production for performance and cost reasons in use cases where high performance with great margins is required such as RPC, MEV, Indexing, Simulations, and P2P activities.

More historical context below:

-   We released 1.0 &quot;production-ready&quot; stable Reth in June 2024.
    -   Reth completed an audit with [Sigma Prime](https://sigmaprime.io/), the developers of [Lighthouse](https://github.com/sigp/lighthouse), the Rust Consensus Layer implementation. Find it [here](./audit/sigma_prime_audit_v2.pdf).
    -   Revm (the EVM used in Reth) underwent an audit with [Guido Vranken](https://x.com/guidovranken) (#1 [Ethereum Bug Bounty](https://ethereum.org/en/bug-bounty)). We will publish the results soon.
-   We released multiple iterative beta versions, up to [beta.9](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.9) on Monday June 3, 2024,the last beta release.
-   We released [beta](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) on Monday March 4, 2024, our first breaking change to the database model, providing faster query speed, smaller database footprint, and allowing &quot;history&quot; to be mounted on separate drives.
-   We shipped iterative improvements until the last alpha release on February 28, 2024, [0.1.0-alpha.21](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.21).
-   We [initially announced](https://www.paradigm.xyz/2023/06/reth-alpha) [0.1.0-alpha.1](https://github.com/paradigmxyz/reth/releases/tag/v0.1.0-alpha.1) on June 20, 2023.

### Database compatibility

We do not have any breaking database changes since beta.1, and we do not plan any in the near future.

Reth [v0.2.0-beta.1](https://github.com/paradigmxyz/reth/releases/tag/v0.2.0-beta.1) includes
a [set of breaking database changes](https://github.com/paradigmxyz/reth/pull/5191) that makes it impossible to use database files produced by earlier versions.

If you had a database produced by alpha versions of Reth, you need to drop it with `reth db drop`
(using the same arguments such as `--config` or `--datadir` that you passed to `reth node`), and resync using the same `reth node` command you&#039;ve used before.

## For Users

See the [Reth documentation](https://reth.rs/) for instructions on how to install and run Reth.

## For Developers

### Using reth as a library

You can use individual crates of reth in your project.

The crate docs can be found [here](https://reth.rs/docs/).

For a general overview of the crates, see [Project Layout](./docs/repo/layout.md).

### Contributing

If you want to contribute, or follow along with contributor discussion, you can use our [main telegram](https://t.me/paradigm_reth) to chat with us about the development of Reth!

-   Our contributor guidelines can be found in [`CONTRIBUTING.md`](./CONTRIBUTING.md).
-   See our [contributor docs](./docs) for more information on the project. A good starting point is [Project Layout](./docs/repo/layout.md).

### Building and testing

&lt;!--
When updating this, also update:
- Cargo.toml
- .github/workflows/lint.yml
--&gt;

The Minimum Supported Rust Version (MSRV) of this project is [1.88.0](https://blog.rust-lang.org/2025/06/26/Rust-1.88.0/).

See the docs for detailed instructions on how to [build from source](https://reth.rs/installation/source/).

To fully test Reth, you will need to have [Geth installed](https://geth.ethereum.org/docs/getting-started/installing-geth), but it is possible to run a subset of tests without Geth.

First, clone the repository:

```sh
git clone https://github.com/paradigmxyz/reth
cd reth
```

Next, run the tests:

```sh
cargo nextest run --workspace

# Run the Ethereum Foundation tests
make ef-tests
```

We highly recommend using [`cargo nextest`](https://nexte.st/) to speed up testing.
Using `cargo test` to run tests may work fine, but this is not tested and does not support more advanced features like retries for spurious failures.

&gt; **Note**
&gt;
&gt; Some tests use random number generators to generate test data. If you want to use a deterministic seed, you can set the `SEED` environment variable.

## Getting Help

If you have any questions, first see if the answer to your question can be found in the [docs][book].

If the answer is not there:

-   Join the [Telegram][tg-url] to get help, or
-   Open a [discussion](https://github.com/paradigmxyz/reth/discussions/new) with your question, or
-   Open an issue with [the bug](https://github.com/paradigmxyz/reth/issues/new?assignees=&amp;labels=C-bug%2CS-needs-triage&amp;projects=&amp;template=bug.yml)

## Security

See [`SECURITY.md`](./SECURITY.md).

## Acknowledgements

Reth is a new implementation of the Ethereum protocol. In the process of developing the node we investigated the design decisions other nodes have made to understand what is done well, what is not, and where we can improve the status quo.

None of this would have been possible without them, so big shoutout to the teams below:

-   [Geth](https://github.com/ethereum/go-ethereum/): We would like to express our heartfelt gratitude to the go-ethereum team for their outstanding contributions to Ethereum over the years. Their tireless efforts and dedication have helped to shape the Ethereum ecosystem and make it the vibrant and innovative community it is today. Thank you for your hard work and commitment to the project.
-   [Erigon](https://github.com/ledgerwatch/erigon) (fka Turbo-Geth): Erigon pioneered the [&quot;Staged Sync&quot; architecture](https://erigon.substack.com/p/erigon-stage-sync-and-control-flows) that Reth is using, as well as [introduced MDBX](https://github.com/ledgerwatch/erigon/wiki/Choice-of-storage-engine) as the database of choice. We thank Erigon for pushing the state of the art research on the performance limits of Ethereum nodes.
-   [Akula](https://github.com/akula-bft/akula/): Reth uses forks of the Apache versions of Akula&#039;s [MDBX Bindings](https://github.com/paradigmxyz/reth/pull/132), [FastRLP](https://github.com/paradigmxyz/reth/pull/63) and [ECIES](https://github.com/paradigmxyz/reth/pull/80). Given that these packages were already released under the Apache License, and they implement standardized solutions, we decided not to reimplement them to iterate faster. We thank the Akula team for their contributions to the Rust Ethereum ecosystem and for publishing these packages.

## Warning

The `NippyJar` and `Compact` encoding formats and their implementations are designed for storing and retrieving data internally. They are not hardened to safely read potentially malicious data.

[book]: https://reth.rs/
[tg-url]: https://t.me/paradigm_reth
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[GreptimeTeam/greptimedb]]></title>
            <link>https://github.com/GreptimeTeam/greptimedb</link>
            <guid>https://github.com/GreptimeTeam/greptimedb</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:27 GMT</pubDate>
            <description><![CDATA[Open-source, cloud-native, unified observability database for metrics, logs and traces, supporting SQL/PromQL/Streaming.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GreptimeTeam/greptimedb">GreptimeTeam/greptimedb</a></h1>
            <p>Open-source, cloud-native, unified observability database for metrics, logs and traces, supporting SQL/PromQL/Streaming.</p>
            <p>Language: Rust</p>
            <p>Stars: 5,759</p>
            <p>Forks: 432</p>
            <p>Stars today: 2 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://cdn.jsdelivr.net/gh/GreptimeTeam/greptimedb@main/docs/logo-text-padding.png&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://cdn.jsdelivr.net/gh/GreptimeTeam/greptimedb@main/docs/logo-text-padding-dark.png&quot;&gt;
    &lt;img alt=&quot;GreptimeDB Logo&quot; src=&quot;https://cdn.jsdelivr.net/gh/GreptimeTeam/greptimedb@main/docs/logo-text-padding.png&quot; width=&quot;400px&quot;&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;h2 align=&quot;center&quot;&gt;Real-Time &amp; Cloud-Native Observability  Database&lt;br/&gt;for metrics, logs, and traces&lt;/h2&gt;

&gt;  Delivers sub-second querying at PB scale and exceptional cost efficiency from edge to cloud.

&lt;div align=&quot;center&quot;&gt;
&lt;h3 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://docs.greptime.com/user-guide/overview/&quot;&gt;User Guide&lt;/a&gt; |
  &lt;a href=&quot;https://greptimedb.rs/&quot;&gt;API Docs&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/issues/5446&quot;&gt;Roadmap 2025&lt;/a&gt;
&lt;/h4&gt;

&lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/releases/latest&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/v/release/GreptimeTeam/greptimedb.svg&quot; alt=&quot;Version&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/releases/latest&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/release-date/GreptimeTeam/greptimedb.svg&quot; alt=&quot;Releases&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://hub.docker.com/r/greptime/greptimedb/&quot;&gt;
&lt;img src=&quot;https://img.shields.io/docker/pulls/greptime/greptimedb.svg&quot; alt=&quot;Docker Pulls&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/GreptimeTeam/greptimedb/actions/workflows/develop.yml&quot;&gt;
&lt;img src=&quot;https://github.com/GreptimeTeam/greptimedb/actions/workflows/develop.yml/badge.svg&quot; alt=&quot;GitHub Actions&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://codecov.io/gh/GrepTimeTeam/greptimedb&quot;&gt;
&lt;img src=&quot;https://codecov.io/gh/GrepTimeTeam/greptimedb/branch/main/graph/badge.svg?token=FITFDI3J3C&quot; alt=&quot;Codecov&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://github.com/greptimeTeam/greptimedb/blob/main/LICENSE&quot;&gt;
&lt;img src=&quot;https://img.shields.io/github/license/greptimeTeam/greptimedb&quot; alt=&quot;License&quot;/&gt;
&lt;/a&gt;

&lt;br/&gt;

&lt;a href=&quot;https://greptime.com/slack&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/slack-GreptimeDB-0abd59?logo=slack&amp;style=for-the-badge&quot; alt=&quot;Slack&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://twitter.com/greptime&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/twitter-follow_us-1d9bf0.svg?style=for-the-badge&quot; alt=&quot;Twitter&quot;/&gt;
&lt;/a&gt;
&lt;a href=&quot;https://www.linkedin.com/company/greptime/&quot;&gt;
&lt;img src=&quot;https://img.shields.io/badge/linkedin-connect_with_us-0a66c2.svg?style=for-the-badge&quot; alt=&quot;LinkedIn&quot;/&gt;
&lt;/a&gt;
&lt;/div&gt;

- [Introduction](#introduction)
- [‚≠ê Key Features](#features)
- [Quick Comparison](#quick-comparison)
- [Architecture](#architecture)
- [Try GreptimeDB](#try-greptimedb)
- [Getting Started](#getting-started)
- [Build From Source](#build-from-source)
- [Tools &amp; Extensions](#tools--extensions)
- [Project Status](#project-status)
- [Community](#community)
- [License](#license)
- [Commercial Support](#commercial-support)
- [Contributing](#contributing)
- [Acknowledgement](#acknowledgement)

## Introduction

**GreptimeDB** is an open-source, cloud-native database that unifies metrics, logs, and traces, enabling real-time observability at any scale ‚Äî across edge, cloud, and hybrid environments.

## Features

|   Feature  | Description |
| --------- | ----------- |
| [All-in-One Observability](https://docs.greptime.com/user-guide/concepts/why-greptimedb) | OpenTelemetry-native platform unifying metrics, logs, and traces. Query via [SQL](https://docs.greptime.com/user-guide/query-data/sql), [PromQL](https://docs.greptime.com/user-guide/query-data/promql), and [Flow](https://docs.greptime.com/user-guide/flow-computation/overview). |
| [High Performance](https://docs.greptime.com/user-guide/manage-data/data-index) | Written in Rust with [rich indexing](https://docs.greptime.com/user-guide/manage-data/data-index) (inverted, fulltext, skipping, vector), delivering sub-second responses at PB scale. |
| [Cost Efficiency](https://docs.greptime.com/user-guide/concepts/architecture) | 50x lower operational and storage costs with compute-storage separation and native object storage (S3, Azure Blob, etc.). |
| [Cloud-Native &amp; Scalable](https://docs.greptime.com/user-guide/deployments-administration/deploy-on-kubernetes/greptimedb-operator-management) | Purpose-built for [Kubernetes](https://docs.greptime.com/user-guide/deployments-administration/deploy-on-kubernetes/greptimedb-operator-management) with unlimited cross-cloud scaling, handling hundreds of thousands of concurrent requests. |
| [Developer-Friendly](https://docs.greptime.com/user-guide/protocols/overview) | SQL/PromQL interfaces, built-in web dashboard, REST API, MySQL/PostgreSQL protocol compatibility, and native [OpenTelemetry](https://docs.greptime.com/user-guide/ingest-data/for-observability/opentelemetry/) support. |
| [Flexible Deployment](https://docs.greptime.com/user-guide/deployments-administration/overview) | Deploy anywhere from ARM-based edge devices (including [Android](https://docs.greptime.com/user-guide/deployments-administration/run-on-android)) to cloud, with unified APIs and efficient data sync. |

  ‚úÖ **Perfect for:**
  - Unified observability stack replacing Prometheus + Loki + Tempo
  - Large-scale metrics with high cardinality (millions to billions of time series)
  - Large-scale observability platform requiring cost efficiency and scalability
  - IoT and edge computing with resource and bandwidth constraints

Learn more in [Why GreptimeDB](https://docs.greptime.com/user-guide/concepts/why-greptimedb) and [Observability 2.0 and the Database for It](https://greptime.com/blogs/2025-04-25-greptimedb-observability2-new-database).

## Quick Comparison

| Feature                         | GreptimeDB            | Traditional TSDB   | Log Stores      |
|----------------------------------|-----------------------|--------------------|-----------------|
| Data Types                      | Metrics, Logs, Traces | Metrics only       | Logs only       |
| Query Language                  | SQL, PromQL |  Custom/PromQL     | Custom/DSL      |
| Deployment                      | Edge + Cloud          | Cloud/On-prem      | Mostly central  |
| Indexing &amp; Performance          | PB-Scale, Sub-second  | Varies             | Varies          |
| Integration                     | REST API, SQL, Common protocols | Varies     | Varies          |

**Performance:**
* [GreptimeDB tops JSONBench&#039;s billion-record cold run test!](https://greptime.com/blogs/2025-03-18-jsonbench-greptimedb-performance)
* [TSBS Benchmark](https://github.com/GreptimeTeam/greptimedb/tree/main/docs/benchmarks/tsbs)

Read [more benchmark reports](https://docs.greptime.com/user-guide/concepts/features-that-you-concern#how-is-greptimedbs-performance-compared-to-other-solutions).

## Architecture

GreptimeDB can run in two modes:
* **Standalone Mode** - Single binary for development and small deployments
* **Distributed Mode** - Separate components for production scale:
  - Frontend: Query processing and protocol handling
  - Datanode: Data storage and retrieval
  - Metasrv: Metadata management and coordination
  
Read the [architecture](https://docs.greptime.com/contributor-guide/overview/#architecture) document. [DeepWiki](https://deepwiki.com/GreptimeTeam/greptimedb/1-overview) provides an in-depth look at GreptimeDB:
  &lt;img alt=&quot;GreptimeDB System Overview&quot; src=&quot;docs/architecture.png&quot;&gt;

## Try GreptimeDB

```shell
docker pull greptime/greptimedb
```

```shell
docker run -p 127.0.0.1:4000-4003:4000-4003 \
  -v &quot;$(pwd)/greptimedb_data:/greptimedb_data&quot; \
  --name greptime --rm \
  greptime/greptimedb:latest standalone start \
  --http-addr 0.0.0.0:4000 \
  --rpc-bind-addr 0.0.0.0:4001 \
  --mysql-addr 0.0.0.0:4002 \
  --postgres-addr 0.0.0.0:4003
```
Dashboard: [http://localhost:4000/dashboard](http://localhost:4000/dashboard)

Read more in the [full Install Guide](https://docs.greptime.com/getting-started/installation/overview).

**Troubleshooting:**
* Cannot connect to the database? Ensure that ports `4000`, `4001`, `4002`, and `4003` are not blocked by a firewall or used by other services.
* Failed to start? Check the container logs with `docker logs greptime` for further details.

## Getting Started

- [Quickstart](https://docs.greptime.com/getting-started/quick-start)
- [User Guide](https://docs.greptime.com/user-guide/overview)
- [Demo Scenes](https://github.com/GreptimeTeam/demo-scene)
- [FAQ](https://docs.greptime.com/faq-and-others/faq)

## Build From Source

**Prerequisites:**
* [Rust toolchain](https://www.rust-lang.org/tools/install) (nightly)
* [Protobuf compiler](https://grpc.io/docs/protoc-installation/) (&gt;= 3.15)
* C/C++ building essentials, including `gcc`/`g++`/`autoconf` and glibc library (eg. `libc6-dev` on Ubuntu and `glibc-devel` on Fedora)
* Python toolchain (optional): Required only if using some test scripts.

**Build and Run:**
```bash
make
cargo run -- standalone start
```

## Tools &amp; Extensions

- **Kubernetes**: [GreptimeDB Operator](https://github.com/GrepTimeTeam/greptimedb-operator)
- **Helm Charts**: [Greptime Helm Charts](https://github.com/GreptimeTeam/helm-charts)
- **Dashboard**: [Web UI](https://github.com/GreptimeTeam/dashboard)
- **gRPC Ingester**: [Go](https://github.com/GreptimeTeam/greptimedb-ingester-go), [Java](https://github.com/GreptimeTeam/greptimedb-ingester-java), [C++](https://github.com/GreptimeTeam/greptimedb-ingester-cpp), [Erlang](https://github.com/GreptimeTeam/greptimedb-ingester-erl), [Rust](https://github.com/GreptimeTeam/greptimedb-ingester-rust)
- **Grafana Data Source**: [GreptimeDB Grafana data source plugin](https://github.com/GreptimeTeam/greptimedb-grafana-datasource)
- **Grafana Dashboard**: [Official Dashboard for monitoring](https://github.com/GreptimeTeam/greptimedb/blob/main/grafana/README.md)

## Project Status

&gt; **Status:** Beta ‚Äî marching toward v1.0 GA!
&gt; **GA (v1.0):** January 10, 2026

- Deployed in production by open-source projects and commercial users
- Stable, actively maintained, with regular releases ([version info](https://docs.greptime.com/nightly/reference/about-greptimedb-version))
- Suitable for evaluation and pilot deployments

GreptimeDB v1.0 represents a major milestone toward maturity ‚Äî marking stable APIs, production readiness, and proven performance.

**Roadmap:** Beta1 (Nov 10) ‚Üí Beta2 (Nov 24) ‚Üí RC1 (Dec 8) ‚Üí GA (Jan 10, 2026), please read [v1.0 highlights and release plan](https://greptime.com/blogs/2025-11-05-greptimedb-v1-highlights) for details.

For production use, we recommend using the latest stable release.
[![Star History Chart](https://api.star-history.com/svg?repos=GreptimeTeam/GreptimeDB&amp;type=Date)](https://www.star-history.com/#GreptimeTeam/GreptimeDB&amp;Date)

If you find this project useful, a ‚≠ê would mean a lot to us!
&lt;img alt=&quot;Known Users&quot; src=&quot;https://greptime.com/logo/img/users.png&quot;/&gt;

## Community

We invite you to engage and contribute!

- [Slack](https://greptime.com/slack)
- [Discussions](https://github.com/GreptimeTeam/greptimedb/discussions)
- [Official Website](https://greptime.com/)
- [Blog](https://greptime.com/blogs/)
- [LinkedIn](https://www.linkedin.com/company/greptime/)
- [X (Twitter)](https://X.com/greptime)
- [YouTube](https://www.youtube.com/@greptime)

## License

GreptimeDB is licensed under the [Apache License 2.0](https://apache.org/licenses/LICENSE-2.0.txt).

## Commercial Support

Running GreptimeDB in your organization?
We offer enterprise add-ons, services, training, and consulting.
[Contact us](https://greptime.com/contactus) for details.

## Contributing

- Read our [Contribution Guidelines](https://github.com/GreptimeTeam/greptimedb/blob/main/CONTRIBUTING.md).
- Explore [Internal Concepts](https://docs.greptime.com/contributor-guide/overview.html) and [DeepWiki](https://deepwiki.com/GreptimeTeam/greptimedb).
- Pick up a [good first issue](https://github.com/GreptimeTeam/greptimedb/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) and join the #contributors [Slack](https://greptime.com/slack) channel.

## Acknowledgement

Special thanks to all contributors! See [AUTHORS.md](https://github.com/GreptimeTeam/greptimedb/blob/main/AUTHOR.md).

- Uses [Apache Arrow‚Ñ¢](https://arrow.apache.org/) (memory model)
- [Apache Parquet‚Ñ¢](https://parquet.apache.org/) (file storage)
- [Apache DataFusion‚Ñ¢](https://arrow.apache.org/datafusion/) (query engine)
- [Apache OpenDAL‚Ñ¢](https://opendal.apache.org/) (data access abstraction)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[esp-rs/esp-hal]]></title>
            <link>https://github.com/esp-rs/esp-hal</link>
            <guid>https://github.com/esp-rs/esp-hal</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:26 GMT</pubDate>
            <description><![CDATA[no_std Hardware Abstraction Layers for ESP32 microcontrollers]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/esp-rs/esp-hal">esp-rs/esp-hal</a></h1>
            <p>no_std Hardware Abstraction Layers for ESP32 microcontrollers</p>
            <p>Language: Rust</p>
            <p>Stars: 1,599</p>
            <p>Forks: 364</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./resources/esp-rs.svg&quot; alt=&quot;esp-rs logo&quot; width=&quot;100px&quot; /&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;esp-hal&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/esp-rs/esp-hal/ci.yml?labelColor=1C2C2E&amp;label=CI&amp;logo=github&amp;style=flat-square&quot; alt=&quot;GitHub Actions Workflow Status&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/esp-rs/esp-hal/hil.yml?labelColor=1C2C2E&amp;label=HIL&amp;logo=github&amp;style=flat-square&amp;event=merge_group&quot; alt=&quot;GitHub Actions Workflow Status&quot; /&gt;
  &lt;img src=&quot;https://img.shields.io/badge/license-MIT%2FApache--2.0-blue?labelColor=1C2C2E&amp;style=flat-square&quot; alt=&quot;MIT/Apache-2.0 licensed&quot; /&gt;
  &lt;a href=&quot;https://matrix.to/#/#esp-rs:matrix.org&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/matrix/esp-rs:matrix.org?labelColor=1C2C2E&amp;label=join%20matrix&amp;color=BEC5C9&amp;logo=matrix&amp;style=flat-square&quot; alt=&quot;Matrix&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

Bare-metal (`no_std`) hardware abstraction layer for Espressif devices. Currently supports the following devices:

- ESP32 Series: _ESP32_
- ESP32-C Series: _ESP32-C2, ESP32-C3, ESP32-C6_
- ESP32-H Series: _ESP32-H2_
- ESP32-S Series: _ESP32-S2, ESP32-S3_

Additionally provides support for programming the low-power RISC-V cores found on the _ESP32-C6_, _ESP32-S2_, and _ESP32-S3_ via the [esp-lp-hal] package.

For additional information regarding any of the crates in this repository, please refer to the relevant crate&#039;s `README.md` file. If you have any questions, comments, or concerns, please [open an issue], [start a new discussion], or join us on [Matrix].

If you are currently using (or considering using) `esp-hal` in a production environment and have any feedback or require support, please feel free to contact us at &lt;rust.support@espressif.com&gt;.

&gt; [!NOTE]
&gt;
&gt; This repository includes crates that are at various stages of maturity and stability. While many functionalities have already been implemented and are usable for most tasks, certain advanced or less common features may still be under development. Each crate may offer different levels of functionality and guarantees.

[esp-lp-hal]: https://github.com/esp-rs/esp-hal/tree/main/esp-lp-hal
[esp-idf-svc]: https://github.com/esp-rs/esp-idf-svc
[open an issue]: https://github.com/esp-rs/esp-hal/issues/new
[start a new discussion]: https://github.com/esp-rs/esp-hal/discussions/new
[matrix]: https://matrix.to/#/#esp-rs:matrix.org

## Getting Started

For information relating to the development of Rust applications on ESP devices, please first read [The Rust on ESP Book].

For information about the HAL and how to use it in your own projects, please refer to the [documentation].

When browsing the examples, we recommend viewing the tag for the `esp-hal` release you are using to ensure compatibility, e.g. [esp-hal-v1.0.0], as the `main` branch is used for development and APIs may have changed in the meantime.

[The Rust on ESP Book]: https://docs.espressif.com/projects/rust/book/
[documentation]: https://docs.espressif.com/projects/rust/
[esp-hal-v1.0.0]: https://github.com/esp-rs/esp-hal/tree/esp-hal-v1.0.0/examples

## Resources

- [The Rust Programming Language](https://doc.rust-lang.org/book/)
- [The Embedded Rust Book](https://docs.rust-embedded.org/book/index.html)
- [The Embedonomicon](https://docs.rust-embedded.org/embedonomicon/)
- [The Rust on ESP Book](https://docs.espressif.com/projects/rust/esp-hal/latest/)
- [Embedded Rust (no_std) on Espressif](https://docs.espressif.com/projects/rust/no_std-training/)

## Support policy

All active development will occur on `main`.

We will only backport fixes to the _latest_ minor release in a major version. For example, this means we will apply patches (bug fixes) to `1.1.x` until `1.2.0` is released, at which point all patches are only backported to the `1.2.x` series of releases.

If you are a user of `unstable` APIs, we will never push breaking changes in a patch release. However, `unstable` changes _will_ make there way into minor releases. This means that as an `unstable` user updating from `1.1.x` to `1.2.x` _may_ introduce breaking changes. If you depend on `unstable`, we recommend defining your esp-hal dependency as follows:

```toml
esp-hal = { version = &quot;~1.1&quot; }
```

Using the [`~` operator](https://doc.rust-lang.org/cargo/reference/specifying-dependencies.html#tilde-requirements) will prevent cargo auto updating to minor versions, allowing you to use `cargo update` without the possiblity of breaking your project.

## AI Contribution Policy

We follow the same policy as the official Rust Embedded working group, please review [the policy](https://github.com/rust-embedded/wg/blob/HEAD/CODE_OF_CONDUCT.md#ai-tool-use-policy) before contributing with AI tools.

## Contributing

We have a number of living documents to aid contributing to the project, please give these a read before modifying code:

- [DEVELOPER-GUIDELINES](https://github.com/esp-rs/esp-hal/blob/main/documentation/DEVELOPER-GUIDELINES.md)
- [CONTRIBUTING-GUIDE](https://github.com/esp-rs/esp-hal/blob/main/documentation/CONTRIBUTING.md)

## License

All packages within this repository are licensed under either of:

- Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or http://www.apache.org/licenses/LICENSE-2.0)
- MIT license ([LICENSE-MIT](LICENSE-MIT) or http://opensource.org/licenses/MIT)

at your option.

### Contribution notice

Unless you explicitly state otherwise, any contribution intentionally submitted for inclusion in
the work by you, as defined in the Apache-2.0 license, shall be dual licensed as above, without
any additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[jdx/mise]]></title>
            <link>https://github.com/jdx/mise</link>
            <guid>https://github.com/jdx/mise</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:25 GMT</pubDate>
            <description><![CDATA[dev tools, env vars, task runner]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jdx/mise">jdx/mise</a></h1>
            <p>dev tools, env vars, task runner</p>
            <p>Language: Rust</p>
            <p>Stars: 21,927</p>
            <p>Forks: 757</p>
            <p>Stars today: 40 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;h1 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mise.jdx.dev&quot;&gt;
    &lt;img src=&quot;docs/public/logo.svg&quot; alt=&quot;mise&quot; width=&quot;256&quot; height=&quot;256&quot; /&gt;
    &lt;br&gt;
    mise-en-place
  &lt;/a&gt;
&lt;/h1&gt;

&lt;p&gt;
  &lt;a href=&quot;https://crates.io/crates/mise&quot;&gt;&lt;img alt=&quot;Crates.io&quot; src=&quot;https://img.shields.io/crates/v/mise?style=for-the-badge&amp;color=00d9ff&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/jdx/mise/blob/main/LICENSE&quot;&gt;&lt;img alt=&quot;GitHub&quot; src=&quot;https://img.shields.io/github/license/jdx/mise?style=for-the-badge&amp;color=52e892&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/jdx/mise/actions/workflows/test.yml&quot;&gt;&lt;img alt=&quot;GitHub Workflow Status&quot; src=&quot;https://img.shields.io/github/actions/workflow/status/jdx/mise/test.yml?style=for-the-badge&amp;color=ff9100&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/mABnUDvP57&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1066429325269794907?style=for-the-badge&amp;color=00d9ff&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;&lt;b&gt;The front-end to your dev env&lt;/b&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mise.jdx.dev/getting-started.html&quot;&gt;Getting Started&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://mise.jdx.dev&quot;&gt;Documentation&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://mise.jdx.dev/dev-tools/&quot;&gt;Dev Tools&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://mise.jdx.dev/environments/&quot;&gt;Environments&lt;/a&gt; ‚Ä¢
  &lt;a href=&quot;https://mise.jdx.dev/tasks/&quot;&gt;Tasks&lt;/a&gt;
&lt;/p&gt;

&lt;hr /&gt;

&lt;/div&gt;

## What is it?

- Like [asdf](https://asdf-vm.com) (or [nvm](https://github.com/nvm-sh/nvm) or [pyenv](https://github.com/pyenv/pyenv) but for any language) it manages [dev tools](https://mise.jdx.dev/dev-tools/) like node, python, cmake, terraform, and [hundreds more](https://mise.jdx.dev/registry.html).
- Like [direnv](https://github.com/direnv/direnv) it manages [environment variables](https://mise.jdx.dev/environments/) for different project directories.
- Like [make](https://www.gnu.org/software/make/manual/make.html) it manages [tasks](https://mise.jdx.dev/tasks/) used to build and test projects.

## Demo

The following demo shows how to install and use `mise` to manage multiple versions of `node` on the same system.
Note that calling `which node` gives us a real path to node, not a shim.

It also shows that you can use `mise` to install and many other tools such as `jq`, `terraform`, or `go`.

[![demo](./docs/tapes/demo.gif)](https://mise.jdx.dev/demo.html)

See [demo transcript](https://mise.jdx.dev/demo.html).

## Quickstart

### Install mise

See [Getting started](https://mise.jdx.dev/getting-started.html) for more options.

```sh-session
$ curl https://mise.run | sh
$ ~/.local/bin/mise --version
2025.12.0 macos-arm64 (a1b2d3e 2025-12-04)
```

Hook mise into your shell (pick the right one for your shell):

```sh-session
# note this assumes mise is located at ~/.local/bin/mise
# which is what https://mise.run does by default
echo &#039;eval &quot;$(~/.local/bin/mise activate bash)&quot;&#039; &gt;&gt; ~/.bashrc
echo &#039;eval &quot;$(~/.local/bin/mise activate zsh)&quot;&#039; &gt;&gt; ~/.zshrc
echo &#039;~/.local/bin/mise activate fish | source&#039; &gt;&gt; ~/.config/fish/config.fish
echo &#039;~/.local/bin/mise activate pwsh | Out-String | Invoke-Expression&#039; &gt;&gt; ~/.config/powershell/Microsoft.PowerShell_profile.ps1
```

### Execute commands with specific tools

```sh-session
$ mise exec node@24 -- node -v
mise node@24.x.x ‚úì installed
v24.x.x
```

### Install tools

```sh-session
$ mise use --global node@24 go@1
$ node -v
v24.x.x
$ go version
go version go1.x.x macos/arm64
```

See [dev tools](https://mise.jdx.dev/dev-tools/) for more examples.

### Manage environment variables

```toml
# mise.toml
[env]
SOME_VAR = &quot;foo&quot;
```

```sh-session
$ mise set SOME_VAR=bar
$ echo $SOME_VAR
bar
```

Note that `mise` can also [load `.env` files](https://mise.jdx.dev/environments/#env-directives).

### Run tasks

```toml
# mise.toml
[tasks.build]
description = &quot;build the project&quot;
run = &quot;echo building...&quot;
```

```sh-session
$ mise run build
building...
```

See [tasks](https://mise.jdx.dev/tasks/) for more information.

### Example mise project

Here is a combined example to give you an idea of how you can use mise to manage your a project&#039;s tools, environment, and tasks.

```toml
# mise.toml
[tools]
terraform = &quot;1&quot;
aws-cli = &quot;2&quot;

[env]
TF_WORKSPACE = &quot;development&quot;
AWS_REGION = &quot;us-west-2&quot;
AWS_PROFILE = &quot;dev&quot;

[tasks.plan]
description = &quot;Run terraform plan with configured workspace&quot;
run = &quot;&quot;&quot;
terraform init
terraform workspace select $TF_WORKSPACE
terraform plan
&quot;&quot;&quot;

[tasks.validate]
description = &quot;Validate AWS credentials and terraform config&quot;
run = &quot;&quot;&quot;
aws sts get-caller-identity
terraform validate
&quot;&quot;&quot;

[tasks.deploy]
description = &quot;Deploy infrastructure after validation&quot;
depends = [&quot;validate&quot;, &quot;plan&quot;]
run = &quot;terraform apply -auto-approve&quot;
```

Run it with:

```sh-session
mise install # install tools specified in mise.toml
mise run deploy
```

Find more examples in the [mise cookbook](https://mise.jdx.dev/mise-cookbook/).

## Full Documentation

See [mise.jdx.dev](https://mise.jdx.dev)

## GitHub Issues &amp; Discussions

Due to the volume of issue submissions mise received, using GitHub Issues became unsustainable for
the project. Instead, mise uses GitHub Discussions which provide a more community-centric platform
for communication and require less management on the part of the maintainers.

Please note the following discussion categories, which match how issues are often used:

- [Announcements](https://github.com/jdx/mise/discussions/categories/announcements)
- [Ideas](https://github.com/jdx/mise/discussions/categories/ideas): for feature requests, etc.
- [Troubleshooting &amp; Bug Reports](https://github.com/jdx/mise/discussions/categories/troubleshooting-and-bug-reports)

## Special Thanks

We&#039;re grateful for Cloudflare&#039;s support through [Project Alexandria](https://www.cloudflare.com/lp/project-alexandria/).

## Contributors

[![Contributors](https://contrib.rocks/image?repo=jdx/mise)](https://github.com/jdx/mise/graphs/contributors)
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[maplibre/martin]]></title>
            <link>https://github.com/maplibre/martin</link>
            <guid>https://github.com/maplibre/martin</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:24 GMT</pubDate>
            <description><![CDATA[Blazing fast and lightweight PostGIS, MBtiles and PMtiles tile server, tile generation, and mbtiles tooling.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/maplibre/martin">maplibre/martin</a></h1>
            <p>Blazing fast and lightweight PostGIS, MBtiles and PMtiles tile server, tile generation, and mbtiles tooling.</p>
            <p>Language: Rust</p>
            <p>Stars: 3,150</p>
            <p>Forks: 306</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>[![Martin](https://raw.githubusercontent.com/maplibre/martin/main/logo.png)](https://maplibre.org/martin/)

[![Book](https://img.shields.io/badge/docs-Book-informational)](https://maplibre.org/martin)
[![docs.rs docs](https://docs.rs/martin/badge.svg)](https://docs.rs/martin)
[![](https://img.shields.io/badge/Slack-%23maplibre--martin-blueviolet?logo=slack)](https://slack.openstreetmap.us/)
[![GitHub](https://img.shields.io/badge/github-maplibre/martin-8da0cb?logo=github)](https://github.com/maplibre/martin)
[![crates.io version](https://img.shields.io/crates/v/martin.svg)](https://crates.io/crates/martin)
[![Security audit](https://github.com/maplibre/martin/workflows/Security%20audit/badge.svg)](https://github.com/maplibre/martin/security)
[![CI build](https://github.com/maplibre/martin/actions/workflows/ci.yml/badge.svg)](https://github.com/maplibre/martin/actions)
[![Codecov](https://img.shields.io/codecov/c/github/maplibre/martin)](https://app.codecov.io/gh/maplibre/martin)

Martin is a tile server and a set of tools able to generate vector tiles on the fly
from large `PostgreSQL` databases, and serve tiles from `PMTiles` and `MBTiles` files. Martin optimizes for speed and heavy traffic, and is written in [Rust](https://github.com/rust-lang/rust).

## Features

* Serve [vector tiles](https://github.com/mapbox/vector-tile-spec) from
  * [PostGIS](https://github.com/postgis/postgis) databases, automatically discovering compatible tables and functions
  * [PMTile](https://protomaps.com/blog/pmtiles-v3-whats-new), both local files and over HTTP
  * [MBTile](https://github.com/mapbox/mbtiles-spec) files
* [Combine](https://maplibre.org/martin/sources-composite.html) multiple tile sources into one
* Serve [styles](https://maplibre.org/martin/sources-styles.html) and generate [sprites](https://maplibre.org/martin/sources-sprites.html) or [font glyphs](https://maplibre.org/martin/sources-fonts.html) on the fly
* Generate tiles in bulk from any Martin-supported sources into an `MBTiles` file with [martin-cp](https://maplibre.org/martin/martin-cp.html) tool
* Examine, copy, validate, compare, and apply diffs between `MBTiles` files with [mbtiles](https://maplibre.org/martin/tools.html#mbtiles) tool

## Documentation

* [Quick Start](https://maplibre.org/martin/quick-start.html)
* [Installation](https://maplibre.org/martin/installation.html)
* Running with [CLI](https://maplibre.org/martin/run-with-cli.html)
  or [configuration file](https://maplibre.org/martin/config-file.html)
* [Usage and API](https://maplibre.org/martin/using.html)

## Getting Involved

Join the `#maplibre-martin` slack channel at OSMUS -- automatic invite is at &lt;https://slack.openstreetmap.us/&gt;

## Contributing

Like any open source project, Martin welcomes contributions from anyone who wants to help improve it.

* See [Development Guide](https://maplibre.org/martin/development.html) for setup
* Use `just help` for common commands
* Check [help wanted](https://github.com/maplibre/martin/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22) issues

## License

Licensed under either of

* Apache License, Version 2.0 ([LICENSE-APACHE](LICENSE-APACHE) or &lt;http://www.apache.org/licenses/LICENSE-2.0&gt;)
* MIT license ([LICENSE-MIT](LICENSE-MIT) or &lt;http://opensource.org/licenses/MIT&gt;)
  at your option.

### Contribution

Unless you explicitly state otherwise, any contribution intentionally
submitted for inclusion in the work by you, as defined in the
Apache-2.0 license, shall be dual licensed as above, without any
additional terms or conditions.
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
        <item>
            <title><![CDATA[typst/typst]]></title>
            <link>https://github.com/typst/typst</link>
            <guid>https://github.com/typst/typst</guid>
            <pubDate>Sat, 06 Dec 2025 00:05:23 GMT</pubDate>
            <description><![CDATA[A markup-based typesetting system that is powerful and easy to learn.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/typst/typst">typst/typst</a></h1>
            <p>A markup-based typesetting system that is powerful and easy to learn.</p>
            <p>Language: Rust</p>
            <p>Stars: 49,086</p>
            <p>Forks: 1,345</p>
            <p>Stars today: 59 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
  &lt;img alt=&quot;Typst&quot; src=&quot;https://user-images.githubusercontent.com/17899797/226108480-722b770e-6313-40d7-84f2-26bebb55a281.png&quot;&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://typst.app/docs/&quot;&gt;
    &lt;img alt=&quot;Documentation&quot; src=&quot;https://img.shields.io/website?down_message=offline&amp;label=docs&amp;up_color=007aff&amp;up_message=online&amp;url=https%3A%2F%2Ftypst.app%2Fdocs&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://typst.app/&quot;&gt;
    &lt;img alt=&quot;Typst App&quot; src=&quot;https://img.shields.io/website?down_message=offline&amp;label=typst.app&amp;up_color=239dad&amp;up_message=online&amp;url=https%3A%2F%2Ftypst.app&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/2uDybryKPe&quot;&gt;
    &lt;img alt=&quot;Discord Server&quot; src=&quot;https://img.shields.io/discord/1054443721975922748?color=5865F2&amp;label=discord&amp;labelColor=555&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/typst/typst/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;Apache-2 License&quot; src=&quot;https://img.shields.io/badge/license-Apache%202-brightgreen&quot;
  &gt;&lt;/a&gt;
  &lt;a href=&quot;https://typst.app/jobs/&quot;&gt;
    &lt;img alt=&quot;Jobs at Typst&quot; src=&quot;https://img.shields.io/badge/dynamic/json?url=https%3A%2F%2Ftypst.app%2Fassets%2Fdata%2Fshields.json&amp;query=%24.jobs.text&amp;label=jobs&amp;color=%23A561FF&amp;cacheSeconds=1800&quot;
  &gt;&lt;/a&gt;
&lt;/p&gt;

Typst is a new markup-based typesetting system that is designed to be as powerful
as LaTeX while being much easier to learn and use. Typst has:

- Built-in markup for the most common formatting tasks
- Flexible functions for everything else
- A tightly integrated scripting system
- Math typesetting, bibliography management, and more
- Fast compile times thanks to incremental compilation
- Friendly error messages in case something goes wrong

This repository contains the Typst compiler and its CLI, which is everything you
need to compile Typst documents locally. For the best writing experience,
consider signing up to our [collaborative online editor][app] for free.

## Example
A [gentle introduction][tutorial] to Typst is available in our documentation.
However, if you want to see the power of Typst encapsulated in one image, here
it is:
&lt;p align=&quot;center&quot;&gt;
 &lt;img alt=&quot;Example&quot; width=&quot;900&quot; src=&quot;https://user-images.githubusercontent.com/17899797/228031796-ced0e452-fcee-4ae9-92da-b9287764ff25.png&quot;&gt;
&lt;/p&gt;


Let&#039;s dissect what&#039;s going on:

- We use _set rules_ to configure element properties like the size of pages or
  the numbering of headings. By setting the page height to `auto`, it scales to
  fit the content. Set rules accommodate the most common configurations. If you
  need full control, you can also use [show rules][show] to completely redefine
  the appearance of an element.

- We insert a heading with the `= Heading` syntax. One equals sign creates a top
  level heading, two create a subheading and so on. Typst has more lightweight
  markup like this, see the [syntax] reference for a full list.

- [Mathematical equations][math] are enclosed in dollar signs. By adding extra
  spaces around the contents of an equation, we can put it into a separate block.
  Multi-letter identifiers are interpreted as Typst definitions and functions
  unless put into quotes. This way, we don&#039;t need backslashes for things like
  `floor` and `sqrt`. And `phi.alt` applies the `alt` modifier to the `phi` to
  select a particular symbol variant.

- Now, we get to some [scripting]. To input code into a Typst document, we can
  write a hash followed by an expression. We define two variables and a
  recursive function to compute the n-th fibonacci number. Then, we display the
  results in a center-aligned table. The table function takes its cells
  row-by-row. Therefore, we first pass the formulas `$F_1$` to `$F_8$` and then
  the computed fibonacci numbers. We apply the spreading operator (`..`) to both
  because they are arrays and we want to pass the arrays&#039; items as individual
  arguments.

&lt;details&gt;
  &lt;summary&gt;Text version of the code example.&lt;/summary&gt;

  ```typst
  #set page(width: 10cm, height: auto)
  #set heading(numbering: &quot;1.&quot;)

  = Fibonacci sequence
  The Fibonacci sequence is defined through the
  recurrence relation $F_n = F_(n-1) + F_(n-2)$.
  It can also be expressed in _closed form:_

  $ F_n = round(1 / sqrt(5) phi.alt^n), quad
    phi.alt = (1 + sqrt(5)) / 2 $

  #let count = 8
  #let nums = range(1, count + 1)
  #let fib(n) = (
    if n &lt;= 2 { 1 }
    else { fib(n - 1) + fib(n - 2) }
  )

  The first #count numbers of the sequence are:

  #align(center, table(
    columns: count,
    ..nums.map(n =&gt; $F_#n$),
    ..nums.map(n =&gt; str(fib(n))),
  ))
  ```
&lt;/details&gt;

## Installation
Typst&#039;s CLI is available from different sources:

- You can get sources and pre-built binaries for the latest release of Typst
  from the [releases page][releases]. Download the archive for your platform and
  place it in a directory that is in your `PATH`. To stay up to date with future
  releases, you can simply run `typst update`.

- You can install Typst through different package managers. Note that the
  versions in the package managers might lag behind the latest release.
  - Linux:
      - View [Typst on Repology][repology]
      - View [Typst&#039;s Snap][snap]
  - macOS: `brew install typst`
  - Windows: `winget install --id Typst.Typst`

- If you have a [Rust][rust] toolchain installed, you can install
  - the latest released Typst version with
    `cargo install --locked typst-cli`
  - a development version with
    `cargo install --git https://github.com/typst/typst --locked typst-cli`

- Nix users can
  - use the `typst` package with `nix-shell -p typst`
  - build and run a development version with
    `nix run github:typst/typst -- --version`.

- Docker users can run a prebuilt image with
  `docker run ghcr.io/typst/typst:latest --help`.

## Usage
Once you have installed Typst, you can use it like this:
```sh
# Creates `file.pdf` in working directory.
typst compile file.typ

# Creates PDF file at the desired path.
typst compile path/to/source.typ path/to/output.pdf
```

You can also watch source files and automatically recompile on changes. This is
faster than compiling from scratch each time because Typst has incremental
compilation.
```sh
# Watches source files and recompiles on changes.
typst watch file.typ
```

Typst further allows you to add custom font paths for your project and list all
of the fonts it discovered:
```sh
# Adds additional directories to search for fonts.
typst compile --font-path path/to/fonts file.typ

# Lists all of the discovered fonts in the system and the given directory.
typst fonts --font-path path/to/fonts

# Or via environment variable (Linux syntax).
TYPST_FONT_PATHS=path/to/fonts typst fonts
```

For other CLI subcommands and options, see below:
```sh
# Prints available subcommands and options.
typst help

# Prints detailed usage of a subcommand.
typst help watch
```

If you prefer an integrated IDE-like experience with autocompletion and instant 
preview, you can also check out our [free web app][app]. Alternatively, there is 
a community-created language server called 
[Tinymist](https://myriad-dreamin.github.io/tinymist/) which is integrated into 
various editor extensions.

## Community
The main places where the community gathers are our [Forum][forum] and our
[Discord server][discord]. The Forum is a great place to ask questions, help
others, and share cool things you created with Typst. The Discord server is more
suitable for quicker questions, discussions about contributing, or just to chat.
We&#039;d be happy to see you there!

[Typst Universe][universe] is where the community shares templates and packages.
If you want to share your own creations, you can submit them to our
[package repository][packages].

If you had a bad experience in our community, please [reach out to us][contact].

## Contributing
We love to see contributions from the community. If you experience bugs, feel
free to open an issue. If you would like to implement a new feature or bug fix,
please follow the steps outlined in the [contribution guide][contributing].

To build Typst yourself, first ensure that you have the
[latest stable Rust][rust] installed. Then, clone this repository and build the
CLI with the following commands:

```sh
git clone https://github.com/typst/typst
cd typst
cargo build --release
```

The optimized binary will be stored in `target/release/`.

Another good way to contribute is by [sharing packages][packages] with the
community.

## Pronunciation and Spelling
IPA: /ta…™pst/. &quot;Ty&quot; like in **Ty**pesetting and &quot;pst&quot; like in Hi**pst**er. When
writing about Typst, capitalize its name as a proper noun, with a capital &quot;T&quot;.

## Design Principles
All of Typst has been designed with three key goals in mind: Power,
simplicity, and performance. We think it&#039;s time for a system that matches the
power of LaTeX, is easy to learn and use, all while being fast enough to realize
instant preview. To achieve these goals, we follow three core design principles:

- **Simplicity through Consistency:**
  If you know how to do one thing in Typst, you should be able to transfer that
  knowledge to other things. If there are multiple ways to do the same thing,
  one of them should be at a different level of abstraction than the other. E.g.
  it&#039;s okay that `= Introduction` and `#heading[Introduction]` do the same thing
  because the former is just syntax sugar for the latter.

- **Power through Composability:**
  There are two ways to make something flexible: Have a knob for everything or
  have a few knobs that you can combine in many ways. Typst is designed with the
  second way in mind. We provide systems that you can compose in ways we&#039;ve
  never even thought of. TeX is also in the second category, but it&#039;s a bit
  low-level and therefore people use LaTeX instead. But there, we don&#039;t really
  have that much composability. Instead, there&#039;s a package for everything
  (`\usepackage{knob}`).

- **Performance through Incrementality:**
  All Typst language features must accommodate for incremental compilation.
  Luckily we have [`comemo`], a system for incremental compilation which does
  most of the hard work in the background.

## Acknowledgements

We&#039;d like to thank everyone who is supporting Typst&#039;s development, be it via
[GitHub sponsors] or elsewhere. In particular, special thanks[^1] go to:

- [Posit](https://posit.co/blog/posit-and-typst/) for financing a full-time
  compiler engineer
- [NLnet](https://nlnet.nl/) for supporting work on Typst via multiple grants
  through the [NGI Zero Core](https://nlnet.nl/core) fund:
  - Work on [HTML export](https://nlnet.nl/project/Typst-HTML/)
  - Work on [PDF accessibility](https://nlnet.nl/project/Typst-Accessibility/)
- [Science &amp; Startups](https://www.science-startups.berlin/) for having financed
  Typst development from January through June 2023 via the Berlin Startup
  Scholarship
- [Zerodha](https://zerodha.tech/blog/1-5-million-pdfs-in-25-minutes/) for their
  generous one-time sponsorship

[^1]: This list only includes contributions for our open-source work that exceed
    or are expected to exceed ‚Ç¨10K.

[docs]: https://typst.app/docs/
[app]: https://typst.app/
[discord]: https://discord.gg/2uDybryKPe
[forum]: https://forum.typst.app/
[universe]: https://typst.app/universe/
[tutorial]: https://typst.app/docs/tutorial/
[show]: https://typst.app/docs/reference/styling/#show-rules
[math]: https://typst.app/docs/reference/math/
[syntax]: https://typst.app/docs/reference/syntax/
[scripting]: https://typst.app/docs/reference/scripting/
[rust]: https://rustup.rs/
[releases]: https://github.com/typst/typst/releases/
[repology]: https://repology.org/project/typst/versions
[contact]: https://typst.app/contact
[architecture]: https://github.com/typst/typst/blob/main/docs/dev/architecture.md
[contributing]: https://github.com/typst/typst/blob/main/CONTRIBUTING.md
[packages]: https://github.com/typst/packages/
[`comemo`]: https://github.com/typst/comemo/
[snap]: https://snapcraft.io/typst
[GitHub sponsors]: https://github.com/sponsors/typst/
</pre>
          ]]></content:encoded>
            <category>Rust</category>
        </item>
    </channel>
</rss>