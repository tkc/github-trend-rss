<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Wed, 31 Dec 2025 00:04:37 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[timescale/pg-aiguide]]></title>
            <link>https://github.com/timescale/pg-aiguide</link>
            <guid>https://github.com/timescale/pg-aiguide</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:37 GMT</pubDate>
            <description><![CDATA[MCP server and Claude plugin for Postgres skills and documentation. Helps AI coding tools generate better PostgreSQL code.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/timescale/pg-aiguide">timescale/pg-aiguide</a></h1>
            <p>MCP server and Claude plugin for Postgres skills and documentation. Helps AI coding tools generate better PostgreSQL code.</p>
            <p>Language: Python</p>
            <p>Stars: 784</p>
            <p>Forks: 43</p>
            <p>Stars today: 384 stars today</p>
            <h2>README</h2><pre># pg-aiguide

**AI-optimized PostgreSQL expertise for coding assistants**

pg-aiguide helps AI coding tools write dramatically better PostgreSQL code. It provides:

- **Semantic search** across the official PostgreSQL manual (version-aware)
- **AI-optimized ‚Äúskills‚Äù** ‚Äî curated, opinionated Postgres best practices used automatically by AI agents
- **Extension ecosystem docs**, starting with TimescaleDB, with more coming soon

Use it either as:

- a **public MCP server** that can be used with any AI coding agent, or
- a **Claude Code plugin** optimized for use with Claude&#039;s native skill support.

## ‚≠ê Why pg-aiguide?

AI coding tools often generate Postgres code that is:

- outdated
- missing constraints and indexes
- unaware of modern PG features
- inconsistent with real-world best practices

pg-aiguide fixes that by giving AI agents deep, versioned PostgreSQL knowledge and proven patterns.

### See the difference

https://github.com/user-attachments/assets/5a426381-09b5-4635-9050-f55422253a3d

&lt;details&gt;
&lt;summary&gt;Video Transcript &lt;/summary&gt;

Prompt given to Claude Code:

&gt; Please describe the schema you would create for an e-commerce website two times, first with the tiger mcp server disabled, then with the tiger mcp server enabled. For each time, write the schema to its own file in the current working directory. Then compare the two files and let me know which approach generated the better schema, using both qualitative and quantitative reasons. For this example, only use standard Postgres.

Result (summarized):

- **4√ó more constraints**
- **55% more indexes** (including partial/expression indexes)
- **PG17-recommended patterns**
- **Modern features** (`GENERATED ALWAYS AS IDENTITY`, `NULLS NOT DISTINCT`)
- **Cleaner naming &amp; documentation**

Conclusion: _pg-aiguide produces more robust, performant, maintainable schemas._

&lt;/details&gt;

## üöÄ Quickstart

pg-aiguide is available as a **public MCP server**:

[https://mcp.tigerdata.com/docs](https://mcp.tigerdata.com/docs)

&lt;details&gt; 
&lt;summary&gt;Manual MCP configuration using JSON&lt;/summary&gt;

```json
{
  &quot;mcpServers&quot;: {
    &quot;pg-aiguide&quot;: {
      &quot;url&quot;: &quot;https://mcp.tigerdata.com/docs&quot;
    }
  }
}
```

&lt;/details&gt;

Or it can be used as a **Claude Code Plugin**:

```bash
claude plugin marketplace add timescale/pg-aiguide
claude plugin install pg@aiguide
```

### Install by environment

#### One-click installs

[![Install in Cursor](https://img.shields.io/badge/Install_in-Cursor-000000?style=flat-square&amp;logoColor=white)](https://cursor.com/en/install-mcp?name=pg-aiguide&amp;config=eyJuYW1lIjoicGctYWlndWlkZSIsInR5cGUiOiJodHRwIiwidXJsIjoiaHR0cHM6Ly9tY3AudGlnZXJkYXRhLmNvbS9kb2NzIn0=)
[![Install in VS Code](https://img.shields.io/badge/Install_in-VS_Code-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://vscode.dev/redirect/mcp/install?name=pg-aiguide&amp;config=%7B%22type%22%3A%22http%22%2C%22url%22%3A%22https%3A%2F%2Fmcp.tigerdata.com%2Fdocs%22%7D)
[![Install in VS Code Insiders](https://img.shields.io/badge/Install_in-VS_Code_Insiders-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=pg-aiguide&amp;config=%7B%22type%22%3A%22http%22%2C%22url%22%3A%22https%3A%2F%2Fmcp.tigerdata.com%2Fdocs%22%7D&amp;quality=insiders)
[![Install in Visual Studio](https://img.shields.io/badge/Install_in-Visual_Studio-C16FDE?style=flat-square&amp;logo=visualstudio&amp;logoColor=white)](https://vs-open.link/mcp-install?%7B%22type%22%3A%22http%22%2C%22url%22%3A%22https%3A%2F%2Fmcp.tigerdata.com%2Fdocs%22%7D)
[![Install in Goose](https://block.github.io/goose/img/extension-install-dark.svg)](https://block.github.io/goose/extension?cmd=&amp;arg=&amp;id=pg-aiguide&amp;name=pg-aiguide&amp;description=MCP%20Server%20for%20pg-aiguide)
[![Add MCP Server pg-aiguide to LM Studio](https://files.lmstudio.ai/deeplink/mcp-install-light.svg)](https://lmstudio.ai/install-mcp?name=pg-aiguide&amp;config=eyJuYW1lIjoicGctYWlndWlkZSIsInR5cGUiOiJodHRwIiwidXJsIjoiaHR0cHM6Ly9tY3AudGlnZXJkYXRhLmNvbS9kb2NzIn0=)

&lt;details&gt;
&lt;summary&gt;Claude Code&lt;/summary&gt;

This repo serves as a claude code marketplace plugin. To install, run:

```bash
claude plugin marketplace add timescale/pg-aiguide
claude plugin install pg@aiguide
```

This plugin uses the skills available in the `skills` directory as well as our
publicly available MCP server endpoint hosted by TigerData for searching PostgreSQL documentation.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt; Codex &lt;/summary&gt;

Run the following to add the MCP server to codex:

```bash
codex mcp add --url &quot;https://mcp.tigerdata.com/docs&quot; pg-aiguide
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt; Cursor &lt;/summary&gt;

One-click install:

[![Install MCP Server](https://cursor.com/deeplink/mcp-install-dark.svg)](https://cursor.com/en-US/install-mcp?name=pg-aiguide&amp;config=eyJ1cmwiOiJodHRwczovL21jcC50aWdlcmRhdGEuY29tL2RvY3MifQ%3D%3D)

Or add the following to `.cursor/mcp.json`

```json
{
  &quot;mcpServers&quot;: {
    &quot;pg-aiguide&quot;: {
      &quot;url&quot;: &quot;https://mcp.tigerdata.com/docs&quot;
    }
  }
}
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt; Gemini CLI &lt;/summary&gt;

Run the following to add the MCP server to Gemini CLI:

```bash
gemini mcp add -s user pg-aiguide &quot;https://mcp.tigerdata.com/docs&quot; -t http
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt; Visual Studio &lt;/summary&gt;

Click the button to install:

[![Install in Visual Studio](https://img.shields.io/badge/Install_in-Visual_Studio-C16FDE?style=flat-square&amp;logo=visualstudio&amp;logoColor=white)](https://vs-open.link/mcp-install?%7B%22type%22%3A%22http%22%2C%22url%22%3A%22https%3A%2F%2Fmcp.tigerdata.com%2Fdocs%22%7D)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt; VS Code &lt;/summary&gt;

Click the button to install:

[![Install in VS Code](https://img.shields.io/badge/Install_in-VS_Code-0098FF?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://vscode.dev/redirect/mcp/install?name=pg-aiguide&amp;config=%7B%22type%22%3A%22http%22%2C%22url%22%3A%22https%3A%2F%2Fmcp.tigerdata.com%2Fdocs%22%7D)

Alternatively, run the following to add the MCP server to VS Code:

```bash
code --add-mcp &#039;{&quot;name&quot;:&quot;pg-aiguide&quot;,&quot;type&quot;:&quot;http&quot;,&quot;url&quot;:&quot;https://mcp.tigerdata.com/docs&quot;}&#039;
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt; VS Code Insiders &lt;/summary&gt;

Click the button to install:

[![Install in VS Code Insiders](https://img.shields.io/badge/Install_in-VS_Code_Insiders-24bfa5?style=flat-square&amp;logo=visualstudiocode&amp;logoColor=white)](https://insiders.vscode.dev/redirect/mcp/install?name=pg-aiguide&amp;config=%7B%22type%22%3A%22http%22%2C%22url%22%3A%22https%3A%2F%2Fmcp.tigerdata.com%2Fdocs%22%7D&amp;quality=insiders)

Alternatively, run the following to add the MCP server to VS Code Insiders:

```bash
code-insiders --add-mcp &#039;{&quot;name&quot;:&quot;pg-aiguide&quot;,&quot;type&quot;:&quot;http&quot;,&quot;url&quot;:&quot;https://mcp.tigerdata.com/docs&quot;}&#039;
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt; Windsurf &lt;/summary&gt;

Add the following to `~/.codeium/windsurf/mcp_config.json`

```json
{
  &quot;mcpServers&quot;: {
    &quot;pg-aiguide&quot;: {
      &quot;serverUrl&quot;: &quot;https://mcp.tigerdata.com/docs&quot;
    }
  }
}
```

&lt;/details&gt;

### üí° Your First Prompt

Once installed, pg-aiguide can answer Postgres questions or design schemas.

**Simple schema example prompt**

&gt; Create a Postgres table schema for storing usernames and unique email addresses.

**Complex schema example prompt**

&gt; You are a senior software engineer. You are given a task to generate a Postgres schema for an IoT device company.
&gt; The devices collect environmental data on a factory floor. The data includes temperature, humidity, pressure, as
&gt; the main data points as well as other measurements that vary from device to device. Each device has a unique id
&gt; and a human-readable name. We want to record the time the data was collected as well. Analysis for recent data
&gt; includes finding outliers and anomalies based on measurements, as well as analyzing the data of particular devices for ad-hoc analysis. Historical data analysis includes analyzing the history of data for one device or getting statistics for all devices over long periods of time.

## Features

### Semantic Search (MCP Tools)

- [**`semantic_search_postgres_docs`**](API.md#semantic_search_postgres_docs)  
  Performs semantic search over the official PostgreSQL manual, with results scoped to a specific Postgres version.

- [**`semantic_search_tiger_docs`** ](API.md#semantic_search_tiger_docs)
  Searches Tiger Data‚Äôs documentation corpus, including TimescaleDB and future ecosystem extensions.

### Skills (AI-Optimized Best Practices)

- **[`view_skill`](API.md#view_skill)**  
  Exposes curated, opinionated PostgreSQL best-practice skills used automatically by AI coding assistants.

  These skills provide guidance on:
  - Schema design
  - Indexing strategies
  - Data types
  - Data integrity and constraints
  - Naming conventions
  - Performance tuning
  - Modern PostgreSQL features

## üîå Ecosystem Documentation

Supported today:

- **TimescaleDB** (docs + skills)

Coming soon:

- **pgvector**
- **PostGIS**

We welcome contributions for additional extensions and tools.

## üõ† Development

See [DEVELOPMENT.md](DEVELOPMENT.md) for:

- running the MCP server locally
- adding new skills
- adding new docs

## ü§ù Contributing

We welcome:

- new Postgres best-practice skills
- additional documentation corpora
- search quality improvements
- bug reports and feature ideas

## üìÑ License

Apache 2.0
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[resemble-ai/chatterbox]]></title>
            <link>https://github.com/resemble-ai/chatterbox</link>
            <guid>https://github.com/resemble-ai/chatterbox</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:36 GMT</pubDate>
            <description><![CDATA[SoTA open-source TTS]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/resemble-ai/chatterbox">resemble-ai/chatterbox</a></h1>
            <p>SoTA open-source TTS</p>
            <p>Language: Python</p>
            <p>Stars: 19,625</p>
            <p>Forks: 2,566</p>
            <p>Stars today: 608 stars today</p>
            <h2>README</h2><pre>![Chatterbox Turbo Image](./Chatterbox-Turbo.jpg)


# Chatterbox TTS

[![Alt Text](https://img.shields.io/badge/listen-demo_samples-blue)](https://resemble-ai.github.io/chatterbox_turbo_demopage/)
[![Alt Text](https://huggingface.co/datasets/huggingface/badges/resolve/main/open-in-hf-spaces-sm.svg)](https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo)
[![Alt Text](https://static-public.podonos.com/badges/insight-on-pdns-sm-dark.svg)](https://podonos.com/resembleai/chatterbox)
[![Discord](https://img.shields.io/discord/1377773249798344776?label=join%20discord&amp;logo=discord&amp;style=flat)](https://discord.gg/rJq9cRJBJ6)

_Made with ‚ô•Ô∏è by &lt;a href=&quot;https://resemble.ai&quot; target=&quot;_blank&quot;&gt;&lt;img width=&quot;100&quot; alt=&quot;resemble-logo-horizontal&quot; src=&quot;https://github.com/user-attachments/assets/35cf756b-3506-4943-9c72-c05ddfa4e525&quot; /&gt;&lt;/a&gt;

**Chatterbox** is a family of three state-of-the-art, open-source text-to-speech models by Resemble AI.

We are excited to introduce **Chatterbox-Turbo**, our most efficient model yet. Built on a streamlined 350M parameter architecture, **Turbo** delivers high-quality speech with less compute and VRAM than our previous models. We have also distilled the speech-token-to-mel decoder, previously a bottleneck, reducing generation from 10 steps to just **one**, while retaining high-fidelity audio output.

**Paralinguistic tags** are now native to the Turbo model, allowing you to use `[cough]`, `[laugh]`, `[chuckle]`, and more to add distinct realism. While Turbo was built primarily for low-latency voice agents, it excels at narration and creative workflows.

If you like the model but need to scale or tune it for higher accuracy, check out our competitively priced TTS service (&lt;a href=&quot;https://resemble.ai&quot;&gt;link&lt;/a&gt;). It delivers reliable performance with ultra-low latency of sub 200ms‚Äîideal for production use in agents, applications, or interactive media.

&lt;img width=&quot;1200&quot; height=&quot;600&quot; alt=&quot;Podonos Turbo Eval&quot; src=&quot;https://storage.googleapis.com/chatterbox-demo-samples/turbo/podonos_turbo.png&quot; /&gt;

### ‚ö° Model Zoo

Choose the right model for your application.

| Model                                                                                                           | Size | Languages | Key Features                                            | Best For                                     | ü§ó                                                                  | Examples |
|:----------------------------------------------------------------------------------------------------------------| :--- | :--- |:--------------------------------------------------------|:---------------------------------------------|:--------------------------------------------------------------------------| :--- |
| **Chatterbox-Turbo**                                                                                            | **350M** | **English** | Paralinguistic Tags (`[laugh]`), Lower Compute and VRAM | Zero-shot voice agents,  Production          | [Demo](https://huggingface.co/spaces/ResembleAI/chatterbox-turbo-demo)        | [Listen](https://resemble-ai.github.io/chatterbox_turbo_demopage/) |
| Chatterbox-Multilingual [(Language list)](#supported-languages)                                                 | 500M | 23+ | Zero-shot cloning, Multiple Languages                   | Global applications, Localization            | [Demo](https://huggingface.co/spaces/ResembleAI/Chatterbox-Multilingual-TTS) | [Listen](https://resemble-ai.github.io/chatterbox_demopage/) |
| Chatterbox [(Tips and Tricks)](#original-chatterbox-tips)                                                       | 500M | English | CFG &amp; Exaggeration tuning                               | General zero-shot TTS with creative controls | [Demo](https://huggingface.co/spaces/ResembleAI/Chatterbox)              | [Listen](https://resemble-ai.github.io/chatterbox_demopage/) |

## Installation
```shell
pip install chatterbox-tts
```

Alternatively, you can install from source:
```shell
# conda create -yn chatterbox python=3.11
# conda activate chatterbox

git clone https://github.com/resemble-ai/chatterbox.git
cd chatterbox
pip install -e .
```
We developed and tested Chatterbox on Python 3.11 on Debian 11 OS; the versions of the dependencies are pinned in `pyproject.toml` to ensure consistency. You can modify the code or dependencies in this installation mode.

## Usage

##### Chatterbox-Turbo

```python
import torchaudio as ta
import torch
from chatterbox.tts_turbo import ChatterboxTurboTTS

# Load the Turbo model
model = ChatterboxTurboTTS.from_pretrained(device=&quot;cuda&quot;)

# Generate with Paralinguistic Tags
text = &quot;Hi there, Sarah here from MochaFone calling you back [chuckle], have you got one minute to chat about the billing issue?&quot;

# Generate audio (requires a reference clip for voice cloning)
wav = model.generate(text, audio_prompt_path=&quot;your_10s_ref_clip.wav&quot;)

ta.save(&quot;test-turbo.wav&quot;, wav, model.sr)
```

##### Chatterbox and Chatterbox-Multilingual

```python

import torchaudio as ta
from chatterbox.tts import ChatterboxTTS
from chatterbox.mtl_tts import ChatterboxMultilingualTTS

# English example
model = ChatterboxTTS.from_pretrained(device=&quot;cuda&quot;)

text = &quot;Ezreal and Jinx teamed up with Ahri, Yasuo, and Teemo to take down the enemy&#039;s Nexus in an epic late-game pentakill.&quot;
wav = model.generate(text)
ta.save(&quot;test-english.wav&quot;, wav, model.sr)

# Multilingual examples
multilingual_model = ChatterboxMultilingualTTS.from_pretrained(device=device)

french_text = &quot;Bonjour, comment √ßa va? Ceci est le mod√®le de synth√®se vocale multilingue Chatterbox, il prend en charge 23 langues.&quot;
wav_french = multilingual_model.generate(spanish_text, language_id=&quot;fr&quot;)
ta.save(&quot;test-french.wav&quot;, wav_french, model.sr)

chinese_text = &quot;‰Ω†Â•ΩÔºå‰ªäÂ§©Â§©Ê∞îÁúü‰∏çÈîôÔºåÂ∏åÊúõ‰Ω†Êúâ‰∏Ä‰∏™ÊÑâÂø´ÁöÑÂë®Êú´„ÄÇ&quot;
wav_chinese = multilingual_model.generate(chinese_text, language_id=&quot;zh&quot;)
ta.save(&quot;test-chinese.wav&quot;, wav_chinese, model.sr)

# If you want to synthesize with a different voice, specify the audio prompt
AUDIO_PROMPT_PATH = &quot;YOUR_FILE.wav&quot;
wav = model.generate(text, audio_prompt_path=AUDIO_PROMPT_PATH)
ta.save(&quot;test-2.wav&quot;, wav, model.sr)
```
See `example_tts.py` and `example_vc.py` for more examples.

## Supported Languages 
Arabic (ar) ‚Ä¢ Danish (da) ‚Ä¢ German (de) ‚Ä¢ Greek (el) ‚Ä¢ English (en) ‚Ä¢ Spanish (es) ‚Ä¢ Finnish (fi) ‚Ä¢ French (fr) ‚Ä¢ Hebrew (he) ‚Ä¢ Hindi (hi) ‚Ä¢ Italian (it) ‚Ä¢ Japanese (ja) ‚Ä¢ Korean (ko) ‚Ä¢ Malay (ms) ‚Ä¢ Dutch (nl) ‚Ä¢ Norwegian (no) ‚Ä¢ Polish (pl) ‚Ä¢ Portuguese (pt) ‚Ä¢ Russian (ru) ‚Ä¢ Swedish (sv) ‚Ä¢ Swahili (sw) ‚Ä¢ Turkish (tr) ‚Ä¢ Chinese (zh)

## Original Chatterbox Tips
- **General Use (TTS and Voice Agents):**
  - Ensure that the reference clip matches the specified language tag. Otherwise, language transfer outputs may inherit the accent of the reference clip‚Äôs language. To mitigate this, set `cfg_weight` to `0`.
  - The default settings (`exaggeration=0.5`, `cfg_weight=0.5`) work well for most prompts across all languages.
  - If the reference speaker has a fast speaking style, lowering `cfg_weight` to around `0.3` can improve pacing.

- **Expressive or Dramatic Speech:**
  - Try lower `cfg_weight` values (e.g. `~0.3`) and increase `exaggeration` to around `0.7` or higher.
  - Higher `exaggeration` tends to speed up speech; reducing `cfg_weight` helps compensate with slower, more deliberate pacing.


## Built-in PerTh Watermarking for Responsible AI

Every audio file generated by Chatterbox includes [Resemble AI&#039;s Perth (Perceptual Threshold) Watermarker](https://github.com/resemble-ai/perth) - imperceptible neural watermarks that survive MP3 compression, audio editing, and common manipulations while maintaining nearly 100% detection accuracy.


## Watermark extraction

You can look for the watermark using the following script.

```python
import perth
import librosa

AUDIO_PATH = &quot;YOUR_FILE.wav&quot;

# Load the watermarked audio
watermarked_audio, sr = librosa.load(AUDIO_PATH, sr=None)

# Initialize watermarker (same as used for embedding)
watermarker = perth.PerthImplicitWatermarker()

# Extract watermark
watermark = watermarker.get_watermark(watermarked_audio, sample_rate=sr)
print(f&quot;Extracted watermark: {watermark}&quot;)
# Output: 0.0 (no watermark) or 1.0 (watermarked)
```


## Official Discord

üëã Join us on [Discord](https://discord.gg/rJq9cRJBJ6) and let&#039;s build something awesome together!

## Acknowledgements
- [Cosyvoice](https://github.com/FunAudioLLM/CosyVoice)
- [Real-Time-Voice-Cloning](https://github.com/CorentinJ/Real-Time-Voice-Cloning)
- [HiFT-GAN](https://github.com/yl4579/HiFTNet)
- [Llama 3](https://github.com/meta-llama/llama3)
- [S3Tokenizer](https://github.com/xingchensong/S3Tokenizer)

## Citation
If you find this model useful, please consider citing.
```
@misc{chatterboxtts2025,
  author       = {{Resemble AI}},
  title        = {{Chatterbox-TTS}},
  year         = {2025},
  howpublished = {\url{https://github.com/resemble-ai/chatterbox}},
  note         = {GitHub repository}
}
```
## Disclaimer
Don&#039;t use this model to do bad things. Prompts are sourced from freely available data on the internet.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[alexta69/metube]]></title>
            <link>https://github.com/alexta69/metube</link>
            <guid>https://github.com/alexta69/metube</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:35 GMT</pubDate>
            <description><![CDATA[Self-hosted YouTube downloader (web UI for youtube-dl / yt-dlp)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/alexta69/metube">alexta69/metube</a></h1>
            <p>Self-hosted YouTube downloader (web UI for youtube-dl / yt-dlp)</p>
            <p>Language: Python</p>
            <p>Stars: 11,545</p>
            <p>Forks: 781</p>
            <p>Stars today: 68 stars today</p>
            <h2>README</h2><pre># MeTube

![Build Status](https://github.com/alexta69/metube/actions/workflows/main.yml/badge.svg)
![Docker Pulls](https://img.shields.io/docker/pulls/alexta69/metube.svg)

Web GUI for youtube-dl (using the [yt-dlp](https://github.com/yt-dlp/yt-dlp) fork) with playlist support. Allows you to download videos from YouTube and [dozens of other sites](https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md).

![screenshot1](https://github.com/alexta69/metube/raw/master/screenshot.gif)

## üê≥ Run using Docker

```bash
docker run -d -p 8081:8081 -v /path/to/downloads:/downloads ghcr.io/alexta69/metube
```

## üê≥ Run using docker-compose

```yaml
services:
  metube:
    image: ghcr.io/alexta69/metube
    container_name: metube
    restart: unless-stopped
    ports:
      - &quot;8081:8081&quot;
    volumes:
      - /path/to/downloads:/downloads
```

## ‚öôÔ∏è Configuration via environment variables

Certain values can be set via environment variables, using the `-e` parameter on the docker command line, or the `environment:` section in docker-compose.

### ‚¨áÔ∏è Download Behavior

* __DOWNLOAD_MODE__: This flag controls how downloads are scheduled and executed. Options are `sequential`, `concurrent`, and `limited`.  Defaults to `limited`:
    *   `sequential`: Downloads are processed one at a time. A new download won&#039;t start until the previous one has finished. This mode is useful for conserving system resources or ensuring downloads occur in strict order.
    *   `concurrent`: Downloads are started immediately as they are added, with no built-in limit on how many run simultaneously. This mode may overwhelm your system if too many downloads start at once.
    *   `limited`: Downloads are started concurrently but are capped by a concurrency limit. In this mode, a semaphore is used so that at most a fixed number of downloads run at any given time.
* __MAX_CONCURRENT_DOWNLOADS__: This flag is used only when `DOWNLOAD_MODE` is set to `limited`.  
    It specifies the maximum number of simultaneous downloads allowed. For example, if set to `5`, then at most five downloads will run concurrently, and any additional downloads will wait until one of the active downloads completes. Defaults to `3`. 
* __DELETE_FILE_ON_TRASHCAN__: if `true`, downloaded files are deleted on the server, when they are trashed from the &quot;Completed&quot; section of the UI. Defaults to `false`.
* __DEFAULT_OPTION_PLAYLIST_STRICT_MODE__: if `true`, the &quot;Strict Playlist mode&quot; switch will be enabled by default. In this mode the playlists will be downloaded only if the URL strictly points to a playlist. URLs to videos inside a playlist will be treated same as direct video URL. Defaults to `false` .
* __DEFAULT_OPTION_PLAYLIST_ITEM_LIMIT__: Maximum number of playlist items that can be downloaded. Defaults to `0` (no limit).

### üìÅ Storage &amp; Directories

* __DOWNLOAD_DIR__: Path to where the downloads will be saved. Defaults to `/downloads` in the Docker image, and `.` otherwise.
* __AUDIO_DOWNLOAD_DIR__: Path to where audio-only downloads will be saved, if you wish to separate them from the video downloads. Defaults to the value of `DOWNLOAD_DIR`.
* __CUSTOM_DIRS__: Whether to enable downloading videos into custom directories within the __DOWNLOAD_DIR__ (or __AUDIO_DOWNLOAD_DIR__). When enabled, a dropdown appears next to the Add button to specify the download directory. Defaults to `true`.
* __CREATE_CUSTOM_DIRS__: Whether to support automatically creating directories within the __DOWNLOAD_DIR__ (or __AUDIO_DOWNLOAD_DIR__) if they do not exist. When enabled, the download directory selector supports free-text input, and the specified directory will be created recursively. Defaults to `true`.
* __CUSTOM_DIRS_EXCLUDE_REGEX__: Regular expression to exclude some custom directories from the dropdown. Empty regex disables exclusion. Defaults to `(^|/)[.@].*$`, which means directories starting with `.` or `@`.
* __DOWNLOAD_DIRS_INDEXABLE__: If `true`, the download directories (__DOWNLOAD_DIR__ and __AUDIO_DOWNLOAD_DIR__) are indexable on the web server. Defaults to `false`.
* __STATE_DIR__: Path to where the queue persistence files will be saved. Defaults to `/downloads/.metube` in the Docker image, and `.` otherwise.
* __TEMP_DIR__: Path where intermediary download files will be saved. Defaults to `/downloads` in the Docker image, and `.` otherwise.
  * Set this to an SSD or RAM filesystem (e.g., `tmpfs`) for better performance.
  * __Note__: Using a RAM filesystem may prevent downloads from being resumed.

### üìù File Naming &amp; yt-dlp

* __OUTPUT_TEMPLATE__: The template for the filenames of the downloaded videos, formatted according to [this spec](https://github.com/yt-dlp/yt-dlp/blob/master/README.md#output-template). Defaults to `%(title)s.%(ext)s`.
* __OUTPUT_TEMPLATE_CHAPTER__: The template for the filenames of the downloaded videos when split into chapters via postprocessors. Defaults to `%(title)s - %(section_number)s %(section_title)s.%(ext)s`.
* __OUTPUT_TEMPLATE_PLAYLIST__: The template for the filenames of the downloaded videos when downloaded as a playlist. Defaults to `%(playlist_title)s/%(title)s.%(ext)s`. When empty, then `OUTPUT_TEMPLATE` is used.
* __YTDL_OPTIONS__: Additional options to pass to yt-dlp in JSON format. [See available options here](https://github.com/yt-dlp/yt-dlp/blob/master/yt_dlp/YoutubeDL.py#L222). They roughly correspond to command-line options, though some do not have exact equivalents here. For example, `--recode-video` has to be specified via `postprocessors`. Also note that dashes are replaced with underscores. You may find [this script](https://github.com/yt-dlp/yt-dlp/blob/master/devscripts/cli_to_api.py) helpful for converting from command-line options to `YTDL_OPTIONS`.
* __YTDL_OPTIONS_FILE__: A path to a JSON file that will be loaded and used for populating `YTDL_OPTIONS` above. Please note that if both `YTDL_OPTIONS_FILE` and `YTDL_OPTIONS` are specified, the options in `YTDL_OPTIONS` take precedence. The file will be monitored for changes and reloaded automatically when changes are detected.

### üåê Web Server &amp; URLs

* __URL_PREFIX__: Base path for the web server (for use when hosting behind a reverse proxy). Defaults to `/`.
* __PUBLIC_HOST_URL__: Base URL for the download links shown in the UI for completed files. By default, MeTube serves them under its own URL. If your download directory is accessible on another URL and you want the download links to be based there, use this variable to set it.
* __PUBLIC_HOST_AUDIO_URL__: Same as PUBLIC_HOST_URL but for audio downloads.
* __HTTPS__: Use `https` instead of `http` (__CERTFILE__ and __KEYFILE__ required). Defaults to `false`.
* __CERTFILE__: HTTPS certificate file path.
* __KEYFILE__: HTTPS key file path.
* __ROBOTS_TXT__: A path to a `robots.txt` file mounted in the container.

### üè† Basic Setup

* __UID__: User under which MeTube will run. Defaults to `1000`.
* __GID__: Group under which MeTube will run. Defaults to `1000`.
* __UMASK__: Umask value used by MeTube. Defaults to `022`.
* __DEFAULT_THEME__: Default theme to use for the UI, can be set to `light`, `dark`, or `auto`. Defaults to `auto`.
* __LOGLEVEL__: Log level, can be set to `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`, or `NONE`. Defaults to `INFO`. 
* __ENABLE_ACCESSLOG__: Whether to enable access log. Defaults to `false`.

The project&#039;s Wiki contains examples of useful configurations contributed by users of MeTube:
* [YTDL_OPTIONS Cookbook](https://github.com/alexta69/metube/wiki/YTDL_OPTIONS-Cookbook)
* [OUTPUT_TEMPLATE Cookbook](https://github.com/alexta69/metube/wiki/OUTPUT_TEMPLATE-Cookbook)

## üç™ Using browser cookies

In case you need to use your browser&#039;s cookies with MeTube, for example to download restricted or private videos:

* Add the following to your docker-compose.yml:

```yaml
    volumes:
      - /path/to/cookies:/cookies
    environment:
      - YTDL_OPTIONS={&quot;cookiefile&quot;:&quot;/cookies/cookies.txt&quot;}
```

* Install in your browser an extension to extract cookies:
  * [Firefox](https://addons.mozilla.org/en-US/firefox/addon/export-cookies-txt/)
  * [Chrome](https://chrome.google.com/webstore/detail/get-cookiestxt-locally/cclelndahbckbenkjhflpdbgdldlbecc)
* Extract the cookies you need with the extension and rename the file `cookies.txt`
* Drop the file in the folder you configured in the docker-compose.yml above
* Restart the container

## üîå Browser extensions

Browser extensions allow right-clicking videos and sending them directly to MeTube. Please note that if you&#039;re on an HTTPS page, your MeTube instance must be behind an HTTPS reverse proxy (see below) for the extensions to work.

__Chrome:__ contributed by [Rpsl](https://github.com/rpsl). You can install it from [Google Chrome Webstore](https://chrome.google.com/webstore/detail/metube-downloader/fbmkmdnlhacefjljljlbhkodfmfkijdh) or use developer mode and install [from sources](https://github.com/Rpsl/metube-browser-extension).

__Firefox:__ contributed by [nanocortex](https://github.com/nanocortex). You can install it from [Firefox Addons](https://addons.mozilla.org/en-US/firefox/addon/metube-downloader) or get sources from [here](https://github.com/nanocortex/metube-firefox-addon).

## üì± iOS Shortcut

[rithask](https://github.com/rithask) created an iOS shortcut to send URLs to MeTube from Safari. Enter the MeTube instance address when prompted which will be saved for later use. You can run the shortcut from Safari‚Äôs share menu. The shortcut can be downloaded from [this iCloud link](https://www.icloud.com/shortcuts/66627a9f334c467baabdb2769763a1a6).

## üì± iOS Compatibility

iOS has strict requirements for video files, requiring h264 or h265 video codec and aac audio codec in MP4 container. This can sometimes be a lower quality than the best quality available. To accommodate iOS requirements, when downloading a MP4 format you can choose &quot;Best (iOS)&quot; to get the best quality formats as compatible as possible with iOS requirements.

To force all downloads to be converted to an iOS-compatible codec, insert this as an environment variable: 

```yaml
  environment:
    - &#039;YTDL_OPTIONS={&quot;format&quot;: &quot;best&quot;, &quot;exec&quot;: &quot;ffmpeg -i %(filepath)q -c:v libx264 -c:a aac %(filepath)q.h264.mp4&quot;}&#039;
```

## üîñ Bookmarklet

[kushfest](https://github.com/kushfest) has created a Chrome bookmarklet for sending the currently open webpage to MeTube. Please note that if you&#039;re on an HTTPS page, your MeTube instance must be configured with `HTTPS` as `true` in the environment, or be behind an HTTPS reverse proxy (see below) for the bookmarklet to work.

GitHub doesn&#039;t allow embedding JavaScript as a link, so the bookmarklet has to be created manually by copying the following code to a new bookmark you create on your bookmarks bar. Change the hostname in the URL below to point to your MeTube instance.

```javascript
javascript:!function(){xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.withCredentials=true;xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function(){if(xhr.status==200){alert(&quot;Sent to metube!&quot;)}else{alert(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}}();
```

[shoonya75](https://github.com/shoonya75) has contributed a Firefox version:

```javascript
javascript:(function(){xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function(){if(xhr.status==200){alert(&quot;Sent to metube!&quot;)}else{alert(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}})();
```

The above bookmarklets use `alert()` as a success/failure notification. The following will show a toast message instead:

Chrome:

```javascript
javascript:!function(){function notify(msg) {var sc = document.scrollingElement.scrollTop; var text = document.createElement(&#039;span&#039;);text.innerHTML=msg;var ts = text.style;ts.all = &#039;revert&#039;;ts.color = &#039;#000&#039;;ts.fontFamily = &#039;Verdana, sans-serif&#039;;ts.fontSize = &#039;15px&#039;;ts.backgroundColor = &#039;white&#039;;ts.padding = &#039;15px&#039;;ts.border = &#039;1px solid gainsboro&#039;;ts.boxShadow = &#039;3px 3px 10px&#039;;ts.zIndex = &#039;100&#039;;document.body.appendChild(text);ts.position = &#039;absolute&#039;; ts.top = 50 + sc + &#039;px&#039;; ts.left = (window.innerWidth / 2)-(text.offsetWidth / 2) + &#039;px&#039;; setTimeout(function () { text.style.visibility = &quot;hidden&quot;; }, 1500);}xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function() { if(xhr.status==200){notify(&quot;Sent to metube!&quot;)}else {notify(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}}();
```

Firefox:

```javascript
javascript:(function(){function notify(msg) {var sc = document.scrollingElement.scrollTop; var text = document.createElement(&#039;span&#039;);text.innerHTML=msg;var ts = text.style;ts.all = &#039;revert&#039;;ts.color = &#039;#000&#039;;ts.fontFamily = &#039;Verdana, sans-serif&#039;;ts.fontSize = &#039;15px&#039;;ts.backgroundColor = &#039;white&#039;;ts.padding = &#039;15px&#039;;ts.border = &#039;1px solid gainsboro&#039;;ts.boxShadow = &#039;3px 3px 10px&#039;;ts.zIndex = &#039;100&#039;;document.body.appendChild(text);ts.position = &#039;absolute&#039;; ts.top = 50 + sc + &#039;px&#039;; ts.left = (window.innerWidth / 2)-(text.offsetWidth / 2) + &#039;px&#039;; setTimeout(function () { text.style.visibility = &quot;hidden&quot;; }, 1500);}xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function() { if(xhr.status==200){notify(&quot;Sent to metube!&quot;)}else {notify(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}})();
```

## ‚ö° Raycast extension

[dotvhs](https://github.com/dotvhs) has created an [extension for Raycast](https://www.raycast.com/dot/metube) that allows adding videos to MeTube directly from Raycast.

## üîí HTTPS support, and running behind a reverse proxy

It&#039;s possible to configure MeTube to listen in HTTPS mode. `docker-compose` example:

```yaml
services:
  metube:
    image: ghcr.io/alexta69/metube
    container_name: metube
    restart: unless-stopped
    ports:
      - &quot;8081:8081&quot;
    volumes:
      - /path/to/downloads:/downloads
      - /path/to/ssl/crt:/ssl/crt.pem
      - /path/to/ssl/key:/ssl/key.pem
    environment:
      - HTTPS=true
      - CERTFILE=/ssl/crt.pem
      - KEYFILE=/ssl/key.pem
```

It&#039;s also possible to run MeTube behind a reverse proxy, in order to support authentication. HTTPS support can also be added in this way.

When running behind a reverse proxy which remaps the URL (i.e. serves MeTube under a subdirectory and not under root), don&#039;t forget to set the URL_PREFIX environment variable to the correct value.

If you&#039;re using the [linuxserver/swag](https://docs.linuxserver.io/general/swag) image for your reverse proxying needs (which I can heartily recommend), it already includes ready snippets for proxying MeTube both in [subfolder](https://github.com/linuxserver/reverse-proxy-confs/blob/master/metube.subfolder.conf.sample) and [subdomain](https://github.com/linuxserver/reverse-proxy-confs/blob/master/metube.subdomain.conf.sample) modes under the `nginx/proxy-confs` directory in the configuration volume. It also includes Authelia which can be used for authentication.

### üåê NGINX

```nginx
location /metube/ {
        proxy_pass http://metube:8081;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection &quot;upgrade&quot;;
        proxy_set_header Host $host;
}
```

Note: the extra `proxy_set_header` directives are there to make WebSocket work.

### üåê Apache

Contributed by [PIE-yt](https://github.com/PIE-yt). Source [here](https://gist.github.com/PIE-yt/29e7116588379032427f5bd446b2cac4).

```apache
# For putting in your Apache sites site.conf
# Serves MeTube under a /metube/ subdir (http://yourdomain.com/metube/)
&lt;Location /metube/&gt;
    ProxyPass http://localhost:8081/ retry=0 timeout=30
    ProxyPassReverse http://localhost:8081/
&lt;/Location&gt;

&lt;Location /metube/socket.io&gt;
    RewriteEngine On
    RewriteCond %{QUERY_STRING} transport=websocket    [NC]
    RewriteRule /(.*) ws://localhost:8081/socket.io/$1 [P,L]
    ProxyPass http://localhost:8081/socket.io retry=0 timeout=30
    ProxyPassReverse http://localhost:8081/socket.io
&lt;/Location&gt;
```

### üåê Caddy

The following example Caddyfile gets a reverse proxy going behind [caddy](https://caddyserver.com).

```caddyfile
example.com {
  route /metube/* {
    uri strip_prefix metube
    reverse_proxy metube:8081
  }
}
```

## üîÑ Updating yt-dlp

The engine which powers the actual video downloads in MeTube is [yt-dlp](https://github.com/yt-dlp/yt-dlp). Since video sites regularly change their layouts, frequent updates of yt-dlp are required to keep up.

There&#039;s an automatic nightly build of MeTube which looks for a new version of yt-dlp, and if one exists, the build pulls it and publishes an updated docker image. Therefore, in order to keep up with the changes, it&#039;s recommended that you update your MeTube container regularly with the latest image.

I recommend installing and setting up [watchtower](https://github.com/nicholas-fedor/watchtower) for this purpose.

## üîß Troubleshooting and submitting issues

Before asking a question or submitting an issue for MeTube, please remember that MeTube is only a UI for [yt-dlp](https://github.com/yt-dlp/yt-dlp). Any issues you might be experiencing with authentication to video websites, postprocessing, permissions, other `YTDL_OPTIONS` configurations which seem not to work, or anything else that concerns the workings of the underlying yt-dlp library, need not be opened on the MeTube project. In order to debug and troubleshoot them, it&#039;s advised to try using the yt-dlp binary directly first, bypassing the UI, and once that is working, importing the options that worked for you into `YTDL_OPTIONS`.

In order to test with the yt-dlp command directly, you can either download it and run it locally, or for a better simulation of its actual conditions, you can run it within the MeTube container itself. Assuming your MeTube container is called `metube`, run the following on your Docker host to get a shell inside the container:

```bash
docker exec -ti metube sh
cd /downloads
```

Once there, you can use the yt-dlp command freely.

## üí° Submitting feature requests

MeTube development relies on code contributions by the community. The program as it currently stands fits my own use cases, and is therefore feature-complete as far as I&#039;m concerned. If your use cases are different and require additional features, please feel free to submit PRs that implement those features. It&#039;s advisable to create an issue first to discuss the planned implementation, because in an effort to reduce bloat, some PRs may not be accepted. However, note that opening a feature request when you don&#039;t intend to implement the feature will rarely result in the request being fulfilled.

## üõ†Ô∏è Building and running locally

Make sure you have Node.js 22+ and Python 3.13 installed.

```bash
cd metube/ui
# install Angular and build the UI
pnpm install
pnpm run build
# install python dependencies
cd ..
curl -LsSf https://astral.sh/uv/install.sh | sh
uv sync
# run
uv run python3 app/main.py
```

A Docker image can be built locally (it will build the UI too):

```bash
docker build -t metube .
```

Note that if you&#039;re running the server in VSCode, your downloads will go to your user&#039;s Downloads folder (this is configured via the environment in `.vscode/launch.json`).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[anthropics/skills]]></title>
            <link>https://github.com/anthropics/skills</link>
            <guid>https://github.com/anthropics/skills</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[Public repository for Agent Skills]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anthropics/skills">anthropics/skills</a></h1>
            <p>Public repository for Agent Skills</p>
            <p>Language: Python</p>
            <p>Stars: 30,167</p>
            <p>Forks: 2,756</p>
            <p>Stars today: 971 stars today</p>
            <h2>README</h2><pre>&gt; **Note:** This repository contains Anthropic&#039;s implementation of skills for Claude. For information about the Agent Skills standard, see [agentskills.io](http://agentskills.io).

# Skills
Skills are folders of instructions, scripts, and resources that Claude loads dynamically to improve performance on specialized tasks. Skills teach Claude how to complete specific tasks in a repeatable way, whether that&#039;s creating documents with your company&#039;s brand guidelines, analyzing data using your organization&#039;s specific workflows, or automating personal tasks.

For more information, check out:
- [What are skills?](https://support.claude.com/en/articles/12512176-what-are-skills)
- [Using skills in Claude](https://support.claude.com/en/articles/12512180-using-skills-in-claude)
- [How to create custom skills](https://support.claude.com/en/articles/12512198-creating-custom-skills)
- [Equipping agents for the real world with Agent Skills](https://anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills)

# About This Repository

This repository contains skills that demonstrate what&#039;s possible with Claude&#039;s skills system. These skills range from creative applications (art, music, design) to technical tasks (testing web apps, MCP server generation) to enterprise workflows (communications, branding, etc.).

Each skill is self-contained in its own folder with a `SKILL.md` file containing the instructions and metadata that Claude uses. Browse through these skills to get inspiration for your own skills or to understand different patterns and approaches.

Many skills in this repo are open source (Apache 2.0). We&#039;ve also included the document creation &amp; editing skills that power [Claude&#039;s document capabilities](https://www.anthropic.com/news/create-files) under the hood in the [`skills/docx`](./skills/docx), [`skills/pdf`](./skills/pdf), [`skills/pptx`](./skills/pptx), and [`skills/xlsx`](./skills/xlsx) subfolders. These are source-available, not open source, but we wanted to share these with developers as a reference for more complex skills that are actively used in a production AI application.

## Disclaimer

**These skills are provided for demonstration and educational purposes only.** While some of these capabilities may be available in Claude, the implementations and behaviors you receive from Claude may differ from what is shown in these skills. These skills are meant to illustrate patterns and possibilities. Always test skills thoroughly in your own environment before relying on them for critical tasks.

# Skill Sets
- [./skills](./skills): Skill examples for Creative &amp; Design, Development &amp; Technical, Enterprise &amp; Communication, and Document Skills
- [./spec](./spec): The Agent Skills specification
- [./template](./template): Skill template

# Try in Claude Code, Claude.ai, and the API

## Claude Code
You can register this repository as a Claude Code Plugin marketplace by running the following command in Claude Code:
```
/plugin marketplace add anthropics/skills
```

Then, to install a specific set of skills:
1. Select `Browse and install plugins`
2. Select `anthropic-agent-skills`
3. Select `document-skills` or `example-skills`
4. Select `Install now`

Alternatively, directly install either Plugin via:
```
/plugin install document-skills@anthropic-agent-skills
/plugin install example-skills@anthropic-agent-skills
```

After installing the plugin, you can use the skill by just mentioning it. For instance, if you install the `document-skills` plugin from the marketplace, you can ask Claude Code to do something like: &quot;Use the PDF skill to extract the form fields from `path/to/some-file.pdf`&quot;

## Claude.ai

These example skills are all already available to paid plans in Claude.ai. 

To use any skill from this repository or upload custom skills, follow the instructions in [Using skills in Claude](https://support.claude.com/en/articles/12512180-using-skills-in-claude#h_a4222fa77b).

## Claude API

You can use Anthropic&#039;s pre-built skills, and upload custom skills, via the Claude API. See the [Skills API Quickstart](https://docs.claude.com/en/api/skills-guide#creating-a-skill) for more.

# Creating a Basic Skill

Skills are simple to create - just a folder with a `SKILL.md` file containing YAML frontmatter and instructions. You can use the **template-skill** in this repository as a starting point:

```markdown
---
name: my-skill-name
description: A clear description of what this skill does and when to use it
---

# My Skill Name

[Add your instructions here that Claude will follow when this skill is active]

## Examples
- Example usage 1
- Example usage 2

## Guidelines
- Guideline 1
- Guideline 2
```

The frontmatter requires only two fields:
- `name` - A unique identifier for your skill (lowercase, hyphens for spaces)
- `description` - A complete description of what the skill does and when to use it

The markdown content below contains the instructions, examples, and guidelines that Claude will follow. For more details, see [How to create custom skills](https://support.claude.com/en/articles/12512198-creating-custom-skills).

# Partner Skills

Skills are a great way to teach Claude how to get better at using specific pieces of software. As we see awesome example skills from partners, we may highlight some of them here:

- **Notion** - [Notion Skills for Claude](https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Shubhamsaboo/awesome-llm-apps]]></title>
            <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
            <guid>https://github.com/Shubhamsaboo/awesome-llm-apps</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Shubhamsaboo/awesome-llm-apps">Shubhamsaboo/awesome-llm-apps</a></h1>
            <p>Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.</p>
            <p>Language: Python</p>
            <p>Stars: 85,517</p>
            <p>Forks: 12,150</p>
            <p>Stars today: 312 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;http://www.theunwindai.com&quot;&gt;
    &lt;img src=&quot;docs/banner/unwind_black.png&quot; width=&quot;900px&quot; alt=&quot;Unwind AI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.linkedin.com/in/shubhamsaboo/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;style=flat-square&quot; alt=&quot;LinkedIn&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/Saboo_Shubham_&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/Shubham_Saboo&quot; alt=&quot;Twitter&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de&quot;&gt;Deutsch&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es&quot;&gt;Espa√±ol&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr&quot;&gt;fran√ßais&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt&quot;&gt;Portugu√™s&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh&quot;&gt;‰∏≠Êñá&lt;/a&gt;
&lt;/p&gt;

&lt;hr/&gt;

# üåü Awesome LLM Apps

A curated collection of **Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.** This repository features LLM apps that use models from &lt;img src=&quot;https://cdn.simpleicons.org/openai&quot;  alt=&quot;openai logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**OpenAI** , &lt;img src=&quot;https://cdn.simpleicons.org/anthropic&quot;  alt=&quot;anthropic logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Anthropic**, &lt;img src=&quot;https://cdn.simpleicons.org/googlegemini&quot;  alt=&quot;google logo&quot; width=&quot;25&quot; height=&quot;18&quot;&gt;**Google**, &lt;img src=&quot;https://cdn.simpleicons.org/x&quot;  alt=&quot;X logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**xAI** and open-source models like &lt;img src=&quot;https://cdn.simpleicons.org/alibabacloud&quot;  alt=&quot;alibaba logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Qwen** or  &lt;img src=&quot;https://cdn.simpleicons.org/meta&quot;  alt=&quot;meta logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Llama** that you can run locally on your computer.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/9876&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/9876&quot; alt=&quot;Shubhamsaboo%2Fawesome-llm-apps | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## ü§î Why Awesome LLM Apps?

- üí° Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.
- üî• Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp; RAG.
- üéì Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.

## üôè Thanks to our sponsors

&lt;table align=&quot;center&quot; cellpadding=&quot;16&quot; cellspacing=&quot;12&quot;&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://tsdb.co/shubham-gh&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;Tiger Data&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsors/tigerdata.png&quot; alt=&quot;Tiger Data&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://tsdb.co/shubham-gh&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Tiger Data MCP
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://github.com/speechmatics/speechmatics-academy&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;Speechmatics&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsors/speechmatics.png&quot; alt=&quot;Speechmatics&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://github.com/speechmatics/speechmatics-academy&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Speechmatics
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://okara.ai/?utm_source=oss&amp;utm_medium=sponsorship&amp;utm_campaign=awesome-llm-apps&quot; title=&quot;Okara&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsors/okara.png&quot; alt=&quot;Okara&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://okara.ai/?utm_source=oss&amp;utm_medium=sponsorship&amp;utm_campaign=awesome-llm-apps&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Okara AI
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://sponsorunwindai.com/&quot; title=&quot;Become a Sponsor&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsor_awesome_llm_apps.png&quot; alt=&quot;Become a Sponsor&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://sponsorunwindai.com/&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Become a Sponsor
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## üìÇ Featured AI Projects

### AI Agents

### üå± Starter AI Agents

*   [üéôÔ∏è AI Blog to Podcast Agent](starter_ai_agents/ai_blog_to_podcast_agent/)
*   [‚ù§Ô∏è‚Äçü©π AI Breakup Recovery Agent](starter_ai_agents/ai_breakup_recovery_agent/)
*   [üìä AI Data Analysis Agent](starter_ai_agents/ai_data_analysis_agent/)
*   [ü©ª AI Medical Imaging Agent](starter_ai_agents/ai_medical_imaging_agent/)
*   [üòÇ AI Meme Generator Agent (Browser)](starter_ai_agents/ai_meme_generator_agent_browseruse/)
*   [üéµ AI Music Generator Agent](starter_ai_agents/ai_music_generator_agent/)
*   [üõ´ AI Travel Agent (Local &amp; Cloud)](starter_ai_agents/ai_travel_agent/)
*   [‚ú® Gemini Multimodal Agent](starter_ai_agents/gemini_multimodal_agent_demo/)
*   [üîÑ Mixture of Agents](starter_ai_agents/mixture_of_agents/)
*   [üìä xAI Finance Agent](starter_ai_agents/xai_finance_agent/)
*   [üîç OpenAI Research Agent](starter_ai_agents/opeani_research_agent/)
*   [üï∏Ô∏è Web Scraping AI Agent (Local &amp; Cloud SDK)](starter_ai_agents/web_scrapping_ai_agent/)

### üöÄ Advanced AI Agents
*   [üèöÔ∏è üçå AI Home Renovation Agent with Nano Banana](advanced_ai_agents/multi_agent_apps/ai_home_renovation_agent)
*   [üîç AI Deep Research Agent](advanced_ai_agents/single_agent_apps/ai_deep_research_agent/)
*   [ü§ù AI Consultant Agent](advanced_ai_agents/single_agent_apps/ai_consultant_agent)
*   [üèóÔ∏è AI System Architect Agent](advanced_ai_agents/single_agent_apps/ai_system_architect_r1/)
*   [üí∞ AI Financial Coach Agent](advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/)
*   [üé¨ AI Movie Production Agent](advanced_ai_agents/single_agent_apps/ai_movie_production_agent/)
*   [üìà AI Investment Agent](advanced_ai_agents/single_agent_apps/ai_investment_agent/)
*   [üèãÔ∏è‚Äç‚ôÇÔ∏è AI Health &amp; Fitness Agent](advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/)
*   [üöÄ AI Product Launch Intelligence Agent](advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent)
*   [üóûÔ∏è AI Journalist Agent](advanced_ai_agents/single_agent_apps/ai_journalist_agent/)
*   [üß† AI Mental Wellbeing Agent](advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/)
*   [üìë AI Meeting Agent](advanced_ai_agents/single_agent_apps/ai_meeting_agent/)
*   [üß¨ AI Self-Evolving Agent](advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/)
*   [üéß AI Social Media News and Podcast Agent](advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/)

### üéÆ Autonomous Game Playing Agents

*   [üéÆ AI 3D Pygame Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/)
*   [‚ôú AI Chess Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/)
*   [üé≤ AI Tic-Tac-Toe Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/)

### ü§ù Multi-agent Teams

*   [üß≤ AI Competitor Intelligence Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/)
*   [üí≤ AI Finance Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/)
*   [üé® AI Game Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/)
*   [üë®‚Äç‚öñÔ∏è AI Legal Agent Team (Cloud &amp; Local)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/)
*   [üíº AI Recruitment Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/)
*   [üè† AI Real Estate Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team)
*   [üë®‚Äçüíº AI Services Agency (CrewAI)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/)
*   [üë®‚Äçüè´ AI Teaching Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/)
*   [üíª Multimodal Coding Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/)
*   [‚ú® Multimodal Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/)
*   [üé® üçå Multimodal UI/UX Feedback Agent Team with Nano Banana](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_uiux_feedback_agent_team/)
*   [üåè AI Travel Planner Agent Team](/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/)

### üó£Ô∏è Voice AI Agents

*   [üó£Ô∏è AI Audio Tour Agent](voice_ai_agents/ai_audio_tour_agent/)
*   [üìû Customer Support Voice Agent](voice_ai_agents/customer_support_voice_agent/)
*   [üîä Voice RAG Agent (OpenAI SDK)](voice_ai_agents/voice_rag_openaisdk/)


### &lt;img src=&quot;https://cdn.simpleicons.org/modelcontextprotocol&quot;  alt=&quot;mcp logo&quot; width=&quot;25&quot; height=&quot;20&quot;&gt; MCP AI Agents 

*   [‚ôæÔ∏è Browser MCP Agent](mcp_ai_agents/browser_mcp_agent/)
*   [üêô GitHub MCP Agent](mcp_ai_agents/github_mcp_agent/)
*   [üìë Notion MCP Agent](mcp_ai_agents/notion_mcp_agent) 
*   [üåç AI Travel Planner MCP Agent](mcp_ai_agents/ai_travel_planner_mcp_agent_team)

### üìÄ RAG (Retrieval Augmented Generation)
*   [üî• Agentic RAG with Embedding Gemma](rag_tutorials/agentic_rag_embedding_gemma)
*   [üßê Agentic RAG with Reasoning](rag_tutorials/agentic_rag_with_reasoning/)
*   [üì∞ AI Blog Search (RAG)](rag_tutorials/ai_blog_search/)
*   [üîç Autonomous RAG](rag_tutorials/autonomous_rag/)
*   [üîÑ Contextual AI RAG Agent](rag_tutorials/contextualai_rag_agent/)
*   [üîÑ Corrective RAG (CRAG)](rag_tutorials/corrective_rag/)
*   [üêã Deepseek Local RAG Agent](rag_tutorials/deepseek_local_rag_agent/)
*   [ü§î Gemini Agentic RAG](rag_tutorials/gemini_agentic_rag/)
*   [üëÄ Hybrid Search RAG (Cloud)](rag_tutorials/hybrid_search_rag/)
*   [üîÑ Llama 3.1 Local RAG](rag_tutorials/llama3.1_local_rag/)
*   [üñ•Ô∏è Local Hybrid Search RAG](rag_tutorials/local_hybrid_search_rag/)
*   [ü¶ô Local RAG Agent](rag_tutorials/local_rag_agent/)
*   [üß© RAG-as-a-Service](rag_tutorials/rag-as-a-service/)
*   [‚ú® RAG Agent with Cohere](rag_tutorials/rag_agent_cohere/)
*   [‚õìÔ∏è Basic RAG Chain](rag_tutorials/rag_chain/)
*   [üì† RAG with Database Routing](rag_tutorials/rag_database_routing/)
*   [üñºÔ∏è Vision RAG](rag_tutorials/vision_rag/)

### üíæ LLM Apps with Memory Tutorials

*   [üíæ AI ArXiv Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/)
*   [üõ©Ô∏è AI Travel Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/)
*   [üí¨ Llama3 Stateful Chat](advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/)
*   [üìù LLM App with Personalized Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/)
*   [üóÑÔ∏è Local ChatGPT Clone with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/)
*   [üß† Multi-LLM Application with Shared Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/)


### üí¨ Chat with X Tutorials

*   [üí¨ Chat with GitHub (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_github/)
*   [üì® Chat with Gmail](advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/)
*   [üìÑ Chat with PDF (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/)
*   [üìö Chat with Research Papers (ArXiv) (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/)
*   [üìù Chat with Substack](advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/)
*   [üìΩÔ∏è Chat with YouTube Videos](advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/)

### üéØ LLM Optimization Tools

*   [üéØ Toonify Token Optimization](advanced_llm_apps/llm_optimization_tools/toonify_token_optimization/) - Reduce LLM API costs by 30-60% using TOON format

### üîß LLM Fine-tuning Tutorials

* &lt;img src=&quot;https://cdn.simpleicons.org/google&quot;  alt=&quot;google logo&quot; width=&quot;20&quot; height=&quot;15&quot;&gt; [Gemma 3 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/gemma3_finetuning/)
* &lt;img src=&quot;https://cdn.simpleicons.org/meta&quot;  alt=&quot;meta logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [Llama 3.2 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/)


### üßë‚Äçüè´ AI Agent Framework Crash Course

&lt;img src=&quot;https://cdn.simpleicons.org/google&quot;  alt=&quot;google logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [Google ADK Crash Course](ai_agent_framework_crash_course/google_adk_crash_course/)
  - Starter agent; model‚Äëagnostic (OpenAI, Claude)
  - Structured outputs (Pydantic)
  - Tools: built‚Äëin, function, third‚Äëparty, MCP tools
  - Memory; callbacks; Plugins
  - Simple multi‚Äëagent; Multi‚Äëagent patterns

&lt;img src=&quot;https://cdn.simpleicons.org/openai&quot;  alt=&quot;openai logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [OpenAI Agents SDK Crash Course](ai_agent_framework_crash_course/openai_sdk_crash_course/)
  - Starter agent; function calling; structured outputs
  - Tools: built‚Äëin, function, third‚Äëparty integrations
  - Memory; callbacks; evaluation
  - Multi‚Äëagent patterns; agent handoffs
  - Swarm orchestration; routing logic

## üöÄ Getting Started

1. **Clone the repository** 

    ```bash 
    git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
    ```

2. **Navigate to the desired project directory**

    ```bash 
    cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
    ```

3. **Install the required dependencies**

    ```bash
    pip install -r requirements.txt
    ```

4. **Follow the project-specific instructions** in each project&#039;s `README.md` file to set up and run the app.


### &lt;img src=&quot;https://cdn.simpleicons.org/github&quot;  alt=&quot;github logo&quot; width=&quot;25&quot; height=&quot;20&quot;&gt; Thank You, Community, for the Support! üôè

[![Star History Chart](https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;type=Date)](https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;Date)

üåü **Don‚Äôt miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.**
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[kijai/ComfyUI-KJNodes]]></title>
            <link>https://github.com/kijai/ComfyUI-KJNodes</link>
            <guid>https://github.com/kijai/ComfyUI-KJNodes</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:32 GMT</pubDate>
            <description><![CDATA[Various custom nodes for ComfyUI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kijai/ComfyUI-KJNodes">kijai/ComfyUI-KJNodes</a></h1>
            <p>Various custom nodes for ComfyUI</p>
            <p>Language: Python</p>
            <p>Stars: 2,103</p>
            <p>Forks: 224</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre># KJNodes for ComfyUI

Various quality of life and masking related -nodes and scripts made by combining functionality of existing nodes for ComfyUI.

I know I&#039;m bad at documentation, especially this project that has grown from random practice nodes to... too many lines in one file.
I have however started to add descriptions to the nodes themselves, there&#039;s a small ? you can click for info what the node does.
This is still work in progress, like everything else.

# Installation
1. Clone this repo into `custom_nodes` folder.
2. Install dependencies: `pip install -r requirements.txt`
   or if you use the portable install, run this in ComfyUI_windows_portable -folder:

  `python_embeded\python.exe -m pip install -r ComfyUI\custom_nodes\ComfyUI-KJNodes\requirements.txt`
   

## Javascript

### browserstatus.js
Sets the favicon to green circle when not processing anything, sets it to red when processing and shows progress percentage and the length of your queue. 
Default off, needs to be enabled from options, overrides Custom-Scripts favicon when enabled.

## Nodes:

### Set/Get

Javascript nodes to set and get constants to reduce unnecessary lines. Takes in and returns anything, purely visual nodes.
On the right click menu of these nodes there&#039;s now an options to visualize the paths, as well as option to jump to the corresponding node on the other end.

**Known limitations**:
  - Will not work with any node that dynamically sets it&#039;s outpute, such as reroute or other Set/Get node
  - Will not work when directly connected to a bypassed node
  - Other possible conflicts with javascript based nodes.

### ColorToMask

RBG color value to mask, works with batches and AnimateDiff.

### ConditioningMultiCombine

Combine any number of conditions, saves space.

### ConditioningSetMaskAndCombine

Mask and combine two sets of conditions, saves space.

### GrowMaskWithBlur

Grows or shrinks (with negative values) mask, option to invert input, returns mask and inverted mask. Additionally Blurs the mask, this is a slow operation especially with big batches.

### RoundMask

![image](https://github.com/kijai/ComfyUI-KJNodes/assets/40791699/52c85202-f74e-4b96-9dac-c8bda5ddcc40)

### WidgetToString
Outputs the value of a widget on any node as a string
![example of use](docs/images/2024-04-03_20_49_29-ComfyUI.png)

Enable node id display from Manager menu, to get the ID of the node you want to read a widget from:
![enable node id display](docs/images/319121636-706b5081-9120-4a29-bd76-901691ada688.png)

Use the node id of the target node, and add the name of the widget to read from
![use node id and widget name](docs/images/319121566-05f66385-7568-4b1f-8bbc-11053660b02f.png)

Recreating or reloading the target node will change its id, and the WidgetToString node will no longer be able to find it until you update the node id value with the new id.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[allenai/olmocr]]></title>
            <link>https://github.com/allenai/olmocr</link>
            <guid>https://github.com/allenai/olmocr</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Toolkit for linearizing PDFs for LLM datasets/training]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/allenai/olmocr">allenai/olmocr</a></h1>
            <p>Toolkit for linearizing PDFs for LLM datasets/training</p>
            <p>Language: Python</p>
            <p>Stars: 16,507</p>
            <p>Forks: 1,296</p>
            <p>Stars today: 52 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img width=&quot;350&quot; alt=&quot;olmocr-2-full@2x&quot; src=&quot;https://github.com/user-attachments/assets/24f1b596-4059-46f1-8130-5d72dcc0b02e&quot; /&gt;
&lt;hr/&gt;
&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/allenai/OLMo/blob/main/LICENSE&quot;&gt;
    &lt;img alt=&quot;GitHub License&quot; src=&quot;https://img.shields.io/github/license/allenai/OLMo&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/allenai/olmocr/releases&quot;&gt;
    &lt;img alt=&quot;GitHub release&quot; src=&quot;https://img.shields.io/github/release/allenai/olmocr.svg&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://arxiv.org/abs/2502.18443&quot;&gt;
    &lt;img alt=&quot;Tech Report v1&quot; src=&quot;https://img.shields.io/badge/Paper_v1-olmOCR-blue&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://arxiv.org/abs/2510.19817&quot;&gt;
    &lt;img alt=&quot;Tech Report v2&quot; src=&quot;https://img.shields.io/badge/Paper_v2-olmOCR-blue&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://olmocr.allenai.org&quot;&gt;
    &lt;img alt=&quot;Demo&quot; src=&quot;https://img.shields.io/badge/Ai2-Demo-F0529C&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/sZq3jTNVNG&quot;&gt;
    &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/Discord%20-%20blue?style=flat&amp;logo=discord&amp;label=Ai2&amp;color=%235B65E9&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

A toolkit for converting PDFs and other image-based document formats into clean, readable, plain text format.

Try the online demo: [https://olmocr.allenai.org/](https://olmocr.allenai.org/)

Features:
 - Convert PDF, PNG, and JPEG based documents into clean Markdown
 - Support for equations, tables, handwriting, and complex formatting
 - Automatically removes headers and footers
 - Convert into text with a natural reading order, even in the presence of
   figures, multi-column layouts, and insets
 - Efficient, less than $200 USD per million pages converted
 - (Based on a 7B parameter VLM, so it requires a GPU)

### News
 - October 21, 2025 - v0.4.0 - [New model release](https://huggingface.co/allenai/olmOCR-2-7B-1025-FP8), boosts olmOCR-bench score by ~4 points using synthetic data and introduces RL training.
 - August 13, 2025 - v0.3.0 - [New model release](https://huggingface.co/allenai/olmOCR-7B-0825-FP8), fixes auto-rotation detection, and hallucinations on blank documents.
 - July 24, 2025 - v0.2.1 - [New model release](https://huggingface.co/allenai/olmOCR-7B-0725-FP8), scores 3 points higher on [olmOCR-Bench](https://github.com/allenai/olmocr/tree/main/olmocr/bench), also runs significantly faster because it&#039;s default FP8, and needs much fewer retries per document.
 - July 23, 2025 - v0.2.0 - New cleaned up [trainer code](https://github.com/allenai/olmocr/tree/main/olmocr/train), makes it much simpler to train olmOCR models yourself.
 - June 17, 2025 - v0.1.75 - Switch from sglang to vllm based inference pipeline, updated docker image to CUDA 12.8.
 - May 23, 2025 - v0.1.70 - Official docker support and images are now available! [See Docker usage](#using-docker)
 - May 19, 2025 - v0.1.68 - [olmOCR-Bench](https://github.com/allenai/olmocr/tree/main/olmocr/bench) launch, scoring 77.4. Launch includes 2 point performance boost in olmOCR pipeline due to bug fixes with prompts.
 - Mar 17, 2025 - v0.1.60 - Performance improvements due to better temperature selection in sampling.
 - Feb 25, 2025 - v0.1.58 -  Initial public launch and demo.

### Benchmark

[**olmOCR-Bench**](https://github.com/allenai/olmocr/tree/main/olmocr/bench):
We also ship a comprehensive benchmark suite covering over 7,000 test cases across 1,400 documents to help measure performance of OCR systems. 

&lt;table&gt;
    &lt;thead&gt;
        &lt;tr&gt;
            &lt;th&gt;&lt;/th&gt;
            &lt;th&gt;ArXiv&lt;/th&gt;
            &lt;th&gt;Old&lt;br&gt;scans&lt;br&gt;math&lt;/th&gt;
            &lt;th&gt;Tables&lt;/th&gt;
            &lt;th&gt;Old&lt;br&gt;scans&lt;/th&gt;
            &lt;th&gt;Headers&lt;br&gt;&amp;&lt;br&gt;footers&lt;/th&gt;
            &lt;th&gt;Multi&lt;br&gt;column&lt;/th&gt;
            &lt;th&gt;Long&lt;br&gt;tiny&lt;br&gt;text&lt;/th&gt;
            &lt;th&gt;Base&lt;/th&gt;
            &lt;th&gt;Overall&lt;/th&gt;
        &lt;/tr&gt;
    &lt;/thead&gt;
    &lt;tbody&gt;
        &lt;tr&gt;
            &lt;td&gt;Mistral OCR API&lt;/td&gt;
            &lt;td&gt;77.2&lt;/td&gt;
            &lt;td&gt;67.5&lt;/td&gt;
            &lt;td&gt;60.6&lt;/td&gt;
            &lt;td&gt;29.3&lt;/td&gt;
            &lt;td&gt;93.6&lt;/td&gt;
            &lt;td&gt;71.3&lt;/td&gt;
            &lt;td&gt;77.1&lt;/td&gt;
            &lt;td&gt;99.4&lt;/td&gt;
            &lt;td&gt;72.0¬±1.1&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Marker 1.10.1&lt;/td&gt;
            &lt;td&gt;83.8&lt;/td&gt;
            &lt;td&gt;66.8&lt;/td&gt;
            &lt;td&gt;72.9&lt;/td&gt;
            &lt;td&gt;33.5&lt;/td&gt;
            &lt;td&gt;86.6&lt;/td&gt;
            &lt;td&gt;80.0&lt;/td&gt;
            &lt;td&gt;85.7&lt;/td&gt;
            &lt;td&gt;99.3&lt;/td&gt;
            &lt;td&gt;76.1¬±1.1&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;MinerU 2.5.4*&lt;/td&gt;
            &lt;td&gt;76.6&lt;/td&gt;
            &lt;td&gt;54.6&lt;/td&gt;
            &lt;td&gt;84.9&lt;/td&gt;
            &lt;td&gt;33.7&lt;/td&gt;
            &lt;td&gt;96.6&lt;/td&gt;
            &lt;td&gt;78.2&lt;/td&gt;
            &lt;td&gt;83.5&lt;/td&gt;
            &lt;td&gt;93.7&lt;/td&gt;
            &lt;td&gt;75.2¬±1.1&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;DeepSeek-OCR&lt;/td&gt;
            &lt;td&gt;77.2&lt;/td&gt;
            &lt;td&gt;73.6&lt;/td&gt;
            &lt;td&gt;80.2&lt;/td&gt;
            &lt;td&gt;33.3&lt;/td&gt;
            &lt;td&gt;96.1&lt;/td&gt;
            &lt;td&gt;66.4&lt;/td&gt;
            &lt;td&gt;79.4&lt;/td&gt;
            &lt;td&gt;99.8&lt;/td&gt;
            &lt;td&gt;75.7¬±1.0&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Nanonets-OCR2-3B&lt;/td&gt;
            &lt;td&gt;75.4&lt;/td&gt;
            &lt;td&gt;46.1&lt;/td&gt;
            &lt;td&gt;86.8&lt;/td&gt;
            &lt;td&gt;40.9&lt;/td&gt;
            &lt;td&gt;32.1&lt;/td&gt;
            &lt;td&gt;81.9&lt;/td&gt;
            &lt;td&gt;93.0&lt;/td&gt;
            &lt;td&gt;99.6&lt;/td&gt;
            &lt;td&gt;69.5¬±1.1&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;PaddleOCR-VL*&lt;/td&gt;
            &lt;td&gt;85.7&lt;/td&gt;
            &lt;td&gt;71.0&lt;/td&gt;
            &lt;td&gt;84.1&lt;/td&gt;
            &lt;td&gt;37.8&lt;/td&gt;
            &lt;td&gt;97.0&lt;/td&gt;
            &lt;td&gt;79.9&lt;/td&gt;
            &lt;td&gt;85.7&lt;/td&gt;
            &lt;td&gt;98.5&lt;/td&gt;
            &lt;td&gt;80.0¬±1.0&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Infinity-Parser 7B*&lt;/td&gt;
            &lt;td&gt;84.4&lt;/td&gt;
            &lt;td&gt;83.8&lt;/td&gt;
            &lt;td&gt;85.0&lt;/td&gt;
            &lt;td&gt;47.9&lt;/td&gt;
            &lt;td&gt;88.7&lt;/td&gt;
            &lt;td&gt;84.2&lt;/td&gt;
            &lt;td&gt;86.4&lt;/td&gt;
            &lt;td&gt;99.8&lt;/td&gt;
            &lt;td&gt;82.5¬±?&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;Chandra OCR 0.1.0*&lt;/td&gt;
            &lt;td&gt;82.2&lt;/td&gt;
            &lt;td&gt;80.3&lt;/td&gt;
            &lt;td&gt;88.0&lt;/td&gt;
            &lt;td&gt;50.4&lt;/td&gt;
            &lt;td&gt;90.8&lt;/td&gt;
            &lt;td&gt;81.2&lt;/td&gt;
            &lt;td&gt;92.3&lt;/td&gt;
            &lt;td&gt;99.9&lt;/td&gt;
            &lt;td&gt;83.1¬±0.9&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td colspan=&quot;10&quot;&gt;&lt;hr&gt;&lt;/td&gt;
        &lt;/tr&gt;
        &lt;tr&gt;
            &lt;td&gt;&lt;strong&gt;olmOCR v0.4.0&lt;/strong&gt;&lt;/td&gt;
            &lt;td&gt;83.0&lt;/td&gt;
            &lt;td&gt;82.3&lt;/td&gt;
            &lt;td&gt;84.9&lt;/td&gt;
            &lt;td&gt;47.7&lt;/td&gt;
            &lt;td&gt;96.1&lt;/td&gt;
            &lt;td&gt;83.7&lt;/td&gt;
            &lt;td&gt;81.9&lt;/td&gt;
            &lt;td&gt;99.7&lt;/td&gt;
            &lt;td&gt;82.4¬±1.1&lt;/td&gt;
        &lt;/tr&gt;
    &lt;/tbody&gt;
&lt;/table&gt;


### Installation

Requirements:
 - Recent NVIDIA GPU (tested on RTX 4090, L40S, A100, H100) with at least 12 GB of GPU RAM
 - 30GB of free disk space

You will need to install poppler-utils and additional fonts for rendering PDF images.

Install dependencies (Ubuntu/Debian)
```bash
sudo apt-get update
sudo apt-get install poppler-utils ttf-mscorefonts-installer msttcorefonts fonts-crosextra-caladea fonts-crosextra-carlito gsfonts lcdf-typetools
```

Set up a conda environment and install olmocr. The requirements for running olmOCR
are difficult to install in an existing python environment, so please do make a clean python environment to install into.
```bash
conda create -n olmocr python=3.11
conda activate olmocr

# For CPU-only operations, ex running the benchmark
pip install olmocr[bench]

# For actually converting the files with your own GPU
pip install olmocr[gpu]  --extra-index-url https://download.pytorch.org/whl/cu128

# Recommended: Install flash infer for faster inference on GPU
pip install https://download.pytorch.org/whl/cu128/flashinfer/flashinfer_python-0.2.5%2Bcu128torch2.7-cp38-abi3-linux_x86_64.whl
```

### Local Usage Example

For quick testing, try the [web demo](https://olmocr.allen.ai/). To run locally, a GPU is required, as inference is powered by [sglang](https://github.com/sgl-project/sglang) under the hood.

Convert a Single PDF:
```bash
# Download a sample PDF
curl -o olmocr-sample.pdf https://olmocr.allenai.org/papers/olmocr_3pg_sample.pdf

# Convert it to markdown
python -m olmocr.pipeline ./localworkspace --markdown --pdfs olmocr-sample.pdf
```

Convert an Image file:
```bash
python -m olmocr.pipeline ./localworkspace --markdown --pdfs random_page.png
```

Convert Multiple PDFs:
```bash
python -m olmocr.pipeline ./localworkspace --markdown --pdfs tests/gnarly_pdfs/*.pdf
```

With the addition of the `--markdown` flag, results will be stored as markdown files inside of `./localworkspace/markdown/`. 

#### Viewing Results

The `./localworkspace/` workspace folder will then have both [Dolma](https://github.com/allenai/dolma) and markdown files (if using `--markdown`).


```bash
cat localworkspace/markdown/olmocr-sample.md 
```

```
olmOCR: Unlocking Trillions of Tokens in PDFs with Vision Language Models
...
```

### Using an Inference Provider or External Server

If you have a vLLM server already running elsewhere (or any inference platform implementing the OpenAI API), you can point olmOCR to use it instead of spawning a local instance:

```bash
# Use external vLLM server instead of local one
python -m olmocr.pipeline ./localworkspace --server http://remote-server:8000/v1 --model allenai/olmOCR-2-7B-1025-FP8 --markdown --pdfs tests/gnarly_pdfs/*.pdf
```
The served model name in VLLM needs to match the value provided in `--model`.

An example vLLM launch command would be:
```bash
vllm serve allenai/olmOCR-2-7B-1025-FP8 --max-model-len 16384
```

#### Verified External Providers

We have tested `olmOCR-2-7B-1025-FP8` on these external model providers and confirmed that they work

|                                                                             | $/1M Input tokens | $/1M Output tokens | Example Command                                                                                                                                                                |
|-----------------------------------------------------------------------------|-------------------|--------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| [Cirrascale](https://ai2endpoints.cirrascale.ai/models/overview)            | $0.07             | $0.15              | `python -m olmocr.pipeline ./localworkspace1 --server https://ai2endpoints.cirrascale.ai/api --api_key sk-XXXXXXX --model olmOCR-2-7B-1025 --pdfs tests/gnarly_pdfs/*.pdf`     |
| [DeepInfra](https://deepinfra.com/)                                         | $0.09             | $0.19              | `python -m olmocr.pipeline ./localworkspace1 --server https://api.deepinfra.com/v1/openai --api_key DfXXXXXXX --model allenai/olmOCR-2-7B-1025 --pdfs tests/gnarly_pdfs/*.pdf` |
| [Parasail](https://www.saas.parasail.io/serverless?name=olmocr-7b-1025-fp8) | $0.10             | $0.20              | `python -m olmocr.pipeline ./localworkspace1 --server https://api.parasail.io/v1 --api_key psk-XXXXX --model allenai/olmOCR-2-7B-1025 --pdfs tests/gnarly_pdfs/*.pdf`          |


Notes on arguments
- `--server`: Defines the OpenAI-compatible endpoint: ex `https://api.deepinfra.com/v1/openai`
- `--api_key`: Your API key, bassed in via Authorization Bearer HTTP header
- `--pages_per_group`: You may want a smaller number of pages per group as many external provides have lower concurrent request limits
- `--model`: The model identifier, ex. `allenai/olmOCR-2-7B-1025`, different providers have different names, and if you run locally, you can use `olmocr`
- Other arguments work the same as with local inference


### Multi-node / Cluster Usage

If you want to convert millions of PDFs, using multiple nodes running in parallel, then olmOCR supports
reading your PDFs from AWS S3, and coordinating work using an AWS S3 output bucket.

For example, you can start this command on your first worker node, and it will set up
a simple work queue in your AWS bucket and start converting PDFs.

```bash
python -m olmocr.pipeline s3://my_s3_bucket/pdfworkspaces/exampleworkspace --pdfs s3://my_s3_bucket/jakep/gnarly_pdfs/*.pdf
```

Now on any subsequent nodes, just run this and they will start grabbing items from the same workspace queue.
```bash
python -m olmocr.pipeline s3://my_s3_bucket/pdfworkspaces/exampleworkspace
```

If you are at Ai2 and want to linearize millions of PDFs efficiently using [beaker](https://www.beaker.org), just add the `--beaker`
flag. This will prepare the workspace on your local machine, and then launch N GPU workers in the cluster to start
converting PDFs.

For example:
```bash
python -m olmocr.pipeline s3://my_s3_bucket/pdfworkspaces/exampleworkspace --pdfs s3://my_s3_bucket/jakep/gnarly_pdfs/*.pdf --beaker --beaker_gpus 4
```


### Using Docker

Pull the Docker image (large, includes the model, ~30GB):
```bash
docker pull alleninstituteforai/olmocr:latest-with-model
```

For advanced users who want to manage their own model downloads, we also provide a base image without the model:
```bash
docker pull alleninstituteforai/olmocr:latest
```

#### Quick Start - Process PDFs

Process a single PDF in your current directory:
```bash
docker run --gpus all \
  -v $(pwd):/workspace \
  alleninstituteforai/olmocr:latest-with-model \
  -c &quot;python -m olmocr.pipeline /workspace/output --markdown --pdfs /workspace/sample.pdf&quot;
```

Process multiple PDFs:
```bash
docker run --gpus all \
  -v /path/to/pdfs:/input \
  -v /path/to/output:/output \
  alleninstituteforai/olmocr:latest-with-model \
  -c &quot;python -m olmocr.pipeline /output --markdown --pdfs /input/*.pdf&quot;
```

#### Interactive Mode

Run the container interactively for exploration and debugging:
```bash
docker run -it --gpus all alleninstituteforai/olmocr:latest-with-model
```

&gt; Visit our Docker repository on [Docker Hub](https://hub.docker.com/r/alleninstituteforai/olmocr) for more information.

### Full documentation for the pipeline

```bash
python -m olmocr.pipeline --help
usage: pipeline.py [-h] [--pdfs [PDFS ...]] [--model MODEL] [--workspace_profile WORKSPACE_PROFILE] [--pdf_profile PDF_PROFILE] [--pages_per_group PAGES_PER_GROUP] [--max_page_retries MAX_PAGE_RETRIES] [--max_page_error_rate MAX_PAGE_ERROR_RATE] [--workers WORKERS]
                   [--apply_filter] [--stats] [--markdown] [--target_longest_image_dim TARGET_LONGEST_IMAGE_DIM] [--target_anchor_text_len TARGET_ANCHOR_TEXT_LEN] [--guided_decoding] [--gpu-memory-utilization GPU_MEMORY_UTILIZATION] [--max_model_len MAX_MODEL_LEN]
                   [--tensor-parallel-size TENSOR_PARALLEL_SIZE] [--data-parallel-size DATA_PARALLEL_SIZE] [--port PORT] [--server SERVER] [--beaker] [--beaker_workspace BEAKER_WORKSPACE] [--beaker_cluster BEAKER_CLUSTER] [--beaker_gpus BEAKER_GPUS] [--beaker_priority BEAKER_PRIORITY]
                   workspace

Manager for running millions of PDFs through a batch inference pipeline

positional arguments:
  workspace             The filesystem path where work will be stored, can be a local folder, or an s3 path if coordinating work with many workers, s3://bucket/prefix/

options:
  -h, --help            show this help message and exit
  --pdfs [PDFS ...]     Path to add pdfs stored in s3 to the workspace, can be a glob path s3://bucket/prefix/*.pdf or path to file containing list of pdf paths
  --model MODEL         Path where the model is located, allenai/olmOCR-7B-0725-FP8 is the default, can be local, s3, or hugging face.
  --workspace_profile WORKSPACE_PROFILE
                        S3 configuration profile for accessing the workspace
  --pdf_profile PDF_PROFILE
                        S3 configuration profile for accessing the raw pdf documents
  --pages_per_group PAGES_PER_GROUP
                        Aiming for this many pdf pages per work item group
  --max_page_retries MAX_PAGE_RETRIES
                        Max number of times we will retry rendering a page
  --max_page_error_rate MAX_PAGE_ERROR_RATE
                        Rate of allowable failed pages in a document, 1/250 by default
  --workers WORKERS     Number of workers to run at a time
  --apply_filter        Apply basic filtering to English pdfs which are not forms, and not likely seo spam
  --stats               Instead of running any job, reports some statistics about the current workspace
  --markdown            Also write natural text to markdown files preserving the folder structure of the input pdfs
  --target_longest_image_dim TARGET_LONGEST_IMAGE_DIM
                        Dimension on longest side to use for rendering the pdf pages
  --target_anchor_text_len TARGET_ANCHOR_TEXT_LEN
                        Maximum amount of anchor text to use (characters), not used for new models
  --guided_decoding     Enable guided decoding for model YAML type outputs

VLLM arguments:
  --gpu-memory-utilization GPU_MEMORY_UTILIZATION
                        Fraction of VRAM vLLM may pre-allocate for KV-cache (passed through to vllm serve).
  --max_model_len MAX_MODEL_LEN
                        Upper bound (tokens) vLLM will allocate KV-cache for, lower if VLLM won&#039;t start
  --tensor-parallel-size TENSOR_PARALLEL_SIZE, -tp TENSOR_PARALLEL_SIZE
                        Tensor parallel size for vLLM
  --data-parallel-size DATA_PARALLEL_SIZE, -dp DATA_PARALLEL_SIZE
                        Data parallel size for vLLM
  --port PORT           Port to use for the VLLM server
  --server SERVER       URL of external vLLM (or other compatible provider)
                        server (e.g., http://hostname:port). If provided,
                        skips spawning local vLLM instance

beaker/cluster execution:
  --beaker              Submit this job to beaker instead of running locally
  --beaker_workspace BEAKER_WORKSPACE
                        Beaker workspace to submit to
  --beaker_cluster BEAKER_CLUSTER
                        Beaker clusters you want to run on
  --beaker_gpus BEAKER_GPUS
                        Number of gpu replicas to run
  --beaker_priority BEAKER_PRIORITY
                        Beaker priority level for the job
```

## Code overview

There are some nice reusable pieces of the code that may be useful for your own projects:
 - A prompting strategy to get really good natural text parsing using ChatGPT 4o - [buildsilver.py](https://github.com/allenai/olmocr/blob/main/olmocr/data/buildsilver.py)
 - Basic filtering by language and SEO spam removal - [filter.py](https://github.com/allenai/olmocr/blob/main/olmocr/filter/filter.py)
 - SFT Finetuning code for Qwen2.5-VL - [train.py](https://github.com/allenai/olmocr/blob/main/olmocr/train/train.py)
 - GRPO RL Trainer - [grpo_train.py](https://github.com/allenai/olmocr/blob/main/olmocr/train/grpo_train.py)
 - Synthetic data generation - [mine_html_templates.py](https://github.com/allenai/olmocr/blob/main/olmocr/bench/synth/mine_html_templates.py)
 - Processing millions of PDFs through a finetuned model using VLLM - [pipeline.py](https://github.com/allenai/olmocr/blob/main/olmocr/pipeline.py)
 - Viewing [Dolma docs](https://github.com/allenai/dolma) created from PDFs - [dolmaviewer.py](https://github.com/allenai/olmocr/blob/main/olmocr/viewer/dolmaviewer.py)



## Team

&lt;!-- start team --&gt;

**olmOCR** is developed and maintained by the AllenNLP team, backed by [the Allen Institute for Artificial Intelligence (AI2)](https://allenai.org/).
AI2 is a non-profit institute with the mission to contribute to humanity through high-impact AI research and engineering.
To learn more about who specifically contributed to this codebase, see [our contributors](https://github.com/allenai/olmocr/graphs/contributors) page.

&lt;!-- end team --&gt;

## License

&lt;!-- start license --&gt;

**olmOCR** is licensed under [Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0).
A full copy of the license can be found [on GitHub](https://github.com/allenai/olmocr/blob/main/LICENSE).

&lt;!-- end license -

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[tencent-ailab/SongGeneration]]></title>
            <link>https://github.com/tencent-ailab/SongGeneration</link>
            <guid>https://github.com/tencent-ailab/SongGeneration</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[The official code repository for LeVo: High-Quality Song Generation with Multi-Preference Alignment]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/tencent-ailab/SongGeneration">tencent-ailab/SongGeneration</a></h1>
            <p>The official code repository for LeVo: High-Quality Song Generation with Multi-Preference Alignment</p>
            <p>Language: Python</p>
            <p>Stars: 1,125</p>
            <p>Forks: 133</p>
            <p>Stars today: 60 stars today</p>
            <h2>README</h2><pre># SongGeneration

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;img/logo.jpg&quot; width=&quot;40%&quot;&gt;&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://levo-demo.github.io/&quot;&gt;Demo&lt;/a&gt; &amp;nbsp;|&amp;nbsp; &lt;a href=&quot;https://arxiv.org/abs/2506.07520&quot;&gt;Paper&lt;/a&gt;  &amp;nbsp;|&amp;nbsp; &lt;a href=&quot;https://huggingface.co/waytan22/SongGeneration&quot;&gt;Hugging Face&lt;/a&gt;  &amp;nbsp;|&amp;nbsp; &lt;a href=&quot;https://huggingface.co/spaces/waytan22/SongGeneration-LeVo&quot;&gt;Space Demo&lt;/a&gt;
&lt;/p&gt;



This repository is the official repository for ‚ÄúLeVo: High-Quality Song Generation with Multi-Preference Alignment‚Äù (NeurIPS 2025). In this repository, we provide the SongGeneration model, inference scripts,pretrained checkpoints, and some music generation tools.

## News and Updates

* **2025.10.16 üî•**: Our [**Demo webpage**](https://huggingface.co/spaces/tencent/SongGeneration) now supports **full-length song generation (up to 4m30s)**! üé∂  Experience end-to-end music generation with vocals and accompaniment ‚Äî try it out now!
* **2025.10.15 üî•**: We have updated the codebase to improve **inference speed** and **generation quality**, and adapted it to the **latest model version**. Please **update to the newest code** to ensure the **best performance and user experience**.
* **2025.10.14 üî•**: We have released the **large model (SongGeneration-large)**.
* **2025.10.13 üî•**: We have released the **full time model (SongGeneration-base-full)** and **evaluation performance**.
* **2025.10.12 üî•**: We have released the **english enhanced model (SongGeneration-base-new)**.
* **2025.09.23 üî•**: We have released the [Data Processing Pipeline](https://github.com/tencent-ailab/SongPrep), which is capable of **analyzing the structure and lyrics** of entire songs and **providing precise timestamps** without the need for additional source separation. On the human-annotated test set [SSLD-200](https://huggingface.co/datasets/waytan22/SSLD-200), the model‚Äôs performance outperforms mainstream models including Gemini-2.5, Seed-ASR, and Qwen3-ASR.
* **2025.07.25 üî•**: SongGeneration can now run with as little as **10GB of GPU memory**.
* **2025.07.18 üî•**: SongGeneration now supports generation of **pure music**, **pure vocals**, and **dual-track (vocals + accompaniment separately)** outputs.
* **2025.06.16 üî•**: We have released the **SongGeneration** series.

## TODOsüìã

- [ ] Release SongGeneration-v1.5 (trained on a larger multilingual dataset, supports more languages, and integrates a Reward Model with Reinforcement Learning to enhance musicality and lyric alignment)
- [ ] Release finetuning scripts.
- [ ] Release Music Codec and VAE.
- [x] Release large model.
- [x] Release full time model.
- [x] Release English enhanced model.
- [x] Release data processing pipeline.
- [x] Update Low memory usage model.
- [x] Support single vocal/bgm track generation.

## Model Versions

| Model                     | Max Length |       Language       | GPU Memory | RFT(A100) | Download Link                                                |
| ------------------------- | :--------: | :------------------: | :---------: | :-------: | ------------------------------------------------------------ |
| SongGeneration-base       |   2m30s    |          zh          |   10G/16G   |   1.26    | [Huggingface](https://huggingface.co/tencent/SongGeneration/tree/main/ckpt/songgeneration_base) |
| SongGeneration-base-new   |   2m30s    |        zh, en        |   10G/16G   |   1.26    | [Huggingface](https://huggingface.co/lglg666/SongGeneration-base-new) |
| SongGeneration-base-full  |   4m30s    |        zh, en        |   12G/18G   |   1.30    | [Huggingface](https://huggingface.co/lglg666/SongGeneration-base-full) |
| SongGeneration-large      |   4m30s    |        zh, en        |   22G/28G   |   1.51    | [Huggingface](https://huggingface.co/lglg666/SongGeneration-large) |
| SongGeneration-v1.5-small |     2m     | zh, en, es, ja, etc. |      -      |     -     | Coming soon                                                  |
| SongGeneration-v1.5-base  |   4m30s    | zh, en, es, ja, etc. |      -      |     -     | Coming soon                                                  |
| SongGeneration-v1.5-large |   4m30s    | zh, en, es, ja, etc. |      -      |     -     | Coming soon                                                  |

üí° **Notes:**

- **GPU Memory** ‚Äî ‚ÄúX / Y‚Äù means X: no prompt audio; Y: with prompt audio.
- **RFT** ‚Äî Real Forward Time (pure inference, excluding model loading).

## Overview

We develop the SongGeneration model. It is an LM-based framework consisting of **LeLM** and a **music codec**. LeLM is capable of parallelly modeling two types of tokens: mixed tokens, which represent the combined audio of vocals and accompaniment to achieve vocal-instrument harmony, and dual-track tokens, which separately encode vocals and accompaniment for high-quality song generation. The music codec reconstructs the dual-track tokens into highfidelity music audio. SongGeneration significantly improves over the open-source music generation models and performs competitively with current state-of-the-art industry systems. For more details, please refer to our [paper](https://arxiv.org/abs/2506.07520).

&lt;img src=&quot;img/over.jpg&quot; alt=&quot;img&quot; style=&quot;zoom:100%;&quot; /&gt; 

## Installation

### Start from scratch

You can install the necessary dependencies using the `requirements.txt` file with Python&gt;=3.8.12 and CUDA&gt;=11.8:

```bash
pip install -r requirements.txt
pip install -r requirements_nodeps.txt --no-deps
```

**(Optional)** Then install flash attention from git. For example, if you&#039;re using Python 3.10 and CUDA 12.0

```bash
pip install https://github.com/Dao-AILab/flash-attention/releases/download/v2.7.4.post1/flash_attn-2.7.4.post1+cu12torch2.6cxx11abiFALSE-cp310-cp310-linux_x86_64.whl
```

### Start with docker

```bash
docker pull juhayna/song-generation-levo:hf0613
docker run -it --gpus all --network=host juhayna/song-generation-levo:hf0613 /bin/bash
```

### Other deploy examples 

 - Windows platform with ComfyUI: https://github.com/smthemex/ComfyUI_SongGeneration
 - Windows installer: http://bilibili.com/video/BV1ATK8zQE8L/?vd_source=22cfc54298226c4161b1aff457d17585
 - Quick start with ComfyUI on CNB: https://cnb.cool/tencent/tencent-ailab/examples/SongGeneration-comfyui

## Inference

To ensure the model runs correctly, **please download all the required folders** from the original source at [Hugging Face](https://huggingface.co/collections/lglg666/levo-68d0c3031c370cbfadade126).

- Download `ckpt` and `third_party` folder from [Hugging Face](https://huggingface.co/lglg666/SongGeneration-Runtime/tree/main) or  [Hugging Face](https://huggingface.co/tencent/SongGeneration/tree/main), and move them into the **root directory** of the project. You can also download models using hugging face-cli.

  ```
  huggingface-cli download lglg666/SongGeneration-Runtime --local-dir ./runtime
  mv runtime/ckpt ckpt
  mv runtime/third_party third_party
  ```

- Download the specific model checkpoint and save it to your specified checkpoint directory: `ckpt_path` (We provide multiple versions of model checkpoints. Please select the most suitable version based on your needs and download the corresponding file. Also, ensure the folder name matches the model version name.) Your can also download models using hugging face-cli.

  ```
  # download SongGeneration-base
  huggingface-cli download lglg666/SongGeneration-base --local-dir ./songgeneration_base
  # download SongGeneration-base-new
  huggingface-cli download lglg666/SongGeneration-base-new --local-dir ./songgeneration_base_new
  # download SongGeneration-base-full
  huggingface-cli download lglg666/SongGeneration-base-full --local-dir ./songgeneration_base_full
  # download SongGeneration-large
  huggingface-cli download lglg666/SongGeneration-large --local-dir ./songgeneration_large
  ```

Once everything is set up, you can run the inference script using the following command:

```bash
sh generate.sh ckpt_path lyrics.jsonl output_path
```

- You may provides sample inputs in JSON Lines (`.jsonl`) format. Each line represents an individual song generation request. The model expects each input to contain the following fields:

  - `idx`: A unique identifier for the output song. It will be used as the name of the generated audio file.
  - `gt_lyric`:The lyrics to be used in generation. It must follow the format of `[Structure] Text`, where `Structure` defines the musical section (e.g., `[Verse]`, `[Chorus]`). See Input Guide.
  - `descriptions` : (Optional) You may customize the text prompt to guide the model‚Äôs generation. This can include attributes like gender, timbre, genre, emotion, instrument, and BPM. See Input Guide.
  - `prompt_audio_path`: (Optional) Path to a 10-second reference audio file. If provided, the model will generate a new song in a similar style to the given reference.

  - `auto_prompt_audio_type`: (Optional) Used only if `prompt_audio_path` is not provided. This allows the model to automatically select a reference audio from a predefined library based on a given style. Supported values include:
    - `&#039;Pop&#039;`, `&#039;R&amp;B&#039;`, `&#039;Dance&#039;`, `&#039;Jazz&#039;`, `&#039;Folk&#039;`, `&#039;Rock&#039;`,`&#039;Chinese Style&#039;`, `&#039;Chinese Tradition&#039;`, `&#039;Metal&#039;`, `&#039;Reggae&#039;`, `&#039;Chinese Opera&#039;`, `&#039;Auto&#039;`.
  - **Note:** If certain optional fields are not required, they can be omitted. 

- Outputs of the loader `output_path`:

  - `audio`: generated audio files
  - `jsonl`: output jsonls

- An example command may look like:

  ```bash
  sh generate.sh songgeneration_base sample/lyrics.jsonl sample/output
  ```

If you encounter **out-of-memory (OOM**) issues, you can manually enable low-memory inference mode using the `--low_mem` flag. For example:

```bash
sh generate.sh ckpt_path lyrics.jsonl output_path --low_mem
```

If your GPU device does **not support Flash Attention** or your environment does **not have Flash Attention installed**, you can disable it by adding the `--not_use_flash_attn` flag. For example:

```bash
sh generate.sh ckpt_path lyrics.jsonl output_path --not_use_flash_attn
```

By default, the model generates **songs with both vocals and accompaniment**. If you want to generate **pure music**, **pure vocals**, or **separated vocal and accompaniment tracks**, please use the following flags:

- `--bgm`‚ÄÉ‚ÄÉGenerate **pure music**
- `--vocal`‚ÄÉGenerate **vocal-only (a cappella)**
- `--separate`‚ÄÉGenerate **separated vocal and accompaniment tracks**

For example:

```bash
sh generate.sh ckpt_path lyrics.jsonl output_path --separate
```

## Input Guide

An example input file can be found in `sample/lyrics.jsonl` 

### üéµ Lyrics Input Format

The `gt_lyric` field defines the lyrics and structure of the song. It consists of multiple musical section, each starting with a structure label. The model uses these labels to guide the musical and lyrical progression of the generated song.

#### üìå Structure Labels

- The following segments **should not** contain lyrics (they are purely instrumental):

  - `[intro-short]`, `[intro-medium]`, `[inst-short]`, `[inst-medium]`, `[outro-short]`, `[outro-medium]`

  &gt; - `short` indicates a segment of approximately 0‚Äì10 seconds
  &gt; - `medium` indicates a segment of approximately 10‚Äì20 seconds
  &gt; - We find that [inst] label is less stable, so we recommend that you do not use it.

- The following segments **require lyrics**:

  - `[verse]`, `[chorus]`, `[bridge]`

#### üßæ Lyrics Formatting Rules

- Each section is **separated by ` ; `**

- Within lyrical segments (`[verse]`, `[chorus]`, `[bridge]`), lyrics must be written in complete sentences and separated by a period (`.`)

- A complete lyric string may look like:

  ```
  [intro-short] ; [verse] These faded memories of us. I can&#039;t erase the tears you cried before. Unchained this heart to find its way. My peace won&#039;t beg you to stay ; [bridge] If ever your truth still remains. Turn around and see. Life rearranged its games. All these lessons in mistakes. Even years may never erase ; [inst-short] ; [chorus] Like a fool begs for supper. I find myself waiting for her. Only to find the broken pieces of my heart. That was needed for my soul to love again ; [outro-short]
  ```

- More examples can be found in `sample/test_en_input.jsonl` and `sample/test_zh_input.jsonl`.

### üìù Description Input Format

The `descriptions` field allows you to control various musical attributes of the generated song. It can describe up to six musical dimensions: **Gender** (e.g., male, female), **Timbre** (e.g., dark, bright, soft), **Genre** (e.g., pop, jazz, rock), **Emotion** (e.g., sad, energetic, romantic), **Instrument** (e.g., piano, drums, guitar), **BPM** (e.g., the bpm is 120). 

- All six dimensions are optional ‚Äî you can specify any subset of them.

- The order of dimensions is flexible.

- Use **commas (`,`)** to separate different attributes.

- Although the model supports open vocabulary, we recommend using predefined tags for more stable and reliable performance. A list of commonly supported tags for each dimension is available in the `sample/description/` folder.

- Here are a few valid `descriptions` inputs:

  ```
  - female, dark, pop, sad, piano and drums.
  - male, piano, jazz.
  - male, dark, the bpm is 110.
  ```

### üéßPrompt Audio Usage Notes

- The input audio file can be longer than 10 seconds, but only the first 10 seconds will be used.
- For best musicality and structure, it is recommended to use the chorus section of a song as the prompt audio.
- You can use this field to influence genre, instrumentation, rhythm, and voice

#### ‚ö†Ô∏è Important Considerations

- **Avoid providing both `prompt_audio_path` and `descriptions` at the same time.**
  If both are present, and they convey conflicting information, the model may struggle to follow instructions accurately, resulting in degraded generation quality.
- If `prompt_audio_path` is not provided, you can instead use `auto_prompt_audio_type` for automatic reference selection.

## Gradio UI

You can start up the UI with the following command:

```bash
sh tools/gradio/run.sh ckpt_path
```

## Evaluation Performance

### Chinese

 &lt;table&gt;
  &lt;tr&gt;
    &lt;th rowspan=&quot;2&quot;&gt;Model&lt;/th&gt;
    &lt;th rowspan=&quot;2&quot;&gt;Open-Source&lt;/th&gt;
    &lt;th rowspan=&quot;2&quot;&gt;PER‚Üì&lt;/th&gt;
    &lt;th colspan=&quot;4&quot; style=&quot;text-align:center;&quot;&gt;Audiobox Aesthetics ‚Üë&lt;/th&gt;
    &lt;th colspan=&quot;5&quot; style=&quot;text-align:center;&quot;&gt;SongEval ‚Üë&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;CE&lt;/th&gt;&lt;th&gt;CU&lt;/th&gt;&lt;th&gt;PC&lt;/th&gt;&lt;th&gt;PQ&lt;/th&gt;
    &lt;th&gt;COH&lt;/th&gt;&lt;th&gt;MUS&lt;/th&gt;&lt;th&gt;MEM&lt;/th&gt;&lt;th&gt;CLA&lt;/th&gt;&lt;th&gt;NAT&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Suno&lt;/td&gt;
    &lt;td&gt;‚ùå&lt;/td&gt;
    &lt;td&gt;21.6%&lt;/td&gt;
    &lt;td&gt;7.65&lt;/td&gt;&lt;td&gt;7.86&lt;/td&gt;&lt;td&gt;5.94&lt;/td&gt;&lt;td&gt;8.35&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;4.41&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;4.34&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;4.44&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;4.38&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;4.26&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Mureka&lt;/td&gt;
    &lt;td&gt;‚ùå&lt;/td&gt;
    &lt;td&gt;7.2%&lt;/td&gt;
    &lt;td&gt;7.71&lt;/td&gt;&lt;td&gt;7.83&lt;/td&gt;&lt;td&gt;&lt;b&gt;6.39&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;8.44&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;4.01&lt;/td&gt;&lt;td&gt;3.85&lt;/td&gt;&lt;td&gt;3.73&lt;/td&gt;&lt;td&gt;3.87&lt;/td&gt;&lt;td&gt;3.75&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Haimian&lt;/td&gt;
    &lt;td&gt;‚ùå&lt;/td&gt;
    &lt;td&gt;11.8%&lt;/td&gt;
    &lt;td&gt;7.56&lt;/td&gt;&lt;td&gt;7.85&lt;/td&gt;&lt;td&gt;5.89&lt;/td&gt;&lt;td&gt;8.27&lt;/td&gt;
    &lt;td&gt;3.69&lt;/td&gt;&lt;td&gt;3.43&lt;/td&gt;&lt;td&gt;3.51&lt;/td&gt;&lt;td&gt;3.52&lt;/td&gt;&lt;td&gt;3.34&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;ACE-Step&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;37.1%&lt;/td&gt;
    &lt;td&gt;7.37&lt;/td&gt;&lt;td&gt;7.52&lt;/td&gt;&lt;td&gt;&lt;b&gt;6.26&lt;/b&gt;&lt;/td&gt;&lt;td&gt;7.85&lt;/td&gt;
    &lt;td&gt;3.68&lt;/td&gt;&lt;td&gt;3.45&lt;/td&gt;&lt;td&gt;3.54&lt;/td&gt;&lt;td&gt;3.48&lt;/td&gt;&lt;td&gt;3.38&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Diffrhythm-v1,2&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;8.78%&lt;/td&gt;
    &lt;td&gt;6.91&lt;/td&gt;&lt;td&gt;7.45&lt;/td&gt;&lt;td&gt;5.45&lt;/td&gt;&lt;td&gt;7.99&lt;/td&gt;
    &lt;td&gt;2.93&lt;/td&gt;&lt;td&gt;2.60&lt;/td&gt;&lt;td&gt;2.70&lt;/td&gt;&lt;td&gt;2.71&lt;/td&gt;&lt;td&gt;2.60&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;YUE&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;14.9%&lt;/td&gt;
    &lt;td&gt;7.29&lt;/td&gt;&lt;td&gt;7.53&lt;/td&gt;&lt;td&gt;6.19&lt;/td&gt;&lt;td&gt;7.96&lt;/td&gt;
    &lt;td&gt;3.68&lt;/td&gt;&lt;td&gt;3.43&lt;/td&gt;&lt;td&gt;3.49&lt;/td&gt;&lt;td&gt;3.49&lt;/td&gt;&lt;td&gt;3.42&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;SongGeneration-base&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;7.2%&lt;/td&gt;
    &lt;td&gt;7.78&lt;/td&gt;&lt;td&gt;7.90&lt;/td&gt;&lt;td&gt;6.03&lt;/td&gt;&lt;td&gt;8.42&lt;/td&gt;
    &lt;td&gt;3.96&lt;/td&gt;&lt;td&gt;3.80&lt;/td&gt;&lt;td&gt;3.85&lt;/td&gt;&lt;td&gt;3.74&lt;/td&gt;&lt;td&gt;3.71&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;SongGeneration-base-new&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;5.7%&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;7.82&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;7.94&lt;/b&gt;&lt;/td&gt;&lt;td&gt;6.07&lt;/td&gt;&lt;td&gt;8.43&lt;/td&gt;
    &lt;td&gt;4.07&lt;/td&gt;&lt;td&gt;3.92&lt;/td&gt;&lt;td&gt;3.98&lt;/td&gt;&lt;td&gt;3.93&lt;/td&gt;&lt;td&gt;3.86&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;SongGeneration-base-full&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;8.4%&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;7.81&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;7.94&lt;/b&gt;&lt;/td&gt;&lt;td&gt;6.07&lt;/td&gt;&lt;td&gt;8.41&lt;/td&gt;
    &lt;td&gt;4.02&lt;/td&gt;&lt;td&gt;3.88&lt;/td&gt;&lt;td&gt;3.94&lt;/td&gt;&lt;td&gt;3.87&lt;/td&gt;&lt;td&gt;3.80&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;SongGeneration-large&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;5.1%&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;7.82&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;7.95&lt;/b&gt;&lt;/td&gt;&lt;td&gt;6.09&lt;/td&gt;&lt;td&gt;&lt;b&gt;8.46&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;4.08&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;3.94&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;4.00&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;3.94&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;3.87&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

### English

&lt;table&gt;
  &lt;tr&gt;
    &lt;th rowspan=&quot;2&quot;&gt;Model&lt;/th&gt;
    &lt;th rowspan=&quot;2&quot;&gt;Open-Source&lt;/th&gt;
    &lt;th rowspan=&quot;2&quot;&gt;PER‚Üì&lt;/th&gt;
    &lt;th colspan=&quot;4&quot; style=&quot;text-align:center;&quot;&gt;Audiobox Aesthetics ‚Üë&lt;/th&gt;
    &lt;th colspan=&quot;5&quot; style=&quot;text-align:center;&quot;&gt;SongEval ‚Üë&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;th&gt;CE&lt;/th&gt;&lt;th&gt;CU&lt;/th&gt;&lt;th&gt;PC&lt;/th&gt;&lt;th&gt;PQ&lt;/th&gt;
    &lt;th&gt;COH&lt;/th&gt;&lt;th&gt;MUS&lt;/th&gt;&lt;th&gt;MEM&lt;/th&gt;&lt;th&gt;CLA&lt;/th&gt;&lt;th&gt;NAT&lt;/th&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Suno&lt;/td&gt;
    &lt;td&gt;‚ùå&lt;/td&gt;
    &lt;td&gt;15.6%&lt;/td&gt;
    &lt;td&gt;7.64&lt;/td&gt;&lt;td&gt;7.85&lt;/td&gt;&lt;td&gt;5.84&lt;/td&gt;&lt;td&gt;8.19&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;4.49&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;4.35&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;4.47&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;4.35&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;4.23&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Mureka&lt;/td&gt;
    &lt;td&gt;‚ùå&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;12.6%&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;7.71&lt;/td&gt;&lt;td&gt;7.93&lt;/td&gt;&lt;td&gt;&lt;b&gt;6.46&lt;/b&gt;&lt;/td&gt;&lt;td&gt;8.39&lt;/td&gt;
    &lt;td&gt;4.06&lt;/td&gt;&lt;td&gt;3.88&lt;/td&gt;&lt;td&gt;3.90&lt;/td&gt;&lt;td&gt;3.90&lt;/td&gt;&lt;td&gt;3.73&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Haimian&lt;/td&gt;
    &lt;td&gt;‚ùå&lt;/td&gt;
    &lt;td&gt;26.6%&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;7.85&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;8.01&lt;/b&gt;&lt;/td&gt;&lt;td&gt;5.28&lt;/td&gt;&lt;td&gt;&lt;b&gt;8.44&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;3.83&lt;/td&gt;&lt;td&gt;3.68&lt;/td&gt;&lt;td&gt;3.71&lt;/td&gt;&lt;td&gt;3.61&lt;/td&gt;&lt;td&gt;3.45&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;ACE-Step&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;32.1%&lt;/td&gt;
    &lt;td&gt;7.19&lt;/td&gt;&lt;td&gt;7.37&lt;/td&gt;&lt;td&gt;6.16&lt;/td&gt;&lt;td&gt;7.57&lt;/td&gt;
    &lt;td&gt;3.59&lt;/td&gt;&lt;td&gt;3.34&lt;/td&gt;&lt;td&gt;3.43&lt;/td&gt;&lt;td&gt;3.36&lt;/td&gt;&lt;td&gt;3.27&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;Diffrhythm-v1.2&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;17.8%&lt;/td&gt;
    &lt;td&gt;7.02&lt;/td&gt;&lt;td&gt;7.58&lt;/td&gt;&lt;td&gt;5.96&lt;/td&gt;&lt;td&gt;7.81&lt;/td&gt;
    &lt;td&gt;3.51&lt;/td&gt;&lt;td&gt;3.12&lt;/td&gt;&lt;td&gt;3.32&lt;/td&gt;&lt;td&gt;3.21&lt;/td&gt;&lt;td&gt;3.08&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;YUE&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;27.3%&lt;/td&gt;
    &lt;td&gt;7.04&lt;/td&gt;&lt;td&gt;7.22&lt;/td&gt;&lt;td&gt;5.89&lt;/td&gt;&lt;td&gt;7.67&lt;/td&gt;
    &lt;td&gt;3.58&lt;/td&gt;&lt;td&gt;3.24&lt;/td&gt;&lt;td&gt;3.42&lt;/td&gt;&lt;td&gt;3.37&lt;/td&gt;&lt;td&gt;3.30&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;SongGeneration-base&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;-&lt;/td&gt;
    &lt;td&gt;-&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;
    &lt;td&gt;-&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;&lt;td&gt;-&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;SongGeneration-base-new&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;16.2%&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;7.78&lt;/b&gt;&lt;/td&gt;&lt;td&gt;7.97&lt;/td&gt;&lt;td&gt;6.03&lt;/td&gt;&lt;td&gt;8.37&lt;/td&gt;
    &lt;td&gt;4.05&lt;/td&gt;&lt;td&gt;3.90&lt;/td&gt;&lt;td&gt;3.99&lt;/td&gt;&lt;td&gt;3.91&lt;/td&gt;&lt;td&gt;3.79&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;SongGeneration-base-full&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;20.1%&lt;/td&gt;
    &lt;td&gt;7.76&lt;/td&gt;&lt;td&gt;7.98&lt;/td&gt;&lt;td&gt;5.96&lt;/td&gt;&lt;td&gt;8.39&lt;/td&gt;
    &lt;td&gt;4.02&lt;/td&gt;&lt;td&gt;3.87&lt;/td&gt;&lt;td&gt;3.97&lt;/td&gt;&lt;td&gt;3.86&lt;/td&gt;&lt;td&gt;3.74&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td&gt;SongGeneration-large&lt;/td&gt;
    &lt;td&gt;‚úÖ&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;14.9%&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;7.85&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;8.05&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;6.17&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;8.46&lt;/b&gt;&lt;/td&gt;
    &lt;td&gt;&lt;b&gt;4.08&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;3.94&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;4.03&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;3.93&lt;/b&gt;&lt;/td&gt;&lt;td&gt;&lt;b&gt;3.82&lt;/b&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

### Notes

1. The evaluation results of SongGeneration are based on **200 generated songs**, including **100 using descriptions** and **100 using `auto_prompt_audio_type=Auto`**. We also provide **40 English** and **40 Chinese** example inputs in
    `sample/test_en_input.jsonl` and `sample/test_zh_input.jsonl` for reference.
2. Since the model attempts to clone the timbre and musical style of the given prompt audio, the choice of prompt audio can significantly affect generation performance, and may lead to fluctuations in the evaluation metrics.
3. The format of the input lyrics has a strong impact on generation quality. If the output quality appears suboptimal, please check whether your lyrics format is correct. You can find more examples of properly forma

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[EbookFoundation/free-programming-books]]></title>
            <link>https://github.com/EbookFoundation/free-programming-books</link>
            <guid>https://github.com/EbookFoundation/free-programming-books</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[üìö Freely available programming books]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EbookFoundation/free-programming-books">EbookFoundation/free-programming-books</a></h1>
            <p>üìö Freely available programming books</p>
            <p>Language: Python</p>
            <p>Stars: 379,623</p>
            <p>Forks: 65,672</p>
            <p>Stars today: 92 stars today</p>
            <h2>README</h2><pre># List of Free Learning Resources In Many Languages

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)&amp;#160;
[![License: CC BY 4.0](https://img.shields.io/github/license/EbookFoundation/free-programming-books)](https://creativecommons.org/licenses/by/4.0/)&amp;#160;
[![Hacktoberfest 2025 stats](https://img.shields.io/github/hacktoberfest/2025/EbookFoundation/free-programming-books?label=Hacktoberfest+2025)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2025-10-01..2025-10-31)

&lt;/div&gt;

Search the list at [https://ebookfoundation.github.io/free-programming-books-search/](https://ebookfoundation.github.io/free-programming-books-search/) [![https://ebookfoundation.github.io/free-programming-books-search/](https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Dynamic%20search%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F)](https://ebookfoundation.github.io/free-programming-books-search/).

This page is available as an easy-to-read website. Access it by clicking on [![https://ebookfoundation.github.io/free-programming-books/](https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Static%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F)](https://ebookfoundation.github.io/free-programming-books/).

&lt;div align=&quot;center&quot;&gt;
  &lt;form action=&quot;https://ebookfoundation.github.io/free-programming-books-search&quot;&gt;
    &lt;input type=&quot;text&quot; id=&quot;fpbSearch&quot; name=&quot;search&quot; required placeholder=&quot;Search Book or Author&quot;/&gt;
    &lt;label for=&quot;submit&quot;&gt; &lt;/label&gt;
    &lt;input type=&quot;submit&quot; id=&quot;submit&quot; name=&quot;submit&quot; value=&quot;Search&quot; /&gt;
  &lt;/form&gt;
&lt;/div&gt;

## Intro

This list was originally a clone of [StackOverflow - List of Freely Available Programming Books](https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926) with contributions from Karan Bhangui and George Stocker.

The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of [GitHub&#039;s most popular repositories](https://octoverse.github.com/).

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![GitHub repo forks](https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Forks)](https://github.com/EbookFoundation/free-programming-books/network)&amp;#160;
[![GitHub repo stars](https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Stars)](https://github.com/EbookFoundation/free-programming-books/stargazers)&amp;#160;
[![GitHub repo contributors](https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Contributors)](https://github.com/EbookFoundation/free-programming-books/graphs/contributors)    
[![GitHub org sponsors](https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Sponsors)](https://github.com/sponsors/EbookFoundation)&amp;#160;
[![GitHub repo watchers](https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Watchers)](https://github.com/EbookFoundation/free-programming-books/watchers)&amp;#160;
[![GitHub repo size](https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Repo%20Size)](https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip)

&lt;/div&gt;

The [Free Ebook Foundation](https://ebookfoundation.org) now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. [Donations](https://ebookfoundation.org/contributions.html) to the Free Ebook Foundation are tax-deductible in the US.


## How To Contribute

Please read [CONTRIBUTING](docs/CONTRIBUTING.md). If you&#039;re new to GitHub, [welcome](docs/HOWTO.md)! Remember to abide by our adapted from ![Contributor Covenant 1.3](https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg) [Code of Conduct](docs/CODE_OF_CONDUCT.md) too ([translations](#translations) also available).

Click on these badges to see how you might be able to help:

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![GitHub repo Issues](https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=red&amp;label=Issues)](https://github.com/EbookFoundation/free-programming-books/issues)&amp;#160;
[![GitHub repo Good Issues for newbies](https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Good%20First%20issues)](https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)&amp;#160;
[![GitHub Help Wanted issues](https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20issues)](https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)    
[![GitHub repo PRs](https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=orange&amp;label=PRs)](https://github.com/EbookFoundation/free-programming-books/pulls)&amp;#160;
[![GitHub repo Merged PRs](https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Merged%20PRs&amp;query=is%3Amerged)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged)&amp;#160;
[![GitHub Help Wanted PRs](https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20PRs)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)

&lt;/div&gt;

## How To Share

&lt;div align=&quot;left&quot; markdown=&quot;1&quot;&gt;
&lt;a href=&quot;https://www.facebook.com/share.php?u=https%3A%2F%2Fgithub.com%2FEbookFoundation%2Ffree-programming-books&amp;p[images][0]=&amp;p[title]=Free%20Programming%20Books&amp;p[summary]=&quot;&gt;Share on Facebook&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://www.linkedin.com/shareArticle?mini=true&amp;url=https://github.com/EbookFoundation/free-programming-books&amp;title=Free%20Programming%20Books&amp;summary=&amp;source=&quot;&gt;Share on LinkedIn&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://toot.kytta.dev/?text=https://github.com/EbookFoundation/free-programming-books&quot;&gt;Share on Mastodon/Fediverse&lt;/a&gt;&lt;br&gt;    
&lt;a href=&quot;https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books&quot;&gt;Share on Telegram&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books&quot;&gt;Share on ùïè (Twitter)&lt;/a&gt;&lt;br&gt;
&lt;/div&gt;

## Resources

This project lists books and other resources grouped by genres:

### Books

[English, By Programming Language](books/free-programming-books-langs.md)

[English, By Subject](books/free-programming-books-subjects.md)

#### Other Languages

+ [Arabic / al arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](books/free-programming-books-ar.md)
+ [Armenian / ’Ä’°’µ’•÷Ä’•’∂](books/free-programming-books-hy.md)
+ [Azerbaijani / –ê–∑”ô—Ä–±–∞—ò“π–∞–Ω –¥–∏–ª–∏ / ÿ¢ÿ∞ÿ±ÿ®ÿßŸäÿ¨ÿßŸÜÿ¨ÿß ÿØŸäŸÑŸä](books/free-programming-books-az.md)
+ [Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](books/free-programming-books-bn.md)
+ [Bulgarian / –±—ä–ª–≥–∞—Ä—Å–∫–∏](books/free-programming-books-bg.md)
+ [Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨](books/free-programming-books-my.md)
+ [Chinese / ‰∏≠Êñá](books/free-programming-books-zh.md)
+ [Czech / ƒçe≈°tina / ƒçesk√Ω jazyk](books/free-programming-books-cs.md)
+ [Catalan / catalan / catal√†](books/free-programming-books-ca.md)
+ [Danish / dansk](books/free-programming-books-da.md)
+ [Dutch / Nederlands](books/free-programming-books-nl.md)
+ [Estonian / eesti keel](books/free-programming-books-et.md)
+ [Finnish / suomi / suomen kieli](books/free-programming-books-fi.md)
+ [French / fran√ßais](books/free-programming-books-fr.md)
+ [German / Deutsch](books/free-programming-books-de.md)
+ [Greek / ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨](books/free-programming-books-el.md)
+ [Hebrew / ◊¢◊ë◊®◊ô◊™](books/free-programming-books-he.md)
+ [Hindi / ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](books/free-programming-books-hi.md)
+ [Hungarian / magyar / magyar nyelv](books/free-programming-books-hu.md)
+ [Indonesian / Bahasa Indonesia](books/free-programming-books-id.md)
+ [Italian / italiano](books/free-programming-books-it.md)
+ [Japanese / Êó•Êú¨Ë™û](books/free-programming-books-ja.md)
+ [Korean / ÌïúÍµ≠Ïñ¥](books/free-programming-books-ko.md)
+ [Latvian / Latvie≈°u](books/free-programming-books-lv.md)
+ [Malayalam / ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç](books/free-programming-books-ml.md)
+ [Norwegian / Norsk](books/free-programming-books-no.md)
+ [Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ](books/free-programming-books-fa_IR.md)
+ [Polish / polski / jƒôzyk polski / polszczyzna](books/free-programming-books-pl.md)
+ [Portuguese (Brazil)](books/free-programming-books-pt_BR.md)
+ [Portuguese (Portugal)](books/free-programming-books-pt_PT.md)
+ [Romanian (Romania) / limba rom√¢nƒÉ / rom√¢n](books/free-programming-books-ro.md)
+ [Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫](books/free-programming-books-ru.md)
+ [Serbian / —Å—Ä–ø—Å–∫–∏ —ò–µ–∑–∏–∫ / srpski jezik](books/free-programming-books-sr.md)
+ [Slovak / slovenƒçina](books/free-programming-books-sk.md)
+ [Slovenian / Sloven≈°ƒçina](books/free-programming-books-sl.md)
+ [Spanish / espa√±ol / castellano](books/free-programming-books-es.md)
+ [Swedish / Svenska](books/free-programming-books-sv.md)
+ [Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç](books/free-programming-books-ta.md)
+ [Telugu / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å](books/free-programming-books-te.md)
+ [Thai / ‡πÑ‡∏ó‡∏¢](books/free-programming-books-th.md)
+ [Turkish / T√ºrk√ße](books/free-programming-books-tr.md)
+ [Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](books/free-programming-books-uk.md)
+ [Urdu / ÿßÿ±ÿØŸà](books/free-programming-books-ur.md)
+ [Vietnamese / Ti·∫øng Vi·ªát](books/free-programming-books-vi.md)

### Cheat Sheets

+ [All Languages](more/free-programming-cheatsheets.md)

### Free Online Courses

+ [Arabic / al arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](courses/free-courses-ar.md)
+ [Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](courses/free-courses-bn.md)
+ [Bulgarian / –±—ä–ª–≥–∞—Ä—Å–∫–∏](courses/free-courses-bg.md)
+ [Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨](courses/free-courses-my.md)
+ [Chinese / ‰∏≠Êñá](courses/free-courses-zh.md)
+ [English](courses/free-courses-en.md)
+ [Finnish / suomi / suomen kieli](courses/free-courses-fi.md)
+ [French / fran√ßais](courses/free-courses-fr.md)
+ [German / Deutsch](courses/free-courses-de.md)
+ [Greek / ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨](courses/free-courses-el.md)
+ [Hebrew / ◊¢◊ë◊®◊ô◊™](courses/free-courses-he.md)
+ [Hindi / ‡§π‡§ø‡§Ç‡§¶‡•Ä](courses/free-courses-hi.md)
+ [Indonesian / Bahasa Indonesia](courses/free-courses-id.md)
+ [Italian / italiano](courses/free-courses-it.md)
+ [Japanese / Êó•Êú¨Ë™û](courses/free-courses-ja.md)
+ [Kannada / ‡≤ï‡≤®‡≥ç‡≤®‡≤°](courses/free-courses-kn.md)
+ [Kazakh / “õ–∞–∑–∞“õ—à–∞](courses/free-courses-kk.md)
+ [Khmer / ·ûó·û∂·ûü·û∂·ûÅ·üí·ûò·üÇ·ûö](courses/free-courses-km.md)
+ [Korean / ÌïúÍµ≠Ïñ¥](courses/free-courses-ko.md)
+ [Malayalam / ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç](courses/free-courses-ml.md)
+ [Marathi / ‡§Æ‡§∞‡§æ‡§†‡•Ä](courses/free-courses-mr.md)
+ [Nepali / ‡§®‡•á‡§™‡§æ‡§≤‡•Ä](courses/free-courses-ne.md)
+ [Norwegian / Norsk](courses/free-courses-no.md)
+ [Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ](courses/free-courses-fa_IR.md)
+ [Polish / polski / jƒôzyk polski / polszczyzna](courses/free-courses-pl.md)
+ [Portuguese (Brazil)](courses/free-courses-pt_BR.md)
+ [Portuguese (Portugal)](courses/free-courses-pt_PT.md)
+ [Punjabi / ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä / ŸæŸÜÿ¨ÿßÿ®€å](courses/free-courses-pa.md)
+ [Romanian (Romania) / limba rom√¢nƒÉ / rom√¢n](courses/free-courses-ro.md)
+ [Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫](courses/free-courses-ru.md)
+ [Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω](courses/free-courses-si.md)
+ [Spanish / espa√±ol / castellano](courses/free-courses-es.md)
+ [Swedish / svenska](courses/free-courses-sv.md)
+ [Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç](courses/free-courses-ta.md)
+ [Telugu / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å](courses/free-courses-te.md)
+ [Thai / ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢](courses/free-courses-th.md)
+ [Turkish / T√ºrk√ße](courses/free-courses-tr.md)
+ [Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](courses/free-courses-uk.md)
+ [Urdu / ÿßÿ±ÿØŸà](courses/free-courses-ur.md)
+ [Vietnamese / Ti·∫øng Vi·ªát](courses/free-courses-vi.md)


### Interactive Programming Resources

+ [Chinese / ‰∏≠Êñá](more/free-programming-interactive-tutorials-zh.md)
+ [English](more/free-programming-interactive-tutorials-en.md)
+ [German / Deutsch](more/free-programming-interactive-tutorials-de.md)
+ [Japanese / Êó•Êú¨Ë™û](more/free-programming-interactive-tutorials-ja.md)
+ [Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫](more/free-programming-interactive-tutorials-ru.md)


### Problem Sets and Competitive Programming

+ [Problem Sets](more/problem-sets-competitive-programming.md)


### Podcast - Screencast

Free Podcasts and Screencasts:

+ [Arabic / al Arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](casts/free-podcasts-screencasts-ar.md)
+ [Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨](casts/free-podcasts-screencasts-my.md)
+ [Chinese / ‰∏≠Êñá](casts/free-podcasts-screencasts-zh.md)
+ [Czech / ƒçe≈°tina / ƒçesk√Ω jazyk](casts/free-podcasts-screencasts-cs.md)
+ [Dutch / Nederlands](casts/free-podcasts-screencasts-nl.md)
+ [English](casts/free-podcasts-screencasts-en.md)
+ [Finnish / Suomi](casts/free-podcasts-screencasts-fi.md)
+ [French / fran√ßais](casts/free-podcasts-screencasts-fr.md)
+ [German / Deutsch](casts/free-podcasts-screencasts-de.md)
+ [Hebrew / ◊¢◊ë◊®◊ô◊™](casts/free-podcasts-screencasts-he.md)
+ [Indonesian / Bahasa Indonesia](casts/free-podcasts-screencasts-id.md)
+ [Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ](casts/free-podcasts-screencasts-fa_IR.md)
+ [Polish / polski / jƒôzyk polski / polszczyzna](casts/free-podcasts-screencasts-pl.md)
+ [Portuguese (Brazil)](casts/free-podcasts-screencasts-pt_BR.md)
+ [Portuguese (Portugal)](casts/free-podcasts-screencasts-pt_PT.md)
+ [Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫](casts/free-podcasts-screencasts-ru.md)
+ [Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω](casts/free-podcasts-screencasts-si.md)
+ [Spanish / espa√±ol / castellano](casts/free-podcasts-screencasts-es.md)
+ [Swedish / Svenska](casts/free-podcasts-screencasts-sv.md)
+ [Turkish / T√ºrk√ße](casts/free-podcasts-screencasts-tr.md)
+ [Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](casts/free-podcasts-screencasts-uk.md)


### Programming Playgrounds

Write, compile, and run your code within a browser. Try it out!

+ [Chinese / ‰∏≠Êñá](more/free-programming-playgrounds-zh.md)
+ [English](more/free-programming-playgrounds.md)
+ [German / Deutsch](more/free-programming-playgrounds-de.md)

## Translations

Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.

+ English
  + [Code of Conduct](docs/CODE_OF_CONDUCT.md)
  + [Contributing](docs/CONTRIBUTING.md)
  + [How-to](docs/HOWTO.md)
+ ... *[More languages](docs/README.md#translations)* ...

You might notice that there are [some missing translations here](docs/README.md#translations) - perhaps you would like to help out by [contributing a translation](docs/CONTRIBUTING.md#help-out-by-contributing-a-translation)?


## License

Each file included in this repository is licensed under the [CC BY License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[vllm-project/vllm]]></title>
            <link>https://github.com/vllm-project/vllm</link>
            <guid>https://github.com/vllm-project/vllm</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[A high-throughput and memory-efficient inference and serving engine for LLMs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vllm-project/vllm">vllm-project/vllm</a></h1>
            <p>A high-throughput and memory-efficient inference and serving engine for LLMs</p>
            <p>Language: Python</p>
            <p>Stars: 66,556</p>
            <p>Forks: 12,303</p>
            <p>Stars today: 94 stars today</p>
            <h2>README</h2><pre>&lt;!-- markdownlint-disable MD001 MD041 --&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-dark.png&quot;&gt;
    &lt;img alt=&quot;vLLM&quot; src=&quot;https://raw.githubusercontent.com/vllm-project/vllm/main/docs/assets/logos/vllm-logo-text-light.png&quot; width=55%&gt;
  &lt;/picture&gt;
&lt;/p&gt;

&lt;h3 align=&quot;center&quot;&gt;
Easy, fast, and cheap LLM serving for everyone
&lt;/h3&gt;

&lt;p align=&quot;center&quot;&gt;
| &lt;a href=&quot;https://docs.vllm.ai&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://blog.vllm.ai/&quot;&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://arxiv.org/abs/2309.06180&quot;&gt;&lt;b&gt;Paper&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://x.com/vllm_project&quot;&gt;&lt;b&gt;Twitter/X&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://discuss.vllm.ai&quot;&gt;&lt;b&gt;User Forum&lt;/b&gt;&lt;/a&gt; | &lt;a href=&quot;https://slack.vllm.ai&quot;&gt;&lt;b&gt;Developer Slack&lt;/b&gt;&lt;/a&gt; |
&lt;/p&gt;

üî• We have built a vllm website to help you get started with vllm. Please visit [vllm.ai](https://vllm.ai) to learn more.
For events, please visit [vllm.ai/events](https://vllm.ai/events) to join us.

---

## About

vLLM is a fast and easy-to-use library for LLM inference and serving.

Originally developed in the [Sky Computing Lab](https://sky.cs.berkeley.edu) at UC Berkeley, vLLM has evolved into a community-driven project with contributions from both academia and industry.

vLLM is fast with:

- State-of-the-art serving throughput
- Efficient management of attention key and value memory with [**PagedAttention**](https://blog.vllm.ai/2023/06/20/vllm.html)
- Continuous batching of incoming requests
- Fast model execution with CUDA/HIP graph
- Quantizations: [GPTQ](https://arxiv.org/abs/2210.17323), [AWQ](https://arxiv.org/abs/2306.00978), [AutoRound](https://arxiv.org/abs/2309.05516), INT4, INT8, and FP8
- Optimized CUDA kernels, including integration with FlashAttention and FlashInfer
- Speculative decoding
- Chunked prefill

vLLM is flexible and easy to use with:

- Seamless integration with popular Hugging Face models
- High-throughput serving with various decoding algorithms, including *parallel sampling*, *beam search*, and more
- Tensor, pipeline, data and expert parallelism support for distributed inference
- Streaming outputs
- OpenAI-compatible API server
- Support for NVIDIA GPUs, AMD CPUs and GPUs, Intel CPUs and GPUs, PowerPC CPUs, Arm CPUs, and TPU. Additionally, support for diverse hardware plugins such as Intel Gaudi, IBM Spyre and Huawei Ascend.
- Prefix caching support
- Multi-LoRA support

vLLM seamlessly supports most popular open-source models on HuggingFace, including:

- Transformer-like LLMs (e.g., Llama)
- Mixture-of-Expert LLMs (e.g., Mixtral, Deepseek-V2 and V3)
- Embedding Models (e.g., E5-Mistral)
- Multi-modal LLMs (e.g., LLaVA)

Find the full list of supported models [here](https://docs.vllm.ai/en/latest/models/supported_models.html).

## Getting Started

Install vLLM with `pip` or [from source](https://docs.vllm.ai/en/latest/getting_started/installation/gpu/index.html#build-wheel-from-source):

```bash
pip install vllm
```

Visit our [documentation](https://docs.vllm.ai/en/latest/) to learn more.

- [Installation](https://docs.vllm.ai/en/latest/getting_started/installation.html)
- [Quickstart](https://docs.vllm.ai/en/latest/getting_started/quickstart.html)
- [List of Supported Models](https://docs.vllm.ai/en/latest/models/supported_models.html)

## Contributing

We welcome and value any contributions and collaborations.
Please check out [Contributing to vLLM](https://docs.vllm.ai/en/latest/contributing/index.html) for how to get involved.

## Citation

If you use vLLM for your research, please cite our [paper](https://arxiv.org/abs/2309.06180):

```bibtex
@inproceedings{kwon2023efficient,
  title={Efficient Memory Management for Large Language Model Serving with PagedAttention},
  author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
  booktitle={Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year={2023}
}
```

## Contact Us

&lt;!-- --8&lt;-- [start:contact-us] --&gt;
- For technical questions and feature requests, please use GitHub [Issues](https://github.com/vllm-project/vllm/issues)
- For discussing with fellow users, please use the [vLLM Forum](https://discuss.vllm.ai)
- For coordinating contributions and development, please use [Slack](https://slack.vllm.ai)
- For security disclosures, please use GitHub&#039;s [Security Advisories](https://github.com/vllm-project/vllm/security/advisories) feature
- For collaborations and partnerships, please contact us at [collaboration@vllm.ai](mailto:collaboration@vllm.ai)
&lt;!-- --8&lt;-- [end:contact-us] --&gt;

## Media Kit

- If you wish to use vLLM&#039;s logo, please refer to [our media kit repo](https://github.com/vllm-project/media-kit)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sansan0/TrendRadar]]></title>
            <link>https://github.com/sansan0/TrendRadar</link>
            <guid>https://github.com/sansan0/TrendRadar</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[üéØ ÂëäÂà´‰ø°ÊÅØËøáËΩΩÔºåAI Âä©‰Ω†ÁúãÊáÇÊñ∞ÈóªËµÑËÆØÁÉ≠ÁÇπÔºåÊîØÊåÅ RSS ËÆ¢ÈòÖÔºåÁÆÄÂçïÁöÑËàÜÊÉÖÁõëÊéßÂàÜÊûê - Â§öÂπ≥Âè∞ÁÉ≠ÁÇπËÅöÂêà+Âü∫‰∫é MCP ÁöÑAIÂàÜÊûêÂ∑•ÂÖ∑„ÄÇÁõëÊéß35‰∏™Âπ≥Âè∞ÔºàÊäñÈü≥„ÄÅÁü•‰πé„ÄÅBÁ´ô„ÄÅÂçéÂ∞îË°óËßÅÈóª„ÄÅË¥¢ËÅîÁ§æÁ≠âÔºâÔºåÊô∫ËÉΩÁ≠õÈÄâ+Ëá™Âä®Êé®ÈÄÅ+AIÂØπËØùÂàÜÊûêÔºàÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊ∑±Â∫¶ÊåñÊéòÊñ∞ÈóªÔºöË∂ãÂäøËøΩË∏™„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅÁõ∏‰ººÊ£ÄÁ¥¢Á≠â20ÁßçÂ∑•ÂÖ∑Ôºâ„ÄÇÊîØÊåÅ‰ºÅ‰∏öÂæÆ‰ø°/‰∏™‰∫∫ÂæÆ‰ø°/È£û‰π¶/ÈíâÈíâ/Telegram/ÈÇÆ‰ª∂/ntfy/bark/slack Êé®ÈÄÅÔºå30ÁßíÂø´ÈÄüÈÉ®ÁΩ≤Ôºå1ÂàÜÈíüÊâãÊú∫ÈÄöÁü•ÔºåÊó†ÈúÄÁºñÁ®ã„ÄÇÊîØÊåÅDockerÈÉ®ÁΩ≤ÔºåÊîØÊåÅÊï∞ÊçÆËøúÁ®ã‰∫ëÂ≠òÂÇ®‚≠ê ËÆ©ÁÆóÊ≥ï‰∏∫‰Ω†ÊúçÂä°ÔºåÁî®AIÁêÜËß£ÁÉ≠ÁÇπ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sansan0/TrendRadar">sansan0/TrendRadar</a></h1>
            <p>üéØ ÂëäÂà´‰ø°ÊÅØËøáËΩΩÔºåAI Âä©‰Ω†ÁúãÊáÇÊñ∞ÈóªËµÑËÆØÁÉ≠ÁÇπÔºåÊîØÊåÅ RSS ËÆ¢ÈòÖÔºåÁÆÄÂçïÁöÑËàÜÊÉÖÁõëÊéßÂàÜÊûê - Â§öÂπ≥Âè∞ÁÉ≠ÁÇπËÅöÂêà+Âü∫‰∫é MCP ÁöÑAIÂàÜÊûêÂ∑•ÂÖ∑„ÄÇÁõëÊéß35‰∏™Âπ≥Âè∞ÔºàÊäñÈü≥„ÄÅÁü•‰πé„ÄÅBÁ´ô„ÄÅÂçéÂ∞îË°óËßÅÈóª„ÄÅË¥¢ËÅîÁ§æÁ≠âÔºâÔºåÊô∫ËÉΩÁ≠õÈÄâ+Ëá™Âä®Êé®ÈÄÅ+AIÂØπËØùÂàÜÊûêÔºàÁî®Ëá™ÁÑ∂ËØ≠Ë®ÄÊ∑±Â∫¶ÊåñÊéòÊñ∞ÈóªÔºöË∂ãÂäøËøΩË∏™„ÄÅÊÉÖÊÑüÂàÜÊûê„ÄÅÁõ∏‰ººÊ£ÄÁ¥¢Á≠â20ÁßçÂ∑•ÂÖ∑Ôºâ„ÄÇÊîØÊåÅ‰ºÅ‰∏öÂæÆ‰ø°/‰∏™‰∫∫ÂæÆ‰ø°/È£û‰π¶/ÈíâÈíâ/Telegram/ÈÇÆ‰ª∂/ntfy/bark/slack Êé®ÈÄÅÔºå30ÁßíÂø´ÈÄüÈÉ®ÁΩ≤Ôºå1ÂàÜÈíüÊâãÊú∫ÈÄöÁü•ÔºåÊó†ÈúÄÁºñÁ®ã„ÄÇÊîØÊåÅDockerÈÉ®ÁΩ≤ÔºåÊîØÊåÅÊï∞ÊçÆËøúÁ®ã‰∫ëÂ≠òÂÇ®‚≠ê ËÆ©ÁÆóÊ≥ï‰∏∫‰Ω†ÊúçÂä°ÔºåÁî®AIÁêÜËß£ÁÉ≠ÁÇπ</p>
            <p>Language: Python</p>
            <p>Stars: 41,591</p>
            <p>Forks: 21,107</p>
            <p>Stars today: 338 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; id=&quot;trendradar&quot;&gt;

&lt;a href=&quot;https://github.com/sansan0/TrendRadar&quot; title=&quot;TrendRadar&quot;&gt;
  &lt;img src=&quot;/_image/banner.webp&quot; alt=&quot;TrendRadar Banner&quot; width=&quot;80%&quot;&gt;
&lt;/a&gt;

üöÄ ÊúÄÂø´&lt;strong&gt;30Áßí&lt;/strong&gt;ÈÉ®ÁΩ≤ÁöÑÁÉ≠ÁÇπÂä©Êâã ‚Äî‚Äî ÂëäÂà´Êó†ÊïàÂà∑Â±èÔºåÂè™ÁúãÁúüÊ≠£ÂÖ≥ÂøÉÁöÑÊñ∞ÈóªËµÑËÆØ

&lt;a href=&quot;https://trendshift.io/repositories/14726&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14726&quot; alt=&quot;sansan0%2FTrendRadar | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;a href=&quot;https://shandianshuo.cn&quot; target=&quot;_blank&quot; title=&quot;AI ËØ≠Èü≥ËæìÂÖ•ÔºåÊØîÊâìÂ≠óÂø´ 4 ÂÄç ‚ö°&quot;&gt;&lt;img src=&quot;_image/shandianshuo.png&quot; alt=&quot;Èó™ÁîµËØ¥ logo&quot; height=&quot;50&quot;/&gt;&lt;/a&gt;

[![GitHub Stars](https://img.shields.io/github/stars/sansan0/TrendRadar?style=flat-square&amp;logo=github&amp;color=yellow)](https://github.com/sansan0/TrendRadar/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/sansan0/TrendRadar?style=flat-square&amp;logo=github&amp;color=blue)](https://github.com/sansan0/TrendRadar/network/members)
[![License](https://img.shields.io/badge/license-GPL--3.0-blue.svg?style=flat-square)](LICENSE)
[![Version](https://img.shields.io/badge/version-v4.5.0-blue.svg)](https://github.com/sansan0/TrendRadar)
[![MCP](https://img.shields.io/badge/MCP-v2.0.0-green.svg)](https://github.com/sansan0/TrendRadar)
[![RSS](https://img.shields.io/badge/RSS-ËÆ¢ÈòÖÊ∫êÊîØÊåÅ-orange.svg?style=flat-square&amp;logo=rss&amp;logoColor=white)](https://github.com/sansan0/TrendRadar)

[![‰ºÅ‰∏öÂæÆ‰ø°ÈÄöÁü•](https://img.shields.io/badge/‰ºÅ‰∏öÂæÆ‰ø°-ÈÄöÁü•-00D4AA?style=flat-square)](https://work.weixin.qq.com/)
[![‰∏™‰∫∫ÂæÆ‰ø°ÈÄöÁü•](https://img.shields.io/badge/‰∏™‰∫∫ÂæÆ‰ø°-ÈÄöÁü•-00D4AA?style=flat-square)](https://weixin.qq.com/)
[![TelegramÈÄöÁü•](https://img.shields.io/badge/Telegram-ÈÄöÁü•-00D4AA?style=flat-square)](https://telegram.org/)
[![dingtalkÈÄöÁü•](https://img.shields.io/badge/ÈíâÈíâ-ÈÄöÁü•-00D4AA?style=flat-square)](#)
[![È£û‰π¶ÈÄöÁü•](https://img.shields.io/badge/È£û‰π¶-ÈÄöÁü•-00D4AA?style=flat-square)](https://www.feishu.cn/)
[![ÈÇÆ‰ª∂ÈÄöÁü•](https://img.shields.io/badge/Email-ÈÄöÁü•-00D4AA?style=flat-square)](#)
[![ntfyÈÄöÁü•](https://img.shields.io/badge/ntfy-ÈÄöÁü•-00D4AA?style=flat-square)](https://github.com/binwiederhier/ntfy)
[![BarkÈÄöÁü•](https://img.shields.io/badge/Bark-ÈÄöÁü•-00D4AA?style=flat-square)](https://github.com/Finb/Bark)
[![SlackÈÄöÁü•](https://img.shields.io/badge/Slack-ÈÄöÁü•-00D4AA?style=flat-square)](https://slack.com/)


[![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-Ëá™Âä®Âåñ-2088FF?style=flat-square&amp;logo=github-actions&amp;logoColor=white)](https://github.com/sansan0/TrendRadar)
[![GitHub Pages](https://img.shields.io/badge/GitHub_Pages-ÈÉ®ÁΩ≤-4285F4?style=flat-square&amp;logo=github&amp;logoColor=white)](https://sansan0.github.io/TrendRadar)
[![Docker](https://img.shields.io/badge/Docker-ÈÉ®ÁΩ≤-2496ED?style=flat-square&amp;logo=docker&amp;logoColor=white)](https://hub.docker.com/r/wantcat/trendradar)
[![MCP Support](https://img.shields.io/badge/MCP-AIÂàÜÊûêÊîØÊåÅ-FF6B6B?style=flat-square&amp;logo=ai&amp;logoColor=white)](https://modelcontextprotocol.io/)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

**‰∏≠Êñá** | **[English](README-EN.md)**

&lt;/div&gt;

&gt; Êú¨È°πÁõÆ‰ª•ËΩªÈáèÔºåÊòìÈÉ®ÁΩ≤‰∏∫ÁõÆÊ†á

## üìë Âø´ÈÄüÂØºËà™

&lt;div align=&quot;center&quot;&gt;

| [üöÄ Âø´ÈÄüÂºÄÂßã](#-Âø´ÈÄüÂºÄÂßã) | [ü§ñ AI Êô∫ËÉΩÂàÜÊûê](#-ai-Êô∫ËÉΩÂàÜÊûê) | [‚öôÔ∏è ÈÖçÁΩÆËØ¶Ëß£](#ÈÖçÁΩÆËØ¶Ëß£) | [üìù Êõ¥Êñ∞Êó•Âøó](#-Êõ¥Êñ∞Êó•Âøó) | [‚ùì Á≠îÁñë‰∏é‰∫§ÊµÅ](#ÈóÆÈ¢òÁ≠îÁñë‰∏é‰∫§ÊµÅ) |
|:---:|:---:|:---:|:---:|:---:|
| [üê≥ DockerÈÉ®ÁΩ≤](#6-docker-ÈÉ®ÁΩ≤) | [üîå MCPÂÆ¢Êà∑Á´Ø](#-mcp-ÂÆ¢Êà∑Á´Ø) | [üìö È°πÁõÆÁõ∏ÂÖ≥](#-È°πÁõÆÁõ∏ÂÖ≥) | | |

&lt;/div&gt;

- ÊÑüË∞¢**ËÄêÂøÉÂèçÈ¶à bug** ÁöÑË¥°ÁåÆËÄÖÔºå‰Ω†‰ª¨ÁöÑÊØè‰∏ÄÊù°ÂèçÈ¶àËÆ©È°πÁõÆÊõ¥Âä†ÂÆåÂñÑüòâ;  
- ÊÑüË∞¢**‰∏∫È°πÁõÆÁÇπ star** ÁöÑËßÇ‰ºó‰ª¨Ôºå**fork** ‰Ω†ÊâÄÊ¨≤‰πüÔºå**star** ÊàëÊâÄÊ¨≤‰πüÔºå‰∏§ËÄÖÂæóÂÖºüòçÊòØÂØπÂºÄÊ∫êÁ≤æÁ•ûÊúÄÂ•ΩÁöÑÊîØÊåÅ; 
- ÊÑüË∞¢**ÂÖ≥Ê≥®[ÂÖ¨‰ºóÂè∑](#ÈóÆÈ¢òÁ≠îÁñë‰∏é‰∫§ÊµÅ)** ÁöÑËØªËÄÖ‰ª¨Ôºå‰Ω†‰ª¨ÁöÑÁïôË®Ä„ÄÅÁÇπËµû„ÄÅÂàÜ‰∫´ÂíåÊé®ËçêÁ≠âÁßØÊûÅ‰∫íÂä®ËÆ©ÂÜÖÂÆπÊõ¥ÊúâÊ∏©Â∫¶üòé„ÄÇ 

&lt;details&gt;
&lt;summary&gt;üëâ ÁÇπÂáªÂ±ïÂºÄÔºö&lt;strong&gt;Ëá¥Ë∞¢ÂêçÂçï&lt;/strong&gt; (ÂΩìÂâç &lt;strong&gt;üî•73üî•&lt;/strong&gt; ‰Ωç)&lt;/summary&gt;

### Âü∫Á°ÄËÆæÊñΩÊîØÊåÅ

ÊÑüË∞¢ **GitHub** ÂÖçË¥πÊèê‰æõÁöÑÂü∫Á°ÄËÆæÊñΩÔºåËøôÊòØÊú¨È°πÁõÆÂæó‰ª•**‰∏ÄÈîÆ fork**‰æøÊç∑ËøêË°åÁöÑÊúÄÂ§ßÂâçÊèê„ÄÇ

### Êï∞ÊçÆÊîØÊåÅ

Êú¨È°πÁõÆ‰ΩøÁî® [newsnow](https://github.com/ourongxing/newsnow) È°πÁõÆÁöÑ API Ëé∑ÂèñÂ§öÂπ≥Âè∞Êï∞ÊçÆÔºåÁâπÂà´ÊÑüË∞¢‰ΩúËÄÖÊèê‰æõÁöÑÊúçÂä°„ÄÇ

ÁªèËÅîÁ≥ªÔºå‰ΩúËÄÖË°®Á§∫Êó†ÈúÄÊãÖÂøÉÊúçÂä°Âô®ÂéãÂäõÔºå‰ΩÜËøôÊòØÂü∫‰∫é‰ªñÁöÑÂñÑÊÑèÂíå‰ø°‰ªª„ÄÇËØ∑Â§ßÂÆ∂Ôºö
- **ÂâçÂæÄ [newsnow È°πÁõÆ](https://github.com/ourongxing/newsnow) ÁÇπ star ÊîØÊåÅ**
- Docker ÈÉ®ÁΩ≤Êó∂ÔºåËØ∑ÂêàÁêÜÊéßÂà∂Êé®ÈÄÅÈ¢ëÁéáÔºåÂãøÁ´≠Ê≥ΩËÄåÊ∏î

### Êé®ÂπøÂä©Âäõ

&gt; ÊÑüË∞¢‰ª•‰∏ãÂπ≥Âè∞Âíå‰∏™‰∫∫ÁöÑÊé®Ëçê(ÊåâÊó∂Èó¥ÊéíÂàó)

- [Â∞è‰ºóËΩØ‰ª∂](https://mp.weixin.qq.com/s/fvutkJ_NPUelSW9OGK39aA) - ÂºÄÊ∫êËΩØ‰ª∂Êé®ËçêÂπ≥Âè∞
- [LinuxDo Á§æÂå∫](https://linux.do/) - ÊäÄÊúØÁà±Â•ΩËÄÖÁöÑËÅöÈõÜÂú∞
- [ÈòÆ‰∏ÄÂ≥∞Âë®Âàä](https://github.com/ruanyf/weekly) - ÊäÄÊúØÂúàÊúâÂΩ±ÂìçÂäõÁöÑÂë®Âàä

### ËßÇ‰ºóÊîØÊåÅ

&gt; ÊÑüË∞¢**Áªô‰∫àËµÑÈáëÊîØÊåÅ**ÁöÑÊúãÂèã‰ª¨Ôºå‰Ω†‰ª¨ÁöÑÊÖ∑ÊÖ®Â∑≤ÂåñË∫´‰∏∫ÈîÆÁõòÊóÅÁöÑÈõ∂È£üÈ•ÆÊñôÔºåÈô™‰º¥ÁùÄÈ°πÁõÆÁöÑÊØè‰∏ÄÊ¨°Ëø≠‰ª£„ÄÇ
&gt;
&gt; **&quot;‰∏ÄÂÖÉÁÇπËµû&quot;Â∑≤ÊöÇÂÅú**ÔºåÂ¶Ç‰ªçÊÉ≥ÊîØÊåÅ‰ΩúËÄÖÔºåÂèØÂâçÂæÄ[ÂÖ¨‰ºóÂè∑](#ÈóÆÈ¢òÁ≠îÁñë‰∏é‰∫§ÊµÅ)ÊñáÁ´†Â∫ïÈÉ®ÁÇπÂáª&quot;ÂñúÊ¨¢‰ΩúËÄÖ&quot;„ÄÇ
&gt;
&gt; ‰∏Ä‰ΩçÂèØÁà±Áå´Â§¥ÂÉèÁöÑÊúãÂèãÔºå‰∏çÁü•‰Ω†‰ªéÂì™‰∏™ËßíËêΩÁøªÂà∞‰∫ÜÊàëÁöÑÊî∂Ê¨æÁ†ÅÔºå‰∏âËøû‰∫Ü 1.8ÔºåÂøÉÊÑèÂ∑≤Êî∂Âà∞ÔºåÊÑüË∞¢ÂéöÁà±

|           ÁÇπËµû‰∫∫            |  ÈáëÈ¢ù  |  Êó•Êúü  |             Â§áÊ≥®             |
| :-------------------------: | :----: | :----: | :-----------------------: |
|           D*5          |  1.8 * 3 | 2025.11.24  |    | 
|           *È¨º          |  1 | 2025.11.17  |    | 
|           *Ë∂Ö          |  10 | 2025.11.17  |    | 
|           R*w          |  10 | 2025.11.17  | Ëøô agent ÂÅöÁöÑÁâõÈÄºÂïä,ÂÖÑÂºü    | 
|           J*o          |  1 | 2025.11.17  | ÊÑüË∞¢ÂºÄÊ∫ê,Á•ùÂ§ß‰Ω¨‰∫ã‰∏öÊúâÊàê    | 
|           *Êô®          |  8.88  | 2025.11.16  | È°πÁõÆ‰∏çÈîô,Á†îÁ©∂Â≠¶‰π†‰∏≠    | 
|           *Êµ∑          |  1  | 2025.11.15  |    | 
|           *Âæ∑          |  1.99  | 2025.11.15  |    | 
|           *Áñè          |  8.8  | 2025.11.14  |  ÊÑüË∞¢ÂºÄÊ∫êÔºåÈ°πÁõÆÂæàÊ£íÔºåÊîØÊåÅ‰∏Ä‰∏ã   | 
|           M*e          |  10  | 2025.11.14  |  ÂºÄÊ∫ê‰∏çÊòìÔºåÂ§ß‰Ω¨ËæõËã¶‰∫Ü   | 
|           **ÊüØ          |  1  | 2025.11.14  |     | 
|           *‰∫ë          |  88  | 2025.11.13  |    Â•ΩÈ°πÁõÆÔºåÊÑüË∞¢ÂºÄÊ∫ê  | 
|           *W          |  6  | 2025.11.13  |      | 
|           *ÂáØ          |  1  | 2025.11.13  |      | 
|           ÂØπ*.          |  1  | 2025.11.13  |    Thanks for your TrendRadar  | 
|           s*y          |  1  | 2025.11.13  |      | 
|           **Áøî          |  10  | 2025.11.13  |   Â•ΩÈ°πÁõÆÔºåÁõ∏ËßÅÊÅ®ÊôöÔºåÊÑüË∞¢ÂºÄÊ∫êÔºÅ     | 
|           *Èü¶          |  9.9  | 2025.11.13  |   TrendRadarË∂ÖËµûÔºåËØ∑ËÄÅÂ∏àÂñùÂíñÂï°~     | 
|           h*p          |  5  | 2025.11.12  |   ÊîØÊåÅ‰∏≠ÂõΩÂºÄÊ∫êÂäõÈáèÔºåÂä†Ê≤πÔºÅ     | 
|           c*r          |  6  | 2025.11.12  |        | 
|           a*n          |  5  | 2025.11.12  |        | 
|           „ÄÇ*c          |  1  | 2025.11.12  |    ÊÑüË∞¢ÂºÄÊ∫êÂàÜ‰∫´    | 
|           *ËÆ∞          |  1  | 2025.11.11  |        | 
|           *‰∏ª          |  1  | 2025.11.10  |        | 
|           *‰∫Ü          |  10  | 2025.11.09  |        | 
|           *Êù∞          |  5  | 2025.11.08  |        | 
|           *ÁÇπ          |  8.80  | 2025.11.07  |   ÂºÄÂèë‰∏çÊòìÔºåÊîØÊåÅ‰∏Ä‰∏ã„ÄÇ     | 
|           Q*Q          |  6.66  | 2025.11.07  |   ÊÑüË∞¢ÂºÄÊ∫êÔºÅ     | 
|           C*e          |  1  | 2025.11.05  |        | 
|           Peter Fan          |  20  | 2025.10.29  |        | 
|           M*n          |  1  | 2025.10.27  |      ÊÑüË∞¢ÂºÄÊ∫ê  | 
|           *ËÆ∏          |  8.88  | 2025.10.23  |      ËÄÅÂ∏à Â∞èÁôΩ‰∏ÄÊûöÔºåÊë∏‰∫ÜÂá†Â§©‰∫ÜËøòÊ≤°Êï¥Ëµ∑Êù•ÔºåÊ±ÇÊïô  | 
|           Eason           |  1  | 2025.10.22  |      ËøòÊ≤°Êï¥ÊòéÁôΩÔºå‰ΩÜ‰Ω†Âú®ÂÅöÂ•Ω‰∫ã  | 
|           P*n           |  1  | 2025.10.20  |          |
|           *Êù∞           |  1  | 2025.10.19  |          |
|           *Âæê           |  1  | 2025.10.18  |          |
|           *Âøó           |  1  | 2025.10.17  |          |
|           *üòÄ           |  10  | 2025.10.16  |     ÁÇπËµû     |
|           **Êù∞           |  10  | 2025.10.16  |          |
|           *Âï∏           |  10  | 2025.10.16  |          |
|           *Á∫™           |  5  | 2025.10.14  | TrendRadar         |
|           J*d           |  1  | 2025.10.14  | Ë∞¢Ë∞¢‰Ω†ÁöÑÂ∑•ÂÖ∑ÔºåÂæàÂ•ΩÁé©...          |
|           *H           |  1  | 2025.10.14  |           |
|           ÈÇ£*O           |  10  | 2025.10.13  |           |
|           *ÂúÜ           |  1  | 2025.10.13  |           |
|           P*g           |  6  | 2025.10.13  |           |
|           Ocean           |  20  | 2025.10.12  |  ...ÁúüÁöÑÂ§™Ê£í‰∫ÜÔºÅÔºÅÔºÅÂ∞èÁôΩÁ∫ßÂà´‰πüËÉΩÁõ¥Êé•Áî®...         |
|           **Âüπ           |  5.2  | 2025.10.2  |  github-yzyf1312:ÂºÄÊ∫ê‰∏áÂ≤Å         |
|           *Ê§ø           |  3  | 2025.9.23  |  Âä†Ê≤πÔºåÂæà‰∏çÈîô         |
|           *üçç           |  10  | 2025.9.21  |           |
|           E*f           |  1  | 2025.9.20  |           |
|           *ËÆ∞            |  1  | 2025.9.20  |           |
|           z*u            |  2  | 2025.9.19  |           |
|           **Êòä            |  5  | 2025.9.17  |           |
|           *Âè∑            |  1  | 2025.9.15  |           |
|           T*T            |  2  | 2025.9.15  |  ÁÇπËµû         |
|           *ÂÆ∂            |  10  | 2025.9.10  |           |
|           *X            |  1.11  | 2025.9.3  |           |
|           *È£ô            |  20  | 2025.8.31  |  Êù•Ëá™ËÄÅÁ´•Ë∞¢Ë∞¢         |
|           *‰∏ã            |  1  | 2025.8.30  |           |
|           2*D            |  88  | 2025.8.13 ‰∏ãÂçà |           |
|           2*D            |  1  | 2025.8.13 ‰∏äÂçà |           |
|           S*o            |  1  | 2025.8.05 |   ÊîØÊåÅ‰∏Ä‰∏ã        |
|           *‰æ†            |  10  | 2025.8.04 |           |
|           x*x            |  2  | 2025.8.03 |  trendRadar Â•ΩÈ°πÁõÆ ÁÇπËµû          |
|           *Ëøú            |  1  | 2025.8.01 |            |
|           *ÈÇ™            |  5  | 2025.8.01 |            |
|           *Ê¢¶            |  0.1  | 2025.7.30 |            |
|           **Èæô            |  10  | 2025.7.29 |      ÊîØÊåÅ‰∏Ä‰∏ã      |


&lt;/details&gt;

&lt;br&gt;

## ü™Ñ ËµûÂä©ÂïÜ

&gt; ÊØèÂ§©ÂÜôÊä•Âëä„ÄÅÂõûÂ§çÊ∂àÊÅØÊòØÂê¶ËÆ©ÊâãËÖïÁñ≤ÊÉ´ÔºüËØïËØï„ÄåÈó™ÁîµËØ¥„ÄçAI ËØ≠Èü≥ËæìÂÖ•Ê≥ï ‚Äî‚Äî ËØ¥ËØùÔºåÊØîÊâìÂ≠óÂø´ 4 ÂÄç ‚ö° 

&lt;div align=&quot;center&quot;&gt;

[![Mac‰∏ãËΩΩ](https://img.shields.io/badge/Mac-ÂÖçË¥π‰∏ãËΩΩ-FF6B6B?style=for-the-badge&amp;logo=apple&amp;logoColor=white)](https://shandianshuo.cn) [![Windows‰∏ãËΩΩ](https://img.shields.io/badge/Windows-ÂÖçË¥π‰∏ãËΩΩ-FF6B6B?style=for-the-badge&amp;logo=lightning&amp;logoColor=white)](https://shandianshuo.cn)
&lt;a href=&quot;https://shandianshuo.cn&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;_image/banner-shandianshuo.png&quot; alt=&quot;Èó™ÁîµËØ¥&quot; width=&quot;700&quot;/&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;br&gt;

## üìù Êõ¥Êñ∞Êó•Âøó

&gt; **üìå Êü•ÁúãÊúÄÊñ∞Êõ¥Êñ∞**Ôºö**[Âéü‰ªìÂ∫ìÊõ¥Êñ∞Êó•Âøó](https://github.com/sansan0/TrendRadar?tab=readme-ov-file#-Êõ¥Êñ∞Êó•Âøó)** Ôºö
- **ÊèêÁ§∫**ÔºöÂª∫ËÆÆÊü•Áúã„ÄêÂéÜÂè≤Êõ¥Êñ∞„ÄëÔºåÊòéÁ°ÆÂÖ∑‰ΩìÁöÑ„ÄêÂäüËÉΩÂÜÖÂÆπ„Äë


### 2025/12/30 - v4.5.0

- **RSS ËÆ¢ÈòÖÊ∫êÊîØÊåÅ**ÔºöÊñ∞Â¢û RSS/Atom ÊäìÂèñÔºåÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑÁªüËÆ°Ôºà‰∏éÁÉ≠Ê¶úÊ†ºÂºè‰∏ÄËá¥Ôºâ
- **Â≠òÂÇ®ÁªìÊûÑÈáçÊûÑ**ÔºöÊâÅÂπ≥ÂåñÁõÆÂΩïÁªìÊûÑ `output/{type}/{date}.db`
- **Áªü‰∏ÄÊéíÂ∫èÈÖçÁΩÆ**Ôºö`sort_by_position_first` ÂêåÊó∂ÂΩ±ÂìçÁÉ≠Ê¶úÂíå RSS
- **ÈÖçÁΩÆÁªìÊûÑÈáçÊûÑ**Ôºö`config.yaml` ÈáçÊñ∞ÁªÑÁªá‰∏∫ 7 ‰∏™ÈÄªËæëÂàÜÁªÑÔºàapp„ÄÅreport„ÄÅnotification„ÄÅstorage„ÄÅplatforms„ÄÅrss„ÄÅadvancedÔºâÔºåÈÖçÁΩÆË∑ØÂæÑÊõ¥Ê∏ÖÊô∞


### 2025/12/30 - mcp-v2.0.0

- **Êû∂ÊûÑË∞ÉÊï¥**ÔºöÁßªÈô§ TXT ÊîØÊåÅÔºåÁªü‰∏Ä‰ΩøÁî® SQLite Êï∞ÊçÆÂ∫ì
- **RSS Êü•ËØ¢**ÔºöÊñ∞Â¢û `get_latest_rss`„ÄÅ`search_rss`„ÄÅ`get_rss_feeds_status`
- **Áªü‰∏ÄÊêúÁ¥¢**Ôºö`search_news` ÊîØÊåÅ `include_rss` ÂèÇÊï∞ÂêåÊó∂ÊêúÁ¥¢ÁÉ≠Ê¶úÂíå RSS


&lt;details&gt;
&lt;summary&gt;üëâ ÁÇπÂáªÂ±ïÂºÄÔºö&lt;strong&gt;ÂéÜÂè≤Êõ¥Êñ∞&lt;/strong&gt;&lt;/summary&gt;


### 2025/12/26 - mcp-v1.2.0

  **MCP Ê®°ÂùóÊõ¥Êñ∞ - ‰ºòÂåñÂ∑•ÂÖ∑ÈõÜÔºåÊñ∞Â¢ûËÅöÂêàÂØπÊØîÂäüËÉΩÔºåÂêàÂπ∂ÂÜó‰ΩôÂ∑•ÂÖ∑:**
  - Êñ∞Â¢û `aggregate_news` Â∑•ÂÖ∑ - Ë∑®Âπ≥Âè∞Êñ∞ÈóªÂéªÈáçËÅöÂêà
  - Êñ∞Â¢û `compare_periods` Â∑•ÂÖ∑ - Êó∂ÊúüÂØπÊØîÂàÜÊûêÔºàÂë®ÁéØÊØî/ÊúàÁéØÊØîÔºâ
  - ÂêàÂπ∂ `find_similar_news` + `search_related_news_history` ‚Üí `find_related_news`
  - Â¢ûÂº∫ `get_trending_topics` - Êñ∞Â¢û `auto_extract` Ê®°ÂºèËá™Âä®ÊèêÂèñÁÉ≠ÁÇπ
  - ‰øÆÂ§çËã•Âπ≤bug
  - ÂêåÊ≠•Êõ¥Êñ∞ README-MCP-FAQ.md ÊñáÊ°£ÁöÑ‰∏≠Ëã±ÊñáÁâà (Q1-Q18)


### 2025/12/20 - v4.0.3

- Êñ∞Â¢û URL Ê†áÂáÜÂåñÂäüËÉΩÔºåËß£ÂÜ≥ÂæÆÂçöÁ≠âÂπ≥Âè∞Âõ†Âä®ÊÄÅÂèÇÊï∞ÔºàÂ¶Ç `band_rank`ÔºâÂØºËá¥ÁöÑÈáçÂ§çÊé®ÈÄÅÈóÆÈ¢ò
- ‰øÆÂ§çÂ¢ûÈáèÊ®°ÂºèÊ£ÄÊµãÈÄªËæëÔºåÊ≠£Á°ÆËØÜÂà´ÂéÜÂè≤Ê†áÈ¢ò


### 2025/12/17 - v4.0.1

- StorageManager Ê∑ªÂä†Êé®ÈÄÅËÆ∞ÂΩï‰ª£ÁêÜÊñπÊ≥ï
- S3 ÂÆ¢Êà∑Á´ØÂàáÊç¢Ëá≥ virtual-hosted style ‰ª•ÊèêÂçáÂÖºÂÆπÊÄßÔºàÊîØÊåÅËÖæËÆØ‰∫ë COS Á≠âÊõ¥Â§öÊúçÂä°Ôºâ


### 2025/12/13 - mcp-v1.1.0

  **MCP Ê®°ÂùóÊõ¥Êñ∞:**
  - ÈÄÇÈÖç v4.0.0ÔºåÂêåÊó∂‰πüÂÖºÂÆπ v3.x ÁöÑÊï∞ÊçÆ
  - Êñ∞Â¢ûÂ≠òÂÇ®ÂêåÊ≠•Â∑•ÂÖ∑Ôºö`sync_from_remote`„ÄÅ`get_storage_status`„ÄÅ`list_available_dates`


### 2025/12/13 - v4.0.0

**üéâ ÈáçÂ§ßÊõ¥Êñ∞ÔºöÂÖ®Èù¢ÈáçÊûÑÂ≠òÂÇ®ÂíåÊ†∏ÂøÉÊû∂ÊûÑ**

- **Â§öÂ≠òÂÇ®ÂêéÁ´ØÊîØÊåÅ**ÔºöÂºïÂÖ•ÂÖ®Êñ∞ÁöÑÂ≠òÂÇ®Ê®°ÂùóÔºåÊîØÊåÅÊú¨Âú∞ SQLite ÂíåËøúÁ®ã‰∫ëÂ≠òÂÇ®ÔºàS3 ÂÖºÂÆπÂçèËÆÆÔºåÊé®ËçêÂÖçË¥πÁöÑ Cloudflare R2ÔºâÔºåÈÄÇÂ∫î GitHub Actions„ÄÅDocker ÂíåÊú¨Âú∞ÁéØÂ¢É„ÄÇ
- **Êï∞ÊçÆÂ∫ìÁªìÊûÑ‰ºòÂåñ**ÔºöÈáçÊûÑ SQLite Êï∞ÊçÆÂ∫ìË°®ÁªìÊûÑÔºåÊèêÂçáÊï∞ÊçÆÊïàÁéáÂíåÊü•ËØ¢ËÉΩÂäõ„ÄÇ
- **Ê†∏ÂøÉ‰ª£Á†ÅÊ®°ÂùóÂåñ**ÔºöÂ∞Ü‰∏ªÁ®ãÂ∫èÈÄªËæëÊãÜÂàÜ‰∏∫ trendradar ÂåÖÁöÑÂ§ö‰∏™Ê®°ÂùóÔºåÊòæËëóÊèêÂçá‰ª£Á†ÅÂèØÁª¥Êä§ÊÄß„ÄÇ
- **Â¢ûÂº∫ÂäüËÉΩ**ÔºöÂÆûÁé∞Êó•ÊúüÊ†ºÂºèÊ†áÂáÜÂåñ„ÄÅÊï∞ÊçÆ‰øùÁïôÁ≠ñÁï•„ÄÅÊó∂Âå∫ÈÖçÁΩÆÊîØÊåÅ„ÄÅÊó∂Èó¥ÊòæÁ§∫‰ºòÂåñÔºåÂπ∂‰øÆÂ§çËøúÁ®ãÂ≠òÂÇ®Êï∞ÊçÆÊåÅ‰πÖÂåñÈóÆÈ¢òÔºåÁ°Æ‰øùÊï∞ÊçÆÂêàÂπ∂ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ
- **Ê∏ÖÁêÜÂíåÂÖºÂÆπ**ÔºöÁßªÈô§‰∫ÜÂ§ßÈÉ®ÂàÜÂéÜÂè≤ÂÖºÂÆπ‰ª£Á†ÅÔºåÁªü‰∏Ä‰∫ÜÊï∞ÊçÆÂ≠òÂÇ®ÂíåËØªÂèñÊñπÂºè„ÄÇ


### 2025/12/03 - v3.5.0

**üéâ Ê†∏ÂøÉÂäüËÉΩÂ¢ûÂº∫**

1. **Â§öË¥¶Âè∑Êé®ÈÄÅÊîØÊåÅ**
   - ÊâÄÊúâÊé®ÈÄÅÊ∏†ÈÅìÔºàÈ£û‰π¶„ÄÅÈíâÈíâ„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°„ÄÅTelegram„ÄÅntfy„ÄÅBark„ÄÅSlackÔºâÊîØÊåÅÂ§öË¥¶Âè∑ÈÖçÁΩÆ
   - ‰ΩøÁî®ÂàÜÂè∑ `;` ÂàÜÈöîÂ§ö‰∏™Ë¥¶Âè∑Ôºå‰æãÂ¶ÇÔºö`FEISHU_WEBHOOK_URL=url1;url2`
   - Ëá™Âä®È™åËØÅÈÖçÂØπÈÖçÁΩÆÔºàÂ¶Ç Telegram ÁöÑ token Âíå chat_idÔºâÊï∞Èáè‰∏ÄËá¥ÊÄß

2. **Êé®ÈÄÅÂÜÖÂÆπÈ°∫Â∫èÂèØÈÖçÁΩÆ**
   - Êñ∞Â¢û `reverse_content_order` ÈÖçÁΩÆÈ°π
   - ÊîØÊåÅËá™ÂÆö‰πâÁÉ≠ÁÇπËØçÊ±áÁªüËÆ°‰∏éÊñ∞Â¢ûÁÉ≠ÁÇπÊñ∞ÈóªÁöÑÊòæÁ§∫È°∫Â∫è

3. **ÂÖ®Â±ÄËøáÊª§ÂÖ≥ÈîÆËØç**
   - Êñ∞Â¢û `[GLOBAL_FILTER]` Âå∫ÂüüÊ†áËÆ∞ÔºåÊîØÊåÅÂÖ®Â±ÄËøáÊª§‰∏çÊÉ≥ÁúãÂà∞ÁöÑÂÜÖÂÆπ
   - ÈÄÇÁî®Âú∫ÊôØÔºöËøáÊª§ÂπøÂëä„ÄÅËê•ÈîÄ„ÄÅ‰ΩéË¥®ÂÜÖÂÆπÁ≠â

**üê≥ Docker ÂèåË∑ØÂæÑ HTML ÁîüÊàê‰ºòÂåñ**

- **ÈóÆÈ¢ò‰øÆÂ§ç**ÔºöËß£ÂÜ≥ Docker ÁéØÂ¢É‰∏ã `index.html` Êó†Ê≥ïÂêåÊ≠•Âà∞ÂÆø‰∏ªÊú∫ÁöÑÈóÆÈ¢ò
- **ÂèåË∑ØÂæÑÁîüÊàê**ÔºöÂΩìÊó•Ê±áÊÄª HTML ÂêåÊó∂ÁîüÊàêÂà∞‰∏§‰∏™‰ΩçÁΩÆ
  - `index.html`ÔºàÈ°πÁõÆÊ†πÁõÆÂΩïÔºâÔºö‰æõ GitHub Pages ËÆøÈóÆ
  - `output/index.html`ÔºöÈÄöËøá Docker Volume ÊåÇËΩΩÔºåÂÆø‰∏ªÊú∫ÂèØÁõ¥Êé•ËÆøÈóÆ
- **ÂÖºÂÆπÊÄß**ÔºöÁ°Æ‰øù Docker„ÄÅGitHub Actions„ÄÅÊú¨Âú∞ËøêË°åÁéØÂ¢ÉÂùáËÉΩÊ≠£Â∏∏ËÆøÈóÆÁΩëÈ°µÁâàÊä•Âëä

**üê≥ Docker MCP ÈïúÂÉèÊîØÊåÅ**

- Êñ∞Â¢ûÁã¨Á´ãÁöÑ MCP ÊúçÂä°ÈïúÂÉè `wantcat/trendradar-mcp`
- ÊîØÊåÅ Docker ÈÉ®ÁΩ≤ AI ÂàÜÊûêÂäüËÉΩÔºåÈÄöËøá HTTP Êé•Âè£ÔºàÁ´ØÂè£ 3333ÔºâÊèê‰æõÊúçÂä°
- ÂèåÂÆπÂô®Êû∂ÊûÑÔºöÊñ∞ÈóªÊé®ÈÄÅÊúçÂä°‰∏é MCP ÊúçÂä°Áã¨Á´ãËøêË°åÔºåÂèØÂàÜÂà´Êâ©Â±ïÂíåÈáçÂêØ
- ËØ¶ËßÅ [Docker ÈÉ®ÁΩ≤ - MCP ÊúçÂä°](#6-docker-ÈÉ®ÁΩ≤)

**üåê Web ÊúçÂä°Âô®ÊîØÊåÅ**

- Êñ∞Â¢ûÂÜÖÁΩÆ Web ÊúçÂä°Âô®ÔºåÊîØÊåÅÈÄöËøáÊµèËßàÂô®ËÆøÈóÆÁîüÊàêÁöÑÊä•Âëä
- ÈÄöËøá `manage.py` ÂëΩ‰ª§ÊéßÂà∂ÂêØÂä®/ÂÅúÊ≠¢Ôºö`docker exec -it trendradar python manage.py start_webserver`
- ËÆøÈóÆÂú∞ÂùÄÔºö`http://localhost:8080`ÔºàÁ´ØÂè£ÂèØÈÖçÁΩÆÔºâ
- ÂÆâÂÖ®ÁâπÊÄßÔºöÈùôÊÄÅÊñá‰ª∂ÊúçÂä°„ÄÅÁõÆÂΩïÈôêÂà∂„ÄÅÊú¨Âú∞ËÆøÈóÆ
- ÊîØÊåÅËá™Âä®ÂêØÂä®ÂíåÊâãÂä®ÊéßÂà∂‰∏§ÁßçÊ®°Âºè

**üìñ ÊñáÊ°£‰ºòÂåñ**

- Êñ∞Â¢û [Êä•ÂëäÈÖçÁΩÆ](#7-Êä•ÂëäÈÖçÁΩÆ) Á´†ËäÇÔºöreport Áõ∏ÂÖ≥ÂèÇÊï∞ËØ¶Ëß£
- Êñ∞Â¢û [Êé®ÈÄÅÊó∂Èó¥Á™óÂè£ÈÖçÁΩÆ](#8-Êé®ÈÄÅÊó∂Èó¥Á™óÂè£ÈÖçÁΩÆ) Á´†ËäÇÔºöpush_window ÈÖçÁΩÆÊïôÁ®ã
- Êñ∞Â¢û [ÊâßË°åÈ¢ëÁéáÈÖçÁΩÆ](#9-ÊâßË°åÈ¢ëÁéáÈÖçÁΩÆ) Á´†ËäÇÔºöCron Ë°®ËææÂºèËØ¥ÊòéÂíåÂ∏∏Áî®Á§∫‰æã
- Êñ∞Â¢û [Â§öË¥¶Âè∑Êé®ÈÄÅÈÖçÁΩÆ](#10-Â§öË¥¶Âè∑Êé®ÈÄÅÈÖçÁΩÆ) Á´†ËäÇÔºöÂ§öË¥¶Âè∑Êé®ÈÄÅÈÖçÁΩÆËØ¶Ëß£
- ‰ºòÂåñÂêÑÈÖçÁΩÆÁ´†ËäÇÔºöÁªü‰∏ÄÊ∑ªÂä†&quot;ÈÖçÁΩÆ‰ΩçÁΩÆ&quot;ËØ¥Êòé
- ÁÆÄÂåñÂø´ÈÄüÂºÄÂßãÈÖçÁΩÆËØ¥ÊòéÔºö‰∏â‰∏™Ê†∏ÂøÉÊñá‰ª∂‰∏ÄÁõÆ‰∫ÜÁÑ∂
- ‰ºòÂåñ [Docker ÈÉ®ÁΩ≤](#6-docker-ÈÉ®ÁΩ≤) Á´†ËäÇÔºöÊñ∞Â¢ûÈïúÂÉèËØ¥Êòé„ÄÅÊé®Ëçê git clone ÈÉ®ÁΩ≤„ÄÅÈáçÁªÑÈÉ®ÁΩ≤ÊñπÂºè

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`„ÄÅ`config/config.yaml`ÔºàÊñ∞Â¢ûÂ§öË¥¶Âè∑Êé®ÈÄÅÊîØÊåÅÔºåÊó†ÈúÄ‰øÆÊîπÁé∞ÊúâÈÖçÁΩÆÔºâ
- **Â§öË¥¶Âè∑Êé®ÈÄÅ**ÔºöÊñ∞ÂäüËÉΩÔºåÈªòËÆ§‰∏çÂêØÁî®ÔºåÁé∞ÊúâÂçïË¥¶Âè∑ÈÖçÁΩÆ‰∏çÂèóÂΩ±Âìç


### 2025/11/26 - mcp-v1.0.3

  **MCP Ê®°ÂùóÊõ¥Êñ∞:**
  - Êñ∞Â¢ûÊó•ÊúüËß£ÊûêÂ∑•ÂÖ∑ resolve_date_range,Ëß£ÂÜ≥ AI Ê®°ÂûãËÆ°ÁÆóÊó•Êúü‰∏ç‰∏ÄËá¥ÁöÑÈóÆÈ¢ò
  - ÊîØÊåÅËá™ÁÑ∂ËØ≠Ë®ÄÊó•ÊúüË°®ËææÂºèËß£Êûê(Êú¨Âë®„ÄÅÊúÄËøë7Â§©„ÄÅ‰∏äÊúàÁ≠â)
  - Â∑•ÂÖ∑ÊÄªÊï∞‰ªé 13 ‰∏™Â¢ûÂä†Âà∞ 14 ‰∏™


### 2025/11/28 - v3.4.1

**üîß Ê†ºÂºè‰ºòÂåñ**

1. **Bark Êé®ÈÄÅÂ¢ûÂº∫**
   - Bark Áé∞ÊîØÊåÅ Markdown Ê∏≤Êüì
   - ÂêØÁî®ÂéüÁîü Markdown Ê†ºÂºèÔºöÁ≤ó‰Ωì„ÄÅÈìæÊé•„ÄÅÂàóË°®„ÄÅ‰ª£Á†ÅÂùóÁ≠â
   - ÁßªÈô§Á∫ØÊñáÊú¨ËΩ¨Êç¢ÔºåÂÖÖÂàÜÂà©Áî® Bark ÂéüÁîüÊ∏≤ÊüìËÉΩÂäõ

2. **Slack Ê†ºÂºèÁ≤æÂáÜÂåñ**
   - ‰ΩøÁî®‰∏ìÁî® mrkdwn Ê†ºÂºèÂ§ÑÁêÜÂàÜÊâπÂÜÖÂÆπ
   - ÊèêÂçáÂ≠óËäÇÂ§ßÂ∞è‰º∞ÁÆóÂáÜÁ°ÆÊÄßÔºàÈÅøÂÖçÊ∂àÊÅØË∂ÖÈôêÔºâ
   - ‰ºòÂåñÈìæÊé•Ê†ºÂºèÔºö`&lt;url|text&gt;` ÂíåÂä†Á≤óËØ≠Ê≥ïÔºö`*text*`

3. **ÊÄßËÉΩÊèêÂçá**
   - Ê†ºÂºèËΩ¨Êç¢Âú®ÂàÜÊâπËøáÁ®ã‰∏≠ÂÆåÊàêÔºåÈÅøÂÖç‰∫åÊ¨°Â§ÑÁêÜ
   - ÂáÜÁ°Æ‰º∞ÁÆóÊ∂àÊÅØÂ§ßÂ∞èÔºåÂáèÂ∞ëÂèëÈÄÅÂ§±Ë¥•Áéá

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`Ôºå`config.yaml`


### 2025/11/25 - v3.4.0

**üéâ Êñ∞Â¢û Slack Êé®ÈÄÅÊîØÊåÅ**

1. **Âõ¢ÈòüÂçè‰ΩúÊé®ÈÄÅÊ∏†ÈÅì**
   - ÊîØÊåÅ Slack Incoming WebhooksÔºàÂÖ®ÁêÉÊµÅË°åÁöÑÂõ¢ÈòüÂçè‰ΩúÂ∑•ÂÖ∑Ôºâ
   - Ê∂àÊÅØÈõÜ‰∏≠ÁÆ°ÁêÜÔºåÈÄÇÂêàÂõ¢ÈòüÂÖ±‰∫´ÁÉ≠ÁÇπËµÑËÆØ
   - ÊîØÊåÅ mrkdwn Ê†ºÂºèÔºàÁ≤ó‰Ωì„ÄÅÈìæÊé•Á≠âÔºâ

2. **Â§öÁßçÈÉ®ÁΩ≤ÊñπÂºè**
   - GitHub ActionsÔºöÈÖçÁΩÆ `SLACK_WEBHOOK_URL` Secret
   - DockerÔºöÁéØÂ¢ÉÂèòÈáè `SLACK_WEBHOOK_URL`
   - Êú¨Âú∞ËøêË°åÔºö`config/config.yaml` ÈÖçÁΩÆÊñá‰ª∂


&gt; üìñ **ËØ¶ÁªÜÈÖçÁΩÆÊïôÁ®ã**Ôºö[Âø´ÈÄüÂºÄÂßã - Slack Êé®ÈÄÅ](#-Âø´ÈÄüÂºÄÂßã)

- ‰ºòÂåñ setup-windows.bat Âíå setup-windows-en.bat ‰∏ÄÈîÆÂÆâË£Ö MCP ÁöÑ‰ΩìÈ™å

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`„ÄÅ`config/config.yaml`„ÄÅ`.github/workflows/crawler.yml`


### 2025/11/24 - v3.3.0

**üéâ Êñ∞Â¢û Bark Êé®ÈÄÅÊîØÊåÅ**

1. **iOS ‰∏ìÂ±ûÊé®ÈÄÅÊ∏†ÈÅì**
   - ÊîØÊåÅ Bark Êé®ÈÄÅÔºàÂü∫‰∫é APNsÔºåiOS Âπ≥Âè∞Ôºâ
   - ÂÖçË¥πÂºÄÊ∫êÔºåÁÆÄÊ¥ÅÈ´òÊïàÔºåÊó†ÂπøÂëäÂπ≤Êâ∞
   - ÊîØÊåÅÂÆòÊñπÊúçÂä°Âô®ÂíåËá™Âª∫ÊúçÂä°Âô®‰∏§ÁßçÊñπÂºè

2. **Â§öÁßçÈÉ®ÁΩ≤ÊñπÂºè**
   - GitHub ActionsÔºöÈÖçÁΩÆ `BARK_URL` Secret
   - DockerÔºöÁéØÂ¢ÉÂèòÈáè `BARK_URL`
   - Êú¨Âú∞ËøêË°åÔºö`config/config.yaml` ÈÖçÁΩÆÊñá‰ª∂

&gt; üìñ **ËØ¶ÁªÜÈÖçÁΩÆÊïôÁ®ã**Ôºö[Âø´ÈÄüÂºÄÂßã - Bark Êé®ÈÄÅ](#-Âø´ÈÄüÂºÄÂßã)

**üêõ Bug ‰øÆÂ§ç**
- ‰øÆÂ§ç `config.yaml` ‰∏≠ `ntfy_server_url` ÈÖçÁΩÆ‰∏çÁîüÊïàÁöÑÈóÆÈ¢ò ([#345](https://github.com/sansan0/TrendRadar/issues/345))

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`„ÄÅ`config/config.yaml`„ÄÅ`.github/workflows/crawler.yml`

### 2025/11/23 - v3.2.0

**üéØ Êñ∞Â¢ûÈ´òÁ∫ßÂÆöÂà∂ÂäüËÉΩ**

1. **ÂÖ≥ÈîÆËØçÊéíÂ∫è‰ºòÂÖàÁ∫ßÈÖçÁΩÆ**
   - ÊîØÊåÅ‰∏§ÁßçÊéíÂ∫èÁ≠ñÁï•ÔºöÁÉ≠Â∫¶‰ºòÂÖà vs ÈÖçÁΩÆÈ°∫Â∫è‰ºòÂÖà
   - Êª°Ë∂≥‰∏çÂêå‰ΩøÁî®Âú∫ÊôØÔºöÁÉ≠ÁÇπËøΩË∏™ or ‰∏™ÊÄßÂåñÂÖ≥Ê≥®

2. **ÊòæÁ§∫Êï∞ÈáèÁ≤æÂáÜÊéßÂà∂**
   - ÂÖ®Â±ÄÈÖçÁΩÆÔºöÁªü‰∏ÄÈôêÂà∂ÊâÄÊúâÂÖ≥ÈîÆËØçÊòæÁ§∫Êï∞Èáè
   - ÂçïÁã¨ÈÖçÁΩÆÔºö‰ΩøÁî® `@Êï∞Â≠ó` ËØ≠Ê≥ï‰∏∫ÁâπÂÆöÂÖ≥ÈîÆËØçËÆæÁΩÆÈôêÂà∂
   - ÊúâÊïàÊéßÂà∂Êé®ÈÄÅÈïøÂ∫¶ÔºåÁ™ÅÂá∫ÈáçÁÇπÂÜÖÂÆπ

&gt; üìñ **ËØ¶ÁªÜÈÖçÁΩÆÊïôÁ®ã**Ôºö[ÂÖ≥ÈîÆËØçÈÖçÁΩÆ - È´òÁ∫ßÈÖçÁΩÆ](#ÂÖ≥ÈîÆËØçÈ´òÁ∫ßÈÖçÁΩÆ)

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`„ÄÅ`config/config.yaml`


### 2025/11/18 - mcp-v1.0.2

  **MCP Ê®°ÂùóÊõ¥Êñ∞:**
  - ‰ºòÂåñÊü•ËØ¢‰ªäÊó•Êñ∞ÈóªÂç¥ÂèØËÉΩÈîôËØØËøîÂõûËøáÂéªÊó•ÊúüÁöÑÊÉÖÂÜµ


### 2025/11/22 - v3.1.1

- **‰øÆÂ§çÊï∞ÊçÆÂºÇÂ∏∏ÂØºËá¥ÁöÑÂ¥©Ê∫ÉÈóÆÈ¢ò**ÔºöËß£ÂÜ≥ÈÉ®ÂàÜÁî®Êà∑Âú® GitHub Actions ÁéØÂ¢É‰∏≠ÈÅáÂà∞ÁöÑ `&#039;float&#039; object has no attribute &#039;lower&#039;` ÈîôËØØ
- Êñ∞Â¢ûÂèåÈáçÈò≤Êä§Êú∫Âà∂ÔºöÂú®Êï∞ÊçÆËé∑ÂèñÈò∂ÊÆµËøáÊª§Êó†ÊïàÊ†áÈ¢òÔºàNone„ÄÅfloat„ÄÅÁ©∫Â≠óÁ¨¶‰∏≤ÔºâÔºåÂêåÊó∂Âú®ÂáΩÊï∞Ë∞ÉÁî®Â§ÑÊ∑ªÂä†Á±ªÂûãÊ£ÄÊü•
- ÊèêÂçáÁ≥ªÁªüÁ®≥ÂÆöÊÄßÔºåÁ°Æ‰øùÂú®Êï∞ÊçÆÊ∫êËøîÂõûÂºÇÂ∏∏Ê†ºÂºèÊó∂‰ªçËÉΩÊ≠£Â∏∏ËøêË°å

**ÂçáÁ∫ßËØ¥Êòé**ÔºàGitHub Fork Áî®Êà∑ÔºâÔºö
- ÂøÖÈ°ªÊõ¥Êñ∞Ôºö`main.py`
- Âª∫ËÆÆ‰ΩøÁî®Â∞èÁâàÊú¨ÂçáÁ∫ßÊñπÂºèÔºöÂ§çÂà∂ÊõøÊç¢‰∏äËø∞Êñá‰ª∂


### 2025/11/20 - v3.1.0

- **Êñ∞Â¢û‰∏™‰∫∫ÂæÆ‰ø°Êé®ÈÄÅÊîØÊåÅ**Ôºö‰ºÅ‰∏öÂæÆ‰ø°Â∫îÁî®ÂèØÊé®ÈÄÅÂà∞‰∏™‰∫∫ÂæÆ‰ø°ÔºåÊó†ÈúÄÂÆâË£Ö‰ºÅ‰∏öÂæÆ‰ø° APP
- ÊîØÊåÅ‰∏§ÁßçÊ∂àÊÅØÊ†ºÂºèÔºö`markdown`Ôºà‰ºÅ‰∏öÂæÆ‰ø°Áæ§Êú∫Âô®‰∫∫ÔºâÂíå `text`Ôºà‰∏™‰∫∫ÂæÆ‰ø°Â∫îÁî®Ôºâ
- Êñ∞Â¢û `WEWORK_MSG_TYPE` ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆÔºåÊîØÊåÅ GitHub Actions„ÄÅDocker„ÄÅdocker compose Á≠âÂ§öÁßçÈÉ®ÁΩ≤ÊñπÂºè
- `text` Ê®°ÂºèËá™Âä®Ê∏ÖÈô§ Markdown ËØ≠Ê≥ïÔºåÊèê‰æõÁ∫ØÊñáÊú¨Êé®ÈÄÅÊïàÊûú
- ËØ¶ËßÅÂø´ÈÄüÂºÄÂßã‰∏≠ÁöÑ„Äå‰∏™‰∫∫ÂæÆ‰ø°Êé®ÈÄÅ„ÄçÈÖçÁΩÆËØ¥Êòé

**ÂçáÁ∫ßËØ¥Êòé**ÔºàGitHub Fork Áî®Êà∑ÔºâÔºö
- ÂøÖÈ°ªÊõ¥Êñ∞Ôºö`main.py`„ÄÅ`config/config.yaml`
- ÂèØÈÄâÊõ¥Êñ∞Ôºö`.github/workflows/crawler.yml`ÔºàÂ¶Ç‰ΩøÁî® GitHub Actions ÈÉ®ÁΩ≤Ôºâ
- Âª∫ËÆÆ‰ΩøÁî®Â∞èÁâàÊú¨ÂçáÁ∫ßÊñπÂºèÔºöÂ§çÂà∂ÊõøÊç¢‰∏äËø∞Êñá‰ª∂

### 2025/11/12 - v3.0.5

- ‰øÆÂ§çÈÇÆ‰ª∂ÂèëÈÄÅ SSL/TLS Á´ØÂè£ÈÖçÁΩÆÈÄªËæëÈîôËØØ
- ‰ºòÂåñÈÇÆÁÆ±ÊúçÂä°ÂïÜÔºàQQ/163/126ÔºâÈªòËÆ§‰ΩøÁî® 465 Á´ØÂè£ÔºàSSLÔºâ
- **Êñ∞Â¢û Docker ÁéØÂ¢ÉÂèòÈáèÊîØÊåÅ**ÔºöÊ†∏ÂøÉÈÖçÁΩÆÈ°πÔºà`enable_crawler`„ÄÅ`report_mode`„ÄÅ`push_window` Á≠âÔºâÊîØÊåÅÈÄöËøáÁéØÂ¢ÉÂèòÈáèË¶ÜÁõñÔºåËß£ÂÜ≥ NAS Áî®Êà∑‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂‰∏çÁîüÊïàÁöÑÈóÆÈ¢òÔºàËØ¶ËßÅ [üê≥ Docker ÈÉ®ÁΩ≤](#-docker-ÈÉ®ÁΩ≤) Á´†ËäÇÔºâ


### 2025/10/26 - mcp-v1.0.1

  **MCP Ê®°ÂùóÊõ¥Êñ∞:**
  - ‰øÆÂ§çÊó•ÊúüÊü•ËØ¢ÂèÇÊï∞‰º†ÈÄíÈîôËØØ
  - Áªü‰∏ÄÊâÄÊúâÂ∑•ÂÖ∑ÁöÑÊó∂Èó¥ÂèÇÊï∞Ê†ºÂºè


### 2025/10/31 - v3.0.4

- Ëß£ÂÜ≥È£û‰π¶Âõ†Êé®ÈÄÅÂÜÖÂÆπËøáÈïøËÄå‰∫ßÁîüÁöÑÈîôËØØÔºåÂÆûÁé∞‰∫ÜÂàÜÊâπÊé®ÈÄÅ


### 2025/10/23 - v3.0.3

- Êâ©Â§ß ntfy ÈîôËØØ‰ø°ÊÅØÊòæÁ§∫ËåÉÂõ¥


### 2025/10/21 - v3.0.2

- ‰øÆÂ§ç ntfy Êé®ÈÄÅÁºñÁ†ÅÈóÆÈ¢ò

### 2025/10/20 - v3.0.0

**ÈáçÂ§ßÊõ¥Êñ∞ - AI ÂàÜÊûêÂäüËÉΩ‰∏äÁ∫ø** ü§ñ

- **Ê†∏ÂøÉÂäüËÉΩ**Ôºö
  - Êñ∞Â¢ûÂü∫‰∫é MCP (Model Context Protocol) ÁöÑ AI ÂàÜÊûêÊúçÂä°Âô®
  - ÊîØÊåÅ17ÁßçÊô∫ËÉΩÂàÜÊûêÂ∑•ÂÖ∑ÔºöÂü∫Á°ÄÊü•ËØ¢„ÄÅÊô∫ËÉΩÊ£ÄÁ¥¢„ÄÅÈ´òÁ∫ßÂàÜÊûê„ÄÅRSS Êü•ËØ¢„ÄÅÁ≥ªÁªüÁÆ°ÁêÜ
  - Ëá™ÁÑ∂ËØ≠Ë®Ä‰∫§‰∫íÔºöÈÄöËøáÂØπËØùÊñπÂºèÊü•ËØ¢ÂíåÂàÜÊûêÊñ∞ÈóªÊï∞ÊçÆ
  - Â§öÂÆ¢Êà∑Á´ØÊîØÊåÅÔºöClaude Desktop„ÄÅCherry Studio„ÄÅCursor„ÄÅCline Á≠â

- **ÂàÜÊûêËÉΩÂäõ**Ôºö
  - ËØùÈ¢òË∂ãÂäøÂàÜÊûêÔºàÁÉ≠Â∫¶ËøΩË∏™„ÄÅÁîüÂëΩÂë®Êúü„ÄÅÁàÜÁÅ´Ê£ÄÊµã„ÄÅË∂ãÂäøÈ¢ÑÊµãÔºâ
  - Êï∞ÊçÆÊ¥ûÂØüÔºàÂπ≥Âè∞ÂØπÊØî„ÄÅÊ¥ªË∑ÉÂ∫¶ÁªüËÆ°„ÄÅÂÖ≥ÈîÆËØçÂÖ±Áé∞Ôºâ
  - ÊÉÖÊÑüÂàÜÊûê„ÄÅÁõ∏‰ººÊñ∞ÈóªÊü•Êâæ„ÄÅÊô∫ËÉΩÊëòË¶ÅÁîüÊàê
  - ÂéÜÂè≤Áõ∏ÂÖ≥Êñ∞ÈóªÊ£ÄÁ¥¢„ÄÅÂ§öÊ®°ÂºèÊêúÁ¥¢

- **Êõ¥Êñ∞ÊèêÁ§∫**Ôºö
  - ËøôÊòØÁã¨Á´ãÁöÑ AI ÂàÜÊûêÂäüËÉΩÔºå‰∏çÂΩ±ÂìçÁé∞ÊúâÁöÑÊé®ÈÄÅÂäüËÉΩ
  - ÂèØÈÄâÊã©ÊÄß‰ΩøÁî®ÔºåÊó†ÈúÄÂçáÁ∫ßÁé∞ÊúâÈÉ®ÁΩ≤


### 2025/10/15 - v2.4.4

- **Êõ¥Êñ∞ÂÜÖÂÆπ**Ôºö
    - ‰øÆÂ§ç ntfy Êé®ÈÄÅÁºñÁ†ÅÈóÆÈ¢ò + 1
    - ‰øÆÂ§çÊé®ÈÄÅÊó∂Èó¥Á™óÂè£Âà§Êñ≠ÈóÆÈ¢ò

- **Êõ¥Êñ∞ÊèêÁ§∫**Ôºö
  - Âª∫ËÆÆ„ÄêÂ∞èÁâàÊú¨ÂçáÁ∫ß„Äë


### 2025/10/10 - v2.4.3

&gt; ÊÑüË∞¢ [nidaye996](https://github.com/sansan0/TrendRadar/issues/98) ÂèëÁé∞ÁöÑ‰ΩìÈ™åÈóÆÈ¢ò

- **Êõ¥Êñ∞ÂÜÖÂÆπ**Ôºö
    - ÈáçÊûÑ&quot;ÈùôÈªòÊé®ÈÄÅÊ®°Âºè&quot;ÂëΩÂêç‰∏∫&quot;Êé®ÈÄÅÊó∂Èó¥Á™óÂè£ÊéßÂà∂&quot;ÔºåÊèêÂçáÂäüËÉΩÁêÜËß£Â∫¶
    - ÊòéÁ°ÆÊé®ÈÄÅÊó∂Èó¥Á™óÂè£‰Ωú‰∏∫ÂèØÈÄâÈôÑÂä†ÂäüËÉΩÔºåÂèØ‰∏é‰∏âÁßçÊé®ÈÄÅÊ®°ÂºèÊê≠ÈÖç‰ΩøÁî®
    - ÊîπËøõÊ≥®ÈáäÂíåÊñáÊ°£ÊèèËø∞Ôºå‰ΩøÂäüËÉΩÂÆö‰ΩçÊõ¥Âä†Ê∏ÖÊô∞

- **Êõ¥Êñ∞ÊèêÁ§∫**Ôºö
  - Ëøô‰∏™‰ªÖ‰ªÖÊòØÈáçÊûÑÔºåÂèØ‰ª•‰∏çÁî®ÂçáÁ∫ß


### 2025/10/8 - v2.4.2

- **Êõ¥Êñ∞ÂÜÖÂÆπ**Ôºö
    - ‰øÆÂ§ç ntfy Êé®ÈÄÅÁºñÁ†ÅÈóÆÈ¢ò
    - ‰øÆÂ§çÈÖçÁΩÆÊñá‰ª∂Áº∫Â§±ÈóÆÈ¢ò
    - ‰ºòÂåñ ntfy Êé®ÈÄÅÊïàÊûú
    - Â¢ûÂä† github page ÂõæÁâáÂàÜÊÆµÂØºÂá∫ÂäüËÉΩ

- **Êõ¥Êñ∞ÊèêÁ§∫**Ôºö
  - Âª∫ËÆÆ‰ΩøÁî®„ÄêÂ§ßÁâàÊú¨Êõ¥Êñ∞„Äë


### 2025/10/2 - v2.4.0

**Êñ∞Â¢û ntfy Êé®ÈÄÅÈÄöÁü•**

- **Ê†∏ÂøÉÂäüËÉΩ**Ôºö
  - ÊîØÊåÅ ntfy.sh ÂÖ¨ÂÖ±ÊúçÂä°ÂíåËá™ÊâòÁÆ°ÊúçÂä°Âô®

- **‰ΩøÁî®Âú∫ÊôØ**Ôºö
  - ÈÄÇÂêàËøΩÊ±ÇÈöêÁßÅÁöÑÁî®Êà∑ÔºàÊîØÊåÅËá™ÊâòÁÆ°Ôºâ
  - Ë∑®Âπ≥Âè∞Êé®ÈÄÅÔºàiOS„ÄÅAndroid„ÄÅDesktop„ÄÅWebÔºâ
  - Êó†ÈúÄÊ≥®ÂÜåË¥¶Âè∑ÔºàÂÖ¨ÂÖ±ÊúçÂä°Âô®Ôºâ
  - ÂºÄÊ∫êÂÖçË¥πÔºàMIT ÂçèËÆÆÔºâ

- **Êõ¥Êñ∞ÊèêÁ§∫**Ôºö
  - Âª∫ËÆÆ‰ΩøÁî®„ÄêÂ§ßÁâàÊú¨Êõ¥Êñ∞„Äë


### 2025/09/26 - v2.3.2

- ‰øÆÊ≠£‰∫ÜÈÇÆ‰ª∂ÈÄöÁü•ÈÖçÁΩÆÊ£ÄÊü•Ë¢´ÈÅóÊºèÁöÑÈóÆÈ¢òÔºà[#88](https://github.com/sansan0/TrendRadar/issues/88)Ôºâ

**‰øÆÂ§çËØ¥Êòé**Ôºö
- Ëß£ÂÜ≥‰∫ÜÂç≥‰ΩøÊ≠£Á°ÆÈÖçÁΩÆÈÇÆ‰ª∂ÈÄöÁü•ÔºåÁ≥ªÁªü‰ªçÊèêÁ§∫&quot;Êú™ÈÖçÁΩÆ‰ªª‰Ωïwebhook&quot;ÁöÑÈóÆÈ¢ò

### 2025/09/22 - v2.3.1

- **Êñ∞Â¢ûÈÇÆ‰ª∂Êé®ÈÄÅÂäüËÉΩ**ÔºåÊîØÊåÅÂ∞ÜÁÉ≠ÁÇπÊñ∞ÈóªÊä•ÂëäÂèëÈÄÅÂà∞ÈÇÆÁÆ±
- **Êô∫ËÉΩ SMTP ËØÜÂà´**ÔºöËá™Âä®ËØÜÂà´ Gmail„ÄÅQQÈÇÆÁÆ±„ÄÅOutlook„ÄÅÁΩëÊòìÈÇÆÁÆ±Á≠â 10+ ÁßçÈÇÆÁÆ±ÊúçÂä°ÂïÜÈÖçÁΩÆ
- **HTML Á≤æÁæéÊ†ºÂºè**ÔºöÈÇÆ‰ª∂ÂÜÖÂÆπÈááÁî®‰∏éÁΩëÈ°µÁâàÁõ∏ÂêåÁöÑ HTML Ê†ºÂºèÔºåÊéíÁâàÁ≤æÁæéÔºåÁßªÂä®Á´ØÈÄÇÈÖç
- **ÊâπÈáèÂèëÈÄÅÊîØÊåÅ**ÔºöÊîØÊåÅÂ§ö‰∏™Êî∂‰ª∂‰∫∫ÔºåÁî®ÈÄóÂè∑ÂàÜÈöîÂç≥ÂèØÂêåÊó∂ÂèëÈÄÅÁªôÂ§ö‰∫∫
- **Ëá™ÂÆö‰πâ SMTP**ÔºöÂèØËá™ÂÆö‰πâ SMTP ÊúçÂä°Âô®ÂíåÁ´ØÂè£
- ‰øÆÂ§çDockerÊûÑÂª∫ÁΩëÁªúËøûÊé•ÈóÆÈ¢ò

**‰ΩøÁî®ËØ¥Êòé**Ôºö
- ÈÄÇÁî®Âú∫ÊôØÔºöÈÄÇÂêàÈúÄË¶ÅÈÇÆ‰ª∂ÂΩíÊ°£„ÄÅÂõ¢ÈòüÂàÜ‰∫´„ÄÅÂÆöÊó∂Êä•ÂëäÁöÑÁî®Êà∑
- ÊîØÊåÅÈÇÆÁÆ±ÔºöGmail„ÄÅQQÈÇÆÁÆ±„ÄÅOutlook/Hotmail„ÄÅ163/126ÈÇÆÁÆ±„ÄÅÊñ∞Êµ™ÈÇÆÁÆ±„ÄÅÊêúÁãêÈÇÆÁÆ±Á≠â

**Êõ¥Êñ∞ÊèêÁ§∫**Ôºö
- Ê≠§Ê¨°Êõ¥Êñ∞ÁöÑÂÜÖÂÆπÊØîËæÉÂ§öÔºåÂ¶ÇÊûúÊÉ≥ÂçáÁ∫ßÔºåÂª∫ËÆÆÈááÁî®„ÄêÂ§ßÁâàÊú¨ÂçáÁ∫ß„Äë

### 2025/09/17 - v2.2.0

- Êñ∞Â¢û‰∏ÄÈîÆ‰øùÂ≠òÊñ∞ÈóªÂõæÁâáÂäüËÉΩÔºåËÆ©‰Ω†ËΩªÊùæÂàÜ‰∫´ÂÖ≥Ê≥®ÁöÑÁÉ≠ÁÇπ

**‰ΩøÁî®ËØ¥Êòé**Ôºö
- ÈÄÇÁî®Âú∫ÊôØÔºöÂΩì‰Ω†ÊåâÁÖßÊïôÁ®ãÂºÄÂêØ‰∫ÜÁΩëÈ°µÁâàÂäüËÉΩÂêé(GitHub Pages)
- ‰ΩøÁî®ÊñπÊ≥ïÔºöÁî®ÊâãÊú∫ÊàñÁîµËÑëÊâìÂºÄËØ•ÁΩëÈ°µÈìæÊé•ÔºåÁÇπÂáªÈ°µÈù¢È°∂ÈÉ®ÁöÑ&quot;‰øùÂ≠ò‰∏∫ÂõæÁâá&quot;ÊåâÈíÆ
- ÂÆûÈôÖÊïàÊûúÔºöÁ≥ªÁªü‰ºöËá™Âä®Â∞ÜÂΩìÂâçÁöÑÊñ∞ÈóªÊä•ÂëäÂà∂‰ΩúÊàê‰∏ÄÂº†Á≤æÁæéÂõæÁâáÔºå‰øùÂ≠òÂà∞‰Ω†ÁöÑÊâãÊú∫Áõ∏ÂÜåÊàñÁîµËÑëÊ°åÈù¢
- ÂàÜ‰∫´‰æøÂà©Ôºö‰Ω†ÂèØ‰ª•Áõ¥Êé•ÊääËøôÂº†ÂõæÁâáÂèëÁªôÊúãÂèã„ÄÅÂèëÂà∞ÊúãÂèãÂúàÔºåÊàñÂàÜ‰∫´Âà∞Â∑•‰ΩúÁæ§ÔºåËÆ©Âà´‰∫∫‰πüËÉΩÁúãÂà∞‰Ω†ÂèëÁé∞ÁöÑÈáçË¶ÅËµÑËÆØ

### 2025/09/13 - v2.1.2

- Ëß£ÂÜ≥ÈíâÈíâÁöÑÊé®ÈÄÅÂÆπÈáèÈôêÂà∂ÂØºËá¥ÁöÑÊñ∞ÈóªÊé®ÈÄÅÂ§±Ë¥•ÈóÆÈ¢ò(ÈááÁî®ÂàÜÊâπÊé®ÈÄÅ)

### 2025/09/04 - v2.1.1

- ‰øÆÂ§çdockerÂú®Êüê‰∫õÊû∂ÊûÑ‰∏≠Êó†Ê≥ïÊ≠£Â∏∏ËøêË°åÁöÑÈóÆÈ¢ò
- Ê≠£ÂºèÂèëÂ∏ÉÂÆòÊñπ Docker ÈïúÂÉè wantcat/trendradarÔºåÊîØÊåÅÂ§öÊû∂ÊûÑ
- ‰ºòÂåñ Docker ÈÉ®ÁΩ≤ÊµÅÁ®ãÔºåÊó†ÈúÄÊú¨Âú∞ÊûÑÂª∫Âç≥ÂèØÂø´ÈÄü‰ΩøÁî®

### 2025/08/30 - v2.1.0

**Ê†∏ÂøÉÊîπËøõ**Ôºö
- **Êé®ÈÄÅÈÄªËæë‰ºòÂåñ**Ôºö‰ªé&quot;ÊØèÊ¨°ÊâßË°åÈÉΩÊé®ÈÄÅ&quot;Êîπ‰∏∫&quot;Êó∂Èó¥Á™óÂè£ÂÜÖÂèØÊéßÊé®ÈÄÅ&quot;
- **Êó∂Èó¥Á™óÂè£ÊéßÂà∂**ÔºöÂèØËÆæÂÆöÊé®ÈÄÅÊó∂Èó¥ËåÉÂõ¥ÔºåÈÅøÂÖçÈùûÂ∑•‰ΩúÊó∂Èó¥ÊâìÊâ∞
- **Êé®ÈÄÅÈ¢ëÁéáÂèØÈÄâ**ÔºöÊó∂Èó¥ÊÆµÂÜÖÊîØÊåÅÂçïÊ¨°Êé®ÈÄÅÊàñÂ§öÊ¨°Êé®ÈÄÅ

**Êõ¥Êñ∞ÊèêÁ§∫**Ôºö
- Êú¨ÂäüËÉΩÈªòËÆ§ÂÖ≥Èó≠ÔºåÈúÄÊâãÂä®Âú® config.yaml ‰∏≠ÂºÄÂêØÊé®ÈÄÅÊó∂Èó¥Á™óÂè£ÊéßÂà∂
- ÂçáÁ∫ßÈúÄÂêåÊó∂Êõ¥Êñ∞ main.py Âíå config.yaml ‰∏§‰∏™Êñá‰ª∂

### 2025/08/27 - v2.0.4

- Êú¨Ê¨°ÁâàÊú¨‰∏çÊòØÂäüËÉΩ‰øÆÂ§çÔºåËÄåÊòØÈáçË¶ÅÊèêÈÜí
- ËØ∑Âä°ÂøÖÂ¶•ÂñÑ‰øùÁÆ°Â•Ω webhooksÔºå‰∏çË¶ÅÂÖ¨ÂºÄÔºå‰∏çË¶ÅÂÖ¨ÂºÄÔºå‰∏çË¶ÅÂÖ¨ÂºÄ
- Â¶ÇÊûú‰Ω†‰ª• fork ÁöÑÊñπÂºèÂ∞ÜÊú¨È°πÁõÆÈÉ®ÁΩ≤Âú® GitHub ‰∏äÔºåËØ∑Â∞Ü webhooks Â°´ÂÖ• GitHub SecretÔºåËÄåÈùû config.yaml
- Â¶ÇÊûú‰Ω†Â∑≤ÁªèÊö¥Èú≤‰∫Ü webhooks ÊàñÂ∞ÜÂÖ∂Â°´ÂÖ•‰∫Ü config.yamlÔºåÂª∫ËÆÆÂà†Èô§ÂêéÈáçÊñ∞ÁîüÊàê

### 2025/08/06 - v2.0.3

- ‰ºòÂåñ github page ÁöÑÁΩëÈ°µÁâàÊïàÊûúÔºåÊñπ‰æøÁßªÂä®Á´Ø‰ΩøÁî®

### 2025/07/28 - v2.0.2

- ÈáçÊûÑ‰ª£Á†Å
- Ëß£ÂÜ≥ÁâàÊú¨Âè∑ÂÆπÊòìË¢´ÈÅóÊºè‰øÆÊîπÁöÑÈóÆÈ¢ò

### 2025/07/27 - v2.0.1

**‰øÆÂ§çÈóÆÈ¢ò**: 

1. docker ÁöÑ shell ËÑöÊú¨ÁöÑÊç¢Ë°åÁ¨¶‰∏∫ CRLF ÂØºËá¥ÁöÑÊâßË°åÂºÇÂ∏∏ÈóÆÈ¢ò
2. frequency_words.txt ‰∏∫Á©∫Êó∂ÔºåÂØºËá¥Êñ∞ÈóªÂèëÈÄÅ‰πü‰∏∫Á©∫ÁöÑÈÄªËæëÈóÆÈ¢ò
  - ‰øÆÂ§çÂêéÔºåÂΩì‰Ω†ÈÄâÊã© frequency_words.txt ‰∏∫Á©∫Êó∂ÔºåÂ∞Ü**Êé®ÈÄÅÊâÄÊúâÊñ∞Èóª**Ôºå‰ΩÜÂèóÈôê‰∫éÊ∂àÊÅØÊé®ÈÄÅÂ§ßÂ∞èÈôêÂà∂ÔºåËØ∑ÂÅöÂ¶Ç‰∏ãË∞ÉÊï¥
    - ÊñπÊ°à‰∏ÄÔºöÂÖ≥Èó≠ÊâãÊú∫Êé®ÈÄÅÔºåÂè™ÈÄâÊã© Github Pages Â∏ÉÁΩÆ(ËøôÊòØËÉΩËé∑ÂæóÊúÄÂÆåÊï¥‰ø°ÊÅØÁöÑÊñπÊ°àÔºåÂ∞ÜÊääÊâÄÊúâÂπ≥Âè∞ÁöÑÁÉ≠ÁÇπÊåâÁÖß‰Ω†**Ëá™ÂÆö‰πâÁöÑÁÉ≠ÊêúÁÆóÊ≥ï**ËøõË°åÈáçÊñ∞ÊéíÂ∫è)
    - ÊñπÊ°à‰∫åÔºöÂáèÂ∞ëÊé®ÈÄÅÂπ≥Âè∞Ôºå‰ºòÂÖàÈÄâÊã©**‰ºÅ‰∏öÂæÆ‰ø°**Êàñ**Telegram**ÔºåËøô‰∏§‰∏™Êé®ÈÄÅÊàëÂÅö‰∫ÜÂàÜÊâπÊé®ÈÄÅÂäüËÉΩ(Âõ†‰∏∫ÂàÜÊâπÊé®ÈÄÅÂΩ±ÂìçÊé®ÈÄÅ‰ΩìÈ™åÔºå‰∏îÂè™ÊúâËøô‰∏§‰∏™Âπ≥Âè∞Âè™Áªô‰∏ÄÁÇπÁÇπÊé®ÈÄÅÂÆπÈáèÔºåÊâÄ‰ª•Êâç‰∏çÂæóÂ∑≤ÂÅö‰∫ÜÂàÜÊâπÊé®ÈÄÅÂäüËÉΩÔºå‰ΩÜËá≥Â∞ëËÉΩ‰øùËØÅËé∑ÂæóÁöÑ‰ø°ÊÅØÂÆåÊï¥)
    - ÊñπÊ°à‰∏âÔºöÂèØ‰∏éÊñπÊ°à‰∫åÁªìÂêàÔºåÊ®°ÂºèÈÄâÊã© current Êàñ incremental ÂèØÊúâÊïàÂáèÂ∞ë‰∏ÄÊ¨°ÊÄßÊé®ÈÄÅÁöÑÂÜÖÂÆπ 

### 2025/07/17 - v2.0.0

**ÈáçÂ§ßÈáçÊûÑ**Ôºö
- ÈÖçÁΩÆÁÆ°ÁêÜÈáçÊûÑÔºöÊâÄÊúâÈÖçÁΩÆÁé∞Âú®ÈÄöËøá `config/config.yaml` Êñá‰ª∂ÁÆ°ÁêÜÔºàmain.py Êàë‰æùÊóßÊ≤°ÊãÜÂàÜÔºåÊñπ‰æø‰Ω†‰ª¨Â§çÂà∂ÂçáÁ∫ßÔºâ
- ËøêË°åÊ®°ÂºèÂçáÁ∫ßÔºöÊîØÊåÅ‰∏âÁßçÊ®°Âºè - `daily`ÔºàÂΩìÊó•Ê±áÊÄªÔºâ„ÄÅ`current`ÔºàÂΩìÂâçÊ¶úÂçïÔºâ„ÄÅ`incremental`ÔºàÂ¢ûÈáèÁõëÊéßÔºâ
- Docker ÊîØÊåÅÔºöÂÆåÊï¥ÁöÑ Docker ÈÉ®ÁΩ≤ÊñπÊ°àÔºåÊîØÊåÅÂÆπÂô®ÂåñËøêË°å

**ÈÖçÁΩÆÊñá‰ª∂ËØ¥Êòé**Ôºö
- `config/config.yaml` - ‰∏ªÈÖçÁΩÆÊñá‰ª∂ÔºàÂ∫îÁî®ËÆæÁΩÆ„ÄÅÁà¨Ëô´ÈÖçÁΩÆ„ÄÅÈÄöÁü•ÈÖçÁΩÆ„ÄÅÂπ≥Âè∞ÈÖçÁΩÆÁ≠âÔºâ
- `config/frequency_words.txt` - ÂÖ≥ÈîÆËØçÈÖçÁΩÆÔºàÁõëÊéßËØçÊ±áËÆæÁΩÆÔºâ

### 2025/07/09 - v1.4.1

**ÂäüËÉΩÊñ∞Â¢û**ÔºöÂ¢ûÂä†Â¢ûÈáèÊé®ÈÄÅ(Âú® main.py Â§¥ÈÉ®ÈÖçÁΩÆ FOCUS_NEW_ONLY)ÔºåËØ•ÂºÄÂÖ≥Âè™ÂÖ≥ÂøÉÊñ∞ËØùÈ¢òËÄåÈùûÊåÅÁª≠ÁÉ≠Â∫¶ÔºåÂè™Âú®ÊúâÊñ∞ÂÜÖÂÆπÊó∂ÊâçÂèëÈÄöÁü•„ÄÇ

**‰øÆÂ§çÈóÆÈ¢ò**: Êüê‰∫õÊÉÖÂÜµ‰∏ãÔºåÁî±‰∫éÊñ∞ÈóªÊú¨Ë∫´Âê´ÊúâÁâπÊÆäÁ¨¶Âè∑ÂØºËá¥ÁöÑÂÅ∂ÂèëÊÄßÊéíÁâàÂºÇÂ∏∏„ÄÇ

### 2025/06/23 - v1.3.0

‰ºÅ‰∏öÂæÆ‰ø° Âíå Telegram ÁöÑÊé®ÈÄÅÊ∂àÊÅØÊúâÈïøÂ∫¶ÈôêÂà∂ÔºåÂØπÊ≠§ÊàëÈááÁî®Â∞ÜÊ∂àÊÅØÊãÜÂàÜÊé®ÈÄÅÁöÑÊñπÂºè„ÄÇÂºÄÂèëÊñáÊ°£ËØ¶ËßÅ[‰ºÅ‰∏öÂæÆ‰ø°](https://developer.work.weixin.qq.com/document/path/91770) Âíå [Telegram](https://core.telegram.org/bots/api)

### 2025/06/21 - v1.2.1

Âú®Êú¨ÁâàÊú¨‰πãÂâçÁöÑÊóßÁâàÊú¨Ôºå‰∏ç‰ªÖ main.py ÈúÄË¶ÅÂ§çÂà∂ÊõøÊç¢Ôºå crawler.yml ‰πüÈúÄË¶Å‰Ω†Â§çÂà∂ÊõøÊç¢
https://github.com/sansan0/TrendRadar/blob/master/.github/workflows/crawler.yml

### 2025/06/19 - v1.2.0

&gt; ÊÑüË∞¢ claude research Êï¥ÁêÜÁöÑÂêÑÂπ≥Âè∞ api ,ËÆ©ÊàëÂø´ÈÄüÂÆåÊàêÂêÑÂπ≥Âè∞ÈÄÇÈÖçÔºàËôΩÁÑ∂‰ª£Á†ÅÊõ¥Â§öÂÜó‰Ωô‰∫Ü~

1. ÊîØÊåÅ telegram Ôºå‰ºÅ‰∏öÂæÆ‰ø°ÔºåÈíâÈíâÊé®ÈÄÅÊ∏†ÈÅì, ÊîØÊåÅÂ§öÊ∏†ÈÅìÈÖçÁΩÆÂíåÂêåÊó∂Êé®ÈÄÅ

### 2025/06/18 - v1.1.0

&gt; **200 star‚≠ê** ‰∫Ü, ÁªßÁª≠ÁªôÂ§ß‰ºôÂÑøÂä©ÂÖ¥~ËøëÊúüÔºåÂú®ÊàëÁöÑ&quot;ÊÄÇÊÅø&quot;‰∏ãÔºåÊå∫Â§ö‰∫∫Âú®ÊàëÂÖ¨‰ºóÂè∑ÁÇπËµûÂàÜ‰∫´Êé®ËçêÂä©Âäõ‰∫ÜÊàëÔºåÊàëÈÉΩÂú®ÂêéÂè∞ÁúãËßÅ‰∫ÜÂÖ∑‰ΩìË¥¶Âè∑ÁöÑÈºìÂä±Êï∞ÊçÆÔºåÂæàÂ§öÈÉΩÊàê‰∫ÜÂ§©‰ΩøËΩÆËÄÅÁ≤âÔºàÊàëÁé©ÂÖ¨‰ºóÂè∑Êâç‰∏Ä‰∏™Â§öÊúàÔºåËôΩÁÑ∂Ê≥®ÂÜåÊòØ‰∏ÉÂÖ´Âπ¥ÂâçÁöÑ‰∫ã‰∫ÜÂìàÂìàÔºåÂ±û‰∫é‰∏äËΩ¶Êó©ÔºåÂèëËΩ¶ÊôöÔºâÔºå‰ΩÜÂõ†‰∏∫‰Ω†‰ª¨Ê≤°ÊúâÁïôË®ÄÊàñÁßÅ‰ø°ÊàëÔºåÊâÄ‰ª•Êàë‰πüÊó†Ê≥ï‰∏Ä‰∏ÄÂõûÂ∫îÂπ∂ÊÑüË∞¢ÊîØÊåÅÔºåÂú®Ê≠§‰∏ÄÂπ∂Ë∞¢Ë∞¢ÔºÅ

1. ÈáçË¶ÅÁöÑÊõ¥Êñ∞ÔºåÂä†‰∫ÜÊùÉÈáçÔºå‰Ω†Áé∞Âú®ÁúãÂà∞ÁöÑÊñ∞ÈóªÈÉΩÊòØÊúÄÁÉ≠ÁÇπÊúÄÊúâÂÖ≥Ê≥®Â∫¶ÁöÑÂá∫Áé∞Âú®ÊúÄ‰∏äÈù¢
2. Êõ¥Êñ∞ÊñáÊ°£‰ΩøÁî®ÔºåÂõ†‰∏∫ËøëÊúüÊõ¥Êñ∞‰∫ÜÂæàÂ§öÂäüËÉΩÔºåËÄå‰∏î‰πãÂâçÁöÑ‰ΩøÁî®ÊñáÊ°£ÊàëÂÅ∑ÊáíÂÜôÁöÑÁÆÄÂçïÔºàËßÅ‰∏ãÈù¢ÁöÑ ‚öôÔ∏è frequency_words.txt ÈÖçÁΩÆÂÆåÊï¥ÊïôÁ®ãÔºâ

### 2025/06/16 - v1.0.0

1. Â¢ûÂä†‰∫Ü‰∏Ä‰∏™È°πÁõÆÊñ∞ÁâàÊú¨Êõ¥Êñ∞ÊèêÁ§∫ÔºåÈªòËÆ§ÊâìÂºÄÔºåÂ¶ÇË¶ÅÂÖ≥ÊéâÔºåÂèØ‰ª•Âú® main.py ‰∏≠Êää &quot;FEISHU_SHOW_VERSION_UPDATE&quot;: True ‰∏≠ÁöÑ True ÊîπÊàê False Âç≥ÂèØ

### 2025/06/13+14

1. ÂéªÊéâ‰∫ÜÂÖºÂÆπ‰ª£Á†ÅÔºå‰πãÂâç fork ÁöÑ

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[SigmaHQ/sigma]]></title>
            <link>https://github.com/SigmaHQ/sigma</link>
            <guid>https://github.com/SigmaHQ/sigma</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[Main Sigma Rule Repository]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/SigmaHQ/sigma">SigmaHQ/sigma</a></h1>
            <p>Main Sigma Rule Repository</p>
            <p>Language: Python</p>
            <p>Stars: 9,967</p>
            <p>Forks: 2,509</p>
            <p>Stars today: 9 stars today</p>
            <h2>README</h2><pre># Sigma - Generic Signature Format for SIEM Systems

&lt;a href=&quot;https://sigmahq.io/&quot;&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;br /&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./images/sigma_logo_dark.png&quot;&gt;
  &lt;img width=&quot;454&quot; alt=&quot;Sigma Logo&quot; src=&quot;./images/sigma_logo_light.png&quot;&gt;
&lt;/picture&gt;
&lt;/p&gt;
&lt;/a&gt;
&lt;br /&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/SigmaHQ/sigma/actions?query=branch%3Amaster&quot;&gt;&lt;img src=&quot;https://github.com/SigmaHQ/sigma/actions/workflows/sigma-test.yml/badge.svg?branch=master&quot; alt=&quot;Sigma Build Status&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://sigmahq.io/&quot;&gt;&lt;img src=&quot;https://cdn.jsdelivr.net/gh/SigmaHQ/sigmahq.github.io@master/images/Sigma%20Official%20Badge.svg&quot; alt=&quot;Sigma Official Badge&quot;&gt;&lt;/a&gt; &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/SigmaHQ/sigma&quot;&gt;
&lt;img alt=&quot;GitHub all releases&quot; src=&quot;https://img.shields.io/github/downloads/SigmaHq/Sigma/total&quot;&gt;
&lt;br /&gt;
&lt;a href=&quot;https://opensourcesecurityindex.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
&lt;img style=&quot;width: 170px;&quot; src=&quot;https://opensourcesecurityindex.io/badge.svg&quot; alt=&quot;Open Source Security Index - Fastest Growing Open Source Security Projects&quot; width=&quot;170&quot; /&gt;
&lt;/a&gt;
&lt;/p&gt;

Welcome to the Sigma main rule repository. The place where detection engineers, threat hunters and all defensive security practitioners collaborate on detection rules. The repository offers more than 3000 detection rules of different type and aims to make reliable detections accessible to all at no cost.

Currently the repository offers three types of rules:

* [Generic Detection Rules](./rules/) - Are threat agnostic, their aim is to detect a behavior or an implementation of a technique or procedure that was, can or will be used by a potential threat actor.
* [Threat Hunting Rules](./rules-threat-hunting/) - Are broader in scope and are meant to give the analyst a starting point to hunt for potential suspicious or malicious activity
* [Emerging Threat Rules](./rules-emerging-threats/) - Are rules that cover specific threats, that are timely and relevant for certain periods of time. These threats include specific APT campaigns, exploitation of Zero-Day vulnerabilities, specific malware used during an attack,...etc.
* [Compliance Rules](./rules-compliance/) - Are rules that help you identify compliance violations based on well known security frameworks such as CIS Controls, NIST, ISO 27001,...etc.
* [Placeholder Rules](./rules-placeholder/) - Are rules that get their final meaning at conversion or usage time of the rule.

## Explore Sigma

To start exploring the Sigma ecosystem, please visit the official website [sigmahq.io](https://sigmahq.io)

### What is Sigma

Sigma is a generic and open signature format that allows you to describe relevant log events in a straightforward manner. The rule format is very flexible, easy to write and applicable to any type of log file.

The main purpose of this project is to provide a structured form in which researchers or analysts can describe their once developed detection methods and make them shareable with others.

Sigma is for log files what [Snort](https://www.snort.org/) is for network traffic and [YARA](https://github.com/VirusTotal/yara) is for files.

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;./images/Sigma_description_dark.png&quot;&gt;
  &lt;img alt=&quot;Sigma Description - A diagram showing Yaml Files (Sigma Rules) moving through a Sigma Convertor, and coming out as many SIEM logos, showing how Sigma rules can be converted to many different available SIEM query languages&quot; src=&quot;./images/Sigma_description_light.png&quot;&gt;
&lt;/picture&gt;

### Why Sigma

Today, everyone collects log data for analysis. People start working on their own, processing numerous white papers, blog posts and log analysis guidelines, extracting the necessary information and build their own searches and dashboard. Some of their searches and correlations are great and very useful but they lack a standardized format in which they can share their work with others.

Others provide excellent analyses, include IOCs and YARA rules to detect the malicious files and network connections, but have no way to describe a specific or generic detection method in log events. Sigma is meant to be an open standard in which such detection mechanisms can be defined, shared and collected in order to improve the detection capabilities for everyone.

### üåü Key Features

* A continuously growing list of detection and hunting rules, peer reviewed by a community of professional Detection Engineers.
* Vendor agnostic detection rules.
* Easily shareable across communities and reports

## üèóÔ∏è Rule Creation

To start writing Sigma rules please check the following high level guide along with the sigma specification:

* [Rule Creation High‚ÄêLevel Guide]([https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-Guide](https://github.com/SigmaHQ/sigma/wiki/Rule-Creation-High%E2%80%90Level-Guide))
* [Sigma Specification](https://github.com/SigmaHQ/sigma-specification)

## üîé Contributing &amp; Making PRs

Please refer to the [CONTRIBUTING](./CONTRIBUTING.md) guide for detailed instructions on how you can start contributing new rules.

## üì¶ Rule Packages

You can download the latest rule packages from the [release page](https://github.com/SigmaHQ/sigma/releases/latest) and start leveraging Sigma rules today.

## üß¨ Rule Usage and Conversion

* You can start converting Sigma rules today using [Sigma CLI](https://github.com/SigmaHQ/sigma-cli) or [sigconverter.io](https://sigconverter.io) the GUI interface

* To integrate Sigma rules in your own toolchain or products use [pySigma](https://github.com/SigmaHQ/pySigma).

## üö® Reporting False Positives or New Rule Ideas

If you find a false positive or would like to propose a new detection rule idea but do not have the time to create one, please create a new issue on the [GitHub repository](https://github.com/SigmaHQ/sigma/issues/new/choose) by selecting one of the available templates.

## üìö Resources &amp; Further Reading

* [Hack.lu 2017 Sigma - Generic Signatures for Log Events by Thomas Patzke](https://www.youtube.com/watch?v=OheVuE9Ifhs)
* [MITRE ATT&amp;CK¬Æ and Sigma Alerting SANS Webcast Recording](https://www.sans.org/webcasts/mitre-att-ck-sigma-alerting-110010 &quot;MITRE ATT&amp;CK¬Æ and Sigma Alerting&quot;)
* [Sigma - Generic Signatures for SIEM Systems by Florian Roth](https://www.slideshare.net/secret/gvgxeXoKblXRcA)

## Projects or Products that use or integrate Sigma rules
* [AlphaSOC](https://docs.alphasoc.com/detections_and_findings/sigma_community/) - Leverages Sigma rules to increase coverage across all supported log sources
* [alterix](https://github.com/mtnmunuklu/alterix) - Converts Sigma rules to the query language of CRYPTTECH&#039;s SIEM
* [AttackIQ](https://www.attackiq.com/2024/01/10/sigmaiq-attackiqs-latest-innovation-for-actionable-detections/) - Sigma Rules integrated in AttackIQ&#039;s platform, and [SigmAIQ](https://github.com/AttackIQ/SigmAIQ) for Sigma rule conversion and LLM apps
* [Atomic Threat Coverage](https://github.com/atc-project/atomic-threat-coverage) (Since December 2018)
* [AttackRuleMap - Mapping of Atomic Red Team tests and Sigma Rules](https://attackrulemap.com/)
* [Confluent Sigma](https://github.com/confluentinc/confluent-sigma) - Kafka Streams supported Sigma rules
* [Detection Studio](https://detection.studio/?ref=sigmahq_readme) - Convert Sigma rules to any supported SIEM.
* [IBM QRadar](https://community.ibm.com/community/user/security/blogs/gladys-koskas1/2023/08/02/qradar-natively-supports-sigma-for-rules-creation)
* [Impede Detection Platform](https://impede.ai/)
* [Joe Sandbox](https://www.joesecurity.org/blog/8225577975210857708)
* [LimaCharlie](https://limacharlie.io/)
* [MISP](http://www.misp-project.org/2017/03/26/MISP.2.4.70.released.html) (Since Version 2.4.70, March 2017)
* [Nextron&#039;s Aurora Agent](https://www.nextron-systems.com/aurora/)
* [Nextron&#039;s THOR Scanner](https://www.nextron-systems.com/thor/) - Scan with Sigma rules on endpoints
* [RANK VASA](https://globenewswire.com/news-release/2019/03/04/1745907/0/en/RANK-Software-to-Help-MSSPs-Scale-Cybersecurity-Offerings.html)
* [Saeros](https://github.com/Saeros-Security/Saeros)
* [Security Onion](https://docs.securityonion.net/en/latest/sigma.html)
* [Sekoia.io XDR](https://www.sekoia.io) - XDR supporting Sigma and Sigma Correlation rules languages
* [sigma2stix](https://github.com/muchdogesec/sigma2stix) - Converts the entire SigmaHQ Ruleset into STIX 2.1 Objects.
  * A versioned archive of sigma2stix STIX 2.1 data is also available to [download here](https://github.com/muchdogesec/cti_knowledge_base_store/tree/main/sigma-rules).
* [SIŒ£GMA](https://github.com/3CORESec/SIEGMA) - SIEM consumable generator that utilizes Sigma for query conversion
* [SOC Prime](https://my.socprime.com/sigma/)
* [TA-Sigma-Searches](https://github.com/dstaulcu/TA-Sigma-Searches) (Splunk App)
* [TimeSketch](https://github.com/google/timesketch/commit/0c6c4b65a6c0f2051d074e87bbb2da2424fa6c35)
* [ypsilon](https://github.com/P4T12ICK/ypsilon) - Automated Use Case Testing

## üìú Maintainers

* [Nasreddine Bencherchali (@nas_bench)](https://twitter.com/nas_bench)
* [Florian Roth (@cyb3rops)](https://twitter.com/cyb3rops)
* [Christian Burkard (@phantinuss)](https://twitter.com/phantinuss)
* [Fran√ßois Hubaut (@frack113)](https://twitter.com/frack113)
* [Thomas Patzke (@blubbfiction)](https://twitter.com/blubbfiction)

## Credits

This project would&#039;ve never reached this height without the help of the hundreds of contributors. Thanks to all past and present contributors for their help.

## Licenses

The content of this repository is released under the [Detection Rule License (DRL) 1.1](https://github.com/SigmaHQ/Detection-Rule-License).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[hesreallyhim/awesome-claude-code]]></title>
            <link>https://github.com/hesreallyhim/awesome-claude-code</link>
            <guid>https://github.com/hesreallyhim/awesome-claude-code</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[A curated list of awesome commands, files, and workflows for Claude Code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/hesreallyhim/awesome-claude-code">hesreallyhim/awesome-claude-code</a></h1>
            <p>A curated list of awesome commands, files, and workflows for Claude Code</p>
            <p>Language: Python</p>
            <p>Stars: 18,996</p>
            <p>Forks: 1,085</p>
            <p>Stars today: 94 stars today</p>
            <h2>README</h2><pre>&lt;!--lint disable remark-lint:awesome-badge--&gt;

&lt;h3 align=&quot;center&quot;&gt;Pick Your Style:&lt;/h3&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;./&quot;&gt;&lt;img src=&quot;assets/badge-style-extra.svg&quot; alt=&quot;Extra&quot; height=&quot;28&quot; style=&quot;border: 2px solid #6a6a8a; border-radius: 6px;&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;README_ALTERNATIVES/README_CLASSIC.md&quot;&gt;&lt;img src=&quot;assets/badge-style-classic.svg&quot; alt=&quot;Classic&quot; height=&quot;28&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;README_ALTERNATIVES/README_FLAT_ALL_AZ.md&quot;&gt;&lt;img src=&quot;assets/badge-style-flat.svg&quot; alt=&quot;Flat&quot; height=&quot;28&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot; id=&quot;awesome-claude-code&quot;&gt;

[![Awesome](https://awesome.re/badge-flat2.svg)](https://awesome.re)

&lt;/div&gt;

&lt;!-- Terminal Header - Theme Adaptive --&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/terminal-header.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/terminal-header-light-anim-lineprint.svg&quot;&gt;
  &lt;img src=&quot;assets/terminal-header-light-anim-lineprint.svg&quot; alt=&quot;Awesome Claude Code Terminal&quot;&gt;
&lt;/picture&gt;

&lt;!-- Generated with https://github.com/denvercoder1/readme-typing-svg --&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;br /&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/repo-ticker.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/repo-ticker-light.svg&quot;&gt;
  &lt;img src=&quot;assets/repo-ticker-light.svg&quot; alt=&quot;Awesome Claude Code Repo Ticker&quot; width=&quot;100%&quot;&gt;
&lt;/picture&gt;

&lt;/div&gt;

&lt;!--lint enable remark-lint:awesome-badge--&gt;

&lt;br&gt;

&lt;!-- Info Terminal - Theme Adaptive --&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/info-terminal.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/info-terminal-light-vintage.svg&quot;&gt;
  &lt;img src=&quot;assets/info-terminal-light-vintage.svg&quot; alt=&quot;System Info Terminal&quot; width=&quot;100%&quot;&gt;
&lt;/picture&gt;

&lt;!--lint enable remark-lint:awesome-badge--&gt;

&lt;br&gt;

&lt;!-- Intro Terminal - Theme Adaptive --&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/intro-terminal.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/intro-terminal-light-vintage.svg&quot;&gt;
  &lt;img src=&quot;assets/intro-terminal-light-vintage.svg&quot; alt=&quot;About Claude Code&quot; width=&quot;100%&quot; style=&quot;max-width: 900px;&quot;&gt;
&lt;/picture&gt;
&lt;/div&gt;

&lt;!-- Design Credit &amp; Disclaimer - Theme Adaptive --&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/designed-by-badge.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/designed-by-badge-light.svg&quot;&gt;
    &lt;img src=&quot;assets/designed-by-badge-light.svg&quot; alt=&quot;Designed by Claude Code Web&quot; width=&quot;280&quot;&gt;
  &lt;/picture&gt;
  &lt;br&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/disclaimer.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/disclaimer-light.svg&quot;&gt;
    &lt;img src=&quot;assets/disclaimer-light.svg&quot; alt=&quot;Disclaimer: Not affiliated or endorsed by Anthropic PBC. Claude Code is a product of Anthropic.&quot; width=&quot;320&quot;&gt;
  &lt;/picture&gt;
&lt;/div&gt;

&lt;!--  --&gt;

&lt;div align=&quot;center&quot;&gt;
  &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;img src=&quot;assets/thinking-asterisk.svg&quot; alt=&quot;*&quot; width=&quot;18&quot; /&gt; &lt;a href=&quot;https://git.io/typing-svg&quot;&gt;&lt;img align=&quot;center&quot; src=&quot;https://readme-typing-svg.demolab.com/?font=Fira+Code&amp;weight=600&amp;duration=3000&amp;pause=100&amp;color=F7080D&amp;width=300&amp;lines=Lollygagging...;Skedaddling...;Bumbershooting...;Widdershinning...;Higgledy-piggledying...;Doodlebugging...;Fiddle-faddling...;Whimwhamming...;Dilly-dallying...;Flapdoodling...;Ballyhooing...;Galumphing...;Razzle-dazzling...;Tiddle-taddling...;Zigzagging...;Twinkletoeing...;Puddle-jumping...;Snicker-snacking...;Jibber-jabbering...;Frabjoussing...;Piffle-puffling...;Whirligigging...;Bibbity-bobbitying...;&quot; /&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

### ‚ö° TERMINAL NAVIGATION ‚ö°

&lt;table&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;#agent-skills-&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/card-skills.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/card-skills-light-anim-lineprint.svg&quot;&gt;
  &lt;img src=&quot;assets/card-skills-light-anim-lineprint.svg&quot; alt=&quot;Agent Skills&quot; width=&quot;200&quot;/&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;#workflows-knowledge-guides-&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/card-workflows.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/card-workflows-light-anim-lineprint.svg&quot;&gt;
  &lt;img src=&quot;assets/card-workflows-light-anim-lineprint.svg&quot; alt=&quot;Workflows&quot; width=&quot;200&quot;/&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;#tooling-&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/card-tooling.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/card-tooling-light-anim-lineprint.svg&quot;&gt;
  &lt;img src=&quot;assets/card-tooling-light-anim-lineprint.svg&quot; alt=&quot;Tooling&quot; width=&quot;200&quot;/&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;#status-lines-&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/card-statusline.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/card-statusline-light-anim-lineprint.svg&quot;&gt;
  &lt;img src=&quot;assets/card-statusline-light-anim-lineprint.svg&quot; alt=&quot;Status Lines&quot; width=&quot;200&quot;/&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;#hooks-&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/card-custom.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/card-custom-light-anim-lineprint.svg&quot;&gt;
  &lt;img src=&quot;assets/card-custom-light-anim-lineprint.svg&quot; alt=&quot;Hooks&quot; width=&quot;200&quot;/&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;#slash-commands-&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/card-commands.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/card-commands-light-anim-lineprint.svg&quot;&gt;
  &lt;img src=&quot;assets/card-commands-light-anim-lineprint.svg&quot; alt=&quot;Slash Commands&quot; width=&quot;200&quot;/&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;#claudemd-files-&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/card-config.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/card-config-light-anim-lineprint.svg&quot;&gt;
  &lt;img src=&quot;assets/card-config-light-anim-lineprint.svg&quot; alt=&quot;CLAUDE.md Files&quot; width=&quot;200&quot;/&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;#alternative-clients-&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/card-clients.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/card-clients-light-anim-lineprint.svg&quot;&gt;
  &lt;img src=&quot;assets/card-clients-light-anim-lineprint.svg&quot; alt=&quot;Alternative Clients&quot; width=&quot;200&quot;/&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;
&lt;a href=&quot;#official-documentation-&quot;&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/card-docs.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/card-docs-light-anim-lineprint.svg&quot;&gt;
  &lt;img src=&quot;assets/card-docs-light-anim-lineprint.svg&quot; alt=&quot;Documentation&quot; width=&quot;200&quot;/&gt;
&lt;/picture&gt;
&lt;/a&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;/div&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/latest-additions-header.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/latest-additions-header-light.svg&quot;&gt;
    &lt;img src=&quot;assets/latest-additions-header-light.svg&quot; alt=&quot;LATEST ADDITIONS&quot;&gt;
  &lt;/picture&gt;
&lt;/div&gt;

&lt;a href=&quot;https://github.com/danielrosehill/Claude-Code-Repos-Index&quot;&gt;&lt;img src=&quot;assets/badge-claude-code-repos-index.svg&quot; alt=&quot;Claude Code Repos Index&quot;&gt;&lt;/a&gt;  
_This is either the work of a prolific genius, or a very clever bot (or both), although it hardly matters because the quality is so good - an index of 75+ Claude Code repositories published by the author - and I&#039;m not talking about slop. CMS, system design, deep research, IoT, agentic workflows, server management, personal health... If you spot the lie, let me know, otherwise please check these out._  
![GitHub Stats for Claude-Code-Repos-Index](https://github-readme-stats-plus-theta.vercel.app/api/pin/?repo=Claude-Code-Repos-Index&amp;username=danielrosehill&amp;all_stats=true&amp;stats_only=true&amp;hide_border=true&amp;bg_color=00000000&amp;icon_color=FF0000&amp;text_color=FF0000)

&lt;a href=&quot;https://github.com/ykdojo/claude-code-tips&quot;&gt;&lt;img src=&quot;assets/badge-claude-code-tips.svg&quot; alt=&quot;Claude Code Tips&quot;&gt;&lt;/a&gt;  
_A nice variety of 35+ brief but information-dense Claude Code tips covering voice input, system prompt patching, container workflows for risky tasks, conversation cloning(!), multi-model orchestration with Gemini CLI, and plenty more. Nice demos, working scripts, a plugin, I&#039;d say this probably has a little something for everyone._  
![GitHub Stats for claude-code-tips](https://github-readme-stats-plus-theta.vercel.app/api/pin/?repo=claude-code-tips&amp;username=ykdojo&amp;all_stats=true&amp;stats_only=true&amp;hide_border=true&amp;bg_color=00000000&amp;icon_color=FF0000&amp;text_color=FF0000)

&lt;a href=&quot;https://github.com/obra/superpowers&quot;&gt;&lt;img src=&quot;assets/badge-superpowers.svg&quot; alt=&quot;Superpowers&quot;&gt;&lt;/a&gt;  
_A strong bundle of core competencies for software engineering, with good coverage of a large portion of the SDLC - from planning, reviewing, testing, debugging... Well written, well organized, and adaptable. The author refers to them as &quot;superpowers&quot;, but many of them are just consolidating engineering best practices - which sometimes does feel like a superpower when working with Claude Code._  
![GitHub Stats for superpowers](https://github-readme-stats-plus-theta.vercel.app/api/pin/?repo=superpowers&amp;username=obra&amp;all_stats=true&amp;stats_only=true&amp;hide_border=true&amp;bg_color=00000000&amp;icon_color=FF0000&amp;text_color=FF0000)


&lt;br&gt;

&lt;div align=&quot;left&quot;&gt;

&lt;div style=&quot;overflow-x:auto;white-space:nowrap;text-align:left;&quot;&gt;
&lt;div style=&quot;height:48px;width:400px;overflow:hidden;display:block;&quot;&gt;&lt;!-- Directory Tree Terminal - Theme Adaptive --&gt;
&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-header.svg&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-header-light-anim-scanline.svg&quot;&gt;
  &lt;img src=&quot;assets/toc-header-light-anim-scanline.svg&quot; alt=&quot;Directory Listing&quot; height=&quot;48&quot; style=&quot;height:48px;max-width:none;&quot;&gt;
&lt;/picture&gt;&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#agent-skills-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-row-skills.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-row-skills-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-row-skills-light-anim-scanline.svg&quot; alt=&quot;Agent Skills&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#skills-general&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-general.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot; alt=&quot;General&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#workflows--knowledge-guides-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-row-workflows.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-row-workflows-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-row-workflows-light-anim-scanline.svg&quot; alt=&quot;Workflows &amp; Knowledge Guides&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#workflows-general&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-general.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot; alt=&quot;General&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#tooling-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-row-tooling.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-row-tooling-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-row-tooling-light-anim-scanline.svg&quot; alt=&quot;Tooling&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#tooling-general&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-general.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot; alt=&quot;General&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#ide-integrations-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-ide.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-ide-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-ide-light-anim-scanline.svg&quot; alt=&quot;IDE Integrations&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#usage-monitors-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-monitors.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-monitors-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-monitors-light-anim-scanline.svg&quot; alt=&quot;Usage Monitors&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#orchestrators-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-orchestrators.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-orchestrators-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-orchestrators-light-anim-scanline.svg&quot; alt=&quot;Orchestrators&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#status-lines-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-row-statusline.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-row-statusline-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-row-statusline-light-anim-scanline.svg&quot; alt=&quot;Status Lines&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#statusline-general&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-general.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot; alt=&quot;General&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#hooks-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-row-custom.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-row-custom-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-row-custom-light-anim-scanline.svg&quot; alt=&quot;Hooks&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#hooks-general&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-general.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot; alt=&quot;General&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#slash-commands-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-row-commands.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-row-commands-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-row-commands-light-anim-scanline.svg&quot; alt=&quot;Slash-Commands&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#slash-commands-general&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-general.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-general-light-anim-scanline.svg&quot; alt=&quot;General&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#version-control--git-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-git.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-git-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-git-light-anim-scanline.svg&quot; alt=&quot;Version Control &amp; Git&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#code-analysis--testing-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-code-analysis.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-code-analysis-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-code-analysis-light-anim-scanline.svg&quot; alt=&quot;Code Analysis &amp; Testing&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#context-loading--priming-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-context.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-context-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-context-light-anim-scanline.svg&quot; alt=&quot;Context Loading &amp; Priming&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#documentation--changelogs-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-documentation.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-documentation-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-documentation-light-anim-scanline.svg&quot; alt=&quot;Documentation &amp; Changelogs&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#ci--deployment-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-ci.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-ci-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-ci-light-anim-scanline.svg&quot; alt=&quot;CI / Deployment&quot; height=&quot;40&quot; style=&quot;height:40px;max-width:none;&quot;&gt;
  &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;
&lt;div style=&quot;height:40px;width:400px;overflow:hidden;display:block;&quot;&gt;
&lt;a href=&quot;#project--task-management-&quot;&gt;
  &lt;picture&gt;
    &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;assets/toc-sub-project-mgmt.svg&quot;&gt;
    &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;assets/toc-sub-project-mgmt-light-anim-scanline.svg&quot;&gt;
    &lt;img src=&quot;assets/toc-sub-project-mgmt-light-anim-scanline.svg&quot; alt=&quot;Project &amp; Task Management&quot; height=&quot;40&quot; style=&quot;height

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[zylon-ai/private-gpt]]></title>
            <link>https://github.com/zylon-ai/private-gpt</link>
            <guid>https://github.com/zylon-ai/private-gpt</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[Interact with your documents using the power of GPT, 100% privately, no data leaks]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zylon-ai/private-gpt">zylon-ai/private-gpt</a></h1>
            <p>Interact with your documents using the power of GPT, 100% privately, no data leaks</p>
            <p>Language: Python</p>
            <p>Stars: 56,977</p>
            <p>Forks: 7,595</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># PrivateGPT 

&lt;a href=&quot;https://trendshift.io/repositories/2601&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/2601&quot; alt=&quot;imartinez%2FprivateGPT | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

[![Tests](https://github.com/zylon-ai/private-gpt/actions/workflows/tests.yml/badge.svg)](https://github.com/zylon-ai/private-gpt/actions/workflows/tests.yml?query=branch%3Amain)
[![Website](https://img.shields.io/website?up_message=check%20it&amp;down_message=down&amp;url=https%3A%2F%2Fdocs.privategpt.dev%2F&amp;label=Documentation)](https://docs.privategpt.dev/)
[![Discord](https://img.shields.io/discord/1164200432894234644?logo=discord&amp;label=PrivateGPT)](https://discord.gg/bK6mRVpErU)
[![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/ZylonPrivateGPT)](https://twitter.com/ZylonPrivateGPT)

![Gradio UI](/fern/docs/assets/ui.png?raw=true)

PrivateGPT is a production-ready AI project that allows you to ask questions about your documents using the power
of Large Language Models (LLMs), even in scenarios without an Internet connection. 100% private, no data leaves your
execution environment at any point.

&gt;[!TIP]
&gt; If you are looking for an **enterprise-ready, fully private AI workspace**
&gt; check out [Zylon&#039;s website](https://zylon.ai)  or [request a demo](https://cal.com/zylon/demo?source=pgpt-readme).
&gt; Crafted by the team behind PrivateGPT, Zylon is a best-in-class AI collaborative
&gt; workspace that can be easily deployed on-premise (data center, bare metal...) or in your private cloud (AWS, GCP, Azure...).

The project provides an API offering all the primitives required to build private, context-aware AI applications.
It follows and extends the [OpenAI API standard](https://openai.com/blog/openai-api),
and supports both normal and streaming responses.

The API is divided into two logical blocks:

**High-level API**, which abstracts all the complexity of a RAG (Retrieval Augmented Generation)
pipeline implementation:
- Ingestion of documents: internally managing document parsing,
splitting, metadata extraction, embedding generation and storage.
- Chat &amp; Completions using context from ingested documents:
abstracting the retrieval of context, the prompt engineering and the response generation.

**Low-level API**, which allows advanced users to implement their own complex pipelines:
- Embeddings generation: based on a piece of text.
- Contextual chunks retrieval: given a query, returns the most relevant chunks of text from the ingested documents.

In addition to this, a working [Gradio UI](https://www.gradio.app/)
client is provided to test the API, together with a set of useful tools such as bulk model
download script, ingestion script, documents folder watch, etc.

## üéûÔ∏è Overview
&gt;[!WARNING]
&gt;  This README is not updated as frequently as the [documentation](https://docs.privategpt.dev/).
&gt;  Please check it out for the latest updates!

### Motivation behind PrivateGPT
Generative AI is a game changer for our society, but adoption in companies of all sizes and data-sensitive
domains like healthcare or legal is limited by a clear concern: **privacy**.
Not being able to ensure that your data is fully under your control when using third-party AI tools
is a risk those industries cannot take.

### Primordial version
The first version of PrivateGPT was launched in May 2023 as a novel approach to address the privacy
concerns by using LLMs in a complete offline way.

That version, which rapidly became a go-to project for privacy-sensitive setups and served as the seed
for thousands of local-focused generative AI projects, was the foundation of what PrivateGPT is becoming nowadays;
thus a simpler and more educational implementation to understand the basic concepts required
to build a fully local -and therefore, private- chatGPT-like tool.

If you want to keep experimenting with it, we have saved it in the
[primordial branch](https://github.com/zylon-ai/private-gpt/tree/primordial) of the project.

&gt; It is strongly recommended to do a clean clone and install of this new version of
PrivateGPT if you come from the previous, primordial version.

### Present and Future of PrivateGPT
PrivateGPT is now evolving towards becoming a gateway to generative AI models and primitives, including
completions, document ingestion, RAG pipelines and other low-level building blocks.
We want to make it easier for any developer to build AI applications and experiences, as well as provide
a suitable extensive architecture for the community to keep contributing.

Stay tuned to our [releases](https://github.com/zylon-ai/private-gpt/releases) to check out all the new features and changes included.

## üìÑ Documentation
Full documentation on installation, dependencies, configuration, running the server, deployment options,
ingesting local documents, API details and UI features can be found here: https://docs.privategpt.dev/

## üß© Architecture
Conceptually, PrivateGPT is an API that wraps a RAG pipeline and exposes its
primitives.
* The API is built using [FastAPI](https://fastapi.tiangolo.com/) and follows
  [OpenAI&#039;s API scheme](https://platform.openai.com/docs/api-reference).
* The RAG pipeline is based on [LlamaIndex](https://www.llamaindex.ai/).

The design of PrivateGPT allows to easily extend and adapt both the API and the
RAG implementation. Some key architectural decisions are:
* Dependency Injection, decoupling the different components and layers.
* Usage of LlamaIndex abstractions such as `LLM`, `BaseEmbedding` or `VectorStore`,
  making it immediate to change the actual implementations of those abstractions.
* Simplicity, adding as few layers and new abstractions as possible.
* Ready to use, providing a full implementation of the API and RAG
  pipeline.

Main building blocks:
* APIs are defined in `private_gpt:server:&lt;api&gt;`. Each package contains an
  `&lt;api&gt;_router.py` (FastAPI layer) and an `&lt;api&gt;_service.py` (the
  service implementation). Each *Service* uses LlamaIndex base abstractions instead
  of specific implementations,
  decoupling the actual implementation from its usage.
* Components are placed in
  `private_gpt:components:&lt;component&gt;`. Each *Component* is in charge of providing
  actual implementations to the base abstractions used in the Services - for example
  `LLMComponent` is in charge of providing an actual implementation of an `LLM`
  (for example `LlamaCPP` or `OpenAI`).

## üí° Contributing
Contributions are welcomed! To ensure code quality we have enabled several format and
typing checks, just run `make check` before committing to make sure your code is ok.
Remember to test your code! You&#039;ll find a tests folder with helpers, and you can run
tests using `make test` command.

Don&#039;t know what to contribute? Here is the public 
[Project Board](https://github.com/users/imartinez/projects/3) with several ideas. 

Head over to Discord 
#contributors channel and ask for write permissions on that GitHub project.

## üí¨ Community
Join the conversation around PrivateGPT on our:
- [Twitter (aka X)](https://twitter.com/PrivateGPT_AI)
- [Discord](https://discord.gg/bK6mRVpErU)

## üìñ Citation
If you use PrivateGPT in a paper, check out the [Citation file](CITATION.cff) for the correct citation.  
You can also use the &quot;Cite this repository&quot; button in this repo to get the citation in different formats.

Here are a couple of examples:

#### BibTeX
```bibtex
@software{Zylon_PrivateGPT_2023,
author = {Zylon by PrivateGPT},
license = {Apache-2.0},
month = may,
title = {{PrivateGPT}},
url = {https://github.com/zylon-ai/private-gpt},
year = {2023}
}
```

#### APA
```
Zylon by PrivateGPT (2023). PrivateGPT [Computer software]. https://github.com/zylon-ai/private-gpt
```

## ü§ó Partners &amp; Supporters
PrivateGPT is actively supported by the teams behind:
* [Qdrant](https://qdrant.tech/), providing the default vector database
* [Fern](https://buildwithfern.com/), providing Documentation and SDKs
* [LlamaIndex](https://www.llamaindex.ai/), providing the base RAG framework and abstractions

This project has been strongly influenced and supported by other amazing projects like 
[LangChain](https://github.com/hwchase17/langchain),
[GPT4All](https://github.com/nomic-ai/gpt4all),
[LlamaCpp](https://github.com/ggerganov/llama.cpp),
[Chroma](https://www.trychroma.com/)
and [SentenceTransformers](https://www.sbert.net/).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[TheAlgorithms/Python]]></title>
            <link>https://github.com/TheAlgorithms/Python</link>
            <guid>https://github.com/TheAlgorithms/Python</guid>
            <pubDate>Wed, 31 Dec 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[All Algorithms implemented in Python]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/TheAlgorithms/Python">TheAlgorithms/Python</a></h1>
            <p>All Algorithms implemented in Python</p>
            <p>Language: Python</p>
            <p>Stars: 216,273</p>
            <p>Forks: 49,814</p>
            <p>Stars today: 209 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;!-- Title: --&gt;
  &lt;a href=&quot;https://github.com/TheAlgorithms/&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/TheAlgorithms/website/1cd824df116b27029f17c2d1b42d81731f28a920/public/logo.svg&quot; height=&quot;100&quot;&gt;
  &lt;/a&gt;
  &lt;h1&gt;&lt;a href=&quot;https://github.com/TheAlgorithms/&quot;&gt;The Algorithms&lt;/a&gt; - Python&lt;/h1&gt;

&lt;!-- Labels: --&gt;
  &lt;!-- First row: --&gt;
  &lt;a href=&quot;https://gitpod.io/#https://github.com/TheAlgorithms/Python&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Gitpod Ready-to-Code&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/static/v1.svg?label=Contributions&amp;message=Welcome&amp;color=0059b3&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Contributions Welcome&quot;&gt;
  &lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;style=flat-square&quot; height=&quot;20&quot;&gt;
  &lt;a href=&quot;https://the-algorithms.com/discord&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;colorB=7289DA&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Discord chat&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://gitter.im/TheAlgorithms/community&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;logo=gitter&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Gitter chat&quot;&gt;
  &lt;/a&gt;

  &lt;!-- Second row: --&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://github.com/TheAlgorithms/Python/actions&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/TheAlgorithms/Python/build.yml?branch=master&amp;label=CI&amp;logo=github&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;GitHub Workflow Status&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/pre-commit/pre-commit&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;logoColor=white&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;pre-commit&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://docs.astral.sh/ruff/formatter/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/static/v1?label=code%20style&amp;message=ruff&amp;color=black&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;code style: black&quot;&gt;
  &lt;/a&gt;

&lt;!-- Short description: --&gt;
  &lt;h3&gt;All algorithms implemented in Python - for education üìö&lt;/h3&gt;
&lt;/div&gt;

Implementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.

## üöÄ Getting Started

üìã Read through our [Contribution Guidelines](CONTRIBUTING.md) before you contribute.

## üåê Community Channels

We are on [Discord](https://the-algorithms.com/discord) and [Gitter](https://gitter.im/TheAlgorithms/community)! Community channels are a great way for you to ask questions and get help. Please join us!

## üìú List of Algorithms

See our [directory](DIRECTORY.md) for easier navigation and a better overview of the project.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>