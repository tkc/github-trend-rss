<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Tue, 24 Feb 2026 00:07:22 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[huggingface/skills]]></title>
            <link>https://github.com/huggingface/skills</link>
            <guid>https://github.com/huggingface/skills</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:22 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/skills">huggingface/skills</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 3,858</p>
            <p>Forks: 268</p>
            <p>Stars today: 1,451 stars today</p>
            <h2>README</h2><pre># Hugging Face Skills

Hugging Face Skills are definitions for AI/ML tasks like dataset creation, model training, and evaluation. They are interoperable with all major coding agent tools like OpenAI Codex, Anthropic&#039;s Claude Code, Google DeepMind&#039;s Gemini CLI, and Cursor.

The Skills in this repository follow the standardized format [Agent Skill](https://agentskills.io/home) format.

## How do Skills work?

In practice, skills are self-contained folders that package instructions, scripts, and resources together for an AI agent to use on a specific use case. Each folder includes a `SKILL.md` file with YAML frontmatter (name and description) followed by the guidance your coding agent follows while the skill is active. 

&gt; [!NOTE]
&gt; &#039;Skills&#039; is actually an Anthropic term used within Claude AI and Claude Code and not adopted by other agent tools, but we love it! OpenAI Codex uses an `AGENTS.md` file to define the instructions for your coding agent. Google Gemini uses &#039;extensions&#039; to define the instructions for your coding agent in a `gemini-extension.json` file. **This repo is compatible with all of them, and more!**

&gt; [!TIP]
&gt; If your agent doesn&#039;t support skills, you can use [`agents/AGENTS.md`](agents/AGENTS.md) directly as a fallback.

## Installation

Hugging Face skills are compatible with Claude Code, Codex, Gemini CLI, and Cursor.

### Claude Code

1. Register the repository as a plugin marketplace:  
   
```
/plugin marketplace add huggingface/skills
```

2. To install a skill, run:  
   
```
/plugin install &lt;skill-name&gt;@huggingface/skills
```

For example:  

```
/plugin install hugging-face-cli@huggingface/skills
```

### Codex

1. Codex will identify the skills via the `AGENTS.md` file. You can verify the instructions are loaded with:

```
codex --ask-for-approval never &quot;Summarize the current instructions.&quot;
```

2. For more details, see the [Codex AGENTS guide](https://developers.openai.com/codex/guides/agents-md).

### Gemini CLI

1. This repo includes `gemini-extension.json` to integrate with the Gemini CLI.

2. Install locally:  

```
gemini extensions install . --consent
```

or use the GitHub URL:

```
gemini extensions install https://github.com/huggingface/skills.git --consent
```

4. See [Gemini CLI extensions docs](https://geminicli.com/docs/extensions/#installing-an-extension) for more help.

### Cursor

This repository includes Cursor plugin manifests:

- `.cursor-plugin/plugin.json`
- `.mcp.json` (configured with the Hugging Face MCP server URL)

Install from repository URL (or local checkout) via the Cursor plugin flow.

For contributors, regenerate manifests with:

```bash
./scripts/publish.sh
```

## Skills

This repository contains a few skills to get you started. You can also contribute your own skills to the repository.

### Available skills

&lt;!-- This table is auto-generated by scripts/generate_agents.py. Do not edit manually. --&gt;
&lt;!-- BEGIN_SKILLS_TABLE --&gt;
| Name | Description | Documentation |
|------|-------------|---------------|
| `hugging-face-cli` | Execute Hugging Face Hub operations using the hf CLI. Download models/datasets, upload files, manage repos, and run cloud compute jobs. | [SKILL.md](skills/hugging-face-cli/SKILL.md) |
| `hugging-face-datasets` | Create and manage datasets on Hugging Face Hub. Supports initializing repos, defining configs/system prompts, streaming row updates, and SQL-based dataset querying/transformation. | [SKILL.md](skills/hugging-face-datasets/SKILL.md) |
| `hugging-face-evaluation` | Add and manage evaluation results in Hugging Face model cards. Supports extracting eval tables from README content, importing scores from Artificial Analysis API, and running custom evaluations with vLLM/lighteval. | [SKILL.md](skills/hugging-face-evaluation/SKILL.md) |
| `hugging-face-jobs` | Run compute jobs on Hugging Face infrastructure. Execute Python scripts, manage scheduled jobs, and monitor job status. | [SKILL.md](skills/hugging-face-jobs/SKILL.md) |
| `hugging-face-model-trainer` | Train or fine-tune language models using TRL on Hugging Face Jobs infrastructure. Covers SFT, DPO, GRPO and reward modeling training methods, plus GGUF conversion for local deployment. Includes hardware selection, cost estimation, Trackio monitoring, and Hub persistence. | [SKILL.md](skills/hugging-face-model-trainer/SKILL.md) |
| `hugging-face-paper-publisher` | Publish and manage research papers on Hugging Face Hub. Supports creating paper pages, linking papers to models/datasets, claiming authorship, and generating professional markdown-based research articles. | [SKILL.md](skills/hugging-face-paper-publisher/SKILL.md) |
| `hugging-face-tool-builder` | Build reusable scripts for Hugging Face API operations. Useful for chaining API calls or automating repeated tasks. | [SKILL.md](skills/hugging-face-tool-builder/SKILL.md) |
| `hugging-face-trackio` | Track and visualize ML training experiments with Trackio. Log metrics via Python API and retrieve them via CLI. Supports real-time dashboards synced to HF Spaces. | [SKILL.md](skills/hugging-face-trackio/SKILL.md) |
&lt;!-- END_SKILLS_TABLE --&gt;

### Using skills in your coding agent

Once a skill is installed, mention it directly while giving your coding agent instructions:

- &quot;Use the HF LLM trainer skill to estimate the GPU memory needed for a 70B model run.&quot;
- &quot;Use the HF model evaluation skill to launch `run_eval_job.py` on the latest checkpoint.&quot;
- &quot;Use the HF dataset creator skill to draft new few-shot classification templates.&quot;
- &quot;Use the HF paper publisher skill to index my arXiv paper and link it to my model.&quot;

Your coding agent automatically loads the corresponding `SKILL.md` instructions and helper scripts while it completes the task.

### Contribute or customize a skill

1. Copy one of the existing skill folders (for example, `hf-datasets/`) and rename it.
2. Update the new folder&#039;s `SKILL.md` frontmatter:
   ```markdown
   ---
   name: my-skill-name
   description: Describe what the skill does and when to use it
   ---

   # Skill Title
   Guidance + examples + guardrails
   ```
3. Add or edit supporting scripts, templates, and documents referenced by your instructions.
4. Add an entry to `.claude-plugin/marketplace.json` with a concise, human-readable description.
5. Run:
   ```bash
   ./scripts/publish.sh
   ```
   to regenerate and validate all generated metadata.
6. Reinstall or reload the skill bundle in your coding agent so the updated folder is available.

### Marketplace

The `.claude-plugin/marketplace.json` file lists skills with human-readable descriptions for the plugin marketplace. The CI validates that skill names and paths match between `SKILL.md` files and `marketplace.json`, but descriptions are maintained separately: `SKILL.md` descriptions guide when Claude activates the skill, while marketplace descriptions are written for humans browsing available skills.

### Additional references
- Browse the latest instructions, scripts, and templates directly at [huggingface/skills](https://github.com/huggingface/skills).
- Review Hugging Face documentation for the specific libraries or workflows you reference inside each skill.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OpenBB-finance/OpenBB]]></title>
            <link>https://github.com/OpenBB-finance/OpenBB</link>
            <guid>https://github.com/OpenBB-finance/OpenBB</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:21 GMT</pubDate>
            <description><![CDATA[Financial data platform for analysts, quants and AI agents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBB-finance/OpenBB">OpenBB-finance/OpenBB</a></h1>
            <p>Financial data platform for analysts, quants and AI agents.</p>
            <p>Language: Python</p>
            <p>Stars: 61,423</p>
            <p>Forks: 5,989</p>
            <p>Stars today: 470 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/odp-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;Open Data Platform by OpenBB logo&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/odp-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;Open Data Platform by OpenBB logo&quot; width=&quot;600&quot;&gt;
&lt;br /&gt;
&lt;br /&gt;

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)
[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)
&lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt;
  &lt;img src=&quot;https://github.com/codespaces/badge.svg&quot; height=&quot;20&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;
[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&amp;label=PyPI%20Package)](https://pypi.org/project/openbb/)

Open Data Platform by OpenBB (ODP) is the open-source toolset that helps data engineers integrate proprietary, licensed, and public data sources into downstream applications like AI copilots and research dashboards.

ODP operates as the &quot;connect once, consume everywhere&quot; infrastructure layer that consolidates and exposes data to multiple surfaces at once: Python environments for quants, OpenBB Workspace and Excel for analysts, MCP servers for AI agents, and REST APIs for other applications.

&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/70b971ef-7a7e-486e-b5ae-1cc602f2162c.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Get started with: `pip install openbb`

```python
from openbb import obb
output = obb.equity.price.historical(&quot;AAPL&quot;)
df = output.to_dataframe()
```

Data integrations available can be found here: &lt;https://docs.openbb.co/python/reference&gt;

---

## OpenBB Workspace

While the Open Data Platform provides the open-source data integration foundation, **OpenBB Workspace** offers the enterprise UI for analysts to visualize datasets and leverage AI agents. The platform&#039;s &quot;connect once, consume everywhere&quot; architecture enables seamless integration between the two.

You can find OpenBB Workspace at &lt;https://pro.openbb.co&gt;.
&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Data integration:

- You can learn more about adding data to the OpenBB workspace from the [docs](https://docs.openbb.co/workspace) or [this open source repository](https://github.com/OpenBB-finance/backends-for-openbb).

AI Agents integration:

- You can learn more about adding AI agents to the OpenBB workspace from [this open source repository](https://github.com/OpenBB-finance/agents-for-openbb).

### Integrating Open Data Platform to the OpenBB Workspace

Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.

#### Run an ODP backend

- Install the packages.

```sh
pip install &quot;openbb[all]&quot;
```

- Start the API server over localhost.

```sh
openbb-api
```

This will launch a FastAPI server, via Uvicorn, at `127.0.0.1:6900`.

You can check that it works by going to &lt;http://127.0.0.1:6900&gt;.

#### Integrate the ODP Backend to OpenBB Workspace

Sign-in to the [OpenBB Workspace](https://pro.openbb.co/), and follow the following steps:

![CleanShot 2025-05-17 at 09 51 56@2x](https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069)

1. Go to the &quot;Apps&quot; tab
2. Click on &quot;Connect backend&quot;
3. Fill in the form with:
   Name: Open Data Platform
   URL: &lt;http://127.0.0.1:6900&gt;
4. Click on &quot;Test&quot;. You should get a &quot;Test successful&quot; with the number of apps found.
5. Click on &quot;Add&quot;.

That&#039;s it.

---

&lt;!-- TABLE OF CONTENTS --&gt;
&lt;details closed=&quot;closed&quot;&gt;
  &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

## 1. Installation

The ODP Python Package can be installed from [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`

or by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process, in the [OpenBB Documentation](https://docs.openbb.co/python/installation).

### ODP CLI installation

The ODP CLI is a command-line interface that allows you to access the ODP directly from your command line.

It can be installed by running `pip install openbb-cli`

or by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).

## 2. Contributing

There are three main ways of contributing to this project. (Hopefully you have starred the project by now ‚≠êÔ∏è)

### Become a Contributor

- More information on our [Developer Documentation](https://docs.openbb.co/python/developer).

### Create a GitHub ticket

Before creating a ticket make sure the one you are creating doesn&#039;t exist already [among the existing issues](https://github.com/OpenBB-finance/OpenBB/issues)

- [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=%5BBug%5D)
- [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=enhancement&amp;template=enhancement.md&amp;title=%5BIMPROVE%5D)
- [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=new+feature&amp;template=feature_request.md&amp;title=%5BFR%5D)

### Provide feedback

We are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.

## 3. License

Distributed under the AGPLv3 License. See
[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.

## 4. Disclaimer

Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment
amount, and may not be suitable for all investors.

Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.

The data contained in the Open Data Platform is not necessarily accurate.

OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.

All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.

Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.

## 5. Contacts

If you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`

If you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`

Any of our social media platforms: [openbb.co/links](https://openbb.co/links)

## 6. Star History

This is a proxy of our growth and that we are just getting started.

But for more metrics important to us check [openbb.co/open](https://openbb.co/open).

[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)

## 7. Contributors

OpenBB wouldn&#039;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.

&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt;
   &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot;/&gt;
&lt;/a&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge
[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge
[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members
[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge
[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers
[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&amp;color=blue
[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues
[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=yellow
[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen
[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=success
[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed
[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge
[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;logo=linkedin&amp;colorB=555
[linkedin-url]: https://linkedin.com/in/DidierRLopes
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[muratcankoylan/Agent-Skills-for-Context-Engineering]]></title>
            <link>https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering</link>
            <guid>https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:20 GMT</pubDate>
            <description><![CDATA[A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems. Use when building, optimizing, or debugging agent systems that require effective context management.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering">muratcankoylan/Agent-Skills-for-Context-Engineering</a></h1>
            <p>A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems. Use when building, optimizing, or debugging agent systems that require effective context management.</p>
            <p>Language: Python</p>
            <p>Stars: 8,903</p>
            <p>Forks: 708</p>
            <p>Stars today: 178 stars today</p>
            <h2>README</h2><pre># Agent Skills for Context Engineering

A comprehensive, open collection of Agent Skills focused on context engineering principles for building production-grade AI agent systems. These skills teach the art and science of curating context to maximize agent effectiveness across any agent platform.

## What is Context Engineering?

Context engineering is the discipline of managing the language model&#039;s context window. Unlike prompt engineering, which focuses on crafting effective instructions, context engineering addresses the holistic curation of all information that enters the model&#039;s limited attention budget: system prompts, tool definitions, retrieved documents, message history, and tool outputs.

The fundamental challenge is that context windows are constrained not by raw token capacity but by attention mechanics. As context length increases, models exhibit predictable degradation patterns: the &quot;lost-in-the-middle&quot; phenomenon, U-shaped attention curves, and attention scarcity. Effective context engineering means finding the smallest possible set of high-signal tokens that maximize the likelihood of desired outcomes.

## Recognition

This repository is cited in academic research as foundational work on static skill architecture:

&gt; &quot;While static skills are well-recognized [Anthropic, 2025b; Muratcan Koylan, 2025], MCE is among the first to dynamically evolve them, bridging manual skill engineering and autonomous self-improvement.&quot;

‚Äî [Meta Context Engineering via Agentic Skill Evolution](https://arxiv.org/pdf/2601.21557), Peking University State Key Laboratory of General Artificial Intelligence (2026)

## Skills Overview

### Foundational Skills

These skills establish the foundational understanding required for all subsequent context engineering work.

| Skill | Description |
|-------|-------------|
| [context-fundamentals](skills/context-fundamentals/) | Understand what context is, why it matters, and the anatomy of context in agent systems |
| [context-degradation](skills/context-degradation/) | Recognize patterns of context failure: lost-in-middle, poisoning, distraction, and clash |
| [context-compression](skills/context-compression/) | Design and evaluate compression strategies for long-running sessions |

### Architectural Skills

These skills cover the patterns and structures for building effective agent systems.

| Skill | Description |
|-------|-------------|
| [multi-agent-patterns](skills/multi-agent-patterns/) | Master orchestrator, peer-to-peer, and hierarchical multi-agent architectures |
| [memory-systems](skills/memory-systems/) | Design short-term, long-term, and graph-based memory architectures |
| [tool-design](skills/tool-design/) | Build tools that agents can use effectively |
| [filesystem-context](skills/filesystem-context/) | Use filesystems for dynamic context discovery, tool output offloading, and plan persistence |
| [hosted-agents](skills/hosted-agents/) | **NEW** Build background coding agents with sandboxed VMs, pre-built images, multiplayer support, and multi-client interfaces |

### Operational Skills

These skills address the ongoing operation and optimization of agent systems.

| Skill | Description |
|-------|-------------|
| [context-optimization](skills/context-optimization/) | Apply compaction, masking, and caching strategies |
| [evaluation](skills/evaluation/) | Build evaluation frameworks for agent systems |
| [advanced-evaluation](skills/advanced-evaluation/) | Master LLM-as-a-Judge techniques: direct scoring, pairwise comparison, rubric generation, and bias mitigation |

### Development Methodology

These skills cover the meta-level practices for building LLM-powered projects.

| Skill | Description |
|-------|-------------|
| [project-development](skills/project-development/) | Design and build LLM projects from ideation through deployment, including task-model fit analysis, pipeline architecture, and structured output design |

### Cognitive Architecture Skills

These skills cover formal cognitive modeling for rational agent systems.

| Skill | Description |
|-------|-------------|
| [bdi-mental-states](skills/bdi-mental-states/) | **NEW** Transform external RDF context into agent mental states (beliefs, desires, intentions) using formal BDI ontology patterns for deliberative reasoning and explainability |

## Design Philosophy

### Progressive Disclosure

Each skill is structured for efficient context use. At startup, agents load only skill names and descriptions. Full content loads only when a skill is activated for relevant tasks.

### Platform Agnosticism

These skills focus on transferable principles rather than vendor-specific implementations. The patterns work across Claude Code, Cursor, and any agent platform that supports skills or allows custom instructions.

### Conceptual Foundation with Practical Examples

Scripts and examples demonstrate concepts using Python pseudocode that works across environments without requiring specific dependency installations.

## Usage

### Usage with Claude Code

This repository is a **Claude Code Plugin Marketplace** containing context engineering skills that Claude automatically discovers and activates based on your task context.

### Installation

**Step 1: Add the Marketplace**

Run this command in Claude Code to register this repository as a plugin source:

```
/plugin marketplace add muratcankoylan/Agent-Skills-for-Context-Engineering
```

**Step 2: Browse and Install**

Option A - Browse available plugins:
1. Select `Browse and install plugins`
2. Select `context-engineering-marketplace`
3. Choose a plugin (e.g., `context-engineering-fundamentals`, `agent-architecture`)
4. Select `Install now`

Option B - Direct install via command:

```
/plugin install context-engineering-fundamentals@context-engineering-marketplace
/plugin install agent-architecture@context-engineering-marketplace
/plugin install agent-evaluation@context-engineering-marketplace
/plugin install agent-development@context-engineering-marketplace
/plugin install cognitive-architecture@context-engineering-marketplace
```

### Available Plugins

| Plugin | Skills Included |
|--------|-----------------|
| `context-engineering-fundamentals` | context-fundamentals, context-degradation, context-compression, context-optimization |
| `agent-architecture` | multi-agent-patterns, memory-systems, tool-design, filesystem-context, hosted-agents |
| `agent-evaluation` | evaluation, advanced-evaluation |
| `agent-development` | project-development |
| `cognitive-architecture` | bdi-mental-states |

### Skill Triggers

| Skill | Triggers On |
|-------|-------------|
| `context-fundamentals` | &quot;understand context&quot;, &quot;explain context windows&quot;, &quot;design agent architecture&quot; |
| `context-degradation` | &quot;diagnose context problems&quot;, &quot;fix lost-in-middle&quot;, &quot;debug agent failures&quot; |
| `context-compression` | &quot;compress context&quot;, &quot;summarize conversation&quot;, &quot;reduce token usage&quot; |
| `context-optimization` | &quot;optimize context&quot;, &quot;reduce token costs&quot;, &quot;implement KV-cache&quot; |
| `multi-agent-patterns` | &quot;design multi-agent system&quot;, &quot;implement supervisor pattern&quot; |
| `memory-systems` | &quot;implement agent memory&quot;, &quot;build knowledge graph&quot;, &quot;track entities&quot; |
| `tool-design` | &quot;design agent tools&quot;, &quot;reduce tool complexity&quot;, &quot;implement MCP tools&quot; |
| `filesystem-context` | &quot;offload context to files&quot;, &quot;dynamic context discovery&quot;, &quot;agent scratch pad&quot;, &quot;file-based context&quot; |
| `hosted-agents` | &quot;build background agent&quot;, &quot;create hosted coding agent&quot;, &quot;sandboxed execution&quot;, &quot;multiplayer agent&quot;, &quot;Modal sandboxes&quot; |
| `evaluation` | &quot;evaluate agent performance&quot;, &quot;build test framework&quot;, &quot;measure quality&quot; |
| `advanced-evaluation` | &quot;implement LLM-as-judge&quot;, &quot;compare model outputs&quot;, &quot;mitigate bias&quot; |
| `project-development` | &quot;start LLM project&quot;, &quot;design batch pipeline&quot;, &quot;evaluate task-model fit&quot; |
| `bdi-mental-states` | &quot;model agent mental states&quot;, &quot;implement BDI architecture&quot;, &quot;transform RDF to beliefs&quot;, &quot;build cognitive agent&quot; |

&lt;img width=&quot;1014&quot; height=&quot;894&quot; alt=&quot;Screenshot 2025-12-26 at 12 34 47‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/f79aaf03-fd2d-4c71-a630-7027adeb9bfe&quot; /&gt;

### For Cursor &amp; Codex &amp; IDE

Copy skill content into `.rules` or create project-specific Skills folders. The skills provide the context and guidelines that agent needs for effective context engineering and agent design.

### For Custom Implementations

Extract the principles and patterns from any skill and implement them in your agent framework. The skills are deliberately platform-agnostic.

## Examples

The [examples](examples/) folder contains complete system designs that demonstrate how multiple skills work together in practice.

| Example | Description | Skills Applied |
|---------|-------------|----------------|
| [digital-brain-skill](examples/digital-brain-skill/) | **NEW** Personal operating system for founders and creators. Complete Claude Code skill with 6 modules, 4 automation scripts | context-fundamentals, context-optimization, memory-systems, tool-design, multi-agent-patterns, evaluation, project-development |
| [x-to-book-system](examples/x-to-book-system/) | Multi-agent system that monitors X accounts and generates daily synthesized books | multi-agent-patterns, memory-systems, context-optimization, tool-design, evaluation |
| [llm-as-judge-skills](examples/llm-as-judge-skills/) | Production-ready LLM evaluation tools with TypeScript implementation, 19 passing tests | advanced-evaluation, tool-design, context-fundamentals, evaluation |
| [book-sft-pipeline](examples/book-sft-pipeline/) | Train models to write in any author&#039;s style. Includes Gertrude Stein case study with 70% human score on Pangram, $2 total cost | project-development, context-compression, multi-agent-patterns, evaluation |

Each example includes:
- Complete PRD with architecture decisions
- Skills mapping showing which concepts informed each decision
- Implementation guidance

### Digital Brain Skill Example

The [digital-brain-skill](examples/digital-brain-skill/) example is a complete personal operating system demonstrating comprehensive skills application:

- **Progressive Disclosure**: 3-level loading (SKILL.md ‚Üí MODULE.md ‚Üí data files)
- **Module Isolation**: 6 independent modules (identity, content, knowledge, network, operations, agents)
- **Append-Only Memory**: JSONL files with schema-first lines for agent-friendly parsing
- **Automation Scripts**: 4 consolidated tools (weekly_review, content_ideas, stale_contacts, idea_to_draft)

Includes detailed traceability in [HOW-SKILLS-BUILT-THIS.md](examples/digital-brain-skill/HOW-SKILLS-BUILT-THIS.md) mapping every architectural decision to specific skill principles.

### LLM-as-Judge Skills Example

The [llm-as-judge-skills](examples/llm-as-judge-skills/) example is a complete TypeScript implementation demonstrating:

- **Direct Scoring**: Evaluate responses against weighted criteria with rubric support
- **Pairwise Comparison**: Compare responses with position bias mitigation
- **Rubric Generation**: Create domain-specific evaluation standards
- **EvaluatorAgent**: High-level agent combining all evaluation capabilities

### Book SFT Pipeline Example

The [book-sft-pipeline](examples/book-sft-pipeline/) example demonstrates training small models (8B) to write in any author&#039;s style:

- **Intelligent Segmentation**: Two-tier chunking with overlap for maximum training examples
- **Prompt Diversity**: 15+ templates to prevent memorization and force style learning
- **Tinker Integration**: Complete LoRA training workflow with $2 total cost
- **Validation Methodology**: Modern scenario testing proves style transfer vs content memorization

Integrates with context engineering skills: project-development, context-compression, multi-agent-patterns, evaluation.

## Star History
&lt;img width=&quot;3664&quot; height=&quot;2648&quot; alt=&quot;star-history-2026113&quot; src=&quot;https://github.com/user-attachments/assets/c60fd73f-4a6c-4679-b7c6-bb8ebf2f3a48&quot; /&gt;

## Structure

Each skill follows the Agent Skills specification:

```
skill-name/
‚îú‚îÄ‚îÄ SKILL.md              # Required: instructions + metadata
‚îú‚îÄ‚îÄ scripts/              # Optional: executable code demonstrating concepts
‚îî‚îÄ‚îÄ references/           # Optional: additional documentation and resources
```

See the [template](template/) folder for the canonical skill structure.

## Contributing

This repository follows the Agent Skills open development model. Contributions are welcome from the broader ecosystem. When contributing:

1. Follow the skill template structure
2. Provide clear, actionable instructions
3. Include working examples where appropriate
4. Document trade-offs and potential issues
5. Keep SKILL.md under 500 lines for optimal performance

Feel free to contact [Muratcan Koylan](https://x.com/koylanai) for collaboration opportunities or any inquiries.

## License

MIT License - see LICENSE file for details.

## References

The principles in these skills are derived from research and production experience at leading AI labs and framework developers. Each skill includes references to the underlying research and case studies that inform its recommendations.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[VectifyAI/PageIndex]]></title>
            <link>https://github.com/VectifyAI/PageIndex</link>
            <guid>https://github.com/VectifyAI/PageIndex</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:19 GMT</pubDate>
            <description><![CDATA[üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/VectifyAI/PageIndex">VectifyAI/PageIndex</a></h1>
            <p>üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG</p>
            <p>Language: Python</p>
            <p>Stars: 16,745</p>
            <p>Forks: 1,196</p>
            <p>Stars today: 624 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  
&lt;a href=&quot;https://vectify.ai/pageindex&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/46201e72-675b-43bc-bfbd-081cc6b65a1d&quot; alt=&quot;PageIndex Banner&quot; /&gt;
&lt;/a&gt;

&lt;br/&gt;
&lt;br/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/14736&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14736&quot; alt=&quot;VectifyAI%2FPageIndex | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

# PageIndex: Vectorless, Reasoning-based RAG

&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Reasoning-based RAG&amp;nbsp; ‚ó¶ &amp;nbsp;No Vector DB&amp;nbsp; ‚ó¶ &amp;nbsp;No Chunking&amp;nbsp; ‚ó¶ &amp;nbsp;Human-like Retrieval&lt;/b&gt;&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vectify.ai&quot;&gt;üè† Homepage&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://chat.pageindex.ai&quot;&gt;üñ•Ô∏è Chat Platform&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://pageindex.ai/mcp&quot;&gt;üîå MCP&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://docs.pageindex.ai&quot;&gt;üìö Docs&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://discord.com/invite/VuXuf29EUj&quot;&gt;üí¨ Discord&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://ii2abc2jejf.typeform.com/to/tK3AXl8T&quot;&gt;‚úâÔ∏è Contact&lt;/a&gt;&amp;nbsp;
&lt;/h4&gt;
  
&lt;/div&gt;


&lt;details open&gt;
&lt;summary&gt;&lt;h3&gt;üì¢ Latest Updates&lt;/h3&gt;&lt;/summary&gt;

 **üî• Releases:**
- [**PageIndex Chat**](https://chat.pageindex.ai): The first human-like document-analysis agent [platform](https://chat.pageindex.ai) built for professional long documents. Can also be integrated via [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart) (beta).
&lt;!-- - [**PageIndex Chat API**](https://docs.pageindex.ai/quickstart): An API that brings PageIndex&#039;s advanced long-document intelligence directly into your applications and workflows. --&gt;
&lt;!-- - [PageIndex MCP](https://pageindex.ai/mcp): Bring PageIndex into Claude, Cursor, or any MCP-enabled agent. Chat with long PDFs in a reasoning-based, human-like way. --&gt;
 
 **üìù Articles:**
- [**PageIndex Framework**](https://pageindex.ai/blog/pageindex-intro): Introduces the PageIndex framework ‚Äî an *agentic, in-context* *tree index* that enables LLMs to perform *reasoning-based*, *human-like retrieval* over long documents, without vector DB or chunking.
&lt;!-- - [Do We Still Need OCR?](https://pageindex.ai/blog/do-we-need-ocr): Explores how vision-based, reasoning-native RAG challenges the traditional OCR pipeline, and why the future of document AI might be *vectorless* and *vision-based*. --&gt;

 **üß™ Cookbooks:**
- [Vectorless RAG](https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex): A minimal, hands-on example of reasoning-based RAG using PageIndex. No vectors, no chunking, and human-like retrieval.
- [Vision-based Vectorless RAG](https://docs.pageindex.ai/cookbook/vision-rag-pageindex): OCR-free, vision-only RAG with PageIndex&#039;s reasoning-native retrieval workflow that works directly over PDF page images.
&lt;/details&gt;

---

# üìë Introduction to PageIndex

Are you frustrated with vector database retrieval accuracy for long professional documents? Traditional vector-based RAG relies on semantic *similarity* rather than true *relevance*. But **similarity ‚â† relevance** ‚Äî what we truly need in retrieval is **relevance**, and that requires **reasoning**. When working with professional documents that demand domain expertise and multi-step reasoning, similarity search often falls short.

Inspired by AlphaGo, we propose **[PageIndex](https://vectify.ai/pageindex)** ‚Äî a **vectorless**, **reasoning-based RAG** system that builds a **hierarchical tree index** from long documents and uses LLMs to **reason** *over that index* for **agentic, context-aware retrieval**.
It simulates how *human experts* navigate and extract knowledge from complex documents through *tree search*, enabling LLMs to *think* and *reason* their way to the most relevant document sections. PageIndex performs retrieval in two steps:

1. Generate a ‚ÄúTable-of-Contents‚Äù **tree structure index** of documents
2. Perform reasoning-based retrieval through **tree search**

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pageindex.ai/blog/pageindex-intro&quot; target=&quot;_blank&quot; title=&quot;The PageIndex Framework&quot;&gt;
    &lt;img src=&quot;https://docs.pageindex.ai/images/cookbook/vectorless-rag.png&quot; width=&quot;70%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

### üéØ Core Features 

Compared to traditional vector-based RAG, **PageIndex** features:
- **No Vector DB**: Uses document structure and LLM reasoning for retrieval, instead of vector similarity search.
- **No Chunking**: Documents are organized into natural sections, not artificial chunks.
- **Human-like Retrieval**: Simulates how human experts navigate and extract knowledge from complex documents.
- **Better Explainability and Traceability**: Retrieval is based on reasoning ‚Äî traceable and interpretable, with page and section references. No more opaque, approximate vector search (‚Äúvibe retrieval‚Äù).

PageIndex powers a reasoning-based RAG system that achieved **state-of-the-art** [98.7% accuracy](https://github.com/VectifyAI/Mafin2.5-FinanceBench) on FinanceBench, demonstrating superior performance over vector-based RAG solutions in professional document analysis (see our [blog post](https://vectify.ai/blog/Mafin2.5) for details).

### üìç Explore PageIndex

To learn more, please see a detailed introduction of the [PageIndex framework](https://pageindex.ai/blog/pageindex-intro). Check out this GitHub repo for open-source code, and the [cookbooks](https://docs.pageindex.ai/cookbook), [tutorials](https://docs.pageindex.ai/tutorials), and [blog](https://pageindex.ai/blog) for additional usage guides and examples. 

The PageIndex service is available as a ChatGPT-style [chat platform](https://chat.pageindex.ai), or can be integrated via [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart).

### üõ†Ô∏è Deployment Options
- Self-host ‚Äî run locally with this open-source repo.
- Cloud Service ‚Äî try instantly with our [Chat Platform](https://chat.pageindex.ai/), or integrate with [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart).
- _Enterprise_ ‚Äî private or on-prem deployment. [Contact us](https://ii2abc2jejf.typeform.com/to/tK3AXl8T) or [book a demo](https://calendly.com/pageindex/meet) for more details.

### üß™ Quick Hands-on

- Try the [**Vectorless RAG**](https://github.com/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb) notebook ‚Äî a *minimal*, hands-on example of reasoning-based RAG using PageIndex.
- Experiment with [*Vision-based Vectorless RAG*](https://github.com/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb) ‚Äî no OCR; a minimal, reasoning-native RAG pipeline that works directly over page images.
  
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Open_In_Colab-Vectorless_RAG-orange?style=for-the-badge&amp;logo=googlecolab&quot; alt=&quot;Open in Colab: Vectorless RAG&quot; /&gt;
  &lt;/a&gt;
  &amp;nbsp;&amp;nbsp;
  &lt;a href=&quot;https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Open_In_Colab-Vision_RAG-orange?style=for-the-badge&amp;logo=googlecolab&quot; alt=&quot;Open in Colab: Vision RAG&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

---

# üå≤ PageIndex Tree Structure
PageIndex can transform lengthy PDF documents into a semantic **tree structure**, similar to a _&quot;table of contents&quot;_ but optimized for use with Large Language Models (LLMs). It&#039;s ideal for: financial reports, regulatory filings, academic textbooks, legal or technical manuals, and any document that exceeds LLM context limits.

Below is an example PageIndex tree structure. Also see more example [documents](https://github.com/VectifyAI/PageIndex/tree/main/tests/pdfs) and generated [tree structures](https://github.com/VectifyAI/PageIndex/tree/main/tests/results).

```jsonc
...
{
  &quot;title&quot;: &quot;Financial Stability&quot;,
  &quot;node_id&quot;: &quot;0006&quot;,
  &quot;start_index&quot;: 21,
  &quot;end_index&quot;: 22,
  &quot;summary&quot;: &quot;The Federal Reserve ...&quot;,
  &quot;nodes&quot;: [
    {
      &quot;title&quot;: &quot;Monitoring Financial Vulnerabilities&quot;,
      &quot;node_id&quot;: &quot;0007&quot;,
      &quot;start_index&quot;: 22,
      &quot;end_index&quot;: 28,
      &quot;summary&quot;: &quot;The Federal Reserve&#039;s monitoring ...&quot;
    },
    {
      &quot;title&quot;: &quot;Domestic and International Cooperation and Coordination&quot;,
      &quot;node_id&quot;: &quot;0008&quot;,
      &quot;start_index&quot;: 28,
      &quot;end_index&quot;: 31,
      &quot;summary&quot;: &quot;In 2023, the Federal Reserve collaborated ...&quot;
    }
  ]
}
...
```

You can generate the PageIndex tree structure with this open-source repo, or use our [API](https://docs.pageindex.ai/quickstart) 

---

# ‚öôÔ∏è Package Usage

You can follow these steps to generate a PageIndex tree from a PDF document.

### 1. Install dependencies

```bash
pip3 install --upgrade -r requirements.txt
```

### 2. Set your OpenAI API key

Create a `.env` file in the root directory and add your API key:

```bash
CHATGPT_API_KEY=your_openai_key_here
```

### 3. Run PageIndex on your PDF

```bash
python3 run_pageindex.py --pdf_path /path/to/your/document.pdf
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Optional parameters&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;
You can customize the processing with additional optional arguments:

```
--model                 OpenAI model to use (default: gpt-4o-2024-11-20)
--toc-check-pages       Pages to check for table of contents (default: 20)
--max-pages-per-node    Max pages per node (default: 10)
--max-tokens-per-node   Max tokens per node (default: 20000)
--if-add-node-id        Add node ID (yes/no, default: yes)
--if-add-node-summary   Add node summary (yes/no, default: yes)
--if-add-doc-description Add doc description (yes/no, default: yes)
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Markdown support&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;
We also provide markdown support for PageIndex. You can use the `-md_path` flag to generate a tree structure for a markdown file.

```bash
python3 run_pageindex.py --md_path /path/to/your/document.md
```

&gt; Note: in this function, we use &quot;#&quot; to determine node heading and their levels. For example, &quot;##&quot; is level 2, &quot;###&quot; is level 3, etc. Make sure your markdown file is formatted correctly. If your Markdown file was converted from a PDF or HTML, we don&#039;t recommend using this function, since most existing conversion tools cannot preserve the original hierarchy. Instead, use our [PageIndex OCR](https://pageindex.ai/blog/ocr), which is designed to preserve the original hierarchy, to convert the PDF to a markdown file and then use this function.
&lt;/details&gt;

&lt;!-- 
# ‚òÅÔ∏è Improved Tree Generation with PageIndex OCR

This repo is designed for generating PageIndex tree structure for simple PDFs, but many real-world use cases involve complex PDFs that are hard to parse by classic Python tools. However, extracting high-quality text from PDF documents remains a non-trivial challenge. Most OCR tools only extract page-level content, losing the broader document context and hierarchy.

To address this, we introduced PageIndex OCR ‚Äî the first long-context OCR model designed to preserve the global structure of documents. PageIndex OCR significantly outperforms other leading OCR tools, such as those from Mistral and Contextual AI, in recognizing true hierarchy and semantic relationships across document pages.

- Experience next-level OCR quality with PageIndex OCR at our [Dashboard](https://dash.pageindex.ai/).
- Integrate PageIndex OCR seamlessly into your stack via our [API](https://docs.pageindex.ai/quickstart).

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/eb35d8ae-865c-4e60-a33b-ebbd00c41732&quot; width=&quot;80%&quot;&gt;
&lt;/p&gt;
--&gt;

---

# üìà Case Study: PageIndex Leads Finance QA Benchmark

[Mafin 2.5](https://vectify.ai/mafin) is a reasoning-based RAG system for financial document analysis, powered by **PageIndex**. It achieved a state-of-the-art [**98.7% accuracy**](https://vectify.ai/blog/Mafin2.5) on the [FinanceBench](https://arxiv.org/abs/2311.11944) benchmark, significantly outperforming traditional vector-based RAG systems.

PageIndex&#039;s hierarchical indexing and reasoning-driven retrieval enable precise navigation and extraction of relevant context from complex financial reports, such as SEC filings and earnings disclosures.

Explore the full [benchmark results](https://github.com/VectifyAI/Mafin2.5-FinanceBench) and our [blog post](https://vectify.ai/blog/Mafin2.5) for detailed comparisons and performance metrics.

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/VectifyAI/Mafin2.5-FinanceBench&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/571aa074-d803-43c7-80c4-a04254b782a3&quot; width=&quot;70%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

---

# üß≠ Resources

* üß™ [Cookbooks](https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex): hands-on, runnable examples and advanced use cases.
* üìñ [Tutorials](https://docs.pageindex.ai/doc-search): practical guides and strategies, including *Document Search* and *Tree Search*.
* üìù [Blog](https://pageindex.ai/blog): technical articles, research insights, and product updates.
* üîå [MCP setup](https://pageindex.ai/mcp#quick-setup) &amp; [API docs](https://docs.pageindex.ai/quickstart): integration details and configuration options.

---

# ‚≠ê Support Us
Please cite this work as:
```
Mingtian Zhang, Yu Tang and PageIndex Team,
&quot;PageIndex: Next-Generation Vectorless, Reasoning-based RAG&quot;,
PageIndex Blog, Sep 2025.
```

Or use the BibTeX citation:

```
@article{zhang2025pageindex,
  author = {Mingtian Zhang and Yu Tang and PageIndex Team},
  title = {PageIndex: Next-Generation Vectorless, Reasoning-based RAG},
  journal = {PageIndex Blog},
  year = {2025},
  month = {September},
  note = {https://pageindex.ai/blog/pageindex-intro},
}
```

Leave us a star üåü if you like our project. Thank you!  

&lt;p&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/eae4ff38-48ae-4a7c-b19f-eab81201d794&quot; width=&quot;80%&quot;&gt;
&lt;/p&gt;

### Connect with Us

[![Twitter](https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white)](https://x.com/PageIndexAI)&amp;nbsp;
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/vectify-ai/)&amp;nbsp;
[![Discord](https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.com/invite/VuXuf29EUj)&amp;nbsp;
[![Contact Us](https://img.shields.io/badge/Contact_Us-3B82F6?style=for-the-badge&amp;logo=envelope&amp;logoColor=white)](https://ii2abc2jejf.typeform.com/to/tK3AXl8T)

---

¬© 2025 [Vectify AI](https://vectify.ai)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[NevaMind-AI/memU]]></title>
            <link>https://github.com/NevaMind-AI/memU</link>
            <guid>https://github.com/NevaMind-AI/memU</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:18 GMT</pubDate>
            <description><![CDATA[Memory for 24/7 proactive agents like openclaw (moltbot, clawdbot).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NevaMind-AI/memU">NevaMind-AI/memU</a></h1>
            <p>Memory for 24/7 proactive agents like openclaw (moltbot, clawdbot).</p>
            <p>Language: Python</p>
            <p>Stars: 10,086</p>
            <p>Forks: 760</p>
            <p>Stars today: 163 stars today</p>
            <h2>README</h2><pre>![MemU Banner](assets/banner.png)

&lt;div align=&quot;center&quot;&gt;

# memU

### 24/7 Always-On Proactive Memory for AI Agents

[![PyPI version](https://badge.fury.io/py/memu-py.svg)](https://badge.fury.io/py/memu-py)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![Discord](https://img.shields.io/badge/Discord-Join%20Chat-5865F2?logo=discord&amp;logoColor=white)](https://discord.gg/memu)
[![Twitter](https://img.shields.io/badge/Twitter-Follow-1DA1F2?logo=x&amp;logoColor=white)](https://x.com/memU_ai)

&lt;a href=&quot;https://trendshift.io/repositories/17374&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/17374&quot; alt=&quot;NevaMind-AI%2FmemU | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

**[English](readme/README_en.md) | [‰∏≠Êñá](readme/README_zh.md) | [Êó•Êú¨Ë™û](readme/README_ja.md) | [ÌïúÍµ≠Ïñ¥](readme/README_ko.md) | [Espa√±ol](readme/README_es.md) | [Fran√ßais](readme/README_fr.md)**

&lt;/div&gt;

---

memU is a memory framework built for **24/7 proactive agents**.
It is designed for long-running use and greatly **reduces the LLM token cost** of keeping agents always online, making always-on, evolving agents practical in production systems.
memU **continuously captures and understands user intent**. Even without a command, the agent can tell what you are about to do and act on it by itself.

---

## ü§ñ [OpenClaw (Moltbot, Clawdbot) Alternative](https://memu.bot)

&lt;img width=&quot;100%&quot; src=&quot;https://github.com/NevaMind-AI/memU/blob/main/assets/memUbot.png&quot; /&gt;

- **Download-and-use and simple** to get started.
- Builds long-term memory to **understand user intent** and act proactively.
- **Cuts LLM token cost** with smaller context.

Try now: [memU bot](https://memu.bot)

---

## üóÉÔ∏è Memory as File System, File System as Memory

memU treats **memory like a file system**‚Äîstructured, hierarchical, and instantly accessible.

| File System | memU Memory |
|-------------|-------------|
| üìÅ Folders | üè∑Ô∏è Categories (auto-organized topics) |
| üìÑ Files | üß† Memory Items (extracted facts, preferences, skills) |
| üîó Symlinks | üîÑ Cross-references (related memories linked) |
| üìÇ Mount points | üì• Resources (conversations, documents, images) |

**Why this matters:**
- **Navigate memories** like browsing directories‚Äîdrill down from broad categories to specific facts
- **Mount new knowledge** instantly‚Äîconversations and documents become queryable memory
- **Cross-link everything**‚Äîmemories reference each other, building a connected knowledge graph
- **Persistent &amp; portable**‚Äîexport, backup, and transfer memory like files

```
memory/
‚îú‚îÄ‚îÄ preferences/
‚îÇ   ‚îú‚îÄ‚îÄ communication_style.md
‚îÇ   ‚îî‚îÄ‚îÄ topic_interests.md
‚îú‚îÄ‚îÄ relationships/
‚îÇ   ‚îú‚îÄ‚îÄ contacts/
‚îÇ   ‚îî‚îÄ‚îÄ interaction_history/
‚îú‚îÄ‚îÄ knowledge/
‚îÇ   ‚îú‚îÄ‚îÄ domain_expertise/
‚îÇ   ‚îî‚îÄ‚îÄ learned_skills/
‚îî‚îÄ‚îÄ context/
    ‚îú‚îÄ‚îÄ recent_conversations/
    ‚îî‚îÄ‚îÄ pending_tasks/
```

Just as a file system turns raw bytes into organized data, memU transforms raw interactions into **structured, searchable, proactive intelligence**.

---

## ‚≠êÔ∏è Star the repository

&lt;img width=&quot;100%&quot; src=&quot;https://github.com/NevaMind-AI/memU/blob/main/assets/star.gif&quot; /&gt;
If you find memU useful or interesting, a GitHub Star ‚≠êÔ∏è would be greatly appreciated.

---


## ‚ú® Core Features

| Capability | Description |
|------------|-------------|
| ü§ñ **24/7 Proactive Agent** | Always-on memory agent that works continuously in the background‚Äînever sleeps, never forgets |
| üéØ **User Intention Capture** | Understands and remembers user goals, preferences, and context across sessions automatically |
| üí∞ **Cost Efficient** | Reduces long-running token costs by caching insights and avoiding redundant LLM calls |
---

## üîÑ How Proactive Memory Works

```bash

cd examples/proactive
python proactive.py

```

---

### Proactive Memory Lifecycle
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                         USER QUERY                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ                                                           ‚îÇ
                 ‚ñº                                                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ü§ñ MAIN AGENT                  ‚îÇ         ‚îÇ              üß† MEMU BOT                       ‚îÇ
‚îÇ                                        ‚îÇ         ‚îÇ                                                ‚îÇ
‚îÇ  Handle user queries &amp; execute tasks   ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  Monitor, memorize &amp; proactive intelligence   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                        ‚îÇ         ‚îÇ                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  1. RECEIVE USER INPUT           ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  1. MONITOR INPUT/OUTPUT                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Parse query, understand      ‚îÇ  ‚îÇ   ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  ‚îÇ     Observe agent interactions           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     context and intent           ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ     Track conversation flow              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  2. PLAN &amp; EXECUTE               ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  2. MEMORIZE &amp; EXTRACT                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Break down tasks             ‚îÇ  ‚îÇ   ‚óÑ‚îÄ‚îÄ‚îÄ  ‚îÇ  ‚îÇ     Store insights, facts, preferences   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Call tools, retrieve data    ‚îÇ  ‚îÇ  inject ‚îÇ  ‚îÇ     Extract skills &amp; knowledge           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Generate responses           ‚îÇ  ‚îÇ  memory ‚îÇ  ‚îÇ     Update user profile                  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  3. RESPOND TO USER              ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  3. PREDICT USER INTENT                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Deliver answer/result        ‚îÇ  ‚îÇ   ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  ‚îÇ     Anticipate next steps                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Continue conversation        ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ     Identify upcoming needs              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  4. LOOP                         ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  4. RUN PROACTIVE TASKS                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Wait for next user input     ‚îÇ  ‚îÇ   ‚óÑ‚îÄ‚îÄ‚îÄ  ‚îÇ  ‚îÇ     Pre-fetch relevant context           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     or proactive suggestions     ‚îÇ  ‚îÇ  suggest‚îÇ  ‚îÇ     Prepare recommendations              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îÇ     Update todolist autonomously         ‚îÇ  ‚îÇ
‚îÇ                                        ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ                                                           ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚ñº
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ     CONTINUOUS SYNC LOOP     ‚îÇ
                              ‚îÇ  Agent ‚óÑ‚îÄ‚îÄ‚ñ∫ MemU Bot ‚óÑ‚îÄ‚îÄ‚ñ∫ DB ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Proactive Use Cases

### 1. **Information Recommendation**
*Agent monitors interests and proactively surfaces relevant content*
```python
# User has been researching AI topics
MemU tracks: reading history, saved articles, search queries

# When new content arrives:
Agent: &quot;I found 3 new papers on RAG optimization that align with
        your recent research on retrieval systems. One author
        (Dr. Chen) you&#039;ve cited before published yesterday.&quot;

# Proactive behaviors:
- Learns topic preferences from browsing patterns
- Tracks author/source credibility preferences
- Filters noise based on engagement history
- Times recommendations for optimal attention
```

### 2. **Email Management**
*Agent learns communication patterns and handles routine correspondence*
```python
# MemU observes email patterns over time:
- Response templates for common scenarios
- Priority contacts and urgent keywords
- Scheduling preferences and availability
- Writing style and tone variations

# Proactive email assistance:
Agent: &quot;You have 12 new emails. I&#039;ve drafted responses for 3 routine
        requests and flagged 2 urgent items from your priority contacts.
        Should I also reschedule tomorrow&#039;s meeting based on the
        conflict John mentioned?&quot;

# Autonomous actions:
‚úì Draft context-aware replies
‚úì Categorize and prioritize inbox
‚úì Detect scheduling conflicts
‚úì Summarize long threads with key decisions
```

### 3. **Trading &amp; Financial Monitoring**
*Agent tracks market context and user investment behavior*
```python
# MemU learns trading preferences:
- Risk tolerance from historical decisions
- Preferred sectors and asset classes
- Response patterns to market events
- Portfolio rebalancing triggers

# Proactive alerts:
Agent: &quot;NVDA dropped 5% in after-hours trading. Based on your past
        behavior, you typically buy tech dips above 3%. Your current
        allocation allows for $2,000 additional exposure while
        maintaining your 70/30 equity-bond target.&quot;

# Continuous monitoring:
- Track price alerts tied to user-defined thresholds
- Correlate news events with portfolio impact
- Learn from executed vs. ignored recommendations
- Anticipate tax-loss harvesting opportunities
```


...

---

## üóÇÔ∏è Hierarchical Memory Architecture

MemU&#039;s three-layer system enables both **reactive queries** and **proactive context loading**:

&lt;img width=&quot;100%&quot; alt=&quot;structure&quot; src=&quot;assets/structure.png&quot; /&gt;

| Layer | Reactive Use | Proactive Use |
|-------|--------------|---------------|
| **Resource** | Direct access to original data | Background monitoring for new patterns |
| **Item** | Targeted fact retrieval | Real-time extraction from ongoing interactions |
| **Category** | Summary-level overview | Automatic context assembly for anticipation |

**Proactive Benefits:**
- **Auto-categorization**: New memories self-organize into topics
- **Pattern Detection**: System identifies recurring themes
- **Context Prediction**: Anticipates what information will be needed next

---

## üöÄ Quick Start

### Option 1: Cloud Version

Experience proactive memory instantly:

üëâ **[memu.so](https://memu.so)** - Hosted service with 7√ó24 continuous learning

For enterprise deployment with custom proactive workflows, contact **info@nevamind.ai**

#### Cloud API (v3)

| Base URL | `https://api.memu.so` |
|----------|----------------------|
| Auth | `Authorization: Bearer YOUR_API_KEY` |

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v3/memory/memorize` | Register continuous learning task |
| `GET` | `/api/v3/memory/memorize/status/{task_id}` | Check real-time processing status |
| `POST` | `/api/v3/memory/categories` | List auto-generated categories |
| `POST` | `/api/v3/memory/retrieve` | Query memory (supports proactive context loading) |

üìö **[Full API Documentation](https://memu.pro/docs#cloud-version)**

---

### Option 2: Self-Hosted

#### Installation
```bash
pip install -e .
```

#### Basic Example

&gt; **Requirements**: Python 3.13+ and an OpenAI API key

**Test Continuous Learning** (in-memory):
```bash
export OPENAI_API_KEY=your_api_key
cd tests
python test_inmemory.py
```

**Test with Persistent Storage** (PostgreSQL):
```bash
# Start PostgreSQL with pgvector
docker run -d \
  --name memu-postgres \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=memu \
  -p 5432:5432 \
  pgvector/pgvector:pg16

# Run continuous learning test
export OPENAI_API_KEY=your_api_key
cd tests
python test_postgres.py
```

Both examples demonstrate **proactive memory workflows**:
1. **Continuous Ingestion**: Process multiple files sequentially
2. **Auto-Extraction**: Immediate memory creation
3. **Proactive Retrieval**: Context-aware memory surfacing

See [`tests/test_inmemory.py`](tests/test_inmemory.py) and [`tests/test_postgres.py`](tests/test_postgres.py) for implementation details.

---

### Custom LLM and Embedding Providers

MemU supports custom LLM and embedding providers beyond OpenAI. Configure them via `llm_profiles`:
```python
from memu import MemUService

service = MemUService(
    llm_profiles={
        # Default profile for LLM operations
        &quot;default&quot;: {
            &quot;base_url&quot;: &quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,
            &quot;api_key&quot;: &quot;your_api_key&quot;,
            &quot;chat_model&quot;: &quot;qwen3-max&quot;,
            &quot;client_backend&quot;: &quot;sdk&quot;  # &quot;sdk&quot; or &quot;http&quot;
        },
        # Separate profile for embeddings
        &quot;embedding&quot;: {
            &quot;base_url&quot;: &quot;https://api.voyageai.com/v1&quot;,
            &quot;api_key&quot;: &quot;your_voyage_api_key&quot;,
            &quot;embed_model&quot;: &quot;voyage-3.5-lite&quot;
        }
    },
    # ... other configuration
)
```

---

### OpenRouter Integration

MemU supports [OpenRouter](https://openrouter.ai) as a model provider, giving you access to multiple LLM providers through a single API.

#### Configuration
```python
from memu import MemoryService

service = MemoryService(
    llm_profiles={
        &quot;default&quot;: {
            &quot;provider&quot;: &quot;openrouter&quot;,
            &quot;client_backend&quot;: &quot;httpx&quot;,
            &quot;base_url&quot;: &quot;https://openrouter.ai&quot;,
            &quot;api_key&quot;: &quot;your_openrouter_api_key&quot;,
            &quot;chat_model&quot;: &quot;anthropic/claude-3.5-sonnet&quot;,  # Any OpenRouter model
            &quot;embed_model&quot;: &quot;openai/text-embedding-3-small&quot;,  # Embedding model
        },
    },
    database_config={
        &quot;metadata_store&quot;: {&quot;provider&quot;: &quot;inmemory&quot;},
    },
)
```

#### Environment Variables

| Variable | Description |
|----------|-------------|
| `OPENROUTER_API_KEY` | Your OpenRouter API key from [openrouter.ai/keys](https://openrouter.ai/keys) |

#### Supported Features

| Feature | Status | Notes |
|---------|--------|-------|
| Chat Completions | Supported | Works with any OpenRouter chat model |
| Embeddings | Supported | Use OpenAI embedding models via OpenRouter |
| Vision | Supported | Use vision-capable models (e.g., `openai/gpt-4o`) |

#### Running OpenRouter Tests
```bash
export OPENROUTER_API_KEY=your_api_key

# Full workflow test (memorize + retrieve)
python tests/test_openrouter.py

# Embedding-specific tests
python tests/test_openrouter_embedding.py

# Vision-specific tests
python tests/test_openrouter_vision.py
```

See [`examples/example_4_openrouter_memory.py`](examples/example_4_openrouter_memory.py) for a complete working example.

---

## üìñ Core APIs

### `memorize()` - Continuous Learning Pipeline

Processes inputs in real-time and immediately updates memory:

&lt;img width=&quot;100%&quot; alt=&quot;memorize&quot; src=&quot;assets/memorize.png&quot; /&gt;

```python
result = await service.memorize(
    resource_url=&quot;path/to/file.json&quot;,  # File path or URL
    modality=&quot;conversation&quot;,            # conversation | document | image | video | audio
    user={&quot;user_id&quot;: &quot;123&quot;}             # Optional: scope to a user
)

# Returns immediately with extracted memory:
{
    &quot;resource&quot;: {...},      # Stored resource metadata
    &quot;items&quot;: [...],         # Extracted memory items (available instantly)
    &quot;categories&quot;: [...]     # Auto-updated category structure
}
```

**Proactive Features:**
- Zero-delay processing‚Äîmemories available immediately
- Automatic categorization without manual tagging
- Cross-reference with existing memories for pattern detection

### `retrieve()` - Dual-Mode Intelligence

MemU supports both **proactive context loading** and **reactive querying**:

&lt;img width=&quot;100%&quot; alt=&quot;retrieve&quot; src=&quot;assets/retrieve.png&quot; /&gt;

#### RAG-based Retrieval (`method=&quot;rag&quot;`)

Fast **proactive context assembly** using embeddings:

- ‚úÖ **Instant context**: Sub-second memory surfacing
- ‚úÖ **Background monitoring**: Can run continuously without LLM costs
- ‚úÖ **Similarity scoring**: Identifies most relevant memories automatically

#### LLM-based Retrieval (`method=&quot;llm&quot;`)

Deep **anticipatory reasoning** for complex contexts:

- ‚úÖ **Intent prediction**: LLM infers what user needs before they ask
- ‚úÖ **Query evolution**: Automatically refines search as context develops
- ‚úÖ **Early termination**: Stops when sufficient context is gathered

#### Comparison

| Aspect | RAG (Fast Context) | LLM (Deep Reasoning) |
|--------|-------------------|---------------------|
| **Speed** | ‚ö° Milliseconds | üê¢ Seconds |
| **Cost** | üí∞ Embedding only | üí∞üí∞ LLM inference |
| **Proactive use** | Continuous monitoring | Triggered context loading |
| **Best for** | Real-time suggestions | Complex anticipation |

#### Usage
```python
# Proactive retrieval with context history
result = await service.retrieve(
    queries=[
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: {&quot;text&quot;: &quot;What are their preferences?&quot;}},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: {&quot;text&quot;: &quot;Tell me about work habits&quot;}}
    ],
    where={&quot;user_id&quot;: &quot;123&quot;},  # Optional: scope filter
    method=&quot;rag&quot;  # or &quot;llm&quot; for deeper reasoning
)

# Returns context-aware results:
{
    &quot;categories&quot;: [...],     # Relevant topic areas (auto-prioritized)
    &quot;items&quot;: [...],          # Specific memory facts
    &quot;resources&quot;: [...],      # Original sources for traceability
    &quot;next_step_query&quot;: &quot;...&quot; # Predicted follow-up context
}
```

**Proactive Filtering**: Use `where` to scope continuous monitoring:
- `where={&quot;user_id&quot;: &quot;123&quot;}` - User-specific context
- `where={&quot;agent_id__in&quot;: [&quot;1&quot;, &quot;2&quot;]}` - Multi-agent coordination
- Omit `where` for global context awareness

---

## üí° Proactive Scenarios

### Example 1: Always-Learning Assistant

Continuously learns from every interaction without explicit memory commands:
```bash
export OPENAI_API_KEY=your_api_key
python examples/example_1_conversation_memory.py
```

**Proactive Behavior:**
- Automatically extracts preferences from casual mentions
- Builds relationship models from interaction patterns
- Surfaces relevant context in future conversations
- Adapts communication style based on learned preferences

**Best for:** Personal AI assistants, customer support that remembers, social chatbots

---

### Example 2: Self-Improving Agent

Learns from execution logs and proactively suggests optimizations:
```bash
export OPENAI_API_KEY=your_api_key
python examples/example_2_skill_extraction.py
```

**Proactive Behavior:**
- Monitors agent actions and outcomes continuously
- Identifies patterns in successes and failures
- Auto-generates skill guides from experience
- Proactively suggests strategies for similar future tasks

**Best for:** DevOps automation, agent self-improvement, knowledge capture

---

### Example 3: Multimodal Context Builder

Unifies memory across different input types for comprehensive context:
```bash
export OPENAI

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sansan0/TrendRadar]]></title>
            <link>https://github.com/sansan0/TrendRadar</link>
            <guid>https://github.com/sansan0/TrendRadar</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:17 GMT</pubDate>
            <description><![CDATA[‚≠êAI-driven public opinion & trend monitor with multi-platform aggregation, RSS, and smart alerts.üéØ ÂëäÂà´‰ø°ÊÅØËøáËΩΩÔºå‰Ω†ÁöÑ AI ËàÜÊÉÖÁõëÊéßÂä©Êâã‰∏éÁÉ≠ÁÇπÁ≠õÈÄâÂ∑•ÂÖ∑ÔºÅËÅöÂêàÂ§öÂπ≥Âè∞ÁÉ≠ÁÇπ + RSS ËÆ¢ÈòÖÔºåÊîØÊåÅÂÖ≥ÈîÆËØçÁ≤æÂáÜÁ≠õÈÄâ„ÄÇAI ÁøªËØë + AI ÂàÜÊûêÁÆÄÊä•Áõ¥Êé®ÊâãÊú∫Ôºå‰πüÊîØÊåÅÊé•ÂÖ• MCP Êû∂ÊûÑÔºåËµãËÉΩ AI Ëá™ÁÑ∂ËØ≠Ë®ÄÂØπËØùÂàÜÊûê„ÄÅÊÉÖÊÑüÊ¥ûÂØü‰∏éË∂ãÂäøÈ¢ÑÊµãÁ≠â„ÄÇÊîØÊåÅ Docker ÔºåÊï∞ÊçÆÊú¨Âú∞/‰∫ëÁ´ØËá™ÊåÅ„ÄÇÈõÜÊàêÂæÆ‰ø°/È£û‰π¶/ÈíâÈíâ/Telegram/ÈÇÆ‰ª∂/ntfy/bark/slack Á≠âÊ∏†ÈÅìÊô∫ËÉΩÊé®ÈÄÅ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sansan0/TrendRadar">sansan0/TrendRadar</a></h1>
            <p>‚≠êAI-driven public opinion & trend monitor with multi-platform aggregation, RSS, and smart alerts.üéØ ÂëäÂà´‰ø°ÊÅØËøáËΩΩÔºå‰Ω†ÁöÑ AI ËàÜÊÉÖÁõëÊéßÂä©Êâã‰∏éÁÉ≠ÁÇπÁ≠õÈÄâÂ∑•ÂÖ∑ÔºÅËÅöÂêàÂ§öÂπ≥Âè∞ÁÉ≠ÁÇπ + RSS ËÆ¢ÈòÖÔºåÊîØÊåÅÂÖ≥ÈîÆËØçÁ≤æÂáÜÁ≠õÈÄâ„ÄÇAI ÁøªËØë + AI ÂàÜÊûêÁÆÄÊä•Áõ¥Êé®ÊâãÊú∫Ôºå‰πüÊîØÊåÅÊé•ÂÖ• MCP Êû∂ÊûÑÔºåËµãËÉΩ AI Ëá™ÁÑ∂ËØ≠Ë®ÄÂØπËØùÂàÜÊûê„ÄÅÊÉÖÊÑüÊ¥ûÂØü‰∏éË∂ãÂäøÈ¢ÑÊµãÁ≠â„ÄÇÊîØÊåÅ Docker ÔºåÊï∞ÊçÆÊú¨Âú∞/‰∫ëÁ´ØËá™ÊåÅ„ÄÇÈõÜÊàêÂæÆ‰ø°/È£û‰π¶/ÈíâÈíâ/Telegram/ÈÇÆ‰ª∂/ntfy/bark/slack Á≠âÊ∏†ÈÅìÊô∫ËÉΩÊé®ÈÄÅ„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 47,004</p>
            <p>Forks: 22,307</p>
            <p>Stars today: 120 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; id=&quot;trendradar&quot;&gt;

&lt;a href=&quot;https://github.com/sansan0/TrendRadar&quot; title=&quot;TrendRadar&quot;&gt;
  &lt;img src=&quot;/_image/banner.webp&quot; alt=&quot;TrendRadar Banner&quot; width=&quot;80%&quot;&gt;
&lt;/a&gt;

ÊúÄÂø´&lt;strong&gt;30Áßí&lt;/strong&gt;ÈÉ®ÁΩ≤ÁöÑÁÉ≠ÁÇπÂä©Êâã ‚Äî‚Äî ÂëäÂà´Êó†ÊïàÂà∑Â±èÔºåÂè™ÁúãÁúüÊ≠£ÂÖ≥ÂøÉÁöÑÊñ∞ÈóªËµÑËÆØ

&lt;a href=&quot;https://trendshift.io/repositories/14726&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14726&quot; alt=&quot;sansan0%2FTrendRadar | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;


[![GitHub Stars](https://img.shields.io/github/stars/sansan0/TrendRadar?style=flat-square&amp;logo=github&amp;color=yellow)](https://github.com/sansan0/TrendRadar/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/sansan0/TrendRadar?style=flat-square&amp;logo=github&amp;color=blue)](https://github.com/sansan0/TrendRadar/network/members)
[![License](https://img.shields.io/badge/license-GPL--3.0-blue.svg?style=flat-square)](LICENSE)
[![Version](https://img.shields.io/badge/version-v6.0.0-blue.svg)](https://github.com/sansan0/TrendRadar)
[![MCP](https://img.shields.io/badge/MCP-v4.0.0-green.svg)](https://github.com/sansan0/TrendRadar)
[![RSS](https://img.shields.io/badge/RSS-ËÆ¢ÈòÖÊ∫êÊîØÊåÅ-orange.svg?style=flat-square&amp;logo=rss&amp;logoColor=white)](https://github.com/sansan0/TrendRadar)
[![AIÁøªËØë](https://img.shields.io/badge/AI-Â§öËØ≠Ë®ÄÊé®ÈÄÅ-purple.svg?style=flat-square)](https://github.com/sansan0/TrendRadar)

[![‰ºÅ‰∏öÂæÆ‰ø°ÈÄöÁü•](https://img.shields.io/badge/‰ºÅ‰∏öÂæÆ‰ø°-ÈÄöÁü•-00D4AA?style=flat-square)](https://work.weixin.qq.com/)
[![‰∏™‰∫∫ÂæÆ‰ø°ÈÄöÁü•](https://img.shields.io/badge/‰∏™‰∫∫ÂæÆ‰ø°-ÈÄöÁü•-00D4AA?style=flat-square)](https://weixin.qq.com/)
[![TelegramÈÄöÁü•](https://img.shields.io/badge/Telegram-ÈÄöÁü•-00D4AA?style=flat-square)](https://telegram.org/)
[![dingtalkÈÄöÁü•](https://img.shields.io/badge/ÈíâÈíâ-ÈÄöÁü•-00D4AA?style=flat-square)](#)
[![È£û‰π¶ÈÄöÁü•](https://img.shields.io/badge/È£û‰π¶-ÈÄöÁü•-00D4AA?style=flat-square)](https://www.feishu.cn/)
[![ÈÇÆ‰ª∂ÈÄöÁü•](https://img.shields.io/badge/Email-ÈÄöÁü•-00D4AA?style=flat-square)](#)
[![ntfyÈÄöÁü•](https://img.shields.io/badge/ntfy-ÈÄöÁü•-00D4AA?style=flat-square)](https://github.com/binwiederhier/ntfy)
[![BarkÈÄöÁü•](https://img.shields.io/badge/Bark-ÈÄöÁü•-00D4AA?style=flat-square)](https://github.com/Finb/Bark)
[![SlackÈÄöÁü•](https://img.shields.io/badge/Slack-ÈÄöÁü•-00D4AA?style=flat-square)](https://slack.com/)
[![ÈÄöÁî®Webhook](https://img.shields.io/badge/ÈÄöÁî®-Webhook-607D8B?style=flat-square&amp;logo=webhook&amp;logoColor=white)](#)


[![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-Ëá™Âä®Âåñ-2088FF?style=flat-square&amp;logo=github-actions&amp;logoColor=white)](https://github.com/sansan0/TrendRadar)
[![GitHub Pages](https://img.shields.io/badge/GitHub_Pages-ÈÉ®ÁΩ≤-4285F4?style=flat-square&amp;logo=github&amp;logoColor=white)](https://sansan0.github.io/TrendRadar)
[![Docker](https://img.shields.io/badge/Docker-ÈÉ®ÁΩ≤-2496ED?style=flat-square&amp;logo=docker&amp;logoColor=white)](https://hub.docker.com/r/wantcat/trendradar)
[![MCP Support](https://img.shields.io/badge/MCP-AIÂàÜÊûêÊîØÊåÅ-FF6B6B?style=flat-square&amp;logo=ai&amp;logoColor=white)](https://modelcontextprotocol.io/)
[![AIÂàÜÊûêÊé®ÈÄÅ](https://img.shields.io/badge/AI-ÂàÜÊûêÊé®ÈÄÅ-FF6B6B?style=flat-square&amp;logo=openai&amp;logoColor=white)](#)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

**‰∏≠Êñá** | **[English](README-EN.md)**

&lt;/div&gt;

&gt; Êú¨È°πÁõÆ‰ª•ËΩªÈáèÔºåÊòìÈÉ®ÁΩ≤‰∏∫ÁõÆÊ†á

&lt;br&gt;

## üìë Âø´ÈÄüÂØºËà™

&gt; üí° **ÁÇπÂáª‰∏ãÊñπÈìæÊé•**ÂèØÂø´ÈÄüË∑≥ËΩ¨Âà∞ÂØπÂ∫îÁ´†ËäÇ„ÄÇÈÉ®ÁΩ≤Êé®Ëçê‰ªé„Äå**Âø´ÈÄüÂºÄÂßã**„ÄçÂÖ•ÊâãÔºåÈúÄË¶ÅËØ¶ÁªÜËá™ÂÆö‰πâËØ∑Áúã„Äå**ÈÖçÁΩÆËØ¶Ëß£**„Äç

&lt;div align=&quot;center&quot;&gt;

|   |   |   |
|:---:|:---:|:---:|
| [üöÄ **Âø´ÈÄüÂºÄÂßã**](#-Âø´ÈÄüÂºÄÂßã) | [AI Êô∫ËÉΩÂàÜÊûê](#-ai-Êô∫ËÉΩÂàÜÊûê) | [‚öôÔ∏è **ÈÖçÁΩÆËØ¶Ëß£**](#ÈÖçÁΩÆËØ¶Ëß£) |
| [DockerÈÉ®ÁΩ≤](#6-docker-ÈÉ®ÁΩ≤) | [MCPÂÆ¢Êà∑Á´Ø](#-mcp-ÂÆ¢Êà∑Á´Ø) | [üìù **Êõ¥Êñ∞Êó•Âøó**](#-Êõ¥Êñ∞Êó•Âøó) |
| [üéØ **Ê†∏ÂøÉÂäüËÉΩ**](#-Ê†∏ÂøÉÂäüËÉΩ) | [‚òï **ÊîØÊåÅÈ°πÁõÆ**](#-ÊîØÊåÅÈ°πÁõÆ) | [üìö **È°πÁõÆÁõ∏ÂÖ≥**](#-È°πÁõÆÁõ∏ÂÖ≥) |

&lt;/div&gt;

&lt;br&gt;

- ÊÑüË∞¢**‰∏∫È°πÁõÆÁÇπ star** ÁöÑËßÇ‰ºó‰ª¨Ôºå**fork** ‰Ω†ÊâÄÊ¨≤‰πüÔºå**star** ÊàëÊâÄÊ¨≤‰πüÔºå‰∏§ËÄÖÂæóÂÖºüòçÊòØÂØπÂºÄÊ∫êÁ≤æÁ•ûÊúÄÂ•ΩÁöÑÊîØÊåÅ

&lt;details&gt;
&lt;summary&gt;üëâ ÁÇπÂáªÂ±ïÂºÄÔºö&lt;strong&gt;Ëá¥Ë∞¢ÂêçÂçï&lt;/strong&gt; (Â§©‰ΩøËΩÆËç£Ë™âÊ¶ú üî•73+üî• ‰Ωç)&lt;/summary&gt;

### Êó©ÊúüÊîØÊåÅËÄÖËá¥Ë∞¢

&gt; üí° **ÁâπÂà´ËØ¥Êòé**Ôºö
&gt;
&gt; 1. **ÂÖ≥‰∫éÂêçÂçï**Ôºö‰∏ãÊñπË°®Ê†ºËÆ∞ÂΩï‰∫ÜÈ°πÁõÆËµ∑Ê≠•Èò∂ÊÆµÔºàÂ§©‰ΩøËΩÆÔºâÁöÑÊîØÊåÅËÄÖ„ÄÇÂõ†Êó©Êúü‰∫∫Â∑•ÁªüËÆ°ÁπÅÁêêÔºå**ÈöæÂÖçÂ≠òÂú®ÁñèÊºèÊàñËÆ∞ÂΩï‰∏çÂÖ®ÁöÑÊÉÖÂÜµÔºåÂ¶ÇÊúâÈÅóÊºèÔºåÂÆûÈùûÊú¨ÊÑèÔºå‰∏áÊúõÊµ∑Ê∂µ**„ÄÇ
&gt; 2. **Êú™Êù•ËßÑÂàí**Ôºö‰∏∫‰∫ÜÂ∞ÜÊúâÈôêÁöÑÁ≤æÂäõÂõûÂΩí‰ª£Á†Å‰∏éÂäüËÉΩËø≠‰ª£Ôºå**Âç≥Êó•Ëµ∑‰∏çÂÜç‰∫∫Â∑•Áª¥Êä§Ê≠§ÂêçÂçï**„ÄÇ
&gt;
&gt; Êó†ËÆ∫ÂêçÂ≠óÊòØÂê¶‰∏äÊ¶úÔºå‰Ω†‰ª¨ÁöÑÊØè‰∏Ä‰ªΩÊîØÊåÅÈÉΩÊòØ TrendRadar ËÉΩÂ§üËµ∞Âà∞‰ªäÂ§©ÁöÑÂü∫Áü≥„ÄÇüôè

### Âü∫Á°ÄËÆæÊñΩÊîØÊåÅ

ÊÑüË∞¢ **GitHub** ÂÖçË¥πÊèê‰æõÁöÑÂü∫Á°ÄËÆæÊñΩÔºåËøôÊòØÊú¨È°πÁõÆÂæó‰ª•**‰∏ÄÈîÆ fork**‰æøÊç∑ËøêË°åÁöÑÊúÄÂ§ßÂâçÊèê„ÄÇ

### Êï∞ÊçÆÊîØÊåÅ

Êú¨È°πÁõÆ‰ΩøÁî® [newsnow](https://github.com/ourongxing/newsnow) È°πÁõÆÁöÑ API Ëé∑ÂèñÂ§öÂπ≥Âè∞Êï∞ÊçÆÔºåÁâπÂà´ÊÑüË∞¢‰ΩúËÄÖÊèê‰æõÁöÑÊúçÂä°„ÄÇ

ÁªèËÅîÁ≥ªÔºå‰ΩúËÄÖË°®Á§∫Êó†ÈúÄÊãÖÂøÉÊúçÂä°Âô®ÂéãÂäõÔºå‰ΩÜËøôÊòØÂü∫‰∫é‰ªñÁöÑÂñÑÊÑèÂíå‰ø°‰ªª„ÄÇËØ∑Â§ßÂÆ∂Ôºö
- **ÂâçÂæÄ [newsnow È°πÁõÆ](https://github.com/ourongxing/newsnow) ÁÇπ star ÊîØÊåÅ**
- Docker ÈÉ®ÁΩ≤Êó∂ÔºåËØ∑ÂêàÁêÜÊéßÂà∂Êé®ÈÄÅÈ¢ëÁéáÔºåÂãøÁ´≠Ê≥ΩËÄåÊ∏î

### Êé®ÂπøÂä©Âäõ

&gt; ÊÑüË∞¢‰ª•‰∏ãÂπ≥Âè∞Âíå‰∏™‰∫∫ÁöÑÊé®Ëçê(ÊåâÊó∂Èó¥ÊéíÂàó)

- [Â∞è‰ºóËΩØ‰ª∂](https://mp.weixin.qq.com/s/fvutkJ_NPUelSW9OGK39aA) - ÂºÄÊ∫êËΩØ‰ª∂Êé®ËçêÂπ≥Âè∞
- [LinuxDo Á§æÂå∫](https://linux.do/) - ÊäÄÊúØÁà±Â•ΩËÄÖÁöÑËÅöÈõÜÂú∞
- [ÈòÆ‰∏ÄÂ≥∞Âë®Âàä](https://github.com/ruanyf/weekly) - ÊäÄÊúØÂúàÊúâÂΩ±ÂìçÂäõÁöÑÂë®Âàä

### ËßÇ‰ºóÊîØÊåÅ

&gt; ÊÑüË∞¢**Áªô‰∫àËµÑÈáëÊîØÊåÅ**ÁöÑÊúãÂèã‰ª¨Ôºå‰Ω†‰ª¨ÁöÑÊÖ∑ÊÖ®Â∑≤ÂåñË∫´‰∏∫ÈîÆÁõòÊóÅÁöÑÈõ∂È£üÈ•ÆÊñôÔºåÈô™‰º¥ÁùÄÈ°πÁõÆÁöÑÊØè‰∏ÄÊ¨°Ëø≠‰ª£„ÄÇ
&gt;
&gt; **ÂÖ≥‰∫é&quot;‰∏ÄÂÖÉÁÇπËµû&quot;ÁöÑÂõûÂΩí**Ôºö
&gt; ÈöèÁùÄ v5.0.0 ÁâàÊú¨ÁöÑÂèëÂ∏ÉÔºåÈ°πÁõÆËøàÂÖ•‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÈò∂ÊÆµ„ÄÇ‰∏∫‰∫ÜÊîØÊåÅÊó•ÁõäÂ¢ûÈïøÁöÑ API ÊàêÊú¨ÂíåÂíñÂï°Âõ†Ê∂àËÄóÔºå&quot;‰∏ÄÂÖÉÁÇπËµû&quot;ÈÄöÈÅìÁé∞Â∑≤ÈáçÊñ∞ÂºÄÂêØ„ÄÇ‰Ω†ÁöÑÊØè‰∏Ä‰ªΩÂøÉÊÑèÔºåÈÉΩÂ∞ÜËΩ¨Âåñ‰∏∫‰ª£Á†Å‰∏ñÁïåÈáåÁöÑ Token ÂíåÂä®Âäõ„ÄÇüöÄ [ÂâçÂæÄÊîØÊåÅ](#-ÊîØÊåÅÈ°πÁõÆ)

|           ÁÇπËµû‰∫∫            |  ÈáëÈ¢ù  |  Êó•Êúü  |             Â§áÊ≥®             |
| :-------------------------: | :----: | :----: | :-----------------------: |
|           D*5          |  1.8 * 3 | 2025.11.24  |    | 
|           *È¨º          |  1 | 2025.11.17  |    | 
|           *Ë∂Ö          |  10 | 2025.11.17  |    | 
|           R*w          |  10 | 2025.11.17  | Ëøô agent ÂÅöÁöÑÁâõÈÄºÂïä,ÂÖÑÂºü    | 
|           J*o          |  1 | 2025.11.17  | ÊÑüË∞¢ÂºÄÊ∫ê,Á•ùÂ§ß‰Ω¨‰∫ã‰∏öÊúâÊàê    | 
|           *Êô®          |  8.88  | 2025.11.16  | È°πÁõÆ‰∏çÈîô,Á†îÁ©∂Â≠¶‰π†‰∏≠    | 
|           *Êµ∑          |  1  | 2025.11.15  |    | 
|           *Âæ∑          |  1.99  | 2025.11.15  |    | 
|           *Áñè          |  8.8  | 2025.11.14  |  ÊÑüË∞¢ÂºÄÊ∫êÔºåÈ°πÁõÆÂæàÊ£íÔºåÊîØÊåÅ‰∏Ä‰∏ã   | 
|           M*e          |  10  | 2025.11.14  |  ÂºÄÊ∫ê‰∏çÊòìÔºåÂ§ß‰Ω¨ËæõËã¶‰∫Ü   | 
|           **ÊüØ          |  1  | 2025.11.14  |     | 
|           *‰∫ë          |  88  | 2025.11.13  |    Â•ΩÈ°πÁõÆÔºåÊÑüË∞¢ÂºÄÊ∫ê  | 
|           *W          |  6  | 2025.11.13  |      | 
|           *ÂáØ          |  1  | 2025.11.13  |      | 
|           ÂØπ*.          |  1  | 2025.11.13  |    Thanks for your TrendRadar  | 
|           s*y          |  1  | 2025.11.13  |      | 
|           **Áøî          |  10  | 2025.11.13  |   Â•ΩÈ°πÁõÆÔºåÁõ∏ËßÅÊÅ®ÊôöÔºåÊÑüË∞¢ÂºÄÊ∫êÔºÅ     | 
|           *Èü¶          |  9.9  | 2025.11.13  |   TrendRadarË∂ÖËµûÔºåËØ∑ËÄÅÂ∏àÂñùÂíñÂï°~     | 
|           h*p          |  5  | 2025.11.12  |   ÊîØÊåÅ‰∏≠ÂõΩÂºÄÊ∫êÂäõÈáèÔºåÂä†Ê≤πÔºÅ     | 
|           c*r          |  6  | 2025.11.12  |        | 
|           a*n          |  5  | 2025.11.12  |        | 
|           „ÄÇ*c          |  1  | 2025.11.12  |    ÊÑüË∞¢ÂºÄÊ∫êÂàÜ‰∫´    | 
|           *ËÆ∞          |  1  | 2025.11.11  |        | 
|           *‰∏ª          |  1  | 2025.11.10  |        | 
|           *‰∫Ü          |  10  | 2025.11.09  |        | 
|           *Êù∞          |  5  | 2025.11.08  |        | 
|           *ÁÇπ          |  8.80  | 2025.11.07  |   ÂºÄÂèë‰∏çÊòìÔºåÊîØÊåÅ‰∏Ä‰∏ã„ÄÇ     | 
|           Q*Q          |  6.66  | 2025.11.07  |   ÊÑüË∞¢ÂºÄÊ∫êÔºÅ     | 
|           C*e          |  1  | 2025.11.05  |        | 
|           Peter Fan          |  20  | 2025.10.29  |        | 
|           M*n          |  1  | 2025.10.27  |      ÊÑüË∞¢ÂºÄÊ∫ê  | 
|           *ËÆ∏          |  8.88  | 2025.10.23  |      ËÄÅÂ∏à Â∞èÁôΩ‰∏ÄÊûöÔºåÊë∏‰∫ÜÂá†Â§©‰∫ÜËøòÊ≤°Êï¥Ëµ∑Êù•ÔºåÊ±ÇÊïô  | 
|           Eason           |  1  | 2025.10.22  |      ËøòÊ≤°Êï¥ÊòéÁôΩÔºå‰ΩÜ‰Ω†Âú®ÂÅöÂ•Ω‰∫ã  | 
|           P*n           |  1  | 2025.10.20  |          |
|           *Êù∞           |  1  | 2025.10.19  |          |
|           *Âæê           |  1  | 2025.10.18  |          |
|           *Âøó           |  1  | 2025.10.17  |          |
|           *üòÄ           |  10  | 2025.10.16  |     ÁÇπËµû     |
|           **Êù∞           |  10  | 2025.10.16  |          |
|           *Âï∏           |  10  | 2025.10.16  |          |
|           *Á∫™           |  5  | 2025.10.14  | TrendRadar         |
|           J*d           |  1  | 2025.10.14  | Ë∞¢Ë∞¢‰Ω†ÁöÑÂ∑•ÂÖ∑ÔºåÂæàÂ•ΩÁé©...          |
|           *H           |  1  | 2025.10.14  |           |
|           ÈÇ£*O           |  10  | 2025.10.13  |           |
|           *ÂúÜ           |  1  | 2025.10.13  |           |
|           P*g           |  6  | 2025.10.13  |           |
|           Ocean           |  20  | 2025.10.12  |  ...ÁúüÁöÑÂ§™Ê£í‰∫ÜÔºÅÔºÅÔºÅÂ∞èÁôΩÁ∫ßÂà´‰πüËÉΩÁõ¥Êé•Áî®...         |
|           **Âüπ           |  5.2  | 2025.10.2  |  github-yzyf1312:ÂºÄÊ∫ê‰∏áÂ≤Å         |
|           *Ê§ø           |  3  | 2025.9.23  |  Âä†Ê≤πÔºåÂæà‰∏çÈîô         |
|           *üçç           |  10  | 2025.9.21  |           |
|           E*f           |  1  | 2025.9.20  |           |
|           *ËÆ∞            |  1  | 2025.9.20  |           |
|           z*u            |  2  | 2025.9.19  |           |
|           **Êòä            |  5  | 2025.9.17  |           |
|           *Âè∑            |  1  | 2025.9.15  |           |
|           T*T            |  2  | 2025.9.15  |  ÁÇπËµû         |
|           *ÂÆ∂            |  10  | 2025.9.10  |           |
|           *X            |  1.11  | 2025.9.3  |           |
|           *È£ô            |  20  | 2025.8.31  |  Êù•Ëá™ËÄÅÁ´•Ë∞¢Ë∞¢         |
|           *‰∏ã            |  1  | 2025.8.30  |           |
|           2*D            |  88  | 2025.8.13 ‰∏ãÂçà |           |
|           2*D            |  1  | 2025.8.13 ‰∏äÂçà |           |
|           S*o            |  1  | 2025.8.05 |   ÊîØÊåÅ‰∏Ä‰∏ã        |
|           *‰æ†            |  10  | 2025.8.04 |           |
|           x*x            |  2  | 2025.8.03 |  trendRadar Â•ΩÈ°πÁõÆ ÁÇπËµû          |
|           *Ëøú            |  1  | 2025.8.01 |            |
|           *ÈÇ™            |  5  | 2025.8.01 |            |
|           *Ê¢¶            |  0.1  | 2025.7.30 |            |
|           **Èæô            |  10  | 2025.7.29 |      ÊîØÊåÅ‰∏Ä‰∏ã      |


&lt;/details&gt;

&lt;br&gt;

## ü™Ñ ËµûÂä©ÂïÜ

&lt;div align=&quot;center&quot;&gt;

&gt; **Ëôö‰Ωç‰ª•ÂæÖ**

&lt;/div&gt;

&lt;br&gt;

&lt;a name=&quot;-ÊîØÊåÅÈ°πÁõÆ&quot;&gt;&lt;/a&gt;

### ‚ù§Ô∏è ËßâÂæóÂ•ΩÁî®ÔºüÊîØÊåÅ‰∏Ä‰∏ã

&gt; Ëã• TrendRadar Êõæ‰∏∫‰Ω†ÊçïÊçâ‰ª∑ÂÄºÔºå‰∏çÂ¶®‰∏∫ÂÆÉÊ≥®ÂÖ•Âä®ÂäõÔºåÂä©ÂÖ∂ÊåÅÁª≠ËøõÂåñ
&gt;
&gt; ÈáëÈ¢ùÈöèÊÑèÔºå1 ÂÖÉ‰πüÊòØÂØπÂºÄÊ∫êÁöÑÈºìÂä±„ÄÇÊ¨¢ËøéÂú®ËµûËµèÊó∂Â§áÊ≥®ÁïôË®Ä (¬¥‚ñΩ` É‚ô°∆™)

&lt;div align=&quot;center&quot;&gt;

| ÂæÆ‰ø°ËµûËµè | ÊîØ‰ªòÂÆùËµûËµè |
|:---:|:---:|
| &lt;img src=&quot;https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F2ae0a88d98079f7e876c2b4dc85233c6-9e8025.JPG&quot; width=&quot;240&quot; alt=&quot;ÂæÆ‰ø°ËµûËµè&quot;&gt; | &lt;img src=&quot;https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F1ed4f20ab8e35be51f8e84c94e6e239b4-fe4947.JPG&quot; width=&quot;240&quot; alt=&quot;ÊîØ‰ªòÂÆùËµûËµè&quot;&gt; |

&lt;/div&gt;


### ü§ù ‰∫åÊ¨°ÂºÄÂèë‰∏éÂºïÁî®

Â¶ÇÊûú‰Ω†Âú®È°πÁõÆ‰∏≠‰ΩøÁî®ÊàñÂÄüÈâ¥‰∫ÜÊú¨È°πÁõÆÁöÑÊÄùË∑Ø„ÄÅÊ†∏ÂøÉ‰ª£Á†ÅÔºå**ÈùûÂ∏∏Ê¨¢Ëøé**Âú® README ÊàñÊñáÊ°£‰∏≠Ê≥®ÊòéÊù•Ê∫êÂπ∂ÈôÑ‰∏äÊú¨‰ªìÂ∫ìÈìæÊé•„ÄÇ

ËøôÂ∞ÜÊúâÂä©‰∫éÈ°πÁõÆÁöÑÊåÅÁª≠Áª¥Êä§ÂíåÁ§æÂå∫ÂèëÂ±ïÔºåÊÑüË∞¢‰Ω†ÁöÑÂ∞äÈáç‰∏éÊîØÊåÅÔºÅ‚ù§Ô∏è


### üí¨ ‰∫§ÊµÅ‰∏éÂèçÈ¶à

- **GitHub Issues**ÔºöÈÄÇÂêàÂÖ∑‰ΩìÁöÑÊäÄÊúØÈóÆÈ¢ò„ÄÇÊèêÈóÆÊó∂ËØ∑Êèê‰æõÂÆåÊï¥‰ø°ÊÅØÔºàÊà™Âõæ„ÄÅÈîôËØØÊó•ÂøóÁ≠âÔºâÔºåÊúâÂä©‰∫éÂø´ÈÄüÂÆö‰Ωç„ÄÇ
- **ÂÖ¨‰ºóÂè∑‰∫§ÊµÅ**ÔºöÂª∫ËÆÆ‰ºòÂÖàÂú®Áõ∏ÂÖ≥ÊñáÁ´†‰∏ãÁöÑÁïôË®ÄÂå∫‰∫§ÊµÅ„ÄÇËã•ÈúÄÂêéÂè∞ÊèêÈóÆÔºå**ÂÖàÁÇπËµû/Êé®Ëçê**ÊñáÁ´†ÊòØÊúÄÂ•ΩÁöÑ‚ÄúÊï≤Èó®Á†ñ‚ÄùÔºåÊàëÂú®ÂêéÂè∞ÈÉΩËÉΩÊÑüÂèóÂà∞Ëøô‰ªΩÂøÉÊÑèÂìü (¬¥‚ñΩ` É‚ô°∆™)„ÄÇ

&gt; **ÂèãÊÉÖÊèêÁ§∫**Ôºö        
&gt; Êú¨È°πÁõÆ‰∏∫ÂºÄÊ∫êÂàÜ‰∫´ÔºåÈùûÂïÜ‰∏ö‰∫ßÂìÅ„ÄÇÊää‰ΩúËÄÖÂΩìÊúãÂèãËÄåÈùûÂÆ¢ÊúçÔºåÊ≤üÈÄöÊïàÁéá‰ºöÊõ¥È´òÂì¶ÔºÅ     

&lt;div align=&quot;center&quot;&gt;

|ÂÖ¨‰ºóÂè∑ÂÖ≥Ê≥® |
|:---:|
| &lt;img src=&quot;_image/weixin.png&quot; width=&quot;500&quot; title=&quot;Á°ÖÂü∫Ëå∂Ê∞¥Èó¥&quot;/&gt; |

&lt;/div&gt;

&lt;br&gt;

## üìù Êõ¥Êñ∞Êó•Âøó

&gt; **üìå Êü•ÁúãÊúÄÊñ∞Êõ¥Êñ∞**Ôºö**[Âéü‰ªìÂ∫ìÊõ¥Êñ∞Êó•Âøó](https://github.com/sansan0/TrendRadar?tab=readme-ov-file#-Êõ¥Êñ∞Êó•Âøó)** Ôºö
- **ÊèêÁ§∫**ÔºöÂª∫ËÆÆÊü•Áúã„ÄêÂéÜÂè≤Êõ¥Êñ∞„ÄëÔºåÊòéÁ°ÆÂÖ∑‰ΩìÁöÑ„ÄêÂäüËÉΩÂÜÖÂÆπ„Äë


### 2026/02/09 - v6.0.0

&gt; **Breaking Change**ÔºöÈÖçÁΩÆÊñá‰ª∂ÂçáÁ∫ßÔºàconfig.yaml 2.0.0ÔºâÔºåÊóßÁâà `push_window` Âíå `analysis_window` ÈÖçÁΩÆ‰∏çÂÜçÂÖºÂÆπÔºåËØ∑ÂèÇËÄÉÊñ∞Áâà config.yaml ËøÅÁßª

- **Áªü‰∏ÄË∞ÉÂ∫¶Á≥ªÁªü**ÔºöÊñ∞Â¢û `timeline.yaml`ÔºåÁî®‰∏ÄÂ•óÈÖçÁΩÆÊéßÂà∂„Äå‰ªÄ‰πàÊó∂Èó¥ÈááÈõÜ / Êé®ÈÄÅ / AI ÂàÜÊûê„Äç
- **5 ÁßçÈ¢ÑËÆæÊ®°Êùø**Ôºö`always_on`ÔºàÂÖ®Â§©ÂÄôÔºåÈªòËÆ§Ôºâ„ÄÅ`morning_evening`ÔºàÊó©ÊôöÊ±áÊÄªÔºâ„ÄÅ`office_hours`ÔºàÂäûÂÖ¨Êó∂Èó¥Ôºâ„ÄÅ`night_owl`ÔºàÂ§úÁå´Â≠êÔºâ„ÄÅ`custom`ÔºàËá™ÂÆö‰πâÔºâÔºõ‰πüÊîØÊåÅÂú® `presets:` ‰∏ãÊñ∞Â¢ûËá™Â∑±ÁöÑÊ®°ÊùøÔºåÂè™Ë¶Å key ‰∏çÈáçÂ§çÔºåÁÑ∂ÂêéÂú® config.yaml ÈáåÂ°´‰Ω†ÁöÑÊ®°ÊùøÂêçÂç≥ÂèØ
- **ÁÅµÊ¥ªÁöÑÊó∂Èó¥ÊÆµÈÖçÁΩÆ**ÔºöÊîØÊåÅÂ∑•‰ΩúÊó•/Âë®Êú´Â∑ÆÂºÇÂåñ„ÄÅË∑®ÂçàÂ§úÊó∂Èó¥ÊÆµ„ÄÅper-period once ÂéªÈáç
- **ÂèØËßÜÂåñÈÖçÁΩÆÁºñËæëÂô®**Ôºö
  - Êñ∞Â¢û `timeline.yaml` ÁºñËæëÊ†áÁ≠æÈ°µÔºå‰∏é config.yaml / frequency_words.txt Âπ∂Âàó
  - È¢ÑËÆæÊ®°ÂºèÂç°ÁâáÈÄâÊã©ÔºöÁÇπÂáªÂç≥ÂàáÊç¢ÔºåËá™Âä®ÂêåÊ≠• config.yaml ÁöÑ `schedule.preset`
  - Âë®ËßÜÂõæÊó∂Èó¥Á∫øÔºö7 Â§© √ó 24 Â∞èÊó∂Ê∞¥Âπ≥Êù°ÔºåÁî®È¢úËâ≤Âå∫ÂàÜÊé®ÈÄÅ/ÂàÜÊûê/ÈááÈõÜÁä∂ÊÄÅ
  - ÂèØ‰∫§‰∫íÊéß‰ª∂ÔºöÂºÄÂÖ≥„ÄÅ‰∏ãÊãâÊ°Ü„ÄÅÊó∂Èó¥ÈÄâÊã©Âô®ÔºåÂè≥‰æß‰øÆÊîπÂÆûÊó∂ÂêåÊ≠•Âà∞Â∑¶‰æß YAML
  - Âë®Êò†Â∞Ñ‰∏ãÊãâÈÄâÊã©ÔºöÊ†πÊçÆÊó•ËÆ°ÂàíÂä®ÊÄÅÂ°´ÂÖÖÔºåÊãñÊãâÁÇπÂáªÂç≥ÂèØÂÆåÊàêË∞ÉÂ∫¶ÈÖçÁΩÆ
- **AI ÊèêÁ§∫ËØçÁ®≥ÂÆöÊÄß‰ºòÂåñ**Ôºàai_analysis_prompt.txt v2.0.0ÔºâÔºö
  - Ê†ºÂºèËßÑËåÉÁã¨Á´ãËØ¥ÊòéÔºöÂ∞ÜÊç¢Ë°å/Ê†áÁ≠æ/Â∫èÂè∑/Á¶ÅÊ≠¢‰∫ãÈ°π‰ªé JSON value ‰∏≠ÊäΩÂá∫Ôºå‰Ωú‰∏∫Áã¨Á´ãÁ´†ËäÇ
  - JSON Ê®°ÊùøÁÆÄÂåñÔºöÂ≠óÊÆµÊèèËø∞Áº©Áü≠‰∏∫‰∏ÄÂè•ËØù + Â≠óÊï∞ÈôêÂà∂ÔºåÂáèÂ∞ë AI ËæìÂá∫Ê†ºÂºèÊ∑∑‰π±
  - ÂéªÈô§ system prompt ‰∏≠ÁöÑ Markdown Ê†ºÂºèÔºå‰∏é&quot;Á¶ÅÊ≠¢ Markdown&quot;Êåá‰ª§‰øùÊåÅ‰∏ÄËá¥
  - ÊâÄÊúâ JSON Â≠óÊÆµÂ£∞Êòé‰∏∫ÂèØÈÄâÔºåÁº∫Â∞ë‰ªª‰ΩïÂ≠óÊÆµ‰∏ç‰ºöÊä•ÈîôÔºåÂ¢ûÂº∫ÂÆπÈîôÊÄß
- **Êñ∞Â¢ûÁã¨Á´ãÂ±ïÁ§∫Âå∫ AI Ê¶ÇÊã¨ÂàÜÊûê**Ôºà`ai_analysis.include_standalone`ÔºâÔºö
  - Êñ∞Â¢ûÁã¨Á´ãÂºÄÂÖ≥ÔºåÂºÄÂêØÂêé AI ÂØπÊØè‰∏™ standalone Ê∫êÁîüÊàêÊ†∏ÂøÉÊ¶ÇÊã¨
  - AI ÂàÜÊûê‰∏éÊé®ÈÄÅÂ±ïÁ§∫Ëß£ËÄ¶ÔºöÊó†ÈúÄÂºÄÂêØÁã¨Á´ãÂ±ïÁ§∫Âå∫ÁöÑÊé®ÈÄÅÊòæÁ§∫ÔºåAI ‰πüÂèØÁã¨Á´ãÂàÜÊûêÂÆåÊï¥ÁÉ≠Ê¶úÊï∞ÊçÆ
  - ÊîØÊåÅÁÉ≠Ê¶úÂπ≥Âè∞Âíå RSS Ê∫êÔºåÂê´ÊéíÂêç/Êó∂Èó¥/ËΩ®ËøπÊï∞ÊçÆ
  - ËΩ®ËøπÂàÜÊûê‰∏é `include_rank_timeline` ËÅîÂä®ÔºöÂºÄÂêØÊó∂Âà©Áî®ËΩ®ËøπÊï∞ÊçÆÂÅöÊ∑±Â∫¶Ë∂ãÂäøÂàÜÊûêÔºåÂÖ≥Èó≠Êó∂Âü∫‰∫éÊéíÂêçÂÅöÁÆÄË¶ÅÂà§Êñ≠
  - Êñ∞Â¢û `standalone_summaries` JSON Â≠óÊÆµÔºàÁã¨Á´ãÊ∫êÁÇπÈÄüËßàÔºâÔºåÊâÄÊúâÊé®ÈÄÅÊ∏†ÈÅìÂùáÂ∑≤ÈÄÇÈÖçÊ∏≤Êüì


### 2026/02/09 - mcp-v4.0.0

- **üî• AI Ê∂àÊÅØÁõ¥Êé®ÊâÄÊúâÊ∏†ÈÅì**ÔºöËÆ© AI ÂÜôÂ•ΩÁöÑÂÜÖÂÆπ‰∏ÄÈîÆÊé®ÈÄÅÂà∞È£û‰π¶„ÄÅÈíâÈíâ„ÄÅTelegram„ÄÅÈÇÆ‰ª∂Á≠â 9 ‰∏™Ê∏†ÈÅìÔºåMarkdown Ëá™Âä®ÈÄÇÈÖçÂêÑÂπ≥Âè∞Ê†ºÂºèÔºå‰∏çÁî®ÊìçÂøÉÊ†ºÂºèÂ∑ÆÂºÇ
- **Êñ∞Â¢ûÊ†ºÂºèÂåñÁ≠ñÁï•ÊåáÂçó**ÔºöÊñ∞Â¢û `get_channel_format_guide` Â∑•ÂÖ∑ÔºåÂëäËØâ AI ÊØè‰∏™Ê∏†ÈÅìÊîØÊåÅ‰ªÄ‰πàÊ†ºÂºè„ÄÅÊúâ‰ªÄ‰πàÈôêÂà∂ÔºåÁîüÊàêÁöÑÂÜÖÂÆπÊéíÁâàÊõ¥Â•ΩÁúã
- **Êô∫ËÉΩÂàÜÊâπÂèëÈÄÅ**ÔºöË∂ÖÈïøÊ∂àÊÅØËá™Âä®ÊåâÂêÑÊ∏†ÈÅìÂ≠óËäÇÈôêÂà∂ÊãÜÂàÜÔºàÈ£û‰π¶ 30KB„ÄÅÈíâÈíâ 20KB Á≠âÔºâÔºåÈÖçÁΩÆËØªÂèñËá™ config.yaml
- **‰øÆÂ§çÊ∏†ÈÅìËØØÊ£ÄÊµã**Ôºöntfy ‰∏çÂÜçÂõ†‰∏∫ÈªòËÆ§Âú∞ÂùÄË¢´ËØØÊä•‰∏∫&quot;Â∑≤ÈÖçÁΩÆ&quot;
- **‰ª£Á†ÅÂ§çÁî®‰ºòÂåñ**ÔºöÊâπÊ¨°Â§ÑÁêÜÂáΩÊï∞Áõ¥Êé•Â§çÁî® trendradar Ê†∏ÂøÉÊ®°ÂùóÔºå‰∏çÈáçÂ§çÈÄ†ËΩÆÂ≠ê


&lt;details&gt;
&lt;summary&gt;üëâ ÁÇπÂáªÂ±ïÂºÄÔºö&lt;strong&gt;ÂéÜÂè≤Êõ¥Êñ∞&lt;/strong&gt;&lt;/summary&gt;


### 2026/01/28 - v5.5.0

&gt; Âíå mcp ÂäüËÉΩ‰∏ÄÊ†∑, Ëøô‰∏™Â∞èÂ∑•ÂÖ∑Êàë‰πü‰∏çÊñ∞ÂºÄ‰∏Ä‰∏™‰ªìÂ∫ìÁª¥Êä§‰∫Ü, ÂèçÊ≠£Á∫ØÂâçÁ´Ø, ÈÉΩÊêÅ‰∏ÄËµ∑Âêß

- Â¢ûÂä† trendradar ÁöÑÂèØËßÜÂåñÈÖçÁΩÆÁºñËæëÂô®


### 2026/02/02 - mcp-v3.2.0

- **Êñ∞Â¢û read_article Â∑•ÂÖ∑**ÔºöÈÄöËøá Jina AI Reader ËØªÂèñÂçïÁØáÊñáÁ´†Ê≠£ÊñáÔºàMarkdown Ê†ºÂºèÔºâ
- **Êñ∞Â¢û read_articles_batch Â∑•ÂÖ∑**ÔºöÊâπÈáèËØªÂèñÂ§öÁØáÊñáÁ´†ÔºàÊúÄÂ§ö 5 ÁØáÔºåËá™Âä®ÈôêÈÄüÔºâ
- **Êé®ËçêÂ∑•‰ΩúÊµÅ**Ôºö`search_news(query=&quot;ÂÖ≥ÈîÆËØç&quot;, include_url=True)` ‚Üí `read_article(url=...)` ËØªÂèñÊ≠£Êñá
- **ÊñáÊ°£Êõ¥Êñ∞**ÔºöREADME-MCP-FAQ.md Âíå README-MCP-FAQ-EN.md Êñ∞Â¢û Q19-Q20 ÊñáÁ´†ËØªÂèñÁõ∏ÂÖ≥ËØ¥Êòé


### 2026/01/10 - mcp-v3.0.0~v3.1.5

- **Breaking Change**ÔºöÊâÄÊúâÂ∑•ÂÖ∑ËøîÂõûÂÄºÁªü‰∏Ä‰∏∫ `{success, summary, data, error}` ÁªìÊûÑ
- **ÂºÇÊ≠•‰∏ÄËá¥ÊÄß**ÔºöÊâÄÊúâ 21 ‰∏™Â∑•ÂÖ∑ÂáΩÊï∞‰ΩøÁî® `asyncio.to_thread()` ÂåÖË£ÖÂêåÊ≠•Ë∞ÉÁî®
- **MCP Resources**ÔºöÊñ∞Â¢û 4 ‰∏™ËµÑÊ∫êÔºàplatforms„ÄÅrss-feeds„ÄÅavailable-dates„ÄÅkeywordsÔºâ
- **RSS Â¢ûÂº∫**Ôºö`get_latest_rss` ÊîØÊåÅÂ§öÊó•Êü•ËØ¢Ôºàdays ÂèÇÊï∞ÔºâÔºåË∑®Êó•Êúü URL ÂéªÈáç
- **Ê≠£ÂàôÂåπÈÖç‰øÆÂ§ç**Ôºö`get_trending_topics` ÊîØÊåÅ `/pattern/` Ê≠£ÂàôËØ≠Ê≥ïÂíå `display_name`
- **ÁºìÂ≠ò‰ºòÂåñ**ÔºöÊñ∞Â¢û `make_cache_key()` ÂáΩÊï∞ÔºåÂèÇÊï∞ÊéíÂ∫è+MD5 ÂìàÂ∏åÁ°Æ‰øù‰∏ÄËá¥ÊÄß
- **Êñ∞Â¢û check_version Â∑•ÂÖ∑**ÔºöÊîØÊåÅÂêåÊó∂Ê£ÄÊü• TrendRadar Âíå MCP Server ÁâàÊú¨Êõ¥Êñ∞


### 2026/01/23 - v5.4.0

- Â¢ûÂä† AI ÂàÜÊûêÊ®°ÂºèÁöÑÁã¨Á´ãÊéßÂà∂ÂäüËÉΩÔºåÂèØÈÄâ follow_report | daily | current | incremental 
- Êñ∞Â¢û AI ÂàÜÊûêÊó∂Èó¥Á™óÂè£ÊéßÂà∂ÔºåÊîØÊåÅËá™ÂÆö‰πâËøêË°åÊÆµÂèäÊØèÊó•È¢ëÊ¨°ÈôêÂà∂
- Â¢ûÂä†ÈÖçÁΩÆÊñá‰ª∂ÁâàÊú¨ÁÆ°ÁêÜÂäüËÉΩ
- ‰øÆÂ§çËã•Âπ≤bug


### 2026/01/19 - v5.3.0

&gt; **ÈáçÂ§ßÈáçÊûÑÔºöAI Ê®°ÂùóËøÅÁßªËá≥ LiteLLM**

- **Áªü‰∏Ä AI Êé•Âè£**Ôºö‰ΩøÁî® LiteLLM Êõø‰ª£ÊâãÂä®ÂÆûÁé∞ÔºåÊîØÊåÅ 100+ AI Êèê‰æõÂïÜ
- **ÁÆÄÂåñÈÖçÁΩÆ**ÔºöÁßªÈô§ `provider` Â≠óÊÆµÔºåÊîπÁî® `model: &quot;provider/model_name&quot;` Ê†ºÂºè
- **Êñ∞Â¢ûÂäüËÉΩ**ÔºöËá™Âä®ÈáçËØï (`num_retries`)„ÄÅÂ§áÁî®Ê®°Âûã (`fallback_models`)
- **ÈÖçÁΩÆÂèòÊõ¥**Ôºö
  - `ai.provider` ‚Üí ÁßªÈô§ÔºàÂ∑≤ÂêàÂπ∂Âà∞ modelÔºâ
  - `ai.base_url` ‚Üí `ai.api_base`
  - `AI_PROVIDER` ÁéØÂ¢ÉÂèòÈáè ‚Üí ÁßªÈô§
  - `AI_BASE_URL` ÁéØÂ¢ÉÂèòÈáè ‚Üí `AI_API_BASE`
- **Ê®°ÂûãÊ†ºÂºèÁ§∫‰æã**Ôºö
  - DeepSeek: `deepseek/deepseek-chat`
  - OpenAI: `openai/gpt-4o`
  - Gemini: `gemini/gemini-2.5-flash`
  - Anthropic: `anthropic/claude-3-5-sonnet`

### 2026/01/17 - v5.2.0

&gt; ‰∏ªË¶ÅËßÅ config.yaml ÊèèËø∞

**üåê AI ÁøªËØëÂäüËÉΩ**

- **Â§öËØ≠Ë®ÄÁøªËØë**ÔºöÊîØÊåÅÂ∞ÜÊé®ÈÄÅÂÜÖÂÆπÁøªËØë‰∏∫‰ªªÊÑèËØ≠Ë®Ä
- **ÊâπÈáèÁøªËØë**ÔºöÊô∫ËÉΩÊâπÈáèÂ§ÑÁêÜÔºåÂáèÂ∞ë API Ë∞ÉÁî®Ê¨°Êï∞
- **Ëá™ÂÆö‰πâÊèêÁ§∫ËØç**ÔºöÊîØÊåÅËá™ÂÆö‰πâÁøªËØëÈ£éÊ†º

**üîß ÈÖçÁΩÆÊû∂ÊûÑ‰ºòÂåñ**

- **AI Ê®°ÂûãÈÖçÁΩÆÁã¨Á´ã**ÔºöÂàÜÊûêÂíåÁøªËØëÂÖ±‰∫´Ê®°ÂûãÈÖçÁΩÆ
- **Âå∫ÂüüÂºÄÂÖ≥Áªü‰∏Ä**ÔºöÁªü‰∏ÄÁÆ°ÁêÜÊé®ÈÄÅÂå∫ÂüüÊòæÁ§∫
- **Âå∫ÂüüÊéíÂ∫èËá™ÂÆö‰πâ**ÔºöÊîØÊåÅËá™ÂÆö‰πâÂêÑÂå∫ÂüüÁöÑÊòæÁ§∫È°∫Â∫è

**‚ú® AI ÂàÜÊûêÂ¢ûÂº∫**

- **AI ÂàÜÊûêÂµåÂÖ• HTML**ÔºöÂàÜÊûêÁªìÊûúÁõ¥Êé•ÂµåÂÖ• HTML Êä•ÂëäÔºåÈÇÆ‰ª∂ÈÄöÁü•Áõ¥Êé•‰ΩøÁî®
- **ÂØåÊ†∑Âºè AI Âå∫Âùó**ÔºöÊ∏êÂèòËìùËâ≤ËÉåÊôØÂç°ÁâáÂºèÂ∏ÉÂ±ÄÔºåÊ∏ÖÊô∞ÂàÜÈöîÂêÑÂàÜÊûêÁª¥Â∫¶
- **ÊéíÂêçÊó∂Èó¥Á∫øÊîØÊåÅ**ÔºöAI ÂèØËé∑ÂèñÊØèÊù°Êñ∞ÈóªÂú®ÊØè‰∏™ÊäìÂèñÊó∂Èó¥ÁÇπÁöÑÁ≤æÁ°ÆÊéíÂêç
- **ÊùøÂùóÈáçÁªÑ (7‚Üí4)**ÔºöÊï¥Âêà‰∏∫Ê†∏ÂøÉÁÉ≠ÁÇπÊÄÅÂäø„ÄÅËàÜËÆ∫È£éÂêë‰∫âËÆÆ„ÄÅÂºÇÂä®‰∏éÂº±‰ø°Âè∑„ÄÅÁ†îÂà§Á≠ñÁï•Âª∫ËÆÆ

**üîß Â§öÊ®°ÂûãÈÄÇÈÖç**

- **ÈÄöÁî®ÂèÇÊï∞ÈÄè‰º†**ÔºöÊîØÊåÅÂêë API ÈÄè‰º†‰ªªÊÑèÈ´òÁ∫ßÂèÇÊï∞
- **Gemini ÈÄÇÈÖç**ÔºöÂéüÁîüÂèÇÊï∞ÊîØÊåÅÔºåÂÜÖÁΩÆÂÆâÂÖ®Á≠ñÁï•ÊîæÂÆΩ

**üêõ Bug ‰øÆÂ§ç**

- ‰øÆÂ§çËã•Âπ≤Â∑≤Áü•ÈóÆÈ¢òÔºåÊèêÂçáÁ≥ªÁªüÁ®≥ÂÆöÊÄß

### 2026/01/10 - v5.0.0

&gt; **ÂºÄÂèëÂ∞èÊèíÊõ≤**Ôºö
&gt; Ëá¥Êï¨ÈÇ£‰∏™Èô™‰º¥Êàë‰∏§Âπ¥Â§ö„ÄÅÂç¥Âú®ÂàöÁª≠Ë¥πÂêéÂèçÊâãÂºπÂá∫ `&quot;This organization has been disabled&quot;` ÁöÑÊüê C ÂéÇÊ®°Âûã

**‚ú® Êé®ÈÄÅÂÜÖÂÆπ&quot;‰∫îÂ§ßÊùøÂùó&quot;ÈáçÊûÑ**

Êú¨Ê¨°Êõ¥Êñ∞ÂØπÊé®ÈÄÅÊ∂àÊÅØËøõË°å‰∫ÜÂå∫ÂüüÂåñÈáçÊûÑÔºåÁé∞Âú®Êé®ÈÄÅÂÜÖÂÆπÊ∏ÖÊô∞Âú∞ÂàíÂàÜ‰∏∫‰∫îÂ§ßÊ†∏ÂøÉÊùøÂùóÔºö

1.  **üìä ÁÉ≠Ê¶úÊñ∞Èóª**ÔºöÊ†πÊçÆ‰Ω†ÁöÑÂÖ≥ÈîÆËØçÁ≤æÂáÜÁ≠õÈÄâÂêéÁöÑÂÖ®ÁΩëÁÉ≠ÁÇπËÅöÂêà„ÄÇ
2.  **üì∞ RSS ËÆ¢ÈòÖ**Ôºö‰Ω†ÁöÑ‰∏™ÊÄßÂåñËÆ¢ÈòÖÊ∫êÂÜÖÂÆπÔºåÊîØÊåÅÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑ„ÄÇ
3.  **üÜï Êú¨Ê¨°Êñ∞Â¢û**ÔºöÂÆûÊó∂ÊçïÊçâËá™‰∏äÊ¨°ËøêË°å‰ª•Êù•ÁöÑÂÖ®Êñ∞ÁÉ≠ÁÇπÔºàÂ∏¶ üÜï Ê†áËÆ∞Ôºâ„ÄÇ
4.  **üìã Áã¨Á´ãÂ±ïÁ§∫Âå∫**ÔºöÊåáÂÆöÂπ≥Âè∞ÁöÑÂÆåÊï¥ÁÉ≠Ê¶úÊàñ RSS Ê∫êÂ±ïÁ§∫Ôºå**ÂÆåÂÖ®‰∏çÂèóÂÖ≥ÈîÆËØçËøáÊª§ÈôêÂà∂**„ÄÇ
5.  **‚ú® AI ÂàÜÊûêÊùøÂùó**ÔºöÁî± AI È©±Âä®ÁöÑÊ∑±Â∫¶Ê¥ûÂØüÔºåÂåÖÂê´Ë∂ãÂäøÊ¶ÇËø∞„ÄÅÁÉ≠Â∫¶Ëµ∞ÂäøÂèä**ÊûÅÂÖ∂ÈáçË¶Å**ÁöÑÊÉÖÊÑüÂÄæÂêëÂàÜÊûê„ÄÇ

**‚ú® AI Êô∫ËÉΩÂàÜÊûêÊé®ÈÄÅÂäüËÉΩ**

- **AI ÂàÜÊûêÈõÜÊàê**Ôºö‰ΩøÁî® AI Â§ßÊ®°ÂûãÂØπÊé®ÈÄÅÂÜÖÂÆπËøõË°åÊ∑±Â∫¶ÂàÜÊûêÔºåËá™Âä®ÁîüÊàêÁÉ≠ÁÇπË∂ãÂäøÊ¶ÇËø∞„ÄÅÂÖ≥ÈîÆËØçÁÉ≠Â∫¶ÂàÜÊûê„ÄÅË∑®Âπ≥Âè∞ÂÖ≥ËÅî„ÄÅÊΩúÂú®ÂΩ±ÂìçËØÑ‰º∞Á≠â
- **ÊÉÖÊÑüÂÄæÂêëÂàÜÊûê**ÔºöÊñ∞Â¢ûÊ∑±Â∫¶ÊÉÖÊÑüËØÜÂà´ÔºåÁ≤æÂáÜÊçïÊçâËàÜËÆ∫ÁöÑÊ≠£Ë¥üÈù¢„ÄÅ‰∫âËÆÆÊàñÊãÖÂøßÊÉÖÁª™
- **Â§ö AI Êèê‰æõÂïÜÊîØÊåÅ**ÔºöÊîØÊåÅ DeepSeekÔºàÈªòËÆ§ÔºåÊÄß‰ª∑ÊØîÈ´òÔºâ„ÄÅOpenAI„ÄÅGoogle Gemini Âèä‰ªªÊÑè OpenAI ÂÖºÂÆπÊé•Âè£
- **‰∏§ÁßçÊé®ÈÄÅÊ®°Âºè**Ôºö`only_analysis`Ôºà‰ªÖ AI ÂàÜÊûêÔºâ„ÄÅ`both`Ôºà‰∏§ËÄÖÈÉΩÊé®ÈÄÅÔºâ
- **Ëá™ÂÆö‰πâÊèêÁ§∫ËØç**ÔºöÈÄöËøá `config/ai_analysis_prompt.txt` Êñá‰ª∂Ëá™ÂÆö‰πâ AI ÂàÜÊûêËßíËâ≤ÂíåËæìÂá∫Ê†ºÂºè
- **Â§öÁª¥Â∫¶Êï∞ÊçÆÂàÜÊûê**ÔºöAI ÂèØÂàÜÊûêÊéíÂêçÂèòÂåñ„ÄÅÁÉ≠Â∫¶ÊåÅÁª≠Êó∂Èó¥„ÄÅË∑®Âπ≥Âè∞Ë°®Áé∞„ÄÅË∂ãÂäøÈ¢ÑÊµãÁ≠â

**üìã Áã¨Á´ãÂ±ïÁ§∫Âå∫ÂäüËÉΩ**

- **ÂÆåÊï¥ÁÉ≠Ê¶úÂ±ïÁ§∫**ÔºöÊåáÂÆöÂπ≥Âè∞ÁöÑÂÆåÊï¥ÁÉ≠Ê¶úÂçïÁã¨Â±ïÁ§∫Ôºå‰∏çÂèóÂÖ≥ÈîÆËØçËøáÊª§ÂΩ±Âìç
- **RSS Áã¨Á´ãÂ±ïÁ§∫**ÔºöRSS Ê∫êÂÜÖÂÆπÂèØÂÆåÊï¥Â±ïÁ§∫ÔºåÈÄÇÂêàÂÜÖÂÆπËæÉÂ∞ëÁöÑËÆ¢ÈòÖÊ∫ê
- **ÁÅµÊ¥ªÈÖçÁΩÆ**ÔºöÊîØÊåÅÈÖçÁΩÆÂ±ïÁ§∫Âπ≥Âè∞ÂàóË°®„ÄÅRSS Ê∫êÂàóË°®„ÄÅÊúÄÂ§ßÂ±ïÁ§∫Êù°Êï∞

**üìä Êé®ÈÄÅ‰ΩìÈ™åÈáçÊûÑ**

- **ÊéíÁâàÂçáÁ∫ß**ÔºöÈáçÊñ∞ËÆæËÆ°Âπ∂Áªü‰∏ÄÂêÑÊ∏†ÈÅìÁªüËÆ°Â§¥ÈÉ®ÔºåÂº∫ÂåñÂå∫ÂùóÁªÑÁªáÔºåÊ∂àÊÅØÂ±ÇÊ¨°‰∏ÄÁõÆ‰∫ÜÁÑ∂
- **ÈÖçÁΩÆÁÆÄÂåñ**Ôºö‰ºòÂåñÈ£û‰π¶Á≠âÈÄöÁü•Ê∏†ÈÅìÁöÑÈÖçÁΩÆÈÄªËæëÔºå‰∏äÊâãÊõ¥ÁÆÄÂçï
- **ÁÉ≠Â∫¶Ë∂ãÂäøÁÆ≠Â§¥**ÔºöÊñ∞Â¢û üî∫(‰∏äÂçá)„ÄÅüîª(‰∏ãÈôç)„ÄÅ‚ûñ(ÊåÅÂπ≥) Ë∂ãÂäøÊ†áËØÜÔºåÁõ¥ËßÇÂ±ïÁ§∫ÁÉ≠Â∫¶ÂèòÂåñ
- **ÈÄöÁî® Webhook**ÔºöÊîØÊåÅËá™ÂÆö‰πâ Webhook URL Âíå JSON Ê®°ÊùøÔºåËΩªÊùæÈÄÇÈÖç Discord„ÄÅMatrix„ÄÅIFTTT Á≠â‰ªªÊÑèÂπ≥Âè∞

**üîß ÈÖçÁΩÆ‰ºòÂåñ**

- **È¢ëÁéáËØçÈÖçÁΩÆÂ¢ûÂº∫**ÔºöÊñ∞Â¢û `[ÁªÑÂà´Âêç]` ËØ≠Ê≥ïÔºåÊîØÊåÅ `#` Ê≥®ÈáäË°åÔºåÈÖçÁΩÆÊõ¥Ê∏ÖÊô∞ÔºàÊÑüË∞¢ [@songge8](https://github.com/sansan0/TrendRadar/issues/752) ÊèêÂá∫ÁöÑÂª∫ËÆÆÔºâ
- **ÁéØÂ¢ÉÂèòÈáèÊîØÊåÅ**ÔºöAI ÂàÜÊûêÁõ∏ÂÖ≥ÈÖçÁΩÆÊîØÊåÅÁéØÂ¢ÉÂèòÈáèË¶ÜÁõñÔºà`AI_API_KEY`„ÄÅ`AI_PROVIDER` Á≠âÔºâ

&gt; üí° ËØ¶ÁªÜÈÖçÁΩÆÊïôÁ®ãËßÅ [ËÆ© AI Â∏ÆÊàëÂàÜÊûêÁÉ≠ÁÇπ](#12-ËÆ©-ai-Â∏ÆÊàëÂàÜÊûêÁÉ≠ÁÇπ)


### 2026/01/02 - v4.7.0

- **‰øÆÂ§ç RSS HTML ÊòæÁ§∫**Ôºö‰øÆÂ§ç RSS Êï∞ÊçÆÊ†ºÂºè‰∏çÂåπÈÖçÂØºËá¥ÁöÑÊ∏≤ÊüìÈóÆÈ¢òÔºåÁé∞Âú®ÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑÊ≠£Á°ÆÊòæÁ§∫
- **Êñ∞Â¢ûÊ≠£ÂàôË°®ËææÂºèËØ≠Ê≥ï**ÔºöÂÖ≥ÈîÆËØçÈÖçÁΩÆÊîØÊåÅ `/pattern/` Ê≠£ÂàôËØ≠Ê≥ïÔºåËß£ÂÜ≥Ëã±ÊñáÂ≠êÂ≠óÁ¨¶‰∏≤ËØØÂåπÈÖçÈóÆÈ¢òÔºàÂ¶Ç `ai` ÂåπÈÖç `training`Ôºâ[üìñ Êü•ÁúãËØ≠Ê≥ïËØ¶Ëß£](#ÂÖ≥ÈîÆËØçÂü∫Á°ÄËØ≠Ê≥ï)
- **Êñ∞Â¢ûÊòæÁ§∫ÂêçÁß∞ËØ≠Ê≥ï**Ôºö‰ΩøÁî® `=&gt; Â§áÊ≥®` ÁªôÂ§çÊùÇÁöÑÊ≠£ÂàôË°®ËææÂºèËµ∑‰∏™Â•ΩËÆ∞ÁöÑÂêçÂ≠óÔºåÊé®ÈÄÅÊ∂àÊÅØÊòæÁ§∫Êõ¥Ê∏ÖÊô∞ÔºàÂ¶Ç `/\bai\b/ =&gt; AIÁõ∏ÂÖ≥`Ôºâ
- **‰∏ç‰ºöÂÜôÊ≠£ÂàôÔºü** README Êñ∞Â¢û AI ÁîüÊàêÊ≠£ÂàôÁöÑÂºïÂØºÔºåÂëäËØâ ChatGPT/Gemini/DeepSeek ‰Ω†ÊÉ≥ÂåπÈÖç‰ªÄ‰πàÔºåËÆ© AI Â∏Æ‰Ω†ÂÜô


### 2025/12/30 - mcp-v2.0.0

- **Êû∂ÊûÑË∞ÉÊï¥**ÔºöÁßªÈô§ TXT ÊîØÊåÅÔºåÁªü‰∏Ä‰ΩøÁî® SQLite Êï∞ÊçÆÂ∫ì
- **RSS Êü•ËØ¢**ÔºöÊñ∞Â¢û `get_latest_rss`„ÄÅ`search_rss`„ÄÅ`get_rss_feeds_status`
- **Áªü‰∏ÄÊêúÁ¥¢**Ôºö`search_news` ÊîØÊåÅ `include_rss` ÂèÇÊï∞ÂêåÊó∂ÊêúÁ¥¢ÁÉ≠Ê¶úÂíå RSS


### 2026/01/01 - v4.6.0

- **‰øÆÂ§ç RSS HTML ÊòæÁ§∫**ÔºöÂ∞Ü RSS ÂÜÖÂÆπÂêàÂπ∂Âà∞ÁÉ≠Ê¶ú HTML È°µÈù¢ÔºåÊåâÊ∫êÂàÜÁªÑÊòæÁ§∫
- **Êñ∞Â¢û display_mode ÈÖçÁΩÆ**ÔºöÊîØÊåÅ `keyword`ÔºàÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑÔºâÂíå `platform`ÔºàÊåâÂπ≥Âè∞ÂàÜÁªÑÔºâ‰∏§ÁßçÊòæÁ§∫Ê®°Âºè


### 2025/12/30 - v4.5.0

- **RSS ËÆ¢ÈòÖÊ∫êÊîØÊåÅ**ÔºöÊñ∞Â¢û RSS/Atom ÊäìÂèñÔºåÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑÁªüËÆ°Ôºà‰∏éÁÉ≠Ê¶úÊ†ºÂºè‰∏ÄËá¥Ôºâ
- **Â≠òÂÇ®ÁªìÊûÑÈáçÊûÑ**ÔºöÊâÅÂπ≥ÂåñÁõÆÂΩïÁªìÊûÑ `output/{type}/{date}.db`
- **Áªü‰∏ÄÊéíÂ∫èÈÖçÁΩÆ**Ôºö`sort_by_position_first` ÂêåÊó∂ÂΩ±ÂìçÁÉ≠Ê¶úÂíå RSS
- **ÈÖçÁΩÆÁªìÊûÑÈáçÊûÑ**Ôºö`config.yaml` ÈáçÊñ∞ÁªÑÁªá‰∏∫ 7 ‰∏™ÈÄªËæëÂàÜÁªÑÔºàapp„ÄÅreport„ÄÅnotification„ÄÅstorage„ÄÅplatforms„ÄÅrss„ÄÅadvancedÔºâÔºåÈÖçÁΩÆË∑ØÂæÑÊõ¥Ê∏ÖÊô∞


### 2025/12/26 - mcp-v1.2.0

  **MCP Ê®°ÂùóÊõ¥Êñ∞ - ‰ºòÂåñÂ∑•ÂÖ∑ÈõÜÔºåÊñ∞Â¢ûËÅöÂêàÂØπÊØîÂäüËÉΩÔºåÂêàÂπ∂ÂÜó‰ΩôÂ∑•ÂÖ∑:**
  - Êñ∞Â¢û `aggregate_news` Â∑•ÂÖ∑ - Ë∑®Âπ≥Âè∞Êñ∞ÈóªÂéªÈáçËÅöÂêà
  - Êñ∞Â¢û `compare_periods` Â∑•ÂÖ∑ - Êó∂ÊúüÂØπÊØîÂàÜÊûêÔºàÂë®ÁéØÊØî/ÊúàÁéØÊØîÔºâ
  - ÂêàÂπ∂ `find_similar_news` + `search_related_news_history` ‚Üí `find_related_news`
  - Â¢ûÂº∫ `get_trending_topics` - Êñ∞Â¢û `auto_extract` Ê®°ÂºèËá™Âä®ÊèêÂèñÁÉ≠ÁÇπ
  - ‰øÆÂ§çËã•Âπ≤bug
  - ÂêåÊ≠•Êõ¥Êñ∞ README-MCP-FAQ.md ÊñáÊ°£ÁöÑ‰∏≠Ëã±ÊñáÁâà (Q1-Q18)


### 2025/12/20 - v4.0.3

- Êñ∞Â¢û URL Ê†áÂáÜÂåñÂäüËÉΩÔºåËß£ÂÜ≥ÂæÆÂçöÁ≠âÂπ≥Âè∞Âõ†Âä®ÊÄÅÂèÇÊï∞ÔºàÂ¶Ç `band_rank`ÔºâÂØºËá¥ÁöÑÈáçÂ§çÊé®ÈÄÅÈóÆÈ¢ò
- ‰øÆÂ§çÂ¢ûÈáèÊ®°ÂºèÊ£ÄÊµãÈÄªËæëÔºåÊ≠£Á°ÆËØÜÂà´ÂéÜÂè≤Ê†áÈ¢ò


### 2025/12/17 - v4.0.1

- StorageManager Ê∑ªÂä†Êé®ÈÄÅËÆ∞ÂΩï‰ª£ÁêÜÊñπÊ≥ï
- S3 ÂÆ¢Êà∑Á´ØÂàáÊç¢Ëá≥ virtual-hosted style ‰ª•ÊèêÂçáÂÖºÂÆπÊÄßÔºàÊîØÊåÅËÖæËÆØ‰∫ë COS Á≠âÊõ¥Â§öÊúçÂä°Ôºâ


### 2025/12/13 - mcp-v1.1.0

  **MCP Ê®°ÂùóÊõ¥Êñ∞:**
  - ÈÄÇÈÖç v4.0.0ÔºåÂêåÊó∂‰πüÂÖºÂÆπ v3.x ÁöÑÊï∞ÊçÆ
  - Êñ∞Â¢ûÂ≠òÂÇ®ÂêåÊ≠•Â∑•ÂÖ∑Ôºö`sync_from_remote`„ÄÅ`get_storage_status`„ÄÅ`list_available_dates`


### 2025/12/13 - v4.0.0

**üéâ ÈáçÂ§ßÊõ¥Êñ∞ÔºöÂÖ®Èù¢ÈáçÊûÑÂ≠òÂÇ®ÂíåÊ†∏ÂøÉÊû∂ÊûÑ**

- **Â§öÂ≠òÂÇ®ÂêéÁ´ØÊîØÊåÅ**ÔºöÂºïÂÖ•ÂÖ®Êñ∞ÁöÑÂ≠òÂÇ®Ê®°ÂùóÔºåÊîØÊåÅÊú¨Âú∞ SQLite ÂíåËøúÁ®ã‰∫ëÂ≠òÂÇ®ÔºàS3 ÂÖºÂÆπÂçèËÆÆÔºå‰æãÂ¶Ç Cloudflare R2ÔºâÔºåÈÄÇÂ∫î GitHub Actions„ÄÅDocker ÂíåÊú¨Âú∞ÁéØÂ¢É„ÄÇ
- **Êï∞ÊçÆÂ∫ìÁªìÊûÑ‰ºòÂåñ**ÔºöÈáçÊûÑ SQLite Êï∞ÊçÆÂ∫ìË°®ÁªìÊûÑÔºåÊèêÂçáÊï∞ÊçÆÊïàÁéáÂíåÊü•ËØ¢ËÉΩÂäõ„ÄÇ
- **Ê†∏ÂøÉ‰ª£Á†ÅÊ®°ÂùóÂåñ**ÔºöÂ∞Ü‰∏ªÁ®ãÂ∫èÈÄªËæëÊãÜÂàÜ‰∏∫ trendradar ÂåÖÁöÑÂ§ö‰∏™Ê®°ÂùóÔºåÊòæËëóÊèêÂçá‰ª£Á†ÅÂèØÁª¥Êä§ÊÄß„ÄÇ
- **Â¢ûÂº∫ÂäüËÉΩ**ÔºöÂÆûÁé∞Êó•ÊúüÊ†ºÂºèÊ†áÂáÜÂåñ„ÄÅÊï∞ÊçÆ‰øùÁïôÁ≠ñÁï•„ÄÅÊó∂Âå∫ÈÖçÁΩÆÊîØÊåÅ„ÄÅÊó∂Èó¥ÊòæÁ§∫‰ºòÂåñÔºåÂπ∂‰øÆÂ§çËøúÁ®ãÂ≠òÂÇ®Êï∞ÊçÆÊåÅ‰πÖÂåñÈóÆÈ¢òÔºåÁ°Æ‰øùÊï∞ÊçÆÂêàÂπ∂ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ
- **Ê∏ÖÁêÜÂíåÂÖºÂÆπ**ÔºöÁßªÈô§‰∫ÜÂ§ßÈÉ®ÂàÜÂéÜÂè≤ÂÖºÂÆπ‰ª£Á†ÅÔºåÁªü‰∏Ä‰∫ÜÊï∞ÊçÆÂ≠òÂÇ®ÂíåËØªÂèñÊñπÂºè„ÄÇ


### 2025/12/03 - v3.5.0

**üéâ Ê†∏ÂøÉÂäüËÉΩÂ¢ûÂº∫**

1. **Â§öË¥¶Âè∑Êé®ÈÄÅÊîØÊåÅ**
   - ÊâÄÊúâÊé®ÈÄÅÊ∏†ÈÅìÔºàÈ£û‰π¶„ÄÅÈíâÈíâ„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°„ÄÅTelegram„ÄÅntfy„ÄÅBark„ÄÅSlackÔºâÊîØÊåÅÂ§öË¥¶Âè∑ÈÖçÁΩÆ
   - ‰ΩøÁî®ÂàÜÂè∑ `;` ÂàÜÈöîÂ§ö‰∏™Ë¥¶Âè∑Ôºå‰æãÂ¶ÇÔºö`FEISHU_WEBHOOK_URL=url1;url2`
   - Ëá™Âä®È™åËØÅÈÖçÂØπÈÖçÁΩÆÔºàÂ¶Ç Telegram ÁöÑ token Âíå chat_idÔºâÊï∞Èáè‰∏ÄËá¥ÊÄß

2. **Êé®ÈÄÅÂå∫ÂüüÈÖçÁΩÆ**
   - ÈÄöËøá `display.region_order` Ëá™ÂÆö‰πâÂêÑÂå∫ÂüüÁöÑÊòæÁ§∫È°∫Â∫èÔºàv5.2.0 Êõø‰ª£Âéü `reverse_content_order`Ôºâ
   - ÈÄöËøá `display.regions` ÊéßÂà∂ÂêÑÂå∫ÂüüÊòØÂê¶ÊòæÁ§∫ÔºàÁÉ≠Ê¶ú„ÄÅÊñ∞Â¢ûÁÉ≠ÁÇπ„ÄÅRSS„ÄÅÁã¨Á´ãÂ±ïÁ§∫Âå∫„ÄÅAI ÂàÜÊûêÔºâ

3. **ÂÖ®Â±ÄËøáÊª§ÂÖ≥ÈîÆËØç**
   - Êñ∞Â¢û `[GLOBAL_FILTER]` Âå∫ÂüüÊ†áËÆ∞ÔºåÊîØÊåÅÂÖ®Â±ÄËøáÊª§‰∏çÊÉ≥ÁúãÂà∞ÁöÑÂÜÖÂÆπ
   - ÈÄÇÁî®Âú∫ÊôØÔºöËøáÊª§ÂπøÂëä„ÄÅËê•ÈîÄ„ÄÅ‰ΩéË¥®ÂÜÖÂÆπÁ≠â

**üê≥ Docker ÂèåË∑ØÂæÑ HTML ÁîüÊàê‰ºòÂåñ**

- **ÈóÆÈ¢ò‰øÆÂ§ç**ÔºöËß£ÂÜ≥ Docker ÁéØÂ¢É‰∏ã `index.html` Êó†Ê≥ïÂêåÊ≠•Âà∞ÂÆø‰∏ªÊú∫ÁöÑÈóÆÈ¢ò
- **ÂèåË∑ØÂæÑÁîüÊàê**ÔºöÂΩìÊó•Ê±áÊÄª HTML ÂêåÊó∂ÁîüÊàêÂà∞‰∏§‰∏™‰ΩçÁΩÆ
  - `index.html`ÔºàÈ°πÁõÆÊ†πÁõÆÂΩïÔºâÔºö‰æõ GitHub Pages ËÆøÈóÆ
  - `output/index.html`ÔºöÈÄöËøá Docker Volume ÊåÇËΩΩÔºåÂÆø‰∏ªÊú∫ÂèØÁõ¥Êé•ËÆøÈóÆ
- **ÂÖºÂÆπÊÄß**ÔºöÁ°Æ‰øù Docker„ÄÅGitHub Actions„ÄÅÊú¨Âú∞ËøêË°åÁéØÂ¢ÉÂùáËÉΩÊ≠£Â∏∏ËÆøÈóÆÁΩëÈ°µÁâàÊä•Âëä

**üê≥ Docker MCP ÈïúÂÉèÊîØÊåÅ**

- Êñ∞Â¢ûÁã¨Á´ãÁöÑ MCP ÊúçÂä°ÈïúÂÉè `wantcat/trendradar-mcp`
- ÊîØÊåÅ Docker ÈÉ®ÁΩ≤ AI ÂàÜÊûêÂäüËÉΩÔºåÈÄöËøá HTTP Êé•Âè£ÔºàÁ´ØÂè£ 3333ÔºâÊèê‰æõÊúçÂä°
- ÂèåÂÆπÂô®Êû∂ÊûÑÔºöÊñ∞ÈóªÊé®ÈÄÅÊúçÂä°‰∏é MCP ÊúçÂä°Áã¨Á´ãËøêË°åÔºåÂèØÂàÜÂà´Êâ©Â±ïÂíåÈáçÂêØ
- ËØ¶ËßÅ [Docker ÈÉ®ÁΩ≤ - MCP ÊúçÂä°](#6-docker-ÈÉ®ÁΩ≤)

**üåê Web ÊúçÂä°Âô®ÊîØÊåÅ**

- Êñ∞Â¢ûÂÜÖÁΩÆ Web ÊúçÂä°Âô®ÔºåÊîØÊåÅÈÄöËøáÊµèËßàÂô®ËÆøÈóÆÁîüÊàêÁöÑÊä•Âëä
- ÈÄöËøá `manage.py` ÂëΩ‰ª§ÊéßÂà∂ÂêØÂä®/ÂÅúÊ≠¢Ôºö`docker exec -it trendradar python manage.py start_webserver`
- ËÆøÈóÆÂú∞ÂùÄÔºö`http://localhost:8080`ÔºàÁ´ØÂè£ÂèØÈÖçÁΩÆÔºâ
- ÂÆâÂÖ®ÁâπÊÄßÔºöÈùôÊÄÅÊñá‰ª∂ÊúçÂä°„ÄÅÁõÆÂΩïÈôêÂà∂„ÄÅÊú¨Âú∞ËÆøÈóÆ
- ÊîØÊåÅËá™Âä®ÂêØÂä®ÂíåÊâãÂä®ÊéßÂà∂‰∏§ÁßçÊ®°Âºè

**üìñ ÊñáÊ°£‰ºòÂåñ**

- Êñ∞Â¢û [Êé®ÈÄÅÂÜÖÂÆπÊÄé‰πàÊòæÁ§∫Ôºü](#7-Êé®ÈÄÅÂÜÖÂÆπÊÄé‰πàÊòæÁ§∫) Á´†ËäÇÔºöËá™ÂÆö‰πâÊé®ÈÄÅÊ†∑ÂºèÂíåÂÜÖÂÆπ
- Êñ∞Â¢û [‰ªÄ‰πàÊó∂ÂÄôÁªôÊàëÊé®ÈÄÅÔºü](#8-‰ªÄ‰πàÊó∂ÂÄôÁªôÊàëÊé®ÈÄÅ) Á´†ËäÇÔºöËÆæÁΩÆÊé®ÈÄÅÊó∂Èó¥ÊÆµ
- Êñ∞Â¢û [Â§ö‰πÖËøêË°å‰∏ÄÊ¨°Ôºü](#9-Â§ö‰πÖËøêË°å‰∏ÄÊ¨°) Á´†ËäÇÔºöËÆæÁΩÆËá™Âä®ËøêË°åÈ¢ëÁéá
- Êñ∞Â¢û [Êé®ÈÄÅÂà∞Â§ö‰∏™Áæ§/ËÆæÂ§á](#10-Êé®ÈÄÅÂà∞Â§ö‰∏™Áæ§ËÆæÂ§á) Á´†ËäÇÔºöÂêåÊó∂Êé®ÈÄÅÁªôÂ§ö‰∏™Êé•Êî∂ËÄÖ
- ‰ºòÂåñÂêÑÈÖçÁΩÆÁ´†ËäÇÔºöÁªü‰∏ÄÊ∑ªÂä†&quot;ÈÖçÁΩÆ‰ΩçÁΩÆ&quot;ËØ¥Êòé
- ÁÆÄÂåñÂø´ÈÄüÂºÄÂßãÈÖçÁΩÆËØ¥ÊòéÔºö‰∏â‰∏™Ê†∏ÂøÉÊñá‰ª∂‰∏ÄÁõÆ‰∫ÜÁÑ∂
- ‰ºòÂåñ [Docker ÈÉ®ÁΩ≤](#6-docker-ÈÉ®ÁΩ≤) Á´†ËäÇÔºöÊñ∞Â¢ûÈïúÂÉèËØ¥Êòé„ÄÅÊé®Ëçê git clone ÈÉ®ÁΩ≤„ÄÅÈáçÁªÑÈÉ®ÁΩ≤ÊñπÂºè

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`„ÄÅ`config/config.yaml`ÔºàÊñ∞Â¢ûÂ§öË¥¶Âè∑Êé®ÈÄÅÊîØÊåÅÔºåÊó†ÈúÄ‰øÆÊîπÁé∞ÊúâÈÖçÁΩÆÔºâ
- **Â§öË¥¶Âè∑Êé®ÈÄÅ**ÔºöÊñ∞ÂäüËÉΩÔºåÈªòËÆ§‰∏çÂêØÁî®ÔºåÁé∞ÊúâÂçïË¥¶Âè∑ÈÖçÁΩÆ‰∏çÂèóÂΩ±Âìç


### 2025/11/26 - mcp-v1.0.3

  **MCP Ê®°ÂùóÊõ¥Êñ∞:**
  - Êñ∞Â¢ûÊó•ÊúüËß£ÊûêÂ∑•ÂÖ∑ resolve_date_range,Ëß£ÂÜ≥ AI Ê®°ÂûãËÆ°ÁÆóÊó•Êúü‰∏ç‰∏ÄËá¥ÁöÑÈóÆÈ¢ò
  - ÊîØÊåÅËá™ÁÑ∂ËØ≠Ë®ÄÊó•ÊúüË°®ËææÂºèËß£Êûê(Êú¨Âë®„ÄÅÊúÄËøë7Â§©„ÄÅ‰∏äÊúàÁ≠â)
  - Â∑•ÂÖ∑ÊÄªÊï∞‰ªé 13 ‰∏™Â¢ûÂä†Âà∞ 14 ‰∏™


### 2025/11/28 - v3.4.1

**üîß Ê†ºÂºè‰ºòÂåñ**

1. **Bark Êé®ÈÄÅÂ¢ûÂº∫**
   - Bark Áé∞ÊîØÊåÅ Markdown Ê∏≤Êüì
   - ÂêØÁî®ÂéüÁîü Markdown Ê†ºÂºèÔºöÁ≤ó‰Ωì„ÄÅÈìæÊé•„ÄÅÂàóË°®„ÄÅ‰ª£Á†ÅÂùóÁ≠â
   - ÁßªÈô§Á∫ØÊñáÊú¨ËΩ¨Êç¢ÔºåÂÖÖÂàÜÂà©Áî® Bark ÂéüÁîüÊ∏≤ÊüìËÉΩÂäõ

2. **Slack Ê†ºÂºèÁ≤æÂáÜÂåñ**
   - ‰ΩøÁî®‰∏ìÁî® mrkdwn Ê†ºÂºèÂ§ÑÁêÜÂàÜÊâπÂÜÖÂÆπ
   - ÊèêÂçáÂ≠óËäÇÂ§ßÂ∞è‰º∞ÁÆóÂáÜÁ°ÆÊÄßÔºàÈÅøÂÖçÊ∂àÊÅØË∂ÖÈôêÔºâ
   - ‰ºòÂåñÈìæÊé•Ê†ºÂºèÔºö`&lt;url|text&gt;` ÂíåÂä†Á≤óËØ≠Ê≥ïÔºö`*text*`

3. **ÊÄßËÉΩÊèêÂçá**
   - Ê†ºÂºèËΩ¨Êç¢Âú®ÂàÜÊâπËøáÁ®ã‰∏≠ÂÆåÊàêÔºåÈÅøÂÖç‰∫åÊ¨°Â§ÑÁêÜ
   - ÂáÜÁ°Æ‰º∞ÁÆóÊ∂àÊÅØÂ§ßÂ∞èÔºåÂáèÂ∞ëÂèëÈÄÅÂ§±Ë¥•Áéá

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`Ôºå`config.yaml`


### 2025/11/25 - v3.4.0

**üéâ Êñ∞Â¢û Slack Êé®ÈÄÅÊîØÊåÅ**

1. **Âõ¢ÈòüÂçè‰ΩúÊé®ÈÄÅÊ∏†ÈÅì**
   - ÊîØÊåÅ Slack Incoming WebhooksÔºàÂÖ®ÁêÉÊµÅË°åÁöÑÂõ¢ÈòüÂçè‰ΩúÂ∑•ÂÖ∑Ôºâ
   - Ê∂àÊÅØÈõÜ‰∏≠ÁÆ°ÁêÜÔºåÈÄÇÂêàÂõ¢ÈòüÂÖ±‰∫´ÁÉ≠ÁÇπËµÑËÆØ
   - ÊîØÊåÅ mrkdwn Ê†ºÂºèÔºàÁ≤ó‰Ωì„ÄÅÈìæÊé•Á≠âÔºâ

2. **Â§öÁßçÈÉ®ÁΩ≤ÊñπÂºè**
   - GitHub ActionsÔºöÈÖçÁΩÆ `SLACK_WEBHOOK_URL` Secret
   - DockerÔºöÁéØÂ¢ÉÂèòÈáè `SLACK_WEBHOOK_URL`
   - Êú¨Âú∞ËøêË°åÔºö`config/config.yaml` ÈÖçÁΩÆÊñá‰ª∂


&gt; üìñ **ËØ¶ÁªÜÈÖçÁΩÆÊïôÁ®ã**Ôºö[Âø´ÈÄüÂºÄÂßã - Slack Êé®ÈÄÅ](#-Âø´ÈÄüÂºÄÂßã)

- ‰ºòÂåñ setup-windows.bat Âíå setup-windows-en.bat ‰∏ÄÈîÆÂÆâË£Ö MCP ÁöÑ‰ΩìÈ™å

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`„ÄÅ`config/config.yaml`„ÄÅ`.github/workflows/crawler.yml`


### 2025/11/24 - v3.3.0

**üéâ Êñ∞Â¢û B

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Netflix/metaflow]]></title>
            <link>https://github.com/Netflix/metaflow</link>
            <guid>https://github.com/Netflix/metaflow</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:16 GMT</pubDate>
            <description><![CDATA[Build, Manage and Deploy AI/ML Systems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Netflix/metaflow">Netflix/metaflow</a></h1>
            <p>Build, Manage and Deploy AI/ML Systems</p>
            <p>Language: Python</p>
            <p>Stars: 9,824</p>
            <p>Forks: 1,050</p>
            <p>Stars today: 21 stars today</p>
            <h2>README</h2><pre>![Metaflow_Logo_Horizontal_FullColor_Ribbon_Dark_RGB](https://user-images.githubusercontent.com/763451/89453116-96a57e00-d713-11ea-9fa6-82b29d4d6eff.png)

# Metaflow

[Metaflow](https://metaflow.org) is a human-centric framework designed to help scientists and engineers **build and manage real-life AI and ML systems**. Serving teams of all sizes and scale, Metaflow streamlines the entire development lifecycle‚Äîfrom rapid prototyping in notebooks to reliable, maintainable production deployments‚Äîenabling teams to iterate quickly and deliver robust systems efficiently.

Originally developed at [Netflix](https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9) and now supported by [Outerbounds](https://outerbounds.com), Metaflow is designed to boost the productivity for research and engineering teams working on [a wide variety of projects](https://netflixtechblog.com/supporting-diverse-ml-systems-at-netflix-2d2e6b6d205d), from classical statistics to state-of-the-art deep learning and foundation models. By unifying code, data, and compute at every stage, Metaflow ensures seamless, end-to-end management of real-world AI and ML systems.

Today, Metaflow powers thousands of AI and ML experiences across a diverse array of companies, large and small, including Amazon, Doordash, Dyson, Goldman Sachs, Ramp, and [many others](ADOPTERS.md). At Netflix alone, Metaflow supports over 3000 AI and ML projects, executes hundreds of millions of data-intensive high-performance compute jobs processing petabytes of data and manages tens of petabytes of models and artifacts for hundreds of users across its AI, ML, data science, and engineering teams.

## From prototype to production (and back)

Metaflow provides a simple and friendly pythonic [API](https://docs.metaflow.org) that covers foundational needs of AI and ML systems:
&lt;img src=&quot;./docs/prototype-to-prod.png&quot; width=&quot;800px&quot;&gt;

1. [Rapid local prototyping](https://docs.metaflow.org/metaflow/basics), [support for notebooks](https://docs.metaflow.org/metaflow/managing-flows/notebook-runs), and built-in support for [experiment tracking, versioning](https://docs.metaflow.org/metaflow/client) and [visualization](https://docs.metaflow.org/metaflow/visualizing-results).
2. [Effortlessly scale horizontally and vertically in your cloud](https://docs.metaflow.org/scaling/remote-tasks/introduction), utilizing both CPUs and GPUs, with [fast data access](https://docs.metaflow.org/scaling/data) for running [massive embarrassingly parallel](https://docs.metaflow.org/metaflow/basics#foreach) as well as [gang-scheduled](https://docs.metaflow.org/scaling/remote-tasks/distributed-computing) compute workloads [reliably](https://docs.metaflow.org/scaling/failures) and [efficiently](https://docs.metaflow.org/scaling/checkpoint/introduction).
3. [Easily manage dependencies](https://docs.metaflow.org/scaling/dependencies) and [deploy with one-click](https://docs.metaflow.org/production/introduction) to highly available production orchestrators with built in support for [reactive orchestration](https://docs.metaflow.org/production/event-triggering).

For full documentation, check out our [API Reference](https://docs.metaflow.org/api) or see our [Release Notes](https://github.com/Netflix/metaflow/releases) for the latest features and improvements. 


## Getting started

Getting up and running is easy. If you don&#039;t know where to start, [Metaflow sandbox](https://outerbounds.com/sandbox) will have you running and exploring in seconds.

### Installing Metaflow

To install Metaflow in your Python environment from [PyPI](https://pypi.org/project/metaflow/):

```sh
pip install metaflow
```
Alternatively, using [conda-forge](https://anaconda.org/conda-forge/metaflow):

```sh
conda install -c conda-forge metaflow
```

Once installed, a great way to get started is by following our [tutorial](https://docs.metaflow.org/getting-started/tutorials). It walks you through creating and running your first Metaflow flow step by step.  

For more details on Metaflow‚Äôs features and best practices, check out:
- [How Metaflow works](https://docs.metaflow.org/metaflow/basics)  
- [Additional resources](https://docs.metaflow.org/introduction/metaflow-resources)  

If you need help, don‚Äôt hesitate to reach out on our [Slack community](http://slack.outerbounds.co/)!


### Deploying infrastructure for Metaflow in your cloud
&lt;img src=&quot;./docs/multicloud.png&quot; width=&quot;800px&quot;&gt;


While you can get started with Metaflow easily on your laptop, the main benefits of Metaflow lie in its ability to [scale out to external compute clusters](https://docs.metaflow.org/scaling/remote-tasks/introduction) 
and to [deploy to production-grade workflow orchestrators](https://docs.metaflow.org/production/introduction). To benefit from these features, follow this [guide](https://outerbounds.com/engineering/welcome/) to 
configure Metaflow and the infrastructure behind it appropriately.


## Get in touch
We&#039;d love to hear from you. Join our community [Slack workspace](http://slack.outerbounds.co/)!

## Contributing
We welcome contributions to Metaflow. Please see our [contribution guide](https://docs.metaflow.org/introduction/contributing-to-metaflow) for more details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[inventree/InvenTree]]></title>
            <link>https://github.com/inventree/InvenTree</link>
            <guid>https://github.com/inventree/InvenTree</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:15 GMT</pubDate>
            <description><![CDATA[Open Source Inventory Management System]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/inventree/InvenTree">inventree/InvenTree</a></h1>
            <p>Open Source Inventory Management System</p>
            <p>Language: Python</p>
            <p>Stars: 6,376</p>
            <p>Forks: 1,245</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/images/logo/inventree.png&quot; alt=&quot;InvenTree logo&quot; width=&quot;200&quot; height=&quot;auto&quot; /&gt;
  &lt;h1&gt;InvenTree&lt;/h1&gt;
  &lt;p&gt;Open Source Inventory Management System &lt;/p&gt;

&lt;!-- Badges --&gt;
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/license/MIT)![GitHub tag (latest SemVer)](https://img.shields.io/github/v/tag/inventree/inventree)[![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/inventree)](https://artifacthub.io/packages/search?repo=inventree)
![CI](https://github.com/inventree/inventree/actions/workflows/qc_checks.yaml/badge.svg)
[![Documentation Status](https://readthedocs.org/projects/inventree/badge/?version=latest)](https://inventree.readthedocs.io/en/latest/?badge=latest)
![Docker Build](https://github.com/inventree/inventree/actions/workflows/docker.yaml/badge.svg)
[![Netlify Status](https://api.netlify.com/api/v1/badges/9bbb2101-0a4d-41e7-ad56-b63fb6053094/deploy-status)](https://app.netlify.com/sites/inventree/deploys)
[![Performance Testing](https://dev.azure.com/InvenTree/InvenTree%20test%20statistics/_apis/build/status%2Fmatmair.InvenTree?branchName=testing)](https://dev.azure.com/InvenTree/InvenTree%20test%20statistics/_build/latest?definitionId=3&amp;branchName=testing)

[![OpenSSF Best Practices](https://bestpractices.coreinfrastructure.org/projects/7179/badge)](https://bestpractices.coreinfrastructure.org/projects/7179)
[![OpenSSF Scorecard](https://api.securityscorecards.dev/projects/github.com/inventree/InvenTree/badge)](https://securityscorecards.dev/viewer/?uri=github.com/inventree/InvenTree)
[![Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=inventree_InvenTree&amp;metric=sqale_rating)](https://sonarcloud.io/summary/new_code?id=inventree_InvenTree)

[![codecov](https://codecov.io/gh/inventree/InvenTree/graph/badge.svg?token=9DZRGUUV7B)](https://codecov.io/gh/inventree/InvenTree)
[![Crowdin](https://badges.crowdin.net/inventree/localized.svg)](https://crowdin.com/project/inventree)
![GitHub commit activity](https://img.shields.io/github/commit-activity/m/inventree/inventree)
[![Docker Pulls](https://img.shields.io/docker/pulls/inventree/inventree)](https://hub.docker.com/r/inventree/inventree)

[![GitHub Org&#039;s stars](https://img.shields.io/github/stars/inventree?style=social)](https://github.com/inventree/InvenTree/)
[![Twitter Follow](https://img.shields.io/twitter/follow/inventreedb?style=social)](https://twitter.com/inventreedb)
[![Subreddit subscribers](https://img.shields.io/reddit/subreddit-subscribers/inventree?style=social)](https://www.reddit.com/r/InvenTree/)
[![Mastdon](https://img.shields.io/badge/dynamic/json?label=Mastodon&amp;query=followers_count&amp;url=https%3A%2F%2Fchaos.social%2Fapi%2Fv1%2Faccounts%2Flookup%3Facct=InvenTree&amp;logo=mastodon&amp;style=social)](https://chaos.social/@InvenTree)

&lt;h4&gt;
    &lt;a href=&quot;https://demo.inventree.org/&quot;&gt;View Demo&lt;/a&gt;
  &lt;span&gt; ¬∑ &lt;/span&gt;
    &lt;a href=&quot;https://docs.inventree.org/en/latest/&quot;&gt;Documentation&lt;/a&gt;
  &lt;span&gt; ¬∑ &lt;/span&gt;
    &lt;a href=&quot;https://github.com/inventree/InvenTree/issues/new?template=bug_report.md&amp;title=[BUG]&quot;&gt;Report Bug&lt;/a&gt;
  &lt;span&gt; ¬∑ &lt;/span&gt;
    &lt;a href=&quot;https://github.com/inventree/InvenTree/issues/new?template=feature_request.md&amp;title=[FR]&quot;&gt;Request Feature&lt;/a&gt;
  &lt;/h4&gt;
&lt;/div&gt;

&lt;!-- About the Project --&gt;
## :star2: About the Project

InvenTree is an open-source Inventory Management System which provides powerful low-level stock control and part tracking. The core of the InvenTree system is a Python/Django database backend which provides an admin interface (web-based) and a REST API for interaction with external interfaces and applications. A powerful plugin system provides support for custom applications and extensions.

Check out [our website](https://inventree.org) for more details.

&lt;!-- Roadmap --&gt;
### :compass: Roadmap

Want to see what we are working on? Check out the [roadmap tag](https://github.com/inventree/InvenTree/issues?q=is%3Aopen+is%3Aissue+label%3Aroadmap) and [horizon milestone](https://github.com/inventree/InvenTree/milestone/42).

&lt;!-- Integration --&gt;
### :hammer_and_wrench: Integration

InvenTree is designed to be **extensible**, and provides multiple options for **integration** with external applications or addition of custom plugins:

* [InvenTree API](https://docs.inventree.org/en/latest/api/)
* [Python module](https://docs.inventree.org/en/latest/api/python/)
* [Plugin interface](https://docs.inventree.org/en/latest/plugins/)
* [Third party tools](https://inventree.org/extend/integrate/)

&lt;!-- TechStack --&gt;
### :space_invader: Tech Stack

&lt;details&gt;
  &lt;summary&gt;Server&lt;/summary&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;https://www.python.org/&quot;&gt;Python&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://www.djangoproject.com/&quot;&gt;Django&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://www.django-rest-framework.org/&quot;&gt;DRF&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://django-q.readthedocs.io/&quot;&gt;Django Q&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://docs.allauth.org/&quot;&gt;Django-Allauth&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;Database&lt;/summary&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;https://www.postgresql.org/&quot;&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://www.mysql.com/&quot;&gt;MySQL&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://www.sqlite.org/&quot;&gt;SQLite&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://redis.io/&quot;&gt;Redis&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/details&gt;

&lt;details&gt;
  &lt;summary&gt;Client&lt;/summary&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;https://react.dev/&quot;&gt;React&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://lingui.dev/&quot;&gt;Lingui&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://reactrouter.com/&quot;&gt;React Router&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://tanstack.com/query/&quot;&gt;TanStack Query&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://github.com/pmndrs/zustand&quot;&gt;Zustand&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://mantine.dev/&quot;&gt;Mantine&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://icflorescu.github.io/mantine-datatable/&quot;&gt;Mantine Data Table&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://codemirror.net/&quot;&gt;CodeMirror&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;DevOps&lt;/summary&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href=&quot;https://hub.docker.com/r/inventree/inventree&quot;&gt;Docker&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://crowdin.com/project/inventree&quot;&gt;Crowdin&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://app.codecov.io/gh/inventree/InvenTree&quot;&gt;Codecov&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://sonarcloud.io/project/overview?id=inventree_InvenTree&quot;&gt;SonarCloud&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;https://packager.io/gh/inventree/InvenTree&quot;&gt;Packager.io&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/details&gt;

&lt;!-- Getting Started --&gt;
## 	:toolbox: Deployment / Getting Started

There are several options to deploy InvenTree.

&lt;div align=&quot;center&quot;&gt;&lt;h4&gt;
    &lt;a href=&quot;https://docs.inventree.org/en/latest/start/docker/&quot;&gt;Docker&lt;/a&gt;
    &lt;span&gt; ¬∑ &lt;/span&gt;
    &lt;a href=&quot;https://inventree.org/digitalocean&quot;&gt;&lt;img src=&quot;https://www.deploytodo.com/do-btn-blue-ghost.svg&quot; alt=&quot;Deploy to DO&quot; width=&quot;auto&quot; height=&quot;40&quot; /&gt;&lt;/a&gt;
    &lt;span&gt; ¬∑ &lt;/span&gt;
    &lt;a href=&quot;https://docs.inventree.org/en/latest/start/install/&quot;&gt;Bare Metal&lt;/a&gt;
&lt;/h4&gt;&lt;/div&gt;

Single line install - read [the docs](https://docs.inventree.org/en/latest/start/installer/) for supported distros and details about the function:
```bash
wget -qO install.sh https://get.inventree.org &amp;&amp; bash install.sh
```

Refer to the [getting started guide](https://docs.inventree.org/en/latest/start/install/) for a full set of installation and setup instructions.

&lt;!-- Mobile App --&gt;
## 	:iphone: Mobile App

InvenTree is supported by a [companion mobile app](https://docs.inventree.org/en/latest/app/) which allows users access to stock control information and functionality.

&lt;div align=&quot;center&quot;&gt;&lt;h4&gt;
    &lt;a href=&quot;https://play.google.com/store/apps/details?id=inventree.inventree_app&quot;&gt;Android Play Store&lt;/a&gt;
     &lt;span&gt; ¬∑ &lt;/span&gt;
    &lt;a href=&quot;https://apps.apple.com/au/app/inventree/id1581731101#?platform=iphone&quot;&gt;Apple App Store&lt;/a&gt;
&lt;/h4&gt;&lt;/div&gt;

&lt;!-- Security --&gt;
## :lock: Code of Conduct &amp; Security Policy

The InvenTree project team is committed to providing a safe and welcoming environment for all users. Please read our [Code of Conduct](CODE_OF_CONDUCT.md) for more information.

InvenTree is following industry best practices for security. Our security policy is included [in this repo](SECURITY.md). We provide dedicated security pages on [our documentation site](https://docs.inventree.org/en/latest/security/).

&lt;!-- Contributing --&gt;
## :wave: Contributing

Contributions are welcomed and encouraged. Please help to make this project even better! Refer to the [contribution page](https://docs.inventree.org/en/latest/develop/contributing/).

&lt;!-- Translation --&gt;
## :scroll: Translation

Native language translation of the InvenTree web application is [community contributed via crowdin](https://crowdin.com/project/inventree). **Contributions are welcomed and encouraged**.

&lt;!-- Sponsor --&gt;
## :money_with_wings: Sponsor

If you use InvenTree and find it to be useful, please consider [sponsoring the project](https://github.com/sponsors/inventree).

&lt;!-- Acknowledgments --&gt;
## :gem: Acknowledgements

We want to acknowledge [PartKeepr](https://github.com/partkeepr/PartKeepr) as a valuable predecessor and inspiration.
Find a full list of used third-party libraries in the license information dialog of your instance.

## :heart: Support

&lt;p&gt;This project is supported by the following sponsors:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/MartinLoeper&quot;&gt;&lt;img src=&quot;https://github.com/MartinLoeper.png&quot; width=&quot;60px&quot; alt=&quot;Martin L√∂per&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/lippoliv&quot;&gt;&lt;img src=&quot;https://github.com/lippoliv.png&quot; width=&quot;60px&quot; alt=&quot;Oliver Lippert&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/lfg-seth&quot;&gt;&lt;img src=&quot;https://github.com/lfg-seth.png&quot; width=&quot;60px&quot; alt=&quot;Seth Smith&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/snorkrat&quot;&gt;&lt;img src=&quot;https://github.com/snorkrat.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/spacequest-ltd&quot;&gt;&lt;img src=&quot;https://github.com/spacequest-ltd.png&quot; width=&quot;60px&quot; alt=&quot;SpaceQuest Ltd&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/appwrite&quot;&gt;&lt;img src=&quot;https://github.com/appwrite.png&quot; width=&quot;60px&quot; alt=&quot;Appwrite&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/PricelessToolkit&quot;&gt;&lt;img src=&quot;https://github.com/PricelessToolkit.png&quot; width=&quot;60px&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/cabottech&quot;&gt;&lt;img src=&quot;https://github.com/cabottech.png&quot; width=&quot;60px&quot; alt=&quot;Cabot Technologies&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/markus-k&quot;&gt;&lt;img src=&quot;https://github.com/markus-k.png&quot; width=&quot;60px&quot; alt=&quot;Markus Kasten&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/jefffhaynes&quot;&gt;&lt;img src=&quot;https://github.com/jefffhaynes.png&quot; width=&quot;60px&quot; alt=&quot;Jeff Haynes&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/dnviti&quot;&gt;&lt;img src=&quot;https://github.com/dnviti.png&quot; width=&quot;60px&quot; alt=&quot;Daniele Viti&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Islendur&quot;&gt;&lt;img src=&quot;https://github.com/Islendur.png&quot; width=&quot;60px&quot; alt=&quot;Islendur&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Gibeon-NL&quot;&gt;&lt;img src=&quot;https://github.com/Gibeon-NL.png&quot; width=&quot;60px&quot; alt=&quot;Gibeon-NL&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Motrac-Research-Engineering&quot;&gt;&lt;img src=&quot;https://github.com/Motrac-Research-Engineering.png&quot; width=&quot;60px&quot; alt=&quot;Motrac Research&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/trytuna&quot;&gt;&lt;img src=&quot;https://github.com/trytuna.png&quot; width=&quot;60px&quot; alt=&quot;Timo Scrappe&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/ATLAS2246&quot;&gt;&lt;img src=&quot;https://github.com/ATLAS2246.png&quot; width=&quot;60px&quot; alt=&quot;ATLAS2246&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/Kedarius&quot;&gt;&lt;img src=&quot;https://github.com/Kedarius.png&quot; width=&quot;60px&quot; alt=&quot;Radek Hladik&quot; /&gt;&lt;/a&gt;

&lt;/p&gt;

&lt;p&gt;With ongoing resources provided by:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://depot.dev?utm_source=inventree&quot;&gt;&lt;img src=&quot;https://depot.dev/badges/built-with-depot.svg&quot; alt=&quot;Built with Depot&quot; /&gt;&lt;/a&gt;
  &lt;a href=&quot;https://inventree.org/digitalocean&quot;&gt;
    &lt;img src=&quot;https://opensource.nyc3.cdn.digitaloceanspaces.com/attribution/assets/SVG/DO_Logo_horizontal_blue.svg&quot; width=&quot;201px&quot; alt=&quot;Servers by Digital Ocean&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.netlify.com&quot;&gt; &lt;img src=&quot;https://www.netlify.com/v3/img/components/netlify-color-bg.svg&quot; alt=&quot;Deploys by Netlify&quot; /&gt; &lt;/a&gt;
  &lt;a href=&quot;https://crowdin.com&quot;&gt; &lt;img src=&quot;https://crowdin.com/images/crowdin-logo.svg&quot; alt=&quot;Translation by Crowdin&quot; /&gt; &lt;/a&gt; &lt;br&gt;
  &lt;a href=&quot;https://codspeed.io/inventree/InvenTree?utm_source=badge&quot;&gt;&lt;img src=&quot;https://img.shields.io/endpoint?url=https://codspeed.io/badge.json&quot; alt=&quot;CodSpeed Badge&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;


&lt;!-- License --&gt;
## :warning: License

Distributed under the [MIT](https://choosealicense.com/licenses/mit/) License. See [LICENSE.txt](https://github.com/inventree/InvenTree/blob/master/LICENSE) for more information.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[mihail911/modern-software-dev-assignments]]></title>
            <link>https://github.com/mihail911/modern-software-dev-assignments</link>
            <guid>https://github.com/mihail911/modern-software-dev-assignments</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:14 GMT</pubDate>
            <description><![CDATA[Assignments for CS146S: The Modern Software Dev (Stanford University Fall 2025)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mihail911/modern-software-dev-assignments">mihail911/modern-software-dev-assignments</a></h1>
            <p>Assignments for CS146S: The Modern Software Dev (Stanford University Fall 2025)</p>
            <p>Language: Python</p>
            <p>Stars: 2,044</p>
            <p>Forks: 498</p>
            <p>Stars today: 60 stars today</p>
            <h2>README</h2><pre># Assignments for CS146S: The Modern Software Developer

This is the home of the assignments for [CS146S: The Modern Software Developer](https://themodernsoftware.dev), taught at Stanford University fall 2025.

## Repo Setup
These steps work with Python 3.12.

1. Install Anaconda
   - Download and install: [Anaconda Individual Edition](https://www.anaconda.com/download)
   - Open a new terminal so `conda` is on your `PATH`.

2. Create and activate a Conda environment (Python 3.12)
   ```bash
   conda create -n cs146s python=3.12 -y
   conda activate cs146s
   ```

3. Install Poetry
   ```bash
   curl -sSL https://install.python-poetry.org | python -
   ```

4. Install project dependencies with Poetry (inside the activated Conda env)
   From the repository root:
   ```bash
   poetry install --no-interaction
   ```</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[usestrix/strix]]></title>
            <link>https://github.com/usestrix/strix</link>
            <guid>https://github.com/usestrix/strix</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:13 GMT</pubDate>
            <description><![CDATA[Open-source AI hackers to find and fix your app‚Äôs vulnerabilities.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/usestrix/strix">usestrix/strix</a></h1>
            <p>Open-source AI hackers to find and fix your app‚Äôs vulnerabilities.</p>
            <p>Language: Python</p>
            <p>Stars: 20,527</p>
            <p>Forks: 2,148</p>
            <p>Stars today: 88 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://strix.ai/&quot;&gt;
    &lt;img src=&quot;https://github.com/usestrix/.github/raw/main/imgs/cover.png&quot; alt=&quot;Strix Banner&quot; width=&quot;100%&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

# Strix

### Open-source AI hackers to find and fix your app‚Äôs vulnerabilities.

&lt;br/&gt;


&lt;a href=&quot;https://docs.strix.ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-docs.strix.ai-2b9246?style=for-the-badge&amp;logo=gitbook&amp;logoColor=white&quot; alt=&quot;Docs&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://strix.ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Website-strix.ai-f0f0f0?style=for-the-badge&amp;logoColor=000000&quot; alt=&quot;Website&quot;&gt;&lt;/a&gt;
[![](https://dcbadge.limes.pink/api/server/strix-ai)](https://discord.gg/strix-ai)

&lt;a href=&quot;https://deepwiki.com/usestrix/strix&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/usestrix/strix&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/usestrix/strix?style=flat-square&quot; alt=&quot;GitHub Stars&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-3b82f6?style=flat-square&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://pypi.org/project/strix-agent/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/strix-agent?style=flat-square&quot; alt=&quot;PyPI Version&quot;&gt;&lt;/a&gt;


&lt;a href=&quot;https://discord.gg/strix-ai&quot;&gt;&lt;img src=&quot;https://github.com/usestrix/.github/raw/main/imgs/Discord.png&quot; height=&quot;40&quot; alt=&quot;Join Discord&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://x.com/strix_ai&quot;&gt;&lt;img src=&quot;https://github.com/usestrix/.github/raw/main/imgs/X.png&quot; height=&quot;40&quot; alt=&quot;Follow on X&quot;&gt;&lt;/a&gt;


&lt;a href=&quot;https://trendshift.io/repositories/15362&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15362&quot; alt=&quot;usestrix/strix | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;


&gt; [!TIP]
&gt; **New!** Strix integrates seamlessly with GitHub Actions and CI/CD pipelines. Automatically scan for vulnerabilities on every pull request and block insecure code before it reaches production!

---


## Strix Overview

Strix are autonomous AI agents that act just like real hackers - they run your code dynamically, find vulnerabilities, and validate them through actual proof-of-concepts. Built for developers and security teams who need fast, accurate security testing without the overhead of manual pentesting or the false positives of static analysis tools.

**Key Capabilities:**

- **Full hacker toolkit** out of the box
- **Teams of agents** that collaborate and scale
- **Real validation** with PoCs, not false positives
- **Developer‚Äëfirst** CLI with actionable reports
- **Auto‚Äëfix &amp; reporting** to accelerate remediation


&lt;br&gt;


&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://strix.ai&quot;&gt;
    &lt;img src=&quot;.github/screenshot.png&quot; alt=&quot;Strix Demo&quot; width=&quot;1000&quot; style=&quot;border-radius: 16px;&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;


## Use Cases

- **Application Security Testing** - Detect and validate critical vulnerabilities in your applications
- **Rapid Penetration Testing** - Get penetration tests done in hours, not weeks, with compliance reports
- **Bug Bounty Automation** - Automate bug bounty research and generate PoCs for faster reporting
- **CI/CD Integration** - Run tests in CI/CD to block vulnerabilities before reaching production

## üöÄ Quick Start

**Prerequisites:**
- Docker (running)
- An LLM API key:
  - Any [supported provider](https://docs.strix.ai/llm-providers/overview) (OpenAI, Anthropic, Google, etc.)
  - Or [Strix Router](https://models.strix.ai) ‚Äî single API key for multiple providers with $10 free credit on signup

### Installation &amp; First Scan

```bash
# Install Strix
curl -sSL https://strix.ai/install | bash

# Configure your AI provider
export STRIX_LLM=&quot;openai/gpt-5&quot;  # or &quot;strix/gpt-5&quot; via Strix Router (https://models.strix.ai)
export LLM_API_KEY=&quot;your-api-key&quot;

# Run your first security assessment
strix --target ./app-directory
```

&gt; [!NOTE]
&gt; First run automatically pulls the sandbox Docker image. Results are saved to `strix_runs/&lt;run-name&gt;`

---

## ‚ú® Features

### Agentic Security Tools

Strix agents come equipped with a comprehensive security testing toolkit:

- **Full HTTP Proxy** - Full request/response manipulation and analysis
- **Browser Automation** - Multi-tab browser for testing of XSS, CSRF, auth flows
- **Terminal Environments** - Interactive shells for command execution and testing
- **Python Runtime** - Custom exploit development and validation
- **Reconnaissance** - Automated OSINT and attack surface mapping
- **Code Analysis** - Static and dynamic analysis capabilities
- **Knowledge Management** - Structured findings and attack documentation

### Comprehensive Vulnerability Detection

Strix can identify and validate a wide range of security vulnerabilities:

- **Access Control** - IDOR, privilege escalation, auth bypass
- **Injection Attacks** - SQL, NoSQL, command injection
- **Server-Side** - SSRF, XXE, deserialization flaws
- **Client-Side** - XSS, prototype pollution, DOM vulnerabilities
- **Business Logic** - Race conditions, workflow manipulation
- **Authentication** - JWT vulnerabilities, session management
- **Infrastructure** - Misconfigurations, exposed services

### Graph of Agents

Advanced multi-agent orchestration for comprehensive security testing:

- **Distributed Workflows** - Specialized agents for different attacks and assets
- **Scalable Testing** - Parallel execution for fast comprehensive coverage
- **Dynamic Coordination** - Agents collaborate and share discoveries

---

## Usage Examples

### Basic Usage

```bash
# Scan a local codebase
strix --target ./app-directory

# Security review of a GitHub repository
strix --target https://github.com/org/repo

# Black-box web application assessment
strix --target https://your-app.com
```

### Advanced Testing Scenarios

```bash
# Grey-box authenticated testing
strix --target https://your-app.com --instruction &quot;Perform authenticated testing using credentials: user:pass&quot;

# Multi-target testing (source code + deployed app)
strix -t https://github.com/org/app -t https://your-app.com

# Focused testing with custom instructions
strix --target api.your-app.com --instruction &quot;Focus on business logic flaws and IDOR vulnerabilities&quot;

# Provide detailed instructions through file (e.g., rules of engagement, scope, exclusions)
strix --target api.your-app.com --instruction-file ./instruction.md
```

### Headless Mode

Run Strix programmatically without interactive UI using the `-n/--non-interactive` flag‚Äîperfect for servers and automated jobs. The CLI prints real-time vulnerability findings, and the final report before exiting. Exits with non-zero code when vulnerabilities are found.

```bash
strix -n --target https://your-app.com
```

### CI/CD (GitHub Actions)

Strix can be added to your pipeline to run a security test on pull requests with a lightweight GitHub Actions workflow:

```yaml
name: strix-penetration-test

on:
  pull_request:

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Install Strix
        run: curl -sSL https://strix.ai/install | bash

      - name: Run Strix
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}

        run: strix -n -t ./ --scan-mode quick
```

### Configuration

```bash
export STRIX_LLM=&quot;openai/gpt-5&quot;
export LLM_API_KEY=&quot;your-api-key&quot;

# Optional
export LLM_API_BASE=&quot;your-api-base-url&quot;  # if using a local model, e.g. Ollama, LMStudio
export PERPLEXITY_API_KEY=&quot;your-api-key&quot;  # for search capabilities
export STRIX_REASONING_EFFORT=&quot;high&quot;  # control thinking effort (default: high, quick scan: medium)
```

&gt; [!NOTE]
&gt; Strix automatically saves your configuration to `~/.strix/cli-config.json`, so you don&#039;t have to re-enter it on every run.

**Recommended models for best results:**

- [OpenAI GPT-5](https://openai.com/api/) ‚Äî `openai/gpt-5`
- [Anthropic Claude Sonnet 4.6](https://claude.com/platform/api) ‚Äî `anthropic/claude-sonnet-4-6`
- [Google Gemini 3 Pro Preview](https://cloud.google.com/vertex-ai) ‚Äî `vertex_ai/gemini-3-pro-preview`

See the [LLM Providers documentation](https://docs.strix.ai/llm-providers/overview) for all supported providers including Vertex AI, Bedrock, Azure, and local models.

## Documentation

Full documentation is available at **[docs.strix.ai](https://docs.strix.ai)** ‚Äî including detailed guides for usage, CI/CD integrations, skills, and advanced configuration.

## Contributing

We welcome contributions of code, docs, and new skills - check out our [Contributing Guide](https://docs.strix.ai/contributing) to get started or open a [pull request](https://github.com/usestrix/strix/pulls)/[issue](https://github.com/usestrix/strix/issues).

## Join Our Community

Have questions? Found a bug? Want to contribute? **[Join our Discord!](https://discord.gg/strix-ai)**

## Support the Project

**Love Strix?** Give us a ‚≠ê on GitHub!

## Acknowledgements

Strix builds on the incredible work of open-source projects like [LiteLLM](https://github.com/BerriAI/litellm), [Caido](https://github.com/caido/caido), [Nuclei](https://github.com/projectdiscovery/nuclei), [Playwright](https://github.com/microsoft/playwright), and [Textual](https://github.com/Textualize/textual). Huge thanks to their maintainers!


&gt; [!WARNING]
&gt; Only test apps you own or have permission to test. You are responsible for using Strix ethically and legally.

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[virattt/ai-hedge-fund]]></title>
            <link>https://github.com/virattt/ai-hedge-fund</link>
            <guid>https://github.com/virattt/ai-hedge-fund</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:12 GMT</pubDate>
            <description><![CDATA[An AI Hedge Fund Team]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/virattt/ai-hedge-fund">virattt/ai-hedge-fund</a></h1>
            <p>An AI Hedge Fund Team</p>
            <p>Language: Python</p>
            <p>Stars: 45,869</p>
            <p>Forks: 8,010</p>
            <p>Stars today: 20 stars today</p>
            <h2>README</h2><pre># AI Hedge Fund

This is a proof of concept for an AI-powered hedge fund.  The goal of this project is to explore the use of AI to make trading decisions.  This project is for **educational** purposes only and is not intended for real trading or investment.

This system employs several agents working together:

1. Aswath Damodaran Agent - The Dean of Valuation, focuses on story, numbers, and disciplined valuation
2. Ben Graham Agent - The godfather of value investing, only buys hidden gems with a margin of safety
3. Bill Ackman Agent - An activist investor, takes bold positions and pushes for change
4. Cathie Wood Agent - The queen of growth investing, believes in the power of innovation and disruption
5. Charlie Munger Agent - Warren Buffett&#039;s partner, only buys wonderful businesses at fair prices
6. Michael Burry Agent - The Big Short contrarian who hunts for deep value
7. Mohnish Pabrai Agent - The Dhandho investor, who looks for doubles at low risk
8. Peter Lynch Agent - Practical investor who seeks &quot;ten-baggers&quot; in everyday businesses
9. Phil Fisher Agent - Meticulous growth investor who uses deep &quot;scuttlebutt&quot; research 
10. Rakesh Jhunjhunwala Agent - The Big Bull of India
11. Stanley Druckenmiller Agent - Macro legend who hunts for asymmetric opportunities with growth potential
12. Warren Buffett Agent - The oracle of Omaha, seeks wonderful companies at a fair price
13. Valuation Agent - Calculates the intrinsic value of a stock and generates trading signals
14. Sentiment Agent - Analyzes market sentiment and generates trading signals
15. Fundamentals Agent - Analyzes fundamental data and generates trading signals
16. Technicals Agent - Analyzes technical indicators and generates trading signals
17. Risk Manager - Calculates risk metrics and sets position limits
18. Portfolio Manager - Makes final trading decisions and generates orders

&lt;img width=&quot;1042&quot; alt=&quot;Screenshot 2025-03-22 at 6 19 07 PM&quot; src=&quot;https://github.com/user-attachments/assets/cbae3dcf-b571-490d-b0ad-3f0f035ac0d4&quot; /&gt;

Note: the system does not actually make any trades.

[![Twitter Follow](https://img.shields.io/twitter/follow/virattt?style=social)](https://twitter.com/virattt)

## Disclaimer

This project is for **educational and research purposes only**.

- Not intended for real trading or investment
- No investment advice or guarantees provided
- Creator assumes no liability for financial losses
- Consult a financial advisor for investment decisions
- Past performance does not indicate future results

By using this software, you agree to use it solely for learning purposes.

## Table of Contents
- [How to Install](#how-to-install)
- [How to Run](#how-to-run)
  - [‚å®Ô∏è Command Line Interface](#Ô∏è-command-line-interface)
  - [üñ•Ô∏è Web Application](#Ô∏è-web-application)
- [How to Contribute](#how-to-contribute)
- [Feature Requests](#feature-requests)
- [License](#license)

## How to Install

Before you can run the AI Hedge Fund, you&#039;ll need to install it and set up your API keys. These steps are common to both the full-stack web application and command line interface.

### 1. Clone the Repository

```bash
git clone https://github.com/virattt/ai-hedge-fund.git
cd ai-hedge-fund
```

### 2. Set up API keys

Create a `.env` file for your API keys:
```bash
# Create .env file for your API keys (in the root directory)
cp .env.example .env
```

Open and edit the `.env` file to add your API keys:
```bash
# For running LLMs hosted by openai (gpt-4o, gpt-4o-mini, etc.)
OPENAI_API_KEY=your-openai-api-key

# For getting financial data to power the hedge fund
FINANCIAL_DATASETS_API_KEY=your-financial-datasets-api-key
```

**Important**: You must set at least one LLM API key (e.g. `OPENAI_API_KEY`, `GROQ_API_KEY`, `ANTHROPIC_API_KEY`, or `DEEPSEEK_API_KEY`) for the hedge fund to work. 

**Financial Data**: Data for AAPL, GOOGL, MSFT, NVDA, and TSLA is free and does not require an API key. For any other ticker, you will need to set the `FINANCIAL_DATASETS_API_KEY` in the .env file.

## How to Run

### ‚å®Ô∏è Command Line Interface

You can run the AI Hedge Fund directly via terminal. This approach offers more granular control and is useful for automation, scripting, and integration purposes.

&lt;img width=&quot;992&quot; alt=&quot;Screenshot 2025-01-06 at 5 50 17 PM&quot; src=&quot;https://github.com/user-attachments/assets/e8ca04bf-9989-4a7d-a8b4-34e04666663b&quot; /&gt;

#### Quick Start

1. Install Poetry (if not already installed):
```bash
curl -sSL https://install.python-poetry.org | python3 -
```

2. Install dependencies:
```bash
poetry install
```

#### Run the AI Hedge Fund
```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA
```

You can also specify a `--ollama` flag to run the AI hedge fund using local LLMs.

```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --ollama
```

You can optionally specify the start and end dates to make decisions over a specific time period.

```bash
poetry run python src/main.py --ticker AAPL,MSFT,NVDA --start-date 2024-01-01 --end-date 2024-03-01
```

#### Run the Backtester
```bash
poetry run python src/backtester.py --ticker AAPL,MSFT,NVDA
```

**Example Output:**
&lt;img width=&quot;941&quot; alt=&quot;Screenshot 2025-01-06 at 5 47 52 PM&quot; src=&quot;https://github.com/user-attachments/assets/00e794ea-8628-44e6-9a84-8f8a31ad3b47&quot; /&gt;


Note: The `--ollama`, `--start-date`, and `--end-date` flags work for the backtester, as well!

### üñ•Ô∏è Web Application

The new way to run the AI Hedge Fund is through our web application that provides a user-friendly interface. This is recommended for users who prefer visual interfaces over command line tools.

Please see detailed instructions on how to install and run the web application [here](https://github.com/virattt/ai-hedge-fund/tree/main/app).

&lt;img width=&quot;1721&quot; alt=&quot;Screenshot 2025-06-28 at 6 41 03‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/b95ab696-c9f4-416c-9ad1-51feb1f5374b&quot; /&gt;


## How to Contribute

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

**Important**: Please keep your pull requests small and focused.  This will make it easier to review and merge.

## Feature Requests

If you have a feature request, please open an [issue](https://github.com/virattt/ai-hedge-fund/issues) and make sure it is tagged with `enhancement`.

## License

This project is licensed under the MIT License - see the LICENSE file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[facebookresearch/detectron2]]></title>
            <link>https://github.com/facebookresearch/detectron2</link>
            <guid>https://github.com/facebookresearch/detectron2</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:11 GMT</pubDate>
            <description><![CDATA[Detectron2 is a platform for object detection, segmentation and other visual recognition tasks.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/facebookresearch/detectron2">facebookresearch/detectron2</a></h1>
            <p>Detectron2 is a platform for object detection, segmentation and other visual recognition tasks.</p>
            <p>Language: Python</p>
            <p>Stars: 34,116</p>
            <p>Forks: 7,902</p>
            <p>Stars today: 13 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;.github/Detectron2-Logo-Horz.svg&quot; width=&quot;300&quot; &gt;

Detectron2 is Facebook AI Research&#039;s next generation library
that provides state-of-the-art detection and segmentation algorithms.
It is the successor of
[Detectron](https://github.com/facebookresearch/Detectron/)
and [maskrcnn-benchmark](https://github.com/facebookresearch/maskrcnn-benchmark/).
It supports a number of computer vision research projects and production applications in Facebook.

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://user-images.githubusercontent.com/1381301/66535560-d3422200-eace-11e9-9123-5535d469db19.png&quot;/&gt;
&lt;/div&gt;
&lt;br&gt;

## Learn More about Detectron2

* Includes new capabilities such as panoptic segmentation, Densepose, Cascade R-CNN, rotated bounding boxes, PointRend,
  DeepLab, ViTDet, MViTv2 etc.
* Used as a library to support building [research projects](projects/) on top of it.
* Models can be exported to TorchScript format or Caffe2 format for deployment.
* It [trains much faster](https://detectron2.readthedocs.io/notes/benchmarks.html).

See our [blog post](https://ai.meta.com/blog/-detectron2-a-pytorch-based-modular-object-detection-library-/)
to see more demos.
See this [interview](https://ai.meta.com/blog/detectron-everingham-prize/) to learn more about the stories behind detectron2.

## Installation

See [installation instructions](https://detectron2.readthedocs.io/tutorials/install.html).

## Getting Started

See [Getting Started with Detectron2](https://detectron2.readthedocs.io/tutorials/getting_started.html),
and the [Colab Notebook](https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5)
to learn about basic usage.

Learn more at our [documentation](https://detectron2.readthedocs.org).
And see [projects/](projects/) for some projects that are built on top of detectron2.

## Model Zoo and Baselines

We provide a large set of baseline results and trained models available for download in the [Detectron2 Model Zoo](MODEL_ZOO.md).

## License

Detectron2 is released under the [Apache 2.0 license](LICENSE).

## Citing Detectron2

If you use Detectron2 in your research or wish to refer to the baseline results published in the [Model Zoo](MODEL_ZOO.md), please use the following BibTeX entry.

```BibTeX
@misc{wu2019detectron2,
  author =       {Yuxin Wu and Alexander Kirillov and Francisco Massa and
                  Wan-Yen Lo and Ross Girshick},
  title =        {Detectron2},
  howpublished = {\url{https://github.com/facebookresearch/detectron2}},
  year =         {2019}
}
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[chenyme/grok2api]]></title>
            <link>https://github.com/chenyme/grok2api</link>
            <guid>https://github.com/chenyme/grok2api</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:10 GMT</pubDate>
            <description><![CDATA[Âü∫‰∫é FastAPI ÈáçÊûÑÁöÑ Grok2APIÔºåÂÖ®Èù¢ÈÄÇÈÖçÊúÄÊñ∞ Web Ë∞ÉÁî®Ê†ºÂºèÔºåÊîØÊåÅÊµÅ/ÈùûÊµÅÂºèÂØπËØù„ÄÅÂõæÂÉèÁîüÊàê/ÁºñËæë„ÄÅÊ∑±Â∫¶ÊÄùËÄÉÔºåÂè∑Ê±†Âπ∂Âèë‰∏éËá™Âä®Ë¥üËΩΩÂùáË°°‰∏Ä‰ΩìÂåñ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/chenyme/grok2api">chenyme/grok2api</a></h1>
            <p>Âü∫‰∫é FastAPI ÈáçÊûÑÁöÑ Grok2APIÔºåÂÖ®Èù¢ÈÄÇÈÖçÊúÄÊñ∞ Web Ë∞ÉÁî®Ê†ºÂºèÔºåÊîØÊåÅÊµÅ/ÈùûÊµÅÂºèÂØπËØù„ÄÅÂõæÂÉèÁîüÊàê/ÁºñËæë„ÄÅÊ∑±Â∫¶ÊÄùËÄÉÔºåÂè∑Ê±†Âπ∂Âèë‰∏éËá™Âä®Ë¥üËΩΩÂùáË°°‰∏Ä‰ΩìÂåñ„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 1,725</p>
            <p>Forks: 576</p>
            <p>Stars today: 41 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[harry0703/MoneyPrinterTurbo]]></title>
            <link>https://github.com/harry0703/MoneyPrinterTurbo</link>
            <guid>https://github.com/harry0703/MoneyPrinterTurbo</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:09 GMT</pubDate>
            <description><![CDATA[Âà©Áî®AIÂ§ßÊ®°ÂûãÔºå‰∏ÄÈîÆÁîüÊàêÈ´òÊ∏ÖÁü≠ËßÜÈ¢ë Generate short videos with one click using AI LLM.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/harry0703/MoneyPrinterTurbo">harry0703/MoneyPrinterTurbo</a></h1>
            <p>Âà©Áî®AIÂ§ßÊ®°ÂûãÔºå‰∏ÄÈîÆÁîüÊàêÈ´òÊ∏ÖÁü≠ËßÜÈ¢ë Generate short videos with one click using AI LLM.</p>
            <p>Language: Python</p>
            <p>Stars: 49,588</p>
            <p>Forks: 7,040</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;h1 align=&quot;center&quot;&gt;MoneyPrinterTurbo üí∏&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Stargazers&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Issues&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/network/members&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Forks&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3&gt;ÁÆÄ‰Ωì‰∏≠Êñá | &lt;a href=&quot;README-en.md&quot;&gt;English&lt;/a&gt;&lt;/h3&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/8731&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/8731&quot; alt=&quot;harry0703%2FMoneyPrinterTurbo | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;br&gt;
Âè™ÈúÄÊèê‰æõ‰∏Ä‰∏™ËßÜÈ¢ë &lt;b&gt;‰∏ªÈ¢ò&lt;/b&gt; Êàñ &lt;b&gt;ÂÖ≥ÈîÆËØç&lt;/b&gt; ÔºåÂ∞±ÂèØ‰ª•ÂÖ®Ëá™Âä®ÁîüÊàêËßÜÈ¢ëÊñáÊ°à„ÄÅËßÜÈ¢ëÁ¥†Êùê„ÄÅËßÜÈ¢ëÂ≠óÂπï„ÄÅËßÜÈ¢ëËÉåÊôØÈü≥‰πêÔºåÁÑ∂ÂêéÂêàÊàê‰∏Ä‰∏™È´òÊ∏ÖÁöÑÁü≠ËßÜÈ¢ë„ÄÇ
&lt;br&gt;

&lt;h4&gt;WebÁïåÈù¢&lt;/h4&gt;

![](docs/webui.jpg)

&lt;h4&gt;APIÁïåÈù¢&lt;/h4&gt;

![](docs/api.jpg)

&lt;/div&gt;

## ÁâπÂà´ÊÑüË∞¢ üôè

Áî±‰∫éËØ•È°πÁõÆÁöÑ **ÈÉ®ÁΩ≤** Âíå **‰ΩøÁî®**ÔºåÂØπ‰∫é‰∏Ä‰∫õÂ∞èÁôΩÁî®Êà∑Êù•ËØ¥ÔºåËøòÊòØ **Êúâ‰∏ÄÂÆöÁöÑÈó®Êßõ**ÔºåÂú®Ê≠§ÁâπÂà´ÊÑüË∞¢
**ÂΩïÂíñÔºàAIÊô∫ËÉΩ Â§öÂ™í‰ΩìÊúçÂä°Âπ≥Âè∞Ôºâ** ÁΩëÁ´ôÂü∫‰∫éËØ•È°πÁõÆÔºåÊèê‰æõÁöÑÂÖçË¥π`AIËßÜÈ¢ëÁîüÊàêÂô®`ÊúçÂä°ÔºåÂèØ‰ª•‰∏çÁî®ÈÉ®ÁΩ≤ÔºåÁõ¥Êé•Âú®Á∫ø‰ΩøÁî®ÔºåÈùûÂ∏∏Êñπ‰æø„ÄÇ

- ‰∏≠ÊñáÁâàÔºöhttps://reccloud.cn
- Ëã±ÊñáÁâàÔºöhttps://reccloud.com

![](docs/reccloud.cn.jpg)

## ÊÑüË∞¢ËµûÂä© üôè

ÊÑüË∞¢‰ΩêÁ≥ñ https://picwish.cn ÂØπËØ•È°πÁõÆÁöÑÊîØÊåÅÂíåËµûÂä©Ôºå‰ΩøÂæóËØ•È°πÁõÆËÉΩÂ§üÊåÅÁª≠ÁöÑÊõ¥Êñ∞ÂíåÁª¥Êä§„ÄÇ

‰ΩêÁ≥ñ‰∏ìÊ≥®‰∫é**ÂõæÂÉèÂ§ÑÁêÜÈ¢ÜÂüü**ÔºåÊèê‰æõ‰∏∞ÂØåÁöÑ**ÂõæÂÉèÂ§ÑÁêÜÂ∑•ÂÖ∑**ÔºåÂ∞ÜÂ§çÊùÇÊìç‰ΩúÊûÅËá¥ÁÆÄÂåñÔºåÁúüÊ≠£ÂÆûÁé∞ËÆ©ÂõæÂÉèÂ§ÑÁêÜÊõ¥ÁÆÄÂçï„ÄÇ

![picwish.jpg](docs/picwish.jpg)

## ÂäüËÉΩÁâπÊÄß üéØ

- [x] ÂÆåÊï¥ÁöÑ **MVCÊû∂ÊûÑ**Ôºå‰ª£Á†Å **ÁªìÊûÑÊ∏ÖÊô∞**ÔºåÊòì‰∫éÁª¥Êä§ÔºåÊîØÊåÅ `API` Âíå `WebÁïåÈù¢`
- [x] ÊîØÊåÅËßÜÈ¢ëÊñáÊ°à **AIËá™Âä®ÁîüÊàê**Ôºå‰πüÂèØ‰ª•**Ëá™ÂÆö‰πâÊñáÊ°à**
- [x] ÊîØÊåÅÂ§öÁßç **È´òÊ∏ÖËßÜÈ¢ë** Â∞∫ÂØ∏
    - [x] Á´ñÂ±è 9:16Ôºå`1080x1920`
    - [x] Ê®™Â±è 16:9Ôºå`1920x1080`
- [x] ÊîØÊåÅ **ÊâπÈáèËßÜÈ¢ëÁîüÊàê**ÔºåÂèØ‰ª•‰∏ÄÊ¨°ÁîüÊàêÂ§ö‰∏™ËßÜÈ¢ëÔºåÁÑ∂ÂêéÈÄâÊã©‰∏Ä‰∏™ÊúÄÊª°ÊÑèÁöÑ
- [x] ÊîØÊåÅ **ËßÜÈ¢ëÁâáÊÆµÊó∂Èïø** ËÆæÁΩÆÔºåÊñπ‰æøË∞ÉËäÇÁ¥†ÊùêÂàáÊç¢È¢ëÁéá
- [x] ÊîØÊåÅ **‰∏≠Êñá** Âíå **Ëã±Êñá** ËßÜÈ¢ëÊñáÊ°à
- [x] ÊîØÊåÅ **Â§öÁßçËØ≠Èü≥** ÂêàÊàêÔºåÂèØ **ÂÆûÊó∂ËØïÂê¨** ÊïàÊûú
- [x] ÊîØÊåÅ **Â≠óÂπïÁîüÊàê**ÔºåÂèØ‰ª•Ë∞ÉÊï¥ `Â≠ó‰Ωì`„ÄÅ`‰ΩçÁΩÆ`„ÄÅ`È¢úËâ≤`„ÄÅ`Â§ßÂ∞è`ÔºåÂêåÊó∂ÊîØÊåÅ`Â≠óÂπïÊèèËæπ`ËÆæÁΩÆ
- [x] ÊîØÊåÅ **ËÉåÊôØÈü≥‰πê**ÔºåÈöèÊú∫ÊàñËÄÖÊåáÂÆöÈü≥‰πêÊñá‰ª∂ÔºåÂèØËÆæÁΩÆ`ËÉåÊôØÈü≥‰πêÈü≥Èáè`
- [x] ËßÜÈ¢ëÁ¥†ÊùêÊù•Ê∫ê **È´òÊ∏Ö**ÔºåËÄå‰∏î **Êó†ÁâàÊùÉ**Ôºå‰πüÂèØ‰ª•‰ΩøÁî®Ëá™Â∑±ÁöÑ **Êú¨Âú∞Á¥†Êùê**
- [x] ÊîØÊåÅ **OpenAI**„ÄÅ**Moonshot**„ÄÅ**Azure**„ÄÅ**gpt4free**„ÄÅ**one-api**„ÄÅ**ÈÄö‰πâÂçÉÈóÆ**„ÄÅ**Google Gemini**„ÄÅ**Ollama**„ÄÅ**DeepSeek**„ÄÅ **ÊñáÂøÉ‰∏ÄË®Ä**, **Pollinations**„ÄÅ**ModelScope** Á≠âÂ§öÁßçÊ®°ÂûãÊé•ÂÖ•
    - ‰∏≠ÂõΩÁî®Êà∑Âª∫ËÆÆ‰ΩøÁî® **DeepSeek** Êàñ **Moonshot** ‰Ωú‰∏∫Â§ßÊ®°ÂûãÊèê‰æõÂïÜÔºàÂõΩÂÜÖÂèØÁõ¥Êé•ËÆøÈóÆÔºå‰∏çÈúÄË¶ÅVPN„ÄÇÊ≥®ÂÜåÂ∞±ÈÄÅÈ¢ùÂ∫¶ÔºåÂü∫Êú¨Â§üÁî®Ôºâ


### ÂêéÊúüËÆ°Âàí üìÖ

- [ ] GPT-SoVITS ÈÖçÈü≥ÊîØÊåÅ
- [ ] ‰ºòÂåñËØ≠Èü≥ÂêàÊàêÔºåÂà©Áî®Â§ßÊ®°ÂûãÔºå‰ΩøÂÖ∂ÂêàÊàêÁöÑÂ£∞Èü≥ÔºåÊõ¥Âä†Ëá™ÁÑ∂ÔºåÊÉÖÁª™Êõ¥Âä†‰∏∞ÂØå
- [ ] Â¢ûÂä†ËßÜÈ¢ëËΩ¨Âú∫ÊïàÊûúÔºå‰ΩøÂÖ∂ÁúãËµ∑Êù•Êõ¥Âä†ÁöÑÊµÅÁïÖ
- [ ] Â¢ûÂä†Êõ¥Â§öËßÜÈ¢ëÁ¥†ÊùêÊù•Ê∫êÔºå‰ºòÂåñËßÜÈ¢ëÁ¥†ÊùêÂíåÊñáÊ°àÁöÑÂåπÈÖçÂ∫¶
- [ ] Â¢ûÂä†ËßÜÈ¢ëÈïøÂ∫¶ÈÄâÈ°πÔºöÁü≠„ÄÅ‰∏≠„ÄÅÈïø
- [ ] ÊîØÊåÅÊõ¥Â§öÁöÑËØ≠Èü≥ÂêàÊàêÊúçÂä°ÂïÜÔºåÊØîÂ¶Ç OpenAI TTS
- [ ] Ëá™Âä®‰∏ä‰º†Âà∞YouTubeÂπ≥Âè∞

## ËßÜÈ¢ëÊºîÁ§∫ üì∫

### Á´ñÂ±è 9:16

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt; „ÄäÂ¶Ç‰ΩïÂ¢ûÂä†ÁîüÊ¥ªÁöÑ‰πêË∂£„Äã&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt; „ÄäÈáëÈí±ÁöÑ‰ΩúÁî®„Äã&lt;br&gt;Êõ¥ÁúüÂÆûÁöÑÂêàÊàêÂ£∞Èü≥&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt; „ÄäÁîüÂëΩÁöÑÊÑè‰πâÊòØ‰ªÄ‰πà„Äã&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

### Ê®™Â±è 16:9

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;„ÄäÁîüÂëΩÁöÑÊÑè‰πâÊòØ‰ªÄ‰πà„Äã&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;„Ää‰∏∫‰ªÄ‰πàË¶ÅËøêÂä®„Äã&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

## ÈÖçÁΩÆË¶ÅÊ±Ç üì¶

- Âª∫ËÆÆÊúÄ‰Ωé CPU **4Ê†∏** Êàñ‰ª•‰∏äÔºåÂÜÖÂ≠ò **4G** Êàñ‰ª•‰∏äÔºåÊòæÂç°ÈùûÂøÖÈ°ª
- Windows 10 Êàñ MacOS 11.0 ‰ª•‰∏äÁ≥ªÁªü


## Âø´ÈÄüÂºÄÂßã üöÄ

### Âú® Google Colab ‰∏≠ËøêË°å
ÂÖçÂéªÊú¨Âú∞ÁéØÂ¢ÉÈÖçÁΩÆÔºåÁÇπÂáªÁõ¥Êé•Âú® Google Colab ‰∏≠Âø´ÈÄü‰ΩìÈ™å MoneyPrinterTurbo

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harry0703/MoneyPrinterTurbo/blob/main/docs/MoneyPrinterTurbo.ipynb)


### Windows‰∏ÄÈîÆÂêØÂä®ÂåÖ

‰∏ãËΩΩ‰∏ÄÈîÆÂêØÂä®ÂåÖÔºåËß£ÂéãÁõ¥Êé•‰ΩøÁî®ÔºàË∑ØÂæÑ‰∏çË¶ÅÊúâ **‰∏≠Êñá**„ÄÅ**ÁâπÊÆäÂ≠óÁ¨¶**„ÄÅ**Á©∫Ê†º**Ôºâ

- ÁôæÂ∫¶ÁΩëÁõòÔºàv1.2.6Ôºâ: https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx ÊèêÂèñÁ†Å: sbqx
- Google Drive (v1.2.6): https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing

‰∏ãËΩΩÂêéÔºåÂª∫ËÆÆÂÖà**ÂèåÂáªÊâßË°å** `update.bat` Êõ¥Êñ∞Âà∞**ÊúÄÊñ∞‰ª£Á†Å**ÔºåÁÑ∂ÂêéÂèåÂáª `start.bat` ÂêØÂä®

ÂêØÂä®ÂêéÔºå‰ºöËá™Âä®ÊâìÂºÄÊµèËßàÂô®ÔºàÂ¶ÇÊûúÊâìÂºÄÊòØÁ©∫ÁôΩÔºåÂª∫ËÆÆÊç¢Êàê **Chrome** ÊàñËÄÖ **Edge** ÊâìÂºÄÔºâ

## ÂÆâË£ÖÈÉ®ÁΩ≤ üì•

### ÂâçÊèêÊù°‰ª∂

- Â∞ΩÈáè‰∏çË¶Å‰ΩøÁî® **‰∏≠ÊñáË∑ØÂæÑ**ÔºåÈÅøÂÖçÂá∫Áé∞‰∏Ä‰∫õÊó†Ê≥ïÈ¢ÑÊñôÁöÑÈóÆÈ¢ò
- ËØ∑Á°Æ‰øù‰Ω†ÁöÑ **ÁΩëÁªú** ÊòØÊ≠£Â∏∏ÁöÑÔºåVPNÈúÄË¶ÅÊâìÂºÄ`ÂÖ®Â±ÄÊµÅÈáè`Ê®°Âºè

#### ‚ë† ÂÖãÈöÜ‰ª£Á†Å

```shell
git clone https://github.com/harry0703/MoneyPrinterTurbo.git
```

#### ‚ë° ‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂ÔºàÂèØÈÄâÔºåÂª∫ËÆÆÂêØÂä®Âêé‰πüÂèØ‰ª•Âú® WebUI ÈáåÈù¢ÈÖçÁΩÆÔºâ

- Â∞Ü `config.example.toml` Êñá‰ª∂Â§çÂà∂‰∏Ä‰ªΩÔºåÂëΩÂêç‰∏∫ `config.toml`
- ÊåâÁÖß `config.toml` Êñá‰ª∂‰∏≠ÁöÑËØ¥ÊòéÔºåÈÖçÁΩÆÂ•Ω `pexels_api_keys` Âíå `llm_provider`ÔºåÂπ∂Ê†πÊçÆ llm_provider ÂØπÂ∫îÁöÑÊúçÂä°ÂïÜÔºåÈÖçÁΩÆÁõ∏ÂÖ≥ÁöÑ
  API Key

### DockerÈÉ®ÁΩ≤ üê≥

#### ‚ë† ÂêØÂä®Docker

Â¶ÇÊûúÊú™ÂÆâË£Ö DockerÔºåËØ∑ÂÖàÂÆâË£Ö https://www.docker.com/products/docker-desktop/

Â¶ÇÊûúÊòØWindowsÁ≥ªÁªüÔºåËØ∑ÂèÇËÄÉÂæÆËΩØÁöÑÊñáÊ°£Ôºö

1. https://learn.microsoft.com/zh-cn/windows/wsl/install
2. https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers

```shell
cd MoneyPrinterTurbo
docker-compose up
```

&gt; Ê≥®ÊÑèÔºöÊúÄÊñ∞ÁâàÁöÑdockerÂÆâË£ÖÊó∂‰ºöËá™Âä®‰ª•Êèí‰ª∂ÁöÑÂΩ¢ÂºèÂÆâË£Ödocker composeÔºåÂêØÂä®ÂëΩ‰ª§Ë∞ÉÊï¥‰∏∫docker compose up

#### ‚ë° ËÆøÈóÆWebÁïåÈù¢

ÊâìÂºÄÊµèËßàÂô®ÔºåËÆøÈóÆ http://0.0.0.0:8501

#### ‚ë¢ ËÆøÈóÆAPIÊñáÊ°£

ÊâìÂºÄÊµèËßàÂô®ÔºåËÆøÈóÆ http://0.0.0.0:8080/docs ÊàñËÄÖ http://0.0.0.0:8080/redoc

### ÊâãÂä®ÈÉ®ÁΩ≤ üì¶

&gt; ËßÜÈ¢ëÊïôÁ®ã

- ÂÆåÊï¥ÁöÑ‰ΩøÁî®ÊºîÁ§∫Ôºöhttps://v.douyin.com/iFhnwsKY/
- Â¶Ç‰ΩïÂú®Windows‰∏äÈÉ®ÁΩ≤Ôºöhttps://v.douyin.com/iFyjoW3M

#### ‚ë† ÂàõÂª∫ËôöÊãüÁéØÂ¢É

Âª∫ËÆÆ‰ΩøÁî® [conda](https://conda.io/projects/conda/en/latest/user-guide/install/index.html) ÂàõÂª∫ python ËôöÊãüÁéØÂ¢É

```shell
git clone https://github.com/harry0703/MoneyPrinterTurbo.git
cd MoneyPrinterTurbo
conda create -n MoneyPrinterTurbo python=3.11
conda activate MoneyPrinterTurbo
pip install -r requirements.txt
```

#### ‚ë° ÂÆâË£ÖÂ•Ω ImageMagick

- Windows:
    - ‰∏ãËΩΩ https://imagemagick.org/script/download.php ÈÄâÊã©WindowsÁâàÊú¨ÔºåÂàáËÆ∞‰∏ÄÂÆöË¶ÅÈÄâÊã© **ÈùôÊÄÅÂ∫ì** ÁâàÊú¨ÔºåÊØîÂ¶Ç
      ImageMagick-7.1.1-32-Q16-x64-**static**.exe
    - ÂÆâË£Ö‰∏ãËΩΩÂ•ΩÁöÑ ImageMagickÔºå**Ê≥®ÊÑè‰∏çË¶Å‰øÆÊîπÂÆâË£ÖË∑ØÂæÑ**
    - ‰øÆÊîπ `ÈÖçÁΩÆÊñá‰ª∂ config.toml` ‰∏≠ÁöÑ `imagemagick_path` ‰∏∫‰Ω†ÁöÑ **ÂÆûÈôÖÂÆâË£ÖË∑ØÂæÑ**

- MacOS:
  ```shell
  brew install imagemagick
  ````
- Ubuntu
  ```shell
  sudo apt-get install imagemagick
  ```
- CentOS
  ```shell
  sudo yum install ImageMagick
  ```

#### ‚ë¢ ÂêØÂä®WebÁïåÈù¢ üåê

Ê≥®ÊÑèÈúÄË¶ÅÂà∞ MoneyPrinterTurbo È°πÁõÆ `Ê†πÁõÆÂΩï` ‰∏ãÊâßË°å‰ª•‰∏ãÂëΩ‰ª§

###### Windows

```bat
webui.bat
```

###### MacOS or Linux

```shell
sh webui.sh
```

ÂêØÂä®ÂêéÔºå‰ºöËá™Âä®ÊâìÂºÄÊµèËßàÂô®ÔºàÂ¶ÇÊûúÊâìÂºÄÊòØÁ©∫ÁôΩÔºåÂª∫ËÆÆÊç¢Êàê **Chrome** ÊàñËÄÖ **Edge** ÊâìÂºÄÔºâ

#### ‚ë£ ÂêØÂä®APIÊúçÂä° üöÄ

```shell
python main.py
```

ÂêØÂä®ÂêéÔºåÂèØ‰ª•Êü•Áúã `APIÊñáÊ°£` http://127.0.0.1:8080/docs ÊàñËÄÖ http://127.0.0.1:8080/redoc Áõ¥Êé•Âú®Á∫øË∞ÉËØïÊé•Âè£ÔºåÂø´ÈÄü‰ΩìÈ™å„ÄÇ

## ËØ≠Èü≥ÂêàÊàê üó£

ÊâÄÊúâÊîØÊåÅÁöÑÂ£∞Èü≥ÂàóË°®ÔºåÂèØ‰ª•Êü•ÁúãÔºö[Â£∞Èü≥ÂàóË°®](./docs/voice-list.txt)

2024-04-16 v1.1.2 Êñ∞Â¢û‰∫Ü9ÁßçAzureÁöÑËØ≠Èü≥ÂêàÊàêÂ£∞Èü≥ÔºåÈúÄË¶ÅÈÖçÁΩÆAPI KEYÔºåËØ•Â£∞Èü≥ÂêàÊàêÁöÑÊõ¥Âä†ÁúüÂÆû„ÄÇ

## Â≠óÂπïÁîüÊàê üìú

ÂΩìÂâçÊîØÊåÅ2ÁßçÂ≠óÂπïÁîüÊàêÊñπÂºèÔºö

- **edge**: ÁîüÊàê`ÈÄüÂ∫¶Âø´`ÔºåÊÄßËÉΩÊõ¥Â•ΩÔºåÂØπÁîµËÑëÈÖçÁΩÆÊ≤°ÊúâË¶ÅÊ±ÇÔºå‰ΩÜÊòØË¥®ÈáèÂèØËÉΩ‰∏çÁ®≥ÂÆö
- **whisper**: ÁîüÊàê`ÈÄüÂ∫¶ÊÖ¢`ÔºåÊÄßËÉΩËæÉÂ∑ÆÔºåÂØπÁîµËÑëÈÖçÁΩÆÊúâ‰∏ÄÂÆöË¶ÅÊ±ÇÔºå‰ΩÜÊòØ`Ë¥®ÈáèÊõ¥ÂèØÈù†`„ÄÇ

ÂèØ‰ª•‰øÆÊîπ `config.toml` ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑ `subtitle_provider` ËøõË°åÂàáÊç¢

Âª∫ËÆÆ‰ΩøÁî® `edge` Ê®°ÂºèÔºåÂ¶ÇÊûúÁîüÊàêÁöÑÂ≠óÂπïË¥®Èáè‰∏çÂ•ΩÔºåÂÜçÂàáÊç¢Âà∞ `whisper` Ê®°Âºè

&gt; Ê≥®ÊÑèÔºö

1. whisper Ê®°Âºè‰∏ãÈúÄË¶ÅÂà∞ HuggingFace ‰∏ãËΩΩ‰∏Ä‰∏™Ê®°ÂûãÊñá‰ª∂ÔºåÂ§ßÁ∫¶ 3GB Â∑¶Âè≥ÔºåËØ∑Á°Æ‰øùÁΩëÁªúÈÄöÁïÖ
2. Â¶ÇÊûúÁïôÁ©∫ÔºåË°®Á§∫‰∏çÁîüÊàêÂ≠óÂπï„ÄÇ

&gt; Áî±‰∫éÂõΩÂÜÖÊó†Ê≥ïËÆøÈóÆ HuggingFaceÔºåÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÊñπÊ≥ï‰∏ãËΩΩ `whisper-large-v3` ÁöÑÊ®°ÂûãÊñá‰ª∂

‰∏ãËΩΩÂú∞ÂùÄÔºö

- ÁôæÂ∫¶ÁΩëÁõò: https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9
- Â§∏ÂÖãÁΩëÁõòÔºöhttps://pan.quark.cn/s/3ee3d991d64b

Ê®°Âûã‰∏ãËΩΩÂêéËß£ÂéãÔºåÊï¥‰∏™ÁõÆÂΩïÊîæÂà∞ `.\MoneyPrinterTurbo\models` ÈáåÈù¢Ôºå
ÊúÄÁªàÁöÑÊñá‰ª∂Ë∑ØÂæÑÂ∫îËØ•ÊòØËøôÊ†∑: `.\MoneyPrinterTurbo\models\whisper-large-v3`

```
MoneyPrinterTurbo  
  ‚îú‚îÄmodels
  ‚îÇ   ‚îî‚îÄwhisper-large-v3
  ‚îÇ          config.json
  ‚îÇ          model.bin
  ‚îÇ          preprocessor_config.json
  ‚îÇ          tokenizer.json
  ‚îÇ          vocabulary.json
```

## ËÉåÊôØÈü≥‰πê üéµ

Áî®‰∫éËßÜÈ¢ëÁöÑËÉåÊôØÈü≥‰πêÔºå‰Ωç‰∫éÈ°πÁõÆÁöÑ `resource/songs` ÁõÆÂΩï‰∏ã„ÄÇ
&gt; ÂΩìÂâçÈ°πÁõÆÈáåÈù¢Êîæ‰∫Ü‰∏Ä‰∫õÈªòËÆ§ÁöÑÈü≥‰πêÔºåÊù•Ëá™‰∫é YouTube ËßÜÈ¢ëÔºåÂ¶ÇÊúâ‰æµÊùÉÔºåËØ∑Âà†Èô§„ÄÇ

## Â≠óÂπïÂ≠ó‰Ωì üÖ∞

Áî®‰∫éËßÜÈ¢ëÂ≠óÂπïÁöÑÊ∏≤ÊüìÔºå‰Ωç‰∫éÈ°πÁõÆÁöÑ `resource/fonts` ÁõÆÂΩï‰∏ãÔºå‰Ω†‰πüÂèØ‰ª•ÊîæËøõÂéªËá™Â∑±ÁöÑÂ≠ó‰Ωì„ÄÇ

## Â∏∏ËßÅÈóÆÈ¢ò ü§î

### ‚ùìRuntimeError: No ffmpeg exe could be found

ÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåffmpeg ‰ºöË¢´Ëá™Âä®‰∏ãËΩΩÔºåÂπ∂‰∏î‰ºöË¢´Ëá™Âä®Ê£ÄÊµãÂà∞„ÄÇ
‰ΩÜÊòØÂ¶ÇÊûú‰Ω†ÁöÑÁéØÂ¢ÉÊúâÈóÆÈ¢òÔºåÊó†Ê≥ïËá™Âä®‰∏ãËΩΩÔºåÂèØËÉΩ‰ºöÈÅáÂà∞Â¶Ç‰∏ãÈîôËØØÔºö

```
RuntimeError: No ffmpeg exe could be found.
Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
```

Ê≠§Êó∂‰Ω†ÂèØ‰ª•‰ªé https://www.gyan.dev/ffmpeg/builds/ ‰∏ãËΩΩffmpegÔºåËß£ÂéãÂêéÔºåËÆæÁΩÆ `ffmpeg_path` ‰∏∫‰Ω†ÁöÑÂÆûÈôÖÂÆâË£ÖË∑ØÂæÑÂç≥ÂèØ„ÄÇ

```toml
[app]
# ËØ∑Ê†πÊçÆ‰Ω†ÁöÑÂÆûÈôÖË∑ØÂæÑËÆæÁΩÆÔºåÊ≥®ÊÑè Windows Ë∑ØÂæÑÂàÜÈöîÁ¨¶‰∏∫ \\
ffmpeg_path = &quot;C:\\Users\\harry\\Downloads\\ffmpeg.exe&quot;
```

### ‚ùìImageMagickÁöÑÂÆâÂÖ®Á≠ñÁï•ÈòªÊ≠¢‰∫Ü‰∏é‰∏¥Êó∂Êñá‰ª∂@/tmp/tmpur5hyyto.txtÁõ∏ÂÖ≥ÁöÑÊìç‰Ωú

ÂèØ‰ª•Âú®ImageMagickÁöÑÈÖçÁΩÆÊñá‰ª∂policy.xml‰∏≠ÊâæÂà∞Ëøô‰∫õÁ≠ñÁï•„ÄÇ
Ëøô‰∏™Êñá‰ª∂ÈÄöÂ∏∏‰Ωç‰∫é /etc/ImageMagick-`X`/ Êàñ ImageMagick ÂÆâË£ÖÁõÆÂΩïÁöÑÁ±ª‰ºº‰ΩçÁΩÆ„ÄÇ
‰øÆÊîπÂåÖÂê´`pattern=&quot;@&quot;`ÁöÑÊù°ÁõÆÔºåÂ∞Ü`rights=&quot;none&quot;`Êõ¥Êîπ‰∏∫`rights=&quot;read|write&quot;`‰ª•ÂÖÅËÆ∏ÂØπÊñá‰ª∂ÁöÑËØªÂÜôÊìç‰Ωú„ÄÇ

### ‚ùìOSError: [Errno 24] Too many open files

Ëøô‰∏™ÈóÆÈ¢òÊòØÁî±‰∫éÁ≥ªÁªüÊâìÂºÄÊñá‰ª∂Êï∞ÈôêÂà∂ÂØºËá¥ÁöÑÔºåÂèØ‰ª•ÈÄöËøá‰øÆÊîπÁ≥ªÁªüÁöÑÊñá‰ª∂ÊâìÂºÄÊï∞ÈôêÂà∂Êù•Ëß£ÂÜ≥„ÄÇ

Êü•ÁúãÂΩìÂâçÈôêÂà∂

```shell
ulimit -n
```

Â¶ÇÊûúËøá‰ΩéÔºåÂèØ‰ª•Ë∞ÉÈ´ò‰∏Ä‰∫õÔºåÊØîÂ¶Ç

```shell
ulimit -n 10240
```

### ‚ùìWhisper Ê®°Âûã‰∏ãËΩΩÂ§±Ë¥•ÔºåÂá∫Áé∞Â¶Ç‰∏ãÈîôËØØ

LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and
outgoing trafic has been disabled.
To enablerepo look-ups and downloads online, pass &#039;local files only=False&#039; as input.

ÊàñËÄÖ

An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub:
An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the
specified revision on the local disk. Please check your internet connection and try again.
Trying to load the model directly from the local cache, if it exists.

Ëß£ÂÜ≥ÊñπÊ≥ïÔºö[ÁÇπÂáªÊü•ÁúãÂ¶Ç‰Ωï‰ªéÁΩëÁõòÊâãÂä®‰∏ãËΩΩÊ®°Âûã](#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-)

## ÂèçÈ¶àÂª∫ËÆÆ üì¢

- ÂèØ‰ª•Êèê‰∫§ [issue](https://github.com/harry0703/MoneyPrinterTurbo/issues)
  ÊàñËÄÖ [pull request](https://github.com/harry0703/MoneyPrinterTurbo/pulls)„ÄÇ

## ËÆ∏ÂèØËØÅ üìù

ÁÇπÂáªÊü•Áúã [`LICENSE`](LICENSE) Êñá‰ª∂

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;type=Date)](https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;Date)</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[learning-unlimited/ESP-Website]]></title>
            <link>https://github.com/learning-unlimited/ESP-Website</link>
            <guid>https://github.com/learning-unlimited/ESP-Website</guid>
            <pubDate>Tue, 24 Feb 2026 00:07:08 GMT</pubDate>
            <description><![CDATA[A website to help manage the logistics of large, short-term educational programs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/learning-unlimited/ESP-Website">learning-unlimited/ESP-Website</a></h1>
            <p>A website to help manage the logistics of large, short-term educational programs</p>
            <p>Language: Python</p>
            <p>Stars: 112</p>
            <p>Forks: 180</p>
            <p>Stars today: 5 stars today</p>
            <h2>README</h2><pre>[![Lint and Unit Tests](https://github.com/learning-unlimited/ESP-Website/actions/workflows/tests.yml/badge.svg)](https://github.com/learning-unlimited/ESP-Website/actions/workflows/tests.yml)
[![codecov](https://codecov.io/gh/learning-unlimited/ESP-Website/branch/main/graph/badge.svg?token=eY0C5a1Lju)](https://codecov.io/gh/learning-unlimited/ESP-Website)
# ESP Website
This repository contains a website to help manage the logistics of preparing for and running large, short-term educational programs. It is written and maintained by members and alums of the interscholastic Splash community and [Learning Unlimited](https://learningu.org). Documentation for [program administrators](/docs/admin) and [developers](/docs/dev) is in the [`docs`](/docs) directory, including [dev setup documentation](/docs/dev/vagrant.rst) and [instructions for contributors](/docs/dev/contributing.rst).  Additional documentation for chapters of Learning Unlimited is on the [LU Wiki](https://wiki.learningu.org).

## Looking to contribute?

[Check out our wiki for details](https://github.com/learning-unlimited/ESP-Website/wiki#i-want-to-get-involved). We also have a strict [code of conduct](https://github.com/learning-unlimited/ESP-Website?tab=coc-ov-file).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>