<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Sun, 22 Feb 2026 00:05:59 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[huggingface/skills]]></title>
            <link>https://github.com/huggingface/skills</link>
            <guid>https://github.com/huggingface/skills</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:59 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/skills">huggingface/skills</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 1,672</p>
            <p>Forks: 148</p>
            <p>Stars today: 247 stars today</p>
            <h2>README</h2><pre># Hugging Face Skills

Hugging Face Skills are definitions for AI/ML tasks like dataset creation, model training, and evaluation. They are interoperable with all major coding agent tools like OpenAI Codex, Anthropic&#039;s Claude Code, Google DeepMind&#039;s Gemini CLI, and Cursor.

The Skills in this repository follow the standardized format [Agent Skill](https://agentskills.io/home) format.

## How do Skills work?

In practice, skills are self-contained folders that package instructions, scripts, and resources together for an AI agent to use on a specific use case. Each folder includes a `SKILL.md` file with YAML frontmatter (name and description) followed by the guidance your coding agent follows while the skill is active. 

&gt; [!NOTE]
&gt; &#039;Skills&#039; is actually an Anthropic term used within Claude AI and Claude Code and not adopted by other agent tools, but we love it! OpenAI Codex uses an `AGENTS.md` file to define the instructions for your coding agent. Google Gemini uses &#039;extensions&#039; to define the instructions for your coding agent in a `gemini-extension.json` file. **This repo is compatible with all of them, and more!**

&gt; [!TIP]
&gt; If your agent doesn&#039;t support skills, you can use [`agents/AGENTS.md`](agents/AGENTS.md) directly as a fallback.

## Installation

Hugging Face skills are compatible with Claude Code, Codex, Gemini CLI, and Cursor.

### Claude Code

1. Register the repository as a plugin marketplace:  
   
```
/plugin marketplace add huggingface/skills
```

2. To install a skill, run:  
   
```
/plugin install &lt;skill-name&gt;@huggingface/skills
```

For example:  

```
/plugin install hugging-face-cli@huggingface/skills
```

### Codex

1. Codex will identify the skills via the `AGENTS.md` file. You can verify the instructions are loaded with:

```
codex --ask-for-approval never &quot;Summarize the current instructions.&quot;
```

2. For more details, see the [Codex AGENTS guide](https://developers.openai.com/codex/guides/agents-md).

### Gemini CLI

1. This repo includes `gemini-extension.json` to integrate with the Gemini CLI.

2. Install locally:  

```
gemini extensions install . --consent
```

or use the GitHub URL:

```
gemini extensions install https://github.com/huggingface/skills.git --consent
```

4. See [Gemini CLI extensions docs](https://geminicli.com/docs/extensions/#installing-an-extension) for more help.

### Cursor

This repository includes Cursor plugin manifests:

- `.cursor-plugin/plugin.json`
- `.mcp.json` (configured with the Hugging Face MCP server URL)

Install from repository URL (or local checkout) via the Cursor plugin flow.

For contributors, regenerate manifests with:

```bash
./scripts/publish.sh
```

## Skills

This repository contains a few skills to get you started. You can also contribute your own skills to the repository.

### Available skills

&lt;!-- This table is auto-generated by scripts/generate_agents.py. Do not edit manually. --&gt;
&lt;!-- BEGIN_SKILLS_TABLE --&gt;
| Name | Description | Documentation |
|------|-------------|---------------|
| `hugging-face-cli` | Execute Hugging Face Hub operations using the hf CLI. Download models/datasets, upload files, manage repos, and run cloud compute jobs. | [SKILL.md](skills/hugging-face-cli/SKILL.md) |
| `hugging-face-datasets` | Create and manage datasets on Hugging Face Hub. Supports initializing repos, defining configs/system prompts, streaming row updates, and SQL-based dataset querying/transformation. | [SKILL.md](skills/hugging-face-datasets/SKILL.md) |
| `hugging-face-evaluation` | Add and manage evaluation results in Hugging Face model cards. Supports extracting eval tables from README content, importing scores from Artificial Analysis API, and running custom evaluations with vLLM/lighteval. | [SKILL.md](skills/hugging-face-evaluation/SKILL.md) |
| `hugging-face-jobs` | Run compute jobs on Hugging Face infrastructure. Execute Python scripts, manage scheduled jobs, and monitor job status. | [SKILL.md](skills/hugging-face-jobs/SKILL.md) |
| `hugging-face-model-trainer` | Train or fine-tune language models using TRL on Hugging Face Jobs infrastructure. Covers SFT, DPO, GRPO and reward modeling training methods, plus GGUF conversion for local deployment. Includes hardware selection, cost estimation, Trackio monitoring, and Hub persistence. | [SKILL.md](skills/hugging-face-model-trainer/SKILL.md) |
| `hugging-face-paper-publisher` | Publish and manage research papers on Hugging Face Hub. Supports creating paper pages, linking papers to models/datasets, claiming authorship, and generating professional markdown-based research articles. | [SKILL.md](skills/hugging-face-paper-publisher/SKILL.md) |
| `hugging-face-tool-builder` | Build reusable scripts for Hugging Face API operations. Useful for chaining API calls or automating repeated tasks. | [SKILL.md](skills/hugging-face-tool-builder/SKILL.md) |
| `hugging-face-trackio` | Track and visualize ML training experiments with Trackio. Log metrics via Python API and retrieve them via CLI. Supports real-time dashboards synced to HF Spaces. | [SKILL.md](skills/hugging-face-trackio/SKILL.md) |
&lt;!-- END_SKILLS_TABLE --&gt;

### Using skills in your coding agent

Once a skill is installed, mention it directly while giving your coding agent instructions:

- &quot;Use the HF LLM trainer skill to estimate the GPU memory needed for a 70B model run.&quot;
- &quot;Use the HF model evaluation skill to launch `run_eval_job.py` on the latest checkpoint.&quot;
- &quot;Use the HF dataset creator skill to draft new few-shot classification templates.&quot;
- &quot;Use the HF paper publisher skill to index my arXiv paper and link it to my model.&quot;

Your coding agent automatically loads the corresponding `SKILL.md` instructions and helper scripts while it completes the task.

### Contribute or customize a skill

1. Copy one of the existing skill folders (for example, `hf-datasets/`) and rename it.
2. Update the new folder&#039;s `SKILL.md` frontmatter:
   ```markdown
   ---
   name: my-skill-name
   description: Describe what the skill does and when to use it
   ---

   # Skill Title
   Guidance + examples + guardrails
   ```
3. Add or edit supporting scripts, templates, and documents referenced by your instructions.
4. Add an entry to `.claude-plugin/marketplace.json` with a concise, human-readable description.
5. Run:
   ```bash
   ./scripts/publish.sh
   ```
   to regenerate and validate all generated metadata.
6. Reinstall or reload the skill bundle in your coding agent so the updated folder is available.

### Marketplace

The `.claude-plugin/marketplace.json` file lists skills with human-readable descriptions for the plugin marketplace. The CI validates that skill names and paths match between `SKILL.md` files and `marketplace.json`, but descriptions are maintained separately: `SKILL.md` descriptions guide when Claude activates the skill, while marketplace descriptions are written for humans browsing available skills.

### Additional references
- Browse the latest instructions, scripts, and templates directly at [huggingface/skills](https://github.com/huggingface/skills).
- Review Hugging Face documentation for the specific libraries or workflows you reference inside each skill.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[RichardAtCT/claude-code-telegram]]></title>
            <link>https://github.com/RichardAtCT/claude-code-telegram</link>
            <guid>https://github.com/RichardAtCT/claude-code-telegram</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:58 GMT</pubDate>
            <description><![CDATA[A powerful Telegram bot that provides remote access to Claude Code, enabling developers to interact with their projects from anywhere with full AI assistance and session persistence.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/RichardAtCT/claude-code-telegram">RichardAtCT/claude-code-telegram</a></h1>
            <p>A powerful Telegram bot that provides remote access to Claude Code, enabling developers to interact with their projects from anywhere with full AI assistance and session persistence.</p>
            <p>Language: Python</p>
            <p>Stars: 1,381</p>
            <p>Forks: 170</p>
            <p>Stars today: 109 stars today</p>
            <h2>README</h2><pre># Claude Code Telegram Bot

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)

A Telegram bot that gives you remote access to [Claude Code](https://claude.ai/code). Chat naturally with Claude about your projects from anywhere -- no terminal commands needed.

## What is this?

This bot connects Telegram to Claude Code, providing a conversational AI interface for your codebase:

- **Chat naturally** -- ask Claude to analyze, edit, or explain your code in plain language
- **Maintain context** across conversations with automatic session persistence per project
- **Code on the go** from any device with Telegram
- **Receive proactive notifications** from webhooks, scheduled jobs, and CI/CD events
- **Stay secure** with built-in authentication, directory sandboxing, and audit logging

## Quick Start

### Demo

```
You: Can you help me add error handling to src/api.py?

Bot: I&#039;ll analyze src/api.py and add error handling...
     [Claude reads your code, suggests improvements, and can apply changes directly]

You: Looks good. Now run the tests to make sure nothing broke.

Bot: Running pytest...
     All 47 tests passed. The error handling changes are working correctly.
```

### 1. Prerequisites

- **Python 3.11+** -- [Download here](https://www.python.org/downloads/)
- **Claude Code CLI** -- [Install from here](https://claude.ai/code)
- **Telegram Bot Token** -- Get one from [@BotFather](https://t.me/botfather)

### 2. Install

Choose your preferred method:

#### Option A: Install from a release tag (Recommended)

```bash
# Using uv (recommended ‚Äî installs in an isolated environment)
uv tool install git+https://github.com/RichardAtCT/claude-code-telegram@v1.3.0

# Or using pip
pip install git+https://github.com/RichardAtCT/claude-code-telegram@v1.3.0

# Track the latest stable release
pip install git+https://github.com/RichardAtCT/claude-code-telegram@latest
```

#### Option B: From source (for development)

```bash
git clone https://github.com/RichardAtCT/claude-code-telegram.git
cd claude-code-telegram
make dev  # requires Poetry
```

&gt; **Note:** Always install from a tagged release (not `main`) for stability. See [Releases](https://github.com/RichardAtCT/claude-code-telegram/releases) for available versions.

### 3. Configure

```bash
cp .env.example .env
# Edit .env with your settings:
```

**Minimum required:**
```bash
TELEGRAM_BOT_TOKEN=1234567890:ABC-DEF1234ghIkl-zyx57W2v1u123ew11
TELEGRAM_BOT_USERNAME=my_claude_bot
APPROVED_DIRECTORY=/Users/yourname/projects
ALLOWED_USERS=123456789  # Your Telegram user ID
```

### 4. Run

```bash
make run          # Production
make run-debug    # With debug logging
```

Message your bot on Telegram to get started.

&gt; **Detailed setup:** See [docs/setup.md](docs/setup.md) for Claude authentication options and troubleshooting.

## Modes

The bot supports two interaction modes:

### Agentic Mode (Default)

The default conversational mode. Just talk to Claude naturally -- no special commands required.

**Commands:** `/start`, `/new`, `/status`, `/verbose`, `/repo`
If `ENABLE_PROJECT_THREADS=true`: `/sync_threads`

```
You: What files are in this project?
Bot: Working... (3s)
     üìñ Read
     üìÇ LS
     üí¨ Let me describe the project structure
Bot: [Claude describes the project structure]

You: Add a retry decorator to the HTTP client
Bot: Working... (8s)
     üìñ Read: http_client.py
     üí¨ I&#039;ll add a retry decorator with exponential backoff
     ‚úèÔ∏è Edit: http_client.py
     üíª Bash: poetry run pytest tests/ -v
Bot: [Claude shows the changes and test results]

You: /verbose 0
Bot: Verbosity set to 0 (quiet)
```

Use `/verbose 0|1|2` to control how much background activity is shown:

| Level | Shows |
|-------|-------|
| **0** (quiet) | Final response only (typing indicator stays active) |
| **1** (normal, default) | Tool names + reasoning snippets in real-time |
| **2** (detailed) | Tool names with inputs + longer reasoning text |

#### GitHub Workflow

Claude Code already knows how to use `gh` CLI and `git`. Authenticate on your server with `gh auth login`, then work with repos conversationally:

```
You: List my repos related to monitoring
Bot: [Claude runs gh repo list, shows results]

You: Clone the uptime one
Bot: [Claude runs gh repo clone, clones into workspace]

You: /repo
Bot: üì¶ uptime-monitor/  ‚óÄ
     üìÅ other-project/

You: Show me the open issues
Bot: [Claude runs gh issue list]

You: Create a fix branch and push it
Bot: [Claude creates branch, commits, pushes]
```

Use `/repo` to list cloned repos in your workspace, or `/repo &lt;name&gt;` to switch directories (sessions auto-resume).

### Classic Mode

Set `AGENTIC_MODE=false` to enable the full 13-command terminal-like interface with directory navigation, inline keyboards, quick actions, git integration, and session export.

**Commands:** `/start`, `/help`, `/new`, `/continue`, `/end`, `/status`, `/cd`, `/ls`, `/pwd`, `/projects`, `/export`, `/actions`, `/git`  
If `ENABLE_PROJECT_THREADS=true`: `/sync_threads`

```
You: /cd my-web-app
Bot: Directory changed to my-web-app/

You: /ls
Bot: src/  tests/  package.json  README.md

You: /actions
Bot: [Run Tests] [Install Deps] [Format Code] [Run Linter]
```

## Event-Driven Automation

Beyond direct chat, the bot can respond to external triggers:

- **Webhooks** -- Receive GitHub events (push, PR, issues) and route them through Claude for automated summaries or code review
- **Scheduler** -- Run recurring Claude tasks on a cron schedule (e.g., daily code health checks)
- **Notifications** -- Deliver agent responses to configured Telegram chats

Enable with `ENABLE_API_SERVER=true` and `ENABLE_SCHEDULER=true`. See [docs/setup.md](docs/setup.md) for configuration.

## Features

### Working Features

- Conversational agentic mode (default) with natural language interaction
- Classic terminal-like mode with 13 commands and inline keyboards
- Full Claude Code integration with SDK (primary) and CLI (fallback)
- Automatic session persistence per user/project directory
- Multi-layer authentication (whitelist + optional token-based)
- Rate limiting with token bucket algorithm
- Directory sandboxing with path traversal prevention
- File upload handling with archive extraction
- Image/screenshot upload with analysis
- Git integration with safe repository operations
- Quick actions system with context-aware buttons
- Session export in Markdown, HTML, and JSON formats
- SQLite persistence with migrations
- Usage and cost tracking
- Audit logging and security event tracking
- Event bus for decoupled message routing
- Webhook API server (GitHub HMAC-SHA256, generic Bearer token auth)
- Job scheduler with cron expressions and persistent storage
- Notification service with per-chat rate limiting

- Tunable verbose output showing Claude&#039;s tool usage and reasoning in real-time
- Persistent typing indicator so users always know the bot is working
- 16 configurable tools with allowlist/disallowlist control (see [docs/tools.md](docs/tools.md))

### Planned Enhancements

- Plugin system for third-party extensions

## Configuration

### Required

```bash
TELEGRAM_BOT_TOKEN=...           # From @BotFather
TELEGRAM_BOT_USERNAME=...        # Your bot&#039;s username
APPROVED_DIRECTORY=...           # Base directory for project access
ALLOWED_USERS=123456789          # Comma-separated Telegram user IDs
```

### Common Options

```bash
# Claude
ANTHROPIC_API_KEY=sk-ant-...     # API key (optional if using CLI auth)
CLAUDE_MAX_COST_PER_USER=10.0    # Spending limit per user (USD)
CLAUDE_TIMEOUT_SECONDS=300       # Operation timeout

# Mode
AGENTIC_MODE=true                # Agentic (default) or classic mode
VERBOSE_LEVEL=1                  # 0=quiet, 1=normal (default), 2=detailed

# Rate Limiting
RATE_LIMIT_REQUESTS=10           # Requests per window
RATE_LIMIT_WINDOW=60             # Window in seconds

# Features (classic mode)
ENABLE_GIT_INTEGRATION=true
ENABLE_FILE_UPLOADS=true
ENABLE_QUICK_ACTIONS=true
```

### Agentic Platform

```bash
# Webhook API Server
ENABLE_API_SERVER=false          # Enable FastAPI webhook server
API_SERVER_PORT=8080             # Server port

# Webhook Authentication
GITHUB_WEBHOOK_SECRET=...        # GitHub HMAC-SHA256 secret
WEBHOOK_API_SECRET=...           # Bearer token for generic providers

# Scheduler
ENABLE_SCHEDULER=false           # Enable cron job scheduler

# Notifications
NOTIFICATION_CHAT_IDS=123,456    # Default chat IDs for proactive notifications
```

### Project Threads Mode

```bash
# Enable strict topic routing by project
ENABLE_PROJECT_THREADS=true

# Mode: private (default) or group
PROJECT_THREADS_MODE=private

# YAML registry file (see config/projects.example.yaml)
PROJECTS_CONFIG_PATH=config/projects.yaml

# Required only when PROJECT_THREADS_MODE=group
PROJECT_THREADS_CHAT_ID=-1001234567890

# Minimum delay (seconds) between Telegram API calls during topic sync
# Set 0 to disable pacing
PROJECT_THREADS_SYNC_ACTION_INTERVAL_SECONDS=1.1
```

In strict mode, only `/start` and `/sync_threads` work outside mapped project topics.
In private mode, `/start` auto-syncs project topics for your private bot chat.
To use topics with your bot, enable them in BotFather:
`Bot Settings -&gt; Threaded mode`.

&gt; **Full reference:** See [docs/configuration.md](docs/configuration.md) and [`.env.example`](.env.example).

### Finding Your Telegram User ID

Message [@userinfobot](https://t.me/userinfobot) on Telegram -- it will reply with your user ID number.

## Troubleshooting

**Bot doesn&#039;t respond:**
- Check your `TELEGRAM_BOT_TOKEN` is correct
- Verify your user ID is in `ALLOWED_USERS`
- Ensure Claude Code CLI is installed and accessible
- Check bot logs with `make run-debug`

**Claude integration not working:**
- SDK mode (default): Check `claude auth status` or verify `ANTHROPIC_API_KEY`
- CLI mode: Verify `claude --version` and `claude auth status`
- Check `CLAUDE_ALLOWED_TOOLS` includes necessary tools (see [docs/tools.md](docs/tools.md) for the full reference)

**High usage costs:**
- Adjust `CLAUDE_MAX_COST_PER_USER` to set spending limits
- Monitor usage with `/status`
- Use shorter, more focused requests

## Security

This bot implements defense-in-depth security:

- **Access Control** -- Whitelist-based user authentication
- **Directory Isolation** -- Sandboxing to approved directories
- **Rate Limiting** -- Request and cost-based limits
- **Input Validation** -- Injection and path traversal protection
- **Webhook Authentication** -- GitHub HMAC-SHA256 and Bearer token verification
- **Audit Logging** -- Complete tracking of all user actions

See [SECURITY.md](SECURITY.md) for details.

## Development

```bash
make dev           # Install all dependencies
make test          # Run tests with coverage
make lint          # Black + isort + flake8 + mypy
make format        # Auto-format code
make run-debug     # Run with debug logging
```

### Version Management

The version is defined once in `pyproject.toml` and read at runtime via `importlib.metadata`. To cut a release:

```bash
make bump-patch    # 1.2.0 -&gt; 1.2.1 (bug fixes)
make bump-minor    # 1.2.0 -&gt; 1.3.0 (new features)
make bump-major    # 1.2.0 -&gt; 2.0.0 (breaking changes)
```

Each command commits, tags, and pushes automatically, triggering CI tests and a GitHub Release with auto-generated notes.

### Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make changes with tests: `make test &amp;&amp; make lint`
4. Submit a Pull Request

**Code standards:** Python 3.11+, Black formatting (88 chars), type hints required, pytest with &gt;85% coverage.

## License

MIT License -- see [LICENSE](LICENSE).

## Acknowledgments

- [Claude](https://claude.ai) by Anthropic
- [python-telegram-bot](https://github.com/python-telegram-bot/python-telegram-bot)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[oppia/oppia]]></title>
            <link>https://github.com/oppia/oppia</link>
            <guid>https://github.com/oppia/oppia</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:57 GMT</pubDate>
            <description><![CDATA[A free, online learning platform to make quality education accessible for all.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/oppia/oppia">oppia/oppia</a></h1>
            <p>A free, online learning platform to make quality education accessible for all.</p>
            <p>Language: Python</p>
            <p>Stars: 6,527</p>
            <p>Forks: 5,361</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[microsoft/agent-framework]]></title>
            <link>https://github.com/microsoft/agent-framework</link>
            <guid>https://github.com/microsoft/agent-framework</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:56 GMT</pubDate>
            <description><![CDATA[A framework for building, orchestrating and deploying AI agents and multi-agent workflows with support for Python and .NET.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/agent-framework">microsoft/agent-framework</a></h1>
            <p>A framework for building, orchestrating and deploying AI agents and multi-agent workflows with support for Python and .NET.</p>
            <p>Language: Python</p>
            <p>Stars: 7,336</p>
            <p>Forks: 1,194</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre>![Microsoft Agent Framework](docs/assets/readme-banner.png)

# Welcome to Microsoft Agent Framework!

[![Microsoft Azure AI Foundry Discord](https://dcbadge.limes.pink/api/server/b5zjErwbQM?style=flat)](https://discord.gg/b5zjErwbQM)
[![MS Learn Documentation](https://img.shields.io/badge/MS%20Learn-Documentation-blue)](https://learn.microsoft.com/en-us/agent-framework/)
[![PyPI](https://img.shields.io/pypi/v/agent-framework)](https://pypi.org/project/agent-framework/)
[![NuGet](https://img.shields.io/nuget/v/Microsoft.Agents.AI)](https://www.nuget.org/profiles/MicrosoftAgentFramework/)

Welcome to Microsoft&#039;s comprehensive multi-language framework for building, orchestrating, and deploying AI agents with support for both .NET and Python implementations. This framework provides everything from simple chat agents to complex multi-agent workflows with graph-based orchestration.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=AAgdMhftj8w&quot; title=&quot;Watch the full Agent Framework introduction (30 min)&quot;&gt;
    &lt;img src=&quot;https://img.youtube.com/vi/AAgdMhftj8w/hqdefault.jpg&quot;
         alt=&quot;Watch the full Agent Framework introduction (30 min)&quot; width=&quot;480&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=AAgdMhftj8w&quot;&gt;
    Watch the full Agent Framework introduction (30 min)
  &lt;/a&gt;
&lt;/p&gt;

## üìã Getting Started

### üì¶ Installation

Python

```bash
pip install agent-framework --pre
# This will install all sub-packages, see `python/packages` for individual packages.
# It may take a minute on first install on Windows.
```

.NET

```bash
dotnet add package Microsoft.Agents.AI
```

### üìö Documentation

- **[Overview](https://learn.microsoft.com/agent-framework/overview/agent-framework-overview)** - High level overview of the framework
- **[Quick Start](https://learn.microsoft.com/agent-framework/tutorials/quick-start)** - Get started with a simple agent
- **[Tutorials](https://learn.microsoft.com/agent-framework/tutorials/overview)** - Step by step tutorials
- **[User Guide](https://learn.microsoft.com/en-us/agent-framework/user-guide/overview)** - In-depth user guide for building agents and workflows
- **[Migration from Semantic Kernel](https://learn.microsoft.com/en-us/agent-framework/migration-guide/from-semantic-kernel)** - Guide to migrate from Semantic Kernel
- **[Migration from AutoGen](https://learn.microsoft.com/en-us/agent-framework/migration-guide/from-autogen)** - Guide to migrate from AutoGen

Still have questions? Join our [weekly office hours](./COMMUNITY.md#public-community-office-hours) or ask questions in our [Discord channel](https://discord.gg/b5zjErwbQM) to get help from the team and other users.

### ‚ú® **Highlights**

- **Graph-based Workflows**: Connect agents and deterministic functions using data flows with streaming, checkpointing, human-in-the-loop, and time-travel capabilities
  - [Python workflows](./python/samples/03-workflows/) | [.NET workflows](./dotnet/samples/GettingStarted/Workflows/)
- **AF Labs**: Experimental packages for cutting-edge features including benchmarking, reinforcement learning, and research initiatives
  - [Labs directory](./python/packages/lab/)
- **DevUI**: Interactive developer UI for agent development, testing, and debugging workflows
  - [DevUI package](./python/packages/devui/)

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=mOAaGY4WPvc&quot;&gt;
    &lt;img src=&quot;https://img.youtube.com/vi/mOAaGY4WPvc/hqdefault.jpg&quot; alt=&quot;See the DevUI in action&quot; width=&quot;480&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=mOAaGY4WPvc&quot;&gt;
    See the DevUI in action (1 min)
  &lt;/a&gt;
&lt;/p&gt;

- **Python and C#/.NET Support**: Full framework support for both Python and C#/.NET implementations with consistent APIs
  - [Python packages](./python/packages/) | [.NET source](./dotnet/src/)
- **Observability**: Built-in OpenTelemetry integration for distributed tracing, monitoring, and debugging
  - [Python observability](./python/samples/02-agents/observability/) | [.NET telemetry](./dotnet/samples/GettingStarted/AgentOpenTelemetry/)
- **Multiple Agent Provider Support**: Support for various LLM providers with more being added continuously
  - [Python examples](./python/samples/02-agents/providers/) | [.NET examples](./dotnet/samples/GettingStarted/AgentProviders/)
- **Middleware**: Flexible middleware system for request/response processing, exception handling, and custom pipelines
  - [Python middleware](./python/samples/02-agents/middleware/) | [.NET middleware](./dotnet/samples/GettingStarted/Agents/Agent_Step14_Middleware/)

### üí¨ **We want your feedback!**

- For bugs, please file a [GitHub issue](https://github.com/microsoft/agent-framework/issues).

## Quickstart

### Basic Agent - Python

Create a simple Azure Responses Agent that writes a haiku about the Microsoft Agent Framework

```python
# pip install agent-framework --pre
# Use `az login` to authenticate with Azure CLI
import os
import asyncio
from agent_framework.azure import AzureOpenAIResponsesClient
from azure.identity import AzureCliCredential


async def main():
    # Initialize a chat agent with Azure OpenAI Responses
    # the endpoint, deployment name, and api version can be set via environment variables
    # or they can be passed in directly to the AzureOpenAIResponsesClient constructor
    agent = AzureOpenAIResponsesClient(
        # endpoint=os.environ[&quot;AZURE_OPENAI_ENDPOINT&quot;],
        # deployment_name=os.environ[&quot;AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME&quot;],
        # api_version=os.environ[&quot;AZURE_OPENAI_API_VERSION&quot;],
        # api_key=os.environ[&quot;AZURE_OPENAI_API_KEY&quot;],  # Optional if using AzureCliCredential
        credential=AzureCliCredential(), # Optional, if using api_key
    ).as_agent(
        name=&quot;HaikuBot&quot;,
        instructions=&quot;You are an upbeat assistant that writes beautifully.&quot;,
    )

    print(await agent.run(&quot;Write a haiku about Microsoft Agent Framework.&quot;))

if __name__ == &quot;__main__&quot;:
    asyncio.run(main())
```

### Basic Agent - .NET

Create a simple Agent, using OpenAI Responses, that writes a haiku about the Microsoft Agent Framework

```c#
// dotnet add package Microsoft.Agents.AI.OpenAI --prerelease
using Microsoft.Agents.AI;
using OpenAI;
using OpenAI.Responses;

// Replace the &lt;apikey&gt; with your OpenAI API key.
var agent = new OpenAIClient(&quot;&lt;apikey&gt;&quot;)
    .GetResponsesClient(&quot;gpt-4o-mini&quot;)
    .AsAIAgent(name: &quot;HaikuBot&quot;, instructions: &quot;You are an upbeat assistant that writes beautifully.&quot;);

Console.WriteLine(await agent.RunAsync(&quot;Write a haiku about Microsoft Agent Framework.&quot;));
```

Create a simple Agent, using Azure OpenAI Responses with token based auth, that writes a haiku about the Microsoft Agent Framework

```c#
// dotnet add package Microsoft.Agents.AI.OpenAI --prerelease
// dotnet add package Azure.Identity
// Use `az login` to authenticate with Azure CLI
using System.ClientModel.Primitives;
using Azure.Identity;
using Microsoft.Agents.AI;
using OpenAI;
using OpenAI.Responses;

// Replace &lt;resource&gt; and gpt-4o-mini with your Azure OpenAI resource name and deployment name.
var agent = new OpenAIClient(
    new BearerTokenPolicy(new AzureCliCredential(), &quot;https://ai.azure.com/.default&quot;),
    new OpenAIClientOptions() { Endpoint = new Uri(&quot;https://&lt;resource&gt;.openai.azure.com/openai/v1&quot;) })
    .GetResponsesClient(&quot;gpt-4o-mini&quot;)
    .AsAIAgent(name: &quot;HaikuBot&quot;, instructions: &quot;You are an upbeat assistant that writes beautifully.&quot;);

Console.WriteLine(await agent.RunAsync(&quot;Write a haiku about Microsoft Agent Framework.&quot;));
```

## More Examples &amp; Samples

### Python

- [Getting Started with Agents](./python/samples/01-get-started): progressive tutorial from hello-world to hosting
- [Agent Concepts](./python/samples/02-agents): deep-dive samples by topic (tools, middleware, providers, etc.)
- [Getting Started with Workflows](./python/samples/03-workflows): workflow creation and integration with agents

### .NET

- [Getting Started with Agents](./dotnet/samples/GettingStarted/Agents): basic agent creation and tool usage
- [Agent Provider Samples](./dotnet/samples/GettingStarted/AgentProviders): samples showing different agent providers
- [Workflow Samples](./dotnet/samples/GettingStarted/Workflows): advanced multi-agent patterns and workflow orchestration

## Contributor Resources

- [Contributing Guide](./CONTRIBUTING.md)
- [Python Development Guide](./python/DEV_SETUP.md)
- [Design Documents](./docs/design)
- [Architectural Decision Records](./docs/decisions)

## Important Notes

If you use the Microsoft Agent Framework to build applications that operate with third-party servers or agents, you do so at your own risk. We recommend reviewing all data being shared with third-party servers or agents and being cognizant of third-party practices for retention and location of data. It is your responsibility to manage whether your data will flow outside of your organization&#039;s Azure compliance and geographic boundaries and any related implications.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[google-research/timesfm]]></title>
            <link>https://github.com/google-research/timesfm</link>
            <guid>https://github.com/google-research/timesfm</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:55 GMT</pubDate>
            <description><![CDATA[TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google-research/timesfm">google-research/timesfm</a></h1>
            <p>TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting.</p>
            <p>Language: Python</p>
            <p>Stars: 9,137</p>
            <p>Forks: 761</p>
            <p>Stars today: 306 stars today</p>
            <h2>README</h2><pre># TimesFM

TimesFM (Time Series Foundation Model) is a pretrained time-series foundation
model developed by Google Research for time-series forecasting.

*   Paper:
    [A decoder-only foundation model for time-series forecasting](https://arxiv.org/abs/2310.10688),
    ICML 2024.
*   All checkpoints:
    [TimesFM Hugging Face Collection](https://huggingface.co/collections/google/timesfm-release-66e4be5fdb56e960c1e482a6).
*   [Google Research blog](https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/).
*   [TimesFM in BigQuery](https://cloud.google.com/bigquery/docs/timesfm-model):
    an official Google product.

This open version is not an officially supported Google product.

**Latest Model Version:** TimesFM 2.5

**Archived Model Versions:**

-   1.0 and 2.0: relevant code archived in the sub directory `v1`. You can `pip
    install timesfm==1.3.0` to install an older version of this package to load
    them.

## Update - Oct. 29, 2025

Added back the covariate support through XReg for TimesFM 2.5.


## Update - Sept. 15, 2025

TimesFM 2.5 is out!

Comparing to TimesFM 2.0, this new 2.5 model:

-   uses 200M parameters, down from 500M.
-   supports up to 16k context length, up from 2048.
-   supports continuous quantile forecast up to 1k horizon via an optional 30M
    quantile head.
-   gets rid of the `frequency` indicator.
-   has a couple of new forecasting flags.

Along with the model upgrade we have also upgraded the inference API. This repo
will be under construction over the next few weeks to

1.  add support for an upcoming Flax version of the model (faster inference).
2.  add back covariate support.
3.  populate more docstrings, docs and notebook.

### Install

1.  Clone the repository:
    ```shell
    git clone https://github.com/google-research/timesfm.git
    cd timesfm
    ```

2.  Create a virtual environment and install dependencies using `uv`:
    ```shell
    # Create a virtual environment
    uv venv
    
    # Activate the environment
    source .venv/bin/activate
    
    # Install the package in editable mode with torch
    uv pip install -e .[torch]
    # Or with flax
    uv pip install -e .[flax]
    # Or XReg is needed
    uv pip install -e .[xreg]
    ```

3. [Optional] Install your preferred `torch` / `jax` backend based on your OS and accelerators
(CPU, GPU, TPU or Apple Silicon).:

-   [Install PyTorch](https://pytorch.org/get-started/locally/).
-   [Install Jax](https://docs.jax.dev/en/latest/installation.html#installation)
    for Flax.

### Code Example

```python
import torch
import numpy as np
import timesfm

torch.set_float32_matmul_precision(&quot;high&quot;)

model = timesfm.TimesFM_2p5_200M_torch.from_pretrained(&quot;google/timesfm-2.5-200m-pytorch&quot;)

model.compile(
    timesfm.ForecastConfig(
        max_context=1024,
        max_horizon=256,
        normalize_inputs=True,
        use_continuous_quantile_head=True,
        force_flip_invariance=True,
        infer_is_positive=True,
        fix_quantile_crossing=True,
    )
)
point_forecast, quantile_forecast = model.forecast(
    horizon=12,
    inputs=[
        np.linspace(0, 1, 100),
        np.sin(np.linspace(0, 20, 67)),
    ],  # Two dummy inputs
)
point_forecast.shape  # (2, 12)
quantile_forecast.shape  # (2, 12, 10): mean, then 10th to 90th quantiles.
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[usestrix/strix]]></title>
            <link>https://github.com/usestrix/strix</link>
            <guid>https://github.com/usestrix/strix</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:54 GMT</pubDate>
            <description><![CDATA[Open-source AI hackers to find and fix your app‚Äôs vulnerabilities.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/usestrix/strix">usestrix/strix</a></h1>
            <p>Open-source AI hackers to find and fix your app‚Äôs vulnerabilities.</p>
            <p>Language: Python</p>
            <p>Stars: 20,340</p>
            <p>Forks: 2,126</p>
            <p>Stars today: 137 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://strix.ai/&quot;&gt;
    &lt;img src=&quot;https://github.com/usestrix/.github/raw/main/imgs/cover.png&quot; alt=&quot;Strix Banner&quot; width=&quot;100%&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

# Strix

### Open-source AI hackers to find and fix your app‚Äôs vulnerabilities.

&lt;br/&gt;


&lt;a href=&quot;https://docs.strix.ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-docs.strix.ai-2b9246?style=for-the-badge&amp;logo=gitbook&amp;logoColor=white&quot; alt=&quot;Docs&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://strix.ai&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Website-strix.ai-f0f0f0?style=for-the-badge&amp;logoColor=000000&quot; alt=&quot;Website&quot;&gt;&lt;/a&gt;
[![](https://dcbadge.limes.pink/api/server/8Suzzd9z)](https://discord.gg/strix-ai)

&lt;a href=&quot;https://deepwiki.com/usestrix/strix&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/usestrix/strix&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/usestrix/strix?style=flat-square&quot; alt=&quot;GitHub Stars&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-Apache%202.0-3b82f6?style=flat-square&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://pypi.org/project/strix-agent/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/strix-agent?style=flat-square&quot; alt=&quot;PyPI Version&quot;&gt;&lt;/a&gt;


&lt;a href=&quot;https://discord.gg/strix-ai&quot;&gt;&lt;img src=&quot;https://github.com/usestrix/.github/raw/main/imgs/Discord.png&quot; height=&quot;40&quot; alt=&quot;Join Discord&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://x.com/strix_ai&quot;&gt;&lt;img src=&quot;https://github.com/usestrix/.github/raw/main/imgs/X.png&quot; height=&quot;40&quot; alt=&quot;Follow on X&quot;&gt;&lt;/a&gt;


&lt;a href=&quot;https://trendshift.io/repositories/15362&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/15362&quot; alt=&quot;usestrix/strix | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;/div&gt;


&gt; [!TIP]
&gt; **New!** Strix integrates seamlessly with GitHub Actions and CI/CD pipelines. Automatically scan for vulnerabilities on every pull request and block insecure code before it reaches production!

---


## Strix Overview

Strix are autonomous AI agents that act just like real hackers - they run your code dynamically, find vulnerabilities, and validate them through actual proof-of-concepts. Built for developers and security teams who need fast, accurate security testing without the overhead of manual pentesting or the false positives of static analysis tools.

**Key Capabilities:**

- **Full hacker toolkit** out of the box
- **Teams of agents** that collaborate and scale
- **Real validation** with PoCs, not false positives
- **Developer‚Äëfirst** CLI with actionable reports
- **Auto‚Äëfix &amp; reporting** to accelerate remediation


&lt;br&gt;


&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://strix.ai&quot;&gt;
    &lt;img src=&quot;.github/screenshot.png&quot; alt=&quot;Strix Demo&quot; width=&quot;1000&quot; style=&quot;border-radius: 16px;&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;


## Use Cases

- **Application Security Testing** - Detect and validate critical vulnerabilities in your applications
- **Rapid Penetration Testing** - Get penetration tests done in hours, not weeks, with compliance reports
- **Bug Bounty Automation** - Automate bug bounty research and generate PoCs for faster reporting
- **CI/CD Integration** - Run tests in CI/CD to block vulnerabilities before reaching production

## üöÄ Quick Start

**Prerequisites:**
- Docker (running)
- An LLM API key:
  - Any [supported provider](https://docs.strix.ai/llm-providers/overview) (OpenAI, Anthropic, Google, etc.)
  - Or [Strix Router](https://models.strix.ai) ‚Äî single API key for multiple providers with $10 free credit on signup

### Installation &amp; First Scan

```bash
# Install Strix
curl -sSL https://strix.ai/install | bash

# Configure your AI provider
export STRIX_LLM=&quot;openai/gpt-5&quot;  # or &quot;strix/gpt-5&quot; via Strix Router (https://models.strix.ai)
export LLM_API_KEY=&quot;your-api-key&quot;

# Run your first security assessment
strix --target ./app-directory
```

&gt; [!NOTE]
&gt; First run automatically pulls the sandbox Docker image. Results are saved to `strix_runs/&lt;run-name&gt;`

---

## ‚ú® Features

### Agentic Security Tools

Strix agents come equipped with a comprehensive security testing toolkit:

- **Full HTTP Proxy** - Full request/response manipulation and analysis
- **Browser Automation** - Multi-tab browser for testing of XSS, CSRF, auth flows
- **Terminal Environments** - Interactive shells for command execution and testing
- **Python Runtime** - Custom exploit development and validation
- **Reconnaissance** - Automated OSINT and attack surface mapping
- **Code Analysis** - Static and dynamic analysis capabilities
- **Knowledge Management** - Structured findings and attack documentation

### Comprehensive Vulnerability Detection

Strix can identify and validate a wide range of security vulnerabilities:

- **Access Control** - IDOR, privilege escalation, auth bypass
- **Injection Attacks** - SQL, NoSQL, command injection
- **Server-Side** - SSRF, XXE, deserialization flaws
- **Client-Side** - XSS, prototype pollution, DOM vulnerabilities
- **Business Logic** - Race conditions, workflow manipulation
- **Authentication** - JWT vulnerabilities, session management
- **Infrastructure** - Misconfigurations, exposed services

### Graph of Agents

Advanced multi-agent orchestration for comprehensive security testing:

- **Distributed Workflows** - Specialized agents for different attacks and assets
- **Scalable Testing** - Parallel execution for fast comprehensive coverage
- **Dynamic Coordination** - Agents collaborate and share discoveries

---

## Usage Examples

### Basic Usage

```bash
# Scan a local codebase
strix --target ./app-directory

# Security review of a GitHub repository
strix --target https://github.com/org/repo

# Black-box web application assessment
strix --target https://your-app.com
```

### Advanced Testing Scenarios

```bash
# Grey-box authenticated testing
strix --target https://your-app.com --instruction &quot;Perform authenticated testing using credentials: user:pass&quot;

# Multi-target testing (source code + deployed app)
strix -t https://github.com/org/app -t https://your-app.com

# Focused testing with custom instructions
strix --target api.your-app.com --instruction &quot;Focus on business logic flaws and IDOR vulnerabilities&quot;

# Provide detailed instructions through file (e.g., rules of engagement, scope, exclusions)
strix --target api.your-app.com --instruction-file ./instruction.md
```

### Headless Mode

Run Strix programmatically without interactive UI using the `-n/--non-interactive` flag‚Äîperfect for servers and automated jobs. The CLI prints real-time vulnerability findings, and the final report before exiting. Exits with non-zero code when vulnerabilities are found.

```bash
strix -n --target https://your-app.com
```

### CI/CD (GitHub Actions)

Strix can be added to your pipeline to run a security test on pull requests with a lightweight GitHub Actions workflow:

```yaml
name: strix-penetration-test

on:
  pull_request:

jobs:
  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Install Strix
        run: curl -sSL https://strix.ai/install | bash

      - name: Run Strix
        env:
          STRIX_LLM: ${{ secrets.STRIX_LLM }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}

        run: strix -n -t ./ --scan-mode quick
```

### Configuration

```bash
export STRIX_LLM=&quot;openai/gpt-5&quot;
export LLM_API_KEY=&quot;your-api-key&quot;

# Optional
export LLM_API_BASE=&quot;your-api-base-url&quot;  # if using a local model, e.g. Ollama, LMStudio
export PERPLEXITY_API_KEY=&quot;your-api-key&quot;  # for search capabilities
export STRIX_REASONING_EFFORT=&quot;high&quot;  # control thinking effort (default: high, quick scan: medium)
```

&gt; [!NOTE]
&gt; Strix automatically saves your configuration to `~/.strix/cli-config.json`, so you don&#039;t have to re-enter it on every run.

**Recommended models for best results:**

- [OpenAI GPT-5](https://openai.com/api/) ‚Äî `openai/gpt-5`
- [Anthropic Claude Sonnet 4.6](https://claude.com/platform/api) ‚Äî `anthropic/claude-sonnet-4-6`
- [Google Gemini 3 Pro Preview](https://cloud.google.com/vertex-ai) ‚Äî `vertex_ai/gemini-3-pro-preview`

See the [LLM Providers documentation](https://docs.strix.ai/llm-providers/overview) for all supported providers including Vertex AI, Bedrock, Azure, and local models.

## Documentation

Full documentation is available at **[docs.strix.ai](https://docs.strix.ai)** ‚Äî including detailed guides for usage, CI/CD integrations, skills, and advanced configuration.

## Contributing

We welcome contributions of code, docs, and new skills - check out our [Contributing Guide](https://docs.strix.ai/contributing) to get started or open a [pull request](https://github.com/usestrix/strix/pulls)/[issue](https://github.com/usestrix/strix/issues).

## Join Our Community

Have questions? Found a bug? Want to contribute? **[Join our Discord!](https://discord.gg/strix-ai)**

## Support the Project

**Love Strix?** Give us a ‚≠ê on GitHub!

## Acknowledgements

Strix builds on the incredible work of open-source projects like [LiteLLM](https://github.com/BerriAI/litellm), [Caido](https://github.com/caido/caido), [Nuclei](https://github.com/projectdiscovery/nuclei), [Playwright](https://github.com/microsoft/playwright), and [Textual](https://github.com/Textualize/textual). Huge thanks to their maintainers!


&gt; [!WARNING]
&gt; Only test apps you own or have permission to test. You are responsible for using Strix ethically and legally.

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[github/spec-kit]]></title>
            <link>https://github.com/github/spec-kit</link>
            <guid>https://github.com/github/spec-kit</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:53 GMT</pubDate>
            <description><![CDATA[üí´ Toolkit to help you get started with Spec-Driven Development]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/spec-kit">github/spec-kit</a></h1>
            <p>üí´ Toolkit to help you get started with Spec-Driven Development</p>
            <p>Language: Python</p>
            <p>Stars: 71,022</p>
            <p>Forks: 6,129</p>
            <p>Stars today: 186 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;./media/logo_large.webp&quot; alt=&quot;Spec Kit Logo&quot; width=&quot;200&quot; height=&quot;200&quot;/&gt;
    &lt;h1&gt;üå± Spec Kit&lt;/h1&gt;
    &lt;h3&gt;&lt;em&gt;Build high-quality software faster.&lt;/em&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;strong&gt;An open source toolkit that allows you to focus on product scenarios and predictable outcomes instead of vibe coding every piece from scratch.&lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/github/spec-kit/actions/workflows/release.yml&quot;&gt;&lt;img src=&quot;https://github.com/github/spec-kit/actions/workflows/release.yml/badge.svg&quot; alt=&quot;Release&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/github/spec-kit/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/github/spec-kit?style=social&quot; alt=&quot;GitHub stars&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/github/spec-kit/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/github/spec-kit&quot; alt=&quot;License&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.github.io/spec-kit/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-GitHub_Pages-blue&quot; alt=&quot;Documentation&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

---

## Table of Contents

- [ü§î What is Spec-Driven Development?](#-what-is-spec-driven-development)
- [‚ö° Get Started](#-get-started)
- [üìΩÔ∏è Video Overview](#Ô∏è-video-overview)
- [ü§ñ Supported AI Agents](#-supported-ai-agents)
- [üîß Specify CLI Reference](#-specify-cli-reference)
- [üìö Core Philosophy](#-core-philosophy)
- [üåü Development Phases](#-development-phases)
- [üéØ Experimental Goals](#-experimental-goals)
- [üîß Prerequisites](#-prerequisites)
- [üìñ Learn More](#-learn-more)
- [üìã Detailed Process](#-detailed-process)
- [üîç Troubleshooting](#-troubleshooting)
- [üí¨ Support](#-support)
- [üôè Acknowledgements](#-acknowledgements)
- [üìÑ License](#-license)

## ü§î What is Spec-Driven Development?

Spec-Driven Development **flips the script** on traditional software development. For decades, code has been king ‚Äî specifications were just scaffolding we built and discarded once the &quot;real work&quot; of coding began. Spec-Driven Development changes this: **specifications become executable**, directly generating working implementations rather than just guiding them.

## ‚ö° Get Started

### 1. Install Specify CLI

Choose your preferred installation method:

#### Option 1: Persistent Installation (Recommended)

Install once and use everywhere:

```bash
uv tool install specify-cli --from git+https://github.com/github/spec-kit.git
```

Then use the tool directly:

```bash
# Create new project
specify init &lt;PROJECT_NAME&gt;

# Or initialize in existing project
specify init . --ai claude
# or
specify init --here --ai claude

# Check installed tools
specify check
```

To upgrade Specify, see the [Upgrade Guide](./docs/upgrade.md) for detailed instructions. Quick upgrade:

```bash
uv tool install specify-cli --force --from git+https://github.com/github/spec-kit.git
```

#### Option 2: One-time Usage

Run directly without installing:

```bash
uvx --from git+https://github.com/github/spec-kit.git specify init &lt;PROJECT_NAME&gt;
```

**Benefits of persistent installation:**

- Tool stays installed and available in PATH
- No need to create shell aliases
- Better tool management with `uv tool list`, `uv tool upgrade`, `uv tool uninstall`
- Cleaner shell configuration

### 2. Establish project principles

Launch your AI assistant in the project directory. The `/speckit.*` commands are available in the assistant.

Use the **`/speckit.constitution`** command to create your project&#039;s governing principles and development guidelines that will guide all subsequent development.

```bash
/speckit.constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements
```

### 3. Create the spec

Use the **`/speckit.specify`** command to describe what you want to build. Focus on the **what** and **why**, not the tech stack.

```bash
/speckit.specify Build an application that can help me organize my photos in separate photo albums. Albums are grouped by date and can be re-organized by dragging and dropping on the main page. Albums are never in other nested albums. Within each album, photos are previewed in a tile-like interface.
```

### 4. Create a technical implementation plan

Use the **`/speckit.plan`** command to provide your tech stack and architecture choices.

```bash
/speckit.plan The application uses Vite with minimal number of libraries. Use vanilla HTML, CSS, and JavaScript as much as possible. Images are not uploaded anywhere and metadata is stored in a local SQLite database.
```

### 5. Break down into tasks

Use **`/speckit.tasks`** to create an actionable task list from your implementation plan.

```bash
/speckit.tasks
```

### 6. Execute implementation

Use **`/speckit.implement`** to execute all tasks and build your feature according to the plan.

```bash
/speckit.implement
```

For detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).

## üìΩÔ∏è Video Overview

Want to see Spec Kit in action? Watch our [video overview](https://www.youtube.com/watch?v=a9eR1xsfvHg&amp;pp=0gcJCckJAYcqIYzv)!

[![Spec Kit video header](/media/spec-kit-video-header.jpg)](https://www.youtube.com/watch?v=a9eR1xsfvHg&amp;pp=0gcJCckJAYcqIYzv)

## ü§ñ Supported AI Agents

| Agent                                                                                | Support | Notes                                                                                                                                     |
| ------------------------------------------------------------------------------------ | ------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| [Qoder CLI](https://qoder.com/cli)                                                   | ‚úÖ      |                                                                                                                                           |
| [Amazon Q Developer CLI](https://aws.amazon.com/developer/learning/q-developer-cli/) | ‚ö†Ô∏è      | Amazon Q Developer CLI [does not support](https://github.com/aws/amazon-q-developer-cli/issues/3064) custom arguments for slash commands. |
| [Amp](https://ampcode.com/)                                                          | ‚úÖ      |                                                                                                                                           |
| [Auggie CLI](https://docs.augmentcode.com/cli/overview)                              | ‚úÖ      |                                                                                                                                           |
| [Claude Code](https://www.anthropic.com/claude-code)                                 | ‚úÖ      |                                                                                                                                           |
| [CodeBuddy CLI](https://www.codebuddy.ai/cli)                                        | ‚úÖ      |                                                                                                                                           |
| [Codex CLI](https://github.com/openai/codex)                                         | ‚úÖ      |                                                                                                                                           |
| [Cursor](https://cursor.sh/)                                                         | ‚úÖ      |                                                                                                                                           |
| [Gemini CLI](https://github.com/google-gemini/gemini-cli)                            | ‚úÖ      |                                                                                                                                           |
| [GitHub Copilot](https://code.visualstudio.com/)                                     | ‚úÖ      |                                                                                                                                           |
| [IBM Bob](https://www.ibm.com/products/bob)                                          | ‚úÖ      | IDE-based agent with slash command support                                                                                                |
| [Jules](https://jules.google.com/)                                                   | ‚úÖ      |                                                                                                                                           |
| [Kilo Code](https://github.com/Kilo-Org/kilocode)                                    | ‚úÖ      |                                                                                                                                           |
| [opencode](https://opencode.ai/)                                                     | ‚úÖ      |                                                                                                                                           |
| [Qwen Code](https://github.com/QwenLM/qwen-code)                                     | ‚úÖ      |                                                                                                                                           |
| [Roo Code](https://roocode.com/)                                                     | ‚úÖ      |                                                                                                                                           |
| [SHAI (OVHcloud)](https://github.com/ovh/shai)                                       | ‚úÖ      |                                                                                                                                           |
| [Windsurf](https://windsurf.com/)                                                    | ‚úÖ      |                                                                                                                                           |
| [Antigravity (agy)](https://agy.ai/)                                                 | ‚úÖ      |                                                                                                                                           |
| Generic                                                                              | ‚úÖ      | Bring your own agent ‚Äî use `--ai generic --ai-commands-dir &lt;path&gt;` for unsupported agents                                                 |

## üîß Specify CLI Reference

The `specify` command supports the following options:

### Commands

| Command | Description                                                                                                                                             |
| ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `init`  | Initialize a new Specify project from the latest template                                                                                               |
| `check` | Check for installed tools (`git`, `claude`, `gemini`, `code`/`code-insiders`, `cursor-agent`, `windsurf`, `qwen`, `opencode`, `codex`, `shai`, `qodercli`) |

### `specify init` Arguments &amp; Options

| Argument/Option        | Type     | Description                                                                                                                                                                                  |
| ---------------------- | -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `&lt;project-name&gt;`       | Argument | Name for your new project directory (optional if using `--here`, or use `.` for current directory)                                                                                           |
| `--ai`                 | Option   | AI assistant to use: `claude`, `gemini`, `copilot`, `cursor-agent`, `qwen`, `opencode`, `codex`, `windsurf`, `kilocode`, `auggie`, `roo`, `codebuddy`, `amp`, `shai`, `q`, `agy`, `bob`, `qodercli`, or `generic` (requires `--ai-commands-dir`) |
| `--ai-commands-dir`    | Option   | Directory for agent command files (required with `--ai generic`, e.g. `.myagent/commands/`)                                                                                                  |
| `--script`             | Option   | Script variant to use: `sh` (bash/zsh) or `ps` (PowerShell)                                                                                                                                  |
| `--ignore-agent-tools` | Flag     | Skip checks for AI agent tools like Claude Code                                                                                                                                              |
| `--no-git`             | Flag     | Skip git repository initialization                                                                                                                                                           |
| `--here`               | Flag     | Initialize project in the current directory instead of creating a new one                                                                                                                    |
| `--force`              | Flag     | Force merge/overwrite when initializing in current directory (skip confirmation)                                                                                                             |
| `--skip-tls`           | Flag     | Skip SSL/TLS verification (not recommended)                                                                                                                                                  |
| `--debug`              | Flag     | Enable detailed debug output for troubleshooting                                                                                                                                             |
| `--github-token`       | Option   | GitHub token for API requests (or set GH_TOKEN/GITHUB_TOKEN env variable)                                                                                                                    |
| `--ai-skills`          | Flag     | Install Prompt.MD templates as agent skills in agent-specific `skills/` directory (requires `--ai`)                                                                                          |

### Examples

```bash
# Basic project initialization
specify init my-project

# Initialize with specific AI assistant
specify init my-project --ai claude

# Initialize with Cursor support
specify init my-project --ai cursor-agent

# Initialize with Qoder support
specify init my-project --ai qodercli

# Initialize with Windsurf support
specify init my-project --ai windsurf

# Initialize with Amp support
specify init my-project --ai amp

# Initialize with SHAI support
specify init my-project --ai shai

# Initialize with IBM Bob support
specify init my-project --ai bob

# Initialize with an unsupported agent (generic / bring your own agent)
specify init my-project --ai generic --ai-commands-dir .myagent/commands/

# Initialize with PowerShell scripts (Windows/cross-platform)
specify init my-project --ai copilot --script ps

# Initialize in current directory
specify init . --ai copilot
# or use the --here flag
specify init --here --ai copilot

# Force merge into current (non-empty) directory without confirmation
specify init . --force --ai copilot
# or
specify init --here --force --ai copilot

# Skip git initialization
specify init my-project --ai gemini --no-git

# Enable debug output for troubleshooting
specify init my-project --ai claude --debug

# Use GitHub token for API requests (helpful for corporate environments)
specify init my-project --ai claude --github-token ghp_your_token_here

# Install agent skills with the project
specify init my-project --ai claude --ai-skills

# Initialize in current directory with agent skills
specify init --here --ai gemini --ai-skills

# Check system requirements
specify check
```

### Available Slash Commands

After running `specify init`, your AI coding agent will have access to these slash commands for structured development:

#### Core Commands

Essential commands for the Spec-Driven Development workflow:

| Command                 | Description                                                              |
| ----------------------- | ------------------------------------------------------------------------ |
| `/speckit.constitution` | Create or update project governing principles and development guidelines |
| `/speckit.specify`      | Define what you want to build (requirements and user stories)            |
| `/speckit.plan`         | Create technical implementation plans with your chosen tech stack        |
| `/speckit.tasks`        | Generate actionable task lists for implementation                        |
| `/speckit.implement`    | Execute all tasks to build the feature according to the plan             |

#### Optional Commands

Additional commands for enhanced quality and validation:

| Command              | Description                                                                                                                          |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| `/speckit.clarify`   | Clarify underspecified areas (recommended before `/speckit.plan`; formerly `/quizme`)                                                |
| `/speckit.analyze`   | Cross-artifact consistency &amp; coverage analysis (run after `/speckit.tasks`, before `/speckit.implement`)                             |
| `/speckit.checklist` | Generate custom quality checklists that validate requirements completeness, clarity, and consistency (like &quot;unit tests for English&quot;) |

### Environment Variables

| Variable          | Description                                                                                                                                                                                                                                                                                            |
| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `SPECIFY_FEATURE` | Override feature detection for non-Git repositories. Set to the feature directory name (e.g., `001-photo-albums`) to work on a specific feature when not using Git branches.&lt;br/&gt;\*\*Must be set in the context of the agent you&#039;re working with prior to using `/speckit.plan` or follow-up commands. |

## üìö Core Philosophy

Spec-Driven Development is a structured process that emphasizes:

- **Intent-driven development** where specifications define the &quot;*what*&quot; before the &quot;*how*&quot;
- **Rich specification creation** using guardrails and organizational principles
- **Multi-step refinement** rather than one-shot code generation from prompts
- **Heavy reliance** on advanced AI model capabilities for specification interpretation

## üåü Development Phases

| Phase                                    | Focus                    | Key Activities                                                                                                                                                     |
| ---------------------------------------- | ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **0-to-1 Development** (&quot;Greenfield&quot;)    | Generate from scratch   

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[wagtail/wagtail]]></title>
            <link>https://github.com/wagtail/wagtail</link>
            <guid>https://github.com/wagtail/wagtail</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:52 GMT</pubDate>
            <description><![CDATA[A Django content management system focused on flexibility and user experience]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wagtail/wagtail">wagtail/wagtail</a></h1>
            <p>A Django content management system focused on flexibility and user experience</p>
            <p>Language: Python</p>
            <p>Stars: 20,182</p>
            <p>Forks: 4,434</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
    &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;.github/wagtail.svg&quot;&gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/wagtail-inverse.svg&quot;&gt;
        &lt;img width=&quot;343&quot; src=&quot;.github/wagtail.svg&quot; alt=&quot;Wagtail&quot;&gt;
    &lt;/picture&gt;
&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;br&gt;
    &lt;a href=&quot;https://github.com/wagtail/wagtail/actions&quot;&gt;
        &lt;img src=&quot;https://github.com/wagtail/wagtail/workflows/Wagtail%20CI/badge.svg&quot; alt=&quot;Build Status&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://opensource.org/licenses/BSD-3-Clause&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/license-BSD-blue.svg&quot; alt=&quot;License&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://pypi.python.org/pypi/wagtail/&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/pypi/v/wagtail.svg&quot; alt=&quot;Version&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://pypi.python.org/pypi/wagtail/&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/pypi/dm/wagtail?logo=Downloads&quot; alt=&quot;Monthly downloads&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://fosstodon.org/@wagtail&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/mastodon/follow/109308882653647818?domain=https%3A%2F%2Ffosstodon.org&amp;style=social&quot; alt=&quot;Follow @wagtail@fosstodon.org&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

Wagtail is an open source content management system built on Django, with a strong community and commercial support. It&#039;s focused on user experience, and offers precise control for designers and developers.

![Wagtail screenshot](https://cdn.jsdelivr.net/gh/wagtail/wagtail@main/.github/wagtail-screenshot-with-browser.png)

### üî• Features

-   A fast, attractive interface for authors
-   Complete control over front-end design and structure
-   Scales to millions of pages and thousands of editors
-   Fast out of the box, cache-friendly when you need it
-   Content API for &#039;headless&#039; sites with decoupled front-end
-   Runs on a Raspberry Pi or a multi-datacenter cloud platform
-   StreamField encourages flexible content without compromising structure
-   Powerful, integrated search, using Elasticsearch or PostgreSQL
-   Excellent support for images and embedded content
-   Multi-site and multi-language ready
-   Embraces and extends Django

Find out more at [wagtail.org](https://wagtail.org/).

### üëâ Getting started

Wagtail works with [Python 3](https://www.python.org/downloads/), on any platform.

To get started with using Wagtail, run the following in a [virtual environment](https://docs.python.org/3/tutorial/venv.html):

![Installing Wagtail](.github/install-animation.gif)

```sh
pip install wagtail
wagtail start mysite
cd mysite
pip install -r requirements.txt
python manage.py migrate
python manage.py createsuperuser
python manage.py runserver
```

For detailed installation and setup docs, see [the getting started tutorial](https://docs.wagtail.org/en/stable/getting_started/tutorial.html).

### üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Who‚Äôs using it?

Wagtail is used by [NASA](https://www.nasa.gov/), [Google](https://www.google.com/), [Oxfam](https://www.oxfam.org/en), the [NHS](https://www.nhs.uk/), [Mozilla](https://www.mozilla.org/en-US/), [MIT](https://www.mit.edu/), the [Red Cross](https://www.icrc.org/en), [Salesforce](https://www.salesforce.com/), [NBC](https://www.nbc.com/), [BMW](https://www.bmw.com/en/index.html), and the US and UK governments. Add your own Wagtail site to [madewithwagtail.org](https://madewithwagtail.org).

### üìñ Documentation

[docs.wagtail.org](https://docs.wagtail.org/) is the full reference for Wagtail, and includes guides for developers, designers and editors, alongside [release notes](https://docs.wagtail.org/en/stable/releases/) and our [roadmap](https://wagtail.org/roadmap/).

For those who are **new to Wagtail**, the [Zen of Wagtail](https://docs.wagtail.org/en/stable/getting_started/the_zen_of_wagtail.html) will help you understand what Wagtail is, and what Wagtail is _not_.

**For developers** who are ready to jump in to their first Wagtail website the [Getting Started Tutorial](https://docs.wagtail.org/en/stable/getting_started/tutorial.html) will guide you through creating and editing your first page.

**Do you have an existing Django project?** The [Wagtail Integration documentation](https://docs.wagtail.org/en/stable/getting_started/integrating_into_django.html) is the best place to start.

### üìå Compatibility

_(If you are reading this on GitHub, the details here may not be indicative of the current released version - please see [Compatible Django / Python versions](https://docs.wagtail.org/en/stable/releases/upgrading.html#compatible-django-python-versions) in the Wagtail documentation.)_

Wagtail supports:

-   Django 5.2.x and 6.0.x
-   Python 3.10, 3.11, 3.12, 3.13, and 3.14
-   PostgreSQL, MySQL, MariaDB and SQLite (with JSON1) as database backends

[Previous versions of Wagtail](https://docs.wagtail.org/en/stable/releases/upgrading.html#compatible-django-python-versions) additionally supported Python 2.7, 3.8 and earlier Django versions.

---

### üì¢ Community Support

There is an active community of Wagtail users and developers responding to questions on [Stack Overflow](https://stackoverflow.com/questions/tagged/wagtail). When posting questions, please read Stack Overflow&#039;s advice on [how to ask questions](https://stackoverflow.com/help/how-to-ask) and remember to tag your question &quot;wagtail&quot;.

For topics and discussions that do not fit Stack Overflow&#039;s question and answer format we have a [Slack workspace](https://github.com/wagtail/wagtail/wiki/Slack). Please respect the time and effort of volunteers by not asking the same question in multiple places.

[![Join slack community](.github/join-slack-community.png)](https://github.com/wagtail/wagtail/wiki/Slack)

Our [GitHub discussion boards](https://github.com/wagtail/wagtail/discussions) are open for sharing ideas and plans for the Wagtail project.

We maintain a curated list of third party packages, articles and other resources at [Awesome Wagtail](https://github.com/springload/awesome-wagtail).

### üßë‚Äçüíº Commercial Support

Wagtail is sponsored by [Torchbox](https://torchbox.com/). If you need help implementing or hosting Wagtail, please contact us: hello@torchbox.com. See also [madewithwagtail.org/developers/](https://madewithwagtail.org/developers/) for expert Wagtail developers around the world.

### üîê Security

We take the security of Wagtail, and related packages we maintain, seriously. If you have found a security issue with any of our projects please email us at [security@wagtail.org](mailto:security@wagtail.org) so we can work together to find and patch the issue. We appreciate responsible disclosure with any security related issues, so please contact us first before creating a GitHub issue.

If you want to send an encrypted email (optional), the public key ID for security@wagtail.org is 0xbed227b4daf93ff9, and this public key is available from most commonly-used keyservers.

### üïí Release schedule

Feature releases of Wagtail are released every three months. Selected releases are designated as Long Term Support (LTS) releases, and will receive maintenance updates for an extended period to address any security and data-loss related issues. For dates of past and upcoming releases and support periods, see [Release Schedule](https://github.com/wagtail/wagtail/wiki/Release-schedule).

#### üïõ Nightly releases

To try out the latest features before a release, we also create builds from `main` every night. You can find instructions on how to install the latest nightly release at https://releases.wagtail.org/nightly/index.html

### üôãüèΩ Contributing

If you&#039;re a Python or Django developer, fork the repo and get stuck in! We have several developer focused channels on the [Slack workspace](https://github.com/wagtail/wagtail/wiki/Slack).

You might like to start by reviewing the [contributing guidelines](https://docs.wagtail.org/en/latest/contributing/index.html) and checking issues with the [good first issue](https://github.com/wagtail/wagtail/labels/good%20first%20issue) label.

We also welcome translations for Wagtail&#039;s interface. Translation work should be submitted through [Transifex](https://explore.transifex.com/torchbox/wagtail/).

### üîì License

[BSD](https://github.com/wagtail/wagtail/blob/main/LICENSE) - Free to use and modify for any purpose, including both open and closed-source code.

### üëè Thanks

We thank the following organisations for their services used in Wagtail&#039;s development:

[![Browserstack](https://cdn.jsdelivr.net/gh/wagtail/wagtail@main/.github/browserstack-logo.svg)](https://www.browserstack.com/)&lt;br&gt;
[BrowserStack](https://www.browserstack.com/) provides the project with free access to their live web-based browser testing tool, and automated Selenium cloud testing.

[![Assistiv Labs](https://cdn.jsdelivr.net/gh/wagtail/wagtail@main/.github/assistivlabs-logo.png)](https://assistivlabs.com/)&lt;br&gt;
[Assistiv Labs](https://assistivlabs.com/) provides the project with unlimited access to their remote testing with assistive technologies.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[pandas-dev/pandas]]></title>
            <link>https://github.com/pandas-dev/pandas</link>
            <guid>https://github.com/pandas-dev/pandas</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:51 GMT</pubDate>
            <description><![CDATA[Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pandas-dev/pandas">pandas-dev/pandas</a></h1>
            <p>Flexible and powerful data analysis / manipulation library for Python, providing labeled data structures similar to R data.frame objects, statistical functions, and much more</p>
            <p>Language: Python</p>
            <p>Stars: 47,938</p>
            <p>Forks: 19,692</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;picture align=&quot;center&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://pandas.pydata.org/static/img/pandas_white.svg&quot;&gt;
  &lt;img alt=&quot;Pandas Logo&quot; src=&quot;https://pandas.pydata.org/static/img/pandas.svg&quot;&gt;
&lt;/picture&gt;

-----------------

# pandas: A Powerful Python Data Analysis Toolkit

| | |
| --- | --- |
| Testing | [![CI - Test](https://github.com/pandas-dev/pandas/actions/workflows/unit-tests.yml/badge.svg)](https://github.com/pandas-dev/pandas/actions/workflows/unit-tests.yml) [![Coverage](https://codecov.io/github/pandas-dev/pandas/coverage.svg?branch=main)](https://codecov.io/gh/pandas-dev/pandas) |
| Package | [![PyPI Latest Release](https://img.shields.io/pypi/v/pandas.svg)](https://pypi.org/project/pandas/) [![PyPI Downloads](https://img.shields.io/pypi/dm/pandas.svg?label=PyPI%20downloads)](https://pypi.org/project/pandas/) [![Conda Latest Release](https://anaconda.org/conda-forge/pandas/badges/version.svg)](https://anaconda.org/conda-forge/pandas) [![Conda Downloads](https://img.shields.io/conda/dn/conda-forge/pandas.svg?label=Conda%20downloads)](https://anaconda.org/conda-forge/pandas) |
| Meta | [![Powered by NumFOCUS](https://img.shields.io/badge/powered%20by-NumFOCUS-orange.svg?style=flat&amp;colorA=E1523D&amp;colorB=007D8A)](https://numfocus.org) [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.3509134.svg)](https://doi.org/10.5281/zenodo.3509134) [![License - BSD 3-Clause](https://img.shields.io/pypi/l/pandas.svg)](https://github.com/pandas-dev/pandas/blob/main/LICENSE) [![Slack](https://img.shields.io/badge/join_Slack-information-brightgreen.svg?logo=slack)](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack) [![LFX Health Score](https://insights.linuxfoundation.org/api/badge/health-score?project=pandas-dev-pandas)](https://insights.linuxfoundation.org/project/pandas-dev-pandas) |


## What is it?

**pandas** is a Python package that provides fast, flexible, and expressive data
structures designed to make working with &quot;relational&quot; or &quot;labeled&quot; data both
easy and intuitive. It aims to be the fundamental high-level building block for
doing practical, **real-world** data analysis in Python. Additionally, it has
the broader goal of becoming **the most powerful and flexible open-source data
analysis/manipulation tool available in any language**. It is already well on
its way towards this goal.

## Table of Contents

- [Main Features](#main-features)
- [Where to get it](#where-to-get-it)
- [Dependencies](#dependencies)
- [Installation from sources](#installation-from-sources)
- [License](#license)
- [Documentation](#documentation)
- [Background](#background)
- [Getting Help](#getting-help)
- [Discussion and Development](#discussion-and-development)
- [Contributing to pandas](#contributing-to-pandas)

## Main Features
Here are just a few of the things that pandas does well:

  - Easy handling of [**missing data**][missing-data] (represented as
    `NaN`, `NA`, or `NaT`) in floating point as well as non-floating point data
  - Size mutability: columns can be [**inserted and
    deleted**][insertion-deletion] from DataFrame and higher dimensional
    objects
  - Automatic and explicit [**data alignment**][alignment]: objects can
    be explicitly aligned to a set of labels, or the user can simply
    ignore the labels and let `Series`, `DataFrame`, etc. automatically
    align the data for you in computations
  - Powerful, flexible [**group by**][groupby] functionality to perform
    split-apply-combine operations on data sets, for both aggregating
    and transforming data
  - Make it [**easy to convert**][conversion] ragged,
    differently-indexed data in other Python and NumPy data structures
    into DataFrame objects
  - Intelligent label-based [**slicing**][slicing], [**fancy
    indexing**][fancy-indexing], and [**subsetting**][subsetting] of
    large data sets
  - Intuitive [**merging**][merging] and [**joining**][joining] data
    sets
  - Flexible [**reshaping**][reshape] and [**pivoting**][pivot-table] of
    data sets
  - [**Hierarchical**][mi] labeling of axes (possible to have multiple
    labels per tick)
  - Robust I/O tools for loading data from [**flat files**][flat-files]
    (CSV and delimited), [**Excel files**][excel], [**databases**][db],
    and saving/loading data from the ultrafast [**HDF5 format**][hdfstore]
  - [**Time series**][timeseries]-specific functionality: date range
    generation and frequency conversion, moving window statistics,
    date shifting and lagging


   [missing-data]: https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html
   [insertion-deletion]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#column-selection-addition-deletion
   [alignment]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html?highlight=alignment#intro-to-data-structures
   [groupby]: https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#group-by-split-apply-combine
   [conversion]: https://pandas.pydata.org/pandas-docs/stable/user_guide/dsintro.html#dataframe
   [slicing]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#slicing-ranges
   [fancy-indexing]: https://pandas.pydata.org/pandas-docs/stable/user_guide/advanced.html#advanced
   [subsetting]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#boolean-indexing
   [merging]: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#database-style-dataframe-or-named-series-joining-merging
   [joining]: https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html#joining-on-index
   [reshape]: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html
   [pivot-table]: https://pandas.pydata.org/pandas-docs/stable/user_guide/reshaping.html
   [mi]: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#hierarchical-indexing-multiindex
   [flat-files]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#csv-text-files
   [excel]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#excel-files
   [db]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#sql-queries
   [hdfstore]: https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#hdf5-pytables
   [timeseries]: https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-series-date-functionality

## Where to get it
The source code is currently hosted on GitHub at:
https://github.com/pandas-dev/pandas

Binary installers for the latest released version are available at the [Python
Package Index (PyPI)](https://pypi.org/project/pandas) and on [Conda](https://anaconda.org/conda-forge/pandas).

```sh
# conda
conda install -c conda-forge pandas
```

```sh
# or PyPI
pip install pandas
```

The list of changes to pandas between each release can be found
[here](https://pandas.pydata.org/pandas-docs/stable/whatsnew/index.html). For full
details, see the commit logs at https://github.com/pandas-dev/pandas.

## Dependencies
- [NumPy - Adds support for large, multi-dimensional arrays, matrices and high-level mathematical functions to operate on these arrays](https://www.numpy.org)
- [python-dateutil - Provides powerful extensions to the standard datetime module](https://dateutil.readthedocs.io/en/stable/index.html)
- [tzdata - Provides an IANA time zone database](https://tzdata.readthedocs.io/en/latest/) (Only required on Windows/Emscripten)

See the [full installation instructions](https://pandas.pydata.org/pandas-docs/stable/install.html#dependencies) for minimum supported versions of required, recommended and optional dependencies.

## Installation from sources
To install pandas from source you need [Cython](https://cython.org/) in addition to the normal
dependencies above. Cython can be installed from PyPI:

```sh
pip install cython
```

In the `pandas` directory (same one where you found this file after
cloning the git repo), execute:

```sh
pip install .
```

or for installing in [development mode](https://pip.pypa.io/en/latest/cli/pip_install/#install-editable):


```sh
python -m pip install -ve . --no-build-isolation --config-settings editable-verbose=true
```

See the full instructions for [installing from source](https://pandas.pydata.org/docs/dev/development/contributing_environment.html).

## License
[BSD 3](LICENSE)

## Documentation
The official documentation is hosted on [PyData.org](https://pandas.pydata.org/pandas-docs/stable/).

## Background
Work on ``pandas`` started at [AQR](https://www.aqr.com/) (a quantitative hedge fund) in 2008 and
has been under active development since then.

## Getting Help

For usage questions, the best place to go to is [Stack Overflow](https://stackoverflow.com/questions/tagged/pandas).
Further, general questions and discussions can also take place on the [pydata mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata).

## Discussion and Development
Most development discussions take place on GitHub in this repo, via the [GitHub issue tracker](https://github.com/pandas-dev/pandas/issues).

Further, the [pandas-dev mailing list](https://mail.python.org/mailman/listinfo/pandas-dev) can also be used for specialized discussions or design issues, and a [Slack channel](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack) is available for quick development related questions.

There are also frequent [community meetings](https://pandas.pydata.org/docs/dev/development/community.html#community-meeting) for project maintainers open to the community as well as monthly [new contributor meetings](https://pandas.pydata.org/docs/dev/development/community.html#new-contributor-meeting) to help support new contributors.

Additional information on the communication channels can be found on the [contributor community](https://pandas.pydata.org/docs/development/community.html) page.

## Contributing to pandas

[![Open Source Helpers](https://www.codetriage.com/pandas-dev/pandas/badges/users.svg)](https://www.codetriage.com/pandas-dev/pandas)

All contributions, bug reports, bug fixes, documentation improvements, enhancements, and ideas are welcome.

A detailed overview on how to contribute can be found in the **[contributing guide](https://pandas.pydata.org/docs/dev/development/contributing.html)**.

If you are simply looking to start working with the pandas codebase, navigate to the [GitHub &quot;issues&quot; tab](https://github.com/pandas-dev/pandas/issues) and start looking through interesting issues. There are a number of issues listed under [Docs](https://github.com/pandas-dev/pandas/issues?q=is%3Aissue%20state%3Aopen%20label%3ADocs%20sort%3Aupdated-desc) and [good first issue](https://github.com/pandas-dev/pandas/issues?q=is%3Aissue%20state%3Aopen%20label%3A%22good%20first%20issue%22%20sort%3Aupdated-desc) where you could start out.

You can also triage issues which may include reproducing bug reports, or asking for vital information such as version numbers or reproduction instructions. If you would like to start triaging issues, one easy way to get started is to [subscribe to pandas on CodeTriage](https://www.codetriage.com/pandas-dev/pandas).

Or maybe through using pandas you have an idea of your own or are looking for something in the documentation and thinking ‚Äòthis can be improved‚Äô... you can do something about it!

Feel free to ask questions on the [mailing list](https://groups.google.com/forum/?fromgroups#!forum/pydata) or on [Slack](https://pandas.pydata.org/docs/dev/development/community.html?highlight=slack#community-slack).

As contributors and maintainers to this project, you are expected to abide by pandas&#039; code of conduct. More information can be found at: [Contributor Code of Conduct](https://github.com/pandas-dev/.github/blob/master/CODE_OF_CONDUCT.md)

&lt;hr&gt;

[Go to Top](#table-of-contents)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[PostHog/posthog]]></title>
            <link>https://github.com/PostHog/posthog</link>
            <guid>https://github.com/PostHog/posthog</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:50 GMT</pubDate>
            <description><![CDATA[ü¶î PostHog is an all-in-one developer platform for building successful products. We offer product analytics, web analytics, session replay, error tracking, feature flags, experimentation, surveys, data warehouse, a CDP, and an AI product assistant to help debug your code, ship features faster, and keep all your usage and customer data in one stack.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/PostHog/posthog">PostHog/posthog</a></h1>
            <p>ü¶î PostHog is an all-in-one developer platform for building successful products. We offer product analytics, web analytics, session replay, error tracking, feature flags, experimentation, surveys, data warehouse, a CDP, and an AI product assistant to help debug your code, ship features faster, and keep all your usage and customer data in one stack.</p>
            <p>Language: Python</p>
            <p>Stars: 31,699</p>
            <p>Forks: 2,315</p>
            <p>Stars today: 317 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img alt=&quot;posthoglogo&quot; src=&quot;https://user-images.githubusercontent.com/65415371/205059737-c8a4f836-4889-4654-902e-f302b187b6a0.png&quot;&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&#039;https://posthog.com/contributors&#039;&gt;&lt;img alt=&quot;GitHub contributors&quot; src=&quot;https://img.shields.io/github/contributors/posthog/posthog&quot;/&gt;&lt;/a&gt;
  &lt;a href=&#039;http://makeapullrequest.com&#039;&gt;&lt;img alt=&#039;PRs Welcome&#039; src=&#039;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=shields&#039;/&gt;&lt;/a&gt;
  &lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/posthog/posthog&quot;/&gt;
  &lt;a href=&quot;https://github.com/PostHog/posthog/commits/master&quot;&gt;&lt;img alt=&quot;GitHub commit activity&quot; src=&quot;https://img.shields.io/github/commit-activity/m/posthog/posthog&quot;/&gt; &lt;/a&gt;
  &lt;a href=&quot;https://github.com/PostHog/posthog/issues?q=is%3Aissue%20state%3Aclosed&quot;&gt;&lt;img alt=&quot;GitHub closed issues&quot; src=&quot;https://img.shields.io/github/issues-closed/posthog/posthog&quot;/&gt; &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://posthog.com/docs&quot;&gt;Docs&lt;/a&gt; - &lt;a href=&quot;https://posthog.com/community&quot;&gt;Community&lt;/a&gt; - &lt;a href=&quot;https://posthog.com/roadmap&quot;&gt;Roadmap&lt;/a&gt; - &lt;a href=&quot;https://posthog.com/why&quot;&gt;Why PostHog?&lt;/a&gt; - &lt;a href=&quot;https://posthog.com/changelog&quot;&gt;Changelog&lt;/a&gt; - &lt;a href=&quot;https://github.com/PostHog/posthog/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.yml&quot;&gt;Bug reports&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=2jQco8hEvTI&quot;&gt;
    &lt;img src=&quot;https://res.cloudinary.com/dmukukwp6/image/upload/demo_thumb_68d0d8d56d&quot; alt=&quot;PostHog Demonstration&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

## PostHog is an all-in-one, open source platform for building successful products

[PostHog](https://posthog.com/) provides every tool you need to build a successful product including:

- [Product Analytics](https://posthog.com/product-analytics): Autocapture or manually instrument event-based analytics to understand user behavior and analyze data with visualization or SQL.
- [Web Analytics](https://posthog.com/web-analytics): Monitor web traffic and user sessions with a GA-like dashboard. Easily monitor conversion, web vitals, and revenue.
- [Session Replays](https://posthog.com/session-replay): Watch real user sessions of interactions with your website or mobile app to diagnose issues and understand user behavior.
- [Feature Flags](https://posthog.com/feature-flags): Safely roll out features to select users or cohorts with feature flags.
- [Experiments](https://posthog.com/experiments): Test changes and measure their statistical impact on goal metrics. Set up experiments with no-code too.
- [Error Tracking](https://posthog.com/error-tracking): Track errors, get alerts, and resolve issues to improve your product.
- [Surveys](https://posthog.com/surveys): Ask anything with our collection of no-code survey templates, or build custom surveys with our survey builder.
- [Data warehouse](https://posthog.com/data-warehouse): Sync data from external tools like Stripe, Hubspot, your data warehouse, and more. Query it alongside your product data.
- [Data pipelines](https://posthog.com/cdp): Run custom filters and transformations on your incoming data. Send it to 25+ tools or any webhook in real time or batch export large amounts to your warehouse.
- [LLM analytics](https://posthog.com/docs/llm-analytics): Capture traces, generations, latency, and cost for your LLM-powered app.
- [Workflows](https://posthog.com/docs/workflows): Create workflows that automate actions or send messages to your users.

Best of all, all of this is free to use with a [generous monthly free tier](https://posthog.com/pricing) for each product. Get started by signing up for [PostHog Cloud US](https://us.posthog.com/signup) or [PostHog Cloud EU](https://eu.posthog.com/signup).

## Table of Contents

- [PostHog is an all-in-one, open source platform for building successful products](#posthog-is-an-all-in-one-open-source-platform-for-building-successful-products)
- [Table of Contents](#table-of-contents)
- [Getting started with PostHog](#getting-started-with-posthog)
  - [PostHog Cloud (Recommended)](#posthog-cloud-recommended)
  - [Self-hosting the open-source hobby deploy (Advanced)](#self-hosting-the-open-source-hobby-deploy-advanced)
- [Setting up PostHog](#setting-up-posthog)
- [Learning more about PostHog](#learning-more-about-posthog)
- [Contributing](#contributing)
- [Open-source vs. paid](#open-source-vs-paid)
- [We‚Äôre hiring!](#were-hiring)

## Getting started with PostHog

### PostHog Cloud (Recommended)

The fastest and most reliable way to get started with PostHog is signing up for free to¬†[PostHog Cloud](https://us.posthog.com/signup) or [PostHog Cloud EU](https://eu.posthog.com/signup). Your first 1 million events, 5k recordings, 1M flag requests, 100k exceptions, and 1500 survey responses are free every month, after which you pay based on usage.

### Self-hosting the open-source hobby deploy (Advanced)

If you want to self-host PostHog, you can deploy a hobby instance in one line on Linux with Docker (recommended 4GB memory):

```bash
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/posthog/posthog/HEAD/bin/deploy-hobby)&quot;
```

Open source deployments should scale to approximately 100k events per month, after which we recommend [migrating to a PostHog Cloud](https://posthog.com/docs/migrate/migrate-to-cloud).

We _do not_ provide customer support or offer guarantees for open source deployments. See our [self-hosting docs](https://posthog.com/docs/self-host), [troubleshooting guide](https://posthog.com/docs/self-host/deploy/troubleshooting), and [disclaimer](https://posthog.com/docs/self-host/open-source/disclaimer) for more info.

## Setting up PostHog

Once you&#039;ve got a PostHog instance, you can set it up by installing our [JavaScript web snippet](https://posthog.com/docs/getting-started/install?tab=snippet), one of [our SDKs](https://posthog.com/docs/getting-started/install?tab=sdks), or by [using our API](https://posthog.com/docs/getting-started/install?tab=api).

We have SDKs and libraries for popular languages and frameworks like:

| Frontend                                              | Mobile                                                          | Backend                                             |
| ----------------------------------------------------- | --------------------------------------------------------------- | --------------------------------------------------- |
| [JavaScript](https://posthog.com/docs/libraries/js)   | [React Native](https://posthog.com/docs/libraries/react-native) | [Python](https://posthog.com/docs/libraries/python) |
| [Next.js](https://posthog.com/docs/libraries/next-js) | [Android](https://posthog.com/docs/libraries/android)           | [Node](https://posthog.com/docs/libraries/node)     |
| [React](https://posthog.com/docs/libraries/react)     | [iOS](https://posthog.com/docs/libraries/ios)                   | [PHP](https://posthog.com/docs/libraries/php)       |
| [Vue](https://posthog.com/docs/libraries/vue-js)      | [Flutter](https://posthog.com/docs/libraries/flutter)           | [Ruby](https://posthog.com/docs/libraries/ruby)     |

Beyond this, we have docs and guides for [Go](https://posthog.com/docs/libraries/go), [.NET/C#](https://posthog.com/docs/libraries/dotnet), [Django](https://posthog.com/docs/libraries/django), [Angular](https://posthog.com/docs/libraries/angular), [WordPress](https://posthog.com/docs/libraries/wordpress), [Webflow](https://posthog.com/docs/libraries/webflow), and more.

Once you&#039;ve installed PostHog, see our [product docs](https://posthog.com/docs/product-os) for more information on how to set up [product analytics](https://posthog.com/docs/product-analytics/capture-events), [web analytics](https://posthog.com/docs/web-analytics/getting-started), [session replays](https://posthog.com/docs/session-replay/how-to-watch-recordings), [feature flags](https://posthog.com/docs/feature-flags/creating-feature-flags), [experiments](https://posthog.com/docs/experiments/creating-an-experiment), [error tracking](https://posthog.com/docs/error-tracking/installation#setting-up-exception-autocapture), [surveys](https://posthog.com/docs/surveys/installation), [data warehouse](https://posthog.com/docs/cdp/sources), and more.

## Learning more about PostHog

Our code isn&#039;t the only thing that&#039;s open source üò≥. We also open source our [company handbook](https://posthog.com/handbook) which details our [strategy](https://posthog.com/handbook/why-does-posthog-exist), [ways of working](https://posthog.com/handbook/company/culture), and [processes](https://posthog.com/handbook/team-structure).

Curious about how to make the most of PostHog? We wrote a guide to [winning with PostHog](https://posthog.com/docs/new-to-posthog/getting-hogpilled) which walks you through the basics of [measuring activation](https://posthog.com/docs/new-to-posthog/activation), [tracking retention](https://posthog.com/docs/new-to-posthog/retention), and [capturing revenue](https://posthog.com/docs/new-to-posthog/revenue).

## Contributing

We &lt;3 contributions big and small:

- Vote on features or get early access to beta functionality in our [roadmap](https://posthog.com/roadmap)
- Open a PR (see our instructions on [developing PostHog locally](https://posthog.com/handbook/engineering/developing-locally))
- Submit a [feature request](https://github.com/PostHog/posthog/issues/new?assignees=&amp;labels=enhancement%2C+feature&amp;template=feature_request.yml) or [bug report](https://github.com/PostHog/posthog/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.yml)

For an overview of the codebase structure, see [monorepo layout](docs/internal/monorepo-layout.md) and [products](products/README.md).

## Open-source vs. paid

This repo is available under the [MIT expat license](https://github.com/PostHog/posthog/blob/master/LICENSE), except for the `ee` directory (which has its [license here](https://github.com/PostHog/posthog/blob/master/ee/LICENSE)) if applicable.

Need _absolutely üíØ% FOSS_? Check out our [posthog-foss](https://github.com/PostHog/posthog-foss) repository, which is purged of all proprietary code and features.

The pricing for our paid plan is completely transparent and available on [our pricing page](https://posthog.com/pricing).

## We&#039;re hiring!

&lt;img src=&quot;https://res.cloudinary.com/dmukukwp6/image/upload/v1/posthog.com/src/components/Home/images/mission-control-hog&quot; alt=&quot;Hedgehog working on a Mission Control Center&quot; width=&quot;350px&quot;/&gt;

Hey! If you&#039;re reading this, you&#039;ve proven yourself as a dedicated README reader.

You might also make a great addition to our team. We&#039;re growing fast [and would love for you to join us](https://posthog.com/careers).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[roboflow/trackers]]></title>
            <link>https://github.com/roboflow/trackers</link>
            <guid>https://github.com/roboflow/trackers</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:49 GMT</pubDate>
            <description><![CDATA[Trackers gives you clean, modular re-implementations of leading multi-object tracking algorithms released under the permissive Apache 2.0 license. You combine them with any detection model you already use.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/roboflow/trackers">roboflow/trackers</a></h1>
            <p>Trackers gives you clean, modular re-implementations of leading multi-object tracking algorithms released under the permissive Apache 2.0 license. You combine them with any detection model you already use.</p>
            <p>Language: Python</p>
            <p>Stars: 2,798</p>
            <p>Forks: 267</p>
            <p>Stars today: 132 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;img width=&quot;200&quot; src=&quot;https://raw.githubusercontent.com/roboflow/trackers/refs/heads/release/stable/docs/assets/logo-trackers-violet.svg&quot; alt=&quot;trackers logo&quot;&gt;
    &lt;h1&gt;trackers&lt;/h1&gt;
    &lt;p&gt;Plug-and-play multi-object tracking for any detection model.&lt;/p&gt;

[![version](https://badge.fury.io/py/trackers.svg)](https://badge.fury.io/py/trackers)
[![downloads](https://img.shields.io/pypi/dm/trackers)](https://pypistats.org/packages/trackers)
[![license](https://img.shields.io/badge/license-Apache%202.0-blue)](https://github.com/roboflow/trackers/blob/release/stable/LICENSE.md)
[![python-version](https://img.shields.io/pypi/pyversions/trackers)](https://badge.fury.io/py/trackers)
[![hf space](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/Roboflow/Trackers)
[![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow-ai/notebooks/blob/main/notebooks/how-to-track-objects-with-bytetrack-tracker.ipynb)
[![discord](https://img.shields.io/discord/1159501506232451173?logo=discord&amp;label=discord&amp;labelColor=fff&amp;color=5865f2&amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk)](https://discord.gg/GbfgXGJ8Bk)

&lt;/div&gt;

## Try It

No install needed. Try trackers in your browser with our [Hugging Face Playground](https://huggingface.co/spaces/roboflow/trackers).

## Install

```bash
pip install trackers
```

&lt;details&gt;
&lt;summary&gt;install from source&lt;/summary&gt;

```bash
pip install git+https://github.com/roboflow/trackers.git
```

&lt;/details&gt;

https://github.com/user-attachments/assets/eef9b00a-cfe4-40f7-a495-954550e3ef1f

## Track from CLI

Point at a video, webcam, RTSP stream, or image directory. Get tracked output.

Use our [interactive command builder](https://trackers.roboflow.com/develop/learn/track) to configure your tracking pipeline.

```bash
trackers track \
    --source video.mp4 \
    --output output.mp4 \
    --model rfdetr-medium \
    --tracker bytetrack \
    --show-labels \
    --show-trajectories
```

## Track from Python

Plug trackers into your existing detection pipeline. Works with any detector.

```python
import cv2
import supervision as sv
from inference import get_model
from trackers import ByteTrackTracker

model = get_model(model_id=&quot;rfdetr-medium&quot;)
tracker = ByteTrackTracker()

label_annotator = sv.LabelAnnotator()
trajectory_annotator = sv.TrajectoryAnnotator()

cap = cv2.VideoCapture(&quot;video.mp4&quot;)
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    result = model.infer(frame)[0]
    detections = sv.Detections.from_inference(result)
    tracked = tracker.update(detections)

    frame = label_annotator.annotate(frame, tracked)
    frame = trajectory_annotator.annotate(frame, tracked)
```

## Evaluate

Benchmark your tracker against ground truth with standard MOT metrics.

```bash
trackers eval \
    --gt-dir data/gt \
    --tracker-dir data/trackers \
    --metrics CLEAR HOTA Identity
```

```
Sequence                        MOTA    HOTA    IDF1  IDSW
----------------------------------------------------------
MOT17-02-FRCNN                75.600  62.300  72.100    42
MOT17-04-FRCNN                78.200  65.100  74.800    31
----------------------------------------------------------
COMBINED                      75.033  62.400  72.033    73
```

## Algorithms

Clean, modular implementations of leading trackers. See the [tracker comparison](https://trackers.roboflow.com/develop/trackers/comparison/) for detailed benchmarks.

|                   Algorithm                   |  MOT17   | SportsMOT | SoccerNet |
| :-------------------------------------------: | :------: | :-------: | :-------: |
|   [SORT](https://arxiv.org/abs/1602.00763)    |   58.4   |   70.9    |   81.6    |
| [ByteTrack](https://arxiv.org/abs/2110.06864) | **60.1** | **73.0**  | **84.0**  |
|  [OC-SORT](https://arxiv.org/abs/2203.14360)  |    ‚Äî     |     ‚Äî     |     ‚Äî     |
| [BoT-SORT](https://arxiv.org/abs/2206.14651)  |    ‚Äî     |     ‚Äî     |     ‚Äî     |
|  [McByte](https://arxiv.org/abs/2506.01373)   |    ‚Äî     |     ‚Äî     |     ‚Äî     |

## Contributing

We welcome contributions. Read our [contributor guidelines](https://github.com/roboflow/trackers/blob/release/stable/CONTRIBUTING.md) to get started.

## License

The code is released under the [Apache 2.0 license](https://github.com/roboflow/trackers/blob/release/stable/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[trycua/cua]]></title>
            <link>https://github.com/trycua/cua</link>
            <guid>https://github.com/trycua/cua</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:48 GMT</pubDate>
            <description><![CDATA[Open-source infrastructure for Computer-Use Agents. Sandboxes, SDKs, and benchmarks to train and evaluate AI agents that can control full desktops (macOS, Linux, Windows).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/trycua/cua">trycua/cua</a></h1>
            <p>Open-source infrastructure for Computer-Use Agents. Sandboxes, SDKs, and benchmarks to train and evaluate AI agents that can control full desktops (macOS, Linux, Windows).</p>
            <p>Language: Python</p>
            <p>Stars: 12,629</p>
            <p>Forks: 772</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://cua.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; alt=&quot;Cua logo&quot; width=&quot;150&quot; srcset=&quot;img/logo_white.svg&quot;&gt;
      &lt;source media=&quot;(prefers-color-scheme: light)&quot; alt=&quot;Cua logo&quot; width=&quot;150&quot; srcset=&quot;img/logo_black.svg&quot;&gt;
      &lt;img alt=&quot;Cua logo&quot; width=&quot;150&quot; src=&quot;img/logo_black.svg&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;

  &lt;p align=&quot;center&quot;&gt;Build, benchmark, and deploy agents that use computers&lt;/p&gt;

  &lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://cua.ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/cua.ai-0ea5e9&quot; alt=&quot;cua.ai&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://discord.com/invite/cua-ai&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Discord-Join%20Server-10b981?logo=discord&amp;logoColor=white&quot; alt=&quot;Discord&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://x.com/trycua&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/twitter/follow/trycua?style=social&quot; alt=&quot;Twitter&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://cua.ai/docs&quot; target=&quot;_blank&quot; rel=&quot;noopener noreferrer&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Docs-0ea5e9.svg&quot; alt=&quot;Documentation&quot;&gt;&lt;/a&gt;
    &lt;br&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13685&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13685&quot; alt=&quot;trycua%2Fcua | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
  &lt;/p&gt;

&lt;/div&gt;

## Choose Your Path

&lt;div align=&quot;center&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;#cua---agentic-ui-automation--code-execution&quot;&gt;
          &lt;picture&gt;
            &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;img/card-cua-dark.png&quot;&gt;
            &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;img/card-cua-light.png&quot;&gt;
            &lt;img src=&quot;img/card-cua-light.png&quot; alt=&quot;Cua&quot; width=&quot;280&quot;&gt;
          &lt;/picture&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;#cua-bench---benchmarks--rl-environments&quot;&gt;
          &lt;picture&gt;
            &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;img/card-cua-bench-dark.png&quot;&gt;
            &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;img/card-cua-bench-light.png&quot;&gt;
            &lt;img src=&quot;img/card-cua-bench-light.png&quot; alt=&quot;Cua-Bench&quot; width=&quot;280&quot;&gt;
          &lt;/picture&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;#lume---macos-virtualization&quot;&gt;
          &lt;picture&gt;
            &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;img/card-lume-dark.png&quot;&gt;
            &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;img/card-lume-light.png&quot;&gt;
            &lt;img src=&quot;img/card-lume-light.png&quot; alt=&quot;Lume&quot; width=&quot;280&quot;&gt;
          &lt;/picture&gt;
        &lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td colspan=&quot;3&quot; align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://cua.ai/docs/cuabot/guide/getting-started/introduction&quot;&gt;
          &lt;picture&gt;
            &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;img/card-cua-bot-dark.png&quot;&gt;
            &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;img/card-cua-bot-light.png&quot;&gt;
            &lt;img src=&quot;img/card-cua-bot-light.png&quot; alt=&quot;Cua Bot&quot; width=&quot;888&quot;&gt;
          &lt;/picture&gt;
        &lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;

---

## CuaBot - Co-op computer-use for any agent

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;img/cuabot-screenshot.png&quot; alt=&quot;cuabot screenshot&quot; width=&quot;720&quot;&gt;
&lt;/div&gt;

`cuabot` gives any coding agent a seamless sandbox for computer-use. Individual windows appear natively on your desktop with H.265, shared clipboard, and audio.

```bash
npx cuabot                 # Setup onboarding
```

```bash
# Run any agent in a sandbox
cuabot claude              # Claude Code
cuabot openclaw            # OpenClaw in the sandbox

# Run any GUI workflow in a sandbox
cuabot chromium
cuabot --screenshot
cuabot --type &quot;hello&quot;
cuabot --click &lt;x&gt; &lt;y&gt; [button]
```

Built-in support for `agent-browser` and `agent-device` (iOS, Android) out of the box.

&lt;div align=&quot;center&quot;&gt;

**[Get Started](https://cua.ai/docs/cuabot/guide/getting-started/introduction)** | **[Installation](https://cua.ai/docs/cuabot/guide/getting-started/installation)** | First spotted at [ClawCon](https://www.claw-con.com/)

&lt;img height=&quot;64&quot; alt=&quot;cuaXclawdbot_nbg&quot; src=&quot;https://github.com/user-attachments/assets/8b92237d-6e9b-4b3a-ae9a-b3560622ec1d&quot; /&gt;

&lt;/div&gt;

## Cua - Agentic UI Automation &amp; Code Execution

Build agents that see screens, click buttons, and complete tasks autonomously. Run isolated code execution environments for AI coding assistants like Claude Code, Codex CLI, or OpenCode.

&lt;!-- &lt;img src=&quot;img/cua-architecture.png&quot; alt=&quot;Cua Architecture&quot; width=&quot;100%&quot;&gt; --&gt;

```python
# Requires Python 3.12 or 3.13
from computer import Computer
from agent import ComputerAgent

computer = Computer(os_type=&quot;linux&quot;, provider_type=&quot;cloud&quot;)
agent = ComputerAgent(model=&quot;anthropic/claude-sonnet-4-5-20250929&quot;, computer=computer)

async for result in agent.run([{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Open Firefox and search for Cua&quot;}]):
    print(result)
```

**[Get Started](https://cua.ai/docs/cua/guide/get-started/set-up-sandbox)** | **[Examples](https://cua.ai/docs/cua/examples)** | **[API Reference](https://cua.ai/docs/cua/reference/agent-sdk)**

---

## Cua-Bench - Benchmarks &amp; RL Environments

Evaluate computer-use agents on OSWorld, ScreenSpot, Windows Arena, and custom tasks. Export trajectories for training.

&lt;!-- &lt;img src=&quot;img/cua-bench-architecture.png&quot; alt=&quot;Cua-Bench Architecture&quot; width=&quot;100%&quot;&gt; --&gt;

```bash
# Install and create base image
cd cua-bench
uv tool install -e . &amp;&amp; cb image create linux-docker

# Run benchmark with agent
cb run dataset datasets/cua-bench-basic --agent cua-agent --max-parallel 4
```

**[Get Started](https://cua.ai/docs/cuabench/guide/getting-started/first-steps)** | **[Partner With Us](https://cuabench.ai/)** | **[Registry](https://cuabench.ai/registry)** | **[CLI Reference](https://cua.ai/docs/cuabench/reference/cli-reference)**

---

## Lume - macOS Virtualization

Create and manage macOS/Linux VMs with near-native performance on Apple Silicon using Apple&#039;s Virtualization.Framework.

&lt;!-- &lt;img src=&quot;img/lume-architecture.png&quot; alt=&quot;Lume Architecture&quot; width=&quot;100%&quot;&gt; --&gt;

```bash
# Install Lume
/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/trycua/cua/main/libs/lume/scripts/install.sh)&quot;

# Pull &amp; start a macOS VM
lume run macos-sequoia-vanilla:latest
```

**[Get Started](https://cua.ai/docs/lume)** | **[FAQ](https://cua.ai/docs/lume/guide/getting-started/faq)** | **[CLI Reference](https://cua.ai/docs/lume/reference/cli-reference)**

---

## Packages

| Package                                                               | Description                                                |
| --------------------------------------------------------------------- | ---------------------------------------------------------- |
| [cuabot](https://cua.ai/docs/cuabot/cuabot)                           | Multi-agent computer-use sandbox CLI                       |
| [cua-agent](https://cua.ai/docs/cua/reference/agent-sdk)              | AI agent framework for computer-use tasks                  |
| [cua-computer](https://cua.ai/docs/cua/reference/computer-sdk)        | SDK for controlling desktop environments                   |
| [cua-computer-server](https://cua.ai/docs/cua/reference/computer-sdk) | Driver for UI interactions and code execution in sandboxes |
| [cua-bench](https://cua.ai/docs/cuabench)                             | Benchmarks and RL environments for computer-use            |
| [lume](https://cua.ai/docs/lume)                                      | macOS/Linux VM management on Apple Silicon                 |
| [lumier](https://cua.ai/docs/lume/guide/advanced/lumier)              | Docker-compatible interface for Lume VMs                   |

## Resources

- [Documentation](https://cua.ai/docs) ‚Äî Guides, examples, and API reference
- [Blog](https://www.cua.ai/blog) ‚Äî Tutorials, updates, and research
- [Discord](https://discord.com/invite/mVnXXpdE85) ‚Äî Community support and discussions
- [GitHub Issues](https://github.com/trycua/cua/issues) ‚Äî Bug reports and feature requests

## Contributing

We welcome contributions! See our [Contributing Guidelines](CONTRIBUTING.md) for details.

## License

MIT License ‚Äî see [LICENSE](LICENSE.md) for details.

Third-party components have their own licenses:

- [Kasm](libs/kasm/LICENSE) (MIT)
- [OmniParser](https://github.com/microsoft/OmniParser/blob/master/LICENSE) (CC-BY-4.0)
- Optional `cua-agent[omni]` includes ultralytics (AGPL-3.0)

## Trademarks

Apple, macOS, Ubuntu, Canonical, and Microsoft are trademarks of their respective owners. This project is not affiliated with or endorsed by these companies.

---

&lt;div align=&quot;center&quot;&gt;

[![Stargazers over time](https://starchart.cc/trycua/cua.svg?variant=adaptive)](https://starchart.cc/trycua/cua)

Thank you to all our [GitHub Sponsors](https://github.com/sponsors/trycua)!

&lt;img width=&quot;300&quot; alt=&quot;coderabbit-cli&quot; src=&quot;https://github.com/user-attachments/assets/23a98e38-7897-4043-8ef7-eb990520dccc&quot; /&gt;

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Crosstalk-Solutions/unifi-toolkit]]></title>
            <link>https://github.com/Crosstalk-Solutions/unifi-toolkit</link>
            <guid>https://github.com/Crosstalk-Solutions/unifi-toolkit</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:47 GMT</pubDate>
            <description><![CDATA[A suite of tools for UniFi network management]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Crosstalk-Solutions/unifi-toolkit">Crosstalk-Solutions/unifi-toolkit</a></h1>
            <p>A suite of tools for UniFi network management</p>
            <p>Language: Python</p>
            <p>Stars: 269</p>
            <p>Forks: 25</p>
            <p>Stars today: 28 stars today</p>
            <h2>README</h2><pre># UI Toolkit

A comprehensive suite of tools for UniFi network management and monitoring.

&gt; **Note:** This project is not affiliated with, endorsed by, or sponsored by Ubiquiti Inc. UniFi is a trademark of Ubiquiti Inc.

&lt;img width=&quot;1094&quot; height=&quot;748&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/a167fc5c-9db5-48f2-8b43-0dfdab3b08a8&quot; /&gt;

## Features

### Dashboard
Real-time system status including:
- **Gateway Info** - Model, firmware, uptime
- **Resource Usage** - CPU and RAM utilization
- **Network Health** - WAN, LAN, WLAN, VPN status with diagnostic reasons
- **Connected Clients** - Wired and wireless counts
- **WAN Status** - IP, ISP, latency, uptime (supports multi-WAN)

### Wi-Fi Stalker
Track specific Wi-Fi client devices through your UniFi infrastructure.
- Device tracking by MAC address
- Roaming detection between access points
- Connection history with timestamps
- Block/unblock devices directly from the UI
- Blocked device indicator in device list
- Webhook alerts (Slack, Discord, n8n) for connect, disconnect, roam, block, and unblock events

&lt;img width=&quot;1355&quot; height=&quot;702&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/383d3c84-1b24-480a-bbaf-e72c47953b85&quot; /&gt;

### Threat Watch
Monitor IDS/IPS security events from your UniFi gateway.
- Real-time event monitoring
- Threat categorization and analysis
- Top attackers and targets
- Webhook alerts (Slack, Discord, n8n)

&lt;img width=&quot;1359&quot; height=&quot;468&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/7bfec7f7-bdf6-4ae2-af0e-143dcd982d4a&quot; /&gt;

### Network Pulse
Real-time network monitoring dashboard.
- Gateway status (model, firmware, uptime, WAN)
- Device counts (total clients, wired, wireless, APs, switches)
- Chart.js visualizations (clients by band, clients by SSID, top bandwidth)
- Clickable AP cards with detailed client views
- WebSocket-powered live updates

&lt;img width=&quot;1895&quot; height=&quot;957&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/ca6f0df5-8657-4c2a-ad16-8807aa21bcac&quot; /&gt;

### UI Product Selector *(External)*
Build the perfect UniFi network at [uiproductselector.com](https://uiproductselector.com)

---

## Quick Start

### Requirements
- **Docker** (recommended) or Python 3.9-3.12
- **Ubuntu 22.04/24.04** (or other Linux)
- Access to UniFi Controller

### Local Deployment (LAN Only)

No authentication, access via `http://localhost:8000`

**Prerequisites:** Install Docker first - see [docs/INSTALLATION.md](docs/INSTALLATION.md#option-a-docker-installation-recommended)

```bash
# Clone and setup
git clone https://github.com/Crosstalk-Solutions/unifi-toolkit.git
cd unifi-toolkit
./setup.sh  # Select 1 for Local

# Start
docker compose up -d
```

Access at **http://localhost:8000**

### Production Deployment (Internet-Facing)

Authentication enabled, HTTPS with Let&#039;s Encrypt via Caddy

**Prerequisites:** Install Docker first - see [docs/INSTALLATION.md](docs/INSTALLATION.md#option-a-docker-installation-recommended)

```bash
# Clone and setup
git clone https://github.com/Crosstalk-Solutions/unifi-toolkit.git
cd unifi-toolkit
./setup.sh  # Select 2 for Production
# Enter: domain name, admin username, password

# Open firewall ports
sudo ufw allow 80/tcp &amp;&amp; sudo ufw allow 443/tcp

# Start with HTTPS
docker compose --profile production up -d
```

Access at **https://your-domain.com**

---

## Documentation

| Guide | Description |
|-------|-------------|
| [INSTALLATION.md](docs/INSTALLATION.md) | Complete installation guide with troubleshooting |
| [SYNOLOGY.md](docs/SYNOLOGY.md) | Synology NAS Container Manager setup |
| [QNAP Guide](https://github.com/Crosstalk-Solutions/unifi-toolkit/issues/29) | QNAP Container Station setup (community) |
| [Unraid Guide](docs/UNRAID.md) | Unraid Community apps Setup |
| [QUICKSTART.md](docs/QUICKSTART.md) | 5-minute quick start reference |

---

## Common Commands

| Action | Command |
|--------|---------|
| Start (local) | `docker compose up -d` |
| Start (production) | `docker compose --profile production up -d` |
| Stop | `docker compose down` |
| View logs | `docker compose logs -f` |
| Restart | `docker compose restart` |
| Reset password | `./reset_password.sh` |
| Update | `./upgrade.sh` |

---

## Configuration

### Setup Wizard (Recommended)

Run the interactive setup wizard:

```bash
./setup.sh
```

The wizard will:
- Generate encryption key
- Configure deployment mode (local/production)
- Set up authentication (production only)
- Create your `.env` file

### Manual Configuration

Copy and edit the example configuration:

```bash
cp .env.example .env
```

#### Required Settings

| Variable | Description |
|----------|-------------|
| `ENCRYPTION_KEY` | Encrypts stored credentials (auto-generated by setup wizard) |

#### Deployment Settings (Production Only)

| Variable | Description |
|----------|-------------|
| `DEPLOYMENT_TYPE` | `local` or `production` |
| `DOMAIN` | Your domain name (e.g., `toolkit.example.com`) |
| `AUTH_USERNAME` | Admin username |
| `AUTH_PASSWORD_HASH` | Bcrypt password hash (generated by setup wizard) |

#### UniFi Controller Settings

Configure via `.env` or the web UI (web UI takes precedence):

| Variable | Description |
|----------|-------------|
| `UNIFI_CONTROLLER_URL` | Controller URL (e.g., `https://192.168.1.1`) |
| `UNIFI_USERNAME` | Username (legacy controllers) |
| `UNIFI_PASSWORD` | Password (legacy controllers) |
| `UNIFI_API_KEY` | API key (UniFi OS: UDM, UCG, Cloud Key) |
| `UNIFI_SITE_ID` | Site ID from URL, not friendly name (default: `default`). For multi-site, use ID from `/manage/site/{id}/...` |
| `UNIFI_VERIFY_SSL` | SSL verification (default: `false`) |

#### Tool Settings

| Variable | Description |
|----------|-------------|
| `STALKER_REFRESH_INTERVAL` | Device refresh interval in seconds (default: `60`) |

---

## Security

### Authentication

- **Local mode**: No authentication (trusted LAN only)
- **Production mode**: Session-based authentication with bcrypt password hashing
- **Rate limiting**: 5 failed login attempts = 5 minute lockout

### HTTPS

Production deployments use Caddy for automatic HTTPS:
- Let&#039;s Encrypt certificates (auto-renewed)
- HTTP to HTTPS redirect
- Security headers (HSTS, X-Frame-Options, etc.)

### Multi-Site Networking

When managing multiple UniFi sites, always use site-to-site VPN:

```
‚úÖ RECOMMENDED: VPN Connection
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  UI Toolkit      ‚îÇ‚óÑ‚îÄ‚îÄVPN‚îÄ‚îÄ‚ñ∫‚îÇ  Remote UniFi    ‚îÇ
‚îÇ  Server          ‚îÇ         ‚îÇ  Controller      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚ùå AVOID: Direct Internet Exposure
Never expose UniFi controllers via port forwarding
```

**VPN Options:** UniFi Site-to-Site, WireGuard, Tailscale, IPSec

---

## Troubleshooting

### Can&#039;t connect to UniFi controller
- Set `UNIFI_VERIFY_SSL=false` for self-signed certificates
- UniFi OS devices (UDM, UCG) require an API key, not username/password
- Verify network connectivity to controller

### Device not showing as online
- Wait 60 seconds for the next refresh cycle
- Verify MAC address format is correct
- Confirm device is connected in UniFi dashboard

### Let&#039;s Encrypt certificate fails
- Verify DNS A record points to your server
- Ensure ports 80 and 443 are open
- Check Caddy logs: `docker compose logs caddy`

### Rate limited on login
- Wait 5 minutes for lockout to expire
- Use `./reset_password.sh` if you forgot your password

### Docker issues
- Verify `.env` exists and contains `ENCRYPTION_KEY`
- Check logs: `docker compose logs -f`
- Pull latest image: `docker compose pull &amp;&amp; docker compose up -d`

---

## Running with Python (Alternative to Docker)

```bash
# Clone repository
git clone https://github.com/Crosstalk-Solutions/unifi-toolkit.git
cd unifi-toolkit

# Create virtual environment (Python 3.9-3.12 only, NOT 3.13+)
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run setup wizard
./setup.sh

# Start application
python run.py
```

---

## Project Structure

```
unifi-toolkit/
‚îú‚îÄ‚îÄ app/                    # Main application
‚îÇ   ‚îú‚îÄ‚îÄ main.py            # FastAPI entry point
‚îÇ   ‚îú‚îÄ‚îÄ routers/           # API routes (auth, config)
‚îÇ   ‚îú‚îÄ‚îÄ static/            # CSS, images
‚îÇ   ‚îî‚îÄ‚îÄ templates/         # HTML templates
‚îú‚îÄ‚îÄ tools/                 # Individual tools
‚îÇ   ‚îú‚îÄ‚îÄ wifi_stalker/      # Wi-Fi Stalker tool
‚îÇ   ‚îú‚îÄ‚îÄ threat_watch/      # Threat Watch tool
‚îÇ   ‚îî‚îÄ‚îÄ network_pulse/     # Network Pulse tool
‚îú‚îÄ‚îÄ shared/                # Shared infrastructure
‚îÇ   ‚îú‚îÄ‚îÄ config.py          # Settings management
‚îÇ   ‚îú‚îÄ‚îÄ database.py        # SQLAlchemy setup
‚îÇ   ‚îú‚îÄ‚îÄ unifi_client.py    # UniFi API wrapper
‚îÇ   ‚îî‚îÄ‚îÄ crypto.py          # Credential encryption
‚îú‚îÄ‚îÄ docs/                  # Documentation
‚îú‚îÄ‚îÄ data/                  # Database (created at runtime)
‚îú‚îÄ‚îÄ setup.sh               # Setup wizard
‚îú‚îÄ‚îÄ upgrade.sh             # Upgrade script
‚îú‚îÄ‚îÄ reset_password.sh      # Password reset utility
‚îú‚îÄ‚îÄ Caddyfile              # Reverse proxy config
‚îú‚îÄ‚îÄ docker-compose.yml     # Docker configuration
‚îî‚îÄ‚îÄ requirements.txt       # Python dependencies
```

---

## Development

### Running Tests

The project includes a comprehensive test suite covering authentication, caching, configuration, and encryption.

```bash
# Install development dependencies
pip install -r requirements-dev.txt

# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_auth.py -v

# Run with coverage
pytest tests/ --cov=shared --cov=app -v
```

**Test modules:**
- `tests/test_auth.py` - Authentication, session management, rate limiting (22 tests)
- `tests/test_cache.py` - In-memory caching with TTL expiration (18 tests)
- `tests/test_config.py` - Pydantic settings and environment variables (13 tests)
- `tests/test_crypto.py` - Fernet encryption for credentials (15 tests)

---

## Support

- **Community**: [#unifi-toolkit on Discord](https://discord.com/invite/crosstalksolutions)
- **Issues**: [GitHub Issues](https://github.com/Crosstalk-Solutions/unifi-toolkit/issues)
- **Documentation**: [docs/](docs/)

### Buy Me a Coffee

If you find UI Toolkit useful, consider supporting development:

[![ko-fi](https://ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/crosstalk)

---

## Credits

Developed by [Crosstalk Solutions](https://www.crosstalksolutions.com/)

- YouTube: [@CrosstalkSolutions](https://www.youtube.com/@CrosstalkSolutions)

---

## License

MIT License
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[freemocap/freemocap]]></title>
            <link>https://github.com/freemocap/freemocap</link>
            <guid>https://github.com/freemocap/freemocap</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:46 GMT</pubDate>
            <description><![CDATA[Free Motion Capture for Everyone üíÄ‚ú®]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/freemocap/freemocap">freemocap/freemocap</a></h1>
            <p>Free Motion Capture for Everyone üíÄ‚ú®</p>
            <p>Language: Python</p>
            <p>Stars: 5,677</p>
            <p>Forks: 450</p>
            <p>Stars today: 188 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/freemocap/freemocap/assets/15314521/da1af7fe-f808-43dc-8f59-c579715d6593&quot; height=&quot;240&quot; alt=&quot;Project Logo&quot;&gt;
&lt;/p&gt; 


&lt;h3 align=&quot;center&quot;&gt;The FreeMoCap Project&lt;/h3&gt;
&lt;h4 align=&quot;center&quot;&gt; A free-and-open-source, hardware-and-software-agnostic, minimal-cost, research-grade, motion capture
system and platform for decentralized scientific research, education, and training&lt;/h2&gt;


&lt;p align=&quot;center&quot;&gt;

&lt;a href=&quot;https://doi.org/10.5281/zenodo.7233714&quot;&gt;
    &lt;img src=&quot;https://zenodo.org/badge/DOI/10.5281/zenodo.7233714.svg&quot; alt=DOI-via-Zenodo.org&gt;
  &lt;/a&gt;

&lt;a href=&quot;https://github.com/psf/black&quot;&gt;
    &lt;img alt=&quot;https://img.shields.io/badge/code%20style-black-000000.svg&quot; src=&quot;https://img.shields.io/badge/code%20style-black-000000.svg&quot;&gt;
  &lt;/a&gt;

&lt;a href=&quot;https://github.com/freemocap/freemocap/releases/latest&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/github/release/freemocap/freemocap.svg&quot; alt=&quot;Latest Release&quot;&gt;
    &lt;/a&gt;

&lt;a href=&quot;https://github.com/freemocap/freemocap/blob/main/LICENSE&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/license-AGPL-blue.svg&quot; alt=&quot;AGPLv3&quot;&gt;
    &lt;/a&gt;

&lt;a href=&quot;https://github.com/freemocap/freemocap/issues&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/contributions-welcome-ff69b4.svg&quot; alt=&quot;Contributions Welcome&quot;&gt;
    &lt;/a&gt;

&lt;a href=&quot;https://github.com/psf/black&quot;&gt;
    &lt;img alt=&quot;https://img.shields.io/badge/code%20style-black-000000.svg&quot; src=&quot;https://img.shields.io/badge/code%20style-black-000000.svg&quot;&gt;
  &lt;/a&gt;

&lt;a href=&quot;https://discord.gg/SgdnzbHDTG&quot;&gt;
    &lt;img alt=&quot;Discord Community Server&quot; src=&quot;https://dcbadge.vercel.app/api/server/SgdnzbHDTG?style=flat&quot;&gt;
  &lt;/a&gt;


&lt;/p&gt;


https://user-images.githubusercontent.com/15314521/192062522-2a8d9305-f181-4869-a4b9-1aa068e094c9.mp4





--
## QUICKSTART

&gt; [!NOTE] 
&gt; For  detailed installation instructions, see our [official documentation&#039;s Installation page](https://freemocap.github.io/documentation/installation.html#detailed-pip-installation-instructions)


#### 0. Create a a Python 3.10 through 3.12 environment (python3.12 recommended)
#### 1. Install software via [pip](https://pypi.org/project/freemocap/#description):

```
pip install freemocap
```

#### 2. Launch the GUI by entering the command:

```
freemocap
``` 

####  3. A GUI should pop up that looks like this: 

   &lt;img width=&quot;1457&quot; alt=&quot;image&quot; src=&quot;https://github.com/freemocap/freemocap/assets/15314521/90ef7e7b-48f3-4f46-8d4a-5b5bcc3254b3&quot;&gt;

#### 4. Have fun! See the [Beginner Tutorials](https://freemocap.github.io/documentation/your-first-recording.html) on our official docs for detailed instructions.

#### 5. [Join the Discord and let us know how it went!](https://discord.gg/nxv5dNTfKT)



___
## Install/run from source code (i.e. the code in this repo)

Open an [Anaconda-enabled command prompt](https://www.anaconda.org) (or your preferred method of environment management) and enter the following commands:

1) Create a `Python` environment (Recommended version  is `python3.11`)

```bash
conda create -n freemocap-env python=3.11
```

2) Activate that newly created environment

```bash
conda activate freemocap-env
```

3) Clone the repository

```bash
git clone https://github.com/freemocap/freemocap
```

4) Navigate into the newly cloned/downloaded `freemocap` folder

```bash
cd freemocap
```

5) Install the package via the `pyproject.toml` file

```bash
pip install -e .
```

6) Launch the GUI (via the `freemocap.__main__.py` entry point)

```bash
python -m freemocap
```

A GUI should pop up!

___

## Documentation 

Our documentation is hosted at: https://freemocap.github.io/documentation

That site is built using `writerside` from this repository: https://github.com/freemocap/documentation

___



### Contribution Guidelines

Please read our contribution doc: [CONTRIBUTING.md](CONTRIBUTING.md)


## Related

[//]: # (* [project-name]&amp;#40;#&amp;#41; - Project description)

## Maintainers

* [Jon Matthis](https://github.com/jonmatthis)
* [Endurance Idehen](https://github.com/endurance)

## License

This project is licensed under the APGL License - see the [LICENSE](LICENSE) file for details.

If the AGPL does not work for your needs, we are happy to discuss terms to license this software to you with a different
agreement at a price point that increases exponentially as you
move [spiritually](https://www.gnu.org/philosophy/open-source-misses-the-point.en.html) away from the `AGPL`

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Azure/azure-sdk-for-python]]></title>
            <link>https://github.com/Azure/azure-sdk-for-python</link>
            <guid>https://github.com/Azure/azure-sdk-for-python</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:45 GMT</pubDate>
            <description><![CDATA[This repository is for active development of the Azure SDK for Python. For consumers of the SDK we recommend visiting our public developer docs at https://learn.microsoft.com/python/azure/ or our versioned developer docs at https://azure.github.io/azure-sdk-for-python.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Azure/azure-sdk-for-python">Azure/azure-sdk-for-python</a></h1>
            <p>This repository is for active development of the Azure SDK for Python. For consumers of the SDK we recommend visiting our public developer docs at https://learn.microsoft.com/python/azure/ or our versioned developer docs at https://azure.github.io/azure-sdk-for-python.</p>
            <p>Language: Python</p>
            <p>Stars: 5,493</p>
            <p>Forks: 3,243</p>
            <p>Stars today: 3 stars today</p>
            <h2>README</h2><pre># Azure SDK for Python

[![Packages](https://img.shields.io/badge/packages-latest-blue.svg)](https://azure.github.io/azure-sdk/releases/latest/python.html) [![Dependencies](https://img.shields.io/badge/dependency-report-blue.svg)](https://azuresdkartifacts.blob.core.windows.net/azure-sdk-for-python/dependencies/dependencies.html) [![DepGraph](https://img.shields.io/badge/dependency-graph-blue.svg)](https://azuresdkartifacts.blob.core.windows.net/azure-sdk-for-python/dependencies/dependencyGraph/index.html) [![Python](https://img.shields.io/pypi/pyversions/azure-core.svg?maxAge=2592000)](https://pypi.python.org/pypi/azure/) [![Build Status](https://dev.azure.com/azure-sdk/public/_apis/build/status/python/python%20-%20core%20-%20ci?branchName=main)](https://dev.azure.com/azure-sdk/public/_build/latest?definitionId=458&amp;branchName=main)

This repository is for the active development of the Azure SDK for Python. For consumers of the SDK we recommend visiting our [public developer docs](https://docs.microsoft.com/python/azure/) or our versioned [developer docs](https://azure.github.io/azure-sdk-for-python).

## Getting started

For your convenience, each service has a separate set of libraries that you can choose to use instead of one, large Azure package. To get started with a specific library, see the `README.md` (or `README.rst`) file located in the library&#039;s project folder.

You can find service libraries in the `/sdk` directory.

### Prerequisites

The client libraries are supported on Python 3.9 or later. For more details, please read our page on [Azure SDK for Python version support policy](https://github.com/Azure/azure-sdk-for-python/wiki/Azure-SDKs-Python-version-support-policy).

## Packages available

Each service might have a number of libraries available from each of the following categories:
* [Client - New Releases](#client-new-releases)
* [Client - Previous Versions](#client-previous-versions)
* [Management - New Releases](#management-new-releases)
* [Management - Previous Versions](#management-previous-versions)

### Client: New Releases

New wave of packages that we are announcing as **GA** and several that are currently releasing in **preview**. These libraries allow you to use and consume existing resources and interact with them, for example: upload a blob. These libraries share  several core functionalities such as: retries, logging, transport protocols, authentication protocols, etc. that can be found in the [azure-core](https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/core/azure-core) library. You can learn more about these libraries by reading guidelines that they follow [here](https://azure.github.io/azure-sdk/python/guidelines/index.html).

You can find the [most up to date list of all of the new packages on our page](https://azure.github.io/azure-sdk/releases/latest/index.html#python)

&gt; NOTE: If you need to ensure your code is ready for production use one of the stable, non-preview libraries.

### Client: Previous Versions

Last stable versions of packages that have been provided for usage with Azure and are production-ready. These libraries provide you with similar functionalities to the Preview ones as they allow you to use and consume existing resources and interact with them, for example: upload a blob. They might not implement the [guidelines](https://azure.github.io/azure-sdk/python/guidelines/index.html) or have the same feature set as the November releases. They do however offer wider coverage of services.

### Management: New Releases
A new set of management libraries that follow the [Azure SDK Design Guidelines for Python](https://azure.github.io/azure-sdk/python/guidelines/) are now available. These new libraries provide a number of core capabilities that are shared amongst all Azure SDKs, including the intuitive Azure Identity library, an HTTP Pipeline with custom policies, error-handling, distributed tracing, and much more.
Documentation and code samples for these new libraries can be found [here](https://aka.ms/azsdk/python/mgmt). In addition, a migration guide that shows how to transition from older versions of libraries is located [here](https://github.com/Azure/azure-sdk-for-python/blob/main/doc/sphinx/mgmt_quickstart.rst#migration-guide).

You can find the [most up to date list of all of the new packages on our page](https://azure.github.io/azure-sdk/releases/latest/mgmt/python.html)

&gt; NOTE: If you need to ensure your code is ready for production use one of the stable, non-preview libraries. Also, if you are experiencing authentication issues with the management libraries after upgrading certain packages, it&#039;s possible that you upgraded to the new versions of SDK without changing the authentication code, please refer to the migration guide mentioned above for proper instructions.

### Management: Previous Versions
For a complete list of management libraries that enable you to provision and manage Azure resources, please [check here](https://azure.github.io/azure-sdk/releases/latest/all/python.html). They might not have the same feature set as the new releases but they do offer wider coverage of services.
Management libraries can be identified by namespaces that start with `azure-mgmt-`, e.g. `azure-mgmt-compute`

## Need help?

* For detailed documentation visit our [Azure SDK for Python documentation](https://aka.ms/python-docs)
* File an issue via [GitHub Issues](https://github.com/Azure/azure-sdk-for-python/issues)
* Check [previous questions](https://stackoverflow.com/questions/tagged/azure+python) or ask new ones on StackOverflow using `azure` and `python` tags.


## Data Collection
The software may collect information about you and your use of the software and send it to Microsoft. Microsoft may use this information to provide services and improve our products and services. You may turn off the telemetry as described below. You can learn more about data collection and use in the help documentation and Microsoft‚Äôs [privacy statement](https://go.microsoft.com/fwlink/?LinkID=824704). For more information on the data collected by the Azure SDK, please visit the [Telemetry Guidelines](https://azure.github.io/azure-sdk/general_azurecore.html#telemetry-policy) page.

### Telemetry Configuration
Telemetry collection is on by default.

To opt out, you can disable telemetry at client construction. Define a `NoUserAgentPolicy` class that is a subclass of `UserAgentPolicy` with an `on_request` method that does nothing. Then pass instance of this class as kwargs `user_agent_policy=NoUserAgentPolicy()` during client creation. This will disable telemetry for all methods in the client. Do this for every new client.

The example below uses the `azure-storage-blob` package. In your code, you can replace `azure-storage-blob` with the package you are using.

```python
import os
from azure.identity import ManagedIdentityCredential
from azure.storage.blob import BlobServiceClient
from azure.core.pipeline.policies import UserAgentPolicy


# Create your credential you want to use
mi_credential = ManagedIdentityCredential()

account_url = &quot;https://&lt;storageaccountname&gt;.blob.core.windows.net&quot;

# Set up user-agent override
class NoUserAgentPolicy(UserAgentPolicy):
    def on_request(self, request):
        pass

# Create the BlobServiceClient object
blob_service_client = BlobServiceClient(account_url, credential=mi_credential, user_agent_policy=NoUserAgentPolicy())

container_client = blob_service_client.get_container_client(container=&lt;container_name&gt;) 
# TODO: do something with the container client like download blob to a file
```

### Reporting security issues and security bugs

Security issues and bugs should be reported privately, via email, to the Microsoft Security Response Center (MSRC) &lt;secure@microsoft.com&gt;. You should receive a response within 24 hours. If for some reason you do not, please follow up via email to ensure we received your original message. Further information, including the MSRC PGP key, can be found in the [Security TechCenter](https://www.microsoft.com/msrc/faqs-report-an-issue).

## Contributing

For details on contributing to this repository, see the [contributing guide](https://github.com/Azure/azure-sdk-for-python/blob/main/CONTRIBUTING.md).

This project welcomes contributions and suggestions. Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit
https://cla.microsoft.com.

When you submit a pull request, a CLA-bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repositories using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/)
or contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.



</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Fosowl/agenticSeek]]></title>
            <link>https://github.com/Fosowl/agenticSeek</link>
            <guid>https://github.com/Fosowl/agenticSeek</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:44 GMT</pubDate>
            <description><![CDATA[Fully Local Manus AI. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity. üîî Official updates only via twitter @Martin993886460 (Beware of fake account)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Fosowl/agenticSeek">Fosowl/agenticSeek</a></h1>
            <p>Fully Local Manus AI. No APIs, No $200 monthly bills. Enjoy an autonomous agent that thinks, browses the web, and code for the sole cost of electricity. üîî Official updates only via twitter @Martin993886460 (Beware of fake account)</p>
            <p>Language: Python</p>
            <p>Stars: 25,082</p>
            <p>Forks: 2,782</p>
            <p>Stars today: 40 stars today</p>
            <h2>README</h2><pre># AgenticSeek: Private, Local Manus Alternative.

&lt;p align=&quot;center&quot;&gt;
&lt;img align=&quot;center&quot; src=&quot;./media/agentic_seek_logo.png&quot; width=&quot;300&quot; height=&quot;300&quot; alt=&quot;Agentic Seek Logo&quot;&gt;
&lt;p&gt;

  English | [‰∏≠Êñá](./README_CHS.md) | [ÁπÅÈ´î‰∏≠Êñá](./README_CHT.md) | [Fran√ßais](./README_FR.md) | [Êó•Êú¨Ë™û](./README_JP.md) | [Portugu√™s (Brasil)](./README_PTBR.md) | [Espa√±ol](./README_ES.md)

*A **100% local alternative to Manus AI**, this voice-enabled AI assistant autonomously browses the web, writes code, and plans tasks while keeping all data on your device. Tailored for local reasoning models, it runs entirely on your hardware, ensuring complete privacy and zero cloud dependency.*

[![Visit AgenticSeek](https://img.shields.io/static/v1?label=Website&amp;message=AgenticSeek&amp;color=blue&amp;style=flat-square)](https://fosowl.github.io/agenticSeek.html) ![License](https://img.shields.io/badge/license-GPL--3.0-green) [![Discord](https://img.shields.io/badge/Discord-Join%20Us-7289DA?logo=discord&amp;logoColor=white)](https://discord.gg/8hGDaME3TC) [![Twitter](https://img.shields.io/twitter/url/https/twitter.com/fosowl.svg?style=social&amp;label=Update%20%40Fosowl)](https://x.com/Martin993886460) [![GitHub stars](https://img.shields.io/github/stars/Fosowl/agenticSeek?style=social)](https://github.com/Fosowl/agenticSeek/stargazers)

### Why AgenticSeek ?

* üîí Fully Local &amp; Private - Everything runs on your machine ‚Äî no cloud, no data sharing. Your files, conversations, and searches stay private.

* üåê Smart Web Browsing - AgenticSeek can browse the internet by itself ‚Äî search, read, extract info, fill web form ‚Äî all hands-free.

* üíª Autonomous Coding Assistant - Need code? It can write, debug, and run programs in Python, C, Go, Java, and more ‚Äî all without supervision.

* üß† Smart Agent Selection - You ask, it figures out the best agent for the job automatically. Like having a team of experts ready to help.

* üìã Plans &amp; Executes Complex Tasks - From trip planning to complex projects ‚Äî it can split big tasks into steps and get things done using multiple AI agents.

* üéôÔ∏è Voice-Enabled - Clean, fast, futuristic voice and speech to text allowing you to talk to it like it&#039;s your personal AI from a sci-fi movie. (In progress)

### **Demo**

&gt; *Can you search for the agenticSeek project, learn what skills are required, then open the CV_candidates.zip and then tell me which match best the project*

https://github.com/user-attachments/assets/b8ca60e9-7b3b-4533-840e-08f9ac426316

Disclaimer: This demo, including all the files that appear (e.g: CV_candidates.zip), are entirely fictional. We are not a corporation, we seek open-source contributors not candidates.

&gt; üõ†‚ö†Ô∏èÔ∏è **Active Work in Progress**

&gt; üôè This project started as a side-project and has zero roadmap and zero funding. It&#039;s grown way beyond what I expected by ending in GitHub Trending. Contributions, feedback, and patience are deeply appreciated.

## Prerequisites

Before you begin, ensure you have the following software installed:

*   **Git:** For cloning the repository. [Download Git](https://git-scm.com/downloads)
*   **Python 3.10.x:** We strongly recommend using Python version 3.10.x. Using other versions might lead to dependency errors. [Download Python 3.10](https://www.python.org/downloads/release/python-3100/) (pick a 3.10.x version).
*   **Docker Engine &amp; Docker Compose:** For running bundled services like SearxNG.
    *   Install Docker Desktop (which includes Docker Compose V2): [Windows](https://docs.docker.com/desktop/install/windows-install/) | [Mac](https://docs.docker.com/desktop/install/mac-install/) | [Linux](https://docs.docker.com/desktop/install/linux-install/)
    *   Alternatively, install Docker Engine and Docker Compose separately on Linux: [Docker Engine](https://docs.docker.com/engine/install/) | [Docker Compose](https://docs.docker.com/compose/install/) (ensure you install Compose V2, e.g., `sudo apt-get install docker-compose-plugin`).

### 1. **Clone the repository and setup**

```sh
git clone https://github.com/Fosowl/agenticSeek.git
cd agenticSeek
mv .env.example .env
```

### 2. Change the .env file content

```sh
SEARXNG_BASE_URL=&quot;http://searxng:8080&quot; # http://127.0.0.1:8080 if running on host
REDIS_BASE_URL=&quot;redis://redis:6379/0&quot;
WORK_DIR=&quot;/Users/mlg/Documents/workspace_for_ai&quot;
OLLAMA_PORT=&quot;11434&quot;
LM_STUDIO_PORT=&quot;1234&quot;
CUSTOM_ADDITIONAL_LLM_PORT=&quot;11435&quot;
OPENAI_API_KEY=&#039;optional&#039;
DEEPSEEK_API_KEY=&#039;optional&#039;
OPENROUTER_API_KEY=&#039;optional&#039;
TOGETHER_API_KEY=&#039;optional&#039;
GOOGLE_API_KEY=&#039;optional&#039;
ANTHROPIC_API_KEY=&#039;optional&#039;
```


Update the `.env` file with your own values as needed:

- **SEARXNG_BASE_URL**: Leave unchanged unless running on host with CLI mode.
- **REDIS_BASE_URL**: Leave unchanged 
- **WORK_DIR**: Path to your working directory on your local machine. AgenticSeek will be able to read and interact with these files.
- **OLLAMA_PORT**: Port number for the Ollama service.
- **LM_STUDIO_PORT**: Port number for the LM Studio service.
- **CUSTOM_ADDITIONAL_LLM_PORT**: Port for any additional custom LLM service.

**API Key are totally optional for user who choose to run LLM locally. Which is the primary purpose of this project. Leave empty if you have sufficient hardware**

### 3. **Start Docker**

Make sure Docker is installed and running on your system. You can start Docker using the following commands:

- **On Linux/macOS:**  
    Open a terminal and run:
    ```sh
    sudo systemctl start docker
    ```
    Or launch Docker Desktop from your applications menu if installed.

- **On Windows:**  
    Start Docker Desktop from the Start menu.

You can verify Docker is running by executing:
```sh
docker info
```
If you see information about your Docker installation, it is running correctly.

See the table of [Local Providers](#list-of-local-providers) below for a summary.

Next step: [Run AgenticSeek locally](#start-services-and-run)

*See the [Troubleshooting](#troubleshooting) section if you are having issues.*
*If your hardware can&#039;t run LLMs locally, see [Setup to run with an API](#setup-to-run-with-an-api).*
*For detailed `config.ini` explanations, see [Config Section](#config).*

---

## Setup for running LLM locally on your machine

**Hardware Requirements:**

To run LLMs locally, you&#039;ll need sufficient hardware. At a minimum, a GPU capable of running Magistral, Qwen or Deepseek 14B is required. See the FAQ for detailed model/performance recommendations.

**Setup your local provider**  

Start your local provider (for example with ollama):

Unless you wish to to run AgenticSeek on host (CLI mode), export or set the provider listen address:

```sh
export OLLAMA_HOST=0.0.0.0:11434
```

Then, start you provider:

```sh
ollama serve
```

See below for a list of local supported provider.

**Update the config.ini**

Change the config.ini file to set the provider_name to a supported provider and provider_model to a LLM supported by your provider. We recommend reasoning model such as *Magistral* or *Deepseek*.

See the **FAQ** at the end of the README for required hardware.

```sh
[MAIN]
is_local = True # Whenever you are running locally or with remote provider.
provider_name = ollama # or lm-studio, openai, etc..
provider_model = deepseek-r1:14b # choose a model that fit your hardware
provider_server_address = 127.0.0.1:11434
agent_name = Jarvis # name of your AI
recover_last_session = True # whenever to recover the previous session
save_session = True # whenever to remember the current session
speak = False # text to speech
listen = False # Speech to text, only for CLI, experimental
jarvis_personality = False # Whenever to use a more &quot;Jarvis&quot; like personality (experimental)
languages = en zh # The list of languages, Text to speech will default to the first language on the list
[BROWSER]
headless_browser = True # leave unchanged unless using CLI on host.
stealth_mode = True # Use undetected selenium to reduce browser detection
```

**Warning**:

- The `config.ini` file format does not support comments. 
Do not copy and paste the example configuration directly, as comments will cause errors.  Instead, manually modify the `config.ini` file with your desired settings, excluding any comments.

- Do *NOT* set provider_name to `openai` if using LM-studio for running LLMs. Set it to `lm-studio`.

- Some provider (eg: lm-studio) require you to have `http://` in front of the IP. For example `http://127.0.0.1:1234`

**List of local providers**

| Provider  | Local? | Description                                               |
|-----------|--------|-----------------------------------------------------------|
| ollama    | Yes    | Run LLMs locally with ease using ollama as a LLM provider |
| lm-studio  | Yes    | Run LLM locally with LM studio (set `provider_name` to `lm-studio`)|
| openai    | Yes     |  Use openai compatible API (eg: llama.cpp server)  |

Next step: [Start services and run AgenticSeek](#Start-services-and-Run)  

*See the [Troubleshooting](#troubleshooting) section if you are having issues.*
*If your hardware can&#039;t run LLMs locally, see [Setup to run with an API](#setup-to-run-with-an-api).*
*For detailed `config.ini` explanations, see [Config Section](#config).*

## Setup to run with an API

This setup uses external, cloud-based LLM providers. You&#039;ll need an API key from your chosen service.

**1. Choose an API Provider and Get an API Key:**

Refer to the [List of API Providers](#list-of-api-providers) below. Visit their websites to sign up and obtain an API key.

**2. Set Your API Key as an Environment Variable:**


*   **Linux/macOS:**
    Open your terminal and use the `export` command. It&#039;s best to add this to your shell&#039;s profile file (e.g., `~/.bashrc`, `~/.zshrc`) for persistence.
    ```sh
    export PROVIDER_API_KEY=&quot;your_api_key_here&quot; 
    # Replace PROVIDER_API_KEY with the specific variable name, e.g., OPENAI_API_KEY, GOOGLE_API_KEY
    ```
    Example for TogetherAI:
    ```sh
    export TOGETHER_API_KEY=&quot;xxxxxxxxxxxxxxxxxxxxxx&quot;
    ```
*   **Windows:**
    *   **Command Prompt (Temporary for current session):**
        ```cmd
        set PROVIDER_API_KEY=your_api_key_here
        ```
    *   **PowerShell (Temporary for current session):**
        ```powershell
        $env:PROVIDER_API_KEY=&quot;your_api_key_here&quot;
        ```
    *   **Permanently:** Search for &quot;environment variables&quot; in the Windows search bar, click &quot;Edit the system environment variables,&quot; then click the &quot;Environment Variables...&quot; button. Add a new User variable with the appropriate name (e.g., `OPENAI_API_KEY`) and your key as the value.

    *(See FAQ: [How do I set API keys?](#how-do-i-set-api-keys) for more details).*


**3. Update `config.ini`:**
```ini
[MAIN]
is_local = False
provider_name = openai # Or google, deepseek, togetherAI, huggingface
provider_model = gpt-3.5-turbo # Or gemini-1.5-flash, deepseek-chat, mistralai/Mixtral-8x7B-Instruct-v0.1 etc.
provider_server_address = # Typically ignored or can be left blank when is_local = False for most APIs
# ... other settings ...
```
*Warning:* Make sure there are no trailing spaces in the `config.ini` values.

**List of API Providers**

| Provider     | `provider_name` | Local? | Description                                       | API Key Link (Examples)                     |
|--------------|-----------------|--------|---------------------------------------------------|---------------------------------------------|
| OpenAI       | `openai`        | No     | Use ChatGPT models via OpenAI&#039;s API.              | [platform.openai.com/signup](https://platform.openai.com/signup) |
| Google Gemini| `google`        | No     | Use Google Gemini models via Google AI Studio.    | [aistudio.google.com/keys](https://aistudio.google.com/keys) |
| Deepseek     | `deepseek`      | No     | Use Deepseek models via their API.                | [platform.deepseek.com](https://platform.deepseek.com) |
| Hugging Face | `huggingface`   | No     | Use models from Hugging Face Inference API.       | [huggingface.co/settings/tokens](https://huggingface.co/settings/tokens) |
| TogetherAI   | `togetherAI`    | No     | Use various open-source models via TogetherAI API.| [api.together.ai/settings/api-keys](https://api.together.ai/settings/api-keys) |
| OpenRouter   | `openrouter`    | No     | Use OpenRouter Models| [https://openrouter.ai/](https://openrouter.ai/) |

*Note:*
*   We advise against using `gpt-4o` or other OpenAI models for complex web browsing and task planning as current prompt optimizations are geared towards models like Deepseek.
*   Coding/bash tasks might encounter issues with Gemini, as it may not strictly follow formatting prompts optimized for Deepseek.
*   The `provider_server_address` in `config.ini` is generally not used when `is_local = False` as the API endpoint is usually hardcoded in the respective provider&#039;s library.

Next step: [Start services and run AgenticSeek](#Start-services-and-Run)

*See the **Known issues** section if you are having issues*

*See the **Config** section for detailed config file explanation.*

---

## Start services and Run

By default AgenticSeek is run fully in docker.

**Option 1:** Run in Docker, use web interface:

Start required services. This will start all services from the docker-compose.yml, including:
    - searxng
    - redis (required by searxng)
    - frontend
    - backend (if using `full` when using the web interface)

```sh
./start_services.sh full # MacOS
start start_services.cmd full # Window
```

**Warning:** This step will download and load all Docker images, which may take up to 30 minutes. After starting the services, please wait until the backend service is fully running (you should see **backend: &quot;GET /health HTTP/1.1&quot; 200 OK** in the log) before sending any messages. The backend services might take 5 minute to start on first run.

Go to `http://localhost:3000/` and you should see the web interface.

*Troubleshooting service start:* If these scripts fail, ensure Docker Engine is running and Docker Compose (V2, `docker compose`) is correctly installed. Check the output in the terminal for error messages. See [FAQ: Help! I get an error when running AgenticSeek or its scripts.](#faq-troubleshooting)

**Option 2:** CLI mode:

To run with CLI interface you would have to install package on host:

```sh
./install.sh
./install.bat # windows
```

Then you must change the SEARXNG_BASE_URL in `config.ini` to:

```sh
SEARXNG_BASE_URL=&quot;http://localhost:8080&quot;
```

Start required services. This will start some services from the docker-compose.yml, including:
    - searxng
    - redis (required by searxng)
    - frontend

```sh
./start_services.sh # MacOS
start start_services.cmd # Window
```

Run: uv run: `uv run python -m ensurepip` to ensure uv has pip enabled.

Use the CLI: `uv run cli.py`


---

## Usage

Make sure the services are up and running with `./start_services.sh full` and go to `localhost:3000` for web interface.

You can also use speech to text by setting `listen = True` in the config. Only for CLI mode.

To exit, simply say/type `goodbye`.

Here are some example usage:

&gt; *Make a snake game in python!*

&gt; *Search the web for top cafes in Rennes, France, and save a list of three with their addresses in rennes_cafes.txt.*

&gt; *Write a Go program to calculate the factorial of a number, save it as factorial.go in your workspace*

&gt; *Search my summer_pictures folder for all JPG files, rename them with today‚Äôs date, and save a list of renamed files in photos_list.txt*

&gt; *Search online for popular sci-fi movies from 2024 and pick three to watch tonight. Save the list in movie_night.txt.*

&gt; *Search the web for the latest AI news articles from 2025, select three, and write a Python script to scrape their titles and summaries. Save the script as news_scraper.py and the summaries in ai_news.txt in /home/projects*

&gt; *Friday, search the web for a free stock price API, register with supersuper7434567@gmail.com then write a Python script to fetch using the API daily prices for Tesla, and save the results in stock_prices.csv*

*Note that form filling capabilities are still experimental and might fail.*



After you type your query, AgenticSeek will allocate the best agent for the task.

Because this is an early prototype, the agent routing system might not always allocate the right agent based on your query.

Therefore, you should be very explicit in what you want and how the AI might proceed for example if you want it to conduct a web search, do not say:

`Do you know some good countries for solo-travel?`

Instead, ask:

`Do a web search and find out which are the best country for solo-travel`

---

## **Setup to run the LLM on your own server**  

If you have a powerful computer or a server that you can use, but you want to use it from your laptop you have the options to run the LLM on a remote server using our custom llm server. 

On your &quot;server&quot; that will run the AI model, get the ip address

```sh
ip a | grep &quot;inet &quot; | grep -v 127.0.0.1 | awk &#039;{print $2}&#039; | cut -d/ -f1 # local ip
curl https://ipinfo.io/ip # public ip
```

Note: For Windows or macOS, use ipconfig or ifconfig respectively to find the IP address.

Clone the repository and enter the `server/`folder.


```sh
git clone --depth 1 https://github.com/Fosowl/agenticSeek.git
cd agenticSeek/llm_server/
```

Install server specific requirements:

```sh
pip3 install -r requirements.txt
```

Run the server script.

```sh
python3 app.py --provider ollama --port 3333
```

You have the choice between using `ollama` and `llamacpp` as a LLM service.


Now on your personal computer:

Change the `config.ini` file to set the `provider_name` to `server` and `provider_model` to `deepseek-r1:xxb`.
Set the `provider_server_address` to the ip address of the machine that will run the model.

```sh
[MAIN]
is_local = False
provider_name = server
provider_model = deepseek-r1:70b
provider_server_address = http://x.x.x.x:3333
```


Next step: [Start services and run AgenticSeek](#Start-services-and-Run)  

---

## Speech to Text

Warning: speech to text only work in CLI mode at the moment.

Please note that currently speech to text only work in english.

The speech-to-text functionality is disabled by default. To enable it, set the listen option to True in the config.ini file:

```
listen = True
```

When enabled, the speech-to-text feature listens for a trigger keyword, which is the agent&#039;s name, before it begins processing your input. You can customize the agent&#039;s name by updating the `agent_name` value in the *config.ini* file:

```
agent_name = Friday
```

For optimal recognition, we recommend using a common English name like &quot;John&quot; or &quot;Emma&quot; as the agent name

Once you see the transcript start to appear, say the agent&#039;s name aloud to wake it up (e.g., &quot;Friday&quot;).

Speak your query clearly.

End your request with a confirmation phrase to signal the system to proceed. Examples of confirmation phrases include:
```
&quot;do it&quot;, &quot;go ahead&quot;, &quot;execute&quot;, &quot;run&quot;, &quot;start&quot;, &quot;thanks&quot;, &quot;would ya&quot;, &quot;please&quot;, &quot;okay?&quot;, &quot;proceed&quot;, &quot;continue&quot;, &quot;go on&quot;, &quot;do that&quot;, &quot;go it&quot;, &quot;do you understand?&quot;
```

## Config

Example config:
```
[MAIN]
is_local = True
provider_name = ollama
provider_model = deepseek-r1:32b
provider_server_address = http://127.0.0.1:11434 # Example for Ollama; use http://127.0.0.1:1234 for LM-Studio
agent_name = Friday
recover_last_session = False
save_session = False
speak = False
listen = False

jarvis_personality = False
languages = en zh # List of languages for TTS and potentially routing.
[BROWSER]
headless_browser = False
stealth_mode = False
```

**Explanation of `config.ini` Settings**:

*   **`[MAIN]` Section:**
    *   `is_local`: `True` if using a local LLM provider (Ollama, LM-Studio, local OpenAI-compatible server) or the self-hosted server option. `False` if using a cloud-based API (OpenAI, Google, etc.).
    *   `provider_name`: Specifies the LLM provider.
        *   Local options: `ollama`, `lm-studio`, `openai` (for local OpenAI-compatible s

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[roboflow/supervision]]></title>
            <link>https://github.com/roboflow/supervision</link>
            <guid>https://github.com/roboflow/supervision</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:43 GMT</pubDate>
            <description><![CDATA[We write your reusable computer vision tools. üíú]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/roboflow/supervision">roboflow/supervision</a></h1>
            <p>We write your reusable computer vision tools. üíú</p>
            <p>Language: Python</p>
            <p>Stars: 36,513</p>
            <p>Forks: 3,092</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
    &lt;a align=&quot;center&quot; href=&quot;&quot; target=&quot;https://supervision.roboflow.com&quot;&gt;
      &lt;img
        width=&quot;100%&quot;
        src=&quot;https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529&quot;
      &gt;
    &lt;/a&gt;
  &lt;/p&gt;

&lt;br&gt;

[notebooks](https://github.com/roboflow/notebooks) | [inference](https://github.com/roboflow/inference) | [autodistill](https://github.com/autodistill/autodistill) | [maestro](https://github.com/roboflow/multimodal-maestro)

&lt;br&gt;

[![version](https://badge.fury.io/py/supervision.svg)](https://badge.fury.io/py/supervision)
[![downloads](https://img.shields.io/pypi/dm/supervision)](https://pypistats.org/packages/supervision)
[![snyk](https://snyk.io/advisor/python/supervision/badge.svg)](https://snyk.io/advisor/python/supervision)
[![license](https://img.shields.io/pypi/l/supervision)](https://github.com/roboflow/supervision/blob/main/LICENSE.md)
[![python-version](https://img.shields.io/pypi/pyversions/supervision)](https://badge.fury.io/py/supervision)
[![colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/roboflow/supervision/blob/main/demo.ipynb)
[![gradio](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Spaces-blue)](https://huggingface.co/spaces/Roboflow/Annotators)
[![discord](https://img.shields.io/discord/1159501506232451173?logo=discord&amp;label=discord&amp;labelColor=fff&amp;color=5865f2&amp;link=https%3A%2F%2Fdiscord.gg%2FGbfgXGJ8Bk)](https://discord.gg/GbfgXGJ8Bk)
[![built-with-material-for-mkdocs](https://img.shields.io/badge/Material_for_MkDocs-526CFE?logo=MaterialForMkDocs&amp;logoColor=white)](https://squidfunk.github.io/mkdocs-material/)

  &lt;div align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/124&quot;  target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/124&quot; alt=&quot;roboflow%2Fsupervision | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
  &lt;/div&gt;

&lt;/div&gt;

## üëã hello

**We write your reusable computer vision tools.** Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ü§ù

## üíª install

Pip install the supervision package in a
[**Python&gt;=3.9**](https://www.python.org/) environment.

```bash
pip install supervision
```

Read more about conda, mamba, and installing from source in our [guide](https://roboflow.github.io/supervision/).

## üî• quickstart

### models

Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created [connectors](https://supervision.roboflow.com/latest/detection/core/#detections) for the most popular libraries like Ultralytics, Transformers, or MMDetection.

```python
import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO(&quot;yolov8s.pt&quot;)
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5
```

&lt;details&gt;
&lt;summary&gt;üëâ more model connectors&lt;/summary&gt;

- inference

  Running with [Inference](https://github.com/roboflow/inference) requires a [Roboflow API KEY](https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key).

  ```python
  import cv2
  import supervision as sv
  from inference import get_model

  image = cv2.imread(...)
  model = get_model(model_id=&quot;yolov8s-640&quot;, api_key=&lt;ROBOFLOW API KEY&gt;)
  result = model.infer(image)[0]
  detections = sv.Detections.from_inference(result)

  len(detections)
  # 5
  ```

&lt;/details&gt;

### annotators

Supervision offers a wide range of highly customizable [annotators](https://supervision.roboflow.com/latest/detection/annotators/), allowing you to compose the perfect visualization for your use case.

```python
import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

box_annotator = sv.BoxAnnotator()
annotated_frame = box_annotator.annotate(
  scene=image.copy(),
  detections=detections)
```

https://github.com/roboflow/supervision/assets/26109316/691e219c-0565-4403-9218-ab5644f39bce

### datasets

Supervision provides a set of [utils](https://supervision.roboflow.com/latest/datasets/core/) that allow you to load, split, merge, and save datasets in one of the supported formats.

```python
import supervision as sv
from roboflow import Roboflow

project = Roboflow().workspace(&lt;WORKSPACE_ID&gt;).project(&lt;PROJECT_ID&gt;)
dataset = project.version(&lt;PROJECT_VERSION&gt;).download(&quot;coco&quot;)

ds = sv.DetectionDataset.from_coco(
    images_directory_path=f&quot;{dataset.location}/train&quot;,
    annotations_path=f&quot;{dataset.location}/train/_annotations.coco.json&quot;,
)

path, image, annotation = ds[0]
    # loads image on demand

for path, image, annotation in ds:
    # loads image on demand
```

&lt;details close&gt;
&lt;summary&gt;üëâ more dataset utils&lt;/summary&gt;

- load

  ```python
  dataset = sv.DetectionDataset.from_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  )

  dataset = sv.DetectionDataset.from_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )

  dataset = sv.DetectionDataset.from_coco(
      images_directory_path=...,
      annotations_path=...
  )
  ```

- split

  ```python
  train_dataset, test_dataset = dataset.split(split_ratio=0.7)
  test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

  len(train_dataset), len(test_dataset), len(valid_dataset)
  # (700, 150, 150)
  ```

- merge

  ```python
  ds_1 = sv.DetectionDataset(...)
  len(ds_1)
  # 100
  ds_1.classes
  # [&#039;dog&#039;, &#039;person&#039;]

  ds_2 = sv.DetectionDataset(...)
  len(ds_2)
  # 200
  ds_2.classes
  # [&#039;cat&#039;]

  ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
  len(ds_merged)
  # 300
  ds_merged.classes
  # [&#039;cat&#039;, &#039;dog&#039;, &#039;person&#039;]
  ```

- save

  ```python
  dataset.as_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  )

  dataset.as_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )

  dataset.as_coco(
      images_directory_path=...,
      annotations_path=...
  )
  ```

- convert

  ```python
  sv.DetectionDataset.from_yolo(
      images_directory_path=...,
      annotations_directory_path=...,
      data_yaml_path=...
  ).as_pascal_voc(
      images_directory_path=...,
      annotations_directory_path=...
  )
  ```

&lt;/details&gt;

## üé¨ tutorials

Want to learn how to use Supervision? Explore our [how-to guides](https://supervision.roboflow.com/develop/how_to/detect_and_annotate/), [end-to-end examples](https://github.com/roboflow/supervision/tree/develop/examples), [cheatsheet](https://roboflow.github.io/cheatsheet-supervision/), and [cookbooks](https://supervision.roboflow.com/develop/cookbooks/)!

&lt;br/&gt;

&lt;p align=&quot;left&quot;&gt;
&lt;a href=&quot;https://youtu.be/hAWpsIuem10&quot; title=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/a742823d-c158-407d-b30f-063a5d11b4e1&quot; alt=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://youtu.be/hAWpsIuem10&quot; title=&quot;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&quot;&gt;&lt;strong&gt;Dwell Time Analysis with Computer Vision | Real-Time Stream Processing&lt;/strong&gt;&lt;/a&gt;
&lt;div&gt;&lt;strong&gt;Created: 5 Apr 2024&lt;/strong&gt;&lt;/div&gt;
&lt;br/&gt;Learn how to use computer vision to analyze wait times and optimize processes. This tutorial covers object detection, tracking, and calculating time spent in designated zones. Use these techniques to improve customer experience in retail, traffic management, or other scenarios.&lt;/p&gt;

&lt;br/&gt;

&lt;p align=&quot;left&quot;&gt;
&lt;a href=&quot;https://youtu.be/uWP6UjDeZvY&quot; title=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot;&gt;&lt;img src=&quot;https://github.com/SkalskiP/SkalskiP/assets/26109316/61a444c8-b135-48ce-b979-2a5ab47c5a91&quot; alt=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot; width=&quot;300px&quot; align=&quot;left&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://youtu.be/uWP6UjDeZvY&quot; title=&quot;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&quot;&gt;&lt;strong&gt;Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source&lt;/strong&gt;&lt;/a&gt;
&lt;div&gt;&lt;strong&gt;Created: 11 Jan 2024&lt;/strong&gt;&lt;/div&gt;
&lt;br/&gt;Learn how to track and estimate the speed of vehicles using YOLO, ByteTrack, and Roboflow Inference. This comprehensive tutorial covers object detection, multi-object tracking, filtering detections, perspective transformation, speed estimation, visualization improvements, and more.&lt;/p&gt;

## üíú built with supervision

Did you build something cool using supervision? [Let us know!](https://github.com/roboflow/supervision/discussions/categories/built-with-supervision)

https://user-images.githubusercontent.com/26109316/207858600-ee862b22-0353-440b-ad85-caa0c4777904.mp4

https://github.com/roboflow/supervision/assets/26109316/c9436828-9fbf-4c25-ae8c-60e9c81b3900

https://github.com/roboflow/supervision/assets/26109316/3ac6982f-4943-4108-9b7f-51787ef1a69f

## üìö documentation

Visit our [documentation](https://roboflow.github.io/supervision) page to learn how supervision can help you build computer vision applications faster and more reliably.

## üèÜ contribution

We love your input! Please see our [contributing guide](https://github.com/roboflow/supervision/blob/main/CONTRIBUTING.md) to get started. Thank you üôè to all our contributors!

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/roboflow/supervision/graphs/contributors&quot;&gt;
      &lt;img src=&quot;https://contrib.rocks/image?repo=roboflow/supervision&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;br&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;div align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://youtube.com/roboflow&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/youtube.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949634652&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/roboflow-app.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949746649&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://www.linkedin.com/company/roboflow-ai/&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/linkedin.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633691&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://docs.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/knowledge.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949634511&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://discuss.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/forum.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633584&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;img src=&quot;https://raw.githubusercontent.com/ultralytics/assets/main/social/logo-transparent.png&quot; width=&quot;3%&quot;/&gt;
      &lt;a href=&quot;https://blog.roboflow.com&quot;&gt;
          &lt;img
            src=&quot;https://media.roboflow.com/notebooks/template/icons/purple/blog.png?ik-sdk-version=javascript-1.4.3&amp;updatedAt=1672949633605&quot;
            width=&quot;3%&quot;
          /&gt;
      &lt;/a&gt;
      &lt;/a&gt;
  &lt;/div&gt;
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[databricks-solutions/ai-dev-kit]]></title>
            <link>https://github.com/databricks-solutions/ai-dev-kit</link>
            <guid>https://github.com/databricks-solutions/ai-dev-kit</guid>
            <pubDate>Sun, 22 Feb 2026 00:05:42 GMT</pubDate>
            <description><![CDATA[Databricks Toolkit for Coding Agents provided by Field Engineering]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/databricks-solutions/ai-dev-kit">databricks-solutions/ai-dev-kit</a></h1>
            <p>Databricks Toolkit for Coding Agents provided by Field Engineering</p>
            <p>Language: Python</p>
            <p>Stars: 610</p>
            <p>Forks: 104</p>
            <p>Stars today: 108 stars today</p>
            <h2>README</h2><pre># Databricks AI Dev Kit

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Databricks-Certified%20Gold%20Project-FFD700?style=for-the-badge&amp;logo=databricks&amp;logoColor=black&quot; alt=&quot;Databricks Certified Gold Project&quot;&gt;
&lt;/p&gt;

---

## Overview

AI-Driven Development (vibe coding) on Databricks just got a whole lot better. The **AI Dev Kit** gives your AI coding assistant (Claude Code, Cursor, Windsurf, etc.) the trusted sources it needs to build faster and smarter on Databricks.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;databricks-tools-core/docs/architecture.svg&quot; alt=&quot;Architecture&quot; width=&quot;700&quot;&gt;
&lt;/p&gt;

---

## What Can I Build?

- **Spark Declarative Pipelines** (streaming tables, CDC, SCD Type 2, Auto Loader)
- **Databricks Jobs** (scheduled workflows, multi-task DAGs)
- **AI/BI Dashboards** (visualizations, KPIs, analytics)
- **Unity Catalog** (tables, volumes, governance)
- **Genie Spaces** (natural language data exploration)
- **Knowledge Assistants** (RAG-based document Q&amp;A)
- **MLflow Experiments** (evaluation, scoring, traces)
- **Model Serving** (deploy ML models and AI agents to endpoints)
- **Databricks Apps** (full-stack web applications)
- ...and more

---

## Choose Your Own Adventure

| Adventure                        | Best For | Start Here |
|----------------------------------|----------|------------|
| :star: [**Install AI Dev Kit**](#install-in-existing-project) | **Start here!** Follow quick install instructions to add to your existing project folder | [Quick Start (install)](#install-in-existing-project)
| [**Visual Builder App**](#visual-builder-app) | Web-based UI for Databricks development | `databricks-builder-app/` |
| [**Core Library**](#core-library) | Building custom integrations (LangChain, OpenAI, etc.) | `pip install` |
| [**Skills Only**](databricks-skills/) | Provide Databricks patterns and best practices (without MCP functions) | Install skills |
| [**MCP Tools Only**](databricks-mcp-server/) | Just executable actions (no guidance) | Register MCP server |
---

## Quick Start

### Prerequisites

- [uv](https://github.com/astral-sh/uv) - Python package manager
- [Databricks CLI](https://docs.databricks.com/aws/en/dev-tools/cli/) - Command line interface for Databricks
- AI coding environment
  - [Claude Code](https://claude.ai/code)
  - [Cursor](https://cursor.com)


### Install in existing project
By default this will install at a project level rather than a user level. This is often a good fit, but requires you to run your client from the exact directory that was used for the install.  
_Note: Project configuration files can be re-used in other projects. You find these configs under .claude or .cursor_

#### Mac / Linux

**Basic installation** (uses DEFAULT profile, project scope)

```bash
bash &lt;(curl -sL https://raw.githubusercontent.com/databricks-solutions/ai-dev-kit/main/install.sh)
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Advanced Options&lt;/strong&gt; (click to expand)&lt;/summary&gt;

**Global installation with force reinstall**

```bash
bash &lt;(curl -sL https://raw.githubusercontent.com/databricks-solutions/ai-dev-kit/main/install.sh) --global --force
```

**Specify profile and force reinstall**

```bash
bash &lt;(curl -sL https://raw.githubusercontent.com/databricks-solutions/ai-dev-kit/main/install.sh) --profile DEFAULT --force
```

**Install for specific tools only**

```bash
bash &lt;(curl -sL https://raw.githubusercontent.com/databricks-solutions/ai-dev-kit/main/install.sh) --tools cursor
```

&lt;/details&gt;

**Next steps:** Respond to interactive prompts and follow the on-screen instructions.
- Note: Cursor and Copilot require updating settings manually after install.

#### Windows (PowerShell)

**Basic installation** (uses DEFAULT profile, project scope)

```powershell
irm https://raw.githubusercontent.com/databricks-solutions/ai-dev-kit/main/install.ps1 | iex
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Advanced Options&lt;/strong&gt; (click to expand)&lt;/summary&gt;

**Download script first**

```powershell
irm https://raw.githubusercontent.com/databricks-solutions/ai-dev-kit/main/install.ps1 -OutFile install.ps1
```

**Global installation with force reinstall**

```powershell
.\install.ps1 -Global -Force
```

**Specify profile and force reinstall**

```powershell
.\install.ps1 -Profile DEFAULT -Force
```

**Install for specific tools only**

```powershell
.\install.ps1 -Tools cursor
```

&lt;/details&gt;

**Next steps:** Respond to interactive prompts and follow the on-screen instructions.
- Note: Cursor and Copilot require updating settings manually after install.


### Visual Builder App

Full-stack web application with chat UI for Databricks development:

```bash
cd ai-dev-kit/databricks-builder-app
./scripts/setup.sh
# Follow instructions to start the app
```


### Core Library

Use `databricks-tools-core` directly in your Python projects:

```python
from databricks_tools_core.sql import execute_sql

results = execute_sql(&quot;SELECT * FROM my_catalog.schema.table LIMIT 10&quot;)
```

Works with LangChain, OpenAI Agents SDK, or any Python framework. See [databricks-tools-core/](databricks-tools-core/) for details.

---

## What&#039;s Included

| Component | Description |
|-----------|-------------|
| [`databricks-tools-core/`](databricks-tools-core/) | Python library with high-level Databricks functions |
| [`databricks-mcp-server/`](databricks-mcp-server/) | MCP server exposing 50+ tools for AI assistants |
| [`databricks-skills/`](databricks-skills/) | 19 markdown skills teaching Databricks patterns |
| [`databricks-builder-app/`](databricks-builder-app/) | Full-stack web app with Claude Code integration |

---

## Star History

&lt;a href=&quot;https://star-history.com/#databricks-solutions/ai-dev-kit&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=databricks-solutions/ai-dev-kit&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=databricks-solutions/ai-dev-kit&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=databricks-solutions/ai-dev-kit&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

---

## License

(c) 2026 Databricks, Inc. All rights reserved.

The source in this project is provided subject to the [Databricks License](https://databricks.com/db-license-source). See [LICENSE.md](LICENSE.md) for details.

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Third-Party Licenses&lt;/strong&gt;&lt;/summary&gt;

| Package | Version | License | Project URL |
|---------|---------|---------|-------------|
| [fastmcp](https://github.com/jlowin/fastmcp) | ‚â•0.1.0 | MIT | https://github.com/jlowin/fastmcp |
| [mcp](https://github.com/modelcontextprotocol/python-sdk) | ‚â•1.0.0 | MIT | https://github.com/modelcontextprotocol/python-sdk |
| [sqlglot](https://github.com/tobymao/sqlglot) | ‚â•20.0.0 | MIT | https://github.com/tobymao/sqlglot |
| [sqlfluff](https://github.com/sqlfluff/sqlfluff) | ‚â•3.0.0 | MIT | https://github.com/sqlfluff/sqlfluff |
| [litellm](https://github.com/BerriAI/litellm) | ‚â•1.0.0 | MIT | https://github.com/BerriAI/litellm |
| [pymupdf](https://github.com/pymupdf/PyMuPDF) | ‚â•1.24.0 | AGPL-3.0 | https://github.com/pymupdf/PyMuPDF |
| [claude-agent-sdk](https://github.com/anthropics/claude-code) | ‚â•0.1.19 | MIT | https://github.com/anthropics/claude-code |
| [fastapi](https://github.com/fastapi/fastapi) | ‚â•0.115.8 | MIT | https://github.com/fastapi/fastapi |
| [uvicorn](https://github.com/encode/uvicorn) | ‚â•0.34.0 | BSD-3-Clause | https://github.com/encode/uvicorn |
| [httpx](https://github.com/encode/httpx) | ‚â•0.28.0 | BSD-3-Clause | https://github.com/encode/httpx |
| [sqlalchemy](https://github.com/sqlalchemy/sqlalchemy) | ‚â•2.0.41 | MIT | https://github.com/sqlalchemy/sqlalchemy |
| [alembic](https://github.com/sqlalchemy/alembic) | ‚â•1.16.1 | MIT | https://github.com/sqlalchemy/alembic |
| [asyncpg](https://github.com/MagicStack/asyncpg) | ‚â•0.30.0 | Apache-2.0 | https://github.com/MagicStack/asyncpg |
| [greenlet](https://github.com/python-greenlet/greenlet) | ‚â•3.0.0 | MIT | https://github.com/python-greenlet/greenlet |
| [psycopg2-binary](https://github.com/psycopg/psycopg2) | ‚â•2.9.11 | LGPL-3.0 | https://github.com/psycopg/psycopg2 |

&lt;/details&gt;

---

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Acknowledgments&lt;/strong&gt;&lt;/summary&gt;

MCP Databricks Command Execution API from [databricks-exec-code](https://github.com/databricks-solutions/databricks-exec-code-mcp) by Natyra Bajraktari and Henryk Borzymowski.

&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>