<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Sun, 04 Jan 2026 00:05:54 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[pathwaycom/pathway]]></title>
            <link>https://github.com/pathwaycom/pathway</link>
            <guid>https://github.com/pathwaycom/pathway</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:54 GMT</pubDate>
            <description><![CDATA[Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pathwaycom/pathway">pathwaycom/pathway</a></h1>
            <p>Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.</p>
            <p>Language: Python</p>
            <p>Stars: 55,933</p>
            <p>Forks: 1,527</p>
            <p>Stars today: 1,219 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pathway.com/&quot;&gt;
    &lt;picture&gt;
      &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://pathway.com/logo-dark.svg&quot;&gt;
      &lt;img src=&quot;https://pathway.com/logo-light.svg&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
  &lt;br /&gt;&lt;br /&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/10388&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/10388&quot; alt=&quot;pathwaycom%2Fpathway | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
  &lt;br /&gt;&lt;br /&gt;
&lt;/div&gt;
&lt;p align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml&quot;&gt;
        &lt;img src=&quot;https://github.com/pathwaycom/pathway/actions/workflows/ubuntu_test.yml/badge.svg&quot; alt=&quot;ubuntu&quot;/&gt;
        &lt;br&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/actions/workflows/release.yml&quot;&gt;
        &lt;img src=&quot;https://github.com/pathwaycom/pathway/actions/workflows/release.yml/badge.svg&quot; alt=&quot;Last release&quot;/&gt;&lt;/a&gt;
        &lt;a href=&quot;https://badge.fury.io/py/pathway&quot;&gt;&lt;img src=&quot;https://badge.fury.io/py/pathway.svg&quot; alt=&quot;PyPI version&quot; height=&quot;18&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://badge.fury.io/py/pathway&quot;&gt;&lt;img src=&quot;https://static.pepy.tech/badge/pathway&quot; alt=&quot;PyPI downloads&quot; height=&quot;18&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://github.com/pathwaycom/pathway/blob/main/LICENSE.txt&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/license-BSL-green&quot; alt=&quot;License: BSL&quot;/&gt;&lt;/a&gt;
      &lt;br&gt;
        &lt;a href=&quot;https://discord.gg/pathway&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/discord/1042405378304004156?logo=discord&quot;
            alt=&quot;chat on Discord&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://twitter.com/intent/follow?screen_name=pathway_com&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/pathwaycom&quot;
            alt=&quot;follow on Twitter&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://linkedin.com/company/pathway&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/pathway-0077B5?style=social&amp;logo=linkedin&quot; alt=&quot;follow on LinkedIn&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;https://github.com/dylanhogg/awesome-python/blob/main/README.md&quot;&gt;
      &lt;img src=&quot;https://awesome.re/badge.svg&quot; alt=&quot;Awesome Python&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;https://gurubase.io/g/pathway&quot;&gt;
      &lt;img src=&quot;https://img.shields.io/badge/Gurubase-Ask%20Pathway%20Guru-006BFF&quot; alt=&quot;Pathway Guru&quot;&gt;&lt;/a&gt;
    &lt;br&gt;
    &lt;a href=&quot;#getting-started&quot;&gt;Getting Started&lt;/a&gt; |
    &lt;a href=&quot;#deployment&quot;&gt;Deployment&lt;/a&gt; |
    &lt;a href=&quot;#resources&quot;&gt;Documentation and Support&lt;/a&gt; |
    &lt;a href=&quot;https://pathway.com/blog/&quot;&gt;Blog&lt;/a&gt; |
    &lt;a href=&quot;#license&quot;&gt;License&lt;/a&gt;

  
&lt;/p&gt;

# Pathway&lt;a id=&quot;pathway&quot;&gt; Live Data Framework&lt;/a&gt;

[Pathway](https://pathway.com) is a Python ETL framework for stream processing, real-time analytics, LLM pipelines, and RAG.

Pathway comes with an **easy-to-use Python API**, allowing you to seamlessly integrate your favorite Python ML libraries.
Pathway code is versatile and robust: **you can use it in both development and production environments, handling both batch and streaming data effectively**.
The same code can be used for local development, CI/CD tests, running batch jobs, handling stream replays, and processing data streams.

Pathway is powered by a **scalable Rust engine** based on Differential Dataflow and performs incremental computation.
Your Pathway code, despite being written in Python, is run by the Rust engine, enabling multithreading, multiprocessing, and distributed computations.
All the pipeline is kept in memory and can be easily deployed with **Docker and Kubernetes**.

You can install Pathway with pip:
```
pip install -U pathway
```

For any questions, you will find the community and team behind the project [on Discord](https://discord.com/invite/pathway).

## Use-cases and templates

Ready to see what Pathway can do?

[Try one of our easy-to-run examples](https://pathway.com/developers/templates)!

Available in both notebook and docker formats, these ready-to-launch examples can be launched in just a few clicks. Pick one and start your hands-on experience with Pathway today!

### Event processing and real-time analytics pipelines
With its unified engine for batch and streaming and its full Python compatibility, Pathway makes data processing as easy as possible. It&#039;s the ideal solution for a wide range of data processing pipelines, including:

- [Showcase: Real-time ETL.](https://pathway.com/developers/templates/kafka-etl)
- [Showcase: Event-driven pipelines with alerting.](https://pathway.com/developers/templates/realtime-log-monitoring)
- [Showcase: Realtime analytics.](https://pathway.com/developers/templates/linear_regression_with_kafka)
- [Docs: Switch from batch to streaming.](https://pathway.com/developers/user-guide/connecting-to-data/switch-from-batch-to-streaming)



### AI Pipelines

Pathway provides dedicated LLM tooling to build live LLM and RAG pipelines. Wrappers for most common LLM services and utilities are included, making working with LLMs and RAGs pipelines incredibly easy. Check out our [LLM xpack documentation](https://pathway.com/developers/user-guide/llm-xpack/overview).

Don&#039;t hesitate to try one of our runnable examples featuring LLM tooling.
You can find such examples [here](https://pathway.com/developers/user-guide/llm-xpack/llm-examples).

  - [Template: Unstructured data to SQL on-the-fly.](https://pathway.com/developers/templates/unstructured-to-structured)
  - [Template: Private RAG with Ollama and Mistral AI](https://pathway.com/developers/templates/private-rag-ollama-mistral)
  - [Template: Adaptive RAG](https://pathway.com/developers/templates/adaptive-rag)
  - [Template: Multimodal RAG with gpt-4o](https://pathway.com/developers/templates/multimodal-rag)

## Features

- **A wide range of connectors**: Pathway comes with connectors that connect to external data sources such as Kafka, GDrive, PostgreSQL, or SharePoint. Its Airbyte connector allows you to connect to more than 300 different data sources. If the connector you want is not available, you can build your own custom connector using Pathway Python connector.
- **Stateless and stateful transformations**: Pathway supports stateful transformations such as joins, windowing, and sorting. It provides many transformations directly implemented in Rust. In addition to the provided transformation, you can use any Python function. You can implement your own or you can use any Python library to process your data.
- **Persistence**: Pathway provides persistence to save the state of the computation. This allows you to restart your pipeline after an update or a crash. Your pipelines are in good hands with Pathway!
- **Consistency**: Pathway handles the time for you, making sure all your computations are consistent. In particular, Pathway manages late and out-of-order points by updating its results whenever new (or late, in this case) data points come into the system. The free version of Pathway gives the &quot;at least once&quot; consistency while the enterprise version provides the &quot;exactly once&quot; consistency.
- **Scalable Rust engine**: with Pathway Rust engine, you are free from the usual limits imposed by Python. You can easily do multithreading, multiprocessing, and distributed computations.
- **LLM helpers**: Pathway provides an LLM extension with all the utilities to integrate LLMs with your data pipelines (LLM wrappers, parsers, embedders, splitters), including an in-memory real-time Vector Index, and integrations with LLamaIndex and LangChain. You can quickly build and deploy RAG applications with your live documents.


## Getting started&lt;a id=&quot;getting-started&quot;&gt;&lt;/a&gt;

### Installation&lt;a id=&quot;installation&quot;&gt;&lt;/a&gt;

Pathway requires Python 3.10 or above.

You can install the current release of Pathway using `pip`:

```
$ pip install -U pathway
```

‚ö†Ô∏è Pathway is available on MacOS and Linux. Users of other systems should run Pathway on a Virtual Machine.


### Example: computing the sum of positive values in real time.&lt;a id=&quot;example&quot;&gt;&lt;/a&gt;

```python
import pathway as pw

# Define the schema of your data (Optional)
class InputSchema(pw.Schema):
  value: int

# Connect to your data using connectors
input_table = pw.io.csv.read(
  &quot;./input/&quot;,
  schema=InputSchema
)

#Define your operations on the data
filtered_table = input_table.filter(input_table.value&gt;=0)
result_table = filtered_table.reduce(
  sum_value = pw.reducers.sum(filtered_table.value)
)

# Load your results to external systems
pw.io.jsonlines.write(result_table, &quot;output.jsonl&quot;)

# Run the computation
pw.run()
```

Run Pathway [in Google Colab](https://colab.research.google.com/drive/1aBIJ2HCng-YEUOMrr0qtj0NeZMEyRz55?usp=sharing).

You can find more examples [here](https://github.com/pathwaycom/pathway/tree/main/examples).


## Deployment&lt;a id=&quot;deployment&quot;&gt;&lt;/a&gt;

### Locally&lt;a id=&quot;running-pathway-locally&quot;&gt;&lt;/a&gt;

To use Pathway, you only need to import it:

```python
import pathway as pw
```

Now, you can easily create your processing pipeline, and let Pathway handle the updates. Once your pipeline is created, you can launch the computation on streaming data with a one-line command:

```python
pw.run()
```

You can then run your Pathway project (say, `main.py`) just like a normal Python script: `$ python main.py`.
Pathway comes with a monitoring dashboard that allows you to keep track of the number of messages sent by each connector and the latency of the system. The dashboard also includes log messages. 

&lt;img src=&quot;https://d14l3brkh44201.cloudfront.net/pathway-dashboard.png&quot; width=&quot;1326&quot; alt=&quot;Pathway dashboard&quot;/&gt;

Alternatively, you can use the pathway&#039;ish version:

```
$ pathway spawn python main.py
```

Pathway natively supports multithreading.
To launch your application with 3 threads, you can do as follows:
```
$ pathway spawn --threads 3 python main.py
```

To jumpstart a Pathway project, you can use our [cookiecutter template](https://github.com/pathwaycom/cookiecutter-pathway).


### Docker&lt;a id=&quot;docker&quot;&gt;&lt;/a&gt;

You can easily run Pathway using docker.

#### Pathway image

You can use the [Pathway docker image](https://hub.docker.com/r/pathwaycom/pathway), using a Dockerfile:

```dockerfile
FROM pathwaycom/pathway:latest

WORKDIR /app

COPY requirements.txt ./
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD [ &quot;python&quot;, &quot;./your-script.py&quot; ]
```

You can then build and run the Docker image:

```console
docker build -t my-pathway-app .
docker run -it --rm --name my-pathway-app my-pathway-app
```

#### Run a single Python script

When dealing with single-file projects, creating a full-fledged `Dockerfile`
might seem unnecessary. In such scenarios, you can execute a
Python script directly using the Pathway Docker image. For example:

```console
docker run -it --rm --name my-pathway-app -v &quot;$PWD&quot;:/app pathwaycom/pathway:latest python my-pathway-app.py
```

#### Python docker image

You can also use a standard Python image and install Pathway using pip with a Dockerfile:

```dockerfile
FROM --platform=linux/x86_64 python:3.10

RUN pip install -U pathway
COPY ./pathway-script.py pathway-script.py

CMD [&quot;python&quot;, &quot;-u&quot;, &quot;pathway-script.py&quot;]
```

### Kubernetes and cloud&lt;a id=&quot;k8s&quot;&gt;&lt;/a&gt;

Docker containers are ideally suited for deployment on the cloud with Kubernetes.
If you want to scale your Pathway application, you may be interested in our Pathway for Enterprise.
Pathway for Enterprise is specially tailored towards end-to-end data processing and real time intelligent analytics.
It scales using distributed computing on the cloud and supports distributed Kubernetes deployment, with external persistence setup.

You can easily deploy Pathway using services like Render: see [how to deploy Pathway in a few clicks](https://pathway.com/developers/user-guide/deployment/render-deploy/).

If you are interested, don&#039;t hesitate to [contact us](mailto:contact@pathway.com) to learn more.

## Performance&lt;a id=&quot;performance&quot;&gt;&lt;/a&gt;

Pathway is made to outperform state-of-the-art technologies designed for streaming and batch data processing tasks, including: Flink, Spark, and Kafka Streaming. It also makes it possible to implement a lot of algorithms/UDF&#039;s in streaming mode which are not readily supported by other streaming frameworks (especially: temporal joins, iterative graph algorithms, machine learning routines).

If you are curious, here are [some benchmarks to play with](https://github.com/pathwaycom/pathway-benchmarks).

&lt;img src=&quot;https://github.com/pathwaycom/pathway-benchmarks/raw/main/images/bm-wordcount-lineplot.png&quot; width=&quot;1326&quot; alt=&quot;WordCount Graph&quot;/&gt;

## Documentation and Support&lt;a id=&quot;resources&quot;&gt;&lt;/a&gt;

The entire documentation of Pathway is available at [pathway.com/developers/](https://pathway.com/developers/user-guide/introduction/welcome), including the [API Docs](https://pathway.com/developers/api-docs/pathway).

If you have any question, don&#039;t hesitate to [open an issue on GitHub](https://github.com/pathwaycom/pathway/issues), join us on [Discord](https://discord.com/invite/pathway), or send us an email at [contact@pathway.com](mailto:contact@pathway.com).



## ü§ù Featured Collaborations &amp; Integrations

We build cutting-edge data processing pipelines and co-promote solutions that push the boundaries of what&#039;s possible with Python and streaming data.
Meet the people helping us shape the future of data engineering.

&lt;div align=&quot;center&quot;&gt;

| Project | Description |
| ------------ | ----------- |
| [Databento](https://databento.com/blog/option-greeks) | A simpler, faster way to get market data. |
| [LangChain](https://docs.langchain.com/oss/python/integrations/vectorstores/pathway) | LangChain is the platform for agent engineering. |
| [LlamaIndex](https://developers.llamaindex.ai/python/examples/retrievers/pathway_retriever/) | The developer-trusted framework for building context-aware AI agents. |
| [MinIO](https://www.min.io/) | MinIO is a high-performance, S3 compatible object store, open sourced under GNU AGPLv3 license. |
| [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) | PaddleOCR is an industry-leading, production-ready OCR and document AI engine, offering end-to-end solutions from text extraction to intelligent document understanding. |
| [Redpanda](https://www.redpanda.com/blog/replace-kafka-redpanda-data-analysis-streaming) | Build, operate, and govern streaming and AI applications without the complexity of Kafka. |
&lt;/div&gt;


## License&lt;a id=&quot;license&quot;&gt;&lt;/a&gt;

Pathway is distributed on a [BSL 1.1 License](https://github.com/pathwaycom/pathway/blob/main/LICENSE.txt) which allows for unlimited non-commercial use, as well as use of the Pathway package [for most commercial purposes](https://pathway.com/license/), free of charge. Code in this repository automatically converts to Open Source (Apache 2.0 License) after 4 years. Some [public repos](https://github.com/pathwaycom) which are complementary to this one (examples, libraries, connectors, etc.) are licensed as Open Source, under the MIT license.


## Contribution guidelines&lt;a id=&quot;contribution-guidelines&quot;&gt;&lt;/a&gt;

If you develop a library or connector which you would like to integrate with this repo, we suggest releasing it first as a separate repo on a MIT/Apache 2.0 license. 

For all concerns regarding core Pathway functionalities, Issues are encouraged. For further information, don&#039;t hesitate to engage with Pathway&#039;s [Discord community](https://discord.gg/pathway).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OpenBB-finance/OpenBB]]></title>
            <link>https://github.com/OpenBB-finance/OpenBB</link>
            <guid>https://github.com/OpenBB-finance/OpenBB</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:53 GMT</pubDate>
            <description><![CDATA[Financial data platform for analysts, quants and AI agents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBB-finance/OpenBB">OpenBB-finance/OpenBB</a></h1>
            <p>Financial data platform for analysts, quants and AI agents.</p>
            <p>Language: Python</p>
            <p>Stars: 56,424</p>
            <p>Forks: 5,492</p>
            <p>Stars today: 195 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/odp-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;Open Data Platform by OpenBB logo&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/odp-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;Open Data Platform by OpenBB logo&quot; width=&quot;600&quot;&gt;
&lt;br /&gt;
&lt;br /&gt;

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)
[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)
&lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt;
  &lt;img src=&quot;https://github.com/codespaces/badge.svg&quot; height=&quot;20&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;
[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&amp;label=PyPI%20Package)](https://pypi.org/project/openbb/)

Open Data Platform by OpenBB (ODP) is the open-source toolset that helps data engineers integrate proprietary, licensed, and public data sources into downstream applications like AI copilots and research dashboards.

ODP operates as the &quot;connect once, consume everywhere&quot; infrastructure layer that consolidates and exposes data to multiple surfaces at once: Python environments for quants, OpenBB Workspace and Excel for analysts, MCP servers for AI agents, and REST APIs for other applications.

&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/70b971ef-7a7e-486e-b5ae-1cc602f2162c.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Get started with: `pip install openbb`

```python
from openbb import obb
output = obb.equity.price.historical(&quot;AAPL&quot;)
df = output.to_dataframe()
```

Data integrations available can be found here: &lt;https://docs.openbb.co/python/reference&gt;

---

## OpenBB Workspace

While the Open Data Platform provides the open-source data integration foundation, **OpenBB Workspace** offers the enterprise UI for analysts to visualize datasets and leverage AI agents. The platform&#039;s &quot;connect once, consume everywhere&quot; architecture enables seamless integration between the two.

You can find OpenBB Workspace at &lt;https://pro.openbb.co&gt;.
&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Data integration:

- You can learn more about adding data to the OpenBB workspace from the [docs](https://docs.openbb.co/workspace) or [this open source repository](https://github.com/OpenBB-finance/backends-for-openbb).

AI Agents integration:

- You can learn more about adding AI agents to the OpenBB workspace from [this open source repository](https://github.com/OpenBB-finance/agents-for-openbb).

### Integrating Open Data Platform to the OpenBB Workspace

Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.

#### Run an ODP backend

- Install the packages.

```sh
pip install &quot;openbb[all]&quot;
```

- Start the API server over localhost.

```sh
openbb-api
```

This will launch a FastAPI server, via Uvicorn, at `127.0.0.1:6900`.

You can check that it works by going to &lt;http://127.0.0.1:6900&gt;.

#### Integrate the ODP Backend to OpenBB Workspace

Sign-in to the [OpenBB Workspace](https://pro.openbb.co/), and follow the following steps:

![CleanShot 2025-05-17 at 09 51 56@2x](https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069)

1. Go to the &quot;Apps&quot; tab
2. Click on &quot;Connect backend&quot;
3. Fill in the form with:
   Name: Open Data Platform
   URL: &lt;http://127.0.0.1:6900&gt;
4. Click on &quot;Test&quot;. You should get a &quot;Test successful&quot; with the number of apps found.
5. Click on &quot;Add&quot;.

That&#039;s it.

---

&lt;!-- TABLE OF CONTENTS --&gt;
&lt;details closed=&quot;closed&quot;&gt;
  &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

## 1. Installation

The ODP Python Package can be installed from [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`

or by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process, in the [OpenBB Documentation](https://docs.openbb.co/python/installation).

### ODP CLI installation

The ODP CLI is a command-line interface that allows you to access the ODP directly from your command line.

It can be installed by running `pip install openbb-cli`

or by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).

## 2. Contributing

There are three main ways of contributing to this project. (Hopefully you have starred the project by now ‚≠êÔ∏è)

### Become a Contributor

- More information on our [Developer Documentation](https://docs.openbb.co/python/developer).

### Create a GitHub ticket

Before creating a ticket make sure the one you are creating doesn&#039;t exist already [among the existing issues](https://github.com/OpenBB-finance/OpenBB/issues)

- [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=%5BBug%5D)
- [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=enhancement&amp;template=enhancement.md&amp;title=%5BIMPROVE%5D)
- [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=new+feature&amp;template=feature_request.md&amp;title=%5BFR%5D)

### Provide feedback

We are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.

## 3. License

Distributed under the AGPLv3 License. See
[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.

## 4. Disclaimer

Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment
amount, and may not be suitable for all investors.

Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.

The data contained in the Open Data Platform is not necessarily accurate.

OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.

All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.

Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.

## 5. Contacts

If you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`

If you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`

Any of our social media platforms: [openbb.co/links](https://openbb.co/links)

## 6. Star History

This is a proxy of our growth and that we are just getting started.

But for more metrics important to us check [openbb.co/open](https://openbb.co/open).

[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)

## 7. Contributors

OpenBB wouldn&#039;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.

&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt;
   &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot;/&gt;
&lt;/a&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge
[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge
[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members
[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge
[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers
[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&amp;color=blue
[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues
[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=yellow
[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen
[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=success
[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed
[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge
[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;logo=linkedin&amp;colorB=555
[linkedin-url]: https://linkedin.com/in/DidierRLopes
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[beancount/beancount]]></title>
            <link>https://github.com/beancount/beancount</link>
            <guid>https://github.com/beancount/beancount</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:52 GMT</pubDate>
            <description><![CDATA[Beancount: Double-Entry Accounting from Text Files.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/beancount/beancount">beancount/beancount</a></h1>
            <p>Beancount: Double-Entry Accounting from Text Files.</p>
            <p>Language: Python</p>
            <p>Stars: 4,954</p>
            <p>Forks: 385</p>
            <p>Stars today: 111 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[MustardChef/WSABuilds]]></title>
            <link>https://github.com/MustardChef/WSABuilds</link>
            <guid>https://github.com/MustardChef/WSABuilds</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:51 GMT</pubDate>
            <description><![CDATA[Run Windows Subsystem For Android on your Windows 10 and Windows 11 PC using prebuilt binaries with Google Play Store (MindTheGapps) and/or Magisk or KernelSU (root solutions) built in.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/MustardChef/WSABuilds">MustardChef/WSABuilds</a></h1>
            <p>Run Windows Subsystem For Android on your Windows 10 and Windows 11 PC using prebuilt binaries with Google Play Store (MindTheGapps) and/or Magisk or KernelSU (root solutions) built in.</p>
            <p>Language: Python</p>
            <p>Stars: 15,372</p>
            <p>Forks: 2,132</p>
            <p>Stars today: 14 stars today</p>
            <h2>README</h2><pre>&gt; [!CAUTION]
&gt;
&gt; # It seems that the last few Windows Updates released on many/all of the update channels (issue started from July) are breaking WSA installations for many users! 
&gt;
&gt; - ## If you are affected by the issue, try these current workarounds:
&gt;   - ### RECOMMENDED FIX: https://github.com/MustardChef/WSABuilds/issues/593#issuecomment-3172749449
&gt;   - #### Switch/Use the builds which do not contain GApps. These are the builds that contain ``NoGApps`` in their .7z archive names. 
&gt;   - #### Really old builds of WSA (2211/2210) are known to be working.  
&gt;
&gt; ## Refer to https://github.com/MustardChef/WSABuilds/issues/593 for more information.

      
&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/MustardChef/WSABuilds#downloads&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/MustardChef/WSABuilds/total?label=Total%20Downloads&amp;amp;style=for-the-badge&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://forum.xda-developers.com/t/wsabuilds-latest-windows-subsystem-for-android-wsa-builds-for-   windows-10-and-11-with-magisk-and-google-play-store.4545087/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/XDA%20Developers-WSABuilds-EA7100?style=for-the-badge&amp;amp;logoColor=white&amp;amp;logo=XDA-Developers&quot;/&gt;&lt;/a&gt; &lt;a href=&quot;https://ko-fi.com/N4N0K08AC&quot;&gt;&lt;img alt=&quot;ko-fi&quot; src=&quot;https://ko-fi.com/img/githubbutton_sm.svg&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;picture&gt;&lt;img align=&quot;left&quot; height=&quot;20%&quot; src=&quot;https://github.com/MustardChef/WSABuilds/assets/68516357/35cd1d5d-e464-4eb8-a676-b451341f65ad&quot; width=&quot;20%&quot;/&gt;&lt;/picture&gt;
&lt;h1&gt;WSABuilds&lt;/h1&gt;
&lt;h3&gt;MagiskOnWSA (For Windows‚Ñ¢ 10 and 11)&lt;/h3&gt;
&lt;h5&gt;Windows Subsystem For Android‚Ñ¢ (WSA) with Google Play Services and Magisk and KernelSU&lt;/h5&gt;
&lt;br/&gt;
&lt;a href=&quot;https://discord.gg/2thee7zzHZ&quot;&gt;&lt;img align=&quot;right&quot; src=&quot;https://invidget.switchblade.xyz/2thee7zzHZ&quot; style=&quot;width: 400px;&quot;/&gt;&lt;/a&gt;
&lt;br/&gt; &lt;br/&gt; &lt;br/&gt; &lt;br/&gt;
&lt;br/&gt;&lt;a href=&quot;https://github.com/MustardChef/WSABuilds/blob/master/Documentation/Sponsors/PetroSky.md&quot;&gt;&lt;img align=&quot;right&quot; src=&quot;https://github.com/user-attachments/assets/5bf3e8f6-2b92-448c-b90f-4d3210900bab&quot; width=&quot;480&quot;/&gt;&lt;/a&gt;
&lt;br/&gt; &lt;br/&gt; &lt;br/&gt; &lt;br/&gt; &lt;br/&gt; &lt;br/&gt; &lt;br/&gt;
&lt;img align=&quot;left&quot; alt=&quot;downloads-folder&quot; height=&quot;54&quot; src=&quot;https://img.icons8.com/3d-fluency/94/downloads-folder.png&quot; width=&quot;54&quot;/&gt;&lt;h2&gt;Downloads&lt;/h2&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;details&gt;
&lt;summary&gt;&lt;a href=&quot;https://github.com/MustardChef/WSABuilds/blob/master/Documentation/WSABuilds/Information.md&quot;&gt;&lt;img height=&quot;35&quot; src=&quot;https://img.icons8.com/3d-fluency/94/ok.png&quot; style=&quot;float: left;&quot; width=&quot;35&quot;/&gt;&lt;h3&gt;&lt;a href=&quot;https://github.com/MustardChef/WSABuilds/blob/master/Documentation/WSABuilds/Information.md&quot;&gt; ¬† WSABuilds Project Status&lt;/a&gt;&lt;/h3&gt;&lt;/a&gt;&lt;/summary&gt;
&lt;center&gt;&lt;h3&gt;‚ö†Ô∏è‚ùóIMPORTANT: Read Before Downloading‚ùó‚ö†Ô∏è&lt;/h3&gt;&lt;/center&gt;
&lt;div align=&quot;left&quot;&gt;  
## WSABuilds Repo Info

#### Known Issues that may affect your WSA experiences:
- ***GApps Issues : https://github.com/LSPosed/MagiskOnWSALocal/issues/595***
- ***Folder Issue : Long folder name for the WSA Folder (auto generated by the MagiskOnWSALocal script) may cause WSA to not start. Rename the folder to ``WSA`` after extracting and before installing WSA.***
- ***Installed Magisk Modules disappear after install and subsequent reboot (WSA v2307):*** https://github.com/MustardChef/WSABuilds/issues/154
&lt;/div&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;WSA Version:&lt;/th&gt;
&lt;th&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/e/e6/Windows_11_logo.svg&quot; width=&quot;200&quot;/&gt;&lt;/th&gt;
&lt;th&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/0/05/Windows_10_Logo.svg&quot; width=&quot;200&quot;/&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;v2210.40000.7.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2211.40000.10.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2211.40000.11.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2301.40000.4.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2301.40000.7.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2302.40000.6.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2302.40000.8.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2302.40000.9.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2303.40000.2.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2303.40000.3.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2303.40000.4.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2303.40000.5.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2304.40000.5.0&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/LSPosed/MagiskOnWSALocal/issues/550&quot;&gt;‚ö†Ô∏è&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/cinit/WSAPatch/issues/33&quot;&gt;‚õî&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2304.40000.6.0&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/LSPosed/MagiskOnWSALocal/issues/550&quot;&gt;‚ö†Ô∏è&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/cinit/WSAPatch/issues/33&quot;&gt;‚õî&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2304.40000.7.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/cinit/WSAPatch/issues/33&quot;&gt;‚õî&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2304.40000.10.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/cinit/WSAPatch/issues/33&quot;&gt;‚õî&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2305.40000.2.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://github.com/cinit/WSAPatch/issues/33&quot;&gt;‚õî&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2305.40000.3.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2305.40000.4.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2305.40000.5.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2305.40000.6.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2306.40000.1.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2306.40000.2.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2306.40000.3.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2306.40000.4.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2307.40000.2.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2307.40000.3.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2307.40000.5.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2307.40000.6.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2308.40000.1.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;i&gt;v2308.40000.2.0&lt;i&gt;&lt;b&gt;&lt;/b&gt;&lt;/i&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;Update Skipped to allow time for adjusting the Docs and the build script (MagiskOnWSALocal). &lt;br/&gt; Sorry for any Inconvenence. Updates will resume as normal after this.&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2308.40000.3.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2309.40000.2.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;&lt;i&gt;v2309.40000.4.0&lt;i&gt; to &lt;i&gt;2310.40000.1.0 and 2311.40000.3.0&lt;i&gt;&lt;b&gt;&lt;/b&gt;&lt;/i&gt;&lt;/i&gt;&lt;/i&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt;
&lt;td colspan=&quot;2&quot; rowspan=&quot;1&quot;&gt;&quot;Updates have been skipped, in order to allow time to switch to GitHub Actions from my Linux Server, which I have been using since the start of the GitHub repo. Rest assure that this will likely be the last disruption. Once again I appologise and would also like to thank you for using this repo.&quot;&lt;br/&gt;&lt;br/&gt;MustardChef&lt;br/&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2310.40000.2.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2311.40000.4.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2311.40000.5.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2311.40000.5.0_LTS_1&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;v2311.40000.5.0_LTS_2&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;/tr&gt;
&lt;td&gt;v2311.40000.5.0_LTS_3&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;v2407.40000.0.0_LTS_4&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;v2407.40000.0.0_LTS_5&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;v2407.40000.0.0_LTS_6&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;v2407.40000.4.0&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;v2407.40000.0.0_LTS_7&lt;/td&gt;
&lt;td&gt;‚ûñ&lt;/td&gt;
&lt;td&gt;‚ûñ&lt;/td&gt;
&lt;td&gt;v2407.40000.4.0_v2&lt;/td&gt;
&lt;td&gt;‚ûñ&lt;/td&gt;
&lt;td&gt;‚ûñ&lt;/td&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th colspan=&quot;4&quot;&gt;Indicator Keys&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;‚úÖ&lt;/td&gt;
&lt;td&gt;Stable&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;Everything works as intended. &lt;br/&gt; If you think that the build is not stable, please open a &lt;a href=&quot;https://github.com/MustardChef/WSABuilds/issues&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;GitHub Issue&lt;/a&gt; or report the issue in our &lt;a href=&quot;https://discord.gg/2thee7zzHZ&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Discord&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;‚ö†Ô∏è&lt;/td&gt;
&lt;td&gt;Unstable&lt;/td&gt;
&lt;td&gt;Experience may not be smooth due to known bugs or issues&lt;/td&gt;
&lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;u&gt;Click on the Emoji for more information&lt;b&gt;&lt;i&gt;&lt;/i&gt;&lt;/b&gt;&lt;/u&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;‚õî&lt;/td&gt;
&lt;td&gt;Not Working&lt;/td&gt;
&lt;td&gt;Build is not working. DO NOT DOWNLOAD! &lt;/td&gt;
&lt;td&gt;&lt;b&gt;&lt;i&gt;&lt;u&gt;Click on the Emoji for more information&lt;b&gt;&lt;i&gt;&lt;/i&gt;&lt;/b&gt;&lt;/u&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;‚ûñ&lt;/td&gt;
&lt;td&gt;No Information Yet&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;Not enough information to confirm status. Please join the &lt;a href=&quot;https://discord.gg/2thee7zzHZ&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Discord&lt;/a&gt; and confirm whether or not the builds are working.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;br/&gt;
&lt;br/&gt;
&lt;/details&gt;
&lt;/div&gt;
&lt;br/&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;b&gt;&lt;i&gt;Download Variant&lt;/i&gt;&lt;/b&gt;&lt;/th&gt;
&lt;th&gt;&lt;img alt=&quot;Image&quot; height=&quot;28&quot; src=&quot;https://img.shields.io/badge/Pre--Release%20Builds-%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20-orange?style=for-the-badge&quot; width=&quot;223&quot;/&gt;&lt;/th&gt;
&lt;th colspan=&quot;2&quot;&gt;&lt;img alt=&quot;Image&quot; src=&quot;https://img.shields.io/badge/Stable%20Builds-%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20%E2%80%8E%20-blue?style=for-the-badge&quot;/&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;b&gt;Differences:&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;&lt;del&gt;Follows &quot;WSA Preview Program Channel&quot;&lt;/del&gt; &lt;h4&gt;WSABuilds LTS Releases&lt;/h4&gt;&lt;br/&gt;&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;&lt;del&gt;Follows the &quot;WSA Retail&quot; or &quot;Insider Fast Channel&quot; &lt;br/&gt;&lt;/del&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;del&gt;Builds are generally newer than the &quot;WSA Retail&quot; and &quot;Insider Fast Channel&quot;&lt;/del&gt;&lt;br/&gt;&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;&lt;del&gt;Builds are generally more stable than the builds in the &quot;WSA Preview Program Channel&quot;&lt;/del&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Current Version:&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;v2407.40000.0.0_LTS_7&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;v2407.40000.4.0_v2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;b&gt;Release Date:&lt;/b&gt;&lt;/td&gt;
&lt;td&gt;02/06/2025&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;02/06/2025&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Update Frequency:&lt;/td&gt;
&lt;td&gt;&lt;del&gt;Multple Releases Every Month&lt;/del&gt;&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;&lt;del&gt;Once Every Month&lt;/del&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Operating System&lt;/th&gt;
&lt;th&gt;Download Page&lt;/th&gt;
&lt;th&gt;Download Mirror&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td rowspan=&quot;4&quot;&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/e/e6/Windows_11_logo.svg&quot; style=&quot;width: 200px;&quot;/&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/MustardChef/WSABuilds/releases/tag/Windows_11_2407.40000.4.0_LTS_7&quot;&gt;&lt;img alt=&quot;win11x64downpre&quot; src=&quot;https://img.shields.io/badge/Download%20Latest%20Pre--Release%20Builds-Windows%2011%20x64-orange?style=for-the-badge&amp;amp;logo=windows11&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://x6cgr-my.sharepoint.com/:f:/g/personal/mcdt_x6cgr_onmicrosoft_com/EoVMTqCKkgVFvFlJTcz1u0gBdOBqLIwjT-9okE8eCpp3Aw?e=7y5PIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/OneDrive-white?style=for-the-badge&amp;amp;logo=Microsoft%20OneDrive&amp;amp;logoColor=0078D4&quot; style=&quot;width: 150px;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/MustardChef/WSABuilds/releases/tag/Windows_11_2407.40000.4.0_LTS_7_arm64&quot;&gt;&lt;img alt=&quot;win11arm64downpre&quot; src=&quot;https://img.shields.io/badge/Download%20Latest%20Pre--Release%20Builds-Windows%2011%20arm64-orange?style=for-the-badge&amp;amp;logo=windows11&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/MustardChef/WSABuilds/releases/tag/Windows_11_2407.40000.4.0_v2&quot;&gt;&lt;img alt=&quot;win11x64downstable&quot; src=&quot;https://img.shields.io/badge/Download%20Latest%20Stable%20Builds-Windows%2011%20x64-blue?style=for-the-badge&amp;amp;logo=windows11&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://x6cgr-my.sharepoint.com/:f:/g/personal/mcdt_x6cgr_onmicrosoft_com/EoVMTqCKkgVFvFlJTcz1u0gBdOBqLIwjT-9okE8eCpp3Aw?e=7y5PIT&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/OneDrive-white?style=for-the-badge&amp;amp;logo=Microsoft%20OneDrive&amp;amp;logoColor=0078D4&quot; style=&quot;width: 150px;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/MustardChef/WSABuilds/releases/tag/Windows_11_2407.40000.4.0_v2_arm64&quot;&gt;&lt;img alt=&quot;win11arm64downstable&quot; src=&quot;https://img.shields.io/badge/Download%20Latest%20Stable%20Builds-Windows%2011%20arm64-blue?style=for-the-badge&amp;amp;logo=windows11&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/0/05/Windows_10_Logo.svg&quot; style=&quot;width: 200px;&quot;/&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/MustardChef/WSABuilds/releases/tag/Windows_10_2407.40000.4.0_LTS_7&quot;&gt;&lt;img alt=&quot;win10x64down&quot; src=&quot;https://img.shields.io/badge/Download%20Latest%20Pre--Release%20Builds-Windows%2010%20x64-orange?style=for-the-badge&amp;amp;logo=windows&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;a href=&quot;https://x6cgr-my.sharepoint.com/:f:/g/personal/mcdt_x6cgr_onmicrosoft_com/Enm0Tn0BRMlFmrfCWP9Omf0BCiQU0zybeXZtAyOfOVSQqA?e=v6UQyp&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/OneDrive-white?style=for-the-badge&amp;amp;logo=Microsoft%20OneDrive&amp;amp;logoColor=0078D4&quot; style=&quot;width: 150px;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/MustardChef/WSABuilds/releases/tag/Windows_10_2407.40000.4.0_v2&quot;&gt;&lt;img alt=&quot;win10x64down&quot; src=&quot;https://img.shields.io/badge/Download%20Latest%20Stable%20Builds-Windows%2010%20x64-blue?style=for-the-badge&amp;amp;logo=windows&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td&gt;&lt;p&gt;&lt;a href=&quot;https://x6cgr-my.sharepoint.com/:f:/g/personal/mcdt_x6cgr_onmicrosoft_com/Enm0Tn0BRMlFmrfCWP9Omf0BCiQU0zybeXZtAyOfOVSQqA?e=v6UQyp&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/OneDrive-white?style=for-the-badge&amp;amp;logo=Microsoft%20OneDrive&amp;amp;logoColor=0078D4&quot; style=&quot;width: 150px;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://img.icons8.com/color/240/null/windows-11.png&quot; style=&quot;width: 50px;&quot;/&gt;&lt;img src=&quot;https://img.icons8.com/color/240/null/windows-10.png&quot; style=&quot;width: 50px;&quot;/&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/MustardChef/WSABuilds/blob/master/Documentation/WSABuilds/OldBuilds.md&quot;&gt;&lt;img alt=&quot;windownold&quot; src=&quot;https://img.shields.io/badge/Windows%2010%2F11-Older%20Builds-red?style=for-the-badge&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://x6cgr-my.sharepoint.com/:f:/g/personal/mcdt_x6cgr_onmicrosoft_com/EgNsfSstHBtIuAZgiNVkanYBTwu0kKVC_QvOiW7i0IojdQ&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/OneDrive-white?style=for-the-badge&amp;amp;logo=Microsoft%20OneDrive&amp;amp;logoColor=0078D4&quot; style=&quot;width: 150px;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;https://img.icons8.com/color/240/null/windows-11.png&quot; style=&quot;width: 50px;&quot;/&gt; &lt;img src=&quot;https://img.icons8.com/color/240/null/windows-10.png&quot; style=&quot;width: 50px;&quot;/&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;h4&gt;Custom Builds:&lt;h4&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/MustardChef/WSAMagiskDelta&quot;&gt;&lt;img alt=&quot;windownmagikdelta&quot; src=&quot;https://img.shields.io/badge/Windows%2010%2F11-Magisk%20Delta-382bef?style=for-the-badge&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/h4&gt;&lt;/h4&gt;&lt;/td&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;picture&gt;&lt;p align=&quot;center&quot;&gt;&lt;img align=&quot;centre;&quot; src=&quot;https://user-images.githubusercontent.com/68516357/216452358-8137df76-875f-4b59-b77d-ca34c8a2d6d3.png&quot; style=&quot;width: 80px;&quot;/&gt;&lt;/p&gt;&lt;/picture&gt;&lt;/td&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/MustardChef/WSAPackages&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Download-.msix%20Sources-3A6B35?style=for-the-badge&amp;amp;logoColor=white&amp;amp;logo=Github&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://x6cgr-my.sharepoint.com/:f:/g/personal/mcdt_x6cgr_onmicrosoft_com/EgSWYr5JLjFNkSmNydPNFKsBJAlCKj61c6BbbbVGPglASA?e=weIk7y&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/OneDrive-white?style=for-the-badge&amp;amp;logo=Microsoft%20OneDrive&amp;amp;logoColor=0078D4&quot; style=&quot;width: 150px;&quot;/&gt;&lt;/a&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;img align=&quot;left&quot; alt=&quot;system-information&quot; height=&quot;58&quot; src=&quot;https://img.icons8.com/fluency/48/system-information.png&quot; width=&quot;58&quot;/&gt;&lt;h2&gt;Requirements&lt;/h2&gt;
&lt;center&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/e/e6/Windows_11_logo.svg&quot; style=&quot;width: 200px;&quot;/&gt;&lt;/th&gt;
&lt;th&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/0/05/Windows_10_Logo.svg&quot; style=&quot;width: 200px;&quot;/&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;img height=&quot;60&quot; src=&quot;https://img.icons8.com/fluency/96/null/windows-update--v1.png&quot; style=&quot;float: left;&quot; width=&quot;60&quot;/&gt;&lt;h4&gt;Windows Build Number&lt;h4&gt;&lt;/h4&gt;&lt;/h4&gt;&lt;/td&gt;
&lt;td&gt;Windows‚Ñ¢ 11: Build 22000.526 or higher.&lt;/td&gt;
&lt;td&gt;Windows‚Ñ¢ 10: 22H2 10.0.19045.2311 or higher. &lt;br/&gt;&lt;br/&gt;&lt;b&gt;&lt;i&gt;May work on Windows‚Ñ¢ 10: 20H1 10.0.19041.264 or higher.&lt;b&gt;&lt;/b&gt;&lt;/i&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;br/&gt;&lt;br/&gt;&lt;sub&gt;&lt;sup&gt;1. You may need to install &lt;a href=&quot;https://www.catalog.update.microsoft.com/Search.aspx?q=KB5014032&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;KB5014032&lt;/a&gt; then install &lt;a href=&quot;https://www.catalog.update.microsoft.com/Search.aspx?q=KB5022834&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;KB5022834&lt;/a&gt; to use WSA on these older Windows 10 builds&lt;b&gt;&lt;br/&gt;&lt;br/&gt;&lt;b&gt;&lt;/b&gt;&lt;/b&gt;&lt;/sup&gt;&lt;/sub&gt;&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&quot;2&quot;&gt;&lt;h5&gt;&lt;b&gt;&lt;i&gt;Custom/modfied Windows OS installations (such as ReviOS, Tiny 10/11 and Ghost Spectre etc.) may have issues with running WSA.&lt;br/&gt;&lt;/i&gt;&lt;/b&gt;&lt;/h5&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img height=&quot;60&quot; src=&quot;https://img.icons8.com/external-smashingstocks-flat-smashing-stocks/66/null/external-RAM-technology-and-devices-smashingstocks-flat-smashing-stocks.png&quot; style=&quot;float: left;&quot; width=&quot;60&quot;/&gt;&lt;h4&gt;RAM&lt;h4&gt;&lt;/h4&gt;&lt;/h4&gt;&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;&lt;ul&gt;&lt;li&gt;4 to 6 GB (Not Recommended)&lt;/li&gt;&lt;li&gt;8 GB (Minimum)&lt;/li&gt;&lt;li&gt;16 GB (Recommended)&lt;/li&gt;&lt;/ul&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;img height=&quot;60&quot; src=&quot;https://img.icons8.com/3d-fluency/94/null/electronics.png&quot; style=&quot;float: left;&quot; width=&quot;60&quot;/&gt;&lt;h4&gt;Processor&lt;h4&gt;&lt;/h4&gt;&lt;/h4&gt;&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;&lt;b&gt;&lt;i&gt;CPU Architecture: x86_64 or arm64&lt;b&gt;&lt;i&gt;&lt;/i&gt;&lt;/b&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Your PC should meet the basic Windows‚Ñ¢ 11 requirements i.e Core i3 8th Gen, Ryzen 3000, Snapdragon 8c, or above&lt;/td&gt;
&lt;td&gt;N/A &lt;br/&gt;&lt;br/&gt; This is a bit of a hit or miss, but it is highly recommended that your processor is listed in the &lt;a href=&quot;https://learn.microsoft.com/en-gb/windows-hardware/design/minimum/windows-processor-requirements&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;supported CPU lists for Windows 11 requirements&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img height=&quot;60&quot; src=&quot;https://img.icons8.com/3d-fluency/94/null/video-card.png&quot; style=&quot;float: left;&quot; width=&quot;60&quot;/&gt;&lt;h4&gt;GPU&lt;h4&gt;&lt;/h4&gt;&lt;/h4&gt;&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;Any compatible Intel, AMD or Nvidia GPU. &lt;br/&gt; GPU Performance may vary depending on its compatibility with Windows Subsystem For Android‚Ñ¢  &lt;br/&gt;&lt;br/&gt;&lt;details&gt;&lt;summary&gt;&lt;h4&gt;Users with Intel HD Graphics 530 and older&lt;h4&gt;&lt;/h4&gt;&lt;/h4&gt;&lt;/summary&gt;&lt;br/&gt;&lt;h5&gt; WSA may not start or graphical glitches will occur when Intel HD Graphics 530 and Older iGPUs are used. This is a known issue, but unfortunately there are no fixes that I currently know of, plus, these GPUs are too old and do not meet Windows 11 requirements and hence are not official supported. &lt;a href=&quot;https://github.com/MustardChef/WSABuilds/blob/master/Documentation/Usage%20Guides/General%20Usage%20Guides/ChangingGPU.md&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;Follow this guide&lt;/a&gt; to switch to another iGPU/dGPU/eGPU that you may have or Microsoft Basic Renderer&lt;h5&gt;&lt;/h5&gt;&lt;/h5&gt;&lt;/details&gt;&lt;br/&gt;&lt;details&gt;&lt;summary&gt;&lt;h4&gt;Users with Nvidia GPUs&lt;h4&gt;&lt;/h4&gt;&lt;/h4&gt;&lt;/summary&gt;&lt;br/&gt;&lt;h5&gt; Nvidia GPUs are known to cause problems. If Windows Subsystem For Android‚Ñ¢ does not start or there are graphical glitches when an Nvidia GPU is used, &lt;a href=&quot;https://github.com/MustardChef/WSABuilds/blob/master/Documentation/Usage%20Guides/General%20Usage%20Guides/ChangingGPU.md&quot; rel=&quot;noopener noreferrer&quot; target=&quot;_blank&quot;&gt;follow this guide&lt;/a&gt; to switch to another iGPU/dGPU/eGPU  that you may have or Microsoft Basic Renderer&lt;h5&gt;&lt;/h5&gt;&lt;/h5&gt;&lt;/details&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td rowspan=&quot;2&quot;&gt;&lt;img height=&quot;60&quot; src=&quot;https://img.icons8.com/3d-fluency/94/null/ssd.png&quot; style=&quot;float: left;&quot; width=&quot;60&quot;/&gt;&lt;h4&gt;Storage&lt;h4&gt;&lt;/h4&gt;&lt;/h4&gt;&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;&lt;b&gt;&lt;i&gt;Solid-state drive (RECOMMENDED)&lt;i&gt;&lt;b&gt; &lt;br/&gt;OR&lt;br/&gt; &lt;b&gt;&lt;i&gt;Hard Disk Drive (HDD)&lt;i&gt;&lt;b&gt;   (NOT RECOMMENDED)&lt;i&gt;&lt;/i&gt;&lt;/b&gt;&lt;/i&gt;&lt;/i&gt;&lt;/b&gt;&lt;/b&gt;&lt;/i&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan=&quot;2&quot;&gt;&lt;b&gt;&lt;i&gt;Minimum Storage Requirements: You must have at least 10GB free on the system drive (C:\)&lt;b&gt;&lt;i&gt;&lt;/i&gt;&lt;/b&gt;&lt;/i&gt;&lt;/b&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img height=&quot;60&quot; src=&quot;https://img.icons8.com/stickers/100/null/storage.png&quot; style=&quot;float: left;&quot; width=&quot;60&quot;/&gt;&lt;h4&gt;Partition&lt;h4&gt;&lt;/h4&gt;&lt;/h4&gt;&lt;/td&gt;
&lt;td colspan=&quot;2&quot;&gt;&lt;b&gt;&lt;i&gt;NTFS ONLY&lt;b&gt;&lt;i&gt; &lt;br/&gt;&lt;br/&gt; Windows Subsystem For 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[rossant/awesome-math]]></title>
            <link>https://github.com/rossant/awesome-math</link>
            <guid>https://github.com/rossant/awesome-math</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:50 GMT</pubDate>
            <description><![CDATA[A curated list of awesome mathematics resources]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/rossant/awesome-math">rossant/awesome-math</a></h1>
            <p>A curated list of awesome mathematics resources</p>
            <p>Language: Python</p>
            <p>Stars: 13,082</p>
            <p>Forks: 1,274</p>
            <p>Stars today: 234 stars today</p>
            <h2>README</h2><pre># Awesome Math [![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)

A curated list of awesome mathematics resources.

All resources are freely available except those with a üí≤ icon.

# Contents

&lt;!-- START_TOC --&gt;

* [Contents](#contents)
* [General Resources](#general-resources)
    * [Learning Platforms](#learning-platforms)
    * [Learn to Learn](#learn-to-learn)
    * [Youtube Series](#youtube-series)
    * [Tools](#tools)
    * [Questions and Answers](#questions-and-answers)
    * [Encyclopedia](#encyclopedia)
    * [Books](#books)
    * [Magazines](#magazines)
    * [Blogs](#blogs)
    * [Meetings and Conferences](#meetings-and-conferences)
    * [Misc](#misc)
* [Branches of Mathematics](#branches-of-mathematics)
    * [Foundations of Mathematics](#foundations-of-mathematics)
        * [Transition To Pure Rigour Math](#transition-to-pure-rigour-math)
        * [Set Theory](#set-theory)
        * [Logic](#logic)
        * [Category Theory](#category-theory)
        * [Type Theory](#type-theory)
        * [Homotopy Type Theory](#homotopy-type-theory)
        * [Surreal Numbers](#surreal-numbers)
    * [Number Theory](#number-theory)
        * [Algebraic Number Theory](#algebraic-number-theory)
        * [Analytic Number Theory](#analytic-number-theory)
    * [Algebra](#algebra)
        * [Abstract Algebra](#abstract-algebra)
        * [Group Theory](#group-theory)
        * [Linear Algebra](#linear-algebra)
        * [Ring Theory](#ring-theory)
        * [Galois Theory](#galois-theory)
        * [Lie Algebras](#lie-algebras)
    * [Combinatorics](#combinatorics)
        * [Graph Theory](#graph-theory)
    * [Geometry and Topology](#geometry-and-topology)
        * [Differential Geometry](#differential-geometry)
        * [Algebraic Geometry](#algebraic-geometry)
        * [Algebraic Statistics](#algebraic-statistics)
        * [Topology](#topology)
        * [Algebraic Topology](#algebraic-topology)
    * [Analysis](#analysis)
        * [Real Analysis](#real-analysis)
        * [Harmonic Analysis](#harmonic-analysis)
        * [Complex Analysis](#complex-analysis)
        * [Functional Analysis](#functional-analysis)
        * [Measure Theory](#measure-theory)
        * [Ordinary Differential Equations](#ordinary-differential-equations)
        * [Partial Differential Equations](#partial-differential-equations)
        * [Chaos Theory](#chaos-theory)
    * [Probability and Statistics](#probability-and-statistics)
        * [Probability Theory](#probability-theory)
        * [Statistics](#statistics)
        * [Statistical Learning](#statistical-learning)
        * [Stochastic processes](#stochastic-processes)
    * [Numerical Analysis](#numerical-analysis)
    * [Signal processing](#signal-processing)
    * [Mathematics for Computer Science](#mathematics-for-computer-science)
    * [Mathematical Biology](#mathematical-biology)
    * [Mathematical Physics](#mathematical-physics)
* [Students Lecture Notes](#students-lecture-notes)
* [Related Awesome Lists](#related-awesome-lists)
* [License](#license)

&lt;!-- END_TOC --&gt;

# General Resources

## Learning Platforms

* [Khan Academy](https://www.khanacademy.org/math)
* [Coursera](https://www.coursera.org/courses?query=mathematics&amp;languages=en)
* [MIT OpenCourseWare](http://ocw.mit.edu/courses/mathematics/)
* [edX](https://www.edx.org/course/subject/math)
* [Brilliant](https://brilliant.org/courses/#math-foundational)
* [WooTube](https://misterwootube.com/)
* [Mathigon](https://mathigon.org/)
* [Calculus.org](http://calculus.org/)
* [Ximera](https://ximera.osu.edu/) : free interactive mathematics textbooks (Ohio State University)
* [Almost Fun](https://www.almostfun.org/lessons/)
* [Oxford Mathematics](https://www.youtube.com/c/OxfordMathematics)
* [Math Academy](https://mathacademy.com/)

## Learn to Learn

* [Understanding Mathematics](https://github.com/nelson-brochado/understanding-math)

## Youtube Series

* [Brandon Foltz](https://www.youtube.com/@BrandonFoltz)
* [StatQuest](https://www.youtube.com/channel/UCtYLUTtgS3k1Fg4y5tAhLbw)
* [3Blue1Brown](https://www.youtube.com/@3blue1brown)
* [NPTEL](https://www.youtube.com/@iit)
* [PatrickJMT](https://www.youtube.com/@patrickjmt)
* [Professor Leonard](https://www.youtube.com/@ProfessorLeonard)
  * [Precalculus - College Algebra/Trigonometry](https://www.youtube.com/playlist?list=PLDesaqWTN6ESsmwELdrzhcGiRhk5DjwLP)
  * [Calculus 1](https://www.youtube.com/playlist?list=PLF797E961509B4EB5)
  * [Calculus 2](https://www.youtube.com/playlist?list=PLDesaqWTN6EQ2J4vgsN1HyBeRADEh4Cw-)
  * [Calculus 3](https://www.youtube.com/playlist?list=PLDesaqWTN6ESk16YRmzuJ8f6-rnuy0Ry7)
  * [Differential Equations](https://www.youtube.com/playlist?list=PLDesaqWTN6ESPaHy2QUKVaXNZuQNxkYQ_)
  * [To The Point Math](https://www.youtube.com/playlist?list=PLDesaqWTN6ETc1ZwHWijCBcZ2gOvS2tTN)
* [Crash Course](https://www.youtube.com/@crashcourse)
* [Harvard](https://www.youtube.com/@harvard)
* [MIT OpenCourseWare](https://www.youtube.com/@mitocw)
* [Mathologer](https://www.youtube.com/@Mathologer)
* [The Math District](https://www.youtube.com/@TheMathDistrict)
* [Mathematical Monk](https://www.youtube.com/@mathematicalmonk)
* [The Math Sorcerer](https://www.youtube.com/@TheMathSorcerer)

## Tools

* [Symbolab](https://www.symbolab.com/)
* [Desmos](https://www.desmos.com/calculator)
* [Math Words](http://www.mathwords.com/)
* [Wolfram Alpha](http://www.wolframalpha.com/)
* [Maxima](https://maxima.sourceforge.io/)
* [Sympy](https://www.sympy.org/)
* [Sagemath](http://www.sagemath.org/)
* [MathFlow](https://github.com/Nonanti/MathFlow) - C# math expression library with symbolic computation (differentiation, simplification, equation solving)
* [Unit Converter](https://unitconverters.net)
* [GeoGebra](https://www.geogebra.org/?lang=en)
* [Macaulay2](http://www2.macaulay2.com/Macaulay2/)
* [Singular](https://www.singular.uni-kl.de/)
* [GNU Octave](https://www.gnu.org/software/octave/)
* [Magma](http://magma.maths.usyd.edu.au/magma/)
* [Maple](https://www.maplesoft.com/products/Maple/)
* [Matlab](https://www.mathworks.com/products/matlab.html)
* [Wolfram Mathematica](https://www.wolfram.com/mathematica/)
* [Free Math](https://freemathapp.org)
* [xhub](https://chrome.google.com/webstore/detail/xhub/anidddebgkllnnnnjfkmjcaallemhjee)
* [CopyPasteMathjax](https://www.copypastemathjax.com/)
* [Finance calculators](https://www.financecharts.com/pages/5724-retirement-calculators-and-stock-market-tips)
* [Mathcheap](https://mathcheap.xyz)
* [Midpoint Calculator](https://midpointcalculator.co)
* [Quartiles Calculator](https://quartilecalculator.net)
* [Corca Editor](https://corca.io/)
* [RunMat](https://github.com/runmat-org/runmat) - Runtime for MATLAB-syntax array math with automatic CPU/GPU execution.
* [Structural Engineering Tools (SEPCO Engineering)](https://github.com/sepcostructural/structural-engineering-tools) - Free online calculators for beam diagrams, Canadian steel section properties, and pressure conversions.


## Questions and Answers

* [Mathematics Stack Exchange](http://math.stackexchange.com/)
* [MathOverflow](http://mathoverflow.net/) - for professional mathematicians

## Encyclopedia

* [Encyclopedia of Mathematics](https://www.encyclopediaofmath.org)
* [Planetmath](http://planetmath.org/)
* [ProofWiki](https://proofwiki.org/wiki/Main_Page)
* [Wolfram Mathworld](http://mathworld.wolfram.com/)
* [The On-Line Encyclopedia of Integer Sequences](https://oeis.org) - Great compendium of many different integer sequences. Founded 1964 by N. J. A. Sloane.
* üí≤ [The Princeton Companion to Mathematics](https://press.princeton.edu/books/hardcover/9780691118802/the-princeton-companion-to-mathematics) - Timothy Gowers (Professor, Fields medallist), June Barrow-Green (Professor), and Imre Leader (Professor).
* üí≤ [Encyclopedia of Distances (4th Edition)](https://link.springer.com/book/10.1007/978-3-662-52844-0) - Michel Marie Deza, Elena Deza.

## Books

* [Calculus: Basic Concepts for High Schools](https://archive.org/details/TarasovCalculus) - L.V. Tarasov
* [Basics of Algebra, Topology, and Differential Calculus](http://www.cis.upenn.edu/~jean/math-basics.pdf) - Jean Gallier (University of Pennsylvania)
* [Multivariable Calculus](http://people.math.gatech.edu/%7Ecain/notes/calculus.html) - G. Cain, J. Herod (Georgia Tech)
* [Wikibooks](https://en.wikibooks.org/wiki/Wikibooks:Mathematics_bookshelf)
* [Online Mathematics Textbooks](https://people.math.gatech.edu/~cain/textbooks/onlinebooks.html)
* [Beginning and Intermediate Algebra](http://www.wallace.ccfaculty.org/book/Beginning_and_Intermediate_Algebra.pdf)
* [Free Mathematics Books](https://github.com/EbookFoundation/free-programming-books/blob/master/books/free-programming-books-subjects.md#mathematics)
* [Trigonometry](http://www.mecmath.net/trig/trigbook.pdf)
* [Math for Frontend Web Dev](https://www.manning.com/books/math-for-frontend-web-dev)
* [Grokking Statistics](https://www.manning.com/books/grokking-statistics)

## Magazines

* [Quanta Magazine](https://www.quantamagazine.org/mathematics/) - Features latest research breakthroughs in an accessible style for non-experts.
* [Bulletin of the American Mathematical Society](https://www.ams.org/journals/bull/all_issues.html) - Expository articles on contemporary mathematical research, written in a way that gives insight to mathematicians who may not be experts in the particular topic.
* [Notices of the American Mathematical Society](http://www.ams.org/cgi-bin/notices/amsnotices.pl?article_id=fullissue&amp;article_type=gallery&amp;gallery_type=fullissue) - Publicizes activities of the Society and features surveys, reports, news, announcements, and opinions on industry trends, academia, and research.
* [European Mathematical Society Magazine](https://euromathsoc.org/magazine) - The Magazine features announcements about meetings and conferences, articles outlining current trends in scientific development, reports on member societies, and many other informational items.
* [Mathematics Today by Institute of Mathematics and its Applications](https://ima.org.uk/publications/mathematics-today/) - News, opinions, and articles related to mathematics, so the reader stays updated.
* [Crux Mathematicorum by Canadian Mathematical Society](https://cms.math.ca/publications/crux/) - source of unique and challenging mathematical problems designed for the secondary and undergraduate levels. It includes an Olympiad Corner which is helpful for math competitions.

## Blogs

* [BetterExplained](https://betterexplained.com/) - Maintained by Kalid Azad
* [ILoveMaths](http://ilovemaths.com/) - For grades 6 thru 12 in K-12 system
* [3blue1brown](https://www.3blue1brown.com/) - Animated Maths
* [Mathsisfun](https://www.mathsisfun.com) simple text lightweight site for students up to highschool
* [MathematicsIsAScience](https://calculus123.com/wiki/Peter_Saveliev) - Peter Saveliev (Professor of mathematics at Marshall University, Huntington WV, USA)

## Meetings and Conferences

* [MathsJam](https://mathsjam.com/) - monthly local recreational maths/puzzle meetups and an annual gathering in Staffordshire, England
* [Talking Maths in Public](https://talkingmathsinpublic.uk/) - a conference for maths communicators, running every two years, usually in the UK
* [Bridges](https://www.bridgesmathart.org/) - an annual conference on mathematical connections in art, music, architecture, and culture. The 2025 meeting is in Eindhoven, Netherlands.

## Misc
* [Areas of mathematics on Wikipedia](https://en.wikipedia.org/wiki/Areas_of_mathematics)
* [Paul&#039;s Online Math Notes](http://tutorial.math.lamar.edu/) - Paul Dawkins (Lamar University)
* [List of electronic textbooks](http://faculty.atu.edu/mfinan/nnotes.html) - Marcel B. Finan (Arkansas Tech University)
* [Topology Atlas](http://at.yorku.ca/topology/)
* [Recreations in Math](http://djm.cc/library/Recreations_in_Mathematics_Licks_edited.pdf) - H. E. Licks (1917)
* [Magic Squares and Cubes](http://djm.cc/library/Magic_Squares_Cubes_Andrews_edited.pdf) - W. S. Andrews (1917)
* [Convex Optimization](https://web.stanford.edu/~boyd/cvxbook/) - Stephen Boyd and Lieven Vandenberghe
* [Fabrice Baudoin&#039;s Notes](https://fabricebaudoin.wordpress.com/) - Both research and lecture notes on many topics, Including Diffusions on foliated manifold, Stochastic Calculus, Global analysis in Dirichlet spaces, and more.

# Branches of Mathematics

**Content Format** \
üìñ Books \
üé• Videos \
üìù Lecture notes, slides, articles, papers

## Foundations of Mathematics
### Transition To Pure Rigour Math
* üìù [Basic Concepts of Mathematics](http://www.trillia.com/zakon1.html) - Elias Zakon
* üìù [Book of Proof](https://richardhammack.github.io/BookOfProof/) - Richard Hammak (Virginia Commonwealth University)
* üìñ [How to Prove It: A Structured Approach (3rd Edition)](https://ia800501.us.archive.org/7/items/how-to-prove-it-a-structured-approach-daniel-j.-velleman/How%20to%20Prove%20It%20A%20Structured%20Approach%20%28Daniel%20J.%20Velleman%29.pdf) - Daniel J. Velleman (Professor).

### Set Theory

* üìù [Sets, Relations, Functions](http://www.cosc.brocku.ca/~duentsch/papers/methprimer1.html) - Ivo D√ºntsch, G√ºnther Gediga
* üìù [An Introduction to Set Theory](http://www.math.toronto.edu/weiss/set_theory.pdf) - William A. R. Weiss
* üìù [Set Theory and Foundations of Mathematics](http://www.settheory.net/) - Sylvain Poirier
* üìù [Set Theory on the Stanford Encyclopedia of Philosophy](http://plato.stanford.edu/entries/set-theory/)

### Logic

* üìù [Introduction to Logic](https://pdfs.semanticscholar.org/6967/f52773d9c2ccfc94658657a5761e0f00e95a.pdf) - Michael Genesereth, Eric Kao (Stanford University)
* üìù [An Introduction to Formal Logic](https://www.fecundity.com/codex/forallx.pdf) - P.D. Magnus (University at Albany)
* üìù [A Problem Course in Mathematical Logic](http://euclid.trentu.ca/math/sb/pcml/pcml-16.pdf) - Stefan Bilaniuk (Trent University)
* üìù [Computability - An introduction to recursive function theory](http://poincare.matf.bg.ac.rs/~zarkom/Book_Math__Cutland_Computability.pdf) - Nigel Cutland (University of Hull)
* üìù [Language, Proof, and Logic](http://homepages.uc.edu/~martinj/Symbolic_Logic/341%20Syllabus,%20Textbook,%20Handouts,%20Notes/LPL%20textbook.pdf) - Jon Barwise, John Etchemendy
* üìù [Mathematical Logic](http://www.mathematik.uni-muenchen.de/~schwicht/lectures/logic/ws03/ml.pdf) - Helmut Schwichtenberg
* üìù [Mathematical Logic](http://www.personal.psu.edu/t20/notes/logic.pdf) - Stephen G. Simpson (Pennsylvania State University)
* üìù [Formal Logic](http://maude.sip.ucm.es/~miguelpt/papers/flogic.pdf) - Miguel Palomino
* üìù [Predictive Arithmetic](https://web.math.princeton.edu/~nelson/books/pa.pdf) - Edward Nelson
* üìù [Proofs and Concepts: the fundamentals of abstract mathematics](http://people.uleth.ca/~dave.morris/books/proofs+concepts.html) - Joy Morris, Dave Morris
* üìù [Mathematical Reasoning: Writing and Proof](https://www.tedsundstrom.com/mathreasoning) - Ted Sundstrom
* üìù [Logic and Proof](http://leanprover.github.io/logic_and_proof/) -  Jeremy Avigad, Robert Y. Lewis, and Floris van Doorn
* üìù [QED - an interactive textbook](https://teorth.github.io/QED) - Terence Tao
* üìù [Open Logic Textbook](http://builds.openlogicproject.org/) - collaborative effort, main contributors listed [here](https://openlogicproject.org/people/)

### Category Theory

* üìù [Introduction to Category Theory and Categorical Logic](http://www.mathematik.tu-darmstadt.de/~streicher/CTCL.pdf) - Thomas Streicher
* üìù [An Introduction to Category Theory](http://www.cs.man.ac.uk/~hsimmons/zCATS.pdf) - Harold Simmons
* üìù [Category Theory](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.211.4754&amp;rep=rep1&amp;type=pdf) - Steve Awodey (Carnegie Mellon University)
* üìù [Category Theory](http://www.mathematik.uni-muenchen.de/~pareigis/Vorlesungen/04SS/Cats1.pdf) - B. Pareigis
* üìù [Category Theory for Computing Science](https://web.archive.org/web/20181221233252/http://www.math.mcgill.ca/triples/Barr-Wells-ctcs.pdf) - Michael Barr, Charles Wells
* üìù [Toposes, Triples and Theories](http://www.tac.mta.ca/tac/reprints/articles/12/tr12.pdf) - Michael Barr, Charles Wells
* üìù [Abelian Categories](http://www.tac.mta.ca/tac/reprints/articles/3/tr3abs.html) - Peter Freyd
* üìù [Categories and Groupoids](http://www.tac.mta.ca/tac/reprints/articles/7/tr7abs.html) - P. J. Higgins
* üìù [Basic Concepts of Enriched Category Theory](http://www.tac.mta.ca/tac/reprints/articles/10/tr10abs.html) - G. M. Kelley
* üìù [Abstract and Concrete Categories: The Joy of Cats](http://www.tac.mta.ca/tac/reprints/articles/17/tr17abs.html) - Jiri Adamek, Horst Herrlich, George Strecker
* üìù [Seven Sketches in Compositionality: An Invitation to Applied Category Theory](http://math.mit.edu/~dspivak/teaching/sp18/7Sketches.pdf) - Brendan Fong and David I. Spivak (MIT)
* üìù [Category Theory in Context](http://www.math.jhu.edu/~eriehl/context/) - Emily Riehl (John Hopkins University)

### Type Theory
* üìù [Proofs and Types](http://www.paultaylor.eu/stable/prot.pdf) - Jean-Yves Girard
* üìù [Intuitionistic Type Theory](https://archive-pml.github.io/martin-lof/pdfs/Bibliopolis-Book-retypeset-1984.pdf) - Per Martin-Lof
* üìù [Type Theory and Functional Programming](https://www.cs.kent.ac.uk/people/staff/sjt/TTFP/) - Simon Thompson
* üìù [Programming in Martin-Lof‚Äôs Type Theory](http://www.cse.chalmers.se/research/group/logic/book/book.pdf) - Bengt Nordstrom, Kent Petersson, Jan M. Smith

### Homotopy Type Theory

* üìù [Homotopy Type Theory](https://hottheory.files.wordpress.com/2013/03/hott-online-611-ga1a258c.pdf)

### Surreal Numbers

* üìù [Surreal Numbers - How two ex-students turned on to pure mathematics and found total happiness](http://www.math.harvard.edu/~knill/teaching/mathe320_2015_fall/blog15/surreal1.pdf) - D. E. Knuth
* üìù [Surreal Numbers and Games](http://web.mit.edu/sp.268/www/2010/surreal.pdf)
* üìù [Conway names, the simplicity hierarchy and the surreal number tree](http://www.ohio.edu/people/ehrlich/ConwayNames.pdf) - Philip Ehrlich


## Number Theory

* üìù [Elementary Number Theory: Primes, Congruences, and Secrets](http://wstein.org/ent/ent.pdf) - William Stein
* üìù [Elementary Number Theory](http://math.utoledo.edu/~codenth/Spring_13/3200/ENT-books/Elementary_Number_Theory-Clark.pdf) - W. Edwin Clark (University of South Florida)
* üìù [A Course on Number Theory](http://www.maths.qmul.ac.uk/~pjc/notes/nt.pdf) - Peter J. Cameron
* üìù [A Computational Introduction to Number Theory and Algebra](http://shoup.net/ntb/ntb-v2.pdf) - Victor Shoup
* üìù [Number Theory: A Contemporary Introduction](http://alpha.math.uga.edu/~pete/4400FULL.pdf) - Pete L. Clark
* üìù [An Introduction to the Theory of Numbers](http://www.trillia.com/moser-number.html) - Leo Moser
* üìù [Yet Another Introductory Number Theory Textbook](https://www.poritz.net/jonathan/share/yaintt/) - Jonathan A. Poritz

### Algebraic Number Theory

* üìù [Introduction to Algebraic Number Theory](https://feog.github.io/ANT10.pdf) - F. Oggier
* üìù [Algebraic Number Theory](http://www.jmilne.org/math/CourseNotes/ANT.pdf) - J.S. Milne
* üìù [Algebraic Number Theory Course Notes](http://people.math.gatech.edu/~mbaker/pdf/ANTBook.pdf) - Matthew Baker (Georgia Tech)
* üìù [A Course In Algebraic Number Theory](http://www.math.uiuc.edu/~r-ash/ANT.html) - Robert Ash

### Analytic Number Theory

* üìù [Introduction to Analytic Number Theory](http://www.math.uiuc.edu/~hildebr/ant/main.pdf) - A.J. Hildebrand (University of Illinois)
* üìù [Elements of Analytic Number Theory](http://math.nsc.ru/~vdovin/lectures/numth_eng.pdf) - P. S. Kolesnikov, E. P. Vdovin (Novosibirsk)
* üìù [Analytic Number Theory](http://www.mathematik.uni-muenchen.de/~forster/v/ann/annth_all.pdf) - Otto Forster (LMU Munich)
* üìù [Analytic Number Theory - Lecture Notes based on Davenport‚Äôs bo

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OWASP/Nest]]></title>
            <link>https://github.com/OWASP/Nest</link>
            <guid>https://github.com/OWASP/Nest</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:49 GMT</pubDate>
            <description><![CDATA[Your gateway to OWASP. Discover, engage, and help shape the future!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OWASP/Nest">OWASP/Nest</a></h1>
            <p>Your gateway to OWASP. Discover, engage, and help shape the future!</p>
            <p>Language: Python</p>
            <p>Stars: 290</p>
            <p>Forks: 389</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

[![OWASP](https://img.shields.io/badge/Lab-blue?&amp;label=owasp%20level&amp;style=for-the-badge)](https://owasp.org/www-project-nest/) [![OWASP](https://img.shields.io/badge/Code-blue?label=OWASP%20Type&amp;style=for-the-badge)](https://owasp.org/www-project-nest/) [![project-nest](https://img.shields.io/badge/%23project--nest-blue?label=OWASP%20Slack&amp;logoColor=white&amp;style=for-the-badge)](https://owasp.slack.com/messages/project-nest)

[![License](https://img.shields.io/github/license/owasp/nest?color=blue&amp;label=License&amp;style=for-the-badge)](https://github.com/OWASP/Nest/blob/main/LICENSE) [![Last Commit](https://img.shields.io/github/last-commit/owasp/nest/main?color=blue&amp;style=for-the-badge&amp;label=Last%20commit)](https://github.com/OWASP/Nest/commits/main/) [![Contributors](https://img.shields.io/github/contributors/owasp/nest?style=for-the-badge&amp;label=Contributors&amp;color=blue)](https://github.com/OWASP/Nest/graphs/contributors)

[![CI/CD](https://img.shields.io/github/actions/workflow/status/owasp/nest/run-ci-cd.yaml?branch=main&amp;color=blue&amp;label=Build&amp;style=for-the-badge)](https://github.com/owasp/nest/actions/workflows/run-ci-cd.yaml?query=branch%3Amain) [![CodeQL](https://img.shields.io/github/actions/workflow/status/owasp/nest/run-code-ql.yaml?branch=main&amp;color=blue&amp;label=CodeQL&amp;style=for-the-badge)](https://github.com/owasp/nest/actions/workflows/run-code-ql.yaml?query=branch%3Amain) [![Sonarqube](https://img.shields.io/sonar/quality_gate/OWASP_Nest?color=blue&amp;server=https://sonarcloud.io&amp;style=for-the-badge&amp;label=Sonarqube)](https://sonarcloud.io/summary/new_code?id=OWASP_Nest&amp;branch=main)

[![Issues](https://img.shields.io/github/issues/owasp/nest?color=blue&amp;style=for-the-badge&amp;label=Issues)](https://github.com/OWASP/Nest/issues) [![Pull Requests](https://img.shields.io/github/issues-pr/owasp/nest?color=blue&amp;style=for-the-badge&amp;label=Pull%20Requests)](https://github.com/OWASP/Nest/pulls)

[![OpenSSF](https://img.shields.io/badge/OpenSSF-84%25-blue?style=for-the-badge)](https://www.bestpractices.dev/projects/10174) [![Snyk Security](https://img.shields.io/badge/Snyk-Scanned-blue?style=for-the-badge)](https://snyk.io)

[![Forks](https://img.shields.io/github/forks/owasp/nest?style=for-the-badge&amp;label=Forks)](https://github.com/OWASP/Nest/network/members) [![Stars](https://img.shields.io/github/stars/owasp/nest?style=for-the-badge&amp;label=Stars)](https://github.com/OWASP/Nest/stargazers)

[![CREATED](https://img.shields.io/badge/created-aug,%202024-blue?style=for-the-badge)](https://github.com/OWASP/Nest/commit/2a213c2efcfc2f8889c2f1d330da0d2e6f649fc1)

&lt;picture&gt;
  &lt;source srcset=&quot;https://raw.githubusercontent.com/OWASP/Nest/refs/heads/main/frontend/public/img/logo_dark.png&quot; media=&quot;(prefers-color-scheme: dark)&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/OWASP/Nest/refs/heads/main/frontend/public/img/logo_light.png&quot; alt=&quot;OWASP Nest Logo&quot; width=&quot;200&quot;&gt;
&lt;/picture&gt;

# [OWASP Nest](https://nest.owasp.org/)

&lt;/div&gt;

**OWASP Nest** is a comprehensive platform designed to enhance collaboration and contribution within the OWASP community. The application serves as a central hub for exploring OWASP projects and ways to contribute to them, empowering contributors to find opportunities that align with their interests and expertise.

Key features of the platform include:

- **Advanced Search Capabilities:** Enables efficient navigation and filtering of projects and issues based on keywords, tags, and contributor preferences.
- **Slack Integration:** Supports seamless communication through a [Slack bot](https://owasp.slack.com/team/U07M1C4JASK) that facilitates direct and channel messaging for updates and discussions.
- **OWASP Chapters Proximity Page:** Offers localized information about nearby OWASP chapters to foster community engagement.
- **AI-Generated Insights:** Provides summarized descriptions and actionable steps for tackling project issues.

OWASP Nest promotes collaboration, making it easier for both new and experienced contributors to engage meaningfully with OWASP&#039;s mission to improve software security worldwide.

## Leaders

OWASP Nest is led by a dedicated team committed to fostering collaboration and supporting contributors. The leadership team ensures the platform aligns with OWASP&#039;s mission, continually improving its features to serve the community better.
Current Leaders:

- [Arkadii Yakovets](https://github.com/arkid15r/)  -- CCSP, CISSP, CSSLP
- [Kate Golovanova](https://github.com/kasya/) -- CC
- [Starr Brown](https://github.com/mamicidal/) -- CISSP

All OWASP Nest leaders are certified ISC2 professionals and adhere to the OWASP Code of Conduct.
For questions or discussions with the leadership team and other contributors, please use the [#project-nest](https://owasp.slack.com/archives/project-nest) channel on OWASP Slack.

## Contributing

OWASP Nest thrives on community contributions. Whether you are a developer, designer, writer, or enthusiast, there are various ways to get involved:

- Code Contributions: Help improve the platform by fixing issues or adding new features.
- Code Review: Review and provide feedback on pull requests to ensure code quality and maintainability.
- Documentation: Enhance user guides or create tutorials to help others navigate the platform.
- Issue Reporting: Identify and report bugs or suggest improvements.
- Engagement: Share feedback, participate in discussions, or promote the project in your network.

To get started, visit the [OWASP Nest Repository](https://github.com/OWASP/Nest), explore the [Contributing Guidelines](https://github.com/OWASP/Nest/blob/main/CONTRIBUTING.md), and [Code of Conduct](https://github.com/OWASP/Nest/blob/main/CODE_OF_CONDUCT.md).

## About

OWASP Nest was **originally created by Arkadii Yakovets** (Ark) to address challenges in navigating OWASP projects. The project was **built from scratch based on Ark&#039;s ideas and discussions with Starr Brown** (Starr), ensuring a well-structured system design aligned with OWASP&#039;s ecosystem. Ark, an experienced software development professional with over 10 years of expertise in Python, Django, Django REST Framework (DRF), and related backend technologies, led the development of the backend using widely adopted Python **open-source frameworks and libraries**, including DRF, django-filter, OpenAI, Algolia Search, slack-bolt, PyGitHub, pre-commit, pytest, and more. The initial frontend, based on Vue.js, was introduced by **Kateryna Golovanova** (Kate), who later became the project co-leader due to her invaluable frontend and project management skills. The **code is licensed under the MIT License**, encouraging contributions while protecting the authors from legal claims. All OWASP Nest leaders are OWASP members and adhere to the OWASP Code of Conduct.

Over time, OWASP Nest has expanded to address broader OWASP community needs, such as Google Summer of Code (GSoC) student guidance and contribution opportunities discovery. The platform, along with NestBot, has become a popular entry point for various OWASP aspects, including projects, chapters, users, and aggregated contribution opportunities -- with even more features planned. OWASP Nest&#039;s success is also the result of many valuable [contributions](https://github.com/OWASP/Nest/graphs/contributors) from the broader [OWASP Nest community](https://owasp.slack.com/archives/project-nest), whose efforts have helped shape and improve the project in countless ways.

**No other OWASP projects&#039; code was used in OWASP Nest&#039;s development.** While explicit attribution (other than per MIT license) is not required, contributors and other OWASP project leaders are welcome to provide it at their discretion.

### Community and Social Media

- [BlueSky account](https://bsky.app/profile/nest.owasp.org)
- [LinkedIn group](https://www.linkedin.com/groups/14656108/)
- [Slack channel](https://owasp.slack.com/archives/project-nest) (join [here](https://owasp.org/slack/invite))
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[QwenLM/Qwen-Image]]></title>
            <link>https://github.com/QwenLM/Qwen-Image</link>
            <guid>https://github.com/QwenLM/Qwen-Image</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:48 GMT</pubDate>
            <description><![CDATA[Qwen-Image is a powerful image generation foundation model capable of complex text rendering and precise image editing.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/QwenLM/Qwen-Image">QwenLM/Qwen-Image</a></h1>
            <p>Qwen-Image is a powerful image generation foundation model capable of complex text rendering and precise image editing.</p>
            <p>Language: Python</p>
            <p>Stars: 6,756</p>
            <p>Forks: 388</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/qwen_image_logo.png&quot; width=&quot;400&quot;/&gt;
&lt;p&gt; 
&lt;p align=&quot;center&quot;&gt;&amp;nbsp&amp;nbspüíú &lt;a href=&quot;https://chat.qwen.ai/&quot;&gt;Qwen Chat&lt;/a&gt;&amp;nbsp&amp;nbsp |
           &amp;nbsp&amp;nbspü§ó &lt;a href=&quot;https://huggingface.co/Qwen/Qwen-Image&quot;&gt;HuggingFace(T2I)&lt;/a&gt;&amp;nbsp&amp;nbsp |
           &amp;nbsp&amp;nbspü§ó &lt;a href=&quot;https://huggingface.co/Qwen/Qwen-Image-Edit-2511&quot;&gt;HuggingFace(Edit)&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspü§ñ &lt;a href=&quot;https://modelscope.cn/models/Qwen/Qwen-Image&quot;&gt;ModelScope-T2I&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspü§ñ &lt;a href=&quot;https://modelscope.cn/models/Qwen/Qwen-Image-Edit-2511&quot;&gt;ModelScope-Edit&lt;/a&gt;&amp;nbsp&amp;nbsp| &amp;nbsp&amp;nbsp üìë &lt;a href=&quot;https://arxiv.org/abs/2508.02324&quot;&gt;Tech Report&lt;/a&gt; &amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbsp üìë &lt;a href=&quot;https://qwenlm.github.io/blog/qwen-image/&quot;&gt;Blog(T2I)&lt;/a&gt; &amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbsp üìë &lt;a href=&quot;https://qwenlm.github.io/blog/qwen-image-edit-2511/&quot;&gt;Blog(Edit)&lt;/a&gt; &amp;nbsp&amp;nbsp 
&lt;br&gt;
üñ•Ô∏è &lt;a href=&quot;https://huggingface.co/spaces/Qwen/Qwen-Image&quot;&gt;T2I Demo&lt;/a&gt;&amp;nbsp&amp;nbsp | üñ•Ô∏è &lt;a href=&quot;https://huggingface.co/spaces/Qwen/Qwen-Image-Edit-2511&quot;&gt;Edit Demo&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspüí¨ &lt;a href=&quot;https://github.com/QwenLM/Qwen-Image/blob/main/assets/wechat.png&quot;&gt;WeChat (ÂæÆ‰ø°)&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspü´® &lt;a href=&quot;https://discord.gg/CV4E9rpNSD&quot;&gt;Discord&lt;/a&gt;&amp;nbsp&amp;nbsp
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/merge3.jpg&quot; width=&quot;1024&quot;/&gt;
&lt;p&gt;

## Introduction
We are thrilled to release **Qwen-Image**, a 20B MMDiT image foundation model that achieves significant advances in **complex text rendering** and **precise image editing**. Experiments show strong general capabilities in both image generation and editing, with exceptional performance in text rendering, especially for Chinese.


![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/bench.png#center)

## News
- 2025.12.31: We released Qwen-Image-2512 weights! Check at [Huggingface](https://huggingface.co/Qwen/Qwen-Image-2512) and [ModelScope](https://modelscope.cn/models/Qwen/Qwen-Image-2512)!
- 2025.12.31: We released Qwen-Image-2512! Check our [Blog](https://qwen.ai/blog?id=qwen-image-2512) for more details!
    üöÄ Our December upgrade to Qwen-Image, just in time for the New Year.

    ‚ú® What‚Äôs new:
    ‚Ä¢ More realistic humans ‚Äî dramatically reduced ‚ÄúAI look,‚Äù richer facial &amp; age details
    ‚Ä¢ Finer natural textures ‚Äî sharper landscapes, water, fur, and materials
    ‚Ä¢ Stronger text rendering ‚Äî better layout, higher accuracy in text‚Äìimage composition

    üèÜ Tested in 10,000+ blind rounds on AI Arena, Qwen-Image-2512 ranks as the strongest open-source image model, while staying competitive with closed-source systems.
    ![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/image2512/arena.png#center)
- 2025.12.31: [Qwen-Image-Lightning](https://github.com/ModelTC/Qwen-Image-Lightning), developed by [Lightx2v](https://github.com/ModelTC/LightX2V), provides [Day 0 acceleration support for Qwen-Image-2512](https://huggingface.co/lightx2v/Qwen-Image-2512-Lightning).
- 2025.12.31:vLLM-Omni supports high performance Qwen-Image-2512 inference from Day-0, with long sequence parallelism, cache acceleration and fast kernels, please check [here](https://github.com/vllm-project/vllm-omni/tree/main/examples/offline_inference/text_to_image) for details.
- 2025.12.23: We released Qwen-Image-Edit-2511 weights! Check at [Huggingface](https://huggingface.co/Qwen/Qwen-Image-Edit-2511) and [ModelScope](https://modelscope.cn/models/Qwen/Qwen-Image-Edit-2511)!
- 2025.12.23: We released Qwen-Image-Edit-2511! Check our [Blog](https://qwen.ai/blog?id=qwen-image-edit-2511) for more details!
- 2025.12.23: **[LightX2V](https://github.com/ModelTC/LightX2V/)** delivers Day 0 acceleration for Qwen-Image-Edit-2511, with native support for a wide range of hardware, including **NVIDIA, Hygon, Metax, Ascend, and Cambricon**. By combining **[diffusion distillation](https://github.com/ModelTC/Qwen-Image-Lightning)** with cutting-edge inference optimizations, LightX2V achieves a **25x reduction in DiT NFEs** and **an order-of-magnitude 42.55x overall speedup**, enabling real-time image editing across diverse AI accelerators.
- 2025.12.23: **vLLM-Omni** supports high performance `Qwen-Image-Edit-2511`, `Qwen-Image-Layered` inference from Day-0, with long sequence parallelism, cache acceleration and fast kernels, please check [here](https://github.com/vllm-project/vllm-omni/tree/main/examples/offline_inference/image_to_image) for details.

- 2025.12.23: **SGLang-Diffusion** provides day-0 support for Qwen-Image models. To play with `Qwen-Image-Edit-2511` in SGlang, please check community supports section for details.

- 2025.12.19: We released Qwen-Image-Layered weights! Check at [Huggingface](https://huggingface.co/Qwen/Qwen-Image-Layered) and [ModelScope](https://modelscope.cn/models/Qwen/Qwen-Image-Layered)!
- 2025.12.19: We released Qwen-Image-Layered! Check our [Blog](https://qwenlm.github.io/blog/qwen-image-layered) for more details!
- 2025.12.18: We released our [Research Paper](https://arxiv.org/abs/2512.15603) on Arxiv!
- 2025.11.11: **[T2I-CoreBench](https://t2i-corebench.github.io/)** offers a comprehensive and complex evaluation of T2I models in real-world scenarios. On this benchmark, Qwen-Image achieves state-of-the-art performance under real-world complexities in both composition and reasoning T2I tasks, surpassing other open-source models and showing comparable results to closed-source ones.
- 2025.11.07: LeMiCa is a diffusion model inference acceleration solution developed by China Unicom Data Science and Artificial Intelligence Research Institute. By leveraging cache-based techniques and global denoising path optimization, LeMiCa provides efficient inference support for Qwen-Image, achieving nearly 3x lossless acceleration while maintaining visual consistency and quality. For more details, please visit the homepage: [https://unicomai.github.io/LeMiCa/](https://unicomai.github.io/LeMiCa/)

- 2025.09.22: This September, we are pleased to introduce Qwen-Image-Edit-2509, the monthly iteration of Qwen-Image-Edit. To experience the latest model, please visit [Qwen Chat](https://qwen.ai)  and select the &quot;Image Editing&quot; feature. Compared with Qwen-Image-Edit released in August, the main improvements of Qwen-Image-Edit-2509 include:

- 2025.08.19: We have observed performance misalignments of Qwen-Image-Edit. To ensure optimal results, please update to the latest diffusers commit. Improvements are expected, especially in identity preservation and instruction following.
- 2025.08.18: We‚Äôre excited to announce the open-sourcing of Qwen-Image-Edit! üéâ Try it out in your local environment with the quick start guide below, or head over to [Qwen Chat](https://chat.qwen.ai/) or [Huggingface Demo](https://huggingface.co/spaces/Qwen/Qwen-Image-Edit) to experience the online demo right away! If you enjoy our work, please show your support by giving our repository a star. Your encouragement means a lot to us!
- 2025.08.09: Qwen-Image now supports a variety of LoRA models, such as MajicBeauty LoRA, enabling the generation of highly realistic beauty images. Check out the available weights on [ModelScope](https://modelscope.cn/models/merjic/majicbeauty-qwen1/summary).
![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/magicbeauty.png#center)
    
- 2025.08.05: Qwen-Image is now natively supported in ComfyUI, see [Qwen-Image in ComfyUI: New Era of Text Generation in Images!](https://blog.comfy.org/p/qwen-image-in-comfyui-new-era-of)
- 2025.08.05: Qwen-Image is now on Qwen Chat. Click [Qwen Chat](https://chat.qwen.ai/) and choose &quot;Image Generation&quot;.
- 2025.08.05: We released our [Technical Report](https://arxiv.org/abs/2508.02324) on Arxiv!
- 2025.08.04: We released Qwen-Image weights! Check at [Huggingface](https://huggingface.co/Qwen/Qwen-Image) and [ModelScope](https://modelscope.cn/models/Qwen/Qwen-Image)!
- 2025.08.04: We released Qwen-Image! Check our [Blog](https://qwenlm.github.io/blog/qwen-image) for more details!

&gt; [!NOTE]
&gt; Due to heavy traffic, if you&#039;d like to experience our demo online, we also recommend visiting DashScope, WaveSpeed, and LibLib. Please find the links below in the community support.

## Quick Start

1. Make sure your transformers&gt;=4.51.3 (Supporting Qwen2.5-VL)

2. Install the latest version of diffusers
```
pip install git+https://github.com/huggingface/diffusers
```

### Qwen-Image-2512 (for Text to Image generation, better character realism/texture quality)

We recommand use the latest prompt enhancing tools for Qwen-Image-2512, please check `src/examples/tools/prompt_utils_2512.py`

```python
from diffusers import QwenImagePipeline
import torch
# Load the pipeline
if torch.cuda.is_available():
    torch_dtype = torch.bfloat16
    device = &quot;cuda&quot;
else:
    torch_dtype = torch.float32
    device = &quot;cpu&quot;

pipe = QwenImagePipeline.from_pretrained(&quot;Qwen/Qwen-Image-2512&quot;, torch_dtype=torch_dtype).to(device)

# Generate image
prompt = &#039;&#039;&#039;A 20-year-old East Asian girl with delicate, charming features and large, bright brown eyes‚Äîexpressive and lively, with a cheerful or subtly smiling expression. Her naturally wavy long hair is either loose or tied in twin ponytails. She has fair skin and light makeup accentuating her youthful freshness. She wears a modern, cute dress or relaxed outfit in bright, soft colors‚Äîlightweight fabric, minimalist cut. She stands indoors at an anime convention, surrounded by banners, posters, or stalls. Lighting is typical indoor illumination‚Äîno staged lighting‚Äîand the image resembles a casual iPhone snapshot: unpretentious composition, yet brimming with vivid, fresh, youthful charm.&#039;&#039;&#039;

negative_prompt = &quot;‰ΩéÂàÜËæ®ÁéáÔºå‰ΩéÁîªË¥®ÔºåËÇ¢‰ΩìÁï∏ÂΩ¢ÔºåÊâãÊåáÁï∏ÂΩ¢ÔºåÁîªÈù¢ËøáÈ•±ÂíåÔºåËú°ÂÉèÊÑüÔºå‰∫∫ËÑ∏Êó†ÁªÜËäÇÔºåËøáÂ∫¶ÂÖâÊªëÔºåÁîªÈù¢ÂÖ∑ÊúâAIÊÑü„ÄÇÊûÑÂõæÊ∑∑‰π±„ÄÇÊñáÂ≠óÊ®°Á≥äÔºåÊâ≠Êõ≤„ÄÇ&quot;


# Generate with different aspect ratios
aspect_ratios = {
    &quot;1:1&quot;: (1328, 1328),
    &quot;16:9&quot;: (1664, 928),
    &quot;9:16&quot;: (928, 1664),
    &quot;4:3&quot;: (1472, 1104),
    &quot;3:4&quot;: (1104, 1472),
    &quot;3:2&quot;: (1584, 1056),
    &quot;2:3&quot;: (1056, 1584),
}

width, height = aspect_ratios[&quot;16:9&quot;]

image = pipe(
    prompt=prompt,
    negative_prompt=negative_prompt,
    width=width,
    height=height,
    num_inference_steps=50,
    true_cfg_scale=4.0,
    generator=torch.Generator(device=&quot;cuda&quot;).manual_seed(42)
).images[0]

image.save(&quot;example.png&quot;)

```


### Qwen-Image-Edit-2511 (for Image Editing, Multiple Image Support and Improved Consistency)

```python
import os
import torch
from PIL import Image
from diffusers import QwenImageEditPlusPipeline
from io import BytesIO
import requests

pipeline = QwenImageEditPlusPipeline.from_pretrained(&quot;Qwen/Qwen-Image-Edit-2511&quot;, torch_dtype=torch.bfloat16)
print(&quot;pipeline loaded&quot;)

pipeline.to(&#039;cuda&#039;)
pipeline.set_progress_bar_config(disable=None)
image1 = Image.open(BytesIO(requests.get(&quot;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/Qwen-Image/edit2511/edit2511input.png&quot;).content))
prompt = &quot;Ëøô‰∏™Â•≥ÁîüÁúãÁùÄÈù¢ÂâçÁöÑÁîµËßÜÂ±èÂπïÔºåÂ±èÂπï‰∏äÈù¢ÂÜôÁùÄ‚ÄúÈòøÈáåÂ∑¥Â∑¥‚Äù&quot;
inputs = {
    &quot;image&quot;: [image1],
    &quot;prompt&quot;: prompt,
    &quot;generator&quot;: torch.manual_seed(0),
    &quot;true_cfg_scale&quot;: 4.0,
    &quot;negative_prompt&quot;: &quot; &quot;,
    &quot;num_inference_steps&quot;: 40,
    &quot;guidance_scale&quot;: 1.0,
    &quot;num_images_per_prompt&quot;: 1,
}
with torch.inference_mode():
    output = pipeline(**inputs)
    output_image = output.images[0]
    output_image.save(&quot;output_image_edit_2511.png&quot;)
    print(&quot;image saved at&quot;, os.path.abspath(&quot;output_image_edit_2511.png&quot;))
```

&lt;details&gt;
&lt;summary&gt; Previous Version &lt;/summary&gt;

### Qwen-Image (for Text-to-Image)

The following contains a code snippet illustrating how to use the model to generate images based on text prompts:

```python
from diffusers import DiffusionPipeline
import torch

model_name = &quot;Qwen/Qwen-Image&quot;

# Load the pipeline
if torch.cuda.is_available():
    torch_dtype = torch.bfloat16
    device = &quot;cuda&quot;
else:
    torch_dtype = torch.float32
    device = &quot;cpu&quot;

pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch_dtype).to(device)

positive_magic = {
    &quot;en&quot;: &quot;, Ultra HD, 4K, cinematic composition.&quot;, # for english prompt
    &quot;zh&quot;: &quot;, Ë∂ÖÊ∏ÖÔºå4KÔºåÁîµÂΩ±Á∫ßÊûÑÂõæ.&quot; # for chinese prompt
}

# Generate image
prompt = &#039;&#039;&#039;A coffee shop entrance features a chalkboard sign reading &quot;Qwen Coffee üòä $2 per cup,&quot; with a neon light beside it displaying &quot;ÈÄö‰πâÂçÉÈóÆ&quot;. Next to it hangs a poster showing a beautiful Chinese woman, and beneath the poster is written &quot;œÄ‚âà3.1415926-53589793-23846264-33832795-02384197&quot;.&#039;&#039;&#039;

negative_prompt = &quot; &quot; # Recommended if you don&#039;t use a negative prompt.


# Generate with different aspect ratios
aspect_ratios = {
    &quot;1:1&quot;: (1328, 1328),
    &quot;16:9&quot;: (1664, 928),
    &quot;9:16&quot;: (928, 1664),
    &quot;4:3&quot;: (1472, 1104),
    &quot;3:4&quot;: (1104, 1472),
    &quot;3:2&quot;: (1584, 1056),
    &quot;2:3&quot;: (1056, 1584),
}

width, height = aspect_ratios[&quot;16:9&quot;]

image = pipe(
    prompt=prompt + positive_magic[&quot;en&quot;],
    negative_prompt=negative_prompt,
    width=width,
    height=height,
    num_inference_steps=50,
    true_cfg_scale=4.0,
    generator=torch.Generator(device=&quot;cuda&quot;).manual_seed(42)
).images[0]

image.save(&quot;example.png&quot;)
```

### Qwen-Image-Edit (for Image Editing, Only Support Single Image Input)
&gt; [!NOTE]
&gt; Qwen-Image-Edit-2509 has better consistency than Qwen-Image-Edit; it is recommended to use Qwen-Image-Edit-2509 directlyÔºåfor both single image input and multiple image inputs.


```python
import os
from PIL import Image
import torch

from diffusers import QwenImageEditPipeline

pipeline = QwenImageEditPipeline.from_pretrained(&quot;Qwen/Qwen-Image-Edit&quot;)
print(&quot;pipeline loaded&quot;)
pipeline.to(torch.bfloat16)
pipeline.to(&quot;cuda&quot;)
pipeline.set_progress_bar_config(disable=None)

image = Image.open(&quot;./input.png&quot;).convert(&quot;RGB&quot;)
prompt = &quot;Change the rabbit&#039;s color to purple, with a flash light background.&quot;


inputs = {
    &quot;image&quot;: image,
    &quot;prompt&quot;: prompt,
    &quot;generator&quot;: torch.manual_seed(0),
    &quot;true_cfg_scale&quot;: 4.0,
    &quot;negative_prompt&quot;: &quot; &quot;,
    &quot;num_inference_steps&quot;: 50,
}

with torch.inference_mode():
    output = pipeline(**inputs)
    output_image = output.images[0]
    output_image.save(&quot;output_image_edit.png&quot;)
    print(&quot;image saved at&quot;, os.path.abspath(&quot;output_image_edit.png&quot;))
```



&gt; [!NOTE]
&gt; We have observed that editing results may become unstable if prompt rewriting is not used. Therefore, we strongly recommend applying prompt rewriting to improve the stability of editing tasks. For reference, please see our official [demo script](src/examples/tools/prompt_utils.py) or Advanced Usage below, which includes example system prompts. Qwen-Image-Edit is actively evolving with ongoing development. Stay tuned for future enhancements!



### Qwen-Image-Edit-2509 (for Image Editing, Multiple Image Support and Improved Consistency)

```python
import os
import torch
from PIL import Image
from diffusers import QwenImageEditPlusPipeline
from io import BytesIO
import requests

pipeline = QwenImageEditPlusPipeline.from_pretrained(&quot;Qwen/Qwen-Image-Edit-2509&quot;, torch_dtype=torch.bfloat16)
print(&quot;pipeline loaded&quot;)

pipeline.to(&#039;cuda&#039;)
pipeline.set_progress_bar_config(disable=None)
image1 = Image.open(BytesIO(requests.get(&quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/edit2509/edit2509_1.jpg&quot;).content))
image2 = Image.open(BytesIO(requests.get(&quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/edit2509/edit2509_2.jpg&quot;).content))
prompt = &quot;The magician bear is on the left, the alchemist bear is on the right, facing each other in the central park square.&quot;
inputs = {
    &quot;image&quot;: [image1, image2],
    &quot;prompt&quot;: prompt,
    &quot;generator&quot;: torch.manual_seed(0),
    &quot;true_cfg_scale&quot;: 4.0,
    &quot;negative_prompt&quot;: &quot; &quot;,
    &quot;num_inference_steps&quot;: 40,
    &quot;guidance_scale&quot;: 1.0,
    &quot;num_images_per_prompt&quot;: 1,
}
with torch.inference_mode():
    output = pipeline(**inputs)
    output_image = output.images[0]
    output_image.save(&quot;output_image_edit_plus.png&quot;)
    print(&quot;image saved at&quot;, os.path.abspath(&quot;output_image_edit_plus.png&quot;))
```
&lt;/details&gt;

### Advanced Usage

#### Prompt Enhance for Text-to-Image
For enhanced prompt optimization and multi-language support, we recommend using our official Prompt Enhancement Tool powered by Qwen-Plus .

You can integrate it directly into your code:
```python
from tools.prompt_utils import rewrite
prompt = rewrite(prompt)
```

Alternatively, run the example script from the command line:

```bash
cd src
DASHSCOPE_API_KEY=sk-xxxxxxxxxxxxxxxxxxxx python examples/generate_w_prompt_enhance.py
```

#### Prompt Enhance for Image Edit
For enhanced stability, we recommend using our official Prompt Enhancement Tool powered by Qwen-VL-Max.

You can integrate it directly into your code:
```python
from tools.prompt_utils import polish_edit_prompt
prompt = polish_edit_prompt(prompt, pil_image)
```


## Deploy Qwen-Image

Qwen-Image supports Multi-GPU API Server for local deployment:

### Multi-GPU API Server Pipeline &amp; Usage

The Multi-GPU API Server will start a Gradio-based web interface with:
- Multi-GPU parallel processing
- Queue management for high concurrency
- Automatic prompt optimization
- Support for multiple aspect ratios

Configuration via environment variables:
```bash
export NUM_GPUS_TO_USE=4          # Number of GPUs to use
export TASK_QUEUE_SIZE=100        # Task queue size
export TASK_TIMEOUT=300           # Task timeout in seconds
```

```bash
# Start the gradio demo server, api key for prompt enhance
cd src
DASHSCOPE_API_KEY=sk-xxxxxxxxxxxxxxxxx python examples/demo.py 
```


## Showcase
For previous showcases, click the following links:
- [Qwen-Image](./Qwen-Image.md)
- [Qwen-Image-Edit](./Qwen-Image-Edit.md)
- [Qwen-Image-Edit-2509](./Qwen-Image-Edit-2509.md)

### Showcase of Qwen-Image-2512
**Enhanced Huamn Realism**

In Qwen-Image-2512, human depiction has been substantially refined. Compared to the August release, Qwen-Image-2512 adds significantly richer facial details and better environmental context. For example:


&gt; A Chinese female college student, around 20 years old, with a very short haircut that conveys a gentle, artistic vibe. Her hair naturally falls to partially cover her cheeks, projecting a tomboyish yet charming demeanor. She has cool-toned fair skin and delicate features, with a slightly shy yet subtly confident expression‚Äîher mouth crooked in a playful, youthful smirk. She wears an off-shoulder top, revealing one shoulder, with a well-proportioned figure. The image is framed as a close-up selfie: she dominates the foreground, while the background clearly shows her dormitory‚Äîa neatly made bed with white linens on the top bunk, a tidy study desk with organized stationery, and wooden cabinets and drawers. The photo is captured on a smartphone under soft, even ambient lighting, with natural tones, high clarity, and a bright, lively atmosphere full of youthful, everyday energy.

![](https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen-Image/image2512/ÂπªÁÅØÁâá1.JPG#center)

For the same prompt, Qwen-Image-2512 yields notably more lifelike facial features, and background objects‚Äîe.g., the desk, stationery, and bedding‚Äîare rendered with significantly greater clarity than in Qwen-Image.


&gt; A 20-year-old East Asian girl with delicate, charming features and large, bright brown eyes‚Äîexpressive and lively, with a cheerful or subtly smiling expression. Her naturally wavy long hair is either loose or tied in twin ponytails. She has fair skin and light makeup accentuating her youthful freshness. She wears a modern, cute dress or relaxed outfit in bright, soft colors‚Äîlightweight fabric, minimalist cut. She stands indoors at an anime convention, surrounded by banners, posters, o

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Project-MONAI/MONAI]]></title>
            <link>https://github.com/Project-MONAI/MONAI</link>
            <guid>https://github.com/Project-MONAI/MONAI</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:47 GMT</pubDate>
            <description><![CDATA[AI Toolkit for Healthcare Imaging]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Project-MONAI/MONAI">Project-MONAI/MONAI</a></h1>
            <p>AI Toolkit for Healthcare Imaging</p>
            <p>Language: Python</p>
            <p>Stars: 7,685</p>
            <p>Forks: 1,390</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/Project-MONAI/MONAI/dev/docs/images/MONAI-logo-color.png&quot; width=&quot;50%&quot; alt=&#039;project-monai&#039;&gt;
&lt;/p&gt;

**M**edical **O**pen **N**etwork for **AI**

![Supported Python versions](https://raw.githubusercontent.com/Project-MONAI/MONAI/dev/docs/images/python.svg)
[![License](https://img.shields.io/badge/license-Apache%202.0-green.svg)](https://opensource.org/licenses/Apache-2.0)
[![PyPI version](https://badge.fury.io/py/monai.svg)](https://badge.fury.io/py/monai)
[![docker](https://img.shields.io/badge/docker-pull-green.svg?logo=docker&amp;logoColor=white)](https://hub.docker.com/r/projectmonai/monai)
[![conda](https://img.shields.io/conda/vn/conda-forge/monai?color=green)](https://anaconda.org/conda-forge/monai)

[![premerge](https://github.com/Project-MONAI/MONAI/actions/workflows/pythonapp.yml/badge.svg?branch=dev)](https://github.com/Project-MONAI/MONAI/actions/workflows/pythonapp.yml)
[![postmerge](https://img.shields.io/github/checks-status/project-monai/monai/dev?label=postmerge)](https://github.com/Project-MONAI/MONAI/actions?query=branch%3Adev)
[![Documentation Status](https://readthedocs.org/projects/monai/badge/?version=latest)](https://docs.monai.io/en/latest/)
[![codecov](https://codecov.io/gh/Project-MONAI/MONAI/branch/dev/graph/badge.svg?token=6FTC7U1JJ4)](https://codecov.io/gh/Project-MONAI/MONAI)
[![monai Downloads Last Month](https://assets.piptrends.com/get-last-month-downloads-badge/monai.svg &#039;monai Downloads Last Month by pip Trends&#039;)](https://piptrends.com/package/monai)

MONAI is a [PyTorch](https://pytorch.org/)-based, [open-source](https://github.com/Project-MONAI/MONAI/blob/dev/LICENSE) framework for deep learning in healthcare imaging, part of the [PyTorch Ecosystem](https://pytorch.org/ecosystem/).
Its ambitions are as follows:

- Developing a community of academic, industrial and clinical researchers collaborating on a common foundation;
- Creating state-of-the-art, end-to-end training workflows for healthcare imaging;
- Providing researchers with the optimized and standardized way to create and evaluate deep learning models.

## Features

&gt; _Please see [the technical highlights](https://docs.monai.io/en/latest/highlights.html) and [What&#039;s New](https://docs.monai.io/en/latest/whatsnew.html) of the milestone releases._

- flexible pre-processing for multi-dimensional medical imaging data;
- compositional &amp; portable APIs for ease of integration in existing workflows;
- domain-specific implementations for networks, losses, evaluation metrics and more;
- customizable design for varying user expertise;
- multi-GPU multi-node data parallelism support.

## Requirements

MONAI works with the [currently supported versions of Python](https://devguide.python.org/versions), and depends directly on NumPy and PyTorch with many optional dependencies.

* Major releases of MONAI will have dependency versions stated for them. The current state of the `dev` branch in this repository is the unreleased development version of MONAI which typically will support current versions of dependencies and include updates and bug fixes to do so.
* PyTorch support covers [the current version](https://github.com/pytorch/pytorch/releases) plus three previous minor versions. If compatibility issues with a PyTorch version and other dependencies arise, support for a version may be delayed until a major release.
* Our support policy for other dependencies adheres for the most part to [SPEC0](https://scientific-python.org/specs/spec-0000), where dependency versions are supported where possible for up to two years. Discovered vulnerabilities or defects may require certain versions to be explicitly not supported.
* See the `requirements*.txt` files for dependency version information.

## Installation

To install [the current release](https://pypi.org/project/monai/), you can simply run:

```bash
pip install monai
```

Please refer to [the installation guide](https://docs.monai.io/en/latest/installation.html) for other installation options.

## Getting Started

[MedNIST demo](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/2d_classification/mednist_tutorial.ipynb) and [MONAI for PyTorch Users](https://colab.research.google.com/github/Project-MONAI/tutorials/blob/main/modules/developer_guide.ipynb) are available on Colab.

Examples and notebook tutorials are located at [Project-MONAI/tutorials](https://github.com/Project-MONAI/tutorials).

Technical documentation is available at [docs.monai.io](https://docs.monai.io).

## Citation

If you have used MONAI in your research, please cite us! The citation can be exported from: &lt;https://arxiv.org/abs/2211.02701&gt;.

## Model Zoo

[The MONAI Model Zoo](https://github.com/Project-MONAI/model-zoo) is a place for researchers and data scientists to share the latest and great models from the community.
Utilizing [the MONAI Bundle format](https://docs.monai.io/en/latest/bundle_intro.html) makes it easy to [get started](https://github.com/Project-MONAI/tutorials/tree/main/model_zoo) building workflows with MONAI.

## Contributing

For guidance on making a contribution to MONAI, see the [contributing guidelines](https://github.com/Project-MONAI/MONAI/blob/dev/CONTRIBUTING.md).

## Community

Join the conversation on Twitter/X [@ProjectMONAI](https://twitter.com/ProjectMONAI), [LinkedIn](https://www.linkedin.com/company/projectmonai), or join our [Slack channel](https://forms.gle/QTxJq3hFictp31UM9).

Ask and answer questions over on [MONAI&#039;s GitHub Discussions tab](https://github.com/Project-MONAI/MONAI/discussions).

## Links

- Website: &lt;https://monai.io/&gt;
- API documentation (milestone): &lt;https://docs.monai.io/&gt;
- API documentation (latest dev): &lt;https://docs.monai.io/en/latest/&gt;
- Code: &lt;https://github.com/Project-MONAI/MONAI&gt;
- Project tracker: &lt;https://github.com/Project-MONAI/MONAI/projects&gt;
- Issue tracker: &lt;https://github.com/Project-MONAI/MONAI/issues&gt;
- Wiki: &lt;https://github.com/Project-MONAI/MONAI/wiki&gt;
- Test status: &lt;https://github.com/Project-MONAI/MONAI/actions&gt;
- PyPI package: &lt;https://pypi.org/project/monai/&gt;
- conda-forge: &lt;https://anaconda.org/conda-forge/monai&gt;
- Weekly previews: &lt;https://pypi.org/project/monai-weekly/&gt;
- Docker Hub: &lt;https://hub.docker.com/r/projectmonai/monai&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[absadiki/whatsapp-msgstore-viewer]]></title>
            <link>https://github.com/absadiki/whatsapp-msgstore-viewer</link>
            <guid>https://github.com/absadiki/whatsapp-msgstore-viewer</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:46 GMT</pubDate>
            <description><![CDATA[Free, open source and cross-platform app to decrypt, read and view the Whatsapp msgstore.db database]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/absadiki/whatsapp-msgstore-viewer">absadiki/whatsapp-msgstore-viewer</a></h1>
            <p>Free, open source and cross-platform app to decrypt, read and view the Whatsapp msgstore.db database</p>
            <p>Language: Python</p>
            <p>Stars: 516</p>
            <p>Forks: 93</p>
            <p>Stars today: 48 stars today</p>
            <h2>README</h2><pre># whatsapp Msgstore Viewer
Free, open source and cross-platform app to decrypt, read and view the Whatsapp `msgstore.db` database.
&lt;br/&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./assets/demo/demo_gif_2.gif&quot;&gt;
&lt;/p&gt;

# Features
* View contact and group chats.
* View call logs with their durations.
* Easy access to media files (images, audio, and video) from within the chat, if the local WhatsApp directory has been provided.
* Decrypt and view the database if you have the decryption `key` (Should support **crypt12**, **crypt14**, and **crypt15**).
* Cross-platform (Should work on Linux, Windows, and Mac)


# Installation
### Prerequisites
- Python 3.9 or later
```bash
git clone https://github.com/absadiki/whatsapp-msgstore-viewer
cd whatsapp-msgstore-viewer
pip install -e .
```

### Run
```bash
wmv
```

&gt; **Note for Ubuntu users:** Additional system dependencies might be needed. See [#19](https://github.com/absadiki/whatsapp-msgstore-viewer/issues/19) for details.

# Usage
To use the app, you will need:
* The `msgstore.db` (`msgstore.db.cryptX` if it is encrypted) database: It is a database where Whatsapp is storing all your messages.
* The `wa.db` database: It is a database where Whatsapp is storing contact names. It is optional, so if it is not provided you will just see phone numbers.
* The `WhatsApp directory`: The directory of WhatsApp in the local storage of your phone. This will be used to view the media files (Optional as well).
* The `key`: If your database is encrypted, you will need to provide the decryption key to decrypt it. The decrypted database will be stored in the same directory as your encrypted database with a `-decrypted.db` suffix.
  (See below for more information).

# Notes
#### Where to find the databases
Check out the great tutorial &quot;[Retrieving WhatsApp Databases](https://github.com/Dexter2389/whatsapp-backup-chat-viewer#retrieving-whatsapp-databases)&quot; by [@Dexter2389](https://github.com/Dexter2389).

#### About the decryption process
The app uses the [WhatsApp-Crypt14-Crypt15-Decrypter](https://github.com/ElDavoo/WhatsApp-Crypt14-Crypt15-Decrypter) by [ElDavoo](https://github.com/ElDavoo) under the hood.
Please check their repository if you face any issues with the decryption.

#### About the Database schema
This app is a reverse engineering attempt of the WhatsApp database and has been tested with my personal `msgstore.db` file. It might break if there are any updates to the `msgstore` database schema.

I&#039;ve made it easy to add support for more schemas (It&#039;s a simple SQLite exercise :D).

All contributions are welcome.

Follow these steps to add support for other schemas (see `db/v1/db.py` as an example):
* Create a package in the `dbs` package and give your schema a name (for example `v2`).
* Inside the newly created package, create a Python module `db.py`.
* Inherit the abstract class `AbstractDatabase` located in the `dbs/abstract_db.py` module.
* The app will dynamically load existing schemas when starting.
* Submit a pull request.

#### About different languages

  - You might encounter an issue where messages are displayed incorrectly (as square characters).
  This is likely a font issue. To resolve this, find a font that supports your language and specify its path in the `advanced settings` on the login screen.
  - For RTL languages, please see [RTL Support #8](https://github.com/absadiki/whatsapp-msgstore-viewer/discussions/8)

# Contributing
If you find a bug, have a suggestion or feedback, please open an issue for discussion.


# License

This project is licensed under the GNU General Public License version 3 or later. You can modify or redistribute it under the conditions
of these licenses (See [LICENSE](./LICENSE) for more information).

# DISCLAIMER
This project is not endorsed or certified by WhatsApp Inc. and is meant for **personal and educational purposes only**.

It is provided &#039;as is&#039; without any express or implied warranties.

The authors, maintainers, and contributors assume no responsibility for errors, omissions, or damages resulting from the use of this information.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[livekit/agents]]></title>
            <link>https://github.com/livekit/agents</link>
            <guid>https://github.com/livekit/agents</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:45 GMT</pubDate>
            <description><![CDATA[A powerful framework for building realtime voice AI agents ü§ñüéôÔ∏èüìπ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/livekit/agents">livekit/agents</a></h1>
            <p>A powerful framework for building realtime voice AI agents ü§ñüéôÔ∏èüìπ</p>
            <p>Language: Python</p>
            <p>Stars: 8,917</p>
            <p>Forks: 2,329</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre>&lt;!--BEGIN_BANNER_IMAGE--&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;/.github/banner_dark.png&quot;&gt;
  &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;/.github/banner_light.png&quot;&gt;
  &lt;img style=&quot;width:100%;&quot; alt=&quot;The LiveKit icon, the name of the repository and some sample code in the background.&quot; src=&quot;https://raw.githubusercontent.com/livekit/agents/main/.github/banner_light.png&quot;&gt;
&lt;/picture&gt;

&lt;!--END_BANNER_IMAGE--&gt;
&lt;br /&gt;

![PyPI - Version](https://img.shields.io/pypi/v/livekit-agents)
[![PyPI Downloads](https://static.pepy.tech/badge/livekit-agents/month)](https://pepy.tech/projects/livekit-agents)
[![Slack community](https://img.shields.io/endpoint?url=https%3A%2F%2Flivekit.io%2Fbadges%2Fslack)](https://livekit.io/join-slack)
[![Twitter Follow](https://img.shields.io/twitter/follow/livekit)](https://twitter.com/livekit)
[![Ask DeepWiki for understanding the codebase](https://deepwiki.com/badge.svg)](https://deepwiki.com/livekit/agents)
[![License](https://img.shields.io/github/license/livekit/livekit)](https://github.com/livekit/livekit/blob/master/LICENSE)

&lt;br /&gt;

Looking for the JS/TS library? Check out [AgentsJS](https://github.com/livekit/agents-js)

## What is Agents?

&lt;!--BEGIN_DESCRIPTION--&gt;

The Agent Framework is designed for building realtime, programmable participants
that run on servers. Use it to create conversational, multi-modal voice
agents that can see, hear, and understand.

&lt;!--END_DESCRIPTION--&gt;

## Features

- **Flexible integrations**: A comprehensive ecosystem to mix and match the right STT, LLM, TTS, and Realtime API to suit your use case.
- **Integrated job scheduling**: Built-in task scheduling and distribution with [dispatch APIs](https://docs.livekit.io/agents/build/dispatch/) to connect end users to agents.
- **Extensive WebRTC clients**: Build client applications using LiveKit&#039;s open-source SDK ecosystem, supporting all major platforms.
- **Telephony integration**: Works seamlessly with LiveKit&#039;s [telephony stack](https://docs.livekit.io/sip/), allowing your agent to make calls to or receive calls from phones.
- **Exchange data with clients**: Use [RPCs](https://docs.livekit.io/home/client/data/rpc/) and other [Data APIs](https://docs.livekit.io/home/client/data/) to seamlessly exchange data with clients.
- **Semantic turn detection**: Uses a transformer model to detect when a user is done with their turn, helps to reduce interruptions.
- **MCP support**: Native support for MCP. Integrate tools provided by MCP servers with one loc.
- **Builtin test framework**: Write tests and use judges to ensure your agent is performing as expected.
- **Open-source**: Fully open-source, allowing you to run the entire stack on your own servers, including [LiveKit server](https://github.com/livekit/livekit), one of the most widely used WebRTC media servers.

## Installation

To install the core Agents library, along with plugins for popular model providers:

```bash
pip install &quot;livekit-agents[openai,silero,deepgram,cartesia,turn-detector]~=1.0&quot;
```

## Docs and guides

Documentation on the framework and how to use it can be found [here](https://docs.livekit.io/agents/)

## Core concepts

- Agent: An LLM-based application with defined instructions.
- AgentSession: A container for agents that manages interactions with end users.
- entrypoint: The starting point for an interactive session, similar to a request handler in a web server.
- Worker: The main process that coordinates job scheduling and launches agents for user sessions.

## Usage

### Simple voice agent

---

```python
from livekit.agents import (
    Agent,
    AgentSession,
    JobContext,
    RunContext,
    WorkerOptions,
    cli,
    function_tool,
)
from livekit.plugins import silero

@function_tool
async def lookup_weather(
    context: RunContext,
    location: str,
):
    &quot;&quot;&quot;Used to look up weather information.&quot;&quot;&quot;

    return {&quot;weather&quot;: &quot;sunny&quot;, &quot;temperature&quot;: 70}


async def entrypoint(ctx: JobContext):
    await ctx.connect()

    agent = Agent(
        instructions=&quot;You are a friendly voice assistant built by LiveKit.&quot;,
        tools=[lookup_weather],
    )
    session = AgentSession(
        vad=silero.VAD.load(),
        # any combination of STT, LLM, TTS, or realtime API can be used
        stt=&quot;assemblyai/universal-streaming:en&quot;,
        llm=&quot;openai/gpt-4.1-mini&quot;,
        tts=&quot;cartesia/sonic-2:9626c31c-bec5-4cca-baa8-f8ba9e84c8bc&quot;,
    )

    await session.start(agent=agent, room=ctx.room)
    await session.generate_reply(instructions=&quot;greet the user and ask about their day&quot;)


if __name__ == &quot;__main__&quot;:
    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))
```

You&#039;ll need the following environment variables for this example:

- DEEPGRAM_API_KEY
- OPENAI_API_KEY
- ELEVEN_API_KEY

### Multi-agent handoff

---

This code snippet is abbreviated. For the full example, see [multi_agent.py](examples/voice_agents/multi_agent.py)

```python
...
class IntroAgent(Agent):
    def __init__(self) -&gt; None:
        super().__init__(
            instructions=f&quot;You are a story teller. Your goal is to gather a few pieces of information from the user to make the story personalized and engaging.&quot;
            &quot;Ask the user for their name and where they are from&quot;
        )

    async def on_enter(self):
        self.session.generate_reply(instructions=&quot;greet the user and gather information&quot;)

    @function_tool
    async def information_gathered(
        self,
        context: RunContext,
        name: str,
        location: str,
    ):
        &quot;&quot;&quot;Called when the user has provided the information needed to make the story personalized and engaging.

        Args:
            name: The name of the user
            location: The location of the user
        &quot;&quot;&quot;

        context.userdata.name = name
        context.userdata.location = location

        story_agent = StoryAgent(name, location)
        return story_agent, &quot;Let&#039;s start the story!&quot;


class StoryAgent(Agent):
    def __init__(self, name: str, location: str) -&gt; None:
        super().__init__(
            instructions=f&quot;You are a storyteller. Use the user&#039;s information in order to make the story personalized.&quot;
            f&quot;The user&#039;s name is {name}, from {location}&quot;
            # override the default model, switching to Realtime API from standard LLMs
            llm=openai.realtime.RealtimeModel(voice=&quot;echo&quot;),
            chat_ctx=chat_ctx,
        )

    async def on_enter(self):
        self.session.generate_reply()


async def entrypoint(ctx: JobContext):
    await ctx.connect()

    userdata = StoryData()
    session = AgentSession[StoryData](
        vad=silero.VAD.load(),
        stt=&quot;deepgram/nova-3&quot;,
        llm=&quot;openai/gpt-4o&quot;,
        tts=&quot;cartesia/sonic-2:9626c31c-bec5-4cca-baa8-f8ba9e84c8bc&quot;,
        userdata=userdata,
    )

    await session.start(
        agent=IntroAgent(),
        room=ctx.room,
    )
...
```

### Testing

Automated tests are essential for building reliable agents, especially with the non-deterministic behavior of LLMs. LiveKit Agents include native test integration to help you create dependable agents.

```python
@pytest.mark.asyncio
async def test_no_availability() -&gt; None:
    llm = google.LLM()
    async AgentSession(llm=llm) as sess:
        await sess.start(MyAgent())
        result = await sess.run(
            user_input=&quot;Hello, I need to place an order.&quot;
        )
        result.expect.skip_next_event_if(type=&quot;message&quot;, role=&quot;assistant&quot;)
        result.expect.next_event().is_function_call(name=&quot;start_order&quot;)
        result.expect.next_event().is_function_call_output()
        await (
            result.expect.next_event()
            .is_message(role=&quot;assistant&quot;)
            .judge(llm, intent=&quot;assistant should be asking the user what they would like&quot;)
        )

```

## Examples

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üéôÔ∏è Starter Agent&lt;/h3&gt;
&lt;p&gt;A starter agent optimized for voice conversations.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;examples/voice_agents/basic_agent.py&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üîÑ Multi-user push to talk&lt;/h3&gt;
&lt;p&gt;Responds to multiple users in the room via push-to-talk.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;examples/voice_agents/push_to_talk.py&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üéµ Background audio&lt;/h3&gt;
&lt;p&gt;Background ambient and thinking audio to improve realism.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;examples/voice_agents/background_audio.py&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üõ†Ô∏è Dynamic tool creation&lt;/h3&gt;
&lt;p&gt;Creating function tools dynamically.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;examples/voice_agents/dynamic_tool_creation.py&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;‚òéÔ∏è Outbound caller&lt;/h3&gt;
&lt;p&gt;Agent that makes outbound phone calls&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://github.com/livekit-examples/outbound-caller-python&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üìã Structured output&lt;/h3&gt;
&lt;p&gt;Using structured output from LLM to guide TTS tone.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;examples/voice_agents/structured_output.py&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üîå MCP support&lt;/h3&gt;
&lt;p&gt;Use tools from MCP servers&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;examples/voice_agents/mcp&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üí¨ Text-only agent&lt;/h3&gt;
&lt;p&gt;Skip voice altogether and use the same code for text-only integrations&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;examples/other/text_only.py&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üìù Multi-user transcriber&lt;/h3&gt;
&lt;p&gt;Produce transcriptions from all users in the room&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;examples/other/transcription/multi-user-transcriber.py&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üé• Video avatars&lt;/h3&gt;
&lt;p&gt;Add an AI avatar with Tavus, Beyond Presence, and Bithuman&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;examples/avatar_agents/&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üçΩÔ∏è Restaurant ordering and reservations&lt;/h3&gt;
&lt;p&gt;Full example of an agent that handles calls for a restaurant.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;examples/voice_agents/restaurant_agent.py&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üëÅÔ∏è Gemini Live vision&lt;/h3&gt;
&lt;p&gt;Full example (including iOS app) of Gemini Live agent that can see.&lt;/p&gt;
&lt;p&gt;
&lt;a href=&quot;https://github.com/livekit-examples/vision-demo&quot;&gt;Code&lt;/a&gt;
&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;

&lt;/table&gt;

## Running your agent

### Testing in terminal

```shell
python myagent.py console
```

Runs your agent in terminal mode, enabling local audio input and output for testing.
This mode doesn&#039;t require external servers or dependencies and is useful for quickly validating behavior.

### Developing with LiveKit clients

```shell
python myagent.py dev
```

Starts the agent server and enables hot reloading when files change. This mode allows each process to host multiple concurrent agents efficiently.

The agent connects to LiveKit Cloud or your self-hosted server. Set the following environment variables:
- LIVEKIT_URL
- LIVEKIT_API_KEY
- LIVEKIT_API_SECRET

You can connect using any LiveKit client SDK or telephony integration.
To get started quickly, try the [Agents Playground](https://agents-playground.livekit.io/).

### Running for production

```shell
python myagent.py start
```

Runs the agent with production-ready optimizations.

## Contributing

The Agents framework is under active development in a rapidly evolving field. We welcome and appreciate contributions of any kind, be it feedback, bugfixes, features, new plugins and tools, or better documentation. You can file issues under this repo, open a PR, or chat with us in LiveKit&#039;s [Slack community](https://livekit.io/join-slack).

&lt;!--BEGIN_REPO_NAV--&gt;
&lt;br/&gt;&lt;table&gt;
&lt;thead&gt;&lt;tr&gt;&lt;th colspan=&quot;2&quot;&gt;LiveKit Ecosystem&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td&gt;LiveKit SDKs&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/client-sdk-js&quot;&gt;Browser&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-swift&quot;&gt;iOS/macOS/visionOS&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-android&quot;&gt;Android&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-flutter&quot;&gt;Flutter&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-react-native&quot;&gt;React Native&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/rust-sdks&quot;&gt;Rust&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/node-sdks&quot;&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/python-sdks&quot;&gt;Python&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-unity&quot;&gt;Unity&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-unity-web&quot;&gt;Unity (WebGL)&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/client-sdk-esp32&quot;&gt;ESP32&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Server APIs&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/node-sdks&quot;&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/server-sdk-go&quot;&gt;Golang&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/server-sdk-ruby&quot;&gt;Ruby&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/server-sdk-kotlin&quot;&gt;Java/Kotlin&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/python-sdks&quot;&gt;Python&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/rust-sdks&quot;&gt;Rust&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/agence104/livekit-server-sdk-php&quot;&gt;PHP (community)&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/pabloFuente/livekit-server-sdk-dotnet&quot;&gt;.NET (community)&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;UI Components&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/components-js&quot;&gt;React&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/components-android&quot;&gt;Android Compose&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/components-swift&quot;&gt;SwiftUI&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/components-flutter&quot;&gt;Flutter&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Agents Frameworks&lt;/td&gt;&lt;td&gt;&lt;b&gt;Python&lt;/b&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/agents-js&quot;&gt;Node.js&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/agent-playground&quot;&gt;Playground&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Services&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://github.com/livekit/livekit&quot;&gt;LiveKit server&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/egress&quot;&gt;Egress&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/ingress&quot;&gt;Ingress&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/sip&quot;&gt;SIP&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td&gt;Resources&lt;/td&gt;&lt;td&gt;&lt;a href=&quot;https://docs.livekit.io&quot;&gt;Docs&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit-examples&quot;&gt;Example apps&lt;/a&gt; ¬∑ &lt;a href=&quot;https://livekit.io/cloud&quot;&gt;Cloud&lt;/a&gt; ¬∑ &lt;a href=&quot;https://docs.livekit.io/home/self-hosting/deployment&quot;&gt;Self-hosting&lt;/a&gt; ¬∑ &lt;a href=&quot;https://github.com/livekit/livekit-cli&quot;&gt;CLI&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;!--END_REPO_NAV--&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[google-research/timesfm]]></title>
            <link>https://github.com/google-research/timesfm</link>
            <guid>https://github.com/google-research/timesfm</guid>
            <pubDate>Sun, 04 Jan 2026 00:05:44 GMT</pubDate>
            <description><![CDATA[TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/google-research/timesfm">google-research/timesfm</a></h1>
            <p>TimesFM (Time Series Foundation Model) is a pretrained time-series foundation model developed by Google Research for time-series forecasting.</p>
            <p>Language: Python</p>
            <p>Stars: 7,478</p>
            <p>Forks: 661</p>
            <p>Stars today: 47 stars today</p>
            <h2>README</h2><pre># TimesFM

TimesFM (Time Series Foundation Model) is a pretrained time-series foundation
model developed by Google Research for time-series forecasting.

*   Paper:
    [A decoder-only foundation model for time-series forecasting](https://arxiv.org/abs/2310.10688),
    ICML 2024.
*   All checkpoints:
    [TimesFM Hugging Face Collection](https://huggingface.co/collections/google/timesfm-release-66e4be5fdb56e960c1e482a6).
*   [Google Research blog](https://research.google/blog/a-decoder-only-foundation-model-for-time-series-forecasting/).
*   [TimesFM in BigQuery](https://cloud.google.com/bigquery/docs/timesfm-model):
    an official Google product.

This open version is not an officially supported Google product.

**Latest Model Version:** TimesFM 2.5

**Archived Model Versions:**

-   1.0 and 2.0: relevant code archived in the sub directory `v1`. You can `pip
    install timesfm==1.3.0` to install an older version of this package to load
    them.

## Update - Oct. 29, 2025

Added back the covariate support through XReg for TimesFM 2.5.


## Update - Sept. 15, 2025

TimesFM 2.5 is out!

Comparing to TimesFM 2.0, this new 2.5 model:

-   uses 200M parameters, down from 500M.
-   supports up to 16k context length, up from 2048.
-   supports continuous quantile forecast up to 1k horizon via an optional 30M
    quantile head.
-   gets rid of the `frequency` indicator.
-   has a couple of new forecasting flags.

Along with the model upgrade we have also upgraded the inference API. This repo
will be under construction over the next few weeks to

1.  add support for an upcoming Flax version of the model (faster inference).
2.  add back covariate support.
3.  populate more docstrings, docs and notebook.

### Install

1.  Clone the repository:
    ```shell
    git clone https://github.com/google-research/timesfm.git
    cd timesfm
    ```

2.  Create a virtual environment and install dependencies using `uv`:
    ```shell
    # Create a virtual environment
    uv venv
    
    # Activate the environment
    source .venv/bin/activate
    
    # Install the package in editable mode with torch
    uv pip install -e .[torch]
    # Or with flax
    uv pip install -e .[flax]
    # Or XReg is needed
    uv pip install -e .[xreg]
    ```

3. [Optional] Install your preferred `torch` / `jax` backend based on your OS and accelerators
(CPU, GPU, TPU or Apple Silicon).:

-   [Install PyTorch](https://pytorch.org/get-started/locally/).
-   [Install Jax](https://docs.jax.dev/en/latest/installation.html#installation)
    for Flax.

### Code Example

```python
import torch
import numpy as np
import timesfm

torch.set_float32_matmul_precision(&quot;high&quot;)

model = timesfm.TimesFM_2p5_200M_torch.from_pretrained(&quot;google/timesfm-2.5-200m-pytorch&quot;)

model.compile(
    timesfm.ForecastConfig(
        max_context=1024,
        max_horizon=256,
        normalize_inputs=True,
        use_continuous_quantile_head=True,
        force_flip_invariance=True,
        infer_is_positive=True,
        fix_quantile_crossing=True,
    )
)
point_forecast, quantile_forecast = model.forecast(
    horizon=12,
    inputs=[
        np.linspace(0, 1, 100),
        np.sin(np.linspace(0, 20, 67)),
    ],  # Two dummy inputs
)
point_forecast.shape  # (2, 12)
quantile_forecast.shape  # (2, 12, 10): mean, then 10th to 90th quantiles.
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>