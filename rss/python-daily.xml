<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Thu, 26 Feb 2026 00:07:25 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[D4Vinci/Scrapling]]></title>
            <link>https://github.com/D4Vinci/Scrapling</link>
            <guid>https://github.com/D4Vinci/Scrapling</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:25 GMT</pubDate>
            <description><![CDATA[üï∑Ô∏è An adaptive Web Scraping framework that handles everything from a single request to a full-scale crawl!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/D4Vinci/Scrapling">D4Vinci/Scrapling</a></h1>
            <p>üï∑Ô∏è An adaptive Web Scraping framework that handles everything from a single request to a full-scale crawl!</p>
            <p>Language: Python</p>
            <p>Stars: 14,940</p>
            <p>Forks: 984</p>
            <p>Stars today: 1,656 stars today</p>
            <h2>README</h2><pre>&lt;!-- mcp-name: io.github.D4Vinci/Scrapling --&gt;

&lt;h1 align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://scrapling.readthedocs.io&quot;&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/docs/assets/cover_dark.svg?sanitize=true&quot;&gt;
          &lt;img alt=&quot;Scrapling Poster&quot; src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/docs/assets/cover_light.svg?sanitize=true&quot;&gt;
        &lt;/picture&gt;
    &lt;/a&gt;
    &lt;br&gt;
    &lt;small&gt;Effortless Web Scraping for the Modern Web&lt;/small&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/14244&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14244&quot; alt=&quot;D4Vinci%2FScrapling | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
    &lt;br/&gt;
    &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_AR.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®ŸäŸá&lt;/a&gt; | &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_ES.md&quot;&gt;Espa√±ol&lt;/a&gt; | &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_DE.md&quot;&gt;Deutsch&lt;/a&gt; | &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_CN.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; |  &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;
    &lt;br/&gt;
    &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/actions/workflows/tests.yml&quot; alt=&quot;Tests&quot;&gt;
        &lt;img alt=&quot;Tests&quot; src=&quot;https://github.com/D4Vinci/Scrapling/actions/workflows/tests.yml/badge.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://badge.fury.io/py/Scrapling&quot; alt=&quot;PyPI version&quot;&gt;
        &lt;img alt=&quot;PyPI version&quot; src=&quot;https://badge.fury.io/py/Scrapling.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://pepy.tech/project/scrapling&quot; alt=&quot;PyPI Downloads&quot;&gt;
        &lt;img alt=&quot;PyPI Downloads&quot; src=&quot;https://static.pepy.tech/personalized-badge/scrapling?period=total&amp;units=INTERNATIONAL_SYSTEM&amp;left_color=GREY&amp;right_color=GREEN&amp;left_text=Downloads&quot;&gt;&lt;/a&gt;
    &lt;br/&gt;
    &lt;a href=&quot;https://discord.gg/EMgGbDceNQ&quot; alt=&quot;Discord&quot; target=&quot;_blank&quot;&gt;
      &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1360786381042880532?style=social&amp;logo=discord&amp;link=https%3A%2F%2Fdiscord.gg%2FEMgGbDceNQ&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://x.com/Scrapling_dev&quot; alt=&quot;X (formerly Twitter)&quot;&gt;
      &lt;img alt=&quot;X (formerly Twitter) Follow&quot; src=&quot;https://img.shields.io/twitter/follow/Scrapling_dev?style=social&amp;logo=x&amp;link=https%3A%2F%2Fx.com%2FScrapling_dev&quot;&gt;
    &lt;/a&gt;
    &lt;br/&gt;
    &lt;a href=&quot;https://pypi.org/project/scrapling/&quot; alt=&quot;Supported Python versions&quot;&gt;
        &lt;img alt=&quot;Supported Python versions&quot; src=&quot;https://img.shields.io/pypi/pyversions/scrapling.svg&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/parsing/selection/&quot;&gt;&lt;strong&gt;Selection methods&lt;/strong&gt;&lt;/a&gt;
    &amp;middot;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/fetching/choosing/&quot;&gt;&lt;strong&gt;Fetchers&lt;/strong&gt;&lt;/a&gt;
    &amp;middot;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/spiders/architecture.html&quot;&gt;&lt;strong&gt;Spiders&lt;/strong&gt;&lt;/a&gt;
    &amp;middot;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/spiders/proxy-blocking.html&quot;&gt;&lt;strong&gt;Proxy Rotation&lt;/strong&gt;&lt;/a&gt;
    &amp;middot;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/cli/overview/&quot;&gt;&lt;strong&gt;CLI&lt;/strong&gt;&lt;/a&gt;
    &amp;middot;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/ai/mcp-server/&quot;&gt;&lt;strong&gt;MCP&lt;/strong&gt;&lt;/a&gt;
&lt;/p&gt;

Scrapling is an adaptive Web Scraping framework that handles everything from a single request to a full-scale crawl.

Its parser learns from website changes and automatically relocates your elements when pages update. Its fetchers bypass anti-bot systems like Cloudflare Turnstile out of the box. And its spider framework lets you scale up to concurrent, multi-session crawls with pause/resume and automatic proxy rotation ‚Äî all in a few lines of Python. One library, zero compromises.

Blazing fast crawls with real-time stats and streaming. Built by Web Scrapers for Web Scrapers and regular users, there&#039;s something for everyone.

```python
from scrapling.fetchers import Fetcher, AsyncFetcher, StealthyFetcher, DynamicFetcher
StealthyFetcher.adaptive = True
p = StealthyFetcher.fetch(&#039;https://example.com&#039;, headless=True, network_idle=True)  # Fetch website under the radar!
products = p.css(&#039;.product&#039;, auto_save=True)                                        # Scrape data that survives website design changes!
products = p.css(&#039;.product&#039;, adaptive=True)                                         # Later, if the website structure changes, pass `adaptive=True` to find them!
```
Or scale up to full crawls
```python
from scrapling.spiders import Spider, Response

class MySpider(Spider):
  name = &quot;demo&quot;
  start_urls = [&quot;https://example.com/&quot;]

  async def parse(self, response: Response):
      for item in response.css(&#039;.product&#039;):
          yield {&quot;title&quot;: item.css(&#039;h2::text&#039;).get()}

MySpider().start()
```

# Platinum Sponsors

# Sponsors 

&lt;!-- sponsors --&gt;

&lt;a href=&quot;https://www.scrapeless.com/en?utm_source=official&amp;utm_term=scrapling&quot; target=&quot;_blank&quot; title=&quot;Effortless Web Scraping Toolkit for Business and Developers&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/scrapeless.jpg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://www.thordata.com/?ls=github&amp;lk=github&quot; target=&quot;_blank&quot; title=&quot;Unblockable proxies and scraping infrastructure, delivering real-time, reliable web data to power AI models and workflows.&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/thordata.jpg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://evomi.com?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=d4vinci-scrapling&quot; target=&quot;_blank&quot; title=&quot;Evomi is your Swiss Quality Proxy Provider, starting at $0.49/GB&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/evomi.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://serpapi.com/?utm_source=scrapling&quot; target=&quot;_blank&quot; title=&quot;Scrape Google and other search engines with SerpApi&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/SerpApi.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://visit.decodo.com/Dy6W0b&quot; target=&quot;_blank&quot; title=&quot;Try the Most Efficient Residential Proxies for Free&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/decodo.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://petrosky.io/d4vinci&quot; target=&quot;_blank&quot; title=&quot;PetroSky delivers cutting-edge VPS hosting.&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/petrosky.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://hasdata.com/?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=D4Vinci&quot; target=&quot;_blank&quot; title=&quot;The web scraping service that actually beats anti-bot systems!&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/hasdata.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://proxyempire.io/&quot; target=&quot;_blank&quot; title=&quot;Collect The Data Your Project Needs with the Best Residential Proxies&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/ProxyEmpire.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://hypersolutions.co/?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=scrapling&quot; target=&quot;_blank&quot; title=&quot;Bot Protection Bypass API for Akamai, DataDome, Incapsula &amp; Kasada&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/HyperSolutions.png&quot;&gt;&lt;/a&gt;


&lt;a href=&quot;https://www.swiftproxy.net/&quot; target=&quot;_blank&quot; title=&quot;Unlock Reliable Proxy Services with Swiftproxy!&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/swiftproxy.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://www.rapidproxy.io/?ref=d4v&quot; target=&quot;_blank&quot; title=&quot;Affordable Access to the Proxy World ‚Äì bypass CAPTCHAs blocks, and avoid additional costs.&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/rapidproxy.jpg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://browser.cash/?utm_source=D4Vinci&amp;utm_medium=referral&quot; target=&quot;_blank&quot; title=&quot;Browser Automation &amp; AI Browser Agent Platform&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/browserCash.png&quot;&gt;&lt;/a&gt;

&lt;!-- /sponsors --&gt;

&lt;i&gt;&lt;sub&gt;Do you want to show your ad here? Click [here](https://github.com/sponsors/D4Vinci) and choose the tier that suites you!&lt;/sub&gt;&lt;/i&gt;

---

## Key Features

### Spiders ‚Äî A Full Crawling Framework
- üï∑Ô∏è **Scrapy-like Spider API**: Define spiders with `start_urls`, async `parse` callbacks, and `Request`/`Response` objects.
- ‚ö° **Concurrent Crawling**: Configurable concurrency limits, per-domain throttling, and download delays.
- üîÑ **Multi-Session Support**: Unified interface for HTTP requests, and stealthy headless browsers in a single spider ‚Äî route requests to different sessions by ID.
- üíæ **Pause &amp; Resume**: Checkpoint-based crawl persistence. Press Ctrl+C for a graceful shutdown; restart to resume from where you left off.
- üì° **Streaming Mode**: Stream scraped items as they arrive via `async for item in spider.stream()` with real-time stats ‚Äî ideal for UI, pipelines, and long-running crawls.
- üõ°Ô∏è **Blocked Request Detection**: Automatic detection and retry of blocked requests with customizable logic.
- üì¶ **Built-in Export**: Export results through hooks and your own pipeline or the built-in JSON/JSONL with `result.items.to_json()` / `result.items.to_jsonl()` respectively.

### Advanced Websites Fetching with Session Support
- **HTTP Requests**: Fast and stealthy HTTP requests with the `Fetcher` class. Can impersonate browsers&#039; TLS fingerprint, headers, and use HTTP/3.
- **Dynamic Loading**: Fetch dynamic websites with full browser automation through the `DynamicFetcher` class supporting Playwright&#039;s Chromium and Google&#039;s Chrome.
- **Anti-bot Bypass**: Advanced stealth capabilities with `StealthyFetcher` and fingerprint spoofing. Can easily bypass all types of Cloudflare&#039;s Turnstile/Interstitial with automation.
- **Session Management**: Persistent session support with `FetcherSession`, `StealthySession`, and `DynamicSession` classes for cookie and state management across requests.
- **Proxy Rotation**: Built-in `ProxyRotator` with cyclic or custom rotation strategies across all session types, plus per-request proxy overrides.
- **Domain Blocking**: Block requests to specific domains (and their subdomains) in browser-based fetchers.
- **Async Support**: Complete async support across all fetchers and dedicated async session classes.

### Adaptive Scraping &amp; AI Integration
- üîÑ **Smart Element Tracking**: Relocate elements after website changes using intelligent similarity algorithms.
- üéØ **Smart Flexible Selection**: CSS selectors, XPath selectors, filter-based search, text search, regex search, and more.
- üîç **Find Similar Elements**: Automatically locate elements similar to found elements.
- ü§ñ **MCP Server to be used with AI**: Built-in MCP server for AI-assisted Web Scraping and data extraction. The MCP server features powerful, custom capabilities that leverage Scrapling to extract targeted content before passing it to the AI (Claude/Cursor/etc), thereby speeding up operations and reducing costs by minimizing token usage. ([demo video](https://www.youtube.com/watch?v=qyFk3ZNwOxE))

### High-Performance &amp; battle-tested Architecture
- üöÄ **Lightning Fast**: Optimized performance outperforming most Python scraping libraries.
- üîã **Memory Efficient**: Optimized data structures and lazy loading for a minimal memory footprint.
- ‚ö° **Fast JSON Serialization**: 10x faster than the standard library.
- üèóÔ∏è **Battle tested**: Not only does Scrapling have 92% test coverage and full type hints coverage, but it has been used daily by hundreds of Web Scrapers over the past year.

### Developer/Web Scraper Friendly Experience
- üéØ **Interactive Web Scraping Shell**: Optional built-in IPython shell with Scrapling integration, shortcuts, and new tools to speed up Web Scraping scripts development, like converting curl requests to Scrapling requests and viewing requests results in your browser.
- üöÄ **Use it directly from the Terminal**: Optionally, you can use Scrapling to scrape a URL without writing a single line of code!
- üõ†Ô∏è **Rich Navigation API**: Advanced DOM traversal with parent, sibling, and child navigation methods.
- üß¨ **Enhanced Text Processing**: Built-in regex, cleaning methods, and optimized string operations.
- üìù **Auto Selector Generation**: Generate robust CSS/XPath selectors for any element.
- üîå **Familiar API**: Similar to Scrapy/BeautifulSoup with the same pseudo-elements used in Scrapy/Parsel.
- üìò **Complete Type Coverage**: Full type hints for excellent IDE support and code completion. The entire codebase is automatically scanned with **PyRight** and **MyPy** with each change.
- üîã **Ready Docker image**: With each release, a Docker image containing all browsers is automatically built and pushed.

## Getting Started

Let&#039;s give you a quick glimpse of what Scrapling can do without deep diving.

### Basic Usage
HTTP requests with session support
```python
from scrapling.fetchers import Fetcher, FetcherSession

with FetcherSession(impersonate=&#039;chrome&#039;) as session:  # Use latest version of Chrome&#039;s TLS fingerprint
    page = session.get(&#039;https://quotes.toscrape.com/&#039;, stealthy_headers=True)
    quotes = page.css(&#039;.quote .text::text&#039;).getall()

# Or use one-off requests
page = Fetcher.get(&#039;https://quotes.toscrape.com/&#039;)
quotes = page.css(&#039;.quote .text::text&#039;).getall()
```
Advanced stealth mode
```python
from scrapling.fetchers import StealthyFetcher, StealthySession

with StealthySession(headless=True, solve_cloudflare=True) as session:  # Keep the browser open until you finish
    page = session.fetch(&#039;https://nopecha.com/demo/cloudflare&#039;, google_search=False)
    data = page.css(&#039;#padded_content a&#039;).getall()

# Or use one-off request style, it opens the browser for this request, then closes it after finishing
page = StealthyFetcher.fetch(&#039;https://nopecha.com/demo/cloudflare&#039;)
data = page.css(&#039;#padded_content a&#039;).getall()
```
Full browser automation
```python
from scrapling.fetchers import DynamicFetcher, DynamicSession

with DynamicSession(headless=True, disable_resources=False, network_idle=True) as session:  # Keep the browser open until you finish
    page = session.fetch(&#039;https://quotes.toscrape.com/&#039;, load_dom=False)
    data = page.xpath(&#039;//span[@class=&quot;text&quot;]/text()&#039;).getall()  # XPath selector if you prefer it

# Or use one-off request style, it opens the browser for this request, then closes it after finishing
page = DynamicFetcher.fetch(&#039;https://quotes.toscrape.com/&#039;)
data = page.css(&#039;.quote .text::text&#039;).getall()
```

### Spiders
Build full crawlers with concurrent requests, multiple session types, and pause/resume:
```python
from scrapling.spiders import Spider, Request, Response

class QuotesSpider(Spider):
    name = &quot;quotes&quot;
    start_urls = [&quot;https://quotes.toscrape.com/&quot;]
    concurrent_requests = 10
    
    async def parse(self, response: Response):
        for quote in response.css(&#039;.quote&#039;):
            yield {
                &quot;text&quot;: quote.css(&#039;.text::text&#039;).get(),
                &quot;author&quot;: quote.css(&#039;.author::text&#039;).get(),
            }
            
        next_page = response.css(&#039;.next a&#039;)
        if next_page:
            yield response.follow(next_page[0].attrib[&#039;href&#039;])

result = QuotesSpider().start()
print(f&quot;Scraped {len(result.items)} quotes&quot;)
result.items.to_json(&quot;quotes.json&quot;)
```
Use multiple session types in a single spider:
```python
from scrapling.spiders import Spider, Request, Response
from scrapling.fetchers import FetcherSession, AsyncStealthySession

class MultiSessionSpider(Spider):
    name = &quot;multi&quot;
    start_urls = [&quot;https://example.com/&quot;]
    
    def configure_sessions(self, manager):
        manager.add(&quot;fast&quot;, FetcherSession(impersonate=&quot;chrome&quot;))
        manager.add(&quot;stealth&quot;, AsyncStealthySession(headless=True), lazy=True)
    
    async def parse(self, response: Response):
        for link in response.css(&#039;a::attr(href)&#039;).getall():
            # Route protected pages through the stealth session
            if &quot;protected&quot; in link:
                yield Request(link, sid=&quot;stealth&quot;)
            else:
                yield Request(link, sid=&quot;fast&quot;, callback=self.parse)  # explicit callback
```
Pause and resume long crawls with checkpoints by running the spider like this:
```python
QuotesSpider(crawldir=&quot;./crawl_data&quot;).start()
```
Press Ctrl+C to pause gracefully ‚Äî progress is saved automatically. Later, when you start the spider again, pass the same `crawldir`, and it will resume from where it stopped.

### Advanced Parsing &amp; Navigation
```python
from scrapling.fetchers import Fetcher

# Rich element selection and navigation
page = Fetcher.get(&#039;https://quotes.toscrape.com/&#039;)

# Get quotes with multiple selection methods
quotes = page.css(&#039;.quote&#039;)  # CSS selector
quotes = page.xpath(&#039;//div[@class=&quot;quote&quot;]&#039;)  # XPath
quotes = page.find_all(&#039;div&#039;, {&#039;class&#039;: &#039;quote&#039;})  # BeautifulSoup-style
# Same as
quotes = page.find_all(&#039;div&#039;, class_=&#039;quote&#039;)
quotes = page.find_all([&#039;div&#039;], class_=&#039;quote&#039;)
quotes = page.find_all(class_=&#039;quote&#039;)  # and so on...
# Find element by text content
quotes = page.find_by_text(&#039;quote&#039;, tag=&#039;div&#039;)

# Advanced navigation
quote_text = page.css(&#039;.quote&#039;)[0].css(&#039;.text::text&#039;).get()
quote_text = page.css(&#039;.quote&#039;).css(&#039;.text::text&#039;).getall()  # Chained selectors
first_quote = page.css(&#039;.quote&#039;)[0]
author = first_quote.next_sibling.css(&#039;.author::text&#039;)
parent_container = first_quote.parent

# Element relationships and similarity
similar_elements = first_quote.find_similar()
below_elements = first_quote.below_elements()
```
You can use the parser right away if you don&#039;t want to fetch websites like below:
```python
from scrapling.parser import Selector

page = Selector(&quot;&lt;html&gt;...&lt;/html&gt;&quot;)
```
And it works precisely the same way!

### Async Session Management Examples
```python
import asyncio
from scrapling.fetchers import FetcherSession, AsyncStealthySession, AsyncDynamicSession

async with FetcherSession(http3=True) as session:  # `FetcherSession` is context-aware and can work in both sync/async patterns
    page1 = session.get(&#039;https://quotes.toscrape.com/&#039;)
    page2 = session.get(&#039;https://quotes.toscrape.com/&#039;, impersonate=&#039;firefox135&#039;)

# Async session usage
async with AsyncStealthySession(max_pages=2) as session:
    tasks = []
    urls = [&#039;https://example.com/page1&#039;, &#039;https://example.com/page2&#039;]
    
    for url in urls:
        task = session.fetch(url)
        tasks.append(task)
    
    print(session.get_pool_stats())  # Optional - The status of the browser tabs pool (busy/free/error)
    results = await asyncio.gather(*tasks)
    print(session.get_pool_stats())
```

## CLI &amp; Interactive Shell

Scrapling includes a powerful command-line interface:

[![asciicast](https://asciinema.org/a/736339.svg)](https://asciinema.org/a/736339)

Launch the interactive Web Scraping shell
```bash
scrapling shell
```
Extract pages to a file directly without programming (Extracts the content inside the `body` tag by default). If the output file ends with `.txt`, then the text content of the target will be extracted. If it ends in `.md`, it will be a Markdown representation of the HTML content; if it ends in `.html`, it will be the HTML content itself.
```bash
scrapling extract get &#039;https://example.com&#039; content.md
scrapling extract get &#039;https://example.com&#039; content.txt --css-selector &#039;#fromSkipToProducts&#039; --impersonate &#039;chrome&#039;  # All elements matching the CSS selector &#039;#fromSkipToProducts&#039;
scrapling extract fetch &#039;https://example.com&#039; content.md --css-selector &#039;#fromSkipToProducts&#039; --no-headless
scrapling extract stealthy-fetch &#039;https://nopecha.com/demo/cloudflare&#039; captchas.html --css-selector &#039;#padded_content a&#039; --solve-cloudflare
```

&gt; [!NOTE]
&gt; There are many additional features, but we want to keep this page concise, including the MCP server and the interactive Web Scraping Shell. Check out the full documentation [here](https://scrapling.readthedocs.io/en/latest/)

## Performance Benchmarks

Scrapling isn&#039;t just powerful‚Äîit&#039;s also blazing fast. The following benchmarks compare Scrapling&#039;s parser with the latest versions of other popular libraries.

###

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[huggingface/skills]]></title>
            <link>https://github.com/huggingface/skills</link>
            <guid>https://github.com/huggingface/skills</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:24 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/skills">huggingface/skills</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 6,352</p>
            <p>Forks: 379</p>
            <p>Stars today: 1,538 stars today</p>
            <h2>README</h2><pre># Hugging Face Skills

Hugging Face Skills are definitions for AI/ML tasks like dataset creation, model training, and evaluation. They are interoperable with all major coding agent tools like OpenAI Codex, Anthropic&#039;s Claude Code, Google DeepMind&#039;s Gemini CLI, and Cursor.

The Skills in this repository follow the standardized format [Agent Skill](https://agentskills.io/home) format.

## How do Skills work?

In practice, skills are self-contained folders that package instructions, scripts, and resources together for an AI agent to use on a specific use case. Each folder includes a `SKILL.md` file with YAML frontmatter (name and description) followed by the guidance your coding agent follows while the skill is active. 

&gt; [!NOTE]
&gt; &#039;Skills&#039; is actually an Anthropic term used within Claude AI and Claude Code and not adopted by other agent tools, but we love it! OpenAI Codex uses the open [Agent Skills](https://agentskills.io/specification) format, where each skill is a directory with a `SKILL.md` file that Codex discovers from standard `.agents/skills` locations documented in the [Codex Skills guide](https://developers.openai.com/codex/skills/). Codex can also work with an `AGENTS.md` file. Google Gemini uses &#039;extensions&#039; to define the instructions for your coding agent in a `gemini-extension.json` file. **This repo is compatible with all of them, and more!**

&gt; [!TIP]
&gt; If your agent doesn&#039;t support skills, you can use [`agents/AGENTS.md`](agents/AGENTS.md) directly as a fallback.

## Installation

Hugging Face skills are compatible with Claude Code, Codex, Gemini CLI, and Cursor.

### Claude Code

1. Register the repository as a plugin marketplace:  
   
```
/plugin marketplace add huggingface/skills
```

2. To install a skill, run:  
   
```
/plugin install &lt;skill-name&gt;@huggingface/skills
```

For example:  

```
/plugin install hugging-face-cli@huggingface/skills
```

### Codex

1. Copy or symlink any skills you want to use from this repository&#039;s `skills/` directory into one of Codex&#039;s standard `.agents/skills` locations (for example, `$REPO_ROOT/.agents/skills` or `$HOME/.agents/skills`) as described in the [Codex Skills guide](https://developers.openai.com/codex/skills/).

2. Once a skill is available in one of those locations, Codex will discover it using the Agent Skills standard and load the `SKILL.md` instructions when it decides to use that skill or when you explicitly invoke it.

3. If your Codex setup still relies on `AGENTS.md`, you can use the generated [`agents/AGENTS.md`](agents/AGENTS.md) file in this repo as a fallback bundle of instructions.

### Gemini CLI

1. This repo includes `gemini-extension.json` to integrate with the Gemini CLI.

2. Install locally:  

```
gemini extensions install . --consent
```

or use the GitHub URL:

```
gemini extensions install https://github.com/huggingface/skills.git --consent
```

4. See [Gemini CLI extensions docs](https://geminicli.com/docs/extensions/#installing-an-extension) for more help.

### Cursor

This repository includes Cursor plugin manifests:

- `.cursor-plugin/plugin.json`
- `.mcp.json` (configured with the Hugging Face MCP server URL)

Install from repository URL (or local checkout) via the Cursor plugin flow.

For contributors, regenerate manifests with:

```bash
./scripts/publish.sh
```

## Skills

This repository contains a few skills to get you started. You can also contribute your own skills to the repository.

### Available skills

&lt;!-- This table is auto-generated by scripts/generate_agents.py. Do not edit manually. --&gt;
&lt;!-- BEGIN_SKILLS_TABLE --&gt;
| Name | Description | Documentation |
|------|-------------|---------------|
| `gradio` | Build Gradio web UIs and demos in Python. Use when creating or editing Gradio apps, components, event listeners, layouts, or chatbots. | [SKILL.md](skills/huggingface-gradio/SKILL.md) |
| `hugging-face-cli` | Execute Hugging Face Hub operations using the hf CLI. Download models/datasets, upload files, manage repos, and run cloud compute jobs. | [SKILL.md](skills/hugging-face-cli/SKILL.md) |
| `hugging-face-datasets` | Create and manage datasets on Hugging Face Hub. Supports initializing repos, defining configs/system prompts, streaming row updates, and SQL-based dataset querying/transformation. | [SKILL.md](skills/hugging-face-datasets/SKILL.md) |
| `hugging-face-evaluation` | Add and manage evaluation results in Hugging Face model cards. Supports extracting eval tables from README content, importing scores from Artificial Analysis API, and running custom evaluations with vLLM/lighteval. | [SKILL.md](skills/hugging-face-evaluation/SKILL.md) |
| `hugging-face-jobs` | Run compute jobs on Hugging Face infrastructure. Execute Python scripts, manage scheduled jobs, and monitor job status. | [SKILL.md](skills/hugging-face-jobs/SKILL.md) |
| `hugging-face-model-trainer` | Train or fine-tune language models using TRL on Hugging Face Jobs infrastructure. Covers SFT, DPO, GRPO and reward modeling training methods, plus GGUF conversion for local deployment. Includes hardware selection, cost estimation, Trackio monitoring, and Hub persistence. | [SKILL.md](skills/hugging-face-model-trainer/SKILL.md) |
| `hugging-face-paper-publisher` | Publish and manage research papers on Hugging Face Hub. Supports creating paper pages, linking papers to models/datasets, claiming authorship, and generating professional markdown-based research articles. | [SKILL.md](skills/hugging-face-paper-publisher/SKILL.md) |
| `hugging-face-tool-builder` | Build reusable scripts for Hugging Face API operations. Useful for chaining API calls or automating repeated tasks. | [SKILL.md](skills/hugging-face-tool-builder/SKILL.md) |
| `hugging-face-trackio` | Track and visualize ML training experiments with Trackio. Log metrics via Python API and retrieve them via CLI. Supports real-time dashboards synced to HF Spaces. | [SKILL.md](skills/hugging-face-trackio/SKILL.md) |
&lt;!-- END_SKILLS_TABLE --&gt;

### Using skills in your coding agent

Once a skill is installed, mention it directly while giving your coding agent instructions:

- &quot;Use the HF LLM trainer skill to estimate the GPU memory needed for a 70B model run.&quot;
- &quot;Use the HF model evaluation skill to launch `run_eval_job.py` on the latest checkpoint.&quot;
- &quot;Use the HF dataset creator skill to draft new few-shot classification templates.&quot;
- &quot;Use the HF paper publisher skill to index my arXiv paper and link it to my model.&quot;

Your coding agent automatically loads the corresponding `SKILL.md` instructions and helper scripts while it completes the task.

### Contribute or customize a skill

1. Copy one of the existing skill folders (for example, `hf-datasets/`) and rename it.
2. Update the new folder&#039;s `SKILL.md` frontmatter:
   ```markdown
   ---
   name: my-skill-name
   description: Describe what the skill does and when to use it
   ---

   # Skill Title
   Guidance + examples + guardrails
   ```
3. Add or edit supporting scripts, templates, and documents referenced by your instructions.
4. Add an entry to `.claude-plugin/marketplace.json` with a concise, human-readable description.
5. Run:
   ```bash
   ./scripts/publish.sh
   ```
   to regenerate and validate all generated metadata.
6. Reinstall or reload the skill bundle in your coding agent so the updated folder is available.

### Marketplace

The `.claude-plugin/marketplace.json` file lists skills with human-readable descriptions for the plugin marketplace. The CI validates that skill names and paths match between `SKILL.md` files and `marketplace.json`, but descriptions are maintained separately: `SKILL.md` descriptions guide when Claude activates the skill, while marketplace descriptions are written for humans browsing available skills.

### Additional references
- Browse the latest instructions, scripts, and templates directly at [huggingface/skills](https://github.com/huggingface/skills).
- Review Hugging Face documentation for the specific libraries or workflows you reference inside each skill.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[muratcankoylan/Agent-Skills-for-Context-Engineering]]></title>
            <link>https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering</link>
            <guid>https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:23 GMT</pubDate>
            <description><![CDATA[A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems. Use when building, optimizing, or debugging agent systems that require effective context management.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering">muratcankoylan/Agent-Skills-for-Context-Engineering</a></h1>
            <p>A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems. Use when building, optimizing, or debugging agent systems that require effective context management.</p>
            <p>Language: Python</p>
            <p>Stars: 10,666</p>
            <p>Forks: 831</p>
            <p>Stars today: 1,042 stars today</p>
            <h2>README</h2><pre># Agent Skills for Context Engineering

A comprehensive, open collection of Agent Skills focused on context engineering principles for building production-grade AI agent systems. These skills teach the art and science of curating context to maximize agent effectiveness across any agent platform.

## What is Context Engineering?

Context engineering is the discipline of managing the language model&#039;s context window. Unlike prompt engineering, which focuses on crafting effective instructions, context engineering addresses the holistic curation of all information that enters the model&#039;s limited attention budget: system prompts, tool definitions, retrieved documents, message history, and tool outputs.

The fundamental challenge is that context windows are constrained not by raw token capacity but by attention mechanics. As context length increases, models exhibit predictable degradation patterns: the &quot;lost-in-the-middle&quot; phenomenon, U-shaped attention curves, and attention scarcity. Effective context engineering means finding the smallest possible set of high-signal tokens that maximize the likelihood of desired outcomes.

## Recognition

This repository is cited in academic research as foundational work on static skill architecture:

&gt; &quot;While static skills are well-recognized [Anthropic, 2025b; Muratcan Koylan, 2025], MCE is among the first to dynamically evolve them, bridging manual skill engineering and autonomous self-improvement.&quot;

‚Äî [Meta Context Engineering via Agentic Skill Evolution](https://arxiv.org/pdf/2601.21557), Peking University State Key Laboratory of General Artificial Intelligence (2026)

## Skills Overview

### Foundational Skills

These skills establish the foundational understanding required for all subsequent context engineering work.

| Skill | Description |
|-------|-------------|
| [context-fundamentals](skills/context-fundamentals/) | Understand what context is, why it matters, and the anatomy of context in agent systems |
| [context-degradation](skills/context-degradation/) | Recognize patterns of context failure: lost-in-middle, poisoning, distraction, and clash |
| [context-compression](skills/context-compression/) | Design and evaluate compression strategies for long-running sessions |

### Architectural Skills

These skills cover the patterns and structures for building effective agent systems.

| Skill | Description |
|-------|-------------|
| [multi-agent-patterns](skills/multi-agent-patterns/) | Master orchestrator, peer-to-peer, and hierarchical multi-agent architectures |
| [memory-systems](skills/memory-systems/) | Design short-term, long-term, and graph-based memory architectures |
| [tool-design](skills/tool-design/) | Build tools that agents can use effectively |
| [filesystem-context](skills/filesystem-context/) | Use filesystems for dynamic context discovery, tool output offloading, and plan persistence |
| [hosted-agents](skills/hosted-agents/) | **NEW** Build background coding agents with sandboxed VMs, pre-built images, multiplayer support, and multi-client interfaces |

### Operational Skills

These skills address the ongoing operation and optimization of agent systems.

| Skill | Description |
|-------|-------------|
| [context-optimization](skills/context-optimization/) | Apply compaction, masking, and caching strategies |
| [evaluation](skills/evaluation/) | Build evaluation frameworks for agent systems |
| [advanced-evaluation](skills/advanced-evaluation/) | Master LLM-as-a-Judge techniques: direct scoring, pairwise comparison, rubric generation, and bias mitigation |

### Development Methodology

These skills cover the meta-level practices for building LLM-powered projects.

| Skill | Description |
|-------|-------------|
| [project-development](skills/project-development/) | Design and build LLM projects from ideation through deployment, including task-model fit analysis, pipeline architecture, and structured output design |

### Cognitive Architecture Skills

These skills cover formal cognitive modeling for rational agent systems.

| Skill | Description |
|-------|-------------|
| [bdi-mental-states](skills/bdi-mental-states/) | **NEW** Transform external RDF context into agent mental states (beliefs, desires, intentions) using formal BDI ontology patterns for deliberative reasoning and explainability |

## Design Philosophy

### Progressive Disclosure

Each skill is structured for efficient context use. At startup, agents load only skill names and descriptions. Full content loads only when a skill is activated for relevant tasks.

### Platform Agnosticism

These skills focus on transferable principles rather than vendor-specific implementations. The patterns work across Claude Code, Cursor, and any agent platform that supports skills or allows custom instructions.

### Conceptual Foundation with Practical Examples

Scripts and examples demonstrate concepts using Python pseudocode that works across environments without requiring specific dependency installations.

## Usage

### Usage with Claude Code

This repository is a **Claude Code Plugin Marketplace** containing context engineering skills that Claude automatically discovers and activates based on your task context.

### Installation

**Step 1: Add the Marketplace**

Run this command in Claude Code to register this repository as a plugin source:

```
/plugin marketplace add muratcankoylan/Agent-Skills-for-Context-Engineering
```

**Step 2: Browse and Install**

Option A - Browse available plugins:
1. Select `Browse and install plugins`
2. Select `context-engineering-marketplace`
3. Choose a plugin (e.g., `context-engineering-fundamentals`, `agent-architecture`)
4. Select `Install now`

Option B - Direct install via command:

```
/plugin install context-engineering-fundamentals@context-engineering-marketplace
/plugin install agent-architecture@context-engineering-marketplace
/plugin install agent-evaluation@context-engineering-marketplace
/plugin install agent-development@context-engineering-marketplace
/plugin install cognitive-architecture@context-engineering-marketplace
```

### Available Plugins

| Plugin | Skills Included |
|--------|-----------------|
| `context-engineering-fundamentals` | context-fundamentals, context-degradation, context-compression, context-optimization |
| `agent-architecture` | multi-agent-patterns, memory-systems, tool-design, filesystem-context, hosted-agents |
| `agent-evaluation` | evaluation, advanced-evaluation |
| `agent-development` | project-development |
| `cognitive-architecture` | bdi-mental-states |

### Skill Triggers

| Skill | Triggers On |
|-------|-------------|
| `context-fundamentals` | &quot;understand context&quot;, &quot;explain context windows&quot;, &quot;design agent architecture&quot; |
| `context-degradation` | &quot;diagnose context problems&quot;, &quot;fix lost-in-middle&quot;, &quot;debug agent failures&quot; |
| `context-compression` | &quot;compress context&quot;, &quot;summarize conversation&quot;, &quot;reduce token usage&quot; |
| `context-optimization` | &quot;optimize context&quot;, &quot;reduce token costs&quot;, &quot;implement KV-cache&quot; |
| `multi-agent-patterns` | &quot;design multi-agent system&quot;, &quot;implement supervisor pattern&quot; |
| `memory-systems` | &quot;implement agent memory&quot;, &quot;build knowledge graph&quot;, &quot;track entities&quot; |
| `tool-design` | &quot;design agent tools&quot;, &quot;reduce tool complexity&quot;, &quot;implement MCP tools&quot; |
| `filesystem-context` | &quot;offload context to files&quot;, &quot;dynamic context discovery&quot;, &quot;agent scratch pad&quot;, &quot;file-based context&quot; |
| `hosted-agents` | &quot;build background agent&quot;, &quot;create hosted coding agent&quot;, &quot;sandboxed execution&quot;, &quot;multiplayer agent&quot;, &quot;Modal sandboxes&quot; |
| `evaluation` | &quot;evaluate agent performance&quot;, &quot;build test framework&quot;, &quot;measure quality&quot; |
| `advanced-evaluation` | &quot;implement LLM-as-judge&quot;, &quot;compare model outputs&quot;, &quot;mitigate bias&quot; |
| `project-development` | &quot;start LLM project&quot;, &quot;design batch pipeline&quot;, &quot;evaluate task-model fit&quot; |
| `bdi-mental-states` | &quot;model agent mental states&quot;, &quot;implement BDI architecture&quot;, &quot;transform RDF to beliefs&quot;, &quot;build cognitive agent&quot; |

&lt;img width=&quot;1014&quot; height=&quot;894&quot; alt=&quot;Screenshot 2025-12-26 at 12 34 47‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/f79aaf03-fd2d-4c71-a630-7027adeb9bfe&quot; /&gt;

### For Cursor &amp; Codex &amp; IDE

Copy skill content into `.rules` or create project-specific Skills folders. The skills provide the context and guidelines that agent needs for effective context engineering and agent design.

### For Custom Implementations

Extract the principles and patterns from any skill and implement them in your agent framework. The skills are deliberately platform-agnostic.

## Examples

The [examples](examples/) folder contains complete system designs that demonstrate how multiple skills work together in practice.

| Example | Description | Skills Applied |
|---------|-------------|----------------|
| [digital-brain-skill](examples/digital-brain-skill/) | **NEW** Personal operating system for founders and creators. Complete Claude Code skill with 6 modules, 4 automation scripts | context-fundamentals, context-optimization, memory-systems, tool-design, multi-agent-patterns, evaluation, project-development |
| [x-to-book-system](examples/x-to-book-system/) | Multi-agent system that monitors X accounts and generates daily synthesized books | multi-agent-patterns, memory-systems, context-optimization, tool-design, evaluation |
| [llm-as-judge-skills](examples/llm-as-judge-skills/) | Production-ready LLM evaluation tools with TypeScript implementation, 19 passing tests | advanced-evaluation, tool-design, context-fundamentals, evaluation |
| [book-sft-pipeline](examples/book-sft-pipeline/) | Train models to write in any author&#039;s style. Includes Gertrude Stein case study with 70% human score on Pangram, $2 total cost | project-development, context-compression, multi-agent-patterns, evaluation |

Each example includes:
- Complete PRD with architecture decisions
- Skills mapping showing which concepts informed each decision
- Implementation guidance

### Digital Brain Skill Example

The [digital-brain-skill](examples/digital-brain-skill/) example is a complete personal operating system demonstrating comprehensive skills application:

- **Progressive Disclosure**: 3-level loading (SKILL.md ‚Üí MODULE.md ‚Üí data files)
- **Module Isolation**: 6 independent modules (identity, content, knowledge, network, operations, agents)
- **Append-Only Memory**: JSONL files with schema-first lines for agent-friendly parsing
- **Automation Scripts**: 4 consolidated tools (weekly_review, content_ideas, stale_contacts, idea_to_draft)

Includes detailed traceability in [HOW-SKILLS-BUILT-THIS.md](examples/digital-brain-skill/HOW-SKILLS-BUILT-THIS.md) mapping every architectural decision to specific skill principles.

### LLM-as-Judge Skills Example

The [llm-as-judge-skills](examples/llm-as-judge-skills/) example is a complete TypeScript implementation demonstrating:

- **Direct Scoring**: Evaluate responses against weighted criteria with rubric support
- **Pairwise Comparison**: Compare responses with position bias mitigation
- **Rubric Generation**: Create domain-specific evaluation standards
- **EvaluatorAgent**: High-level agent combining all evaluation capabilities

### Book SFT Pipeline Example

The [book-sft-pipeline](examples/book-sft-pipeline/) example demonstrates training small models (8B) to write in any author&#039;s style:

- **Intelligent Segmentation**: Two-tier chunking with overlap for maximum training examples
- **Prompt Diversity**: 15+ templates to prevent memorization and force style learning
- **Tinker Integration**: Complete LoRA training workflow with $2 total cost
- **Validation Methodology**: Modern scenario testing proves style transfer vs content memorization

Integrates with context engineering skills: project-development, context-compression, multi-agent-patterns, evaluation.

## Star History
&lt;img width=&quot;3664&quot; height=&quot;2648&quot; alt=&quot;star-history-2026224&quot; src=&quot;https://github.com/user-attachments/assets/b3bdbf23-4b6a-4774-ae85-42ef4d9b2d79&quot; /&gt;

## Structure

Each skill follows the Agent Skills specification:

```
skill-name/
‚îú‚îÄ‚îÄ SKILL.md              # Required: instructions + metadata
‚îú‚îÄ‚îÄ scripts/              # Optional: executable code demonstrating concepts
‚îî‚îÄ‚îÄ references/           # Optional: additional documentation and resources
```

See the [template](template/) folder for the canonical skill structure.

## Contributing

This repository follows the Agent Skills open development model. Contributions are welcome from the broader ecosystem. When contributing:

1. Follow the skill template structure
2. Provide clear, actionable instructions
3. Include working examples where appropriate
4. Document trade-offs and potential issues
5. Keep SKILL.md under 500 lines for optimal performance

Feel free to contact [Muratcan Koylan](https://x.com/koylanai) for collaboration opportunities or any inquiries.

## License

MIT License - see LICENSE file for details.

## References

The principles in these skills are derived from research and production experience at leading AI labs and framework developers. Each skill includes references to the underlying research and case studies that inform its recommendations.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[datawhalechina/hello-agents]]></title>
            <link>https://github.com/datawhalechina/hello-agents</link>
            <guid>https://github.com/datawhalechina/hello-agents</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:22 GMT</pubDate>
            <description><![CDATA[üìö „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã‚Äî‚Äî‰ªéÈõ∂ÂºÄÂßãÁöÑÊô∫ËÉΩ‰ΩìÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/datawhalechina/hello-agents">datawhalechina/hello-agents</a></h1>
            <p>üìö „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã‚Äî‚Äî‰ªéÈõ∂ÂºÄÂßãÁöÑÊô∫ËÉΩ‰ΩìÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã</p>
            <p>Language: Python</p>
            <p>Stars: 21,917</p>
            <p>Forks: 2,524</p>
            <p>Stars today: 222 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;right&quot;&gt;
  &lt;a href=&quot;./README_EN.md&quot;&gt;English&lt;/a&gt; | ‰∏≠Êñá
&lt;/div&gt;

&lt;div align=&#039;center&#039;&gt;
  &lt;img src=&quot;./docs/images/hello-agents.png&quot; alt=&quot;alt text&quot; width=&quot;100%&quot;&gt;
  &lt;h1&gt;Hello-Agents&lt;/h1&gt;
  &lt;h3&gt;ü§ñ „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã&lt;/h3&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/15520&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/15520&quot; alt=&quot;datawhalechina%2Fhello-agents | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;&lt;em&gt;‰ªéÂü∫Á°ÄÁêÜËÆ∫Âà∞ÂÆûÈôÖÂ∫îÁî®ÔºåÂÖ®Èù¢ÊéåÊè°Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂÆûÁé∞&lt;/em&gt;&lt;/p&gt;
  &lt;img src=&quot;https://img.shields.io/github/stars/datawhalechina/Hello-Agents?style=flat&amp;logo=github&quot; alt=&quot;GitHub stars&quot;/&gt;
  &lt;img src=&quot;https://img.shields.io/github/forks/datawhalechina/Hello-Agents?style=flat&amp;logo=github&quot; alt=&quot;GitHub forks&quot;/&gt;
  &lt;img src=&quot;https://img.shields.io/badge/language-Chinese-brightgreen?style=flat&quot; alt=&quot;Language&quot;/&gt;
  &lt;a href=&quot;https://github.com/datawhalechina/Hello-Agents&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;logo=github&quot; alt=&quot;GitHub Project&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://datawhalechina.github.io/hello-agents/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Âú®Á∫øÈòÖËØª-Online%20Reading-green?style=flat&amp;logo=gitbook&quot; alt=&quot;Online Reading&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

---

## üéØ È°πÁõÆ‰ªãÁªç

&amp;emsp;&amp;emsp;Â¶ÇÊûúËØ¥ 2024 Âπ¥ÊòØ&quot;ÁôæÊ®°Â§ßÊàò&quot;ÁöÑÂÖÉÂπ¥ÔºåÈÇ£‰πà 2025 Âπ¥Êó†ÁñëÂºÄÂêØ‰∫Ü&quot;Agent ÂÖÉÂπ¥&quot;„ÄÇÊäÄÊúØÁöÑÁÑ¶ÁÇπÊ≠£‰ªéËÆ≠ÁªÉÊõ¥Â§ßÁöÑÂü∫Á°ÄÊ®°ÂûãÔºåËΩ¨ÂêëÊûÑÂª∫Êõ¥ËÅ™ÊòéÁöÑÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁ≥ªÁªüÊÄß„ÄÅÈáçÂÆûË∑µÁöÑÊïôÁ®ãÂç¥ÊûÅÂ∫¶ÂåÆ‰πè„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂèëËµ∑‰∫Ü Hello-Agents È°πÁõÆÔºåÂ∏åÊúõËÉΩ‰∏∫Á§æÂå∫Êèê‰æõ‰∏ÄÊú¨‰ªéÈõ∂ÂºÄÂßã„ÄÅÁêÜËÆ∫‰∏éÂÆûÊàòÂπ∂ÈáçÁöÑÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÊûÑÂª∫ÊåáÂçó„ÄÇ

&amp;emsp;&amp;emsp;Hello-Agents ÊòØ Datawhale Á§æÂå∫ÁöÑ&lt;strong&gt;Á≥ªÁªüÊÄßÊô∫ËÉΩ‰ΩìÂ≠¶‰π†ÊïôÁ®ã&lt;/strong&gt;„ÄÇÂ¶Ç‰ªä Agent ÊûÑÂª∫‰∏ªË¶ÅÂàÜ‰∏∫‰∏§Ê¥æÔºå‰∏ÄÊ¥æÊòØ DifyÔºåCozeÔºån8n ËøôÁ±ªËΩØ‰ª∂Â∑•Á®ãÁ±ª AgentÔºåÂÖ∂Êú¨Ë¥®ÊòØÊµÅÁ®ãÈ©±Âä®ÁöÑËΩØ‰ª∂ÂºÄÂèëÔºåLLM ‰Ωú‰∏∫Êï∞ÊçÆÂ§ÑÁêÜÁöÑÂêéÁ´ØÔºõÂè¶‰∏ÄÊ¥æÂàôÊòØ AI ÂéüÁîüÁöÑ AgentÔºåÂç≥ÁúüÊ≠£‰ª• AI È©±Âä®ÁöÑ Agent„ÄÇÊú¨ÊïôÁ®ãÊó®Âú®Â∏¶È¢ÜÂ§ßÂÆ∂Ê∑±ÂÖ•ÁêÜËß£Âπ∂ÊûÑÂª∫ÂêéËÄÖ‚Äî‚ÄîÁúüÊ≠£ÁöÑ AI Native Agent„ÄÇÊïôÁ®ãÂ∞ÜÂ∏¶È¢Ü‰Ω†Á©øÈÄèÊ°ÜÊû∂Ë°®Ë±°Ôºå‰ªéÊô∫ËÉΩ‰ΩìÁöÑÊ†∏ÂøÉÂéüÁêÜÂá∫ÂèëÔºåÊ∑±ÂÖ•ÂÖ∂Ê†∏ÂøÉÊû∂ÊûÑÔºåÁêÜËß£ÂÖ∂ÁªèÂÖ∏ËåÉÂºèÔºåÂπ∂ÊúÄÁªà‰∫≤ÊâãÊûÑÂª∫Ëµ∑Â±û‰∫éËá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÊàë‰ª¨Áõ∏‰ø°ÔºåÊúÄÂ•ΩÁöÑÂ≠¶‰π†ÊñπÂºèÂ∞±ÊòØÂä®ÊâãÂÆûË∑µ„ÄÇÂ∏åÊúõËøôÊú¨ÊïôÁ®ãËÉΩÊàê‰∏∫‰Ω†Êé¢Á¥¢Êô∫ËÉΩ‰Ωì‰∏ñÁïåÁöÑËµ∑ÁÇπÔºåËÉΩÂ§ü‰ªé‰∏ÄÂêçÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑ&quot;‰ΩøÁî®ËÄÖ&quot;ÔºåËúïÂèò‰∏∫‰∏ÄÂêçÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑ&quot;ÊûÑÂª∫ËÄÖ&quot;„ÄÇ

## üìö Âø´ÈÄüÂºÄÂßã

### Âú®Á∫øÈòÖËØª
**[üåê ÁÇπÂáªËøôÈáåÂºÄÂßãÂú®Á∫øÈòÖËØª](https://datawhalechina.github.io/hello-agents/)** - Êó†ÈúÄ‰∏ãËΩΩÔºåÈöèÊó∂ÈöèÂú∞Â≠¶‰π†

**[üìñ Cookbook](https://book.heterocat.com.cn/)**

### Êú¨Âú∞ÈòÖËØª
Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®Êú¨Âú∞ÈòÖËØªÊàñË¥°ÁåÆÂÜÖÂÆπÔºåËØ∑ÂèÇËÄÉ‰∏ãÊñπÁöÑÂ≠¶‰π†ÊåáÂçó„ÄÇ

### ‚ú® ‰Ω†Â∞ÜÊî∂Ëé∑‰ªÄ‰πàÔºü

- üìñ &lt;strong&gt;Datawhale ÂºÄÊ∫êÂÖçË¥π&lt;/strong&gt; ÂÆåÂÖ®ÂÖçË¥πÂ≠¶‰π†Êú¨È°πÁõÆÊâÄÊúâÂÜÖÂÆπÔºå‰∏éÁ§æÂå∫ÂÖ±ÂêåÊàêÈïø
- üîç &lt;strong&gt;ÁêÜËß£Ê†∏ÂøÉÂéüÁêÜ&lt;/strong&gt; Ê∑±ÂÖ•ÁêÜËß£Êô∫ËÉΩ‰ΩìÁöÑÊ¶ÇÂøµ„ÄÅÂéÜÂè≤‰∏éÁªèÂÖ∏ËåÉÂºè
- üèóÔ∏è &lt;strong&gt;‰∫≤ÊâãÂÆûÁé∞&lt;/strong&gt; ÊéåÊè°ÁÉ≠Èó®‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÂíåÊô∫ËÉΩ‰Ωì‰ª£Á†ÅÊ°ÜÊû∂ÁöÑ‰ΩøÁî®
- üõ†Ô∏è &lt;strong&gt;Ëá™Á†îÊ°ÜÊû∂[HelloAgents](https://github.com/jjyaoao/helloagents)&lt;/strong&gt; Âü∫‰∫é Openai ÂéüÁîü API ‰ªéÈõ∂ÊûÑÂª∫‰∏Ä‰∏™Ëá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂
- ‚öôÔ∏è &lt;strong&gt;ÊéåÊè°È´òÁ∫ßÊäÄËÉΩ&lt;/strong&gt; ‰∏ÄÊ≠•Ê≠•ÂÆûÁé∞‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅMemory„ÄÅÂçèËÆÆ„ÄÅËØÑ‰º∞Á≠âÁ≥ªÁªüÊÄßÊäÄÊúØ
- ü§ù &lt;strong&gt;Ê®°ÂûãËÆ≠ÁªÉ&lt;/strong&gt; ÊéåÊè° Agentic RLÔºå‰ªé SFT Âà∞ GRPO ÁöÑÂÖ®ÊµÅÁ®ãÂÆûÊàòËÆ≠ÁªÉ LLM
- üöÄ &lt;strong&gt;È©±Âä®ÁúüÂÆûÊ°à‰æã&lt;/strong&gt; ÂÆûÊàòÂºÄÂèëÊô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËµõÂçöÂ∞èÈïáÁ≠âÁªºÂêàÈ°πÁõÆ
- üìñ &lt;strong&gt;Ê±ÇËÅåÈù¢ËØï&lt;/strong&gt; Â≠¶‰π†Êô∫ËÉΩ‰ΩìÊ±ÇËÅåÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò

## üìñ ÂÜÖÂÆπÂØºËà™

| Á´†ËäÇ                                                                                        | ÂÖ≥ÈîÆÂÜÖÂÆπ                                      | Áä∂ÊÄÅ |
| ------------------------------------------------------------------------------------------- | --------------------------------------------- | ---- |
| [ÂâçË®Ä](./docs/ÂâçË®Ä.md)                                                                      | È°πÁõÆÁöÑÁºòËµ∑„ÄÅËÉåÊôØÂèäËØªËÄÖÂª∫ËÆÆ                    | ‚úÖ    |
| &lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;                                             |                                               |      |
| [Á¨¨‰∏ÄÁ´† ÂàùËØÜÊô∫ËÉΩ‰Ωì](./docs/chapter1/Á¨¨‰∏ÄÁ´†%20ÂàùËØÜÊô∫ËÉΩ‰Ωì.md)                                 | Êô∫ËÉΩ‰ΩìÂÆö‰πâ„ÄÅÁ±ªÂûã„ÄÅËåÉÂºè‰∏éÂ∫îÁî®                  | ‚úÖ    |
| [Á¨¨‰∫åÁ´† Êô∫ËÉΩ‰ΩìÂèëÂ±ïÂè≤](./docs/chapter2/Á¨¨‰∫åÁ´†%20Êô∫ËÉΩ‰ΩìÂèëÂ±ïÂè≤.md)                             | ‰ªéÁ¨¶Âè∑‰∏ª‰πâÂà∞ LLM È©±Âä®ÁöÑÊô∫ËÉΩ‰ΩìÊºîËøõ             | ‚úÖ    |
| [Á¨¨‰∏âÁ´† Â§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä](./docs/chapter3/Á¨¨‰∏âÁ´†%20Â§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä.md)                         | Transformer„ÄÅÊèêÁ§∫„ÄÅ‰∏ªÊµÅ LLM ÂèäÂÖ∂Â±ÄÈôê          | ‚úÖ    |
| &lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;                                         |                                               |      |
| [Á¨¨ÂõõÁ´† Êô∫ËÉΩ‰ΩìÁªèÂÖ∏ËåÉÂºèÊûÑÂª∫](./docs/chapter4/Á¨¨ÂõõÁ´†%20Êô∫ËÉΩ‰ΩìÁªèÂÖ∏ËåÉÂºèÊûÑÂª∫.md)                 | ÊâãÊääÊâãÂÆûÁé∞ ReAct„ÄÅPlan-and-Solve„ÄÅReflection  | ‚úÖ    |
| [Á¨¨‰∫îÁ´† Âü∫‰∫é‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑÊô∫ËÉΩ‰ΩìÊê≠Âª∫](./docs/chapter5/Á¨¨‰∫îÁ´†%20Âü∫‰∫é‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑÊô∫ËÉΩ‰ΩìÊê≠Âª∫.md) | ‰∫ÜËß£ Coze„ÄÅDify„ÄÅn8n Á≠â‰Ωé‰ª£Á†ÅÊô∫ËÉΩ‰ΩìÂπ≥Âè∞‰ΩøÁî®   | ‚úÖ    |
| [Á¨¨ÂÖ≠Á´† Ê°ÜÊû∂ÂºÄÂèëÂÆûË∑µ](./docs/chapter6/Á¨¨ÂÖ≠Á´†%20Ê°ÜÊû∂ÂºÄÂèëÂÆûË∑µ.md)                             | AutoGen„ÄÅAgentScope„ÄÅLangGraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂Â∫îÁî® | ‚úÖ    |
| [Á¨¨‰∏ÉÁ´† ÊûÑÂª∫‰Ω†ÁöÑAgentÊ°ÜÊû∂](./docs/chapter7/Á¨¨‰∏ÉÁ´†%20ÊûÑÂª∫‰Ω†ÁöÑAgentÊ°ÜÊû∂.md)                   | ‰ªé 0 ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰ΩìÊ°ÜÊû∂                       | ‚úÖ    |
| &lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;                                                     |                                               |      |
| [Á¨¨ÂÖ´Á´† ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢](./docs/chapter8/Á¨¨ÂÖ´Á´†%20ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢.md)                                 | ËÆ∞ÂøÜÁ≥ªÁªüÔºåRAGÔºåÂ≠òÂÇ®                           | ‚úÖ    |
| [Á¨¨‰πùÁ´† ‰∏ä‰∏ãÊñáÂ∑•Á®ã](./docs/chapter9/Á¨¨‰πùÁ´†%20‰∏ä‰∏ãÊñáÂ∑•Á®ã.md)                                 | ÊåÅÁª≠‰∫§‰∫íÁöÑ&quot;ÊÉÖÂ¢ÉÁêÜËß£&quot;                          | ‚úÖ    |
| [Á¨¨ÂçÅÁ´† Êô∫ËÉΩ‰ΩìÈÄö‰ø°ÂçèËÆÆ](./docs/chapter10/Á¨¨ÂçÅÁ´†%20Êô∫ËÉΩ‰ΩìÈÄö‰ø°ÂçèËÆÆ.md)                        | MCP„ÄÅA2A„ÄÅANP Á≠âÂçèËÆÆËß£Êûê                      | ‚úÖ    |
| [Á¨¨ÂçÅ‰∏ÄÁ´† Agentic-RL](./docs/chapter11/Á¨¨ÂçÅ‰∏ÄÁ´†%20Agentic-RL.md)                            | ‰ªé SFT Âà∞ GRPO ÁöÑ LLM ËÆ≠ÁªÉÂÆûÊàò                | ‚úÖ    |
| [Á¨¨ÂçÅ‰∫åÁ´† Êô∫ËÉΩ‰ΩìÊÄßËÉΩËØÑ‰º∞](./docs/chapter12/Á¨¨ÂçÅ‰∫åÁ´†%20Êô∫ËÉΩ‰ΩìÊÄßËÉΩËØÑ‰º∞.md)                    | Ê†∏ÂøÉÊåáÊ†á„ÄÅÂü∫ÂáÜÊµãËØï‰∏éËØÑ‰º∞Ê°ÜÊû∂                  | ‚úÖ    |
| &lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;                                                     |                                               |      |
| [Á¨¨ÂçÅ‰∏âÁ´† Êô∫ËÉΩÊóÖË°åÂä©Êâã](./docs/chapter13/Á¨¨ÂçÅ‰∏âÁ´†%20Êô∫ËÉΩÊóÖË°åÂä©Êâã.md)                        | MCP ‰∏éÂ§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÁöÑÁúüÂÆû‰∏ñÁïåÂ∫îÁî®              | ‚úÖ    |
| [Á¨¨ÂçÅÂõõÁ´† Ëá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰Ωì](./docs/chapter14/Á¨¨ÂçÅÂõõÁ´†%20Ëá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰Ωì.md)        | DeepResearch Agent Â§çÁé∞‰∏éËß£Êûê                 | ‚úÖ    |
| [Á¨¨ÂçÅ‰∫îÁ´† ÊûÑÂª∫ËµõÂçöÂ∞èÈïá](./docs/chapter15/Á¨¨ÂçÅ‰∫îÁ´†%20ÊûÑÂª∫ËµõÂçöÂ∞èÈïá.md)                        | Agent ‰∏éÊ∏∏ÊàèÁöÑÁªìÂêàÔºåÊ®°ÊãüÁ§æ‰ºöÂä®ÊÄÅ              | ‚úÖ    |
| &lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;                                               |                                               |      |
| [Á¨¨ÂçÅÂÖ≠Á´† ÊØï‰∏öËÆæËÆ°](./docs/chapter16/Á¨¨ÂçÅÂÖ≠Á´†%20ÊØï‰∏öËÆæËÆ°.md)                                | ÊûÑÂª∫Â±û‰∫é‰Ω†ÁöÑÂÆåÊï¥Â§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®                  | ‚úÖ    |

### Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ (Community Blog)

&amp;emsp;&amp;emsp;Ê¨¢ËøéÂ§ßÂÆ∂Â∞ÜÂú®Â≠¶‰π† Hello-Agents Êàñ Agent Áõ∏ÂÖ≥ÊäÄÊúØ‰∏≠ÁöÑÁã¨Âà∞ËßÅËß£„ÄÅÂÆûË∑µÊÄªÁªìÔºå‰ª• PR ÁöÑÂΩ¢ÂºèË¥°ÁåÆÂà∞Á§æÂå∫Á≤æÈÄâ„ÄÇÂ¶ÇÊûúÊòØÁã¨Á´ã‰∫éÊ≠£ÊñáÁöÑÂÜÖÂÆπÔºå‰πüÂèØ‰ª•ÊäïÁ®øËá≥ Extra-ChapterÔºÅ&lt;strong&gt;ÊúüÂæÖ‰Ω†ÁöÑÁ¨¨‰∏ÄÊ¨°Ë¥°ÁåÆÔºÅ&lt;/strong&gt;

| Á§æÂå∫Á≤æÈÄâ                                                                                                                                      | ÂÜÖÂÆπÊÄªÁªì                  |
| --------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------- |
| [00-ÂÖ±ÂàõÊØï‰∏öËÆæËÆ°](https://github.com/datawhalechina/hello-agents/blob/main/Co-creation-projects)                                             | Á§æÂå∫ÂÖ±ÂàõÊØï‰∏öËÆæËÆ°È°πÁõÆ      |
| [01-AgentÈù¢ËØïÈ¢òÊÄªÁªì](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra01-Èù¢ËØïÈóÆÈ¢òÊÄªÁªì.md)                          | Agent Â≤ó‰ΩçÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò    |
| [01-AgentÈù¢ËØïÈ¢òÁ≠îÊ°à](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra01-ÂèÇËÄÉÁ≠îÊ°à.md)                              | Áõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢òÁ≠îÊ°à          |
| [02-‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπË°•ÂÖÖ](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra02-‰∏ä‰∏ãÊñáÂ∑•Á®ãË°•ÂÖÖÁü•ËØÜ.md)                 | ‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπÊâ©Â±ï        |
| [03-DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra03-DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊìç‰ΩúÊµÅÁ®ã.md) | DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã  |
| [04-Hello-agentsËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra04-DatawhaleFAQ.md)                 | DatawhaleËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò     |
| [05-Agent Skills‰∏éMCPÂØπÊØîËß£ËØª](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra05-AgentSkillsËß£ËØª.md)             | Agent Skills‰∏éMCPÊäÄÊúØÂØπÊØî |
| [06-GUI AgentÁßëÊôÆ‰∏éÂÆûÊàò](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra06-GUIAgentÁßëÊôÆ‰∏éÂÆûÊàò.md)                | GUI AgentÁßëÊôÆ‰∏éÂ§öÂú∫ÊôØÂÆûÊàò |
| [07-ÁéØÂ¢ÉÈÖçÁΩÆ](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra07-ÁéØÂ¢ÉÈÖçÁΩÆ.md)                | ÁéØÂ¢ÉÈÖçÁΩÆ |
| [08-Â¶Ç‰ΩïÂÜôÂá∫Â•ΩÁöÑSkill](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra08-Â¶Ç‰ΩïÂÜôÂá∫Â•ΩÁöÑSkill.md) | Skill ÂÜô‰ΩúÊúÄ‰Ω≥ÂÆûË∑µ |

### PDF ÁâàÊú¨‰∏ãËΩΩ

&amp;emsp;&amp;emsp;*&lt;strong&gt;Êú¨ Hello-Agents PDF ÊïôÁ®ãÂÆåÂÖ®ÂºÄÊ∫êÂÖçË¥π„ÄÇ‰∏∫Èò≤Ê≠¢ÂêÑÁ±ªËê•ÈîÄÂè∑Âä†Ê∞¥Âç∞ÂêéË¥©ÂçñÁªôÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÂàùÂ≠¶ËÄÖÔºåÊàë‰ª¨ÁâπÂú∞Âú® PDF Êñá‰ª∂‰∏≠È¢ÑÂÖàÊ∑ªÂä†‰∫Ü‰∏çÂΩ±ÂìçÈòÖËØªÁöÑ Datawhale ÂºÄÊ∫êÊ†áÂøóÊ∞¥Âç∞ÔºåÊï¨ËØ∑Ë∞ÖËß£ÔΩû&lt;/strong&gt;*

&gt; *Hello-Agents PDF : https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0*  
&gt; *Hello-Agents PDF ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄ : https://www.datawhale.cn/learn/summary/239* 

## üí° Â¶Ç‰ΩïÂ≠¶‰π†

&amp;emsp;&amp;emsp;Ê¨¢Ëøé‰Ω†ÔºåÊú™Êù•ÁöÑÊô∫ËÉΩÁ≥ªÁªüÊûÑÂª∫ËÄÖÔºÅÂú®ÂºÄÂêØËøôÊÆµÊøÄÂä®‰∫∫ÂøÉÁöÑÊóÖÁ®ã‰πãÂâçÔºåËØ∑ÂÖÅËÆ∏Êàë‰ª¨Áªô‰Ω†‰∏Ä‰∫õÊ∏ÖÊô∞ÁöÑÊåáÂºï„ÄÇ

&amp;emsp;&amp;emsp;Êú¨È°πÁõÆÂÜÖÂÆπÂÖºÈ°æÁêÜËÆ∫‰∏éÂÆûÊàòÔºåÊó®Âú®Â∏ÆÂä©‰Ω†Á≥ªÁªüÊÄßÂú∞ÊéåÊè°‰ªéÂçï‰∏™Êô∫ËÉΩ‰ΩìÂà∞Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂºÄÂèëÂÖ®ÊµÅÁ®ã„ÄÇÂõ†Ê≠§ÔºåÂ∞§ÂÖ∂ÈÄÇÂêàÊúâ‰∏ÄÂÆöÁºñÁ®ãÂü∫Á°ÄÁöÑ &lt;strong&gt;AI ÂºÄÂèëËÄÖ„ÄÅËΩØ‰ª∂Â∑•Á®ãÂ∏à„ÄÅÂú®Ê†°Â≠¶Áîü&lt;/strong&gt; ‰ª•ÂèäÂØπÂâçÊ≤ø AI ÊäÄÊúØÊä±ÊúâÊµìÂéöÂÖ¥Ë∂£ÁöÑ &lt;strong&gt;Ëá™Â≠¶ËÄÖ&lt;/strong&gt;„ÄÇÂú®Â≠¶‰π†Êú¨È°πÁõÆ‰πãÂâçÔºåÊàë‰ª¨Â∏åÊúõ‰Ω†ÂÖ∑Â§áÂü∫Á°ÄÁöÑ Python ÁºñÁ®ãËÉΩÂäõÔºåÂπ∂ÂØπÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊúâÂü∫Êú¨ÁöÑÊ¶ÇÂøµÊÄß‰∫ÜËß£Ôºà‰æãÂ¶ÇÔºåÁü•ÈÅìÂ¶Ç‰ΩïÈÄöËøá API Ë∞ÉÁî®‰∏Ä‰∏™ LLMÔºâ„ÄÇÈ°πÁõÆÁöÑÈáçÁÇπÊòØÂ∫îÁî®‰∏éÊûÑÂª∫ÔºåÂõ†Ê≠§‰Ω†Êó†ÈúÄÂÖ∑Â§áÊ∑±ÂéöÁöÑÁÆóÊ≥ïÊàñÊ®°ÂûãËÆ≠ÁªÉËÉåÊôØ„ÄÇ

&amp;emsp;&amp;emsp;È°πÁõÆÂàÜ‰∏∫‰∫îÂ§ßÈÉ®ÂàÜÔºåÊØè‰∏ÄÈÉ®ÂàÜÈÉΩÊòØÈÄöÂæÄ‰∏ã‰∏ÄÈò∂ÊÆµÁöÑÂùöÂÆûÈò∂Ê¢ØÔºö

- &lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;ÔºàÁ¨¨‰∏ÄÁ´†ÔΩûÁ¨¨‰∏âÁ´†ÔºâÔºåÊàë‰ª¨Â∞Ü‰ªéÊô∫ËÉΩ‰ΩìÁöÑÂÆö‰πâ„ÄÅÁ±ªÂûã‰∏éÂèëÂ±ïÂéÜÂè≤ËÆ≤Ëµ∑Ôºå‰∏∫‰Ω†Ê¢≥ÁêÜ&quot;Êô∫ËÉΩ‰Ωì&quot;Ëøô‰∏ÄÊ¶ÇÂøµÁöÑÊù•ÈæôÂéªËÑâ„ÄÇÈöèÂêéÔºåÊàë‰ª¨‰ºöÂø´ÈÄüÂ∑©Âõ∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ†∏ÂøÉÁü•ËØÜÔºå‰∏∫‰Ω†ÁöÑÂÆûË∑µ‰πãÊóÖÊâì‰∏ãÂùöÂÆûÁöÑÁêÜËÆ∫Âú∞Âü∫„ÄÇ

- &lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;ÔºàÁ¨¨ÂõõÁ´†ÔΩûÁ¨¨‰∏ÉÁ´†ÔºâÔºåËøôÊòØ‰Ω†Âä®ÊâãÂÆûË∑µÁöÑËµ∑ÁÇπ„ÄÇ‰Ω†Â∞Ü‰∫≤ÊâãÂÆûÁé∞ ReAct Á≠âÁªèÂÖ∏ËåÉÂºèÔºå‰ΩìÈ™å Coze Á≠â‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑ‰æøÊç∑ÔºåÂπ∂ÊéåÊè° Langgraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂ÁöÑÂ∫îÁî®„ÄÇÊúÄÁªàÔºåÊàë‰ª¨Ëøò‰ºöÂ∏¶‰Ω†‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫‰∏Ä‰∏™Â±û‰∫éËá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºåËÆ©‰Ω†ÂÖºÂÖ∑‚ÄúÁî®ËΩÆÂ≠ê‚Äù‰∏é‚ÄúÈÄ†ËΩÆÂ≠ê‚ÄùÁöÑËÉΩÂäõ„ÄÇ

- &lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;ÔºàÁ¨¨ÂÖ´Á´†ÔΩûÁ¨¨ÂçÅ‰∫åÁ´†ÔºâÔºåÂú®Ëøô‰∏ÄÈÉ®ÂàÜÔºå‰Ω†ÁöÑÊô∫ËÉΩ‰ΩìÂ∞Ü‚ÄúÂ≠¶‰ºö‚ÄùÊÄùËÄÉ‰∏éÂçè‰Ωú„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®Á¨¨‰∫åÈÉ®ÂàÜÁöÑËá™Á†îÊ°ÜÊû∂ÔºåÊ∑±ÂÖ•Êé¢Á¥¢ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢„ÄÅ‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅAgent ËÆ≠ÁªÉÁ≠âÊ†∏ÂøÉÊäÄÊúØÔºåÂπ∂Â≠¶‰π†Â§öÊô∫ËÉΩ‰ΩìÈó¥ÁöÑÈÄö‰ø°ÂçèËÆÆ„ÄÇÊúÄÁªàÔºå‰Ω†Â∞ÜÊéåÊè°ËØÑ‰º∞Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÊÄßËÉΩÁöÑ‰∏ì‰∏öÊñπÊ≥ï„ÄÇ

- &lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;ÔºàÁ¨¨ÂçÅ‰∏âÁ´†ÔΩûÁ¨¨ÂçÅ‰∫îÁ´†ÔºâÔºåËøôÈáåÊòØÁêÜËÆ∫‰∏éÂÆûË∑µÁöÑ‰∫§Ê±áÁÇπ„ÄÇ‰Ω†Â∞ÜÊääÊâÄÂ≠¶Ëûç‰ºöË¥ØÈÄöÔºå‰∫≤ÊâãÊâìÈÄ†Êô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰ΩìÔºå‰πÉËá≥‰∏Ä‰∏™Ê®°ÊãüÁ§æ‰ºöÂä®ÊÄÅÁöÑËµõÂçöÂ∞èÈïáÔºåÂú®ÁúüÂÆûÊúâË∂£ÁöÑÈ°πÁõÆ‰∏≠Ê∑¨ÁÇº‰Ω†ÁöÑÊûÑÂª∫ËÉΩÂäõ„ÄÇ

- &lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;ÔºàÁ¨¨ÂçÅÂÖ≠Á´†ÔºâÔºåÂú®ÊóÖÁ®ãÁöÑÁªàÁÇπÔºå‰Ω†Â∞ÜËøéÊù•‰∏Ä‰∏™ÊØï‰∏öËÆæËÆ°ÔºåÊûÑÂª∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ„ÄÅÂ±û‰∫é‰Ω†Ëá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®ÔºåÂÖ®Èù¢Ê£ÄÈ™å‰Ω†ÁöÑÂ≠¶‰π†ÊàêÊûú„ÄÇÊàë‰ª¨ËøòÂ∞Ü‰∏é‰Ω†‰∏ÄÂêåÂ±ïÊúõÊô∫ËÉΩ‰ΩìÁöÑÊú™Êù•ÔºåÊé¢Á¥¢ÊøÄÂä®‰∫∫ÂøÉÁöÑÂâçÊ≤øÊñπÂêë„ÄÇ


&amp;emsp;&amp;emsp;Êô∫ËÉΩ‰ΩìÊòØ‰∏Ä‰∏™È£ûÈÄüÂèëÂ±ï‰∏îÊûÅÂ∫¶‰æùËµñÂÆûË∑µÁöÑÈ¢ÜÂüü„ÄÇ‰∏∫‰∫ÜËé∑ÂæóÊúÄ‰Ω≥ÁöÑÂ≠¶‰π†ÊïàÊûúÔºåÊàë‰ª¨Âú®È°πÁõÆÁöÑ`code`Êñá‰ª∂Â§πÂÜÖÊèê‰æõ‰∫ÜÈÖçÂ•óÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºåÂº∫ÁÉàÂª∫ËÆÆ‰Ω†&lt;strong&gt;Â∞ÜÁêÜËÆ∫‰∏éÂÆûË∑µÁõ∏ÁªìÂêà&lt;/strong&gt;„ÄÇËØ∑Âä°ÂøÖ‰∫≤ÊâãËøêË°å„ÄÅË∞ÉËØïÁîöËá≥‰øÆÊîπÈ°πÁõÆÈáåÊèê‰æõÁöÑÊØè‰∏Ä‰ªΩ‰ª£Á†Å„ÄÇÊ¨¢Ëøé‰Ω†ÈöèÊó∂ÂÖ≥Ê≥® Datawhale ‰ª•ÂèäÂÖ∂‰ªñ Agent Áõ∏ÂÖ≥Á§æÂå∫ÔºåÂΩìÈÅáÂà∞ÈóÆÈ¢òÊó∂Ôºå‰Ω†ÂèØ‰ª•ÈöèÊó∂Âú®Êú¨È°πÁõÆÁöÑ issue Âå∫ÊèêÈóÆ„ÄÇ

&amp;emsp;&amp;emsp;Áé∞Âú®ÔºåÂáÜÂ§áÂ•ΩËøõÂÖ•Êô∫ËÉΩ‰ΩìÁöÑÂ•áÂ¶ô‰∏ñÁïå‰∫ÜÂêóÔºüËÆ©Êàë‰ª¨Âç≥ÂàªÂêØÁ®ãÔºÅ

## ‰∏ã‰∏ÄÊ≠•ËßÑÂàí

- ËßÜÈ¢ëËØæÁ®ãÈôÜÁª≠ÊîæÂá∫ÔºàÂ∞Ü‰ºöÊõ¥Âä†ÁªÜËá¥ÔºåÂÆûË∑µËØæÂ∏¶È¢ÜÂ§ßÂÆ∂‰ªéËÆæËÆ°ÊÄùË∑ØÂà∞ÂÆûÊñΩÔºåÊéà‰∫∫‰ª•È±º‰πüÊéà‰∫∫‰ª•Ê∏îÔºâ
- ÂÆåÂñÑHelloAgentsÊ°ÜÊû∂ÔºåÂºÄÂ±ïDevÂàÜÊîØÁªßÁª≠Áª¥Êä§ÔºåÂÖºÂÆπÂ≠¶‰π†ÁâàÊú¨„ÄÇ
- ÊÑüË∞¢Â§ßÂÆ∂Âä©Âäõ2W Star! ËææÂà∞3W StarÂ∞Ü‰ºöÊõ¥Êñ∞Áª≠‰ΩúÔºå„Ää‰ªéÈõ∂ÂºÄÂßãËÆ≠ÁªÉÊô∫ËÉΩ‰Ωì„ÄãÔºåÂ∏ÆÂä©ÊØè‰∏Ä‰∏™Â≠¶‰π†ËÄÖÊéåÊè°‰ªéÈõ∂Âà∞‰∏ÄËÆ≠ÁªÉËá™ÂÆö‰πâÂú∫ÊôØÊô∫ËÉΩ‰ΩìÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇ

## ü§ù Â¶Ç‰ΩïË¥°ÁåÆ

Êàë‰ª¨ÊòØ‰∏Ä‰∏™ÂºÄÊîæÁöÑÂºÄÊ∫êÁ§æÂå∫ÔºåÊ¨¢Ëøé‰ªª‰ΩïÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ

- üêõ &lt;strong&gt;Êä•Âëä Bug&lt;/strong&gt; - ÂèëÁé∞ÂÜÖÂÆπÊàñ‰ª£Á†ÅÈóÆÈ¢òÔºåËØ∑Êèê‰∫§ Issue
- üí° &lt;strong&gt;ÊèêÂá∫Âª∫ËÆÆ&lt;/strong&gt; - ÂØπÈ°πÁõÆÊúâÂ•ΩÊÉ≥Ê≥ïÔºåÊ¨¢ËøéÂèëËµ∑ËÆ®ËÆ∫
- üìù &lt;strong&gt;ÂÆåÂñÑÂÜÖÂÆπ&lt;/strong&gt; - Â∏ÆÂä©ÊîπËøõÊïôÁ®ãÔºåÊèê‰∫§‰Ω†ÁöÑ Pull Request
- ‚úçÔ∏è &lt;strong&gt;ÂàÜ‰∫´ÂÆûË∑µ&lt;/strong&gt; - Âú®&quot;Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ&quot;‰∏≠ÂàÜ‰∫´‰Ω†ÁöÑÂ≠¶‰π†Á¨îËÆ∞ÂíåÈ°πÁõÆ

## üôè Ëá¥Ë∞¢

### Ê†∏ÂøÉË¥°ÁåÆËÄÖ
- [ÈôàÊÄùÂ∑û-È°πÁõÆË¥üË¥£‰∫∫](https://github.com/jjyaoao) (Datawhale ÊàêÂëò, ÂÖ®ÊñáÂÜô‰ΩúÂíåÊ†°ÂØπ)
- [Â≠ôÈü¨-ËÅîÂêàÂèëËµ∑ËÄÖ](https://github.com/fengju0213) (Datawhale ÊàêÂëò„ÄÅCAMEL-AI, Á¨¨‰πùÁ´†ÂÜÖÂÆπÂíåÊ†°ÂØπ)  
- [ÂßúËàíÂá°-ËÅîÂêàÂèëËµ∑ËÄÖ](https://github.com/Tsumugii24)ÔºàDatawhale ÊàêÂëò, Á´†ËäÇ‰π†È¢òËÆæËÆ°ÂíåÊ†°ÂØπÔºâ
- [ÈªÑ‰Ω©Êûó-DatawhaleÊÑèÂêëÊàêÂëò](https://github.com/HeteroCat) (Agent ÂºÄÂèëÂ∑•Á®ãÂ∏à, Á¨¨‰∫îÁ´†ÂÜÖÂÆπË¥°ÁåÆËÄÖ)
- [ÊõæÈë´Ê∞ë-AgentÂ∑•Á®ãÂ∏à](https://github.com/fancyboi999) (ÁâõÂÆ¢ÁßëÊäÄ, Á¨¨ÂçÅÂõõÁ´†Ê°à‰æãÂºÄÂèë)
- [Êú±‰ø°Âø†-ÊåáÂØº‰∏ìÂÆ∂](https://xinzhongzhu.github.io/) (DatawhaleÈ¶ñÂ∏≠ÁßëÂ≠¶ÂÆ∂-ÊµôÊ±üÂ∏àËåÉÂ§ßÂ≠¶Êù≠Â∑û‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂Èô¢ÊïôÊéà)
### Extra-Chapter Ë¥°ÁåÆËÄÖ
- [WH](https://github.com/WHQAQ11) (ÂÜÖÂÆπË¥°ÁåÆËÄÖ)
- [Âë®Â••Êù∞-DWË¥°ÁåÆËÄÖÂõ¢Èòü](https://github.com/thunderbolt-fire) (Ë•øÂÆâ‰∫§ÈÄöÂ§ßÂ≠¶, Extra02 ÂÜÖÂÆπË¥°ÁåÆ)
- [Âº†ÂÆ∏Êó≠-‰∏™‰∫∫ÂºÄÂèëËÄÖ](https://github.com/Tasselszcx)(Â∏ùÂõΩÁêÜÂ∑•Â≠¶Èô¢, Extra03 ÂÜÖÂÆπË¥°ÁåÆ)
- [ÈªÑÂÆèÊôó-DWË¥°ÁåÆËÄÖÂõ¢Èòü](https://github.com/XiaoMa-PM) (Ê∑±Âú≥Â§ßÂ≠¶, Extra04 ÂÜÖÂÆπË¥°ÁåÆ)
- [ÁéãÂ§ßÈπè-DatawhaleÊàêÂëò](https://github.com/ditingdapeng) (È´òÁ∫ßÁ†îÂèëÂ∑•Á®ãÂ∏à, Extra08 ÂÜÖÂÆπË¥°ÁåÆ)

### ÁâπÂà´ÊÑüË∞¢
- ÊÑüË∞¢ [@Sm1les](https://github.com/Sm1les) ÂØπÊú¨È°πÁõÆÁöÑÂ∏ÆÂä©‰∏éÊîØÊåÅ
- ÊÑüË∞¢ÊâÄÊúâ‰∏∫Êú¨È°πÁõÆÂÅöÂá∫Ë¥°ÁåÆÁöÑÂºÄÂèëËÄÖ‰ª¨ ‚ù§Ô∏è

&lt;div align=center style=&quot;margin-top: 30px;&quot;&gt;
  &lt;a href=&quot;https://github.com/datawhalechina/Hello-Agents/graphs/contributors&quot;&gt;
    &lt;img src=&quot;https://contrib.rocks/image?repo=datawhalechina/Hello-Agents&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

## Star History

&lt;div align=&#039;center&#039;&gt;
    &lt;img src=&quot;./docs/images/star-history-2026210.png&quot; alt=&quot;Datawhale&quot; width=&quot;90%&quot;&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;‚≠ê Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ÁªôÊàë‰ª¨‰∏Ä‰∏™ StarÔºÅ&lt;/p&gt;
&lt;/div&gt;

## ËØªËÄÖ‰∫§ÊµÅÁæ§

&lt;div align=&#039;center&#039;&gt;
    &lt;img src=&quot;./ËØªËÄÖÁæ§‰∫åÁª¥Á†Å.png&quot; alt=&quot;ËØªËÄÖÁæ§‰∫åÁª¥Á†Å&quot; width=&quot;30%&quot;&gt;
    &lt;p&gt;Êâ´Êèè‰∫åÁª¥Á†ÅÂä†ÂÖ•ËØªËÄÖ‰∫§ÊµÅÁæ§Ôºå‰∏éÊõ¥Â§öÂ≠¶‰π†ËÄÖ‰∫§ÊµÅËÆ®ËÆ∫&lt;/p&gt;
&lt;/div&gt;

## ÂÖ≥‰∫é Datawhale

&lt;div align=&#039;center&#039;&gt;
    &lt;img src=&quot;./docs/images/datawhale.png&quot; alt=&quot;Datawhale&quot; width=&quot;30%&quot;&gt;
    &lt;p&gt;Êâ´Êèè‰∫åÁª¥Á†ÅÂÖ≥Ê≥® Datawhale ÂÖ¨‰ºóÂè∑ÔºåËé∑ÂèñÊõ¥Â§ö‰ºòË¥®ÂºÄÊ∫êÂÜÖÂÆπ&lt;/p&gt;
&lt;/div&gt;

---

## üìú ÂºÄÊ∫êÂçèËÆÆ

Êú¨‰ΩúÂìÅÈááÁî®[Áü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Áõ∏ÂêåÊñπÂºèÂÖ±‰∫´ 4.0 ÂõΩÈôÖËÆ∏ÂèØÂçèËÆÆ](http://creativecommons.org/licenses/by-nc-sa/4.0/)ËøõË°åËÆ∏ÂèØ„ÄÇ
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[VectifyAI/PageIndex]]></title>
            <link>https://github.com/VectifyAI/PageIndex</link>
            <guid>https://github.com/VectifyAI/PageIndex</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:21 GMT</pubDate>
            <description><![CDATA[üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/VectifyAI/PageIndex">VectifyAI/PageIndex</a></h1>
            <p>üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG</p>
            <p>Language: Python</p>
            <p>Stars: 17,693</p>
            <p>Forks: 1,259</p>
            <p>Stars today: 378 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  
&lt;a href=&quot;https://vectify.ai/pageindex&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/46201e72-675b-43bc-bfbd-081cc6b65a1d&quot; alt=&quot;PageIndex Banner&quot; /&gt;
&lt;/a&gt;

&lt;br/&gt;
&lt;br/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/14736&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14736&quot; alt=&quot;VectifyAI%2FPageIndex | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

# PageIndex: Vectorless, Reasoning-based RAG

&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Reasoning-based RAG&amp;nbsp; ‚ó¶ &amp;nbsp;No Vector DB&amp;nbsp; ‚ó¶ &amp;nbsp;No Chunking&amp;nbsp; ‚ó¶ &amp;nbsp;Human-like Retrieval&lt;/b&gt;&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vectify.ai&quot;&gt;üè† Homepage&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://chat.pageindex.ai&quot;&gt;üñ•Ô∏è Chat Platform&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://pageindex.ai/mcp&quot;&gt;üîå MCP&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://docs.pageindex.ai&quot;&gt;üìö Docs&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://discord.com/invite/VuXuf29EUj&quot;&gt;üí¨ Discord&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://ii2abc2jejf.typeform.com/to/tK3AXl8T&quot;&gt;‚úâÔ∏è Contact&lt;/a&gt;&amp;nbsp;
&lt;/h4&gt;
  
&lt;/div&gt;


&lt;details open&gt;
&lt;summary&gt;&lt;h3&gt;üì¢ Latest Updates&lt;/h3&gt;&lt;/summary&gt;

 **üî• Releases:**
- [**PageIndex Chat**](https://chat.pageindex.ai): The first human-like document-analysis agent [platform](https://chat.pageindex.ai) built for professional long documents. Can also be integrated via [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart) (beta).
&lt;!-- - [**PageIndex Chat API**](https://docs.pageindex.ai/quickstart): An API that brings PageIndex&#039;s advanced long-document intelligence directly into your applications and workflows. --&gt;
&lt;!-- - [PageIndex MCP](https://pageindex.ai/mcp): Bring PageIndex into Claude, Cursor, or any MCP-enabled agent. Chat with long PDFs in a reasoning-based, human-like way. --&gt;
 
 **üìù Articles:**
- [**PageIndex Framework**](https://pageindex.ai/blog/pageindex-intro): Introduces the PageIndex framework ‚Äî an *agentic, in-context* *tree index* that enables LLMs to perform *reasoning-based*, *human-like retrieval* over long documents, without vector DB or chunking.
&lt;!-- - [Do We Still Need OCR?](https://pageindex.ai/blog/do-we-need-ocr): Explores how vision-based, reasoning-native RAG challenges the traditional OCR pipeline, and why the future of document AI might be *vectorless* and *vision-based*. --&gt;

 **üß™ Cookbooks:**
- [Vectorless RAG](https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex): A minimal, hands-on example of reasoning-based RAG using PageIndex. No vectors, no chunking, and human-like retrieval.
- [Vision-based Vectorless RAG](https://docs.pageindex.ai/cookbook/vision-rag-pageindex): OCR-free, vision-only RAG with PageIndex&#039;s reasoning-native retrieval workflow that works directly over PDF page images.
&lt;/details&gt;

---

# üìë Introduction to PageIndex

Are you frustrated with vector database retrieval accuracy for long professional documents? Traditional vector-based RAG relies on semantic *similarity* rather than true *relevance*. But **similarity ‚â† relevance** ‚Äî what we truly need in retrieval is **relevance**, and that requires **reasoning**. When working with professional documents that demand domain expertise and multi-step reasoning, similarity search often falls short.

Inspired by AlphaGo, we propose **[PageIndex](https://vectify.ai/pageindex)** ‚Äî a **vectorless**, **reasoning-based RAG** system that builds a **hierarchical tree index** from long documents and uses LLMs to **reason** *over that index* for **agentic, context-aware retrieval**.
It simulates how *human experts* navigate and extract knowledge from complex documents through *tree search*, enabling LLMs to *think* and *reason* their way to the most relevant document sections. PageIndex performs retrieval in two steps:

1. Generate a ‚ÄúTable-of-Contents‚Äù **tree structure index** of documents
2. Perform reasoning-based retrieval through **tree search**

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pageindex.ai/blog/pageindex-intro&quot; target=&quot;_blank&quot; title=&quot;The PageIndex Framework&quot;&gt;
    &lt;img src=&quot;https://docs.pageindex.ai/images/cookbook/vectorless-rag.png&quot; width=&quot;70%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

### üéØ Core Features 

Compared to traditional vector-based RAG, **PageIndex** features:
- **No Vector DB**: Uses document structure and LLM reasoning for retrieval, instead of vector similarity search.
- **No Chunking**: Documents are organized into natural sections, not artificial chunks.
- **Human-like Retrieval**: Simulates how human experts navigate and extract knowledge from complex documents.
- **Better Explainability and Traceability**: Retrieval is based on reasoning ‚Äî traceable and interpretable, with page and section references. No more opaque, approximate vector search (‚Äúvibe retrieval‚Äù).

PageIndex powers a reasoning-based RAG system that achieved **state-of-the-art** [98.7% accuracy](https://github.com/VectifyAI/Mafin2.5-FinanceBench) on FinanceBench, demonstrating superior performance over vector-based RAG solutions in professional document analysis (see our [blog post](https://vectify.ai/blog/Mafin2.5) for details).

### üìç Explore PageIndex

To learn more, please see a detailed introduction of the [PageIndex framework](https://pageindex.ai/blog/pageindex-intro). Check out this GitHub repo for open-source code, and the [cookbooks](https://docs.pageindex.ai/cookbook), [tutorials](https://docs.pageindex.ai/tutorials), and [blog](https://pageindex.ai/blog) for additional usage guides and examples. 

The PageIndex service is available as a ChatGPT-style [chat platform](https://chat.pageindex.ai), or can be integrated via [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart).

### üõ†Ô∏è Deployment Options
- Self-host ‚Äî run locally with this open-source repo.
- Cloud Service ‚Äî try instantly with our [Chat Platform](https://chat.pageindex.ai/), or integrate with [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart).
- _Enterprise_ ‚Äî private or on-prem deployment. [Contact us](https://ii2abc2jejf.typeform.com/to/tK3AXl8T) or [book a demo](https://calendly.com/pageindex/meet) for more details.

### üß™ Quick Hands-on

- Try the [**Vectorless RAG**](https://github.com/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb) notebook ‚Äî a *minimal*, hands-on example of reasoning-based RAG using PageIndex.
- Experiment with [*Vision-based Vectorless RAG*](https://github.com/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb) ‚Äî no OCR; a minimal, reasoning-native RAG pipeline that works directly over page images.
  
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Open_In_Colab-Vectorless_RAG-orange?style=for-the-badge&amp;logo=googlecolab&quot; alt=&quot;Open in Colab: Vectorless RAG&quot; /&gt;
  &lt;/a&gt;
  &amp;nbsp;&amp;nbsp;
  &lt;a href=&quot;https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Open_In_Colab-Vision_RAG-orange?style=for-the-badge&amp;logo=googlecolab&quot; alt=&quot;Open in Colab: Vision RAG&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

---

# üå≤ PageIndex Tree Structure
PageIndex can transform lengthy PDF documents into a semantic **tree structure**, similar to a _&quot;table of contents&quot;_ but optimized for use with Large Language Models (LLMs). It&#039;s ideal for: financial reports, regulatory filings, academic textbooks, legal or technical manuals, and any document that exceeds LLM context limits.

Below is an example PageIndex tree structure. Also see more example [documents](https://github.com/VectifyAI/PageIndex/tree/main/tests/pdfs) and generated [tree structures](https://github.com/VectifyAI/PageIndex/tree/main/tests/results).

```jsonc
...
{
  &quot;title&quot;: &quot;Financial Stability&quot;,
  &quot;node_id&quot;: &quot;0006&quot;,
  &quot;start_index&quot;: 21,
  &quot;end_index&quot;: 22,
  &quot;summary&quot;: &quot;The Federal Reserve ...&quot;,
  &quot;nodes&quot;: [
    {
      &quot;title&quot;: &quot;Monitoring Financial Vulnerabilities&quot;,
      &quot;node_id&quot;: &quot;0007&quot;,
      &quot;start_index&quot;: 22,
      &quot;end_index&quot;: 28,
      &quot;summary&quot;: &quot;The Federal Reserve&#039;s monitoring ...&quot;
    },
    {
      &quot;title&quot;: &quot;Domestic and International Cooperation and Coordination&quot;,
      &quot;node_id&quot;: &quot;0008&quot;,
      &quot;start_index&quot;: 28,
      &quot;end_index&quot;: 31,
      &quot;summary&quot;: &quot;In 2023, the Federal Reserve collaborated ...&quot;
    }
  ]
}
...
```

You can generate the PageIndex tree structure with this open-source repo, or use our [API](https://docs.pageindex.ai/quickstart) 

---

# ‚öôÔ∏è Package Usage

You can follow these steps to generate a PageIndex tree from a PDF document.

### 1. Install dependencies

```bash
pip3 install --upgrade -r requirements.txt
```

### 2. Set your OpenAI API key

Create a `.env` file in the root directory and add your API key:

```bash
CHATGPT_API_KEY=your_openai_key_here
```

### 3. Run PageIndex on your PDF

```bash
python3 run_pageindex.py --pdf_path /path/to/your/document.pdf
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Optional parameters&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;
You can customize the processing with additional optional arguments:

```
--model                 OpenAI model to use (default: gpt-4o-2024-11-20)
--toc-check-pages       Pages to check for table of contents (default: 20)
--max-pages-per-node    Max pages per node (default: 10)
--max-tokens-per-node   Max tokens per node (default: 20000)
--if-add-node-id        Add node ID (yes/no, default: yes)
--if-add-node-summary   Add node summary (yes/no, default: yes)
--if-add-doc-description Add doc description (yes/no, default: yes)
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Markdown support&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;
We also provide markdown support for PageIndex. You can use the `-md_path` flag to generate a tree structure for a markdown file.

```bash
python3 run_pageindex.py --md_path /path/to/your/document.md
```

&gt; Note: in this function, we use &quot;#&quot; to determine node heading and their levels. For example, &quot;##&quot; is level 2, &quot;###&quot; is level 3, etc. Make sure your markdown file is formatted correctly. If your Markdown file was converted from a PDF or HTML, we don&#039;t recommend using this function, since most existing conversion tools cannot preserve the original hierarchy. Instead, use our [PageIndex OCR](https://pageindex.ai/blog/ocr), which is designed to preserve the original hierarchy, to convert the PDF to a markdown file and then use this function.
&lt;/details&gt;

&lt;!-- 
# ‚òÅÔ∏è Improved Tree Generation with PageIndex OCR

This repo is designed for generating PageIndex tree structure for simple PDFs, but many real-world use cases involve complex PDFs that are hard to parse by classic Python tools. However, extracting high-quality text from PDF documents remains a non-trivial challenge. Most OCR tools only extract page-level content, losing the broader document context and hierarchy.

To address this, we introduced PageIndex OCR ‚Äî the first long-context OCR model designed to preserve the global structure of documents. PageIndex OCR significantly outperforms other leading OCR tools, such as those from Mistral and Contextual AI, in recognizing true hierarchy and semantic relationships across document pages.

- Experience next-level OCR quality with PageIndex OCR at our [Dashboard](https://dash.pageindex.ai/).
- Integrate PageIndex OCR seamlessly into your stack via our [API](https://docs.pageindex.ai/quickstart).

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/eb35d8ae-865c-4e60-a33b-ebbd00c41732&quot; width=&quot;80%&quot;&gt;
&lt;/p&gt;
--&gt;

---

# üìà Case Study: PageIndex Leads Finance QA Benchmark

[Mafin 2.5](https://vectify.ai/mafin) is a reasoning-based RAG system for financial document analysis, powered by **PageIndex**. It achieved a state-of-the-art [**98.7% accuracy**](https://vectify.ai/blog/Mafin2.5) on the [FinanceBench](https://arxiv.org/abs/2311.11944) benchmark, significantly outperforming traditional vector-based RAG systems.

PageIndex&#039;s hierarchical indexing and reasoning-driven retrieval enable precise navigation and extraction of relevant context from complex financial reports, such as SEC filings and earnings disclosures.

Explore the full [benchmark results](https://github.com/VectifyAI/Mafin2.5-FinanceBench) and our [blog post](https://vectify.ai/blog/Mafin2.5) for detailed comparisons and performance metrics.

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/VectifyAI/Mafin2.5-FinanceBench&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/571aa074-d803-43c7-80c4-a04254b782a3&quot; width=&quot;70%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

---

# üß≠ Resources

* üß™ [Cookbooks](https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex): hands-on, runnable examples and advanced use cases.
* üìñ [Tutorials](https://docs.pageindex.ai/doc-search): practical guides and strategies, including *Document Search* and *Tree Search*.
* üìù [Blog](https://pageindex.ai/blog): technical articles, research insights, and product updates.
* üîå [MCP setup](https://pageindex.ai/mcp#quick-setup) &amp; [API docs](https://docs.pageindex.ai/quickstart): integration details and configuration options.

---

# ‚≠ê Support Us
Please cite this work as:
```
Mingtian Zhang, Yu Tang and PageIndex Team,
&quot;PageIndex: Next-Generation Vectorless, Reasoning-based RAG&quot;,
PageIndex Blog, Sep 2025.
```

Or use the BibTeX citation:

```
@article{zhang2025pageindex,
  author = {Mingtian Zhang and Yu Tang and PageIndex Team},
  title = {PageIndex: Next-Generation Vectorless, Reasoning-based RAG},
  journal = {PageIndex Blog},
  year = {2025},
  month = {September},
  note = {https://pageindex.ai/blog/pageindex-intro},
}
```

Leave us a star üåü if you like our project. Thank you!  

&lt;p&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/eae4ff38-48ae-4a7c-b19f-eab81201d794&quot; width=&quot;80%&quot;&gt;
&lt;/p&gt;

### Connect with Us

[![Twitter](https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white)](https://x.com/PageIndexAI)&amp;nbsp;
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/vectify-ai/)&amp;nbsp;
[![Discord](https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.com/invite/VuXuf29EUj)&amp;nbsp;
[![Contact Us](https://img.shields.io/badge/Contact_Us-3B82F6?style=for-the-badge&amp;logo=envelope&amp;logoColor=white)](https://ii2abc2jejf.typeform.com/to/tK3AXl8T)

---

¬© 2025 [Vectify AI](https://vectify.ai)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[NevaMind-AI/memU]]></title>
            <link>https://github.com/NevaMind-AI/memU</link>
            <guid>https://github.com/NevaMind-AI/memU</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:20 GMT</pubDate>
            <description><![CDATA[Memory for 24/7 proactive agents like openclaw (moltbot, clawdbot).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NevaMind-AI/memU">NevaMind-AI/memU</a></h1>
            <p>Memory for 24/7 proactive agents like openclaw (moltbot, clawdbot).</p>
            <p>Language: Python</p>
            <p>Stars: 10,776</p>
            <p>Forks: 790</p>
            <p>Stars today: 187 stars today</p>
            <h2>README</h2><pre>![MemU Banner](assets/banner.png)

&lt;div align=&quot;center&quot;&gt;

# memU

### 24/7 Always-On Proactive Memory for AI Agents

[![PyPI version](https://badge.fury.io/py/memu-py.svg)](https://badge.fury.io/py/memu-py)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![Discord](https://img.shields.io/badge/Discord-Join%20Chat-5865F2?logo=discord&amp;logoColor=white)](https://discord.gg/memu)
[![Twitter](https://img.shields.io/badge/Twitter-Follow-1DA1F2?logo=x&amp;logoColor=white)](https://x.com/memU_ai)

&lt;a href=&quot;https://trendshift.io/repositories/17374&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/17374&quot; alt=&quot;NevaMind-AI%2FmemU | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

**[English](readme/README_en.md) | [‰∏≠Êñá](readme/README_zh.md) | [Êó•Êú¨Ë™û](readme/README_ja.md) | [ÌïúÍµ≠Ïñ¥](readme/README_ko.md) | [Espa√±ol](readme/README_es.md) | [Fran√ßais](readme/README_fr.md)**

&lt;/div&gt;

---

memU is a memory framework built for **24/7 proactive agents**.
It is designed for long-running use and greatly **reduces the LLM token cost** of keeping agents always online, making always-on, evolving agents practical in production systems.
memU **continuously captures and understands user intent**. Even without a command, the agent can tell what you are about to do and act on it by itself.

---

## ü§ñ [OpenClaw (Moltbot, Clawdbot) Alternative](https://memu.bot)

&lt;img width=&quot;100%&quot; src=&quot;https://github.com/NevaMind-AI/memU/blob/main/assets/memUbot.png&quot; /&gt;

- **Download-and-use and simple** to get started.
- Builds long-term memory to **understand user intent** and act proactively.
- **Cuts LLM token cost** with smaller context.

Try now: [memU bot](https://memu.bot)

---

## üóÉÔ∏è Memory as File System, File System as Memory

memU treats **memory like a file system**‚Äîstructured, hierarchical, and instantly accessible.

| File System | memU Memory |
|-------------|-------------|
| üìÅ Folders | üè∑Ô∏è Categories (auto-organized topics) |
| üìÑ Files | üß† Memory Items (extracted facts, preferences, skills) |
| üîó Symlinks | üîÑ Cross-references (related memories linked) |
| üìÇ Mount points | üì• Resources (conversations, documents, images) |

**Why this matters:**
- **Navigate memories** like browsing directories‚Äîdrill down from broad categories to specific facts
- **Mount new knowledge** instantly‚Äîconversations and documents become queryable memory
- **Cross-link everything**‚Äîmemories reference each other, building a connected knowledge graph
- **Persistent &amp; portable**‚Äîexport, backup, and transfer memory like files

```
memory/
‚îú‚îÄ‚îÄ preferences/
‚îÇ   ‚îú‚îÄ‚îÄ communication_style.md
‚îÇ   ‚îî‚îÄ‚îÄ topic_interests.md
‚îú‚îÄ‚îÄ relationships/
‚îÇ   ‚îú‚îÄ‚îÄ contacts/
‚îÇ   ‚îî‚îÄ‚îÄ interaction_history/
‚îú‚îÄ‚îÄ knowledge/
‚îÇ   ‚îú‚îÄ‚îÄ domain_expertise/
‚îÇ   ‚îî‚îÄ‚îÄ learned_skills/
‚îî‚îÄ‚îÄ context/
    ‚îú‚îÄ‚îÄ recent_conversations/
    ‚îî‚îÄ‚îÄ pending_tasks/
```

Just as a file system turns raw bytes into organized data, memU transforms raw interactions into **structured, searchable, proactive intelligence**.

---

## ‚≠êÔ∏è Star the repository

&lt;img width=&quot;100%&quot; src=&quot;https://github.com/NevaMind-AI/memU/blob/main/assets/star.gif&quot; /&gt;
If you find memU useful or interesting, a GitHub Star ‚≠êÔ∏è would be greatly appreciated.

---


## ‚ú® Core Features

| Capability | Description |
|------------|-------------|
| ü§ñ **24/7 Proactive Agent** | Always-on memory agent that works continuously in the background‚Äînever sleeps, never forgets |
| üéØ **User Intention Capture** | Understands and remembers user goals, preferences, and context across sessions automatically |
| üí∞ **Cost Efficient** | Reduces long-running token costs by caching insights and avoiding redundant LLM calls |
---

## üîÑ How Proactive Memory Works

```bash

cd examples/proactive
python proactive.py

```

---

### Proactive Memory Lifecycle
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                         USER QUERY                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ                                                           ‚îÇ
                 ‚ñº                                                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ü§ñ MAIN AGENT                  ‚îÇ         ‚îÇ              üß† MEMU BOT                       ‚îÇ
‚îÇ                                        ‚îÇ         ‚îÇ                                                ‚îÇ
‚îÇ  Handle user queries &amp; execute tasks   ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  Monitor, memorize &amp; proactive intelligence   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                        ‚îÇ         ‚îÇ                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  1. RECEIVE USER INPUT           ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  1. MONITOR INPUT/OUTPUT                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Parse query, understand      ‚îÇ  ‚îÇ   ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  ‚îÇ     Observe agent interactions           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     context and intent           ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ     Track conversation flow              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  2. PLAN &amp; EXECUTE               ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  2. MEMORIZE &amp; EXTRACT                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Break down tasks             ‚îÇ  ‚îÇ   ‚óÑ‚îÄ‚îÄ‚îÄ  ‚îÇ  ‚îÇ     Store insights, facts, preferences   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Call tools, retrieve data    ‚îÇ  ‚îÇ  inject ‚îÇ  ‚îÇ     Extract skills &amp; knowledge           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Generate responses           ‚îÇ  ‚îÇ  memory ‚îÇ  ‚îÇ     Update user profile                  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  3. RESPOND TO USER              ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  3. PREDICT USER INTENT                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Deliver answer/result        ‚îÇ  ‚îÇ   ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  ‚îÇ     Anticipate next steps                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Continue conversation        ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ     Identify upcoming needs              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  4. LOOP                         ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  4. RUN PROACTIVE TASKS                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Wait for next user input     ‚îÇ  ‚îÇ   ‚óÑ‚îÄ‚îÄ‚îÄ  ‚îÇ  ‚îÇ     Pre-fetch relevant context           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     or proactive suggestions     ‚îÇ  ‚îÇ  suggest‚îÇ  ‚îÇ     Prepare recommendations              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îÇ     Update todolist autonomously         ‚îÇ  ‚îÇ
‚îÇ                                        ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ                                                           ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚ñº
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ     CONTINUOUS SYNC LOOP     ‚îÇ
                              ‚îÇ  Agent ‚óÑ‚îÄ‚îÄ‚ñ∫ MemU Bot ‚óÑ‚îÄ‚îÄ‚ñ∫ DB ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Proactive Use Cases

### 1. **Information Recommendation**
*Agent monitors interests and proactively surfaces relevant content*
```python
# User has been researching AI topics
MemU tracks: reading history, saved articles, search queries

# When new content arrives:
Agent: &quot;I found 3 new papers on RAG optimization that align with
        your recent research on retrieval systems. One author
        (Dr. Chen) you&#039;ve cited before published yesterday.&quot;

# Proactive behaviors:
- Learns topic preferences from browsing patterns
- Tracks author/source credibility preferences
- Filters noise based on engagement history
- Times recommendations for optimal attention
```

### 2. **Email Management**
*Agent learns communication patterns and handles routine correspondence*
```python
# MemU observes email patterns over time:
- Response templates for common scenarios
- Priority contacts and urgent keywords
- Scheduling preferences and availability
- Writing style and tone variations

# Proactive email assistance:
Agent: &quot;You have 12 new emails. I&#039;ve drafted responses for 3 routine
        requests and flagged 2 urgent items from your priority contacts.
        Should I also reschedule tomorrow&#039;s meeting based on the
        conflict John mentioned?&quot;

# Autonomous actions:
‚úì Draft context-aware replies
‚úì Categorize and prioritize inbox
‚úì Detect scheduling conflicts
‚úì Summarize long threads with key decisions
```

### 3. **Trading &amp; Financial Monitoring**
*Agent tracks market context and user investment behavior*
```python
# MemU learns trading preferences:
- Risk tolerance from historical decisions
- Preferred sectors and asset classes
- Response patterns to market events
- Portfolio rebalancing triggers

# Proactive alerts:
Agent: &quot;NVDA dropped 5% in after-hours trading. Based on your past
        behavior, you typically buy tech dips above 3%. Your current
        allocation allows for $2,000 additional exposure while
        maintaining your 70/30 equity-bond target.&quot;

# Continuous monitoring:
- Track price alerts tied to user-defined thresholds
- Correlate news events with portfolio impact
- Learn from executed vs. ignored recommendations
- Anticipate tax-loss harvesting opportunities
```


...

---

## üóÇÔ∏è Hierarchical Memory Architecture

MemU&#039;s three-layer system enables both **reactive queries** and **proactive context loading**:

&lt;img width=&quot;100%&quot; alt=&quot;structure&quot; src=&quot;assets/structure.png&quot; /&gt;

| Layer | Reactive Use | Proactive Use |
|-------|--------------|---------------|
| **Resource** | Direct access to original data | Background monitoring for new patterns |
| **Item** | Targeted fact retrieval | Real-time extraction from ongoing interactions |
| **Category** | Summary-level overview | Automatic context assembly for anticipation |

**Proactive Benefits:**
- **Auto-categorization**: New memories self-organize into topics
- **Pattern Detection**: System identifies recurring themes
- **Context Prediction**: Anticipates what information will be needed next

---

## üöÄ Quick Start

### Option 1: Cloud Version

Experience proactive memory instantly:

üëâ **[memu.so](https://memu.so)** - Hosted service with 7√ó24 continuous learning

For enterprise deployment with custom proactive workflows, contact **info@nevamind.ai**

#### Cloud API (v3)

| Base URL | `https://api.memu.so` |
|----------|----------------------|
| Auth | `Authorization: Bearer YOUR_API_KEY` |

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v3/memory/memorize` | Register continuous learning task |
| `GET` | `/api/v3/memory/memorize/status/{task_id}` | Check real-time processing status |
| `POST` | `/api/v3/memory/categories` | List auto-generated categories |
| `POST` | `/api/v3/memory/retrieve` | Query memory (supports proactive context loading) |

üìö **[Full API Documentation](https://memu.pro/docs#cloud-version)**

---

### Option 2: Self-Hosted

#### Installation
```bash
pip install -e .
```

#### Basic Example

&gt; **Requirements**: Python 3.13+ and an OpenAI API key

**Test Continuous Learning** (in-memory):
```bash
export OPENAI_API_KEY=your_api_key
cd tests
python test_inmemory.py
```

**Test with Persistent Storage** (PostgreSQL):
```bash
# Start PostgreSQL with pgvector
docker run -d \
  --name memu-postgres \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=memu \
  -p 5432:5432 \
  pgvector/pgvector:pg16

# Run continuous learning test
export OPENAI_API_KEY=your_api_key
cd tests
python test_postgres.py
```

Both examples demonstrate **proactive memory workflows**:
1. **Continuous Ingestion**: Process multiple files sequentially
2. **Auto-Extraction**: Immediate memory creation
3. **Proactive Retrieval**: Context-aware memory surfacing

See [`tests/test_inmemory.py`](tests/test_inmemory.py) and [`tests/test_postgres.py`](tests/test_postgres.py) for implementation details.

---

### Custom LLM and Embedding Providers

MemU supports custom LLM and embedding providers beyond OpenAI. Configure them via `llm_profiles`:
```python
from memu import MemUService

service = MemUService(
    llm_profiles={
        # Default profile for LLM operations
        &quot;default&quot;: {
            &quot;base_url&quot;: &quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,
            &quot;api_key&quot;: &quot;your_api_key&quot;,
            &quot;chat_model&quot;: &quot;qwen3-max&quot;,
            &quot;client_backend&quot;: &quot;sdk&quot;  # &quot;sdk&quot; or &quot;http&quot;
        },
        # Separate profile for embeddings
        &quot;embedding&quot;: {
            &quot;base_url&quot;: &quot;https://api.voyageai.com/v1&quot;,
            &quot;api_key&quot;: &quot;your_voyage_api_key&quot;,
            &quot;embed_model&quot;: &quot;voyage-3.5-lite&quot;
        }
    },
    # ... other configuration
)
```

---

### OpenRouter Integration

MemU supports [OpenRouter](https://openrouter.ai) as a model provider, giving you access to multiple LLM providers through a single API.

#### Configuration
```python
from memu import MemoryService

service = MemoryService(
    llm_profiles={
        &quot;default&quot;: {
            &quot;provider&quot;: &quot;openrouter&quot;,
            &quot;client_backend&quot;: &quot;httpx&quot;,
            &quot;base_url&quot;: &quot;https://openrouter.ai&quot;,
            &quot;api_key&quot;: &quot;your_openrouter_api_key&quot;,
            &quot;chat_model&quot;: &quot;anthropic/claude-3.5-sonnet&quot;,  # Any OpenRouter model
            &quot;embed_model&quot;: &quot;openai/text-embedding-3-small&quot;,  # Embedding model
        },
    },
    database_config={
        &quot;metadata_store&quot;: {&quot;provider&quot;: &quot;inmemory&quot;},
    },
)
```

#### Environment Variables

| Variable | Description |
|----------|-------------|
| `OPENROUTER_API_KEY` | Your OpenRouter API key from [openrouter.ai/keys](https://openrouter.ai/keys) |

#### Supported Features

| Feature | Status | Notes |
|---------|--------|-------|
| Chat Completions | Supported | Works with any OpenRouter chat model |
| Embeddings | Supported | Use OpenAI embedding models via OpenRouter |
| Vision | Supported | Use vision-capable models (e.g., `openai/gpt-4o`) |

#### Running OpenRouter Tests
```bash
export OPENROUTER_API_KEY=your_api_key

# Full workflow test (memorize + retrieve)
python tests/test_openrouter.py

# Embedding-specific tests
python tests/test_openrouter_embedding.py

# Vision-specific tests
python tests/test_openrouter_vision.py
```

See [`examples/example_4_openrouter_memory.py`](examples/example_4_openrouter_memory.py) for a complete working example.

---

## üìñ Core APIs

### `memorize()` - Continuous Learning Pipeline

Processes inputs in real-time and immediately updates memory:

&lt;img width=&quot;100%&quot; alt=&quot;memorize&quot; src=&quot;assets/memorize.png&quot; /&gt;

```python
result = await service.memorize(
    resource_url=&quot;path/to/file.json&quot;,  # File path or URL
    modality=&quot;conversation&quot;,            # conversation | document | image | video | audio
    user={&quot;user_id&quot;: &quot;123&quot;}             # Optional: scope to a user
)

# Returns immediately with extracted memory:
{
    &quot;resource&quot;: {...},      # Stored resource metadata
    &quot;items&quot;: [...],         # Extracted memory items (available instantly)
    &quot;categories&quot;: [...]     # Auto-updated category structure
}
```

**Proactive Features:**
- Zero-delay processing‚Äîmemories available immediately
- Automatic categorization without manual tagging
- Cross-reference with existing memories for pattern detection

### `retrieve()` - Dual-Mode Intelligence

MemU supports both **proactive context loading** and **reactive querying**:

&lt;img width=&quot;100%&quot; alt=&quot;retrieve&quot; src=&quot;assets/retrieve.png&quot; /&gt;

#### RAG-based Retrieval (`method=&quot;rag&quot;`)

Fast **proactive context assembly** using embeddings:

- ‚úÖ **Instant context**: Sub-second memory surfacing
- ‚úÖ **Background monitoring**: Can run continuously without LLM costs
- ‚úÖ **Similarity scoring**: Identifies most relevant memories automatically

#### LLM-based Retrieval (`method=&quot;llm&quot;`)

Deep **anticipatory reasoning** for complex contexts:

- ‚úÖ **Intent prediction**: LLM infers what user needs before they ask
- ‚úÖ **Query evolution**: Automatically refines search as context develops
- ‚úÖ **Early termination**: Stops when sufficient context is gathered

#### Comparison

| Aspect | RAG (Fast Context) | LLM (Deep Reasoning) |
|--------|-------------------|---------------------|
| **Speed** | ‚ö° Milliseconds | üê¢ Seconds |
| **Cost** | üí∞ Embedding only | üí∞üí∞ LLM inference |
| **Proactive use** | Continuous monitoring | Triggered context loading |
| **Best for** | Real-time suggestions | Complex anticipation |

#### Usage
```python
# Proactive retrieval with context history
result = await service.retrieve(
    queries=[
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: {&quot;text&quot;: &quot;What are their preferences?&quot;}},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: {&quot;text&quot;: &quot;Tell me about work habits&quot;}}
    ],
    where={&quot;user_id&quot;: &quot;123&quot;},  # Optional: scope filter
    method=&quot;rag&quot;  # or &quot;llm&quot; for deeper reasoning
)

# Returns context-aware results:
{
    &quot;categories&quot;: [...],     # Relevant topic areas (auto-prioritized)
    &quot;items&quot;: [...],          # Specific memory facts
    &quot;resources&quot;: [...],      # Original sources for traceability
    &quot;next_step_query&quot;: &quot;...&quot; # Predicted follow-up context
}
```

**Proactive Filtering**: Use `where` to scope continuous monitoring:
- `where={&quot;user_id&quot;: &quot;123&quot;}` - User-specific context
- `where={&quot;agent_id__in&quot;: [&quot;1&quot;, &quot;2&quot;]}` - Multi-agent coordination
- Omit `where` for global context awareness

---

## üí° Proactive Scenarios

### Example 1: Always-Learning Assistant

Continuously learns from every interaction without explicit memory commands:
```bash
export OPENAI_API_KEY=your_api_key
python examples/example_1_conversation_memory.py
```

**Proactive Behavior:**
- Automatically extracts preferences from casual mentions
- Builds relationship models from interaction patterns
- Surfaces relevant context in future conversations
- Adapts communication style based on learned preferences

**Best for:** Personal AI assistants, customer support that remembers, social chatbots

---

### Example 2: Self-Improving Agent

Learns from execution logs and proactively suggests optimizations:
```bash
export OPENAI_API_KEY=your_api_key
python examples/example_2_skill_extraction.py
```

**Proactive Behavior:**
- Monitors agent actions and outcomes continuously
- Identifies patterns in successes and failures
- Auto-generates skill guides from experience
- Proactively suggests strategies for similar future tasks

**Best for:** DevOps automation, agent self-improvement, knowledge capture

---

### Example 3: Multimodal Context Builder

Unifies memory across different input types for comprehensive context:
```bash
export OPENAI

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[NVIDIA/Megatron-LM]]></title>
            <link>https://github.com/NVIDIA/Megatron-LM</link>
            <guid>https://github.com/NVIDIA/Megatron-LM</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:19 GMT</pubDate>
            <description><![CDATA[Ongoing research training transformer models at scale]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NVIDIA/Megatron-LM">NVIDIA/Megatron-LM</a></h1>
            <p>Ongoing research training transformer models at scale</p>
            <p>Language: Python</p>
            <p>Stars: 15,345</p>
            <p>Forks: 3,627</p>
            <p>Stars today: 10 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

Megatron-LM and Megatron Core
=============================

&lt;h4&gt;GPU-optimized library for training transformer models at scale&lt;/h4&gt;

[![Documentation](https://img.shields.io/badge/docs-latest-brightgreen.svg?style=flat)](https://docs.nvidia.com/megatron-core/developer-guide/latest/index.html)
[![version](https://img.shields.io/badge/release-0.15.0-green)](./CHANGELOG.md)
[![license](https://img.shields.io/badge/license-Apache-blue)](./LICENSE)

&lt;div align=&quot;left&quot;&gt;

## About

This repository contains two components: **Megatron-LM** and **Megatron Core**.

**Megatron-LM** is a reference example that includes Megatron Core plus pre-configured training scripts. Best for research teams, learning distributed training, and quick experimentation.

**Megatron Core** is a composable library with GPU-optimized building blocks for custom training frameworks. It provides transformer building blocks, advanced parallelism strategies (TP, PP, DP, EP, CP), mixed precision support (FP16, BF16, FP8, FP4), and model architectures. Best for framework developers and ML engineers building custom training pipelines.

**[Megatron Bridge](https://github.com/NVIDIA-NeMo/Megatron-Bridge)** provides bidirectional Hugging Face ‚Üî Megatron checkpoint conversion with production-ready recipes.


## Quick Start

Install Megatron Core with pip:

1. Install Megatron Core with required dependencies:

    ```bash
    pip install --no-build-isolation megatron-core[mlm,dev]
    ```

2. Clone repository for examples:

    ```bash
    git clone https://github.com/NVIDIA/Megatron-LM.git
    cd Megatron-LM
    pip install --no-build-isolation .[mlm,dev]
    ```


# Latest News

- **[2026/01]** **[Dynamic Context Parallelism](https://developer.nvidia.com/blog/speeding-up-variable-length-training-with-dynamic-context-parallelism-and-nvidia-megatron-core/)** - Up to 1.48x speedup for variable-length sequence training with adaptive CP sizing.
- **[2025/12]** **Megatron Core development has moved to GitHub!** All development and CI now happens in the open. We welcome community contributions.
- **[2025/10]** **[Megatron Dev Branch](https://github.com/NVIDIA/Megatron-LM/tree/dev)** - early access branch with experimental features.
- **[2025/10]** **[Megatron Bridge](https://github.com/NVIDIA-NeMo/Megatron-Bridge)** - Bidirectional converter for interoperability between Hugging Face and Megatron checkpoints, featuring production-ready recipes for popular models.
- **[2025/08]** **[MoE Q3-Q4 2025 Roadmap](https://github.com/NVIDIA/Megatron-LM/issues/1729)** - Comprehensive roadmap for MoE features including DeepSeek-V3, Qwen3, advanced parallelism strategies, FP8 optimizations, and Blackwell performance enhancements.
- **[2025/08]** **[GPT-OSS Model](https://github.com/NVIDIA/Megatron-LM/issues/1739)** - Advanced features including YaRN RoPE scaling, attention sinks, and custom activation functions are being integrated into Megatron Core.
- **[2025/06]** **[Megatron MoE Model Zoo](https://github.com/yanring/Megatron-MoE-ModelZoo)** - Best practices and optimized configurations for training DeepSeek-V3, Mixtral, and Qwen3 MoE models with performance benchmarking and checkpoint conversion tools.
- **[2025/05]** Megatron Core v0.11.0 brings new capabilities for multi-data center LLM training ([blog](https://developer.nvidia.com/blog/turbocharge-llm-training-across-long-haul-data-center-networks-with-nvidia-nemo-framework/)).

&lt;details&gt;
&lt;summary&gt;Previous News&lt;/summary&gt;

- **[2024/07]** Megatron Core v0.7 improves scalability and training resiliency and adds support for multimodal training ([blog](https://developer.nvidia.com/blog/train-generative-ai-models-more-efficiently-with-new-nvidia-Megatron-Core-functionalities/)).
- **[2024/06]** Megatron Core added supports for Mamba-based models. Check out our paper [An Empirical Study of Mamba-based Language Models](https://arxiv.org/pdf/2406.07887) and [code example](https://github.com/NVIDIA/Megatron-LM/tree/ssm/examples/mamba).
- **[2024/01 Announcement]** NVIDIA has released the core capabilities in **Megatron-LM** into [**Megatron Core**](https://github.com/NVIDIA/Megatron-LM/tree/main/megatron/core) in this repository. Megatron Core expands upon Megatron-LM&#039;s GPU-optimized techniques with more cutting-edge innovations on system-level optimizations, featuring composable and modular APIs.

&lt;/details&gt;


# Project Structure

```
Megatron-LM/
‚îú‚îÄ‚îÄ megatron/
‚îÇ   ‚îú‚îÄ‚îÄ core/                    # Megatron Core (kernels, parallelism, building blocks)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/              # Transformer models
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ transformer/         # Transformer building blocks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tensor_parallel/     # Tensor parallelism
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline_parallel/   # Pipeline parallelism
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ distributed/         # Distributed training (FSDP, DDP)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ optimizer/           # Optimizers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ datasets/            # Dataset loaders
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference/           # Inference engines and server
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ export/              # Model export (e.g. TensorRT-LLM)
‚îÇ   ‚îú‚îÄ‚îÄ training/                # Training scripts
‚îÇ   ‚îú‚îÄ‚îÄ legacy/                  # Legacy components
‚îÇ   ‚îú‚îÄ‚îÄ post_training/           # Post-training (quantization, distillation, pruning, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ rl/                      # Reinforcement learning (RLHF, etc.)
‚îú‚îÄ‚îÄ examples/                    # Ready-to-use training examples
‚îú‚îÄ‚îÄ tools/                       # Utility tools
‚îú‚îÄ‚îÄ tests/                       # Comprehensive test suite
‚îî‚îÄ‚îÄ docs/                        # Documentation
```


# Performance Benchmarking

For our latest performance benchmarking results, please refer to [NVIDIA Megatron Bridge Performance Summary](https://docs.nvidia.com/nemo/megatron-bridge/latest/performance-summary.html).

Our codebase efficiently trains models from 2B to 462B parameters across thousands of GPUs, achieving up to **47% Model FLOP Utilization (MFU)** on H100 clusters.

![Model table](images/model_table.png)

**Benchmark Configuration:**

- **Vocabulary size**: 131,072 tokens
- **Sequence length**: 4096 tokens
- **Model scaling**: Varied hidden size, attention heads, and layers to achieve target parameter counts
- **Communication optimizations**: Fine-grained overlapping with DP (`--overlap-grad-reduce`, `--overlap-param-gather`), TP (`--tp-comm-overlap`), and PP (enabled by default)

**Key Results:**

- **6144 H100 GPUs**: Successfully benchmarked 462B parameter model training
- **Superlinear scaling**: MFU increases from 41% to 47-48% with model size
- **End-to-end measurement**: Throughputs include all operations (data loading, optimizer steps, communication, logging)
- **Production ready**: Full training pipeline with checkpointing and fault tolerance
- *Note: Performance results measured without training to convergence*

## Weak Scaling Results

Our weak scaled results show superlinear scaling (MFU increases from 41% for the smallest model considered to 47-48% for the largest models); this is because larger GEMMs have higher arithmetic intensity and are consequently more efficient to execute.

![Weak scaling](images/weak_scaling.png)

## Strong Scaling Results

We also strong scaled the standard GPT-3 model (our version has slightly more than 175 billion parameters due to larger vocabulary size) from 96 H100 GPUs to 4608 GPUs, using the same batch size of 1152 sequences throughout. Communication becomes more exposed at larger scale, leading to a reduction in MFU from 47% to 42%.

![Strong scaling](images/strong_scaling.png)


# Roadmaps

- **[MoE Roadmap](https://github.com/NVIDIA/Megatron-LM/issues/1729)** - DeepSeek-V3, Qwen3, advanced parallelism, FP8 optimizations, and Blackwell enhancements


# Resources

## Getting Help

- üìñ **[Documentation](https://docs.nvidia.com/megatron-core/developer-guide/latest/index.html)** - Official documentation
- üêõ **[Issues](https://github.com/NVIDIA/Megatron-LM/issues)** - Bug reports and feature requests

## Contributing

We ‚ù§Ô∏è contributions! Ways to contribute:

- üêõ **Report bugs** - Help us improve reliability
- üí° **Suggest features** - Shape the future of Megatron Core
- üìù **Improve docs** - Make Megatron Core more accessible
- üîß **Submit PRs** - Contribute code improvements

**‚Üí [Contributing Guide](https://docs.nvidia.com/megatron-core/developer-guide/latest/developer/contribute.html)**

## Citation

If you use Megatron in your research or project, we appreciate that you use the following citations:

```bibtex
@article{megatron-lm,
  title={Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[business-science/ai-data-science-team]]></title>
            <link>https://github.com/business-science/ai-data-science-team</link>
            <guid>https://github.com/business-science/ai-data-science-team</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:18 GMT</pubDate>
            <description><![CDATA[An AI-powered data science team of agents to help you perform common data science tasks 10X faster.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/business-science/ai-data-science-team">business-science/ai-data-science-team</a></h1>
            <p>An AI-powered data science team of agents to help you perform common data science tasks 10X faster.</p>
            <p>Language: Python</p>
            <p>Stars: 4,973</p>
            <p>Forks: 851</p>
            <p>Stars today: 37 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/business-science/ai-data-science-team&quot;&gt;
    &lt;picture&gt;
      &lt;img src=&quot;./img/ai_data_science_logo.png&quot; alt=&quot;AI Data Science Team&quot; width=&quot;360&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;em&gt;AI Data Science Team + AI Pipeline Studio&lt;/em&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pypi.python.org/pypi/ai-data-science-team&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/ai-data-science-team.svg?style=for-the-badge&quot; alt=&quot;PyPI&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/business-science/ai-data-science-team&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/ai-data-science-team.svg?style=for-the-badge&quot; alt=&quot;versions&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/business-science/ai-data-science-team/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/business-science/ai-data-science-team.svg?style=for-the-badge&quot; alt=&quot;license&quot;&gt;&lt;/a&gt;
  &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/business-science/ai-data-science-team?style=for-the-badge&quot;&gt;
&lt;/div&gt;

# AI Data Science Team

AI Data Science Team is a Python library of specialized agents for common data science workflows, plus a flagship app: **AI Pipeline Studio**. The Studio turns your work into a visual, reproducible pipeline, while the AI team handles data loading, cleaning, visualization, and modeling.

**Status:** Beta. Breaking changes may occur until 0.1.0.

[**Please ‚≠ê us on GitHub (it takes 2 seconds and means a lot).**](https://github.com/business-science/ai-data-science-team)

## AI Pipeline Studio (Flagship App)

AI Pipeline Studio is the main example of the AI Data Science Team in action.

![AI Pipeline Studio](/img/apps/ai_pipeline_studio_app.jpg)

Highlights:
- Pipeline-first workspace: Visual Editor, Table, Chart, EDA, Code, Model, Predictions, MLflow
- Manual + AI steps with lineage and reproducible scripts
- Multi-dataset handling and merge workflows
- Project saves: metadata-only or full-data
- Storage footprint controls and rehydrate workflows

Run it:
```bash
streamlit run apps/ai-pipeline-studio-app/app.py
```

Full app docs: `apps/ai-pipeline-studio-app/README.md`

## Quickstart

### Requirements
- Python 3.10+
- OpenAI API key (or Ollama for local models)

### Install the app and library
Clone the repo and install in editable mode:
```bash
pip install -e .
```

### Run the AI Pipeline Studio app
```bash
streamlit run apps/ai-pipeline-studio-app/app.py
```

## Library Overview

The repository includes both the **AI Pipeline Studio** app and the underlying **AI Data Science Team** library. The library provides agent building blocks and multi-agent workflows for:
- Data loading and inspection
- Cleaning, wrangling, and feature engineering
- Visualization and EDA
- Modeling and evaluation (H2O + MLflow tools)
- SQL database interaction

### Agents (Snapshot)

Agent examples live in `examples/`. Notable agents:
- Data Loader Tools Agent
- Data Wrangling Agent
- Data Cleaning Agent
- Data Visualization Agent
- EDA Tools Agent
- Feature Engineering Agent
- SQL Database Agent
- H2O ML Agent
- MLflow Tools Agent
- Multi-agent workflows (e.g., Pandas Data Analyst, SQL Data Analyst)
- Supervisor Agent (oversees other agents)
- Custom tools for data science tasks

## Apps

See all apps in `apps/`. Notable apps:
- AI Pipeline Studio: `apps/ai-pipeline-studio-app/`
- EDA Explorer App: `apps/exploratory-copilot-app/`
- Pandas Data Analyst App: `apps/pandas-data-analyst-app/`

## Use OpenAI

```python
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(
    model_name=&quot;gpt-4.1-mini&quot;,
)
```

## Use Ollama (Local LLM)

```bash
ollama serve
ollama pull llama3.1:8b
```

```python
from langchain_ollama import ChatOllama

llm = ChatOllama(
    model=&quot;llama3.1:8b&quot;,
)
```

## Next-Gen AI Agentic Workshop

Want to learn how to build AI agents and AI apps for real data science workflows? Join my next‚Äëgen AI workshop:
https://learn.business-science.io/ai-register
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[infiniflow/ragflow]]></title>
            <link>https://github.com/infiniflow/ragflow</link>
            <guid>https://github.com/infiniflow/ragflow</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:17 GMT</pubDate>
            <description><![CDATA[RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/infiniflow/ragflow">infiniflow/ragflow</a></h1>
            <p>RAGFlow is a leading open-source Retrieval-Augmented Generation (RAG) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs</p>
            <p>Language: Python</p>
            <p>Stars: 73,715</p>
            <p>Forks: 8,187</p>
            <p>Stars today: 86 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://demo.ragflow.io/&quot;&gt;
&lt;img src=&quot;web/src/assets/logo-with-text.svg&quot; width=&quot;520&quot; alt=&quot;ragflow logo&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;./README.md&quot;&gt;&lt;img alt=&quot;README in English&quot; src=&quot;https://img.shields.io/badge/English-DBEDFA&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_zh.md&quot;&gt;&lt;img alt=&quot;ÁÆÄ‰Ωì‰∏≠ÊñáÁâàËá™Ëø∞Êñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁÆÄ‰Ωì‰∏≠Êñá-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_tzh.md&quot;&gt;&lt;img alt=&quot;ÁπÅÈ´îÁâà‰∏≠ÊñáËá™Ëø∞Êñá‰ª∂&quot; src=&quot;https://img.shields.io/badge/ÁπÅÈ´î‰∏≠Êñá-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ja.md&quot;&gt;&lt;img alt=&quot;Êó•Êú¨Ë™û„ÅÆREADME&quot; src=&quot;https://img.shields.io/badge/Êó•Êú¨Ë™û-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_ko.md&quot;&gt;&lt;img alt=&quot;ÌïúÍµ≠Ïñ¥&quot; src=&quot;https://img.shields.io/badge/ÌïúÍµ≠Ïñ¥-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_id.md&quot;&gt;&lt;img alt=&quot;Bahasa Indonesia&quot; src=&quot;https://img.shields.io/badge/Bahasa Indonesia-DFE0E5&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;./README_pt_br.md&quot;&gt;&lt;img alt=&quot;Portugu√™s(Brasil)&quot; src=&quot;https://img.shields.io/badge/Portugu√™s(Brasil)-DFE0E5&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://x.com/intent/follow?screen_name=infiniflowai&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/twitter/follow/infiniflow?logo=X&amp;color=%20%23f5f5f5&quot; alt=&quot;follow on X(Twitter)&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://demo.ragflow.io&quot; target=&quot;_blank&quot;&gt;
        &lt;img alt=&quot;Static Badge&quot; src=&quot;https://img.shields.io/badge/Online-Demo-4e6b99&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://hub.docker.com/r/infiniflow/ragflow&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/docker/pulls/infiniflow/ragflow?label=Docker%20Pulls&amp;color=0db7ed&amp;logo=docker&amp;logoColor=white&amp;style=flat-square&quot; alt=&quot;docker pull infiniflow/ragflow:v0.24.0&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/releases/latest&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/github/v/release/infiniflow/ragflow?color=blue&amp;label=Latest%20Release&quot; alt=&quot;Latest Release&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://github.com/infiniflow/ragflow/blob/main/LICENSE&quot;&gt;
        &lt;img height=&quot;21&quot; src=&quot;https://img.shields.io/badge/License-Apache--2.0-ffffff?labelColor=d4eaf7&amp;color=2e6cc4&quot; alt=&quot;license&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://deepwiki.com/infiniflow/ragflow&quot;&gt;
        &lt;img alt=&quot;Ask DeepWiki&quot; src=&quot;https://deepwiki.com/badge.svg&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://ragflow.io/docs/dev/&quot;&gt;Document&lt;/a&gt; |
  &lt;a href=&quot;https://github.com/infiniflow/ragflow/issues/12241&quot;&gt;Roadmap&lt;/a&gt; |
  &lt;a href=&quot;https://twitter.com/infiniflowai&quot;&gt;Twitter&lt;/a&gt; |
  &lt;a href=&quot;https://discord.gg/NjYzJD3GM3&quot;&gt;Discord&lt;/a&gt; |
  &lt;a href=&quot;https://demo.ragflow.io&quot;&gt;Demo&lt;/a&gt;
&lt;/h4&gt;

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/ragflow-octoverse.png&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/9064&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/9064&quot; alt=&quot;infiniflow%2Fragflow | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;üìï Table of Contents&lt;/b&gt;&lt;/summary&gt;

- üí° [What is RAGFlow?](#-what-is-ragflow)
- üéÆ [Demo](#-demo)
- üìå [Latest Updates](#-latest-updates)
- üåü [Key Features](#-key-features)
- üîé [System Architecture](#-system-architecture)
- üé¨ [Get Started](#-get-started)
- üîß [Configurations](#-configurations)
- üîß [Build a Docker image](#-build-a-docker-image)
- üî® [Launch service from source for development](#-launch-service-from-source-for-development)
- üìö [Documentation](#-documentation)
- üìú [Roadmap](#-roadmap)
- üèÑ [Community](#-community)
- üôå [Contributing](#-contributing)

&lt;/details&gt;

## üí° What is RAGFlow?

[RAGFlow](https://ragflow.io/) is a leading open-source Retrieval-Augmented Generation ([RAG](https://ragflow.io/basics/what-is-rag)) engine that fuses cutting-edge RAG with Agent capabilities to create a superior context layer for LLMs. It offers a streamlined RAG workflow adaptable to enterprises of any scale. Powered by a converged [context engine](https://ragflow.io/basics/what-is-agent-context-engine) and pre-built agent templates, RAGFlow enables developers to transform complex data into high-fidelity, production-ready AI systems with exceptional efficiency and precision.

## üéÆ Demo

Try our demo at [https://demo.ragflow.io](https://demo.ragflow.io).

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/chunking.gif&quot; width=&quot;1200&quot;/&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/infiniflow/ragflow-docs/refs/heads/image/image/agentic-dark.gif&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## üî• Latest Updates

- 2025-12-26 Supports &#039;Memory&#039; for AI agent.
- 2025-11-19 Supports Gemini 3 Pro.
- 2025-11-12 Supports data synchronization from Confluence, S3, Notion, Discord, Google Drive.
- 2025-10-23 Supports MinerU &amp; Docling as document parsing methods.
- 2025-10-15 Supports orchestrable ingestion pipeline.
- 2025-08-08 Supports OpenAI&#039;s latest GPT-5 series models.
- 2025-08-01 Supports agentic workflow and MCP.
- 2025-05-23 Adds a Python/JavaScript code executor component to Agent.
- 2025-05-05 Supports cross-language query.
- 2025-03-19 Supports using a multi-modal model to make sense of images within PDF or DOCX files.

## üéâ Stay Tuned

‚≠êÔ∏è Star our repository to stay up-to-date with exciting new features and improvements! Get instant notifications for new
releases! üåü

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/18c9707e-b8aa-4caf-a154-037089c105ba&quot; width=&quot;1200&quot;/&gt;
&lt;/div&gt;

## üåü Key Features

### üç≠ **&quot;Quality in, quality out&quot;**

- [Deep document understanding](./deepdoc/README.md)-based knowledge extraction from unstructured data with complicated
  formats.
- Finds &quot;needle in a data haystack&quot; of literally unlimited tokens.

### üç± **Template-based chunking**

- Intelligent and explainable.
- Plenty of template options to choose from.

### üå± **Grounded citations with reduced hallucinations**

- Visualization of text chunking to allow human intervention.
- Quick view of the key references and traceable citations to support grounded answers.

### üçî **Compatibility with heterogeneous data sources**

- Supports Word, slides, excel, txt, images, scanned copies, structured data, web pages, and more.

### üõÄ **Automated and effortless RAG workflow**

- Streamlined RAG orchestration catered to both personal and large businesses.
- Configurable LLMs as well as embedding models.
- Multiple recall paired with fused re-ranking.
- Intuitive APIs for seamless integration with business.

## üîé System Architecture

&lt;div align=&quot;center&quot; style=&quot;margin-top:20px;margin-bottom:20px;&quot;&gt;
&lt;img src=&quot;https://github.com/user-attachments/assets/31b0dd6f-ca4f-445a-9457-70cb44a381b2&quot; width=&quot;1000&quot;/&gt;
&lt;/div&gt;

## üé¨ Get Started

### üìù Prerequisites

- CPU &gt;= 4 cores
- RAM &gt;= 16 GB
- Disk &gt;= 50 GB
- Docker &gt;= 24.0.0 &amp; Docker Compose &gt;= v2.26.1
- [gVisor](https://gvisor.dev/docs/user_guide/install/): Required only if you intend to use the code executor (sandbox) feature of RAGFlow.

&gt; [!TIP]
&gt; If you have not installed Docker on your local machine (Windows, Mac, or Linux), see [Install Docker Engine](https://docs.docker.com/engine/install/).

### üöÄ Start up the server

1. Ensure `vm.max_map_count` &gt;= 262144:

   &gt; To check the value of `vm.max_map_count`:
   &gt;
   &gt; ```bash
   &gt; $ sysctl vm.max_map_count
   &gt; ```
   &gt;
   &gt; Reset `vm.max_map_count` to a value at least 262144 if it is not.
   &gt;
   &gt; ```bash
   &gt; # In this case, we set it to 262144:
   &gt; $ sudo sysctl -w vm.max_map_count=262144
   &gt; ```
   &gt;
   &gt; This change will be reset after a system reboot. To ensure your change remains permanent, add or update the
   &gt; `vm.max_map_count` value in **/etc/sysctl.conf** accordingly:
   &gt;
   &gt; ```bash
   &gt; vm.max_map_count=262144
   &gt; ```
   &gt;
2. Clone the repo:

   ```bash
   $ git clone https://github.com/infiniflow/ragflow.git
   ```
3. Start up the server using the pre-built Docker images:

&gt; [!CAUTION]
&gt; All Docker images are built for x86 platforms. We don&#039;t currently offer Docker images for ARM64.
&gt; If you are on an ARM64 platform, follow [this guide](https://ragflow.io/docs/dev/build_docker_image) to build a Docker image compatible with your system.

&gt; The command below downloads the `v0.24.0` edition of the RAGFlow Docker image. See the following table for descriptions of different RAGFlow editions. To download a RAGFlow edition different from `v0.24.0`, update the `RAGFLOW_IMAGE` variable accordingly in **docker/.env** before using `docker compose` to start the server.

```bash
   $ cd ragflow/docker

   # git checkout v0.24.0
   # Optional: use a stable tag (see releases: https://github.com/infiniflow/ragflow/releases)
   # This step ensures the **entrypoint.sh** file in the code matches the Docker image version.

   # Use CPU for DeepDoc tasks:
   $ docker compose -f docker-compose.yml up -d

   # To use GPU to accelerate DeepDoc tasks:
   # sed -i &#039;1i DEVICE=gpu&#039; .env
   # docker compose -f docker-compose.yml up -d
```

&gt; Note: Prior to `v0.22.0`, we provided both images with embedding models and slim images without embedding models. Details as follows:

| RAGFlow image tag | Image size (GB) | Has embedding models? | Stable?        |
|-------------------|-----------------|-----------------------|----------------|
| v0.21.1           | &amp;approx;9       | ‚úîÔ∏è                    | Stable release |
| v0.21.1-slim      | &amp;approx;2       | ‚ùå                     | Stable release |

&gt; Starting with `v0.22.0`, we ship only the slim edition and no longer append the **-slim** suffix to the image tag.

4. Check the server status after having the server up and running:

   ```bash
   $ docker logs -f docker-ragflow-cpu-1
   ```

   _The following output confirms a successful launch of the system:_

   ```bash

         ____   ___    ______ ______ __
        / __ \ /   |  / ____// ____// /____  _      __
       / /_/ // /| | / / __ / /_   / // __ \| | /| / /
      / _, _// ___ |/ /_/ // __/  / // /_/ /| |/ |/ /
     /_/ |_|/_/  |_|\____//_/    /_/ \____/ |__/|__/

    * Running on all addresses (0.0.0.0)
   ```

   &gt; If you skip this confirmation step and directly log in to RAGFlow, your browser may prompt a `network abnormal`
   &gt; error because, at that moment, your RAGFlow may not be fully initialized.
   &gt;
5. In your web browser, enter the IP address of your server and log in to RAGFlow.

   &gt; With the default settings, you only need to enter `http://IP_OF_YOUR_MACHINE` (**sans** port number) as the default
   &gt; HTTP serving port `80` can be omitted when using the default configurations.
   &gt;
6. In [service_conf.yaml.template](./docker/service_conf.yaml.template), select the desired LLM factory in `user_default_llm` and update
   the `API_KEY` field with the corresponding API key.

   &gt; See [llm_api_key_setup](https://ragflow.io/docs/dev/llm_api_key_setup) for more information.
   &gt;

   _The show is on!_

## üîß Configurations

When it comes to system configurations, you will need to manage the following files:

- [.env](./docker/.env): Keeps the fundamental setups for the system, such as `SVR_HTTP_PORT`, `MYSQL_PASSWORD`, and
  `MINIO_PASSWORD`.
- [service_conf.yaml.template](./docker/service_conf.yaml.template): Configures the back-end services. The environment variables in this file will be automatically populated when the Docker container starts. Any environment variables set within the Docker container will be available for use, allowing you to customize service behavior based on the deployment environment.
- [docker-compose.yml](./docker/docker-compose.yml): The system relies on [docker-compose.yml](./docker/docker-compose.yml) to start up.

&gt; The [./docker/README](./docker/README.md) file provides a detailed description of the environment settings and service
&gt; configurations which can be used as `${ENV_VARS}` in the [service_conf.yaml.template](./docker/service_conf.yaml.template) file.

To update the default HTTP serving port (80), go to [docker-compose.yml](./docker/docker-compose.yml) and change `80:80`
to `&lt;YOUR_SERVING_PORT&gt;:80`.

Updates to the above configurations require a reboot of all containers to take effect:

&gt; ```bash
&gt; $ docker compose -f docker-compose.yml up -d
&gt; ```

### Switch doc engine from Elasticsearch to Infinity

RAGFlow uses Elasticsearch by default for storing full text and vectors. To switch to [Infinity](https://github.com/infiniflow/infinity/), follow these steps:

1. Stop all running containers:

   ```bash
   $ docker compose -f docker/docker-compose.yml down -v
   ```

&gt; [!WARNING]
&gt; `-v` will delete the docker container volumes, and the existing data will be cleared.

2. Set `DOC_ENGINE` in **docker/.env** to `infinity`.
3. Start the containers:

   ```bash
   $ docker compose -f docker-compose.yml up -d
   ```

&gt; [!WARNING]
&gt; Switching to Infinity on a Linux/arm64 machine is not yet officially supported.

## üîß Build a Docker image

This image is approximately 2 GB in size and relies on external LLM and embedding services.

```bash
git clone https://github.com/infiniflow/ragflow.git
cd ragflow/
docker build --platform linux/amd64 -f Dockerfile -t infiniflow/ragflow:nightly .
```

Or if you are behind a proxy, you can pass proxy arguments:

```bash
docker build --platform linux/amd64 \
  --build-arg http_proxy=http://YOUR_PROXY:PORT \
  --build-arg https_proxy=http://YOUR_PROXY:PORT \
  -f Dockerfile -t infiniflow/ragflow:nightly .
```

## üî® Launch service from source for development

1. Install `uv` and `pre-commit`, or skip this step if they are already installed:

   ```bash
   pipx install uv pre-commit
   ```
2. Clone the source code and install Python dependencies:

   ```bash
   git clone https://github.com/infiniflow/ragflow.git
   cd ragflow/
   uv sync --python 3.12 # install RAGFlow dependent python modules
   uv run download_deps.py
   pre-commit install
   ```
3. Launch the dependent services (MinIO, Elasticsearch, Redis, and MySQL) using Docker Compose:

   ```bash
   docker compose -f docker/docker-compose-base.yml up -d
   ```

   Add the following line to `/etc/hosts` to resolve all hosts specified in **docker/.env** to `127.0.0.1`:

   ```
   127.0.0.1       es01 infinity mysql minio redis sandbox-executor-manager
   ```
4. If you cannot access HuggingFace, set the `HF_ENDPOINT` environment variable to use a mirror site:

   ```bash
   export HF_ENDPOINT=https://hf-mirror.com
   ```
5. If your operating system does not have jemalloc, please install it as follows:

   ```bash
   # Ubuntu
   sudo apt-get install libjemalloc-dev
   # CentOS
   sudo yum install jemalloc
   # OpenSUSE
   sudo zypper install jemalloc
   # macOS
   sudo brew install jemalloc
   ```
6. Launch backend service:

   ```bash
   source .venv/bin/activate
   export PYTHONPATH=$(pwd)
   bash docker/launch_backend_service.sh
   ```
7. Install frontend dependencies:

   ```bash
   cd web
   npm install
   ```
8. Launch frontend service:

   ```bash
   npm run dev
   ```

   _The following output confirms a successful launch of the system:_

   ![](https://github.com/user-attachments/assets/0daf462c-a24d-4496-a66f-92533534e187)
9. Stop RAGFlow front-end and back-end service after development is complete:

   ```bash
   pkill -f &quot;ragflow_server.py|task_executor.py&quot;
   ```

## üìö Documentation

- [Quickstart](https://ragflow.io/docs/dev/)
- [Configuration](https://ragflow.io/docs/dev/configurations)
- [Release notes](https://ragflow.io/docs/dev/release_notes)
- [User guides](https://ragflow.io/docs/dev/category/guides)
- [Developer guides](https://ragflow.io/docs/dev/category/developers)
- [References](https://ragflow.io/docs/dev/category/references)
- [FAQs](https://ragflow.io/docs/dev/faq)

## üìú Roadmap

See the [RAGFlow Roadmap 2026](https://github.com/infiniflow/ragflow/issues/12241)

## üèÑ Community

- [Discord](https://discord.gg/NjYzJD3GM3)
- [Twitter](https://twitter.com/infiniflowai)
- [GitHub Discussions](https://github.com/orgs/infiniflow/discussions)

## üôå Contributing

RAGFlow flourishes via open-source collaboration. In this spirit, we embrace diverse contributions from the community.
If you would like to be a part, review our [Contribution Guidelines](https://ragflow.io/docs/dev/contributing) first.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[anthropics/skills]]></title>
            <link>https://github.com/anthropics/skills</link>
            <guid>https://github.com/anthropics/skills</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:16 GMT</pubDate>
            <description><![CDATA[Public repository for Agent Skills]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anthropics/skills">anthropics/skills</a></h1>
            <p>Public repository for Agent Skills</p>
            <p>Language: Python</p>
            <p>Stars: 75,749</p>
            <p>Forks: 7,861</p>
            <p>Stars today: 958 stars today</p>
            <h2>README</h2><pre>&gt; **Note:** This repository contains Anthropic&#039;s implementation of skills for Claude. For information about the Agent Skills standard, see [agentskills.io](http://agentskills.io).

# Skills
Skills are folders of instructions, scripts, and resources that Claude loads dynamically to improve performance on specialized tasks. Skills teach Claude how to complete specific tasks in a repeatable way, whether that&#039;s creating documents with your company&#039;s brand guidelines, analyzing data using your organization&#039;s specific workflows, or automating personal tasks.

For more information, check out:
- [What are skills?](https://support.claude.com/en/articles/12512176-what-are-skills)
- [Using skills in Claude](https://support.claude.com/en/articles/12512180-using-skills-in-claude)
- [How to create custom skills](https://support.claude.com/en/articles/12512198-creating-custom-skills)
- [Equipping agents for the real world with Agent Skills](https://anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills)

# About This Repository

This repository contains skills that demonstrate what&#039;s possible with Claude&#039;s skills system. These skills range from creative applications (art, music, design) to technical tasks (testing web apps, MCP server generation) to enterprise workflows (communications, branding, etc.).

Each skill is self-contained in its own folder with a `SKILL.md` file containing the instructions and metadata that Claude uses. Browse through these skills to get inspiration for your own skills or to understand different patterns and approaches.

Many skills in this repo are open source (Apache 2.0). We&#039;ve also included the document creation &amp; editing skills that power [Claude&#039;s document capabilities](https://www.anthropic.com/news/create-files) under the hood in the [`skills/docx`](./skills/docx), [`skills/pdf`](./skills/pdf), [`skills/pptx`](./skills/pptx), and [`skills/xlsx`](./skills/xlsx) subfolders. These are source-available, not open source, but we wanted to share these with developers as a reference for more complex skills that are actively used in a production AI application.

## Disclaimer

**These skills are provided for demonstration and educational purposes only.** While some of these capabilities may be available in Claude, the implementations and behaviors you receive from Claude may differ from what is shown in these skills. These skills are meant to illustrate patterns and possibilities. Always test skills thoroughly in your own environment before relying on them for critical tasks.

# Skill Sets
- [./skills](./skills): Skill examples for Creative &amp; Design, Development &amp; Technical, Enterprise &amp; Communication, and Document Skills
- [./spec](./spec): The Agent Skills specification
- [./template](./template): Skill template

# Try in Claude Code, Claude.ai, and the API

## Claude Code
You can register this repository as a Claude Code Plugin marketplace by running the following command in Claude Code:
```
/plugin marketplace add anthropics/skills
```

Then, to install a specific set of skills:
1. Select `Browse and install plugins`
2. Select `anthropic-agent-skills`
3. Select `document-skills` or `example-skills`
4. Select `Install now`

Alternatively, directly install either Plugin via:
```
/plugin install document-skills@anthropic-agent-skills
/plugin install example-skills@anthropic-agent-skills
```

After installing the plugin, you can use the skill by just mentioning it. For instance, if you install the `document-skills` plugin from the marketplace, you can ask Claude Code to do something like: &quot;Use the PDF skill to extract the form fields from `path/to/some-file.pdf`&quot;

## Claude.ai

These example skills are all already available to paid plans in Claude.ai. 

To use any skill from this repository or upload custom skills, follow the instructions in [Using skills in Claude](https://support.claude.com/en/articles/12512180-using-skills-in-claude#h_a4222fa77b).

## Claude API

You can use Anthropic&#039;s pre-built skills, and upload custom skills, via the Claude API. See the [Skills API Quickstart](https://docs.claude.com/en/api/skills-guide#creating-a-skill) for more.

# Creating a Basic Skill

Skills are simple to create - just a folder with a `SKILL.md` file containing YAML frontmatter and instructions. You can use the **template-skill** in this repository as a starting point:

```markdown
---
name: my-skill-name
description: A clear description of what this skill does and when to use it
---

# My Skill Name

[Add your instructions here that Claude will follow when this skill is active]

## Examples
- Example usage 1
- Example usage 2

## Guidelines
- Guideline 1
- Guideline 2
```

The frontmatter requires only two fields:
- `name` - A unique identifier for your skill (lowercase, hyphens for spaces)
- `description` - A complete description of what the skill does and when to use it

The markdown content below contains the instructions, examples, and guidelines that Claude will follow. For more details, see [How to create custom skills](https://support.claude.com/en/articles/12512198-creating-custom-skills).

# Partner Skills

Skills are a great way to teach Claude how to get better at using specific pieces of software. As we see awesome example skills from partners, we may highlight some of them here:

- **Notion** - [Notion Skills for Claude](https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[NanmiCoder/MediaCrawler]]></title>
            <link>https://github.com/NanmiCoder/MediaCrawler</link>
            <guid>https://github.com/NanmiCoder/MediaCrawler</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:15 GMT</pubDate>
            <description><![CDATA[Â∞èÁ∫¢‰π¶Á¨îËÆ∞ | ËØÑËÆ∫Áà¨Ëô´„ÄÅÊäñÈü≥ËßÜÈ¢ë | ËØÑËÆ∫Áà¨Ëô´„ÄÅÂø´ÊâãËßÜÈ¢ë | ËØÑËÆ∫Áà¨Ëô´„ÄÅB Á´ôËßÜÈ¢ë ÔΩú ËØÑËÆ∫Áà¨Ëô´„ÄÅÂæÆÂçöÂ∏ñÂ≠ê ÔΩú ËØÑËÆ∫Áà¨Ëô´„ÄÅÁôæÂ∫¶Ë¥¥ÂêßÂ∏ñÂ≠ê ÔΩú ÁôæÂ∫¶Ë¥¥ÂêßËØÑËÆ∫ÂõûÂ§çÁà¨Ëô´ | Áü•‰πéÈóÆÁ≠îÊñáÁ´†ÔΩúËØÑËÆ∫Áà¨Ëô´]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NanmiCoder/MediaCrawler">NanmiCoder/MediaCrawler</a></h1>
            <p>Â∞èÁ∫¢‰π¶Á¨îËÆ∞ | ËØÑËÆ∫Áà¨Ëô´„ÄÅÊäñÈü≥ËßÜÈ¢ë | ËØÑËÆ∫Áà¨Ëô´„ÄÅÂø´ÊâãËßÜÈ¢ë | ËØÑËÆ∫Áà¨Ëô´„ÄÅB Á´ôËßÜÈ¢ë ÔΩú ËØÑËÆ∫Áà¨Ëô´„ÄÅÂæÆÂçöÂ∏ñÂ≠ê ÔΩú ËØÑËÆ∫Áà¨Ëô´„ÄÅÁôæÂ∫¶Ë¥¥ÂêßÂ∏ñÂ≠ê ÔΩú ÁôæÂ∫¶Ë¥¥ÂêßËØÑËÆ∫ÂõûÂ§çÁà¨Ëô´ | Áü•‰πéÈóÆÁ≠îÊñáÁ´†ÔΩúËØÑËÆ∫Áà¨Ëô´</p>
            <p>Language: Python</p>
            <p>Stars: 44,294</p>
            <p>Forks: 9,718</p>
            <p>Stars today: 68 stars today</p>
            <h2>README</h2><pre># üî• MediaCrawler - Ëá™Â™í‰ΩìÂπ≥Âè∞Áà¨Ëô´ üï∑Ô∏è

&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://trendshift.io/repositories/8291&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://trendshift.io/api/badge/repositories/8291&quot; alt=&quot;NanmiCoder%2FMediaCrawler | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
&lt;/a&gt;

[![GitHub Stars](https://img.shields.io/github/stars/NanmiCoder/MediaCrawler?style=social)](https://github.com/NanmiCoder/MediaCrawler/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/NanmiCoder/MediaCrawler?style=social)](https://github.com/NanmiCoder/MediaCrawler/network/members)
[![GitHub Issues](https://img.shields.io/github/issues/NanmiCoder/MediaCrawler)](https://github.com/NanmiCoder/MediaCrawler/issues)
[![GitHub Pull Requests](https://img.shields.io/github/issues-pr/NanmiCoder/MediaCrawler)](https://github.com/NanmiCoder/MediaCrawler/pulls)
[![License](https://img.shields.io/github/license/NanmiCoder/MediaCrawler)](https://github.com/NanmiCoder/MediaCrawler/blob/main/LICENSE)
[![‰∏≠Êñá](https://img.shields.io/badge/üá®üá≥_‰∏≠Êñá-ÂΩìÂâç-blue)](README.md)
[![English](https://img.shields.io/badge/üá∫üá∏_English-Available-green)](README_en.md)
[![Espa√±ol](https://img.shields.io/badge/üá™üá∏_Espa√±ol-Available-green)](README_es.md)
&lt;/div&gt;



&gt; **ÂÖçË¥£Â£∞ÊòéÔºö**
&gt; 
&gt; Â§ßÂÆ∂ËØ∑‰ª•Â≠¶‰π†‰∏∫ÁõÆÁöÑ‰ΩøÁî®Êú¨‰ªìÂ∫ì‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏èÔºå[Áà¨Ëô´ËøùÊ≥ïËøùËßÑÁöÑÊ°à‰ª∂](https://github.com/HiddenStrawberry/Crawler_Illegal_Cases_In_China)  &lt;br&gt;
&gt;
&gt;Êú¨‰ªìÂ∫ìÁöÑÊâÄÊúâÂÜÖÂÆπ‰ªÖ‰æõÂ≠¶‰π†ÂíåÂèÇËÄÉ‰πãÁî®ÔºåÁ¶ÅÊ≠¢Áî®‰∫éÂïÜ‰∏öÁî®ÈÄî„ÄÇ‰ªª‰Ωï‰∫∫ÊàñÁªÑÁªá‰∏çÂæóÂ∞ÜÊú¨‰ªìÂ∫ìÁöÑÂÜÖÂÆπÁî®‰∫éÈùûÊ≥ïÁî®ÈÄîÊàñ‰æµÁäØ‰ªñ‰∫∫ÂêàÊ≥ïÊùÉÁõä„ÄÇÊú¨‰ªìÂ∫ìÊâÄÊ∂âÂèäÁöÑÁà¨Ëô´ÊäÄÊúØ‰ªÖÁî®‰∫éÂ≠¶‰π†ÂíåÁ†îÁ©∂Ôºå‰∏çÂæóÁî®‰∫éÂØπÂÖ∂‰ªñÂπ≥Âè∞ËøõË°åÂ§ßËßÑÊ®°Áà¨Ëô´ÊàñÂÖ∂‰ªñÈùûÊ≥ïË°å‰∏∫„ÄÇÂØπ‰∫éÂõ†‰ΩøÁî®Êú¨‰ªìÂ∫ìÂÜÖÂÆπËÄåÂºïËµ∑ÁöÑ‰ªª‰ΩïÊ≥ïÂæãË¥£‰ªªÔºåÊú¨‰ªìÂ∫ì‰∏çÊâøÊãÖ‰ªª‰ΩïË¥£‰ªª„ÄÇ‰ΩøÁî®Êú¨‰ªìÂ∫ìÁöÑÂÜÖÂÆπÂç≥Ë°®Á§∫ÊÇ®ÂêåÊÑèÊú¨ÂÖçË¥£Â£∞ÊòéÁöÑÊâÄÊúâÊù°Ê¨æÂíåÊù°‰ª∂„ÄÇ
&gt;
&gt; ÁÇπÂáªÊü•ÁúãÊõ¥‰∏∫ËØ¶ÁªÜÁöÑÂÖçË¥£Â£∞Êòé„ÄÇ[ÁÇπÂáªË∑≥ËΩ¨](#disclaimer)




## üìñ È°πÁõÆÁÆÄ‰ªã

‰∏Ä‰∏™ÂäüËÉΩÂº∫Â§ßÁöÑ**Â§öÂπ≥Âè∞Ëá™Â™í‰ΩìÊï∞ÊçÆÈááÈõÜÂ∑•ÂÖ∑**ÔºåÊîØÊåÅÂ∞èÁ∫¢‰π¶„ÄÅÊäñÈü≥„ÄÅÂø´Êâã„ÄÅBÁ´ô„ÄÅÂæÆÂçö„ÄÅË¥¥Âêß„ÄÅÁü•‰πéÁ≠â‰∏ªÊµÅÂπ≥Âè∞ÁöÑÂÖ¨ÂºÄ‰ø°ÊÅØÊäìÂèñ„ÄÇ

### üîß ÊäÄÊúØÂéüÁêÜ

- **Ê†∏ÂøÉÊäÄÊúØ**ÔºöÂü∫‰∫é [Playwright](https://playwright.dev/) ÊµèËßàÂô®Ëá™Âä®ÂåñÊ°ÜÊû∂ÁôªÂΩï‰øùÂ≠òÁôªÂΩïÊÄÅ
- **Êó†ÈúÄJSÈÄÜÂêë**ÔºöÂà©Áî®‰øùÁïôÁôªÂΩïÊÄÅÁöÑÊµèËßàÂô®‰∏ä‰∏ãÊñáÁéØÂ¢ÉÔºåÈÄöËøá JS Ë°®ËææÂºèËé∑ÂèñÁ≠æÂêçÂèÇÊï∞
- **‰ºòÂäøÁâπÁÇπ**ÔºöÊó†ÈúÄÈÄÜÂêëÂ§çÊùÇÁöÑÂä†ÂØÜÁÆóÊ≥ïÔºåÂ§ßÂπÖÈôç‰ΩéÊäÄÊúØÈó®Êßõ


## ‚ú® ÂäüËÉΩÁâπÊÄß
| Âπ≥Âè∞   | ÂÖ≥ÈîÆËØçÊêúÁ¥¢ | ÊåáÂÆöÂ∏ñÂ≠êIDÁà¨Âèñ | ‰∫åÁ∫ßËØÑËÆ∫ | ÊåáÂÆöÂàõ‰ΩúËÄÖ‰∏ªÈ°µ | ÁôªÂΩïÊÄÅÁºìÂ≠ò | IP‰ª£ÁêÜÊ±† | ÁîüÊàêËØÑËÆ∫ËØç‰∫ëÂõæ |
| ------ | ---------- | -------------- | -------- | -------------- | ---------- | -------- | -------------- |
| Â∞èÁ∫¢‰π¶ | ‚úÖ          | ‚úÖ              | ‚úÖ        | ‚úÖ              | ‚úÖ          | ‚úÖ        | ‚úÖ              |
| ÊäñÈü≥   | ‚úÖ          | ‚úÖ              | ‚úÖ        | ‚úÖ              | ‚úÖ          | ‚úÖ        | ‚úÖ              |
| Âø´Êâã   | ‚úÖ          | ‚úÖ              | ‚úÖ        | ‚úÖ              | ‚úÖ          | ‚úÖ        | ‚úÖ              |
| B Á´ô   | ‚úÖ          | ‚úÖ              | ‚úÖ        | ‚úÖ              | ‚úÖ          | ‚úÖ        | ‚úÖ              |
| ÂæÆÂçö   | ‚úÖ          | ‚úÖ              | ‚úÖ        | ‚úÖ              | ‚úÖ          | ‚úÖ        | ‚úÖ              |
| Ë¥¥Âêß   | ‚úÖ          | ‚úÖ              | ‚úÖ        | ‚úÖ              | ‚úÖ          | ‚úÖ        | ‚úÖ              |
| Áü•‰πé   | ‚úÖ          | ‚úÖ              | ‚úÖ        | ‚úÖ              | ‚úÖ          | ‚úÖ        | ‚úÖ              |



&lt;strong&gt;MediaCrawlerPro ÈáçÁ£ÖÂèëÂ∏ÉÔºÅÂºÄÊ∫ê‰∏çÊòìÔºåÊ¨¢ËøéËÆ¢ÈòÖÊîØÊåÅ&lt;/strong&gt;

&gt; ‰∏ìÊ≥®‰∫éÂ≠¶‰π†ÊàêÁÜüÈ°πÁõÆÁöÑÊû∂ÊûÑËÆæËÆ°Ôºå‰∏ç‰ªÖ‰ªÖÊòØÁà¨Ëô´ÊäÄÊúØÔºåPro ÁâàÊú¨ÁöÑ‰ª£Á†ÅËÆæËÆ°ÊÄùË∑ØÂêåÊ†∑ÂÄºÂæóÊ∑±ÂÖ•Â≠¶‰π†ÔºÅ

[MediaCrawlerPro](https://github.com/MediaCrawlerPro) Áõ∏ËæÉ‰∫éÂºÄÊ∫êÁâàÊú¨ÁöÑÊ†∏ÂøÉ‰ºòÂäøÔºö

#### üéØ Ê†∏ÂøÉÂäüËÉΩÂçáÁ∫ß
- ‚úÖ **Ëá™Â™í‰ΩìÂÜÖÂÆπÊãÜËß£Agent**ÔºàÊñ∞Â¢ûÂäüËÉΩÔºâ
- ‚úÖ **Êñ≠ÁÇπÁª≠Áà¨ÂäüËÉΩ**ÔºàÈáçÁÇπÁâπÊÄßÔºâ
- ‚úÖ **Â§öË¥¶Âè∑ + IP‰ª£ÁêÜÊ±†ÊîØÊåÅ**ÔºàÈáçÁÇπÁâπÊÄßÔºâ
- ‚úÖ **ÂéªÈô§ Playwright ‰æùËµñ**Ôºå‰ΩøÁî®Êõ¥ÁÆÄÂçï
- ‚úÖ **ÂÆåÊï¥ Linux ÁéØÂ¢ÉÊîØÊåÅ**

#### üèóÔ∏è Êû∂ÊûÑËÆæËÆ°‰ºòÂåñ
- ‚úÖ **‰ª£Á†ÅÈáçÊûÑ‰ºòÂåñ**ÔºåÊõ¥ÊòìËØªÊòìÁª¥Êä§ÔºàËß£ËÄ¶ JS Á≠æÂêçÈÄªËæëÔºâ
- ‚úÖ **‰ºÅ‰∏öÁ∫ß‰ª£Á†ÅË¥®Èáè**ÔºåÈÄÇÂêàÊûÑÂª∫Â§ßÂûãÁà¨Ëô´È°πÁõÆ
- ‚úÖ **ÂÆåÁæéÊû∂ÊûÑËÆæËÆ°**ÔºåÈ´òÊâ©Â±ïÊÄßÔºåÊ∫êÁ†ÅÂ≠¶‰π†‰ª∑ÂÄºÊõ¥Â§ß

#### üéÅ È¢ùÂ§ñÂäüËÉΩ
- ‚úÖ **Ëá™Â™í‰ΩìËßÜÈ¢ë‰∏ãËΩΩÂô®Ê°åÈù¢Á´Ø**ÔºàÈÄÇÂêàÂ≠¶‰π†ÂÖ®Ê†àÂºÄÂèëÔºâ
- ‚úÖ **Â§öÂπ≥Âè∞È¶ñÈ°µ‰ø°ÊÅØÊµÅÊé®Ëçê**ÔºàHomeFeedÔºâ
- [ ] **Âü∫‰∫éËØÑËÆ∫ÂàÜÊûêAI AgentÊ≠£Âú®ÂºÄÂèë‰∏≠ üöÄüöÄ**

ÁÇπÂáªÊü•ÁúãÔºö[MediaCrawlerPro È°πÁõÆ‰∏ªÈ°µ](https://github.com/MediaCrawlerPro) Êõ¥Â§ö‰ªãÁªç



## üöÄ Âø´ÈÄüÂºÄÂßã

&gt; üí° **Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑Áªô‰∏™ ‚≠ê Star ÊîØÊåÅ‰∏Ä‰∏ãÔºÅ**

## üìã ÂâçÁΩÆ‰æùËµñ

### üöÄ uv ÂÆâË£ÖÔºàÊé®ËçêÔºâ

Âú®ËøõË°å‰∏ã‰∏ÄÊ≠•Êìç‰Ωú‰πãÂâçÔºåËØ∑Á°Æ‰øùÁîµËÑë‰∏äÂ∑≤ÁªèÂÆâË£Ö‰∫Ü uvÔºö

- **ÂÆâË£ÖÂú∞ÂùÄ**Ôºö[uv ÂÆòÊñπÂÆâË£ÖÊåáÂçó](https://docs.astral.sh/uv/getting-started/installation)
- **È™åËØÅÂÆâË£Ö**ÔºöÁªàÁ´ØËæìÂÖ•ÂëΩ‰ª§ `uv --version`ÔºåÂ¶ÇÊûúÊ≠£Â∏∏ÊòæÁ§∫ÁâàÊú¨Âè∑ÔºåËØÅÊòéÂ∑≤ÁªèÂÆâË£ÖÊàêÂäü
- **Êé®ËçêÁêÜÁî±**Ôºöuv ÊòØÁõÆÂâçÊúÄÂº∫ÁöÑ Python ÂåÖÁÆ°ÁêÜÂ∑•ÂÖ∑ÔºåÈÄüÂ∫¶Âø´„ÄÅ‰æùËµñËß£ÊûêÂáÜÁ°Æ

### üü¢ Node.js ÂÆâË£Ö

È°πÁõÆ‰æùËµñ Node.jsÔºåËØ∑ÂâçÂæÄÂÆòÁΩë‰∏ãËΩΩÂÆâË£ÖÔºö

- **‰∏ãËΩΩÂú∞ÂùÄ**Ôºöhttps://nodejs.org/en/download/
- **ÁâàÊú¨Ë¶ÅÊ±Ç**Ôºö&gt;= 16.0.0

### üì¶ Python ÂåÖÂÆâË£Ö

```shell
# ËøõÂÖ•È°πÁõÆÁõÆÂΩï
cd MediaCrawler

# ‰ΩøÁî® uv sync ÂëΩ‰ª§Êù•‰øùËØÅ python ÁâàÊú¨ÂíåÁõ∏ÂÖ≥‰æùËµñÂåÖÁöÑ‰∏ÄËá¥ÊÄß
uv sync
```

### üåê ÊµèËßàÂô®È©±Âä®ÂÆâË£Ö

```shell
# ÂÆâË£ÖÊµèËßàÂô®È©±Âä®
uv run playwright install
```

## üöÄ ËøêË°åÁà¨Ëô´Á®ãÂ∫è

```shell
# Âú® config/base_config.py Êü•ÁúãÈÖçÁΩÆÈ°πÁõÆÂäüËÉΩÔºåÂÜôÁöÑÊúâ‰∏≠ÊñáÊ≥®Èáä

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÂÖ≥ÈîÆËØçÊêúÁ¥¢Áõ∏ÂÖ≥ÁöÑÂ∏ñÂ≠êÂπ∂Áà¨ÂèñÂ∏ñÂ≠ê‰ø°ÊÅØ‰∏éËØÑËÆ∫
uv run main.py --platform xhs --lt qrcode --type search

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÊåáÂÆöÁöÑÂ∏ñÂ≠êIDÂàóË°®Ëé∑ÂèñÊåáÂÆöÂ∏ñÂ≠êÁöÑ‰ø°ÊÅØ‰∏éËØÑËÆ∫‰ø°ÊÅØ
uv run main.py --platform xhs --lt qrcode --type detail

# ÊâìÂºÄÂØπÂ∫îAPPÊâ´‰∫åÁª¥Á†ÅÁôªÂΩï

# ÂÖ∂‰ªñÂπ≥Âè∞Áà¨Ëô´‰ΩøÁî®Á§∫‰æãÔºåÊâßË°å‰∏ãÈù¢ÁöÑÂëΩ‰ª§Êü•Áúã
uv run main.py --help
```

&lt;details&gt;
&lt;summary&gt;üñ•Ô∏è &lt;strong&gt;WebUI ÂèØËßÜÂåñÊìç‰ΩúÁïåÈù¢&lt;/strong&gt;&lt;/summary&gt;

MediaCrawler Êèê‰æõ‰∫ÜÂü∫‰∫é Web ÁöÑÂèØËßÜÂåñÊìç‰ΩúÁïåÈù¢ÔºåÊó†ÈúÄÂëΩ‰ª§Ë°å‰πüËÉΩËΩªÊùæ‰ΩøÁî®Áà¨Ëô´ÂäüËÉΩ„ÄÇ

#### ÂêØÂä® WebUI ÊúçÂä°

```shell
# ÂêØÂä® API ÊúçÂä°Âô®ÔºàÈªòËÆ§Á´ØÂè£ 8080Ôºâ
uv run uvicorn api.main:app --port 8080 --reload

# ÊàñËÄÖ‰ΩøÁî®Ê®°ÂùóÊñπÂºèÂêØÂä®
uv run python -m api.main
```

ÂêØÂä®ÊàêÂäüÂêéÔºåËÆøÈóÆ `http://localhost:8080` Âç≥ÂèØÊâìÂºÄ WebUI ÁïåÈù¢„ÄÇ

#### WebUI ÂäüËÉΩÁâπÊÄß

- ÂèØËßÜÂåñÈÖçÁΩÆÁà¨Ëô´ÂèÇÊï∞ÔºàÂπ≥Âè∞„ÄÅÁôªÂΩïÊñπÂºè„ÄÅÁà¨ÂèñÁ±ªÂûãÁ≠âÔºâ
- ÂÆûÊó∂Êü•ÁúãÁà¨Ëô´ËøêË°åÁä∂ÊÄÅÂíåÊó•Âøó
- Êï∞ÊçÆÈ¢ÑËßàÂíåÂØºÂá∫

#### ÁïåÈù¢È¢ÑËßà

&lt;img src=&quot;docs/static/images/img_8.png&quot; alt=&quot;WebUI ÁïåÈù¢È¢ÑËßà&quot;&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;üîó &lt;strong&gt;‰ΩøÁî® Python ÂéüÁîü venv ÁÆ°ÁêÜÁéØÂ¢ÉÔºà‰∏çÊé®ËçêÔºâ&lt;/strong&gt;&lt;/summary&gt;

#### ÂàõÂª∫Âπ∂ÊøÄÊ¥ª Python ËôöÊãüÁéØÂ¢É

&gt; Â¶ÇÊûúÊòØÁà¨ÂèñÊäñÈü≥ÂíåÁü•‰πéÔºåÈúÄË¶ÅÊèêÂâçÂÆâË£Ö nodejs ÁéØÂ¢ÉÔºåÁâàÊú¨Â§ß‰∫éÁ≠â‰∫éÔºö`16` Âç≥ÂèØ

```shell
# ËøõÂÖ•È°πÁõÆÊ†πÁõÆÂΩï
cd MediaCrawler

# ÂàõÂª∫ËôöÊãüÁéØÂ¢É
# ÊàëÁöÑ python ÁâàÊú¨ÊòØÔºö3.11 requirements.txt ‰∏≠ÁöÑÂ∫ìÊòØÂü∫‰∫éËøô‰∏™ÁâàÊú¨ÁöÑ
# Â¶ÇÊûúÊòØÂÖ∂‰ªñ python ÁâàÊú¨ÔºåÂèØËÉΩ requirements.txt ‰∏≠ÁöÑÂ∫ì‰∏çÂÖºÂÆπÔºåÈúÄËá™Ë°åËß£ÂÜ≥
python -m venv venv

# macOS &amp; Linux ÊøÄÊ¥ªËôöÊãüÁéØÂ¢É
source venv/bin/activate

# Windows ÊøÄÊ¥ªËôöÊãüÁéØÂ¢É
venv\Scripts\activate
```

#### ÂÆâË£Ö‰æùËµñÂ∫ì

```shell
pip install -r requirements.txt
```

#### ÂÆâË£Ö playwright ÊµèËßàÂô®È©±Âä®

```shell
playwright install
```

#### ËøêË°åÁà¨Ëô´Á®ãÂ∫èÔºàÂéüÁîüÁéØÂ¢ÉÔºâ

```shell
# È°πÁõÆÈªòËÆ§ÊòØÊ≤°ÊúâÂºÄÂêØËØÑËÆ∫Áà¨ÂèñÊ®°ÂºèÔºåÂ¶ÇÈúÄËØÑËÆ∫ËØ∑Âú® config/base_config.py ‰∏≠ÁöÑ ENABLE_GET_COMMENTS ÂèòÈáè‰øÆÊîπ
# ‰∏Ä‰∫õÂÖ∂‰ªñÊîØÊåÅÈ°πÔºå‰πüÂèØ‰ª•Âú® config/base_config.py Êü•ÁúãÂäüËÉΩÔºåÂÜôÁöÑÊúâ‰∏≠ÊñáÊ≥®Èáä

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÂÖ≥ÈîÆËØçÊêúÁ¥¢Áõ∏ÂÖ≥ÁöÑÂ∏ñÂ≠êÂπ∂Áà¨ÂèñÂ∏ñÂ≠ê‰ø°ÊÅØ‰∏éËØÑËÆ∫
python main.py --platform xhs --lt qrcode --type search

# ‰ªéÈÖçÁΩÆÊñá‰ª∂‰∏≠ËØªÂèñÊåáÂÆöÁöÑÂ∏ñÂ≠êIDÂàóË°®Ëé∑ÂèñÊåáÂÆöÂ∏ñÂ≠êÁöÑ‰ø°ÊÅØ‰∏éËØÑËÆ∫‰ø°ÊÅØ
python main.py --platform xhs --lt qrcode --type detail

# ÊâìÂºÄÂØπÂ∫îAPPÊâ´‰∫åÁª¥Á†ÅÁôªÂΩï

# ÂÖ∂‰ªñÂπ≥Âè∞Áà¨Ëô´‰ΩøÁî®Á§∫‰æãÔºåÊâßË°å‰∏ãÈù¢ÁöÑÂëΩ‰ª§Êü•Áúã
python main.py --help
```

&lt;/details&gt;


## üíæ Êï∞ÊçÆ‰øùÂ≠ò

MediaCrawler ÊîØÊåÅÂ§öÁßçÊï∞ÊçÆÂ≠òÂÇ®ÊñπÂºèÔºåÂåÖÊã¨ CSV„ÄÅJSON„ÄÅExcel„ÄÅSQLite Âíå MySQL Êï∞ÊçÆÂ∫ì„ÄÇ

üìñ **ËØ¶ÁªÜ‰ΩøÁî®ËØ¥ÊòéËØ∑Êü•ÁúãÔºö[Êï∞ÊçÆÂ≠òÂÇ®ÊåáÂçó](docs/data_storage_guide.md)**


[üöÄ MediaCrawlerPro ÈáçÁ£ÖÂèëÂ∏É üöÄÔºÅÊõ¥Â§öÁöÑÂäüËÉΩÔºåÊõ¥Â•ΩÁöÑÊû∂ÊûÑËÆæËÆ°ÔºÅÂºÄÊ∫ê‰∏çÊòìÔºåÊ¨¢ËøéËÆ¢ÈòÖÊîØÊåÅÔºÅ](https://github.com/MediaCrawlerPro)


## üí¨ ‰∫§ÊµÅÁæ§ÁªÑ
- **ÂæÆ‰ø°‰∫§ÊµÅÁæ§**Ôºö[ÁÇπÂáªÂä†ÂÖ•](https://nanmicoder.github.io/MediaCrawler/%E5%BE%AE%E4%BF%A1%E4%BA%A4%E6%B5%81%E7%BE%A4.html)
- **BÁ´ôË¥¶Âè∑**Ôºö[ÂÖ≥Ê≥®Êàë](https://space.bilibili.com/434377496)ÔºåÂàÜ‰∫´AI‰∏éÁà¨Ëô´ÊäÄÊúØÁü•ËØÜ


## üí∞ ËµûÂä©ÂïÜÂ±ïÁ§∫

&lt;a href=&quot;https://tikhub.io/?utm_source=github.com/NanmiCoder/MediaCrawler&amp;utm_medium=marketing_social&amp;utm_campaign=retargeting&amp;utm_content=carousel_ad&quot;&gt;
&lt;img width=&quot;500&quot; src=&quot;docs/static/images/tikhub_banner_zh.png&quot;&gt;
&lt;br&gt;
TikHub.io Êèê‰æõ 900+ È´òÁ®≥ÂÆöÊÄßÊï∞ÊçÆÊé•Âè£ÔºåË¶ÜÁõñ TK„ÄÅDY„ÄÅXHS„ÄÅY2B„ÄÅIns„ÄÅX Á≠â 14+ Êµ∑ÂÜÖÂ§ñ‰∏ªÊµÅÂπ≥Âè∞ÔºåÊîØÊåÅÁî®Êà∑„ÄÅÂÜÖÂÆπ„ÄÅÂïÜÂìÅ„ÄÅËØÑËÆ∫Á≠âÂ§öÁª¥Â∫¶ÂÖ¨ÂºÄÊï∞ÊçÆ APIÔºåÂπ∂ÈÖçÂ•ó 4000 ‰∏á+ Â∑≤Ê∏ÖÊ¥óÁªìÊûÑÂåñÊï∞ÊçÆÈõÜÔºå‰ΩøÁî®ÈÇÄËØ∑Á†Å &lt;code&gt;cfzyejV9&lt;/code&gt; Ê≥®ÂÜåÂπ∂ÂÖÖÂÄºÔºåÂç≥ÂèØÈ¢ùÂ§ñËé∑Âæó $2 Ëµ†ÈÄÅÈ¢ùÂ∫¶„ÄÇ
&lt;/a&gt;

---

&lt;a href=&quot;https://www.thordata.com/?ls=github&amp;lk=mediacrawler&quot;&gt;
&lt;img width=&quot;500&quot; src=&quot;docs/static/images/Thordata.png&quot;&gt;
&lt;br&gt;
ThordataÔºöÂèØÈù†‰∏îÁªèÊµéÈ´òÊïàÁöÑ‰ª£ÁêÜÊúçÂä°Êèê‰æõÂïÜ„ÄÇ‰∏∫‰ºÅ‰∏öÂíåÂºÄÂèëËÄÖÊèê‰æõÁ®≥ÂÆö„ÄÅÈ´òÊïà‰∏îÂêàËßÑÁöÑÂÖ®ÁêÉ‰ª£ÁêÜ IP ÊúçÂä°„ÄÇÁ´ãÂç≥Ê≥®ÂÜåÔºåËµ†ÈÄÅ1GB‰ΩèÂÆÖ‰ª£ÁêÜÂÖçË¥πËØïÁî®Âíå2000Ê¨°serp-apiË∞ÉÁî®„ÄÇ
&lt;/a&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.thordata.com/products/residential-proxies/?ls=github&amp;lk=mediacrawler&quot;&gt;„Äê‰ΩèÂÆÖ‰ª£ÁêÜ„Äë&lt;/a&gt; | &lt;a href=&quot;https://www.thordata.com/products/web-scraper/?ls=github&amp;lk=mediacrawler&quot;&gt;„Äêserp-api„Äë&lt;/a&gt;


## ü§ù Êàê‰∏∫ËµûÂä©ËÄÖ

Êàê‰∏∫ËµûÂä©ËÄÖÔºåÂèØ‰ª•Â∞ÜÊÇ®ÁöÑ‰∫ßÂìÅÂ±ïÁ§∫Âú®ËøôÈáåÔºåÊØèÂ§©Ëé∑ÂæóÂ§ßÈáèÊõùÂÖâÔºÅ

**ËÅîÁ≥ªÊñπÂºè**Ôºö
- ÂæÆ‰ø°Ôºö`relakkes`
- ÈÇÆÁÆ±Ôºö`relakkes@gmail.com`
---

## üìö ÂÖ∂‰ªñ
- **Â∏∏ËßÅÈóÆÈ¢ò**Ôºö[MediaCrawler ÂÆåÊï¥ÊñáÊ°£](https://nanmicoder.github.io/MediaCrawler/)
- **Áà¨Ëô´ÂÖ•Èó®ÊïôÁ®ã**Ôºö[CrawlerTutorial ÂÖçË¥πÊïôÁ®ã](https://github.com/NanmiCoder/CrawlerTutorial)
- **Êñ∞ÈóªÁà¨Ëô´ÂºÄÊ∫êÈ°πÁõÆ**Ôºö[NewsCrawlerCollection](https://github.com/NanmiCoder/NewsCrawlerCollection)


## ‚≠ê Star Ë∂ãÂäøÂõæ

Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑Áªô‰∏™ ‚≠ê Star ÊîØÊåÅ‰∏Ä‰∏ãÔºåËÆ©Êõ¥Â§öÁöÑ‰∫∫ÁúãÂà∞ MediaCrawlerÔºÅ

[![Star History Chart](https://api.star-history.com/svg?repos=NanmiCoder/MediaCrawler&amp;type=Date)](https://star-history.com/#NanmiCoder/MediaCrawler&amp;Date)


## üìö ÂèÇËÄÉ

- **Â∞èÁ∫¢‰π¶Á≠æÂêç‰ªìÂ∫ì**Ôºö[Cloxl ÁöÑ xhs Á≠æÂêç‰ªìÂ∫ì](https://github.com/Cloxl/xhshow)
- **Â∞èÁ∫¢‰π¶ÂÆ¢Êà∑Á´Ø**Ôºö[ReaJason ÁöÑ xhs ‰ªìÂ∫ì](https://github.com/ReaJason/xhs)
- **Áü≠‰ø°ËΩ¨Âèë**Ôºö[SmsForwarder ÂèÇËÄÉ‰ªìÂ∫ì](https://github.com/pppscn/SmsForwarder)
- **ÂÜÖÁΩëÁ©øÈÄèÂ∑•ÂÖ∑**Ôºö[ngrok ÂÆòÊñπÊñáÊ°£](https://ngrok.com/docs/)


# ÂÖçË¥£Â£∞Êòé
&lt;div id=&quot;disclaimer&quot;&gt; 

## 1. È°πÁõÆÁõÆÁöÑ‰∏éÊÄßË¥®
Êú¨È°πÁõÆÔºà‰ª•‰∏ãÁÆÄÁß∞‚ÄúÊú¨È°πÁõÆ‚ÄùÔºâÊòØ‰Ωú‰∏∫‰∏Ä‰∏™ÊäÄÊúØÁ†îÁ©∂‰∏éÂ≠¶‰π†Â∑•ÂÖ∑ËÄåÂàõÂª∫ÁöÑÔºåÊó®Âú®Êé¢Á¥¢ÂíåÂ≠¶‰π†ÁΩëÁªúÊï∞ÊçÆÈááÈõÜÊäÄÊúØ„ÄÇÊú¨È°πÁõÆ‰∏ìÊ≥®‰∫éËá™Â™í‰ΩìÂπ≥Âè∞ÁöÑÊï∞ÊçÆÁà¨ÂèñÊäÄÊúØÁ†îÁ©∂ÔºåÊó®Âú®Êèê‰æõÁªôÂ≠¶‰π†ËÄÖÂíåÁ†îÁ©∂ËÄÖ‰Ωú‰∏∫ÊäÄÊúØ‰∫§ÊµÅ‰πãÁî®„ÄÇ

## 2. Ê≥ïÂæãÂêàËßÑÊÄßÂ£∞Êòé
Êú¨È°πÁõÆÂºÄÂèëËÄÖÔºà‰ª•‰∏ãÁÆÄÁß∞‚ÄúÂºÄÂèëËÄÖ‚ÄùÔºâÈÉëÈáçÊèêÈÜíÁî®Êà∑Âú®‰∏ãËΩΩ„ÄÅÂÆâË£ÖÂíå‰ΩøÁî®Êú¨È°πÁõÆÊó∂Ôºå‰∏•Ê†ºÈÅµÂÆà‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫é„Ää‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÁΩëÁªúÂÆâÂÖ®Ê≥ï„Äã„ÄÅ„Ää‰∏≠Âçé‰∫∫Ê∞ëÂÖ±ÂíåÂõΩÂèçÈó¥Ë∞çÊ≥ï„ÄãÁ≠âÊâÄÊúâÈÄÇÁî®ÁöÑÂõΩÂÆ∂Ê≥ïÂæãÂíåÊîøÁ≠ñ„ÄÇÁî®Êà∑Â∫îËá™Ë°åÊâøÊãÖ‰∏ÄÂàáÂõ†‰ΩøÁî®Êú¨È°πÁõÆËÄåÂèØËÉΩÂºïËµ∑ÁöÑÊ≥ïÂæãË¥£‰ªª„ÄÇ

## 3. ‰ΩøÁî®ÁõÆÁöÑÈôêÂà∂
Êú¨È°πÁõÆ‰∏•Á¶ÅÁî®‰∫é‰ªª‰ΩïÈùûÊ≥ïÁõÆÁöÑÊàñÈùûÂ≠¶‰π†„ÄÅÈùûÁ†îÁ©∂ÁöÑÂïÜ‰∏öË°å‰∏∫„ÄÇÊú¨È°πÁõÆ‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂΩ¢ÂºèÁöÑÈùûÊ≥ï‰æµÂÖ•‰ªñ‰∫∫ËÆ°ÁÆóÊú∫Á≥ªÁªüÔºå‰∏çÂæóÁî®‰∫é‰ªª‰Ωï‰æµÁäØ‰ªñ‰∫∫Áü•ËØÜ‰∫ßÊùÉÊàñÂÖ∂‰ªñÂêàÊ≥ïÊùÉÁõäÁöÑË°å‰∏∫„ÄÇÁî®Êà∑Â∫î‰øùËØÅÂÖ∂‰ΩøÁî®Êú¨È°πÁõÆÁöÑÁõÆÁöÑÁ∫ØÂ±û‰∏™‰∫∫Â≠¶‰π†ÂíåÊäÄÊúØÁ†îÁ©∂Ôºå‰∏çÂæóÁî®‰∫é‰ªª‰ΩïÂΩ¢ÂºèÁöÑÈùûÊ≥ïÊ¥ªÂä®„ÄÇ

## 4. ÂÖçË¥£Â£∞Êòé
ÂºÄÂèëËÄÖÂ∑≤Â∞ΩÊúÄÂ§ßÂä™ÂäõÁ°Æ‰øùÊú¨È°πÁõÆÁöÑÊ≠£ÂΩìÊÄßÂèäÂÆâÂÖ®ÊÄßÔºå‰ΩÜ‰∏çÂØπÁî®Êà∑‰ΩøÁî®Êú¨È°πÁõÆÂèØËÉΩÂºïËµ∑ÁöÑ‰ªª‰ΩïÂΩ¢ÂºèÁöÑÁõ¥Êé•ÊàñÈó¥Êé•ÊçüÂ§±ÊâøÊãÖË¥£‰ªª„ÄÇÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÁî±‰∫é‰ΩøÁî®Êú¨È°πÁõÆËÄåÂØºËá¥ÁöÑ‰ªª‰ΩïÊï∞ÊçÆ‰∏¢Â§±„ÄÅËÆæÂ§áÊçüÂùè„ÄÅÊ≥ïÂæãËØâËÆºÁ≠â„ÄÇ

## 5. Áü•ËØÜ‰∫ßÊùÉÂ£∞Êòé
Êú¨È°πÁõÆÁöÑÁü•ËØÜ‰∫ßÊùÉÂΩíÂºÄÂèëËÄÖÊâÄÊúâ„ÄÇÊú¨È°πÁõÆÂèóÂà∞Ëëó‰ΩúÊùÉÊ≥ïÂíåÂõΩÈôÖËëó‰ΩúÊùÉÊù°Á∫¶‰ª•ÂèäÂÖ∂‰ªñÁü•ËØÜ‰∫ßÊùÉÊ≥ïÂæãÂíåÊù°Á∫¶ÁöÑ‰øùÊä§„ÄÇÁî®Êà∑Âú®ÈÅµÂÆàÊú¨Â£∞ÊòéÂèäÁõ∏ÂÖ≥Ê≥ïÂæãÊ≥ïËßÑÁöÑÂâçÊèê‰∏ãÔºåÂèØ‰ª•‰∏ãËΩΩÂíå‰ΩøÁî®Êú¨È°πÁõÆ„ÄÇ

## 6. ÊúÄÁªàËß£ÈáäÊùÉ
ÂÖ≥‰∫éÊú¨È°πÁõÆÁöÑÊúÄÁªàËß£ÈáäÊùÉÂΩíÂºÄÂèëËÄÖÊâÄÊúâ„ÄÇÂºÄÂèëËÄÖ‰øùÁïôÈöèÊó∂Êõ¥ÊîπÊàñÊõ¥Êñ∞Êú¨ÂÖçË¥£Â£∞ÊòéÁöÑÊùÉÂà©ÔºåÊÅï‰∏çÂè¶Ë°åÈÄöÁü•„ÄÇ
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[AUTOMATIC1111/stable-diffusion-webui]]></title>
            <link>https://github.com/AUTOMATIC1111/stable-diffusion-webui</link>
            <guid>https://github.com/AUTOMATIC1111/stable-diffusion-webui</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:14 GMT</pubDate>
            <description><![CDATA[Stable Diffusion web UI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">AUTOMATIC1111/stable-diffusion-webui</a></h1>
            <p>Stable Diffusion web UI</p>
            <p>Language: Python</p>
            <p>Stars: 161,232</p>
            <p>Forks: 30,056</p>
            <p>Stars today: 359 stars today</p>
            <h2>README</h2><pre># Stable Diffusion web UI
A web interface for Stable Diffusion, implemented using Gradio library.

![](screenshot.png)

## Features
[Detailed feature showcase with images](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features):
- Original txt2img and img2img modes
- One click install and run script (but you still must install python and git)
- Outpainting
- Inpainting
- Color Sketch
- Prompt Matrix
- Stable Diffusion Upscale
- Attention, specify parts of text that the model should pay more attention to
    - a man in a `((tuxedo))` - will pay more attention to tuxedo
    - a man in a `(tuxedo:1.21)` - alternative syntax
    - select text and press `Ctrl+Up` or `Ctrl+Down` (or `Command+Up` or `Command+Down` if you&#039;re on a MacOS) to automatically adjust attention to selected text (code contributed by anonymous user)
- Loopback, run img2img processing multiple times
- X/Y/Z plot, a way to draw a 3 dimensional plot of images with different parameters
- Textual Inversion
    - have as many embeddings as you want and use any names you like for them
    - use multiple embeddings with different numbers of vectors per token
    - works with half precision floating point numbers
    - train embeddings on 8GB (also reports of 6GB working)
- Extras tab with:
    - GFPGAN, neural network that fixes faces
    - CodeFormer, face restoration tool as an alternative to GFPGAN
    - RealESRGAN, neural network upscaler
    - ESRGAN, neural network upscaler with a lot of third party models
    - SwinIR and Swin2SR ([see here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/pull/2092)), neural network upscalers
    - LDSR, Latent diffusion super resolution upscaling
- Resizing aspect ratio options
- Sampling method selection
    - Adjust sampler eta values (noise multiplier)
    - More advanced noise setting options
- Interrupt processing at any time
- 4GB video card support (also reports of 2GB working)
- Correct seeds for batches
- Live prompt token length validation
- Generation parameters
     - parameters you used to generate images are saved with that image
     - in PNG chunks for PNG, in EXIF for JPEG
     - can drag the image to PNG info tab to restore generation parameters and automatically copy them into UI
     - can be disabled in settings
     - drag and drop an image/text-parameters to promptbox
- Read Generation Parameters Button, loads parameters in promptbox to UI
- Settings page
- Running arbitrary python code from UI (must run with `--allow-code` to enable)
- Mouseover hints for most UI elements
- Possible to change defaults/mix/max/step values for UI elements via text config
- Tiling support, a checkbox to create images that can be tiled like textures
- Progress bar and live image generation preview
    - Can use a separate neural network to produce previews with almost none VRAM or compute requirement
- Negative prompt, an extra text field that allows you to list what you don&#039;t want to see in generated image
- Styles, a way to save part of prompt and easily apply them via dropdown later
- Variations, a way to generate same image but with tiny differences
- Seed resizing, a way to generate same image but at slightly different resolution
- CLIP interrogator, a button that tries to guess prompt from an image
- Prompt Editing, a way to change prompt mid-generation, say to start making a watermelon and switch to anime girl midway
- Batch Processing, process a group of files using img2img
- Img2img Alternative, reverse Euler method of cross attention control
- Highres Fix, a convenience option to produce high resolution pictures in one click without usual distortions
- Reloading checkpoints on the fly
- Checkpoint Merger, a tab that allows you to merge up to 3 checkpoints into one
- [Custom scripts](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts) with many extensions from community
- [Composable-Diffusion](https://energy-based-model.github.io/Compositional-Visual-Generation-with-Composable-Diffusion-Models/), a way to use multiple prompts at once
     - separate prompts using uppercase `AND`
     - also supports weights for prompts: `a cat :1.2 AND a dog AND a penguin :2.2`
- No token limit for prompts (original stable diffusion lets you use up to 75 tokens)
- DeepDanbooru integration, creates danbooru style tags for anime prompts
- [xformers](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Xformers), major speed increase for select cards: (add `--xformers` to commandline args)
- via extension: [History tab](https://github.com/yfszzx/stable-diffusion-webui-images-browser): view, direct and delete images conveniently within the UI
- Generate forever option
- Training tab
     - hypernetworks and embeddings options
     - Preprocessing images: cropping, mirroring, autotagging using BLIP or deepdanbooru (for anime)
- Clip skip
- Hypernetworks
- Loras (same as Hypernetworks but more pretty)
- A separate UI where you can choose, with preview, which embeddings, hypernetworks or Loras to add to your prompt
- Can select to load a different VAE from settings screen
- Estimated completion time in progress bar
- API
- Support for dedicated [inpainting model](https://github.com/runwayml/stable-diffusion#inpainting-with-stable-diffusion) by RunwayML
- via extension: [Aesthetic Gradients](https://github.com/AUTOMATIC1111/stable-diffusion-webui-aesthetic-gradients), a way to generate images with a specific aesthetic by using clip images embeds (implementation of [https://github.com/vicgalle/stable-diffusion-aesthetic-gradients](https://github.com/vicgalle/stable-diffusion-aesthetic-gradients))
- [Stable Diffusion 2.0](https://github.com/Stability-AI/stablediffusion) support - see [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#stable-diffusion-20) for instructions
- [Alt-Diffusion](https://arxiv.org/abs/2211.06679) support - see [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Features#alt-diffusion) for instructions
- Now without any bad letters!
- Load checkpoints in safetensors format
- Eased resolution restriction: generated image&#039;s dimensions must be a multiple of 8 rather than 64
- Now with a license!
- Reorder elements in the UI from settings screen
- [Segmind Stable Diffusion](https://huggingface.co/segmind/SSD-1B) support

## Installation and Running
Make sure the required [dependencies](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Dependencies) are met and follow the instructions available for:
- [NVidia](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs) (recommended)
- [AMD](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-AMD-GPUs) GPUs.
- [Intel CPUs, Intel GPUs (both integrated and discrete)](https://github.com/openvinotoolkit/stable-diffusion-webui/wiki/Installation-on-Intel-Silicon) (external wiki page)
- [Ascend NPUs](https://github.com/wangshuai09/stable-diffusion-webui/wiki/Install-and-run-on-Ascend-NPUs) (external wiki page)

Alternatively, use online services (like Google Colab):

- [List of Online Services](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Online-Services)

### Installation on Windows 10/11 with NVidia-GPUs using release package
1. Download `sd.webui.zip` from [v1.0.0-pre](https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases/tag/v1.0.0-pre) and extract its contents.
2. Run `update.bat`.
3. Run `run.bat`.
&gt; For more details see [Install-and-Run-on-NVidia-GPUs](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs)

### Automatic Installation on Windows
1. Install [Python 3.10.6](https://www.python.org/downloads/release/python-3106/) (Newer version of Python does not support torch), checking &quot;Add Python to PATH&quot;.
2. Install [git](https://git-scm.com/download/win).
3. Download the stable-diffusion-webui repository, for example by running `git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git`.
4. Run `webui-user.bat` from Windows Explorer as normal, non-administrator, user.

### Automatic Installation on Linux
1. Install the dependencies:
```bash
# Debian-based:
sudo apt install wget git python3 python3-venv libgl1 libglib2.0-0
# Red Hat-based:
sudo dnf install wget git python3 gperftools-libs libglvnd-glx
# openSUSE-based:
sudo zypper install wget git python3 libtcmalloc4 libglvnd
# Arch-based:
sudo pacman -S wget git python3
```
If your system is very new, you need to install python3.11 or python3.10:
```bash
# Ubuntu 24.04
sudo add-apt-repository ppa:deadsnakes/ppa
sudo apt update
sudo apt install python3.11

# Manjaro/Arch
sudo pacman -S yay
yay -S python311 # do not confuse with python3.11 package

# Only for 3.11
# Then set up env variable in launch script
export python_cmd=&quot;python3.11&quot;
# or in webui-user.sh
python_cmd=&quot;python3.11&quot;
```
2. Navigate to the directory you would like the webui to be installed and execute the following command:
```bash
wget -q https://raw.githubusercontent.com/AUTOMATIC1111/stable-diffusion-webui/master/webui.sh
```
Or just clone the repo wherever you want:
```bash
git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui
```

3. Run `webui.sh`.
4. Check `webui-user.sh` for options.
### Installation on Apple Silicon

Find the instructions [here](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Installation-on-Apple-Silicon).

## Contributing
Here&#039;s how to add code to this repo: [Contributing](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Contributing)

## Documentation

The documentation was moved from this README over to the project&#039;s [wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki).

For the purposes of getting Google and other search engines to crawl the wiki, here&#039;s a link to the (not for humans) [crawlable wiki](https://github-wiki-see.page/m/AUTOMATIC1111/stable-diffusion-webui/wiki).

## Credits
Licenses for borrowed code can be found in `Settings -&gt; Licenses` screen, and also in `html/licenses.html` file.

- Stable Diffusion - https://github.com/Stability-AI/stablediffusion, https://github.com/CompVis/taming-transformers, https://github.com/mcmonkey4eva/sd3-ref
- k-diffusion - https://github.com/crowsonkb/k-diffusion.git
- Spandrel - https://github.com/chaiNNer-org/spandrel implementing
  - GFPGAN - https://github.com/TencentARC/GFPGAN.git
  - CodeFormer - https://github.com/sczhou/CodeFormer
  - ESRGAN - https://github.com/xinntao/ESRGAN
  - SwinIR - https://github.com/JingyunLiang/SwinIR
  - Swin2SR - https://github.com/mv-lab/swin2sr
- LDSR - https://github.com/Hafiidz/latent-diffusion
- MiDaS - https://github.com/isl-org/MiDaS
- Ideas for optimizations - https://github.com/basujindal/stable-diffusion
- Cross Attention layer optimization - Doggettx - https://github.com/Doggettx/stable-diffusion, original idea for prompt editing.
- Cross Attention layer optimization - InvokeAI, lstein - https://github.com/invoke-ai/InvokeAI (originally http://github.com/lstein/stable-diffusion)
- Sub-quadratic Cross Attention layer optimization - Alex Birch (https://github.com/Birch-san/diffusers/pull/1), Amin Rezaei (https://github.com/AminRezaei0x443/memory-efficient-attention)
- Textual Inversion - Rinon Gal - https://github.com/rinongal/textual_inversion (we&#039;re not using his code, but we are using his ideas).
- Idea for SD upscale - https://github.com/jquesnelle/txt2imghd
- Noise generation for outpainting mk2 - https://github.com/parlance-zz/g-diffuser-bot
- CLIP interrogator idea and borrowing some code - https://github.com/pharmapsychotic/clip-interrogator
- Idea for Composable Diffusion - https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch
- xformers - https://github.com/facebookresearch/xformers
- DeepDanbooru - interrogator for anime diffusers https://github.com/KichangKim/DeepDanbooru
- Sampling in float32 precision from a float16 UNet - marunine for the idea, Birch-san for the example Diffusers implementation (https://github.com/Birch-san/diffusers-play/tree/92feee6)
- Instruct pix2pix - Tim Brooks (star), Aleksander Holynski (star), Alexei A. Efros (no star) - https://github.com/timothybrooks/instruct-pix2pix
- Security advice - RyotaK
- UniPC sampler - Wenliang Zhao - https://github.com/wl-zhao/UniPC
- TAESD - Ollin Boer Bohan - https://github.com/madebyollin/taesd
- LyCORIS - KohakuBlueleaf
- Restart sampling - lambertae - https://github.com/Newbeeer/diffusion_restart_sampling
- Hypertile - tfernd - https://github.com/tfernd/HyperTile
- Initial Gradio script - posted on 4chan by an Anonymous user. Thank you Anonymous user.
- (You)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[BerriAI/litellm]]></title>
            <link>https://github.com/BerriAI/litellm</link>
            <guid>https://github.com/BerriAI/litellm</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:13 GMT</pubDate>
            <description><![CDATA[Python SDK, Proxy Server (AI Gateway) to call 100+ LLM APIs in OpenAI (or native) format, with cost tracking, guardrails, loadbalancing and logging. [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, VLLM, NVIDIA NIM]]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/BerriAI/litellm">BerriAI/litellm</a></h1>
            <p>Python SDK, Proxy Server (AI Gateway) to call 100+ LLM APIs in OpenAI (or native) format, with cost tracking, guardrails, loadbalancing and logging. [Bedrock, Azure, OpenAI, VertexAI, Cohere, Anthropic, Sagemaker, HuggingFace, VLLM, NVIDIA NIM]</p>
            <p>Language: Python</p>
            <p>Stars: 36,909</p>
            <p>Forks: 5,984</p>
            <p>Stars today: 124 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
        üöÖ LiteLLM
    &lt;/h1&gt;
    &lt;p align=&quot;center&quot;&gt;
        &lt;p align=&quot;center&quot;&gt;Call 100+ LLMs in OpenAI format. [Bedrock, Azure, OpenAI, VertexAI, Anthropic, Groq, etc.]
        &lt;/p&gt;
        &lt;p align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://render.com/deploy?repo=https://github.com/BerriAI/litellm&quot; target=&quot;_blank&quot; rel=&quot;nofollow&quot;&gt;&lt;img src=&quot;https://render.com/images/deploy-to-render-button.svg&quot; alt=&quot;Deploy to Render&quot;&gt;&lt;/a&gt;
        &lt;a href=&quot;https://railway.app/template/HLP0Ub?referralCode=jch2ME&quot;&gt;
          &lt;img src=&quot;https://railway.app/button.svg&quot; alt=&quot;Deploy on Railway&quot;&gt;
        &lt;/a&gt;
        &lt;/p&gt;
    &lt;/p&gt;
&lt;h4 align=&quot;center&quot;&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/simple_proxy&quot; target=&quot;_blank&quot;&gt;LiteLLM Proxy Server (AI Gateway)&lt;/a&gt; | &lt;a href=&quot;https://docs.litellm.ai/docs/enterprise#hosted-litellm-proxy&quot; target=&quot;_blank&quot;&gt; Hosted Proxy&lt;/a&gt; | &lt;a href=&quot;https://docs.litellm.ai/docs/enterprise&quot;target=&quot;_blank&quot;&gt;Enterprise Tier&lt;/a&gt;&lt;/h4&gt;
&lt;h4 align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://pypi.org/project/litellm/&quot; target=&quot;_blank&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/pypi/v/litellm.svg&quot; alt=&quot;PyPI Version&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.ycombinator.com/companies/berriai&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/Y%20Combinator-W23-orange?style=flat-square&quot; alt=&quot;Y Combinator W23&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://wa.link/huol9n&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;message=WhatsApp&amp;color=success&amp;logo=WhatsApp&amp;style=flat-square&quot; alt=&quot;Whatsapp&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://discord.gg/wuPM9dRgDw&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;message=Discord&amp;color=blue&amp;logo=Discord&amp;style=flat-square&quot; alt=&quot;Discord&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://www.litellm.ai/support&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/static/v1?label=Chat%20on&amp;message=Slack&amp;color=black&amp;logo=Slack&amp;style=flat-square&quot; alt=&quot;Slack&quot;&gt;
    &lt;/a&gt;
&lt;/h4&gt;

&lt;img width=&quot;2688&quot; height=&quot;1600&quot; alt=&quot;Group 7154 (1)&quot; src=&quot;https://github.com/user-attachments/assets/c5ee0412-6fb5-4fb6-ab5b-bafae4209ca6&quot; /&gt;


## Use LiteLLM for

&lt;details open&gt;
&lt;summary&gt;&lt;b&gt;LLMs&lt;/b&gt; - Call 100+ LLMs (Python SDK + AI Gateway)&lt;/summary&gt;

[**All Supported Endpoints**](https://docs.litellm.ai/docs/supported_endpoints) - `/chat/completions`, `/responses`, `/embeddings`, `/images`, `/audio`, `/batches`, `/rerank`, `/a2a`, `/messages` and more.

### Python SDK

```shell
pip install litellm
```

```python
from litellm import completion
import os

os.environ[&quot;OPENAI_API_KEY&quot;] = &quot;your-openai-key&quot;
os.environ[&quot;ANTHROPIC_API_KEY&quot;] = &quot;your-anthropic-key&quot;

# OpenAI
response = completion(model=&quot;openai/gpt-4o&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}])

# Anthropic  
response = completion(model=&quot;anthropic/claude-sonnet-4-20250514&quot;, messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}])
```

### AI Gateway (Proxy Server)

[**Getting Started - E2E Tutorial**](https://docs.litellm.ai/docs/proxy/docker_quick_start) - Setup virtual keys, make your first request

```shell
pip install &#039;litellm[proxy]&#039;
litellm --model gpt-4o
```

```python
import openai

client = openai.OpenAI(api_key=&quot;anything&quot;, base_url=&quot;http://0.0.0.0:4000&quot;)
response = client.chat.completions.create(
    model=&quot;gpt-4o&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hello!&quot;}]
)
```

[**Docs: LLM Providers**](https://docs.litellm.ai/docs/providers)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Agents&lt;/b&gt; - Invoke A2A Agents (Python SDK + AI Gateway)&lt;/summary&gt;

[**Supported Providers**](https://docs.litellm.ai/docs/a2a#add-a2a-agents) - LangGraph, Vertex AI Agent Engine, Azure AI Foundry, Bedrock AgentCore, Pydantic AI

### Python SDK - A2A Protocol

```python
from litellm.a2a_protocol import A2AClient
from a2a.types import SendMessageRequest, MessageSendParams
from uuid import uuid4

client = A2AClient(base_url=&quot;http://localhost:10001&quot;)

request = SendMessageRequest(
    id=str(uuid4()),
    params=MessageSendParams(
        message={
            &quot;role&quot;: &quot;user&quot;,
            &quot;parts&quot;: [{&quot;kind&quot;: &quot;text&quot;, &quot;text&quot;: &quot;Hello!&quot;}],
            &quot;messageId&quot;: uuid4().hex,
        }
    )
)
response = await client.send_message(request)
```

### AI Gateway (Proxy Server)

**Step 1.** [Add your Agent to the AI Gateway](https://docs.litellm.ai/docs/a2a#adding-your-agent)

**Step 2.** Call Agent via A2A SDK

```python
from a2a.client import A2ACardResolver, A2AClient
from a2a.types import MessageSendParams, SendMessageRequest
from uuid import uuid4
import httpx

base_url = &quot;http://localhost:4000/a2a/my-agent&quot;  # LiteLLM proxy + agent name
headers = {&quot;Authorization&quot;: &quot;Bearer sk-1234&quot;}    # LiteLLM Virtual Key

async with httpx.AsyncClient(headers=headers) as httpx_client:
    resolver = A2ACardResolver(httpx_client=httpx_client, base_url=base_url)
    agent_card = await resolver.get_agent_card()
    client = A2AClient(httpx_client=httpx_client, agent_card=agent_card)

    request = SendMessageRequest(
        id=str(uuid4()),
        params=MessageSendParams(
            message={
                &quot;role&quot;: &quot;user&quot;,
                &quot;parts&quot;: [{&quot;kind&quot;: &quot;text&quot;, &quot;text&quot;: &quot;Hello!&quot;}],
                &quot;messageId&quot;: uuid4().hex,
            }
        )
    )
    response = await client.send_message(request)
```

[**Docs: A2A Agent Gateway**](https://docs.litellm.ai/docs/a2a)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;MCP Tools&lt;/b&gt; - Connect MCP servers to any LLM (Python SDK + AI Gateway)&lt;/summary&gt;

### Python SDK - MCP Bridge

```python
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client
from litellm import experimental_mcp_client
import litellm

server_params = StdioServerParameters(command=&quot;python&quot;, args=[&quot;mcp_server.py&quot;])

async with stdio_client(server_params) as (read, write):
    async with ClientSession(read, write) as session:
        await session.initialize()

        # Load MCP tools in OpenAI format
        tools = await experimental_mcp_client.load_mcp_tools(session=session, format=&quot;openai&quot;)

        # Use with any LiteLLM model
        response = await litellm.acompletion(
            model=&quot;gpt-4o&quot;,
            messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;What&#039;s 3 + 5?&quot;}],
            tools=tools
        )
```

### AI Gateway - MCP Gateway

**Step 1.** [Add your MCP Server to the AI Gateway](https://docs.litellm.ai/docs/mcp#adding-your-mcp)

**Step 2.** Call MCP tools via `/chat/completions`

```bash
curl -X POST &#039;http://0.0.0.0:4000/v1/chat/completions&#039; \
  -H &#039;Authorization: Bearer sk-1234&#039; \
  -H &#039;Content-Type: application/json&#039; \
  -d &#039;{
    &quot;model&quot;: &quot;gpt-4o&quot;,
    &quot;messages&quot;: [{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Summarize the latest open PR&quot;}],
    &quot;tools&quot;: [{
      &quot;type&quot;: &quot;mcp&quot;,
      &quot;server_url&quot;: &quot;litellm_proxy/mcp/github&quot;,
      &quot;server_label&quot;: &quot;github_mcp&quot;,
      &quot;require_approval&quot;: &quot;never&quot;
    }]
  }&#039;
```

### Use with Cursor IDE

```json
{
  &quot;mcpServers&quot;: {
    &quot;LiteLLM&quot;: {
      &quot;url&quot;: &quot;http://localhost:4000/mcp/&quot;,
      &quot;headers&quot;: {
        &quot;x-litellm-api-key&quot;: &quot;Bearer sk-1234&quot;
      }
    }
  }
}
```

[**Docs: MCP Gateway**](https://docs.litellm.ai/docs/mcp)

&lt;/details&gt;

---

## How to use LiteLLM

You can use LiteLLM through either the Proxy Server or Python SDK. Both gives you a unified interface to access multiple LLMs (100+ LLMs). Choose the option that best fits your needs:

&lt;table style={{width: &#039;100%&#039;, tableLayout: &#039;fixed&#039;}}&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style={{width: &#039;14%&#039;}}&gt;&lt;/th&gt;
&lt;th style={{width: &#039;43%&#039;}}&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/simple_proxy&quot;&gt;LiteLLM AI Gateway&lt;/a&gt;&lt;/strong&gt;&lt;/th&gt;
&lt;th style={{width: &#039;43%&#039;}}&gt;&lt;strong&gt;&lt;a href=&quot;https://docs.litellm.ai/docs/&quot;&gt;LiteLLM Python SDK&lt;/a&gt;&lt;/strong&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style={{width: &#039;14%&#039;}}&gt;&lt;strong&gt;Use Case&lt;/strong&gt;&lt;/td&gt;
&lt;td style={{width: &#039;43%&#039;}}&gt;Central service (LLM Gateway) to access multiple LLMs&lt;/td&gt;
&lt;td style={{width: &#039;43%&#039;}}&gt;Use LiteLLM directly in your Python code&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style={{width: &#039;14%&#039;}}&gt;&lt;strong&gt;Who Uses It?&lt;/strong&gt;&lt;/td&gt;
&lt;td style={{width: &#039;43%&#039;}}&gt;Gen AI Enablement / ML Platform Teams&lt;/td&gt;
&lt;td style={{width: &#039;43%&#039;}}&gt;Developers building LLM projects&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style={{width: &#039;14%&#039;}}&gt;&lt;strong&gt;Key Features&lt;/strong&gt;&lt;/td&gt;
&lt;td style={{width: &#039;43%&#039;}}&gt;Centralized API gateway with authentication and authorization, multi-tenant cost tracking and spend management per project/user, per-project customization (logging, guardrails, caching), virtual keys for secure access control, admin dashboard UI for monitoring and management&lt;/td&gt;
&lt;td style={{width: &#039;43%&#039;}}&gt;Direct Python library integration in your codebase, Router with retry/fallback logic across multiple deployments (e.g. Azure/OpenAI) - &lt;a href=&quot;https://docs.litellm.ai/docs/routing&quot;&gt;Router&lt;/a&gt;, application-level load balancing and cost tracking, exception handling with OpenAI-compatible errors, observability callbacks (Lunary, MLflow, Langfuse, etc.)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

LiteLLM Performance: **8ms P95 latency** at 1k RPS (See benchmarks [here](https://docs.litellm.ai/docs/benchmarks))

[**Jump to LiteLLM Proxy (LLM Gateway) Docs**](https://docs.litellm.ai/docs/simple_proxy) &lt;br&gt;
[**Jump to Supported LLM Providers**](https://docs.litellm.ai/docs/providers)

**Stable Release:** Use docker images with the `-stable` tag. These have undergone 12 hour load tests, before being published. [More information about the release cycle here](https://docs.litellm.ai/docs/proxy/release_cycle)

Support for more providers. Missing a provider or LLM Platform, raise a [feature request](https://github.com/BerriAI/litellm/issues/new?assignees=&amp;labels=enhancement&amp;projects=&amp;template=feature_request.yml&amp;title=%5BFeature%5D%3A+).

## OSS Adopters 

&lt;table&gt;
  &lt;tr&gt;
    &lt;td&gt;&lt;img height=&quot;60&quot; alt=&quot;Stripe&quot; src=&quot;https://github.com/user-attachments/assets/f7296d4f-9fbd-460d-9d05-e4df31697c4b&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img height=&quot;60&quot; alt=&quot;Google ADK&quot; src=&quot;https://github.com/user-attachments/assets/caf270a2-5aee-45c4-8222-41a2070c4f19&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img height=&quot;60&quot; alt=&quot;Greptile&quot; src=&quot;https://github.com/user-attachments/assets/0be4bd8a-7cfa-48d3-9090-f415fe948280&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img height=&quot;60&quot; alt=&quot;OpenHands&quot; src=&quot;https://github.com/user-attachments/assets/a6150c4c-149e-4cae-888b-8b92be6e003f&quot; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;h2&gt;Netflix&lt;/h2&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img height=&quot;60&quot; alt=&quot;OpenAI Agents SDK&quot; src=&quot;https://github.com/user-attachments/assets/c02f7be0-8c2e-4d27-aea7-7c024bfaebc0&quot; /&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## Supported Providers ([Website Supported Models](https://models.litellm.ai/) | [Docs](https://docs.litellm.ai/docs/providers))

| Provider                                                                            | `/chat/completions` | `/messages` | `/responses` | `/embeddings` | `/image/generations` | `/audio/transcriptions` | `/audio/speech` | `/moderations` | `/batches` | `/rerank` |
|-------------------------------------------------------------------------------------|---------------------|-------------|--------------|---------------|----------------------|-------------------------|-----------------|----------------|-----------|-----------|
| [Abliteration (`abliteration`)](https://docs.litellm.ai/docs/providers/abliteration) | ‚úÖ |  |  |  |  |  |  |  |  |  |
| [AI/ML API (`aiml`)](https://docs.litellm.ai/docs/providers/aiml) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |
| [AI21 (`ai21`)](https://docs.litellm.ai/docs/providers/ai21) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [AI21 Chat (`ai21_chat`)](https://docs.litellm.ai/docs/providers/ai21) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Aleph Alpha](https://docs.litellm.ai/docs/providers/aleph_alpha) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Amazon Nova](https://docs.litellm.ai/docs/providers/amazon_nova) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Anthropic (`anthropic`)](https://docs.litellm.ai/docs/providers/anthropic) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  | ‚úÖ |  |
| [Anthropic Text (`anthropic_text`)](https://docs.litellm.ai/docs/providers/anthropic) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  | ‚úÖ |  |
| [Anyscale](https://docs.litellm.ai/docs/providers/anyscale) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [AssemblyAI (`assemblyai`)](https://docs.litellm.ai/docs/pass_through/assembly_ai) | ‚úÖ | ‚úÖ | ‚úÖ |  |  | ‚úÖ |  |  |  |  |
| [Auto Router (`auto_router`)](https://docs.litellm.ai/docs/proxy/auto_routing) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [AWS - Bedrock (`bedrock`)](https://docs.litellm.ai/docs/providers/bedrock) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  | ‚úÖ |
| [AWS - Sagemaker (`sagemaker`)](https://docs.litellm.ai/docs/providers/aws_sagemaker) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |
| [Azure (`azure`)](https://docs.litellm.ai/docs/providers/azure) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |
| [Azure AI (`azure_ai`)](https://docs.litellm.ai/docs/providers/azure_ai) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |
| [Azure Text (`azure_text`)](https://docs.litellm.ai/docs/providers/azure) | ‚úÖ | ‚úÖ | ‚úÖ |  |  | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |
| [Baseten (`baseten`)](https://docs.litellm.ai/docs/providers/baseten) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Bytez (`bytez`)](https://docs.litellm.ai/docs/providers/bytez) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Cerebras (`cerebras`)](https://docs.litellm.ai/docs/providers/cerebras) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Clarifai (`clarifai`)](https://docs.litellm.ai/docs/providers/clarifai) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Cloudflare AI Workers (`cloudflare`)](https://docs.litellm.ai/docs/providers/cloudflare_workers) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Codestral (`codestral`)](https://docs.litellm.ai/docs/providers/codestral) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Cohere (`cohere`)](https://docs.litellm.ai/docs/providers/cohere) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  | ‚úÖ |
| [Cohere Chat (`cohere_chat`)](https://docs.litellm.ai/docs/providers/cohere) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [CometAPI (`cometapi`)](https://docs.litellm.ai/docs/providers/cometapi) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |
| [CompactifAI (`compactifai`)](https://docs.litellm.ai/docs/providers/compactifai) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Custom (`custom`)](https://docs.litellm.ai/docs/providers/custom_llm_server) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Custom OpenAI (`custom_openai`)](https://docs.litellm.ai/docs/providers/openai_compatible) | ‚úÖ | ‚úÖ | ‚úÖ |  |  | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |
| [Dashscope (`dashscope`)](https://docs.litellm.ai/docs/providers/dashscope) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Databricks (`databricks`)](https://docs.litellm.ai/docs/providers/databricks) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [DataRobot (`datarobot`)](https://docs.litellm.ai/docs/providers/datarobot) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Deepgram (`deepgram`)](https://docs.litellm.ai/docs/providers/deepgram) | ‚úÖ | ‚úÖ | ‚úÖ |  |  | ‚úÖ |  |  |  |  |
| [DeepInfra (`deepinfra`)](https://docs.litellm.ai/docs/providers/deepinfra) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Deepseek (`deepseek`)](https://docs.litellm.ai/docs/providers/deepseek) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [ElevenLabs (`elevenlabs`)](https://docs.litellm.ai/docs/providers/elevenlabs) | ‚úÖ | ‚úÖ | ‚úÖ |  |  | ‚úÖ | ‚úÖ |  |  |  |
| [Empower (`empower`)](https://docs.litellm.ai/docs/providers/empower) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Fal AI (`fal_ai`)](https://docs.litellm.ai/docs/providers/fal_ai) | ‚úÖ | ‚úÖ | ‚úÖ |  | ‚úÖ |  |  |  |  |  |
| [Featherless AI (`featherless_ai`)](https://docs.litellm.ai/docs/providers/featherless_ai) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Fireworks AI (`fireworks_ai`)](https://docs.litellm.ai/docs/providers/fireworks_ai) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [FriendliAI (`friendliai`)](https://docs.litellm.ai/docs/providers/friendliai) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Galadriel (`galadriel`)](https://docs.litellm.ai/docs/providers/galadriel) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [GitHub Copilot (`github_copilot`)](https://docs.litellm.ai/docs/providers/github_copilot) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |
| [GitHub Models (`github`)](https://docs.litellm.ai/docs/providers/github) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Google - PaLM](https://docs.litellm.ai/docs/providers/palm) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Google - Vertex AI (`vertex_ai`)](https://docs.litellm.ai/docs/providers/vertex) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |
| [Google AI Studio - Gemini (`gemini`)](https://docs.litellm.ai/docs/providers/gemini) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [GradientAI (`gradient_ai`)](https://docs.litellm.ai/docs/providers/gradient_ai) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Groq AI (`groq`)](https://docs.litellm.ai/docs/providers/groq) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Heroku (`heroku`)](https://docs.litellm.ai/docs/providers/heroku) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Hosted VLLM (`hosted_vllm`)](https://docs.litellm.ai/docs/providers/vllm) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Huggingface (`huggingface`)](https://docs.litellm.ai/docs/providers/huggingface) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  | ‚úÖ |
| [Hyperbolic (`hyperbolic`)](https://docs.litellm.ai/docs/providers/hyperbolic) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [IBM - Watsonx.ai (`watsonx`)](https://docs.litellm.ai/docs/providers/watsonx) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |
| [Infinity (`infinity`)](https://docs.litellm.ai/docs/providers/infinity) |  |  |  | ‚úÖ |  |  |  |  |  |  |
| [Jina AI (`jina_ai`)](https://docs.litellm.ai/docs/providers/jina_ai) |  |  |  | ‚úÖ |  |  |  |  |  |  |
| [Lambda AI (`lambda_ai`)](https://docs.litellm.ai/docs/providers/lambda_ai) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Lemonade (`lemonade`)](https://docs.litellm.ai/docs/providers/lemonade) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [LiteLLM Proxy (`litellm_proxy`)](https://docs.litellm.ai/docs/providers/litellm_proxy) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |
| [Llamafile (`llamafile`)](https://docs.litellm.ai/docs/providers/llamafile) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [LM Studio (`lm_studio`)](https://docs.litellm.ai/docs/providers/lm_studio) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Maritalk (`maritalk`)](https://docs.litellm.ai/docs/providers/maritalk) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Meta - Llama API (`meta_llama`)](https://docs.litellm.ai/docs/providers/meta_llama) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Mistral AI API (`mistral`)](https://docs.litellm.ai/docs/providers/mistral) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |
| [Moonshot (`moonshot`)](https://docs.litellm.ai/docs/providers/moonshot) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Morph (`morph`)](https://docs.litellm.ai/docs/providers/morph) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Nebius AI Studio (`nebius`)](https://docs.litellm.ai/docs/providers/nebius) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |
| [NLP Cloud (`nlp_cloud`)](https://docs.litellm.ai/docs/providers/nlp_cloud) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Novita AI (`novita`)](https://novita.ai/models/llm?utm_source=github_litellm&amp;utm_medium=github_readme&amp;utm_campaign=github_link) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Nscale (`nscale`)](https://docs.litellm.ai/docs/providers/nscale) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Nvidia NIM (`nvidia_nim`)](https://docs.litellm.ai/docs/providers/nvidia_nim) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [OCI (`oci`)](https://docs.litellm.ai/docs/providers/oci) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Ollama (`ollama`)](https://docs.litellm.ai/docs/providers/ollama) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |
| [Ollama Chat (`ollama_chat`)](https://docs.litellm.ai/docs/providers/ollama) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Oobabooga (`oobabooga`)](https://docs.litellm.ai/docs/providers/openai_compatible) | ‚úÖ | ‚úÖ | ‚úÖ |  |  | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |
| [OpenAI (`openai`)](https://docs.litellm.ai/docs/providers/openai) | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ | ‚úÖ |  |
| [OpenAI-like (`openai_like`)](https://docs.litellm.ai/docs/providers/openai_compatible) |  |  |  | ‚úÖ |  |  |  |  |  |  |
| [OpenRouter (`openrouter`)](https://docs.litellm.ai/docs/providers/openrouter) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [OVHCloud AI Endpoints (`ovhcloud`)](https://docs.litellm.ai/docs/providers/ovhcloud) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| [Perplexity AI (`perplexity`)](https://docs.litellm.ai/docs/providers/perplexity) | ‚úÖ | ‚úÖ | ‚úÖ |  |  |  |  |  |  |  |
| 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[yichuan-w/LEANN]]></title>
            <link>https://github.com/yichuan-w/LEANN</link>
            <guid>https://github.com/yichuan-w/LEANN</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:12 GMT</pubDate>
            <description><![CDATA[[MLsys2026]: RAG on Everything with LEANN. Enjoy 97% storage savings while running a fast, accurate, and 100% private RAG application on your personal device.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yichuan-w/LEANN">yichuan-w/LEANN</a></h1>
            <p>[MLsys2026]: RAG on Everything with LEANN. Enjoy 97% storage savings while running a fast, accurate, and 100% private RAG application on your personal device.</p>
            <p>Language: Python</p>
            <p>Stars: 10,091</p>
            <p>Forks: 870</p>
            <p>Stars today: 58 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/logo-text.png&quot; alt=&quot;LEANN Logo&quot; width=&quot;400&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/15049&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/15049&quot; alt=&quot;yichuan-w/LEANN | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Python-3.9%20%7C%203.10%20%7C%203.11%20%7C%203.12%20%7C%203.13-blue.svg&quot; alt=&quot;Python Versions&quot;&gt;
  &lt;img src=&quot;https://github.com/yichuan-w/LEANN/actions/workflows/build-and-publish.yml/badge.svg&quot; alt=&quot;CI Status&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/Platform-Ubuntu%20%26%20Arch%20%26%20WSL%20%7C%20macOS%20(ARM64%2FIntel)-lightgrey&quot; alt=&quot;Platform&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/License-MIT-green.svg&quot; alt=&quot;MIT License&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/MCP-Native%20Integration-blue&quot; alt=&quot;MCP Integration&quot;&gt;
  &lt;a href=&quot;https://join.slack.com/t/leann-e2u9779/shared_invite/zt-3ol2ww9ic-Eg_kB8omwe6xmYVd0epr4Q&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Slack-Join-4A154B?logo=slack&amp;logoColor=white&quot; alt=&quot;Join Slack&quot;&gt;
  &lt;/a&gt;

&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://forms.gle/rDbZf864gMNxhpTq8&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/üì£_Community_Survey-Help_Shape_v0.4-007ec6?style=for-the-badge&amp;logo=google-forms&amp;logoColor=white&quot; alt=&quot;Take Survey&quot;&gt;
  &lt;/a&gt;
  &lt;p&gt;
    We track &lt;b&gt;zero telemetry&lt;/b&gt;. This survey is the ONLY way to tell us if you want &lt;br&gt;
    &lt;b&gt;GPU Acceleration&lt;/b&gt; or &lt;b&gt;More Integrations&lt;/b&gt; next.&lt;br&gt;
    üëâ &lt;a href=&quot;https://forms.gle/rDbZf864gMNxhpTq8&quot;&gt;&lt;b&gt;Click here to cast your vote (2 mins)&lt;/b&gt;&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;üí¨ Join our Slack community!&lt;/h3&gt;
  &lt;p&gt;
    We&#039;d love for you to be part of the LEANN community!&lt;br&gt;
    üëâ &lt;a href=&quot;https://join.slack.com/t/leann-e2u9779/shared_invite/zt-3ol2ww9ic-Eg_kB8omwe6xmYVd0epr4Q&quot;&gt;&lt;b&gt;Join LEANN Slack&lt;/b&gt;&lt;/a&gt;&lt;br&gt;
    If the invite link has expired or you have trouble joining, please &lt;a href=&quot;https://github.com/yichuan-w/LEANN/issues&quot;&gt;open an issue&lt;/a&gt; and we&#039;ll help you get in!
  &lt;/p&gt;
&lt;/div&gt;

&lt;h2 align=&quot;center&quot; tabindex=&quot;-1&quot; class=&quot;heading-element&quot; dir=&quot;auto&quot;&gt;
    The smallest vector index in the world. RAG Everything with LEANN!
&lt;/h2&gt;

LEANN is an innovative vector database that democratizes personal AI. Transform your laptop into a powerful RAG system that can index and search through millions of documents while using **97% less storage** than traditional solutions **without accuracy loss**.


LEANN achieves this through *graph-based selective recomputation* with *high-degree preserving pruning*, computing embeddings on-demand instead of storing them all. [Illustration Fig ‚Üí](#Ô∏è-architecture--how-it-works) | [Paper ‚Üí](https://arxiv.org/abs/2506.08276)

**Ready to RAG Everything?** Transform your laptop into a personal AI assistant that can semantic search your **[file system](#-personal-data-manager-process-any-documents-pdf-txt-md)**, **[emails](#-your-personal-email-secretary-rag-on-apple-mail)**, **[browser history](#-time-machine-for-the-web-rag-your-entire-browser-history)**, **[chat history](#-wechat-detective-unlock-your-golden-memories)** ([WeChat](#-wechat-detective-unlock-your-golden-memories), [iMessage](#-imessage-history-your-personal-conversation-archive)), **[agent memory](#-chatgpt-chat-history-your-personal-ai-conversation-archive)** ([ChatGPT](#-chatgpt-chat-history-your-personal-ai-conversation-archive), [Claude](#-claude-chat-history-your-personal-ai-conversation-archive)), **[live data](#mcp-integration-rag-on-live-data-from-any-platform)** ([Slack](#slack-messages-search-your-team-conversations), [Twitter](#-twitter-bookmarks-your-personal-tweet-library)), **[codebase](#-claude-code-integration-transform-your-development-workflow)**\* , or external knowledge bases (i.e., 60M documents) - all on your laptop, with zero cloud costs and complete privacy.


\* Claude Code only supports basic `grep`-style keyword search. **LEANN** is a drop-in **semantic search MCP service fully compatible with Claude Code**, unlocking intelligent retrieval without changing your workflow. üî• Check out [the easy setup ‚Üí](packages/leann-mcp/README.md)



## Why LEANN?

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/effects.png&quot; alt=&quot;LEANN vs Traditional Vector DB Storage Comparison&quot; width=&quot;70%&quot;&gt;
&lt;/p&gt;

&gt; **The numbers speak for themselves:** Index 60 million text chunks in just 6GB instead of 201GB. From emails to browser history, everything fits on your laptop. [See detailed benchmarks for different applications below ‚Üì](#-storage-comparison)


üîí **Privacy:** Your data never leaves your laptop. No OpenAI, no cloud, no &quot;terms of service&quot;.

ü™∂ **Lightweight:** Graph-based recomputation eliminates heavy embedding storage, while smart graph pruning and CSR format minimize graph storage overhead. Always less storage, less memory usage!

üì¶ **Portable:** Transfer your entire knowledge base between devices (even with others) with minimal cost - your personal AI memory travels with you.

üìà **Scalability:** Handle messy personal data that would crash traditional vector DBs, easily managing your growing personalized data and agent generated memory!

‚ú® **No Accuracy Loss:** Maintain the same search quality as heavyweight solutions while using 97% less storage.

## Installation

### üì¶ Prerequisites: Install uv

[Install uv](https://docs.astral.sh/uv/getting-started/installation/#installation-methods) first if you don&#039;t have it. Typically, you can install it with:

```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
```

### üöÄ Quick Install

Clone the repository to access all examples and try amazing applications,

```bash
git clone https://github.com/yichuan-w/LEANN.git leann
cd leann
```

and install LEANN from [PyPI](https://pypi.org/project/leann/) to run them immediately:

```bash
uv venv
source .venv/bin/activate
uv pip install leann

# CPU-only (Linux): use the `cpu` extra (e.g. `leann[cpu]`)
```

&lt;!--
&gt; Low-resource? See &quot;Low-resource setups&quot; in the [Configuration Guide](docs/configuration-guide.md#low-resource-setups). --&gt;

&lt;details&gt;
&lt;summary&gt;
&lt;strong&gt;üîß Build from Source (Recommended for development)&lt;/strong&gt;
&lt;/summary&gt;



```bash
git clone https://github.com/yichuan-w/LEANN.git leann
cd leann
git submodule update --init --recursive
```

**macOS:**

Note: DiskANN requires MacOS 13.3 or later.

```bash
brew install libomp boost protobuf zeromq pkgconf
uv sync --extra diskann
```

**Linux (Ubuntu/Debian):**

Note: On Ubuntu 20.04, you may need to build a newer Abseil and pin Protobuf (e.g., v3.20.x) for building DiskANN. See [Issue #30](https://github.com/yichuan-w/LEANN/issues/30) for a step-by-step note.

You can manually install [Intel oneAPI MKL](https://www.intel.com/content/www/us/en/developer/tools/oneapi/onemkl.html) instead of `libmkl-full-dev` for DiskANN. You can also use `libopenblas-dev` for building HNSW only, by removing `--extra diskann` in the command below.

```bash
sudo apt-get update &amp;&amp; sudo apt-get install -y \
  libomp-dev libboost-all-dev protobuf-compiler libzmq3-dev \
  pkg-config libabsl-dev libaio-dev libprotobuf-dev \
  libmkl-full-dev

uv sync --extra diskann
```

**Linux (Arch Linux):**

```bash
sudo pacman -Syu &amp;&amp; sudo pacman -S --needed base-devel cmake pkgconf git gcc \
  boost boost-libs protobuf abseil-cpp libaio zeromq

# For MKL in DiskANN
sudo pacman -S --needed base-devel git
git clone https://aur.archlinux.org/paru-bin.git
cd paru-bin &amp;&amp; makepkg -si
paru -S intel-oneapi-mkl intel-oneapi-compiler
source /opt/intel/oneapi/setvars.sh

uv sync --extra diskann
```

**Linux (RHEL / CentOS Stream / Oracle / Rocky / AlmaLinux):**

See [Issue #50](https://github.com/yichuan-w/LEANN/issues/50) for more details.

```bash
sudo dnf groupinstall -y &quot;Development Tools&quot;
sudo dnf install -y libomp-devel boost-devel protobuf-compiler protobuf-devel \
  abseil-cpp-devel libaio-devel zeromq-devel pkgconf-pkg-config

# For MKL in DiskANN
sudo dnf install -y intel-oneapi-mkl intel-oneapi-mkl-devel \
  intel-oneapi-openmp || sudo dnf install -y intel-oneapi-compiler
source /opt/intel/oneapi/setvars.sh

uv sync --extra diskann
```

&lt;/details&gt;


## Quick Start

Our declarative API makes RAG as easy as writing a config file.

Check out [demo.ipynb](demo.ipynb) or [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yichuan-w/LEANN/blob/main/demo.ipynb)

```python
from leann import LeannBuilder, LeannSearcher, LeannChat
from pathlib import Path
INDEX_PATH = str(Path(&quot;./&quot;).resolve() / &quot;demo.leann&quot;)

# Build an index
builder = LeannBuilder(backend_name=&quot;hnsw&quot;)
builder.add_text(&quot;LEANN saves 97% storage compared to traditional vector databases.&quot;)
builder.add_text(&quot;Tung Tung Tung Sahur called‚Äîthey need their banana‚Äëcrocodile hybrid back&quot;)
builder.build_index(INDEX_PATH)

# Search
searcher = LeannSearcher(INDEX_PATH)
results = searcher.search(&quot;fantastical AI-generated creatures&quot;, top_k=1)

# Chat with your data
chat = LeannChat(INDEX_PATH, llm_config={&quot;type&quot;: &quot;hf&quot;, &quot;model&quot;: &quot;Qwen/Qwen3-0.6B&quot;})
response = chat.ask(&quot;How much storage does LEANN save?&quot;, top_k=1)
```

## RAG on Everything!

LEANN supports RAG on various data sources including documents (`.pdf`, `.txt`, `.md`), Apple Mail, Google Search History, WeChat, ChatGPT conversations, Claude conversations, iMessage conversations, and **live data from any platform through MCP (Model Context Protocol) servers** - including Slack, Twitter, and more.



### Generation Model Setup

#### LLM Backend

LEANN supports many LLM providers for text generation (HuggingFace, Ollama, Anthropic, and Any OpenAI compatible API).


&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;üîë OpenAI API Setup (Default)&lt;/strong&gt;&lt;/summary&gt;

Set your OpenAI API key as an environment variable:

```bash
export OPENAI_API_KEY=&quot;your-api-key-here&quot;
```

Make sure to use `--llm openai` flag when using the CLI.
You can also specify the model name with `--llm-model &lt;model-name&gt;` flag.

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;üõ†Ô∏è Supported LLM &amp; Embedding Providers (via OpenAI Compatibility)&lt;/strong&gt;&lt;/summary&gt;

Thanks to the widespread adoption of the OpenAI API format, LEANN is compatible out-of-the-box with a vast array of LLM and embedding providers. Simply set the `OPENAI_BASE_URL` and `OPENAI_API_KEY` environment variables to connect to your preferred service.

```sh
export OPENAI_API_KEY=&quot;xxx&quot;
export OPENAI_BASE_URL=&quot;http://localhost:1234/v1&quot; # base url of the provider
```

To use OpenAI compatible endpoint with the CLI interface:

If you are using it for text generation, make sure to use `--llm openai` flag and specify the model name with `--llm-model &lt;model-name&gt;` flag.

If you are using it for embedding, set the `--embedding-mode openai` flag and specify the model name with `--embedding-model &lt;MODEL&gt;`.

-----


Below is a list of base URLs for common providers to get you started.


### üñ•Ô∏è Local Inference Engines (Recommended for full privacy)

| Provider         | Sample Base URL             |
| ---------------- | --------------------------- |
| **Ollama** | `http://localhost:11434/v1` |
| **LM Studio** | `http://localhost:1234/v1`  |
| **vLLM** | `http://localhost:8000/v1`  |
| **llama.cpp** | `http://localhost:8080/v1`  |
| **SGLang** | `http://localhost:30000/v1` |
| **LiteLLM** | `http://localhost:4000`     |

-----

### ‚òÅÔ∏è Cloud Providers

&gt; **üö® A Note on Privacy:** Before choosing a cloud provider, carefully review their privacy and data retention policies. Depending on their terms, your data may be used for their own purposes, including but not limited to human reviews and model training, which can lead to serious consequences if not handled properly.


| Provider         | Base URL                                                   |
| ---------------- | ---------------------------------------------------------- |
| **OpenAI** | `https://api.openai.com/v1`                                |
| **OpenRouter** | `https://openrouter.ai/api/v1`                             |
| **Gemini** | `https://generativelanguage.googleapis.com/v1beta/openai/` |
| **x.AI (Grok)** | `https://api.x.ai/v1`                                      |
| **Groq AI** | `https://api.groq.com/openai/v1`                           |
| **DeepSeek** | `https://api.deepseek.com/v1`                              |
| **SiliconFlow** | `https://api.siliconflow.cn/v1`                            |
| **Zhipu (BigModel)** | `https://open.bigmodel.cn/api/paas/v4/`                |
| **Mistral AI** | `https://api.mistral.ai/v1`                                |
| **Anthropic** | `https://api.anthropic.com/v1`                             |
| **Jina AI** (Embeddings) | `https://api.jina.ai/v1`                         |

&gt; **üí° Tip: Separate Embedding Provider**
&gt;
&gt; To use a different provider for embeddings (e.g., Jina AI) while using another for LLM, use `--embedding-api-base` and `--embedding-api-key`:
&gt; ```bash
&gt; leann build my-index --docs ./docs \
&gt;   --embedding-mode openai \
&gt;   --embedding-model jina-embeddings-v3 \
&gt;   --embedding-api-base https://api.jina.ai/v1 \
&gt;   --embedding-api-key $JINA_API_KEY
&gt; ```

If your provider isn&#039;t on this list, don&#039;t worry! Check their documentation for an OpenAI-compatible endpoint‚Äîchances are, it&#039;s OpenAI Compatible too!

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;üîß Ollama Setup (Recommended for full privacy)&lt;/strong&gt;&lt;/summary&gt;

**macOS:**

First, [download Ollama for macOS](https://ollama.com/download/mac).

```bash
# Pull a lightweight model (recommended for consumer hardware)
ollama pull llama3.2:1b
```

**Linux:**

```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Start Ollama service manually
ollama serve &amp;

# Pull a lightweight model (recommended for consumer hardware)
ollama pull llama3.2:1b
```

&lt;/details&gt;


## ‚≠ê Flexible Configuration

LEANN provides flexible parameters for embedding models, search strategies, and data processing to fit your specific needs.

üìö **Need configuration best practices?** Check our [Configuration Guide](docs/configuration-guide.md) for detailed optimization tips, model selection advice, and solutions to common issues like slow embeddings or poor search quality.

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;üìã Click to expand: Common Parameters (Available in All Examples)&lt;/strong&gt;&lt;/summary&gt;

All RAG examples share these common parameters. **Interactive mode** is available in all examples - simply run without `--query` to start a continuous Q&amp;A session where you can ask multiple questions. Type &#039;quit&#039; to exit.

```bash
# Environment Variables (GPU Device Selection)
LEANN_EMBEDDING_DEVICE       # GPU for embedding model (e.g., cuda:0, cuda:1, cpu)
LEANN_LLM_DEVICE             # GPU for HFChat LLM (e.g., cuda:1, or &quot;cuda&quot; for multi-GPU auto)

# Core Parameters (General preprocessing for all examples)
--index-dir DIR              # Directory to store the index (default: current directory)
--query &quot;YOUR QUESTION&quot;      # Single query mode. Omit for interactive chat (type &#039;quit&#039; to exit), and now you can play with your index interactively
--max-items N                # Limit data preprocessing (default: -1, process all data)
--force-rebuild              # Force rebuild index even if it exists

# Embedding Parameters
--embedding-model MODEL      # e.g., facebook/contriever, text-embedding-3-small, mlx-community/Qwen3-Embedding-0.6B-8bit or nomic-embed-text
--embedding-mode MODE        # sentence-transformers, openai, mlx, or ollama

# LLM Parameters (Text generation models)
--llm TYPE                   # LLM backend: openai, ollama, hf, or anthropic (default: openai)
--llm-model MODEL            # Model name (default: gpt-4o) e.g., gpt-4o-mini, llama3.2:1b, Qwen/Qwen2.5-1.5B-Instruct
--thinking-budget LEVEL      # Thinking budget for reasoning models: low/medium/high (supported by o3, o3-mini, GPT-Oss:20b, and other reasoning models)

# Search Parameters
--top-k N                    # Number of results to retrieve (default: 20)
--search-complexity N        # Search complexity for graph traversal (default: 32)

# Chunking Parameters
--chunk-size N               # Size of text chunks (default varies by source: 256 for most, 192 for WeChat)
--chunk-overlap N            # Overlap between chunks (default varies: 25-128 depending on source)

# Index Building Parameters
--backend-name NAME          # Backend to use: hnsw or diskann (default: hnsw)
--graph-degree N             # Graph degree for index construction (default: 32)
--build-complexity N         # Build complexity for index construction (default: 64)
--compact / --no-compact     # Use compact storage (default: true). Must be `no-compact` for `no-recompute` build.
--recompute / --no-recompute # Enable/disable embedding recomputation (default: enabled). Should not do a `no-recompute` search in a `recompute` build.
```

&lt;/details&gt;

### üìÑ Personal Data Manager: Process Any Documents (`.pdf`, `.txt`, `.md`)!

Ask questions directly about your personal PDFs, documents, and any directory containing your files!

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;videos/paper_clear.gif&quot; alt=&quot;LEANN Document Search Demo&quot; width=&quot;600&quot;&gt;
&lt;/p&gt;

The example below asks a question about summarizing our paper (uses default data in `data/`, which is a directory with diverse data sources: two papers, Pride and Prejudice, and a Technical report about LLM in Huawei in Chinese), and this is the **easiest example** to run here:

```bash
source .venv/bin/activate # Don&#039;t forget to activate the virtual environment
python -m apps.document_rag --query &quot;What are the main techniques LEANN explores?&quot;
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;üìã Click to expand: Document-Specific Arguments&lt;/strong&gt;&lt;/summary&gt;

#### Parameters
```bash
--data-dir DIR           # Directory containing documents to process (default: data)
--file-types .ext .ext   # Filter by specific file types (optional - all LlamaIndex supported types if omitted)
```

#### Example Commands
```bash
# Process all documents with larger chunks for academic papers
python -m apps.document_rag --data-dir &quot;~/Documents/Papers&quot; --chunk-size 1024

# Filter only markdown and Python files with smaller chunks
python -m apps.document_rag --data-dir &quot;./docs&quot; --chunk-size 256 --file-types .md .py

# Enable AST-aware chunking for code files
python -m apps.document_rag --enable-code-chunking --data-dir &quot;./my_project&quot;

# Or use the specialized code RAG for better code understanding
python -m apps.code_rag --repo-dir &quot;./my_codebase&quot; --query &quot;How does authentication work?&quot;
```

&lt;/details&gt;

### üé® ColQwen: Multimodal PDF Retrieval with Vision-Language Models

Search through PDFs using both text and visual understanding with ColQwen2/ColPali models. Perfect for research papers, technical documents, and any PDFs with complex layouts, figures, or diagrams.

&gt; **üçé Mac Users**: ColQwen is optimized for Apple Silicon with MPS acceleration for faster inference!

```bash
# Build index from PDFs
python -m apps.colqwen_rag build --pdfs ./my_papers/ --index research_papers

# Search with text queries
python -m apps.colqwen_rag search research_papers &quot;How does attention mechanism work?&quot;

# Interactive Q&amp;A
python -m apps.colqwen_rag ask research_papers --interactive
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;üìã Click to expand: ColQwen Setup &amp; Usage&lt;/strong&gt;&lt;/summary&gt;

#### Prerequisites
```bash
# Install dependencies
uv pip install colpali_engine pdf2image pillow matplotlib qwen_vl_utils einops seaborn
brew install poppler  # macOS only, for PDF processing
```

#### Build Index
```bash
python -m apps.colqwen_rag build \
  --pdfs ./pdf_directory/ \
  --index my_index \
  --model colqwen2  # or colpali
```

#### Search
```bash
python -m apps.colqwen_rag search my_index &quot;your question here&quot; --top-k 5
```

#### Models
- **ColQwen2** (`colqwen2`): Latest vision-language model with improved performance
- **ColPali** (`colpali`): Proven multimodal retriever

For detailed usage, see the [ColQwen Guide](docs/COLQWEN_

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sansan0/TrendRadar]]></title>
            <link>https://github.com/sansan0/TrendRadar</link>
            <guid>https://github.com/sansan0/TrendRadar</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:11 GMT</pubDate>
            <description><![CDATA[‚≠êAI-driven public opinion & trend monitor with multi-platform aggregation, RSS, and smart alerts.üéØ ÂëäÂà´‰ø°ÊÅØËøáËΩΩÔºå‰Ω†ÁöÑ AI ËàÜÊÉÖÁõëÊéßÂä©Êâã‰∏éÁÉ≠ÁÇπÁ≠õÈÄâÂ∑•ÂÖ∑ÔºÅËÅöÂêàÂ§öÂπ≥Âè∞ÁÉ≠ÁÇπ + RSS ËÆ¢ÈòÖÔºåÊîØÊåÅÂÖ≥ÈîÆËØçÁ≤æÂáÜÁ≠õÈÄâ„ÄÇAI ÁøªËØë + AI ÂàÜÊûêÁÆÄÊä•Áõ¥Êé®ÊâãÊú∫Ôºå‰πüÊîØÊåÅÊé•ÂÖ• MCP Êû∂ÊûÑÔºåËµãËÉΩ AI Ëá™ÁÑ∂ËØ≠Ë®ÄÂØπËØùÂàÜÊûê„ÄÅÊÉÖÊÑüÊ¥ûÂØü‰∏éË∂ãÂäøÈ¢ÑÊµãÁ≠â„ÄÇÊîØÊåÅ Docker ÔºåÊï∞ÊçÆÊú¨Âú∞/‰∫ëÁ´ØËá™ÊåÅ„ÄÇÈõÜÊàêÂæÆ‰ø°/È£û‰π¶/ÈíâÈíâ/Telegram/ÈÇÆ‰ª∂/ntfy/bark/slack Á≠âÊ∏†ÈÅìÊô∫ËÉΩÊé®ÈÄÅ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sansan0/TrendRadar">sansan0/TrendRadar</a></h1>
            <p>‚≠êAI-driven public opinion & trend monitor with multi-platform aggregation, RSS, and smart alerts.üéØ ÂëäÂà´‰ø°ÊÅØËøáËΩΩÔºå‰Ω†ÁöÑ AI ËàÜÊÉÖÁõëÊéßÂä©Êâã‰∏éÁÉ≠ÁÇπÁ≠õÈÄâÂ∑•ÂÖ∑ÔºÅËÅöÂêàÂ§öÂπ≥Âè∞ÁÉ≠ÁÇπ + RSS ËÆ¢ÈòÖÔºåÊîØÊåÅÂÖ≥ÈîÆËØçÁ≤æÂáÜÁ≠õÈÄâ„ÄÇAI ÁøªËØë + AI ÂàÜÊûêÁÆÄÊä•Áõ¥Êé®ÊâãÊú∫Ôºå‰πüÊîØÊåÅÊé•ÂÖ• MCP Êû∂ÊûÑÔºåËµãËÉΩ AI Ëá™ÁÑ∂ËØ≠Ë®ÄÂØπËØùÂàÜÊûê„ÄÅÊÉÖÊÑüÊ¥ûÂØü‰∏éË∂ãÂäøÈ¢ÑÊµãÁ≠â„ÄÇÊîØÊåÅ Docker ÔºåÊï∞ÊçÆÊú¨Âú∞/‰∫ëÁ´ØËá™ÊåÅ„ÄÇÈõÜÊàêÂæÆ‰ø°/È£û‰π¶/ÈíâÈíâ/Telegram/ÈÇÆ‰ª∂/ntfy/bark/slack Á≠âÊ∏†ÈÅìÊô∫ËÉΩÊé®ÈÄÅ„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 47,255</p>
            <p>Forks: 22,372</p>
            <p>Stars today: 145 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; id=&quot;trendradar&quot;&gt;

&lt;a href=&quot;https://github.com/sansan0/TrendRadar&quot; title=&quot;TrendRadar&quot;&gt;
  &lt;img src=&quot;/_image/banner.webp&quot; alt=&quot;TrendRadar Banner&quot; width=&quot;80%&quot;&gt;
&lt;/a&gt;

ÊúÄÂø´&lt;strong&gt;30Áßí&lt;/strong&gt;ÈÉ®ÁΩ≤ÁöÑÁÉ≠ÁÇπÂä©Êâã ‚Äî‚Äî ÂëäÂà´Êó†ÊïàÂà∑Â±èÔºåÂè™ÁúãÁúüÊ≠£ÂÖ≥ÂøÉÁöÑÊñ∞ÈóªËµÑËÆØ

&lt;a href=&quot;https://trendshift.io/repositories/14726&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14726&quot; alt=&quot;sansan0%2FTrendRadar | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;


[![GitHub Stars](https://img.shields.io/github/stars/sansan0/TrendRadar?style=flat-square&amp;logo=github&amp;color=yellow)](https://github.com/sansan0/TrendRadar/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/sansan0/TrendRadar?style=flat-square&amp;logo=github&amp;color=blue)](https://github.com/sansan0/TrendRadar/network/members)
[![License](https://img.shields.io/badge/license-GPL--3.0-blue.svg?style=flat-square)](LICENSE)
[![Version](https://img.shields.io/badge/version-v6.0.0-blue.svg)](https://github.com/sansan0/TrendRadar)
[![MCP](https://img.shields.io/badge/MCP-v4.0.0-green.svg)](https://github.com/sansan0/TrendRadar)
[![RSS](https://img.shields.io/badge/RSS-ËÆ¢ÈòÖÊ∫êÊîØÊåÅ-orange.svg?style=flat-square&amp;logo=rss&amp;logoColor=white)](https://github.com/sansan0/TrendRadar)
[![AIÁøªËØë](https://img.shields.io/badge/AI-Â§öËØ≠Ë®ÄÊé®ÈÄÅ-purple.svg?style=flat-square)](https://github.com/sansan0/TrendRadar)

[![‰ºÅ‰∏öÂæÆ‰ø°ÈÄöÁü•](https://img.shields.io/badge/‰ºÅ‰∏öÂæÆ‰ø°-ÈÄöÁü•-00D4AA?style=flat-square)](https://work.weixin.qq.com/)
[![‰∏™‰∫∫ÂæÆ‰ø°ÈÄöÁü•](https://img.shields.io/badge/‰∏™‰∫∫ÂæÆ‰ø°-ÈÄöÁü•-00D4AA?style=flat-square)](https://weixin.qq.com/)
[![TelegramÈÄöÁü•](https://img.shields.io/badge/Telegram-ÈÄöÁü•-00D4AA?style=flat-square)](https://telegram.org/)
[![dingtalkÈÄöÁü•](https://img.shields.io/badge/ÈíâÈíâ-ÈÄöÁü•-00D4AA?style=flat-square)](#)
[![È£û‰π¶ÈÄöÁü•](https://img.shields.io/badge/È£û‰π¶-ÈÄöÁü•-00D4AA?style=flat-square)](https://www.feishu.cn/)
[![ÈÇÆ‰ª∂ÈÄöÁü•](https://img.shields.io/badge/Email-ÈÄöÁü•-00D4AA?style=flat-square)](#)
[![ntfyÈÄöÁü•](https://img.shields.io/badge/ntfy-ÈÄöÁü•-00D4AA?style=flat-square)](https://github.com/binwiederhier/ntfy)
[![BarkÈÄöÁü•](https://img.shields.io/badge/Bark-ÈÄöÁü•-00D4AA?style=flat-square)](https://github.com/Finb/Bark)
[![SlackÈÄöÁü•](https://img.shields.io/badge/Slack-ÈÄöÁü•-00D4AA?style=flat-square)](https://slack.com/)
[![ÈÄöÁî®Webhook](https://img.shields.io/badge/ÈÄöÁî®-Webhook-607D8B?style=flat-square&amp;logo=webhook&amp;logoColor=white)](#)


[![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-Ëá™Âä®Âåñ-2088FF?style=flat-square&amp;logo=github-actions&amp;logoColor=white)](https://github.com/sansan0/TrendRadar)
[![GitHub Pages](https://img.shields.io/badge/GitHub_Pages-ÈÉ®ÁΩ≤-4285F4?style=flat-square&amp;logo=github&amp;logoColor=white)](https://sansan0.github.io/TrendRadar)
[![Docker](https://img.shields.io/badge/Docker-ÈÉ®ÁΩ≤-2496ED?style=flat-square&amp;logo=docker&amp;logoColor=white)](https://hub.docker.com/r/wantcat/trendradar)
[![MCP Support](https://img.shields.io/badge/MCP-AIÂàÜÊûêÊîØÊåÅ-FF6B6B?style=flat-square&amp;logo=ai&amp;logoColor=white)](https://modelcontextprotocol.io/)
[![AIÂàÜÊûêÊé®ÈÄÅ](https://img.shields.io/badge/AI-ÂàÜÊûêÊé®ÈÄÅ-FF6B6B?style=flat-square&amp;logo=openai&amp;logoColor=white)](#)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

**‰∏≠Êñá** | **[English](README-EN.md)**

&lt;/div&gt;

&gt; Êú¨È°πÁõÆ‰ª•ËΩªÈáèÔºåÊòìÈÉ®ÁΩ≤‰∏∫ÁõÆÊ†á

&lt;br&gt;

## üìë Âø´ÈÄüÂØºËà™

&gt; üí° **ÁÇπÂáª‰∏ãÊñπÈìæÊé•**ÂèØÂø´ÈÄüË∑≥ËΩ¨Âà∞ÂØπÂ∫îÁ´†ËäÇ„ÄÇÈÉ®ÁΩ≤Êé®Ëçê‰ªé„Äå**Âø´ÈÄüÂºÄÂßã**„ÄçÂÖ•ÊâãÔºåÈúÄË¶ÅËØ¶ÁªÜËá™ÂÆö‰πâËØ∑Áúã„Äå**ÈÖçÁΩÆËØ¶Ëß£**„Äç

&lt;div align=&quot;center&quot;&gt;

|   |   |   |
|:---:|:---:|:---:|
| [üöÄ **Âø´ÈÄüÂºÄÂßã**](#-Âø´ÈÄüÂºÄÂßã) | [AI Êô∫ËÉΩÂàÜÊûê](#-ai-Êô∫ËÉΩÂàÜÊûê) | [‚öôÔ∏è **ÈÖçÁΩÆËØ¶Ëß£**](#ÈÖçÁΩÆËØ¶Ëß£) |
| [DockerÈÉ®ÁΩ≤](#6-docker-ÈÉ®ÁΩ≤) | [MCPÂÆ¢Êà∑Á´Ø](#-mcp-ÂÆ¢Êà∑Á´Ø) | [üìù **Êõ¥Êñ∞Êó•Âøó**](#-Êõ¥Êñ∞Êó•Âøó) |
| [üéØ **Ê†∏ÂøÉÂäüËÉΩ**](#-Ê†∏ÂøÉÂäüËÉΩ) | [‚òï **ÊîØÊåÅÈ°πÁõÆ**](#-ÊîØÊåÅÈ°πÁõÆ) | [üìö **È°πÁõÆÁõ∏ÂÖ≥**](#-È°πÁõÆÁõ∏ÂÖ≥) |

&lt;/div&gt;

&lt;br&gt;

- ÊÑüË∞¢**‰∏∫È°πÁõÆÁÇπ star** ÁöÑËßÇ‰ºó‰ª¨Ôºå**fork** ‰Ω†ÊâÄÊ¨≤‰πüÔºå**star** ÊàëÊâÄÊ¨≤‰πüÔºå‰∏§ËÄÖÂæóÂÖºüòçÊòØÂØπÂºÄÊ∫êÁ≤æÁ•ûÊúÄÂ•ΩÁöÑÊîØÊåÅ

&lt;details&gt;
&lt;summary&gt;üëâ ÁÇπÂáªÂ±ïÂºÄÔºö&lt;strong&gt;Ëá¥Ë∞¢ÂêçÂçï&lt;/strong&gt; (Â§©‰ΩøËΩÆËç£Ë™âÊ¶ú üî•73+üî• ‰Ωç)&lt;/summary&gt;

### Êó©ÊúüÊîØÊåÅËÄÖËá¥Ë∞¢

&gt; üí° **ÁâπÂà´ËØ¥Êòé**Ôºö
&gt;
&gt; 1. **ÂÖ≥‰∫éÂêçÂçï**Ôºö‰∏ãÊñπË°®Ê†ºËÆ∞ÂΩï‰∫ÜÈ°πÁõÆËµ∑Ê≠•Èò∂ÊÆµÔºàÂ§©‰ΩøËΩÆÔºâÁöÑÊîØÊåÅËÄÖ„ÄÇÂõ†Êó©Êúü‰∫∫Â∑•ÁªüËÆ°ÁπÅÁêêÔºå**ÈöæÂÖçÂ≠òÂú®ÁñèÊºèÊàñËÆ∞ÂΩï‰∏çÂÖ®ÁöÑÊÉÖÂÜµÔºåÂ¶ÇÊúâÈÅóÊºèÔºåÂÆûÈùûÊú¨ÊÑèÔºå‰∏áÊúõÊµ∑Ê∂µ**„ÄÇ
&gt; 2. **Êú™Êù•ËßÑÂàí**Ôºö‰∏∫‰∫ÜÂ∞ÜÊúâÈôêÁöÑÁ≤æÂäõÂõûÂΩí‰ª£Á†Å‰∏éÂäüËÉΩËø≠‰ª£Ôºå**Âç≥Êó•Ëµ∑‰∏çÂÜç‰∫∫Â∑•Áª¥Êä§Ê≠§ÂêçÂçï**„ÄÇ
&gt;
&gt; Êó†ËÆ∫ÂêçÂ≠óÊòØÂê¶‰∏äÊ¶úÔºå‰Ω†‰ª¨ÁöÑÊØè‰∏Ä‰ªΩÊîØÊåÅÈÉΩÊòØ TrendRadar ËÉΩÂ§üËµ∞Âà∞‰ªäÂ§©ÁöÑÂü∫Áü≥„ÄÇüôè

### Âü∫Á°ÄËÆæÊñΩÊîØÊåÅ

ÊÑüË∞¢ **GitHub** ÂÖçË¥πÊèê‰æõÁöÑÂü∫Á°ÄËÆæÊñΩÔºåËøôÊòØÊú¨È°πÁõÆÂæó‰ª•**‰∏ÄÈîÆ fork**‰æøÊç∑ËøêË°åÁöÑÊúÄÂ§ßÂâçÊèê„ÄÇ

### Êï∞ÊçÆÊîØÊåÅ

Êú¨È°πÁõÆ‰ΩøÁî® [newsnow](https://github.com/ourongxing/newsnow) È°πÁõÆÁöÑ API Ëé∑ÂèñÂ§öÂπ≥Âè∞Êï∞ÊçÆÔºåÁâπÂà´ÊÑüË∞¢‰ΩúËÄÖÊèê‰æõÁöÑÊúçÂä°„ÄÇ

ÁªèËÅîÁ≥ªÔºå‰ΩúËÄÖË°®Á§∫Êó†ÈúÄÊãÖÂøÉÊúçÂä°Âô®ÂéãÂäõÔºå‰ΩÜËøôÊòØÂü∫‰∫é‰ªñÁöÑÂñÑÊÑèÂíå‰ø°‰ªª„ÄÇËØ∑Â§ßÂÆ∂Ôºö
- **ÂâçÂæÄ [newsnow È°πÁõÆ](https://github.com/ourongxing/newsnow) ÁÇπ star ÊîØÊåÅ**
- Docker ÈÉ®ÁΩ≤Êó∂ÔºåËØ∑ÂêàÁêÜÊéßÂà∂Êé®ÈÄÅÈ¢ëÁéáÔºåÂãøÁ´≠Ê≥ΩËÄåÊ∏î

### Êé®ÂπøÂä©Âäõ

&gt; ÊÑüË∞¢‰ª•‰∏ãÂπ≥Âè∞Âíå‰∏™‰∫∫ÁöÑÊé®Ëçê(ÊåâÊó∂Èó¥ÊéíÂàó)

- [Â∞è‰ºóËΩØ‰ª∂](https://mp.weixin.qq.com/s/fvutkJ_NPUelSW9OGK39aA) - ÂºÄÊ∫êËΩØ‰ª∂Êé®ËçêÂπ≥Âè∞
- [LinuxDo Á§æÂå∫](https://linux.do/) - ÊäÄÊúØÁà±Â•ΩËÄÖÁöÑËÅöÈõÜÂú∞
- [ÈòÆ‰∏ÄÂ≥∞Âë®Âàä](https://github.com/ruanyf/weekly) - ÊäÄÊúØÂúàÊúâÂΩ±ÂìçÂäõÁöÑÂë®Âàä

### ËßÇ‰ºóÊîØÊåÅ

&gt; ÊÑüË∞¢**Áªô‰∫àËµÑÈáëÊîØÊåÅ**ÁöÑÊúãÂèã‰ª¨Ôºå‰Ω†‰ª¨ÁöÑÊÖ∑ÊÖ®Â∑≤ÂåñË∫´‰∏∫ÈîÆÁõòÊóÅÁöÑÈõ∂È£üÈ•ÆÊñôÔºåÈô™‰º¥ÁùÄÈ°πÁõÆÁöÑÊØè‰∏ÄÊ¨°Ëø≠‰ª£„ÄÇ
&gt;
&gt; **ÂÖ≥‰∫é&quot;‰∏ÄÂÖÉÁÇπËµû&quot;ÁöÑÂõûÂΩí**Ôºö
&gt; ÈöèÁùÄ v5.0.0 ÁâàÊú¨ÁöÑÂèëÂ∏ÉÔºåÈ°πÁõÆËøàÂÖ•‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÈò∂ÊÆµ„ÄÇ‰∏∫‰∫ÜÊîØÊåÅÊó•ÁõäÂ¢ûÈïøÁöÑ API ÊàêÊú¨ÂíåÂíñÂï°Âõ†Ê∂àËÄóÔºå&quot;‰∏ÄÂÖÉÁÇπËµû&quot;ÈÄöÈÅìÁé∞Â∑≤ÈáçÊñ∞ÂºÄÂêØ„ÄÇ‰Ω†ÁöÑÊØè‰∏Ä‰ªΩÂøÉÊÑèÔºåÈÉΩÂ∞ÜËΩ¨Âåñ‰∏∫‰ª£Á†Å‰∏ñÁïåÈáåÁöÑ Token ÂíåÂä®Âäõ„ÄÇüöÄ [ÂâçÂæÄÊîØÊåÅ](#-ÊîØÊåÅÈ°πÁõÆ)

|           ÁÇπËµû‰∫∫            |  ÈáëÈ¢ù  |  Êó•Êúü  |             Â§áÊ≥®             |
| :-------------------------: | :----: | :----: | :-----------------------: |
|           D*5          |  1.8 * 3 | 2025.11.24  |    | 
|           *È¨º          |  1 | 2025.11.17  |    | 
|           *Ë∂Ö          |  10 | 2025.11.17  |    | 
|           R*w          |  10 | 2025.11.17  | Ëøô agent ÂÅöÁöÑÁâõÈÄºÂïä,ÂÖÑÂºü    | 
|           J*o          |  1 | 2025.11.17  | ÊÑüË∞¢ÂºÄÊ∫ê,Á•ùÂ§ß‰Ω¨‰∫ã‰∏öÊúâÊàê    | 
|           *Êô®          |  8.88  | 2025.11.16  | È°πÁõÆ‰∏çÈîô,Á†îÁ©∂Â≠¶‰π†‰∏≠    | 
|           *Êµ∑          |  1  | 2025.11.15  |    | 
|           *Âæ∑          |  1.99  | 2025.11.15  |    | 
|           *Áñè          |  8.8  | 2025.11.14  |  ÊÑüË∞¢ÂºÄÊ∫êÔºåÈ°πÁõÆÂæàÊ£íÔºåÊîØÊåÅ‰∏Ä‰∏ã   | 
|           M*e          |  10  | 2025.11.14  |  ÂºÄÊ∫ê‰∏çÊòìÔºåÂ§ß‰Ω¨ËæõËã¶‰∫Ü   | 
|           **ÊüØ          |  1  | 2025.11.14  |     | 
|           *‰∫ë          |  88  | 2025.11.13  |    Â•ΩÈ°πÁõÆÔºåÊÑüË∞¢ÂºÄÊ∫ê  | 
|           *W          |  6  | 2025.11.13  |      | 
|           *ÂáØ          |  1  | 2025.11.13  |      | 
|           ÂØπ*.          |  1  | 2025.11.13  |    Thanks for your TrendRadar  | 
|           s*y          |  1  | 2025.11.13  |      | 
|           **Áøî          |  10  | 2025.11.13  |   Â•ΩÈ°πÁõÆÔºåÁõ∏ËßÅÊÅ®ÊôöÔºåÊÑüË∞¢ÂºÄÊ∫êÔºÅ     | 
|           *Èü¶          |  9.9  | 2025.11.13  |   TrendRadarË∂ÖËµûÔºåËØ∑ËÄÅÂ∏àÂñùÂíñÂï°~     | 
|           h*p          |  5  | 2025.11.12  |   ÊîØÊåÅ‰∏≠ÂõΩÂºÄÊ∫êÂäõÈáèÔºåÂä†Ê≤πÔºÅ     | 
|           c*r          |  6  | 2025.11.12  |        | 
|           a*n          |  5  | 2025.11.12  |        | 
|           „ÄÇ*c          |  1  | 2025.11.12  |    ÊÑüË∞¢ÂºÄÊ∫êÂàÜ‰∫´    | 
|           *ËÆ∞          |  1  | 2025.11.11  |        | 
|           *‰∏ª          |  1  | 2025.11.10  |        | 
|           *‰∫Ü          |  10  | 2025.11.09  |        | 
|           *Êù∞          |  5  | 2025.11.08  |        | 
|           *ÁÇπ          |  8.80  | 2025.11.07  |   ÂºÄÂèë‰∏çÊòìÔºåÊîØÊåÅ‰∏Ä‰∏ã„ÄÇ     | 
|           Q*Q          |  6.66  | 2025.11.07  |   ÊÑüË∞¢ÂºÄÊ∫êÔºÅ     | 
|           C*e          |  1  | 2025.11.05  |        | 
|           Peter Fan          |  20  | 2025.10.29  |        | 
|           M*n          |  1  | 2025.10.27  |      ÊÑüË∞¢ÂºÄÊ∫ê  | 
|           *ËÆ∏          |  8.88  | 2025.10.23  |      ËÄÅÂ∏à Â∞èÁôΩ‰∏ÄÊûöÔºåÊë∏‰∫ÜÂá†Â§©‰∫ÜËøòÊ≤°Êï¥Ëµ∑Êù•ÔºåÊ±ÇÊïô  | 
|           Eason           |  1  | 2025.10.22  |      ËøòÊ≤°Êï¥ÊòéÁôΩÔºå‰ΩÜ‰Ω†Âú®ÂÅöÂ•Ω‰∫ã  | 
|           P*n           |  1  | 2025.10.20  |          |
|           *Êù∞           |  1  | 2025.10.19  |          |
|           *Âæê           |  1  | 2025.10.18  |          |
|           *Âøó           |  1  | 2025.10.17  |          |
|           *üòÄ           |  10  | 2025.10.16  |     ÁÇπËµû     |
|           **Êù∞           |  10  | 2025.10.16  |          |
|           *Âï∏           |  10  | 2025.10.16  |          |
|           *Á∫™           |  5  | 2025.10.14  | TrendRadar         |
|           J*d           |  1  | 2025.10.14  | Ë∞¢Ë∞¢‰Ω†ÁöÑÂ∑•ÂÖ∑ÔºåÂæàÂ•ΩÁé©...          |
|           *H           |  1  | 2025.10.14  |           |
|           ÈÇ£*O           |  10  | 2025.10.13  |           |
|           *ÂúÜ           |  1  | 2025.10.13  |           |
|           P*g           |  6  | 2025.10.13  |           |
|           Ocean           |  20  | 2025.10.12  |  ...ÁúüÁöÑÂ§™Ê£í‰∫ÜÔºÅÔºÅÔºÅÂ∞èÁôΩÁ∫ßÂà´‰πüËÉΩÁõ¥Êé•Áî®...         |
|           **Âüπ           |  5.2  | 2025.10.2  |  github-yzyf1312:ÂºÄÊ∫ê‰∏áÂ≤Å         |
|           *Ê§ø           |  3  | 2025.9.23  |  Âä†Ê≤πÔºåÂæà‰∏çÈîô         |
|           *üçç           |  10  | 2025.9.21  |           |
|           E*f           |  1  | 2025.9.20  |           |
|           *ËÆ∞            |  1  | 2025.9.20  |           |
|           z*u            |  2  | 2025.9.19  |           |
|           **Êòä            |  5  | 2025.9.17  |           |
|           *Âè∑            |  1  | 2025.9.15  |           |
|           T*T            |  2  | 2025.9.15  |  ÁÇπËµû         |
|           *ÂÆ∂            |  10  | 2025.9.10  |           |
|           *X            |  1.11  | 2025.9.3  |           |
|           *È£ô            |  20  | 2025.8.31  |  Êù•Ëá™ËÄÅÁ´•Ë∞¢Ë∞¢         |
|           *‰∏ã            |  1  | 2025.8.30  |           |
|           2*D            |  88  | 2025.8.13 ‰∏ãÂçà |           |
|           2*D            |  1  | 2025.8.13 ‰∏äÂçà |           |
|           S*o            |  1  | 2025.8.05 |   ÊîØÊåÅ‰∏Ä‰∏ã        |
|           *‰æ†            |  10  | 2025.8.04 |           |
|           x*x            |  2  | 2025.8.03 |  trendRadar Â•ΩÈ°πÁõÆ ÁÇπËµû          |
|           *Ëøú            |  1  | 2025.8.01 |            |
|           *ÈÇ™            |  5  | 2025.8.01 |            |
|           *Ê¢¶            |  0.1  | 2025.7.30 |            |
|           **Èæô            |  10  | 2025.7.29 |      ÊîØÊåÅ‰∏Ä‰∏ã      |


&lt;/details&gt;

&lt;br&gt;

## ü™Ñ ËµûÂä©ÂïÜ

&lt;div align=&quot;center&quot;&gt;

&gt; **Ëôö‰Ωç‰ª•ÂæÖ**

&lt;/div&gt;

&lt;br&gt;

&lt;a name=&quot;-ÊîØÊåÅÈ°πÁõÆ&quot;&gt;&lt;/a&gt;

### ‚ù§Ô∏è ËßâÂæóÂ•ΩÁî®ÔºüÊîØÊåÅ‰∏Ä‰∏ã

&gt; Ëã• TrendRadar Êõæ‰∏∫‰Ω†ÊçïÊçâ‰ª∑ÂÄºÔºå‰∏çÂ¶®‰∏∫ÂÆÉÊ≥®ÂÖ•Âä®ÂäõÔºåÂä©ÂÖ∂ÊåÅÁª≠ËøõÂåñ
&gt;
&gt; ÈáëÈ¢ùÈöèÊÑèÔºå1 ÂÖÉ‰πüÊòØÂØπÂºÄÊ∫êÁöÑÈºìÂä±„ÄÇÊ¨¢ËøéÂú®ËµûËµèÊó∂Â§áÊ≥®ÁïôË®Ä (¬¥‚ñΩ` É‚ô°∆™)

&lt;div align=&quot;center&quot;&gt;

| ÂæÆ‰ø°ËµûËµè | ÊîØ‰ªòÂÆùËµûËµè |
|:---:|:---:|
| &lt;img src=&quot;https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F2ae0a88d98079f7e876c2b4dc85233c6-9e8025.JPG&quot; width=&quot;240&quot; alt=&quot;ÂæÆ‰ø°ËµûËµè&quot;&gt; | &lt;img src=&quot;https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F1ed4f20ab8e35be51f8e84c94e6e239b4-fe4947.JPG&quot; width=&quot;240&quot; alt=&quot;ÊîØ‰ªòÂÆùËµûËµè&quot;&gt; |

&lt;/div&gt;


### ü§ù ‰∫åÊ¨°ÂºÄÂèë‰∏éÂºïÁî®

Â¶ÇÊûú‰Ω†Âú®È°πÁõÆ‰∏≠‰ΩøÁî®ÊàñÂÄüÈâ¥‰∫ÜÊú¨È°πÁõÆÁöÑÊÄùË∑Ø„ÄÅÊ†∏ÂøÉ‰ª£Á†ÅÔºå**ÈùûÂ∏∏Ê¨¢Ëøé**Âú® README ÊàñÊñáÊ°£‰∏≠Ê≥®ÊòéÊù•Ê∫êÂπ∂ÈôÑ‰∏äÊú¨‰ªìÂ∫ìÈìæÊé•„ÄÇ

ËøôÂ∞ÜÊúâÂä©‰∫éÈ°πÁõÆÁöÑÊåÅÁª≠Áª¥Êä§ÂíåÁ§æÂå∫ÂèëÂ±ïÔºåÊÑüË∞¢‰Ω†ÁöÑÂ∞äÈáç‰∏éÊîØÊåÅÔºÅ‚ù§Ô∏è


### üí¨ ‰∫§ÊµÅ‰∏éÂèçÈ¶à

- **GitHub Issues**ÔºöÈÄÇÂêàÂÖ∑‰ΩìÁöÑÊäÄÊúØÈóÆÈ¢ò„ÄÇÊèêÈóÆÊó∂ËØ∑Êèê‰æõÂÆåÊï¥‰ø°ÊÅØÔºàÊà™Âõæ„ÄÅÈîôËØØÊó•ÂøóÁ≠âÔºâÔºåÊúâÂä©‰∫éÂø´ÈÄüÂÆö‰Ωç„ÄÇ
- **ÂÖ¨‰ºóÂè∑‰∫§ÊµÅ**ÔºöÂª∫ËÆÆ‰ºòÂÖàÂú®Áõ∏ÂÖ≥ÊñáÁ´†‰∏ãÁöÑÁïôË®ÄÂå∫‰∫§ÊµÅ„ÄÇËã•ÈúÄÂêéÂè∞ÊèêÈóÆÔºå**ÂÖàÁÇπËµû/Êé®Ëçê**ÊñáÁ´†ÊòØÊúÄÂ•ΩÁöÑ‚ÄúÊï≤Èó®Á†ñ‚ÄùÔºåÊàëÂú®ÂêéÂè∞ÈÉΩËÉΩÊÑüÂèóÂà∞Ëøô‰ªΩÂøÉÊÑèÂìü (¬¥‚ñΩ` É‚ô°∆™)„ÄÇ

&gt; **ÂèãÊÉÖÊèêÁ§∫**Ôºö        
&gt; Êú¨È°πÁõÆ‰∏∫ÂºÄÊ∫êÂàÜ‰∫´ÔºåÈùûÂïÜ‰∏ö‰∫ßÂìÅ„ÄÇÊää‰ΩúËÄÖÂΩìÊúãÂèãËÄåÈùûÂÆ¢ÊúçÔºåÊ≤üÈÄöÊïàÁéá‰ºöÊõ¥È´òÂì¶ÔºÅ     

&lt;div align=&quot;center&quot;&gt;

|ÂÖ¨‰ºóÂè∑ÂÖ≥Ê≥® |
|:---:|
| &lt;img src=&quot;_image/weixin.png&quot; width=&quot;500&quot; title=&quot;Á°ÖÂü∫Ëå∂Ê∞¥Èó¥&quot;/&gt; |

&lt;/div&gt;

&lt;br&gt;

## üìù Êõ¥Êñ∞Êó•Âøó

&gt; **üìå Êü•ÁúãÊúÄÊñ∞Êõ¥Êñ∞**Ôºö**[Âéü‰ªìÂ∫ìÊõ¥Êñ∞Êó•Âøó](https://github.com/sansan0/TrendRadar?tab=readme-ov-file#-Êõ¥Êñ∞Êó•Âøó)** Ôºö
- **ÊèêÁ§∫**ÔºöÂª∫ËÆÆÊü•Áúã„ÄêÂéÜÂè≤Êõ¥Êñ∞„ÄëÔºåÊòéÁ°ÆÂÖ∑‰ΩìÁöÑ„ÄêÂäüËÉΩÂÜÖÂÆπ„Äë


### 2026/02/09 - v6.0.0

&gt; **Breaking Change**ÔºöÈÖçÁΩÆÊñá‰ª∂ÂçáÁ∫ßÔºàconfig.yaml 2.0.0ÔºâÔºåÊóßÁâà `push_window` Âíå `analysis_window` ÈÖçÁΩÆ‰∏çÂÜçÂÖºÂÆπÔºåËØ∑ÂèÇËÄÉÊñ∞Áâà config.yaml ËøÅÁßª

- **Áªü‰∏ÄË∞ÉÂ∫¶Á≥ªÁªü**ÔºöÊñ∞Â¢û `timeline.yaml`ÔºåÁî®‰∏ÄÂ•óÈÖçÁΩÆÊéßÂà∂„Äå‰ªÄ‰πàÊó∂Èó¥ÈááÈõÜ / Êé®ÈÄÅ / AI ÂàÜÊûê„Äç
- **5 ÁßçÈ¢ÑËÆæÊ®°Êùø**Ôºö`always_on`ÔºàÂÖ®Â§©ÂÄôÔºåÈªòËÆ§Ôºâ„ÄÅ`morning_evening`ÔºàÊó©ÊôöÊ±áÊÄªÔºâ„ÄÅ`office_hours`ÔºàÂäûÂÖ¨Êó∂Èó¥Ôºâ„ÄÅ`night_owl`ÔºàÂ§úÁå´Â≠êÔºâ„ÄÅ`custom`ÔºàËá™ÂÆö‰πâÔºâÔºõ‰πüÊîØÊåÅÂú® `presets:` ‰∏ãÊñ∞Â¢ûËá™Â∑±ÁöÑÊ®°ÊùøÔºåÂè™Ë¶Å key ‰∏çÈáçÂ§çÔºåÁÑ∂ÂêéÂú® config.yaml ÈáåÂ°´‰Ω†ÁöÑÊ®°ÊùøÂêçÂç≥ÂèØ
- **ÁÅµÊ¥ªÁöÑÊó∂Èó¥ÊÆµÈÖçÁΩÆ**ÔºöÊîØÊåÅÂ∑•‰ΩúÊó•/Âë®Êú´Â∑ÆÂºÇÂåñ„ÄÅË∑®ÂçàÂ§úÊó∂Èó¥ÊÆµ„ÄÅper-period once ÂéªÈáç
- **ÂèØËßÜÂåñÈÖçÁΩÆÁºñËæëÂô®**Ôºö
  - Êñ∞Â¢û `timeline.yaml` ÁºñËæëÊ†áÁ≠æÈ°µÔºå‰∏é config.yaml / frequency_words.txt Âπ∂Âàó
  - È¢ÑËÆæÊ®°ÂºèÂç°ÁâáÈÄâÊã©ÔºöÁÇπÂáªÂç≥ÂàáÊç¢ÔºåËá™Âä®ÂêåÊ≠• config.yaml ÁöÑ `schedule.preset`
  - Âë®ËßÜÂõæÊó∂Èó¥Á∫øÔºö7 Â§© √ó 24 Â∞èÊó∂Ê∞¥Âπ≥Êù°ÔºåÁî®È¢úËâ≤Âå∫ÂàÜÊé®ÈÄÅ/ÂàÜÊûê/ÈááÈõÜÁä∂ÊÄÅ
  - ÂèØ‰∫§‰∫íÊéß‰ª∂ÔºöÂºÄÂÖ≥„ÄÅ‰∏ãÊãâÊ°Ü„ÄÅÊó∂Èó¥ÈÄâÊã©Âô®ÔºåÂè≥‰æß‰øÆÊîπÂÆûÊó∂ÂêåÊ≠•Âà∞Â∑¶‰æß YAML
  - Âë®Êò†Â∞Ñ‰∏ãÊãâÈÄâÊã©ÔºöÊ†πÊçÆÊó•ËÆ°ÂàíÂä®ÊÄÅÂ°´ÂÖÖÔºåÊãñÊãâÁÇπÂáªÂç≥ÂèØÂÆåÊàêË∞ÉÂ∫¶ÈÖçÁΩÆ
- **AI ÊèêÁ§∫ËØçÁ®≥ÂÆöÊÄß‰ºòÂåñ**Ôºàai_analysis_prompt.txt v2.0.0ÔºâÔºö
  - Ê†ºÂºèËßÑËåÉÁã¨Á´ãËØ¥ÊòéÔºöÂ∞ÜÊç¢Ë°å/Ê†áÁ≠æ/Â∫èÂè∑/Á¶ÅÊ≠¢‰∫ãÈ°π‰ªé JSON value ‰∏≠ÊäΩÂá∫Ôºå‰Ωú‰∏∫Áã¨Á´ãÁ´†ËäÇ
  - JSON Ê®°ÊùøÁÆÄÂåñÔºöÂ≠óÊÆµÊèèËø∞Áº©Áü≠‰∏∫‰∏ÄÂè•ËØù + Â≠óÊï∞ÈôêÂà∂ÔºåÂáèÂ∞ë AI ËæìÂá∫Ê†ºÂºèÊ∑∑‰π±
  - ÂéªÈô§ system prompt ‰∏≠ÁöÑ Markdown Ê†ºÂºèÔºå‰∏é&quot;Á¶ÅÊ≠¢ Markdown&quot;Êåá‰ª§‰øùÊåÅ‰∏ÄËá¥
  - ÊâÄÊúâ JSON Â≠óÊÆµÂ£∞Êòé‰∏∫ÂèØÈÄâÔºåÁº∫Â∞ë‰ªª‰ΩïÂ≠óÊÆµ‰∏ç‰ºöÊä•ÈîôÔºåÂ¢ûÂº∫ÂÆπÈîôÊÄß
- **Êñ∞Â¢ûÁã¨Á´ãÂ±ïÁ§∫Âå∫ AI Ê¶ÇÊã¨ÂàÜÊûê**Ôºà`ai_analysis.include_standalone`ÔºâÔºö
  - Êñ∞Â¢ûÁã¨Á´ãÂºÄÂÖ≥ÔºåÂºÄÂêØÂêé AI ÂØπÊØè‰∏™ standalone Ê∫êÁîüÊàêÊ†∏ÂøÉÊ¶ÇÊã¨
  - AI ÂàÜÊûê‰∏éÊé®ÈÄÅÂ±ïÁ§∫Ëß£ËÄ¶ÔºöÊó†ÈúÄÂºÄÂêØÁã¨Á´ãÂ±ïÁ§∫Âå∫ÁöÑÊé®ÈÄÅÊòæÁ§∫ÔºåAI ‰πüÂèØÁã¨Á´ãÂàÜÊûêÂÆåÊï¥ÁÉ≠Ê¶úÊï∞ÊçÆ
  - ÊîØÊåÅÁÉ≠Ê¶úÂπ≥Âè∞Âíå RSS Ê∫êÔºåÂê´ÊéíÂêç/Êó∂Èó¥/ËΩ®ËøπÊï∞ÊçÆ
  - ËΩ®ËøπÂàÜÊûê‰∏é `include_rank_timeline` ËÅîÂä®ÔºöÂºÄÂêØÊó∂Âà©Áî®ËΩ®ËøπÊï∞ÊçÆÂÅöÊ∑±Â∫¶Ë∂ãÂäøÂàÜÊûêÔºåÂÖ≥Èó≠Êó∂Âü∫‰∫éÊéíÂêçÂÅöÁÆÄË¶ÅÂà§Êñ≠
  - Êñ∞Â¢û `standalone_summaries` JSON Â≠óÊÆµÔºàÁã¨Á´ãÊ∫êÁÇπÈÄüËßàÔºâÔºåÊâÄÊúâÊé®ÈÄÅÊ∏†ÈÅìÂùáÂ∑≤ÈÄÇÈÖçÊ∏≤Êüì


### 2026/02/09 - mcp-v4.0.0

- **üî• AI Ê∂àÊÅØÁõ¥Êé®ÊâÄÊúâÊ∏†ÈÅì**ÔºöËÆ© AI ÂÜôÂ•ΩÁöÑÂÜÖÂÆπ‰∏ÄÈîÆÊé®ÈÄÅÂà∞È£û‰π¶„ÄÅÈíâÈíâ„ÄÅTelegram„ÄÅÈÇÆ‰ª∂Á≠â 9 ‰∏™Ê∏†ÈÅìÔºåMarkdown Ëá™Âä®ÈÄÇÈÖçÂêÑÂπ≥Âè∞Ê†ºÂºèÔºå‰∏çÁî®ÊìçÂøÉÊ†ºÂºèÂ∑ÆÂºÇ
- **Êñ∞Â¢ûÊ†ºÂºèÂåñÁ≠ñÁï•ÊåáÂçó**ÔºöÊñ∞Â¢û `get_channel_format_guide` Â∑•ÂÖ∑ÔºåÂëäËØâ AI ÊØè‰∏™Ê∏†ÈÅìÊîØÊåÅ‰ªÄ‰πàÊ†ºÂºè„ÄÅÊúâ‰ªÄ‰πàÈôêÂà∂ÔºåÁîüÊàêÁöÑÂÜÖÂÆπÊéíÁâàÊõ¥Â•ΩÁúã
- **Êô∫ËÉΩÂàÜÊâπÂèëÈÄÅ**ÔºöË∂ÖÈïøÊ∂àÊÅØËá™Âä®ÊåâÂêÑÊ∏†ÈÅìÂ≠óËäÇÈôêÂà∂ÊãÜÂàÜÔºàÈ£û‰π¶ 30KB„ÄÅÈíâÈíâ 20KB Á≠âÔºâÔºåÈÖçÁΩÆËØªÂèñËá™ config.yaml
- **‰øÆÂ§çÊ∏†ÈÅìËØØÊ£ÄÊµã**Ôºöntfy ‰∏çÂÜçÂõ†‰∏∫ÈªòËÆ§Âú∞ÂùÄË¢´ËØØÊä•‰∏∫&quot;Â∑≤ÈÖçÁΩÆ&quot;
- **‰ª£Á†ÅÂ§çÁî®‰ºòÂåñ**ÔºöÊâπÊ¨°Â§ÑÁêÜÂáΩÊï∞Áõ¥Êé•Â§çÁî® trendradar Ê†∏ÂøÉÊ®°ÂùóÔºå‰∏çÈáçÂ§çÈÄ†ËΩÆÂ≠ê


&lt;details&gt;
&lt;summary&gt;üëâ ÁÇπÂáªÂ±ïÂºÄÔºö&lt;strong&gt;ÂéÜÂè≤Êõ¥Êñ∞&lt;/strong&gt;&lt;/summary&gt;


### 2026/01/28 - v5.5.0

&gt; Âíå mcp ÂäüËÉΩ‰∏ÄÊ†∑, Ëøô‰∏™Â∞èÂ∑•ÂÖ∑Êàë‰πü‰∏çÊñ∞ÂºÄ‰∏Ä‰∏™‰ªìÂ∫ìÁª¥Êä§‰∫Ü, ÂèçÊ≠£Á∫ØÂâçÁ´Ø, ÈÉΩÊêÅ‰∏ÄËµ∑Âêß

- Â¢ûÂä† trendradar ÁöÑÂèØËßÜÂåñÈÖçÁΩÆÁºñËæëÂô®


### 2026/02/02 - mcp-v3.2.0

- **Êñ∞Â¢û read_article Â∑•ÂÖ∑**ÔºöÈÄöËøá Jina AI Reader ËØªÂèñÂçïÁØáÊñáÁ´†Ê≠£ÊñáÔºàMarkdown Ê†ºÂºèÔºâ
- **Êñ∞Â¢û read_articles_batch Â∑•ÂÖ∑**ÔºöÊâπÈáèËØªÂèñÂ§öÁØáÊñáÁ´†ÔºàÊúÄÂ§ö 5 ÁØáÔºåËá™Âä®ÈôêÈÄüÔºâ
- **Êé®ËçêÂ∑•‰ΩúÊµÅ**Ôºö`search_news(query=&quot;ÂÖ≥ÈîÆËØç&quot;, include_url=True)` ‚Üí `read_article(url=...)` ËØªÂèñÊ≠£Êñá
- **ÊñáÊ°£Êõ¥Êñ∞**ÔºöREADME-MCP-FAQ.md Âíå README-MCP-FAQ-EN.md Êñ∞Â¢û Q19-Q20 ÊñáÁ´†ËØªÂèñÁõ∏ÂÖ≥ËØ¥Êòé


### 2026/01/10 - mcp-v3.0.0~v3.1.5

- **Breaking Change**ÔºöÊâÄÊúâÂ∑•ÂÖ∑ËøîÂõûÂÄºÁªü‰∏Ä‰∏∫ `{success, summary, data, error}` ÁªìÊûÑ
- **ÂºÇÊ≠•‰∏ÄËá¥ÊÄß**ÔºöÊâÄÊúâ 21 ‰∏™Â∑•ÂÖ∑ÂáΩÊï∞‰ΩøÁî® `asyncio.to_thread()` ÂåÖË£ÖÂêåÊ≠•Ë∞ÉÁî®
- **MCP Resources**ÔºöÊñ∞Â¢û 4 ‰∏™ËµÑÊ∫êÔºàplatforms„ÄÅrss-feeds„ÄÅavailable-dates„ÄÅkeywordsÔºâ
- **RSS Â¢ûÂº∫**Ôºö`get_latest_rss` ÊîØÊåÅÂ§öÊó•Êü•ËØ¢Ôºàdays ÂèÇÊï∞ÔºâÔºåË∑®Êó•Êúü URL ÂéªÈáç
- **Ê≠£ÂàôÂåπÈÖç‰øÆÂ§ç**Ôºö`get_trending_topics` ÊîØÊåÅ `/pattern/` Ê≠£ÂàôËØ≠Ê≥ïÂíå `display_name`
- **ÁºìÂ≠ò‰ºòÂåñ**ÔºöÊñ∞Â¢û `make_cache_key()` ÂáΩÊï∞ÔºåÂèÇÊï∞ÊéíÂ∫è+MD5 ÂìàÂ∏åÁ°Æ‰øù‰∏ÄËá¥ÊÄß
- **Êñ∞Â¢û check_version Â∑•ÂÖ∑**ÔºöÊîØÊåÅÂêåÊó∂Ê£ÄÊü• TrendRadar Âíå MCP Server ÁâàÊú¨Êõ¥Êñ∞


### 2026/01/23 - v5.4.0

- Â¢ûÂä† AI ÂàÜÊûêÊ®°ÂºèÁöÑÁã¨Á´ãÊéßÂà∂ÂäüËÉΩÔºåÂèØÈÄâ follow_report | daily | current | incremental 
- Êñ∞Â¢û AI ÂàÜÊûêÊó∂Èó¥Á™óÂè£ÊéßÂà∂ÔºåÊîØÊåÅËá™ÂÆö‰πâËøêË°åÊÆµÂèäÊØèÊó•È¢ëÊ¨°ÈôêÂà∂
- Â¢ûÂä†ÈÖçÁΩÆÊñá‰ª∂ÁâàÊú¨ÁÆ°ÁêÜÂäüËÉΩ
- ‰øÆÂ§çËã•Âπ≤bug


### 2026/01/19 - v5.3.0

&gt; **ÈáçÂ§ßÈáçÊûÑÔºöAI Ê®°ÂùóËøÅÁßªËá≥ LiteLLM**

- **Áªü‰∏Ä AI Êé•Âè£**Ôºö‰ΩøÁî® LiteLLM Êõø‰ª£ÊâãÂä®ÂÆûÁé∞ÔºåÊîØÊåÅ 100+ AI Êèê‰æõÂïÜ
- **ÁÆÄÂåñÈÖçÁΩÆ**ÔºöÁßªÈô§ `provider` Â≠óÊÆµÔºåÊîπÁî® `model: &quot;provider/model_name&quot;` Ê†ºÂºè
- **Êñ∞Â¢ûÂäüËÉΩ**ÔºöËá™Âä®ÈáçËØï (`num_retries`)„ÄÅÂ§áÁî®Ê®°Âûã (`fallback_models`)
- **ÈÖçÁΩÆÂèòÊõ¥**Ôºö
  - `ai.provider` ‚Üí ÁßªÈô§ÔºàÂ∑≤ÂêàÂπ∂Âà∞ modelÔºâ
  - `ai.base_url` ‚Üí `ai.api_base`
  - `AI_PROVIDER` ÁéØÂ¢ÉÂèòÈáè ‚Üí ÁßªÈô§
  - `AI_BASE_URL` ÁéØÂ¢ÉÂèòÈáè ‚Üí `AI_API_BASE`
- **Ê®°ÂûãÊ†ºÂºèÁ§∫‰æã**Ôºö
  - DeepSeek: `deepseek/deepseek-chat`
  - OpenAI: `openai/gpt-4o`
  - Gemini: `gemini/gemini-2.5-flash`
  - Anthropic: `anthropic/claude-3-5-sonnet`

### 2026/01/17 - v5.2.0

&gt; ‰∏ªË¶ÅËßÅ config.yaml ÊèèËø∞

**üåê AI ÁøªËØëÂäüËÉΩ**

- **Â§öËØ≠Ë®ÄÁøªËØë**ÔºöÊîØÊåÅÂ∞ÜÊé®ÈÄÅÂÜÖÂÆπÁøªËØë‰∏∫‰ªªÊÑèËØ≠Ë®Ä
- **ÊâπÈáèÁøªËØë**ÔºöÊô∫ËÉΩÊâπÈáèÂ§ÑÁêÜÔºåÂáèÂ∞ë API Ë∞ÉÁî®Ê¨°Êï∞
- **Ëá™ÂÆö‰πâÊèêÁ§∫ËØç**ÔºöÊîØÊåÅËá™ÂÆö‰πâÁøªËØëÈ£éÊ†º

**üîß ÈÖçÁΩÆÊû∂ÊûÑ‰ºòÂåñ**

- **AI Ê®°ÂûãÈÖçÁΩÆÁã¨Á´ã**ÔºöÂàÜÊûêÂíåÁøªËØëÂÖ±‰∫´Ê®°ÂûãÈÖçÁΩÆ
- **Âå∫ÂüüÂºÄÂÖ≥Áªü‰∏Ä**ÔºöÁªü‰∏ÄÁÆ°ÁêÜÊé®ÈÄÅÂå∫ÂüüÊòæÁ§∫
- **Âå∫ÂüüÊéíÂ∫èËá™ÂÆö‰πâ**ÔºöÊîØÊåÅËá™ÂÆö‰πâÂêÑÂå∫ÂüüÁöÑÊòæÁ§∫È°∫Â∫è

**‚ú® AI ÂàÜÊûêÂ¢ûÂº∫**

- **AI ÂàÜÊûêÂµåÂÖ• HTML**ÔºöÂàÜÊûêÁªìÊûúÁõ¥Êé•ÂµåÂÖ• HTML Êä•ÂëäÔºåÈÇÆ‰ª∂ÈÄöÁü•Áõ¥Êé•‰ΩøÁî®
- **ÂØåÊ†∑Âºè AI Âå∫Âùó**ÔºöÊ∏êÂèòËìùËâ≤ËÉåÊôØÂç°ÁâáÂºèÂ∏ÉÂ±ÄÔºåÊ∏ÖÊô∞ÂàÜÈöîÂêÑÂàÜÊûêÁª¥Â∫¶
- **ÊéíÂêçÊó∂Èó¥Á∫øÊîØÊåÅ**ÔºöAI ÂèØËé∑ÂèñÊØèÊù°Êñ∞ÈóªÂú®ÊØè‰∏™ÊäìÂèñÊó∂Èó¥ÁÇπÁöÑÁ≤æÁ°ÆÊéíÂêç
- **ÊùøÂùóÈáçÁªÑ (7‚Üí4)**ÔºöÊï¥Âêà‰∏∫Ê†∏ÂøÉÁÉ≠ÁÇπÊÄÅÂäø„ÄÅËàÜËÆ∫È£éÂêë‰∫âËÆÆ„ÄÅÂºÇÂä®‰∏éÂº±‰ø°Âè∑„ÄÅÁ†îÂà§Á≠ñÁï•Âª∫ËÆÆ

**üîß Â§öÊ®°ÂûãÈÄÇÈÖç**

- **ÈÄöÁî®ÂèÇÊï∞ÈÄè‰º†**ÔºöÊîØÊåÅÂêë API ÈÄè‰º†‰ªªÊÑèÈ´òÁ∫ßÂèÇÊï∞
- **Gemini ÈÄÇÈÖç**ÔºöÂéüÁîüÂèÇÊï∞ÊîØÊåÅÔºåÂÜÖÁΩÆÂÆâÂÖ®Á≠ñÁï•ÊîæÂÆΩ

**üêõ Bug ‰øÆÂ§ç**

- ‰øÆÂ§çËã•Âπ≤Â∑≤Áü•ÈóÆÈ¢òÔºåÊèêÂçáÁ≥ªÁªüÁ®≥ÂÆöÊÄß

### 2026/01/10 - v5.0.0

&gt; **ÂºÄÂèëÂ∞èÊèíÊõ≤**Ôºö
&gt; Ëá¥Êï¨ÈÇ£‰∏™Èô™‰º¥Êàë‰∏§Âπ¥Â§ö„ÄÅÂç¥Âú®ÂàöÁª≠Ë¥πÂêéÂèçÊâãÂºπÂá∫ `&quot;This organization has been disabled&quot;` ÁöÑÊüê C ÂéÇÊ®°Âûã

**‚ú® Êé®ÈÄÅÂÜÖÂÆπ&quot;‰∫îÂ§ßÊùøÂùó&quot;ÈáçÊûÑ**

Êú¨Ê¨°Êõ¥Êñ∞ÂØπÊé®ÈÄÅÊ∂àÊÅØËøõË°å‰∫ÜÂå∫ÂüüÂåñÈáçÊûÑÔºåÁé∞Âú®Êé®ÈÄÅÂÜÖÂÆπÊ∏ÖÊô∞Âú∞ÂàíÂàÜ‰∏∫‰∫îÂ§ßÊ†∏ÂøÉÊùøÂùóÔºö

1.  **üìä ÁÉ≠Ê¶úÊñ∞Èóª**ÔºöÊ†πÊçÆ‰Ω†ÁöÑÂÖ≥ÈîÆËØçÁ≤æÂáÜÁ≠õÈÄâÂêéÁöÑÂÖ®ÁΩëÁÉ≠ÁÇπËÅöÂêà„ÄÇ
2.  **üì∞ RSS ËÆ¢ÈòÖ**Ôºö‰Ω†ÁöÑ‰∏™ÊÄßÂåñËÆ¢ÈòÖÊ∫êÂÜÖÂÆπÔºåÊîØÊåÅÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑ„ÄÇ
3.  **üÜï Êú¨Ê¨°Êñ∞Â¢û**ÔºöÂÆûÊó∂ÊçïÊçâËá™‰∏äÊ¨°ËøêË°å‰ª•Êù•ÁöÑÂÖ®Êñ∞ÁÉ≠ÁÇπÔºàÂ∏¶ üÜï Ê†áËÆ∞Ôºâ„ÄÇ
4.  **üìã Áã¨Á´ãÂ±ïÁ§∫Âå∫**ÔºöÊåáÂÆöÂπ≥Âè∞ÁöÑÂÆåÊï¥ÁÉ≠Ê¶úÊàñ RSS Ê∫êÂ±ïÁ§∫Ôºå**ÂÆåÂÖ®‰∏çÂèóÂÖ≥ÈîÆËØçËøáÊª§ÈôêÂà∂**„ÄÇ
5.  **‚ú® AI ÂàÜÊûêÊùøÂùó**ÔºöÁî± AI È©±Âä®ÁöÑÊ∑±Â∫¶Ê¥ûÂØüÔºåÂåÖÂê´Ë∂ãÂäøÊ¶ÇËø∞„ÄÅÁÉ≠Â∫¶Ëµ∞ÂäøÂèä**ÊûÅÂÖ∂ÈáçË¶Å**ÁöÑÊÉÖÊÑüÂÄæÂêëÂàÜÊûê„ÄÇ

**‚ú® AI Êô∫ËÉΩÂàÜÊûêÊé®ÈÄÅÂäüËÉΩ**

- **AI ÂàÜÊûêÈõÜÊàê**Ôºö‰ΩøÁî® AI Â§ßÊ®°ÂûãÂØπÊé®ÈÄÅÂÜÖÂÆπËøõË°åÊ∑±Â∫¶ÂàÜÊûêÔºåËá™Âä®ÁîüÊàêÁÉ≠ÁÇπË∂ãÂäøÊ¶ÇËø∞„ÄÅÂÖ≥ÈîÆËØçÁÉ≠Â∫¶ÂàÜÊûê„ÄÅË∑®Âπ≥Âè∞ÂÖ≥ËÅî„ÄÅÊΩúÂú®ÂΩ±ÂìçËØÑ‰º∞Á≠â
- **ÊÉÖÊÑüÂÄæÂêëÂàÜÊûê**ÔºöÊñ∞Â¢ûÊ∑±Â∫¶ÊÉÖÊÑüËØÜÂà´ÔºåÁ≤æÂáÜÊçïÊçâËàÜËÆ∫ÁöÑÊ≠£Ë¥üÈù¢„ÄÅ‰∫âËÆÆÊàñÊãÖÂøßÊÉÖÁª™
- **Â§ö AI Êèê‰æõÂïÜÊîØÊåÅ**ÔºöÊîØÊåÅ DeepSeekÔºàÈªòËÆ§ÔºåÊÄß‰ª∑ÊØîÈ´òÔºâ„ÄÅOpenAI„ÄÅGoogle Gemini Âèä‰ªªÊÑè OpenAI ÂÖºÂÆπÊé•Âè£
- **‰∏§ÁßçÊé®ÈÄÅÊ®°Âºè**Ôºö`only_analysis`Ôºà‰ªÖ AI ÂàÜÊûêÔºâ„ÄÅ`both`Ôºà‰∏§ËÄÖÈÉΩÊé®ÈÄÅÔºâ
- **Ëá™ÂÆö‰πâÊèêÁ§∫ËØç**ÔºöÈÄöËøá `config/ai_analysis_prompt.txt` Êñá‰ª∂Ëá™ÂÆö‰πâ AI ÂàÜÊûêËßíËâ≤ÂíåËæìÂá∫Ê†ºÂºè
- **Â§öÁª¥Â∫¶Êï∞ÊçÆÂàÜÊûê**ÔºöAI ÂèØÂàÜÊûêÊéíÂêçÂèòÂåñ„ÄÅÁÉ≠Â∫¶ÊåÅÁª≠Êó∂Èó¥„ÄÅË∑®Âπ≥Âè∞Ë°®Áé∞„ÄÅË∂ãÂäøÈ¢ÑÊµãÁ≠â

**üìã Áã¨Á´ãÂ±ïÁ§∫Âå∫ÂäüËÉΩ**

- **ÂÆåÊï¥ÁÉ≠Ê¶úÂ±ïÁ§∫**ÔºöÊåáÂÆöÂπ≥Âè∞ÁöÑÂÆåÊï¥ÁÉ≠Ê¶úÂçïÁã¨Â±ïÁ§∫Ôºå‰∏çÂèóÂÖ≥ÈîÆËØçËøáÊª§ÂΩ±Âìç
- **RSS Áã¨Á´ãÂ±ïÁ§∫**ÔºöRSS Ê∫êÂÜÖÂÆπÂèØÂÆåÊï¥Â±ïÁ§∫ÔºåÈÄÇÂêàÂÜÖÂÆπËæÉÂ∞ëÁöÑËÆ¢ÈòÖÊ∫ê
- **ÁÅµÊ¥ªÈÖçÁΩÆ**ÔºöÊîØÊåÅÈÖçÁΩÆÂ±ïÁ§∫Âπ≥Âè∞ÂàóË°®„ÄÅRSS Ê∫êÂàóË°®„ÄÅÊúÄÂ§ßÂ±ïÁ§∫Êù°Êï∞

**üìä Êé®ÈÄÅ‰ΩìÈ™åÈáçÊûÑ**

- **ÊéíÁâàÂçáÁ∫ß**ÔºöÈáçÊñ∞ËÆæËÆ°Âπ∂Áªü‰∏ÄÂêÑÊ∏†ÈÅìÁªüËÆ°Â§¥ÈÉ®ÔºåÂº∫ÂåñÂå∫ÂùóÁªÑÁªáÔºåÊ∂àÊÅØÂ±ÇÊ¨°‰∏ÄÁõÆ‰∫ÜÁÑ∂
- **ÈÖçÁΩÆÁÆÄÂåñ**Ôºö‰ºòÂåñÈ£û‰π¶Á≠âÈÄöÁü•Ê∏†ÈÅìÁöÑÈÖçÁΩÆÈÄªËæëÔºå‰∏äÊâãÊõ¥ÁÆÄÂçï
- **ÁÉ≠Â∫¶Ë∂ãÂäøÁÆ≠Â§¥**ÔºöÊñ∞Â¢û üî∫(‰∏äÂçá)„ÄÅüîª(‰∏ãÈôç)„ÄÅ‚ûñ(ÊåÅÂπ≥) Ë∂ãÂäøÊ†áËØÜÔºåÁõ¥ËßÇÂ±ïÁ§∫ÁÉ≠Â∫¶ÂèòÂåñ
- **ÈÄöÁî® Webhook**ÔºöÊîØÊåÅËá™ÂÆö‰πâ Webhook URL Âíå JSON Ê®°ÊùøÔºåËΩªÊùæÈÄÇÈÖç Discord„ÄÅMatrix„ÄÅIFTTT Á≠â‰ªªÊÑèÂπ≥Âè∞

**üîß ÈÖçÁΩÆ‰ºòÂåñ**

- **È¢ëÁéáËØçÈÖçÁΩÆÂ¢ûÂº∫**ÔºöÊñ∞Â¢û `[ÁªÑÂà´Âêç]` ËØ≠Ê≥ïÔºåÊîØÊåÅ `#` Ê≥®ÈáäË°åÔºåÈÖçÁΩÆÊõ¥Ê∏ÖÊô∞ÔºàÊÑüË∞¢ [@songge8](https://github.com/sansan0/TrendRadar/issues/752) ÊèêÂá∫ÁöÑÂª∫ËÆÆÔºâ
- **ÁéØÂ¢ÉÂèòÈáèÊîØÊåÅ**ÔºöAI ÂàÜÊûêÁõ∏ÂÖ≥ÈÖçÁΩÆÊîØÊåÅÁéØÂ¢ÉÂèòÈáèË¶ÜÁõñÔºà`AI_API_KEY`„ÄÅ`AI_PROVIDER` Á≠âÔºâ

&gt; üí° ËØ¶ÁªÜÈÖçÁΩÆÊïôÁ®ãËßÅ [ËÆ© AI Â∏ÆÊàëÂàÜÊûêÁÉ≠ÁÇπ](#12-ËÆ©-ai-Â∏ÆÊàëÂàÜÊûêÁÉ≠ÁÇπ)


### 2026/01/02 - v4.7.0

- **‰øÆÂ§ç RSS HTML ÊòæÁ§∫**Ôºö‰øÆÂ§ç RSS Êï∞ÊçÆÊ†ºÂºè‰∏çÂåπÈÖçÂØºËá¥ÁöÑÊ∏≤ÊüìÈóÆÈ¢òÔºåÁé∞Âú®ÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑÊ≠£Á°ÆÊòæÁ§∫
- **Êñ∞Â¢ûÊ≠£ÂàôË°®ËææÂºèËØ≠Ê≥ï**ÔºöÂÖ≥ÈîÆËØçÈÖçÁΩÆÊîØÊåÅ `/pattern/` Ê≠£ÂàôËØ≠Ê≥ïÔºåËß£ÂÜ≥Ëã±ÊñáÂ≠êÂ≠óÁ¨¶‰∏≤ËØØÂåπÈÖçÈóÆÈ¢òÔºàÂ¶Ç `ai` ÂåπÈÖç `training`Ôºâ[üìñ Êü•ÁúãËØ≠Ê≥ïËØ¶Ëß£](#ÂÖ≥ÈîÆËØçÂü∫Á°ÄËØ≠Ê≥ï)
- **Êñ∞Â¢ûÊòæÁ§∫ÂêçÁß∞ËØ≠Ê≥ï**Ôºö‰ΩøÁî® `=&gt; Â§áÊ≥®` ÁªôÂ§çÊùÇÁöÑÊ≠£ÂàôË°®ËææÂºèËµ∑‰∏™Â•ΩËÆ∞ÁöÑÂêçÂ≠óÔºåÊé®ÈÄÅÊ∂àÊÅØÊòæÁ§∫Êõ¥Ê∏ÖÊô∞ÔºàÂ¶Ç `/\bai\b/ =&gt; AIÁõ∏ÂÖ≥`Ôºâ
- **‰∏ç‰ºöÂÜôÊ≠£ÂàôÔºü** README Êñ∞Â¢û AI ÁîüÊàêÊ≠£ÂàôÁöÑÂºïÂØºÔºåÂëäËØâ ChatGPT/Gemini/DeepSeek ‰Ω†ÊÉ≥ÂåπÈÖç‰ªÄ‰πàÔºåËÆ© AI Â∏Æ‰Ω†ÂÜô


### 2025/12/30 - mcp-v2.0.0

- **Êû∂ÊûÑË∞ÉÊï¥**ÔºöÁßªÈô§ TXT ÊîØÊåÅÔºåÁªü‰∏Ä‰ΩøÁî® SQLite Êï∞ÊçÆÂ∫ì
- **RSS Êü•ËØ¢**ÔºöÊñ∞Â¢û `get_latest_rss`„ÄÅ`search_rss`„ÄÅ`get_rss_feeds_status`
- **Áªü‰∏ÄÊêúÁ¥¢**Ôºö`search_news` ÊîØÊåÅ `include_rss` ÂèÇÊï∞ÂêåÊó∂ÊêúÁ¥¢ÁÉ≠Ê¶úÂíå RSS


### 2026/01/01 - v4.6.0

- **‰øÆÂ§ç RSS HTML ÊòæÁ§∫**ÔºöÂ∞Ü RSS ÂÜÖÂÆπÂêàÂπ∂Âà∞ÁÉ≠Ê¶ú HTML È°µÈù¢ÔºåÊåâÊ∫êÂàÜÁªÑÊòæÁ§∫
- **Êñ∞Â¢û display_mode ÈÖçÁΩÆ**ÔºöÊîØÊåÅ `keyword`ÔºàÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑÔºâÂíå `platform`ÔºàÊåâÂπ≥Âè∞ÂàÜÁªÑÔºâ‰∏§ÁßçÊòæÁ§∫Ê®°Âºè


### 2025/12/30 - v4.5.0

- **RSS ËÆ¢ÈòÖÊ∫êÊîØÊåÅ**ÔºöÊñ∞Â¢û RSS/Atom ÊäìÂèñÔºåÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑÁªüËÆ°Ôºà‰∏éÁÉ≠Ê¶úÊ†ºÂºè‰∏ÄËá¥Ôºâ
- **Â≠òÂÇ®ÁªìÊûÑÈáçÊûÑ**ÔºöÊâÅÂπ≥ÂåñÁõÆÂΩïÁªìÊûÑ `output/{type}/{date}.db`
- **Áªü‰∏ÄÊéíÂ∫èÈÖçÁΩÆ**Ôºö`sort_by_position_first` ÂêåÊó∂ÂΩ±ÂìçÁÉ≠Ê¶úÂíå RSS
- **ÈÖçÁΩÆÁªìÊûÑÈáçÊûÑ**Ôºö`config.yaml` ÈáçÊñ∞ÁªÑÁªá‰∏∫ 7 ‰∏™ÈÄªËæëÂàÜÁªÑÔºàapp„ÄÅreport„ÄÅnotification„ÄÅstorage„ÄÅplatforms„ÄÅrss„ÄÅadvancedÔºâÔºåÈÖçÁΩÆË∑ØÂæÑÊõ¥Ê∏ÖÊô∞


### 2025/12/26 - mcp-v1.2.0

  **MCP Ê®°ÂùóÊõ¥Êñ∞ - ‰ºòÂåñÂ∑•ÂÖ∑ÈõÜÔºåÊñ∞Â¢ûËÅöÂêàÂØπÊØîÂäüËÉΩÔºåÂêàÂπ∂ÂÜó‰ΩôÂ∑•ÂÖ∑:**
  - Êñ∞Â¢û `aggregate_news` Â∑•ÂÖ∑ - Ë∑®Âπ≥Âè∞Êñ∞ÈóªÂéªÈáçËÅöÂêà
  - Êñ∞Â¢û `compare_periods` Â∑•ÂÖ∑ - Êó∂ÊúüÂØπÊØîÂàÜÊûêÔºàÂë®ÁéØÊØî/ÊúàÁéØÊØîÔºâ
  - ÂêàÂπ∂ `find_similar_news` + `search_related_news_history` ‚Üí `find_related_news`
  - Â¢ûÂº∫ `get_trending_topics` - Êñ∞Â¢û `auto_extract` Ê®°ÂºèËá™Âä®ÊèêÂèñÁÉ≠ÁÇπ
  - ‰øÆÂ§çËã•Âπ≤bug
  - ÂêåÊ≠•Êõ¥Êñ∞ README-MCP-FAQ.md ÊñáÊ°£ÁöÑ‰∏≠Ëã±ÊñáÁâà (Q1-Q18)


### 2025/12/20 - v4.0.3

- Êñ∞Â¢û URL Ê†áÂáÜÂåñÂäüËÉΩÔºåËß£ÂÜ≥ÂæÆÂçöÁ≠âÂπ≥Âè∞Âõ†Âä®ÊÄÅÂèÇÊï∞ÔºàÂ¶Ç `band_rank`ÔºâÂØºËá¥ÁöÑÈáçÂ§çÊé®ÈÄÅÈóÆÈ¢ò
- ‰øÆÂ§çÂ¢ûÈáèÊ®°ÂºèÊ£ÄÊµãÈÄªËæëÔºåÊ≠£Á°ÆËØÜÂà´ÂéÜÂè≤Ê†áÈ¢ò


### 2025/12/17 - v4.0.1

- StorageManager Ê∑ªÂä†Êé®ÈÄÅËÆ∞ÂΩï‰ª£ÁêÜÊñπÊ≥ï
- S3 ÂÆ¢Êà∑Á´ØÂàáÊç¢Ëá≥ virtual-hosted style ‰ª•ÊèêÂçáÂÖºÂÆπÊÄßÔºàÊîØÊåÅËÖæËÆØ‰∫ë COS Á≠âÊõ¥Â§öÊúçÂä°Ôºâ


### 2025/12/13 - mcp-v1.1.0

  **MCP Ê®°ÂùóÊõ¥Êñ∞:**
  - ÈÄÇÈÖç v4.0.0ÔºåÂêåÊó∂‰πüÂÖºÂÆπ v3.x ÁöÑÊï∞ÊçÆ
  - Êñ∞Â¢ûÂ≠òÂÇ®ÂêåÊ≠•Â∑•ÂÖ∑Ôºö`sync_from_remote`„ÄÅ`get_storage_status`„ÄÅ`list_available_dates`


### 2025/12/13 - v4.0.0

**üéâ ÈáçÂ§ßÊõ¥Êñ∞ÔºöÂÖ®Èù¢ÈáçÊûÑÂ≠òÂÇ®ÂíåÊ†∏ÂøÉÊû∂ÊûÑ**

- **Â§öÂ≠òÂÇ®ÂêéÁ´ØÊîØÊåÅ**ÔºöÂºïÂÖ•ÂÖ®Êñ∞ÁöÑÂ≠òÂÇ®Ê®°ÂùóÔºåÊîØÊåÅÊú¨Âú∞ SQLite ÂíåËøúÁ®ã‰∫ëÂ≠òÂÇ®ÔºàS3 ÂÖºÂÆπÂçèËÆÆÔºå‰æãÂ¶Ç Cloudflare R2ÔºâÔºåÈÄÇÂ∫î GitHub Actions„ÄÅDocker ÂíåÊú¨Âú∞ÁéØÂ¢É„ÄÇ
- **Êï∞ÊçÆÂ∫ìÁªìÊûÑ‰ºòÂåñ**ÔºöÈáçÊûÑ SQLite Êï∞ÊçÆÂ∫ìË°®ÁªìÊûÑÔºåÊèêÂçáÊï∞ÊçÆÊïàÁéáÂíåÊü•ËØ¢ËÉΩÂäõ„ÄÇ
- **Ê†∏ÂøÉ‰ª£Á†ÅÊ®°ÂùóÂåñ**ÔºöÂ∞Ü‰∏ªÁ®ãÂ∫èÈÄªËæëÊãÜÂàÜ‰∏∫ trendradar ÂåÖÁöÑÂ§ö‰∏™Ê®°ÂùóÔºåÊòæËëóÊèêÂçá‰ª£Á†ÅÂèØÁª¥Êä§ÊÄß„ÄÇ
- **Â¢ûÂº∫ÂäüËÉΩ**ÔºöÂÆûÁé∞Êó•ÊúüÊ†ºÂºèÊ†áÂáÜÂåñ„ÄÅÊï∞ÊçÆ‰øùÁïôÁ≠ñÁï•„ÄÅÊó∂Âå∫ÈÖçÁΩÆÊîØÊåÅ„ÄÅÊó∂Èó¥ÊòæÁ§∫‰ºòÂåñÔºåÂπ∂‰øÆÂ§çËøúÁ®ãÂ≠òÂÇ®Êï∞ÊçÆÊåÅ‰πÖÂåñÈóÆÈ¢òÔºåÁ°Æ‰øùÊï∞ÊçÆÂêàÂπ∂ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ
- **Ê∏ÖÁêÜÂíåÂÖºÂÆπ**ÔºöÁßªÈô§‰∫ÜÂ§ßÈÉ®ÂàÜÂéÜÂè≤ÂÖºÂÆπ‰ª£Á†ÅÔºåÁªü‰∏Ä‰∫ÜÊï∞ÊçÆÂ≠òÂÇ®ÂíåËØªÂèñÊñπÂºè„ÄÇ


### 2025/12/03 - v3.5.0

**üéâ Ê†∏ÂøÉÂäüËÉΩÂ¢ûÂº∫**

1. **Â§öË¥¶Âè∑Êé®ÈÄÅÊîØÊåÅ**
   - ÊâÄÊúâÊé®ÈÄÅÊ∏†ÈÅìÔºàÈ£û‰π¶„ÄÅÈíâÈíâ„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°„ÄÅTelegram„ÄÅntfy„ÄÅBark„ÄÅSlackÔºâÊîØÊåÅÂ§öË¥¶Âè∑ÈÖçÁΩÆ
   - ‰ΩøÁî®ÂàÜÂè∑ `;` ÂàÜÈöîÂ§ö‰∏™Ë¥¶Âè∑Ôºå‰æãÂ¶ÇÔºö`FEISHU_WEBHOOK_URL=url1;url2`
   - Ëá™Âä®È™åËØÅÈÖçÂØπÈÖçÁΩÆÔºàÂ¶Ç Telegram ÁöÑ token Âíå chat_idÔºâÊï∞Èáè‰∏ÄËá¥ÊÄß

2. **Êé®ÈÄÅÂå∫ÂüüÈÖçÁΩÆ**
   - ÈÄöËøá `display.region_order` Ëá™ÂÆö‰πâÂêÑÂå∫ÂüüÁöÑÊòæÁ§∫È°∫Â∫èÔºàv5.2.0 Êõø‰ª£Âéü `reverse_content_order`Ôºâ
   - ÈÄöËøá `display.regions` ÊéßÂà∂ÂêÑÂå∫ÂüüÊòØÂê¶ÊòæÁ§∫ÔºàÁÉ≠Ê¶ú„ÄÅÊñ∞Â¢ûÁÉ≠ÁÇπ„ÄÅRSS„ÄÅÁã¨Á´ãÂ±ïÁ§∫Âå∫„ÄÅAI ÂàÜÊûêÔºâ

3. **ÂÖ®Â±ÄËøáÊª§ÂÖ≥ÈîÆËØç**
   - Êñ∞Â¢û `[GLOBAL_FILTER]` Âå∫ÂüüÊ†áËÆ∞ÔºåÊîØÊåÅÂÖ®Â±ÄËøáÊª§‰∏çÊÉ≥ÁúãÂà∞ÁöÑÂÜÖÂÆπ
   - ÈÄÇÁî®Âú∫ÊôØÔºöËøáÊª§ÂπøÂëä„ÄÅËê•ÈîÄ„ÄÅ‰ΩéË¥®ÂÜÖÂÆπÁ≠â

**üê≥ Docker ÂèåË∑ØÂæÑ HTML ÁîüÊàê‰ºòÂåñ**

- **ÈóÆÈ¢ò‰øÆÂ§ç**ÔºöËß£ÂÜ≥ Docker ÁéØÂ¢É‰∏ã `index.html` Êó†Ê≥ïÂêåÊ≠•Âà∞ÂÆø‰∏ªÊú∫ÁöÑÈóÆÈ¢ò
- **ÂèåË∑ØÂæÑÁîüÊàê**ÔºöÂΩìÊó•Ê±áÊÄª HTML ÂêåÊó∂ÁîüÊàêÂà∞‰∏§‰∏™‰ΩçÁΩÆ
  - `index.html`ÔºàÈ°πÁõÆÊ†πÁõÆÂΩïÔºâÔºö‰æõ GitHub Pages ËÆøÈóÆ
  - `output/index.html`ÔºöÈÄöËøá Docker Volume ÊåÇËΩΩÔºåÂÆø‰∏ªÊú∫ÂèØÁõ¥Êé•ËÆøÈóÆ
- **ÂÖºÂÆπÊÄß**ÔºöÁ°Æ‰øù Docker„ÄÅGitHub Actions„ÄÅÊú¨Âú∞ËøêË°åÁéØÂ¢ÉÂùáËÉΩÊ≠£Â∏∏ËÆøÈóÆÁΩëÈ°µÁâàÊä•Âëä

**üê≥ Docker MCP ÈïúÂÉèÊîØÊåÅ**

- Êñ∞Â¢ûÁã¨Á´ãÁöÑ MCP ÊúçÂä°ÈïúÂÉè `wantcat/trendradar-mcp`
- ÊîØÊåÅ Docker ÈÉ®ÁΩ≤ AI ÂàÜÊûêÂäüËÉΩÔºåÈÄöËøá HTTP Êé•Âè£ÔºàÁ´ØÂè£ 3333ÔºâÊèê‰æõÊúçÂä°
- ÂèåÂÆπÂô®Êû∂ÊûÑÔºöÊñ∞ÈóªÊé®ÈÄÅÊúçÂä°‰∏é MCP ÊúçÂä°Áã¨Á´ãËøêË°åÔºåÂèØÂàÜÂà´Êâ©Â±ïÂíåÈáçÂêØ
- ËØ¶ËßÅ [Docker ÈÉ®ÁΩ≤ - MCP ÊúçÂä°](#6-docker-ÈÉ®ÁΩ≤)

**üåê Web ÊúçÂä°Âô®ÊîØÊåÅ**

- Êñ∞Â¢ûÂÜÖÁΩÆ Web ÊúçÂä°Âô®ÔºåÊîØÊåÅÈÄöËøáÊµèËßàÂô®ËÆøÈóÆÁîüÊàêÁöÑÊä•Âëä
- ÈÄöËøá `manage.py` ÂëΩ‰ª§ÊéßÂà∂ÂêØÂä®/ÂÅúÊ≠¢Ôºö`docker exec -it trendradar python manage.py start_webserver`
- ËÆøÈóÆÂú∞ÂùÄÔºö`http://localhost:8080`ÔºàÁ´ØÂè£ÂèØÈÖçÁΩÆÔºâ
- ÂÆâÂÖ®ÁâπÊÄßÔºöÈùôÊÄÅÊñá‰ª∂ÊúçÂä°„ÄÅÁõÆÂΩïÈôêÂà∂„ÄÅÊú¨Âú∞ËÆøÈóÆ
- ÊîØÊåÅËá™Âä®ÂêØÂä®ÂíåÊâãÂä®ÊéßÂà∂‰∏§ÁßçÊ®°Âºè

**üìñ ÊñáÊ°£‰ºòÂåñ**

- Êñ∞Â¢û [Êé®ÈÄÅÂÜÖÂÆπÊÄé‰πàÊòæÁ§∫Ôºü](#7-Êé®ÈÄÅÂÜÖÂÆπÊÄé‰πàÊòæÁ§∫) Á´†ËäÇÔºöËá™ÂÆö‰πâÊé®ÈÄÅÊ†∑ÂºèÂíåÂÜÖÂÆπ
- Êñ∞Â¢û [‰ªÄ‰πàÊó∂ÂÄôÁªôÊàëÊé®ÈÄÅÔºü](#8-‰ªÄ‰πàÊó∂ÂÄôÁªôÊàëÊé®ÈÄÅ) Á´†ËäÇÔºöËÆæÁΩÆÊé®ÈÄÅÊó∂Èó¥ÊÆµ
- Êñ∞Â¢û [Â§ö‰πÖËøêË°å‰∏ÄÊ¨°Ôºü](#9-Â§ö‰πÖËøêË°å‰∏ÄÊ¨°) Á´†ËäÇÔºöËÆæÁΩÆËá™Âä®ËøêË°åÈ¢ëÁéá
- Êñ∞Â¢û [Êé®ÈÄÅÂà∞Â§ö‰∏™Áæ§/ËÆæÂ§á](#10-Êé®ÈÄÅÂà∞Â§ö‰∏™Áæ§ËÆæÂ§á) Á´†ËäÇÔºöÂêåÊó∂Êé®ÈÄÅÁªôÂ§ö‰∏™Êé•Êî∂ËÄÖ
- ‰ºòÂåñÂêÑÈÖçÁΩÆÁ´†ËäÇÔºöÁªü‰∏ÄÊ∑ªÂä†&quot;ÈÖçÁΩÆ‰ΩçÁΩÆ&quot;ËØ¥Êòé
- ÁÆÄÂåñÂø´ÈÄüÂºÄÂßãÈÖçÁΩÆËØ¥ÊòéÔºö‰∏â‰∏™Ê†∏ÂøÉÊñá‰ª∂‰∏ÄÁõÆ‰∫ÜÁÑ∂
- ‰ºòÂåñ [Docker ÈÉ®ÁΩ≤](#6-docker-ÈÉ®ÁΩ≤) Á´†ËäÇÔºöÊñ∞Â¢ûÈïúÂÉèËØ¥Êòé„ÄÅÊé®Ëçê git clone ÈÉ®ÁΩ≤„ÄÅÈáçÁªÑÈÉ®ÁΩ≤ÊñπÂºè

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`„ÄÅ`config/config.yaml`ÔºàÊñ∞Â¢ûÂ§öË¥¶Âè∑Êé®ÈÄÅÊîØÊåÅÔºåÊó†ÈúÄ‰øÆÊîπÁé∞ÊúâÈÖçÁΩÆÔºâ
- **Â§öË¥¶Âè∑Êé®ÈÄÅ**ÔºöÊñ∞ÂäüËÉΩÔºåÈªòËÆ§‰∏çÂêØÁî®ÔºåÁé∞ÊúâÂçïË¥¶Âè∑ÈÖçÁΩÆ‰∏çÂèóÂΩ±Âìç


### 2025/11/26 - mcp-v1.0.3

  **MCP Ê®°ÂùóÊõ¥Êñ∞:**
  - Êñ∞Â¢ûÊó•ÊúüËß£ÊûêÂ∑•ÂÖ∑ resolve_date_range,Ëß£ÂÜ≥ AI Ê®°ÂûãËÆ°ÁÆóÊó•Êúü‰∏ç‰∏ÄËá¥ÁöÑÈóÆÈ¢ò
  - ÊîØÊåÅËá™ÁÑ∂ËØ≠Ë®ÄÊó•ÊúüË°®ËææÂºèËß£Êûê(Êú¨Âë®„ÄÅÊúÄËøë7Â§©„ÄÅ‰∏äÊúàÁ≠â)
  - Â∑•ÂÖ∑ÊÄªÊï∞‰ªé 13 ‰∏™Â¢ûÂä†Âà∞ 14 ‰∏™


### 2025/11/28 - v3.4.1

**üîß Ê†ºÂºè‰ºòÂåñ**

1. **Bark Êé®ÈÄÅÂ¢ûÂº∫**
   - Bark Áé∞ÊîØÊåÅ Markdown Ê∏≤Êüì
   - ÂêØÁî®ÂéüÁîü Markdown Ê†ºÂºèÔºöÁ≤ó‰Ωì„ÄÅÈìæÊé•„ÄÅÂàóË°®„ÄÅ‰ª£Á†ÅÂùóÁ≠â
   - ÁßªÈô§Á∫ØÊñáÊú¨ËΩ¨Êç¢ÔºåÂÖÖÂàÜÂà©Áî® Bark ÂéüÁîüÊ∏≤ÊüìËÉΩÂäõ

2. **Slack Ê†ºÂºèÁ≤æÂáÜÂåñ**
   - ‰ΩøÁî®‰∏ìÁî® mrkdwn Ê†ºÂºèÂ§ÑÁêÜÂàÜÊâπÂÜÖÂÆπ
   - ÊèêÂçáÂ≠óËäÇÂ§ßÂ∞è‰º∞ÁÆóÂáÜÁ°ÆÊÄßÔºàÈÅøÂÖçÊ∂àÊÅØË∂ÖÈôêÔºâ
   - ‰ºòÂåñÈìæÊé•Ê†ºÂºèÔºö`&lt;url|text&gt;` ÂíåÂä†Á≤óËØ≠Ê≥ïÔºö`*text*`

3. **ÊÄßËÉΩÊèêÂçá**
   - Ê†ºÂºèËΩ¨Êç¢Âú®ÂàÜÊâπËøáÁ®ã‰∏≠ÂÆåÊàêÔºåÈÅøÂÖç‰∫åÊ¨°Â§ÑÁêÜ
   - ÂáÜÁ°Æ‰º∞ÁÆóÊ∂àÊÅØÂ§ßÂ∞èÔºåÂáèÂ∞ëÂèëÈÄÅÂ§±Ë¥•Áéá

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`Ôºå`config.yaml`


### 2025/11/25 - v3.4.0

**üéâ Êñ∞Â¢û Slack Êé®ÈÄÅÊîØÊåÅ**

1. **Âõ¢ÈòüÂçè‰ΩúÊé®ÈÄÅÊ∏†ÈÅì**
   - ÊîØÊåÅ Slack Incoming WebhooksÔºàÂÖ®ÁêÉÊµÅË°åÁöÑÂõ¢ÈòüÂçè‰ΩúÂ∑•ÂÖ∑Ôºâ
   - Ê∂àÊÅØÈõÜ‰∏≠ÁÆ°ÁêÜÔºåÈÄÇÂêàÂõ¢ÈòüÂÖ±‰∫´ÁÉ≠ÁÇπËµÑËÆØ
   - ÊîØÊåÅ mrkdwn Ê†ºÂºèÔºàÁ≤ó‰Ωì„ÄÅÈìæÊé•Á≠âÔºâ

2. **Â§öÁßçÈÉ®ÁΩ≤ÊñπÂºè**
   - GitHub ActionsÔºöÈÖçÁΩÆ `SLACK_WEBHOOK_URL` Secret
   - DockerÔºöÁéØÂ¢ÉÂèòÈáè `SLACK_WEBHOOK_URL`
   - Êú¨Âú∞ËøêË°åÔºö`config/config.yaml` ÈÖçÁΩÆÊñá‰ª∂


&gt; üìñ **ËØ¶ÁªÜÈÖçÁΩÆÊïôÁ®ã**Ôºö[Âø´ÈÄüÂºÄÂßã - Slack Êé®ÈÄÅ](#-Âø´ÈÄüÂºÄÂßã)

- ‰ºòÂåñ setup-windows.bat Âíå setup-windows-en.bat ‰∏ÄÈîÆÂÆâË£Ö MCP ÁöÑ‰ΩìÈ™å

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`„ÄÅ`config/config.yaml`„ÄÅ`.github/workflows/crawler.yml`


### 2025/11/24 - v3.3.0

**üéâ Êñ∞Â¢û B

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[lintsinghua/DeepAudit]]></title>
            <link>https://github.com/lintsinghua/DeepAudit</link>
            <guid>https://github.com/lintsinghua/DeepAudit</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:10 GMT</pubDate>
            <description><![CDATA[DeepAuditÔºö‰∫∫‰∫∫Êã•ÊúâÁöÑ AI ÈªëÂÆ¢ÊàòÈòüÔºåËÆ©ÊºèÊ¥ûÊåñÊéòËß¶ÊâãÂèØÂèä„ÄÇÂõΩÂÜÖÈ¶ñ‰∏™ÂºÄÊ∫êÁöÑ‰ª£Á†ÅÊºèÊ¥ûÊåñÊéòÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü„ÄÇÂ∞èÁôΩ‰∏ÄÈîÆÈÉ®ÁΩ≤ËøêË°åÔºåËá™‰∏ªÂçè‰ΩúÂÆ°ËÆ° + Ëá™Âä®ÂåñÊ≤ôÁÆ± PoC È™åËØÅ„ÄÇÊîØÊåÅ Ollama ÁßÅÊúâÈÉ®ÁΩ≤ Ôºå‰∏ÄÈîÆÁîüÊàêÊä•Âëä„ÄÇÊîØÊåÅ‰∏≠ËΩ¨Á´ô„ÄÇ‚ÄãËÆ©ÂÆâÂÖ®‰∏çÂÜçÊòÇË¥µÔºåËÆ©ÂÆ°ËÆ°‰∏çÂÜçÂ§çÊùÇ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/lintsinghua/DeepAudit">lintsinghua/DeepAudit</a></h1>
            <p>DeepAuditÔºö‰∫∫‰∫∫Êã•ÊúâÁöÑ AI ÈªëÂÆ¢ÊàòÈòüÔºåËÆ©ÊºèÊ¥ûÊåñÊéòËß¶ÊâãÂèØÂèä„ÄÇÂõΩÂÜÖÈ¶ñ‰∏™ÂºÄÊ∫êÁöÑ‰ª£Á†ÅÊºèÊ¥ûÊåñÊéòÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªü„ÄÇÂ∞èÁôΩ‰∏ÄÈîÆÈÉ®ÁΩ≤ËøêË°åÔºåËá™‰∏ªÂçè‰ΩúÂÆ°ËÆ° + Ëá™Âä®ÂåñÊ≤ôÁÆ± PoC È™åËØÅ„ÄÇÊîØÊåÅ Ollama ÁßÅÊúâÈÉ®ÁΩ≤ Ôºå‰∏ÄÈîÆÁîüÊàêÊä•Âëä„ÄÇÊîØÊåÅ‰∏≠ËΩ¨Á´ô„ÄÇ‚ÄãËÆ©ÂÆâÂÖ®‰∏çÂÜçÊòÇË¥µÔºåËÆ©ÂÆ°ËÆ°‰∏çÂÜçÂ§çÊùÇ„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 4,768</p>
            <p>Forks: 566</p>
            <p>Stars today: 32 stars today</p>
            <h2>README</h2><pre># XCodeReviewer - ÊÇ®ÁöÑÊô∫ËÉΩ‰ª£Á†ÅÂÆ°ËÆ°‰ºô‰º¥ üöÄ

&lt;div style=&quot;width: 100%; max-width: 600px; margin: 0 auto;&quot;&gt;
  &lt;img src=&quot;public/images/logo.png&quot; alt=&quot;XCodeReviewer Logo&quot; style=&quot;width: 100%; height: auto; display: block; margin: 0 auto;&quot;&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
    &lt;a href=&quot;README.md&quot;&gt;‰∏≠Êñá&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;README_EN.md&quot;&gt;English&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[![Version](https://img.shields.io/badge/version-1.2.0-blue.svg)](https://github.com/lintsinghua/XCodeReviewer/releases)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![React](https://img.shields.io/badge/React-18-61dafb.svg)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.7-3178c6.svg)](https://www.typescriptlang.org/)
[![Vite](https://img.shields.io/badge/Vite-5.1-646cff.svg)](https://vitejs.dev/)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/lintsinghua/XCodeReviewer)

[![Stars](https://img.shields.io/github/stars/lintsinghua/XCodeReviewer?style=social)](https://github.com/lintsinghua/XCodeReviewer/stargazers)
[![Forks](https://img.shields.io/github/forks/lintsinghua/XCodeReviewer?style=social)](https://github.com/lintsinghua/XCodeReviewer/network/members)

[![Sponsor](https://img.shields.io/badge/Sponsor-ËµûÂä©-blueviolet)](https://github.com/lintsinghua/lintsinghua.github.io/issues/1)
&lt;/div&gt;

&lt;div style=&quot;width: 100%; max-width: 600px; margin: 0 auto;&quot;&gt;
  &lt;a href=&quot;https://github.com/lintsinghua/XCodeReviewer&quot;&gt;
    &lt;img src=&quot;public/star-me-cn.svg&quot; alt=&quot;Star this project&quot; style=&quot;width: 100%; height: auto; display: block; margin: 0 auto;&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

**XCodeReviewer** ÊòØ‰∏Ä‰∏™Áî±Â§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÔºàLLMÔºâÈ©±Âä®ÁöÑÁé∞‰ª£Âåñ‰ª£Á†ÅÂÆ°ËÆ°Âπ≥Âè∞ÔºåÊó®Âú®‰∏∫ÂºÄÂèëËÄÖÊèê‰æõÊô∫ËÉΩ„ÄÅÂÖ®Èù¢‰∏îÊûÅÂÖ∑Ê∑±Â∫¶ÁöÑ‰ª£Á†ÅË¥®ÈáèÂàÜÊûêÂíåÂÆ°Êü•ÊúçÂä°„ÄÇ

#### üåê Âú®Á∫øÊºîÁ§∫

Êó†ÈúÄÈÉ®ÁΩ≤ÔºåÁõ¥Êé•ËÆøÈóÆÂú®Á∫øÊºîÁ§∫ÔºàÊï∞ÊçÆÂ≠òÂÇ®Âú®ÊµèËßàÂô®Êú¨Âú∞ÔºåÊîØÊåÅÊâÄÊúâÊ†∏ÂøÉÂäüËÉΩÔºâÔºö

**[https://xcodereviewer-preview.vercel.app](https://xcodereviewer-preview.vercel.app)**

## üåü ‰∏∫‰ªÄ‰πàÈÄâÊã© XCodeReviewerÔºü

Âú®Âø´ËäÇÂ•èÁöÑËΩØ‰ª∂ÂºÄÂèë‰∏≠Ôºå‰øùËØÅ‰ª£Á†ÅË¥®ÈáèËá≥ÂÖ≥ÈáçË¶Å„ÄÇ‰º†Áªü‰ª£Á†ÅÂÆ°ËÆ°Â∑•ÂÖ∑ËßÑÂàôÊ≠ªÊùø„ÄÅÊïàÁéá‰Ωé‰∏ãÔºåËÄå‰∫∫Â∑•ÂÆ°ËÆ°ÂàôËÄóÊó∂ËÄóÂäõ„ÄÇXCodeReviewer ÂÄüÂä© LLM ÁöÑÂº∫Â§ßËÉΩÂäõÔºåÂΩªÂ∫ïÊîπÂèò‰∫Ü‰ª£Á†ÅÂÆ°Êü•ÁöÑÊñπÂºèÔºö

![Á≥ªÁªüÊû∂ÊûÑÂõæ](public/diagram.svg)

&lt;div div align=&quot;center&quot;&gt;
  &lt;em&gt;
    XCodeReviewerÁ≥ªÁªüÊû∂ÊûÑÂõæ
  &lt;/em&gt;
&lt;/div&gt;

---

- **AI È©±Âä®ÁöÑÊ∑±Â∫¶ÂàÜÊûê**ÔºöË∂ÖË∂ä‰º†ÁªüÈùôÊÄÅÂàÜÊûêÔºåÁêÜËß£‰ª£Á†ÅÊÑèÂõæÔºåÂèëÁé∞Ê∑±Â±ÇÈÄªËæëÈóÆÈ¢ò„ÄÇ
- **Â§öÁª¥Â∫¶„ÄÅÂÖ®Êñπ‰ΩçËØÑ‰º∞**Ôºö‰ªé**ÂÆâÂÖ®ÊÄß**„ÄÅ**ÊÄßËÉΩ**„ÄÅ**ÂèØÁª¥Êä§ÊÄß**Âà∞**‰ª£Á†ÅÈ£éÊ†º**ÔºåÊèê‰æõ 360 Â∫¶Êó†Ê≠ªËßíÁöÑË¥®ÈáèËØÑ‰º∞„ÄÇ
- **Ê∏ÖÊô∞„ÄÅÂèØË°åÁöÑ‰øÆÂ§çÂª∫ËÆÆ**ÔºöÁã¨Âàõ **What-Why-How** Ê®°ÂºèÔºå‰∏ç‰ªÖÂëäËØâÊÇ®&quot;ÊòØ‰ªÄ‰πà&quot;ÈóÆÈ¢òÔºåËøòËß£Èáä&quot;‰∏∫‰ªÄ‰πà&quot;ÔºåÂπ∂Êèê‰æõ&quot;Â¶Ç‰Ωï‰øÆÂ§ç&quot;ÁöÑÂÖ∑‰Ωì‰ª£Á†ÅÁ§∫‰æã„ÄÇ
- **Â§öÂπ≥Âè∞LLM/Êú¨Âú∞LLMÊîØÊåÅ**: Â∑≤ÂÆûÁé∞ 10+ ‰∏ªÊµÅÂπ≥Âè∞APIË∞ÉÁî®ÂäüËÉΩÔºàGemini„ÄÅOpenAI„ÄÅClaude„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅDeepSeek„ÄÅÊô∫Ë∞±AI„ÄÅKimi„ÄÅÊñáÂøÉ‰∏ÄË®Ä„ÄÅMiniMax„ÄÅË±ÜÂåÖ„ÄÅOllamaÊú¨Âú∞Â§ßÊ®°ÂûãÔºâÔºåÊîØÊåÅÁî®Êà∑Ëá™Áî±ÈÖçÁΩÆÂíåÂàáÊç¢„ÄÇ
- **ÂèØËßÜÂåñËøêË°åÊó∂ÈÖçÁΩÆ**ÔºöÊó†ÈúÄÈáçÊñ∞ÊûÑÂª∫ÈïúÂÉèÔºåÁõ¥Êé•Âú®ÊµèËßàÂô®‰∏≠ÈÖçÁΩÆÊâÄÊúâ LLM ÂèÇÊï∞Âíå API KeysÔºåÊîØÊåÅ API ‰∏≠ËΩ¨Á´ôÔºåÈÖçÁΩÆ‰øùÂ≠òÂú®Êú¨Âú∞ÊµèËßàÂô®ÔºåÂÆâÂÖ®‰æøÊç∑„ÄÇ
- **Áé∞‰ª£Âåñ„ÄÅÈ´òÈ¢úÂÄºÁöÑÁî®Êà∑ÁïåÈù¢**ÔºöÂü∫‰∫é React + TypeScript ÊûÑÂª∫ÔºåÊèê‰æõÊµÅÁïÖ„ÄÅÁõ¥ËßÇÁöÑÊìç‰Ωú‰ΩìÈ™å„ÄÇ

## üé¨ È°πÁõÆÊºîÁ§∫

### ‰∏ªË¶ÅÂäüËÉΩÁïåÈù¢

#### Êô∫ËÉΩ‰ª™Ë°®Áõò
![Êô∫ËÉΩ‰ª™Ë°®Áõò](public/images/example1.png)
*ÂÆûÊó∂Â±ïÁ§∫È°πÁõÆÁªüËÆ°„ÄÅË¥®ÈáèË∂ãÂäøÂíåÁ≥ªÁªüÊÄßËÉΩÔºåÊèê‰æõÂÖ®Èù¢ÁöÑ‰ª£Á†ÅÂÆ°ËÆ°Ê¶ÇËßà*

#### Âç≥Êó∂ÂàÜÊûê
![Âç≥Êó∂ÂàÜÊûê](public/images/example2.png)
*ÊîØÊåÅ‰ª£Á†ÅÁâáÊÆµÂø´ÈÄüÂàÜÊûêÔºåÊèê‰æõËØ¶ÁªÜÁöÑ What-Why-How Ëß£ÈáäÂíå‰øÆÂ§çÂª∫ËÆÆ*

#### È°πÁõÆÁÆ°ÁêÜ
![È°πÁõÆÁÆ°ÁêÜ](public/images/example3.png)
*ÈõÜÊàê GitHub/GitLab ‰ªìÂ∫ìÔºåÊîØÊåÅÂ§öËØ≠Ë®ÄÈ°πÁõÆÂÆ°ËÆ°ÂíåÊâπÈáè‰ª£Á†ÅÂàÜÊûê*

## üöÄ Âø´ÈÄüÂºÄÂßã

### ‚òÅÔ∏è Vercel ‰∏ÄÈîÆÈÉ®ÁΩ≤

ÈÄÇÂêàÂø´ÈÄüÈÉ®ÁΩ≤Âíå‰ΩìÈ™åÔºåÊó†ÈúÄÊúçÂä°Âô®ÔºåÂÖ®ÁêÉ CDN Âä†ÈÄü„ÄÇ

#### ÊñπÂºè‰∏ÄÔºö‰∏ÄÈîÆÈÉ®ÁΩ≤ÊåâÈíÆÔºàÊé®ËçêÔºâ‚≠ê

ÁÇπÂáª‰∏ãÊñπÊåâÈíÆÁõ¥Êé•ÈÉ®ÁΩ≤Âà∞ VercelÔºö

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/lintsinghua/XCodeReviewer)

#### ÊñπÂºè‰∫åÔºöÈÄöËøá Vercel CLI ÈÉ®ÁΩ≤

```bash
# 1. ÂÆâË£Ö Vercel CLI
npm i -g vercel

# 2. ÁôªÂΩï Vercel
vercel login

# 3. ÈÉ®ÁΩ≤È°πÁõÆ
vercel

# 4. ÈÉ®ÁΩ≤Âà∞Áîü‰∫ßÁéØÂ¢É
vercel --prod
```

#### ÊñπÂºè‰∏âÔºöÈÄöËøá Vercel Dashboard ÈÉ®ÁΩ≤

1. ËÆøÈóÆ [Vercel Dashboard](https://vercel.com/dashboard)
2. ÁÇπÂáª &quot;Add New...&quot; ‚Üí &quot;Project&quot;
3. ÂØºÂÖ•‰Ω†ÁöÑ GitHub ‰ªìÂ∫ì
4. Vercel ‰ºöËá™Âä®Ê£ÄÊµã Vite È°πÁõÆÈÖçÁΩÆ
5. ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáèÔºàËá≥Â∞ëÈúÄË¶ÅÔºâÔºö
   ```
   VITE_LLM_PROVIDER=your_llm_provider
   VITE_LLM_API_KEY=your_api_key_here
   VITE_USE_LOCAL_DB=true
   ```
6. ÁÇπÂáª &quot;Deploy&quot;

**‚ú® Vercel ÈÉ®ÁΩ≤‰ºòÂäø**Ôºö
- ‚úÖ ÂÖ®ÁêÉ CDN Âä†ÈÄüÔºåËÆøÈóÆÈÄüÂ∫¶Âø´
- ‚úÖ Ëá™Âä® HTTPS ÂíåÂüüÂêçÈÖçÁΩÆ
- ‚úÖ Èõ∂ÈÖçÁΩÆÔºåÂºÄÁÆ±Âç≥Áî®
- ‚úÖ ÊîØÊåÅËá™ÂÆö‰πâÂüüÂêç
- ‚úÖ Ëá™Âä®ÈÉ®ÁΩ≤ÔºàGit Êé®ÈÄÅÂêéËá™Âä®Êõ¥Êñ∞Ôºâ

**‚ú® Êï∞ÊçÆÂ∫ìÊ®°Âºè**Ôºö
- ÈªòËÆ§Ëá™Âä®‰ΩøÁî®**Êú¨Âú∞Êï∞ÊçÆÂ∫ìÊ®°Âºè**ÔºàIndexedDBÔºâÔºåÊï∞ÊçÆÂ≠òÂÇ®Âú®ÊµèËßàÂô®‰∏≠
- Êó†ÈúÄÈÖçÁΩÆ‰ªª‰ΩïÊï∞ÊçÆÂ∫ìÔºåÂºÄÁÆ±Âç≥Áî®
- Â¶ÇÈúÄ‰ΩøÁî® Supabase ‰∫ëÁ´ØÊï∞ÊçÆÂ∫ìÔºåÂèØÂú®ÁéØÂ¢ÉÂèòÈáè‰∏≠ÈÖçÁΩÆ

**‚ö†Ô∏è Ê≥®ÊÑè‰∫ãÈ°π**Ôºö
- Vercel ‰∏ªË¶ÅÁî®‰∫éÂâçÁ´ØÈÉ®ÁΩ≤ÔºåÂêéÁ´Ø API ÈúÄÂçïÁã¨ÈÉ®ÁΩ≤
- ÈÉ®ÁΩ≤ÂêéÂèØÂú® `/admin` È°µÈù¢ËøõË°åËøêË°åÊó∂ÈÖçÁΩÆ

---

### üê≥ Docker ÈÉ®ÁΩ≤ÔºàÊé®ËçêÁîü‰∫ßÁéØÂ¢ÉÔºâ

#### ÊñπÂºè‰∏ÄÔºö‰ΩøÁî®ÂèëÂ∏ÉÁöÑÈïúÂÉèÔºàÊúÄÁÆÄÂçïÔºâ‚≠ê

Áõ¥Êé•‰ΩøÁî®ÊúÄÊñ∞ÂèëÂ∏ÉÁöÑ Docker ÈïúÂÉèÔºåÊîØÊåÅ x86„ÄÅARM64ÔºàMac MÁ≥ªÂàóÔºâ„ÄÅARMv7 Êû∂ÊûÑÔºö

```bash
# 1. ÊãâÂèñÊúÄÊñ∞ÁâàÊú¨ÈïúÂÉè
docker pull ghcr.io/lintsinghua/xcodereviewer:latest

# 2. ËøêË°åÂÆπÂô®
docker run -d \
  -p 8888:80 \
  --name xcodereviewer \
  --restart unless-stopped \
  ghcr.io/lintsinghua/xcodereviewer:latest

# 3. ËÆøÈóÆÂ∫îÁî®
# ÊµèËßàÂô®ÊâìÂºÄ http://localhost:8888
```

**‰ΩøÁî®ÁâπÂÆöÁâàÊú¨**Ôºö
```bash
# ÊãâÂèñÊåáÂÆöÁâàÊú¨ÔºàÂ¶Ç v1.1.0Ôºâ
docker pull ghcr.io/lintsinghua/xcodereviewer:v1.1.0

# ËøêË°å
docker run -d -p 8888:80 --name xcodereviewer ghcr.io/lintsinghua/xcodereviewer:v1.1.0
```

#### ÊñπÂºè‰∫åÔºöÊú¨Âú∞ÊûÑÂª∫ÔºàÂèØÈÄâÔºâ

Â¶ÇÊûúÈúÄË¶ÅËá™ÂÆö‰πâÊûÑÂª∫Ôºö

```bash
# 1. ÂÖãÈöÜÈ°πÁõÆ
git clone https://github.com/lintsinghua/XCodeReviewer.git
cd XCodeReviewer

# 2. ‰ΩøÁî® Docker Compose ÊûÑÂª∫Âπ∂ÂêØÂä®
docker-compose up -d

# 3. ËÆøÈóÆÂ∫îÁî®
# ÊµèËßàÂô®ÊâìÂºÄ http://localhost:8888
```

**‚ú® ËøêË°åÊó∂ÈÖçÁΩÆÔºàÊé®ËçêÔºâ**

Docker ÈÉ®ÁΩ≤ÂêéÔºåÊÇ®ÂèØ‰ª•Áõ¥Êé•Âú®ÊµèËßàÂô®‰∏≠ÈÖçÁΩÆÊâÄÊúâËÆæÁΩÆÔºåÊó†ÈúÄÈáçÊñ∞ÊûÑÂª∫ÈïúÂÉèÔºö

1. ËÆøÈóÆ `http://localhost:8888/admin`ÔºàÁ≥ªÁªüÁÆ°ÁêÜÈ°µÈù¢Ôºâ
2. Âú®&quot;Á≥ªÁªüÈÖçÁΩÆ&quot;Ê†áÁ≠æÈ°µ‰∏≠ÈÖçÁΩÆ LLM API Keys ÂíåÂÖ∂‰ªñÂèÇÊï∞
3. ÁÇπÂáª‰øùÂ≠òÂπ∂Âà∑Êñ∞È°µÈù¢Âç≥ÂèØ‰ΩøÁî®

&gt; üìñ **ËØ¶ÁªÜÈÖçÁΩÆËØ¥ÊòéËØ∑ÂèÇËÄÉ**Ôºö[Á≥ªÁªüÈÖçÁΩÆ‰ΩøÁî®ÊåáÂçó](#Á≥ªÁªüÈÖçÁΩÆÈ¶ñÊ¨°‰ΩøÁî®ÂøÖÁúã)

### üíª Êú¨Âú∞ÂºÄÂèëÈÉ®ÁΩ≤

ÈÄÇÂêàÈúÄË¶ÅÂºÄÂèëÊàñËá™ÂÆö‰πâ‰øÆÊîπÁöÑÂú∫ÊôØ„ÄÇ

#### ÁéØÂ¢ÉË¶ÅÊ±Ç
- Node.js 18+
- pnpm 8+ (Êé®Ëçê) Êàñ npm/yarn

#### Âø´ÈÄüÂêØÂä®

```bash
# 1. ÂÖãÈöÜÈ°πÁõÆ
git clone https://github.com/lintsinghua/XCodeReviewer.git
cd XCodeReviewer

# 2. ÂÆâË£Ö‰æùËµñ
pnpm install  # Êàñ npm install / yarn install

# 3. ÈÖçÁΩÆÁéØÂ¢ÉÂèòÈáè
cp .env.example .env
# ÁºñËæë .env Êñá‰ª∂ÔºåÈÖçÁΩÆÂøÖË¶ÅÂèÇÊï∞ÔºàËßÅ‰∏ãÊñπÈÖçÁΩÆËØ¥ÊòéÔºâ

# 4. ÂêØÂä®ÂºÄÂèëÊúçÂä°Âô®
pnpm dev

# 5. ËÆøÈóÆÂ∫îÁî®
# ÊµèËßàÂô®ÊâìÂºÄ http://localhost:5173
```

#### Ê†∏ÂøÉÈÖçÁΩÆËØ¥Êòé

ÁºñËæë `.env` Êñá‰ª∂ÔºåÈÖçÁΩÆ‰ª•‰∏ãÂøÖÈúÄÂèÇÊï∞Ôºö

```env
# ========== ÂøÖÈúÄÈÖçÁΩÆ ==========
# LLM Êèê‰æõÂïÜÈÄâÊã© (gemini|openai|claude|qwen|deepseek|zhipu|moonshot|baidu|minimax|doubao|ollama)
VITE_LLM_PROVIDER=gemini
# ÂØπÂ∫îÁöÑ API Key
VITE_LLM_API_KEY=your_api_key_here

# ========== Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºà‰∏âÈÄâ‰∏ÄÔºâ==========
# ÊñπÂºè1ÔºöÊú¨Âú∞Êï∞ÊçÆÂ∫ìÔºàÊé®ËçêÔºåÂºÄÁÆ±Âç≥Áî®Ôºâ
VITE_USE_LOCAL_DB=true

# ÊñπÂºè2ÔºöSupabase ‰∫ëÁ´ØÊï∞ÊçÆÂ∫ìÔºàÊîØÊåÅÂ§öËÆæÂ§áÂêåÊ≠•Ôºâ
# VITE_SUPABASE_URL=https://your-project.supabase.co
# VITE_SUPABASE_ANON_KEY=your_anon_key

# ÊñπÂºè3ÔºöÊºîÁ§∫Ê®°ÂºèÔºà‰∏çÈÖçÁΩÆ‰ªª‰ΩïÊï∞ÊçÆÂ∫ìÔºåÊï∞ÊçÆ‰∏çÊåÅ‰πÖÂåñÔºâ

# ========== ÂèØÈÄâÈÖçÁΩÆ ==========
# GitHub ÈõÜÊàêÔºàÁî®‰∫é‰ªìÂ∫ìÂàÜÊûêÔºâ
# VITE_GITHUB_TOKEN=your_github_token

# ËæìÂá∫ËØ≠Ë®ÄÔºàzh-CN: ‰∏≠Êñá | en-US: Ëã±ÊñáÔºâ
VITE_OUTPUT_LANGUAGE=zh-CN

# ÂàÜÊûêÂèÇÊï∞Ë∞É‰ºò
VITE_MAX_ANALYZE_FILES=40    # ÂçïÊ¨°ÊúÄÂ§ßÂàÜÊûêÊñá‰ª∂Êï∞
VITE_LLM_CONCURRENCY=2       # Âπ∂ÂèëËØ∑Ê±ÇÊï∞
VITE_LLM_GAP_MS=500          # ËØ∑Ê±ÇÈó¥Èöî(ms)
```

#### È´òÁ∫ßÈÖçÁΩÆ

ÈÅáÂà∞Ë∂ÖÊó∂ÊàñËøûÊé•ÈóÆÈ¢òÊó∂ÔºåÂèØË∞ÉÊï¥‰ª•‰∏ãÂèÇÊï∞Ôºö

```env
VITE_LLM_TIMEOUT=300000                      # Â¢ûÂä†Ë∂ÖÊó∂Êó∂Èó¥
VITE_LLM_BASE_URL=https://your-proxy.com/v1 # ‰ΩøÁî®‰ª£ÁêÜÊàñ‰∏≠ËΩ¨ÊúçÂä°
VITE_LLM_CONCURRENCY=1                       # Èôç‰ΩéÂπ∂ÂèëÊï∞
VITE_LLM_GAP_MS=1000                         # Â¢ûÂä†ËØ∑Ê±ÇÈó¥Èöî
```

**Ëá™ÂÆö‰πâËØ∑Ê±ÇÂ§¥Á§∫‰æã**ÔºàÈíàÂØπÁâπÊÆä‰∏≠ËΩ¨Á´ôÔºâÔºö

```env
# JSON Ê†ºÂºèÂ≠óÁ¨¶‰∏≤
VITE_LLM_CUSTOM_HEADERS=&#039;{&quot;X-API-Version&quot;:&quot;v1&quot;,&quot;X-Custom-Auth&quot;:&quot;token123&quot;}&#039;
```

### Â∏∏ËßÅÈóÆÈ¢ò

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Â¶Ç‰ΩïÂø´ÈÄüÂàáÊç¢ LLM Âπ≥Âè∞Ôºü&lt;/b&gt;&lt;/summary&gt;

**ÊñπÂºè‰∏ÄÔºöÊµèËßàÂô®ÈÖçÁΩÆÔºàÊé®ËçêÔºâ**

1. ËÆøÈóÆ `http://localhost:8888/admin` Á≥ªÁªüÁÆ°ÁêÜÈ°µÈù¢
2. Âú®&quot;Á≥ªÁªüÈÖçÁΩÆ&quot;Ê†áÁ≠æÈ°µÈÄâÊã©‰∏çÂêåÁöÑ LLM Êèê‰æõÂïÜ
3. Â°´ÂÖ•ÂØπÂ∫îÁöÑ API Key
4. ‰øùÂ≠òÂπ∂Âà∑Êñ∞È°µÈù¢

**ÊñπÂºè‰∫åÔºöÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ**

‰øÆÊîπ `.env` ‰∏≠ÁöÑÈÖçÁΩÆÔºö

```env
# ÂàáÊç¢Âà∞ OpenAI
VITE_LLM_PROVIDER=openai
VITE_OPENAI_API_KEY=your_key

# ÂàáÊç¢Âà∞ÈÄö‰πâÂçÉÈóÆ
VITE_LLM_PROVIDER=qwen
VITE_QWEN_API_KEY=your_key
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;ÈÅáÂà∞ËØ∑Ê±ÇË∂ÖÊó∂ÊÄé‰πàÂäûÔºü&lt;/b&gt;&lt;/summary&gt;

1. Â¢ûÂä†Ë∂ÖÊó∂Êó∂Èó¥Ôºö`VITE_LLM_TIMEOUT=300000`
2. ‰ΩøÁî®‰ª£ÁêÜÔºöÈÖçÁΩÆ `VITE_LLM_BASE_URL`
3. ÂàáÊç¢Âà∞ÂõΩÂÜÖÂπ≥Âè∞ÔºöÈÄö‰πâÂçÉÈóÆ„ÄÅDeepSeek„ÄÅÊô∫Ë∞±AI Á≠â
4. Èôç‰ΩéÂπ∂ÂèëÔºö`VITE_LLM_CONCURRENCY=1`
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Êï∞ÊçÆÂ∫ìÊ®°ÂºèÂ¶Ç‰ΩïÈÄâÊã©Ôºü&lt;/b&gt;&lt;/summary&gt;

**Êú¨Âú∞Ê®°ÂºèÔºàÊé®ËçêÔºâ**ÔºöÊï∞ÊçÆÂ≠òÂÇ®Âú®ÊµèËßàÂô® IndexedDBÔºåÂºÄÁÆ±Âç≥Áî®ÔºåÈöêÁßÅÂÆâÂÖ®
```env
VITE_USE_LOCAL_DB=true
```

**‰∫ëÁ´ØÊ®°Âºè**ÔºöÊï∞ÊçÆÂ≠òÂÇ®Âú® SupabaseÔºåÊîØÊåÅÂ§öËÆæÂ§áÂêåÊ≠•
```env
VITE_SUPABASE_URL=https://your-project.supabase.co
VITE_SUPABASE_ANON_KEY=your_key
```

**ÊºîÁ§∫Ê®°Âºè**Ôºö‰∏çÈÖçÁΩÆ‰ªª‰ΩïÊï∞ÊçÆÂ∫ìÔºåÊï∞ÊçÆ‰∏çÊåÅ‰πÖÂåñ
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Â¶Ç‰Ωï‰ΩøÁî® Ollama Êú¨Âú∞Â§ßÊ®°ÂûãÔºü&lt;/b&gt;&lt;/summary&gt;

```bash
# 1. ÂÆâË£Ö Ollama
curl -fsSL https://ollama.com/install.sh | sh  # macOS/Linux
# Windows: ËÆøÈóÆ https://ollama.com/download

# 2. ÊãâÂèñÊ®°Âûã
ollama pull llama3  # Êàñ codellama„ÄÅqwen2.5„ÄÅdeepseek-coder

# 3. ÈÖçÁΩÆ XCodeReviewer
# Âú® .env ‰∏≠ËÆæÁΩÆÔºö
VITE_LLM_PROVIDER=ollama
VITE_LLM_MODEL=llama3
VITE_LLM_BASE_URL=http://localhost:11434/v1
```

Êé®ËçêÊ®°ÂûãÔºö`llama3`ÔºàÁªºÂêàÔºâ„ÄÅ`codellama`Ôºà‰ª£Á†Å‰∏ìÁî®Ôºâ„ÄÅ`qwen2.5`Ôºà‰∏≠ÊñáÔºâ
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;ÁôæÂ∫¶ÊñáÂøÉ‰∏ÄË®ÄÁöÑ API Key Ê†ºÂºèÔºü&lt;/b&gt;&lt;/summary&gt;

ÁôæÂ∫¶ÈúÄË¶ÅÂêåÊó∂Êèê‰æõ API Key Âíå Secret KeyÔºåÁî®ÂÜíÂè∑ÂàÜÈöîÔºö
```env
VITE_LLM_PROVIDER=baidu
VITE_BAIDU_API_KEY=your_api_key:your_secret_key
```
Ëé∑ÂèñÂú∞ÂùÄÔºöhttps://console.bce.baidu.com/qianfan/
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Â¶Ç‰Ωï‰ΩøÁî® API ‰∏≠ËΩ¨Á´ôÔºü&lt;/b&gt;&lt;/summary&gt;

ËÆ∏Â§öÁî®Êà∑‰ΩøÁî® API ‰∏≠ËΩ¨ÊúçÂä°Êù•ËÆøÈóÆ LLMÔºàÊõ¥Á®≥ÂÆö„ÄÅÊõ¥‰æøÂÆúÔºâ„ÄÇÈÖçÁΩÆÊñπÊ≥ïÔºö

1. ËÆøÈóÆÁ≥ªÁªüÁÆ°ÁêÜÈ°µÈù¢Ôºà`/admin`Ôºâ
2. Âú®&quot;Á≥ªÁªüÈÖçÁΩÆ&quot;Ê†áÁ≠æÈ°µ‰∏≠Ôºö
   - ÈÄâÊã© LLM Êèê‰æõÂïÜÔºàÂ¶Ç OpenAIÔºâ
   - **API Âü∫Á°Ä URL**: Â°´ÂÖ•‰∏≠ËΩ¨Á´ôÂú∞ÂùÄÔºàÂ¶Ç `https://your-proxy.com/v1`Ôºâ
   - **API Key**: Â°´ÂÖ•‰∏≠ËΩ¨Á´ôÊèê‰æõÁöÑÂØÜÈí•ÔºàËÄåÈùûÂÆòÊñπÂØÜÈí•Ôºâ
3. ‰øùÂ≠òÂπ∂Âà∑Êñ∞È°µÈù¢

**Ê≥®ÊÑè**Ôºö
- ‰∏≠ËΩ¨Á´ô URL ÈÄöÂ∏∏‰ª• `/v1` ÁªìÂ∞æÔºàOpenAI ÂÖºÂÆπÊ†ºÂºèÔºâ
- ‰ΩøÁî®‰∏≠ËΩ¨Á´ôÁöÑ API KeyÔºå‰∏çÊòØÂÆòÊñπÁöÑ
- Á°ÆËÆ§‰∏≠ËΩ¨Á´ôÊîØÊåÅ‰Ω†ÈÄâÊã©ÁöÑ AI Ê®°Âûã
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Â¶Ç‰ΩïÂ§á‰ªΩÊú¨Âú∞Êï∞ÊçÆÂ∫ìÔºü&lt;/b&gt;&lt;/summary&gt;

Êú¨Âú∞Êï∞ÊçÆÂ≠òÂÇ®Âú®ÊµèËßàÂô® IndexedDB ‰∏≠Ôºö
- Âú®Â∫îÁî®ÁöÑ&quot;Á≥ªÁªüÁÆ°ÁêÜ&quot;È°µÈù¢ÂØºÂá∫‰∏∫ JSON Êñá‰ª∂
- ÈÄöËøáÂØºÂÖ• JSON Êñá‰ª∂ÊÅ¢Â§çÊï∞ÊçÆ
- Ê≥®ÊÑèÔºöÊ∏ÖÈô§ÊµèËßàÂô®Êï∞ÊçÆ‰ºöÂà†Èô§ÊâÄÊúâÊú¨Âú∞Êï∞ÊçÆ
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Â¶Ç‰ΩïËÆæÁΩÆËæìÂá∫ËØ≠Ë®ÄÔºü&lt;/b&gt;&lt;/summary&gt;

```env
VITE_OUTPUT_LANGUAGE=zh-CN  # ‰∏≠ÊñáÔºàÈªòËÆ§Ôºâ
VITE_OUTPUT_LANGUAGE=en-US  # Ëã±Êñá
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Â¶Ç‰ΩïÈÖçÁΩÆÂ§ö‰∏™Âπ≥Âè∞Âπ∂Âø´ÈÄüÂàáÊç¢Ôºü&lt;/b&gt;&lt;/summary&gt;

Âú® `.env` ‰∏≠È¢ÑÈÖçÁΩÆÊâÄÊúâÂπ≥Âè∞ÁöÑ KeyÔºåÂàáÊç¢Êó∂Âè™ÈúÄ‰øÆÊîπ `VITE_LLM_PROVIDER`Ôºö
```env
VITE_LLM_PROVIDER=gemini  # ÂΩìÂâç‰ΩøÁî®ÁöÑÂπ≥Âè∞

# È¢ÑÈÖçÁΩÆÊâÄÊúâÂπ≥Âè∞
VITE_GEMINI_API_KEY=key1
VITE_OPENAI_API_KEY=key2
VITE_QWEN_API_KEY=key3
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;Â¶Ç‰ΩïÊü•ÁúãÁ≥ªÁªüÊó•ÂøóÂíåË∞ÉËØï‰ø°ÊÅØÔºü&lt;/b&gt;&lt;/summary&gt;

XCodeReviewer ÂÜÖÁΩÆ‰∫ÜÊó•ÂøóÁ≥ªÁªüÔºåËÆ∞ÂΩïÊ†∏ÂøÉÊìç‰ΩúÂíåÈîôËØØÔºö

**Êü•ÁúãÊó•Âøó**Ôºö
- ÂØºËà™Ê†è -&gt; Á≥ªÁªüÊó•Âøó
- ÊàñËÆøÈóÆÔºö`http://localhost:5173/logs` (ÂºÄÂèë) / `http://localhost:8888/logs` (Áîü‰∫ß)

**ËÆ∞ÂΩïÂÜÖÂÆπ**Ôºö
- ‚úÖ Áî®Êà∑Ê†∏ÂøÉÊìç‰ΩúÔºàÂàõÂª∫È°πÁõÆ„ÄÅÂÆ°ËÆ°‰ªªÂä°„ÄÅ‰øÆÊîπÈÖçÁΩÆÁ≠âÔºâ
- ‚úÖ API ËØ∑Ê±ÇÂ§±Ë¥•ÂíåÈîôËØØ
- ‚úÖ ÊéßÂà∂Âè∞ÈîôËØØÔºàËá™Âä®ÊçïËé∑Ôºâ
- ‚úÖ Êú™Â§ÑÁêÜÁöÑÂºÇÂ∏∏

**ÂäüËÉΩÁâπÊÄß**Ôºö
- Êó•ÂøóÁ≠õÈÄâ„ÄÅÊêúÁ¥¢
- ÂØºÂá∫Êó•ÂøóÔºàJSON/CSVÔºâ
- ÈîôËØØËØ¶ÊÉÖÊü•Áúã

**ÊâãÂä®ËÆ∞ÂΩïÁî®Êà∑Êìç‰Ωú**Ôºö
```typescript
import { logger, LogCategory } from &#039;@/shared/utils/logger&#039;;

// ËÆ∞ÂΩïÁî®Êà∑Êìç‰Ωú
logger.logUserAction(&#039;ÂàõÂª∫È°πÁõÆ&#039;, { projectName, projectType });
logger.logUserAction(&#039;ÂºÄÂßãÂÆ°ËÆ°&#039;, { taskId, fileCount });
```

&lt;/details&gt;

### üîë Ëé∑Âèñ API Key

#### ÊîØÊåÅÁöÑ LLM Âπ≥Âè∞

XCodeReviewer ÊîØÊåÅ 10+ ‰∏ªÊµÅ LLM Âπ≥Âè∞ÔºåÂèØÊ†πÊçÆÈúÄÊ±ÇËá™Áî±ÈÄâÊã©Ôºö

| Âπ≥Âè∞Á±ªÂûã | Âπ≥Âè∞ÂêçÁß∞ | ÁâπÁÇπ | Ëé∑ÂèñÂú∞ÂùÄ |
|---------|---------|------|---------|
| **ÂõΩÈôÖÂπ≥Âè∞** | Google Gemini | ÂÖçË¥πÈÖçÈ¢ùÂÖÖË∂≥ÔºåÊé®Ëçê | [Ëé∑Âèñ](https://makersuite.google.com/app/apikey) |
| | OpenAI GPT | Á®≥ÂÆöÂèØÈù†ÔºåÊÄßËÉΩÊúÄ‰Ω≥ | [Ëé∑Âèñ](https://platform.openai.com/api-keys) |
| | Anthropic Claude | ‰ª£Á†ÅÁêÜËß£ËÉΩÂäõÂº∫ | [Ëé∑Âèñ](https://console.anthropic.com/) |
| | DeepSeek | ÊÄß‰ª∑ÊØîÈ´ò | [Ëé∑Âèñ](https://platform.deepseek.com/) |
| **ÂõΩÂÜÖÂπ≥Âè∞** | ÈòøÈáå‰∫ëÈÄö‰πâÂçÉÈóÆ | ÂõΩÂÜÖËÆøÈóÆÂø´ | [Ëé∑Âèñ](https://dashscope.console.aliyun.com/) |
| | Êô∫Ë∞±AI (GLM) | ‰∏≠ÊñáÊîØÊåÅÂ•Ω | [Ëé∑Âèñ](https://open.bigmodel.cn/) |
| | Êúà‰πãÊöóÈù¢ Kimi | ÈïøÊñáÊú¨Â§ÑÁêÜ | [Ëé∑Âèñ](https://platform.moonshot.cn/) |
| | ÁôæÂ∫¶ÊñáÂøÉ‰∏ÄË®Ä | ‰ºÅ‰∏öÁ∫ßÊúçÂä° | [Ëé∑Âèñ](https://console.bce.baidu.com/qianfan/) |
| | MiniMax | Â§öÊ®°ÊÄÅËÉΩÂäõ | [Ëé∑Âèñ](https://www.minimaxi.com/) |
| | Â≠óËäÇË±ÜÂåÖ | È´òÊÄß‰ª∑ÊØî | [Ëé∑Âèñ](https://console.volcengine.com/ark) |
| **Êú¨Âú∞ÈÉ®ÁΩ≤** | Ollama | ÂÆåÂÖ®Êú¨Âú∞ÂåñÔºåÈöêÁßÅÂÆâÂÖ® | [ÂÆâË£Ö](https://ollama.com/) |

#### ÈÖçÁΩÆÁ§∫‰æã

```env
# ÈÄöÁî®ÈÖçÁΩÆÔºàÊé®ËçêÔºâ
VITE_LLM_PROVIDER=gemini
VITE_LLM_API_KEY=your_api_key_here

# Êàñ‰ΩøÁî®Âπ≥Âè∞‰∏ìÁî®ÈÖçÁΩÆ
VITE_GEMINI_API_KEY=your_gemini_key
VITE_OPENAI_API_KEY=your_openai_key
# ... Êõ¥Â§öÂπ≥Âè∞ÈÖçÁΩÆËßÅ .env.example
```

#### Supabase ÈÖçÁΩÆÔºàÂèØÈÄâÔºâ

Â¶ÇÈúÄ‰∫ëÁ´ØÊï∞ÊçÆÂêåÊ≠•Ôºö
1. ËÆøÈóÆ [Supabase](https://supabase.com/) ÂàõÂª∫È°πÁõÆ
2. Ëé∑Âèñ URL ÂíåÂåøÂêçÂØÜÈí•
3. Âú® Supabase SQL ÁºñËæëÂô®ÊâßË°å `supabase/migrations/full_schema.sql`
4. Âú® `.env` ‰∏≠ÈÖçÁΩÆÁõ∏ÂÖ≥ÂèÇÊï∞

## ‚ú® Ê†∏ÂøÉÂäüËÉΩ

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;üöÄ È°πÁõÆÁÆ°ÁêÜ&lt;/b&gt;&lt;/summary&gt;

- **‰∏ÄÈîÆÈõÜÊàê‰ª£Á†Å‰ªìÂ∫ì**ÔºöÊó†ÁºùÂØπÊé• GitHub„ÄÅGitLab Á≠â‰∏ªÊµÅÂπ≥Âè∞„ÄÇ
- **Â§öËØ≠Ë®Ä‚ÄúÂÖ®ÂÆ∂Ê°∂‚ÄùÊîØÊåÅ**ÔºöË¶ÜÁõñ JavaScript, TypeScript, Python, Java, Go, Rust Á≠âÁÉ≠Èó®ËØ≠Ë®Ä„ÄÇ
- **ÁÅµÊ¥ªÁöÑÂàÜÊîØÂÆ°ËÆ°**ÔºöÊîØÊåÅÂØπÊåáÂÆö‰ª£Á†ÅÂàÜÊîØËøõË°åÁ≤æÁ°ÆÂàÜÊûê„ÄÇ
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;‚ö° Âç≥Êó∂ÂàÜÊûê&lt;/b&gt;&lt;/summary&gt;

- **‰ª£Á†ÅÁâáÊÆµ‚ÄúÈöèÊâãË¥¥‚Äù**ÔºöÁõ¥Êé•Âú® Web ÁïåÈù¢Á≤òË¥¥‰ª£Á†ÅÔºåÁ´ãÂç≥Ëé∑ÂæóÂàÜÊûêÁªìÊûú„ÄÇ
- **10+ ÁßçËØ≠Ë®ÄÂç≥Êó∂ÊîØÊåÅ**ÔºöÊª°Ë∂≥ÊÇ®Â§öÊ†∑ÂåñÁöÑ‰ª£Á†ÅÂàÜÊûêÈúÄÊ±Ç„ÄÇ
- **ÊØ´ÁßíÁ∫ßÂìçÂ∫î**ÔºöÂø´ÈÄüËé∑Âèñ‰ª£Á†ÅË¥®ÈáèËØÑÂàÜÂíå‰ºòÂåñÂª∫ËÆÆ„ÄÇ
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;üß† Êô∫ËÉΩÂÆ°ËÆ°&lt;/b&gt;&lt;/summary&gt;

- **AI Ê∑±Â∫¶‰ª£Á†ÅÁêÜËß£**ÔºöÊîØÊåÅÂ§ö‰∏™‰∏ªÊµÅ LLM Âπ≥Âè∞ÔºàGemini„ÄÅOpenAI„ÄÅClaude„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅDeepSeek Á≠âÔºâÔºåÊèê‰æõË∂ÖË∂äÂÖ≥ÈîÆËØçÂåπÈÖçÁöÑÊô∫ËÉΩÂàÜÊûê„ÄÇ
- **‰∫îÂ§ßÊ†∏ÂøÉÁª¥Â∫¶Ê£ÄÊµã**Ôºö
  - üêõ **ÊΩúÂú® Bug**ÔºöÁ≤æÂáÜÊçïÊçâÈÄªËæëÈîôËØØ„ÄÅËæπÁïåÊù°‰ª∂ÂíåÁ©∫ÊåáÈíàÁ≠âÈóÆÈ¢ò„ÄÇ
  - üîí **ÂÆâÂÖ®ÊºèÊ¥û**ÔºöËØÜÂà´ SQL Ê≥®ÂÖ•„ÄÅXSS„ÄÅÊïèÊÑü‰ø°ÊÅØÊ≥ÑÈú≤Á≠âÂÆâÂÖ®È£éÈô©„ÄÇ
  - ‚ö° **ÊÄßËÉΩÁì∂È¢à**ÔºöÂèëÁé∞‰ΩéÊïàÁÆóÊ≥ï„ÄÅÂÜÖÂ≠òÊ≥ÑÊºèÂíå‰∏çÂêàÁêÜÁöÑÂºÇÊ≠•Êìç‰Ωú„ÄÇ
  - üé® **‰ª£Á†ÅÈ£éÊ†º**ÔºöÁ°Æ‰øù‰ª£Á†ÅÈÅµÂæ™Ë°å‰∏öÊúÄ‰Ω≥ÂÆûË∑µÂíåÁªü‰∏ÄËßÑËåÉ„ÄÇ
  - üîß **ÂèØÁª¥Êä§ÊÄß**ÔºöËØÑ‰º∞‰ª£Á†ÅÁöÑÂèØËØªÊÄß„ÄÅÂ§çÊùÇÂ∫¶ÂíåÊ®°ÂùóÂåñÁ®ãÂ∫¶„ÄÇ
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;üí° ÂèØËß£ÈáäÊÄßÂàÜÊûê (What-Why-How)&lt;/b&gt;&lt;/summary&gt;

- **What (ÊòØ‰ªÄ‰πà)**ÔºöÊ∏ÖÊô∞Âú∞ÊåáÂá∫‰ª£Á†Å‰∏≠Â≠òÂú®ÁöÑÈóÆÈ¢ò„ÄÇ
- **Why (‰∏∫‰ªÄ‰πà)**ÔºöËØ¶ÁªÜËß£ÈáäËØ•ÈóÆÈ¢òÂèØËÉΩÂ∏¶Êù•ÁöÑÊΩúÂú®È£éÈô©ÂíåÂΩ±Âìç„ÄÇ
- **How (Â¶Ç‰Ωï‰øÆÂ§ç)**ÔºöÊèê‰æõÂÖ∑‰ΩìÁöÑ„ÄÅÂèØÁõ¥Êé•‰ΩøÁî®ÁöÑ‰ª£Á†Å‰øÆÂ§çÁ§∫‰æã„ÄÇ
- **Á≤æÂáÜ‰ª£Á†ÅÂÆö‰Ωç**ÔºöÂø´ÈÄüË∑≥ËΩ¨Âà∞ÈóÆÈ¢òÊâÄÂú®ÁöÑË°åÂíåÂàó„ÄÇ
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;üìä ÂèØËßÜÂåñÊä•Âëä&lt;/b&gt;&lt;/summary&gt;

- **‰ª£Á†ÅË¥®Èáè‰ª™Ë°®Áõò**ÔºöÊèê‰æõ 0-100 ÂàÜÁöÑÁªºÂêàË¥®ÈáèËØÑ‰º∞ÔºåËÆ©‰ª£Á†ÅÂÅ•Â∫∑Áä∂ÂÜµ‰∏ÄÁõÆ‰∫ÜÁÑ∂„ÄÇ
- **Â§öÁª¥Â∫¶ÈóÆÈ¢òÁªüËÆ°**ÔºöÊåâÁ±ªÂûãÂíå‰∏•ÈáçÁ®ãÂ∫¶ÂØπÈóÆÈ¢òËøõË°åÂàÜÁ±ªÁªüËÆ°„ÄÇ
- **Ë¥®ÈáèË∂ãÂäøÂàÜÊûê**ÔºöÈÄöËøáÂõæË°®Â±ïÁ§∫‰ª£Á†ÅË¥®ÈáèÈöèÊó∂Èó¥ÁöÑÂèòÂåñË∂ãÂäø„ÄÇ
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;b&gt;‚öôÔ∏è Á≥ªÁªüÁÆ°ÁêÜ&lt;/b&gt;&lt;/summary&gt;

ËÆøÈóÆ `/admin` È°µÈù¢ÔºåÊèê‰æõÂÆåÊï¥ÁöÑÁ≥ªÁªüÈÖçÁΩÆÂíåÊï∞ÊçÆÁÆ°ÁêÜÂäüËÉΩÔºö

- **üîß ÂèØËßÜÂåñÈÖçÁΩÆÁÆ°ÁêÜ**ÔºàËøêË°åÊó∂ÈÖçÁΩÆÔºâÔºö
  - üéØ **LLM ÈÖçÁΩÆ**ÔºöÂú®ÊµèËßàÂô®‰∏≠Áõ¥Êé•ÈÖçÁΩÆ API Keys„ÄÅÊ®°Âûã„ÄÅË∂ÖÊó∂Á≠âÂèÇÊï∞
  - üîë **Âπ≥Âè∞ÂØÜÈí•**ÔºöÁÆ°ÁêÜ 10+ LLM Âπ≥Âè∞ÁöÑ API KeysÔºåÊîØÊåÅÂø´ÈÄüÂàáÊç¢
  - ‚ö° **ÂàÜÊûêÂèÇÊï∞**ÔºöË∞ÉÊï¥Âπ∂ÂèëÊï∞„ÄÅÈó¥ÈöîÊó∂Èó¥„ÄÅÊúÄÂ§ßÊñá‰ª∂Êï∞Á≠â
  - üåê **API ‰∏≠ËΩ¨Á´ôÊîØÊåÅ**ÔºöËΩªÊùæÈÖçÁΩÆÁ¨¨‰∏âÊñπ API ‰ª£ÁêÜÊúçÂä°
  - üíæ **ÈÖçÁΩÆ‰ºòÂÖàÁ∫ß**ÔºöËøêË°åÊó∂ÈÖçÁΩÆ &gt; ÊûÑÂª∫Êó∂ÈÖçÁΩÆÔºåÊó†ÈúÄÈáçÊñ∞ÊûÑÂª∫ÈïúÂÉè
  
- **üíæ Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜ**Ôºö
  - üè† **‰∏âÁßçÊ®°Âºè**ÔºöÊú¨Âú∞ IndexedDB / Supabase ‰∫ëÁ´Ø / ÊºîÁ§∫Ê®°Âºè
  - üì§ **ÂØºÂá∫Â§á‰ªΩ**ÔºöÂ∞ÜÊï∞ÊçÆÂØºÂá∫‰∏∫ JSON Êñá‰ª∂
  - üì• **ÂØºÂÖ•ÊÅ¢Â§ç**Ôºö‰ªéÂ§á‰ªΩÊñá‰ª∂ÊÅ¢Â§çÊï∞ÊçÆ
  - üóëÔ∏è **Ê∏ÖÁ©∫Êï∞ÊçÆ**Ôºö‰∏ÄÈîÆÊ∏ÖÁêÜÊâÄÊúâÊú¨Âú∞Êï∞ÊçÆ
  - üìä **Â≠òÂÇ®ÁõëÊéß**ÔºöÂÆûÊó∂Êü•ÁúãÂ≠òÂÇ®Á©∫Èó¥‰ΩøÁî®ÊÉÖÂÜµ
  
- **üìà Êï∞ÊçÆÊ¶ÇËßà**Ôºö
  - È°πÁõÆ„ÄÅ‰ªªÂä°„ÄÅÈóÆÈ¢òÁöÑÂÆåÊï¥ÁªüËÆ°
  - ÂèØËßÜÂåñÂõæË°®Â±ïÁ§∫Ë¥®ÈáèË∂ãÂäø
  - Â≠òÂÇ®‰ΩøÁî®ÊÉÖÂÜµÂàÜÊûê
&lt;/details&gt;

## üõ†Ô∏è ÊäÄÊúØÊ†à

| ÂàÜÁ±ª | ÊäÄÊúØ | ËØ¥Êòé |
| :--- | :--- | :--- |
| **ÂâçÁ´ØÊ°ÜÊû∂** | `React 18` `TypeScript` `Vite` | Áé∞‰ª£ÂåñÂâçÁ´ØÂºÄÂèëÊ†àÔºåÊîØÊåÅÁÉ≠ÈáçËΩΩÂíåÁ±ªÂûãÂÆâÂÖ® |
| **UI ÁªÑ‰ª∂** | `Tailwind CSS` `Radix UI` `Lucide React` | ÂìçÂ∫îÂºèËÆæËÆ°ÔºåÊó†ÈöúÁ¢çËÆøÈóÆÔºå‰∏∞ÂØåÁöÑÂõæÊ†áÂ∫ì |
| **Êï∞ÊçÆÂèØËßÜÂåñ** | `Recharts` | ‰∏ì‰∏öÁöÑÂõæË°®Â∫ìÔºåÊîØÊåÅÂ§öÁßçÂõæË°®Á±ªÂûã |
| **Ë∑ØÁî±ÁÆ°ÁêÜ** | `React Router v6` | ÂçïÈ°µÂ∫îÁî®Ë∑ØÁî±Ëß£ÂÜ≥ÊñπÊ°à |
| **Áä∂ÊÄÅÁÆ°ÁêÜ** | `React Hooks` `Sonner` | ËΩªÈáèÁ∫ßÁä∂ÊÄÅÁÆ°ÁêÜÂíåÈÄöÁü•Á≥ªÁªü |
| **AI ÂºïÊìé** | `Â§öÂπ≥Âè∞ LLM` | ÊîØÊåÅ Gemini„ÄÅOpenAI„ÄÅClaude„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅDeepSeek Á≠â 10+ ‰∏ªÊµÅÂπ≥Âè∞ |
| **Êï∞ÊçÆÂ≠òÂÇ®** | `IndexedDB` `Supabase` `PostgreSQL` | Êú¨Âú∞Êï∞ÊçÆÂ∫ì + ‰∫ëÁ´ØÊï∞ÊçÆÂ∫ìÂèåÊ®°ÂºèÊîØÊåÅ |
| **HTTP ÂÆ¢Êà∑Á´Ø** | `Axios` `Ky` | Áé∞‰ª£ÂåñÁöÑ HTTP ËØ∑Ê±ÇÂ∫ì |
| **‰ª£Á†ÅË¥®Èáè** | `Biome` `Ast-grep` `TypeScript` | ‰ª£Á†ÅÊ†ºÂºèÂåñ„ÄÅÈùôÊÄÅÂàÜÊûêÂíåÁ±ªÂûãÊ£ÄÊü• |
| **ÊûÑÂª∫Â∑•ÂÖ∑** | `Vite` `PostCSS` `Autoprefixer` | Âø´ÈÄüÁöÑÊûÑÂª∫Â∑•ÂÖ∑Âíå CSS Â§ÑÁêÜ |

## üìÅ È°πÁõÆÁªìÊûÑ

```
XCodeReviewer/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/                # Â∫îÁî®ÈÖçÁΩÆ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ App.tsx         # ‰∏ªÂ∫îÁî®ÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.tsx        # Â∫îÁî®ÂÖ•Âè£ÁÇπ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ routes.tsx      # Ë∑ØÁî±ÈÖçÁΩÆ
‚îÇ   ‚îú‚îÄ‚îÄ components/         # React ÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout/         # Â∏ÉÂ±ÄÁªÑ‰ª∂ (Header, Footer, PageMeta)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ui/             # UI ÁªÑ‰ª∂Â∫ì (Âü∫‰∫é Radix UI)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ system/         # Á≥ªÁªüÈÖçÁΩÆÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database/       # Êï∞ÊçÆÂ∫ìÁÆ°ÁêÜÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ debug/          # Ë∞ÉËØïÁªÑ‰ª∂
‚îÇ   ‚îú‚îÄ‚îÄ pages/              # È°µÈù¢ÁªÑ‰ª∂
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Dashboard.tsx   # ‰ª™Ë°®Áõò
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Projects.tsx    # È°πÁõÆÁÆ°ÁêÜ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ InstantAnalysis.tsx # Âç≥Êó∂ÂàÜÊûê
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ AuditTasks.tsx  # ÂÆ°ËÆ°‰ªªÂä°
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ AdminDashboard.tsx # Á≥ªÁªüÁÆ°ÁêÜ
‚îÇ   ‚îú‚îÄ‚îÄ features/           # ÂäüËÉΩÊ®°Âùó
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analysis/       # ÂàÜÊûêÁõ∏ÂÖ≥ÊúçÂä°
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ services/   # AI ‰ª£Á†ÅÂàÜÊûêÂºïÊìé
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ projects/       # È°πÁõÆÁõ∏ÂÖ≥ÊúçÂä°
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ services/   # ‰ªìÂ∫ìÊâ´Êèè„ÄÅZIP Êñá‰ª∂Êâ´Êèè
‚îÇ   ‚îú‚îÄ‚îÄ shared/             # ÂÖ±‰∫´Â∑•ÂÖ∑
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config/         # ÈÖçÁΩÆÊñá‰ª∂
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.ts      # Êï∞ÊçÆÂ∫ìÁªü‰∏ÄÊé•Âè£
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ localDatabase.ts # IndexedDB ÂÆûÁé∞
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ env.ts           # ÁéØÂ¢ÉÂèòÈáèÈÖçÁΩÆ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ types/          # TypeScript Á±ªÂûãÂÆö‰πâ
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ hooks/          # Ëá™ÂÆö‰πâ React Hooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ utils/          # Â∑•ÂÖ∑ÂáΩÊï∞
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ initLocalDB.ts   # Êú¨Âú∞Êï∞ÊçÆÂ∫ìÂàùÂßãÂåñ
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ constants/      # Â∏∏ÈáèÂÆö‰πâ
‚îÇ   ‚îî‚îÄ‚îÄ assets/             # ÈùôÊÄÅËµÑÊ∫ê
‚îÇ       ‚îî‚îÄ‚îÄ styles/         # Ê†∑ÂºèÊñá‰ª∂
‚îú‚îÄ‚îÄ supabase/
‚îÇ   ‚îî‚îÄ‚îÄ migrations/         # Êï∞ÊçÆÂ∫ìËøÅÁßªÊñá‰ª∂
‚îú‚îÄ‚îÄ public/
‚îÇ   ‚îî‚îÄ‚îÄ images/             # ÂõæÁâáËµÑÊ∫ê
‚îú‚îÄ‚îÄ scripts/                # ÊûÑÂª∫ÂíåËÆæÁΩÆËÑöÊú¨
‚îî‚îÄ‚îÄ rules/                  # ‰ª£Á†ÅËßÑÂàôÈÖçÁΩÆ
```

## üéØ ‰ΩøÁî®ÊåáÂçó

### Á≥ªÁªüÈÖçÁΩÆÔºàÈ¶ñÊ¨°‰ΩøÁî®ÂøÖÁúãÔºâ

ËÆøÈóÆ `/admin` Á≥ªÁªüÁÆ°ÁêÜÈ°µÈù¢ÔºåÂú®&quot;Á≥ªÁªüÈÖçÁΩÆ&quot;Ê†áÁ≠æÈ°µ‰∏≠ÈÖçÁΩÆÔºö

#### 1. **ÈÖçÁΩÆ LLM Êèê‰æõÂïÜ**
- ÈÄâÊã©ÊÇ®Ë¶Å‰ΩøÁî®ÁöÑ LLM Âπ≥Âè∞ÔºàGemini„ÄÅOpenAI„ÄÅClaude Á≠âÔºâ
- Â°´ÂÖ• API KeyÔºàÊîØÊåÅÈÄöÁî® Key ÊàñÂπ≥Âè∞‰∏ìÁî® KeyÔºâ
- ÂèØÈÄâÔºöÈÖçÁΩÆÊ®°ÂûãÂêçÁß∞„ÄÅAPI Âü∫Á°Ä URLÔºàÁî®‰∫é‰∏≠ËΩ¨Á´ôÔºâ

#### 2. **ÈÖçÁΩÆ API ‰∏≠ËΩ¨Á´ô**ÔºàÂ¶ÇÊûú‰ΩøÁî®Ôºâ
- Âú®&quot;API Âü∫Á°Ä URL&quot;‰∏≠Â°´ÂÖ•‰∏≠ËΩ¨Á´ôÂú∞ÂùÄÔºàÂ¶Ç `https://your-proxy.com/v1`Ôºâ
- Â°´ÂÖ•‰∏≠ËΩ¨Á´ôÊèê‰æõÁöÑ API Key
- ‰øùÂ≠òÈÖçÁΩÆ

#### 3. **Ë∞ÉÊï¥ÂàÜÊûêÂèÇÊï∞**ÔºàÂèØÈÄâÔºâ
- ÊúÄÂ§ßÂàÜÊûêÊñá‰ª∂Êï∞„ÄÅÂπ∂ÂèëËØ∑Ê±ÇÊï∞„ÄÅËØ∑Ê±ÇÈó¥Èöî
- ËæìÂá∫ËØ≠Ë®ÄÔºà‰∏≠Êñá/Ëã±ÊñáÔºâ

**ÈÖçÁΩÆÂÆåÊàêÂêéÁÇπÂáª&quot;‰øùÂ≠òÊâÄÊúâÊõ¥Êîπ&quot;Âπ∂Âà∑Êñ∞È°µÈù¢Âç≥ÂèØ‰ΩøÁî®„ÄÇ**

### Âç≥Êó∂‰ª£Á†ÅÂàÜÊûê
1. ËÆøÈóÆ `/instant-analysis` È°µÈù¢
2. ÈÄâÊã©ÁºñÁ®ãËØ≠Ë®ÄÔºàÊîØÊåÅ 10+ ÁßçËØ≠Ë®ÄÔºâ
3. Á≤òË¥¥‰ª£Á†ÅÊàñ‰∏ä‰º†Êñá‰ª∂
4. ÁÇπÂáª&quot;ÂºÄÂßãÂàÜÊûê&quot;Ëé∑Âæó AI ÂàÜÊûêÁªìÊûú
5. Êü•ÁúãËØ¶ÁªÜÁöÑÈóÆÈ¢òÊä•ÂëäÂíå‰øÆÂ§çÂª∫ËÆÆ

### È°πÁõÆÁÆ°ÁêÜ
1. ËÆøÈóÆ `/projects` È°µÈù¢
2. ÁÇπÂáª&quot;Êñ∞Âª∫È°πÁõÆ&quot;ÂàõÂª∫È°πÁõÆ
3. ÈÖçÁΩÆ‰ªìÂ∫ì URL ÂíåÊâ´ÊèèÂèÇÊï∞
4. ÂêØÂä®‰ª£Á†ÅÂÆ°ËÆ°‰ªªÂä°
5. Êü•ÁúãÂÆ°ËÆ°ÁªìÊûúÂíåÈóÆÈ¢òÁªüËÆ°

### ÂÆ°ËÆ°‰ªªÂä°
1. Âú®È°πÁõÆËØ¶ÊÉÖÈ°µÂàõÂª∫ÂÆ°ËÆ°‰ªªÂä°
2. ÈÄâÊã©Êâ´ÊèèÂàÜÊîØÂíåÊéíÈô§Ê®°Âºè
3. ÈÖçÁΩÆÂàÜÊûêÊ∑±Â∫¶ÂíåËåÉÂõ¥
4. ÁõëÊéß‰ªªÂä°ÊâßË°åÁä∂ÊÄÅ
5. Êü•ÁúãËØ¶ÁªÜÁöÑÈóÆÈ¢òÊä•Âëä

### ÂÆ°ËÆ°Êä•ÂëäÂØºÂá∫
1. Âú®‰ªªÂä°ËØ¶ÊÉÖÈ°µÁÇπÂáª&quot;ÂØºÂá∫Êä•Âëä&quot;ÊåâÈíÆ
2. ÈÄâÊã©ÂØºÂá∫Ê†ºÂºèÔºö
   - **JSON Ê†ºÂºè**ÔºöÁªìÊûÑÂåñÊï∞ÊçÆÔºåÈÄÇÂêàÁ®ãÂ∫èÂ§ÑÁêÜÂíåÈõÜÊàê
   - **PDF Ê†ºÂºè**Ôºö‰∏ì‰∏öÊä•ÂëäÔºåÈÄÇÂêàÊâìÂç∞ÂíåÂàÜ‰∫´ÔºàÈÄöËøáÊµèËßàÂô®ÊâìÂç∞ÂäüËÉΩÔºâ
3. JSON Êä•ÂëäÂåÖÂê´ÂÆåÊï¥ÁöÑ‰ªªÂä°‰ø°ÊÅØ„ÄÅÈóÆÈ¢òËØ¶ÊÉÖÂíåÁªüËÆ°Êï∞ÊçÆ
4. PDF Êä•ÂëäÊèê‰æõÁæéËßÇÁöÑÂèØËßÜÂåñÂ±ïÁ§∫ÔºåÊîØÊåÅ‰∏≠ÊñáÊòæÁ§∫
5. Êä•ÂëäÂÜÖÂÆπÂåÖÊã¨ÔºöÈ°πÁõÆ‰ø°ÊÅØ„ÄÅÂÆ°ËÆ°ÁªüËÆ°„ÄÅÈóÆÈ¢òËØ¶ÊÉÖÔºàÊåâ‰∏•ÈáçÁ®ãÂ∫¶ÂàÜÁ±ªÔºâ„ÄÅ‰øÆÂ§çÂª∫ËÆÆÁ≠â

**PDF ÂØºÂá∫ÊèêÁ§∫Ôºö**
- ÁÇπÂáª&quot;ÂØºÂá∫ PDF&quot;Âêé‰ºöÂºπÂá∫ÊµèËßàÂô®ÊâìÂç∞ÂØπËØùÊ°Ü
- Âª∫ËÆÆÂú®ÊâìÂç∞ËÆæÁΩÆ‰∏≠**ÂèñÊ∂àÂãæÈÄâ&quot;È°µÁúâÂíåÈ°µËÑö&quot;ÈÄâÈ°π**Ôºå‰ª•Ëé∑ÂæóÊõ¥Âπ≤ÂáÄÁöÑÊä•ÂëäÔºàÈÅøÂÖçÊòæÁ§∫ URL Á≠â‰ø°ÊÅØÔºâ
- Âú®ÊâìÂç∞ÂØπËØùÊ°Ü‰∏≠ÈÄâÊã©&quot;Âè¶Â≠ò‰∏∫ PDF&quot;Âç≥ÂèØ‰øùÂ≠òÊä•ÂëäÊñá‰ª∂

### ÊûÑÂª∫ÂíåÈÉ®ÁΩ≤

```bash
# ÂºÄÂèëÊ®°Âºè
pnpm dev

# ÊûÑÂª∫Áîü‰∫ßÁâàÊú¨
pnpm build

# È¢ÑËßàÊûÑÂª∫ÁªìÊûú
pnpm preview

# ‰ª£Á†ÅÊ£ÄÊü•
pnpm lint
```

### ÁéØÂ¢ÉÂèòÈáèËØ¥Êòé

#### Ê†∏ÂøÉLLMÈÖçÁΩÆ
| ÂèòÈáèÂêç | ÂøÖÈúÄ | ÈªòËÆ§ÂÄº | ËØ¥Êòé |
|--------|------|--------|------|
| `VITE_LLM_PROVIDER` | ‚úÖ | `gemini` | LLMÊèê‰æõÂïÜÔºö`gemini`\|`openai`\|`claude`\|`qwen`\|`deepseek`\|`zhipu`\|`moonshot`\|`baidu`\|`minimax`\|`doubao`\|`ollama` |
| `VITE_LLM_API_KEY` | ‚úÖ | - | ÈÄöÁî®API KeyÔºà‰ºòÂÖàÁ∫ßÈ´ò‰∫éÂπ≥Âè∞‰∏ìÁî®ÈÖçÁΩÆÔºâ |
| `VITE_LLM_MODEL` | ‚ùå | Ëá™Âä® | Ê®°ÂûãÂêçÁß∞Ôºà‰∏çÊåáÂÆöÂàô‰ΩøÁî®ÂêÑÂπ≥Âè∞ÈªòËÆ§Ê®°ÂûãÔºâ |
| `VITE_LLM_BASE_URL` | ‚ùå | - | Ëá™ÂÆö‰πâAPIÁ´ØÁÇπÔºà**ÊîØÊåÅÊâÄÊúâÂπ≥Âè∞ÁöÑ‰∏≠ËΩ¨Á´ô**„ÄÅ‰ª£ÁêÜÊàñÁßÅÊúâÈÉ®ÁΩ≤Ôºâ |
| `VITE_LLM_TIMEOUT` | ‚ùå | `150000` | ËØ∑Ê±ÇË∂ÖÊó∂Êó∂Èó¥ÔºàÊØ´ÁßíÔºâ |
| `VITE_LLM_TEMPERATURE` | ‚ùå | `0.2` | Ê∏©Â∫¶ÂèÇÊï∞Ôºà0.0-2.0ÔºâÔºåÊéßÂà∂ËæìÂá∫ÈöèÊú∫ÊÄß |
| `VITE_LLM_MAX_TOKENS` | ‚ùå | `4096` | ÊúÄÂ§ßËæìÂá∫tokenÊï∞ |
| `VITE_LLM_CUSTOM_HEADERS` | ‚ùå | - | Ëá™ÂÆö‰πâHTTPËØ∑Ê±ÇÂ§¥ÔºàJSONÊ†ºÂºèÂ≠óÁ¨¶‰∏≤ÔºâÔºåÁî®‰∫éÁâπÊÆä‰∏≠ËΩ¨Á´ôÊàñËá™Âª∫ÊúçÂä° |

&gt; üí° **API Ê†ºÂºèÊîØÊåÅ**ÔºöXCodeReviewer ÊîØÊåÅ‰∏âÁßç‰∏ªÊµÅ API Ê†ºÂºèÔºö
&gt; - **OpenAI ÂÖºÂÆπÊ†ºÂºè**ÔºàÊúÄÂ∏∏ËßÅÔºâÔºöÈÄÇÁî®‰∫éÂ§ßÂ§öÊï∞‰∏≠ËΩ¨Á´ôÂíå OpenRouter
&gt; - **Gemini Ê†ºÂºè**ÔºöGoogle Gemini ÂÆòÊñπÂèäÂÖºÂÆπÊúçÂä°
&gt; - **Claude Ê†ºÂºè**ÔºöAnthropic Claude ÂÆòÊñπÂèäÂÖºÂÆπÊúçÂä°
&gt; 
&gt; ÈÖçÁΩÆÊó∂Âè™ÈúÄÈÄâÊã©ÂØπÂ∫îÁöÑ LLM Êèê‰æõÂïÜÔºåÂ°´ÂÖ•‰∏≠ËΩ¨Á´ôÂú∞ÂùÄÂíå Key Âç≥ÂèØ„ÄÇËá™ÂÆö‰πâËØ∑Ê±ÇÂ§¥ÂäüËÉΩÂèØÊª°Ë∂≥ÁâπÊÆä‰∏≠ËΩ¨Á´ôÁöÑÈ¢ùÂ§ñË¶ÅÊ±Ç„ÄÇ

#### Âπ≥Âè∞‰∏ìÁî®API KeyÈÖçÁΩÆÔºàÂèØÈÄâÔºâ
| ÂèòÈáèÂêç | ËØ¥Êòé | ÁâπÊÆäË¶ÅÊ±Ç |
|--------|------|---------|
| `VITE_GEMINI_API_KEY` | Google Gemini API Key | - |
| `VITE_GEMINI_MODEL` | GeminiÊ®°Âûã (ÈªòËÆ§: gemini-1.5-flash) | - |
| `VITE_OPENAI_API_KEY` | OpenAI API Key | - |
| `VITE_OPENAI_MODEL` | OpenAIÊ®°Âûã (ÈªòËÆ§: gpt-4o-mini) | - |
| `VITE_OPENAI_BASE_URL` | OpenAIËá™ÂÆö‰πâÁ´ØÁÇπ | Áî®‰∫é‰∏≠ËΩ¨ÊúçÂä° |
| `VITE_CLAUDE_API_KEY` | Anthropic Claude API Key | - |
| `VITE_CLAUDE_MODEL` | ClaudeÊ®°Âûã (ÈªòËÆ§: claude-3-5-sonnet-20241022) | - |
| `VITE_QWEN_API_KEY` | ÈòøÈáå‰∫ëÈÄö‰πâÂçÉÈóÆ API Key | - |
| `VITE_QWEN_MODEL` | ÈÄö‰πâÂçÉÈóÆÊ®°Âûã (ÈªòËÆ§: qwen-turbo) | - |
| `VITE_DEEPSEEK_API_KEY` | DeepSeek API Key | - |
| `VITE_DEEPSEEK_MODEL` | DeepSeekÊ®°Âûã (ÈªòËÆ§: deepseek-chat) | - |
| `VITE_ZHIPU_API_KEY` | Êô∫Ë∞±AI API Key | - |
| `VITE_ZHIPU_MODEL` | Êô∫Ë∞±Ê®°Âûã (ÈªòËÆ§: glm-4-flash) | - |
| `VITE_MOONSHOT_API_KEY` | Êúà‰πãÊöóÈù¢ Kimi API Key | - |
| `VITE_MOONSHOT_MODEL` | KimiÊ®°Âûã (ÈªòËÆ§: moonshot-v1-8k) | - |
| `VITE_BAIDU_API_KEY` | ÁôæÂ∫¶ÊñáÂøÉ‰∏ÄË®Ä API Key | ‚ö†Ô∏è Ê†ºÂºè: `API_KEY:SECRET_KEY` |
| `VITE_BAIDU_MODEL` | ÊñáÂøÉÊ®°Âûã (ÈªòËÆ§: ERNIE-3.5-8K) | - |
| `VITE_MINIMAX_API_KEY` | MiniMax API Key | - |
| `VITE_MINIMAX_MODEL` | MiniMaxÊ®°Âûã (ÈªòËÆ§: abab6.5-chat) | - |
| `VITE_DOUBAO_API_KEY` | Â≠óËäÇË±ÜÂåÖ API Key | - |
| `VITE_DOUBAO_MODEL` | Ë±ÜÂåÖÊ®°Âûã (ÈªòËÆ§: doubao-pro-32k) | - |

#### Êï∞ÊçÆÂ∫ìÈÖçÁΩÆÔºàÂèØÈÄâÔºâ
| ÂèòÈáèÂêç | ÂøÖÈúÄ | ËØ¥Êòé |
|--------|------|------|
| `VITE_SUPABASE_URL` | ‚ùå | SupabaseÈ°πÁõÆURLÔºàÁî®‰∫éÊï∞ÊçÆÊåÅ‰πÖÂåñÔºâ |
| `VITE_SUPABASE_ANON_KEY` | ‚ùå | SupabaseÂåøÂêçÂØÜÈí• |

&gt; üí° **ÊèêÁ§∫**Ôºö‰∏çÈÖçÁΩÆSupabaseÊó∂ÔºåÁ≥ªÁªü‰ª•ÊºîÁ§∫Ê®°ÂºèËøêË°åÔºåÊï∞ÊçÆ‰∏çÊåÅ‰πÖÂåñ

#### Git‰ªìÂ∫ìÈõÜÊàêÈÖçÁΩÆ
| ÂèòÈáèÂêç | ÂøÖÈúÄ | ËØ¥Êòé |
|--------|------|------|
| `VITE_GITHUB_TOKEN` | ‚úÖ | GitHub Personal Access Token |
| `VITE_GITLAB_TOKEN` | ‚úÖ | GitLab Personal Access Token Êàñ Project Access Token |

#### ÂàÜÊûêË°å‰∏∫ÈÖçÁΩÆ
| ÂèòÈáèÂêç | ÈªòËÆ§ÂÄº | ËØ¥Êòé |
|--------|--------|------|
| `VITE_MAX_ANALYZE_FILES` | `40` | ÂçïÊ¨°ÂàÜÊûêÁöÑÊúÄÂ§ßÊñá‰ª∂Êï∞ |
| `VITE_LLM_CONCURRENCY` | `2` | LLMÂπ∂ÂèëËØ∑Ê±ÇÊï∞ÔºàÈôç‰ΩéÂèØÈÅøÂÖçÈ¢ëÁéáÈôêÂà∂Ôºâ |
| `VITE_LLM_GAP_MS` | `500` | LLMËØ∑Ê±ÇÈó¥ÈöîÔºàÊØ´ÁßíÔºåÂ¢ûÂä†ÂèØÈÅøÂÖçÈ¢ëÁéáÈôêÂà∂Ôºâ |

#### Â∫îÁî®ÈÖçÁΩÆ
| ÂèòÈáèÂêç | ÈªòËÆ§ÂÄº | ËØ¥Êòé |
|--------|--------|------|
| `VITE_APP_ID` | `xcodereviewer` | Â∫îÁî®Ê†áËØÜÁ¨¶ |

## ü§ù Ë¥°ÁåÆÊåáÂçó

Êàë‰ª¨ÁÉ≠ÁÉàÊ¨¢ËøéÊâÄÊúâÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅÊó†ËÆ∫ÊòØÊèê‰∫§ issue„ÄÅÂàõÂª∫ PRÔºåËøòÊòØÊîπËøõÊñáÊ°£ÔºåÊÇ®ÁöÑÊØè‰∏ÄÊ¨°Ë¥°ÁåÆÂØπÊàë‰ª¨ÈÉΩËá≥ÂÖ≥ÈáçË¶Å„ÄÇËØ∑ËÅîÁ≥ªÊàë‰ª¨‰∫ÜËß£ËØ¶ÁªÜ‰ø°ÊÅØ„ÄÇ

### ÂºÄÂèëÊµÅÁ®ã

1.  **Fork** Êú¨È°πÁõÆ
2.  ÂàõÂª∫ÊÇ®ÁöÑÂäüËÉΩÂàÜÊîØ (`git checkout -b feature/AmazingFeature`)
3.  Êèê‰∫§ÊÇ®ÁöÑÊõ¥Êîπ (`git commit -m &#039;Add some AmazingFeature&#039;`)
4.  Êé®ÈÄÅÂà∞ÂàÜÊîØ (`git push origin feature/AmazingFeature`)
5.  ÂàõÂª∫‰∏Ä‰∏™ **Pull Request**

## üôè Ëá¥Ë∞¢

### Ê†∏ÂøÉÊäÄÊúØÊîØÊåÅ
- **[React](https://reactjs.org/)** &amp; **[Vite](https://vitejs.dev/)**: Êèê‰æõÁé∞‰ª£ÂåñÁöÑÂâçÁ´ØÂºÄÂèë‰ΩìÈ™å
- **[TypeScript](https://www.typescriptlang.org/)**: Êèê‰æõÁ±ªÂûãÂÆâÂÖ®‰øùÈöú
- **[Tailwind CSS](https://tailwindcss.com/)**: Êèê‰æõÁé∞‰ª£ÂåñÁöÑ CSS Ê°ÜÊû∂
- **[Radix UI](https://www.radix-ui.com/)**: Êèê‰æõÊó†ÈöúÁ¢çÁöÑ UI ÁªÑ‰ª∂Â∫ì

### AI Âπ≥Âè∞ÊîØÊåÅ
- **[Google Gemini AI](https://ai.google.dev/)**: Êèê‰æõÂº∫Â§ßÁöÑ AI ÂàÜÊûêËÉΩÂäõ
- **[OpenAI](https://openai.com/)**: GPTÁ≥ªÂàóÊ®°ÂûãÊîØÊåÅ
- **[Anthropic Claude](https://www.anthropic.com/)**: ClaudeÊ®°ÂûãÊîØÊåÅ
- **[DeepSeek](https://www.deepseek.com/)**: ÂõΩ‰∫ßAIÂ§ßÊ®°ÂûãÊîØÊåÅ
- **[ÈòøÈáå‰∫ëÈÄö‰πâÂçÉÈóÆ](https://tongyi.aliyun.com/)**: ‰ºÅ‰∏öÁ∫ßAIÊúçÂä°
- **[Êô∫Ë∞±AI](https://www.zhipuai.cn/)**: GLMÁ≥ªÂàóÊ®°Âûã
- **[Moonshot AI](https://www.moonshot.cn/)**: KimiÊ®°ÂûãÊîØÊåÅ
- **[Ollama](https://ollama.com/)**: Êú¨Âú∞Ê®°ÂûãÈÉ®ÁΩ≤ÊñπÊ°à

### Êï∞ÊçÆÂ≠òÂÇ®
- **[Supabase](https://supabase.com/)**: Êèê‰æõ‰æøÊç∑ÁöÑÂêéÁ´ØÂç≥ÊúçÂä°ÊîØÊåÅ
- **[IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API)**: ÊµèËßàÂô®Êú¨Âú∞Â≠òÂÇ®ÊñπÊ°à

### ÂäüËÉΩÁªÑ‰ª∂
- **[Recharts](https://recharts.org/)**: Êèê‰æõ‰∏ì‰∏öÁöÑÂõæË°®ÁªÑ‰ª∂
- **[Lucide Icons](https://lucide.dev/)**: Êèê‰æõÁ≤æÁæéÁöÑÂõæÊ†áÂ∫ì
- **[Sonner](https://sonner.emilkowal.ski/)**: Êèê‰æõ‰ºòÈõÖÁöÑÈÄöÁü•ÁªÑ‰ª∂
- **[fflate](https://github.com/101arrowz/fflate)**: ZIPÊñá‰ª∂Â§ÑÁêÜ

### ÁâπÂà´ÊÑüË∞¢
- ÊÑüË∞¢ÊâÄÊúâ‰∏∫Êú¨È°πÁõÆÊèê‰∫§ Issue Âíå Pull Request ÁöÑË¥°ÁåÆËÄÖ
- ÊÑüË∞¢ÊâÄÊúâ Star Êú¨È°πÁõÆÁöÑÂºÄÂèëËÄÖ
- ÊÑüË∞¢ÂºÄÊ∫êÁ§æÂå∫ÁöÑÊó†ÁßÅÂàÜ‰∫´Á≤æÁ•û
- ‰ª•ÂèäÊâÄÊúâÊú¨È°πÁõÆÊâÄ‰ΩøÁî®ÁöÑÂºÄÊ∫êËΩØ‰ª∂ÁöÑ‰ΩúËÄÖ‰ª¨ÔºÅ

## üë• Ë¥°ÁåÆËÄÖ

ÊÑüË∞¢‰ª•‰∏ã‰ºòÁßÄÁöÑË¥°ÁåÆËÄÖ‰ª¨Ôºå‰ªñ‰ª¨ËÆ© XCodeReviewer Êõ¥Âº∫Â§ßÔºÅ

[![Contributors](https://contrib.rocks/image?re

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[GVCLab/PersonaLive]]></title>
            <link>https://github.com/GVCLab/PersonaLive</link>
            <guid>https://github.com/GVCLab/PersonaLive</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:09 GMT</pubDate>
            <description><![CDATA[[CVPR 2026] PersonaLive! : Expressive Portrait Image Animation for Live Streaming]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GVCLab/PersonaLive">GVCLab/PersonaLive</a></h1>
            <p>[CVPR 2026] PersonaLive! : Expressive Portrait Image Animation for Live Streaming</p>
            <p>Language: Python</p>
            <p>Stars: 2,239</p>
            <p>Forks: 302</p>
            <p>Stars today: 371 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;assets/header.svg&quot; alt=&quot;PersonaLive&quot; width=&quot;100%&quot;&gt;

&lt;h2&gt;Expressive Portrait Image Animation for Live Streaming&lt;/h2&gt;

#### [Zhiyuan Li&lt;sup&gt;1,2,3&lt;/sup&gt;](https://huai-chang.github.io/) ¬∑ [Chi-Man Pun&lt;sup&gt;1,üì™&lt;/sup&gt;](https://cmpun.github.io/) ¬∑ [Chen Fang&lt;sup&gt;2&lt;/sup&gt;](http://fangchen.org/) ¬∑ [Jue Wang&lt;sup&gt;2&lt;/sup&gt;](https://scholar.google.com/citations?user=Bt4uDWMAAAAJ&amp;hl=en) ¬∑ [Xiaodong Cun&lt;sup&gt;3,üì™&lt;/sup&gt;](https://vinthony.github.io/academic/) 
&lt;sup&gt;1&lt;/sup&gt; University of Macau  &amp;nbsp;&amp;nbsp; &lt;sup&gt;2&lt;/sup&gt; [Dzine.ai](https://www.dzine.ai/)  &amp;nbsp;&amp;nbsp; &lt;sup&gt;3&lt;/sup&gt; [GVC Lab, Great Bay University](https://gvclab.github.io/)

&lt;a href=&#039;https://arxiv.org/abs/2512.11253&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/ArXiv-2512.11253-red&#039;&gt;&lt;/a&gt; &lt;a href=&#039;https://huggingface.co/huaichang/PersonaLive&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Model-ffc107&#039;&gt;&lt;/a&gt; &lt;a href=&#039;https://modelscope.cn/models/huaichang/PersonaLive&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/ModelScope-Model-624AFF&#039;&gt;&lt;/a&gt; [![GitHub](https://img.shields.io/github/stars/GVCLab/PersonaLive?style=social)](https://github.com/GVCLab/PersonaLive)

&lt;img src=&quot;assets/highlight.svg&quot; alt=&quot;highlight&quot; width=&quot;95%&quot;&gt;

&lt;img src=&quot;assets/demo_3.gif&quot; width=&quot;46%&quot;&gt; &amp;nbsp;&amp;nbsp; &lt;img src=&quot;assets/demo_2.gif&quot; width=&quot;40.5%&quot;&gt;
&lt;/div&gt;

## üìã TODO
- [ ] If you find PersonaLive useful or interesting, please give us a Starüåü! Your support drives us to keep improving.
- [ ] Fix bugs (If you encounter any issues, please feel free to open an issue or contact me! üôè)
- [x] **[2026.02.21]** ü•≥ PersonaLive is accepted by CVPR2026 üéâ.
- [x] **[2025.12.29]** üî• Enhance WebUI (Support reference image replacement).
- [x] **[2025.12.22]** üî• Supported streaming strategy in offline inference to generate long videos on 12GB VRAM!
- [x] **[2025.12.17]** üî• [ComfyUI-PersonaLive](https://github.com/okdalto/ComfyUI-PersonaLive) is now supported! (Thanks to [@okdalto](https://github.com/okdalto))
- [x] **[2025.12.15]** üî• Release `paper`!
- [x] **[2025.12.12]** üî• Release `inference code`, `config`, and `pretrained weights`!
  
## ‚öñÔ∏è Disclaimer

- [x] This project is released for **academic research only**.
- [x] Users must not use this repository to generate harmful, defamatory, or illegal content.
- [x] The authors bear no responsibility for any misuse or legal consequences arising from the use of this tool.
- [x] By using this code, you agree that you are solely responsible for any content generated.

## ‚öôÔ∏è Framework
&lt;img src=&quot;assets/overview.png&quot; alt=&quot;Image 1&quot; width=&quot;100%&quot;&gt;


We present PersonaLive, a `real-time` and `streamable` diffusion framework capable of generating `infinite-length` portrait animations.


## üöÄ Getting Started
### üõ† Installation
```
# clone this repo
git clone https://github.com/GVCLab/PersonaLive
cd PersonaLive

# Create conda environment
conda create -n personalive python=3.10
conda activate personalive

# Install packages with pip
pip install -r requirements_base.txt
```

### ‚è¨ Download weights
Option 1: Download pre-trained weights of base models and other components ([sd-image-variations-diffusers](https://huggingface.co/lambdalabs/sd-image-variations-diffusers) and [sd-vae-ft-mse](https://huggingface.co/stabilityai/sd-vae-ft-mse)). You can run the following command to download weights automatically:
    
```bash
python tools/download_weights.py
```

Option 2: Download pre-trained weights into the `./pretrained_weights` folder from one of the below URLs:
    
&lt;a href=&#039;https://drive.google.com/drive/folders/1GOhDBKIeowkMpBnKhGB8jgEhJt_--vbT?usp=drive_link&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/Google%20Drive-5B8DEF?style=for-the-badge&amp;logo=googledrive&amp;logoColor=white&#039;&gt;&lt;/a&gt; &lt;a href=&#039;https://pan.baidu.com/s/1DCv4NvUy_z7Gj2xCGqRMkQ?pwd=gj64&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/Baidu%20Netdisk-3E4A89?style=for-the-badge&amp;logo=baidu&amp;logoColor=white&#039;&gt;&lt;/a&gt; &lt;a href=&#039;https://modelscope.cn/models/huaichang/PersonaLive&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/ModelScope-624AFF?style=for-the-badge&amp;logo=alibabacloud&amp;logoColor=white&#039;&gt;&lt;/a&gt; &lt;a href=&#039;https://huggingface.co/huaichang/PersonaLive&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/HuggingFace-E67E22?style=for-the-badge&amp;logo=huggingface&amp;logoColor=white&#039;&gt;&lt;/a&gt;

Finally, these weights should be organized as follows:
```
pretrained_weights
‚îú‚îÄ‚îÄ onnx
‚îÇ   ‚îú‚îÄ‚îÄ unet_opt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unet_opt.onnx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ unet_opt.onnx.data
‚îÇ   ‚îî‚îÄ‚îÄ unet
‚îú‚îÄ‚îÄ personalive
‚îÇ   ‚îú‚îÄ‚îÄ denoising_unet.pth
‚îÇ   ‚îú‚îÄ‚îÄ motion_encoder.pth
‚îÇ   ‚îú‚îÄ‚îÄ motion_extractor.pth
‚îÇ   ‚îú‚îÄ‚îÄ pose_guider.pth
‚îÇ   ‚îú‚îÄ‚îÄ reference_unet.pth
‚îÇ   ‚îî‚îÄ‚îÄ temporal_module.pth
‚îú‚îÄ‚îÄ sd-vae-ft-mse
‚îÇ   ‚îú‚îÄ‚îÄ diffusion_pytorch_model.bin
‚îÇ   ‚îî‚îÄ‚îÄ config.json
‚îú‚îÄ‚îÄ sd-image-variations-diffusers
‚îÇ   ‚îú‚îÄ‚îÄ image_encoder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pytorch_model.bin
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.json
‚îÇ   ‚îú‚îÄ‚îÄ unet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ diffusion_pytorch_model.bin
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.json
‚îÇ   ‚îî‚îÄ‚îÄ model_index.json
‚îî‚îÄ‚îÄ tensorrt
    ‚îî‚îÄ‚îÄ unet_work.engine
```

### üéûÔ∏è Offline Inference
Run offline inference with the default configuration:

```
python inference_offline.py
```

* `-L`: Max number of frames to generate. (Default: 100)
* `--use_xformers`: Enable xFormers memory efficient attention. (Default: True)
* `--stream_gen`: Enable streaming generation strategy. (Default: True)
* `--reference_image`: Path to a specific reference image. Overrides settings in config.
* `--driving_video`: Path to a specific driving video. Overrides settings in config.

‚ö†Ô∏è Note for RTX 50-Series (Blackwell) Users: xformers is not yet fully compatible with the new architecture. To avoid crashes, please disable it by running:

```
python inference_offline.py --use_xformers False
```

### üì∏ Online Inference
#### üì¶ Setup Web UI
```
# install Node.js 18+
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash
nvm install 18

source web_start.sh
```

#### üèéÔ∏è Acceleration (Optional)
Converting the model to TensorRT can significantly speed up inference (~ 2x ‚ö°Ô∏è). Building the engine may take about `20 minutes` depending on your device. Note that TensorRT optimizations may lead to slight variations or a small drop in output quality.
```
# Install packages with pip
pip install -r requirements_trt.txt

# Converting the model to TensorRT
python torch2trt.py
```
üí° **PyCUDA Installation Issues**: If you encounter a &quot;Failed to build wheel for pycuda&quot; error during the installation above, please follow these steps:
```
# Install PyCUDA manually using Conda (avoids compilation issues):
conda install -c conda-forge pycuda &quot;numpy&lt;2.0&quot;

# Open requirements_trt.txt and comment out or remove the line &quot;pycuda==2024.1.2&quot;

# Install other packages with pip
pip install -r requirements_trt.txt

# Converting the model to TensorRT
python torch2trt.py
```
‚ö†Ô∏è The provided TensorRT model is from an `H100`. We recommend `ALL users` (including H100 users) re-run `python torch2trt.py` locally to ensure best compatibility.

#### ‚ñ∂Ô∏è Start Streaming
```
python inference_online.py --acceleration none (for RTX 50-Series) or xformers or tensorrt
```
Then open `http://0.0.0.0:7860` in your browser. (*If `http://0.0.0.0:7860` does not work well, try `http://localhost:7860`)

**How to use**: Upload Image ‚û°Ô∏è Fuse Reference ‚û°Ô∏è Start Animation ‚û°Ô∏è Enjoy! üéâ
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/guide.png&quot; alt=&quot;PersonaLive&quot; width=&quot;60%&quot;&gt;
&lt;/div&gt;

**Regarding Latency**: Latency varies depending on your device&#039;s computing power. You can try the following methods to optimize it:

1. Lower the &quot;Driving FPS&quot; setting in the WebUI to reduce the computational workload.
2. You can increase the multiplier (e.g., set to `num_frames_needed * 4` or higher) to better match your device&#039;s inference speed. https://github.com/GVCLab/PersonaLive/blob/6953d1a8b409f360a3ee1d7325093622b29f1e22/webcam/util.py#L73

## üìö Community Contribution

Special thanks to the community for providing helpful setups! ü•Ç

* **Windows + RTX 50-Series Guide**: Thanks to [@dknos](https://github.com/dknos) for providing a [detailed guide](https://github.com/GVCLab/PersonaLive/issues/10#issuecomment-3662785532) on running this project on Windows with Blackwell GPUs.

* **TensorRT on Windows**: If you are trying to convert TensorRT models on Windows, [this discussion](https://github.com/GVCLab/PersonaLive/issues/8) might be helpful. Special thanks to [@MaraScott](https://github.com/MaraScott) and [@Jeremy8776](https://github.com/Jeremy8776) for their insights.
  
* **ComfyUI**: Thanks to [@okdalto](https://github.com/okdalto) for helping implement the [ComfyUI-PersonaLive](https://github.com/okdalto/ComfyUI-PersonaLive) support.

* **Useful Scripts**: Thanks to [@suruoxi](https://github.com/suruoxi) for implementing `download_weights.py`, and to [@andchir](https://github.com/andchir) for adding audio merging functionality.

## üé¨ More Results
#### üëÄ Visualization results

&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/cdc885ef-5e1c-4139-987a-2fa50fefd6a4&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/014f7bae-74ce-4f56-8621-24bc76f3c123&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/1e6a0809-15d2-4cab-ae8f-8cf1728c6281&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/d9cf265d-9db0-4f83-81da-be967bbd5f26&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/86235139-b63e-4f26-b09c-d218466e8e24&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/238785de-3b4c-484e-9ad0-9d90e7962fee&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/c71c4717-d528-4a98-b132-2b0ec8cec22d&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/7e11fe71-fd16-4011-a6b2-2dbaf7e343fb&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/f62e2162-d239-4575-9514-34575c16301c&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/813e7fbd-37e9-47d7-a270-59887fafeca5&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

#### ü§∫ Comparisons

&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td width=&quot;100%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/36407cf9-bf82-43ff-9508-a794d223d3f7&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;100%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/3be99b91-c6a1-4ca4-89e9-8fad42bb9583&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;100%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/5bd21fe4-96ae-4be6-bf06-a7c476b04ec9&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;


## ‚≠ê Citation
If you find PersonaLive useful for your research, welcome to cite our work using the following BibTeX:
```bibtex
@article{li2025personalive,
  title={PersonaLive! Expressive Portrait Image Animation for Live Streaming},
  author={Li, Zhiyuan and Pun, Chi-Man and Fang, Chen and Wang, Jue and Cun, Xiaodong},
  journal={arXiv preprint arXiv:2512.11253},
  year={2025}
}
```

## ‚ù§Ô∏è Acknowledgement
This code is mainly built upon [Moore-AnimateAnyone](https://github.com/MooreThreads/Moore-AnimateAnyone), [X-NeMo](https://byteaigc.github.io/X-Portrait2/), [StreamDiffusion](https://github.com/cumulo-autumn/StreamDiffusion), [RAIN](https://pscgylotti.github.io/pages/RAIN/) and [LivePortrait](https://github.com/KlingTeam/LivePortrait), thanks to their invaluable contributions.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[TauricResearch/TradingAgents]]></title>
            <link>https://github.com/TauricResearch/TradingAgents</link>
            <guid>https://github.com/TauricResearch/TradingAgents</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:08 GMT</pubDate>
            <description><![CDATA[TradingAgents: Multi-Agents LLM Financial Trading Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/TauricResearch/TradingAgents">TauricResearch/TradingAgents</a></h1>
            <p>TradingAgents: Multi-Agents LLM Financial Trading Framework</p>
            <p>Language: Python</p>
            <p>Stars: 30,719</p>
            <p>Forks: 5,900</p>
            <p>Stars today: 123 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/TauricResearch.png&quot; style=&quot;width: 60%; height: auto;&quot;&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot; style=&quot;line-height: 1;&quot;&gt;
  &lt;a href=&quot;https://arxiv.org/abs/2412.20138&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;arXiv&quot; src=&quot;https://img.shields.io/badge/arXiv-2412.20138-B31B1B?logo=arxiv&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.com/invite/hk9PGKShPK&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/Discord-TradingResearch-7289da?logo=discord&amp;logoColor=white&amp;color=7289da&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;./assets/wechat.png&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;WeChat&quot; src=&quot;https://img.shields.io/badge/WeChat-TauricResearch-brightgreen?logo=wechat&amp;logoColor=white&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/TauricResearch&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;X Follow&quot; src=&quot;https://img.shields.io/badge/X-TauricResearch-white?logo=x&amp;logoColor=white&quot;/&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://github.com/TauricResearch/&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Community&quot; src=&quot;https://img.shields.io/badge/Join_GitHub_Community-TauricResearch-14C290?logo=discourse&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=de&quot;&gt;Deutsch&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=es&quot;&gt;Espa√±ol&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=fr&quot;&gt;fran√ßais&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=ja&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=ko&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=pt&quot;&gt;Portugu√™s&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=ru&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=zh&quot;&gt;‰∏≠Êñá&lt;/a&gt;
&lt;/div&gt;

---

# TradingAgents: Multi-Agents LLM Financial Trading Framework

## News
- [2026-02] **TradingAgents v0.2.0** released with multi-provider LLM support (GPT-5.x, Gemini 3.x, Claude 4.x, Grok 4.x) and improved system architecture.
- [2026-01] **Trading-R1** [Technical Report](https://arxiv.org/abs/2509.11420) released, with [Terminal](https://github.com/TauricResearch/Trading-R1) expected to land soon.

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.star-history.com/#TauricResearch/TradingAgents&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=TauricResearch/TradingAgents&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=TauricResearch/TradingAgents&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;TradingAgents Star History&quot; src=&quot;https://api.star-history.com/svg?repos=TauricResearch/TradingAgents&amp;type=Date&quot; style=&quot;width: 80%; height: auto;&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;

&gt; üéâ **TradingAgents** officially released! We have received numerous inquiries about the work, and we would like to express our thanks for the enthusiasm in our community.
&gt;
&gt; So we decided to fully open-source the framework. Looking forward to building impactful projects with you!

&lt;div align=&quot;center&quot;&gt;

üöÄ [TradingAgents](#tradingagents-framework) | ‚ö° [Installation &amp; CLI](#installation-and-cli) | üé¨ [Demo](https://www.youtube.com/watch?v=90gr5lwjIho) | üì¶ [Package Usage](#tradingagents-package) | ü§ù [Contributing](#contributing) | üìÑ [Citation](#citation)

&lt;/div&gt;

## TradingAgents Framework

TradingAgents is a multi-agent trading framework that mirrors the dynamics of real-world trading firms. By deploying specialized LLM-powered agents: from fundamental analysts, sentiment experts, and technical analysts, to trader, risk management team, the platform collaboratively evaluates market conditions and informs trading decisions. Moreover, these agents engage in dynamic discussions to pinpoint the optimal strategy.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/schema.png&quot; style=&quot;width: 100%; height: auto;&quot;&gt;
&lt;/p&gt;

&gt; TradingAgents framework is designed for research purposes. Trading performance may vary based on many factors, including the chosen backbone language models, model temperature, trading periods, the quality of data, and other non-deterministic factors. [It is not intended as financial, investment, or trading advice.](https://tauric.ai/disclaimer/)

Our framework decomposes complex trading tasks into specialized roles. This ensures the system achieves a robust, scalable approach to market analysis and decision-making.

### Analyst Team
- Fundamentals Analyst: Evaluates company financials and performance metrics, identifying intrinsic values and potential red flags.
- Sentiment Analyst: Analyzes social media and public sentiment using sentiment scoring algorithms to gauge short-term market mood.
- News Analyst: Monitors global news and macroeconomic indicators, interpreting the impact of events on market conditions.
- Technical Analyst: Utilizes technical indicators (like MACD and RSI) to detect trading patterns and forecast price movements.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/analyst.png&quot; width=&quot;100%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

### Researcher Team
- Comprises both bullish and bearish researchers who critically assess the insights provided by the Analyst Team. Through structured debates, they balance potential gains against inherent risks.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/researcher.png&quot; width=&quot;70%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

### Trader Agent
- Composes reports from the analysts and researchers to make informed trading decisions. It determines the timing and magnitude of trades based on comprehensive market insights.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/trader.png&quot; width=&quot;70%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

### Risk Management and Portfolio Manager
- Continuously evaluates portfolio risk by assessing market volatility, liquidity, and other risk factors. The risk management team evaluates and adjusts trading strategies, providing assessment reports to the Portfolio Manager for final decision.
- The Portfolio Manager approves/rejects the transaction proposal. If approved, the order will be sent to the simulated exchange and executed.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/risk.png&quot; width=&quot;70%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

## Installation and CLI

### Installation

Clone TradingAgents:
```bash
git clone https://github.com/TauricResearch/TradingAgents.git
cd TradingAgents
```

Create a virtual environment in any of your favorite environment managers:
```bash
conda create -n tradingagents python=3.13
conda activate tradingagents
```

Install dependencies:
```bash
pip install -r requirements.txt
```

### Required APIs

TradingAgents supports multiple LLM providers. Set the API key for your chosen provider:

```bash
export OPENAI_API_KEY=...          # OpenAI (GPT)
export GOOGLE_API_KEY=...          # Google (Gemini)
export ANTHROPIC_API_KEY=...       # Anthropic (Claude)
export XAI_API_KEY=...             # xAI (Grok)
export OPENROUTER_API_KEY=...      # OpenRouter
export ALPHA_VANTAGE_API_KEY=...   # Alpha Vantage
```

For local models, configure Ollama with `llm_provider: &quot;ollama&quot;` in your config.

Alternatively, copy `.env.example` to `.env` and fill in your keys:
```bash
cp .env.example .env
```

### CLI Usage

You can also try out the CLI directly by running:
```bash
python -m cli.main
```
You will see a screen where you can select your desired tickers, date, LLMs, research depth, etc.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/cli/cli_init.png&quot; width=&quot;100%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

An interface will appear showing results as they load, letting you track the agent&#039;s progress as it runs.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/cli/cli_news.png&quot; width=&quot;100%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/cli/cli_transaction.png&quot; width=&quot;100%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

## TradingAgents Package

### Implementation Details

We built TradingAgents with LangGraph to ensure flexibility and modularity. The framework supports multiple LLM providers: OpenAI, Google, Anthropic, xAI, OpenRouter, and Ollama.

### Python Usage

To use TradingAgents inside your code, you can import the `tradingagents` module and initialize a `TradingAgentsGraph()` object. The `.propagate()` function will return a decision. You can run `main.py`, here&#039;s also a quick example:

```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

ta = TradingAgentsGraph(debug=True, config=DEFAULT_CONFIG.copy())

# forward propagate
_, decision = ta.propagate(&quot;NVDA&quot;, &quot;2026-01-15&quot;)
print(decision)
```

You can also adjust the default configuration to set your own choice of LLMs, debate rounds, etc.

```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

config = DEFAULT_CONFIG.copy()
config[&quot;llm_provider&quot;] = &quot;openai&quot;        # openai, google, anthropic, xai, openrouter, ollama
config[&quot;deep_think_llm&quot;] = &quot;gpt-5.2&quot;     # Model for complex reasoning
config[&quot;quick_think_llm&quot;] = &quot;gpt-5-mini&quot; # Model for quick tasks
config[&quot;max_debate_rounds&quot;] = 2

ta = TradingAgentsGraph(debug=True, config=config)
_, decision = ta.propagate(&quot;NVDA&quot;, &quot;2026-01-15&quot;)
print(decision)
```

See `tradingagents/default_config.py` for all configuration options.

## Contributing

We welcome contributions from the community! Whether it&#039;s fixing a bug, improving documentation, or suggesting a new feature, your input helps make this project better. If you are interested in this line of research, please consider joining our open-source financial AI research community [Tauric Research](https://tauric.ai/).

## Citation

Please reference our work if you find *TradingAgents* provides you with some help :)

```
@misc{xiao2025tradingagentsmultiagentsllmfinancial,
      title={TradingAgents: Multi-Agents LLM Financial Trading Framework}, 
      author={Yijia Xiao and Edward Sun and Di Luo and Wei Wang},
      year={2025},
      eprint={2412.20138},
      archivePrefix={arXiv},
      primaryClass={q-fin.TR},
      url={https://arxiv.org/abs/2412.20138}, 
}
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[ComposioHQ/awesome-claude-skills]]></title>
            <link>https://github.com/ComposioHQ/awesome-claude-skills</link>
            <guid>https://github.com/ComposioHQ/awesome-claude-skills</guid>
            <pubDate>Thu, 26 Feb 2026 00:07:07 GMT</pubDate>
            <description><![CDATA[A curated list of awesome Claude Skills, resources, and tools for customizing Claude AI workflows]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ComposioHQ/awesome-claude-skills">ComposioHQ/awesome-claude-skills</a></h1>
            <p>A curated list of awesome Claude Skills, resources, and tools for customizing Claude AI workflows</p>
            <p>Language: Python</p>
            <p>Stars: 37,688</p>
            <p>Forks: 3,710</p>
            <p>Stars today: 345 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;Awesome Claude Skills&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://platform.composio.dev/?utm_source=Github&amp;utm_medium=Youtube&amp;utm_campaign=2025-11&amp;utm_content=AwesomeSkills&quot;&gt;
  &lt;img width=&quot;1280&quot; height=&quot;640&quot; alt=&quot;Composio banner&quot; src=&quot;https://github.com/user-attachments/assets/e91255af-e4ba-4d71-b1a8-bd081e8a234a&quot;&gt;
&lt;/a&gt;


&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://awesome.re&quot;&gt;
    &lt;img src=&quot;https://awesome.re/badge.svg&quot; alt=&quot;Awesome&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://makeapullrequest.com&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square&quot; alt=&quot;PRs Welcome&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.apache.org/licenses/LICENSE-2.0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/License-Apache_2.0-blue.svg?style=flat-square&quot; alt=&quot;License: Apache-2.0&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;div&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://twitter.com/composio&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Follow on X-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white&quot; alt=&quot;Follow on X&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.linkedin.com/company/composiohq/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Follow on LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white&quot; alt=&quot;Follow on LinkedIn&quot; /&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://discord.com/invite/composio&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Join our Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white&quot; alt=&quot;Join our Discord&quot; /&gt;
  &lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;

A curated list of practical Claude Skills for enhancing productivity across Claude.ai, Claude Code, and the Claude API.


&gt; **Want skills that do more than generate text?** Claude can send emails, create issues, post to Slack, and take actions across 1000+ apps. [See how ‚Üí](./connect/)

---

## Quickstart: Connect Claude to 500+ Apps

The **connect-apps** plugin lets Claude perform real actions - send emails, create issues, post to Slack. It handles auth and connects to 500+ apps using Composio under the hood.

### 1. Install the Plugin

```bash
claude --plugin-dir ./connect-apps-plugin
```

### 2. Run Setup

```
/connect-apps:setup
```

Paste your API key when asked. (Get a free key at [platform.composio.dev](https://platform.composio.dev/?utm_source=Github&amp;utm_content=AwesomeSkills))

### 3. Restart &amp; Try It

```bash
exit
claude
```

&gt; **Want skills that do more than generate text?** Claude can send emails, create issues, post to Slack, and take actions across 1000+ apps. [See how ‚Üí](./connect/)

If you receive the email, Claude is now connected to 500+ apps.

**[See all supported apps ‚Üí](https://composio.dev/toolkits)**

---

## Contents

- [What Are Claude Skills?](#what-are-claude-skills)
- [Skills](#skills)
  - [Document Processing](#document-processing)
  - [Development &amp; Code Tools](#development--code-tools)
  - [Data &amp; Analysis](#data--analysis)
  - [Business &amp; Marketing](#business--marketing)
  - [Communication &amp; Writing](#communication--writing)
  - [Creative &amp; Media](#creative--media)
  - [Productivity &amp; Organization](#productivity--organization)
  - [Collaboration &amp; Project Management](#collaboration--project-management)
  - [Security &amp; Systems](#security--systems)
  - [App Automation via Composio](#app-automation-via-composio)
- [Getting Started](#getting-started)
- [Creating Skills](#creating-skills)
- [Contributing](#contributing)
- [Resources](#resources)
- [License](#license)

## What Are Claude Skills?

Claude Skills are customizable workflows that teach Claude how to perform specific tasks according to your unique requirements. Skills enable Claude to execute tasks in a repeatable, standardized manner across all Claude platforms.

## Skills

### Document Processing

- [docx](https://github.com/anthropics/skills/tree/main/skills/docx) - Create, edit, analyze Word docs with tracked changes, comments, formatting.
- [pdf](https://github.com/anthropics/skills/tree/main/skills/pdf) - Extract text, tables, metadata, merge &amp; annotate PDFs.
- [pptx](https://github.com/anthropics/skills/tree/main/skills/pptx) - Read, generate, and adjust slides, layouts, templates.
- [xlsx](https://github.com/anthropics/skills/tree/main/skills/xlsx) - Spreadsheet manipulation: formulas, charts, data transformations.
- [Markdown to EPUB Converter](https://github.com/smerchek/claude-epub-skill) - Converts markdown documents and chat summaries into professional EPUB ebook files. *By [@smerchek](https://github.com/smerchek)*

### Development &amp; Code Tools

- [artifacts-builder](https://github.com/anthropics/skills/tree/main/skills/web-artifacts-builder) - Suite of tools for creating elaborate, multi-component claude.ai HTML artifacts using modern frontend web technologies (React, Tailwind CSS, shadcn/ui).
- [aws-skills](https://github.com/zxkane/aws-skills) - AWS development with CDK best practices, cost optimization MCP servers, and serverless/event-driven architecture patterns.
- [Changelog Generator](./changelog-generator/) - Automatically creates user-facing changelogs from git commits by analyzing history and transforming technical commits into customer-friendly release notes.
- [Claude Code Terminal Title](https://github.com/bluzername/claude-code-terminal-title) - Gives each Claud-Code terminal window a dynamic title that describes the work being done so you don&#039;t lose track of what window is doing what.
- [D3.js Visualization](https://github.com/chrisvoncsefalvay/claude-d3js-skill) - Teaches Claude to produce D3 charts and interactive data visualizations. *By [@chrisvoncsefalvay](https://github.com/chrisvoncsefalvay)*
- [FFUF Web Fuzzing](https://github.com/jthack/ffuf_claude_skill) - Integrates the ffuf web fuzzer so Claude can run fuzzing tasks and analyze results for vulnerabilities. *By [@jthack](https://github.com/jthack)*
- [finishing-a-development-branch](https://github.com/obra/superpowers/tree/main/skills/finishing-a-development-branch) - Guides completion of development work by presenting clear options and handling chosen workflow.
- [iOS Simulator](https://github.com/conorluddy/ios-simulator-skill) - Enables Claude to interact with iOS Simulator for testing and debugging iOS applications. *By [@conorluddy](https://github.com/conorluddy)*
- [jules](https://github.com/sanjay3290/ai-skills/tree/main/skills/jules) - Delegate coding tasks to Google Jules AI agent for async bug fixes, documentation, tests, and feature implementation on GitHub repos. *By [@sanjay3290](https://github.com/sanjay3290)*
- [LangSmith Fetch](./langsmith-fetch/) - Debug LangChain and LangGraph agents by automatically fetching and analyzing execution traces from LangSmith Studio. First AI observability skill for Claude Code. *By [@OthmanAdi](https://github.com/OthmanAdi)*
- [MCP Builder](./mcp-builder/) - Guides creation of high-quality MCP (Model Context Protocol) servers for integrating external APIs and services with LLMs using Python or TypeScript.
- [move-code-quality-skill](https://github.com/1NickPappas/move-code-quality-skill) - Analyzes Move language packages against the official Move Book Code Quality Checklist for Move 2024 Edition compliance and best practices.
- [Playwright Browser Automation](https://github.com/lackeyjb/playwright-skill) - Model-invoked Playwright automation for testing and validating web applications. *By [@lackeyjb](https://github.com/lackeyjb)*
- [prompt-engineering](https://github.com/NeoLabHQ/context-engineering-kit/tree/master/plugins/customaize-agent/skills/prompt-engineering) - Teaches well-known prompt engineering techniques and patterns, including Anthropic best practices and agent persuasion principles.
- [pypict-claude-skill](https://github.com/omkamal/pypict-claude-skill) - Design comprehensive test cases using PICT (Pairwise Independent Combinatorial Testing) for requirements or code, generating optimized test suites with pairwise coverage.
- [reddit-fetch](https://github.com/ykdojo/claude-code-tips/tree/main/skills/reddit-fetch) - Fetches Reddit content via Gemini CLI when WebFetch is blocked or returns 403 errors.
- [Skill Creator](./skill-creator/) - Provides guidance for creating effective Claude Skills that extend capabilities with specialized knowledge, workflows, and tool integrations.
- [Skill Seekers](https://github.com/yusufkaraaslan/Skill_Seekers) - Automatically converts any documentation website into a Claude AI skill in minutes. *By [@yusufkaraaslan](https://github.com/yusufkaraaslan)*
- [software-architecture](https://github.com/NeoLabHQ/context-engineering-kit/tree/master/plugins/ddd/skills/software-architecture) - Implements design patterns including Clean Architecture, SOLID principles, and comprehensive software design best practices.
- [subagent-driven-development](https://github.com/NeoLabHQ/context-engineering-kit/tree/master/plugins/sadd/skills/subagent-driven-development) - Dispatches independent subagents for individual tasks with code review checkpoints between iterations for rapid, controlled development.
- [test-driven-development](https://github.com/obra/superpowers/tree/main/skills/test-driven-development) - Use when implementing any feature or bugfix, before writing implementation code.
- [using-git-worktrees](https://github.com/obra/superpowers/blob/main/skills/using-git-worktrees/) - Creates isolated git worktrees with smart directory selection and safety verification.
- [Connect](./connect/) - Connect Claude to any app. Send emails, create issues, post messages, update databases - take real actions across Gmail, Slack, GitHub, Notion, and 1000+ services.
- [Webapp Testing](./webapp-testing/) - Tests local web applications using Playwright for verifying frontend functionality, debugging UI behavior, and capturing screenshots.

### Data &amp; Analysis

- [CSV Data Summarizer](https://github.com/coffeefuelbump/csv-data-summarizer-claude-skill) - Automatically analyzes CSV files and generates comprehensive insights with visualizations without requiring user prompts. *By [@coffeefuelbump](https://github.com/coffeefuelbump)*
- [deep-research](https://github.com/sanjay3290/ai-skills/tree/main/skills/deep-research) - Execute autonomous multi-step research using Gemini Deep Research Agent for market analysis, competitive landscaping, and literature reviews. *By [@sanjay3290](https://github.com/sanjay3290)*
- [postgres](https://github.com/sanjay3290/ai-skills/tree/main/skills/postgres) - Execute safe read-only SQL queries against PostgreSQL databases with multi-connection support and defense-in-depth security. *By [@sanjay3290](https://github.com/sanjay3290)*
- [root-cause-tracing](https://github.com/obra/superpowers/tree/main/skills/root-cause-tracing) - Use when errors occur deep in execution and you need to trace back to find the original trigger.

### Business &amp; Marketing

- [Brand Guidelines](./brand-guidelines/) - Applies Anthropic&#039;s official brand colors and typography to artifacts for consistent visual identity and professional design standards.
- [Competitive Ads Extractor](./competitive-ads-extractor/) - Extracts and analyzes competitors&#039; ads from ad libraries to understand messaging and creative approaches that resonate.
- [Domain Name Brainstormer](./domain-name-brainstormer/) - Generates creative domain name ideas and checks availability across multiple TLDs including .com, .io, .dev, and .ai extensions.
- [Internal Comms](./internal-comms/) - Helps write internal communications including 3P updates, company newsletters, FAQs, status reports, and project updates using company-specific formats.
- [Lead Research Assistant](./lead-research-assistant/) - Identifies and qualifies high-quality leads by analyzing your product, searching for target companies, and providing actionable outreach strategies.

### Communication &amp; Writing

- [article-extractor](https://github.com/michalparkola/tapestry-skills-for-claude-code/tree/main/article-extractor) - Extract full article text and metadata from web pages.
- [brainstorming](https://github.com/obra/superpowers/tree/main/skills/brainstorming) - Transform rough ideas into fully-formed designs through structured questioning and alternative exploration.
- [Content Research Writer](./content-research-writer/) - Assists in writing high-quality content by conducting research, adding citations, improving hooks, and providing section-by-section feedback.
- [family-history-research](https://github.com/emaynard/claude-family-history-research-skill) - Provides assistance with planning family history and genealogy research projects.
- [Meeting Insights Analyzer](./meeting-insights-analyzer/) - Analyzes meeting transcripts to uncover behavioral patterns including conflict avoidance, speaking ratios, filler words, and leadership style.
- [NotebookLM Integration](https://github.com/PleasePrompto/notebooklm-skill) - Lets Claude Code chat directly with NotebookLM for source-grounded answers based exclusively on uploaded documents. *By [@PleasePrompto](https://github.com/PleasePrompto)*
- [Twitter Algorithm Optimizer](./twitter-algorithm-optimizer/) - Analyze and optimize tweets for maximum reach using Twitter&#039;s open-source algorithm insights. Rewrite and edit tweets to improve engagement and visibility.

### Creative &amp; Media

- [Canvas Design](./canvas-design/) - Creates beautiful visual art in PNG and PDF documents using design philosophy and aesthetic principles for posters, designs, and static pieces.
- [imagen](https://github.com/sanjay3290/ai-skills/tree/main/skills/imagen) - Generate images using Google Gemini&#039;s image generation API for UI mockups, icons, illustrations, and visual assets. *By [@sanjay3290](https://github.com/sanjay3290)*
- [Image Enhancer](./image-enhancer/) - Improves image and screenshot quality by enhancing resolution, sharpness, and clarity for professional presentations and documentation.
- [Slack GIF Creator](./slack-gif-creator/) - Creates animated GIFs optimized for Slack with validators for size constraints and composable animation primitives.
- [Theme Factory](./theme-factory/) - Applies professional font and color themes to artifacts including slides, docs, reports, and HTML landing pages with 10 pre-set themes.
- [Video Downloader](./video-downloader/) - Downloads videos from YouTube and other platforms for offline viewing, editing, or archival with support for various formats and quality options.
- [youtube-transcript](https://github.com/michalparkola/tapestry-skills-for-claude-code/tree/main/youtube-transcript) - Fetch transcripts from YouTube videos and prepare summaries.

### Productivity &amp; Organization

- [File Organizer](./file-organizer/) - Intelligently organizes files and folders by understanding context, finding duplicates, and suggesting better organizational structures.
- [Invoice Organizer](./invoice-organizer/) - Automatically organizes invoices and receipts for tax preparation by reading files, extracting information, and renaming consistently.
- [kaizen](https://github.com/NeoLabHQ/context-engineering-kit/tree/master/plugins/kaizen/skills/kaizen) - Applies continuous improvement methodology with multiple analytical approaches, based on Japanese Kaizen philosophy and Lean methodology.
- [n8n-skills](https://github.com/haunchen/n8n-skills) - Enables AI assistants to directly understand and operate n8n workflows.
- [Raffle Winner Picker](./raffle-winner-picker/) - Randomly selects winners from lists, spreadsheets, or Google Sheets for giveaways and contests with cryptographically secure randomness.
- [Tailored Resume Generator](./tailored-resume-generator/) - Analyzes job descriptions and generates tailored resumes that highlight relevant experience, skills, and achievements to maximize interview chances.
- [ship-learn-next](https://github.com/michalparkola/tapestry-skills-for-claude-code/tree/main/ship-learn-next) - Skill to help iterate on what to build or learn next, based on feedback loops.
- [tapestry](https://github.com/michalparkola/tapestry-skills-for-claude-code/tree/main/tapestry) - Interlink and summarize related documents into knowledge networks.

### Collaboration &amp; Project Management

- [git-pushing](https://github.com/mhattingpete/claude-skills-marketplace/tree/main/engineering-workflow-plugin/skills/git-pushing) - Automate git operations and repository interactions.
- [google-workspace-skills](https://github.com/sanjay3290/ai-skills/tree/main/skills) - Suite of Google Workspace integrations: Gmail, Calendar, Chat, Docs, Sheets, Slides, and Drive with cross-platform OAuth. *By [@sanjay3290](https://github.com/sanjay3290)*
- [outline](https://github.com/sanjay3290/ai-skills/tree/main/skills/outline) - Search, read, create, and manage documents in Outline wiki instances (cloud or self-hosted). *By [@sanjay3290](https://github.com/sanjay3290)*
- [review-implementing](https://github.com/mhattingpete/claude-skills-marketplace/tree/main/engineering-workflow-plugin/skills/review-implementing) - Evaluate code implementation plans and align with specs.
- [test-fixing](https://github.com/mhattingpete/claude-skills-marketplace/tree/main/engineering-workflow-plugin/skills/test-fixing) - Detect failing tests and propose patches or fixes.

### Security &amp; Systems

- [computer-forensics](https://github.com/mhattingpete/claude-skills-marketplace/tree/main/computer-forensics-skills/skills/computer-forensics) - Digital forensics analysis and investigation techniques.
- [file-deletion](https://github.com/mhattingpete/claude-skills-marketplace/tree/main/computer-forensics-skills/skills/file-deletion) - Secure file deletion and data sanitization methods.
- [metadata-extraction](https://github.com/mhattingpete/claude-skills-marketplace/tree/main/computer-forensics-skills/skills/metadata-extraction) - Extract and analyze file metadata for forensic purposes.
- [threat-hunting-with-sigma-rules](https://github.com/jthack/threat-hunting-with-sigma-rules-skill) - Use Sigma detection rules to hunt for threats and analyze security events.

### App Automation via Composio

Pre-built workflow skills for 78 SaaS apps via [Rube MCP (Composio)](https://composio.dev). Each skill includes tool sequences, parameter guidance, known pitfalls, and quick reference tables ‚Äî all using real tool slugs discovered from Composio&#039;s API.

**CRM &amp; Sales**
- [Close Automation](./close-automation/) - Automate Close CRM: leads, contacts, opportunities, activities, and pipelines.
- [HubSpot Automation](./hubspot-automation/) - Automate HubSpot CRM: contacts, deals, companies, tickets, and email engagement.
- [Pipedrive Automation](./pipedrive-automation/) - Automate Pipedrive: deals, contacts, organizations, activities, and pipelines.
- [Salesforce Automation](./salesforce-automation/) - Automate Salesforce: objects, records, SOQL queries, and bulk operations.
- [Zoho CRM Automation](./zoho-crm-automation/) - Automate Zoho CRM: leads, contacts, deals, accounts, and modules.

**Project Management**
- [Asana Automation](./asana-automation/) - Automate Asana: tasks, projects, sections, assignments, and workspaces.
- [Basecamp Automation](./basecamp-automation/) - Automate Basecamp: to-do lists, messages, people, groups, and projects.
- [ClickUp Automation](./clickup-automation/) - Automate ClickUp: tasks, lists, spaces, goals, and time tracking.
- [Jira Automation](./jira-automation/) - Automate Jira: issues, projects, boards, sprints, and JQL queries.
- [Linear Automation](./linear-automation/) - Automate Linear: issues, projects, cycles, teams, and workflows.
- [Monday Automation](./monday-automation/) - Automate Monday.com: boards, items, columns, groups, and workspaces.
- [Notion Automation](./notion-automation/) - Automate Notion: pages, databases, blocks, comments, and search.
- [Todoist Automation](./todoist-automation/) - Automate Todoist: tasks, projects, sections, labels, and filters.
- [Trello Automation](./trello-automation/) - Automate Trello: boards, cards, lists, members, and checklists.
- [Wrike Automation](./wrike-automation/) - Automate Wrike: tasks, folders, projects, comments, and workflows.

**Communic

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>