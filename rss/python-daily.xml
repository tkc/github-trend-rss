<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Mon, 29 Dec 2025 00:05:00 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[TheAlgorithms/Python]]></title>
            <link>https://github.com/TheAlgorithms/Python</link>
            <guid>https://github.com/TheAlgorithms/Python</guid>
            <pubDate>Mon, 29 Dec 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[All Algorithms implemented in Python]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/TheAlgorithms/Python">TheAlgorithms/Python</a></h1>
            <p>All Algorithms implemented in Python</p>
            <p>Language: Python</p>
            <p>Stars: 215,825</p>
            <p>Forks: 49,762</p>
            <p>Stars today: 372 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;!-- Title: --&gt;
  &lt;a href=&quot;https://github.com/TheAlgorithms/&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/TheAlgorithms/website/1cd824df116b27029f17c2d1b42d81731f28a920/public/logo.svg&quot; height=&quot;100&quot;&gt;
  &lt;/a&gt;
  &lt;h1&gt;&lt;a href=&quot;https://github.com/TheAlgorithms/&quot;&gt;The Algorithms&lt;/a&gt; - Python&lt;/h1&gt;

&lt;!-- Labels: --&gt;
  &lt;!-- First row: --&gt;
  &lt;a href=&quot;https://gitpod.io/#https://github.com/TheAlgorithms/Python&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Gitpod-Ready--to--Code-blue?logo=gitpod&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Gitpod Ready-to-Code&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/TheAlgorithms/Python/blob/master/CONTRIBUTING.md&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/static/v1.svg?label=Contributions&amp;message=Welcome&amp;color=0059b3&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Contributions Welcome&quot;&gt;
  &lt;/a&gt;
  &lt;img src=&quot;https://img.shields.io/github/repo-size/TheAlgorithms/Python.svg?label=Repo%20size&amp;style=flat-square&quot; height=&quot;20&quot;&gt;
  &lt;a href=&quot;https://the-algorithms.com/discord&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/discord/808045925556682782.svg?logo=discord&amp;colorB=7289DA&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Discord chat&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://gitter.im/TheAlgorithms/community&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Chat-Gitter-ff69b4.svg?label=Chat&amp;logo=gitter&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;Gitter chat&quot;&gt;
  &lt;/a&gt;

  &lt;!-- Second row: --&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://github.com/TheAlgorithms/Python/actions&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/actions/workflow/status/TheAlgorithms/Python/build.yml?branch=master&amp;label=CI&amp;logo=github&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;GitHub Workflow Status&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/pre-commit/pre-commit&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/pre--commit-enabled-brightgreen?logo=pre-commit&amp;logoColor=white&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;pre-commit&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://docs.astral.sh/ruff/formatter/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/static/v1?label=code%20style&amp;message=ruff&amp;color=black&amp;style=flat-square&quot; height=&quot;20&quot; alt=&quot;code style: black&quot;&gt;
  &lt;/a&gt;

&lt;!-- Short description: --&gt;
  &lt;h3&gt;All algorithms implemented in Python - for education ğŸ“š&lt;/h3&gt;
&lt;/div&gt;

Implementations are for learning purposes only. They may be less efficient than the implementations in the Python standard library. Use them at your discretion.

## ğŸš€ Getting Started

ğŸ“‹ Read through our [Contribution Guidelines](CONTRIBUTING.md) before you contribute.

## ğŸŒ Community Channels

We are on [Discord](https://the-algorithms.com/discord) and [Gitter](https://gitter.im/TheAlgorithms/community)! Community channels are a great way for you to ask questions and get help. Please join us!

## ğŸ“œ List of Algorithms

See our [directory](DIRECTORY.md) for easier navigation and a better overview of the project.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Shubhamsaboo/awesome-llm-apps]]></title>
            <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
            <guid>https://github.com/Shubhamsaboo/awesome-llm-apps</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Shubhamsaboo/awesome-llm-apps">Shubhamsaboo/awesome-llm-apps</a></h1>
            <p>Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.</p>
            <p>Language: Python</p>
            <p>Stars: 84,847</p>
            <p>Forks: 12,061</p>
            <p>Stars today: 395 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;http://www.theunwindai.com&quot;&gt;
    &lt;img src=&quot;docs/banner/unwind_black.png&quot; width=&quot;900px&quot; alt=&quot;Unwind AI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.linkedin.com/in/shubhamsaboo/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;style=flat-square&quot; alt=&quot;LinkedIn&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/Saboo_Shubham_&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/Shubham_Saboo&quot; alt=&quot;Twitter&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de&quot;&gt;Deutsch&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es&quot;&gt;EspaÃ±ol&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr&quot;&gt;franÃ§ais&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja&quot;&gt;æ—¥æœ¬èª&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko&quot;&gt;í•œêµ­ì–´&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt&quot;&gt;PortuguÃªs&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru&quot;&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh&quot;&gt;ä¸­æ–‡&lt;/a&gt;
&lt;/p&gt;

&lt;hr/&gt;

# ğŸŒŸ Awesome LLM Apps

A curated collection of **Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.** This repository features LLM apps that use models from &lt;img src=&quot;https://cdn.simpleicons.org/openai&quot;  alt=&quot;openai logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**OpenAI** , &lt;img src=&quot;https://cdn.simpleicons.org/anthropic&quot;  alt=&quot;anthropic logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Anthropic**, &lt;img src=&quot;https://cdn.simpleicons.org/googlegemini&quot;  alt=&quot;google logo&quot; width=&quot;25&quot; height=&quot;18&quot;&gt;**Google**, &lt;img src=&quot;https://cdn.simpleicons.org/x&quot;  alt=&quot;X logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**xAI** and open-source models like &lt;img src=&quot;https://cdn.simpleicons.org/alibabacloud&quot;  alt=&quot;alibaba logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Qwen** or  &lt;img src=&quot;https://cdn.simpleicons.org/meta&quot;  alt=&quot;meta logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt;**Llama** that you can run locally on your computer.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/9876&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/9876&quot; alt=&quot;Shubhamsaboo%2Fawesome-llm-apps | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## ğŸ¤” Why Awesome LLM Apps?

- ğŸ’¡ Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.
- ğŸ”¥ Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp; RAG.
- ğŸ“ Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.

## ğŸ™ Thanks to our sponsors

&lt;table align=&quot;center&quot; cellpadding=&quot;16&quot; cellspacing=&quot;12&quot;&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://tsdb.co/shubham-gh&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;Tiger Data&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsors/tigerdata.png&quot; alt=&quot;Tiger Data&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://tsdb.co/shubham-gh&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Tiger Data MCP
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://github.com/speechmatics/speechmatics-academy&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; title=&quot;Speechmatics&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsors/speechmatics.png&quot; alt=&quot;Speechmatics&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://github.com/speechmatics/speechmatics-academy&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Speechmatics
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://okara.ai/?utm_source=oss&amp;utm_medium=sponsorship&amp;utm_campaign=awesome-llm-apps&quot; title=&quot;Okara&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsors/okara.png&quot; alt=&quot;Okara&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://okara.ai/?utm_source=oss&amp;utm_medium=sponsorship&amp;utm_campaign=awesome-llm-apps&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Okara AI
      &lt;/a&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;a href=&quot;https://sponsorunwindai.com/&quot; title=&quot;Become a Sponsor&quot;&gt;
        &lt;img src=&quot;docs/banner/sponsor_awesome_llm_apps.png&quot; alt=&quot;Become a Sponsor&quot; width=&quot;500&quot;&gt;
      &lt;/a&gt;
      &lt;br&gt;
      &lt;a href=&quot;https://sponsorunwindai.com/&quot; style=&quot;text-decoration: none; color: #333; font-weight: bold; font-size: 18px;&quot;&gt;
        Become a Sponsor
      &lt;/a&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

## ğŸ“‚ Featured AI Projects

### AI Agents

### ğŸŒ± Starter AI Agents

*   [ğŸ™ï¸ AI Blog to Podcast Agent](starter_ai_agents/ai_blog_to_podcast_agent/)
*   [â¤ï¸â€ğŸ©¹ AI Breakup Recovery Agent](starter_ai_agents/ai_breakup_recovery_agent/)
*   [ğŸ“Š AI Data Analysis Agent](starter_ai_agents/ai_data_analysis_agent/)
*   [ğŸ©» AI Medical Imaging Agent](starter_ai_agents/ai_medical_imaging_agent/)
*   [ğŸ˜‚ AI Meme Generator Agent (Browser)](starter_ai_agents/ai_meme_generator_agent_browseruse/)
*   [ğŸµ AI Music Generator Agent](starter_ai_agents/ai_music_generator_agent/)
*   [ğŸ›« AI Travel Agent (Local &amp; Cloud)](starter_ai_agents/ai_travel_agent/)
*   [âœ¨ Gemini Multimodal Agent](starter_ai_agents/gemini_multimodal_agent_demo/)
*   [ğŸ”„ Mixture of Agents](starter_ai_agents/mixture_of_agents/)
*   [ğŸ“Š xAI Finance Agent](starter_ai_agents/xai_finance_agent/)
*   [ğŸ” OpenAI Research Agent](starter_ai_agents/opeani_research_agent/)
*   [ğŸ•¸ï¸ Web Scraping AI Agent (Local &amp; Cloud SDK)](starter_ai_agents/web_scrapping_ai_agent/)

### ğŸš€ Advanced AI Agents
*   [ğŸšï¸ ğŸŒ AI Home Renovation Agent with Nano Banana](advanced_ai_agents/multi_agent_apps/ai_home_renovation_agent)
*   [ğŸ” AI Deep Research Agent](advanced_ai_agents/single_agent_apps/ai_deep_research_agent/)
*   [ğŸ¤ AI Consultant Agent](advanced_ai_agents/single_agent_apps/ai_consultant_agent)
*   [ğŸ—ï¸ AI System Architect Agent](advanced_ai_agents/single_agent_apps/ai_system_architect_r1/)
*   [ğŸ’° AI Financial Coach Agent](advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/)
*   [ğŸ¬ AI Movie Production Agent](advanced_ai_agents/single_agent_apps/ai_movie_production_agent/)
*   [ğŸ“ˆ AI Investment Agent](advanced_ai_agents/single_agent_apps/ai_investment_agent/)
*   [ğŸ‹ï¸â€â™‚ï¸ AI Health &amp; Fitness Agent](advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/)
*   [ğŸš€ AI Product Launch Intelligence Agent](advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent)
*   [ğŸ—ï¸ AI Journalist Agent](advanced_ai_agents/single_agent_apps/ai_journalist_agent/)
*   [ğŸ§  AI Mental Wellbeing Agent](advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/)
*   [ğŸ“‘ AI Meeting Agent](advanced_ai_agents/single_agent_apps/ai_meeting_agent/)
*   [ğŸ§¬ AI Self-Evolving Agent](advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/)
*   [ğŸ§ AI Social Media News and Podcast Agent](advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/)

### ğŸ® Autonomous Game Playing Agents

*   [ğŸ® AI 3D Pygame Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/)
*   [â™œ AI Chess Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/)
*   [ğŸ² AI Tic-Tac-Toe Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/)

### ğŸ¤ Multi-agent Teams

*   [ğŸ§² AI Competitor Intelligence Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/)
*   [ğŸ’² AI Finance Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/)
*   [ğŸ¨ AI Game Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/)
*   [ğŸ‘¨â€âš–ï¸ AI Legal Agent Team (Cloud &amp; Local)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/)
*   [ğŸ’¼ AI Recruitment Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/)
*   [ğŸ  AI Real Estate Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team)
*   [ğŸ‘¨â€ğŸ’¼ AI Services Agency (CrewAI)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/)
*   [ğŸ‘¨â€ğŸ« AI Teaching Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/)
*   [ğŸ’» Multimodal Coding Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/)
*   [âœ¨ Multimodal Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/)
*   [ğŸ¨ ğŸŒ Multimodal UI/UX Feedback Agent Team with Nano Banana](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_uiux_feedback_agent_team/)
*   [ğŸŒ AI Travel Planner Agent Team](/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/)

### ğŸ—£ï¸ Voice AI Agents

*   [ğŸ—£ï¸ AI Audio Tour Agent](voice_ai_agents/ai_audio_tour_agent/)
*   [ğŸ“ Customer Support Voice Agent](voice_ai_agents/customer_support_voice_agent/)
*   [ğŸ”Š Voice RAG Agent (OpenAI SDK)](voice_ai_agents/voice_rag_openaisdk/)


### &lt;img src=&quot;https://cdn.simpleicons.org/modelcontextprotocol&quot;  alt=&quot;mcp logo&quot; width=&quot;25&quot; height=&quot;20&quot;&gt; MCP AI Agents 

*   [â™¾ï¸ Browser MCP Agent](mcp_ai_agents/browser_mcp_agent/)
*   [ğŸ™ GitHub MCP Agent](mcp_ai_agents/github_mcp_agent/)
*   [ğŸ“‘ Notion MCP Agent](mcp_ai_agents/notion_mcp_agent) 
*   [ğŸŒ AI Travel Planner MCP Agent](mcp_ai_agents/ai_travel_planner_mcp_agent_team)

### ğŸ“€ RAG (Retrieval Augmented Generation)
*   [ğŸ”¥ Agentic RAG with Embedding Gemma](rag_tutorials/agentic_rag_embedding_gemma)
*   [ğŸ§ Agentic RAG with Reasoning](rag_tutorials/agentic_rag_with_reasoning/)
*   [ğŸ“° AI Blog Search (RAG)](rag_tutorials/ai_blog_search/)
*   [ğŸ” Autonomous RAG](rag_tutorials/autonomous_rag/)
*   [ğŸ”„ Contextual AI RAG Agent](rag_tutorials/contextualai_rag_agent/)
*   [ğŸ”„ Corrective RAG (CRAG)](rag_tutorials/corrective_rag/)
*   [ğŸ‹ Deepseek Local RAG Agent](rag_tutorials/deepseek_local_rag_agent/)
*   [ğŸ¤” Gemini Agentic RAG](rag_tutorials/gemini_agentic_rag/)
*   [ğŸ‘€ Hybrid Search RAG (Cloud)](rag_tutorials/hybrid_search_rag/)
*   [ğŸ”„ Llama 3.1 Local RAG](rag_tutorials/llama3.1_local_rag/)
*   [ğŸ–¥ï¸ Local Hybrid Search RAG](rag_tutorials/local_hybrid_search_rag/)
*   [ğŸ¦™ Local RAG Agent](rag_tutorials/local_rag_agent/)
*   [ğŸ§© RAG-as-a-Service](rag_tutorials/rag-as-a-service/)
*   [âœ¨ RAG Agent with Cohere](rag_tutorials/rag_agent_cohere/)
*   [â›“ï¸ Basic RAG Chain](rag_tutorials/rag_chain/)
*   [ğŸ“  RAG with Database Routing](rag_tutorials/rag_database_routing/)
*   [ğŸ–¼ï¸ Vision RAG](rag_tutorials/vision_rag/)

### ğŸ’¾ LLM Apps with Memory Tutorials

*   [ğŸ’¾ AI ArXiv Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/)
*   [ğŸ›©ï¸ AI Travel Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/)
*   [ğŸ’¬ Llama3 Stateful Chat](advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/)
*   [ğŸ“ LLM App with Personalized Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/)
*   [ğŸ—„ï¸ Local ChatGPT Clone with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/)
*   [ğŸ§  Multi-LLM Application with Shared Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/)


### ğŸ’¬ Chat with X Tutorials

*   [ğŸ’¬ Chat with GitHub (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_github/)
*   [ğŸ“¨ Chat with Gmail](advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/)
*   [ğŸ“„ Chat with PDF (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/)
*   [ğŸ“š Chat with Research Papers (ArXiv) (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/)
*   [ğŸ“ Chat with Substack](advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/)
*   [ğŸ“½ï¸ Chat with YouTube Videos](advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/)

### ğŸ¯ LLM Optimization Tools

*   [ğŸ¯ Toonify Token Optimization](advanced_llm_apps/llm_optimization_tools/toonify_token_optimization/) - Reduce LLM API costs by 30-60% using TOON format

### ğŸ”§ LLM Fine-tuning Tutorials

* &lt;img src=&quot;https://cdn.simpleicons.org/google&quot;  alt=&quot;google logo&quot; width=&quot;20&quot; height=&quot;15&quot;&gt; [Gemma 3 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/gemma3_finetuning/)
* &lt;img src=&quot;https://cdn.simpleicons.org/meta&quot;  alt=&quot;meta logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [Llama 3.2 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/)


### ğŸ§‘â€ğŸ« AI Agent Framework Crash Course

&lt;img src=&quot;https://cdn.simpleicons.org/google&quot;  alt=&quot;google logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [Google ADK Crash Course](ai_agent_framework_crash_course/google_adk_crash_course/)
  - Starter agent; modelâ€‘agnostic (OpenAI, Claude)
  - Structured outputs (Pydantic)
  - Tools: builtâ€‘in, function, thirdâ€‘party, MCP tools
  - Memory; callbacks; Plugins
  - Simple multiâ€‘agent; Multiâ€‘agent patterns

&lt;img src=&quot;https://cdn.simpleicons.org/openai&quot;  alt=&quot;openai logo&quot; width=&quot;25&quot; height=&quot;15&quot;&gt; [OpenAI Agents SDK Crash Course](ai_agent_framework_crash_course/openai_sdk_crash_course/)
  - Starter agent; function calling; structured outputs
  - Tools: builtâ€‘in, function, thirdâ€‘party integrations
  - Memory; callbacks; evaluation
  - Multiâ€‘agent patterns; agent handoffs
  - Swarm orchestration; routing logic

## ğŸš€ Getting Started

1. **Clone the repository** 

    ```bash 
    git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
    ```

2. **Navigate to the desired project directory**

    ```bash 
    cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
    ```

3. **Install the required dependencies**

    ```bash
    pip install -r requirements.txt
    ```

4. **Follow the project-specific instructions** in each project&#039;s `README.md` file to set up and run the app.


### &lt;img src=&quot;https://cdn.simpleicons.org/github&quot;  alt=&quot;github logo&quot; width=&quot;25&quot; height=&quot;20&quot;&gt; Thank You, Community, for the Support! ğŸ™

[![Star History Chart](https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;type=Date)](https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;Date)

ğŸŒŸ **Donâ€™t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.**
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[wshobson/agents]]></title>
            <link>https://github.com/wshobson/agents</link>
            <guid>https://github.com/wshobson/agents</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[Intelligent automation and multi-agent orchestration for Claude Code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wshobson/agents">wshobson/agents</a></h1>
            <p>Intelligent automation and multi-agent orchestration for Claude Code</p>
            <p>Language: Python</p>
            <p>Stars: 23,731</p>
            <p>Forks: 2,628</p>
            <p>Stars today: 93 stars today</p>
            <h2>README</h2><pre># Claude Code Plugins: Orchestration and Automation

&gt; **âš¡ Updated for Opus 4.5, Sonnet 4.5 &amp; Haiku 4.5** â€” Three-tier model strategy for optimal performance

[![Run in Smithery](https://smithery.ai/badge/skills/wshobson)](https://smithery.ai/skills?ns=wshobson&amp;utm_source=github&amp;utm_medium=badge)

&gt; **ğŸ¯ Agent Skills Enabled** â€” 107 specialized skills extend Claude&#039;s capabilities across plugins with progressive disclosure

A comprehensive production-ready system combining **99 specialized AI agents**, **15 multi-agent workflow orchestrators**, **107 agent skills**, and **71 development tools** organized into **67 focused, single-purpose plugins** for [Claude Code](https://docs.claude.com/en/docs/claude-code/overview).

## Overview

This unified repository provides everything needed for intelligent automation and multi-agent orchestration across modern software development:

- **67 Focused Plugins** - Granular, single-purpose plugins optimized for minimal token usage and composability
- **99 Specialized Agents** - Domain experts with deep knowledge across architecture, languages, infrastructure, quality, data/AI, documentation, business operations, and SEO
- **107 Agent Skills** - Modular knowledge packages with progressive disclosure for specialized expertise
- **15 Workflow Orchestrators** - Multi-agent coordination systems for complex operations like full-stack development, security hardening, ML pipelines, and incident response
- **71 Development Tools** - Optimized utilities including project scaffolding, security scanning, test automation, and infrastructure setup

### Key Features

- **Granular Plugin Architecture**: 67 focused plugins optimized for minimal token usage
- **Comprehensive Tooling**: 71 development tools including test generation, scaffolding, and security scanning
- **100% Agent Coverage**: All plugins include specialized agents
- **Agent Skills**: 107 specialized skills following for progressive disclosure and token efficiency
- **Clear Organization**: 23 categories with 1-6 plugins each for easy discovery
- **Efficient Design**: Average 3.4 components per plugin (follows Anthropic&#039;s 2-8 pattern)

### How It Works

Each plugin is completely isolated with its own agents, commands, and skills:

- **Install only what you need** - Each plugin loads only its specific agents, commands, and skills
- **Minimal token usage** - No unnecessary resources loaded into context
- **Mix and match** - Compose multiple plugins for complex workflows
- **Clear boundaries** - Each plugin has a single, focused purpose
- **Progressive disclosure** - Skills load knowledge only when activated

**Example**: Installing `python-development` loads 3 Python agents, 1 scaffolding tool, and makes 5 skills available (~300 tokens), not the entire marketplace.

## Quick Start

### Step 1: Add the Marketplace

Add this marketplace to Claude Code:

```bash
/plugin marketplace add wshobson/agents
```

This makes all 67 plugins available for installation, but **does not load any agents or tools** into your context.

### Step 2: Install Plugins

Browse available plugins:

```bash
/plugin
```

Install the plugins you need:

```bash
# Essential development plugins
/plugin install python-development          # Python with 5 specialized skills
/plugin install javascript-typescript       # JS/TS with 4 specialized skills
/plugin install backend-development         # Backend APIs with 3 architecture skills

# Infrastructure &amp; operations
/plugin install kubernetes-operations       # K8s with 4 deployment skills
/plugin install cloud-infrastructure        # AWS/Azure/GCP with 4 cloud skills

# Security &amp; quality
/plugin install security-scanning           # SAST with security skill
/plugin install code-review-ai             # AI-powered code review

# Full-stack orchestration
/plugin install full-stack-orchestration   # Multi-agent workflows
```

Each installed plugin loads **only its specific agents, commands, and skills** into Claude&#039;s context.

## Documentation

### Core Guides

- **[Plugin Reference](docs/plugins.md)** - Complete catalog of all 67 plugins
- **[Agent Reference](docs/agents.md)** - All 99 agents organized by category
- **[Agent Skills](docs/agent-skills.md)** - 107 specialized skills with progressive disclosure
- **[Usage Guide](docs/usage.md)** - Commands, workflows, and best practices
- **[Architecture](docs/architecture.md)** - Design principles and patterns

### Quick Links

- [Installation](#quick-start) - Get started in 2 steps
- [Essential Plugins](docs/plugins.md#quick-start---essential-plugins) - Top plugins for immediate productivity
- [Command Reference](docs/usage.md#command-reference-by-category) - All slash commands organized by category
- [Multi-Agent Workflows](docs/usage.md#multi-agent-workflow-examples) - Pre-configured orchestration examples
- [Model Configuration](docs/agents.md#model-configuration) - Haiku/Sonnet hybrid orchestration

## What&#039;s New

### Agent Skills (107 skills across 18 plugins)

Specialized knowledge packages following Anthropic&#039;s progressive disclosure architecture:

**Language Development:**
- **Python** (5 skills): async patterns, testing, packaging, performance, UV package manager
- **JavaScript/TypeScript** (4 skills): advanced types, Node.js patterns, testing, modern ES6+

**Infrastructure &amp; DevOps:**
- **Kubernetes** (4 skills): manifests, Helm charts, GitOps, security policies
- **Cloud Infrastructure** (4 skills): Terraform, multi-cloud, hybrid networking, cost optimization
- **CI/CD** (4 skills): pipeline design, GitHub Actions, GitLab CI, secrets management

**Development &amp; Architecture:**
- **Backend** (3 skills): API design, architecture patterns, microservices
- **LLM Applications** (4 skills): LangChain, prompt engineering, RAG, evaluation

**Blockchain &amp; Web3** (4 skills): DeFi protocols, NFT standards, Solidity security, Web3 testing

**And more:** Framework migration, observability, payment processing, ML operations, security scanning

[â†’ View complete skills documentation](docs/agent-skills.md)

### Three-Tier Model Strategy

Strategic model assignment for optimal performance and cost:

| Tier | Model | Agents | Use Case |
|------|-------|--------|----------|
| **Tier 1** | Opus 4.5 | 42 | Critical architecture, security, ALL code review, production coding (language pros, frameworks) |
| **Tier 2** | Inherit | 42 | Complex tasks - user chooses model (AI/ML, backend, frontend/mobile, specialized) |
| **Tier 3** | Sonnet | 51 | Support with intelligence (docs, testing, debugging, network, API docs, DX, legacy, payments) |
| **Tier 4** | Haiku | 18 | Fast operational tasks (SEO, deployment, simple docs, sales, content, search) |

**Why Opus 4.5 for Critical Agents?**
- 80.9% on SWE-bench (industry-leading)
- 65% fewer tokens for complex tasks
- Best for architecture decisions and security audits

**Tier 2 Flexibility (`inherit`):**
Agents marked `inherit` use your session&#039;s default model, letting you balance cost and capability:
- Set via `claude --model opus` or `claude --model sonnet` when starting a session
- Falls back to Sonnet 4.5 if no default specified
- Perfect for frontend/mobile developers who want cost control
- AI/ML engineers can choose Opus for complex model work

**Cost Considerations:**
- **Opus 4.5**: $5/$25 per million input/output tokens - Premium for critical work
- **Sonnet 4.5**: $3/$15 per million tokens - Balanced performance/cost
- **Haiku 4.5**: $1/$5 per million tokens - Fast, cost-effective operations
- Opus&#039;s 65% token reduction on complex tasks often offsets higher rate
- Use `inherit` tier to control costs for high-volume use cases

Orchestration patterns combine models for efficiency:
```
Opus (architecture) â†’ Sonnet (development) â†’ Haiku (deployment)
```

[â†’ View model configuration details](docs/agents.md#model-configuration)

## Popular Use Cases

### Full-Stack Feature Development

```bash
/full-stack-orchestration:full-stack-feature &quot;user authentication with OAuth2&quot;
```

Coordinates 7+ agents: backend-architect â†’ database-architect â†’ frontend-developer â†’ test-automator â†’ security-auditor â†’ deployment-engineer â†’ observability-engineer

[â†’ View all workflow examples](docs/usage.md#multi-agent-workflow-examples)

### Security Hardening

```bash
/security-scanning:security-hardening --level comprehensive
```

Multi-agent security assessment with SAST, dependency scanning, and code review.

### Python Development with Modern Tools

```bash
/python-development:python-scaffold fastapi-microservice
```

Creates production-ready FastAPI project with async patterns, activating skills:
- `async-python-patterns` - AsyncIO and concurrency
- `python-testing-patterns` - pytest and fixtures
- `uv-package-manager` - Fast dependency management

### Kubernetes Deployment

```bash
# Activates k8s skills automatically
&quot;Create production Kubernetes deployment with Helm chart and GitOps&quot;
```

Uses kubernetes-architect agent with 4 specialized skills for production-grade configs.

[â†’ View complete usage guide](docs/usage.md)

## Plugin Categories

**23 categories, 67 plugins:**

- ğŸ¨ **Development** (4) - debugging, backend, frontend, multi-platform
- ğŸ“š **Documentation** (3) - code docs, API specs, diagrams, C4 architecture
- ğŸ”„ **Workflows** (3) - git, full-stack, TDD
- âœ… **Testing** (2) - unit testing, TDD workflows
- ğŸ” **Quality** (3) - code review, comprehensive review, performance
- ğŸ¤– **AI &amp; ML** (4) - LLM apps, agent orchestration, context, MLOps
- ğŸ“Š **Data** (2) - data engineering, data validation
- ğŸ—„ï¸ **Database** (2) - database design, migrations
- ğŸš¨ **Operations** (4) - incident response, diagnostics, distributed debugging, observability
- âš¡ **Performance** (2) - application performance, database/cloud optimization
- â˜ï¸ **Infrastructure** (5) - deployment, validation, Kubernetes, cloud, CI/CD
- ğŸ”’ **Security** (4) - scanning, compliance, backend/API, frontend/mobile
- ğŸ’» **Languages** (7) - Python, JS/TS, systems, JVM, scripting, functional, embedded
- ğŸ”— **Blockchain** (1) - smart contracts, DeFi, Web3
- ğŸ’° **Finance** (1) - quantitative trading, risk management
- ğŸ’³ **Payments** (1) - Stripe, PayPal, billing
- ğŸ® **Gaming** (1) - Unity, Minecraft plugins
- ğŸ“¢ **Marketing** (4) - SEO content, technical SEO, SEO analysis, content marketing
- ğŸ’¼ **Business** (3) - analytics, HR/legal, customer/sales
- And more...

[â†’ View complete plugin catalog](docs/plugins.md)

## Architecture Highlights

### Granular Design

- **Single responsibility** - Each plugin does one thing well
- **Minimal token usage** - Average 3.4 components per plugin
- **Composable** - Mix and match for complex workflows
- **100% coverage** - All 99 agents accessible across plugins

### Progressive Disclosure (Skills)

Three-tier architecture for token efficiency:
1. **Metadata** - Name and activation criteria (always loaded)
2. **Instructions** - Core guidance (loaded when activated)
3. **Resources** - Examples and templates (loaded on demand)

### Repository Structure

```
claude-agents/
â”œâ”€â”€ .claude-plugin/
â”‚   â””â”€â”€ marketplace.json          # 67 plugins
â”œâ”€â”€ plugins/
â”‚   â”œâ”€â”€ python-development/
â”‚   â”‚   â”œâ”€â”€ agents/               # 3 Python experts
â”‚   â”‚   â”œâ”€â”€ commands/             # Scaffolding tool
â”‚   â”‚   â””â”€â”€ skills/               # 5 specialized skills
â”‚   â”œâ”€â”€ kubernetes-operations/
â”‚   â”‚   â”œâ”€â”€ agents/               # K8s architect
â”‚   â”‚   â”œâ”€â”€ commands/             # Deployment tools
â”‚   â”‚   â””â”€â”€ skills/               # 4 K8s skills
â”‚   â””â”€â”€ ... (65 more plugins)
â”œâ”€â”€ docs/                          # Comprehensive documentation
â””â”€â”€ README.md                      # This file
```

[â†’ View architecture details](docs/architecture.md)

## Contributing

To add new agents, skills, or commands:

1. Identify or create the appropriate plugin directory in `plugins/`
2. Create `.md` files in the appropriate subdirectory:
   - `agents/` - For specialized agents
   - `commands/` - For tools and workflows
   - `skills/` - For modular knowledge packages
3. Follow naming conventions (lowercase, hyphen-separated)
4. Write clear activation criteria and comprehensive content
5. Update the plugin definition in `.claude-plugin/marketplace.json`

See [Architecture Documentation](docs/architecture.md) for detailed guidelines.

## Resources

### Documentation
- [Claude Code Documentation](https://docs.claude.com/en/docs/claude-code/overview)
- [Plugins Guide](https://docs.claude.com/en/docs/claude-code/plugins)
- [Subagents Guide](https://docs.claude.com/en/docs/claude-code/sub-agents)
- [Agent Skills Guide](https://docs.claude.com/en/docs/agents-and-tools/agent-skills/overview)
- [Slash Commands Reference](https://docs.claude.com/en/docs/claude-code/slash-commands)

### This Repository
- [Plugin Reference](docs/plugins.md)
- [Agent Reference](docs/agents.md)
- [Agent Skills Guide](docs/agent-skills.md)
- [Usage Guide](docs/usage.md)
- [Architecture](docs/architecture.md)

## License

MIT License - see [LICENSE](LICENSE) file for details.

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=wshobson/agents&amp;type=date&amp;legend=top-left)](https://www.star-history.com/#wshobson/agents&amp;type=date&amp;legend=top-left)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[NanmiCoder/MediaCrawler]]></title>
            <link>https://github.com/NanmiCoder/MediaCrawler</link>
            <guid>https://github.com/NanmiCoder/MediaCrawler</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[å°çº¢ä¹¦ç¬”è®° | è¯„è®ºçˆ¬è™«ã€æŠ–éŸ³è§†é¢‘ | è¯„è®ºçˆ¬è™«ã€å¿«æ‰‹è§†é¢‘ | è¯„è®ºçˆ¬è™«ã€B ç«™è§†é¢‘ ï½œ è¯„è®ºçˆ¬è™«ã€å¾®åšå¸–å­ ï½œ è¯„è®ºçˆ¬è™«ã€ç™¾åº¦è´´å§å¸–å­ ï½œ ç™¾åº¦è´´å§è¯„è®ºå›å¤çˆ¬è™« | çŸ¥ä¹é—®ç­”æ–‡ç« ï½œè¯„è®ºçˆ¬è™«]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NanmiCoder/MediaCrawler">NanmiCoder/MediaCrawler</a></h1>
            <p>å°çº¢ä¹¦ç¬”è®° | è¯„è®ºçˆ¬è™«ã€æŠ–éŸ³è§†é¢‘ | è¯„è®ºçˆ¬è™«ã€å¿«æ‰‹è§†é¢‘ | è¯„è®ºçˆ¬è™«ã€B ç«™è§†é¢‘ ï½œ è¯„è®ºçˆ¬è™«ã€å¾®åšå¸–å­ ï½œ è¯„è®ºçˆ¬è™«ã€ç™¾åº¦è´´å§å¸–å­ ï½œ ç™¾åº¦è´´å§è¯„è®ºå›å¤çˆ¬è™« | çŸ¥ä¹é—®ç­”æ–‡ç« ï½œè¯„è®ºçˆ¬è™«</p>
            <p>Language: Python</p>
            <p>Stars: 41,080</p>
            <p>Forks: 9,193</p>
            <p>Stars today: 69 stars today</p>
            <h2>README</h2><pre># ğŸ”¥ MediaCrawler - è‡ªåª’ä½“å¹³å°çˆ¬è™« ğŸ•·ï¸

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;
   &lt;sup&gt;Special thanks to:&lt;/sup&gt;
   &lt;br&gt;
   &lt;br&gt;
   &lt;a href=&quot;https://go.warp.dev/MediaCrawler&quot;&gt;
      &lt;img alt=&quot;Warp sponsorship&quot; width=&quot;400&quot; src=&quot;https://github.com/warpdotdev/brand-assets/blob/main/Github/Sponsor/Warp-Github-LG-02.png?raw=true&quot;&gt;
   &lt;/a&gt;

### [Warp is built for coding with multiple AI agents](https://go.warp.dev/MediaCrawler)


&lt;/div&gt;
&lt;hr&gt;

&lt;div align=&quot;center&quot;&gt;

&lt;a href=&quot;https://trendshift.io/repositories/8291&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://trendshift.io/api/badge/repositories/8291&quot; alt=&quot;NanmiCoder%2FMediaCrawler | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
&lt;/a&gt;

[![GitHub Stars](https://img.shields.io/github/stars/NanmiCoder/MediaCrawler?style=social)](https://github.com/NanmiCoder/MediaCrawler/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/NanmiCoder/MediaCrawler?style=social)](https://github.com/NanmiCoder/MediaCrawler/network/members)
[![GitHub Issues](https://img.shields.io/github/issues/NanmiCoder/MediaCrawler)](https://github.com/NanmiCoder/MediaCrawler/issues)
[![GitHub Pull Requests](https://img.shields.io/github/issues-pr/NanmiCoder/MediaCrawler)](https://github.com/NanmiCoder/MediaCrawler/pulls)
[![License](https://img.shields.io/github/license/NanmiCoder/MediaCrawler)](https://github.com/NanmiCoder/MediaCrawler/blob/main/LICENSE)
[![ä¸­æ–‡](https://img.shields.io/badge/ğŸ‡¨ğŸ‡³_ä¸­æ–‡-å½“å‰-blue)](README.md)
[![English](https://img.shields.io/badge/ğŸ‡ºğŸ‡¸_English-Available-green)](README_en.md)
[![EspaÃ±ol](https://img.shields.io/badge/ğŸ‡ªğŸ‡¸_EspaÃ±ol-Available-green)](README_es.md)
&lt;/div&gt;



&gt; **å…è´£å£°æ˜ï¼š**
&gt; 
&gt; å¤§å®¶è¯·ä»¥å­¦ä¹ ä¸ºç›®çš„ä½¿ç”¨æœ¬ä»“åº“âš ï¸âš ï¸âš ï¸âš ï¸ï¼Œ[çˆ¬è™«è¿æ³•è¿è§„çš„æ¡ˆä»¶](https://github.com/HiddenStrawberry/Crawler_Illegal_Cases_In_China)  &lt;br&gt;
&gt;
&gt;æœ¬ä»“åº“çš„æ‰€æœ‰å†…å®¹ä»…ä¾›å­¦ä¹ å’Œå‚è€ƒä¹‹ç”¨ï¼Œç¦æ­¢ç”¨äºå•†ä¸šç”¨é€”ã€‚ä»»ä½•äººæˆ–ç»„ç»‡ä¸å¾—å°†æœ¬ä»“åº“çš„å†…å®¹ç”¨äºéæ³•ç”¨é€”æˆ–ä¾µçŠ¯ä»–äººåˆæ³•æƒç›Šã€‚æœ¬ä»“åº“æ‰€æ¶‰åŠçš„çˆ¬è™«æŠ€æœ¯ä»…ç”¨äºå­¦ä¹ å’Œç ”ç©¶ï¼Œä¸å¾—ç”¨äºå¯¹å…¶ä»–å¹³å°è¿›è¡Œå¤§è§„æ¨¡çˆ¬è™«æˆ–å…¶ä»–éæ³•è¡Œä¸ºã€‚å¯¹äºå› ä½¿ç”¨æœ¬ä»“åº“å†…å®¹è€Œå¼•èµ·çš„ä»»ä½•æ³•å¾‹è´£ä»»ï¼Œæœ¬ä»“åº“ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚ä½¿ç”¨æœ¬ä»“åº“çš„å†…å®¹å³è¡¨ç¤ºæ‚¨åŒæ„æœ¬å…è´£å£°æ˜çš„æ‰€æœ‰æ¡æ¬¾å’Œæ¡ä»¶ã€‚
&gt;
&gt; ç‚¹å‡»æŸ¥çœ‹æ›´ä¸ºè¯¦ç»†çš„å…è´£å£°æ˜ã€‚[ç‚¹å‡»è·³è½¬](#disclaimer)




## ğŸ“– é¡¹ç›®ç®€ä»‹

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„**å¤šå¹³å°è‡ªåª’ä½“æ•°æ®é‡‡é›†å·¥å…·**ï¼Œæ”¯æŒå°çº¢ä¹¦ã€æŠ–éŸ³ã€å¿«æ‰‹ã€Bç«™ã€å¾®åšã€è´´å§ã€çŸ¥ä¹ç­‰ä¸»æµå¹³å°çš„å…¬å¼€ä¿¡æ¯æŠ“å–ã€‚

### ğŸ”§ æŠ€æœ¯åŸç†

- **æ ¸å¿ƒæŠ€æœ¯**ï¼šåŸºäº [Playwright](https://playwright.dev/) æµè§ˆå™¨è‡ªåŠ¨åŒ–æ¡†æ¶ç™»å½•ä¿å­˜ç™»å½•æ€
- **æ— éœ€JSé€†å‘**ï¼šåˆ©ç”¨ä¿ç•™ç™»å½•æ€çš„æµè§ˆå™¨ä¸Šä¸‹æ–‡ç¯å¢ƒï¼Œé€šè¿‡ JS è¡¨è¾¾å¼è·å–ç­¾åå‚æ•°
- **ä¼˜åŠ¿ç‰¹ç‚¹**ï¼šæ— éœ€é€†å‘å¤æ‚çš„åŠ å¯†ç®—æ³•ï¼Œå¤§å¹…é™ä½æŠ€æœ¯é—¨æ§›


## âœ¨ åŠŸèƒ½ç‰¹æ€§
| å¹³å°   | å…³é”®è¯æœç´¢ | æŒ‡å®šå¸–å­IDçˆ¬å– | äºŒçº§è¯„è®º | æŒ‡å®šåˆ›ä½œè€…ä¸»é¡µ | ç™»å½•æ€ç¼“å­˜ | IPä»£ç†æ±  | ç”Ÿæˆè¯„è®ºè¯äº‘å›¾ |
| ------ | ---------- | -------------- | -------- | -------------- | ---------- | -------- | -------------- |
| å°çº¢ä¹¦ | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| æŠ–éŸ³   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| å¿«æ‰‹   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| B ç«™   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| å¾®åš   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| è´´å§   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |
| çŸ¥ä¹   | âœ…          | âœ…              | âœ…        | âœ…              | âœ…          | âœ…        | âœ…              |



&lt;details&gt;
&lt;summary&gt;ğŸš€ &lt;strong&gt;MediaCrawlerPro é‡ç£…å‘å¸ƒï¼å¼€æºä¸æ˜“ï¼Œæ¬¢è¿è®¢é˜…æ”¯æŒ&lt;/strong&gt;&lt;/summary&gt;

&gt; ä¸“æ³¨äºå­¦ä¹ æˆç†Ÿé¡¹ç›®çš„æ¶æ„è®¾è®¡ï¼Œä¸ä»…ä»…æ˜¯çˆ¬è™«æŠ€æœ¯ï¼ŒPro ç‰ˆæœ¬çš„ä»£ç è®¾è®¡æ€è·¯åŒæ ·å€¼å¾—æ·±å…¥å­¦ä¹ ï¼

[MediaCrawlerPro](https://github.com/MediaCrawlerPro) ç›¸è¾ƒäºå¼€æºç‰ˆæœ¬çš„æ ¸å¿ƒä¼˜åŠ¿ï¼š

#### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½å‡çº§
- âœ… **æ–­ç‚¹ç»­çˆ¬åŠŸèƒ½**ï¼ˆé‡ç‚¹ç‰¹æ€§ï¼‰
- âœ… **å¤šè´¦å· + IPä»£ç†æ± æ”¯æŒ**ï¼ˆé‡ç‚¹ç‰¹æ€§ï¼‰
- âœ… **å»é™¤ Playwright ä¾èµ–**ï¼Œä½¿ç”¨æ›´ç®€å•
- âœ… **å®Œæ•´ Linux ç¯å¢ƒæ”¯æŒ**

#### ğŸ—ï¸ æ¶æ„è®¾è®¡ä¼˜åŒ–
- âœ… **ä»£ç é‡æ„ä¼˜åŒ–**ï¼Œæ›´æ˜“è¯»æ˜“ç»´æŠ¤ï¼ˆè§£è€¦ JS ç­¾åé€»è¾‘ï¼‰
- âœ… **ä¼ä¸šçº§ä»£ç è´¨é‡**ï¼Œé€‚åˆæ„å»ºå¤§å‹çˆ¬è™«é¡¹ç›®
- âœ… **å®Œç¾æ¶æ„è®¾è®¡**ï¼Œé«˜æ‰©å±•æ€§ï¼Œæºç å­¦ä¹ ä»·å€¼æ›´å¤§

#### ğŸ é¢å¤–åŠŸèƒ½
- âœ… **è‡ªåª’ä½“è§†é¢‘ä¸‹è½½å™¨æ¡Œé¢ç«¯**ï¼ˆé€‚åˆå­¦ä¹ å…¨æ ˆå¼€å‘ï¼‰
- âœ… **å¤šå¹³å°é¦–é¡µä¿¡æ¯æµæ¨è**ï¼ˆHomeFeedï¼‰
- [ ] **åŸºäºè‡ªåª’ä½“å¹³å°çš„AI Agentæ­£åœ¨å¼€å‘ä¸­ ğŸš€ğŸš€**

ç‚¹å‡»æŸ¥çœ‹ï¼š[MediaCrawlerPro é¡¹ç›®ä¸»é¡µ](https://github.com/MediaCrawlerPro) æ›´å¤šä»‹ç»

&lt;/details&gt;


## ğŸš€ å¿«é€Ÿå¼€å§‹

&gt; ğŸ’¡ **å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ Star æ”¯æŒä¸€ä¸‹ï¼**

## ğŸ“‹ å‰ç½®ä¾èµ–

### ğŸš€ uv å®‰è£…ï¼ˆæ¨èï¼‰

åœ¨è¿›è¡Œä¸‹ä¸€æ­¥æ“ä½œä¹‹å‰ï¼Œè¯·ç¡®ä¿ç”µè„‘ä¸Šå·²ç»å®‰è£…äº† uvï¼š

- **å®‰è£…åœ°å€**ï¼š[uv å®˜æ–¹å®‰è£…æŒ‡å—](https://docs.astral.sh/uv/getting-started/installation)
- **éªŒè¯å®‰è£…**ï¼šç»ˆç«¯è¾“å…¥å‘½ä»¤ `uv --version`ï¼Œå¦‚æœæ­£å¸¸æ˜¾ç¤ºç‰ˆæœ¬å·ï¼Œè¯æ˜å·²ç»å®‰è£…æˆåŠŸ
- **æ¨èç†ç”±**ï¼šuv æ˜¯ç›®å‰æœ€å¼ºçš„ Python åŒ…ç®¡ç†å·¥å…·ï¼Œé€Ÿåº¦å¿«ã€ä¾èµ–è§£æå‡†ç¡®

### ğŸŸ¢ Node.js å®‰è£…

é¡¹ç›®ä¾èµ– Node.jsï¼Œè¯·å‰å¾€å®˜ç½‘ä¸‹è½½å®‰è£…ï¼š

- **ä¸‹è½½åœ°å€**ï¼šhttps://nodejs.org/en/download/
- **ç‰ˆæœ¬è¦æ±‚**ï¼š&gt;= 16.0.0

### ğŸ“¦ Python åŒ…å®‰è£…

```shell
# è¿›å…¥é¡¹ç›®ç›®å½•
cd MediaCrawler

# ä½¿ç”¨ uv sync å‘½ä»¤æ¥ä¿è¯ python ç‰ˆæœ¬å’Œç›¸å…³ä¾èµ–åŒ…çš„ä¸€è‡´æ€§
uv sync
```

### ğŸŒ æµè§ˆå™¨é©±åŠ¨å®‰è£…

```shell
# å®‰è£…æµè§ˆå™¨é©±åŠ¨
uv run playwright install
```

## ğŸš€ è¿è¡Œçˆ¬è™«ç¨‹åº

```shell
# åœ¨ config/base_config.py æŸ¥çœ‹é…ç½®é¡¹ç›®åŠŸèƒ½ï¼Œå†™çš„æœ‰ä¸­æ–‡æ³¨é‡Š

# ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–å…³é”®è¯æœç´¢ç›¸å…³çš„å¸–å­å¹¶çˆ¬å–å¸–å­ä¿¡æ¯ä¸è¯„è®º
uv run main.py --platform xhs --lt qrcode --type search

# ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨è·å–æŒ‡å®šå¸–å­çš„ä¿¡æ¯ä¸è¯„è®ºä¿¡æ¯
uv run main.py --platform xhs --lt qrcode --type detail

# æ‰“å¼€å¯¹åº”APPæ‰«äºŒç»´ç ç™»å½•

# å…¶ä»–å¹³å°çˆ¬è™«ä½¿ç”¨ç¤ºä¾‹ï¼Œæ‰§è¡Œä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹
uv run main.py --help
```

## WebUIæ”¯æŒ

&lt;details&gt;
&lt;summary&gt;ğŸ–¥ï¸ &lt;strong&gt;WebUI å¯è§†åŒ–æ“ä½œç•Œé¢&lt;/strong&gt;&lt;/summary&gt;

MediaCrawler æä¾›äº†åŸºäº Web çš„å¯è§†åŒ–æ“ä½œç•Œé¢ï¼Œæ— éœ€å‘½ä»¤è¡Œä¹Ÿèƒ½è½»æ¾ä½¿ç”¨çˆ¬è™«åŠŸèƒ½ã€‚

#### å¯åŠ¨ WebUI æœåŠ¡

```shell
# å¯åŠ¨ API æœåŠ¡å™¨ï¼ˆé»˜è®¤ç«¯å£ 8080ï¼‰
uv run uvicorn api.main:app --port 8080 --reload

# æˆ–è€…ä½¿ç”¨æ¨¡å—æ–¹å¼å¯åŠ¨
uv run python -m api.main
```

å¯åŠ¨æˆåŠŸåï¼Œè®¿é—® `http://localhost:8080` å³å¯æ‰“å¼€ WebUI ç•Œé¢ã€‚

#### WebUI åŠŸèƒ½ç‰¹æ€§

- å¯è§†åŒ–é…ç½®çˆ¬è™«å‚æ•°ï¼ˆå¹³å°ã€ç™»å½•æ–¹å¼ã€çˆ¬å–ç±»å‹ç­‰ï¼‰
- å®æ—¶æŸ¥çœ‹çˆ¬è™«è¿è¡ŒçŠ¶æ€å’Œæ—¥å¿—
- æ•°æ®é¢„è§ˆå’Œå¯¼å‡º

#### ç•Œé¢é¢„è§ˆ

&lt;img src=&quot;docs/static/images/img_8.png&quot; alt=&quot;WebUI ç•Œé¢é¢„è§ˆ&quot;&gt;

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;ğŸ”— &lt;strong&gt;ä½¿ç”¨ Python åŸç”Ÿ venv ç®¡ç†ç¯å¢ƒï¼ˆä¸æ¨èï¼‰&lt;/strong&gt;&lt;/summary&gt;

#### åˆ›å»ºå¹¶æ¿€æ´» Python è™šæ‹Ÿç¯å¢ƒ

&gt; å¦‚æœæ˜¯çˆ¬å–æŠ–éŸ³å’ŒçŸ¥ä¹ï¼Œéœ€è¦æå‰å®‰è£… nodejs ç¯å¢ƒï¼Œç‰ˆæœ¬å¤§äºç­‰äºï¼š`16` å³å¯

```shell
# è¿›å…¥é¡¹ç›®æ ¹ç›®å½•
cd MediaCrawler

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
# æˆ‘çš„ python ç‰ˆæœ¬æ˜¯ï¼š3.11 requirements.txt ä¸­çš„åº“æ˜¯åŸºäºè¿™ä¸ªç‰ˆæœ¬çš„
# å¦‚æœæ˜¯å…¶ä»– python ç‰ˆæœ¬ï¼Œå¯èƒ½ requirements.txt ä¸­çš„åº“ä¸å…¼å®¹ï¼Œéœ€è‡ªè¡Œè§£å†³
python -m venv venv

# macOS &amp; Linux æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# Windows æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
venv\Scripts\activate
```

#### å®‰è£…ä¾èµ–åº“

```shell
pip install -r requirements.txt
```

#### å®‰è£… playwright æµè§ˆå™¨é©±åŠ¨

```shell
playwright install
```

#### è¿è¡Œçˆ¬è™«ç¨‹åºï¼ˆåŸç”Ÿç¯å¢ƒï¼‰

```shell
# é¡¹ç›®é»˜è®¤æ˜¯æ²¡æœ‰å¼€å¯è¯„è®ºçˆ¬å–æ¨¡å¼ï¼Œå¦‚éœ€è¯„è®ºè¯·åœ¨ config/base_config.py ä¸­çš„ ENABLE_GET_COMMENTS å˜é‡ä¿®æ”¹
# ä¸€äº›å…¶ä»–æ”¯æŒé¡¹ï¼Œä¹Ÿå¯ä»¥åœ¨ config/base_config.py æŸ¥çœ‹åŠŸèƒ½ï¼Œå†™çš„æœ‰ä¸­æ–‡æ³¨é‡Š

# ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–å…³é”®è¯æœç´¢ç›¸å…³çš„å¸–å­å¹¶çˆ¬å–å¸–å­ä¿¡æ¯ä¸è¯„è®º
python main.py --platform xhs --lt qrcode --type search

# ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–æŒ‡å®šçš„å¸–å­IDåˆ—è¡¨è·å–æŒ‡å®šå¸–å­çš„ä¿¡æ¯ä¸è¯„è®ºä¿¡æ¯
python main.py --platform xhs --lt qrcode --type detail

# æ‰“å¼€å¯¹åº”APPæ‰«äºŒç»´ç ç™»å½•

# å…¶ä»–å¹³å°çˆ¬è™«ä½¿ç”¨ç¤ºä¾‹ï¼Œæ‰§è¡Œä¸‹é¢çš„å‘½ä»¤æŸ¥çœ‹
python main.py --help
```

&lt;/details&gt;


## ğŸ’¾ æ•°æ®ä¿å­˜

MediaCrawler æ”¯æŒå¤šç§æ•°æ®å­˜å‚¨æ–¹å¼ï¼ŒåŒ…æ‹¬ CSVã€JSONã€Excelã€SQLite å’Œ MySQL æ•°æ®åº“ã€‚

ğŸ“– **è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·æŸ¥çœ‹ï¼š[æ•°æ®å­˜å‚¨æŒ‡å—](docs/data_storage_guide.md)**


[ğŸš€ MediaCrawlerPro é‡ç£…å‘å¸ƒ ğŸš€ï¼æ›´å¤šçš„åŠŸèƒ½ï¼Œæ›´å¥½çš„æ¶æ„è®¾è®¡ï¼å¼€æºä¸æ˜“ï¼Œæ¬¢è¿è®¢é˜…æ”¯æŒï¼](https://github.com/MediaCrawlerPro)


### ğŸ’¬ äº¤æµç¾¤ç»„
- **å¾®ä¿¡äº¤æµç¾¤**ï¼š[ç‚¹å‡»åŠ å…¥](https://nanmicoder.github.io/MediaCrawler/%E5%BE%AE%E4%BF%A1%E4%BA%A4%E6%B5%81%E7%BE%A4.html)
- **Bç«™è´¦å·**ï¼š[å…³æ³¨æˆ‘](https://space.bilibili.com/434377496)ï¼Œåˆ†äº«AIä¸çˆ¬è™«æŠ€æœ¯çŸ¥è¯†


### ğŸ’° èµåŠ©å•†å±•ç¤º

&lt;a href=&quot;https://h.wandouip.com&quot;&gt;
&lt;img src=&quot;docs/static/images/img_8.jpg&quot;&gt;
&lt;br&gt;
è±Œè±†HTTPè‡ªè¥åƒä¸‡çº§IPèµ„æºæ± ï¼ŒIPçº¯å‡€åº¦â‰¥99.8%ï¼Œæ¯æ—¥ä¿æŒIPé«˜é¢‘æ›´æ–°ï¼Œå¿«é€Ÿå“åº”ï¼Œç¨³å®šè¿æ¥,æ»¡è¶³å¤šç§ä¸šåŠ¡åœºæ™¯ï¼Œæ”¯æŒæŒ‰éœ€å®šåˆ¶ï¼Œæ³¨å†Œå…è´¹æå–10000ipã€‚
&lt;/a&gt;

---

&lt;a href=&quot;https://tikhub.io/?utm_source=github.com/NanmiCoder/MediaCrawler&amp;utm_medium=marketing_social&amp;utm_campaign=retargeting&amp;utm_content=carousel_ad&quot;&gt;
&lt;img width=&quot;500&quot; src=&quot;docs/static/images/tikhub_banner_zh.png&quot;&gt;
&lt;br&gt;
TikHub.io æä¾› 900+ é«˜ç¨³å®šæ€§æ•°æ®æ¥å£ï¼Œè¦†ç›– TKã€DYã€XHSã€Y2Bã€Insã€X ç­‰ 14+ æµ·å†…å¤–ä¸»æµå¹³å°ï¼Œæ”¯æŒç”¨æˆ·ã€å†…å®¹ã€å•†å“ã€è¯„è®ºç­‰å¤šç»´åº¦å…¬å¼€æ•°æ® APIï¼Œå¹¶é…å¥— 4000 ä¸‡+ å·²æ¸…æ´—ç»“æ„åŒ–æ•°æ®é›†ï¼Œä½¿ç”¨é‚€è¯·ç  &lt;code&gt;cfzyejV9&lt;/code&gt; æ³¨å†Œå¹¶å……å€¼ï¼Œå³å¯é¢å¤–è·å¾— $2 èµ é€é¢åº¦ã€‚
&lt;/a&gt;

---

&lt;a href=&quot;https://www.thordata.com/?ls=github&amp;lk=mediacrawler&quot;&gt;
&lt;img width=&quot;500&quot; src=&quot;docs/static/images/Thordata.png&quot;&gt;
&lt;br&gt;
Thordataï¼šå¯é ä¸”ç»æµé«˜æ•ˆçš„ä»£ç†æœåŠ¡æä¾›å•†ã€‚ä¸ºä¼ä¸šå’Œå¼€å‘è€…æä¾›ç¨³å®šã€é«˜æ•ˆä¸”åˆè§„çš„å…¨çƒä»£ç† IP æœåŠ¡ã€‚ç«‹å³æ³¨å†Œï¼Œèµ é€1GBä½å®…ä»£ç†å…è´¹è¯•ç”¨å’Œ2000æ¬¡serp-apiè°ƒç”¨ã€‚
&lt;/a&gt;
&lt;br&gt;
&lt;a href=&quot;https://www.thordata.com/products/residential-proxies/?ls=github&amp;lk=mediacrawler&quot;&gt;ã€ä½å®…ä»£ç†ã€‘&lt;/a&gt; | &lt;a href=&quot;https://www.thordata.com/products/web-scraper/?ls=github&amp;lk=mediacrawler&quot;&gt;ã€serp-apiã€‘&lt;/a&gt;


### ğŸ¤ æˆä¸ºèµåŠ©è€…

æˆä¸ºèµåŠ©è€…ï¼Œå¯ä»¥å°†æ‚¨çš„äº§å“å±•ç¤ºåœ¨è¿™é‡Œï¼Œæ¯å¤©è·å¾—å¤§é‡æ›å…‰ï¼

**è”ç³»æ–¹å¼**ï¼š
- å¾®ä¿¡ï¼š`relakkes`
- é‚®ç®±ï¼š`relakkes@gmail.com`
---

### ğŸ“š å…¶ä»–
- **å¸¸è§é—®é¢˜**ï¼š[MediaCrawler å®Œæ•´æ–‡æ¡£](https://nanmicoder.github.io/MediaCrawler/)
- **çˆ¬è™«å…¥é—¨æ•™ç¨‹**ï¼š[CrawlerTutorial å…è´¹æ•™ç¨‹](https://github.com/NanmiCoder/CrawlerTutorial)
- **æ–°é—»çˆ¬è™«å¼€æºé¡¹ç›®**ï¼š[NewsCrawlerCollection](https://github.com/NanmiCoder/NewsCrawlerCollection)


## â­ Star è¶‹åŠ¿å›¾

å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª â­ Star æ”¯æŒä¸€ä¸‹ï¼Œè®©æ›´å¤šçš„äººçœ‹åˆ° MediaCrawlerï¼

[![Star History Chart](https://api.star-history.com/svg?repos=NanmiCoder/MediaCrawler&amp;type=Date)](https://star-history.com/#NanmiCoder/MediaCrawler&amp;Date)


## ğŸ“š å‚è€ƒ

- **å°çº¢ä¹¦ç­¾åä»“åº“**ï¼š[Cloxl çš„ xhs ç­¾åä»“åº“](https://github.com/Cloxl/xhshow)
- **å°çº¢ä¹¦å®¢æˆ·ç«¯**ï¼š[ReaJason çš„ xhs ä»“åº“](https://github.com/ReaJason/xhs)
- **çŸ­ä¿¡è½¬å‘**ï¼š[SmsForwarder å‚è€ƒä»“åº“](https://github.com/pppscn/SmsForwarder)
- **å†…ç½‘ç©¿é€å·¥å…·**ï¼š[ngrok å®˜æ–¹æ–‡æ¡£](https://ngrok.com/docs/)


# å…è´£å£°æ˜
&lt;div id=&quot;disclaimer&quot;&gt; 

## 1. é¡¹ç›®ç›®çš„ä¸æ€§è´¨
æœ¬é¡¹ç›®ï¼ˆä»¥ä¸‹ç®€ç§°â€œæœ¬é¡¹ç›®â€ï¼‰æ˜¯ä½œä¸ºä¸€ä¸ªæŠ€æœ¯ç ”ç©¶ä¸å­¦ä¹ å·¥å…·è€Œåˆ›å»ºçš„ï¼Œæ—¨åœ¨æ¢ç´¢å’Œå­¦ä¹ ç½‘ç»œæ•°æ®é‡‡é›†æŠ€æœ¯ã€‚æœ¬é¡¹ç›®ä¸“æ³¨äºè‡ªåª’ä½“å¹³å°çš„æ•°æ®çˆ¬å–æŠ€æœ¯ç ”ç©¶ï¼Œæ—¨åœ¨æä¾›ç»™å­¦ä¹ è€…å’Œç ”ç©¶è€…ä½œä¸ºæŠ€æœ¯äº¤æµä¹‹ç”¨ã€‚

## 2. æ³•å¾‹åˆè§„æ€§å£°æ˜
æœ¬é¡¹ç›®å¼€å‘è€…ï¼ˆä»¥ä¸‹ç®€ç§°â€œå¼€å‘è€…â€ï¼‰éƒ‘é‡æé†’ç”¨æˆ·åœ¨ä¸‹è½½ã€å®‰è£…å’Œä½¿ç”¨æœ¬é¡¹ç›®æ—¶ï¼Œä¸¥æ ¼éµå®ˆä¸­åäººæ°‘å…±å’Œå›½ç›¸å…³æ³•å¾‹æ³•è§„ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºã€Šä¸­åäººæ°‘å…±å’Œå›½ç½‘ç»œå®‰å…¨æ³•ã€‹ã€ã€Šä¸­åäººæ°‘å…±å’Œå›½åé—´è°æ³•ã€‹ç­‰æ‰€æœ‰é€‚ç”¨çš„å›½å®¶æ³•å¾‹å’Œæ”¿ç­–ã€‚ç”¨æˆ·åº”è‡ªè¡Œæ‰¿æ‹…ä¸€åˆ‡å› ä½¿ç”¨æœ¬é¡¹ç›®è€Œå¯èƒ½å¼•èµ·çš„æ³•å¾‹è´£ä»»ã€‚

## 3. ä½¿ç”¨ç›®çš„é™åˆ¶
æœ¬é¡¹ç›®ä¸¥ç¦ç”¨äºä»»ä½•éæ³•ç›®çš„æˆ–éå­¦ä¹ ã€éç ”ç©¶çš„å•†ä¸šè¡Œä¸ºã€‚æœ¬é¡¹ç›®ä¸å¾—ç”¨äºä»»ä½•å½¢å¼çš„éæ³•ä¾µå…¥ä»–äººè®¡ç®—æœºç³»ç»Ÿï¼Œä¸å¾—ç”¨äºä»»ä½•ä¾µçŠ¯ä»–äººçŸ¥è¯†äº§æƒæˆ–å…¶ä»–åˆæ³•æƒç›Šçš„è¡Œä¸ºã€‚ç”¨æˆ·åº”ä¿è¯å…¶ä½¿ç”¨æœ¬é¡¹ç›®çš„ç›®çš„çº¯å±ä¸ªäººå­¦ä¹ å’ŒæŠ€æœ¯ç ”ç©¶ï¼Œä¸å¾—ç”¨äºä»»ä½•å½¢å¼çš„éæ³•æ´»åŠ¨ã€‚

## 4. å…è´£å£°æ˜
å¼€å‘è€…å·²å°½æœ€å¤§åŠªåŠ›ç¡®ä¿æœ¬é¡¹ç›®çš„æ­£å½“æ€§åŠå®‰å…¨æ€§ï¼Œä½†ä¸å¯¹ç”¨æˆ·ä½¿ç”¨æœ¬é¡¹ç›®å¯èƒ½å¼•èµ·çš„ä»»ä½•å½¢å¼çš„ç›´æ¥æˆ–é—´æ¥æŸå¤±æ‰¿æ‹…è´£ä»»ã€‚åŒ…æ‹¬ä½†ä¸é™äºç”±äºä½¿ç”¨æœ¬é¡¹ç›®è€Œå¯¼è‡´çš„ä»»ä½•æ•°æ®ä¸¢å¤±ã€è®¾å¤‡æŸåã€æ³•å¾‹è¯‰è®¼ç­‰ã€‚

## 5. çŸ¥è¯†äº§æƒå£°æ˜
æœ¬é¡¹ç›®çš„çŸ¥è¯†äº§æƒå½’å¼€å‘è€…æ‰€æœ‰ã€‚æœ¬é¡¹ç›®å—åˆ°è‘—ä½œæƒæ³•å’Œå›½é™…è‘—ä½œæƒæ¡çº¦ä»¥åŠå…¶ä»–çŸ¥è¯†äº§æƒæ³•å¾‹å’Œæ¡çº¦çš„ä¿æŠ¤ã€‚ç”¨æˆ·åœ¨éµå®ˆæœ¬å£°æ˜åŠç›¸å…³æ³•å¾‹æ³•è§„çš„å‰æä¸‹ï¼Œå¯ä»¥ä¸‹è½½å’Œä½¿ç”¨æœ¬é¡¹ç›®ã€‚

## 6. æœ€ç»ˆè§£é‡Šæƒ
å…³äºæœ¬é¡¹ç›®çš„æœ€ç»ˆè§£é‡Šæƒå½’å¼€å‘è€…æ‰€æœ‰ã€‚å¼€å‘è€…ä¿ç•™éšæ—¶æ›´æ”¹æˆ–æ›´æ–°æœ¬å…è´£å£°æ˜çš„æƒåˆ©ï¼Œæ•ä¸å¦è¡Œé€šçŸ¥ã€‚
&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[HKUDS/RAG-Anything]]></title>
            <link>https://github.com/HKUDS/RAG-Anything</link>
            <guid>https://github.com/HKUDS/RAG-Anything</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:56 GMT</pubDate>
            <description><![CDATA["RAG-Anything: All-in-One RAG Framework"]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/HKUDS/RAG-Anything">HKUDS/RAG-Anything</a></h1>
            <p>"RAG-Anything: All-in-One RAG Framework"</p>
            <p>Language: Python</p>
            <p>Stars: 11,585</p>
            <p>Forks: 1,380</p>
            <p>Stars today: 108 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;div style=&quot;margin: 20px 0;&quot;&gt;
  &lt;img src=&quot;./assets/logo.png&quot; width=&quot;120&quot; height=&quot;120&quot; alt=&quot;RAG-Anything Logo&quot; style=&quot;border-radius: 20px; box-shadow: 0 8px 32px rgba(0, 217, 255, 0.3);&quot;&gt;
&lt;/div&gt;

# ğŸš€ RAG-Anything: All-in-One RAG Framework

&lt;a href=&quot;https://trendshift.io/repositories/14959&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14959&quot; alt=&quot;HKUDS%2FRAG-Anything | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://readme-typing-svg.herokuapp.com?font=Orbitron&amp;size=24&amp;duration=3000&amp;pause=1000&amp;color=00D9FF&amp;center=true&amp;vCenter=true&amp;width=600&amp;lines=Welcome+to+RAG-Anything;Next-Gen+Multimodal+RAG+System;Powered+by+Advanced+AI+Technology&quot; alt=&quot;Typing Animation&quot; /&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;div style=&quot;background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); border-radius: 15px; padding: 25px; text-align: center;&quot;&gt;
    &lt;p&gt;
      &lt;a href=&#039;https://github.com/HKUDS/RAG-Anything&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/ğŸ”¥Project-Page-00d9ff?style=for-the-badge&amp;logo=github&amp;logoColor=white&amp;labelColor=1a1a2e&#039;&gt;&lt;/a&gt;
      &lt;a href=&#039;https://arxiv.org/abs/2510.12323&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/ğŸ“„arXiv-2510.12323-ff6b6b?style=for-the-badge&amp;logo=arxiv&amp;logoColor=white&amp;labelColor=1a1a2e&#039;&gt;&lt;/a&gt;
      &lt;a href=&#039;https://github.com/HKUDS/LightRAG&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/âš¡Based%20on-LightRAG-4ecdc4?style=for-the-badge&amp;logo=lightning&amp;logoColor=white&amp;labelColor=1a1a2e&#039;&gt;&lt;/a&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;a href=&quot;https://github.com/HKUDS/RAG-Anything/stargazers&quot;&gt;&lt;img src=&#039;https://img.shields.io/github/stars/HKUDS/RAG-Anything?color=00d9ff&amp;style=for-the-badge&amp;logo=star&amp;logoColor=white&amp;labelColor=1a1a2e&#039; /&gt;&lt;/a&gt;
      &lt;img src=&quot;https://img.shields.io/badge/ğŸPython-3.10-4ecdc4?style=for-the-badge&amp;logo=python&amp;logoColor=white&amp;labelColor=1a1a2e&quot;&gt;
      &lt;a href=&quot;https://pypi.org/project/raganything/&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/raganything.svg?style=for-the-badge&amp;logo=pypi&amp;logoColor=white&amp;labelColor=1a1a2e&amp;color=ff6b6b&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;https://github.com/astral-sh/uv&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/âš¡uv-Ready-ff6b6b?style=for-the-badge&amp;logo=python&amp;logoColor=white&amp;labelColor=1a1a2e&quot;&gt;&lt;/a&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;a href=&quot;https://discord.gg/yF2MmDJyGJ&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/ğŸ’¬Discord-Community-7289da?style=for-the-badge&amp;logo=discord&amp;logoColor=white&amp;labelColor=1a1a2e&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;https://github.com/HKUDS/RAG-Anything/issues/7&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/ğŸ’¬WeChat-Group-07c160?style=for-the-badge&amp;logo=wechat&amp;logoColor=white&amp;labelColor=1a1a2e&quot;&gt;&lt;/a&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;a href=&quot;README_zh.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/ğŸ‡¨ğŸ‡³ä¸­æ–‡ç‰ˆ-1a1a2e?style=for-the-badge&quot;&gt;&lt;/a&gt;
      &lt;a href=&quot;README.md&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/ğŸ‡ºğŸ‡¸English-1a1a2e?style=for-the-badge&quot;&gt;&lt;/a&gt;
    &lt;/p&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;div style=&quot;width: 100%; height: 2px; margin: 20px 0; background: linear-gradient(90deg, transparent, #00d9ff, transparent);&quot;&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;#-quick-start&quot; style=&quot;text-decoration: none;&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Quick%20Start-Get%20Started%20Now-00d9ff?style=for-the-badge&amp;logo=rocket&amp;logoColor=white&amp;labelColor=1a1a2e&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

---

## ğŸ‰ News
- [X] [2025.10]ğŸ¯ğŸ“¢ ğŸš€ We have released the technical report of [RAG-Anything](http://arxiv.org/abs/2510.12323). Access it now to explore our latest research findings.
- [X] [2025.08]ğŸ¯ğŸ“¢ ğŸ” RAG-Anything now features **VLM-Enhanced Query** mode! When documents include images, the system seamlessly integrates them into VLM for advanced multimodal analysis, combining visual and textual context for deeper insights.
- [X] [2025.07]ğŸ¯ğŸ“¢ RAG-Anything now features a [context configuration module](docs/context_aware_processing.md), enabling intelligent integration of relevant contextual information to enhance multimodal content processing.
- [X] [2025.07]ğŸ¯ğŸ“¢ ğŸš€ RAG-Anything now supports multimodal query capabilities, enabling enhanced RAG with seamless processing of text, images, tables, and equations.
- [X] [2025.07]ğŸ¯ğŸ“¢ ğŸ‰ RAG-Anything has reached 1kğŸŒŸ stars on GitHub! Thank you for your incredible support and valuable contributions to the project.

---

## ğŸŒŸ System Overview

*Next-Generation Multimodal Intelligence*

&lt;div style=&quot;background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f3460 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border: 2px solid #00d9ff; box-shadow: 0 0 30px rgba(0, 217, 255, 0.3);&quot;&gt;

Modern documents increasingly contain diverse multimodal contentâ€”text, images, tables, equations, charts, and multimediaâ€”that traditional text-focused RAG systems cannot effectively process. **RAG-Anything** addresses this challenge as a comprehensive **All-in-One Multimodal Document Processing RAG system** built on [LightRAG](https://github.com/HKUDS/LightRAG).

As a unified solution, RAG-Anything **eliminates the need for multiple specialized tools**. It provides **seamless processing and querying across all content modalities** within a single integrated framework. Unlike conventional RAG approaches that struggle with non-textual elements, our all-in-one system delivers **comprehensive multimodal retrieval capabilities**.

Users can query documents containing **interleaved text**, **visual diagrams**, **structured tables**, and **mathematical formulations** through **one cohesive interface**. This consolidated approach makes RAG-Anything particularly valuable for academic research, technical documentation, financial reports, and enterprise knowledge management where rich, mixed-content documents demand a **unified processing framework**.

&lt;img src=&quot;assets/rag_anything_framework.png&quot; alt=&quot;RAG-Anything&quot; /&gt;

&lt;/div&gt;

### ğŸ¯ Key Features

&lt;div style=&quot;background: linear-gradient(135deg, #1a1a2e 0%, #16213e 100%); border-radius: 15px; padding: 25px; margin: 20px 0;&quot;&gt;

- **ğŸ”„ End-to-End Multimodal Pipeline** - Complete workflow from document ingestion and parsing to intelligent multimodal query answering
- **ğŸ“„ Universal Document Support** - Seamless processing of PDFs, Office documents, images, and diverse file formats
- **ğŸ§  Specialized Content Analysis** - Dedicated processors for images, tables, mathematical equations, and heterogeneous content types
- **ğŸ”— Multimodal Knowledge Graph** - Automatic entity extraction and cross-modal relationship discovery for enhanced understanding
- **âš¡ Adaptive Processing Modes** - Flexible MinerU-based parsing or direct multimodal content injection workflows
- **ğŸ“‹ Direct Content List Insertion** - Bypass document parsing by directly inserting pre-parsed content lists from external sources
- **ğŸ¯ Hybrid Intelligent Retrieval** - Advanced search capabilities spanning textual and multimodal content with contextual understanding

&lt;/div&gt;

---

## ğŸ—ï¸ Algorithm &amp; Architecture

&lt;div style=&quot;background: linear-gradient(135deg, #0f0f23 0%, #1a1a2e 100%); border-radius: 15px; padding: 25px; margin: 20px 0; border-left: 5px solid #00d9ff;&quot;&gt;

### Core Algorithm

**RAG-Anything** implements an effective **multi-stage multimodal pipeline** that fundamentally extends traditional RAG architectures to seamlessly handle diverse content modalities through intelligent orchestration and cross-modal understanding.

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;div style=&quot;width: 100%; max-width: 600px; margin: 20px auto; padding: 20px; background: linear-gradient(135deg, rgba(0, 217, 255, 0.1) 0%, rgba(0, 217, 255, 0.05) 100%); border-radius: 15px; border: 1px solid rgba(0, 217, 255, 0.2);&quot;&gt;
    &lt;div style=&quot;display: flex; justify-content: space-around; align-items: center; flex-wrap: wrap; gap: 20px;&quot;&gt;
      &lt;div style=&quot;text-align: center;&quot;&gt;
        &lt;div style=&quot;font-size: 24px; margin-bottom: 10px;&quot;&gt;ğŸ“„&lt;/div&gt;
        &lt;div style=&quot;font-size: 14px; color: #00d9ff;&quot;&gt;Document Parsing&lt;/div&gt;
      &lt;/div&gt;
      &lt;div style=&quot;font-size: 20px; color: #00d9ff;&quot;&gt;â†’&lt;/div&gt;
      &lt;div style=&quot;text-align: center;&quot;&gt;
        &lt;div style=&quot;font-size: 24px; margin-bottom: 10px;&quot;&gt;ğŸ§ &lt;/div&gt;
        &lt;div style=&quot;font-size: 14px; color: #00d9ff;&quot;&gt;Content Analysis&lt;/div&gt;
      &lt;/div&gt;
      &lt;div style=&quot;font-size: 20px; color: #00d9ff;&quot;&gt;â†’&lt;/div&gt;
      &lt;div style=&quot;text-align: center;&quot;&gt;
        &lt;div style=&quot;font-size: 24px; margin-bottom: 10px;&quot;&gt;ğŸ”&lt;/div&gt;
        &lt;div style=&quot;font-size: 14px; color: #00d9ff;&quot;&gt;Knowledge Graph&lt;/div&gt;
      &lt;/div&gt;
      &lt;div style=&quot;font-size: 20px; color: #00d9ff;&quot;&gt;â†’&lt;/div&gt;
      &lt;div style=&quot;text-align: center;&quot;&gt;
        &lt;div style=&quot;font-size: 24px; margin-bottom: 10px;&quot;&gt;ğŸ¯&lt;/div&gt;
        &lt;div style=&quot;font-size: 14px; color: #00d9ff;&quot;&gt;Intelligent Retrieval&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;

### 1. Document Parsing Stage

&lt;div style=&quot;background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;&quot;&gt;

The system provides high-fidelity document extraction through adaptive content decomposition. It intelligently segments heterogeneous elements while preserving contextual relationships. Universal format compatibility is achieved via specialized optimized parsers.

**Key Components:**

- **âš™ï¸ MinerU Integration**: Leverages [MinerU](https://github.com/opendatalab/MinerU) for high-fidelity document structure extraction and semantic preservation across complex layouts.

- **ğŸ§© Adaptive Content Decomposition**: Automatically segments documents into coherent text blocks, visual elements, structured tables, mathematical equations, and specialized content types while preserving contextual relationships.

- **ğŸ“ Universal Format Support**: Provides comprehensive handling of PDFs, Office documents (DOC/DOCX/PPT/PPTX/XLS/XLSX), images, and emerging formats through specialized parsers with format-specific optimization.

&lt;/div&gt;

### 2. Multi-Modal Content Understanding &amp; Processing

&lt;div style=&quot;background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;&quot;&gt;

The system automatically categorizes and routes content through optimized channels. It uses concurrent pipelines for parallel text and multimodal processing. Document hierarchy and relationships are preserved during transformation.

**Key Components:**

- **ğŸ¯ Autonomous Content Categorization and Routing**: Automatically identify, categorize, and route different content types through optimized execution channels.

- **âš¡ Concurrent Multi-Pipeline Architecture**: Implements concurrent execution of textual and multimodal content through dedicated processing pipelines. This approach maximizes throughput efficiency while preserving content integrity.

- **ğŸ—ï¸ Document Hierarchy Extraction**: Extracts and preserves original document hierarchy and inter-element relationships during content transformation.

&lt;/div&gt;

### 3. Multimodal Analysis Engine

&lt;div style=&quot;background: linear-gradient(90deg, #0f3460 0%, #1a1a2e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #00d9ff;&quot;&gt;

The system deploys modality-aware processing units for heterogeneous data modalities:

**Specialized Analyzers:**

- **ğŸ” Visual Content Analyzer**:
  - Integrate vision model for image analysis.
  - Generates context-aware descriptive captions based on visual semantics.
  - Extracts spatial relationships and hierarchical structures between visual elements.

- **ğŸ“Š Structured Data Interpreter**:
  - Performs systematic interpretation of tabular and structured data formats.
  - Implements statistical pattern recognition algorithms for data trend analysis.
  - Identifies semantic relationships and dependencies across multiple tabular datasets.

- **ğŸ“ Mathematical Expression Parser**:
  - Parses complex mathematical expressions and formulas with high accuracy.
  - Provides native LaTeX format support for seamless integration with academic workflows.
  - Establishes conceptual mappings between mathematical equations and domain-specific knowledge bases.

- **ğŸ”§ Extensible Modality Handler**:
  - Provides configurable processing framework for custom and emerging content types.
  - Enables dynamic integration of new modality processors through plugin architecture.
  - Supports runtime configuration of processing pipelines for specialized use cases.

&lt;/div&gt;

### 4. Multimodal Knowledge Graph Index

&lt;div style=&quot;background: linear-gradient(90deg, #1a1a2e 0%, #16213e 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #4ecdc4;&quot;&gt;

The multi-modal knowledge graph construction module transforms document content into structured semantic representations. It extracts multimodal entities, establishes cross-modal relationships, and preserves hierarchical organization. The system applies weighted relevance scoring for optimized knowledge retrieval.

**Core Functions:**

- **ğŸ” Multi-Modal Entity Extraction**: Transforms significant multimodal elements into structured knowledge graph entities. The process includes semantic annotations and metadata preservation.

- **ğŸ”— Cross-Modal Relationship Mapping**: Establishes semantic connections and dependencies between textual entities and multimodal components. This is achieved through automated relationship inference algorithms.

- **ğŸ—ï¸ Hierarchical Structure Preservation**: Maintains original document organization through &quot;belongs_to&quot; relationship chains. These chains preserve logical content hierarchy and sectional dependencies.

- **âš–ï¸ Weighted Relationship Scoring**: Assigns quantitative relevance scores to relationship types. Scoring is based on semantic proximity and contextual significance within the document structure.

&lt;/div&gt;

### 5. Modality-Aware Retrieval

&lt;div style=&quot;background: linear-gradient(90deg, #16213e 0%, #0f3460 100%); border-radius: 10px; padding: 20px; margin: 15px 0; border-left: 4px solid #ff6b6b;&quot;&gt;

The hybrid retrieval system combines vector similarity search with graph traversal algorithms for comprehensive content retrieval. It implements modality-aware ranking mechanisms and maintains relational coherence between retrieved elements to ensure contextually integrated information delivery.

**Retrieval Mechanisms:**

- **ğŸ”€ Vector-Graph Fusion**: Integrates vector similarity search with graph traversal algorithms. This approach leverages both semantic embeddings and structural relationships for comprehensive content retrieval.

- **ğŸ“Š Modality-Aware Ranking**: Implements adaptive scoring mechanisms that weight retrieval results based on content type relevance. The system adjusts rankings according to query-specific modality preferences.

- **ğŸ”— Relational Coherence Maintenance**: Maintains semantic and structural relationships between retrieved elements. This ensures coherent information delivery and contextual integrity.

&lt;/div&gt;

---

## ğŸš€ Quick Start

*Initialize Your AI Journey*

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://user-images.githubusercontent.com/74038190/212284158-e840e285-664b-44d7-b79b-e264b5e54825.gif&quot; width=&quot;400&quot;&gt;
&lt;/div&gt;

### Installation

#### Option 1: Install from PyPI (Recommended)

```bash
# Basic installation
pip install raganything

# With optional dependencies for extended format support:
pip install &#039;raganything[all]&#039;              # All optional features
pip install &#039;raganything[image]&#039;            # Image format conversion (BMP, TIFF, GIF, WebP)
pip install &#039;raganything[text]&#039;             # Text file processing (TXT, MD)
pip install &#039;raganything[image,text]&#039;       # Multiple features
```

#### Option 2: Install from Source
```bash
# Install uv (if not already installed)
curl -LsSf https://astral.sh/uv/install.sh | sh

# Clone and setup the project with uv
git clone https://github.com/HKUDS/RAG-Anything.git
cd RAG-Anything

# Install the package and dependencies in a virtual environment
uv sync

# If you encounter network timeouts (especially for opencv packages):
# UV_HTTP_TIMEOUT=120 uv sync

# Run commands directly with uv (recommended approach)
uv run python examples/raganything_example.py --help

# Install with optional dependencies
uv sync --extra image --extra text  # Specific extras
uv sync --all-extras                 # All optional features
```

#### Optional Dependencies

- **`[image]`** - Enables processing of BMP, TIFF, GIF, WebP image formats (requires Pillow)
- **`[text]`** - Enables processing of TXT and MD files (requires ReportLab)
- **`[all]`** - Includes all Python optional dependencies

&gt; **âš ï¸ Office Document Processing Requirements:**
&gt; - Office documents (.doc, .docx, .ppt, .pptx, .xls, .xlsx) require **LibreOffice** installation
&gt; - Download from [LibreOffice official website](https://www.libreoffice.org/download/download/)
&gt; - **Windows**: Download installer from official website
&gt; - **macOS**: `brew install --cask libreoffice`
&gt; - **Ubuntu/Debian**: `sudo apt-get install libreoffice`
&gt; - **CentOS/RHEL**: `sudo yum install libreoffice`

**Check MinerU installation:**

```bash
# Verify installation
mineru --version

# Check if properly configured
python -c &quot;from raganything import RAGAnything; rag = RAGAnything(); print(&#039;âœ… MinerU installed properly&#039; if rag.check_parser_installation() else &#039;âŒ MinerU installation issue&#039;)&quot;
```

Models are downloaded automatically on first use. For manual download, refer to [MinerU Model Source Configuration](https://github.com/opendatalab/MinerU/blob/master/README.md#22-model-source-configuration).

### Usage Examples

#### 1. End-to-End Document Processing

```python
import asyncio
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.llm.openai import openai_complete_if_cache, openai_embed
from lightrag.utils import EmbeddingFunc

async def main():
    # Set up API configuration
    api_key = &quot;your-api-key&quot;
    base_url = &quot;your-base-url&quot;  # Optional

    # Create RAGAnything configuration
    config = RAGAnythingConfig(
        working_dir=&quot;./rag_storage&quot;,
        parser=&quot;mineru&quot;,  # Parser selection: mineru or docling
        parse_method=&quot;auto&quot;,  # Parse method: auto, ocr, or txt
        enable_image_processing=True,
        enable_table_processing=True,
        enable_equation_processing=True,
    )

    # Define LLM model function
    def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
        return openai_complete_if_cache(
            &quot;gpt-4o-mini&quot;,
            prompt,
            system_prompt=system_prompt,
            history_messages=history_messages,
            api_key=api_key,
            base_url=base_url,
            **kwargs,
        )

    # Define vision model function for image processing
    def vision_model_func(
        prompt, system_prompt=None, history_messages=[], image_data=None, messages=None, **kwargs
    ):
        # If messages format is provided (for multimodal VLM enhanced query), use it directly
        if messages:
            return openai_complete_if_cache(
                &quot;gpt-4o&quot;,
                &quot;&quot;,
                system_prompt=None,
                history_messages=[],
                messages=messages,
                api_key=api_key,
                base_url=base_url,
                **kwargs,
            )
        # Traditional single image format
        elif image_data:
            return openai_complete_if_cache(
                &quot;gpt-4o&quot;,
                &quot;&quot;,
                system_prompt=None,
                history_messages=[],
                messages=[
                    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt}
                    if system_prompt
                    else None,
                    {
                        &quot;role&quot;: &quot;user&quot;,
                        &quot;content&quot;: [
                            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: prompt},
                            {
                                &quot;type&quot;: &quot;image_url&quot;,
                                &quot;image_url&quot;: {
                                    &quot;url&quot;: f&quot;data:image/jpeg;base64,{image_data}&quot;
             

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[public-apis/public-apis]]></title>
            <link>https://github.com/public-apis/public-apis</link>
            <guid>https://github.com/public-apis/public-apis</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[A collective list of free APIs]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/public-apis/public-apis">public-apis/public-apis</a></h1>
            <p>A collective list of free APIs</p>
            <p>Language: Python</p>
            <p>Stars: 388,322</p>
            <p>Forks: 41,471</p>
            <p>Stars today: 184 stars today</p>
            <h2>README</h2><pre># Try Public APIs for free
The Public APIs repository is manually curated by community members like you and folks working at [APILayer](https://apilayer.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo). It includes an extensive list of public APIs from many domains that you can use for your own products. Consider it a treasure trove of APIs well-managed by the community over the years.

&lt;br &gt;

&lt;p&gt;
    &lt;a href=&quot;https://apilayer.com&quot;&gt;
        &lt;div&gt;
            &lt;img src=&quot;.github/cs1586-APILayerLogoUpdate2022-LJ_v2-HighRes.png&quot; width=&quot;100%&quot; alt=&quot;APILayer Logo&quot; /&gt;
        &lt;/div&gt;
    &lt;/a&gt;
  &lt;/p&gt;

APILayer is the fastest way to integrate APIs into any product. Explore [APILayer APIs](https://apilayer.com/products/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo) here for your next project.

Join our [Discord server](https://discord.com/invite/hgjA78638n/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo) to get updates, ask questions, get answers, random community calls, and more.

&lt;br &gt;

## APILayer APIs
| API | Description | Call this API |
|:---|:---|:---|
| [IPstack](https://ipstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Locate and Identify Website Visitors by IP Address | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-55145132-244c-448c-8e6f-8780866e4862?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-55145132-244c-448c-8e6f-8780866e4862%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Marketstack](https://marketstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Free, easy-to-use REST API interface delivering worldwide stock market data in JSON format | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-9cbac391-3611-4f50-9bfd-d24ae41c97c1%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Weatherstack](https://weatherstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Retrieve instant, accurate weather information for any location in the world in lightweight JSON format | [&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-276c4312-f682-425d-b6b1-0f82c0a7f2b3%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Numverify](https://numverify.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers ) | Global Phone Number Validation &amp; Lookup JSON API |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-0760d25e-b802-412e-b0e4-26e5ca3b9ffa%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Fixer](https://fixer.io/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Fixer is a simple and lightweight API for current and historical foreign exchange (forex) rates. |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d?action=collection%2Ffork&amp;source=rip_markdown&amp;collection-url=entityId%3D10131015-0d9c66b3-5f1a-42ed-a5ca-379217bd629d%26entityType%3Dcollection%26workspaceId%3D2b7498b6-6d91-4fa8-817f-608441fe42a8)|
| [Aviationstack](https://aviationstack.com/?utm_source=Github&amp;utm_medium=Referral&amp;utm_campaign=Public-apis-repo-Best-sellers) | Free, real-time flight status and global Aviation data API |[&lt;img src=&quot;https://run.pstmn.io/button.svg&quot; alt=&quot;Run In Postman&quot; style=&quot;width: 128px; height: 32px;&quot;&gt;](https://god.gw.postman.com/run-collection/10131015-72ee0d35-018e-4370-a2b6-a66d3ebd5b5a?action=collection/fork)|

&lt;br &gt;

## Learn more about Public APIs

&lt;strong&gt;Get Involved&lt;/strong&gt;

* [Contributing Guide](CONTRIBUTING.md)
* [API for this project](https://github.com/davemachado/public-api)
* [Issues](https://github.com/public-apis/public-apis/issues)
* [Pull Requests](https://github.com/public-apis/public-apis/pulls)
* [LICENSE](LICENSE) 

&lt;br /&gt;

## Index

* [Animals](#animals)
* [Anime](#anime)
* [Anti-Malware](#anti-malware)
* [Art &amp; Design](#art--design)
* [Authentication &amp; Authorization](#authentication--authorization)
* [Blockchain](#blockchain)
* [Books](#books)
* [Business](#business)
* [Calendar](#calendar)
* [Cloud Storage &amp; File Sharing](#cloud-storage--file-sharing)
* [Continuous Integration](#continuous-integration)
* [Cryptocurrency](#cryptocurrency)
* [Currency Exchange](#currency-exchange)
* [Data Validation](#data-validation)
* [Development](#development)
* [Dictionaries](#dictionaries)
* [Documents &amp; Productivity](#documents--productivity)
* [Email](#email)
* [Entertainment](#entertainment)
* [Environment](#environment)
* [Events](#events)
* [Finance](#finance)
* [Food &amp; Drink](#food--drink)
* [Games &amp; Comics](#games--comics)
* [Geocoding](#geocoding)
* [Government](#government)
* [Health](#health)
* [Jobs](#jobs)
* [Machine Learning](#machine-learning)
* [Music](#music)
* [News](#news)
* [Open Data](#open-data)
* [Open Source Projects](#open-source-projects)
* [Patent](#patent)
* [Personality](#personality)
* [Phone](#phone)
* [Photography](#photography)
* [Programming](#programming)
* [Science &amp; Math](#science--math)
* [Security](#security)
* [Shopping](#shopping)
* [Social](#social)
* [Sports &amp; Fitness](#sports--fitness)
* [Test Data](#test-data)
* [Text Analysis](#text-analysis)
* [Tracking](#tracking)
* [Transportation](#transportation)
* [URL Shorteners](#url-shorteners)
* [Vehicle](#vehicle)
* [Video](#video)
* [Weather](#weather)
&lt;br &gt;

### Animals
API | Description | Auth | HTTPS | CORS 
|:---|:---|:---|:---|:---|
| [AdoptAPet](https://www.adoptapet.com/public/apis/pet_list.html) | Resource to help get pets adopted | `apiKey` | Yes | Yes |
| [Axolotl](https://theaxolotlapi.netlify.app/) | Collection of axolotl pictures and facts | No | Yes | No |
| [Cat Facts](https://alexwohlbruck.github.io/cat-facts/) | Daily cat facts | No | Yes | No | |
| [Cataas](https://cataas.com/) | Cat as a service (cats pictures and gifs) | No | Yes | No |
| [Cats](https://docs.thecatapi.com/) | Pictures of cats from Tumblr | `apiKey` | Yes | No |
| [Dog Facts](https://dukengn.github.io/Dog-facts-API/) | Random dog facts | No | Yes | Yes |
| [Dog Facts](https://kinduff.github.io/dog-api/) | Random facts of Dogs | No | Yes | Yes |
| [Dogs](https://dog.ceo/dog-api/) | Based on the Stanford Dogs Dataset | No | Yes | Yes |
| [eBird](https://documenter.getpostman.com/view/664302/S1ENwy59) | Retrieve recent or notable birding observations within a region | `apiKey` | Yes | No |
| [FishWatch](https://www.fishwatch.gov/developers) | Information and pictures about individual fish species | No | Yes | Yes |
| [HTTP Cat](https://http.cat/) | Cat for every HTTP Status | No | Yes | Yes |
| [HTTP Dog](https://http.dog/) | Dogs for every HTTP response status code | No | Yes | Yes |
| [IUCN](http://apiv3.iucnredlist.org/api/v3/docs) | IUCN Red List of Threatened Species | `apiKey` | No | No |
| [MeowFacts](https://github.com/wh-iterabb-it/meowfacts) | Get random cat facts | No | Yes | No |
| [Movebank](https://github.com/movebank/movebank-api-doc) | Movement and Migration data of animals | No | Yes | Yes |
| [Petfinder](https://www.petfinder.com/developers/) | Petfinder is dedicated to helping pets find homes, another resource to get pets adopted | `apiKey` | Yes | Yes |
| [PlaceBear](https://placebear.com/) | Placeholder bear pictures | No | Yes | Yes |
| [PlaceDog](https://place.dog) | Placeholder Dog pictures | No | Yes | Yes |
| [PlaceKitten](https://placekitten.com/) | Placeholder Kitten pictures | No | Yes | Yes |
| [RandomDog](https://random.dog/woof.json) | Random pictures of dogs | No | Yes | Yes |
| [RandomDuck](https://random-d.uk/api) | Random pictures of ducks | No | Yes | No |
| [RandomFox](https://randomfox.ca/floof/) | Random pictures of foxes | No | Yes | No |
| [RescueGroups](https://userguide.rescuegroups.org/display/APIDG/API+Developers+Guide+Home) | Adoption | No | Yes | Unknown |
| [Shibe.Online](http://shibe.online/) | Random pictures of Shiba Inu, cats or birds | No | Yes | Yes |
| [The Dog](https://thedogapi.com/) | A public service all about Dogs, free to use when making your fancy new App, Website or Service | `apiKey` | Yes | No |
| [xeno-canto](https://xeno-canto.org/explore/api) | Bird recordings | No | Yes | Unknown |
| [Zoo Animals](https://zoo-animal-api.herokuapp.com/) | Facts and pictures of zoo animals | No | Yes | Yes |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;

### Anime
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AniAPI](https://aniapi.com/docs/) | Anime discovery, streaming &amp; syncing with trackers | `OAuth` | Yes | Yes |
| [AniDB](https://wiki.anidb.net/HTTP_API_Definition) | Anime Database | `apiKey` | No | Unknown |
| [AniList](https://github.com/AniList/ApiV2-GraphQL-Docs) | Anime discovery &amp; tracking | `OAuth` | Yes | Unknown |
| [AnimeChan](https://github.com/RocktimSaikia/anime-chan) | Anime quotes (over 10k+) | No | Yes | No |
| [AnimeFacts](https://chandan-02.github.io/anime-facts-rest-api/) | Anime Facts (over 100+) | No | Yes | Yes |
| [AnimeNewsNetwork](https://www.animenewsnetwork.com/encyclopedia/api.php) | Anime industry news | No | Yes | Yes |
| [Catboy](https://catboys.com/api) | Neko images, funny GIFs &amp; more | No | Yes | Yes |
| [Danbooru Anime](https://danbooru.donmai.us/wiki_pages/help:api) | Thousands of anime artist database to find good anime art | `apiKey` | Yes | Yes |
| [Jikan](https://jikan.moe) | Unofficial MyAnimeList API | No | Yes | Yes |
| [Kitsu](https://kitsu.docs.apiary.io/) | Anime discovery platform | `OAuth` | Yes | Yes |
| [MangaDex](https://api.mangadex.org/docs.html) | Manga Database and Community | `apiKey` | Yes | Unknown |
| [Mangapi](https://rapidapi.com/pierre.carcellermeunier/api/mangapi3/) | Translate manga pages from one language to another | `apiKey` | Yes | Unknown |
| [MyAnimeList](https://myanimelist.net/clubs.php?cid=13727) | Anime and Manga Database and Community | `OAuth` | Yes | Unknown |
| [NekosBest](https://docs.nekos.best) | Neko Images &amp; Anime roleplaying GIFs | No | Yes | Yes |
| [Shikimori](https://shikimori.one/api/doc) | Anime discovery, tracking, forum, rates | `OAuth` | Yes | Unknown |
| [Studio Ghibli](https://ghibliapi.herokuapp.com) | Resources from Studio Ghibli films | No | Yes | Yes |
| [Trace Moe](https://soruly.github.io/trace.moe-api/#/) | A useful tool to get the exact scene of an anime from a screenshot | No | Yes | No |
| [Waifu.im](https://waifu.im/docs) | Get waifu pictures from an archive of over 4000 images and multiple tags | No | Yes | Yes |
| [Waifu.pics](https://waifu.pics/docs) | Image sharing platform for anime images | No | Yes | No |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;

### Anti-Malware
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AbuseIPDB](https://docs.abuseipdb.com/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [AlienVault Open Threat Exchange (OTX)](https://otx.alienvault.com/api) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [CAPEsandbox](https://capev2.readthedocs.io/en/latest/usage/api.html) | Malware execution and analysis | `apiKey` | Yes | Unknown |
| [Google Safe Browsing](https://developers.google.com/safe-browsing/) | Google Link/Domain Flagging | `apiKey` | Yes | Unknown |
| [MalDatabase](https://maldatabase.com/api-doc.html) | Provide malware datasets and threat intelligence feeds | `apiKey` | Yes | Unknown |
| [MalShare](https://malshare.com/doc.php) | Malware Archive / file sourcing | `apiKey` | Yes | No |
| [MalwareBazaar](https://bazaar.abuse.ch/api/) | Collect and share malware samples | `apiKey` | Yes | Unknown |
| [Metacert](https://metacert.com/) | Metacert Link Flagging | `apiKey` | Yes | Unknown |
| [NoPhishy](https://rapidapi.com/Amiichu/api/exerra-phishing-check/) | Check links to see if they&#039;re known phishing attempts | `apiKey` | Yes | Yes |
| [Phisherman](https://phisherman.gg/) | IP/domain/URL reputation | `apiKey` | Yes | Unknown |
| [Scanii](https://docs.scanii.com/) | Simple REST API that can scan submitted documents/files for the presence of threats | `apiKey` | Yes | Yes |
| [URLhaus](https://urlhaus-api.abuse.ch/) | Bulk queries and Download Malware Samples | No | Yes | Yes |
| [URLScan.io](https://urlscan.io/about-api/) | Scan and Analyse URLs | `apiKey` | Yes | Unknown |
| [VirusTotal](https://www.virustotal.com/en/documentation/public-api/) | VirusTotal File/URL Analysis | `apiKey` | Yes | Unknown |
| [Web of Trust](https://support.mywot.com/hc/en-us/sections/360004477734-API-) | IP/domain/URL reputation | `apiKey` | Yes | Unknown | 

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Art &amp; Design
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [AmÃ©thyste](https://api.amethyste.moe/) | Generate images for Discord users | `apiKey` | Yes | Unknown |
| [Art Institute of Chicago](https://api.artic.edu/docs/) | Art | No | Yes | Yes |
| [Colormind](http://colormind.io/api-access/) | Color scheme generator | No | No | Unknown |
| [ColourLovers](http://www.colourlovers.com/api) | Get various patterns, palettes and images | No | No | Unknown |
| [Cooper Hewitt](https://collection.cooperhewitt.org/api) | Smithsonian Design Museum | `apiKey` | Yes | Unknown |
| [Dribbble](https://developer.dribbble.com) | Discover the worldâ€™s top designers &amp; creatives | `OAuth` | Yes | Unknown |
| [EmojiHub](https://github.com/cheatsnake/emojihub) | Get emojis by categories and groups | No | Yes | Yes |
| [Europeana](https://pro.europeana.eu/resources/apis/search) | European Museum and Galleries content | `apiKey` | Yes | Unknown |
| [Harvard Art Museums](https://github.com/harvardartmuseums/api-docs) | Art | `apiKey` | No | Unknown |
| [Icon Horse](https://icon.horse) | Favicons for any website, with fallbacks | No | Yes | Yes |
| [Iconfinder](https://developer.iconfinder.com) | Icons | `apiKey` | Yes | Unknown |
| [Icons8](https://img.icons8.com/) | Icons (find &quot;search icon&quot; hyperlink in page) | No | Yes | Unknown |
| [Lordicon](https://lordicon.com/) | Icons with predone Animations | No | Yes | Yes |
| [Metropolitan Museum of Art](https://metmuseum.github.io/) | Met Museum of Art | No | Yes | No |
| [Noun Project](http://api.thenounproject.com/index.html) | Icons | `OAuth` | No | Unknown |
| [PHP-Noise](https://php-noise.com/) | Noise Background Image Generator | No | Yes | Yes |
| [Pixel Encounter](https://pixelencounter.com/api) | SVG Icon Generator | No | Yes | No |
| [Rijksmuseum](https://data.rijksmuseum.nl/object-metadata/api/) | RijksMuseum Data | `apiKey` | Yes | Unknown |
| [Word Cloud](https://wordcloudapi.com/) | Easily create word clouds | `apiKey` | Yes | Unknown |
| [xColors](https://x-colors.herokuapp.com/) | Generate &amp; convert colors | No | Yes | Yes |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Authentication &amp; Authorization
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [Auth0](https://auth0.com) | Easy to implement, adaptable authentication and authorization platform | `apiKey` | Yes | Yes |
| [GetOTP](https://otp.dev/en/docs/) | Implement OTP flow quickly | `apiKey` | Yes | No |
| [Micro User Service](https://m3o.com/user) | User management and authentication | `apiKey` | Yes | No |
| [MojoAuth](https://mojoauth.com) | Secure and modern passwordless authentication platform | `apiKey` | Yes | Yes |
| [SAWO Labs](https://sawolabs.com) | Simplify login and improve user experience by integrating passwordless authentication in your app | `apiKey` | Yes | Yes |
| [Stytch](https://stytch.com/) | User infrastructure for modern applications | `apiKey` | Yes | No |
| [Warrant](https://warrant.dev/) | APIs for authorization and access control | `apiKey` | Yes | Yes |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Blockchain
| API | Description | Auth | HTTPS | CORS |
|---|:---|:---|:---|:---|
| [Bitquery](https://graphql.bitquery.io/ide) | Onchain GraphQL APIs &amp; DEX APIs | `apiKey` | Yes | Yes |
| [Chainlink](https://chain.link/developer-resources) | Build hybrid smart contracts with Chainlink | No | Yes | Unknown |
| [Chainpoint](https://tierion.com/chainpoint/) | Chainpoint is a global network for anchoring data to the Bitcoin blockchain | No | Yes | Unknown |
| [Covalent](https://www.covalenthq.com/docs/api/) | Multi-blockchain data aggregator platform | `apiKey` | Yes | Unknown |
| [Etherscan](https://etherscan.io/apis) | Ethereum explorer API | `apiKey` | Yes | Yes |
| [Helium](https://docs.helium.com/api/blockchain/introduction/) | Helium is a global, distributed network of Hotspots that create public, long-range wireless coverage | No | Yes | Unknown |
| [Nownodes](https://nownodes.io/) | Blockchain-as-a-service solution that provides high-quality connection via API | `apiKey` | Yes | Unknown |
| [Steem](https://developers.steem.io/) | Blockchain-based blogging and social media website | No | No | No |
| [The Graph](https://thegraph.com) | Indexing protocol for querying networks like Ethereum with GraphQL | `apiKey` | Yes | Unknown |
| [Walltime](https://walltime.info/api.html) | To retrieve Walltime&#039;s market info | No | Yes | Unknown |
| [Watchdata](https://docs.watchdata.io) | Provide simple and reliable API access to Ethereum blockchain | `apiKey` | Yes | Unknown |

**[â¬† Back to Index](#index)**
&lt;br &gt;
&lt;br &gt;
### Books
API | Description | Auth | HTTPS | CORS |
|:---|:---|:---|:---|:---|
| [A BÃ­blia Digital](https://www.abibliadigital.com.br/en) | Do not worry about managing the multiple versions of the Bible | `apiKey` | Yes | No |
| [Bhagavad Gita](https://docs.bhagavadgitaapi.in) | Open Source Shrimad Bhagavad Gita API including 21+ authors translation in Sanskrit/English/Hindi | `apiKey` | Yes | Yes |
| [Bhagavad Gita](https://bhagavadgita.io/api) | Bhagavad Gita text | `OAuth` | Yes | Yes |
| [Bhagavad Gita telugu](https://gita-api.vercel.app) | Bhagavad Gita API in telugu and odia languages | No | Yes | Yes |
| [Bible-api](https://bible-api.com/) | Free Bible API with multiple languages | No | Yes | Yes |
| [British National Bibliography](http://bnb.data.bl.uk/) | Books | No | No | Unknown |
| [Crossref Metadata Search](https://github.com/CrossRef/rest-api-doc) | Books &amp; Articles Metadata | No | Yes | Unknown |
| [Ganjoor](https://api.ganjoor.net) | Classic Persian poetry works including access to related manuscripts, recitations and music tracks | `OAuth` | Yes | Yes |
| [Google Books](https://developers.google.com/books/) | Books | `OAuth` | Yes | Unknown |
| [GurbaniNow](https://github.com/GurbaniNow/api) | Fast and Accurate Gurbani RESTful API | No | Yes | Unknown |
| [Gutendex](https://gutendex.com/) | Web-API for fetching data from Project Gutenberg Books Library | No | Yes | Unknown |
| [Open Library](https://openlibrary.org/developers/api) | Books, book covers and related data | No | Yes | No |
| [Penguin Publishing](http://www.penguinrandomhouse.biz/webservices/rest/) | Books, book covers and related data | No | Yes | Yes |
| [PoetryDB](https://github.com/thundercomb/poetrydb#readme) | Enables you to get instant data from our vast p

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[alexta69/metube]]></title>
            <link>https://github.com/alexta69/metube</link>
            <guid>https://github.com/alexta69/metube</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[Self-hosted YouTube downloader (web UI for youtube-dl / yt-dlp)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/alexta69/metube">alexta69/metube</a></h1>
            <p>Self-hosted YouTube downloader (web UI for youtube-dl / yt-dlp)</p>
            <p>Language: Python</p>
            <p>Stars: 11,266</p>
            <p>Forks: 759</p>
            <p>Stars today: 16 stars today</p>
            <h2>README</h2><pre># MeTube

![Build Status](https://github.com/alexta69/metube/actions/workflows/main.yml/badge.svg)
![Docker Pulls](https://img.shields.io/docker/pulls/alexta69/metube.svg)

Web GUI for youtube-dl (using the [yt-dlp](https://github.com/yt-dlp/yt-dlp) fork) with playlist support. Allows you to download videos from YouTube and [dozens of other sites](https://github.com/yt-dlp/yt-dlp/blob/master/supportedsites.md).

![screenshot1](https://github.com/alexta69/metube/raw/master/screenshot.gif)

## ğŸ³ Run using Docker

```bash
docker run -d -p 8081:8081 -v /path/to/downloads:/downloads ghcr.io/alexta69/metube
```

## ğŸ³ Run using docker-compose

```yaml
services:
  metube:
    image: ghcr.io/alexta69/metube
    container_name: metube
    restart: unless-stopped
    ports:
      - &quot;8081:8081&quot;
    volumes:
      - /path/to/downloads:/downloads
```

## âš™ï¸ Configuration via environment variables

Certain values can be set via environment variables, using the `-e` parameter on the docker command line, or the `environment:` section in docker-compose.

### â¬‡ï¸ Download Behavior

* __DOWNLOAD_MODE__: This flag controls how downloads are scheduled and executed. Options are `sequential`, `concurrent`, and `limited`.  Defaults to `limited`:
    *   `sequential`: Downloads are processed one at a time. A new download won&#039;t start until the previous one has finished. This mode is useful for conserving system resources or ensuring downloads occur in strict order.
    *   `concurrent`: Downloads are started immediately as they are added, with no built-in limit on how many run simultaneously. This mode may overwhelm your system if too many downloads start at once.
    *   `limited`: Downloads are started concurrently but are capped by a concurrency limit. In this mode, a semaphore is used so that at most a fixed number of downloads run at any given time.
* __MAX_CONCURRENT_DOWNLOADS__: This flag is used only when `DOWNLOAD_MODE` is set to `limited`.  
    It specifies the maximum number of simultaneous downloads allowed. For example, if set to `5`, then at most five downloads will run concurrently, and any additional downloads will wait until one of the active downloads completes. Defaults to `3`. 
* __DELETE_FILE_ON_TRASHCAN__: if `true`, downloaded files are deleted on the server, when they are trashed from the &quot;Completed&quot; section of the UI. Defaults to `false`.
* __DEFAULT_OPTION_PLAYLIST_STRICT_MODE__: if `true`, the &quot;Strict Playlist mode&quot; switch will be enabled by default. In this mode the playlists will be downloaded only if the URL strictly points to a playlist. URLs to videos inside a playlist will be treated same as direct video URL. Defaults to `false` .
* __DEFAULT_OPTION_PLAYLIST_ITEM_LIMIT__: Maximum number of playlist items that can be downloaded. Defaults to `0` (no limit).

### ğŸ“ Storage &amp; Directories

* __DOWNLOAD_DIR__: Path to where the downloads will be saved. Defaults to `/downloads` in the Docker image, and `.` otherwise.
* __AUDIO_DOWNLOAD_DIR__: Path to where audio-only downloads will be saved, if you wish to separate them from the video downloads. Defaults to the value of `DOWNLOAD_DIR`.
* __CUSTOM_DIRS__: Whether to enable downloading videos into custom directories within the __DOWNLOAD_DIR__ (or __AUDIO_DOWNLOAD_DIR__). When enabled, a dropdown appears next to the Add button to specify the download directory. Defaults to `true`.
* __CREATE_CUSTOM_DIRS__: Whether to support automatically creating directories within the __DOWNLOAD_DIR__ (or __AUDIO_DOWNLOAD_DIR__) if they do not exist. When enabled, the download directory selector supports free-text input, and the specified directory will be created recursively. Defaults to `true`.
* __CUSTOM_DIRS_EXCLUDE_REGEX__: Regular expression to exclude some custom directories from the dropdown. Empty regex disables exclusion. Defaults to `(^|/)[.@].*$`, which means directories starting with `.` or `@`.
* __DOWNLOAD_DIRS_INDEXABLE__: If `true`, the download directories (__DOWNLOAD_DIR__ and __AUDIO_DOWNLOAD_DIR__) are indexable on the web server. Defaults to `false`.
* __STATE_DIR__: Path to where the queue persistence files will be saved. Defaults to `/downloads/.metube` in the Docker image, and `.` otherwise.
* __TEMP_DIR__: Path where intermediary download files will be saved. Defaults to `/downloads` in the Docker image, and `.` otherwise.
  * Set this to an SSD or RAM filesystem (e.g., `tmpfs`) for better performance.
  * __Note__: Using a RAM filesystem may prevent downloads from being resumed.

### ğŸ“ File Naming &amp; yt-dlp

* __OUTPUT_TEMPLATE__: The template for the filenames of the downloaded videos, formatted according to [this spec](https://github.com/yt-dlp/yt-dlp/blob/master/README.md#output-template). Defaults to `%(title)s.%(ext)s`.
* __OUTPUT_TEMPLATE_CHAPTER__: The template for the filenames of the downloaded videos when split into chapters via postprocessors. Defaults to `%(title)s - %(section_number)s %(section_title)s.%(ext)s`.
* __OUTPUT_TEMPLATE_PLAYLIST__: The template for the filenames of the downloaded videos when downloaded as a playlist. Defaults to `%(playlist_title)s/%(title)s.%(ext)s`. When empty, then `OUTPUT_TEMPLATE` is used.
* __YTDL_OPTIONS__: Additional options to pass to yt-dlp in JSON format. [See available options here](https://github.com/yt-dlp/yt-dlp/blob/master/yt_dlp/YoutubeDL.py#L222). They roughly correspond to command-line options, though some do not have exact equivalents here. For example, `--recode-video` has to be specified via `postprocessors`. Also note that dashes are replaced with underscores. You may find [this script](https://github.com/yt-dlp/yt-dlp/blob/master/devscripts/cli_to_api.py) helpful for converting from command-line options to `YTDL_OPTIONS`.
* __YTDL_OPTIONS_FILE__: A path to a JSON file that will be loaded and used for populating `YTDL_OPTIONS` above. Please note that if both `YTDL_OPTIONS_FILE` and `YTDL_OPTIONS` are specified, the options in `YTDL_OPTIONS` take precedence. The file will be monitored for changes and reloaded automatically when changes are detected.

### ğŸŒ Web Server &amp; URLs

* __URL_PREFIX__: Base path for the web server (for use when hosting behind a reverse proxy). Defaults to `/`.
* __PUBLIC_HOST_URL__: Base URL for the download links shown in the UI for completed files. By default, MeTube serves them under its own URL. If your download directory is accessible on another URL and you want the download links to be based there, use this variable to set it.
* __PUBLIC_HOST_AUDIO_URL__: Same as PUBLIC_HOST_URL but for audio downloads.
* __HTTPS__: Use `https` instead of `http` (__CERTFILE__ and __KEYFILE__ required). Defaults to `false`.
* __CERTFILE__: HTTPS certificate file path.
* __KEYFILE__: HTTPS key file path.
* __ROBOTS_TXT__: A path to a `robots.txt` file mounted in the container.

### ğŸ  Basic Setup

* __UID__: User under which MeTube will run. Defaults to `1000`.
* __GID__: Group under which MeTube will run. Defaults to `1000`.
* __UMASK__: Umask value used by MeTube. Defaults to `022`.
* __DEFAULT_THEME__: Default theme to use for the UI, can be set to `light`, `dark`, or `auto`. Defaults to `auto`.
* __LOGLEVEL__: Log level, can be set to `DEBUG`, `INFO`, `WARNING`, `ERROR`, `CRITICAL`, or `NONE`. Defaults to `INFO`. 
* __ENABLE_ACCESSLOG__: Whether to enable access log. Defaults to `false`.

The project&#039;s Wiki contains examples of useful configurations contributed by users of MeTube:
* [YTDL_OPTIONS Cookbook](https://github.com/alexta69/metube/wiki/YTDL_OPTIONS-Cookbook)
* [OUTPUT_TEMPLATE Cookbook](https://github.com/alexta69/metube/wiki/OUTPUT_TEMPLATE-Cookbook)

## ğŸª Using browser cookies

In case you need to use your browser&#039;s cookies with MeTube, for example to download restricted or private videos:

* Add the following to your docker-compose.yml:

```yaml
    volumes:
      - /path/to/cookies:/cookies
    environment:
      - YTDL_OPTIONS={&quot;cookiefile&quot;:&quot;/cookies/cookies.txt&quot;}
```

* Install in your browser an extension to extract cookies:
  * [Firefox](https://addons.mozilla.org/en-US/firefox/addon/export-cookies-txt/)
  * [Chrome](https://chrome.google.com/webstore/detail/get-cookiestxt-locally/cclelndahbckbenkjhflpdbgdldlbecc)
* Extract the cookies you need with the extension and rename the file `cookies.txt`
* Drop the file in the folder you configured in the docker-compose.yml above
* Restart the container

## ğŸ”Œ Browser extensions

Browser extensions allow right-clicking videos and sending them directly to MeTube. Please note that if you&#039;re on an HTTPS page, your MeTube instance must be behind an HTTPS reverse proxy (see below) for the extensions to work.

__Chrome:__ contributed by [Rpsl](https://github.com/rpsl). You can install it from [Google Chrome Webstore](https://chrome.google.com/webstore/detail/metube-downloader/fbmkmdnlhacefjljljlbhkodfmfkijdh) or use developer mode and install [from sources](https://github.com/Rpsl/metube-browser-extension).

__Firefox:__ contributed by [nanocortex](https://github.com/nanocortex). You can install it from [Firefox Addons](https://addons.mozilla.org/en-US/firefox/addon/metube-downloader) or get sources from [here](https://github.com/nanocortex/metube-firefox-addon).

## ğŸ“± iOS Shortcut

[rithask](https://github.com/rithask) created an iOS shortcut to send URLs to MeTube from Safari. Enter the MeTube instance address when prompted which will be saved for later use. You can run the shortcut from Safariâ€™s share menu. The shortcut can be downloaded from [this iCloud link](https://www.icloud.com/shortcuts/66627a9f334c467baabdb2769763a1a6).

## ğŸ“± iOS Compatibility

iOS has strict requirements for video files, requiring h264 or h265 video codec and aac audio codec in MP4 container. This can sometimes be a lower quality than the best quality available. To accommodate iOS requirements, when downloading a MP4 format you can choose &quot;Best (iOS)&quot; to get the best quality formats as compatible as possible with iOS requirements.

To force all downloads to be converted to an iOS-compatible codec, insert this as an environment variable: 

```yaml
  environment:
    - &#039;YTDL_OPTIONS={&quot;format&quot;: &quot;best&quot;, &quot;exec&quot;: &quot;ffmpeg -i %(filepath)q -c:v libx264 -c:a aac %(filepath)q.h264.mp4&quot;}&#039;
```

## ğŸ”– Bookmarklet

[kushfest](https://github.com/kushfest) has created a Chrome bookmarklet for sending the currently open webpage to MeTube. Please note that if you&#039;re on an HTTPS page, your MeTube instance must be configured with `HTTPS` as `true` in the environment, or be behind an HTTPS reverse proxy (see below) for the bookmarklet to work.

GitHub doesn&#039;t allow embedding JavaScript as a link, so the bookmarklet has to be created manually by copying the following code to a new bookmark you create on your bookmarks bar. Change the hostname in the URL below to point to your MeTube instance.

```javascript
javascript:!function(){xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.withCredentials=true;xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function(){if(xhr.status==200){alert(&quot;Sent to metube!&quot;)}else{alert(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}}();
```

[shoonya75](https://github.com/shoonya75) has contributed a Firefox version:

```javascript
javascript:(function(){xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function(){if(xhr.status==200){alert(&quot;Sent to metube!&quot;)}else{alert(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}})();
```

The above bookmarklets use `alert()` as a success/failure notification. The following will show a toast message instead:

Chrome:

```javascript
javascript:!function(){function notify(msg) {var sc = document.scrollingElement.scrollTop; var text = document.createElement(&#039;span&#039;);text.innerHTML=msg;var ts = text.style;ts.all = &#039;revert&#039;;ts.color = &#039;#000&#039;;ts.fontFamily = &#039;Verdana, sans-serif&#039;;ts.fontSize = &#039;15px&#039;;ts.backgroundColor = &#039;white&#039;;ts.padding = &#039;15px&#039;;ts.border = &#039;1px solid gainsboro&#039;;ts.boxShadow = &#039;3px 3px 10px&#039;;ts.zIndex = &#039;100&#039;;document.body.appendChild(text);ts.position = &#039;absolute&#039;; ts.top = 50 + sc + &#039;px&#039;; ts.left = (window.innerWidth / 2)-(text.offsetWidth / 2) + &#039;px&#039;; setTimeout(function () { text.style.visibility = &quot;hidden&quot;; }, 1500);}xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function() { if(xhr.status==200){notify(&quot;Sent to metube!&quot;)}else {notify(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}}();
```

Firefox:

```javascript
javascript:(function(){function notify(msg) {var sc = document.scrollingElement.scrollTop; var text = document.createElement(&#039;span&#039;);text.innerHTML=msg;var ts = text.style;ts.all = &#039;revert&#039;;ts.color = &#039;#000&#039;;ts.fontFamily = &#039;Verdana, sans-serif&#039;;ts.fontSize = &#039;15px&#039;;ts.backgroundColor = &#039;white&#039;;ts.padding = &#039;15px&#039;;ts.border = &#039;1px solid gainsboro&#039;;ts.boxShadow = &#039;3px 3px 10px&#039;;ts.zIndex = &#039;100&#039;;document.body.appendChild(text);ts.position = &#039;absolute&#039;; ts.top = 50 + sc + &#039;px&#039;; ts.left = (window.innerWidth / 2)-(text.offsetWidth / 2) + &#039;px&#039;; setTimeout(function () { text.style.visibility = &quot;hidden&quot;; }, 1500);}xhr=new XMLHttpRequest();xhr.open(&quot;POST&quot;,&quot;https://metube.domain.com/add&quot;);xhr.send(JSON.stringify({&quot;url&quot;:document.location.href,&quot;quality&quot;:&quot;best&quot;}));xhr.onload=function() { if(xhr.status==200){notify(&quot;Sent to metube!&quot;)}else {notify(&quot;Send to metube failed. Check the javascript console for clues.&quot;)}}})();
```

## âš¡ Raycast extension

[dotvhs](https://github.com/dotvhs) has created an [extension for Raycast](https://www.raycast.com/dot/metube) that allows adding videos to MeTube directly from Raycast.

## ğŸ”’ HTTPS support, and running behind a reverse proxy

It&#039;s possible to configure MeTube to listen in HTTPS mode. `docker-compose` example:

```yaml
services:
  metube:
    image: ghcr.io/alexta69/metube
    container_name: metube
    restart: unless-stopped
    ports:
      - &quot;8081:8081&quot;
    volumes:
      - /path/to/downloads:/downloads
      - /path/to/ssl/crt:/ssl/crt.pem
      - /path/to/ssl/key:/ssl/key.pem
    environment:
      - HTTPS=true
      - CERTFILE=/ssl/crt.pem
      - KEYFILE=/ssl/key.pem
```

It&#039;s also possible to run MeTube behind a reverse proxy, in order to support authentication. HTTPS support can also be added in this way.

When running behind a reverse proxy which remaps the URL (i.e. serves MeTube under a subdirectory and not under root), don&#039;t forget to set the URL_PREFIX environment variable to the correct value.

If you&#039;re using the [linuxserver/swag](https://docs.linuxserver.io/general/swag) image for your reverse proxying needs (which I can heartily recommend), it already includes ready snippets for proxying MeTube both in [subfolder](https://github.com/linuxserver/reverse-proxy-confs/blob/master/metube.subfolder.conf.sample) and [subdomain](https://github.com/linuxserver/reverse-proxy-confs/blob/master/metube.subdomain.conf.sample) modes under the `nginx/proxy-confs` directory in the configuration volume. It also includes Authelia which can be used for authentication.

### ğŸŒ NGINX

```nginx
location /metube/ {
        proxy_pass http://metube:8081;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection &quot;upgrade&quot;;
        proxy_set_header Host $host;
}
```

Note: the extra `proxy_set_header` directives are there to make WebSocket work.

### ğŸŒ Apache

Contributed by [PIE-yt](https://github.com/PIE-yt). Source [here](https://gist.github.com/PIE-yt/29e7116588379032427f5bd446b2cac4).

```apache
# For putting in your Apache sites site.conf
# Serves MeTube under a /metube/ subdir (http://yourdomain.com/metube/)
&lt;Location /metube/&gt;
    ProxyPass http://localhost:8081/ retry=0 timeout=30
    ProxyPassReverse http://localhost:8081/
&lt;/Location&gt;

&lt;Location /metube/socket.io&gt;
    RewriteEngine On
    RewriteCond %{QUERY_STRING} transport=websocket    [NC]
    RewriteRule /(.*) ws://localhost:8081/socket.io/$1 [P,L]
    ProxyPass http://localhost:8081/socket.io retry=0 timeout=30
    ProxyPassReverse http://localhost:8081/socket.io
&lt;/Location&gt;
```

### ğŸŒ Caddy

The following example Caddyfile gets a reverse proxy going behind [caddy](https://caddyserver.com).

```caddyfile
example.com {
  route /metube/* {
    uri strip_prefix metube
    reverse_proxy metube:8081
  }
}
```

## ğŸ”„ Updating yt-dlp

The engine which powers the actual video downloads in MeTube is [yt-dlp](https://github.com/yt-dlp/yt-dlp). Since video sites regularly change their layouts, frequent updates of yt-dlp are required to keep up.

There&#039;s an automatic nightly build of MeTube which looks for a new version of yt-dlp, and if one exists, the build pulls it and publishes an updated docker image. Therefore, in order to keep up with the changes, it&#039;s recommended that you update your MeTube container regularly with the latest image.

I recommend installing and setting up [watchtower](https://github.com/nicholas-fedor/watchtower) for this purpose.

## ğŸ”§ Troubleshooting and submitting issues

Before asking a question or submitting an issue for MeTube, please remember that MeTube is only a UI for [yt-dlp](https://github.com/yt-dlp/yt-dlp). Any issues you might be experiencing with authentication to video websites, postprocessing, permissions, other `YTDL_OPTIONS` configurations which seem not to work, or anything else that concerns the workings of the underlying yt-dlp library, need not be opened on the MeTube project. In order to debug and troubleshoot them, it&#039;s advised to try using the yt-dlp binary directly first, bypassing the UI, and once that is working, importing the options that worked for you into `YTDL_OPTIONS`.

In order to test with the yt-dlp command directly, you can either download it and run it locally, or for a better simulation of its actual conditions, you can run it within the MeTube container itself. Assuming your MeTube container is called `metube`, run the following on your Docker host to get a shell inside the container:

```bash
docker exec -ti metube sh
cd /downloads
```

Once there, you can use the yt-dlp command freely.

## ğŸ’¡ Submitting feature requests

MeTube development relies on code contributions by the community. The program as it currently stands fits my own use cases, and is therefore feature-complete as far as I&#039;m concerned. If your use cases are different and require additional features, please feel free to submit PRs that implement those features. It&#039;s advisable to create an issue first to discuss the planned implementation, because in an effort to reduce bloat, some PRs may not be accepted. However, note that opening a feature request when you don&#039;t intend to implement the feature will rarely result in the request being fulfilled.

## ğŸ› ï¸ Building and running locally

Make sure you have Node.js 22+ and Python 3.13 installed.

```bash
cd metube/ui
# install Angular and build the UI
pnpm install
pnpm run build
# install python dependencies
cd ..
curl -LsSf https://astral.sh/uv/install.sh | sh
uv sync
# run
uv run python3 app/main.py
```

A Docker image can be built locally (it will build the UI too):

```bash
docker build -t metube .
```

Note that if you&#039;re running the server in VSCode, your downloads will go to your user&#039;s Downloads folder (this is configured via the environment in `.vscode/launch.json`).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[MODSetter/SurfSense]]></title>
            <link>https://github.com/MODSetter/SurfSense</link>
            <guid>https://github.com/MODSetter/SurfSense</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:53 GMT</pubDate>
            <description><![CDATA[Open source alternative to NotebookLM, Perplexity, and Glean. Connects to search engines, Slack, Linear, Jira, ClickUp, Notion, Discord, and 15+ more connectors. Join our Discord: https://discord.gg/ejRNvftDp9]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/MODSetter/SurfSense">MODSetter/SurfSense</a></h1>
            <p>Open source alternative to NotebookLM, Perplexity, and Glean. Connects to search engines, Slack, Linear, Jira, ClickUp, Notion, Discord, and 15+ more connectors. Join our Discord: https://discord.gg/ejRNvftDp9</p>
            <p>Language: Python</p>
            <p>Stars: 12,015</p>
            <p>Forks: 1,013</p>
            <p>Stars today: 119 stars today</p>
            <h2>README</h2><pre>
![new_header](https://github.com/user-attachments/assets/e236b764-0ddc-42ff-a1f1-8fbb3d2e0e65)


&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://discord.gg/ejRNvftDp9&quot;&gt;
&lt;img src=&quot;https://img.shields.io/discord/1359368468260192417&quot; alt=&quot;Discord&quot;&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

[English](README.md) | [ç®€ä½“ä¸­æ–‡](README.zh-CN.md)

&lt;/div&gt;

# SurfSense
While tools like NotebookLM and Perplexity are impressive and highly effective for conducting research on any topic/query, SurfSense elevates this capability by integrating with your personal knowledge base. It is a highly customizable AI research agent, connected to external sources such as Search Engines (SearxNG, Tavily, LinkUp), Slack, Linear, Jira, ClickUp, Confluence, BookStack, Gmail, Notion, YouTube, GitHub, Discord, Airtable, Google Calendar, Luma, Elasticsearch and more to come.

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13606&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13606&quot; alt=&quot;MODSetter%2FSurfSense | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;


# Video 

https://github.com/user-attachments/assets/42a29ea1-d4d8-4213-9c69-972b5b806d58



## Podcast Sample

https://github.com/user-attachments/assets/a0a16566-6967-4374-ac51-9b3e07fbecd7




## Key Features

### ğŸ’¡ **Idea**: 
- Have your own highly customizable private NotebookLM and Perplexity integrated with external sources.
### ğŸ“ **Multiple File Format Uploading Support**
- Save content from your own personal files *(Documents, images, videos and supports **50+ file extensions**)* to your own personal knowledge base .
### ğŸ” **Powerful Search**
- Quickly research or find anything in your saved content .
### ğŸ’¬ **Chat with your Saved Content**
- Interact in Natural Language and get cited answers.
### ğŸ“„ **Cited Answers**
- Get Cited answers just like Perplexity.
### ğŸ”” **Privacy &amp; Local LLM Support**
- Works Flawlessly with Ollama local LLMs.
### ğŸ  **Self Hostable**
- Open source and easy to deploy locally.
### ğŸ‘¥ **Team Collaboration with RBAC**
- Role-Based Access Control for Search Spaces
- Invite team members with customizable roles (Owner, Admin, Editor, Viewer)
- Granular permissions for documents, chats, connectors, and settings
- Share knowledge bases securely within your organization
### ğŸ™ï¸ Podcasts 
- Blazingly fast podcast generation agent. (Creates a 3-minute podcast in under 20 seconds.)
- Convert your chat conversations into engaging audio content
- Support for local TTS providers (Kokoro TTS)
- Support for multiple TTS providers (OpenAI, Azure, Google Vertex AI)

### ğŸ¤– **Deep Agent Architecture**

#### Built-in Agent Tools
| Tool | Description |
|------|-------------|
| **search_knowledge_base** | Search your personal knowledge base with semantic + full-text hybrid search, date filtering, and connector-specific queries |
| **generate_podcast** | Generate audio podcasts from chat conversations or knowledge base content |
| **link_preview** | Fetch rich Open Graph metadata for URLs to display preview cards |
| **display_image** | Display images in chat with metadata and source attribution |
| **scrape_webpage** | Extract full content from webpages for analysis and summarization (supports Firecrawl or local Chromium/Trafilatura) |

#### Extensible Tools Registry
Contributors can easily add new tools via the registry pattern:
1. Create a tool factory function in `surfsense_backend/app/agents/new_chat/tools/`
2. Register it in the `BUILTIN_TOOLS` list in `registry.py`

#### Configurable System Prompts
- Custom system instructions via LLM configuration
- Toggle citations on/off per configuration
- Supports 100+ LLMs via LiteLLM integration

### ğŸ“Š **Advanced RAG Techniques**
- Supports 100+ LLM&#039;s
- Supports 6000+ Embedding Models.
- Supports all major Rerankers (Pinecone, Cohere, Flashrank etc)
- Uses Hierarchical Indices (2 tiered RAG setup).
- Utilizes Hybrid Search (Semantic + Full Text Search combined with Reciprocal Rank Fusion).

### â„¹ï¸ **External Sources**
- Search Engines (Tavily, LinkUp)
- SearxNG (self-hosted instances)
- Slack
- Linear
- Jira
- ClickUp
- Confluence
- BookStack
- Notion
- Gmail
- Youtube Videos
- GitHub
- Discord
- Airtable
- Google Calendar
- Luma
- Elasticsearch
- and more to come.....

## ğŸ“„ **Supported File Extensions**

| ETL Service | Formats | Notes |
|-------------|---------|-------|
| **LlamaCloud** | 50+ formats | Documents, presentations, spreadsheets, images |
| **Unstructured** | 34+ formats | Core formats + email support |
| **Docling** | Core formats | Local processing, no API key required |

**Audio/Video** (via STT Service): `.mp3`, `.wav`, `.mp4`, `.webm`, etc.

### ğŸ”– Cross Browser Extension
- The SurfSense extension can be used to save any webpage you like.
- Its main usecase is to save any webpages protected beyond authentication.



## FEATURE REQUESTS AND FUTURE


**SurfSense is actively being developed.** While it&#039;s not yet production-ready, you can help us speed up the process.

Join the [SurfSense Discord](https://discord.gg/ejRNvftDp9) and help shape the future of SurfSense!

## ğŸš€ Roadmap

Stay up to date with our development progress and upcoming features!  
Check out our public roadmap and contribute your ideas or feedback:

**ğŸ“‹ Roadmap Discussion:** [SurfSense 2025-2026 Roadmap: Deep Agents, Real-Time Collaboration &amp; MCP Servers](https://github.com/MODSetter/SurfSense/discussions/565)

**ğŸ“Š Kanban Board:** [SurfSense Project Board](https://github.com/users/MODSetter/projects/3)


## How to get started?

### Quick Start with Docker ğŸ³

&gt; [!TIP]
&gt; For production deployments, use the full [Docker Compose setup](https://www.surfsense.com/docs/docker-installation) which offers more control and scalability.

**Linux/macOS:**

```bash
docker run -d -p 3000:3000 -p 8000:8000 \
  -v surfsense-data:/data \
  --name surfsense \
  --restart unless-stopped \
  ghcr.io/modsetter/surfsense:latest
```

**Windows (PowerShell):**

```powershell
docker run -d -p 3000:3000 -p 8000:8000 `
  -v surfsense-data:/data `
  --name surfsense `
  --restart unless-stopped `
  ghcr.io/modsetter/surfsense:latest
```

**With Custom Configuration (e.g., OpenAI Embeddings):**

```bash
docker run -d -p 3000:3000 -p 8000:8000 \
  -v surfsense-data:/data \
  -e EMBEDDING_MODEL=openai://text-embedding-ada-002 \
  -e OPENAI_API_KEY=your_openai_api_key \
  --name surfsense \
  --restart unless-stopped \
  ghcr.io/modsetter/surfsense:latest
```

After starting, access SurfSense at:
- **Frontend**: [http://localhost:3000](http://localhost:3000)
- **Backend API**: [http://localhost:8000](http://localhost:8000)
- **API Docs**: [http://localhost:8000/docs](http://localhost:8000/docs)

**Useful Commands:**

```bash
docker logs -f surfsense      # View logs
docker stop surfsense         # Stop
docker start surfsense        # Start
docker rm surfsense           # Remove (data preserved in volume)
```

### Installation Options

SurfSense provides multiple options to get started:

1. **[SurfSense Cloud](https://www.surfsense.com/login)** - The easiest way to try SurfSense without any setup.
   - No installation required
   - Instant access to all features
   - Perfect for getting started quickly

2. **Quick Start Docker (Above)** - Single command to get SurfSense running locally.
   - All-in-one image with PostgreSQL, Redis, and all services bundled
   - Perfect for evaluation, development, and small deployments
   - Data persisted via Docker volume

3. **[Docker Compose (Production)](https://www.surfsense.com/docs/docker-installation)** - Full stack deployment with separate services.
   - Includes pgAdmin for database management through a web UI
   - Supports environment variable customization via `.env` file
   - Flexible deployment options (full stack or core services only)
   - Better for production with separate scaling of services

4. **[Manual Installation](https://www.surfsense.com/docs/manual-installation)** - For users who prefer more control over their setup or need to customize their deployment.

Docker and manual installation guides include detailed OS-specific instructions for Windows, macOS, and Linux.

Before self-hosting installation, make sure to complete the [prerequisite setup steps](https://www.surfsense.com/docs/) including:
- Auth setup (optional - defaults to LOCAL auth)
- **File Processing ETL Service** (optional - defaults to Docling):
  - Docling (default, local processing, no API key required, supports PDF, Office docs, images, HTML, CSV)
  - Unstructured.io API key (supports 34+ formats)
  - LlamaIndex API key (enhanced parsing, supports 50+ formats)
- Other API keys as needed for your use case



## Tech Stack


 ### **BackEnd** 

-  **FastAPI**: Modern, fast web framework for building APIs with Python
  
-  **PostgreSQL with pgvector**: Database with vector search capabilities for similarity searches

-  **SQLAlchemy**: SQL toolkit and ORM (Object-Relational Mapping) for database interactions

-  **Alembic**: A database migrations tool for SQLAlchemy.

-  **FastAPI Users**: Authentication and user management with JWT and OAuth support

-  **Deep Agents**: Custom agent framework built on LangGraph for reasoning and acting AI agents with configurable tools

-  **LangGraph**: Framework for developing stateful AI agents with conversation persistence

-  **LangChain**: Framework for developing AI-powered applications.

-  **LiteLLM**: Universal LLM integration supporting 100+ models (OpenAI, Anthropic, Ollama, etc.)

-  **Rerankers**: Advanced result ranking for improved search relevance

-  **Hybrid Search**: Combines vector similarity and full-text search for optimal results using Reciprocal Rank Fusion (RRF)

-  **Vector Embeddings**: Document and text embeddings for semantic search

-  **pgvector**: PostgreSQL extension for efficient vector similarity operations

-  **Redis**: In-memory data structure store used as message broker and result backend for Celery

-  **Celery**: Distributed task queue for handling asynchronous background jobs (document processing, podcast generation, etc.)

-  **Flower**: Real-time monitoring and administration tool for Celery task queues

-  **Chonkie**: Advanced document chunking and embedding library
 - Uses `AutoEmbeddings` for flexible embedding model selection
 -  `LateChunker` for optimized document chunking based on embedding model&#039;s max sequence length


  
---
 ### **FrontEnd**

-  **Next.js**: React framework featuring App Router, server components, automatic code-splitting, and optimized rendering.

-  **React**: JavaScript library for building user interfaces.

-  **TypeScript**: Static type-checking for JavaScript, enhancing code quality and developer experience.

- **Vercel AI SDK Kit UI Stream Protocol**: To create scalable chat UI.

-  **Tailwind CSS**: Utility-first CSS framework for building custom UI designs.

-  **Shadcn**: Headless components library.

-  **Motion (Framer Motion)**: Animation library for React.



 ### **DevOps**

-  **Docker**: Container platform for consistent deployment across environments
  
-  **Docker Compose**: Tool for defining and running multi-container Docker applications

-  **pgAdmin**: Web-based PostgreSQL administration tool included in Docker setup


### **Extension** 
 Manifest v3 on Plasmo


## Contribute 

Contributions are very welcome! A contribution can be as small as a â­ or even finding and creating issues.
Fine-tuning the Backend is always desired.

### Adding New Agent Tools

Want to add a new tool to the SurfSense agent? It&#039;s easy:

1. Create your tool file in `surfsense_backend/app/agents/new_chat/tools/my_tool.py`
2. Register it in `registry.py`:

```python
ToolDefinition(
    name=&quot;my_tool&quot;,
    description=&quot;What my tool does&quot;,
    factory=lambda deps: create_my_tool(
        search_space_id=deps[&quot;search_space_id&quot;],
        db_session=deps[&quot;db_session&quot;],
    ),
    requires=[&quot;search_space_id&quot;, &quot;db_session&quot;],
),
```

For detailed contribution guidelines, please see our [CONTRIBUTING.md](CONTRIBUTING.md) file.

## Star History

&lt;a href=&quot;https://www.star-history.com/#MODSetter/SurfSense&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;Star History Chart&quot; src=&quot;https://api.star-history.com/svg?repos=MODSetter/SurfSense&amp;type=Date&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;

---
---
&lt;p align=&quot;center&quot;&gt;
    &lt;img 
      src=&quot;https://github.com/user-attachments/assets/329c9bc2-6005-4aed-a629-700b5ae296b4&quot; 
      alt=&quot;Catalyst Project&quot; 
      width=&quot;200&quot;
    /&gt;
&lt;/p&gt;

---
---
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[topoteretes/cognee]]></title>
            <link>https://github.com/topoteretes/cognee</link>
            <guid>https://github.com/topoteretes/cognee</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:52 GMT</pubDate>
            <description><![CDATA[Memory for AI Agents in 6 lines of code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/topoteretes/cognee">topoteretes/cognee</a></h1>
            <p>Memory for AI Agents in 6 lines of code</p>
            <p>Language: Python</p>
            <p>Stars: 10,649</p>
            <p>Forks: 981</p>
            <p>Stars today: 49 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/topoteretes/cognee&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png&quot; alt=&quot;Cognee Logo&quot; height=&quot;60&quot;&gt;
  &lt;/a&gt;

  &lt;br /&gt;

  Cognee - Accurate and Persistent AI Memory

  &lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=1bezuvLwJmw&amp;t=2s&quot;&gt;Demo&lt;/a&gt;
  .
  &lt;a href=&quot;https://docs.cognee.ai/&quot;&gt;Docs&lt;/a&gt;
  .
  &lt;a href=&quot;https://cognee.ai&quot;&gt;Learn More&lt;/a&gt;
  Â·
  &lt;a href=&quot;https://discord.gg/NQPKmU5CCg&quot;&gt;Join Discord&lt;/a&gt;
  Â·
  &lt;a href=&quot;https://www.reddit.com/r/AIMemory/&quot;&gt;Join r/AIMemory&lt;/a&gt;
  .
  &lt;a href=&quot;https://github.com/topoteretes/cognee-community&quot;&gt;Community Plugins &amp; Add-ons&lt;/a&gt;
  &lt;/p&gt;


  [![GitHub forks](https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;label=Fork&amp;maxAge=2592000)](https://GitHub.com/topoteretes/cognee/network/)
  [![GitHub stars](https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;label=Star&amp;maxAge=2592000)](https://GitHub.com/topoteretes/cognee/stargazers/)
  [![GitHub commits](https://badgen.net/github/commits/topoteretes/cognee)](https://GitHub.com/topoteretes/cognee/commit/)
  [![GitHub tag](https://badgen.net/github/tag/topoteretes/cognee)](https://github.com/topoteretes/cognee/tags/)
  [![Downloads](https://static.pepy.tech/badge/cognee)](https://pepy.tech/project/cognee)
  [![License](https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;colorB=000000)](https://github.com/topoteretes/cognee/blob/main/LICENSE)
  [![Contributors](https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;colorB=000000)](https://github.com/topoteretes/cognee/graphs/contributors)
  &lt;a href=&quot;https://github.com/sponsors/topoteretes&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Sponsor-â¤ï¸-ff69b4.svg&quot; alt=&quot;Sponsor&quot;&gt;&lt;/a&gt;

&lt;p&gt;
  &lt;a href=&quot;https://www.producthunt.com/posts/cognee?embed=true&amp;utm_source=badge-top-post-badge&amp;utm_medium=badge&amp;utm_souce=badge-cognee&quot; target=&quot;_blank&quot; style=&quot;display:inline-block; margin-right:10px;&quot;&gt;
    &lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;theme=light&amp;period=daily&amp;t=1744472480704&quot; alt=&quot;cognee - Memory&amp;#0032;for&amp;#0032;AI&amp;#0032;Agents&amp;#0032;&amp;#0032;in&amp;#0032;5&amp;#0032;lines&amp;#0032;of&amp;#0032;code | Product Hunt&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;
  &lt;/a&gt;

  &lt;a href=&quot;https://trendshift.io/repositories/13955&quot; target=&quot;_blank&quot; style=&quot;display:inline-block;&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/13955&quot; alt=&quot;topoteretes%2Fcognee | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

Use your data to build personalized and dynamic memory for AI Agents. Cognee lets you replace RAG with scalable and modular ECL (Extract, Cognify, Load) pipelines.

  &lt;p align=&quot;center&quot;&gt;
  ğŸŒ Available Languages
  :
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=de&quot;&gt;Deutsch&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=es&quot;&gt;EspaÃ±ol&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=fr&quot;&gt;FranÃ§ais&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=ja&quot;&gt;æ—¥æœ¬èª&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=ko&quot;&gt;í•œêµ­ì–´&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=pt&quot;&gt;PortuguÃªs&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=ru&quot;&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=zh&quot;&gt;ä¸­æ–‡&lt;/a&gt;
  &lt;/p&gt;


&lt;div style=&quot;text-align: center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png&quot; alt=&quot;Why cognee?&quot; width=&quot;50%&quot; /&gt;
&lt;/div&gt;
&lt;/div&gt;

## About Cognee

Cognee is an open-source tool and platform that transforms your raw data into persistent and dynamic AI memory for Agents. It combines vector search with graph databases to make your documents both searchable by meaning and connected by relationships. 

You can use Cognee in two ways:

1. [Self-host Cognee Open Source](https://docs.cognee.ai/getting-started/installation), which stores all data locally by default.
2. [Connect to Cognee Cloud](https://platform.cognee.ai/), and get the same OSS stack on managed infrastructure for easier development and productionization. 

### Cognee Open Source (self-hosted):

- Interconnects any type of data â€” including past conversations, files, images, and audio transcriptions
- Replaces traditional RAG systems with a unified memory layer built on graphs and vectors
- Reduces developer effort and infrastructure cost while improving quality and precision
- Provides Pythonic data pipelines for ingestion from 30+ data sources
- Offers high customizability through user-defined tasks, modular pipelines, and built-in search endpoints

### Cognee Cloud (managed):
- Hosted web UI dashboard 
- Automatic version updates 
- Resource usage analytics
- GDPR compliant, enterprise-grade security

## Basic Usage &amp; Feature Guide

To learn more, [check out this short, end-to-end Colab walkthrough](https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing) of Cognee&#039;s core features.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing)

## Quickstart

Letâ€™s try Cognee in just a few lines of code. For detailed setup and configuration, see the [Cognee Docs](https://docs.cognee.ai/getting-started/installation#environment-configuration).

### Prerequisites

- Python 3.10 to 3.13

### Step 1: Install Cognee

You can install Cognee with **pip**, **poetry**, **uv**, or your preferred Python package manager.

```bash
uv pip install cognee
```

### Step 2: Configure the LLM
```python
import os
os.environ[&quot;LLM_API_KEY&quot;] = &quot;YOUR OPENAI_API_KEY&quot;
```
Alternatively, create a `.env` file using our [template](https://github.com/topoteretes/cognee/blob/main/.env.template).

To integrate other LLM providers, see our [LLM Provider Documentation](https://docs.cognee.ai/setup-configuration/llm-providers).

### Step 3: Run the Pipeline

Cognee will take your documents, generate a knowledge graph from them and then query the graph based on combined relationships. 

Now, run a minimal pipeline:

```python
import cognee
import asyncio
from pprint import pprint


async def main():
    # Add text to cognee
    await cognee.add(&quot;Cognee turns documents into AI memory.&quot;)

    # Generate the knowledge graph
    await cognee.cognify()

    # Add memory algorithms to the graph
    await cognee.memify()

    # Query the knowledge graph
    results = await cognee.search(&quot;What does Cognee do?&quot;)

    # Display the results
    for result in results:
        pprint(result)


if __name__ == &#039;__main__&#039;:
    asyncio.run(main())

```

As you can see, the output is generated from the document we previously stored in Cognee:

```bash
  Cognee turns documents into AI memory.
```

### Use the Cognee CLI 

As an alternative, you can get started with these essential commands:

```bash
cognee-cli add &quot;Cognee turns documents into AI memory.&quot;

cognee-cli cognify

cognee-cli search &quot;What does Cognee do?&quot;
cognee-cli delete --all

```

To open the local UI, run:
```bash
cognee-cli -ui
```

## Demos &amp; Examples

See Cognee in action:

### Persistent Agent Memory

[Cognee Memory for LangGraph Agents](https://github.com/user-attachments/assets/e113b628-7212-4a2b-b288-0be39a93a1c3)

### Simple GraphRAG

[Watch Demo](https://github.com/user-attachments/assets/f2186b2e-305a-42b0-9c2d-9f4473f15df8)

### Cognee with Ollama

[Watch Demo](https://github.com/user-attachments/assets/39672858-f774-4136-b957-1e2de67b8981)


## Community &amp; Support

### Contributing
We welcome contributions from the community! Your input helps make Cognee better for everyone. See [`CONTRIBUTING.md`](CONTRIBUTING.md) to get started.

### Code of Conduct

We&#039;re committed to fostering an inclusive and respectful community. Read our [Code of Conduct](https://github.com/topoteretes/cognee/blob/main/CODE_OF_CONDUCT.md) for guidelines.

## Research &amp; Citation

We recently published a research paper on optimizing knowledge graphs for LLM reasoning:

```bibtex
@misc{markovic2025optimizinginterfaceknowledgegraphs,
      title={Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning},
      author={Vasilije Markovic and Lazar Obradovic and Laszlo Hajdu and Jovan Pavlovic},
      year={2025},
      eprint={2505.24478},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.24478},
}
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[SkyworkAI/SkyReels-V2]]></title>
            <link>https://github.com/SkyworkAI/SkyReels-V2</link>
            <guid>https://github.com/SkyworkAI/SkyReels-V2</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:51 GMT</pubDate>
            <description><![CDATA[SkyReels-V2: Infinite-length Film Generative model]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/SkyworkAI/SkyReels-V2">SkyworkAI/SkyReels-V2</a></h1>
            <p>SkyReels-V2: Infinite-length Film Generative model</p>
            <p>Language: Python</p>
            <p>Stars: 5,417</p>
            <p>Forks: 952</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/logo2.png&quot; alt=&quot;SkyReels Logo&quot; width=&quot;50%&quot;&gt;
&lt;/p&gt;

&lt;h1 align=&quot;center&quot;&gt;SkyReels V2: Infinite-Length Film Generative Model&lt;/h1&gt; 

&lt;p align=&quot;center&quot;&gt;
ğŸ“‘ &lt;a href=&quot;https://arxiv.org/pdf/2504.13074&quot;&gt;Technical Report&lt;/a&gt; Â· ğŸ‘‹ &lt;a href=&quot;https://www.skyreels.ai/home?utm_campaign=github_SkyReels_V2&quot; target=&quot;_blank&quot;&gt;Playground&lt;/a&gt; Â· ğŸ’¬ &lt;a href=&quot;https://discord.gg/PwM6NYtccQ&quot; target=&quot;_blank&quot;&gt;Discord&lt;/a&gt; Â· ğŸ¤— &lt;a href=&quot;https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9&quot; target=&quot;_blank&quot;&gt;Hugging Face&lt;/a&gt; Â· ğŸ¤– &lt;a href=&quot;https://www.modelscope.cn/collections/SkyReels-V2-f665650130b144&quot; target=&quot;_blank&quot;&gt;ModelScope&lt;/a&gt;
&lt;/p&gt;

---
Welcome to the **SkyReels V2** repository! Here, you&#039;ll find the model weights and inference code for our infinite-length film generative models. To the best of our knowledge, it represents the first open-source video generative model employing **AutoRegressive Diffusion-Forcing architecture** that achieves the **SOTA performance** among publicly available models.


## ğŸ”¥ğŸ”¥ğŸ”¥ News!!
* Jun 1, 2025: ğŸ‰ We published the technical report, [SkyReels-Audio: Omni Audio-Conditioned Talking Portraits in Video Diffusion Transformers](https://arxiv.org/pdf/2506.00830).
* May 16, 2025: ğŸ”¥ We release the inference code for [video extension](#ve) and [start/end frame control](#se) in diffusion forcing model.
* Apr 24, 2025: ğŸ”¥ We release the 720P models, [SkyReels-V2-DF-14B-720P](https://huggingface.co/Skywork/SkyReels-V2-DF-14B-720P) and [SkyReels-V2-I2V-14B-720P](https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-720P). The former facilitates infinite-length autoregressive video generation, and the latter focuses on Image2Video synthesis.
* Apr 21, 2025: ğŸ‘‹ We release the inference code and model weights of [SkyReels-V2](https://huggingface.co/collections/Skywork/skyreels-v2-6801b1b93df627d441d0d0d9) Series Models and the video captioning model [SkyCaptioner-V1](https://huggingface.co/Skywork/SkyCaptioner-V1) .
* Apr 3, 2025: ğŸ”¥ We also release [SkyReels-A2](https://github.com/SkyworkAI/SkyReels-A2). This is an open-sourced controllable video generation framework capable of assembling arbitrary visual elements.
* Feb 18, 2025: ğŸ”¥ we released [SkyReels-A1](https://github.com/SkyworkAI/SkyReels-A1). This is an open-sourced and effective framework for portrait image animation.
* Feb 18, 2025: ğŸ”¥ We released [SkyReels-V1](https://github.com/SkyworkAI/SkyReels-V1). This is the first and most advanced open-source human-centric video foundation model.

## ğŸ¥ Demos
&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/f6f9f9a7-5d5f-433c-9d73-d8d593b7ad25&quot; width=&quot;100%&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/0eb13415-f4d9-4aaf-bcd3-3031851109b9&quot; width=&quot;100%&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/dcd16603-5bf4-4786-8e4d-1ed23889d07a&quot; width=&quot;100%&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
The demos above showcase 30-second videos generated using our SkyReels-V2 Diffusion Forcing model.


## ğŸ“‘ TODO List

- [x] &lt;a href=&quot;https://arxiv.org/pdf/2504.13074&quot;&gt;Technical Report&lt;/a&gt;
- [x] Checkpoints of the 14B and 1.3B Models Series
- [x] Single-GPU &amp; Multi-GPU Inference Code
- [x] &lt;a href=&quot;https://huggingface.co/Skywork/SkyCaptioner-V1&quot;&gt;SkyCaptioner-V1&lt;/a&gt;: A Video Captioning Model
- [x] Prompt Enhancer
- [x] Diffusers integration
- [ ] Checkpoints of the 5B Models Series
- [ ] Checkpoints of the Camera Director Models
- [ ] Checkpoints of the Step &amp; Guidance Distill Model


## ğŸš€ Quickstart

#### Installation
```shell
# clone the repository.
git clone https://github.com/SkyworkAI/SkyReels-V2
cd SkyReels-V2
# Install dependencies. Test environment uses Python 3.10.12.
pip install -r requirements.txt
```

#### Model Download
You can download our models from Hugging Face:
&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Type&lt;/th&gt;
      &lt;th&gt;Model Variant&lt;/th&gt;
      &lt;th&gt;Recommended Height/Width/Frame&lt;/th&gt;
      &lt;th&gt;Link&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td rowspan=&quot;5&quot;&gt;Diffusion Forcing&lt;/td&gt;
      &lt;td&gt;1.3B-540P&lt;/td&gt;
      &lt;td&gt;544 * 960 * 97f&lt;/td&gt;
      &lt;td&gt;ğŸ¤— &lt;a href=&quot;https://huggingface.co/Skywork/SkyReels-V2-DF-1.3B-540P&quot;&gt;Huggingface&lt;/a&gt; ğŸ¤– &lt;a href=&quot;https://www.modelscope.cn/models/Skywork/SkyReels-V2-DF-1.3B-540P&quot;&gt;ModelScope&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5B-540P&lt;/td&gt;
      &lt;td&gt;544 * 960 * 97f&lt;/td&gt;
      &lt;td&gt;Coming Soon&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5B-720P&lt;/td&gt;
      &lt;td&gt;720 * 1280 * 121f&lt;/td&gt;
      &lt;td&gt;Coming Soon&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14B-540P&lt;/td&gt;
      &lt;td&gt;544 * 960 * 97f&lt;/td&gt;
      &lt;td&gt;ğŸ¤— &lt;a href=&quot;https://huggingface.co/Skywork/SkyReels-V2-DF-14B-540P&quot;&gt;Huggingface&lt;/a&gt; ğŸ¤– &lt;a href=&quot;https://www.modelscope.cn/models/Skywork/SkyReels-V2-DF-14B-540P&quot;&gt;ModelScope&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14B-720P&lt;/td&gt;
      &lt;td&gt;720 * 1280 * 121f&lt;/td&gt;
      &lt;td&gt;ğŸ¤— &lt;a href=&quot;https://huggingface.co/Skywork/SkyReels-V2-DF-14B-720P&quot;&gt;Huggingface&lt;/a&gt; ğŸ¤– &lt;a href=&quot;https://www.modelscope.cn/models/Skywork/SkyReels-V2-DF-14B-720P&quot;&gt;ModelScope&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td rowspan=&quot;5&quot;&gt;Text-to-Video&lt;/td&gt;
      &lt;td&gt;1.3B-540P&lt;/td&gt;
      &lt;td&gt;544 * 960 * 97f&lt;/td&gt;
      &lt;td&gt;Coming Soon&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5B-540P&lt;/td&gt;
      &lt;td&gt;544 * 960 * 97f&lt;/td&gt;
      &lt;td&gt;Coming Soon&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5B-720P&lt;/td&gt;
      &lt;td&gt;720 * 1280 * 121f&lt;/td&gt;
      &lt;td&gt;Coming Soon&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14B-540P&lt;/td&gt;
      &lt;td&gt;544 * 960 * 97f&lt;/td&gt;
      &lt;td&gt;ğŸ¤— &lt;a href=&quot;https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-540P&quot;&gt;Huggingface&lt;/a&gt; ğŸ¤– &lt;a href=&quot;https://www.modelscope.cn/models/Skywork/SkyReels-V2-T2V-14B-540P&quot;&gt;ModelScope&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14B-720P&lt;/td&gt;
      &lt;td&gt;720 * 1280 * 121f&lt;/td&gt;
      &lt;td&gt;ğŸ¤— &lt;a href=&quot;https://huggingface.co/Skywork/SkyReels-V2-T2V-14B-720P&quot;&gt;Huggingface&lt;/a&gt; ğŸ¤– &lt;a href=&quot;https://www.modelscope.cn/models/Skywork/SkyReels-V2-T2V-14B-720P&quot;&gt;ModelScope&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td rowspan=&quot;5&quot;&gt;Image-to-Video&lt;/td&gt;
      &lt;td&gt;1.3B-540P&lt;/td&gt;
      &lt;td&gt;544 * 960 * 97f&lt;/td&gt;
      &lt;td&gt;ğŸ¤— &lt;a href=&quot;https://huggingface.co/Skywork/SkyReels-V2-I2V-1.3B-540P&quot;&gt;Huggingface&lt;/a&gt; ğŸ¤– &lt;a href=&quot;https://www.modelscope.cn/models/Skywork/SkyReels-V2-I2V-1.3B-540P&quot;&gt;ModelScope&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5B-540P&lt;/td&gt;
      &lt;td&gt;544 * 960 * 97f&lt;/td&gt;
      &lt;td&gt;Coming Soon&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5B-720P&lt;/td&gt;
      &lt;td&gt;720 * 1280 * 121f&lt;/td&gt;
      &lt;td&gt;Coming Soon&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14B-540P&lt;/td&gt;
      &lt;td&gt;544 * 960 * 97f&lt;/td&gt;
      &lt;td&gt;ğŸ¤— &lt;a href=&quot;https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-540P&quot;&gt;Huggingface&lt;/a&gt; ğŸ¤– &lt;a href=&quot;https://www.modelscope.cn/models/Skywork/SkyReels-V2-I2V-14B-540P&quot;&gt;ModelScope&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14B-720P&lt;/td&gt;
      &lt;td&gt;720 * 1280 * 121f&lt;/td&gt;
      &lt;td&gt;ğŸ¤— &lt;a href=&quot;https://huggingface.co/Skywork/SkyReels-V2-I2V-14B-720P&quot;&gt;Huggingface&lt;/a&gt; ğŸ¤– &lt;a href=&quot;https://www.modelscope.cn/models/Skywork/SkyReels-V2-I2V-14B-720P&quot;&gt;ModelScope&lt;/a&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td rowspan=&quot;3&quot;&gt;Camera Director&lt;/td&gt;
      &lt;td&gt;5B-540P&lt;/td&gt;
      &lt;td&gt;544 * 960 * 97f&lt;/td&gt;
      &lt;td&gt;Coming Soon&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5B-720P&lt;/td&gt;
      &lt;td&gt;720 * 1280 * 121f&lt;/td&gt;
      &lt;td&gt;Coming Soon&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14B-720P&lt;/td&gt;
      &lt;td&gt;720 * 1280 * 121f&lt;/td&gt;
      &lt;td&gt;Coming Soon&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

After downloading, set the model path in your generation commands:


#### Single GPU Inference

- **Diffusion Forcing for Long Video Generation**

The &lt;a href=&quot;https://arxiv.org/abs/2407.01392&quot;&gt;**Diffusion Forcing**&lt;/a&gt; version model allows us to generate Infinite-Length videos. This model supports both **text-to-video (T2V)** and **image-to-video (I2V)** tasks, and it can perform inference in both synchronous and asynchronous modes. Here we demonstrate 2 running scripts as examples for long video generation. If you want to adjust the inference parameters, e.g., the duration of video, inference mode, read the Note below first.

synchronous generation for 10s video
```shell
model_id=Skywork/SkyReels-V2-DF-14B-540P
# synchronous inference
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 257 \
  --overlap_history 17 \
  --prompt &quot;A graceful white swan with a curved neck and delicate feathers swimming in a serene lake at dawn, its reflection perfectly mirrored in the still water as mist rises from the surface, with the swan occasionally dipping its head into the water to feed.&quot; \
  --addnoise_condition 20 \
  --offload \
  --teacache \
  --use_ret_steps \
  --teacache_thresh 0.3
```

asynchronous generation for 30s video
```shell
model_id=Skywork/SkyReels-V2-DF-14B-540P
# asynchronous inference
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 5 \
  --causal_block_size 5 \
  --base_num_frames 97 \
  --num_frames 737 \
  --overlap_history 17 \
  --prompt &quot;A graceful white swan with a curved neck and delicate feathers swimming in a serene lake at dawn, its reflection perfectly mirrored in the still water as mist rises from the surface, with the swan occasionally dipping its head into the water to feed.&quot; \
  --addnoise_condition 20 \
  --offload
```

Text-to-video with `diffusers`:
```py
import torch
from diffusers import AutoModel, SkyReelsV2DiffusionForcingPipeline, UniPCMultistepScheduler
from diffusers.utils import export_to_video

vae = AutoModel.from_pretrained(&quot;Skywork/SkyReels-V2-DF-14B-540P-Diffusers&quot;, subfolder=&quot;vae&quot;, torch_dtype=torch.float32)

pipeline = SkyReelsV2DiffusionForcingPipeline.from_pretrained(
    &quot;Skywork/SkyReels-V2-DF-14B-540P-Diffusers&quot;,
    vae=vae,
    torch_dtype=torch.bfloat16
)
flow_shift = 8.0  # 8.0 for T2V, 5.0 for I2V
pipeline.scheduler = UniPCMultistepScheduler.from_config(pipeline.scheduler.config, flow_shift=flow_shift)
pipeline = pipeline.to(&quot;cuda&quot;)

prompt = &quot;A cat and a dog baking a cake together in a kitchen. The cat is carefully measuring flour, while the dog is stirring the batter with a wooden spoon. The kitchen is cozy, with sunlight streaming through the window.&quot;

output = pipeline(
    prompt=prompt,
    num_inference_steps=30,
    height=544,  # 720 for 720P
    width=960,   # 1280 for 720P
    num_frames=97,
    base_num_frames=97,  # 121 for 720P
    ar_step=5,  # Controls asynchronous inference (0 for synchronous mode)
    causal_block_size=5,  # Number of frames in each block for asynchronous processing
    overlap_history=None,  # Number of frames to overlap for smooth transitions in long videos; 17 for long video generations
    addnoise_condition=20,  # Improves consistency in long video generation
).frames[0]
export_to_video(output, &quot;T2V.mp4&quot;, fps=24, quality=8)
```

Image-to-video with `diffusers`:
```py
import numpy as np
import torch
import torchvision.transforms.functional as TF
from diffusers import AutoencoderKLWan, SkyReelsV2DiffusionForcingImageToVideoPipeline, UniPCMultistepScheduler
from diffusers.utils import export_to_video, load_image

model_id = &quot;Skywork/SkyReels-V2-DF-14B-720P-Diffusers&quot;
vae = AutoencoderKLWan.from_pretrained(model_id, subfolder=&quot;vae&quot;, torch_dtype=torch.float32)
pipeline = SkyReelsV2DiffusionForcingImageToVideoPipeline.from_pretrained(
    model_id, vae=vae, torch_dtype=torch.bfloat16
)
flow_shift = 5.0  # 8.0 for T2V, 5.0 for I2V
pipeline.scheduler = UniPCMultistepScheduler.from_config(pipeline.scheduler.config, flow_shift=flow_shift)
pipeline.to(&quot;cuda&quot;)

first_frame = load_image(&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/flf2v_input_first_frame.png&quot;)
last_frame = load_image(&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/flf2v_input_last_frame.png&quot;)

def aspect_ratio_resize(image, pipeline, max_area=720 * 1280):
    aspect_ratio = image.height / image.width
    mod_value = pipeline.vae_scale_factor_spatial * pipeline.transformer.config.patch_size[1]
    height = round(np.sqrt(max_area * aspect_ratio)) // mod_value * mod_value
    width = round(np.sqrt(max_area / aspect_ratio)) // mod_value * mod_value
    image = image.resize((width, height))
    return image, height, width

def center_crop_resize(image, height, width):
    # Calculate resize ratio to match first frame dimensions
    resize_ratio = max(width / image.width, height / image.height)

    # Resize the image
    width = round(image.width * resize_ratio)
    height = round(image.height * resize_ratio)
    size = [width, height]
    image = TF.center_crop(image, size)

    return image, height, width

first_frame, height, width = aspect_ratio_resize(first_frame, pipeline)
if last_frame.size != first_frame.size:
    last_frame, _, _ = center_crop_resize(last_frame, height, width)

prompt = &quot;CG animation style, a small blue bird takes off from the ground, flapping its wings. The bird&#039;s feathers are delicate, with a unique pattern on its chest. The background shows a blue sky with white clouds under bright sunshine. The camera follows the bird upward, capturing its flight and the vastness of the sky from a close-up, low-angle perspective.&quot;

output = pipeline(
    image=first_frame, last_image=last_frame, prompt=prompt, height=height, width=width, guidance_scale=5.0
).frames[0]
export_to_video(output, &quot;output.mp4&quot;, fps=24, quality=8)
```

&gt; **Note**: 
&gt; - If you want to run the **image-to-video (I2V)** task, add `--image ${image_path}` to your command and it is also better to use **text-to-video (T2V)**-like prompt which includes some descriptions of the first-frame image.
&gt; - For long video generation, you can just switch the `--num_frames`, e.g., `--num_frames 257` for 10s video, `--num_frames 377` for 15s video, `--num_frames 737` for 30s video, `--num_frames 1457` for 60s video. The number is not strictly aligned with the logical frame number for specified time duration, but it is aligned with some training parameters, which means it may perform better. When you use asynchronous inference with causal_block_size &gt; 1, the `--num_frames` should be carefully set.
&gt; - You can use `--ar_step 5` to enable asynchronous inference. When asynchronous inference, `--causal_block_size 5` is recommended while it is not supposed to be set for synchronous generation. REMEMBER that the frame latent number inputted into the model in every iteration, e.g., base frame latent number (e.g., (97-1)//4+1=25 for base_num_frames=97) and (e.g., (237-97-(97-17)x1+17-1)//4+1=20 for base_num_frames=97, num_frames=237, overlap_history=17) for the last iteration, MUST be divided by causal_block_size. If you find it too hard to calculate and set proper values, just use our recommended setting above :). Asynchronous inference will take more steps to diffuse the whole sequence which means it will be SLOWER than synchronous mode. In our experiments, asynchronous inference may improve the instruction following and visual consistent performance.
&gt; - To reduce peak VRAM, just lower the `--base_num_frames`, e.g., to 77 or 57, while keeping the same generative length `--num_frames` you want to generate. This may slightly reduce video quality, and it should not be set too small.
&gt; - `--addnoise_condition` is used to help smooth the long video generation by adding some noise to the clean condition. Too large noise can cause the inconsistency as well. 20 is a recommended value, and you may try larger ones, but it is recommended to not exceed 50.
&gt; - Generating a 540P video using the 1.3B model requires approximately 14.7GB peak VRAM, while the same resolution video using the 14B model demands around 51.2GB peak VRAM.

- **&lt;span id=&quot;ve&quot;&gt;Video Extention&lt;/span&gt;**
```shell
model_id=Skywork/SkyReels-V2-DF-14B-540P
# video extention
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 120 \
  --overlap_history 17 \
  --prompt ${prompt} \
  --addnoise_condition 20 \
  --offload \
  --use_ret_steps \
  --teacache \
  --teacache_thresh 0.3 \
  --video_path ${video_path}
```
&gt; **Note**: 
&gt; - When performing video extension, you need to pass the `--video_path  ${video_path}` parameter to specify the video to be extended.

- **&lt;span id=&quot;se&quot;&gt;Start/End Frame Control&lt;/span&gt;**
```shell
model_id=Skywork/SkyReels-V2-DF-14B-540P
# start/end frame control
python3 generate_video_df.py \
  --model_id ${model_id} \
  --resolution 540P \
  --ar_step 0 \
  --base_num_frames 97 \
  --num_frames 97 \
  --overlap_history 17 \
  --prompt ${prompt} \
  --addnoise_condition 20 \
  --offload \
  --use_ret_steps \
  --teacache \
  --teacache_thresh 0.3 \
  --image ${image} \
  --end_image ${end_image}
```
&gt; **Note**:
&gt; - When controlling the start and end frames, you need to pass the `--image  ${image}` parameter to control the generation of the start frame and the `--end_image  ${end_image}` parameter to control the generation of the end frame.

Video extension with `diffusers`:
```py
import numpy as np
import torch
import torchvision.transforms.functional as TF
from diffusers import AutoencoderKLWan, SkyReelsV2DiffusionForcingVideoToVideoPipeline, UniPCMultistepScheduler
from diffusers.utils import export_to_video, load_video

model_id = &quot;Skywork/SkyReels-V2-DF-14B-540P-Diffusers&quot;
vae = AutoencoderKLWan.from_pretrained(model_id, subfolder=&quot;vae&quot;, torch_dtype=torch.float32)
pipeline = SkyReelsV2DiffusionForcingVideoToVideoPipeline.from_pretrained(
    model_id, vae=vae, torch_dtype=torch.bfloat16
)
flow_shift = 5.0  # 8.0 for T2V, 5.0 for I2V
pipeline.scheduler = UniPCMultistepScheduler.from_config(pipeline.scheduler.config, flow_shift=flow_shift)
pipeline.to(&quot;cuda&quot;)

video = load_video(&quot;input_video.mp4&quot;)

prompt = &quot;CG animation style, a small blue bird takes off from the ground, flapping its wings. The bird&#039;s feathers are delicate, with a unique pattern on its chest. The background shows a blue sky with white clouds under bright sunshine. The camera follows the bird upward, capturing its flight and the vastness of the sky from a close-up, low-angle perspective.&quot;

output = pipeline(
    video=video, prompt=prompt, height=544, width=960, guidance_scale=5.0,
    num_inference_steps=30, num_frames=257, base_num_frames=97#, ar_step=5, causal_block_size=5,
).frames[0]
export_to_video(output, &quot;output.mp4&quot;, fps=24, quality=8)
# Total frames will be the number of frames of given video + 257
```

- **Text To Video &amp; Image To Video**

```shell
# run Text-to-Video Generation
model_id=Skywork/SkyReels-V2-T2V-14B-540P
python3 generate_video.py \
  --model_id ${model_id} \
  --resolution 540P \
  --num_frames 97 \
  --guidance_scale 6.0 \
  --shift 8.0 \
  --fps 24 \
  --prompt &quot;A serene lake surrounded by towering mountains, with a few swans gracefully gliding across the water and sunlight dancing on the surface.&quot; \
  --offload \
  --teacache \
  --use_ret_steps \
  --teacache_thresh 0.3
```
&gt; **Note**: 
&gt; - When using an **image-to-video (I2V)** model, you must provide an input image using the `--image  ${image_path}` parameter. The `--guidance_scale 5.0` and `--shift 3.0` is recommended for I2V model.
&gt; - Generating a 540P video using the 1.3B model requires approximately 14.7GB peak VRAM, while the same resolution video using the 14B model demands around 43.4GB peak VRAM.

T2V models with `diffusers`:
```py
import torch
from diffusers import (
    SkyReelsV2Pipeline,
    UniPCMultistepScheduler,
    AutoencoderKLWan,
)
from diffusers.utils import export_to_video

# Load the pipeline
# Available models:
# - Skywork/SkyReels-V2-T2V-14B-540P-Diffusers
# - Skywork/SkyReels-V2-T2V-14B-720P-Diffusers
vae = AutoencoderKLWan.from_pretrained(
    &quot;Skywork/SkyReels-V2-T2V-14B-720P-Diffusers&quot;,
    subfolder=&quot;vae&quot;,
    torch_dtype=torch.float32,
)
pipe = SkyReelsV2Pipeline.from_pretrained(
    &quot;Skywork/SkyReels-V2-T2V-14B-720P-Diffusers&quot;,
    vae=

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Zie619/n8n-workflows]]></title>
            <link>https://github.com/Zie619/n8n-workflows</link>
            <guid>https://github.com/Zie619/n8n-workflows</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:50 GMT</pubDate>
            <description><![CDATA[all of the workflows of n8n i could find (also from the site itself)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Zie619/n8n-workflows">Zie619/n8n-workflows</a></h1>
            <p>all of the workflows of n8n i could find (also from the site itself)</p>
            <p>Language: Python</p>
            <p>Stars: 48,645</p>
            <p>Forks: 5,673</p>
            <p>Stars today: 77 stars today</p>
            <h2>README</h2><pre># ğŸš€ n8n Workflow Collection

&lt;div align=&quot;center&quot;&gt;

![n8n Workflows](https://img.shields.io/badge/n8n-Workflows-orange?style=for-the-badge&amp;logo=n8n)
![Workflows](https://img.shields.io/badge/Workflows-4343+-blue?style=for-the-badge)
![Integrations](https://img.shields.io/badge/Integrations-365+-green?style=for-the-badge)
![License](https://img.shields.io/badge/License-MIT-purple?style=for-the-badge)
[![Buy Me a Coffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-FFDD00?style=for-the-badge&amp;logo=buy-me-a-coffee&amp;logoColor=black)](https://www.buymeacoffee.com/zie619)

### ğŸŒŸ The Ultimate Collection of n8n Automation Workflows

**[ğŸ” Browse Online](https://zie619.github.io/n8n-workflows)** â€¢ **[ğŸ“š Documentation](#documentation)** â€¢ **[ğŸ¤ Contributing](#contributing)** â€¢ **[ğŸ“„ License](#license)**

&lt;/div&gt;

---

## âœ¨ What&#039;s New

### ğŸ‰ Latest Updates (November 2025)
- **ğŸ”’ Enhanced Security**: Full security audit completed, all CVEs resolved
- **ğŸ³ Docker Support**: Multi-platform builds for linux/amd64 and linux/arm64
- **ğŸ“Š GitHub Pages**: Live searchable interface at [zie619.github.io/n8n-workflows](https://zie619.github.io/n8n-workflows)
- **âš¡ Performance**: 100x faster search with SQLite FTS5 integration
- **ğŸ¨ Modern UI**: Completely redesigned interface with dark/light mode

---

## ğŸŒ Quick Access

### ğŸ”¥ Use Online (No Installation)
Visit **[zie619.github.io/n8n-workflows](https://zie619.github.io/n8n-workflows)** for instant access to:
- ğŸ” **Smart Search** - Find workflows instantly
- ğŸ“‚ **15+ Categories** - Browse by use case
- ğŸ“± **Mobile Ready** - Works on any device
- â¬‡ï¸ **Direct Downloads** - Get workflow JSONs instantly

---

## ğŸš€ Features

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;

### ğŸ“Š By The Numbers
- **4,343** Production-Ready Workflows
- **365** Unique Integrations
- **29,445** Total Nodes
- **15** Organized Categories
- **100%** Import Success Rate

&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;

### âš¡ Performance
- **&lt; 100ms** Search Response
- **&lt; 50MB** Memory Usage
- **700x** Smaller Than v1
- **10x** Faster Load Times
- **40x** Less RAM Usage

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

---

## ğŸ’» Local Installation

### Prerequisites
- Python 3.9+
- pip (Python package manager)
- 100MB free disk space

### Quick Start
```bash
# Clone the repository
git clone https://github.com/Zie619/n8n-workflows.git
cd n8n-workflows

# Install dependencies
pip install -r requirements.txt

# Start the server
python run.py

# Open in browser
# http://localhost:8000
```

### ğŸ³ Docker Installation
```bash
# Using Docker Hub
docker run -p 8000:8000 zie619/n8n-workflows:latest

# Or build locally
docker build -t n8n-workflows .
docker run -p 8000:8000 n8n-workflows
```

---

## ğŸ“š Documentation

### API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Web interface |
| `/api/search` | GET | Search workflows |
| `/api/stats` | GET | Repository statistics |
| `/api/workflow/{id}` | GET | Get workflow JSON |
| `/api/categories` | GET | List all categories |
| `/api/export` | GET | Export workflows |

### Search Features
- **Full-text search** across names, descriptions, and nodes
- **Category filtering** (Marketing, Sales, DevOps, etc.)
- **Complexity filtering** (Low, Medium, High)
- **Trigger type filtering** (Webhook, Schedule, Manual, etc.)
- **Service filtering** (365+ integrations)

---

## ğŸ—ï¸ Architecture

```mermaid
graph LR
    A[User] --&gt; B[Web Interface]
    B --&gt; C[FastAPI Server]
    C --&gt; D[SQLite FTS5]
    D --&gt; E[Workflow Database]
    C --&gt; F[Static Files]
    F --&gt; G[Workflow JSONs]
```

### Tech Stack
- **Backend**: Python, FastAPI, SQLite with FTS5
- **Frontend**: Vanilla JS, Tailwind CSS
- **Database**: SQLite with Full-Text Search
- **Deployment**: Docker, GitHub Actions, GitHub Pages
- **Security**: Trivy scanning, CORS protection, Input validation

---

## ğŸ“‚ Repository Structure

```
n8n-workflows/
â”œâ”€â”€ workflows/           # 4,343 workflow JSON files
â”‚   â””â”€â”€ [category]/     # Organized by integration
â”œâ”€â”€ docs/               # GitHub Pages site
â”œâ”€â”€ src/                # Python source code
â”œâ”€â”€ scripts/            # Utility scripts
â”œâ”€â”€ api_server.py       # FastAPI application
â”œâ”€â”€ run.py              # Server launcher
â”œâ”€â”€ workflow_db.py      # Database manager
â””â”€â”€ requirements.txt    # Python dependencies
```

---

## ğŸ¤ Contributing

We love contributions! Here&#039;s how you can help:

### Ways to Contribute
- ğŸ› **Report bugs** via [Issues](https://github.com/Zie619/n8n-workflows/issues)
- ğŸ’¡ **Suggest features** in [Discussions](https://github.com/Zie619/n8n-workflows/discussions)
- ğŸ“ **Improve documentation**
- ğŸ”§ **Submit workflow fixes**
- â­ **Star the repository**

### Development Setup
```bash
# Fork and clone
git clone https://github.com/YOUR_USERNAME/n8n-workflows.git

# Create branch
git checkout -b feature/amazing-feature

# Make changes and test
python run.py --debug

# Commit and push
git add .
git commit -m &quot;feat: add amazing feature&quot;
git push origin feature/amazing-feature

# Open PR
```

---

## ğŸ”’ Security

### Security Features
- âœ… **Path traversal protection**
- âœ… **Input validation &amp; sanitization**
- âœ… **CORS protection**
- âœ… **Rate limiting**
- âœ… **Docker security hardening**
- âœ… **Non-root container user**
- âœ… **Regular security scanning**

### Reporting Security Issues
Please report security vulnerabilities to the maintainers via [Security Advisory](https://github.com/Zie619/n8n-workflows/security/advisories/new).

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2025 Zie619

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the &quot;Software&quot;), to deal
in the Software without restriction...
```

---

## ğŸ’– Support

If you find this project helpful, please consider:

&lt;div align=&quot;center&quot;&gt;

[![Buy Me a Coffee](https://img.shields.io/badge/Buy%20Me%20a%20Coffee-FFDD00?style=for-the-badge&amp;logo=buy-me-a-coffee&amp;logoColor=black)](https://www.buymeacoffee.com/zie619)
[![Star on GitHub](https://img.shields.io/badge/Star%20on%20GitHub-181717?style=for-the-badge&amp;logo=github)](https://github.com/Zie619/n8n-workflows)
[![Follow](https://img.shields.io/badge/Follow-1DA1F2?style=for-the-badge&amp;logo=twitter&amp;logoColor=white)](https://twitter.com/zie619)

&lt;/div&gt;

---

## ğŸ“Š Stats &amp; Badges

&lt;div align=&quot;center&quot;&gt;

![GitHub stars](https://img.shields.io/github/stars/Zie619/n8n-workflows?style=social)
![GitHub forks](https://img.shields.io/github/forks/Zie619/n8n-workflows?style=social)
![GitHub watchers](https://img.shields.io/github/watchers/Zie619/n8n-workflows?style=social)
![GitHub issues](https://img.shields.io/github/issues/Zie619/n8n-workflows)
![GitHub pull requests](https://img.shields.io/github/issues-pr/Zie619/n8n-workflows)
![GitHub last commit](https://img.shields.io/github/last-commit/Zie619/n8n-workflows)
![GitHub repo size](https://img.shields.io/github/repo-size/Zie619/n8n-workflows)

&lt;/div&gt;

---

## ğŸ™ Acknowledgments

- **n8n** - For creating an amazing automation platform
- **Contributors** - Everyone who has helped improve this collection
- **Community** - For feedback and support
- **You** - For using and supporting this project!

---

&lt;div align=&quot;center&quot;&gt;

### â­ Star us on GitHub â€” it motivates us a lot!

Made with â¤ï¸ by [Zie619](https://github.com/Zie619) and [contributors](https://github.com/Zie619/n8n-workflows/graphs/contributors)

&lt;/div&gt;</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[apurvsinghgautam/robin]]></title>
            <link>https://github.com/apurvsinghgautam/robin</link>
            <guid>https://github.com/apurvsinghgautam/robin</guid>
            <pubDate>Mon, 29 Dec 2025 00:04:49 GMT</pubDate>
            <description><![CDATA[AI-Powered Dark Web OSINT Tool]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/apurvsinghgautam/robin">apurvsinghgautam/robin</a></h1>
            <p>AI-Powered Dark Web OSINT Tool</p>
            <p>Language: Python</p>
            <p>Stars: 3,249</p>
            <p>Forks: 634</p>
            <p>Stars today: 46 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
   &lt;img src=&quot;.github/assets/logo.png&quot; alt=&quot;Logo&quot; width=&quot;300&quot;&gt;
   &lt;br&gt;&lt;a href=&quot;https://github.com/apurvsinghgautam/robin/actions/workflows/binary.yml&quot;&gt;&lt;img alt=&quot;Build&quot; src=&quot;https://github.com/apurvsinghgautam/robin/actions/workflows/binary.yml/badge.svg&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://github.com/apurvsinghgautam/robin/releases&quot;&gt;&lt;img alt=&quot;GitHub Release&quot; src=&quot;https://img.shields.io/github/v/release/apurvsinghgautam/robin&quot;&gt;&lt;/a&gt; &lt;a href=&quot;https://hub.docker.com/r/apurvsg/robin&quot;&gt;&lt;img alt=&quot;Docker Pulls&quot; src=&quot;https://img.shields.io/docker/pulls/apurvsg/robin&quot;&gt;&lt;/a&gt;
   &lt;h1&gt;Robin: AI-Powered Dark Web OSINT Tool&lt;/h1&gt;

   &lt;p&gt;Robin is an AI-powered tool for conducting dark web OSINT investigations. It leverages LLMs to refine queries, filter search results from dark web search engines, and provide an investigation summary.&lt;/p&gt;
   &lt;a href=&quot;#installation&quot;&gt;Installation&lt;/a&gt; &amp;bull; &lt;a href=&quot;#usage&quot;&gt;Usage&lt;/a&gt; &amp;bull; &lt;a href=&quot;#contributing&quot;&gt;Contributing&lt;/a&gt; &amp;bull; &lt;a href=&quot;#acknowledgements&quot;&gt;Acknowledgements&lt;/a&gt;&lt;br&gt;&lt;br&gt;
&lt;/div&gt;

![Demo](.github/assets/screen.png)
![Demo](.github/assets/screen-ui.png)
![Workflow](.github/assets/robin-workflow.png)

---

## Features

- âš™ï¸ **Modular Architecture** â€“ Clean separation between search, scrape, and LLM workflows.
- ğŸ¤– **Multi-Model Support** â€“ Easily switch between OpenAI, Claude, Gemini or local models like Ollama.
- ğŸ’» **CLI-First Design** â€“ Built for terminal warriors and automation ninjas.
- ğŸ³ **Docker-Ready** â€“ Optional Docker deployment for clean, isolated usage.
- ğŸ“ **Custom Reporting** â€“ Save investigation output to file for reporting or further analysis.
- ğŸ§© **Extensible** â€“ Easy to plug in new search engines, models, or output formats.

---

## âš ï¸ Disclaimer
&gt; This tool is intended for educational and lawful investigative purposes only. Accessing or interacting with certain dark web content may be illegal depending on your jurisdiction. The author is not responsible for any misuse of this tool or the data gathered using it.
&gt;
&gt; Use responsibly and at your own risk. Ensure you comply with all relevant laws and institutional policies before conducting OSINT investigations.
&gt;
&gt; Additionally, Robin leverages third-party APIs (including LLMs). Be cautious when sending potentially sensitive queries, and review the terms of service for any API or model provider you use.

## Installation
&gt; [!NOTE]
&gt; The tool needs Tor to do the searches. You can install Tor using `apt install tor` on Linux/Windows(WSL) or `brew install tor` on Mac. Once installed, confirm if Tor is running in the background.

&gt; [!TIP]
&gt; You can provide OpenAI or Anthropic or Google API key by either creating .env file (refer to sample env file in the repo) or by setting env variables in PATH.
&gt;
&gt; For Ollama, provide `http://host.docker.internal:11434` as `OLLAMA_BASE_URL` in your env if running using docker method or `http://127.0.0.1:11434` for other methods. You might need to serve Ollama on 0.0.0.0 depending on your OS. You can do by running `OLLAMA_HOST=0.0.0.0 ollama serve &amp;` in your terminal.

### Docker (Web UI Mode) [Recommended]

- Pull the latest Robin docker image
```bash
docker pull apurvsg/robin:latest
```

- Run the docker image as:
```bash
docker run --rm \
   -v &quot;$(pwd)/.env:/app/.env&quot; \
   --add-host=host.docker.internal:host-gateway \
   -p 8501:8501 \
   apurvsg/robin:latest ui --ui-port 8501 --ui-host 0.0.0.0
```

### Release Binary (CLI Mode)

- Download the appropriate binary for your system from the [latest release](https://github.com/apurvsinghgautam/robin/releases/latest)
- Unzip the file, make it executable 
```bash
chmod +x robin
```

- Run the binary as:
```bash
robin cli --model gpt-4.1 --query &quot;ransomware payments&quot;
```

### Using Python (Development Version)

- With `Python 3.10+` installed, run the following:

```bash
pip install -r requirements.txt
python main.py cli -m gpt-4.1 -q &quot;ransomware payments&quot; -t 12
```

---

## Usage

```bash
Robin: AI-Powered Dark Web OSINT Tool

options:
  -h, --help            show this help message and exit
  --model {gpt4o,gpt-4.1,claude-3-5-sonnet-latest,llama3.1,gemini-2.5-flash}, -m {gpt4o,gpt-4.1,claude-3-5-sonnet-latest,llama3.1,gemini-2.5-flash}
                        Select LLM model (e.g., gpt4o, claude sonnet 3.5, ollama models, gemini 2.5 flash)
  --query QUERY, -q QUERY
                        Dark web search query
  --threads THREADS, -t THREADS
                        Number of threads to use for scraping (Default: 5)
  --output OUTPUT, -o OUTPUT
                        Filename to save the final intelligence summary. If not provided, a filename based on the
                        current date and time is used.

Example commands:
 - robin -m gpt4.1 -q &quot;ransomware payments&quot; -t 12
 - robin --model gpt4.1 --query &quot;sensitive credentials exposure&quot; --threads 8 --output filename
 - robin -m llama3.1 -q &quot;zero days&quot;
 - robin -m gemini-2.5-flash -q &quot;zero days&quot;
```

---

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request if you have major feature updates.

- Fork the repository
- Create your feature branch (git checkout -b feature/amazing-feature)
- Commit your changes (git commit -m &#039;Add some amazing feature&#039;)
- Push to the branch (git push origin feature/amazing-feature)
- Open a Pull Request

Open an Issue for any of these situations:
- If you spot a bug or bad code
- If you have a feature request idea
- If you have questions or doubts about usage
- If you have minor code changes

---

## Acknowledgements

- Idea inspiration from [Thomas Roccia](https://x.com/fr0gger_) and his demo of [Perplexity of the Dark Web](https://x.com/fr0gger_/status/1908051083068645558).
- Tools inspiration from my [OSINT Tools for the Dark Web](https://github.com/apurvsinghgautam/dark-web-osint-tools) repository.
- LLM Prompt inspiration from [OSINT-Assistant](https://github.com/AXRoux/OSINT-Assistant) repository.
- Logo Design by my friend [Tanishq Rupaal](https://github.com/Tanq16/)
- Workflow Design by [Chintan Gurjar](https://www.linkedin.com/in/chintangurjar)





</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>