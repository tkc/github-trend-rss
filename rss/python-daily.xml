<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Thu, 15 May 2025 00:04:34 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[mem0ai/mem0]]></title>
            <link>https://github.com/mem0ai/mem0</link>
            <guid>https://github.com/mem0ai/mem0</guid>
            <pubDate>Thu, 15 May 2025 00:04:34 GMT</pubDate>
            <description><![CDATA[Memory for AI Agents; SOTA in AI Agent Memory; Announcing OpenMemory MCP - local and secure memory management.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mem0ai/mem0">mem0ai/mem0</a></h1>
            <p>Memory for AI Agents; SOTA in AI Agent Memory; Announcing OpenMemory MCP - local and secure memory management.</p>
            <p>Language: Python</p>
            <p>Stars: 29,757</p>
            <p>Forks: 2,871</p>
            <p>Stars today: 473 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/mem0ai/mem0&quot;&gt;
    &lt;img src=&quot;docs/images/banner-sm.png&quot; width=&quot;800px&quot; alt=&quot;Mem0 - The Memory Layer for Personalized AI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot; style=&quot;display: flex; justify-content: center; gap: 20px; align-items: center;&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/11194&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/11194&quot; alt=&quot;mem0ai%2Fmem0 | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mem0.ai&quot;&gt;Learn more&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://mem0.dev/DiG&quot;&gt;Join Discord&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://mem0.dev/demo&quot;&gt;Demo&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://mem0.dev/openmemory&quot;&gt;OpenMemory&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mem0.dev/DiG&quot;&gt;
    &lt;img src=&quot;https://dcbadge.vercel.app/api/server/6PzXDgEjG5?style=flat&quot; alt=&quot;Mem0 Discord&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pepy.tech/project/mem0ai&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/dm/mem0ai&quot; alt=&quot;Mem0 PyPI - Downloads&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://github.com/mem0ai/mem0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/github/commit-activity/m/mem0ai/mem0?style=flat-square&quot; alt=&quot;GitHub commit activity&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://pypi.org/project/mem0ai&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/pypi/v/mem0ai?color=%2334D058&amp;label=pypi%20package&quot; alt=&quot;Package version&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.npmjs.com/package/mem0ai&quot; target=&quot;blank&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/npm/v/mem0ai&quot; alt=&quot;Npm package&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://www.ycombinator.com/companies/mem0&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Y%20Combinator-S24-orange?style=flat-square&quot; alt=&quot;Y Combinator S24&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://mem0.ai/research&quot;&gt;&lt;strong&gt;üìÑ Building Production-Ready AI Agents with Scalable Long-Term Memory ‚Üí&lt;/strong&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;‚ö° +26% Accuracy vs. OpenAI Memory ‚Ä¢ üöÄ 91% Faster ‚Ä¢ üí∞ 90% Fewer Tokens&lt;/strong&gt;
&lt;/p&gt;

##  üî• Research Highlights
- **+26% Accuracy** over OpenAI Memory on the LOCOMO benchmark
- **91% Faster Responses** than full-context, ensuring low-latency at scale
- **90% Lower Token Usage** than full-context, cutting costs without compromise
- [Read the full paper](https://mem0.ai/research)

# Introduction

[Mem0](https://mem0.ai) (&quot;mem-zero&quot;) enhances AI assistants and agents with an intelligent memory layer, enabling personalized AI interactions. It remembers user preferences, adapts to individual needs, and continuously learns over time‚Äîideal for customer support chatbots, AI assistants, and autonomous systems.

### Key Features &amp; Use Cases

**Core Capabilities:**
- **Multi-Level Memory**: Seamlessly retains User, Session, and Agent state with adaptive personalization
- **Developer-Friendly**: Intuitive API, cross-platform SDKs, and a fully managed service option

**Applications:**
- **AI Assistants**: Consistent, context-rich conversations
- **Customer Support**: Recall past tickets and user history for tailored help
- **Healthcare**: Track patient preferences and history for personalized care
- **Productivity &amp; Gaming**: Adaptive workflows and environments based on user behavior

## üöÄ Quickstart Guide &lt;a name=&quot;quickstart&quot;&gt;&lt;/a&gt;

Choose between our hosted platform or self-hosted package:

### Hosted Platform

Get up and running in minutes with automatic updates, analytics, and enterprise security.

1. Sign up on [Mem0 Platform](https://app.mem0.ai)
2. Embed the memory layer via SDK or API keys

### Self-Hosted (Open Source)

Install the sdk via pip:

```bash
pip install mem0ai
```

Install sdk via npm:
```bash
npm install mem0ai
```

### Basic Usage

Mem0 requires an LLM to function, with `gpt-4o-mini` from OpenAI as the default. However, it supports a variety of LLMs; for details, refer to our [Supported LLMs documentation](https://docs.mem0.ai/components/llms/overview).

First step is to instantiate the memory:

```python
from openai import OpenAI
from mem0 import Memory

openai_client = OpenAI()
memory = Memory()

def chat_with_memories(message: str, user_id: str = &quot;default_user&quot;) -&gt; str:
    # Retrieve relevant memories
    relevant_memories = memory.search(query=message, user_id=user_id, limit=3)
    memories_str = &quot;\n&quot;.join(f&quot;- {entry[&#039;memory&#039;]}&quot; for entry in relevant_memories[&quot;results&quot;])

    # Generate Assistant response
    system_prompt = f&quot;You are a helpful AI. Answer the question based on query and memories.\nUser Memories:\n{memories_str}&quot;
    messages = [{&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: system_prompt}, {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: message}]
    response = openai_client.chat.completions.create(model=&quot;gpt-4o-mini&quot;, messages=messages)
    assistant_response = response.choices[0].message.content

    # Create new memories from the conversation
    messages.append({&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: assistant_response})
    memory.add(messages, user_id=user_id)

    return assistant_response

def main():
    print(&quot;Chat with AI (type &#039;exit&#039; to quit)&quot;)
    while True:
        user_input = input(&quot;You: &quot;).strip()
        if user_input.lower() == &#039;exit&#039;:
            print(&quot;Goodbye!&quot;)
            break
        print(f&quot;AI: {chat_with_memories(user_input)}&quot;)

if __name__ == &quot;__main__&quot;:
    main()
```

For detailed integration steps, see the [Quickstart](https://docs.mem0.ai/quickstart) and [API Reference](https://docs.mem0.ai/api-reference).

## üîó Integrations &amp; Demos

- **ChatGPT with Memory**: Personalized chat powered by Mem0 ([Live Demo](https://mem0.dev/demo))
- **Browser Extension**: Store memories across ChatGPT, Perplexity, and Claude ([Chrome Extension](https://chromewebstore.google.com/detail/onihkkbipkfeijkadecaafbgagkhglop?utm_source=item-share-cb))
- **Langgraph Support**: Build a customer bot with Langgraph + Mem0 ([Guide](https://docs.mem0.ai/integrations/langgraph))
- **CrewAI Integration**: Tailor CrewAI outputs with Mem0 ([Example](https://docs.mem0.ai/integrations/crewai))

## üìö Documentation &amp; Support

- Full docs: https://docs.mem0.ai
- Community: [Discord](https://mem0.dev/DiG) ¬∑ [Twitter](https://x.com/mem0ai)
- Contact: founders@mem0.ai

## Citation

We now have a paper you can cite:

```bibtex
@article{mem0,
  title={Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory},
  author={Chhikara, Prateek and Khant, Dev and Aryan, Saket and Singh, Taranjeet and Yadav, Deshraj},
  journal={arXiv preprint arXiv:2504.19413},
  year={2025}
}
```

## ‚öñÔ∏è License

Apache 2.0 ‚Äî see the [LICENSE](LICENSE) file for details.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[airweave-ai/airweave]]></title>
            <link>https://github.com/airweave-ai/airweave</link>
            <guid>https://github.com/airweave-ai/airweave</guid>
            <pubDate>Thu, 15 May 2025 00:04:33 GMT</pubDate>
            <description><![CDATA[Airweave lets agents search any app]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/airweave-ai/airweave">airweave-ai/airweave</a></h1>
            <p>Airweave lets agents search any app</p>
            <p>Language: Python</p>
            <p>Stars: 1,596</p>
            <p>Forks: 170</p>
            <p>Stars today: 183 stars today</p>
            <h2>README</h2><pre>&lt;img width=&quot;1673&quot; alt=&quot;airweave-lettermark&quot; style=&quot;padding-bottom: 12px;&quot; src=&quot;https://github.com/user-attachments/assets/e79a9af7-2e93-4888-9cf4-0f700f19fe05&quot;/&gt;


&lt;div align=&quot;center&quot;&gt;

[![Ruff](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/ruff.yml)
[![ESLint](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml/badge.svg)](https://github.com/airweave-ai/airweave/actions/workflows/eslint.yml)
[![Backend Tests](https://github.com/airweave-ai/airweave/actions/workflows/tests.yml/badge.svg?branch=main)](https://github.com/airweave-ai/airweave/actions/workflows/tests.yml)
[![Codecov](https://codecov.io/gh/airweave-ai/airweave/branch/main/graph/badge.svg)](https://codecov.io/gh/airweave-ai/airweave)
[![Discord](https://img.shields.io/discord/1323415085011701870?label=Discord&amp;logo=discord&amp;logoColor=white&amp;style=flat-square)](https://discord.com/invite/484HY9Ehxt)

&lt;/div&gt;

# Airweave

**Airweave is a tool that lets agents semantically search any app.** It&#039;s MCP compatible and seamlessly connects any app, database, or API, to transform their contents into agent-ready knowledge.

&lt;div align=&quot;center&quot;&gt;
  
### üé• Watch Demo

https://github.com/user-attachments/assets/abdf85cb-a8f5-4b6c-b5a3-d4b5177e6bda

&lt;/div&gt;

## Overview

Airweave simplifies the process of making information retrievable for your agent. Whether you have structured or unstructured data, Airweave helps you break it into processable entities, store the data and make it retrievable through REST and MCP endpoints.

## Table of Contents

- [Airweave](#airweave)
    - [üé• Watch Demo](#-watch-demo)
  - [Overview](#overview)
  - [Table of Contents](#table-of-contents)
  - [üöÄ Quick Start](#-quick-start)
  - [üîå Supported Integrations](#-supported-integrations)
  - [üíª Usage](#-usage)
    - [Frontend](#frontend)
    - [API](#api)
  - [üì¶ SDKs](#-sdks)
    - [Python](#python)
    - [TypeScript/JavaScript](#typescriptjavascript)
  - [üîë Key Features](#-key-features)
  - [üîß Technology Stack](#-technology-stack)
  - [üõ£Ô∏è Roadmap](#Ô∏è-roadmap)
  - [üë• Contributing](#-contributing)
  - [üìÑ License](#-license)
  - [üîó Connect](#-connect)

## üöÄ Quick Start

```bash
# 1. Clone the repository
git clone https://github.com/airweave-ai/airweave.git
cd airweave

# 2. Build and run
chmod +x start.sh
./start.sh
```

That&#039;s it! Access the dashboard at http://localhost:8080

## üîå Supported Integrations

&lt;!-- START_APP_GRID --&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;div style=&quot;display: inline-block; text-align: center; padding: 4px;&quot;&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/asana.svg&quot; alt=&quot;Asana&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/calendly.svg&quot; alt=&quot;Calendly&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/chat-gpt.svg&quot; alt=&quot;Chat-gpt&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/clickup.svg&quot; alt=&quot;Clickup&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/confluence.svg&quot; alt=&quot;Confluence&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/dropbox.svg&quot; alt=&quot;Dropbox&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/facebook.svg&quot; alt=&quot;Facebook&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/github.svg&quot; alt=&quot;Github&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/gmail.svg&quot; alt=&quot;Gmail&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/google_calendar.svg&quot; alt=&quot;Google Calendar&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/google_drive.svg&quot; alt=&quot;Google Drive&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/hubspot.svg&quot; alt=&quot;Hubspot&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/intercom.svg&quot; alt=&quot;Intercom&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/jira.svg&quot; alt=&quot;Jira&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/linear.svg&quot; alt=&quot;Linear&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/linkedin.svg&quot; alt=&quot;Linkedin&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/mailchimp.svg&quot; alt=&quot;Mailchimp&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/monday.svg&quot; alt=&quot;Monday&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/mysql.svg&quot; alt=&quot;Mysql&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/notion.svg&quot; alt=&quot;Notion&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/onedrive.svg&quot; alt=&quot;Onedrive&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/oracle.svg&quot; alt=&quot;Oracle&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/outlook_calendar.svg&quot; alt=&quot;Outlook Calendar&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/outlook_mail.svg&quot; alt=&quot;Outlook Mail&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;img src=&quot;frontend/src/components/icons/apps/perplexity.svg&quot; alt=&quot;Perplexity&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/postgresql.svg&quot; alt=&quot;Postgresql&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/salesforce.svg&quot; alt=&quot;Salesforce&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/slack.svg&quot; alt=&quot;Slack&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/sql_server.svg&quot; alt=&quot;Sql Server&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/sqlite.svg&quot; alt=&quot;Sqlite&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/stripe.svg&quot; alt=&quot;Stripe&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/todoist.svg&quot; alt=&quot;Todoist&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
    &lt;span style=&quot;width: 40px; display: inline-block; margin: 4px;&quot;&gt;&lt;/span&gt;&lt;span style=&quot;width: 40px; display: inline-block; margin: 4px;&quot;&gt;&lt;/span&gt;&lt;img src=&quot;frontend/src/components/icons/apps/trello.svg&quot; alt=&quot;Trello&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/whatsapp.svg&quot; alt=&quot;Whatsapp&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;&lt;img src=&quot;frontend/src/components/icons/apps/zendesk.svg&quot; alt=&quot;Zendesk&quot; width=&quot;40&quot; height=&quot;40&quot; style=&quot;margin: 4px; padding: 2px;&quot; /&gt;
  &lt;/div&gt;
&lt;/p&gt;

&lt;!-- END_APP_GRID --&gt;

## üíª Usage

### Frontend
- Access the UI at `http://localhost:8080`
- Connect sources, configure syncs, and query data

### API
- Swagger docs: `http://localhost:8001/docs`
- Create connections, trigger syncs, and search data

## üì¶ SDKs

### Python

```bash
pip install airweave-sdk
```

```python
from airweave import AirweaveClient

client = AirweaveClient(api_key=&quot;your-api-key&quot;)

# List all sources
sources = client.sources.list()

# Create a sync job
job = client.sync.create_sync(
  name=&quot;My first sync&quot;,
  source_connection_id=source_id,
  run_immediately=True
)
```

### TypeScript/JavaScript

```bash
npm install @airweave/sdk
# or
yarn add @airweave/sdk
```

```typescript
import { AirweaveClient } from &quot;@airweave/sdk&quot;;

const client = new AirweaveClient({
  apiKey: &quot;your-api-key&quot;,
});

// List sources
const sources = await client.sources.list();

// Create a sync job
const job = await client.sync.create_sync({
  name: &quot;My first sync&quot;,
  source_connection_id: sourceId,
  run_immediately: true,
});
```

## üîë Key Features

- **Data synchronization** from 25+ sources with minimal config
- **Entity extraction** and transformation pipeline
- **Multi-tenant** architecture with OAuth2
- **Incremental updates** using content hashing
- **Semantic search** for agent queries
- **Versioning** for data changes
- **White-labeling** support for SaaS builders

## üîß Technology Stack

- **Frontend**: React/TypeScript with ShadCN
- **Backend**: FastAPI (Python)
- **Databases**: PostgreSQL (metadata), Qdrant (vectors)
- **Deployment**: Docker Compose (dev), Kubernetes (prod)

## üõ£Ô∏è Roadmap

- Additional source integrations
- Redis worker queues for large-scale syncs
- Webhooks for event-driven syncs
- Kubernetes support via Helm charts

## üë• Contributing

We welcome contributions! Please check [CONTRIBUTING.md](https://github.com/airweave-ai/airweave/blob/main/CONTRIBUTING.md) for details.

## üìÑ License

Airweave is released under the [MIT](LICENSE) license.

## üîó Connect

- **[Discord](https://discord.com/invite/484HY9Ehxt)** - Get help and discuss features
- **[GitHub Issues](https://github.com/airweave-ai/airweave/issues)** - Report bugs or request features
- **[Twitter](https://x.com/airweave_ai)** - Follow for updates
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[openai/simple-evals]]></title>
            <link>https://github.com/openai/simple-evals</link>
            <guid>https://github.com/openai/simple-evals</guid>
            <pubDate>Thu, 15 May 2025 00:04:32 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/simple-evals">openai/simple-evals</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 3,181</p>
            <p>Forks: 313</p>
            <p>Stars today: 131 stars today</p>
            <h2>README</h2><pre># Overview
This repository contains a lightweight library for evaluating language models.
We are open sourcing it so we can be transparent about the accuracy numbers we&#039;re publishing alongside our latest models.

## Benchmark Results

| Model                        | Prompt        | MMLU   | GPQA [^8]   | MATH [^6]| HumanEval | MGSM[^5] | DROP[^5]&lt;br&gt;(F1, 3-shot) | SimpleQA
|:----------------------------:|:-------------:|:------:|:------:|:--------:|:---------:|:------:|:--------------------------:|:---------:|
| **o3**                         |               |        |        |          |           |        |                             |                      |           |
| o3-high [^10]                | n/a [^7]      |  93.3  |  83.4  |   98.1   |  88.4     |  92.0  |  89.8                      |  48.6     |
| o3 [^9] [^10]                | n/a           |  92.9  |  82.8  |   97.8   |  87.4     |  92.3  |  80.6                      |  49.4     |
| o3-low [^10]                 | n/a           |  92.8  |  78.6  |   96.9   |  87.3     |  91.9  |  82.3                      |  49.4     |
| **o4-mini**                    |               |        |        |          |           |        |                             |                      |
| o4-mini-high [^9] [^10]      | n/a           |  90.3  |  81.3  |   98.2   |  99.3     |  93.5  |  78.1                      |  19.3     |
| o4-mini [^9] [^10]           | n/a           |  90.0  |  77.6  |   97.5   |  97.3     |  93.7  |  77.7                      |  20.2     |
| o4-mini-low [^10]            | n/a           |  89.5  |  73.6  |   96.2   |  95.9     |  93.0  |  76.0                      |  20.2     |
| **o3-mini**                    |               |        |        |          |           |        |                             |                      |           |
| o3-mini-high                 | n/a           |  86.9  |  77.2  |   97.9   |  97.6     |  92.0  |  80.6                      |  13.8     |
| o3-mini                      | n/a           |  85.9  |  74.9  |   97.3   |  96.3     |  90.8  |  79.2                      |  13.4     |
| o3-mini-low                  | n/a           |  84.9  |  67.6  |   95.8   |  94.5     |  89.4  |  77.6                      |  13.0     |
| **o1**                         |               |        |        |          |           |        |                             |                      |
|  o1                          | n/a           |  91.8  |  75.7  |   96.4   |    -      |  89.3  |  90.2                      |  42.6     |
| o1-preview                   | n/a           |  90.8  |  73.3  |   85.5   |  92.4     |  90.8  |  74.8                      |  42.4     |
| o1-mini                      | n/a           |  85.2  |  60.0  |   90.0   |  92.4     |  89.9  |  83.9                      |  07.6     |
| **GPT-4.1**                            |               |        |        |          |           |        |                             |                      |           |
| gpt-4.1-2025-04-14           | assistant [^2]|  90.2  |  66.3  |   82.1   |   94.5    |  86.9  |  79.4                      | 41.6      |
| gpt-4.1-mini-2025-04-14      | assistant     |  87.5  |  65.0  |   81.4   |   93.8    |  88.2  |  81.0                      | 16.8      |
| gpt-4.1-nano-2025-04-14      | assistant     |  80.1  |  50.3  |   62.3   |   87.0    |  73.0  |  82.2                      | 07.6      |
| **GPT-4o**                     |               |        |        |          |           |        |                             |                      |           |
| gpt-4o-2024-11-20            | assistant     |  85.7  |  46.0  |   68.5   |   90.2    |  90.3  |  81.5                      | 38.8      |
| gpt-4o-2024-08-06            | assistant     |  88.7  |  53.1  |   75.9   |   90.2    |  90.0  |  79.8                      | 40.1      |
| gpt-4o-2024-05-13            | assistant     |  87.2  |  49.9  |   76.6   |   91.0    |  89.9  |  83.7                      | 39.0      |
| gpt-4o-mini-2024-07-18       | assistant     |  82.0  |  40.2  |   70.2   |   87.2    |  87.0  |  79.7                      | 09.5      |
| **GPT-4.5-preview**          |               |        |        |          |           |        |                            |           |
| gpt-4.5-preview-2025-02-27   | assistant     |  90.8  |  69.5  |   87.1   |   88.6    |  86.9  |  83.4                      | 62.5      |
| **GPT-4 Turbo and GPT-4**    |               |        |        |          |           |        |                            |           |
| gpt-4-turbo-2024-04-09       | assistant     |  86.7  |  49.3  |   73.4   |   88.2    |  89.6  |  86.0                      | 24.2      |
| gpt-4-0125-preview           | assistant     |  85.4  |  41.4  |   64.5   |   86.6    |  85.1  |  81.5                      | n/a       |
| gpt-4-1106-preview           | assistant     |  84.7  |  42.5  |   64.3   |   83.7    |  87.1  |  83.2                      | n/a       |
| **Other Models (Reported)**   |               |        |        |        |           |        |                           |
| [Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet) | unknown |  88.3  |  59.4  |  71.1  |   92.0    | 91.6 | 87.1 |  28.9 |
| [Claude 3 Opus](https://www.anthropic.com/news/claude-3-family) | unknown |  86.8  |  50.4  |  60.1  |   84.9    |   90.7   |  83.1 |  23.5 |
| [Llama 3.1 405b](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md) | unknown |  88.6  |  50.7  |  73.8  |   89.0    | 91.6 |  84.8                   | n/a
| [Llama 3.1 70b](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md) | unknown |  82.0  |  41.7  |  68.0  |   80.5    |  86.9  |  79.6                   | n/a
| [Llama 3.1 8b](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md) | unknown |  68.4  |  30.4  |  51.9  |   72.6    |  68.9  |  59.5                   | n/a
| [Grok 2](https://x.ai/blog/grok-2) | unknown | 87.5 | 56.0 | 76.1 | 88.4 | n/a | n/a | n/a
| [Grok 2 mini](https://x.ai/blog/grok-2) | unknown | 86.2 | 51.0 | 73.0 | 85.7 | n/a | n/a | n/a
| [Gemini 1.0 Ultra](https://goo.gle/GeminiV1-5) | unknown | 83.7 | n/a | 53.2 | 74.4 | 79.0 | 82.4 | n/a
| [Gemini 1.5 Pro](https://goo.gle/GeminiV1-5) | unknown | 81.9 | n/a | 58.5 | 71.9 | 88.7 | 78.9 | n/a
| [Gemini 1.5 Flash](https://goo.gle/GeminiV1-5) | unknown | 77.9 | 38.6 | 40.9 | 71.5 | 75.5 | 78.4 | n/a

## Background

Evals are sensitive to prompting, and there&#039;s significant variation in the formulations used in recent publications and libraries.
Some use few-shot prompts or role playing prompts (&quot;You are an expert software programmer...&quot;).
These approaches are carryovers from evaluating *base models* (rather than instruction/chat-tuned models) and from models that were worse at following instructions.

For this library, we are emphasizing the *zero-shot, chain-of-thought* setting, with simple instructions like &quot;Solve the following multiple choice problem&quot;. We believe that this prompting technique is a better reflection of the models&#039; performance in realistic usage.

**We will not be actively maintaining this repository and monitoring PRs and Issues.** In particular, we&#039;re not accepting new evals. Here are the changes we might accept.
- Bug fixes (hopefully not needed!)
- Adding adapters for new models
- Adding new rows to the table below with eval results, given new models and new system prompts.

This repository is NOT intended as a replacement for https://github.com/openai/evals, which is designed to be a comprehensive collection of a large number of evals.

## Evals

This repository currently contains the following evals:

- MMLU: Measuring Massive Multitask Language Understanding, reference: https://arxiv.org/abs/2009.03300, https://github.com/hendrycks/test, [MIT License](https://github.com/hendrycks/test/blob/master/LICENSE)
- MATH: Measuring Mathematical Problem Solving With the MATH Dataset, reference: https://arxiv.org/abs/2103.03874, https://github.com/hendrycks/math, [MIT License](https://github.com/idavidrein/gpqa/blob/main/LICENSE)
- GPQA: A Graduate-Level Google-Proof Q&amp;A Benchmark, reference: https://arxiv.org/abs/2311.12022, https://github.com/idavidrein/gpqa/,  [MIT License](https://github.com/idavidrein/gpqa/blob/main/LICENSE)
- DROP: A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs, reference: https://arxiv.org/abs/1903.00161, https://allenai.org/data/drop, [Apache License 2.0](https://github.com/allenai/allennlp-models/blob/main/LICENSE)
- MGSM: Multilingual Grade School Math Benchmark (MGSM), Language Models are Multilingual Chain-of-Thought Reasoners, reference: https://arxiv.org/abs/2210.03057, https://github.com/google-research/url-nlp, [Creative Commons Attribution 4.0 International Public License (CC-BY)](https://github.com/google-research/url-nlp/blob/main/LICENSE)
- HumanEval: Evaluating Large Language Models Trained on Code, reference https://arxiv.org/abs/2107.03374, https://github.com/openai/human-eval, [MIT License](https://github.com/openai/human-eval/blob/master/LICENSE)
- SimpleQA: Measuring short-form factuality in large language models, reference: https://openai.com/index/introducing-simpleqa, [MIT License](https://github.com/openai/simple-evals/blob/main/LICENSE)
- BrowseComp: A Simple Yet Challenging Benchmark for Browsing Agents, reference: https://openai.com/index/browsecomp, [MIT License](https://github.com/openai/simple-evals/blob/main/LICENSE)
- HealthBench: Evaluating Large Language Models Towards Improved Human Health, reference: https://openai.com/index/healthbench, [MIT License](https://github.com/openai/simple-evals/blob/main/LICENSE)

## Samplers

We have implemented sampling interfaces for the following language model APIs:

- OpenAI: https://platform.openai.com/docs/overview
- Claude: https://www.anthropic.com/api

Make sure to set the `*_API_KEY` environment variables before using these APIs.

## Setup

Due to the optional dependencies, we&#039;re not providing a unified setup mechanism. Instead, we&#039;re providing instructions for each eval and sampler.

For [HumanEval](https://github.com/openai/human-eval/) (python programming)
```bash
git clone https://github.com/openai/human-eval
pip install -e human-eval
```

For the [OpenAI API](https://pypi.org/project/openai/):
```bash
pip install openai
```

For the [Anthropic API](https://docs.anthropic.com/claude/docs/quickstart-guide):
```bash
pip install anthropic
```

## Running the evals
```bash
python -m simple-evals.simple_evals --list-models
```
This will list all the models that you can evaluate.

To run the evaluations, you can use the following command:
```bash
python -m simple-evals.simple_evals --model &lt;model_name&gt; --examples &lt;num_examples&gt;
```
This will launch evaluations through the OpenAI API.

## Notes

[^1]:chatgpt system message: &quot;You are ChatGPT, a large language model trained by OpenAI, based on the GPT-4 architecture.\nKnowledge cutoff: 2023-12\nCurrent date: 2024-04-01&quot;
[^2]:assistant system message in [OpenAI API doc](https://platform.openai.com/docs/api-reference/introduction): &quot;You are a helpful assistant.&quot; .
[^3]:claude-3 empty system message: suggested by Anthropic API doc, and we have done limited experiments due to [rate limit](https://docs.anthropic.com/claude/reference/rate-limits) issues, but we welcome PRs with alternative choices.
[^4]:claude-3 lmsys system message: system message in LMSYS [Fast-chat open source code](https://github.com/lm-sys/FastChat/blob/7899355ebe32117fdae83985cf8ee476d2f4243f/fastchat/conversation.py#L894): &quot;The assistant is Claude, created by Anthropic. The current date is {{currentDateTime}}. Claude&#039;s knowledge base was last updated ... &quot;. We have done limited experiments due to [rate limit](https://docs.anthropic.com/claude/reference/rate-limits) issues, but we welcome PRs with alternative choices.
[^5]:We believe these evals are saturated for our newer models, but are reporting them for completeness.
[^6]:For newer models (anything on or after o1) we evaluate on [MATH-500](https://github.com/openai/prm800k/tree/main/prm800k/math_splits), which is a newer, IID version of MATH.
[^7]:o-series models do not support using a system prompt.
[^8]:Includes an answer regex tweak for GPQA benchmark.
[^9]:The default reasoning level for o3-mini is &quot;medium&quot;.
[^10]:These results are with no tools enabled for o3 or o4-mini

## Legal Stuff
By contributing to evals, you are agreeing to make your evaluation logic and data under the same MIT license as this repository. You must have adequate rights to upload any data used in an eval. OpenAI reserves the right to use this data in future service improvements to our product. Contributions to OpenAI evals will be subject to our usual Usage Policies: https://platform.openai.com/docs/usage-policies.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[harry0703/MoneyPrinterTurbo]]></title>
            <link>https://github.com/harry0703/MoneyPrinterTurbo</link>
            <guid>https://github.com/harry0703/MoneyPrinterTurbo</guid>
            <pubDate>Thu, 15 May 2025 00:04:31 GMT</pubDate>
            <description><![CDATA[Âà©Áî®AIÂ§ßÊ®°ÂûãÔºå‰∏ÄÈîÆÁîüÊàêÈ´òÊ∏ÖÁü≠ËßÜÈ¢ë Generate short videos with one click using AI LLM.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/harry0703/MoneyPrinterTurbo">harry0703/MoneyPrinterTurbo</a></h1>
            <p>Âà©Áî®AIÂ§ßÊ®°ÂûãÔºå‰∏ÄÈîÆÁîüÊàêÈ´òÊ∏ÖÁü≠ËßÜÈ¢ë Generate short videos with one click using AI LLM.</p>
            <p>Language: Python</p>
            <p>Stars: 32,698</p>
            <p>Forks: 4,599</p>
            <p>Stars today: 537 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;h1 align=&quot;center&quot;&gt;MoneyPrinterTurbo üí∏&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Stargazers&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Issues&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/network/members&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;Forks&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/harry0703/MoneyPrinterTurbo/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/harry0703/MoneyPrinterTurbo.svg?style=for-the-badge&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;
&lt;br&gt;
&lt;h3&gt;ÁÆÄ‰Ωì‰∏≠Êñá | &lt;a href=&quot;README-en.md&quot;&gt;English&lt;/a&gt;&lt;/h3&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/8731&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/8731&quot; alt=&quot;harry0703%2FMoneyPrinterTurbo | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;br&gt;
Âè™ÈúÄÊèê‰æõ‰∏Ä‰∏™ËßÜÈ¢ë &lt;b&gt;‰∏ªÈ¢ò&lt;/b&gt; Êàñ &lt;b&gt;ÂÖ≥ÈîÆËØç&lt;/b&gt; ÔºåÂ∞±ÂèØ‰ª•ÂÖ®Ëá™Âä®ÁîüÊàêËßÜÈ¢ëÊñáÊ°à„ÄÅËßÜÈ¢ëÁ¥†Êùê„ÄÅËßÜÈ¢ëÂ≠óÂπï„ÄÅËßÜÈ¢ëËÉåÊôØÈü≥‰πêÔºåÁÑ∂ÂêéÂêàÊàê‰∏Ä‰∏™È´òÊ∏ÖÁöÑÁü≠ËßÜÈ¢ë„ÄÇ
&lt;br&gt;

&lt;h4&gt;WebÁïåÈù¢&lt;/h4&gt;

![](docs/webui.jpg)

&lt;h4&gt;APIÁïåÈù¢&lt;/h4&gt;

![](docs/api.jpg)

&lt;/div&gt;

## ÁâπÂà´ÊÑüË∞¢ üôè

Áî±‰∫éËØ•È°πÁõÆÁöÑ **ÈÉ®ÁΩ≤** Âíå **‰ΩøÁî®**ÔºåÂØπ‰∫é‰∏Ä‰∫õÂ∞èÁôΩÁî®Êà∑Êù•ËØ¥ÔºåËøòÊòØ **Êúâ‰∏ÄÂÆöÁöÑÈó®Êßõ**ÔºåÂú®Ê≠§ÁâπÂà´ÊÑüË∞¢
**ÂΩïÂíñÔºàAIÊô∫ËÉΩ Â§öÂ™í‰ΩìÊúçÂä°Âπ≥Âè∞Ôºâ** ÁΩëÁ´ôÂü∫‰∫éËØ•È°πÁõÆÔºåÊèê‰æõÁöÑÂÖçË¥π`AIËßÜÈ¢ëÁîüÊàêÂô®`ÊúçÂä°ÔºåÂèØ‰ª•‰∏çÁî®ÈÉ®ÁΩ≤ÔºåÁõ¥Êé•Âú®Á∫ø‰ΩøÁî®ÔºåÈùûÂ∏∏Êñπ‰æø„ÄÇ

- ‰∏≠ÊñáÁâàÔºöhttps://reccloud.cn
- Ëã±ÊñáÁâàÔºöhttps://reccloud.com

![](docs/reccloud.cn.jpg)

## ÊÑüË∞¢ËµûÂä© üôè

ÊÑüË∞¢‰ΩêÁ≥ñ https://picwish.cn ÂØπËØ•È°πÁõÆÁöÑÊîØÊåÅÂíåËµûÂä©Ôºå‰ΩøÂæóËØ•È°πÁõÆËÉΩÂ§üÊåÅÁª≠ÁöÑÊõ¥Êñ∞ÂíåÁª¥Êä§„ÄÇ

‰ΩêÁ≥ñ‰∏ìÊ≥®‰∫é**ÂõæÂÉèÂ§ÑÁêÜÈ¢ÜÂüü**ÔºåÊèê‰æõ‰∏∞ÂØåÁöÑ**ÂõæÂÉèÂ§ÑÁêÜÂ∑•ÂÖ∑**ÔºåÂ∞ÜÂ§çÊùÇÊìç‰ΩúÊûÅËá¥ÁÆÄÂåñÔºåÁúüÊ≠£ÂÆûÁé∞ËÆ©ÂõæÂÉèÂ§ÑÁêÜÊõ¥ÁÆÄÂçï„ÄÇ

![picwish.jpg](docs/picwish.jpg)

## ÂäüËÉΩÁâπÊÄß üéØ

- [x] ÂÆåÊï¥ÁöÑ **MVCÊû∂ÊûÑ**Ôºå‰ª£Á†Å **ÁªìÊûÑÊ∏ÖÊô∞**ÔºåÊòì‰∫éÁª¥Êä§ÔºåÊîØÊåÅ `API` Âíå `WebÁïåÈù¢`
- [x] ÊîØÊåÅËßÜÈ¢ëÊñáÊ°à **AIËá™Âä®ÁîüÊàê**Ôºå‰πüÂèØ‰ª•**Ëá™ÂÆö‰πâÊñáÊ°à**
- [x] ÊîØÊåÅÂ§öÁßç **È´òÊ∏ÖËßÜÈ¢ë** Â∞∫ÂØ∏
    - [x] Á´ñÂ±è 9:16Ôºå`1080x1920`
    - [x] Ê®™Â±è 16:9Ôºå`1920x1080`
- [x] ÊîØÊåÅ **ÊâπÈáèËßÜÈ¢ëÁîüÊàê**ÔºåÂèØ‰ª•‰∏ÄÊ¨°ÁîüÊàêÂ§ö‰∏™ËßÜÈ¢ëÔºåÁÑ∂ÂêéÈÄâÊã©‰∏Ä‰∏™ÊúÄÊª°ÊÑèÁöÑ
- [x] ÊîØÊåÅ **ËßÜÈ¢ëÁâáÊÆµÊó∂Èïø** ËÆæÁΩÆÔºåÊñπ‰æøË∞ÉËäÇÁ¥†ÊùêÂàáÊç¢È¢ëÁéá
- [x] ÊîØÊåÅ **‰∏≠Êñá** Âíå **Ëã±Êñá** ËßÜÈ¢ëÊñáÊ°à
- [x] ÊîØÊåÅ **Â§öÁßçËØ≠Èü≥** ÂêàÊàêÔºåÂèØ **ÂÆûÊó∂ËØïÂê¨** ÊïàÊûú
- [x] ÊîØÊåÅ **Â≠óÂπïÁîüÊàê**ÔºåÂèØ‰ª•Ë∞ÉÊï¥ `Â≠ó‰Ωì`„ÄÅ`‰ΩçÁΩÆ`„ÄÅ`È¢úËâ≤`„ÄÅ`Â§ßÂ∞è`ÔºåÂêåÊó∂ÊîØÊåÅ`Â≠óÂπïÊèèËæπ`ËÆæÁΩÆ
- [x] ÊîØÊåÅ **ËÉåÊôØÈü≥‰πê**ÔºåÈöèÊú∫ÊàñËÄÖÊåáÂÆöÈü≥‰πêÊñá‰ª∂ÔºåÂèØËÆæÁΩÆ`ËÉåÊôØÈü≥‰πêÈü≥Èáè`
- [x] ËßÜÈ¢ëÁ¥†ÊùêÊù•Ê∫ê **È´òÊ∏Ö**ÔºåËÄå‰∏î **Êó†ÁâàÊùÉ**Ôºå‰πüÂèØ‰ª•‰ΩøÁî®Ëá™Â∑±ÁöÑ **Êú¨Âú∞Á¥†Êùê**
- [x] ÊîØÊåÅ **OpenAI**„ÄÅ**Moonshot**„ÄÅ**Azure**„ÄÅ**gpt4free**„ÄÅ**one-api**„ÄÅ**ÈÄö‰πâÂçÉÈóÆ**„ÄÅ**Google Gemini**„ÄÅ**Ollama**„ÄÅ**DeepSeek**„ÄÅ **ÊñáÂøÉ‰∏ÄË®Ä**, **Pollinations** Á≠âÂ§öÁßçÊ®°ÂûãÊé•ÂÖ•
    - ‰∏≠ÂõΩÁî®Êà∑Âª∫ËÆÆ‰ΩøÁî® **DeepSeek** Êàñ **Moonshot** ‰Ωú‰∏∫Â§ßÊ®°ÂûãÊèê‰æõÂïÜÔºàÂõΩÂÜÖÂèØÁõ¥Êé•ËÆøÈóÆÔºå‰∏çÈúÄË¶ÅVPN„ÄÇÊ≥®ÂÜåÂ∞±ÈÄÅÈ¢ùÂ∫¶ÔºåÂü∫Êú¨Â§üÁî®Ôºâ


### ÂêéÊúüËÆ°Âàí üìÖ

- [ ] GPT-SoVITS ÈÖçÈü≥ÊîØÊåÅ
- [ ] ‰ºòÂåñËØ≠Èü≥ÂêàÊàêÔºåÂà©Áî®Â§ßÊ®°ÂûãÔºå‰ΩøÂÖ∂ÂêàÊàêÁöÑÂ£∞Èü≥ÔºåÊõ¥Âä†Ëá™ÁÑ∂ÔºåÊÉÖÁª™Êõ¥Âä†‰∏∞ÂØå
- [ ] Â¢ûÂä†ËßÜÈ¢ëËΩ¨Âú∫ÊïàÊûúÔºå‰ΩøÂÖ∂ÁúãËµ∑Êù•Êõ¥Âä†ÁöÑÊµÅÁïÖ
- [ ] Â¢ûÂä†Êõ¥Â§öËßÜÈ¢ëÁ¥†ÊùêÊù•Ê∫êÔºå‰ºòÂåñËßÜÈ¢ëÁ¥†ÊùêÂíåÊñáÊ°àÁöÑÂåπÈÖçÂ∫¶
- [ ] Â¢ûÂä†ËßÜÈ¢ëÈïøÂ∫¶ÈÄâÈ°πÔºöÁü≠„ÄÅ‰∏≠„ÄÅÈïø
- [ ] ÊîØÊåÅÊõ¥Â§öÁöÑËØ≠Èü≥ÂêàÊàêÊúçÂä°ÂïÜÔºåÊØîÂ¶Ç OpenAI TTS
- [ ] Ëá™Âä®‰∏ä‰º†Âà∞YouTubeÂπ≥Âè∞

## ËßÜÈ¢ëÊºîÁ§∫ üì∫

### Á´ñÂ±è 9:16

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt; „ÄäÂ¶Ç‰ΩïÂ¢ûÂä†ÁîüÊ¥ªÁöÑ‰πêË∂£„Äã&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt; „ÄäÈáëÈí±ÁöÑ‰ΩúÁî®„Äã&lt;br&gt;Êõ¥ÁúüÂÆûÁöÑÂêàÊàêÂ£∞Èü≥&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt; „ÄäÁîüÂëΩÁöÑÊÑè‰πâÊòØ‰ªÄ‰πà„Äã&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/a84d33d5-27a2-4aba-8fd0-9fb2bd91c6a6&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/af2f3b0b-002e-49fe-b161-18ba91c055e8&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/112c9564-d52b-4472-99ad-970b75f66476&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

### Ê®™Â±è 16:9

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;„ÄäÁîüÂëΩÁöÑÊÑè‰πâÊòØ‰ªÄ‰πà„Äã&lt;/th&gt;
&lt;th align=&quot;center&quot;&gt;&lt;g-emoji class=&quot;g-emoji&quot; alias=&quot;arrow_forward&quot;&gt;‚ñ∂Ô∏è&lt;/g-emoji&gt;„Ää‰∏∫‰ªÄ‰πàË¶ÅËøêÂä®„Äã&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/346ebb15-c55f-47a9-a653-114f08bb8073&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;td align=&quot;center&quot;&gt;&lt;video src=&quot;https://github.com/harry0703/MoneyPrinterTurbo/assets/4928832/271f2fae-8283-44a0-8aa0-0ed8f9a6fa87&quot;&gt;&lt;/video&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

## ÈÖçÁΩÆË¶ÅÊ±Ç üì¶

- Âª∫ËÆÆÊúÄ‰Ωé CPU **4Ê†∏** Êàñ‰ª•‰∏äÔºåÂÜÖÂ≠ò **4G** Êàñ‰ª•‰∏äÔºåÊòæÂç°ÈùûÂøÖÈ°ª
- Windows 10 Êàñ MacOS 11.0 ‰ª•‰∏äÁ≥ªÁªü


## Âø´ÈÄüÂºÄÂßã üöÄ

### Âú® Google Colab ‰∏≠ËøêË°å
ÂÖçÂéªÊú¨Âú∞ÁéØÂ¢ÉÈÖçÁΩÆÔºåÁÇπÂáªÁõ¥Êé•Âú® Google Colab ‰∏≠Âø´ÈÄü‰ΩìÈ™å MoneyPrinterTurbo

[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harry0703/MoneyPrinterTurbo/blob/main/docs/MoneyPrinterTurbo.ipynb)


### Windows‰∏ÄÈîÆÂêØÂä®ÂåÖ

‰∏ãËΩΩ‰∏ÄÈîÆÂêØÂä®ÂåÖÔºåËß£ÂéãÁõ¥Êé•‰ΩøÁî®ÔºàË∑ØÂæÑ‰∏çË¶ÅÊúâ **‰∏≠Êñá**„ÄÅ**ÁâπÊÆäÂ≠óÁ¨¶**„ÄÅ**Á©∫Ê†º**Ôºâ

- ÁôæÂ∫¶ÁΩëÁõòÔºàv1.2.6Ôºâ: https://pan.baidu.com/s/1wg0UaIyXpO3SqIpaq790SQ?pwd=sbqx ÊèêÂèñÁ†Å: sbqx
- Google Drive (v1.2.6): https://drive.google.com/file/d/1HsbzfT7XunkrCrHw5ncUjFX8XX4zAuUh/view?usp=sharing

‰∏ãËΩΩÂêéÔºåÂª∫ËÆÆÂÖà**ÂèåÂáªÊâßË°å** `update.bat` Êõ¥Êñ∞Âà∞**ÊúÄÊñ∞‰ª£Á†Å**ÔºåÁÑ∂ÂêéÂèåÂáª `start.bat` ÂêØÂä®

ÂêØÂä®ÂêéÔºå‰ºöËá™Âä®ÊâìÂºÄÊµèËßàÂô®ÔºàÂ¶ÇÊûúÊâìÂºÄÊòØÁ©∫ÁôΩÔºåÂª∫ËÆÆÊç¢Êàê **Chrome** ÊàñËÄÖ **Edge** ÊâìÂºÄÔºâ

## ÂÆâË£ÖÈÉ®ÁΩ≤ üì•

### ÂâçÊèêÊù°‰ª∂

- Â∞ΩÈáè‰∏çË¶Å‰ΩøÁî® **‰∏≠ÊñáË∑ØÂæÑ**ÔºåÈÅøÂÖçÂá∫Áé∞‰∏Ä‰∫õÊó†Ê≥ïÈ¢ÑÊñôÁöÑÈóÆÈ¢ò
- ËØ∑Á°Æ‰øù‰Ω†ÁöÑ **ÁΩëÁªú** ÊòØÊ≠£Â∏∏ÁöÑÔºåVPNÈúÄË¶ÅÊâìÂºÄ`ÂÖ®Â±ÄÊµÅÈáè`Ê®°Âºè

#### ‚ë† ÂÖãÈöÜ‰ª£Á†Å

```shell
git clone https://github.com/harry0703/MoneyPrinterTurbo.git
```

#### ‚ë° ‰øÆÊîπÈÖçÁΩÆÊñá‰ª∂ÔºàÂèØÈÄâÔºåÂª∫ËÆÆÂêØÂä®Âêé‰πüÂèØ‰ª•Âú® WebUI ÈáåÈù¢ÈÖçÁΩÆÔºâ

- Â∞Ü `config.example.toml` Êñá‰ª∂Â§çÂà∂‰∏Ä‰ªΩÔºåÂëΩÂêç‰∏∫ `config.toml`
- ÊåâÁÖß `config.toml` Êñá‰ª∂‰∏≠ÁöÑËØ¥ÊòéÔºåÈÖçÁΩÆÂ•Ω `pexels_api_keys` Âíå `llm_provider`ÔºåÂπ∂Ê†πÊçÆ llm_provider ÂØπÂ∫îÁöÑÊúçÂä°ÂïÜÔºåÈÖçÁΩÆÁõ∏ÂÖ≥ÁöÑ
  API Key

### DockerÈÉ®ÁΩ≤ üê≥

#### ‚ë† ÂêØÂä®Docker

Â¶ÇÊûúÊú™ÂÆâË£Ö DockerÔºåËØ∑ÂÖàÂÆâË£Ö https://www.docker.com/products/docker-desktop/

Â¶ÇÊûúÊòØWindowsÁ≥ªÁªüÔºåËØ∑ÂèÇËÄÉÂæÆËΩØÁöÑÊñáÊ°£Ôºö

1. https://learn.microsoft.com/zh-cn/windows/wsl/install
2. https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/wsl-containers

```shell
cd MoneyPrinterTurbo
docker-compose up
```

&gt; Ê≥®ÊÑèÔºöÊúÄÊñ∞ÁâàÁöÑdockerÂÆâË£ÖÊó∂‰ºöËá™Âä®‰ª•Êèí‰ª∂ÁöÑÂΩ¢ÂºèÂÆâË£Ödocker composeÔºåÂêØÂä®ÂëΩ‰ª§Ë∞ÉÊï¥‰∏∫docker compose up

#### ‚ë° ËÆøÈóÆWebÁïåÈù¢

ÊâìÂºÄÊµèËßàÂô®ÔºåËÆøÈóÆ http://0.0.0.0:8501

#### ‚ë¢ ËÆøÈóÆAPIÊñáÊ°£

ÊâìÂºÄÊµèËßàÂô®ÔºåËÆøÈóÆ http://0.0.0.0:8080/docs ÊàñËÄÖ http://0.0.0.0:8080/redoc

### ÊâãÂä®ÈÉ®ÁΩ≤ üì¶

&gt; ËßÜÈ¢ëÊïôÁ®ã

- ÂÆåÊï¥ÁöÑ‰ΩøÁî®ÊºîÁ§∫Ôºöhttps://v.douyin.com/iFhnwsKY/
- Â¶Ç‰ΩïÂú®Windows‰∏äÈÉ®ÁΩ≤Ôºöhttps://v.douyin.com/iFyjoW3M

#### ‚ë† ÂàõÂª∫ËôöÊãüÁéØÂ¢É

Âª∫ËÆÆ‰ΩøÁî® [conda](https://conda.io/projects/conda/en/latest/user-guide/install/index.html) ÂàõÂª∫ python ËôöÊãüÁéØÂ¢É

```shell
git clone https://github.com/harry0703/MoneyPrinterTurbo.git
cd MoneyPrinterTurbo
conda create -n MoneyPrinterTurbo python=3.11
conda activate MoneyPrinterTurbo
pip install -r requirements.txt
```

#### ‚ë° ÂÆâË£ÖÂ•Ω ImageMagick

- Windows:
    - ‰∏ãËΩΩ https://imagemagick.org/script/download.php ÈÄâÊã©WindowsÁâàÊú¨ÔºåÂàáËÆ∞‰∏ÄÂÆöË¶ÅÈÄâÊã© **ÈùôÊÄÅÂ∫ì** ÁâàÊú¨ÔºåÊØîÂ¶Ç
      ImageMagick-7.1.1-32-Q16-x64-**static**.exe
    - ÂÆâË£Ö‰∏ãËΩΩÂ•ΩÁöÑ ImageMagickÔºå**Ê≥®ÊÑè‰∏çË¶Å‰øÆÊîπÂÆâË£ÖË∑ØÂæÑ**
    - ‰øÆÊîπ `ÈÖçÁΩÆÊñá‰ª∂ config.toml` ‰∏≠ÁöÑ `imagemagick_path` ‰∏∫‰Ω†ÁöÑ **ÂÆûÈôÖÂÆâË£ÖË∑ØÂæÑ**

- MacOS:
  ```shell
  brew install imagemagick
  ````
- Ubuntu
  ```shell
  sudo apt-get install imagemagick
  ```
- CentOS
  ```shell
  sudo yum install ImageMagick
  ```

#### ‚ë¢ ÂêØÂä®WebÁïåÈù¢ üåê

Ê≥®ÊÑèÈúÄË¶ÅÂà∞ MoneyPrinterTurbo È°πÁõÆ `Ê†πÁõÆÂΩï` ‰∏ãÊâßË°å‰ª•‰∏ãÂëΩ‰ª§

###### Windows

```bat
webui.bat
```

###### MacOS or Linux

```shell
sh webui.sh
```

ÂêØÂä®ÂêéÔºå‰ºöËá™Âä®ÊâìÂºÄÊµèËßàÂô®ÔºàÂ¶ÇÊûúÊâìÂºÄÊòØÁ©∫ÁôΩÔºåÂª∫ËÆÆÊç¢Êàê **Chrome** ÊàñËÄÖ **Edge** ÊâìÂºÄÔºâ

#### ‚ë£ ÂêØÂä®APIÊúçÂä° üöÄ

```shell
python main.py
```

ÂêØÂä®ÂêéÔºåÂèØ‰ª•Êü•Áúã `APIÊñáÊ°£` http://127.0.0.1:8080/docs ÊàñËÄÖ http://127.0.0.1:8080/redoc Áõ¥Êé•Âú®Á∫øË∞ÉËØïÊé•Âè£ÔºåÂø´ÈÄü‰ΩìÈ™å„ÄÇ

## ËØ≠Èü≥ÂêàÊàê üó£

ÊâÄÊúâÊîØÊåÅÁöÑÂ£∞Èü≥ÂàóË°®ÔºåÂèØ‰ª•Êü•ÁúãÔºö[Â£∞Èü≥ÂàóË°®](./docs/voice-list.txt)

2024-04-16 v1.1.2 Êñ∞Â¢û‰∫Ü9ÁßçAzureÁöÑËØ≠Èü≥ÂêàÊàêÂ£∞Èü≥ÔºåÈúÄË¶ÅÈÖçÁΩÆAPI KEYÔºåËØ•Â£∞Èü≥ÂêàÊàêÁöÑÊõ¥Âä†ÁúüÂÆû„ÄÇ

## Â≠óÂπïÁîüÊàê üìú

ÂΩìÂâçÊîØÊåÅ2ÁßçÂ≠óÂπïÁîüÊàêÊñπÂºèÔºö

- **edge**: ÁîüÊàê`ÈÄüÂ∫¶Âø´`ÔºåÊÄßËÉΩÊõ¥Â•ΩÔºåÂØπÁîµËÑëÈÖçÁΩÆÊ≤°ÊúâË¶ÅÊ±ÇÔºå‰ΩÜÊòØË¥®ÈáèÂèØËÉΩ‰∏çÁ®≥ÂÆö
- **whisper**: ÁîüÊàê`ÈÄüÂ∫¶ÊÖ¢`ÔºåÊÄßËÉΩËæÉÂ∑ÆÔºåÂØπÁîµËÑëÈÖçÁΩÆÊúâ‰∏ÄÂÆöË¶ÅÊ±ÇÔºå‰ΩÜÊòØ`Ë¥®ÈáèÊõ¥ÂèØÈù†`„ÄÇ

ÂèØ‰ª•‰øÆÊîπ `config.toml` ÈÖçÁΩÆÊñá‰ª∂‰∏≠ÁöÑ `subtitle_provider` ËøõË°åÂàáÊç¢

Âª∫ËÆÆ‰ΩøÁî® `edge` Ê®°ÂºèÔºåÂ¶ÇÊûúÁîüÊàêÁöÑÂ≠óÂπïË¥®Èáè‰∏çÂ•ΩÔºåÂÜçÂàáÊç¢Âà∞ `whisper` Ê®°Âºè

&gt; Ê≥®ÊÑèÔºö

1. whisper Ê®°Âºè‰∏ãÈúÄË¶ÅÂà∞ HuggingFace ‰∏ãËΩΩ‰∏Ä‰∏™Ê®°ÂûãÊñá‰ª∂ÔºåÂ§ßÁ∫¶ 3GB Â∑¶Âè≥ÔºåËØ∑Á°Æ‰øùÁΩëÁªúÈÄöÁïÖ
2. Â¶ÇÊûúÁïôÁ©∫ÔºåË°®Á§∫‰∏çÁîüÊàêÂ≠óÂπï„ÄÇ

&gt; Áî±‰∫éÂõΩÂÜÖÊó†Ê≥ïËÆøÈóÆ HuggingFaceÔºåÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÊñπÊ≥ï‰∏ãËΩΩ `whisper-large-v3` ÁöÑÊ®°ÂûãÊñá‰ª∂

‰∏ãËΩΩÂú∞ÂùÄÔºö

- ÁôæÂ∫¶ÁΩëÁõò: https://pan.baidu.com/s/11h3Q6tsDtjQKTjUu3sc5cA?pwd=xjs9
- Â§∏ÂÖãÁΩëÁõòÔºöhttps://pan.quark.cn/s/3ee3d991d64b

Ê®°Âûã‰∏ãËΩΩÂêéËß£ÂéãÔºåÊï¥‰∏™ÁõÆÂΩïÊîæÂà∞ `.\MoneyPrinterTurbo\models` ÈáåÈù¢Ôºå
ÊúÄÁªàÁöÑÊñá‰ª∂Ë∑ØÂæÑÂ∫îËØ•ÊòØËøôÊ†∑: `.\MoneyPrinterTurbo\models\whisper-large-v3`

```
MoneyPrinterTurbo  
  ‚îú‚îÄmodels
  ‚îÇ   ‚îî‚îÄwhisper-large-v3
  ‚îÇ          config.json
  ‚îÇ          model.bin
  ‚îÇ          preprocessor_config.json
  ‚îÇ          tokenizer.json
  ‚îÇ          vocabulary.json
```

## ËÉåÊôØÈü≥‰πê üéµ

Áî®‰∫éËßÜÈ¢ëÁöÑËÉåÊôØÈü≥‰πêÔºå‰Ωç‰∫éÈ°πÁõÆÁöÑ `resource/songs` ÁõÆÂΩï‰∏ã„ÄÇ
&gt; ÂΩìÂâçÈ°πÁõÆÈáåÈù¢Êîæ‰∫Ü‰∏Ä‰∫õÈªòËÆ§ÁöÑÈü≥‰πêÔºåÊù•Ëá™‰∫é YouTube ËßÜÈ¢ëÔºåÂ¶ÇÊúâ‰æµÊùÉÔºåËØ∑Âà†Èô§„ÄÇ

## Â≠óÂπïÂ≠ó‰Ωì üÖ∞

Áî®‰∫éËßÜÈ¢ëÂ≠óÂπïÁöÑÊ∏≤ÊüìÔºå‰Ωç‰∫éÈ°πÁõÆÁöÑ `resource/fonts` ÁõÆÂΩï‰∏ãÔºå‰Ω†‰πüÂèØ‰ª•ÊîæËøõÂéªËá™Â∑±ÁöÑÂ≠ó‰Ωì„ÄÇ

## Â∏∏ËßÅÈóÆÈ¢ò ü§î

### ‚ùìRuntimeError: No ffmpeg exe could be found

ÈÄöÂ∏∏ÊÉÖÂÜµ‰∏ãÔºåffmpeg ‰ºöË¢´Ëá™Âä®‰∏ãËΩΩÔºåÂπ∂‰∏î‰ºöË¢´Ëá™Âä®Ê£ÄÊµãÂà∞„ÄÇ
‰ΩÜÊòØÂ¶ÇÊûú‰Ω†ÁöÑÁéØÂ¢ÉÊúâÈóÆÈ¢òÔºåÊó†Ê≥ïËá™Âä®‰∏ãËΩΩÔºåÂèØËÉΩ‰ºöÈÅáÂà∞Â¶Ç‰∏ãÈîôËØØÔºö

```
RuntimeError: No ffmpeg exe could be found.
Install ffmpeg on your system, or set the IMAGEIO_FFMPEG_EXE environment variable.
```

Ê≠§Êó∂‰Ω†ÂèØ‰ª•‰ªé https://www.gyan.dev/ffmpeg/builds/ ‰∏ãËΩΩffmpegÔºåËß£ÂéãÂêéÔºåËÆæÁΩÆ `ffmpeg_path` ‰∏∫‰Ω†ÁöÑÂÆûÈôÖÂÆâË£ÖË∑ØÂæÑÂç≥ÂèØ„ÄÇ

```toml
[app]
# ËØ∑Ê†πÊçÆ‰Ω†ÁöÑÂÆûÈôÖË∑ØÂæÑËÆæÁΩÆÔºåÊ≥®ÊÑè Windows Ë∑ØÂæÑÂàÜÈöîÁ¨¶‰∏∫ \\
ffmpeg_path = &quot;C:\\Users\\harry\\Downloads\\ffmpeg.exe&quot;
```

### ‚ùìImageMagickÁöÑÂÆâÂÖ®Á≠ñÁï•ÈòªÊ≠¢‰∫Ü‰∏é‰∏¥Êó∂Êñá‰ª∂@/tmp/tmpur5hyyto.txtÁõ∏ÂÖ≥ÁöÑÊìç‰Ωú

ÂèØ‰ª•Âú®ImageMagickÁöÑÈÖçÁΩÆÊñá‰ª∂policy.xml‰∏≠ÊâæÂà∞Ëøô‰∫õÁ≠ñÁï•„ÄÇ
Ëøô‰∏™Êñá‰ª∂ÈÄöÂ∏∏‰Ωç‰∫é /etc/ImageMagick-`X`/ Êàñ ImageMagick ÂÆâË£ÖÁõÆÂΩïÁöÑÁ±ª‰ºº‰ΩçÁΩÆ„ÄÇ
‰øÆÊîπÂåÖÂê´`pattern=&quot;@&quot;`ÁöÑÊù°ÁõÆÔºåÂ∞Ü`rights=&quot;none&quot;`Êõ¥Êîπ‰∏∫`rights=&quot;read|write&quot;`‰ª•ÂÖÅËÆ∏ÂØπÊñá‰ª∂ÁöÑËØªÂÜôÊìç‰Ωú„ÄÇ

### ‚ùìOSError: [Errno 24] Too many open files

Ëøô‰∏™ÈóÆÈ¢òÊòØÁî±‰∫éÁ≥ªÁªüÊâìÂºÄÊñá‰ª∂Êï∞ÈôêÂà∂ÂØºËá¥ÁöÑÔºåÂèØ‰ª•ÈÄöËøá‰øÆÊîπÁ≥ªÁªüÁöÑÊñá‰ª∂ÊâìÂºÄÊï∞ÈôêÂà∂Êù•Ëß£ÂÜ≥„ÄÇ

Êü•ÁúãÂΩìÂâçÈôêÂà∂

```shell
ulimit -n
```

Â¶ÇÊûúËøá‰ΩéÔºåÂèØ‰ª•Ë∞ÉÈ´ò‰∏Ä‰∫õÔºåÊØîÂ¶Ç

```shell
ulimit -n 10240
```

### ‚ùìWhisper Ê®°Âûã‰∏ãËΩΩÂ§±Ë¥•ÔºåÂá∫Áé∞Â¶Ç‰∏ãÈîôËØØ

LocalEntryNotfoundEror: Cannot find an appropriate cached snapshotfolderfor the specified revision on the local disk and
outgoing trafic has been disabled.
To enablerepo look-ups and downloads online, pass &#039;local files only=False&#039; as input.

ÊàñËÄÖ

An error occured while synchronizing the model Systran/faster-whisper-large-v3 from the Hugging Face Hub:
An error happened while trying to locate the files on the Hub and we cannot find the appropriate snapshot folder for the
specified revision on the local disk. Please check your internet connection and try again.
Trying to load the model directly from the local cache, if it exists.

Ëß£ÂÜ≥ÊñπÊ≥ïÔºö[ÁÇπÂáªÊü•ÁúãÂ¶Ç‰Ωï‰ªéÁΩëÁõòÊâãÂä®‰∏ãËΩΩÊ®°Âûã](#%E5%AD%97%E5%B9%95%E7%94%9F%E6%88%90-)

## ÂèçÈ¶àÂª∫ËÆÆ üì¢

- ÂèØ‰ª•Êèê‰∫§ [issue](https://github.com/harry0703/MoneyPrinterTurbo/issues)
  ÊàñËÄÖ [pull request](https://github.com/harry0703/MoneyPrinterTurbo/pulls)„ÄÇ

## ËÆ∏ÂèØËØÅ üìù

ÁÇπÂáªÊü•Áúã [`LICENSE`](LICENSE) Êñá‰ª∂

## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=harry0703/MoneyPrinterTurbo&amp;type=Date)](https://star-history.com/#harry0703/MoneyPrinterTurbo&amp;Date)</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[xming521/WeClone]]></title>
            <link>https://github.com/xming521/WeClone</link>
            <guid>https://github.com/xming521/WeClone</guid>
            <pubDate>Thu, 15 May 2025 00:04:30 GMT</pubDate>
            <description><![CDATA[üöÄ‰ªéËÅäÂ§©ËÆ∞ÂΩïÂàõÈÄ†Êï∞Â≠óÂàÜË∫´ÁöÑ‰∏ÄÁ´ôÂºèËß£ÂÜ≥ÊñπÊ°àüí° ‰ΩøÁî®ËÅäÂ§©ËÆ∞ÂΩïÂæÆË∞ÉÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåËÆ©Â§ßÊ®°ÂûãÊúâ‚ÄúÈÇ£Âë≥ÂÑø‚ÄùÔºåÂπ∂ÁªëÂÆöÂà∞ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂÆûÁé∞Ëá™Â∑±ÁöÑÊï∞Â≠óÂàÜË∫´„ÄÇ Êï∞Â≠óÂÖãÈöÜ/Êï∞Â≠óÂàÜË∫´/Êï∞Â≠óÊ∞∏Áîü/LLM/ËÅäÂ§©Êú∫Âô®‰∫∫/LoRA]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xming521/WeClone">xming521/WeClone</a></h1>
            <p>üöÄ‰ªéËÅäÂ§©ËÆ∞ÂΩïÂàõÈÄ†Êï∞Â≠óÂàÜË∫´ÁöÑ‰∏ÄÁ´ôÂºèËß£ÂÜ≥ÊñπÊ°àüí° ‰ΩøÁî®ËÅäÂ§©ËÆ∞ÂΩïÂæÆË∞ÉÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºåËÆ©Â§ßÊ®°ÂûãÊúâ‚ÄúÈÇ£Âë≥ÂÑø‚ÄùÔºåÂπ∂ÁªëÂÆöÂà∞ËÅäÂ§©Êú∫Âô®‰∫∫ÔºåÂÆûÁé∞Ëá™Â∑±ÁöÑÊï∞Â≠óÂàÜË∫´„ÄÇ Êï∞Â≠óÂÖãÈöÜ/Êï∞Â≠óÂàÜË∫´/Êï∞Â≠óÊ∞∏Áîü/LLM/ËÅäÂ§©Êú∫Âô®‰∫∫/LoRA</p>
            <p>Language: Python</p>
            <p>Stars: 7,294</p>
            <p>Forks: 556</p>
            <p>Stars today: 2,057 stars today</p>
            <h2>README</h2><pre>![download](https://github.com/user-attachments/assets/5842e84e-004f-4afd-9373-af64e9575b78)
&lt;h3 align=&quot;center&quot;&gt;üöÄ‰ªéËÅäÂ§©ËÆ∞ÂΩïÂàõÈÄ†Êï∞Â≠óÂàÜË∫´ÁöÑ‰∏ÄÁ´ôÂºèËß£ÂÜ≥ÊñπÊ°àüí°&lt;/h3&gt;  

&lt;div align=&quot;center&quot;&gt;

[![GitHub stars](https://img.shields.io/github/stars/xming521/WeClone?style=for-the-badge&amp;logo=github&amp;label=Stars&amp;logoColor=white&amp;color=ffda65)](https://github.com/xming521/WeClone/stargazers)
[![GitHub release](https://img.shields.io/github/v/release/xming521/WeClone?style=for-the-badge&amp;logo=github&amp;label=Release&amp;logoColor=white&amp;color=06d094)](https://github.com/xming521/WeClone/releases)
&lt;a href=&quot;https://qm.qq.com/cgi-bin/qm/qr?k=wNdgbOVT6oFOJ2wlMLsolUXErW9ESLpk&amp;jump_from=webapi&amp;authKey=z/reOp6YLyvR4Tl2k2nYMsLoMC3w9/99ucgKMX0oRGlxDV/WbYnvq2QxODoIkfxn&quot; target=&quot;_blank&quot; style=&quot;text-decoration: none;&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/QQÁæ§-708067078-12B7F5?style=for-the-badge&amp;logo=qq&amp;logoColor=white&quot; alt=&quot;WeClone‚ë†&quot; title=&quot;WeClone‚ë†&quot;&gt;
&lt;/a&gt;
[![Telegram](https://img.shields.io/badge/Telegram-2CA5E0?style=for-the-badge&amp;logo=telegram&amp;logoColor=white)](https://t.me/+JEdak4m0XEQ3NGNl)

&lt;a href=&quot;https://hellogithub.com/repository/12ab209b56cb4cfd885c8cfd4cfdd53e&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=12ab209b56cb4cfd885c8cfd4cfdd53e&amp;claim_uid=RThlPDoGrFvdMY5&quot; alt=&quot;FeaturedÔΩúHelloGitHub&quot; style=&quot;width: 150px; height: 28px;&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://trendshift.io/repositories/13759&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/13759&quot; alt=&quot;xming521%2FWeClone | Trendshift&quot; style=&quot;width: 220px; height: 50px;&quot; /&gt;&lt;/a&gt;
&lt;a href=&quot;https://deepwiki.com/xming521/WeClone&quot;&gt;&lt;img src=&quot;https://deepwiki.com/badge.svg&quot; alt=&quot;Ask DeepWiki&quot;  style=&quot;width: 134px; height: 23px;margin-bottom: 3px;&quot;&gt;&lt;/a&gt;
&lt;/div&gt;


## ‚ú®Ê†∏ÂøÉÂäüËÉΩ
- üí´ Ê∂µÁõñÊâìÈÄ†Êï∞Â≠óÂàÜË∫´ÁöÑÂÖ®ÈìæË∑ØÊñπÊ°àÔºåÂåÖÊã¨ËÅäÂ§©Êï∞ÊçÆÂØºÂá∫„ÄÅÈ¢ÑÂ§ÑÁêÜ„ÄÅÊ®°ÂûãËÆ≠ÁªÉ„ÄÅÈÉ®ÁΩ≤
- üí¨ ‰ΩøÁî®ÂæÆ‰ø°ËÅäÂ§©ËÆ∞ÂΩïÂæÆË∞ÉLLMÔºåËÆ©Â§ßÊ®°ÂûãÊúâ&quot;ÈÇ£Âë≥ÂÑø&quot;
- üîó ÁªëÂÆöÂà∞ÂæÆ‰ø°„ÄÅQQ„ÄÅTelegram„ÄÅ‰ºÅÂæÆ„ÄÅÈ£û‰π¶Êú∫Âô®‰∫∫ÔºåÂÆûÁé∞Ëá™Â∑±ÁöÑÊï∞Â≠óÂàÜË∫´
- üõ°Ô∏è ÈöêÁßÅ‰ø°ÊÅØËøáÊª§ÔºåÊú¨Âú∞ÂåñÂæÆË∞ÉÈÉ®ÁΩ≤ÔºåÊï∞ÊçÆÂÆâÂÖ®ÂèØÊéß

## üìãÁâπÊÄß‰∏éËØ¥Êòé

&gt; [!IMPORTANT]
&gt; ### 0.2.1ÁâàÊú¨ÊîØÊåÅ‰∫ÜÂëΩ‰ª§Ë°åÂ∑•ÂÖ∑Ôºå‰ΩøÁî®ÂâçÈúÄË¶ÅÈáçÊñ∞ÊâßË°å `uv pip install -e .` 

&gt; [!IMPORTANT]
&gt; 0.2.0ÁâàÊú¨ËøõË°å‰∫ÜÂÖ®Èù¢ÈáçÊûÑÔºåÊï∞ÊçÆÈõÜÁõÆÂΩïÂíåËÑöÊú¨Ë∑ØÂæÑÂÖ®ÈÉ®ËøõË°å‰∫Ü‰øÆÊîπÔºåÊãâÂèñÊñ∞‰ª£Á†ÅÂêéÔºå`csv`Êñá‰ª∂Â§πÊîæÂú®`dataset`‰∏ãÔºåÂπ∂‰∏îÈúÄË¶ÅÈáçÊñ∞ÂÆâË£Ö‰æùËµñ„ÄÇ

&gt; [!IMPORTANT]
&gt; - WeClone‰ªçÂú®Âø´ÈÄüËø≠‰ª£ÊúüÔºåÂΩìÂâçÊïàÊûú‰∏ç‰ª£Ë°®ÊúÄÁªàÊïàÊûú„ÄÇ  
&gt; - ÂæÆË∞ÉLLMÊïàÊûúÂæàÂ§ßÁ®ãÂ∫¶ÂèñÂÜ≥‰∫éÊ®°ÂûãÂ§ßÂ∞è„ÄÅËÅäÂ§©Êï∞ÊçÆÁöÑÊï∞ÈáèÂíåË¥®ÈáèÔºåÁêÜËÆ∫‰∏äÊ®°ÂûãË∂äÂ§ßÔºåÊï∞ÊçÆË∂äÂ§öÔºåÊïàÊûúË∂äÂ•Ω„ÄÇ   
&gt; - WindowsÁéØÂ¢ÉÊú™ËøõË°å‰∏•Ê†ºÊµãËØïÔºåÂèØ‰ª•‰ΩøÁî®WSL‰Ωú‰∏∫ËøêË°åÁéØÂ¢É„ÄÇ

### Á°¨‰ª∂Ë¶ÅÊ±Ç

È°πÁõÆÈªòËÆ§‰ΩøÁî®Qwen2.5-7B-InstructÊ®°ÂûãÔºåLoRAÊñπÊ≥ïÂØπsftÈò∂ÊÆµÂæÆË∞ÉÔºåÂ§ßÁ∫¶ÈúÄË¶Å16GBÊòæÂ≠ò„ÄÇ‰πüÂèØ‰ª•‰ΩøÁî®[LLaMA Factory](https://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md#%E6%A8%A1%E5%9E%8B)ÊîØÊåÅÁöÑÂÖ∂‰ªñÊ®°ÂûãÂíåÊñπÊ≥ï„ÄÇ

ÈúÄË¶ÅÊòæÂ≠òÁöÑ‰º∞ÁÆóÂÄºÔºö
| ÊñπÊ≥ï                             | Á≤æÂ∫¶ |   7B  |  14B  |  30B  |   70B  |   `x`B  |
| ------------------------------- | ---- | ----- | ----- | ----- | ------ | ------- |
| Full (`bf16` or `fp16`)         |  32  | 120GB | 240GB | 600GB | 1200GB | `18x`GB |
| Full (`pure_bf16`)              |  16  |  60GB | 120GB | 300GB |  600GB |  `8x`GB |
| Freeze/LoRA/GaLore/APOLLO/BAdam |  16  |  16GB |  32GB |  64GB |  160GB |  `2x`GB |
| QLoRA                           |   8  |  10GB |  20GB |  40GB |   80GB |   `x`GB |
| QLoRA                           |   4  |   6GB |  12GB |  24GB |   48GB | `x/2`GB |
| QLoRA                           |   2  |   4GB |   8GB |  16GB |   24GB | `x/4`GB |


## ÁéØÂ¢ÉÊê≠Âª∫
1.cudaÂÆâË£Ö(Â∑≤ÂÆâË£ÖÂèØË∑≥ËøáÔºå**Ë¶ÅÊ±ÇÁâàÊú¨12.4Âèä‰ª•‰∏ä**)Ôºö[LLaMA Factory](https://llamafactory.readthedocs.io/zh-cn/latest/getting_started/installation.html#cuda) 

2.Âª∫ËÆÆ‰ΩøÁî® [uv](https://docs.astral.sh/uv/)ÂÆâË£Ö‰æùËµñÔºåËøôÊòØ‰∏Ä‰∏™ÈùûÂ∏∏Âø´ÈÄüÁöÑ Python ÁéØÂ¢ÉÁÆ°ÁêÜÂô®„ÄÇÂÆâË£ÖuvÂêéÔºåÊÇ®ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§ÂàõÂª∫‰∏Ä‰∏™Êñ∞ÁöÑPythonÁéØÂ¢ÉÂπ∂ÂÆâË£Ö‰æùËµñÈ°πÔºåÊ≥®ÊÑèËøô‰∏çÂåÖÂê´Èü≥È¢ëÂÖãÈöÜÂäüËÉΩÁöÑ‰æùËµñÔºö
```bash
git clone https://github.com/xming521/WeClone.git
cd WeClone
uv venv .venv --python=3.10
source .venv/bin/activate # windows‰∏ãÊâßË°å .venv\Scripts\activate
uv pip install --group main -e . 
```
&gt; [!TIP]
&gt; Â¶ÇÊûúË¶Å‰ΩøÁî®ÊúÄÊñ∞ÁöÑÊ®°ÂûãËøõË°åÂæÆË∞ÉÔºåÈúÄË¶ÅÊâãÂä®ÂÆâË£ÖÊúÄÊñ∞ÁâàLLaMA FactoryÔºö`uv pip install --upgrade git+https://github.com/hiyouga/LLaMA-Factory.git`,ÂêåÊó∂ÂÖ∂‰ªñ‰æùËµñÁâàÊú¨‰πüÂèØËÉΩÈúÄË¶Å‰øÆÊîπÔºå‰æãÂ¶Çvllm pytorch transforms

3.Â∞ÜÈÖçÁΩÆÊñá‰ª∂Ê®°ÊùøÂ§çÂà∂‰∏Ä‰ªΩÂπ∂ÈáçÂëΩÂêç‰∏∫`settings.jsonc`ÔºåÂêéÁª≠ÈÖçÁΩÆ‰øÆÊîπÂú®Ê≠§Êñá‰ª∂ËøõË°åÔºö
```bash
cp settings.template.json settings.jsonc
```
&gt; [!NOTE]
&gt; ËÆ≠ÁªÉ‰ª•ÂèäÊé®ÁêÜÁõ∏ÂÖ≥ÈÖçÁΩÆÁªü‰∏ÄÂú®Êñá‰ª∂`settings.jsonc`

4.‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§ÊµãËØïCUDAÁéØÂ¢ÉÊòØÂê¶Ê≠£Á°ÆÈÖçÁΩÆÂπ∂ÂèØË¢´PyTorchËØÜÂà´ÔºåMac‰∏çÈúÄË¶ÅÔºö
```bash
python -c &quot;import torch; print(&#039;CUDAÊòØÂê¶ÂèØÁî®:&#039;, torch.cuda.is_available());&quot;
```

5.ÔºàÂèØÈÄâÔºâÂÆâË£ÖFlashAttentionÔºåÂä†ÈÄüËÆ≠ÁªÉÂíåÊé®ÁêÜÔºö`uv pip install flash-attn --no-build-isolation`

## Ê®°Âûã‰∏ãËΩΩ
```bash
git lfs install
git clone https://www.modelscope.cn/Qwen/Qwen2.5-7B-Instruct.git
```
‰∏ãËΩΩÊúâÈóÆÈ¢ò‰ΩøÁî®ÂÖ∂‰ªñÊñπÂºè‰∏ãËΩΩÔºö[Ê®°ÂûãÁöÑ‰∏ãËΩΩ](https://www.modelscope.cn/docs/models/download)


## Êï∞ÊçÆÂáÜÂ§á

ËØ∑‰ΩøÁî®[PyWxDump](https://github.com/xaoyaoo/PyWxDump)ÊèêÂèñÂæÆ‰ø°ËÅäÂ§©ËÆ∞ÂΩïÔºà‰∏çÊîØÊåÅ4.0ÁâàÊú¨ÂæÆ‰ø°Ôºâ„ÄÇÂèØ‰ª•ÂÖàÂ∞ÜÊâãÊú∫ÁöÑËÅäÂ§©ËÆ∞ÂΩïËøÅÁßªÔºàÂ§á‰ªΩÔºâÂà∞ÁîµËÑëÔºåÊï∞ÊçÆÈáèÊõ¥Â§ö‰∏Ä‰∫õ„ÄÇ‰∏ãËΩΩËΩØ‰ª∂Âπ∂Ëß£ÂØÜÊï∞ÊçÆÂ∫ìÂêéÔºåÁÇπÂáªËÅäÂ§©Â§á‰ªΩÔºåÂØºÂá∫Á±ªÂûã‰∏∫CSVÔºåÂèØ‰ª•ÂØºÂá∫Â§ö‰∏™ËÅîÁ≥ª‰∫∫Ôºà‰∏çÂª∫ËÆÆ‰ΩøÁî®Áæ§ËÅäËÆ∞ÂΩïÔºâÔºåÁÑ∂ÂêéÂ∞ÜÂØºÂá∫ÁöÑ‰Ωç‰∫é`wxdump_tmp/export` ÁöÑ `csv` Êñá‰ª∂Â§πÊîæÂú®`./dataset`ÁõÆÂΩïÂç≥ÂèØÔºå‰πüÂ∞±ÊòØ‰∏çÂêå‰∫∫ËÅäÂ§©ËÆ∞ÂΩïÁöÑÊñá‰ª∂Â§π‰∏ÄËµ∑ÊîæÂú® `./dataset/csv`„ÄÇ   

## Êï∞ÊçÆÈ¢ÑÂ§ÑÁêÜ

- È°πÁõÆÈªòËÆ§ÂéªÈô§‰∫ÜÊï∞ÊçÆ‰∏≠ÁöÑÊâãÊú∫Âè∑„ÄÅË∫´‰ªΩËØÅÂè∑„ÄÅÈÇÆÁÆ±„ÄÅÁΩëÂùÄ„ÄÇËøòÂú®`settings.jsonc`‰∏≠Êèê‰æõ‰∫Ü‰∏Ä‰∏™Á¶ÅÁî®ËØçËØçÂ∫ì`blocked_words`ÔºåÂèØ‰ª•Ëá™Ë°åÊ∑ªÂä†ÈúÄË¶ÅËøáÊª§ÁöÑËØçÂè•Ôºà‰ºöÈªòËÆ§ÂéªÊéâÂåÖÊã¨Á¶ÅÁî®ËØçÁöÑÊï¥Âè•Ôºâ„ÄÇ
&gt; [!IMPORTANT]
&gt; üö® ËØ∑‰∏ÄÂÆöÊ≥®ÊÑè‰øùÊä§‰∏™‰∫∫ÈöêÁßÅÔºå‰∏çË¶ÅÊ≥ÑÈú≤‰∏™‰∫∫‰ø°ÊÅØÔºÅ

- ÊâßË°å‰ª•‰∏ãÂëΩ‰ª§ÂØπÊï∞ÊçÆËøõË°åÂ§ÑÁêÜÔºåÂèØ‰ª•Ê†πÊçÆËá™Â∑±ÁöÑËÅäÂ§©È£éÊ†º‰øÆÊîπsettings.jsoncÁöÑ`make_dataset_args`„ÄÇ
```bash
weclone-cli make-dataset
```
- ÁõÆÂâç‰ªÖÊîØÊåÅÊó∂Èó¥Á™óÂè£Á≠ñÁï•ÔºåÊ†πÊçÆ`single_combine_time_window`Â∞ÜÂçï‰∫∫ËøûÁª≠Ê∂àÊÅØÈÄöËøáÈÄóÂè∑ËøûÊé•ÂêàÂπ∂‰∏∫‰∏ÄÂè•ÔºåÊ†πÊçÆ`qa_match_time_window`ÂåπÈÖçÈóÆÁ≠îÂØπ„ÄÇ
- ÂèØ‰ª•ÂêØÁî®`clean_dataset`‰∏≠ÁöÑ`enable_clean`ÈÄâÈ°πÔºåÂØπÊï∞ÊçÆËøõË°åÊ∏ÖÊ¥óÔºå‰ª•ËææÂà∞Êõ¥Â•ΩÊïàÊûú„ÄÇÂΩìÂâç‰ΩøÁî®llm judgeÂØπËÅäÂ§©ËÆ∞ÂΩïËøõË°åÊâìÂàÜÔºå‰ΩøÁî®vllmËøõË°åÁ¶ªÁ∫øÊé®ÁêÜ„ÄÇÂú®ÂæóÂà∞`llmÊâìÂàÜÂàÜÊï∞ÂàÜÂ∏ÉÊÉÖÂÜµ`ÂêéÔºåË∞ÉÊï¥`accept_score`ÈÄâÊã©ÂèØ‰ª•Êé•ÂèóÁöÑÂàÜÊï∞ÔºåÂÜçÈÄÇÂΩìÈôç‰Ωé`train_sft_args`ÁöÑ`lora_dropout`ÂèÇÊï∞ÊèêÂçáÊãüÂêàÊïàÊûú„ÄÇ

## ÈÖçÁΩÆÂèÇÊï∞Âπ∂ÂæÆË∞ÉÊ®°Âûã

- (ÂèØÈÄâ)‰øÆÊîπ `settings.jsonc` ÁöÑ `model_name_or_path` Âíå `template` ÈÄâÊã©Êú¨Âú∞‰∏ãËΩΩÂ•ΩÁöÑÂÖ∂‰ªñÊ®°Âûã„ÄÇ  
- ‰øÆÊîπ`per_device_train_batch_size`‰ª•Âèä`gradient_accumulation_steps`Êù•Ë∞ÉÊï¥ÊòæÂ≠òÂç†Áî®„ÄÇ  
- ÂèØ‰ª•Ê†πÊçÆËá™Â∑±Êï∞ÊçÆÈõÜÁöÑÊï∞ÈáèÂíåË¥®Èáè‰øÆÊîπ`train_sft_args`ÁöÑ`num_train_epochs`„ÄÅ`lora_rank`„ÄÅ`lora_dropout`Á≠âÂèÇÊï∞„ÄÇ

### ÂçïÂç°ËÆ≠ÁªÉ
```bash
weclone-cli train-sft
```
Â§öÂç°ÁéØÂ¢ÉÂçïÂç°ËÆ≠ÁªÉÔºåÈúÄË¶ÅÂÖàÊâßË°å `export CUDA_VISIBLE_DEVICES=0`

### Â§öÂç°ËÆ≠ÁªÉ
ÂèñÊ∂à`settings.jsonc`‰∏≠`deepspeed`Ë°å‰ª£Á†ÅÊ≥®ÈáäÔºå‰ΩøÁî®‰ª•‰∏ãÂëΩ‰ª§Â§öÂç°ËÆ≠ÁªÉÔºö
```bash
uv pip install deepspeed
deepspeed --num_gpus=‰ΩøÁî®ÊòæÂç°Êï∞Èáè weclone/train/train_sft.py
```

### ‰ΩøÁî®ÊµèËßàÂô®demoÁÆÄÂçïÊé®ÁêÜ
ÂèØ‰ª•Âú®Ëøô‰∏ÄÊ≠•ÊµãËØïÂá∫ÂêàÈÄÇÁöÑtemperature„ÄÅtop_pÂÄºÔºå‰øÆÊîπsettings.jsoncÁöÑ`infer_args`ÂêéÔºå‰æõÂêéÁª≠Êé®ÁêÜÊó∂‰ΩøÁî®„ÄÇ
```bash
weclone-cli webchat-demo
```

### ‰ΩøÁî®Êé•Âè£ËøõË°åÊé®ÁêÜ

```bash
weclone-cli server
```

### ‰ΩøÁî®Â∏∏ËßÅËÅäÂ§©ÈóÆÈ¢òÊµãËØï
‰∏çÂåÖÂê´ËØ¢ÈóÆ‰∏™‰∫∫‰ø°ÊÅØÁöÑÈóÆÈ¢òÔºå‰ªÖÊúâÊó•Â∏∏ËÅäÂ§©„ÄÇÊµãËØïÁªìÊûúÂú®test_result-my.txt„ÄÇ
```bash
weclone-cli server
weclone-cli test-model
```

## üñºÔ∏è ÂæÆË∞ÉÊïàÊûú
‰ΩøÁî®Qwen2.5-14B-InstructÊ®°ÂûãÔºåÂ§ßÊ¶Ç3‰∏áÊù°Â§ÑÁêÜÂêéÁöÑÊúâÊïàÊï∞ÊçÆÔºålossÈôçÂà∞‰∫Ü3.5Â∑¶Âè≥ÁöÑÊïàÊûú„ÄÇ
&lt;details&gt;
&lt;summary&gt;Êà™Âõæ&lt;/summary&gt;
&lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 10px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/0775ec52-452b-485f-9785-c6eb7b277132&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/8c7628b5-da70-4c37-9e51-fdfb0eadd2df&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/523aa742-2aa3-40e9-bd67-b98b336e83a8&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/dabf0603-dcc4-4a47-b5c3-2bbc036820d9&quot; alt=&quot;alt text&quot; style=&quot;width: 48%; min-width: 150px;&quot;&gt;
&lt;/div&gt;
&lt;/details&gt;


## ü§ñ ÈÉ®ÁΩ≤Âà∞ËÅäÂ§©Êú∫Âô®‰∫∫

[AstrBot](https://github.com/AstrBotDevs/AstrBot) ÊòØÊòì‰∏äÊâãÁöÑÂ§öÂπ≥Âè∞ LLM ËÅäÂ§©Êú∫Âô®‰∫∫ÂèäÂºÄÂèëÊ°ÜÊû∂ ‚ú® Âπ≥Âè∞ÊîØÊåÅ QQ„ÄÅQQÈ¢ëÈÅì„ÄÅTelegram„ÄÅÂæÆ‰ø°„ÄÅ‰ºÅÂæÆ„ÄÅÈ£û‰π¶„ÄÇ      

‰ΩøÁî®Ê≠•È™§Ôºö
1. ÈÉ®ÁΩ≤ AstrBot
2. Âú® AstrBot ‰∏≠ÈÉ®ÁΩ≤Ê∂àÊÅØÂπ≥Âè∞
3. ÊâßË°å `weclone-cli server` ÂêØÂä®apiÊúçÂä°
4. Âú® AstrBot ‰∏≠Êñ∞Â¢ûÊúçÂä°Êèê‰æõÂïÜÔºåÁ±ªÂûãÈÄâÊã©OpenAIÔºåAPI Base URL Ê†πÊçÆAstrBotÈÉ®ÁΩ≤ÊñπÂºèÂ°´ÂÜôÔºà‰æãÂ¶ÇdockerÈÉ®ÁΩ≤ÂèØËÉΩ‰∏∫http://172.17.0.1:8005/v1Ôºâ ÔºåÊ®°ÂûãÂ°´ÂÜôgpt-3.5-turbo,API KeyÈöèÊÑèÂ°´ÂÜô‰∏Ä‰∏™
5. ÂæÆË∞ÉÂêé‰∏çÊîØÊåÅÂ∑•ÂÖ∑Ë∞ÉÁî®ÔºåËØ∑ÂÖàÂÖ≥ÊéâÈªòËÆ§ÁöÑÂ∑•ÂÖ∑ÔºåÊ∂àÊÅØÂπ≥Âè∞ÂèëÈÄÅÊåá‰ª§Ôºö `/tool off all`ÔºåÂê¶Âàô‰ºöÊ≤°ÊúâÂæÆË∞ÉÂêéÁöÑÊïàÊûú„ÄÇ 
6. Ê†πÊçÆÂæÆË∞ÉÊó∂‰ΩøÁî®ÁöÑdefault_systemÔºåÂú® AstrBot ‰∏≠ËÆæÁΩÆÁ≥ªÁªüÊèêÁ§∫ËØç„ÄÇ
![5](https://github.com/user-attachments/assets/19de7072-076a-4cdf-8ae6-46b9b89f536a)
&gt; [!IMPORTANT]
&gt; Ê£ÄÊü•api_serviceÁöÑÊó•ÂøóÔºåÂ∞ΩÈáè‰øùËØÅÂ§ßÊ®°ÂûãÊúçÂä°ËØ∑Ê±ÇÁöÑÂèÇÊï∞ÂíåÂæÆË∞ÉÊó∂‰∏ÄËá¥ÔºåtoolÊèí‰ª∂ËÉΩÂäõÈÉΩÂÖ≥Êéâ„ÄÇ
7. Ë∞ÉÊï¥ÈááÊ†∑ÂèÇÊï∞Ôºå‰æãÂ¶Çtemperature„ÄÅtop_p„ÄÅtop_kÁ≠â
[ÈÖçÁΩÆËá™ÂÆö‰πâÁöÑÊ®°ÂûãÂèÇÊï∞](https://astrbot.app/config/model-config.html#%E9%85%8D%E7%BD%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0)

## üìå Ë∑ØÁ∫øÂõæ
- [ ] Êõ¥‰∏∞ÂØåÁöÑ‰∏ä‰∏ãÊñáÔºöÂåÖÊã¨‰∏ä‰∏ãÊñáÂØπËØù„ÄÅËÅäÂ§©ÂØπË±°‰ø°ÊÅØ„ÄÅÊó∂Èó¥Á≠â + ÊÄùËÄÉ
- [ ] Memory ÊîØÊåÅ
- [ ] ÊîØÊåÅÂ§öÊ®°ÊÄÅ
- [ ] Êï∞ÊçÆÂ¢ûÂº∫
- [ ] ÊîØÊåÅGUI

## ÈóÆÈ¢òËß£ÂÜ≥
- ÂæÆË∞ÉÈóÆÈ¢òÔºö[LLaMA-Factory| FAQs | Â∏∏ËßÅÈóÆÈ¢ò](https://github.com/hiyouga/LLaMA-Factory/issues/4614) ÊàñËÄÖÊõ¥Êñπ‰æøÁöÑ [![Êõ¥Êñπ‰æøÁöÑAsk DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/hiyouga/LLaMA-Factory)

## ‚ù§Ô∏è Ë¥°ÁåÆ‰ª£Á†Å

Ê¨¢Ëøé‰ªª‰Ωï Issues/Pull RequestsÔºÅ

‰Ω†ÂèØ‰ª•ÈÄöËøáÊü•ÁúãIssuesÊàñÂ∏ÆÂä©ÂÆ°Ê†∏ PRÔºàÊãâÂèñËØ∑Ê±ÇÔºâÊù•Ë¥°ÁåÆ„ÄÇÂØπ‰∫éÊñ∞ÂäüËÉΩÁöÑÊ∑ªÂä†ÔºåËØ∑ÂÖàÈÄöËøá Issue ËÆ®ËÆ∫„ÄÇ   
ËøêË°å`uv pip install --group dev -e .`ÂÆâË£ÖÂºÄÂèë‰æùËµñ„ÄÇ   
È°πÁõÆ‰ΩøÁî®`pytest`ÊµãËØï(ÊµãËØïËÑöÊú¨ÂæÖÂÆåÂñÑ)Ôºå`pyright`Ê£ÄÊü•Á±ªÂûãÔºå`ruff`Ê£ÄÊü•‰ª£Á†ÅÊ†ºÂºè„ÄÇ


## ‚ö†Ô∏è ÂÖçË¥£Â£∞Êòé
&gt; [!CAUTION]
&gt; ËØ∑ÂãøÁî®‰∫éÈùûÊ≥ïÁî®ÈÄîÔºåÂê¶ÂàôÂêéÊûúËá™Ë¥ü„ÄÇ
&lt;details&gt;
&lt;summary&gt;1. ‰ΩøÁî®ÁõÆÁöÑ&lt;/summary&gt;

* Êú¨È°πÁõÆ‰ªÖ‰æõÂ≠¶‰π†‰∫§ÊµÅ‰ΩøÁî®Ôºå**ËØ∑ÂãøÁî®‰∫éÈùûÊ≥ïÁî®ÈÄî**Ôºå**ËØ∑ÂãøÁî®‰∫éÈùûÊ≥ïÁî®ÈÄî**Ôºå**ËØ∑ÂãøÁî®‰∫éÈùûÊ≥ïÁî®ÈÄî**ÔºåÂê¶ÂàôÂêéÊûúËá™Ë¥ü„ÄÇ
* Áî®Êà∑ÁêÜËß£Âπ∂ÂêåÊÑèÔºå‰ªª‰ΩïËøùÂèçÊ≥ïÂæãÊ≥ïËßÑ„ÄÅ‰æµÁäØ‰ªñ‰∫∫ÂêàÊ≥ïÊùÉÁõäÁöÑË°å‰∏∫ÔºåÂùá‰∏éÊú¨È°πÁõÆÂèäÂÖ∂ÂºÄÂèëËÄÖÊó†ÂÖ≥ÔºåÂêéÊûúÁî±Áî®Êà∑Ëá™Ë°åÊâøÊãÖ„ÄÇ

2. ‰ΩøÁî®ÊúüÈôê

* ÊÇ®Â∫îËØ•Âú®‰∏ãËΩΩ‰øùÂ≠ò‰ΩøÁî®Êú¨È°πÁõÆÁöÑ24Â∞èÊó∂ÂÜÖÔºåÂà†Èô§Êú¨È°πÁõÆÁöÑÊ∫ê‰ª£Á†ÅÂíåÁ®ãÂ∫èÔºõË∂ÖÂá∫Ê≠§ÊúüÈôêÁöÑ‰ªª‰Ωï‰ΩøÁî®Ë°å‰∏∫Ôºå‰∏ÄÊ¶Ç‰∏éÊú¨È°πÁõÆÂèäÂÖ∂ÂºÄÂèëËÄÖÊó†ÂÖ≥„ÄÇ

3. Êìç‰ΩúËßÑËåÉ

* Êú¨È°πÁõÆ‰ªÖÂÖÅËÆ∏Âú®ÊéàÊùÉÊÉÖÂÜµ‰∏ã‰ΩøÁî®Êï∞ÊçÆËÆ≠ÁªÉÔºå‰∏•Á¶ÅÁî®‰∫éÈùûÊ≥ïÁõÆÁöÑÔºåÂê¶ÂàôËá™Ë°åÊâøÊãÖÊâÄÊúâÁõ∏ÂÖ≥Ë¥£‰ªªÔºõÁî®Êà∑Â¶ÇÂõ†ËøùÂèçÊ≠§ËßÑÂÆöËÄåÂºïÂèëÁöÑ‰ªª‰ΩïÊ≥ïÂæãË¥£‰ªªÔºåÂ∞ÜÁî±Áî®Êà∑Ëá™Ë°åÊâøÊãÖÔºå‰∏éÊú¨È°πÁõÆÂèäÂÖ∂ÂºÄÂèëËÄÖÊó†ÂÖ≥„ÄÇ
* ‰∏•Á¶ÅÁî®‰∫éÁ™ÉÂèñ‰ªñ‰∫∫ÈöêÁßÅÔºå‰∏•Á¶ÅÁî®‰∫éÁ™ÉÂèñ‰ªñ‰∫∫ÈöêÁßÅÔºå‰∏•Á¶ÅÁî®‰∫éÁ™ÉÂèñ‰ªñ‰∫∫ÈöêÁßÅÔºåÂê¶ÂàôËá™Ë°åÊâøÊãÖÊâÄÊúâÁõ∏ÂÖ≥Ë¥£‰ªª„ÄÇ

4. ÂÖçË¥£Â£∞ÊòéÊé•Âèó

* ‰∏ãËΩΩ„ÄÅ‰øùÂ≠ò„ÄÅËøõ‰∏ÄÊ≠•ÊµèËßàÊ∫ê‰ª£Á†ÅÊàñËÄÖ‰∏ãËΩΩÂÆâË£Ö„ÄÅÁºñËØë‰ΩøÁî®Êú¨Á®ãÂ∫èÔºåË°®Á§∫‰Ω†ÂêåÊÑèÊú¨Ë≠¶ÂëäÔºåÂπ∂ÊâøËØ∫ÈÅµÂÆàÂÆÉ;

5. Á¶ÅÊ≠¢Áî®‰∫éÈùûÊ≥ïÊµãËØïÊàñÊ∏óÈÄè

* Á¶ÅÊ≠¢Âà©Áî®Êú¨È°πÁõÆÁöÑÁõ∏ÂÖ≥ÊäÄÊúØ‰ªé‰∫ãÈùûÊ≥ïÊµãËØïÊàñÊ∏óÈÄèÔºåÁ¶ÅÊ≠¢Âà©Áî®Êú¨È°πÁõÆÁöÑÁõ∏ÂÖ≥‰ª£Á†ÅÊàñÁõ∏ÂÖ≥ÊäÄÊúØ‰ªé‰∫ã‰ªª‰ΩïÈùûÊ≥ïÂ∑•‰ΩúÔºåÂ¶ÇÂõ†Ê≠§‰∫ßÁîüÁöÑ‰∏ÄÂàá‰∏çËâØÂêéÊûú‰∏éÊú¨È°πÁõÆÂèäÂÖ∂ÂºÄÂèëËÄÖÊó†ÂÖ≥„ÄÇ
* ‰ªª‰ΩïÂõ†Ê≠§‰∫ßÁîüÁöÑ‰∏çËâØÂêéÊûúÔºåÂåÖÊã¨‰ΩÜ‰∏çÈôê‰∫éÊï∞ÊçÆÊ≥ÑÈú≤„ÄÅÁ≥ªÁªüÁò´Áó™„ÄÅ‰æµÁäØÈöêÁßÅÁ≠âÔºåÂùá‰∏éÊú¨È°πÁõÆÂèäÂÖ∂ÂºÄÂèëËÄÖÊó†ÂÖ≥ÔºåË¥£‰ªªÁî±Áî®Êà∑Ëá™Ë°åÊâøÊãÖ„ÄÇ

6. ÂÖçË¥£Â£∞Êòé‰øÆÊîπ

* Êú¨ÂÖçË¥£Â£∞ÊòéÂèØËÉΩÊ†πÊçÆÈ°πÁõÆËøêË°åÊÉÖÂÜµÂíåÊ≥ïÂæãÊ≥ïËßÑÁöÑÂèòÂåñËøõË°å‰øÆÊîπÂíåË∞ÉÊï¥„ÄÇÁî®Êà∑Â∫îÂÆöÊúüÊü•ÈòÖÊú¨È°µÈù¢‰ª•Ëé∑ÂèñÊúÄÊñ∞ÁâàÊú¨ÁöÑÂÖçË¥£Â£∞ÊòéÔºå‰ΩøÁî®Êú¨È°πÁõÆÊó∂Â∫îÈÅµÂÆàÊúÄÊñ∞ÁâàÊú¨ÁöÑÂÖçË¥£Â£∞Êòé„ÄÇ

7. ÂÖ∂‰ªñ

* Èô§Êú¨ÂÖçË¥£Â£∞ÊòéËßÑÂÆöÂ§ñÔºåÁî®Êà∑Âú®‰ΩøÁî®Êú¨È°πÁõÆËøáÁ®ã‰∏≠Â∫îÈÅµÂÆàÁõ∏ÂÖ≥ÁöÑÊ≥ïÂæãÊ≥ïËßÑÂíåÈÅìÂæ∑ËßÑËåÉ„ÄÇÂØπ‰∫éÂõ†Áî®Êà∑ËøùÂèçÁõ∏ÂÖ≥ËßÑÂÆöËÄåÂºïÂèëÁöÑ‰ªª‰ΩïÁ∫†Á∫∑ÊàñÊçüÂ§±ÔºåÊú¨È°πÁõÆÂèäÂÖ∂ÂºÄÂèëËÄÖ‰∏çÊâøÊãÖ‰ªª‰ΩïË¥£‰ªª„ÄÇ

* ËØ∑Áî®Êà∑ÊÖéÈáçÈòÖËØªÂπ∂ÁêÜËß£Êú¨ÂÖçË¥£Â£∞ÊòéÁöÑÊâÄÊúâÂÜÖÂÆπÔºåÁ°Æ‰øùÂú®‰ΩøÁî®Êú¨È°πÁõÆÊó∂‰∏•Ê†ºÈÅµÂÆàÁõ∏ÂÖ≥ËßÑÂÆö„ÄÇ

&lt;/details&gt;
ËØ∑Áî®Êà∑ÊÖéÈáçÈòÖËØªÂπ∂ÁêÜËß£Êú¨ÂÖçË¥£Â£∞ÊòéÁöÑÊâÄÊúâÂÜÖÂÆπÔºåÁ°Æ‰øùÂú®‰ΩøÁî®Êú¨È°πÁõÆÊó∂‰∏•Ê†ºÈÅµÂÆàÁõ∏ÂÖ≥ËßÑÂÆö„ÄÇ

&lt;br&gt;  
&lt;br&gt;  
&lt;br&gt;  

## ‚≠ê Star History
&gt; [!TIP] 
&gt; Â¶ÇÊûúÊú¨È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåÊàñËÄÖÊÇ®ÂÖ≥Ê≥®Êú¨È°πÁõÆÁöÑÊú™Êù•ÂèëÂ±ïÔºåËØ∑ÁªôÈ°πÁõÆ StarÔºåË∞¢Ë∞¢ 

&lt;div align=&quot;center&quot;&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=xming521/WeClone&amp;type=Date)](https://www.star-history.com/#xming521/WeClone&amp;Date)

&lt;/div&gt;


&lt;div align=&quot;center&quot;&gt; ÂÖãÈöÜÊàë‰ª¨Ôºå‰øùÁïôÁÅµÈ≠ÇÁöÑËä¨Ëä≥ &lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[xaoyaoo/PyWxDump]]></title>
            <link>https://github.com/xaoyaoo/PyWxDump</link>
            <guid>https://github.com/xaoyaoo/PyWxDump</guid>
            <pubDate>Thu, 15 May 2025 00:04:29 GMT</pubDate>
            <description><![CDATA[Ëé∑ÂèñÂæÆ‰ø°‰ø°ÊÅØÔºõËØªÂèñÊï∞ÊçÆÂ∫ìÔºåÊú¨Âú∞Êü•ÁúãËÅäÂ§©ËÆ∞ÂΩïÂπ∂ÂØºÂá∫‰∏∫csv„ÄÅhtmlÁ≠âÊ†ºÂºèÁî®‰∫éAIËÆ≠ÁªÉÔºåËá™Âä®ÂõûÂ§çÁ≠â„ÄÇÊîØÊåÅÂ§öË¥¶Êà∑‰ø°ÊÅØËé∑ÂèñÔºåÊîØÊåÅÊâÄÊúâÂæÆ‰ø°ÁâàÊú¨„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xaoyaoo/PyWxDump">xaoyaoo/PyWxDump</a></h1>
            <p>Ëé∑ÂèñÂæÆ‰ø°‰ø°ÊÅØÔºõËØªÂèñÊï∞ÊçÆÂ∫ìÔºåÊú¨Âú∞Êü•ÁúãËÅäÂ§©ËÆ∞ÂΩïÂπ∂ÂØºÂá∫‰∏∫csv„ÄÅhtmlÁ≠âÊ†ºÂºèÁî®‰∫éAIËÆ≠ÁªÉÔºåËá™Âä®ÂõûÂ§çÁ≠â„ÄÇÊîØÊåÅÂ§öË¥¶Êà∑‰ø°ÊÅØËé∑ÂèñÔºåÊîØÊåÅÊâÄÊúâÂæÆ‰ø°ÁâàÊú¨„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 7,692</p>
            <p>Forks: 1,215</p>
            <p>Stars today: 141 stars today</p>
            <h2>README</h2><pre>[![‰∏≠Êñá](https://img.shields.io/badge/README-‰∏≠Êñá-494cad.svg)](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/README_CN.md) [![English](https://img.shields.io/badge/README-English-494cad.svg)](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/README_EN.md)

# &lt;center&gt;PyWxDump&lt;/center&gt;

[![Python](https://img.shields.io/badge/Python-3-blue.svg)](https://www.python.org/)
[![GitHub code size in bytes](https://img.shields.io/github/languages/code-size/xaoyaoo/pywxdump)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub all releases](https://img.shields.io/github/downloads/xaoyaoo/pywxdump/total)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub stars](https://img.shields.io/github/stars/xaoyaoo/PyWxDump.svg)](https://github.com/xaoyaoo/PyWxDump)
[![GitHub forks](https://img.shields.io/github/forks/xaoyaoo/PyWxDump.svg)](https://github.com/xaoyaoo/PyWxDump/fork)
[![GitHub issues](https://img.shields.io/github/issues/xaoyaoo/PyWxDump)](https://github.com/xaoyaoo/PyWxDump/issues)

[![PyPI](https://img.shields.io/pypi/v/pywxdump)](https://pypi.org/project/pywxdump/)
[![Wheel](https://img.shields.io/pypi/wheel/pywxdump)](https://pypi.org/project/pywxdump/)
[![PyPI-Downloads](https://img.shields.io/pypi/dm/pywxdump)](https://pypistats.org/packages/pywxdump)
[![GitHub license](https://img.shields.io/pypi/l/pywxdump)](https://github.com/xaoyaoo/PyWxDump/blob/master/LICENSE)

* Welcome to provide more ideas or code to improve this project together.

### If you are a novice, please pay attention to the Official Accounts: `ÈÄçÈÅ•‰πãËäØ` (the QR code is below), and reply: `PyWxDump` to get a picture text tutorial.

### If you have any questions, please check first: [FAQ](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/FAQ.md) Whether there is an answer, or follow the Official Accounts to reply: `FAQ`.

QQ GROUPÔºö[276392799](https://s.xaoyo.top/gOLUDl) or [276392799](https://s.xaoyo.top/bgNcRa)ÔºàPASSWORD,please read:[UserGuide.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/UserGuide.md)Ôºâ.

&lt;div&gt;
  &lt;img align=&quot;&quot; width=&quot;200&quot;  src=&quot;https://github.com/xaoyaoo/PyWxDump/blob/master/doc/img/qrcode_gh.jpg&quot; alt=&quot;the Official Accounts&quot; title=&quot;the Official Accounts&quot; height=&quot;200&quot;/&gt;
&lt;/div&gt;

# I. Project Introduction

## 1. Brief Introduction

[PyWxDump](https://github.com/xaoyaoo/PyWxDump) is a tool for obtaining wx account information (nicknames/accounts/phones/emails/database keys), decrypting databases, viewing wx chat, and exporting chat as html backups.

* &lt;strong&gt;&lt;big&gt;Super eager for stars, if you&#039;ve come across this project, please give me a [![Star](https://img.shields.io/github/stars/xaoyaoo/PyWxDump.svg?style=social&amp;label=Star)](https://github.com/xaoyaoo/PyWxDump/)! Thank you so much~ &lt;/big&gt;&lt;/strong&gt;

## 2. Feature

#### 2.1 Core

* (1) Get the **base address offset** of WeChat nickname, WeChat account, WeChat phone number, WeChat email, and WeChat KEY
* (2) Get the WeChat nickname, WeChat account, WeChat phone number, WeChat email, WeChat KEY, WeChat original ID (wxid_******), and WeChat folder path of the currently logged-in WeChat
* (3) Decrypt WeChat database based on key
* (4) Combine multiple types of databases for unified viewing

#### 2.2 Extend Function

* (1) View chat history through the web
* (2) Support exporting chat logs as html, csv, and backing up WeChat chat logs
* (3) Remote viewing of WeChat chat history (must be network accessible, such as a local area network)

#### 2.3 Document Class

* (1) Provide descriptions of some fields in the database
* (2) Provide CE to obtain the base address offset method
* (3) Provide a decryption method for MAC database

#### 2.4 Other functions

* (1) Added a minimalist version of [pywxdumpmini](https://github.com/xaoyaoo/pywxdumpmini), which provides only the ability to obtain database keys and database locations
* (2) Support multiple WeChat opening scenarios, obtain multiple user information, etc.

**Utilize the scene**

1. Network security...
2. Daily backup archiving
3. View chat history remotely (view chat history through the web)
4. Wait...............

## 3. Update plan

* 1.Analyze chat logs of each person and generate word clouds.
* ~~2.Analyze the number of chats per person per day and generate a line chart (day-number of chats)~~
* ~~3.Analyze the monthly and annual chat volume of different people and generate a line chart~~
* ~~4.Generate annual visualization reports~~
* 8.Increase support for enterprise WeChat
* 12.Viewing and backing up of the circle of friends
* ~~13.Clean up WeChat storage space and reduce the space occupied by WeChat (hopefully by selecting a person or group and finding out the media files involved in the chat logs of this group, such as pictures, videos, files, voice recordings, etc., and selectively (such as time periods) or batch-wise clearing them from the computer&#039;s cache by group conversation.)~~
* 14.Automatically send messages to specified people through UI control

## 4. Other

[PyWxDump](https://github.com/xaoyaoo/PyWxDump) is a refactored python language version of [SharpWxDump](https://github.com/AdminTest0/SharpWxDump), with many new features added.

* Project address: https://github.com/xaoyaoo/PyWxDump
* Currently tested only under Windows, there may be issues under mac and Linux.
* If you find any missing or incorrect information, bugs, or suggestions for improvement in the [WX_OFFS.json](https://github.com/xaoyaoo/PyWxDump/tree/master/pywxdump/WX_OFFS.json), please submit an issue on GitHub.
* For common issues, please refer to [FAQ](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/FAQ.md), and for the update log, please refer to [CHANGELOG](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/CHANGELOG.md)
* Web UI repository location [wxdump_web](https://github.com/xaoyaoo/wxdump_web )
* If you are interested in the implementation principle of wxdump, please pay attention to the Official Accounts: `ÈÄçÈÅ•‰πãËäØ`, reply: `ÂéüÁêÜ` to get the principle analysis.
* [:sparkling\_heart: Support Me]( https://github.com/xaoyaoo/xaoyaoo/blob/main/donate.md)

## 5. Star History

&lt;details&gt;
&lt;summary&gt;click to expand&lt;/summary&gt;

[![Star History Chart](https://api.star-history.com/svg?repos=xaoyaoo/pywxdump&amp;type=Date)](https://star-history.com/#xaoyaoo/pywxdump&amp;Date)

&lt;/details&gt;

# ‚Ö°. Instructions For Use

* Detailed instructions, see: [UserGuide.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/UserGuide.md)

* the minimalist version, see: [pywxdumpmini](https://github.com/xaoyaoo/pywxdumpmini)

* If you want to modify the UI, clone the [wx_dump_web](https://github.com/xaoyaoo/wxdump_web) and modify it as needed (the UI is developed using VUE+ElementUI)

„Äênote„Äë:

* For obtaining the base address using cheat engine, refer to [CE obtaining base address.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/CEËé∑ÂèñÂü∫ÂùÄ.md)
  (This method can be replaced by the `wxdump bias` command, and is only used for learning principles.)
* For database parsing, refer to [wx database brief.md](https://github.com/xaoyaoo/PyWxDump/tree/master/doc/wxÊï∞ÊçÆÂ∫ìÁÆÄËø∞.md)

# ‚Ö¢. Disclaimer (VERY VERY VERY IMPORTANT ! ! ! ! ! !)

### 1. Purpose of use

* This project is only for learning and communication purposes, **please do not use it for illegal purposes**, **please do not use it for illegal purposes**, **please do not use it for illegal purposes**, otherwise the consequences will be borne by yourself.
* Users understand and agree that any violation of laws and regulations, infringement of the legitimate rights and interests of others, is unrelated to this project and its developers, and the consequences are borne by the user themselves.

### 2. Usage Period

* You should delete the source code and (compiled) program of this project within 24 hours of downloading, saving, compiling, and using it; any use beyond this period is not related to this project or its developer.

### 3. Operation specifications

* This project only allows backup and viewing of the database under authorization. It is strictly prohibited for illegal purposes, otherwise all related responsibilities will be borne by the user. Any legal liability incurred by the user due to violation of this regulation will be borne by the user, and is unrelated to this project and its developer.
* It is strictly prohibited to use it to steal others&#039; privacy. Otherwise, all relevant responsibilities shall be borne by yourself.
* It is strictly prohibited to conduct secondary development, otherwise all related responsibilities shall be borne by yourself.

### 4. Acceptance of Disclaimer

* Downloading, saving, further browsing the source code, or downloading, installing, compiling, and using this program indicates that you agree with this warning and promise to abide by it;

### 5. Forbidden for illegal testing or penetration

* It is prohibited to use the relevant technologies of this project to engage in illegal testing or penetration, and it is prohibited to use the relevant codes or related technologies of this project to engage in any illegal work. Any adverse consequences arising therefrom are not related to this project and its developers.
* Any resulting adverse consequences, including but not limited to data leakage, system failure, and privacy infringement, are not related to this project or its developers and are the responsibility of the user.

### 6. Modification of disclaimer

* This disclaimer may be modified and adjusted based on the project&#039;s operating conditions and changes in laws and regulations. Users should regularly check this page for the latest version of the disclaimer, and should comply with the latest version of the disclaimer when using this project.

### 7. Others

* In addition to the provisions of this disclaimer, users should comply with relevant laws, regulations, and ethical norms during the use of this project. The project and its developers will not be held responsible for any disputes or losses caused by users&#039; violation of relevant regulations.

* Users are requested to carefully read and understand all contents of this disclaimer, and ensure that they strictly comply with relevant regulations when using this project.

# ‚Ö£. Acknowledgments

[![PyWxDump CONTRIBUTORS](https://contrib.rocks/image?repo=xaoyaoo/PyWxDump)](https://github.com/xaoyaoo/PyWxDump/graphs/contributors)  

UI CONTRIBUTORS:    

[![UI CONTRIBUTORS](https://contrib.rocks/image?repo=xaoyaoo/wxdump_web)](https://github.com/xaoyaoo/wxdump_web/graphs/contributors)

otherContributors:

[643104191](https://github.com/643104191) (add [ctypes_utils](https://github.com/xaoyaoo/PyWxDump/blob/9e3e4cb5aec2b9b445c8283d61c58863f4129c6e/pywxdump/wx_info/ctypes_utils.py), Accelerated the acquisition of wxinfo; [9e3e4cb](https://github.com/xaoyaoo/PyWxDump/commit/9e3e4cb5aec2b9b445c8283d61c58863f4129c6e))

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[browser-use/web-ui]]></title>
            <link>https://github.com/browser-use/web-ui</link>
            <guid>https://github.com/browser-use/web-ui</guid>
            <pubDate>Thu, 15 May 2025 00:04:28 GMT</pubDate>
            <description><![CDATA[Run AI Agent in your browser.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/browser-use/web-ui">browser-use/web-ui</a></h1>
            <p>Run AI Agent in your browser.</p>
            <p>Language: Python</p>
            <p>Stars: 13,014</p>
            <p>Forks: 2,155</p>
            <p>Stars today: 33 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;./assets/web-ui.png&quot; alt=&quot;Browser Use Web UI&quot; width=&quot;full&quot;/&gt;

&lt;br/&gt;

[![GitHub stars](https://img.shields.io/github/stars/browser-use/web-ui?style=social)](https://github.com/browser-use/web-ui/stargazers)
[![Discord](https://img.shields.io/discord/1303749220842340412?color=7289DA&amp;label=Discord&amp;logo=discord&amp;logoColor=white)](https://link.browser-use.com/discord)
[![Documentation](https://img.shields.io/badge/Documentation-üìï-blue)](https://docs.browser-use.com)
[![WarmShao](https://img.shields.io/twitter/follow/warmshao?style=social)](https://x.com/warmshao)

This project builds upon the foundation of the [browser-use](https://github.com/browser-use/browser-use), which is designed to make websites accessible for AI agents.

We would like to officially thank [WarmShao](https://github.com/warmshao) for his contribution to this project.

**WebUI:** is built on Gradio and supports most of `browser-use` functionalities. This UI is designed to be user-friendly and enables easy interaction with the browser agent.

**Expanded LLM Support:** We&#039;ve integrated support for various Large Language Models (LLMs), including: Google, OpenAI, Azure OpenAI, Anthropic, DeepSeek, Ollama etc. And we plan to add support for even more models in the future.

**Custom Browser Support:** You can use your own browser with our tool, eliminating the need to re-login to sites or deal with other authentication challenges. This feature also supports high-definition screen recording.

**Persistent Browser Sessions:** You can choose to keep the browser window open between AI tasks, allowing you to see the complete history and state of AI interactions.

&lt;video src=&quot;https://github.com/user-attachments/assets/56bc7080-f2e3-4367-af22-6bf2245ff6cb&quot; controls=&quot;controls&quot;&gt;Your browser does not support playing this video!&lt;/video&gt;

## Installation Guide

### Option 1: Local Installation

Read the [quickstart guide](https://docs.browser-use.com/quickstart#prepare-the-environment) or follow the steps below to get started.

#### Step 1: Clone the Repository
```bash
git clone https://github.com/browser-use/web-ui.git
cd web-ui
```

#### Step 2: Set Up Python Environment
We recommend using [uv](https://docs.astral.sh/uv/) for managing the Python environment.

Using uv (recommended):
```bash
uv venv --python 3.11
```

Activate the virtual environment:
- Windows (Command Prompt):
```cmd
.venv\Scripts\activate
```
- Windows (PowerShell):
```powershell
.\.venv\Scripts\Activate.ps1
```
- macOS/Linux:
```bash
source .venv/bin/activate
```

#### Step 3: Install Dependencies
Install Python packages:
```bash
uv pip install -r requirements.txt
```

Install Browsers in Patchright. 
```bash
patchright install --with-deps
```
Or you can install specific browsers by running:
```bash
patchright install chromium --with-deps
```

#### Step 4: Configure Environment
1. Create a copy of the example environment file:
- Windows (Command Prompt):
```bash
copy .env.example .env
```
- macOS/Linux/Windows (PowerShell):
```bash
cp .env.example .env
```
2. Open `.env` in your preferred text editor and add your API keys and other settings

#### Step 5: Enjoy the web-ui
1.  **Run the WebUI:**
    ```bash
    python webui.py --ip 127.0.0.1 --port 7788
    ```
2. **Access the WebUI:** Open your web browser and navigate to `http://127.0.0.1:7788`.
3. **Using Your Own Browser(Optional):**
    - Set `BROWSER_PATH` to the executable path of your browser and `BROWSER_USER_DATA` to the user data directory of your browser. Leave `BROWSER_USER_DATA` empty if you want to use local user data.
      - Windows
        ```env
         BROWSER_PATH=&quot;C:\Program Files\Google\Chrome\Application\chrome.exe&quot;
         BROWSER_USER_DATA=&quot;C:\Users\YourUsername\AppData\Local\Google\Chrome\User Data&quot;
        ```
        &gt; Note: Replace `YourUsername` with your actual Windows username for Windows systems.
      - Mac
        ```env
         BROWSER_PATH=&quot;/Applications/Google Chrome.app/Contents/MacOS/Google Chrome&quot;
         BROWSER_USER_DATA=&quot;/Users/YourUsername/Library/Application Support/Google/Chrome&quot;
        ```
    - Close all Chrome windows
    - Open the WebUI in a non-Chrome browser, such as Firefox or Edge. This is important because the persistent browser context will use the Chrome data when running the agent.
    - Check the &quot;Use Own Browser&quot; option within the Browser Settings.

### Option 2: Docker Installation

#### Prerequisites
- Docker and Docker Compose installed
  - [Docker Desktop](https://www.docker.com/products/docker-desktop/) (For Windows/macOS)
  - [Docker Engine](https://docs.docker.com/engine/install/) and [Docker Compose](https://docs.docker.com/compose/install/) (For Linux)

#### Step 1: Clone the Repository
```bash
git clone https://github.com/browser-use/web-ui.git
cd web-ui
```

#### Step 2: Configure Environment
1. Create a copy of the example environment file:
- Windows (Command Prompt):
```bash
copy .env.example .env
```
- macOS/Linux/Windows (PowerShell):
```bash
cp .env.example .env
```
2. Open `.env` in your preferred text editor and add your API keys and other settings

#### Step 3: Docker Build and Run
```bash
docker compose up --build
```
For ARM64 systems (e.g., Apple Silicon Macs), please run follow command:
```bash
TARGETPLATFORM=linux/arm64 docker compose up --build
```

#### Step 4: Enjoy the web-ui and vnc
- Web-UI: Open `http://localhost:7788` in your browser
- VNC Viewer (for watching browser interactions): Open `http://localhost:6080/vnc.html`
  - Default VNC password: &quot;youvncpassword&quot;
  - Can be changed by setting `VNC_PASSWORD` in your `.env` file

## Changelog
- [x] **2025/01/26:** Thanks to @vvincent1234. Now browser-use-webui can combine with DeepSeek-r1 to engage in deep thinking!
- [x] **2025/01/10:** Thanks to @casistack. Now we have Docker Setup option and also Support keep browser open between tasks.[Video tutorial demo](https://github.com/browser-use/web-ui/issues/1#issuecomment-2582511750).
- [x] **2025/01/06:** Thanks to @richard-devbot. A New and Well-Designed WebUI is released. [Video tutorial demo](https://github.com/warmshao/browser-use-webui/issues/1#issuecomment-2573393113).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[microsoft/markitdown]]></title>
            <link>https://github.com/microsoft/markitdown</link>
            <guid>https://github.com/microsoft/markitdown</guid>
            <pubDate>Thu, 15 May 2025 00:04:27 GMT</pubDate>
            <description><![CDATA[Python tool for converting files and office documents to Markdown.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/markitdown">microsoft/markitdown</a></h1>
            <p>Python tool for converting files and office documents to Markdown.</p>
            <p>Language: Python</p>
            <p>Stars: 57,029</p>
            <p>Forks: 2,907</p>
            <p>Stars today: 202 stars today</p>
            <h2>README</h2><pre># MarkItDown

[![PyPI](https://img.shields.io/pypi/v/markitdown.svg)](https://pypi.org/project/markitdown/)
![PyPI - Downloads](https://img.shields.io/pypi/dd/markitdown)
[![Built by AutoGen Team](https://img.shields.io/badge/Built%20by-AutoGen%20Team-blue)](https://github.com/microsoft/autogen)

&gt; [!TIP]
&gt; MarkItDown now offers an MCP (Model Context Protocol) server for integration with LLM applications like Claude Desktop. See [markitdown-mcp](https://github.com/microsoft/markitdown/tree/main/packages/markitdown-mcp) for more information.

&gt; [!IMPORTANT]
&gt; Breaking changes between 0.0.1 to 0.1.0:
&gt; * Dependencies are now organized into optional feature-groups (further details below). Use `pip install &#039;markitdown[all]&#039;` to have backward-compatible behavior. 
&gt; * convert\_stream() now requires a binary file-like object (e.g., a file opened in binary mode, or an io.BytesIO object). This is a breaking change from the previous version, where it previously also accepted text file-like objects, like io.StringIO.
&gt; * The DocumentConverter class interface has changed to read from file-like streams rather than file paths. *No temporary files are created anymore*. If you are the maintainer of a plugin, or custom DocumentConverter, you likely need to update your code. Otherwise, if only using the MarkItDown class or CLI (as in these examples), you should not need to change anything.

MarkItDown is a lightweight Python utility for converting various files to Markdown for use with LLMs and related text analysis pipelines. To this end, it is most comparable to [textract](https://github.com/deanmalmgren/textract), but with a focus on preserving important document structure and content as Markdown (including: headings, lists, tables, links, etc.) While the output is often reasonably presentable and human-friendly, it is meant to be consumed by text analysis tools -- and may not be the best option for high-fidelity document conversions for human consumption.

At present, MarkItDown supports:

- PDF
- PowerPoint
- Word
- Excel
- Images (EXIF metadata and OCR)
- Audio (EXIF metadata and speech transcription)
- HTML
- Text-based formats (CSV, JSON, XML)
- ZIP files (iterates over contents)
- Youtube URLs
- EPubs
- ... and more!

## Why Markdown?

Markdown is extremely close to plain text, with minimal markup or formatting, but still
provides a way to represent important document structure. Mainstream LLMs, such as
OpenAI&#039;s GPT-4o, natively &quot;_speak_&quot; Markdown, and often incorporate Markdown into their
responses unprompted. This suggests that they have been trained on vast amounts of
Markdown-formatted text, and understand it well. As a side benefit, Markdown conventions
are also highly token-efficient.

## Installation

To install MarkItDown, use pip: `pip install &#039;markitdown[all]&#039;`. Alternatively, you can install it from the source:

```bash
git clone git@github.com:microsoft/markitdown.git
cd markitdown
pip install -e &#039;packages/markitdown[all]&#039;
```

## Usage

### Command-Line

```bash
markitdown path-to-file.pdf &gt; document.md
```

Or use `-o` to specify the output file:

```bash
markitdown path-to-file.pdf -o document.md
```

You can also pipe content:

```bash
cat path-to-file.pdf | markitdown
```

### Optional Dependencies
MarkItDown has optional dependencies for activating various file formats. Earlier in this document, we installed all optional dependencies with the `[all]` option. However, you can also install them individually for more control. For example:

```bash
pip install &#039;markitdown[pdf, docx, pptx]&#039;
```

will install only the dependencies for PDF, DOCX, and PPTX files.

At the moment, the following optional dependencies are available:

* `[all]` Installs all optional dependencies
* `[pptx]` Installs dependencies for PowerPoint files
* `[docx]` Installs dependencies for Word files
* `[xlsx]` Installs dependencies for Excel files
* `[xls]` Installs dependencies for older Excel files
* `[pdf]` Installs dependencies for PDF files
* `[outlook]` Installs dependencies for Outlook messages
* `[az-doc-intel]` Installs dependencies for Azure Document Intelligence
* `[audio-transcription]` Installs dependencies for audio transcription of wav and mp3 files
* `[youtube-transcription]` Installs dependencies for fetching YouTube video transcription

### Plugins

MarkItDown also supports 3rd-party plugins. Plugins are disabled by default. To list installed plugins:

```bash
markitdown --list-plugins
```

To enable plugins use:

```bash
markitdown --use-plugins path-to-file.pdf
```

To find available plugins, search GitHub for the hashtag `#markitdown-plugin`. To develop a plugin, see `packages/markitdown-sample-plugin`.

### Azure Document Intelligence

To use Microsoft Document Intelligence for conversion:

```bash
markitdown path-to-file.pdf -o document.md -d -e &quot;&lt;document_intelligence_endpoint&gt;&quot;
```

More information about how to set up an Azure Document Intelligence Resource can be found [here](https://learn.microsoft.com/en-us/azure/ai-services/document-intelligence/how-to-guides/create-document-intelligence-resource?view=doc-intel-4.0.0)

### Python API

Basic usage in Python:

```python
from markitdown import MarkItDown

md = MarkItDown(enable_plugins=False) # Set to True to enable plugins
result = md.convert(&quot;test.xlsx&quot;)
print(result.text_content)
```

Document Intelligence conversion in Python:

```python
from markitdown import MarkItDown

md = MarkItDown(docintel_endpoint=&quot;&lt;document_intelligence_endpoint&gt;&quot;)
result = md.convert(&quot;test.pdf&quot;)
print(result.text_content)
```

To use Large Language Models for image descriptions, provide `llm_client` and `llm_model`:

```python
from markitdown import MarkItDown
from openai import OpenAI

client = OpenAI()
md = MarkItDown(llm_client=client, llm_model=&quot;gpt-4o&quot;)
result = md.convert(&quot;example.jpg&quot;)
print(result.text_content)
```

### Docker

```sh
docker build -t markitdown:latest .
docker run --rm -i markitdown:latest &lt; ~/your-file.pdf &gt; output.md
```

## Contributing

This project welcomes contributions and suggestions. Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.

When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

### How to Contribute

You can help by looking at issues or helping review PRs. Any issue or PR is welcome, but we have also marked some as &#039;open for contribution&#039; and &#039;open for reviewing&#039; to help facilitate community contributions. These are ofcourse just suggestions and you are welcome to contribute in any way you like.

&lt;div align=&quot;center&quot;&gt;

|            | All                                                          | Especially Needs Help from Community                                                                                                      |
| ---------- | ------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------- |
| **Issues** | [All Issues](https://github.com/microsoft/markitdown/issues) | [Issues open for contribution](https://github.com/microsoft/markitdown/issues?q=is%3Aissue+is%3Aopen+label%3A%22open+for+contribution%22) |
| **PRs**    | [All PRs](https://github.com/microsoft/markitdown/pulls)     | [PRs open for reviewing](https://github.com/microsoft/markitdown/pulls?q=is%3Apr+is%3Aopen+label%3A%22open+for+reviewing%22)              |

&lt;/div&gt;

### Running Tests and Checks

- Navigate to the MarkItDown package:

  ```sh
  cd packages/markitdown
  ```

- Install `hatch` in your environment and run tests:

  ```sh
  pip install hatch  # Other ways of installing hatch: https://hatch.pypa.io/dev/install/
  hatch shell
  hatch test
  ```

  (Alternative) Use the Devcontainer which has all the dependencies installed:

  ```sh
  # Reopen the project in Devcontainer and run:
  hatch test
  ```

- Run pre-commit checks before submitting a PR: `pre-commit run --all-files`

### Contributing 3rd-party Plugins

You can also contribute by creating and sharing 3rd party plugins. See `packages/markitdown-sample-plugin` for more details.

## Trademarks

This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
[Microsoft&#039;s Trademark &amp; Brand Guidelines](https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general).
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party&#039;s policies.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[reflex-dev/reflex]]></title>
            <link>https://github.com/reflex-dev/reflex</link>
            <guid>https://github.com/reflex-dev/reflex</guid>
            <pubDate>Thu, 15 May 2025 00:04:26 GMT</pubDate>
            <description><![CDATA[üï∏Ô∏è Web apps in pure Python üêç]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/reflex-dev/reflex">reflex-dev/reflex</a></h1>
            <p>üï∏Ô∏è Web apps in pure Python üêç</p>
            <p>Language: Python</p>
            <p>Stars: 22,706</p>
            <p>Forks: 1,336</p>
            <p>Stars today: 39 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/reflex_dark.svg#gh-light-mode-only&quot; alt=&quot;Reflex Logo&quot; width=&quot;300px&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/reflex_light.svg#gh-dark-mode-only&quot; alt=&quot;Reflex Logo&quot; width=&quot;300px&quot;&gt;

&lt;hr&gt;

### **‚ú® Performant, customizable web apps in pure Python. Deploy in seconds. ‚ú®**

[![PyPI version](https://badge.fury.io/py/reflex.svg)](https://badge.fury.io/py/reflex)
![versions](https://img.shields.io/pypi/pyversions/reflex.svg)
[![Documentation](https://img.shields.io/badge/Documentation%20-Introduction%20-%20%23007ec6)](https://reflex.dev/docs/getting-started/introduction)
[![PyPI Downloads](https://static.pepy.tech/badge/reflex)](https://pepy.tech/projects/reflex)
[![Discord](https://img.shields.io/discord/1029853095527727165?color=%237289da&amp;label=Discord)](https://discord.gg/T5WSbC2YtQ)

&lt;/div&gt;

---

[English](https://github.com/reflex-dev/reflex/blob/main/README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](https://github.com/reflex-dev/reflex/blob/main/docs/zh/zh_cn/README.md) | [ÁπÅÈ´î‰∏≠Êñá](https://github.com/reflex-dev/reflex/blob/main/docs/zh/zh_tw/README.md) | [T√ºrk√ße](https://github.com/reflex-dev/reflex/blob/main/docs/tr/README.md) | [‡§π‡§ø‡§Ç‡§¶‡•Ä](https://github.com/reflex-dev/reflex/blob/main/docs/in/README.md) | [Portugu√™s (Brasil)](https://github.com/reflex-dev/reflex/blob/main/docs/pt/pt_br/README.md) | [Italiano](https://github.com/reflex-dev/reflex/blob/main/docs/it/README.md) | [Espa√±ol](https://github.com/reflex-dev/reflex/blob/main/docs/es/README.md) | [ÌïúÍµ≠Ïñ¥](https://github.com/reflex-dev/reflex/blob/main/docs/kr/README.md) | [Êó•Êú¨Ë™û](https://github.com/reflex-dev/reflex/blob/main/docs/ja/README.md) | [Deutsch](https://github.com/reflex-dev/reflex/blob/main/docs/de/README.md) | [Persian (Ÿæÿßÿ±ÿ≥€å)](https://github.com/reflex-dev/reflex/blob/main/docs/pe/README.md) | [Ti·∫øng Vi·ªát](https://github.com/reflex-dev/reflex/blob/main/docs/vi/README.md)

---

# Reflex

Reflex is a library to build full-stack web apps in pure Python.

Key features:

- **Pure Python** - Write your app&#039;s frontend and backend all in Python, no need to learn Javascript.
- **Full Flexibility** - Reflex is easy to get started with, but can also scale to complex apps.
- **Deploy Instantly** - After building, deploy your app with a [single command](https://reflex.dev/docs/hosting/deploy-quick-start/) or host it on your own server.

See our [architecture page](https://reflex.dev/blog/2024-03-21-reflex-architecture/#the-reflex-architecture) to learn how Reflex works under the hood.

## ‚öôÔ∏è Installation

Open a terminal and run (Requires Python 3.10+):

```bash
pip install reflex
```

## ü•≥ Create your first app

Installing `reflex` also installs the `reflex` command line tool.

Test that the install was successful by creating a new project. (Replace `my_app_name` with your project name):

```bash
mkdir my_app_name
cd my_app_name
reflex init
```

This command initializes a template app in your new directory.

You can run this app in development mode:

```bash
reflex run
```

You should see your app running at http://localhost:3000.

Now you can modify the source code in `my_app_name/my_app_name.py`. Reflex has fast refreshes so you can see your changes instantly when you save your code.

## ü´ß Example App

Let&#039;s go over an example: creating an image generation UI around [DALL¬∑E](https://platform.openai.com/docs/guides/images/image-generation?context=node). For simplicity, we just call the [OpenAI API](https://platform.openai.com/docs/api-reference/authentication), but you could replace this with an ML model run locally.

&amp;nbsp;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle.gif&quot; alt=&quot;A frontend wrapper for DALL¬∑E, shown in the process of generating an image.&quot; width=&quot;550&quot; /&gt;
&lt;/div&gt;

&amp;nbsp;

Here is the complete code to create this. This is all done in one Python file!

```python
import reflex as rx
import openai

openai_client = openai.OpenAI()


class State(rx.State):
    &quot;&quot;&quot;The app state.&quot;&quot;&quot;

    prompt = &quot;&quot;
    image_url = &quot;&quot;
    processing = False
    complete = False

    def get_image(self):
        &quot;&quot;&quot;Get the image from the prompt.&quot;&quot;&quot;
        if self.prompt == &quot;&quot;:
            return rx.window_alert(&quot;Prompt Empty&quot;)

        self.processing, self.complete = True, False
        yield
        response = openai_client.images.generate(
            prompt=self.prompt, n=1, size=&quot;1024x1024&quot;
        )
        self.image_url = response.data[0].url
        self.processing, self.complete = False, True


def index():
    return rx.center(
        rx.vstack(
            rx.heading(&quot;DALL-E&quot;, font_size=&quot;1.5em&quot;),
            rx.input(
                placeholder=&quot;Enter a prompt..&quot;,
                on_blur=State.set_prompt,
                width=&quot;25em&quot;,
            ),
            rx.button(
                &quot;Generate Image&quot;,
                on_click=State.get_image,
                width=&quot;25em&quot;,
                loading=State.processing
            ),
            rx.cond(
                State.complete,
                rx.image(src=State.image_url, width=&quot;20em&quot;),
            ),
            align=&quot;center&quot;,
        ),
        width=&quot;100%&quot;,
        height=&quot;100vh&quot;,
    )

# Add state and page to the app.
app = rx.App()
app.add_page(index, title=&quot;Reflex:DALL-E&quot;)
```

## Let&#039;s break this down.

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/reflex-dev/reflex/main/docs/images/dalle_colored_code_example.png&quot; alt=&quot;Explaining the differences between backend and frontend parts of the DALL-E app.&quot; width=&quot;900&quot; /&gt;
&lt;/div&gt;

### **Reflex UI**

Let&#039;s start with the UI.

```python
def index():
    return rx.center(
        ...
    )
```

This `index` function defines the frontend of the app.

We use different components such as `center`, `vstack`, `input`, and `button` to build the frontend. Components can be nested within each other
to create complex layouts. And you can use keyword args to style them with the full power of CSS.

Reflex comes with [60+ built-in components](https://reflex.dev/docs/library) to help you get started. We are actively adding more components, and it&#039;s easy to [create your own components](https://reflex.dev/docs/wrapping-react/overview/).

### **State**

Reflex represents your UI as a function of your state.

```python
class State(rx.State):
    &quot;&quot;&quot;The app state.&quot;&quot;&quot;
    prompt = &quot;&quot;
    image_url = &quot;&quot;
    processing = False
    complete = False

```

The state defines all the variables (called vars) in an app that can change and the functions that change them.

Here the state is comprised of a `prompt` and `image_url`. There are also the booleans `processing` and `complete` to indicate when to disable the button (during image generation) and when to show the resulting image.

### **Event Handlers**

```python
def get_image(self):
    &quot;&quot;&quot;Get the image from the prompt.&quot;&quot;&quot;
    if self.prompt == &quot;&quot;:
        return rx.window_alert(&quot;Prompt Empty&quot;)

    self.processing, self.complete = True, False
    yield
    response = openai_client.images.generate(
        prompt=self.prompt, n=1, size=&quot;1024x1024&quot;
    )
    self.image_url = response.data[0].url
    self.processing, self.complete = False, True
```

Within the state, we define functions called event handlers that change the state vars. Event handlers are the way that we can modify the state in Reflex. They can be called in response to user actions, such as clicking a button or typing in a text box. These actions are called events.

Our DALL¬∑E. app has an event handler, `get_image` to which get this image from the OpenAI API. Using `yield` in the middle of an event handler will cause the UI to update. Otherwise the UI will update at the end of the event handler.

### **Routing**

Finally, we define our app.

```python
app = rx.App()
```

We add a page from the root of the app to the index component. We also add a title that will show up in the page preview/browser tab.

```python
app.add_page(index, title=&quot;DALL-E&quot;)
```

You can create a multi-page app by adding more pages.

## üìë Resources

&lt;div align=&quot;center&quot;&gt;

üìë [Docs](https://reflex.dev/docs/getting-started/introduction) &amp;nbsp; | &amp;nbsp; üóûÔ∏è [Blog](https://reflex.dev/blog) &amp;nbsp; | &amp;nbsp; üì± [Component Library](https://reflex.dev/docs/library) &amp;nbsp; | &amp;nbsp; üñºÔ∏è [Templates](https://reflex.dev/templates/) &amp;nbsp; | &amp;nbsp; üõ∏ [Deployment](https://reflex.dev/docs/hosting/deploy-quick-start) &amp;nbsp;

&lt;/div&gt;

## ‚úÖ Status

Reflex launched in December 2022 with the name Pynecone.

Beginning in 2025, [Reflex Cloud](https://cloud.reflex.dev) has launched to provide the best hosting experience for Reflex apps. We will continue to develop it and implement more features.

Reflex has new releases and features coming every week! Make sure to :star: star and :eyes: watch this repository to stay up to date.

## Contributing

We welcome contributions of any size! Below are some good ways to get started in the Reflex community.

- **Join Our Discord**: Our [Discord](https://discord.gg/T5WSbC2YtQ) is the best place to get help on your Reflex project and to discuss how you can contribute.
- **GitHub Discussions**: A great way to talk about features you want added or things that are confusing/need clarification.
- **GitHub Issues**: [Issues](https://github.com/reflex-dev/reflex/issues) are an excellent way to report bugs. Additionally, you can try and solve an existing issue and submit a PR.

We are actively looking for contributors, no matter your skill level or experience. To contribute check out [CONTRIBUTING.md](https://github.com/reflex-dev/reflex/blob/main/CONTRIBUTING.md)

## All Thanks To Our Contributors:

&lt;a href=&quot;https://github.com/reflex-dev/reflex/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=reflex-dev/reflex&quot; /&gt;
&lt;/a&gt;

## License

Reflex is open-source and licensed under the [Apache License 2.0](https://raw.githubusercontent.com/reflex-dev/reflex/main/LICENSE).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[openai/gpt-2]]></title>
            <link>https://github.com/openai/gpt-2</link>
            <guid>https://github.com/openai/gpt-2</guid>
            <pubDate>Thu, 15 May 2025 00:04:25 GMT</pubDate>
            <description><![CDATA[Code for the paper "Language Models are Unsupervised Multitask Learners"]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/gpt-2">openai/gpt-2</a></h1>
            <p>Code for the paper "Language Models are Unsupervised Multitask Learners"</p>
            <p>Language: Python</p>
            <p>Stars: 23,559</p>
            <p>Forks: 5,660</p>
            <p>Stars today: 55 stars today</p>
            <h2>README</h2><pre>**Status:** Archive (code is provided as-is, no updates expected)

# gpt-2

Code and models from the paper [&quot;Language Models are Unsupervised Multitask Learners&quot;](https://d4mucfpksywv.cloudfront.net/better-language-models/language-models.pdf).

You can read about GPT-2 and its staged release in our [original blog post](https://openai.com/research/better-language-models/), [6 month follow-up post](https://openai.com/blog/gpt-2-6-month-follow-up/), and [final post](https://www.openai.com/blog/gpt-2-1-5b-release/).

We have also [released a dataset](https://github.com/openai/gpt-2-output-dataset) for researchers to study their behaviors.

&lt;sup&gt;*&lt;/sup&gt; *Note that our original parameter counts were wrong due to an error (in our previous blog posts and paper).  Thus you may have seen small referred to as 117M and medium referred to as 345M.*

## Usage

This repository is meant to be a starting point for researchers and engineers to experiment with GPT-2.

For basic information, see our [model card](./model_card.md).

### Some caveats

- GPT-2 models&#039; robustness and worst case behaviors are not well-understood.  As with any machine-learned model, carefully evaluate GPT-2 for your use case, especially if used without fine-tuning or in safety-critical applications where reliability is important.
- The dataset our GPT-2 models were trained on contains many texts with [biases](https://twitter.com/TomerUllman/status/1101485289720242177) and factual inaccuracies, and thus GPT-2 models are likely to be biased and inaccurate as well.
- To avoid having samples mistaken as human-written, we recommend clearly labeling samples as synthetic before wide dissemination.  Our models are often incoherent or inaccurate in subtle ways, which takes more than a quick read for a human to notice.

### Work with us

Please [let us know](mailto:languagequestions@openai.com) if you‚Äôre doing interesting research with or working on applications of GPT-2!  We‚Äôre especially interested in hearing from and potentially working with those who are studying
- Potential malicious use cases and defenses against them (e.g. the detectability of synthetic text)
- The extent of problematic content (e.g. bias) being baked into the models and effective mitigations

## Development

See [DEVELOPERS.md](./DEVELOPERS.md)

## Contributors

See [CONTRIBUTORS.md](./CONTRIBUTORS.md)

## Citation

Please use the following bibtex entry:
```
@article{radford2019language,
  title={Language Models are Unsupervised Multitask Learners},
  author={Radford, Alec and Wu, Jeff and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya},
  year={2019}
}
```

## Future work

We may release code for evaluating the models on various benchmarks.

We are still considering release of the larger models.

## License

[Modified MIT](./LICENSE)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[pirxthepilot/wtfis]]></title>
            <link>https://github.com/pirxthepilot/wtfis</link>
            <guid>https://github.com/pirxthepilot/wtfis</guid>
            <pubDate>Thu, 15 May 2025 00:04:24 GMT</pubDate>
            <description><![CDATA[Passive hostname, domain and IP lookup tool for non-robots]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/pirxthepilot/wtfis">pirxthepilot/wtfis</a></h1>
            <p>Passive hostname, domain and IP lookup tool for non-robots</p>
            <p>Language: Python</p>
            <p>Stars: 1,427</p>
            <p>Forks: 65</p>
            <p>Stars today: 82 stars today</p>
            <h2>README</h2><pre># wtfis

[![Tests](https://github.com/pirxthepilot/wtfis/actions/workflows/tests.yml/badge.svg)](https://github.com/pirxthepilot/wtfis/actions/workflows/tests.yml)
[![PyPI](https://img.shields.io/pypi/v/wtfis?color=blue&amp;logo=pypi&amp;logoColor=gold)](https://pypi.org/project/wtfis/)

Passive hostname, domain and IP lookup tool for non-robots

![](https://github.com/pirxthepilot/wtfis/blob/main/imgs/demo.gif?raw=true)

![](https://github.com/pirxthepilot/wtfis/blob/main/imgs/example-ip.png?raw=true)


## WTF is it?

**wtfis** is a commandline tool that gathers information about a domain, FQDN or IP address using various OSINT services. Unlike other tools of its kind, it&#039;s built specifically for human consumption, providing results that are pretty (YMMV) and easy to read and understand.

This tool assumes that you are using free tier / community level accounts, and so makes as few API calls as possible to minimize hitting quotas and rate limits.

The project name is a play on &quot;whois&quot;.


## Data Sources

| Service | Used in lookup | Required | Free Tier |
| --- | --- | --- | --- |
| [Virustotal](https://virustotal.com) | All | Yes | [Yes](https://www.virustotal.com/gui/join-us) |
| [IP2Whois](https://www.ip2whois.com) | Domain/FQDN | No | [Yes](https://www.ip2location.io/pricing#ip2whois)
| [IPWhois](https://ipwhois.io) | IP address | No | Yes (no signup) |
| [Shodan](https://shodan.io) | IP address | No | [No](https://account.shodan.io/billing) |
| [Greynoise](https://greynoise.io) | IP address | No | [Yes](https://www.greynoise.io/plans/community)
| [URLhaus](https://urlhaus.abuse.ch/) | All | No | Yes (no signup)
| [AbuseIPDB](https://www.abuseipdb.com/)| IP address | No | [Yes](https://www.abuseipdb.com/register?plan=free)

### Virustotal

The primary source of information. Retrieves:

* [Hostname (FQDN), domain or IP](https://developers.virustotal.com/reference/domains-1)
    * Latest analysis stats with vendor detail
    * Reputation score (based on VT community votes)
    * Popularity ranks (Alexa, Cisco Umbrella, etc.) (FQDN and domain only)
    * Categories (assigned by different vendors)
* [Resolutions](https://developers.virustotal.com/reference/domain-resolutions) (FQDN and domain only)
    * Last n IP addresses (default: 3, max: 10)
    * Latest analysis stats of each IP above
* [Whois](https://developers.virustotal.com/reference/whois)
    * Fallback only: if IP2Whois creds are not available
    * Various whois data about the domain itself

### IP2Whois

Optionally used if creds are provided. Retrieves:

* [Whois](https://www.ip2location.io/ip2whois-documentation)
    * Various whois data about the domain itself

IP2Whois is recommended over Virustotal for whois data for a couple of reasons:

* VT whois data format is less consistent
* IP2Whois whois data tends to be of better quality than VT. Also, VT&#039;s registrant data is apparently [anonymized](https://developers.virustotal.com/reference/whois).
* You can save one VT API call by offloading to IP2Whois.

### IPWhois

Default Geolocation and ASN lookup source for IP addresses. Retrieves:

* ASN, Org, ISP and Geolocation

IPWhois should not be confused with IP2Whois, which provides domain Whois data.

### Shodan

GETs data from the `/shodan/host/{ip}` endpoint (see [doc](https://developer.shodan.io/api)). For each IP, retrieves:

* List of open ports and services
* Operating system (if available)
* Tags (assigned by Shodan)

### Greynoise

Using Greynoise&#039;s [community API](https://docs.greynoise.io/docs/using-the-greynoise-community-api), wtfis will show whether an IP is in one of Greynoise&#039;s datasets:

* **Noise**: IP has been seen regularly scanning the Internet
* **RIOT**: IP belongs to a common business application (e.g. Microsoft O365, Google Workspace, Slack)

More information about the datasets [here](https://docs.greynoise.io/docs/understanding-greynoise-data-sets).

In addition, the API also returns Greynoise&#039;s [classification](https://docs.greynoise.io/docs/understanding-greynoise-classifications) of an IP (if available). Possible values are **benign**, **malicious**, and **unknown**.

### URLhaus

[URLhaus](https://urlhaus.abuse.ch/) is a crowd-sourced database of reported malicious URLs. This enrichment provides insight on whether the queried hostname or IP is being or was used for malware distribution via HTTP or HTTPS. Data that is provided include:

* Count of currently online and total malware URLs
* Whether the hostname or IP is currently in the [DNSBL](https://www.dnsbl.info/) and [SURBL](https://www.surbl.org/) public blocklists
* All tags that have been assigned to the URL throughout its history in the URLhaus database

### AbuseIPDB

[AbuseIPDB](https://www.abuseipdb.com/) is a crowd-sourced database of reported malicious IP addresses. Through its API wtfis shows:

* Abuse confidence score (0-100)
* Number of reports


## Install

```
$ pip install wtfis
```

To install via `conda` (from conda-forge), see [wtfis-feedstock](https://github.com/conda-forge/wtfis-feedstock).

To install via [`brew`](https://brew.sh):

```
brew install wtfis
```

## Setup

wtfis uses these environment variables:

* `VT_API_KEY` (required) - Virustotal API key
* `IP2WHOIS_API_KEY` (optional) - IP2WHOIS API key
* `SHODAN_API_KEY` (optional) - Shodan API key
* `GREYNOISE_API_KEY` (optional) - Greynoise API key
* `ABUSEIPDB_API_KEY` (optional) - AbuseIPDB API key
* `WTFIS_DEFAULTS` (optional) - Default arguments

Set these using your own method.

Alternatively, create a file in your home directory `~/.env.wtfis` with the above declarations. See [.env.wtfis.example](./.env.wtfis.example) for a template. **NOTE: Don&#039;t forget to `chmod 400` the file!**


## Usage

```
usage: wtfis [-h] [-m N] [-s] [-g] [-a] [-u] [-n] [-1] [-V] entity

positional arguments:
  entity                Hostname, domain or IP

optional arguments:
  -h, --help            show this help message and exit
  -m N, --max-resolutions N
                        Maximum number of resolutions to show (default: 3)
  -s, --use-shodan      Use Shodan to enrich IPs
  -g, --use-greynoise   Enable Greynoise for IPs
  -a, --use-abuseipdb   Enable AbuseIPDB for IPs
  -u, --use-urlhaus     Enable URLhaus for IPs and domains
  -n, --no-color        Show output without colors
  -1, --one-column      Display results in one column
  -V, --version         Print version number
```

Basically:

```
$ wtfis FQDN_OR_DOMAIN_OR_IP
```

and you will get results organized by panel, similar to the image above.

Defanged input is accepted (e.g. `api[.]google[.]com`).

If the terminal supports it, certain fields and headings are clickable hyperlinks that point to the respective services&#039; websites.

### Shodan

Shodan can be used to show an IP&#039;s open ports or services, and OS in some results. Invoke with the `-s` or `--use-shodan` flag.

![](https://github.com/pirxthepilot/wtfis/blob/main/imgs/example-shodan.png?raw=true)

If supported by the terminal, the `Services` field is a clickable hyperlink that takes you to the Shodan web interface.

### Greynoise

To enable Greynoise, invoke with the `-g` or `--use-greynoise` flag. Because the API quota is quite low (50 requests per week as of March 2023), this lookup is off by default.

![](https://github.com/pirxthepilot/wtfis/blob/main/imgs/example-greynoise.png?raw=true)

The `GreyNoise` field name is also a hyperlink (if terminal-supported) that points to the IP entry in the Greynoise web interface, where more context is shown.

### URLhaus

Use the `-u` or `--use-urlhaus` flag to enable URLhaus enrichment for hostnames, domains and IPs.

![](https://github.com/pirxthepilot/wtfis/blob/main/imgs/example-urlhaus.png?raw=true)

The `Malware URLs` field name is a hyperlink (if terminal-supported) that takes you to the specific URLhaus database page for your query.

### AbuseIPDB

Use the `-a` or `--use-abuseipdb` flag to enable AbuseIPDB enrichment for hostnames, domains and IPs.

![](https://github.com/pirxthepilot/wtfis/blob/main/imgs/example-abuseipdb.png?raw=true)

The `AbuseIPDB` field name is a hyperlink (if terminal-supported) that takes you to the specific AbuseIPDB database page for your query.

### Display options

For FQDN and domain lookups, you can increase or decrease the maximum number of displayed IP resolutions with `-m NUMBER` or `--max-resolutions=NUMBER`. The upper limit is 10. If you don&#039;t need resolutions at all, set the number to `0`.

To show all panels in one column, use the `-1` or `--one-column` flag.

![](https://github.com/pirxthepilot/wtfis/blob/main/imgs/example-one-column.png?raw=true)

Panels can be displayed with no color with `-n` or `--no-color`. 

![](https://github.com/pirxthepilot/wtfis/blob/main/imgs/example-no-color.png?raw=true)

### Defaults

Default arguments can be defined by setting the `WTFIS_DEFAULTS` environment variable. For example, to use shodan and display results in one column by default:

```
WTFIS_DEFAULTS=-s -1
```

If an argument is in `WTFIS_DEFAULTS`, then specifying the same argument during command invocation **negates** that argument. So in the example above, if you then run:

```
$ wtfis example.com -s
```

then Shodan will NOT be used.

Note that maximum resolutions (`-m N, --max-resolutions N`) cannot be defined in defaults at the moment.


## Docker

wtfis can be run from a Docker image. First, build the image (using the included [Dockerfile](./Dockerfile)) by running:

```
$ make docker-image
```

The image will have the latest _tagged_ version (not necessarily from the latest commit) wtfis. This ensures that you are getting a stable release.

Two ways you can run the image:

Ensure `.env.wtfis` is in your home directory and set with the necessary envvars. Then simply run:

```
$ make docker-run
```

This is an alias to

```
$ docker run --env-file=${HOME}/.env.wtfis -it wtfis
```

Note that each definition must NOT have any spaces before and after the equal sign (`FOO=bar`, not `FOO = bar`).

Altenatively, you can set the environment variables yourself, then run, e.g.:

```
$ docker run -e VT_API_KEY -e SHODAN_API_KEY -it wtfis
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Zeyi-Lin/HivisionIDPhotos]]></title>
            <link>https://github.com/Zeyi-Lin/HivisionIDPhotos</link>
            <guid>https://github.com/Zeyi-Lin/HivisionIDPhotos</guid>
            <pubDate>Thu, 15 May 2025 00:04:23 GMT</pubDate>
            <description><![CDATA[‚ö°Ô∏èHivisionIDPhotos: a lightweight and efficient AI ID photos tools. ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑAIËØÅ‰ª∂ÁÖßÂà∂‰ΩúÁÆóÊ≥ï„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Zeyi-Lin/HivisionIDPhotos">Zeyi-Lin/HivisionIDPhotos</a></h1>
            <p>‚ö°Ô∏èHivisionIDPhotos: a lightweight and efficient AI ID photos tools. ‰∏Ä‰∏™ËΩªÈáèÁ∫ßÁöÑAIËØÅ‰ª∂ÁÖßÂà∂‰ΩúÁÆóÊ≥ï„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 16,005</p>
            <p>Forks: 1,730</p>
            <p>Stars today: 60 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img alt=&quot;hivision_logo&quot; src=&quot;assets/hivision_logo.png&quot; width=120 height=120&gt;
&lt;h1&gt;HivisionIDPhoto&lt;/h1&gt;

[English](README_EN.md) / ‰∏≠Êñá / [Êó•Êú¨Ë™û](README_JP.md) / [ÌïúÍµ≠Ïñ¥](README_KO.md)

[![][release-shield]][release-link]
[![][dockerhub-shield]][dockerhub-link]
[![][github-stars-shield]][github-stars-link]
[![][github-issues-shield]][github-issues-link]
[![][github-contributors-shield]][github-contributors-link]
[![][github-forks-shield]][github-forks-link]
[![][license-shield]][license-link]  
[![][wechat-shield]][wechat-link]
[![][spaces-shield]][spaces-link]
[![][swanhub-demo-shield]][swanhub-demo-link]
[![][modelscope-shield]][modelscope-link]
[![][modelers-shield]][modelers-link]
[![][compshare-shield]][compshare-link]

[![][trendshift-shield]][trendshift-link]
[![][hellogithub-shield]][hellogithub-link]

&lt;img src=&quot;assets/demoImage.jpg&quot; width=900&gt;

&lt;/div&gt;

&gt; **Áõ∏ÂÖ≥È°πÁõÆ**Ôºö
&gt;
&gt; - [SwanLab](https://github.com/SwanHubX/SwanLab)Ôºö‰∏Ä‰∏™ÂºÄÊ∫ê„ÄÅÁé∞‰ª£ÂåñËÆæËÆ°ÁöÑÊ∑±Â∫¶Â≠¶‰π†ËÆ≠ÁªÉË∑üË∏™‰∏éÂèØËßÜÂåñÂ∑•ÂÖ∑ÔºåÂêåÊó∂ÊîØÊåÅ‰∫ëÁ´Ø/Á¶ªÁ∫ø‰ΩøÁî®ÔºåÂõΩÂÜÖÂ•ΩÁî®ÁöÑWandbÂπ≥ÊõøÔºõÈÄÇÈÖç30+‰∏ªÊµÅÊ°ÜÊû∂ÔºàPyTorch„ÄÅHuggingFace Transformers„ÄÅLLaMA Factory„ÄÅLightningÁ≠âÔºâÔºåÊ¨¢Ëøé‰ΩøÁî®ÔºÅ


&lt;br&gt;

# ÁõÆÂΩï

- [ÊúÄËøëÊõ¥Êñ∞](#-ÊúÄËøëÊõ¥Êñ∞)
- [È°πÁõÆÁÆÄ‰ªã](#-È°πÁõÆÁÆÄ‰ªã)
- [Á§æÂå∫](#-Á§æÂå∫)
- [ÂáÜÂ§áÂ∑•‰Ωú](#-ÂáÜÂ§áÂ∑•‰Ωú)
- [DemoÂêØÂä®](#-ËøêË°å-gradio-demo)
- [PythonÊé®ÁêÜ](#-python-Êé®ÁêÜ)
- [APIÊúçÂä°ÈÉ®ÁΩ≤](#Ô∏è-ÈÉ®ÁΩ≤-api-ÊúçÂä°)
- [DockerÈÉ®ÁΩ≤](#-docker-ÈÉ®ÁΩ≤)
- [ËÅîÁ≥ªÊàë‰ª¨](#-ËÅîÁ≥ªÊàë‰ª¨)
- [FAQ](#faq)
- [ÊÑüË∞¢ÊîØÊåÅ](#-ÊÑüË∞¢ÊîØÊåÅ)
- [License](#-lincese)
- [ÂºïÁî®](#-ÂºïÁî®)

&lt;br&gt;

# ü§© ÊúÄËøëÊõ¥Êñ∞

- Âú®Á∫ø‰ΩìÈ™åÔºö [![SwanHub Demo](https://img.shields.io/static/v1?label=Demo&amp;message=SwanHub%20Demo&amp;color=blue)](https://swanhub.co/ZeYiLin/HivisionIDPhotos/demo)„ÄÅ[![Spaces](https://img.shields.io/badge/ü§ó-Open%20in%20Spaces-blue)](https://huggingface.co/spaces/TheEeeeLin/HivisionIDPhotos)„ÄÅ[![][modelscope-shield]][modelscope-link]„ÄÅ[![][compshare-shield]][compshare-link]

- 2024.11.20: Gradio DemoÂ¢ûÂä†**ÊâìÂç∞ÊéíÁâà**ÈÄâÈ°πÂç°ÔºåÊîØÊåÅÂÖ≠ÂØ∏„ÄÅ‰∫îÂØ∏„ÄÅA4„ÄÅ3R„ÄÅ4R‰∫îÁßçÊéíÁâàÂ∞∫ÂØ∏
- 2024.11.16: APIÊé•Âè£Â¢ûÂä†ÁæéÈ¢úÂèÇÊï∞
- 2024.09.25: Â¢ûÂä†**‰∫îÂØ∏Áõ∏Á∫∏**Âíå**JPEG‰∏ãËΩΩ**ÈÄâÈ°πÔΩúÈªòËÆ§ÁÖßÁâá‰∏ãËΩΩÊîØÊåÅ300DPI
- 2024.09.24: APIÊé•Âè£Â¢ûÂä†base64ÂõæÂÉè‰º†ÂÖ•ÈÄâÈ°π | Gradio DemoÂ¢ûÂä†**ÊéíÁâàÁÖßË£ÅÂâ™Á∫ø**ÂäüËÉΩ
- 2024.09.22: Gradio DemoÂ¢ûÂä†**ÈáéÂÖΩÊ®°Âºè**ÔºåÂèØËÆæÁΩÆÂÜÖÂ≠òÂä†ËΩΩÁ≠ñÁï• | APIÊé•Âè£Â¢ûÂä†**dpi„ÄÅface_alignment**ÂèÇÊï∞
- 2024.09.18: Gradio DemoÂ¢ûÂä†**ÂàÜ‰∫´Ê®°ÁâàÁÖß**ÂäüËÉΩ„ÄÅÂ¢ûÂä†**ÁæéÂºèËØÅ‰ª∂ÁÖß**ËÉåÊôØÈÄâÈ°π
- 2024.09.17: Gradio DemoÂ¢ûÂä†**Ëá™ÂÆö‰πâÂ∫ïËâ≤-HEXËæìÂÖ•**ÂäüËÉΩ | **ÔºàÁ§æÂå∫Ë¥°ÁåÆÔºâC++ÁâàÊú¨** - [HivisionIDPhotos-cpp](https://github.com/zjkhahah/HivisionIDPhotos-cpp) Ë¥°ÁåÆ by [zjkhahah](https://github.com/zjkhahah)
- 2024.09.16: Gradio DemoÂ¢ûÂä†**‰∫∫ËÑ∏ÊóãËΩ¨ÂØπÈΩê**ÂäüËÉΩÔºåËá™ÂÆö‰πâÂ∞∫ÂØ∏ËæìÂÖ•ÊîØÊåÅ**ÊØ´Á±≥**Âçï‰Ωç

&lt;br&gt;

# È°πÁõÆÁÆÄ‰ªã

&gt; üöÄ Ë∞¢Ë∞¢‰Ω†ÂØπÊàë‰ª¨ÁöÑÂ∑•‰ΩúÊÑüÂÖ¥Ë∂£„ÄÇÊÇ®ÂèØËÉΩËøòÊÉ≥Êü•ÁúãÊàë‰ª¨Âú®ÂõæÂÉèÈ¢ÜÂüüÁöÑÂÖ∂‰ªñÊàêÊûúÔºåÊ¨¢ËøéÊù•‰ø°:zeyi.lin@swanhub.co.

HivisionIDPhoto Êó®Âú®ÂºÄÂèë‰∏ÄÁßçÂÆûÁî®„ÄÅÁ≥ªÁªüÊÄßÁöÑËØÅ‰ª∂ÁÖßÊô∫ËÉΩÂà∂‰ΩúÁÆóÊ≥ï„ÄÇ

ÂÆÉÂà©Áî®‰∏ÄÂ•óÂÆåÂñÑÁöÑAIÊ®°ÂûãÂ∑•‰ΩúÊµÅÁ®ãÔºåÂÆûÁé∞ÂØπÂ§öÁßçÁî®Êà∑ÊãçÁÖßÂú∫ÊôØÁöÑËØÜÂà´„ÄÅÊä†Âõæ‰∏éËØÅ‰ª∂ÁÖßÁîüÊàê„ÄÇ

**HivisionIDPhoto ÂèØ‰ª•ÂÅöÂà∞Ôºö**

1. ËΩªÈáèÁ∫ßÊä†ÂõæÔºàÁ∫ØÁ¶ªÁ∫øÔºå‰ªÖÈúÄ **CPU** Âç≥ÂèØÂø´ÈÄüÊé®ÁêÜÔºâ
2. Ê†πÊçÆ‰∏çÂêåÂ∞∫ÂØ∏ËßÑÊ†ºÁîüÊàê‰∏çÂêåÁöÑÊ†áÂáÜËØÅ‰ª∂ÁÖß„ÄÅÂÖ≠ÂØ∏ÊéíÁâàÁÖß
3. ÊîØÊåÅ Á∫ØÁ¶ªÁ∫ø Êàñ Á´Ø‰∫ë Êé®ÁêÜ
4. ÁæéÈ¢ú
5. Êô∫ËÉΩÊç¢Ê≠£Ë£ÖÔºàwaitingÔºâ

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;assets/demo.png&quot; width=900&gt;
&lt;/div&gt;

---

Â¶ÇÊûú HivisionIDPhoto ÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ star Ëøô‰∏™ repo ÊàñÊé®ËçêÁªô‰Ω†ÁöÑÊúãÂèãÔºåËß£ÂÜ≥ËØÅ‰ª∂ÁÖßÂ∫îÊÄ•Âà∂‰ΩúÈóÆÈ¢òÔºÅ

&lt;br&gt;

# üè† Á§æÂå∫

Êàë‰ª¨ÂàÜ‰∫´‰∫Ü‰∏Ä‰∫õÁî±Á§æÂå∫ÊûÑÂª∫ÁöÑHivisionIDPhotosÁöÑÊúâË∂£Â∫îÁî®ÂíåÊâ©Â±ïÔºö

| [HivisionIDPhotos-ComfyUI][community-hivision-comfyui] | [HivisionIDPhotos-wechat-weapp][community-hivision-wechat] |
| :----------------------------------------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------------------------------------: |
| &lt;a href=&quot;https://github.com/AIFSH/HivisionIDPhotos-ComfyUI&quot;&gt; &lt;img src=&quot;assets/comfyui.png&quot; width=&quot;900&quot; alt=&quot;ComfyUI workflow&quot;&gt; &lt;/a&gt;  | &lt;a href=&quot;https://github.com/no1xuan/HivisionIDPhotos-wechat-weapp&quot;&gt; &lt;img src=&quot;assets/community-wechat-miniprogram.png&quot; width=&quot;900&quot; alt=&quot;ComfyUI workflow&quot;&gt; &lt;/a&gt;  |
|ComfyUIËØÅ‰ª∂ÁÖßÂ§ÑÁêÜÂ∑•‰ΩúÊµÅ | ËØÅ‰ª∂ÁÖßÂæÆ‰ø°Â∞èÁ®ãÂ∫èÔºàJAVAÂêéÁ´Ø+ÂéüÁîüÂâçÁ´ØÔºâ |

| [HivisionIDPhotos-Uniapp][community-hivision-uniapp] | [HivisionIDPhotos-web](https://github.com/jkm199/HivisionIDPhotos-web)|
| :------------------------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------------------------------------: |
| &lt;a href=&quot;https://github.com/soulerror/HivisionIDPhotos-Uniapp&quot;&gt; &lt;img src=&quot;assets/community-uniapp-wechat-miniprogram.png&quot; width=&quot;900&quot; alt=&quot;HivisionIDPhotos-uniapp&quot;&gt; &lt;/a&gt;  | &lt;a href=&quot;https://github.com/jkm199/HivisionIDPhotos-web&quot;&gt; &lt;img src=&quot;assets/community-web.png&quot; width=&quot;900&quot; alt=&quot;HivisionIDPhotos-uniapp&quot;&gt; &lt;/a&gt;  |
| ËØÅ‰ª∂ÁÖßÂæÆ‰ø°Â∞èÁ®ãÂ∫èÔºàuniappÔºâ| ËØÅ‰ª∂ÁÖßÂ∫îÁî®ÁΩëÈ°µÁâà |


- [HivisionIDPhotos-cpp](https://github.com/zjkhahah/HivisionIDPhotos-cpp): HivisionIDphotos C++ÁâàÊú¨ÔºåÁî± [zjkhahah](https://github.com/zjkhahah) ÊûÑÂª∫
- [ai-idphoto](https://github.com/wmlcjj/ai-idphoto): [HivisionIDPhotos-wechat-weapp](https://github.com/no1xuan/HivisionIDPhotos-wechat-weapp) ÁöÑuniappÂ§öÁ´ØÂÖºÂÆπÁâàÔºåÁî± [wmlcjj](https://github.com/wmlcjj) Ë¥°ÁåÆ
- [HivisionIDPhotos-uniapp-WeChat-gpto1](https://github.com/jkm199/HivisionIDPhotos-uniapp-WeChat-gpto1/): Áî±gpt-o1ËæÖÂä©ÂÆåÊàêÂºÄÂèëÁöÑËØÅ‰ª∂ÁÖßÂæÆ‰ø°Â∞èÁ®ãÂ∫èÔºåÁî± [jkm199](https://github.com/jkm199) Ë¥°ÁåÆ
- [HivisionIDPhotos-windows-GUI](https://github.com/zhaoyun0071/HivisionIDPhotos-windows-GUI)ÔºöWindowsÂÆ¢Êà∑Á´ØÂ∫îÁî®ÔºåÁî± [zhaoyun0071](https://github.com/zhaoyun0071) ÊûÑÂª∫
- [HivisionIDPhotos-NAS](https://github.com/ONG-Leo/HivisionIDPhotos-NAS): Áæ§ÊôñNASÈÉ®ÁΩ≤‰∏≠ÊñáÊïôÁ®ãÔºåÁî± [ONG-Leo](https://github.com/ONG-Leo) Ë¥°ÁåÆ


&lt;br&gt;

# üîß ÂáÜÂ§áÂ∑•‰Ωú

ÁéØÂ¢ÉÂÆâË£Ö‰∏é‰æùËµñÔºö
- Python &gt;= 3.7ÔºàÈ°πÁõÆ‰∏ªË¶ÅÊµãËØïÂú® python 3.10Ôºâ
- OS: Linux, Windows, MacOS

## 1. ÂÖãÈöÜÈ°πÁõÆ

```bash
git clone https://github.com/Zeyi-Lin/HivisionIDPhotos.git
cd  HivisionIDPhotos
```

## 2. ÂÆâË£Ö‰æùËµñÁéØÂ¢É

&gt; Âª∫ËÆÆ conda ÂàõÂª∫‰∏Ä‰∏™ python3.10 ËôöÊãüÁéØÂ¢ÉÂêéÔºåÊâßË°å‰ª•‰∏ãÂëΩ‰ª§

```bash
pip install -r requirements.txt
pip install -r requirements-app.txt
```

## 3. ‰∏ãËΩΩ‰∫∫ÂÉèÊä†ÂõæÊ®°ÂûãÊùÉÈáçÊñá‰ª∂

**ÊñπÂºè‰∏ÄÔºöËÑöÊú¨‰∏ãËΩΩ**

```bash
python scripts/download_model.py --models all
# Â¶ÇÈúÄÊåáÂÆö‰∏ãËΩΩÊüê‰∏™Ê®°Âûã
# python scripts/download_model.py --models modnet_photographic_portrait_matting
```

**ÊñπÂºè‰∫åÔºöÁõ¥Êé•‰∏ãËΩΩ**

Ê®°ÂûãÂùáÂ≠òÂà∞È°πÁõÆÁöÑ`hivision/creator/weights`ÁõÆÂΩï‰∏ãÔºö

| ‰∫∫ÂÉèÊä†ÂõæÊ®°Âûã | ‰ªãÁªç | ‰∏ãËΩΩ |
| -- | -- | -- |
| MODNet | [MODNet](https://github.com/ZHKKKe/MODNet)ÂÆòÊñπÊùÉÈáç | [‰∏ãËΩΩ](https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/download/pretrained-model/modnet_photographic_portrait_matting.onnx)(24.7MB)|
| hivision_modnet | ÂØπÁ∫ØËâ≤Êç¢Â∫ïÈÄÇÈÖçÊÄßÊõ¥Â•ΩÁöÑÊä†ÂõæÊ®°Âûã | [‰∏ãËΩΩ](https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/download/pretrained-model/hivision_modnet.onnx)(24.7MB) |
| rmbg-1.4 | [BRIA AI](https://huggingface.co/briaai/RMBG-1.4) ÂºÄÊ∫êÁöÑÊä†ÂõæÊ®°Âûã | [‰∏ãËΩΩ](https://huggingface.co/briaai/RMBG-1.4/resolve/main/onnx/model.onnx?download=true)(176.2MB)ÂêéÈáçÂëΩÂêç‰∏∫`rmbg-1.4.onnx` |
| birefnet-v1-lite | [ZhengPeng7](https://github.com/ZhengPeng7/BiRefNet) ÂºÄÊ∫êÁöÑÊä†ÂõæÊ®°ÂûãÔºåÊã•ÊúâÊúÄÂ•ΩÁöÑÂàÜÂâ≤Á≤æÂ∫¶ | [‰∏ãËΩΩ](https://github.com/ZhengPeng7/BiRefNet/releases/download/v1/BiRefNet-general-bb_swin_v1_tiny-epoch_232.onnx)(224MB)ÂêéÈáçÂëΩÂêç‰∏∫`birefnet-v1-lite.onnx` |

&gt; Â¶ÇÊûú‰∏ãËΩΩÁΩëÈÄü‰∏çÈ°∫Âà©ÔºöÂâçÂæÄ[SwanHub](https://swanhub.co/ZeYiLin/HivisionIDPhotos_models/tree/main)‰∏ãËΩΩ„ÄÇ


## 4. ‰∫∫ËÑ∏Ê£ÄÊµãÊ®°ÂûãÈÖçÁΩÆÔºàÂèØÈÄâÔºâ

| ÊãìÂ±ï‰∫∫ËÑ∏Ê£ÄÊµãÊ®°Âûã | ‰ªãÁªç | ‰ΩøÁî®ÊñáÊ°£ |
| -- | -- | -- |
| MTCNN | **Á¶ªÁ∫ø**‰∫∫ËÑ∏Ê£ÄÊµãÊ®°ÂûãÔºåÈ´òÊÄßËÉΩCPUÊé®ÁêÜÔºàÊØ´ÁßíÁ∫ßÔºâÔºå‰∏∫ÈªòËÆ§Ê®°ÂûãÔºåÊ£ÄÊµãÁ≤æÂ∫¶ËæÉ‰Ωé | CloneÊ≠§È°πÁõÆÂêéÁõ¥Êé•‰ΩøÁî® |
| RetinaFace | **Á¶ªÁ∫ø**‰∫∫ËÑ∏Ê£ÄÊµãÊ®°ÂûãÔºåCPUÊé®ÁêÜÈÄüÂ∫¶‰∏≠Á≠âÔºàÁßíÁ∫ßÔºâÔºåÁ≤æÂ∫¶ËæÉÈ´ò| [‰∏ãËΩΩ](https://github.com/Zeyi-Lin/HivisionIDPhotos/releases/download/pretrained-model/retinaface-resnet50.onnx)ÂêéÊîæÂà∞`hivision/creator/retinaface/weights`ÁõÆÂΩï‰∏ã |
| Face++ | Êó∑ËßÜÊé®Âá∫ÁöÑÂú®Á∫ø‰∫∫ËÑ∏Ê£ÄÊµãAPIÔºåÊ£ÄÊµãÁ≤æÂ∫¶ËæÉÈ´òÔºå[ÂÆòÊñπÊñáÊ°£](https://console.faceplusplus.com.cn/documents/4888373) | [‰ΩøÁî®ÊñáÊ°£](docs/face++_CN.md)|

## 5. ÊÄßËÉΩÂèÇËÄÉ

&gt; ÊµãËØïÁéØÂ¢É‰∏∫Mac M1 Max 64GBÔºåÈùûGPUÂä†ÈÄüÔºåÊµãËØïÂõæÁâáÂàÜËæ®Áéá‰∏∫ 512x715(1) ‰∏é 764√ó1146(2)„ÄÇ

| Ê®°ÂûãÁªÑÂêà | ÂÜÖÂ≠òÂç†Áî® | Êé®ÁêÜÊó∂Èïø(1) | Êé®ÁêÜÊó∂Èïø(2) |
| -- | -- | -- | -- |
| MODNet + mtcnn | 410MB | 0.207s | 0.246s |
| MODNet + retinaface | 405MB | 0.571s | 0.971s |
| birefnet-v1-lite + retinaface | 6.20GB | 7.063s | 7.128s |

## 6. GPUÊé®ÁêÜÂä†ÈÄüÔºàÂèØÈÄâÔºâ

Âú®ÂΩìÂâçÁâàÊú¨ÔºåÂèØË¢´Ëã±‰ºüËææGPUÂä†ÈÄüÁöÑÊ®°Âûã‰∏∫`birefnet-v1-lite`ÔºåÂπ∂ËØ∑Á°Æ‰øù‰Ω†Êúâ16GBÂ∑¶Âè≥ÁöÑÊòæÂ≠ò„ÄÇ

Â¶ÇÈúÄ‰ΩøÁî®Ëã±‰ºüËææGPUÂä†ÈÄüÊé®ÁêÜÔºåÂú®Á°Æ‰øù‰Ω†Â∑≤ÁªèÂÆâË£Ö[CUDA](https://developer.nvidia.com/cuda-downloads)‰∏é[cuDNN](https://developer.nvidia.com/cudnn)ÂêéÔºåÊ†πÊçÆ[onnxruntime-gpuÊñáÊ°£](https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#cuda-12x)ÊâæÂà∞ÂØπÂ∫îÁöÑ`onnxruntime-gpu`ÁâàÊú¨ÂÆâË£ÖÔºå‰ª•ÂèäÊ†πÊçÆ[pytorchÂÆòÁΩë](https://pytorch.org/get-started/locally/)ÊâæÂà∞ÂØπÂ∫îÁöÑ`torch`ÁâàÊú¨ÂÆâË£Ö„ÄÇ

```bash
# ÂÅáÂ¶Ç‰Ω†ÁöÑÁîµËÑëÂÆâË£ÖÁöÑÊòØCUDA 12.x, cuDNN 8
# ÂÆâË£ÖtorchÊòØÂèØÈÄâÁöÑÔºåÂ¶ÇÊûú‰Ω†ÂßãÁªàÈÖçÁΩÆ‰∏çÂ•ΩcuDNNÔºåÈÇ£‰πàËØïËØïÂÆâË£Ötorch
pip install onnxruntime-gpu==1.18.0
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

ÂÆåÊàêÂÆâË£ÖÂêéÔºåË∞ÉÁî®`birefnet-v1-lite`Ê®°ÂûãÂç≥ÂèØÂà©Áî®GPUÂä†ÈÄüÊé®ÁêÜ„ÄÇ

&gt; TIPS: CUDA ÊîØÊåÅÂêë‰∏ãÂÖºÂÆπ„ÄÇÊØîÂ¶Ç‰Ω†ÁöÑ CUDA ÁâàÊú¨‰∏∫ 12.6Ôºå`torch` ÂÆòÊñπÁõÆÂâçÊîØÊåÅÁöÑÊúÄÈ´òÁâàÊú¨‰∏∫ 12.4Ôºà&lt;12.6ÔºâÔºå`torch`‰ªçÂèØ‰ª•Ê≠£Â∏∏‰ΩøÁî®CUDA„ÄÇ

&lt;br&gt;

# ‚ö°Ô∏è ËøêË°å Gradio Demo

```bash
python app.py
```

ËøêË°åÁ®ãÂ∫èÂ∞ÜÁîüÊàê‰∏Ä‰∏™Êú¨Âú∞ Web È°µÈù¢ÔºåÂú®È°µÈù¢‰∏≠ÂèØÂÆåÊàêËØÅ‰ª∂ÁÖßÁöÑÊìç‰Ωú‰∏é‰∫§‰∫í„ÄÇ

&lt;img src=&quot;assets/harry.png&quot; width=900&gt;

&lt;br&gt;

# üöÄ Python Êé®ÁêÜ

Ê†∏ÂøÉÂèÇÊï∞Ôºö

- `-i`: ËæìÂÖ•ÂõæÂÉèË∑ØÂæÑ
- `-o`: ‰øùÂ≠òÂõæÂÉèË∑ØÂæÑ
- `-t`: Êé®ÁêÜÁ±ªÂûãÔºåÊúâidphoto„ÄÅhuman_matting„ÄÅadd_background„ÄÅgenerate_layout_photosÂèØÈÄâ
- `--matting_model`: ‰∫∫ÂÉèÊä†ÂõæÊ®°ÂûãÊùÉÈáçÈÄâÊã©
- `--face_detect_model`: ‰∫∫ËÑ∏Ê£ÄÊµãÊ®°ÂûãÈÄâÊã©

Êõ¥Â§öÂèÇÊï∞ÂèØÈÄöËøá`python inference.py --help`Êü•Áúã

## 1. ËØÅ‰ª∂ÁÖßÂà∂‰Ωú

ËæìÂÖ• 1 Âº†ÁÖßÁâáÔºåËé∑Âæó 1 Âº†Ê†áÂáÜËØÅ‰ª∂ÁÖßÂíå 1 Âº†È´òÊ∏ÖËØÅ‰ª∂ÁÖßÁöÑ 4 ÈÄöÈÅìÈÄèÊòé png

```python
python inference.py -i demo/images/test0.jpg -o ./idphoto.png --height 413 --width 295
```

## 2. ‰∫∫ÂÉèÊä†Âõæ

ËæìÂÖ• 1 Âº†ÁÖßÁâáÔºåËé∑Âæó 1Âº† 4 ÈÄöÈÅìÈÄèÊòé png

```python
python inference.py -t human_matting -i demo/images/test0.jpg -o ./idphoto_matting.png --matting_model hivision_modnet
```

## 3. ÈÄèÊòéÂõæÂ¢ûÂä†Â∫ïËâ≤

ËæìÂÖ• 1 Âº† 4 ÈÄöÈÅìÈÄèÊòé pngÔºåËé∑Âæó 1 Âº†Â¢ûÂä†‰∫ÜÂ∫ïËâ≤ÁöÑ 3ÈÄöÈÅìÂõæÂÉè

```python
python inference.py -t add_background -i ./idphoto.png -o ./idphoto_ab.jpg  -c 4f83ce -k 30 -r 1
```

## 4. ÂæóÂà∞ÂÖ≠ÂØ∏ÊéíÁâàÁÖß

ËæìÂÖ• 1 Âº† 3 ÈÄöÈÅìÁÖßÁâáÔºåËé∑Âæó 1 Âº†ÂÖ≠ÂØ∏ÊéíÁâàÁÖß

```python
python inference.py -t generate_layout_photos -i ./idphoto_ab.jpg -o ./idphoto_layout.jpg  --height 413 --width 295 -k 200
```

## 5. ËØÅ‰ª∂ÁÖßË£ÅÂâ™

ËæìÂÖ• 1 Âº† 4 ÈÄöÈÅìÁÖßÁâáÔºàÊä†ÂõæÂ•ΩÁöÑÂõæÂÉèÔºâÔºåËé∑Âæó 1 Âº†Ê†áÂáÜËØÅ‰ª∂ÁÖßÂíå 1 Âº†È´òÊ∏ÖËØÅ‰ª∂ÁÖßÁöÑ 4 ÈÄöÈÅìÈÄèÊòé png

```python
python inference.py -t idphoto_crop -i ./idphoto_matting.png -o ./idphoto_crop.png --height 413 --width 295
```


&lt;br&gt;

# ‚ö°Ô∏è ÈÉ®ÁΩ≤ API ÊúçÂä°

## ÂêØÂä®ÂêéÁ´Ø

```
python deploy_api.py
```

## ËØ∑Ê±Ç API ÊúçÂä°

ËØ¶ÁªÜËØ∑Ê±ÇÊñπÂºèËØ∑ÂèÇËÄÉ [API ÊñáÊ°£](docs/api_CN.md)ÔºåÂåÖÂê´‰ª•‰∏ãËØ∑Ê±ÇÁ§∫‰æãÔºö
- [cURL](docs/api_CN.md#curl-ËØ∑Ê±ÇÁ§∫‰æã)
- [Python](docs/api_CN.md#python-ËØ∑Ê±ÇÁ§∫‰æã)

&lt;br&gt;

# üê≥ Docker ÈÉ®ÁΩ≤

## 1. ÊãâÂèñÊàñÊûÑÂª∫ÈïúÂÉè

&gt; ‰ª•‰∏ãÊñπÂºè‰∏âÈÄâ‰∏Ä

**ÊñπÂºè‰∏ÄÔºöÊãâÂèñÊúÄÊñ∞ÈïúÂÉèÔºö**

```bash
docker pull linzeyi/hivision_idphotos
```

**ÊñπÂºè‰∫åÔºöDockrfile Áõ¥Êé•ÊûÑÂª∫ÈïúÂÉèÔºö**

Âú®Á°Æ‰øùÂ∞ÜËá≥Â∞ë‰∏Ä‰∏™[Êä†ÂõæÊ®°ÂûãÊùÉÈáçÊñá‰ª∂](#3-‰∏ãËΩΩÊùÉÈáçÊñá‰ª∂)ÊîæÂà∞`hivision/creator/weights`‰∏ãÂêéÔºåÂú®È°πÁõÆÊ†πÁõÆÂΩïÊâßË°åÔºö

```bash
docker build -t linzeyi/hivision_idphotos .
```

**ÊñπÂºè‰∏âÔºöDocker compose ÊûÑÂª∫Ôºö**

Âú®Á°Æ‰øùÂ∞ÜËá≥Â∞ë‰∏Ä‰∏™[Êä†ÂõæÊ®°ÂûãÊùÉÈáçÊñá‰ª∂](#3-‰∏ãËΩΩÊùÉÈáçÊñá‰ª∂)ÊîæÂà∞`hivision/creator/weights`‰∏ãÂêéÔºåÂú®È°πÁõÆÊ†πÁõÆÂΩï‰∏ãÊâßË°åÔºö

```bash
docker compose build
```

## 2. ËøêË°åÊúçÂä°

**ÂêØÂä® Gradio Demo ÊúçÂä°**

ËøêË°å‰∏ãÈù¢ÁöÑÂëΩ‰ª§ÔºåÂú®‰Ω†ÁöÑÊú¨Âú∞ËÆøÈóÆ [http://127.0.0.1:7860](http://127.0.0.1:7860/) Âç≥ÂèØ‰ΩøÁî®„ÄÇ

```bash
docker run -d -p 7860:7860 linzeyi/hivision_idphotos
```

**ÂêØÂä® API ÂêéÁ´ØÊúçÂä°**

```bash
docker run -d -p 8080:8080 linzeyi/hivision_idphotos python3 deploy_api.py
```

**‰∏§‰∏™ÊúçÂä°ÂêåÊó∂ÂêØÂä®**

```bash
docker compose up -d
```

## ÁéØÂ¢ÉÂèòÈáè

Êú¨È°πÁõÆÊèê‰æõ‰∫Ü‰∏Ä‰∫õÈ¢ùÂ§ñÁöÑÈÖçÁΩÆÈ°πÔºå‰ΩøÁî®ÁéØÂ¢ÉÂèòÈáèËøõË°åËÆæÁΩÆÔºö

| ÁéØÂ¢ÉÂèòÈáè | Á±ªÂûã	| ÊèèËø∞ | Á§∫‰æã |
|--|--|--|--|
| FACE_PLUS_API_KEY	 | ÂèØÈÄâ	| ËøôÊòØ‰Ω†Âú® Face++ ÊéßÂà∂Âè∞Áî≥ËØ∑ÁöÑ API ÂØÜÈí•	 | `7-fZStDJ¬∑¬∑¬∑¬∑` |
| FACE_PLUS_API_SECRET	 | ÂèØÈÄâ	| Face++ APIÂØÜÈí•ÂØπÂ∫îÁöÑSecret | `VTee824E¬∑¬∑¬∑¬∑` |
| RUN_MODE | ÂèØÈÄâ | ËøêË°åÊ®°ÂºèÔºåÂèØÈÄâÂÄº‰∏∫`beast`(ÈáéÂÖΩÊ®°Âºè)„ÄÇÈáéÂÖΩÊ®°Âºè‰∏ã‰∫∫ËÑ∏Ê£ÄÊµãÂíåÊä†ÂõæÊ®°ÂûãÂ∞Ü‰∏çÈáäÊîæÂÜÖÂ≠òÔºå‰ªéËÄåËé∑ÂæóÊõ¥Âø´ÁöÑ‰∫åÊ¨°Êé®ÁêÜÈÄüÂ∫¶„ÄÇÂª∫ËÆÆÂÜÖÂ≠ò16GB‰ª•‰∏äÂ∞ùËØï„ÄÇ | `beast` |
| DEFAULT_LANG | ÂèØÈÄâ | Gradio DemoÂêØÂä®Êó∂ÁöÑÈªòËÆ§ËØ≠Ë®Ä| `en` |

docker‰ΩøÁî®ÁéØÂ¢ÉÂèòÈáèÁ§∫‰æãÔºö
```bash
docker run  -d -p 7860:7860 \
    -e FACE_PLUS_API_KEY=7-fZStDJ¬∑¬∑¬∑¬∑ \
    -e FACE_PLUS_API_SECRET=VTee824E¬∑¬∑¬∑¬∑ \
    -e RUN_MODE=beast \
    -e DEFAULT_LANG=en \
    linzeyi/hivision_idphotos  
```

&lt;br&gt;

# FAQ

## 1. Â¶Ç‰Ωï‰øÆÊîπÈ¢ÑËÆæÂ∞∫ÂØ∏ÂíåÈ¢úËâ≤Ôºü

- Â∞∫ÂØ∏Ôºö‰øÆÊîπ[size_list_CN.csv](demo/assets/size_list_CN.csv)ÂêéÂÜçÊ¨°ËøêË°å `app.py` Âç≥ÂèØÔºåÂÖ∂‰∏≠Á¨¨‰∏ÄÂàó‰∏∫Â∞∫ÂØ∏ÂêçÔºåÁ¨¨‰∫åÂàó‰∏∫È´òÂ∫¶ÔºåÁ¨¨‰∏âÂàó‰∏∫ÂÆΩÂ∫¶„ÄÇ
- È¢úËâ≤Ôºö‰øÆÊîπ[color_list_CN.csv](demo/assets/color_list_CN.csv)ÂêéÂÜçÊ¨°ËøêË°å `app.py` Âç≥ÂèØÔºåÂÖ∂‰∏≠Á¨¨‰∏ÄÂàó‰∏∫È¢úËâ≤ÂêçÔºåÁ¨¨‰∫åÂàó‰∏∫HexÂÄº„ÄÇ

## 2. Â¶Ç‰Ωï‰øÆÊîπÊ∞¥Âç∞Â≠ó‰ΩìÔºü

1. Â∞ÜÂ≠ó‰ΩìÊñá‰ª∂ÊîæÂà∞`hivision/plugin/font`Êñá‰ª∂Â§π‰∏ã
2. ‰øÆÊîπ`hivision/plugin/watermark.py`ÁöÑ`font_file`ÂèÇÊï∞ÂÄº‰∏∫Â≠ó‰ΩìÊñá‰ª∂Âêç

## 3. Â¶Ç‰ΩïÊ∑ªÂä†Á§æ‰∫§Â™í‰ΩìÊ®°ÊùøÁÖßÔºü

1. Â∞ÜÊ®°ÊùøÂõæÁâáÊîæÂà∞`hivision/plugin/template/assets`Êñá‰ª∂Â§π‰∏ã„ÄÇÊ®°ÊùøÂõæÁâáÊòØ‰∏Ä‰∏™4ÈÄöÈÅìÁöÑÈÄèÊòépng„ÄÇ
2. Âú®`hivision/plugin/template/assets/template_config.json`Êñá‰ª∂‰∏≠Ê∑ªÂä†ÊúÄÊñ∞ÁöÑÊ®°Êùø‰ø°ÊÅØÔºåÂÖ∂‰∏≠`width`‰∏∫Ê®°ÊùøÂõæÂÆΩÂ∫¶(px)Ôºå`height`‰∏∫Ê®°ÊùøÂõæÈ´òÂ∫¶(px)Ôºå`anchor_points`‰∏∫Ê®°Êùø‰∏≠ÈÄèÊòéÂå∫ÂüüÁöÑÂõõ‰∏™ËßíÁöÑÂùêÊ†á(px)Ôºõ`rotation`‰∏∫ÈÄèÊòéÂå∫ÂüüÁõ∏ÂØπ‰∫éÂûÇÁõ¥ÊñπÂêëÁöÑÊóãËΩ¨ËßíÂ∫¶Ôºå&gt;0‰∏∫ÈÄÜÊó∂ÈíàÔºå&lt;0‰∏∫È°∫Êó∂Èíà„ÄÇ
3. Âú®`demo/processor.py`ÁöÑ`_generate_image_template`ÂáΩÊï∞‰∏≠ÁöÑ`TEMPLATE_NAME_LIST`ÂèòÈáèÊ∑ªÂä†ÊúÄÊñ∞ÁöÑÊ®°ÊùøÂêç

&lt;img src=&quot;assets/social_template.png&quot; width=&quot;500&quot;&gt;

## 4. Â¶Ç‰Ωï‰øÆÊîπGradio DemoÁöÑÈ°∂ÈÉ®ÂØºËà™Ê†èÔºü

- ‰øÆÊîπ`demo/assets/title.md`

## 5. Â¶Ç‰ΩïÊ∑ªÂä†/‰øÆÊîπ„ÄåÊâìÂç∞ÊéíÁâà„Äç‰∏≠ÁöÑÂ∞∫ÂØ∏Ôºü

- ‰øÆÊîπ`demo/locales.py`‰∏≠ÁöÑ`print_switch`Â≠óÂÖ∏ÔºåÊ∑ªÂä†/‰øÆÊîπÊñ∞ÁöÑÂ∞∫ÂØ∏ÂêçÁß∞ÂíåÂ∞∫ÂØ∏ÂèÇÊï∞ÔºåÁÑ∂ÂêéÈáçÊñ∞ËøêË°å`python app.py`

&lt;br&gt;

# üìß ËÅîÁ≥ªÊàë‰ª¨

Â¶ÇÊûúÊÇ®Êúâ‰ªª‰ΩïÈóÆÈ¢òÔºåËØ∑ÂèëÈÇÆ‰ª∂Ëá≥ zeyi.lin@swanhub.co

&lt;br&gt;

# üôè ÊÑüË∞¢ÊîØÊåÅ

[![Stargazers repo roster for @Zeyi-Lin/HivisionIDPhotos](https://reporoster.com/stars/Zeyi-Lin/HivisionIDPhotos)](https://github.com/Zeyi-Lin/HivisionIDPhotos/stargazers)

[![Forkers repo roster for @Zeyi-Lin/HivisionIDPhotos](https://reporoster.com/forks/Zeyi-Lin/HivisionIDPhotos)](https://github.com/Zeyi-Lin/HivisionIDPhotos/network/members)

[![Star History Chart](https://api.star-history.com/svg?repos=Zeyi-Lin/HivisionIDPhotos&amp;type=Date)](https://star-history.com/#Zeyi-Lin/HivisionIDPhotos&amp;Date)

Ë¥°ÁåÆËÄÖ‰ª¨Ôºö

&lt;a href=&quot;https://github.com/Zeyi-Lin/HivisionIDPhotos/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=Zeyi-Lin/HivisionIDPhotos&quot; /&gt;
&lt;/a&gt;

[Zeyi-Lin](https://github.com/Zeyi-Lin)„ÄÅ[SAKURA-CAT](https://github.com/SAKURA-CAT)„ÄÅ[Feudalman](https://github.com/Feudalman)„ÄÅ[swpfY](https://github.com/swpfY)„ÄÅ[Kaikaikaifang](https://github.com/Kaikaikaifang)„ÄÅ[ShaohonChen](https://github.com/ShaohonChen)„ÄÅ[KashiwaByte](https://github.com/KashiwaByte)

&lt;br&gt;

# üìú Lincese

This repository is licensed under the [Apache-2.0 License](LICENSE).

&lt;br&gt;

# üìö ÂºïÁî®

Â¶ÇÊûúÊÇ®Âú®Á†îÁ©∂ÊàñÈ°πÁõÆ‰∏≠‰ΩøÁî®‰∫ÜHivisionIDPhotosÔºåËØ∑ËÄÉËôëÂºïÁî®Êàë‰ª¨ÁöÑÂ∑•‰Ωú„ÄÇÊÇ®ÂèØ‰ª•‰ΩøÁî®‰ª•‰∏ãBibTeXÊù°ÁõÆÔºö

```bibtex
@misc{hivisionidphotos,
      title={{HivisionIDPhotos: A Lightweight and Efficient AI ID Photos Tool}},
      author={Zeyi Lin and SwanLab Team},
      year={2024},
      publisher={GitHub},
      url = {\url{https://github.com/Zeyi-Lin/HivisionIDPhotos}},
}
```




[github-stars-shield]: https://img.shields.io/github/stars/zeyi-lin/hivisionidphotos?color=ffcb47&amp;labelColor=black&amp;style=flat-square
[github-stars-link]: https://github.com/zeyi-lin/hivisionidphotos/stargazers

[swanhub-demo-shield]: https://swanhub.co/git/repo/SwanHub%2FAuto-README/file/preview?ref=main&amp;path=swanhub.svg
[swanhub-demo-link]: https://swanhub.co/ZeYiLin/HivisionIDPhotos/demo

[spaces-shield]: https://img.shields.io/badge/ü§ó-Open%20in%20Spaces-blue
[spaces-link]: https://huggingface.co/spaces/TheEeeeLin/HivisionIDPhotos

&lt;!-- ÂæÆ‰ø°Áæ§ÈìæÊé• --&gt;
[wechat-shield]: https://img.shields.io/badge/WeChat-ÂæÆ‰ø°-4cb55e
[wechat-link]: https://docs.qq.com/doc/DUkpBdk90eWZFS2JW

&lt;!-- Github Release --&gt;
[release-shield]: https://img.shields.io/github/v/release/zeyi-lin/hivisionidphotos?color=369eff&amp;labelColor=black&amp;logo=github&amp;style=flat-square
[release-link]: https://github.com/zeyi-lin/hivisionidphotos/releases

[license-shield]: https://img.shields.io/badge/license-apache%202.0-white?labelColor=black&amp;style=flat-square
[license-link]: https://github.com/Zeyi-Lin/HivisionIDPhotos/blob/master/LICENSE

[github-issues-shield]: https://img.shields.io/github/issues/zeyi-lin/hivisionidphotos?color=ff80eb&amp;labelColor=black&amp;style=flat-square
[github-issues-link]: https://github.com/zeyi-lin/hivisionidphotos/issues

[dockerhub-shield]: https://img.shields.io/docker/v/linzeyi/hivision_idphotos?color=369eff&amp;label=docker&amp;labelColor=black&amp;logoColor=white&amp;style=flat-square
[dockerhub-link]: https://hub.docker.com/r/linzeyi/hivision_idphotos/tags

[trendshift-shield]: https://trendshift.io/api/badge/repositories/11622
[trendshift-link]: https://trendshift.io/repositories/11622

[hellogithub-shield]: https://abroad.hellogithub.com/v1/widgets/recommend.svg?rid=8ea1457289fb4062ba661e5299e733d6&amp;claim_uid=Oh5UaGjfrblg0yZ
[hellogithub-link]: https://hellogithub.com/repository/8ea1457289fb4062ba661e5299e733d6

[github-contributors-shield]: https://img.shields.io/github/contributors/zeyi-lin/hivisionidphotos?color=c4f042&amp;labelColor=black&amp;style=flat-square
[github-contributors-link]: https://github.com/zeyi-lin/hivisionidphotos/graphs/contributors

[github-forks-shield]: https://img.shields.io/github/forks/zeyi-lin/hivisionidphotos?color=8ae8ff&amp;labelColor=black&amp;style=flat-square
[github-forks-link]: https://github.com/zeyi-lin/hivisionidphotos/network/members

[modelscope-shield]: https://img.shields.io/badge/Demo_on_ModelScope-purple?logo=data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjIzIiBoZWlnaHQ9IjIwMCIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KCiA8Zz4KICA8dGl0bGU+TGF5ZXIgMTwvdGl0bGU+CiAgPHBhdGggaWQ9InN2Z18xNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTAsODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTUiIGZpbGw9IiM2MjRhZmYiIGQ9Im05OS4xNCwxMTUuNDlsMjUuNjUsMGwwLDI1LjY1bC0yNS42NSwwbDAsLTI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTYiIGZpbGw9IiM2MjRhZmYiIGQ9Im0xNzYuMDksMTQxLjE0bC0yNS42NDk5OSwwbDAsMjIuMTlsNDcuODQsMGwwLC00Ny44NGwtMjIuMTksMGwwLDI1LjY1eiIvPgogIDxwYXRoIGlkPSJzdmdfMTciIGZpbGw9IiMzNmNmZDEiIGQ9Im0xMjQuNzksODkuODRsMjUuNjUsMGwwLDI1LjY0OTk5bC0yNS42NSwwbDAsLTI1LjY0OTk5eiIvPgogIDxwYXRoIGlkPSJzdmdfMTgiIGZpbGw9IiMzNmNmZDEiIGQ9Im0wLDY0LjE5bDI1LjY1LDBsMCwyNS42NWwtMjUuNjUsMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzE5IiBmaWxsPSIjNjI0YWZmIiBkPSJtMTk4LjI4LDg5Ljg0bDI1LjY0OTk5LDBsMCwyNS42NDk5OWwtMjUuNjQ5OTksMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIwIiBmaWxsPSIjMzZjZmQxIiBkPSJtMTk4LjI4LDY0LjE5bDI1LjY0OTk5LDBsMCwyNS42NWwtMjUuNjQ5OTksMGwwLC0yNS42NXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIxIiBmaWxsPSIjNjI0YWZmIiBkPSJtMTUwLjQ0LDQybDAsMjIuMTlsMjUuNjQ5OTksMGwwLDI1LjY1bDIyLjE5LDBsMCwtNDcuODRsLTQ3Ljg0LDB6Ii8+CiAgPHBhdGggaWQ9InN2Z18yMiIgZmlsbD0iIzM2Y2ZkMSIgZD0ibTczLjQ5LDg5Ljg0bDI1LjY1LDBsMCwyNS42NDk5OWwtMjUuNjUsMGwwLC0yNS42NDk5OXoiLz4KICA8cGF0aCBpZD0ic3ZnXzIzIiBmaWxsPSIjNjI0YWZmIiBkPSJtNDcuODQsNjQuMTlsMjUuNjUsMGwwLC0yMi4xOWwtNDcuODQsMGwwLDQ3Ljg0bDIyLjE5LDBsMCwtMjUuNjV6Ii8+CiAgPHBhdGggaWQ9InN2Z18yNCIgZmlsbD0iIzYyNGFmZiIgZD0ibTQ3Ljg0LDExNS40OWwtMjIuMTksMGwwLDQ3Ljg0bDQ3Ljg0LDBsMCwtMjIuMTlsLTI1LjY1LDBsMCwtMjUuNjV6Ii8+CiA8L2c+Cjwvc3ZnPg==&amp;labelColor=white
[modelscope-link]: https://modelscope.cn/studios/SwanLab/HivisionIDPhotos

[modelers-shield]: https://img.shields.io/badge/Demo_on_Modelers-c42a2a?logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjQiIGhlaWdodD0iNjQiIHZpZXdCb3g9IjAgMCAxMjQgNjQiIGZpbGw9Im5vbmUiPgo8cGF0aCBkPSJNNDIuNzc4MyAwSDI2LjU5NzdWMTUuNzc4N0g0Mi43NzgzVjBaIiBmaWxsPSIjREUwNDI5Ii8+CjxwYXRoIGQ9Ik0xNi41MDg4IDQuMTc5MkgwLjMyODEyNVYxOS45NTc5SDE2LjUwODhWNC4xNzkyWiIgZmlsbD0iIzI0NDk5QyIvPgo8cGF0aCBkPSJNMTIzLjk1MiA0LjE3OTJIMTA3Ljc3MVYxOS45NTc5SDEyMy45NTJWNC4xNzkyWiIgZmlsbD0iIzI0NDk5QyIvPgo8cGF0aCBkPSJNMTYuNTA4OCA0NS40NjE5SDAuMzI4MTI1VjYxLjI0MDZIMTYuNTA4OFY0NS40NjE5WiIgZmlsbD0iIzI0NDk5QyIvPgo8cGF0aCBkPSJNMTIzLjk1MiA0NS40NjE5SDEwNy43NzFWNjEuMjQwNkgxMjMuOTUyVjQ1LjQ2MTlaIiBmaWxsPSIjMjQ0OTlDIi8+CjxwYXRoIGQ9Ik0zMi43MDggMTUuNzc4OEgxNi41MjczVjMxLjU1NzVIMzIuNzA4VjE1Ljc3ODhaIiBmaWxsPSIjREUwNDI5Ii8+CjxwYXRoIGQ9Ik01Mi44NDg2IDE1Ljc3ODhIMzYuNjY4VjMxLjU1NzVINTIuODQ4NlYxNS43Nzg4WiIgZmlsbD0iI0RFMDQyOSIvPgo8cGF0aCBkPSJNOTcuNzIzNyAwSDgxLjU0M1YxNS43Nzg3SDk3LjcyMzdWMFoiIGZpbGw9IiNERTA0MjkiLz4KPHBhdGggZD0iTTg3LjY1MzQgMTUuNzc4OEg3MS40NzI3VjMxLjU1NzVIODcuNjUzNFYxNS43Nzg4WiIgZmlsbD0iI0RFMDQyOSIvPgo8cGF0aCBkPSJNMTA3Ljc5NCAxNS43Nzg4SDkxLjYxMzNWMzEuNTU3NUgxMDcuNzk0VjE1Ljc3ODhaIiBmaWxsPSIjREUwNDI5Ii8+CjxwYXRoIGQ9Ik0yNC42NzQ4IDMxLjU1NzZIOC40OTQxNFY0Ny4zMzYzSDI0LjY3NDhWMzEuNTU3NloiIGZpbGw9IiNERTA0MjkiLz4KPHBhdGggZD0iTTYwLjg3OTkgMzEuNTU3Nkg0NC42OTkyVjQ3LjMzNjNINjAuODc5OVYzMS41NTc2WiIgZmlsbD0iI0RFMDQyOSIvPgo8cGF0aCBkPSJNNzkuNjIwMSAzMS41NTc2SDYzLjQzOTVWNDcuMzM2M0g3OS42MjAxVjMxLjU1NzZaIiBmaWxsPSIjREUwNDI5Ii8+CjxwYXRoIGQ9Ik0xMTUuODI1IDMxLjU1NzZIOTkuNjQ0NVY0Ny4zMzYzSDExNS44MjVWMzEuNTU3NloiIGZpbGw9IiNERTA0MjkiLz4KPHBhdGggZD0iTTcwLjI1NDkgNDcuMzM1OUg1NC4wNzQyVjYzLjExNDdINzAuMjU0OVY0Ny4zMzU5WiIgZmlsbD0iI0RFMDQyOSIvPgo8L3N2Zz4=&amp;labelColor=white
[modelers-link]: https://modelers.cn/spaces/SwanLab/HivisionIDPhotos

[compshare-shield]: https://www-s.ucloud.cn/2025/02/dbef8b07ea3d316006d9c22765c3cd53_1740104342584.svg
[compshare-link]: https://www.compshare.cn/images-detail?ImageID=compshareImage-17jacgm4ju16&amp;ytag=HG_GPU_HivisionIDPhotos

&lt;!-- Á§æÂå∫È°πÁõÆÈìæÊé• --&gt;
[community-hivision-comfyui]: https://github.com/AIFSH/HivisionIDPhotos-ComfyUI
[community-hivision-wechat]: https://github.com/no1xuan/HivisionIDPhotos-wechat-weapp
[community-hivision-uniapp]: https://github.com/soulerror/HivisionIDPhotos-Uniapp
[community-hivision-cpp]: https://github.com/zjkhahah/HivisionIDPhotos-cpp
[community-hivision-windows-gui]: https://github.com/zhaoyun0071/HivisionIDPhotos-windows-GUI
[community-hivision-nas]: https://github.com/ONG-Leo/HivisionIDPhotos-NAS</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[comet-ml/opik]]></title>
            <link>https://github.com/comet-ml/opik</link>
            <guid>https://github.com/comet-ml/opik</guid>
            <pubDate>Thu, 15 May 2025 00:04:22 GMT</pubDate>
            <description><![CDATA[Debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/comet-ml/opik">comet-ml/opik</a></h1>
            <p>Debug, evaluate, and monitor your LLM applications, RAG systems, and agentic workflows with comprehensive tracing, automated evaluations, and production-ready dashboards.</p>
            <p>Language: Python</p>
            <p>Stars: 8,036</p>
            <p>Forks: 541</p>
            <p>Stars today: 195 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;&lt;b&gt;&lt;a href=&quot;README.md&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;readme_CN.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;readme_JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; | &lt;a href=&quot;readme_KO.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt;&lt;/b&gt;&lt;/div&gt;

&lt;h1 align=&quot;center&quot; style=&quot;border-bottom: none&quot;&gt;
    &lt;div&gt;
        &lt;a href=&quot;https://www.comet.com/site/products/opik/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=header_img&amp;utm_campaign=opik&quot;&gt;&lt;picture&gt;
            &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/comet-ml/opik/refs/heads/main/apps/opik-documentation/documentation/static/img/logo-dark-mode.svg&quot;&gt;
            &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://raw.githubusercontent.com/comet-ml/opik/refs/heads/main/apps/opik-documentation/documentation/static/img/opik-logo.svg&quot;&gt;
            &lt;img alt=&quot;Comet Opik logo&quot; src=&quot;https://raw.githubusercontent.com/comet-ml/opik/refs/heads/main/apps/opik-documentation/documentation/static/img/opik-logo.svg&quot; width=&quot;200&quot; /&gt;
        &lt;/picture&gt;&lt;/a&gt;
        &lt;br&gt;
        Opik
    &lt;/div&gt;
    Open source LLM evaluation framework&lt;br&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
From RAG chatbots to code assistants to complex agentic pipelines and beyond, build LLM systems that run better, faster, and cheaper with tracing, evaluations, and dashboards.
&lt;/p&gt;

&lt;div align=&quot;center&quot;&gt;

[![Python SDK](https://img.shields.io/pypi/v/opik)](https://pypi.org/project/opik/)
[![License](https://img.shields.io/github/license/comet-ml/opik)](https://github.com/comet-ml/opik/blob/main/LICENSE)
[![Build](https://github.com/comet-ml/opik/actions/workflows/build_apps.yml/badge.svg)](https://github.com/comet-ml/opik/actions/workflows/build_apps.yml)
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/opik_quickstart.ipynb&quot;&gt;

  &lt;!-- &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open Quickstart In Colab&quot;/&gt; --&gt;
&lt;/a&gt;

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://www.comet.com/site/products/opik/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=website_button&amp;utm_campaign=opik&quot;&gt;&lt;b&gt;Website&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://chat.comet.com&quot;&gt;&lt;b&gt;Slack community&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://x.com/Cometml&quot;&gt;&lt;b&gt;Twitter&lt;/b&gt;&lt;/a&gt; ‚Ä¢
    &lt;a href=&quot;https://www.comet.com/docs/opik/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=docs_button&amp;utm_campaign=opik&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt;
&lt;/p&gt;

![Opik thumbnail](readme-thumbnail.png)

## Important change on version 1.7.0
**Please check the change log [here](CHANGELOG.md).**

## üöÄ What is Opik?

Opik is an open-source platform for evaluating, testing and monitoring LLM applications. Built by [Comet](https://www.comet.com?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=what_is_opik_link&amp;utm_campaign=opik).

&lt;br&gt;

You can use Opik for:
* **Development:**

  * **Tracing:** Track all LLM calls and traces during development and production ([Quickstart](https://www.comet.com/docs/opik/quickstart/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=quickstart_link&amp;utm_campaign=opik), [Integrations](https://www.comet.com/docs/opik/tracing/integrations/overview/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=integrations_link&amp;utm_campaign=opik))

  * **Annotations:** Annotate your LLM calls by logging feedback scores using the [Python SDK](https://www.comet.com/docs/opik/tracing/annotate_traces/#annotating-traces-and-spans-using-the-sdk?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=sdk_link&amp;utm_campaign=opik) or the [UI](https://www.comet.com/docs/opik/tracing/annotate_traces/#annotating-traces-through-the-ui?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=ui_link&amp;utm_campaign=opik).

  * **Playground:** Try out different prompts and models in the [prompt playground](https://www.comet.com/docs/opik/prompt_engineering/playground).

* **Evaluation**: Automate the evaluation process of your LLM application:

    * **Datasets and Experiments**: Store test cases and run experiments ([Datasets](https://www.comet.com/docs/opik/evaluation/manage_datasets/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=datasets_link&amp;utm_campaign=opik), [Evaluate your LLM Application](https://www.comet.com/docs/opik/evaluation/evaluate_your_llm/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=eval_link&amp;utm_campaign=opik))

    * **LLM as a judge metrics**: Use Opik&#039;s LLM as a judge metric for complex issues like [hallucination detection](https://www.comet.com/docs/opik/evaluation/metrics/hallucination/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=hallucination_link&amp;utm_campaign=opik), [moderation](https://www.comet.com/docs/opik/evaluation/metrics/moderation/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=moderation_link&amp;utm_campaign=opik) and RAG evaluation ([Answer Relevance](https://www.comet.com/docs/opik/evaluation/metrics/answer_relevance/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=alex_link&amp;utm_campaign=opik), [Context Precision](https://www.comet.com/docs/opik/evaluation/metrics/context_precision/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=context_link&amp;utm_campaign=opik)

    * **CI/CD integration**: Run evaluations as part of your CI/CD pipeline using our [PyTest integration](https://www.comet.com/docs/opik/testing/pytest_integration/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=pytest_link&amp;utm_campaign=opik)

* **Production Monitoring**:
    
    * **Log all your production traces**: Opik has been designed to support high volumes of traces, making it easy to monitor your production applications. Even small deployments can ingest more than 40 million traces per day!
    
    * **Monitoring dashboards**: Review your feedback scores, trace count and tokens over time in the [Opik Dashboard](https://www.comet.com/docs/opik/production/production_monitoring/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=dashboard_link&amp;utm_campaign=opik).

    * **Online evaluation metrics**: Easily score all your production traces using LLM as a Judge metrics and identify any issues with your production LLM application thanks to [Opik&#039;s online evaluation metrics](https://www.comet.com/docs/opik/production/rules/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=dashboard_link&amp;utm_campaign=opik)

&gt; [!TIP]  
&gt; If you are looking for features that Opik doesn&#039;t have today, please raise a new [Feature request](https://github.com/comet-ml/opik/issues/new/choose) üöÄ

&lt;br&gt;

## üõ†Ô∏è Installation
Opik is available as a fully open source local installation or using Comet.com as a hosted solution.
The easiest way to get started with Opik is by creating a free Comet account at [comet.com](https://www.comet.com/signup?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=install&amp;utm_campaign=opik).

If you&#039;d like to self-host Opik, you can do so by cloning the repository and starting the platform using Docker Compose:

On Linux or Mac do:
```bash
# Clone the Opik repository
git clone https://github.com/comet-ml/opik.git

# Navigate to the repository
cd opik

# Start the Opik platform
./opik.sh
```

On Windows do:
```powershell
# Clone the Opik repository
git clone https://github.com/comet-ml/opik.git

# Navigate to the repository
cd opik

# Start the Opik platform
powershell -ExecutionPolicy ByPass -c &quot;.\opik.ps1&quot;
```

Use the `--help` or `--info` options to troubleshoot issues.

Once all is up and running, you can now visit [localhost:5173](http://localhost:5173) on your browser!

For more information about the different deployment options, please see our deployment guides:

| Installation methods | Docs link |
| ------------------- | --------- |
| Local instance | [![Local Deployment](https://img.shields.io/badge/Local%20Deployments-%232496ED?style=flat&amp;logo=docker&amp;logoColor=white)](https://www.comet.com/docs/opik/self-host/local_deployment?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=self_host_link&amp;utm_campaign=opik)
| Kubernetes | [![Kubernetes](https://img.shields.io/badge/Kubernetes-%23326ce5.svg?&amp;logo=kubernetes&amp;logoColor=white)](https://www.comet.com/docs/opik/self-host/kubernetes/#kubernetes-installation?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=kubernetes_link&amp;utm_campaign=opik)


## üèÅ Get Started

To get started, you will need to first install the Python SDK:

```bash
pip install opik
```

Once the SDK is installed, you can configure it by running the `opik configure` command:

```bash
opik configure
```

This will allow you to configure Opik locally by setting the correct local server address or if you&#039;re using the Cloud platform by setting the API Key

&gt; [!TIP]  
&gt; You can also call the `opik.configure(use_local=True)` method from your Python code to configure the SDK to run on the local installation.

You are now ready to start logging traces using the [Python SDK](https://www.comet.com/docs/opik/python-sdk-reference/?from=llm&amp;utm_source=opik&amp;utm_medium=github&amp;utm_content=sdk_link2&amp;utm_campaign=opik).

### üìù Logging Traces

The easiest way to get started is to use one of our integrations. Opik supports:

| Integration | Description                                                                  | Documentation                                                                                                                                                      | Try in Colab                                                                                                                                                                                                                      |
|-------------|------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| OpenAI      | Log traces for all OpenAI LLM calls                                          | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/openai/?utm_source=opik&amp;utm_medium=github&amp;utm_content=openai_link&amp;utm_campaign=opik)          | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/openai.ipynb)      |
| LiteLLM     | Call any LLM model using the OpenAI format                                   | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/litellm/?utm_source=opik&amp;utm_medium=github&amp;utm_content=openai_link&amp;utm_campaign=opik)                                                                                                                  | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/litellm.ipynb)     |
| LangChain   | Log traces for all LangChain LLM calls                                       | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/langchain/?utm_source=opik&amp;utm_medium=github&amp;utm_content=langchain_link&amp;utm_campaign=opik)    | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/langchain.ipynb)   |
| Haystack    | Log traces for all Haystack calls                                            | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/haystack/?utm_source=opik&amp;utm_medium=github&amp;utm_content=haystack_link&amp;utm_campaign=opik)      | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/haystack.ipynb)    |
| Anthropic   | Log traces for all Anthropic LLM calls                                       | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/anthropic?utm_source=opik&amp;utm_medium=github&amp;utm_content=anthropic_link&amp;utm_campaign=opik)     | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/anthropic.ipynb)   |
| Bedrock     | Log traces for all Bedrock LLM calls                                         | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/bedrock?utm_source=opik&amp;utm_medium=github&amp;utm_content=bedrock_link&amp;utm_campaign=opik)         | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/bedrock.ipynb)     |
| CrewAI      | Log traces for all CrewAI calls                                              | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/crewai?utm_source=opik&amp;utm_medium=github&amp;utm_content=crewai_link&amp;utm_campaign=opik)           | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/crewai.ipynb)      |
| DeepSeek    | Log traces for all DeepSeek LLM calls                                        | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/deepseek?utm_source=opik&amp;utm_medium=github&amp;utm_content=deepseek_link&amp;utm_campaign=opik)       | |
| DSPy        | Log traces for all DSPy runs                                                 | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/dspy?utm_source=opik&amp;utm_medium=github&amp;utm_content=dspy_link&amp;utm_campaign=opik)               | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/dspy.ipynb)        |
| Gemini      | Log traces for all Gemini LLM calls                                          | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/gemini?utm_source=opik&amp;utm_medium=github&amp;utm_content=gemini_link&amp;utm_campaign=opik)           | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/gemini.ipynb)      |
| Groq        | Log traces for all Groq LLM calls                                            | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/groq?utm_source=opik&amp;utm_medium=github&amp;utm_content=groq_link&amp;utm_campaign=opik)               | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/groq.ipynb)        |
| Guardrails  | Log traces for all Guardrails validations                                    | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/guardrails/?utm_source=opik&amp;utm_medium=github&amp;utm_content=guardrails_link&amp;utm_campaign=opik)    | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/guardrails-ai.ipynb)   |
| Instructor  | Log traces for all LLM calls made with Instructor                            | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/instructor/?utm_source=opik&amp;utm_medium=github&amp;utm_content=instructor_link&amp;utm_campaign=opik)    | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/instructor.ipynb)   |
| LangGraph   | Log traces for all LangGraph executions                                      | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/langgraph/?utm_source=opik&amp;utm_medium=github&amp;utm_content=langchain_link&amp;utm_campaign=opik)    | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/langgraph.ipynb)   |
| LlamaIndex  | Log traces for all LlamaIndex LLM calls                                      | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/llama_index?utm_source=opik&amp;utm_medium=github&amp;utm_content=llama_index_link&amp;utm_campaign=opik) | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/llama-index.ipynb) |
| Ollama      | Log traces for all Ollama LLM calls                                          | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/ollama?utm_source=opik&amp;utm_medium=github&amp;utm_content=ollama_link&amp;utm_campaign=opik)           | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/ollama.ipynb)      |
| Predibase   | Fine-tune and serve open-source Large Language Models                        | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/predibase?utm_source=opik&amp;utm_medium=github&amp;utm_content=predibase_link&amp;utm_campaign=opik)     | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/predibase.ipynb)   |
| Pydantic AI | Fine-tune and serve open-source Large Language Models                        | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/predibase?utm_source=opik&amp;utm_medium=github&amp;utm_content=predibase_link&amp;utm_campaign=opik)     | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/predibase.ipynb)   |
| Ragas       | PydanticAI is a Python agent framework designed to build production apps     | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/pydantic-ai?utm_source=opik&amp;utm_medium=github&amp;utm_content=pydantic_ai_link&amp;utm_campaign=opik) | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/pydantic-ai.ipynb) |
| watsonx     | Log traces for all watsonx LLM calls                                         | [Documentation](https://www.comet.com/docs/opik/tracing/integrations/watsonx?utm_source=opik&amp;utm_medium=github&amp;utm_content=watsonx_link&amp;utm_campaign=opik)         | [![Open Quickstart In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/comet-ml/opik/blob/master/apps/opik-documentation/documentation/docs/cookbook/watsonx.ipynb)     |

&gt; [!TIP]  
&gt; If the framework you are using is not listed above, feel free to [open an issue](https://github.com/comet-ml/opik/issues) or submit a PR with the integration.

If you are not using any of the frameworks above, you can also use the `track` function decorator to [log t

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[mlflow/mlflow]]></title>
            <link>https://github.com/mlflow/mlflow</link>
            <guid>https://github.com/mlflow/mlflow</guid>
            <pubDate>Thu, 15 May 2025 00:04:21 GMT</pubDate>
            <description><![CDATA[Open source platform for the machine learning lifecycle]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mlflow/mlflow">mlflow/mlflow</a></h1>
            <p>Open source platform for the machine learning lifecycle</p>
            <p>Language: Python</p>
            <p>Stars: 20,506</p>
            <p>Forks: 4,520</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre># MLflow: A Machine Learning Lifecycle Platform

[![Latest Docs](https://img.shields.io/badge/docs-latest-success.svg?style=for-the-badge)](https://mlflow.org/docs/latest/index.html)
[![Apache 2 License](https://img.shields.io/badge/license-Apache%202-brightgreen.svg?style=for-the-badge&amp;logo=apache)](https://github.com/mlflow/mlflow/blob/master/LICENSE.txt)
[![Total Downloads](https://img.shields.io/pypi/dw/mlflow?style=for-the-badge&amp;logo=pypi&amp;logoColor=white)](https://pepy.tech/project/mlflow)
[![Slack](https://img.shields.io/badge/slack-@mlflow--users-CF0E5B.svg?logo=slack&amp;logoColor=white&amp;labelColor=3F0E40&amp;style=for-the-badge)](https://mlflow.org/community/#slack)
[![Twitter](https://img.shields.io/twitter/follow/MLflow?style=for-the-badge&amp;labelColor=00ACEE&amp;logo=twitter&amp;logoColor=white)](https://twitter.com/MLflow)

MLflow is an open-source platform, purpose-built to assist machine learning practitioners and teams in handling the complexities of the machine learning process. MLflow focuses on the full lifecycle for machine learning projects, ensuring that each phase is manageable, traceable, and reproducible

---

The core components of MLflow are:

- [Experiment Tracking](https://mlflow.org/docs/latest/tracking.html) üìù: A set of APIs to log models, params, and results in ML experiments and compare them using an interactive UI.
- [Model Packaging](https://mlflow.org/docs/latest/models.html) üì¶: A standard format for packaging a model and its metadata, such as dependency versions, ensuring reliable deployment and strong reproducibility.
- [Model Registry](https://mlflow.org/docs/latest/model-registry.html) üíæ: A centralized model store, set of APIs, and UI, to collaboratively manage the full lifecycle of MLflow Models.
- [Serving](https://mlflow.org/docs/latest/deployment/index.html) üöÄ: Tools for seamless model deployment to batch and real-time scoring on platforms like Docker, Kubernetes, Azure ML, and AWS SageMaker.
- [Evaluation](https://mlflow.org/docs/latest/model-evaluation/index.html) üìä: A suite of automated model evaluation tools, seamlessly integrated with experiment tracking to record model performance and visually compare results across multiple models.
- [Observability](https://mlflow.org/docs/latest/llms/tracing/index.html) üîç: Tracing integrations with various GenAI libraries and a Python SDK for manual instrumentation, offering smoother debugging experience and supporting online monitoring.

&lt;img src=&quot;https://mlflow.org/img/hero.png&quot; alt=&quot;MLflow Hero&quot; width=100%&gt;

## Installation

To install the MLflow Python package, run the following command:

```
pip install mlflow
```

Alternatively, you can install MLflow from on different package hosting platforms:

|               |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| PyPI          | [![PyPI - mlflow](https://img.shields.io/pypi/v/mlflow.svg?style=for-the-badge&amp;logo=pypi&amp;logoColor=white&amp;label=mlflow)](https://pypi.org/project/mlflow/) [![PyPI - mlflow-skinny](https://img.shields.io/pypi/v/mlflow-skinny.svg?style=for-the-badge&amp;logo=pypi&amp;logoColor=white&amp;label=mlflow-skinny)](https://pypi.org/project/mlflow-skinny/)                                                                                                                                                                                                                                                                                                                                          |
| conda-forge   | [![Conda - mlflow](https://img.shields.io/conda/vn/conda-forge/mlflow.svg?style=for-the-badge&amp;logo=anaconda&amp;label=mlflow)](https://anaconda.org/conda-forge/mlflow) [![Conda - mlflow-skinny](https://img.shields.io/conda/vn/conda-forge/mlflow.svg?style=for-the-badge&amp;logo=anaconda&amp;label=mlflow-skinny)](https://anaconda.org/conda-forge/mlflow-skinny)                                                                                                                                                                                                                                                                                                                             |
| CRAN          | [![CRAN - mlflow](https://img.shields.io/cran/v/mlflow.svg?style=for-the-badge&amp;logo=r&amp;label=mlflow)](https://cran.r-project.org/package=mlflow)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| Maven Central | [![Maven Central - mlflow-client](https://img.shields.io/maven-central/v/org.mlflow/mlflow-client.svg?style=for-the-badge&amp;logo=apache-maven&amp;label=mlflow-client)](https://mvnrepository.com/artifact/org.mlflow/mlflow-client) [![Maven Central - mlflow-parent](https://img.shields.io/maven-central/v/org.mlflow/mlflow-parent.svg?style=for-the-badge&amp;logo=apache-maven&amp;label=mlflow-parent)](https://mvnrepository.com/artifact/org.mlflow/mlflow-parent) [![Maven Central - mlflow-spark](https://img.shields.io/maven-central/v/org.mlflow/mlflow-spark.svg?style=for-the-badge&amp;logo=apache-maven&amp;label=mlflow-spark)](https://mvnrepository.com/artifact/org.mlflow/mlflow-spark) |

## Documentation üìò

Official documentation for MLflow can be found at [here](https://mlflow.org/docs/latest/index.html).

## Running Anywhere üåê

You can run MLflow on many different environments, including local development, Amazon SageMaker, AzureML, and Databricks. Please refer to [this guidance](https://mlflow.org/docs/latest/index.html#running-mlflow-anywhere) for how to setup MLflow on your environment.

## Usage

### Experiment Tracking ([Doc](https://mlflow.org/docs/latest/tracking.html))

The following examples trains a simple regression model with scikit-learn, while enabling MLflow&#039;s [autologging](https://mlflow.org/docs/latest/tracking/autolog.html) feature for experiment tracking.

```python
import mlflow

from sklearn.model_selection import train_test_split
from sklearn.datasets import load_diabetes
from sklearn.ensemble import RandomForestRegressor

# Enable MLflow&#039;s automatic experiment tracking for scikit-learn
mlflow.sklearn.autolog()

# Load the training dataset
db = load_diabetes()
X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)

rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)
# MLflow triggers logging automatically upon model fitting
rf.fit(X_train, y_train)
```

Once the above code finishes, run the following command in a separate terminal and access the MLflow UI via the printed URL. An MLflow **Run** should be automatically created, which tracks the training dataset, hyper parameters, performance metrics, the trained model, dependencies, and even more.

```
mlflow ui
```

### Serving Models ([Doc](https://mlflow.org/docs/latest/deployment/index.html))

You can deploy the logged model to a local inference server by a one-line command using the MLflow CLI. Visit the documentation for how to deploy models to other hosting platforms.

```bash
mlflow models serve --model-uri runs:/&lt;run-id&gt;/model
```

### Evaluating Models ([Doc](https://mlflow.org/docs/latest/model-evaluation/index.html))

The following example runs automatic evaluation for question-answering tasks with several built-in metrics.

```python
import mlflow
import pandas as pd

# Evaluation set contains (1) input question (2) model outputs (3) ground truth
df = pd.DataFrame(
    {
        &quot;inputs&quot;: [&quot;What is MLflow?&quot;, &quot;What is Spark?&quot;],
        &quot;outputs&quot;: [
            &quot;MLflow is an innovative fully self-driving airship powered by AI.&quot;,
            &quot;Sparks is an American pop and rock duo formed in Los Angeles.&quot;,
        ],
        &quot;ground_truth&quot;: [
            &quot;MLflow is an open-source platform for managing the end-to-end machine learning (ML) &quot;
            &quot;lifecycle.&quot;,
            &quot;Apache Spark is an open-source, distributed computing system designed for big data &quot;
            &quot;processing and analytics.&quot;,
        ],
    }
)
eval_dataset = mlflow.data.from_pandas(
    df, predictions=&quot;outputs&quot;, targets=&quot;ground_truth&quot;
)

# Start an MLflow Run to record the evaluation results to
with mlflow.start_run(run_name=&quot;evaluate_qa&quot;):
    # Run automatic evaluation with a set of built-in metrics for question-answering models
    results = mlflow.evaluate(
        data=eval_dataset,
        model_type=&quot;question-answering&quot;,
    )

print(results.tables[&quot;eval_results_table&quot;])
```

### Observability ([Doc](https://mlflow.org/docs/latest/llms/tracing/index.html))

MLflow Tracing provides LLM observability for various GenAI libraries such as OpenAI, LangChain, LlamaIndex, DSPy, AutoGen, and more. To enable auto-tracing, call `mlflow.xyz.autolog()` before running your models. Refer to the documentation for customization and manual instrumentation.

```python
import mlflow
from openai import OpenAI

# Enable tracing for OpenAI
mlflow.openai.autolog()

# Query OpenAI LLM normally
response = OpenAI().chat.completions.create(
    model=&quot;gpt-4o-mini&quot;,
    messages=[{&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;Hi!&quot;}],
    temperature=0.1,
)
```

Then navigate to the &quot;Traces&quot; tab in the MLflow UI to find the trace records OpenAI query.

## Community

- For help or questions about MLflow usage (e.g. &quot;how do I do X?&quot;) visit the [docs](https://mlflow.org/docs/latest/index.html)
  or [Stack Overflow](https://stackoverflow.com/questions/tagged/mlflow).
- Alternatively, you can ask the question to our AI-powered chat bot. Visit the doc website and click on the **&quot;Ask AI&quot;** button at the right bottom to start chatting with the bot.
- To report a bug, file a documentation issue, or submit a feature request, please [open a GitHub issue](https://github.com/mlflow/mlflow/issues/new/choose).
- For release announcements and other discussions, please subscribe to our mailing list (mlflow-users@googlegroups.com)
  or join us on [Slack](https://mlflow.org/slack).

## Contributing

We happily welcome contributions to MLflow! We are also seeking contributions to items on the
[MLflow Roadmap](https://github.com/mlflow/mlflow/milestone/3). Please see our
[contribution guide](CONTRIBUTING.md) to learn more about contributing to MLflow.

## Core Members

MLflow is currently maintained by the following core members with significant contributions from hundreds of exceptionally talented community members.

- [Ben Wilson](https://github.com/BenWilson2)
- [Corey Zumar](https://github.com/dbczumar)
- [Daniel Lok](https://github.com/daniellok-db)
- [Gabriel Fu](https://github.com/gabrielfu)
- [Harutaka Kawamura](https://github.com/harupy)
- [Serena Ruan](https://github.com/serena-ruan)
- [Weichen Xu](https://github.com/WeichenXu123)
- [Yuki Watanabe](https://github.com/B-Step62)
- [Tomu Hirata](https://github.com/TomeHirata)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Azure/Azure-Sentinel]]></title>
            <link>https://github.com/Azure/Azure-Sentinel</link>
            <guid>https://github.com/Azure/Azure-Sentinel</guid>
            <pubDate>Thu, 15 May 2025 00:04:20 GMT</pubDate>
            <description><![CDATA[Cloud-native SIEM for intelligent security analytics for your entire enterprise.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Azure/Azure-Sentinel">Azure/Azure-Sentinel</a></h1>
            <p>Cloud-native SIEM for intelligent security analytics for your entire enterprise.</p>
            <p>Language: Python</p>
            <p>Stars: 5,039</p>
            <p>Forks: 3,181</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>
# Microsoft Sentinel and Microsoft 365 Defender 
Welcome to the unified Microsoft Sentinel and Microsoft 365 Defender repository! This repository contains out of the box detections, exploration queries, hunting queries, workbooks, playbooks and much more to help you get ramped up with Microsoft Sentinel and provide you security content to secure your environment and hunt for threats. The hunting queries also include Microsoft 365 Defender hunting queries for advanced hunting scenarios in both Microsoft 365 Defender and Microsoft Sentinel. You can also submit to [issues](https://github.com/Azure/Azure-Sentinel/issues) for any samples or resources you would like to see here as you onboard to Microsoft Sentinel. This repository welcomes contributions and refer to this repository&#039;s [wiki](https://aka.ms/threathunters) to get started. For questions and feedback, please contact [AzureSentinel@microsoft.com](AzureSentinel@microsoft.com) 

# Resources
* [Microsoft Sentinel documentation](https://go.microsoft.com/fwlink/?linkid=2073774&amp;clcid=0x409)
* [Microsoft 365 Defender documentation](https://docs.microsoft.com/microsoft-365/security/defender/microsoft-365-defender?view=o365-worldwide)
* [Security Community Webinars](https://aka.ms/securitywebinars)
* [Getting started with GitHub](https://help.github.com/en#dotcom)

We value your feedback. Here are some channels to help surface your questions or feedback:
1. General product specific Q&amp;A for SIEM and SOAR - Join in the [Microsoft Sentinel Tech Community conversations](https://techcommunity.microsoft.com/t5/microsoft-sentinel/bd-p/MicrosoftSentinel)
2. General product specific Q&amp;A for XDR - Join in the [Microsoft 365 Defender Tech Community conversations](https://techcommunity.microsoft.com/t5/microsoft-365-defender/bd-p/MicrosoftThreatProtection)
3. Product specific feature requests - Upvote or post new on [Microsoft Sentinel feedback forums](https://feedback.azure.com/d365community/forum/37638d17-0625-ec11-b6e6-000d3a4f07b8)
4. Report product or contribution bugs - File a GitHub Issue using [Bug template](https://github.com/Azure/Azure-Sentinel/issues/new?assignees=&amp;labels=&amp;template=bug_report.md&amp;title=)
5. General feedback on community and contribution process - File a GitHub Issue using [Feature Request template](https://github.com/Azure/Azure-Sentinel/issues/new?assignees=&amp;labels=&amp;template=feature_request.md&amp;title=)


# Contribution guidelines

This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit https://cla.microsoft.com.

## Add in your new or updated contributions to GitHub
Note: If you are a first time contributor to this repository, [General GitHub Fork the repo guidance](https://docs.github.com/github/getting-started-with-github/fork-a-repo) before cloning or [Specific steps for the Sentinel repo](https://github.com/Azure/Azure-Sentinel/blob/master/GettingStarted.md). 

## General Steps
Brand new or update to a contribution via these methods:
* Submit for review directly on GitHub website 
    * Browse to the folder you want to upload your file to
    * Choose Upload Files and browse to your file. 
    * You will be required to create your own branch and then submit the Pull Request for review.
* Use [GitHub Desktop](https://docs.github.com/en/desktop/overview/getting-started-with-github-desktop) or [Visual Studio](https://visualstudio.microsoft.com/vs/) or [VSCode](https://code.visualstudio.com/?wt.mc_id=DX_841432)
    * [Fork the repo](https://docs.github.com/github/getting-started-with-github/fork-a-repo)  
    * [Clone the repo](https://help.github.com/en/github/creating-cloning-and-archiving-repositories/cloning-a-repository)
    * [Create your own branch](https://help.github.com/en/desktop/contributing-to-projects/creating-a-branch-for-your-work)
    * Do your additions/updates in GitHub Desktop
    * Be sure to merge master back to your branch before you push. 
    * [Push your changes to GitHub](https://help.github.com/en/github/using-git/pushing-commits-to-a-remote-repository)

## Pull Request
* After you push your changes, you will need to submit the [Pull Request (PR)](https://help.github.com/en/github/collaborating-with-issues-and-pull-requests/about-pull-requests)
* Details about the Proposed Changes are required, be sure to include a minimal level of detail so a review can clearly understand the reason for the change and what he change is related to in the code.
* After submission, check the [Pull Request](https://github.com/Azure/Azure-Sentinel/pulls) for comments
* Make changes as suggested and update your branch or explain why no change is needed. Resolve the comment when done.

### Pull Request Detection Template Structure Validation Check
As part of the PR checks we run a structure validation to make sure all required parts of the YAML structure are included.  For Detections, there is a new section that must be included.  See the [contribution guidelines](https://github.com/Azure/Azure-Sentinel/wiki/Contribute-to-Sentinel-GitHub-Community-of-Queries#now-onto-the-how) for more information.  If this section or any other required section is not included, then a validation error will occur similar to the below.
The example is specifically if the YAML is missing the entityMappings section:

```
A total of 1 test files matched the specified pattern.
[xUnit.net 00:00:00.95]     Kqlvalidations.Tests.DetectionTemplateStructureValidationTests.Validate_DetectionTemplates_HaveValidTemplateStructure(detectionsYamlFileName: &quot;ExcessiveBlockedTrafficGeneratedbyUser.yaml&quot;) [FAIL]
  X Kqlvalidations.Tests.DetectionTemplateStructureValidationTests.Validate_DetectionTemplates_HaveValidTemplateStructure(detectionsYamlFileName: &quot;ExcessiveBlockedTrafficGeneratedbyUser.yaml&quot;) [104ms]
  Error Message:
   Expected object to be &lt;null&gt;, but found System.ComponentModel.DataAnnotations.ValidationException with message &quot;An old mapping for entity &#039;AccountCustomEntity&#039; does not have a matching new mapping entry.&quot;
```

### Pull Request KQL Validation Check
As part of the PR checks we run a syntax validation of the KQL queries defined in the template. If this check fails go to Azure Pipeline (by pressing on the errors link on the checks tab in your PR)
![Azurepipeline](.github/Media/Azurepipeline.png)
In the pipeline you can see which test failed and what is the cause:
![Pipeline Tests Tab](.github/Media/PipelineTestsTab.png)

Example error message:
```
A total of 1 test files matched the specified pattern.
[xUnit.net 00:00:01.81]     Kqlvalidations.Tests.KqlValidationTests.Validate_DetectionQueries_HaveValidKql(detectionsYamlFileName: &quot;ExcessiveBlockedTrafficGeneratedbyUser.yaml&quot;) [FAIL]
  X Kqlvalidations.Tests.KqlValidationTests.Validate_DetectionQueries_HaveValidKql(detectionsYamlFileName: &quot;ExcessiveBlockedTrafficGeneratedbyUser.yaml&quot;) [21ms]
  Error Message:
   Template Id:fa0ab69c-7124-4f62-acdd-61017cf6ce89 is not valid Errors:The name &#039;SymantecEndpointProtection&#039; does not refer to any known table, tabular variable or function., Code: &#039;KS204&#039;, Severity: &#039;Error&#039;, Location: &#039;67..93&#039;,The name &#039;SymantecEndpointProtection&#039; does not refer to any known table, tabular variable or function., Code: &#039;KS204&#039;, Severity: &#039;Error&#039;, Location: &#039;289..315&#039;
```
If you are using custom logs table (a table which is not defined on all workspaces by default) you should verify
your table schema is defined in json file in the folder *Azure-Sentinel\\.script\tests\KqlvalidationsTests\CustomTables*

**Example for table tablexyz.json**
```json
{
  &quot;Name&quot;: &quot;tablexyz&quot;,
  &quot;Properties&quot;: [
    {
      &quot;Name&quot;: &quot;SomeDateTimeColumn&quot;,
      &quot;Type&quot;: &quot;DateTime&quot;
    },
    {
      &quot;Name&quot;: &quot;SomeStringColumn&quot;,
      &quot;Type&quot;: &quot;String&quot;
    },
    {
      &quot;Name&quot;: &quot;SomeDynamicColumn&quot;,
      &quot;Type&quot;: &quot;Dynamic&quot;
    }
  ]
}
```
### Run KQL Validation Locally
In order to run the KQL validation before submitting Pull Request in you local machine:
* You need to have **.Net Core 3.1 SDK** installed [How to download .Net](https://dotnet.microsoft.com/download) (Supports all platforms)
* Open Shell and navigate to  `Azure-Sentinel\\.script\tests\KqlvalidationsTests\`
* Execute `dotnet test`

Example of output (in Ubuntu):
```
Welcome to .NET Core 3.1!
---------------------
SDK Version: 3.1.403

Telemetry
---------
The .NET Core tools collect usage data in order to help us improve your experience. The data is anonymous. It is collected by Microsoft and shared with the community. You can opt-out of telemetry by setting the DOTNET_CLI_TELEMETRY_OPTOUT environment variable to &#039;1&#039; or &#039;true&#039; using your favorite shell.

Read more about .NET Core CLI Tools telemetry: https://aka.ms/dotnet-cli-telemetry

----------------
Explore documentation: https://aka.ms/dotnet-docs
Report issues and find source on GitHub: https://github.com/dotnet/core
Find out what&#039;s new: https://aka.ms/dotnet-whats-new
Learn about the installed HTTPS developer cert: https://aka.ms/aspnet-core-https
Use &#039;dotnet --help&#039; to see available commands or visit: https://aka.ms/dotnet-cli-docs
Write your first app: https://aka.ms/first-net-core-app
--------------------------------------------------------------------------------------
Test run for /mnt/c/git/Azure-Sentinel/.script/tests/KqlvalidationsTests/bin/Debug/netcoreapp3.1/Kqlvalidations.Tests.dll(.NETCoreApp,Version=v3.1)
Microsoft (R) Test Execution Command Line Tool Version 16.7.0
Copyright (c) Microsoft Corporation.  All rights reserved.

Starting test execution, please wait...

A total of 1 test files matched the specified pattern.

Test Run Successful.
Total tests: 171
     Passed: 171
 Total time: 25.7973 Seconds
```

### Detection schema validation tests
Similarly to KQL Validation, there is an automatic validation of the schema of a detection.
The schema validation includes the detection&#039;s frequency and period, the detection&#039;s trigger type and threshold, validity of connectors Ids ([valid connectors Ids list](https://github.com/Azure/Azure-Sentinel/blob/master/.script/tests/detectionTemplateSchemaValidation/ValidConnectorIds.json)), etc.
A wrong format or missing attributes will result with an informative check failure, which should guide you through the resolution of the issue, but make sure to look into the format of already approved detection.

### Run Detection Schema Validation Locally
In order to run the KQL validation before submitting Pull Request in you local machine:
* You need to have **.Net Core 3.1 SDK** installed [How to download .Net](https://dotnet.microsoft.com/download) (Supports all platforms)
* Open Shell and navigate to  `Azure-Sentinel\\.script\tests\DetectionTemplateSchemaValidation\`
* Execute `dotnet test`


When you submit a pull request, a CLA-bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., label, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.

This project has adopted the [Microsoft Open Source Code of Conduct](https://opensource.microsoft.com/codeofconduct/).
For more information see the [Code of Conduct FAQ](https://opensource.microsoft.com/codeofconduct/faq/) or
contact [opencode@microsoft.com](mailto:opencode@microsoft.com) with any additional questions or comments.

For information on what you can contribute and further details, refer to the [&quot;get started&quot;](https://github.com/Azure/Azure-Sentinel/wiki#get-started) section on the project&#039;s [wiki](https://aka.ms/threathunters).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>