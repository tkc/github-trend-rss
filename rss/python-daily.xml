<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Fri, 06 Feb 2026 00:05:10 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[openai/skills]]></title>
            <link>https://github.com/openai/skills</link>
            <guid>https://github.com/openai/skills</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:10 GMT</pubDate>
            <description><![CDATA[Skills Catalog for Codex]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/skills">openai/skills</a></h1>
            <p>Skills Catalog for Codex</p>
            <p>Language: Python</p>
            <p>Stars: 4,255</p>
            <p>Forks: 245</p>
            <p>Stars today: 621 stars today</p>
            <h2>README</h2><pre># Agent Skills

Agent Skills are folders of instructions, scripts, and resources that AI agents can discover and use to perform at specific tasks. Write once, use everywhere.

Codex uses skills to help package capabilities that teams and individuals can use to complete specific tasks in a repeatable way. This repository catalogs skills for use and distribution with Codex.

Learn more:
- [Using skills in Codex](https://developers.openai.com/codex/skills)
- [Create custom skills in Codex](https://developers.openai.com/codex/skills/create-skill)
- [Agent Skills open standard](https://agentskills.io)

## Installing a skill

Skills in [`.system`](skills/.system/) are automatically installed in the latest version of Codex.

To install [curated](skills/.curated/) or [experimental](skills/.experimental/) skills, you can use the `$skill-installer` inside Codex.

Curated skills can be installed by name (defaults to `skills/.curated`):

```
$skill-installer gh-address-comments
```

For experimental skills, specify the skill folder. For example:

```
$skill-installer install the create-plan skill from the .experimental folder
```

Or provide the GitHub directory URL:

```
$skill-installer install https://github.com/openai/skills/tree/main/skills/.experimental/create-plan
```

After installing a skill, restart Codex to pick up new skills.

## License

The license of an individual skill can be found directly inside the skill&#039;s directory inside the `LICENSE.txt` file.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[topoteretes/cognee]]></title>
            <link>https://github.com/topoteretes/cognee</link>
            <guid>https://github.com/topoteretes/cognee</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:09 GMT</pubDate>
            <description><![CDATA[Memory for AI Agents in 6 lines of code]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/topoteretes/cognee">topoteretes/cognee</a></h1>
            <p>Memory for AI Agents in 6 lines of code</p>
            <p>Language: Python</p>
            <p>Stars: 11,827</p>
            <p>Forks: 1,157</p>
            <p>Stars today: 74 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/topoteretes/cognee&quot;&gt;
    &lt;img src=&quot;https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/dev/assets/cognee-logo-transparent.png&quot; alt=&quot;Cognee Logo&quot; height=&quot;60&quot;&gt;
  &lt;/a&gt;

  &lt;br /&gt;

  Cognee - Accurate and Persistent AI Memory

  &lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.youtube.com/watch?v=1bezuvLwJmw&amp;t=2s&quot;&gt;Demo&lt;/a&gt;
  .
  &lt;a href=&quot;https://docs.cognee.ai/&quot;&gt;Docs&lt;/a&gt;
  .
  &lt;a href=&quot;https://cognee.ai&quot;&gt;Learn More&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://discord.gg/NQPKmU5CCg&quot;&gt;Join Discord&lt;/a&gt;
  ¬∑
  &lt;a href=&quot;https://www.reddit.com/r/AIMemory/&quot;&gt;Join r/AIMemory&lt;/a&gt;
  .
  &lt;a href=&quot;https://github.com/topoteretes/cognee-community&quot;&gt;Community Plugins &amp; Add-ons&lt;/a&gt;
  &lt;/p&gt;


  [![GitHub forks](https://img.shields.io/github/forks/topoteretes/cognee.svg?style=social&amp;label=Fork&amp;maxAge=2592000)](https://GitHub.com/topoteretes/cognee/network/)
  [![GitHub stars](https://img.shields.io/github/stars/topoteretes/cognee.svg?style=social&amp;label=Star&amp;maxAge=2592000)](https://GitHub.com/topoteretes/cognee/stargazers/)
  [![GitHub commits](https://badgen.net/github/commits/topoteretes/cognee)](https://GitHub.com/topoteretes/cognee/commit/)
  [![GitHub tag](https://badgen.net/github/tag/topoteretes/cognee)](https://github.com/topoteretes/cognee/tags/)
  [![Downloads](https://static.pepy.tech/badge/cognee)](https://pepy.tech/project/cognee)
  [![License](https://img.shields.io/github/license/topoteretes/cognee?colorA=00C586&amp;colorB=000000)](https://github.com/topoteretes/cognee/blob/main/LICENSE)
  [![Contributors](https://img.shields.io/github/contributors/topoteretes/cognee?colorA=00C586&amp;colorB=000000)](https://github.com/topoteretes/cognee/graphs/contributors)
  &lt;a href=&quot;https://github.com/sponsors/topoteretes&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Sponsor-‚ù§Ô∏è-ff69b4.svg&quot; alt=&quot;Sponsor&quot;&gt;&lt;/a&gt;

&lt;p&gt;
  &lt;a href=&quot;https://www.producthunt.com/posts/cognee?embed=true&amp;utm_source=badge-top-post-badge&amp;utm_medium=badge&amp;utm_souce=badge-cognee&quot; target=&quot;_blank&quot; style=&quot;display:inline-block; margin-right:10px;&quot;&gt;
    &lt;img src=&quot;https://api.producthunt.com/widgets/embed-image/v1/top-post-badge.svg?post_id=946346&amp;theme=light&amp;period=daily&amp;t=1744472480704&quot; alt=&quot;cognee - Memory&amp;#0032;for&amp;#0032;AI&amp;#0032;Agents&amp;#0032;&amp;#0032;in&amp;#0032;5&amp;#0032;lines&amp;#0032;of&amp;#0032;code | Product Hunt&quot; width=&quot;250&quot; height=&quot;54&quot; /&gt;
  &lt;/a&gt;

  &lt;a href=&quot;https://trendshift.io/repositories/13955&quot; target=&quot;_blank&quot; style=&quot;display:inline-block;&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/13955&quot; alt=&quot;topoteretes%2Fcognee | Trendshift&quot; width=&quot;250&quot; height=&quot;55&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

Use your data to build personalized and dynamic memory for AI Agents. Cognee lets you replace RAG with scalable and modular ECL (Extract, Cognify, Load) pipelines.

  &lt;p align=&quot;center&quot;&gt;
  üåê Available Languages
  :
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=de&quot;&gt;Deutsch&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=es&quot;&gt;Espa√±ol&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=fr&quot;&gt;Fran√ßais&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=ja&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; |
  &lt;a href=&quot;README_ko.md&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=pt&quot;&gt;Portugu√™s&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=ru&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; |
  &lt;a href=&quot;https://www.readme-i18n.com/topoteretes/cognee?lang=zh&quot;&gt;‰∏≠Êñá&lt;/a&gt;
  &lt;/p&gt;


&lt;div style=&quot;text-align: center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/topoteretes/cognee/refs/heads/main/assets/cognee_benefits.png&quot; alt=&quot;Why cognee?&quot; width=&quot;50%&quot; /&gt;
&lt;/div&gt;
&lt;/div&gt;




## About Cognee

Cognee is an open-source tool and platform that transforms your raw data into persistent and dynamic AI memory for Agents. It combines vector search with graph databases to make your documents both searchable by meaning and connected by relationships.
Cognee offers default memory creation and search which we describe bellow. But with Cognee you can build your own!


:star: _Help us reach more developers and grow the cognee community. Star this repo!_


### Cognee Open Source:

- Interconnects any type of data ‚Äî including past conversations, files, images, and audio transcriptions
- Replaces traditional RAG systems with a unified memory layer built on graphs and vectors
- Reduces developer effort and infrastructure cost while improving quality and precision
- Provides Pythonic data pipelines for ingestion from 30+ data sources
- Offers high customizability through user-defined tasks, modular pipelines, and built-in search endpoints


## Basic Usage &amp; Feature Guide

To learn more, [check out this short, end-to-end Colab walkthrough](https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing) of Cognee&#039;s core features.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/12Vi9zID-M3fpKpKiaqDBvkk98ElkRPWy?usp=sharing)

## Quickstart

Let‚Äôs try Cognee in just a few lines of code. For detailed setup and configuration, see the [Cognee Docs](https://docs.cognee.ai/getting-started/installation#environment-configuration).

### Prerequisites

- Python 3.10 to 3.13

### Step 1: Install Cognee

You can install Cognee with **pip**, **poetry**, **uv**, or your preferred Python package manager.

```bash
uv pip install cognee
```

### Step 2: Configure the LLM
```python
import os
os.environ[&quot;LLM_API_KEY&quot;] = &quot;YOUR OPENAI_API_KEY&quot;
```
Alternatively, create a `.env` file using our [template](https://github.com/topoteretes/cognee/blob/main/.env.template).

To integrate other LLM providers, see our [LLM Provider Documentation](https://docs.cognee.ai/setup-configuration/llm-providers).

### Step 3: Run the Pipeline

Cognee will take your documents, generate a knowledge graph from them and then query the graph based on combined relationships.

Now, run a minimal pipeline:

```python
import cognee
import asyncio
from pprint import pprint


async def main():
    # Add text to cognee
    await cognee.add(&quot;Cognee turns documents into AI memory.&quot;)

    # Generate the knowledge graph
    await cognee.cognify()

    # Add memory algorithms to the graph
    await cognee.memify()

    # Query the knowledge graph
    results = await cognee.search(&quot;What does Cognee do?&quot;)

    # Display the results
    for result in results:
        pprint(result)


if __name__ == &#039;__main__&#039;:
    asyncio.run(main())

```

As you can see, the output is generated from the document we previously stored in Cognee:

```bash
  Cognee turns documents into AI memory.
```

### Use the Cognee CLI

As an alternative, you can get started with these essential commands:

```bash
cognee-cli add &quot;Cognee turns documents into AI memory.&quot;

cognee-cli cognify

cognee-cli search &quot;What does Cognee do?&quot;
cognee-cli delete --all

```

To open the local UI, run:
```bash
cognee-cli -ui
```

## Demos &amp; Examples

See Cognee in action:

### Persistent Agent Memory

[Cognee Memory for LangGraph Agents](https://github.com/user-attachments/assets/e113b628-7212-4a2b-b288-0be39a93a1c3)

### Simple GraphRAG

[Watch Demo](https://github.com/user-attachments/assets/f2186b2e-305a-42b0-9c2d-9f4473f15df8)

### Cognee with Ollama

[Watch Demo](https://github.com/user-attachments/assets/39672858-f774-4136-b957-1e2de67b8981)


## Community &amp; Support

### Contributing
We welcome contributions from the community! Your input helps make Cognee better for everyone. See [`CONTRIBUTING.md`](CONTRIBUTING.md) to get started.

### Code of Conduct

We&#039;re committed to fostering an inclusive and respectful community. Read our [Code of Conduct](https://github.com/topoteretes/cognee/blob/main/CODE_OF_CONDUCT.md) for guidelines.

## Research &amp; Citation

We recently published a research paper on optimizing knowledge graphs for LLM reasoning:

```bibtex
@misc{markovic2025optimizinginterfaceknowledgegraphs,
      title={Optimizing the Interface Between Knowledge Graphs and LLMs for Complex Reasoning},
      author={Vasilije Markovic and Lazar Obradovic and Laszlo Hajdu and Jovan Pavlovic},
      year={2025},
      eprint={2505.24478},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2505.24478},
}
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[chenyme/grok2api]]></title>
            <link>https://github.com/chenyme/grok2api</link>
            <guid>https://github.com/chenyme/grok2api</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:08 GMT</pubDate>
            <description><![CDATA[Âü∫‰∫é FastAPI ÈáçÊûÑÁöÑ Grok2APIÔºåÂÖ®Èù¢ÈÄÇÈÖçÊúÄÊñ∞ Web Ë∞ÉÁî®Ê†ºÂºèÔºåÊîØÊåÅÊµÅ/ÈùûÊµÅÂºèÂØπËØù„ÄÅÂõæÂÉèÁîüÊàê/ÁºñËæë„ÄÅÊ∑±Â∫¶ÊÄùËÄÉÔºåÂè∑Ê±†Âπ∂Âèë‰∏éËá™Âä®Ë¥üËΩΩÂùáË°°‰∏Ä‰ΩìÂåñ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/chenyme/grok2api">chenyme/grok2api</a></h1>
            <p>Âü∫‰∫é FastAPI ÈáçÊûÑÁöÑ Grok2APIÔºåÂÖ®Èù¢ÈÄÇÈÖçÊúÄÊñ∞ Web Ë∞ÉÁî®Ê†ºÂºèÔºåÊîØÊåÅÊµÅ/ÈùûÊµÅÂºèÂØπËØù„ÄÅÂõæÂÉèÁîüÊàê/ÁºñËæë„ÄÅÊ∑±Â∫¶ÊÄùËÄÉÔºåÂè∑Ê±†Âπ∂Âèë‰∏éËá™Âä®Ë¥üËΩΩÂùáË°°‰∏Ä‰ΩìÂåñ„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 1,034</p>
            <p>Forks: 311</p>
            <p>Stars today: 71 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[anthropics/skills]]></title>
            <link>https://github.com/anthropics/skills</link>
            <guid>https://github.com/anthropics/skills</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:07 GMT</pubDate>
            <description><![CDATA[Public repository for Agent Skills]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anthropics/skills">anthropics/skills</a></h1>
            <p>Public repository for Agent Skills</p>
            <p>Language: Python</p>
            <p>Stars: 63,949</p>
            <p>Forks: 6,309</p>
            <p>Stars today: 894 stars today</p>
            <h2>README</h2><pre>&gt; **Note:** This repository contains Anthropic&#039;s implementation of skills for Claude. For information about the Agent Skills standard, see [agentskills.io](http://agentskills.io).

# Skills
Skills are folders of instructions, scripts, and resources that Claude loads dynamically to improve performance on specialized tasks. Skills teach Claude how to complete specific tasks in a repeatable way, whether that&#039;s creating documents with your company&#039;s brand guidelines, analyzing data using your organization&#039;s specific workflows, or automating personal tasks.

For more information, check out:
- [What are skills?](https://support.claude.com/en/articles/12512176-what-are-skills)
- [Using skills in Claude](https://support.claude.com/en/articles/12512180-using-skills-in-claude)
- [How to create custom skills](https://support.claude.com/en/articles/12512198-creating-custom-skills)
- [Equipping agents for the real world with Agent Skills](https://anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills)

# About This Repository

This repository contains skills that demonstrate what&#039;s possible with Claude&#039;s skills system. These skills range from creative applications (art, music, design) to technical tasks (testing web apps, MCP server generation) to enterprise workflows (communications, branding, etc.).

Each skill is self-contained in its own folder with a `SKILL.md` file containing the instructions and metadata that Claude uses. Browse through these skills to get inspiration for your own skills or to understand different patterns and approaches.

Many skills in this repo are open source (Apache 2.0). We&#039;ve also included the document creation &amp; editing skills that power [Claude&#039;s document capabilities](https://www.anthropic.com/news/create-files) under the hood in the [`skills/docx`](./skills/docx), [`skills/pdf`](./skills/pdf), [`skills/pptx`](./skills/pptx), and [`skills/xlsx`](./skills/xlsx) subfolders. These are source-available, not open source, but we wanted to share these with developers as a reference for more complex skills that are actively used in a production AI application.

## Disclaimer

**These skills are provided for demonstration and educational purposes only.** While some of these capabilities may be available in Claude, the implementations and behaviors you receive from Claude may differ from what is shown in these skills. These skills are meant to illustrate patterns and possibilities. Always test skills thoroughly in your own environment before relying on them for critical tasks.

# Skill Sets
- [./skills](./skills): Skill examples for Creative &amp; Design, Development &amp; Technical, Enterprise &amp; Communication, and Document Skills
- [./spec](./spec): The Agent Skills specification
- [./template](./template): Skill template

# Try in Claude Code, Claude.ai, and the API

## Claude Code
You can register this repository as a Claude Code Plugin marketplace by running the following command in Claude Code:
```
/plugin marketplace add anthropics/skills
```

Then, to install a specific set of skills:
1. Select `Browse and install plugins`
2. Select `anthropic-agent-skills`
3. Select `document-skills` or `example-skills`
4. Select `Install now`

Alternatively, directly install either Plugin via:
```
/plugin install document-skills@anthropic-agent-skills
/plugin install example-skills@anthropic-agent-skills
```

After installing the plugin, you can use the skill by just mentioning it. For instance, if you install the `document-skills` plugin from the marketplace, you can ask Claude Code to do something like: &quot;Use the PDF skill to extract the form fields from `path/to/some-file.pdf`&quot;

## Claude.ai

These example skills are all already available to paid plans in Claude.ai. 

To use any skill from this repository or upload custom skills, follow the instructions in [Using skills in Claude](https://support.claude.com/en/articles/12512180-using-skills-in-claude#h_a4222fa77b).

## Claude API

You can use Anthropic&#039;s pre-built skills, and upload custom skills, via the Claude API. See the [Skills API Quickstart](https://docs.claude.com/en/api/skills-guide#creating-a-skill) for more.

# Creating a Basic Skill

Skills are simple to create - just a folder with a `SKILL.md` file containing YAML frontmatter and instructions. You can use the **template-skill** in this repository as a starting point:

```markdown
---
name: my-skill-name
description: A clear description of what this skill does and when to use it
---

# My Skill Name

[Add your instructions here that Claude will follow when this skill is active]

## Examples
- Example usage 1
- Example usage 2

## Guidelines
- Guideline 1
- Guideline 2
```

The frontmatter requires only two fields:
- `name` - A unique identifier for your skill (lowercase, hyphens for spaces)
- `description` - A complete description of what the skill does and when to use it

The markdown content below contains the instructions, examples, and guidelines that Claude will follow. For more details, see [How to create custom skills](https://support.claude.com/en/articles/12512198-creating-custom-skills).

# Partner Skills

Skills are a great way to teach Claude how to get better at using specific pieces of software. As we see awesome example skills from partners, we may highlight some of them here:

- **Notion** - [Notion Skills for Claude](https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[GH05TCREW/pentestagent]]></title>
            <link>https://github.com/GH05TCREW/pentestagent</link>
            <guid>https://github.com/GH05TCREW/pentestagent</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:06 GMT</pubDate>
            <description><![CDATA[PentestAgent is an AI agent framework for black-box security testing, supporting bug bounty, red-team, and penetration testing workflows.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GH05TCREW/pentestagent">GH05TCREW/pentestagent</a></h1>
            <p>PentestAgent is an AI agent framework for black-box security testing, supporting bug bounty, red-team, and penetration testing workflows.</p>
            <p>Language: Python</p>
            <p>Stars: 1,404</p>
            <p>Forks: 330</p>
            <p>Stars today: 49 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;assets/pentestagent-logo.png&quot; alt=&quot;PentestAgent Logo&quot; width=&quot;220&quot; style=&quot;margin-bottom: 20px;&quot;/&gt;

# PentestAgent
### AI Penetration Testing

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/) [![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE.txt) [![Version](https://img.shields.io/badge/Version-0.2.0-orange.svg)](https://github.com/GH05TCREW/pentestagent/releases) [![Security](https://img.shields.io/badge/Security-Penetration%20Testing-red.svg)](https://github.com/GH05TCREW/pentestagent) [![MCP](https://img.shields.io/badge/MCP-Compatible-purple.svg)](https://github.com/GH05TCREW/pentestagent)

&lt;/div&gt;

https://github.com/user-attachments/assets/a67db2b5-672a-43df-b709-149c8eaee975

## Requirements

- Python 3.10+
- API key for OpenAI, Anthropic, or other LiteLLM-supported provider

## Install

```bash
# Clone
git clone https://github.com/GH05TCREW/pentestagent.git
cd pentestagent

# Setup (creates venv, installs deps)
.\scripts\setup.ps1   # Windows
./scripts/setup.sh    # Linux/macOS

# Or manual
python -m venv venv
.\venv\Scripts\Activate.ps1  # Windows
source venv/bin/activate     # Linux/macOS
pip install -e &quot;.[all]&quot;
playwright install chromium  # Required for browser tool
```

## Configure

Create `.env` in the project root:

```
ANTHROPIC_API_KEY=sk-ant-...
PENTESTAGENT_MODEL=claude-sonnet-4-20250514
```

Or for OpenAI:

```
OPENAI_API_KEY=sk-...
PENTESTAGENT_MODEL=gpt-5
```

Any [LiteLLM-supported model](https://docs.litellm.ai/docs/providers) works.

## Run

```bash
pentestagent                    # Launch TUI
pentestagent -t 192.168.1.1     # Launch with target
pentestagent --docker           # Run tools in Docker container
```

## Docker

Run tools inside a Docker container for isolation and pre-installed pentesting tools.

### Option 1: Pull pre-built image (fastest)

```bash
# Base image with nmap, netcat, curl
docker run -it --rm \
  -e ANTHROPIC_API_KEY=your-key \
  -e PENTESTAGENT_MODEL=claude-sonnet-4-20250514 \
  ghcr.io/gh05tcrew/pentestagent:latest

# Kali image with metasploit, sqlmap, hydra, etc.
docker run -it --rm \
  -e ANTHROPIC_API_KEY=your-key \
  ghcr.io/gh05tcrew/pentestagent:kali
```

### Option 2: Build locally

```bash
# Build
docker compose build

# Run
docker compose run --rm pentestagent

# Or with Kali
docker compose --profile kali build
docker compose --profile kali run --rm pentestagent-kali
```

The container runs PentestAgent with access to Linux pentesting tools. The agent can use `nmap`, `msfconsole`, `sqlmap`, etc. directly via the terminal tool.

Requires Docker to be installed and running.

## Modes

PentestAgent has three modes, accessible via commands in the TUI:

| Mode | Command | Description |
|------|---------|-------------|
| Assist | (default) | Chat with the agent. You control the flow. |
| Agent | `/agent &lt;task&gt;` | Autonomous execution of a single task. |
| Crew | `/crew &lt;task&gt;` | Multi-agent mode. Orchestrator spawns specialized workers. |

### TUI Commands

```
/agent &lt;task&gt;    Run autonomous agent on task
/crew &lt;task&gt;     Run multi-agent crew on task
/target &lt;host&gt;   Set target
/tools           List available tools
/notes           Show saved notes
/report          Generate report from session
/memory          Show token/memory usage
/prompt          Show system prompt
/clear           Clear chat and history
/quit            Exit (also /exit, /q)
/help            Show help (also /h, /?)
```

Press `Esc` to stop a running agent. `Ctrl+Q` to quit.

## Playbooks

PentestAgent includes prebuilt **attack playbooks** for black-box security testing. Playbooks define a structured approach to specific security assessments.

**Run a playbook:**

```bash
pentestagent run -t example.com --playbook thp3_web
```

![Playbook Demo](assets/playbook.gif)

## Tools

PentestAgent includes built-in tools and supports MCP (Model Context Protocol) for extensibility.

**Built-in tools:** `terminal`, `browser`, `notes`, `web_search` (requires `TAVILY_API_KEY`)

### MCP Integration

PentestAgent supports MCP (Model Context Protocol) servers, but automatic
installation and auto-start of vendored MCP adapters has been removed. Operators
should run the installers and setup scripts under `third_party/` manually and
then configure `mcp_servers.json` for any MCP servers they intend to use. Example
config (place under `mcp_servers.json`):

```json
{
  &quot;mcpServers&quot;: {
    &quot;nmap&quot;: {
      &quot;command&quot;: &quot;npx&quot;,
      &quot;args&quot;: [&quot;-y&quot;, &quot;gc-nmap-mcp&quot;],
      &quot;env&quot;: {
        &quot;NMAP_PATH&quot;: &quot;/usr/bin/nmap&quot;
      }
    }
  }
}
```

### CLI Tool Management

```bash
pentestagent tools list         # List all tools
pentestagent tools info &lt;name&gt;  # Show tool details
pentestagent mcp list           # List MCP servers
pentestagent mcp add &lt;name&gt; &lt;command&gt; [args...]  # Add MCP server
pentestagent mcp test &lt;name&gt;    # Test MCP connection
```

## Knowledge

- **RAG:** Place methodologies, CVEs, or wordlists in `pentestagent/knowledge/sources/` for automatic context injection.
- **Notes:** Agents save findings to `loot/notes.json` with categories (`credential`, `vulnerability`, `finding`, `artifact`). Notes persist across sessions and are injected into agent context.
- **Shadow Graph:** In Crew mode, the orchestrator builds a knowledge graph from notes to derive strategic insights (e.g., &quot;We have credentials for host X&quot;).

## Project Structure

```
pentestagent/
  agents/         # Agent implementations
  config/         # Settings and constants
  interface/      # TUI and CLI
  knowledge/      # RAG system and shadow graph
  llm/            # LiteLLM wrapper
  mcp/            # MCP client and server configs
  playbooks/      # Attack playbooks
  runtime/        # Execution environment
  tools/          # Built-in tools
```

## Development

```bash
pip install -e &quot;.[dev]&quot;
pytest                       # Run tests
pytest --cov=pentestagent    # With coverage
black pentestagent           # Format
ruff check pentestagent      # Lint
```

## Legal

Only use against systems you have explicit authorization to test. Unauthorized access is illegal.

## License

MIT

## HexStrike Integration &amp; Thanks

This branch vendors an optional integration with HexStrike (a powerful MCP-enabled scoring and tooling framework). HexStrike acts as a force-multiplier for PentestAgent by exposing a rich set of automated pentesting tools and workflows that the agent can call via MCP ‚Äî greatly expanding available capabilities with minimal setup.

Special thanks and credit to the HexStrike project and its author: https://github.com/0x4m4/hexstrike-ai

- Notes:
- HexStrike is vendored under `third_party/hexstrike` and is opt-in; follow `scripts/install_hexstrike_deps.sh` or the vendor README to install its dependencies and start the service manually.
- Automatic background install/start of vendored MCP adapters has been removed; operators should use the provided third-party scripts and then update `mcp_servers.json`.
- This update also includes several TUI fixes (improved background worker handling and safer task cancellation) to stabilize the terminal UI while using long-running MCP tools.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[CVHub520/X-AnyLabeling]]></title>
            <link>https://github.com/CVHub520/X-AnyLabeling</link>
            <guid>https://github.com/CVHub520/X-AnyLabeling</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:05 GMT</pubDate>
            <description><![CDATA[Effortless data labeling with AI support from Segment Anything and other awesome models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/CVHub520/X-AnyLabeling">CVHub520/X-AnyLabeling</a></h1>
            <p>Effortless data labeling with AI support from Segment Anything and other awesome models.</p>
            <p>Language: Python</p>
            <p>Stars: 8,081</p>
            <p>Forks: 885</p>
            <p>Stars today: 15 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
    &lt;a href=&quot;https://github.com/CVHub520/X-AnyLabeling/&quot; target=&quot;_blank&quot;&gt;
      &lt;img alt=&quot;X-AnyLabeling&quot; height=&quot;200px&quot; src=&quot;https://github.com/user-attachments/assets/0714a182-92bd-4b47-b48d-1c5d7c225176&quot;&gt;&lt;/a&gt;
  &lt;/p&gt;

[English](README.md) | [ÁÆÄ‰Ωì‰∏≠Êñá](README_zh-CN.md)

&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;./LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/License-LGPL%20v3-blue.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/v/release/CVHub520/X-AnyLabeling?color=ffa&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/x-anylabeling-cvhub?logo=pypi&amp;logoColor=white&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/python-3.10+-aff.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/os-linux%2C%20win%2C%20mac-pink.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/downloads/CVHub520/X-AnyLabeling/total?label=downloads&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://modelscope.cn/collections/X-AnyLabeling-7b0e1798bcda43&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/modelscope-X--AnyLabeling-6750FF?link=https%3A%2F%2Fmodelscope.cn%2Fcollections%2FX-AnyLabeling-7b0e1798bcda43&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

![](https://user-images.githubusercontent.com/18329471/234640541-a6a65fbc-d7a5-4ec3-9b65-55305b01a7aa.png)

&lt;img src=&quot;https://github.com/user-attachments/assets/8b5f290a-dddf-410c-a004-21e5a7bcd1cc&quot; width=&quot;100%&quot; /&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Auto-Training&lt;/strong&gt;&lt;/summary&gt;

&lt;video src=&quot;https://github.com/user-attachments/assets/c0ab2056-2743-4a2c-ba93-13f478d3481e&quot; width=&quot;100%&quot; controls&gt;
&lt;/video&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Auto-Labeling&lt;/strong&gt;&lt;/summary&gt;

&lt;video src=&quot;https://github.com/user-attachments/assets/f517fa94-c49c-4f05-864e-96b34f592079&quot; width=&quot;100%&quot; controls&gt;
&lt;/video&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Detect Anything&lt;/strong&gt;&lt;/summary&gt;

&lt;img src=&quot;https://github.com/user-attachments/assets/7f43bcec-96fd-48d1-bd36-9e5a440a66f6&quot; width=&quot;100%&quot; /&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Segment Anything&lt;/strong&gt;&lt;/summary&gt;

&lt;img src=&quot;https://github.com/user-attachments/assets/208dc9ed-b8c9-4127-9e5b-e76f53892f03&quot; width=&quot;100%&quot; /&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Promptable Concept Grounding&lt;/strong&gt;&lt;/summary&gt;

&lt;video src=&quot;https://github.com/user-attachments/assets/52cbdb5d-cc60-4be5-826f-903ea4330ca8&quot; width=&quot;100%&quot; controls&gt;
&lt;/video&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;VQA&lt;/strong&gt;&lt;/summary&gt;

&lt;video src=&quot;https://github.com/user-attachments/assets/53adcff4-b962-41b7-a408-3afecd8d8c82&quot; width=&quot;100%&quot; controls&gt;
&lt;/video&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Chatbot&lt;/strong&gt;&lt;/summary&gt;

&lt;img src=&quot;https://github.com/user-attachments/assets/56c9a20b-c836-47aa-8b54-bad5bb99b735&quot; width=&quot;100%&quot; /&gt;
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Image Classifier&lt;/strong&gt;&lt;/summary&gt;

&lt;video src=&quot;https://github.com/user-attachments/assets/0652adfb-48a4-4219-9b18-16ff5ce31be0&quot; width=&quot;100%&quot; controls&gt;
&lt;/video&gt;
&lt;/details&gt;

## ü•≥ What&#039;s New

&lt;video src=&quot;https://github.com/user-attachments/assets/493183fd-6cbe-45fb-9808-ec2b0af7a0f9&quot; width=&quot;100%&quot; controls&gt;
&lt;/video&gt;

&lt;video src=&quot;https://github.com/user-attachments/assets/4a676ebf-d2ae-4327-b078-8e63a5323793&quot; width=&quot;100%&quot; controls&gt;
&lt;/video&gt;

- Added [PP-DocLayoutV3](./examples/optical_character_recognition/document_layout_analysis/README.md), supporting multi-point localization (quadrilaterals/polygons) and logical reading order prediction
- Added [PaddleOCR-VL-1.5](./examples/optical_character_recognition/multi_task/README.md), supporting OCR, table recognition, formula recognition, chart recognition, text spotting, and seal recognition
- Added [YOLO26](https://github.com/ultralytics/ultralytics) series models for object detection, instance segmentation, pose estimation, and rotated object detection
- Added Compare View feature for split-screen image comparison (ideal for infrared/visible fusion, mask preview, and super-resolution) [[docs](./docs/en/user_guide.md#36-compare-view)]
- Added multimodal large language model [Rex-Omni](https://github.com/IDEA-Research/Rex-Omni) with support for grounding, keypoints, referring pointing, OCR, and visual prompting tasks [[docs](./examples/vision_language/rexomni/README.md)]
- Added powerful file search feature upporting text search, regular expression search, and attribute-based filtering [[docs](./docs/en/user_guide.md#25-searching-images)]
- Added semi-transparent mask rendering for polygon, rectangle, rotation, and circle shapes with toggle support (`Ctrl+M`)
- Added one-click text and visual prompt video detection and segmentation tracking based on Segment Anything 3 [[docs](./examples/interactive_video_object_segmentation/sam3/README.md)]
- For more details, please refer to the [CHANGELOG](./CHANGELOG.md)

## X-AnyLabeling

**X-AnyLabeling** is a powerful annotation tool that integrates an AI engine for fast and automatic labeling. It&#039;s designed for multi-modal data engineers, offering industrial-grade solutions for complex tasks.

&lt;img src=&quot;https://github.com/user-attachments/assets/632e629b-0dec-407b-95a6-728052e1dd7b&quot; width=&quot;100%&quot; /&gt;

Also, we highly recommend trying out [X-AnyLabeling-Server](https://github.com/CVHub520/X-AnyLabeling-Server), a simple, lightweight, and extensible framework that enables remote inference capabilities for X-AnyLabeling.

## Features

&lt;img src=&quot;https://github.com/user-attachments/assets/c65db18f-167b-49e8-bea3-fcf4b43a8ffd&quot; width=&quot;100%&quot; /&gt;

- Supports remote inference service.
- Processes both `images` and `videos`.
- Accelerates inference with `GPU` support.
- Allows custom models and secondary development.
- Supports one-click inference for all images in the current task.
- Supports import/export for formats like COCO, VOC, YOLO, DOTA, MOT, MASK, PPOCR, MMGD, VLM-R1.
- Handles tasks like `classification`, `detection`, `segmentation`, `caption`, `rotation`, `tracking`, `estimation`, `ocr`, `vqa`, `grounding` and so on.
- Supports diverse annotation styles: `polygons`, `rectangles`, `rotated boxes`, `circles`, `lines`, `points`, and annotations for `text detection`, `recognition`, and `KIE`.

### Model library

&lt;img src=&quot;https://github.com/user-attachments/assets/7da2da2e-f182-4a1b-85f6-bfd0dfcc6a1b&quot; width=&quot;100%&quot; /&gt;

| **Task Category** | **Supported Models** |
| :--- | :--- |
| üñºÔ∏è Image Classification | YOLOv5-Cls, YOLOv8-Cls, YOLO11-Cls, InternImage, PULC |
| üéØ Object Detection | YOLOv5/6/7/8/9/10, YOLO11/12/26, YOLOX, YOLO-NAS, D-FINE, DAMO-YOLO, Gold_YOLO, RT-DETR, RF-DETR, DEIMv2 |
| üñåÔ∏è Instance Segmentation | YOLOv5-Seg, YOLOv8-Seg, YOLO11-Seg, YOLO26-Seg, Hyper-YOLO-Seg, RF-DETR-Seg |
| üèÉ Pose Estimation | YOLOv8-Pose, YOLO11-Pose, YOLO26-Pose, DWPose, RTMO |
| üë£ Tracking | Bot-SORT, ByteTrack, SAM2/3-Video |
| üîÑ Rotated Object Detection | YOLOv5-Obb, YOLOv8-Obb, YOLO11-Obb, YOLO26-Obb |
| üìè Depth Estimation | Depth Anything |
| üß© Segment Anything | SAM 1/2/3, SAM-HQ, SAM-Med2D, EdgeSAM, EfficientViT-SAM, MobileSAM |
| ‚úÇÔ∏è Image Matting | RMBG 1.4/2.0 |
| üí° Proposal | UPN |
| üè∑Ô∏è Tagging | RAM, RAM++ |
| üìÑ OCR | PP-OCRv4, PP-OCRv5, PP-DocLayoutV3, PaddleOCR-VL-1.5 |
| üó£Ô∏è Vision Foundation Models | Rex-Omni, Florence2 |
| üëÅÔ∏è Vision Language Models | Qwen3-VL, Gemini, ChatGPT |
| üõ£Ô∏è Land Detection | CLRNet |
| üìç Grounding | CountGD, GeCO, Grounding DINO, YOLO-World, YOLOE |
| üìö Other | üëâ [model_zoo](./docs/en/model_zoo.md) üëà |

## Docs

0. [Remote Inference Service](https://github.com/CVHub520/X-AnyLabeling-Server)
1. [Installation &amp; Quickstart](./docs/en/get_started.md)
2. [Usage](./docs/en/user_guide.md)
3. [Command Line Interface](./docs/en/cli.md)
4. [Customize a model](./docs/en/custom_model.md)
5. [Chatbot](./docs/en/chatbot.md)
6. [VQA](./docs/en/vqa.md)
7. [Multi-class Image Classifier](./docs/en/image_classifier.md)

&lt;img src=&quot;https://github.com/user-attachments/assets/0d67311c-f441-44b6-9ee0-932f25f51b1c&quot; width=&quot;100%&quot; /&gt;

## Examples

- [Classification](./examples/classification/)
  - [Image-Level](./examples/classification/image-level/README.md)
  - [Shape-Level](./examples/classification/shape-level/README.md)
- [Detection](./examples/detection/)
  - [HBB Object Detection](./examples/detection/hbb/README.md)
  - [OBB Object Detection](./examples/detection/obb/README.md)
- [Segmentation](./examples/segmentation/README.md)
  - [Instance Segmentation](./examples/segmentation/instance_segmentation/)
  - [Binary Semantic Segmentation](./examples/segmentation/binary_semantic_segmentation/)
  - [Multiclass Semantic Segmentation](./examples/segmentation/multiclass_semantic_segmentation/)
- [Description](./examples/description/)
  - [Tagging](./examples/description/tagging/README.md)
  - [Captioning](./examples/description/captioning/README.md)
- [Estimation](./examples/estimation/)
  - [Pose Estimation](./examples/estimation/pose_estimation/README.md)
  - [Depth Estimation](./examples/estimation/depth_estimation/README.md)
- [OCR](./examples/optical_character_recognition/)
  - [Text Recognition](./examples/optical_character_recognition/text_recognition/)
  - [Key Information Extraction](./examples/optical_character_recognition/key_information_extraction/README.md)
- [MOT](./examples/multiple_object_tracking/README.md)
  - [Tracking by HBB Object Detection](./examples/multiple_object_tracking/README.md)
  - [Tracking by OBB Object Detection](./examples/multiple_object_tracking/README.md)
  - [Tracking by Instance Segmentation](./examples/multiple_object_tracking/README.md)
  - [Tracking by Pose Estimation](./examples/multiple_object_tracking/README.md)
- [iVOS](./examples/interactive_video_object_segmentation)
  - [SAM2-Video](./examples/interactive_video_object_segmentation/sam2/README.md)
  - [SAM3-Video](./examples/interactive_video_object_segmentation/sam3/README.md)
- [Matting](./examples/matting/)
  - [Image Matting](./examples/matting/image_matting/README.md)
- [Vision-Language](./examples/vision_language/)
  - [Rex-Omni](./examples/vision_language/rexomni/README.md)
  - [Florence 2](./examples/vision_language/florence2/README.md)
- [Counting](./examples/counting/)
  - [GeCo](./examples/counting/geco/README.md)
- [Grounding](./examples/grounding/)
  - [YOLOE](./examples/grounding/yoloe/README.md)
  - [SAM 3](./examples/grounding/sam3/README.md)
- [Training](./examples/training/)
  - [Ultralytics](./examples/training/ultralytics/README.md)


## Contribute

We believe in open collaboration! **X‚ÄëAnyLabeling** continues to grow with the support of the community. Whether you&#039;re fixing bugs, improving documentation, or adding new features, your contributions make a real impact.

To get started, please read our [Contributing Guide](./CONTRIBUTING.md) and make sure to agree to the [Contributor License Agreement (CLA)](./CLA.md) before submitting a pull request.

If you find this project helpful, please consider giving it a ‚≠êÔ∏è star! Have questions or suggestions? Open an [issue](https://github.com/CVHub520/X-AnyLabeling/issues) or email us at cv_hub@163.com.

A huge thank you üôè to everyone helping to make X‚ÄëAnyLabeling better.

## License

This project is licensed under the [GPL-3.0 license](./LICENSE) and is completely open source and free. The original intention is to enable more developers, researchers, and enterprises to conveniently use this AI application platform, promoting the development of the entire industry. We encourage everyone to use it freely (including commercial use), and you can also add features based on this project and commercialize it, but you must retain the brand identity and indicate the source project address.

Additionally, to understand the ecosystem and usage of X-AnyLabeling, if you use this project for academic, research, teaching, or enterprise purposes, please fill out the [registration form](https://forms.gle/MZCKhU7UJ4TRSWxR7). This registration is only for statistical purposes and will not incur any fees. We will strictly keep all information confidential.

X-AnyLabeling is independently developed and maintained by an individual. If this project has been helpful to you, we welcome your support through the donation links below to help sustain the project&#039;s continued development. Your support is the greatest encouragement! If you have any questions about the project or would like to collaborate, please feel free to contact via WeChat: ww10874 or email provided above.

## Sponsors

- [buy-me-a-coffee](https://ko-fi.com/cvhub520)
- [Wechat/Alipay](https://github.com/CVHub520/X-AnyLabeling/blob/main/README_zh-CN.md#%E8%B5%9E%E5%8A%A9)

## Acknowledgement

I extend my heartfelt thanks to the developers and contributors of [AnyLabeling](https://github.com/vietanhdev/anylabeling), [LabelMe](https://github.com/wkentaro/labelme), [LabelImg](https://github.com/tzutalin/labelImg), [roLabelImg](https://github.com/cgvict/roLabelImg), [PPOCRLabel](https://github.com/PFCCLab/PPOCRLabel) and [CVAT](https://github.com/opencv/cvat), whose work has been crucial to the success of this project.

## Citing

If you use this software in your research, please cite it as below:

```
@misc{X-AnyLabeling,
  year = {2023},
  author = {Wei Wang},
  publisher = {Github},
  organization = {CVHub},
  journal = {Github repository},
  title = {Advanced Auto Labeling Solution with Added Features},
  howpublished = {\url{https://github.com/CVHub520/X-AnyLabeling}}
}
```

---

![Star History Chart](https://api.star-history.com/svg?repos=CVHub520/X-AnyLabeling&amp;type=Date)

&lt;div align=&quot;center&quot;&gt;&lt;a href=&quot;#top&quot;&gt;üîù Back to Top&lt;/a&gt;&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[frappe/erpnext]]></title>
            <link>https://github.com/frappe/erpnext</link>
            <guid>https://github.com/frappe/erpnext</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:04 GMT</pubDate>
            <description><![CDATA[Free and Open Source Enterprise Resource Planning (ERP)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/frappe/erpnext">frappe/erpnext</a></h1>
            <p>Free and Open Source Enterprise Resource Planning (ERP)</p>
            <p>Language: Python</p>
            <p>Stars: 31,546</p>
            <p>Forks: 10,365</p>
            <p>Stars today: 45 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://github.com/frappe/design/blob/master/logos/logo-2019/erpnext-logo.png&quot; height=&quot;128&quot;&gt;
    &lt;h2&gt;ERPNext&lt;/h2&gt;
    &lt;p align=&quot;center&quot;&gt;
        &lt;p&gt;ERP made simple&lt;/p&gt;
    &lt;/p&gt;

[![Build Status](https://travis-ci.com/frappe/erpnext.png)](https://travis-ci.com/frappe/erpnext)
[![Open Source Helpers](https://www.codetriage.com/frappe/erpnext/badges/users.svg)](https://www.codetriage.com/frappe/erpnext)
[![Coverage Status](https://coveralls.io/repos/github/frappe/erpnext/badge.svg?branch=develop)](https://coveralls.io/github/frappe/erpnext?branch=develop)

[https://erpnext.com](https://erpnext.com)

&lt;/div&gt;

Includes: Accounting, Inventory, Manufacturing, CRM, Sales, Purchase, Project Management, HRMS. Requires MariaDB.

ERPNext is built on the [Frappe](https://github.com/frappe/frappe) Framework, a full-stack web app framework in Python &amp; JavaScript.

- [User Guide](https://erpnext.com/docs/user)
- [Discussion Forum](https://discuss.erpnext.com/)

---

### Full Install

The Easy Way: our install script for bench will install all dependencies (e.g. MariaDB). See https://github.com/frappe/bench for more details.

New passwords will be created for the ERPNext &quot;Administrator&quot; user, the MariaDB root user, and the frappe user (the script displays the passwords and saves them to ~/frappe_passwords.txt).

### Virtual Image

You can download a virtual image to run ERPNext in a virtual machine on your local system.

- [ERPNext Download](http://erpnext.com/download)

System and user credentials are listed on the download page.

---

## License

GNU/General Public License (see [license.txt](license.txt))

The ERPNext code is licensed as GNU General Public License (v3) and the Documentation is licensed as Creative Commons (CC-BY-SA-3.0) and the copyright is owned by Frappe Technologies Pvt Ltd (Frappe) and Contributors.

---

## Contributing

1. [Issue Guidelines](https://github.com/frappe/erpnext/wiki/Issue-Guidelines)
1. [Report Security Vulnerabilities](https://erpnext.com/report)
1. [Pull Request Requirements](https://github.com/frappe/erpnext/wiki/Contribution-Guidelines)
1. [Translations](https://translate.erpnext.com)
1. [Chart of Accounts](https://charts.erpnext.com)

---

## Logo and Trademark

The brand name ERPNext and the logo are trademarks of Frappe Technologies Pvt. Ltd.

### Introduction

Frappe Technologies Pvt. Ltd. (Frappe) owns and oversees the trademarks for the ERPNext name and logos. We have developed this trademark usage policy with the following goals in mind:

- We‚Äôd like to make it easy for anyone to use the ERPNext name or logo for community-oriented efforts that help spread and improve ERPNext.
- We‚Äôd like to make it clear how ERPNext-related businesses and projects can (and cannot) use the ERPNext name and logo.
- We‚Äôd like to make it hard for anyone to use the ERPNext name and logo to unfairly profit from, trick or confuse people who are looking for official ERPNext resources.

### Frappe Trademark Usage Policy

Permission from Frappe is required to use the ERPNext name or logo as part of any project, product, service, domain or company name.

We will grant permission to use the ERPNext name and logo for projects that meet the following criteria:

- The primary purpose of your project is to promote the spread and improvement of the ERPNext software.
- Your project is non-commercial in nature (it can make money to cover its costs or contribute to non-profit entities, but it cannot be run as a for-profit project or business).
Your project neither promotes nor is associated with entities that currently fail to comply with the GPL license under which ERPNext is distributed.
- If your project meets these criteria, you will be permitted to use the ERPNext name and logo to promote your project in any way you see fit with one exception: Please do not use ERPNext as part of a domain name.

Use of the ERPNext name and logo is additionally allowed in the following situations:

All other ERPNext-related businesses or projects can use the ERPNext name and logo to refer to and explain their services, but they cannot use them as part of a product, project, service, domain, or company name and they cannot use them in any way that suggests an affiliation with or endorsement by ERPNext or Frappe Technologies or the ERPNext open source project. For example, a consulting company can describe its business as ‚Äú123 Web Services, offering ERPNext consulting for small businesses,‚Äù but cannot call its business ‚ÄúThe ERPNext Consulting Company.‚Äù

Similarly, it‚Äôs OK to use the ERPNext logo as part of a page that describes your products or services, but it is not OK to use it as part of your company or product logo or branding itself. Under no circumstances is it permitted to use ERPNext as part of a top-level domain name.

We do not allow the use of the trademark in advertising, including AdSense/AdWords.

Please note that it is not the goal of this policy to limit commercial activity around ERPNext. We encourage ERPNext-based businesses, and we would love to see hundreds of them.

When in doubt about your use of the ERPNext name or logo, please contact Frappe Technologies for clarification.

(inspired by WordPress)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[JerBouma/FinanceDatabase]]></title>
            <link>https://github.com/JerBouma/FinanceDatabase</link>
            <guid>https://github.com/JerBouma/FinanceDatabase</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:03 GMT</pubDate>
            <description><![CDATA[This is a database of 300.000+ symbols containing Equities, ETFs, Funds, Indices, Currencies, Cryptocurrencies and Money Markets.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/JerBouma/FinanceDatabase">JerBouma/FinanceDatabase</a></h1>
            <p>This is a database of 300.000+ symbols containing Equities, ETFs, Funds, Indices, Currencies, Cryptocurrencies and Money Markets.</p>
            <p>Language: Python</p>
            <p>Stars: 6,879</p>
            <p>Forks: 719</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre>&lt;img src=&quot;https://user-images.githubusercontent.com/46355364/220746807-669cdbc1-ac67-404c-b0bb-4a3d67d9931f.jpg&quot; alt=&quot;Logo&quot;&gt;

[![GitHub Sponsors](https://img.shields.io/badge/Sponsor_this_Project-grey?logo=github)](https://github.com/sponsors/JerBouma)
[![Buy Me a Coffee](https://img.shields.io/badge/Buy_Me_a_Coffee-grey?logo=buymeacoffee)](https://www.buymeacoffee.com/jerbouma)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-grey?logo=Linkedin&amp;logoColor=white)](https://www.linkedin.com/in/boumajeroen/)
[![Documentation](https://img.shields.io/badge/Documentation-grey?logo=readme)](https://www.jeroenbouma.com/projects/financedatabase)
[![Supported Python Versions](https://img.shields.io/pypi/pyversions/financedatabase)](https://pypi.org/project/financedatabase/)
[![PYPI Version](https://img.shields.io/pypi/v/financedatabase)](https://pypi.org/project/financedatabase/)
[![PYPI Downloads](https://static.pepy.tech/badge/financedatabase/month)](https://pepy.tech/project/financedatabase)

| **Call for Contributors to the FinanceDatabase**    |
|:------------------------------------------------------:|
| The **FinanceDatabase** serves the role of providing anyone with any type of financial product categorization entirely for free. To achieve this, the FinanceDatabase relies on community involvement to add, edit, and remove tickers over time. This is made easy enough that anyone, even those with a lack of coding experience, can contribute because of the use of CSV files that can be manually edited with ease.
**I&#039;d like to invite you to go to the [Contributing Guidelines](https://github.com/JerBouma/FinanceDatabase/blob/main/CONTRIBUTING.md) to understand how you can help. Thank you!** |

As a private investor, the sheer amount of information that can be found on the internet is rather daunting. Trying to understand what types of companies or ETFs are available is incredibly challenging, with millions of companies and derivatives available on the market. Sure, the most traded companies and ETFs can quickly be found simply because they are known to the public (for example, Microsoft, Tesla, S&amp;P 500 ETF, or an All-World ETF). However, what else is out there is often unknown.

**This database tries to solve that**. It features 300,000+ symbols containing Equities, ETFs, Funds, Indices, Currencies, Cryptocurrencies, and Money Markets. It therefore allows you to obtain a broad overview of sectors, industries, types of investments, and much more.

The aim of this database is explicitly _not_ to provide up-to-date fundamentals or stock data, as those can be obtained with ease (with the help of this database) by using the [Finance Toolkit üõ†Ô∏è](https://github.com/JerBouma/FinanceToolkit). Instead, it gives insights into the products that exist in each country, industry, and sector and provides the most essential information about each product. With this information, you can analyze specific areas of the financial world and/or find a product that is hard to find. For examples of how you can combine this database with the earlier mentioned packages, see the [Usage](#usage) section.

Some key statistics of the database:

| Product           | Quantity   | Sectors    | Industries    | Countries | Exchanges |
| ----------------- | ---------- | ---------- | ------------- | --------- | --------- |
| Equities          | 158.429    | 12         | 63            | 111       | 83        | 
| ETFs              | 36.786     | 295        | 22            | 111       | 53        |
| Funds             | 57.881     | 1541       | 52            | 111       | 34        |

| Product           | Quantity  | Category              |
| ----------------- | --------- | --------------------- |
| Currencies        | 2.556     | 175 Currencies        |
| Cryptocurrencies  | 3.367     | 352 Cryptocurrencies  |
| Indices           | 91.183    | 64 Exchanges          |
| Money Markets     | 1.367     | 3 Exchanges           |

The Finance Database is used within or referenced by:

&lt;a href=&quot;https://algotrading101.com/learn/financedatabase-python-guide/&quot;&gt;&lt;img width=&quot;200&quot; height=&quot;100&quot; alt=&quot;AlgoTrading&quot; src=&quot;https://github-production-user-asset-6210df.s3.amazonaws.com/46355364/265290727-4c113348-45fc-45fe-afb5-e043b738ee94.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://twitter.com/pyquantnews/status/1576185955677077504?lang=en&quot;&gt;&lt;img width=&quot;200&quot; height=&quot;100&quot; alt=&quot;PyQuantNews&quot; src=&quot;https://github-production-user-asset-6210df.s3.amazonaws.com/46355364/265290754-8c9025fb-3830-4f41-95fd-e5e6d0f84758.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://alpha2phi.medium.com/investment-analysis-finance-database-61f47ecfe7ca&quot;&gt;&lt;img width=&quot;200&quot; height=&quot;100&quot; alt=&quot;Medium&quot; src=&quot;https://github-production-user-asset-6210df.s3.amazonaws.com/46355364/265290765-dfbd0f4c-85eb-4de6-adba-345cb5189f31.png&quot;&gt;&lt;/a&gt;

___

# Installation

Before installation, consider starring the project on GitHub, which helps others find the project as well.

&lt;img width=&quot;1353&quot; alt=&quot;image&quot; src=&quot;https://github.com/JerBouma/FinanceDatabase/assets/46355364/4132edde-72f9-4e32-adfe-8872207f46ff&quot;&gt;

To install the FinanceDatabase, simply use the following:

```
pip install financedatabase -U
```

Then within Python use:

```python
import financedatabase as fd
```

# Usage
This section explains in detail how the database can be queried with the related `financedatabase` package. Note that examples here are purposely cut off to a maximum of 10 entries due to the sheer size of the database. Furthermore, the summary column is also omitted for readability. For the full detailed results, see the Notebook [here](https://www.jeroenbouma.com/projects/financedatabase/getting-started). Let&#039;s start by importing the package:

```python
import financedatabase as fd
```

Initialization of each asset class is only required &lt;u&gt;once&lt;/u&gt;. It is therefore important that you save the class to a variable so that you can query the database much more quickly. A simple example is shown below.

```python
equities = fd.Equities()

equities.select()
```

A sample of the output is shown below:

| symbol   | name                           | currency   | sector                 | industry_group                                 | industry                               | exchange   | market                    | country       | state   | city                | zipcode    | website                          | market_cap   | isin         | cusip     | figi         | composite_figi   | shareclass_figi   |
|:---------|:-------------------------------|:-----------|:-----------------------|:-----------------------------------------------|:---------------------------------------|:-----------|:--------------------------|:--------------|:--------|:--------------------|:-----------|:---------------------------------|:-------------|:-------------|:----------|:-------------|:-----------------|:------------------|
| PMTA.DU  | PTC Inc.                       | EUR        | Information Technology | Software &amp; Services                            | Software                               | DUS        | Dusseldorf Stock Exchange | United States | MA      | Boston              | 2210       | http://www.ptc.com               | Large Cap    | US69370C1009 | 69370C100 | BBG000FC6SC5 | BBG000FC5PS5     | BBG001S6DNK6      |
| VAW.F    | VAALCO Energy, Inc.            | EUR        | Energy                 | Energy                                         | Oil, Gas &amp; Consumable Fuels            | FRA        | Frankfurt Stock Exchange  | United States | TX      | Houston             | 77042      | http://www.vaalco.com            | Micro Cap    | US91851C2017 | 91851C201 | BBG000CN15Y5 | BBG000CN15F6     | BBG001S76ZS7      |
| ORC.DE   | Oracle Corporation             | EUR        | Information Technology | Software &amp; Services                            | Software                               | GER        | XETRA                     | United States | TX      | Austin              | 78741      | http://www.oracle.com            | Mega Cap     | US68389X1054 | 68389X105 | BBG000C0RY38 | BBG000C0RWW0     | BBG001S5SJG6      |
| PAYX     | Paychex, Inc.                  | USD        | Industrials            | Commercial &amp; Professional Services             | Professional Services                  | NMS        | NASDAQ Global Select      | United States | NY      | Rochester           | 14625-2396 | http://www.paychex.com           | Large Cap    | US7043261079 | 704326107 | BBG000BQT1J5 | BBG000BQSQ38     | BBG001S5V135      |
| RI2A.F   | Rigel Pharmaceuticals, Inc.    | EUR        | Health Care            | Pharmaceuticals, Biotechnology &amp; Life Sciences | Biotechnology                          | FRA        | Frankfurt Stock Exchange  | United States | CA      | South San Francisco | 94080      | http://www.rigel.com             | Small Cap    | US7665596034 | 766559603 | BBG000BKZNR4 | BBG000BKZNC0     | BBG001SD33Z0      |
| PGEN     | Precigen, Inc.                 | USD        | Health Care            | Pharmaceuticals, Biotechnology &amp; Life Sciences | Biotechnology                          | NMS        | NASDAQ Global Select      | United States | MD      | Germantown          | 20876      | http://www.precigen.com          | Small Cap    | US74017N1054 | 74017N105 | BBG004TDDJ32 | BBG000QL8VH9     | BBG001SSB3T5      |
| GOGO     | Gogo Inc.                      | USD        | Communication Services | Telecommunication Services                     | Diversified Telecommunication Services | NMS        | NASDAQ Global Select      | United States | IL      | Chicago             | 60606      | http://www.gogoair.com           | Small Cap    | US38046C1099 | 38046C109 | BBG002CN8Y71 | BBG002CN8XN5     | BBG002CN8YD4      |
| CRK      | Comstock Resources, Inc.       | USD        | Energy                 | Energy                                         | Oil, Gas &amp; Consumable Fuels            | NYQ        | New York Stock Exchange   | United States | TX      | Frisco              | 75034      | http://www.comstockresources.com | Mid Cap      | US2057683029 | 205768302 | BBG000DNBMJ3 | BBG000DNBK89     | BBG001S8FX55      |
| OIS      | Oil States International, Inc. | USD        | Energy                 | Energy                                         | Energy Equipment &amp; Services            | NYQ        | New York Stock Exchange   | United States | TX      | Houston             | 77002      | http://www.oilstatesintl.com     | Small Cap    | US6780261052 | 678026105 | BBG000BDDQ06 | BBG000BDDN94     | BBG001S7WK56      |
| CVLC.BE  | Vale S.A.                      | EUR        | Materials              | Materials                                      | Metals &amp; Mining                        | BER        | Berlin Stock Exchange     | Brazil        | RJ      | Rio De Janeiro      | 22250-145  | http://www.vale.com              | Large Cap    | US91912E1055 | 9.19E+109 | BBG000HCJTN5 | BBG000HCJNQ5     | BBG001S7RS91      |


With `show_options`, all possible options are given per column. **This is useful as it doesn&#039;t require loading the larger data files.** For example, obtaining all options for equities is done as follows:

```python
fd.show_options(&quot;equities&quot;)
```

This returns all available options for each column.

```text
{&#039;currency&#039;: array([&#039;ARS&#039;, &#039;AUD&#039;, &#039;BRL&#039;, &#039;CAD&#039;, &#039;CHF&#039;, &#039;CLP&#039;, &#039;CNY&#039;, &#039;COP&#039;, &#039;CZK&#039;,
    &#039;DKK&#039;, &#039;EUR&#039;, &#039;GBP&#039;, &#039;HKD&#039;, &#039;HUF&#039;, &#039;IDR&#039;, &#039;ILA&#039;, &#039;ILS&#039;, &#039;INR&#039;,
    &#039;ISK&#039;, &#039;JPY&#039;, &#039;KES&#039;, &#039;KRW&#039;, &#039;LKR&#039;, &#039;MXN&#039;, &#039;MYR&#039;, &#039;NOK&#039;, &#039;NZD&#039;,
    &#039;PEN&#039;, &#039;PHP&#039;, &#039;PLN&#039;, &#039;QAR&#039;, &#039;RUB&#039;, &#039;SAR&#039;, &#039;SEK&#039;, &#039;SGD&#039;, &#039;THB&#039;,
    &#039;TRY&#039;, &#039;TWD&#039;, &#039;USD&#039;, &#039;ZAC&#039;, &#039;ZAR&#039;], dtype=object),
 &#039;sector&#039;: array([&#039;Communication Services&#039;, &#039;Consumer Discretionary&#039;,
    &#039;Consumer Staples&#039;, &#039;Energy&#039;, &#039;Financials&#039;, &#039;Health Care&#039;,
    &#039;Industrials&#039;, &#039;Information Technology&#039;, &#039;Materials&#039;,
    &#039;Real Estate&#039;, &#039;Utilities&#039;], dtype=object),
 &#039;industry_group&#039;: array([&#039;Automobiles &amp; Components&#039;, &#039;Banks&#039;, &#039;Capital Goods&#039;,
    &#039;Commercial &amp; Professional Services&#039;,
    &#039;Consumer Durables &amp; Apparel&#039;, &#039;Consumer Services&#039;,
    &#039;Diversified Financials&#039;, &#039;Energy&#039;, &#039;Food &amp; Staples Retailing&#039;,
    &#039;Food, Beverage &amp; Tobacco&#039;, &#039;Health Care Equipment &amp; Services&#039;,
    &#039;Household &amp; Personal Products&#039;, &#039;Insurance&#039;, &#039;Materials&#039;,
    &#039;Media &amp; Entertainment&#039;,
    &#039;Pharmaceuticals, Biotechnology &amp; Life Sciences&#039;, &#039;Real Estate&#039;,
    &#039;Retailing&#039;, &#039;Semiconductors &amp; Semiconductor Equipment&#039;,
    &#039;Software &amp; Services&#039;, &#039;Technology Hardware &amp; Equipment&#039;,
    &#039;Telecommunication Services&#039;, &#039;Transportation&#039;, &#039;Utilities&#039;],
       dtype=object)}
```

Since the equities database has already been loaded, it is also possible to use similar functionality from within the class as follows. The main difference is that this functionality allows you to see the options based on specific filtering. For example:

```python
equities.show_options(country=&#039;Netherlands&#039;)
```

This shows a more concise list of parameters given the focus on the Netherlands.

```text
{&#039;currency&#039;: array([&#039;ARS&#039;, &#039;AUD&#039;, &#039;BRL&#039;, &#039;CHF&#039;, &#039;CZK&#039;, &#039;EUR&#039;, &#039;GBP&#039;, &#039;ILA&#039;, &#039;MXN&#039;,
    &#039;NOK&#039;, &#039;RUB&#039;, &#039;USD&#039;, &#039;ZAC&#039;], dtype=object),
 &#039;sector&#039;: array([&#039;Communication Services&#039;, &#039;Consumer Discretionary&#039;,
    &#039;Consumer Staples&#039;, &#039;Energy&#039;, &#039;Financials&#039;, &#039;Health Care&#039;,
    &#039;Industrials&#039;, &#039;Information Technology&#039;, &#039;Materials&#039;,
    &#039;Real Estate&#039;, &#039;Utilities&#039;], dtype=object),
 &#039;industry_group&#039;: array([&#039;Automobiles &amp; Components&#039;, &#039;Banks&#039;, &#039;Capital Goods&#039;,
    &#039;Commercial &amp; Professional Services&#039;,
    &#039;Consumer Durables &amp; Apparel&#039;, &#039;Consumer Services&#039;,
    &#039;Diversified Financials&#039;, &#039;Energy&#039;, &#039;Food &amp; Staples Retailing&#039;,
    &#039;Food, Beverage &amp; Tobacco&#039;, &#039;Health Care Equipment &amp; Services&#039;,
    &#039;Household &amp; Personal Products&#039;, &#039;Insurance&#039;, &#039;Materials&#039;,
    &#039;Media &amp; Entertainment&#039;,
    &#039;Pharmaceuticals, Biotechnology &amp; Life Sciences&#039;, &#039;Real Estate&#039;,
    &#039;Retailing&#039;, &#039;Semiconductors &amp; Semiconductor Equipment&#039;,
    &#039;Software &amp; Services&#039;, &#039;Technology Hardware &amp; Equipment&#039;,
    &#039;Telecommunication Services&#039;, &#039;Transportation&#039;, &#039;Utilities&#039;],
       dtype=object)}
```

Or only showing one specific parameter:

```python
equities.show_options(
    selection=&#039;industry&#039;,
    sector=&#039;Financials&#039;,
    country=&#039;Netherlands&#039;)
```

Which returns:

```text
array([&#039;Banks&#039;, &#039;Capital Markets&#039;, &#039;Consumer Finance&#039;,
       &#039;Diversified Financial Services&#039;, &#039;Insurance&#039;], dtype=object)
```

Given this information, it then becomes possible to filter the database based on the parameters you are interested in. For example, if you are interested in &#039;Insurance&#039; companies in the &#039;Netherlands&#039;, you can use the following. Note that I omit the `sector` here, given that the selection I make is on a deeper level and therefore it is a given that the sector is &#039;Financials&#039;.

```python
equities.select(
    country=&#039;Netherlands&#039;,
    industry=&#039;Insurance&#039;,
)
```

This returns a small selection of companies on all exchanges where the companies are listed.


| symbol    | name               | currency   | sector     | industry_group   | industry   | exchange   | market                   | country     |   state | city      | zipcode   | website              | market_cap   | isin         |   cusip | figi         | composite_figi   | shareclass_figi   |
|:----------|:-------------------|:-----------|:-----------|:-----------------|:-----------|:-----------|:-------------------------|:------------|--------:|:----------|:----------|:---------------------|:-------------|:-------------|--------:|:-------------|:-----------------|:------------------|
| A16.F     | ASR Nederland N.V. | EUR        | Financials | Insurance        | Insurance  | FRA        | Frankfurt Stock Exchange | Netherlands |     nan | Utrecht   | 3584 BA   | http://www.asrnl.com | Mid Cap      | NL0011872643 |     nan | BBG00D2VFV96 | BBG00D2VFV78     | BBG00CWZ0HK0      |
| A1EG34.SA | Aegon N.V.         | BRL        | Financials | Insurance        | Insurance  | SAO        | Bovespa Soma             | Netherlands |     nan | The Hague | 2591 TV   | http://www.aegon.com | Mid Cap      | NL0000303709 |     nan | nan          | nan              | nan               |
| AEG       | Aegon N.V.         | USD        | Financials | Insurance        | Insurance  | NYQ        | New York Stock Exchange  | Netherlands |     nan | The Hague | 2591 TV   | http://www.aegon.com | Large Cap    | NL0000303709 |     nan | BBG000CKQTN4 | BBG000CKQSN6     | BBG001S6Y6M8      |
| AEGOF     | Aegon N.V.         | USD        | Financials | Insurance        | Insurance  | PNK        | OTC Bulletin Board       | Netherlands |     nan | The Hague | 2591 TV   | http://www.aegon.com | Mid Cap      | NL0000303709 |     nan | nan          | nan              | nan               |
| AEND.DE   | Aegon N.V.         | EUR        | Financials | Insurance        | Insurance  | GER        | XETRA                    | Netherlands |     nan | The Hague | 2591 TV   | http://www.aegon.com | Mid Cap      | NL0000303709 |     nan | BBG000DJK260 | BBG000DJHZF1     | BBG001S5V8R4      |

You&#039;ll see that the same company can appear multiple times. This is because by default all exchanges are shown. There are two methods to focus on one entry:

- Use the `only_primary_listing` parameter. This will only show the primary listing of each company. This is useful mostly if you are looking at US exchanges.
- Use the `exchange` or `market` parameter. This will allow you to filter on a specific exchange or market. This is useful when you are not necessarily looking at US exchanges and are already filtering on a specific country.

For example, when filtering on the Netherlands, it makes sense to select a Dutch exchange as well. This could be the exchange &quot;AMS&quot; or the market &quot;Euronext Amsterdam&quot;. This will give you a much smaller selection.

```python
equities.select(
    country=&#039;Netherlands&#039;,
    industry=&#039;Insurance&#039;,
    market=&#039;Euronext Amsterdam&#039;,
)
```

This gives the following three companies (not shortened):

| symbol   | name               | currency   | sector     | industry_group   | industry   | exchange   | market             | country     |   state | city      | zipcode   | website                 | market_cap   | isin         |   cusip | figi         | composite_figi   | shareclass_figi   |
|:---------|:-------------------|:-----------|:-----------|:-----------------|:-----------|:-----------|:-------------------|:------------|--------:|:----------|:----------|:------------------------|:-------------|:-------------|--------:|:-------------|:-----------------|:------------------|
| AGN.AS   | Aegon N.V.         | EUR        | Financials | Insurance        | Insurance  | AMS        | Euronext Amsterdam | Netherlands |     nan | The Hague | 2591 TV   | http://www.aegon.com    | Mid Cap      | NL0000303709 |     nan | BBG000JN9DM6 | BBG000JN9C93     | BBG001S5V8R4      |
| ASRNL.AS | ASR Nederland N.V. | EUR        | Financials | Insurance        | Insurance  | AMS        | Euronext Amsterdam | Netherlands |     nan | Utrecht   | 3584 BA   | http://www.asrnl.com    | Mid Cap      | NL0011872643 |     nan | BBG00CWZ0HG5 | BBG00CWZ0HF6     | BBG00CWZ0HK0      |
| NN.AS    | NN Group N.V.      | EUR        | Financials | Insurance        | Insurance  | AMS        | Euronext Amsterdam | Netherlands |     nan | The Hague | 2595 AS   | http://www.nn-group.com | Large Cap    | nan          |     nan | nan          | nan              | nan               |

Given that the Netherlands is a relatively small country, it is not uncommon for the list to become small quickly. For example, the same selection for the United States is already much larger, also utilizing the `only_primary_listing` parameter.

```python
equities.select(
    country=&#039;United States&#039;,
    industry=&#039;Insurance&#039;,
    only_primary_listing=True
)
```

While not immediately obvious in this shortened output, it returns about 180 diffe

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sgl-project/sglang]]></title>
            <link>https://github.com/sgl-project/sglang</link>
            <guid>https://github.com/sgl-project/sglang</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:02 GMT</pubDate>
            <description><![CDATA[SGLang is a high-performance serving framework for large language models and multimodal models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sgl-project/sglang">sgl-project/sglang</a></h1>
            <p>SGLang is a high-performance serving framework for large language models and multimodal models.</p>
            <p>Language: Python</p>
            <p>Stars: 23,341</p>
            <p>Forks: 4,335</p>
            <p>Stars today: 128 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; id=&quot;sglangtop&quot;&gt;
&lt;img src=&quot;https://raw.githubusercontent.com/sgl-project/sglang/main/assets/logo.png&quot; alt=&quot;logo&quot; width=&quot;400&quot; margin=&quot;10px&quot;&gt;&lt;/img&gt;

[![PyPI](https://img.shields.io/pypi/v/sglang)](https://pypi.org/project/sglang)
![PyPI - Downloads](https://static.pepy.tech/badge/sglang?period=month)
[![license](https://img.shields.io/github/license/sgl-project/sglang.svg)](https://github.com/sgl-project/sglang/tree/main/LICENSE)
[![issue resolution](https://img.shields.io/github/issues-closed-raw/sgl-project/sglang)](https://github.com/sgl-project/sglang/issues)
[![open issues](https://img.shields.io/github/issues-raw/sgl-project/sglang)](https://github.com/sgl-project/sglang/issues)
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/sgl-project/sglang)

&lt;/div&gt;

--------------------------------------------------------------------------------

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://lmsys.org/blog/&quot;&gt;&lt;b&gt;Blog&lt;/b&gt;&lt;/a&gt; |
&lt;a href=&quot;https://docs.sglang.io/&quot;&gt;&lt;b&gt;Documentation&lt;/b&gt;&lt;/a&gt; |
&lt;a href=&quot;https://roadmap.sglang.io/&quot;&gt;&lt;b&gt;Roadmap&lt;/b&gt;&lt;/a&gt; |
&lt;a href=&quot;https://slack.sglang.io/&quot;&gt;&lt;b&gt;Join Slack&lt;/b&gt;&lt;/a&gt; |
&lt;a href=&quot;https://meet.sglang.io/&quot;&gt;&lt;b&gt;Weekly Dev Meeting&lt;/b&gt;&lt;/a&gt; |
&lt;a href=&quot;https://github.com/sgl-project/sgl-learning-materials?tab=readme-ov-file#slides&quot;&gt;&lt;b&gt;Slides&lt;/b&gt;&lt;/a&gt;
&lt;/p&gt;

## News
- [2026/01] üî• SGLang Diffusion accelerates video and image generation ([blog](https://lmsys.org/blog/2026-01-16-sglang-diffusion/)).
- [2025/12] SGLang provides day-0 support for latest open models ([MiMo-V2-Flash](https://lmsys.org/blog/2025-12-16-mimo-v2-flash/), [Nemotron 3 Nano](https://lmsys.org/blog/2025-12-15-run-nvidia-nemotron-3-nano/), [Mistral Large 3](https://github.com/sgl-project/sglang/pull/14213), [LLaDA 2.0 Diffusion LLM](https://lmsys.org/blog/2025-12-19-diffusion-llm/), [MiniMax M2](https://lmsys.org/blog/2025-11-04-miminmax-m2/)).
- [2025/10] üî• SGLang now runs natively on TPU with the SGLang-Jax backend ([blog](https://lmsys.org/blog/2025-10-29-sglang-jax/)).
- [2025/09] Deploying DeepSeek on GB200 NVL72 with PD and Large Scale EP (Part II): 3.8x Prefill, 4.8x Decode Throughput ([blog](https://lmsys.org/blog/2025-09-25-gb200-part-2/)).
- [2025/09] SGLang Day 0 Support for DeepSeek-V3.2 with Sparse Attention ([blog](https://lmsys.org/blog/2025-09-29-deepseek-V32/)).
- [2025/08] SGLang x AMD SF Meetup on 8/22: Hands-on GPU workshop, tech talks by AMD/xAI/SGLang, and networking ([Roadmap](https://github.com/sgl-project/sgl-learning-materials/blob/main/slides/amd_meetup_sglang_roadmap.pdf), [Large-scale EP](https://github.com/sgl-project/sgl-learning-materials/blob/main/slides/amd_meetup_sglang_ep.pdf), [Highlights](https://github.com/sgl-project/sgl-learning-materials/blob/main/slides/amd_meetup_highlights.pdf), [AITER/MoRI](https://github.com/sgl-project/sgl-learning-materials/blob/main/slides/amd_meetup_aiter_mori.pdf), [Wave](https://github.com/sgl-project/sgl-learning-materials/blob/main/slides/amd_meetup_wave.pdf)).

&lt;details&gt;
&lt;summary&gt;More&lt;/summary&gt;

- [2025/11] SGLang Diffusion accelerates video and image generation ([blog](https://lmsys.org/blog/2025-11-07-sglang-diffusion/)).
- [2025/10] PyTorch Conference 2025 SGLang Talk ([slide](https://github.com/sgl-project/sgl-learning-materials/blob/main/slides/sglang_pytorch_2025.pdf)).
- [2025/10] SGLang x Nvidia SF Meetup on 10/2 ([recap](https://x.com/lmsysorg/status/1975339501934510231)).
- [2025/08] SGLang provides day-0 support for OpenAI gpt-oss model ([instructions](https://github.com/sgl-project/sglang/issues/8833))
- [2025/06] SGLang, the high-performance serving infrastructure powering trillions of tokens daily, has been awarded the third batch of the Open Source AI Grant by a16z ([a16z blog](https://a16z.com/advancing-open-source-ai-through-benchmarks-and-bold-experimentation/)).
- [2025/05] Deploying DeepSeek with PD Disaggregation and Large-scale Expert Parallelism on 96 H100 GPUs ([blog](https://lmsys.org/blog/2025-05-05-large-scale-ep/)).
- [2025/06] Deploying DeepSeek on GB200 NVL72 with PD and Large Scale EP (Part I): 2.7x Higher Decoding Throughput ([blog](https://lmsys.org/blog/2025-06-16-gb200-part-1/)).
- [2025/03] Supercharge DeepSeek-R1 Inference on AMD Instinct MI300X ([AMD blog](https://rocm.blogs.amd.com/artificial-intelligence/DeepSeekR1-Part2/README.html))
- [2025/03] SGLang Joins PyTorch Ecosystem: Efficient LLM Serving Engine ([PyTorch blog](https://pytorch.org/blog/sglang-joins-pytorch/))
- [2025/02] Unlock DeepSeek-R1 Inference Performance on AMD Instinct‚Ñ¢ MI300X GPU ([AMD blog](https://rocm.blogs.amd.com/artificial-intelligence/DeepSeekR1_Perf/README.html))
- [2025/01] SGLang provides day one support for DeepSeek V3/R1 models on NVIDIA and AMD GPUs with DeepSeek-specific optimizations. ([instructions](https://github.com/sgl-project/sglang/tree/main/benchmark/deepseek_v3), [AMD blog](https://www.amd.com/en/developer/resources/technical-articles/amd-instinct-gpus-power-deepseek-v3-revolutionizing-ai-development-with-sglang.html), [10+ other companies](https://x.com/lmsysorg/status/1887262321636221412))
- [2024/12] v0.4 Release: Zero-Overhead Batch Scheduler, Cache-Aware Load Balancer, Faster Structured Outputs ([blog](https://lmsys.org/blog/2024-12-04-sglang-v0-4/)).
- [2024/10] The First SGLang Online Meetup ([slides](https://github.com/sgl-project/sgl-learning-materials?tab=readme-ov-file#the-first-sglang-online-meetup)).
- [2024/09] v0.3 Release: 7x Faster DeepSeek MLA, 1.5x Faster torch.compile, Multi-Image/Video LLaVA-OneVision ([blog](https://lmsys.org/blog/2024-09-04-sglang-v0-3/)).
- [2024/07] v0.2 Release: Faster Llama3 Serving with SGLang Runtime (vs. TensorRT-LLM, vLLM) ([blog](https://lmsys.org/blog/2024-07-25-sglang-llama3/)).
- [2024/02] SGLang enables **3x faster JSON decoding** with compressed finite state machine ([blog](https://lmsys.org/blog/2024-02-05-compressed-fsm/)).
- [2024/01] SGLang provides up to **5x faster inference** with RadixAttention ([blog](https://lmsys.org/blog/2024-01-17-sglang/)).
- [2024/01] SGLang powers the serving of the official **LLaVA v1.6** release demo ([usage](https://github.com/haotian-liu/LLaVA?tab=readme-ov-file#demo)).

&lt;/details&gt;

## About
SGLang is a high-performance serving framework for large language models and multimodal models.
It is designed to deliver low-latency and high-throughput inference across a wide range of setups, from a single GPU to large distributed clusters.
Its core features include:

- **Fast Runtime**: Provides efficient serving with RadixAttention for prefix caching, a zero-overhead CPU scheduler, prefill-decode disaggregation, speculative decoding, continuous batching, paged attention, tensor/pipeline/expert/data parallelism, structured outputs, chunked prefill, quantization (FP4/FP8/INT4/AWQ/GPTQ), and multi-LoRA batching.
- **Broad Model Support**: Supports a wide range of language models (Llama, Qwen, DeepSeek, Kimi, GLM, GPT, Gemma, Mistral, etc.), embedding models (e5-mistral, gte, mcdse), reward models (Skywork), and diffusion models (WAN, Qwen-Image), with easy extensibility for adding new models. Compatible with most Hugging Face models and OpenAI APIs.
- **Extensive Hardware Support**: Runs on NVIDIA GPUs (GB200/B300/H100/A100/Spark), AMD GPUs (MI355/MI300), Intel Xeon CPUs, Google TPUs, Ascend NPUs, and more.
- **Active Community**: SGLang is open-source and supported by a vibrant community with widespread industry adoption, powering over 400,000 GPUs worldwide.
- **RL &amp; Post-Training Backbone**: SGLang is a proven rollout backend across the world, with native RL integrations and adoption by well-known post-training frameworks such as [**AReaL**](https://github.com/inclusionAI/AReaL), [**Miles**](https://github.com/radixark/miles), [**slime**](https://github.com/THUDM/slime), [**Tunix**](https://github.com/google/tunix), [**verl**](https://github.com/volcengine/verl) and more.

## Getting Started
- [Install SGLang](https://docs.sglang.io/get_started/install.html)
- [Quick Start](https://docs.sglang.io/basic_usage/send_request.html)
- [Backend Tutorial](https://docs.sglang.io/basic_usage/openai_api_completions.html)
- [Frontend Tutorial](https://docs.sglang.io/references/frontend/frontend_tutorial.html)
- [Contribution Guide](https://docs.sglang.io/developer_guide/contribution_guide.html)

## Benchmark and Performance
Learn more in the release blogs: [v0.2 blog](https://lmsys.org/blog/2024-07-25-sglang-llama3/), [v0.3 blog](https://lmsys.org/blog/2024-09-04-sglang-v0-3/), [v0.4 blog](https://lmsys.org/blog/2024-12-04-sglang-v0-4/), [Large-scale expert parallelism](https://lmsys.org/blog/2025-05-05-large-scale-ep/), [GB200 rack-scale parallelism](https://lmsys.org/blog/2025-09-25-gb200-part-2/).

## Adoption and Sponsorship
SGLang has been deployed at large scale, generating trillions of tokens in production each day. It is trusted and adopted by a wide range of leading enterprises and institutions, including xAI, AMD, NVIDIA, Intel, LinkedIn, Cursor, Oracle Cloud, Google Cloud, Microsoft Azure, AWS, Atlas Cloud, Voltage Park, Nebius, DataCrunch, Novita, InnoMatrix, MIT, UCLA, the University of Washington, Stanford, UC Berkeley, Tsinghua University, Jam &amp; Tea Studios, Baseten, and other major technology organizations across North America and Asia.
As an open-source LLM inference engine, SGLang has become the de facto industry standard, with deployments running on over 400,000 GPUs worldwide.
SGLang is currently hosted under the non-profit open-source organization [LMSYS](https://lmsys.org/about/).

&lt;img src=&quot;https://raw.githubusercontent.com/sgl-project/sgl-learning-materials/refs/heads/main/slides/adoption.png&quot; alt=&quot;logo&quot; width=&quot;800&quot; margin=&quot;10px&quot;&gt;&lt;/img&gt;

## Contact Us
For enterprises interested in adopting or deploying SGLang at scale, including technical consulting, sponsorship opportunities, or partnership inquiries, please contact us at sglang@lmsys.org

## Acknowledgment
We learned the design and reused code from the following projects: [Guidance](https://github.com/guidance-ai/guidance), [vLLM](https://github.com/vllm-project/vllm), [LightLLM](https://github.com/ModelTC/lightllm), [FlashInfer](https://github.com/flashinfer-ai/flashinfer), [Outlines](https://github.com/outlines-dev/outlines), and [LMQL](https://github.com/eth-sri/lmql).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[qodo-ai/pr-agent]]></title>
            <link>https://github.com/qodo-ai/pr-agent</link>
            <guid>https://github.com/qodo-ai/pr-agent</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:01 GMT</pubDate>
            <description><![CDATA[üöÄ PR Agent - The Original Open-Source PR Reviewer, This repo is not the Qodo free tier! Try the free version on our website.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/qodo-ai/pr-agent">qodo-ai/pr-agent</a></h1>
            <p>üöÄ PR Agent - The Original Open-Source PR Reviewer, This repo is not the Qodo free tier! Try the free version on our website.</p>
            <p>Language: Python</p>
            <p>Stars: 10,065</p>
            <p>Forks: 1,262</p>
            <p>Stars today: 18 stars today</p>
            <h2>README</h2><pre>&lt;a href=&quot;https://github.com/Codium-ai/pr-agent/commits/main&quot;&gt;
&lt;img alt=&quot;GitHub&quot; src=&quot;https://img.shields.io/github/last-commit/Codium-ai/pr-agent/main?style=for-the-badge&quot; height=&quot;20&quot;&gt;
&lt;/a&gt;

&lt;br /&gt;

# üöÄ The first AI Code Reviewer


PR-Agent is an open-source, AI-powered code review agent and a community-maintained legacy project of Qodo. It is distinct from Qodo‚Äôs primary AI code review offering, which provides a feature-rich, context-aware experience. Qodo now offers a free tier that integrates seamlessly with GitHub, GitLab, Bitbucket, and Azure DevOps for high-quality automated reviews.

## Table of Contents

- [Getting Started](#getting-started)
- [Why Use PR-Agent?](#why-use-pr-agent)
- [Features](#features)
- [See It in Action](#see-it-in-action)
- [Try It Now](#try-it-now)
- [How It Works](#how-it-works)
- [Data Privacy](#data-privacy)
- [Contributing](#contributing)

## Getting Started

### üöÄ Quick Start for PR-Agent

#### 1. Try it Instantly (No Setup)
Test PR-Agent on any public GitHub repository by commenting `@CodiumAI-Agent /improve`

#### 2. GitHub Action (Recommended)
Add automated PR reviews to your repository with a simple workflow file:
```yaml
# .github/workflows/pr-agent.yml
name: PR Agent
on:
  pull_request:
    types: [opened, synchronize]
jobs:
  pr_agent_job:
    runs-on: ubuntu-latest
    steps:
    - name: PR Agent action step
      uses: Codium-ai/pr-agent@main
      env:
        OPENAI_KEY: ${{ secrets.OPENAI_KEY }}
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
```
[Full GitHub Action setup guide](https://qodo-merge-docs.qodo.ai/installation/github/#run-as-a-github-action)

#### 3. CLI Usage (Local Development)
Run PR-Agent locally on your repository:
```bash
pip install pr-agent
export OPENAI_KEY=your_key_here
pr-agent --pr_url https://github.com/owner/repo/pull/123 review
```
[Complete CLI setup guide](https://qodo-merge-docs.qodo.ai/usage-guide/automations_and_usage/#local-repo-cli)

#### 4. Other Platforms
- [GitLab webhook setup](https://qodo-merge-docs.qodo.ai/installation/gitlab/)
- [BitBucket app installation](https://qodo-merge-docs.qodo.ai/installation/bitbucket/)
- [Azure DevOps setup](https://qodo-merge-docs.qodo.ai/installation/azure/)

[//]: # (## News and Updates)

[//]: # ()
[//]: # (## Aug 8, 2025)

[//]: # ()
[//]: # (Added full support for GPT-5 models. View the [benchmark results]&amp;#40;https://qodo-merge-docs.qodo.ai/pr_benchmark/#pr-benchmark-results&amp;#41; for details on the performance of GPT-5 models in PR-Agent.)

[//]: # ()
[//]: # ()
[//]: # (## Jul 17, 2025)

[//]: # ()
[//]: # (Introducing `/compliance`, a new Qodo Merge üíé tool that runs comprehensive checks for security, ticket requirements, codebase duplication, and custom organizational rules. )

[//]: # ()
[//]: # (&lt;img width=&quot;384&quot; alt=&quot;compliance-image&quot; src=&quot;https://codium.ai/images/pr_agent/compliance_partial.png&quot;/&gt;)

[//]: # ()
[//]: # (Read more about it [here]&amp;#40;https://qodo-merge-docs.qodo.ai/tools/compliance/&amp;#41;)

[//]: # ()
[//]: # ()
[//]: # (## Jul 1, 2025)

[//]: # (You can now receive automatic feedback from Qodo Merge in your local IDE after each commit. Read more about it [here]&amp;#40;https://github.com/qodo-ai/agents/tree/main/agents/qodo-merge-post-commit&amp;#41;.)

[//]: # ()
[//]: # ()
[//]: # (## Jun 21, 2025)

[//]: # ()
[//]: # (v0.30 was [released]&amp;#40;https://github.com/qodo-ai/pr-agent/releases&amp;#41;)

[//]: # ()
[//]: # ()
[//]: # (## Jun 3, 2025)

[//]: # ()
[//]: # (Qodo Merge now offers a simplified free tier üíé.)

[//]: # (Organizations can use Qodo Merge at no cost, with a [monthly limit]&amp;#40;https://qodo-merge-docs.qodo.ai/installation/qodo_merge/#cloud-users&amp;#41; of 75 PR reviews per organization.)

[//]: # ()
[//]: # ()
[//]: # (## Apr 30, 2025)

[//]: # ()
[//]: # (A new feature is now available in the `/improve` tool for Qodo Merge üíé - Chat on code suggestions.)

[//]: # ()
[//]: # (&lt;img width=&quot;512&quot; alt=&quot;image&quot; src=&quot;https://codium.ai/images/pr_agent/improve_chat_on_code_suggestions_ask.png&quot; /&gt;)

[//]: # ()
[//]: # (Read more about it [here]&amp;#40;https://qodo-merge-docs.qodo.ai/tools/improve/#chat-on-code-suggestions&amp;#41;.)

[//]: # ()
[//]: # ()
[//]: # (## Apr 16, 2025)

[//]: # ()
[//]: # (New tool for Qodo Merge üíé - `/scan_repo_discussions`.)

[//]: # ()
[//]: # (&lt;img width=&quot;635&quot; alt=&quot;image&quot; src=&quot;https://codium.ai/images/pr_agent/scan_repo_discussions_2.png&quot; /&gt;)

[//]: # ()
[//]: # (Read more about it [here]&amp;#40;https://qodo-merge-docs.qodo.ai/tools/scan_repo_discussions/&amp;#41;.)

## Why Use PR-Agent?

### üéØ Built for Real Development Teams

**Fast &amp; Affordable**: Each tool (`/review`, `/improve`, `/ask`) uses a single LLM call (~30 seconds, low cost)

**Handles Any PR Size**: Our [PR Compression strategy](https://qodo-merge-docs.qodo.ai/core-abilities/#pr-compression-strategy) effectively processes both small and large PRs

**Highly Customizable**: JSON-based prompting allows easy customization of review categories and behavior via [configuration files](pr_agent/settings/configuration.toml)

**Platform Agnostic**: 
- **Git Providers**: GitHub, GitLab, BitBucket, Azure DevOps, Gitea
- **Deployment**: CLI, GitHub Actions, Docker, self-hosted, webhooks
- **AI Models**: OpenAI GPT, Claude, Deepseek, and more

**Open Source Benefits**:
- Full control over your data and infrastructure
- Customize prompts and behavior for your team&#039;s needs
- No vendor lock-in
- Community-driven development

## Features

&lt;div style=&quot;text-align:left;&quot;&gt;

PR-Agent offers comprehensive pull request functionalities integrated with various git providers:

|                                                         |                                                                                        | GitHub | GitLab | Bitbucket | Azure DevOps | Gitea |
|---------------------------------------------------------|----------------------------------------------------------------------------------------|:------:|:------:|:---------:|:------------:|:-----:|
| [TOOLS](https://qodo-merge-docs.qodo.ai/tools/)         | [Describe](https://qodo-merge-docs.qodo.ai/tools/describe/)                            |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |  ‚úÖ   |
|                                                         | [Review](https://qodo-merge-docs.qodo.ai/tools/review/)                                |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |  ‚úÖ   |
|                                                         | [Improve](https://qodo-merge-docs.qodo.ai/tools/improve/)                              |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |  ‚úÖ   |
|                                                         | [Ask](https://qodo-merge-docs.qodo.ai/tools/ask/)                                      |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |       |
|                                                         | ‚Æë [Ask on code lines](https://qodo-merge-docs.qodo.ai/tools/ask/#ask-lines)            |   ‚úÖ   |   ‚úÖ   |           |              |       |
|                                                         | [Help Docs](https://qodo-merge-docs.qodo.ai/tools/help_docs/?h=auto#auto-approval)     |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |              |       |
|                                                         | [Update CHANGELOG](https://qodo-merge-docs.qodo.ai/tools/update_changelog/)            |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |       |
|                                                         |                                                                                                                     |        |        |           |              |       |
| [USAGE](https://qodo-merge-docs.qodo.ai/usage-guide/)   | [CLI](https://qodo-merge-docs.qodo.ai/usage-guide/automations_and_usage/#local-repo-cli)                            |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |  ‚úÖ   |
|                                                         | [App / webhook](https://qodo-merge-docs.qodo.ai/usage-guide/automations_and_usage/#github-app)                      |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |  ‚úÖ   |
|                                                         | [Tagging bot](https://github.com/Codium-ai/pr-agent#try-it-now)                                                     |   ‚úÖ   |        |           |              |       |
|                                                         | [Actions](https://qodo-merge-docs.qodo.ai/installation/github/#run-as-a-github-action)                              |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |       |
|                                                         |                                                                                                                     |        |        |           |              |       |
| [CORE](https://qodo-merge-docs.qodo.ai/core-abilities/) | [Adaptive and token-aware file patch fitting](https://qodo-merge-docs.qodo.ai/core-abilities/compression_strategy/) |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |       |
|                                                         | [Chat on code suggestions](https://qodo-merge-docs.qodo.ai/core-abilities/chat_on_code_suggestions/)                |   ‚úÖ   |  ‚úÖ   |           |              |       |
|                                                         | [Dynamic context](https://qodo-merge-docs.qodo.ai/core-abilities/dynamic_context/)                                  |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |       |
|                                                         | [Fetching ticket context](https://qodo-merge-docs.qodo.ai/core-abilities/fetching_ticket_context/)                  |   ‚úÖ    |  ‚úÖ    |     ‚úÖ     |              |       |
|                                                         | [Incremental Update](https://qodo-merge-docs.qodo.ai/core-abilities/incremental_update/)                            |   ‚úÖ    |       |           |              |       |
|                                                         | [Interactivity](https://qodo-merge-docs.qodo.ai/core-abilities/interactivity/)                                      |   ‚úÖ   |  ‚úÖ   |           |              |       |
|                                                         | [Local and global metadata](https://qodo-merge-docs.qodo.ai/core-abilities/metadata/)                               |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |       |
|                                                         | [Multiple models support](https://qodo-merge-docs.qodo.ai/usage-guide/changing_a_model/)                            |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |       |
|                                                         | [PR compression](https://qodo-merge-docs.qodo.ai/core-abilities/compression_strategy/)                              |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |       |
|                                                         | [RAG context enrichment](https://qodo-merge-docs.qodo.ai/core-abilities/rag_context_enrichment/)                    |   ‚úÖ    |       |    ‚úÖ     |              |       |
|                                                         | [Self reflection](https://qodo-merge-docs.qodo.ai/core-abilities/self_reflection/)                                  |   ‚úÖ   |   ‚úÖ   |    ‚úÖ     |      ‚úÖ      |       |

[//]: # (- Support for additional git providers is described in [here]&amp;#40;./docs/Full_environments.md&amp;#41;)
___

## See It in Action

&lt;/div&gt;
&lt;h4&gt;&lt;a href=&quot;https://github.com/Codium-ai/pr-agent/pull/530&quot;&gt;/describe&lt;/a&gt;&lt;/h4&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;p float=&quot;center&quot;&gt;
&lt;img src=&quot;https://www.codium.ai/images/pr_agent/describe_new_short_main.png&quot; width=&quot;512&quot;&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;

&lt;h4&gt;&lt;a href=&quot;https://github.com/Codium-ai/pr-agent/pull/732#issuecomment-1975099151&quot;&gt;/review&lt;/a&gt;&lt;/h4&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;p float=&quot;center&quot;&gt;
&lt;kbd&gt;
&lt;img src=&quot;https://www.codium.ai/images/pr_agent/review_new_short_main.png&quot; width=&quot;512&quot;&gt;
&lt;/kbd&gt;
&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;

&lt;h4&gt;&lt;a href=&quot;https://github.com/Codium-ai/pr-agent/pull/732#issuecomment-1975099159&quot;&gt;/improve&lt;/a&gt;&lt;/h4&gt;
&lt;div align=&quot;center&quot;&gt;
&lt;p float=&quot;center&quot;&gt;
&lt;kbd&gt;
&lt;img src=&quot;https://www.codium.ai/images/pr_agent/improve_new_short_main.png&quot; width=&quot;512&quot;&gt;
&lt;/kbd&gt;
&lt;/p&gt;
&lt;/div&gt;

&lt;div align=&quot;left&quot;&gt;

&lt;/div&gt;
&lt;hr&gt;

## Try It Now

Try the GPT-5 powered PR-Agent instantly on _your public GitHub repository_. Just mention `@CodiumAI-Agent` and add the desired command in any PR comment. The agent will generate a response based on your command.
For example, add a comment to any pull request with the following text:

```
@CodiumAI-Agent /review
```

and the agent will respond with a review of your PR.

Note that this is a promotional bot, suitable only for initial experimentation.
It does not have &#039;edit&#039; access to your repo, for example, so it cannot update the PR description or add labels (`@CodiumAI-Agent /describe` will publish PR description as a comment). In addition, the bot cannot be used on private repositories, as it does not have access to the files there.


## How It Works

The following diagram illustrates PR-Agent tools and their flow:

![PR-Agent Tools](https://www.qodo.ai/images/pr_agent/diagram-v0.9.png)

## Data Privacy

### Self-hosted PR-Agent

- If you host PR-Agent with your OpenAI API key, it is between you and OpenAI. You can read their API data privacy policy here:
https://openai.com/enterprise-privacy

## Contributing

To contribute to the project, get started by reading our [Contributing Guide](https://github.com/qodo-ai/pr-agent/blob/b09eec265ef7d36c232063f76553efb6b53979ff/CONTRIBUTING.md).


## ‚ù§Ô∏è Community

This open-source release remains here as a community contribution from Qodo ‚Äî the origin of modern AI-powered code collaboration. We‚Äôre proud to share it and inspire developers worldwide.

The project now has its first external maintainer, Naor ([@naorpeled](https://github.com/naorpeled)), and is currently in the process of being donated to an open-source foundation.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[QwenLM/Qwen3-Coder]]></title>
            <link>https://github.com/QwenLM/Qwen3-Coder</link>
            <guid>https://github.com/QwenLM/Qwen3-Coder</guid>
            <pubDate>Fri, 06 Feb 2026 00:05:00 GMT</pubDate>
            <description><![CDATA[Qwen3-Coder is the code version of Qwen3, the large language model series developed by Qwen team.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/QwenLM/Qwen3-Coder">QwenLM/Qwen3-Coder</a></h1>
            <p>Qwen3-Coder is the code version of Qwen3, the large language model series developed by Qwen team.</p>
            <p>Language: Python</p>
            <p>Stars: 15,319</p>
            <p>Forks: 1,066</p>
            <p>Stars today: 78 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://qianwen-res.oss-cn-beijing.aliyuncs.com/Qwen3-Coder/qwen3_coder.png&quot; width=&quot;400&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/Qwen3-Coder-Next/swebench_pro.png&quot; width=&quot;800&quot;/&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
        üíú &lt;a href=&quot;https://chat.qwen.ai/&quot;&gt;&lt;b&gt;Qwen Chat&lt;/b&gt;&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspü§ó &lt;a href=&quot;https://huggingface.co/collections/Qwen/qwen3-coder-687fc861e53c939e52d52d10&quot;&gt;Hugging Face&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspü§ñ &lt;a href=&quot;https://modelscope.cn/organization/qwen&quot;&gt;ModelScope&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbsp üìë &lt;a href=&quot;https://qwenlm.github.io/blog/qwen3-coder-next/&quot;&gt;Blog&lt;/a&gt; &amp;nbsp&amp;nbsp ÔΩú &amp;nbsp&amp;nbspüìñ &lt;a href=&quot;https://qwen.readthedocs.io/&quot;&gt;Documentation&lt;/a&gt;
&lt;br&gt;
üåç &lt;a href=&quot;https://huggingface.co/spaces/Qwen/Qwen3-Coder-WebDev&quot;&gt;WebDev&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspüí¨ &lt;a href=&quot;https://github.com/QwenLM/Qwen/blob/main/assets/wechat.png&quot;&gt;WeChat (ÂæÆ‰ø°)&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbspü´® &lt;a href=&quot;https://discord.gg/CV4E9rpNSD&quot;&gt; Discord&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbsp üìÑ &lt;a href=&quot;https://github.com/QwenLM/Qwen3-Coder/blob/main/qwen3_coder_next_tech_report.pdf&quot;&gt;Arxiv&lt;/a&gt;&amp;nbsp&amp;nbsp | &amp;nbsp&amp;nbsp üëΩ &lt;a href=&quot;https://github.com/QwenLM/qwen-code&quot;&gt;Qwen Code&lt;/a&gt;
&lt;/p&gt;

Visit our Hugging Face or ModelScope organization (click links above), search checkpoints with names starting with `Qwen3-Coder-`, and you will find all you need! Enjoy!

---

## Table of Contents
  - [Introduction](#introduction)
    - [Key Features](#key-features)
  - [Basic Information](#basic-information)
  - [Quick Start](#quick-start)
    - [üëâüèª Chat with Qwen3-Coder](#-chat-with-qwen3-coder)
      - [Fill in the middle with Qwen3-Coder](#fill-in-the-middle-with-qwen3-coder)
  - [Use Cases](#use-cases)
    - [Example: Releasing a Website](#example-releasing-a-website)
    - [Example: Desktop Tidy](#example-desktop-tidy)
    - [Example: Zombies vs. Plants](#example-zombies-vs-plants)
    - [Example: Sound ASCII Art](#example-sound-ascii-art)
    - [Example: Vibe Checking](#example-vibe-checking)
    - [Example: Parkour Game](#example-parkour-game)
  - [Star History](#star-history)
  - [Citation](#citation)
  - [Contact Us](#contact-us)

---

# Qwen3-Coder-Next: Pushing Small Hybrid Models on Agentic Coding

## Introduction

We are announcing Qwen3-Coder, our most agentic code model to date. **Qwen3-Coder** is available in multiple sizes, **Qwen3-Coder-480B-A35B-Instruct**, **Qwen3-Coder-30B-A3B-Instruct**, **Qwen3-Coder-Next**, offering exceptional performance in both coding and agentic tasks. 

**Qwen3-Coder-Next**, an open-weight language model designed specifically for coding agents and local development. Built on top of **Qwen3-Next-80B-A3B-Base**, which adopts a novel architecture with hybrid attention and MoE, Qwen3-Coder-Next has been agentically trained at scale on large-scale executable task synthesis, environment interaction, and reinforcement learning, obtaining strong coding and agentic capabilities with significantly lower inference costs.

### Key Features

üíª **Efficiency-Performance Tradeoff**: among open models on **Agentic Coding**, **Agentic Browser-Use**, and other foundational coding tasks, achieving results comparable to Claude Sonnet.

üõ† **Scaling Agentic Coding**: supporting most platforms such as **Qwen Code**, **CLINE**, **Claude Code**, featuring a specially designed function call format;

üìö **Long-context Capabilities**: with native support for **256K** tokens, extendable up to **1M** tokens using Yarn, optimized for repository-scale understanding.

---


## Basic Information

1. ‚ú® Supporting long context understanding and generation with the context length of 256K tokens;
2. ‚ú® Supporting 358 coding languages;

&lt;details&gt;
&lt;summary&gt;Click to view all supported languages&lt;/summary&gt;
```
[&#039;ABAP&#039;, &#039;ActionScript&#039;, &#039;Ada&#039;, &#039;Agda&#039;, &#039;Alloy&#039;, &#039;ApacheConf&#039;, &#039;AppleScript&#039;, &#039;Arc&#039;, &#039;Arduino&#039;, &#039;AsciiDoc&#039;, &#039;AspectJ&#039;, &#039;Assembly&#039;, &#039;Augeas&#039;, &#039;AutoHotkey&#039;, &#039;AutoIt&#039;, &#039;Awk&#039;, &#039;Batchfile&#039;, &#039;Befunge&#039;, &#039;Bison&#039;, &#039;BitBake&#039;, &#039;BlitzBasic&#039;, &#039;BlitzMax&#039;, &#039;Bluespec&#039;, &#039;Boo&#039;, &#039;Brainfuck&#039;, &#039;Brightscript&#039;, &#039;Bro&#039;, &#039;C&#039;, &#039;C#&#039;, &#039;C++&#039;, &#039;C2hs Haskell&#039;, &#039;CLIPS&#039;, &#039;CMake&#039;, &#039;COBOL&#039;, &#039;CSS&#039;, &#039;CSV&#039;, &quot;Cap&#039;n Proto&quot;, &#039;CartoCSS&#039;, &#039;Ceylon&#039;, &#039;Chapel&#039;, &#039;ChucK&#039;, &#039;Cirru&#039;, &#039;Clarion&#039;, &#039;Clean&#039;, &#039;Click&#039;, &#039;Clojure&#039;, &#039;CoffeeScript&#039;, &#039;ColdFusion&#039;, &#039;ColdFusion CFC&#039;, &#039;Common Lisp&#039;, &#039;Component Pascal&#039;, &#039;Coq&#039;, &#039;Creole&#039;, &#039;Crystal&#039;, &#039;Csound&#039;, &#039;Cucumber&#039;, &#039;Cuda&#039;, &#039;Cycript&#039;, &#039;Cython&#039;, &#039;D&#039;, &#039;DIGITAL Command Language&#039;, &#039;DM&#039;, &#039;DNS Zone&#039;, &#039;Darcs Patch&#039;, &#039;Dart&#039;, &#039;Diff&#039;, &#039;Dockerfile&#039;, &#039;Dogescript&#039;, &#039;Dylan&#039;, &#039;E&#039;, &#039;ECL&#039;, &#039;Eagle&#039;, &#039;Ecere Projects&#039;, &#039;Eiffel&#039;, &#039;Elixir&#039;, &#039;Elm&#039;, &#039;Emacs Lisp&#039;, &#039;EmberScript&#039;, &#039;Erlang&#039;, &#039;F#&#039;, &#039;FLUX&#039;, &#039;FORTRAN&#039;, &#039;Factor&#039;, &#039;Fancy&#039;, &#039;Fantom&#039;, &#039;Forth&#039;, &#039;FreeMarker&#039;, &#039;G-code&#039;, &#039;GAMS&#039;, &#039;GAP&#039;, &#039;GAS&#039;, &#039;GDScript&#039;, &#039;GLSL&#039;, &#039;Genshi&#039;, &#039;Gentoo Ebuild&#039;, &#039;Gentoo Eclass&#039;, &#039;Gettext Catalog&#039;, &#039;Glyph&#039;, &#039;Gnuplot&#039;, &#039;Go&#039;, &#039;Golo&#039;, &#039;Gosu&#039;, &#039;Grace&#039;, &#039;Gradle&#039;, &#039;Grammatical Framework&#039;, &#039;GraphQL&#039;, &#039;Graphviz (DOT)&#039;, &#039;Groff&#039;, &#039;Groovy&#039;, &#039;Groovy Server Pages&#039;, &#039;HCL&#039;, &#039;HLSL&#039;, &#039;HTML&#039;, &#039;HTML+Django&#039;, &#039;HTML+EEX&#039;, &#039;HTML+ERB&#039;, &#039;HTML+PHP&#039;, &#039;HTTP&#039;, &#039;Haml&#039;, &#039;Handlebars&#039;, &#039;Harbour&#039;, &#039;Haskell&#039;, &#039;Haxe&#039;, &#039;Hy&#039;, &#039;IDL&#039;, &#039;IGOR Pro&#039;, &#039;INI&#039;, &#039;IRC log&#039;, &#039;Idris&#039;, &#039;Inform 7&#039;, &#039;Inno Setup&#039;, &#039;Io&#039;, &#039;Ioke&#039;, &#039;Isabelle&#039;, &#039;J&#039;, &#039;JFlex&#039;, &#039;JSON&#039;, &#039;JSON5&#039;, &#039;JSONLD&#039;, &#039;JSONiq&#039;, &#039;JSX&#039;, &#039;Jade&#039;, &#039;Jasmin&#039;, &#039;Java&#039;, &#039;Java Server Pages&#039;, &#039;JavaScript&#039;, &#039;Julia&#039;, &#039;Jupyter Notebook&#039;, &#039;KRL&#039;, &#039;KiCad&#039;, &#039;Kit&#039;, &#039;Kotlin&#039;, &#039;LFE&#039;, &#039;LLVM&#039;, &#039;LOLCODE&#039;, &#039;LSL&#039;, &#039;LabVIEW&#039;, &#039;Lasso&#039;, &#039;Latte&#039;, &#039;Lean&#039;, &#039;Less&#039;, &#039;Lex&#039;, &#039;LilyPond&#039;, &#039;Linker Script&#039;, &#039;Liquid&#039;, &#039;Literate Agda&#039;, &#039;Literate CoffeeScript&#039;, &#039;Literate Haskell&#039;, &#039;LiveScript&#039;, &#039;Logos&#039;, &#039;Logtalk&#039;, &#039;LookML&#039;, &#039;Lua&#039;, &#039;M&#039;, &#039;M4&#039;, &#039;MAXScript&#039;, &#039;MTML&#039;, &#039;MUF&#039;, &#039;Makefile&#039;, &#039;Mako&#039;, &#039;Maple&#039;, &#039;Markdown&#039;, &#039;Mask&#039;, &#039;Mathematica&#039;, &#039;Matlab&#039;, &#039;Max&#039;, &#039;MediaWiki&#039;, &#039;Metal&#039;, &#039;MiniD&#039;, &#039;Mirah&#039;, &#039;Modelica&#039;, &#039;Module Management System&#039;, &#039;Monkey&#039;, &#039;MoonScript&#039;, &#039;Myghty&#039;, &#039;NSIS&#039;, &#039;NetLinx&#039;, &#039;NetLogo&#039;, &#039;Nginx&#039;, &#039;Nimrod&#039;, &#039;Ninja&#039;, &#039;Nit&#039;, &#039;Nix&#039;, &#039;Nu&#039;, &#039;NumPy&#039;, &#039;OCaml&#039;, &#039;ObjDump&#039;, &#039;Objective-C++&#039;, &#039;Objective-J&#039;, &#039;Octave&#039;, &#039;Omgrofl&#039;, &#039;Opa&#039;, &#039;Opal&#039;, &#039;OpenCL&#039;, &#039;OpenEdge ABL&#039;, &#039;OpenSCAD&#039;, &#039;Org&#039;, &#039;Ox&#039;, &#039;Oxygene&#039;, &#039;Oz&#039;, &#039;PAWN&#039;, &#039;PHP&#039;, &#039;POV-Ray SDL&#039;, &#039;Pan&#039;, &#039;Papyrus&#039;, &#039;Parrot&#039;, &#039;Parrot Assembly&#039;, &#039;Parrot Internal Representation&#039;, &#039;Pascal&#039;, &#039;Perl&#039;, &#039;Perl6&#039;, &#039;Pickle&#039;, &#039;PigLatin&#039;, &#039;Pike&#039;, &#039;Pod&#039;, &#039;PogoScript&#039;, &#039;Pony&#039;, &#039;PostScript&#039;, &#039;PowerShell&#039;, &#039;Processing&#039;, &#039;Prolog&#039;, &#039;Propeller Spin&#039;, &#039;Protocol Buffer&#039;, &#039;Public Key&#039;, &#039;Pure Data&#039;, &#039;PureBasic&#039;, &#039;PureScript&#039;, &#039;Python&#039;, &#039;Python traceback&#039;, &#039;QML&#039;, &#039;QMake&#039;, &#039;R&#039;, &#039;RAML&#039;, &#039;RDoc&#039;, &#039;REALbasic&#039;, &#039;RHTML&#039;, &#039;RMarkdown&#039;, &#039;Racket&#039;, &#039;Ragel in Ruby Host&#039;, &#039;Raw token data&#039;, &#039;Rebol&#039;, &#039;Red&#039;, &#039;Redcode&#039;, &quot;Ren&#039;Py&quot;, &#039;RenderScript&#039;, &#039;RobotFramework&#039;, &#039;Rouge&#039;, &#039;Ruby&#039;, &#039;Rust&#039;, &#039;SAS&#039;, &#039;SCSS&#039;, &#039;SMT&#039;, &#039;SPARQL&#039;, &#039;SQF&#039;, &#039;SQL&#039;, &#039;STON&#039;, &#039;SVG&#039;, &#039;Sage&#039;, &#039;SaltStack&#039;, &#039;Sass&#039;, &#039;Scala&#039;, &#039;Scaml&#039;, &#039;Scheme&#039;, &#039;Scilab&#039;, &#039;Self&#039;, &#039;Shell&#039;, &#039;ShellSession&#039;, &#039;Shen&#039;, &#039;Slash&#039;, &#039;Slim&#039;, &#039;Smali&#039;, &#039;Smalltalk&#039;, &#039;Smarty&#039;, &#039;Solidity&#039;, &#039;SourcePawn&#039;, &#039;Squirrel&#039;, &#039;Stan&#039;, &#039;Standard ML&#039;, &#039;Stata&#039;, &#039;Stylus&#039;, &#039;SuperCollider&#039;, &#039;Swift&#039;, &#039;SystemVerilog&#039;, &#039;TOML&#039;, &#039;TXL&#039;, &#039;Tcl&#039;, &#039;Tcsh&#039;, &#039;TeX&#039;, &#039;Tea&#039;, &#039;Text&#039;, &#039;Textile&#039;, &#039;Thrift&#039;, &#039;Turing&#039;, &#039;Turtle&#039;, &#039;Twig&#039;, &#039;TypeScript&#039;, &#039;Unified Parallel C&#039;, &#039;Unity3D Asset&#039;, &#039;Uno&#039;, &#039;UnrealScript&#039;, &#039;UrWeb&#039;, &#039;VCL&#039;, &#039;VHDL&#039;, &#039;Vala&#039;, &#039;Verilog&#039;, &#039;VimL&#039;, &#039;Visual Basic&#039;, &#039;Volt&#039;, &#039;Vue&#039;, &#039;Web Ontology Language&#039;, &#039;WebAssembly&#039;, &#039;WebIDL&#039;, &#039;X10&#039;, &#039;XC&#039;, &#039;XML&#039;, &#039;XPages&#039;, &#039;XProc&#039;, &#039;XQuery&#039;, &#039;XS&#039;, &#039;XSLT&#039;, &#039;Xojo&#039;, &#039;Xtend&#039;, &#039;YAML&#039;, &#039;YANG&#039;, &#039;Yacc&#039;, &#039;Zephir&#039;, &#039;Zig&#039;, &#039;Zimpl&#039;, &#039;desktop&#039;, &#039;eC&#039;, &#039;edn&#039;, &#039;fish&#039;, &#039;mupad&#039;, &#039;nesC&#039;, &#039;ooc&#039;, &#039;reStructuredText&#039;, &#039;wisp&#039;, &#039;xBase&#039;]
```
&lt;/details&gt;

3. ‚ú® Retain strengths in math and general capabilities from base model.

&gt; [!Important]
&gt; 
&gt; Qwen3-Coder function calling relies on our new tool parser in both **SGLang** and **vLLM** &lt;a href=&quot;https://huggingface.co/Qwen/Qwen3-Coder-Next/blob/main/&quot;&gt;here&lt;/a&gt;.
&gt;
&gt; We updated both the special tokens and their corresponding token ids, in order to maintain consistency with Qwen3. Please make sure to use the new tokenizer.


| model name                  | type     | length | Download                                                                                                                                                                        |
|-----------------------------|----------|--------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Qwen3-Coder-Next         | instruct     | 256k    | ü§ó [Hugging Face](https://huggingface.co/Qwen/Qwen3-Coder-Next  ) ‚Ä¢ ü§ñ [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-Coder-Next)                                       |
| Qwen3-Coder-Next-Base         | base     | 256k    | ü§ó [Hugging Face](https://huggingface.co/Qwen/Qwen3-Coder-Next-Base) ‚Ä¢ ü§ñ [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-Coder-Next-Base)     |
| Qwen3-Coder-480B-A35B-Instruct         | instruct     | 256k    | ü§ó [Hugging Face](https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct  ) ‚Ä¢ ü§ñ [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-Coder-480B-A35B-Instruct)                                       |
| Qwen3-Coder-30B-A3B-Instruct         | instruct     | 256k    | ü§ó [Hugging Face](https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct) ‚Ä¢ ü§ñ [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct)                                       |
| Qwen3-Coder-Next-FP8         | instruct     | 256k    | ü§ó [Hugging Face](https://huggingface.co/Qwen/Qwen3-Coder-Next-FP8  ) ‚Ä¢ ü§ñ [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-Coder-Next-FP8)
| Qwen3-Coder-Next-GGUF         | instruct     | 256k    | ü§ó [Hugging Face](https://huggingface.co/Qwen/Qwen3-Coder-Next-GGUF  ) ‚Ä¢ ü§ñ [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-Coder-Next-GGUF)                                       |
| Qwen3-Coder-480B-A35B-Instruct-FP8         | instruct     | 256k    | ü§ó [Hugging Face](https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8) ‚Ä¢ ü§ñ [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-Coder-480B-A35B-Instruct-FP8)                                       |
| Qwen3-Coder-30B-A3B-Instruct-FP8         | instruct     | 256k    | ü§ó [Hugging Face](https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8) ‚Ä¢ ü§ñ [ModelScope](https://modelscope.cn/models/Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8)                                       |


Detailed performance and introduction are shown in this &lt;a href=&quot;https://qwenlm.github.io/blog/qwen3-coder-next/&quot;&gt;üìë blog&lt;/a&gt;.

---

## Quick Start

&gt; [!Important]
&gt; **Qwen3-Coder** are instruct models for chatting;
&gt;
&gt; This model supports only non-thinking mode and does not generate `&lt;think&gt;&lt;/think&gt;` blocks in its output. Meanwhile, specifying `enable_thinking=False` is no longer required.
&gt;
### üëâüèª Chat with Qwen3-Coder
You can write several lines of code with `transformers` to chat with Qwen3-Coder-Next. Essentially, we build the tokenizer and the model with the `from_pretrained` method, and we use the generate method to perform chatting with the help of the chat template provided by the tokenizer. Below is an example of how to chat with **Qwen3-Coder-Next**:

```python
from transformers import AutoModelForCausalLM, AutoTokenizer

model_name = &quot;Qwen/Qwen3-Coder-Next&quot;

model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=&quot;auto&quot;,
    device_map=&quot;auto&quot;
)
tokenizer = AutoTokenizer.from_pretrained(model_name)

prompt = &quot;write a quick sort algorithm.&quot;
messages = [
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt}
]
text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)

generated_ids = model.generate(
    **model_inputs,
    max_new_tokens=65536
)
generated_ids = [
    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
]

response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
```
The `apply_chat_template()` function is used to convert the messages into a format that the model can understand.
The `add_generation_prompt` argument is used to add a generation prompt, which refers to `&lt;|im_start|&gt;assistant\n` to the input. Notably, we apply the ChatML template for chat models following our previous practice.
The `max_new_tokens` argument is used to set the maximum length of the response. The `tokenizer.batch_decode()` function is used to decode the response. In terms of the input, the above messages are an example to show how to format your dialog history and system prompt.
You can use the other sizes of instruct models in the same way.


#### Fill in the middle with Qwen3-Coder

The code insertion task, also referred to as the &quot;fill-in-the-middle&quot; challenge, requires the insertion of code segments in a manner that bridges the gaps within a given code context. For an approach aligned with best practices, we recommend adhering to the formatting guidelines outlined in the paper &quot;Efficient Training of Language Models to Fill in the Middle&quot; [[arxiv](https://arxiv.org/abs/2207.14255)]. 

&gt; [!Important]
&gt; It should be noted that FIM is supported in every version of Qwen3-Coder. Qwen3-Coder-Next is shown here as an example.
&gt;

The prompt should be structured as follows:
```python
prompt = &#039;&lt;|fim_prefix|&gt;&#039; + prefix_code + &#039;&lt;|fim_suffix|&gt;&#039; + suffix_code + &#039;&lt;|fim_middle|&gt;&#039;
```
Following the approach mentioned, an example would be structured in this manner:

```python
from transformers import AutoTokenizer, AutoModelForCausalLM
# load model
device = &quot;cuda&quot; # the device to load the model onto

TOKENIZER = AutoTokenizer.from_pretrained(&quot;Qwen/Qwen3-Coder-Next&quot;)
MODEL = AutoModelForCausalLM.from_pretrained(&quot;Qwen/Qwen3-Coder-Next&quot;, device_map=&quot;auto&quot;).eval()


input_text = &quot;&quot;&quot;&lt;|fim_prefix|&gt;def quicksort(arr):
    if len(arr) &lt;= 1:
        return arr
    pivot = arr[len(arr) // 2]
    &lt;|fim_suffix|&gt;
    middle = [x for x in arr if x == pivot]
    right = [x for x in arr if x &gt; pivot]
    return quicksort(left) + middle + quicksort(right)&lt;|fim_middle|&gt;&quot;&quot;&quot;
            
messages = [
    {&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are a code completion assistant.&quot;},
    {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: input_text}
]


text = tokenizer.apply_chat_template(
    messages,
    tokenize=False,
    add_generation_prompt=True
)
model_inputs = TOKENIZER([text], return_tensors=&quot;pt&quot;).to(model.device)

# Use `max_new_tokens` to control the maximum output length.
eos_token_ids = [151659, 151661, 151662, 151663, 151664, 151643, 151645]
generated_ids = MODEL.generate(model_inputs.input_ids, max_new_tokens=512, do_sample=False, eos_token_id=eos_token_ids)[0]
# The generated_ids include prompt_ids, we only need to decode the tokens after prompt_ids.
output_text = TOKENIZER.decode(generated_ids[len(model_inputs.input_ids[0]):], skip_special_tokens=True)

print(f&quot;Prompt: {input_text}\n\nGenerated text: {output_text}&quot;)
```

## Use Cases

### Example: Releasing a Website

&lt;details&gt;
&lt;summary&gt;Prompt with OpenClaw &lt;/summary&gt;

```
next week we will release new coder model, can you collect the history of qwen coder and write a web page, the release the website with the nginx, you can seach how to do this in alibaba cloud linux first
```

&lt;/details&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/Qwen3-Coder-Next/openclaw/claw_mix.mp4&quot;&gt;
    &lt;img src=&quot;assets/qwen3-coder-next-demo/openclaw.png&quot; width=&quot;400&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;


### Example: Desktop Tidy

&lt;details&gt;
&lt;summary&gt;Prompt with Qwen Code &lt;/summary&gt;

```
Please tidy up my desk.
```
&lt;/details&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/Qwen3-Coder-Next/qwencode/exp-tidy-desktop.mp4&quot;&gt;
    &lt;img src=&quot;assets/qwen3-coder-next-demo/tidy_desktop.png&quot; width=&quot;400&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

### Example: Zombies vs. Plants

&lt;details&gt;
&lt;summary&gt;Prompt with Claude Code &lt;/summary&gt;

```
Â∏ÆÊàëÂÆûÁé∞„ÄäÂÉµÂ∞∏Â§ßÊàòÊ§çÁâ©„ÄãÁΩëÈ°µÊ∏∏Êàè

„ÄêÊ†∏ÂøÉÊú∫Âà∂„Äë
- ÂèçÂêëÂ°îÈò≤ÔºöÁé©ÂÆ∂ÊâÆÊºîÂÉµÂ∞∏ÊñπÔºå‰ªéÂú∞ÂõæÂè≥‰æßÔºàÈÉ®ÁΩ≤Âå∫ÔºâÂè¨Âî§ÂÉµÂ∞∏ÂêëÂ∑¶ËøõÊîª
- ËµÑÊ∫êÂæ™ÁéØÔºöÂàùÂßã300ËÑëÂ≠êÁÇπÊï∞ÔºåÂÉµÂ∞∏ÂêÉÊéâÊ§çÁâ©ËøîËøò100ÁÇπÔºåÂΩ¢ÊàêÁªèÊµéÂæ™ÁéØ
- ÂÄíËÆ°Êó∂Âà∂Ôºö120ÁßíÂÜÖÊ∏ÖÈô§ÊâÄÊúâÊ§çÁâ©Ëé∑ËÉúÔºåË∂ÖÊó∂Â§±Ë¥•

„ÄêÂú∞ÂõæËßÑÊ†º„Äë
- 5Ë°å9ÂàóÁΩëÊ†ºÔºåÂè≥‰æß3Âàó‰∏∫ÂèØÈÉ®ÁΩ≤Âå∫ÂüüÔºàÁ∫¢Ëâ≤È´ò‰∫ÆÊ†áËØÜÔºâ
- ÊØèÊ†º100x100ÂÉèÁ¥†ÔºåËçâÂú∞Á∫πÁêÜ‰∫§ÊõøÊ∏≤Êüì
- ÂùêÊ†áÁ≥ªÔºöÂ∑¶‰æß‰∏∫Ê§çÁâ©Èò≤Á∫øÔºåÂè≥‰æß‰∏∫ÂÉµÂ∞∏Âá∫ÁîüÁÇπ

„ÄêÂçï‰ΩçÁ≥ªÁªü„Äë
ÂÉµÂ∞∏ÊñπÔºàÂè≥‰æßË¥≠‰π∞ÔºâÔºö
- ÊôÆÈÄöÂÉµÂ∞∏Ôºö50ËÑëÔºå100HPÔºå0.5ÈÄüÔºåÊ†áÂáÜÂçï‰Ωç
- Ë∑ØÈöúÂÉµÂ∞∏Ôºö100ËÑëÔºå200HPÔºå0.5ÈÄüÔºå‰∏≠ÊúüËÇâÁõæ  
- ÈìÅÊ°∂ÂÉµÂ∞∏Ôºö150ËÑëÔºå400HPÔºå0.3ÈÄüÔºåÈáçÂûãÂù¶ÂÖã
- ÂÜ≤Âà∫ÂÉµÂ∞∏Ôºö80ËÑëÔºå80HPÔºå1.2ÈÄüÔºåÂø´ÈÄüÁ™ÅËøõ

Ê§çÁâ©ÊñπÔºàÂ∑¶‰æßÈöèÊú∫ÂàùÂßãÈÉ®ÁΩ≤12‰∏™ÔºâÔºö
- Ë±åË±ÜÂ∞ÑÊâãÔºö100HPÔºå20‰º§/ÂèëÔºå2ÁßíÈó¥ÈöîÔºåÁõ¥Á∫øÂ∞ÑÂáª
- ÂèåÂèëÂ∞ÑÊâãÔºö120HPÔºå20‰º§/ÂèëÔºå1ÁßíÈó¥ÈöîÔºåÁÅ´ÂäõÂéãÂà∂
- ÂùöÊûúÂ¢ôÔºö300HPÔºå0‰º§ÔºåÁ∫ØËÇâÁõæÈòªÊå°
- ÂêëÊó•ËëµÔºö80HPÔºå0‰º§ÔºåÁªèÊµéÂçï‰ΩçÔºàÁ∫ØÂπ≤Êâ∞Ôºâ

„ÄêÊàòÊñóÈÄªËæë„Äë
- Á¢∞ÊíûÊ£ÄÊµãÔºöÂÉµÂ∞∏Âà∞ËææÊ§çÁâ©50pxÂÜÖËß¶ÂèëÂïÉÈ£üÁä∂ÊÄÅÔºåÂÅúÊ≠¢ÁßªÂä®
- ‰º§ÂÆ≥ÁªìÁÆóÔºöÂÉµÂ∞∏30Â∏ß/Ê¨°Âí¨ÂáªÔºà0.5ÁßíÔºâÔºåÊ§çÁâ©Â∞ÑÂá∫ÂºπÈÅìÁâ©ÁêÜ
- ÂáªÊØÅÂèçÈ¶àÔºöÊ§çÁâ©Ê≠ª‰∫°Êó∂ÁîüÊàê&quot;+100&quot;È£òÂ≠óÁâπÊïà‰∏éÁ≤íÂ≠êÁàÜÁÇ∏
- Ë∑ØÂæÑAIÔºöÂêåÊ†ºÂÉµÂ∞∏ÈòüÂàó‰∏çÈáçÂè†ÔºåÊ§çÁâ©‰ºòÂÖàÊîªÂáªÊ®™ÂêëÊúÄËøëÁõÆÊ†á

„Äê‰∫§‰∫íËÆæËÆ°„Äë
- Âè≥‰æßÂç°ÁâáÂºèUIÔºöÊòæÁ§∫ÂÉµÂ∞∏ÂõæÊ†á„ÄÅÂêçÁß∞„ÄÅËÑëÂ≠êÊ∂àËÄó
- ËµÑÊ∫ê‰∏çË∂≥Êó∂Âç°ÁâáÁΩÆÁÅ∞Âπ∂Ëá™Âä®ÂàáÊç¢ÂèØÈÄâÁ±ªÂûã
- Èº†Ê†áÊÇ¨ÂÅúÈÉ®ÁΩ≤Âå∫ÊòæÁ§∫ÂçäÈÄèÊòéÈ¢ÑËßàÂúà
- ÂÆûÊó∂Ë°ÄÊù°ÔºöÂÆû‰ΩìÂ§¥È°∂ÊòæÁ§∫Áªø/ÈªÑ/Á∫¢‰∏âËâ≤Ë°ÄÊßΩ

„ÄêËÉúÂà©Êù°‰ª∂„Äë
- ËÉúÂà©Ôºöplants.length === 0 &amp;&amp; timeLeft &gt; 0
- Â§±Ë¥•ÔºötimeLeft === 0 || (ÂèØÈÄâ)ÂÉµÂ∞∏ÂÖ®ÁÅ≠‰∏îËÑëÂ≠ê‰∏∫0
```

&lt;/details&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/Qwen3-Coder-Next/claudecode/cc_zombine_vs_plants.mp4&quot;&gt;
    &lt;img src=&quot;assets/qwen3-coder-next-demo/zombiesvsplants.png&quot; width=&quot;400&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

### Example: Sound ASCII Art

&lt;details&gt;
&lt;summary&gt;Prompt with Cline &lt;/summary&gt;

```
Build an interactive ASCII art drawing tool with sound feedback. The application should:
 
1. Create a canvas where users can draw by clicking and dragging
2. Place different ASCII characters or symbols when the user draws
3. Play corresponding musical notes when each character is placed
4. Include multiple pattern sets with different characters and
corresponding note scales
5. Add a pattern switcher button to cycle through different
character/sound themes
6. Include a clear button to reset the canvas
7. Support both mouse and touch input for mobile compatibility
 
The application should be creative and fun to use, creating an audio-visual experience where patterns of characters create both visual art and musical patterns. Ensure the musical notes are harmonious when played in sequence.
```

&lt;/details&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/Qwen3-Coder-Next/cline/sound_art.mp4&quot;&gt;
    &lt;img src=&quot;assets/qwen3-coder-next-demo/sound_art.png&quot; width=&quot;400&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

### Example: Vibe Checking


&lt;details&gt;
&lt;summary&gt; Prompt with Browser Use Agent &lt;/summary&gt;

```
Vibe test this website. Click around, try things, report what&#039;s broken.
```
&lt;/details&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/Qwen3-Coder-Next/bua/vibe.mp4&quot;&gt;
    &lt;img src=&quot;assets/qwen3-coder-next-demo/vibing_check.png&quot; width=&quot;400&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;

### Example: Parkour Game


&lt;details&gt;
&lt;summary&gt; Prompt with Qwen Chat Web Dev &lt;/summary&gt;

```
Create an interactive real-time particle system using HTML5 Canvas:

Core Features:
- Render 800-1200 animated particles with physics-based movement
- Mouse cursor exerts attractive/repulsive force on nearby particles
- Click to toggle between attraction and repulsion modes
- Particles respond with smooth acceleration and velocity calculations

Technical Requirements:
- Use requestAnimationFrame for optimal performance
- Implement force calculation based on distance from cursor
- Add visual feedback: particle glow, color variation, and fade effects
- Include performance monitoring (FPS counter)

Deliverables:
- Single HTML file with embedded CSS and JavaScript
- Clean, commented code following best practices
- Responsive design compatible with modern browsers
```
&lt;/details&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://qianwen-res.oss-accelerate-overseas.aliyuncs.com/Qwen3-Coder-Next/WebDev/chico_paredao.mp4&quot;&gt;
    &lt;img src=&quot;assets/qwen3-coder-next-demo/parkourgame.png&quot; width=&quot;400&quot; /&gt;
    &lt;/a&gt;
&lt;/p&gt;


---

## Star History
[![Star History Chart](https://api.star-history.com/svg?repos=QwenLM/Qwen3-Coder&amp;type=Date)](https://star-history.com/#QwenLM/Qwen3-Coder&amp;Date)

---

## Citation

If you find our work helpful, feel free to give us a cite.

```bibtex
@techreport{qwen_qwen3_coder_next_tech_report,
  title

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Polymarket/agents]]></title>
            <link>https://github.com/Polymarket/agents</link>
            <guid>https://github.com/Polymarket/agents</guid>
            <pubDate>Fri, 06 Feb 2026 00:04:59 GMT</pubDate>
            <description><![CDATA[Trade autonomously on Polymarket using AI Agents]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Polymarket/agents">Polymarket/agents</a></h1>
            <p>Trade autonomously on Polymarket using AI Agents</p>
            <p>Language: Python</p>
            <p>Stars: 2,023</p>
            <p>Forks: 534</p>
            <p>Stars today: 34 stars today</p>
            <h2>README</h2><pre>&lt;!-- PROJECT SHIELDS --&gt;
[![Contributors][contributors-shield]][contributors-url]
[![Forks][forks-shield]][forks-url]
[![Stargazers][stars-shield]][stars-url]
[![Issues][issues-shield]][issues-url]
[![MIT License][license-shield]][license-url]


&lt;!-- PROJECT LOGO --&gt;
&lt;br /&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/polymarket/agents&quot;&gt;
    &lt;img src=&quot;docs/images/cli.png&quot; alt=&quot;Logo&quot; width=&quot;466&quot; height=&quot;262&quot;&gt;
  &lt;/a&gt;

&lt;h3 align=&quot;center&quot;&gt;Polymarket Agents&lt;/h3&gt;

  &lt;p align=&quot;center&quot;&gt;
    Trade autonomously on Polymarket using AI Agents
    &lt;br /&gt;
    &lt;a href=&quot;https://github.com/polymarket/agents&quot;&gt;&lt;strong&gt;Explore the docs ¬ª&lt;/strong&gt;&lt;/a&gt;
    &lt;br /&gt;
    &lt;br /&gt;
    &lt;a href=&quot;https://github.com/polymarket/agents&quot;&gt;View Demo&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/polymarket/agents/issues/new?labels=bug&amp;template=bug-report---.md&quot;&gt;Report Bug&lt;/a&gt;
    ¬∑
    &lt;a href=&quot;https://github.com/polymarket/agents/issues/new?labels=enhancement&amp;template=feature-request---.md&quot;&gt;Request Feature&lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;


&lt;!-- CONTENT --&gt;
# Polymarket Agents

Polymarket Agents is a developer framework and set of utilities for building AI agents for Polymarket.

This code is free and publicly available under MIT License open source license ([terms of service](#terms-of-service))!

## Features

- Integration with Polymarket API
- AI agent utilities for prediction markets
- Local and remote RAG (Retrieval-Augmented Generation) support
- Data sourcing from betting services, news providers, and web search
- Comphrehensive LLM tools for prompt engineering

# Getting started

This repo is inteded for use with Python 3.9

1. Clone the repository

   ```
   git clone https://github.com/{username}/polymarket-agents.git
   cd polymarket-agents
   ```

2. Create the virtual environment

   ```
   virtualenv --python=python3.9 .venv
   ```

3. Activate the virtual environment

   - On Windows:

   ```
   .venv\Scripts\activate
   ```

   - On macOS and Linux:

   ```
   source .venv/bin/activate
   ```

4. Install the required dependencies:

   ```
   pip install -r requirements.txt
   ```

5. Set up your environment variables:

   - Create a `.env` file in the project root directory

   ```
   cp .env.example .env
   ```

   - Add the following environment variables:

   ```
   POLYGON_WALLET_PRIVATE_KEY=&quot;&quot;
   OPENAI_API_KEY=&quot;&quot;
   ```

6. Load your wallet with USDC.

7. Try the command line interface...

   ```
   python scripts/python/cli.py
   ```

   Or just go trade! 

   ```
   python agents/application/trade.py
   ```

8. Note: If running the command outside of docker, please set the following env var:

   ```
   export PYTHONPATH=&quot;.&quot;
   ```

   If running with docker is preferred, we provide the following scripts:

   ```
   ./scripts/bash/build-docker.sh
   ./scripts/bash/run-docker-dev.sh
   ```

## Architecture

The Polymarket Agents architecture features modular components that can be maintained and extended by individual community members.

### APIs

Polymarket Agents connectors standardize data sources and order types.

- `Chroma.py`: chroma DB for vectorizing news sources and other API data. Developers are able to add their own vector database implementations.

- `Gamma.py`: defines `GammaMarketClient` class, which interfaces with the Polymarket Gamma API to fetch and parse market and event metadata. Methods to retrieve current and tradable markets, as well as defined information on specific markets and events.

- `Polymarket.py`: defines a Polymarket class that interacts with the Polymarket API to retrieve and manage market and event data, and to execute orders on the Polymarket DEX. It includes methods for API key initialization, market and event data retrieval, and trade execution. The file also provides utility functions for building and signing orders, as well as examples for testing API interactions.

- `Objects.py`: data models using Pydantic; representations for trades, markets, events, and related entities.

### Scripts

Files for managing your local environment, server set-up to run the application remotely, and cli for end-user commands.

`cli.py` is the primary user interface for the repo. Users can run various commands to interact with the Polymarket API, retrieve relevant news articles, query local data, send data/prompts to LLMs, and execute trades in Polymarkets.

Commands should follow this format:

`python scripts/python/cli.py command_name [attribute value] [attribute value]`

Example:

`get-all-markets`
Retrieve and display a list of markets from Polymarket, sorted by volume.

   ```
   python scripts/python/cli.py get-all-markets --limit &lt;LIMIT&gt; --sort-by &lt;SORT_BY&gt;
   ```

- limit: The number of markets to retrieve (default: 5).
- sort_by: The sorting criterion, either volume (default) or another valid attribute.

# Contributing

If you would like to contribute to this project, please follow these steps:

1. Fork the repository.
2. Create a new branch.
3. Make your changes.
4. Submit a pull request.

Please run pre-commit hooks before making contributions. To initialize them:

   ```
   pre-commit install
   ```

# Related Repos

- [py-clob-client](https://github.com/Polymarket/py-clob-client): Python client for the Polymarket CLOB
- [python-order-utils](https://github.com/Polymarket/python-order-utils): Python utilities to generate and sign orders from Polymarket&#039;s CLOB
- [Polymarket CLOB client](https://github.com/Polymarket/clob-client): Typescript client for Polymarket CLOB
- [Langchain](https://github.com/langchain-ai/langchain): Utility for building context-aware reasoning applications
- [Chroma](https://docs.trychroma.com/getting-started): Chroma is an AI-native open-source vector database

# Prediction markets reading

- Prediction Markets: Bottlenecks and the Next Major Unlocks, Mikey 0x: https://mirror.xyz/1kx.eth/jnQhA56Kx9p3RODKiGzqzHGGEODpbskivUUNdd7hwh0
- The promise and challenges of crypto + AI applications, Vitalik Buterin: https://vitalik.eth.limo/general/2024/01/30/cryptoai.html
- Superforecasting: How to Upgrade Your Company&#039;s Judgement, Schoemaker and Tetlock: https://hbr.org/2016/05/superforecasting-how-to-upgrade-your-companys-judgment

# License

This project is licensed under the MIT License. See the [LICENSE](https://github.com/Polymarket/agents/blob/main/LICENSE.md) file for details.

# Contact

For any questions or inquiries, please contact liam@polymarket.com or reach out at www.greenestreet.xyz

Enjoy using the CLI application! If you encounter any issues, feel free to open an issue on the repository.

# Terms of Service

[Terms of Service](https://polymarket.com/tos) prohibit US persons and persons from certain other jurisdictions from trading on Polymarket (via UI &amp; API and including agents developed by persons in restricted jurisdictions), although data and information is viewable globally.


&lt;!-- LINKS --&gt;
[contributors-shield]: https://img.shields.io/github/contributors/polymarket/agents?style=for-the-badge
[contributors-url]: https://github.com/polymarket/agents/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/polymarket/agents?style=for-the-badge
[forks-url]: https://github.com/polymarket/agents/network/members
[stars-shield]: https://img.shields.io/github/stars/polymarket/agents?style=for-the-badge
[stars-url]: https://github.com/polymarket/agents/stargazers
[issues-shield]: https://img.shields.io/github/issues/polymarket/agents?style=for-the-badge
[issues-url]: https://github.com/polymarket/agents/issues
[license-shield]: https://img.shields.io/github/license/polymarket/agents?style=for-the-badge
[license-url]: https://github.com/polymarket/agents/blob/master/LICENSE.md
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>