<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Mon, 18 Aug 2025 00:05:09 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2025, GitHub</copyright>
        <item>
            <title><![CDATA[coleam00/Archon]]></title>
            <link>https://github.com/coleam00/Archon</link>
            <guid>https://github.com/coleam00/Archon</guid>
            <pubDate>Mon, 18 Aug 2025 00:05:09 GMT</pubDate>
            <description><![CDATA[Beta release of Archon OS - the knowledge and task management backbone for AI coding assistants.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/coleam00/Archon">coleam00/Archon</a></h1>
            <p>Beta release of Archon OS - the knowledge and task management backbone for AI coding assistants.</p>
            <p>Language: Python</p>
            <p>Stars: 7,570</p>
            <p>Forks: 1,457</p>
            <p>Stars today: 990 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;./archon-ui-main/public/archon-main-graphic.png&quot; alt=&quot;Archon Main Graphic&quot; width=&quot;853&quot; height=&quot;422&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;em&gt;Power up your AI coding assistants with your own custom knowledge base and task management as an MCP server&lt;/em&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;#quick-start&quot;&gt;Quick Start&lt;/a&gt; â€¢
  &lt;a href=&quot;#whats-included&quot;&gt;What&#039;s Included&lt;/a&gt; â€¢
  &lt;a href=&quot;#architecture&quot;&gt;Architecture&lt;/a&gt;
&lt;/p&gt;

---

## ğŸ¯ What is Archon?

&gt; Archon is currently in beta! Expect things to not work 100%, and please feel free to share any feedback and contribute with fixes/new features!

Archon is the **command center** for AI coding assistants. For you, it&#039;s a sleek interface to manage knowledge, context, and tasks for your projects. For the AI coding assistant(s), it&#039;s a **Model Context Protocol (MCP) server** to collaborate on and leverage the same knowledge, context, and tasks. Connect Claude Code, Kiro, Cursor, Windsurf, etc. to give your AI agents access to:

- **Your documentation** (crawled websites, uploaded PDFs/docs)
- **Smart search capabilities** with advanced RAG strategies  
- **Task management** integrated with your knowledge base
- **Real-time updates** as you add new content and collaborate with your coding assistant on tasks
- **Much more** coming soon to build Archon into an integrated environment for all context engineering

This new vision for Archon replaces the old one (the agenteer). Archon used to be the AI agent that builds other agents, and now you can use Archon to do that and more.

&gt; It doesn&#039;t matter what you&#039;re building or if it&#039;s a new/existing codebase - Archon&#039;s knowledge and task management capabilities will improve the output of **any** AI driven coding.

## ğŸ”— Important Links

- **[GitHub Discussions](https://github.com/coleam00/Archon/discussions)** - Join the conversation and share ideas about Archon
- **[Contributing Guide](CONTRIBUTING.md)** - How to get involved and contribute to Archon
- **[Introduction Video](https://youtu.be/8pRc_s2VQIo)** - Getting Started Guide and Vision for Archon
- **[Dynamous AI Mastery](https://dynamous.ai)** - The birthplace of Archon - come join a vibrant community of other early AI adopters all helping each other transform their careers and businesses!

## Quick Start

### Prerequisites
- [Docker Desktop](https://www.docker.com/products/docker-desktop/)
- [Supabase](https://supabase.com/) account (free tier or local Supabase both work)
- [OpenAI API key](https://platform.openai.com/api-keys) (Gemini and Ollama are supported too!)

### Setup Instructions

1. **Clone Repository**:
   ```bash
   git clone https://github.com/coleam00/archon.git
   cd archon
   ```

2. **Environment Configuration**:
   ```bash
   cp .env.example .env
   # Edit .env and add your Supabase credentials:
   # SUPABASE_URL=https://your-project.supabase.co
   # SUPABASE_SERVICE_KEY=your-service-key-here
   ```

   NOTE: Supabase introduced a new type of service key but use the legacy one (the longer one).

   OPTIONAL: If you want to enable the reranking RAG strategy, uncomment lines 20-22 in `python\requirements.server.txt`. This will significantly increase the size of the Archon Server container which is why it&#039;s off by default.

3. **Database Setup**: In your [Supabase project](https://supabase.com/dashboard) SQL Editor, copy, paste, and execute the contents of `migration/complete_setup.sql`

4. **Start Services**:
   ```bash
   docker-compose up --build -d
   ```
   
   This starts the core microservices:
   - **Server**: Core API and business logic (Port: 8181)
   - **MCP Server**: Protocol interface for AI clients (Port: 8051)
   - **Agents (coming soon!)**: AI operations and streaming (Port: 8052)
   - **UI**: Web interface (Port: 3737)

   Ports are configurable in your .env as well!

5. **Configure API Keys**:
   - Open http://localhost:3737
   - Go to **Settings** â†’ Select your LLM/embedding provider and set the API key (OpenAI is default)
   - Test by uploading a document or crawling a website

## ğŸ”„ Database Reset (Start Fresh if Needed)

If you need to completely reset your database and start fresh:

&lt;details&gt;
&lt;summary&gt;âš ï¸ &lt;strong&gt;Reset Database - This will delete ALL data for Archon!&lt;/strong&gt;&lt;/summary&gt;

1. **Run Reset Script**: In your Supabase SQL Editor, run the contents of `migration/RESET_DB.sql`
   
   âš ï¸ WARNING: This will delete all Archon specific tables and data! Nothing else will be touched in your DB though.

2. **Rebuild Database**: After reset, run `migration/complete_setup.sql` to create all the tables again.

3. **Restart Services**:
   ```bash
   docker-compose up -d
   ```

4. **Reconfigure**: 
   - Select your LLM/embedding provider and set the API key again
   - Re-upload any documents or re-crawl websites

The reset script safely removes all tables, functions, triggers, and policies with proper dependency handling.

&lt;/details&gt;

## âš¡ Quick Test

Once everything is running:

1. **Test Web Crawling**: Go to http://localhost:3737 â†’ Knowledge Base â†’ &quot;Crawl Website&quot; â†’ Enter a doc URL (such as https://ai.pydantic.dev/llms-full.txt)
2. **Test Document Upload**: Knowledge Base â†’ Upload a PDF
3. **Test Projects**: Projects â†’ Create a new project and add tasks
4. **Integrate with your AI coding assistant**: MCP Dashboard â†’ Copy connection config for your AI coding assistant

## ğŸ“š Documentation

### Core Services

| Service | Container Name | Default URL | Purpose |
|---------|---------------|-------------|---------|
| **Web Interface** | archon-ui | http://localhost:3737 | Main dashboard and controls |
| **API Service** | archon-server | http://localhost:8181 | Web crawling, document processing |
| **MCP Server** | archon-mcp | http://localhost:8051 | Model Context Protocol interface |
| **Agents Service** | archon-agents | http://localhost:8052 | AI/ML operations, reranking |

## What&#039;s Included

### ğŸ§  Knowledge Management
- **Smart Web Crawling**: Automatically detects and crawls entire documentation sites, sitemaps, and individual pages
- **Document Processing**: Upload and process PDFs, Word docs, markdown files, and text documents with intelligent chunking
- **Code Example Extraction**: Automatically identifies and indexes code examples from documentation for enhanced search
- **Vector Search**: Advanced semantic search with contextual embeddings for precise knowledge retrieval
- **Source Management**: Organize knowledge by source, type, and tags for easy filtering

### ğŸ¤– AI Integration  
- **Model Context Protocol (MCP)**: Connect any MCP-compatible client (Claude Code, Cursor, even non-AI coding assistants like Claude Desktop)
- **10 MCP Tools**: Comprehensive yet simple set of tools for RAG queries, task management, and project operations
- **Multi-LLM Support**: Works with OpenAI, Ollama, and Google Gemini models
- **RAG Strategies**: Hybrid search, contextual embeddings, and result reranking for optimal AI responses
- **Real-time Streaming**: Live responses from AI agents with progress tracking

### ğŸ“‹ Project &amp; Task Management
- **Hierarchical Projects**: Organize work with projects, features, and tasks in a structured workflow
- **AI-Assisted Creation**: Generate project requirements and tasks using integrated AI agents  
- **Document Management**: Version-controlled documents with collaborative editing capabilities
- **Progress Tracking**: Real-time updates and status management across all project activities

### ğŸ”„ Real-time Collaboration
- **WebSocket Updates**: Live progress tracking for crawling, processing, and AI operations
- **Multi-user Support**: Collaborative knowledge building and project management
- **Background Processing**: Asynchronous operations that don&#039;t block the user interface
- **Health Monitoring**: Built-in service health checks and automatic reconnection

## Architecture

### Microservices Structure

Archon uses true microservices architecture with clear separation of concerns:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend UI   â”‚    â”‚  Server (API)   â”‚    â”‚   MCP Server    â”‚    â”‚ Agents Service  â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚  React + Vite   â”‚â—„â”€â”€â–ºâ”‚    FastAPI +    â”‚â—„â”€â”€â–ºâ”‚    Lightweight  â”‚â—„â”€â”€â–ºâ”‚   PydanticAI    â”‚
â”‚  Port 3737      â”‚    â”‚    SocketIO     â”‚    â”‚    HTTP Wrapper â”‚    â”‚   Port 8052     â”‚
â”‚                 â”‚    â”‚    Port 8181    â”‚    â”‚    Port 8051    â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚                        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚                        â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
                         â”‚    Database     â”‚               â”‚
                         â”‚                 â”‚               â”‚
                         â”‚    Supabase     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚    PostgreSQL   â”‚
                         â”‚    PGVector     â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Service Responsibilities

| Service | Location | Purpose | Key Features |
|---------|----------|---------|--------------|
| **Frontend** | `archon-ui-main/` | Web interface and dashboard | React, TypeScript, TailwindCSS, Socket.IO client |
| **Server** | `python/src/server/` | Core business logic and APIs | FastAPI, service layer, Socket.IO broadcasts, all ML/AI operations |
| **MCP Server** | `python/src/mcp/` | MCP protocol interface | Lightweight HTTP wrapper, 10 MCP tools, session management |
| **Agents** | `python/src/agents/` | PydanticAI agent hosting | Document and RAG agents, streaming responses |

### Communication Patterns

- **HTTP-based**: All inter-service communication uses HTTP APIs
- **Socket.IO**: Real-time updates from Server to Frontend  
- **MCP Protocol**: AI clients connect to MCP Server via SSE or stdio
- **No Direct Imports**: Services are truly independent with no shared code dependencies

### Key Architectural Benefits

- **Lightweight Containers**: Each service contains only required dependencies
- **Independent Scaling**: Services can be scaled independently based on load
- **Development Flexibility**: Teams can work on different services without conflicts
- **Technology Diversity**: Each service uses the best tools for its specific purpose

## ğŸ”§ Configuring Custom Ports &amp; Hostname

By default, Archon services run on the following ports:
- **Archon-UI**: 3737
- **Archon-Server**: 8181  
- **Archon-MCP**: 8051
- **Archon-Agents**: 8052
- **Archon-Docs**: 3838 (optional)

### Changing Ports

To use custom ports, add these variables to your `.env` file:

```bash
# Service Ports Configuration
ARCHON_UI_PORT=3737
ARCHON_SERVER_PORT=8181
ARCHON_MCP_PORT=8051
ARCHON_AGENTS_PORT=8052
ARCHON_DOCS_PORT=3838
```

Example: Running on different ports:
```bash
ARCHON_SERVER_PORT=8282
ARCHON_MCP_PORT=8151
```

### Configuring Hostname

By default, Archon uses `localhost` as the hostname. You can configure a custom hostname or IP address by setting the `HOST` variable in your `.env` file:

```bash
# Hostname Configuration
HOST=localhost  # Default

# Examples of custom hostnames:
HOST=192.168.1.100     # Use specific IP address
HOST=archon.local      # Use custom domain
HOST=myserver.com      # Use public domain
```

This is useful when:
- Running Archon on a different machine and accessing it remotely
- Using a custom domain name for your installation
- Deploying in a network environment where `localhost` isn&#039;t accessible

After changing hostname or ports:
1. Restart Docker containers: `docker-compose down &amp;&amp; docker-compose up -d`
2. Access the UI at: `http://${HOST}:${ARCHON_UI_PORT}`
3. Update your AI client configuration with the new hostname and MCP port

## ğŸ”§ Development

For development with hot reload:

```bash
# Backend services (with auto-reload)
docker-compose up archon-server archon-mcp archon-agents --build

# Frontend (with hot reload) 
cd archon-ui-main &amp;&amp; npm run dev

# Documentation (with hot reload)
cd docs &amp;&amp; npm start
```

**Note**: The backend services are configured with `--reload` flag in their uvicorn commands and have source code mounted as volumes for automatic hot reloading when you make changes.

## ğŸ“„ License

Archon Community License (ACL) v1.2 - see [LICENSE](LICENSE) file for details.

**TL;DR**: Archon is free, open, and hackable. Run it, fork it, share it - just don&#039;t sell it as-a-service without permission.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[emcie-co/parlant]]></title>
            <link>https://github.com/emcie-co/parlant</link>
            <guid>https://github.com/emcie-co/parlant</guid>
            <pubDate>Mon, 18 Aug 2025 00:05:08 GMT</pubDate>
            <description><![CDATA[LLM agents built for control. Designed for real-world use. Deployed in minutes.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/emcie-co/parlant">emcie-co/parlant</a></h1>
            <p>LLM agents built for control. Designed for real-world use. Deployed in minutes.</p>
            <p>Language: Python</p>
            <p>Stars: 4,822</p>
            <p>Forks: 462</p>
            <p>Stars today: 460 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;picture&gt;
  &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentLight.png?raw=true&quot;&gt;
  &lt;img alt=&quot;Parlant - AI Agent Framework&quot; src=&quot;https://github.com/emcie-co/parlant/blob/develop/docs/LogoTransparentDark.png?raw=true&quot; width=400 /&gt;
&lt;/picture&gt;

&lt;h3&gt;Finally, LLM agents that actually follow instructions&lt;/h3&gt;

&lt;p&gt;
  &lt;a href=&quot;https://www.parlant.io/&quot; target=&quot;_blank&quot;&gt;ğŸŒ Website&lt;/a&gt; â€¢
  &lt;a href=&quot;https://www.parlant.io/docs/quickstart/installation&quot; target=&quot;_blank&quot;&gt;âš¡ Quick Start&lt;/a&gt; â€¢
  &lt;a href=&quot;https://discord.gg/duxWqxKk6J&quot; target=&quot;_blank&quot;&gt;ğŸ’¬ Discord&lt;/a&gt; â€¢
  &lt;a href=&quot;https://www.parlant.io/docs/quickstart/examples&quot; target=&quot;_blank&quot;&gt;ğŸ“– Examples&lt;/a&gt;
&lt;/p&gt;

&lt;p&gt;
  &lt;a href=&quot;https://pypi.org/project/parlant/&quot;&gt;&lt;img alt=&quot;PyPI&quot; src=&quot;https://img.shields.io/pypi/v/parlant?color=blue&quot;&gt;&lt;/a&gt;
  &lt;img alt=&quot;Python 3.10+&quot; src=&quot;https://img.shields.io/badge/python-3.10+-blue&quot;&gt;
  &lt;a href=&quot;https://opensource.org/licenses/Apache-2.0&quot;&gt;&lt;img alt=&quot;License&quot; src=&quot;https://img.shields.io/badge/license-Apache%202.0-green&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.gg/duxWqxKk6J&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1312378700993663007?color=7289da&amp;logo=discord&amp;logoColor=white&quot;&gt;&lt;/a&gt;
  &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/emcie-co/parlant?style=social&quot;&gt;
&lt;/p&gt;

&lt;a href=&quot;https://trendshift.io/repositories/12768&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://trendshift.io/api/badge/repositories/12768&quot; alt=&quot;Trending on TrendShift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
&lt;/a&gt;

&lt;/div&gt;

## ğŸ¯ The Problem Every AI Developer Faces

You build an AI agent. It works great in testing. Then real users start talking to it and...

- âŒ It ignores your carefully crafted system prompts
- âŒ It hallucinates responses in critical moments
- âŒ It can&#039;t handle edge cases consistently
- âŒ Each conversation feels like a roll of the dice

**Sound familiar?** You&#039;re not alone. This is the #1 pain point for developers building production AI agents.

## âš¡ The Solution: Teach Principles, Not Scripts

Parlant flips the script on AI agent development. Instead of hoping your LLM will follow instructions, **Parlant guarantees it**.

```python
# Traditional approach: Cross your fingers ğŸ¤
system_prompt = &quot;You are a helpful assistant. Please follow these 47 rules...&quot;

# Parlant approach: Guaranteed compliance âœ…
await agent.create_guideline(
    condition=&quot;Customer asks about refunds&quot;,
    action=&quot;Check order status first to see if eligible&quot;,
    tools=[check_order_status],
)
```

&lt;div align=&quot;center&quot;&gt;

## ğŸš€ Get Your Agent Running in 60 Seconds

&lt;/div&gt;

```bash
pip install parlant
```

```python
import parlant.sdk as p

@p.tool
async def get_weather(context: p.ToolContext, city: str) -&gt; p.ToolResult:
    # Your weather API logic here
    return p.ToolResult(f&quot;Sunny, 72Â°F in {city}&quot;)

async def main():
    async with p.Server() as server:
        agent = await server.create_agent(
            name=&quot;WeatherBot&quot;,
            description=&quot;Helpful weather assistant&quot;
        )

        # Define behavior with natural language
        await agent.create_guideline(
            condition=&quot;User asks about weather&quot;,
            action=&quot;Get current weather and provide a friendly response with suggestions&quot;,
            tools=[get_weather]
        )

        # ğŸ‰ Test playground ready at http://localhost:8800
        # Integrate the official React widget into your app,
        # or follow the tutorial to build your own frontend!

if __name__ == &quot;__main__&quot;:
    import asyncio
    asyncio.run(main())
```

**That&#039;s it!** Your agent is running with guaranteed rule-following behavior.

## ğŸ¬ See It In Action

&lt;img alt=&quot;Parlant Demo&quot; src=&quot;https://github.com/emcie-co/parlant/blob/develop/docs/demo.gif?raw=true&quot; width=&quot;100%&quot; /&gt;

## ğŸ”¥ Why Developers Are Switching to Parlant

&lt;table width=&quot;100%&quot;&gt;
&lt;tr&gt;
  &lt;td width=&quot;50%&quot;&gt;

### ğŸ—ï¸ **Traditional AI Frameworks**

  &lt;/td&gt;
  &lt;td width=&quot;50%&quot;&gt;

### âš¡ **Parlant**

  &lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;

- Write complex system prompts
- Hope the LLM follows them
- Debug unpredictable behaviors
- Scale by prompt engineering
- Cross fingers for reliability

&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;

- Define rules in natural language
- **Guaranteed** rule compliance
- Predictable, consistent behavior
- Scale by adding guidelines
- Production-ready from day one

&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## ğŸ¯ Perfect For Your Use Case

&lt;div align=&quot;center&quot;&gt;

|  **Financial Services**  |     **Healthcare**      |       **E-commerce**        |       **Legal Tech**       |
| :----------------------: | :---------------------: | :-------------------------: | :------------------------: |
| Compliance-first design  |   HIPAA-ready agents    |  Customer service at scale  |   Precise legal guidance   |
| Built-in risk management | Patient data protection | Order processing automation | Document review assistance |

&lt;/div&gt;

## ğŸ› ï¸ Enterprise-Grade Features

- **ğŸ§­ Conversational Journeys** - Lead the customer step-by-step to a goal
- **ğŸ¯ Dynamic Guideline Matching** - Context-aware rule application
- **ğŸ”§ Reliable Tool Integration** - APIs, databases, external services
- **ğŸ“Š Conversation Analytics** - Deep insights into agent behavior
- **ğŸ”„ Iterative Refinement** - Continuously improve agent responses
- **ğŸ›¡ï¸ Built-in Guardrails** - Prevent hallucination and off-topic responses
- **ğŸ“± React Widget** - [Drop-in chat UI for any web app](https://github.com/emcie-co/parlant-chat-react)
- **ğŸ” Full Explainability** - Understand every decision your agent makes

## ğŸ“ˆ Join 1000+ Developers Building Better AI

&lt;div align=&quot;center&quot;&gt;

**Companies using Parlant in production:**

_Financial institutions â€¢ Healthcare providers â€¢ Legal firms â€¢ E-commerce platforms_

[![Star History Chart](https://api.star-history.com/svg?repos=emcie-co/parlant&amp;type=Date)](https://star-history.com/#emcie-co/parlant&amp;Date)

&lt;/div&gt;

## ğŸƒâ€â™‚ï¸ Quick Start Paths

&lt;table border=&quot;0&quot;&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;ğŸ¯ I want to test it myself&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.parlant.io/docs/quickstart/installation&quot;&gt;â†’ 5-minute quickstart&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;ğŸ› ï¸ I want to see an example&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://www.parlant.io/docs/quickstart/examples&quot;&gt;â†’ Healthcare agent example&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;ğŸš€ I want to get involved&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&quot;https://discord.gg/duxWqxKk6J&quot;&gt;â†’ Join our Discord community&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

## ğŸŒŸ What Developers Are Saying

&gt; _&quot;By far the most elegant conversational AI framework that I&#039;ve come across! Developing with Parlant is pure joy.&quot;_ **â€” Vishal Ahuja, Senior Lead, Customer-Facing Conversational AI @ JPMorgan Chase**

## ğŸ¤ Community &amp; Support

- ğŸ’¬ **[Discord Community](https://discord.gg/duxWqxKk6J)** - Get help from the team and community
- ğŸ“– **[Documentation](https://parlant.io/docs/quickstart/installation)** - Comprehensive guides and examples
- ğŸ› **[GitHub Issues](https://github.com/emcie-co/parlant/issues)** - Bug reports and feature requests
- ğŸ“§ **[Direct Support](https://parlant.io/contact)** - Direct line to our engineering team

## ğŸ“„ License

Apache 2.0 - Use it anywhere, including commercial projects.

---

&lt;div align=&quot;center&quot;&gt;

**Ready to build AI agents that actually work?**

â­ **Star this repo** â€¢ ğŸš€ **[Try Parlant now](https://parlant.io/)** â€¢ ğŸ’¬ **[Join Discord](https://discord.gg/duxWqxKk6J)**

_Built with â¤ï¸ by the team at [Emcie](https://emcie.co)_

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Shubhamsaboo/awesome-llm-apps]]></title>
            <link>https://github.com/Shubhamsaboo/awesome-llm-apps</link>
            <guid>https://github.com/Shubhamsaboo/awesome-llm-apps</guid>
            <pubDate>Mon, 18 Aug 2025 00:05:07 GMT</pubDate>
            <description><![CDATA[Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Shubhamsaboo/awesome-llm-apps">Shubhamsaboo/awesome-llm-apps</a></h1>
            <p>Collection of awesome LLM apps with AI Agents and RAG using OpenAI, Anthropic, Gemini and opensource models.</p>
            <p>Language: Python</p>
            <p>Stars: 58,737</p>
            <p>Forks: 7,038</p>
            <p>Stars today: 441 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;http://www.theunwindai.com&quot;&gt;
    &lt;img src=&quot;docs/banner/unwind_black.png&quot; width=&quot;900px&quot; alt=&quot;Unwind AI&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.linkedin.com/in/shubhamsaboo/&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/-Follow%20Shubham%20Saboo-blue?logo=linkedin&amp;style=flat-square&quot; alt=&quot;LinkedIn&quot;&gt;
  &lt;/a&gt;
  &lt;a href=&quot;https://twitter.com/Saboo_Shubham_&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/twitter/follow/Shubham_Saboo&quot; alt=&quot;Twitter&quot;&gt;
  &lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=de&quot;&gt;Deutsch&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=es&quot;&gt;EspaÃ±ol&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=fr&quot;&gt;franÃ§ais&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ja&quot;&gt;æ—¥æœ¬èª&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ko&quot;&gt;í•œêµ­ì–´&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=pt&quot;&gt;PortuguÃªs&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=ru&quot;&gt;Ğ ÑƒÑÑĞºĞ¸Ğ¹&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/Shubhamsaboo/awesome-llm-apps?lang=zh&quot;&gt;ä¸­æ–‡&lt;/a&gt;
&lt;/p&gt;

&lt;hr/&gt;

# ğŸŒŸ Awesome LLM Apps

A curated collection of **Awesome LLM apps built with RAG, AI Agents, Multi-agent Teams, MCP, Voice Agents, and more.** This repository features LLM apps that use models from OpenAI, Anthropic, Google, and open-source models like DeepSeek, Qwen or Llama that you can run locally on your computer.

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/9876&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/9876&quot; alt=&quot;Shubhamsaboo%2Fawesome-llm-apps | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; /&gt;
  &lt;/a&gt;
&lt;/p&gt;

## ğŸ¤” Why Awesome LLM Apps?

- ğŸ’¡ Discover practical and creative ways LLMs can be applied across different domains, from code repositories to email inboxes and more.
- ğŸ”¥ Explore apps that combine LLMs from OpenAI, Anthropic, Gemini, and open-source alternatives with AI Agents, Agent Teams, MCP &amp; RAG.
- ğŸ“ Learn from well-documented projects and contribute to the growing open-source ecosystem of LLM-powered applications.

## ğŸ“‚ Featured AI Projects

### AI Agents

### ğŸŒ± Starter AI Agents

*   [ğŸ™ï¸ AI Blog to Podcast Agent](starter_ai_agents/ai_blog_to_podcast_agent/)
*   [â¤ï¸â€ğŸ©¹ AI Breakup Recovery Agent](starter_ai_agents/ai_breakup_recovery_agent/)
*   [ğŸ“Š AI Data Analysis Agent](starter_ai_agents/ai_data_analysis_agent/)
*   [ğŸ©» AI Medical Imaging Agent](starter_ai_agents/ai_medical_imaging_agent/)
*   [ğŸ˜‚ AI Meme Generator Agent (Browser)](starter_ai_agents/ai_meme_generator_agent_browseruse/)
*   [ğŸµ AI Music Generator Agent](starter_ai_agents/ai_music_generator_agent/)
*   [ğŸ›« AI Travel Agent (Local &amp; Cloud)](starter_ai_agents/ai_travel_agent/)
*   [âœ¨ Gemini Multimodal Agent](starter_ai_agents/gemini_multimodal_agent_demo/)
*   [ğŸŒ Local News Agent (OpenAI Swarm)](starter_ai_agents/local_news_agent_openai_swarm/)
*   [ğŸ”„ Mixture of Agents](starter_ai_agents/mixture_of_agents/)
*   [ğŸ“Š xAI Finance Agent](starter_ai_agents/xai_finance_agent/)
*   [ğŸ” OpenAI Research Agent](starter_ai_agents/opeani_research_agent/)
*   [ğŸ•¸ï¸ Web Scrapping AI Agent (Local &amp; Cloud)](starter_ai_agents/web_scrapping_ai_agent/)

### ğŸš€ Advanced AI Agents

*   [ğŸ” AI Deep Research Agent](advanced_ai_agents/single_agent_apps/ai_deep_research_agent/)
*   [ğŸ¤ AI Consultant Agent](advanced_ai_agents/single_agent_apps/ai_consultant_agent)
*   [ğŸ—ï¸ AI System Architect Agent](advanced_ai_agents/single_agent_apps/ai_system_architect_r1/)
*   [ğŸ¯ AI Lead Generation Agent](advanced_ai_agents/single_agent_apps/ai_lead_generation_agent/)
*   [ğŸ’° AI Financial Coach Agent](advanced_ai_agents/multi_agent_apps/ai_financial_coach_agent/)
*   [ğŸ¬ AI Movie Production Agent](advanced_ai_agents/single_agent_apps/ai_movie_production_agent/)
*   [ğŸ“ˆ AI Investment Agent](advanced_ai_agents/single_agent_apps/ai_investment_agent/)
*   [ğŸ‹ï¸â€â™‚ï¸ AI Health &amp; Fitness Agent](advanced_ai_agents/single_agent_apps/ai_health_fitness_agent/)
*   [ğŸš€ AI Product Launch Intelligence Agent](advanced_ai_agents/multi_agent_apps/product_launch_intelligence_agent)
*   [ğŸ—ï¸ AI Journalist Agent](advanced_ai_agents/single_agent_apps/ai_journalist_agent/)
*   [ğŸ§  AI Mental Wellbeing Agent](advanced_ai_agents/multi_agent_apps/ai_mental_wellbeing_agent/)
*   [ğŸ“‘ AI Meeting Agent](advanced_ai_agents/single_agent_apps/ai_meeting_agent/)
*   [ğŸ§¬ AI Self-Evolving Agent](advanced_ai_agents/multi_agent_apps/ai_Self-Evolving_agent/)
*   [ğŸ§ AI Social Media News and Podcast Agent](advanced_ai_agents/multi_agent_apps/ai_news_and_podcast_agents/)

### ğŸ® Autonomous Game Playing Agents

*   [ğŸ® AI 3D Pygame Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_3dpygame_r1/)
*   [â™œ AI Chess Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_chess_agent/)
*   [ğŸ² AI Tic-Tac-Toe Agent](advanced_ai_agents/autonomous_game_playing_agent_apps/ai_tic_tac_toe_agent/)

### ğŸ¤ Multi-agent Teams

*   [ğŸ§² AI Competitor Intelligence Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_competitor_intelligence_agent_team/)
*   [ğŸ’² AI Finance Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_finance_agent_team/)
*   [ğŸ¨ AI Game Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_game_design_agent_team/)
*   [ğŸ‘¨â€âš–ï¸ AI Legal Agent Team (Cloud &amp; Local)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_legal_agent_team/)
*   [ğŸ’¼ AI Recruitment Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_recruitment_agent_team/)
*   [ğŸ  AI Real Estate Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_real_estate_agent_team)
*   [ğŸ‘¨â€ğŸ’¼ AI Services Agency (CrewAI)](advanced_ai_agents/multi_agent_apps/agent_teams/ai_services_agency/)
*   [ğŸ‘¨â€ğŸ« AI Teaching Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/ai_teaching_agent_team/)
*   [ğŸ’» Multimodal Coding Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_coding_agent_team/)
*   [âœ¨ Multimodal Design Agent Team](advanced_ai_agents/multi_agent_apps/agent_teams/multimodal_design_agent_team/)
*   [ğŸŒ AI Travel Planner Agent Team](/advanced_ai_agents/multi_agent_apps/agent_teams/ai_travel_planner_agent_team/)

### ğŸ—£ï¸ Voice AI Agents

*   [ğŸ—£ï¸ AI Audio Tour Agent](voice_ai_agents/ai_audio_tour_agent/)
*   [ğŸ“ Customer Support Voice Agent](voice_ai_agents/customer_support_voice_agent/)
*   [ğŸ”Š Voice RAG Agent (OpenAI SDK)](voice_ai_agents/voice_rag_openaisdk/)


### ğŸŒ MCP AI Agents

*   [â™¾ï¸ Browser MCP Agent](mcp_ai_agents/browser_mcp_agent/)
*   [ğŸ™ GitHub MCP Agent](mcp_ai_agents/github_mcp_agent/)
*   [ğŸ“‘ Notion MCP Agent](mcp_ai_agents/notion_mcp_agent) 
*   [ğŸŒ AI Travel Planner MCP Agent](mcp_ai_agents/ai_travel_planner_mcp_agent_team)

### ğŸ“€ RAG (Retrieval Augmented Generation)
*   [ğŸ”— Agentic RAG](rag_tutorials/agentic_rag/)
*   [ğŸ§ Agentic RAG with Reasoning](rag_tutorials/agentic_rag_with_reasoning/)
*   [ğŸ“° AI Blog Search (RAG)](rag_tutorials/ai_blog_search/)
*   [ğŸ” Autonomous RAG](rag_tutorials/autonomous_rag/)
*   [ğŸ”„ Corrective RAG (CRAG)](rag_tutorials/corrective_rag/)
*   [ğŸ‹ Deepseek Local RAG Agent](rag_tutorials/deepseek_local_rag_agent/)
*   [ğŸ¤” Gemini Agentic RAG](rag_tutorials/gemini_agentic_rag/)
*   [ğŸ‘€ Hybrid Search RAG (Cloud)](rag_tutorials/hybrid_search_rag/)
*   [ğŸ”„ Llama 3.1 Local RAG](rag_tutorials/llama3.1_local_rag/)
*   [ğŸ–¥ï¸ Local Hybrid Search RAG](rag_tutorials/local_hybrid_search_rag/)
*   [ğŸ¦™ Local RAG Agent](rag_tutorials/local_rag_agent/)
*   [ğŸ§© RAG-as-a-Service](rag_tutorials/rag-as-a-service/)
*   [âœ¨ RAG Agent with Cohere](rag_tutorials/rag_agent_cohere/)
*   [â›“ï¸ Basic RAG Chain](rag_tutorials/rag_chain/)
*   [ğŸ“  RAG with Database Routing](rag_tutorials/rag_database_routing/)
*   [ğŸ–¼ï¸ Vision RAG](rag_tutorials/vision_rag/)

### ğŸ’¾ LLM Apps with Memory Tutorials

*   [ğŸ’¾ AI ArXiv Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_arxiv_agent_memory/)
*   [ğŸ›©ï¸ AI Travel Agent with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/ai_travel_agent_memory/)
*   [ğŸ’¬ Llama3 Stateful Chat](advanced_llm_apps/llm_apps_with_memory_tutorials/llama3_stateful_chat/)
*   [ğŸ“ LLM App with Personalized Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/llm_app_personalized_memory/)
*   [ğŸ—„ï¸ Local ChatGPT Clone with Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/local_chatgpt_with_memory/)
*   [ğŸ§  Multi-LLM Application with Shared Memory](advanced_llm_apps/llm_apps_with_memory_tutorials/multi_llm_memory/)


### ğŸ’¬ Chat with X Tutorials

*   [ğŸ’¬ Chat with GitHub (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_github/)
*   [ğŸ“¨ Chat with Gmail](advanced_llm_apps/chat_with_X_tutorials/chat_with_gmail/)
*   [ğŸ“„ Chat with PDF (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_pdf/)
*   [ğŸ“š Chat with Research Papers (ArXiv) (GPT &amp; Llama3)](advanced_llm_apps/chat_with_X_tutorials/chat_with_research_papers/)
*   [ğŸ“ Chat with Substack](advanced_llm_apps/chat_with_X_tutorials/chat_with_substack/)
*   [ğŸ“½ï¸ Chat with YouTube Videos](advanced_llm_apps/chat_with_X_tutorials/chat_with_youtube_videos/)

### ğŸ”§ LLM Fine-tuning Tutorials

*   [ğŸ”§ Llama 3.2 Fine-tuning](advanced_llm_apps/llm_finetuning_tutorials/llama3.2_finetuning/)

## ğŸš€ Getting Started

1. **Clone the repository** 

    ```bash 
    git clone https://github.com/Shubhamsaboo/awesome-llm-apps.git 
    ```

2. **Navigate to the desired project directory**

    ```bash 
    cd awesome-llm-apps/starter_ai_agents/ai_travel_agent
    ```

3. **Install the required dependencies**

    ```bash
    pip install -r requirements.txt
    ```

4. **Follow the project-specific instructions** in each project&#039;s `README.md` file to set up and run the app.

## ğŸ¤ Contributing to Open Source

Contributions are welcome! If you have any ideas, improvements, or new apps to add, please create a new [GitHub Issue](https://github.com/Shubhamsaboo/awesome-llm-apps/issues) or submit a pull request. Make sure to follow the existing project structure and include a detailed `README.md` for each new app.

### Thank You, Community, for the Support! ğŸ™

[![Star History Chart](https://api.star-history.com/svg?repos=Shubhamsaboo/awesome-llm-apps&amp;type=Date)](https://star-history.com/#Shubhamsaboo/awesome-llm-apps&amp;Date)

ğŸŒŸ **Donâ€™t miss out on future updates! Star the repo now and be the first to know about new and exciting LLM apps with RAG and AI Agents.**
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[aliasrobotics/cai]]></title>
            <link>https://github.com/aliasrobotics/cai</link>
            <guid>https://github.com/aliasrobotics/cai</guid>
            <pubDate>Mon, 18 Aug 2025 00:05:06 GMT</pubDate>
            <description><![CDATA[Cybersecurity AI (CAI), an open Bug Bounty-ready Artificial Intelligence]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/aliasrobotics/cai">aliasrobotics/cai</a></h1>
            <p>Cybersecurity AI (CAI), an open Bug Bounty-ready Artificial Intelligence</p>
            <p>Language: Python</p>
            <p>Stars: 2,646</p>
            <p>Forks: 399</p>
            <p>Stars today: 120 stars today</p>
            <h2>README</h2><pre># Cybersecurity AI (`CAI`)

&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
    &lt;a align=&quot;center&quot; href=&quot;&quot; target=&quot;https://github.com/aliasrobotics/CAI&quot;&gt;
      &lt;img
        width=&quot;100%&quot;
        src=&quot;https://github.com/aliasrobotics/cai/raw/main/media/cai.png&quot;
      &gt;
    &lt;/a&gt;
  &lt;/p&gt;

## ğŸ¯ Milestones
[![](https://img.shields.io/badge/HTB_ranking-top_90_Spain_(5_days)-red.svg)](https://app.hackthebox.com/users/2268644)
[![](https://img.shields.io/badge/HTB_ranking-top_50_Spain_(6_days)-red.svg)](https://app.hackthebox.com/users/2268644)
[![](https://img.shields.io/badge/HTB_ranking-top_30_Spain_(7_days)-red.svg)](https://app.hackthebox.com/users/2268644)
[![](https://img.shields.io/badge/HTB_ranking-top_500_World_(7_days)-red.svg)](https://app.hackthebox.com/users/2268644)
[![](https://img.shields.io/badge/HTB_&quot;Human_vs_AI&quot;_CTF-top_1_(AIs)_world-red.svg)](https://ctf.hackthebox.com/event/2000/scoreboard)
[![](https://img.shields.io/badge/HTB_&quot;Human_vs_AI&quot;_CTF-top_1_Spain-red.svg)](https://ctf.hackthebox.com/event/2000/scoreboard)
[![](https://img.shields.io/badge/HTB_&quot;Human_vs_AI&quot;_CTF-top_20_World-red.svg)](https://ctf.hackthebox.com/event/2000/scoreboard)
[![](https://img.shields.io/badge/HTB_&quot;Human_vs_AI&quot;_CTF-750_$-yellow.svg)](https://ctf.hackthebox.com/event/2000/scoreboard)
[![](https://img.shields.io/badge/Mistral_AI_Robotics_Hackathon-2500_$-yellow.svg)](https://lu.ma/roboticshack?tk=RuryKF)
[![](https://img.shields.io/badge/Bug_rewards-250_$-yellow.svg)](https://github.com/aliasrobotics/cai)

## ğŸ“¦ Package Attributes
[![version](https://badge.fury.io/py/cai-framework.svg)](https://badge.fury.io/py/cai-framework)
[![downloads](https://img.shields.io/pypi/dm/cai-framework)](https://pypistats.org/packages/cai-framework)
[![Linux](https://img.shields.io/badge/Linux-Supported-brightgreen?logo=linux&amp;logoColor=white)](https://github.com/aliasrobotics/cai)
[![OS X](https://img.shields.io/badge/OS%20X-Supported-brightgreen?logo=apple&amp;logoColor=white)](https://github.com/aliasrobotics/cai)
[![Windows](https://img.shields.io/badge/Windows-Supported-brightgreen?logo=windows&amp;logoColor=white)](https://github.com/aliasrobotics/cai)
[![Android](https://img.shields.io/badge/Android-Supported-brightgreen?logo=android&amp;logoColor=white)](https://github.com/aliasrobotics/cai)
[![Discord](https://img.shields.io/badge/Discord-7289DA?logo=discord&amp;logoColor=white)](https://discord.gg/fnUFcTaQAC)
[![arXiv](https://img.shields.io/badge/arXiv-2504.06017-b31b1b.svg)](https://arxiv.org/pdf/2504.06017)
[![arXiv](https://img.shields.io/badge/arXiv-2506.23592-b31b1b.svg)](https://arxiv.org/abs/2506.23592)



&lt;/div&gt;

A lightweight, ergonomic framework for building bug bounty-ready Cybersecurity AIs (CAIs).

| CAI with `alias0` on ROS message injection attacks in MiR-100 robot | CAI with `alias0` on API vulnerability discovery at Mercado Libre |
|-----------------------------------------------|---------------------------------|
| [![asciicast](https://asciinema.org/a/dNv705hZel2Rzrw0cju9HBGPh.svg)](https://asciinema.org/a/dNv705hZel2Rzrw0cju9HBGPh) | [![asciicast](https://asciinema.org/a/9Hc9z1uFcdNjqP3bY5y7wO1Ww.svg)](https://asciinema.org/a/9Hc9z1uFcdNjqP3bY5y7wO1Ww) |


| CAI on JWT@PortSwigger CTF â€” Cybersecurity AI | CAI on HackableII Boot2Root CTF â€” Cybersecurity AI |
|-----------------------------------------------|---------------------------------|
| [![asciicast](https://asciinema.org/a/713487.svg)](https://asciinema.org/a/713487) | [![asciicast](https://asciinema.org/a/713485.svg)](https://asciinema.org/a/713485) |


&gt; [!NOTE]
&gt; We encourage you to read CAI&#039;s the technical report at https://arxiv.org/pdf/2504.06017.

&gt; [!WARNING]
&gt; :warning: CAI is in active development, so don&#039;t expect it to work flawlessly. Instead, contribute by raising an issue or [sending a PR](https://github.com/aliasrobotics/cai/pulls).
&gt;
&gt; Access to this library and the use of information, materials (or portions thereof), is **&lt;u&gt;not intended&lt;/u&gt;, and is &lt;u&gt;prohibited&lt;/u&gt;, where such access or use violates applicable laws or regulations**. By no means the authors encourage or promote the unauthorized tampering with running systems. This can cause serious human harm and material damages.
&gt;
&gt; *By no means the authors of CAI encourage or promote the unauthorized tampering with compute systems. Please don&#039;t use the source code in here for cybercrime. &lt;u&gt;Pentest for good instead&lt;/u&gt;*. By downloading, using, or modifying this source code, you agree to the terms of the [`LICENSE`](LICENSE) and the limitations outlined in the [`DISCLAIMER`](DISCLAIMER) file.

## :bookmark: Table of Contents

- [Cybersecurity AI (`CAI`)](#cybersecurity-ai-cai)
  - [ğŸ¯ Milestones](#-milestones)
  - [ğŸ“¦ Package Attributes](#-package-attributes)
  - [:bookmark: Table of Contents](#bookmark-table-of-contents)
  - [Motivation](#motivation)
    - [:bust\_in\_silhouette: Why CAI?](#bust_in_silhouette-why-cai)
    - [Ethical principles behind CAI](#ethical-principles-behind-cai)
    - [Closed-source alternatives](#closed-source-alternatives)
  - [Learn - `CAI` Fluency](#learn---cai-fluency)
  - [:nut\_and\_bolt: Install](#nut_and_bolt-install)
    - [OS X](#os-x)
    - [Ubuntu 24.04](#ubuntu-2404)
    - [Ubuntu 20.04](#ubuntu-2004)
    - [Windows WSL](#windows-wsl)
    - [Android](#android)
    - [:nut\_and\_bolt: Setup `.env` file](#nut_and_bolt-setup-env-file)
    - [ğŸ”¹ Custom OpenAI Base URL Support](#-custom-openai-base-url-support)
  - [:triangular\_ruler: Architecture:](#triangular_ruler-architecture)
    - [ğŸ”¹ Agent](#-agent)
    - [ğŸ”¹ Tools](#-tools)
    - [ğŸ”¹ Handoffs](#-handoffs)
    - [ğŸ”¹ Patterns](#-patterns)
    - [ğŸ”¹ Turns and Interactions](#-turns-and-interactions)
    - [ğŸ”¹ Tracing](#-tracing)
    - [ğŸ”¹ Human-In-The-Loop (HITL)](#-human-in-the-loop-hitl)
  - [:rocket: Quickstart](#rocket-quickstart)
    - [Environment Variables](#environment-variables)
    - [OpenRouter Integration](#openrouter-integration)
    - [MCP](#mcp)
  - [Development](#development)
    - [Contributions](#contributions)
    - [Optional Requirements: caiextensions](#optional-requirements-caiextensions)
    - [:information\_source: Usage Data Collection](#information_source-usage-data-collection)
    - [Reproduce CI-Setup locally](#reproduce-ci-setup-locally)
  - [FAQ](#faq)
  - [Citation](#citation)
  - [Acknowledgements](#acknowledgements)



## Motivation
### :bust_in_silhouette: Why CAI?
The cybersecurity landscape is undergoing a dramatic transformation as AI becomes increasingly integrated into security operations. **We predict that by 2028, AI-powered security testing tools will outnumber human pentesters**. This shift represents a fundamental change in how we approach cybersecurity challenges. *AI is not just another tool - it&#039;s becoming essential for addressing complex security vulnerabilities and staying ahead of sophisticated threats. As organizations face more advanced cyber attacks, AI-enhanced security testing will be crucial for maintaining robust defenses.*

This work builds upon prior efforts[^4] and similarly, we believe that democratizing access to advanced cybersecurity AI tools is vital for the entire security community. That&#039;s why we&#039;re releasing Cybersecurity AI (`CAI`) as an open source framework. Our goal is to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools. By making these capabilities openly available, we aim to level the playing field and ensure that cutting-edge security AI technology isn&#039;t limited to well-funded private companies or state actors.

Bug Bounty programs have become a cornerstone of modern cybersecurity, providing a crucial mechanism for organizations to identify and fix vulnerabilities in their systems before they can be exploited. These programs have proven highly effective at securing both public and private infrastructure, with researchers discovering critical vulnerabilities that might have otherwise gone unnoticed. CAI is specifically designed to enhance these efforts by providing a lightweight, ergonomic framework for building specialized AI agents that can assist in various aspects of Bug Bounty hunting - from initial reconnaissance to vulnerability validation and reporting. Our framework aims to augment human expertise with AI capabilities, helping researchers work more efficiently and thoroughly in their quest to make digital systems more secure.

### Ethical principles behind CAI

You might be wondering if releasing CAI *in-the-wild* given its capabilities and security implications is ethical. Our decision to open-source this framework is guided by two core ethical principles:

1. **Democratizing Cybersecurity AI**: We believe that advanced cybersecurity AI tools should be accessible to the entire security community, not just well-funded private companies or state actors. By releasing CAI as an open source framework, we aim to empower security researchers, ethical hackers, and organizations to build and deploy powerful AI-driven security tools, leveling the playing field in cybersecurity.

2. **Transparency in AI Security Capabilities**: Based on our research results, understanding of the technology, and dissection of top technical reports, we argue that current LLM vendors are undermining their cybersecurity capabilities. This is extremely dangerous and misleading. By developing CAI openly, we provide a transparent benchmark of what AI systems can actually do in cybersecurity contexts, enabling more informed decisions about security postures.

CAI is built on the following core principles:
- **Cybersecurity oriented AI framework**: CAI is specifically designed for cybersecurity use cases, aiming at semi- and fully-automating offensive and defensive security tasks.
- **Open source, free for research**: CAI is open source and free for research purposes. We aim at democratizing access to AI and Cybersecurity. For professional or commercial use, including on-premise deployments, dedicated technical support and custom extensions [reach out](mailto:research@aliasrobotics.com) to obtain a license.
- **Lightweight**: CAI is designed to be fast, and easy to use.
- **Modular and agent-centric design**: CAI operates on the basis of agents and agentic patterns, which allows flexibility and scalability. You can easily add the most suitable agents and pattern for your cybersecuritytarget case.
- **Tool-integration**: CAI integrates already built-in tools, and allows the user to integrate their own tools with their own logic easily.
- **Logging and tracing integrated**: using [`phoenix`](https://github.com/Arize-ai/phoenix), the open source tracing and logging tool for LLMs. This provides the user with a detailed traceability of the agents and their execution.
- **Multi-Model Support**: more than 300 supported and empowered by [LiteLLM](https://github.com/BerriAI/litellm). The most popular providers:
  - **Anthropic**: `Claude 3.7`, `Claude 3.5`, `Claude 3`, `Claude 3 Opus`
  - **OpenAI**: `O1`, `O1 Mini`, `O3 Mini`, `GPT-4o`, `GPT-4.5 Preview`
  - **DeepSeek**: `DeepSeek V3`, `DeepSeek R1`
  - **Ollama**: `Qwen2.5 72B`, `Qwen2.5 14B`, etc


### Closed-source alternatives
Cybersecurity AI is a critical field, yet many groups are misguidedly pursuing it through closed-source methods for pure economic return, leveraging similar techniques and building upon existing closed-source (*often third-party owned*) models. This approach not only squanders valuable engineering resources but also represents an economic waste and results in redundant efforts, as they often end up reinventing the wheel. Here are some of the closed-source initiatives we keep track of and attempting to leverage genAI and agentic frameworks in cybersecurity AI:

- [Autonomous Cyber](https://www.acyber.co/)
- [CrackenAGI](https://cracken.ai/)
- [ETHIACK](https://ethiack.com/)
- [Horizon3](https://horizon3.ai/)
- [Kindo](https://www.kindo.ai/)
- [Lakera](https://lakera.ai)
- [Mindfort](www.mindfort.ai)
- [Mindgard](https://mindgard.ai/)
- [NDAY Security](https://ndaysecurity.com/)
- [Runsybil](https://www.runsybil.com)
- [Selfhack](https://www.selfhack.fi)
- [SQUR](https://squr.ai/)
- [Staris](https://staris.tech/)
- [Sxipher](https://www.sxipher.com/) (seems discontinued)
- [Terra Security](https://www.terra.security)
- [Xint](https://xint.io/)
- [XBOW](https://www.xbow.com)
- [ZeroPath](https://www.zeropath.com)
- [Zynap](https://www.zynap.com)
- [7ai](https://7ai.com)


## Learn - `CAI` Fluency

&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;
    &lt;a align=&quot;center&quot; href=&quot;&quot; target=&quot;https://github.com/aliasrobotics/CAI&quot;&gt;
      &lt;img
        width=&quot;100%&quot;
        src=&quot;https://github.com/aliasrobotics/cai/raw/main/media/caiedu.PNG&quot;
      &gt;
    &lt;/a&gt;
  &lt;/p&gt;
&lt;/div&gt;


|       |   Description  | English | Spanish |
|-------|----------------|---------|---------|
| **Episode 0**: What is CAI? | Cybersecurity AI (`CAI`) explained  |  [![Watch the video](https://img.youtube.com/vi/nBdTxbKM4oo/0.jpg)](https://www.youtube.com/watch?v=nBdTxbKM4oo) | [![Watch the video](https://img.youtube.com/vi/FaUL9HXrQ5k/0.jpg)](https://www.youtube.com/watch?v=FaUL9HXrQ5k) |
| **Episode 1**: The `CAI` Framework | Vision &amp; Ethics - Explore the core motivation behind CAI and delve into the crucial ethical principles guiding its development. Understand the motivation behind CAI and how you can actively contribute to the future of cybersecurity and the CAI framework. | [![Watch the video](https://img.youtube.com/vi/QEiGdsMf29M/0.jpg)](https://www.youtube.com/watch?v=QEiGdsMf29M&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=3) |  |
| **Episode 2**: From Zero to Cyber Hero | Breaking into Cybersecurity with AI - A comprehensive guide for complete beginners to become cybersecurity practitioners using CAI and AI tools. Learn how to leverage artificial intelligence to accelerate your cybersecurity learning journey, from understanding basic security concepts to performing real-world security assessments, all without requiring prior cybersecurity experience. | [![Watch the video](https://img.youtube.com/vi/hSTLHOOcQoY/0.jpg)](https://www.youtube.com/watch?v=hSTLHOOcQoY&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=14) |  |
| **Episode 3**: Vibe-Hacking Tutorial | &quot;My first Hack&quot; - A Vibe-Hacking guide for newbies. We demonstrate a simple web security hack using a default agent and show how to leverage tools and interpret CIA output with the help of the CAI Python API. You&#039;ll also learn to compare different LLM models to find the best fit for your hacking endeavors. | [![Watch the video](https://img.youtube.com/vi/9vZ_Iyex7uI/0.jpg)](https://www.youtube.com/watch?v=9vZ_Iyex7uI&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=1) | [![Watch the video](https://img.youtube.com/vi/iAOMaI1ftiA/0.jpg)](https://www.youtube.com/watch?v=iAOMaI1ftiA&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=2) |
| **Episode 4**: Intro ReAct | The Evolution of LLMs - Learn how LLMs evolved from basic language models to advanced multiagency AI systems. From basic LLMs to Chain-of-Thought and Reasoning LLMs towards ReAct and Multi-Agent Architectures. Get to know the basic terms | [![Watch the video](https://img.youtube.com/vi/tLdFO1flj_o/0.jpg)](https://www.youtube.com/watch?v=tLdFO1flj_o&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=13) | |
| **Episode 5**: CAI on CTF challenges | Dive into Capture The Flag (CTF) competitions using CAI. Learn how to leverage AI agents to solve various cybersecurity challenges including web exploitation, cryptography, reverse engineering, and forensics. Discover how to configure CAI for competitive hacking scenarios and maximize your CTF performance with intelligent automation. | [![Watch the video](https://img.youtube.com/vi/MrXTQ0e2to4/0.jpg)](https://www.youtube.com/watch?v=MrXTQ0e2to4&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=13) | [![Watch the video](https://img.youtube.com/vi/r9US_JZa9_c/0.jpg)](https://www.youtube.com/watch?v=r9US_JZa9_c&amp;list=PLLc16OUiZWd4RuFdN5_Wx9xwjCVVbopzr&amp;index=12) |
| **Episode 6**: CAI Fluency Framework | Introducing CAI Fluency: An Educational Framework for Cybersecurity AI - Learn about the comprehensive educational platform designed to democratize cybersecurity AI knowledge. Explore the theoretical foundations, the 4 C&#039;s competencies (Command, Communication, Critique, Custody), and the three modalities of Human-AI interaction in security contexts. | *Coming soon* | *Coming soon* |
|  |  |  |  |
| **Annex 1**: `CAI` 0.5.x release  | Introduce version 0.5 of `CAI` including new multi-agent functionality, new commands such as `/history`, `/compact`, `/graph` or `/memory` and a case study showing how `CAI` found a critical security flaw in OT heap pumps spread around the world. |  [![Watch the video](https://img.youtube.com/vi/OPFH0ANUMMw/0.jpg)](https://www.youtube.com/watch?v=OPFH0ANUMMw) | [![Watch the video](https://img.youtube.com/vi/Q8AI4E4gH8k/0.jpg)](https://www.youtube.com/watch?v=Q8AI4E4gH8k) |
| **Annex 2**: `CAI` 0.4.x release and `alias0`  | Introducing version 0.4 of `CAI` with *streaming* and improved MCP support. We also introduce `alias0`, the Privacy-First Cybersecurity AI, a Model-of-Models Intelligence that implements a Privacy-by-Design architecture and obtains state-of-the-art results in cybersecurity benchmarks. |  [![Watch the video](https://img.youtube.com/vi/NZjzfnvAZcc/0.jpg)](https://www.youtube.com/watch?v=NZjzfnvAZcc) |  |
| **Annex 3**: Cybersecurity AI Community Meeting #1  | First Cybersecurity AI (`CAI`) community meeting, over 40 participants from academia, industry, and defense gathered to discuss the open-source scaffolding behind CAI â€” a project designed to build agentic AI systems for cybersecurity that are open, modular, and Bug Bounty-ready. |  [![Watch the video](https://img.youtube.com/vi/4JqaTiVlgsw/0.jpg)](https://www.youtube.com/watch?v=4JqaTiVlgsw) |  |




## :nut_and_bolt: Install

```bash
pip install cai-framework
```

Always create a new virtual environment to ensure proper dependency installation when updating CAI.

The following subsections provide a more detailed walkthrough on selected popular Operating Systems. Refer to the [Development](#development) section for developer-related install instructions.

### OS X
```bash
brew update &amp;&amp; \
    brew install git python@3.12

# Create virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;&amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e &#039;OPENAI_API_KEY=&quot;sk-1234&quot;\nANTHROPIC_API_KEY=&quot;&quot;\nOLLAMA=&quot;&quot;\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false&#039; &gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
```

### Ubuntu 24.04
```bash
sudo apt-get update &amp;&amp; \
    sudo apt-get install -y git python3-pip python3.12-venv

# Create the virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;&amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e &#039;OPENAI_API_KEY=&quot;sk-1234&quot;\nANTHROPIC_API_KEY=&quot;&quot;\nOLLAMA=&quot;&quot;\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false&#039; &gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
```

### Ubuntu 20.04
```bash
sudo apt-get update &amp;&amp; \
    sudo apt-get install -y software-properties-common

# Fetch Python 3.12
sudo add-apt-repository ppa:deadsnakes/ppa &amp;&amp; sudo apt update
sudo apt install python3.12 python3.12-venv python3.12-dev -y

# Create the virtual environment
python3.12 -m venv cai_env

# Install the package from the local directory
source cai_env/bin/activate &amp;&amp; pip install cai-framework

# Generate a .env file and set up with defaults
echo -e &#039;OPENAI_API_KEY=&quot;sk-1234&quot;\nANTHROPIC_API_KEY=&quot;&quot;\nOLLAMA=&quot;&quot;\nPROMPT_TOOLKIT_NO_CPR=1\nCAI_STREAM=false&#039; &gt; .env

# Launch CAI
cai  # first launch it can take up to 30 seconds
```

### Windows WSL
Go to the Microsoft page: https://learn.microsoft.com/en-us/windows/wsl/install. Here you will find all the 

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[LMCache/LMCache]]></title>
            <link>https://github.com/LMCache/LMCache</link>
            <guid>https://github.com/LMCache/LMCache</guid>
            <pubDate>Mon, 18 Aug 2025 00:05:05 GMT</pubDate>
            <description><![CDATA[Supercharge Your LLM with the Fastest KV Cache Layer]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/LMCache/LMCache">LMCache/LMCache</a></h1>
            <p>Supercharge Your LLM with the Fastest KV Cache Layer</p>
            <p>Language: Python</p>
            <p>Stars: 4,510</p>
            <p>Forks: 503</p>
            <p>Stars today: 136 stars today</p>
            <h2>README</h2><pre># LMCache core library

## Installation

**Prerequisite:** Python &gt;= 3.10

```bash
pip install -e .
```

## Demos
Feel free to try our docker-based demos yourself! All the demos are available [in this repo](https://github.com/LMCache/demo).

## Quickstart: 

**Prerequisites**: To run the quickstart demo, your server should have 1 GPU and the [docker environment](https://docs.docker.com/engine/install/) installed.

**Step 1:** Pull docker images
```bash
docker pull apostacyh/vllm:lmcache-0.1.0
```

**Step 2:** Start vLLM + LMCache 
```bash
model=mistralai/Mistral-7B-Instruct-v0.2    # Replace with your model name
sudo docker run --runtime nvidia --gpus &#039;&quot;device=0&quot;&#039; \
    -v &lt;Huggingface cache dir on your local machine&gt;:/root/.cache/huggingface \
    -p 8000:8000 \
    --env &quot;HF_TOKEN=&lt;Your huggingface access token&gt;&quot; \
    --ipc=host \
    --network=host \
    apostacyh/vllm:lmcache-0.1.0 \
    --model $model --gpu-memory-utilization 0.6 --port 8000 \
    --lmcache-config-file /lmcache/LMCache/examples/example-local.yaml
```
Please fill `Huggingface cache dir on your local machine` and `Your huggingface access token` in the above command. 

You can also change the `model` variable to use different models.

The vLLM engine is ready after you see the logs like this:
```
INFO:     Started server process [865615]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

**Step 3:** Run demo application

You can now run the demo application in the LMCache repo. Please execute the following commands on the server
```bash
git clone https://github.com/LMCache/LMCache
cd LMCache/examples/

# Install openai client library
pip install openai

# Start the demo chat application
python openai_chat_completion_client.py 8000
```

This demo is a QA application based on a long context (`examples/f.txt`). The TTFT should be drastically reduced since the second round of QA.



## Use case 1: share prefix KV between different vLLM instance through LMCache
The following instructions help deploy LMCache backend + multile vLLM instance by docker containers. The architecture of the demo application looks like this:

&lt;img width=&quot;817&quot; alt=&quot;image&quot; src=&quot;https://github.com/LMCache/LMCache/assets/25103655/ab64f84d-26e1-46ce-a503-e7e917b618bc&quot;&gt;


**Prerequisites**: To run the quickstart demo, your server must have 2 GPUs and the [docker environment](https://docs.docker.com/engine/install/) installed.


**Step 1:** Pull docker images
```bash
docker pull apostacyh/lmcache-server:0.1.0
docker pull apostacyh/vllm:lmcache-0.1.0
```

**Step 2:** Start LMCache backend server 
```bash
docker run --name lmcache-server --network host -d apostacyh/lmcache-server:0.1.0 0.0.0.0 65432
```

**Step 3:** start 2 vLLM instances
```bash
# The first vLLM instance listens at port 8000
model=mistralai/Mistral-7B-Instruct-v0.2    # Replace with your model name
sudo docker run --runtime nvidia --gpus &#039;&quot;device=0&quot;&#039; \
    -v &lt;Huggingface cache dir on your local machine&gt;:/root/.cache/huggingface \
    -p 8000:8000 \
    --env &quot;HF_TOKEN=&lt;Your huggingface token&gt;&quot; \
    --ipc=host \
    --network=host \
    apostacyh/vllm:lmcache-0.1.0 \
    --model $model --gpu-memory-utilization 0.7 --port 8000 \
    --lmcache-config-file /lmcache/LMCache/examples/example.yaml
```

Now, open another terminal and start another vLLM instance
```bash
# The second vLLM instance listens at port 8001
model=mistralai/Mistral-7B-Instruct-v0.2    # Replace with your model name
sudo docker run --runtime nvidia --gpus &#039;&quot;device=1&quot;&#039; \
    -v &lt;Huggingface cache dir on your local machine&gt;:/root/.cache/huggingface \
    -p 8001:8001 \
    --env &quot;HF_TOKEN=&lt;Your huggingface token&gt;&quot; \
    --ipc=host \
    --network=host \
    apostacyh/vllm:lmcache-0.1.0 \
    --model $model --gpu-memory-utilization 0.7 --port 8001 \
    --lmcache-config-file /lmcache/LMCache/examples/example.yaml
```

Remember to replace the `Huggingface cache dir on your local machine` and `Your huggingface token` in the commandline.

The vLLM engines are ready after you see the logs like this:
```
INFO:     Started server process [865615]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
```

**Step 4:** Run demo application
You can run the demo application in the LMCache repo. Please execute the following commands on the server
```bash
git clone https://github.com/LMCache/LMCache
cd LMCache/examples/

# Install openai client library
pip install openai
```

In one terminal:
```
# Connect to the first vLLM engine
python openai_chat_completion_client.py 8000
```

In another terminal
```
# Connect to the second vLLM engine
python openai_chat_completion_client.py 8001
```

You should be able to see the second vLLM engine has much lower response delay.
This is because the KV cache of the long context can be shared across both vLLM engines by using LMCache.

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OpenBB-finance/OpenBB]]></title>
            <link>https://github.com/OpenBB-finance/OpenBB</link>
            <guid>https://github.com/OpenBB-finance/OpenBB</guid>
            <pubDate>Mon, 18 Aug 2025 00:05:04 GMT</pubDate>
            <description><![CDATA[Financial data aggregator for humans and AI agents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBB-finance/OpenBB">OpenBB-finance/OpenBB</a></h1>
            <p>Financial data aggregator for humans and AI agents.</p>
            <p>Language: Python</p>
            <p>Stars: 49,813</p>
            <p>Forks: 4,640</p>
            <p>Stars today: 241 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/platform-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;OpenBB Platform logo&quot; width=&quot;600&quot;&gt;
&lt;br /&gt;
&lt;br /&gt;

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)
[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)
&lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt;
  &lt;img src=&quot;https://github.com/codespaces/badge.svg&quot; height=&quot;20&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;
[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&amp;label=PyPI%20Package)](https://pypi.org/project/openbb/)

The first financial Platform that is open source.

The OpenBB Platform offers access to equity, options, crypto, forex, macro economy, fixed income, and more while also offering a broad range of extensions to enhance the user experience according to their needs.

Get started with: `pip install openbb`

```python
from openbb import obb
output = obb.equity.price.historical(&quot;AAPL&quot;)
df = output.to_dataframe()
```

You can sign up to the [OpenBB Hub](https://my.openbb.co/login) to get the most out of the OpenBB ecosystem.

Data integrations available can be found here: &lt;https://docs.openbb.co/platform/reference&gt;

---

## OpenBB Workspace

While the OpenBB Platform is all about an integration to dozens of different data vendors, the interface is either Python or a CLI.

If you want an enterprise UI to visualize this datasets and use AI agents on top, you can find OpenBB Workspace at &lt;https://pro.openbb.co&gt;.

&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Data integration:

- You can learn more about adding data to the OpenBB workspace from the [docs](https://docs.openbb.co/workspace) or [this open source repository](https://github.com/OpenBB-finance/backends-for-openbb).

AI Agents integration:

- You can learn more about adding AI agents to the OpenBB workspace from [this open source repository](https://github.com/OpenBB-finance/agents-for-openbb).

### Integrating OpenBB Platform to the OpenBB Workspace

Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.

#### Run OpenBB Platform backend

- Install the packages.

```sh
pip install &quot;openbb[all]&quot;
```

- Start the API server over localhost.

```sh
openbb-api
```

This will launch a FastAPI server, via Uvicorn, at `127.0.0.1:6900`.

You can check that it works by going to &lt;http://127.0.0.1:6900&gt;.

#### Integrate OpenBB Platform backend to OpenBB Workspace

Sign-in to the [OpenBB Workspace](https://pro.openbb.co/), and follow the following steps:

![CleanShot 2025-05-17 at 09 51 56@2x](https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069)

1. Go to the &quot;Apps&quot; tab
2. Click on &quot;Connect backend&quot;
3. Fill in the form with:
   Name: OpenBB Platform
   URL: &lt;http://127.0.0.1:6900&gt;
4. Click on &quot;Test&quot;. You should get a &quot;Test successful&quot; with the number of apps found.
5. Click on &quot;Add&quot;.

That&#039;s it.

---

&lt;!-- TABLE OF CONTENTS --&gt;
&lt;details closed=&quot;closed&quot;&gt;
  &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

## 1. Installation

The OpenBB Platform can be installed as a [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`

or by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process, in the [OpenBB Documentation](https://docs.openbb.co/platform/installation).

### OpenBB Platform CLI installation

The OpenBB Platform CLI is a command-line interface that allows you to access the OpenBB Platform directly from your command line.

It can be installed by running `pip install openbb-cli`

or by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).

## 2. Contributing

There are three main ways of contributing to this project. (Hopefully you have starred the project by now â­ï¸)

### Become a Contributor

- More information on our [Contributing Documentation](https://docs.openbb.co/platform/developer_guide/misc/contributing).

### Create a GitHub ticket

Before creating a ticket make sure the one you are creating doesn&#039;t exist already [here](https://github.com/OpenBB-finance/OpenBB/issues)

- [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=%5BBug%5D)
- [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=enhancement&amp;template=enhancement.md&amp;title=%5BIMPROVE%5D)
- [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=new+feature&amp;template=feature_request.md&amp;title=%5BFR%5D)

### Provide feedback

We are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.

## 3. License

Distributed under the AGPLv3 License. See
[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.

## 4. Disclaimer

Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment
amount, and may not be suitable for all investors.

Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.

The data contained in the OpenBB Platform is not necessarily accurate.

OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.

All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.

Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.

## 5. Contacts

If you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`

If you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`

Any of our social media platforms: [openbb.co/links](https://openbb.co/links)

## 6. Star History

This is a proxy of our growth and that we are just getting started.

But for more metrics important to us check [openbb.co/open](https://openbb.co/open).

[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)

## 7. Contributors

OpenBB wouldn&#039;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.

&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt;
   &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot;/&gt;
&lt;/a&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge
[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge
[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members
[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge
[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers
[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&amp;color=blue
[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues
[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=yellow
[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen
[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=success
[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed
[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge
[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;logo=linkedin&amp;colorB=555
[linkedin-url]: https://linkedin.com/in/DidierRLopes
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[yt-dlp/yt-dlp]]></title>
            <link>https://github.com/yt-dlp/yt-dlp</link>
            <guid>https://github.com/yt-dlp/yt-dlp</guid>
            <pubDate>Mon, 18 Aug 2025 00:05:03 GMT</pubDate>
            <description><![CDATA[A feature-rich command-line audio/video downloader]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/yt-dlp/yt-dlp">yt-dlp/yt-dlp</a></h1>
            <p>A feature-rich command-line audio/video downloader</p>
            <p>Language: Python</p>
            <p>Stars: 122,796</p>
            <p>Forks: 9,782</p>
            <p>Stars today: 128 stars today</p>
            <h2>README</h2><pre>&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt;
&lt;div align=&quot;center&quot;&gt;

[![YT-DLP](https://raw.githubusercontent.com/yt-dlp/yt-dlp/master/.github/banner.svg)](#readme)

[![Release version](https://img.shields.io/github/v/release/yt-dlp/yt-dlp?color=brightgreen&amp;label=Download&amp;style=for-the-badge)](#installation &quot;Installation&quot;)
[![PyPI](https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;labelColor=555555&amp;style=for-the-badge)](https://pypi.org/project/yt-dlp &quot;PyPI&quot;)
[![Donate](https://img.shields.io/badge/_-Donate-red.svg?logo=githubsponsors&amp;labelColor=555555&amp;style=for-the-badge)](Collaborators.md#collaborators &quot;Donate&quot;)
[![Discord](https://img.shields.io/discord/807245652072857610?color=blue&amp;labelColor=555555&amp;label=&amp;logo=discord&amp;style=for-the-badge)](https://discord.gg/H5MNcFW63r &quot;Discord&quot;)
[![Supported Sites](https://img.shields.io/badge/-Supported_Sites-brightgreen.svg?style=for-the-badge)](supportedsites.md &quot;Supported Sites&quot;)
[![License: Unlicense](https://img.shields.io/badge/-Unlicense-blue.svg?style=for-the-badge)](LICENSE &quot;License&quot;)
[![CI Status](https://img.shields.io/github/actions/workflow/status/yt-dlp/yt-dlp/core.yml?branch=master&amp;label=Tests&amp;style=for-the-badge)](https://github.com/yt-dlp/yt-dlp/actions &quot;CI Status&quot;)
[![Commits](https://img.shields.io/github/commit-activity/m/yt-dlp/yt-dlp?label=commits&amp;style=for-the-badge)](https://github.com/yt-dlp/yt-dlp/commits &quot;Commit History&quot;)
[![Last Commit](https://img.shields.io/github/last-commit/yt-dlp/yt-dlp/master?label=&amp;style=for-the-badge&amp;display_timestamp=committer)](https://github.com/yt-dlp/yt-dlp/pulse/monthly &quot;Last activity&quot;)

&lt;/div&gt;
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt;

yt-dlp is a feature-rich command-line audio/video downloader with support for [thousands of sites](supportedsites.md). The project is a fork of [youtube-dl](https://github.com/ytdl-org/youtube-dl) based on the now inactive [youtube-dlc](https://github.com/blackjack4494/yt-dlc).

&lt;!-- MANPAGE: MOVE &quot;USAGE AND OPTIONS&quot; SECTION HERE --&gt;

&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt;
* [INSTALLATION](#installation)
    * [Detailed instructions](https://github.com/yt-dlp/yt-dlp/wiki/Installation)
    * [Release Files](#release-files)
    * [Update](#update)
    * [Dependencies](#dependencies)
    * [Compile](#compile)
* [USAGE AND OPTIONS](#usage-and-options)
    * [General Options](#general-options)
    * [Network Options](#network-options)
    * [Geo-restriction](#geo-restriction)
    * [Video Selection](#video-selection)
    * [Download Options](#download-options)
    * [Filesystem Options](#filesystem-options)
    * [Thumbnail Options](#thumbnail-options)
    * [Internet Shortcut Options](#internet-shortcut-options)
    * [Verbosity and Simulation Options](#verbosity-and-simulation-options)
    * [Workarounds](#workarounds)
    * [Video Format Options](#video-format-options)
    * [Subtitle Options](#subtitle-options)
    * [Authentication Options](#authentication-options)
    * [Post-processing Options](#post-processing-options)
    * [SponsorBlock Options](#sponsorblock-options)
    * [Extractor Options](#extractor-options)
    * [Preset Aliases](#preset-aliases)
* [CONFIGURATION](#configuration)
    * [Configuration file encoding](#configuration-file-encoding)
    * [Authentication with netrc](#authentication-with-netrc)
    * [Notes about environment variables](#notes-about-environment-variables)
* [OUTPUT TEMPLATE](#output-template)
    * [Output template examples](#output-template-examples)
* [FORMAT SELECTION](#format-selection)
    * [Filtering Formats](#filtering-formats)
    * [Sorting Formats](#sorting-formats)
    * [Format Selection examples](#format-selection-examples)
* [MODIFYING METADATA](#modifying-metadata)
    * [Modifying metadata examples](#modifying-metadata-examples)
* [EXTRACTOR ARGUMENTS](#extractor-arguments)
* [PLUGINS](#plugins)
    * [Installing Plugins](#installing-plugins)
    * [Developing Plugins](#developing-plugins)
* [EMBEDDING YT-DLP](#embedding-yt-dlp)
    * [Embedding examples](#embedding-examples)
* [CHANGES FROM YOUTUBE-DL](#changes-from-youtube-dl)
    * [New features](#new-features)
    * [Differences in default behavior](#differences-in-default-behavior)
    * [Deprecated options](#deprecated-options)
* [CONTRIBUTING](CONTRIBUTING.md#contributing-to-yt-dlp)
    * [Opening an Issue](CONTRIBUTING.md#opening-an-issue)
    * [Developer Instructions](CONTRIBUTING.md#developer-instructions)
* [WIKI](https://github.com/yt-dlp/yt-dlp/wiki)
    * [FAQ](https://github.com/yt-dlp/yt-dlp/wiki/FAQ)
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt;


# INSTALLATION

&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt;
[![Windows](https://img.shields.io/badge/-Windows_x64-blue.svg?style=for-the-badge&amp;logo=windows)](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe)
[![Unix](https://img.shields.io/badge/-Linux/BSD-red.svg?style=for-the-badge&amp;logo=linux)](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp)
[![MacOS](https://img.shields.io/badge/-MacOS-lightblue.svg?style=for-the-badge&amp;logo=apple)](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos)
[![PyPI](https://img.shields.io/badge/-PyPI-blue.svg?logo=pypi&amp;labelColor=555555&amp;style=for-the-badge)](https://pypi.org/project/yt-dlp)
[![Source Tarball](https://img.shields.io/badge/-Source_tar-green.svg?style=for-the-badge)](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz)
[![Other variants](https://img.shields.io/badge/-Other-grey.svg?style=for-the-badge)](#release-files)
[![All versions](https://img.shields.io/badge/-All_Versions-lightgrey.svg?style=for-the-badge)](https://github.com/yt-dlp/yt-dlp/releases)
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt;

You can install yt-dlp using [the binaries](#release-files), [pip](https://pypi.org/project/yt-dlp) or one using a third-party package manager. See [the wiki](https://github.com/yt-dlp/yt-dlp/wiki/Installation) for detailed instructions


&lt;!-- MANPAGE: BEGIN EXCLUDED SECTION --&gt;
## RELEASE FILES

#### Recommended

File|Description
:---|:---
[yt-dlp](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp)|Platform-independent [zipimport](https://docs.python.org/3/library/zipimport.html) binary. Needs Python (recommended for **Linux/BSD**)
[yt-dlp.exe](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.exe)|Windows (Win8+) standalone x64 binary (recommended for **Windows**)
[yt-dlp_macos](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos)|Universal MacOS (10.15+) standalone executable (recommended for **MacOS**)

#### Alternatives

File|Description
:---|:---
[yt-dlp_x86.exe](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_x86.exe)|Windows (Win8+) standalone x86 (32-bit) binary
[yt-dlp_linux](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux)|Linux standalone x64 binary
[yt-dlp_linux_armv7l](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_armv7l)|Linux standalone armv7l (32-bit) binary
[yt-dlp_linux_aarch64](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_linux_aarch64)|Linux standalone aarch64 (64-bit) binary
[yt-dlp_win.zip](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_win.zip)|Unpackaged Windows executable (no auto-update)
[yt-dlp_macos.zip](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp_macos.zip)|Unpackaged MacOS (10.15+) executable (no auto-update)

#### Misc

File|Description
:---|:---
[yt-dlp.tar.gz](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz)|Source tarball
[SHA2-512SUMS](https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS)|GNU-style SHA512 sums
[SHA2-512SUMS.sig](https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-512SUMS.sig)|GPG signature file for SHA512 sums
[SHA2-256SUMS](https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS)|GNU-style SHA256 sums
[SHA2-256SUMS.sig](https://github.com/yt-dlp/yt-dlp/releases/latest/download/SHA2-256SUMS.sig)|GPG signature file for SHA256 sums

The public key that can be used to verify the GPG signatures is [available here](https://github.com/yt-dlp/yt-dlp/blob/master/public.key)
Example usage:
```
curl -L https://github.com/yt-dlp/yt-dlp/raw/master/public.key | gpg --import
gpg --verify SHA2-256SUMS.sig SHA2-256SUMS
gpg --verify SHA2-512SUMS.sig SHA2-512SUMS
```
&lt;!-- MANPAGE: END EXCLUDED SECTION --&gt;

**Note**: The manpages, shell completion (autocomplete) files etc. are available inside the [source tarball](https://github.com/yt-dlp/yt-dlp/releases/latest/download/yt-dlp.tar.gz)


## UPDATE
You can use `yt-dlp -U` to update if you are using the [release binaries](#release-files)

If you [installed with pip](https://github.com/yt-dlp/yt-dlp/wiki/Installation#with-pip), simply re-run the same command that was used to install the program

For other third-party package managers, see [the wiki](https://github.com/yt-dlp/yt-dlp/wiki/Installation#third-party-package-managers) or refer to their documentation

&lt;a id=&quot;update-channels&quot;&gt;&lt;/a&gt;

There are currently three release channels for binaries: `stable`, `nightly` and `master`.

* `stable` is the default channel, and many of its changes have been tested by users of the `nightly` and `master` channels.
* The `nightly` channel has releases scheduled to build every day around midnight UTC, for a snapshot of the project&#039;s new patches and changes. This is the **recommended channel for regular users** of yt-dlp. The `nightly` releases are available from [yt-dlp/yt-dlp-nightly-builds](https://github.com/yt-dlp/yt-dlp-nightly-builds/releases) or as development releases of the `yt-dlp` PyPI package (which can be installed with pip&#039;s `--pre` flag).
* The `master` channel features releases that are built after each push to the master branch, and these will have the very latest fixes and additions, but may also be more prone to regressions. They are available from [yt-dlp/yt-dlp-master-builds](https://github.com/yt-dlp/yt-dlp-master-builds/releases).

When using `--update`/`-U`, a release binary will only update to its current channel.
`--update-to CHANNEL` can be used to switch to a different channel when a newer version is available. `--update-to [CHANNEL@]TAG` can also be used to upgrade or downgrade to specific tags from a channel.

You may also use `--update-to &lt;repository&gt;` (`&lt;owner&gt;/&lt;repository&gt;`) to update to a channel on a completely different repository. Be careful with what repository you are updating to though, there is no verification done for binaries from different repositories.

Example usage:

* `yt-dlp --update-to master` switch to the `master` channel and update to its latest release
* `yt-dlp --update-to stable@2023.07.06` upgrade/downgrade to release to `stable` channel tag `2023.07.06`
* `yt-dlp --update-to 2023.10.07` upgrade/downgrade to tag `2023.10.07` if it exists on the current channel
* `yt-dlp --update-to example/yt-dlp@2023.09.24` upgrade/downgrade to the release from the `example/yt-dlp` repository, tag `2023.09.24`

**Important**: Any user experiencing an issue with the `stable` release should install or update to the `nightly` release before submitting a bug report:
```
# To update to nightly from stable executable/binary:
yt-dlp --update-to nightly

# To install nightly with pip:
python3 -m pip install -U --pre &quot;yt-dlp[default]&quot;
```

When running a yt-dlp version that is older than 90 days, you will see a warning message suggesting to update to the latest version.
You can suppress this warning by adding `--no-update` to your command or configuration file.

## DEPENDENCIES
Python versions 3.9+ (CPython) and 3.11+ (PyPy) are supported. Other versions and implementations may or may not work correctly.

&lt;!-- Python 3.5+ uses VC++14 and it is already embedded in the binary created
&lt;!x-- https://www.microsoft.com/en-us/download/details.aspx?id=26999 --x&gt;
On Windows, [Microsoft Visual C++ 2010 SP1 Redistributable Package (x86)](https://download.microsoft.com/download/1/6/5/165255E7-1014-4D0A-B094-B6A430A6BFFC/vcredist_x86.exe) is also necessary to run yt-dlp. You probably already have this, but if the executable throws an error due to missing `MSVCR100.dll` you need to install it manually.
--&gt;

While all the other dependencies are optional, `ffmpeg` and `ffprobe` are highly recommended

### Strongly recommended

* [**ffmpeg** and **ffprobe**](https://www.ffmpeg.org) - Required for [merging separate video and audio files](#format-selection), as well as for various [post-processing](#post-processing-options) tasks. License [depends on the build](https://www.ffmpeg.org/legal.html)

    There are bugs in ffmpeg that cause various issues when used alongside yt-dlp. Since ffmpeg is such an important dependency, we provide [custom builds](https://github.com/yt-dlp/FFmpeg-Builds#ffmpeg-static-auto-builds) with patches for some of these issues at [yt-dlp/FFmpeg-Builds](https://github.com/yt-dlp/FFmpeg-Builds). See [the readme](https://github.com/yt-dlp/FFmpeg-Builds#patches-applied) for details on the specific issues solved by these builds

    **Important**: What you need is ffmpeg *binary*, **NOT** [the Python package of the same name](https://pypi.org/project/ffmpeg)

### Networking
* [**certifi**](https://github.com/certifi/python-certifi)\* - Provides Mozilla&#039;s root certificate bundle. Licensed under [MPLv2](https://github.com/certifi/python-certifi/blob/master/LICENSE)
* [**brotli**](https://github.com/google/brotli)\* or [**brotlicffi**](https://github.com/python-hyper/brotlicffi) - [Brotli](https://en.wikipedia.org/wiki/Brotli) content encoding support. Both licensed under MIT &lt;sup&gt;[1](https://github.com/google/brotli/blob/master/LICENSE) [2](https://github.com/python-hyper/brotlicffi/blob/master/LICENSE) &lt;/sup&gt;
* [**websockets**](https://github.com/aaugustin/websockets)\* - For downloading over websocket. Licensed under [BSD-3-Clause](https://github.com/aaugustin/websockets/blob/main/LICENSE)
* [**requests**](https://github.com/psf/requests)\* - HTTP library. For HTTPS proxy and persistent connections support. Licensed under [Apache-2.0](https://github.com/psf/requests/blob/main/LICENSE)

#### Impersonation

The following provide support for impersonating browser requests. This may be required for some sites that employ TLS fingerprinting.

* [**curl_cffi**](https://github.com/lexiforest/curl_cffi) (recommended) - Python binding for [curl-impersonate](https://github.com/lexiforest/curl-impersonate). Provides impersonation targets for Chrome, Edge and Safari. Licensed under [MIT](https://github.com/lexiforest/curl_cffi/blob/main/LICENSE)
  * Can be installed with the `curl-cffi` group, e.g. `pip install &quot;yt-dlp[default,curl-cffi]&quot;`
  * Currently included in `yt-dlp.exe`, `yt-dlp_linux` and `yt-dlp_macos` builds


### Metadata

* [**mutagen**](https://github.com/quodlibet/mutagen)\* - For `--embed-thumbnail` in certain formats. Licensed under [GPLv2+](https://github.com/quodlibet/mutagen/blob/master/COPYING)
* [**AtomicParsley**](https://github.com/wez/atomicparsley) - For `--embed-thumbnail` in `mp4`/`m4a` files when `mutagen`/`ffmpeg` cannot. Licensed under [GPLv2+](https://github.com/wez/atomicparsley/blob/master/COPYING)
* [**xattr**](https://github.com/xattr/xattr), [**pyxattr**](https://github.com/iustin/pyxattr) or [**setfattr**](http://savannah.nongnu.org/projects/attr) - For writing xattr metadata (`--xattrs`) on **Mac** and **BSD**. Licensed under [MIT](https://github.com/xattr/xattr/blob/master/LICENSE.txt), [LGPL2.1](https://github.com/iustin/pyxattr/blob/master/COPYING) and [GPLv2+](http://git.savannah.nongnu.org/cgit/attr.git/tree/doc/COPYING) respectively

### Misc

* [**pycryptodomex**](https://github.com/Legrandin/pycryptodome)\* - For decrypting AES-128 HLS streams and various other data. Licensed under [BSD-2-Clause](https://github.com/Legrandin/pycryptodome/blob/master/LICENSE.rst)
* [**phantomjs**](https://github.com/ariya/phantomjs) - Used in extractors where javascript needs to be run. Licensed under [BSD-3-Clause](https://github.com/ariya/phantomjs/blob/master/LICENSE.BSD)
* [**secretstorage**](https://github.com/mitya57/secretstorage)\* - For `--cookies-from-browser` to access the **Gnome** keyring while decrypting cookies of **Chromium**-based browsers on **Linux**. Licensed under [BSD-3-Clause](https://github.com/mitya57/secretstorage/blob/master/LICENSE)
* Any external downloader that you want to use with `--downloader`

### Deprecated

* [**avconv** and **avprobe**](https://www.libav.org) - Now **deprecated** alternative to ffmpeg. License [depends on the build](https://libav.org/legal)
* [**sponskrub**](https://github.com/faissaloo/SponSkrub) - For using the now **deprecated** [sponskrub options](#sponskrub-options). Licensed under [GPLv3+](https://github.com/faissaloo/SponSkrub/blob/master/LICENCE.md)
* [**rtmpdump**](http://rtmpdump.mplayerhq.hu) - For downloading `rtmp` streams. ffmpeg can be used instead with `--downloader ffmpeg`. Licensed under [GPLv2+](http://rtmpdump.mplayerhq.hu)
* [**mplayer**](http://mplayerhq.hu/design7/info.html) or [**mpv**](https://mpv.io) - For downloading `rstp`/`mms` streams. ffmpeg can be used instead with `--downloader ffmpeg`. Licensed under [GPLv2+](https://github.com/mpv-player/mpv/blob/master/Copyright)

To use or redistribute the dependencies, you must agree to their respective licensing terms.

The standalone release binaries are built with the Python interpreter and the packages marked with **\*** included.

If you do not have the necessary dependencies for a task you are attempting, yt-dlp will warn you. All the currently available dependencies are visible at the top of the `--verbose` output


## COMPILE

### Standalone PyInstaller Builds
To build the standalone executable, you must have Python and `pyinstaller` (plus any of yt-dlp&#039;s [optional dependencies](#dependencies) if needed). The executable will be built for the same CPU architecture as the Python used.

You can run the following commands:

```
python3 devscripts/install_deps.py --include pyinstaller
python3 devscripts/make_lazy_extractors.py
python3 -m bundle.pyinstaller
```

On some systems, you may need to use `py` or `python` instead of `python3`.

`python -m bundle.pyinstaller` accepts any arguments that can be passed to `pyinstaller`, such as `--onefile/-F` or `--onedir/-D`, which is further [documented here](https://pyinstaller.org/en/stable/usage.html#what-to-generate).

**Note**: Pyinstaller versions below 4.4 [do not support](https://github.com/pyinstaller/pyinstaller#requirements-and-tested-platforms) Python installed from the Windows store without using a virtual environment.

**Important**: Running `pyinstaller` directly **instead of** using `python -m bundle.pyinstaller` is **not** officially supported. This may or may not work correctly.

### Platform-independent Binary (UNIX)
You will need the build tools `python` (3.9+), `zip`, `make` (GNU), `pandoc`\* and `pytest`\*.

After installing these, simply run `make`.

You can also run `make yt-dlp` instead to compile only the binary without updating any of the additional files. (The build tools marked with **\*** are not needed for this)

### Related scripts

* **`devscripts/install_deps.py`** - Install dependencies for yt-dlp.
* **`devscripts/update-version.py`** - Update the version number based on the current date.
* **`devscripts/set-variant.py`** - Set the build variant of the executable.
* **`devscripts/make_changelog.py`** - Create a markdown changelog using short commit messages and update `CONTRIBUTORS` file.
* **`devscripts/make_lazy_extractors.py`** - Create lazy extractors. Running this before building the binaries (any variant) will improve their startup performance. Set the environment variable `YTDLP_NO_LAZY_EXTRACTORS` to something nonempty to forcefully disable lazy extractor loading.

Note: See their `--help` for more info.

### Forking the project
If you fork the project on Git

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[HunxByts/GhostTrack]]></title>
            <link>https://github.com/HunxByts/GhostTrack</link>
            <guid>https://github.com/HunxByts/GhostTrack</guid>
            <pubDate>Mon, 18 Aug 2025 00:05:02 GMT</pubDate>
            <description><![CDATA[Useful tool to track location or mobile number]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/HunxByts/GhostTrack">HunxByts/GhostTrack</a></h1>
            <p>Useful tool to track location or mobile number</p>
            <p>Language: Python</p>
            <p>Stars: 1,746</p>
            <p>Forks: 299</p>
            <p>Stars today: 27 stars today</p>
            <h2>README</h2><pre># GhostTrack
Useful tool to track location or mobile number, so this tool can be called osint or also information gathering

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/bn.png&quot;/&gt;

New update :
```Version 2.2```

### Instalation on Linux (deb)
```
sudo apt-get install git
sudo apt-get install python3
```

### Instalation on Termux
```
pkg install git
pkg install python3
```

### Usage Tool
```
git clone https://github.com/HunxByts/GhostTrack.git
cd GhostTrack
pip3 install -r requirements.txt
python3 GhostTR.py
```

Display on the menu ```IP Tracker```

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/ip.png &quot; /&gt;

on the IP Track menu, you can combo with the seeker tool to get the target IP
&lt;details&gt;
&lt;summary&gt;:zap: Install Seeker :&lt;/summary&gt;
- &lt;strong&gt;&lt;a href=&quot;https://github.com/thewhiteh4t/seeker&quot;&gt;Get Seeker&lt;/a&gt;&lt;/strong&gt;
&lt;/details&gt;

Display on the menu ```Phone Tracker```

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/phone.png&quot; /&gt;

on this menu you can search for information from the target phone number

Display on the menu ```Username Tracker```

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/User.png&quot;/&gt;
on this menu you can search for information from the target username on social media

&lt;details&gt;
&lt;summary&gt;:zap: Author :&lt;/summary&gt;
- &lt;strong&gt;&lt;a href=&quot;https://github.com/HunxByts&quot;&gt;HunxByts&lt;/a&gt;&lt;/strong&gt;
&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[IBM/mcp-context-forge]]></title>
            <link>https://github.com/IBM/mcp-context-forge</link>
            <guid>https://github.com/IBM/mcp-context-forge</guid>
            <pubDate>Mon, 18 Aug 2025 00:05:01 GMT</pubDate>
            <description><![CDATA[A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/IBM/mcp-context-forge">IBM/mcp-context-forge</a></h1>
            <p>A Model Context Protocol (MCP) Gateway & Registry. Serves as a central management point for tools, resources, and prompts that can be accessed by MCP-compatible LLM applications. Converts REST API endpoints to MCP, composes virtual MCP servers with added security and observability, and converts between protocols (stdio, SSE, Streamable HTTP).</p>
            <p>Language: Python</p>
            <p>Stars: 1,337</p>
            <p>Forks: 202</p>
            <p>Stars today: 177 stars today</p>
            <h2>README</h2><pre># MCP Gateway

&gt; Model Context Protocol gateway &amp; proxy - unify REST, MCP, and A2A with federation, virtual servers, retries, security, and an optional admin UI.

![](docs/docs/images/contextforge-banner.png)

&lt;!-- === CI / Security / Build Badges === --&gt;
[![Build Python Package](https://github.com/IBM/mcp-context-forge/actions/workflows/python-package.yml/badge.svg)](https://github.com/IBM/mcp-context-forge/actions/workflows/python-package.yml)&amp;nbsp;
[![CodeQL](https://github.com/IBM/mcp-context-forge/actions/workflows/codeql.yml/badge.svg)](https://github.com/IBM/mcp-context-forge/actions/workflows/codeql.yml)&amp;nbsp;
[![Bandit Security](https://github.com/IBM/mcp-context-forge/actions/workflows/bandit.yml/badge.svg)](https://github.com/IBM/mcp-context-forge/actions/workflows/bandit.yml)&amp;nbsp;
[![Dependency Review](https://github.com/IBM/mcp-context-forge/actions/workflows/dependency-review.yml/badge.svg)](https://github.com/IBM/mcp-context-forge/actions/workflows/dependency-review.yml)&amp;nbsp;
[![Tests &amp; Coverage](https://github.com/IBM/mcp-context-forge/actions/workflows/pytest.yml/badge.svg)](https://github.com/IBM/mcp-context-forge/actions/workflows/pytest.yml)&amp;nbsp;
[![Lint &amp; Static Analysis](https://github.com/IBM/mcp-context-forge/actions/workflows/lint.yml/badge.svg)](https://github.com/IBM/mcp-context-forge/actions/workflows/lint.yml)

&lt;!-- === Container Build &amp; Deploy === --&gt;
[![Secure Docker Build](https://github.com/IBM/mcp-context-forge/actions/workflows/docker-image.yml/badge.svg)](https://github.com/IBM/mcp-context-forge/actions/workflows/docker-image.yml)&amp;nbsp;
[![Deploy to IBM Code Engine](https://github.com/IBM/mcp-context-forge/actions/workflows/ibm-cloud-code-engine.yml/badge.svg)](https://github.com/IBM/mcp-context-forge/actions/workflows/ibm-cloud-code-engine.yml)

&lt;!-- === Package / Container === --&gt;
[![Async](https://img.shields.io/badge/async-await-green.svg)](https://docs.python.org/3/library/asyncio.html)
[![License](https://img.shields.io/github/license/ibm/mcp-context-forge)](LICENSE)&amp;nbsp;
[![PyPI](https://img.shields.io/pypi/v/mcp-contextforge-gateway)](https://pypi.org/project/mcp-contextforge-gateway/)&amp;nbsp;
[![Docker Image](https://img.shields.io/badge/docker-ghcr.io%2Fibm%2Fmcp--context--forge-blue)](https://github.com/ibm/mcp-context-forge/pkgs/container/mcp-context-forge)&amp;nbsp;


ContextForge MCP Gateway is a feature-rich gateway, proxy and MCP Registry that federates MCP and REST services - unifying discovery, auth, rate-limiting, observability, virtual servers, multi-transport protocols, and an optional Admin UI into one clean endpoint for your AI clients. It runs as a fully compliant MCP server, deployable via PyPI or Docker, and scales to multi-cluster environments on Kubernetes with Redis-backed federation and caching.

![MCP Gateway](https://ibm.github.io/mcp-context-forge/images/mcpgateway.gif)
---

&lt;!-- vscode-markdown-toc --&gt;
## Table of Contents

* 1. [Table of Contents](#table-of-contents)
* 2. [ğŸš€ Overview &amp; Goals](#-overview--goals)
* 3. [Quick Start - PyPI](#quick-start---pypi)
    * 3.1. [1 - Install &amp; run (copy-paste friendly)](#1---install--run-copy-paste-friendly)
* 4. [Quick Start - Containers](#quick-start---containers)
    * 4.1. [ğŸ³ Docker](#-docker)
        * 4.1.1. [1 - Minimum viable run](#1---minimum-viable-run)
        * 4.1.2. [2 - Persist the SQLite database](#2---persist-the-sqlite-database)
        * 4.1.3. [3 - Local tool discovery (host network)](#3---local-tool-discovery-host-network)
    * 4.2. [ğŸ¦­ Podman (rootless-friendly)](#-podman-rootless-friendly)
        * 4.2.1. [1 - Basic run](#1---basic-run)
        * 4.2.2. [2 - Persist SQLite](#2---persist-sqlite)
        * 4.2.3. [3 - Host networking (rootless)](#3---host-networking-rootless)
* 5. [Testing `mcpgateway.wrapper` by hand](#testing-mcpgatewaywrapper-by-hand)
    * 5.1. [ğŸ§© Running from an MCP Client (`mcpgateway.wrapper`)](#-running-from-an-mcp-client-mcpgatewaywrapper)
        * 5.1.1. [1 - Install `uv` (`uvx` is an alias it provides)](#1---install-uv-uvx-is-an-alias-it-provides)
        * 5.1.2. [2 - Create an on-the-spot venv &amp; run the wrapper](#2---create-an-on-the-spot-venv--run-the-wrapper)
        * 5.1.3. [Claude Desktop JSON (runs through **uvx**)](#claude-desktop-json-runs-through-uvx)
    * 5.2. [ğŸš€ Using with Claude Desktop (or any GUI MCP client)](#-using-with-claude-desktop-or-any-gui-mcp-client)
* 6. [ğŸš€ Quick Start: VS Code Dev Container](#-quick-start-vs-code-dev-container)
    * 6.1. [1 - Clone &amp; Open](#1---clone--open)
    * 6.2. [2 - First-Time Build (Automatic)](#2---first-time-build-automatic)
* 7. [Quick Start (manual install)](#quick-start-manual-install)
    * 7.1. [Prerequisites](#prerequisites)
    * 7.2. [One-liner (dev)](#one-liner-dev)
    * 7.3. [Containerized (self-signed TLS)](#containerized-self-signed-tls)
    * 7.4. [Smoke-test the API](#smoke-test-the-api)
* 8. [Installation](#installation)
    * 8.1. [Via Make](#via-make)
    * 8.2. [UV (alternative)](#uv-alternative)
    * 8.3. [pip (alternative)](#pip-alternative)
    * 8.4. [Optional (PostgreSQL adapter)](#optional-postgresql-adapter)
        * 8.4.1. [Quick Postgres container](#quick-postgres-container)
* 9. [Configuration (`.env` or env vars)](#configuration-env-or-env-vars)
    * 9.1. [Basic](#basic)
    * 9.2. [Authentication](#authentication)
    * 9.3. [UI Features](#ui-features)
    * 9.4. [Security](#security)
    * 9.5. [Logging](#logging)
    * 9.6. [Transport](#transport)
    * 9.7. [Federation](#federation)
    * 9.8. [Resources](#resources)
    * 9.9. [Tools](#tools)
    * 9.10. [Prompts](#prompts)
    * 9.11. [Health Checks](#health-checks)
    * 9.12. [Database](#database)
    * 9.13. [Cache Backend](#cache-backend)
    * 9.14. [Development](#development)
* 10. [Running](#running)
    * 10.1. [Makefile](#makefile)
    * 10.2. [Script helper](#script-helper)
    * 10.3. [Manual (Uvicorn)](#manual-uvicorn)
* 11. [Authentication examples](#authentication-examples)
* 12. [â˜ï¸ AWS / Azure / OpenShift](#ï¸-aws--azure--openshift)
* 13. [â˜ï¸ IBM Cloud Code Engine Deployment](#ï¸-ibm-cloud-code-engine-deployment)
    * 13.1. [ğŸ”§ Prerequisites](#-prerequisites-1)
    * 13.2. [ğŸ“¦ Environment Variables](#-environment-variables)
    * 13.3. [ğŸš€ Make Targets](#-make-targets)
    * 13.4. [ğŸ“ Example Workflow](#-example-workflow)
* 14. [API Endpoints](#api-endpoints)
* 15. [Testing](#testing)
* 16. [Project Structure](#project-structure)
* 17. [API Documentation](#api-documentation)
* 18. [Makefile targets](#makefile-targets)
* 19. [ğŸ” Troubleshooting](#-troubleshooting)
    * 19.1. [Diagnose the listener](#diagnose-the-listener)
    * 19.2. [Why localhost fails on Windows](#why-localhost-fails-on-windows)
        * 19.2.1. [Fix (Podman rootless)](#fix-podman-rootless)
        * 19.2.2. [Fix (Docker Desktop &gt; 4.19)](#fix-docker-desktop--419)
* 20. [Contributing](#contributing)
* 21. [Changelog](#changelog)
* 22. [License](#license)
* 23. [Core Authors and Maintainers](#core-authors-and-maintainers)
* 24. [Star History and Project Activity](#star-history-and-project-activity)

&lt;!-- vscode-markdown-toc-config
    numbering=true
    autoSave=true
    /vscode-markdown-toc-config --&gt;
&lt;!-- /vscode-markdown-toc --&gt;



## ğŸš€ Overview &amp; Goals

**ContextForge MCP Gateway** is a gateway, registry, and proxy that sits in front of any [Model Context Protocol](https://modelcontextprotocol.io) (MCP) server or REST API-exposing a unified endpoint for all your AI clients.

**âš ï¸ Caution**: The current release (0.5.0) is considered alpha / early beta. It is not production-ready and should only be used for local development, testing, or experimentation. Features, APIs, and behaviors are subject to change without notice. **Do not** deploy in production environments without thorough security review, validation and additional security mechanisms.  Many of the features required for secure, large-scale, or multi-tenant production deployments are still on the [project roadmap](https://ibm.github.io/mcp-context-forge/architecture/roadmap/) - which is itself evolving.

It currently supports:

* Federation across multiple MCP and REST services
* Virtualization of legacy APIs as MCP-compliant tools and servers
* Transport over HTTP, JSON-RPC, WebSocket, SSE (with configurable keepalive), stdio and streamable-HTTP
* An Admin UI for real-time management, configuration, and log monitoring
* Built-in auth, retries, and rate-limiting
* **OpenTelemetry observability** with Phoenix, Jaeger, Zipkin, and other OTLP backends
* Scalable deployments via Docker or PyPI, Redis-backed caching, and multi-cluster federation

![MCP Gateway Architecture](https://ibm.github.io/mcp-context-forge/images/mcpgateway.svg)

For a list of upcoming features, check out the [ContextForge MCP Gateway Roadmap](https://ibm.github.io/mcp-context-forge/architecture/roadmap/)

**âš ï¸ Important**: MCP Gateway is not a standalone product - it is an open source component with **NO OFFICIAL SUPPORT** from IBM or its affiliates that can be integrated into your own solution architecture. If you choose to use it, you are responsible for evaluating its fit, securing the deployment, and managing its lifecycle. See [SECURITY.md](./SECURITY.md) for more details.

---

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ”Œ Gateway Layer with Protocol Flexibility&lt;/strong&gt;&lt;/summary&gt;

* Sits in front of any MCP server or REST API
* Lets you choose your MCP protocol version (e.g., `2025-03-26`)
* Exposes a single, unified interface for diverse backends

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸŒ Federation of Peer Gateways (MCP Registry)&lt;/strong&gt;&lt;/summary&gt;

* Auto-discovers or configures peer gateways (via mDNS or manual)
* Performs health checks and merges remote registries transparently
* Supports Redis-backed syncing and fail-over

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ§© Virtualization of REST/gRPC Services&lt;/strong&gt;&lt;/summary&gt;

* Wraps non-MCP services as virtual MCP servers
* Registers tools, prompts, and resources with minimal configuration

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ” REST-to-MCP Tool Adapter&lt;/strong&gt;&lt;/summary&gt;

* Adapts REST APIs into tools with:

  * Automatic JSON Schema extraction
  * Support for headers, tokens, and custom auth
  * Retry, timeout, and rate-limit policies

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ§  Unified Registries&lt;/strong&gt;&lt;/summary&gt;

* **Prompts**: Jinja2 templates, multimodal support, rollback/versioning
* **Resources**: URI-based access, MIME detection, caching, SSE updates
* **Tools**: Native or adapted, with input validation and concurrency controls

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ“ˆ Admin UI, Observability &amp; Dev Experience&lt;/strong&gt;&lt;/summary&gt;

* Admin UI built with HTMX + Alpine.js
* Real-time log viewer with filtering, search, and export capabilities
* Auth: Basic, JWT, or custom schemes
* Structured logs, health endpoints, metrics
* 400+ tests, Makefile targets, live reload, pre-commit hooks

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ” OpenTelemetry Observability&lt;/strong&gt;&lt;/summary&gt;

* **Vendor-agnostic tracing** with OpenTelemetry (OTLP) protocol support
* **Multiple backend support**: Phoenix (LLM-focused), Jaeger, Zipkin, Tempo, DataDog, New Relic
* **Distributed tracing** across federated gateways and services
* **Automatic instrumentation** of tools, prompts, resources, and gateway operations
* **LLM-specific metrics**: Token usage, costs, model performance
* **Zero-overhead when disabled** with graceful degradation
* **Easy configuration** via environment variables

Quick start with Phoenix (LLM observability):
```bash
# Start Phoenix
docker run -p 6006:6006 -p 4317:4317 arizephoenix/phoenix:latest

# Configure gateway
export OTEL_ENABLE_OBSERVABILITY=true
export OTEL_TRACES_EXPORTER=otlp
export OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317

# Run gateway - traces automatically sent to Phoenix
mcpgateway
```

See [Observability Documentation](https://ibm.github.io/mcp-context-forge/manage/observability/) for detailed setup with other backends.

&lt;/details&gt;

---

## Quick Start - PyPI

MCP Gateway is published on [PyPI](https://pypi.org/project/mcp-contextforge-gateway/) as `mcp-contextforge-gateway`.

---

**TLDR;**:
(single command using [uv](https://docs.astral.sh/uv/))

```bash
BASIC_AUTH_PASSWORD=pass \
MCPGATEWAY_UI_ENABLED=true \
MCPGATEWAY_ADMIN_API_ENABLED=true \
uvx --from mcp-contextforge-gateway mcpgateway --host 0.0.0.0 --port 4444
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ“‹ Prerequisites&lt;/strong&gt;&lt;/summary&gt;

* **Python â‰¥ 3.10** (3.11 recommended)
* **curl + jq** - only for the last smoke-test step

&lt;/details&gt;

### 1 - Install &amp; run (copy-paste friendly)

```bash
# 1ï¸âƒ£  Isolated env + install from pypi
mkdir mcpgateway &amp;&amp; cd mcpgateway
python3 -m venv .venv &amp;&amp; source .venv/bin/activate
pip install --upgrade pip
pip install mcp-contextforge-gateway

# 2ï¸âƒ£  Launch on all interfaces with custom creds &amp; secret key
# Enable the Admin API endpoints (true/false) - disabled by default
export MCPGATEWAY_UI_ENABLED=true
export MCPGATEWAY_ADMIN_API_ENABLED=true

BASIC_AUTH_PASSWORD=pass JWT_SECRET_KEY=my-test-key \
  mcpgateway --host 0.0.0.0 --port 4444 &amp;   # admin/pass

# 3ï¸âƒ£  Generate a bearer token &amp; smoke-test the API
export MCPGATEWAY_BEARER_TOKEN=$(python3 -m mcpgateway.utils.create_jwt_token \
    --username admin --exp 10080 --secret my-test-key)

curl -s -H &quot;Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN&quot; \
     http://127.0.0.1:4444/version | jq
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Windows (PowerShell) quick-start&lt;/strong&gt;&lt;/summary&gt;

```powershell
# 1ï¸âƒ£  Isolated env + install from PyPI
mkdir mcpgateway ; cd mcpgateway
python3 -m venv .venv ; .\.venv\Scripts\Activate.ps1
pip install --upgrade pip
pip install mcp-contextforge-gateway

# 2ï¸âƒ£  Environment variables (session-only)
$Env:MCPGATEWAY_UI_ENABLED        = &quot;true&quot;
$Env:MCPGATEWAY_ADMIN_API_ENABLED = &quot;true&quot;
$Env:BASIC_AUTH_PASSWORD          = &quot;changeme&quot;      # admin/changeme
$Env:JWT_SECRET_KEY               = &quot;my-test-key&quot;

# 3ï¸âƒ£  Launch the gateway
mcpgateway.exe --host 0.0.0.0 --port 4444

#   Optional: background it
# Start-Process -FilePath &quot;mcpgateway.exe&quot; -ArgumentList &quot;--host 0.0.0.0 --port 4444&quot;

# 4ï¸âƒ£  Bearer token and smoke-test
$Env:MCPGATEWAY_BEARER_TOKEN = python3 -m mcpgateway.utils.create_jwt_token `
    --username admin --exp 10080 --secret my-test-key

curl -s -H &quot;Authorization: Bearer $Env:MCPGATEWAY_BEARER_TOKEN&quot; `
     http://127.0.0.1:4444/version | jq
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;More configuration&lt;/strong&gt;&lt;/summary&gt;

Copy [.env.example](.env.example) to `.env` and tweak any of the settings (or use them as env variables).

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸš€ End-to-end demo (register a local MCP server)&lt;/strong&gt;&lt;/summary&gt;

```bash
# 1ï¸âƒ£  Spin up the sample GO MCP time server using mcpgateway.translate &amp; docker
python3 -m mcpgateway.translate \
     --stdio &quot;docker run --rm -i -p 8888:8080 ghcr.io/ibm/fast-time-server:latest -transport=stdio&quot; \
     --expose-sse \
     --port 8003

# Or using the official mcp-server-git using uvx:
pip install uv # to install uvx, if not already installed
python3 -m mcpgateway.translate --stdio &quot;uvx mcp-server-git&quot; --expose-sse --port 9000

# Alternative: running the local binary
# cd mcp-servers/go/fast-time-server; make build
# python3 -m mcpgateway.translate --stdio &quot;./dist/fast-time-server -transport=stdio&quot; --expose-sse --port 8002

# NEW: Expose via multiple protocols simultaneously!
python3 -m mcpgateway.translate \
     --stdio &quot;uvx mcp-server-git&quot; \
     --expose-sse \
     --expose-streamable-http \
     --port 9000
# Now accessible via both /sse (SSE) and /mcp (streamable HTTP) endpoints

# 2ï¸âƒ£  Register it with the gateway
curl -s -X POST -H &quot;Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN&quot; \
     -H &quot;Content-Type: application/json&quot; \
     -d &#039;{&quot;name&quot;:&quot;fast_time&quot;,&quot;url&quot;:&quot;http://localhost:9000/sse&quot;}&#039; \
     http://localhost:4444/gateways

# 3ï¸âƒ£  Verify tool catalog
curl -s -H &quot;Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN&quot; http://localhost:4444/tools | jq

# 4ï¸âƒ£  Create a *virtual server* bundling those tools. Use the ID of tools from the tool catalog (Step #3) and pass them in the associatedTools list.
curl -s -X POST -H &quot;Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN&quot; \
     -H &quot;Content-Type: application/json&quot; \
     -d &#039;{&quot;name&quot;:&quot;time_server&quot;,&quot;description&quot;:&quot;Fast time tools&quot;,&quot;associatedTools&quot;:[&lt;ID_OF_TOOLS&gt;]}&#039; \
     http://localhost:4444/servers | jq

# Example curl
curl -s -X POST -H &quot;Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN&quot;
     -H &quot;Content-Type: application/json&quot;
     -d &#039;{&quot;name&quot;:&quot;time_server&quot;,&quot;description&quot;:&quot;Fast time tools&quot;,&quot;associatedTools&quot;:[&quot;6018ca46d32a4ac6b4c054c13a1726a2&quot;]}&#039; \
     http://localhost:4444/servers | jq

# 5ï¸âƒ£  List servers (should now include the UUID of the newly created virtual server)
curl -s -H &quot;Authorization: Bearer $MCPGATEWAY_BEARER_TOKEN&quot; http://localhost:4444/servers | jq

# 6ï¸âƒ£  Client SSE endpoint. Inspect it interactively with the MCP Inspector CLI (or use any MCP client)
npx -y @modelcontextprotocol/inspector
# Transport Type: SSE, URL: http://localhost:4444/servers/UUID_OF_SERVER_1/sse,  Header Name: &quot;Authorization&quot;, Bearer Token
```

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;ğŸ–§ Using the stdio wrapper (mcpgateway-wrapper)&lt;/strong&gt;&lt;/summary&gt;

```bash
export MCP_AUTH_TOKEN=$MCPGATEWAY_BEARER_TOKEN
export MCP_SERVER_CATALOG_URLS=http://localhost:4444/servers/UUID_OF_SERVER_1
python3 -m mcpgateway.wrapper  # Ctrl-C to exit
```

You can also run it with `uv` or inside Docker/Podman - see the *Containers* section above.

In MCP Inspector, define `MCP_AUTH_TOKEN` and `MCP_SERVER_CATALOG_URLS` env variables, and select `python3` as the Command, and `-m mcpgateway.wrapper` as Arguments.

```bash
echo $PWD/.venv/bin/python3 # Using the Python3 full path ensures you have a working venv
export MCP_SERVER_CATALOG_URLS=&#039;http://localhost:4444/servers/UUID_OF_SERVER_1&#039;
export MCP_AUTH_TOKEN=${MCPGATEWAY_BEARER_TOKEN}
npx -y @modelcontextprotocol/inspector
```

When using a MCP Client such as Claude with stdio:

```json
{
  &quot;mcpServers&quot;: {
    &quot;mcpgateway-wrapper&quot;: {
      &quot;command&quot;: &quot;python&quot;,
      &quot;args&quot;: [&quot;-m&quot;, &quot;mcpgateway.wrapper&quot;],
      &quot;env&quot;: {
        &quot;MCP_AUTH_TOKEN&quot;: &quot;your-token-here&quot;,
        &quot;MCP_SERVER_CATALOG_URLS&quot;: &quot;http://localhost:4444/servers/UUID_OF_SERVER_1&quot;,
        &quot;MCP_TOOL_CALL_TIMEOUT&quot;: &quot;120&quot;
      }
    }
  }
}
```

&lt;/details&gt;

---

## Quick Start - Containers

Use the official OCI image from GHCR with **Docker** *or* **Podman**.

---

### ğŸ³ Docker

#### 1 - Minimum viable run

```bash
docker run -d --name mcpgateway \
  -p 4444:4444 \
  -e MCPGATEWAY_UI_ENABLED=true \
  -e MCPGATEWAY_ADMIN_API_ENABLED=true \
  -e HOST=0.0.0.0 \
  -e JWT_SECRET_KEY=my-test-key \
  -e BASIC_AUTH_USER=admin \
  -e BASIC_AUTH_PASSWORD=changeme \
  -e AUTH_REQUIRED=true \
  -e DATABASE_URL=sqlite:///./mcp.db \
  ghcr.io/ibm/mcp-context-forge:0.5.0

# Tail logs (Ctrl+C to quit)
docker logs -f mcpgateway

# Generating an API key
docker run --rm -it ghcr.io/ibm/mcp-context-forge:0.5.0 \
  python3 -m mcpgateway.utils.create_jwt_token --username admin --exp 0 --secret my-test-key
```

Browse to **[http://localhost:4444/admin](http://localhost:4444/admin)** (user `admin` / pass `changeme`).

#### 2 - Persist the SQLite database

```bash
mkdir -p $(pwd)/data

touch $(pwd)/data/mcp.db

sudo chown -R :docker $(pwd)/data

chmod 777 $(pwd)/data

docker run -d --name mcpgateway \
  --restart unless-stopped \
  -p 4444:4444 \
  -v $(pwd)/data:/data \
  -e MCPGATEWAY_UI_ENABLED=true \
  -e MCPGATEWAY_ADMIN_API_ENABLED=true \
  -e DATABASE_URL=sqlite:////data/mcp.db \
  -e HOST=0.0.0.0 \
  -e JWT_SECRET_KEY=my-test-key \
  -e BASIC_AUTH_USER=admin \
  -e BASIC_AUTH_PASSWORD=changeme \
  ghcr.io/ibm/mcp-context-forge:0.5.0
```

SQLite now lives on the host at `./data/mcp.db`.

#### 3 - Local tool discovery (host network)

```bash
mkdir -p $(pwd)/data

touch $(pwd)/data/mcp.db

sudo chown -R :do

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[manycore-research/SpatialLM]]></title>
            <link>https://github.com/manycore-research/SpatialLM</link>
            <guid>https://github.com/manycore-research/SpatialLM</guid>
            <pubDate>Mon, 18 Aug 2025 00:05:00 GMT</pubDate>
            <description><![CDATA[SpatialLM: Training Large Language Models for Structured Indoor Modeling]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/manycore-research/SpatialLM">manycore-research/SpatialLM</a></h1>
            <p>SpatialLM: Training Large Language Models for Structured Indoor Modeling</p>
            <p>Language: Python</p>
            <p>Stars: 3,798</p>
            <p>Forks: 294</p>
            <p>Stars today: 17 stars today</p>
            <h2>README</h2><pre># SpatialLM

&lt;!-- markdownlint-disable first-line-h1 --&gt;
&lt;!-- markdownlint-disable html --&gt;
&lt;!-- markdownlint-disable no-duplicate-header --&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;figures/logo_light.png#gh-light-mode-only&quot; width=&quot;60%&quot; alt=&quot;SpatialLM&quot; /&gt;
  &lt;img src=&quot;figures/logo_dark.png#gh-dark-mode-only&quot; width=&quot;60%&quot; alt=&quot;SpatialLM&quot; /&gt;
&lt;/div&gt;
&lt;hr style=&quot;margin-top: 0; margin-bottom: 8px;&quot;&gt;
&lt;div align=&quot;center&quot; style=&quot;margin-top: 0; padding-top: 0; line-height: 1;&quot;&gt;
    &lt;a href=&quot;https://manycore-research.github.io/SpatialLM&quot; target=&quot;_blank&quot; style=&quot;margin: 2px;&quot;&gt;&lt;img alt=&quot;Project&quot;
    src=&quot;https://img.shields.io/badge/ğŸŒ%20Website-SpatialLM-ffc107?color=42a5f5&amp;logoColor=white&quot; style=&quot;display: inline-block; vertical-align: middle;&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://arxiv.org/abs/2506.07491&quot; target=&quot;_blank&quot; style=&quot;margin: 2px;&quot;&gt;&lt;img alt=&quot;arXiv&quot;
    src=&quot;https://img.shields.io/badge/arXiv-Techreport-b31b1b?logo=arxiv&amp;logoColor=white&quot; style=&quot;display: inline-block; vertical-align: middle;&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/manycore-research/SpatialLM&quot; target=&quot;_blank&quot; style=&quot;margin: 2px;&quot;&gt;&lt;img alt=&quot;GitHub&quot;
    src=&quot;https://img.shields.io/badge/GitHub-SpatialLM-24292e?logo=github&amp;logoColor=white&quot; style=&quot;display: inline-block; vertical-align: middle;&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot; style=&quot;line-height: 1;&quot;&gt;
    &lt;a href=&quot;https://huggingface.co/manycore-research/SpatialLM1.1-Qwen-0.5B&quot; target=&quot;_blank&quot; style=&quot;margin: 2px;&quot;&gt;&lt;img alt=&quot;Hugging Face&quot;
    src=&quot;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-SpatialLM-ffc107?color=ffc107&amp;logoColor=white&quot; style=&quot;display: inline-block; vertical-align: middle;&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://huggingface.co/datasets/manycore-research/SpatialLM-Testset&quot; target=&quot;_blank&quot; style=&quot;margin: 2px;&quot;&gt;&lt;img alt=&quot;Dataset&quot;
    src=&quot;https://img.shields.io/badge/%F0%9F%A4%97%20Dataset-Testset-ffc107?color=ffc107&amp;logoColor=white&quot; style=&quot;display: inline-block; vertical-align: middle;&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

## âœ¨ News

- [Jun, 2025] Check out our new models: [SpatialLM1.1-Llama-1B](https://huggingface.co/manycore-research/SpatialLM1.1-Llama-1B) and [SpatialLM1.1-Qwen-0.5B](https://huggingface.co/manycore-research/SpatialLM1.1-Qwen-0.5B), now available on Hugging Face. SpatialLM1.1 doubles the point cloud resolution, incorporates a more powerful point cloud encoder [Sonata](https://xywu.me/sonata/) and supports detection with user-specified categories.
- [Jun, 2025] SpatialLM [Technical Report](https://arxiv.org/abs/2506.07491) is now on arXiv.
- [Mar, 2025] We&#039;re excited to release the [SpatialLM-Llama-1B](https://huggingface.co/manycore-research/SpatialLM-Llama-1B) and [SpatialLM-Qwen-0.5B](https://huggingface.co/manycore-research/SpatialLM-Qwen-0.5B) on Hugging Face.
- [Mar, 2025] Initial release of SpatialLM!

## Introduction

SpatialLM is a 3D large language model designed to process 3D point cloud data and generate structured 3D scene understanding outputs. These outputs include architectural elements like walls, doors, windows, and oriented object bounding boxes with their semantic categories. Unlike previous methods that require specialized equipment for data collection, SpatialLM can handle point clouds from diverse sources such as monocular video sequences, RGBD images, and LiDAR sensors. This multimodal architecture effectively bridges the gap between unstructured 3D geometric data and structured 3D representations, offering high-level semantic understanding. It enhances spatial reasoning capabilities for applications in embodied robotics, autonomous navigation, and other complex 3D scene analysis tasks.

&lt;div align=&quot;center&quot;&gt;
  &lt;video src=&quot;https://github.com/user-attachments/assets/c0218d6a-f676-41f8-ae76-bba228866306&quot; poster=&quot;figures/cover.png&quot;&gt; &lt;/video&gt;
  &lt;p&gt;&lt;i&gt;SpatialLM reconstructs 3D layout from a monocular RGB video with MASt3R-SLAM. Results aligned to video with GT cameras for visualization.&lt;/i&gt;&lt;/p&gt;
&lt;/div&gt;

## SpatialLM Models

&lt;div align=&quot;center&quot;&gt;

|       **Model**        | **Download**                                                                      |
| :--------------------: | --------------------------------------------------------------------------------- |
| SpatialLM1.1-Llama-1B  | [ğŸ¤— HuggingFace](https://huggingface.co/manycore-research/SpatialLM1.1-Llama-1B)  |
| SpatialLM1.1-Qwen-0.5B | [ğŸ¤— HuggingFace](https://huggingface.co/manycore-research/SpatialLM1.1-Qwen-0.5B) |
| SpatialLM1.0-Llama-1B  | [ğŸ¤— HuggingFace](https://huggingface.co/manycore-research/SpatialLM-Llama-1B)     |
| SpatialLM1.0-Qwen-0.5B | [ğŸ¤— HuggingFace](https://huggingface.co/manycore-research/SpatialLM-Qwen-0.5B)    |

&lt;/div&gt;

## Usage

### Installation

Tested with the following environment:

- Python 3.11
- Pytorch 2.4.1
- CUDA Version 12.4

```bash
# clone the repository
git clone https://github.com/manycore-research/SpatialLM.git
cd SpatialLM

# create a conda environment with cuda 12.4
conda create -n spatiallm python=3.11
conda activate spatiallm
conda install -y -c nvidia/label/cuda-12.4.0 cuda-toolkit conda-forge::sparsehash

# Install dependencies with poetry
pip install poetry &amp;&amp; poetry config virtualenvs.create false --local
poetry install
# SpatialLM1.0 dependency
poe install-torchsparse # Building wheel for torchsparse will take a while
# SpatialLM1.1 dependency
poe install-sonata # Building wheel for flash-attn will take a while
```

### Inference

In the current version of SpatialLM, input point clouds are considered axis-aligned where the z-axis is the up axis. This orientation is crucial for maintaining consistency in spatial understanding and scene interpretation across different datasets and applications.
Example preprocessed point clouds, reconstructed from RGB videos using [MASt3R-SLAM](https://github.com/rmurai0610/MASt3R-SLAM), are available in [SpatialLM-Testset](#spatiallm-testset).

Download an example point cloud:

```bash
huggingface-cli download manycore-research/SpatialLM-Testset pcd/scene0000_00.ply --repo-type dataset --local-dir .
```

Run inference:

```bash
python inference.py --point_cloud pcd/scene0000_00.ply --output scene0000_00.txt --model_path manycore-research/SpatialLM1.1-Qwen-0.5B
```

### Detection with user-specified categories

SpatialLM1.1 supports object detection conditioned on user-specified categories by leveraging the flexibility of LLMs.

SpatialLM1.1 offers three variants of structured indoor modeling tasks:

- **Structured Reconstruction**: Detect walls, doors, windows, boxes.
- **Layout Estimation**: Detect walls, doors, windows.
- **3D Object Detection**: Detect boxes.

For tasks that include object box estimation, you can specify a subset of the 59 furniture categories, and the model will only predict objects within those specified categories. For example:

```bash
python inference.py --point_cloud pcd/scene0000_00.ply --output scene0000_00.txt --model_path manycore-research/SpatialLM1.1-Qwen-0.5B --detect_type object --category bed nightstand
```

### Visualization

Use `rerun` to visualize the point cloud and the predicted structured 3D layout output:

```bash
# Convert the predicted layout to Rerun format
python visualize.py --point_cloud pcd/scene0000_00.ply --layout scene0000_00.txt --save scene0000_00.rrd

# Visualize the point cloud and the predicted layout
rerun scene0000_00.rrd
```

### Evaluation

To evaluate the performance of SpatialLM, we provide `eval.py` script that reports the benchmark results on the SpatialLM-Testset in the table below in section [Benchmark Results](#benchmark-results).

Download the testset:

```bash
huggingface-cli download manycore-research/SpatialLM-Testset --repo-type dataset --local-dir SpatialLM-Testset
```

Run evaluation:

```bash
# Run inference on the PLY point clouds in folder SpatialLM-Testset/pcd with SpatialLM1.1-Qwen-0.5B model
python inference.py --point_cloud SpatialLM-Testset/pcd --output SpatialLM-Testset/pred --model_path manycore-research/SpatialLM1.1-Qwen-0.5B

# Evaluate the predicted layouts
python eval.py --metadata SpatialLM-Testset/test.csv --gt_dir SpatialLM-Testset/layout --pred_dir SpatialLM-Testset/pred --label_mapping SpatialLM-Testset/benchmark_categories.tsv
```

### Example using a custom video

We provide an example of how to use our model to estimate scene layout starting from a RGB video with the newly released [SLAM3R](https://github.com/PKU-VCL-3DV/SLAM3R) in [EXAMPLE.md](EXAMPLE.md). These steps work for MASt3R-SLAM, and other reconstruction methods as well.

## SpatialLM Testset

We provide a test set of 107 preprocessed point clouds, reconstructed from RGB videos using [MASt3R-SLAM](https://github.com/rmurai0610/MASt3R-SLAM). SpatialLM-Testset is quite challenging compared to prior clean RGBD scans datasets due to the noises and occlusions in the point clouds reconstructed from monocular RGB videos.

&lt;div align=&quot;center&quot;&gt;

|    **Dataset**    | **Download**                                                                       |
| :---------------: | ---------------------------------------------------------------------------------- |
| SpatialLM-Testset | [ğŸ¤— Datasets](https://huggingface.co/datasets/manycore-research/SpatialLM-TestSet) |

&lt;/div&gt;

## Benchmark Results

### Layout Estimation

Layout estimation focuses on predicting architectural elements, i.e., walls, doors, and windows, within an indoor scene. We evaluated this task on the [Structured3D](https://structured3d-dataset.org) dataset. For [RoomFormer](https://github.com/ywyue/RoomFormer), we directly downloaded the model checkpoint. SceneScript and SpatialLM were first trained on our dataset, and further fine-tuned on Structured3D.

&lt;div align=&quot;center&quot;&gt;

|   **Method**    | **RoomFormer** | **SceneScript (finetuned)** | **SpatialLM1.1-Qwen-0.5B (finetuned)** |
| :-------------: | :------------: | :-------------------------: | :------------------------------------: |
| **F1 @.25 IoU** |      70.4      |            83.1             |                  86.5                  |
| **F1 @.5 IoU**  |      67.2      |            80.8             |                  84.6                  |

&lt;/div&gt;

### 3D Object Detection

We evaluate 3D object detection on [ScanNet](http://www.scan-net.org) with annotations of 18 object categories. For [V-DETR](https://github.com/V-DETR/V-DETR), we directly download the model checkpoint. SceneScript and SpatialLM were first trained on our dataset, and further fine-tuned on ScanNet.

&lt;div align=&quot;center&quot;&gt;

|   **Method**    | **V-DETR** | **SceneScript (finetuned)** | **SpatialLM1.1-Qwen-0.5B (finetuned)** |
| :-------------: | :--------: | :-------------------------: | :------------------------------------: |
| **F1 @.25 IoU** |    65.1    |            49.1             |                  65.6                  |
| **F1 @.5 IoU**  |    56.8    |            36.8             |                  52.6                  |

&lt;/div&gt;

### Zero-shot Detection on Videos

Zero-shot detection results on the challenging SpatialLM-Testset are reported in the following table:

&lt;div align=&quot;center&quot;&gt;

|   **Method**    | **SpatialLM1.1-Llama-1B** | **SpatialLM1.1-Qwen-0.5B** |
| :-------------: | :-----------------------: | :------------------------: |
|   **Layout**    |   **F1 @.25 IoU (2D)**    |    **F1 @.25 IoU (2D)**    |
|      wall       |           68.9            |            68.2            |
|      door       |           46.3            |            43.1            |
|     window      |           43.8            |            47.4            |
|                 |                           |                            |
|   **Objects**   |   **F1 @.25 IoU (3D)**    |    **F1 @.25 IoU (2D)**    |
|     curtain     |           34.9            |            37.0            |
|   nightstand    |           62.8            |            67.0            |
|   chandelier    |           53.5            |            36.8            |
|    wardrobe     |           29.4            |            39.6            |
|       bed       |           96.8            |            95.2            |
|      sofa       |           66.9            |            69.1            |
|      chair      |           20.8            |            32.3            |
|     cabinet     |           15.2            |            11.2            |
|  dining table   |           40.7            |            24.2            |
|     plants      |           29.5            |            26.3            |
|   tv cabinet    |           34.4            |            27.3            |
|  coffee table   |           56.4            |            64.9            |
|   side table    |           14.6            |            9.7             |
| air conditioner |           16.7            |            24.0            |
|     dresser     |           46.7            |            46.7            |
|      stool      |           17.6            |            30.8            |
|  refrigerator   |            0.0            |            16.7            |
|    painting     |           34.9            |            38.2            |
|     carpet      |           40.3            |            24.1            |
|       tv        |           16.0            |            18.0            |

&lt;/div&gt;

### Result Visualizations

&lt;div align=&quot;center&quot;&gt;

|                                                            Layout Estimation                                                            |                                                          Object Detection                                                          |                                                       Zero-shot Reconstruction                                                        |
| :-------------------------------------------------------------------------------------------------------------------------------------: | :--------------------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------: |
|                                                  ![Structured3D](./figures/stru3d.jpg)                                                  |                                                 ![ScanNet](./figures/scannet.jpg)                                                  |                                                 ![Zero-shot](./figures/zeroshot.jpg)                                                  |
| [Structured3D Results](https://manycore-research-azure.kujiale.com/manycore-research/SpatialLM/supplementary/visualization_layout.html) | [ScanNet Results](https://manycore-research-azure.kujiale.com/manycore-research/SpatialLM/supplementary/visualization_object.html) | [Zeroshot Results](https://manycore-research-azure.kujiale.com/manycore-research/SpatialLM/supplementary/visualization_zeroshot.html) |

&lt;/div&gt;

## License

SpatialLM-Llama-1B is derived from Llama3.2-1B-Instruct, which is licensed under the Llama3.2 license.
SpatialLM-Qwen-0.5B is derived from the Qwen-2.5 series, originally licensed under the Apache 2.0 License.

SpatialLM1.0 are built upon the SceneScript point cloud encoder, licensed under the CC-BY-NC-4.0 License. TorchSparse, utilized in this project, is licensed under the MIT License.

SpatialLM1.1 are built upon Sonata point cloud encoder, model weight is licensed under the CC-BY-NC-4.0 License. Code built on Pointcept is licensed under the Apache 2.0 License.

## Citation

If you find this work useful, please consider citing:

```bibtex
@article{SpatialLM,
    title         = {SpatialLM: Training Large Language Models for Structured Indoor Modeling},
    author        = {Mao, Yongsen and Zhong, Junhao and Fang, Chuan and Zheng, Jia and Tang, Rui and Zhu, Hao and Tan, Ping and Zhou, Zihan},
    journal       = {arXiv preprint},
    year          = {2025},
    eprint        = {2506.07491},
    archivePrefix = {arXiv},
    primaryClass  = {cs.CV}
}
```

## Acknowledgements

We would like to thank the following projects that made this work possible:

[Llama3.2](https://github.com/meta-llama) | [Qwen2.5](https://github.com/QwenLM/Qwen2.5) | [Transformers](https://github.com/huggingface/transformers) | [SceneScript](https://github.com/facebookresearch/scenescript) | [TorchSparse](https://github.com/mit-han-lab/torchsparse) | [Sonata](https://xywu.me/sonata/) | [Pointcept](https://github.com/Pointcept/Pointcept)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Rapptz/discord.py]]></title>
            <link>https://github.com/Rapptz/discord.py</link>
            <guid>https://github.com/Rapptz/discord.py</guid>
            <pubDate>Mon, 18 Aug 2025 00:04:59 GMT</pubDate>
            <description><![CDATA[An API wrapper for Discord written in Python.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Rapptz/discord.py">Rapptz/discord.py</a></h1>
            <p>An API wrapper for Discord written in Python.</p>
            <p>Language: Python</p>
            <p>Stars: 15,614</p>
            <p>Forks: 3,880</p>
            <p>Stars today: 4 stars today</p>
            <h2>README</h2><pre>README not available. Either the repository does not have a README or it could not be accessed.</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sqlmapproject/sqlmap]]></title>
            <link>https://github.com/sqlmapproject/sqlmap</link>
            <guid>https://github.com/sqlmapproject/sqlmap</guid>
            <pubDate>Mon, 18 Aug 2025 00:04:58 GMT</pubDate>
            <description><![CDATA[Automatic SQL injection and database takeover tool]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sqlmapproject/sqlmap">sqlmapproject/sqlmap</a></h1>
            <p>Automatic SQL injection and database takeover tool</p>
            <p>Language: Python</p>
            <p>Stars: 35,042</p>
            <p>Forks: 5,998</p>
            <p>Stars today: 8 stars today</p>
            <h2>README</h2><pre># sqlmap ![](https://i.imgur.com/fe85aVR.png)

[![.github/workflows/tests.yml](https://github.com/sqlmapproject/sqlmap/actions/workflows/tests.yml/badge.svg)](https://github.com/sqlmapproject/sqlmap/actions/workflows/tests.yml) [![Python 2.6|2.7|3.x](https://img.shields.io/badge/python-2.6|2.7|3.x-yellow.svg)](https://www.python.org/) [![License](https://img.shields.io/badge/license-GPLv2-red.svg)](https://raw.githubusercontent.com/sqlmapproject/sqlmap/master/LICENSE) [![x](https://img.shields.io/badge/x-@sqlmap-blue.svg)](https://x.com/sqlmap)

sqlmap is an open source penetration testing tool that automates the process of detecting and exploiting SQL injection flaws and taking over of database servers. It comes with a powerful detection engine, many niche features for the ultimate penetration tester, and a broad range of switches including database fingerprinting, over data fetching from the database, accessing the underlying file system, and executing commands on the operating system via out-of-band connections.

Screenshots
----

![Screenshot](https://raw.github.com/wiki/sqlmapproject/sqlmap/images/sqlmap_screenshot.png)

You can visit the [collection of screenshots](https://github.com/sqlmapproject/sqlmap/wiki/Screenshots) demonstrating some of the features on the wiki.

Installation
----

You can download the latest tarball by clicking [here](https://github.com/sqlmapproject/sqlmap/tarball/master) or latest zipball by clicking [here](https://github.com/sqlmapproject/sqlmap/zipball/master).

Preferably, you can download sqlmap by cloning the [Git](https://github.com/sqlmapproject/sqlmap) repository:

    git clone --depth 1 https://github.com/sqlmapproject/sqlmap.git sqlmap-dev

sqlmap works out of the box with [Python](https://www.python.org/download/) version **2.6**, **2.7** and **3.x** on any platform.

Usage
----

To get a list of basic options and switches use:

    python sqlmap.py -h

To get a list of all options and switches use:

    python sqlmap.py -hh

You can find a sample run [here](https://asciinema.org/a/46601).
To get an overview of sqlmap capabilities, a list of supported features, and a description of all options and switches, along with examples, you are advised to consult the [user&#039;s manual](https://github.com/sqlmapproject/sqlmap/wiki/Usage).

Links
----

* Homepage: https://sqlmap.org
* Download: [.tar.gz](https://github.com/sqlmapproject/sqlmap/tarball/master) or [.zip](https://github.com/sqlmapproject/sqlmap/zipball/master)
* Commits RSS feed: https://github.com/sqlmapproject/sqlmap/commits/master.atom
* Issue tracker: https://github.com/sqlmapproject/sqlmap/issues
* User&#039;s manual: https://github.com/sqlmapproject/sqlmap/wiki
* Frequently Asked Questions (FAQ): https://github.com/sqlmapproject/sqlmap/wiki/FAQ
* X: [@sqlmap](https://x.com/sqlmap)
* Demos: [https://www.youtube.com/user/inquisb/videos](https://www.youtube.com/user/inquisb/videos)
* Screenshots: https://github.com/sqlmapproject/sqlmap/wiki/Screenshots

Translations
----

* [Arabic](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-ar-AR.md)
* [Bengali](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-bn-BD.md)
* [Bulgarian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-bg-BG.md)
* [Chinese](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-zh-CN.md)
* [Croatian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-hr-HR.md)
* [Dutch](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-nl-NL.md)
* [French](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-fr-FR.md)
* [Georgian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-ka-GE.md)
* [German](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-de-DE.md)
* [Greek](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-gr-GR.md)
* [Hindi](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-in-HI.md)
* [Indonesian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-id-ID.md)
* [Italian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-it-IT.md)
* [Japanese](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-ja-JP.md)
* [Korean](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-ko-KR.md)
* [Kurdish (Central)](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-ckb-KU.md)
* [Persian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-fa-IR.md)
* [Polish](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-pl-PL.md)
* [Portuguese](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-pt-BR.md)
* [Russian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-ru-RU.md)
* [Serbian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-rs-RS.md)
* [Slovak](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-sk-SK.md)
* [Spanish](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-es-MX.md)
* [Turkish](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-tr-TR.md)
* [Ukrainian](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-uk-UA.md)
* [Vietnamese](https://github.com/sqlmapproject/sqlmap/blob/master/doc/translations/README-vi-VN.md)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[swisskyrepo/PayloadsAllTheThings]]></title>
            <link>https://github.com/swisskyrepo/PayloadsAllTheThings</link>
            <guid>https://github.com/swisskyrepo/PayloadsAllTheThings</guid>
            <pubDate>Mon, 18 Aug 2025 00:04:57 GMT</pubDate>
            <description><![CDATA[A list of useful payloads and bypass for Web Application Security and Pentest/CTF]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/swisskyrepo/PayloadsAllTheThings">swisskyrepo/PayloadsAllTheThings</a></h1>
            <p>A list of useful payloads and bypass for Web Application Security and Pentest/CTF</p>
            <p>Language: Python</p>
            <p>Stars: 69,259</p>
            <p>Forks: 15,813</p>
            <p>Stars today: 23 stars today</p>
            <h2>README</h2><pre># Payloads All The Things

A list of useful payloads and bypasses for Web Application Security.
Feel free to improve with your payloads and techniques !

You can also contribute with a :beers: IRL, or using the sponsor button.

[![Sponsor](https://img.shields.io/static/v1?label=Sponsor&amp;message=%E2%9D%A4&amp;logo=GitHub&amp;link=https://github.com/sponsors/swisskyrepo)](https://github.com/sponsors/swisskyrepo)
[![Tweet](https://img.shields.io/twitter/url/http/shields.io.svg?style=social)](https://twitter.com/intent/tweet?text=Payloads%20All%20The%20Things,%20a%20list%20of%20useful%20payloads%20and%20bypasses%20for%20Web%20Application%20Security%20-%20by%20@pentest_swissky&amp;url=https://github.com/swisskyrepo/PayloadsAllTheThings/)

An alternative display version is available at [PayloadsAllTheThingsWeb](https://swisskyrepo.github.io/PayloadsAllTheThings/).

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://raw.githubusercontent.com/swisskyrepo/PayloadsAllTheThings/master/.github/banner.png&quot; alt=&quot;banner&quot;&gt;
&lt;/p&gt;

## :book: Documentation

Every section contains the following files, you can use the `_template_vuln` folder to create a new chapter:

- README.md - vulnerability description and how to exploit it, including several payloads
- Intruder - a set of files to give to Burp Intruder
- Images - pictures for the README.md
- Files - some files referenced in the README.md

You might also like the other projects from the AllTheThings family :

- [InternalAllTheThings](https://swisskyrepo.github.io/InternalAllTheThings/) - Active Directory and Internal Pentest Cheatsheets
- [HardwareAllTheThings](https://swisskyrepo.github.io/HardwareAllTheThings/) - Hardware/IOT Pentesting Wiki

You want more ? Check the [Books](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/_LEARNING_AND_SOCIALS/BOOKS.md) and [Youtube channel](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/_LEARNING_AND_SOCIALS/YOUTUBE.md) selections.

## :technologist: Contributions

Be sure to read [CONTRIBUTING.md](https://github.com/swisskyrepo/PayloadsAllTheThings/blob/master/CONTRIBUTING.md)

&lt;p align=&quot;center&quot;&gt;
&lt;a href=&quot;https://github.com/swisskyrepo/PayloadsAllTheThings/graphs/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=swisskyrepo/PayloadsAllTheThings&amp;max=36&quot; alt=&quot;sponsors-list&quot; &gt;
&lt;/a&gt;
&lt;/p&gt;

Thanks again for your contribution! :heart:

## :beers: Sponsors

This project is proudly sponsored by these companies.

| Logo | Description |
| --- | --- |
| [&lt;img src=&quot;https://avatars.githubusercontent.com/u/34724717?s=40&amp;v=4&quot; alt=&quot;sponsor-serpapi&quot;&gt;](https://serpapi.com) | **SerpApi** is a real time API to access Google search results. It solves the issues of having to rent proxies, solving captchas, and JSON parsing. |
| [&lt;img src=&quot;https://avatars.githubusercontent.com/u/50994705?s=40&amp;v=4&quot; alt=&quot;sponsor-projectdiscovery&quot;&gt;](https://projectdiscovery.io/) | **ProjectDiscovery** - Detect real, exploitable vulnerabilities. Harness the power of Nuclei for fast and accurate findings without false positives. |
| [&lt;img src=&quot;https://avatars.githubusercontent.com/u/48131541?s=40&amp;v=4&quot; alt=&quot;sponsor-vaadata&quot;&gt;](https://www.vaadata.com/) | **VAADATA** - Ethical Hacking Services |
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sissbruecker/linkding]]></title>
            <link>https://github.com/sissbruecker/linkding</link>
            <guid>https://github.com/sissbruecker/linkding</guid>
            <pubDate>Mon, 18 Aug 2025 00:04:56 GMT</pubDate>
            <description><![CDATA[Self-hosted bookmark manager that is designed be to be minimal, fast, and easy to set up using Docker.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sissbruecker/linkding">sissbruecker/linkding</a></h1>
            <p>Self-hosted bookmark manager that is designed be to be minimal, fast, and easy to set up using Docker.</p>
            <p>Language: Python</p>
            <p>Stars: 8,904</p>
            <p>Forks: 442</p>
            <p>Stars today: 6 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;br&gt;
    &lt;a href=&quot;https://github.com/sissbruecker/linkding&quot;&gt;
        &lt;img src=&quot;assets/header.svg&quot; height=&quot;50&quot;&gt;
    &lt;/a&gt;
    &lt;br&gt;
&lt;/div&gt;

##  Introduction

linkding is a bookmark manager that you can host yourself.
It&#039;s designed be to be minimal, fast, and easy to set up using Docker.

The name comes from:
- *link* which is often used as a synonym for URLs and bookmarks in common language
- *Ding* which is German for thing
- ...so basically something for managing your links

**Feature Overview:**
- Clean UI optimized for readability
- Organize bookmarks with tags
- Bulk editing, Markdown notes, read it later functionality
- Share bookmarks with other users or guests
- Automatically provides titles, descriptions and icons of bookmarked websites
- Automatically archive websites, either as local HTML file or on Internet Archive
- Import and export bookmarks in Netscape HTML format
- Installable as a Progressive Web App (PWA)
- Extensions for [Firefox](https://addons.mozilla.org/firefox/addon/linkding-extension/) and [Chrome](https://chrome.google.com/webstore/detail/linkding-extension/beakmhbijpdhipnjhnclmhgjlddhidpe), as well as a bookmarklet
- SSO support via OIDC or authentication proxies
- REST API for developing 3rd party apps
- Admin panel for user self-service and raw data access


**Demo:** https://demo.linkding.link/

**Screenshot:**

![Screenshot](/docs/public/linkding-screenshot.png?raw=true &quot;Screenshot&quot;)

## Getting Started

The following links help you to get started with linkding:
- [Install linkding on your own server](https://linkding.link/installation) or [check managed hosting options](https://linkding.link/managed-hosting)
- [Install the browser extension](https://linkding.link/browser-extension)
- [Check out community projects](https://linkding.link/community), which include mobile apps, browser extensions, libraries and more

## Documentation

The full documentation is now available at [linkding.link](https://linkding.link/).

If you want to contribute to the documentation, you can find the source files in the `docs` folder.

If you want to contribute a community project, feel free to [submit a PR](https://github.com/sissbruecker/linkding/edit/master/docs/src/content/docs/community.md).

## Contributing

Small improvements, bugfixes and documentation improvements are always welcome. If you want to contribute a larger feature, consider opening an issue first to discuss it. I may choose to ignore PRs for features that don&#039;t align with the project&#039;s goals or that I don&#039;t want to maintain.

## Development

The application is built using the Django web framework. You can get started by checking out the excellent [Django docs](https://docs.djangoproject.com/en/4.1/). The `bookmarks` folder contains the actual bookmark application. Other than that the code should be self-explanatory / standard Django stuff ğŸ™‚.

### Prerequisites
- Python 3.12
- Node.js

### Setup

Create a virtual environment for the application (https://docs.python.org/3/tutorial/venv.html):
```
python3 -m venv ~/environments/linkding
```
Activate the environment for your shell:
```
source ~/environments/linkding/bin/activate[.csh|.fish]
```
Within the active environment install the application dependencies from the application folder:
```
pip3 install -r requirements.txt -r requirements.dev.txt
```
Install frontend dependencies:
```
npm install
```
Initialize database:
```
mkdir -p data
python3 manage.py migrate
```
Create a user for the frontend:
```
python3 manage.py createsuperuser --username=joe --email=joe@example.com
```
Start the Node.js development server (used for compiling JavaScript components like tag auto-completion) with:
```
npm run dev
```
Start the Django development server with:
```
python3 manage.py runserver
```
The frontend is now available under http://localhost:8000

### Tests

Run all tests with pytest:
```
make test
```

### Formatting

Format Python code with black, and JavaScript code with prettier:
```
make format
```

### DevContainers

This repository also supports DevContainers: [![Open in Remote - Containers](https://img.shields.io/static/v1?label=Remote%20-%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/sissbruecker/linkding.git)

Once checked out, only the following commands are required to get started:

Create a user for the frontend:
```
python3 manage.py createsuperuser --username=joe --email=joe@example.com
```
Start the Node.js development server (used for compiling JavaScript components like tag auto-completion) with:
```
npm run dev
```
Start the Django development server with:
```
python3 manage.py runserver
```
The frontend is now available under http://localhost:8000
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[budtmo/docker-android]]></title>
            <link>https://github.com/budtmo/docker-android</link>
            <guid>https://github.com/budtmo/docker-android</guid>
            <pubDate>Mon, 18 Aug 2025 00:04:55 GMT</pubDate>
            <description><![CDATA[Android in docker solution with noVNC supported and video recording]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/budtmo/docker-android">budtmo/docker-android</a></h1>
            <p>Android in docker solution with noVNC supported and video recording</p>
            <p>Language: Python</p>
            <p>Stars: 12,297</p>
            <p>Forks: 1,456</p>
            <p>Stars today: 71 stars today</p>
            <h2>README</h2><pre>
&lt;p align=&quot;center&quot;&gt;
  &lt;img id=&quot;header&quot; src=&quot;./images/logo_docker-android.png&quot; /&gt;
&lt;/p&gt;

[![Paypal Donate](https://img.shields.io/badge/paypal-donate-blue.svg)](http://paypal.me/budtmo) [![PRs Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com) [![codecov](https://codecov.io/gh/budtmo/docker-android/branch/master/graph/badge.svg)](https://codecov.io/gh/budtmo/docker-android) [![Join the chat at https://gitter.im/budtmo/docker-android](https://badges.gitter.im/budtmo/docker-android.svg)](https://gitter.im/budtmo/docker-android?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge) [![GitHub release](https://img.shields.io/github/release/budtmo/docker-android.svg)](https://github.com/budtmo/docker-android/releases)

Docker-Android is a docker image built to be used for everything related to Android. It can be used for Application development and testing (native, web and hybrid-app).

Advantages of using this project
--------------------------------
1. Emulator with different device profile and skins, such as Samsung Galaxy S6, LG Nexus 4, HTC Nexus One and more.
2. Support vnc to be able to see what happen inside docker container
3. Support log sharing feature where all logs can be accessed from web-UI
4. Ability to control emulator from outside container by using adb connect
5. Integrated with other cloud solutions, e.g. [Genymotion Cloud](https://www.genymotion.com/cloud/)
6. It can be used to build Android project
7. It can be used to run unit and UI-Test with different test-frameworks, e.g. Appium, Espresso, etc.

List of Docker-Images
---------------------
|Android   |API   |Image with latest release version   |Image with specific release version|
|:---|:---|:---|:---|
|9.0|28|budtmo/docker-android:emulator_9.0|budtmo/docker-android:emulator_9.0_&lt;release_version&gt;|
|10.0|29|budtmo/docker-android:emulator_10.0|budtmo/docker-android:emulator_10.0_&lt;release_version&gt;|
|11.0|30|budtmo/docker-android:emulator_11.0|budtmo/docker-android:emulator_11.0_&lt;release_version&gt;|
|12.0|32|budtmo/docker-android:emulator_12.0|budtmo/docker-android:emulator_12.0_&lt;release_version&gt;|
|13.0|33|budtmo/docker-android:emulator_13.0|budtmo/docker-android:emulator_13.0_&lt;release_version&gt;|
|14.0|34|budtmo/docker-android:emulator_14.0|budtmo/docker-android:emulator_14.0_&lt;release_version&gt;|
|-|-|budtmo/docker-android:genymotion|budtmo/docker-android:genymotion_&lt;release_version&gt;|

List of Devices
---------------

Type   | Device Name
-----  | -----
Phone  | Samsung Galaxy S10
Phone  | Samsung Galaxy S9
Phone  | Samsung Galaxy S8
Phone  | Samsung Galaxy S7 Edge
Phone  | Samsung Galaxy S7
Phone  | Samsung Galaxy S6
Phone  | Nexus 4
Phone  | Nexus 5
Phone  | Nexus One
Phone  | Nexus S
Tablet | Nexus 7
Tablet | Pixel C

Requirements
------------

1. Docker is installed on your system.

Quick Start
-----------

1. If you use ***Ubuntu OS*** on your host machine, you can skip this step. For ***OSX*** and ***Windows OS*** user, you need to use Virtual Machine that support Virtualization with Ubuntu OS because the image can be run under ***Ubuntu OS only***.

2. Your machine should support virtualization. To check if the virtualization is enabled is:
    ```
    sudo apt install cpu-checker
    kvm-ok
    ```

3. Run Docker-Android container
    ```
    docker run -d -p 6080:6080 -e EMULATOR_DEVICE=&quot;Samsung Galaxy S10&quot; -e WEB_VNC=true --device /dev/kvm --name android-container budtmo/docker-android:emulator_11.0
    ```

4. Open ***http://localhost:6080*** to see inside running container.

5. To check the status of the emulator
    ```
    docker exec -it android-container cat device_status
    ```

Persisting data
-----------

The default behaviour is to destroy the emulated device on container restart. To persist data, you need to mount a volume at `/home/androidusr`:
    ```
    docker run -v data:/home/androidusr budtmo/docker-android:emulator_11.0
    ```

WSL2 Hardware acceleration (Windows 11 only)
-----------

Credit goes to [Guillaume - The Parallel Interface blog](https://www.paralint.com/2022/11/find-new-modified-and-unversioned-subversion-files-on-windows)

[Microsoft - Advanced settings configuration in WSL](https://learn.microsoft.com/en-us/windows/wsl/wsl-config)


1. Add yourself to the `kvm` usergroup.
    ```
    sudo usermod -a -G kvm ${USER}
    ```

2. Add necessary flags to `/etc/wsl2.conf` to their respective sections.
    ```
    [boot]
    command = /bin/bash -c &#039;chown -v root:kvm /dev/kvm &amp;&amp; chmod 660 /dev/kvm&#039;

    [wsl2]
    nestedVirtualization=true
    ```
3. Restart WSL2 via CMD prompt or Powershell
    ```
    wsl --shutdown
    ```


`command = /bin/bash -c &#039;chown -v root:kvm /dev/kvm &amp;&amp; chmod 660 /dev/kvm&#039;` sets `/dev/kvm` to `kvm` usergroup rather than the default `root` usergroup on WSL2 startup.

`nestedVirtualization` flag is only available to Windows 11.

Use-Cases
---------

1. [Build Android project](./documentations/USE_CASE_BUILD_ANDROID_PROJECT.md)
2. [UI-Test with Appium](./documentations/USE_CASE_APPIUM.md)
3. [Control Android emulator on host machine](./documentations/USE_CASE_CONTROL_EMULATOR.md)
4. [SMS Simulation](./documentations/USE_CASE_SMS.md)
5. [Jenkins](./documentations/USE_CASE_JENKINS.md)
6. [Deploying on cloud (Azure, AWS, GCP)](./documentations/USE_CASE_CLOUD.md)

Custom-Configurations
---------------------

This [document](./documentations/CUSTOM_CONFIGURATIONS.md) contains information about configurations that can be used to enable some features, e.g. log-sharing, etc.

Genymotion
----------

&lt;p align=&quot;center&quot;&gt;
  &lt;img id=&quot;geny&quot; src=&quot;./images/logo_genymotion_and_dockerandroid.png&quot; /&gt;
&lt;/p&gt;

For you who do not have ressources to maintain the simulator or to buy machines or need different device profiles, you can give a try by using [Genymotion SAAS](https://cloud.geny.io/). Docker-Android is [integrated with Genymotion](https://www.genymotion.com/blog/partner_tag/docker/) on different cloud services, e.g. Genymotion SAAS, AWS, GCP, Alibaba Cloud. Please follow [this document](./documentations/THIRD_PARTY_GENYMOTION.md) for more detail.

Emulator Skins
--------------
The Emulator skins are taken from [Android Studio IDE](https://developer.android.com/studio) and [Samsung Developer Website](https://developer.samsung.com/)

USERS
-----

&lt;a href=&quot;https://lookerstudio.google.com/s/iGaemHJqQvg&quot;&gt;
  &lt;p align=&quot;center&quot;&gt;
    &lt;img src=&quot;./images/docker-android_users.png&quot; alt=&quot;docker-android-users&quot; width=&quot;800&quot; height=&quot;600&quot;&gt;
  &lt;/p&gt;
&lt;/a&gt;

PRO VERSION
-----------

Due to high requests for help and to be able to actively maintain the projects, the creator has decided to create docker-android-pro. Docker-Android-Pro is a sponsor based project which mean that the docker image of pro-version can be pulled only by [active sponsor](https://github.com/sponsors/budtmo).

The differences between normal version and pro version are:

|Feature   |Normal   |Pro   |Comment|
|:---|:---|:---|:---|
|user-behavior-analytics|Yes|No|-|
|proxy|No|Yes|Set up company proxy on Android emulator on fly|
|language|No|Yes|Set up language on Android emulator on fly|
|Newer Android version|No|Yes|Support other newer Android version e.g. Android 15, Android 16, etc|
|root-privileged|No|Yes|Able to run command with security privileged|
|headless-mode|No|Yes|Save resources by using headless mode|
|Selenium 4.x integration|No|Yes|Running Appium UI-Tests againt one (Selenium Hub) endpoint for Android- and iOS emulator(s) / device(s)|
|multiple Android-Simulators|No|Yes (soon)|Save resources by having multiple Android-Simulators on one docker-container|
|Google Play Store|No|Yes (soon)|-|
|Video Recording|No|Yes (soon)|Helpful for debugging|

This [document](./documentations/DOCKER-ANDROID-PRO.md) contains detail information about how to use docker-android-pro.

LICENSE
-------
See [License](LICENSE.md)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[freqtrade/freqtrade]]></title>
            <link>https://github.com/freqtrade/freqtrade</link>
            <guid>https://github.com/freqtrade/freqtrade</guid>
            <pubDate>Mon, 18 Aug 2025 00:04:54 GMT</pubDate>
            <description><![CDATA[Free, open source crypto trading bot]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/freqtrade/freqtrade">freqtrade/freqtrade</a></h1>
            <p>Free, open source crypto trading bot</p>
            <p>Language: Python</p>
            <p>Stars: 41,440</p>
            <p>Forks: 8,429</p>
            <p>Stars today: 31 stars today</p>
            <h2>README</h2><pre># ![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade_poweredby.svg)

[![Freqtrade CI](https://github.com/freqtrade/freqtrade/actions/workflows/ci.yml/badge.svg?branch=develop)](https://github.com/freqtrade/freqtrade/actions/)
[![DOI](https://joss.theoj.org/papers/10.21105/joss.04864/status.svg)](https://doi.org/10.21105/joss.04864)
[![Coverage Status](https://coveralls.io/repos/github/freqtrade/freqtrade/badge.svg?branch=develop&amp;service=github)](https://coveralls.io/github/freqtrade/freqtrade?branch=develop)
[![Documentation](https://readthedocs.org/projects/freqtrade/badge/)](https://www.freqtrade.io)
[![Maintainability](https://api.codeclimate.com/v1/badges/5737e6d668200b7518ff/maintainability)](https://codeclimate.com/github/freqtrade/freqtrade/maintainability)

Freqtrade is a free and open source crypto trading bot written in Python. It is designed to support all major exchanges and be controlled via Telegram or webUI. It contains backtesting, plotting and money management tools as well as strategy optimization by machine learning.

![freqtrade](https://raw.githubusercontent.com/freqtrade/freqtrade/develop/docs/assets/freqtrade-screenshot.png)

## Disclaimer

This software is for educational purposes only. Do not risk money which
you are afraid to lose. USE THE SOFTWARE AT YOUR OWN RISK. THE AUTHORS
AND ALL AFFILIATES ASSUME NO RESPONSIBILITY FOR YOUR TRADING RESULTS.

Always start by running a trading bot in Dry-run and do not engage money
before you understand how it works and what profit/loss you should
expect.

We strongly recommend you to have coding and Python knowledge. Do not
hesitate to read the source code and understand the mechanism of this bot.

## Supported Exchange marketplaces

Please read the [exchange specific notes](docs/exchanges.md) to learn about eventual, special configurations needed for each exchange.

- [X] [Binance](https://www.binance.com/)
- [X] [Bitmart](https://bitmart.com/)
- [X] [BingX](https://bingx.com/invite/0EM9RX)
- [X] [Bybit](https://bybit.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [HTX](https://www.htx.com/)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [Kraken](https://kraken.com/)
- [X] [OKX](https://okx.com/)
- [X] [MyOKX](https://okx.com/) (OKX EEA)
- [ ] [potentially many others](https://github.com/ccxt/ccxt/). _(We cannot guarantee they will work)_

### Supported Futures Exchanges (experimental)

- [X] [Binance](https://www.binance.com/)
- [X] [Gate.io](https://www.gate.io/ref/6266643)
- [X] [Hyperliquid](https://hyperliquid.xyz/) (A decentralized exchange, or DEX)
- [X] [OKX](https://okx.com/)
- [X] [Bybit](https://bybit.com/)

Please make sure to read the [exchange specific notes](docs/exchanges.md), as well as the [trading with leverage](docs/leverage.md) documentation before diving in.

### Community tested

Exchanges confirmed working by the community:

- [X] [Bitvavo](https://bitvavo.com/)
- [X] [Kucoin](https://www.kucoin.com/)

## Documentation

We invite you to read the bot documentation to ensure you understand how the bot is working.

Please find the complete documentation on the [freqtrade website](https://www.freqtrade.io).

## Features

- [x] **Based on Python 3.11+**: For botting on any operating system - Windows, macOS and Linux.
- [x] **Persistence**: Persistence is achieved through sqlite.
- [x] **Dry-run**: Run the bot without paying money.
- [x] **Backtesting**: Run a simulation of your buy/sell strategy.
- [x] **Strategy Optimization by machine learning**: Use machine learning to optimize your buy/sell strategy parameters with real exchange data.
- [X] **Adaptive prediction modeling**: Build a smart strategy with FreqAI that self-trains to the market via adaptive machine learning methods. [Learn more](https://www.freqtrade.io/en/stable/freqai/)
- [x] **Whitelist crypto-currencies**: Select which crypto-currency you want to trade or use dynamic whitelists.
- [x] **Blacklist crypto-currencies**: Select which crypto-currency you want to avoid.
- [x] **Builtin WebUI**: Builtin web UI to manage your bot.
- [x] **Manageable via Telegram**: Manage the bot with Telegram.
- [x] **Display profit/loss in fiat**: Display your profit/loss in fiat currency.
- [x] **Performance status report**: Provide a performance status of your current trades.

## Quick start

Please refer to the [Docker Quickstart documentation](https://www.freqtrade.io/en/stable/docker_quickstart/) on how to get started quickly.

For further (native) installation methods, please refer to the [Installation documentation page](https://www.freqtrade.io/en/stable/installation/).

## Basic Usage

### Bot commands

```
usage: freqtrade [-h] [-V]
                 {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
                 ...

Free, open source crypto trading bot

positional arguments:
  {trade,create-userdir,new-config,show-config,new-strategy,download-data,convert-data,convert-trade-data,trades-to-ohlcv,list-data,backtesting,backtesting-show,backtesting-analysis,edge,hyperopt,hyperopt-list,hyperopt-show,list-exchanges,list-markets,list-pairs,list-strategies,list-hyperoptloss,list-freqaimodels,list-timeframes,show-trades,test-pairlist,convert-db,install-ui,plot-dataframe,plot-profit,webserver,strategy-updater,lookahead-analysis,recursive-analysis}
    trade               Trade module.
    create-userdir      Create user-data directory.
    new-config          Create new config
    show-config         Show resolved config
    new-strategy        Create new strategy
    download-data       Download backtesting data.
    convert-data        Convert candle (OHLCV) data from one format to
                        another.
    convert-trade-data  Convert trade data from one format to another.
    trades-to-ohlcv     Convert trade data to OHLCV data.
    list-data           List downloaded data.
    backtesting         Backtesting module.
    backtesting-show    Show past Backtest results
    backtesting-analysis
                        Backtest Analysis module.
    hyperopt            Hyperopt module.
    hyperopt-list       List Hyperopt results
    hyperopt-show       Show details of Hyperopt results
    list-exchanges      Print available exchanges.
    list-markets        Print markets on exchange.
    list-pairs          Print pairs on exchange.
    list-strategies     Print available strategies.
    list-hyperoptloss   Print available hyperopt loss functions.
    list-freqaimodels   Print available freqAI models.
    list-timeframes     Print available timeframes for the exchange.
    show-trades         Show trades.
    test-pairlist       Test your pairlist configuration.
    convert-db          Migrate database to different system
    install-ui          Install FreqUI
    plot-dataframe      Plot candles with indicators.
    plot-profit         Generate plot showing profits.
    webserver           Webserver module.
    strategy-updater    updates outdated strategy files to the current version
    lookahead-analysis  Check for potential look ahead bias.
    recursive-analysis  Check for potential recursive formula issue.

options:
  -h, --help            show this help message and exit
  -V, --version         show program&#039;s version number and exit
```

### Telegram RPC commands

Telegram is not mandatory. However, this is a great way to control your bot. More details and the full command list on the [documentation](https://www.freqtrade.io/en/latest/telegram-usage/)

- `/start`: Starts the trader.
- `/stop`: Stops the trader.
- `/stopentry`: Stop entering new trades.
- `/status &lt;trade_id&gt;|[table]`: Lists all or specific open trades.
- `/profit [&lt;n&gt;]`: Lists cumulative profit from all finished trades, over the last n days.
- `/profit_long [&lt;n&gt;]`: Lists cumulative profit from all finished long trades, over the last n days.
- `/profit_short [&lt;n&gt;]`: Lists cumulative profit from all finished short trades, over the last n days.
- `/forceexit &lt;trade_id&gt;|all`: Instantly exits the given trade (Ignoring `minimum_roi`).
- `/fx &lt;trade_id&gt;|all`: Alias to `/forceexit`
- `/performance`: Show performance of each finished trade grouped by pair
- `/balance`: Show account balance per currency.
- `/daily &lt;n&gt;`: Shows profit or loss per day, over the last n days.
- `/help`: Show help message.
- `/version`: Show version.


## Development branches

The project is currently setup in two main branches:

- `develop` - This branch has often new features, but might also contain breaking changes. We try hard to keep this branch as stable as possible.
- `stable` - This branch contains the latest stable release. This branch is generally well tested.
- `feat/*` - These are feature branches, which are being worked on heavily. Please don&#039;t use these unless you want to test a specific feature.

## Support

### Help / Discord

For any questions not covered by the documentation or for further information about the bot, or to simply engage with like-minded individuals, we encourage you to join the Freqtrade [discord server](https://discord.gg/p7nuUNVfP7).

### [Bugs / Issues](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)

If you discover a bug in the bot, please
[search the issue tracker](https://github.com/freqtrade/freqtrade/issues?q=is%3Aissue)
first. If it hasn&#039;t been reported, please
[create a new issue](https://github.com/freqtrade/freqtrade/issues/new/choose) and
ensure you follow the template guide so that the team can assist you as
quickly as possible.

For every [issue](https://github.com/freqtrade/freqtrade/issues/new/choose) created, kindly follow up and mark satisfaction or reminder to close issue when equilibrium ground is reached.

--Maintain github&#039;s [community policy](https://docs.github.com/en/site-policy/github-terms/github-community-code-of-conduct)--

### [Feature Requests](https://github.com/freqtrade/freqtrade/labels/enhancement)

Have you a great idea to improve the bot you want to share? Please,
first search if this feature was not [already discussed](https://github.com/freqtrade/freqtrade/labels/enhancement).
If it hasn&#039;t been requested, please
[create a new request](https://github.com/freqtrade/freqtrade/issues/new/choose)
and ensure you follow the template guide so that it does not get lost
in the bug reports.

### [Pull Requests](https://github.com/freqtrade/freqtrade/pulls)

Feel like the bot is missing a feature? We welcome your pull requests!

Please read the
[Contributing document](https://github.com/freqtrade/freqtrade/blob/develop/CONTRIBUTING.md)
to understand the requirements before sending your pull-requests.

Coding is not a necessity to contribute - maybe start with improving the documentation?
Issues labeled [good first issue](https://github.com/freqtrade/freqtrade/labels/good%20first%20issue) can be good first contributions, and will help get you familiar with the codebase.

**Note** before starting any major new feature work, *please open an issue describing what you are planning to do* or talk to us on [discord](https://discord.gg/p7nuUNVfP7) (please use the #dev channel for this). This will ensure that interested parties can give valuable feedback on the feature, and let others know that you are working on it.

**Important:** Always create your PR against the `develop` branch, not `stable`.

## Requirements

### Up-to-date clock

The clock must be accurate, synchronized to a NTP server very frequently to avoid problems with communication to the exchanges.

### Minimum hardware required

To run this bot we recommend you a cloud instance with a minimum of:

- Minimal (advised) system requirements: 2GB RAM, 1GB disk space, 2vCPU

### Software requirements

- [Python &gt;= 3.11](http://docs.python-guide.org/en/latest/starting/installation/)
- [pip](https://pip.pypa.io/en/stable/installing/)
- [git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)
- [TA-Lib](https://ta-lib.github.io/ta-lib-python/)
- [virtualenv](https://virtualenv.pypa.io/en/stable/installation.html) (Recommended)
- [Docker](https://www.docker.com/products/docker) (Recommended)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>