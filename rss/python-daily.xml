<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Wed, 04 Feb 2026 00:06:05 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[masoncl/review-prompts]]></title>
            <link>https://github.com/masoncl/review-prompts</link>
            <guid>https://github.com/masoncl/review-prompts</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:05 GMT</pubDate>
            <description><![CDATA[AI review prompts]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/masoncl/review-prompts">masoncl/review-prompts</a></h1>
            <p>AI review prompts</p>
            <p>Language: Python</p>
            <p>Stars: 330</p>
            <p>Forks: 32</p>
            <p>Stars today: 54 stars today</p>
            <h2>README</h2><pre># Review Prompts for AI-Assisted Code Review

AI-assisted code review prompts for Linux kernel and systemd development.
Works with Claude Code and other AI tools.

## Quick Start

### Install Kernel Prompts Only

```bash
cd kernel/scripts
./claude-setup.sh
```

### Install systemd Prompts Only

```bash
cd systemd/scripts
./claude-setup.sh
```

### Install Both

```bash
cd kernel/scripts &amp;&amp; ./claude-setup.sh
cd ../systemd/scripts &amp;&amp; ./claude-setup.sh
```

## Available Commands

| Project | Review | Debug | Verify |
|---------|--------|-------|--------|
| Kernel  | `/kreview` | `/kdebug` | `/kverify` |
| systemd | `/systemd-review` | `/systemd-debug` | `/systemd-verify` |

## Project Documentation

- [Kernel Review Prompts](kernel/README.md) - Linux kernel specific patterns and protocols
- [systemd Review Prompts](systemd/README.md) - systemd specific patterns and protocols

## How It Works

Each project has:
- **Skill file** - Automatically loads context when working in the project tree
- **Slash commands** - Quick access to review, debug, and verify workflows
- **Subsystem files** - Domain-specific knowledge loaded on demand

The skills detect your working directory and load appropriate context:
- In a kernel tree: kernel skill loads automatically
- In a systemd tree: systemd skill loads automatically

## Structure

```
review-prompts/
‚îú‚îÄ‚îÄ kernel/                    # Linux kernel prompts
‚îÇ   ‚îú‚îÄ‚îÄ skills/               # Skill template
‚îÇ   ‚îú‚îÄ‚îÄ slash-commands/       # /kreview, /kdebug, /kverify
‚îÇ   ‚îú‚îÄ‚îÄ scripts/              # Setup script and utilities
‚îÇ   ‚îú‚îÄ‚îÄ patterns/             # Bug pattern documentation
‚îÇ   ‚îî‚îÄ‚îÄ *.md                  # Subsystem and protocol files
‚îÇ
‚îú‚îÄ‚îÄ systemd/                   # systemd prompts
‚îÇ   ‚îú‚îÄ‚îÄ skills/               # Skill template
‚îÇ   ‚îú‚îÄ‚îÄ slash-commands/       # /systemd-review, /systemd-debug, /systemd-verify
‚îÇ   ‚îú‚îÄ‚îÄ scripts/              # Setup script
‚îÇ   ‚îú‚îÄ‚îÄ patterns/             # Bug pattern documentation
‚îÇ   ‚îî‚îÄ‚îÄ *.md                  # Subsystem and protocol files
‚îÇ
‚îî‚îÄ‚îÄ README.md                  # This file
```

## Semcode Integration

These prompts work best with [semcode](https://github.com/facebookexperimental/semcode)
for fast code navigation and semantic search.

## License

See [kernel/LICENSE](kernel/LICENSE) for license information.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[openai/skills]]></title>
            <link>https://github.com/openai/skills</link>
            <guid>https://github.com/openai/skills</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:04 GMT</pubDate>
            <description><![CDATA[Skills Catalog for Codex]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/openai/skills">openai/skills</a></h1>
            <p>Skills Catalog for Codex</p>
            <p>Language: Python</p>
            <p>Stars: 2,993</p>
            <p>Forks: 178</p>
            <p>Stars today: 377 stars today</p>
            <h2>README</h2><pre># Agent Skills

Agent Skills are folders of instructions, scripts, and resources that AI agents can discover and use to perform at specific tasks. Write once, use everywhere.

Codex uses skills to help package capabilities that teams and individuals can use to complete specific tasks in a repeatable way. This repository catalogs skills for use and distribution with Codex.

Learn more:
- [Using skills in Codex](https://developers.openai.com/codex/skills)
- [Create custom skills in Codex](https://developers.openai.com/codex/skills/create-skill)
- [Agent Skills open standard](https://agentskills.io)

## Installing a skill

Skills in [`.system`](skills/.system/) are automatically installed in the latest version of Codex.

To install [curated](skills/.curated/) or [experimental](skills/.experimental/) skills, you can use the `$skill-installer` inside Codex.

Curated skills can be installed by name (defaults to `skills/.curated`):

```
$skill-installer gh-address-comments
```

For experimental skills, specify the skill folder. For example:

```
$skill-installer install the create-plan skill from the .experimental folder
```

Or provide the GitHub directory URL:

```
$skill-installer install https://github.com/openai/skills/tree/main/skills/.experimental/create-plan
```

After installing a skill, restart Codex to pick up new skills.

## License

The license of an individual skill can be found directly inside the skill&#039;s directory inside the `LICENSE.txt` file.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[karpathy/nanochat]]></title>
            <link>https://github.com/karpathy/nanochat</link>
            <guid>https://github.com/karpathy/nanochat</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:03 GMT</pubDate>
            <description><![CDATA[The best ChatGPT that $100 can buy.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/karpathy/nanochat">karpathy/nanochat</a></h1>
            <p>The best ChatGPT that $100 can buy.</p>
            <p>Language: Python</p>
            <p>Stars: 42,011</p>
            <p>Forks: 5,426</p>
            <p>Stars today: 447 stars today</p>
            <h2>README</h2><pre># nanochat

![nanochat logo](dev/nanochat.png)
![scaling laws](dev/scaling_laws_jan26.png)

nanochat is the simplest experimental harness for training LLMs. It is designed to run on a single GPU node, the code is minimal/hackable, and it covers all major LLM stages including tokenization, pretraining, finetuning, evaluation, inference, and a chat UI. For example, you can train your own GPT-2 capability LLM (which cost ~$50,000 to train in 2019) for only $73 (3 hours of 8XH100 GPU node) and then talk to it in a familiar ChatGPT-like web UI.

For questions about the repo, I recommend either using [DeepWiki](https://deepwiki.com/karpathy/nanochat) from Devin/Cognition to ask questions about the repo, or use the [Discussions tab](https://github.com/karpathy/nanochat/discussions), or come by the [#nanochat](https://discord.com/channels/1020383067459821711/1427295580895314031) channel on Discord.

## Updates

- (Jan 31 2026) Major revamp of all scripts/README ongoing, deleting midtraining stage, might be a bit messy briefly...
- (Jan 30 2026) With all the latest improvements we&#039;re able to train GPT-2 grade LLM in about $73. The [runs/speedrun.sh](runs/speedrun.sh) script will become the refernece way to train GPT-2 grade model and talk to it.

## Leaderboard

| # | time | val_bpb | CORE | Description | Date | Commit | Contributors |
|---|-------------|---------|------|-------------|------|--------|--------------|
| 0 | 168 hours | - | 0.2565 | Original OpenAI GPT-2 checkpoint | 2019 | - | OpenAI |
| 1 | 3.04 | 0.74833 | 0.2585 | d24 baseline, slightly overtrained | Jan 29 2026 | 348fbb3 | @karpathy |
| 2 | 2.91 | 0.74504 | 0.2578 | d26 slightly undertrained **+fp8** | Feb 2 2026 | 8309b83 | @karpathy |

The primary metric we care about is &quot;time to GPT-2&quot; - the wall clock time needed to outperform the GPT-2 (1.6B) CORE metric on an 8XH100 GPU node. The GPT-2 CORE score is 0.256525. In 2019, the training of GPT-2 cost approximately $50,000 so it is incredible that due to many advances over 7 years across the stack, we can now do so much faster and for well below $100 (e.g. at the current ~$3/GPU/hr, an 8XH100 node is ~$24/hr, so 3 hours is ~$72).

See [dev/LEADERBOARD.md](dev/LEADERBOARD.md) for more docs on how to interpret and contribute to the leaderboard.

## Getting started

### Reproduce and talk to GPT-2

The most fun you can have is to train your own GPT-2 and talk to it. The entire pipeline to do so is contained in the single file [runs/speedrun.sh](runs/speedrun.sh), which is designed to be run on an 8XH100 GPU node. Currently, at ~$24/hour for these nodes, pretraining GPT-2 grade model takes approximately 3 hours and will set you back about $75. Boot up a new 8XH100 GPU box from your favorite provider (e.g. I use and like [Lambda](https://lambda.ai/service/gpu-cloud)), and kick off the training script:

```bash
bash runs/speedrun.sh
```

You mish to do so in a screen session as this will take ~3 hours to run. Once it&#039;s done, you can talk to it via the ChatGPT-like web UI. Make sure again that your local uv virtual environment is active (run `source .venv/bin/activate`), and serve it:

```bash
python -m scripts.chat_web
```

And then visit the URL shown. Make sure to access it correctly, e.g. on Lambda use the public IP of the node you&#039;re on, followed by the port, so for example [http://209.20.xxx.xxx:8000/](http://209.20.xxx.xxx:8000/), etc. Then talk to your LLM as you&#039;d normally talk to ChatGPT! Get it to write stories or poems. Ask it to tell you who you are to see a hallucination. Ask it why the sky is blue. Or why it&#039;s green. The speedrun is a 4e19 FLOPs capability model so it&#039;s a bit like talking to a kindergartener :).

---

&lt;img width=&quot;2672&quot; height=&quot;1520&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/ed39ddf8-2370-437a-bedc-0f39781e76b5&quot; /&gt;

---

A few more notes:

- The code will run just fine on the Ampere 8XA100 GPU node as well, but a bit slower.
- All code will run just fine on even a single GPU by omitting `torchrun`, and will produce ~identical results (code will automatically switch to gradient accumulation), but you&#039;ll have to wait 8 times longer.
- If your GPU(s) have less than 80GB, you&#039;ll have to tune some of the hyperparameters or you will OOM / run out of VRAM. Look for `--device_batch_size` in the scripts and reduce it until things fit. E.g. from 32 (default) to 16, 8, 4, 2, or even 1. Less than that you&#039;ll have to know a bit more what you&#039;re doing and get more creative.
- Most of the code is fairly vanilla PyTorch so it should run on anything that supports that - xpu, mps, or etc, but I haven&#039;t personally exercised all of these code paths so there might be sharp edges.

## Research

If you are a researcher and wish to help improve nanochat, two scripts of interest are [runs/scaling_laws.sh](runs/scaling_laws.sh) and [runs/miniseries.sh](runs/miniseries.sh). See [Jan 7 miniseries v1](https://github.com/karpathy/nanochat/discussions/420) for related documentation. For quick experimentation (~5 min pretraining runs) my favorite scale is to train a 12-layer model (GPT-1 sized), e.g. like this:

```
OMP_NUM_THREADS=1 torchrun --standalone --nproc_per_node=8 -m scripts.base_train -- \
    --depth=12 \
    --run=&quot;d12&quot; \
    --model-tag=&quot;d12&quot; \
    --core-metric-every=999999 \
    --sample-every=-1 \
    --save-every=-1 \
```

This uses wandb (run name &quot;d12&quot;), only runs the CORE metric on last step, and it doesn&#039;t sample and save intermediate checkpoints. I like to change something in the code, re-run a d12 (or a d16 etc) and see if it helped, in an iteration loop.

The overall approach is to treat the depth of the model as the single dial of complexity. By sweeping out the depth, we get increasingly more powerful models. We determine the scaling laws, set the data budget to a compute optimal setting, train a whole miniseries of models of increasing sizes, and compare them to the GPT-2 and GPT-3 miniseries. Right now, beating GPT-2 specifically faster and faster is the most interesting target.

## Running on CPU / MPS

The script [runs/runcpu.sh](runs/runcpu.sh) shows a very simple example of running on CPU or Apple Silicon. It dramatically shrinks the LLM tha tis being trained to make things fit into a reasonable time interval of a few ten minutes of training. You will not get strong results in this way.

## Guides

I&#039;ve published a number of guides that might contain helpful information:

- [Oct 13 2025 original nanochat post](https://github.com/karpathy/nanochat/discussions/1) introducing nanochat, though now it contains some deprecated information and the model is a lot older (with worse results) than current master.
- [Jan 7 miniseries v1](https://github.com/karpathy/nanochat/discussions/420) documents the first nanochat miniseries of models.
- To customize your nanochat, see [Guide: infusing identity to your nanochat](https://github.com/karpathy/nanochat/discussions/139) in Discussions, which describes how you can tune your nanochat&#039;s personality through synthetic data generation and mixing that data into the SFT stage.
- To add new abilities to nanochat, see [Guide: counting r in strawberry (and how to add abilities generally)](https://github.com/karpathy/nanochat/discussions/164).

## File structure

```
.
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ dev
‚îÇ   ‚îú‚îÄ‚îÄ gen_synthetic_data.py       # Example synthetic data for identity
‚îÇ   ‚îú‚îÄ‚îÄ generate_logo.html
‚îÇ   ‚îú‚îÄ‚îÄ nanochat.png
‚îÇ   ‚îî‚îÄ‚îÄ repackage_data_reference.py # Pretraining data shard generation
‚îú‚îÄ‚îÄ nanochat
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                 # empty
‚îÇ   ‚îú‚îÄ‚îÄ checkpoint_manager.py       # Save/Load model checkpoints
‚îÇ   ‚îú‚îÄ‚îÄ common.py                   # Misc small utilities, quality of life
‚îÇ   ‚îú‚îÄ‚îÄ core_eval.py                # Evaluates base model CORE score (DCLM paper)
‚îÇ   ‚îú‚îÄ‚îÄ dataloader.py               # Tokenizing Distributed Data Loader
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py                  # Download/read utils for pretraining data
‚îÇ   ‚îú‚îÄ‚îÄ engine.py                   # Efficient model inference with KV Cache
‚îÇ   ‚îú‚îÄ‚îÄ execution.py                # Allows the LLM to execute Python code as tool
‚îÇ   ‚îú‚îÄ‚îÄ gpt.py                      # The GPT nn.Module Transformer
‚îÇ   ‚îú‚îÄ‚îÄ logo.svg
‚îÇ   ‚îú‚îÄ‚îÄ loss_eval.py                # Evaluate bits per byte (instead of loss)
‚îÇ   ‚îú‚îÄ‚îÄ optim.py                    # AdamW + Muon optimizer, 1GPU and distributed
‚îÇ   ‚îú‚îÄ‚îÄ report.py                   # Utilities for writing the nanochat Report
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer.py                # BPE Tokenizer wrapper in style of GPT-4
‚îÇ   ‚îî‚îÄ‚îÄ ui.html                     # HTML/CSS/JS for nanochat frontend
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ runs
‚îÇ   ‚îú‚îÄ‚îÄ miniseries.sh               # Miniseries training script
‚îÇ   ‚îú‚îÄ‚îÄ runcpu.sh                   # Small example of how to run on CPU/MPS
‚îÇ   ‚îú‚îÄ‚îÄ scaling_laws.sh             # Scaling laws experiments
‚îÇ   ‚îî‚îÄ‚îÄ speedrun.sh                 # Train the ~$100 nanochat d20
‚îú‚îÄ‚îÄ scripts
‚îÇ   ‚îú‚îÄ‚îÄ base_eval.py                # Base model: CORE score, bits per byte, samples
‚îÇ   ‚îú‚îÄ‚îÄ base_train.py               # Base model: train
‚îÇ   ‚îú‚îÄ‚îÄ chat_cli.py                 # Chat model: talk to over CLI
‚îÇ   ‚îú‚îÄ‚îÄ chat_eval.py                # Chat model: eval tasks
‚îÇ   ‚îú‚îÄ‚îÄ chat_rl.py                  # Chat model: reinforcement learning
‚îÇ   ‚îú‚îÄ‚îÄ chat_sft.py                 # Chat model: train SFT
‚îÇ   ‚îú‚îÄ‚îÄ chat_web.py                 # Chat model: talk to over WebUI
‚îÇ   ‚îú‚îÄ‚îÄ tok_eval.py                 # Tokenizer: evaluate compression rate
‚îÇ   ‚îî‚îÄ‚îÄ tok_train.py                # Tokenizer: train it
‚îú‚îÄ‚îÄ tasks
‚îÇ   ‚îú‚îÄ‚îÄ arc.py                      # Multiple choice science questions
‚îÇ   ‚îú‚îÄ‚îÄ common.py                   # TaskMixture | TaskSequence
‚îÇ   ‚îú‚îÄ‚îÄ customjson.py               # Make Task from arbitrary jsonl convos
‚îÇ   ‚îú‚îÄ‚îÄ gsm8k.py                    # 8K Grade School Math questions
‚îÇ   ‚îú‚îÄ‚îÄ humaneval.py                # Misnomer; Simple Python coding task
‚îÇ   ‚îú‚îÄ‚îÄ mmlu.py                     # Multiple choice questions, broad topics
‚îÇ   ‚îú‚îÄ‚îÄ smoltalk.py                 # Conglomerate dataset of SmolTalk from HF
‚îÇ   ‚îî‚îÄ‚îÄ spellingbee.py              # Task teaching model to spell/count letters
‚îú‚îÄ‚îÄ tests
‚îÇ   ‚îî‚îÄ‚îÄ test_engine.py
‚îî‚îÄ‚îÄ uv.lock
```

## Contributing

The goal of nanochat is to improve the state of the art in micro models that are accessible to work with end to end on budgets of &lt; $1000 dollars. Accessibility is about overall cost but also about cognitive complexity - nanochat is not an exhaustively configurable LLM &quot;framework&quot;; there are no giant configuration objects, model factories, or if-then-else monsters in the code base. It is a single, cohesive, minimal, readable, hackable, maximally-forkable &quot;strong baseline&quot; codebase designed to run start to end and produce a ChatGPT model you can talk to. Currently, the most interesting part personally is speeding up the latency to GPT-2 (i.e. getting a CORE score above 0.256525). Currently this takes ~3 hours, but by improving the pretraining stage we can improve this further.

Current AI policy: disclosure. When submitting a PR, please declare any parts that had substantial LLM contribution and that you have not written or that you do not fully understand.

## Acknowledgements

- The name (nanochat) derives from my earlier project [nanoGPT](https://github.com/karpathy/nanoGPT), which only covered pretraining.
- nanochat is also inspired by [modded-nanoGPT](https://github.com/KellerJordan/modded-nanogpt), which gamified the nanoGPT repo with clear metrics and a leaderboard, and borrows a lot of its ideas and some implementation for pretraining.
- Thank you to [HuggingFace](https://huggingface.co/) for fineweb and smoltalk.
- Thank you [Lambda](https://lambda.ai/service/gpu-cloud) for the compute used in developing this project.
- Thank you to chief LLM whisperer üßô‚Äç‚ôÇÔ∏è Alec Radford for advice/guidance.
- Thank you to the repo czar Sofie [@svlandeg](https://github.com/svlandeg) for help with managing issues, pull requests and discussions of nanochat.

## Cite

If you find nanochat helpful in your research cite simply as:

```bibtex
@misc{nanochat,
  author = {Andrej Karpathy},
  title = {nanochat: The best ChatGPT that \$100 can buy},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/karpathy/nanochat}
}
```

## License

MIT
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[kovidgoyal/calibre]]></title>
            <link>https://github.com/kovidgoyal/calibre</link>
            <guid>https://github.com/kovidgoyal/calibre</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:02 GMT</pubDate>
            <description><![CDATA[The official source code repository for the calibre ebook manager]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/kovidgoyal/calibre">kovidgoyal/calibre</a></h1>
            <p>The official source code repository for the calibre ebook manager</p>
            <p>Language: Python</p>
            <p>Stars: 23,923</p>
            <p>Forks: 2,547</p>
            <p>Stars today: 141 stars today</p>
            <h2>README</h2><pre># calibre

&lt;img align=&quot;left&quot; src=&quot;https://raw.githubusercontent.com/kovidgoyal/calibre/master/resources/images/lt.png&quot; height=&quot;200&quot; width=&quot;200&quot;/&gt;

calibre is an e-book manager. It can view, convert, edit and catalog e-books 
in all of the major e-book formats. It can also talk to e-book reader 
devices. It can go out to the internet and fetch metadata for your books. 
It can download newspapers and convert them into e-books for convenient 
reading. It is cross platform, running on Linux, Windows and macOS.

For more information, see the [calibre About page](https://calibre-ebook.com/about).

[![Build Status](https://github.com/kovidgoyal/calibre/workflows/CI/badge.svg)](https://github.com/kovidgoyal/calibre/actions?query=workflow%3ACI)

## Screenshots  

[Screenshots page](https://calibre-ebook.com/demo)

## Usage

See the [User Manual](https://manual.calibre-ebook.com).

## Development

[Setting up a development environment for calibre](https://manual.calibre-ebook.com/develop.html).

A [tarball of the source code](https://calibre-ebook.com/dist/src) for the 
current calibre release.

## Bugs

Bug reports and feature requests should be made in the calibre bug tracker at [Launchpad](https://bugs.launchpad.net/calibre).
GitHub is only used for code hosting and pull requests.

## Support calibre

calibre is a result of the efforts of many volunteers from all over the world.
If you find it useful, please consider contributing to support its development.
[Donate to support calibre development](https://calibre-ebook.com/donate).

## Building calibre binaries

See [Build instructions](bypy/README.rst) for instructions on how to build the
calibre binaries and installers for all the platforms calibre supports.

## calibre package versions in various repositories

[![Packaging Status](https://repology.org/badge/vertical-allrepos/calibre.svg?columns=3&amp;header=calibre)](https://repology.org/project/calibre/versions)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OpenBMB/ChatDev]]></title>
            <link>https://github.com/OpenBMB/ChatDev</link>
            <guid>https://github.com/OpenBMB/ChatDev</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:01 GMT</pubDate>
            <description><![CDATA[ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBMB/ChatDev">OpenBMB/ChatDev</a></h1>
            <p>ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration</p>
            <p>Language: Python</p>
            <p>Stars: 29,769</p>
            <p>Forks: 3,686</p>
            <p>Stars today: 476 stars today</p>
            <h2>README</h2><pre># ChatDev 2.0 - DevAll

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;frontend/public/media/logo.png&quot; alt=&quot;DevAll Logo&quot; width=&quot;500&quot;/&gt;
&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;A Zero-Code Multi-Agent Platform for Developing Everything&lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  „Äê&lt;a href=&quot;./README.md&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;./README-zh.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;„Äë
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    „Äêüìö &lt;a href=&quot;#developers&quot;&gt;Developers&lt;/a&gt; | üë• &lt;a href=&quot;#primary-contributors&quot;&gt;Contributors&lt;/a&gt;ÔΩú‚≠êÔ∏è &lt;a href=&quot;https://github.com/OpenBMB/ChatDev/tree/chatdev1.0&quot;&gt;ChatDev 1.0 (Legacy)&lt;/a&gt;„Äë
&lt;/p&gt;

## üìñ Overview
ChatDev has evolved from a specialized software development multi-agent system into a comprehensive multi-agent orchestration platform.

- &lt;a href=&quot;https://github.com/OpenBMB/ChatDev/tree/main&quot;&gt;**ChatDev 2.0 (DevAll)**&lt;/a&gt; is a **Zero-Code Multi-Agent Platform** for &quot;Developing Everything&quot;. It empowers users to rapidly build and execute customized multi-agent systems through simple configuration. No coding is required‚Äîusers can define agents, workflows, and tasks to orchestrate complex scenarios such as data visualization, 3D generation, and deep research.
- &lt;a href=&quot;https://github.com/OpenBMB/ChatDev/tree/chatdev1.0&quot;&gt;**ChatDev 1.0 (Legacy)**&lt;/a&gt; operates as a **Virtual Software Company**. It utilizes various intelligent agents (e.g., CEO, CTO, Programmer) participating in specialized functional seminars to automate the entire software development life cycle‚Äîincluding designing, coding, testing, and documenting. It serves as the foundational paradigm for communicative agent collaboration.

## üéâ News
‚Ä¢ **Jan 07, 2026: üöÄ We are excited to announce the official release of ChatDev 2.0 (DevAll)!** This version introduces a zero-code multi-agent orchestration platform. The classic ChatDev (v1.x) has been moved to the [`chatdev1.0`](https://github.com/OpenBMB/ChatDev/tree/chatdev1.0) branch for maintenance. More details about ChatDev 2.0 can be found on [our official post](https://x.com/OpenBMB/status/2008916790399701335).

&lt;details&gt;
&lt;summary&gt;Old News&lt;/summary&gt;

‚Ä¢Sep 24, 2025: üéâ Our paper [Multi-Agent Collaboration via Evolving Orchestration](https://arxiv.org/abs/2505.19591) has been accepted to NeurIPS 2025. The implementation is available in the `puppeteer` branch of this repository.

‚Ä¢May 26, 2025: üéâ We propose a novel puppeteer-style paradigm for multi-agent collaboration among large language model based agents. By leveraging a learnable central orchestrator optimized with reinforcement learning, our method dynamically activates and sequences agents to construct efficient, context-aware reasoning paths. This approach not only improves reasoning quality but also reduces computational costs, enabling scalable and adaptable multi-agent cooperation in complex tasks.
See our paper in [Multi-Agent Collaboration via Evolving Orchestration](https://arxiv.org/abs/2505.19591).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/puppeteer.png&#039; width=800&gt;
  &lt;/p&gt;

‚Ä¢June 25, 2024: üéâTo foster development in LLM-powered multi-agent collaborationü§ñü§ñ and related fields, the ChatDev team has curated a collection of seminal papersüìÑ presented in a [open-source](https://github.com/OpenBMB/ChatDev/tree/main/MultiAgentEbook) interactive e-booküìö format. Now you can explore the latest advancements on the [Ebook Website](https://thinkwee.top/multiagent_ebook) and download the [paper list](https://github.com/OpenBMB/ChatDev/blob/main/MultiAgentEbook/papers.csv).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/ebook.png&#039; width=800&gt;
  &lt;/p&gt;
  
‚Ä¢June 12, 2024: We introduced Multi-Agent Collaboration Networks (MacNet) üéâ, which utilize directed acyclic graphs to facilitate effective task-oriented collaboration among agents through linguistic interactions ü§ñü§ñ. MacNet supports co-operation across various topologies and among more than a thousand agents without exceeding context limits. More versatile and scalable, MacNet can be considered as a more advanced version of ChatDev&#039;s chain-shaped topology. Our preprint paper is available at [https://arxiv.org/abs/2406.07155](https://arxiv.org/abs/2406.07155). This technique has been incorporated into the [macnet](https://github.com/OpenBMB/ChatDev/tree/macnet) branch, enhancing support for diverse organizational structures and offering richer solutions beyond software development (e.g., logical reasoning, data analysis, story generation, and more).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/macnet.png&#039; width=500&gt;
  &lt;/p&gt;

‚Ä¢ May 07, 2024, we introduced &quot;Iterative Experience Refinement&quot; (IER), a novel method where instructor and assistant agents enhance shortcut-oriented experiences to efficiently adapt to new tasks. This approach encompasses experience acquisition, utilization, propagation and elimination across a series of tasks and making the pricess shorter and efficient. Our preprint paper is available at https://arxiv.org/abs/2405.04219, and this technique will soon be incorporated into ChatDev.
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/ier.png&#039; width=220&gt;
  &lt;/p&gt;

‚Ä¢ January 25, 2024: We have integrated Experiential Co-Learning Module into ChatDev. Please see the [Experiential Co-Learning Guide](wiki.md#co-tracking).

‚Ä¢ December 28, 2023: We present Experiential Co-Learning, an innovative approach where instructor and assistant agents accumulate shortcut-oriented experiences to effectively solve new tasks, reducing repetitive errors and enhancing efficiency.  Check out our preprint paper at https://arxiv.org/abs/2312.17025 and this technique will soon be integrated into ChatDev.
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/ecl.png&#039; width=860&gt;
  &lt;/p&gt;
‚Ä¢ November 15, 2023: We launched ChatDev as a SaaS platform that enables software developers and innovative entrepreneurs to build software efficiently at a very low cost and remove the barrier to entry. Try it out at https://chatdev.modelbest.cn/.
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/saas.png&#039; width=560&gt;
  &lt;/p&gt;

‚Ä¢ November 2, 2023: ChatDev is now supported with a new feature: incremental development, which allows agents to develop upon existing codes. Try ```--config &quot;incremental&quot; --path &quot;[source_code_directory_path]&quot;``` to start it.
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/increment.png&#039; width=700&gt;
  &lt;/p&gt;

‚Ä¢ October 26, 2023: ChatDev is now supported with Docker for safe execution (thanks to contribution from [ManindraDeMel](https://github.com/ManindraDeMel)). Please see [Docker Start Guide](wiki.md#docker-start).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/docker.png&#039; width=400&gt;
  &lt;/p&gt;
  
‚Ä¢ September 25, 2023: The **Git** mode is now available, enabling the programmer &lt;img src=&#039;visualizer/static/figures/programmer.png&#039; height=20&gt; to utilize Git for version control. To enable this feature, simply set ``&quot;git_management&quot;`` to ``&quot;True&quot;`` in ``ChatChainConfig.json``. See [guide](wiki.md#git-mode).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/github.png&#039; width=600&gt;
  &lt;/p&gt;

‚Ä¢ September 20, 2023: The **Human-Agent-Interaction** mode is now available! You can get involved with the ChatDev team by playing the role of reviewer &lt;img src=&#039;visualizer/static/figures/reviewer.png&#039; height=20&gt; and making suggestions to the programmer &lt;img src=&#039;visualizer/static/figures/programmer.png&#039; height=20&gt;;
  try ``python3 run.py --task [description_of_your_idea] --config &quot;Human&quot;``. See [guide](wiki.md#human-agent-interaction) and [example](WareHouse/Gomoku_HumanAgentInteraction_20230920135038).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/Human_intro.png&#039; width=600&gt;
  &lt;/p&gt;

‚Ä¢ September 1, 2023: The **Art** mode is available now! You can activate the designer agent &lt;img src=&#039;visualizer/static/figures/designer.png&#039; height=20&gt; to generate images used in the software;
  try ``python3 run.py --task [description_of_your_idea] --config &quot;Art&quot;``. See [guide](wiki.md#art) and [example](WareHouse/gomokugameArtExample_THUNLP_20230831122822).
  
‚Ä¢ August 28, 2023: The system is publicly available.

‚Ä¢ August 17, 2023: The v1.0.0 version was ready for release.

‚Ä¢ July 30, 2023: Users can customize ChatChain, Phasea and Role settings. Additionally, both online Log mode and replay
  mode are now supported.

‚Ä¢ July 16, 2023: The [preprint paper](https://arxiv.org/abs/2307.07924) associated with this project was published.

‚Ä¢ June 30, 2023: The initial version of the ChatDev repository was released.
&lt;/details&gt;


## üöÄ Quick Start

### üìã Prerequisites

*   **OS**: macOS / Linux / WSL / Windows
*   **Python**: 3.12+
*   **Node.js**: 18+
*   **Package Manager**: [uv](https://docs.astral.sh/uv/)

### üì¶ Installation

1.  **Backend Dependencies** (Python managed by `uv`):
    ```bash
    uv sync
    ```

2.  **Frontend Dependencies** (Vite + Vue 3):
    ```bash
    cd frontend &amp;&amp; npm install
    ```

### ‚ö°Ô∏è Run the Application

1.  **Start Backend** :
    ```bash
    # Run from the project root
    uv run python server_main.py --port 6400 --reload
    ```
    &gt; Remove `--reload` if output files (e.g., GameDev) trigger restarts, which interrupts tasks and loses progress.

2.  **Start Frontend**:
    ```bash
    cd frontend
    VITE_API_BASE_URL=http://localhost:6400 npm run dev
    ```
    &gt; Then access the Web Console at **[http://localhost:5173](http://localhost:5173)**. 
    
    
    &gt; **üí° Tip**: If the frontend fails to connect to the backend, the default port `6400` may already be occupied.
    &gt; Please switch both services to an available port, for example:
    &gt;
    &gt; * **Backend**: start with `--port 6401`
    &gt; * **Frontend**: set `VITE_API_BASE_URL=http://localhost:6401`


### üîë Configuration

*   **Environment Variables**: Create a `.env` file in the project root.
*   **Model Keys**: Set `API_KEY` and `BASE_URL` in `.env` for your LLM provider.
*   **YAML placeholders**: Use `${VAR}`Ôºàe.g., `${API_KEY}`Ôºâin configuration files to reference these variables.

---

## üí° How to Use

### üñ•Ô∏è Web Console

The DevAll interface provides a seamless experience for both construction and execution

*   **Tutorial**: Comprehensive step-by-step guides and documentation integrated directly into the platform to help you get started quickly.
&lt;img src=&quot;assets/tutorial-en.png&quot;/&gt; 

*   **Workflow**: A visual canvas to design your multi-agent systems. Configure node parameters, define context flows, and orchestrate complex agent interactions with drag-and-drop ease.
&lt;img src=&quot;assets/workflow.gif&quot;/&gt;

*   **Launch**: Initiate workflows, monitor real-time logs, inspect intermediate artifacts, and provide human-in-the-loop feedback.
&lt;img src=&quot;assets/launch.gif&quot;/&gt;

### üß∞ Python SDK
For automation and batch processing, use our lightweight Python SDK to execute workflows programmatically and retrieve results directly.

```python
from runtime.sdk import run_workflow

# Execute a workflow and get the final node message
result = run_workflow(
    yaml_file=&quot;yaml_instance/demo.yaml&quot;,
    task_prompt=&quot;Summarize the attached document in one sentence.&quot;,
    attachments=[&quot;/path/to/document.pdf&quot;],
    variables={&quot;API_KEY&quot;: &quot;sk-xxxx&quot;} # Override .env variables if needed
)

if result.final_message:
    print(f&quot;Output: {result.final_message.text_content()}&quot;)
```

---

&lt;a id=&quot;developers&quot;&gt;&lt;/a&gt;
## ‚öôÔ∏è For Developers

**For secondary development and extensions, please proceed with this section.**

Extend DevAll with new nodes, providers, and tools.
The project is organized into a modular structure:
*   **Core Systems**: `server/` hosts the FastAPI backend, while `runtime/` manages agent abstraction and tool execution.
*   **Orchestration**: `workflow/` handles the multi-agent logic, driven by configurations in `entity/`.
*   **Frontend**: `frontend/` contains the Vue 3 Web Console.
*   **Extensibility**: `functions/` is the place for custom Python tools.

Relevant reference documentation:
*   **Getting Started**: [Start Guide](./docs/user_guide/en/index.md)
*   **Core Modules**: [Workflow Authoring](./docs/user_guide/en/workflow_authoring.md), [Memory](./docs/user_guide/en/modules/memory.md), and [Tooling](./docs/user_guide/en/modules/tooling/index.md)

---

## üåü Featured Workflows
We provide robust, out-of-the-box templates for common scenarios. All runnable workflow configs are located in `yaml_instance/`.
*   **Demos**: Files named `demo_*.yaml` showcase specific features or modules.
*   **Implementations**: Files named directly (e.g., `ChatDev_v1.yaml`) are full in-house or recreated workflows. As follows:

### üìã Workflow Collection

| Category | Workflow                                                                                                    | Case | 
| :--- |:------------------------------------------------------------------------------------------------------------| :--- | 
| **üìà Data Visualization** | `data_visualization_basic.yaml`&lt;br&gt;`data_visualization_enhanced.yaml`                                       | &lt;img src=&quot;assets/cases/data_analysis/data_analysis.gif&quot; width=&quot;100%&quot;&gt;&lt;br&gt;Prompt: *&quot;Create 4‚Äì6 high-quality PNG charts for my large real-estate transactions dataset.&quot;* |
| **üõ†Ô∏è 3D Generation**&lt;br&gt;*(Requires [Blender](https://www.blender.org/) &amp; [blender-mcp](https://github.com/ahujasid/blender-mcp))* | `blender_3d_builder_simple.yaml`&lt;br&gt;`blender_3d_builder_hub.yaml`&lt;br&gt;`blender_scientific_illustration.yaml` | &lt;img src=&quot;assets/cases/3d_generation/3d.gif&quot; width=&quot;100%&quot;&gt;&lt;br&gt;Prompt: *&quot;Please build a Christmas tree.&quot;* |
| **üéÆ Game Dev** | `GameDev_v1.yaml`&lt;br&gt;`ChatDev_v1.yaml`                                                                      | &lt;img src=&quot;assets/cases/game_development/game.gif&quot; width=&quot;100%&quot;&gt;&lt;br&gt;Prompt: *&quot;Please help me design and develop a Tank Battle game.&quot;* |
| **üìö Deep Research** | `deep_research_v1.yaml`                                                                                     | &lt;img src=&quot;assets/cases/deep_research/deep_research.gif&quot; width=&quot;85%&quot;&gt;&lt;br&gt;Prompt: *&quot;Research about recent advances in the field of LLM-based agent RL&quot;* |
| **üéì Teach Video** | `teach_video.yaml` (Please run command `uv add manim` before running this workflow)                         | &lt;img src=&quot;assets/cases/video_generation/video.gif&quot; width=&quot;140%&quot;&gt;&lt;br&gt;Prompt: *&quot;ËÆ≤‰∏Ä‰∏ã‰ªÄ‰πàÊòØÂá∏‰ºòÂåñ&quot;* |

---

### üí° Usage Guide
For those implementations, you can use the **Launch** tab to execute them.
1.  **Select**: Choose a workflow in the **Launch** tab.
2.  **Upload**: Upload necessary files (e.g., `.csv` for data analysis) if required.
3.  **Prompt**: Enter your request (e.g., *&quot;Visualize the sales trends&quot;* or *&quot;Design a snake game&quot;*).

---

## ü§ù Contributing

We welcome contributions from the community! Whether you&#039;re fixing bugs, adding new workflow templates, or sharing high-quality cases/artifacts produced by DevAll, your help is much appreciated. Feel free to contribute by submitting **Issues** or **Pull Requests**.

By contributing to DevAll, you&#039;ll be recognized in our **Contributors** list below. Check out our [Developer Guide](#developers) to get started!

### üë• Contributors

#### Primary Contributors

&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/NA-Wen&quot;&gt;&lt;img src=&quot;https://github.com/NA-Wen.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;NA-Wen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/zxrys&quot;&gt;&lt;img src=&quot;https://github.com/zxrys.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;zxrys&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/swugi&quot;&gt;&lt;img src=&quot;https://github.com/swugi.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;swugi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/huatl98&quot;&gt;&lt;img src=&quot;https://github.com/huatl98.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;huatl98&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

#### Contributors
&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/shiowen&quot;&gt;&lt;img src=&quot;https://github.com/shiowen.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shiowen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/kilo2127&quot;&gt;&lt;img src=&quot;https://github.com/kilo2127.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;kilo2127&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/AckerlyLau&quot;&gt;&lt;img src=&quot;https://github.com/AckerlyLau.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;AckerlyLau&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/table&gt;

## ü§ù Acknowledgments

&lt;a href=&quot;http://nlp.csai.tsinghua.edu.cn/&quot;&gt;&lt;img src=&quot;assets/thunlp.png&quot; height=50pt&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://modelbest.cn/&quot;&gt;&lt;img src=&quot;assets/modelbest.png&quot; height=50pt&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/OpenBMB/AgentVerse/&quot;&gt;&lt;img src=&quot;assets/agentverse.png&quot; height=50pt&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/OpenBMB/RepoAgent&quot;&gt;&lt;img src=&quot;assets/repoagent.png&quot;  height=50pt&gt;&lt;/a&gt;
&lt;a href=&quot;https://app.commanddash.io/agent?github=https://github.com/OpenBMB/ChatDev&quot;&gt;&lt;img src=&quot;assets/CommandDash.png&quot; height=50pt&gt;&lt;/a&gt;
&lt;a href=&quot;www.teachmaster.cn&quot;&gt;&lt;img src=&quot;assets/teachmaster.png&quot; height=50pt&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/OpenBMB/AppCopilot&quot;&gt;&lt;img src=&quot;assets/appcopilot.png&quot; height=50pt&gt;&lt;/a&gt;

## üîé Citation

```
@article{chatdev,
    title = {ChatDev: Communicative Agents for Software Development},
    author = {Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2307.07924},
    url = {https://arxiv.org/abs/2307.07924},
    year = {2023}
}

@article{colearning,
    title = {Experiential Co-Learning of Software-Developing Agents},
    author = {Chen Qian and Yufan Dang and Jiahao Li and Wei Liu and Zihao Xie and Yifei Wang and Weize Chen and Cheng Yang and Xin Cong and Xiaoyin Che and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2312.17025},
    url = {https://arxiv.org/abs/2312.17025},
    year = {2023}
}

@article{macnet,
    title={Scaling Large-Language-Model-based Multi-Agent Collaboration},
    author={Chen Qian and Zihao Xie and Yifei Wang and Wei Liu and Yufan Dang and Zhuoyun Du and Weize Chen and Cheng Yang and Zhiyuan Liu and Maosong Sun}
    journal={arXiv preprint arXiv:2406.07155},
    url = {https://arxiv.org/abs/2406.07155},
    year={2024}
}

@article{iagents,
    title={Autonomous Agents for Collaborative Task under Information Asymmetry},
    author={Wei Liu and Chenxi Wang and Yifei Wang and Zihao Xie and Rennai Qiu and Yufan Dnag and Zhuoyun Du and Weize Chen and Cheng Yang and Chen Qian},
    journal={arXiv preprint arXiv:2406.14928},
    url = {https://arxiv.org/abs/2406.14928},
    year={2024}
}

@article{puppeteer,
      title={Multi-Agent Collaboration via Evolving Orchestration}, 
      author={Yufan Dang and Chen Qian and Xueheng Luo and Jingru Fan and Zihao Xie and Ruijie Shi and Weize Chen and Cheng Yang and Xiaoyin Che and Ye Tian and Xuantang Xiong and Lei Han and Zhiyuan Liu and Maosong Sun},
      journal={arXiv preprint arXiv:2505.19591},
      url={https://arxiv.org/abs/2505.19591},
      year={2025}
}
```

## üì¨ Contact

If you have any questions, feedback, or would like to get in touch, please feel free to reach out to us via email at [qianc62@gmail.com](mailto:qianc62@gmail.com)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[EbookFoundation/free-programming-books]]></title>
            <link>https://github.com/EbookFoundation/free-programming-books</link>
            <guid>https://github.com/EbookFoundation/free-programming-books</guid>
            <pubDate>Wed, 04 Feb 2026 00:06:00 GMT</pubDate>
            <description><![CDATA[üìö Freely available programming books]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/EbookFoundation/free-programming-books">EbookFoundation/free-programming-books</a></h1>
            <p>üìö Freely available programming books</p>
            <p>Language: Python</p>
            <p>Stars: 382,014</p>
            <p>Forks: 65,894</p>
            <p>Stars today: 115 stars today</p>
            <h2>README</h2><pre># List of Free Learning Resources In Many Languages

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome)&amp;#160;
[![License: CC BY 4.0](https://img.shields.io/github/license/EbookFoundation/free-programming-books)](https://creativecommons.org/licenses/by/4.0/)&amp;#160;
[![Hacktoberfest 2025 stats](https://img.shields.io/github/hacktoberfest/2025/EbookFoundation/free-programming-books?label=Hacktoberfest+2025)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged+created%3A2025-10-01..2025-10-31)

&lt;/div&gt;

Search the list at [https://ebookfoundation.github.io/free-programming-books-search/](https://ebookfoundation.github.io/free-programming-books-search/) [![https://ebookfoundation.github.io/free-programming-books-search/](https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Dynamic%20search%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books-search%2F)](https://ebookfoundation.github.io/free-programming-books-search/).

This page is available as an easy-to-read website. Access it by clicking on [![https://ebookfoundation.github.io/free-programming-books/](https://img.shields.io/website?style=flat&amp;logo=www&amp;logoColor=whitesmoke&amp;label=Static%20site&amp;down_color=red&amp;down_message=down&amp;up_color=green&amp;up_message=up&amp;url=https%3A%2F%2Febookfoundation.github.io%2Ffree-programming-books%2F)](https://ebookfoundation.github.io/free-programming-books/).

&lt;div align=&quot;center&quot;&gt;
  &lt;form action=&quot;https://ebookfoundation.github.io/free-programming-books-search&quot;&gt;
    &lt;input type=&quot;text&quot; id=&quot;fpbSearch&quot; name=&quot;search&quot; required placeholder=&quot;Search Book or Author&quot;/&gt;
    &lt;label for=&quot;submit&quot;&gt; &lt;/label&gt;
    &lt;input type=&quot;submit&quot; id=&quot;submit&quot; name=&quot;submit&quot; value=&quot;Search&quot; /&gt;
  &lt;/form&gt;
&lt;/div&gt;

## Intro

This list was originally a clone of [StackOverflow - List of Freely Available Programming Books](https://web.archive.org/web/20140606191453/http://stackoverflow.com/questions/194812/list-of-freely-available-programming-books/392926) with contributions from Karan Bhangui and George Stocker.

The list was moved to GitHub by Victor Felder for collaborative updating and maintenance. It has grown to become one of [GitHub&#039;s most popular repositories](https://octoverse.github.com/).

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![GitHub repo forks](https://img.shields.io/github/forks/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Forks)](https://github.com/EbookFoundation/free-programming-books/network)&amp;#160;
[![GitHub repo stars](https://img.shields.io/github/stars/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Stars)](https://github.com/EbookFoundation/free-programming-books/stargazers)&amp;#160;
[![GitHub repo contributors](https://img.shields.io/github/contributors-anon/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Contributors)](https://github.com/EbookFoundation/free-programming-books/graphs/contributors)    
[![GitHub org sponsors](https://img.shields.io/github/sponsors/EbookFoundation?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Sponsors)](https://github.com/sponsors/EbookFoundation)&amp;#160;
[![GitHub repo watchers](https://img.shields.io/github/watchers/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Watchers)](https://github.com/EbookFoundation/free-programming-books/watchers)&amp;#160;
[![GitHub repo size](https://img.shields.io/github/repo-size/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=whitesmoke&amp;label=Repo%20Size)](https://github.com/EbookFoundation/free-programming-books/archive/refs/heads/main.zip)

&lt;/div&gt;

The [Free Ebook Foundation](https://ebookfoundation.org) now administers the repo, a not-for-profit organization devoted to promoting the creation, distribution, archiving, and sustainability of free ebooks. [Donations](https://ebookfoundation.org/contributions.html) to the Free Ebook Foundation are tax-deductible in the US.


## How To Contribute

Please read [CONTRIBUTING](docs/CONTRIBUTING.md). If you&#039;re new to GitHub, [welcome](docs/HOWTO.md)! Remember to abide by our adapted from ![Contributor Covenant 1.3](https://img.shields.io/badge/Contributor%20Covenant-1.3-4baaaa.svg) [Code of Conduct](docs/CODE_OF_CONDUCT.md) too ([translations](#translations) also available).

Click on these badges to see how you might be able to help:

&lt;div align=&quot;center&quot; markdown=&quot;1&quot;&gt;

[![GitHub repo Issues](https://img.shields.io/github/issues/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=red&amp;label=Issues)](https://github.com/EbookFoundation/free-programming-books/issues)&amp;#160;
[![GitHub repo Good Issues for newbies](https://img.shields.io/github/issues/EbookFoundation/free-programming-books/good%20first%20issue?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Good%20First%20issues)](https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22)&amp;#160;
[![GitHub Help Wanted issues](https://img.shields.io/github/issues/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20issues)](https://github.com/EbookFoundation/free-programming-books/issues?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)    
[![GitHub repo PRs](https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=orange&amp;label=PRs)](https://github.com/EbookFoundation/free-programming-books/pulls)&amp;#160;
[![GitHub repo Merged PRs](https://img.shields.io/github/issues-search/EbookFoundation/free-programming-books?style=flat&amp;logo=github&amp;logoColor=green&amp;label=Merged%20PRs&amp;query=is%3Amerged)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Apr+is%3Amerged)&amp;#160;
[![GitHub Help Wanted PRs](https://img.shields.io/github/issues-pr/EbookFoundation/free-programming-books/help%20wanted?style=flat&amp;logo=github&amp;logoColor=b545d1&amp;label=%22Help%20Wanted%22%20PRs)](https://github.com/EbookFoundation/free-programming-books/pulls?q=is%3Aopen+is%3Aissue+label%3A%22help+wanted%22)

&lt;/div&gt;

## How To Share

&lt;div align=&quot;left&quot; markdown=&quot;1&quot;&gt;
&lt;a href=&quot;https://www.facebook.com/share.php?u=https%3A%2F%2Fgithub.com%2FEbookFoundation%2Ffree-programming-books&amp;p[images][0]=&amp;p[title]=Free%20Programming%20Books&amp;p[summary]=&quot;&gt;Share on Facebook&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;http://www.linkedin.com/shareArticle?mini=true&amp;url=https://github.com/EbookFoundation/free-programming-books&amp;title=Free%20Programming%20Books&amp;summary=&amp;source=&quot;&gt;Share on LinkedIn&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://toot.kytta.dev/?text=https://github.com/EbookFoundation/free-programming-books&quot;&gt;Share on Mastodon/Fediverse&lt;/a&gt;&lt;br&gt;    
&lt;a href=&quot;https://t.me/share/url?url=https://github.com/EbookFoundation/free-programming-books&quot;&gt;Share on Telegram&lt;/a&gt;&lt;br&gt;
&lt;a href=&quot;https://twitter.com/intent/tweet?text=https://github.com/EbookFoundation/free-programming-books%0AFree%20Programming%20Books&quot;&gt;Share on ùïè (Twitter)&lt;/a&gt;&lt;br&gt;
&lt;/div&gt;

## Resources

This project lists books and other resources grouped by genres:

### Books

[English, By Programming Language](books/free-programming-books-langs.md)

[English, By Subject](books/free-programming-books-subjects.md)

#### Other Languages

+ [Arabic / al arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](books/free-programming-books-ar.md)
+ [Armenian / ’Ä’°’µ’•÷Ä’•’∂](books/free-programming-books-hy.md)
+ [Azerbaijani / –ê–∑”ô—Ä–±–∞—ò“π–∞–Ω –¥–∏–ª–∏ / ÿ¢ÿ∞ÿ±ÿ®ÿßŸäÿ¨ÿßŸÜÿ¨ÿß ÿØŸäŸÑŸä](books/free-programming-books-az.md)
+ [Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](books/free-programming-books-bn.md)
+ [Bulgarian / –±—ä–ª–≥–∞—Ä—Å–∫–∏](books/free-programming-books-bg.md)
+ [Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨](books/free-programming-books-my.md)
+ [Chinese / ‰∏≠Êñá](books/free-programming-books-zh.md)
+ [Czech / ƒçe≈°tina / ƒçesk√Ω jazyk](books/free-programming-books-cs.md)
+ [Catalan / catalan / catal√†](books/free-programming-books-ca.md)
+ [Danish / dansk](books/free-programming-books-da.md)
+ [Dutch / Nederlands](books/free-programming-books-nl.md)
+ [Estonian / eesti keel](books/free-programming-books-et.md)
+ [Finnish / suomi / suomen kieli](books/free-programming-books-fi.md)
+ [French / fran√ßais](books/free-programming-books-fr.md)
+ [German / Deutsch](books/free-programming-books-de.md)
+ [Greek / ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨](books/free-programming-books-el.md)
+ [Hebrew / ◊¢◊ë◊®◊ô◊™](books/free-programming-books-he.md)
+ [Hindi / ‡§π‡§ø‡§®‡•ç‡§¶‡•Ä](books/free-programming-books-hi.md)
+ [Hungarian / magyar / magyar nyelv](books/free-programming-books-hu.md)
+ [Indonesian / Bahasa Indonesia](books/free-programming-books-id.md)
+ [Italian / italiano](books/free-programming-books-it.md)
+ [Japanese / Êó•Êú¨Ë™û](books/free-programming-books-ja.md)
+ [Korean / ÌïúÍµ≠Ïñ¥](books/free-programming-books-ko.md)
+ [Latvian / Latvie≈°u](books/free-programming-books-lv.md)
+ [Malayalam / ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç](books/free-programming-books-ml.md)
+ [Norwegian / Norsk](books/free-programming-books-no.md)
+ [Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ](books/free-programming-books-fa_IR.md)
+ [Polish / polski / jƒôzyk polski / polszczyzna](books/free-programming-books-pl.md)
+ [Portuguese (Brazil)](books/free-programming-books-pt_BR.md)
+ [Portuguese (Portugal)](books/free-programming-books-pt_PT.md)
+ [Romanian (Romania) / limba rom√¢nƒÉ / rom√¢n](books/free-programming-books-ro.md)
+ [Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫](books/free-programming-books-ru.md)
+ [Serbian / —Å—Ä–ø—Å–∫–∏ —ò–µ–∑–∏–∫ / srpski jezik](books/free-programming-books-sr.md)
+ [Slovak / slovenƒçina](books/free-programming-books-sk.md)
+ [Slovenian / Sloven≈°ƒçina](books/free-programming-books-sl.md)
+ [Spanish / espa√±ol / castellano](books/free-programming-books-es.md)
+ [Swedish / Svenska](books/free-programming-books-sv.md)
+ [Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç](books/free-programming-books-ta.md)
+ [Telugu / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å](books/free-programming-books-te.md)
+ [Thai / ‡πÑ‡∏ó‡∏¢](books/free-programming-books-th.md)
+ [Turkish / T√ºrk√ße](books/free-programming-books-tr.md)
+ [Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](books/free-programming-books-uk.md)
+ [Urdu / ÿßÿ±ÿØŸà](books/free-programming-books-ur.md)
+ [Vietnamese / Ti·∫øng Vi·ªát](books/free-programming-books-vi.md)

### Cheat Sheets

+ [All Languages](more/free-programming-cheatsheets.md)

### Free Online Courses

+ [Arabic / al arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](courses/free-courses-ar.md)
+ [Bengali / ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ](courses/free-courses-bn.md)
+ [Bulgarian / –±—ä–ª–≥–∞—Ä—Å–∫–∏](courses/free-courses-bg.md)
+ [Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨](courses/free-courses-my.md)
+ [Chinese / ‰∏≠Êñá](courses/free-courses-zh.md)
+ [English](courses/free-courses-en.md)
+ [Finnish / suomi / suomen kieli](courses/free-courses-fi.md)
+ [French / fran√ßais](courses/free-courses-fr.md)
+ [German / Deutsch](courses/free-courses-de.md)
+ [Greek / ŒµŒªŒªŒ∑ŒΩŒπŒ∫Œ¨](courses/free-courses-el.md)
+ [Hebrew / ◊¢◊ë◊®◊ô◊™](courses/free-courses-he.md)
+ [Hindi / ‡§π‡§ø‡§Ç‡§¶‡•Ä](courses/free-courses-hi.md)
+ [Indonesian / Bahasa Indonesia](courses/free-courses-id.md)
+ [Italian / italiano](courses/free-courses-it.md)
+ [Japanese / Êó•Êú¨Ë™û](courses/free-courses-ja.md)
+ [Kannada / ‡≤ï‡≤®‡≥ç‡≤®‡≤°](courses/free-courses-kn.md)
+ [Kazakh / “õ–∞–∑–∞“õ—à–∞](courses/free-courses-kk.md)
+ [Khmer / ·ûó·û∂·ûü·û∂·ûÅ·üí·ûò·üÇ·ûö](courses/free-courses-km.md)
+ [Korean / ÌïúÍµ≠Ïñ¥](courses/free-courses-ko.md)
+ [Malayalam / ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç](courses/free-courses-ml.md)
+ [Marathi / ‡§Æ‡§∞‡§æ‡§†‡•Ä](courses/free-courses-mr.md)
+ [Nepali / ‡§®‡•á‡§™‡§æ‡§≤‡•Ä](courses/free-courses-ne.md)
+ [Norwegian / Norsk](courses/free-courses-no.md)
+ [Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ](courses/free-courses-fa_IR.md)
+ [Polish / polski / jƒôzyk polski / polszczyzna](courses/free-courses-pl.md)
+ [Portuguese (Brazil)](courses/free-courses-pt_BR.md)
+ [Portuguese (Portugal)](courses/free-courses-pt_PT.md)
+ [Punjabi / ‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä / ŸæŸÜÿ¨ÿßÿ®€å](courses/free-courses-pa.md)
+ [Romanian (Romania) / limba rom√¢nƒÉ / rom√¢n](courses/free-courses-ro.md)
+ [Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫](courses/free-courses-ru.md)
+ [Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω](courses/free-courses-si.md)
+ [Spanish / espa√±ol / castellano](courses/free-courses-es.md)
+ [Swedish / svenska](courses/free-courses-sv.md)
+ [Tamil / ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç](courses/free-courses-ta.md)
+ [Telugu / ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å](courses/free-courses-te.md)
+ [Thai / ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢](courses/free-courses-th.md)
+ [Turkish / T√ºrk√ße](courses/free-courses-tr.md)
+ [Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](courses/free-courses-uk.md)
+ [Urdu / ÿßÿ±ÿØŸà](courses/free-courses-ur.md)
+ [Vietnamese / Ti·∫øng Vi·ªát](courses/free-courses-vi.md)


### Interactive Programming Resources

+ [Chinese / ‰∏≠Êñá](more/free-programming-interactive-tutorials-zh.md)
+ [English](more/free-programming-interactive-tutorials-en.md)
+ [German / Deutsch](more/free-programming-interactive-tutorials-de.md)
+ [Japanese / Êó•Êú¨Ë™û](more/free-programming-interactive-tutorials-ja.md)
+ [Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫](more/free-programming-interactive-tutorials-ru.md)


### Problem Sets and Competitive Programming

+ [Problem Sets](more/problem-sets-competitive-programming.md)


### Podcast - Screencast

Free Podcasts and Screencasts:

+ [Arabic / al Arabiya / ÿßŸÑÿπÿ±ÿ®Ÿäÿ©](casts/free-podcasts-screencasts-ar.md)
+ [Burmese / ·Äô·Äº·Äî·Ä∫·Äô·Ä¨·Äò·Ä¨·Äû·Ä¨](casts/free-podcasts-screencasts-my.md)
+ [Chinese / ‰∏≠Êñá](casts/free-podcasts-screencasts-zh.md)
+ [Czech / ƒçe≈°tina / ƒçesk√Ω jazyk](casts/free-podcasts-screencasts-cs.md)
+ [Dutch / Nederlands](casts/free-podcasts-screencasts-nl.md)
+ [English](casts/free-podcasts-screencasts-en.md)
+ [Finnish / Suomi](casts/free-podcasts-screencasts-fi.md)
+ [French / fran√ßais](casts/free-podcasts-screencasts-fr.md)
+ [German / Deutsch](casts/free-podcasts-screencasts-de.md)
+ [Hebrew / ◊¢◊ë◊®◊ô◊™](casts/free-podcasts-screencasts-he.md)
+ [Indonesian / Bahasa Indonesia](casts/free-podcasts-screencasts-id.md)
+ [Persian / Farsi (Iran) / ŸÅÿßÿ±ÿ≥Ÿâ](casts/free-podcasts-screencasts-fa_IR.md)
+ [Polish / polski / jƒôzyk polski / polszczyzna](casts/free-podcasts-screencasts-pl.md)
+ [Portuguese (Brazil)](casts/free-podcasts-screencasts-pt_BR.md)
+ [Portuguese (Portugal)](casts/free-podcasts-screencasts-pt_PT.md)
+ [Russian / –†—É—Å—Å–∫–∏–π —è–∑—ã–∫](casts/free-podcasts-screencasts-ru.md)
+ [Sinhala / ‡∑É‡∑í‡∂Ç‡∑Ñ‡∂Ω](casts/free-podcasts-screencasts-si.md)
+ [Spanish / espa√±ol / castellano](casts/free-podcasts-screencasts-es.md)
+ [Swedish / Svenska](casts/free-podcasts-screencasts-sv.md)
+ [Turkish / T√ºrk√ße](casts/free-podcasts-screencasts-tr.md)
+ [Ukrainian / –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞](casts/free-podcasts-screencasts-uk.md)


### Programming Playgrounds

Write, compile, and run your code within a browser. Try it out!

+ [Chinese / ‰∏≠Êñá](more/free-programming-playgrounds-zh.md)
+ [English](more/free-programming-playgrounds.md)
+ [German / Deutsch](more/free-programming-playgrounds-de.md)

## Translations

Volunteers have translated many of our Contributing, How-to, and Code of Conduct documents into languages covered by our lists.

+ English
  + [Code of Conduct](docs/CODE_OF_CONDUCT.md)
  + [Contributing](docs/CONTRIBUTING.md)
  + [How-to](docs/HOWTO.md)
+ ... *[More languages](docs/README.md#translations)* ...

You might notice that there are [some missing translations here](docs/README.md#translations) - perhaps you would like to help out by [contributing a translation](docs/CONTRIBUTING.md#help-out-by-contributing-a-translation)?


## License

Each file included in this repository is licensed under the [CC BY License](LICENSE).
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[VectifyAI/PageIndex]]></title>
            <link>https://github.com/VectifyAI/PageIndex</link>
            <guid>https://github.com/VectifyAI/PageIndex</guid>
            <pubDate>Wed, 04 Feb 2026 00:05:59 GMT</pubDate>
            <description><![CDATA[üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/VectifyAI/PageIndex">VectifyAI/PageIndex</a></h1>
            <p>üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG</p>
            <p>Language: Python</p>
            <p>Stars: 12,924</p>
            <p>Forks: 933</p>
            <p>Stars today: 543 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  
&lt;a href=&quot;https://vectify.ai/pageindex&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/46201e72-675b-43bc-bfbd-081cc6b65a1d&quot; alt=&quot;PageIndex Banner&quot; /&gt;
&lt;/a&gt;

&lt;br/&gt;
&lt;br/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/14736&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14736&quot; alt=&quot;VectifyAI%2FPageIndex | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

# PageIndex: Vectorless, Reasoning-based RAG

&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Reasoning-based RAG&amp;nbsp; ‚ó¶ &amp;nbsp;No Vector DB&amp;nbsp; ‚ó¶ &amp;nbsp;No Chunking&amp;nbsp; ‚ó¶ &amp;nbsp;Human-like Retrieval&lt;/b&gt;&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vectify.ai&quot;&gt;üè† Homepage&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://chat.pageindex.ai&quot;&gt;üñ•Ô∏è Chat Platform&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://pageindex.ai/mcp&quot;&gt;üîå MCP&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://docs.pageindex.ai&quot;&gt;üìö Docs&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://discord.com/invite/VuXuf29EUj&quot;&gt;üí¨ Discord&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://ii2abc2jejf.typeform.com/to/tK3AXl8T&quot;&gt;‚úâÔ∏è Contact&lt;/a&gt;&amp;nbsp;
&lt;/h4&gt;
  
&lt;/div&gt;


&lt;details open&gt;
&lt;summary&gt;&lt;h3&gt;üì¢ Latest Updates&lt;/h3&gt;&lt;/summary&gt;

 **üî• Releases:**
- [**PageIndex Chat**](https://chat.pageindex.ai): The first human-like document-analysis agent [platform](https://chat.pageindex.ai) built for professional long documents. Can also be integrated via [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart) (beta).
&lt;!-- - [**PageIndex Chat API**](https://docs.pageindex.ai/quickstart): An API that brings PageIndex&#039;s advanced long-document intelligence directly into your applications and workflows. --&gt;
&lt;!-- - [PageIndex MCP](https://pageindex.ai/mcp): Bring PageIndex into Claude, Cursor, or any MCP-enabled agent. Chat with long PDFs in a reasoning-based, human-like way. --&gt;
 
 **üìù Articles:**
- [**PageIndex Framework**](https://pageindex.ai/blog/pageindex-intro): Introduces the PageIndex framework ‚Äî an *agentic, in-context* *tree index* that enables LLMs to perform *reasoning-based*, *human-like retrieval* over long documents, without vector DB or chunking.
&lt;!-- - [Do We Still Need OCR?](https://pageindex.ai/blog/do-we-need-ocr): Explores how vision-based, reasoning-native RAG challenges the traditional OCR pipeline, and why the future of document AI might be *vectorless* and *vision-based*. --&gt;

 **üß™ Cookbooks:**
- [Vectorless RAG](https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex): A minimal, hands-on example of reasoning-based RAG using PageIndex. No vectors, no chunking, and human-like retrieval.
- [Vision-based Vectorless RAG](https://docs.pageindex.ai/cookbook/vision-rag-pageindex): OCR-free, vision-only RAG with PageIndex&#039;s reasoning-native retrieval workflow that works directly over PDF page images.
&lt;/details&gt;

---

# üìë Introduction to PageIndex

Are you frustrated with vector database retrieval accuracy for long professional documents? Traditional vector-based RAG relies on semantic *similarity* rather than true *relevance*. But **similarity ‚â† relevance** ‚Äî what we truly need in retrieval is **relevance**, and that requires **reasoning**. When working with professional documents that demand domain expertise and multi-step reasoning, similarity search often falls short.

Inspired by AlphaGo, we propose **[PageIndex](https://vectify.ai/pageindex)** ‚Äî a **vectorless**, **reasoning-based RAG** system that builds a **hierarchical tree index** from long documents and uses LLMs to **reason** *over that index* for **agentic, context-aware retrieval**.
It simulates how *human experts* navigate and extract knowledge from complex documents through *tree search*, enabling LLMs to *think* and *reason* their way to the most relevant document sections. PageIndex performs retrieval in two steps:

1. Generate a ‚ÄúTable-of-Contents‚Äù **tree structure index** of documents
2. Perform reasoning-based retrieval through **tree search**

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pageindex.ai/blog/pageindex-intro&quot; target=&quot;_blank&quot; title=&quot;The PageIndex Framework&quot;&gt;
    &lt;img src=&quot;https://docs.pageindex.ai/images/cookbook/vectorless-rag.png&quot; width=&quot;70%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

### üéØ Core Features 

Compared to traditional vector-based RAG, **PageIndex** features:
- **No Vector DB**: Uses document structure and LLM reasoning for retrieval, instead of vector similarity search.
- **No Chunking**: Documents are organized into natural sections, not artificial chunks.
- **Human-like Retrieval**: Simulates how human experts navigate and extract knowledge from complex documents.
- **Better Explainability and Traceability**: Retrieval is based on reasoning ‚Äî traceable and interpretable, with page and section references. No more opaque, approximate vector search (‚Äúvibe retrieval‚Äù).

PageIndex powers a reasoning-based RAG system that achieved **state-of-the-art** [98.7% accuracy](https://github.com/VectifyAI/Mafin2.5-FinanceBench) on FinanceBench, demonstrating superior performance over vector-based RAG solutions in professional document analysis (see our [blog post](https://vectify.ai/blog/Mafin2.5) for details).

### üìç Explore PageIndex

To learn more, please see a detailed introduction of the [PageIndex framework](https://pageindex.ai/blog/pageindex-intro). Check out this GitHub repo for open-source code, and the [cookbooks](https://docs.pageindex.ai/cookbook), [tutorials](https://docs.pageindex.ai/tutorials), and [blog](https://pageindex.ai/blog) for additional usage guides and examples. 

The PageIndex service is available as a ChatGPT-style [chat platform](https://chat.pageindex.ai), or can be integrated via [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart).

### üõ†Ô∏è Deployment Options
- Self-host ‚Äî run locally with this open-source repo.
- Cloud Service ‚Äî try instantly with our [Chat Platform](https://chat.pageindex.ai/), or integrate with [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart).
- _Enterprise_ ‚Äî private or on-prem deployment. [Contact us](https://ii2abc2jejf.typeform.com/to/tK3AXl8T) or [book a demo](https://calendly.com/pageindex/meet) for more details.

### üß™ Quick Hands-on

- Try the [**Vectorless RAG**](https://github.com/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb) notebook ‚Äî a *minimal*, hands-on example of reasoning-based RAG using PageIndex.
- Experiment with [*Vision-based Vectorless RAG*](https://github.com/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb) ‚Äî no OCR; a minimal, reasoning-native RAG pipeline that works directly over page images.
  
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Open_In_Colab-Vectorless_RAG-orange?style=for-the-badge&amp;logo=googlecolab&quot; alt=&quot;Open in Colab: Vectorless RAG&quot; /&gt;
  &lt;/a&gt;
  &amp;nbsp;&amp;nbsp;
  &lt;a href=&quot;https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Open_In_Colab-Vision_RAG-orange?style=for-the-badge&amp;logo=googlecolab&quot; alt=&quot;Open in Colab: Vision RAG&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

---

# üå≤ PageIndex Tree Structure
PageIndex can transform lengthy PDF documents into a semantic **tree structure**, similar to a _&quot;table of contents&quot;_ but optimized for use with Large Language Models (LLMs). It&#039;s ideal for: financial reports, regulatory filings, academic textbooks, legal or technical manuals, and any document that exceeds LLM context limits.

Below is an example PageIndex tree structure. Also see more example [documents](https://github.com/VectifyAI/PageIndex/tree/main/tests/pdfs) and generated [tree structures](https://github.com/VectifyAI/PageIndex/tree/main/tests/results).

```jsonc
...
{
  &quot;title&quot;: &quot;Financial Stability&quot;,
  &quot;node_id&quot;: &quot;0006&quot;,
  &quot;start_index&quot;: 21,
  &quot;end_index&quot;: 22,
  &quot;summary&quot;: &quot;The Federal Reserve ...&quot;,
  &quot;nodes&quot;: [
    {
      &quot;title&quot;: &quot;Monitoring Financial Vulnerabilities&quot;,
      &quot;node_id&quot;: &quot;0007&quot;,
      &quot;start_index&quot;: 22,
      &quot;end_index&quot;: 28,
      &quot;summary&quot;: &quot;The Federal Reserve&#039;s monitoring ...&quot;
    },
    {
      &quot;title&quot;: &quot;Domestic and International Cooperation and Coordination&quot;,
      &quot;node_id&quot;: &quot;0008&quot;,
      &quot;start_index&quot;: 28,
      &quot;end_index&quot;: 31,
      &quot;summary&quot;: &quot;In 2023, the Federal Reserve collaborated ...&quot;
    }
  ]
}
...
```

You can generate the PageIndex tree structure with this open-source repo, or use our [API](https://docs.pageindex.ai/quickstart) 

---

# ‚öôÔ∏è Package Usage

You can follow these steps to generate a PageIndex tree from a PDF document.

### 1. Install dependencies

```bash
pip3 install --upgrade -r requirements.txt
```

### 2. Set your OpenAI API key

Create a `.env` file in the root directory and add your API key:

```bash
CHATGPT_API_KEY=your_openai_key_here
```

### 3. Run PageIndex on your PDF

```bash
python3 run_pageindex.py --pdf_path /path/to/your/document.pdf
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Optional parameters&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;
You can customize the processing with additional optional arguments:

```
--model                 OpenAI model to use (default: gpt-4o-2024-11-20)
--toc-check-pages       Pages to check for table of contents (default: 20)
--max-pages-per-node    Max pages per node (default: 10)
--max-tokens-per-node   Max tokens per node (default: 20000)
--if-add-node-id        Add node ID (yes/no, default: yes)
--if-add-node-summary   Add node summary (yes/no, default: yes)
--if-add-doc-description Add doc description (yes/no, default: yes)
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Markdown support&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;
We also provide markdown support for PageIndex. You can use the `-md_path` flag to generate a tree structure for a markdown file.

```bash
python3 run_pageindex.py --md_path /path/to/your/document.md
```

&gt; Note: in this function, we use &quot;#&quot; to determine node heading and their levels. For example, &quot;##&quot; is level 2, &quot;###&quot; is level 3, etc. Make sure your markdown file is formatted correctly. If your Markdown file was converted from a PDF or HTML, we don&#039;t recommend using this function, since most existing conversion tools cannot preserve the original hierarchy. Instead, use our [PageIndex OCR](https://pageindex.ai/blog/ocr), which is designed to preserve the original hierarchy, to convert the PDF to a markdown file and then use this function.
&lt;/details&gt;

&lt;!-- 
# ‚òÅÔ∏è Improved Tree Generation with PageIndex OCR

This repo is designed for generating PageIndex tree structure for simple PDFs, but many real-world use cases involve complex PDFs that are hard to parse by classic Python tools. However, extracting high-quality text from PDF documents remains a non-trivial challenge. Most OCR tools only extract page-level content, losing the broader document context and hierarchy.

To address this, we introduced PageIndex OCR ‚Äî the first long-context OCR model designed to preserve the global structure of documents. PageIndex OCR significantly outperforms other leading OCR tools, such as those from Mistral and Contextual AI, in recognizing true hierarchy and semantic relationships across document pages.

- Experience next-level OCR quality with PageIndex OCR at our [Dashboard](https://dash.pageindex.ai/).
- Integrate PageIndex OCR seamlessly into your stack via our [API](https://docs.pageindex.ai/quickstart).

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/eb35d8ae-865c-4e60-a33b-ebbd00c41732&quot; width=&quot;80%&quot;&gt;
&lt;/p&gt;
--&gt;

---

# üìà Case Study: PageIndex Leads Finance QA Benchmark

[Mafin 2.5](https://vectify.ai/mafin) is a reasoning-based RAG system for financial document analysis, powered by **PageIndex**. It achieved a state-of-the-art [**98.7% accuracy**](https://vectify.ai/blog/Mafin2.5) on the [FinanceBench](https://arxiv.org/abs/2311.11944) benchmark, significantly outperforming traditional vector-based RAG systems.

PageIndex&#039;s hierarchical indexing and reasoning-driven retrieval enable precise navigation and extraction of relevant context from complex financial reports, such as SEC filings and earnings disclosures.

Explore the full [benchmark results](https://github.com/VectifyAI/Mafin2.5-FinanceBench) and our [blog post](https://vectify.ai/blog/Mafin2.5) for detailed comparisons and performance metrics.

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/VectifyAI/Mafin2.5-FinanceBench&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/571aa074-d803-43c7-80c4-a04254b782a3&quot; width=&quot;70%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

---

# üß≠ Resources

* üß™ [Cookbooks](https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex): hands-on, runnable examples and advanced use cases.
* üìñ [Tutorials](https://docs.pageindex.ai/doc-search): practical guides and strategies, including *Document Search* and *Tree Search*.
* üìù [Blog](https://pageindex.ai/blog): technical articles, research insights, and product updates.
* üîå [MCP setup](https://pageindex.ai/mcp#quick-setup) &amp; [API docs](https://docs.pageindex.ai/quickstart): integration details and configuration options.

---

# ‚≠ê Support Us

Leave us a star üåü if you like our project. Thank you!  

&lt;p&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/eae4ff38-48ae-4a7c-b19f-eab81201d794&quot; width=&quot;80%&quot;&gt;
&lt;/p&gt;

### Connect with Us

[![Twitter](https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white)](https://x.com/PageIndexAI)&amp;nbsp;
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/vectify-ai/)&amp;nbsp;
[![Discord](https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.com/invite/VuXuf29EUj)&amp;nbsp;
[![Contact Us](https://img.shields.io/badge/Contact_Us-3B82F6?style=for-the-badge&amp;logo=envelope&amp;logoColor=white)](https://ii2abc2jejf.typeform.com/to/tK3AXl8T)

---

¬© 2025 [Vectify AI](https://vectify.ai)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[shareAI-lab/learn-claude-code]]></title>
            <link>https://github.com/shareAI-lab/learn-claude-code</link>
            <guid>https://github.com/shareAI-lab/learn-claude-code</guid>
            <pubDate>Wed, 04 Feb 2026 00:05:58 GMT</pubDate>
            <description><![CDATA[Bash is all You need - Write a nano Claude Code 0 - 1]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/shareAI-lab/learn-claude-code">shareAI-lab/learn-claude-code</a></h1>
            <p>Bash is all You need - Write a nano Claude Code 0 - 1</p>
            <p>Language: Python</p>
            <p>Stars: 16,270</p>
            <p>Forks: 3,531</p>
            <p>Stars today: 118 stars today</p>
            <h2>README</h2><pre># Learn Claude Code - Bash is all you &amp; agent need

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Tests](https://github.com/shareAI-lab/learn-claude-code/actions/workflows/test.yml/badge.svg)](https://github.com/shareAI-lab/learn-claude-code/actions)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](./LICENSE)

&gt; **Disclaimer**: This is an independent educational project by [shareAI Lab](https://github.com/shareAI-lab). It is not affiliated with, endorsed by, or sponsored by Anthropic. &quot;Claude Code&quot; is a trademark of Anthropic.

**Learn how modern AI agents work by building one from scratch.**

[Chinese / ‰∏≠Êñá](./README_zh.md) | [Japanese / Êó•Êú¨Ë™û](./README_ja.md)

---

## Why This Repository?

We created this repository out of admiration for Claude Code - **what we believe to be the most capable AI coding agent in the world**. Initially, we attempted to reverse-engineer its design through behavioral observation and speculation. The analysis we published was riddled with inaccuracies, unfounded guesses, and technical errors. We deeply apologize to the Claude Code team and anyone who was misled by that content.

Over the past six months, through building and iterating on real agent systems, our understanding of **&quot;what makes a true AI agent&quot;** has been fundamentally reshaped. We&#039;d like to share these insights with you. All previous speculative content has been removed and replaced with original educational material.

---

&gt; Works with **[Kode CLI](https://github.com/shareAI-lab/Kode)**, **Claude Code**, **Cursor**, and any agent supporting the [Agent Skills Spec](https://agentskills.io/specification).

&lt;img height=&quot;400&quot; alt=&quot;demo&quot; src=&quot;https://github.com/user-attachments/assets/0e1e31f8-064f-4908-92ce-121e2eb8d453&quot; /&gt;

## What You&#039;ll Learn

After completing this tutorial, you will understand:

- **The Agent Loop** - The surprisingly simple pattern behind all AI coding agents
- **Tool Design** - How to give AI models the ability to interact with the real world
- **Explicit Planning** - Using constraints to make AI behavior predictable
- **Context Management** - Keeping agent memory clean through subagent isolation
- **Knowledge Injection** - Loading domain expertise on-demand without retraining

## Learning Path

```
Start Here
    |
    v
[v0: Bash Agent] -----&gt; &quot;One tool is enough&quot;
    |                    16-50 lines
    v
[v1: Basic Agent] ----&gt; &quot;The complete agent pattern&quot;
    |                    4 tools, ~200 lines
    v
[v2: Todo Agent] -----&gt; &quot;Make plans explicit&quot;
    |                    +TodoManager, ~300 lines
    v
[v3: Subagent] -------&gt; &quot;Divide and conquer&quot;
    |                    +Task tool, ~450 lines
    v
[v4: Skills Agent] ---&gt; &quot;Domain expertise on-demand&quot;
                         +Skill tool, ~550 lines
```

**Recommended approach:**
1. Read and run v0 first - understand the core loop
2. Compare v0 and v1 - see how tools evolve
3. Study v2 for planning patterns
4. Explore v3 for complex task decomposition
5. Master v4 for building extensible agents

## Quick Start

```bash
# Clone the repository
git clone https://github.com/shareAI-lab/learn-claude-code
cd learn-claude-code

# Install dependencies
pip install -r requirements.txt

# Configure API key
cp .env.example .env
# Edit .env with your ANTHROPIC_API_KEY

# Run any version
python v0_bash_agent.py      # Minimal (start here!)
python v1_basic_agent.py     # Core agent loop
python v2_todo_agent.py      # + Todo planning
python v3_subagent.py        # + Subagents
python v4_skills_agent.py    # + Skills
```

## The Core Pattern

Every coding agent is just this loop:

```python
while True:
    response = model(messages, tools)
    if response.stop_reason != &quot;tool_use&quot;:
        return response.text
    results = execute(response.tool_calls)
    messages.append(results)
```

That&#039;s it. The model calls tools until done. Everything else is refinement.

## Version Comparison

| Version | Lines | Tools | Core Addition | Key Insight |
|---------|-------|-------|---------------|-------------|
| [v0](./v0_bash_agent.py) | ~50 | bash | Recursive subagents | One tool is enough |
| [v1](./v1_basic_agent.py) | ~200 | bash, read, write, edit | Core loop | Model as Agent |
| [v2](./v2_todo_agent.py) | ~300 | +TodoWrite | Explicit planning | Constraints enable complexity |
| [v3](./v3_subagent.py) | ~450 | +Task | Context isolation | Clean context = better results |
| [v4](./v4_skills_agent.py) | ~550 | +Skill | Knowledge loading | Expertise without retraining |

## File Structure

```
learn-claude-code/
‚îú‚îÄ‚îÄ v0_bash_agent.py       # ~50 lines: 1 tool, recursive subagents
‚îú‚îÄ‚îÄ v0_bash_agent_mini.py  # ~16 lines: extreme compression
‚îú‚îÄ‚îÄ v1_basic_agent.py      # ~200 lines: 4 tools, core loop
‚îú‚îÄ‚îÄ v2_todo_agent.py       # ~300 lines: + TodoManager
‚îú‚îÄ‚îÄ v3_subagent.py         # ~450 lines: + Task tool, agent registry
‚îú‚îÄ‚îÄ v4_skills_agent.py     # ~550 lines: + Skill tool, SkillLoader
‚îú‚îÄ‚îÄ skills/                # Example skills (pdf, code-review, mcp-builder, agent-builder)
‚îú‚îÄ‚îÄ docs/                  # Technical documentation (EN + ZH + JA)
‚îú‚îÄ‚îÄ articles/              # Blog-style articles (ZH)
‚îî‚îÄ‚îÄ tests/                 # Unit and integration tests
```

## Documentation

### Technical Tutorials (docs/)

- [v0: Bash is All You Need](./docs/v0-bash-is-all-you-need.md)
- [v1: Model as Agent](./docs/v1-model-as-agent.md)
- [v2: Structured Planning](./docs/v2-structured-planning.md)
- [v3: Subagent Mechanism](./docs/v3-subagent-mechanism.md)
- [v4: Skills Mechanism](./docs/v4-skills-mechanism.md)

### Articles

See [articles/](./articles/) for blog-style explanations.

## Using the Skills System

### Example Skills Included

| Skill | Purpose |
|-------|---------|
| [agent-builder](./skills/agent-builder/) | Meta-skill: how to build agents |
| [code-review](./skills/code-review/) | Systematic code review methodology |
| [pdf](./skills/pdf/) | PDF manipulation patterns |
| [mcp-builder](./skills/mcp-builder/) | MCP server development |

### Scaffold a New Agent

```bash
# Use the agent-builder skill to create a new project
python skills/agent-builder/scripts/init_agent.py my-agent

# Specify complexity level
python skills/agent-builder/scripts/init_agent.py my-agent --level 0  # Minimal
python skills/agent-builder/scripts/init_agent.py my-agent --level 1  # 4 tools
```

### Install Skills for Production

```bash
# Kode CLI (recommended)
kode plugins install https://github.com/shareAI-lab/shareAI-skills

# Claude Code
claude plugins install https://github.com/shareAI-lab/shareAI-skills
```

## Configuration

```bash
# .env file options
ANTHROPIC_API_KEY=sk-ant-xxx      # Required: Your API key
ANTHROPIC_BASE_URL=https://...    # Optional: For API proxies
MODEL_ID=claude-sonnet-4-5-20250929  # Optional: Model selection
```

## Related Projects

| Repository | Description |
|------------|-------------|
| [Kode](https://github.com/shareAI-lab/Kode) | Production-ready open source agent CLI |
| [shareAI-skills](https://github.com/shareAI-lab/shareAI-skills) | Production skills collection |
| [Agent Skills Spec](https://agentskills.io/specification) | Official specification |

## Philosophy

&gt; **The model is 80%. Code is 20%.**

Modern agents like Kode and Claude Code work not because of clever engineering, but because the model is trained to be an agent. Our job is to give it tools and stay out of the way.

## Contributing

Contributions are welcome! Please feel free to submit issues and pull requests.

- Add new example skills in `skills/`
- Improve documentation in `docs/`
- Report bugs or suggest features via [Issues](https://github.com/shareAI-lab/learn-claude-code/issues)

## License

MIT

---

**Model as Agent. That&#039;s the whole secret.**

[@baicai003](https://x.com/baicai003) | [shareAI Lab](https://github.com/shareAI-lab)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[xerrors/Yuxi-Know]]></title>
            <link>https://github.com/xerrors/Yuxi-Know</link>
            <guid>https://github.com/xerrors/Yuxi-Know</guid>
            <pubDate>Wed, 04 Feb 2026 00:05:57 GMT</pubDate>
            <description><![CDATA[ÁªìÂêàLightRAG Áü•ËØÜÂ∫ìÁöÑÁü•ËØÜÂõæË∞±Êô∫ËÉΩ‰ΩìÂπ≥Âè∞„ÄÇ An agent platform that integrates a LightRAG knowledge base and knowledge graphs. Build with LangChain v1 + Vue + FastAPI, support DeepAgents„ÄÅMinerU PDF„ÄÅNeo4j „ÄÅMCP.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/xerrors/Yuxi-Know">xerrors/Yuxi-Know</a></h1>
            <p>ÁªìÂêàLightRAG Áü•ËØÜÂ∫ìÁöÑÁü•ËØÜÂõæË∞±Êô∫ËÉΩ‰ΩìÂπ≥Âè∞„ÄÇ An agent platform that integrates a LightRAG knowledge base and knowledge graphs. Build with LangChain v1 + Vue + FastAPI, support DeepAgents„ÄÅMinerU PDF„ÄÅNeo4j „ÄÅMCP.</p>
            <p>Language: Python</p>
            <p>Stars: 4,221</p>
            <p>Forks: 533</p>
            <p>Stars today: 29 stars today</p>
            <h2>README</h2><pre>
&lt;div align=&quot;center&quot;&gt;
&lt;img width=&quot;140&quot; height=&quot;140&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/299137b7-08d8-45b0-9feb-7b4ab35d7b48&quot; /&gt;

&lt;h1&gt;ËØ≠Êûê - Âü∫‰∫éÂ§ßÊ®°ÂûãÁöÑÁü•ËØÜÂ∫ì‰∏éÁü•ËØÜÂõæË∞±Êô∫ËÉΩ‰ΩìÂºÄÂèëÂπ≥Âè∞&lt;/h1&gt;

[![Stable](https://img.shields.io/badge/stable-v0.4.4-blue.svg)](https://github.com/xerrors/Yuxi-Know/tree/v0.4.4)
[![](https://img.shields.io/badge/Docker-2496ED?style=flat&amp;logo=docker&amp;logoColor=ffffff)](https://github.com/xerrors/Yuxi-Know/blob/main/docker-compose.yml)
[![](https://img.shields.io/github/issues/xerrors/Yuxi-Know?color=F48D73)](https://github.com/xerrors/Yuxi-Know/issues)
[![License](https://img.shields.io/github/license/bitcookies/winrar-keygen.svg?logo=github)](https://github.com/xerrors/Yuxi-Know/blob/main/LICENSE)
[![DeepWiki](https://img.shields.io/badge/DeepWiki-blue.svg)](https://deepwiki.com/xerrors/Yuxi-Know)
[![zread](https://img.shields.io/badge/Ask_Zread-_.svg?style=flat&amp;color=00b0aa&amp;labelColor=000000&amp;logo=data%3Aimage%2Fsvg%2Bxml%3Bbase64%2CPHN2ZyB3aWR0aD0iMTYiIGhlaWdodD0iMTYiIHZpZXdCb3g9IjAgMCAxNiAxNiIgZmlsbD0ibm9uZSIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIj4KPHBhdGggZD0iTTQuOTYxNTYgMS42MDAxSDIuMjQxNTZDMS44ODgxIDEuNjAwMSAxLjYwMTU2IDEuODg2NjQgMS42MDE1NiAyLjI0MDFWNC45NjAxQzEuNjAxNTYgNS4zMTM1NiAxLjg4ODEgNS42MDAxIDIuMjQxNTYgNS42MDAxSDQuOTYxNTZDNS4zMTUwMiA1LjYwMDEgNS42MDE1NiA1LjMxMzU2IDUuNjAxNTYgNC45NjAxVjIuMjQwMUM1LjYwMTU2IDEuODg2NjQgNS4zMTUwMiAxLjYwMDEgNC45NjE1NiAxLjYwMDFaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00Ljk2MTU2IDEwLjM5OTlIMi4yNDE1NkMxLjg4ODEgMTAuMzk5OSAxLjYwMTU2IDEwLjY4NjQgMS42MDE1NiAxMS4wMzk5VjEzLjc1OTlDMS42MDE1NiAxNC4xMTM0IDEuODg4MSAxNC4zOTk5IDIuMjQxNTYgMTQuMzk5OUg0Ljk2MTU2QzUuMzE1MDIgMTQuMzk5OSA1LjYwMTU2IDE0LjExMzQgNS42MDE1NiAxMy43NTk5VjExLjAzOTlDNS42MDE1NiAxMC42ODY0IDUuMzE1MDIgMTAuMzk5OSA0Ljk2MTU2IDEwLjM5OTlaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik0xMy43NTg0IDEuNjAwMUgxMS4wMzg0QzEwLjY4NSAxLjYwMDEgMTAuMzk4NCAxLjg4NjY0IDEwLjM5ODQgMi4yNDAxVjQuOTYwMUMxMC4zOTg0IDUuMzEzNTYgMTAuNjg1IDUuNjAwMSAxMS4wMzg0IDUuNjAwMUgxMy43NTg0QzE0LjExMTkgNS42MDAxIDE0LjM5ODQgNS4zMTM1NiAxNC4zOTg0IDQuOTYwMVYyLjI0MDFDMTQuMzk4NCAxLjg4NjY0IDE0LjExMTkgMS42MDAxIDEzLjc1ODQgMS42MDAxWiIgZmlsbD0iI2ZmZiIvPgo8cGF0aCBkPSJNNCAxMkwxMiA0TDQgMTJaIiBmaWxsPSIjZmZmIi8%2BCjxwYXRoIGQ9Ik00IDEyTDEyIDQiIHN0cm9rZT0iI2ZmZiIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIvPgo8L3N2Zz4K&amp;logoColor=ffffff)](https://zread.ai/xerrors/Yuxi-Know)
[![demo](https://img.shields.io/badge/demo-00A1D6.svg?style=flat&amp;logo=bilibili&amp;logoColor=white)](https://www.bilibili.com/video/BV1DF14BTETq/)


&lt;a href=&quot;https://trendshift.io/repositories/15845&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://trendshift.io/api/badge/repositories/15845&quot; alt=&quot;Yuxi-Know | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
&lt;/a&gt;

[**ÊñáÊ°£‰∏≠ÂøÉ**](https://xerrors.github.io/Yuxi-Know/) |
[**ËßÜÈ¢ëÊºîÁ§∫**](https://www.bilibili.com/video/BV1DF14BTETq/)

&lt;/div&gt;


## Ê†∏ÂøÉÁâπÊÄß

- **Êô∫ËÉΩ‰ΩìÂºÄÂèë**ÔºöÂü∫‰∫é LangGraph v1 ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÊû∂ÊûÑÔºåÊîØÊåÅÂ≠êÊô∫ËÉΩ‰Ωì„ÄÅÂ∑•ÂÖ∑Ë∞ÉÁî®‰∏é‰∏≠Èó¥‰ª∂Êú∫Âà∂
- **Áü•ËØÜÂ∫ìÔºàRAGÔºâ**ÔºöÂ§öÊ†ºÂºèÊñáÊ°£‰∏ä‰º†ÔºåÊîØÊåÅ Embedding / Rerank ÈÖçÁΩÆÂèäÁü•ËØÜÂ∫ìËØÑ‰º∞
- **Áü•ËØÜÂõæË∞±**ÔºöÂü∫‰∫é LightRAG ÁöÑÂõæË∞±ÊûÑÂª∫‰∏éÂèØËßÜÂåñÔºåÊîØÊåÅÂ±ûÊÄßÂõæË∞±Âπ∂ÂèÇ‰∏éÊô∫ËÉΩ‰ΩìÊé®ÁêÜ
- **Âπ≥Âè∞‰∏éÂ∑•Á®ãÂåñ**ÔºöVue + FastAPI Êû∂ÊûÑÔºåÊîØÊåÅÊöóÈªëÊ®°Âºè„ÄÅDocker ‰∏éÁîü‰∫ßÁ∫ßÈÉ®ÁΩ≤


## ‰Ω†ÂèØ‰ª•Áî®ËØ≠ÊûêÂÅö‰ªÄ‰πàÔºü

- ÊûÑÂª∫ **Èù¢ÂêëÁúüÂÆû‰∏öÂä°ÁöÑ RAG + Áü•ËØÜÂõæË∞±Êô∫ËÉΩ‰Ωì**
- Â∞Ü PDF / Word / Markdown / ÂõæÁâáÂø´ÈÄüËΩ¨Âåñ‰∏∫ÂèØÊé®ÁêÜÁöÑÁü•ËØÜÂ∫ì
- Ëá™Âä®ÔºàLightRAGÔºâÊàñÊâãÂä®ÊûÑÂª∫Áü•ËØÜÂõæË∞±ÔºåÂπ∂Áî®‰∫éÊô∫ËÉΩ‰ΩìÊé®ÁêÜ
- ‰ΩøÁî® LangGraph v1 ÊûÑÂª∫Â§öÊô∫ËÉΩ‰Ωì / Â≠êÊô∫ËÉΩ‰ΩìÁ≥ªÁªü

## ÊúÄÊñ∞Âä®ÊÄÅ

&lt;details&gt;
&lt;summary&gt;[2026/01/24] v0.5.0-beta ÁâàÊú¨ÂèëÂ∏É&lt;/summary&gt;

### Êñ∞Â¢û

- ‰ºòÂåñ OCR ‰ΩìÈ™åÂπ∂Êñ∞Â¢ûÂØπ Deepseek OCR ÁöÑÊîØÊåÅ
- ‰ºòÂåñ RAG Ê£ÄÁ¥¢ÔºåÊîØÊåÅÊ†πÊçÆÊñá‰ª∂ pattern Êù•Ê£ÄÁ¥¢ÔºàAgentic ModeÔºâ
- ÈáçÊûÑÊô∫ËÉΩ‰ΩìÂØπ‰∫é‚ÄúÂ∑•ÂÖ∑ÂèòÊõ¥/Ê®°ÂûãÂèòÊõ¥‚ÄùÁöÑÂ§ÑÁêÜÈÄªËæëÔºåÊó†ÈúÄÂØºÂÖ•Êõ¥Â§çÊùÇÁöÑ‰∏≠Èó¥‰ª∂
- ÈáçÊûÑÁü•ËØÜÂ∫ìÁöÑ Agentic ÈÖçÁΩÆÈÄªËæëÔºå‰∏é Tools Ëß£ËÄ¶
- Â∞ÜÂ∑•ÂÖ∑‰∏éÁü•ËØÜÂ∫ìËß£ËÄ¶ÔºåÂú® context ‰∏≠Â∞±ÂÆåÊàêËß£ËÄ¶ÔºåËôΩÁÑ∂ÊúÄÁªàÈÉΩÊòØÂú® Agent ‰∏≠ÁöÑ get_tools ‰∏≠Ëé∑Âèñ
- ‰ºòÂåñchunkÈÄªËæëÔºåÁßªÈô§ QA ÂàÜÂâ≤ÔºåÈõÜÊàêÂà∞ÊôÆÈÄöÂàÜÂùó‰∏≠ÔºåÂπ∂‰ºòÂåñÂèØËßÜÂåñÈÄªËæë
- ÈáçÊûÑÁü•ËØÜÂ∫ìÂ§ÑÁêÜÈÄªËæëÔºåÂàÜ‰∏∫ ‰∏ä‰º†‚ÄîËß£Êûê‚ÄîÂÖ•Â∫ì ‰∏â‰∏™Èò∂ÊÆµ
- ÈáçÊûÑ MCP Áõ∏ÂÖ≥ÈÖçÁΩÆÔºå‰ΩøÁî®Êï∞ÊçÆÂ∫ìÊù•ÊéßÂà∂ [#469](https://github.com/xerrors/Yuxi-Know/pull/469)
- ‰ΩøÁî® docling Ëß£Êûê office Êñá‰ª∂Ôºàdocx/xlsx/pptxÔºâ
- ‰ºòÂåñÂêéÁ´ØÁöÑ‰æùËµñÔºåÂáèÂ∞ëÈïúÂÉè‰ΩìÁßØ [#428](https://github.com/xerrors/Yuxi-Know/issues/428)
- ‰ºòÂåñ liaghtrag ÁöÑÁü•ËØÜÂ∫ìË∞ÉÁî®ÁªìÊûúÔºåÊèê‰æõ content/graph/both Â§ö‰∏™ÈÄâÈ°π
- ‰ºòÂåñÊï∞ÊçÆÂ∫ìÊü•ËØ¢Â∑•ÂÖ∑ÔºåÂèØÈÄöËøáËÆæËÆ°ÁéØÂ¢ÉÂèòÈáèÊ∑ªÂä†ÊèèËø∞ÔºåËÆ©Ê®°ÂûãÊõ¥Â•ΩÁöÑË∞ÉÁî®

### ‰øÆÂ§ç

- ‰øÆÂ§çÁü•ËØÜÂõæË∞±‰∏ä‰º†ÁöÑÂêëÈáèÈÖçÁΩÆÈîôËØØÔºåÂπ∂Êñ∞Â¢ûÊ®°ÂûãÈÄâÊã©‰ª•Âèä batch size ÈÄâÊã©
- ‰øÆÂ§çÈÉ®ÂàÜÂú∫ÊôØ‰∏ãËé∑ÂèñÂ∑•ÂÖ∑ÂàóË°®Êä•Èîô [#470](https://github.com/xerrors/Yuxi-Know/pull/470)
- ‰øÆÊîπÊñπÊ≥ïÂ§áÊ≥®‰ø°ÊÅØ [#478](https://github.com/xerrors/Yuxi-Know/pull/478)
- ‰øÆÂ§çÂ§öÊ¨° human-in-the-loop ÁöÑÊ∏≤ÊüìËß£ÊûêÈóÆÈ¢ò [#453](https://github.com/xerrors/Yuxi-Know/issues/453) [#475](https://github.com/xerrors/Yuxi-Know/pull/475)

&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;[2025/12/19] v0.4.0 ÁâàÊú¨ÂèëÂ∏É&lt;/summary&gt;

### Êñ∞Â¢û
- Êñ∞Â¢ûÂØπ‰∫é‰∏ä‰º†ÈôÑ‰ª∂ÁöÑÊô∫ËÉΩ‰Ωì‰∏≠Èó¥‰ª∂ÔºåËØ¶ËßÅ[ÊñáÊ°£](https://xerrors.github.io/Yuxi-Know/latest/advanced/agents-config.html#%E6%96%87%E4%BB%B6%E4%B8%8A%E4%BC%A0%E4%B8%AD%E9%97%B4%E4%BB%B6)
- Êñ∞Â¢ûÂ§öÊ®°ÊÄÅÊ®°ÂûãÊîØÊåÅÔºàÂΩìÂâç‰ªÖÊîØÊåÅÂõæÁâáÔºâÔºåËØ¶ËßÅ[ÊñáÊ°£](https://xerrors.github.io/Yuxi-Know/latest/advanced/agents-config.html#%E5%A4%9A%E6%A8%A1%E6%80%81%E5%9B%BE%E7%89%87%E6%94%AF%E6%8C%81)
- Êñ∞Âª∫ DeepAgents Êô∫ËÉΩ‰ΩìÔºàÊ∑±Â∫¶ÂàÜÊûêÊô∫ËÉΩ‰ΩìÔºâÔºåÊîØÊåÅ todoÔºåfiles Á≠âÊ∏≤ÊüìÔºåÊîØÊåÅÊñá‰ª∂ÁöÑ‰∏ãËΩΩ„ÄÇ
- Êñ∞Â¢ûÂü∫‰∫éÁü•ËØÜÂ∫ìÊñá‰ª∂ÁîüÊàêÊÄùÁª¥ÂØºÂõæÂäüËÉΩÔºà[#335](https://github.com/xerrors/Yuxi-Know/pull/335#issuecomment-3530976425)Ôºâ
- Êñ∞Â¢ûÂü∫‰∫éÁü•ËØÜÂ∫ìÊñá‰ª∂ÁîüÊàêÁ§∫‰æãÈóÆÈ¢òÂäüËÉΩÔºà[#335](https://github.com/xerrors/Yuxi-Know/pull/335#issuecomment-3530976425)Ôºâ
- Êñ∞Â¢ûÁü•ËØÜÂ∫ìÊîØÊåÅÊñá‰ª∂Â§π/ÂéãÁº©ÂåÖ‰∏ä‰º†ÁöÑÂäüËÉΩÔºà[#335](https://github.com/xerrors/Yuxi-Know/pull/335#issuecomment-3530976425)Ôºâ
- Êñ∞Â¢ûËá™ÂÆö‰πâÊ®°ÂûãÊîØÊåÅ„ÄÅÊñ∞Â¢û dashscope rerank/embeddings Ê®°ÂûãÁöÑÊîØÊåÅ
- Êñ∞Â¢ûÊñáÊ°£Ëß£ÊûêÁöÑÂõæÁâáÊîØÊåÅÔºåÂ∑≤ÊîØÊåÅ MinerU Officical„ÄÅDocs„ÄÅMarkdown Zip Ê†ºÂºè
- Êñ∞Â¢ûÊöóËâ≤Ê®°ÂºèÊîØÊåÅÂπ∂Ë∞ÉÊï¥Êï¥‰Ωì UIÔºà[#343](https://github.com/xerrors/Yuxi-Know/pull/343)Ôºâ
- Êñ∞Â¢ûÁü•ËØÜÂ∫ìËØÑ‰º∞ÂäüËÉΩÔºåÊîØÊåÅÂØºÂÖ•ËØÑ‰º∞Âü∫ÂáÜÊàñËÄÖËá™Âä®ÊûÑÂª∫ËØÑ‰º∞Âü∫ÂáÜÔºàÁõÆÂâç‰ªÖÊîØÊåÅ Milvus Á±ªÂûãÁü•ËØÜÂ∫ìÔºâËØ¶ËßÅ[ÊñáÊ°£](https://xerrors.github.io/Yuxi-Know/latest/intro/evaluation.html)
- Êñ∞Â¢ûÂêåÂêçÊñá‰ª∂Â§ÑÁêÜÈÄªËæëÔºöÈÅáÂà∞ÂêåÂêçÊñá‰ª∂ÂàôÂú®‰∏ä‰º†Âå∫ÂüüÊèêÁ§∫ÔºåÊòØÂê¶Âà†Èô§ÊóßÊñá‰ª∂
- Êñ∞Â¢ûÁîü‰∫ßÁéØÂ¢ÉÈÉ®ÁΩ≤ËÑöÊú¨ÔºåÂõ∫ÂÆö python ‰æùËµñÁâàÊú¨ÔºåÊèêÂçáÈÉ®ÁΩ≤Á®≥ÂÆöÊÄß
- ‰ºòÂåñÂõæË∞±ÂèØËßÜÂåñÊñπÂºèÔºåÁªü‰∏ÄÂõæË∞±Êï∞ÊçÆÁªìÊûÑÔºåÁªü‰∏Ä‰ΩøÁî®Âü∫‰∫é G6 ÁöÑÂèØËßÜÂåñÊñπÂºèÔºåÂêåÊó∂ÊîØÊåÅ‰∏ä‰º†Â∏¶Â±ûÊÄßÁöÑÂõæË∞±Êñá‰ª∂ÔºåËØ¶ËßÅ[ÊñáÊ°£](https://xerrors.github.io/Yuxi-Know/latest/intro/knowledge-base.html#_1-%E4%BB%A5%E4%B8%89%E5%85%83%E7%BB%84%E5%BD%A2%E5%BC%8F%E5%AF%BC%E5%85%A5)
- ‰ºòÂåñ DBManager / ConversationManagerÔºåÊîØÊåÅÂºÇÊ≠•Êìç‰Ωú
- ‰ºòÂåñ Áü•ËØÜÂ∫ìËØ¶ÊÉÖÈ°µÈù¢ÔºåÊõ¥Âä†ÁÆÄÊ¥ÅÊ∏ÖÊô∞ÔºåÂ¢ûÂº∫Êñá‰ª∂‰∏ãËΩΩÂäüËÉΩ

### ‰øÆÂ§ç
- ‰øÆÂ§çÈáçÊéíÂ∫èÊ®°ÂûãÂÆûÈôÖÊú™ÁîüÊïàÁöÑÈóÆÈ¢ò
- ‰øÆÂ§çÊ∂àÊÅØ‰∏≠Êñ≠ÂêéÊ∂àÊÅØÊ∂àÂ§±ÁöÑÈóÆÈ¢òÔºåÂπ∂ÊîπÂñÑÂºÇÂ∏∏ÊïàÊûú
- ‰øÆÂ§çÂΩìÂâçÁâàÊú¨Â¶ÇÊûúË∞ÉÁî®ÁªìÊûú‰∏∫Á©∫ÁöÑÊó∂ÂÄôÔºåÂ∑•ÂÖ∑Ë∞ÉÁî®Áä∂ÊÄÅ‰ºö‰∏ÄÁõ¥Â§Ñ‰∫éË∞ÉÁî®Áä∂ÊÄÅÔºåÂ∞ΩÁÆ°Ë∞ÉÁî®ÊòØÊàêÂäüÁöÑ
- ‰øÆÂ§çÊ£ÄÁ¥¢ÈÖçÁΩÆÂÆûÈôÖÊú™ÁîüÊïàÁöÑÈóÆÈ¢ò

### Á†¥ÂùèÊÄßÊõ¥Êñ∞

- ÁßªÈô§ Chroma ÁöÑÊîØÊåÅÔºåÂΩìÂâçÁâàÊú¨Ê†áËÆ∞‰∏∫ÁßªÈô§
- ÁßªÈô§Ê®°ÂûãÈÖçÁΩÆÈ¢ÑËÆæÁöÑ TogetherAI
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;[2025/11/05] v0.3.0 ÁâàÊú¨ÂèëÂ∏É&lt;/summary&gt;

- ÂÖ®Èù¢ÈÄÇÈÖç LangChain/LangGraph v1 ÁâàÊú¨ÁöÑÁâπÊÄßÔºå‰ΩøÁî® create_agent ÂàõÂª∫Êô∫ËÉΩ‰ΩìÂÖ•Âè£„ÄÇ
- ÊñáÊ°£Ëß£ÊûêÂçáÁ∫ßÔºåÈÄÇÈÖç mineru-2.6 ‰ª•Âèä mineru-api„ÄÇ
- Êõ¥Â§öÊô∫ËÉΩ‰ΩìÂºÄÂèëÂ•ó‰ª∂ ‰∏≠Èó¥‰ª∂„ÄÅÂ≠êÊô∫ËÉΩ‰ΩìÔºåÊõ¥ÁÆÄÊ¥ÅÔºåÊõ¥Êòì‰∏äÊâã„ÄÇ
&lt;/details&gt;

&lt;img width=&quot;1846&quot; height=&quot;434&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/ccbd2cbf-574a-4cd3-baac-167b3c619b6e&quot; /&gt;




## Âø´ÈÄüÂºÄÂßã

ÂÖãÈöÜ‰ª£Á†ÅÔºåÂπ∂ÂàùÂßãÂåñ

```
git clone --branch v0.4.4 --depth 1 https://github.com/xerrors/Yuxi-Know.git
cd Yuxi-Know

# Linux/macOS
./scripts/init.sh

# Windows PowerShell
.\scripts\init.ps1
```

ÁÑ∂ÂêéÈúÄË¶Å‰ΩøÁî® docker ÂêØÂä®È°πÁõÆ

```
docker compose up --build
```

Á≠âÂæÖÂêØÂä®ÂÆåÊàêÂêéÔºåËÆøÈóÆ `http://localhost:5173`

## Á§∫‰æã‰∏éÊºîÁ§∫


&lt;img width=&quot;4420&quot; height=&quot;2510&quot; alt=&quot;image&quot; src=&quot;https://github.com/user-attachments/assets/76d58c8f-e4ef-4373-8ab6-7c80da568910&quot; /&gt;
&lt;br&gt;
&lt;img width=&quot;10116&quot; height=&quot;5751&quot; alt=&quot;11111&quot; src=&quot;https://github.com/user-attachments/assets/d3e4fe09-fa48-4686-93ea-2c50300ade21&quot; /&gt;
&lt;br&gt;
&lt;img width=&quot;10116&quot; height=&quot;5751&quot; alt=&quot;22222&quot; src=&quot;https://github.com/user-attachments/assets/734a7cce-8b38-48ae-8e21-ca88996e5dde&quot; /&gt;

&lt;br&gt;
&lt;img width=&quot;10116&quot; height=&quot;5751&quot; alt=&quot;1212&quot; src=&quot;https://github.com/user-attachments/assets/06d56525-69bf-463a-8360-286b2cf8796f&quot; /&gt;
&lt;br&gt;
&lt;img width=&quot;10116&quot; height=&quot;5751&quot; alt=&quot;44444&quot; src=&quot;https://github.com/user-attachments/assets/e390ec4b-8690-4aee-bbb2-3536f7f67dc9&quot; /&gt;


## ÂèÇ‰∏éË¥°ÁåÆ

ÊÑüË∞¢ÊâÄÊúâË¥°ÁåÆËÄÖÁöÑÊîØÊåÅÔºÅ

&lt;a href=&quot;https://github.com/xerrors/Yuxi-Know/contributors&quot;&gt;
  &lt;img src=&quot;https://contrib.rocks/image?repo=xerrors/Yuxi-Know&amp;max=100&amp;columns=15&quot; /&gt;
&lt;/a&gt;


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=xerrors/Yuxi-Know)](https://star-history.com/#xerrors/Yuxi-Know)

## üìÑ ËÆ∏ÂèØËØÅ

Êú¨È°πÁõÆÈááÁî® MIT ËÆ∏ÂèØËØÅ - Êü•Áúã [LICENSE](LICENSE) Êñá‰ª∂‰∫ÜËß£ËØ¶ÊÉÖ„ÄÇ

---

&lt;div align=&quot;center&quot;&gt;

**Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπÊÇ®ÊúâÂ∏ÆÂä©ÔºåËØ∑‰∏çË¶ÅÂøòËÆ∞ÁªôÊàë‰ª¨‰∏Ä‰∏™ ‚≠êÔ∏è**

[Êä•ÂëäÈóÆÈ¢ò](https://github.com/xerrors/Yuxi-Know/issues) | [ÂäüËÉΩËØ∑Ê±Ç](https://github.com/xerrors/Yuxi-Know/issues) | [ËÆ®ËÆ∫](https://github.com/xerrors/Yuxi-Know/discussions)

&lt;/div&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[jingyaogong/minimind]]></title>
            <link>https://github.com/jingyaogong/minimind</link>
            <guid>https://github.com/jingyaogong/minimind</guid>
            <pubDate>Wed, 04 Feb 2026 00:05:56 GMT</pubDate>
            <description><![CDATA[üöÄüöÄ „ÄåÂ§ßÊ®°Âûã„Äç2Â∞èÊó∂ÂÆåÂÖ®‰ªé0ËÆ≠ÁªÉ26MÁöÑÂ∞èÂèÇÊï∞GPTÔºÅüåè Train a 26M-parameter GPT from scratch in just 2h!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/jingyaogong/minimind">jingyaogong/minimind</a></h1>
            <p>üöÄüöÄ „ÄåÂ§ßÊ®°Âûã„Äç2Â∞èÊó∂ÂÆåÂÖ®‰ªé0ËÆ≠ÁªÉ26MÁöÑÂ∞èÂèÇÊï∞GPTÔºÅüåè Train a 26M-parameter GPT from scratch in just 2h!</p>
            <p>Language: Python</p>
            <p>Stars: 38,636</p>
            <p>Forks: 4,640</p>
            <p>Stars today: 84 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

![logo](./images/logo.png)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

![visitors](https://visitor-badge.laobi.icu/badge?page_id=jingyaogong/minimind)
[![GitHub Repo stars](https://img.shields.io/github/stars/jingyaogong/minimind?style=social)](https://github.com/jingyaogong/minimind/stargazers)
[![GitHub Code License](https://img.shields.io/github/license/jingyaogong/minimind)](LICENSE)
[![GitHub last commit](https://img.shields.io/github/last-commit/jingyaogong/minimind)](https://github.com/jingyaogong/minimind/commits/master)
[![GitHub pull request](https://img.shields.io/badge/PRs-welcome-blue)](https://github.com/jingyaogong/minimind/pulls)
[![Collection](https://img.shields.io/badge/ü§ó-MiniMind%20%20Collection-blue)](https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

![GitHub Trend](https://trendshift.io/api/badge/repositories/12586)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;h3&gt;&quot;Â§ßÈÅìËá≥ÁÆÄ&quot;&lt;/h3&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

‰∏≠Êñá | [English](./README_en.md)

&lt;/div&gt;

* Ê≠§ÂºÄÊ∫êÈ°πÁõÆÊó®Âú®ÂÆåÂÖ®‰ªé0ÂºÄÂßãÔºå‰ªÖÁî®3ÂùóÈí±ÊàêÊú¨ + 2Â∞èÊó∂ÔºÅÂç≥ÂèØËÆ≠ÁªÉÂá∫‰ªÖ‰∏∫25.8MÁöÑË∂ÖÂ∞èËØ≠Ë®ÄÊ®°Âûã**MiniMind**„ÄÇ
* **MiniMind**Á≥ªÂàóÊûÅÂÖ∂ËΩªÈáèÔºåÊúÄÂ∞èÁâàÊú¨‰ΩìÁßØÊòØ GPT-3 ÁöÑ $\frac{1}{7000}$ÔºåÂäõÊ±ÇÂÅöÂà∞ÊúÄÊôÆÈÄöÁöÑ‰∏™‰∫∫GPU‰πüÂèØÂø´ÈÄüËÆ≠ÁªÉ„ÄÇ
* È°πÁõÆÂêåÊó∂ÂºÄÊ∫ê‰∫ÜÂ§ßÊ®°ÂûãÁöÑÊûÅÁÆÄÁªìÊûÑ-ÂåÖÂê´ÊãìÂ±ïÂÖ±‰∫´Ê∑∑Âêà‰∏ìÂÆ∂(MoE)„ÄÅÊï∞ÊçÆÈõÜÊ∏ÖÊ¥ó„ÄÅÈ¢ÑËÆ≠ÁªÉ(Pretrain)„ÄÅÁõëÁù£ÂæÆË∞É(SFT)„ÄÅLoRAÂæÆË∞É„ÄÅÁõ¥Êé•ÂÅèÂ•Ω‰ºòÂåñ(DPO)„ÄÅÂº∫ÂåñÂ≠¶‰π†ËÆ≠ÁªÉ(RLAIF: PPO/GRPOÁ≠â)„ÄÅÊ®°ÂûãËí∏È¶èÁ≠âÂÖ®ËøáÁ®ã‰ª£Á†Å„ÄÇ
* **MiniMind**ÂêåÊó∂ÊãìÂ±ï‰∫ÜËßÜËßâÂ§öÊ®°ÊÄÅÁöÑVLM: [MiniMind-V](https://github.com/jingyaogong/minimind-v)„ÄÇ
* È°πÁõÆÊâÄÊúâÊ†∏ÂøÉÁÆóÊ≥ï‰ª£Á†ÅÂùá‰ªé0‰ΩøÁî®PyTorchÂéüÁîüÈáçÊûÑÔºÅ‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∫ìÊèê‰æõÁöÑÊäΩË±°Êé•Âè£„ÄÇ
* Ëøô‰∏ç‰ªÖÊòØÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ®Èò∂ÊÆµÂºÄÊ∫êÂ§çÁé∞Ôºå‰πüÊòØ‰∏Ä‰∏™ÂÖ•Èó®LLMÁöÑÊïôÁ®ã„ÄÇ
* Â∏åÊúõÊ≠§È°πÁõÆËÉΩ‰∏∫ÊâÄÊúâ‰∫∫Êèê‰æõ‰∏Ä‰∏™ÊäõÁ†ñÂºïÁéâÁöÑÁ§∫‰æãÔºå‰∏ÄËµ∑ÊÑüÂèóÂàõÈÄ†ÁöÑ‰πêË∂£ÔºÅÊé®Âä®Êõ¥ÂπøÊ≥õAIÁ§æÂå∫ÁöÑËøõÊ≠•ÔºÅ

&gt; ‰∏∫Èò≤Ê≠¢ËØØËß£Ôºå‚Äú2Â∞èÊó∂‚Äù Âü∫‰∫éNVIDIA 3090Á°¨‰ª∂ËÆæÂ§áÔºàÂçïÂç°ÔºâÊµãËØïÔºå‚Äú3ÂùóÈí±‚ÄùÊåáGPUÊúçÂä°Âô®ÁßüÁî®ÊàêÊú¨ÔºåÂÖ∑‰ΩìËßÑÊ†ºËØ¶ÊÉÖËßÅ‰∏ãÊñá„ÄÇ

---


&lt;div align=&quot;center&quot;&gt;

![minimind2](./images/minimind2.gif)

[üîóüçìÊé®ÁêÜÊ®°Âûã](https://www.modelscope.cn/studios/gongjy/MiniMind-Reasoning) | [üîóü§ñÂ∏∏ËßÑÊ®°Âûã](https://www.modelscope.cn/studios/gongjy/MiniMind) | [üîóüéûÔ∏èËßÜÈ¢ë‰ªãÁªç](https://www.bilibili.com/video/BV12dHPeqE72/?share_source=copy_web&amp;vd_source=670c2504f88726f8cf4a21ef6147c0e8)


&lt;div align=&quot;center&quot;&gt;
  &lt;table&gt;
    &lt;tr&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://huggingface.co/collections/jingyaogong/minimind-66caf8d999f5c7fa64f399e5&quot; style=&quot;text-decoration: none;&quot;&gt;
          &lt;img src=&quot;./images/and_huggingface.png&quot; alt=&quot;Hugging Face Logo&quot; style=&quot;vertical-align: middle; width: auto; max-width: 100%;&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
      &lt;td align=&quot;center&quot;&gt;
        &lt;a href=&quot;https://www.modelscope.cn/profile/gongjy&quot; style=&quot;text-decoration: none;&quot;&gt;
          &lt;img src=&quot;./images/and_modelscope.png&quot; alt=&quot;ModelScope Logo&quot; style=&quot;vertical-align: middle; width: auto; max-width: 100%;&quot; /&gt;
        &lt;/a&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/table&gt;
&lt;/div&gt;


&lt;/div&gt;

# üìå Introduction

Â§ßËØ≠Ë®ÄÊ®°ÂûãÔºàLarge Language Model, LLMÔºâÁöÑÂá∫Áé∞ÂºïÂèë‰∫ÜÂÖ®‰∏ñÁïåÂØπAIÁöÑÁ©∫ÂâçÂÖ≥Ê≥®„ÄÇ
Êó†ËÆ∫ÊòØChatGPT„ÄÅDeepSeekËøòÊòØQwenÔºåÈÉΩ‰ª•ÂÖ∂ÊÉäËâ≥ÁöÑÊïàÊûú‰ª§‰∫∫Âèπ‰∏∫ËßÇÊ≠¢„ÄÇ
ÁÑ∂ËÄåÔºåÂä®ËæÑÊï∞Áôæ‰∫øÂèÇÊï∞ÁöÑÂ∫ûÂ§ßËßÑÊ®°Ôºå‰ΩøÂæóÂÆÉ‰ª¨ÂØπ‰∏™‰∫∫ËÆæÂ§áËÄåË®Ä‰∏ç‰ªÖÈöæ‰ª•ËÆ≠ÁªÉÔºåÁîöËá≥ËøûÈÉ®ÁΩ≤ÈÉΩÊòæÂæóÈÅ•‰∏çÂèØÂèä„ÄÇ
ÊâìÂºÄÂ§ßÊ®°ÂûãÁöÑ‚ÄúÈªëÁõíÂ≠ê‚ÄùÔºåÊé¢Á¥¢ÂÖ∂ÂÜÖÈÉ®Ëøê‰ΩúÊú∫Âà∂ÔºåÂ§ö‰πà‰ª§‰∫∫ÂøÉÊΩÆÊæéÊπÉÔºÅ
ÈÅóÊÜæÁöÑÊòØÔºå99%ÁöÑÊé¢Á¥¢Âè™ËÉΩÊ≠¢Ê≠•‰∫é‰ΩøÁî®LoRAÁ≠âÊäÄÊúØÂØπÁé∞ÊúâÂ§ßÊ®°ÂûãËøõË°åÂ∞ëÈáèÂæÆË∞ÉÔºåÂ≠¶‰π†‰∏Ä‰∫õÊñ∞Êåá‰ª§Êàñ‰ªªÂä°„ÄÇ
ËøôÂ∞±Â•ΩÊØîÊïôÁâõÈ°øÂ¶Ç‰Ωï‰ΩøÁî®21‰∏ñÁ∫™ÁöÑÊô∫ËÉΩÊâãÊú∫‚Äî‚ÄîËôΩÁÑ∂ÊúâË∂£ÔºåÂç¥ÂÆåÂÖ®ÂÅèÁ¶ª‰∫ÜÁêÜËß£Áâ©ÁêÜÊú¨Ë¥®ÁöÑÂàùË°∑„ÄÇ
‰∏éÊ≠§ÂêåÊó∂ÔºåÁ¨¨‰∏âÊñπÁöÑÂ§ßÊ®°ÂûãÊ°ÜÊû∂ÂíåÂ∑•ÂÖ∑Â∫ìÔºåÂ¶Çtransformers+trlÔºåÂá†‰πéÂè™Êö¥Èú≤‰∫ÜÈ´òÂ∫¶ÊäΩË±°ÁöÑÊé•Âè£„ÄÇ
ÈÄöËøáÁü≠Áü≠10Ë°å‰ª£Á†ÅÔºåÂ∞±ËÉΩÂÆåÊàê‚ÄúÂä†ËΩΩÊ®°Âûã+Âä†ËΩΩÊï∞ÊçÆÈõÜ+Êé®ÁêÜ+Âº∫ÂåñÂ≠¶‰π†‚ÄùÁöÑÂÖ®ÊµÅÁ®ãËÆ≠ÁªÉ„ÄÇ
ËøôÁßçÈ´òÊïàÁöÑÂ∞ÅË£ÖÂõ∫ÁÑ∂‰æøÂà©Ôºå‰ΩÜ‰πüÂÉè‰∏ÄÊû∂È´òÈÄüÈ£ûËàπÔºåÂ∞ÜÂºÄÂèëËÄÖ‰∏éÂ∫ïÂ±ÇÂÆûÁé∞ÈöîÁ¶ªÂºÄÊù•ÔºåÈòªÁ¢ç‰∫ÜÊ∑±ÂÖ•Êé¢Á©∂LLMÊ†∏ÂøÉ‰ª£Á†ÅÁöÑÊú∫‰ºö„ÄÇ
ÁÑ∂ËÄåÔºå‚ÄúÁî®‰πêÈ´òÊãºÂá∫‰∏ÄÊû∂È£ûÊú∫ÔºåËøúÊØîÂùêÂú®Â§¥Á≠âËà±ÈáåÈ£ûË°åÊõ¥ËÆ©‰∫∫ÂÖ¥Â•ãÔºÅ‚Äù„ÄÇ
Êõ¥Á≥üÁ≥ïÁöÑÊòØÔºå‰∫íËÅîÁΩë‰∏äÂÖÖÊñ•ÁùÄÂ§ßÈáè‰ªòË¥πËØæÁ®ãÂíåËê•ÈîÄÂè∑Ôºå‰ª•ÊºèÊ¥ûÁôæÂá∫„ÄÅ‰∏ÄÁü•ÂçäËß£ÁöÑÂÜÖÂÆπÊé®ÈîÄAIÊïôÁ®ã„ÄÇ
Ê≠£Âõ†Â¶ÇÊ≠§ÔºåÊú¨È°πÁõÆÂàùË°∑ÊòØÊãâ‰ΩéLLMÁöÑÂ≠¶‰π†Èó®ÊßõÔºåËÆ©ÊØè‰∏™‰∫∫ÈÉΩËÉΩ‰ªéÁêÜËß£ÊØè‰∏ÄË°å‰ª£Á†ÅÂºÄÂßãÔºå
‰ªéÈõ∂ÂºÄÂßã‰∫≤ÊâãËÆ≠ÁªÉ‰∏Ä‰∏™ÊûÅÂ∞èÁöÑËØ≠Ë®ÄÊ®°Âûã„ÄÇÊòØÁöÑÔºå‰ªé**Èõ∂ÂºÄÂßãËÆ≠ÁªÉ**ÔºåËÄå‰∏çÊòØ‰ªÖ‰ªÖËøõË°å**Êé®ÁêÜ**ÔºÅ
ÊúÄ‰ΩéÂè™ÈúÄ3ÂùóÈí±‰∏çÂà∞ÁöÑÊúçÂä°Âô®ÊàêÊú¨ÔºåÂ∞±ËÉΩ‰∫≤Ë∫´‰ΩìÈ™å‰ªé0Âà∞1ÊûÑÂª∫‰∏Ä‰∏™ËØ≠Ë®ÄÊ®°ÂûãÁöÑÂÖ®ËøáÁ®ã„ÄÇ
‰∏ÄËµ∑ÊÑüÂèóÂàõÈÄ†ÁöÑ‰πêË∂£ÂêßÔºÅ

&gt; [!NOTE]
&gt; ÔºàÊà™Ëá≥2025-10ÔºâMiniMindÁ≥ªÂàóÂ∑≤ÂÆåÊàêÂ§ö‰∏™ÂûãÂè∑Ê®°ÂûãÁöÑÈ¢ÑËÆ≠ÁªÉÔºåÊúÄÂ∞è‰ªÖÈúÄ25.8MÔºà0.02BÔºâÔºåÂç≥ÂèØÂÖ∑Â§áÊµÅÁïÖÂØπËØùËÉΩÂäõÔºÅ

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;Models List&lt;/summary&gt;

| Ê®°Âûã (Â§ßÂ∞è)                 | Êé®ÁêÜÂç†Áî® (Á∫¶) | Release    | 
|-------------------------|----------|------------|
| MiniMind2-small (26M)   | 0.5 GB   | 2025.04.26 |
| MiniMind2-MoE (145M)    | 1.0 GB   | 2025.04.26 |
| MiniMind2 (104M)        | 1.0 GB   | 2025.04.26 |
| minimind-v1-small (26M) | 0.5 GB   | 2024.08.28 |
| minimind-v1-moe (4√ó26M) | 1.0 GB   | 2024.09.17 |
| minimind-v1 (108M)      | 1.0 GB   | 2024.09.01 |

&lt;/details&gt;

**È°πÁõÆÂåÖÂê´**

- MiniMind-LLMÁªìÊûÑÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºàDense+MoEÊ®°ÂûãÔºâ„ÄÇ
- ÂåÖÂê´TokenizerÂàÜËØçÂô®ËØ¶ÁªÜËÆ≠ÁªÉ‰ª£Á†Å„ÄÇ
- ÂåÖÂê´Pretrain„ÄÅSFT„ÄÅLoRA„ÄÅRLHF-DPO„ÄÅRLAIF(PPO/GRPO/SPO)„ÄÅÊ®°ÂûãËí∏È¶èÁöÑÂÖ®ËøáÁ®ãËÆ≠ÁªÉ‰ª£Á†Å„ÄÇ
- Êî∂ÈõÜ„ÄÅËí∏È¶è„ÄÅÊï¥ÁêÜÂπ∂Ê∏ÖÊ¥óÂéªÈáçÊâÄÊúâÈò∂ÊÆµÁöÑÈ´òË¥®ÈáèÊï∞ÊçÆÈõÜÔºå‰∏îÂÖ®ÈÉ®ÂºÄÊ∫ê„ÄÇ
- ‰ªé0ÂÆûÁé∞È¢ÑËÆ≠ÁªÉ„ÄÅÊåá‰ª§ÂæÆË∞É„ÄÅLoRA„ÄÅDPO/PPO/GRPO/SPOÂº∫ÂåñÂ≠¶‰π†ÔºåÁôΩÁõíÊ®°ÂûãËí∏È¶è„ÄÇÂÖ≥ÈîÆÁÆóÊ≥ïÂá†‰πé‰∏ç‰æùËµñÁ¨¨‰∏âÊñπÂ∞ÅË£ÖÁöÑÊ°ÜÊû∂Ôºå‰∏îÂÖ®ÈÉ®ÂºÄÊ∫ê„ÄÇ
- ÂêåÊó∂ÂÖºÂÆπ`transformers`„ÄÅ`trl`„ÄÅ`peft`Á≠âÁ¨¨‰∏âÊñπ‰∏ªÊµÅÊ°ÜÊû∂„ÄÇ
- ËÆ≠ÁªÉÊîØÊåÅÂçïÊú∫ÂçïÂç°„ÄÅÂçïÊú∫Â§öÂç°(DDP„ÄÅDeepSpeed)ËÆ≠ÁªÉÔºåÊîØÊåÅwandb/swanlabÂèØËßÜÂåñËÆ≠ÁªÉÊµÅÁ®ã„ÄÇÊîØÊåÅÂä®ÊÄÅÂêØÂÅúËÆ≠ÁªÉ„ÄÇ
- Âú®Á¨¨‰∏âÊñπÊµãËØÑÊ¶úÔºàC-Eval„ÄÅC-MMLU„ÄÅOpenBookQAÁ≠âÔºâËøõË°åÊ®°ÂûãÊµãËØïÔºåÊîØÊåÅYaRNÁÆóÊ≥ïÊâßË°åRoPEÈïøÊñáÊú¨Â§ñÊé®„ÄÇ
- ÂÆûÁé∞Openai-ApiÂçèËÆÆÁöÑÊûÅÁÆÄÊúçÂä°Á´ØÔºå‰æø‰∫éÈõÜÊàêÂà∞Á¨¨‰∏âÊñπChatUI‰ΩøÁî®ÔºàFastGPT„ÄÅOpen-WebUIÁ≠âÔºâ„ÄÇ
- Âü∫‰∫éstreamlitÂÆûÁé∞ÊúÄÁÆÄËÅäÂ§©WebUIÂâçÁ´Ø„ÄÇ
- ÂÖ®Èù¢ÂÖºÂÆπÁ§æÂå∫ÁÉ≠Èó®`llama.cpp`„ÄÅ`vllm`„ÄÅ`ollama`Êé®ÁêÜÂºïÊìéÊàñ`Llama-Factory`ËÆ≠ÁªÉÊ°ÜÊû∂„ÄÇ
- Â§çÁé∞(Ëí∏È¶è/RL)Â§ßÂûãÊé®ÁêÜÊ®°ÂûãDeepSeek-R1ÁöÑMiniMind-ReasonÊ®°ÂûãÔºå**Êï∞ÊçÆ+Ê®°Âûã**ÂÖ®ÈÉ®ÂºÄÊ∫êÔºÅ

Â∏åÊúõÊ≠§ÂºÄÊ∫êÈ°πÁõÆÂèØ‰ª•Â∏ÆÂä©LLMÂàùÂ≠¶ËÄÖÂø´ÈÄüÂÖ•Èó®ÔºÅ

### üëâ**Êõ¥Êñ∞Êó•Âøó**

&lt;details close&gt; 
&lt;summary&gt; &lt;b&gt;2025-10-24&lt;/b&gt; &lt;/summary&gt;

- üî• Êñ∞Â¢ûRLAIFËÆ≠ÁªÉÁÆóÊ≥ïÔºöPPO„ÄÅGRPO„ÄÅSPOÔºà‰ªé0ÂéüÁîüÂÆûÁé∞Ôºâ
- Êñ∞Â¢ûÊñ≠ÁÇπÁª≠ËÆ≠ÂäüËÉΩÔºöÊîØÊåÅËÆ≠ÁªÉËá™Âä®ÊÅ¢Â§ç„ÄÅË∑®GPUÊï∞ÈáèÊÅ¢Â§ç„ÄÅwandbËÆ∞ÂΩïËøûÁª≠ÊÄß
- Êñ∞Â¢ûRLAIFÊï∞ÊçÆÈõÜÔºörlaif-mini.jsonlÔºà‰ªéSFTÊï∞ÊçÆÈöèÊú∫ÈááÊ†∑1‰∏áÊù°ÔºâÔºõÁÆÄÂåñDPOÊï∞ÊçÆÈõÜÔºåÂä†ÂÖ•‰∏≠ÊñáÊï∞ÊçÆ
- Êñ∞Â¢ûYaRNÁÆóÊ≥ïÔºöÊîØÊåÅRoPEÈïøÊñáÊú¨Â§ñÊé®ÔºåÊèêÂçáÈïøÂ∫èÂàóÂ§ÑÁêÜËÉΩÂäõ
- Adaptive ThinkingÔºöReasonÊ®°ÂûãÂèØÈÄâÊòØÂê¶ÂêØÁî®ÊÄùËÄÉÈìæ
- chat_templateÂÖ®Èù¢ÊîØÊåÅTool CallingÂíåReasoningÊ†áÁ≠æÔºà`&lt;tool_call&gt;`„ÄÅ`&lt;think&gt;`Á≠âÔºâ
- Êñ∞Â¢ûRLAIFÂÆåÊï¥Á´†ËäÇ„ÄÅËÆ≠ÁªÉÊõ≤Á∫øÂØπÊØî„ÄÅÁÆóÊ≥ïÂéüÁêÜÊäòÂè†ËØ¥Êòé
- [SwanLab](https://swanlab.cn/)Êõø‰ª£WandBÔºàÂõΩÂÜÖËÆøÈóÆÂèãÂ•ΩÔºåAPIÂÆåÂÖ®ÂÖºÂÆπÔºâ
- ËßÑËåÉÂåñÊâÄÊúâ‰ª£Á†Å &amp; ‰øÆÂ§ç‰∏Ä‰∫õÂ∑≤Áü•bugs

&lt;/details&gt;

&lt;details close&gt; 
&lt;summary&gt; &lt;b&gt;2025-04-26&lt;/b&gt; &lt;/summary&gt;

- ÈáçË¶ÅÊõ¥Êñ∞
- Â¶ÇÊúâÂÖºÂÆπÊÄßÈúÄË¶ÅÔºåÂèØËÆøÈóÆ[üîóÊóß‰ªìÂ∫ìÂÜÖÂÆπüîó](https://github.com/jingyaogong/minimind/tree/7da201a944a90ed49daef8a0265c959288dff83a)„ÄÇ
- MiniMindÊ®°ÂûãÂèÇÊï∞ÂÆåÂÖ®ÊîπÂêçÔºåÂØπÈΩêTransformersÂ∫ìÊ®°ÂûãÔºàÁªü‰∏ÄÂëΩÂêçÔºâ„ÄÇ
- generateÊñπÂºèÈáçÊûÑÔºåÁªßÊâøËá™GenerationMixinÁ±ª„ÄÇ
- üî•ÊîØÊåÅllama.cpp„ÄÅvllm„ÄÅollamaÁ≠âÁÉ≠Èó®‰∏âÊñπÁîüÊÄÅ„ÄÇ
- ËßÑËåÉ‰ª£Á†ÅÂíåÁõÆÂΩïÁªìÊûÑ„ÄÇ
- ÊîπÂä®ËØçË°®`&lt;s&gt;&lt;/s&gt;`-&gt;`&lt;|im_start|&gt;&lt;|im_end|&gt;`

```text
‰∏∫ÂÖºÂÆπÁ¨¨‰∏âÊñπÊé®ÁêÜÊ°ÜÊû∂llama.cpp„ÄÅvllmÔºåÊú¨Ê¨°Êõ¥Êñ∞ÈúÄ‰ªòÂá∫‰∏Ä‰∫õÂèØËßÇ‰ª£‰ª∑„ÄÇ
Êú¨Ê¨°Êõ¥Êñ∞‰∏çÂÜçÊîØÊåÅ„ÄåÁõ¥Êé•„ÄçÂä†ËΩΩ25-04-26‰ª•ÂâçÁöÑÊóßÊ®°ÂûãËøõË°åÊé®ÁêÜ„ÄÇ
Áî±‰∫éLlama‰ΩçÁΩÆÁºñÁ†ÅÊñπÂºè‰∏éminimindÂ≠òÂú®Âå∫Âà´ÔºåÂØºËá¥Êò†Â∞ÑLlamaÊ®°ÂûãÂêéQKÂÄºÂ≠òÂú®Â∑ÆÂºÇ
MiniMind2Á≥ªÂàóÊóßÊ®°ÂûãÂùáÁªèËøáÊùÉÈáçÊò†Â∞Ñ+ÔºàÂæÆË∞ÉËÆ≠ÁªÉÔºâQKVOÁ∫øÊÄßÂ±ÇÊ†°ÂáÜÊÅ¢Â§çËÄåÊù•„ÄÇ
Êú¨Ê¨°Êõ¥Êñ∞ÂêéÂ∞ÜÊîæÂºÉÂØπ`minimind-v1`ÂÖ®Á≥ªÂàóÁöÑÁª¥Êä§ÔºåÂπ∂Âú®‰ªìÂ∫ì‰∏≠‰∏ãÁ∫ø„ÄÇ
```

&lt;/details&gt;

&lt;details close&gt; 
&lt;summary&gt; &lt;b&gt;2025-02-09&lt;/b&gt; &lt;/summary&gt;

- ËøéÊù•ÂèëÂ∏É‰ª•Êù•ÈáçÂ§ßÊõ¥Êñ∞ÔºåRelease MiniMind2 Series„ÄÇ
- ‰ª£Á†ÅÂá†‰πéÂÖ®ÈÉ®ÈáçÊûÑÔºå‰ΩøÁî®Êõ¥ÁÆÄÊ¥ÅÊòé‰∫ÜÁöÑÁªü‰∏ÄÁªìÊûÑ„ÄÇ
  Â¶ÇÊúâÊóß‰ª£Á†ÅÁöÑÂÖºÂÆπÊÄßÈúÄË¶ÅÔºåÂèØËÆøÈóÆ[üîóÊóß‰ªìÂ∫ìÂÜÖÂÆπüîó](https://github.com/jingyaogong/minimind/tree/6e9cd28ef9b34a0a10afbdf6f59e65cb6e628efb)„ÄÇ
- ÂÖçÂéªÊï∞ÊçÆÈ¢ÑÂ§ÑÁêÜÊ≠•È™§„ÄÇÁªü‰∏ÄÊï∞ÊçÆÈõÜÊ†ºÂºèÔºåÊõ¥Êç¢‰∏∫`jsonl`Ê†ºÂºèÊùúÁªùÊï∞ÊçÆÈõÜ‰∏ãËΩΩÊ∑∑‰π±ÁöÑÈóÆÈ¢ò„ÄÇ
- MiniMind2Á≥ªÂàóÊïàÊûúÁõ∏ÊØîMiniMind-V1ÊòæËëóÊèêÂçá„ÄÇ
- Â∞èÈóÆÈ¢òÔºö{kv-cacheÂÜôÊ≥ïÊõ¥Ê†áÂáÜ„ÄÅMoEÁöÑË¥üËΩΩÂùáË°°lossË¢´ËÄÉËôëÁ≠âÁ≠â}
- Êèê‰æõÊ®°ÂûãËøÅÁßªÂà∞ÁßÅÊúâÊï∞ÊçÆÈõÜÁöÑËÆ≠ÁªÉÊñπÊ°àÔºàÂåªÁñóÊ®°Âûã„ÄÅËá™ÊàëËÆ§Áü•Ê†∑‰æãÔºâ„ÄÇ
- Á≤æÁÆÄÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåÂπ∂Â§ßÂπÖÊèêÂçáÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆË¥®ÈáèÔºåÂ§ßÂπÖÁº©Áü≠‰∏™‰∫∫Âø´ÈÄüËÆ≠ÁªÉÊâÄÈúÄÊó∂Èó¥ÔºåÂçïÂç°3090Âç≥ÂèØ2Â∞èÊó∂Â§çÁé∞ÔºÅ
- Êõ¥Êñ∞ÔºöLoRAÂæÆË∞ÉËÑ±Á¶ªpeftÂåÖË£ÖÔºå‰ªé0ÂÆûÁé∞LoRAËøáÁ®ãÔºõDPOÁÆóÊ≥ï‰ªé0‰ΩøÁî®PyTorchÂéüÁîüÂÆûÁé∞ÔºõÊ®°ÂûãÁôΩÁõíËí∏È¶èÂéüÁîüÂÆûÁé∞„ÄÇ
- MiniMind2-DeepSeek-R1Á≥ªÂàóËí∏È¶èÊ®°ÂûãËØûÁîüÔºÅ
- MiniMind2ÂÖ∑Â§á‰∏ÄÂÆöÁöÑËã±ÊñáËÉΩÂäõÔºÅ
- Êõ¥Êñ∞MiniMind2‰∏éÁ¨¨‰∏âÊñπÊ®°ÂûãÁöÑÂü∫‰∫éÊõ¥Â§öÂ§ßÊ®°ÂûãÊ¶úÂçïÊµãËØïÊÄßËÉΩÁöÑÁªìÊûú„ÄÇ

&lt;/details&gt;

&lt;details close&gt;
&lt;summary&gt; &lt;b&gt;More...&lt;/b&gt; &lt;/summary&gt;

**2024-10-05**
- ‰∏∫MiniMindÊãìÂ±ï‰∫ÜÂ§öÊ®°ÊÄÅËÉΩÂäõ‰πã---ËßÜËßâ
- ÁßªÊ≠•Â≠™ÁîüÈ°πÁõÆ[minimind-v](https://github.com/jingyaogong/minimind-v)Êü•ÁúãËØ¶ÊÉÖÔºÅ

**2024-09-27**
- 09-27Êõ¥Êñ∞pretrainÊï∞ÊçÆÈõÜÁöÑÈ¢ÑÂ§ÑÁêÜÊñπÂºèÔºå‰∏∫‰∫Ü‰øùËØÅÊñáÊú¨ÂÆåÊï¥ÊÄßÔºåÊîæÂºÉÈ¢ÑÂ§ÑÁêÜÊàê.binËÆ≠ÁªÉÁöÑÂΩ¢ÂºèÔºàËΩªÂæÆÁâ∫Áâ≤ËÆ≠ÁªÉÈÄüÂ∫¶Ôºâ„ÄÇ
- ÁõÆÂâçpretrainÈ¢ÑÂ§ÑÁêÜÂêéÁöÑÊñá‰ª∂ÂëΩÂêç‰∏∫Ôºöpretrain_data.csv„ÄÇ
- Âà†Èô§‰∫Ü‰∏Ä‰∫õÂÜó‰ΩôÁöÑ‰ª£Á†Å„ÄÇ

**2024-09-17**
- Êõ¥Êñ∞minimind-v1-moeÊ®°Âûã
- ‰∏∫‰∫ÜÈò≤Ê≠¢Ê≠ß‰πâÔºå‰∏çÂÜç‰ΩøÁî®mistral_tokenizerÂàÜËØçÔºåÂÖ®ÈÉ®ÈááÁî®Ëá™ÂÆö‰πâÁöÑminimind_tokenizer‰Ωú‰∏∫ÂàÜËØçÂô®„ÄÇ

**2024-09-01**
- Êõ¥Êñ∞minimind-v1 (108M)Ê®°ÂûãÔºåÈááÁî®minimind_tokenizerÔºåÈ¢ÑËÆ≠ÁªÉËΩÆÊ¨°3 + SFTËΩÆÊ¨°10ÔºåÊõ¥ÂÖÖÂàÜËÆ≠ÁªÉÔºåÊÄßËÉΩÊõ¥Âº∫„ÄÇ
- È°πÁõÆÂ∑≤ÈÉ®ÁΩ≤Ëá≥ModelScopeÂàõÁ©∫Èó¥ÔºåÂèØ‰ª•Âú®Ê≠§ÁΩëÁ´ô‰∏ä‰ΩìÈ™åÔºö
- [üîóModelScopeÂú®Á∫ø‰ΩìÈ™åüîó](https://www.modelscope.cn/studios/gongjy/minimind)

**2024-08-27**
- È°πÁõÆÈ¶ñÊ¨°ÂºÄÊ∫ê

&lt;/details&gt;

# üìå Âø´ÈÄüÂºÄÂßã

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;ÂàÜ‰∫´Êú¨‰∫∫ÁöÑËΩØÁ°¨‰ª∂ÈÖçÁΩÆÔºà‰ªÖ‰æõÂèÇËÄÉÔºâ&lt;/summary&gt;

* CPU: Intel(R) Core(TM) i9-10980XE CPU @ 3.00GHz
* RAM: 128 GB
* GPU: NVIDIA GeForce RTX 3090(24GB) * 8
* Ubuntu==20.04
* CUDA==12.2
* Python==3.10.16
* [requirements.txt](./requirements.txt)

&lt;/details&gt;

### Á¨¨0Ê≠•

```bash
git clone https://github.com/jingyaogong/minimind.git
```

## ‚Ö† ÊµãËØïÂ∑≤ÊúâÊ®°ÂûãÊïàÊûú

### 1.ÁéØÂ¢ÉÂáÜÂ§á

```bash
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple
```

### 2.‰∏ãËΩΩÊ®°Âûã

Âà∞È°πÁõÆÊ†πÁõÆÂΩï

```bash
git clone https://huggingface.co/jingyaogong/MiniMind2 # or https://www.modelscope.cn/models/gongjy/MiniMind2
```

### ÔºàÂèØÈÄâÔºâÂëΩ‰ª§Ë°åÈóÆÁ≠î

```bash
# ‰ΩøÁî®transformersÊ†ºÂºèÊ®°Âûã
python eval_llm.py --load_from ./MiniMind2
```

### ÔºàÂèØÈÄâÔºâÂêØÂä®WebUI

```bash
# ÂèØËÉΩÈúÄË¶Å`python&gt;=3.10` ÂÆâË£Ö `pip install streamlit`
# cd scripts
streamlit run web_demo.py
```

### ÔºàÂèØÈÄâÔºâÁ¨¨‰∏âÊñπÊé®ÁêÜÊ°ÜÊû∂

```bash
# ollama
ollama run jingyaogong/minimind2
# vllm
vllm serve ./MiniMind2/ --served-model-name &quot;minimind&quot;
```

## ‚Ö° ‰ªé0ÂºÄÂßãËá™Â∑±ËÆ≠ÁªÉ

### 1.ÁéØÂ¢ÉÂáÜÂ§á

```bash
pip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple
```

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;Ê≥®ÔºöÊèêÂâçÊµãËØïTorchÊòØÂê¶ÂèØÁî®cuda&lt;/summary&gt;

```bash
import torch
print(torch.cuda.is_available())
```

Â¶ÇÊûú‰∏çÂèØÁî®ÔºåËØ∑Ëá™Ë°åÂéª[torch_stable](https://download.pytorch.org/whl/torch_stable.html)
‰∏ãËΩΩwhlÊñá‰ª∂ÂÆâË£Ö„ÄÇÂèÇËÄÉ[ÈìæÊé•](https://blog.csdn.net/weixin_45456738/article/details/141029610?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E5%AE%89%E8%A3%85torch&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-2-141029610.nonecase&amp;spm=1018.2226.3001.4187)

&lt;/details&gt;

### 2.Êï∞ÊçÆ‰∏ãËΩΩ

‰ªé‰∏ãÊñáÊèê‰æõÁöÑ[Êï∞ÊçÆÈõÜ‰∏ãËΩΩÈìæÊé•](https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files)
‰∏ãËΩΩÈúÄË¶ÅÁöÑÊï∞ÊçÆÊñá‰ª∂ÔºàÂàõÂª∫`./dataset`ÁõÆÂΩïÔºâÂπ∂ÊîæÂà∞`./dataset`‰∏ã

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;Ê≥®ÔºöÊï∞ÊçÆÈõÜÈ°ªÁü•&lt;/summary&gt;

ÈªòËÆ§Êé®Ëçê‰∏ãËΩΩ`pretrain_hq.jsonl` + `sft_mini_512.jsonl`ÊúÄÂø´ÈÄüÂ∫¶Â§çÁé∞ZeroËÅäÂ§©Ê®°Âûã„ÄÇ

Êï∞ÊçÆÊñá‰ª∂ÂèØËá™Áî±ÈÄâÊã©Ôºå‰∏ãÊñáÊèê‰æõ‰∫ÜÂ§öÁßçÊê≠ÈÖçÊñπÊ°àÔºåÂèØÊ†πÊçÆËá™Â∑±ÊâãÂ§¥ÁöÑËÆ≠ÁªÉÈúÄÊ±ÇÂíåGPUËµÑÊ∫êËøõË°åÈÄÇÂΩìÁªÑÂêà„ÄÇ

&lt;/details&gt;

### 3.ÂºÄÂßãËÆ≠ÁªÉ

ÁõÆÂΩï‰Ωç‰∫é`trainer`

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;üí° Ê£ÄÊü•ÁÇπÊöÇÂÅúÁª≠ËÆ≠&lt;/summary&gt;

ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨ÂùáËá™Âä®‰øùÂ≠òÊ£ÄÊü•ÁÇπÔºåÂè™ÈúÄÊ∑ªÂä† `--from_resume 1` ÂèÇÊï∞Âç≥ÂèØËá™Âä®Ê£ÄÊµãÂä†ËΩΩ&amp;ÊÅ¢Â§çËÆ≠ÁªÉÔºö

```bash
python train_pretrain.py --from_resume 1
python train_full_sft.py --from_resume 1
...
```

**Êñ≠ÁÇπÁª≠ËÆ≠Êú∫Âà∂ËØ¥ÊòéÔºö**
- ËÆ≠ÁªÉËøáÁ®ãËá™Âä®Âú® `./checkpoints/` ÁõÆÂΩï‰øùÂ≠òÂÆåÊï¥Ê£ÄÊü•ÁÇπÔºàÊ®°Âûã„ÄÅ‰ºòÂåñÂô®„ÄÅËÆ≠ÁªÉËøõÂ∫¶Á≠âÔºâ
- Ê£ÄÊü•ÁÇπÊñá‰ª∂ÂëΩÂêçÔºö`&lt;ÊùÉÈáçÂêç&gt;_&lt;Áª¥Â∫¶&gt;_resume.pth`ÔºàÂ¶ÇÔºö`full_sft_512_resume.pth`Ôºâ
- ÊîØÊåÅË∑®‰∏çÂêåGPUÊï∞ÈáèÊÅ¢Â§çÔºàËá™Âä®Ë∞ÉÊï¥stepÔºâ
- ÊîØÊåÅwandbËÆ≠ÁªÉËÆ∞ÂΩïËøûÁª≠ÊÄßÔºàËá™Âä®ÊÅ¢Â§çÂêå‰∏Ä‰∏™runÔºâ

&gt; ÈÄÇÂêàÈïøÊó∂Èó¥ËÆ≠ÁªÉÊàñ‰∏çÁ®≥ÂÆöÁéØÂ¢ÉÔºåÊó†ÈúÄÊãÖÂøÉËÆ≠ÁªÉ‰∏≠Êñ≠ÂØºËá¥ËøõÂ∫¶‰∏¢Â§±

&lt;/details&gt;

**3.1 È¢ÑËÆ≠ÁªÉÔºàÂ≠¶Áü•ËØÜÔºâ**

```bash
python train_pretrain.py
```

&gt; ÊâßË°åÈ¢ÑËÆ≠ÁªÉÔºåÂæóÂà∞ `pretrain_*.pth` ‰Ωú‰∏∫È¢ÑËÆ≠ÁªÉÁöÑËæìÂá∫ÊùÉÈáçÔºàÂÖ∂‰∏≠*‰∏∫Ê®°ÂûãÁöÑdimensionÔºåÈªòËÆ§‰∏∫512Ôºâ


**3.2 ÁõëÁù£ÂæÆË∞ÉÔºàÂ≠¶ÂØπËØùÊñπÂºèÔºâ**

```bash
python train_full_sft.py
```

&gt; ÊâßË°åÁõëÁù£ÂæÆË∞ÉÔºåÂæóÂà∞ `full_sft_*.pth` ‰Ωú‰∏∫Êåá‰ª§ÂæÆË∞ÉÁöÑËæìÂá∫ÊùÉÈáçÔºàÂÖ∂‰∏≠`full`Âç≥‰∏∫ÂÖ®ÂèÇÊï∞ÂæÆË∞ÉÔºâ

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;Ê≥®ÔºöËÆ≠ÁªÉÈ°ªÁü•&lt;/summary&gt;

ÊâÄÊúâËÆ≠ÁªÉËøáÁ®ãÈªòËÆ§ÊØèÈöî100Ê≠•‰øùÂ≠ò1Ê¨°ÂèÇÊï∞Âà∞Êñá‰ª∂`./out/***.pth`ÔºàÊØèÊ¨°‰ºöË¶ÜÁõñÊéâÊóßÊùÉÈáçÊñá‰ª∂Ôºâ„ÄÇ

ÁÆÄÂçïËµ∑ËßÅÔºåÊ≠§Â§ÑÂè™ÂÜôÊòé‰∏§‰∏™Èò∂ÊÆµËÆ≠ÁªÉËøáÁ®ã„ÄÇÂ¶ÇÈúÄÂÖ∂ÂÆÉËÆ≠ÁªÉ (LoRA, Ëí∏È¶è, Âº∫ÂåñÂ≠¶‰π†, ÂæÆË∞ÉÊé®ÁêÜÁ≠â) ÂèØÂèÇËÄÉ‰∏ãÊñá„ÄêÂÆûÈ™å„ÄëÂ∞èËäÇÁöÑËØ¶ÁªÜËØ¥Êòé„ÄÇ

&lt;/details&gt;


---

### 4.ÊµãËØïËá™Â∑±ËÆ≠ÁªÉÁöÑÊ®°ÂûãÊïàÊûú

Á°Æ‰øùÈúÄË¶ÅÊµãËØïÁöÑÊ®°Âûã`*.pth`Êñá‰ª∂‰Ωç‰∫é`./out/`ÁõÆÂΩï‰∏ã„ÄÇ
‰πüÂèØ‰ª•Áõ¥Êé•Âéª[Ê≠§Â§Ñ](https://www.modelscope.cn/models/gongjy/MiniMind2-PyTorch/files)‰∏ãËΩΩ‰ΩøÁî®ÊàëËÆ≠ÁªÉÁöÑ`*.pth`Êñá‰ª∂„ÄÇ

```bash
python eval_llm.py --weight full_sft # Êàñ pretrain/dpo/ppo/grpo...
```

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;Ê≥®ÔºöÊµãËØïÈ°ªÁü•&lt;/summary&gt;

`--weight` ÂèÇÊï∞ÊåáÂÆöÊùÉÈáçÂêçÁß∞ÂâçÁºÄÔºåÂèØÈÄâÔºö`pretrain`, `full_sft`, `dpo`, `reason`, `ppo_actor`, `grpo`, `spo` Á≠â

ÂÖ∂‰ªñÂ∏∏Áî®ÂèÇÊï∞Ôºö
- `--load_from`: Ê®°ÂûãÂä†ËΩΩË∑ØÂæÑÔºà`model`=ÂéüÁîütorchÊùÉÈáçÔºåÂÖ∂‰ªñË∑ØÂæÑ=transformersÊ†ºÂºèÔºâ
- `--save_dir`: Ê®°ÂûãÊùÉÈáçÁõÆÂΩïÔºàÈªòËÆ§`out`Ôºâ
- `--lora_weight`: LoRAÊùÉÈáçÂêçÁß∞Ôºà`None`Ë°®Á§∫‰∏ç‰ΩøÁî®Ôºâ
- `--historys`: Êê∫Â∏¶ÂéÜÂè≤ÂØπËØùËΩÆÊï∞ÔºàÈúÄ‰∏∫ÂÅ∂Êï∞Ôºå0Ë°®Á§∫‰∏çÊê∫Â∏¶ÂéÜÂè≤Ôºâ
- `--max_new_tokens`: ÊúÄÂ§ßÁîüÊàêÈïøÂ∫¶ÔºàÈªòËÆ§8192Ôºâ
- `--temperature`: ÁîüÊàêÊ∏©Â∫¶ÔºàÈªòËÆ§0.85Ôºâ
- `--top_p`: nucleusÈááÊ†∑ÈòàÂÄºÔºàÈªòËÆ§0.85Ôºâ


‰ΩøÁî®ÊñπÂºèÁõ¥Êé•Êü•Áúã`eval_llm.py`‰ª£Á†ÅÂç≥ÂèØ„ÄÇ

&lt;/details&gt;


---

&gt; [!TIP]
&gt; ÊâÄÊúâËÆ≠ÁªÉËÑöÊú¨Âùá‰∏∫PytorchÂéüÁîüÊ°ÜÊû∂ÔºåÂùáÊîØÊåÅÂ§öÂç°Âä†ÈÄüÔºåÂÅáËÆæ‰Ω†ÁöÑËÆæÂ§áÊúâN (NÔºû1) Âº†ÊòæÂç°Ôºö

ÂçïÊú∫NÂç°ÂêØÂä®ËÆ≠ÁªÉÊñπÂºè (DDP, ÊîØÊåÅÂ§öÊú∫Â§öÂç°ÈõÜÁæ§)

```bash
torchrun --nproc_per_node N train_xxx.py
```

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;Ê≥®ÔºöÂÖ∂ÂÆÉÈ°ªÁü•&lt;/summary&gt;

&lt;del&gt;
ÂçïÊú∫NÂç°ÂêØÂä®ËÆ≠ÁªÉ (DeepSpeed)

```bash
deepspeed --master_port 29500 --num_gpus=N train_xxx.py
```
&lt;/del&gt;

ÂèØÊ†πÊçÆÈúÄË¶ÅÂºÄÂêØwandbËÆ∞ÂΩïËÆ≠ÁªÉËøáÁ®ãÔºàÈúÄÂèØÁõ¥ËøûÔºâ

```bash
# ÈúÄË¶ÅÁôªÂΩï: wandb login
torchrun --nproc_per_node N train_xxx.py --use_wandb
# and
python train_xxx.py --use_wandb
```

ÈÄöËøáÊ∑ªÂä†`--use_wandb`ÂèÇÊï∞ÔºåÂèØ‰ª•ËÆ∞ÂΩïËÆ≠ÁªÉËøáÁ®ãÔºåËÆ≠ÁªÉÂÆåÊàêÂêéÔºåÂèØ‰ª•Âú®wandbÁΩëÁ´ô‰∏äÊü•ÁúãËÆ≠ÁªÉËøáÁ®ã„ÄÇÈÄöËøá‰øÆÊîπ`wandb_project`
Âíå`wandb_run_name`ÂèÇÊï∞ÔºåÂèØ‰ª•ÊåáÂÆöÈ°πÁõÆÂêçÁß∞ÂíåËøêË°åÂêçÁß∞„ÄÇ

„ÄêÊ≥®„ÄëÔºö25Âπ¥6ÊúàÂêéÔºåÂõΩÂÜÖÁΩëÁªúÁéØÂ¢ÉÊó†Ê≥ïÁõ¥ËøûWandBÔºåMiniMindÈ°πÁõÆÈªòËÆ§ËΩ¨‰∏∫‰ΩøÁî®[SwanLab](https://swanlab.cn/)‰Ωú‰∏∫ËÆ≠ÁªÉÂèØËßÜÂåñÂ∑•ÂÖ∑ÔºàÂÆåÂÖ®ÂÖºÂÆπWandB APIÔºâÔºåÂç≥`import wandb`Êîπ‰∏∫`import swanlab as wandb`Âç≥ÂèØÔºåÂÖ∂‰ªñÂùáÊó†ÈúÄÊîπÂä®„ÄÇ

&lt;/details&gt;

# üìå Êï∞ÊçÆ‰ªãÁªç

## ‚Ö† Tokenizer

ÂàÜËØçÂô®Â∞ÜÂçïËØç‰ªéËá™ÁÑ∂ËØ≠Ë®ÄÈÄöËøá‚ÄúËØçÂÖ∏‚ÄùÊò†Â∞ÑÂà∞`0, 1, 36`ËøôÊ†∑ÁöÑÊï∞Â≠óÔºåÂèØ‰ª•ÁêÜËß£‰∏∫Êï∞Â≠óÂ∞±‰ª£Ë°®‰∫ÜÂçïËØçÂú®‚ÄúËØçÂÖ∏‚Äù‰∏≠ÁöÑÈ°µÁ†Å„ÄÇ
ÂèØ‰ª•ÈÄâÊã©Ëá™Â∑±ÊûÑÈÄ†ËØçË°®ËÆ≠ÁªÉ‰∏Ä‰∏™‚ÄúËØçÂÖ∏‚ÄùÔºå‰ª£Á†ÅÂèØËßÅ`./trainer/train_tokenizer.py`Ôºà‰ªÖ‰æõÂ≠¶‰π†ÂèÇËÄÉÔºåËã•ÈùûÂøÖË¶ÅÊó†ÈúÄÂÜçËá™Ë°åËÆ≠ÁªÉÔºåMiniMindÂ∑≤Ëá™Â∏¶tokenizerÔºâ„ÄÇ
ÊàñËÄÖÈÄâÊã©ÊØîËæÉÂá∫ÂêçÁöÑÂºÄÊ∫êÂ§ßÊ®°ÂûãÂàÜËØçÂô®Ôºå
Ê≠£Â¶ÇÂêåÁõ¥Êé•Áî®Êñ∞Âçé/ÁâõÊ¥•ËØçÂÖ∏ÁöÑ‰ºòÁÇπÊòØtokenÁºñÁ†ÅÂéãÁº©ÁéáÂæàÂ•ΩÔºåÁº∫ÁÇπÊòØÈ°µÊï∞Â§™Â§öÔºåÂä®ËæÑÊï∞ÂçÅ‰∏á‰∏™ËØçÊ±áÁü≠ËØ≠Ôºõ
Ëá™Â∑±ËÆ≠ÁªÉÁöÑÂàÜËØçÂô®Ôºå‰ºòÁÇπÊòØËØçË°®ÈïøÂ∫¶ÂíåÂÜÖÂÆπÈöèÊÑèÊéßÂà∂ÔºåÁº∫ÁÇπÊòØÂéãÁº©ÁéáÂæà‰ΩéÔºà‰æãÂ¶Ç&quot;hello&quot;‰πüËÆ∏‰ºöË¢´ÊãÜÂàÜ‰∏∫&quot;h e l l o&quot;
‰∫î‰∏™Áã¨Á´ãÁöÑtokenÔºâÔºå‰∏îÁîüÂÉªËØçÈöæ‰ª•Ë¶ÜÁõñ„ÄÇ
‚ÄúËØçÂÖ∏‚ÄùÁöÑÈÄâÊã©Âõ∫ÁÑ∂ÂæàÈáçË¶ÅÔºåLLMÁöÑËæìÂá∫Êú¨Ë¥®‰∏äÊòØSoftMaxÂà∞ËØçÂÖ∏N‰∏™ËØçÁöÑÂ§öÂàÜÁ±ªÈóÆÈ¢òÔºåÁÑ∂ÂêéÈÄöËøá‚ÄúËØçÂÖ∏‚ÄùËß£Á†ÅÂà∞Ëá™ÁÑ∂ËØ≠Ë®Ä„ÄÇ
Âõ†‰∏∫MiniMind‰ΩìÁßØÈúÄË¶Å‰∏•Ê†ºÊéßÂà∂Ôºå‰∏∫‰∫ÜÈÅøÂÖçÊ®°ÂûãÂ§¥ÈáçËÑöËΩªÔºàËØçÂµåÂÖ•embeddingÂ±ÇÂèÇÊï∞Âú®LLMÂç†ÊØîÂ§™È´òÔºâÔºåÊâÄ‰ª•ËØçË°®ÈïøÂ∫¶Áü≠Áü≠ÁõäÂñÑ„ÄÇ

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;Tokenizer‰ªãÁªç&lt;/summary&gt;

Á¨¨‰∏âÊñπÂº∫Â§ßÁöÑÂºÄÊ∫êÊ®°Âûã‰æãÂ¶ÇYi„ÄÅqwen„ÄÅchatglm„ÄÅmistral„ÄÅLlama3ÁöÑtokenizerËØçË°®ÈïøÂ∫¶Â¶Ç‰∏ãÔºö

&lt;table&gt;
  &lt;tr&gt;&lt;th&gt;TokenizerÊ®°Âûã&lt;/th&gt;&lt;th&gt;ËØçË°®Â§ßÂ∞è&lt;/th&gt;&lt;th&gt;Êù•Ê∫ê&lt;/th&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;yi tokenizer&lt;/td&gt;&lt;td&gt;64,000&lt;/td&gt;&lt;td&gt;01‰∏áÁâ©Ôºà‰∏≠ÂõΩÔºâ&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;qwen2 tokenizer&lt;/td&gt;&lt;td&gt;151,643&lt;/td&gt;&lt;td&gt;ÈòøÈáå‰∫ëÔºà‰∏≠ÂõΩÔºâ&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;glm tokenizer&lt;/td&gt;&lt;td&gt;151,329&lt;/td&gt;&lt;td&gt;Êô∫Ë∞±AIÔºà‰∏≠ÂõΩÔºâ&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;mistral tokenizer&lt;/td&gt;&lt;td&gt;32,000&lt;/td&gt;&lt;td&gt;Mistral AIÔºàÊ≥ïÂõΩÔºâ&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;llama3 tokenizer&lt;/td&gt;&lt;td&gt;128,000&lt;/td&gt;&lt;td&gt;MetaÔºàÁæéÂõΩÔºâ&lt;/td&gt;&lt;/tr&gt;
  &lt;tr&gt;&lt;td&gt;minimind tokenizer&lt;/td&gt;&lt;td&gt;6,400&lt;/td&gt;&lt;td&gt;Ëá™ÂÆö‰πâ&lt;/td&gt;&lt;/tr&gt;
&lt;/table&gt;

&gt; üëâ2024-09-17Êõ¥Êñ∞Ôºö‰∏∫‰∫ÜÈò≤Ê≠¢ËøáÂéªÁöÑÁâàÊú¨Ê≠ß‰πâ&amp;ÊéßÂà∂‰ΩìÁßØÔºåminimindÊâÄÊúâÊ®°ÂûãÂùá‰ΩøÁî®minimind_tokenizerÂàÜËØçÔºåÂ∫üÂºÉÊâÄÊúâmistral_tokenizerÁâàÊú¨„ÄÇ

```
# ‰∏Ä‰∫õËá™Ë®ÄËá™ËØ≠
&gt; Â∞ΩÁÆ°minimind_tokenizerÈïøÂ∫¶ÂæàÂ∞èÔºåÁºñËß£Á†ÅÊïàÁéáÂº±‰∫éqwen2„ÄÅglmÁ≠â‰∏≠ÊñáÂèãÂ•ΩÂûãÂàÜËØçÂô®„ÄÇ
&gt; ‰ΩÜminimindÊ®°ÂûãÈÄâÊã©‰∫ÜËá™Â∑±ËÆ≠ÁªÉÁöÑminimind_tokenizer‰Ωú‰∏∫ÂàÜËØçÂô®Ôºå‰ª•‰øùÊåÅÊï¥‰ΩìÂèÇÊï∞ËΩªÈáèÔºåÈÅøÂÖçÁºñÁ†ÅÂ±ÇÂíåËÆ°ÁÆóÂ±ÇÂç†ÊØîÂ§±Ë°°ÔºåÂ§¥ÈáçËÑöËΩªÔºåÂõ†‰∏∫minimindÁöÑËØçË°®Â§ßÂ∞èÂè™Êúâ6400„ÄÇ
&gt; ‰∏îminimindÂú®ÂÆûÈôÖÊµãËØï‰∏≠Ê≤°ÊúâÂá∫Áé∞ËøáÁîüÂÉªËØçÊ±áËß£Á†ÅÂ§±Ë¥•ÁöÑÊÉÖÂÜµÔºåÊïàÊûúËâØÂ•Ω„ÄÇ
&gt; Áî±‰∫éËá™ÂÆö‰πâËØçË°®ÂéãÁº©ÈïøÂ∫¶Âà∞6400Ôºå‰ΩøÂæóLLMÊÄªÂèÇÊï∞ÈáèÊúÄ‰ΩéÂè™Êúâ25.8M„ÄÇ
&gt; ËÆ≠ÁªÉÊï∞ÊçÆ`pretrain_hq.jsonl`ÂùáÊù•Ëá™‰∫é`Âå†Êï∞Â§ßÊ®°ÂûãÊï∞ÊçÆÈõÜ`ÔºåËøôÈÉ®ÂàÜÊï∞ÊçÆÁõ∏ÂØπÊ¨°Ë¶ÅÔºåÂ¶ÇÈúÄËÆ≠ÁªÉÂèØ‰ª•Ëá™Áî±ÈÄâÊã©„ÄÇ
```

&lt;/details&gt;

## ‚Ö° PretrainÊï∞ÊçÆ

ÁªèÂéÜ‰∫ÜMiniMind-V1ÁöÑ‰ΩéË¥®ÈáèÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆÔºåÂØºËá¥Ê®°ÂûãËÉ°Ë®Ä‰π±ËØ≠ÁöÑÊïôËÆ≠Ôºå`2025-02-05` ‰πãÂêéÂÜ≥ÂÆö‰∏çÂÜçÈááÁî®Â§ßËßÑÊ®°Êó†ÁõëÁù£ÁöÑÊï∞ÊçÆÈõÜÂÅöÈ¢ÑËÆ≠ÁªÉ„ÄÇ
ËøõËÄåÂ∞ùËØïÊää[Âå†Êï∞Â§ßÊ®°ÂûãÊï∞ÊçÆÈõÜ](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data)ÁöÑ‰∏≠ÊñáÈÉ®ÂàÜÊèêÂèñÂá∫Êù•Ôºå
Ê∏ÖÊ¥óÂá∫Â≠óÁ¨¶`&lt;512`ÈïøÂ∫¶ÁöÑÂ§ßÁ∫¶1.6GBÁöÑËØ≠ÊñôÁõ¥Êé•ÊãºÊé•ÊàêÈ¢ÑËÆ≠ÁªÉÊï∞ÊçÆ `pretrain_hq.jsonl`ÔºåhqÂç≥‰∏∫high
qualityÔºàÂΩìÁÑ∂‰πüËøò‰∏çÁÆóhighÔºåÊèêÂçáÊï∞ÊçÆË¥®ÈáèÊó†Ê≠¢Â∞ΩÔºâ„ÄÇ

Êñá‰ª∂`pretrain_hq.jsonl` Êï∞ÊçÆÊ†ºÂºè‰∏∫

```json
{&quot;text&quot;: &quot;Â¶Ç‰ΩïÊâçËÉΩÊëÜËÑ±ÊãñÂª∂ÁóáÔºü Ê≤ªÊÑàÊãñÂª∂ÁóáÂπ∂‰∏çÂÆπÊòìÔºå‰ΩÜ‰ª•‰∏ãÂª∫ËÆÆÂèØËÉΩÊúâÊâÄÂ∏ÆÂä©...&quot;}
```

## ‚Ö¢ SFTÊï∞ÊçÆ

[Âå†Êï∞Â§ßÊ®°ÂûãSFTÊï∞ÊçÆÈõÜ](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data)
‚ÄúÊòØ‰∏Ä‰∏™ÂÆåÊï¥„ÄÅÊ†ºÂºèÁªü‰∏Ä„ÄÅÂÆâÂÖ®ÁöÑÂ§ßÊ®°ÂûãËÆ≠ÁªÉÂíåÁ†îÁ©∂ËµÑÊ∫ê„ÄÇ
‰ªéÁΩëÁªú‰∏äÁöÑÂÖ¨ÂºÄÊï∞ÊçÆÊ∫êÊî∂ÈõÜÂπ∂Êï¥ÁêÜ‰∫ÜÂ§ßÈáèÂºÄÊ∫êÊï∞ÊçÆÈõÜÔºåÂØπÂÖ∂ËøõË°å‰∫ÜÊ†ºÂºèÁªü‰∏ÄÔºåÊï∞ÊçÆÊ∏ÖÊ¥óÔºå
ÂåÖÂê´10MÊù°Êï∞ÊçÆÁöÑ‰∏≠ÊñáÊï∞ÊçÆÈõÜÂíåÂåÖÂê´2MÊù°Êï∞ÊçÆÁöÑËã±ÊñáÊï∞ÊçÆÈõÜ„ÄÇ‚Äù
‰ª•‰∏äÊòØÂÆòÊñπ‰ªãÁªçÔºå‰∏ãËΩΩÊñá‰ª∂ÂêéÁöÑÊï∞ÊçÆÊÄªÈáèÂ§ßÁ∫¶Âú®4B tokensÔºåËÇØÂÆöÊòØÈÄÇÂêà‰Ωú‰∏∫‰∏≠ÊñáÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑSFTÊï∞ÊçÆÁöÑ„ÄÇ
‰ΩÜÊòØÂÆòÊñπÊèê‰æõÁöÑÊï∞ÊçÆÊ†ºÂºèÂæà‰π±ÔºåÂÖ®ÈÉ®Áî®Êù•sft‰ª£‰ª∑Â§™Â§ß„ÄÇ
ÊàëÂ∞ÜÊääÂÆòÊñπÊï∞ÊçÆÈõÜËøõË°å‰∫Ü‰∫åÊ¨°Ê∏ÖÊ¥óÔºåÊääÂê´ÊúâÁ¨¶Âè∑Ê±°ÊüìÂíåÂô™Â£∞ÁöÑÊù°ÁõÆÂéªÈô§ÔºõÂè¶Â§ñ‰æùÁÑ∂Âè™‰øùÁïô‰∫ÜÊÄªÈïøÂ∫¶`&lt;512`
ÁöÑÂÜÖÂÆπÔºåÊ≠§Èò∂ÊÆµÂ∏åÊúõÈÄöËøáÂ§ßÈáèÂØπËØùË°•ÂÖÖÈ¢ÑËÆ≠ÁªÉÈò∂ÊÆµÊ¨†Áº∫ÁöÑÁü•ËØÜ„ÄÇ
ÂØºÂá∫Êñá‰ª∂‰∏∫`sft_512.jsonl`(~7.5GB)„ÄÇ

[Magpie-SFTÊï∞ÊçÆÈõÜ](https://www.modelscope.cn/organization/Magpie-Align)
Êî∂ÈõÜ‰∫Ü~1MÊù°Êù•Ëá™Qwen2/2.5ÁöÑÈ´òË¥®ÈáèÂØπËØùÔºåÊàëÂ∞ÜËøôÈÉ®ÂàÜÊï∞ÊçÆËøõ‰∏ÄÊ≠•Ê∏ÖÊ¥óÔºåÊääÊÄªÈïøÂ∫¶`&lt;2048`ÁöÑÈÉ®ÂàÜÂØºÂá∫‰∏∫`sft_2048.jsonl`(~9GB)„ÄÇ
ÈïøÂ∫¶`&lt;1024`ÁöÑÈÉ®ÂàÜÂØºÂá∫‰∏∫`sft_1024.jsonl`(~5.5GB)ÔºåÁî®Â§ßÊ®°ÂûãÂØπËØùÊï∞ÊçÆÁõ¥Êé•ËøõË°åsftÂ∞±Â±û‰∫é‚ÄúÈªëÁõíËí∏È¶è‚ÄùÁöÑËåÉÁï¥„ÄÇ

Ëøõ‰∏ÄÊ≠•Ê∏ÖÊ¥óÂâç‰∏§Ê≠•sftÁöÑÊï∞ÊçÆÔºàÂè™‰øùÁïô‰∏≠ÊñáÂ≠óÁ¨¶Âç†ÊØîÈ´òÁöÑÂÜÖÂÆπÔºâÔºåÁ≠õÈÄâÈïøÂ∫¶`&lt;512`ÁöÑÂØπËØùÔºåÂæóÂà∞`sft_mini_512.jsonl`(~1.2GB)„ÄÇ

ÊâÄÊúâsftÊñá‰ª∂ `sft_X.jsonl` Êï∞ÊçÆÊ†ºÂºèÂùá‰∏∫

```text
{
    &quot;conversations&quot;: [
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;‰Ω†Â•Ω&quot;},
        {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;‰Ω†Â•ΩÔºÅ&quot;},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;ÂÜçËßÅ&quot;},
        {&quot;role&quot;: &quot;assistant&quot;, &quot;content&quot;: &quot;ÂÜçËßÅÔºÅ&quot;}
    ]
}
```

## ‚Ö£ RLHFÊï∞ÊçÆ

Êù•Ëá™[Magpie-DPOÊï∞ÊçÆÈõÜ](https://www.modelscope.cn/datasets/Magpie-Align/MagpieLM-DPO-Data-v0.1)
Â§ßÁ∫¶200kÊù°ÂÅèÂ•ΩÊï∞ÊçÆÔºàÂùáÊòØËã±ÊñáÔºâÁîüÊàêËá™Llama3.1-70B/8BÔºåÂèØ‰ª•Áî®‰∫éËÆ≠ÁªÉÂ•ñÂä±Ê®°ÂûãÔºå‰ºòÂåñÊ®°ÂûãÂõûÂ§çË¥®ÈáèÔºå‰ΩøÂÖ∂Êõ¥Âä†Á¨¶Âêà‰∫∫Á±ªÂÅèÂ•Ω„ÄÇ
ËøôÈáåÂ∞ÜÊï∞ÊçÆÊÄªÈïøÂ∫¶`&lt;3000`ÁöÑÂÜÖÂÆπÈáçÁªÑ‰∏∫`dpo.jsonl`(~0.9GB)ÔºåÂåÖÂê´`chosen`Âíå`rejected`‰∏§‰∏™Â≠óÊÆµÔºå`chosen`
‰∏∫ÂÅèÂ•ΩÁöÑÂõûÂ§çÔºå`rejected`‰∏∫ÊãíÁªùÁöÑÂõûÂ§ç„ÄÇ

Êñá‰ª∂ `dpo.jsonl` Êï∞ÊçÆÊ†ºÂºè‰∏∫

```text
{
  &quot;chosen&quot;: [
    {&quot;content&quot;: &quot;Q&quot;, &quot;role&quot;: &quot;user&quot;}, 
    {&quot;content&quot;: &quot;good answer&quot;, &quot;role&quot;: &quot;assistant&quot;}
  ], 
  &quot;rejected&quot;: [
    {&quot;content&quot;: &quot;Q&quot;, &quot;role&quot;: &quot;user&quot;}, 
    {&quot;content&quot;: &quot;bad answer&quot;, &quot;role&quot;: &quot;assistant&quot;}
  ]
}
```

## ‚Ö§ ReasonÊï∞ÊçÆÈõÜÔºö

‰∏çÂæó‰∏çËØ¥2025Âπ¥2ÊúàË∞ÅËÉΩÁÅ´ÁöÑËøáDeepSeek...
‰πüÊøÄÂèë‰∫ÜÊàëÂØπRLÂºïÂØºÁöÑÊé®ÁêÜÊ®°ÂûãÁöÑÊµìÂéöÂÖ¥Ë∂£ÔºåÁõÆÂâçÂ∑≤ÁªèÁî®Qwen2.5Â§çÁé∞‰∫ÜR1-Zero„ÄÇ
Â¶ÇÊûúÊúâÊó∂Èó¥+ÊïàÊûúworkÔºà‰ΩÜ99%Âü∫Ê®°ËÉΩÂäõ‰∏çË∂≥ÔºâÊàë‰ºöÂú®‰πãÂêéÊõ¥Êñ∞MiniMindÂü∫‰∫éRLËÆ≠ÁªÉÁöÑÊé®ÁêÜÊ®°ÂûãËÄå‰∏çÊòØËí∏È¶èÊ®°Âûã„ÄÇ
Êó∂Èó¥ÊúâÈôêÔºåÊúÄÂø´ÁöÑ‰ΩéÊàêÊú¨ÊñπÊ°à‰æùÁÑ∂ÊòØÁõ¥Êé•Ëí∏È¶èÔºàÈªëÁõíÊñπÂºèÔºâ„ÄÇ
ËÄê‰∏ç‰ΩèR1Â§™ÁÅ´ÔºåÁü≠Áü≠Âá†Â§©Â∞±Â∑≤ÁªèÂ≠òÂú®‰∏Ä‰∫õR1ÁöÑËí∏È¶èÊï∞ÊçÆÈõÜ[R1-Llama-70B](https://www.modelscope.cn/datasets/Magpie-Align/Magpie-Reasoning-V2-250K-CoT-Deepseek-R1-Llama-70B)„ÄÅ[R1-Distill-SFT](https://www.modelscope.cn/datasets/AI-ModelScope/R1-Distill-SFT)„ÄÅ
[Alpaca-Distill-R1](https://huggingface.co/datasets/shareAI/Alpaca-Distill-R1-ZH)„ÄÅ
[deepseek_r1_zh](https://huggingface.co/datasets/jinliuxi/deepseek_r1_zh)Á≠âÁ≠âÔºåÁ∫Ø‰∏≠ÊñáÁöÑÊï∞ÊçÆÂèØËÉΩÊØîËæÉÂ∞ë„ÄÇ
ÊúÄÁªàÊï¥ÂêàÂÆÉ‰ª¨ÔºåÂØºÂá∫Êñá‰ª∂‰∏∫`r1_mix_1024.jsonl`ÔºåÊï∞ÊçÆÊ†ºÂºèÂíå`sft_X.jsonl`‰∏ÄËá¥„ÄÇ

## ‚Ö• Êõ¥Â§öÊï∞ÊçÆÈõÜ

ÁõÆÂâçÂ∑≤ÁªèÊúâ[HqWu-HITCS/Awesome-Chinese-LLM](https://github.com/HqWu-HITCS/Awesome-Chinese-LLM)
Âú®Êî∂ÈõÜÂíåÊ¢≥ÁêÜ‰∏≠ÊñáLLMÁõ∏ÂÖ≥ÁöÑÂºÄÊ∫êÊ®°Âûã„ÄÅÂ∫îÁî®„ÄÅÊï∞ÊçÆÈõÜÂèäÊïôÁ®ãÁ≠âËµÑÊñôÔºåÂπ∂ÊåÅÁª≠Êõ¥Êñ∞ËøôÊñπÈù¢ÁöÑÊúÄÊñ∞ËøõÂ±ï„ÄÇÂÖ®Èù¢‰∏î‰∏ì‰∏öÔºåRespectÔºÅ

---

## ‚Öß MiniMindËÆ≠ÁªÉÊï∞ÊçÆÈõÜ

&gt; [!NOTE]
&gt; 2025-02-05ÂêéÔºåÂºÄÊ∫êMiniMindÊúÄÁªàËÆ≠ÁªÉÊâÄÁî®ÁöÑÊâÄÊúâÊï∞ÊçÆÈõÜÔºåÂõ†Ê≠§Êó†ÈúÄÂÜçËá™Ë°åÈ¢ÑÂ§ÑÁêÜÂ§ßËßÑÊ®°Êï∞ÊçÆÈõÜÔºåÈÅøÂÖçÈáçÂ§çÊÄßÁöÑÊï∞ÊçÆÂ§ÑÁêÜÂ∑•‰Ωú„ÄÇ

MiniMindËÆ≠ÁªÉÊï∞ÊçÆÈõÜ‰∏ãËΩΩÂú∞ÂùÄÔºö [ModelScope](https://www.modelscope.cn/datasets/gongjy/minimind_dataset/files) | [HuggingFace](https://huggingface.co/datasets/jingyaogong/minimind_dataset/tree/main)

&gt; Êó†ÈúÄÂÖ®ÈÉ®cloneÔºåÂèØÂçïÁã¨‰∏ãËΩΩÊâÄÈúÄÁöÑÊñá‰ª∂

Â∞Ü‰∏ãËΩΩÁöÑÊï∞ÊçÆÈõÜÊñá‰ª∂ÊîæÂà∞`./dataset/`ÁõÆÂΩï‰∏ãÔºà‚ú®‰∏∫Êé®ËçêÁöÑÂøÖÈ°ªÈ°πÔºâ

```bash
./dataset/
‚îú‚îÄ‚îÄ dpo.jsonl (55MB, ‚ú®)
‚îú‚îÄ‚îÄ lora_identity.jsonl (22.8KB)
‚îú‚îÄ‚îÄ lora_medical.jsonl (34MB)
‚îú‚îÄ‚îÄ pretrain_hq.jsonl (1.6GB, ‚ú®)
‚îú‚îÄ‚îÄ r1_mix_1024.jsonl (340MB)
‚îú‚îÄ‚îÄ rlaif-mini.jsonl (1MB, ‚ú®)
‚îú‚îÄ‚îÄ sft_1024.jsonl (5.6GB)
‚îú‚îÄ‚îÄ sft_2048.jsonl (9GB)
‚îú‚îÄ‚îÄ sft_512.jsonl (7.5GB)
‚îî‚îÄ‚îÄ sft_mini_512.jsonl (1.2GB, ‚ú®)
```

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;Ê≥®ÔºöÂêÑÊï∞ÊçÆÈõÜÁÆÄ‰ªã&lt;/summary&gt;

* `dpo.jsonl`‚ú® --RLHFÈò∂ÊÆµÊï∞ÊçÆÈõÜÔºàÂ∑≤Á≤æÁÆÄ‰ºòÂåñÔºåÈÄÇÂêàÂø´ÈÄüËÆ≠ÁªÉÔºâ
* `lora_identity.jsonl` --Ëá™ÊàëËÆ§Áü•Êï∞ÊçÆÈõÜÔºà‰æãÂ¶ÇÔºö‰Ω†ÊòØË∞ÅÔºüÊàëÊòØminimind...ÔºâÔºåÊé®ËçêÁî®‰∫éloraËÆ≠ÁªÉÔºà‰∫¶ÂèØÁî®‰∫éÂÖ®ÂèÇSFTÔºåÂãøË¢´ÂêçÂ≠óÂ±ÄÈôêÔºâ
* `lora_medical.jsonl` --ÂåªÁñóÈóÆÁ≠îÊï∞ÊçÆÈõÜÔºåÊé®ËçêÁî®‰∫éloraËÆ≠ÁªÉÔºà‰∫¶ÂèØÁî®‰∫éÂÖ®ÂèÇSFTÔºåÂãøË¢´ÂêçÂ≠óÂ±ÄÈôêÔºâ
* `pretrain_hq.jsonl`‚ú® --È¢ÑËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºåÊï¥ÂêàËá™Âå†Êï∞ÁßëÊäÄÔºàÊé®ËçêËÆæÁΩÆ`max_seq_len‚âà320`Ôºâ
* `r1_mix_1024.jsonl` --DeepSeek-R1-1.5BËí∏È¶èÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫1024ÔºàÊé®ËçêËÆæÁΩÆ`max_seq_len‚âà720`Ôºâ
* `rlaif-mini.jsonl` --RLAIFËÆ≠ÁªÉÊï∞ÊçÆÈõÜÔºå‰ªéSFTÊï∞ÊçÆÈõÜ‰∏≠ÈöèÊú∫ÈááÊ†∑1‰∏áÊù°È´òË¥®ÈáèÂØπËØùÔºåÁî®‰∫éPPO/GRPO/SPOÁ≠âÂº∫ÂåñÂ≠¶‰π†ÁÆóÊ≥ïËÆ≠ÁªÉ
* `sft_1024.jsonl` --Êï¥ÂêàËá™Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºàÊòØsft_2048ÁöÑÂ≠êÈõÜÔºâÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫1024ÔºàÊé®ËçêËÆæÁΩÆ`max_seq_len‚âà650`Ôºâ
* `sft_2048.jsonl` --Êï¥ÂêàËá™Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫2048ÔºàÊé®ËçêËÆæÁΩÆ`max_seq_len‚âà1400`Ôºâ
* `sft_512.jsonl` --Êï¥ÂêàËá™Âå†Êï∞ÁßëÊäÄSFTÊï∞ÊçÆÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫512ÔºàÊé®ËçêËÆæÁΩÆ`max_seq_len‚âà350`Ôºâ
* `sft_mini_512.jsonl`‚ú® --ÊûÅÁÆÄÊï¥ÂêàËá™Âå†Êï∞ÁßëÊäÄSFTÊï∞ÊçÆ+Qwen2.5Ëí∏È¶èÊï∞ÊçÆÔºàÁî®‰∫éÂø´ÈÄüËÆ≠ÁªÉZeroÊ®°ÂûãÔºâÔºåÊØèÊù°Êï∞ÊçÆÂ≠óÁ¨¶ÊúÄÂ§ßÈïøÂ∫¶‰∏∫512ÔºàÊé®ËçêËÆæÁΩÆ`max_seq_len‚âà340`Ôºâ


ËÆ≠ÁªÉÂèÇÊï∞`max_seq_len`ÁõÆÂâçÊåáÁöÑÊòØtokensÈïøÂ∫¶ÔºåËÄåÈùûÁªùÂØπÂ≠óÁ¨¶Êï∞„ÄÇ
Êú¨È°πÁõÆtokenizerÂú®‰∏≠ÊñáÊñáÊú¨‰∏äÂ§ßÁ∫¶`1.5~1.7 Â≠óÁ¨¶/token`ÔºåÁ∫ØËã±ÊñáÁöÑÂéãÁº©ÊØîÂú®`4~5 Â≠óÁ¨¶/token`Ôºå‰∏çÂêåÊï∞ÊçÆÂàÜÂ∏É‰ºöÊúâÊ≥¢Âä®„ÄÇ
Êï∞ÊçÆÈõÜÂëΩÂêçÊ†áÊ≥®ÁöÑ‚ÄúÊúÄÂ§ßÈïøÂ∫¶‚ÄùÂùá‰∏∫Â≠óÁ¨¶Êï∞Ôºå100ÈïøÂ∫¶ÁöÑÂ≠óÁ¨¶‰∏≤ÂèØÁ≤óÁï•Êç¢ÁÆóÊàê`100/1.5‚âà67`ÁöÑtokensÈïøÂ∫¶„ÄÇ

‰æãÂ¶ÇÔºö

* ‰∏≠ÊñáÔºö`ÁôΩÊó•‰æùÂ±±Â∞Ω`5‰∏™Â≠óÁ¨¶ÂèØËÉΩË¢´ÊãÜÂàÜ‰∏∫[`ÁôΩÊó•`,`‰æù`,`Â±±`,`Â∞Ω`] 4‰∏™tokensÔºõ
* Ëã±ÊñáÔºö`The sun sets in the west`24‰∏™Â≠óÁ¨¶ÂèØËÉΩË¢´ÊãÜÂàÜ‰∏∫[`The `,`sun `,`sets `,`in `,`the`,`west`] 6‰∏™tokens

‚ÄúÊé®ËçêËÆæÁΩÆ‚ÄùÁªôÂá∫‰∫ÜÂêÑ‰∏™Êï∞ÊçÆÈõÜ‰∏äÊúÄÂ§ßtokensÈïøÂ∫¶ÁöÑÁ≤óÁï•‰º∞ËÆ°„ÄÇ
È°ªÁü•max_seq_lenÂèØ‰ª•ÊøÄËøõ/‰øùÂÆà/ÂùáË°°Âú∞Ë∞ÉÊï¥ÔºåÂõ†‰∏∫Êõ¥Â§ßÊàñÊõ¥Â∞èÂùáÊó†Ê≥ïÈÅøÂÖçÂâØ‰ΩúÁî®Ôºö‰∏Ä‰∫õÊ†∑Êú¨Áü≠‰∫émax_seq_lenÂêéË¢´paddingÊµ™Ë¥πÁÆóÂäõÔºå‰∏Ä‰∫õÊ†∑Êú¨Èïø‰∫émax_seq_lenÂêéË¢´Êà™Êñ≠ËØ≠ÊÑè„ÄÇ

Âú® `ÁÆóÂäõÊïàÁéá` &lt;---&gt; `ËØ≠‰πâÂÆåÊï¥ÊÄß` ‰πãÈó¥ÊâæÂà∞‰∏Ä‰∏™Âπ≥Ë°°ÁÇπÂç≥ÂèØ

&lt;/details&gt;


![dataset](./images/dataset.jpg)

&lt;details style=&quot;color:rgb(128,128,128)&quot;&gt;
&lt;summary&gt;ËØ¥Êòé &amp; Êé®ËçêËÆ≠ÁªÉÊñπÊ°à&lt;/summary&gt;

* MiniMind2 SeriesÂùáÁªèËøáÂÖ±Á∫¶20GBËØ≠ÊñôËÆ≠ÁªÉÔºåÂ§ßÁ∫¶4B tokensÔºåÂç≥ÂØπÂ∫î‰∏äÈù¢ÁöÑÊï∞ÊçÆÁªÑÂêàËÆ≠ÁªÉÁªìÊûúÔºàÂºÄÈîÄÔºöüí∞üí∞üí∞üí∞üí∞üí∞üí∞üí∞ÔºåÊïàÊûúÔºöüòäüòäüòäüòäüòäüòäÔºâ

* ÊÉ≥Ë¶ÅÊúÄÂø´ÈÄüÂ∫¶‰ªé0ÂÆûÁé∞ZeroÊ®°ÂûãÔºåÊé®Ëçê‰ΩøÁî®`pretrain_hq.jsonl` + `sft_mini_512.jsonl` ÁöÑÊï∞ÊçÆÁªÑÂêàÔºåÂÖ∑‰ΩìËä±ÈîÄÂíåÊïàÊûúÂèØÊü•Áúã‰∏ãÊñáË°®Ê†ºÔºàÂºÄÈîÄÔºöüí∞ÔºåÊïàÊûúÔºöüòäüòäÔºâ

* Êé®ËçêÂÖ∑Â§á‰∏ÄÂÆöÁÆóÂäõËµÑÊ∫êÊàñÊõ¥Âú®ÊÑèÊïàÊûúÁöÑÊúãÂèãÂèØ‰ª•ËÄÉËôëÂâçËÄÖÂÆåÊï¥Â§çÁé∞MiniMind2Ôºõ‰ªÖÊúâÂçïÂç°GPUÊàñÂú®‰πéÁü≠Êó∂Èó¥Âø´ÈÄüÂ§çÁé∞ÁöÑÊúãÂèãÂº∫ÁÉàÊé®ËçêÂêéËÄÖÔºõ

* „ÄêÊäò‰∏≠ÊñπÊ°à„Äë‰∫¶ÂèØÈÄâÊã©‰æãÂ¶Ç`sft_mini_512.jsonl`„ÄÅ`sft_1024.jsonl`‰∏≠Á≠âËßÑÊ®°Êï∞ÊçÆËøõË°åËá™Áî±ÁªÑÂêàËÆ≠ÁªÉÔºàÂºÄÈîÄÔºöüí∞üí∞üí∞ÔºåÊïàÊûúÔºöüòäüòäüòäüòäÔºâ„ÄÇ

&lt;/details&gt;

# üìå Model

## Structure

MiniMind-DenseÔºàÂíå[Llama3.1](https://ai.meta.com/blog/meta-llama-3-1/)‰∏ÄÊ†∑Ôºâ‰ΩøÁî®‰∫ÜTransformerÁöÑDecoder-OnlyÁªìÊûÑÔºåË∑üGPT-3ÁöÑÂå∫Âà´Âú®‰∫éÔºö

* ÈááÁî®‰∫ÜGPT-3ÁöÑÈ¢ÑÊ†áÂáÜÂåñÊñπÊ≥ïÔºå‰πüÂ∞±ÊòØÂú®ÊØè‰∏™TransformerÂ≠êÂ±ÇÁöÑËæìÂÖ•‰∏äËøõË°åÂΩí‰∏ÄÂåñÔºåËÄå‰∏çÊòØÂú®ËæìÂá∫‰∏ä„ÄÇÂÖ∑‰ΩìÊù•ËØ¥Ôºå‰ΩøÁî®ÁöÑÊòØRMSNormÂΩí‰∏ÄÂåñÂáΩÊï∞„ÄÇ
* Áî®SwiGLUÊøÄÊ¥ªÂáΩÊï∞Êõø‰ª£‰∫ÜReLUÔºåËøôÊ†∑ÂÅöÊòØ‰∏∫‰∫ÜÊèêÈ´òÊÄßËÉΩ„ÄÇ
* ÂÉèGPT-Neo‰∏ÄÊ†∑ÔºåÂéªÊéâ‰∫ÜÁªùÂØπ‰ΩçÁΩÆÂµåÂÖ•ÔºåÊîπÁî®‰∫ÜÊóãËΩ¨‰ΩçÁΩÆÂµåÂÖ•ÔºàRoPEÔºâÔºåËøôÊ†∑Âú®Â§ÑÁêÜË∂ÖÂá∫ËÆ≠ÁªÉÈïøÂ∫¶ÁöÑÊé®ÁêÜÊó∂ÊïàÊûúÊõ¥Â•Ω„ÄÇ

---

MiniMind-MoEÊ®°ÂûãÔºåÂÆÉÁöÑÁªìÊûÑÂü∫‰∫éLlama3Âíå[Deepseek-V2/3](https://arxiv.org/pdf/2405.04434)‰∏≠ÁöÑMixFFNÊ∑∑Âêà‰∏ìÂÆ∂Ê®°Âùó„ÄÇ

* DeepSeek-V2Âú®ÂâçÈ¶àÁΩëÁªúÔºàFFNÔºâÊñπÈù¢ÔºåÈááÁî®‰∫ÜÊõ¥ÁªÜÁ≤íÂ∫¶ÁöÑ‰∏ìÂÆ∂ÂàÜÂâ≤ÂíåÂÖ±‰∫´ÁöÑ‰∏ìÂÆ∂ÈöîÁ¶ªÊäÄÊúØÔºå‰ª•ÊèêÈ´òExpertsÁöÑÊïàÊûú„ÄÇ

---

MiniMindÁöÑÊï¥‰ΩìÁªìÊûÑ‰∏ÄËá¥ÔºåÂè™ÊòØÂú®RoPEËÆ°ÁÆó„ÄÅÊé®ÁêÜÂáΩÊï∞ÂíåFFNÂ±ÇÁöÑ‰ª£Á†Å‰∏äÂÅö‰∫Ü‰∏Ä‰∫õÂ∞èË∞ÉÊï¥„ÄÇ
ÂÖ∂ÁªìÊûÑÂ¶Ç‰∏ãÂõæÔºàÈáçÁªòÁâàÔºâÔºö

![structure](./images/LLM-structure.png)
![structure-moe](./images/LLM-structure-moe.png)

‰øÆÊîπÊ®°ÂûãÈÖçÁΩÆËßÅ[./model/model_minimind.py](./model/model_minimind.py)„ÄÇ
ÂèÇËÄÉÊ®°ÂûãÂèÇÊï∞ÁâàÊú¨ËßÅ‰∏ãË°®Ôºö

| Model Name        | params | len_vocab | rope_theta | n_layers | d_model | kv_heads | q_heads | share+route |
|-------------------|--------|-----------|------------|----------|---------|----------|---------|-------------|
| MiniMind2-Small   | 26M    | 6400      | 1e6        | 8        | 512     | 2        | 8       | -           |
| MiniMind2-MoE     | 145M   | 6400      | 1e6        | 8        | 640     | 2        | 8       | 1+4         |
| MiniMind2         | 104M   | 6400      | 1e6        | 16       | 768     | 2        | 8       | -           |
| minimind-v1-small | 26M    | 6400      | 1e4        | 8        | 512     | 8        | 16      | -           |
| minimind-v1-moe   | 4√ó26M  | 6400      | 1e4        | 8        | 512     | 8        | 16      | 1+4         |
| minimind-v1       | 108M   | 6400      | 1e4        | 16       | 768     | 8        | 16      | -           |


## Model Configuration

üìãÂÖ≥‰∫éLLMÁöÑÂèÇÊï∞ÈÖçÁΩÆÔºåÊúâ‰∏ÄÁØáÂæàÊúâÊÑèÊÄùÁöÑËÆ∫Êñá[MobileLLM](https://arxiv.org/pdf/2402.14905)ÂÅö‰∫ÜËØ¶ÁªÜÁöÑÁ†îÁ©∂ÂíåÂÆûÈ™å„ÄÇ
Scaling LawÂú®Â∞èÊ®°Âûã‰∏≠ÊúâËá™Â∑±Áã¨ÁâπÁöÑËßÑÂæã„ÄÇ
ÂºïËµ∑TransformerÂèÇÊï∞ÊàêËßÑÊ®°ÂèòÂåñÁöÑÂèÇÊï∞Âá†‰πéÂè™ÂèñÂÜ≥‰∫é`d_model`Âíå`n_layers`„ÄÇ

* `d_model`‚Üë + `n_layers`‚Üì -&gt; ÁüÆËÉñÂ≠ê
* `d_model`‚Üì + `n_layers`‚Üë -&gt; Áò¶È´ò‰∏™

2020Âπ¥ÊèêÂá∫Scaling LawÁöÑËÆ∫ÊñáËÆ§‰∏∫ÔºåËÆ≠ÁªÉÊï∞ÊçÆÈáè„ÄÅÂèÇÊï∞Èáè‰ª•ÂèäËÆ≠ÁªÉËø≠‰ª£Ê¨°Êï∞ÊâçÊòØÂÜ≥ÂÆöÊÄßËÉΩÁöÑÂÖ≥ÈîÆÂõ†Á¥†ÔºåËÄåÊ®°ÂûãÊû∂ÊûÑÁöÑÂΩ±ÂìçÂá†‰πéÂèØ‰ª•ÂøΩËßÜ„ÄÇ
ÁÑ∂ËÄå‰ºº‰πéËøô‰∏™ÂÆöÂæãÂØπÂ∞èÊ®°ÂûãÂπ∂‰∏çÂÆåÂÖ®ÈÄÇÁî®„ÄÇ
MobileLLMÊèêÂá∫Êû∂ÊûÑÁöÑÊ∑±Â∫¶ÊØîÂÆΩÂ∫¶Êõ¥ÈáçË¶ÅÔºå„ÄåÊ∑±ËÄåÁ™Ñ„ÄçÁöÑ„ÄåÁò¶Èïø„ÄçÊ®°ÂûãÂèØ‰ª•Â≠¶‰π†Âà∞ÊØî„ÄåÂÆΩËÄåÊµÖ„ÄçÊ®°ÂûãÊõ¥Â§öÁöÑÊäΩË±°Ê¶ÇÂøµ„ÄÇ
‰æãÂ¶ÇÂΩìÊ®°ÂûãÂèÇÊï∞Âõ∫ÂÆöÂú®125MÊàñËÄÖ350MÊó∂Ôºå30ÔΩû42Â±ÇÁöÑ„ÄåÁã≠Èïø„ÄçÊ®°ÂûãÊòéÊòæÊØî12Â±ÇÂ∑¶Âè≥ÁöÑ„ÄåÁüÆËÉñ„ÄçÊ®°ÂûãÊúâÊõ¥‰ºòË∂äÁöÑÊÄßËÉΩÔºå
Âú®Â∏∏ËØÜÊé®ÁêÜ„ÄÅÈóÆÁ≠î„ÄÅÈòÖËØªÁêÜËß£Á≠â8‰∏™Âü∫ÂáÜÊµãËØï‰∏äÈÉΩÊúâÁ±ª‰ººÁöÑË∂ãÂäø„ÄÇ
ËøôÂÖ∂ÂÆûÊòØÈùûÂ∏∏ÊúâË∂£ÁöÑÂèëÁé∞ÔºåÂõ†‰∏∫‰ª•ÂæÄ‰∏∫100MÂ∑¶Âè≥ÈáèÁ∫ßÁöÑÂ∞èÊ®°ÂûãËÆæËÆ°Êû∂ÊûÑÊó∂ÔºåÂá†‰πéÊ≤°‰∫∫Â∞ùËØïËøáÂè†Âä†Ë∂ÖËøá12Â±Ç„ÄÇ
Ëøô‰∏éMiniMindÂú®ËÆ≠ÁªÉËøáÁ®ã‰∏≠ÔºåÊ®°ÂûãÂèÇÊï∞ÈáèÂú®`d_model`Âíå`n_layers`‰πãÈó¥ËøõË°åË∞ÉÊï¥ÂÆûÈ™åËßÇÂØüÂà∞ÁöÑÊïàÊûúÊòØ‰∏ÄËá¥ÁöÑ„ÄÇ
ÁÑ∂ËÄå„ÄåÊ∑±ËÄåÁ™Ñ„ÄçÁöÑ„ÄåÁ™Ñ„Äç‰πüÊòØÊúâÁª¥Â∫¶ÊûÅÈôêÁöÑÔºåÂΩìd_model&lt;512Êó∂ÔºåËØçÂµåÂÖ•Áª¥Â∫¶ÂùçÂ°åÁöÑÂä£ÂäøÈùûÂ∏∏ÊòéÊòæÔºå
Â¢ûÂä†ÁöÑlayersÂπ∂‰∏çËÉΩÂº•Ë°•ËØçÂµåÂÖ•Âú®Âõ∫ÂÆöq_headÂ∏¶Êù•d_head‰∏çË∂≥ÁöÑ

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[github/spec-kit]]></title>
            <link>https://github.com/github/spec-kit</link>
            <guid>https://github.com/github/spec-kit</guid>
            <pubDate>Wed, 04 Feb 2026 00:05:55 GMT</pubDate>
            <description><![CDATA[üí´ Toolkit to help you get started with Spec-Driven Development]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/github/spec-kit">github/spec-kit</a></h1>
            <p>üí´ Toolkit to help you get started with Spec-Driven Development</p>
            <p>Language: Python</p>
            <p>Stars: 67,340</p>
            <p>Forks: 5,813</p>
            <p>Stars today: 269 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
    &lt;img src=&quot;./media/logo_large.webp&quot; alt=&quot;Spec Kit Logo&quot; width=&quot;200&quot; height=&quot;200&quot;/&gt;
    &lt;h1&gt;üå± Spec Kit&lt;/h1&gt;
    &lt;h3&gt;&lt;em&gt;Build high-quality software faster.&lt;/em&gt;&lt;/h3&gt;
&lt;/div&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;strong&gt;An open source toolkit that allows you to focus on product scenarios and predictable outcomes instead of vibe coding every piece from scratch.&lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://github.com/github/spec-kit/actions/workflows/release.yml&quot;&gt;&lt;img src=&quot;https://github.com/github/spec-kit/actions/workflows/release.yml/badge.svg&quot; alt=&quot;Release&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/github/spec-kit/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/github/spec-kit?style=social&quot; alt=&quot;GitHub stars&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.com/github/spec-kit/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/github/spec-kit&quot; alt=&quot;License&quot;/&gt;&lt;/a&gt;
    &lt;a href=&quot;https://github.github.io/spec-kit/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/docs-GitHub_Pages-blue&quot; alt=&quot;Documentation&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

---

## Table of Contents

- [ü§î What is Spec-Driven Development?](#-what-is-spec-driven-development)
- [‚ö° Get Started](#-get-started)
- [üìΩÔ∏è Video Overview](#Ô∏è-video-overview)
- [ü§ñ Supported AI Agents](#-supported-ai-agents)
- [üîß Specify CLI Reference](#-specify-cli-reference)
- [üìö Core Philosophy](#-core-philosophy)
- [üåü Development Phases](#-development-phases)
- [üéØ Experimental Goals](#-experimental-goals)
- [üîß Prerequisites](#-prerequisites)
- [üìñ Learn More](#-learn-more)
- [üìã Detailed Process](#-detailed-process)
- [üîç Troubleshooting](#-troubleshooting)
- [üë• Maintainers](#-maintainers)
- [üí¨ Support](#-support)
- [üôè Acknowledgements](#-acknowledgements)
- [üìÑ License](#-license)

## ü§î What is Spec-Driven Development?

Spec-Driven Development **flips the script** on traditional software development. For decades, code has been king ‚Äî specifications were just scaffolding we built and discarded once the &quot;real work&quot; of coding began. Spec-Driven Development changes this: **specifications become executable**, directly generating working implementations rather than just guiding them.

## ‚ö° Get Started

### 1. Install Specify CLI

Choose your preferred installation method:

#### Option 1: Persistent Installation (Recommended)

Install once and use everywhere:

```bash
uv tool install specify-cli --from git+https://github.com/github/spec-kit.git
```

Then use the tool directly:

```bash
# Create new project
specify init &lt;PROJECT_NAME&gt;

# Or initialize in existing project
specify init . --ai claude
# or
specify init --here --ai claude

# Check installed tools
specify check
```

To upgrade Specify, see the [Upgrade Guide](./docs/upgrade.md) for detailed instructions. Quick upgrade:

```bash
uv tool install specify-cli --force --from git+https://github.com/github/spec-kit.git
```

#### Option 2: One-time Usage

Run directly without installing:

```bash
uvx --from git+https://github.com/github/spec-kit.git specify init &lt;PROJECT_NAME&gt;
```

**Benefits of persistent installation:**

- Tool stays installed and available in PATH
- No need to create shell aliases
- Better tool management with `uv tool list`, `uv tool upgrade`, `uv tool uninstall`
- Cleaner shell configuration

### 2. Establish project principles

Launch your AI assistant in the project directory. The `/speckit.*` commands are available in the assistant.

Use the **`/speckit.constitution`** command to create your project&#039;s governing principles and development guidelines that will guide all subsequent development.

```bash
/speckit.constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements
```

### 3. Create the spec

Use the **`/speckit.specify`** command to describe what you want to build. Focus on the **what** and **why**, not the tech stack.

```bash
/speckit.specify Build an application that can help me organize my photos in separate photo albums. Albums are grouped by date and can be re-organized by dragging and dropping on the main page. Albums are never in other nested albums. Within each album, photos are previewed in a tile-like interface.
```

### 4. Create a technical implementation plan

Use the **`/speckit.plan`** command to provide your tech stack and architecture choices.

```bash
/speckit.plan The application uses Vite with minimal number of libraries. Use vanilla HTML, CSS, and JavaScript as much as possible. Images are not uploaded anywhere and metadata is stored in a local SQLite database.
```

### 5. Break down into tasks

Use **`/speckit.tasks`** to create an actionable task list from your implementation plan.

```bash
/speckit.tasks
```

### 6. Execute implementation

Use **`/speckit.implement`** to execute all tasks and build your feature according to the plan.

```bash
/speckit.implement
```

For detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).

## üìΩÔ∏è Video Overview

Want to see Spec Kit in action? Watch our [video overview](https://www.youtube.com/watch?v=a9eR1xsfvHg&amp;pp=0gcJCckJAYcqIYzv)!

[![Spec Kit video header](/media/spec-kit-video-header.jpg)](https://www.youtube.com/watch?v=a9eR1xsfvHg&amp;pp=0gcJCckJAYcqIYzv)

## ü§ñ Supported AI Agents

| Agent                                                                                | Support | Notes                                                                                                                                     |
| ------------------------------------------------------------------------------------ | ------- | ----------------------------------------------------------------------------------------------------------------------------------------- |
| [Qoder CLI](https://qoder.com/cli)                                                   | ‚úÖ      |                                                                                                                                           |
| [Amazon Q Developer CLI](https://aws.amazon.com/developer/learning/q-developer-cli/) | ‚ö†Ô∏è      | Amazon Q Developer CLI [does not support](https://github.com/aws/amazon-q-developer-cli/issues/3064) custom arguments for slash commands. |
| [Amp](https://ampcode.com/)                                                          | ‚úÖ      |                                                                                                                                           |
| [Auggie CLI](https://docs.augmentcode.com/cli/overview)                              | ‚úÖ      |                                                                                                                                           |
| [Claude Code](https://www.anthropic.com/claude-code)                                 | ‚úÖ      |                                                                                                                                           |
| [CodeBuddy CLI](https://www.codebuddy.ai/cli)                                        | ‚úÖ      |                                                                                                                                           |
| [Codex CLI](https://github.com/openai/codex)                                         | ‚úÖ      |                                                                                                                                           |
| [Cursor](https://cursor.sh/)                                                         | ‚úÖ      |                                                                                                                                           |
| [Gemini CLI](https://github.com/google-gemini/gemini-cli)                            | ‚úÖ      |                                                                                                                                           |
| [GitHub Copilot](https://code.visualstudio.com/)                                     | ‚úÖ      |                                                                                                                                           |
| [IBM Bob](https://www.ibm.com/products/bob)                                          | ‚úÖ      | IDE-based agent with slash command support                                                                                                |
| [Jules](https://jules.google.com/)                                                   | ‚úÖ      |                                                                                                                                           |
| [Kilo Code](https://github.com/Kilo-Org/kilocode)                                    | ‚úÖ      |                                                                                                                                           |
| [opencode](https://opencode.ai/)                                                     | ‚úÖ      |                                                                                                                                           |
| [Qwen Code](https://github.com/QwenLM/qwen-code)                                     | ‚úÖ      |                                                                                                                                           |
| [Roo Code](https://roocode.com/)                                                     | ‚úÖ      |                                                                                                                                           |
| [SHAI (OVHcloud)](https://github.com/ovh/shai)                                       | ‚úÖ      |                                                                                                                                           |
| [Windsurf](https://windsurf.com/)                                                    | ‚úÖ      |                                                                                                                                           |

## üîß Specify CLI Reference

The `specify` command supports the following options:

### Commands

| Command | Description                                                                                                                                             |
| ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `init`  | Initialize a new Specify project from the latest template                                                                                               |
| `check` | Check for installed tools (`git`, `claude`, `gemini`, `code`/`code-insiders`, `cursor-agent`, `windsurf`, `qwen`, `opencode`, `codex`, `shai`, `qoder`) |

### `specify init` Arguments &amp; Options

| Argument/Option        | Type     | Description                                                                                                                                                                                  |
| ---------------------- | -------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `&lt;project-name&gt;`       | Argument | Name for your new project directory (optional if using `--here`, or use `.` for current directory)                                                                                           |
| `--ai`                 | Option   | AI assistant to use: `claude`, `gemini`, `copilot`, `cursor-agent`, `qwen`, `opencode`, `codex`, `windsurf`, `kilocode`, `auggie`, `roo`, `codebuddy`, `amp`, `shai`, `q`, `bob`, or `qoder` |
| `--script`             | Option   | Script variant to use: `sh` (bash/zsh) or `ps` (PowerShell)                                                                                                                                  |
| `--ignore-agent-tools` | Flag     | Skip checks for AI agent tools like Claude Code                                                                                                                                              |
| `--no-git`             | Flag     | Skip git repository initialization                                                                                                                                                           |
| `--here`               | Flag     | Initialize project in the current directory instead of creating a new one                                                                                                                    |
| `--force`              | Flag     | Force merge/overwrite when initializing in current directory (skip confirmation)                                                                                                             |
| `--skip-tls`           | Flag     | Skip SSL/TLS verification (not recommended)                                                                                                                                                  |
| `--debug`              | Flag     | Enable detailed debug output for troubleshooting                                                                                                                                             |
| `--github-token`       | Option   | GitHub token for API requests (or set GH_TOKEN/GITHUB_TOKEN env variable)                                                                                                                    |

### Examples

```bash
# Basic project initialization
specify init my-project

# Initialize with specific AI assistant
specify init my-project --ai claude

# Initialize with Cursor support
specify init my-project --ai cursor-agent

# Initialize with Qoder support
specify init my-project --ai qoder

# Initialize with Windsurf support
specify init my-project --ai windsurf

# Initialize with Amp support
specify init my-project --ai amp

# Initialize with SHAI support
specify init my-project --ai shai

# Initialize with IBM Bob support
specify init my-project --ai bob

# Initialize with PowerShell scripts (Windows/cross-platform)
specify init my-project --ai copilot --script ps

# Initialize in current directory
specify init . --ai copilot
# or use the --here flag
specify init --here --ai copilot

# Force merge into current (non-empty) directory without confirmation
specify init . --force --ai copilot
# or
specify init --here --force --ai copilot

# Skip git initialization
specify init my-project --ai gemini --no-git

# Enable debug output for troubleshooting
specify init my-project --ai claude --debug

# Use GitHub token for API requests (helpful for corporate environments)
specify init my-project --ai claude --github-token ghp_your_token_here

# Check system requirements
specify check
```

### Available Slash Commands

After running `specify init`, your AI coding agent will have access to these slash commands for structured development:

#### Core Commands

Essential commands for the Spec-Driven Development workflow:

| Command                 | Description                                                              |
| ----------------------- | ------------------------------------------------------------------------ |
| `/speckit.constitution` | Create or update project governing principles and development guidelines |
| `/speckit.specify`      | Define what you want to build (requirements and user stories)            |
| `/speckit.plan`         | Create technical implementation plans with your chosen tech stack        |
| `/speckit.tasks`        | Generate actionable task lists for implementation                        |
| `/speckit.implement`    | Execute all tasks to build the feature according to the plan             |

#### Optional Commands

Additional commands for enhanced quality and validation:

| Command              | Description                                                                                                                          |
| -------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| `/speckit.clarify`   | Clarify underspecified areas (recommended before `/speckit.plan`; formerly `/quizme`)                                                |
| `/speckit.analyze`   | Cross-artifact consistency &amp; coverage analysis (run after `/speckit.tasks`, before `/speckit.implement`)                             |
| `/speckit.checklist` | Generate custom quality checklists that validate requirements completeness, clarity, and consistency (like &quot;unit tests for English&quot;) |

### Environment Variables

| Variable          | Description                                                                                                                                                                                                                                                                                            |
| ----------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `SPECIFY_FEATURE` | Override feature detection for non-Git repositories. Set to the feature directory name (e.g., `001-photo-albums`) to work on a specific feature when not using Git branches.&lt;br/&gt;\*\*Must be set in the context of the agent you&#039;re working with prior to using `/speckit.plan` or follow-up commands. |

## üìö Core Philosophy

Spec-Driven Development is a structured process that emphasizes:

- **Intent-driven development** where specifications define the &quot;*what*&quot; before the &quot;*how*&quot;
- **Rich specification creation** using guardrails and organizational principles
- **Multi-step refinement** rather than one-shot code generation from prompts
- **Heavy reliance** on advanced AI model capabilities for specification interpretation

## üåü Development Phases

| Phase                                    | Focus                    | Key Activities                                                                                                                                                     |
| ---------------------------------------- | ------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **0-to-1 Development** (&quot;Greenfield&quot;)    | Generate from scratch    | &lt;ul&gt;&lt;li&gt;Start with high-level requirements&lt;/li&gt;&lt;li&gt;Generate specifications&lt;/li&gt;&lt;li&gt;Plan implementation steps&lt;/li&gt;&lt;li&gt;Build production-ready applications&lt;/li&gt;&lt;/ul&gt; |
| **Creative Exploration**                 | Parallel implementations | &lt;ul&gt;&lt;li&gt;Explore diverse solutions&lt;/li&gt;&lt;li&gt;Support multiple technology stacks &amp; architectures&lt;/li&gt;&lt;li&gt;Experiment with UX patterns&lt;/li&gt;&lt;/ul&gt;                         |
| **Iterative Enhancement** (&quot;Brownfield&quot;) | Brownfield modernization | &lt;ul&gt;&lt;li&gt;Add features iteratively&lt;/li&gt;&lt;li&gt;Modernize legacy systems&lt;/li&gt;&lt;li&gt;Adapt processes&lt;/li&gt;&lt;/ul&gt;                                                                |

## üéØ Experimental Goals

Our research and experimentation focus on:

### Technology independence

- Create applications using diverse technology stacks
- Validate the hypothesis that Spec-Driven Development is a process not tied to specific technologies, programming languages, or frameworks

### Enterprise constraints

- Demonstrate mission-critical application development
- Incorporate organizational constraints (cloud providers, tech stacks, engineering practices)
- Support enterprise design systems and compliance requirements

### User-centric development

- Build applications for different user cohorts and preferences
- Support various

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[TauricResearch/TradingAgents]]></title>
            <link>https://github.com/TauricResearch/TradingAgents</link>
            <guid>https://github.com/TauricResearch/TradingAgents</guid>
            <pubDate>Wed, 04 Feb 2026 00:05:54 GMT</pubDate>
            <description><![CDATA[TradingAgents: Multi-Agents LLM Financial Trading Framework]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/TauricResearch/TradingAgents">TauricResearch/TradingAgents</a></h1>
            <p>TradingAgents: Multi-Agents LLM Financial Trading Framework</p>
            <p>Language: Python</p>
            <p>Stars: 29,179</p>
            <p>Forks: 5,585</p>
            <p>Stars today: 207 stars today</p>
            <h2>README</h2><pre>&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/TauricResearch.png&quot; style=&quot;width: 60%; height: auto;&quot;&gt;
&lt;/p&gt;

&lt;div align=&quot;center&quot; style=&quot;line-height: 1;&quot;&gt;
  &lt;a href=&quot;https://arxiv.org/abs/2412.20138&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;arXiv&quot; src=&quot;https://img.shields.io/badge/arXiv-2412.20138-B31B1B?logo=arxiv&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://discord.com/invite/hk9PGKShPK&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/badge/Discord-TradingResearch-7289da?logo=discord&amp;logoColor=white&amp;color=7289da&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;./assets/wechat.png&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;WeChat&quot; src=&quot;https://img.shields.io/badge/WeChat-TauricResearch-brightgreen?logo=wechat&amp;logoColor=white&quot;/&gt;&lt;/a&gt;
  &lt;a href=&quot;https://x.com/TauricResearch&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;X Follow&quot; src=&quot;https://img.shields.io/badge/X-TauricResearch-white?logo=x&amp;logoColor=white&quot;/&gt;&lt;/a&gt;
  &lt;br&gt;
  &lt;a href=&quot;https://github.com/TauricResearch/&quot; target=&quot;_blank&quot;&gt;&lt;img alt=&quot;Community&quot; src=&quot;https://img.shields.io/badge/Join_GitHub_Community-TauricResearch-14C290?logo=discourse&quot;/&gt;&lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;!-- Keep these links. Translations will automatically update with the README. --&gt;
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=de&quot;&gt;Deutsch&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=es&quot;&gt;Espa√±ol&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=fr&quot;&gt;fran√ßais&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=ja&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=ko&quot;&gt;ÌïúÍµ≠Ïñ¥&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=pt&quot;&gt;Portugu√™s&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=ru&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt; | 
  &lt;a href=&quot;https://www.readme-i18n.com/TauricResearch/TradingAgents?lang=zh&quot;&gt;‰∏≠Êñá&lt;/a&gt;
&lt;/div&gt;

---

# TradingAgents: Multi-Agents LLM Financial Trading Framework 

&gt; üéâ **TradingAgents** officially released! We have received numerous inquiries about the work, and we would like to express our thanks for the enthusiasm in our community.
&gt;
&gt; So we decided to fully open-source the framework. Looking forward to building impactful projects with you!

&lt;div align=&quot;center&quot;&gt;
&lt;a href=&quot;https://www.star-history.com/#TauricResearch/TradingAgents&amp;Date&quot;&gt;
 &lt;picture&gt;
   &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://api.star-history.com/svg?repos=TauricResearch/TradingAgents&amp;type=Date&amp;theme=dark&quot; /&gt;
   &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;https://api.star-history.com/svg?repos=TauricResearch/TradingAgents&amp;type=Date&quot; /&gt;
   &lt;img alt=&quot;TradingAgents Star History&quot; src=&quot;https://api.star-history.com/svg?repos=TauricResearch/TradingAgents&amp;type=Date&quot; style=&quot;width: 80%; height: auto;&quot; /&gt;
 &lt;/picture&gt;
&lt;/a&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

üöÄ [TradingAgents](#tradingagents-framework) | ‚ö° [Installation &amp; CLI](#installation-and-cli) | üé¨ [Demo](https://www.youtube.com/watch?v=90gr5lwjIho) | üì¶ [Package Usage](#tradingagents-package) | ü§ù [Contributing](#contributing) | üìÑ [Citation](#citation)

&lt;/div&gt;

## TradingAgents Framework

TradingAgents is a multi-agent trading framework that mirrors the dynamics of real-world trading firms. By deploying specialized LLM-powered agents: from fundamental analysts, sentiment experts, and technical analysts, to trader, risk management team, the platform collaboratively evaluates market conditions and informs trading decisions. Moreover, these agents engage in dynamic discussions to pinpoint the optimal strategy.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/schema.png&quot; style=&quot;width: 100%; height: auto;&quot;&gt;
&lt;/p&gt;

&gt; TradingAgents framework is designed for research purposes. Trading performance may vary based on many factors, including the chosen backbone language models, model temperature, trading periods, the quality of data, and other non-deterministic factors. [It is not intended as financial, investment, or trading advice.](https://tauric.ai/disclaimer/)

Our framework decomposes complex trading tasks into specialized roles. This ensures the system achieves a robust, scalable approach to market analysis and decision-making.

### Analyst Team
- Fundamentals Analyst: Evaluates company financials and performance metrics, identifying intrinsic values and potential red flags.
- Sentiment Analyst: Analyzes social media and public sentiment using sentiment scoring algorithms to gauge short-term market mood.
- News Analyst: Monitors global news and macroeconomic indicators, interpreting the impact of events on market conditions.
- Technical Analyst: Utilizes technical indicators (like MACD and RSI) to detect trading patterns and forecast price movements.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/analyst.png&quot; width=&quot;100%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

### Researcher Team
- Comprises both bullish and bearish researchers who critically assess the insights provided by the Analyst Team. Through structured debates, they balance potential gains against inherent risks.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/researcher.png&quot; width=&quot;70%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

### Trader Agent
- Composes reports from the analysts and researchers to make informed trading decisions. It determines the timing and magnitude of trades based on comprehensive market insights.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/trader.png&quot; width=&quot;70%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

### Risk Management and Portfolio Manager
- Continuously evaluates portfolio risk by assessing market volatility, liquidity, and other risk factors. The risk management team evaluates and adjusts trading strategies, providing assessment reports to the Portfolio Manager for final decision.
- The Portfolio Manager approves/rejects the transaction proposal. If approved, the order will be sent to the simulated exchange and executed.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/risk.png&quot; width=&quot;70%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

## Installation and CLI

### Installation

Clone TradingAgents:
```bash
git clone https://github.com/TauricResearch/TradingAgents.git
cd TradingAgents
```

Create a virtual environment in any of your favorite environment managers:
```bash
conda create -n tradingagents python=3.13
conda activate tradingagents
```

Install dependencies:
```bash
pip install -r requirements.txt
```

### Required APIs

You will need the OpenAI API for all the agents, and [Alpha Vantage API](https://www.alphavantage.co/support/#api-key) for fundamental and news data (default configuration).

```bash
export OPENAI_API_KEY=$YOUR_OPENAI_API_KEY
export ALPHA_VANTAGE_API_KEY=$YOUR_ALPHA_VANTAGE_API_KEY
```

Alternatively, you can create a `.env` file in the project root with your API keys (see `.env.example` for reference):
```bash
cp .env.example .env
# Edit .env with your actual API keys
```

**Note:** We are happy to partner with Alpha Vantage to provide robust API support for TradingAgents. You can get a free AlphaVantage API [here](https://www.alphavantage.co/support/#api-key), TradingAgents-sourced requests also have increased rate limits to 60 requests per minute with no daily limits. Typically the quota is sufficient for performing complex tasks with TradingAgents thanks to Alpha Vantage‚Äôs open-source support program. If you prefer to use OpenAI for these data sources instead, you can modify the data vendor settings in `tradingagents/default_config.py`.

### CLI Usage

You can also try out the CLI directly by running:
```bash
python -m cli.main
```
You will see a screen where you can select your desired tickers, date, LLMs, research depth, etc.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/cli/cli_init.png&quot; width=&quot;100%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

An interface will appear showing results as they load, letting you track the agent&#039;s progress as it runs.

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/cli/cli_news.png&quot; width=&quot;100%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/cli/cli_transaction.png&quot; width=&quot;100%&quot; style=&quot;display: inline-block; margin: 0 2%;&quot;&gt;
&lt;/p&gt;

## TradingAgents Package

### Implementation Details

We built TradingAgents with LangGraph to ensure flexibility and modularity. We utilize `o1-preview` and `gpt-4o` as our deep thinking and fast thinking LLMs for our experiments. However, for testing purposes, we recommend you use `o4-mini` and `gpt-4.1-mini` to save on costs as our framework makes **lots of** API calls.

### Python Usage

To use TradingAgents inside your code, you can import the `tradingagents` module and initialize a `TradingAgentsGraph()` object. The `.propagate()` function will return a decision. You can run `main.py`, here&#039;s also a quick example:

```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

ta = TradingAgentsGraph(debug=True, config=DEFAULT_CONFIG.copy())

# forward propagate
_, decision = ta.propagate(&quot;NVDA&quot;, &quot;2024-05-10&quot;)
print(decision)
```

You can also adjust the default configuration to set your own choice of LLMs, debate rounds, etc.

```python
from tradingagents.graph.trading_graph import TradingAgentsGraph
from tradingagents.default_config import DEFAULT_CONFIG

# Create a custom config
config = DEFAULT_CONFIG.copy()
config[&quot;deep_think_llm&quot;] = &quot;gpt-4.1-nano&quot;  # Use a different model
config[&quot;quick_think_llm&quot;] = &quot;gpt-4.1-nano&quot;  # Use a different model
config[&quot;max_debate_rounds&quot;] = 1  # Increase debate rounds

# Configure data vendors (default uses yfinance and Alpha Vantage)
config[&quot;data_vendors&quot;] = {
    &quot;core_stock_apis&quot;: &quot;yfinance&quot;,           # Options: yfinance, alpha_vantage, local
    &quot;technical_indicators&quot;: &quot;yfinance&quot;,      # Options: yfinance, alpha_vantage, local
    &quot;fundamental_data&quot;: &quot;alpha_vantage&quot;,     # Options: openai, alpha_vantage, local
    &quot;news_data&quot;: &quot;alpha_vantage&quot;,            # Options: openai, alpha_vantage, google, local
}

# Initialize with custom config
ta = TradingAgentsGraph(debug=True, config=config)

# forward propagate
_, decision = ta.propagate(&quot;NVDA&quot;, &quot;2024-05-10&quot;)
print(decision)
```

&gt; The default configuration uses yfinance for stock price and technical data, and Alpha Vantage for fundamental and news data. For production use or if you encounter rate limits, consider upgrading to [Alpha Vantage Premium](https://www.alphavantage.co/premium/) for more stable and reliable data access. For offline experimentation, there&#039;s a local data vendor option that uses our **Tauric TradingDB**, a curated dataset for backtesting, though this is still in development. We&#039;re currently refining this dataset and plan to release it soon alongside our upcoming projects. Stay tuned!

You can view the full list of configurations in `tradingagents/default_config.py`.

## Contributing

We welcome contributions from the community! Whether it&#039;s fixing a bug, improving documentation, or suggesting a new feature, your input helps make this project better. If you are interested in this line of research, please consider joining our open-source financial AI research community [Tauric Research](https://tauric.ai/).

## Citation

Please reference our work if you find *TradingAgents* provides you with some help :)

```
@misc{xiao2025tradingagentsmultiagentsllmfinancial,
      title={TradingAgents: Multi-Agents LLM Financial Trading Framework}, 
      author={Yijia Xiao and Edward Sun and Di Luo and Wei Wang},
      year={2025},
      eprint={2412.20138},
      archivePrefix={arXiv},
      primaryClass={q-fin.TR},
      url={https://arxiv.org/abs/2412.20138}, 
}
```
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[microsoft/autogen]]></title>
            <link>https://github.com/microsoft/autogen</link>
            <guid>https://github.com/microsoft/autogen</guid>
            <pubDate>Wed, 04 Feb 2026 00:05:53 GMT</pubDate>
            <description><![CDATA[A programming framework for agentic AI]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/microsoft/autogen">microsoft/autogen</a></h1>
            <p>A programming framework for agentic AI</p>
            <p>Language: Python</p>
            <p>Stars: 54,231</p>
            <p>Forks: 8,176</p>
            <p>Stars today: 59 stars today</p>
            <h2>README</h2><pre>&lt;a name=&quot;readme-top&quot;&gt;&lt;/a&gt;

&lt;div align=&quot;center&quot;&gt;
&lt;img src=&quot;https://microsoft.github.io/autogen/0.2/img/ag.svg&quot; alt=&quot;AutoGen Logo&quot; width=&quot;100&quot;&gt;

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/cloudposse.svg?style=social&amp;label=Follow%20%40pyautogen)](https://twitter.com/pyautogen)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Company?style=flat&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/105812540)
[![Discord](https://img.shields.io/badge/discord-chat-green?logo=discord)](https://aka.ms/autogen-discord)
[![Documentation](https://img.shields.io/badge/Documentation-AutoGen-blue?logo=read-the-docs)](https://microsoft.github.io/autogen/)
[![Blog](https://img.shields.io/badge/Blog-AutoGen-blue?logo=blogger)](https://devblogs.microsoft.com/autogen/)

&lt;/div&gt;

# AutoGen

**AutoGen** is a framework for creating multi-agent AI applications that can act autonomously or work alongside humans.

&gt; **Important:** if you are new to AutoGen, please checkout [Microsoft Agent Framework](https://github.com/microsoft/agent-framework).
&gt; AutoGen will still be maintained and continue to receive bug fixes and critical security patches.
&gt; Read our [announcement](https://github.com/microsoft/autogen/discussions/7066).

## Installation

AutoGen requires **Python 3.10 or later**.

```bash
# Install AgentChat and OpenAI client from Extensions
pip install -U &quot;autogen-agentchat&quot; &quot;autogen-ext[openai]&quot;
```

The current stable version can be found in the [releases](https://github.com/microsoft/autogen/releases). If you are upgrading from AutoGen v0.2, please refer to the [Migration Guide](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/migration-guide.html) for detailed instructions on how to update your code and configurations.

```bash
# Install AutoGen Studio for no-code GUI
pip install -U &quot;autogenstudio&quot;
```

## Quickstart

The following samples call OpenAI API, so you first need to create an account and export your key as `export OPENAI_API_KEY=&quot;sk-...&quot;`.

### Hello World

Create an assistant agent using OpenAI&#039;s GPT-4o model. See [other supported models](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/models.html).

```python
import asyncio
from autogen_agentchat.agents import AssistantAgent
from autogen_ext.models.openai import OpenAIChatCompletionClient

async def main() -&gt; None:
    model_client = OpenAIChatCompletionClient(model=&quot;gpt-4.1&quot;)
    agent = AssistantAgent(&quot;assistant&quot;, model_client=model_client)
    print(await agent.run(task=&quot;Say &#039;Hello World!&#039;&quot;))
    await model_client.close()

asyncio.run(main())
```

### MCP Server

Create a web browsing assistant agent that uses the Playwright MCP server.

```python
# First run `npm install -g @playwright/mcp@latest` to install the MCP server.
import asyncio
from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.ui import Console
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_ext.tools.mcp import McpWorkbench, StdioServerParams


async def main() -&gt; None:
    model_client = OpenAIChatCompletionClient(model=&quot;gpt-4.1&quot;)
    server_params = StdioServerParams(
        command=&quot;npx&quot;,
        args=[
            &quot;@playwright/mcp@latest&quot;,
            &quot;--headless&quot;,
        ],
    )
    async with McpWorkbench(server_params) as mcp:
        agent = AssistantAgent(
            &quot;web_browsing_assistant&quot;,
            model_client=model_client,
            workbench=mcp, # For multiple MCP servers, put them in a list.
            model_client_stream=True,
            max_tool_iterations=10,
        )
        await Console(agent.run_stream(task=&quot;Find out how many contributors for the microsoft/autogen repository&quot;))


asyncio.run(main())
```

&gt; **Warning**: Only connect to trusted MCP servers as they may execute commands
&gt; in your local environment or expose sensitive information.

### Multi-Agent Orchestration

You can use `AgentTool` to create a basic multi-agent orchestration setup.

```python
import asyncio

from autogen_agentchat.agents import AssistantAgent
from autogen_agentchat.tools import AgentTool
from autogen_agentchat.ui import Console
from autogen_ext.models.openai import OpenAIChatCompletionClient


async def main() -&gt; None:
    model_client = OpenAIChatCompletionClient(model=&quot;gpt-4.1&quot;)

    math_agent = AssistantAgent(
        &quot;math_expert&quot;,
        model_client=model_client,
        system_message=&quot;You are a math expert.&quot;,
        description=&quot;A math expert assistant.&quot;,
        model_client_stream=True,
    )
    math_agent_tool = AgentTool(math_agent, return_value_as_last_message=True)

    chemistry_agent = AssistantAgent(
        &quot;chemistry_expert&quot;,
        model_client=model_client,
        system_message=&quot;You are a chemistry expert.&quot;,
        description=&quot;A chemistry expert assistant.&quot;,
        model_client_stream=True,
    )
    chemistry_agent_tool = AgentTool(chemistry_agent, return_value_as_last_message=True)

    agent = AssistantAgent(
        &quot;assistant&quot;,
        system_message=&quot;You are a general assistant. Use expert tools when needed.&quot;,
        model_client=model_client,
        model_client_stream=True,
        tools=[math_agent_tool, chemistry_agent_tool],
        max_tool_iterations=10,
    )
    await Console(agent.run_stream(task=&quot;What is the integral of x^2?&quot;))
    await Console(agent.run_stream(task=&quot;What is the molecular weight of water?&quot;))


asyncio.run(main())
```

For more advanced multi-agent orchestrations and workflows, read
[AgentChat documentation](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/index.html).

### AutoGen Studio

Use AutoGen Studio to prototype and run multi-agent workflows without writing code.

```bash
# Run AutoGen Studio on http://localhost:8080
autogenstudio ui --port 8080 --appdir ./my-app
```

## Why Use AutoGen?

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;autogen-landing.jpg&quot; alt=&quot;AutoGen Landing&quot; width=&quot;500&quot;&gt;
&lt;/div&gt;

The AutoGen ecosystem provides everything you need to create AI agents, especially multi-agent workflows -- framework, developer tools, and applications.

The _framework_ uses a layered and extensible design. Layers have clearly divided responsibilities and build on top of layers below. This design enables you to use the framework at different levels of abstraction, from high-level APIs to low-level components.

- [Core API](./python/packages/autogen-core/) implements message passing, event-driven agents, and local and distributed runtime for flexibility and power. It also support cross-language support for .NET and Python.
- [AgentChat API](./python/packages/autogen-agentchat/) implements a simpler but opinionated¬†API for rapid prototyping. This API is built on top of the Core API and is closest to what users of v0.2 are familiar with and supports common multi-agent patterns such as two-agent chat or group chats.
- [Extensions API](./python/packages/autogen-ext/) enables first- and third-party extensions continuously expanding framework capabilities. It support specific implementation of LLM clients (e.g., OpenAI, AzureOpenAI), and capabilities such as code execution.

The ecosystem also supports two essential _developer tools_:

&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://media.githubusercontent.com/media/microsoft/autogen/refs/heads/main/python/packages/autogen-studio/docs/ags_screen.png&quot; alt=&quot;AutoGen Studio Screenshot&quot; width=&quot;500&quot;&gt;
&lt;/div&gt;

- [AutoGen Studio](./python/packages/autogen-studio/) provides a no-code GUI for building multi-agent applications.
- [AutoGen Bench](./python/packages/agbench/) provides a benchmarking suite for evaluating agent performance.

You can use the AutoGen framework and developer tools to create applications for your domain. For example, [Magentic-One](./python/packages/magentic-one-cli/) is a state-of-the-art multi-agent team built using AgentChat API and Extensions API that can handle a variety of tasks that require web browsing, code execution, and file handling.

With AutoGen you get to join and contribute to a thriving ecosystem. We host weekly office hours and talks with maintainers and community. We also have a [Discord server](https://aka.ms/autogen-discord) for real-time chat, GitHub Discussions for Q&amp;A, and a blog for tutorials and updates.

## Where to go next?

&lt;div align=&quot;center&quot;&gt;

|               | [![Python](https://img.shields.io/badge/AutoGen-Python-blue?logo=python&amp;logoColor=white)](./python)                                                                                                                                                                                                                                                                                                                | [![.NET](https://img.shields.io/badge/AutoGen-.NET-green?logo=.net&amp;logoColor=white)](./dotnet)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | [![Studio](https://img.shields.io/badge/AutoGen-Studio-purple?logo=visual-studio&amp;logoColor=white)](./python/packages/autogen-studio)                        |
| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Installation  | [![Installation](https://img.shields.io/badge/Install-blue)](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/installation.html)                                                                                                                                                                                                                                                         | [![Install](https://img.shields.io/badge/Install-green)](https://microsoft.github.io/autogen/dotnet/dev/core/installation.html)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | [![Install](https://img.shields.io/badge/Install-purple)](https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/installation.html) |
| Quickstart    | [![Quickstart](https://img.shields.io/badge/Quickstart-blue)](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/quickstart.html#)                                                                                                                                                                                                                                                         | [![Quickstart](https://img.shields.io/badge/Quickstart-green)](https://microsoft.github.io/autogen/dotnet/dev/core/index.html)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    | [![Usage](https://img.shields.io/badge/Quickstart-purple)](https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/usage.html#)      |
| Tutorial      | [![Tutorial](https://img.shields.io/badge/Tutorial-blue)](https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/tutorial/index.html)                                                                                                                                                                                                                                                          | [![Tutorial](https://img.shields.io/badge/Tutorial-green)](https://microsoft.github.io/autogen/dotnet/dev/core/tutorial.html)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | [![Usage](https://img.shields.io/badge/Tutorial-purple)](https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/usage.html#)        |
| API Reference | [![API](https://img.shields.io/badge/Docs-blue)](https://microsoft.github.io/autogen/stable/reference/index.html#)                                                                                                                                                                                                                                                                                                 | [![API](https://img.shields.io/badge/Docs-green)](https://microsoft.github.io/autogen/dotnet/dev/api/Microsoft.AutoGen.Contracts.html)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | [![API](https://img.shields.io/badge/Docs-purple)](https://microsoft.github.io/autogen/stable/user-guide/autogenstudio-user-guide/usage.html)               |
| Packages      | [![PyPi autogen-core](https://img.shields.io/badge/PyPi-autogen--core-blue?logo=pypi)](https://pypi.org/project/autogen-core/) &lt;br&gt; [![PyPi autogen-agentchat](https://img.shields.io/badge/PyPi-autogen--agentchat-blue?logo=pypi)](https://pypi.org/project/autogen-agentchat/) &lt;br&gt; [![PyPi autogen-ext](https://img.shields.io/badge/PyPi-autogen--ext-blue?logo=pypi)](https://pypi.org/project/autogen-ext/) | [![NuGet Contracts](https://img.shields.io/badge/NuGet-Contracts-green?logo=nuget)](https://www.nuget.org/packages/Microsoft.AutoGen.Contracts/) &lt;br&gt; [![NuGet Core](https://img.shields.io/badge/NuGet-Core-green?logo=nuget)](https://www.nuget.org/packages/Microsoft.AutoGen.Core/) &lt;br&gt; [![NuGet Core.Grpc](https://img.shields.io/badge/NuGet-Core.Grpc-green?logo=nuget)](https://www.nuget.org/packages/Microsoft.AutoGen.Core.Grpc/) &lt;br&gt; [![NuGet RuntimeGateway.Grpc](https://img.shields.io/badge/NuGet-RuntimeGateway.Grpc-green?logo=nuget)](https://www.nuget.org/packages/Microsoft.AutoGen.RuntimeGateway.Grpc/) | [![PyPi autogenstudio](https://img.shields.io/badge/PyPi-autogenstudio-purple?logo=pypi)](https://pypi.org/project/autogenstudio/)                          |

&lt;/div&gt;

Interested in contributing? See [CONTRIBUTING.md](./CONTRIBUTING.md) for guidelines on how to get started. We welcome contributions of all kinds, including bug fixes, new features, and documentation improvements. Join our community and help us make AutoGen better!

Have questions? Check out our [Frequently Asked Questions (FAQ)](./FAQ.md) for answers to common queries. If you don&#039;t find what you&#039;re looking for, feel free to ask in our [GitHub Discussions](https://github.com/microsoft/autogen/discussions) or join our [Discord server](https://aka.ms/autogen-discord) for real-time support. You can also read our [blog](https://devblogs.microsoft.com/autogen/) for updates.

## Legal Notices

Microsoft and any contributors grant you a license to the Microsoft documentation and other content
in this repository under the [Creative Commons Attribution 4.0 International Public License](https://creativecommons.org/licenses/by/4.0/legalcode),
see the [LICENSE](LICENSE) file, and grant you a license to any code in the repository under the [MIT License](https://opensource.org/licenses/MIT), see the
[LICENSE-CODE](LICENSE-CODE) file.

Microsoft, Windows, Microsoft Azure, and/or other Microsoft products and services referenced in the documentation
may be either trademarks or registered trademarks of Microsoft in the United States and/or other countries.
The licenses for this project do not grant you rights to use any Microsoft names, logos, or trademarks.
Microsoft&#039;s general trademark guidelines can be found at &lt;http://go.microsoft.com/fwlink/?LinkID=254653&gt;.

Privacy information can be found at &lt;https://go.microsoft.com/fwlink/?LinkId=521839&gt;

Microsoft and any contributors reserve all other rights, whether under their respective copyrights, patents,
or trademarks, whether by implication, estoppel, or otherwise.

&lt;p align=&quot;right&quot; style=&quot;font-size: 14px; color: #555; margin-top: 20px;&quot;&gt;
  &lt;a href=&quot;#readme-top&quot; style=&quot;text-decoration: none; color: blue; font-weight: bold;&quot;&gt;
    ‚Üë Back to Top ‚Üë
  &lt;/a&gt;
&lt;/p&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[vanna-ai/vanna]]></title>
            <link>https://github.com/vanna-ai/vanna</link>
            <guid>https://github.com/vanna-ai/vanna</guid>
            <pubDate>Wed, 04 Feb 2026 00:05:52 GMT</pubDate>
            <description><![CDATA[ü§ñ Chat with your SQL database üìä. Accurate Text-to-SQL Generation via LLMs using Agentic Retrieval üîÑ.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/vanna-ai/vanna">vanna-ai/vanna</a></h1>
            <p>ü§ñ Chat with your SQL database üìä. Accurate Text-to-SQL Generation via LLMs using Agentic Retrieval üîÑ.</p>
            <p>Language: Python</p>
            <p>Stars: 22,510</p>
            <p>Forks: 2,166</p>
            <p>Stars today: 25 stars today</p>
            <h2>README</h2><pre># Vanna 2.0: Turn Questions into Data Insights

**Natural language ‚Üí SQL ‚Üí Answers.** Now with enterprise security and user-aware permissions.

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://python.org)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

https://github.com/user-attachments/assets/476cd421-d0b0-46af-8b29-0f40c73d6d83


![Vanna2 Demo](img/architecture.png)

---

## What&#039;s New in 2.0

üîê **User-Aware at Every Layer** ‚Äî Queries automatically filtered per user permissions

üé® **Modern Web Interface** ‚Äî Beautiful pre-built `&lt;vanna-chat&gt;` component

‚ö° **Streaming Responses** ‚Äî Real-time tables, charts, and progress updates

üîí **Enterprise Security** ‚Äî Row-level security, audit logs, rate limiting

üîÑ **Production-Ready** ‚Äî FastAPI integration, observability, lifecycle hooks

&gt; **Upgrading from 0.x?** See the [Migration Guide](MIGRATION_GUIDE.md) | [What changed?](#migration-notes)

---

## Get Started

### Try it with Sample Data

[Quickstart](https://vanna.ai/docs/quick-start)

### Configure

[Configure](https://vanna.ai/docs/configure)

### Web Component

```html
&lt;!-- Drop into any existing webpage --&gt;
&lt;script src=&quot;https://img.vanna.ai/vanna-components.js&quot;&gt;&lt;/script&gt;
&lt;vanna-chat
  sse-endpoint=&quot;https://your-api.com/chat&quot;
  theme=&quot;dark&quot;&gt;
&lt;/vanna-chat&gt;
```

Uses your existing cookies/JWTs. Works with React, Vue, or plain HTML.

---

## What You Get

Ask a question in natural language and get back:

**1. Streaming Progress Updates**

**2. SQL Code Block (By default only shown to &quot;admin&quot; users)**

**3. Interactive Data Table**

**4. Charts** (Plotly visualizations)

**5. Natural Language Summary**

All streamed in real-time to your web component.

---

## Why Vanna 2.0?

### ‚úÖ Get Started Instantly
* Production chat interface
* Custom agent with your database
* Embed in any webpage

### ‚úÖ Enterprise-Ready Security
**User-aware at every layer** ‚Äî Identity flows through system prompts, tool execution, and SQL filtering
**Row-level security** ‚Äî Queries automatically filtered per user permissions
**Audit logs** ‚Äî Every query tracked per user for compliance
**Rate limiting** ‚Äî Per-user quotas via lifecycle hooks

### ‚úÖ Beautiful Web UI Included
**Pre-built `&lt;vanna-chat&gt;` component** ‚Äî No need to build your own chat interface
**Streaming tables &amp; charts** ‚Äî Rich components, not just text
**Responsive &amp; customizable** ‚Äî Works on mobile, desktop, light/dark themes
**Framework-agnostic** ‚Äî React, Vue, plain HTML

### ‚úÖ Works With Your Stack
**Any LLM:** OpenAI, Anthropic, Ollama, Azure, Google Gemini, AWS Bedrock, Mistral, Others
**Any Database:** PostgreSQL, MySQL, Snowflake, BigQuery, Redshift, SQLite, Oracle, SQL Server, DuckDB, ClickHouse, Others
**Your Auth System:** Bring your own ‚Äî cookies, JWTs, OAuth tokens
**Your Framework:** FastAPI, Flask

### ‚úÖ Extensible But Opinionated
**Custom tools** ‚Äî Extend the `Tool` base class
**Lifecycle hooks** ‚Äî Quota checking, logging, content filtering
**LLM middlewares** ‚Äî Caching, prompt engineering
**Observability** ‚Äî Built-in tracing and metrics

---

## Architecture

![Vanna2 Diagram](img/vanna2.svg)

---

## How It Works

```mermaid
sequenceDiagram
    participant U as üë§ User
    participant W as üåê &lt;vanna-chat&gt;
    participant S as üêç Your Server
    participant A as ü§ñ Agent
    participant T as üß∞ Tools

    U-&gt;&gt;W: &quot;Show Q4 sales&quot;
    W-&gt;&gt;S: POST /api/vanna/v2/chat_sse (with auth)
    S-&gt;&gt;A: User(id=alice, groups=[read_sales])
    A-&gt;&gt;T: Execute SQL tool (user-aware)
    T-&gt;&gt;T: Apply row-level security
    T-&gt;&gt;A: Filtered results
    A-&gt;&gt;W: Stream: Table ‚Üí Chart ‚Üí Summary
    W-&gt;&gt;U: Display beautiful UI
```

**Key Concepts:**

1. **User Resolver** ‚Äî You define how to extract user identity from requests (cookies, JWTs, etc.)
2. **User-Aware Tools** ‚Äî Tools automatically check permissions based on user&#039;s group memberships
3. **Streaming Components** ‚Äî Backend streams structured UI components (tables, charts) to frontend
4. **Built-in Web UI** ‚Äî Pre-built `&lt;vanna-chat&gt;` component renders everything beautifully

---

## Production Setup with Your Auth

Here&#039;s a complete example integrating Vanna with your existing FastAPI app and authentication:

```python
from fastapi import FastAPI
from vanna import Agent
from vanna.servers.fastapi.routes import register_chat_routes
from vanna.servers.base import ChatHandler
from vanna.core.user import UserResolver, User, RequestContext
from vanna.integrations.anthropic import AnthropicLlmService
from vanna.tools import RunSqlTool
from vanna.integrations.sqlite import SqliteRunner
from vanna.core.registry import ToolRegistry

# Your existing FastAPI app
app = FastAPI()

# 1. Define your user resolver (using YOUR auth system)
class MyUserResolver(UserResolver):
    async def resolve_user(self, request_context: RequestContext) -&gt; User:
        # Extract from cookies, JWTs, or session
        token = request_context.get_header(&#039;Authorization&#039;)
        user_data = self.decode_jwt(token)  # Your existing logic

        return User(
            id=user_data[&#039;id&#039;],
            email=user_data[&#039;email&#039;],
            group_memberships=user_data[&#039;groups&#039;]  # Used for permissions
        )

# 2. Set up agent with tools
llm = AnthropicLlmService(model=&quot;claude-sonnet-4-5&quot;)
tools = ToolRegistry()
tools.register(RunSqlTool(sql_runner=SqliteRunner(&quot;./data.db&quot;)))

agent = Agent(
    llm_service=llm,
    tool_registry=tools,
    user_resolver=MyUserResolver()
)

# 3. Add Vanna routes to your app
chat_handler = ChatHandler(agent)
register_chat_routes(app, chat_handler)

# Now you have:
# - POST /api/vanna/v2/chat_sse (streaming endpoint)
# - GET / (optional web UI)
```

**Then in your frontend:**
```html
&lt;vanna-chat sse-endpoint=&quot;/api/vanna/v2/chat_sse&quot;&gt;&lt;/vanna-chat&gt;
```

See [Full Documentation](https://vanna.ai/docs) for custom tools, lifecycle hooks, and advanced configuration

---

## Custom Tools

Extend Vanna with custom tools for your specific use case:

```python
from vanna.core.tool import Tool, ToolContext, ToolResult
from pydantic import BaseModel, Field
from typing import Type

class EmailArgs(BaseModel):
    recipient: str = Field(description=&quot;Email recipient&quot;)
    subject: str = Field(description=&quot;Email subject&quot;)

class EmailTool(Tool[EmailArgs]):
    @property
    def name(self) -&gt; str:
        return &quot;send_email&quot;

    @property
    def access_groups(self) -&gt; list[str]:
        return [&quot;send_email&quot;]  # Permission check

    def get_args_schema(self) -&gt; Type[EmailArgs]:
        return EmailArgs

    async def execute(self, context: ToolContext, args: EmailArgs) -&gt; ToolResult:
        user = context.user  # Automatically injected

        # Your business logic
        await self.email_service.send(
            from_email=user.email,
            to=args.recipient,
            subject=args.subject
        )

        return ToolResult(success=True, result_for_llm=f&quot;Email sent to {args.recipient}&quot;)

# Register your tool
tools.register(EmailTool())
```

---

## Advanced Features

Vanna 2.0 includes powerful enterprise features for production use:

**Lifecycle Hooks** ‚Äî Add quota checking, custom logging, content filtering at key points in the request lifecycle

**LLM Middlewares** ‚Äî Implement caching, prompt engineering, or cost tracking around LLM calls

**Conversation Storage** ‚Äî Persist and retrieve conversation history per user

**Observability** ‚Äî Built-in tracing and metrics integration

**Context Enrichers** ‚Äî Add RAG, memory, or documentation to enhance agent responses

**Agent Configuration** ‚Äî Control streaming, temperature, max iterations, and more

---

## Use Cases

**Vanna is ideal for:**
- üìä Data analytics applications with natural language interfaces
- üîê Multi-tenant SaaS needing user-aware permissions
- üé® Teams wanting a pre-built web component + backend
- üè¢ Enterprise environments with security/audit requirements
- üìà Applications needing rich streaming responses (tables, charts, SQL)
- üîÑ Integrating with existing authentication systems

---

## Community &amp; Support

- üìñ **[Full Documentation](https://vanna.ai/docs)** ‚Äî Complete guides and API reference
- üí° **[GitHub Discussions](https://github.com/vanna-ai/vanna/discussions)** ‚Äî Feature requests and Q&amp;A
- üêõ **[GitHub Issues](https://github.com/vanna-ai/vanna/issues)** ‚Äî Bug reports
- üìß **Enterprise Support** ‚Äî support@vanna.ai

---

## Migration Notes

**Upgrading from Vanna 0.x?**

Vanna 2.0 is a complete rewrite focused on user-aware agents and production deployments. Key changes:

- **New API**: Agent-based instead of `VannaBase` class methods
- **User-aware**: Every component now knows the user identity
- **Streaming**: Rich UI components instead of text/dataframes
- **Web-first**: Built-in `&lt;vanna-chat&gt;` component and server

**Migration path:**

1. **Quick wrap** ‚Äî Use `LegacyVannaAdapter` to wrap your existing Vanna 0.x instance and get the new web UI immediately
2. **Gradual migration** ‚Äî Incrementally move to the new Agent API and tools

See the complete [Migration Guide](MIGRATION_GUIDE.md) for step-by-step instructions.

---

## License

MIT License ‚Äî See [LICENSE](LICENSE) for details.

---

**Built with ‚ù§Ô∏è by the Vanna team** | [Website](https://vanna.ai) | [Docs](https://vanna.ai/docs) | [Discussions](https://github.com/vanna-ai/vanna/discussions)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>