<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>GitHub Trending Today for python - Python Daily</title>
        <link>https://github.com/trending</link>
        <description>The most popular GitHub repositories today for python.</description>
        <lastBuildDate>Wed, 25 Feb 2026 00:08:44 GMT</lastBuildDate>
        <docs>https://validator.w3.org/feed/docs/rss2.html</docs>
        <generator>GitHub Trending RSS Generator</generator>
        <language>en</language>
        <copyright>All rights reserved 2026, GitHub</copyright>
        <item>
            <title><![CDATA[huggingface/skills]]></title>
            <link>https://github.com/huggingface/skills</link>
            <guid>https://github.com/huggingface/skills</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:44 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/huggingface/skills">huggingface/skills</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 5,234</p>
            <p>Forks: 335</p>
            <p>Stars today: 1,206 stars today</p>
            <h2>README</h2><pre># Hugging Face Skills

Hugging Face Skills are definitions for AI/ML tasks like dataset creation, model training, and evaluation. They are interoperable with all major coding agent tools like OpenAI Codex, Anthropic&#039;s Claude Code, Google DeepMind&#039;s Gemini CLI, and Cursor.

The Skills in this repository follow the standardized format [Agent Skill](https://agentskills.io/home) format.

## How do Skills work?

In practice, skills are self-contained folders that package instructions, scripts, and resources together for an AI agent to use on a specific use case. Each folder includes a `SKILL.md` file with YAML frontmatter (name and description) followed by the guidance your coding agent follows while the skill is active. 

&gt; [!NOTE]
&gt; &#039;Skills&#039; is actually an Anthropic term used within Claude AI and Claude Code and not adopted by other agent tools, but we love it! OpenAI Codex uses an `AGENTS.md` file to define the instructions for your coding agent. Google Gemini uses &#039;extensions&#039; to define the instructions for your coding agent in a `gemini-extension.json` file. **This repo is compatible with all of them, and more!**

&gt; [!TIP]
&gt; If your agent doesn&#039;t support skills, you can use [`agents/AGENTS.md`](agents/AGENTS.md) directly as a fallback.

## Installation

Hugging Face skills are compatible with Claude Code, Codex, Gemini CLI, and Cursor.

### Claude Code

1. Register the repository as a plugin marketplace:  
   
```
/plugin marketplace add huggingface/skills
```

2. To install a skill, run:  
   
```
/plugin install &lt;skill-name&gt;@huggingface/skills
```

For example:  

```
/plugin install hugging-face-cli@huggingface/skills
```

### Codex

1. Codex will identify the skills via the `AGENTS.md` file. You can verify the instructions are loaded with:

```
codex --ask-for-approval never &quot;Summarize the current instructions.&quot;
```

2. For more details, see the [Codex AGENTS guide](https://developers.openai.com/codex/guides/agents-md).

### Gemini CLI

1. This repo includes `gemini-extension.json` to integrate with the Gemini CLI.

2. Install locally:  

```
gemini extensions install . --consent
```

or use the GitHub URL:

```
gemini extensions install https://github.com/huggingface/skills.git --consent
```

4. See [Gemini CLI extensions docs](https://geminicli.com/docs/extensions/#installing-an-extension) for more help.

### Cursor

This repository includes Cursor plugin manifests:

- `.cursor-plugin/plugin.json`
- `.mcp.json` (configured with the Hugging Face MCP server URL)

Install from repository URL (or local checkout) via the Cursor plugin flow.

For contributors, regenerate manifests with:

```bash
./scripts/publish.sh
```

## Skills

This repository contains a few skills to get you started. You can also contribute your own skills to the repository.

### Available skills

&lt;!-- This table is auto-generated by scripts/generate_agents.py. Do not edit manually. --&gt;
&lt;!-- BEGIN_SKILLS_TABLE --&gt;
| Name | Description | Documentation |
|------|-------------|---------------|
| `hugging-face-cli` | Execute Hugging Face Hub operations using the hf CLI. Download models/datasets, upload files, manage repos, and run cloud compute jobs. | [SKILL.md](skills/hugging-face-cli/SKILL.md) |
| `hugging-face-datasets` | Create and manage datasets on Hugging Face Hub. Supports initializing repos, defining configs/system prompts, streaming row updates, and SQL-based dataset querying/transformation. | [SKILL.md](skills/hugging-face-datasets/SKILL.md) |
| `hugging-face-evaluation` | Add and manage evaluation results in Hugging Face model cards. Supports extracting eval tables from README content, importing scores from Artificial Analysis API, and running custom evaluations with vLLM/lighteval. | [SKILL.md](skills/hugging-face-evaluation/SKILL.md) |
| `hugging-face-jobs` | Run compute jobs on Hugging Face infrastructure. Execute Python scripts, manage scheduled jobs, and monitor job status. | [SKILL.md](skills/hugging-face-jobs/SKILL.md) |
| `hugging-face-model-trainer` | Train or fine-tune language models using TRL on Hugging Face Jobs infrastructure. Covers SFT, DPO, GRPO and reward modeling training methods, plus GGUF conversion for local deployment. Includes hardware selection, cost estimation, Trackio monitoring, and Hub persistence. | [SKILL.md](skills/hugging-face-model-trainer/SKILL.md) |
| `hugging-face-paper-publisher` | Publish and manage research papers on Hugging Face Hub. Supports creating paper pages, linking papers to models/datasets, claiming authorship, and generating professional markdown-based research articles. | [SKILL.md](skills/hugging-face-paper-publisher/SKILL.md) |
| `hugging-face-tool-builder` | Build reusable scripts for Hugging Face API operations. Useful for chaining API calls or automating repeated tasks. | [SKILL.md](skills/hugging-face-tool-builder/SKILL.md) |
| `hugging-face-trackio` | Track and visualize ML training experiments with Trackio. Log metrics via Python API and retrieve them via CLI. Supports real-time dashboards synced to HF Spaces. | [SKILL.md](skills/hugging-face-trackio/SKILL.md) |
&lt;!-- END_SKILLS_TABLE --&gt;

### Using skills in your coding agent

Once a skill is installed, mention it directly while giving your coding agent instructions:

- &quot;Use the HF LLM trainer skill to estimate the GPU memory needed for a 70B model run.&quot;
- &quot;Use the HF model evaluation skill to launch `run_eval_job.py` on the latest checkpoint.&quot;
- &quot;Use the HF dataset creator skill to draft new few-shot classification templates.&quot;
- &quot;Use the HF paper publisher skill to index my arXiv paper and link it to my model.&quot;

Your coding agent automatically loads the corresponding `SKILL.md` instructions and helper scripts while it completes the task.

### Contribute or customize a skill

1. Copy one of the existing skill folders (for example, `hf-datasets/`) and rename it.
2. Update the new folder&#039;s `SKILL.md` frontmatter:
   ```markdown
   ---
   name: my-skill-name
   description: Describe what the skill does and when to use it
   ---

   # Skill Title
   Guidance + examples + guardrails
   ```
3. Add or edit supporting scripts, templates, and documents referenced by your instructions.
4. Add an entry to `.claude-plugin/marketplace.json` with a concise, human-readable description.
5. Run:
   ```bash
   ./scripts/publish.sh
   ```
   to regenerate and validate all generated metadata.
6. Reinstall or reload the skill bundle in your coding agent so the updated folder is available.

### Marketplace

The `.claude-plugin/marketplace.json` file lists skills with human-readable descriptions for the plugin marketplace. The CI validates that skill names and paths match between `SKILL.md` files and `marketplace.json`, but descriptions are maintained separately: `SKILL.md` descriptions guide when Claude activates the skill, while marketplace descriptions are written for humans browsing available skills.

### Additional references
- Browse the latest instructions, scripts, and templates directly at [huggingface/skills](https://github.com/huggingface/skills).
- Review Hugging Face documentation for the specific libraries or workflows you reference inside each skill.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[muratcankoylan/Agent-Skills-for-Context-Engineering]]></title>
            <link>https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering</link>
            <guid>https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:43 GMT</pubDate>
            <description><![CDATA[A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems. Use when building, optimizing, or debugging agent systems that require effective context management.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/muratcankoylan/Agent-Skills-for-Context-Engineering">muratcankoylan/Agent-Skills-for-Context-Engineering</a></h1>
            <p>A comprehensive collection of Agent Skills for context engineering, multi-agent architectures, and production agent systems. Use when building, optimizing, or debugging agent systems that require effective context management.</p>
            <p>Language: Python</p>
            <p>Stars: 9,851</p>
            <p>Forks: 780</p>
            <p>Stars today: 722 stars today</p>
            <h2>README</h2><pre># Agent Skills for Context Engineering

A comprehensive, open collection of Agent Skills focused on context engineering principles for building production-grade AI agent systems. These skills teach the art and science of curating context to maximize agent effectiveness across any agent platform.

## What is Context Engineering?

Context engineering is the discipline of managing the language model&#039;s context window. Unlike prompt engineering, which focuses on crafting effective instructions, context engineering addresses the holistic curation of all information that enters the model&#039;s limited attention budget: system prompts, tool definitions, retrieved documents, message history, and tool outputs.

The fundamental challenge is that context windows are constrained not by raw token capacity but by attention mechanics. As context length increases, models exhibit predictable degradation patterns: the &quot;lost-in-the-middle&quot; phenomenon, U-shaped attention curves, and attention scarcity. Effective context engineering means finding the smallest possible set of high-signal tokens that maximize the likelihood of desired outcomes.

## Recognition

This repository is cited in academic research as foundational work on static skill architecture:

&gt; &quot;While static skills are well-recognized [Anthropic, 2025b; Muratcan Koylan, 2025], MCE is among the first to dynamically evolve them, bridging manual skill engineering and autonomous self-improvement.&quot;

‚Äî [Meta Context Engineering via Agentic Skill Evolution](https://arxiv.org/pdf/2601.21557), Peking University State Key Laboratory of General Artificial Intelligence (2026)

## Skills Overview

### Foundational Skills

These skills establish the foundational understanding required for all subsequent context engineering work.

| Skill | Description |
|-------|-------------|
| [context-fundamentals](skills/context-fundamentals/) | Understand what context is, why it matters, and the anatomy of context in agent systems |
| [context-degradation](skills/context-degradation/) | Recognize patterns of context failure: lost-in-middle, poisoning, distraction, and clash |
| [context-compression](skills/context-compression/) | Design and evaluate compression strategies for long-running sessions |

### Architectural Skills

These skills cover the patterns and structures for building effective agent systems.

| Skill | Description |
|-------|-------------|
| [multi-agent-patterns](skills/multi-agent-patterns/) | Master orchestrator, peer-to-peer, and hierarchical multi-agent architectures |
| [memory-systems](skills/memory-systems/) | Design short-term, long-term, and graph-based memory architectures |
| [tool-design](skills/tool-design/) | Build tools that agents can use effectively |
| [filesystem-context](skills/filesystem-context/) | Use filesystems for dynamic context discovery, tool output offloading, and plan persistence |
| [hosted-agents](skills/hosted-agents/) | **NEW** Build background coding agents with sandboxed VMs, pre-built images, multiplayer support, and multi-client interfaces |

### Operational Skills

These skills address the ongoing operation and optimization of agent systems.

| Skill | Description |
|-------|-------------|
| [context-optimization](skills/context-optimization/) | Apply compaction, masking, and caching strategies |
| [evaluation](skills/evaluation/) | Build evaluation frameworks for agent systems |
| [advanced-evaluation](skills/advanced-evaluation/) | Master LLM-as-a-Judge techniques: direct scoring, pairwise comparison, rubric generation, and bias mitigation |

### Development Methodology

These skills cover the meta-level practices for building LLM-powered projects.

| Skill | Description |
|-------|-------------|
| [project-development](skills/project-development/) | Design and build LLM projects from ideation through deployment, including task-model fit analysis, pipeline architecture, and structured output design |

### Cognitive Architecture Skills

These skills cover formal cognitive modeling for rational agent systems.

| Skill | Description |
|-------|-------------|
| [bdi-mental-states](skills/bdi-mental-states/) | **NEW** Transform external RDF context into agent mental states (beliefs, desires, intentions) using formal BDI ontology patterns for deliberative reasoning and explainability |

## Design Philosophy

### Progressive Disclosure

Each skill is structured for efficient context use. At startup, agents load only skill names and descriptions. Full content loads only when a skill is activated for relevant tasks.

### Platform Agnosticism

These skills focus on transferable principles rather than vendor-specific implementations. The patterns work across Claude Code, Cursor, and any agent platform that supports skills or allows custom instructions.

### Conceptual Foundation with Practical Examples

Scripts and examples demonstrate concepts using Python pseudocode that works across environments without requiring specific dependency installations.

## Usage

### Usage with Claude Code

This repository is a **Claude Code Plugin Marketplace** containing context engineering skills that Claude automatically discovers and activates based on your task context.

### Installation

**Step 1: Add the Marketplace**

Run this command in Claude Code to register this repository as a plugin source:

```
/plugin marketplace add muratcankoylan/Agent-Skills-for-Context-Engineering
```

**Step 2: Browse and Install**

Option A - Browse available plugins:
1. Select `Browse and install plugins`
2. Select `context-engineering-marketplace`
3. Choose a plugin (e.g., `context-engineering-fundamentals`, `agent-architecture`)
4. Select `Install now`

Option B - Direct install via command:

```
/plugin install context-engineering-fundamentals@context-engineering-marketplace
/plugin install agent-architecture@context-engineering-marketplace
/plugin install agent-evaluation@context-engineering-marketplace
/plugin install agent-development@context-engineering-marketplace
/plugin install cognitive-architecture@context-engineering-marketplace
```

### Available Plugins

| Plugin | Skills Included |
|--------|-----------------|
| `context-engineering-fundamentals` | context-fundamentals, context-degradation, context-compression, context-optimization |
| `agent-architecture` | multi-agent-patterns, memory-systems, tool-design, filesystem-context, hosted-agents |
| `agent-evaluation` | evaluation, advanced-evaluation |
| `agent-development` | project-development |
| `cognitive-architecture` | bdi-mental-states |

### Skill Triggers

| Skill | Triggers On |
|-------|-------------|
| `context-fundamentals` | &quot;understand context&quot;, &quot;explain context windows&quot;, &quot;design agent architecture&quot; |
| `context-degradation` | &quot;diagnose context problems&quot;, &quot;fix lost-in-middle&quot;, &quot;debug agent failures&quot; |
| `context-compression` | &quot;compress context&quot;, &quot;summarize conversation&quot;, &quot;reduce token usage&quot; |
| `context-optimization` | &quot;optimize context&quot;, &quot;reduce token costs&quot;, &quot;implement KV-cache&quot; |
| `multi-agent-patterns` | &quot;design multi-agent system&quot;, &quot;implement supervisor pattern&quot; |
| `memory-systems` | &quot;implement agent memory&quot;, &quot;build knowledge graph&quot;, &quot;track entities&quot; |
| `tool-design` | &quot;design agent tools&quot;, &quot;reduce tool complexity&quot;, &quot;implement MCP tools&quot; |
| `filesystem-context` | &quot;offload context to files&quot;, &quot;dynamic context discovery&quot;, &quot;agent scratch pad&quot;, &quot;file-based context&quot; |
| `hosted-agents` | &quot;build background agent&quot;, &quot;create hosted coding agent&quot;, &quot;sandboxed execution&quot;, &quot;multiplayer agent&quot;, &quot;Modal sandboxes&quot; |
| `evaluation` | &quot;evaluate agent performance&quot;, &quot;build test framework&quot;, &quot;measure quality&quot; |
| `advanced-evaluation` | &quot;implement LLM-as-judge&quot;, &quot;compare model outputs&quot;, &quot;mitigate bias&quot; |
| `project-development` | &quot;start LLM project&quot;, &quot;design batch pipeline&quot;, &quot;evaluate task-model fit&quot; |
| `bdi-mental-states` | &quot;model agent mental states&quot;, &quot;implement BDI architecture&quot;, &quot;transform RDF to beliefs&quot;, &quot;build cognitive agent&quot; |

&lt;img width=&quot;1014&quot; height=&quot;894&quot; alt=&quot;Screenshot 2025-12-26 at 12 34 47‚ÄØPM&quot; src=&quot;https://github.com/user-attachments/assets/f79aaf03-fd2d-4c71-a630-7027adeb9bfe&quot; /&gt;

### For Cursor &amp; Codex &amp; IDE

Copy skill content into `.rules` or create project-specific Skills folders. The skills provide the context and guidelines that agent needs for effective context engineering and agent design.

### For Custom Implementations

Extract the principles and patterns from any skill and implement them in your agent framework. The skills are deliberately platform-agnostic.

## Examples

The [examples](examples/) folder contains complete system designs that demonstrate how multiple skills work together in practice.

| Example | Description | Skills Applied |
|---------|-------------|----------------|
| [digital-brain-skill](examples/digital-brain-skill/) | **NEW** Personal operating system for founders and creators. Complete Claude Code skill with 6 modules, 4 automation scripts | context-fundamentals, context-optimization, memory-systems, tool-design, multi-agent-patterns, evaluation, project-development |
| [x-to-book-system](examples/x-to-book-system/) | Multi-agent system that monitors X accounts and generates daily synthesized books | multi-agent-patterns, memory-systems, context-optimization, tool-design, evaluation |
| [llm-as-judge-skills](examples/llm-as-judge-skills/) | Production-ready LLM evaluation tools with TypeScript implementation, 19 passing tests | advanced-evaluation, tool-design, context-fundamentals, evaluation |
| [book-sft-pipeline](examples/book-sft-pipeline/) | Train models to write in any author&#039;s style. Includes Gertrude Stein case study with 70% human score on Pangram, $2 total cost | project-development, context-compression, multi-agent-patterns, evaluation |

Each example includes:
- Complete PRD with architecture decisions
- Skills mapping showing which concepts informed each decision
- Implementation guidance

### Digital Brain Skill Example

The [digital-brain-skill](examples/digital-brain-skill/) example is a complete personal operating system demonstrating comprehensive skills application:

- **Progressive Disclosure**: 3-level loading (SKILL.md ‚Üí MODULE.md ‚Üí data files)
- **Module Isolation**: 6 independent modules (identity, content, knowledge, network, operations, agents)
- **Append-Only Memory**: JSONL files with schema-first lines for agent-friendly parsing
- **Automation Scripts**: 4 consolidated tools (weekly_review, content_ideas, stale_contacts, idea_to_draft)

Includes detailed traceability in [HOW-SKILLS-BUILT-THIS.md](examples/digital-brain-skill/HOW-SKILLS-BUILT-THIS.md) mapping every architectural decision to specific skill principles.

### LLM-as-Judge Skills Example

The [llm-as-judge-skills](examples/llm-as-judge-skills/) example is a complete TypeScript implementation demonstrating:

- **Direct Scoring**: Evaluate responses against weighted criteria with rubric support
- **Pairwise Comparison**: Compare responses with position bias mitigation
- **Rubric Generation**: Create domain-specific evaluation standards
- **EvaluatorAgent**: High-level agent combining all evaluation capabilities

### Book SFT Pipeline Example

The [book-sft-pipeline](examples/book-sft-pipeline/) example demonstrates training small models (8B) to write in any author&#039;s style:

- **Intelligent Segmentation**: Two-tier chunking with overlap for maximum training examples
- **Prompt Diversity**: 15+ templates to prevent memorization and force style learning
- **Tinker Integration**: Complete LoRA training workflow with $2 total cost
- **Validation Methodology**: Modern scenario testing proves style transfer vs content memorization

Integrates with context engineering skills: project-development, context-compression, multi-agent-patterns, evaluation.

## Star History
&lt;img width=&quot;3664&quot; height=&quot;2648&quot; alt=&quot;star-history-2026224&quot; src=&quot;https://github.com/user-attachments/assets/b3bdbf23-4b6a-4774-ae85-42ef4d9b2d79&quot; /&gt;

## Structure

Each skill follows the Agent Skills specification:

```
skill-name/
‚îú‚îÄ‚îÄ SKILL.md              # Required: instructions + metadata
‚îú‚îÄ‚îÄ scripts/              # Optional: executable code demonstrating concepts
‚îî‚îÄ‚îÄ references/           # Optional: additional documentation and resources
```

See the [template](template/) folder for the canonical skill structure.

## Contributing

This repository follows the Agent Skills open development model. Contributions are welcome from the broader ecosystem. When contributing:

1. Follow the skill template structure
2. Provide clear, actionable instructions
3. Include working examples where appropriate
4. Document trade-offs and potential issues
5. Keep SKILL.md under 500 lines for optimal performance

Feel free to contact [Muratcan Koylan](https://x.com/koylanai) for collaboration opportunities or any inquiries.

## License

MIT License - see LICENSE file for details.

## References

The principles in these skills are derived from research and production experience at leading AI labs and framework developers. Each skill includes references to the underlying research and case studies that inform its recommendations.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OpenBB-finance/OpenBB]]></title>
            <link>https://github.com/OpenBB-finance/OpenBB</link>
            <guid>https://github.com/OpenBB-finance/OpenBB</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:42 GMT</pubDate>
            <description><![CDATA[Financial data platform for analysts, quants and AI agents.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBB-finance/OpenBB">OpenBB-finance/OpenBB</a></h1>
            <p>Financial data platform for analysts, quants and AI agents.</p>
            <p>Language: Python</p>
            <p>Stars: 61,859</p>
            <p>Forks: 6,027</p>
            <p>Stars today: 504 stars today</p>
            <h2>README</h2><pre>&lt;br /&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/odp-light.svg?raw=true#gh-light-mode-only&quot; alt=&quot;Open Data Platform by OpenBB logo&quot; width=&quot;600&quot;&gt;
&lt;img src=&quot;https://github.com/OpenBB-finance/OpenBB/blob/develop/images/odp-dark.svg?raw=true#gh-dark-mode-only&quot; alt=&quot;Open Data Platform by OpenBB logo&quot; width=&quot;600&quot;&gt;
&lt;br /&gt;
&lt;br /&gt;

[![Twitter](https://img.shields.io/twitter/url/https/twitter.com/openbb_finance.svg?style=social&amp;label=Follow%20%40openbb_finance)](https://x.com/openbb_finance)
[![Discord Shield](https://img.shields.io/discord/831165782750789672)](https://discord.com/invite/xPHTuHCmuV)
[![Open in Dev Containers](https://img.shields.io/static/v1?label=Dev%20Containers&amp;message=Open&amp;color=blue&amp;logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/OpenBB-finance/OpenBB)
&lt;a href=&quot;https://codespaces.new/OpenBB-finance/OpenBB&quot;&gt;
  &lt;img src=&quot;https://github.com/codespaces/badge.svg&quot; height=&quot;20&quot; /&gt;
&lt;/a&gt;
&lt;a target=&quot;_blank&quot; href=&quot;https://colab.research.google.com/github/OpenBB-finance/OpenBB/blob/develop/examples/googleColab.ipynb&quot;&gt;
  &lt;img src=&quot;https://colab.research.google.com/assets/colab-badge.svg&quot; alt=&quot;Open In Colab&quot;/&gt;
&lt;/a&gt;
[![PyPI](https://img.shields.io/pypi/v/openbb?color=blue&amp;label=PyPI%20Package)](https://pypi.org/project/openbb/)

Open Data Platform by OpenBB (ODP) is the open-source toolset that helps data engineers integrate proprietary, licensed, and public data sources into downstream applications like AI copilots and research dashboards.

ODP operates as the &quot;connect once, consume everywhere&quot; infrastructure layer that consolidates and exposes data to multiple surfaces at once: Python environments for quants, OpenBB Workspace and Excel for analysts, MCP servers for AI agents, and REST APIs for other applications.

&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/70b971ef-7a7e-486e-b5ae-1cc602f2162c.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Get started with: `pip install openbb`

```python
from openbb import obb
output = obb.equity.price.historical(&quot;AAPL&quot;)
df = output.to_dataframe()
```

Data integrations available can be found here: &lt;https://docs.openbb.co/python/reference&gt;

---

## OpenBB Workspace

While the Open Data Platform provides the open-source data integration foundation, **OpenBB Workspace** offers the enterprise UI for analysts to visualize datasets and leverage AI agents. The platform&#039;s &quot;connect once, consume everywhere&quot; architecture enables seamless integration between the two.

You can find OpenBB Workspace at &lt;https://pro.openbb.co&gt;.
&lt;a href=&quot;https://pro.openbb.co&quot;&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://openbb-cms.directus.app/assets/f69b6aaf-0821-4bc8-a43c-715e03a924ef.png&quot; alt=&quot;Logo&quot; width=&quot;1000&quot;&gt;
  &lt;/div&gt;
&lt;/a&gt;

Data integration:

- You can learn more about adding data to the OpenBB workspace from the [docs](https://docs.openbb.co/workspace) or [this open source repository](https://github.com/OpenBB-finance/backends-for-openbb).

AI Agents integration:

- You can learn more about adding AI agents to the OpenBB workspace from [this open source repository](https://github.com/OpenBB-finance/agents-for-openbb).

### Integrating Open Data Platform to the OpenBB Workspace

Connect this library to the OpenBB Workspace with a few simple commands, in a Python (3.9.21 - 3.12) environment.

#### Run an ODP backend

- Install the packages.

```sh
pip install &quot;openbb[all]&quot;
```

- Start the API server over localhost.

```sh
openbb-api
```

This will launch a FastAPI server, via Uvicorn, at `127.0.0.1:6900`.

You can check that it works by going to &lt;http://127.0.0.1:6900&gt;.

#### Integrate the ODP Backend to OpenBB Workspace

Sign-in to the [OpenBB Workspace](https://pro.openbb.co/), and follow the following steps:

![CleanShot 2025-05-17 at 09 51 56@2x](https://github.com/user-attachments/assets/75cffb4a-5e95-470a-b9d0-6ffd4067e069)

1. Go to the &quot;Apps&quot; tab
2. Click on &quot;Connect backend&quot;
3. Fill in the form with:
   Name: Open Data Platform
   URL: &lt;http://127.0.0.1:6900&gt;
4. Click on &quot;Test&quot;. You should get a &quot;Test successful&quot; with the number of apps found.
5. Click on &quot;Add&quot;.

That&#039;s it.

---

&lt;!-- TABLE OF CONTENTS --&gt;
&lt;details closed=&quot;closed&quot;&gt;
  &lt;summary&gt;&lt;h2 style=&quot;display: inline-block&quot;&gt;Table of Contents&lt;/h2&gt;&lt;/summary&gt;
  &lt;ol&gt;
    &lt;li&gt;&lt;a href=&quot;#1-installation&quot;&gt;Installation&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#2-contributing&quot;&gt;Contributing&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#3-license&quot;&gt;License&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#4-disclaimer&quot;&gt;Disclaimer&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#5-contacts&quot;&gt;Contacts&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#6-star-history&quot;&gt;Star History&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href=&quot;#7-contributors&quot;&gt;Contributors&lt;/a&gt;&lt;/li&gt;
  &lt;/ol&gt;
&lt;/details&gt;

## 1. Installation

The ODP Python Package can be installed from [PyPI package](https://pypi.org/project/openbb/) by running `pip install openbb`

or by cloning the repository directly with `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process, in the [OpenBB Documentation](https://docs.openbb.co/python/installation).

### ODP CLI installation

The ODP CLI is a command-line interface that allows you to access the ODP directly from your command line.

It can be installed by running `pip install openbb-cli`

or by cloning the repository directly with  `git clone https://github.com/OpenBB-finance/OpenBB.git`.

Please find more about the installation process in the [OpenBB Documentation](https://docs.openbb.co/cli/installation).

## 2. Contributing

There are three main ways of contributing to this project. (Hopefully you have starred the project by now ‚≠êÔ∏è)

### Become a Contributor

- More information on our [Developer Documentation](https://docs.openbb.co/python/developer).

### Create a GitHub ticket

Before creating a ticket make sure the one you are creating doesn&#039;t exist already [among the existing issues](https://github.com/OpenBB-finance/OpenBB/issues)

- [Report bug](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=bug&amp;template=bug_report.md&amp;title=%5BBug%5D)
- [Suggest improvement](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=enhancement&amp;template=enhancement.md&amp;title=%5BIMPROVE%5D)
- [Request a feature](https://github.com/OpenBB-finance/OpenBB/issues/new?assignees=&amp;labels=new+feature&amp;template=feature_request.md&amp;title=%5BFR%5D)

### Provide feedback

We are most active on [our Discord](https://openbb.co/discord), but feel free to reach out to us in any of [our social media](https://openbb.co/links) for feedback.

## 3. License

Distributed under the AGPLv3 License. See
[LICENSE](https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE) for more information.

## 4. Disclaimer

Trading in financial instruments involves high risks including the risk of losing some, or all, of your investment
amount, and may not be suitable for all investors.

Before deciding to trade in a financial instrument you should be fully informed of the risks and costs associated with trading the financial markets, carefully consider your investment objectives, level of experience, and risk appetite, and seek professional advice where needed.

The data contained in the Open Data Platform is not necessarily accurate.

OpenBB and any provider of the data contained in this website will not accept liability for any loss or damage as a result of your trading, or your reliance on the information displayed.

All names, logos, and brands of third parties that may be referenced in our sites, products or documentation are trademarks of their respective owners. Unless otherwise specified, OpenBB and its products and services are not endorsed by, sponsored by, or affiliated with these third parties.

Our use of these names, logos, and brands is for identification purposes only, and does not imply any such endorsement, sponsorship, or affiliation.

## 5. Contacts

If you have any questions about the platform or anything OpenBB, feel free to email us at `support@openbb.co`

If you want to say hi, or are interested in partnering with us, feel free to reach us at `hello@openbb.co`

Any of our social media platforms: [openbb.co/links](https://openbb.co/links)

## 6. Star History

This is a proxy of our growth and that we are just getting started.

But for more metrics important to us check [openbb.co/open](https://openbb.co/open).

[![Star History Chart](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)](https://api.star-history.com/svg?repos=openbb-finance/OpenBB&amp;type=Date&amp;theme=dark)

## 7. Contributors

OpenBB wouldn&#039;t be OpenBB without you. If we are going to disrupt financial industry, every contribution counts. Thank you for being part of this journey.

&lt;a href=&quot;https://github.com/OpenBB-finance/OpenBB/graphs/contributors&quot;&gt;
   &lt;img src=&quot;https://contributors-img.web.app/image?repo=OpenBB-finance/OpenBB&quot; width=&quot;800&quot;/&gt;
&lt;/a&gt;

&lt;!-- MARKDOWN LINKS &amp; IMAGES --&gt;
&lt;!-- https://www.markdownguide.org/basic-syntax/#reference-style-links --&gt;

[contributors-shield]: https://img.shields.io/github/contributors/OpenBB-finance/OpenBB.svg?style=for-the-badge
[contributors-url]: https://github.com/OpenBB-finance/OpenBB/graphs/contributors
[forks-shield]: https://img.shields.io/github/forks/OpenBB-finance/OpenBB.svg?style=for-the-badge
[forks-url]: https://github.com/OpenBB-finance/OpenBB/network/members
[stars-shield]: https://img.shields.io/github/stars/OpenBB-finance/OpenBB.svg?style=for-the-badge
[stars-url]: https://github.com/OpenBB-finance/OpenBB/stargazers
[issues-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB.svg?style=for-the-badge&amp;color=blue
[issues-url]: https://github.com/OpenBB-finance/OpenBB/issues
[bugs-open-shield]: https://img.shields.io/github/issues/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=yellow
[bugs-open-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aopen
[bugs-closed-shield]: https://img.shields.io/github/issues-closed/OpenBB-finance/OpenBB/bug.svg?style=for-the-badge&amp;color=success
[bugs-closed-url]: https://github.com/OpenBB-finance/OpenBB/issues?q=is%3Aissue+label%3Abug+is%3Aclosed
[license-shield]: https://img.shields.io/github/license/OpenBB-finance/OpenBB.svg?style=for-the-badge
[license-url]: https://github.com/OpenBB-finance/OpenBB/blob/main/LICENSE.txt
[linkedin-shield]: https://img.shields.io/badge/-LinkedIn-black.svg?style=for-the-badge&amp;logo=linkedin&amp;colorB=555
[linkedin-url]: https://linkedin.com/in/DidierRLopes
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[D4Vinci/Scrapling]]></title>
            <link>https://github.com/D4Vinci/Scrapling</link>
            <guid>https://github.com/D4Vinci/Scrapling</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:41 GMT</pubDate>
            <description><![CDATA[üï∑Ô∏è An adaptive Web Scraping framework that handles everything from a single request to a full-scale crawl!]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/D4Vinci/Scrapling">D4Vinci/Scrapling</a></h1>
            <p>üï∑Ô∏è An adaptive Web Scraping framework that handles everything from a single request to a full-scale crawl!</p>
            <p>Language: Python</p>
            <p>Stars: 12,541</p>
            <p>Forks: 846</p>
            <p>Stars today: 1,970 stars today</p>
            <h2>README</h2><pre>&lt;!-- mcp-name: io.github.D4Vinci/Scrapling --&gt;

&lt;h1 align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://scrapling.readthedocs.io&quot;&gt;
        &lt;picture&gt;
          &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/docs/assets/cover_dark.svg?sanitize=true&quot;&gt;
          &lt;img alt=&quot;Scrapling Poster&quot; src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/docs/assets/cover_light.svg?sanitize=true&quot;&gt;
        &lt;/picture&gt;
    &lt;/a&gt;
    &lt;br&gt;
    &lt;small&gt;Effortless Web Scraping for the Modern Web&lt;/small&gt;
&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://trendshift.io/repositories/14244&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14244&quot; alt=&quot;D4Vinci%2FScrapling | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
    &lt;br/&gt;
    &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_AR.md&quot;&gt;ÿßŸÑÿπÿ±ÿ®ŸäŸá&lt;/a&gt; | &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_ES.md&quot;&gt;Espa√±ol&lt;/a&gt; | &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_DE.md&quot;&gt;Deutsch&lt;/a&gt; | &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_CN.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt; | &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_JP.md&quot;&gt;Êó•Êú¨Ë™û&lt;/a&gt; |  &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/blob/main/docs/README_RU.md&quot;&gt;–†—É—Å—Å–∫–∏–π&lt;/a&gt;
    &lt;br/&gt;
    &lt;a href=&quot;https://github.com/D4Vinci/Scrapling/actions/workflows/tests.yml&quot; alt=&quot;Tests&quot;&gt;
        &lt;img alt=&quot;Tests&quot; src=&quot;https://github.com/D4Vinci/Scrapling/actions/workflows/tests.yml/badge.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://badge.fury.io/py/Scrapling&quot; alt=&quot;PyPI version&quot;&gt;
        &lt;img alt=&quot;PyPI version&quot; src=&quot;https://badge.fury.io/py/Scrapling.svg&quot;&gt;&lt;/a&gt;
    &lt;a href=&quot;https://pepy.tech/project/scrapling&quot; alt=&quot;PyPI Downloads&quot;&gt;
        &lt;img alt=&quot;PyPI Downloads&quot; src=&quot;https://static.pepy.tech/personalized-badge/scrapling?period=total&amp;units=INTERNATIONAL_SYSTEM&amp;left_color=GREY&amp;right_color=GREEN&amp;left_text=Downloads&quot;&gt;&lt;/a&gt;
    &lt;br/&gt;
    &lt;a href=&quot;https://discord.gg/EMgGbDceNQ&quot; alt=&quot;Discord&quot; target=&quot;_blank&quot;&gt;
      &lt;img alt=&quot;Discord&quot; src=&quot;https://img.shields.io/discord/1360786381042880532?style=social&amp;logo=discord&amp;link=https%3A%2F%2Fdiscord.gg%2FEMgGbDceNQ&quot;&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://x.com/Scrapling_dev&quot; alt=&quot;X (formerly Twitter)&quot;&gt;
      &lt;img alt=&quot;X (formerly Twitter) Follow&quot; src=&quot;https://img.shields.io/twitter/follow/Scrapling_dev?style=social&amp;logo=x&amp;link=https%3A%2F%2Fx.com%2FScrapling_dev&quot;&gt;
    &lt;/a&gt;
    &lt;br/&gt;
    &lt;a href=&quot;https://pypi.org/project/scrapling/&quot; alt=&quot;Supported Python versions&quot;&gt;
        &lt;img alt=&quot;Supported Python versions&quot; src=&quot;https://img.shields.io/pypi/pyversions/scrapling.svg&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/parsing/selection/&quot;&gt;&lt;strong&gt;Selection methods&lt;/strong&gt;&lt;/a&gt;
    &amp;middot;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/fetching/choosing/&quot;&gt;&lt;strong&gt;Fetchers&lt;/strong&gt;&lt;/a&gt;
    &amp;middot;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/spiders/architecture.html&quot;&gt;&lt;strong&gt;Spiders&lt;/strong&gt;&lt;/a&gt;
    &amp;middot;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/spiders/proxy-blocking.html&quot;&gt;&lt;strong&gt;Proxy Rotation&lt;/strong&gt;&lt;/a&gt;
    &amp;middot;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/cli/overview/&quot;&gt;&lt;strong&gt;CLI&lt;/strong&gt;&lt;/a&gt;
    &amp;middot;
    &lt;a href=&quot;https://scrapling.readthedocs.io/en/latest/ai/mcp-server/&quot;&gt;&lt;strong&gt;MCP&lt;/strong&gt;&lt;/a&gt;
&lt;/p&gt;

Scrapling is an adaptive Web Scraping framework that handles everything from a single request to a full-scale crawl.

Its parser learns from website changes and automatically relocates your elements when pages update. Its fetchers bypass anti-bot systems like Cloudflare Turnstile out of the box. And its spider framework lets you scale up to concurrent, multi-session crawls with pause/resume and automatic proxy rotation ‚Äî all in a few lines of Python. One library, zero compromises.

Blazing fast crawls with real-time stats and streaming. Built by Web Scrapers for Web Scrapers and regular users, there&#039;s something for everyone.

```python
from scrapling.fetchers import Fetcher, AsyncFetcher, StealthyFetcher, DynamicFetcher
StealthyFetcher.adaptive = True
p = StealthyFetcher.fetch(&#039;https://example.com&#039;, headless=True, network_idle=True)  # Fetch website under the radar!
products = p.css(&#039;.product&#039;, auto_save=True)                                        # Scrape data that survives website design changes!
products = p.css(&#039;.product&#039;, adaptive=True)                                         # Later, if the website structure changes, pass `adaptive=True` to find them!
```
Or scale up to full crawls
```python
from scrapling.spiders import Spider, Response

class MySpider(Spider):
  name = &quot;demo&quot;
  start_urls = [&quot;https://example.com/&quot;]

  async def parse(self, response: Response):
      for item in response.css(&#039;.product&#039;):
          yield {&quot;title&quot;: item.css(&#039;h2::text&#039;).get()}

MySpider().start()
```

# Platinum Sponsors

# Sponsors 

&lt;!-- sponsors --&gt;

&lt;a href=&quot;https://www.scrapeless.com/en?utm_source=official&amp;utm_term=scrapling&quot; target=&quot;_blank&quot; title=&quot;Effortless Web Scraping Toolkit for Business and Developers&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/scrapeless.jpg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://www.thordata.com/?ls=github&amp;lk=github&quot; target=&quot;_blank&quot; title=&quot;Unblockable proxies and scraping infrastructure, delivering real-time, reliable web data to power AI models and workflows.&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/thordata.jpg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://evomi.com?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=d4vinci-scrapling&quot; target=&quot;_blank&quot; title=&quot;Evomi is your Swiss Quality Proxy Provider, starting at $0.49/GB&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/evomi.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://serpapi.com/?utm_source=scrapling&quot; target=&quot;_blank&quot; title=&quot;Scrape Google and other search engines with SerpApi&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/SerpApi.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://visit.decodo.com/Dy6W0b&quot; target=&quot;_blank&quot; title=&quot;Try the Most Efficient Residential Proxies for Free&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/decodo.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://petrosky.io/d4vinci&quot; target=&quot;_blank&quot; title=&quot;PetroSky delivers cutting-edge VPS hosting.&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/petrosky.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://hasdata.com/?utm_source=github&amp;utm_medium=banner&amp;utm_campaign=D4Vinci&quot; target=&quot;_blank&quot; title=&quot;The web scraping service that actually beats anti-bot systems!&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/hasdata.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://proxyempire.io/&quot; target=&quot;_blank&quot; title=&quot;Collect The Data Your Project Needs with the Best Residential Proxies&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/ProxyEmpire.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://hypersolutions.co/?utm_source=github&amp;utm_medium=readme&amp;utm_campaign=scrapling&quot; target=&quot;_blank&quot; title=&quot;Bot Protection Bypass API for Akamai, DataDome, Incapsula &amp; Kasada&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/HyperSolutions.png&quot;&gt;&lt;/a&gt;


&lt;a href=&quot;https://www.swiftproxy.net/&quot; target=&quot;_blank&quot; title=&quot;Unlock Reliable Proxy Services with Swiftproxy!&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/swiftproxy.png&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://www.rapidproxy.io/?ref=d4v&quot; target=&quot;_blank&quot; title=&quot;Affordable Access to the Proxy World ‚Äì bypass CAPTCHAs blocks, and avoid additional costs.&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/rapidproxy.jpg&quot;&gt;&lt;/a&gt;
&lt;a href=&quot;https://browser.cash/?utm_source=D4Vinci&amp;utm_medium=referral&quot; target=&quot;_blank&quot; title=&quot;Browser Automation &amp; AI Browser Agent Platform&quot;&gt;&lt;img src=&quot;https://raw.githubusercontent.com/D4Vinci/Scrapling/main/images/browserCash.png&quot;&gt;&lt;/a&gt;

&lt;!-- /sponsors --&gt;

&lt;i&gt;&lt;sub&gt;Do you want to show your ad here? Click [here](https://github.com/sponsors/D4Vinci) and choose the tier that suites you!&lt;/sub&gt;&lt;/i&gt;

---

## Key Features

### Spiders ‚Äî A Full Crawling Framework
- üï∑Ô∏è **Scrapy-like Spider API**: Define spiders with `start_urls`, async `parse` callbacks, and `Request`/`Response` objects.
- ‚ö° **Concurrent Crawling**: Configurable concurrency limits, per-domain throttling, and download delays.
- üîÑ **Multi-Session Support**: Unified interface for HTTP requests, and stealthy headless browsers in a single spider ‚Äî route requests to different sessions by ID.
- üíæ **Pause &amp; Resume**: Checkpoint-based crawl persistence. Press Ctrl+C for a graceful shutdown; restart to resume from where you left off.
- üì° **Streaming Mode**: Stream scraped items as they arrive via `async for item in spider.stream()` with real-time stats ‚Äî ideal for UI, pipelines, and long-running crawls.
- üõ°Ô∏è **Blocked Request Detection**: Automatic detection and retry of blocked requests with customizable logic.
- üì¶ **Built-in Export**: Export results through hooks and your own pipeline or the built-in JSON/JSONL with `result.items.to_json()` / `result.items.to_jsonl()` respectively.

### Advanced Websites Fetching with Session Support
- **HTTP Requests**: Fast and stealthy HTTP requests with the `Fetcher` class. Can impersonate browsers&#039; TLS fingerprint, headers, and use HTTP/3.
- **Dynamic Loading**: Fetch dynamic websites with full browser automation through the `DynamicFetcher` class supporting Playwright&#039;s Chromium and Google&#039;s Chrome.
- **Anti-bot Bypass**: Advanced stealth capabilities with `StealthyFetcher` and fingerprint spoofing. Can easily bypass all types of Cloudflare&#039;s Turnstile/Interstitial with automation.
- **Session Management**: Persistent session support with `FetcherSession`, `StealthySession`, and `DynamicSession` classes for cookie and state management across requests.
- **Proxy Rotation**: Built-in `ProxyRotator` with cyclic or custom rotation strategies across all session types, plus per-request proxy overrides.
- **Domain Blocking**: Block requests to specific domains (and their subdomains) in browser-based fetchers.
- **Async Support**: Complete async support across all fetchers and dedicated async session classes.

### Adaptive Scraping &amp; AI Integration
- üîÑ **Smart Element Tracking**: Relocate elements after website changes using intelligent similarity algorithms.
- üéØ **Smart Flexible Selection**: CSS selectors, XPath selectors, filter-based search, text search, regex search, and more.
- üîç **Find Similar Elements**: Automatically locate elements similar to found elements.
- ü§ñ **MCP Server to be used with AI**: Built-in MCP server for AI-assisted Web Scraping and data extraction. The MCP server features powerful, custom capabilities that leverage Scrapling to extract targeted content before passing it to the AI (Claude/Cursor/etc), thereby speeding up operations and reducing costs by minimizing token usage. ([demo video](https://www.youtube.com/watch?v=qyFk3ZNwOxE))

### High-Performance &amp; battle-tested Architecture
- üöÄ **Lightning Fast**: Optimized performance outperforming most Python scraping libraries.
- üîã **Memory Efficient**: Optimized data structures and lazy loading for a minimal memory footprint.
- ‚ö° **Fast JSON Serialization**: 10x faster than the standard library.
- üèóÔ∏è **Battle tested**: Not only does Scrapling have 92% test coverage and full type hints coverage, but it has been used daily by hundreds of Web Scrapers over the past year.

### Developer/Web Scraper Friendly Experience
- üéØ **Interactive Web Scraping Shell**: Optional built-in IPython shell with Scrapling integration, shortcuts, and new tools to speed up Web Scraping scripts development, like converting curl requests to Scrapling requests and viewing requests results in your browser.
- üöÄ **Use it directly from the Terminal**: Optionally, you can use Scrapling to scrape a URL without writing a single line of code!
- üõ†Ô∏è **Rich Navigation API**: Advanced DOM traversal with parent, sibling, and child navigation methods.
- üß¨ **Enhanced Text Processing**: Built-in regex, cleaning methods, and optimized string operations.
- üìù **Auto Selector Generation**: Generate robust CSS/XPath selectors for any element.
- üîå **Familiar API**: Similar to Scrapy/BeautifulSoup with the same pseudo-elements used in Scrapy/Parsel.
- üìò **Complete Type Coverage**: Full type hints for excellent IDE support and code completion. The entire codebase is automatically scanned with **PyRight** and **MyPy** with each change.
- üîã **Ready Docker image**: With each release, a Docker image containing all browsers is automatically built and pushed.

## Getting Started

Let&#039;s give you a quick glimpse of what Scrapling can do without deep diving.

### Basic Usage
HTTP requests with session support
```python
from scrapling.fetchers import Fetcher, FetcherSession

with FetcherSession(impersonate=&#039;chrome&#039;) as session:  # Use latest version of Chrome&#039;s TLS fingerprint
    page = session.get(&#039;https://quotes.toscrape.com/&#039;, stealthy_headers=True)
    quotes = page.css(&#039;.quote .text::text&#039;).getall()

# Or use one-off requests
page = Fetcher.get(&#039;https://quotes.toscrape.com/&#039;)
quotes = page.css(&#039;.quote .text::text&#039;).getall()
```
Advanced stealth mode
```python
from scrapling.fetchers import StealthyFetcher, StealthySession

with StealthySession(headless=True, solve_cloudflare=True) as session:  # Keep the browser open until you finish
    page = session.fetch(&#039;https://nopecha.com/demo/cloudflare&#039;, google_search=False)
    data = page.css(&#039;#padded_content a&#039;).getall()

# Or use one-off request style, it opens the browser for this request, then closes it after finishing
page = StealthyFetcher.fetch(&#039;https://nopecha.com/demo/cloudflare&#039;)
data = page.css(&#039;#padded_content a&#039;).getall()
```
Full browser automation
```python
from scrapling.fetchers import DynamicFetcher, DynamicSession

with DynamicSession(headless=True, disable_resources=False, network_idle=True) as session:  # Keep the browser open until you finish
    page = session.fetch(&#039;https://quotes.toscrape.com/&#039;, load_dom=False)
    data = page.xpath(&#039;//span[@class=&quot;text&quot;]/text()&#039;).getall()  # XPath selector if you prefer it

# Or use one-off request style, it opens the browser for this request, then closes it after finishing
page = DynamicFetcher.fetch(&#039;https://quotes.toscrape.com/&#039;)
data = page.css(&#039;.quote .text::text&#039;).getall()
```

### Spiders
Build full crawlers with concurrent requests, multiple session types, and pause/resume:
```python
from scrapling.spiders import Spider, Request, Response

class QuotesSpider(Spider):
    name = &quot;quotes&quot;
    start_urls = [&quot;https://quotes.toscrape.com/&quot;]
    concurrent_requests = 10
    
    async def parse(self, response: Response):
        for quote in response.css(&#039;.quote&#039;):
            yield {
                &quot;text&quot;: quote.css(&#039;.text::text&#039;).get(),
                &quot;author&quot;: quote.css(&#039;.author::text&#039;).get(),
            }
            
        next_page = response.css(&#039;.next a&#039;)
        if next_page:
            yield response.follow(next_page[0].attrib[&#039;href&#039;])

result = QuotesSpider().start()
print(f&quot;Scraped {len(result.items)} quotes&quot;)
result.items.to_json(&quot;quotes.json&quot;)
```
Use multiple session types in a single spider:
```python
from scrapling.spiders import Spider, Request, Response
from scrapling.fetchers import FetcherSession, AsyncStealthySession

class MultiSessionSpider(Spider):
    name = &quot;multi&quot;
    start_urls = [&quot;https://example.com/&quot;]
    
    def configure_sessions(self, manager):
        manager.add(&quot;fast&quot;, FetcherSession(impersonate=&quot;chrome&quot;))
        manager.add(&quot;stealth&quot;, AsyncStealthySession(headless=True), lazy=True)
    
    async def parse(self, response: Response):
        for link in response.css(&#039;a::attr(href)&#039;).getall():
            # Route protected pages through the stealth session
            if &quot;protected&quot; in link:
                yield Request(link, sid=&quot;stealth&quot;)
            else:
                yield Request(link, sid=&quot;fast&quot;, callback=self.parse)  # explicit callback
```
Pause and resume long crawls with checkpoints by running the spider like this:
```python
QuotesSpider(crawldir=&quot;./crawl_data&quot;).start()
```
Press Ctrl+C to pause gracefully ‚Äî progress is saved automatically. Later, when you start the spider again, pass the same `crawldir`, and it will resume from where it stopped.

### Advanced Parsing &amp; Navigation
```python
from scrapling.fetchers import Fetcher

# Rich element selection and navigation
page = Fetcher.get(&#039;https://quotes.toscrape.com/&#039;)

# Get quotes with multiple selection methods
quotes = page.css(&#039;.quote&#039;)  # CSS selector
quotes = page.xpath(&#039;//div[@class=&quot;quote&quot;]&#039;)  # XPath
quotes = page.find_all(&#039;div&#039;, {&#039;class&#039;: &#039;quote&#039;})  # BeautifulSoup-style
# Same as
quotes = page.find_all(&#039;div&#039;, class_=&#039;quote&#039;)
quotes = page.find_all([&#039;div&#039;], class_=&#039;quote&#039;)
quotes = page.find_all(class_=&#039;quote&#039;)  # and so on...
# Find element by text content
quotes = page.find_by_text(&#039;quote&#039;, tag=&#039;div&#039;)

# Advanced navigation
quote_text = page.css(&#039;.quote&#039;)[0].css(&#039;.text::text&#039;).get()
quote_text = page.css(&#039;.quote&#039;).css(&#039;.text::text&#039;).getall()  # Chained selectors
first_quote = page.css(&#039;.quote&#039;)[0]
author = first_quote.next_sibling.css(&#039;.author::text&#039;)
parent_container = first_quote.parent

# Element relationships and similarity
similar_elements = first_quote.find_similar()
below_elements = first_quote.below_elements()
```
You can use the parser right away if you don&#039;t want to fetch websites like below:
```python
from scrapling.parser import Selector

page = Selector(&quot;&lt;html&gt;...&lt;/html&gt;&quot;)
```
And it works precisely the same way!

### Async Session Management Examples
```python
import asyncio
from scrapling.fetchers import FetcherSession, AsyncStealthySession, AsyncDynamicSession

async with FetcherSession(http3=True) as session:  # `FetcherSession` is context-aware and can work in both sync/async patterns
    page1 = session.get(&#039;https://quotes.toscrape.com/&#039;)
    page2 = session.get(&#039;https://quotes.toscrape.com/&#039;, impersonate=&#039;firefox135&#039;)

# Async session usage
async with AsyncStealthySession(max_pages=2) as session:
    tasks = []
    urls = [&#039;https://example.com/page1&#039;, &#039;https://example.com/page2&#039;]
    
    for url in urls:
        task = session.fetch(url)
        tasks.append(task)
    
    print(session.get_pool_stats())  # Optional - The status of the browser tabs pool (busy/free/error)
    results = await asyncio.gather(*tasks)
    print(session.get_pool_stats())
```

## CLI &amp; Interactive Shell

Scrapling includes a powerful command-line interface:

[![asciicast](https://asciinema.org/a/736339.svg)](https://asciinema.org/a/736339)

Launch the interactive Web Scraping shell
```bash
scrapling shell
```
Extract pages to a file directly without programming (Extracts the content inside the `body` tag by default). If the output file ends with `.txt`, then the text content of the target will be extracted. If it ends in `.md`, it will be a Markdown representation of the HTML content; if it ends in `.html`, it will be the HTML content itself.
```bash
scrapling extract get &#039;https://example.com&#039; content.md
scrapling extract get &#039;https://example.com&#039; content.txt --css-selector &#039;#fromSkipToProducts&#039; --impersonate &#039;chrome&#039;  # All elements matching the CSS selector &#039;#fromSkipToProducts&#039;
scrapling extract fetch &#039;https://example.com&#039; content.md --css-selector &#039;#fromSkipToProducts&#039; --no-headless
scrapling extract stealthy-fetch &#039;https://nopecha.com/demo/cloudflare&#039; captchas.html --css-selector &#039;#padded_content a&#039; --solve-cloudflare
```

&gt; [!NOTE]
&gt; There are many additional features, but we want to keep this page concise, including the MCP server and the interactive Web Scraping Shell. Check out the full documentation [here](https://scrapling.readthedocs.io/en/latest/)

## Performance Benchmarks

Scrapling isn&#039;t just powerful‚Äîit&#039;s also blazing fast. The following benchmarks compare Scrapling&#039;s parser with the latest versions of other popular libraries.

###

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[GVCLab/PersonaLive]]></title>
            <link>https://github.com/GVCLab/PersonaLive</link>
            <guid>https://github.com/GVCLab/PersonaLive</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:40 GMT</pubDate>
            <description><![CDATA[[CVPR 2026] PersonaLive! : Expressive Portrait Image Animation for Live Streaming]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/GVCLab/PersonaLive">GVCLab/PersonaLive</a></h1>
            <p>[CVPR 2026] PersonaLive! : Expressive Portrait Image Animation for Live Streaming</p>
            <p>Language: Python</p>
            <p>Stars: 1,947</p>
            <p>Forks: 288</p>
            <p>Stars today: 73 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;

&lt;img src=&quot;assets/header.svg&quot; alt=&quot;PersonaLive&quot; width=&quot;100%&quot;&gt;

&lt;h2&gt;Expressive Portrait Image Animation for Live Streaming&lt;/h2&gt;

#### [Zhiyuan Li&lt;sup&gt;1,2,3&lt;/sup&gt;](https://huai-chang.github.io/) ¬∑ [Chi-Man Pun&lt;sup&gt;1,üì™&lt;/sup&gt;](https://cmpun.github.io/) ¬∑ [Chen Fang&lt;sup&gt;2&lt;/sup&gt;](http://fangchen.org/) ¬∑ [Jue Wang&lt;sup&gt;2&lt;/sup&gt;](https://scholar.google.com/citations?user=Bt4uDWMAAAAJ&amp;hl=en) ¬∑ [Xiaodong Cun&lt;sup&gt;3,üì™&lt;/sup&gt;](https://vinthony.github.io/academic/) 
&lt;sup&gt;1&lt;/sup&gt; University of Macau  &amp;nbsp;&amp;nbsp; &lt;sup&gt;2&lt;/sup&gt; [Dzine.ai](https://www.dzine.ai/)  &amp;nbsp;&amp;nbsp; &lt;sup&gt;3&lt;/sup&gt; [GVC Lab, Great Bay University](https://gvclab.github.io/)

&lt;a href=&#039;https://arxiv.org/abs/2512.11253&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/ArXiv-2512.11253-red&#039;&gt;&lt;/a&gt; &lt;a href=&#039;https://huggingface.co/huaichang/PersonaLive&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Model-ffc107&#039;&gt;&lt;/a&gt; &lt;a href=&#039;https://modelscope.cn/models/huaichang/PersonaLive&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/ModelScope-Model-624AFF&#039;&gt;&lt;/a&gt; [![GitHub](https://img.shields.io/github/stars/GVCLab/PersonaLive?style=social)](https://github.com/GVCLab/PersonaLive)

&lt;img src=&quot;assets/highlight.svg&quot; alt=&quot;highlight&quot; width=&quot;95%&quot;&gt;

&lt;img src=&quot;assets/demo_3.gif&quot; width=&quot;46%&quot;&gt; &amp;nbsp;&amp;nbsp; &lt;img src=&quot;assets/demo_2.gif&quot; width=&quot;40.5%&quot;&gt;
&lt;/div&gt;

## üìã TODO
- [ ] If you find PersonaLive useful or interesting, please give us a Starüåü! Your support drives us to keep improving.
- [ ] Fix bugs (If you encounter any issues, please feel free to open an issue or contact me! üôè)
- [x] **[2026.02.21]** ü•≥ PersonaLive is accepted by CVPR2026 üéâ.
- [x] **[2025.12.29]** üî• Enhance WebUI (Support reference image replacement).
- [x] **[2025.12.22]** üî• Supported streaming strategy in offline inference to generate long videos on 12GB VRAM!
- [x] **[2025.12.17]** üî• [ComfyUI-PersonaLive](https://github.com/okdalto/ComfyUI-PersonaLive) is now supported! (Thanks to [@okdalto](https://github.com/okdalto))
- [x] **[2025.12.15]** üî• Release `paper`!
- [x] **[2025.12.12]** üî• Release `inference code`, `config`, and `pretrained weights`!
  
## ‚öñÔ∏è Disclaimer

- [x] This project is released for **academic research only**.
- [x] Users must not use this repository to generate harmful, defamatory, or illegal content.
- [x] The authors bear no responsibility for any misuse or legal consequences arising from the use of this tool.
- [x] By using this code, you agree that you are solely responsible for any content generated.

## ‚öôÔ∏è Framework
&lt;img src=&quot;assets/overview.png&quot; alt=&quot;Image 1&quot; width=&quot;100%&quot;&gt;


We present PersonaLive, a `real-time` and `streamable` diffusion framework capable of generating `infinite-length` portrait animations.


## üöÄ Getting Started
### üõ† Installation
```
# clone this repo
git clone https://github.com/GVCLab/PersonaLive
cd PersonaLive

# Create conda environment
conda create -n personalive python=3.10
conda activate personalive

# Install packages with pip
pip install -r requirements_base.txt
```

### ‚è¨ Download weights
Option 1: Download pre-trained weights of base models and other components ([sd-image-variations-diffusers](https://huggingface.co/lambdalabs/sd-image-variations-diffusers) and [sd-vae-ft-mse](https://huggingface.co/stabilityai/sd-vae-ft-mse)). You can run the following command to download weights automatically:
    
```bash
python tools/download_weights.py
```

Option 2: Download pre-trained weights into the `./pretrained_weights` folder from one of the below URLs:
    
&lt;a href=&#039;https://drive.google.com/drive/folders/1GOhDBKIeowkMpBnKhGB8jgEhJt_--vbT?usp=drive_link&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/Google%20Drive-5B8DEF?style=for-the-badge&amp;logo=googledrive&amp;logoColor=white&#039;&gt;&lt;/a&gt; &lt;a href=&#039;https://pan.baidu.com/s/1DCv4NvUy_z7Gj2xCGqRMkQ?pwd=gj64&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/Baidu%20Netdisk-3E4A89?style=for-the-badge&amp;logo=baidu&amp;logoColor=white&#039;&gt;&lt;/a&gt; &lt;a href=&#039;https://modelscope.cn/models/huaichang/PersonaLive&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/ModelScope-624AFF?style=for-the-badge&amp;logo=alibabacloud&amp;logoColor=white&#039;&gt;&lt;/a&gt; &lt;a href=&#039;https://huggingface.co/huaichang/PersonaLive&#039;&gt;&lt;img src=&#039;https://img.shields.io/badge/HuggingFace-E67E22?style=for-the-badge&amp;logo=huggingface&amp;logoColor=white&#039;&gt;&lt;/a&gt;

Finally, these weights should be organized as follows:
```
pretrained_weights
‚îú‚îÄ‚îÄ onnx
‚îÇ   ‚îú‚îÄ‚îÄ unet_opt
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unet_opt.onnx
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ unet_opt.onnx.data
‚îÇ   ‚îî‚îÄ‚îÄ unet
‚îú‚îÄ‚îÄ personalive
‚îÇ   ‚îú‚îÄ‚îÄ denoising_unet.pth
‚îÇ   ‚îú‚îÄ‚îÄ motion_encoder.pth
‚îÇ   ‚îú‚îÄ‚îÄ motion_extractor.pth
‚îÇ   ‚îú‚îÄ‚îÄ pose_guider.pth
‚îÇ   ‚îú‚îÄ‚îÄ reference_unet.pth
‚îÇ   ‚îî‚îÄ‚îÄ temporal_module.pth
‚îú‚îÄ‚îÄ sd-vae-ft-mse
‚îÇ   ‚îú‚îÄ‚îÄ diffusion_pytorch_model.bin
‚îÇ   ‚îî‚îÄ‚îÄ config.json
‚îú‚îÄ‚îÄ sd-image-variations-diffusers
‚îÇ   ‚îú‚îÄ‚îÄ image_encoder
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pytorch_model.bin
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.json
‚îÇ   ‚îú‚îÄ‚îÄ unet
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ diffusion_pytorch_model.bin
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ config.json
‚îÇ   ‚îî‚îÄ‚îÄ model_index.json
‚îî‚îÄ‚îÄ tensorrt
    ‚îî‚îÄ‚îÄ unet_work.engine
```

### üéûÔ∏è Offline Inference
Run offline inference with the default configuration:

```
python inference_offline.py
```

* `-L`: Max number of frames to generate. (Default: 100)
* `--use_xformers`: Enable xFormers memory efficient attention. (Default: True)
* `--stream_gen`: Enable streaming generation strategy. (Default: True)
* `--reference_image`: Path to a specific reference image. Overrides settings in config.
* `--driving_video`: Path to a specific driving video. Overrides settings in config.

‚ö†Ô∏è Note for RTX 50-Series (Blackwell) Users: xformers is not yet fully compatible with the new architecture. To avoid crashes, please disable it by running:

```
python inference_offline.py --use_xformers False
```

### üì∏ Online Inference
#### üì¶ Setup Web UI
```
# install Node.js 18+
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash
nvm install 18

source web_start.sh
```

#### üèéÔ∏è Acceleration (Optional)
Converting the model to TensorRT can significantly speed up inference (~ 2x ‚ö°Ô∏è). Building the engine may take about `20 minutes` depending on your device. Note that TensorRT optimizations may lead to slight variations or a small drop in output quality.
```
# Install packages with pip
pip install -r requirements_trt.txt

# Converting the model to TensorRT
python torch2trt.py
```
üí° **PyCUDA Installation Issues**: If you encounter a &quot;Failed to build wheel for pycuda&quot; error during the installation above, please follow these steps:
```
# Install PyCUDA manually using Conda (avoids compilation issues):
conda install -c conda-forge pycuda &quot;numpy&lt;2.0&quot;

# Open requirements_trt.txt and comment out or remove the line &quot;pycuda==2024.1.2&quot;

# Install other packages with pip
pip install -r requirements_trt.txt

# Converting the model to TensorRT
python torch2trt.py
```
‚ö†Ô∏è The provided TensorRT model is from an `H100`. We recommend `ALL users` (including H100 users) re-run `python torch2trt.py` locally to ensure best compatibility.

#### ‚ñ∂Ô∏è Start Streaming
```
python inference_online.py --acceleration none (for RTX 50-Series) or xformers or tensorrt
```
Then open `http://0.0.0.0:7860` in your browser. (*If `http://0.0.0.0:7860` does not work well, try `http://localhost:7860`)

**How to use**: Upload Image ‚û°Ô∏è Fuse Reference ‚û°Ô∏è Start Animation ‚û°Ô∏è Enjoy! üéâ
&lt;div align=&quot;center&quot;&gt;
  &lt;img src=&quot;assets/guide.png&quot; alt=&quot;PersonaLive&quot; width=&quot;60%&quot;&gt;
&lt;/div&gt;

**Regarding Latency**: Latency varies depending on your device&#039;s computing power. You can try the following methods to optimize it:

1. Lower the &quot;Driving FPS&quot; setting in the WebUI to reduce the computational workload.
2. You can increase the multiplier (e.g., set to `num_frames_needed * 4` or higher) to better match your device&#039;s inference speed. https://github.com/GVCLab/PersonaLive/blob/6953d1a8b409f360a3ee1d7325093622b29f1e22/webcam/util.py#L73

## üìö Community Contribution

Special thanks to the community for providing helpful setups! ü•Ç

* **Windows + RTX 50-Series Guide**: Thanks to [@dknos](https://github.com/dknos) for providing a [detailed guide](https://github.com/GVCLab/PersonaLive/issues/10#issuecomment-3662785532) on running this project on Windows with Blackwell GPUs.

* **TensorRT on Windows**: If you are trying to convert TensorRT models on Windows, [this discussion](https://github.com/GVCLab/PersonaLive/issues/8) might be helpful. Special thanks to [@MaraScott](https://github.com/MaraScott) and [@Jeremy8776](https://github.com/Jeremy8776) for their insights.
  
* **ComfyUI**: Thanks to [@okdalto](https://github.com/okdalto) for helping implement the [ComfyUI-PersonaLive](https://github.com/okdalto/ComfyUI-PersonaLive) support.

* **Useful Scripts**: Thanks to [@suruoxi](https://github.com/suruoxi) for implementing `download_weights.py`, and to [@andchir](https://github.com/andchir) for adding audio merging functionality.

## üé¨ More Results
#### üëÄ Visualization results

&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td width=&quot;50%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/cdc885ef-5e1c-4139-987a-2fa50fefd6a4&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;50%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/014f7bae-74ce-4f56-8621-24bc76f3c123&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/1e6a0809-15d2-4cab-ae8f-8cf1728c6281&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/d9cf265d-9db0-4f83-81da-be967bbd5f26&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/86235139-b63e-4f26-b09c-d218466e8e24&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/238785de-3b4c-484e-9ad0-9d90e7962fee&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/c71c4717-d528-4a98-b132-2b0ec8cec22d&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/7e11fe71-fd16-4011-a6b2-2dbaf7e343fb&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/f62e2162-d239-4575-9514-34575c16301c&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
    &lt;td width=&quot;25%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/813e7fbd-37e9-47d7-a270-59887fafeca5&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

#### ü§∫ Comparisons

&lt;table width=&quot;100%&quot;&gt;
  &lt;tr&gt;
    &lt;td width=&quot;100%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/36407cf9-bf82-43ff-9508-a794d223d3f7&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;100%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/3be99b91-c6a1-4ca4-89e9-8fad42bb9583&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td width=&quot;100%&quot;&gt;
      &lt;video src=&quot;https://github.com/user-attachments/assets/5bd21fe4-96ae-4be6-bf06-a7c476b04ec9&quot; controls=&quot;controls&quot; style=&quot;max-width: 100%; display: block;&quot;&gt;&lt;/video&gt;
    &lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;


## ‚≠ê Citation
If you find PersonaLive useful for your research, welcome to cite our work using the following BibTeX:
```bibtex
@article{li2025personalive,
  title={PersonaLive! Expressive Portrait Image Animation for Live Streaming},
  author={Li, Zhiyuan and Pun, Chi-Man and Fang, Chen and Wang, Jue and Cun, Xiaodong},
  journal={arXiv preprint arXiv:2512.11253},
  year={2025}
}
```

## ‚ù§Ô∏è Acknowledgement
This code is mainly built upon [Moore-AnimateAnyone](https://github.com/MooreThreads/Moore-AnimateAnyone), [X-NeMo](https://byteaigc.github.io/X-Portrait2/), [StreamDiffusion](https://github.com/cumulo-autumn/StreamDiffusion), [RAIN](https://pscgylotti.github.io/pages/RAIN/) and [LivePortrait](https://github.com/KlingTeam/LivePortrait), thanks to their invaluable contributions.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[HunxByts/GhostTrack]]></title>
            <link>https://github.com/HunxByts/GhostTrack</link>
            <guid>https://github.com/HunxByts/GhostTrack</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:39 GMT</pubDate>
            <description><![CDATA[Useful tool to track location or mobile number]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/HunxByts/GhostTrack">HunxByts/GhostTrack</a></h1>
            <p>Useful tool to track location or mobile number</p>
            <p>Language: Python</p>
            <p>Stars: 7,431</p>
            <p>Forks: 983</p>
            <p>Stars today: 145 stars today</p>
            <h2>README</h2><pre># GhostTrack
Useful tool to track location or mobile number, so this tool can be called osint or also information gathering

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/bn.png&quot;/&gt;

New update :
```Version 2.2```

### Instalation on Linux (deb)
```
sudo apt-get install git
sudo apt-get install python3
```

### Instalation on Termux
```
pkg install git
pkg install python3
```

### Usage Tool
```
git clone https://github.com/HunxByts/GhostTrack.git
cd GhostTrack
pip3 install -r requirements.txt
python3 GhostTR.py
```

Display on the menu ```IP Tracker```

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/ip.png &quot; /&gt;

on the IP Track menu, you can combo with the seeker tool to get the target IP
&lt;details&gt;
&lt;summary&gt;:zap: Install Seeker :&lt;/summary&gt;
- &lt;strong&gt;&lt;a href=&quot;https://github.com/thewhiteh4t/seeker&quot;&gt;Get Seeker&lt;/a&gt;&lt;/strong&gt;
&lt;/details&gt;

Display on the menu ```Phone Tracker```

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/phone.png&quot; /&gt;

on this menu you can search for information from the target phone number

Display on the menu ```Username Tracker```

&lt;img src=&quot;https://github.com/HunxByts/GhostTrack/blob/main/asset/User.png&quot;/&gt;
on this menu you can search for information from the target username on social media

&lt;details&gt;
&lt;summary&gt;:zap: Author :&lt;/summary&gt;
- &lt;strong&gt;&lt;a href=&quot;https://github.com/HunxByts&quot;&gt;HunxByts&lt;/a&gt;&lt;/strong&gt;
&lt;/details&gt;
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[VectifyAI/PageIndex]]></title>
            <link>https://github.com/VectifyAI/PageIndex</link>
            <guid>https://github.com/VectifyAI/PageIndex</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:38 GMT</pubDate>
            <description><![CDATA[üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/VectifyAI/PageIndex">VectifyAI/PageIndex</a></h1>
            <p>üìë PageIndex: Document Index for Vectorless, Reasoning-based RAG</p>
            <p>Language: Python</p>
            <p>Stars: 17,223</p>
            <p>Forks: 1,225</p>
            <p>Stars today: 714 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  
&lt;a href=&quot;https://vectify.ai/pageindex&quot; target=&quot;_blank&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/46201e72-675b-43bc-bfbd-081cc6b65a1d&quot; alt=&quot;PageIndex Banner&quot; /&gt;
&lt;/a&gt;

&lt;br/&gt;
&lt;br/&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/14736&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14736&quot; alt=&quot;VectifyAI%2FPageIndex | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;
&lt;/p&gt;

# PageIndex: Vectorless, Reasoning-based RAG

&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Reasoning-based RAG&amp;nbsp; ‚ó¶ &amp;nbsp;No Vector DB&amp;nbsp; ‚ó¶ &amp;nbsp;No Chunking&amp;nbsp; ‚ó¶ &amp;nbsp;Human-like Retrieval&lt;/b&gt;&lt;/p&gt;

&lt;h4 align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://vectify.ai&quot;&gt;üè† Homepage&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://chat.pageindex.ai&quot;&gt;üñ•Ô∏è Chat Platform&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://pageindex.ai/mcp&quot;&gt;üîå MCP&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://docs.pageindex.ai&quot;&gt;üìö Docs&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://discord.com/invite/VuXuf29EUj&quot;&gt;üí¨ Discord&lt;/a&gt;&amp;nbsp; ‚Ä¢ &amp;nbsp;
  &lt;a href=&quot;https://ii2abc2jejf.typeform.com/to/tK3AXl8T&quot;&gt;‚úâÔ∏è Contact&lt;/a&gt;&amp;nbsp;
&lt;/h4&gt;
  
&lt;/div&gt;


&lt;details open&gt;
&lt;summary&gt;&lt;h3&gt;üì¢ Latest Updates&lt;/h3&gt;&lt;/summary&gt;

 **üî• Releases:**
- [**PageIndex Chat**](https://chat.pageindex.ai): The first human-like document-analysis agent [platform](https://chat.pageindex.ai) built for professional long documents. Can also be integrated via [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart) (beta).
&lt;!-- - [**PageIndex Chat API**](https://docs.pageindex.ai/quickstart): An API that brings PageIndex&#039;s advanced long-document intelligence directly into your applications and workflows. --&gt;
&lt;!-- - [PageIndex MCP](https://pageindex.ai/mcp): Bring PageIndex into Claude, Cursor, or any MCP-enabled agent. Chat with long PDFs in a reasoning-based, human-like way. --&gt;
 
 **üìù Articles:**
- [**PageIndex Framework**](https://pageindex.ai/blog/pageindex-intro): Introduces the PageIndex framework ‚Äî an *agentic, in-context* *tree index* that enables LLMs to perform *reasoning-based*, *human-like retrieval* over long documents, without vector DB or chunking.
&lt;!-- - [Do We Still Need OCR?](https://pageindex.ai/blog/do-we-need-ocr): Explores how vision-based, reasoning-native RAG challenges the traditional OCR pipeline, and why the future of document AI might be *vectorless* and *vision-based*. --&gt;

 **üß™ Cookbooks:**
- [Vectorless RAG](https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex): A minimal, hands-on example of reasoning-based RAG using PageIndex. No vectors, no chunking, and human-like retrieval.
- [Vision-based Vectorless RAG](https://docs.pageindex.ai/cookbook/vision-rag-pageindex): OCR-free, vision-only RAG with PageIndex&#039;s reasoning-native retrieval workflow that works directly over PDF page images.
&lt;/details&gt;

---

# üìë Introduction to PageIndex

Are you frustrated with vector database retrieval accuracy for long professional documents? Traditional vector-based RAG relies on semantic *similarity* rather than true *relevance*. But **similarity ‚â† relevance** ‚Äî what we truly need in retrieval is **relevance**, and that requires **reasoning**. When working with professional documents that demand domain expertise and multi-step reasoning, similarity search often falls short.

Inspired by AlphaGo, we propose **[PageIndex](https://vectify.ai/pageindex)** ‚Äî a **vectorless**, **reasoning-based RAG** system that builds a **hierarchical tree index** from long documents and uses LLMs to **reason** *over that index* for **agentic, context-aware retrieval**.
It simulates how *human experts* navigate and extract knowledge from complex documents through *tree search*, enabling LLMs to *think* and *reason* their way to the most relevant document sections. PageIndex performs retrieval in two steps:

1. Generate a ‚ÄúTable-of-Contents‚Äù **tree structure index** of documents
2. Perform reasoning-based retrieval through **tree search**

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pageindex.ai/blog/pageindex-intro&quot; target=&quot;_blank&quot; title=&quot;The PageIndex Framework&quot;&gt;
    &lt;img src=&quot;https://docs.pageindex.ai/images/cookbook/vectorless-rag.png&quot; width=&quot;70%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

### üéØ Core Features 

Compared to traditional vector-based RAG, **PageIndex** features:
- **No Vector DB**: Uses document structure and LLM reasoning for retrieval, instead of vector similarity search.
- **No Chunking**: Documents are organized into natural sections, not artificial chunks.
- **Human-like Retrieval**: Simulates how human experts navigate and extract knowledge from complex documents.
- **Better Explainability and Traceability**: Retrieval is based on reasoning ‚Äî traceable and interpretable, with page and section references. No more opaque, approximate vector search (‚Äúvibe retrieval‚Äù).

PageIndex powers a reasoning-based RAG system that achieved **state-of-the-art** [98.7% accuracy](https://github.com/VectifyAI/Mafin2.5-FinanceBench) on FinanceBench, demonstrating superior performance over vector-based RAG solutions in professional document analysis (see our [blog post](https://vectify.ai/blog/Mafin2.5) for details).

### üìç Explore PageIndex

To learn more, please see a detailed introduction of the [PageIndex framework](https://pageindex.ai/blog/pageindex-intro). Check out this GitHub repo for open-source code, and the [cookbooks](https://docs.pageindex.ai/cookbook), [tutorials](https://docs.pageindex.ai/tutorials), and [blog](https://pageindex.ai/blog) for additional usage guides and examples. 

The PageIndex service is available as a ChatGPT-style [chat platform](https://chat.pageindex.ai), or can be integrated via [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart).

### üõ†Ô∏è Deployment Options
- Self-host ‚Äî run locally with this open-source repo.
- Cloud Service ‚Äî try instantly with our [Chat Platform](https://chat.pageindex.ai/), or integrate with [MCP](https://pageindex.ai/mcp) or [API](https://docs.pageindex.ai/quickstart).
- _Enterprise_ ‚Äî private or on-prem deployment. [Contact us](https://ii2abc2jejf.typeform.com/to/tK3AXl8T) or [book a demo](https://calendly.com/pageindex/meet) for more details.

### üß™ Quick Hands-on

- Try the [**Vectorless RAG**](https://github.com/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb) notebook ‚Äî a *minimal*, hands-on example of reasoning-based RAG using PageIndex.
- Experiment with [*Vision-based Vectorless RAG*](https://github.com/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb) ‚Äî no OCR; a minimal, reasoning-native RAG pipeline that works directly over page images.
  
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/pageindex_RAG_simple.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Open_In_Colab-Vectorless_RAG-orange?style=for-the-badge&amp;logo=googlecolab&quot; alt=&quot;Open in Colab: Vectorless RAG&quot; /&gt;
  &lt;/a&gt;
  &amp;nbsp;&amp;nbsp;
  &lt;a href=&quot;https://colab.research.google.com/github/VectifyAI/PageIndex/blob/main/cookbook/vision_RAG_pageindex.ipynb&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
    &lt;img src=&quot;https://img.shields.io/badge/Open_In_Colab-Vision_RAG-orange?style=for-the-badge&amp;logo=googlecolab&quot; alt=&quot;Open in Colab: Vision RAG&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

---

# üå≤ PageIndex Tree Structure
PageIndex can transform lengthy PDF documents into a semantic **tree structure**, similar to a _&quot;table of contents&quot;_ but optimized for use with Large Language Models (LLMs). It&#039;s ideal for: financial reports, regulatory filings, academic textbooks, legal or technical manuals, and any document that exceeds LLM context limits.

Below is an example PageIndex tree structure. Also see more example [documents](https://github.com/VectifyAI/PageIndex/tree/main/tests/pdfs) and generated [tree structures](https://github.com/VectifyAI/PageIndex/tree/main/tests/results).

```jsonc
...
{
  &quot;title&quot;: &quot;Financial Stability&quot;,
  &quot;node_id&quot;: &quot;0006&quot;,
  &quot;start_index&quot;: 21,
  &quot;end_index&quot;: 22,
  &quot;summary&quot;: &quot;The Federal Reserve ...&quot;,
  &quot;nodes&quot;: [
    {
      &quot;title&quot;: &quot;Monitoring Financial Vulnerabilities&quot;,
      &quot;node_id&quot;: &quot;0007&quot;,
      &quot;start_index&quot;: 22,
      &quot;end_index&quot;: 28,
      &quot;summary&quot;: &quot;The Federal Reserve&#039;s monitoring ...&quot;
    },
    {
      &quot;title&quot;: &quot;Domestic and International Cooperation and Coordination&quot;,
      &quot;node_id&quot;: &quot;0008&quot;,
      &quot;start_index&quot;: 28,
      &quot;end_index&quot;: 31,
      &quot;summary&quot;: &quot;In 2023, the Federal Reserve collaborated ...&quot;
    }
  ]
}
...
```

You can generate the PageIndex tree structure with this open-source repo, or use our [API](https://docs.pageindex.ai/quickstart) 

---

# ‚öôÔ∏è Package Usage

You can follow these steps to generate a PageIndex tree from a PDF document.

### 1. Install dependencies

```bash
pip3 install --upgrade -r requirements.txt
```

### 2. Set your OpenAI API key

Create a `.env` file in the root directory and add your API key:

```bash
CHATGPT_API_KEY=your_openai_key_here
```

### 3. Run PageIndex on your PDF

```bash
python3 run_pageindex.py --pdf_path /path/to/your/document.pdf
```

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Optional parameters&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;
You can customize the processing with additional optional arguments:

```
--model                 OpenAI model to use (default: gpt-4o-2024-11-20)
--toc-check-pages       Pages to check for table of contents (default: 20)
--max-pages-per-node    Max pages per node (default: 10)
--max-tokens-per-node   Max tokens per node (default: 20000)
--if-add-node-id        Add node ID (yes/no, default: yes)
--if-add-node-summary   Add node summary (yes/no, default: yes)
--if-add-doc-description Add doc description (yes/no, default: yes)
```
&lt;/details&gt;

&lt;details&gt;
&lt;summary&gt;&lt;strong&gt;Markdown support&lt;/strong&gt;&lt;/summary&gt;
&lt;br&gt;
We also provide markdown support for PageIndex. You can use the `-md_path` flag to generate a tree structure for a markdown file.

```bash
python3 run_pageindex.py --md_path /path/to/your/document.md
```

&gt; Note: in this function, we use &quot;#&quot; to determine node heading and their levels. For example, &quot;##&quot; is level 2, &quot;###&quot; is level 3, etc. Make sure your markdown file is formatted correctly. If your Markdown file was converted from a PDF or HTML, we don&#039;t recommend using this function, since most existing conversion tools cannot preserve the original hierarchy. Instead, use our [PageIndex OCR](https://pageindex.ai/blog/ocr), which is designed to preserve the original hierarchy, to convert the PDF to a markdown file and then use this function.
&lt;/details&gt;

&lt;!-- 
# ‚òÅÔ∏è Improved Tree Generation with PageIndex OCR

This repo is designed for generating PageIndex tree structure for simple PDFs, but many real-world use cases involve complex PDFs that are hard to parse by classic Python tools. However, extracting high-quality text from PDF documents remains a non-trivial challenge. Most OCR tools only extract page-level content, losing the broader document context and hierarchy.

To address this, we introduced PageIndex OCR ‚Äî the first long-context OCR model designed to preserve the global structure of documents. PageIndex OCR significantly outperforms other leading OCR tools, such as those from Mistral and Contextual AI, in recognizing true hierarchy and semantic relationships across document pages.

- Experience next-level OCR quality with PageIndex OCR at our [Dashboard](https://dash.pageindex.ai/).
- Integrate PageIndex OCR seamlessly into your stack via our [API](https://docs.pageindex.ai/quickstart).

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/eb35d8ae-865c-4e60-a33b-ebbd00c41732&quot; width=&quot;80%&quot;&gt;
&lt;/p&gt;
--&gt;

---

# üìà Case Study: PageIndex Leads Finance QA Benchmark

[Mafin 2.5](https://vectify.ai/mafin) is a reasoning-based RAG system for financial document analysis, powered by **PageIndex**. It achieved a state-of-the-art [**98.7% accuracy**](https://vectify.ai/blog/Mafin2.5) on the [FinanceBench](https://arxiv.org/abs/2311.11944) benchmark, significantly outperforming traditional vector-based RAG systems.

PageIndex&#039;s hierarchical indexing and reasoning-driven retrieval enable precise navigation and extraction of relevant context from complex financial reports, such as SEC filings and earnings disclosures.

Explore the full [benchmark results](https://github.com/VectifyAI/Mafin2.5-FinanceBench) and our [blog post](https://vectify.ai/blog/Mafin2.5) for detailed comparisons and performance metrics.

&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/VectifyAI/Mafin2.5-FinanceBench&quot;&gt;
    &lt;img src=&quot;https://github.com/user-attachments/assets/571aa074-d803-43c7-80c4-a04254b782a3&quot; width=&quot;70%&quot;&gt;
  &lt;/a&gt;
&lt;/div&gt;

---

# üß≠ Resources

* üß™ [Cookbooks](https://docs.pageindex.ai/cookbook/vectorless-rag-pageindex): hands-on, runnable examples and advanced use cases.
* üìñ [Tutorials](https://docs.pageindex.ai/doc-search): practical guides and strategies, including *Document Search* and *Tree Search*.
* üìù [Blog](https://pageindex.ai/blog): technical articles, research insights, and product updates.
* üîå [MCP setup](https://pageindex.ai/mcp#quick-setup) &amp; [API docs](https://docs.pageindex.ai/quickstart): integration details and configuration options.

---

# ‚≠ê Support Us
Please cite this work as:
```
Mingtian Zhang, Yu Tang and PageIndex Team,
&quot;PageIndex: Next-Generation Vectorless, Reasoning-based RAG&quot;,
PageIndex Blog, Sep 2025.
```

Or use the BibTeX citation:

```
@article{zhang2025pageindex,
  author = {Mingtian Zhang and Yu Tang and PageIndex Team},
  title = {PageIndex: Next-Generation Vectorless, Reasoning-based RAG},
  journal = {PageIndex Blog},
  year = {2025},
  month = {September},
  note = {https://pageindex.ai/blog/pageindex-intro},
}
```

Leave us a star üåü if you like our project. Thank you!  

&lt;p&gt;
  &lt;img src=&quot;https://github.com/user-attachments/assets/eae4ff38-48ae-4a7c-b19f-eab81201d794&quot; width=&quot;80%&quot;&gt;
&lt;/p&gt;

### Connect with Us

[![Twitter](https://img.shields.io/badge/Twitter-000000?style=for-the-badge&amp;logo=x&amp;logoColor=white)](https://x.com/PageIndexAI)&amp;nbsp;
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&amp;logo=linkedin&amp;logoColor=white)](https://www.linkedin.com/company/vectify-ai/)&amp;nbsp;
[![Discord](https://img.shields.io/badge/Discord-5865F2?style=for-the-badge&amp;logo=discord&amp;logoColor=white)](https://discord.com/invite/VuXuf29EUj)&amp;nbsp;
[![Contact Us](https://img.shields.io/badge/Contact_Us-3B82F6?style=for-the-badge&amp;logo=envelope&amp;logoColor=white)](https://ii2abc2jejf.typeform.com/to/tK3AXl8T)

---

¬© 2025 [Vectify AI](https://vectify.ai)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[smittix/intercept]]></title>
            <link>https://github.com/smittix/intercept</link>
            <guid>https://github.com/smittix/intercept</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:37 GMT</pubDate>
            <description><![CDATA[iNTERCEPT, a free and open-source platform that unites the best signal intelligence tools into a single, accessible interface.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/smittix/intercept">smittix/intercept</a></h1>
            <p>iNTERCEPT, a free and open-source platform that unites the best signal intelligence tools into a single, accessible interface.</p>
            <p>Language: Python</p>
            <p>Stars: 1,308</p>
            <p>Forks: 161</p>
            <p>Stars today: 76 stars today</p>
            <h2>README</h2><pre># INTERCEPT

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/python-3.9+-blue.svg&quot; alt=&quot;Python 3.9+&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/license-Apache--2.0-green.svg&quot; alt=&quot;Apache 2.0 License&quot;&gt;
  &lt;img src=&quot;https://img.shields.io/badge/platform-macOS%20%7C%20Linux-lightgrey.svg&quot; alt=&quot;Platform&quot;&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
Support the developer of this open-source project 
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.buymeacoffee.com/smittix&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png&quot; alt=&quot;Buy Me A Coffee&quot; style=&quot;height: 41px !important;width: 174px !important;box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 3px 2px 0px rgba(190, 190, 190, 0.5) !important;&quot; &gt;&lt;/a&gt;
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;Signal Intelligence Platform&lt;/strong&gt;&lt;br&gt;
  A web-based interface for software-defined radio tools.
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;static/images/screenshots/intercept-main.png&quot; alt=&quot;Screenshot&quot;&gt;
&lt;/p&gt;

---

## Features

- **Pager Decoding** - POCSAG/FLEX via rtl_fm + multimon-ng
- **433MHz Sensors** - Weather stations, TPMS, IoT devices via rtl_433
- **Sub-GHz Analyzer** - RF capture and protocol decoding for 300-928 MHz ISM bands via HackRF
- **Aircraft Tracking** - ADS-B via dump1090 with real-time map and radar
- **Vessel Tracking** - AIS ship tracking with VHF DSC distress monitoring
- **ACARS Messaging** - Aircraft datalink messages via acarsdec
- **VDL2** - VHF Data Link Mode 2 aircraft datalink decoding via dumpvdl2
- **Listening Post** - Wideband frequency scanner with real-time audio monitoring
- **Weather Satellites** - NOAA APT and Meteor LRPT image decoding via SatDump with auto-scheduler
- **WebSDR** - Remote HF/shortwave listening via KiwiSDR network
- **ISS SSTV** - Slow-scan TV image reception from the International Space Station
- **HF SSTV** - Terrestrial SSTV on shortwave frequencies (80m-10m, VHF, UHF)
- **APRS** - Amateur packet radio position reports and telemetry via direwolf
- **Satellite Tracking** - Pass prediction with polar plot and ground track map
- **Utility Meters** - Electric, gas, and water meter reading via rtlamr
- **ADS-B History** - Persistent aircraft history with reporting dashboard (Postgres optional)
- **WiFi Scanning** - Monitor mode reconnaissance via aircrack-ng
- **Bluetooth Scanning** - Device discovery and tracker detection (with Ubertooth support)
- **BT Locate** - SAR Bluetooth device location with GPS-tagged signal trail mapping and proximity alerts
- **GPS** - Real-time GPS position tracking with live map, speed, altitude, and satellite info
- **TSCM** - Counter-surveillance with RF baseline comparison and threat detection
- **Meshtastic** - LoRa mesh network integration
- **Space Weather** - Real-time solar and geomagnetic data from NOAA SWPC, NASA SDO, and HamQSL (no SDR required)
- **Spy Stations** - Number stations and diplomatic HF network database
- **Remote Agents** - Distributed SIGINT with remote sensor nodes
- **Offline Mode** - Bundled assets for air-gapped/field deployments

---

## Installation / Debian / Ubuntu / MacOS

**1. Clone and run:**
```bash
git clone https://github.com/smittix/intercept.git
cd intercept
./setup.sh
sudo -E venv/bin/python intercept.py
```

### Docker

```bash
git clone https://github.com/smittix/intercept.git
cd intercept
docker compose --profile basic up -d --build
```

&gt; **Note:** Docker requires privileged mode for USB SDR access. SDR devices are passed through via `/dev/bus/usb`.

#### Multi-Architecture Builds (amd64 + arm64)

Cross-compile on an x64 machine and push to a registry. This is much faster than building natively on an RPi.

```bash
# One-time setup on your x64 build machine
docker run --privileged --rm tonistiigi/binfmt --install all
docker buildx create --name intercept-builder --use --bootstrap

# Build and push for both architectures
REGISTRY=ghcr.io/youruser ./build-multiarch.sh --push

# On the RPi5, just pull and run
INTERCEPT_IMAGE=ghcr.io/youruser/intercept:latest docker compose --profile basic up -d
```

Build script options:

| Flag | Description |
|------|-------------|
| `--push` | Push to container registry |
| `--load` | Load into local Docker (single platform only) |
| `--arm64-only` | Build arm64 only (for RPi deployment) |
| `--amd64-only` | Build amd64 only |

Environment variables: `REGISTRY`, `IMAGE_NAME`, `IMAGE_TAG`

#### Using a Pre-built Image

If you&#039;ve pushed to a registry, you can skip building entirely on the target machine:

```bash
# Set in .env or export
INTERCEPT_IMAGE=ghcr.io/youruser/intercept:latest

# Then just run
docker compose --profile basic up -d
```

### ADS-B History (Optional)

The ADS-B history feature persists aircraft messages to Postgres for long-term analysis.

```bash
# Start with ADS-B history and Postgres
docker compose --profile history up -d
```

Set the following environment variables (for example in a `.env` file):

```bash
INTERCEPT_ADSB_HISTORY_ENABLED=true
INTERCEPT_ADSB_DB_HOST=adsb_db
INTERCEPT_ADSB_DB_PORT=5432
INTERCEPT_ADSB_DB_NAME=intercept_adsb
INTERCEPT_ADSB_DB_USER=intercept
INTERCEPT_ADSB_DB_PASSWORD=intercept
```

### Other ADS-B Settings

Set these as environment variables for either local installs or Docker:

| Variable | Default | Description |
|----------|---------|-------------|
| `INTERCEPT_ADSB_AUTO_START` | `false` | Auto-start ADS-B tracking when the dashboard loads |
| `INTERCEPT_SHARED_OBSERVER_LOCATION` | `true` | Share observer location across ADS-B/AIS/SSTV/Satellite modules |

**Local install example**

```bash
INTERCEPT_ADSB_AUTO_START=true \
INTERCEPT_SHARED_OBSERVER_LOCATION=false \
sudo -E venv/bin/python intercept.py
```

**Docker example (.env)**

```bash
INTERCEPT_ADSB_AUTO_START=true
INTERCEPT_SHARED_OBSERVER_LOCATION=false
```

To store Postgres data on external storage, set `PGDATA_PATH` (defaults to `./pgdata`):

```bash
PGDATA_PATH=/mnt/usbpi1/intercept/pgdata
```

Then open **/adsb/history** for the reporting dashboard.

### Open the Interface

After starting, open **http://localhost:5050** in your browser. The username and password is &lt;b&gt;admin&lt;/b&gt;:&lt;b&gt;admin&lt;/b&gt; 

The credentials can be changed in the ADMIN_USERNAME &amp; ADMIN_PASSWORD variables in config.py

---

## Hardware Requirements

| Hardware | Purpose | Price |
|----------|---------|-------|
| **RTL-SDR** | Required for all SDR features | ~$25-35 |
| **WiFi adapter** | Must support promiscuous (monitor) mode | ~$20-40 |
| **Bluetooth adapter** | Device scanning (usually built-in) | - |
| **GPS** | Any Linux supported GPS Unit | ~10 |

Most features work with a basic RTL-SDR dongle (RTL2832U + R820T2).

| :exclamation:  Not using an RTL-SDR Device?   |
|-----------------------------------------------
|Intercept supports any device that SoapySDR supports. You must however have the correct module for your device installed! For example if you have an SDRPlay device you&#039;d need to install soapysdr-module-sdrplay.

| :exclamation:  GPS Usage   |
|-----------------------------------------------
|gpsd is needed for real time location. Intercept automatically checks to see if you&#039;re running gpsd in the background when any maps are rendered.

---

## Discord Server

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://discord.gg/EyeksEJmWE&quot;&gt;Join our Discord&lt;/a&gt;
&lt;/p&gt;


---

## Documentation

- [Usage Guide](docs/USAGE.md) - Detailed instructions for each mode
- [Distributed Agents](docs/DISTRIBUTED_AGENTS.md) - Remote sensor node deployment
- [Hardware Guide](docs/HARDWARE.md) - SDR hardware and advanced setup
- [Troubleshooting](docs/TROUBLESHOOTING.md) - Common issues and solutions
- [Security](docs/SECURITY.md) - Network security and best practices

---

## Disclaimer

This project was developed using AI as a coding partner, combining human direction with AI-assisted implementation. The goal: make Software Defined Radio more accessible by providing a clean, unified interface for common SDR tools.

**This software is for educational and authorized testing purposes only.**

- Only use with proper authorization
- Intercepting communications without consent may be illegal
- You are responsible for compliance with applicable laws

---

## License

Apache 2.0 License - see [LICENSE](LICENSE)

## Author

Created by **smittix** - [GitHub](https://github.com/smittix)

## Acknowledgments

[rtl-sdr](https://osmocom.org/projects/rtl-sdr/wiki) |
[multimon-ng](https://github.com/EliasOenal/multimon-ng) |
[rtl_433](https://github.com/merbanan/rtl_433) |
[dump1090](https://github.com/flightaware/dump1090) |
[AIS-catcher](https://github.com/jvde-github/AIS-catcher) |
[acarsdec](https://github.com/TLeconte/acarsdec) |
[direwolf](https://github.com/wb2osz/direwolf) |
[rtlamr](https://github.com/bemasher/rtlamr) |
[dumpvdl2](https://github.com/szpajder/dumpvdl2) |
[aircrack-ng](https://www.aircrack-ng.org/) |
[Leaflet.js](https://leafletjs.com/) |
[SatDump](https://github.com/SatDump/SatDump) |
[Celestrak](https://celestrak.org/) |
[Priyom.org](https://priyom.org/)










</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[OpenBMB/ChatDev]]></title>
            <link>https://github.com/OpenBMB/ChatDev</link>
            <guid>https://github.com/OpenBMB/ChatDev</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:36 GMT</pubDate>
            <description><![CDATA[ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/OpenBMB/ChatDev">OpenBMB/ChatDev</a></h1>
            <p>ChatDev 2.0: Dev All through LLM-powered Multi-Agent Collaboration</p>
            <p>Language: Python</p>
            <p>Stars: 31,184</p>
            <p>Forks: 3,854</p>
            <p>Stars today: 47 stars today</p>
            <h2>README</h2><pre># ChatDev 2.0 - DevAll

&lt;p align=&quot;center&quot;&gt;
  &lt;img src=&quot;frontend/public/media/logo.png&quot; alt=&quot;DevAll Logo&quot; width=&quot;500&quot;/&gt;
&lt;/p&gt;


&lt;p align=&quot;center&quot;&gt;
  &lt;strong&gt;A Zero-Code Multi-Agent Platform for Developing Everything&lt;/strong&gt;
&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  „Äê&lt;a href=&quot;./README.md&quot;&gt;English&lt;/a&gt; | &lt;a href=&quot;./README-zh.md&quot;&gt;ÁÆÄ‰Ωì‰∏≠Êñá&lt;/a&gt;„Äë
&lt;/p&gt;
&lt;p align=&quot;center&quot;&gt;
    „Äêüìö &lt;a href=&quot;#developers&quot;&gt;Developers&lt;/a&gt; | üë• &lt;a href=&quot;#primary-contributors&quot;&gt;Contributors&lt;/a&gt;ÔΩú‚≠êÔ∏è &lt;a href=&quot;https://github.com/OpenBMB/ChatDev/tree/chatdev1.0&quot;&gt;ChatDev 1.0 (Legacy)&lt;/a&gt;„Äë
&lt;/p&gt;

## üìñ Overview
ChatDev has evolved from a specialized software development multi-agent system into a comprehensive multi-agent orchestration platform.

- &lt;a href=&quot;https://github.com/OpenBMB/ChatDev/tree/main&quot;&gt;**ChatDev 2.0 (DevAll)**&lt;/a&gt; is a **Zero-Code Multi-Agent Platform** for &quot;Developing Everything&quot;. It empowers users to rapidly build and execute customized multi-agent systems through simple configuration. No coding is required‚Äîusers can define agents, workflows, and tasks to orchestrate complex scenarios such as data visualization, 3D generation, and deep research.
- &lt;a href=&quot;https://github.com/OpenBMB/ChatDev/tree/chatdev1.0&quot;&gt;**ChatDev 1.0 (Legacy)**&lt;/a&gt; operates as a **Virtual Software Company**. It utilizes various intelligent agents (e.g., CEO, CTO, Programmer) participating in specialized functional seminars to automate the entire software development life cycle‚Äîincluding designing, coding, testing, and documenting. It serves as the foundational paradigm for communicative agent collaboration.

## üéâ News
‚Ä¢ **Jan 07, 2026: üöÄ We are excited to announce the official release of ChatDev 2.0 (DevAll)!** This version introduces a zero-code multi-agent orchestration platform. The classic ChatDev (v1.x) has been moved to the [`chatdev1.0`](https://github.com/OpenBMB/ChatDev/tree/chatdev1.0) branch for maintenance. More details about ChatDev 2.0 can be found on [our official post](https://x.com/OpenBMB/status/2008916790399701335).

&lt;details&gt;
&lt;summary&gt;Old News&lt;/summary&gt;

‚Ä¢Sep 24, 2025: üéâ Our paper [Multi-Agent Collaboration via Evolving Orchestration](https://arxiv.org/abs/2505.19591) has been accepted to NeurIPS 2025. The implementation is available in the `puppeteer` branch of this repository.

‚Ä¢May 26, 2025: üéâ We propose a novel puppeteer-style paradigm for multi-agent collaboration among large language model based agents. By leveraging a learnable central orchestrator optimized with reinforcement learning, our method dynamically activates and sequences agents to construct efficient, context-aware reasoning paths. This approach not only improves reasoning quality but also reduces computational costs, enabling scalable and adaptable multi-agent cooperation in complex tasks.
See our paper in [Multi-Agent Collaboration via Evolving Orchestration](https://arxiv.org/abs/2505.19591).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/puppeteer.png&#039; width=800&gt;
  &lt;/p&gt;

‚Ä¢June 25, 2024: üéâTo foster development in LLM-powered multi-agent collaborationü§ñü§ñ and related fields, the ChatDev team has curated a collection of seminal papersüìÑ presented in a [open-source](https://github.com/OpenBMB/ChatDev/tree/main/MultiAgentEbook) interactive e-booküìö format. Now you can explore the latest advancements on the [Ebook Website](https://thinkwee.top/multiagent_ebook) and download the [paper list](https://github.com/OpenBMB/ChatDev/blob/main/MultiAgentEbook/papers.csv).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/ebook.png&#039; width=800&gt;
  &lt;/p&gt;
  
‚Ä¢June 12, 2024: We introduced Multi-Agent Collaboration Networks (MacNet) üéâ, which utilize directed acyclic graphs to facilitate effective task-oriented collaboration among agents through linguistic interactions ü§ñü§ñ. MacNet supports co-operation across various topologies and among more than a thousand agents without exceeding context limits. More versatile and scalable, MacNet can be considered as a more advanced version of ChatDev&#039;s chain-shaped topology. Our preprint paper is available at [https://arxiv.org/abs/2406.07155](https://arxiv.org/abs/2406.07155). This technique has been incorporated into the [macnet](https://github.com/OpenBMB/ChatDev/tree/macnet) branch, enhancing support for diverse organizational structures and offering richer solutions beyond software development (e.g., logical reasoning, data analysis, story generation, and more).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/macnet.png&#039; width=500&gt;
  &lt;/p&gt;

‚Ä¢ May 07, 2024, we introduced &quot;Iterative Experience Refinement&quot; (IER), a novel method where instructor and assistant agents enhance shortcut-oriented experiences to efficiently adapt to new tasks. This approach encompasses experience acquisition, utilization, propagation and elimination across a series of tasks and making the pricess shorter and efficient. Our preprint paper is available at https://arxiv.org/abs/2405.04219, and this technique will soon be incorporated into ChatDev.
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/ier.png&#039; width=220&gt;
  &lt;/p&gt;

‚Ä¢ January 25, 2024: We have integrated Experiential Co-Learning Module into ChatDev. Please see the [Experiential Co-Learning Guide](wiki.md#co-tracking).

‚Ä¢ December 28, 2023: We present Experiential Co-Learning, an innovative approach where instructor and assistant agents accumulate shortcut-oriented experiences to effectively solve new tasks, reducing repetitive errors and enhancing efficiency.  Check out our preprint paper at https://arxiv.org/abs/2312.17025 and this technique will soon be integrated into ChatDev.
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/ecl.png&#039; width=860&gt;
  &lt;/p&gt;
‚Ä¢ November 15, 2023: We launched ChatDev as a SaaS platform that enables software developers and innovative entrepreneurs to build software efficiently at a very low cost and remove the barrier to entry. Try it out at https://chatdev.modelbest.cn/.
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/saas.png&#039; width=560&gt;
  &lt;/p&gt;

‚Ä¢ November 2, 2023: ChatDev is now supported with a new feature: incremental development, which allows agents to develop upon existing codes. Try ```--config &quot;incremental&quot; --path &quot;[source_code_directory_path]&quot;``` to start it.
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/increment.png&#039; width=700&gt;
  &lt;/p&gt;

‚Ä¢ October 26, 2023: ChatDev is now supported with Docker for safe execution (thanks to contribution from [ManindraDeMel](https://github.com/ManindraDeMel)). Please see [Docker Start Guide](wiki.md#docker-start).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/docker.png&#039; width=400&gt;
  &lt;/p&gt;
  
‚Ä¢ September 25, 2023: The **Git** mode is now available, enabling the programmer &lt;img src=&#039;visualizer/static/figures/programmer.png&#039; height=20&gt; to utilize Git for version control. To enable this feature, simply set ``&quot;git_management&quot;`` to ``&quot;True&quot;`` in ``ChatChainConfig.json``. See [guide](wiki.md#git-mode).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/github.png&#039; width=600&gt;
  &lt;/p&gt;

‚Ä¢ September 20, 2023: The **Human-Agent-Interaction** mode is now available! You can get involved with the ChatDev team by playing the role of reviewer &lt;img src=&#039;visualizer/static/figures/reviewer.png&#039; height=20&gt; and making suggestions to the programmer &lt;img src=&#039;visualizer/static/figures/programmer.png&#039; height=20&gt;;
  try ``python3 run.py --task [description_of_your_idea] --config &quot;Human&quot;``. See [guide](wiki.md#human-agent-interaction) and [example](WareHouse/Gomoku_HumanAgentInteraction_20230920135038).
  &lt;p align=&quot;center&quot;&gt;
  &lt;img src=&#039;./assets/Human_intro.png&#039; width=600&gt;
  &lt;/p&gt;

‚Ä¢ September 1, 2023: The **Art** mode is available now! You can activate the designer agent &lt;img src=&#039;visualizer/static/figures/designer.png&#039; height=20&gt; to generate images used in the software;
  try ``python3 run.py --task [description_of_your_idea] --config &quot;Art&quot;``. See [guide](wiki.md#art) and [example](WareHouse/gomokugameArtExample_THUNLP_20230831122822).
  
‚Ä¢ August 28, 2023: The system is publicly available.

‚Ä¢ August 17, 2023: The v1.0.0 version was ready for release.

‚Ä¢ July 30, 2023: Users can customize ChatChain, Phasea and Role settings. Additionally, both online Log mode and replay
  mode are now supported.

‚Ä¢ July 16, 2023: The [preprint paper](https://arxiv.org/abs/2307.07924) associated with this project was published.

‚Ä¢ June 30, 2023: The initial version of the ChatDev repository was released.
&lt;/details&gt;


## üöÄ Quick Start

### üìã Prerequisites

*   **OS**: macOS / Linux / WSL / Windows
*   **Python**: 3.12+
*   **Node.js**: 18+
*   **Package Manager**: [uv](https://docs.astral.sh/uv/)

### üì¶ Installation

1.  **Backend Dependencies** (Python managed by `uv`):
    ```bash
    uv sync
    ```

2.  **Frontend Dependencies** (Vite + Vue 3):
    ```bash
    cd frontend &amp;&amp; npm install
    ```

### üîë Configuration

*   **Environment Variables**:
    ```bash
    cp .env.example .env
    ```
*   **Model Keys**: Set `API_KEY` and `BASE_URL` in `.env` for your LLM provider.
*   **YAML placeholders**: Use `${VAR}`Ôºàe.g., `${API_KEY}`Ôºâin configuration files to reference these variables.

### ‚ö°Ô∏è Run the Application

#### Using Makefile (Recommended)

**Start both Backend and Frontent**:
```bash
make dev
```

&gt; Then access the Web Console at **[http://localhost:5173](http://localhost:5173)**.

#### Manual Commands

1.  **Start Backend**:
    ```bash
    # Run from the project root
    uv run python server_main.py --port 6400 --reload
    ```
    &gt; Remove `--reload` if output files (e.g., GameDev) trigger restarts, which interrupts tasks and loses progress.

2.  **Start Frontend**:
    ```bash
    cd frontend
    VITE_API_BASE_URL=http://localhost:6400 npm run dev
    ```
    &gt; Then access the Web Console at **[http://localhost:5173](http://localhost:5173)**. 
    
    
    &gt; **üí° Tip**: If the frontend fails to connect to the backend, the default port `6400` may already be occupied.
    &gt; Please switch both services to an available port, for example:
    &gt;
    &gt; * **Backend**: start with `--port 6401`
    &gt; * **Frontend**: set `VITE_API_BASE_URL=http://localhost:6401`

#### Utility Commands

*   **Help command**:
    ```bash
    make help
    ```

*   **Sync YAML workflows to frontend**:
    ```bash
    make sync
    ```
    Uploads all workflow files from `yaml_instance/` to the database.

*   **Validate all YAML workflows**:
    ```bash
    make validate-yamls
    ```
    Checks all YAML files for syntax and schema errors.

### üê≥ Run with Docker
Alternatively, you can run the entire application using Docker Compose. This method simplifies dependency management and provides a consistent environment.

1.  **Prerequisites**:
    *   [Docker](https://docs.docker.com/get-docker/) and [Docker Compose](https://docs.docker.com/compose/install/) installed.
    *   Ensure you have a `.env` file in the project root for your API keys.

2.  **Build and Run**:
    ```bash
    # From the project root
    docker compose up --build
    ```

3.  **Access**:
    *   **Backend**: `http://localhost:6400`
    *   **Frontend**: `http://localhost:5173`

&gt; The services will automatically restart if they crash, and local file changes will be reflected inside the containers for live development.

---

## üí° How to Use

### üñ•Ô∏è Web Console

The DevAll interface provides a seamless experience for both construction and execution

*   **Tutorial**: Comprehensive step-by-step guides and documentation integrated directly into the platform to help you get started quickly.
&lt;img src=&quot;assets/tutorial-en.png&quot;/&gt; 

*   **Workflow**: A visual canvas to design your multi-agent systems. Configure node parameters, define context flows, and orchestrate complex agent interactions with drag-and-drop ease.
&lt;img src=&quot;assets/workflow.gif&quot;/&gt;

*   **Launch**: Initiate workflows, monitor real-time logs, inspect intermediate artifacts, and provide human-in-the-loop feedback.
&lt;img src=&quot;assets/launch.gif&quot;/&gt;

### üß∞ Python SDK
For automation and batch processing, use our lightweight Python SDK to execute workflows programmatically and retrieve results directly.

```python
from runtime.sdk import run_workflow

# Execute a workflow and get the final node message
result = run_workflow(
    yaml_file=&quot;yaml_instance/demo.yaml&quot;,
    task_prompt=&quot;Summarize the attached document in one sentence.&quot;,
    attachments=[&quot;/path/to/document.pdf&quot;],
    variables={&quot;API_KEY&quot;: &quot;sk-xxxx&quot;} # Override .env variables if needed
)

if result.final_message:
    print(f&quot;Output: {result.final_message.text_content()}&quot;)
```

---

&lt;a id=&quot;developers&quot;&gt;&lt;/a&gt;
## ‚öôÔ∏è For Developers

**For secondary development and extensions, please proceed with this section.**

Extend DevAll with new nodes, providers, and tools.
The project is organized into a modular structure:
*   **Core Systems**: `server/` hosts the FastAPI backend, while `runtime/` manages agent abstraction and tool execution.
*   **Orchestration**: `workflow/` handles the multi-agent logic, driven by configurations in `entity/`.
*   **Frontend**: `frontend/` contains the Vue 3 Web Console.
*   **Extensibility**: `functions/` is the place for custom Python tools.

Relevant reference documentation:
*   **Getting Started**: [Start Guide](./docs/user_guide/en/index.md)
*   **Core Modules**: [Workflow Authoring](./docs/user_guide/en/workflow_authoring.md), [Memory](./docs/user_guide/en/modules/memory.md), and [Tooling](./docs/user_guide/en/modules/tooling/index.md)

---

## üåü Featured Workflows
We provide robust, out-of-the-box templates for common scenarios. All runnable workflow configs are located in `yaml_instance/`.
*   **Demos**: Files named `demo_*.yaml` showcase specific features or modules.
*   **Implementations**: Files named directly (e.g., `ChatDev_v1.yaml`) are full in-house or recreated workflows. As follows:

### üìã Workflow Collection

| Category | Workflow                                                                                                    | Case | 
| :--- |:------------------------------------------------------------------------------------------------------------| :--- | 
| **üìà Data Visualization** | `data_visualization_basic.yaml`&lt;br&gt;`data_visualization_enhanced.yaml`                                       | &lt;img src=&quot;assets/cases/data_analysis/data_analysis.gif&quot; width=&quot;100%&quot;&gt;&lt;br&gt;Prompt: *&quot;Create 4‚Äì6 high-quality PNG charts for my large real-estate transactions dataset.&quot;* |
| **üõ†Ô∏è 3D Generation**&lt;br&gt;*(Requires [Blender](https://www.blender.org/) &amp; [blender-mcp](https://github.com/ahujasid/blender-mcp))* | `blender_3d_builder_simple.yaml`&lt;br&gt;`blender_3d_builder_hub.yaml`&lt;br&gt;`blender_scientific_illustration.yaml` | &lt;img src=&quot;assets/cases/3d_generation/3d.gif&quot; width=&quot;100%&quot;&gt;&lt;br&gt;Prompt: *&quot;Please build a Christmas tree.&quot;* |
| **üéÆ Game Dev** | `GameDev_v1.yaml`&lt;br&gt;`ChatDev_v1.yaml`                                                                      | &lt;img src=&quot;assets/cases/game_development/game.gif&quot; width=&quot;100%&quot;&gt;&lt;br&gt;Prompt: *&quot;Please help me design and develop a Tank Battle game.&quot;* |
| **üìö Deep Research** | `deep_research_v1.yaml`                                                                                     | &lt;img src=&quot;assets/cases/deep_research/deep_research.gif&quot; width=&quot;85%&quot;&gt;&lt;br&gt;Prompt: *&quot;Research about recent advances in the field of LLM-based agent RL&quot;* |
| **üéì Teach Video** | `teach_video.yaml` (Please run command `uv add manim` before running this workflow)                         | &lt;img src=&quot;assets/cases/video_generation/video.gif&quot; width=&quot;140%&quot;&gt;&lt;br&gt;Prompt: *&quot;ËÆ≤‰∏Ä‰∏ã‰ªÄ‰πàÊòØÂá∏‰ºòÂåñ&quot;* |

---

### üí° Usage Guide
For those implementations, you can use the **Launch** tab to execute them.
1.  **Select**: Choose a workflow in the **Launch** tab.
2.  **Upload**: Upload necessary files (e.g., `.csv` for data analysis) if required.
3.  **Prompt**: Enter your request (e.g., *&quot;Visualize the sales trends&quot;* or *&quot;Design a snake game&quot;*).

---

## ü§ù Contributing

We welcome contributions from the community! Whether you&#039;re fixing bugs, adding new workflow templates, or sharing high-quality cases/artifacts produced by DevAll, your help is much appreciated. Feel free to contribute by submitting **Issues** or **Pull Requests**.

By contributing to DevAll, you&#039;ll be recognized in our **Contributors** list below. Check out our [Developer Guide](#developers) to get started!

### üë• Contributors

#### Primary Contributors

&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/NA-Wen&quot;&gt;&lt;img src=&quot;https://github.com/NA-Wen.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;NA-Wen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/zxrys&quot;&gt;&lt;img src=&quot;https://github.com/zxrys.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;zxrys&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/swugi&quot;&gt;&lt;img src=&quot;https://github.com/swugi.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;swugi&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/huatl98&quot;&gt;&lt;img src=&quot;https://github.com/huatl98.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;huatl98&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;

#### Contributors
&lt;table&gt;
  &lt;tr&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/shiowen&quot;&gt;&lt;img src=&quot;https://github.com/shiowen.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;shiowen&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/kilo2127&quot;&gt;&lt;img src=&quot;https://github.com/kilo2127.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;kilo2127&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/AckerlyLau&quot;&gt;&lt;img src=&quot;https://github.com/AckerlyLau.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;AckerlyLau&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/LaansDole&quot;&gt;&lt;img src=&quot;https://github.com/LaansDole.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;LaansDole&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/zivkovicp&quot;&gt;&lt;img src=&quot;https://github.com/zivkovicp.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;zivkovicp&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/rainoeelmae&quot;&gt;&lt;img src=&quot;https://github.com/rainoeelmae.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;rainoeelmae&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
    &lt;td align=&quot;center&quot;&gt;&lt;a href=&quot;https://github.com/conprour&quot;&gt;&lt;img src=&quot;https://github.com/conprour.png?size=100&quot; width=&quot;64px;&quot; alt=&quot;&quot;/&gt;&lt;br /&gt;&lt;sub&gt;&lt;b&gt;conprour&lt;/b&gt;&lt;/sub&gt;&lt;/a&gt;&lt;/td&gt;
&lt;/table&gt;

## ü§ù Acknowledgments

&lt;a href=&quot;http://nlp.csai.tsinghua.edu.cn/&quot;&gt;&lt;img src=&quot;assets/thunlp.png&quot; height=50pt&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://modelbest.cn/&quot;&gt;&lt;img src=&quot;assets/modelbest.png&quot; height=50pt&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/OpenBMB/AgentVerse/&quot;&gt;&lt;img src=&quot;assets/agentverse.png&quot; height=50pt&gt;&lt;/a&gt;&amp;nbsp;&amp;nbsp;
&lt;a href=&quot;https://github.com/OpenBMB/RepoAgent&quot;&gt;&lt;img src=&quot;assets/repoagent.png&quot;  height=50pt&gt;&lt;/a&gt;
&lt;a href=&quot;https://app.commanddash.io/agent?github=https://github.com/OpenBMB/ChatDev&quot;&gt;&lt;img src=&quot;assets/CommandDash.png&quot; height=50pt&gt;&lt;/a&gt;
&lt;a href=&quot;www.teachmaster.cn&quot;&gt;&lt;img src=&quot;assets/teachmaster.png&quot; height=50pt&gt;&lt;/a&gt;
&lt;a href=&quot;https://github.com/OpenBMB/AppCopilot&quot;&gt;&lt;img src=&quot;assets/appcopilot.png&quot; height=50pt&gt;&lt;/a&gt;

## üîé Citation

```
@article{chatdev,
    title = {ChatDev: Communicative Agents for Software Development},
    author = {Chen Qian and Wei Liu and Hongzhang Liu and Nuo Chen and Yufan Dang and Jiahao Li and Cheng Yang and Weize Chen and Yusheng Su and Xin Cong and Juyuan Xu and Dahai Li and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2307.07924},
    url = {https://arxiv.org/abs/2307.07924},
    year = {2023}
}

@article{colearning,
    title = {Experiential Co-Learning of Software-Developing Agents},
    author = {Chen Qian and Yufan Dang and Jiahao Li and Wei Liu and Zihao Xie and Yifei Wang and Weize Chen and Cheng Yang and Xin Cong and Xiaoyin Che and Zhiyuan Liu and Maosong Sun},
    journal = {arXiv preprint arXiv:2312.17025},
    url = {https://arxiv.org/abs/2312.17025},
    year = {2023}
}

@article{macnet,
    title={Scaling Large-Language-Model-based Multi-Agent Collaboration},
    author={Chen Qian and Zihao Xie and Yifei Wang and Wei Liu and Yufan Dang a

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[anthropics/claude-code-security-review]]></title>
            <link>https://github.com/anthropics/claude-code-security-review</link>
            <guid>https://github.com/anthropics/claude-code-security-review</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:35 GMT</pubDate>
            <description><![CDATA[An AI-powered security review GitHub Action using Claude to analyze code changes for security vulnerabilities.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anthropics/claude-code-security-review">anthropics/claude-code-security-review</a></h1>
            <p>An AI-powered security review GitHub Action using Claude to analyze code changes for security vulnerabilities.</p>
            <p>Language: Python</p>
            <p>Stars: 3,264</p>
            <p>Forks: 258</p>
            <p>Stars today: 73 stars today</p>
            <h2>README</h2><pre># Claude Code Security Reviewer

An AI-powered security review GitHub Action using Claude to analyze code changes for security vulnerabilities. This action provides intelligent, context-aware security analysis for pull requests using Anthropic&#039;s Claude Code tool for deep semantic security analysis. See our blog post [here](https://www.anthropic.com/news/automate-security-reviews-with-claude-code) for more details.

## Features

- **AI-Powered Analysis**: Uses Claude&#039;s advanced reasoning to detect security vulnerabilities with deep semantic understanding
- **Diff-Aware Scanning**: For PRs, only analyzes changed files
- **PR Comments**: Automatically comments on PRs with security findings
- **Contextual Understanding**: Goes beyond pattern matching to understand code semantics
- **Language Agnostic**: Works with any programming language
- **False Positive Filtering**: Advanced filtering to reduce noise and focus on real vulnerabilities

## Quick Start

Add this to your repository&#039;s `.github/workflows/security.yml`:

```yaml
name: Security Review

permissions:
  pull-requests: write  # Needed for leaving PR comments
  contents: read

on:
  pull_request:

jobs:
  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.sha }}
          fetch-depth: 2
      
      - uses: anthropics/claude-code-security-review@main
        with:
          comment-pr: true
          claude-api-key: ${{ secrets.CLAUDE_API_KEY }}
```

## Security Considerations

This action is not hardened against prompt injection attacks and should only be used to review trusted PRs. We recommend [configuring your repository](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/enabling-features-for-your-repository/managing-github-actions-settings-for-a-repository#controlling-changes-from-forks-to-workflows-in-public-repositories) to use the &quot;Require approval for all external contributors&quot; option to ensure workflows only run after a maintainer has reviewed the PR.

## Configuration Options

### Action Inputs

| Input | Description | Default | Required |
|-------|-------------|---------|----------|
| `claude-api-key` | Anthropic Claude API key for security analysis. &lt;br&gt;*Note*: This API key needs to be enabled for both the Claude API and Claude Code usage. | None | Yes |
| `comment-pr` | Whether to comment on PRs with findings | `true` | No |
| `upload-results` | Whether to upload results as artifacts | `true` | No |
| `exclude-directories` | Comma-separated list of directories to exclude from scanning | None | No |
| `claude-model` | Claude [model name](https://docs.anthropic.com/en/docs/about-claude/models/overview#model-names) to use. Defaults to Opus 4.1. | `claude-opus-4-1-20250805` | No |
| `claudecode-timeout` | Timeout for ClaudeCode analysis in minutes | `20` | No |
| `run-every-commit` | Run ClaudeCode on every commit (skips cache check). Warning: May increase false positives on PRs with many commits. | `false` | No |
| `false-positive-filtering-instructions` | Path to custom false positive filtering instructions text file | None | No |
| `custom-security-scan-instructions` | Path to custom security scan instructions text file to append to audit prompt | None | No |

### Action Outputs

| Output | Description |
|--------|-------------|
| `findings-count` | Total number of security findings |
| `results-file` | Path to the results JSON file |

## How It Works

### Architecture

```
claudecode/
‚îú‚îÄ‚îÄ github_action_audit.py  # Main audit script for GitHub Actions
‚îú‚îÄ‚îÄ prompts.py              # Security audit prompt templates
‚îú‚îÄ‚îÄ findings_filter.py      # False positive filtering logic
‚îú‚îÄ‚îÄ claude_api_client.py    # Claude API client for false positive filtering
‚îú‚îÄ‚îÄ json_parser.py          # Robust JSON parsing utilities
‚îú‚îÄ‚îÄ requirements.txt        # Python dependencies
‚îú‚îÄ‚îÄ test_*.py               # Test suites
‚îî‚îÄ‚îÄ evals/                  # Eval tooling to test CC on arbitrary PRs
```

### Workflow

1. **PR Analysis**: When a pull request is opened, Claude analyzes the diff to understand what changed
2. **Contextual Review**: Claude examines the code changes in context, understanding the purpose and potential security implications
3. **Finding Generation**: Security issues are identified with detailed explanations, severity ratings, and remediation guidance
4. **False Positive Filtering**: Advanced filtering removes low-impact or false positive prone findings to reduce noise
5. **PR Comments**: Findings are posted as review comments on the specific lines of code

## Security Analysis Capabilities

### Types of Vulnerabilities Detected

- **Injection Attacks**: SQL injection, command injection, LDAP injection, XPath injection, NoSQL injection, XXE
- **Authentication &amp; Authorization**: Broken authentication, privilege escalation, insecure direct object references, bypass logic, session flaws
- **Data Exposure**: Hardcoded secrets, sensitive data logging, information disclosure, PII handling violations
- **Cryptographic Issues**: Weak algorithms, improper key management, insecure random number generation
- **Input Validation**: Missing validation, improper sanitization, buffer overflows
- **Business Logic Flaws**: Race conditions, time-of-check-time-of-use (TOCTOU) issues
- **Configuration Security**: Insecure defaults, missing security headers, permissive CORS
- **Supply Chain**: Vulnerable dependencies, typosquatting risks
- **Code Execution**: RCE via deserialization, pickle injection, eval injection
- **Cross-Site Scripting (XSS)**: Reflected, stored, and DOM-based XSS

### False Positive Filtering

The tool automatically excludes a variety of low-impact and false positive prone findings to focus on high-impact vulnerabilities:
- Denial of Service vulnerabilities
- Rate limiting concerns
- Memory/CPU exhaustion issues
- Generic input validation without proven impact
- Open redirect vulnerabilities

The false positive filtering can also be tuned as needed for a given project&#039;s security goals.

### Benefits Over Traditional SAST

- **Contextual Understanding**: Understands code semantics and intent, not just patterns
- **Lower False Positives**: AI-powered analysis reduces noise by understanding when code is actually vulnerable
- **Detailed Explanations**: Provides clear explanations of why something is a vulnerability and how to fix it
- **Adaptive Learning**: Can be customized with organization-specific security requirements

## Installation &amp; Setup

### GitHub Actions

Follow the Quick Start guide above. The action handles all dependencies automatically.

### Local Development

To run the security scanner locally against a specific PR, see the [evaluation framework documentation](claudecode/evals/README.md).

&lt;a id=&quot;security-review-slash-command&quot;&gt;&lt;/a&gt;

## Claude Code Integration: /security-review Command 

By default, Claude Code ships a `/security-review` [slash command](https://docs.anthropic.com/en/docs/claude-code/slash-commands) that provides the same security analysis capabilities as the GitHub Action workflow, but integrated directly into your Claude Code development environment. To use this, simply run `/security-review` to perform a comprehensive security review of all pending changes.

### Customizing the Command

The default `/security-review` command is designed to work well in most cases, but it can also be customized based on your specific security needs. To do so: 

1. Copy the [`security-review.md`](https://github.com/anthropics/claude-code-security-review/blob/main/.claude/commands/security-review.md?plain=1) file from this repository to your project&#039;s `.claude/commands/` folder. 
2. Edit `security-review.md` to customize the security analysis. For example, you could add additional organization-specific directions to the false positive filtering instructions. 

## Custom Scanning Configuration

It is also possible to configure custom scanning and false positive filtering instructions, see the [`docs/`](docs/) folder for more details.  

## Testing

Run the test suite to validate functionality:

```bash
cd claude-code-security-review
# Run all tests
pytest claudecode -v
```

## Support

For issues or questions:
- Open an issue in this repository
- Check the [GitHub Actions logs](https://docs.github.com/en/actions/monitoring-and-troubleshooting-workflows/viewing-workflow-run-history) for debugging information

## License

MIT License - see [LICENSE](LICENSE) file for details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[datawhalechina/hello-agents]]></title>
            <link>https://github.com/datawhalechina/hello-agents</link>
            <guid>https://github.com/datawhalechina/hello-agents</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:34 GMT</pubDate>
            <description><![CDATA[üìö „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã‚Äî‚Äî‰ªéÈõ∂ÂºÄÂßãÁöÑÊô∫ËÉΩ‰ΩìÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/datawhalechina/hello-agents">datawhalechina/hello-agents</a></h1>
            <p>üìö „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã‚Äî‚Äî‰ªéÈõ∂ÂºÄÂßãÁöÑÊô∫ËÉΩ‰ΩìÂéüÁêÜ‰∏éÂÆûË∑µÊïôÁ®ã</p>
            <p>Language: Python</p>
            <p>Stars: 21,573</p>
            <p>Forks: 2,486</p>
            <p>Stars today: 187 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;right&quot;&gt;
  &lt;a href=&quot;./README_EN.md&quot;&gt;English&lt;/a&gt; | ‰∏≠Êñá
&lt;/div&gt;

&lt;div align=&#039;center&#039;&gt;
  &lt;img src=&quot;./docs/images/hello-agents.png&quot; alt=&quot;alt text&quot; width=&quot;100%&quot;&gt;
  &lt;h1&gt;Hello-Agents&lt;/h1&gt;
  &lt;h3&gt;ü§ñ „Ää‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰Ωì„Äã&lt;/h3&gt;
  &lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://trendshift.io/repositories/15520&quot; target=&quot;_blank&quot;&gt;
    &lt;img src=&quot;https://trendshift.io/api/badge/repositories/15520&quot; alt=&quot;datawhalechina%2Fhello-agents | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;
  &lt;/a&gt;
  &lt;/div&gt;
  &lt;p&gt;&lt;em&gt;‰ªéÂü∫Á°ÄÁêÜËÆ∫Âà∞ÂÆûÈôÖÂ∫îÁî®ÔºåÂÖ®Èù¢ÊéåÊè°Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂÆûÁé∞&lt;/em&gt;&lt;/p&gt;
  &lt;img src=&quot;https://img.shields.io/github/stars/datawhalechina/Hello-Agents?style=flat&amp;logo=github&quot; alt=&quot;GitHub stars&quot;/&gt;
  &lt;img src=&quot;https://img.shields.io/github/forks/datawhalechina/Hello-Agents?style=flat&amp;logo=github&quot; alt=&quot;GitHub forks&quot;/&gt;
  &lt;img src=&quot;https://img.shields.io/badge/language-Chinese-brightgreen?style=flat&quot; alt=&quot;Language&quot;/&gt;
  &lt;a href=&quot;https://github.com/datawhalechina/Hello-Agents&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/GitHub-Project-blue?style=flat&amp;logo=github&quot; alt=&quot;GitHub Project&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://datawhalechina.github.io/hello-agents/&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/Âú®Á∫øÈòÖËØª-Online%20Reading-green?style=flat&amp;logo=gitbook&quot; alt=&quot;Online Reading&quot;&gt;&lt;/a&gt;
&lt;/div&gt;

---

## üéØ È°πÁõÆ‰ªãÁªç

&amp;emsp;&amp;emsp;Â¶ÇÊûúËØ¥ 2024 Âπ¥ÊòØ&quot;ÁôæÊ®°Â§ßÊàò&quot;ÁöÑÂÖÉÂπ¥ÔºåÈÇ£‰πà 2025 Âπ¥Êó†ÁñëÂºÄÂêØ‰∫Ü&quot;Agent ÂÖÉÂπ¥&quot;„ÄÇÊäÄÊúØÁöÑÁÑ¶ÁÇπÊ≠£‰ªéËÆ≠ÁªÉÊõ¥Â§ßÁöÑÂü∫Á°ÄÊ®°ÂûãÔºåËΩ¨ÂêëÊûÑÂª∫Êõ¥ËÅ™ÊòéÁöÑÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÁÑ∂ËÄåÔºåÂΩìÂâçÁ≥ªÁªüÊÄß„ÄÅÈáçÂÆûË∑µÁöÑÊïôÁ®ãÂç¥ÊûÅÂ∫¶ÂåÆ‰πè„ÄÇ‰∏∫Ê≠§ÔºåÊàë‰ª¨ÂèëËµ∑‰∫Ü Hello-Agents È°πÁõÆÔºåÂ∏åÊúõËÉΩ‰∏∫Á§æÂå∫Êèê‰æõ‰∏ÄÊú¨‰ªéÈõ∂ÂºÄÂßã„ÄÅÁêÜËÆ∫‰∏éÂÆûÊàòÂπ∂ÈáçÁöÑÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÊûÑÂª∫ÊåáÂçó„ÄÇ

&amp;emsp;&amp;emsp;Hello-Agents ÊòØ Datawhale Á§æÂå∫ÁöÑ&lt;strong&gt;Á≥ªÁªüÊÄßÊô∫ËÉΩ‰ΩìÂ≠¶‰π†ÊïôÁ®ã&lt;/strong&gt;„ÄÇÂ¶Ç‰ªä Agent ÊûÑÂª∫‰∏ªË¶ÅÂàÜ‰∏∫‰∏§Ê¥æÔºå‰∏ÄÊ¥æÊòØ DifyÔºåCozeÔºån8n ËøôÁ±ªËΩØ‰ª∂Â∑•Á®ãÁ±ª AgentÔºåÂÖ∂Êú¨Ë¥®ÊòØÊµÅÁ®ãÈ©±Âä®ÁöÑËΩØ‰ª∂ÂºÄÂèëÔºåLLM ‰Ωú‰∏∫Êï∞ÊçÆÂ§ÑÁêÜÁöÑÂêéÁ´ØÔºõÂè¶‰∏ÄÊ¥æÂàôÊòØ AI ÂéüÁîüÁöÑ AgentÔºåÂç≥ÁúüÊ≠£‰ª• AI È©±Âä®ÁöÑ Agent„ÄÇÊú¨ÊïôÁ®ãÊó®Âú®Â∏¶È¢ÜÂ§ßÂÆ∂Ê∑±ÂÖ•ÁêÜËß£Âπ∂ÊûÑÂª∫ÂêéËÄÖ‚Äî‚ÄîÁúüÊ≠£ÁöÑ AI Native Agent„ÄÇÊïôÁ®ãÂ∞ÜÂ∏¶È¢Ü‰Ω†Á©øÈÄèÊ°ÜÊû∂Ë°®Ë±°Ôºå‰ªéÊô∫ËÉΩ‰ΩìÁöÑÊ†∏ÂøÉÂéüÁêÜÂá∫ÂèëÔºåÊ∑±ÂÖ•ÂÖ∂Ê†∏ÂøÉÊû∂ÊûÑÔºåÁêÜËß£ÂÖ∂ÁªèÂÖ∏ËåÉÂºèÔºåÂπ∂ÊúÄÁªà‰∫≤ÊâãÊûÑÂª∫Ëµ∑Â±û‰∫éËá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®„ÄÇÊàë‰ª¨Áõ∏‰ø°ÔºåÊúÄÂ•ΩÁöÑÂ≠¶‰π†ÊñπÂºèÂ∞±ÊòØÂä®ÊâãÂÆûË∑µ„ÄÇÂ∏åÊúõËøôÊú¨ÊïôÁ®ãËÉΩÊàê‰∏∫‰Ω†Êé¢Á¥¢Êô∫ËÉΩ‰Ωì‰∏ñÁïåÁöÑËµ∑ÁÇπÔºåËÉΩÂ§ü‰ªé‰∏ÄÂêçÂ§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑ&quot;‰ΩøÁî®ËÄÖ&quot;ÔºåËúïÂèò‰∏∫‰∏ÄÂêçÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑ&quot;ÊûÑÂª∫ËÄÖ&quot;„ÄÇ

## üìö Âø´ÈÄüÂºÄÂßã

### Âú®Á∫øÈòÖËØª
**[üåê ÁÇπÂáªËøôÈáåÂºÄÂßãÂú®Á∫øÈòÖËØª](https://datawhalechina.github.io/hello-agents/)** - Êó†ÈúÄ‰∏ãËΩΩÔºåÈöèÊó∂ÈöèÂú∞Â≠¶‰π†

**[üìñ Cookbook](https://book.heterocat.com.cn/)**

### Êú¨Âú∞ÈòÖËØª
Â¶ÇÊûúÊÇ®Â∏åÊúõÂú®Êú¨Âú∞ÈòÖËØªÊàñË¥°ÁåÆÂÜÖÂÆπÔºåËØ∑ÂèÇËÄÉ‰∏ãÊñπÁöÑÂ≠¶‰π†ÊåáÂçó„ÄÇ

### ‚ú® ‰Ω†Â∞ÜÊî∂Ëé∑‰ªÄ‰πàÔºü

- üìñ &lt;strong&gt;Datawhale ÂºÄÊ∫êÂÖçË¥π&lt;/strong&gt; ÂÆåÂÖ®ÂÖçË¥πÂ≠¶‰π†Êú¨È°πÁõÆÊâÄÊúâÂÜÖÂÆπÔºå‰∏éÁ§æÂå∫ÂÖ±ÂêåÊàêÈïø
- üîç &lt;strong&gt;ÁêÜËß£Ê†∏ÂøÉÂéüÁêÜ&lt;/strong&gt; Ê∑±ÂÖ•ÁêÜËß£Êô∫ËÉΩ‰ΩìÁöÑÊ¶ÇÂøµ„ÄÅÂéÜÂè≤‰∏éÁªèÂÖ∏ËåÉÂºè
- üèóÔ∏è &lt;strong&gt;‰∫≤ÊâãÂÆûÁé∞&lt;/strong&gt; ÊéåÊè°ÁÉ≠Èó®‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÂíåÊô∫ËÉΩ‰Ωì‰ª£Á†ÅÊ°ÜÊû∂ÁöÑ‰ΩøÁî®
- üõ†Ô∏è &lt;strong&gt;Ëá™Á†îÊ°ÜÊû∂[HelloAgents](https://github.com/jjyaoao/helloagents)&lt;/strong&gt; Âü∫‰∫é Openai ÂéüÁîü API ‰ªéÈõ∂ÊûÑÂª∫‰∏Ä‰∏™Ëá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂
- ‚öôÔ∏è &lt;strong&gt;ÊéåÊè°È´òÁ∫ßÊäÄËÉΩ&lt;/strong&gt; ‰∏ÄÊ≠•Ê≠•ÂÆûÁé∞‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅMemory„ÄÅÂçèËÆÆ„ÄÅËØÑ‰º∞Á≠âÁ≥ªÁªüÊÄßÊäÄÊúØ
- ü§ù &lt;strong&gt;Ê®°ÂûãËÆ≠ÁªÉ&lt;/strong&gt; ÊéåÊè° Agentic RLÔºå‰ªé SFT Âà∞ GRPO ÁöÑÂÖ®ÊµÅÁ®ãÂÆûÊàòËÆ≠ÁªÉ LLM
- üöÄ &lt;strong&gt;È©±Âä®ÁúüÂÆûÊ°à‰æã&lt;/strong&gt; ÂÆûÊàòÂºÄÂèëÊô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËµõÂçöÂ∞èÈïáÁ≠âÁªºÂêàÈ°πÁõÆ
- üìñ &lt;strong&gt;Ê±ÇËÅåÈù¢ËØï&lt;/strong&gt; Â≠¶‰π†Êô∫ËÉΩ‰ΩìÊ±ÇËÅåÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò

## üìñ ÂÜÖÂÆπÂØºËà™

| Á´†ËäÇ                                                                                        | ÂÖ≥ÈîÆÂÜÖÂÆπ                                      | Áä∂ÊÄÅ |
| ------------------------------------------------------------------------------------------- | --------------------------------------------- | ---- |
| [ÂâçË®Ä](./docs/ÂâçË®Ä.md)                                                                      | È°πÁõÆÁöÑÁºòËµ∑„ÄÅËÉåÊôØÂèäËØªËÄÖÂª∫ËÆÆ                    | ‚úÖ    |
| &lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;                                             |                                               |      |
| [Á¨¨‰∏ÄÁ´† ÂàùËØÜÊô∫ËÉΩ‰Ωì](./docs/chapter1/Á¨¨‰∏ÄÁ´†%20ÂàùËØÜÊô∫ËÉΩ‰Ωì.md)                                 | Êô∫ËÉΩ‰ΩìÂÆö‰πâ„ÄÅÁ±ªÂûã„ÄÅËåÉÂºè‰∏éÂ∫îÁî®                  | ‚úÖ    |
| [Á¨¨‰∫åÁ´† Êô∫ËÉΩ‰ΩìÂèëÂ±ïÂè≤](./docs/chapter2/Á¨¨‰∫åÁ´†%20Êô∫ËÉΩ‰ΩìÂèëÂ±ïÂè≤.md)                             | ‰ªéÁ¨¶Âè∑‰∏ª‰πâÂà∞ LLM È©±Âä®ÁöÑÊô∫ËÉΩ‰ΩìÊºîËøõ             | ‚úÖ    |
| [Á¨¨‰∏âÁ´† Â§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä](./docs/chapter3/Á¨¨‰∏âÁ´†%20Â§ßËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä.md)                         | Transformer„ÄÅÊèêÁ§∫„ÄÅ‰∏ªÊµÅ LLM ÂèäÂÖ∂Â±ÄÈôê          | ‚úÖ    |
| &lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;                                         |                                               |      |
| [Á¨¨ÂõõÁ´† Êô∫ËÉΩ‰ΩìÁªèÂÖ∏ËåÉÂºèÊûÑÂª∫](./docs/chapter4/Á¨¨ÂõõÁ´†%20Êô∫ËÉΩ‰ΩìÁªèÂÖ∏ËåÉÂºèÊûÑÂª∫.md)                 | ÊâãÊääÊâãÂÆûÁé∞ ReAct„ÄÅPlan-and-Solve„ÄÅReflection  | ‚úÖ    |
| [Á¨¨‰∫îÁ´† Âü∫‰∫é‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑÊô∫ËÉΩ‰ΩìÊê≠Âª∫](./docs/chapter5/Á¨¨‰∫îÁ´†%20Âü∫‰∫é‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑÊô∫ËÉΩ‰ΩìÊê≠Âª∫.md) | ‰∫ÜËß£ Coze„ÄÅDify„ÄÅn8n Á≠â‰Ωé‰ª£Á†ÅÊô∫ËÉΩ‰ΩìÂπ≥Âè∞‰ΩøÁî®   | ‚úÖ    |
| [Á¨¨ÂÖ≠Á´† Ê°ÜÊû∂ÂºÄÂèëÂÆûË∑µ](./docs/chapter6/Á¨¨ÂÖ≠Á´†%20Ê°ÜÊû∂ÂºÄÂèëÂÆûË∑µ.md)                             | AutoGen„ÄÅAgentScope„ÄÅLangGraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂Â∫îÁî® | ‚úÖ    |
| [Á¨¨‰∏ÉÁ´† ÊûÑÂª∫‰Ω†ÁöÑAgentÊ°ÜÊû∂](./docs/chapter7/Á¨¨‰∏ÉÁ´†%20ÊûÑÂª∫‰Ω†ÁöÑAgentÊ°ÜÊû∂.md)                   | ‰ªé 0 ÂºÄÂßãÊûÑÂª∫Êô∫ËÉΩ‰ΩìÊ°ÜÊû∂                       | ‚úÖ    |
| &lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;                                                     |                                               |      |
| [Á¨¨ÂÖ´Á´† ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢](./docs/chapter8/Á¨¨ÂÖ´Á´†%20ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢.md)                                 | ËÆ∞ÂøÜÁ≥ªÁªüÔºåRAGÔºåÂ≠òÂÇ®                           | ‚úÖ    |
| [Á¨¨‰πùÁ´† ‰∏ä‰∏ãÊñáÂ∑•Á®ã](./docs/chapter9/Á¨¨‰πùÁ´†%20‰∏ä‰∏ãÊñáÂ∑•Á®ã.md)                                 | ÊåÅÁª≠‰∫§‰∫íÁöÑ&quot;ÊÉÖÂ¢ÉÁêÜËß£&quot;                          | ‚úÖ    |
| [Á¨¨ÂçÅÁ´† Êô∫ËÉΩ‰ΩìÈÄö‰ø°ÂçèËÆÆ](./docs/chapter10/Á¨¨ÂçÅÁ´†%20Êô∫ËÉΩ‰ΩìÈÄö‰ø°ÂçèËÆÆ.md)                        | MCP„ÄÅA2A„ÄÅANP Á≠âÂçèËÆÆËß£Êûê                      | ‚úÖ    |
| [Á¨¨ÂçÅ‰∏ÄÁ´† Agentic-RL](./docs/chapter11/Á¨¨ÂçÅ‰∏ÄÁ´†%20Agentic-RL.md)                            | ‰ªé SFT Âà∞ GRPO ÁöÑ LLM ËÆ≠ÁªÉÂÆûÊàò                | ‚úÖ    |
| [Á¨¨ÂçÅ‰∫åÁ´† Êô∫ËÉΩ‰ΩìÊÄßËÉΩËØÑ‰º∞](./docs/chapter12/Á¨¨ÂçÅ‰∫åÁ´†%20Êô∫ËÉΩ‰ΩìÊÄßËÉΩËØÑ‰º∞.md)                    | Ê†∏ÂøÉÊåáÊ†á„ÄÅÂü∫ÂáÜÊµãËØï‰∏éËØÑ‰º∞Ê°ÜÊû∂                  | ‚úÖ    |
| &lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;                                                     |                                               |      |
| [Á¨¨ÂçÅ‰∏âÁ´† Êô∫ËÉΩÊóÖË°åÂä©Êâã](./docs/chapter13/Á¨¨ÂçÅ‰∏âÁ´†%20Êô∫ËÉΩÊóÖË°åÂä©Êâã.md)                        | MCP ‰∏éÂ§öÊô∫ËÉΩ‰ΩìÂçè‰ΩúÁöÑÁúüÂÆû‰∏ñÁïåÂ∫îÁî®              | ‚úÖ    |
| [Á¨¨ÂçÅÂõõÁ´† Ëá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰Ωì](./docs/chapter14/Á¨¨ÂçÅÂõõÁ´†%20Ëá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰Ωì.md)        | DeepResearch Agent Â§çÁé∞‰∏éËß£Êûê                 | ‚úÖ    |
| [Á¨¨ÂçÅ‰∫îÁ´† ÊûÑÂª∫ËµõÂçöÂ∞èÈïá](./docs/chapter15/Á¨¨ÂçÅ‰∫îÁ´†%20ÊûÑÂª∫ËµõÂçöÂ∞èÈïá.md)                        | Agent ‰∏éÊ∏∏ÊàèÁöÑÁªìÂêàÔºåÊ®°ÊãüÁ§æ‰ºöÂä®ÊÄÅ              | ‚úÖ    |
| &lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;                                               |                                               |      |
| [Á¨¨ÂçÅÂÖ≠Á´† ÊØï‰∏öËÆæËÆ°](./docs/chapter16/Á¨¨ÂçÅÂÖ≠Á´†%20ÊØï‰∏öËÆæËÆ°.md)                                | ÊûÑÂª∫Â±û‰∫é‰Ω†ÁöÑÂÆåÊï¥Â§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®                  | ‚úÖ    |

### Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ (Community Blog)

&amp;emsp;&amp;emsp;Ê¨¢ËøéÂ§ßÂÆ∂Â∞ÜÂú®Â≠¶‰π† Hello-Agents Êàñ Agent Áõ∏ÂÖ≥ÊäÄÊúØ‰∏≠ÁöÑÁã¨Âà∞ËßÅËß£„ÄÅÂÆûË∑µÊÄªÁªìÔºå‰ª• PR ÁöÑÂΩ¢ÂºèË¥°ÁåÆÂà∞Á§æÂå∫Á≤æÈÄâ„ÄÇÂ¶ÇÊûúÊòØÁã¨Á´ã‰∫éÊ≠£ÊñáÁöÑÂÜÖÂÆπÔºå‰πüÂèØ‰ª•ÊäïÁ®øËá≥ Extra-ChapterÔºÅ&lt;strong&gt;ÊúüÂæÖ‰Ω†ÁöÑÁ¨¨‰∏ÄÊ¨°Ë¥°ÁåÆÔºÅ&lt;/strong&gt;

| Á§æÂå∫Á≤æÈÄâ                                                                                                                                      | ÂÜÖÂÆπÊÄªÁªì                  |
| --------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------- |
| [00-ÂÖ±ÂàõÊØï‰∏öËÆæËÆ°](https://github.com/datawhalechina/hello-agents/blob/main/Co-creation-projects)                                             | Á§æÂå∫ÂÖ±ÂàõÊØï‰∏öËÆæËÆ°È°πÁõÆ      |
| [01-AgentÈù¢ËØïÈ¢òÊÄªÁªì](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra01-Èù¢ËØïÈóÆÈ¢òÊÄªÁªì.md)                          | Agent Â≤ó‰ΩçÁõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢ò    |
| [01-AgentÈù¢ËØïÈ¢òÁ≠îÊ°à](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra01-ÂèÇËÄÉÁ≠îÊ°à.md)                              | Áõ∏ÂÖ≥Èù¢ËØïÈóÆÈ¢òÁ≠îÊ°à          |
| [02-‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπË°•ÂÖÖ](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra02-‰∏ä‰∏ãÊñáÂ∑•Á®ãË°•ÂÖÖÁü•ËØÜ.md)                 | ‰∏ä‰∏ãÊñáÂ∑•Á®ãÂÜÖÂÆπÊâ©Â±ï        |
| [03-DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra03-DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊìç‰ΩúÊµÅÁ®ã.md) | DifyÊô∫ËÉΩ‰ΩìÂàõÂª∫‰øùÂßÜÁ∫ßÊïôÁ®ã  |
| [04-Hello-agentsËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra04-DatawhaleFAQ.md)                 | DatawhaleËØæÁ®ãÂ∏∏ËßÅÈóÆÈ¢ò     |
| [05-Agent Skills‰∏éMCPÂØπÊØîËß£ËØª](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra05-AgentSkillsËß£ËØª.md)             | Agent Skills‰∏éMCPÊäÄÊúØÂØπÊØî |
| [06-GUI AgentÁßëÊôÆ‰∏éÂÆûÊàò](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra06-GUIAgentÁßëÊôÆ‰∏éÂÆûÊàò.md)                | GUI AgentÁßëÊôÆ‰∏éÂ§öÂú∫ÊôØÂÆûÊàò |
| [07-ÁéØÂ¢ÉÈÖçÁΩÆ](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra07-ÁéØÂ¢ÉÈÖçÁΩÆ.md)                | ÁéØÂ¢ÉÈÖçÁΩÆ |
| [08-Â¶Ç‰ΩïÂÜôÂá∫Â•ΩÁöÑSkill](https://github.com/datawhalechina/hello-agents/blob/main/Extra-Chapter/Extra08-Â¶Ç‰ΩïÂÜôÂá∫Â•ΩÁöÑSkill.md) | Skill ÂÜô‰ΩúÊúÄ‰Ω≥ÂÆûË∑µ |

### PDF ÁâàÊú¨‰∏ãËΩΩ

&amp;emsp;&amp;emsp;*&lt;strong&gt;Êú¨ Hello-Agents PDF ÊïôÁ®ãÂÆåÂÖ®ÂºÄÊ∫êÂÖçË¥π„ÄÇ‰∏∫Èò≤Ê≠¢ÂêÑÁ±ªËê•ÈîÄÂè∑Âä†Ê∞¥Âç∞ÂêéË¥©ÂçñÁªôÂ§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÂàùÂ≠¶ËÄÖÔºåÊàë‰ª¨ÁâπÂú∞Âú® PDF Êñá‰ª∂‰∏≠È¢ÑÂÖàÊ∑ªÂä†‰∫Ü‰∏çÂΩ±ÂìçÈòÖËØªÁöÑ Datawhale ÂºÄÊ∫êÊ†áÂøóÊ∞¥Âç∞ÔºåÊï¨ËØ∑Ë∞ÖËß£ÔΩû&lt;/strong&gt;*

&gt; *Hello-Agents PDF : https://github.com/datawhalechina/hello-agents/releases/tag/V1.0.0*  
&gt; *Hello-Agents PDF ÂõΩÂÜÖ‰∏ãËΩΩÂú∞ÂùÄ : https://www.datawhale.cn/learn/summary/239* 

## üí° Â¶Ç‰ΩïÂ≠¶‰π†

&amp;emsp;&amp;emsp;Ê¨¢Ëøé‰Ω†ÔºåÊú™Êù•ÁöÑÊô∫ËÉΩÁ≥ªÁªüÊûÑÂª∫ËÄÖÔºÅÂú®ÂºÄÂêØËøôÊÆµÊøÄÂä®‰∫∫ÂøÉÁöÑÊóÖÁ®ã‰πãÂâçÔºåËØ∑ÂÖÅËÆ∏Êàë‰ª¨Áªô‰Ω†‰∏Ä‰∫õÊ∏ÖÊô∞ÁöÑÊåáÂºï„ÄÇ

&amp;emsp;&amp;emsp;Êú¨È°πÁõÆÂÜÖÂÆπÂÖºÈ°æÁêÜËÆ∫‰∏éÂÆûÊàòÔºåÊó®Âú®Â∏ÆÂä©‰Ω†Á≥ªÁªüÊÄßÂú∞ÊéåÊè°‰ªéÂçï‰∏™Êô∫ËÉΩ‰ΩìÂà∞Â§öÊô∫ËÉΩ‰ΩìÁ≥ªÁªüÁöÑËÆæËÆ°‰∏éÂºÄÂèëÂÖ®ÊµÅÁ®ã„ÄÇÂõ†Ê≠§ÔºåÂ∞§ÂÖ∂ÈÄÇÂêàÊúâ‰∏ÄÂÆöÁºñÁ®ãÂü∫Á°ÄÁöÑ &lt;strong&gt;AI ÂºÄÂèëËÄÖ„ÄÅËΩØ‰ª∂Â∑•Á®ãÂ∏à„ÄÅÂú®Ê†°Â≠¶Áîü&lt;/strong&gt; ‰ª•ÂèäÂØπÂâçÊ≤ø AI ÊäÄÊúØÊä±ÊúâÊµìÂéöÂÖ¥Ë∂£ÁöÑ &lt;strong&gt;Ëá™Â≠¶ËÄÖ&lt;/strong&gt;„ÄÇÂú®Â≠¶‰π†Êú¨È°πÁõÆ‰πãÂâçÔºåÊàë‰ª¨Â∏åÊúõ‰Ω†ÂÖ∑Â§áÂü∫Á°ÄÁöÑ Python ÁºñÁ®ãËÉΩÂäõÔºåÂπ∂ÂØπÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊúâÂü∫Êú¨ÁöÑÊ¶ÇÂøµÊÄß‰∫ÜËß£Ôºà‰æãÂ¶ÇÔºåÁü•ÈÅìÂ¶Ç‰ΩïÈÄöËøá API Ë∞ÉÁî®‰∏Ä‰∏™ LLMÔºâ„ÄÇÈ°πÁõÆÁöÑÈáçÁÇπÊòØÂ∫îÁî®‰∏éÊûÑÂª∫ÔºåÂõ†Ê≠§‰Ω†Êó†ÈúÄÂÖ∑Â§áÊ∑±ÂéöÁöÑÁÆóÊ≥ïÊàñÊ®°ÂûãËÆ≠ÁªÉËÉåÊôØ„ÄÇ

&amp;emsp;&amp;emsp;È°πÁõÆÂàÜ‰∏∫‰∫îÂ§ßÈÉ®ÂàÜÔºåÊØè‰∏ÄÈÉ®ÂàÜÈÉΩÊòØÈÄöÂæÄ‰∏ã‰∏ÄÈò∂ÊÆµÁöÑÂùöÂÆûÈò∂Ê¢ØÔºö

- &lt;strong&gt;Á¨¨‰∏ÄÈÉ®ÂàÜÔºöÊô∫ËÉΩ‰Ωì‰∏éËØ≠Ë®ÄÊ®°ÂûãÂü∫Á°Ä&lt;/strong&gt;ÔºàÁ¨¨‰∏ÄÁ´†ÔΩûÁ¨¨‰∏âÁ´†ÔºâÔºåÊàë‰ª¨Â∞Ü‰ªéÊô∫ËÉΩ‰ΩìÁöÑÂÆö‰πâ„ÄÅÁ±ªÂûã‰∏éÂèëÂ±ïÂéÜÂè≤ËÆ≤Ëµ∑Ôºå‰∏∫‰Ω†Ê¢≥ÁêÜ&quot;Êô∫ËÉΩ‰Ωì&quot;Ëøô‰∏ÄÊ¶ÇÂøµÁöÑÊù•ÈæôÂéªËÑâ„ÄÇÈöèÂêéÔºåÊàë‰ª¨‰ºöÂø´ÈÄüÂ∑©Âõ∫Â§ßËØ≠Ë®ÄÊ®°ÂûãÁöÑÊ†∏ÂøÉÁü•ËØÜÔºå‰∏∫‰Ω†ÁöÑÂÆûË∑µ‰πãÊóÖÊâì‰∏ãÂùöÂÆûÁöÑÁêÜËÆ∫Âú∞Âü∫„ÄÇ

- &lt;strong&gt;Á¨¨‰∫åÈÉ®ÂàÜÔºöÊûÑÂª∫‰Ω†ÁöÑÂ§ßËØ≠Ë®ÄÊ®°ÂûãÊô∫ËÉΩ‰Ωì&lt;/strong&gt;ÔºàÁ¨¨ÂõõÁ´†ÔΩûÁ¨¨‰∏ÉÁ´†ÔºâÔºåËøôÊòØ‰Ω†Âä®ÊâãÂÆûË∑µÁöÑËµ∑ÁÇπ„ÄÇ‰Ω†Â∞Ü‰∫≤ÊâãÂÆûÁé∞ ReAct Á≠âÁªèÂÖ∏ËåÉÂºèÔºå‰ΩìÈ™å Coze Á≠â‰Ωé‰ª£Á†ÅÂπ≥Âè∞ÁöÑ‰æøÊç∑ÔºåÂπ∂ÊéåÊè° Langgraph Á≠â‰∏ªÊµÅÊ°ÜÊû∂ÁöÑÂ∫îÁî®„ÄÇÊúÄÁªàÔºåÊàë‰ª¨Ëøò‰ºöÂ∏¶‰Ω†‰ªéÈõ∂ÂºÄÂßãÊûÑÂª∫‰∏Ä‰∏™Â±û‰∫éËá™Â∑±ÁöÑÊô∫ËÉΩ‰ΩìÊ°ÜÊû∂ÔºåËÆ©‰Ω†ÂÖºÂÖ∑‚ÄúÁî®ËΩÆÂ≠ê‚Äù‰∏é‚ÄúÈÄ†ËΩÆÂ≠ê‚ÄùÁöÑËÉΩÂäõ„ÄÇ

- &lt;strong&gt;Á¨¨‰∏âÈÉ®ÂàÜÔºöÈ´òÁ∫ßÁü•ËØÜÊâ©Â±ï&lt;/strong&gt;ÔºàÁ¨¨ÂÖ´Á´†ÔΩûÁ¨¨ÂçÅ‰∫åÁ´†ÔºâÔºåÂú®Ëøô‰∏ÄÈÉ®ÂàÜÔºå‰Ω†ÁöÑÊô∫ËÉΩ‰ΩìÂ∞Ü‚ÄúÂ≠¶‰ºö‚ÄùÊÄùËÄÉ‰∏éÂçè‰Ωú„ÄÇÊàë‰ª¨Â∞Ü‰ΩøÁî®Á¨¨‰∫åÈÉ®ÂàÜÁöÑËá™Á†îÊ°ÜÊû∂ÔºåÊ∑±ÂÖ•Êé¢Á¥¢ËÆ∞ÂøÜ‰∏éÊ£ÄÁ¥¢„ÄÅ‰∏ä‰∏ãÊñáÂ∑•Á®ã„ÄÅAgent ËÆ≠ÁªÉÁ≠âÊ†∏ÂøÉÊäÄÊúØÔºåÂπ∂Â≠¶‰π†Â§öÊô∫ËÉΩ‰ΩìÈó¥ÁöÑÈÄö‰ø°ÂçèËÆÆ„ÄÇÊúÄÁªàÔºå‰Ω†Â∞ÜÊéåÊè°ËØÑ‰º∞Êô∫ËÉΩ‰ΩìÁ≥ªÁªüÊÄßËÉΩÁöÑ‰∏ì‰∏öÊñπÊ≥ï„ÄÇ

- &lt;strong&gt;Á¨¨ÂõõÈÉ®ÂàÜÔºöÁªºÂêàÊ°à‰æãËøõÈò∂&lt;/strong&gt;ÔºàÁ¨¨ÂçÅ‰∏âÁ´†ÔΩûÁ¨¨ÂçÅ‰∫îÁ´†ÔºâÔºåËøôÈáåÊòØÁêÜËÆ∫‰∏éÂÆûË∑µÁöÑ‰∫§Ê±áÁÇπ„ÄÇ‰Ω†Â∞ÜÊääÊâÄÂ≠¶Ëûç‰ºöË¥ØÈÄöÔºå‰∫≤ÊâãÊâìÈÄ†Êô∫ËÉΩÊóÖË°åÂä©Êâã„ÄÅËá™Âä®ÂåñÊ∑±Â∫¶Á†îÁ©∂Êô∫ËÉΩ‰ΩìÔºå‰πÉËá≥‰∏Ä‰∏™Ê®°ÊãüÁ§æ‰ºöÂä®ÊÄÅÁöÑËµõÂçöÂ∞èÈïáÔºåÂú®ÁúüÂÆûÊúâË∂£ÁöÑÈ°πÁõÆ‰∏≠Ê∑¨ÁÇº‰Ω†ÁöÑÊûÑÂª∫ËÉΩÂäõ„ÄÇ

- &lt;strong&gt;Á¨¨‰∫îÈÉ®ÂàÜÔºöÊØï‰∏öËÆæËÆ°ÂèäÊú™Êù•Â±ïÊúõ&lt;/strong&gt;ÔºàÁ¨¨ÂçÅÂÖ≠Á´†ÔºâÔºåÂú®ÊóÖÁ®ãÁöÑÁªàÁÇπÔºå‰Ω†Â∞ÜËøéÊù•‰∏Ä‰∏™ÊØï‰∏öËÆæËÆ°ÔºåÊûÑÂª∫‰∏Ä‰∏™ÂÆåÊï¥ÁöÑ„ÄÅÂ±û‰∫é‰Ω†Ëá™Â∑±ÁöÑÂ§öÊô∫ËÉΩ‰ΩìÂ∫îÁî®ÔºåÂÖ®Èù¢Ê£ÄÈ™å‰Ω†ÁöÑÂ≠¶‰π†ÊàêÊûú„ÄÇÊàë‰ª¨ËøòÂ∞Ü‰∏é‰Ω†‰∏ÄÂêåÂ±ïÊúõÊô∫ËÉΩ‰ΩìÁöÑÊú™Êù•ÔºåÊé¢Á¥¢ÊøÄÂä®‰∫∫ÂøÉÁöÑÂâçÊ≤øÊñπÂêë„ÄÇ


&amp;emsp;&amp;emsp;Êô∫ËÉΩ‰ΩìÊòØ‰∏Ä‰∏™È£ûÈÄüÂèëÂ±ï‰∏îÊûÅÂ∫¶‰æùËµñÂÆûË∑µÁöÑÈ¢ÜÂüü„ÄÇ‰∏∫‰∫ÜËé∑ÂæóÊúÄ‰Ω≥ÁöÑÂ≠¶‰π†ÊïàÊûúÔºåÊàë‰ª¨Âú®È°πÁõÆÁöÑ`code`Êñá‰ª∂Â§πÂÜÖÊèê‰æõ‰∫ÜÈÖçÂ•óÁöÑÂÖ®ÈÉ®‰ª£Á†ÅÔºåÂº∫ÁÉàÂª∫ËÆÆ‰Ω†&lt;strong&gt;Â∞ÜÁêÜËÆ∫‰∏éÂÆûË∑µÁõ∏ÁªìÂêà&lt;/strong&gt;„ÄÇËØ∑Âä°ÂøÖ‰∫≤ÊâãËøêË°å„ÄÅË∞ÉËØïÁîöËá≥‰øÆÊîπÈ°πÁõÆÈáåÊèê‰æõÁöÑÊØè‰∏Ä‰ªΩ‰ª£Á†Å„ÄÇÊ¨¢Ëøé‰Ω†ÈöèÊó∂ÂÖ≥Ê≥® Datawhale ‰ª•ÂèäÂÖ∂‰ªñ Agent Áõ∏ÂÖ≥Á§æÂå∫ÔºåÂΩìÈÅáÂà∞ÈóÆÈ¢òÊó∂Ôºå‰Ω†ÂèØ‰ª•ÈöèÊó∂Âú®Êú¨È°πÁõÆÁöÑ issue Âå∫ÊèêÈóÆ„ÄÇ

&amp;emsp;&amp;emsp;Áé∞Âú®ÔºåÂáÜÂ§áÂ•ΩËøõÂÖ•Êô∫ËÉΩ‰ΩìÁöÑÂ•áÂ¶ô‰∏ñÁïå‰∫ÜÂêóÔºüËÆ©Êàë‰ª¨Âç≥ÂàªÂêØÁ®ãÔºÅ

## ‰∏ã‰∏ÄÊ≠•ËßÑÂàí

- ËßÜÈ¢ëËØæÁ®ãÈôÜÁª≠ÊîæÂá∫ÔºàÂ∞Ü‰ºöÊõ¥Âä†ÁªÜËá¥ÔºåÂÆûË∑µËØæÂ∏¶È¢ÜÂ§ßÂÆ∂‰ªéËÆæËÆ°ÊÄùË∑ØÂà∞ÂÆûÊñΩÔºåÊéà‰∫∫‰ª•È±º‰πüÊéà‰∫∫‰ª•Ê∏îÔºâ
- ÂÆåÂñÑHelloAgentsÊ°ÜÊû∂ÔºåÂºÄÂ±ïDevÂàÜÊîØÁªßÁª≠Áª¥Êä§ÔºåÂÖºÂÆπÂ≠¶‰π†ÁâàÊú¨„ÄÇ
- ÊÑüË∞¢Â§ßÂÆ∂Âä©Âäõ2W Star! ËææÂà∞3W StarÂ∞Ü‰ºöÊõ¥Êñ∞Áª≠‰ΩúÔºå„Ää‰ªéÈõ∂ÂºÄÂßãËÆ≠ÁªÉÊô∫ËÉΩ‰Ωì„ÄãÔºåÂ∏ÆÂä©ÊØè‰∏Ä‰∏™Â≠¶‰π†ËÄÖÊéåÊè°‰ªéÈõ∂Âà∞‰∏ÄËÆ≠ÁªÉËá™ÂÆö‰πâÂú∫ÊôØÊô∫ËÉΩ‰ΩìÊ®°ÂûãÁöÑËÉΩÂäõ„ÄÇ

## ü§ù Â¶Ç‰ΩïË¥°ÁåÆ

Êàë‰ª¨ÊòØ‰∏Ä‰∏™ÂºÄÊîæÁöÑÂºÄÊ∫êÁ§æÂå∫ÔºåÊ¨¢Ëøé‰ªª‰ΩïÂΩ¢ÂºèÁöÑË¥°ÁåÆÔºÅ

- üêõ &lt;strong&gt;Êä•Âëä Bug&lt;/strong&gt; - ÂèëÁé∞ÂÜÖÂÆπÊàñ‰ª£Á†ÅÈóÆÈ¢òÔºåËØ∑Êèê‰∫§ Issue
- üí° &lt;strong&gt;ÊèêÂá∫Âª∫ËÆÆ&lt;/strong&gt; - ÂØπÈ°πÁõÆÊúâÂ•ΩÊÉ≥Ê≥ïÔºåÊ¨¢ËøéÂèëËµ∑ËÆ®ËÆ∫
- üìù &lt;strong&gt;ÂÆåÂñÑÂÜÖÂÆπ&lt;/strong&gt; - Â∏ÆÂä©ÊîπËøõÊïôÁ®ãÔºåÊèê‰∫§‰Ω†ÁöÑ Pull Request
- ‚úçÔ∏è &lt;strong&gt;ÂàÜ‰∫´ÂÆûË∑µ&lt;/strong&gt; - Âú®&quot;Á§æÂå∫Ë¥°ÁåÆÁ≤æÈÄâ&quot;‰∏≠ÂàÜ‰∫´‰Ω†ÁöÑÂ≠¶‰π†Á¨îËÆ∞ÂíåÈ°πÁõÆ

## üôè Ëá¥Ë∞¢

### Ê†∏ÂøÉË¥°ÁåÆËÄÖ
- [ÈôàÊÄùÂ∑û-È°πÁõÆË¥üË¥£‰∫∫](https://github.com/jjyaoao) (Datawhale ÊàêÂëò, ÂÖ®ÊñáÂÜô‰ΩúÂíåÊ†°ÂØπ)
- [Â≠ôÈü¨-ËÅîÂêàÂèëËµ∑ËÄÖ](https://github.com/fengju0213) (Datawhale ÊàêÂëò„ÄÅCAMEL-AI, Á¨¨‰πùÁ´†ÂÜÖÂÆπÂíåÊ†°ÂØπ)  
- [ÂßúËàíÂá°-ËÅîÂêàÂèëËµ∑ËÄÖ](https://github.com/Tsumugii24)ÔºàDatawhale ÊàêÂëò, Á´†ËäÇ‰π†È¢òËÆæËÆ°ÂíåÊ†°ÂØπÔºâ
- [ÈªÑ‰Ω©Êûó-DatawhaleÊÑèÂêëÊàêÂëò](https://github.com/HeteroCat) (Agent ÂºÄÂèëÂ∑•Á®ãÂ∏à, Á¨¨‰∫îÁ´†ÂÜÖÂÆπË¥°ÁåÆËÄÖ)
- [ÊõæÈë´Ê∞ë-AgentÂ∑•Á®ãÂ∏à](https://github.com/fancyboi999) (ÁâõÂÆ¢ÁßëÊäÄ, Á¨¨ÂçÅÂõõÁ´†Ê°à‰æãÂºÄÂèë)
- [Êú±‰ø°Âø†-ÊåáÂØº‰∏ìÂÆ∂](https://xinzhongzhu.github.io/) (DatawhaleÈ¶ñÂ∏≠ÁßëÂ≠¶ÂÆ∂-ÊµôÊ±üÂ∏àËåÉÂ§ßÂ≠¶Êù≠Â∑û‰∫∫Â∑•Êô∫ËÉΩÁ†îÁ©∂Èô¢ÊïôÊéà)
### Extra-Chapter Ë¥°ÁåÆËÄÖ
- [WH](https://github.com/WHQAQ11) (ÂÜÖÂÆπË¥°ÁåÆËÄÖ)
- [Âë®Â••Êù∞-DWË¥°ÁåÆËÄÖÂõ¢Èòü](https://github.com/thunderbolt-fire) (Ë•øÂÆâ‰∫§ÈÄöÂ§ßÂ≠¶, Extra02 ÂÜÖÂÆπË¥°ÁåÆ)
- [Âº†ÂÆ∏Êó≠-‰∏™‰∫∫ÂºÄÂèëËÄÖ](https://github.com/Tasselszcx)(Â∏ùÂõΩÁêÜÂ∑•Â≠¶Èô¢, Extra03 ÂÜÖÂÆπË¥°ÁåÆ)
- [ÈªÑÂÆèÊôó-DWË¥°ÁåÆËÄÖÂõ¢Èòü](https://github.com/XiaoMa-PM) (Ê∑±Âú≥Â§ßÂ≠¶, Extra04 ÂÜÖÂÆπË¥°ÁåÆ)
- [ÁéãÂ§ßÈπè-DatawhaleÊàêÂëò](https://github.com/ditingdapeng) (È´òÁ∫ßÁ†îÂèëÂ∑•Á®ãÂ∏à, Extra08 ÂÜÖÂÆπË¥°ÁåÆ)

### ÁâπÂà´ÊÑüË∞¢
- ÊÑüË∞¢ [@Sm1les](https://github.com/Sm1les) ÂØπÊú¨È°πÁõÆÁöÑÂ∏ÆÂä©‰∏éÊîØÊåÅ
- ÊÑüË∞¢ÊâÄÊúâ‰∏∫Êú¨È°πÁõÆÂÅöÂá∫Ë¥°ÁåÆÁöÑÂºÄÂèëËÄÖ‰ª¨ ‚ù§Ô∏è

&lt;div align=center style=&quot;margin-top: 30px;&quot;&gt;
  &lt;a href=&quot;https://github.com/datawhalechina/Hello-Agents/graphs/contributors&quot;&gt;
    &lt;img src=&quot;https://contrib.rocks/image?repo=datawhalechina/Hello-Agents&quot; /&gt;
  &lt;/a&gt;
&lt;/div&gt;

## Star History

&lt;div align=&#039;center&#039;&gt;
    &lt;img src=&quot;./docs/images/star-history-2026210.png&quot; alt=&quot;Datawhale&quot; width=&quot;90%&quot;&gt;
&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;
  &lt;p&gt;‚≠ê Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåËØ∑ÁªôÊàë‰ª¨‰∏Ä‰∏™ StarÔºÅ&lt;/p&gt;
&lt;/div&gt;

## ËØªËÄÖ‰∫§ÊµÅÁæ§

&lt;div align=&#039;center&#039;&gt;
    &lt;img src=&quot;./ËØªËÄÖÁæ§‰∫åÁª¥Á†Å.png&quot; alt=&quot;ËØªËÄÖÁæ§‰∫åÁª¥Á†Å&quot; width=&quot;30%&quot;&gt;
    &lt;p&gt;Êâ´Êèè‰∫åÁª¥Á†ÅÂä†ÂÖ•ËØªËÄÖ‰∫§ÊµÅÁæ§Ôºå‰∏éÊõ¥Â§öÂ≠¶‰π†ËÄÖ‰∫§ÊµÅËÆ®ËÆ∫&lt;/p&gt;
&lt;/div&gt;

## ÂÖ≥‰∫é Datawhale

&lt;div align=&#039;center&#039;&gt;
    &lt;img src=&quot;./docs/images/datawhale.png&quot; alt=&quot;Datawhale&quot; width=&quot;30%&quot;&gt;
    &lt;p&gt;Êâ´Êèè‰∫åÁª¥Á†ÅÂÖ≥Ê≥® Datawhale ÂÖ¨‰ºóÂè∑ÔºåËé∑ÂèñÊõ¥Â§ö‰ºòË¥®ÂºÄÊ∫êÂÜÖÂÆπ&lt;/p&gt;
&lt;/div&gt;

---

## üìú ÂºÄÊ∫êÂçèËÆÆ

Êú¨‰ΩúÂìÅÈááÁî®[Áü•ËØÜÂÖ±‰∫´ÁΩ≤Âêç-ÈùûÂïÜ‰∏öÊÄß‰ΩøÁî®-Áõ∏ÂêåÊñπÂºèÂÖ±‰∫´ 4.0 ÂõΩÈôÖËÆ∏ÂèØÂçèËÆÆ](http://creativecommons.org/licenses/by-nc-sa/4.0/)ËøõË°åËÆ∏ÂèØ„ÄÇ
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[wagtail/wagtail]]></title>
            <link>https://github.com/wagtail/wagtail</link>
            <guid>https://github.com/wagtail/wagtail</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:33 GMT</pubDate>
            <description><![CDATA[A Django content management system focused on flexibility and user experience]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/wagtail/wagtail">wagtail/wagtail</a></h1>
            <p>A Django content management system focused on flexibility and user experience</p>
            <p>Language: Python</p>
            <p>Stars: 20,207</p>
            <p>Forks: 4,447</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;
    &lt;picture&gt;
        &lt;source media=&quot;(prefers-color-scheme: light)&quot; srcset=&quot;.github/wagtail.svg&quot;&gt;
        &lt;source media=&quot;(prefers-color-scheme: dark)&quot; srcset=&quot;.github/wagtail-inverse.svg&quot;&gt;
        &lt;img width=&quot;343&quot; src=&quot;.github/wagtail.svg&quot; alt=&quot;Wagtail&quot;&gt;
    &lt;/picture&gt;
&lt;/h1&gt;
&lt;p align=&quot;center&quot;&gt;
    &lt;br&gt;
    &lt;a href=&quot;https://github.com/wagtail/wagtail/actions&quot;&gt;
        &lt;img src=&quot;https://github.com/wagtail/wagtail/workflows/Wagtail%20CI/badge.svg&quot; alt=&quot;Build Status&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://opensource.org/licenses/BSD-3-Clause&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/badge/license-BSD-blue.svg&quot; alt=&quot;License&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://pypi.python.org/pypi/wagtail/&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/pypi/v/wagtail.svg&quot; alt=&quot;Version&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://pypi.python.org/pypi/wagtail/&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/pypi/dm/wagtail?logo=Downloads&quot; alt=&quot;Monthly downloads&quot; /&gt;
    &lt;/a&gt;
    &lt;a href=&quot;https://fosstodon.org/@wagtail&quot;&gt;
        &lt;img src=&quot;https://img.shields.io/mastodon/follow/109308882653647818?domain=https%3A%2F%2Ffosstodon.org&amp;style=social&quot; alt=&quot;Follow @wagtail@fosstodon.org&quot;&gt;
    &lt;/a&gt;
&lt;/p&gt;

Wagtail is an open source content management system built on Django, with a strong community and commercial support. It&#039;s focused on user experience, and offers precise control for designers and developers.

![Wagtail screenshot](https://cdn.jsdelivr.net/gh/wagtail/wagtail@main/.github/wagtail-screenshot-with-browser.png)

### üî• Features

-   A fast, attractive interface for authors
-   Complete control over front-end design and structure
-   Scales to millions of pages and thousands of editors
-   Fast out of the box, cache-friendly when you need it
-   Content API for &#039;headless&#039; sites with decoupled front-end
-   Runs on a Raspberry Pi or a multi-datacenter cloud platform
-   StreamField encourages flexible content without compromising structure
-   Powerful, integrated search, using Elasticsearch or PostgreSQL
-   Excellent support for images and embedded content
-   Multi-site and multi-language ready
-   Embraces and extends Django

Find out more at [wagtail.org](https://wagtail.org/).

### üëâ Getting started

Wagtail works with [Python 3](https://www.python.org/downloads/), on any platform.

To get started with using Wagtail, run the following in a [virtual environment](https://docs.python.org/3/tutorial/venv.html):

![Installing Wagtail](.github/install-animation.gif)

```sh
pip install wagtail
wagtail start mysite
cd mysite
pip install -r requirements.txt
python manage.py migrate
python manage.py createsuperuser
python manage.py runserver
```

For detailed installation and setup docs, see [the getting started tutorial](https://docs.wagtail.org/en/stable/getting_started/tutorial.html).

### üë®‚Äçüë©‚Äçüëß‚Äçüë¶ Who‚Äôs using it?

Wagtail is used by [NASA](https://www.nasa.gov/), [Google](https://www.google.com/), [Oxfam](https://www.oxfam.org/en), the [NHS](https://www.nhs.uk/), [Mozilla](https://www.mozilla.org/en-US/), [MIT](https://www.mit.edu/), the [Red Cross](https://www.icrc.org/en), [Salesforce](https://www.salesforce.com/), [NBC](https://www.nbc.com/), [BMW](https://www.bmw.com/en/index.html), and the US and UK governments. Add your own Wagtail site to [madewithwagtail.org](https://madewithwagtail.org).

### üìñ Documentation

[docs.wagtail.org](https://docs.wagtail.org/) is the full reference for Wagtail, and includes guides for developers, designers and editors, alongside [release notes](https://docs.wagtail.org/en/stable/releases/) and our [roadmap](https://wagtail.org/roadmap/).

For those who are **new to Wagtail**, the [Zen of Wagtail](https://docs.wagtail.org/en/stable/getting_started/the_zen_of_wagtail.html) will help you understand what Wagtail is, and what Wagtail is _not_.

**For developers** who are ready to jump in to their first Wagtail website the [Getting Started Tutorial](https://docs.wagtail.org/en/stable/getting_started/tutorial.html) will guide you through creating and editing your first page.

**Do you have an existing Django project?** The [Wagtail Integration documentation](https://docs.wagtail.org/en/stable/getting_started/integrating_into_django.html) is the best place to start.

### üìå Compatibility

_(If you are reading this on GitHub, the details here may not be indicative of the current released version - please see [Compatible Django / Python versions](https://docs.wagtail.org/en/stable/releases/upgrading.html#compatible-django-python-versions) in the Wagtail documentation.)_

Wagtail supports:

-   Django 5.2.x and 6.0.x
-   Python 3.10, 3.11, 3.12, 3.13, and 3.14
-   PostgreSQL, MySQL, MariaDB and SQLite (with JSON1) as database backends

[Previous versions of Wagtail](https://docs.wagtail.org/en/stable/releases/upgrading.html#compatible-django-python-versions) additionally supported Python 2.7, 3.8 and earlier Django versions.

---

### üì¢ Community Support

There is an active community of Wagtail users and developers responding to questions on [Stack Overflow](https://stackoverflow.com/questions/tagged/wagtail). When posting questions, please read Stack Overflow&#039;s advice on [how to ask questions](https://stackoverflow.com/help/how-to-ask) and remember to tag your question &quot;wagtail&quot;.

For topics and discussions that do not fit Stack Overflow&#039;s question and answer format we have a [Slack workspace](https://github.com/wagtail/wagtail/wiki/Slack). Please respect the time and effort of volunteers by not asking the same question in multiple places.

[![Join slack community](.github/join-slack-community.png)](https://github.com/wagtail/wagtail/wiki/Slack)

Our [GitHub discussion boards](https://github.com/wagtail/wagtail/discussions) are open for sharing ideas and plans for the Wagtail project.

We maintain a curated list of third party packages, articles and other resources at [Awesome Wagtail](https://github.com/springload/awesome-wagtail).

### üßë‚Äçüíº Commercial Support

Wagtail is sponsored by [Torchbox](https://torchbox.com/). If you need help implementing or hosting Wagtail, please contact us: hello@torchbox.com. See also [madewithwagtail.org/developers/](https://madewithwagtail.org/developers/) for expert Wagtail developers around the world.

### üîê Security

We take the security of Wagtail, and related packages we maintain, seriously. If you have found a security issue with any of our projects please email us at [security@wagtail.org](mailto:security@wagtail.org) so we can work together to find and patch the issue. We appreciate responsible disclosure with any security related issues, so please contact us first before creating a GitHub issue.

If you want to send an encrypted email (optional), the public key ID for security@wagtail.org is 0xbed227b4daf93ff9, and this public key is available from most commonly-used keyservers.

### üïí Release schedule

Feature releases of Wagtail are released every three months. Selected releases are designated as Long Term Support (LTS) releases, and will receive maintenance updates for an extended period to address any security and data-loss related issues. For dates of past and upcoming releases and support periods, see [Release Schedule](https://github.com/wagtail/wagtail/wiki/Release-schedule).

#### üïõ Nightly releases

To try out the latest features before a release, we also create builds from `main` every night. You can find instructions on how to install the latest nightly release at https://releases.wagtail.org/nightly/index.html

### üôãüèΩ Contributing

If you&#039;re a Python or Django developer, fork the repo and get stuck in! We have several developer focused channels on the [Slack workspace](https://github.com/wagtail/wagtail/wiki/Slack).

You might like to start by reviewing the [contributing guidelines](https://docs.wagtail.org/en/latest/contributing/index.html) and checking issues with the [good first issue](https://github.com/wagtail/wagtail/labels/good%20first%20issue) label.

We also welcome translations for Wagtail&#039;s interface. Translation work should be submitted through [Transifex](https://explore.transifex.com/torchbox/wagtail/).

### üîì License

[BSD](https://github.com/wagtail/wagtail/blob/main/LICENSE) - Free to use and modify for any purpose, including both open and closed-source code.

### üëè Thanks

We thank the following organisations for their services used in Wagtail&#039;s development:

[![Browserstack](https://cdn.jsdelivr.net/gh/wagtail/wagtail@main/.github/browserstack-logo.svg)](https://www.browserstack.com/)&lt;br&gt;
[BrowserStack](https://www.browserstack.com/) provides the project with free access to their live web-based browser testing tool, and automated Selenium cloud testing.

[![Assistiv Labs](https://cdn.jsdelivr.net/gh/wagtail/wagtail@main/.github/assistivlabs-logo.png)](https://assistivlabs.com/)&lt;br&gt;
[Assistiv Labs](https://assistivlabs.com/) provides the project with unlimited access to their remote testing with assistive technologies.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[Netflix/metaflow]]></title>
            <link>https://github.com/Netflix/metaflow</link>
            <guid>https://github.com/Netflix/metaflow</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:32 GMT</pubDate>
            <description><![CDATA[Build, Manage and Deploy AI/ML Systems]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/Netflix/metaflow">Netflix/metaflow</a></h1>
            <p>Build, Manage and Deploy AI/ML Systems</p>
            <p>Language: Python</p>
            <p>Stars: 9,840</p>
            <p>Forks: 1,062</p>
            <p>Stars today: 22 stars today</p>
            <h2>README</h2><pre>![Metaflow_Logo_Horizontal_FullColor_Ribbon_Dark_RGB](https://user-images.githubusercontent.com/763451/89453116-96a57e00-d713-11ea-9fa6-82b29d4d6eff.png)

# Metaflow

[Metaflow](https://metaflow.org) is a human-centric framework designed to help scientists and engineers **build and manage real-life AI and ML systems**. Serving teams of all sizes and scale, Metaflow streamlines the entire development lifecycle‚Äîfrom rapid prototyping in notebooks to reliable, maintainable production deployments‚Äîenabling teams to iterate quickly and deliver robust systems efficiently.

Originally developed at [Netflix](https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9) and now supported by [Outerbounds](https://outerbounds.com), Metaflow is designed to boost the productivity for research and engineering teams working on [a wide variety of projects](https://netflixtechblog.com/supporting-diverse-ml-systems-at-netflix-2d2e6b6d205d), from classical statistics to state-of-the-art deep learning and foundation models. By unifying code, data, and compute at every stage, Metaflow ensures seamless, end-to-end management of real-world AI and ML systems.

Today, Metaflow powers thousands of AI and ML experiences across a diverse array of companies, large and small, including Amazon, Doordash, Dyson, Goldman Sachs, Ramp, and [many others](ADOPTERS.md). At Netflix alone, Metaflow supports over 3000 AI and ML projects, executes hundreds of millions of data-intensive high-performance compute jobs processing petabytes of data and manages tens of petabytes of models and artifacts for hundreds of users across its AI, ML, data science, and engineering teams.

## From prototype to production (and back)

Metaflow provides a simple and friendly pythonic [API](https://docs.metaflow.org) that covers foundational needs of AI and ML systems:
&lt;img src=&quot;./docs/prototype-to-prod.png&quot; width=&quot;800px&quot;&gt;

1. [Rapid local prototyping](https://docs.metaflow.org/metaflow/basics), [support for notebooks](https://docs.metaflow.org/metaflow/managing-flows/notebook-runs), and built-in support for [experiment tracking, versioning](https://docs.metaflow.org/metaflow/client) and [visualization](https://docs.metaflow.org/metaflow/visualizing-results).
2. [Effortlessly scale horizontally and vertically in your cloud](https://docs.metaflow.org/scaling/remote-tasks/introduction), utilizing both CPUs and GPUs, with [fast data access](https://docs.metaflow.org/scaling/data) for running [massive embarrassingly parallel](https://docs.metaflow.org/metaflow/basics#foreach) as well as [gang-scheduled](https://docs.metaflow.org/scaling/remote-tasks/distributed-computing) compute workloads [reliably](https://docs.metaflow.org/scaling/failures) and [efficiently](https://docs.metaflow.org/scaling/checkpoint/introduction).
3. [Easily manage dependencies](https://docs.metaflow.org/scaling/dependencies) and [deploy with one-click](https://docs.metaflow.org/production/introduction) to highly available production orchestrators with built in support for [reactive orchestration](https://docs.metaflow.org/production/event-triggering).

For full documentation, check out our [API Reference](https://docs.metaflow.org/api) or see our [Release Notes](https://github.com/Netflix/metaflow/releases) for the latest features and improvements. 


## Getting started

Getting up and running is easy. If you don&#039;t know where to start, [Metaflow sandbox](https://outerbounds.com/sandbox) will have you running and exploring in seconds.

### Installing Metaflow

To install Metaflow in your Python environment from [PyPI](https://pypi.org/project/metaflow/):

```sh
pip install metaflow
```
Alternatively, using [conda-forge](https://anaconda.org/conda-forge/metaflow):

```sh
conda install -c conda-forge metaflow
```

Once installed, a great way to get started is by following our [tutorial](https://docs.metaflow.org/getting-started/tutorials). It walks you through creating and running your first Metaflow flow step by step.  

For more details on Metaflow‚Äôs features and best practices, check out:
- [How Metaflow works](https://docs.metaflow.org/metaflow/basics)  
- [Additional resources](https://docs.metaflow.org/introduction/metaflow-resources)  

If you need help, don‚Äôt hesitate to reach out on our [Slack community](http://slack.outerbounds.co/)!


### Deploying infrastructure for Metaflow in your cloud
&lt;img src=&quot;./docs/multicloud.png&quot; width=&quot;800px&quot;&gt;


While you can get started with Metaflow easily on your laptop, the main benefits of Metaflow lie in its ability to [scale out to external compute clusters](https://docs.metaflow.org/scaling/remote-tasks/introduction) 
and to [deploy to production-grade workflow orchestrators](https://docs.metaflow.org/production/introduction). To benefit from these features, follow this [guide](https://outerbounds.com/engineering/welcome/) to 
configure Metaflow and the infrastructure behind it appropriately.


## Get in touch
We&#039;d love to hear from you. Join our community [Slack workspace](http://slack.outerbounds.co/)!

## Contributing
We welcome contributions to Metaflow. Please see our [contribution guide](https://docs.metaflow.org/introduction/contributing-to-metaflow) for more details.
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[AIDC-AI/Pixelle-Video]]></title>
            <link>https://github.com/AIDC-AI/Pixelle-Video</link>
            <guid>https://github.com/AIDC-AI/Pixelle-Video</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:31 GMT</pubDate>
            <description><![CDATA[üöÄ AI ÂÖ®Ëá™Âä®Áü≠ËßÜÈ¢ëÂºïÊìé | AI Fully Automated Short Video Engine]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/AIDC-AI/Pixelle-Video">AIDC-AI/Pixelle-Video</a></h1>
            <p>üöÄ AI ÂÖ®Ëá™Âä®Áü≠ËßÜÈ¢ëÂºïÊìé | AI Fully Automated Short Video Engine</p>
            <p>Language: Python</p>
            <p>Stars: 2,539</p>
            <p>Forks: 419</p>
            <p>Stars today: 160 stars today</p>
            <h2>README</h2><pre>&lt;h1 align=&quot;center&quot;&gt;üé¨ Pixelle-Video ‚Äî‚Äî AI ÂÖ®Ëá™Âä®Áü≠ËßÜÈ¢ëÂºïÊìé&lt;/h1&gt;

&lt;p align=&quot;center&quot;&gt;&lt;a href=&quot;README_EN.md&quot;&gt;English&lt;/a&gt; | &lt;b&gt;‰∏≠Êñá&lt;/b&gt;&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://www.bilibili.com/video/BV1WzyGBnEVp/?vd_source=e7e7d4ca8db9a18c80f17a24a6582fca&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/üé• ËßÜÈ¢ëÊïôÁ®ã-EA4C89&quot; alt=&quot;ËßÜÈ¢ëÊïôÁ®ã&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/AIDC-AI/Pixelle-Video/releases&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/üì¶ WindowsÂåÖ-50C878&quot; alt=&quot;WindowsÊï¥ÂêàÂåÖ&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://aidc-ai.github.io/Pixelle-Video/zh&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://img.shields.io/badge/üìò ‰ΩøÁî®ÊñáÊ°£-4A90E2&quot; alt=&quot;‰ΩøÁî®ÊñáÊ°£&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/AIDC-AI/Pixelle-Video/stargazers&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/stars/AIDC-AI/Pixelle-Video.svg&quot; alt=&quot;Stargazers&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/AIDC-AI/Pixelle-Video/issues&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/issues/AIDC-AI/Pixelle-Video.svg&quot; alt=&quot;Issues&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/AIDC-AI/Pixelle-Video/network/members&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/forks/AIDC-AI/Pixelle-Video.svg&quot; alt=&quot;Forks&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/AIDC-AI/Pixelle-Video/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/AIDC-AI/Pixelle-Video.svg&quot; alt=&quot;License&quot;&gt;&lt;/a&gt;
&lt;/p&gt;

https://github.com/user-attachments/assets/a42e7457-fcc8-40da-83fc-784c45a8b95d

&lt;br/&gt;

Âè™ÈúÄËæìÂÖ•‰∏Ä‰∏™ **‰∏ªÈ¢ò**ÔºåPixelle-Video Â∞±ËÉΩËá™Âä®ÂÆåÊàêÔºö
- ‚úçÔ∏è Êí∞ÂÜôËßÜÈ¢ëÊñáÊ°à  
- üé® ÁîüÊàê AI ÈÖçÂõæ/ËßÜÈ¢ë  
- üó£Ô∏è ÂêàÊàêËØ≠Èü≥Ëß£ËØ¥  
- üéµ Ê∑ªÂä†ËÉåÊôØÈü≥‰πê  
- üé¨ ‰∏ÄÈîÆÂêàÊàêËßÜÈ¢ë  

**Èõ∂Èó®ÊßõÔºåÈõ∂Ââ™ËæëÁªèÈ™å**ÔºåËÆ©ËßÜÈ¢ëÂàõ‰ΩúÊàê‰∏∫‰∏ÄÂè•ËØùÁöÑ‰∫ãÔºÅ


## üñ•Ô∏è Web ÁïåÈù¢È¢ÑËßà

![Web UIÁïåÈù¢](resources/webui.png)


## üìã ÊúÄËøëÊõ¥Êñ∞

- ‚úÖ **2026-01-26**: Êñ∞Â¢û„ÄåÂä®‰ΩúËøÅÁßª„ÄçÊ®°ÂùóÔºå‰∏ä‰º†ÂèÇËÄÉËßÜÈ¢ëÂíåÂõæÁâáËøõË°åÂä®‰ΩúËøÅÁßª
- ‚úÖ **2026-01-14**: Êñ∞Â¢û„ÄåÊï∞Â≠ó‰∫∫Âè£Êí≠„ÄçÂíå„ÄåÂõæÁîüËßÜÈ¢ë„ÄçÊµÅÊ∞¥Á∫øÔºåÊñ∞Â¢ûÂ§öËØ≠Ë®Ä TTS Èü≥Ëâ≤ÊîØÊåÅ
- ‚úÖ **2026-01-06**: Êñ∞Â¢û RunningHub 48G ÊòæÂ≠òÊú∫Âô®Ë∞ÉÁî®ÊîØÊåÅ
- ‚úÖ **2025-12-28**: ÊîØÊåÅ RunningHub Âπ∂ÂèëÈôêÂà∂ÂèØÈÖçÁΩÆÔºå‰ºòÂåñ LLM ËøîÂõûÁªìÊûÑÂåñÊï∞ÊçÆÁöÑÈÄªËæë
- ‚úÖ **2025-12-17**: ÊîØÊåÅ ComfyUI API Key ÈÖçÁΩÆÔºåÊîØÊåÅ Nano Banana Ê®°ÂûãË∞ÉÁî®ÔºåAPI Êé•Âè£ÊîØÊåÅÊ®°ÊùøËá™ÂÆö‰πâÂèÇÊï∞
- ‚úÖ **2025-12-10**: ‰æßËæπÊ†èÂÜÖÁΩÆ FAQÔºåÈîÅÂÆö edge-tts ÁâàÊú¨‰øÆÂ§ç TTS ÊúçÂä°‰∏çÁ®≥ÂÆöÈóÆÈ¢ò
- ‚úÖ **2025-12-08**: ÊîØÊåÅÂõ∫ÂÆöËÑöÊú¨Â§öÁßçÂàÜÂâ≤ÊñπÂºè(ÊÆµËêΩ/Ë°å/Âè•Â≠ê)Ôºå‰ºòÂåñÊ®°ÊùøÈÄâÊã©‰∫§‰∫íÈÄªËæëÊîØÊåÅÁõ¥Êé•È¢ÑËßàÈÄâÊã©
- ‚úÖ **2025-12-06**: ‰øÆÂ§çËßÜÈ¢ëÁîüÊàê API ËøîÂõû URL Ë∑ØÂæÑÂ§ÑÁêÜÔºåÊîØÊåÅË∑®Âπ≥Âè∞ÂÖºÂÆπ
- ‚úÖ **2025-12-05**: Êñ∞Â¢û Windows Êï¥ÂêàÂåÖ‰∏ãËΩΩÔºå‰ºòÂåñÂõæÁâá‰∏éËßÜÈ¢ëÂèçÊé®Â∑•‰ΩúÊµÅ
- ‚úÖ **2025-12-04**: Êñ∞Â¢û„ÄåËá™ÂÆö‰πâÁ¥†Êùê„ÄçÂäüËÉΩÔºåÊîØÊåÅÁî®Êà∑‰∏ä‰º†Ëá™Â∑±ÁöÑÁÖßÁâáÂíåËßÜÈ¢ëÔºåAI Êô∫ËÉΩÂàÜÊûêÁîüÊàêËÑöÊú¨
- ‚úÖ **2025-11-18**: ‰ºòÂåñ RunningHub ÊúçÂä°Ë∞ÉÁî®ÊîØÊåÅÂπ∂Ë°åÂ§ÑÁêÜÔºåÊñ∞Â¢ûÂéÜÂè≤ËÆ∞ÂΩïÈ°µÈù¢ÔºåÊîØÊåÅÊâπÈáèÂàõÂª∫ËßÜÈ¢ë‰ªªÂä°


## ‚ú® ÂäüËÉΩ‰∫ÆÁÇπ

- ‚úÖ **ÂÖ®Ëá™Âä®ÁîüÊàê** - ËæìÂÖ•‰∏ªÈ¢òÔºåËá™Âä®ÁîüÊàêÂÆåÊï¥ËßÜÈ¢ë
- ‚úÖ **AI Êô∫ËÉΩÊñáÊ°à** - Ê†πÊçÆ‰∏ªÈ¢òÊô∫ËÉΩÂàõ‰ΩúËß£ËØ¥ËØçÔºåÊó†ÈúÄËá™Â∑±ÂÜôËÑöÊú¨
- ‚úÖ **AI ÁîüÊàêÈÖçÂõæ** - ÊØèÂè•ËØùÈÉΩÈÖç‰∏äÁ≤æÁæéÁöÑ AI ÊèíÂõæ
- ‚úÖ **AI ÁîüÊàêËßÜÈ¢ë** - ÊîØÊåÅ‰ΩøÁî® AI ËßÜÈ¢ëÁîüÊàêÊ®°ÂûãÔºàÂ¶Ç WAN 2.1ÔºâÂàõÂª∫Âä®ÊÄÅËßÜÈ¢ëÂÜÖÂÆπ
- ‚úÖ **AI ÁîüÊàêËØ≠Èü≥** - ÊîØÊåÅ Edge-TTS„ÄÅIndex-TTS Á≠â‰ºóÂ§ö‰∏ªÊµÅ TTS ÊñπÊ°à
- ‚úÖ **ËÉåÊôØÈü≥‰πê** - ÊîØÊåÅÊ∑ªÂä† BGMÔºåËÆ©ËßÜÈ¢ëÊõ¥ÊúâÊ∞õÂõ¥
- ‚úÖ **ËßÜËßâÈ£éÊ†º** - Â§öÁßçÊ®°ÊùøÂèØÈÄâÔºåÊâìÈÄ†Áã¨ÁâπËßÜÈ¢ëÈ£éÊ†º
- ‚úÖ **ÁÅµÊ¥ªÂ∞∫ÂØ∏** - ÊîØÊåÅÁ´ñÂ±è„ÄÅÊ®™Â±èÁ≠âÂ§öÁßçËßÜÈ¢ëÂ∞∫ÂØ∏
- ‚úÖ **Â§öÁßç AI Ê®°Âûã** - ÊîØÊåÅ GPT„ÄÅÈÄö‰πâÂçÉÈóÆ„ÄÅDeepSeek„ÄÅOllama Á≠â
- ‚úÖ **ÂéüÂ≠êËÉΩÂäõÁÅµÊ¥ªÁªÑÂêà** - Âü∫‰∫é ComfyUI Êû∂ÊûÑÔºåÂèØ‰ΩøÁî®È¢ÑÁΩÆÂ∑•‰ΩúÊµÅÔºå‰πüÂèØËá™ÂÆö‰πâ‰ªªÊÑèËÉΩÂäõÔºàÂ¶ÇÊõøÊç¢ÁîüÂõæÊ®°Âûã‰∏∫ FLUX„ÄÅÊõøÊç¢ TTS ‰∏∫ ChatTTS Á≠âÔºâ


## üìä ËßÜÈ¢ëÁîüÊàêÊµÅÁ®ã

Pixelle-Video ÈááÁî®Ê®°ÂùóÂåñËÆæËÆ°ÔºåÊï¥‰∏™ËßÜÈ¢ëÁîüÊàêÊµÅÁ®ãÊ∏ÖÊô∞ÁÆÄÊ¥ÅÔºö

![ËßÜÈ¢ëÁîüÊàêÊµÅÁ®ãÂõæ](resources/flow.png)

‰ªéËæìÂÖ•ÊñáÊú¨Âà∞ÊúÄÁªàËßÜÈ¢ëËæìÂá∫ÔºåÊï¥‰∏™ÊµÅÁ®ãÁÆÄÊ¥ÅÊ∏ÖÊô∞Ôºö**ÊñáÊ°àÁîüÊàê ‚Üí ÈÖçÂõæËßÑÂàí ‚Üí ÈÄêÂ∏ßÂ§ÑÁêÜ ‚Üí ËßÜÈ¢ëÂêàÊàê**

ÊØè‰∏™ÁéØËäÇÈÉΩÊîØÊåÅÁÅµÊ¥ªÂÆöÂà∂ÔºåÂèØÈÄâÊã©‰∏çÂêåÁöÑ AI Ê®°Âûã„ÄÅÈü≥È¢ëÂºïÊìé„ÄÅËßÜËßâÈ£éÊ†ºÁ≠âÔºåÊª°Ë∂≥‰∏™ÊÄßÂåñÂàõ‰ΩúÈúÄÊ±Ç„ÄÇ


## üé¨ ËßÜÈ¢ëÁ§∫‰æã

‰ª•‰∏ãÊòØ‰ΩøÁî® Pixelle-Video ÁîüÊàêÁöÑÂÆûÈôÖÊ°à‰æãÔºåÂ±ïÁ§∫‰∫Ü‰∏çÂêå‰∏ªÈ¢òÂíåÈ£éÊ†ºÁöÑËßÜÈ¢ëÊïàÊûúÔºö

### üì± Êâ©Â±ïÊ®°ÂùóËßÜÈ¢ëÂ±ïÁ§∫

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üë§ Êï∞Â≠ó‰∫∫Âè£Êí≠&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/7c122563-c2e0-4dcd-a73c-25ba1d4fa2dd&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Èü©ËØ≠Êï∞Â≠ó‰∫∫Âè£Êí≠&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üñºÔ∏è ÂõæÁîüËßÜÈ¢ë&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/5b4eef17-07d0-4bde-9748-2ed68cc9888e&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Âç°ÈÄöËßÜÈ¢ë&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üíÉ Âä®‰ΩúËøÅÁßª&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/7b1240bc-e965-434c-b343-118ec4793d4f&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Ë∑≥ËàûÂ∞èÁå´&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;


### üì± Á´ñÂ±èËßÜÈ¢ëÂ±ïÁ§∫

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üåÑ ‰∫∫ÊñáÁ∫™ÂÆûÁ±ª - ËßÜÈ¢ëÈªòËÆ§Ê®°Áâà&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/e6716c1d-78de-453d-84c2-10873c8c595f&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;ÊóÖË°åË∑Ø‰∏äÁöÑÈ£éÊôØËÆ©‰∫∫ÊµÅËøûÂøòËøî&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üîç ÊñáÂåñËß£ÊûÑÁ±ª - ËßÜÈ¢ëÈªòËÆ§Ê®°Áâà&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/f5de75f6-135a-4ab4-9f5f-079f649764d5&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Santa ID&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üî≠ ÁßëÂ≠¶ÊÄùËæ®Á±ª - ËßÜÈ¢ëÈªòËÆ§Ê®°Áâà&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/ceb8b0df-8331-4e1f-88e7-db5b295a1c1d&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;‰∏∫‰ªÄ‰πàÊàë‰ª¨ËøòÊ≤°ÊúâÊâæÂà∞Â§ñÊòüÊñáÊòéÔºü&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üå± ‰∏™‰∫∫ÊàêÈïøÁ±ª - ÂÖãÈöÜÈü≥Ëâ≤&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/1bad9a49-df83-4905-9cc8-9a7640e9c7d8&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Â¶Ç‰ΩïÊèêÂçáËá™Â∑±&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üß† Ê∑±Â∫¶ÊÄùËÄÉÁ±ª - ÈªòËÆ§Ê®°Êùø&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/663b705a-2aea-44bc-b266-4bb27aa255a8&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;Â¶Ç‰ΩïÁêÜËß£ÂèçËÑÜÂº±&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üèØ ÂéÜÂè≤ÊñáÂåñÁ±ª - Âõ∫ÂÆöÁîªÈù¢&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/56e0a018-fa99-47eb-a97f-fc2fa8915724&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;ËµÑÊ≤ªÈÄöÈâ¥&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;‚òÄÔ∏è ÊÉÖÊÑüÁ±ª - ÂÖãÈöÜÈü≥Ëâ≤&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/4687df95-dd21-4a7b-b01e-f33a7b646644&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;ÂÜ¨Êó•ÊöñÈò≥&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üìú Â∞èËØ¥Ëß£ËØ¥Á±ª - Ëá™ÂàõËÑöÊú¨&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/d354465e-3fa8-40b4-93e9-61ad75ef0697&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;ÊñóÁ†¥ËãçÁ©π&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;33%&quot;&gt;
&lt;h3&gt;üß¨ Áü•ËØÜÁßëÊôÆÁ±ª - QwenÁîüÂõæ&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/8ac21768-41ce-4d41-acdd-e3dd3eb9725a&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;ÂÖªÁîüÁü•ËØÜ&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

### üñ•Ô∏è Ê®™Â±èËßÜÈ¢ëÂ±ïÁ§∫

&lt;table&gt;
&lt;tr&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üí∞ ÂâØ‰∏öËµöÈí± - ÁîµÂΩ±Ê®°Êùø&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/c9209d4e-73a6-4b82-aaad-cf102248c9e2&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;ÂâØ‰∏öËµöÈí±&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;td width=&quot;50%&quot;&gt;
&lt;h3&gt;üèõÔ∏è ÂéÜÂè≤Ëß£ËØ¥ - Ëá™ÂÆö‰πâÊ®°Êùø&lt;/h3&gt;
&lt;video src=&quot;https://github.com/user-attachments/assets/a767c452-d5f1-4cff-bb34-b80fff0d4c3e&quot; controls width=&quot;100%&quot;&gt;&lt;/video&gt;
&lt;p align=&quot;center&quot;&gt;&lt;b&gt;ËµÑÊ≤ªÈÄöÈâ¥ÂêØÁ§∫ÂΩï&lt;/b&gt;&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&gt; üí° **ÊèêÁ§∫**: Ëøô‰∫õËßÜÈ¢ëÈÉΩÊòØÈÄöËøáËæìÂÖ•‰∏Ä‰∏™‰∏ªÈ¢òÂÖ≥ÈîÆËØçÔºåÁî± AI ÂÖ®Ëá™Âä®ÁîüÊàêÁöÑÔºåÊó†ÈúÄ‰ªª‰ΩïËßÜÈ¢ëÂâ™ËæëÁªèÈ™åÔºÅ


&lt;div id=&quot;tutorial-start&quot; /&gt;


## üöÄ Âø´ÈÄüÂºÄÂßã

### ü™ü Windows ‰∏ÄÈîÆÊï¥ÂêàÂåÖÔºàÊé®Ëçê Windows Áî®Êà∑‰ΩøÁî®Ôºâ

**Êó†ÈúÄÂÆâË£Ö Python„ÄÅuv Êàñ ffmpegÔºå‰∏ÄÈîÆÂºÄÁÆ±Âç≥Áî®ÔºÅ**

üëâ **[‰∏ãËΩΩ Windows ‰∏ÄÈîÆÊï¥ÂêàÂåÖ](https://github.com/AIDC-AI/Pixelle-Video/releases/latest)**

1. ‰∏ãËΩΩÊúÄÊñ∞ÁöÑ Windows ‰∏ÄÈîÆÊï¥ÂêàÂåÖÂπ∂Ëß£Âéã
2. ÂèåÂáªËøêË°å `start.bat` ÂêØÂä® Web ÁïåÈù¢
3. ÊµèËßàÂô®‰ºöËá™Âä®ÊâìÂºÄ http://localhost:8501
4. Âú®„Äå‚öôÔ∏è Á≥ªÁªüÈÖçÁΩÆ„Äç‰∏≠ÈÖçÁΩÆ LLM API ÂíåÂõæÂÉèÁîüÊàêÊúçÂä°
5. ÂºÄÂßãÁîüÊàêËßÜÈ¢ëÔºÅ

&gt; üí° **ÊèêÁ§∫**: Êï¥ÂêàÂåÖÂ∑≤ÂåÖÂê´ÊâÄÊúâ‰æùËµñÔºåÊó†ÈúÄÊâãÂä®ÂÆâË£Ö‰ªª‰ΩïÁéØÂ¢É„ÄÇÈ¶ñÊ¨°‰ΩøÁî®Âè™ÈúÄÈÖçÁΩÆ API ÂØÜÈí•Âç≥ÂèØ„ÄÇ


### ‰ªéÊ∫êÁ†ÅÂÆâË£ÖÔºàÈÄÇÂêà macOS / Linux Áî®Êà∑ÊàñÈúÄË¶ÅËá™ÂÆö‰πâÁöÑÁî®Êà∑Ôºâ

#### ÂâçÁΩÆÁéØÂ¢É‰æùËµñ

Âú®ÂºÄÂßã‰πãÂâçÔºåÈúÄË¶ÅÂÖàÂÆâË£Ö Python ÂåÖÁÆ°ÁêÜÂô® `uv` ÂíåËßÜÈ¢ëÂ§ÑÁêÜÂ∑•ÂÖ∑ `ffmpeg`Ôºö

##### ÂÆâË£Ö uv

ËØ∑ËÆøÈóÆ uv ÂÆòÊñπÊñáÊ°£Êü•ÁúãÈÄÇÂêà‰Ω†Á≥ªÁªüÁöÑÂÆâË£ÖÊñπÊ≥ïÔºö  
üëâ **[uv ÂÆâË£ÖÊåáÂçó](https://docs.astral.sh/uv/getting-started/installation/)**

ÂÆâË£ÖÂÆåÊàêÂêéÔºåÂú®ÁªàÁ´Ø‰∏≠ËøêË°å `uv --version` È™åËØÅÂÆâË£ÖÊàêÂäü„ÄÇ

##### ÂÆâË£Ö ffmpeg

**macOS**
```bash
brew install ffmpeg
```

**Ubuntu / Debian**
```bash
sudo apt update
sudo apt install ffmpeg
```

**Windows**
- ‰∏ãËΩΩÂú∞ÂùÄÔºöhttps://ffmpeg.org/download.html
- ‰∏ãËΩΩÂêéËß£ÂéãÔºåÂ∞Ü `bin` ÁõÆÂΩïÊ∑ªÂä†Âà∞Á≥ªÁªüÁéØÂ¢ÉÂèòÈáè PATH ‰∏≠

ÂÆâË£ÖÂÆåÊàêÂêéÔºåÂú®ÁªàÁ´Ø‰∏≠ËøêË°å `ffmpeg -version` È™åËØÅÂÆâË£ÖÊàêÂäü„ÄÇ


#### Á¨¨‰∏ÄÊ≠•Ôºö‰∏ãËΩΩÈ°πÁõÆ

```bash
git clone https://github.com/AIDC-AI/Pixelle-Video.git
cd Pixelle-Video
```

#### Á¨¨‰∫åÊ≠•ÔºöÂêØÂä® Web ÁïåÈù¢

```bash
# ‰ΩøÁî® uv ËøêË°åÔºàÊé®ËçêÔºå‰ºöËá™Âä®ÂÆâË£Ö‰æùËµñÔºâ
uv run streamlit run web/app.py
```

ÊµèËßàÂô®‰ºöËá™Âä®ÊâìÂºÄ http://localhost:8501

#### Á¨¨‰∏âÊ≠•ÔºöÂú® Web ÁïåÈù¢ÈÖçÁΩÆ

È¶ñÊ¨°‰ΩøÁî®Êó∂ÔºåÂ±ïÂºÄ„Äå‚öôÔ∏è Á≥ªÁªüÈÖçÁΩÆ„ÄçÈù¢ÊùøÔºåÂ°´ÂÜôÔºö
- **LLM ÈÖçÁΩÆ**: ÈÄâÊã© AI Ê®°ÂûãÔºàÂ¶ÇÈÄö‰πâÂçÉÈóÆ„ÄÅGPT Á≠âÔºâÂπ∂Â°´ÂÖ• API Key
- **ÂõæÂÉèÈÖçÁΩÆ**: Â¶ÇÈúÄÁîüÊàêÂõæÁâáÔºåÈÖçÁΩÆ ComfyUI Âú∞ÂùÄÊàñ RunningHub API Key

ÈÖçÁΩÆÂ•ΩÂêéÁÇπÂáª„Äå‰øùÂ≠òÈÖçÁΩÆ„ÄçÔºåÂ∞±ÂèØ‰ª•ÂºÄÂßãÁîüÊàêËßÜÈ¢ë‰∫ÜÔºÅ

&lt;div id=&quot;tutorial-end&quot; /&gt;

## üíª ‰ΩøÁî®ÊñπÊ≥ï

ÊâìÂºÄ Web ÁïåÈù¢ÂêéÔºå‰Ω†‰ºöÁúãÂà∞‰∏âÊ†èÂ∏ÉÂ±ÄÔºå‰∏ãÈù¢ËØ¶ÁªÜËÆ≤Ëß£ÊØè‰∏™ÈÉ®ÂàÜÔºö


### ‚öôÔ∏è Á≥ªÁªüÈÖçÁΩÆÔºàÈ¶ñÊ¨°ÂøÖÂ°´Ôºâ

È¶ñÊ¨°‰ΩøÁî®Êó∂ÈúÄË¶ÅÈÖçÁΩÆÔºåÁÇπÂáªÂ±ïÂºÄ„Äå‚öôÔ∏è Á≥ªÁªüÈÖçÁΩÆ„ÄçÈù¢ÊùøÔºö

#### 1. LLM ÈÖçÁΩÆÔºàÂ§ßËØ≠Ë®ÄÊ®°ÂûãÔºâ
Áî®‰∫éÁîüÊàêËßÜÈ¢ëÊñáÊ°àÁöÑ AI„ÄÇ

**Âø´ÈÄüÈÄâÊã©È¢ÑËÆæ**  
- ÈÄöËøá‰∏ãÊãâËèúÂçïÈÄâÊã©È¢ÑËÆæÊ®°ÂûãÔºàÈÄö‰πâÂçÉÈóÆ„ÄÅGPT-4o„ÄÅDeepSeek Á≠âÔºâ
- ÈÄâÊã©Âêé‰ºöËá™Âä®Â°´ÂÖÖ base_url Âíå model
- ÁÇπÂáª„Äåüîë Ëé∑Âèñ API Key„ÄçÈìæÊé•ÂéªÊ≥®ÂÜåÂπ∂Ëé∑ÂèñÂØÜÈí•

**ÊâãÂä®ÈÖçÁΩÆ**  
- API Key: Â°´ÂÖ•‰Ω†ÁöÑÂØÜÈí•
- Base URL: API Âú∞ÂùÄ
- Model: Ê®°ÂûãÂêçÁß∞

#### 2. ÂõæÂÉèÈÖçÁΩÆ
Áî®‰∫éÁîüÊàêËßÜÈ¢ëÈÖçÂõæÁöÑ AI„ÄÇ

**Êú¨Âú∞ÈÉ®ÁΩ≤ÔºàÊé®ËçêÔºâ**  
- ComfyUI URL: Êú¨Âú∞ ComfyUI ÊúçÂä°Âú∞ÂùÄÔºàÈªòËÆ§ http://127.0.0.1:8188Ôºâ
- ÁÇπÂáª„ÄåÊµãËØïËøûÊé•„ÄçÁ°ÆËÆ§ÊúçÂä°ÂèØÁî®

**‰∫ëÁ´ØÈÉ®ÁΩ≤**  
- RunningHub API Key: ‰∫ëÁ´ØÂõæÂÉèÁîüÊàêÊúçÂä°ÁöÑÂØÜÈí•

ÈÖçÁΩÆÂÆåÊàêÂêéÁÇπÂáª„Äå‰øùÂ≠òÈÖçÁΩÆ„Äç„ÄÇ


### üìù ÂÜÖÂÆπËæìÂÖ•ÔºàÂ∑¶‰æßÊ†èÔºâ

#### ÁîüÊàêÊ®°Âºè
- **AI ÁîüÊàêÂÜÖÂÆπ**: ËæìÂÖ•‰∏ªÈ¢òÔºåAI Ëá™Âä®Âàõ‰ΩúÊñáÊ°à
  - ÈÄÇÂêàÔºöÊÉ≥Âø´ÈÄüÁîüÊàêËßÜÈ¢ëÔºåËÆ© AI ÂÜôÁ®ø
  - ‰æãÂ¶ÇÔºö„Äå‰∏∫‰ªÄ‰πàË¶ÅÂÖªÊàêÈòÖËØª‰π†ÊÉØ„Äç
- **Âõ∫ÂÆöÊñáÊ°àÂÜÖÂÆπ**: Áõ¥Êé•ËæìÂÖ•ÂÆåÊï¥ÊñáÊ°àÔºåË∑≥Ëøá AI Âàõ‰Ωú
  - ÈÄÇÂêàÔºöÂ∑≤ÊúâÁé∞ÊàêÊñáÊ°àÔºåÁõ¥Êé•ÁîüÊàêËßÜÈ¢ë

#### ËÉåÊôØÈü≥‰πêÔºàBGMÔºâ
- **Êó† BGM**: Á∫Ø‰∫∫Â£∞Ëß£ËØ¥
- **ÂÜÖÁΩÆÈü≥‰πê**: ÈÄâÊã©È¢ÑÁΩÆÁöÑËÉåÊôØÈü≥‰πêÔºàÂ¶Ç default.mp3Ôºâ
- **Ëá™ÂÆö‰πâÈü≥‰πê**: Â∞Ü‰Ω†ÁöÑÈü≥‰πêÊñá‰ª∂ÔºàMP3/WAV Á≠âÔºâÊîæÂà∞ `bgm/` Êñá‰ª∂Â§π
- ÁÇπÂáª„ÄåËØïÂê¨ BGM„ÄçÂèØ‰ª•È¢ÑËßàÈü≥‰πê


### üé§ ËØ≠Èü≥ËÆæÁΩÆÔºà‰∏≠Èó¥Ê†èÔºâ

#### TTS Â∑•‰ΩúÊµÅ
- ‰ªé‰∏ãÊãâËèúÂçïÈÄâÊã© TTS Â∑•‰ΩúÊµÅÔºàÊîØÊåÅ Edge-TTS„ÄÅIndex-TTS Á≠âÔºâ
- Á≥ªÁªü‰ºöËá™Âä®Êâ´Êèè `workflows/` Êñá‰ª∂Â§π‰∏≠ÁöÑ TTS Â∑•‰ΩúÊµÅ
- Â¶ÇÊûúÊáÇ ComfyUIÔºåÂèØ‰ª•Ëá™ÂÆö‰πâ TTS Â∑•‰ΩúÊµÅ

#### ÂèÇËÄÉÈü≥È¢ëÔºàÂèØÈÄâÔºâ
- ‰∏ä‰º†ÂèÇËÄÉÈü≥È¢ëÊñá‰ª∂Áî®‰∫éÂ£∞Èü≥ÂÖãÈöÜÔºàÊîØÊåÅ MP3/WAV/FLAC Á≠âÊ†ºÂºèÔºâ
- ÈÄÇÁî®‰∫éÊîØÊåÅÂ£∞Èü≥ÂÖãÈöÜÁöÑ TTS Â∑•‰ΩúÊµÅÔºàÂ¶Ç Index-TTSÔºâ
- ‰∏ä‰º†ÂêéÂèØ‰ª•Áõ¥Êé•ËØïÂê¨

#### È¢ÑËßàÂäüËÉΩ
- ËæìÂÖ•ÊµãËØïÊñáÊú¨ÔºåÁÇπÂáª„ÄåÈ¢ÑËßàËØ≠Èü≥„ÄçÂç≥ÂèØËØïÂê¨ÊïàÊûú
- ÊîØÊåÅ‰ΩøÁî®ÂèÇËÄÉÈü≥È¢ëËøõË°åÈ¢ÑËßà


### üé® ËßÜËßâËÆæÁΩÆÔºà‰∏≠Èó¥Ê†èÔºâ

#### ÂõæÂÉèÁîüÊàê
ÂÜ≥ÂÆö AI ÁîüÊàê‰ªÄ‰πàÈ£éÊ†ºÁöÑÈÖçÂõæ„ÄÇ

**ComfyUI Â∑•‰ΩúÊµÅ**  
- ‰ªé‰∏ãÊãâËèúÂçïÈÄâÊã©ÂõæÂÉèÁîüÊàêÂ∑•‰ΩúÊµÅ
- ÊîØÊåÅÊú¨Âú∞ÈÉ®ÁΩ≤ÔºàselfhostÔºâÂíå‰∫ëÁ´ØÔºàRunningHubÔºâÂ∑•‰ΩúÊµÅ
- ÈªòËÆ§‰ΩøÁî® `image_flux.json`
- Â¶ÇÊûúÊáÇ ComfyUIÔºåÂèØ‰ª•ÊîæËá™Â∑±ÁöÑÂ∑•‰ΩúÊµÅÂà∞ `workflows/` Êñá‰ª∂Â§π

**ÂõæÂÉèÂ∞∫ÂØ∏**  
- ËÆæÁΩÆÁîüÊàêÂõæÂÉèÁöÑÂÆΩÂ∫¶ÂíåÈ´òÂ∫¶ÔºàÂçï‰ΩçÔºöÂÉèÁ¥†Ôºâ
- ÈªòËÆ§ 1024x1024ÔºåÂèØÊ†πÊçÆÈúÄË¶ÅË∞ÉÊï¥
- Ê≥®ÊÑèÔºö‰∏çÂêåÁöÑÊ®°ÂûãÂØπÂ∞∫ÂØ∏Êúâ‰∏çÂêåÁöÑÈôêÂà∂

**ÊèêÁ§∫ËØçÂâçÁºÄÔºàPrompt PrefixÔºâ**  
- ÊéßÂà∂ÂõæÂÉèÁöÑÊï¥‰ΩìÈ£éÊ†ºÔºàËØ≠Ë®ÄÈúÄË¶ÅÊòØËã±ÊñáÁöÑÔºâ
- ‰æãÂ¶ÇÔºöMinimalist black-and-white matchstick figure style illustration, clean lines, simple sketch style
- ÁÇπÂáª„ÄåÈ¢ÑËßàÈ£éÊ†º„ÄçÂèØ‰ª•ÊµãËØïÊïàÊûú

#### ËßÜÈ¢ëÊ®°Êùø
ÂÜ≥ÂÆöËßÜÈ¢ëÁîªÈù¢ÁöÑÂ∏ÉÂ±ÄÂíåËÆæËÆ°„ÄÇ

**Ê®°ÊùøÂëΩÂêçËßÑËåÉ**  
- `static_*.html`: ÈùôÊÄÅÊ®°ÊùøÔºàÊó†ÈúÄAIÁîüÊàêÂ™í‰ΩìÔºåÁ∫ØÊñáÂ≠óÊ†∑ÂºèÔºâ
- `image_*.html`: ÂõæÁâáÊ®°ÊùøÔºà‰ΩøÁî®AIÁîüÊàêÁöÑÂõæÁâá‰Ωú‰∏∫ËÉåÊôØÔºâ
- `video_*.html`: ËßÜÈ¢ëÊ®°ÊùøÔºà‰ΩøÁî®AIÁîüÊàêÁöÑËßÜÈ¢ë‰Ωú‰∏∫ËÉåÊôØÔºâ

**‰ΩøÁî®ÊñπÊ≥ï**  
- ‰ªé‰∏ãÊãâËèúÂçïÈÄâÊã©Ê®°ÊùøÔºåÊåâÂ∞∫ÂØ∏ÂàÜÁªÑÊòæÁ§∫ÔºàÁ´ñÂ±è/Ê®™Â±è/ÊñπÂΩ¢Ôºâ
- ÁÇπÂáª„ÄåÈ¢ÑËßàÊ®°Êùø„ÄçÂèØ‰ª•Ëá™ÂÆö‰πâÂèÇÊï∞ÊµãËØïÊïàÊûú
- Â¶ÇÊûúÊáÇ HTMLÔºåÂèØ‰ª•Âú® `templates/` Êñá‰ª∂Â§πÂàõÂª∫Ëá™Â∑±ÁöÑÊ®°Êùø
- üîó [Êü•ÁúãÊâÄÊúâÊ®°ÊùøÊïàÊûúÂõæ](https://aidc-ai.github.io/Pixelle-Video/zh/user-guide/templates/#_3)


### üé¨ ÁîüÊàêËßÜÈ¢ëÔºàÂè≥‰æßÊ†èÔºâ

#### ÁîüÊàêÊåâÈíÆ
- ÈÖçÁΩÆÂ•ΩÊâÄÊúâÂèÇÊï∞ÂêéÔºåÁÇπÂáª„Äåüé¨ ÁîüÊàêËßÜÈ¢ë„Äç
- ‰ºöÊòæÁ§∫ÂÆûÊó∂ËøõÂ∫¶ÔºàÁîüÊàêÊñáÊ°à ‚Üí ÁîüÊàêÈÖçÂõæ ‚Üí ÂêàÊàêËØ≠Èü≥ ‚Üí ÂêàÊàêËßÜÈ¢ëÔºâ
- ÁîüÊàêÂÆåÊàêÂêéËá™Âä®ÊòæÁ§∫ËßÜÈ¢ëÈ¢ÑËßà

#### ËøõÂ∫¶ÊòæÁ§∫
- ÂÆûÊó∂ÊòæÁ§∫ÂΩìÂâçÊ≠•È™§
- ‰æãÂ¶ÇÔºö„ÄåÂàÜÈïú 3/5 - ÁîüÊàêÊèíÂõæ„Äç

#### ËßÜÈ¢ëÈ¢ÑËßà
- ÁîüÊàêÂÆåÊàêÂêéËá™Âä®Êí≠Êîæ
- ÊòæÁ§∫ËßÜÈ¢ëÊó∂Èïø„ÄÅÊñá‰ª∂Â§ßÂ∞è„ÄÅÂàÜÈïúÊï∞Á≠â‰ø°ÊÅØ
- ËßÜÈ¢ëÊñá‰ª∂‰øùÂ≠òÂú® `output/` Êñá‰ª∂Â§π


### ‚ùì Â∏∏ËßÅÈóÆÈ¢ò

**Q: Á¨¨‰∏ÄÊ¨°‰ΩøÁî®ÈúÄË¶ÅÂ§ö‰πÖÔºü**  
A: ÁîüÊàêÊó∂ÈïøÂèñÂÜ≥‰∫éËßÜÈ¢ëÂàÜÈïúÊï∞Èáè„ÄÅÁΩëÁªúÁä∂ÂÜµÂíå AI Êé®ÁêÜÈÄüÂ∫¶ÔºåÈÄöÂ∏∏Âá†ÂàÜÈíüÂÜÖÂç≥ÂèØÂÆåÊàê„ÄÇ

**Q: ËßÜÈ¢ëÊïàÊûú‰∏çÊª°ÊÑèÊÄé‰πàÂäûÔºü**  
A: ÂèØ‰ª•Â∞ùËØïÔºö
1. Êõ¥Êç¢ LLM Ê®°ÂûãÔºà‰∏çÂêåÊ®°ÂûãÊñáÊ°àÈ£éÊ†º‰∏çÂêåÔºâ
2. Ë∞ÉÊï¥ÂõæÂÉèÂ∞∫ÂØ∏ÂíåÊèêÁ§∫ËØçÂâçÁºÄÔºàÊîπÂèòÈÖçÂõæÈ£éÊ†ºÔºâ
3. Êõ¥Êç¢ TTS Â∑•‰ΩúÊµÅÊàñ‰∏ä‰º†ÂèÇËÄÉÈü≥È¢ëÔºàÊîπÂèòËØ≠Èü≥ÊïàÊûúÔºâ
4. Â∞ùËØï‰∏çÂêåÁöÑËßÜÈ¢ëÊ®°ÊùøÂíåÂ∞∫ÂØ∏

**Q: Ë¥πÁî®Â§ßÊ¶ÇÂ§öÂ∞ëÔºü**  
A: **Êú¨È°πÁõÆÂÆåÂÖ®ÊîØÊåÅÂÖçË¥πËøêË°åÔºÅ**

- **ÂÆåÂÖ®ÂÖçË¥πÊñπÊ°à**: LLM ‰ΩøÁî® OllamaÔºàÊú¨Âú∞ËøêË°åÔºâ+ ComfyUI Êú¨Âú∞ÈÉ®ÁΩ≤ = 0 ÂÖÉ
- **Êé®ËçêÊñπÊ°à**: LLM ‰ΩøÁî®ÈÄö‰πâÂçÉÈóÆÔºàÊàêÊú¨ÊûÅ‰ΩéÔºåÊÄß‰ª∑ÊØîÈ´òÔºâ+ ComfyUI Êú¨Âú∞ÈÉ®ÁΩ≤
- **‰∫ëÁ´ØÊñπÊ°à**: LLM ‰ΩøÁî® OpenAI + ÂõæÂÉè‰ΩøÁî® RunningHubÔºàË¥πÁî®ËæÉÈ´ò‰ΩÜÊó†ÈúÄÊú¨Âú∞ÁéØÂ¢ÉÔºâ

**ÈÄâÊã©Âª∫ËÆÆ**ÔºöÊú¨Âú∞ÊúâÊòæÂç°Âª∫ËÆÆÂÆåÂÖ®ÂÖçË¥πÊñπÊ°àÔºåÂê¶ÂàôÊé®Ëçê‰ΩøÁî®ÈÄö‰πâÂçÉÈóÆÔºàÊÄß‰ª∑ÊØîÈ´òÔºâ


## ü§ù ÂèÇËÄÉÈ°πÁõÆ

Pixelle-Video ÁöÑËÆæËÆ°ÂèóÂà∞‰ª•‰∏ã‰ºòÁßÄÂºÄÊ∫êÈ°πÁõÆÁöÑÂêØÂèëÔºö

- [Pixelle-MCP](https://github.com/AIDC-AI/Pixelle-MCP) - ComfyUI MCP ÊúçÂä°Âô®ÔºåËÆ© AI Âä©ÊâãÁõ¥Êé•Ë∞ÉÁî® ComfyUI
- [MoneyPrinterTurbo](https://github.com/harry0703/MoneyPrinterTurbo) - ‰ºòÁßÄÁöÑËßÜÈ¢ëÁîüÊàêÂ∑•ÂÖ∑
- [NarratoAI](https://github.com/linyqh/NarratoAI) - ÂΩ±ËßÜËß£ËØ¥Ëá™Âä®ÂåñÂ∑•ÂÖ∑
- [MoneyPrinterPlus](https://github.com/ddean2009/MoneyPrinterPlus) - ËßÜÈ¢ëÂàõ‰ΩúÂπ≥Âè∞
- [ComfyKit](https://github.com/puke3615/ComfyKit) - ComfyUI Â∑•‰ΩúÊµÅÂ∞ÅË£ÖÂ∫ì

ÊÑüË∞¢Ëøô‰∫õÈ°πÁõÆÁöÑÂºÄÊ∫êÁ≤æÁ•ûÔºÅüôè


## üí¨ Á§æÂå∫‰∫§ÊµÅ

Êâ´Êèè‰∏ãÊñπ‰∫åÁª¥Á†ÅÂä†ÂÖ•Êàë‰ª¨ÁöÑÁ§æÂå∫ÔºåËé∑ÂèñÊúÄÊñ∞Âä®ÊÄÅÂíåÊäÄÊúØÊîØÊåÅÔºö

| ÂæÆ‰ø°Áæ§ | Discord Á§æÂå∫ |
| ---- | ---- |
| &lt;img src=&quot;resources/wechat.png&quot; alt=&quot;ÂæÆ‰ø°‰∫§ÊµÅÁæ§&quot; width=&quot;250&quot; /&gt; | &lt;img src=&quot;resources/discord.png&quot; alt=&quot;Discord Á§æÂå∫&quot; width=&quot;250&quot; /&gt; |


## üì¢ ÂèçÈ¶à‰∏éÊîØÊåÅ

- üêõ **ÈÅáÂà∞ÈóÆÈ¢ò**: Êèê‰∫§ [Issue](https://github.com/AIDC-AI/Pixelle-Video/issues)
- üí° **ÂäüËÉΩÂª∫ËÆÆ**: Êèê‰∫§ [Feature Request](https://github.com/AIDC-AI/Pixelle-Video/issues)
- ‚≠ê **Áªô‰∏™ Star**: Â¶ÇÊûúËøô‰∏™È°πÁõÆÂØπ‰Ω†ÊúâÂ∏ÆÂä©ÔºåÊ¨¢ËøéÁªô‰∏™ Star ÊîØÊåÅ‰∏Ä‰∏ãÔºÅ


## üìù ËÆ∏ÂèØËØÅ

Êú¨È°πÁõÆÈááÁî® Apache 2.0 ËÆ∏ÂèØËØÅÔºåËØ¶ÊÉÖËØ∑Êü•Áúã [LICENSE](LICENSE) Êñá‰ª∂„ÄÇ


## ‚≠ê Star History

[![Star History Chart](https://api.star-history.com/svg?repos=AIDC-AI/Pixelle-Video&amp;type=Date)](https://star-history.com/#AIDC-AI/Pixelle-Video&amp;Date)

</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[zou-group/sleepfm-clinical]]></title>
            <link>https://github.com/zou-group/sleepfm-clinical</link>
            <guid>https://github.com/zou-group/sleepfm-clinical</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:30 GMT</pubDate>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/zou-group/sleepfm-clinical">zou-group/sleepfm-clinical</a></h1>
            <p></p>
            <p>Language: Python</p>
            <p>Stars: 554</p>
            <p>Forks: 106</p>
            <p>Stars today: 7 stars today</p>
            <h2>README</h2><pre># SleepFM-Clinical

## üî• News &amp; Updates

### üì∞ Publication
- **SleepFM** has been published in **Nature Medicine**  
  üëâ https://doi.org/10.1038/s41591-025-04133-4

### ü§ñ Model Releases
- **Pretrained Base Model**  
  `sleepfm/checkpoints/model_base`
- **Finetuned Disease Prediction Model**  
  `sleepfm/checkpoints/model_diagnosis`
- **Finetuned Sleep Staging Model**  
  `sleepfm/checkpoints/model_sleep_staging`

### üìä Dataset Release
- **Stanford Sleep Dataset**  
  Public release of the Stanford of data used to pretrain **SleepFM**  
  üëâ https://bdsp.io/content/08vg8vqv2wdtwonc1ddy/1.0

### üöÄ Demos
- üìì **End-to-End Inference Demo**  
  `notebooks/demo.ipynb`

## üìñ Introduction

Sleep is a fundamental biological process with broad implications for physical and mental health, yet its complex relationship with disease remains poorly understood. Polysomnography (PSG), the gold standard for sleep analysis, captures rich physiological signals but remains underutilized due to challenges in standardization, generalizability, and multimodal integration. To address these limitations, we developed SleepFM, a multimodal sleep foundation model trained with a novel contrastive learning approach that accommodates multiple PSG montages‚Äîthe specific arrangements of electrodes and sensors used to record physiological signals during sleep. Trained on a curated dataset of over 585,000 hours of PSG recordings from approximately 65,000 participants across multiple cohorts, SleepFM produces latent sleep representations that capture the physiological and temporal structure of sleep and enable accurate prediction of future disease risk. SleepFM achieved a C-Index of at least 0.75 (Bonferroni-corrected p &lt; 0.01) for 130 conditions, including all-cause mortality (C-Index: 0.84), dementia (0.85), myocardial infarction (0.81), heart failure (0.80), chronic kidney disease (0.79), stroke (0.78), and atrial fibrillation (0.78). Moreover, the model demonstrates strong transfer learning performance on a dataset from the Sleep Heart Health Study (SHHS), a dataset that was excluded from pretraining, and performs competitively with specialized sleep-staging models such as U-Sleep and YASA on common sleep analysis tasks, achieving mean F1 scores of 0.70‚Äì0.78 for sleep staging and accuracies of 0.69 and 0.87 for classifying sleep apnea severity and presence. This work shows that foundation models can extract clinically meaningful features from multi-modal sleep recordings, enabling scalable, label-efficient analysis and disease prediction.

# üìñ Table of Contents
1. [Installation](#installation)
2. [Usage](#usage)
3. [Licence](#license)

&lt;a name=&quot;installation&quot;/&gt;

# üíø Installation

Follow the steps below to set up an environment for running **SleepFM**.

We recommend using **Python 3.10**. All required packages and their specific versions are listed in the [requirements.txt](https://github.com/zou-group/sleepfm-clinical/blob/main/requirements.txt) file. Installing all dependencies should take only **2‚Äì3 minutes**.

### üñ•Ô∏è System Requirements

SleepFM was developed and tested on Linux systems with the following configuration:

- **GPU**: NVIDIA A40, A100, and RTX 2080 Ti
- **CUDA**: 12.4
- **CPU**: 8 cores recommended
- **RAM**: At least 32 GB
- **OS**: CentOS Linux 7.9.2009 (Core)

Although optimized for **A40/A100** GPUs, the model can be run on smaller GPUs (e.g., **RTX 2080 Ti**) by reducing the batch size. For smooth performance during preprocessing and training, we recommend using at least **8 CPU cores**.

### üöÄ Demo Run

This codebase includes a demo using the **MESA** dataset. On an **NVIDIA A40**, pretraining on MESA for one epoch takes approximately **1 hour**, and fine-tuning for one epoch takes about **1 minute**. Note that **MESA is significantly smaller** than the full dataset used in our main experiments.




```bash
git clone https://github.com/zou-group/sleepfm-clinical.git
cd sleepfm-clinical
conda env create -f env.yml
conda activate sleepfm_env
```

&lt;a name=&quot;usage&quot;/&gt;

# üë©‚Äçüíª Usage

This codebase will serve as a framework that you can adapt to your dataset for pretraining and testing. Below, we outline the steps to pretrain and adapt the model on a publicly available dataset called [MESA](https://sleepdata.org/datasets/mesa). Please keep in mind that this dataset is small and will most likely not yield optimal results.

**Note**: Please make sure to download the dataset with in your local path, with dataset name, `mesa`. Later on, we will need this path. 

## Preprocessing Dataset

PSG files may be stored in different formats. Here, we specifically provide scripts to process .EDF file format.

- **Step 0:** `preprocessing/preprocessing.py`
  - This script converts .EDF file into .hdf5 files with is the format that the model will expect below. 


## Pretraining

Note that we provide with dataset split as json file here: `configs/dataset_split.json`. We also provide with different channel groups within a modality: `configs/channel_groups.json`.

- **Step 1:** `sleepfm/pipeline/pretrain.py`
  - This script has our main pretraining config. Its corresponding config file is inside `configs/config_set_transformer_contrastive.yaml`, where you will set all the parameters and data path. This step will roughly take about an hour for an epoch on `MESA`. 
- **Step 2:** `sleepfm/pipeline/generate_embeddings.py`
  - After pretraining our model, we want to generate the embeddings for train/valid/test so that we can train a model for downstream classification. We do sleep stage classification here. This step will roughly take few minutes on `MESA`. 

## Evaluation

Note: These evaluation results will not match the ones that we have in our paper as this is a small dataset. This step does not require GPU support. 

You should also have extracted the sleep stage labels, which should look like this:

```csv
Start,Stop,StageName,StageNumber
0.0,5190.0,Wake,0
0.0,5190.0,Wake,0,
0.0,5190.0,Wake,0
```

These labels files are stored inside a folder as such `&lt;path&gt;/mesa/mesa-sleep-0001.csv`. Note that `mesa-sleep-0001` is the filename that should correspond with the original `.EDF` file and `.hdf5` files. 

- **Step 3:** `sleepfm/pipelinefinetune_sleep_staging.py`
  - This will finetune the pretrained model on sleep stage classification task. Please make sure to check config `configs/config_finetune_sleep_events.yaml`. This step roughly takes less than a minute on `MESA`. 

- **Step 4:** `sleepfm/pipeline/evaluate_sleep_staging.py`
  - This will evaluate the model on test set. This step only takes few seconds on `MESA`.
 

For disease prediction task:

- **Step 3:** `sleepfm/pipeline/finetune_diagnosis_coxph.py`
  - This will finetune the pretrained model on disease prediction task, using CoxPH loss function. Note that you will need to provide your own data, and set up dataloaders. Please see corresponding config `sleepfm/configs/config_finetune_diagnosis_coxph.yaml`


## BibTeX

```bibtex
@article{thapa2026multimodal,
  title={A multimodal sleep foundation model for disease prediction},
  author={Thapa, Rahul and Kjaer, Magnus Ruud and He, Bryan and Covert, Ian and Moore IV, Hyatt and Hanif, Umaer and Ganjoo, Gauri and Westover, M Brandon and Jennum, Poul and Brink-Kjaer, Andreas and others},
  journal={Nature Medicine},
  pages={1--11},
  year={2026},
  publisher={Nature Publishing Group US New York}
}
```

## License

[MIT License](LICENSE)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[anthropics/skills]]></title>
            <link>https://github.com/anthropics/skills</link>
            <guid>https://github.com/anthropics/skills</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:29 GMT</pubDate>
            <description><![CDATA[Public repository for Agent Skills]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/anthropics/skills">anthropics/skills</a></h1>
            <p>Public repository for Agent Skills</p>
            <p>Language: Python</p>
            <p>Stars: 74,843</p>
            <p>Forks: 7,721</p>
            <p>Stars today: 832 stars today</p>
            <h2>README</h2><pre>&gt; **Note:** This repository contains Anthropic&#039;s implementation of skills for Claude. For information about the Agent Skills standard, see [agentskills.io](http://agentskills.io).

# Skills
Skills are folders of instructions, scripts, and resources that Claude loads dynamically to improve performance on specialized tasks. Skills teach Claude how to complete specific tasks in a repeatable way, whether that&#039;s creating documents with your company&#039;s brand guidelines, analyzing data using your organization&#039;s specific workflows, or automating personal tasks.

For more information, check out:
- [What are skills?](https://support.claude.com/en/articles/12512176-what-are-skills)
- [Using skills in Claude](https://support.claude.com/en/articles/12512180-using-skills-in-claude)
- [How to create custom skills](https://support.claude.com/en/articles/12512198-creating-custom-skills)
- [Equipping agents for the real world with Agent Skills](https://anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills)

# About This Repository

This repository contains skills that demonstrate what&#039;s possible with Claude&#039;s skills system. These skills range from creative applications (art, music, design) to technical tasks (testing web apps, MCP server generation) to enterprise workflows (communications, branding, etc.).

Each skill is self-contained in its own folder with a `SKILL.md` file containing the instructions and metadata that Claude uses. Browse through these skills to get inspiration for your own skills or to understand different patterns and approaches.

Many skills in this repo are open source (Apache 2.0). We&#039;ve also included the document creation &amp; editing skills that power [Claude&#039;s document capabilities](https://www.anthropic.com/news/create-files) under the hood in the [`skills/docx`](./skills/docx), [`skills/pdf`](./skills/pdf), [`skills/pptx`](./skills/pptx), and [`skills/xlsx`](./skills/xlsx) subfolders. These are source-available, not open source, but we wanted to share these with developers as a reference for more complex skills that are actively used in a production AI application.

## Disclaimer

**These skills are provided for demonstration and educational purposes only.** While some of these capabilities may be available in Claude, the implementations and behaviors you receive from Claude may differ from what is shown in these skills. These skills are meant to illustrate patterns and possibilities. Always test skills thoroughly in your own environment before relying on them for critical tasks.

# Skill Sets
- [./skills](./skills): Skill examples for Creative &amp; Design, Development &amp; Technical, Enterprise &amp; Communication, and Document Skills
- [./spec](./spec): The Agent Skills specification
- [./template](./template): Skill template

# Try in Claude Code, Claude.ai, and the API

## Claude Code
You can register this repository as a Claude Code Plugin marketplace by running the following command in Claude Code:
```
/plugin marketplace add anthropics/skills
```

Then, to install a specific set of skills:
1. Select `Browse and install plugins`
2. Select `anthropic-agent-skills`
3. Select `document-skills` or `example-skills`
4. Select `Install now`

Alternatively, directly install either Plugin via:
```
/plugin install document-skills@anthropic-agent-skills
/plugin install example-skills@anthropic-agent-skills
```

After installing the plugin, you can use the skill by just mentioning it. For instance, if you install the `document-skills` plugin from the marketplace, you can ask Claude Code to do something like: &quot;Use the PDF skill to extract the form fields from `path/to/some-file.pdf`&quot;

## Claude.ai

These example skills are all already available to paid plans in Claude.ai. 

To use any skill from this repository or upload custom skills, follow the instructions in [Using skills in Claude](https://support.claude.com/en/articles/12512180-using-skills-in-claude#h_a4222fa77b).

## Claude API

You can use Anthropic&#039;s pre-built skills, and upload custom skills, via the Claude API. See the [Skills API Quickstart](https://docs.claude.com/en/api/skills-guide#creating-a-skill) for more.

# Creating a Basic Skill

Skills are simple to create - just a folder with a `SKILL.md` file containing YAML frontmatter and instructions. You can use the **template-skill** in this repository as a starting point:

```markdown
---
name: my-skill-name
description: A clear description of what this skill does and when to use it
---

# My Skill Name

[Add your instructions here that Claude will follow when this skill is active]

## Examples
- Example usage 1
- Example usage 2

## Guidelines
- Guideline 1
- Guideline 2
```

The frontmatter requires only two fields:
- `name` - A unique identifier for your skill (lowercase, hyphens for spaces)
- `description` - A complete description of what the skill does and when to use it

The markdown content below contains the instructions, examples, and guidelines that Claude will follow. For more details, see [How to create custom skills](https://support.claude.com/en/articles/12512198-creating-custom-skills).

# Partner Skills

Skills are a great way to teach Claude how to get better at using specific pieces of software. As we see awesome example skills from partners, we may highlight some of them here:

- **Notion** - [Notion Skills for Claude](https://www.notion.so/notiondevs/Notion-Skills-for-Claude-28da4445d27180c7af1df7d8615723d0)
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[sansan0/TrendRadar]]></title>
            <link>https://github.com/sansan0/TrendRadar</link>
            <guid>https://github.com/sansan0/TrendRadar</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:28 GMT</pubDate>
            <description><![CDATA[‚≠êAI-driven public opinion & trend monitor with multi-platform aggregation, RSS, and smart alerts.üéØ ÂëäÂà´‰ø°ÊÅØËøáËΩΩÔºå‰Ω†ÁöÑ AI ËàÜÊÉÖÁõëÊéßÂä©Êâã‰∏éÁÉ≠ÁÇπÁ≠õÈÄâÂ∑•ÂÖ∑ÔºÅËÅöÂêàÂ§öÂπ≥Âè∞ÁÉ≠ÁÇπ + RSS ËÆ¢ÈòÖÔºåÊîØÊåÅÂÖ≥ÈîÆËØçÁ≤æÂáÜÁ≠õÈÄâ„ÄÇAI ÁøªËØë + AI ÂàÜÊûêÁÆÄÊä•Áõ¥Êé®ÊâãÊú∫Ôºå‰πüÊîØÊåÅÊé•ÂÖ• MCP Êû∂ÊûÑÔºåËµãËÉΩ AI Ëá™ÁÑ∂ËØ≠Ë®ÄÂØπËØùÂàÜÊûê„ÄÅÊÉÖÊÑüÊ¥ûÂØü‰∏éË∂ãÂäøÈ¢ÑÊµãÁ≠â„ÄÇÊîØÊåÅ Docker ÔºåÊï∞ÊçÆÊú¨Âú∞/‰∫ëÁ´ØËá™ÊåÅ„ÄÇÈõÜÊàêÂæÆ‰ø°/È£û‰π¶/ÈíâÈíâ/Telegram/ÈÇÆ‰ª∂/ntfy/bark/slack Á≠âÊ∏†ÈÅìÊô∫ËÉΩÊé®ÈÄÅ„ÄÇ]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/sansan0/TrendRadar">sansan0/TrendRadar</a></h1>
            <p>‚≠êAI-driven public opinion & trend monitor with multi-platform aggregation, RSS, and smart alerts.üéØ ÂëäÂà´‰ø°ÊÅØËøáËΩΩÔºå‰Ω†ÁöÑ AI ËàÜÊÉÖÁõëÊéßÂä©Êâã‰∏éÁÉ≠ÁÇπÁ≠õÈÄâÂ∑•ÂÖ∑ÔºÅËÅöÂêàÂ§öÂπ≥Âè∞ÁÉ≠ÁÇπ + RSS ËÆ¢ÈòÖÔºåÊîØÊåÅÂÖ≥ÈîÆËØçÁ≤æÂáÜÁ≠õÈÄâ„ÄÇAI ÁøªËØë + AI ÂàÜÊûêÁÆÄÊä•Áõ¥Êé®ÊâãÊú∫Ôºå‰πüÊîØÊåÅÊé•ÂÖ• MCP Êû∂ÊûÑÔºåËµãËÉΩ AI Ëá™ÁÑ∂ËØ≠Ë®ÄÂØπËØùÂàÜÊûê„ÄÅÊÉÖÊÑüÊ¥ûÂØü‰∏éË∂ãÂäøÈ¢ÑÊµãÁ≠â„ÄÇÊîØÊåÅ Docker ÔºåÊï∞ÊçÆÊú¨Âú∞/‰∫ëÁ´ØËá™ÊåÅ„ÄÇÈõÜÊàêÂæÆ‰ø°/È£û‰π¶/ÈíâÈíâ/Telegram/ÈÇÆ‰ª∂/ntfy/bark/slack Á≠âÊ∏†ÈÅìÊô∫ËÉΩÊé®ÈÄÅ„ÄÇ</p>
            <p>Language: Python</p>
            <p>Stars: 47,124</p>
            <p>Forks: 22,340</p>
            <p>Stars today: 134 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot; id=&quot;trendradar&quot;&gt;

&lt;a href=&quot;https://github.com/sansan0/TrendRadar&quot; title=&quot;TrendRadar&quot;&gt;
  &lt;img src=&quot;/_image/banner.webp&quot; alt=&quot;TrendRadar Banner&quot; width=&quot;80%&quot;&gt;
&lt;/a&gt;

ÊúÄÂø´&lt;strong&gt;30Áßí&lt;/strong&gt;ÈÉ®ÁΩ≤ÁöÑÁÉ≠ÁÇπÂä©Êâã ‚Äî‚Äî ÂëäÂà´Êó†ÊïàÂà∑Â±èÔºåÂè™ÁúãÁúüÊ≠£ÂÖ≥ÂøÉÁöÑÊñ∞ÈóªËµÑËÆØ

&lt;a href=&quot;https://trendshift.io/repositories/14726&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/14726&quot; alt=&quot;sansan0%2FTrendRadar | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;


[![GitHub Stars](https://img.shields.io/github/stars/sansan0/TrendRadar?style=flat-square&amp;logo=github&amp;color=yellow)](https://github.com/sansan0/TrendRadar/stargazers)
[![GitHub Forks](https://img.shields.io/github/forks/sansan0/TrendRadar?style=flat-square&amp;logo=github&amp;color=blue)](https://github.com/sansan0/TrendRadar/network/members)
[![License](https://img.shields.io/badge/license-GPL--3.0-blue.svg?style=flat-square)](LICENSE)
[![Version](https://img.shields.io/badge/version-v6.0.0-blue.svg)](https://github.com/sansan0/TrendRadar)
[![MCP](https://img.shields.io/badge/MCP-v4.0.0-green.svg)](https://github.com/sansan0/TrendRadar)
[![RSS](https://img.shields.io/badge/RSS-ËÆ¢ÈòÖÊ∫êÊîØÊåÅ-orange.svg?style=flat-square&amp;logo=rss&amp;logoColor=white)](https://github.com/sansan0/TrendRadar)
[![AIÁøªËØë](https://img.shields.io/badge/AI-Â§öËØ≠Ë®ÄÊé®ÈÄÅ-purple.svg?style=flat-square)](https://github.com/sansan0/TrendRadar)

[![‰ºÅ‰∏öÂæÆ‰ø°ÈÄöÁü•](https://img.shields.io/badge/‰ºÅ‰∏öÂæÆ‰ø°-ÈÄöÁü•-00D4AA?style=flat-square)](https://work.weixin.qq.com/)
[![‰∏™‰∫∫ÂæÆ‰ø°ÈÄöÁü•](https://img.shields.io/badge/‰∏™‰∫∫ÂæÆ‰ø°-ÈÄöÁü•-00D4AA?style=flat-square)](https://weixin.qq.com/)
[![TelegramÈÄöÁü•](https://img.shields.io/badge/Telegram-ÈÄöÁü•-00D4AA?style=flat-square)](https://telegram.org/)
[![dingtalkÈÄöÁü•](https://img.shields.io/badge/ÈíâÈíâ-ÈÄöÁü•-00D4AA?style=flat-square)](#)
[![È£û‰π¶ÈÄöÁü•](https://img.shields.io/badge/È£û‰π¶-ÈÄöÁü•-00D4AA?style=flat-square)](https://www.feishu.cn/)
[![ÈÇÆ‰ª∂ÈÄöÁü•](https://img.shields.io/badge/Email-ÈÄöÁü•-00D4AA?style=flat-square)](#)
[![ntfyÈÄöÁü•](https://img.shields.io/badge/ntfy-ÈÄöÁü•-00D4AA?style=flat-square)](https://github.com/binwiederhier/ntfy)
[![BarkÈÄöÁü•](https://img.shields.io/badge/Bark-ÈÄöÁü•-00D4AA?style=flat-square)](https://github.com/Finb/Bark)
[![SlackÈÄöÁü•](https://img.shields.io/badge/Slack-ÈÄöÁü•-00D4AA?style=flat-square)](https://slack.com/)
[![ÈÄöÁî®Webhook](https://img.shields.io/badge/ÈÄöÁî®-Webhook-607D8B?style=flat-square&amp;logo=webhook&amp;logoColor=white)](#)


[![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-Ëá™Âä®Âåñ-2088FF?style=flat-square&amp;logo=github-actions&amp;logoColor=white)](https://github.com/sansan0/TrendRadar)
[![GitHub Pages](https://img.shields.io/badge/GitHub_Pages-ÈÉ®ÁΩ≤-4285F4?style=flat-square&amp;logo=github&amp;logoColor=white)](https://sansan0.github.io/TrendRadar)
[![Docker](https://img.shields.io/badge/Docker-ÈÉ®ÁΩ≤-2496ED?style=flat-square&amp;logo=docker&amp;logoColor=white)](https://hub.docker.com/r/wantcat/trendradar)
[![MCP Support](https://img.shields.io/badge/MCP-AIÂàÜÊûêÊîØÊåÅ-FF6B6B?style=flat-square&amp;logo=ai&amp;logoColor=white)](https://modelcontextprotocol.io/)
[![AIÂàÜÊûêÊé®ÈÄÅ](https://img.shields.io/badge/AI-ÂàÜÊûêÊé®ÈÄÅ-FF6B6B?style=flat-square&amp;logo=openai&amp;logoColor=white)](#)

&lt;/div&gt;

&lt;div align=&quot;center&quot;&gt;

**‰∏≠Êñá** | **[English](README-EN.md)**

&lt;/div&gt;

&gt; Êú¨È°πÁõÆ‰ª•ËΩªÈáèÔºåÊòìÈÉ®ÁΩ≤‰∏∫ÁõÆÊ†á

&lt;br&gt;

## üìë Âø´ÈÄüÂØºËà™

&gt; üí° **ÁÇπÂáª‰∏ãÊñπÈìæÊé•**ÂèØÂø´ÈÄüË∑≥ËΩ¨Âà∞ÂØπÂ∫îÁ´†ËäÇ„ÄÇÈÉ®ÁΩ≤Êé®Ëçê‰ªé„Äå**Âø´ÈÄüÂºÄÂßã**„ÄçÂÖ•ÊâãÔºåÈúÄË¶ÅËØ¶ÁªÜËá™ÂÆö‰πâËØ∑Áúã„Äå**ÈÖçÁΩÆËØ¶Ëß£**„Äç

&lt;div align=&quot;center&quot;&gt;

|   |   |   |
|:---:|:---:|:---:|
| [üöÄ **Âø´ÈÄüÂºÄÂßã**](#-Âø´ÈÄüÂºÄÂßã) | [AI Êô∫ËÉΩÂàÜÊûê](#-ai-Êô∫ËÉΩÂàÜÊûê) | [‚öôÔ∏è **ÈÖçÁΩÆËØ¶Ëß£**](#ÈÖçÁΩÆËØ¶Ëß£) |
| [DockerÈÉ®ÁΩ≤](#6-docker-ÈÉ®ÁΩ≤) | [MCPÂÆ¢Êà∑Á´Ø](#-mcp-ÂÆ¢Êà∑Á´Ø) | [üìù **Êõ¥Êñ∞Êó•Âøó**](#-Êõ¥Êñ∞Êó•Âøó) |
| [üéØ **Ê†∏ÂøÉÂäüËÉΩ**](#-Ê†∏ÂøÉÂäüËÉΩ) | [‚òï **ÊîØÊåÅÈ°πÁõÆ**](#-ÊîØÊåÅÈ°πÁõÆ) | [üìö **È°πÁõÆÁõ∏ÂÖ≥**](#-È°πÁõÆÁõ∏ÂÖ≥) |

&lt;/div&gt;

&lt;br&gt;

- ÊÑüË∞¢**‰∏∫È°πÁõÆÁÇπ star** ÁöÑËßÇ‰ºó‰ª¨Ôºå**fork** ‰Ω†ÊâÄÊ¨≤‰πüÔºå**star** ÊàëÊâÄÊ¨≤‰πüÔºå‰∏§ËÄÖÂæóÂÖºüòçÊòØÂØπÂºÄÊ∫êÁ≤æÁ•ûÊúÄÂ•ΩÁöÑÊîØÊåÅ

&lt;details&gt;
&lt;summary&gt;üëâ ÁÇπÂáªÂ±ïÂºÄÔºö&lt;strong&gt;Ëá¥Ë∞¢ÂêçÂçï&lt;/strong&gt; (Â§©‰ΩøËΩÆËç£Ë™âÊ¶ú üî•73+üî• ‰Ωç)&lt;/summary&gt;

### Êó©ÊúüÊîØÊåÅËÄÖËá¥Ë∞¢

&gt; üí° **ÁâπÂà´ËØ¥Êòé**Ôºö
&gt;
&gt; 1. **ÂÖ≥‰∫éÂêçÂçï**Ôºö‰∏ãÊñπË°®Ê†ºËÆ∞ÂΩï‰∫ÜÈ°πÁõÆËµ∑Ê≠•Èò∂ÊÆµÔºàÂ§©‰ΩøËΩÆÔºâÁöÑÊîØÊåÅËÄÖ„ÄÇÂõ†Êó©Êúü‰∫∫Â∑•ÁªüËÆ°ÁπÅÁêêÔºå**ÈöæÂÖçÂ≠òÂú®ÁñèÊºèÊàñËÆ∞ÂΩï‰∏çÂÖ®ÁöÑÊÉÖÂÜµÔºåÂ¶ÇÊúâÈÅóÊºèÔºåÂÆûÈùûÊú¨ÊÑèÔºå‰∏áÊúõÊµ∑Ê∂µ**„ÄÇ
&gt; 2. **Êú™Êù•ËßÑÂàí**Ôºö‰∏∫‰∫ÜÂ∞ÜÊúâÈôêÁöÑÁ≤æÂäõÂõûÂΩí‰ª£Á†Å‰∏éÂäüËÉΩËø≠‰ª£Ôºå**Âç≥Êó•Ëµ∑‰∏çÂÜç‰∫∫Â∑•Áª¥Êä§Ê≠§ÂêçÂçï**„ÄÇ
&gt;
&gt; Êó†ËÆ∫ÂêçÂ≠óÊòØÂê¶‰∏äÊ¶úÔºå‰Ω†‰ª¨ÁöÑÊØè‰∏Ä‰ªΩÊîØÊåÅÈÉΩÊòØ TrendRadar ËÉΩÂ§üËµ∞Âà∞‰ªäÂ§©ÁöÑÂü∫Áü≥„ÄÇüôè

### Âü∫Á°ÄËÆæÊñΩÊîØÊåÅ

ÊÑüË∞¢ **GitHub** ÂÖçË¥πÊèê‰æõÁöÑÂü∫Á°ÄËÆæÊñΩÔºåËøôÊòØÊú¨È°πÁõÆÂæó‰ª•**‰∏ÄÈîÆ fork**‰æøÊç∑ËøêË°åÁöÑÊúÄÂ§ßÂâçÊèê„ÄÇ

### Êï∞ÊçÆÊîØÊåÅ

Êú¨È°πÁõÆ‰ΩøÁî® [newsnow](https://github.com/ourongxing/newsnow) È°πÁõÆÁöÑ API Ëé∑ÂèñÂ§öÂπ≥Âè∞Êï∞ÊçÆÔºåÁâπÂà´ÊÑüË∞¢‰ΩúËÄÖÊèê‰æõÁöÑÊúçÂä°„ÄÇ

ÁªèËÅîÁ≥ªÔºå‰ΩúËÄÖË°®Á§∫Êó†ÈúÄÊãÖÂøÉÊúçÂä°Âô®ÂéãÂäõÔºå‰ΩÜËøôÊòØÂü∫‰∫é‰ªñÁöÑÂñÑÊÑèÂíå‰ø°‰ªª„ÄÇËØ∑Â§ßÂÆ∂Ôºö
- **ÂâçÂæÄ [newsnow È°πÁõÆ](https://github.com/ourongxing/newsnow) ÁÇπ star ÊîØÊåÅ**
- Docker ÈÉ®ÁΩ≤Êó∂ÔºåËØ∑ÂêàÁêÜÊéßÂà∂Êé®ÈÄÅÈ¢ëÁéáÔºåÂãøÁ´≠Ê≥ΩËÄåÊ∏î

### Êé®ÂπøÂä©Âäõ

&gt; ÊÑüË∞¢‰ª•‰∏ãÂπ≥Âè∞Âíå‰∏™‰∫∫ÁöÑÊé®Ëçê(ÊåâÊó∂Èó¥ÊéíÂàó)

- [Â∞è‰ºóËΩØ‰ª∂](https://mp.weixin.qq.com/s/fvutkJ_NPUelSW9OGK39aA) - ÂºÄÊ∫êËΩØ‰ª∂Êé®ËçêÂπ≥Âè∞
- [LinuxDo Á§æÂå∫](https://linux.do/) - ÊäÄÊúØÁà±Â•ΩËÄÖÁöÑËÅöÈõÜÂú∞
- [ÈòÆ‰∏ÄÂ≥∞Âë®Âàä](https://github.com/ruanyf/weekly) - ÊäÄÊúØÂúàÊúâÂΩ±ÂìçÂäõÁöÑÂë®Âàä

### ËßÇ‰ºóÊîØÊåÅ

&gt; ÊÑüË∞¢**Áªô‰∫àËµÑÈáëÊîØÊåÅ**ÁöÑÊúãÂèã‰ª¨Ôºå‰Ω†‰ª¨ÁöÑÊÖ∑ÊÖ®Â∑≤ÂåñË∫´‰∏∫ÈîÆÁõòÊóÅÁöÑÈõ∂È£üÈ•ÆÊñôÔºåÈô™‰º¥ÁùÄÈ°πÁõÆÁöÑÊØè‰∏ÄÊ¨°Ëø≠‰ª£„ÄÇ
&gt;
&gt; **ÂÖ≥‰∫é&quot;‰∏ÄÂÖÉÁÇπËµû&quot;ÁöÑÂõûÂΩí**Ôºö
&gt; ÈöèÁùÄ v5.0.0 ÁâàÊú¨ÁöÑÂèëÂ∏ÉÔºåÈ°πÁõÆËøàÂÖ•‰∫Ü‰∏Ä‰∏™Êñ∞ÁöÑÈò∂ÊÆµ„ÄÇ‰∏∫‰∫ÜÊîØÊåÅÊó•ÁõäÂ¢ûÈïøÁöÑ API ÊàêÊú¨ÂíåÂíñÂï°Âõ†Ê∂àËÄóÔºå&quot;‰∏ÄÂÖÉÁÇπËµû&quot;ÈÄöÈÅìÁé∞Â∑≤ÈáçÊñ∞ÂºÄÂêØ„ÄÇ‰Ω†ÁöÑÊØè‰∏Ä‰ªΩÂøÉÊÑèÔºåÈÉΩÂ∞ÜËΩ¨Âåñ‰∏∫‰ª£Á†Å‰∏ñÁïåÈáåÁöÑ Token ÂíåÂä®Âäõ„ÄÇüöÄ [ÂâçÂæÄÊîØÊåÅ](#-ÊîØÊåÅÈ°πÁõÆ)

|           ÁÇπËµû‰∫∫            |  ÈáëÈ¢ù  |  Êó•Êúü  |             Â§áÊ≥®             |
| :-------------------------: | :----: | :----: | :-----------------------: |
|           D*5          |  1.8 * 3 | 2025.11.24  |    | 
|           *È¨º          |  1 | 2025.11.17  |    | 
|           *Ë∂Ö          |  10 | 2025.11.17  |    | 
|           R*w          |  10 | 2025.11.17  | Ëøô agent ÂÅöÁöÑÁâõÈÄºÂïä,ÂÖÑÂºü    | 
|           J*o          |  1 | 2025.11.17  | ÊÑüË∞¢ÂºÄÊ∫ê,Á•ùÂ§ß‰Ω¨‰∫ã‰∏öÊúâÊàê    | 
|           *Êô®          |  8.88  | 2025.11.16  | È°πÁõÆ‰∏çÈîô,Á†îÁ©∂Â≠¶‰π†‰∏≠    | 
|           *Êµ∑          |  1  | 2025.11.15  |    | 
|           *Âæ∑          |  1.99  | 2025.11.15  |    | 
|           *Áñè          |  8.8  | 2025.11.14  |  ÊÑüË∞¢ÂºÄÊ∫êÔºåÈ°πÁõÆÂæàÊ£íÔºåÊîØÊåÅ‰∏Ä‰∏ã   | 
|           M*e          |  10  | 2025.11.14  |  ÂºÄÊ∫ê‰∏çÊòìÔºåÂ§ß‰Ω¨ËæõËã¶‰∫Ü   | 
|           **ÊüØ          |  1  | 2025.11.14  |     | 
|           *‰∫ë          |  88  | 2025.11.13  |    Â•ΩÈ°πÁõÆÔºåÊÑüË∞¢ÂºÄÊ∫ê  | 
|           *W          |  6  | 2025.11.13  |      | 
|           *ÂáØ          |  1  | 2025.11.13  |      | 
|           ÂØπ*.          |  1  | 2025.11.13  |    Thanks for your TrendRadar  | 
|           s*y          |  1  | 2025.11.13  |      | 
|           **Áøî          |  10  | 2025.11.13  |   Â•ΩÈ°πÁõÆÔºåÁõ∏ËßÅÊÅ®ÊôöÔºåÊÑüË∞¢ÂºÄÊ∫êÔºÅ     | 
|           *Èü¶          |  9.9  | 2025.11.13  |   TrendRadarË∂ÖËµûÔºåËØ∑ËÄÅÂ∏àÂñùÂíñÂï°~     | 
|           h*p          |  5  | 2025.11.12  |   ÊîØÊåÅ‰∏≠ÂõΩÂºÄÊ∫êÂäõÈáèÔºåÂä†Ê≤πÔºÅ     | 
|           c*r          |  6  | 2025.11.12  |        | 
|           a*n          |  5  | 2025.11.12  |        | 
|           „ÄÇ*c          |  1  | 2025.11.12  |    ÊÑüË∞¢ÂºÄÊ∫êÂàÜ‰∫´    | 
|           *ËÆ∞          |  1  | 2025.11.11  |        | 
|           *‰∏ª          |  1  | 2025.11.10  |        | 
|           *‰∫Ü          |  10  | 2025.11.09  |        | 
|           *Êù∞          |  5  | 2025.11.08  |        | 
|           *ÁÇπ          |  8.80  | 2025.11.07  |   ÂºÄÂèë‰∏çÊòìÔºåÊîØÊåÅ‰∏Ä‰∏ã„ÄÇ     | 
|           Q*Q          |  6.66  | 2025.11.07  |   ÊÑüË∞¢ÂºÄÊ∫êÔºÅ     | 
|           C*e          |  1  | 2025.11.05  |        | 
|           Peter Fan          |  20  | 2025.10.29  |        | 
|           M*n          |  1  | 2025.10.27  |      ÊÑüË∞¢ÂºÄÊ∫ê  | 
|           *ËÆ∏          |  8.88  | 2025.10.23  |      ËÄÅÂ∏à Â∞èÁôΩ‰∏ÄÊûöÔºåÊë∏‰∫ÜÂá†Â§©‰∫ÜËøòÊ≤°Êï¥Ëµ∑Êù•ÔºåÊ±ÇÊïô  | 
|           Eason           |  1  | 2025.10.22  |      ËøòÊ≤°Êï¥ÊòéÁôΩÔºå‰ΩÜ‰Ω†Âú®ÂÅöÂ•Ω‰∫ã  | 
|           P*n           |  1  | 2025.10.20  |          |
|           *Êù∞           |  1  | 2025.10.19  |          |
|           *Âæê           |  1  | 2025.10.18  |          |
|           *Âøó           |  1  | 2025.10.17  |          |
|           *üòÄ           |  10  | 2025.10.16  |     ÁÇπËµû     |
|           **Êù∞           |  10  | 2025.10.16  |          |
|           *Âï∏           |  10  | 2025.10.16  |          |
|           *Á∫™           |  5  | 2025.10.14  | TrendRadar         |
|           J*d           |  1  | 2025.10.14  | Ë∞¢Ë∞¢‰Ω†ÁöÑÂ∑•ÂÖ∑ÔºåÂæàÂ•ΩÁé©...          |
|           *H           |  1  | 2025.10.14  |           |
|           ÈÇ£*O           |  10  | 2025.10.13  |           |
|           *ÂúÜ           |  1  | 2025.10.13  |           |
|           P*g           |  6  | 2025.10.13  |           |
|           Ocean           |  20  | 2025.10.12  |  ...ÁúüÁöÑÂ§™Ê£í‰∫ÜÔºÅÔºÅÔºÅÂ∞èÁôΩÁ∫ßÂà´‰πüËÉΩÁõ¥Êé•Áî®...         |
|           **Âüπ           |  5.2  | 2025.10.2  |  github-yzyf1312:ÂºÄÊ∫ê‰∏áÂ≤Å         |
|           *Ê§ø           |  3  | 2025.9.23  |  Âä†Ê≤πÔºåÂæà‰∏çÈîô         |
|           *üçç           |  10  | 2025.9.21  |           |
|           E*f           |  1  | 2025.9.20  |           |
|           *ËÆ∞            |  1  | 2025.9.20  |           |
|           z*u            |  2  | 2025.9.19  |           |
|           **Êòä            |  5  | 2025.9.17  |           |
|           *Âè∑            |  1  | 2025.9.15  |           |
|           T*T            |  2  | 2025.9.15  |  ÁÇπËµû         |
|           *ÂÆ∂            |  10  | 2025.9.10  |           |
|           *X            |  1.11  | 2025.9.3  |           |
|           *È£ô            |  20  | 2025.8.31  |  Êù•Ëá™ËÄÅÁ´•Ë∞¢Ë∞¢         |
|           *‰∏ã            |  1  | 2025.8.30  |           |
|           2*D            |  88  | 2025.8.13 ‰∏ãÂçà |           |
|           2*D            |  1  | 2025.8.13 ‰∏äÂçà |           |
|           S*o            |  1  | 2025.8.05 |   ÊîØÊåÅ‰∏Ä‰∏ã        |
|           *‰æ†            |  10  | 2025.8.04 |           |
|           x*x            |  2  | 2025.8.03 |  trendRadar Â•ΩÈ°πÁõÆ ÁÇπËµû          |
|           *Ëøú            |  1  | 2025.8.01 |            |
|           *ÈÇ™            |  5  | 2025.8.01 |            |
|           *Ê¢¶            |  0.1  | 2025.7.30 |            |
|           **Èæô            |  10  | 2025.7.29 |      ÊîØÊåÅ‰∏Ä‰∏ã      |


&lt;/details&gt;

&lt;br&gt;

## ü™Ñ ËµûÂä©ÂïÜ

&lt;div align=&quot;center&quot;&gt;

&gt; **Ëôö‰Ωç‰ª•ÂæÖ**

&lt;/div&gt;

&lt;br&gt;

&lt;a name=&quot;-ÊîØÊåÅÈ°πÁõÆ&quot;&gt;&lt;/a&gt;

### ‚ù§Ô∏è ËßâÂæóÂ•ΩÁî®ÔºüÊîØÊåÅ‰∏Ä‰∏ã

&gt; Ëã• TrendRadar Êõæ‰∏∫‰Ω†ÊçïÊçâ‰ª∑ÂÄºÔºå‰∏çÂ¶®‰∏∫ÂÆÉÊ≥®ÂÖ•Âä®ÂäõÔºåÂä©ÂÖ∂ÊåÅÁª≠ËøõÂåñ
&gt;
&gt; ÈáëÈ¢ùÈöèÊÑèÔºå1 ÂÖÉ‰πüÊòØÂØπÂºÄÊ∫êÁöÑÈºìÂä±„ÄÇÊ¨¢ËøéÂú®ËµûËµèÊó∂Â§áÊ≥®ÁïôË®Ä (¬¥‚ñΩ` É‚ô°∆™)

&lt;div align=&quot;center&quot;&gt;

| ÂæÆ‰ø°ËµûËµè | ÊîØ‰ªòÂÆùËµûËµè |
|:---:|:---:|
| &lt;img src=&quot;https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F2ae0a88d98079f7e876c2b4dc85233c6-9e8025.JPG&quot; width=&quot;240&quot; alt=&quot;ÂæÆ‰ø°ËµûËµè&quot;&gt; | &lt;img src=&quot;https://cdn-1258574687.cos.ap-shanghai.myqcloud.com/img/%2F2025%2F07%2F17%2F1ed4f20ab8e35be51f8e84c94e6e239b4-fe4947.JPG&quot; width=&quot;240&quot; alt=&quot;ÊîØ‰ªòÂÆùËµûËµè&quot;&gt; |

&lt;/div&gt;


### ü§ù ‰∫åÊ¨°ÂºÄÂèë‰∏éÂºïÁî®

Â¶ÇÊûú‰Ω†Âú®È°πÁõÆ‰∏≠‰ΩøÁî®ÊàñÂÄüÈâ¥‰∫ÜÊú¨È°πÁõÆÁöÑÊÄùË∑Ø„ÄÅÊ†∏ÂøÉ‰ª£Á†ÅÔºå**ÈùûÂ∏∏Ê¨¢Ëøé**Âú® README ÊàñÊñáÊ°£‰∏≠Ê≥®ÊòéÊù•Ê∫êÂπ∂ÈôÑ‰∏äÊú¨‰ªìÂ∫ìÈìæÊé•„ÄÇ

ËøôÂ∞ÜÊúâÂä©‰∫éÈ°πÁõÆÁöÑÊåÅÁª≠Áª¥Êä§ÂíåÁ§æÂå∫ÂèëÂ±ïÔºåÊÑüË∞¢‰Ω†ÁöÑÂ∞äÈáç‰∏éÊîØÊåÅÔºÅ‚ù§Ô∏è


### üí¨ ‰∫§ÊµÅ‰∏éÂèçÈ¶à

- **GitHub Issues**ÔºöÈÄÇÂêàÂÖ∑‰ΩìÁöÑÊäÄÊúØÈóÆÈ¢ò„ÄÇÊèêÈóÆÊó∂ËØ∑Êèê‰æõÂÆåÊï¥‰ø°ÊÅØÔºàÊà™Âõæ„ÄÅÈîôËØØÊó•ÂøóÁ≠âÔºâÔºåÊúâÂä©‰∫éÂø´ÈÄüÂÆö‰Ωç„ÄÇ
- **ÂÖ¨‰ºóÂè∑‰∫§ÊµÅ**ÔºöÂª∫ËÆÆ‰ºòÂÖàÂú®Áõ∏ÂÖ≥ÊñáÁ´†‰∏ãÁöÑÁïôË®ÄÂå∫‰∫§ÊµÅ„ÄÇËã•ÈúÄÂêéÂè∞ÊèêÈóÆÔºå**ÂÖàÁÇπËµû/Êé®Ëçê**ÊñáÁ´†ÊòØÊúÄÂ•ΩÁöÑ‚ÄúÊï≤Èó®Á†ñ‚ÄùÔºåÊàëÂú®ÂêéÂè∞ÈÉΩËÉΩÊÑüÂèóÂà∞Ëøô‰ªΩÂøÉÊÑèÂìü (¬¥‚ñΩ` É‚ô°∆™)„ÄÇ

&gt; **ÂèãÊÉÖÊèêÁ§∫**Ôºö        
&gt; Êú¨È°πÁõÆ‰∏∫ÂºÄÊ∫êÂàÜ‰∫´ÔºåÈùûÂïÜ‰∏ö‰∫ßÂìÅ„ÄÇÊää‰ΩúËÄÖÂΩìÊúãÂèãËÄåÈùûÂÆ¢ÊúçÔºåÊ≤üÈÄöÊïàÁéá‰ºöÊõ¥È´òÂì¶ÔºÅ     

&lt;div align=&quot;center&quot;&gt;

|ÂÖ¨‰ºóÂè∑ÂÖ≥Ê≥® |
|:---:|
| &lt;img src=&quot;_image/weixin.png&quot; width=&quot;500&quot; title=&quot;Á°ÖÂü∫Ëå∂Ê∞¥Èó¥&quot;/&gt; |

&lt;/div&gt;

&lt;br&gt;

## üìù Êõ¥Êñ∞Êó•Âøó

&gt; **üìå Êü•ÁúãÊúÄÊñ∞Êõ¥Êñ∞**Ôºö**[Âéü‰ªìÂ∫ìÊõ¥Êñ∞Êó•Âøó](https://github.com/sansan0/TrendRadar?tab=readme-ov-file#-Êõ¥Êñ∞Êó•Âøó)** Ôºö
- **ÊèêÁ§∫**ÔºöÂª∫ËÆÆÊü•Áúã„ÄêÂéÜÂè≤Êõ¥Êñ∞„ÄëÔºåÊòéÁ°ÆÂÖ∑‰ΩìÁöÑ„ÄêÂäüËÉΩÂÜÖÂÆπ„Äë


### 2026/02/09 - v6.0.0

&gt; **Breaking Change**ÔºöÈÖçÁΩÆÊñá‰ª∂ÂçáÁ∫ßÔºàconfig.yaml 2.0.0ÔºâÔºåÊóßÁâà `push_window` Âíå `analysis_window` ÈÖçÁΩÆ‰∏çÂÜçÂÖºÂÆπÔºåËØ∑ÂèÇËÄÉÊñ∞Áâà config.yaml ËøÅÁßª

- **Áªü‰∏ÄË∞ÉÂ∫¶Á≥ªÁªü**ÔºöÊñ∞Â¢û `timeline.yaml`ÔºåÁî®‰∏ÄÂ•óÈÖçÁΩÆÊéßÂà∂„Äå‰ªÄ‰πàÊó∂Èó¥ÈááÈõÜ / Êé®ÈÄÅ / AI ÂàÜÊûê„Äç
- **5 ÁßçÈ¢ÑËÆæÊ®°Êùø**Ôºö`always_on`ÔºàÂÖ®Â§©ÂÄôÔºåÈªòËÆ§Ôºâ„ÄÅ`morning_evening`ÔºàÊó©ÊôöÊ±áÊÄªÔºâ„ÄÅ`office_hours`ÔºàÂäûÂÖ¨Êó∂Èó¥Ôºâ„ÄÅ`night_owl`ÔºàÂ§úÁå´Â≠êÔºâ„ÄÅ`custom`ÔºàËá™ÂÆö‰πâÔºâÔºõ‰πüÊîØÊåÅÂú® `presets:` ‰∏ãÊñ∞Â¢ûËá™Â∑±ÁöÑÊ®°ÊùøÔºåÂè™Ë¶Å key ‰∏çÈáçÂ§çÔºåÁÑ∂ÂêéÂú® config.yaml ÈáåÂ°´‰Ω†ÁöÑÊ®°ÊùøÂêçÂç≥ÂèØ
- **ÁÅµÊ¥ªÁöÑÊó∂Èó¥ÊÆµÈÖçÁΩÆ**ÔºöÊîØÊåÅÂ∑•‰ΩúÊó•/Âë®Êú´Â∑ÆÂºÇÂåñ„ÄÅË∑®ÂçàÂ§úÊó∂Èó¥ÊÆµ„ÄÅper-period once ÂéªÈáç
- **ÂèØËßÜÂåñÈÖçÁΩÆÁºñËæëÂô®**Ôºö
  - Êñ∞Â¢û `timeline.yaml` ÁºñËæëÊ†áÁ≠æÈ°µÔºå‰∏é config.yaml / frequency_words.txt Âπ∂Âàó
  - È¢ÑËÆæÊ®°ÂºèÂç°ÁâáÈÄâÊã©ÔºöÁÇπÂáªÂç≥ÂàáÊç¢ÔºåËá™Âä®ÂêåÊ≠• config.yaml ÁöÑ `schedule.preset`
  - Âë®ËßÜÂõæÊó∂Èó¥Á∫øÔºö7 Â§© √ó 24 Â∞èÊó∂Ê∞¥Âπ≥Êù°ÔºåÁî®È¢úËâ≤Âå∫ÂàÜÊé®ÈÄÅ/ÂàÜÊûê/ÈááÈõÜÁä∂ÊÄÅ
  - ÂèØ‰∫§‰∫íÊéß‰ª∂ÔºöÂºÄÂÖ≥„ÄÅ‰∏ãÊãâÊ°Ü„ÄÅÊó∂Èó¥ÈÄâÊã©Âô®ÔºåÂè≥‰æß‰øÆÊîπÂÆûÊó∂ÂêåÊ≠•Âà∞Â∑¶‰æß YAML
  - Âë®Êò†Â∞Ñ‰∏ãÊãâÈÄâÊã©ÔºöÊ†πÊçÆÊó•ËÆ°ÂàíÂä®ÊÄÅÂ°´ÂÖÖÔºåÊãñÊãâÁÇπÂáªÂç≥ÂèØÂÆåÊàêË∞ÉÂ∫¶ÈÖçÁΩÆ
- **AI ÊèêÁ§∫ËØçÁ®≥ÂÆöÊÄß‰ºòÂåñ**Ôºàai_analysis_prompt.txt v2.0.0ÔºâÔºö
  - Ê†ºÂºèËßÑËåÉÁã¨Á´ãËØ¥ÊòéÔºöÂ∞ÜÊç¢Ë°å/Ê†áÁ≠æ/Â∫èÂè∑/Á¶ÅÊ≠¢‰∫ãÈ°π‰ªé JSON value ‰∏≠ÊäΩÂá∫Ôºå‰Ωú‰∏∫Áã¨Á´ãÁ´†ËäÇ
  - JSON Ê®°ÊùøÁÆÄÂåñÔºöÂ≠óÊÆµÊèèËø∞Áº©Áü≠‰∏∫‰∏ÄÂè•ËØù + Â≠óÊï∞ÈôêÂà∂ÔºåÂáèÂ∞ë AI ËæìÂá∫Ê†ºÂºèÊ∑∑‰π±
  - ÂéªÈô§ system prompt ‰∏≠ÁöÑ Markdown Ê†ºÂºèÔºå‰∏é&quot;Á¶ÅÊ≠¢ Markdown&quot;Êåá‰ª§‰øùÊåÅ‰∏ÄËá¥
  - ÊâÄÊúâ JSON Â≠óÊÆµÂ£∞Êòé‰∏∫ÂèØÈÄâÔºåÁº∫Â∞ë‰ªª‰ΩïÂ≠óÊÆµ‰∏ç‰ºöÊä•ÈîôÔºåÂ¢ûÂº∫ÂÆπÈîôÊÄß
- **Êñ∞Â¢ûÁã¨Á´ãÂ±ïÁ§∫Âå∫ AI Ê¶ÇÊã¨ÂàÜÊûê**Ôºà`ai_analysis.include_standalone`ÔºâÔºö
  - Êñ∞Â¢ûÁã¨Á´ãÂºÄÂÖ≥ÔºåÂºÄÂêØÂêé AI ÂØπÊØè‰∏™ standalone Ê∫êÁîüÊàêÊ†∏ÂøÉÊ¶ÇÊã¨
  - AI ÂàÜÊûê‰∏éÊé®ÈÄÅÂ±ïÁ§∫Ëß£ËÄ¶ÔºöÊó†ÈúÄÂºÄÂêØÁã¨Á´ãÂ±ïÁ§∫Âå∫ÁöÑÊé®ÈÄÅÊòæÁ§∫ÔºåAI ‰πüÂèØÁã¨Á´ãÂàÜÊûêÂÆåÊï¥ÁÉ≠Ê¶úÊï∞ÊçÆ
  - ÊîØÊåÅÁÉ≠Ê¶úÂπ≥Âè∞Âíå RSS Ê∫êÔºåÂê´ÊéíÂêç/Êó∂Èó¥/ËΩ®ËøπÊï∞ÊçÆ
  - ËΩ®ËøπÂàÜÊûê‰∏é `include_rank_timeline` ËÅîÂä®ÔºöÂºÄÂêØÊó∂Âà©Áî®ËΩ®ËøπÊï∞ÊçÆÂÅöÊ∑±Â∫¶Ë∂ãÂäøÂàÜÊûêÔºåÂÖ≥Èó≠Êó∂Âü∫‰∫éÊéíÂêçÂÅöÁÆÄË¶ÅÂà§Êñ≠
  - Êñ∞Â¢û `standalone_summaries` JSON Â≠óÊÆµÔºàÁã¨Á´ãÊ∫êÁÇπÈÄüËßàÔºâÔºåÊâÄÊúâÊé®ÈÄÅÊ∏†ÈÅìÂùáÂ∑≤ÈÄÇÈÖçÊ∏≤Êüì


### 2026/02/09 - mcp-v4.0.0

- **üî• AI Ê∂àÊÅØÁõ¥Êé®ÊâÄÊúâÊ∏†ÈÅì**ÔºöËÆ© AI ÂÜôÂ•ΩÁöÑÂÜÖÂÆπ‰∏ÄÈîÆÊé®ÈÄÅÂà∞È£û‰π¶„ÄÅÈíâÈíâ„ÄÅTelegram„ÄÅÈÇÆ‰ª∂Á≠â 9 ‰∏™Ê∏†ÈÅìÔºåMarkdown Ëá™Âä®ÈÄÇÈÖçÂêÑÂπ≥Âè∞Ê†ºÂºèÔºå‰∏çÁî®ÊìçÂøÉÊ†ºÂºèÂ∑ÆÂºÇ
- **Êñ∞Â¢ûÊ†ºÂºèÂåñÁ≠ñÁï•ÊåáÂçó**ÔºöÊñ∞Â¢û `get_channel_format_guide` Â∑•ÂÖ∑ÔºåÂëäËØâ AI ÊØè‰∏™Ê∏†ÈÅìÊîØÊåÅ‰ªÄ‰πàÊ†ºÂºè„ÄÅÊúâ‰ªÄ‰πàÈôêÂà∂ÔºåÁîüÊàêÁöÑÂÜÖÂÆπÊéíÁâàÊõ¥Â•ΩÁúã
- **Êô∫ËÉΩÂàÜÊâπÂèëÈÄÅ**ÔºöË∂ÖÈïøÊ∂àÊÅØËá™Âä®ÊåâÂêÑÊ∏†ÈÅìÂ≠óËäÇÈôêÂà∂ÊãÜÂàÜÔºàÈ£û‰π¶ 30KB„ÄÅÈíâÈíâ 20KB Á≠âÔºâÔºåÈÖçÁΩÆËØªÂèñËá™ config.yaml
- **‰øÆÂ§çÊ∏†ÈÅìËØØÊ£ÄÊµã**Ôºöntfy ‰∏çÂÜçÂõ†‰∏∫ÈªòËÆ§Âú∞ÂùÄË¢´ËØØÊä•‰∏∫&quot;Â∑≤ÈÖçÁΩÆ&quot;
- **‰ª£Á†ÅÂ§çÁî®‰ºòÂåñ**ÔºöÊâπÊ¨°Â§ÑÁêÜÂáΩÊï∞Áõ¥Êé•Â§çÁî® trendradar Ê†∏ÂøÉÊ®°ÂùóÔºå‰∏çÈáçÂ§çÈÄ†ËΩÆÂ≠ê


&lt;details&gt;
&lt;summary&gt;üëâ ÁÇπÂáªÂ±ïÂºÄÔºö&lt;strong&gt;ÂéÜÂè≤Êõ¥Êñ∞&lt;/strong&gt;&lt;/summary&gt;


### 2026/01/28 - v5.5.0

&gt; Âíå mcp ÂäüËÉΩ‰∏ÄÊ†∑, Ëøô‰∏™Â∞èÂ∑•ÂÖ∑Êàë‰πü‰∏çÊñ∞ÂºÄ‰∏Ä‰∏™‰ªìÂ∫ìÁª¥Êä§‰∫Ü, ÂèçÊ≠£Á∫ØÂâçÁ´Ø, ÈÉΩÊêÅ‰∏ÄËµ∑Âêß

- Â¢ûÂä† trendradar ÁöÑÂèØËßÜÂåñÈÖçÁΩÆÁºñËæëÂô®


### 2026/02/02 - mcp-v3.2.0

- **Êñ∞Â¢û read_article Â∑•ÂÖ∑**ÔºöÈÄöËøá Jina AI Reader ËØªÂèñÂçïÁØáÊñáÁ´†Ê≠£ÊñáÔºàMarkdown Ê†ºÂºèÔºâ
- **Êñ∞Â¢û read_articles_batch Â∑•ÂÖ∑**ÔºöÊâπÈáèËØªÂèñÂ§öÁØáÊñáÁ´†ÔºàÊúÄÂ§ö 5 ÁØáÔºåËá™Âä®ÈôêÈÄüÔºâ
- **Êé®ËçêÂ∑•‰ΩúÊµÅ**Ôºö`search_news(query=&quot;ÂÖ≥ÈîÆËØç&quot;, include_url=True)` ‚Üí `read_article(url=...)` ËØªÂèñÊ≠£Êñá
- **ÊñáÊ°£Êõ¥Êñ∞**ÔºöREADME-MCP-FAQ.md Âíå README-MCP-FAQ-EN.md Êñ∞Â¢û Q19-Q20 ÊñáÁ´†ËØªÂèñÁõ∏ÂÖ≥ËØ¥Êòé


### 2026/01/10 - mcp-v3.0.0~v3.1.5

- **Breaking Change**ÔºöÊâÄÊúâÂ∑•ÂÖ∑ËøîÂõûÂÄºÁªü‰∏Ä‰∏∫ `{success, summary, data, error}` ÁªìÊûÑ
- **ÂºÇÊ≠•‰∏ÄËá¥ÊÄß**ÔºöÊâÄÊúâ 21 ‰∏™Â∑•ÂÖ∑ÂáΩÊï∞‰ΩøÁî® `asyncio.to_thread()` ÂåÖË£ÖÂêåÊ≠•Ë∞ÉÁî®
- **MCP Resources**ÔºöÊñ∞Â¢û 4 ‰∏™ËµÑÊ∫êÔºàplatforms„ÄÅrss-feeds„ÄÅavailable-dates„ÄÅkeywordsÔºâ
- **RSS Â¢ûÂº∫**Ôºö`get_latest_rss` ÊîØÊåÅÂ§öÊó•Êü•ËØ¢Ôºàdays ÂèÇÊï∞ÔºâÔºåË∑®Êó•Êúü URL ÂéªÈáç
- **Ê≠£ÂàôÂåπÈÖç‰øÆÂ§ç**Ôºö`get_trending_topics` ÊîØÊåÅ `/pattern/` Ê≠£ÂàôËØ≠Ê≥ïÂíå `display_name`
- **ÁºìÂ≠ò‰ºòÂåñ**ÔºöÊñ∞Â¢û `make_cache_key()` ÂáΩÊï∞ÔºåÂèÇÊï∞ÊéíÂ∫è+MD5 ÂìàÂ∏åÁ°Æ‰øù‰∏ÄËá¥ÊÄß
- **Êñ∞Â¢û check_version Â∑•ÂÖ∑**ÔºöÊîØÊåÅÂêåÊó∂Ê£ÄÊü• TrendRadar Âíå MCP Server ÁâàÊú¨Êõ¥Êñ∞


### 2026/01/23 - v5.4.0

- Â¢ûÂä† AI ÂàÜÊûêÊ®°ÂºèÁöÑÁã¨Á´ãÊéßÂà∂ÂäüËÉΩÔºåÂèØÈÄâ follow_report | daily | current | incremental 
- Êñ∞Â¢û AI ÂàÜÊûêÊó∂Èó¥Á™óÂè£ÊéßÂà∂ÔºåÊîØÊåÅËá™ÂÆö‰πâËøêË°åÊÆµÂèäÊØèÊó•È¢ëÊ¨°ÈôêÂà∂
- Â¢ûÂä†ÈÖçÁΩÆÊñá‰ª∂ÁâàÊú¨ÁÆ°ÁêÜÂäüËÉΩ
- ‰øÆÂ§çËã•Âπ≤bug


### 2026/01/19 - v5.3.0

&gt; **ÈáçÂ§ßÈáçÊûÑÔºöAI Ê®°ÂùóËøÅÁßªËá≥ LiteLLM**

- **Áªü‰∏Ä AI Êé•Âè£**Ôºö‰ΩøÁî® LiteLLM Êõø‰ª£ÊâãÂä®ÂÆûÁé∞ÔºåÊîØÊåÅ 100+ AI Êèê‰æõÂïÜ
- **ÁÆÄÂåñÈÖçÁΩÆ**ÔºöÁßªÈô§ `provider` Â≠óÊÆµÔºåÊîπÁî® `model: &quot;provider/model_name&quot;` Ê†ºÂºè
- **Êñ∞Â¢ûÂäüËÉΩ**ÔºöËá™Âä®ÈáçËØï (`num_retries`)„ÄÅÂ§áÁî®Ê®°Âûã (`fallback_models`)
- **ÈÖçÁΩÆÂèòÊõ¥**Ôºö
  - `ai.provider` ‚Üí ÁßªÈô§ÔºàÂ∑≤ÂêàÂπ∂Âà∞ modelÔºâ
  - `ai.base_url` ‚Üí `ai.api_base`
  - `AI_PROVIDER` ÁéØÂ¢ÉÂèòÈáè ‚Üí ÁßªÈô§
  - `AI_BASE_URL` ÁéØÂ¢ÉÂèòÈáè ‚Üí `AI_API_BASE`
- **Ê®°ÂûãÊ†ºÂºèÁ§∫‰æã**Ôºö
  - DeepSeek: `deepseek/deepseek-chat`
  - OpenAI: `openai/gpt-4o`
  - Gemini: `gemini/gemini-2.5-flash`
  - Anthropic: `anthropic/claude-3-5-sonnet`

### 2026/01/17 - v5.2.0

&gt; ‰∏ªË¶ÅËßÅ config.yaml ÊèèËø∞

**üåê AI ÁøªËØëÂäüËÉΩ**

- **Â§öËØ≠Ë®ÄÁøªËØë**ÔºöÊîØÊåÅÂ∞ÜÊé®ÈÄÅÂÜÖÂÆπÁøªËØë‰∏∫‰ªªÊÑèËØ≠Ë®Ä
- **ÊâπÈáèÁøªËØë**ÔºöÊô∫ËÉΩÊâπÈáèÂ§ÑÁêÜÔºåÂáèÂ∞ë API Ë∞ÉÁî®Ê¨°Êï∞
- **Ëá™ÂÆö‰πâÊèêÁ§∫ËØç**ÔºöÊîØÊåÅËá™ÂÆö‰πâÁøªËØëÈ£éÊ†º

**üîß ÈÖçÁΩÆÊû∂ÊûÑ‰ºòÂåñ**

- **AI Ê®°ÂûãÈÖçÁΩÆÁã¨Á´ã**ÔºöÂàÜÊûêÂíåÁøªËØëÂÖ±‰∫´Ê®°ÂûãÈÖçÁΩÆ
- **Âå∫ÂüüÂºÄÂÖ≥Áªü‰∏Ä**ÔºöÁªü‰∏ÄÁÆ°ÁêÜÊé®ÈÄÅÂå∫ÂüüÊòæÁ§∫
- **Âå∫ÂüüÊéíÂ∫èËá™ÂÆö‰πâ**ÔºöÊîØÊåÅËá™ÂÆö‰πâÂêÑÂå∫ÂüüÁöÑÊòæÁ§∫È°∫Â∫è

**‚ú® AI ÂàÜÊûêÂ¢ûÂº∫**

- **AI ÂàÜÊûêÂµåÂÖ• HTML**ÔºöÂàÜÊûêÁªìÊûúÁõ¥Êé•ÂµåÂÖ• HTML Êä•ÂëäÔºåÈÇÆ‰ª∂ÈÄöÁü•Áõ¥Êé•‰ΩøÁî®
- **ÂØåÊ†∑Âºè AI Âå∫Âùó**ÔºöÊ∏êÂèòËìùËâ≤ËÉåÊôØÂç°ÁâáÂºèÂ∏ÉÂ±ÄÔºåÊ∏ÖÊô∞ÂàÜÈöîÂêÑÂàÜÊûêÁª¥Â∫¶
- **ÊéíÂêçÊó∂Èó¥Á∫øÊîØÊåÅ**ÔºöAI ÂèØËé∑ÂèñÊØèÊù°Êñ∞ÈóªÂú®ÊØè‰∏™ÊäìÂèñÊó∂Èó¥ÁÇπÁöÑÁ≤æÁ°ÆÊéíÂêç
- **ÊùøÂùóÈáçÁªÑ (7‚Üí4)**ÔºöÊï¥Âêà‰∏∫Ê†∏ÂøÉÁÉ≠ÁÇπÊÄÅÂäø„ÄÅËàÜËÆ∫È£éÂêë‰∫âËÆÆ„ÄÅÂºÇÂä®‰∏éÂº±‰ø°Âè∑„ÄÅÁ†îÂà§Á≠ñÁï•Âª∫ËÆÆ

**üîß Â§öÊ®°ÂûãÈÄÇÈÖç**

- **ÈÄöÁî®ÂèÇÊï∞ÈÄè‰º†**ÔºöÊîØÊåÅÂêë API ÈÄè‰º†‰ªªÊÑèÈ´òÁ∫ßÂèÇÊï∞
- **Gemini ÈÄÇÈÖç**ÔºöÂéüÁîüÂèÇÊï∞ÊîØÊåÅÔºåÂÜÖÁΩÆÂÆâÂÖ®Á≠ñÁï•ÊîæÂÆΩ

**üêõ Bug ‰øÆÂ§ç**

- ‰øÆÂ§çËã•Âπ≤Â∑≤Áü•ÈóÆÈ¢òÔºåÊèêÂçáÁ≥ªÁªüÁ®≥ÂÆöÊÄß

### 2026/01/10 - v5.0.0

&gt; **ÂºÄÂèëÂ∞èÊèíÊõ≤**Ôºö
&gt; Ëá¥Êï¨ÈÇ£‰∏™Èô™‰º¥Êàë‰∏§Âπ¥Â§ö„ÄÅÂç¥Âú®ÂàöÁª≠Ë¥πÂêéÂèçÊâãÂºπÂá∫ `&quot;This organization has been disabled&quot;` ÁöÑÊüê C ÂéÇÊ®°Âûã

**‚ú® Êé®ÈÄÅÂÜÖÂÆπ&quot;‰∫îÂ§ßÊùøÂùó&quot;ÈáçÊûÑ**

Êú¨Ê¨°Êõ¥Êñ∞ÂØπÊé®ÈÄÅÊ∂àÊÅØËøõË°å‰∫ÜÂå∫ÂüüÂåñÈáçÊûÑÔºåÁé∞Âú®Êé®ÈÄÅÂÜÖÂÆπÊ∏ÖÊô∞Âú∞ÂàíÂàÜ‰∏∫‰∫îÂ§ßÊ†∏ÂøÉÊùøÂùóÔºö

1.  **üìä ÁÉ≠Ê¶úÊñ∞Èóª**ÔºöÊ†πÊçÆ‰Ω†ÁöÑÂÖ≥ÈîÆËØçÁ≤æÂáÜÁ≠õÈÄâÂêéÁöÑÂÖ®ÁΩëÁÉ≠ÁÇπËÅöÂêà„ÄÇ
2.  **üì∞ RSS ËÆ¢ÈòÖ**Ôºö‰Ω†ÁöÑ‰∏™ÊÄßÂåñËÆ¢ÈòÖÊ∫êÂÜÖÂÆπÔºåÊîØÊåÅÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑ„ÄÇ
3.  **üÜï Êú¨Ê¨°Êñ∞Â¢û**ÔºöÂÆûÊó∂ÊçïÊçâËá™‰∏äÊ¨°ËøêË°å‰ª•Êù•ÁöÑÂÖ®Êñ∞ÁÉ≠ÁÇπÔºàÂ∏¶ üÜï Ê†áËÆ∞Ôºâ„ÄÇ
4.  **üìã Áã¨Á´ãÂ±ïÁ§∫Âå∫**ÔºöÊåáÂÆöÂπ≥Âè∞ÁöÑÂÆåÊï¥ÁÉ≠Ê¶úÊàñ RSS Ê∫êÂ±ïÁ§∫Ôºå**ÂÆåÂÖ®‰∏çÂèóÂÖ≥ÈîÆËØçËøáÊª§ÈôêÂà∂**„ÄÇ
5.  **‚ú® AI ÂàÜÊûêÊùøÂùó**ÔºöÁî± AI È©±Âä®ÁöÑÊ∑±Â∫¶Ê¥ûÂØüÔºåÂåÖÂê´Ë∂ãÂäøÊ¶ÇËø∞„ÄÅÁÉ≠Â∫¶Ëµ∞ÂäøÂèä**ÊûÅÂÖ∂ÈáçË¶Å**ÁöÑÊÉÖÊÑüÂÄæÂêëÂàÜÊûê„ÄÇ

**‚ú® AI Êô∫ËÉΩÂàÜÊûêÊé®ÈÄÅÂäüËÉΩ**

- **AI ÂàÜÊûêÈõÜÊàê**Ôºö‰ΩøÁî® AI Â§ßÊ®°ÂûãÂØπÊé®ÈÄÅÂÜÖÂÆπËøõË°åÊ∑±Â∫¶ÂàÜÊûêÔºåËá™Âä®ÁîüÊàêÁÉ≠ÁÇπË∂ãÂäøÊ¶ÇËø∞„ÄÅÂÖ≥ÈîÆËØçÁÉ≠Â∫¶ÂàÜÊûê„ÄÅË∑®Âπ≥Âè∞ÂÖ≥ËÅî„ÄÅÊΩúÂú®ÂΩ±ÂìçËØÑ‰º∞Á≠â
- **ÊÉÖÊÑüÂÄæÂêëÂàÜÊûê**ÔºöÊñ∞Â¢ûÊ∑±Â∫¶ÊÉÖÊÑüËØÜÂà´ÔºåÁ≤æÂáÜÊçïÊçâËàÜËÆ∫ÁöÑÊ≠£Ë¥üÈù¢„ÄÅ‰∫âËÆÆÊàñÊãÖÂøßÊÉÖÁª™
- **Â§ö AI Êèê‰æõÂïÜÊîØÊåÅ**ÔºöÊîØÊåÅ DeepSeekÔºàÈªòËÆ§ÔºåÊÄß‰ª∑ÊØîÈ´òÔºâ„ÄÅOpenAI„ÄÅGoogle Gemini Âèä‰ªªÊÑè OpenAI ÂÖºÂÆπÊé•Âè£
- **‰∏§ÁßçÊé®ÈÄÅÊ®°Âºè**Ôºö`only_analysis`Ôºà‰ªÖ AI ÂàÜÊûêÔºâ„ÄÅ`both`Ôºà‰∏§ËÄÖÈÉΩÊé®ÈÄÅÔºâ
- **Ëá™ÂÆö‰πâÊèêÁ§∫ËØç**ÔºöÈÄöËøá `config/ai_analysis_prompt.txt` Êñá‰ª∂Ëá™ÂÆö‰πâ AI ÂàÜÊûêËßíËâ≤ÂíåËæìÂá∫Ê†ºÂºè
- **Â§öÁª¥Â∫¶Êï∞ÊçÆÂàÜÊûê**ÔºöAI ÂèØÂàÜÊûêÊéíÂêçÂèòÂåñ„ÄÅÁÉ≠Â∫¶ÊåÅÁª≠Êó∂Èó¥„ÄÅË∑®Âπ≥Âè∞Ë°®Áé∞„ÄÅË∂ãÂäøÈ¢ÑÊµãÁ≠â

**üìã Áã¨Á´ãÂ±ïÁ§∫Âå∫ÂäüËÉΩ**

- **ÂÆåÊï¥ÁÉ≠Ê¶úÂ±ïÁ§∫**ÔºöÊåáÂÆöÂπ≥Âè∞ÁöÑÂÆåÊï¥ÁÉ≠Ê¶úÂçïÁã¨Â±ïÁ§∫Ôºå‰∏çÂèóÂÖ≥ÈîÆËØçËøáÊª§ÂΩ±Âìç
- **RSS Áã¨Á´ãÂ±ïÁ§∫**ÔºöRSS Ê∫êÂÜÖÂÆπÂèØÂÆåÊï¥Â±ïÁ§∫ÔºåÈÄÇÂêàÂÜÖÂÆπËæÉÂ∞ëÁöÑËÆ¢ÈòÖÊ∫ê
- **ÁÅµÊ¥ªÈÖçÁΩÆ**ÔºöÊîØÊåÅÈÖçÁΩÆÂ±ïÁ§∫Âπ≥Âè∞ÂàóË°®„ÄÅRSS Ê∫êÂàóË°®„ÄÅÊúÄÂ§ßÂ±ïÁ§∫Êù°Êï∞

**üìä Êé®ÈÄÅ‰ΩìÈ™åÈáçÊûÑ**

- **ÊéíÁâàÂçáÁ∫ß**ÔºöÈáçÊñ∞ËÆæËÆ°Âπ∂Áªü‰∏ÄÂêÑÊ∏†ÈÅìÁªüËÆ°Â§¥ÈÉ®ÔºåÂº∫ÂåñÂå∫ÂùóÁªÑÁªáÔºåÊ∂àÊÅØÂ±ÇÊ¨°‰∏ÄÁõÆ‰∫ÜÁÑ∂
- **ÈÖçÁΩÆÁÆÄÂåñ**Ôºö‰ºòÂåñÈ£û‰π¶Á≠âÈÄöÁü•Ê∏†ÈÅìÁöÑÈÖçÁΩÆÈÄªËæëÔºå‰∏äÊâãÊõ¥ÁÆÄÂçï
- **ÁÉ≠Â∫¶Ë∂ãÂäøÁÆ≠Â§¥**ÔºöÊñ∞Â¢û üî∫(‰∏äÂçá)„ÄÅüîª(‰∏ãÈôç)„ÄÅ‚ûñ(ÊåÅÂπ≥) Ë∂ãÂäøÊ†áËØÜÔºåÁõ¥ËßÇÂ±ïÁ§∫ÁÉ≠Â∫¶ÂèòÂåñ
- **ÈÄöÁî® Webhook**ÔºöÊîØÊåÅËá™ÂÆö‰πâ Webhook URL Âíå JSON Ê®°ÊùøÔºåËΩªÊùæÈÄÇÈÖç Discord„ÄÅMatrix„ÄÅIFTTT Á≠â‰ªªÊÑèÂπ≥Âè∞

**üîß ÈÖçÁΩÆ‰ºòÂåñ**

- **È¢ëÁéáËØçÈÖçÁΩÆÂ¢ûÂº∫**ÔºöÊñ∞Â¢û `[ÁªÑÂà´Âêç]` ËØ≠Ê≥ïÔºåÊîØÊåÅ `#` Ê≥®ÈáäË°åÔºåÈÖçÁΩÆÊõ¥Ê∏ÖÊô∞ÔºàÊÑüË∞¢ [@songge8](https://github.com/sansan0/TrendRadar/issues/752) ÊèêÂá∫ÁöÑÂª∫ËÆÆÔºâ
- **ÁéØÂ¢ÉÂèòÈáèÊîØÊåÅ**ÔºöAI ÂàÜÊûêÁõ∏ÂÖ≥ÈÖçÁΩÆÊîØÊåÅÁéØÂ¢ÉÂèòÈáèË¶ÜÁõñÔºà`AI_API_KEY`„ÄÅ`AI_PROVIDER` Á≠âÔºâ

&gt; üí° ËØ¶ÁªÜÈÖçÁΩÆÊïôÁ®ãËßÅ [ËÆ© AI Â∏ÆÊàëÂàÜÊûêÁÉ≠ÁÇπ](#12-ËÆ©-ai-Â∏ÆÊàëÂàÜÊûêÁÉ≠ÁÇπ)


### 2026/01/02 - v4.7.0

- **‰øÆÂ§ç RSS HTML ÊòæÁ§∫**Ôºö‰øÆÂ§ç RSS Êï∞ÊçÆÊ†ºÂºè‰∏çÂåπÈÖçÂØºËá¥ÁöÑÊ∏≤ÊüìÈóÆÈ¢òÔºåÁé∞Âú®ÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑÊ≠£Á°ÆÊòæÁ§∫
- **Êñ∞Â¢ûÊ≠£ÂàôË°®ËææÂºèËØ≠Ê≥ï**ÔºöÂÖ≥ÈîÆËØçÈÖçÁΩÆÊîØÊåÅ `/pattern/` Ê≠£ÂàôËØ≠Ê≥ïÔºåËß£ÂÜ≥Ëã±ÊñáÂ≠êÂ≠óÁ¨¶‰∏≤ËØØÂåπÈÖçÈóÆÈ¢òÔºàÂ¶Ç `ai` ÂåπÈÖç `training`Ôºâ[üìñ Êü•ÁúãËØ≠Ê≥ïËØ¶Ëß£](#ÂÖ≥ÈîÆËØçÂü∫Á°ÄËØ≠Ê≥ï)
- **Êñ∞Â¢ûÊòæÁ§∫ÂêçÁß∞ËØ≠Ê≥ï**Ôºö‰ΩøÁî® `=&gt; Â§áÊ≥®` ÁªôÂ§çÊùÇÁöÑÊ≠£ÂàôË°®ËææÂºèËµ∑‰∏™Â•ΩËÆ∞ÁöÑÂêçÂ≠óÔºåÊé®ÈÄÅÊ∂àÊÅØÊòæÁ§∫Êõ¥Ê∏ÖÊô∞ÔºàÂ¶Ç `/\bai\b/ =&gt; AIÁõ∏ÂÖ≥`Ôºâ
- **‰∏ç‰ºöÂÜôÊ≠£ÂàôÔºü** README Êñ∞Â¢û AI ÁîüÊàêÊ≠£ÂàôÁöÑÂºïÂØºÔºåÂëäËØâ ChatGPT/Gemini/DeepSeek ‰Ω†ÊÉ≥ÂåπÈÖç‰ªÄ‰πàÔºåËÆ© AI Â∏Æ‰Ω†ÂÜô


### 2025/12/30 - mcp-v2.0.0

- **Êû∂ÊûÑË∞ÉÊï¥**ÔºöÁßªÈô§ TXT ÊîØÊåÅÔºåÁªü‰∏Ä‰ΩøÁî® SQLite Êï∞ÊçÆÂ∫ì
- **RSS Êü•ËØ¢**ÔºöÊñ∞Â¢û `get_latest_rss`„ÄÅ`search_rss`„ÄÅ`get_rss_feeds_status`
- **Áªü‰∏ÄÊêúÁ¥¢**Ôºö`search_news` ÊîØÊåÅ `include_rss` ÂèÇÊï∞ÂêåÊó∂ÊêúÁ¥¢ÁÉ≠Ê¶úÂíå RSS


### 2026/01/01 - v4.6.0

- **‰øÆÂ§ç RSS HTML ÊòæÁ§∫**ÔºöÂ∞Ü RSS ÂÜÖÂÆπÂêàÂπ∂Âà∞ÁÉ≠Ê¶ú HTML È°µÈù¢ÔºåÊåâÊ∫êÂàÜÁªÑÊòæÁ§∫
- **Êñ∞Â¢û display_mode ÈÖçÁΩÆ**ÔºöÊîØÊåÅ `keyword`ÔºàÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑÔºâÂíå `platform`ÔºàÊåâÂπ≥Âè∞ÂàÜÁªÑÔºâ‰∏§ÁßçÊòæÁ§∫Ê®°Âºè


### 2025/12/30 - v4.5.0

- **RSS ËÆ¢ÈòÖÊ∫êÊîØÊåÅ**ÔºöÊñ∞Â¢û RSS/Atom ÊäìÂèñÔºåÊåâÂÖ≥ÈîÆËØçÂàÜÁªÑÁªüËÆ°Ôºà‰∏éÁÉ≠Ê¶úÊ†ºÂºè‰∏ÄËá¥Ôºâ
- **Â≠òÂÇ®ÁªìÊûÑÈáçÊûÑ**ÔºöÊâÅÂπ≥ÂåñÁõÆÂΩïÁªìÊûÑ `output/{type}/{date}.db`
- **Áªü‰∏ÄÊéíÂ∫èÈÖçÁΩÆ**Ôºö`sort_by_position_first` ÂêåÊó∂ÂΩ±ÂìçÁÉ≠Ê¶úÂíå RSS
- **ÈÖçÁΩÆÁªìÊûÑÈáçÊûÑ**Ôºö`config.yaml` ÈáçÊñ∞ÁªÑÁªá‰∏∫ 7 ‰∏™ÈÄªËæëÂàÜÁªÑÔºàapp„ÄÅreport„ÄÅnotification„ÄÅstorage„ÄÅplatforms„ÄÅrss„ÄÅadvancedÔºâÔºåÈÖçÁΩÆË∑ØÂæÑÊõ¥Ê∏ÖÊô∞


### 2025/12/26 - mcp-v1.2.0

  **MCP Ê®°ÂùóÊõ¥Êñ∞ - ‰ºòÂåñÂ∑•ÂÖ∑ÈõÜÔºåÊñ∞Â¢ûËÅöÂêàÂØπÊØîÂäüËÉΩÔºåÂêàÂπ∂ÂÜó‰ΩôÂ∑•ÂÖ∑:**
  - Êñ∞Â¢û `aggregate_news` Â∑•ÂÖ∑ - Ë∑®Âπ≥Âè∞Êñ∞ÈóªÂéªÈáçËÅöÂêà
  - Êñ∞Â¢û `compare_periods` Â∑•ÂÖ∑ - Êó∂ÊúüÂØπÊØîÂàÜÊûêÔºàÂë®ÁéØÊØî/ÊúàÁéØÊØîÔºâ
  - ÂêàÂπ∂ `find_similar_news` + `search_related_news_history` ‚Üí `find_related_news`
  - Â¢ûÂº∫ `get_trending_topics` - Êñ∞Â¢û `auto_extract` Ê®°ÂºèËá™Âä®ÊèêÂèñÁÉ≠ÁÇπ
  - ‰øÆÂ§çËã•Âπ≤bug
  - ÂêåÊ≠•Êõ¥Êñ∞ README-MCP-FAQ.md ÊñáÊ°£ÁöÑ‰∏≠Ëã±ÊñáÁâà (Q1-Q18)


### 2025/12/20 - v4.0.3

- Êñ∞Â¢û URL Ê†áÂáÜÂåñÂäüËÉΩÔºåËß£ÂÜ≥ÂæÆÂçöÁ≠âÂπ≥Âè∞Âõ†Âä®ÊÄÅÂèÇÊï∞ÔºàÂ¶Ç `band_rank`ÔºâÂØºËá¥ÁöÑÈáçÂ§çÊé®ÈÄÅÈóÆÈ¢ò
- ‰øÆÂ§çÂ¢ûÈáèÊ®°ÂºèÊ£ÄÊµãÈÄªËæëÔºåÊ≠£Á°ÆËØÜÂà´ÂéÜÂè≤Ê†áÈ¢ò


### 2025/12/17 - v4.0.1

- StorageManager Ê∑ªÂä†Êé®ÈÄÅËÆ∞ÂΩï‰ª£ÁêÜÊñπÊ≥ï
- S3 ÂÆ¢Êà∑Á´ØÂàáÊç¢Ëá≥ virtual-hosted style ‰ª•ÊèêÂçáÂÖºÂÆπÊÄßÔºàÊîØÊåÅËÖæËÆØ‰∫ë COS Á≠âÊõ¥Â§öÊúçÂä°Ôºâ


### 2025/12/13 - mcp-v1.1.0

  **MCP Ê®°ÂùóÊõ¥Êñ∞:**
  - ÈÄÇÈÖç v4.0.0ÔºåÂêåÊó∂‰πüÂÖºÂÆπ v3.x ÁöÑÊï∞ÊçÆ
  - Êñ∞Â¢ûÂ≠òÂÇ®ÂêåÊ≠•Â∑•ÂÖ∑Ôºö`sync_from_remote`„ÄÅ`get_storage_status`„ÄÅ`list_available_dates`


### 2025/12/13 - v4.0.0

**üéâ ÈáçÂ§ßÊõ¥Êñ∞ÔºöÂÖ®Èù¢ÈáçÊûÑÂ≠òÂÇ®ÂíåÊ†∏ÂøÉÊû∂ÊûÑ**

- **Â§öÂ≠òÂÇ®ÂêéÁ´ØÊîØÊåÅ**ÔºöÂºïÂÖ•ÂÖ®Êñ∞ÁöÑÂ≠òÂÇ®Ê®°ÂùóÔºåÊîØÊåÅÊú¨Âú∞ SQLite ÂíåËøúÁ®ã‰∫ëÂ≠òÂÇ®ÔºàS3 ÂÖºÂÆπÂçèËÆÆÔºå‰æãÂ¶Ç Cloudflare R2ÔºâÔºåÈÄÇÂ∫î GitHub Actions„ÄÅDocker ÂíåÊú¨Âú∞ÁéØÂ¢É„ÄÇ
- **Êï∞ÊçÆÂ∫ìÁªìÊûÑ‰ºòÂåñ**ÔºöÈáçÊûÑ SQLite Êï∞ÊçÆÂ∫ìË°®ÁªìÊûÑÔºåÊèêÂçáÊï∞ÊçÆÊïàÁéáÂíåÊü•ËØ¢ËÉΩÂäõ„ÄÇ
- **Ê†∏ÂøÉ‰ª£Á†ÅÊ®°ÂùóÂåñ**ÔºöÂ∞Ü‰∏ªÁ®ãÂ∫èÈÄªËæëÊãÜÂàÜ‰∏∫ trendradar ÂåÖÁöÑÂ§ö‰∏™Ê®°ÂùóÔºåÊòæËëóÊèêÂçá‰ª£Á†ÅÂèØÁª¥Êä§ÊÄß„ÄÇ
- **Â¢ûÂº∫ÂäüËÉΩ**ÔºöÂÆûÁé∞Êó•ÊúüÊ†ºÂºèÊ†áÂáÜÂåñ„ÄÅÊï∞ÊçÆ‰øùÁïôÁ≠ñÁï•„ÄÅÊó∂Âå∫ÈÖçÁΩÆÊîØÊåÅ„ÄÅÊó∂Èó¥ÊòæÁ§∫‰ºòÂåñÔºåÂπ∂‰øÆÂ§çËøúÁ®ãÂ≠òÂÇ®Êï∞ÊçÆÊåÅ‰πÖÂåñÈóÆÈ¢òÔºåÁ°Æ‰øùÊï∞ÊçÆÂêàÂπ∂ÁöÑÂáÜÁ°ÆÊÄß„ÄÇ
- **Ê∏ÖÁêÜÂíåÂÖºÂÆπ**ÔºöÁßªÈô§‰∫ÜÂ§ßÈÉ®ÂàÜÂéÜÂè≤ÂÖºÂÆπ‰ª£Á†ÅÔºåÁªü‰∏Ä‰∫ÜÊï∞ÊçÆÂ≠òÂÇ®ÂíåËØªÂèñÊñπÂºè„ÄÇ


### 2025/12/03 - v3.5.0

**üéâ Ê†∏ÂøÉÂäüËÉΩÂ¢ûÂº∫**

1. **Â§öË¥¶Âè∑Êé®ÈÄÅÊîØÊåÅ**
   - ÊâÄÊúâÊé®ÈÄÅÊ∏†ÈÅìÔºàÈ£û‰π¶„ÄÅÈíâÈíâ„ÄÅ‰ºÅ‰∏öÂæÆ‰ø°„ÄÅTelegram„ÄÅntfy„ÄÅBark„ÄÅSlackÔºâÊîØÊåÅÂ§öË¥¶Âè∑ÈÖçÁΩÆ
   - ‰ΩøÁî®ÂàÜÂè∑ `;` ÂàÜÈöîÂ§ö‰∏™Ë¥¶Âè∑Ôºå‰æãÂ¶ÇÔºö`FEISHU_WEBHOOK_URL=url1;url2`
   - Ëá™Âä®È™åËØÅÈÖçÂØπÈÖçÁΩÆÔºàÂ¶Ç Telegram ÁöÑ token Âíå chat_idÔºâÊï∞Èáè‰∏ÄËá¥ÊÄß

2. **Êé®ÈÄÅÂå∫ÂüüÈÖçÁΩÆ**
   - ÈÄöËøá `display.region_order` Ëá™ÂÆö‰πâÂêÑÂå∫ÂüüÁöÑÊòæÁ§∫È°∫Â∫èÔºàv5.2.0 Êõø‰ª£Âéü `reverse_content_order`Ôºâ
   - ÈÄöËøá `display.regions` ÊéßÂà∂ÂêÑÂå∫ÂüüÊòØÂê¶ÊòæÁ§∫ÔºàÁÉ≠Ê¶ú„ÄÅÊñ∞Â¢ûÁÉ≠ÁÇπ„ÄÅRSS„ÄÅÁã¨Á´ãÂ±ïÁ§∫Âå∫„ÄÅAI ÂàÜÊûêÔºâ

3. **ÂÖ®Â±ÄËøáÊª§ÂÖ≥ÈîÆËØç**
   - Êñ∞Â¢û `[GLOBAL_FILTER]` Âå∫ÂüüÊ†áËÆ∞ÔºåÊîØÊåÅÂÖ®Â±ÄËøáÊª§‰∏çÊÉ≥ÁúãÂà∞ÁöÑÂÜÖÂÆπ
   - ÈÄÇÁî®Âú∫ÊôØÔºöËøáÊª§ÂπøÂëä„ÄÅËê•ÈîÄ„ÄÅ‰ΩéË¥®ÂÜÖÂÆπÁ≠â

**üê≥ Docker ÂèåË∑ØÂæÑ HTML ÁîüÊàê‰ºòÂåñ**

- **ÈóÆÈ¢ò‰øÆÂ§ç**ÔºöËß£ÂÜ≥ Docker ÁéØÂ¢É‰∏ã `index.html` Êó†Ê≥ïÂêåÊ≠•Âà∞ÂÆø‰∏ªÊú∫ÁöÑÈóÆÈ¢ò
- **ÂèåË∑ØÂæÑÁîüÊàê**ÔºöÂΩìÊó•Ê±áÊÄª HTML ÂêåÊó∂ÁîüÊàêÂà∞‰∏§‰∏™‰ΩçÁΩÆ
  - `index.html`ÔºàÈ°πÁõÆÊ†πÁõÆÂΩïÔºâÔºö‰æõ GitHub Pages ËÆøÈóÆ
  - `output/index.html`ÔºöÈÄöËøá Docker Volume ÊåÇËΩΩÔºåÂÆø‰∏ªÊú∫ÂèØÁõ¥Êé•ËÆøÈóÆ
- **ÂÖºÂÆπÊÄß**ÔºöÁ°Æ‰øù Docker„ÄÅGitHub Actions„ÄÅÊú¨Âú∞ËøêË°åÁéØÂ¢ÉÂùáËÉΩÊ≠£Â∏∏ËÆøÈóÆÁΩëÈ°µÁâàÊä•Âëä

**üê≥ Docker MCP ÈïúÂÉèÊîØÊåÅ**

- Êñ∞Â¢ûÁã¨Á´ãÁöÑ MCP ÊúçÂä°ÈïúÂÉè `wantcat/trendradar-mcp`
- ÊîØÊåÅ Docker ÈÉ®ÁΩ≤ AI ÂàÜÊûêÂäüËÉΩÔºåÈÄöËøá HTTP Êé•Âè£ÔºàÁ´ØÂè£ 3333ÔºâÊèê‰æõÊúçÂä°
- ÂèåÂÆπÂô®Êû∂ÊûÑÔºöÊñ∞ÈóªÊé®ÈÄÅÊúçÂä°‰∏é MCP ÊúçÂä°Áã¨Á´ãËøêË°åÔºåÂèØÂàÜÂà´Êâ©Â±ïÂíåÈáçÂêØ
- ËØ¶ËßÅ [Docker ÈÉ®ÁΩ≤ - MCP ÊúçÂä°](#6-docker-ÈÉ®ÁΩ≤)

**üåê Web ÊúçÂä°Âô®ÊîØÊåÅ**

- Êñ∞Â¢ûÂÜÖÁΩÆ Web ÊúçÂä°Âô®ÔºåÊîØÊåÅÈÄöËøáÊµèËßàÂô®ËÆøÈóÆÁîüÊàêÁöÑÊä•Âëä
- ÈÄöËøá `manage.py` ÂëΩ‰ª§ÊéßÂà∂ÂêØÂä®/ÂÅúÊ≠¢Ôºö`docker exec -it trendradar python manage.py start_webserver`
- ËÆøÈóÆÂú∞ÂùÄÔºö`http://localhost:8080`ÔºàÁ´ØÂè£ÂèØÈÖçÁΩÆÔºâ
- ÂÆâÂÖ®ÁâπÊÄßÔºöÈùôÊÄÅÊñá‰ª∂ÊúçÂä°„ÄÅÁõÆÂΩïÈôêÂà∂„ÄÅÊú¨Âú∞ËÆøÈóÆ
- ÊîØÊåÅËá™Âä®ÂêØÂä®ÂíåÊâãÂä®ÊéßÂà∂‰∏§ÁßçÊ®°Âºè

**üìñ ÊñáÊ°£‰ºòÂåñ**

- Êñ∞Â¢û [Êé®ÈÄÅÂÜÖÂÆπÊÄé‰πàÊòæÁ§∫Ôºü](#7-Êé®ÈÄÅÂÜÖÂÆπÊÄé‰πàÊòæÁ§∫) Á´†ËäÇÔºöËá™ÂÆö‰πâÊé®ÈÄÅÊ†∑ÂºèÂíåÂÜÖÂÆπ
- Êñ∞Â¢û [‰ªÄ‰πàÊó∂ÂÄôÁªôÊàëÊé®ÈÄÅÔºü](#8-‰ªÄ‰πàÊó∂ÂÄôÁªôÊàëÊé®ÈÄÅ) Á´†ËäÇÔºöËÆæÁΩÆÊé®ÈÄÅÊó∂Èó¥ÊÆµ
- Êñ∞Â¢û [Â§ö‰πÖËøêË°å‰∏ÄÊ¨°Ôºü](#9-Â§ö‰πÖËøêË°å‰∏ÄÊ¨°) Á´†ËäÇÔºöËÆæÁΩÆËá™Âä®ËøêË°åÈ¢ëÁéá
- Êñ∞Â¢û [Êé®ÈÄÅÂà∞Â§ö‰∏™Áæ§/ËÆæÂ§á](#10-Êé®ÈÄÅÂà∞Â§ö‰∏™Áæ§ËÆæÂ§á) Á´†ËäÇÔºöÂêåÊó∂Êé®ÈÄÅÁªôÂ§ö‰∏™Êé•Êî∂ËÄÖ
- ‰ºòÂåñÂêÑÈÖçÁΩÆÁ´†ËäÇÔºöÁªü‰∏ÄÊ∑ªÂä†&quot;ÈÖçÁΩÆ‰ΩçÁΩÆ&quot;ËØ¥Êòé
- ÁÆÄÂåñÂø´ÈÄüÂºÄÂßãÈÖçÁΩÆËØ¥ÊòéÔºö‰∏â‰∏™Ê†∏ÂøÉÊñá‰ª∂‰∏ÄÁõÆ‰∫ÜÁÑ∂
- ‰ºòÂåñ [Docker ÈÉ®ÁΩ≤](#6-docker-ÈÉ®ÁΩ≤) Á´†ËäÇÔºöÊñ∞Â¢ûÈïúÂÉèËØ¥Êòé„ÄÅÊé®Ëçê git clone ÈÉ®ÁΩ≤„ÄÅÈáçÁªÑÈÉ®ÁΩ≤ÊñπÂºè

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`„ÄÅ`config/config.yaml`ÔºàÊñ∞Â¢ûÂ§öË¥¶Âè∑Êé®ÈÄÅÊîØÊåÅÔºåÊó†ÈúÄ‰øÆÊîπÁé∞ÊúâÈÖçÁΩÆÔºâ
- **Â§öË¥¶Âè∑Êé®ÈÄÅ**ÔºöÊñ∞ÂäüËÉΩÔºåÈªòËÆ§‰∏çÂêØÁî®ÔºåÁé∞ÊúâÂçïË¥¶Âè∑ÈÖçÁΩÆ‰∏çÂèóÂΩ±Âìç


### 2025/11/26 - mcp-v1.0.3

  **MCP Ê®°ÂùóÊõ¥Êñ∞:**
  - Êñ∞Â¢ûÊó•ÊúüËß£ÊûêÂ∑•ÂÖ∑ resolve_date_range,Ëß£ÂÜ≥ AI Ê®°ÂûãËÆ°ÁÆóÊó•Êúü‰∏ç‰∏ÄËá¥ÁöÑÈóÆÈ¢ò
  - ÊîØÊåÅËá™ÁÑ∂ËØ≠Ë®ÄÊó•ÊúüË°®ËææÂºèËß£Êûê(Êú¨Âë®„ÄÅÊúÄËøë7Â§©„ÄÅ‰∏äÊúàÁ≠â)
  - Â∑•ÂÖ∑ÊÄªÊï∞‰ªé 13 ‰∏™Â¢ûÂä†Âà∞ 14 ‰∏™


### 2025/11/28 - v3.4.1

**üîß Ê†ºÂºè‰ºòÂåñ**

1. **Bark Êé®ÈÄÅÂ¢ûÂº∫**
   - Bark Áé∞ÊîØÊåÅ Markdown Ê∏≤Êüì
   - ÂêØÁî®ÂéüÁîü Markdown Ê†ºÂºèÔºöÁ≤ó‰Ωì„ÄÅÈìæÊé•„ÄÅÂàóË°®„ÄÅ‰ª£Á†ÅÂùóÁ≠â
   - ÁßªÈô§Á∫ØÊñáÊú¨ËΩ¨Êç¢ÔºåÂÖÖÂàÜÂà©Áî® Bark ÂéüÁîüÊ∏≤ÊüìËÉΩÂäõ

2. **Slack Ê†ºÂºèÁ≤æÂáÜÂåñ**
   - ‰ΩøÁî®‰∏ìÁî® mrkdwn Ê†ºÂºèÂ§ÑÁêÜÂàÜÊâπÂÜÖÂÆπ
   - ÊèêÂçáÂ≠óËäÇÂ§ßÂ∞è‰º∞ÁÆóÂáÜÁ°ÆÊÄßÔºàÈÅøÂÖçÊ∂àÊÅØË∂ÖÈôêÔºâ
   - ‰ºòÂåñÈìæÊé•Ê†ºÂºèÔºö`&lt;url|text&gt;` ÂíåÂä†Á≤óËØ≠Ê≥ïÔºö`*text*`

3. **ÊÄßËÉΩÊèêÂçá**
   - Ê†ºÂºèËΩ¨Êç¢Âú®ÂàÜÊâπËøáÁ®ã‰∏≠ÂÆåÊàêÔºåÈÅøÂÖç‰∫åÊ¨°Â§ÑÁêÜ
   - ÂáÜÁ°Æ‰º∞ÁÆóÊ∂àÊÅØÂ§ßÂ∞èÔºåÂáèÂ∞ëÂèëÈÄÅÂ§±Ë¥•Áéá

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`Ôºå`config.yaml`


### 2025/11/25 - v3.4.0

**üéâ Êñ∞Â¢û Slack Êé®ÈÄÅÊîØÊåÅ**

1. **Âõ¢ÈòüÂçè‰ΩúÊé®ÈÄÅÊ∏†ÈÅì**
   - ÊîØÊåÅ Slack Incoming WebhooksÔºàÂÖ®ÁêÉÊµÅË°åÁöÑÂõ¢ÈòüÂçè‰ΩúÂ∑•ÂÖ∑Ôºâ
   - Ê∂àÊÅØÈõÜ‰∏≠ÁÆ°ÁêÜÔºåÈÄÇÂêàÂõ¢ÈòüÂÖ±‰∫´ÁÉ≠ÁÇπËµÑËÆØ
   - ÊîØÊåÅ mrkdwn Ê†ºÂºèÔºàÁ≤ó‰Ωì„ÄÅÈìæÊé•Á≠âÔºâ

2. **Â§öÁßçÈÉ®ÁΩ≤ÊñπÂºè**
   - GitHub ActionsÔºöÈÖçÁΩÆ `SLACK_WEBHOOK_URL` Secret
   - DockerÔºöÁéØÂ¢ÉÂèòÈáè `SLACK_WEBHOOK_URL`
   - Êú¨Âú∞ËøêË°åÔºö`config/config.yaml` ÈÖçÁΩÆÊñá‰ª∂


&gt; üìñ **ËØ¶ÁªÜÈÖçÁΩÆÊïôÁ®ã**Ôºö[Âø´ÈÄüÂºÄÂßã - Slack Êé®ÈÄÅ](#-Âø´ÈÄüÂºÄÂßã)

- ‰ºòÂåñ setup-windows.bat Âíå setup-windows-en.bat ‰∏ÄÈîÆÂÆâË£Ö MCP ÁöÑ‰ΩìÈ™å

**üîß ÂçáÁ∫ßËØ¥Êòé**Ôºö
- **GitHub Fork Áî®Êà∑**ÔºöÊõ¥Êñ∞ `main.py`„ÄÅ`config/config.yaml`„ÄÅ`.github/workflows/crawler.yml`


### 2025/11/24 - v3.3.0

**üéâ Êñ∞Â¢û B

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[NevaMind-AI/memU]]></title>
            <link>https://github.com/NevaMind-AI/memU</link>
            <guid>https://github.com/NevaMind-AI/memU</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:27 GMT</pubDate>
            <description><![CDATA[Memory for 24/7 proactive agents like openclaw (moltbot, clawdbot).]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/NevaMind-AI/memU">NevaMind-AI/memU</a></h1>
            <p>Memory for 24/7 proactive agents like openclaw (moltbot, clawdbot).</p>
            <p>Language: Python</p>
            <p>Stars: 10,458</p>
            <p>Forks: 781</p>
            <p>Stars today: 508 stars today</p>
            <h2>README</h2><pre>![MemU Banner](assets/banner.png)

&lt;div align=&quot;center&quot;&gt;

# memU

### 24/7 Always-On Proactive Memory for AI Agents

[![PyPI version](https://badge.fury.io/py/memu-py.svg)](https://badge.fury.io/py/memu-py)
[![License: Apache 2.0](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![Discord](https://img.shields.io/badge/Discord-Join%20Chat-5865F2?logo=discord&amp;logoColor=white)](https://discord.gg/memu)
[![Twitter](https://img.shields.io/badge/Twitter-Follow-1DA1F2?logo=x&amp;logoColor=white)](https://x.com/memU_ai)

&lt;a href=&quot;https://trendshift.io/repositories/17374&quot; target=&quot;_blank&quot;&gt;&lt;img src=&quot;https://trendshift.io/api/badge/repositories/17374&quot; alt=&quot;NevaMind-AI%2FmemU | Trendshift&quot; style=&quot;width: 250px; height: 55px;&quot; width=&quot;250&quot; height=&quot;55&quot;/&gt;&lt;/a&gt;

**[English](readme/README_en.md) | [‰∏≠Êñá](readme/README_zh.md) | [Êó•Êú¨Ë™û](readme/README_ja.md) | [ÌïúÍµ≠Ïñ¥](readme/README_ko.md) | [Espa√±ol](readme/README_es.md) | [Fran√ßais](readme/README_fr.md)**

&lt;/div&gt;

---

memU is a memory framework built for **24/7 proactive agents**.
It is designed for long-running use and greatly **reduces the LLM token cost** of keeping agents always online, making always-on, evolving agents practical in production systems.
memU **continuously captures and understands user intent**. Even without a command, the agent can tell what you are about to do and act on it by itself.

---

## ü§ñ [OpenClaw (Moltbot, Clawdbot) Alternative](https://memu.bot)

&lt;img width=&quot;100%&quot; src=&quot;https://github.com/NevaMind-AI/memU/blob/main/assets/memUbot.png&quot; /&gt;

- **Download-and-use and simple** to get started.
- Builds long-term memory to **understand user intent** and act proactively.
- **Cuts LLM token cost** with smaller context.

Try now: [memU bot](https://memu.bot)

---

## üóÉÔ∏è Memory as File System, File System as Memory

memU treats **memory like a file system**‚Äîstructured, hierarchical, and instantly accessible.

| File System | memU Memory |
|-------------|-------------|
| üìÅ Folders | üè∑Ô∏è Categories (auto-organized topics) |
| üìÑ Files | üß† Memory Items (extracted facts, preferences, skills) |
| üîó Symlinks | üîÑ Cross-references (related memories linked) |
| üìÇ Mount points | üì• Resources (conversations, documents, images) |

**Why this matters:**
- **Navigate memories** like browsing directories‚Äîdrill down from broad categories to specific facts
- **Mount new knowledge** instantly‚Äîconversations and documents become queryable memory
- **Cross-link everything**‚Äîmemories reference each other, building a connected knowledge graph
- **Persistent &amp; portable**‚Äîexport, backup, and transfer memory like files

```
memory/
‚îú‚îÄ‚îÄ preferences/
‚îÇ   ‚îú‚îÄ‚îÄ communication_style.md
‚îÇ   ‚îî‚îÄ‚îÄ topic_interests.md
‚îú‚îÄ‚îÄ relationships/
‚îÇ   ‚îú‚îÄ‚îÄ contacts/
‚îÇ   ‚îî‚îÄ‚îÄ interaction_history/
‚îú‚îÄ‚îÄ knowledge/
‚îÇ   ‚îú‚îÄ‚îÄ domain_expertise/
‚îÇ   ‚îî‚îÄ‚îÄ learned_skills/
‚îî‚îÄ‚îÄ context/
    ‚îú‚îÄ‚îÄ recent_conversations/
    ‚îî‚îÄ‚îÄ pending_tasks/
```

Just as a file system turns raw bytes into organized data, memU transforms raw interactions into **structured, searchable, proactive intelligence**.

---

## ‚≠êÔ∏è Star the repository

&lt;img width=&quot;100%&quot; src=&quot;https://github.com/NevaMind-AI/memU/blob/main/assets/star.gif&quot; /&gt;
If you find memU useful or interesting, a GitHub Star ‚≠êÔ∏è would be greatly appreciated.

---


## ‚ú® Core Features

| Capability | Description |
|------------|-------------|
| ü§ñ **24/7 Proactive Agent** | Always-on memory agent that works continuously in the background‚Äînever sleeps, never forgets |
| üéØ **User Intention Capture** | Understands and remembers user goals, preferences, and context across sessions automatically |
| üí∞ **Cost Efficient** | Reduces long-running token costs by caching insights and avoiding redundant LLM calls |
---

## üîÑ How Proactive Memory Works

```bash

cd examples/proactive
python proactive.py

```

---

### Proactive Memory Lifecycle
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                                         USER QUERY                                               ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ                                                           ‚îÇ
                 ‚ñº                                                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         ü§ñ MAIN AGENT                  ‚îÇ         ‚îÇ              üß† MEMU BOT                       ‚îÇ
‚îÇ                                        ‚îÇ         ‚îÇ                                                ‚îÇ
‚îÇ  Handle user queries &amp; execute tasks   ‚îÇ  ‚óÑ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  Monitor, memorize &amp; proactive intelligence   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                        ‚îÇ         ‚îÇ                                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  1. RECEIVE USER INPUT           ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  1. MONITOR INPUT/OUTPUT                 ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Parse query, understand      ‚îÇ  ‚îÇ   ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  ‚îÇ     Observe agent interactions           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     context and intent           ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ     Track conversation flow              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  2. PLAN &amp; EXECUTE               ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  2. MEMORIZE &amp; EXTRACT                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Break down tasks             ‚îÇ  ‚îÇ   ‚óÑ‚îÄ‚îÄ‚îÄ  ‚îÇ  ‚îÇ     Store insights, facts, preferences   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Call tools, retrieve data    ‚îÇ  ‚îÇ  inject ‚îÇ  ‚îÇ     Extract skills &amp; knowledge           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Generate responses           ‚îÇ  ‚îÇ  memory ‚îÇ  ‚îÇ     Update user profile                  ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  3. RESPOND TO USER              ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  3. PREDICT USER INTENT                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Deliver answer/result        ‚îÇ  ‚îÇ   ‚îÄ‚îÄ‚îÄ‚ñ∫  ‚îÇ  ‚îÇ     Anticipate next steps                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Continue conversation        ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ     Identify upcoming needs              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                 ‚îÇ                      ‚îÇ         ‚îÇ                    ‚îÇ                           ‚îÇ
‚îÇ                 ‚ñº                      ‚îÇ         ‚îÇ                    ‚ñº                           ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ         ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  4. LOOP                         ‚îÇ  ‚îÇ         ‚îÇ  ‚îÇ  4. RUN PROACTIVE TASKS                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     Wait for next user input     ‚îÇ  ‚îÇ   ‚óÑ‚îÄ‚îÄ‚îÄ  ‚îÇ  ‚îÇ     Pre-fetch relevant context           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ     or proactive suggestions     ‚îÇ  ‚îÇ  suggest‚îÇ  ‚îÇ     Prepare recommendations              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ         ‚îÇ  ‚îÇ     Update todolist autonomously         ‚îÇ  ‚îÇ
‚îÇ                                        ‚îÇ         ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ                                                           ‚îÇ
                 ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                             ‚ñº
                              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                              ‚îÇ     CONTINUOUS SYNC LOOP     ‚îÇ
                              ‚îÇ  Agent ‚óÑ‚îÄ‚îÄ‚ñ∫ MemU Bot ‚óÑ‚îÄ‚îÄ‚ñ∫ DB ‚îÇ
                              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üéØ Proactive Use Cases

### 1. **Information Recommendation**
*Agent monitors interests and proactively surfaces relevant content*
```python
# User has been researching AI topics
MemU tracks: reading history, saved articles, search queries

# When new content arrives:
Agent: &quot;I found 3 new papers on RAG optimization that align with
        your recent research on retrieval systems. One author
        (Dr. Chen) you&#039;ve cited before published yesterday.&quot;

# Proactive behaviors:
- Learns topic preferences from browsing patterns
- Tracks author/source credibility preferences
- Filters noise based on engagement history
- Times recommendations for optimal attention
```

### 2. **Email Management**
*Agent learns communication patterns and handles routine correspondence*
```python
# MemU observes email patterns over time:
- Response templates for common scenarios
- Priority contacts and urgent keywords
- Scheduling preferences and availability
- Writing style and tone variations

# Proactive email assistance:
Agent: &quot;You have 12 new emails. I&#039;ve drafted responses for 3 routine
        requests and flagged 2 urgent items from your priority contacts.
        Should I also reschedule tomorrow&#039;s meeting based on the
        conflict John mentioned?&quot;

# Autonomous actions:
‚úì Draft context-aware replies
‚úì Categorize and prioritize inbox
‚úì Detect scheduling conflicts
‚úì Summarize long threads with key decisions
```

### 3. **Trading &amp; Financial Monitoring**
*Agent tracks market context and user investment behavior*
```python
# MemU learns trading preferences:
- Risk tolerance from historical decisions
- Preferred sectors and asset classes
- Response patterns to market events
- Portfolio rebalancing triggers

# Proactive alerts:
Agent: &quot;NVDA dropped 5% in after-hours trading. Based on your past
        behavior, you typically buy tech dips above 3%. Your current
        allocation allows for $2,000 additional exposure while
        maintaining your 70/30 equity-bond target.&quot;

# Continuous monitoring:
- Track price alerts tied to user-defined thresholds
- Correlate news events with portfolio impact
- Learn from executed vs. ignored recommendations
- Anticipate tax-loss harvesting opportunities
```


...

---

## üóÇÔ∏è Hierarchical Memory Architecture

MemU&#039;s three-layer system enables both **reactive queries** and **proactive context loading**:

&lt;img width=&quot;100%&quot; alt=&quot;structure&quot; src=&quot;assets/structure.png&quot; /&gt;

| Layer | Reactive Use | Proactive Use |
|-------|--------------|---------------|
| **Resource** | Direct access to original data | Background monitoring for new patterns |
| **Item** | Targeted fact retrieval | Real-time extraction from ongoing interactions |
| **Category** | Summary-level overview | Automatic context assembly for anticipation |

**Proactive Benefits:**
- **Auto-categorization**: New memories self-organize into topics
- **Pattern Detection**: System identifies recurring themes
- **Context Prediction**: Anticipates what information will be needed next

---

## üöÄ Quick Start

### Option 1: Cloud Version

Experience proactive memory instantly:

üëâ **[memu.so](https://memu.so)** - Hosted service with 7√ó24 continuous learning

For enterprise deployment with custom proactive workflows, contact **info@nevamind.ai**

#### Cloud API (v3)

| Base URL | `https://api.memu.so` |
|----------|----------------------|
| Auth | `Authorization: Bearer YOUR_API_KEY` |

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/v3/memory/memorize` | Register continuous learning task |
| `GET` | `/api/v3/memory/memorize/status/{task_id}` | Check real-time processing status |
| `POST` | `/api/v3/memory/categories` | List auto-generated categories |
| `POST` | `/api/v3/memory/retrieve` | Query memory (supports proactive context loading) |

üìö **[Full API Documentation](https://memu.pro/docs#cloud-version)**

---

### Option 2: Self-Hosted

#### Installation
```bash
pip install -e .
```

#### Basic Example

&gt; **Requirements**: Python 3.13+ and an OpenAI API key

**Test Continuous Learning** (in-memory):
```bash
export OPENAI_API_KEY=your_api_key
cd tests
python test_inmemory.py
```

**Test with Persistent Storage** (PostgreSQL):
```bash
# Start PostgreSQL with pgvector
docker run -d \
  --name memu-postgres \
  -e POSTGRES_USER=postgres \
  -e POSTGRES_PASSWORD=postgres \
  -e POSTGRES_DB=memu \
  -p 5432:5432 \
  pgvector/pgvector:pg16

# Run continuous learning test
export OPENAI_API_KEY=your_api_key
cd tests
python test_postgres.py
```

Both examples demonstrate **proactive memory workflows**:
1. **Continuous Ingestion**: Process multiple files sequentially
2. **Auto-Extraction**: Immediate memory creation
3. **Proactive Retrieval**: Context-aware memory surfacing

See [`tests/test_inmemory.py`](tests/test_inmemory.py) and [`tests/test_postgres.py`](tests/test_postgres.py) for implementation details.

---

### Custom LLM and Embedding Providers

MemU supports custom LLM and embedding providers beyond OpenAI. Configure them via `llm_profiles`:
```python
from memu import MemUService

service = MemUService(
    llm_profiles={
        # Default profile for LLM operations
        &quot;default&quot;: {
            &quot;base_url&quot;: &quot;https://dashscope.aliyuncs.com/compatible-mode/v1&quot;,
            &quot;api_key&quot;: &quot;your_api_key&quot;,
            &quot;chat_model&quot;: &quot;qwen3-max&quot;,
            &quot;client_backend&quot;: &quot;sdk&quot;  # &quot;sdk&quot; or &quot;http&quot;
        },
        # Separate profile for embeddings
        &quot;embedding&quot;: {
            &quot;base_url&quot;: &quot;https://api.voyageai.com/v1&quot;,
            &quot;api_key&quot;: &quot;your_voyage_api_key&quot;,
            &quot;embed_model&quot;: &quot;voyage-3.5-lite&quot;
        }
    },
    # ... other configuration
)
```

---

### OpenRouter Integration

MemU supports [OpenRouter](https://openrouter.ai) as a model provider, giving you access to multiple LLM providers through a single API.

#### Configuration
```python
from memu import MemoryService

service = MemoryService(
    llm_profiles={
        &quot;default&quot;: {
            &quot;provider&quot;: &quot;openrouter&quot;,
            &quot;client_backend&quot;: &quot;httpx&quot;,
            &quot;base_url&quot;: &quot;https://openrouter.ai&quot;,
            &quot;api_key&quot;: &quot;your_openrouter_api_key&quot;,
            &quot;chat_model&quot;: &quot;anthropic/claude-3.5-sonnet&quot;,  # Any OpenRouter model
            &quot;embed_model&quot;: &quot;openai/text-embedding-3-small&quot;,  # Embedding model
        },
    },
    database_config={
        &quot;metadata_store&quot;: {&quot;provider&quot;: &quot;inmemory&quot;},
    },
)
```

#### Environment Variables

| Variable | Description |
|----------|-------------|
| `OPENROUTER_API_KEY` | Your OpenRouter API key from [openrouter.ai/keys](https://openrouter.ai/keys) |

#### Supported Features

| Feature | Status | Notes |
|---------|--------|-------|
| Chat Completions | Supported | Works with any OpenRouter chat model |
| Embeddings | Supported | Use OpenAI embedding models via OpenRouter |
| Vision | Supported | Use vision-capable models (e.g., `openai/gpt-4o`) |

#### Running OpenRouter Tests
```bash
export OPENROUTER_API_KEY=your_api_key

# Full workflow test (memorize + retrieve)
python tests/test_openrouter.py

# Embedding-specific tests
python tests/test_openrouter_embedding.py

# Vision-specific tests
python tests/test_openrouter_vision.py
```

See [`examples/example_4_openrouter_memory.py`](examples/example_4_openrouter_memory.py) for a complete working example.

---

## üìñ Core APIs

### `memorize()` - Continuous Learning Pipeline

Processes inputs in real-time and immediately updates memory:

&lt;img width=&quot;100%&quot; alt=&quot;memorize&quot; src=&quot;assets/memorize.png&quot; /&gt;

```python
result = await service.memorize(
    resource_url=&quot;path/to/file.json&quot;,  # File path or URL
    modality=&quot;conversation&quot;,            # conversation | document | image | video | audio
    user={&quot;user_id&quot;: &quot;123&quot;}             # Optional: scope to a user
)

# Returns immediately with extracted memory:
{
    &quot;resource&quot;: {...},      # Stored resource metadata
    &quot;items&quot;: [...],         # Extracted memory items (available instantly)
    &quot;categories&quot;: [...]     # Auto-updated category structure
}
```

**Proactive Features:**
- Zero-delay processing‚Äîmemories available immediately
- Automatic categorization without manual tagging
- Cross-reference with existing memories for pattern detection

### `retrieve()` - Dual-Mode Intelligence

MemU supports both **proactive context loading** and **reactive querying**:

&lt;img width=&quot;100%&quot; alt=&quot;retrieve&quot; src=&quot;assets/retrieve.png&quot; /&gt;

#### RAG-based Retrieval (`method=&quot;rag&quot;`)

Fast **proactive context assembly** using embeddings:

- ‚úÖ **Instant context**: Sub-second memory surfacing
- ‚úÖ **Background monitoring**: Can run continuously without LLM costs
- ‚úÖ **Similarity scoring**: Identifies most relevant memories automatically

#### LLM-based Retrieval (`method=&quot;llm&quot;`)

Deep **anticipatory reasoning** for complex contexts:

- ‚úÖ **Intent prediction**: LLM infers what user needs before they ask
- ‚úÖ **Query evolution**: Automatically refines search as context develops
- ‚úÖ **Early termination**: Stops when sufficient context is gathered

#### Comparison

| Aspect | RAG (Fast Context) | LLM (Deep Reasoning) |
|--------|-------------------|---------------------|
| **Speed** | ‚ö° Milliseconds | üê¢ Seconds |
| **Cost** | üí∞ Embedding only | üí∞üí∞ LLM inference |
| **Proactive use** | Continuous monitoring | Triggered context loading |
| **Best for** | Real-time suggestions | Complex anticipation |

#### Usage
```python
# Proactive retrieval with context history
result = await service.retrieve(
    queries=[
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: {&quot;text&quot;: &quot;What are their preferences?&quot;}},
        {&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: {&quot;text&quot;: &quot;Tell me about work habits&quot;}}
    ],
    where={&quot;user_id&quot;: &quot;123&quot;},  # Optional: scope filter
    method=&quot;rag&quot;  # or &quot;llm&quot; for deeper reasoning
)

# Returns context-aware results:
{
    &quot;categories&quot;: [...],     # Relevant topic areas (auto-prioritized)
    &quot;items&quot;: [...],          # Specific memory facts
    &quot;resources&quot;: [...],      # Original sources for traceability
    &quot;next_step_query&quot;: &quot;...&quot; # Predicted follow-up context
}
```

**Proactive Filtering**: Use `where` to scope continuous monitoring:
- `where={&quot;user_id&quot;: &quot;123&quot;}` - User-specific context
- `where={&quot;agent_id__in&quot;: [&quot;1&quot;, &quot;2&quot;]}` - Multi-agent coordination
- Omit `where` for global context awareness

---

## üí° Proactive Scenarios

### Example 1: Always-Learning Assistant

Continuously learns from every interaction without explicit memory commands:
```bash
export OPENAI_API_KEY=your_api_key
python examples/example_1_conversation_memory.py
```

**Proactive Behavior:**
- Automatically extracts preferences from casual mentions
- Builds relationship models from interaction patterns
- Surfaces relevant context in future conversations
- Adapts communication style based on learned preferences

**Best for:** Personal AI assistants, customer support that remembers, social chatbots

---

### Example 2: Self-Improving Agent

Learns from execution logs and proactively suggests optimizations:
```bash
export OPENAI_API_KEY=your_api_key
python examples/example_2_skill_extraction.py
```

**Proactive Behavior:**
- Monitors agent actions and outcomes continuously
- Identifies patterns in successes and failures
- Auto-generates skill guides from experience
- Proactively suggests strategies for similar future tasks

**Best for:** DevOps automation, agent self-improvement, knowledge capture

---

### Example 3: Multimodal Context Builder

Unifies memory across different input types for comprehensive context:
```bash
export OPENAI

... [README content truncated due to size. Visit the repository for the complete README] ...</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[ShisatoYano/AutonomousVehicleControlBeginnersGuide]]></title>
            <link>https://github.com/ShisatoYano/AutonomousVehicleControlBeginnersGuide</link>
            <guid>https://github.com/ShisatoYano/AutonomousVehicleControlBeginnersGuide</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:26 GMT</pubDate>
            <description><![CDATA[Python sample codes and documents about Autonomous vehicle control algorithm. This project can be used as a technical guide book to study the algorithms and the software architectures for beginners.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/ShisatoYano/AutonomousVehicleControlBeginnersGuide">ShisatoYano/AutonomousVehicleControlBeginnersGuide</a></h1>
            <p>Python sample codes and documents about Autonomous vehicle control algorithm. This project can be used as a technical guide book to study the algorithms and the software architectures for beginners.</p>
            <p>Language: Python</p>
            <p>Stars: 1,398</p>
            <p>Forks: 209</p>
            <p>Stars today: 43 stars today</p>
            <h2>README</h2><pre># AutonomousVehicleControlBeginnersGuide
[![Linux_CI](https://github.com/ShisatoYano/AutonomousDrivingSamplePrograms/actions/workflows/Linux_CI.yml/badge.svg)](https://github.com/ShisatoYano/AutonomousDrivingSamplePrograms/actions/workflows/Linux_CI.yml) [![Windows_CI](https://github.com/ShisatoYano/AutonomousDrivingSamplePrograms/actions/workflows/Windows_CI.yml/badge.svg)](https://github.com/ShisatoYano/AutonomousDrivingSamplePrograms/actions/workflows/Windows_CI.yml) [![MacOS_CI](https://github.com/ShisatoYano/AutonomousDrivingSamplePrograms/actions/workflows/MacOS_CI.yml/badge.svg)](https://github.com/ShisatoYano/AutonomousDrivingSamplePrograms/actions/workflows/MacOS_CI.yml) [![CodeFactor](https://www.codefactor.io/repository/github/shisatoyano/autonomousvehiclecontrolbeginnersguide/badge)](https://www.codefactor.io/repository/github/shisatoyano/autonomousvehiclecontrolbeginnersguide)  

Python sample codes and documents about Autonomous vehicle control algorithm. This project can be used as a technical guide book to study the algorithms and the software architectures for beginners.  

![](src/simulations/mapping/ndt_map_construction/ndt_map_construction.gif)  


## Table of Contents
* [What is this?](#what-is-this)
* [Goal of this project](#goal-of-this-project)
* [Requirements](#requirements)
* [How to use](#how-to-use)
* [Examples of Simulation](#examples-of-simulation)
    * [Localization](#localization)
        * [Extended Kalman Filter Localization](#extended-kalman-filter-localization)
        * [Unscented Kalman Filter Localization](#unscented-kalman-filter-localization)
        * [Particle Filter Localization](#particle-filter-localization)
    * [Mapping](#mapping)
        * [Binary Occupancy Grid Map](#binary-occupancy-grid-map)
        * [Cost Map](#cost-map)
        * [Potential Field Map](#potential-field-map)
        * [NDT Map](#ndt-map)
    * [Path Planning](#path-planning)
        * [A*](#a)
        * [Bidirectional A*](#bidirectional-a)
        * [Hybrid A*](#hybrid-a)
        * [Dijkstra](#dijkstra)
        * [RRT](#rrt)
        * [Bidirectional RRT*](#bidirectional-rrt)
        * [RRT*](#rrt-star)
        * [Informed RRT*](#informed-rrt)
    * [Path Tracking](#path-tracking)
        * [Pure pursuit Path Tracking](#pure-pursuit-path-tracking)
        * [Adaptive Pure pursuit Path Tracking](#adaptive-pure-pursuit-path-tracking)
        * [Rear wheel feedback Path Tracking](#rear-wheel-feedback-path-tracking)
        * [LQR(Linear Quadratic Regulator) Path Tracking](#lqrlinear-quadratic-regulator-path-tracking)
        * [Stanley steering control Path tracking](#stanley-steering-control-path-tracking)
        * [MPPI Path Tracking](#mppi-path-tracking)
    * [Perception](#perception)
        * [Rectangle fitting Detection](#rectangle-fitting-detection)
        * [Sensor&#039;s Extrinsic Parameters Estimation](#sensors-extrinsic-parameters-estimation)
* [Documents](#documents)
* [License](#license)
* [Use Case](#use-case)
* [Contribution](#contribution)
* [Author](#author)


## What is this?
This is a sample codes collections about Autonomous vehicle control algorithm. Each source codes are implemented with Python to help your understanding. You can fork this repository and use for studying, education or work freely.  


## Goal of this project
I want to release my own technical book about Autonomous Vehicle algorithms in the future. The book will include all of codes and documents in this repository as contents.  


## Requirements
Please satisfy with the following requirements on native or VM Linux in advance.  
For running each sample codes:  
* [Python 3.13.x](https://www.python.org/)
* [Matplotlib](https://matplotlib.org/)
* [NumPy](https://numpy.org/)
* [SciPy](https://scipy.org/)

For development:
* [pytest](https://docs.pytest.org/en/7.4.x/) (for unit tests)
* [pytest-cov](https://github.com/pytest-dev/pytest-cov) (for coverage measurement)

For setting up the environment with Docker:
* [VS Code](https://code.visualstudio.com/)
* [Docker](https://www.docker.com/)


## How to use
1. Clone this repository  
    ```bash
    $ git clone https://github.com/ShisatoYano/AutonomousVehicleControlBeginnersGuide
    ```

2. Set up the environment for running each codes
    * Set up with Docker on WSL:
        * Before cloning thi repo, [install Docker](https://docs.docker.com/desktop/install/linux-install/) in advance
        * Clone this repo following the above Step 1
        * Open this repo&#039;s folder by VSCode
        * [Create Dev Container](https://code.visualstudio.com/docs/devcontainers/create-dev-container)
        * And then, all required libraries are installed automatically
3. Execute unit tests to confirm the environment were installed successfully
    ```bash
    $ . run_test_suites.sh
    ```
4. Execute a python script at src/simulations directory
    * For example, when you want to execute localization simulation of Extended Kalman Filter:
        ```bash
        $ python src/simulations/localization/extended_kalman_filter_localization/extended_kalman_filter_localization.py
        ```
5. Add star to this repository if you like it!!


## Examples of Simulation
### Localization
#### Extended Kalman Filter Localization
![](src/simulations/localization/extended_kalman_filter_localization/extended_kalman_filter_localization.gif)  
#### Unscented Kalman Filter Localization
![](src/simulations/localization/unscented_kalman_filter_localization/unscented_kalman_filter_localization.gif)  
#### Particle Filter Localization
![](src/simulations/localization/particle_filter_localization/particle_filter_localization.gif)  
### Mapping
#### Binary Occupancy Grid Map
![](src/simulations/mapping/binary_grid_map_construction/binary_grid_map_construction.gif)  
#### Cost Map
![](src/simulations/mapping/cost_grid_map_construction/cost_grid_map_construction.gif)  
#### Potential Field Map
![](src/simulations/mapping/potential_field_map_construction/potential_field_demo.gif)   
#### NDT Map
![](src/simulations/mapping/ndt_map_construction/ndt_map_construction.gif)  
### Path Planning
#### A*
Planning  
![](src/simulations/path_planning/astar_path_planning/astar_search.gif)  
#### Bidirectional A*
Planning  
![](src/simulations/path_planning/astar_bidirectional_path_planning/astar_bidirectional_search.gif)  
#### Hybrid A*
Planning  
![](src/simulations/path_planning/astar_hybrid_path_planning/astar_hybrid_search.gif)  
#### Dijkstra
Planning(Reduce frames by sampling every nth node to prevent memory exhaustion)  
![](src/simulations/path_planning/dijkstra_path_planning/dijkstra_search.gif)  
#### RRT
Planning  
![](src/simulations/path_planning/rrt_path_planning/rrt_search.gif)  
Navigation  
![](src/simulations/path_planning/rrt_path_planning/rrt_navigate.gif)  
#### Bidirectional RRT*
Planning  
![](src/simulations/path_planning/rrt_star_bidirectional_path_planning/rrt_star_bidirectional_search.gif)  
Navigation  
![](src/simulations/path_planning/rrt_star_bidirectional_path_planning/rrt_star_bidirectional_navigate.gif)  
#### RRT*
Planning  
![](src/simulations/path_planning/rrt_star_path_planning/rrt_star_search.gif)  
Navigation  
![](src/simulations/path_planning/rrt_star_path_planning/rrt_star_navigate.gif)  
#### Informed RRT*
Planning  
![](src/simulations/path_planning/informed_rrt_star_path_planning/informed_rrt_star_search.gif)  
Navigation  
![](src/simulations/path_planning/informed_rrt_star_path_planning/informed_rrt_star_navigate.gif)  
### Path Tracking
#### Pure pursuit Path Tracking
![](src/simulations/path_tracking/pure_pursuit_path_tracking/pure_pursuit_path_tracking.gif)  
#### Adaptive Pure pursuit Path Tracking
![](src/simulations/path_tracking/adaptive_pure_pursuit_path_tracking/adaptive_pure_pursuit_path_tracking.gif)  
#### Rear wheel feedback Path Tracking
![](src/simulations//path_tracking/rear_wheel_feedback_tracking/rear_wheel_feedback_tracking.gif)  
#### LQR(Linear Quadratic Regulator) Path Tracking
![](src/simulations/path_tracking/lqr_path_tracking/lqr_path_tracking.gif)  
#### Stanley steering control Path Tracking
![](src/simulations/path_tracking/stanley_path_tracking/stanley_path_tracking.gif)  
#### MPPI Path Tracking
![](src/simulations/path_tracking/mppi_path_tracking/mppi_path_tracking.gif)  
### Perception
#### Rectangle fitting Detection
![](src/simulations/perception/point_cloud_rectangle_fitting/point_cloud_rectangle_fitting.gif)  
#### Sensor&#039;s Extrinsic Parameters Estimation
Estimation by Unscented Kalman Filter  
![](src/simulations/perception/sensor_auto_calibration/sensor_auto_calibration.gif)  


## Documents
Design documents of each Python programs are prepared here. The documents are still not completed. They have been being updated. If you found any problems in them, please tell me by creating an issue.  
[Documents link](/doc/DESIGN_DOCUMENT.md)  


## License
MIT  


## Use Case
I started this project to study an algorithm and software development for Autonomous Vehicle system by myself. You can also use this repo for your own studying, education, researching and development.  

If this project helps your task, please let me know by creating a issue.  
Any paper, animation, video as your output, always welcome!! It will encourage me to continue this project.  

Your comment and output is added to [this list of user comments](/USERS_COMMENTS.md).  


## Contribution
Any contribution by creating an issue or sending a pull request is welcome!! Please check [this document about how to contribute](/HOWTOCONTRIBUTE.md).  


## Author
[Shisato Yano](https://github.com/ShisatoYano)  
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[business-science/ai-data-science-team]]></title>
            <link>https://github.com/business-science/ai-data-science-team</link>
            <guid>https://github.com/business-science/ai-data-science-team</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:25 GMT</pubDate>
            <description><![CDATA[An AI-powered data science team of agents to help you perform common data science tasks 10X faster.]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/business-science/ai-data-science-team">business-science/ai-data-science-team</a></h1>
            <p>An AI-powered data science team of agents to help you perform common data science tasks 10X faster.</p>
            <p>Language: Python</p>
            <p>Stars: 4,945</p>
            <p>Forks: 850</p>
            <p>Stars today: 93 stars today</p>
            <h2>README</h2><pre>&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://github.com/business-science/ai-data-science-team&quot;&gt;
    &lt;picture&gt;
      &lt;img src=&quot;./img/ai_data_science_logo.png&quot; alt=&quot;AI Data Science Team&quot; width=&quot;360&quot;&gt;
    &lt;/picture&gt;
  &lt;/a&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;em&gt;AI Data Science Team + AI Pipeline Studio&lt;/em&gt;
&lt;/div&gt;
&lt;div align=&quot;center&quot;&gt;
  &lt;a href=&quot;https://pypi.python.org/pypi/ai-data-science-team&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/v/ai-data-science-team.svg?style=for-the-badge&quot; alt=&quot;PyPI&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/business-science/ai-data-science-team&quot;&gt;&lt;img src=&quot;https://img.shields.io/pypi/pyversions/ai-data-science-team.svg?style=for-the-badge&quot; alt=&quot;versions&quot;&gt;&lt;/a&gt;
  &lt;a href=&quot;https://github.com/business-science/ai-data-science-team/blob/main/LICENSE&quot;&gt;&lt;img src=&quot;https://img.shields.io/github/license/business-science/ai-data-science-team.svg?style=for-the-badge&quot; alt=&quot;license&quot;&gt;&lt;/a&gt;
  &lt;img alt=&quot;GitHub Repo stars&quot; src=&quot;https://img.shields.io/github/stars/business-science/ai-data-science-team?style=for-the-badge&quot;&gt;
&lt;/div&gt;

# AI Data Science Team

AI Data Science Team is a Python library of specialized agents for common data science workflows, plus a flagship app: **AI Pipeline Studio**. The Studio turns your work into a visual, reproducible pipeline, while the AI team handles data loading, cleaning, visualization, and modeling.

**Status:** Beta. Breaking changes may occur until 0.1.0.

[**Please ‚≠ê us on GitHub (it takes 2 seconds and means a lot).**](https://github.com/business-science/ai-data-science-team)

## AI Pipeline Studio (Flagship App)

AI Pipeline Studio is the main example of the AI Data Science Team in action.

![AI Pipeline Studio](/img/apps/ai_pipeline_studio_app.jpg)

Highlights:
- Pipeline-first workspace: Visual Editor, Table, Chart, EDA, Code, Model, Predictions, MLflow
- Manual + AI steps with lineage and reproducible scripts
- Multi-dataset handling and merge workflows
- Project saves: metadata-only or full-data
- Storage footprint controls and rehydrate workflows

Run it:
```bash
streamlit run apps/ai-pipeline-studio-app/app.py
```

Full app docs: `apps/ai-pipeline-studio-app/README.md`

## Quickstart

### Requirements
- Python 3.10+
- OpenAI API key (or Ollama for local models)

### Install the app and library
Clone the repo and install in editable mode:
```bash
pip install -e .
```

### Run the AI Pipeline Studio app
```bash
streamlit run apps/ai-pipeline-studio-app/app.py
```

## Library Overview

The repository includes both the **AI Pipeline Studio** app and the underlying **AI Data Science Team** library. The library provides agent building blocks and multi-agent workflows for:
- Data loading and inspection
- Cleaning, wrangling, and feature engineering
- Visualization and EDA
- Modeling and evaluation (H2O + MLflow tools)
- SQL database interaction

### Agents (Snapshot)

Agent examples live in `examples/`. Notable agents:
- Data Loader Tools Agent
- Data Wrangling Agent
- Data Cleaning Agent
- Data Visualization Agent
- EDA Tools Agent
- Feature Engineering Agent
- SQL Database Agent
- H2O ML Agent
- MLflow Tools Agent
- Multi-agent workflows (e.g., Pandas Data Analyst, SQL Data Analyst)
- Supervisor Agent (oversees other agents)
- Custom tools for data science tasks

## Apps

See all apps in `apps/`. Notable apps:
- AI Pipeline Studio: `apps/ai-pipeline-studio-app/`
- EDA Explorer App: `apps/exploratory-copilot-app/`
- Pandas Data Analyst App: `apps/pandas-data-analyst-app/`

## Use OpenAI

```python
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(
    model_name=&quot;gpt-4.1-mini&quot;,
)
```

## Use Ollama (Local LLM)

```bash
ollama serve
ollama pull llama3.1:8b
```

```python
from langchain_ollama import ChatOllama

llm = ChatOllama(
    model=&quot;llama3.1:8b&quot;,
)
```

## Next-Gen AI Agentic Workshop

Want to learn how to build AI agents and AI apps for real data science workflows? Join my next‚Äëgen AI workshop:
https://learn.business-science.io/ai-register
</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
        <item>
            <title><![CDATA[mihail911/modern-software-dev-assignments]]></title>
            <link>https://github.com/mihail911/modern-software-dev-assignments</link>
            <guid>https://github.com/mihail911/modern-software-dev-assignments</guid>
            <pubDate>Wed, 25 Feb 2026 00:08:24 GMT</pubDate>
            <description><![CDATA[Assignments for CS146S: The Modern Software Dev (Stanford University Fall 2025)]]></description>
            <content:encoded><![CDATA[
            <h1><a href="https://github.com/mihail911/modern-software-dev-assignments">mihail911/modern-software-dev-assignments</a></h1>
            <p>Assignments for CS146S: The Modern Software Dev (Stanford University Fall 2025)</p>
            <p>Language: Python</p>
            <p>Stars: 2,195</p>
            <p>Forks: 512</p>
            <p>Stars today: 131 stars today</p>
            <h2>README</h2><pre># Assignments for CS146S: The Modern Software Developer

This is the home of the assignments for [CS146S: The Modern Software Developer](https://themodernsoftware.dev), taught at Stanford University fall 2025.

## Repo Setup
These steps work with Python 3.12.

1. Install Anaconda
   - Download and install: [Anaconda Individual Edition](https://www.anaconda.com/download)
   - Open a new terminal so `conda` is on your `PATH`.

2. Create and activate a Conda environment (Python 3.12)
   ```bash
   conda create -n cs146s python=3.12 -y
   conda activate cs146s
   ```

3. Install Poetry
   ```bash
   curl -sSL https://install.python-poetry.org | python -
   ```

4. Install project dependencies with Poetry (inside the activated Conda env)
   From the repository root:
   ```bash
   poetry install --no-interaction
   ```</pre>
          ]]></content:encoded>
            <category>Python</category>
        </item>
    </channel>
</rss>